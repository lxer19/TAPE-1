URL: http://www.isi.edu/isd/rickel/mii97.ps
Refering-URL: http://www.isi.edu/isd/rickel/publications.html
Root-URL: http://www.isi.edu
Email: rickel, johnson@isi.edu  
Title: Computational Models for Mixed Initiative Interaction, March 1997. Mixed-Initiative Interaction between Pedagogical Agents and Students
Author: Jeff Rickel and W. Lewis Johnson 
Web: http://www.isi.edu/isd/VET/vet.html  
Address: 4676 Admiralty Way, Marina del Rey, CA 90292-6695  
Affiliation: Information Sciences Institute Computer Science Department University of Southern California  
Note: Appears in Proceedings of AAAI Spring Symposium on  
Abstract: Virtual reality can broaden the types of interaction between students and computer tutors. As in conventional simulation-based training, the computer can watch students practice tasks, responding to questions and offering advice. However, immersive virtual environments also allow the computer tutor to physically inhabit the virtual world with the student. Such a "pedagogical agent" can physically collaborate with the student on tasks and employ the sorts of nonverbal communication used by human tutors. This paper describes Steve, a pedagogical agent for virtual environments that helps students learn procedural tasks. Steve inhabits the virtual world with students, and he collaborates with them on tasks by gracefully shifting between demonstrating the task and providing assistance while the student performs the task. The paper also describes the subtle ways in which such a pedagogical agent can interact with students through nonverbal communication to achieve more human-like collaboration. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Badler, N. I.; Phillips, C. B.; and Webber, B. L. </author> <year> 1993. </year> <title> Simulating Humans. </title> <address> New York: </address> <publisher> Oxford University Press. </publisher>
Reference-contexts: We are also developing methods by which Steve can appear as a full human figure, using the Jack software developed at the University of Penn-sylvania <ref> (Badler, Phillips, & Webber 1993) </ref>. For example, Figure 4 shows one Steve agent, represented by a human figure, watching (via dynamic gaze control) a demonstration by another Steve agent, represented by a hand.
Reference: <author> Billinghurst, M., and Savage, J. </author> <year> 1996. </year> <title> Adding intelligence to the interface. </title> <booktitle> In Proceedings of the IEEE Virtual Reality Annual International Symposium (VRAIS '96), </booktitle> <pages> 168-175. </pages> <address> Los Alamitos, CA: </address> <publisher> IEEE Computer Society Press. </publisher>
Reference: <author> Cassell, J.; Pelachaud, C.; Badler, N.; Steedman, M.; Achorn, B.; Becket, T.; Douville, B.; Prevost, S.; and Stone, M. </author> <year> 1994. </year> <title> Animated conversation: Rule-based generation of facial expression, gesture and spoken intonation for multiple conversational agents. </title> <booktitle> In Proceedings of ACM SIGGRAPH '94. </booktitle>
Reference: <author> Cawsey, A. </author> <year> 1992. </year> <title> Explanation and Interaction: The Computer Generation of Explanatory Dialogues. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Ultimately, we are working toward an agent that can carry on flexible, interactive, tutorial and collaborative dialogues with students. There has been much recent work in this area in the text planning community (e.g., <ref> (Cawsey 1992) </ref>, (Lambert & Carberry 1991), (Lochbaum, Grosz, & Sidner 1990), (Moore 1995), (Walker & Whittaker 1990)), and we expect to build on that work.
Reference: <author> Durlach, N. I., and Mavor, A. S., eds. </author> <year> 1995. </year> <title> Virtual Reality: Scientific and Technological Challenges. </title>
Reference-contexts: Virtual environments can potentially extend the range of situations that can be adequately simulated, because they are more suitable than previous technologies for providing realistic perceptual stimuli (e.g., visual, auditory, and haptic) <ref> (Durlach & Mavor 1995) </ref>. Virtual environment technology also enables intelligent tutoring systems to overcome key limitations of the computer coach paradigm. In the coaching paradigm, the computer watches as the student performs tasks, responding to questions and offering advice (Goldstein 1976).
Reference: <institution> Washington, </institution> <address> D.C.: </address> <publisher> National Academy Press. </publisher>
Reference: <author> Goldstein, I. P. </author> <year> 1976. </year> <title> The computer as coach: An athletic paradigm for intellectual education. </title> <note> Artificial Intelligence Laboratory Memo 389, </note> <institution> Massachusetts Institute of Technology, </institution> <address> Cambridge, MA. </address>
Reference-contexts: Virtual environment technology also enables intelligent tutoring systems to overcome key limitations of the computer coach paradigm. In the coaching paradigm, the computer watches as the student performs tasks, responding to questions and offering advice <ref> (Goldstein 1976) </ref>. In virtual environments, the coach can physically inhabit the virtual world along with the student.
Reference: <author> Hill, Jr., R. W., and Johnson, W. L. </author> <year> 1995. </year> <title> Situated plan attribution. </title> <journal> Journal of Artificial Intelligence in Education 6(1) </journal> <pages> 35-66. </pages>
Reference-contexts: TOTS also intervenes when the student makes a mistake (i.e., performs an inappropriate action). In this case, TOTS describes why the student's action is inappropriate and then demonstrates the appropriate action. In contrast, the REACT tutor built by Hill and Johnson <ref> (Hill & Johnson 1995) </ref> only intervenes when it believes the student is at an "impasse". Informally, an impasse is a point at which the student is failing to make progress or has made a mistake that will impede subsequent progress.
Reference: <author> Johnson, W. L. </author> <year> 1994. </year> <title> Agents that learn to explain themselves. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94), </booktitle> <pages> 1257-1263. </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Finally, after the task is complete, Steve can answer questions about the rationale behind actions he took during the task. Steve uses Johnson's Debrief system <ref> (Johnson 1994) </ref> to maintain an episodic memory of the actions he performs and the situations in which he performs them, so he answers such "after-action review" questions by recalling the situation and applying the same question answering ability illustrated in Figure 5.
Reference: <author> Laird, J. E.; Newell, A.; and Rosenbloom, P. S. </author> <year> 1987. </year> <title> Soar: An architecture for general intelligence. </title> <booktitle> Artificial Intelligence 33(1) </booktitle> <pages> 1-64. </pages>
Reference: <author> Lambert, L., and Carberry, S. </author> <year> 1991. </year> <title> A tripartite plan-based model of dialogue. </title> <booktitle> In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 47-54. </pages> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: Ultimately, we are working toward an agent that can carry on flexible, interactive, tutorial and collaborative dialogues with students. There has been much recent work in this area in the text planning community (e.g., (Cawsey 1992), <ref> (Lambert & Carberry 1991) </ref>, (Lochbaum, Grosz, & Sidner 1990), (Moore 1995), (Walker & Whittaker 1990)), and we expect to build on that work.
Reference: <author> Lochbaum, K. E.; Grosz, B. J.; and Sidner, C. L. </author> <year> 1990. </year> <title> Models of plans to support communication: An initial report. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence (AAAI-90), </booktitle> <pages> 485-490. </pages> <address> Los Altos, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Ultimately, we are working toward an agent that can carry on flexible, interactive, tutorial and collaborative dialogues with students. There has been much recent work in this area in the text planning community (e.g., (Cawsey 1992), (Lambert & Carberry 1991), <ref> (Lochbaum, Grosz, & Sidner 1990) </ref>, (Moore 1995), (Walker & Whittaker 1990)), and we expect to build on that work. However, our focus includes not only language but also the nonverbal types of communication facilitated by having a virtual environment where both students and agents are physically situated.
Reference: <author> McAllester, D., and Rosenblitt, D. </author> <year> 1991. </year> <title> Systematic nonlinear planning. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence (AAAI-91), </booktitle> <pages> 634-639. </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Second, there may be ordering constraints among the 2 3 steps; these constraints define a partial order over the steps. Finally, the role of the steps in the plan is represented by a set of causal links <ref> (McAllester & Rosenblitt 1991) </ref>; each causal link specifies that one step in the plan achieves a goal that is a precondition for another step in the plan (or for termination of the task).
Reference: <author> Moore, J. D. </author> <year> 1995. </year> <title> Participating in Explanatory Dialogues. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Ultimately, we are working toward an agent that can carry on flexible, interactive, tutorial and collaborative dialogues with students. There has been much recent work in this area in the text planning community (e.g., (Cawsey 1992), (Lambert & Carberry 1991), (Lochbaum, Grosz, & Sidner 1990), <ref> (Moore 1995) </ref>, (Walker & Whittaker 1990)), and we expect to build on that work. However, our focus includes not only language but also the nonverbal types of communication facilitated by having a virtual environment where both students and agents are physically situated.
Reference: <author> Munro, A.; Johnson, M.; Surmon, D.; and Wogulis, J. </author> <year> 1993. </year> <title> Attribute-centered simulation authoring for instruction. </title> <booktitle> In Proceedings of the World Conference on Artificial Intelligence in Education (AI-ED '93), </booktitle> <pages> 82-89. </pages> <booktitle> Association for the Advancement of Computing in Education. </booktitle>
Reference-contexts: The VET system is built around a distributed architecture, in which each component runs as a separate process, possibly on a separate workstation. The components communicate by sending messages to one another. There are several types of components. A simulator component <ref> (Munro et al. 1993) </ref> controls the behavior of the virtual world. The simulation is driven by events, such as the passage of time and the actions taken by humans and agents.
Reference: <author> Newell, A. </author> <year> 1990. </year> <title> Unified Theories of Cognition. </title> <address> Cam-bridge, MA: </address> <publisher> Harvard University Press. </publisher>
Reference: <author> Rickel, J., and Johnson, W. L. </author> <year> 1997. </year> <title> Integrating pedagogical capabilities in a virtual environment agent. </title> <booktitle> In Proceedings of the First International Conference on Autonomous Agents. </booktitle>
Reference-contexts: In order to focus on issues of mixed-initiative interaction between Steve and students, this paper provides only an abbreviated description of the technical details underlying Steve and the motivation behind design de cisions; for more information, see <ref> (Rickel & Johnson 1997) </ref>. 2 Steve's World Before discussing Steve's interaction with students, it is helpful to understand the world as Steve sees it. Steve is but one component in the overall VET system.
Reference: <author> Rickel, J. </author> <year> 1988. </year> <title> An intelligent tutoring framework for task-oriented domains. </title> <booktitle> In Proceedings of the International Conference on Intelligent Tutoring Systems. </booktitle>
Reference-contexts: Thus, while Steve is capable of shifting control, he is not capable of initiating shifts. However, previous tutoring systems built by the authors did include methods for automatically shifting control, and these methods could be incorporated into Steve. Like Steve, the TOTS tutor built by Rickel <ref> (Rickel 1988) </ref> coaches students through procedural tasks. Unlike Steve, TOTS maintains a record of which subtasks the student has been taught. As 4 Steve: I suggest you press the function test button. Student: Why? Steve: That action is relevant because we want the drain monitor in test mode.
Reference: <author> Russell, S., and Norvig, P. </author> <year> 1995. </year> <title> Artificial Intelligence: A Modern Approach. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall. </publisher>
Reference-contexts: In the case of monitoring, Steve must be able to advise the student, when asked, on the next appropriate action, and he must be able to rationalize his advice in terms of how that action helps complete the task. Steve uses a standard plan representation <ref> (Russell & Norvig 1995) </ref>. First, each plan consists of a set of steps, each of which is either a primitive action (e.g., push a button) or a complex action (i.e., itself a plan).
Reference: <author> Sacerdoti, E. </author> <year> 1977. </year> <title> A Structure for Plans and Behavior. </title> <address> New York: </address> <publisher> Elsevier North-Holland. 6 Stiles, </publisher> <editor> R.; McCarthy, L.; and Pontecorvo, M. </editor> <year> 1995. </year> <title> Training studio: A virtual environment for training. </title> <booktitle> In Workshop on Simulation and Interaction in Virtual Environments (SIVE-95). </booktitle> <address> Iowa City, IW: </address> <publisher> ACM Press. </publisher>
Reference-contexts: Given a task to demonstrate or monitor, Steve constructs a plan for performing the task, using top-down task decomposition <ref> (Sacerdoti 1977) </ref>. That is, he repeatedly expands any complex step in the evolving plan with the subplan (given to Steve as domain knowledge) for achieving it, until the plan has been fully decomposed. However, Steve cannot simply execute this plan by rote.
Reference: <author> Walker, M., and Whittaker, S. </author> <year> 1990. </year> <title> Mixed initiative in dialogue: An investigation into discourse segmentation. </title> <booktitle> In Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 70-78. </pages> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: Ultimately, we are working toward an agent that can carry on flexible, interactive, tutorial and collaborative dialogues with students. There has been much recent work in this area in the text planning community (e.g., (Cawsey 1992), (Lambert & Carberry 1991), (Lochbaum, Grosz, & Sidner 1990), (Moore 1995), <ref> (Walker & Whittaker 1990) </ref>), and we expect to build on that work. However, our focus includes not only language but also the nonverbal types of communication facilitated by having a virtual environment where both students and agents are physically situated.
Reference: <author> Weld, D. S. </author> <year> 1994. </year> <title> An introduction to least commitment planning. </title> <journal> AI Magazine 15(4) </journal> <pages> 27-61. 7 </pages>
Reference-contexts: Then, by continually comparing the goals of the plan (both end goals and intermediate ones) against the state of the changing world, Steve repeatedly identifies the subset of the plan that is still relevant to completing the task, using a method analogous to partial-order planning <ref> (Weld 1994) </ref>. As long as some subset of the plan suffices for completing the task, Steve can identify the next appropriate action.
References-found: 22

