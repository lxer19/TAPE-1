URL: http://www.media.mit.edu/~fliu/publications/delos.ps.gz
Refering-URL: http://www.media.mit.edu/~fliu/publications/publications.html
Root-URL: http://www.media.mit.edu
Email: fliu@media.mit.edu  
Title: Image and Video Modeling and Understanding  
Author: Fang Liu 
Address: Cambridge, MA 02139, USA  
Affiliation: The MIT Media Laboratory Massachusetts Institute of Technology  
Abstract: Seven digital library related projects conducted in the Vision and Modeling Group of the MIT Media Laboratory are reviewed. These projects address a large variety of issues that are essential to building sophisticated, efficient, and user friendly tools for image and video library applications. The problems on which these projects focus include feature extraction, feature combination, similarity comparison, image and video understanding, and learning from man-machine interaction. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. R. Bergen and E. H. Adelson. </author> <title> Visual texture segmentation based on energy measures. </title> <journal> J. Opt. Soc. of Amer. A, </journal> <volume> 3(13), </volume> <year> 1986. </year>
Reference: [2] <author> J. R. Bergen and E. H. Adelson. </author> <title> Early vision and texture perception. </title> <journal> Nature, </journal> <volume> 333 </volume> <pages> 363-364, </pages> <year> 1988. </year>
Reference: [3] <author> P. Brodatz. </author> <title> Textures: A Photographic Album for Artists and Designers. </title> <publisher> Dover, </publisher> <address> New York, </address> <year> 1966. </year>
Reference-contexts: The retrieval system was evaluated on the Brodatz Texture Database. This database contains 1008 eight-bit gray scale images cropped from the Brodatz album <ref> [3] </ref>. Each page of the album contributes nine images. 2.2.1 Harmonicity Test The harmonicity of a textured image (i.e., the amount of repetitive structure in the image) is determined by examining the energy distribution of the image autocovariance function.
Reference: [4] <author> M.A. Casey and J.S. Wachman. </author> <title> Unsupervised cross-modal analysis of professional monologue discourse. </title> <booktitle> In Proc. Workshop on the Integration of Gesture in Language and Speech, </booktitle> <year> 1996. </year>
Reference-contexts: This system interprets in real-time a forty-word subset of ASL with 99% accuracy. 7 Analysis of Discourse Video (Casey and Wachman) This project explores ways of combining features extracted from both audio and video data for video understanding <ref> [4] </ref>. Syllabic inter-onset intervals are used for temporal segmentation. Other features include the position and velocity of the hands (use Pfinder) and the value and change in pitch. Unsupervised analysis of video is conducted via clustering in the feature space.
Reference: [5] <author> F. Liu. </author> <title> Modeling Spatial and Temporal Textures. </title> <type> PhD thesis, </type> <institution> Media Arts and Sciences, MIT, </institution> <address> Cambridge, </address> <month> Sept. </month> <year> 1997. </year>
Reference-contexts: This technique is robust to noise and computationally efficient, providing a useful tool for video analysis and understanding. In the following subsections, the Wold-based texture modeling work is briefly described. Details can be found in <ref> [5] </ref> and [6]. 2.2 Textured Image Database Retrieval The textured image database retrieval system is based on Wold texture modeling. Given a texture pattern, its repetitive structure is represented by its spectral harmonic peaks, and its randomness modeled by a multi-resolution simultaneous autoregressive (MRSAR) fitting. <p> To further investigate the perceptual properties of Wold-based modeling, a psychophysical study was conducted <ref> [5] </ref>. Rao and Lohse identified the most important dimension of human texture perception as repetitiveness vs. randomness [13]. In the current study, humans and a computer program order a set of texture samples along this dimension. <p> Based on models of human early vision system [1][2], the total energy of the Wold components was used as the physical quantity to measure the perceptual strength of the components. For each test sample, the computer program first performs a spectral Wold decomposition <ref> [5] </ref> to obtain the orthogonal image components. Then the signal energy of the components are computed.
Reference: [6] <author> F. Liu and R. W. </author> <title> Picard. Periodicity, directionality, and randomness: Wold features for image modeling and retrieval. </title> <editor> IEEE T. Pat. Analy. </editor> <booktitle> and Machine Intel., </booktitle> <volume> 18(7) </volume> <pages> 722-733, </pages> <month> July </month> <year> 1996. </year>
Reference-contexts: This technique is robust to noise and computationally efficient, providing a useful tool for video analysis and understanding. In the following subsections, the Wold-based texture modeling work is briefly described. Details can be found in [5] and <ref> [6] </ref>. 2.2 Textured Image Database Retrieval The textured image database retrieval system is based on Wold texture modeling. Given a texture pattern, its repetitive structure is represented by its spectral harmonic peaks, and its randomness modeled by a multi-resolution simultaneous autoregressive (MRSAR) fitting. <p> The autocovariance energy ratio r e was computed for each image in the Brodatz database. The histogram of the ratios has a bi-modal structure. Gaussian assumptions were made to model the energy ratio data using an expectation and maximization (EM) procedure <ref> [6] </ref>. Denote the resulting classes as ! h (harmonic) and ! r (random). <p> The Wold method demonstrates superior qualitative and quantitative performance by offering both "intra-class" accuracy and perceptually more satisfying "inter-class" similarity. The benchmarking results of five texture models, where the Wold model placed the first, can be found in <ref> [6] </ref>. 3 (a1) (b1) (a3) (b3) are compared: SPCA ((a1),(b1)), MRSAR ((a2),(b2)), and Wold ((a3),(b3)). In each picture, the images are raster-scan ordered by their similarities to the image in upper left. 2.3 Natural Scene Representation A K-means-based MRSAR feature clustering algorithm was introduced in [6] to segment natural scene images <p> first, can be found in <ref> [6] </ref>. 3 (a1) (b1) (a3) (b3) are compared: SPCA ((a1),(b1)), MRSAR ((a2),(b2)), and Wold ((a3),(b3)). In each picture, the images are raster-scan ordered by their similarities to the image in upper left. 2.3 Natural Scene Representation A K-means-based MRSAR feature clustering algorithm was introduced in [6] to segment natural scene images for homogeneous regions. The Wold features of these regions can be used for subsequent content identification and similarity comparison. 2.4 Perceptual Properties of Wold-based models In the image retrieval experiment, the Wold texture model appears to offer perceptually more satisfying results.
Reference: [7] <author> F. Liu and R. W. </author> <title> Picard. Finding periodicity in space and time. </title> <booktitle> In Proc. Int. Conf. on Computer Vision, </booktitle> <address> Bombay, India, </address> <month> January </month> <year> 1998. </year> <note> To appear. </note>
Reference-contexts: Decoupling object tracking and periodicity detection conceptually modularizes the analysis process and allows the use of other tracking algorithms. In the following, the Walker sequence will be used to illustrate the key technical points. More detailed explanations of the algorithm can be found in <ref> [7] </ref>. 2.5.2 Frame Alignment In this work, a procedure is developed for the alignment of image sequences that involves little ego-motion and contains objects moving approximately frontoparallel to the camera along a straight line and at a constant speed. <p> One side of the belt is patterned and appears periodic. Every region with periodicity should be captured: the hub caps, the wheels, and one side of the belt. The algorithm accomplishes just that. More examples can be found in <ref> [7] </ref>.
Reference: [8] <author> J. Mao and A. K. Jain. </author> <title> Texture classification and segmentation using multiresolution simultaneous autoregressive models. </title> <booktitle> Patt. Rec., </booktitle> <volume> 25(2) </volume> <pages> 173-188, </pages> <year> 1992. </year>
Reference-contexts: An example is shown in Figure 2. The relatively unstructured texture components are characterized by using the MRSAR method introduced by Mao and Jain <ref> [8] </ref>. A second-order symmetric MRSAR model is fit to the image at three scales, resulting a 15-parameter feature vector and its covariance matrix. 2.2.3 Image Similarity Comparison Two orderings of the entire database are generated in this stage.
Reference: [9] <author> T. Minka. </author> <title> An image database browser that learns from user interaction. </title> <type> Master's thesis, </type> <institution> Dept. of EECS, MIT, </institution> <address> Cambridge, MA, </address> <year> 1996. </year>
Reference-contexts: This is usually a difficult task for a user. Using relevance feedback eliminates the task, and provides a more natural form of man-machine interaction. FourEyes <ref> [9] </ref> is an extensible and self-improving interactive learning system that assists users in digital library image and video segmentation, retrieval, and annotation. The system makes tentative groupings of the data using user relevance feedback and features provided by a variety of computational models.
Reference: [10] <author> B. Moghaddam and A. Pentland. </author> <title> Probabilistic visual learning for object representation. </title> <editor> In S.K. Nayar and T. Poggio, editors, </editor> <booktitle> Early Visual Learning, </booktitle> <pages> pages 99-130. </pages> <publisher> Oxford Univ. Press, </publisher> <year> 1996. </year>
Reference-contexts: The feature space consists of the eigenspace dimensions that correspond to the largest eigenvalues. For face and facial feature (eyes, nose, and mouth) detection, an unsupervised learning technique is developed <ref> [10] </ref>. This learning technique uses either a multivariate Gaussian or a mixture-of-Gaussian model to characterize the feature space. The location of a face in an image is found by using the maximum-likelihood ratio test over multi-scale.
Reference: [11] <author> P.J. Phillips et al.. </author> <title> The FERET September 1996 database and evaluation procedure. </title> <booktitle> In Proc. First Intl. Conf. on Audio and Video-based Biometric Person Authentication, </booktitle> <address> Crans-Montana, Switzerland, March 12-14, </address> <year> 1997. </year>
Reference-contexts: Then the facial region is extracted, normalized for contrast, and projected onto a set of eigenfaces to obtain a feature vector, which is subsequently used for similarity comparison to other faces. This face detection and recognition system placed first in the 1996 FERET (Face Recognition Technology) contest <ref> [11] </ref>, which uses over 3000 images taken of people at different times and with different facial expressions. 5 Pfinder (Wren, Azarbayejani, Darrell, and Pentland) Using a static camera, Pfinder (Person Finder) [16] is a real-time system that can find and track a person and the person's head, hands, and body while
Reference: [12] <author> R. W. Picard and T. Kabir. </author> <title> Finding similar patterns in large image databases. </title> <booktitle> In Proc. Int. Conf. on Acous., Speech, and Signal Proc., pages V-161-V-164, </booktitle> <address> Minneapolis, MN, </address> <year> 1993. </year>
Reference-contexts: image is computed as O joint = O h P (! h jr e ) + O r P (! r jr e ): The final similarity ordering of the database is formed by sorting images in the ascending order of their joint rank values. 2.2.5 Image Retrieval Examples (SPCA) <ref> [12] </ref>, the MRSAR, and the Wold-based methods over the Brodatz Database. In each picture, the upper left image is the prototype, and the retrieved images are shown by descending similarity to the prototype in raster-scan order.
Reference: [13] <author> A. R. Rao and G. L. Lohse. </author> <title> Towards a texture naming system: identifying relevant dimensions of texture. </title> <journal> Vision Research, </journal> <volume> 36(11) </volume> <pages> 1649-1669, </pages> <year> 1996. </year>
Reference-contexts: The perceptual properties of the components can be described respectively as "periodicity", "directionality", and "randomness", agreeing closely with that of the top dimensions of human texture perception <ref> [13] </ref>. Hence, perceptually salient features can be constructed based on the Wold theory. A textured image database retrieval system has been developed. The core of the system is a Wold-based shift, rotation, and scale invariant texture model. <p> To further investigate the perceptual properties of Wold-based modeling, a psychophysical study was conducted [5]. Rao and Lohse identified the most important dimension of human texture perception as repetitiveness vs. randomness <ref> [13] </ref>. In the current study, humans and a computer program order a set of texture samples along this dimension.
Reference: [14] <author> T. Starner and A. Pentland. </author> <title> Real-time American Sign Language recognition from video using hidden Markov models. Perceptual Computing Section Technical Report No. </title> <type> 375, </type> <institution> MIT Media Lab, </institution> <address> Cambridge, MA, </address> <year> 1996. </year>
Reference-contexts: This recognition system uses Pfinder for hand tracking and hidden Markov modeling (HMM) for recognition <ref> [14] </ref>. Using one color camera the hand tracking process produces a coarse description of hand shape, orientation, and trajectory. The hand tracking data are then sent to a four-state HMM for sentence-level ASL recognition.
Reference: [15] <author> M. Szummer and R.W. </author> <title> Picard. Indoor/outdoor image classification. Perceptual Computing Section, </title> <publisher> MIT Media Lab, </publisher> <month> April </month> <year> 1997. </year> <note> Unpublished article. </note>
Reference-contexts: This algorithm can also be considered as a periodicity filter, providing a model of low-level periodicity perception. 8 3 Scene Classification (Szummer and Picard) Classifying images into high-level semantic classes is a very difficult task for a computer. This work <ref> [15] </ref> shows how one particular scene classification problem classifying indoor and outdoor scenes of consumer photographs can be approached. Color histograms and multi-resolution autoregressive texture model coefficients are used as low-level image features. The images are also tessellated to incorporate coarse spatial position information.
Reference: [16] <author> C. Wren et al.. Pfinder: </author> <title> real-time tracking of the human body. </title> <editor> IEEE T. Pat. Analy. </editor> <booktitle> and Machine Intel., </booktitle> <volume> 19(7) </volume> <pages> 780-785, </pages> <month> July </month> <year> 1997. </year> <month> 10 </month>
Reference-contexts: This face detection and recognition system placed first in the 1996 FERET (Face Recognition Technology) contest [11], which uses over 3000 images taken of people at different times and with different facial expressions. 5 Pfinder (Wren, Azarbayejani, Darrell, and Pentland) Using a static camera, Pfinder (Person Finder) <ref> [16] </ref> is a real-time system that can find and track a person and the person's head, hands, and body while the person moves around a room. The system uses a maximum a posteriori probability based approach.
References-found: 16

