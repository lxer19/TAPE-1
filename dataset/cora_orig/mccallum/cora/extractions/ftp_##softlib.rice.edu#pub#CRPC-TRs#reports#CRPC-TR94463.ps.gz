URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR94463.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Title: CHOOSING THE FORCING TERMS IN AN INEXACT NEWTON METHOD  
Author: STANLEY C. EISENSTATy AND HOMER F. WALKERz 
Keyword: Key words. forcing terms, inexact Newton methods, Newton iterative methods, truncated New-ton methods, Newton's method, iterative linear algebra methods, GMRES  
Note: AMS(MOS) subject classifications. 65H10, 65F10  
Abstract: An inexact Newton method is a generalization of Newton's method for solving F (x) = 0, F : IR n ! IR n , in which, at the kth iteration, the step s k from the current approximate solution x k is required to satisfy a condition kF (x k ) + F 0 (x k ) s k k k kF (x k )k for a "forcing term" k 2 [0; 1). In typical applications, the choice of the forcing terms is critical to the efficiency of the method and can affect robustness as well. Promising choices of the forcing terms are given, their local convergence properties are analyzed, and their practical performance is shown on a representative set of test problems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Bjtrstad, </author> <title> Fast numerical solution of the biharmonic Dirichlet problem on rectangles, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 20 (1983), </volume> <pages> pp. 59-71. </pages>
Reference-contexts: However, this possibility was not as suc cessful in our experiments as the other choices proposed here, and we do not consider it further. Our second choice is the following: Choice 2: Given fl 2 <ref> [0; 1] </ref>, ff 2 (1; 2], and 0 2 [0; 1), choose k = fl kF (x k )k ff The choice (2.6) does not directly reflect the agreement between F and its local linear model, as does Choice 1. <p> All computing was done in double precision on Sun Microsystems workstations using the Sun Fortran compiler. 3.2. The test problems. The test set consisted of four PDE problems and two integral equation problems. The PDE problems are all elliptic boundary value problems posed on <ref> [0; 1] </ref> fi [0; 1] IR 2 . 3.2.1. A PDE problem. The problem is u + u 3 = 0 in ; u = 0 on @: This problem has multiple solutions, but only one that is positive everywhere (McKenna [10], Schaaf [13]). <p> All computing was done in double precision on Sun Microsystems workstations using the Sun Fortran compiler. 3.2. The test problems. The test set consisted of four PDE problems and two integral equation problems. The PDE problems are all elliptic boundary value problems posed on <ref> [0; 1] </ref> fi [0; 1] IR 2 . 3.2.1. A PDE problem. The problem is u + u 3 = 0 in ; u = 0 on @: This problem has multiple solutions, but only one that is positive everywhere (McKenna [10], Schaaf [13]). <p> The numerical problem becomes harder as the Reynolds number Re increases. Discretization was by piecewise-linear finite elements on a uniform 63 fi 63 grid 4 , so that n = 3969. The discretized problem was preconditioned on the right using a fast biharmonic solver of Bjtrstad <ref> [1] </ref>. Products of F 0 with vectors were approximated with finite differences. The initial approximate solution was zero. Two test cases were considered: Re = 100 and Re = 500. 3.2.4. The porous medium equation. <p> Two test cases were considered: d = 50 and d = 50. 3.2.5. An integral equation. The problem, from Kelley and Northrup [9], is cu (x) 2 2 0 1 sin 1 c = 0; x 2 <ref> [0; 1] </ref>: Clearly, u (x) 1 is always a solution, and there exist other solutions for at least some values of c. The discretized problem was determined by approximating integrals using 20-point Gaussian quadrature 5 over 20 subintervals of [0; 1], so that n = 400. No preconditioning was necessary. <p> 2 2 0 1 sin 1 c = 0; x 2 <ref> [0; 1] </ref>: Clearly, u (x) 1 is always a solution, and there exist other solutions for at least some values of c. The discretized problem was determined by approximating integrals using 20-point Gaussian quadrature 5 over 20 subintervals of [0; 1], so that n = 400. No preconditioning was necessary. Products of F 0 with vectors were approximated with finite differences. The initial approximate solution was a discretization of u 0 (x) 1 + cos 9x. One test case was considered: c = = 1:25. 3.2.6. The Chandrasekhar H-equation.
Reference: [2] <author> P. N. Brown and Y. Saad, </author> <title> Hybrid Krylov methods for nonlinear systems of equations, </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 11 (1990), </volume> <pages> pp. 450-481. </pages>
Reference-contexts: The choice k = 1=2 k+1 of Brown and Saad <ref> [2] </ref>. This choice results in local q-superlinear convergence and allows relatively inaccurate approximations of Newton steps for small k, when x k may not be near x fl ; however, it incorpo rates no information about F . 4. <p> This is a widely used test problem; see, e.g., Brown and Saad <ref> [2] </ref> or Glowinski, Keller, and Reinhart [8]. The numerical problem becomes harder as the Reynolds number Re increases. Discretization was by piecewise-linear finite elements on a uniform 63 fi 63 grid 4 , so that n = 3969.
Reference: [3] <author> X.-C. Cai, W. D. Gropp, D. E. Keyes, and M. D. Tidriri, </author> <title> Newton-Krylov-Schwarz methods in CFD, </title> <booktitle> in Proceedings of the International Workshop on the Navier-Stokes Equations, </booktitle> <editor> R. Rannacher, ed., </editor> <booktitle> Notes in Numerical Fluid Mechanics, Braunschwieg, 1994 (to appear), </booktitle> <publisher> Vieweg Verlag. </publisher>
Reference-contexts: The choice k = 10 1 , which requires modestly accurate approximations of Newton steps and results in local q-linear convergence in the norm k k fl . 2. The choice k = 10 4 used by Cai, Gropp, Keyes, and Tidriri <ref> [3] </ref>, which requires uniformly close approximations of Newton steps for all k and results 8 in fast local q-linear convergence in the norm k k fl . 3. The choice k = 1=2 k+1 of Brown and Saad [2].
Reference: [4] <author> R. S. Dembo, S. C. Eisenstat, and T. Steihaug, </author> <title> Inexact Newton methods, </title> <journal> SIAM J. Numer. 17 Anal., </journal> <volume> 19 (1982), </volume> <pages> pp. 400-408. </pages>
Reference-contexts: An inexact Newton method (Dembo, Eisenstat, and Steihaug <ref> [4] </ref>) is an extension of classical Newton's method for approximating x fl formulated as follows: Algorithm IN: Inexact Newton Method [4] Let x 0 be given. <p> An inexact Newton method (Dembo, Eisenstat, and Steihaug <ref> [4] </ref>) is an extension of classical Newton's method for approximating x fl formulated as follows: Algorithm IN: Inexact Newton Method [4] Let x 0 be given. <p> The local convergence of an inexact Newton method is controlled by the forcing terms. Some specific illustrative results are the following (see Dembo, Eisenstat, and Steihaug <ref> [4] </ref>): Under the present assumptions, if x 0 is sufficiently close to x fl and 0 k max &lt; 1 for each k, then fx k g converges to x fl q-linearly in the norm k k fl , defined by kvk fl kF 0 (x fl )vk for v 2
Reference: [5] <author> R. S. Dembo and T. Steihaug, </author> <title> Truncated Newton algorithms for large-scale optimization, </title> <journal> Math. Prog., </journal> <volume> 26 (1983), </volume> <pages> pp. 190-212. </pages>
Reference-contexts: The choice k = minf1=(k + 2); kF (x k )kg of Dembo and Steihaug <ref> [5] </ref>. This choice results in q-quadratic local convergence and also may allow relatively inaccurate approximations of Newton steps for small k. <p> As in x3.2.5, no preconditioning was necessary. Products of F 0 with vectors were approximated with finite differences. The initial approximate solution was zero. Three test cases were considered: c = :5, c = :999, and c = 1. 3.3. An example of oversolving. Algorithm INB with the Dembo-Steihaug <ref> [5] </ref> choice k = minf1=(k + 2); kF (x k )k 2 g was applied to the driven cavity problem with Re = 500.
Reference: [6] <author> J. E. Dennis, Jr. and R. B. Schnabel, </author> <title> Numerical Methods for Unconstrained Optimization and Nonlinear Equations, Series in Automatic Computation, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1983. </year>
Reference-contexts: x 2 N ffi fl (x fl ) and if s is such that x + x + s 2 N ffi fl (x fl ), then kF (x + ) F (x) F 0 (x) sk 2kx x fl k + 2 ksk: 2 See, e.g., Dennis and Schnabel <ref> [6, xx2.3 and 3.1] </ref> for definitions of the types of convergence referred to throughout this paper. 2 Proof.
Reference: [7] <author> S. C. Eisenstat and H. F. Walker, </author> <title> Globally convergent inexact Newton methods, </title> <journal> SIAM J. Optimization, </journal> <volume> 4 (1994), </volume> <pages> pp. 393-422. </pages>
Reference-contexts: The algorithm. A globalized inexact Newton algorithm was necessary because initial approximate solutions were not always near a solution. We used Algorithm INB of Eisenstat and Walker <ref> [7, x6] </ref>. This is an inexact Newton method globalized by backtracking, which we write here as follows: Algorithm INB: Inexact Newton Backtracking Method [7] Let x 0 , max 2 [0; 1), t 2 (0; 1), and 0 &lt; min &lt; max &lt; 1 be given. <p> A globalized inexact Newton algorithm was necessary because initial approximate solutions were not always near a solution. We used Algorithm INB of Eisenstat and Walker [7, x6]. This is an inexact Newton method globalized by backtracking, which we write here as follows: Algorithm INB: Inexact Newton Backtracking Method <ref> [7] </ref> Let x 0 , max 2 [0; 1), t 2 (0; 1), and 0 &lt; min &lt; max &lt; 1 be given. <p> Set x k+1 = x k + s k . Note that Algorithm INB requires k 2 [0; max ] for each initial k . For the safeguarded choices in x2, this necessitates the additional safeguard k minf k ; max g. Theorem 6.1 of Eisenstat and Walker <ref> [7] </ref> states that if fx k g generated by Algorithm INB has a limit point x fl such that F 0 (x fl ) is invertible, then F (x fl ) = 0 and x k ! x fl .
Reference: [8] <author> R. Glowinski, H. B. Keller, and L. Reinhart, </author> <title> Continuation-conjugate gradient methods for the least squares solution of nonlinear boundary value problems, </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 6 (1985), </volume> <pages> pp. 793-832. </pages>
Reference-contexts: For the latter value, the initial approximate solution is farther from the solution and the problem is harder. 3.2.2. The (modified) Bratu problem. The problem is u + @x 1 The actual Bratu (or Gelfand) problem has = 0; see, e.g., Glowinski, Keller, and Reinhart <ref> [8] </ref> or the description by Glowinski and Keller in the collection of nonlinear model problems assembled by More [11, pp. 733-737]. As and grow, solving the Newton equations for the discretized problem becomes harder for GMRES (20). Discretization and preconditioning were as in x3.2.1. <p> This is a widely used test problem; see, e.g., Brown and Saad [2] or Glowinski, Keller, and Reinhart <ref> [8] </ref>. The numerical problem becomes harder as the Reynolds number Re increases. Discretization was by piecewise-linear finite elements on a uniform 63 fi 63 grid 4 , so that n = 3969. The discretized problem was preconditioned on the right using a fast biharmonic solver of Bjtrstad [1].
Reference: [9] <author> C. T. Kelley and J. I. Northrup, </author> <title> A pointwise quasi-Newton method for integral equations, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 25 (1988), </volume> <pages> pp. 1138-1155. </pages>
Reference-contexts: Two test cases were considered: d = 50 and d = 50. 3.2.5. An integral equation. The problem, from Kelley and Northrup <ref> [9] </ref>, is cu (x) 2 2 0 1 sin 1 c = 0; x 2 [0; 1]: Clearly, u (x) 1 is always a solution, and there exist other solutions for at least some values of c.
Reference: [10] <author> P. J. McKenna, </author> <year> 1992. </year> <title> Private communication. </title>
Reference-contexts: A PDE problem. The problem is u + u 3 = 0 in ; u = 0 on @: This problem has multiple solutions, but only one that is positive everywhere (McKenna <ref> [10] </ref>, Schaaf [13]). These properties appear to be shared by the discretized problem, and finding the everywhere-positive solution can be difficult without a good initial approximate solution. Discretization was by the usual centered differences on a 100fi100 uniform grid, so that n = 10 4 .
Reference: [11] <author> J. J. Mor e, </author> <title> A collection of nonlinear model problems, in Computational Solution of Nonlinear Systems of Equations, </title> <editor> E. L. Allgower and K. Georg, eds., </editor> <booktitle> Lectures in Applied Mathematics Vol. </booktitle> <volume> 26, </volume> <publisher> American Mathematical Society, </publisher> <year> 1990, </year> <pages> pp. 723-762. </pages>
Reference-contexts: The (modified) Bratu problem. The problem is u + @x 1 The actual Bratu (or Gelfand) problem has = 0; see, e.g., Glowinski, Keller, and Reinhart [8] or the description by Glowinski and Keller in the collection of nonlinear model problems assembled by More <ref> [11, pp. 733-737] </ref>. As and grow, solving the Newton equations for the discretized problem becomes harder for GMRES (20). Discretization and preconditioning were as in x3.2.1. Products of F 0 with vectors were evaluated analytically. The initial approximate solution was zero. <p> One test case was considered: c = = 1:25. 3.2.6. The Chandrasekhar H-equation. The problem is u (x) 1 Lu (x) where Lu (x) 2 0 x + ~ This problem arises in radiative transfer problems; see, e.g., the description by Kelley in the More problem collection <ref> [11, pp. 737-739] </ref>. The continuous problem is singular at c = 1, and so is the discretized problem considered here with discretization as in 4 We thank P. N. Brown for providing the code for this. 5 We thank C. T. Kelley for providing the code for this. 11 x3.2.5.
Reference: [12] <author> Y. Saad and M. H. Schultz, </author> <title> GMRES: a generalized minimal residual method for solving nonsymmetric linear systems, </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 7 (1986), </volume> <pages> pp. 856-869. </pages>
Reference-contexts: In implementing Algorithm INB, we first chose each initial k (with 0 = 1=2 for Choices 1 and 2) and then determined an initial s k by approximately solving the Newton equation using GMRES (m), the restarted GMRES method of Saad and Schultz <ref> [12] </ref>, with restart value m = 20. Products of F 0 (x k ) with vectors were evaluated analytically in some cases and approximated by finite differences of F -values in others; see x3.2.
Reference: [13] <author> R. Schaaf, </author> <year> 1994. </year> <title> Private communication. </title>
Reference-contexts: A PDE problem. The problem is u + u 3 = 0 in ; u = 0 on @: This problem has multiple solutions, but only one that is positive everywhere (McKenna [10], Schaaf <ref> [13] </ref>). These properties appear to be shared by the discretized problem, and finding the everywhere-positive solution can be difficult without a good initial approximate solution. Discretization was by the usual centered differences on a 100fi100 uniform grid, so that n = 10 4 .
Reference: [14] <author> J. Stoer and R. </author> <title> Bulirsch, Introduction to Numerical Analysis, </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1980. </year>
Reference-contexts: Remark: It follows immediately from (2.3) that the convergence is q-superlinear and two-step q-quadratic. As in the case of the classical secant method, it also follows that the convergence is of r-order (1 + p 5)=2; see, e.g., Stoer and Bulirsch <ref> [14, p. 293] </ref> for the argument. Proof. It suffices to prove the theorem with f k g given by (2.1). Suppose that 0 2 [0; 1) is given.
Reference: [15] <author> P. N. Swartztrauber and R. A. Sweet, </author> <title> Algorithm 541: Efficient Fortran subprograms for the solution of separable elliptic partial differential equations, </title> <journal> ACM Trans. Math. Software, </journal> <volume> 5 (1979), </volume> <pages> pp. 352-364. </pages>
Reference-contexts: Discretization was by the usual centered differences on a 100fi100 uniform grid, so that n = 10 4 . The discretized problem was preconditioned on the right using a fast Poisson solver from Fishpack (Swartztrauber and Sweet <ref> [15] </ref>). Products of F 0 with vectors were evaluated analytically. The initial approximate solution was a discretization of u 0 (x) x 1 (1 x 1 )x 2 (1 x 2 ), which should lead to the everywhere-positive solution for large .
Reference: [16] <author> K. Turner and H. F. Walker, </author> <title> Efficient high accuracy solutions with GMRES(m), </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 13 (1992), </volume> <pages> pp. 815-825. </pages>
Reference-contexts: This selective second-order differencing gave essentially the same accuracy as if central differences had been used throughout, but at much lower cost (see Turner and Walker <ref> [16] </ref>). The parameters used were max = :9, t = 10 4 , min = 1=10, and max = 1=2. The norm was the Euclidean norm k k 2 .
Reference: [17] <author> C. J. van Duijn and J. M. de Graaf, </author> <title> Large time behaviour of solutions of the porous medium equation with convection, J. Differential Equations, </title> <booktitle> 84 (1990), </booktitle> <pages> pp. 183-203. 18 </pages>
Reference-contexts: This is more or less a steady-state special case of a general problem considered by van Duijn and de Graaf <ref> [17] </ref>. Discretization was by the usual centered differences on a 64fi64 uniform grid, so that n = 4096. The discretized problem was preconditioned on the right using the tridiagonal part of the Jacobian. Products of F 0 with vectors were evaluated analytically.
References-found: 17

