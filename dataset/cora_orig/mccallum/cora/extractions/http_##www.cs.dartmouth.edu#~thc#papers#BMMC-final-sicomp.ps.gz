URL: http://www.cs.dartmouth.edu/~thc/papers/BMMC-final-sicomp.ps.gz
Refering-URL: http://www.cs.dartmouth.edu/~thc/papers.html
Root-URL: http://www.cs.dartmouth.edu
Title: Asymptotically Tight Bounds for Performing BMMC Permutations on Parallel Disk Systems factoring uses new subclasses
Author: Thomas H. Cormen Thomas Sundquist Leonard F. Wisniewski 
Address: College.  
Affiliation: Dartmouth College Department of Computer Science.  Dartmouth College  Dartmouth College Department of Mathematics.  Dartmouth  
Note: The  Portions of this research were performed while at the MIT Laboratory for Computer Science and appear in [9]; supported in part by the Defense Advanced Research Projects Agency under Grant N00014-91-J-1698 during that time. Other portions of this research were performed while at  and were supported in part by funds from Dartmouth College and in part by the National Science Foundation under Grant CCR-9308667.  Supported in part by funds from  
Abstract: This paper presents asymptotically equal lower and upper bounds for the number of parallel I/O operations required to perform bit-matrix-multiply/complement (BMMC) permutations on the Parallel Disk Model proposed by Vitter and Shriver. A BMMC permutation maps a source index to a target index by an affine transformation over GF (2), where the source and target indices are treated as bit vectors. The class of BMMC permutations includes many common permutations, such as matrix transposition (when dimensions are powers of 2), bit-reversal permutations, vector-reversal permutations, hypercube permutations, matrix reblocking, Gray-code permutations, and inverse Gray-code permutations. The upper bound improves upon the asymptotic bound in the previous best known BMMC algorithm and upon the constant factor in the previous best known bit-permute/complement (BPC) permutation algorithm. The algorithm achieving the upper bound uses basic linear-algebra techniques to factor the characteristic matrix for the BMMC permutation into a product of factors, each of which characterizes a permutation that can be performed in one pass over the data. Although many BMMC permutations of practical interest fall into subclasses that might be explicitly invoked within the source code, this paper shows how to detect quickly whether a given vector of target addresses specifies a BMMC permutation. Thus, one can determine efficiently at run time whether a permutation to be performed is BMMC and then avoid the general-permutation algorithm and save parallel I/Os by using the BMMC-permutation algorithm herein. z Thinking Machines Corporation. Research performed while at the Dartmouth College Department of Computer Science. Supported in part by INFOSEC Grant 3-56666, in part by the National Science Foundation under Grant CCR-9308667, and in part by a Dartmouth Graduate Fellowship. An extended abstract of this paper appeared in the Proceedings of the 5th Annual ACM Symposium on Parallel Algorithms and Architectures. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aggarwal, A. K. Chandra, and M. Snir, </author> <title> Hierarchical memory with block transfer, </title> <booktitle> in Proceedings of the 28th Annual Symposium on Foundations of Computer Science, </booktitle> <month> Oct. </month> <year> 1987, </year> <pages> pp. 204-216. </pages>
Reference-contexts: The cross-rank of A is the maximum of the band m-cross-ranks: (A) = max ( b (A); m (A)) : (3) The BPC algorithm in [10] uses at most 2N ~ lg (M=B) + 1 3 Johnsson and Ho [19] call BPC permutations dimension permutations, and Aggarwal, Chandra, and Snir <ref> [1] </ref> call BPC permutations without complementing rational permutations. BMMC Permutations on Parallel Disk Systems 7 parallel I/Os. One can adapt the lower bound we prove in Section 3 for BMMC permutations to show that this BPC algorithm is asymptotically optimal.
Reference: [2] <author> A. Aggarwal and J. S. Vitter, </author> <title> The input/output complexity of sorting and related problems, </title> <journal> Comm. ACM, </journal> <volume> 31 (1988), </volume> <pages> pp. 1116-1127. </pages>
Reference-contexts: These bounds are asymptotically tight, because they match the lower bounds proven earlier by Aggarwal and Vitter <ref> [2] </ref> using a model with one disk and D independent read/write heads, which is at least as powerful as the Parallel Disk Model. Specific classes of permutations sometimes require fewer parallel I/Os than general permutations. <p> Section 6 presents an algorithm that achieves the bound given by Theorem 6, and so this algorithm is asymptotically optimal. Technique To prove Theorem 6, we rely heavily on the technique used by Aggarwal and Vitter <ref> [2] </ref> to prove a lower bound on I/Os for matrix transposition; their proof is based in turn on a method by Floyd [16]. We prove the lower bound for the case in which D = 1; the general case follows by dividing by D. <p> A later implementation that runs on either the DEC 2100 server or a network of workstations [11] uses asynchronous striped reads and asynchronous independent writes; it is a key subroutine in an efficient out-of-core Fast Fourier Transform implementation [12]. One can adapt the proof by Aggarwal and Vitter <ref> [2] </ref> of Lemma 9 to bound max precisely, rather than just asymptotically. In particular, it is a straightforward exercise to derive the bound max B 2 + lg (M=B) : Moreover, the potential change is at most zero for write operations, and so the potential increases only during read operations.
Reference: [3] <author> L. Arge, </author> <title> The buffer tree: A new technique for optimal I/O-algorithms, </title> <booktitle> in 4th International Workshop on Algorithms and Data Structures (WADS), </booktitle> <month> Aug. </month> <year> 1995, </year> <pages> pp. </pages> <month> 334-345. </month> <title> [4] , The I/O-complexity of ordered binary-decision diagram manipulation, </title> <booktitle> in Proceedings of the 6th International Symposium on Algorithms and Computations (ISAAC '95), </booktitle> <editor> J. Staples, P. Eades, N. Katoh, and A. Moffat, eds., </editor> <volume> vol. </volume> <booktitle> 1004 of Lecture Notes in Computer Science, </booktitle> <publisher> Springer-Verlag, </publisher> <month> Dec. </month> <year> 1995, </year> <pages> pp. 82-91. </pages>
Reference-contexts: Optimal algorithms have appeared in the literature for fundamental problems such as sorting <ref> [3, 6, 21, 22, 24] </ref>, general permutations [24], and structured permutations [9, 10, 26], as well as higher-level domains such as Fast Fourier transform [24], matrix-matrix multiplication [24], LUP decomposition [27], computational geometry problems [5, 18], graph algorithms [8], and boolean function manipulation [4]. <p> The first term comes into play when the block size B is small, and the second term is the sorting bound fi BD lg (M=B) , which was shown by Vitter and Shriver for randomized sorting and subsequently by Nodine and Vitter [22] and others <ref> [3, 6, 21] </ref> for deterministic sorting. These bounds are asymptotically tight, because they match the lower bounds proven earlier by Aggarwal and Vitter [2] using a model with one disk and D independent read/write heads, which is at least as powerful as the Parallel Disk Model.
Reference: [5] <author> L. Arge, D. E. Vengroff, and J. S. Vitter, </author> <title> External-memory algorithms for processing line segments in geographic information systems, </title> <booktitle> in Proceedings of the Third Annual European Symposium on Algorithms (ESA '95), </booktitle> <editor> P. Spirakis, ed., </editor> <volume> vol. </volume> <booktitle> 979 of Lecture Notes in Computer Science, </booktitle> <publisher> Springer-Verlag, </publisher> <month> Sept. </month> <year> 1995, </year> <pages> pp. 295-310. </pages> <note> BMMC Permutations on Parallel Disk Systems 34 </note>
Reference-contexts: Optimal algorithms have appeared in the literature for fundamental problems such as sorting [3, 6, 21, 22, 24], general permutations [24], and structured permutations [9, 10, 26], as well as higher-level domains such as Fast Fourier transform [24], matrix-matrix multiplication [24], LUP decomposition [27], computational geometry problems <ref> [5, 18] </ref>, graph algorithms [8], and boolean function manipulation [4].
Reference: [6] <author> R. D. Barve, E. F. Grove, and J. S. Vitter, </author> <title> Simple randomized mergesort for parallel disks, </title> <booktitle> in Proceedings of the 8th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <month> June </month> <year> 1996, </year> <pages> pp. 109-118. </pages>
Reference-contexts: Optimal algorithms have appeared in the literature for fundamental problems such as sorting <ref> [3, 6, 21, 22, 24] </ref>, general permutations [24], and structured permutations [9, 10, 26], as well as higher-level domains such as Fast Fourier transform [24], matrix-matrix multiplication [24], LUP decomposition [27], computational geometry problems [5, 18], graph algorithms [8], and boolean function manipulation [4]. <p> The first term comes into play when the block size B is small, and the second term is the sorting bound fi BD lg (M=B) , which was shown by Vitter and Shriver for randomized sorting and subsequently by Nodine and Vitter [22] and others <ref> [3, 6, 21] </ref> for deterministic sorting. These bounds are asymptotically tight, because they match the lower bounds proven earlier by Aggarwal and Vitter [2] using a model with one disk and D independent read/write heads, which is at least as powerful as the Parallel Disk Model.
Reference: [7] <author> P. Chen, G. Gibson, R. H. Katz, D. A. Patterson, and M. Schulze, </author> <title> Two papers on RAIDs, </title> <type> Tech. Rep. </type> <institution> UCB/CSD 88/479, Computer Science Division (EECS), University of California, Berkeley, </institution> <month> Dec. </month> <year> 1988. </year>
Reference-contexts: BMMC Permutations on Parallel Disk Systems 20 Striped writes may be valuable when redundant data is maintained on a parallel disk system to reduce the chance of data loss due to a failed device. Many common parallel-disk organizations fall under the heading of RAID (Redundant Array of Inexpensive Disks) <ref> [7, 17] </ref>, which is organized into "levels" of redundancy. In RAID levels 3 and 4, an additional disk is added to the disk array to store redundancy. Each block of this parity disk contains the bitwise exclusive-or of the contents of the corresponding blocks of the other D data disks.
Reference: [8] <author> Y.-J. Chiang, M. T. Goodrich, E. F. Grove, R. Tamassia, D. E. Vengroff, and J. S. Vitter, </author> <title> External-memory graph algorithms, </title> <booktitle> in Proceedings of the Sixth Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <month> Jan. </month> <year> 1995, </year> <pages> pp. 139-149. </pages>
Reference-contexts: algorithms have appeared in the literature for fundamental problems such as sorting [3, 6, 21, 22, 24], general permutations [24], and structured permutations [9, 10, 26], as well as higher-level domains such as Fast Fourier transform [24], matrix-matrix multiplication [24], LUP decomposition [27], computational geometry problems [5, 18], graph algorithms <ref> [8] </ref>, and boolean function manipulation [4].
Reference: [9] <author> T. H. Cormen, </author> <title> Virtual Memory for Data-Parallel Computing, </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <year> 1992. </year> <title> Available as Technical Report MIT/LCS/TR-559. [10] , Fast permuting in disk arrays, </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 17 (1993), </volume> <pages> pp. 41-57. </pages>
Reference-contexts: Optimal algorithms have appeared in the literature for fundamental problems such as sorting [3, 6, 21, 22, 24], general permutations [24], and structured permutations <ref> [9, 10, 26] </ref>, as well as higher-level domains such as Fast Fourier transform [24], matrix-matrix multiplication [24], LUP decomposition [27], computational geometry problems [5, 18], graph algorithms [8], and boolean function manipulation [4]. <p> &gt; &gt; : ~ lg (M=B) + 9 if M N ; ~ lg (M=B) + 1 if N &lt; M &lt; NB ; p (1) One can adapt the lower bound proven in this paper to show that BD lg (M=B) parallel I/Os are necessary (see Section 2.8 of <ref> [9] </ref>), but so far it has been unknown whether the fi N term is necessary in all cases. This paper shows that it is not. <p> It is particularly satisfying that the tight bound was achieved not by raising the lower bound proven here and in <ref> [9] </ref>, but by decreasing the upper bound in [10]. (After all, we would rather perform BMMC permutations with fewer parallel I/Os.) The multiplicative and additive constants in the I/O complexity of our algorithm are small, which is especially fortunate in light of the expense of disk accesses. <p> On what other memory models can we use this technique to efficiently perform BMMC permutations? What other permutations can be performed quickly? Several O (1)-pass permutation classes appear in <ref> [9] </ref>, and this paper has added two more (MLD and MLD 1 permutations in Section 4). We have shown that the inverse of any one-pass permutation is a one-pass permutation. One can also show that the composition of an MLD permutation with an MLD 1 permutation is a one-pass permutation.
Reference: [11] <author> T. H. Cormen and M. Hirschl, </author> <title> Early experiences in evaluating the Parallel Disk Model with the ViC* implementation, </title> <type> Tech. Rep. </type> <institution> PCS-TR96-293, Dartmouth College Department of Computer Science, </institution> <month> Aug. </month> <year> 1996. </year> <note> To appear in Parallel Computing. </note>
Reference-contexts: A later implementation that runs on either the DEC 2100 server or a network of workstations <ref> [11] </ref> uses asynchronous striped reads and asynchronous independent writes; it is a key subroutine in an efficient out-of-core Fast Fourier Transform implementation [12]. One can adapt the proof by Aggarwal and Vitter [2] of Lemma 9 to bound max precisely, rather than just asymptotically.
Reference: [12] <author> T. H. Cormen and D. M. Nicol, </author> <title> Performing out-of-core FFTs on parallel disk systems, </title> <type> Tech. Rep. </type> <institution> PCS-TR96-294, Dartmouth College Department of Computer Science, </institution> <month> Aug. </month> <year> 1996. </year>
Reference-contexts: A later implementation that runs on either the DEC 2100 server or a network of workstations [11] uses asynchronous striped reads and asynchronous independent writes; it is a key subroutine in an efficient out-of-core Fast Fourier Transform implementation <ref> [12] </ref>. One can adapt the proof by Aggarwal and Vitter [2] of Lemma 9 to bound max precisely, rather than just asymptotically.
Reference: [13] <author> S. R. Cushman, </author> <title> A multiple discrete pass algorithm on a DEC Alpha 2100, </title> <type> Tech. Rep. </type> <institution> PCS-TR95-259, Dartmouth College Department of Computer Science, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: Our algorithm has been implemented on a DEC 2100 server with 8 disk drives <ref> [13] </ref>. This implementation uses asynchronous independent reads and asynchronous striped writes, so that when performing each MRC or MLD 1 permutation, it overlaps prefetching the next memoryload, writing the previous memoryload, and permuting in memory the current memoryload.
Reference: [14] <author> J. M. del Rosario and A. Choudhary, </author> <title> High-performance I/O for massively parallel computers, </title> <booktitle> IEEE Computer, </booktitle> <year> (1994), </year> <pages> pp. 59-67. </pages>
Reference-contexts: For a list of Grand Challenge applications with huge I/O requirements, see the list compiled by del Rosario and Choudhary <ref> [14] </ref>.) One solution is to store large matrices and vectors on parallel disk systems. The high latency of disk accesses makes it essential to minimize the number of disk I/O operations.
Reference: [15] <author> A. Edelman, S. Heller, and S. L. Johnsson, </author> <title> Index transformation algorithms in a linear algebra framework, </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 5 (1994), </volume> <pages> pp. 1302-1309. </pages>
Reference-contexts: Corollary 2 Let the n fi n characteristic matrix A be factored as A = A (k) A (k1) A (k2) A (1) , where each factor A (i) is a nonsingular nfi n matrix. Then we can perform the BMMC permutation 1 Edelman, Heller, and Johnsson <ref> [15] </ref> call BMMC permutations affine transformations or, if there is no complementing, linear transformations. 2 Matrix multiplication over GF (2) is like standard matrix multiplication over the reals but with all arithmetic performed modulo 2. Equivalently, multiplication is replaced by logical-and, and addition is replaced by exclusive-or.
Reference: [16] <author> R. W. Floyd, </author> <title> Permuting information in idealized two-level storage, in Complexity of Computer Computations, </title> <editor> R. E. Miller and J. W. Thatcher, eds., </editor> <publisher> Plenum Press, </publisher> <year> 1972, </year> <pages> pp. 105-109. </pages>
Reference-contexts: Technique To prove Theorem 6, we rely heavily on the technique used by Aggarwal and Vitter [2] to prove a lower bound on I/Os for matrix transposition; their proof is based in turn on a method by Floyd <ref> [16] </ref>. We prove the lower bound for the case in which D = 1; the general case follows by dividing by D. We consider only I/Os that are simple. An input is simple if each record read is removed from the disk and moved into an empty location in memory.
Reference: [17] <author> G. A. Gibson, </author> <title> Redundant Disk Arrays: Reliable, Parallel Secondary Storage, </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1992. </year> <note> Also available as Technical Report UCB/CSD 91/613, </note> <institution> Computer Science Division (EECS), University of California, Berkeley, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: BMMC Permutations on Parallel Disk Systems 20 Striped writes may be valuable when redundant data is maintained on a parallel disk system to reduce the chance of data loss due to a failed device. Many common parallel-disk organizations fall under the heading of RAID (Redundant Array of Inexpensive Disks) <ref> [7, 17] </ref>, which is organized into "levels" of redundancy. In RAID levels 3 and 4, an additional disk is added to the disk array to store redundancy. Each block of this parity disk contains the bitwise exclusive-or of the contents of the corresponding blocks of the other D data disks.
Reference: [18] <author> M. T. Goodrich, J.-J. Tsay, D. E. Vengroff, and J. S. Vitter, </author> <title> External-memory computational geometry, </title> <booktitle> in Proceedings of the 34th Annual Symposium on Foundations of Computer Science, </booktitle> <month> Nov. </month> <year> 1993, </year> <pages> pp. 714-723. </pages>
Reference-contexts: Optimal algorithms have appeared in the literature for fundamental problems such as sorting [3, 6, 21, 22, 24], general permutations [24], and structured permutations [9, 10, 26], as well as higher-level domains such as Fast Fourier transform [24], matrix-matrix multiplication [24], LUP decomposition [27], computational geometry problems <ref> [5, 18] </ref>, graph algorithms [8], and boolean function manipulation [4].
Reference: [19] <author> S. L. Johnsson and C.-T. Ho, </author> <title> Generalized shu*e permutations on boolean cubes, </title> <type> Tech. Rep. </type> <institution> TR-04-91, Harvard University Center for Research in Computing Technology, </institution> <month> Feb. </month> <year> 1991. </year> <title> BMMC Permutations on Parallel Disk Systems 35 </title>
Reference-contexts: The cross-rank of A is the maximum of the band m-cross-ranks: (A) = max ( b (A); m (A)) : (3) The BPC algorithm in [10] uses at most 2N ~ lg (M=B) + 1 3 Johnsson and Ho <ref> [19] </ref> call BPC permutations dimension permutations, and Aggarwal, Chandra, and Snir [1] call BPC permutations without complementing rational permutations. BMMC Permutations on Parallel Disk Systems 7 parallel I/Os.
Reference: [20] <author> S. Lang, </author> <title> Linear Algebra, </title> <publisher> Springer-Verlag, 3rd ed., </publisher> <year> 1987. </year>
Reference-contexts: Thus we have ker K ker L iff (row K) ? (row L) ? which proves the lemma. 4 The proof that this property holds over GF (2) is not as straightforward as the conventional proof that it holds over R n . Lang <ref> [20, p. 131] </ref> contains a proof for GF (2). BMMC Permutations on Parallel Disk Systems 11 Finding a maximal set of linearly independent columns We conclude this section with a simple sequential algorithm to find a maximal set S of linearly independent columns of a p fi q matrix K.
Reference: [21] <author> M. H. Nodine and J. S. Vitter, </author> <title> Deterministic distribution sort in shared and distributed memory multiprocessors, </title> <booktitle> in Proceedings of the 5th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <month> June </month> <year> 1993, </year> <pages> pp. </pages> <month> 120-129. </month> <title> [22] , Greed sort: Optimal deterministic sorting on parallel disks, </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 42 (1995), </volume> <pages> pp. 919-933. </pages>
Reference-contexts: Optimal algorithms have appeared in the literature for fundamental problems such as sorting <ref> [3, 6, 21, 22, 24] </ref>, general permutations [24], and structured permutations [9, 10, 26], as well as higher-level domains such as Fast Fourier transform [24], matrix-matrix multiplication [24], LUP decomposition [27], computational geometry problems [5, 18], graph algorithms [8], and boolean function manipulation [4]. <p> The first term comes into play when the block size B is small, and the second term is the sorting bound fi BD lg (M=B) , which was shown by Vitter and Shriver for randomized sorting and subsequently by Nodine and Vitter [22] and others <ref> [3, 6, 21] </ref> for deterministic sorting. These bounds are asymptotically tight, because they match the lower bounds proven earlier by Aggarwal and Vitter [2] using a model with one disk and D independent read/write heads, which is at least as powerful as the Parallel Disk Model.
Reference: [23] <author> G. Strang, </author> <title> Linear Algebra and Its Applications, </title> <publisher> Harcourt Brace Jovanovich, </publisher> <address> San Diego, third ed., </address> <year> 1988. </year>
Reference-contexts: We use the following well-known facts from linear algebra (see Strang <ref> [23, pp. 138-139] </ref> for example): 1. The row space and the kernel are orthogonal spaces of each other. Thus, (row K) ? = ker K and (row L) ? = ker L. 2. For any vector spaces X and Y , X Y implies Y ? X ? . 3.
Reference: [24] <author> J. S. Vitter and E. A. M. Shriver, </author> <title> Algorithms for parallel memory I: Two-level memories, </title> <journal> Algorithmica, </journal> <volume> 12 (1994), </volume> <pages> pp. 110-147. </pages>
Reference-contexts: Moreover, the low constant factor in our algorithm makes it very practical. Model and previous results We use the Parallel Disk Model first proposed by Vitter and Shriver <ref> [24] </ref>, who also gave asymptotically optimal algorithms for several problems including sorting and general permutations. In the Parallel Disk Model, N records are stored on D disks D 0 ; D 1 ; : : : ; D D1 , with N=D records stored on each disk. <p> Optimal algorithms have appeared in the literature for fundamental problems such as sorting <ref> [3, 6, 21, 22, 24] </ref>, general permutations [24], and structured permutations [9, 10, 26], as well as higher-level domains such as Fast Fourier transform [24], matrix-matrix multiplication [24], LUP decomposition [27], computational geometry problems [5, 18], graph algorithms [8], and boolean function manipulation [4]. <p> Optimal algorithms have appeared in the literature for fundamental problems such as sorting [3, 6, 21, 22, 24], general permutations <ref> [24] </ref>, and structured permutations [9, 10, 26], as well as higher-level domains such as Fast Fourier transform [24], matrix-matrix multiplication [24], LUP decomposition [27], computational geometry problems [5, 18], graph algorithms [8], and boolean function manipulation [4]. <p> Optimal algorithms have appeared in the literature for fundamental problems such as sorting [3, 6, 21, 22, 24], general permutations <ref> [24] </ref>, and structured permutations [9, 10, 26], as well as higher-level domains such as Fast Fourier transform [24], matrix-matrix multiplication [24], LUP decomposition [27], computational geometry problems [5, 18], graph algorithms [8], and boolean function manipulation [4]. <p> Optimal algorithms have appeared in the literature for fundamental problems such as sorting [3, 6, 21, 22, 24], general permutations <ref> [24] </ref>, and structured permutations [9, 10, 26], as well as higher-level domains such as Fast Fourier transform [24], matrix-matrix multiplication [24], LUP decomposition [27], computational geometry problems [5, 18], graph algorithms [8], and boolean function manipulation [4].
Reference: [25] <author> L. F. Wisniewski, </author> <title> Efficient Design and Implementation of Permutation Algorithms on the Memory Hierarchy, </title> <type> PhD thesis, </type> <institution> Dartmouth College Department of Computer Science, </institution> <month> Mar. </month> <year> 1996. </year> <title> [26] , Structured permuting in place on parallel disk systems, </title> <booktitle> in Proceedings of the Fourth Annual Workshop on I/O in Parallel and Distributed Systems (IOPADS), </booktitle> <month> May </month> <year> 1996, </year> <pages> pp. 128-139. </pages>
Reference-contexts: We have also shown how to detect BMMC permutations at run time, given a vector of target addresses. Detection is inexpensive and, when successful, permits the execution of our BMMC algorithm or possibly a faster algorithm for a more restricted permutation class. Wisniewski <ref> [25] </ref> uses the linear-algebraic technique of performing column additions and row additions to derive BMMC-permutation algorithms on distributed-memory models and main-memory/cache models.
Reference: [27] <author> D. Womble, D. Greenberg, S. Wheat, and R. Riesen, </author> <title> Beyond core: Making parallel computer I/O practical, </title> <booktitle> in DAGS '93, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: Optimal algorithms have appeared in the literature for fundamental problems such as sorting [3, 6, 21, 22, 24], general permutations [24], and structured permutations [9, 10, 26], as well as higher-level domains such as Fast Fourier transform [24], matrix-matrix multiplication [24], LUP decomposition <ref> [27] </ref>, computational geometry problems [5, 18], graph algorithms [8], and boolean function manipulation [4].
References-found: 23

