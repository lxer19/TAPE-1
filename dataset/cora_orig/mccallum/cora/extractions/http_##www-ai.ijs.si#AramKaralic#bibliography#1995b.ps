URL: http://www-ai.ijs.si/AramKaralic/bibliography/1995b.ps
Refering-URL: http://www-ai.ijs.si/AramKaralic/bibliography/1995b.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: email: aram.karalic@ijs.si  
Phone: voice: +386 61 177 37 78, fax: +386 61 125 10 38  
Title: First Order Induction Using Real-Valued Class and Variables  
Author: Aram Karalic 
Web: http://www-ai.ijs.si/AramKaralic/home.html  
Address: Jamova 39, 61111 Ljubljana, Slovenia  
Affiliation: Jozef Stefan Institute, Artificial Intelligence Laboratory  
Abstract: A first order regression algorithm capable of handling real-valued variables is introduced and some of its applications are presented. Regressional learning assumes real-valued (continuous) class and discrete or real-valued variables. The algorithm combines regressional learning with standard ILP concepts, such as first order concept description and background knowledge. IN particular, our goals were to develop a system which can: induce first-order logic concepts which incorporate real-valued variables, use background knowledge in intensional form, model dynamic systems (learn from time series), partition attribute space to subspaces in order to find a regressional submodel for each subspace separately, end handle noisy data. An outline of the algorithm and the results of the system's application in some artificial and real-world domains are presented. Real-world domains comprise modelling of the water behavior in a surge tank and modelling of the workpiece roughness in the steel grinding process. The results confirm the advantage of combining of various techniques and again confirm that the comprehensibility of the induced knowledge in crucial for successfull application of AI techniques.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Breiman, J. H. Friedman, R.A. Olshen, and C.J. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth Int. Group, </publisher> <address> Belmont, California, USA, </address> <year> 1984. </year>
Reference-contexts: Examples of algorithms of this kind are: ID3 [18], Assistant [2], AQ15 [16]. Algorithms learning a real-valued class induce a functional dependence between discrete and real-valued independent variables and a real-valued dependent variable. Some algorithms of this kind are: Abacus [5], Bacon [14] Fahrenheit [21], Cart <ref> [1] </ref>, Retis [8], M5 [20], Lagrange [3], GoldHorn [12]. Propositional algorithms capable of handling real-valued variables have already reached certain efficiency and practical applicability, while the researchers in the field of Inductive Logic Programming (ILP) only recently began to focus their attention on algorithms capable of handling real data.
Reference: [2] <author> Bojan Cestnik, Igor Kononenko, and Ivan Bratko. </author> <title> Assistant 86: A knowledge-elicitation tool for sophisticated users. </title> <editor> In Ivan Bratko and Nada Lavrac, editors, </editor> <booktitle> Progress in Machine Learning, Wilmslow, 1987. </booktitle> <publisher> Sigma Press. </publisher> <pages> 10 </pages>
Reference-contexts: Algorithms learning a discrete class induce a classification rule. Examples of algorithms of this kind are: ID3 [18], Assistant <ref> [2] </ref>, AQ15 [16]. Algorithms learning a real-valued class induce a functional dependence between discrete and real-valued independent variables and a real-valued dependent variable. Some algorithms of this kind are: Abacus [5], Bacon [14] Fahrenheit [21], Cart [1], Retis [8], M5 [20], Lagrange [3], GoldHorn [12].
Reference: [3] <author> Saso Dzeroski and Ljupco Todorovski. </author> <title> Discovering dynamics. </title> <booktitle> In Proceedings of Tenth Machine Learning Conference, </booktitle> <pages> pages 97-103, </pages> <address> Amherst, Massachusetts, USA, </address> <month> June 27-29 </month> <year> 1993. </year>
Reference-contexts: Algorithms learning a real-valued class induce a functional dependence between discrete and real-valued independent variables and a real-valued dependent variable. Some algorithms of this kind are: Abacus [5], Bacon [14] Fahrenheit [21], Cart [1], Retis [8], M5 [20], Lagrange <ref> [3] </ref>, GoldHorn [12]. Propositional algorithms capable of handling real-valued variables have already reached certain efficiency and practical applicability, while the researchers in the field of Inductive Logic Programming (ILP) only recently began to focus their attention on algorithms capable of handling real data.
Reference: [4] <author> Saso Dzeroski, Ljupco Todorovski, and Tanja Urbancic. </author> <title> Handling real numbers in ilp: A step towards successful behavioral cloning (extended abstract). </title> <booktitle> In Proceedings of Eighth European Conference on Machine Learning ECML'95, </booktitle> <pages> pages 283-286, </pages> <address> Berlin, Germany, 1995. </address> <publisher> Springer. </publisher>
Reference-contexts: Such variables are rather common when dealing with real-life domains, therefore the need for algorithms capable of handling real-valued variables is obvious if one wants to apply the systems to the real-life problems. Dzeroski and Todorovski <ref> [4] </ref> have lately introduced an ILP system Dinus, which can handle real class. Dinus, a successor of Linus [15], transforms ILP problems into propositional form and then applies propositional learning systems that have the desired capability.
Reference: [5] <author> B. Falkenheiner and Ryszard Michalski. </author> <title> Integrating quantitative and qualitative discovery in the ABACUS system. </title> <editor> In Yves Kodratoff and Ryszard Michalski, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, Volume III, </booktitle> <pages> pages 153-190, </pages> <address> San Mateo, CA, USA, 1990. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Algorithms learning a discrete class induce a classification rule. Examples of algorithms of this kind are: ID3 [18], Assistant [2], AQ15 [16]. Algorithms learning a real-valued class induce a functional dependence between discrete and real-valued independent variables and a real-valued dependent variable. Some algorithms of this kind are: Abacus <ref> [5] </ref>, Bacon [14] Fahrenheit [21], Cart [1], Retis [8], M5 [20], Lagrange [3], GoldHorn [12].
Reference: [6] <author> Bogdan Filipic, Miha Junkar, Ivan Bratko, and Aram Karalic. </author> <title> An application of machine learning to a metal-working process. </title> <booktitle> In Proceedings of ITI-91, </booktitle> <address> Cavtat, Croatia, </address> <year> 1991. </year>
Reference-contexts: An example of a control action is terminating the process when its performance reaches an unacceptable degree <ref> [6] </ref>. Since a control action is easily deducible from workpiece roughness, the subproblem of the workpiece roughness estimation was addressed first. Several machine learning techniques were already applied to the problem, yielding encouraging results [6] and showing that machine learning tools can produce adequate models of the system behavior. 4.2.1 Experiments <p> example of a control action is terminating the process when its performance reaches an unacceptable degree <ref> [6] </ref>. Since a control action is easily deducible from workpiece roughness, the subproblem of the workpiece roughness estimation was addressed first. Several machine learning techniques were already applied to the problem, yielding encouraging results [6] and showing that machine learning tools can produce adequate models of the system behavior. 4.2.1 Experiments Data were obtained during an experiment in which vibration signals generated by the grinding wheel and the workpiece were detected by an accelerometer sensor and processed by a spectrum analyser.
Reference: [7] <institution> Mihael Junkar. University of Ljubljana, Faculty for Mechanical Engineering, Laboratory for Alternative Technologies. </institution> <type> Personal communication. </type>
Reference-contexts: However, newly induced models frequently contained background knowledge literals. It is interesting that according to domain experts <ref> [7, 17] </ref>, this can be considered as a significant improvement, because newly induced models are more general than models without background knowledge.
Reference: [8] <author> Aram Karalic. </author> <title> Induction of Regression Trees From Incomplete Data. </title> <type> Master's thesis, </type> <institution> University of Ljubl-jana, Faculty for Electrical Engineering and Computer Science, Ljubljana, Slovenia, </institution> <year> 1991. </year>
Reference-contexts: Examples of algorithms of this kind are: ID3 [18], Assistant [2], AQ15 [16]. Algorithms learning a real-valued class induce a functional dependence between discrete and real-valued independent variables and a real-valued dependent variable. Some algorithms of this kind are: Abacus [5], Bacon [14] Fahrenheit [21], Cart [1], Retis <ref> [8] </ref>, M5 [20], Lagrange [3], GoldHorn [12]. Propositional algorithms capable of handling real-valued variables have already reached certain efficiency and practical applicability, while the researchers in the field of Inductive Logic Programming (ILP) only recently began to focus their attention on algorithms capable of handling real data.
Reference: [9] <author> Aram Karalic. </author> <title> Employing linear regression in regression tree leaves. </title> <booktitle> In Proceedings of ECAI'92 (European Conference on Artificial Intelligence), </booktitle> <pages> pages 440-441, </pages> <address> Wienna, Austria, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: Currently, Dinus 1 procedure InduceModel (var M) begin M:= ; E:= "All training examples" MakeDefaultClause (E,C 0 ) while not StopLearning (E) do begin GenerateClause (C,E) AddClauseToModel (C,M) RemoveExamplesCoveredByClause (C,E) end employs propositional algorithm Retis <ref> [9] </ref> to perform the induction when the treatment of real-valued attributes and class is required. In the paper we describe a system which induces concepts in first order logic and handles real-valued attributes.
Reference: [10] <author> Aram Karalic. </author> <title> First Order Regression. </title> <type> PhD thesis, </type> <institution> University of Ljubljana, Faculty for Electrical Engineering and Computer Science, </institution> <year> 1995. </year>
Reference-contexts: All specializations can be enabled and disabled through definable user options. The rest of the section explores in more detail some individual aspects of the search. Detailed description of the algorithm can be found in <ref> [10] </ref>. Error Estimate: For every candidate clause an error estimate is calculated aimed at predicting the clause's error when classifying unseen examples. The mean squared error (R) is used as an error estimate in our case. <p> Detailed description of the pruning methods can be found in <ref> [10] </ref>. Linear Regression: Two kinds of candidate clauses are encountered during the clause construction: candidate clauses which instantiate the class variable, and candidate clauses that don't instantiate the class variable.
Reference: [11] <institution> Boris Kompare. Faculty for Civil Engineering and Geodesy, Department for Hydroengineering, Institute for Sanitary Engineering. </institution> <type> Personal communication. </type>
Reference-contexts: As a measure of a model's fitness, the difference between the behavior according to the model, and the measured behavior is taken. A domain expert <ref> [11] </ref> suggested using a b = P N i=1 jh a (t i ) h b (t i )j as a difference measure a b between two behaviors a and b. Table 1 gives the quality of various models.
Reference: [12] <author> Viljem Krizman. </author> <title> Handling Noisy Data in Automatic Modelling of Dynamical Systems. </title> <type> Master's thesis, </type> <institution> University of Ljubljana, Faculty for Electrical Engineering and Computer Science, Ljubljana, Slovenia, </institution> <year> 1993. </year> <note> In Slovene. </note>
Reference-contexts: Algorithms learning a real-valued class induce a functional dependence between discrete and real-valued independent variables and a real-valued dependent variable. Some algorithms of this kind are: Abacus [5], Bacon [14] Fahrenheit [21], Cart [1], Retis [8], M5 [20], Lagrange [3], GoldHorn <ref> [12] </ref>. Propositional algorithms capable of handling real-valued variables have already reached certain efficiency and practical applicability, while the researchers in the field of Inductive Logic Programming (ILP) only recently began to focus their attention on algorithms capable of handling real data. <p> h 3:84900069 _ h 2 otherwise : 4.1.2 Expert's Evaluation and Conclusions The best theoretically derived model of the tank was known to be h = 0:05608 h 3:75771 _ hj _ hj: We will now evaluate the induced model and compare its performance with the model induced with GoldHorn <ref> [12] </ref> and with the performance of the best known model (the "correct" model). Performance of the correct model will be estimated because even the correct model does not reproduce the system's behavior perfectly.
Reference: [13] <author> Viljem Krizman, Saso Dzeroski, and Boris Kompare. </author> <title> Discovering dynamics from measured data. </title> <booktitle> In Working Notes on the MLNet Workshop on Statistics, Machine Learning, and Knowledge Discovery in Databases. </booktitle> <institution> Institute of Computer Science, </institution> <address> Heraklion, Greece, </address> <year> 1995. </year>
Reference-contexts: Surge pressure is transformed to water movement in the surge tank, resulting in an increase or decrease of the steady-state water level in the tank. The rest of the pipeline is thus not exposed to the pressure shocks <ref> [13] </ref>. 4.1.1 Experiments Our experiments were conducted on measurements of the water movement in a laboratory replica of a surge tank. Only one variable was measured: the water level h. The data consists of time series describing the water level.
Reference: [14] <author> Pat Langley, Herbert A. Simon, and Gary L. Bradshaw. </author> <title> Heuristics for empirical discovery. </title> <editor> In L. Bolc, editor, </editor> <booktitle> Computational Models of Learning, </booktitle> <pages> pages 355-372, </pages> <address> Berlin, 1987. </address> <publisher> Springer. </publisher>
Reference-contexts: Examples of algorithms of this kind are: ID3 [18], Assistant [2], AQ15 [16]. Algorithms learning a real-valued class induce a functional dependence between discrete and real-valued independent variables and a real-valued dependent variable. Some algorithms of this kind are: Abacus [5], Bacon <ref> [14] </ref> Fahrenheit [21], Cart [1], Retis [8], M5 [20], Lagrange [3], GoldHorn [12]. <p> In our experiment the same data was used as in experiments with Bacon <ref> [14] </ref>. Fors was presented with data for six planets known at Kepler's time (P = period (years), D = major semi-axis of the orbit (astronomical units)): 4 P 0.241 0.616 1.000 1.881 11.855 29.459 Background knowledge consisted of the predicates enabling square root and multiplication.
Reference: [15] <author> Nada Lavrac, Saso Dzeroski, and Marko Grobelnik. </author> <title> Learning nonrecursive definitions of relation s with linus. </title> <booktitle> In Proceedings of Fifth European Working Session on Learning, </booktitle> <pages> pages 265-281, </pages> <address> Berlin, 1991. </address> <publisher> Springer. </publisher>
Reference-contexts: Dzeroski and Todorovski [4] have lately introduced an ILP system Dinus, which can handle real class. Dinus, a successor of Linus <ref> [15] </ref>, transforms ILP problems into propositional form and then applies propositional learning systems that have the desired capability.
Reference: [16] <author> Ryszard Michalski, Igor Mozetic, J. R. Hong, and Nada Lavrac. </author> <title> The AQ15 inductive learning system. </title> <type> Technical Report UIUCDCS-R-86-1260, </type> <institution> Department of Computer Science, University of Illinois at Urbana-Champaign, </institution> <year> 1986. </year>
Reference-contexts: Algorithms learning a discrete class induce a classification rule. Examples of algorithms of this kind are: ID3 [18], Assistant [2], AQ15 <ref> [16] </ref>. Algorithms learning a real-valued class induce a functional dependence between discrete and real-valued independent variables and a real-valued dependent variable. Some algorithms of this kind are: Abacus [5], Bacon [14] Fahrenheit [21], Cart [1], Retis [8], M5 [20], Lagrange [3], GoldHorn [12].
Reference: [17] <institution> Robert Posel. University of Ljubljana, Faculty for Mechanical Engineering, Laboratory for Alternative Technologies. </institution> <type> Personal communication. </type>
Reference-contexts: However, newly induced models frequently contained background knowledge literals. It is interesting that according to domain experts <ref> [7, 17] </ref>, this can be considered as a significant improvement, because newly induced models are more general than models without background knowledge.
Reference: [18] <author> Ross Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: Algorithms learning a discrete class induce a classification rule. Examples of algorithms of this kind are: ID3 <ref> [18] </ref>, Assistant [2], AQ15 [16]. Algorithms learning a real-valued class induce a functional dependence between discrete and real-valued independent variables and a real-valued dependent variable. Some algorithms of this kind are: Abacus [5], Bacon [14] Fahrenheit [21], Cart [1], Retis [8], M5 [20], Lagrange [3], GoldHorn [12].
Reference: [19] <author> Ross Quinlan. </author> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 3(5), </volume> <year> 1990. </year>
Reference-contexts: By analogy with the attribute-value learning, variable Y is called a class variable while variables V 1 to V n represent attributes. Fors uses covering approach similar to the one used in Foil <ref> [19] </ref>. The algorithm repeatedly constructs a clause. When a clause is found, all examples covered by the clause are removed from the training set. The procedure is repeated while there are enough examples left. The top level of the algorithm is depicted in Figure 1.
Reference: [20] <author> Ross Quinlan. </author> <title> Learning with continuous classes. </title> <booktitle> In Proceedings if AI'92, </booktitle> <address> Singapore, 1992. </address> <publisher> World Scientific. </publisher>
Reference-contexts: Algorithms learning a real-valued class induce a functional dependence between discrete and real-valued independent variables and a real-valued dependent variable. Some algorithms of this kind are: Abacus [5], Bacon [14] Fahrenheit [21], Cart [1], Retis [8], M5 <ref> [20] </ref>, Lagrange [3], GoldHorn [12]. Propositional algorithms capable of handling real-valued variables have already reached certain efficiency and practical applicability, while the researchers in the field of Inductive Logic Programming (ILP) only recently began to focus their attention on algorithms capable of handling real data.
Reference: [21] <author> R. Zembowitz and J _ Zytkov. </author> <title> Discovery of equations: Experimental evaluation of convergence. </title> <booktitle> In Proceedings of 10 th National Conference on Artificial Intelligence, </booktitle> <address> San Mateo, CA, USA, 1992. </address> <publisher> Morgan Kaufman. </publisher> <pages> 11 </pages>
Reference-contexts: Examples of algorithms of this kind are: ID3 [18], Assistant [2], AQ15 [16]. Algorithms learning a real-valued class induce a functional dependence between discrete and real-valued independent variables and a real-valued dependent variable. Some algorithms of this kind are: Abacus [5], Bacon [14] Fahrenheit <ref> [21] </ref>, Cart [1], Retis [8], M5 [20], Lagrange [3], GoldHorn [12].
References-found: 21

