URL: http://www.cs.ucsd.edu/users/mihir/papers/os.ps.gz
Refering-URL: http://www.cs.ucsd.edu/users/mihir/papers/complexity-papers.html
Root-URL: http://www.cs.ucsd.edu
Title: Oblivious Sampling  P m fi for any function f f0; 1g l  
Author: Mihir Bellare John Rompel 
Address: San Diego, 9500 Gilman Drive, La Jolla, CA 92093.  
Affiliation: Department of Computer Science Engineering, Mail Code 0114, University of California at  
Note: Randomness-Efficient  Pr fi 1  Work done while the author was at MIT. Present whereabouts unknown.  
Pubnum: [0;  
Email: E-mail: mihir@cs.ucsd.edu  
Date: November 1994  1].  
Abstract: A preliminary version of this paper appears in Proceedings of the 35th Symposium on Foundations Abstract We introduce a natural notion of obliviousness of a sampling procedure, and construct a randomness-efficient oblivious sampler. Our sampler uses O(l + log ffi 1 log l) coins to output m = poly(* 1 ; log ffi 1 ; log l) sample points x 1 ; : : : ; x m 2 f0; 1g l such that We apply this sampling procedure to reduce the randomness required to halve the number of rounds of interaction in an Arthur Merlin proof system. Given a 2g(n) round AM proof for L in which Arthur sends l(n) coins per round and Merlin responds with a q(n) bit string, we construct a g(n) round AM proof for L in which Arthur sends O(l + (q + log g) log l) coins per round and Merlin responds with a poly(n) bit string. of Computer Science, IEEE, 1994.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W. Aiello, S. Goldwasser and J. H -astad. </author> <title> On the Power of Interaction. </title> <type> Combinatorica 10(1), </type> <pages> 3-25, </pages> <year> 1990. </year>
Reference-contexts: The second is a pair of tail inequalities for low independence random variables which are simple both to state and to prove. 1.1 Randomness-efficient sampling A security parameter n is ubiquitous in the following discussion. Parameters l; m are integer valued functions of n, and *; ffi are <ref> [0; 1] </ref> valued functions of n, such that l (n); * 1 (n); log ffi 1 (n) are at most poly (n). <p> Approximation, obliviousness and our result We are interested in procedures which enable us to approximate the average value E [f ] = 2 l (n) x2f0;1g l (n) f (x) of an arbitrary function f : f0; 1g l (n) ! <ref> [0; 1] </ref>. Typically, such a procedure has two stages; it is accordingly specified by a pair A = (S; E) of polynomial time algorithms. The first algorithm, called the sampler , is probabilistic, and the second, called the estimator , is assumed here, for simplicity, to be deterministic. <p> We say that A = (S; E) is a universal (l; *; ffi)-approximator if for all n and all f : f0; 1g l (n) ! <ref> [0; 1] </ref> it is the case that Pr fi f E [f ] fi i the probability being over the coin tosses of the sampler. (The universality refers to the fact that the approximator works for all functions, not some subset like just the boolean functions). <p> A simple application of a Chernoff bound, such as that of Lemma A.3, shows that if m = (* 2 log ffi 1 ) then (1) indeed holds, for any f : f0; 1g l (n) ! <ref> [0; 1] </ref>. The particular simple form of estimation used in the standard procedure seems natural, and is crucial to some applications such as those in this paper. <p> AM denotes the class of languages possessing Arthur-Merlin proof systems. Clearly, Arthur-Merlin games are special kinds of interactive proof systems [15]. Their special properties make them very useful for proving structural results <ref> [1, 4, 8] </ref>, and on the other hand we lose none of the language recognition power: AM = IP = PSPACE [16, 19, 24]. <p> Research into the effect of varying the amount of interaction or randomness in an Arthur Merlin game arose out of the desire to understand, more quantitatively, the power of these resources as demonstrated by the AM = PSPACE result. Following many results on interaction <ref> [1, 3, 4, 8] </ref>, and the recent initiation of work on randomness [5], we would like a more unified treatment enabling us to understand tradeoffs; for example: if you want to reduce the number of rounds, how much do you pay in coins? The so-called "speedup" problem, which we now discuss, <p> Typically we are looking at a collection of t-wise independent random variables. For simplicity let them take values between 0 and 1. Definition 2.1 Let X 1 ; : : : ; X n be random variables taking values in the interval <ref> [0; 1] </ref>. We say that X 1 ; : : : ; X n are t-wise independent if for any a 1 ; : : : ; a t 2 [0; 1], and any distinct indices 1 i 1 ; : : : ; i t n, it is the case <p> Definition 2.1 Let X 1 ; : : : ; X n be random variables taking values in the interval <ref> [0; 1] </ref>. We say that X 1 ; : : : ; X n are t-wise independent if for any a 1 ; : : : ; a t 2 [0; 1], and any distinct indices 1 i 1 ; : : : ; i t n, it is the case that Pr [ X i 1 = a 1 ; : : : ; X i t = a t ] = j=1 Pr X i j = a j <p> Lemma 2.2 (First t-wise Independence Tail Inequality) Let t 4 be an even integer. Suppose X 1 ; : : : ; X n are t-wise independent random variables taking values in <ref> [0; 1] </ref>. Let X = X 1 + + X n and = E [X], and let A &gt; 0. <p> Lemma 2.3 (Second t-wise Independence Tail Inequality) Let t 4 be an even integer. Suppose X 1 ; : : :; X n are t-wise independent random variables taking values in <ref> [0; 1] </ref>. Let X = X 1 + + X n and = E [X], and let A &gt; 0. Then Pr [ jX j A ] C t t + t 2 ! t=2 where C t = 2 p The basic paradigm for proving such inequalities is standard. <p> Definition 3.1 Let l; m: N ! N and *; ffi: N ! <ref> [0; 1] </ref>. <p> which on input 1 n outputs a sequence of points x 1 ; : : : ; x m (n) 2 f0; 1g l (n) such that: for any collection of m (n) functions f 1 ; : : : ; f m (n) : f0; 1g l (n) ! <ref> [0; 1] </ref> it is the case that Pr fi m (n) i=1 (f i (x i ) E [f i ]) fi i the probability being over the coin tosses of S. <p> It follows from the definition of t-universal hash functions that Y 1 ; : : : ; Y m is a collection of t-wise independent random variables in the range <ref> [0; 1] </ref>. <p> Lemma 4.2 Let t; m; d be integers such that t 6 is even, m t * 2 ffi 2=t , and d lg m. Then for any collection of m functions f 1 ; : : :; f m : f0; 1g l ! <ref> [0; 1] </ref>, picking h at random from H t (d; l) implies that Pr fi m i=1 ( f i (h (i)) E [f i ] ) fi i Next, observe that this sampler uses t max (d; l) random bits. <p> The reason is that we actually think of sampling each function individually except for the final sample. Lemma 4.3 Let t; d be integers such that t 6 is even and 2 d t * 2 ffi 2=t . Then for any function f : f0; 1g l ! <ref> [0; 1] </ref>, picking h at random from H t (d; l) implies that Pr [ j E [f ffih] E [f ] j &lt; * ] 1 ffi : Proof: Let m = 2 d . <p> Suppose d lg m, 2 2 rj d * 2 2=t j (j = 1; : : :; r 1) and t r fl ffi fl Then for any collection of m functions f 1 ; : : : ; f m : f0; 1g 2 r d ! <ref> [0; 1] </ref>, picking h j at random from H t j (2 rj d; 2 rj+1 d) implies that Pr fi m i=1 ( (f i ffih 1 ffi ffih r )(i) E [f i ] ) fi fi &lt; r* fl 1 rffi fl : Proof: Let f = 1 <p> The error probability of the game on input w with respect to a language L is defined by err L (w) = 1 acc (w) if w 2 L acc (w) otherwise. The error probability of the game, with respect to L, is e L : N ! <ref> [0; 1] </ref> defined by e L (n) = sup jwj=n err L (w). Thus the game is a proof system for L if e L 1=3.
Reference: [2] <author> M. Ajtai, J. Komlos and E. Szemeredi. </author> <title> Deterministic Simulation in Logspace. </title> <booktitle> Proceedings of the 19th Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1987. </year>
Reference-contexts: The approximation method of [5] uses both pairwise independence and expanders. The sampler expends only 2l + O (log ffi 1 ) coins to generate m = O (* 2 log ffi 1 ) sample points, which is optimal 1 Gillman's analysis improves those of <ref> [2, 12, 18] </ref>.
Reference: [3] <author> L. Babai. </author> <title> Trading Group Theory for Randomness. </title> <booktitle> Proceedings of the 17th Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1985. </year>
Reference-contexts: One then applies [20, Lemma 3]. 1.2 Randomness-efficient speedup An Arthur-Merlin game <ref> [3] </ref> is a two-party protocol. The players are an all-powerful, but, without loss of generality, deterministic, "prover," called Merlin, and a probabilistic, polynomial-time "verifier," called Arthur . <p> Research into the effect of varying the amount of interaction or randomness in an Arthur Merlin game arose out of the desire to understand, more quantitatively, the power of these resources as demonstrated by the AM = PSPACE result. Following many results on interaction <ref> [1, 3, 4, 8] </ref>, and the recent initiation of work on randomness [5], we would like a more unified treatment enabling us to understand tradeoffs; for example: if you want to reduce the number of rounds, how much do you pay in coins? The so-called "speedup" problem, which we now discuss, <p> The log l factor in the number of random bits comes from the fact that we have about O (log l) iterations of the sampling. 5 Application We prove Theorem 1.2. Our analysis uses the notion of the accepting probability function of an AM game <ref> [3, 4] </ref>, so we begin by recalling it. We then note that we may restrict our attention to a special class of games, provide an overview of the construction, and finally provide the proof. 5.1 Preliminaries Fix an Arthur-Merlin game. <p> The accepting probability function acc (; ) captures the interaction of Arthur with such an "optimal Merlin," and is defined by reverse induction on partial conversations, as follows (cf. <ref> [3, 4] </ref>): * Let ~c be a conversation. Then the value of the accepting probability function at ~c is the value of the deciding predicate. <p> We begin with a discussion of the proof of [4] and then go on to our approach and see how it motivates oblivious sampling. Following <ref> [3, 4] </ref> it is convenient to specify the move structure of games symbolically.
Reference: [4] <author> L. Babai and S. Moran. </author> <title> Arthur-Merlin Games: A Randomized Proof System, and a Hierarchy of Complexity Classes. </title> <journal> J. Computer and System Sciences 36, </journal> <pages> 254-276, </pages> <year> 1988. </year>
Reference-contexts: do we need in order to reduce the number of rounds of interaction in an interactive proof by a constant factor? Oblivious sampling seemed crucial, and, in particular, we apply our new sampling procedure to prove a randomness-efficient version of the well-known "speedup," or round-halving theorem of Babai and Moran <ref> [4] </ref>. We hope this work will have further applications in this area, particularly for multi-prover or probabilistically checkable proofs. There are two side aspects of this work which we feel might be interesting or useful. The first is a simpler and more direct proof of the speedup theorem of [4], obtained <p> Moran <ref> [4] </ref>. We hope this work will have further applications in this area, particularly for multi-prover or probabilistically checkable proofs. There are two side aspects of this work which we feel might be interesting or useful. The first is a simpler and more direct proof of the speedup theorem of [4], obtained in the process of reducing the randomness used. The second is a pair of tail inequalities for low independence random variables which are simple both to state and to prove. 1.1 Randomness-efficient sampling A security parameter n is ubiquitous in the following discussion. <p> AM denotes the class of languages possessing Arthur-Merlin proof systems. Clearly, Arthur-Merlin games are special kinds of interactive proof systems [15]. Their special properties make them very useful for proving structural results <ref> [1, 4, 8] </ref>, and on the other hand we lose none of the language recognition power: AM = IP = PSPACE [16, 19, 24]. <p> Research into the effect of varying the amount of interaction or randomness in an Arthur Merlin game arose out of the desire to understand, more quantitatively, the power of these resources as demonstrated by the AM = PSPACE result. Following many results on interaction <ref> [1, 3, 4, 8] </ref>, and the recent initiation of work on randomness [5], we would like a more unified treatment enabling us to understand tradeoffs; for example: if you want to reduce the number of rounds, how much do you pay in coins? The so-called "speedup" problem, which we now discuss, <p> The speedup problem is to construct a g (n) round Arthur-Merlin proof system for L. Babai and Moran <ref> [4] </ref> showed that speedup is possible, but quite costly: in their construction, the length of Arthur's messages (number of random bits he sends per round) in the final g (n) round game is O (lqg 3 log g), considerably more than the l (n) bits it was in the original game. <p> Underlying this result is a new analysis of the basic speedup procedure of <ref> [4] </ref>. This analysis is actually simpler and more direct than the original one, yielding a simpler proof of the speedup theorem. It is also tighter, showing that Arthur can use less resources in the final game. <p> The log l factor in the number of random bits comes from the fact that we have about O (log l) iterations of the sampling. 5 Application We prove Theorem 1.2. Our analysis uses the notion of the accepting probability function of an AM game <ref> [3, 4] </ref>, so we begin by recalling it. We then note that we may restrict our attention to a special class of games, provide an overview of the construction, and finally provide the proof. 5.1 Preliminaries Fix an Arthur-Merlin game. <p> The accepting probability function acc (; ) captures the interaction of Arthur with such an "optimal Merlin," and is defined by reverse induction on partial conversations, as follows (cf. <ref> [3, 4] </ref>): * Let ~c be a conversation. Then the value of the accepting probability function at ~c is the value of the deciding predicate. <p> Note however that the above transformation will increase the length of Merlin's messages by a poly (n) factor. 5.2 Overview of our solution In this section we give a high level overview of the ideas behind our randomness-efficient speedup theorem. We begin with a discussion of the proof of <ref> [4] </ref> and then go on to our approach and see how it motivates oblivious sampling. Following [3, 4] it is convenient to specify the move structure of games symbolically. <p> We begin with a discussion of the proof of [4] and then go on to our approach and see how it motivates oblivious sampling. Following <ref> [3, 4] </ref> it is convenient to specify the move structure of games symbolically. <p> In <ref> [4] </ref>, the given game is visualized as (AMAM) g A. Then, in each AMAM block, MAM is converted to AMA. Merging consecutive Arthur moves gives the desired outcome. <p> Clearly Merlin's chances of winning can only increase in the new game. One has to show they do not increase too much. The analysis of <ref> [4] </ref> begins by showing that a block is "lucky" with high enough probability (a block is deemed lucky if, given that the value of the accepting probability function at the start of the MAM block was a, the corresponding value in the switched AMA block is O (ga)). <p> The amplification method of [5], while reducing Arthur's coin flips, increases the length of Merlin's messages, and if we were to use this the final cost in randomness of our speedup would actually end up being even worse than that of <ref> [4] </ref>. This fact, pointed out to us by Goldreich, motivates us to try a different approach. Our first step, rather than try to reduce the error cheaply, is to remove the need for error reduction. To do this requires stronger properties from the MAM to AMA switch. <p> This will enable us to derive much tighter bounds on the change in the value of the accepting probability function: we will prove that with high probability, the change can be restricted to an additive amount (recall that in <ref> [4] </ref> the change is a multiplicative factor of O (g)). We present this novel MAM to AMA switch as a general Switching Lemma for converting a game of the form X (MAM)Y, (where X; Y are arbitrary game segments) into one of the form X (AMA)Y. <p> We present this novel MAM to AMA switch as a general Switching Lemma for converting a game of the form X (MAM)Y, (where X; Y are arbitrary game segments) into one of the form X (AMA)Y. This approach would already serve to yield some improvement over <ref> [4] </ref>, but the main motivation is that the problem has now been cast in a form which is amenable to the use of oblivious sampling. <p> This is the route to a simpler proof of the speedup theorem of <ref> [4] </ref>, but one which nonetheless yields a final game of lower complexity than that derived in [4]. To reduce the randomness further, we will use the sampler of Theorem 4.5 in the role of S. <p> This is the route to a simpler proof of the speedup theorem of <ref> [4] </ref>, but one which nonetheless yields a final game of lower complexity than that derived in [4]. To reduce the randomness further, we will use the sampler of Theorem 4.5 in the role of S. We will write E i f (x i ) for 1 m i=1 f (x i ); because we will have Arthur sending i at random this will be more natural. <p> Note that we did not need to reduce the error probability of the original game by more than a constant factor. Let's look at randomness efficiency. We begin by recalling that in the result of <ref> [4] </ref>, Arthur uses O (lqg 3 log g) random bits per round in the final game. How much do we use? It depends on which oblivious sampler we use, as follows. We focus on l log n which by Lemma 5.1 is without loss of generality. <p> If we set the sampler in Theorem 5.3 to the standard universal (l; *; ffi)-oblivious sampler then, in the final game, Arthur uses O (l* 2 log ffi 1 ) = O (lg 2 (q + log g)) random bits per round, already an improvement over <ref> [4] </ref>. If instead we set it to the sampler of Theorem 4.5 then Arthur uses O (l + log ffi 1 log l) = O (l + (q + log g) log l) random bits per round, which yields Theorem 1.2.
Reference: [5] <author> M. Bellare, O. Goldreich and S. Goldwasser. </author> <title> Randomness in Interactive Proofs. </title> <booktitle> Computational Complexity 3, </booktitle> <pages> 319-354, </pages> <year> 1993. </year>
Reference-contexts: Thus much research has been invested in devising randomness-efficient samplers. The conclusion from the prior work, reviewed below, is that saving randomness seems finally to have been at odds with obliviousness in that the most randomness-efficient known sampler, namely that of <ref> [5] </ref>, is non-oblivious. The following theorem addresses this gap. Theorem 1.1 Let l: N ! N and *; ffi : N ! (0; 1]. <p> The approximation method of <ref> [5] </ref> uses both pairwise independence and expanders. The sampler expends only 2l + O (log ffi 1 ) coins to generate m = O (* 2 log ffi 1 ) sample points, which is optimal 1 Gillman's analysis improves those of [2, 12, 18]. <p> points (m) Standard Full independence Yes O (l * 2 log ffi 1 ) m st = O (e 2 log ffi 1 ) [11] Pairwise Independence Yes O (l) O (* 2 ffi 1 ) [13] Expanders Yes O (l + * 2 log ffi 1 ) m st <ref> [5] </ref> Pair. Ind. + Expanders No O (l + log ffi 1 ) m st This paper Iterated sampling Yes O (l + log ffi 1 log l) poly (* 1 ; log ffi 1 ; log l) logarithmic factor in coin tosses. up to constant factors [9]. <p> Thus the reduction in randomness was at the cost of obliviousness. Goldreich and Wigderson [14] reduce the randomness from 2l + O (log ffi 1 ) to l + O (log ffi 1 ), but they use, in their final step, the method of <ref> [5] </ref>, so that their sampler too is non-oblivious. <p> Following many results on interaction [1, 3, 4, 8], and the recent initiation of work on randomness <ref> [5] </ref>, we would like a more unified treatment enabling us to understand tradeoffs; for example: if you want to reduce the number of rounds, how much do you pay in coins? The so-called "speedup" problem, which we now discuss, captures this question in a crisp way. <p> It is convenient to restrict our attention to games in which l (n) log n. This does not reduce the generality of our results, since the following lemma of <ref> [5] </ref> says that any Arthur-Merlin game can transformed, without increasing the number of rounds, and without increasing the number of coins flipped by more than a constant factor, into one in which Arthur's messages are of length log n. Lemma 5.1 [5] Suppose we have an Arthur-Merlin proof system for L <p> generality of our results, since the following lemma of <ref> [5] </ref> says that any Arthur-Merlin game can transformed, without increasing the number of rounds, and without increasing the number of coins flipped by more than a constant factor, into one in which Arthur's messages are of length log n. Lemma 5.1 [5] Suppose we have an Arthur-Merlin proof system for L in which (some or all of) Arthur's messages are of length log n. <p> Given that a large factor of the cost is in error reduction, a tempting solution springs to mind. In <ref> [5] </ref>, a randomness-efficient error reduction method is presented. <p> Why not just use this? The reason this will not help is that the second step of the above speedup, namely switching MAM to AMA, has a cost which depends on the length of the messages from Merlin to Arthur in the M steps. The amplification method of <ref> [5] </ref>, while reducing Arthur's coin flips, increases the length of Merlin's messages, and if we were to use this the final cost in randomness of our speedup would actually end up being even worse than that of [4].
Reference: [6] <author> M. Bellare and J. Rompel. </author> <title> Randomness-efficient Sampling of Arbitrary Functions. </title> <address> MIT/LCS/TM-433.b, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: We are not aware of any other explicitly stated t-wise independent tail inequalities 6 prior to the appearance of the above lemmas in the preliminary versions of this work <ref> [6, 22] </ref>. Since then, however, other such inequalities have appeared [23].
Reference: [7] <author> B. Berger and J. Rompel. </author> <title> Simulating (log c n)-wise independence in NC. </title> <booktitle> Proceedings of the 30th Symposium on Foundations of Computer Science, IEEE, </booktitle> <year> 1989. </year>
Reference-contexts: Lemma A.5). The special case of Lemma 2.2 in which Pr [X i = 0] = Pr [X i = 1] = 1=2 for all i = 1; : : : ; n appeared in <ref> [7] </ref>. We are not aware of any other explicitly stated t-wise independent tail inequalities 6 prior to the appearance of the above lemmas in the preliminary versions of this work [6, 22]. Since then, however, other such inequalities have appeared [23].
Reference: [8] <author> R. Boppana, J. H -astad and S. Zachos. </author> <title> Does co-NP have Short Interactive Proofs? Info. </title> <journal> Processing Letters 25, </journal> <pages> 127-132, </pages> <year> 1987. </year>
Reference-contexts: AM denotes the class of languages possessing Arthur-Merlin proof systems. Clearly, Arthur-Merlin games are special kinds of interactive proof systems [15]. Their special properties make them very useful for proving structural results <ref> [1, 4, 8] </ref>, and on the other hand we lose none of the language recognition power: AM = IP = PSPACE [16, 19, 24]. <p> Research into the effect of varying the amount of interaction or randomness in an Arthur Merlin game arose out of the desire to understand, more quantitatively, the power of these resources as demonstrated by the AM = PSPACE result. Following many results on interaction <ref> [1, 3, 4, 8] </ref>, and the recent initiation of work on randomness [5], we would like a more unified treatment enabling us to understand tradeoffs; for example: if you want to reduce the number of rounds, how much do you pay in coins? The so-called "speedup" problem, which we now discuss,
Reference: [9] <author> R. Canetti, G. Even and O. Goldreich. </author> <title> Lower bounds for sampling algorithms for estimating the average. </title> <institution> TR-686, Computer Science Dept., Technion, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: Note that this number of sample points would be optimal, and, for constructions using this number of sample points, O (l + log ffi 1 ) coin tosses is optimal, both up to constant factors <ref> [9] </ref>. Prior work in approximation A comparison of universal approximators based on their complexity involves consideration of many parameters. We will stress whether or not the sampler is oblivious, the number of coins used, and the number m (n) of sample points used. <p> Ind. + Expanders No O (l + log ffi 1 ) m st This paper Iterated sampling Yes O (l + log ffi 1 log l) poly (* 1 ; log ffi 1 ; log l) logarithmic factor in coin tosses. up to constant factors <ref> [9] </ref>. But this sampler is not oblivious. The estimate is not the average of the function values on the sample points; rather, it is computed as follows.
Reference: [10] <author> L. Carter and M. Wegman. </author> <title> Universal Classes of Hash Functions. </title> <journal> J. Computer and System Sciences 18, </journal> <pages> 143-154, </pages> <year> 1979. </year>
Reference-contexts: For the rest of this section, H t (n; m) will denote a t-universal collection of hash functions mapping n bits to m bits in which the description of a function uses t max (n; m) bits (cf. <ref> [10] </ref>). 4.2 A Simple Oblivious Sampler Using t-universal hash functions we can construct a very simple (l; *; ffi)-oblivious sampler as follows.
Reference: [11] <author> B. Chor and O. Goldreich. </author> <title> On the Power of Two-Point Based Sampling. </title> <editor> J. </editor> <booktitle> of Complexity 5, </booktitle> <pages> 96-106, </pages> <year> 1989. </year>
Reference-contexts: The known results are discussed below and summarized in Figure 1, with ours in the last line for comparison. First, as already indicated, the sampler of the standard method is oblivious, but uses too many coins. Generating the sample points pairwise independently <ref> [11] </ref> yields a large savings in randomness and preserves obliviousness, but the number of sample points grows to poly (* 1 ; ffi 1 ; l). (Recall, we wanted poly (* 1 ; log ffi 1 ; l) sample points). <p> of approximating the average value of a function in the sense of (l; *; ffi)-approximation we are considering here. 3 Due to Method Oblivious? Coins Sample points (m) Standard Full independence Yes O (l * 2 log ffi 1 ) m st = O (e 2 log ffi 1 ) <ref> [11] </ref> Pairwise Independence Yes O (l) O (* 2 ffi 1 ) [13] Expanders Yes O (l + * 2 log ffi 1 ) m st [5] Pair.
Reference: [12] <author> A. Cohen and A. Wigderson. Dispersers, </author> <title> Deterministic Amplification, and Weak Random Sources. </title> <booktitle> Proceedings of the 30th Symposium on Foundations of Computer Science, IEEE, </booktitle> <year> 1989. </year>
Reference-contexts: The approximation method of [5] uses both pairwise independence and expanders. The sampler expends only 2l + O (log ffi 1 ) coins to generate m = O (* 2 log ffi 1 ) sample points, which is optimal 1 Gillman's analysis improves those of <ref> [2, 12, 18] </ref>.
Reference: [13] <author> D. Gillman. </author> <title> A Chernoff bound for random walks on expander graphs. </title> <booktitle> Proceedings of the 34th Symposium on Foundations of Computer Science, IEEE, </booktitle> <year> 1993. </year>
Reference-contexts: Generate the m (n) sample points by a m (n) step random walk on a constant degree expander graph with vertex set f0; 1g l (n) ; an application of Gillman's Chernoff bound for expanders <ref> [13] </ref> shows that this yields a universal oblivious sampler for m = (* 2 log ffi 1 ). 1 But now the randomness has grown, to l + O (m) = O (l + * 2 log ffi 1 ). <p> (l; *; ffi)-approximation we are considering here. 3 Due to Method Oblivious? Coins Sample points (m) Standard Full independence Yes O (l * 2 log ffi 1 ) m st = O (e 2 log ffi 1 ) [11] Pairwise Independence Yes O (l) O (* 2 ffi 1 ) <ref> [13] </ref> Expanders Yes O (l + * 2 log ffi 1 ) m st [5] Pair. <p> Acknowledgments We thank Oded Goldreich for pointing out that a randomness-efficient speedup theorem does not follow from the existence of a randomness-efficient error-reduction technique and suggesting that we look for a direct proof. We thank Nabil Kahale for drawing our attention to <ref> [13] </ref>. 14 In the course of this work, the first author was at MIT and later at the IBM T.J. Watson Research Center, New York. The second author was at MIT.
Reference: [14] <author> O. Goldreich and A. Wigderson. </author> <title> Tiny families of functions with random properties. </title> <booktitle> Proceedings of the 26th Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1994. </year>
Reference-contexts: Thus the reduction in randomness was at the cost of obliviousness. Goldreich and Wigderson <ref> [14] </ref> reduce the randomness from 2l + O (log ffi 1 ) to l + O (log ffi 1 ), but they use, in their final step, the method of [5], so that their sampler too is non-oblivious.
Reference: [15] <author> S. Goldwasser, S. Micali and C. Rackoff. </author> <title> The Knowledge Complexity of Interactive Proofs. </title> <journal> SIAM J. Computing 18(1), </journal> <pages> 186-208, </pages> <year> 1989. </year>
Reference-contexts: AM denotes the class of languages possessing Arthur-Merlin proof systems. Clearly, Arthur-Merlin games are special kinds of interactive proof systems <ref> [15] </ref>. Their special properties make them very useful for proving structural results [1, 4, 8], and on the other hand we lose none of the language recognition power: AM = IP = PSPACE [16, 19, 24].
Reference: [16] <author> S. Goldwasser and M. Sipser. </author> <title> Private Coins versus Public Coins in Interactive Proof Systems. </title> <booktitle> Proceedings of the 18th Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1986. </year> <month> 15 </month>
Reference-contexts: Clearly, Arthur-Merlin games are special kinds of interactive proof systems [15]. Their special properties make them very useful for proving structural results [1, 4, 8], and on the other hand we lose none of the language recognition power: AM = IP = PSPACE <ref> [16, 19, 24] </ref>. Arthur's message length is the number of (random) bits he sends in each of his moves, and we usually denote it by l = l (n), where n = jwj is the length of the common input.
Reference: [17] <author> W. Hoeffding. </author> <title> Probability inequalities for sums of bounded random variables. </title> <journal> J. of the American Statistical Association 58, </journal> <pages> 13-30, </pages> <year> 1963. </year>
Reference: [18] <author> R. Impagliazzo and D. Zuckerman. </author> <title> How to Recycle Random Bits. </title> <booktitle> Proceedings of the 30th Symposium on Foundations of Computer Science, IEEE, </booktitle> <year> 1989. </year>
Reference-contexts: The approximation method of [5] uses both pairwise independence and expanders. The sampler expends only 2l + O (log ffi 1 ) coins to generate m = O (* 2 log ffi 1 ) sample points, which is optimal 1 Gillman's analysis improves those of <ref> [2, 12, 18] </ref>.
Reference: [19] <author> C. Lund, L. Fortnow, H. Karloff and N. Nisan. </author> <title> Algebraic Methods for Interactive Proof Systems. </title> <journal> JACM 39(4), </journal> <pages> 859-868, </pages> <year> 1992. </year>
Reference-contexts: Clearly, Arthur-Merlin games are special kinds of interactive proof systems [15]. Their special properties make them very useful for proving structural results [1, 4, 8], and on the other hand we lose none of the language recognition power: AM = IP = PSPACE <ref> [16, 19, 24] </ref>. Arthur's message length is the number of (random) bits he sends in each of his moves, and we usually denote it by l = l (n), where n = jwj is the length of the common input.
Reference: [20] <author> N. Nisan. </author> <title> Pseudorandom Generators for Space Bounded Computation. </title> <booktitle> Proceedings of the 22nd Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1990. </year>
Reference-contexts: Zuckerman [25] has pointed out that an oblivious sampler can be derived from the space bounded generator of Nisan <ref> [20] </ref>. 2 The complexity is quite good, but the construction only works when the given parameters l; *; ffi are restricted to have certain relations to each other. <p> Then the construction uses O (log (m st ) (l + log ffi 1 )) coins and m st sample points. The idea is to define an FSM (cf. <ref> [20, Section 2.1] </ref>) which has space and block size O (log (m st =*) + l + log ffi 1 ) and which keeps track of the average value of f on the input sequence to within a precision of *=m st . <p> One then applies <ref> [20, Lemma 3] </ref>. 1.2 Randomness-efficient speedup An Arthur-Merlin game [3] is a two-party protocol. The players are an all-powerful, but, without loss of generality, deterministic, "prover," called Merlin, and a probabilistic, polynomial-time "verifier," called Arthur .
Reference: [21] <author> N. Nisan and D. Zuckermann. </author> <title> More deterministic simulation in Logspace. </title> <booktitle> Proceedings of the 25th Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1993. </year>
Reference-contexts: At the end of the game, he evaluates a polynomial-time predicate, applied to the common input and the full transcript of the interaction, 2 Later constructions of space bounded generators <ref> [21] </ref> don't seem to help to do better. 4 in order to decide whether to accept or reject.
Reference: [22] <author> J. Rompel. </author> <title> Techniques for computing with low independence randomness. </title> <type> Ph. D Thesis, </type> <institution> Dept. of Computer Science, MIT, </institution> <month> September </month> <year> 1990. </year>
Reference-contexts: We are not aware of any other explicitly stated t-wise independent tail inequalities 6 prior to the appearance of the above lemmas in the preliminary versions of this work <ref> [6, 22] </ref>. Since then, however, other such inequalities have appeared [23].
Reference: [23] <author> J. Schmidt, A. Siegel, A. Srinivasan. </author> <title> Chernoff-Hoeffding bounds for applications with limited independence. </title> <booktitle> Proceedings of the 4th Annual Symposium on Discrete Algorithms, ACM-SIAM, </booktitle> <year> 1993. </year>
Reference-contexts: We are not aware of any other explicitly stated t-wise independent tail inequalities 6 prior to the appearance of the above lemmas in the preliminary versions of this work [6, 22]. Since then, however, other such inequalities have appeared <ref> [23] </ref>.
Reference: [24] <author> A. Shamir. </author> <title> IP = PSPACE. </title> <journal> JACM 39(4), </journal> <pages> 869-877, </pages> <year> 1992. </year>
Reference-contexts: Clearly, Arthur-Merlin games are special kinds of interactive proof systems [15]. Their special properties make them very useful for proving structural results [1, 4, 8], and on the other hand we lose none of the language recognition power: AM = IP = PSPACE <ref> [16, 19, 24] </ref>. Arthur's message length is the number of (random) bits he sends in each of his moves, and we usually denote it by l = l (n), where n = jwj is the length of the common input.
Reference: [25] <author> D. Zuckerman. </author> <title> Private communication, </title> <month> September </month> <year> 1994. </year>
Reference-contexts: Goldreich and Wigderson [14] reduce the randomness from 2l + O (log ffi 1 ) to l + O (log ffi 1 ), but they use, in their final step, the method of [5], so that their sampler too is non-oblivious. Zuckerman <ref> [25] </ref> has pointed out that an oblivious sampler can be derived from the space bounded generator of Nisan [20]. 2 The complexity is quite good, but the construction only works when the given parameters l; *; ffi are restricted to have certain relations to each other.
References-found: 25

