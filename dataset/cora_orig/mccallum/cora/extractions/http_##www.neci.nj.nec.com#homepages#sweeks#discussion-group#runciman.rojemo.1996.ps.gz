URL: http://www.neci.nj.nec.com/homepages/sweeks/discussion-group/runciman.rojemo.1996.ps.gz
Refering-URL: http://www.neci.nj.nec.com/homepages/sweeks/discussion-group/index.html
Root-URL: http://www.neci.nj.nec.com
Email: (e-mail: fcolin,rojemog@cs.york.ac.uk)  
Title: New dimensions in heap profiling  the need to build a heap profiler for your own compiler.  
Author: COLIN RUNCIMAN and NIKLAS R OJEMO 
Address: Heslington, York, YO1 5DD, UK  
Affiliation: Department of Computer Science, University of York,  
Date: 6(4): 587-620, July 1996  
Note: J. Functional Programming  c 1996 Cambridge University Press 587  For all those who are interested in optimising the performance of functional programs, this is another paper (after (Runciman Wakeling, 1993a)) that should convince you of  
Abstract: First-generation heap profilers for lazy functional languages have proved to be effective tools for locating some kinds of space faults, but in other cases they cannot provide sufficient information to solve the problem. This paper describes the design, implementation and use of a new profiler that goes beyond the two-dimensional `who produces what' view of heap cells to provide information about their more dynamic and structural attributes. Specifically, the new profiler can distinguish between cells according to their eventual lifetime, or on the basis of the closure retainers by virtue of which they remain part of the live heap. A bootstrapping Haskell compiler (nhc) hosts the implementation: among examples of the profiler's use we include self-application to nhc. Another example is the original heap-profiling case study clausify, which now consumes even less memory and is much Capsule Review This paper extends the famous Runciman-Wakeling heap profiler by measuring the lifetime and the closure retainers of heap objects. This information is very expensive to measure accurately, so the authors design and implement some efficient heuristics to measure an approximation or a subset of the above information. Applying the new profiler to several functional programs yields many interesting observations and insights on how to write space-efficient functional programs (by the programmer) and how to generate space-efficient code (by the compiler). faster.
Abstract-found: 1
Intro-found: 1
Reference: <author> Clack, C., Clayman, S., & Parrott, D. </author> <year> (1995). </year> <title> Lexical profiling: </title> <journal> theory and practice. Journal of Functional Programming, </journal> <volume> 5(2), </volume> <pages> 225-277. </pages>
Reference-contexts: As we have seen in x5.1, retainer profiling points to the source of unicl's heavy workload, and a revision there leads to a more dramatic improvement. 618 C. Runciman and N. Rojemo Clack, Clayman and Parrott advocate lexical profiling <ref> (Clack et al., 1995) </ref>, which they claim reflects the programmer's view of a program, as opposed to the evaluator's or implementor's view supported by other profilers.
Reference: <author> Darlington, J. </author> <year> (1978). </year> <title> A synthesis of several sorting algorithms. </title> <journal> Acta Informatica, </journal> <volume> 11, </volume> <pages> 1-30. </pages>
Reference-contexts: This sort of program transformation is sometimes termed filter promotion <ref> (Darlington, 1978) </ref>. To implement the idea we define a normalising constructor dis to be used in place of Dis in the final disin' equation. To realise the full benefits we also need an extra Formula constructor Taut to represent a tautology.
Reference: <author> Hartel, P.H., & Veen, A.H. </author> <year> (1988). </year> <title> Statistics on graph reduction of SASL programs. </title> <journal> Software | Practice and Experience, </journal> <volume> 18(3), </volume> <pages> 239-253. </pages>
Reference-contexts: A more recent study with similar aims, but for the Standard ML of New Jersey system, is described in (Stefanovic & Moss, 1994). Hartel and Veen <ref> (Hartel & Veen, 1988) </ref> used an instrumented SASL interpreter to study the characteristics of intermediate combinator graphs during reduction. Their method too was to `analyse the graph at regular intervals'.
Reference: <author> Partain, W. </author> <year> (1993). </year> <title> The nofib benchmark suite of Haskell programs. Pages 195-202 of: Launchbury, </title> <editor> John, & Sansom, Patrick (eds), </editor> <booktitle> Proc. 1992 Glasgow Workshop on Functional Programming. </booktitle> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Compilation without lexical horns. 5.3 Examples from the `nofib' Benchmark Suite By applying nhc to some programs from the `nofib' Benchmark Suite <ref> (Partain, 1993) </ref>, we hoped to gain knowledge about `normal' lazy programs. Compilation succeeded for 42 of the 45 programs available x | not counting clausify. We were able to locate space faults in several of these programs.
Reference: <editor> Peyton Jones, S.L. </editor> <booktitle> (1987). The implementation of functional programming languages. </booktitle> <publisher> Prentice-Hall. </publisher>
Reference-contexts: Fancy algorithms that increase the memory requirements of the compiler itself are ruled out; nhc provides only what is essential in a G-machine implementation <ref> (Peyton Jones, 1987) </ref>. The source code for nhc is less than 11,000 lines of Haskell. To reduce run-time code size, nhc generates byte code instead of machine code.
Reference: <author> Ripley, G.D., Griswold, R.E., & Hanson, D.R. </author> <year> (1978). </year> <title> Performance of storage management in an implementation of SNOBOL4. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-4(2), </volume> <pages> 130-137. </pages>
Reference-contexts: An outline of that work was given in x1. Our attention has only recently been drawn to an implementation of memory profiling some years ago in a SNOBOL4 interpreter <ref> (Ripley et al., 1978) </ref>. This system labels allocated memory blocks with creation histories comprising a source line-number responsible for the allocation, an indication of the type of data stored (one of a small number of fixed categories) and a time of allocation.
Reference: <author> Runciman, C., & Wakeling, D. </author> <year> (1991). </year> <title> Problems and proposals for time and space profiling of functional programs. Pages 237-245 of: </title> <editor> Peyton Jones, S. L., Hutton, G., & Holst, C. K. (eds), </editor> <booktitle> Proc. 1990 Glasgow Workshop on Functional Programming. </booktitle> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Similarly, the postprocessor must build and transform an New dimensions in heap profiling 595 array for each separate construction. As this may involve a large amount of data, the efforts to devise an efficient transformation algorithm are well spent. 3 Retainer profiling An earlier paper <ref> (Runciman & Wakeling, 1991) </ref> argued in principle that programmers may need to know not only about the producers of heap cells, but also about consumers.
Reference: <author> Runciman, C., & Wakeling, D. </author> <year> (1993a). </year> <title> Heap profiling of lazy functional programs. </title> <journal> Journal of Functional Programming, </journal> <volume> 3(2), </volume> <pages> 217-245. </pages>
Reference-contexts: Although the basic idea of heap-profiling is simple, it has often proved effective. In many successful applications, iterative profiling and improvement has achieved substantial gains in efficiency. The original case-study was a propositional simplifier <ref> (Runciman & Wakeling, 1993a) </ref> for which the gains were better than two orders of magnitude. (This example application is revisited in x5.1.) With constructions aggregated by type, and producers by module or source file, heap-profiling has also been successfully applied to large and complex programs (Runciman & Wakeling, 1993b; Zhang et <p> Sharing traversal with garbage collection The garbage collector also has to traverse the heap, so a natural way to improve efficiency is to combine garbage collection with census taking <ref> (Runciman & Wakeling, 1993a) </ref>. If the implementor is concerned about space-efficiency the garbage collector may use pointer reversal to avoid the need for a large stack of ancestral cells (Schorr & Waite, 1967). <p> Several design choices in nhc help to reduce the amount of live data. For example, all three of the space faults attributed to compilation in <ref> (Runciman & Wakeling, 1993a) </ref> are avoided: Variables in a LHS pattern are updated simultaneously. When a variable in a left-hand pattern is used, all variables in the pattern are set to point to their parts of the expression, using a compilation scheme due to Jan Sparud (Sparud, 1993). <p> New dimensions in heap profiling 603 Table 1. Code size of nhc by level of profiling. level code size options available 0 893 kb none 1 1344 kb -k,-m,-p,-c For all but lifetime profiles, bands are ordered in the way described in <ref> (Runciman & Wakeling, 1993a) </ref>, with smoother bands below rougher ones. In lifetime profiles, bands for long-lived objects are placed lower than bands for short-lived ones. The result is similar to the `smoothness' ordering, as the populations of longer-lived cells tend to be more stable. <p> is informed, and has the option to force hp2graph to use all census data regardless of cost.) The maximum post-processing time needed for any example in this paper is 7 seconds; most examples need less than 2 seconds. 5 Example applications 5.1 Clausify revisited The original paper on heap profiling <ref> (Runciman & Wakeling, 1993a) </ref> includes as an extended example a program called clausify that puts logical formulae into clausal form. After several iterations of profiling and improvement, the 1.3 Mb required by Version 0 of the program for a benchmark computation is reduced to just 7 kb for Version 5. <p> As Figure 17 shows, this reformulation is very successful for the benchmark problem of <ref> (Runciman & Wakeling, 1993a) </ref>. The peak memory demand is reduced from 7 kb to 1 kb, and the time drops to a fraction of a second. Not only is the heap far smaller, the program runs much faster.
Reference: <author> Runciman, C., & Wakeling, D. </author> <year> (1993b). </year> <title> Heap profiling of a lazy functional compiler. Pages 203-214 of: Launchbury, </title> <editor> John, & Sansom, Patrick (eds), </editor> <booktitle> Proc. 1992 Glasgow Workshop on Functional Programming. </booktitle> <publisher> Springer-Verlag. </publisher> <address> 620 C. Runciman and N. Rojemo Rojemo, Niklas. </address> <year> 1995a </year> <month> (May). </month> <title> Garbage collection, and memory efficiency, in lazy functional languages. </title> <type> Ph.D. thesis, </type> <institution> Department of Computer Sciences, Chalmers University of Technology, S-412 96 Goteborg, Sweden. Rojemo, Niklas. </institution> <year> (1995b). </year> <title> Highlights from nhc: a space-efficient Haskell compiler. </title> <booktitle> Pages 282-292 of: Proc. 7th Intl. Conf. on Functional Programming Languages and Computer Architecture. </booktitle> <publisher> ACM Press. </publisher>
Reference: <author> Sansom, P.M. </author> <year> 1994 </year> <month> (September). </month> <title> Execution profiling for non-strict functional languages. </title> <type> Ph.D. thesis, </type> <institution> Department of Computing Science, University of Glasgow. </institution>
Reference-contexts: The technique for profiling space essentially follows Runciman and Wakeling, with cost centres as producers. Experiments with profiling based on the age of cells were abandoned because the profiles were found awkward to interpret, but a straightforward creation-time scheme remains (cf. x2). In his thesis <ref> (Sansom, 1994) </ref>, Sansom discusses the clausify example (cf. x5.1): a time profile reveals that unicl is doing the most work, sorting and sifting character literals; unboxing these characters yields a 25% speed-up.
Reference: <editor> Sansom, P.M., & Peyton Jones, S.L. </editor> <year> 1995 </year> <month> (January). </month> <title> Time and space profiling for non-strict higher-order functional languages. </title> <booktitle> Pages 355-366 of: Proc. ACM Conf. on Principles of Programming Languages (POPL'95). </booktitle>
Reference-contexts: Sansom and Peyton Jones describe a profiling scheme implemented in ghc, the optimising Haskell compiler developed at Glasgow <ref> (Sansom & Peyton Jones, 1995) </ref>. Their profiler attributes both space and time costs of a lazy functional program to `cost centres' assigned either implicitly (eg. by identifying a cost centre with each module) or by explicit scc (`set cost centre') expression formers.
Reference: <author> Schorr, H., & Waite, W. </author> <year> (1967). </year> <title> An efficient machine-independent procedure for garbage collection. </title> <journal> Communications of the ACM, </journal> <volume> 10(8), </volume> <pages> 501-506. </pages>
Reference-contexts: If the implementor is concerned about space-efficiency the garbage collector may use pointer reversal to avoid the need for a large stack of ancestral cells <ref> (Schorr & Waite, 1967) </ref>. But if pointers are reversed, it is not possible to re-traverse parts of the graph! The solution is to introduce a comparatively small stack of traversal requests.
Reference: <author> Sparud, </author> <month> Jan. </month> <year> (1993). </year> <title> Fixing some space leaks without a garbage collector. </title> <booktitle> Pages 117-122 of: Proc. 6th Int'l. Conf. on Functional Programming Languages and Computer Architecture (FPCA'93). </booktitle> <publisher> ACM Press. </publisher>
Reference-contexts: When a variable in a left-hand pattern is used, all variables in the pattern are set to point to their parts of the expression, using a compilation scheme due to Jan Sparud <ref> (Sparud, 1993) </ref>. This means that the node representing the right hand expression can be released as soon as the first variable in the pattern is used instead of waiting for the last one. No updates are done by copying.
Reference: <author> Stefanovic, Darko, & Moss, J. Eliot B. </author> <year> (1994). </year> <title> Characterisation of object behaviour in Standard ML of New Jersey. </title> <booktitle> Pages 43-54 of: Proc. ACM Conf. on Lisp and Functional Programming. </booktitle> <publisher> ACM Press. </publisher>
Reference-contexts: In their concluding remarks, they mention the potential value of a more sophisticated `spectral analysis' of memory, both at run-time and in subsequent post-processing. A more recent study with similar aims, but for the Standard ML of New Jersey system, is described in <ref> (Stefanovic & Moss, 1994) </ref>. Hartel and Veen (Hartel & Veen, 1988) used an instrumented SASL interpreter to study the characteristics of intermediate combinator graphs during reduction. Their method too was to `analyse the graph at regular intervals'.
Reference: <author> Wadler, P. </author> <year> (1990). </year> <title> Deforestation: transforming programs to eliminate trees. </title> <booktitle> Theoretical Computer Science, </booktitle> <pages> 231-248. </pages>
Reference-contexts: Identifying any sizable population of either very long-lived or very short-lived cells may help to improve programs. For example, short-lived cells may be intermediate structures to which deforestation <ref> (Wadler, 1990) </ref> is applicable; long-lived cells might represent large unevaluated closures that can be reduced to small results before they are actually needed. 2.1 Post-processing for lifetimes Let time in a profiled computation be measured as the number of heap censuses taken so far.
Reference: <author> Zhang, X., Webster, M.F., Sharp, J.A., & Grant, P.W. </author> <year> (1995). </year> <title> Chapter 9: Computational fluid dynamics. Pages 128-158 of: Runciman, </title> <editor> C., & Wakeling, D. (eds), </editor> <booktitle> Applications of functional programming. </booktitle> <publisher> UCL Press. </publisher>
References-found: 16

