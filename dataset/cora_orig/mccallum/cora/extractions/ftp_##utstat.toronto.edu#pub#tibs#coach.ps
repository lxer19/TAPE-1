URL: ftp://utstat.toronto.edu/pub/tibs/coach.ps
Refering-URL: http://utstat.toronto.edu:80/tibs/research.html
Root-URL: 
Title: "Coaching" variables for regression and classification  
Author: Robert Tibshirani and Geoffrey Hinton 
Keyword: regression, classification, missing data, mixtures of experts  
Note: c flUniversity of Toronto  
Date: September 26, 1995  
Address: Toronto, Ontario  
Affiliation: Department of Preventive Medicine and Biostatistics and Department of Statistics University of Toronto  Department of Computer Science University of Toronto  
Abstract: In a regression or classification setting where we wish to predict Y from x 1 ; x 2 ; . . . x p , we suppose that an additional set of "coaching" variables z 1 ; z 2 ; . . . z m are available in our training sample. These might be variables that are difficult to measure, and they will not be available when we predict Y from x 1 ; x 2 ; . . . x p in the future. We consider two methods of making use of the coaching variables in order to improve the prediction of Y from x 1 ; x 2 ; . . . x p . The relative merits of these approaches are discussed and compared in a number of examples. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Andrews, D. & Herzberg, A. </author> <year> (1985), </year> <title> Data, </title> <publisher> Springer-Verlag, </publisher> <address> Berlin. </address>
Reference: <author> Breiman, L. & Friedman, J. </author> <year> (1994), </year> <title> Multivariate multiple shrinkage, </title> <booktitle> Poster at Snowbird Neural Nets Conference. </booktitle>
Reference: <author> Breiman, L., Friedman, J., Olshen, R. & Stone, C. </author> <year> (1984), </year> <title> Classification and Regression Trees, </title> <publisher> Wadsworth. </publisher>
Reference: <author> Cleveland, W., Grosse, E., Shyu, W. & Terpenning, I. </author> <year> (1991), </year> <title> Local regression models, </title> <editor> in J. Chambers & T. Hastie, eds, </editor> <title> `Statistical models in S', Wadsworth. 14 Hastie, </title> <editor> T. & Tibshirani, R. </editor> <year> (1993), </year> <title> `Varying coefficient models (with discus-sion)', </title> <journal> J. Royal. Statist. Soc. </journal> <volume> B 55, </volume> <pages> 757-796. </pages>
Reference: <author> Hosmer, D. & Dick, N. </author> <year> (1974), </year> <title> `Information and mixtures of two normal distributions', </title> <journal> J. Statist. Comput. </journal> <volume> Simul. </volume> <pages> pp. 995-1006. </pages>
Reference: <author> Jacobs, R., Jordan, M., Nowlan, S. & Hinton, G. </author> <year> (1991), </year> <title> `Adaptive mixtures of local experts', </title> <booktitle> Neural computation 3, </booktitle> <pages> 79-87. </pages>
Reference: <author> Jordan, M. & Jacobs, R. </author> <year> (1994), </year> <title> `Hierachical mixtures of experts and the em algorithm', </title> <booktitle> Neural computation 6, </booktitle> <pages> 181-214. </pages>
Reference: <author> Nowlan, S. </author> <year> (1991), </year> <title> Soft competition and adaptation, </title> <type> Technical report, PhD. thesis, </type> <institution> Comp. Sci., Carnegie Mellon University. </institution> <month> 15 </month>
References-found: 8

