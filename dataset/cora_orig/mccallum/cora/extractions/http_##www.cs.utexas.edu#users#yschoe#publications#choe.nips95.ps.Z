URL: http://www.cs.utexas.edu/users/yschoe/publications/choe.nips95.ps.Z
Refering-URL: http://www.cs.cmu.edu/Web/Groups/NIPS/NIPS95/Papers.html
Root-URL: 
Email: yschoe,sirosh,risto@cs.utexas.edu  
Title: Laterally Interconnected Self-Organizing Maps in Hand-Written Digit Recognition  
Author: Yoonsuck Choe, Joseph Sirosh, and Risto Miikkulainen 
Address: Austin, TX 78712  
Affiliation: Department of Computer Sciences The University of Texas at Austin  
Abstract: An application of laterally interconnected self-organizing maps (LISSOM) to handwritten digit recognition is presented. The lateral connections learn the correlations of activity between units on the map. The resulting excitatory connections focus the activity into local patches and the inhibitory connections decorrelate redundant activity on the map. The map thus forms internal representations that are easy to recognize with e.g. a perceptron network. The recognition rate on a subset of NIST database 3 is 4.0% higher with LISSOM than with a regular Self-Organizing Map (SOM) as the front end, and 15.8% higher than recognition of raw input bitmaps directly. These results form a promising starting point for building pattern recognition systems with a LISSOM map as a front end.
Abstract-found: 1
Intro-found: 1
Reference: <author> Denker, J. S., Gardner, W. R., Graf, H. P., Henderson, D., Howard, R. E., Hubbard, W., Jackel, L. D., Baird, H. S., and Guyon, I. </author> <year> (1989). </year> <title> Neural network recognizer for hand-written zip code digits. </title> <editor> In Touretzky, D. S., editor, </editor> <booktitle> Advances in Neural Information Processing Systems 1. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Fukushima, K., and Wake, N. </author> <year> (1990). </year> <title> Alphanumeric character recognition by neocognitron. </title> <booktitle> In Advanced Neural Computers, </booktitle> <pages> 263-270. </pages> <publisher> Elsevier Science Publishers B.V. (North-Holland). </publisher> <editor> le Cun, Y., Boser, B., Denker, J. S., Henderson, D., Howard, R. E., Hubbard, W., and Jackel, L. D. </editor> <year> (1990). </year> <title> Handwritten digit recognition with a backpropagation network. </title> <editor> In Touretzky, D. S., editor, </editor> <booktitle> Advances in Neural Information Processing Systems 2. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Diverse architectures with varying learning rules have been proposed, including feed-forward networks (Denker et al. 1989; le Cun et al. 1990; Martin and Pittman 1990), self-organizing maps (Allinson et al. 1994), and dedicated approaches such as the neocognitron <ref> (Fukushima and Wake 1990) </ref>. The problem is difficult because handwriting varies a lot, some digits are easily confusable, and recognition must be based on small but crucial differences.
Reference: <author> Martin, G. L., and Pittman, J. A. </author> <year> (1990). </year> <title> Recognizing hand-printed letters and digits. </title> <editor> In Touretzky, D. S., editor, </editor> <booktitle> Advances in Neural Information Processing Systems 2. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Sirosh, J., and Miikkulainen, R. </author> <year> (1994). </year> <title> Cooperative self-organization of afferent and lateral connections in cortical maps. </title> <journal> Biological Cybernetics, </journal> <volume> 71 </volume> <pages> 66-78. </pages>
Reference-contexts: The units in the excitatory region also have inhibitory lateral connections (indicated by medium shading) to the center unit. The excitatory radius is 1 and the inhibitory radius 3 in this case. vector remains the same; lateral weights are normalized to keep the sum of weights constant <ref> (Sirosh and Miikkulainen 1994) </ref>: ij;mn (t + 1) = p P ; (3) ! ij;kl (t) + ff ij kl P ; (4) where ij;mn is the afferent weight from input unit (m; n) to map unit (i; j), and ff inp is the input learning rate; ! ij;kl is the <p> The differences in each set are statistically significant with p &gt; :9999. 3 Experiments A subset of 2992 patterns from the NIST Database 3 was used as training and testing data. 1 The patterns were normalized to make sure taht each example had an equal effect on the LISSOM map <ref> (Sirosh and Miikkulainen 1994) </ref>. LISSOM was trained with 2000 patterns. Of these, 1700 were used to train the perceptron layer, and the remaining 300 were used as the validation set to determine when to stop training the perceptrons. <p> However, if the input dimensionality is large, as it is in case of the 32 fi 32 bitmaps, each unit on the map is activated roughly to the same degree, and it is difficult to bootstrap the self-organizing process <ref> (Sirosh and Miikkulainen 1994, 1996) </ref>. The standard Self-Organizing Map algorithm can be used to preorganize the map in this case. The SOM performs preliminary feature analysis of the input, and forms a coarse topological map of the input space.
Reference: <author> Sirosh, J., and Miikkulainen, R. </author> <year> (1995). </year> <title> Ocular dominance and patterned lateral connections in a self-organizing model of the primary visual cortex. </title> <editor> In Tesauro, G., Touretzky, D. S., and Leen, T. K., editors, </editor> <booktitle> Advances in Neural Information Processing Systems 7. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Sirosh, J., and Miikkulainen, R. </author> <year> (1996). </year> <title> Topographic receptive fields and patterned lateral interaction in a self-organizing model of the primary visual cortex. </title> <note> Neural Computation (in press). </note>
References-found: 6

