URL: ftp://ftp.cs.wisc.edu/sohi/papers/1996/isca.hbat.ps.gz
Refering-URL: http://www.cs.wisc.edu/~sohi/sohi.html
Root-URL: 
Email: faustin,sohig@cs.wisc.edu  
Title: High-Bandwidth Address Translation for Multiple-Issue Processors  
Author: Todd M. Austin Gurindar S. Sohi 
Address: 1210 W. Dayton Street Madison, WI 53706  
Affiliation: Computer Sciences Department University of Wisconsin-Madison  
Abstract: In an effort to push the envelope of system performance, microprocessor designs are continually exploiting higher levels of instruction-level parallelism, resulting in increasing bandwidth demands on the address translation mechanism. Most current microprocessor designs meet this demand with a multi-ported TLB. While this design provides an excellent hit rate at each port, its access latency and area grow very quickly as the number of ports is increased. As bandwidth demands continue to increase, multi-ported designs will soon impact memory access latency. We present four high-bandwidth address translation mechanisms with latency and area characteristics that scale better than a multi-ported TLB design. We extend traditional high-bandwidth memory design techniques to address translation, developing interleaved and multi-level TLB designs. In addition, we introduce two new designs crafted specifically for high-bandwidth address translation. Piggyback ports are introduced as a technique to exploit spatial locality in simultaneous translation requests, allowing accesses to the same virtual memory page to combine their requests at the TLB access port. Pretranslation is introduced as a technique for attaching translations to base register values, making it possible to reuse a single translation many times. We perform extensive simulation-based studies to evaluate our designs. We vary key system parameters, such as processor model, page size, and number of architected registers, to see what effects these changes have on the relative merits of each approach. A number of designs show particular promise. Multi-level TLBs with as few as eight entries in the upper-level TLB nearly achieve the performance of a TLB with unlimited bandwidth. Piggyback ports combined with a lesser-ported TLB structure, e.g., an interleaved or multi-ported TLB, also perform well. Pretranslation over a single-ported TLB performs almost as well as a same-sized multi-level TLB with the added benefit of decreased access latency for physically indexed caches. 
Abstract-found: 1
Intro-found: 1
Reference: [BF92] <author> B. K. Bray and M. J. Flynn. </author> <title> Translation hint buffers to reduce access time of physically-addressed instruction caches. </title> <booktitle> Proc. of the 25th Annual International Symposium on Microarchitec-ture, </booktitle> <volume> 23(1) </volume> <pages> 206-209, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: On either of these events, the previous translation is invalidated and another address translation of the PC is initiated. Bray's translation hit buffer (THB) <ref> [BF92] </ref> further extends this idea to include a prediction of the fragment in which pointer p strides through an array. Figure b) illustrates the operations that occur over the lifetime of pointer p. next translation as well.
Reference: [BHIL94] <author> J. Borkenhagen, G. Handlogten, J. Irish, and S. Levenstein. </author> <title> AS/400 64-bit PowerPC-compatible processor implementation. </title> <booktitle> ICCD, </booktitle> <year> 1994. </year>
Reference-contexts: Already, some processor designs have turned to alternative TLB organizations with better latency and bandwidth characteristics; for example, Hal's SPARC64 [Gwe95] and IBM's AS/400 64-bit PowerPC <ref> [BHIL94] </ref> processor both implement multi-level TLBs. Our goal in this paper is to extend the work on high-bandwidth address translation in two ways. <p> At least two commercial processors have explored the use of multi-level TLBs; Hal's SPARC64 [Gwe95] and IBM's AS/400 64-bit PowerPC <ref> [BHIL94] </ref> processors both implement multi-level TLBs to meet the latency and bandwidth needs of their respective designs. Multi-level TLB designs have long been used for reducing the latency of instruction fetch translations [CBJ92]. 3.4 Piggyback Ports Piggyback ports, shown in Figure 3a, exploit spatial locality in simultaneous address translation requests.
Reference: [BRG + 89] <author> D. Black, R. Rashid, D. Golub, C. Hill, and R. Baron. </author> <title> Translation lookaside buffer consistency: A software approach. </title> <booktitle> Proc. of the 3rd International Conference on Architectural Support for Programming Languages Operating Systems, </booktitle> <pages> pages 113-122, </pages> <year> 1989. </year>
Reference-contexts: If the processor supports hardware-based TLB consistency opera tions <ref> [BRG + 89] </ref>, multi-level inclusion should be enforced in the L1 TLB during L2 TLB replacements or invalidations, i.e., the entries in the L1 TLB should be a subset of the entries in the L2 TLB.
Reference: [CBJ92] <author> J. B. Chen, A. Borg, and N. P. Jouppi. </author> <title> A simulation based study of TLB performance. </title> <booktitle> Proc. of the 19th Annual International Symposium on Computer Architecture, </booktitle> <volume> 19(2) </volume> <pages> 114-123, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Instruction fetch translation is well served by a single-ported instruction TLB or by a small micro-TLB implemented over a unified instruction and data TLB <ref> [CBJ92] </ref>. The rest of this paper is organized as follows: Section 2 describes our framework for address translation and qualitatively explores the impact that address translation latency and bandwidth have on system performance. <p> Multi-level TLB designs have long been used for reducing the latency of instruction fetch translations <ref> [CBJ92] </ref>. 3.4 Piggyback Ports Piggyback ports, shown in Figure 3a, exploit spatial locality in simultaneous address translation requests. When simultaneous requests arrive at a TLB port, requests with identical virtual page addresses may be satisfied by the same TLB access.
Reference: [CCH + 87] <author> F. Chow, S. Correll, M. Himelstein, E. Killian, and L. Weber. </author> <title> How many addressing modes are enough. </title> <booktitle> Proc. of the 2nd International Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 117-121, </pages> <month> Oc-tober </month> <year> 1987. </year>
Reference-contexts: Figure 4 illustrates the basis for this approach. Loads and stores access memory through register pointers: global accesses through the global pointer <ref> [CCH + 87] </ref>, stack accesses through the stack pointer, and all other references through general purpose register pointers. Pointers are created whenever a variable is referenced, its address is taken, or when dynamic storage is allocated.
Reference: [Che87] <author> R. Cheng. </author> <title> Virtual address caches in UNIX. </title> <booktitle> Proc. of the Summer 1987 USENIX Technical Conference, </booktitle> <pages> pages 217-224, </pages> <year> 1987. </year>
Reference-contexts: In a multiprocessing environment, cache coherence operations must first be reverse-translated to remote virtual addresses before remote data can be located in the remote cache. Many solutions have been devised to eliminate synonyms, including alignment restrictions on shared data <ref> [Che87] </ref>, selective invalidation [WBL89], and single address space operating systems [KCE92]. However, these approaches have yet to come into widespread use due to per formance and/or implementation impacts on application and system software.
Reference: [CK92] <author> T. Chiueh and R. H. Katz. </author> <title> Eliminating the address translation bottleneck for physical address cache. </title> <booktitle> Proc. of the 5th International Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <volume> 27(9) </volume> <pages> 137-148, </pages> <month> Oc-tober </month> <year> 1992. </year>
Reference-contexts: Figure b) illustrates the operations that occur over the lifetime of pointer p. next translation as well. Pretranslation can be viewed as an extension of Chiueh and Katz's branch address cache (BAC) <ref> [CK92] </ref>, which was applied as a mechanism to reduce access latency of physically indexed caches. (A similar mechanism was proposed in [HHL + 90].) Our design extends the BAC technique to provide high-bandwidth translation.
Reference: [CMMP95] <author> T. Conte, K. Menezes, P. Mills, and B. Patel. </author> <title> Optimization of instruction fetch mechanisms for high issue rates. </title> <booktitle> Proc. of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <volume> 23(2) </volume> <pages> 333-344, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: The data cache modeled is a four-ported 32k two-way set-associative non-blocking cache. We found early on that instruction fetch bandwidth was a critical performance bottleneck. To mitigate this problem, we implemented a limited variant of the collapsing buffer described in <ref> [CMMP95] </ref>. Our implementation supports two predictions per cycle within the same instruction cache block, which provides significantly more instruction fetch bandwidth and better pipeline resource utilization. A number of changes were made to the simulator to support our high-bandwidth address translation mechanisms.
Reference: [EV93] <author> R. J. Eickemeyer and S. Vassiliadis. </author> <title> A load-instruction unit for pipelined processors. </title> <journal> IBM J. Res. Develop., </journal> <volume> 37(4) </volume> <pages> 547-564, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: During the lifetime of a pointer, it is dereferenced at loads and stores, and manipulated using integer arithmetic. Over the lifetime of the pointer, it may be dereferenced and manipulated many times. Studies have shown, e.g. <ref> [EV93] </ref>, that when pointers are manipulated, it is often the case that small constant values are added to or subtracted from the pointer. The end result, which we exploit in this design, is that translations between successive uses of a pointer often yield accesses to the same virtual memory page.
Reference: [Gwe95] <author> L. Gwennap. </author> <title> Hal reveals multichip SPARC processor. </title> <type> Microprocessor Report, 9(3) </type> <pages> 1-11, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: While this design meets the latency and bandwidth requirements of many current designs, continued demands may soon render it impractical, forcing tomorrow's designs to find alternative translation mechanisms. Already, some processor designs have turned to alternative TLB organizations with better latency and bandwidth characteristics; for example, Hal's SPARC64 <ref> [Gwe95] </ref> and IBM's AS/400 64-bit PowerPC [BHIL94] processor both implement multi-level TLBs. Our goal in this paper is to extend the work on high-bandwidth address translation in two ways. <p> The additional area overhead of this design is concentrated in the implementation of the L1 TLB, which for small sizes and few ports should be much smaller than the L2 TLB. At least two commercial processors have explored the use of multi-level TLBs; Hal's SPARC64 <ref> [Gwe95] </ref> and IBM's AS/400 64-bit PowerPC [BHIL94] processors both implement multi-level TLBs to meet the latency and bandwidth needs of their respective designs.
Reference: [Hea86] <author> M. Hill and et al. </author> <title> Design decisions in SPUR. </title> <journal> IEEE Computer, </journal> 19(11) 8-22, November 1986. 
Reference-contexts: As a result, their implementation has been naturally integrated into the TLB. If the TLB is eliminated through use of a virtual address cache, the problem of implementing protection still remains. One solution is to integrate protection information into cache blocks <ref> [Hea86] </ref>. However, the page-granularity of protection information makes managing these fields both complicated and expensive. Another solution is to implement a TLB minus the physical page address information [KCE92] this TLB-like structure, however, still requires high-bandwidth and low-latency access (although, latency requirements are somewhat relaxed).
Reference: [HHL + 90] <author> K. Hua, A. Hunt, L. Liu, J-K. Peir, D. Pruett, and J. </author> <title> Temple. Early resolution of address translation in cache design. </title> <booktitle> Proc. of the 1990 IEEE International Conference on Computer Design, </booktitle> <pages> pages 408-412, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Pretranslation can be viewed as an extension of Chiueh and Katz's branch address cache (BAC) [CK92], which was applied as a mechanism to reduce access latency of physically indexed caches. (A similar mechanism was proposed in <ref> [HHL + 90] </ref>.) Our design extends the BAC technique to provide high-bandwidth translation. By attaching the virtual page address to a register value, the base TLB mechanism does not have to be accessed to validate use of an attached physical page address.
Reference: [HP90] <author> J. L. Hennessy and D. A. Patterson. </author> <booktitle> Computer Architecture: </booktitle>
Reference-contexts: 1 Introduction Address translation is a vital mechanism in modern computer systems. The process provides the operating system with the mapping and protection mechanisms necessary to manage multiple large and private address spaces in a single, limited size physical memory <ref> [HP90] </ref>. In practice, most microprocessors implement low-latency address translation with a translation lookaside buffer (TLB).
References-found: 13

