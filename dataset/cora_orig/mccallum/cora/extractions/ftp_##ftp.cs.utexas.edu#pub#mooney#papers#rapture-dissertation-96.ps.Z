URL: ftp://ftp.cs.utexas.edu/pub/mooney/papers/rapture-dissertation-96.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/ml/theory-rev.html
Root-URL: http://www.cs.utexas.edu
Title: Combining Symbolic and Connectionist Learning Methods to Refine Certainty-Factor Rule-Bases  
Author: by J. Jeffrey Mahoney, MS, MM, BA 
Degree: Dissertation Presented to the Faculty of the Graduate School of  in Partial Fulfillment of the Requirements for the Degree of Doctor of Philosophy  
Date: May, 1996  
Address: Austin  Austin  
Affiliation: The University of Texas at  The University of Texas at  
Abstract-found: 0
Intro-found: 1
Reference: <author> Alberts, B. </author> <year> (1988). </year> <title> Mapping and Sequencing the Human Genome. </title> <publisher> National Academy Press, </publisher> <address> Washington, D.C. </address>
Reference-contexts: a clear demonstration of the value of the domain knowledge, as these simpler rule bases result in worse performance. 42 43 44 45 4.5.2 The 468-example Promoter Data Set This data set is a more extensive set of examples of Promoters and non-Promoters that comes from the Human Genome Project <ref> (Alberts, 1988) </ref>. Once again, the examples are an even mix of 234 Promoters and 234 non-Promoters, though the key difference in these examples is the presence of missing features. Approximately 15% of the examples have missing values for one or more of the features.
Reference: <author> Baffes, P., & Mooney, R. J. </author> <year> (1992). </year> <title> Using theory revision to model students and acquire stereotypical errors. </title> <booktitle> In Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. 617-622 Bloomington, </pages> <note> IN. </note>
Reference: <author> Baffes, P., & Mooney, R. </author> <year> (1993a). </year> <title> Symbolic revision of theories with M-of-N rules. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 1135-1140 Chambery, France. </address>
Reference: <author> Baffes, P. T., & Mooney, R. J. </author> <year> (1993b). </year> <title> Extending theory refinement to M-of-N rules. </title> <journal> Informatica, </journal> <volume> 17, </volume> <pages> 387-397. </pages>
Reference-contexts: This generalizes the rule base. Similarly, by raising the value of M, more antecedent conditions must be satisfied, making it more difficult for rules to become active. These properties gives Neither the ability to perform better in domains such as Promoter that benefit from partial matching <ref> (Baffes & Mooney, 1993b) </ref>. 2.5.3 KBANN As previously mentioned, Kbann (Towell & Shavlik, 1994) is a refinement system which translates a rule base into a neural network and then refines it using backpropagation. The translation into a neural network proceeds in a straightforward manner.
Reference: <author> Berenji, H. </author> <year> (1990). </year> <title> Refinement of approximate reasoning-based controllers by reinforcement learning. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pp. </pages> <address> 475-479 Evanston, IL. </address>
Reference-contexts: In addition, techniques for inducing Bayesian networks from data (Connolly, 1993; Cooper & Herskovits, 1992) could potentially be used to refine the underlying causal structure as well. Finally, there has also been some recent work on combining symbolic and neural-network methods to revise fuzzy-logic controllers <ref> (Berenji, 1990) </ref>. 76 Chapter 7 Conclusions Automatic refinement of uncertain rule-bases is an under-studied problem with important applications to the development of intelligent systems. This dissertation has described and evaluated an approach to refining certainty-factor rule bases that integrates connectionist and symbolic learning.
Reference: <editor> Buchanan, G., & Shortliffe, E. (Eds.). </editor> <year> (1984). </year> <title> Rule-Based Expert Systems:The MYCIN Experiments of the Stanford Heuristic Programming Project. </title> <publisher> Addison-Wesley Publishing Co., </publisher> <address> Reading, MA. </address>
Reference-contexts: The ability to precisely specify necessary problem-solving expertise, and put it "in a bottle" would be of significant value (both economic and social) to everyone. This desire has led to a great deal of research into developing expert systems <ref> (Buchanan & Shortliffe, 1984) </ref>, which are simply automated systems that aid, enhance, or replace the human expert. The use of expert systems has had a significant impact upon everyday society for a number of years, and is helping many corporations achieve higher profits and productivity (Feigenbaum, McCorduck, & Nii, 1988). <p> This system combines both symbolic and neural learning methods. Rapture begins by converting a symbolic rule-base into a connectionist network. Rapture requires that rules be initially expressed using certainty factors <ref> (Buchanan & Shortliffe, 1984) </ref>. Literals in the rules map to units in the network, and the certainty factors become the weights on the connections between units. <p> In particular, we present results for revising rule bases for recognizing promoter sequences in strands of DNA (Towell et al., 1990), identifying splice-junction sites in DNA (Towell & Shav-lik, 1994), diagnosing diseased soybeans (Michalski & Chilausky, 1980), and diagnosing bacterial infections in humans <ref> (Buchanan & Shortliffe, 1984) </ref>. This last domain is based on a version of the Mycin knowledge-base, which Rapture has successfully revised. <p> Certainty-factors grew out of Mycin|an expert system for diagnosing infectious diseases, which was a part of the Stanford Heuristic Programming Project <ref> (Buchanan & Shortliffe, 1984) </ref>. All Mycin rules are of the form A 0:8 ! D, indicating that belief in proposition A gives additional reason for believing in proposition D. <p> In other words, any evidence for believing in a proposition automatically provides evidence for disbelieving it. Domain experts agree that this is not the intent of such rules 10 <ref> (Buchanan & Shortliffe, 1984) </ref>. For certainty factors, evidence supporting a proposition has no direct bearing upon belief in its negation. Measures of belief and disbelief are calculated separately and combined to determine overall certainty factor as described above. <p> This permits only the minimum value from among all inputs to propagate up the network. This is in agreement with the certainty-factor combining rules <ref> (Buchanan & Shortliffe, 1984) </ref>. Note that each of the conjuncts is connected to the corresponding MIN mode with a solid line. This represents the fact that the link is non-adjustable, and simply passes its full activation value onto the MIN node.
Reference: <author> Buntine, W. </author> <year> (1991). </year> <title> Theory refinement on Bayesian networks. </title> <booktitle> In Proceedings of the Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pp. 52-60. </pages>
Reference: <author> Cain, T. </author> <year> (1991). </year> <title> The DUCTOR: A theory revision system for propositional domains. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pp. </pages> <address> 485-489 Evanston, IL. </address>
Reference: <author> Caruana, R. </author> <year> (1989). </year> <title> The automatic training of rule bases that use numerical uncertainty representations. </title> <booktitle> In Proceedings of the Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pp. 347-356. </pages>
Reference: <author> Clark, K. </author> <year> (1978). </year> <title> Negation as failure. </title> <editor> In Gallaire, H., & Minker, J. (Eds.), </editor> <booktitle> Logic and Data Bases. </booktitle> <publisher> Plenum Press, </publisher> <address> New York, NY. </address>
Reference-contexts: Remembering that negative certainty factors never propagate forward (see Chapter 2), this is the smallest value that can usefully be assigned. A literal with certainty factor 0:0 gives its negation a value of 1:0. This is in accordance with the methodology of negation as failure <ref> (Clark, 1978) </ref>. 19 This was adopted for strictly intuitive reasons. If an expert is checking for a certain characteristic, she may have several tests (rules) that check for this. If each test fails, she is likely to be inclined to conclude that the particular characteristic is absent.
Reference: <author> Cohen, W. </author> <year> (1992). </year> <title> Compiling prior knowledge into an explicit bias. </title> <booktitle> In Proceedings of the Ninth International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 102-110 Aberdeen, Scotland. </address>
Reference: <author> Connolly, D. </author> <year> (1993). </year> <title> Constructing hidden variables in bayesian networks via conceptual clustering. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 65-72 Amherst, MA. </address>
Reference: <author> Cooper, G. </author> <year> (1990). </year> <title> Computational complexity of probabilistic inference using Bayesian belief networks (research note). </title> <journal> Artificial Intelligence, </journal> <volume> 42, </volume> <pages> 393-405. </pages>
Reference-contexts: Second, probabilistic sum is a simple, differentiable, non-linear function. This is crucial for implementing gradient descent using backpropagation. Further, other formalisms for uncertain reasoning (e.g. Bayesian networks) have been shown to be NP-hard to evaluate in the general case <ref> (Cooper, 1990) </ref>, and require the specification of exponentially many conditional probabilities in the fan-in of a node (Schwalb, 1993). Even more significantly, however, is the widespread use of certainty factors.
Reference: <author> Cooper, G. G., & Herskovits, E. </author> <year> (1992). </year> <title> A Bayesian method for the induction of probabilistic networks from data. </title> <journal> Machine Learning, </journal> <volume> 9, </volume> <pages> 309-347. </pages>
Reference: <author> Davis, L. </author> <year> (1995). </year> <title> Genetic algorithms and trading. </title> <booktitle> In Proceedings of the Sixth Annual Conference on Advanced Technologies for Trading and Asset Management, </booktitle> <pages> pp. </pages> <address> 79-88 New York, New York. </address>
Reference-contexts: It took them slightly more than two years to complete the task, and they admitted that the resulting rules were still not perfect, though they were able to correctly classified returns over 90% of the time <ref> (Davis, 1995) </ref>. Out of an attempt to alleviate this bottleneck, researchers (Ginsberg, 1988; Mooney & Ourston, 1991; Towell, Shavlik, & Noordewier, 1990; Pazzani & Kibler, 1992) have sought ways of automating the process of fine-tuning a rule base.
Reference: <author> DeJong, G. F., & Mooney, R. J. </author> <year> (1986). </year> <title> Explanation-based learning: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1 (2), </volume> <pages> 145-176. </pages> <note> Reprinted in Readings in Machine Learning, </note> <editor> J. W. Shavlik and T. </editor> <publisher> G. </publisher>
Reference: <editor> Dietterich (eds.), </editor> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference: <author> Fahlman, S., & Lebiere, C. </author> <year> (1989). </year> <booktitle> The cascade-correlation learning architecture. In Advances in Neural Information Processing Systems, </booktitle> <volume> Vol. 2, </volume> <pages> pp. </pages> <address> 524-532 San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Fu does, however, present data on a rule base which is initially 100% accurate, and then corrupted by adding contradictory rules. There have been a number of methods for building a connectionist networks from scratch that are able to correctly classify a set of training examples, e.g. Cascade Correlation <ref> (Fahlman & Lebiere, 1989) </ref>, the Upstart algorithm (Frean, 1990), and the Tiling algorithm (Mezard & Nadal, 1989). Rapture makes use of one of these (Upstart) in creating new hidden units in existing networks, and also uses methods from decision-tree induction (Quinlan, 1986) to add observable units.
Reference: <author> Feigenbaum, E., Buchanan, B., & Lederberg, J. </author> <year> (1971). </year> <title> On generality and problem solving: A case study involving the dendral program. </title> <journal> Machine Intelligence, </journal> <volume> 6, </volume> <pages> 165-190. </pages>
Reference-contexts: The first of these is the Mycin system (Shortliffe, 1976; Buchanan & Shortliffe, 1984), which was designed to provide consultative advice for diagnosing and treating infectious diseases. Developed as part of the Stanford Heuristic Programming project, it was heavily influenced by earlier expert systems, most notably dendral <ref> (Feigenbaum, Buchanan, & Lederberg, 1971) </ref>. dendral was a system for determining molecular structures of complex organic chemicals from mass spec-trograms. This was the first AI program that put more emphasis on domain-specific knowledge than on general problem-solving methods, which became a large part of Mycin.
Reference: <author> Feigenbaum, E., & McCorduck, P. </author> <year> (1983). </year> <booktitle> The Fifth Generation: Artificial Intelligence and Japan's Computer Challenge to the World. </booktitle> <publisher> Addison-Wesley Publishing Co., </publisher> <address> Reading, MA. </address>
Reference-contexts: This is no reflection on the expert, but rather on the difficulty of the rule-base construction problem. This difficulty has become prevalent enough to have been named the knowledge-acquisition bottleneck <ref> (Feigenbaum & McCorduck, 1983) </ref>. This name refers to the fact that the bottleneck in creating an effective expert-system lies in the acquisition and specification of the knowledge. 1.1 The Knowledge-Acquisition Bottleneck A real-world example of this bottleneck comes from the IRS.
Reference: <author> Feigenbaum, E., McCorduck, P., & Nii, H. </author> <year> (1988). </year> <title> The Rise of the Expert Company. </title> <publisher> Times BooksAcademic Press, </publisher> <address> New York, NY. </address>
Reference-contexts: The use of expert systems has had a significant impact upon everyday society for a number of years, and is helping many corporations achieve higher profits and productivity <ref> (Feigenbaum, McCorduck, & Nii, 1988) </ref>. The major difficulty in creating such systems, however, is in properly extracting the necessary information from the expert. Not only is it difficult for experts to translate their reasoning abilities into concrete sets of rules, but once done, the result is usually inaccurate and inconsistent.
Reference: <author> Frank-Kamenetskii, M. </author> <year> (1993). </year> <title> Unraveling DNA. </title> <publisher> VCH Publishers, Inc., </publisher> <address> New York, N.Y. </address>
Reference: <author> Frean, M. </author> <year> (1990). </year> <title> The Upstart algorithm: A method for constructing and training feedforward neural networks. </title> <journal> Neural Computation, </journal> <volume> 2, </volume> <pages> 198-209. </pages>
Reference-contexts: Backpropagation and feature addition continue in a cycle until either all of the training examples are correctly classified, or training accuracy again reaches a plateau. In the latter case, a call to the final Rapture routine is made. This is a call to the Upstart algorithm <ref> (Frean, 1990) </ref>. Upstart is a connectionist technique for building new hidden nodes in a neural network, and can be thought of as creating new hidden features for the rule-base. For each output unit that is incorrectly classifying examples, two new hidden units are created. <p> The process of CFBP followed by feature addition continues until either all of the training examples are successfully classified, or no further progress is being made. The latter case signals 17 the final Rapture training mechanism, which is to use the Upstart <ref> (Frean, 1990) </ref> algorithm. This is a connectionist technique for constructing hidden units. These hidden units act as intermediate terms in the symbolic rule base. For each output category with either false-negative or false-positive examples, two new hidden units are created. <p> This does not cause a call to Upstart, and features continue to be added for this category. Once every category is either completely trained, or ready for Upstart, the feature addition module terminates. 3.8 The UPSTART Algorithm The final module used by Rapture is the Upstart algorithm <ref> (Frean, 1990) </ref>. This is a connectionist technique for creating hidden nodes in a neural network. The basic idea is to create new hidden units directly beneath any output nodes that are producing classification errors. <p> There have been a number of methods for building a connectionist networks from scratch that are able to correctly classify a set of training examples, e.g. Cascade Correlation (Fahlman & Lebiere, 1989), the Upstart algorithm <ref> (Frean, 1990) </ref>, and the Tiling algorithm (Mezard & Nadal, 1989). Rapture makes use of one of these (Upstart) in creating new hidden units in existing networks, and also uses methods from decision-tree induction (Quinlan, 1986) to add observable units.
Reference: <author> Fu, L.-M. </author> <year> (1989). </year> <title> Integration of neural heuristics into knowledge-based inference. </title> <journal> Connection Science, </journal> <volume> 1 (3), </volume> <pages> 325-339. </pages>
Reference: <editor> Fu, L., & Lacher, C. (Eds.). </editor> <booktitle> (1994). Proceedings of the International Symposium on Integrating Knowledge and Neural Heuristics, 1994, </booktitle> <address> Pensacola, FL. </address>
Reference: <author> Gallant, S. </author> <year> (1988). </year> <title> Connectionist expert systems. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 31, </volume> <pages> 152-169. </pages>
Reference: <author> Ginsberg, A. </author> <year> (1988). </year> <title> Theory revision via prior operationalization. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 590-595 St. Paul, MN. </address>
Reference-contexts: This system attempted to combine credit assignment with weight adjustment in order to improve performance. Unfortunately, much of the weight adjustment was ad hoc, and their were no mechanisms for architecture modification. Another early attempt at automating rule-base revision is the Seek2 system of <ref> (Ginsberg, 1988) </ref>. This system is able to specialize and generalize choice-component rules, which are simply M-of-N rules. Guided by heuristics that estimate the net gain of various rule modifications, this system could adjust the threshold, N, of individual rules.
Reference: <author> Ginsberg, A. </author> <year> (1990). </year> <title> Theory reduction, theory revision, </title> <booktitle> and retranslation. In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 777-782 Detroit, MI. </address>
Reference: <author> Heckerman, D. </author> <year> (1986). </year> <title> Probabilistic interpretations for Mycin's certainty factors. </title> <editor> In Kanal, L. N., & Lemmer, J. F. (Eds.), </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <pages> pp. 167-196. </pages> <publisher> North Holland, Amsterdam. </publisher>
Reference-contexts: Heuristic techniques will probably be required. Although they have proven quite useful in practice, certainty factors have frequently been criticized as ad hoc and restrictive (Shafer & Pearl, 1990). Actually, certainty factors have been shown to have a clear probabilistic semantics, but only under very restrictive independence assumptions <ref> (Heckerman, 1986) </ref>. Nevertheless, the basic revision framework in Rapture should be applicable to other uncertain reasoning formalisms such as Bayesian networks (Pearl, 1988), Dempster-Shafer theory (Shafer, 1976), or fuzzy logic (Zadeh, 1965).
Reference: <author> Hinton, G. E. </author> <year> (1986). </year> <title> Learning distributed representations of concepts. </title> <booktitle> In Proceedings of the Eighth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. </pages> <address> 1-12 Amherst, MA. </address> <note> 109 Kandel, </note> <editor> A., & Langholz, G. (Eds.). </editor> <year> (1992). </year> <title> Hybrid Architectures for Intelligent Systems. </title> <publisher> CRC Press, Inc., </publisher> <address> Boca Raton, FL. </address>
Reference-contexts: Unfortunately, this approach does not consider the relative strengths of each of the antecedents. Neural 3 networks on the other hand, use connection weights to encode relative strengths. By representing rules as a neural network, standard backpropagation <ref> (Rumelhart, Hinton, & Williams, 1986) </ref> can be used to modify the weights representing rule strengths (Fu, 1989; Towell & Shavlik, 1994; Lacher, 1992). <p> The network is then fully connected by adding low-weighted links from every node in layer n to every node in layer n + 1. Once built, the network is trained using backpropagation. To help minimize the size of the network, weight-decay <ref> (Hinton, 1986) </ref> is utilized. By adjusting each weight in the network slightly towards zero after each weight update, links that are not contributing to the network are eliminated. After training, symbolic rules can be extracted from the network. <p> The network is then fully connected by linking all nodes in one layer, to all nodes in the next higher layer. These new additional links are given a minimal link-weight. CFBP and weight decay <ref> (Hinton, 1986) </ref> are performed over this network until training accuracy ceases to improve. Finally, CF-Net is CFBP performed over an initially random-weighted two-layer certainty-factor network. This system is created out of an attempt to discover any potential differences between standard Backpropagation and CFBP. <p> Also, it is unclear how certainty-factor rules might be mapped into a Kbann network. Kbann allows the learning of new rules by including an underlying fully-connected network of low-weighted links. These links can be "recruited" by backpropagation and eventually mapped back into new rules. Weight decay <ref> (Hinton, 1986) </ref> is used to keep weights small and therefore help minimize the number of new rules that are eventually introduced. By contrast, Rapture uses symbolic methods to add a minimal number of new connections (rules) as needed.
Reference: <author> Kohavi, R., & John, G. </author> <year> (1995). </year> <title> Automatic parameter setting by minimizing estimated error. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 304-312 San Francisco, CA. </address> <publisher> Morgan Kaufman. </publisher>
Reference: <author> Koppel, M., Feldman, R., & Segre, A. M. </author> <year> (1994a). </year> <title> Bias-driven revision of logical domain theories. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1, </volume> <pages> 1-50. </pages>
Reference: <author> Koppel, M., Segre, A., & Feldman, R. </author> <year> (1994b). </year> <title> Getting the most from flawed theories. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 139-147 New Brunswick, NJ. </address>
Reference-contexts: They further demonstrate the significance of the rule base for identifying promoters. By simply noting how closely each example is satisfied by the rules, and categorizing the top 50% as promoters, results similar to those of Rapture are obtained <ref> (Koppel, Segre, & Feldman, 1994b) </ref>. It is unclear how well this technique would do on further domains. A similar result has been obtained by Ortega (1995). By modifying the promoter rules into a set of M-of-N rules, accuracy of 93:4% is achieved.
Reference: <author> Kornberg, A. </author> <year> (1974). </year> <title> DNA Synthesis. W.H. </title> <publisher> Freeman and Company, </publisher> <address> San Francisco, CA. </address>
Reference: <author> Lacher, R. </author> <year> (1992). </year> <title> Node error assignment in expert networks. </title> <editor> In Kandel, A., & Langholz, G. (Eds.), </editor> <booktitle> Hybrid Architectures for Intelligent Systems, </booktitle> <pages> pp. 29-48. </pages> <publisher> CRC Press, Inc., </publisher> <address> Boca Raton, FL. </address>
Reference-contexts: This is similar to methods employed in Fu (1989) and Lacher (1992), and throughout this text I refer to this technique as Certainty-Factor Backpropagation (CFBP), though others have called it expert-network backpropagation <ref> (Lacher, 1992) </ref>. Once all of the training examples are classified correctly, the network is considered trained, and learning is complete. It is often the case, however, that CFBP plateaus before achieving 100% accuracy on the training data. When this occurs, architecture modification routines are called.
Reference: <author> Lacher, R., Hruska, S., & Kuncicky, D. </author> <year> (1992). </year> <title> Back-propagation learning in expert networks. </title> <journal> IEEE Transaction on Neural Networks, </journal> <volume> 3 (1), </volume> <pages> 62-72. </pages>
Reference-contexts: This is similar to methods employed in Fu (1989) and Lacher (1992), and throughout this text I refer to this technique as Certainty-Factor Backpropagation (CFBP), though others have called it expert-network backpropagation <ref> (Lacher, 1992) </ref>. Once all of the training examples are classified correctly, the network is considered trained, and learning is complete. It is often the case, however, that CFBP plateaus before achieving 100% accuracy on the training data. When this occurs, architecture modification routines are called.
Reference: <author> Langley, P., & Simon, H. A. </author> <year> (1995). </year> <title> Applications of machine learning and rule induction. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 38 (11), </volume> <pages> 55-64. </pages>
Reference: <author> Ling, X., & Valtorta, M. </author> <year> (1991). </year> <title> Revision of reduced theories. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pp. </pages> <address> 519-523 Evanston, IL. </address>
Reference-contexts: This modularity of evidence, as well as the use of probabilistic sum enables many small pieces of evidence to add up to significant evidence. This is lacking in formalisms that use only MIN or MAX for combining evidence <ref> (Ling & Valtorta, 1991) </ref>. Second, probabilistic sum is a simple, differentiable, non-linear function. This is crucial for implementing gradient descent using backpropagation. Further, other formalisms for uncertain reasoning (e.g.
Reference: <author> Ma, Y., & Wilkins, D. C. </author> <year> (1991). </year> <title> Improving the performance of inconsistent knowledge bases via combined optimization method. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pp. </pages> <address> 23-27 Evanston, IL. </address>
Reference-contexts: Rapture borrows from this formalism for representing the rule bases that it revises. A version of the Mycin rule base was prepared for Rapture consisting of 99 examples of solved cases (patients) of infectious diseases drawn from the Stanford Medical Center <ref> (Ma & Wilkins, 1991) </ref>.
Reference: <author> Merz, C., Murphy, P. M., & Aha, D. W. </author> <year> (1996). </year> <note> Repository of machine learning databases http://www.ics.uci.edu/~mlearn/mlrepository.html. Department of Information and Computer Science, </note> <institution> University of California, </institution> <address> Irvine, CA. </address>
Reference-contexts: Attempts to revise this rule base are discussed in the following sections. 4.5.1 The 106-example Promoter Data Set The 106 example Promoter data set is available from the Irvine machine-learning data repository <ref> (Merz, Murphy, & Aha, 1996) </ref>, and because of its wide availability has been tested on a number of learning systems. This data set consists of 53 examples of Promoters (i.e. positive example), and 53 examples of non Promoters.
Reference: <author> Mezard, M., & Nadal, J. </author> <year> (1989). </year> <title> Learning in feedforward layered networks: The tiling algorithm. </title> <journal> Journal of Physics, </journal> <volume> A22 (12), </volume> <pages> 2191-2203. </pages>
Reference-contexts: There have been a number of methods for building a connectionist networks from scratch that are able to correctly classify a set of training examples, e.g. Cascade Correlation (Fahlman & Lebiere, 1989), the Upstart algorithm (Frean, 1990), and the Tiling algorithm <ref> (Mezard & Nadal, 1989) </ref>. Rapture makes use of one of these (Upstart) in creating new hidden units in existing networks, and also uses methods from decision-tree induction (Quinlan, 1986) to add observable units.
Reference: <author> Michalksi, R., Mozetic, I., Hong, J., & Lavrac, N. </author> <year> (1986). </year> <title> The multi-purpose incremental learning system AQ15 and its testing application to three medical domains. </title> <booktitle> In Proceedings of the Fifth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 1041-1045 Philadelphia, PA. </address>
Reference: <author> Michalski, R. S., & Chilausky, S. </author> <year> (1980). </year> <title> Learning by being told and learning from examples: An experimental comparison of the two methods of knowledge acquisition in the context of developing an expert system for soybean disease diagnosis. </title> <journal> Journal of Policy Analysis and Information Systems, </journal> <volume> 4 (2), </volume> <pages> 126-161. </pages>
Reference-contexts: Rapture has been tested on revising several real-world knowledge bases with encouraging results. In particular, we present results for revising rule bases for recognizing promoter sequences in strands of DNA (Towell et al., 1990), identifying splice-junction sites in DNA (Towell & Shav-lik, 1994), diagnosing diseased soybeans <ref> (Michalski & Chilausky, 1980) </ref>, and diagnosing bacterial infections in humans (Buchanan & Shortliffe, 1984). This last domain is based on a version of the Mycin knowledge-base, which Rapture has successfully revised. <p> This indicates that certain DNA strings can be identified whenever M-of-N consecutive nucleotides match a given pattern. This is clearly evidenced in the original expert rules for determining splice-junction points (see Appendix B). Also, a set of rules for diagnosing diseased soybeans (described fully in Chapter 4 <ref> (Michalski & Chilausky, 1980) </ref>) was created that made use of uncertain reasoning. The rule base contains two different types of rules. Rules labelled significant are suggested to carry 0.9 weight (out of a possible 1.0), while those labelled confirmatory carry the remaining 0.1. <p> Weighted Horn-Clause Rules The original rule base for Soybean Disease Diagnosis was developed with the help of a soybean expert, and contained two types of rules that were given different levels of importance <ref> (Michalski & Chilausky, 1980) </ref>. Though described in Horn-clause form, rules labelled as significant were suggested to carry approximately nine times as much weight as those labelled confirmatory.
Reference: <author> Mitchell, T. M., Keller, R. M., & Kedar-Cabelli, S. T. </author> <year> (1986). </year> <title> Explanation-based generalization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1 (1), </volume> <pages> 47-80. </pages> <note> 110 Mooney, </note> <author> R. J., & Ourston, D. </author> <year> (1991). </year> <title> A multistrategy approach to theory refinement. </title> <booktitle> In Proceed--ings of the First International Workshop on Multistrategy Learning, </booktitle> <pages> pp. </pages> <address> 115-130 Harper's Ferry, W.Va. </address>
Reference: <author> Musick, R. C. </author> <year> (1994). </year> <title> Belief Network Induction. </title> <type> Ph.D. thesis, </type> <institution> University of California at Berkeley. </institution>
Reference: <author> Noordewier, M. O., Towell, G. G., & Shavlik, J. W. </author> <year> (1991). </year> <title> Training knowledge-based neural networks to recognize genes in DNA sequences. </title> <booktitle> In Advances in Neural Information Processing Systems, Vol. </booktitle> <address> 3 San Mateo, CA. </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Similarly, Exon-Intron (EI) borders (known as donors) delimit the end of a sequence of genetic information, and the beginning of junk DNA. The rules and examples for this domain come from M. Noordewier <ref> (Noordewier et al., 1991) </ref>, and consists of a database of 3190 examples of DNA strings. Of these examples, there are 768 (or 24%) examples of IE borders, 767 (24%) EI borders, and 1655 (52%) negative examples, which are randomly chosed DNA sequences containing neither border.
Reference: <author> O'Neill, M., & Chiafari, F. </author> <year> (1989). </year> <title> Escherichia coli promoters. </title> <journal> Journal of Biological Chemistry, </journal> <volume> 264, </volume> <pages> 5531-5534. </pages>
Reference: <author> Opitz, D. W., & Shavlik, J. W. </author> <year> (1993). </year> <title> Heuristically expanding knowledge-based neural networks. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 512-517 Chamberry, France. </address>
Reference-contexts: In a standard neural network with many hidden layers, backpropagation tends to modify weights equally throughout the layers. By placing more emphasis on weight adjustment at the lowest layers, better performances can result. TopGen <ref> (Opitz & Shavlik, 1993) </ref> is a method for adding new hidden units to a Kbann-network. By keeping track of of the false negative and false positives for which each node is responsible, the algorithm locates areas of the network requiring additional units. <p> Perhaps the use of other connectionist techniques would prove significantly better. By examining those nodes in the network that appear to be creating network error, revisions can perhaps be better focused. TopGen <ref> (Opitz & Shavlik, 1993) </ref> offers an approach similar to this. One aspect of Rapture that has gone almost completely untested is the setting of parameters. One of the undesirable characteristics that Rapture inherited from backpropagation is the usage of many parameters. These include the learning rate, momentum, weight-decay rate, etc.
Reference: <author> Ortega, J. </author> <year> (1995). </year> <title> On the informativeness of the dna promoter sequences domain theory. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 2, </volume> <pages> 361-367. </pages>
Reference: <author> Ourston, D. </author> <year> (1991). </year> <title> Using Explanation-Based and Empirical Methods in Theory Revision. </title> <type> Ph.D. thesis, </type> <institution> University of Texas, Austin, TX. </institution> <note> Also appears as Artificial Intelligence Laboratory Technical Report AI 91-164. </note>
Reference-contexts: Flexible matching methods, which have been used successfully in inductive rule-learning (Michalski & Chilausky, 1980; Michalksi, Mozetic, Hong, & Lavrac, 1986) and rule-base revision <ref> (Mooney & Ourston, 1991) </ref>, are one way of dealing with this problem. In this approach, a score is calculated measuring how well an example matches each symbolic rule, and the rule with the greatest score is invoked. <p> It is unclear how well this technique would do on further domains. A similar result has been obtained by Ortega (1995). By modifying the promoter rules into a set of M-of-N rules, accuracy of 93:4% is achieved. Either <ref> (Ourston, 1991) </ref> was one of the inspirations for Rapture. This is a completely symbolic system that modifies initial rule-bases by adding and deleting antecedents and rules.
Reference: <author> Ourston, D., & Mooney, R. </author> <year> (1990). </year> <title> Changing the rules: A comprehensive approach to theory refinement. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 815-820 Detroit, MI. </address>
Reference: <author> Ourston, D., & Mooney, R. J. </author> <year> (1994). </year> <title> Theory refinement combining analytical and empirical methods. </title> <journal> Artificial Intelligence, </journal> <volume> 66, </volume> <pages> 311-344. </pages>
Reference-contexts: We compare our results to those obtained for purely inductive methods (C4.5 (Quinlan, 1993), standard backpropagation, and Rapture given no initial knowledge), a purely connectionist method for knowledge-base refinement (Kbann), a purely symbolic method for knowledge-base refinement (Either <ref> (Ourston & Mooney, 1994) </ref>), as well as various Rapture ablations which demonstrate the effects of each of the components. <p> Results of these systems will be compared with those of Rapture in Chapter 4. One of these is a purely symbolic system, and another is predominantly connectionist. 12 2.5.1 EITHER Either <ref> (Ourston & Mooney, 1994) </ref> is a rule-base revision system that uses propositional Horn-clause logic to represent its rule bases. It begins with background knowledge in the form of a Horn-clause rule base, along with a set of training examples. <p> This ideally enables the rules to perform at a superior level of accuracy on unseen examples. Ourston illustrates the success of this heuristic with results from several domains <ref> (Ourston & Mooney, 1994) </ref>. 2.5.2 NEITHER Neither, or New-Either, is an updated version of Either developed by Baffes and Mooney (1993a). While still a purely symbolic-learning system, it allows M-of-N style rules that allow consequents to be concluded whenever M of the N antecedents are true. <p> Either to date has only been run up to 100 examples. It has, however, also been run using a partial-matching technique, where examples are classified into the category that was closest to firing, in which case its performance through 100 examples nearly matches that of Rapture <ref> (Ourston & Mooney, 1994) </ref>. From 80 examples onward, Rapture is performing at significantly better levels than the variants. This can only be attributed to the Upstart algorithm. As the initial set of rules lacks essential information for distinguishing the Spot diseases, Upstart is able to create useful hidden concepts.
Reference: <author> Pazzani, M., & Kibler, D. </author> <year> (1992). </year> <title> The utility of background knowledge in inductive learning. </title> <journal> Machine Learning, </journal> <volume> 9, </volume> <pages> 57-94. </pages>
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, Inc., </publisher> <address> San Mateo,CA. </address>
Reference-contexts: Actually, certainty factors have been shown to have a clear probabilistic semantics, but only under very restrictive independence assumptions (Heckerman, 1986). Nevertheless, the basic revision framework in Rapture should be applicable to other uncertain reasoning formalisms such as Bayesian networks <ref> (Pearl, 1988) </ref>, Dempster-Shafer theory (Shafer, 1976), or fuzzy logic (Zadeh, 1965). Although Schwalb's approach to revising Bayesian networks is intractable in the general case (Schwalb, 1993), it may be useful for networks with limited fan-in.
Reference: <author> Portugal, F., & Cohen, J. </author> <year> (1977). </year> <title> A Century of DNA: A History of the Discovery of the Structure and Function of the Genetic Substance. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Quinlan, J. R. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 (1), </volume> <pages> 81-106. </pages>
Reference-contexts: When this occurs, architecture modification routines are called. These routines borrow from both symbolic and connectionist methods common to machine learning. The first of these is the feature-addition routine. Specifically, features are added into the network that best discriminate between incorrectly handled examples using ID3's information gain <ref> (Quinlan, 1986) </ref>. Backpropagation and feature addition continue in a cycle until either all of the training examples are correctly classified, or training accuracy again reaches a plateau. In the latter case, a call to the final Rapture routine is made. This is a call to the Upstart algorithm (Frean, 1990). <p> It is connected with a small positive link weight to one output node, and with a small negative link weight to others. The selection of the most appropriate feature to add uses the information-gain metric of ID3 <ref> (Quinlan, 1986) </ref>. The following subsection describes this process in detail. 3.7.1 Choosing the Best Feature to Add Assuming that the network has not reached 100% training accuracy, by definition there remain training examples that are being classified into incorrect categories. <p> Since the network is classifying the false-negative examples into these incorrect categories, a new feature is needed that the network can use to better discriminate between these groups of examples. Quinlan's ID3 metric <ref> (Quinlan, 1986) </ref> has been adopted by Rapture as the solution to this problem. ID3 is designed to build decision trees that classify examples into pre-defined categories. <p> Cascade Correlation (Fahlman & Lebiere, 1989), the Upstart algorithm (Frean, 1990), and the Tiling algorithm (Mezard & Nadal, 1989). Rapture makes use of one of these (Upstart) in creating new hidden units in existing networks, and also uses methods from decision-tree induction <ref> (Quinlan, 1986) </ref> to add observable units. Currently, however, Rapture is limited to adding new units that directly feed into the output layer, and there exists no way to add a new link into an existing non-output unit, other than a newly created Upstart node.
Reference: <author> Quinlan, J. R. </author> <year> (1993). </year> <title> C4.5: Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo,CA. </address>
Reference-contexts: This last domain is based on a version of the Mycin knowledge-base, which Rapture has successfully revised. We compare our results to those obtained for purely inductive methods (C4.5 <ref> (Quinlan, 1993) </ref>, standard backpropagation, and Rapture given no initial knowledge), a purely connectionist method for knowledge-base refinement (Kbann), a purely symbolic method for knowledge-base refinement (Either (Ourston & Mooney, 1994)), as well as various Rapture ablations which demonstrate the effects of each of the components. <p> This list is sorted, and midpoints are created between each successive numeric value. Each of these midpoint values is then used, and tested as a potential threshold for this feature. This has been shown to be a successful technique for creating values to test against <ref> (Quinlan, 1993) </ref>. All intermediate (non-observable) features appearing in the network are also tested for information gain. Every example when processed by the network will give some certainty-factor 28 value to every node in the network.
Reference: <author> Rada, R. </author> <year> (1985). </year> <title> Gradualness facilitates knowledge refinement. </title> <journal> IEEE transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 7 (5). </volume>
Reference: <author> Ramachandran, S. </author> <year> (1995). </year> <title> Refinement of Bayesian networks by combining connectionist and symbolic techniques. </title> <note> cs.utexas.edu FTP archive. 111 Rissanen, J. </note> <year> (1978). </year> <title> Modeling by shortest data description. </title> <journal> Automatica, </journal> <volume> 14, </volume> <pages> 465-471. </pages>
Reference: <author> Rosenfield, I., Ziff, E., & van Loon, B. </author> <year> (1983). </year> <title> DNA For Beginners. </title> <publisher> Writers and Readers Publishing Cooperative Ltd., London. </publisher>
Reference: <author> Rumelhart, D. E., Hinton, G. E., & Williams, J. R. </author> <year> (1986). </year> <title> Learning internal representations by error propagation. </title> <editor> In Rumelhart, D. E., & McClelland, J. L. (Eds.), </editor> <booktitle> Parallel Distributed Processing, </booktitle> <volume> Vol. I, </volume> <pages> pp. 318-362. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: Unfortunately, this approach does not consider the relative strengths of each of the antecedents. Neural 3 networks on the other hand, use connection weights to encode relative strengths. By representing rules as a neural network, standard backpropagation <ref> (Rumelhart, Hinton, & Williams, 1986) </ref> can be used to modify the weights representing rule strengths (Fu, 1989; Towell & Shavlik, 1994; Lacher, 1992). <p> No thresholding output function is needed for units in the certainty-factor network, since the probabilistic sum already provides the required non-linearity. Next, the network is modified to correctly classify a set of training examples. Network training is performed in three phases. First, a modified version of backpropagation <ref> (Rumelhart et al., 1986) </ref> is used to adjust the certainty-factors on existing rules. The normal backpropagation equations are modified in order to perform gradient descent for certainty-factor combining functions (e.g., probabilistic sum, min, and max). <p> This is a clear indication that this approach is one that is worth pursuing. 2.4 Backpropagation Backpropagation, or simply BackProp, is a standard connectionist technique for training neural networks to correctly categorize sets of labelled examples <ref> (Rumelhart et al., 1986) </ref>. This is a gradient-descent method that gradually shifts all of the weights in the network in a direction that will decrease network mean-squared error. Each time a training example is processed by the network, any errors occurring at the output layer are noted. <p> Errors at the output level are then backpropagated back down towards the input layer. This has the effect of modifying some or all of the certainty factors associated with each rule. Backpropation <ref> (Rumelhart et al., 1986) </ref> is a hill-climbing technique that slightly adjusts the weight on each link in a direction that will most directly minimize the error caused by the particular training example. <p> Rapture contains three separate mechanisms for achieving this|certainty-factor backpropagation (CFBP), feature addition, and Upstart hidden-node creation. These are fully described in the following sections. 23 3.6 Certainty-Factor Backpropagation CFBP is the gradient-descent algorithm developed for Rapture. Gradient descent, or backpropagation <ref> (Rumelhart et al., 1986) </ref>, is a standard connectionist algorithm for adjusting weights in a neural network. The basic idea is to systematically adjust all of the weights on the links in the direction that minimizes the mean-squared error of the network. <p> This creates rules that should generally be easier to comprehend. 78 Appendix A Derivation of the CFBP Formulae Using the designed Rapture network, we wish to perform backpropagation on the certainty factors (which are the weights on the links between the nodes). Following the presentation given in <ref> (Rumelhart et al., 1986) </ref>, we can define the network error due to input pattern p as E p = 2 j and total error is similarly measured as E = P E p .
Reference: <author> Samuel, A. </author> <year> (1959). </year> <title> Some studies in machine learning using the game of checkers. </title> <journal> IBM Journal of Research and Development, </journal> <pages> pp. 211-229. </pages>
Reference: <author> Schwalb, E. </author> <year> (1993). </year> <title> Compiling Bayesian networks into neural networks. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 291-297 Amherst, MA. </address>
Reference-contexts: This is crucial for implementing gradient descent using backpropagation. Further, other formalisms for uncertain reasoning (e.g. Bayesian networks) have been shown to be NP-hard to evaluate in the general case (Cooper, 1990), and require the specification of exponentially many conditional probabilities in the fan-in of a node <ref> (Schwalb, 1993) </ref>. Even more significantly, however, is the widespread use of certainty factors. Despite recent criticism of certainty factors (Shafer & Pearl, 1990), there have been numerous knowledge-bases implemented using the certainty-factor model, which immediately gives our approach a large base of applicability. <p> Nevertheless, the basic revision framework in Rapture should be applicable to other uncertain reasoning formalisms such as Bayesian networks (Pearl, 1988), Dempster-Shafer theory (Shafer, 1976), or fuzzy logic (Zadeh, 1965). Although Schwalb's approach to revising Bayesian networks is intractable in the general case <ref> (Schwalb, 1993) </ref>, it may be useful for networks with limited fan-in. The approach of Ramachandran (1995), utilizing noisy-or and noisy-and nodes seems to confirm that the Bayesian approach is worthy of further study.
Reference: <author> Shafer, G. </author> <year> (1976). </year> <title> A Mathematical Theory of Evidence. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ. </address>
Reference-contexts: Actually, certainty factors have been shown to have a clear probabilistic semantics, but only under very restrictive independence assumptions (Heckerman, 1986). Nevertheless, the basic revision framework in Rapture should be applicable to other uncertain reasoning formalisms such as Bayesian networks (Pearl, 1988), Dempster-Shafer theory <ref> (Shafer, 1976) </ref>, or fuzzy logic (Zadeh, 1965). Although Schwalb's approach to revising Bayesian networks is intractable in the general case (Schwalb, 1993), it may be useful for networks with limited fan-in.
Reference: <author> Shafer, G., & Pearl, J. (Eds.). </author> <year> (1990). </year> <title> Readings in Uncertain Reasoning. </title> <publisher> Morgan Kaufmann, Inc., </publisher> <address> San Mateo,CA. </address>
Reference-contexts: Though several refinement systems have been successfully applied to real-world problems (Ginsberg, 1990; Ourston & Mooney, 1994; Towell & Shavlik, 1994), to date these have focused largely on revising logical Horn-clause theories. Many real-world domains, however, require some type of probabilistic or uncertain reasoning <ref> (Shafer & Pearl, 1990) </ref>. The primary advantage of these methods is their ability to combine evidence from several different sources and draw conclusions based on the total combined evidence for each possible decision. <p> Even more significantly, however, is the widespread use of certainty factors. Despite recent criticism of certainty factors <ref> (Shafer & Pearl, 1990) </ref>, there have been numerous knowledge-bases implemented using the certainty-factor model, which immediately gives our approach a large base of applicability. <p> In first-order logic, this may require the consideration of every possible value for each first-order variable. Heuristic techniques will probably be required. Although they have proven quite useful in practice, certainty factors have frequently been criticized as ad hoc and restrictive <ref> (Shafer & Pearl, 1990) </ref>. Actually, certainty factors have been shown to have a clear probabilistic semantics, but only under very restrictive independence assumptions (Heckerman, 1986).
Reference: <author> Shavlik, J. W., Mooney, R. J., & Towell, G. G. </author> <year> (1991). </year> <title> Symbolic and neural learning algorithms: An experimental comparison. </title> <journal> Machine Learning, </journal> <volume> 6, </volume> <pages> 111-143. </pages> <note> Reprinted in Readings in Knowledge Acquisition and Learning, </note> <editor> B. G. Buchanan and D. C. Wilkins (eds.), </editor> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: If the example is missing the value for this feature, a certainty factor of 1=n is used, where n is the number of possible values for this feature. This has been shown to be an effective encoding for missing features in neural networks <ref> (Shavlik, Mooney, & Towell, 1991) </ref>. In many domains, there also occur features with continuous values, such as a patient's age. An input node corresponding to the feature (AGE-OF-PATIENT &lt; 50) will receive a certainty factor dependent upon how closely the example satisfies the condition of the rule.
Reference: <author> Shortliffe, E. </author> <year> (1976). </year> <title> Computer-Based Medical Consultations: MYCIN. </title> <publisher> American Elsevier Publishing Company, INC., </publisher> <address> New York, NY. </address>
Reference: <author> Shortliffe, E., & Buchanan, B. </author> <year> (1975). </year> <title> A model of inexact reasoning in medicine. </title> <journal> Mathematical Biosciences, </journal> <volume> 23, </volume> <pages> 351-379. </pages>
Reference-contexts: For any p-sum unit j, the net input to this unit for input pattern p is defined as the certainty factor of all incoming activation values. net pj = CF (w ji o pi ) 8i (A.2) Certainty factor (CF) is defined in <ref> (Shortliffe & Buchanan, 1975) </ref> as CF = 1 min (MB; MD) where MB (Measure of Belief) is the positive or confirming evidence, and MD (Measure of Disbelief) is the negative or disconfirming evidence.
Reference: <author> Swartout, W. </author> <year> (1981). </year> <title> Explaining and justifying in expert consulting programs. </title> <booktitle> In Proceedings of the Seventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 203-208 Vancouver, BC. </address>
Reference-contexts: This approach therefore combines the effectiveness of connectionist learning methods with the interpretability of rules. Comprehensibility is important since it has been found that users will generally not accept a system's conclusions unless it can present meaningful explanations for them <ref> (Swartout, 1981) </ref>. Rapture has been tested on revising several real-world knowledge bases with encouraging results.
Reference: <author> Thompson, K., Langley, P., & Iba, W. </author> <year> (1991). </year> <title> Using background knowledge in concept formation. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pp. </pages> <address> 554-558 Evanston, IL. </address>
Reference: <author> Towell, G., & Shavlik, J. </author> <year> (1991). </year> <title> Refining symbolic knowledge using neural networks. </title> <booktitle> In Proceedings of the First International Workshop on Multistrategy Learning, </booktitle> <pages> pp. </pages> <address> 257-272 Harper's Ferry, W.Va. </address>
Reference-contexts: If the example is missing the value for this feature, a certainty factor of 1=n is used, where n is the number of possible values for this feature. This has been shown to be an effective encoding for missing features in neural networks <ref> (Shavlik, Mooney, & Towell, 1991) </ref>. In many domains, there also occur features with continuous values, such as a patient's age. An input node corresponding to the feature (AGE-OF-PATIENT &lt; 50) will receive a certainty factor dependent upon how closely the example satisfies the condition of the rule.
Reference: <author> Towell, G., & Shavlik, J. </author> <year> (1992). </year> <title> Interpretation of artificial neural networks: Mapping knowledge-based neural networks into rules. </title> <editor> In Lippmann, R., Moody, J., & Touretzky, D. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> Vol. 4. </volume> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: These new units are trained using the Rapture algorithm recursively, and linked appropriately to their 4 corresponding output units. One elegant feature of the Rapture algorithm is that once a network is trained, the revised rules can be read directly off of the network. Unlike the Kbann system <ref> (Towell & Shavlik, 1992) </ref> (see section 2:5:3), where revised networks are mapped back into rules to improve the comprehensibility of the final result, no retranslation in necessary for Rapture. <p> The original Kbann work contained a suggestion for adding new hidden units into a Kbann-net that would seem to work only in very specialized domains|such as promoter recognition. This was achieved through adding "cone" units that would connect contiguous features. Kbann-Daid <ref> (Towell & Shavlik, 1992) </ref> is an attempt to improve the way that backpropagation adjusts network weights. In a standard neural network with many hidden layers, backpropagation tends to modify weights equally throughout the layers. By placing more emphasis on weight adjustment at the lowest layers, better performances can result.
Reference: <author> Towell, G. G., Shavlik, J. W., & Noordewier, M. O. </author> <year> (1990). </year> <title> Refinement of approximate domain theories by knowledge-based artificial neural networks. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 861-866 Boston, MA. </address> <note> 112 Towell, </note> <author> G., & Shavlik, J. </author> <year> (1992). </year> <title> Using symbolic learning to improve knowledge-based neural networks. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 177-182 San Jose, CA. </address>
Reference-contexts: Rapture has been tested on revising several real-world knowledge bases with encouraging results. In particular, we present results for revising rule bases for recognizing promoter sequences in strands of DNA <ref> (Towell et al., 1990) </ref>, identifying splice-junction sites in DNA (Towell & Shav-lik, 1994), diagnosing diseased soybeans (Michalski & Chilausky, 1980), and diagnosing bacterial infections in humans (Buchanan & Shortliffe, 1984). This last domain is based on a version of the Mycin knowledge-base, which Rapture has successfully revised.
Reference: <author> Towell, G., & Shavlik, J. </author> <year> (1994). </year> <title> Knowledge-based artificial neural networks. </title> <journal> Artificial Intelligence, </journal> <volume> 69. </volume>
Reference-contexts: Rapture has been tested on revising several real-world knowledge bases with encouraging results. In particular, we present results for revising rule bases for recognizing promoter sequences in strands of DNA (Towell et al., 1990), identifying splice-junction sites in DNA <ref> (Towell & Shav-lik, 1994) </ref>, diagnosing diseased soybeans (Michalski & Chilausky, 1980), and diagnosing bacterial infections in humans (Buchanan & Shortliffe, 1984). This last domain is based on a version of the Mycin knowledge-base, which Rapture has successfully revised. <p> These properties gives Neither the ability to perform better in domains such as Promoter that benefit from partial matching (Baffes & Mooney, 1993b). 2.5.3 KBANN As previously mentioned, Kbann <ref> (Towell & Shavlik, 1994) </ref> is a refinement system which translates a rule base into a neural network and then refines it using backpropagation. The translation into a neural network proceeds in a straightforward manner. <p> New nodes are created and linked through feature-addition, CFBP is performed, and the Upstart algorithm is called to 34 create hidden units. Rapture-Null terminates when training accuracy reaches 100%. The variant Rapture-Kbann, is an attempt to replicate the Kbann algorithm <ref> (Towell & Shavlik, 1994) </ref> using Rapture's certainty-factor combining functions. Beginning with an initial theory represented as a certainty-factor network, all features from the domain not currently represented in the network are added to the input layer.
Reference: <author> Valtorta, M. </author> <year> (1988). </year> <title> Some results on the complexity of knowledge-base refinement. </title> <booktitle> In Proceedings of the Sixth International Workshop on Machine Learning, </booktitle> <pages> pp. </pages> <address> 326-331 Ithaca, NY. </address>
Reference: <author> Valtorta, M. </author> <year> (1990). </year> <title> More results on the complexity of knowledge-base refinement:belief networks. </title> <booktitle> In Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 419-424 Austin, TX. </address> <publisher> von Heijne, G. </publisher> <year> (1987). </year> <title> Sequence Analysis in Molecular Biology: Treasure Trove or Trivial Pursuit. </title> <publisher> Academic Press, </publisher> <address> San Diego, CA. </address>
Reference: <author> Wade, N. </author> <year> (1995). </year> <title> Rapid gains are reported on genome. The New York Times, Section A, </title> <type> 13. </type>
Reference-contexts: Since there are only 20 amino acids found in proteins, the 64 = 4 3 possible base triplets are easily sufficient. There is much ongoing research into decoding the information contained in strands of DNA, and more is being learned continuously. The New York Times <ref> (Wade, 1995) </ref> reports on rapid progress currently being made, and quotes two scientific reports that estimate that as much as 99% of human-DNA genetic-information should be fully decoded by the year 2002. One current unknown in the decoding process is the determination of the starting points of gene sequences.
Reference: <author> Watson, J., Roberts, H., Steitz, J., & Weiner, A. </author> <year> (1987). </year> <title> The Molecular Biology of the Gene. </title> <address> Benjamin-Cummings, Menlo, Park, CA. </address>
Reference: <author> Yu, Y.-H., & Simmons, R. </author> <year> (1990). </year> <title> Descending epsilon in back-propagation: A technique for better generalization. </title> <type> Tech. rep. </type> <institution> AI90-130, Artificial Intelligence Laboratory, The University of Texas at Austin, Austin, TX. </institution>
Reference: <author> Zadeh, L. </author> <year> (1965). </year> <title> Fuzzy sets. </title> <journal> Information and Control, </journal> <volume> 8, </volume> <pages> 338-353. 113 </pages>
Reference-contexts: A patient exactly 50 years old will produce a certainty factor of 0:5, and this value will decrease rapidly towards 0:0 for older patients. This type of evaluation is typical of the method used to determine set membership in fuzzy set theory <ref> (Zadeh, 1965) </ref>. All examples with no value for this feature are assigned the average value for the feature. <p> Actually, certainty factors have been shown to have a clear probabilistic semantics, but only under very restrictive independence assumptions (Heckerman, 1986). Nevertheless, the basic revision framework in Rapture should be applicable to other uncertain reasoning formalisms such as Bayesian networks (Pearl, 1988), Dempster-Shafer theory (Shafer, 1976), or fuzzy logic <ref> (Zadeh, 1965) </ref>. Although Schwalb's approach to revising Bayesian networks is intractable in the general case (Schwalb, 1993), it may be useful for networks with limited fan-in. The approach of Ramachandran (1995), utilizing noisy-or and noisy-and nodes seems to confirm that the Bayesian approach is worthy of further study.
References-found: 80

