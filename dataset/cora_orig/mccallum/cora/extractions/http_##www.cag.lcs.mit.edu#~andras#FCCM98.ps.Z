URL: http://www.cag.lcs.mit.edu/~andras/FCCM98.ps.Z
Refering-URL: http://www.cag.lcs.mit.edu/~andras/
Root-URL: 
Email: fandras,piano,agarwalg@lcs.mit.edu  
Title: Exploring Optimal Cost-Performance Designs for Raw Microprocessors words/cycle global I/O, 20Kbytes of local memory per
Author: Csaba Andras Moritz Donald Yeung Anant Agarwal 
Note: approximately 1000 tiles, 30  
Address: Cambridge, Massachusetts 02139  
Affiliation: Laboratory for Computer Science Massachusetts Institute of Technology  
Abstract: The semiconductor industry roadmap projects that advances in VLSI technology will permit more than one billion transistors on a chip by the year 2010. The MIT Raw microprocessor is a proposed architecture that strives to exploit these chip-level resources by implementing thousands of tiles, each comprising a processing element and a small amount of memory, coupled by a static two-dimensional interconnect. A compiler partitions fine-grain instruction-level parallelism across the tiles and statically schedules inter-tile communication over the interconnect. Because Raw microprocessors fully expose their internal hardware structure to the software, they can be viewed as a gigantic FPGA with coarse-grained tiles, in which software orchestrates communication over static interconnections. One open challenge in Raw architectures is to determine their optimal grain size and balance. The grain size is the area of each tile, and the balance is the proportion of area in each tile devoted to memory, processing, communication, and I/O. If the total chip area is fixed, more area devoted to processing will result in a higher processing power per node, but will lead to a fewer number of tiles. This paper presents an analytical framework using which designers can reason about the design space of Raw microprocessors. Based on an architectural model and a VLSI cost analysis, the framework computes the performance of applications, and uses an optimization process to identify designs that will execute these applications most cost-effectively. Although the optimal machine configurations obtained vary for different applications, problem sizes and budgets, the general trends for various applications are similar. Accordingly, for the applications studied, assuming an 1 billion logic transistor equivalent area, we recommend building a Raw chip with 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Elliot Waingold, Michael Taylor, Devabhaktuni Srikrishna, Vivek Sarkar, Walter Lee, Victor Lee, Jang Kim, Matthew Frank, Peter Finch, Rajeev Barua, Jonathan Babb, Saman Amarasinghe, </author> <title> and Anant Agarwal Baring it all to Software: Raw Machines. </title> <booktitle> IEEE Computer, </booktitle> <month> September </month> <year> 1997, </year> <pages> pp. 86-93. </pages>
Reference-contexts: The MIT Raw microprocessor is a proposed architecture that exposes its internal hardware structure to the compiler, so that the compiler can determine and orchestrate the best mapping of an application to the hardware. A Raw microprocessor <ref> [1] </ref> is reminiscent of a coarse-grained FPGA and comprises a replicated set of tiles coupled together by a set of compiler orchestrated, pipelined, switches (Figure 1). Each tile contains a simple RISC-like processing core and an SRAM memory for instructions and data. <p> This requirement reflects the total amount of computation required per Jacobi node given the algorithmic assumptions described above. The total number of operations for each point are three additions and one multiplication. R p = i t 4 P N 3 : P 2 <ref> [1; N ] </ref> (10) Required amount of memory words per node R m . The required memory is comprised by the memory required to solve the subblock of size N 0 and also the memory buffers needed to overlap local and global communication.
Reference: [2] <author> D. Culler, R. Karp, D. Patterson, A. Sahay, K. Schauser, E. Santos, R. Subramonian, and T. Eicken, </author> <title> "LogP: Towards a Realistic Model of Parallel Computation," </title> <booktitle> Proc. of Fourth ACM SIG-PLAN Symp. on Principles and Practices of Parallel Programming, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: The following sections discuss each of the components of the framework and the optimization process in more detail. 2.3 Architecture model This section discusses parameters necessary for architecture characterization. Although several approaches to modeling the performance of a parallel computer have been proposed in the literature <ref> [2, 3] </ref>, none are completely suited to modeling fine-grain parallel systems built on a chip.
Reference: [3] <author> A. Alexandrov, M. Ionescu, K. E. Schauser, and C. Scheiman. "LogGP: </author> <title> Incorporating Long Messages into the LogP Model" Proc. </title> <booktitle> of the SPAA'95, </booktitle> <address> Santa Barbara, CA, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: The following sections discuss each of the components of the framework and the optimization process in more detail. 2.3 Architecture model This section discusses parameters necessary for architecture characterization. Although several approaches to modeling the performance of a parallel computer have been proposed in the literature <ref> [2, 3] </ref>, none are completely suited to modeling fine-grain parallel systems built on a chip.
Reference: [4] <author> J. Babb and R. Tessier and M. Dahl and S. Hanono and D. Hoki and A. Agarwal. </author> <title> Logic Emulation with Virtual Wires. </title> <journal> IEEE Transactions on Computer Aided Design, </journal> <volume> VOL. 16, No.6, </volume> <month> June </month> <year> 1997, </year> <pages> pp. 609-626. </pages>
Reference-contexts: The switches themselves contain some amount of SRAM so that the compiler can load into the switch a program that multiplexes the interconnect in a cycle by cycle fashion, just as in a virtual-wires based multi-FPGA system <ref> [4] </ref>. A typical Raw system includes a Raw microprocessor coupled with off-chip RDRAM (RamBus DRAM) through multiple high bandwidth paths.
Reference: [5] <author> Donald Yeung, William J. Dally, Anant Agarwal. </author> <title> How to Choose the Grain Size of a Parallel Computer. </title> <type> MIT/LCS Technical Report, </type> <institution> MIT-LCS-TR-739. </institution>
Reference-contexts: On the other hand, building a large number of very small (fine grain) nodes will also result in diminishing returns as the communication costs dominate. The highest efficiency occurs at an optimal point between the two extremes. Similarly, as observed by Kung and others <ref> [11, 5] </ref>, there is an optimal balance of resources between the processor, memory, and communication components within a node. While there has been much debate on this topic, few concrete results have been reported. <p> transistor equivalent area, designers should build a system with about 1000 nodes, 30 words/cycle of global I/O, 20Kbyte of local memory per node, 3-4 words/cycle local communication bandwidth and single-issue processors for optimal performance. 5 Acknowledgements This work leverages the early work on grain size by Yeung, Dally, and Agarwal <ref> [5] </ref>. The research is funded by DARPA contract #DABT63-96-C-0036. We are also grateful to Tom Knight for many relevant discussions on cost modeling. A Applications
Reference: [6] <author> Charles L. Seitz, Nanette J. Boden, Jakov Seizovic, and Wen-King Su. </author> <title> The Design of the Caltech Mosaic C Multicomputer. </title> <booktitle> Research on Integrated Systems, Proceedings of the 1993 Symposium, </booktitle> <publisher> The MIT Press. </publisher> <address> Cambridge, Mas-sachusetts, </address> <year> 1993. </year> <pages> pp. 1-22. </pages>
Reference-contexts: It also captures the fact that it is easier to obtain performance close to the theoretical maximum cycles per instruction in lower-issue processors as they require a smaller amount of instruction-level parallelism in applications. Studying the layout of some simple RISC processors <ref> [6, 14, 13, 8] </ref> leads to a base cost of B p = 2:5 fi 10 5 transistor. That is, a minimal single issue 64 bit processor can be built in the area of 250K SRAM bits or with 250K logic transistors. <p> The base area for a router, B c is estimated at 2:5 fi 10 4 . We arrive at this from a study of simple routers <ref> [10, 9, 6, 15] </ref>. Examples of routers with the number of transistors used in current implementations are shown in Table 3. The The estimates using our communication cost model are also shown.
Reference: [7] <author> Hiroaki Nishi, Ken-ichiro Anjo, Tomohiro Ku-doh, Hideharu Amano. </author> <title> The RDT Router Chip: </title>
Reference-contexts: Examples of routers with the number of transistors used in current implementations are shown in Table 3. The The estimates using our communication cost model are also shown. The comparison indicates that our cost model reflects relatively accurately the area occupied by these routers except the RDT <ref> [7] </ref> router chip that has more than half of its area devoted to a multicast mechanism module and a bit-map generator. Global communication cost. We approximate global communication cost as a linear function of global off-chip communication capacity.
References-found: 7

