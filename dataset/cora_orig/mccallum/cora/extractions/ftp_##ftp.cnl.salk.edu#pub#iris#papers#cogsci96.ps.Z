URL: ftp://ftp.cnl.salk.edu/pub/iris/papers/cogsci96.ps.Z
Refering-URL: http://www.cnl.salk.edu/cgi-bin/pub-search/
Root-URL: 
Email: e-mail: iris@salk.edu  
Title: Dynamics of Rule Induction by Making Queries: Transition Between Strategies  
Author: Iris Ginzburg Terrence J. Sejnowski 
Address: 10010 N. Torrey Pines Rd. La Jolla, CA 92037  
Affiliation: Howard Hughes Medical Institute The Salk Institute  
Abstract: The induction of rules by making queries is a dynamical process based on seeking information. Experimenters typically look for one dominant strategy that is used by subjects, which may or may not agree with normative models of this psychological process. In this study we approach this problem from a different perspective, related to work in learning theory (see for example Baum 1991, Freund et al. 1995). Using information theory in a Bayesian framework, we estimated the information gained by queries when the task is to find a specific rule in a hypothesis space. Assuming that at each point subjects have a preferred working hypothesis, we considered several possible strategies, and determined the best one so that information gain is maximized at each step. We found that when the confidence in the preferred hypothesis is weak, "Confirmation Queries" result in maximum information gain; the information gained by "Investigation Queries" is higher when the confidence in the preferred hypothesis is high. Considering the dynamical process of searching for the rule, starting with low confidence in the preferred hypothesis and gradually raising confidence, there should be a transition from the "Confirmation Strategy" to the "Investigative Strategy", as the search proceeds. If we assume that subjects update their beliefs regarding the task, while performing, we would expect that the "Positive Confirmation Strategy" would yield more information at low confidence levels while the "Negative Confirmation Strategy" (simple elimination) would be more informative at higher confidence levels. We tested subjects performance in such a task, using a paradigm introduced by Wason (1960). All subjects first assumed a hypothesis and then made positive confirmation queries. Upon receiving confirmation, half the subjects presented negative confirmation queries and later, half switched into investigative queries before attempting to guess the experimenter's rule. Also, the frequency of queries in the more 'advanced' strategies went down as the confidence level required to evoke the strategy went up. We conclude that subjects appear to be using different strategies at different stages of the search, which is theoretically optimal when queries are guided by a paradigm that maximizes information gain at each step. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Baum E. </author> <year> (1991). </year> <title> Neural net algorithms that learn in polynomial time from examples and queries. </title> <journal> IEEE Trans. Neural Networks, </journal> <volume> 2 </volume> <pages> 5-19. </pages>
Reference: <author> Freund Y., Seung H.S., Shamir E. and Tishby N. </author> <year> (1995). </year> <title> Information, prediction, and query by committee. </title> <type> preprint. </type>
Reference-contexts: In order to do so, however, one needs to know the values of many hypotheses at each data point, an ability that requires a large memory capacity when dealing with a large space, see <ref> (Freund et al. 1995) </ref>. Since humans have a limited capacity for working memory, the strategies used by subjects will probably not be optimal, leading perhaps to the use of more than one strategy at different times, in a way that approximates the optimal strategy.
Reference: <author> Kahneman D. and Tversky A. </author> <year> (1974). </year> <title> Judgment under uncertainty: Heuristics and biases. </title> <publisher> Science, V185:1124-1131. </publisher>
Reference-contexts: In our theoretical analysis we assumed that the subjects updated their beliefs about the likelihood of receiving positive (or negative) answers during the task, which is equivalent to the presumed size of the target subset. This correlates with the anchoring effect <ref> (Kahneman and Tversky, 1974) </ref>: information that is explicitly not relevant to the task subjects are required to perform still affects the behavior of subjects. Acknowldgments I.G. is grateful to W. Bialek for motivating this study and to C. McKenzie for interesting and helpful discussions.
Reference: <author> Klayman J. and Ha Y-W. </author> <year> (1987). </year> <title> Confirmation, dis-confirmation, and information in hypothesis testing. </title> <journal> Psychological Review, V94. </journal> <volume> No 2.211-228. </volume>
Reference-contexts: More recent studies <ref> (Klayman & Ha, 1987) </ref>, (Oaksford & Chater, 1994) suggested that under some conditions it may be better to use a confirmation strategy rather than the disproving one.
Reference: <author> Oaksford M. and Chater N. </author> <year> (1994). </year> <title> A rational analysis of the selection task as optimal data selection. </title> <journal> Psychological Review, V101 (n4):608-631. </journal>
Reference-contexts: More recent studies (Klayman & Ha, 1987), <ref> (Oaksford & Chater, 1994) </ref> suggested that under some conditions it may be better to use a confirmation strategy rather than the disproving one.
Reference: <author> Van Wallendaeland L. R. and Hastie R. </author> <year> (1990). </year> <title> Tracing the footsteps of Sherlock Holmes: Cognitive representations of hypothesis testing. Memory & Cognition, </title> <publisher> V18 (n3):240-250. </publisher>
Reference-contexts: In addition, one can easily show, using the paradigm we have presented, that as the hypothesis space becomes larger, it is less valuable to consider alternative hypotheses. Evidence for this notion was found by <ref> (Van Wal-lendaeland and Hastie, 1990) </ref> who showed that when the number of possible alternative hypotheses was large, subjects tended to update their beliefs regarding one working hypothesis only.
Reference: <author> Wason P.C. </author> <year> (1960). </year> <title> On the failure to eliminate hypotheses in a conceptual task. </title> <journal> Quarterly Journal of Experimental Psychology, </journal> <month> V12 129-140. </month> <title> level. n is the number of queries that correspond to each strategy. The error bars represent the standard deviation of the distributions and not the deviations of the means. that correspond to each strategy. The error bars represent the standard deviation of the distributions and not the deviations of the means. </title>
References-found: 7

