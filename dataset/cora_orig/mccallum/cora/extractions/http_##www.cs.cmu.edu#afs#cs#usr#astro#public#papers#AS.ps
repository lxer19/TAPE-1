URL: http://www.cs.cmu.edu/afs/cs/usr/astro/public/papers/AS.ps
Refering-URL: http://www.cs.bham.ac.uk/~wbl/biblio/gp-bibliography.html
Root-URL: 
Title: Neural Programming and an Internal Reinforcement Policy  
Author: Astro Teller and Manuela Veloso 
Address: Pittsburgh PA 15213, USA  
Affiliation: Carnegie Mellon University,  
Abstract: An important reason for the continued popularity of Artificial Neural Networks (ANNs) in the machine learning community is that the gradient-descent backpropagation procedure gives ANNs a locally optimal change procedure and, in addition, a framework for understanding the ANN learning performance. Genetic programming (GP) is also a successful evolutionary learning technique that provides powerful parameterized primitive constructs. Unlike ANNs, though, GP does not have such a principled procedure for changing parts of the learned system based on its current performance. This paper introduces Neural Programming, a connectionist representation for evolving programs that maintains the benefits of GP. The connectionist model of Neural Programming allows for a regression credit-blame procedure in an evolutionary learning system. We describe a general method for an informed feedback mechanism for Neural Programming, Internal Reinforcement. We introduce an Internal Reinforcement procedure and demon strate its use through an illustrative experiment.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> L. Altenberg. </author> <title> The evolution of evolvability in genetic programming. </title> <editor> In Jr. Kenneth E. Kinnear, editor, </editor> <booktitle> Advances In Genetic Programming, </booktitle> <pages> pages 4774. </pages> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: In brief, ANN is a successful representative of the machine learning practice of explicit credit-assignment. GP is a successful representative of empirical credit-assignment [2]. Empirical credit-assignment is the machine learning practice of allowing the dynamics of the system to implicitly determine credit and blame. Evolution does just this <ref> [1] </ref>. The goal of this work is to begin to bridge this credit-assignment gap by finding ways in which explicit and empirical credit-assignment can find mutual benefit in a single machine learning technique.
Reference: 2. <author> P. Angeline. </author> <title> Evolutionary Algorithms and Emergent Intelligence. </title> <type> PhD thesis, </type> <institution> Ohio State University, Department of Computer Science, </institution> <year> 1993. </year>
Reference-contexts: In brief, ANN is a successful representative of the machine learning practice of explicit credit-assignment. GP is a successful representative of empirical credit-assignment <ref> [2] </ref>. Empirical credit-assignment is the machine learning practice of allowing the dynamics of the system to implicitly determine credit and blame. Evolution does just this [1].
Reference: 3. <author> P. Angeline. </author> <title> Two self-adaptive crossover operators for genetic programming. </title> <editor> In P. Angeline and K. Kinnear, editors, </editor> <booktitle> Advances in Genetic Programming 2. </booktitle> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: Some work, has, however, been done in these areas. [8] describes a process for trying to find sub-functions in an evolving GP function that are more likely than randomly selected ones to contribute positively to fitness when crossed-over into other programs. <ref> [3] </ref> and [5] describe possible approaches for allowing the mechanism of evolution to ? This work is supported in part through an ONR Muri grant and the first author is supported through the generosity of the Hertz Foundation. provide self-adaptation all the way down to the single node level. <p> Traditional GP uses random crossover and relies entirely on the mechanism of empirical credit assignment. Work has been done to boot-strap this mechanism by using the evolutionary process itself to evolve improved crossover procedures (e.g. <ref> [3, 12] </ref>). Thus, NP has the potential not only to improve on the existing GP mechanism, but also to help explain the central mystery of GP, crossover. Mutation can take a variety of forms in NP.
Reference: 4. <author> F. Dellaert and R.D. Beer. </author> <title> Co-evolving body and brain in autonomous agents using a developmental model. </title> <note> In Technical Report CES-94-16, </note> <institution> Department of Computer Engineering and Science. Case Western Reserve University, Cleveland, OH 44106, </institution> <year> 1994. </year>
Reference-contexts: Both GP [6] and ANNs [9] continue to be well investigated fields. In ANNs, the focus on improving the power of the technique has not been on changing what is inside an artificial neuron. Works like <ref> [4, 10] </ref> have, however, investigated the possible additional benefit of complicating and un-homogenizing artificial neurons.
Reference: 5. <editor> L. Fogel, P. Angeline, and D. Fogel. </editor> <title> An evolutionary programming approach to self-adaptation on finite state machines. </title> <editor> In J. McDonnell, R. Reynolds, and D. Fogel, editors, </editor> <booktitle> Proceedings of the 4th Annual Conference on Evolutionary Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: Some work, has, however, been done in these areas. [8] describes a process for trying to find sub-functions in an evolving GP function that are more likely than randomly selected ones to contribute positively to fitness when crossed-over into other programs. [3] and <ref> [5] </ref> describe possible approaches for allowing the mechanism of evolution to ? This work is supported in part through an ONR Muri grant and the first author is supported through the generosity of the Hertz Foundation. provide self-adaptation all the way down to the single node level.
Reference: 6. <editor> J. Koza. </editor> <booktitle> Genetic Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: This new representation, Neural Programming (NP) has been developed with the goal of incorporating positive aspects of both artificial neural networks and genetic programming. Neural Programming is a connectionist programming language that has been designed to make internal reinforcement, hither-to unaccomplished in genetic programming, possible. Both GP <ref> [6] </ref> and ANNs [9] continue to be well investigated fields. In ANNs, the focus on improving the power of the technique has not been on changing what is inside an artificial neuron. Works like [4, 10] have, however, investigated the possible additional benefit of complicating and un-homogenizing artificial neurons.
Reference: 7. <editor> J. Koza. </editor> <booktitle> Genetic Programming 2. </booktitle> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: This kind of embedding of complex (often co-evolved) components as primitives in the evolving GP system has repeated shown to be effective (e.g., <ref> [7] </ref>) and is an important reason for trying to find a compromise between GP and ANNs. Furthermore, these powerful input-access-primitives, as part of the learning process, can be used in place of brittle preprocessing. <p> In the parley of GP, this can be seen as a kind of highly flexible automatically defined function (ADF) <ref> [7] </ref> mechanism. This fan-out is a connectionist advantage that GP programs might profit by incorporating. Neural Programming was designed to be a representation for evolving programs. As such, there are two dominate forms of change that evolving programs typically undergo: crossover and mutation.
Reference: 8. <author> J. Rosca and D. Ballard. </author> <title> Discovery of subroutines in genetic programming. </title> <editor> In P. Angeline and K. E. Kinnear, Jr., editors, </editor> <booktitle> Advances in Genetic Programming 2. </booktitle> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: In GP, the focus of investigation for increased power of the technique has not been on changing the GP representation or on finding principled (non-random) update policies. Some work, has, however, been done in these areas. <ref> [8] </ref> describes a process for trying to find sub-functions in an evolving GP function that are more likely than randomly selected ones to contribute positively to fitness when crossed-over into other programs. [3] and [5] describe possible approaches for allowing the mechanism of evolution to ? This work is supported in
Reference: 9. <author> D.E. Rumelhart, G.E. Hinton, and R.J Williams. </author> <title> Learning internal represenations by error propogation. In Parallel Distributed Processing. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, USA, </address> <year> 1986. </year>
Reference-contexts: Neural Programming is a connectionist programming language that has been designed to make internal reinforcement, hither-to unaccomplished in genetic programming, possible. Both GP [6] and ANNs <ref> [9] </ref> continue to be well investigated fields. In ANNs, the focus on improving the power of the technique has not been on changing what is inside an artificial neuron. Works like [4, 10] have, however, investigated the possible additional benefit of complicating and un-homogenizing artificial neurons.
Reference: 10. <author> K. Sharman, A. Alcazar, and Y. Li. </author> <title> Evolving signal processing algorithms by genetic programming. </title> <booktitle> In First International Conference on Genetic Algorithms in Engineering Systems: Innovations and Applications, GALESIA, </booktitle> <year> 1995. </year>
Reference-contexts: Both GP [6] and ANNs [9] continue to be well investigated fields. In ANNs, the focus on improving the power of the technique has not been on changing what is inside an artificial neuron. Works like <ref> [4, 10] </ref> have, however, investigated the possible additional benefit of complicating and un-homogenizing artificial neurons.
Reference: 11. <author> A. Teller. </author> <title> The evolution of mental models. </title> <editor> In Kenneth E. Kinnear, editor, </editor> <booktitle> Advances In Genetic Programming, pages 199220. </booktitle> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: This is a network flow style program! 2 These memory functions manipulate an indexed, randomly addressable memory <ref> [11] </ref>. * One of the possible node functions is OUTPUT. OUTPUT nodes are responsible for contributing, through a function F 1 of the inputs and the time, to the program's response collected in OutputTotal. * There can be multiple OUTPUT nodes in one program (as determined by evolu tion).
Reference: 12. <author> A. Teller. </author> <title> Evolving programmers: The co-evolution of intelligent recombination operators. </title> <editor> In K. Kinnear and P. Angeline, editors, </editor> <booktitle> Advances in Genetic Programming 2. </booktitle> <publisher> MIT, </publisher> <year> 1996. </year>
Reference-contexts: For the sake of brevity and clarity, this paper will focus on only one technique for each of the two stages. The evolved NP programs that we consider now are part of the PADO system (described in <ref> [12, 13, 14] </ref>). For the purpose of this paper, it is sufficient to know that PADO is a machine learning system designed for signal classification. <p> Traditional GP uses random crossover and relies entirely on the mechanism of empirical credit assignment. Work has been done to boot-strap this mechanism by using the evolutionary process itself to evolve improved crossover procedures (e.g. <ref> [3, 12] </ref>). Thus, NP has the potential not only to improve on the existing GP mechanism, but also to help explain the central mystery of GP, crossover. Mutation can take a variety of forms in NP.
Reference: 13. <author> A. Teller and M. Veloso. </author> <title> Program evolution for data mining. </title> <editor> In Sushil Louis, editor, </editor> <booktitle> The International Journal of Expert Systems. Third Quarter. Special Issue on Genetic Algorithms and Knowledge Bases., </booktitle> <pages> pages 216236. </pages> <publisher> JAI Press, </publisher> <year> 1995. </year>
Reference-contexts: For the sake of brevity and clarity, this paper will focus on only one technique for each of the two stages. The evolved NP programs that we consider now are part of the PADO system (described in <ref> [12, 13, 14] </ref>). For the purpose of this paper, it is sufficient to know that PADO is a machine learning system designed for signal classification.
Reference: 14. <author> A. Teller and M. Veloso. </author> <title> PADO: A new learning architecture for object recognition. </title> <editor> In K. Ikeuchi and M. Veloso, editors, </editor> <title> Symbolic Visual Learning. </title> <publisher> Oxford University Press, </publisher> <year> 1996. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: For the sake of brevity and clarity, this paper will focus on only one technique for each of the two stages. The evolved NP programs that we consider now are part of the PADO system (described in <ref> [12, 13, 14] </ref>). For the purpose of this paper, it is sufficient to know that PADO is a machine learning system designed for signal classification.
References-found: 14

