URL: file://ftp.netlib.org/lapack/lawns/lawn79.ps
Refering-URL: 
Root-URL: 
Title: PARALLELIZING THE QR ALGORITHM FOR THE UNSYMMETRIC ALGEBRAIC EIGENVALUE PROBLEM: MYTHS AND REALITY  
Author: GREG HENRY AND ROBERT VAN DE GEIJN 
Abstract: Over the last few years, it has been suggested that the popular QR algorithm for the unsymmetric eigenvalue problem does not parallelize. In this paper, we present both positive and negative results on this subject: In theory, asymptotically perfect speedup can be obtained. In practice, reasonable speedup can be obtained on a MIMD distributed memory computer, for a relatively small number of processors. However, we also show theoretically that it is impossible for the standard QR algorithm to be scalable. Performance of a parallel implementation of the LAPACK DLAHQR routine on the Intel Paragon TM system is reported. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Anderson, E., Bai, Z., Bischof, C., Demmel, J., Dongarra, J., Du Croz, J., Greenbaum, A., Hammarling, S., McKenney, A., Sorenson, D., </author> <title> LAPACK Users' Guide, </title> <publisher> SIAM Publications, </publisher> <address> Philadelphia, PA, </address> <year> 1992 </year>
Reference-contexts: Finally, we show that these techniques can indeed be incorporated into a real code by giving details of a prototype distributed memory implementation of the serial algorithm DLAHQR <ref> [1] </ref>, the LAPACK version of the double implicit shifted QR algorithm. Full functionality of the LAPACK code can be supported. That is, the techniques can be extended to allow for the cases of computing the Schur vectors, computing the Schur decomposition of H, or just computing the eigenvalues alone. <p> Nonetheless, our model gives us insight. 4. Performance Results. In this section, we report the performance of a prototype working implementation of the described parallel implementation. Our implementation is a paral-lelization of the LAPACK <ref> [1] </ref> routine DLAHQR, and is mathematically exact except that the sequential routine applies one final rotation per converged eigenpair so that the resulting "Schur" form has some regularity.
Reference: [2] <author> Auslander, L., Tsao, A., </author> <title> On Parallelizable Eigensolvers, </title> <journal> Advanced Appl. Math., </journal> <volume> Vol. 13, </volume> <pages> pp. 253-261, </pages> <year> 1992 </year>
Reference-contexts: 1. Introduction. Distributed memory parallel algorithms for the unsymmetric eigenvalue problem have been allusive. There are several matrix multiply-based methods currently being studied. Auslander and Tsao <ref> [2] </ref> and Lederman, Tsao, and Turnbull [24] have a matrix multiply-based parallel algorithm, which uses a polynomial mapping of the eigenvalues. Bai and Demmel [4] have another parallel algorithm based on bisection with the matrix sign function.
Reference: [3] <author> Bai, Z., Demmel, J., </author> <title> On a Block Implementation of Hessenberg Multishift QR Iteration, </title> <journal> International Journal of High Speed Computing, </journal> <volume> Vol. 1, </volume> <pages> pp. 97-112, </pages> <year> 1989 </year>
Reference-contexts: There have also been attempts at improving data reuse by increasing the number of shifts either by using a multi-implicited shifted QR algorithm <ref> [3] </ref> or pipelining several double shifts simultaneously [31, 32].
Reference: [4] <author> Bai, Z., Demmel, J., </author> <title> Design of a Parallel Nonsymmetric Eigenroutine Toolbox, Part I, Parallel Processing for Scientific Computing, </title> <editor> Editors R. Sincovec, D. Keyes, M. Leuze, L. Petzold, and D. Reed, </editor> <publisher> SIAM Publications, </publisher> <address> Philadelphia, PA, </address> <year> 1993 </year>
Reference-contexts: 1. Introduction. Distributed memory parallel algorithms for the unsymmetric eigenvalue problem have been allusive. There are several matrix multiply-based methods currently being studied. Auslander and Tsao [2] and Lederman, Tsao, and Turnbull [24] have a matrix multiply-based parallel algorithm, which uses a polynomial mapping of the eigenvalues. Bai and Demmel <ref> [4] </ref> have another parallel algorithm based on bisection with the matrix sign function. Matrix tearing methods for finding the eigensystem of an unsymmetric Hessenberg matrix have been proposed by Dongarra and Sidani [9]. <p> We caution the reader against misinterpreting the results in this paper as largely supporting the notion that new methods like those developed by Bai and Demmel <ref> [4] </ref> and Dongarra and Sidani [9] must be pursued if nonsymmetric eigenvalue problems are to be solved on massively parallel computers. Let us address some of the arguments that can be made to support such an interpretation and how these arguments are somewhat unsatisfactory.
Reference: [5] <author> Berry, M. W., Dongarra, J. J., and Kim, Y., </author> <title> A Highly Parallel Algorithm for the Reduction of a Nonsymmetric Matrix to Block Upper-Hessenberg Form, </title> <note> LAPACK working note 68, </note> <institution> University of Tennessee, CS-94-221, </institution> <month> Feb. </month> <year> 1994 </year>
Reference-contexts: We assume for simplicity that our initial matrix H is Hessenberg. The parallelization of the reduction to Hessenberg form is a well understood problem, and unlike the eigenvalue problem, the Hessenberg reduction has been shown to parallelize well <ref> [5, 10] </ref>. One step of the Francis double shift Schur decomposition is in Figure 1. <p> Examples include the standard decomposition algorithms, like LU, QR, and Cholesky factorization [11, 16], as well as the reduction to condensed form required for reducing a general matrix to upper Hessenberg form <ref> [5, 10] </ref>. It is therefore natural to try to reformulate the parallel QR algorithm in an attempt to extract an algorithm that has better scalability properties.
Reference: [6] <author> Boley, D., </author> <title> Solving the Generalized Eigenvalue Problem on a Synchronous Linear Processor Array, </title> <journal> Parallel Computing, </journal> <volume> Vol. 3, </volume> <pages> pp. 123-166, </pages> <year> 1986 </year>
Reference: [7] <author> Boley., D., Maier, R., </author> <title> A Parallel QR Algorithm for the Nonsymmetric Eigenvalue Problem, </title> <institution> Univ. of Minn., Dept. of Computer Science, </institution> <type> Technical Report TR-88-12, </type> <year> 1988 </year>
Reference-contexts: There have also been attempts at improving data reuse by increasing the number of shifts either by using a multi-implicited shifted QR algorithm [3] or pipelining several double shifts simultaneously [31, 32]. A number of attempts at parallelizing the QR algorithm have been made (see Boley and Maier <ref> [7] </ref>, Geist, Ward, Davis, and Funderlic [14], and Stewart [27].) Distributing the work evenly amongst the processors has proven difficult for conventional storage schemes, especially when compared to the parallel solution of dense linear systems [22, 23]. Communication also becomes a more significant bottleneck for the parallel QR algorithm.
Reference: [8] <author> Demmel, J. W., </author> <title> LAPACK Working Note 47: Open Problems in Numerical Linear Algebra, </title> <institution> University of Tennessee, </institution> <type> Technical Report CS-92-164, </type> <month> May </month> <year> 1992 </year>
Reference: [9] <author> Dongarra, J. J., and Sidani, M., </author> <title> A Parallel Algorithm for the Nonsymmetric Eigenvalue Problem, </title> <type> Technical Report Number ORNL/TM-12003, ORNL, </type> <institution> Oak Ridge Tennessee, </institution> <year> 1991 </year>
Reference-contexts: Bai and Demmel [4] have another parallel algorithm based on bisection with the matrix sign function. Matrix tearing methods for finding the eigensystem of an unsymmetric Hessenberg matrix have been proposed by Dongarra and Sidani <ref> [9] </ref>. These involve doing a rank one change to the Hessenberg matrix to make two separate submatrices and then finding the eigenpairs of each submatrix, followed by performing Newton's method on these values to find the solution to the original problem. <p> We caution the reader against misinterpreting the results in this paper as largely supporting the notion that new methods like those developed by Bai and Demmel [4] and Dongarra and Sidani <ref> [9] </ref> must be pursued if nonsymmetric eigenvalue problems are to be solved on massively parallel computers. Let us address some of the arguments that can be made to support such an interpretation and how these arguments are somewhat unsatisfactory. No parallelism exists in the nonsymmetric QR algorithm.
Reference: [10] <author> Dongarra, J. J., van de Geijn, R. A., </author> <title> Reduction to Condensed Form on Distributed Memory Architectures, </title> <journal> Parallel Computing, </journal> <volume> 18, </volume> <pages> pp. 973-982, </pages> <year> 1992. </year>
Reference-contexts: We assume for simplicity that our initial matrix H is Hessenberg. The parallelization of the reduction to Hessenberg form is a well understood problem, and unlike the eigenvalue problem, the Hessenberg reduction has been shown to parallelize well <ref> [5, 10] </ref>. One step of the Francis double shift Schur decomposition is in Figure 1. <p> Examples include the standard decomposition algorithms, like LU, QR, and Cholesky factorization [11, 16], as well as the reduction to condensed form required for reducing a general matrix to upper Hessenberg form <ref> [5, 10] </ref>. It is therefore natural to try to reformulate the parallel QR algorithm in an attempt to extract an algorithm that has better scalability properties.
Reference: [11] <author> Dongarra, J. J., van de Geijn, R. A., and Walker, D. </author> , <title> Scalability Issues Affecting the Design of a Dense Linear Algebra Library, </title> <journal> Journal of Parallel and Distributed Computing,Vol. </journal> <volume> 22, No. 3, </volume> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: Theoretical Limitations. For many dense linear algebra algorithms, better scalability can be obtained by using a so-called two dimensional data decomposition. Examples include the standard decomposition algorithms, like LU, QR, and Cholesky factorization <ref> [11, 16] </ref>, as well as the reduction to condensed form required for reducing a general matrix to upper Hessenberg form [5, 10]. It is therefore natural to try to reformulate the parallel QR algorithm in an attempt to extract an algorithm that has better scalability properties.
Reference: [12] <author> Eberlein, P. J., </author> <title> On the Schur Decomposition of a Matrix for Parallel Computation, </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. C-36, </volume> <pages> pp. 167-174, </pages> <year> 1987 </year>
Reference: [13] <author> Francis, J. G. F., </author> <title> The QR Transformation: A Unitary Analogue to the LR Transformation, Parts I and II, </title> <journal> Comp. J., </journal> <volume> Vol. 4, </volume> <pages> pp. 332-345, </pages> <year> 1961 </year>
Reference-contexts: They suffer from requiring more floating point operations (flops) and/or yield a loss of accuracy when compared to efficient implementations of the QR algorithm. Efficient sequential (and shared memory parallel) implementations of the QR algorithm use a blocked version of the Francis double implicit shifted algorithm <ref> [13] </ref> or a variant thereof [20]. There have also been attempts at improving data reuse by increasing the number of shifts either by using a multi-implicited shifted QR algorithm [3] or pipelining several double shifts simultaneously [31, 32].
Reference: [14] <author> Geist, G.A., Ward, R.C., Davis, G.J., Funderlic, R.E., </author> <title> Finding Eigenvalues and Eigenvectors of Unsym-metric Matrices using a Hypercube Multiprocessor, </title> <booktitle> Proceedings of the Third Conference on Hypercube Concurrent Computers and Applications, </booktitle> <editor> Editor G. </editor> <booktitle> Fox, </booktitle> <pages> pp. 1577-1582, </pages> <year> 1988 </year>
Reference-contexts: A number of attempts at parallelizing the QR algorithm have been made (see Boley and Maier [7], Geist, Ward, Davis, and Funderlic <ref> [14] </ref>, and Stewart [27].) Distributing the work evenly amongst the processors has proven difficult for conventional storage schemes, especially when compared to the parallel solution of dense linear systems [22, 23]. Communication also becomes a more significant bottleneck for the parallel QR algorithm.
Reference: [15] <author> Golub, G., Van Loan, C., F., </author> <title> Matrix Computations, 2nd Ed., 1989, </title> <publisher> The John Hopkins University Press. </publisher>
Reference-contexts: Since deflation occurs less frequently in the beginning than the end, our overall model satisfies: Overall Flops = n X 3 fl 20k 2 = 20n 3 ; where 3 is a heuristic fudge factor. Compare, for example, <ref> [15] </ref> which uses a similar heuristic, but different fudge factor, to suggest overall flops at 25n 3 . Similarly, we can extend any of the formulas in the previous subsection. In Equation 4, the number of communication start-ups is n + 2n=h.
Reference: [16] <author> Hendrickson, B.A., Womble, D.E., </author> <title> The torus-wrap mapping for dense matrix calculations on massively parallel computers., </title> <note> SIAM J. </note> <institution> Sci. Stat. Comput., </institution> <year> 1994 </year>
Reference-contexts: Theoretical Limitations. For many dense linear algebra algorithms, better scalability can be obtained by using a so-called two dimensional data decomposition. Examples include the standard decomposition algorithms, like LU, QR, and Cholesky factorization <ref> [11, 16] </ref>, as well as the reduction to condensed form required for reducing a general matrix to upper Hessenberg form [5, 10]. It is therefore natural to try to reformulate the parallel QR algorithm in an attempt to extract an algorithm that has better scalability properties.
Reference: [17] <author> Henry, G., </author> <title> Improving the Unsymmetric Parallel QR Algorithm on Vector Machines, </title> <booktitle> SIAM 6th Parallel Conference Proceedings, </booktitle> <pages> 3/93 </pages>
Reference-contexts: This is repeated n=r times, and border information must be communicated every h transformations, giving a (very rough) total estimated time of 20 p fl + Cnfl + 40nfl + n ff + 3nfi + 2 h n 2 fi + O (1): 1 As is noted in Henry <ref> [17, 20] </ref>, the minimal information needed to determine the upcoming transforms is roughly eighty percent of the total flops required to actually complete the entire update in region "1" of Figure 3.
Reference: [18] <author> Henry, G., </author> <title> Increasing Data Reuse in the Unsymmetric QR Algorithm, </title> <note> Theory Center Technical Report, CTC92TR100, 7/92 </note>
Reference: [19] <author> Henry, G., </author> <title> A New Approach to the Schur Decomposition, </title> <note> Theory Center Technical Report in Progress </note>
Reference-contexts: This "partial" step is referred to as a lookahead step and can also be used to determine better shifts (cf. Henry <ref> [19] </ref>.) Clearly the above estimate is only a rough estimate: It suggests that increasing bundling factor r arbitrarily will continue to improve total time. Notice that this estimate is only reasonable when the pipe is undisturbed.
Reference: [20] <author> Henry, G., </author> <title> Improving Data Re-Use in Eigenvalue-Related Computations, </title> <type> Ph.D. Thesis, </type> <institution> Cornell University, </institution> <month> January </month> <year> 1994 </year>
Reference-contexts: Efficient sequential (and shared memory parallel) implementations of the QR algorithm use a blocked version of the Francis double implicit shifted algorithm [13] or a variant thereof <ref> [20] </ref>. There have also been attempts at improving data reuse by increasing the number of shifts either by using a multi-implicited shifted QR algorithm [3] or pipelining several double shifts simultaneously [31, 32]. <p> This is repeated n=r times, and border information must be communicated every h transformations, giving a (very rough) total estimated time of 20 p fl + Cnfl + 40nfl + n ff + 3nfi + 2 h n 2 fi + O (1): 1 As is noted in Henry <ref> [17, 20] </ref>, the minimal information needed to determine the upcoming transforms is roughly eighty percent of the total flops required to actually complete the entire update in region "1" of Figure 3.
Reference: [21] <author> Ipsen, I.C.F., Saad, Y., </author> <title> The Impact of Parallel Architectures on the Solution of Eigenvalue Problems, Large Scale Eigenvalue Problems, </title> <editor> Editors J. Cullum and R. Willoughby, </editor> <publisher> Elsevier Science Publishers, </publisher> <year> 1986 </year>
Reference: [22] <author> Ipsen, I.C.F., Saad, Y., Schultz, M. H., </author> <title> Complexity of Dense-Linear-System Solution on a Multiprocessor Ring, </title> <journal> Linear Algebra and its Applications, </journal> <volume> Vol. 77, </volume> <pages> pp. 205-239, </pages> <year> 1986 </year>
Reference-contexts: number of attempts at parallelizing the QR algorithm have been made (see Boley and Maier [7], Geist, Ward, Davis, and Funderlic [14], and Stewart [27].) Distributing the work evenly amongst the processors has proven difficult for conventional storage schemes, especially when compared to the parallel solution of dense linear systems <ref> [22, 23] </ref>. Communication also becomes a more significant bottleneck for the parallel QR algorithm. As noted by van de Geijn [29] and van de Geijn and Hudson [30], the use of a block Hankel-wrapped storage scheme can alleviate some of the problems involved in parallelizing the QR algorithm.
Reference: [23] <author> Juszczak, J.W., van de Geijn, R.A., </author> <title> An Experiment in Coding Portable Parallel Matrix Algorithms, </title> <booktitle> Proceedings of the Fourth Conference on Hypercube Concurrent Computers and Applications, </booktitle> <year> 1989 </year>
Reference-contexts: number of attempts at parallelizing the QR algorithm have been made (see Boley and Maier [7], Geist, Ward, Davis, and Funderlic [14], and Stewart [27].) Distributing the work evenly amongst the processors has proven difficult for conventional storage schemes, especially when compared to the parallel solution of dense linear systems <ref> [22, 23] </ref>. Communication also becomes a more significant bottleneck for the parallel QR algorithm. As noted by van de Geijn [29] and van de Geijn and Hudson [30], the use of a block Hankel-wrapped storage scheme can alleviate some of the problems involved in parallelizing the QR algorithm.
Reference: [24] <author> Lederman, S., Tsao, A., Turnbull, T., </author> <title> A parallelizable eigensolver for real diagonalizable matrices with real eigenvalues, </title> <type> Technical Report TR-91-042, </type> <institution> Supercomputing Research Center, </institution> <year> 1991 </year>
Reference-contexts: 1. Introduction. Distributed memory parallel algorithms for the unsymmetric eigenvalue problem have been allusive. There are several matrix multiply-based methods currently being studied. Auslander and Tsao [2] and Lederman, Tsao, and Turnbull <ref> [24] </ref> have a matrix multiply-based parallel algorithm, which uses a polynomial mapping of the eigenvalues. Bai and Demmel [4] have another parallel algorithm based on bisection with the matrix sign function.
Reference: [25] <author> Moler, C.B., </author> <title> MATLAB User's Guide Technical Report CS81-1, </title> <institution> Department of Computer Science, University of New Mexico, </institution> <address> Albuquerque, New Mexico, </address> <year> 1980 </year>
Reference: [26] <author> Purkayastha, A., </author> <title> A Parallel algorithm for the Sylvester-Observer Equations, </title> <type> Ph.D. dissertation, </type> <institution> Northern Illinois University, DeKalb, Illinois, </institution> <month> Jan. </month> <year> 1993 </year>

Reference: [31] <author> Watkins, D., </author> <title> Shifting strategies for the parallel QR algorithm, </title> <journal> SIAM J. Sci. Comput., </journal> <volume> Vol. 15, </volume> <month> July </month> <year> 1994 </year>
Reference-contexts: There have also been attempts at improving data reuse by increasing the number of shifts either by using a multi-implicited shifted QR algorithm [3] or pipelining several double shifts simultaneously <ref> [31, 32] </ref>.
Reference: [32] <author> Watkins, D., </author> <title> Transmission of shifts in the multishift QR algorithm, </title> <booktitle> Proceedings of the 5th SIAM Conference on Applied Linear Algebra, </booktitle> <address> Snowbird, Utah, </address> <month> June </month> <year> 1994 </year>
Reference-contexts: There have also been attempts at improving data reuse by increasing the number of shifts either by using a multi-implicited shifted QR algorithm [3] or pipelining several double shifts simultaneously <ref> [31, 32] </ref>.
Reference: [33] <author> Wilkinson, J.H., </author> <title> The Algebraic Eigenvalue Problem, </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1965 </year>
References-found: 29

