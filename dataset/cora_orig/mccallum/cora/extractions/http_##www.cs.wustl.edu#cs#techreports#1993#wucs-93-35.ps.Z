URL: http://www.cs.wustl.edu/cs/techreports/1993/wucs-93-35.ps.Z
Refering-URL: http://www.cs.wustl.edu/cs/cs/publications.html
Root-URL: 
Title: A Unified Model for Shared-Memory and Message-Passing Systems  
Author: Kenneth Goldman and Katherine Yelick 
Address: Campus Box 1045 One Brookings Drive Saint Louis, MO 63130-4899  
Affiliation: Department of Computer Science Washington University  
Date: June 1993  
Pubnum: WUCS-93-35  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Anant Agarwal, David Chaiken, Godfrey D'Souza, Kirk Johnson, David Kranz, John Kubi-atowicz, Kiyoshi Kurihara, Beng-Hong Lim, Gino Maa, Dan Nussbaum, Mike Parkin, and Donald Yeung. </author> <title> The mit alewife machine: A large-scale distributed-memory multiprocessor. </title> <booktitle> In Proceedings of Workshop on Scalable Shared Memory Multiprocessors. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year>
Reference-contexts: In addition, a unified model provides the ability to describe systems that use both shared memory and message passing communication. For example, systems like the Alewife multiprocessor <ref> [1] </ref> or the Split-C language [5] implement a global shared memory abstraction using a combination of message passing between processors and shared memory accesses between threads (or handlers) on a single processor. Reasoning about the behavior of these systems requires a mixture of shared memory and message passing semantics.
Reference: [2] <author> Hagit Attiya and Jennifer L. Welch. </author> <title> Sequential consistency versus linearizability. </title> <type> Technical Report 694, </type> <institution> Technion, Department of Computer Science, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: We begin, in Section 4.1 by describing the basic architecture of an invocation-response system, including the interfaces and specification mechanisms for the objects and processes. Then, in 5 A comparison of sequential consistency and linearizability is given by Attiya and Welch <ref> [2] </ref>. 17 Section 4.2, we describe three systems: a concurrent system, a sequential system, and an atomic system. All three systems are described in the I/O automaton model.
Reference: [3] <author> Andrew Birrell, John Guttag, Jim Horning, and Roy Levin. </author> <title> Synchronization primitives for a multiprocessor: A formal specification. </title> <type> Technical Report 20, </type> <institution> Digital Equipment Corporation Stanford Research Center, </institution> <month> August </month> <year> 1987. </year>
Reference-contexts: One such x becomes the current state of O following the operation, and r is returned by the operation. For arguments a and states x 0 for which P (a; x 0 ) does not hold, the new state and return value are unspecified. In Larch specifications <ref> [3] </ref>, this information is conveniently represented in the following way: = proc (a:args ()) returns (r:rets ()) requires: P (a; x 0 ) ensures: Q (a; x 0 ; x; r) Having defined a sequential specification, we now wish to define what it means for the object automata of System C
Reference: [4] <author> K. Mani Chandy and Jayadev Misra. </author> <title> A Foundation of Parallel Program Design. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1988. </year>
Reference-contexts: Examples include CSP [9], in which system components communicate by sending messages over synchronous channels, and UNITY <ref> [4] </ref>, in which components communicate by reading and modifying shared variables. The I/O automaton model [15, 16] is particularly well-suited for modelling distributed algorithms described using message passing. <p> We begin by defining a special type of action called a "shared memory action" that will be used to model accesses to the shared variables. In some sense, this is the reverse of what is often done to incorporate message passing into a shared memory model. In UNITY <ref> [4] </ref>, for example, shared queue variables are declared to model "channels" and atomic accesses to these shared queues model "sending" and "receiving" data across the channels. However, we emphasize that we do not implement shared memory on top of message passing.
Reference: [5] <author> David E. Culler, Andrea Dusseau, Seth C. Goldstein, Arvind Krishnamurthy, Steven Lumetta, Thorsten von Eicken, and Katherine Yelick. </author> <note> Parallel programming in split-c. Submitted for publication, </note> <year> 1993. </year>
Reference-contexts: In addition, a unified model provides the ability to describe systems that use both shared memory and message passing communication. For example, systems like the Alewife multiprocessor [1] or the Split-C language <ref> [5] </ref> implement a global shared memory abstraction using a combination of message passing between processors and shared memory accesses between threads (or handlers) on a single processor. Reasoning about the behavior of these systems requires a mixture of shared memory and message passing semantics.
Reference: [6] <author> G. A. Geist and V. S. Sunderam. </author> <title> The PVM system: Supercomputer level concurrent computation on a heterogeneous network of workstations. </title> <booktitle> In Sixth Annual Distributed-Memory Computer Conference, </booktitle> <pages> pages 258-261, </pages> <year> 1991. </year>
Reference-contexts: Within a multiprocessor, communication may be done using shared memory, while communicating across the network involves message passing. Numerous examples of systems exist to support such heterogeneous network computing, with one of the most popular being PVM <ref> [6] </ref>. Perhaps one of the most important benefits of a unified model is that of providing a context in which to understand and prove correspondences between shared memory and message passing systems.
Reference: [7] <author> Kenneth Goldman and Nancy Lynch. </author> <title> Modelling shared state in a shared action model. </title> <booktitle> In Proceedings of the 5th Annual IEEE Symposium on Logic in Computer Science, </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: Both safety and progress properties of algorithms may be shown using standard proof techniques (e.g., invariant assertions and variant functions). For example, these techniques have been used within the extended model for proving the correctness of Dijkstra's classical shared memory mutual exclusion algorithm <ref> [7] </ref>.
Reference: [8] <author> Maurice P. Herlihy and Jeannette M. Wing. </author> <title> Axioms for concurrent objects. </title> <booktitle> In Proceedings of the 14th Principles of Programming Languages, </booktitle> <pages> pages 13-26, </pages> <month> January </month> <year> 1987. </year> <note> Also to appear in Transactions on Programming Languages and Systems. </note>
Reference-contexts: Thus, an important problem in multiprocessor algorithm design is to carefully construct the processes and objects in such a way that any the invocation-response system "simulates" an atomic access system. One approach to this problem has been advanced by Herlihy and Wing <ref> [8] </ref>. They propose a property of objects, called linearizability, that permits one to construct invocation-response systems, and then to reason about only those executions in which each response immediately follows the corresponding invocation. <p> In an invocation-response system, it is possible to consider operation executions that overlap in time. Herlihy and Wing <ref> [8] </ref> use this model to define a correctness condition called linearizabil-ity that extends Lamport's notion of atomicity for reads and writes [11] to arbitrary data types. Linearizability requires that in any (concurrent) execution, each operation "appears" to take effect instantaneously, sometime between the invocation and response events of the operation. <p> such that 8i 2 I; 8p 2 ops (type (i)); 8a 2 args (p); 8r 2 rets (p); each respond i;j (p; a; r) action is immediately preceded in fl j by an invoke i;j (p; a) action. 7 This proof follows closely the proof of a similar theorem in <ref> [8] </ref> and uses ideas from [14], page 78, to treat the actions of the environment. 24 The second condition induces a total order &lt; j on the operations invoked by p j , and by Lemma 15, we know that each invocation has a matching response.
Reference: [9] <author> C.A.R. Hoare. </author> <title> Communicating Sequential Processes. </title> <booktitle> Prentice-Hall International, </booktitle> <address> Englewood Cliffs, New Jersey, </address> <year> 1985. </year> <month> 28 </month>
Reference-contexts: These models allow one to be explicit about the possible interleavings that may occur in a distributed system and may specify which of those interleavings are to be considered "fair" to the individual system components. Examples include CSP <ref> [9] </ref>, in which system components communicate by sending messages over synchronous channels, and UNITY [4], in which components communicate by reading and modifying shared variables. The I/O automaton model [15, 16] is particularly well-suited for modelling distributed algorithms described using message passing.
Reference: [10] <author> Leslie Lamport. </author> <title> How to make a multiprocessor computer that correctly executes multiprocess programs. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 28(9):690, </volume> <month> September </month> <year> 1979. </year>
Reference-contexts: Linearizability requires that in any (concurrent) execution, each operation "appears" to take effect instantaneously, sometime between the invocation and response events of the operation. Lineariz-ability is also similar to Lamport's sequential consistency <ref> [10] </ref>, but requires that if two operations on a given object do not overlap in time, then the order in which they "appear" to occur is consistent with the order in which they actually occur 5 .
Reference: [11] <author> Leslie Lamport. </author> <title> On interprocess communication. </title> <journal> Distributed Computing, </journal> <volume> 1(1) 77-85,86-101, </volume> <year> 1986. </year>
Reference-contexts: In an invocation-response system, it is possible to consider operation executions that overlap in time. Herlihy and Wing [8] use this model to define a correctness condition called linearizabil-ity that extends Lamport's notion of atomicity for reads and writes <ref> [11] </ref> to arbitrary data types. Linearizability requires that in any (concurrent) execution, each operation "appears" to take effect instantaneously, sometime between the invocation and response events of the operation.
Reference: [12] <author> N. Lynch and M. Merritt. </author> <title> Introduction to the theory of nested transactions. </title> <booktitle> In International Conference on Database Theory, </booktitle> <pages> pages 278-305, </pages> <address> Rome, Italy, </address> <month> September </month> <year> 1986. </year> <note> Also, expanded version in Technical Report, </note> <institution> MIT/LCS/TR-367, MIT Laboratory for Computer Science, </institution> <month> July </month> <year> 1986. </year> <note> Revised version in Theoretical Computer Science, 62(1988) 123-185. </note>
Reference-contexts: Borrowing a technique from <ref> [12] </ref>, we construct a particular automaton, called a "sequential object" that captures the meaning of a sequential specification. The sequential object construction will be used not only to define a linearizable implementation of a sequential specification, but also to define System B.
Reference: [13] <author> Nancy A. Lynch and Michael J. Fischer. </author> <title> On describing the behavior and implementation of a distributed system. </title> <journal> Theoretical Computer Science, </journal> <volume> 13 </volume> <pages> 17-43, </pages> <year> 1981. </year>
Reference-contexts: Also, one might wish to use both shared-memory and message-passing to describe different components of a heterogeneous system. Therefore, introducing a shared-memory mechanism into the I/O automaton model is a useful unification of these two approaches. The shared memory model of Lynch and Fischer <ref> [13] </ref> introduced the separation of input and output actions, and was a precursor of the current I/O automaton model. However, until now it has not been clear how to integrate the two basic approaches.
Reference: [14] <author> Nancy A. Lynch and Kenneth J. Goldman. </author> <title> Distributed algorithms. </title> <type> Technical Report MIT/LCS/RSS-5, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> May </month> <year> 1989. </year> <title> MIT Research Seminar Series. </title>
Reference-contexts: For each j 2 J , we let obj (j) I denote that set of objects that p j may access, and define the signature of p j as follows: 6 A similar idea appears in <ref> [14] </ref> on page 79. 19 Input Actions: invoke j;k (; a), where k 2 K; 2 ops (type (j)) and a 2 args () respond i;j (; a; r), where i 2 obj (j); 2 ops (type (i)), a 2 args (), and r 2 rets () Output Actions: respond j;k <p> 8p 2 ops (type (i)); 8a 2 args (p); 8r 2 rets (p); each respond i;j (p; a; r) action is immediately preceded in fl j by an invoke i;j (p; a) action. 7 This proof follows closely the proof of a similar theorem in [8] and uses ideas from <ref> [14] </ref>, page 78, to treat the actions of the environment. 24 The second condition induces a total order &lt; j on the operations invoked by p j , and by Lemma 15, we know that each invocation has a matching response.
Reference: [15] <author> Nancy A. Lynch and Mark R. Tuttle. </author> <title> Hierarchical correctness proofs for distributed algorithms. </title> <booktitle> In Proceedings of the 6th ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 137-151, </pages> <month> August </month> <year> 1987. </year> <note> A full version is available as MIT Technical Report MIT/LCS/TR-387. </note>
Reference-contexts: Examples include CSP [9], in which system components communicate by sending messages over synchronous channels, and UNITY [4], in which components communicate by reading and modifying shared variables. The I/O automaton model <ref> [15, 16] </ref> is particularly well-suited for modelling distributed algorithms described using message passing. The I/O automaton model is a (not necessarily finite) state machine model that provides extra support for classifying actions as input or output and for describing fairness conditions. <p> Next, in Section 4, we use the extended model to establish a formal relationship between invocation-response systems and atomic access systems. The paper concludes with a summary and discussion. 2 The I/O Automaton Model The I/O automaton model of Lynch and Tuttle <ref> [15, 16] </ref> is the starting point for this work. One of the I/O automaton model's distinguishing features is the clear separation of input and output actions. This will be particularly important for our shared memory extensions for two reasons.
Reference: [16] <author> Nancy A. Lynch and Mark R. Tuttle. </author> <title> An introduction to Input/Output Automata. </title> <journal> CWI-Quarterly, </journal> <volume> 2(3), </volume> <year> 1989. </year>
Reference-contexts: Examples include CSP [9], in which system components communicate by sending messages over synchronous channels, and UNITY [4], in which components communicate by reading and modifying shared variables. The I/O automaton model <ref> [15, 16] </ref> is particularly well-suited for modelling distributed algorithms described using message passing. The I/O automaton model is a (not necessarily finite) state machine model that provides extra support for classifying actions as input or output and for describing fairness conditions. <p> Next, in Section 4, we use the extended model to establish a formal relationship between invocation-response systems and atomic access systems. The paper concludes with a summary and discussion. 2 The I/O Automaton Model The I/O automaton model of Lynch and Tuttle <ref> [15, 16] </ref> is the starting point for this work. One of the I/O automaton model's distinguishing features is the clear separation of input and output actions. This will be particularly important for our shared memory extensions for two reasons. <p> Other features of the model important to us are its treatment of fairness and its compositionality properties. Before describing our extensions to the I/O automaton model, we present a brief introduction to the I/O automaton model. This brief introduction is adapted from <ref> [16] </ref>, which explains the model in more detail, presents examples, and includes comparisons to other models. 2.1 I/O Automata I/O automata are best suited for modelling systems in which the components operate asynchronously. <p> The definitions of composition and fairness imply certain natural relationships between the (fair) executions of a composition and the (fair) executions of the individual components. For example, the following lemma from <ref> [16] </ref> states that (fair) executions of component automata can often be pasted together to form a (fair) execution of the composition. Lemma 1: Let fA i g i2I be a strongly compatible collection of automata and let A = i2I A i . <p> Proof: By Theorem 3, for each A i , augment (A i ; Z) is a shared memory automaton for Z. Therefore, by Theorem 2, the result holds. The following three compositionality results follow immediately from the corresponding results in <ref> [16] </ref>, together with Theorems 6 and 7. The first result says that an execution of an augmented-composition induces executions of the component shared memory automata. Corollary 8: Let fX i g i2I be a collection of sets of variables, where Z = [ i2I X i .
Reference: [17] <author> Bala Swaminathan and Kenneth J. Goldman. </author> <title> Hierarchical correctness proofs for recursive distributed algorithms using dynamic process creation. </title> <type> Technical Report WUCS-92-10, </type> <institution> Wash-ington University in St. Louis, </institution> <month> September </month> <year> 1992. </year> <note> Revised April 1993. 29 </note>
Reference-contexts: The various recursive instantiations of the algorithm on a given processor communicate with their corresponding instantiations on other processors through message passing, and they communicate among themselves through shared memory <ref> [17] </ref>. In addition, a unified model provides the ability to describe systems that use both shared memory and message passing communication.
References-found: 17

