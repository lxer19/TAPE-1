URL: http://www.cis.ohio-state.edu/lair/TechReports/cog-arch.ps
Refering-URL: http://www.cis.ohio-state.edu/lair/Papers/Directories/a-dir.html
Root-URL: 
Title: Architecture of Intelligence: The Problems and Current Approaches to Solutions 1  
Author: B. Chandrasekaran and Susan G. Josephson 
Keyword: Dimensions for Thinking About Thinking  
Address: Columbus, OH 43210 USA  
Affiliation: Laboratory for AI Research The Ohio State University  
Date: February 28, 1993  
Note: Mss dated  Dimension 1. Is intelligence separable from other mental phenomena?  
Abstract: We start by making a distinction between mind and cognition, and by positing that cognition is an aspect of mind. We propose as a working hypothesis a Separability Hypothesis which posits that we can factor off an architecture for cognition from a more general architecture for mind, thus avoiding a number of philosophical objections that have been raised about the "Strong AI" hypothesis. We then discuss different positions that have been taken about how biological a theory of intelligence or cognition needs to be. Using a coinsorting machine as an example, we discuss a range of positions on representations, and argue that for many purposes, the same body of matter can be interpreted as bearing different representational formalisms. We adopt the view that one way to understand the diversity of architectural theories is to make a distinction between deliberative and subdeliberative architectures. We propose that symbolic architectures, especially those based on logic or problem spaces, are essentially modeled on intuitions about deliberation, while connectionist and other architectures are inspired by phenomena that occur below deliberation. Much of the discussion and arguments in the field are not so much about "facts of the matter" as they are about analytic stances. Thus the search for an architectural level which will explain all the interesting phenomena of cognition is likely to be futile. There are a number of levels which interact, unlike in the computer model, and this interaction makes explanation of even relatively simple cognitive phenomena in terms of one level quite incomplete. A major problem in the study of intelligence and cognition is the range of - often implicit - assumptions about what phenomena these terms are meant to cover. Are we just talking about cognition as having and using knowledge, or are we also talking about other mental states such as emotions and subjective awareness? Are we talking about intelligence as an abstract set of capacities, or as a set of biological mechanisms and phenomena? These two questions set up two dimensions of discussion about intelligence. After we discuss these dimensions we will discuss information processing, representation, and cognitive architectures. When people think of intelligence and cognition, they often think of an agent being in some knowledge state, that is, having thoughts, beliefs. They also think of the underlying process of cognition as something that changes knowledge states. Since knowledge states are particular types of information states the underlying process is thought of as information processing. (We will discuss this in more detail later in the paper.) However, besides these knowledge states, mental phenomena also include such things as emotional states and subjective consciousness. Under what conditions can these other mental properties also be attributed to artifacts to which we attribute knowledge states? Is intelligence separable from these other mental phenomena? 1 This paper is a slightly revised version of the paper with the same title appearing in Current Science, 
Abstract-found: 1
Intro-found: 1
Reference: <author> Chandrasekaran, B. </author> <booktitle> (1991) Roles of logic in Artificial Intelligence Vivek: A Quarterly in Artificial Intelligence, Bombay: National Center for Software Technology, </booktitle> <volume> 4 , 2, </volume> <pages> 13-55. </pages>
Reference: <author> Chandrasekaran, B. </author> <year> (1986). </year> <title> Generic tasks in knowledge-based reasoning: high-level building blocks for expert system design. </title> <booktitle> IEEE Expert , 1 , 3, Fall, </booktitle> <pages> pp 23-30. </pages>
Reference: <author> Clancey, W. J. and Roschelle, J. </author> <title> (1991) Situated cognition: How representations are created and given meaning. </title> <type> Technical report, </type> <institution> Institute for Research on Learning, </institution> <address> Palo Alto, CA 94304, USA. </address>
Reference: <author> Crutchfield, J. P., and Young, K. </author> <year> (1989). </year> <title> Computation at the onset of chaos. In Computation, Entropy and the Physics of Information , W.Zurek, </title> <editor> editor, </editor> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> Dennett, D. </author> <year> (1987). </year> <title> The Intentional Stance . Cambridge, </title> <address> MA: </address> <publisher> MIT Press/Bradford Books. </publisher>
Reference: <author> Dreyfus, H. </author> <year> (1972). </year> <title> What Computers Cannot Do: </title> <journal> The Limits of Artificial Intelligence . New York: Harper and Row. </journal> <volume> 19 02/28/93 Edelman, </volume> <editor> G. M. </editor> <year> (1987). </year> <title> Neural Darwinism: The Theory of Neuronal Group Selection . New York: </title> <publisher> Basic Books. </publisher>
Reference: <author> Edelman, G. M. </author> <year> (1989). </year> <title> The Remembered Present: A Biological Theory of Consciousness . New York: </title> <publisher> Basic Books. </publisher>
Reference: <author> Fodor, J. A. </author> <year> (1983). </year> <title> The Modularity of Mind: An Essay on Faculty Psychology , Cambridge, </title> <address> MA: </address> <publisher> MIT Press/Bradford Books. </publisher>
Reference: <author> Fodor, J. A. and Pylyshyn, Z. W. </author> <year> (1988). </year> <title> Connectionism and cognitive architecture: A critical analysis. </title> <type> Cognition , 28 , 3-71. </type>
Reference: <author> Harnad, S. </author> <title> (1990) The symbol grounding problem. </title> <journal> Physica , D, </journal> <volume> 42, </volume> <pages> 335-346. </pages>
Reference: <author> Iran-Nejad, A. </author> <year> (1987). </year> <title> The schema: A long-term memory structure or transient functional pattern. </title> <booktitle> In R. </booktitle>
Reference: <editor> J. Tierney, et al, editors, </editor> <title> Understanding Readers' Understanding: Theory and Practice , Hillsdale: </title> <publisher> Lawrence Erlbaum. </publisher>
Reference: <author> McCarthy, J. </author> <title> (1980) Circumscription: A form of non-monotonic reasoning. </title> <booktitle> Artificial Intelligence , 13 , 1-2, </booktitle> <pages> 27-41. </pages>
Reference: <author> McCarthy, J. and Hayes, P. J. </author> <year> (1969). </year> <title> Some philosphical problems from the standpoint of artificial intelligence. </title> <booktitle> Machine Intelligence, </booktitle> <pages> 6 , 133-153. </pages>
Reference: <author> Minsky, M. </author> <year> (1975). </year> <title> A framework for representing knowledge. In The Psychology of Computer Vision , P H. </title> <publisher> Winston, ed., </publisher> <pages> pp. 211-280, </pages> <address> New York: </address> <publisher> McGraw Hill. </publisher>
Reference: <author> Minsky, M. </author> <year> (1986). </year> <title> The Society of Mind . New York: </title> <publisher> Simon and Schuster. </publisher>
Reference: <author> Newell, A. </author> <year> (1990). </year> <title> Unified Theories of Cognition. </title> <address> Cambridge, MA: </address> <publisher> Harvard Univerity Press. </publisher>
Reference: <author> Newell, A. and H. </author> <title> Simon (1972). Human Problem Solving. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall. </publisher>
Reference: <author> Patten, T., Geis, M., and Becker, B. </author> <year> (1992). </year> <title> Toward a theory of compilation for natural languge generation. </title> <booktitle> Computational Intelligence , 8 ,1, </booktitle> <pages> 77-110. </pages>
Reference: <author> Pollack, J. B. </author> <year> (1990). </year> <title> Recursive distributed representations. </title> <booktitle> Artificial Intelligence , 46 , 1, </booktitle> <pages> 77-105. </pages>
Reference: <author> Pollack, J. B. </author> <year> (1993). </year> <journal> Review of Unified Theories of Cognition , Artificial Intelligence, </journal> <note> in press. </note>
Reference: <author> Putnam, H. </author> <year> (1988). </year> <title> Representation and Reality. </title> <address> Cambridge, MA: </address> <publisher> MIT Press/Bradford Books. </publisher>
Reference: <author> Rumelhart, D. E., J. L. </author> <title> McClelland and the PDP research group, </title> <booktitle> eds (1986). Parallel Distributed Processing: Essays in the Microstructure of Cognition , Vol. I, Foundations . Cambridge, </booktitle> <address> MA: </address> <publisher> MIT Press/Bradford Books. </publisher>
Reference: <author> Schank, R. C. </author> <year> (1982). </year> <title> Dynamic Memory: A Theory of Reminding and Learning in Computers and People . New York: </title> <publisher> Cambridge University Press. </publisher>
Reference: <author> Searle, J. R. </author> <year> (1980). </year> <title> Minds, brains, and programs, </title> <journal> Behavioral and Brain Sciences , 3 , 417-424. </journal> <volume> 20 02/28/93 Shastri, </volume> <editor> L. </editor> <year> (1990). </year> <title> Connectionism and the computational effectiveness of reasoning. </title> <booktitle> Theoretical Linguistics , 16:1, </booktitle> <pages> 65-87. </pages>
Reference: <author> Skarda, C. A., and Freeman, W. J. </author> <title> (1987) How brains make chaos in order to make sense of the world. </title> <booktitle> Behavioral and Brain Sciences , 10 , 161-195. </booktitle>

References-found: 26

