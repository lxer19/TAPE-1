URL: http://www.icsi.berkeley.edu/~phlipp/forall.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/~phlipp/phlipp.publ.html
Root-URL: http://www.icsi.berkeley.edu
Title: Data Parallelism in Java  
Author: Michael Philippsen 
Address: PO-Box 6980, 76128 Karlsruhe, Germany  
Affiliation: Computer Science Dept., University of Karlsruhe,  
Abstract: Tel: +49/721/608-4067, Fax: +49/721/7343, eMail: phlipp@ira.uka.de This paper has been submitted to HPCS'98, the 12th Annual Int. Symposium on High Performance Computing Systems and Applications, May 1998, Edmonton, Alberta, Canada. Abstract Java supports threads and remote method invocation but it does neither support data parallel nor distributed programming. This paper discusses Java's shortcomings with respect to data parallel programming. It then presents countermeasures that allow for data parallel programming in Java. The technical contributions of this paper are twofold: a source-to-source transformation is presented that maps forall statements into efficient multi-threaded Java code. In addition, an optimization strategy is presented that achieves a minimal number of synchronization barriers. The transformation, the optimization, and a distributed runtime system have been implemented in the JavaParty environment. In JavaParty, code compiled with current just-in-time compilers runs merely a factor of two to three slower than Fortran, on both a shared-memory parallel machine (IBM SP/2). Furthermore, better compiler technology is on the horizon, which will narrow the performance gap. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Gerald Brose, Klaus-Peter Lohr, and Andre Spiegel. </author> <title> Java does not distribute. </title> <type> Technical Report B 97-07, </type> <institution> Freie Universitat Berlin, </institution> <year> 1997. </year>
Reference-contexts: This doubling of code size happens both for socket based communication and for RMI based approaches. Moreover, Brose et al. argue in <ref> [1] </ref> that RMI's object model that distinguishes between remote and local objects causes severe misunderstandings and bugs when programming with that model. We therefore have designed an additional transformation phase, that turns Java objects into remote Java objects that reside in a distributed setting.
Reference: [2] <author> Bryan Carpenter, Yuh-Jye Chang, Geoffrey Fox, Donald Leskiw, and Xiaoming Li. </author> <title> Experiments with "HPJava". </title> <journal> Concurrency: Practice and Experience, </journal> <month> June </month> <year> 1997. </year>
Reference-contexts: Such classes are useful for JavaParty. The system runs on an IBM SP/2, but in contrast to JavaParty's 100% pure Java approach, it uses a runtime system written in C that interacts with a native MPI communication library. In the HPJava <ref> [2] </ref> project at Syracuse, Carpenter, Fox et al. use wrappers to interface to native HPF code and library-based extensions of Java. They offer useful classes for distribution of array data and for collective communication as well.
Reference: [3] <author> K. Mani Chandy and Carl Kesselman. </author> <title> CC++: A declarative concurrent object-oriented programming notation. </title> <editor> In Gul Agha, Peter Wegner, and Akinori Yonezawa, editors, </editor> <booktitle> Research Directions in Concurrent Object-Oriented Programming, </booktitle> <pages> pages 281-313. </pages> <publisher> MIT Press Cambridge, </publisher> <address> Massachusetts, London, England, </address> <year> 1993. </year>
Reference-contexts: C) Pre-Compiler and Library. A third approach is to extend the expressive power by means of libraries for data distribution, collective communication, and forall statements. This approach has been taken for various parallel extensions of C++, e.g. <ref> [3, 6] </ref>. However, since Java does neither support templates nor macros, some restrictions apply. Both data distribution and collective communication are best handled by libraries that handle and partition arrays on a distributed parallel machine.
Reference: [4] <author> J. Clearbout and B. Biondi. </author> <title> Geophysics in object-oriented numerics (GOON): Informal conference. In Stanford Exploration Project Report No. </title> <type> 93. </type> <month> October </month> <year> 1996. </year> <note> http://sepwww.stanford.edu/sep. </note>
Reference-contexts: Since it can take terra bytes of input data to cover a reasonable area, the performance of these algorithms is crucial. The geophysics and the details of the benchmarks can be found in [9]. In cooperation with the Stanford Exploration Project <ref> [4] </ref>, we have implemented these algorithms in JavaParty, in HPF, and in Fortran90. We then bench-marked the programs on up to 16 nodes of an IBM SP/2 distributed memory parallel computer as well as on 16 nodes of an SGI PowerChallenge shared memory machine.
Reference: [5] <author> Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides. </author> <title> Design Patterns Elements of Reusable Object-Oriented Software. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1994. </year>
Reference-contexts: and the closure type system of Pizza can be found in [12]. class ForallThread extends Thread - private WorkPile wp; ... public void run () - while (true) - (-&gt;void) fkt = wp.getWork (); fkt (); wp.doneWork (); - - The work pile is designed according to several design patterns <ref> [5] </ref>. There is only a single work pile in the system ("Singleton"), initialized upon program start. The design pattern "Strategy" is used for the SplitStrategy that is explained later on. The method doWork puts new work onto work pile.
Reference: [6] <author> Andrew S. Grimshaw. </author> <title> Easy to use object-oriented parallel programming. </title> <journal> IEEE Computer, </journal> <volume> 26(5) </volume> <pages> 39-51, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: C) Pre-Compiler and Library. A third approach is to extend the expressive power by means of libraries for data distribution, collective communication, and forall statements. This approach has been taken for various parallel extensions of C++, e.g. <ref> [3, 6] </ref>. However, since Java does neither support templates nor macros, some restrictions apply. Both data distribution and collective communication are best handled by libraries that handle and partition arrays on a distributed parallel machine.
Reference: [7] <author> Susan Flynn Hummel, Ton Ngo, and Harini Srini-vasan. </author> <title> SPMD programming in Java. </title> <journal> Concur-rency: Practice and Experience, </journal> <month> June </month> <year> 1997. </year>
Reference-contexts: JavaParty programs run on workstations, on shared memory parallel computers and in truly distributed environments. Moreover, JavaParty's forall statement allows for a single program approach that is independent of the underlying topology. And finally, JavaParty programs come close the native HPF and Fortran90 performance. Hummel et al. <ref> [7] </ref> work on SPMD programming in Java and faced some of the same problems we have discussed in section 2. The main contribution are classes for efficient synchronization and for regular and irregular collective communications. Such classes are useful for JavaParty.
Reference: [8] <author> IBM. </author> <title> High performance compiler for Java. </title> <address> http://www.alphaWorks.ibm.com. </address>
Reference-contexts: We expect the factor 8.2 to shrink significantly when truly parallel Java threads become available with a future release of SGI's Java virtual machine. 9 Although the IBM SP/2 offers an alpha version of a High Performance Java Compiler <ref> [8] </ref> compiling to native and statically linked code, it is too early to seriously use that compiler. <p> Future releases (JDK 1.2) are announced to speed up the JVM even further. Second, compilers producing optimized native code like IBM's High Performance Java Compiler <ref> [8] </ref> are on the horizon. These compilers will approach Fortran performance because they can apply much more sophisticated optimization techniques than current just-in-time compilers. 8 Related Work An advantages of JavaParty in comparison to other projects aimed at adding data parallelism to Java is portability.
Reference: [9] <author> Matthias Jacob. </author> <title> Implementing Large-Scale Geophysical Algorithms with Java: A Feasibility Study. </title> <type> Master's thesis, </type> <institution> Karlsruhe Univeristy, </institution> <month> November </month> <year> 1997. </year>
Reference-contexts: Since it can take terra bytes of input data to cover a reasonable area, the performance of these algorithms is crucial. The geophysics and the details of the benchmarks can be found in <ref> [9] </ref>. In cooperation with the Stanford Exploration Project [4], we have implemented these algorithms in JavaParty, in HPF, and in Fortran90.
Reference: [10] <author> Charles H. Koelbel, David B. Loveman, Robert S. Schreiber, Guy L. Steele Jr., and Mary E. Zosel. </author> <title> The High Performance Fortran Handbook. </title> <publisher> MIT Press Cambridge, </publisher> <address> Massachusetts, London, Eng-land, </address> <year> 1994. </year>
Reference-contexts: Hence, it does not offer adequate support for either of them, as we will show below. 1 HPF is a procedural language and still an descendent of Fortran. From the software engineering point of view, Java is preferable to HPF <ref> [10] </ref>, since it allows for clearly designed, re-usable, and maintainable code. But since HPF combines the collective knowledge on data parallel programming it must be considered when thinking about data parallelism in Java. 1 Java stands for Java as defined in the JDK 1.1.5.
Reference: [11] <author> Doug Lea. </author> <title> Concurrent Programming in Java - Design Principles and Patterns. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1996. </year>
Reference-contexts: When threads are recycled instead of being created over and over, start and join can no longer be used. But without them, tree structured re-start and barriers are even more difficult to implement. The reason is that Java's weak memory consistency model -there is no sequential consistency <ref> [11] </ref>- is coupled to unsuitable or too costly synchronization operations. 4 Monitors and critical sections are too heavy weight to implement re-starts and barriers since they often cause slow kernel entries in current JVMs.
Reference: [12] <author> Martin Odersky and Philip Wadler. </author> <title> Pizza into Java: Translating theory into practice. </title> <booktitle> In Proc. 24th ACM Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1997. </year>
Reference-contexts: In Pizza terminology, this function is of type (-&gt;void). More details on closure implementation and the closure type system of Pizza can be found in <ref> [12] </ref>. class ForallThread extends Thread - private WorkPile wp; ... public void run () - while (true) - (-&gt;void) fkt = wp.getWork (); fkt (); wp.doneWork (); - - The work pile is designed according to several design patterns [5].
Reference: [13] <author> Michael Philippsen and Ernst A. Heinz. </author> <title> Automatic synchronization elimination in synchronous foralls. </title> <booktitle> In Frontiers '95:The 5th Symp. on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 350-357, </pages> <address> Mc Lean, VA, </address> <month> February 6-9, </month> <year> 1995. </year>
Reference-contexts: Moreover, it is not even promising to use compile time data dependence analysis techniques, e.g. <ref> [13, 18] </ref>, for that task, since the same reasons render those techniques either too costly or too weak.
Reference: [14] <author> Michael Philippsen and Matthias Zenger. Java-Party: </author> <title> Transparent remote objects in Java. </title> <journal> Con-currency: Practice and Experience, </journal> <volume> 9(11) </volume> <pages> 1225-1242, </pages> <month> November </month> <year> 1997. </year>
Reference-contexts: This section sketches ways to distribute objects in a network, and since threads are objects, thread distribution is covered as well. Java provides socket communication and RMI, the remote method invocation interface, for programming of distributed memory environments. Unfortunately, both are not appropriate. We have shown in <ref> [14] </ref> that the number of lines that have to be added to or changed in a given multi-threaded program to make it work in a distributed environment is of the same order of magnitude as the original program size. <p> Migration and object placement can be done by the runtime system (runtime and compiler techniques to enhance locality are available) or objects can be placed manually. We do not recapitulate the transformation techniques here, since the details can be found in <ref> [14] </ref>. 7 Results We have studied large-scale geophysical algorithms, called Veltran velocity analysis and Kirchhoff migration to evaluate the efficiency of JavaParty's forall. These are basic algorithms used in geophysics for the analysis of the earth's sublayers by means of sound wave reflection.
Reference: [15] <author> Pizza. </author> <note> http://www.cis.unisa.edu.au/~pizza. </note>
Reference-contexts: Upon program start, a fixed number of these threads are started. Their run method is an endless loop that gets work from a work pile, executes that work, indicates completion and starts over. JavaParty uses Pizza's closures <ref> [15] </ref> to capture state and to construct functions. 5 In the code fragment below, wp.getWork returns a function from the work pile 5 Pizza uses a source-to-source transformation as well.
Reference: [16] <author> Michael J. Quinn and Philip J. Hatcher. </author> <title> Data-parallel programming on multicomputers. </title> <journal> IEEE Software, </journal> <volume> 7(5) </volume> <pages> 69-76, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: To avoid that sort of inefficiency and to make a transformation work for nested parallelism as well, threads must be re-used and standard virtualization loop techniques <ref> [16] </ref> must used. Both will increase the complexity of the transformation, since re-use of threads is difficult to achieve in Java, and since code for index set splitting and additional boundary checks for the first/last thread need to be added. * Fan-out and fan-in restrictions.
Reference: [17] <author> JavaSoft (John Rose). </author> <title> Inner class specification: Further example: Multi-threaded task partitioning. </title> <address> http://java.sun.com/products/jdk/1.1/docs /guide/innerclasses/spec/innerclasses.doc13.html. </address>
Reference-contexts: Consider the following forall statement: forall (int i = 0; i &lt; 100; i++) bar (i); With inner classes, 2 the JDK documentation suggests a multi-threaded equivalent as follows <ref> [17] </ref>: 1 Thread [] worker = new Thread [100]; 2 for (int i = 0; i &lt; 100; i++) - 3 final int ii = i; 4 worker [i] = new Thread () - 5 public void run () - 6 bar (ii); 8 -; 9 worker [i].start (); 10 -
Reference: [18] <author> Chau-Wen Tseng. </author> <title> Compiler optimizations for eliminating barrier synchronization. </title> <booktitle> In 5th ACM SIGPLAN Symp. on Principles and Practice of Parallel Programming, PPoPP, </booktitle> <pages> pages 144-155, </pages> <address> Santa Barbara, CA, </address> <month> July 19-21 </month> <year> 1995. </year>
Reference-contexts: Moreover, it is not even promising to use compile time data dependence analysis techniques, e.g. <ref> [13, 18] </ref>, for that task, since the same reasons render those techniques either too costly or too weak.
Reference: [19] <author> Matthias Winkel. </author> <title> Erweiterung von Java um ein FORALL. </title> <type> Studienarbeit, </type> <institution> University of Karls-ruhe, Department of Informatics, </institution> <month> May </month> <year> 1997. </year> <month> 10 </month>
Reference-contexts: For details and downloading see http://wwwipd.ira.uka.de/JavaParty. Acknowledgements I would like to thank the JavaParty group, especially Matthias Zenger, for their support of the JavaParty environment. Matthias Jacob implemented the geophysical algorithms. Christian Nester pointed out several synchronization bugs in the first version <ref> [19] </ref> of the forall transformation. Furthermore, we want to express gratitude to Maui High Performance Computing Center as well as Karlsruhe Computing Center for the granting access on the IBM SP/2.
References-found: 19

