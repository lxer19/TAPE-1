URL: http://www.cs.ucsb.edu/~tyang/papers/hpdc7swala.ps
Refering-URL: http://www.cs.ucsb.edu/Research/rapid_sweb/SWEB.html
Root-URL: http://www.cs.ucsb.edu
Email: fveho, besmith, tyangg@cs.ucsb.edu  
Title: Cooperative Caching of Dynamic Content on a Distributed Web Server  
Author: Vegard Holmedahl, Ben Smith, Tao Yang 
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California  
Abstract: In this paper we propose a new method for improving the average response time of Web servers by cooperatively caching the results of requests for dynamic content. The work is motivated by our recent study of access logs from the Alexandria Digital Library server at UCSB, which demonstrates that approximately a 30 percent decrease in average response time could be achieved by caching dynamically generated content. We have developed a distributed Web server called Swala, in which the nodes cooperatively cache the results of CGI requests, and the cache meta-data is stored in a replicated global cache directory. Our experiments show that the single-node performance of Swala without caching is comparable to the Netscape Enterprise server, that considerable speedups are obtained using caching, and that the cache hit ratio is substantially higher with cooperative cache than with stand-alone cache. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Andresen, L. Carver, R. Dolin, C. Fischer, J. Frew, M. Good-child, O. Ibarra, R. Kothuri, M. Larsgaard, B. Manjunath, D. Nebert, J. Simpson, T. Smith, T. Yang, Q. Zheng, </author> <title> The WWW Prototype of the Alexandria Digital Library, </title> <booktitle> Proceedings of ISDL'95: International Symposium on Digital Libraries, </booktitle> <year> 1995. </year>
Reference-contexts: Our solution is a distributed Web server, called Swala, which cooperatively caches the results of CGI requests. Our work is motivated, in part, by our experience with the Alexandria Digital Library (ADL) system <ref> [1] </ref> developed at UCSB. The current ADL system provides on-line browsing and processing of digitized maps and other geo-spatially mapped data through the Web. <p> Our work overcomes both limitations, since our cache is built into the Web server. 3 Access log analysis In this section we illustrate the benefits of dynamic request results caching by analyzing an access log from the Alexandria Digital Library (ADL) at UCSB <ref> [1] </ref>. We have studied its log for September and October 1997, which contains a total of 69,990 requests. After filtering out HEAD and POST requests [4], we have re-sent the requests to the server and timed them.
Reference: [2] <author> D. Andresen, T. Yang, V. Holmedahl, O. Ibarra, SWEB: </author> <title> Towards a Scalable World Wide Web Server on Multicomputers, </title> <booktitle> Proc. of 10th IEEE International Symp. on Parallel Processing (IPPS'96), </booktitle> <pages> pp. 850-856. </pages> <month> April, </month> <year> 1996. </year>
Reference-contexts: In order to accommodate the growth, advances in server technology are needed to improve the response time to the client under heavy load conditions. Typical methods for improving performance are file caching with proxies [5, 6], and load balancing multi-node Web servers <ref> [2, 7, 13] </ref>. Research shows that for file fetches on the Web, the network is responsible for a significant portion of the response time. Web proxy caching is effective because it reduces the network bottleneck by keeping copies of files closer to clients.
Reference: [3] <author> D. Andresen, T. Yang, O. Egecioglu, O. Ibarra, T. Smith, </author> <title> Scalability Issues for High Performance Digital Libraries on the World Wide Web, </title> <booktitle> Proc. of the 3rd IEEE ADL96 (Advances in Digital Libraries), </booktitle> <pages> pp. 139-148, </pages> <year> 1996. </year>
Reference: [4] <author> T. Berners-Lee, R. Fielding, and H. Frystyk, </author> <title> Hypertext Transfer Protocol HTTP/1.0, RFC 1945, </title> <institution> HTTP Working Group, </institution> <month> May, </month> <year> 1996. </year>
Reference-contexts: We have studied its log for September and October 1997, which contains a total of 69,990 requests. After filtering out HEAD and POST requests <ref> [4] </ref>, we have re-sent the requests to the server and timed them. Illegal requests have been removed from the result file before analyzing the statistics, so the total number of requests studied is 69,337, of which 28,663 (41.3%) require execution of a CGI program.
Reference: [5] <author> P. Cao, S. Irani, </author> <title> Cost-Aware WWW Proxy Caching Algorithms, </title> <booktitle> Proc. of the USENIX Symposium on Internet Technologies and Systems, </booktitle> <pages> pp. 193-206, </pages> <month> December, </month> <year> 1997. </year>
Reference-contexts: 1 Introduction World Wide Web usage has experienced explosive growth in the last few years. In order to accommodate the growth, advances in server technology are needed to improve the response time to the client under heavy load conditions. Typical methods for improving performance are file caching with proxies <ref> [5, 6] </ref>, and load balancing multi-node Web servers [2, 7, 13]. Research shows that for file fetches on the Web, the network is responsible for a significant portion of the response time. <p> Our work is applicable to any Web site making extensive use of dynamic requests with long execution times, given a reasonable amount of repetition. 2 Related work Numerous papers <ref> [5, 6] </ref> discuss caching of Web content; however, they focus on caching static data and intentionally avoid caching dynamic data. Furthermore, they concentrate on proxy caching rather than server-side caching. <p> There are two reasons for this. First, our access log analysis in Section 3 shows that execution of dynamic requests generally takes orders of magnitude more time than file fetches. Secondly, previous work on Web file caching <ref> [5] </ref> has determined that for file requests, the network is the bottleneck, so file caching should occur as close to the client as possible, i.e. at a proxy server rather than at the base Web server.
Reference: [6] <author> A. Chankhunthod, P. Danzig, C. Neerdaels, M. Schwartz and K. Wor-rell, </author> <title> A Hierarchical Internet Object Cache, </title> <type> Technical Report 95-611, </type> <institution> Computer Science Department, University of Southern California, </institution> <address> Los Angeles, California, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: 1 Introduction World Wide Web usage has experienced explosive growth in the last few years. In order to accommodate the growth, advances in server technology are needed to improve the response time to the client under heavy load conditions. Typical methods for improving performance are file caching with proxies <ref> [5, 6] </ref>, and load balancing multi-node Web servers [2, 7, 13]. Research shows that for file fetches on the Web, the network is responsible for a significant portion of the response time. <p> Our work is applicable to any Web site making extensive use of dynamic requests with long execution times, given a reasonable amount of repetition. 2 Related work Numerous papers <ref> [5, 6] </ref> discuss caching of Web content; however, they focus on caching static data and intentionally avoid caching dynamic data. Furthermore, they concentrate on proxy caching rather than server-side caching.
Reference: [7] <author> D. Dias, W. Kish, R. Mukherjee, R. Tewari, </author> <title> A Scalable and Highly Available Web Server, </title> <booktitle> Proc. of COMPCON 1996, Forty-First IEEE Computer Society International Conference: Technologies for the Information Superhighway, </booktitle> <address> Santa Clara, California, </address> <month> February, </month> <year> 1996. </year>
Reference-contexts: In order to accommodate the growth, advances in server technology are needed to improve the response time to the client under heavy load conditions. Typical methods for improving performance are file caching with proxies [5, 6], and load balancing multi-node Web servers <ref> [2, 7, 13] </ref>. Research shows that for file fetches on the Web, the network is responsible for a significant portion of the response time. Web proxy caching is effective because it reduces the network bottleneck by keeping copies of files closer to clients.
Reference: [8] <author> S. Gadde, M. Rabinovich, J. Chase, </author> <title> Reduce, Reuse, Recycle: An Approach to Building Large Internet Caches, </title> <booktitle> Workshop on Hot Topics in Operating Systems (HotOS), </booktitle> <month> May </month> <year> 1997. </year>
Reference: [9] <author> James Gwertzman, Margo Seltzer, </author> <title> World Wide Web Cache Consistency, </title> <booktitle> Proceedings of the 1996 USENIX Technical Conference, </booktitle> <address> San Diego, CA, </address> <month> Jan </month> <year> 1996. </year>
Reference: [10] <author> V. Holmedahl, B. Smith, T. Yang, </author> <title> Cooperative caching of dynamic content on a distributed Web server, </title> <institution> University of California at Santa Barbara technical report #TRCS98-12. </institution>
Reference-contexts: More advanced cache replacement methods can alleviate some of the problem, by keeping the most important requests (in terms of execution time, access frequency, time of access, size etc.) in the cache. For a discussion of the five cache replacement methods implemented in Swala, we refer the reader to <ref> [10] </ref>. While our log analysis has been limited to a digital library, we expect that other Web sites that make extensive use of dynamic requests also can benefit from dynamic content caching.
Reference: [11] <author> J. Hu, S. Mungee, D. Schmidt, </author> <title> Techniques for Developing and Measuring High-performance Web Servers over ATM Networks, </title> <note> Wash-ington University technical report #WUCS-97-09. </note>
Reference-contexts: Multi-threading raises consistency issues, which we discuss in section 4.2. We use memory-mapped I/O whenever possible to minimize the number of system calls and eliminate double-buffering. Multi-threading and memory-mapped I/O are important compo nents of efficient Web servers <ref> [11] </ref>. 2 4.1 Module design As illustrated in Figure 1, every Swala node contains two primary runtime modules: The HTTP module starts and shuts down all other threads. During startup, it initializes the thread-pool responsible for handling HTTP requests (hereafter called request threads). <p> We use NCSA HTTPd because it is a widely used research package, and we use Netscape Enterprise because it is one of the most efficient commercial Web servers available <ref> [11] </ref>. We use WebStone [17], a standard Web bench-marking tool, for the experiments in this sub-section. # clients HTTPd Enterprise Swala 6 0.207 0.032 0.058 18 0.604 0.105 0.099 30 1.146 0.174 0.164 42 1.709 0.248 0.235 Table 2. File fetch average response time in seconds measured using WebStone.
Reference: [12] <author> A. Iyengar, J. Challenger, </author> <title> Improving Web Server Performance by Caching Dynamic Data, </title> <booktitle> Proc. of the USENIX Symposium on Internet Technologies and Systems, </booktitle> <pages> pp. 49-60, </pages> <month> December, </month> <year> 1997. </year>
Reference-contexts: Nor does it permit other methods of inval-idation. It also requires file system access on every cache lookup, because they do not maintain an in-memory cache table. Caching the results of dynamic requests has been studied recently by IBM <ref> [12] </ref>. They have written a cache server and rewritten their server applications to insert and delete cache items. There are two main drawbacks to this approach. First, they require that a server application be rewritten to take advantage of the cache, and this can be a nontrivial task. <p> While our log analysis has been limited to a digital library, we expect that other Web sites that make extensive use of dynamic requests also can benefit from dynamic content caching. This is verified by recent work <ref> [12] </ref>. 4 Design of the Swala distributed Web server Swala is a multi-threaded, distributed Web server that runs on a cluster of workstations and shares cache information and cache data between nodes. <p> This is true in digital library applications, where the material available through the Web server normally is read-only. For Web sites that need stronger content consistency, we plan to investigate other cache entry invalidation methods in future versions of Swala, for example by receiving invalidation messages from applications <ref> [12] </ref>, or by monitoring the input of the CGI programs whose output is being cached, to detect invalidation [16]. We address cache table consistency with a two-level con sistency protocol: intra-server and inter-server consistency. In the following section we describe our cache table consistency protocol.
Reference: [13] <author> E.D. Katz, M. Butler, R. McGrath, </author> <title> A Scalable HTTP Server: the NCSA Prototype, </title> <journal> Computer Networks and ISDN Systems. </journal> <volume> vol. 27, </volume> <year> 1994, </year> <pages> pp. 155-164. </pages>
Reference-contexts: In order to accommodate the growth, advances in server technology are needed to improve the response time to the client under heavy load conditions. Typical methods for improving performance are file caching with proxies [5, 6], and load balancing multi-node Web servers <ref> [2, 7, 13] </ref>. Research shows that for file fetches on the Web, the network is responsible for a significant portion of the response time. Web proxy caching is effective because it reduces the network bottleneck by keeping copies of files closer to clients.
Reference: [14] <institution> Netscape Server Central Index Page, http://home.netscape.com/comprod/server central/. </institution>
Reference-contexts: For all these experiments, clients are located within the campus network to avoid Internet bandwidth fluctuations. 5.1 Single-node performance of Swala and over head of cache fetch We present the results of a series of experiments comparing Swala with NCSA's HTTPd Version 1.5.1 [15] and Netscape Corporation's Enterprise Server <ref> [14] </ref>. The purpose of these experiments is twofold. We compare the efficiency of Swala with popular research and commercial servers, for a workload consisting of file fetches and CGI execution.
Reference: [15] <institution> The NCSA HTTPd Home Page, </institution> <note> http://hoohoo.ncsa.uiuc.edu/. </note>
Reference-contexts: For all these experiments, clients are located within the campus network to avoid Internet bandwidth fluctuations. 5.1 Single-node performance of Swala and over head of cache fetch We present the results of a series of experiments comparing Swala with NCSA's HTTPd Version 1.5.1 <ref> [15] </ref> and Netscape Corporation's Enterprise Server [14]. The purpose of these experiments is twofold. We compare the efficiency of Swala with popular research and commercial servers, for a workload consisting of file fetches and CGI execution.
Reference: [16] <author> A. Vahdat, T. An-derson, </author> <title> Transparent Result Caching, </title> <note> draft accepted for publication in USENIX '98, http://now.cs.berkeley.edu/WebOS/papers/trec.ps. </note>
Reference-contexts: In a project currently in progress at UC Berkeley, Vahdat and Anderson propose a framework for monitoring source files, automatically invalidating the result whenever the source changes <ref> [16] </ref>. An example application that uses the monitoring system is dynamic content caching: they have modified a version of the Apache HTTP server to cache CGI results, and use their monitoring system to invalidate cached entries. <p> For Web sites that need stronger content consistency, we plan to investigate other cache entry invalidation methods in future versions of Swala, for example by receiving invalidation messages from applications [12], or by monitoring the input of the CGI programs whose output is being cached, to detect invalidation <ref> [16] </ref>. We address cache table consistency with a two-level con sistency protocol: intra-server and inter-server consistency. In the following section we describe our cache table consistency protocol. Our intra-node consistency protocol protects the internal cache directory against simultaneous updates, avoiding potential data corruption.
Reference: [17] <author> WebStone, </author> <note> http://www.sgi.com/Products/WebFORCE/WebStone/index.html. 8 </note>
Reference-contexts: We use NCSA HTTPd because it is a widely used research package, and we use Netscape Enterprise because it is one of the most efficient commercial Web servers available [11]. We use WebStone <ref> [17] </ref>, a standard Web bench-marking tool, for the experiments in this sub-section. # clients HTTPd Enterprise Swala 6 0.207 0.032 0.058 18 0.604 0.105 0.099 30 1.146 0.174 0.164 42 1.709 0.248 0.235 Table 2. File fetch average response time in seconds measured using WebStone.
References-found: 17

