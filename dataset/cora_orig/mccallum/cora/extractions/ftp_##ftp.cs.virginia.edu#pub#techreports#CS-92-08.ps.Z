URL: ftp://ftp.cs.virginia.edu/pub/techreports/CS-92-08.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Hardware Support for Parallel Discrete Event Simulations  
Author: Paul F. Reynolds, Jr., Carmen M. Pancerella 
Note: This research was supported in part by NSF Grant #CCR-9108448 and JPL Contract #957721.  
Abstract: Computer Science Report No. TR-92-08 April 20, 1992 
Abstract-found: 1
Intro-found: 1
Reference: [AbRi91] <author> Abrams, M. and Richardson, D., </author> <title> "Implementing a Global Termination Condition and Collecting Output Measures in Parallel Simulation", </title> <booktitle> Proceedings of the SCS Multiconference on Advances in Parallel and Distributed Simulation, </booktitle> <address> Anaheim, California, </address> <pages> pp. 86-91, </pages> <month> (January </month> <year> 1991). </year>
Reference-contexts: Finally, global termination conditions (e.g. sums and boolean operations) in a PDES <ref> [AbRi91] </ref> can be calculated and 21 disseminated in the PRN. The applicability of PRN's is not limited to parallel simulation; PRN's can be efficiently used in many application areas that require the rapid dissemination of global synchronization results. For example, the PRN can support a variety of parallel numerical computations.
Reference: [Ayan89] <author> Ayani, R., </author> <title> "A Parallel Simulation Scheme Based on Distances Between Objects", </title> <booktitle> Proceedings of the SCS Multiconference on Distributed Simulation, </booktitle> <address> Tampa, Florida, </address> <pages> pp. 113-118, </pages> <month> (March </month> <year> 1989). </year>
Reference-contexts: Non-aggressive protocols can be enhanced by disseminating minimum lookahead [Fuji88] values through the PRN. Iterative PDES algorithms often require the rapid computation and dissemination of ceiling values or fault values. (See [Dick90], [Luba88], [Luba89], [SoSH89], [SoBW88], <ref> [Ayan89] </ref>.) Aggressive protocols [Jeff85] can be enhanced by the efficient computation of GVT and by limiting aggressive processing without the simulation deadlocking.
Reference: [Blel89] <author> Blelloch, G. E., </author> <title> "Scans as Primitive Parallel Operations", </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 38, No. 11, </volume> <pages> pp. 1526-1538, </pages> <month> (November </month> <year> 1989). </year>
Reference-contexts: The tree structure of the PRN facilitates the pipelining since a tree circuit is easier to synchronize than other structures <ref> [Blel89] </ref>. The PRN, however, operates asynchronously to the PP's, and it does not block if an input register has not been updated during the previous major cycle. 13 Each node of the PRN operates asynchronously. <p> Researchers at IBM have constructed a configuration of barrier synchronization modules [HeRS89] as a low-cost device for barrier synchronization. The hardware that we propose, on the other hand, provides support for a larger class of algorithms than barrier synchronization algorithms. Blelloch <ref> [Blel89] </ref> proposed a tree-structured hardware implementation of parallel prefix operations. One of our future goals is to enhance our hardware design to calculate and disseminate "target specific" synchronization information in a PDES. Parallel prefix computations may be useful in realizing that goal. 11.
Reference: [BuRo90] <author> Buzzell, C. A. and Robb, M. J., </author> <title> "Modular VME Rollback Hardware for Time Warp", </title> <booktitle> Proceedings of the SCS Multiconference on Distributed Simulation, </booktitle> <address> San Diego, California, </address> <pages> pp. 153-156, </pages> <month> (January </month> <year> 1990). </year>
Reference-contexts: Fujimoto, et. al., developed the rollback chip [FuTG88a, FuTG88b] as a hardware enhancement to a Time Warp engine. The rollback chip is a memory management unit that facilitates the state saving and restoration that is inherent in aggressive protocols such as Time Warp. As reported in <ref> [BuRo90] </ref> the chip has excellent performance capabilities. At about the same time that Reynolds introduced the framework, Filoque, et.al., [FiGP91] proposed the use of a processor network with programmable logic for efficient global computations, such as the computation of GVT in a Time Warp simulation.
Reference: [ChMi79] <author> Chandy, K. M. and Misra, J., </author> <title> "Distributed Simulation: A Case Study in Design and Verification of Distributed Programs", </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. SE-5, No. 5, </volume> <pages> pp. 440-452, </pages> <month> (September </month> <year> 1979). </year>
Reference-contexts: There are two common approaches to PDES synchronization protocols: non-aggressive and aggressive. Non-aggressive protocols, as discussed in <ref> [ChMi79] </ref>, must determine when it is safe 3 to process an event in order to avoid causality errors. Aggressive approaches, the most well--known is Time Warp based on Jefferson's virtual time model [Jeff85], do not avoid causality errors but rather detect them and correct them using rollback.
Reference: [CrKn85] <author> Crockett, T. W. and Knott, J. D., </author> <title> "System Software for the Finite Element Machine", </title> <type> NASA Contractor Report 3870, </type> <institution> NASA Langley, Hampton, Virginia, </institution> <month> February </month> <year> 1985. </year>
Reference-contexts: The conjugate gradient method, which is a popular iterative method for solving linear equations, is an example of an algorithm which benefits from an efficient inner product computation. The PRN can also support the same numerical applications for which the Finite Element Machine (FEM) <ref> [CrKn85] </ref> was developed. 22 The PRN as defined above can also support barrier synchronization as defined in [Ston90]. <p> The Finite Element Machine, a NASA prototype, utilizes a binary tree-structured max/summation network to perform the global sum and maximum calculations necessary to support structural analysis algorithms based on the finite element method <ref> [CrKn85, JoSc79] </ref>. Like the hardware we propose, the sum and max calculations in the FEM are calculated alternately without processor synchronization. Our hardware design, however, employs a small set of input and output registers, whereas the network in the FEM uses a single input and a single output register.
Reference: [Dick90] <author> Dickens, P. M., </author> <title> "An Analytic Investigation of the Global Rollback Algorithm", A Research Proposal, </title> <institution> Department of Computer Science, University of Virginia, Charlottesville, Virginia, </institution> <month> September </month> <year> 1990. </year> <month> 29 </month>
Reference-contexts: Besides supporting the parallel simulation framework, there are several ways in which a PRN can support PDES implementations. Non-aggressive protocols can be enhanced by disseminating minimum lookahead [Fuji88] values through the PRN. Iterative PDES algorithms often require the rapid computation and dissemination of ceiling values or fault values. (See <ref> [Dick90] </ref>, [Luba88], [Luba89], [SoSH89], [SoBW88], [Ayan89].) Aggressive protocols [Jeff85] can be enhanced by the efficient computation of GVT and by limiting aggressive processing without the simulation deadlocking.
Reference: [FiGP91] <author> Filoque, J. M., Gautrin, E. and Pottier, B., </author> <title> "Efficient Global Computations on a Processors Network with Programmable Logic", </title> <type> Report 1374, </type> <institution> Institut National de Recherche en Informatique et en Anutomatique, France, </institution> <month> January </month> <year> 1991. </year>
Reference-contexts: The rollback chip is a memory management unit that facilitates the state saving and restoration that is inherent in aggressive protocols such as Time Warp. As reported in [BuRo90] the chip has excellent performance capabilities. At about the same time that Reynolds introduced the framework, Filoque, et.al., <ref> [FiGP91] </ref> proposed the use of a processor network with programmable logic for efficient global computations, such as the computation of GVT in a Time Warp simulation. This hardware is not a single network like the PRN; it is, however, a distributed system of sockets, one per processor. <p> When the token returns to the controller, the global computation is complete. Therefore, their proposed hardware performs global computations in O (n) time whereas the PRN performs the same computations in O (logn) time. Furthermore, the proposed synchronization algorithms for computing GVT in <ref> [FiGP91] </ref> rely on the host communication network for message acknowledgements and our framework uses the PRN. The goals of both approaches are similar, but our framework is more efficient, more flexible, and more scalable. 10.
Reference: [FoJL88] <author> Fox, G., Johnson, M., Lyzenga, G., Otto, S., Salmon, J. and Walker, D., </author> <title> Solving Problems on Concurrent Processors, Volume 1, </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1988. </year>
Reference-contexts: In [Reyn92], it was shown how the PRN can effectively support PDES. We have also shown how the PRN can support parallel numerical calculations and barrier synchronization. We feel that this network can effectively improve the running time of many other loosely synchronous computations <ref> [FoJL88] </ref> that periodically require a small amount of global synchronization information to be disseminated. The novel features of this network are a network interface which preserves state vectors and the use of an auxiliary processor to manage high-frequency data asynchronously to the host processor's computation.
Reference: [Fuji88] <author> Fujimoto, R. M., </author> <title> "Lookahead in Parallel Discrete Event Simulation", </title> <booktitle> Proceedings of the 1988 International Conference on Parallel Processing, </booktitle> <address> University Park, Pennsylvania, </address> <pages> pp. 34-41, </pages> <month> (August </month> <year> 1988). </year>
Reference-contexts: APPLICATIONS OF THE PRN BEYOND PARALLEL SIMULATION We have introduced the PRN as a hardware network supporting PDES. Besides supporting the parallel simulation framework, there are several ways in which a PRN can support PDES implementations. Non-aggressive protocols can be enhanced by disseminating minimum lookahead <ref> [Fuji88] </ref> values through the PRN. Iterative PDES algorithms often require the rapid computation and dissemination of ceiling values or fault values. (See [Dick90], [Luba88], [Luba89], [SoSH89], [SoBW88], [Ayan89].) Aggressive protocols [Jeff85] can be enhanced by the efficient computation of GVT and by limiting aggressive processing without the simulation deadlocking.
Reference: [FuTG88a] <author> Fujimoto, R. M., Tsai, J. and Gopalakrishnan, G. C., </author> <title> "Design and Evaluation of the Rollback Chip: Special Purpose Hardware for Time Warp", </title> <type> Technical Report No. </type> <institution> UUCS-88-011, Department of Computer Science, University of Utah, </institution> <address> Salt Lake City, Utah, </address> <month> July </month> <year> 1988. </year>
Reference-contexts: Furthermore, by rapidly disseminating GVT and by limiting aggressive processing, the PRN can benefit a PDES that uses the rollback chip <ref> [FuTG88a, FuTG88b] </ref>, a high-speed memory device which enhances a Time Warp simulation; the PRN provides accurate state information which facilitates fossil collection on the rollback chip. Finally, global termination conditions (e.g. sums and boolean operations) in a PDES [AbRi91] can be calculated and 21 disseminated in the PRN. <p> Fujimoto initially targeted the Virtual Time Machine [Fuji89] as hardware support for discrete event simulation, but this machine is now intended to utilize an aggressive style of execution in a general purpose parallel computer. Fujimoto, et. al., developed the rollback chip <ref> [FuTG88a, FuTG88b] </ref> as a hardware enhancement to a Time Warp engine. The rollback chip is a memory management unit that facilitates the state saving and restoration that is inherent in aggressive protocols such as Time Warp. As reported in [BuRo90] the chip has excellent performance capabilities.
Reference: [FuTG88b] <author> Fujimoto, R. M., Tsai, J. J. and Gopalakrishnan, G., </author> <title> "The Roll Back Chip: Hardware Support for Distributed Simulation Using Time Warp", </title> <booktitle> Proceedings of the SCS Multiconference on Distributed Simulation, </booktitle> <address> San Diego, California, </address> <pages> pp. 81-86, </pages> <month> (February </month> <year> 1988). </year>
Reference-contexts: Furthermore, by rapidly disseminating GVT and by limiting aggressive processing, the PRN can benefit a PDES that uses the rollback chip <ref> [FuTG88a, FuTG88b] </ref>, a high-speed memory device which enhances a Time Warp simulation; the PRN provides accurate state information which facilitates fossil collection on the rollback chip. Finally, global termination conditions (e.g. sums and boolean operations) in a PDES [AbRi91] can be calculated and 21 disseminated in the PRN. <p> Fujimoto initially targeted the Virtual Time Machine [Fuji89] as hardware support for discrete event simulation, but this machine is now intended to utilize an aggressive style of execution in a general purpose parallel computer. Fujimoto, et. al., developed the rollback chip <ref> [FuTG88a, FuTG88b] </ref> as a hardware enhancement to a Time Warp engine. The rollback chip is a memory management unit that facilitates the state saving and restoration that is inherent in aggressive protocols such as Time Warp. As reported in [BuRo90] the chip has excellent performance capabilities.
Reference: [Fuji89] <author> Fujimoto, R. M., </author> <title> "The Virtual Time Machine", </title> <booktitle> Proceedings of the 1989 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <address> Santa Fe, New Mexico, </address> <pages> pp. 199-208, </pages> <month> (June </month> <year> 1989). </year>
Reference-contexts: The current trend in this area of research, however, is to design a high performance, discrete event simulation 24 engine. Fujimoto initially targeted the Virtual Time Machine <ref> [Fuji89] </ref> as hardware support for discrete event simulation, but this machine is now intended to utilize an aggressive style of execution in a general purpose parallel computer. Fujimoto, et. al., developed the rollback chip [FuTG88a, FuTG88b] as a hardware enhancement to a Time Warp engine.
Reference: [Fuji90] <author> Fujimoto, R. M., </author> <title> "Parallel Discrete Event Simulation", </title> <journal> Communications of the ACM, </journal> <volume> Vol. 33, No. 10, </volume> <pages> pp. 30-53, </pages> <month> (October </month> <year> 1990). </year>
Reference-contexts: 1. INTRODUCTION Recently Reynolds [Reyn92] proposed a novel framework for providing rapid dissemination of critical synchronization information in all parallel discrete event simulation (PDES) <ref> [Fuji90] </ref> implementations. This framework can produce a significant reduction in the finishing times of parallel simulations. The strength of this framework lies in its use of special-purpose, high-speed hardware, specifically a parallel reduction network (PRN) which computes and disseminates results of global reduction operations. <p> A parallel simulation will be correct if and only if each LP processes events in nondecreasing timestamp order. Adherence to this local causality constraint is sufficient, though not always necessary, to guarantee the absence of causality errors <ref> [Fuji90] </ref>. However, there is no way of guaranteeing that messages received by LP i occur in a specific order due to both the asynchronous nature of LP's logical clocks and communications delays in the host network. There are two common approaches to PDES synchronization protocols: non-aggressive and aggressive.
Reference: [HeRS89] <author> Heidelberger, P., Rathi, B. D. and Stone, H. S., </author> <title> "A Low-Cost Device for Contention-Free Barrier Synchronization", </title> <journal> IBM Technical Disclosure Bulletin, </journal> <volume> Vol. 31, No. 11, </volume> <pages> pp. 382-389, </pages> <month> (April </month> <year> 1989), </year> <institution> IBM Research. </institution>
Reference-contexts: The PRN also supports barrier synchronization among a set of all processors since non-participating processors can simply contribute a positive flag to the logical reduction operation and not block execution. Furthermore, the PRN supports multiple barriers [Ston90] efficiently without additional hardware <ref> [HeRS89] </ref> since the PRN already has a set of input registers. A PRN-like network can support an approach to load sharing we call Waterfall Load Sharing (WFLS). WFLS takes into account the distance a relocated process's remote data accesses (back to its home processor) must traverse. <p> Stone [Ston90] suggests the use of global busses to find the maximum value in a set and to implement Fetch-and-increment as a synchronization technique. Researchers at IBM have constructed a configuration of barrier synchronization modules <ref> [HeRS89] </ref> as a low-cost device for barrier synchronization. The hardware that we propose, on the other hand, provides support for a larger class of algorithms than barrier synchronization algorithms. Blelloch [Blel89] proposed a tree-structured hardware implementation of parallel prefix operations.
Reference: [Hosh85] <author> Hoshino, T., </author> <title> PAX Computer: High-Speed Parallel Processing and Scientific Computing, </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, Massachusetts, </address> <year> 1985. </year>
Reference-contexts: Furthermore, our 26 hardware design employs auxiliary processors to manage the high-speed data emitted from the PRN, and the PRN computes reductions on state vectors. Several researchers have proposed the use of hardware to implement barrier synchronization. In Hoshino's PAX Computer <ref> [Hosh85] </ref> barrier synchronization is accomplished by each processor setting a single bit such that the collection of bits is fed into an AND gate and an OR gate, and the outputs of both gates are bussed to all processors.
Reference: [Inte89] <author> Intel Corporation, </author> <title> iPSC/2 Programmer's Reference Manual, Intel Scientific Computers, </title> <institution> Beaverton, Oregon, </institution> <month> October </month> <year> 1989. </year> <month> 30 </month>
Reference-contexts: Furthermore, our proposed synchronization network is also enhanced to satisfy correctness criteria for our PDES framework. Global operations on the Intel iPSC/2 <ref> [Inte89] </ref> are provided for arithmetic and logical binary associative operations where each processor contributes a value and all processors receive the result.
Reference: [Jeff85] <author> Jefferson, D. R., </author> <title> "Virtual Time", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 7, No. 3, </volume> <pages> pp. 404-425, </pages> <month> (July </month> <year> 1985). </year>
Reference-contexts: There are two common approaches to PDES synchronization protocols: non-aggressive and aggressive. Non-aggressive protocols, as discussed in [ChMi79], must determine when it is safe 3 to process an event in order to avoid causality errors. Aggressive approaches, the most well--known is Time Warp based on Jefferson's virtual time model <ref> [Jeff85] </ref>, do not avoid causality errors but rather detect them and correct them using rollback. The framework for PDES introduced in [Reyn92] is a low-level synchronization mechanism that sits below a PDES synchronization protocol. It disseminates a small set of globally reduced values. <p> The single cell registers are treated as a single state vector output from the reduction network. The host processor can compute global virtual time (GVT) <ref> [Jeff85] </ref> and make adaptive processing decisions based on the global synchronization values. In addition to executing the SENDMSG and RCVMSG algorithms in Figure 1, the auxiliary processor executes all message acknowledgement algorithms, such as CHKACK in Figure 1. <p> Non-aggressive protocols can be enhanced by disseminating minimum lookahead [Fuji88] values through the PRN. Iterative PDES algorithms often require the rapid computation and dissemination of ceiling values or fault values. (See [Dick90], [Luba88], [Luba89], [SoSH89], [SoBW88], [Ayan89].) Aggressive protocols <ref> [Jeff85] </ref> can be enhanced by the efficient computation of GVT and by limiting aggressive processing without the simulation deadlocking.
Reference: [JoSc79] <author> Jordan, H. F., Scalabrin, M. and Calvert, W., </author> <title> "A Comparison of Three Types of Multiprocessor Algorithms", </title> <booktitle> Proceedings of the 1979 International Conference on Parallel Processing, </booktitle> <pages> pp. 231-238, </pages> <month> (August </month> <year> 1979). </year>
Reference-contexts: The Finite Element Machine, a NASA prototype, utilizes a binary tree-structured max/summation network to perform the global sum and maximum calculations necessary to support structural analysis algorithms based on the finite element method <ref> [CrKn85, JoSc79] </ref>. Like the hardware we propose, the sum and max calculations in the FEM are calculated alternately without processor synchronization. Our hardware design, however, employs a small set of input and output registers, whereas the network in the FEM uses a single input and a single output register.
Reference: [Lill91] <author> Lillevik, S. L., </author> <title> "The Touchstone 30 Gigaflop DELTA Prototype", </title> <booktitle> Proceedings of the Sixth Distributed Memory Computing Conference, Portland, Oregon, </booktitle> <pages> pp. 671-677, </pages> <year> (1991). </year>
Reference-contexts: Of courses, advances made in dissemination of target specific of information would be beneficial as well. As noted, this latter activity is an open research issue. The trend in distributed memory parallel architectures is a mesh-connected communication topology; Intel's Touchstone DELTA machine <ref> [Lill91] </ref> is one such example. While this architecture is scalable to a larger number of processors than a hypercube, the number of hops between two processors can exceed log n, where n is the total number of processors.
Reference: [LiMa85] <author> Livny, M. and Manber, U., </author> <title> "Distributed Computation Via Active Messages", </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. C-34, No. 12, </volume> <pages> pp. 1185-1190, </pages> <month> (December </month> <year> 1985). </year>
Reference-contexts: His control synchronization network is presented strictly in support of the bounded lag protocol; nonetheless, this has served as a motivating factor in our approach. Hardware enhancements for Time Warp have been prevalent in the research; for example, Livny and Manber suggested using token rings for disseminating GVT <ref> [LiMa85] </ref>. The current trend in this area of research, however, is to design a high performance, discrete event simulation 24 engine.
Reference: [Luba88] <author> Lubachevsky, B. D., </author> <title> "Bounded Lag Distributed Discrete Event Simulation", </title> <booktitle> Proceedings of the SCS Multiconference on Distributed Simulation, </booktitle> <address> San Diego, California, </address> <pages> pp. 183-191, </pages> <month> (February </month> <year> 1988). </year>
Reference-contexts: Non-aggressive protocols can be enhanced by disseminating minimum lookahead [Fuji88] values through the PRN. Iterative PDES algorithms often require the rapid computation and dissemination of ceiling values or fault values. (See [Dick90], <ref> [Luba88] </ref>, [Luba89], [SoSH89], [SoBW88], [Ayan89].) Aggressive protocols [Jeff85] can be enhanced by the efficient computation of GVT and by limiting aggressive processing without the simulation deadlocking. <p> In addition, simulation programs, especially those employing aggressive processing, often utilize a large amount of memory. Therefore, future research in the area of hardware support for PDES is important. The use of special-purpose hardware to improve the performance of simulation programs is not novel. Lubachevsky <ref> [Luba88] </ref> suggests using a binary tree implemented in hardware in order to support synchronization barriers and to compute and broadcast a minimum next event time in a bounded lag PDES.
Reference: [Luba89] <author> Lubachevsky, B. D., </author> <title> "Efficient Distributed Event-Driven Simulations of Multiple-Loop Networks", </title> <journal> Communications of the ACM, </journal> <volume> Vol. 32, No. 1, </volume> <pages> pp. 111-123, </pages> <month> (January </month> <year> 1989). </year>
Reference-contexts: Non-aggressive protocols can be enhanced by disseminating minimum lookahead [Fuji88] values through the PRN. Iterative PDES algorithms often require the rapid computation and dissemination of ceiling values or fault values. (See [Dick90], [Luba88], <ref> [Luba89] </ref>, [SoSH89], [SoBW88], [Ayan89].) Aggressive protocols [Jeff85] can be enhanced by the efficient computation of GVT and by limiting aggressive processing without the simulation deadlocking.
Reference: [Misr86] <author> Misra, J., </author> <title> "Distributed Discrete-Event Simulation", </title> <journal> Computing Surveys, </journal> <volume> Vol. 18, No. 1, </volume> <pages> pp. 39-65, </pages> <month> (March </month> <year> 1986). </year>
Reference-contexts: Finally, we describe a prototype PRN which is currently being designed and built by the Departments of Computer Science and Electrical Engineering at the University of Virginia. 2. REQUIREMENTS FOR PARALLEL SIMULATION A general model of a PDES is introduced in <ref> [Misr86] </ref>. A PDES consists of a set of logical processes (LP's) that model physical processes in a system. All interactions among physical processes are modeled by event messages sent among LP's. Each message contains a timestamp indicating the logical time at which a scheduled event will occur.
Reference: [Panc92] <author> Pancerella, C. M., </author> <title> "Improving the Efficiency of a Framework for Parallel Simulations", </title> <booktitle> to appear in the Proceedings of the SCS Multiconference on Advances in Parallel and Distributed Simulation, </booktitle> <address> Newport Beach, California, </address> <month> (January </month> <year> 1992). </year>
Reference-contexts: The globally reduced values for message acknowledgements were introduced in <ref> [Panc92] </ref>. Without loss of generality, it is assumed that each LP i occupies a unique physical processor PP i . <p> These global values, together with the following synchronization algorithms (which appear in [Reyn92] and <ref> [Panc92] </ref>), are sufficient to support deadlock-free parallel simulation, independent of the application being simulated. 4 hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh TEST: IF [(T h i = T h ) AND (T h i T u ) ] --Identify the next event in system. <p> This is discussed in greater detail in <ref> [Panc92] </ref>. As seen in Figure 4, an ordered buffer of tagged messages is used for communication from the host processor to the auxiliary processor. The host processor writes into the buffer while the AP reads from the buffer.
Reference: [PfNo85] <author> Pfister, G. F. and Norton, V. A., </author> <title> "'Hot Spot' Contention and Combining in Multistage Interconnection Networks", </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. C-34, No. 10, </volume> <pages> pp. 943-948, </pages> <month> (October </month> <year> 1985). </year>
Reference-contexts: In a shared memory machine, the frequent update of a small amount of global information can be a source of memory contention or hot spots <ref> [PfNo85] </ref>. The PRN eliminates the synchronization traffic both in the interconnection network and at the global memory. 14 6. AN AUXILIARY NETWORK PROCESSOR Auxiliary, general-purpose processors are added at the interface of the reduction network, one processor per host processor, in order to manage the high-speed I/O with the PRN.
Reference: [PfBG85] <author> Pfister, G. F., Brantley, W. C., George, D. A., Harvey, S. L., Kleinfelder, W. J., McAuliffe, K. P., Melton, E. A., Norton, V. A. and Weiss, J., </author> <title> "The IBM Research Parallel Prototype (RP3): Introduction and Architecture", </title> <booktitle> Proceedings of the 1985 International Conference on Parallel Processing, </booktitle> <address> St. Charles, </address> <publisher> Illinois, </publisher> <pages> pp. 764-771, </pages> <month> (August </month> <year> 1985). </year> <month> 31 </month>
Reference-contexts: The goals of both approaches are similar, but our framework is more efficient, more flexible, and more scalable. 10. RELATED SYNCHRONIZATION NETWORKS The proposal of using a separate synchronization network for improving system performance is not new. The IBM RP3 <ref> [PfBG85] </ref> was designed as a shared memory multiprocessor that houses both a combining network for synchronization traffic and a low 25 latency network for regular message traffic. Our proposed special-purpose hardware is not as complex or expensive as a combining network, yet it performs global synchronization operations very efficiently.
Reference: [Reyn92] <author> Reynolds Jr., P. F., </author> <title> "An Efficient Framework for Parallel Simulations", </title> <note> to appear in International Journal on Computer Simulation, </note> <year> (1992). </year>
Reference-contexts: 1. INTRODUCTION Recently Reynolds <ref> [Reyn92] </ref> proposed a novel framework for providing rapid dissemination of critical synchronization information in all parallel discrete event simulation (PDES) [Fuji90] implementations. This framework can produce a significant reduction in the finishing times of parallel simulations. <p> We propose using PRN's in conjunction with both shared memory and distributed memory parallel architectures as a means of rapidly disseminating a small amount of critical synchronization information in a PDES. This paper is a companion paper to <ref> [Reyn92] </ref>; it describes requirements for a PDES and elaborates on the hardware implementation of the PRN that satisfies these requirements in accordance with established correctness criteria. In Section 2 we explain the requirements for PDES and briefly review the framework algorithms. <p> Aggressive approaches, the most well--known is Time Warp based on Jefferson's virtual time model [Jeff85], do not avoid causality errors but rather detect them and correct them using rollback. The framework for PDES introduced in <ref> [Reyn92] </ref> is a low-level synchronization mechanism that sits below a PDES synchronization protocol. It disseminates a small set of globally reduced values. Operations are carried out in a synchronization network that is completely transparent to LP's. <p> These global values, together with the following synchronization algorithms (which appear in <ref> [Reyn92] </ref> and [Panc92]), are sufficient to support deadlock-free parallel simulation, independent of the application being simulated. 4 hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh TEST: IF [(T h i = T h ) AND (T h i T u ) ] --Identify the next event in system. <p> A SYNCHRONIZATION NETWORK The block diagram of a network supporting efficient synchronization, as shown in Figure 2, was given in <ref> [Reyn92] </ref>. <p> This network is easily realized in hardware, cost-efficient, and scalable. Furthermore, this network can be useful in a shared memory multiprocessor or a distributed memory multicomputer. In <ref> [Reyn92] </ref>, it was shown how the PRN can effectively support PDES. We have also shown how the PRN can support parallel numerical calculations and barrier synchronization.
Reference: [SoBW88] <author> Sokol, L. M., Briscoe, D. P. and Wieland, A. P., "MTW: </author> <title> A Strategy for Scheduling Discrete Simulation Events for Concurrent Execution", </title> <booktitle> Proceedings of the SCS Multiconference on Distributed Simulation, </booktitle> <address> San Diego, California, </address> <pages> pp. 34-42, </pages> <month> (February </month> <year> 1988). </year>
Reference-contexts: Non-aggressive protocols can be enhanced by disseminating minimum lookahead [Fuji88] values through the PRN. Iterative PDES algorithms often require the rapid computation and dissemination of ceiling values or fault values. (See [Dick90], [Luba88], [Luba89], [SoSH89], <ref> [SoBW88] </ref>, [Ayan89].) Aggressive protocols [Jeff85] can be enhanced by the efficient computation of GVT and by limiting aggressive processing without the simulation deadlocking.
Reference: [SoSH89] <author> Sokol, L. M., Stucky, B. K. and Hwang, V. S., "MTW: </author> <title> A Control Mechanism for Parallel Discrete Simulation", </title> <booktitle> Proceedings of the 1989 International Conference on Parallel Processing, </booktitle> <address> University Park, Pennsylvania, </address> <pages> pp. 34-41, </pages> <month> (August </month> <year> 1989). </year>
Reference-contexts: Non-aggressive protocols can be enhanced by disseminating minimum lookahead [Fuji88] values through the PRN. Iterative PDES algorithms often require the rapid computation and dissemination of ceiling values or fault values. (See [Dick90], [Luba88], [Luba89], <ref> [SoSH89] </ref>, [SoBW88], [Ayan89].) Aggressive protocols [Jeff85] can be enhanced by the efficient computation of GVT and by limiting aggressive processing without the simulation deadlocking.
Reference: [Ston90] <author> Stone, H. S., </author> <title> High-Performance Computer Architecture, </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: The PRN can also support the same numerical applications for which the Finite Element Machine (FEM) [CrKn85] was developed. 22 The PRN as defined above can also support barrier synchronization as defined in <ref> [Ston90] </ref>. Each processor can submit a flag to the PRN, and all processes can block until the global reduction operation (a logical operation, in this case) reflects when the barrier has been reached by all processors. <p> The PRN also supports barrier synchronization among a set of all processors since non-participating processors can simply contribute a positive flag to the logical reduction operation and not block execution. Furthermore, the PRN supports multiple barriers <ref> [Ston90] </ref> efficiently without additional hardware [HeRS89] since the PRN already has a set of input registers. A PRN-like network can support an approach to load sharing we call Waterfall Load Sharing (WFLS). <p> In Hoshino's PAX Computer [Hosh85] barrier synchronization is accomplished by each processor setting a single bit such that the collection of bits is fed into an AND gate and an OR gate, and the outputs of both gates are bussed to all processors. Stone <ref> [Ston90] </ref> suggests the use of global busses to find the maximum value in a set and to implement Fetch-and-increment as a synchronization technique. Researchers at IBM have constructed a configuration of barrier synchronization modules [HeRS89] as a low-cost device for barrier synchronization.
Reference: [Thin92] <institution> Thinking Machines Corporation, The Connection Machine CM-5 Technical Summary , Thinking Machines Corporation, Cambridge, Massachusetts, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: We estimate that a global operation can be performed in 750 nanoseconds for a 32-processor machine using a PRN (assuming 150 ns. per PRN stage as described later). The Thinking Machines' CM-5 <ref> [Thin92] </ref> has comparable speeds for performing arithmetic reduction operations, yet a PRN can compute and disseminate global reduction results on state vectors without the coordination of the host processors. <p> They require the complete synchronization of all processors; all processors must contribute a new value to each global operation and a global operation blocks until all processors enter one. Our approach is asynchronous (i.e., allows stale data to be contributed to global operations). The CM-5 <ref> [Thin92] </ref> contains two separate networks for different types of communication and synchronization: the data network is the primary message-passing network in the machine and the control network provides hardware support for common cooperative operations.
References-found: 32

