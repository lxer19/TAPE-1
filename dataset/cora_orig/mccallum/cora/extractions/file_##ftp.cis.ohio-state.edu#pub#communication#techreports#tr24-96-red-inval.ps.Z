URL: file://ftp.cis.ohio-state.edu/pub/communication/techreports/tr24-96-red-inval.ps.Z
Refering-URL: http://www.cis.ohio-state.edu/~dai/
Root-URL: 
Title: Reducing Cache Invalidation Overheads in Wormhole Routed DSMs Using Multidestination Message Passing  
Abstract: Donglai Dai and Dhabaleswar K. Panda Technical Report OSU-CISRC-4/96-TR21 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Amza, A. L. Cox, and et al. Treadmarks: </author> <title> Shared memory computing on networks of workstations. </title> <journal> IEEE Computer, </journal> <volume> 29(2) </volume> <pages> 18-28, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: The home node receives all these acknowledgments and then provides exclusive-write access to the writer node requesting the cache block. This last step is necessary to maintain sequential consistency [13]. Variations of this sequence of steps are used to support other consistency models like release consistency and lazy consistency <ref> [1] </ref>. In addition to such invalidation schemes, data-forwarding schemes have also been recently introduced in the literature [21] to reduce cache misses in DSM systems.
Reference: [2] <author> S. Balakrishnan and D. K. Panda. </author> <title> Impact of Multiple Consumption Channels on Wormhole Routed k-ary n-cube Networks. </title> <booktitle> In Proceedings of the International Parallel Processing Symposium, </booktitle> <pages> pages 163-167, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Interestingly, in addition to solving the deadlock problem, having multiple consumption channels from a router interface to the associated node also helps to alleviate the degradation of network throughput and to reduce the network latency caused by the hot-spot effects <ref> [2] </ref>. 4.3.4 Virtual Cut-Through and Deferred-Delivery No consumption channel reservation is needed at any intermediate destination for an i-gather worm. However, the i-gather worm can not move if the i-ack signal to be collected at the router has not arrived from the associated node.
Reference: [3] <author> L. A. Barroso and M. Dubois. </author> <title> Cache Coherence on a Slotted Ring. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <pages> pages I:230-237, </pages> <month> Aug </month> <year> 1991. </year>
Reference-contexts: In recent years, most research related to DSM systems have emphasized on designing efficient directory structures, designing new cache coherence protocols, deriving optimal cache sizes, analyzing cache invalidation patterns, and reducing synchronization overheads <ref> [3, 16, 19, 22, 25, 34] </ref>. However, very little research is done towards reducing overheads of cache coherence protocols on message-passing systems by taking advantage of underlying interconnection networks and routing schemes. Directory-based cache coherence protocols can use either write-invalidation or write-update schemes.
Reference: [4] <author> R. V. Boppana, S. Chalasani, and C. S. Raghavendra. </author> <title> On Multicast Wormhole Routing in Multicomputer Networks. </title> <booktitle> In Symposium on Parallel and Distributed Processing, </booktitle> <pages> pages 722-729, </pages> <year> 1994. </year>
Reference-contexts: With the increasing popularity of wormhole-routing switching technique many new adaptive routing schemes have been proposed in the literature 1 [7, 14, 20, 41, 45]. Similarly, many new multicasting schemes and mechanisms have also been proposed <ref> [4, 31, 39] </ref>. These developments lead to a natural question whether we can take advantage of these routing schemes and mechanisms to reduce cache coherence overheads in DSM systems.
Reference: [5] <author> A. A. Chien and J. H. Kim. </author> <title> Planar-Adaptive Routing: Low-Cost Adaptive Networks for Multiprocessors. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 268-277, </pages> <year> 1992. </year>
Reference-contexts: Interested readers are encouraged to refer [37, 38, 39] for details. 3.1 The BRCP Model Let us assume a network supporting a deadlock-free routing scheme R for unicast message passing. This routing R could be e-cube [6], planar-adaptive <ref> [5] </ref>, turn-model [15], fully-adaptive [7], or any other routing scheme. We identify R as the base-routing. <p> For example, in an ecube system (assuming messages are routed first along the row and then along the column), a multidestination worm can cover a set of destinations in row/column/row-column order. On a planar adaptive system <ref> [5] </ref>, a multidestination worm can cover a set of destinations along any diagonal in addition to the flexibility provided by the ecube support. Similarly, other adaptive routing systems like turn-model [15] and fully-adaptive [7] provide flexibility for multidestination worms.
Reference: [6] <author> W. J. Dally and C. L. Seitz. </author> <title> Deadlock-Free Message Routing in Multiprocessor Interconnection Networks. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 547-553, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: In the interconnection networks literature, the former communication pattern is known as multicast and the latter pattern as gather. Both patterns belong to the class of collective communication [30], as defined by the MPI standard [32]. Currently the wormhole-routing switching technique <ref> [6, 33] </ref> is the trend in building scalable parallel systems supporting both distributed-memory and distributed-shared memory programming paradigms. IBM SP1/SP2, Intel Paragon, Cray T3D, Ncube, J-Machine, Stanford DASH, Stanford FLASH, and Alewife are representative systems using this switching technique. <p> Depending on the underlying routing adaptivity we propose different grouping schemes to send cache-invalidation signals and collect acknowledgment signals using minimum number of messages. A set of six different grouping schemes are developed and evaluated for deterministic (e-cube <ref> [6] </ref>) and adaptive (turn-model [15]) routing schemes. For some of these schemes we propose using a small set of invalidation-acknowledgment (i-ack) buffers (2-4) at the router interface to facilitate fast collection of acknowledgment signals. For simplicity, we consider a fully-mapped directory system with sequential consistency. <p> Interested readers are encouraged to refer [37, 38, 39] for details. 3.1 The BRCP Model Let us assume a network supporting a deadlock-free routing scheme R for unicast message passing. This routing R could be e-cube <ref> [6] </ref>, planar-adaptive [5], turn-model [15], fully-adaptive [7], or any other routing scheme. We identify R as the base-routing.
Reference: [7] <author> J. Duato. </author> <title> A New Theory of Deadlock-Free Adaptive Routing in Wormhole Networks. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(12) </volume> <pages> 1320-1331, </pages> <year> 1993. </year>
Reference-contexts: IBM SP1/SP2, Intel Paragon, Cray T3D, Ncube, J-Machine, Stanford DASH, Stanford FLASH, and Alewife are representative systems using this switching technique. With the increasing popularity of wormhole-routing switching technique many new adaptive routing schemes have been proposed in the literature 1 <ref> [7, 14, 20, 41, 45] </ref>. Similarly, many new multicasting schemes and mechanisms have also been proposed [4, 31, 39]. These developments lead to a natural question whether we can take advantage of these routing schemes and mechanisms to reduce cache coherence overheads in DSM systems. <p> Interested readers are encouraged to refer [37, 38, 39] for details. 3.1 The BRCP Model Let us assume a network supporting a deadlock-free routing scheme R for unicast message passing. This routing R could be e-cube [6], planar-adaptive [5], turn-model [15], fully-adaptive <ref> [7] </ref>, or any other routing scheme. We identify R as the base-routing. <p> On a planar adaptive system [5], a multidestination worm can cover a set of destinations along any diagonal in addition to the flexibility provided by the ecube support. Similarly, other adaptive routing systems like turn-model [15] and fully-adaptive <ref> [7] </ref> provide flexibility for multidestination worms. Such additional paths are shown as bold lines in the figure. base routing schemes in a 2-D mesh. In addition to ecube paths, added flexibility for new paths under west-first and planar routing schemes are shown in bold lines.
Reference: [8] <author> A. Agarwal et al. </author> <title> The MIT Alewife Machine: Architecture and Performance. </title> <booktitle> In International Symposium on Computer Architecture, </booktitle> <pages> pages 2-13, </pages> <year> 1995. </year>
Reference-contexts: DSM systems provide a coherent single programming address space. In order to design scalable parallel systems with DSM paradigm, the current approach used by architects is to support directory-based cache-coherence protocols on top of message-passing hardware <ref> [8, 9, 12] </ref>. In recent years, most research related to DSM systems have emphasized on designing efficient directory structures, designing new cache coherence protocols, deriving optimal cache sizes, analyzing cache invalidation patterns, and reducing synchronization overheads [3, 16, 19, 22, 25, 34]. <p> The outgoing message controller (OC) takes information from DC or CC, generates the desired network messages, and sends them through the router interface. Such organization is similar to other DSM systems like DASH [10] (at cluster level), Alewife <ref> [8] </ref>, FLASH [12], etc. 3 2.2 Directory-based Protocols A directory entry associated with a memory block consists of current state and a pointer array [44]. <p> Table 5 shows the break down of the derived latencies of a clean read-miss to neighboring node. These results are very comparable with the hardware measurement results reported on the DASH [26] machine, the Alewife <ref> [8] </ref> machine and simulation results of the FLASH [17] project. 32 Table 4: Derived typical memory miss latencies in 5ns cycles.
Reference: [9] <author> D. Lenoski et al. </author> <title> The Directory-Based Cache Coherence Protocol for the DASH Multiprocessor. </title> <booktitle> In Proceedings of the 17th Annual Symposium on Computer Architecture, </booktitle> <pages> pages 148-159, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: DSM systems provide a coherent single programming address space. In order to design scalable parallel systems with DSM paradigm, the current approach used by architects is to support directory-based cache-coherence protocols on top of message-passing hardware <ref> [8, 9, 12] </ref>. In recent years, most research related to DSM systems have emphasized on designing efficient directory structures, designing new cache coherence protocols, deriving optimal cache sizes, analyzing cache invalidation patterns, and reducing synchronization overheads [3, 16, 19, 22, 25, 34]. <p> However, very little research is done towards reducing overheads of cache coherence protocols on message-passing systems by taking advantage of underlying interconnection networks and routing schemes. Directory-based cache coherence protocols can use either write-invalidation or write-update schemes. Most of the current generation systems use write-invalidation scheme <ref> [9, 12, 22] </ref>. In such systems, when a request to obtain exclusive-write access comes from a writer node to the home node of a cache block, the home node sends write-invalidation messages to all other nodes having a copy of the cache block.
Reference: [10] <author> D. Lenoski et al. </author> <title> The Stanford DASH Multiprocessor. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 63-79, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: The outgoing message controller (OC) takes information from DC or CC, generates the desired network messages, and sends them through the router interface. Such organization is similar to other DSM systems like DASH <ref> [10] </ref> (at cluster level), Alewife [8], FLASH [12], etc. 3 2.2 Directory-based Protocols A directory entry associated with a memory block consists of current state and a pointer array [44]. <p> While in the acknowledging phase, the Y-dimension links along the column containing the home node are congested. It is to be noted that a strong dependency exists among the request and reply messages for achieving cache coherence. This leads to the inherent deadlocks in the system <ref> [10] </ref>. Avoiding such deadlocks has been a major concern in the design of DSM systems in the past. As a common practice, a pair of separate networks (at least logically separated) are used.
Reference: [11] <author> D. V. James et al. </author> <title> Distributed-Directory Scheme: Scalable Coherent Interface. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 74-77, </pages> <month> June </month> <year> 1990. </year> <month> 40 </month>
Reference-contexts: At each sharing node that the worm reaches, this worm waits for the invalidation of the local cache before leaving the associated router interface and moving to the next router interface along its path. Such an approach is used in IEEE Scalable Coherent Interface (SCI) protocols <ref> [11] </ref>. This design can fulfill our intended reduction in the acknowledgment phase of an invalidation transaction. However, a major concern of the approach is that the processing of the invalidation request at every sharing node on the path of a worm get totally sequentialized in a chained fashion.
Reference: [12] <author> J. Kuskin et al. </author> <title> The Stanford FLASH Multiprocessor. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 302-313, </pages> <year> 1994. </year>
Reference-contexts: DSM systems provide a coherent single programming address space. In order to design scalable parallel systems with DSM paradigm, the current approach used by architects is to support directory-based cache-coherence protocols on top of message-passing hardware <ref> [8, 9, 12] </ref>. In recent years, most research related to DSM systems have emphasized on designing efficient directory structures, designing new cache coherence protocols, deriving optimal cache sizes, analyzing cache invalidation patterns, and reducing synchronization overheads [3, 16, 19, 22, 25, 34]. <p> However, very little research is done towards reducing overheads of cache coherence protocols on message-passing systems by taking advantage of underlying interconnection networks and routing schemes. Directory-based cache coherence protocols can use either write-invalidation or write-update schemes. Most of the current generation systems use write-invalidation scheme <ref> [9, 12, 22] </ref>. In such systems, when a request to obtain exclusive-write access comes from a writer node to the home node of a cache block, the home node sends write-invalidation messages to all other nodes having a copy of the cache block. <p> Such unicast message passing increases traffic and contention in the network. It also makes the home nodes as hot-spots in the system. This has considerable impact on increasing the occupancy of messages at directories <ref> [12, 18] </ref>. Such overheads get translated into high-latency for write operations, leading to degradation on the overall system performance. Recently multidestination message-passing mechanisms have been introduced for wormhole networks to achieve low-latency multicast [28, 39] and gather [38] operations on distributed memory systems. <p> The outgoing message controller (OC) takes information from DC or CC, generates the desired network messages, and sends them through the router interface. Such organization is similar to other DSM systems like DASH [10] (at cluster level), Alewife [8], FLASH <ref> [12] </ref>, etc. 3 2.2 Directory-based Protocols A directory entry associated with a memory block consists of current state and a pointer array [44].
Reference: [13] <author> K. Gharachorloo, D. Lenoski, and et al. </author> <title> Memory Consistency and Event Ordering in Scalable Shared-memory Multiprocessors. </title> <booktitle> In 17th International Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: The home node receives all these acknowledgments and then provides exclusive-write access to the writer node requesting the cache block. This last step is necessary to maintain sequential consistency <ref> [13] </ref>. Variations of this sequence of steps are used to support other consistency models like release consistency and lazy consistency [1]. In addition to such invalidation schemes, data-forwarding schemes have also been recently introduced in the literature [21] to reduce cache misses in DSM systems.
Reference: [14] <author> C. J. Glass and L. Ni. </author> <title> Maximally Fully Adaptive Routing in 2D Meshes. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <pages> pages I:101-104, </pages> <year> 1992. </year>
Reference-contexts: IBM SP1/SP2, Intel Paragon, Cray T3D, Ncube, J-Machine, Stanford DASH, Stanford FLASH, and Alewife are representative systems using this switching technique. With the increasing popularity of wormhole-routing switching technique many new adaptive routing schemes have been proposed in the literature 1 <ref> [7, 14, 20, 41, 45] </ref>. Similarly, many new multicasting schemes and mechanisms have also been proposed [4, 31, 39]. These developments lead to a natural question whether we can take advantage of these routing schemes and mechanisms to reduce cache coherence overheads in DSM systems.
Reference: [15] <author> C. J. Glass and L. Ni. </author> <title> The Turn Model for Adaptive Routing. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 278-287, </pages> <year> 1992. </year>
Reference-contexts: Depending on the underlying routing adaptivity we propose different grouping schemes to send cache-invalidation signals and collect acknowledgment signals using minimum number of messages. A set of six different grouping schemes are developed and evaluated for deterministic (e-cube [6]) and adaptive (turn-model <ref> [15] </ref>) routing schemes. For some of these schemes we propose using a small set of invalidation-acknowledgment (i-ack) buffers (2-4) at the router interface to facilitate fast collection of acknowledgment signals. For simplicity, we consider a fully-mapped directory system with sequential consistency. <p> Interested readers are encouraged to refer [37, 38, 39] for details. 3.1 The BRCP Model Let us assume a network supporting a deadlock-free routing scheme R for unicast message passing. This routing R could be e-cube [6], planar-adaptive [5], turn-model <ref> [15] </ref>, fully-adaptive [7], or any other routing scheme. We identify R as the base-routing. <p> On a planar adaptive system [5], a multidestination worm can cover a set of destinations along any diagonal in addition to the flexibility provided by the ecube support. Similarly, other adaptive routing systems like turn-model <ref> [15] </ref> and fully-adaptive [7] provide flexibility for multidestination worms. Such additional paths are shown as bold lines in the figure. base routing schemes in a 2-D mesh. In addition to ecube paths, added flexibility for new paths under west-first and planar routing schemes are shown in bold lines.
Reference: [16] <author> A. Gupta, W.-D. Weber, and T. Mowry. </author> <title> Reducing Memory and Traffic Requirements for Scalable Directory-Based Cache Coherence Schemes. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <pages> pages I:312-321, </pages> <month> Aug </month> <year> 1990. </year>
Reference-contexts: In recent years, most research related to DSM systems have emphasized on designing efficient directory structures, designing new cache coherence protocols, deriving optimal cache sizes, analyzing cache invalidation patterns, and reducing synchronization overheads <ref> [3, 16, 19, 22, 25, 34] </ref>. However, very little research is done towards reducing overheads of cache coherence protocols on message-passing systems by taking advantage of underlying interconnection networks and routing schemes. Directory-based cache coherence protocols can use either write-invalidation or write-update schemes.
Reference: [17] <author> M. Heinrich, J. Kuskin, </author> <title> and et at. The performance impact of flexibility in the stanford flash multiprocessor. </title> <booktitle> In The sixth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VI), </booktitle> <address> San Jose, CA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: Table 5 shows the break down of the derived latencies of a clean read-miss to neighboring node. These results are very comparable with the hardware measurement results reported on the DASH [26] machine, the Alewife [8] machine and simulation results of the FLASH <ref> [17] </ref> project. 32 Table 4: Derived typical memory miss latencies in 5ns cycles.
Reference: [18] <author> C. Holt, M. Heinrich, J. P. Singh, E. Rothberg, and J. Hennessy. </author> <title> The Effects of Latency, Occupancy, and Bandwidth in Distributed Shared Memory Multiprocessors. </title> <type> Technical Report CSL-TR-95-660, </type> <institution> Computer Systems Laboratory, Stanford University, </institution> <year> 1995. </year>
Reference-contexts: Such unicast message passing increases traffic and contention in the network. It also makes the home nodes as hot-spots in the system. This has considerable impact on increasing the occupancy of messages at directories <ref> [12, 18] </ref>. Such overheads get translated into high-latency for write operations, leading to degradation on the overall system performance. Recently multidestination message-passing mechanisms have been introduced for wormhole networks to achieve low-latency multicast [28, 39] and gather [38] operations on distributed memory systems. <p> Home node occupancy <ref> [18] </ref> reflects the amount of processing time required at a home node in order to send the request messages and receive the acknowledgment messages. It is proportional to the number of messages sent from and received by the home node.
Reference: [19] <author> A. Kagi, N. Abolenein, D. C. Burger, and J. R. Goodman. </author> <title> Techniques for Reducing Overheads of Shared-Memory Multiprocessing. </title> <booktitle> In ACM International Conference on Supercomputing, </booktitle> <pages> pages 11-20, </pages> <year> 1995. </year>
Reference-contexts: In recent years, most research related to DSM systems have emphasized on designing efficient directory structures, designing new cache coherence protocols, deriving optimal cache sizes, analyzing cache invalidation patterns, and reducing synchronization overheads <ref> [3, 16, 19, 22, 25, 34] </ref>. However, very little research is done towards reducing overheads of cache coherence protocols on message-passing systems by taking advantage of underlying interconnection networks and routing schemes. Directory-based cache coherence protocols can use either write-invalidation or write-update schemes.
Reference: [20] <author> J. H. Kim and A. A. Chien. </author> <title> An Evaluation of Planar-Adaptive Routing (PAR). </title> <booktitle> In Proceedings of the Symposium on Parallel and Distributed Pro cessing, </booktitle> <pages> pages 470-478, </pages> <year> 1992. </year>
Reference-contexts: IBM SP1/SP2, Intel Paragon, Cray T3D, Ncube, J-Machine, Stanford DASH, Stanford FLASH, and Alewife are representative systems using this switching technique. With the increasing popularity of wormhole-routing switching technique many new adaptive routing schemes have been proposed in the literature 1 <ref> [7, 14, 20, 41, 45] </ref>. Similarly, many new multicasting schemes and mechanisms have also been proposed [4, 31, 39]. These developments lead to a natural question whether we can take advantage of these routing schemes and mechanisms to reduce cache coherence overheads in DSM systems.
Reference: [21] <author> D. A. Koufaty, X. Chen, D. K. Poulsen, and J. Torrellas. </author> <title> Data Forwarding in Scalable Shared-Memory Multiprocessors. </title> <booktitle> In ACM International Conference on Supercomputing, </booktitle> <pages> pages 255-264, </pages> <year> 1995. </year>
Reference-contexts: This last step is necessary to maintain sequential consistency [13]. Variations of this sequence of steps are used to support other consistency models like release consistency and lazy consistency [1]. In addition to such invalidation schemes, data-forwarding schemes have also been recently introduced in the literature <ref> [21] </ref> to reduce cache misses in DSM systems. Under closer examination, it can be observed that these cache coherence protocols use two fundamental message-passing operations: sending one-to-many messages from one node to a set of other nodes and collecting many-to-one messages from a set of nodes to one node.
Reference: [22] <author> David Kranz, Kirk Johnson, Anant Agrawal, John Kubiatowicz, and Beng-Hom Lim. </author> <title> Integrating Message-Passing and Shared Memory: Early Experience. </title> <booktitle> In Proceedings of Practice and Principle of Parallel Programming. ACM, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: In recent years, most research related to DSM systems have emphasized on designing efficient directory structures, designing new cache coherence protocols, deriving optimal cache sizes, analyzing cache invalidation patterns, and reducing synchronization overheads <ref> [3, 16, 19, 22, 25, 34] </ref>. However, very little research is done towards reducing overheads of cache coherence protocols on message-passing systems by taking advantage of underlying interconnection networks and routing schemes. Directory-based cache coherence protocols can use either write-invalidation or write-update schemes. <p> However, very little research is done towards reducing overheads of cache coherence protocols on message-passing systems by taking advantage of underlying interconnection networks and routing schemes. Directory-based cache coherence protocols can use either write-invalidation or write-update schemes. Most of the current generation systems use write-invalidation scheme <ref> [9, 12, 22] </ref>. In such systems, when a request to obtain exclusive-write access comes from a writer node to the home node of a cache block, the home node sends write-invalidation messages to all other nodes having a copy of the cache block.
Reference: [23] <author> J. Kubiatowicz. </author> <title> Closing the window of vulnerability in multiphase memory transactions: The alewife transaction store. </title> <type> Technical Report MIT/LCS TR 594, </type> <institution> Dept. of Electrical Engineering and Computer Science, MIT, </institution> <address> Cambridge, MA 02139, </address> <month> Feb </month> <year> 1993. </year>
Reference-contexts: Most directory-based cache coherence protocols appeared in literatures assume some implicit order among different types of coherent messages between a home node and a sharing node. The objective is to make the implementation of the coherence protocol simple and efficient. In the past few years, several cache coherence protocols <ref> [23, 42] </ref> allowing out-of-order message delivery between a source-destination pair have been proposed.
Reference: [24] <author> V. Kumar, A. Grama, A. Gupta, and G. Karypis. </author> <title> Introduction to Parallel Computing: Design and Analysis of Algorithms. </title> <address> Benjamin/Cummings, </address> <year> 1994. </year> <month> 41 </month>
Reference-contexts: 1 Introduction The distributed shared memory (DSM) programming paradigm is gaining increasing popularity in the parallel computing community due to the simplicity in programming style that it offers <ref> [24, 35] </ref>. DSM systems provide a coherent single programming address space. In order to design scalable parallel systems with DSM paradigm, the current approach used by architects is to support directory-based cache-coherence protocols on top of message-passing hardware [8, 9, 12].
Reference: [25] <author> A. R. Lebeck and D. A. Wood. </author> <title> Dynamic Self-Invalidation: Reducing Coherence Overhead in Shared-Memory Multiprocessors. </title> <booktitle> In Int'l Symposium on Computer Architecture, </booktitle> <pages> pages 48-59, </pages> <year> 1995. </year>
Reference-contexts: In recent years, most research related to DSM systems have emphasized on designing efficient directory structures, designing new cache coherence protocols, deriving optimal cache sizes, analyzing cache invalidation patterns, and reducing synchronization overheads <ref> [3, 16, 19, 22, 25, 34] </ref>. However, very little research is done towards reducing overheads of cache coherence protocols on message-passing systems by taking advantage of underlying interconnection networks and routing schemes. Directory-based cache coherence protocols can use either write-invalidation or write-update schemes.
Reference: [26] <author> D. Lenoski, J. Laudon, T. Joe, D. Nakahira, L. Stevens, A. Gupta, and J. Hennessy. </author> <title> The DASH Prototype: Logic Overhead and Performance. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(1) </volume> <pages> 41-61, </pages> <month> Jan </month> <year> 1993. </year>
Reference-contexts: Table 5 shows the break down of the derived latencies of a clean read-miss to neighboring node. These results are very comparable with the hardware measurement results reported on the DASH <ref> [26] </ref> machine, the Alewife [8] machine and simulation results of the FLASH [17] project. 32 Table 4: Derived typical memory miss latencies in 5ns cycles.
Reference: [27] <author> X. Lin, P. K. McKinley, and L. M. Ni. </author> <title> Performance Evaluation of Multicast Wormhole Routing in 2D-Mesh Multicomputers. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <pages> pages I:435-442, </pages> <year> 1991. </year>
Reference-contexts: However, in traditional unicast-based wormhole routing, a router interface makes the routing decision based on the information of a fixed portion, usually the first flit, of a worm. For a multidestination worm, as proposed in <ref> [27, 40] </ref>, the effective next destination is always at the beginning portion of the multidestination worm to conform to the above decision making convention. The header flits are stripped off one after another as the worm moves to the final destination.
Reference: [28] <author> X. Lin and L. M. Ni. </author> <title> Deadlock-free Multicast Wormhole Routing in Multicomputer Networks. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 116-124, </pages> <year> 1991. </year>
Reference-contexts: This has considerable impact on increasing the occupancy of messages at directories [12, 18]. Such overheads get translated into high-latency for write operations, leading to degradation on the overall system performance. Recently multidestination message-passing mechanisms have been introduced for wormhole networks to achieve low-latency multicast <ref> [28, 39] </ref> and gather [38] operations on distributed memory systems. This leads to a challenge whether such schemes can be applied to wormhole DSM systems. <p> This leads to collective communication operations (like multicast and gather) to be implemented as multiple phases of unicast message exchange. Such an approach leads to high latency for these operations as well as large number of message exchange in the system. In <ref> [28] </ref> Ni proposed a path-based routing to support multidestination messages (a message with multiple destinations). Such a mechanism allows a multicast/broadcast message to be consumed at a destination node while being forwarded to the next node concurrently. However, the message propagation in this scheme is restricted to Hamiltonian-path routing.
Reference: [29] <author> P. Mannava, A. Kumar, and L. N. Bhuyan. </author> <title> Cache Coherence Architecture for Large Scale Multiprocessors. </title> <booktitle> In Proceedings of the Fifth Workshop on Scalable Shared Memory Multiprocessors, Int'l Symposium on Computer Architecture, </booktitle> <year> 1995. </year>
Reference-contexts: Recently multidestination message-passing mechanisms have been introduced for wormhole networks to achieve low-latency multicast [28, 39] and gather [38] operations on distributed memory systems. This leads to a challenge whether such schemes can be applied to wormhole DSM systems. It has been shown in <ref> [29] </ref> that a single invalidation message with implicit multiple destinations, along hierarchical rings statically defined at configuration time on a hypercube machine, can be used over a broadcast network to reduce cache coherence overheads. <p> Besides the third, all other frameworks have been discussed earlier in this paper. This third framework is proposed by Bhuyan's research group <ref> [29] </ref> in Texas A&M. It uses collective communication (pre-embedded hierarchical ring broadcast) mechanism 18 for implementing fast invalidations (when the overflow bits of the pointer arrays in directory are set).
Reference: [30] <author> P. K. Mckinley and D. F. Robinson. </author> <title> Collective Communication in Wormhole-Routed Massively Parallel Computers. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 39-50, </pages> <month> Dec </month> <year> 1995. </year>
Reference-contexts: In the interconnection networks literature, the former communication pattern is known as multicast and the latter pattern as gather. Both patterns belong to the class of collective communication <ref> [30] </ref>, as defined by the MPI standard [32]. Currently the wormhole-routing switching technique [6, 33] is the trend in building scalable parallel systems supporting both distributed-memory and distributed-shared memory programming paradigms.
Reference: [31] <author> P. K. McKinley, H. Xu, A.-H. Esfahanian, and L. M. Ni. </author> <title> Unicast-based Multicast Communication in Wormhole-routed Networks. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 5(12) </volume> <pages> 1252-1265, </pages> <month> Dec </month> <year> 1994. </year>
Reference-contexts: With the increasing popularity of wormhole-routing switching technique many new adaptive routing schemes have been proposed in the literature 1 [7, 14, 20, 41, 45]. Similarly, many new multicasting schemes and mechanisms have also been proposed <ref> [4, 31, 39] </ref>. These developments lead to a natural question whether we can take advantage of these routing schemes and mechanisms to reduce cache coherence overheads in DSM systems.
Reference: [32] <author> Message Passing Interface Forum. </author> <title> MPI: A Message-Passing Interface Standard, </title> <month> Mar </month> <year> 1994. </year>
Reference-contexts: In the interconnection networks literature, the former communication pattern is known as multicast and the latter pattern as gather. Both patterns belong to the class of collective communication [30], as defined by the MPI standard <ref> [32] </ref>. Currently the wormhole-routing switching technique [6, 33] is the trend in building scalable parallel systems supporting both distributed-memory and distributed-shared memory programming paradigms. IBM SP1/SP2, Intel Paragon, Cray T3D, Ncube, J-Machine, Stanford DASH, Stanford FLASH, and Alewife are representative systems using this switching technique.
Reference: [33] <author> L. Ni and P. K. McKinley. </author> <title> A Survey of Wormhole Routing Techniques in Direct Networks. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 62-76, </pages> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: In the interconnection networks literature, the former communication pattern is known as multicast and the latter pattern as gather. Both patterns belong to the class of collective communication [30], as defined by the MPI standard [32]. Currently the wormhole-routing switching technique <ref> [6, 33] </ref> is the trend in building scalable parallel systems supporting both distributed-memory and distributed-shared memory programming paradigms. IBM SP1/SP2, Intel Paragon, Cray T3D, Ncube, J-Machine, Stanford DASH, Stanford FLASH, and Alewife are representative systems using this switching technique. <p> We will use these four performance measures to compare the schemes. 2.3.3 Estimating Invalidation Latency and Associated Communication Traffic Let us derive an estimate for latency of an invalidation transaction on a k fi k mesh using wormhole routing switching technique <ref> [33] </ref>, as commonly being used in current generation parallel systems. Assume the average number of nodes sharing a block is d. This will require 2d messages for invalidation request and acknowledgment.
Reference: [34] <author> H. Nilsson and P. Stenstrom. </author> <title> The Scalable Tree Protocol A Cache Coherence Approach for Large-Scale Multiprocessors. </title> <booktitle> In Symposium on Parallel and Distributed Processing, </booktitle> <pages> pages 498-506, </pages> <year> 1992. </year>
Reference-contexts: In recent years, most research related to DSM systems have emphasized on designing efficient directory structures, designing new cache coherence protocols, deriving optimal cache sizes, analyzing cache invalidation patterns, and reducing synchronization overheads <ref> [3, 16, 19, 22, 25, 34] </ref>. However, very little research is done towards reducing overheads of cache coherence protocols on message-passing systems by taking advantage of underlying interconnection networks and routing schemes. Directory-based cache coherence protocols can use either write-invalidation or write-update schemes.
Reference: [35] <author> B. Nitzberg and Virginia Lo. </author> <title> Distributed Shared Memory: A Survey of Issues and Algorithms. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 52-60, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: 1 Introduction The distributed shared memory (DSM) programming paradigm is gaining increasing popularity in the parallel computing community due to the simplicity in programming style that it offers <ref> [24, 35] </ref>. DSM systems provide a coherent single programming address space. In order to design scalable parallel systems with DSM paradigm, the current approach used by architects is to support directory-based cache-coherence protocols on top of message-passing hardware [8, 9, 12].
Reference: [36] <author> D. K. Panda. </author> <title> Global Reduction in Wormhole k-ary n-cube Networks with Multidestination Exchange Worms. </title> <booktitle> In International Parallel Processing Symposium, </booktitle> <year> 1994. </year> <note> accepted for presentation. </note>
Reference-contexts: This again can cause severe network throughput degradation or deadlocks when multiple simultaneous multidestination-based worms exist in the system. A virtual cut-through switching technique is proposed in <ref> [36] </ref> to alleviate such problems. This allows the waiting i-gather worms to get stored into the i-ack buffers. Hence, a message field needs to be added to the i-ack buffer entries in the router interface as shown in Fig. 7.
Reference: [37] <author> D. K. Panda. </author> <title> Fast Barrier Synchronization in Wormhole k-ary n-cube Networks with Multidestination Worms. </title> <journal> Future Generation Computer Systems, </journal> <volume> 11 </volume> <pages> 585-602, </pages> <month> Nov </month> <year> 1995. </year> <title> Special issue on High Performance Computer Architecture, </title> <booktitle> Collection of best eight papers from Int'l Symposium on High Performance Computer Architecture (Proceedings of the HPCA-1, </booktitle> <pages> pages 200-209, </pages> <year> 1995). </year> <month> 42 </month>
Reference-contexts: In this section we briefly provide an overview of this model and show the operational principles behind multidestination multicast and gather worms. Interested readers are encouraged to refer <ref> [37, 38, 39] </ref> for details. 3.1 The BRCP Model Let us assume a network supporting a deadlock-free routing scheme R for unicast message passing. This routing R could be e-cube [6], planar-adaptive [5], turn-model [15], fully-adaptive [7], or any other routing scheme. We identify R as the base-routing. <p> Instead of forwarding and absorbing a flit at the router of each intermediate destination, a gather worm gathers/collects information (supplied by the associated processor) at the router interface and proceeds ahead <ref> [37, 38] </ref>. Similar to the concept of registers in Cray T3D barrier network and buffers in CM5 control network, each router interface can have of a set of buffers. These buffers are accessed by the associated processor by memory-mapped I/O references. <p> Let us consider organizing presence bits (i.e., the fully-mapped pointer array) of a directory entry in a column fashion (along Y dimension). We use the bit string encoding of multidestination addresses <ref> [37, 38] </ref>. Thus, different portions of the presence bits can be directly taken as the routing headers of the i-reserve worms without any modification. The details will become clear in the following discussion when we introduce six different schemes of fast grouping.
Reference: [38] <author> D. K. Panda. </author> <title> Global Reduction in Wormhole k-ary n-cube Networks with Multidestination Exchange Worms. </title> <booktitle> In International Parallel Processing Symposium, </booktitle> <pages> pages 652-659, </pages> <month> Apr </month> <year> 1995. </year>
Reference-contexts: This has considerable impact on increasing the occupancy of messages at directories [12, 18]. Such overheads get translated into high-latency for write operations, leading to degradation on the overall system performance. Recently multidestination message-passing mechanisms have been introduced for wormhole networks to achieve low-latency multicast [28, 39] and gather <ref> [38] </ref> operations on distributed memory systems. This leads to a challenge whether such schemes can be applied to wormhole DSM systems. <p> In this section we briefly provide an overview of this model and show the operational principles behind multidestination multicast and gather worms. Interested readers are encouraged to refer <ref> [37, 38, 39] </ref> for details. 3.1 The BRCP Model Let us assume a network supporting a deadlock-free routing scheme R for unicast message passing. This routing R could be e-cube [6], planar-adaptive [5], turn-model [15], fully-adaptive [7], or any other routing scheme. We identify R as the base-routing. <p> Instead of forwarding and absorbing a flit at the router of each intermediate destination, a gather worm gathers/collects information (supplied by the associated processor) at the router interface and proceeds ahead <ref> [37, 38] </ref>. Similar to the concept of registers in Cray T3D barrier network and buffers in CM5 control network, each router interface can have of a set of buffers. These buffers are accessed by the associated processor by memory-mapped I/O references. <p> Let us consider organizing presence bits (i.e., the fully-mapped pointer array) of a directory entry in a column fashion (along Y dimension). We use the bit string encoding of multidestination addresses <ref> [37, 38] </ref>. Thus, different portions of the presence bits can be directly taken as the routing headers of the i-reserve worms without any modification. The details will become clear in the following discussion when we introduce six different schemes of fast grouping.
Reference: [39] <author> D. K. Panda, S. Singal, and P. Prabhakaran. </author> <title> Multidestination Message Passing Mechanism Conforming to Base Wormhole Routing Scheme. </title> <booktitle> In Proceedings of the Parallel Computer Routing and Communication Workshop, </booktitle> <pages> pages 131-145, </pages> <year> 1994. </year>
Reference-contexts: With the increasing popularity of wormhole-routing switching technique many new adaptive routing schemes have been proposed in the literature 1 [7, 14, 20, 41, 45]. Similarly, many new multicasting schemes and mechanisms have also been proposed <ref> [4, 31, 39] </ref>. These developments lead to a natural question whether we can take advantage of these routing schemes and mechanisms to reduce cache coherence overheads in DSM systems. <p> This has considerable impact on increasing the occupancy of messages at directories [12, 18]. Such overheads get translated into high-latency for write operations, leading to degradation on the overall system performance. Recently multidestination message-passing mechanisms have been introduced for wormhole networks to achieve low-latency multicast <ref> [28, 39] </ref> and gather [38] operations on distributed memory systems. This leads to a challenge whether such schemes can be applied to wormhole DSM systems. <p> In this paper we take on such challenges and propose a set of multidestination reservation and gather worms to implement cache-coherence with reduced overheads. Such worms use base-routing-conformed-paths <ref> [39] </ref> and can be applied to any wormhole routing scheme without adding any extra virtual channels. Depending on the underlying routing adaptivity we propose different grouping schemes to send cache-invalidation signals and collect acknowledgment signals using minimum number of messages. <p> Such a mechanism allows a multicast/broadcast message to be consumed at a destination node while being forwarded to the next node concurrently. However, the message propagation in this scheme is restricted to Hamiltonian-path routing. Recently a Base-Routing 8 Confirmed-Path (BRCP) model has been proposed in <ref> [39] </ref> to apply multidestination message passing to e-cube as well as other adaptive wormhole routing schemes. In this section we briefly provide an overview of this model and show the operational principles behind multidestination multicast and gather worms. <p> In this section we briefly provide an overview of this model and show the operational principles behind multidestination multicast and gather worms. Interested readers are encouraged to refer <ref> [37, 38, 39] </ref> for details. 3.1 The BRCP Model Let us assume a network supporting a deadlock-free routing scheme R for unicast message passing. This routing R could be e-cube [6], planar-adaptive [5], turn-model [15], fully-adaptive [7], or any other routing scheme. We identify R as the base-routing. <p> Such a worm uses forward-and-absorb capability at the router interface of each intermediate destination (except the last one), i.e., the flits are forwarded to an adjacent router as well as copied to the system buffer of the associated processor-router interface <ref> [39] </ref>. It is to be noted that such a worm is quite powerful and can deliver a message to multiple destinations much faster using less number of messages compared to unicast message passing. <p> This demonstrates considerable potential to reduce occupancy at the home node as well as the invalidation latency. (a) UI-UA and (b) MI-UA. Sharing nodes corresponding to column 6 of the example invalidation pattern in Fig. 4 are only considered. Besides supporting forward-and-absorb mechanism at each router interface <ref> [39] </ref>, the MI-UA framework does not require any additional modifications to the current generation DSM systems. The main thrust of this framework is to reduce occupancy of the home node and the volume of network traffic incurred in the request phase of an invalidation transaction. <p> Consider a regular multidestination-based worm in the network. As the worm propagates, it 17 must successfully reserve a consumption channel <ref> [39] </ref> before proceeding to the next destination at every router interface of intermediate destinations. It will get blocked if there is no consumption channel available. Such hold-and-wait property of multidestination-based worms can cause network deadlocks if each router interface does not have enough consumption channels. <p> It will get blocked if there is no consumption channel available. Such hold-and-wait property of multidestination-based worms can cause network deadlocks if each router interface does not have enough consumption channels. An upper bound on the number of consumption channels required at each router interface is proved in <ref> [39] </ref> to prevent deadlocks in a network using multidestination-based worms. For a 2D mesh, 4 consumption channels at each router interface are sufficient to guarantee deadlock-freedom.
Reference: [40] <author> D. K. Panda, S. Singal, and P. Prabhakaran. </author> <title> Multidestination Message Passing Mechanism Conforming to Base Wormhole Routing Scheme. </title> <type> Technical Report OSU-CISRC-6/94-TR33, </type> <institution> Dept. of Computer and Information Science, The Ohio State University, </institution> <year> 1994. </year>
Reference-contexts: However, in traditional unicast-based wormhole routing, a router interface makes the routing decision based on the information of a fixed portion, usually the first flit, of a worm. For a multidestination worm, as proposed in <ref> [27, 40] </ref>, the effective next destination is always at the beginning portion of the multidestination worm to conform to the above decision making convention. The header flits are stripped off one after another as the worm moves to the final destination.
Reference: [41] <author> G. D. Pifarre, L. Gravano, S. A. Felperin, and J. Sanz. </author> <title> Fully Adaptive Minimal Deadlock-Free Routing in Hypercubes, Meshes, and Other Networks: Algorithms and Simulations. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 5(3) </volume> <pages> 247-263, </pages> <year> 1994. </year>
Reference-contexts: IBM SP1/SP2, Intel Paragon, Cray T3D, Ncube, J-Machine, Stanford DASH, Stanford FLASH, and Alewife are representative systems using this switching technique. With the increasing popularity of wormhole-routing switching technique many new adaptive routing schemes have been proposed in the literature 1 <ref> [7, 14, 20, 41, 45] </ref>. Similarly, many new multicasting schemes and mechanisms have also been proposed [4, 31, 39]. These developments lead to a natural question whether we can take advantage of these routing schemes and mechanisms to reduce cache coherence overheads in DSM systems.
Reference: [42] <author> F. Pong and M. Dubois. </author> <title> Formal verification of complex coherence protocols using symbolic state models. </title> <type> Technical Report CENG-94-01, </type> <institution> Dept. of EE-Systems, University of Southern California, </institution> <address> Los Angeles, CA 90089-2562, </address> <month> January </month> <year> 1994. </year>
Reference-contexts: Most directory-based cache coherence protocols appeared in literatures assume some implicit order among different types of coherent messages between a home node and a sharing node. The objective is to make the implementation of the coherence protocol simple and efficient. In the past few years, several cache coherence protocols <ref> [23, 42] </ref> allowing out-of-order message delivery between a source-destination pair have been proposed.
Reference: [43] <author> H.D. Schwetman. </author> <title> CSIM Reference Manual (Revision 13). </title> <type> Technical report, </type> <institution> Microelectronics and Computer Technology Corporation, Austin, Texas, </institution> <month> January </month> <year> 1989. </year>
Reference-contexts: The entire simulation environment accurately models the intranodal and internodal communication, including memory access contention and network contention, occurring in a typical DSM system during an application execution. All simulations are designed using CSIM <ref> [43] </ref>. 6.1 System Characteristics 6.1.1 System Parameters For almost all simulation experiments, we assumed system parameters representing the current trend in technology in processor, memory, and the interconnection network. The following 31 parameters were used: 100 MHz processors, 200 Mbytes/sec communication link and 20.0 nanosec router delay.
Reference: [44] <author> Per Stenstrom. </author> <title> A survey of cache coherence schemes for multiprocessors. </title> <journal> IEEE Computer, </journal> <volume> 23(6) </volume> <pages> 12-24, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Such organization is similar to other DSM systems like DASH [10] (at cluster level), Alewife [8], FLASH [12], etc. 3 2.2 Directory-based Protocols A directory entry associated with a memory block consists of current state and a pointer array <ref> [44] </ref>. The state indicates whether the block is not cached (uncached), cached and shared by several nodes (shared), exclusively cached by a single node (exclusive), or transitory waiting (waiting). The pointer array identifies the nodes having valid cache copies of this block when the current state is shared or exclusive.
Reference: [45] <author> J. H. Upadhyay, V. Varavithya, and P. Mohapatra. </author> <title> Efficient and Balanced Adaptive Routing in Two-Dimensional Meshes. </title> <booktitle> In International Symposium on High Performance Computer Architecture, </booktitle> <pages> pages 112-121, </pages> <year> 1995. </year>
Reference-contexts: IBM SP1/SP2, Intel Paragon, Cray T3D, Ncube, J-Machine, Stanford DASH, Stanford FLASH, and Alewife are representative systems using this switching technique. With the increasing popularity of wormhole-routing switching technique many new adaptive routing schemes have been proposed in the literature 1 <ref> [7, 14, 20, 41, 45] </ref>. Similarly, many new multicasting schemes and mechanisms have also been proposed [4, 31, 39]. These developments lead to a natural question whether we can take advantage of these routing schemes and mechanisms to reduce cache coherence overheads in DSM systems.
Reference: [46] <author> S. C. Woo, M. Ohara, E. Torrie, J. P. Singh, and A. Gupta. </author> <title> The SPLASH-2 Programs: Chracterization and Methodological Considerations. </title> <booktitle> In International Symposium on Computer Architecture, </booktitle> <pages> pages 24-36, </pages> <year> 1995. </year>
Reference-contexts: They are listed in Table 6. The first application, Barnes-Hut, was ported to our simulator from Stanford SPLASH2 benchmark suite <ref> [46] </ref>. For all experiments we simulated 128 bodies for 4 time steps. We also ported the blocked LU decomposition kernel from Stanford SPLASH2 benchmark suite. We simulated 128 fi 128 ma trices with 8 fi 8 blocks. The third application we chose was All Pairs Shortest Path (APS).
Reference: [47] <author> P. C. Yew, N. F. Tzeng, and D. H. Lawrie. </author> <title> Distributed Hot-spot Addressing in Large-scale Multiprocessor. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 388-395, </pages> <month> Apr </month> <year> 1987. </year> <month> 43 </month>
Reference-contexts: Let us denote such a framework as Unicast-based Invalidation and Unicast-based Acknowledgment (UI-UA). Under this framework it can be observed that the invalidation will take considerable time due to sending and receiving a large number of messages. The hot-spot effect <ref> [47] </ref> occurs at the home node in both the request phase as well as the acknowledgment phase. In the request phase, the X-dimension links along the row containing the home node are congested. While in the acknowledging phase, the Y-dimension links along the column containing the home node are congested.
References-found: 47

