URL: http://tiny-tera.stanford.edu/~nickm/papers/Comparison.ps
Refering-URL: http://www.cs.washington.edu/homes/tom/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: A Quantitative Comparison of Iterative Scheduling Algorithms for Input-Queued Switches  
Author: Nick McKeown Thomas E. Anderson 
Abstract: In this paper we quantitatively evaluate three iterative algorithms for scheduling cells in a high-bandwidth input-queued ATM switch. In particular, we compare the performance of an algorithm described previously | parallel iterative matching (PIM) | with two new algorithms: iterative round-robin matching with slip (iSLIP) and iterative least-recently used (iLRU). We also compare each algorithm against FIFO input-queueing and perfect output-queueing. For the synthetic workloads we consider, including uniform and bursty traffic, iSLIP performs almost identically to the other algorithms. Cases for which PIM and iSLIP perform poorly are presented, indicating that care should be taken when using these algorithms. But, we show that the implementation complexity of iSLIP is an order of magnitude less than for PIM, making it feasible to implement a 32 fi 32 switch scheduler for iSLIP on a single chip.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Ali, M., Nguyen, H. </author> <title> "A neural network implementation of an input access scheme in a high-speed packet switch," </title> <booktitle> Proc. of GLOBECOM 1989, </booktitle> <address> pp.1192-1196. </address>
Reference-contexts: Our work is motivated by a different approach. HOL blocking can also be eliminated by maintaing at each input, a separate queue for each output <ref> [1, 2, 15, 27] </ref>, where any cell queued at an input is eligible for forwarding across the switch. This technique is sometimes called virtual output queueing. <p> algorithm must now consider the cells at the head of all N 2 input FIFOs and determine a pattern of conflict-free flows that will provide a high throughput. (The algorithm is an example of bipartite graph matching [28] and is also an example of the "rooks on a chessboard problem" <ref> [1] </ref>). Recently it has been shown that 100% throughput can be achieved in an input-queued switch if an algorithm considers the occupancy of each of the N 2 input queues [22]. However, as the authors point out, it is infeasible for this algorithm to perform quickly in hardware.
Reference: [2] <author> Anderson, T., Owicki, S., Saxe, J., and Thacker, C. </author> <title> "High speed switch scheduling for local area networks," </title> <journal> ACM Trans. on Computer Systems. </journal> <month> Nov </month> <year> 1993, </year> <pages> pp. 319-352. </pages>
Reference-contexts: One reason for the popularity of arbitrary topology networks is that they offer a number of potential advantages relative to other approaches <ref> [2] </ref>: (i) aggregate throughput that can be much larger than that of a single link, (ii) the ability to add throughput incrementally as the workload changes by simply adding extra links and switches, (iii) improved fault tolerance fl Nick McKeown was supported by Pacific Bell, Bellcore and California State MICRO Program <p> A large number of alternative switch designs have been proposed with varying approaches to these three functions <ref> [2, 7, 9, 13, 16, 25, 26] </ref>, each with their own set of advantages and disadvantages. The goal of this paper is to make a quantitative comparison of scheduling policies for input-queued switches, considering both hardware complexity and switch performance. <p> Our work is motivated by a different approach. HOL blocking can also be eliminated by maintaing at each input, a separate queue for each output <ref> [1, 2, 15, 27] </ref>, where any cell queued at an input is eligible for forwarding across the switch. This technique is sometimes called virtual output queueing. <p> The central problem with random-access input queues is the need for fast scheduling quickly finding a conflict-free set of cells to be forwarded across the switch, such that each input is connected to at most one output, and vice versa. As observed in <ref> [2] </ref>, this is equivalent to matching 1 inputs to outputs [28]. In this paper we evaluate fast, parallel, iterative algorithms for scheduling cells in an input-queued switch. In particular, we compare DEC's parallel iterative matching (PIM) algorithm with two novel algorithms that we have devised: iSLIP and iLRU. <p> If cells for one output are blocked because the output is busy, the scheduling algorithm may select a cell for some other output. This method was implemented in <ref> [2] </ref>, where they showed that the scheme is not only straightforward to build, but yields large performance gains. Note that despite the increased complexity at the input buffer, the memory bandwidth need not increase: each input still receives and transmits at most one cell per time slot. <p> Furthermore, by introducing randomness or time-varying priorities, we shall see that starvation can be avoided. 2.3 Parallel Iterative Matching (PIM) The first iterative algorithm that we shall describe is called parallel iterative matching <ref> [2] </ref>. It uses randomness to (i) reduce the number of iterations needed, and (ii) avoid starvation. PIM attempts to quickly converge on a conflict-free match in multiple iterations where each iteration consists of three steps. <p> By considering only unmatched inputs and outputs, each iteration only considers flows not made by earlier iterations. Note that in step (2) the independent output arbiters randomly select a request among contending requests. This has three effects: first, in <ref> [2] </ref>, the authors show that each iteration will match or eliminate at least 3=4 of the remaining possible flows and thus the algorithm will converge to a maximal match in O (log N ) iterations. Second, it ensures that all requests will eventually be granted. <p> However, this indicates that there is no backlog on this flow and can be ignored. 9 Input Choice Output Choice Random Rotating LRU Random PIM <ref> [2] </ref> Rotating iSLIP LRU iLRU Table 2: Alternative Selection methods for Input and Output arbiters. move, do not clash with each other in the next cell time. The heavier the load, the more flows are made and so the smaller the number of clashes in the next cell time. <p> For this reason, we compare the algorithms for a single iteration. In other applications, there may be time for more than one iteration, particularly if the scheduler can be integrated on a single chip. In <ref> [2] </ref>, the authors were able to achieve four iterations of the PIM algorithm within a single 53-byte ATM cell time (420ns) at link speeds of 1Gbits/sec. <p> When 11 the scheduler completes its matching decision, it informs each input which output, if any, it can send a cell to. A PIM scheduler is difficult to implement|random selection is an expensive operation, particularly for a variable number of input requests. In the implementation described in <ref> [2] </ref>, the scheduler filled approximately 1.5 Xilinx 3190 [31] devices for each port [29]. For a 16fi16 switch, this is approximately 64,000 complex gates. If we assume that each gate is approximately eight 2-input gate equivalents this totals 512,000 simple gates. <p> We chose four iterations as this was the number of iterations performed in a single slot in the implementation of PIM <ref> [2] </ref>. There is a large improvement for PIM, iSLIP and iLRU for multiple iterations and their performance is now almost indistinguishable. All three algorithms are now significantly better than FIFO due to the elimination of HOL blocking and all approach the performance to maximum size matching.
Reference: [3] <author> Anick, D., Mitra, D., Sondhi, </author> <title> M.M., "Stochastic theory of a data-handling system with multiple sources," </title> <journal> Bell System Technical Journal 61, </journal> <year> 1982, </year> <month> pp.1871-1894. </month>
Reference-contexts: Although this workload is poor for iSLIP with a single iteration, further iterations will efficiently find other flows. 5.3 Performance Under Bursty Traffic Real traffic is not only asymmetric; it is also bursty. Many ways of modeling bursts in network traffic have been described <ref> [10, 14, 3, 18] </ref>. Recently, Leland et al. have demonstrated that measured network traffic is bursty at every level and that, contrary to popular belief, burstiness in Ethernet networks typically intensifies as the number of active traffic sources increases [18].
Reference: [4] <author> ANSI. </author> <title> "Fiber distributed data interface (FDDI). Token ring media access control(MAC)," ANSI Standard X3.139, </title> <publisher> American National Standards Institute, Inc., </publisher> <address> New York. </address>
Reference-contexts: In these networks, hosts are connected together by an arbitrary graph of communication links and switches, instead of via a shared medium, as in Ethernet [24], or a ring, as in FDDI <ref> [4] </ref>.
Reference: [5] <author> The ATM Forum. </author> <title> "The ATM Forum user-network interface specification, version 3.0, </title> " <publisher> Prentice Hall Intl., </publisher> <address> New Jersey, </address> <year> 1993. </year> <month> 23 </month>
Reference-contexts: 1 Introduction The past few years has seen increasing interest in arbitrary topology cell-based local area networks, such as ATM <ref> [5] </ref>. In these networks, hosts are connected together by an arbitrary graph of communication links and switches, instead of via a shared medium, as in Ethernet [24], or a ring, as in FDDI [4].
Reference: [6] <author> Brayton, R.; Rudell, R.;Sangiovanni-Vincentelli, A.; and Wang, A. </author> <title> "MIS: A Multiple-Level Logic Optimization System", </title> <journal> IEEE Trans on CAD, </journal> <volume> CAD-6 (6), pp.1062-1081, </volume> <month> November </month> <year> 1987. </year>
Reference-contexts: Each arbiter is an N input priority encoder with a programmable priority level. A schematic of the complete scheduler is shown in Figure 4; the details of one arbiter is shown in Figure 5. Using the "misII" tools from the Berkeley Octtools VLSI design package <ref> [6] </ref>, we have determined that the scheduler for a 16 fi 16 switch will require approximately 35,000 2-input gate equivalents. This is an order of magnitude less complex than for PIM for the same sized switch.
Reference: [7] <author> Eng, K., Hluchyj, M., and Yeh, Y. </author> <title> "Multicast and broadcast services in a knockout packet switch," </title> <booktitle> INFOCOM '88, </booktitle> <address> 35(12) pp.29-34. </address>
Reference-contexts: A large number of alternative switch designs have been proposed with varying approaches to these three functions <ref> [2, 7, 9, 13, 16, 25, 26] </ref>, each with their own set of advantages and disadvantages. The goal of this paper is to make a quantitative comparison of scheduling policies for input-queued switches, considering both hardware complexity and switch performance.
Reference: [8] <author> Even, S., Tarjan, R.E. </author> <title> "Network flow and testing graph connectivity" SIAM J. </title> <institution> Comput., </institution> <month> 4 </month> <year> (1975), </year> <month> pp.507-518. </month>
Reference-contexts: This would provide the highest possible instantaneous throughput in a given time slot. There are several algorithms for achieving a maximum size match <ref> [8, 11, 17, 28] </ref>, but these are not suitable for this application for two reasons. First, a maximum size match can take a long time to converge and, second, it can lead to starvation of an input-output flow under certain traffic patterns.
Reference: [9] <author> Giacopelli, J., Hickey, J., Marcus, W., Sincoskie, D., Littlewood, M. "Sunshine: </author> <title> A high-performance self-routing broadband packet switch architecture," </title> <journal> IEEE J. Selected Areas Commun., </journal> <volume> 9, 8, </volume> <month> Oct </month> <year> 1991, </year> <month> pp.1289-1298. </month>
Reference-contexts: A large number of alternative switch designs have been proposed with varying approaches to these three functions <ref> [2, 7, 9, 13, 16, 25, 26] </ref>, each with their own set of advantages and disadvantages. The goal of this paper is to make a quantitative comparison of scheduling policies for input-queued switches, considering both hardware complexity and switch performance.
Reference: [10] <author> Heffes, H., Lucantoni, D. M., </author> <title> "A Markov modulated characterization of packetized voice and data traffic and related statistical multiplexer performance," </title> <journal> IEEE J. Selected Areas in Commun., </journal> <volume> 4, </volume> <year> 1986, </year> <month> pp.856-868. </month>
Reference-contexts: Although this workload is poor for iSLIP with a single iteration, further iterations will efficiently find other flows. 5.3 Performance Under Bursty Traffic Real traffic is not only asymmetric; it is also bursty. Many ways of modeling bursts in network traffic have been described <ref> [10, 14, 3, 18] </ref>. Recently, Leland et al. have demonstrated that measured network traffic is bursty at every level and that, contrary to popular belief, burstiness in Ethernet networks typically intensifies as the number of active traffic sources increases [18].
Reference: [11] <author> Hopcroft, J.E., Karp, </author> <title> R.M. "An O(n 5=2 ) algorithm for maximum matching in bipartite graphs," </title> <institution> Society for Industrial and Applied Mathematics J. Comput., </institution> <month> 2 </month> <year> (1973), </year> <month> pp.225-231. </month>
Reference-contexts: This would provide the highest possible instantaneous throughput in a given time slot. There are several algorithms for achieving a maximum size match <ref> [8, 11, 17, 28] </ref>, but these are not suitable for this application for two reasons. First, a maximum size match can take a long time to converge and, second, it can lead to starvation of an input-output flow under certain traffic patterns.
Reference: [12] <author> Huang, A., Knauer, S. "Starlite: </author> <title> A wideband digital switch," </title> <booktitle> Proc. GLOBECOM '84 (1984), </booktitle> <address> pp.121-125. </address>
Reference-contexts: With less benign traffic patterns, the situation can be much worse [19]. Several methods have been proposed for reducing HOL blocking <ref> [12, 15, 16, 25, 27] </ref>, but a simple way described in [15, 16] to eliminate HOL blocking is to maintain a separate FIFO queue at each input for each output. 1 This is illustrated in Figure 1.
Reference: [13] <author> Hui, J., Arthurs, E. </author> <title> "A broadband packet switch for integrated transport," </title> <journal> IEEE J. Selected Areas Commun., </journal> <volume> 5, 8, </volume> <month> Oct </month> <year> 1987, </year> <pages> pp 1264-1273. </pages>
Reference-contexts: A large number of alternative switch designs have been proposed with varying approaches to these three functions <ref> [2, 7, 9, 13, 16, 25, 26] </ref>, each with their own set of advantages and disadvantages. The goal of this paper is to make a quantitative comparison of scheduling policies for input-queued switches, considering both hardware complexity and switch performance.
Reference: [14] <author> Jain, R., Routhier, S. A., </author> <title> "Packet Trains: measurements and a new model for computer network traffic," </title> <journal> IEEE J. Selected Areas in Commun., </journal> <volume> 4, </volume> <year> 1986, </year> <month> pp.986-995. </month>
Reference-contexts: Although this workload is poor for iSLIP with a single iteration, further iterations will efficiently find other flows. 5.3 Performance Under Bursty Traffic Real traffic is not only asymmetric; it is also bursty. Many ways of modeling bursts in network traffic have been described <ref> [10, 14, 3, 18] </ref>. Recently, Leland et al. have demonstrated that measured network traffic is bursty at every level and that, contrary to popular belief, burstiness in Ethernet networks typically intensifies as the number of active traffic sources increases [18]. <p> We illustrate the effect of burstiness on PIM, iSLIP and iLRU using a simple packet train model similar to the one introduced in <ref> [14] </ref>. The source alternately produces a burst (train) of full cells (all with the same destination) followed by one or more empty cells. The bursts contain a geometrically distributed number of cells.
Reference: [15] <author> Karol, M., Hluchyj, M., and Morgan, S. </author> <title> "Input versus output queueing on a space division switch," </title> <journal> IEEE Trans. Comm, </journal> <note> 35(12) (1987) pp.1347-1356. </note>
Reference-contexts: As a result, FIFO input queues suffer from head of line (HOL) blocking <ref> [15] </ref> if the cell at the front of the queue is blocked, other cells in the queue cannot be forwarded to other unused inputs. HOL blocking can limit the throughput to just 58%. <p> Our work is motivated by a different approach. HOL blocking can also be eliminated by maintaing at each input, a separate queue for each output <ref> [1, 2, 15, 27] </ref>, where any cell queued at an input is eligible for forwarding across the switch. This technique is sometimes called virtual output queueing. <p> This choice between random and time-varying priorities is found in all of the approaches we consider. Before considering other scheduling approaches, we need to examine a serious performance problem caused by maintaining FIFO queues at the inputs: head of line (HOL) blocking <ref> [15] </ref>. <p> HOL blocking has been shown to limit the aggregate throughput of the switch to just 2 q of its maximum for independent Bernoulli arrivals and destinations uniformly distributed over outputs <ref> [15] </ref>. With less benign traffic patterns, the situation can be much worse [19]. <p> With less benign traffic patterns, the situation can be much worse [19]. Several methods have been proposed for reducing HOL blocking <ref> [12, 15, 16, 25, 27] </ref>, but a simple way described in [15, 16] to eliminate HOL blocking is to maintain a separate FIFO queue at each input for each output. 1 This is illustrated in Figure 1. <p> With less benign traffic patterns, the situation can be much worse [19]. Several methods have been proposed for reducing HOL blocking [12, 15, 16, 25, 27], but a simple way described in <ref> [15, 16] </ref> to eliminate HOL blocking is to maintain a separate FIFO queue at each input for each output. 1 This is illustrated in Figure 1. If cells for one output are blocked because the output is busy, the scheduling algorithm may select a cell for some other output.
Reference: [16] <author> Karol, M., Eng, K., Obara, H. </author> <title> "Improving the performance of input-queued ATM packet switches," </title> <type> INFOCOM '92, </type> <institution> pp.110-115. </institution>
Reference-contexts: A large number of alternative switch designs have been proposed with varying approaches to these three functions <ref> [2, 7, 9, 13, 16, 25, 26] </ref>, each with their own set of advantages and disadvantages. The goal of this paper is to make a quantitative comparison of scheduling policies for input-queued switches, considering both hardware complexity and switch performance. <p> With less benign traffic patterns, the situation can be much worse [19]. Several methods have been proposed for reducing HOL blocking <ref> [12, 15, 16, 25, 27] </ref>, but a simple way described in [15, 16] to eliminate HOL blocking is to maintain a separate FIFO queue at each input for each output. 1 This is illustrated in Figure 1. <p> With less benign traffic patterns, the situation can be much worse [19]. Several methods have been proposed for reducing HOL blocking [12, 15, 16, 25, 27], but a simple way described in <ref> [15, 16] </ref> to eliminate HOL blocking is to maintain a separate FIFO queue at each input for each output. 1 This is illustrated in Figure 1. If cells for one output are blocked because the output is busy, the scheduling algorithm may select a cell for some other output.
Reference: [17] <author> Karp, R., Vazirani, U., and Vazirani, V. </author> <title> "An optimal algorithm for on-line bipartite matching," </title> <booktitle> Proc. 22nd ACM Symp. on Theory of Computing, </booktitle> <address> pp.352-358, Maryland, </address> <year> 1990. </year>
Reference-contexts: This would provide the highest possible instantaneous throughput in a given time slot. There are several algorithms for achieving a maximum size match <ref> [8, 11, 17, 28] </ref>, but these are not suitable for this application for two reasons. First, a maximum size match can take a long time to converge and, second, it can lead to starvation of an input-output flow under certain traffic patterns.
Reference: [18] <author> Leland, W.E., Willinger, W., Taqqu, M., Wilson, D., </author> <title> "On the self-similar nature of Ethernet traffic" Proc. </title> <booktitle> of Sigcomm, </booktitle> <address> San Francisco, </address> <year> 1993, </year> <month> pp.183-193. </month>
Reference-contexts: Second, the algorithm should provide high throughput and avoid starvation for any flow pattern. This is because real network traffic is rarely uniformly distributed over inputs and outputs. Fourth, the algorithm should provide high throughput for bursty traffic. Real network traffic is highly correlated from cell to cell <ref> [18] </ref> and the scheduling algorithm should not be unduly affected by the burstiness. However, we can expect all algorithms to perform worse under more bursty traffic. <p> Although this workload is poor for iSLIP with a single iteration, further iterations will efficiently find other flows. 5.3 Performance Under Bursty Traffic Real traffic is not only asymmetric; it is also bursty. Many ways of modeling bursts in network traffic have been described <ref> [10, 14, 3, 18] </ref>. Recently, Leland et al. have demonstrated that measured network traffic is bursty at every level and that, contrary to popular belief, burstiness in Ethernet networks typically intensifies as the number of active traffic sources increases [18]. <p> Recently, Leland et al. have demonstrated that measured network traffic is bursty at every level and that, contrary to popular belief, burstiness in Ethernet networks typically intensifies as the number of active traffic sources increases <ref> [18] </ref>. So it is very important to understand the performance of switches in the presence of bursty traffic, whether it is a small private switch with a small number of active users, or a large public switch with many thousands of aggregated flows.
Reference: [19] <author> Li, S.-Y., </author> <title> "Theory of periodic contention and its application to packet switching" Proc. </title> <booktitle> of INFOCOM 1988, </booktitle> <address> pp.320-325. </address>
Reference-contexts: HOL blocking can limit the throughput to just 58%. Because HOL blocking has very poor performance in the worst case <ref> [19] </ref>, the standard approach has been to abandon input queueing and instead use output queueing by increasing the bandwidth of the internal interconnect, multiple cells can be forwarded at the same time to the same output, and queued there for transmission on the output link. <p> HOL blocking has been shown to limit the aggregate throughput of the switch to just 2 q of its maximum for independent Bernoulli arrivals and destinations uniformly distributed over outputs [15]. With less benign traffic patterns, the situation can be much worse <ref> [19] </ref>. Several methods have been proposed for reducing HOL blocking [12, 15, 16, 25, 27], but a simple way described in [15, 16] to eliminate HOL blocking is to maintain a separate FIFO queue at each input for each output. 1 This is illustrated in Figure 1.
Reference: [20] <author> McKeown, N., Varaiya, P., Walrand, J., </author> <title> "Scheduling Cells in an Input-Queued Switch," </title> <journal> Electronics Letters, </journal> <volume> Vol. </volume> <pages> 29, </pages> <address> No.25 pp.2174-2175, </address> <month> 9 Dec. </month> <year> 1993. </year>
Reference: [21] <author> McKeown, N., </author> <title> "Scheduling Cells for Input-Queued Cell Switches," </title> <type> PhD Thesis, </type> <institution> University of California at Berkeley, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: Instead they use a varying priority based on state information that is maintained from one time slot to the next. 2.4 Iterative Round Robin Matching with Slip (iSLIP) iSLIP, like PIM, is an iterative algorithm and was first described in <ref> [21] </ref>. The following three steps are iterated for an N fi N switch: 1. Each unmatched input sends a request to every output for which it has a queued cell. 2. <p> When a successful matched output arbiter moves its pointer to one position beyond the input that it is connected to, it must be the only output that moves its pointer to that position. 2 In other words, the set of output pointers that 1 Refer to <ref> [21] </ref> for a more detailed description. 2 The output arbiter may of course clash with another output arbiter that already points to the same input, but was not matched in the previous cell time.
Reference: [22] <author> McKeown, N., Anantharam, V., Walrand, J., </author> <title> "Achieving 100% Throughput in an Input-Queued Switch," </title> <note> Proc. INFOCOM '96, To appear. 24 </note>
Reference-contexts: Recently it has been shown that 100% throughput can be achieved in an input-queued switch if an algorithm considers the occupancy of each of the N 2 input queues <ref> [22] </ref>. However, as the authors point out, it is infeasible for this algorithm to perform quickly in hardware. The algorithms that 1 Throughout this paper we will refer to the stream of cells flowing between an input and output as a "flow".
Reference: [23] <author> McKeown, N., Izzard, M., Mekkittikul, A., Ellersick, W., and Horowitz, M.; </author> <title> "The Tiny Tera: A Small High-Bandwidth Packet Switch Core," </title> <journal> IEEE Micro Magaine, </journal> <volume> Vol. 17, No. 1, </volume> <pages> pp. 26 - 33, </pages> <month> January-February </month> <year> 1997. </year>
Reference-contexts: We are currently completing the implementation of a 32 fi 32 iSLIP scheduler as part of the Tiny Tera project at Stanford <ref> [23] </ref>. Although we did not design a full implementation for iLRU, it is much more complex than iSLIP. Like iSLIP, the implementation requires 2N identical arbiters. Each arbiter must keep an ordered list indicating how recently an input or output was selected.
Reference: [24] <author> Metcalfe, R., Boggs, D. </author> <title> "Ethernet: Distributed packet switching for local computer networks," </title> <journal> Communic. ACM, </journal> <volume> 19, 7, </volume> <month> July </month> <year> 1976, </year> <month> pp.395-404. </month>
Reference-contexts: 1 Introduction The past few years has seen increasing interest in arbitrary topology cell-based local area networks, such as ATM [5]. In these networks, hosts are connected together by an arbitrary graph of communication links and switches, instead of via a shared medium, as in Ethernet <ref> [24] </ref>, or a ring, as in FDDI [4].
Reference: [25] <author> Obara, H. </author> <title> "Optimum architecture for input queueing ATM switches," Elect. Letters, 28th March 1991, </title> <publisher> pp.555-557. </publisher>
Reference-contexts: A large number of alternative switch designs have been proposed with varying approaches to these three functions <ref> [2, 7, 9, 13, 16, 25, 26] </ref>, each with their own set of advantages and disadvantages. The goal of this paper is to make a quantitative comparison of scheduling policies for input-queued switches, considering both hardware complexity and switch performance. <p> With less benign traffic patterns, the situation can be much worse [19]. Several methods have been proposed for reducing HOL blocking <ref> [12, 15, 16, 25, 27] </ref>, but a simple way described in [15, 16] to eliminate HOL blocking is to maintain a separate FIFO queue at each input for each output. 1 This is illustrated in Figure 1.
Reference: [26] <author> Obara, H., Okamoto, S., and Hamazumi, Y. </author> <title> "Input and output queueing ATM switch architecture with spatial and temporal slot reservation control" Elect. Letters, </title> <booktitle> 2nd Jan 1992, </booktitle> <address> pp.22-24. </address>
Reference-contexts: A large number of alternative switch designs have been proposed with varying approaches to these three functions <ref> [2, 7, 9, 13, 16, 25, 26] </ref>, each with their own set of advantages and disadvantages. The goal of this paper is to make a quantitative comparison of scheduling policies for input-queued switches, considering both hardware complexity and switch performance.
Reference: [27] <author> Tamir, Y., Frazier, G. </author> <title> "High performance multi-queue buffers for VLSI communication switches," </title> <booktitle> Proc. of 15th Ann. Symp. on Comp. Arch., </booktitle> <month> June </month> <year> 1988, </year> <month> pp.343-354. </month>
Reference-contexts: Our work is motivated by a different approach. HOL blocking can also be eliminated by maintaing at each input, a separate queue for each output <ref> [1, 2, 15, 27] </ref>, where any cell queued at an input is eligible for forwarding across the switch. This technique is sometimes called virtual output queueing. <p> With less benign traffic patterns, the situation can be much worse [19]. Several methods have been proposed for reducing HOL blocking <ref> [12, 15, 16, 25, 27] </ref>, but a simple way described in [15, 16] to eliminate HOL blocking is to maintain a separate FIFO queue at each input for each output. 1 This is illustrated in Figure 1.
Reference: [28] <author> Tarjan, R.E. </author> <title> "Data structures and network algorithms," </title> <institution> Society for Industrial and Applied Mathematics, Pennsylvania, </institution> <month> Nov </month> <year> 1983. </year>
Reference-contexts: As observed in [2], this is equivalent to matching 1 inputs to outputs <ref> [28] </ref>. In this paper we evaluate fast, parallel, iterative algorithms for scheduling cells in an input-queued switch. In particular, we compare DEC's parallel iterative matching (PIM) algorithm with two novel algorithms that we have devised: iSLIP and iLRU. <p> buffering to eliminate HOL blocking, we must change the flow scheduling algorithm: the algorithm must now consider the cells at the head of all N 2 input FIFOs and determine a pattern of conflict-free flows that will provide a high throughput. (The algorithm is an example of bipartite graph matching <ref> [28] </ref> and is also an example of the "rooks on a chessboard problem" [1]). Recently it has been shown that 100% throughput can be achieved in an input-queued switch if an algorithm considers the occupancy of each of the N 2 input queues [22]. <p> This would provide the highest possible instantaneous throughput in a given time slot. There are several algorithms for achieving a maximum size match <ref> [8, 11, 17, 28] </ref>, but these are not suitable for this application for two reasons. First, a maximum size match can take a long time to converge and, second, it can lead to starvation of an input-output flow under certain traffic patterns.
Reference: [29] <author> Thacker, C., </author> <title> Private communication. </title>
Reference-contexts: A PIM scheduler is difficult to implement|random selection is an expensive operation, particularly for a variable number of input requests. In the implementation described in [2], the scheduler filled approximately 1.5 Xilinx 3190 [31] devices for each port <ref> [29] </ref>. For a 16fi16 switch, this is approximately 64,000 complex gates. If we assume that each gate is approximately eight 2-input gate equivalents this totals 512,000 simple gates.
Reference: [30] <author> Wolff, R.W. </author> <title> "Stochastic modeling and the theory of queues," </title> <publisher> Prentice Hall Intl., </publisher> <address> New Jersey, </address> <year> 1989. </year>
Reference: [31] <author> Xilinx, Inc. "Xilinx: </author> <title> The programmable gate array data book" Xilinx, </title> <publisher> Inc., </publisher> <year> 1991. </year> <month> 25 </month>
Reference-contexts: A PIM scheduler is difficult to implement|random selection is an expensive operation, particularly for a variable number of input requests. In the implementation described in [2], the scheduler filled approximately 1.5 Xilinx 3190 <ref> [31] </ref> devices for each port [29]. For a 16fi16 switch, this is approximately 64,000 complex gates. If we assume that each gate is approximately eight 2-input gate equivalents this totals 512,000 simple gates.
References-found: 31

