URL: http://www.cs.yale.edu/pub/TR/tr1099.ps.gz
Refering-URL: http://www.cs.yale.edu/pub/TR/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Reversal of Markov Chains and the Forget Time  
Author: Laszlo Lovasz and Peter Winkler 
Date: (March 1996)  
Affiliation: Department of Computer Science Yale University  
Pubnum: Technical Report No. 1099  
Abstract: We study three quantities that can each be viewed as the time needed for a finite irreducible Markov chain to "forget" where it started. One of these is the mixing time, the minimum mean length of a stopping rule that yields the stationary distribution from the worst starting state. A second is the forget time, the minimum mean length of any stopping rule that yields the same distribution from any starting state. The third is the reset time, the minimum expected time between independent samples from the stationary distribution. Our main results state that the mixing time of a chain is equal to the mixing time of the time-reversed chain, while the forget time of a chain is equal to the reset time of the reverse chain. In particular, the forget time and the reset time of a time-reversible chain are equal. Moreover, the mixing time lies between absolute constant multiples of the sum of the forget time and the reset time. We also derive an explicit formula for the forget time, in terms of the "access times" introduced in [11]. This enables us to relate the forget and reset times to other mixing measures of the chain.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D.J. Aldous and J.A. Fill, </author> <title> Reversible Markov Chains and Random Walks on Graphs (book in preparation) </title>
Reference-contexts: We are going to show by an example that minfT forget ; T reset g=T mix can be arbitrarily close to 0. These facts relate our results to studies important for the analysis of certain randomized algorithms for sampling. Aldous [3], <ref> [1] </ref> proved the surprising and powerful result that for time-reversible chains, essentially all reasonable "mixing parameters" are within absolute constant factors of each other. These parameters include, besides T mix , the times T tv and T fill . <p> We denote by its stationary distribution. Let k denote the distribution of w k ; we often denote the starting distribution 0 by . A stopping rule is a map from V fl (the set of finite strings of states) to <ref> [0; 1] </ref>: for w = w 0 w 1 : : : w t , the value of (w) is the probability of continuing given that w is the walk so far observed. (Each such stop-or-go decision is made independently.) It is useful sometimes to regard a stopping rule as a <p> i j Using the notion of access times, we can write this definition as T hit = j (This is only formally similar to the definition of T reset ; in general, T hit is much larger.) The very useful "Random Target Lemma" (called the "right averaging principle" by Aldous <ref> [1] </ref>) asserts that T hit does not depend on the distribution of the starting point: for every state i, j 9 4 Reverse chains Given a Markov chain with transition probabilities p ij , we define the reverse chain as the Markov chain on the same set of states, with transition
Reference: [2] <author> D.J. Aldous, </author> <title> Some inequalities for reversible Markov chains, </title> <journal> J. London Math. Soc. </journal> <volume> 25 (1982), </volume> <pages> 564-576. </pages>
Reference: [3] <author> D.J. Aldous, </author> <title> Applications of random walks on graphs, </title> <note> preprint (1989). </note>
Reference-contexts: We are going to show by an example that minfT forget ; T reset g=T mix can be arbitrarily close to 0. These facts relate our results to studies important for the analysis of certain randomized algorithms for sampling. Aldous <ref> [3] </ref>, [1] proved the surprising and powerful result that for time-reversible chains, essentially all reasonable "mixing parameters" are within absolute constant factors of each other. These parameters include, besides T mix , the times T tv and T fill .
Reference: [4] <author> D.J. Aldous and P. Diaconis, </author> <title> Shu*ing cards and stopping times, </title> <journal> Amer. Math. </journal> <volume> Monthly 93 No. 5 (1986), </volume> <pages> 333-348. </pages>
Reference: [5] <author> D.J. Aldous, L. Lovasz and P. Winkler, </author> <title> Mixing times for uniformly ergodic Markov chains, </title> <type> preprint. </type>
Reference-contexts: It is clear that T forget T mix ; and T reset T mix : The following inequality is noted in <ref> [5] </ref>: T mix 2 (T reset + T forget ) : (1) Thus it follows that maxfT forget ; T reset g is between T mix and T mix =4. <p> The case of non-reversible chains is only a little more complicated. It is shown in <ref> [5] </ref> that most "mixing parameters" of a Markov chain fall into one of two groups, and parameters in the same group differ only by a constant factor. One group contains the time T tv (along with other mixing parameters, like the set-hitting time T set defined below in Section 3). <p> The forget time, which may also be considered as a mixing parameter, fits this pattern. In the time-reversible case, T forget = T reset is between T mix and T mix =4, by inequality (1). It is proved in <ref> [5] </ref> that in the general case, T forget is within a constant factor of T tv . On the other hand, the reset time, which seems to be conceptually closer to the mixing time, belongs to a new group.
Reference: [6] <author> D. Bayer and P. Diaconis, </author> <title> Trailing the dovetail shu*e to its liar, </title> <journal> Ann. Appl. Prob. </journal> <volume> 2 (1992), </volume> <pages> 294-313. </pages>
Reference-contexts: time for this rule is about 11 3 4 unshu*es, so by Theorem 2 we have for the 6 original ri*e shu*e chain that: T mix = ^ T mix 11 4 It is interesting to compare this figure with the famous 7 ri*e shu*es recommended by Bayer and Diaconis <ref> [6] </ref>. Their need for a fixed-time stopping rule seems to be much more than compensated by sufficiency of approximate mixing.
Reference: [7] <author> D. Coppersmith, P. Tetali, and P. Winkler, </author> <title> Collisions among random walks on a graph, </title> <note> SIAM J. on Discrete Mathematics 6 No. </note> <month> 3 </month> <year> (1993), </year> <pages> 363-374. </pages>
Reference-contexts: Remark. Several results about reversible Markov chains can be extended by using the notion of reverse chain. For example, the "cycle reversing" identity of <ref> [7] </ref> can be generalized (with a virtually identical proof) as H (i; j) + H (j; k) + H (k; i) = ^ H (i; k) + ^ H (k; j) + ^ H (j; i) for any three states i, j and k. (From here we could get another way
Reference: [8] <author> P. Doyle, </author> <title> seminar at Center for Elementary Studies, </title> <address> Pinecrest Lodge, Sonora CA (1995). </address>
Reference-contexts: Their need for a fixed-time stopping rule seems to be much more than compensated by sufficiency of approximate mixing. In fact Doyle <ref> [8] </ref> has devised a game which he calls "New Age Solitaire" which has a winning probability of 50% for a random deck but about 80% for a 7-times-ri*e-shu*ed fresh deck of Bicycle cards. Fortunately Doyle's game is not one which is likely to replace standard forms of solitaire.
Reference: [9] <author> P.G. Doyle and J.L. Snell, </author> <title> Random Walks and Electric Networks, </title> <publisher> Mathematical Assoc. of America, </publisher> <address> Washington, DC 1984. </address>
Reference: [10] <author> E. Gilbert, </author> <note> Theory of shu*ing, Bell Laboratories Technical Memorandum (1955). </note>
Reference: [11] <author> L. Lovasz and P. Winkler, </author> <title> Efficient stopping Rules for Markov Chains, </title> <booktitle> Proceedings of the 1995 ACM Symposium on the Theory of Computing, </booktitle> <pages> 76-82. </pages>
Reference-contexts: In Section 3, we recall from <ref> [11, 12] </ref> a calculus of "access times between distributions" and properties of optimal stopping rules. Section 4 contains some elementary facts about reversed Markov chains. Section 5 collects some known and (perhaps) not-quite-known relations between hitting times and the transition matrix.
Reference: [12] <author> L. Lovasz and P. Winkler, </author> <title> Mixing of random walks and other diffusions on a graph, </title> <booktitle> Proc. 15th British Combinatorial Conference, Sterling, </booktitle> <year> 1995, </year> <note> to appear. </note>
Reference-contexts: In Section 3, we recall from <ref> [11, 12] </ref> a calculus of "access times between distributions" and properties of optimal stopping rules. Section 4 contains some elementary facts about reversed Markov chains. Section 5 collects some known and (perhaps) not-quite-known relations between hitting times and the transition matrix.
Reference: [13] <author> J.W. </author> <title> Pitman, Occupation measures for Markov chains, </title> <journal> Adv. Appl. Prob. </journal> <volume> 9 (1977), </volume> <pages> 69-86. </pages>
Reference-contexts: Exit frequencies are related to the starting and ending distributions by a simple formula, found in Pitman <ref> [13] </ref>: X p i;j x i x j = t j j : (4) This equation implies that the exit frequencies are almost determined by and t in the sense that the exit frequencies of two rules from the same starting distribution to the the same target distribution t differ by
Reference: [14] <author> J. Reeds, </author> <note> unpublished manuscript (1981). 19 </note>
Reference-contexts: It will turn out that this rule is nearly optimal. Example 3 A classic example of mixing occurs in shu*ing a deck of playing cards. Here the states of the chain are the 52! permutations of the deck; in the Gilbert-Shannon-Reeds model ([10], <ref> [14] </ref>) of the ri*e (or "dovetail") shu*e the reverse of a shu*e is described elegantly as follows. Each card is randomly, uniformly and independently assigned a bit from f0; 1g.
References-found: 14

