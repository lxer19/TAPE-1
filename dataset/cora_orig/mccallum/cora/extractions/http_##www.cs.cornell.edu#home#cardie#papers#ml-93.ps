URL: http://www.cs.cornell.edu/home/cardie/papers/ml-93.ps
Refering-URL: http://www.cs.cornell.edu/home/cardie/
Root-URL: 
Email: E-mail: cardie@cs.umass.edu  
Title: Using Decision Trees to Improve Case-Based Learning  
Author: Claire Cardie 
Date: 25-32.  
Note: Proceedings of the Tenth International Conference on Machine Learning, 1993, Morgan Kaufmann, pages  
Address: Amherst, MA 01003  
Affiliation: Department of Computer Science University of Massachusetts  
Abstract: This paper shows that decision trees can be used to improve the performance of case-based learning (CBL) systems. We introduce a performance task for machine learning systems called semi-flexible prediction that lies between the classification task performed by decision tree algorithms and the flexible prediction task performed by conceptual clustering systems. In semi-flexible prediction, learning should improve prediction of a specific set of features known a priori rather than a single known feature (as in classification) or an arbitrary set of features (as in conceptual clustering). We describe one such task from natural language processing and present experiments that compare solutions to the problem using decision trees, CBL, and a hybrid approach that combines the two. In the hybrid approach, decision trees are used to specify the features to be included in k-nearest neighbor case retrieval. Results from the experiments show that the hybrid approach outperforms both the decision tree and case-based approaches as well as two case-based systems that incorporate expert knowledge into their case retrieval algorithms. Results clearly indicate that decision trees can be used to improve the performance of CBL systems and do so without reliance on potentially expensive expert knowledge.
Abstract-found: 1
Intro-found: 1
Reference: <author> Aha, D., Kibler, D., & Albert, M. </author> <year> (1991). </year> <title> Instance-Based Learning Algorithms. </title> <booktitle> Machine Learning 6 (1): </booktitle> <pages> pp. 37-66. </pages>
Reference-contexts: The speed of the algorithm degrades linearly with the size of the case base and modifications would be required before the approach could be tested using a hierarchical case base. Methods described in <ref> (Aha, Kibler, & Albert 1991) </ref> to reduce the storage requirements of T algorithms provide an alternative to construction of a hierarchical case base, however.
Reference: <author> Aha, D. </author> <year> (1989). </year> <title> Incremental, Instance-Based Learning of Independent and Graded Concept Descriptions. </title> <booktitle> Proceedings, Sixth International Workshop on Machine Learning, </booktitle> <pages> pp. 387-391. </pages> <institution> Cornell University, </institution> <address> Ithaca, NY. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In the hybrid approach, decision trees specify the features to be included in k-nearest neighbor case retrieval. In related work, <ref> (Aha 1989) </ref> presents a method for learning concept-dependent attribute relevancies in a case-based paradigm. He dynamically updates the similarity function for each concept by modifying an attribute weight vector associated with the concept in response to classification performance.
Reference: <author> Almuallim, H., & Dietterich, T. G. </author> <year> (1991). </year> <title> Learning With Many Irrelevant Features. </title> <booktitle> Proceedings, Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 547-552. </pages> <address> Anaheim, CA. </address> <publisher> AAAI Press / The MIT Press. </publisher>
Reference-contexts: On one hand, these results may not seem surprising since previous research has found the converse to be true | (Skalak & Rissland 1990) show that a case-based reasoning system can successfully perform the feature specification task for a decision tree classification system. However, <ref> (Almuallim & T 1991) </ref> show that ID3 (Quinlan 1986) is not particularly good at selecting a minimum set of features from an original set containing possibly many irrelevant attributes.
Reference: <author> Berwick, R. </author> <year> (1983). </year> <title> Learning word meanings from examples. </title> <booktitle> Proceedings, Eighth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 459-461. </pages> <address> Karls-ruhe, Germany. </address>
Reference: <author> Brent, M. </author> <year> (1991). </year> <title> Automatic acquisition of subcat-egorization frames from untagged text. </title> <booktitle> Proceedings, 29th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pp. 209-214. </pages> <institution> University of Califor-nia, Berkeley. Association for Computational Linguistics. </institution>
Reference: <author> Brent, M. </author> <year> (1990). </year> <title> Semantic classification of verbs from their syntactic contexts: automated lexicography with implications for child language acquisition. </title> <booktitle> Proceedings, Twelfth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. 428-437. </pages> <address> Cambridge MA. </address> <publisher> The Cognitive Science Society. </publisher>
Reference: <author> Cardie, C. </author> <year> (1993). </year> <title> A Case-Based Approach to Knowledge Acquisition for Domain-Specific Sentence Analysis. </title> <booktitle> To appear in Proceedings, Eleventh National Conference on Artificial Intelligence. </booktitle> <address> Washington, DC. </address>
Reference-contexts: A more detailed description of the instance representation, the taxonomies, and the semi-automated method used to generate the training instances is described in <ref> (Cardie 1993) </ref>. 5 Every training instance in the experiments below is based on the the 38-attribute feature set described here. In all test instances, however, we omit the po-s, gen-att, and spec-att word definition features we are trying to predict. <p> As a result, there are minor differences in the instance representations described in each paper. Verbs, for example, take on semantic features in the representation used here, but do not in <ref> (Cardie 1993) </ref>. 3 COMPARING THE DECISION TREE, CBL, AND HYBRID APPROACHES In each of the following experiments, we draw the training and test instances from a base set of 2056 38-attribute instances, one for each occurrence of an open class word in 120 sentences of the TIPSTER JV corpus. <p> * the same learning algorithm and instance representation are used to simultaneously learn both syntactic and semantic lexical knowledge * the approach does not rely on hand-coded heuristics, and * relatively little training is needed. 12 12 For a more detailed description of this work from an NLP perspective, see <ref> (Cardie, 1993) </ref>. In that paper, we Table 4: Results for Hybrid Approach (% correct). (^ indicates results not significantly different than the hybrid system.
Reference: <author> Church, K., & Hanks, P. </author> <year> (1990). </year> <title> Word association norms, mutual information, and lexicography. </title> <journal> Computational Linguistics, </journal> <volume> 16. </volume>
Reference: <author> Fisher, D. </author> <year> (1989). </year> <title> Noise-Tolerant Conceptual Clustering. </title> <booktitle> Proceedings, Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 630-635. </pages> <address> Detroit MI. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Fisher, D. H. </author> <year> (1987). </year> <title> Knowledge Acquisition Via Incremental Conceptual Clustering. </title> <booktitle> Machine Learning 2: </booktitle> <pages> 139-172. </pages>
Reference: <author> Granger, R. </author> <year> (1977). </year> <title> Foulup: A program that figures out meanings of words from context. </title> <booktitle> Proceedings, Fifth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 172-178. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Grefenstette, G. </author> <year> (1992). </year> <title> SEXTANT: Exploring unexplored contexts for semantic extraction from syntactic analysis. </title> <booktitle> Proceedings, 30th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pp. 324-326. </pages> <institution> University of Delaware, Newark, DE. Association for Computational Linguistics. </institution>
Reference: <author> Hastings, P., Lytinen, S., & Lindsay, R. </author> <year> (1991). </year> <title> Learning Words from Context. </title> <booktitle> Proceedings, Eighth International Conference on Machine Learning, </booktitle> <pages> pp. 55-59. </pages> <institution> Northwestern University, </institution> <address> Chicago, IL. </address> <publisher> Morgan Kauf-mann. </publisher>
Reference: <author> Hindle, D. </author> <year> (1990). </year> <title> Noun classification from predicate-argument structures. </title> <booktitle> Proceedings, 28th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pp. 268-275. </pages> <institution> University of Pittsburgh. Association for Computational Linguistics. </institution>
Reference: <author> Jacobs, P., & Zernik, U. </author> <year> (1988). </year> <title> Acquiring Lexical Knowledge from Text: A Case Study. </title> <booktitle> Proceedings, Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. 739-744. </pages> <address> St. Paul, MN. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: 1992; and Zernik 1991)), or knowledge-intensive methods that acquire syntactic and/or semantic lexical knowledge, but rely heavily on hand-coded world knowledge (e.g., (Berwick 1983; Granger 1977; Hastings et al. 1991; Lytinen & Roberts 1989; and Selfridge 1986)) or hand-coded heuristics that describe how and when to acquire new word definitions <ref> (e.g., Jacobs & Zernik 1988 and Wilensky 1991) </ref>.
Reference: <author> Lehnert, W. </author> <year> (1990). </year> <title> Symbolic/Subsymbolic Sentence Analysis: Exploiting the Best of Two Worlds. </title> <note> In J. </note>
Reference-contexts: In particular, the representation is based on the kinds of knowledge available to the CIRCUS conceptual sentence analyzer <ref> (Lehnert 1990) </ref> that was used to process the TIPSTER JV corpus.
Reference: <editor> Barnden, & J. Pollack (Eds.), </editor> <booktitle> Advances in Connectionist and Neural Computation Theory, </booktitle> <pages> pp. 135-164. </pages> <address> Norwood, NJ: </address> <publisher> Ablex Publishers. </publisher>
Reference: <author> Lytinen, S., & Roberts, S. </author> <year> (1989). </year> <title> Lexical Acquisition as a By-Product of Natural Language Processing. </title> <booktitle> Proceedings, IJCAI-89 Workshop on Lexical Acquisition. </booktitle>
Reference: <author> Michalski, R. S., & Stepp, R. </author> <year> (1983). </year> <title> Learning from observation: conceptual clustering. </title> <editor> In R. S. Michal-ski, J. G. Carbonell, & T. M. Mitchell (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Quinlan, J. R. </author> <year> (1992). </year> <title> C4.5: Programs for Machine Learning. </title> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: We will refer to these as the missing features of the unknown word. To generate the decision tree for feature x, we present the training instances to the C4.5 decision tree system <ref> (Quinlan 1992) </ref> after removing the 3 missing features and augmenting the training instance with the value for x as its supervisory class information. The missing features were also removed from the test instances.
Reference: <author> Quinlan, J. R. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1: </volume> <pages> 81-106. </pages>
Reference-contexts: Because it requires classification 1 This sentence was taken from the TIPSTER joint ventures corpus. along multiple, sometimes related, dimensions, lexi-cal acquisition isn't simply a classification problem of the type typically handled by decision tree algorithms <ref> (Quinlan 1986) </ref>. However, because the features to be predicted are known beforehand, neither is it a pure example of the flexible prediction task (e.g., Fisher 1989; Fisher 1987) performed by conceptual clustering algorithms (Fisher 1987; Michalski & Stepp 1983). <p> However, (Almuallim & T 1991) show that ID3 <ref> (Quinlan 1986) </ref> is not particularly good at selecting a minimum set of features from an original set containing possibly many irrelevant attributes.
Reference: <author> Quinlan, J. R. </author> <year> (1983). </year> <title> Learning Efficient Classification Procedures and Their Application to Chess End Games. </title> <editor> In R. S. Michalski, J. G. Carbonell, & T. </editor> <publisher> M. </publisher>
Reference-contexts: Given that feature set specification is a notoriously time-consuming and knowledge-intensive task however <ref> (Quinlan 1983) </ref>, it would be better if the feature set could be chosen systematically and automatically.
Reference: <editor> Mitchell (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach. </booktitle> <address> Palo Alto: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Resnik, P. </author> <year> (1992). </year> <title> A class-based approach to lexical discovery. </title> <booktitle> Proceedings, 30th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pp. 327-329. </pages> <institution> University of Delaware, Newark, DE. Association for Computational Linguistics. </institution>
Reference: <author> Selfridge, M. </author> <year> (1986). </year> <title> A computer model of child language learning. </title> <journal> Artificial Intelligence, </journal> <volume> 29: </volume> <pages> 171-216. </pages>
Reference: <author> Skalak, D. and Rissland, E. </author> <year> (1990). </year> <title> Inductive Learning in a Mixed Paradigm Setting. </title> <booktitle> Proceedings, Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 840-847. </pages> <address> Boston, MA. </address> <publisher> AAAI Press/MIT Press. </publisher>
Reference-contexts: On one hand, these results may not seem surprising since previous research has found the converse to be true | <ref> (Skalak & Rissland 1990) </ref> show that a case-based reasoning system can successfully perform the feature specification task for a decision tree classification system.
Reference: <author> Wilensky, R. </author> <year> (1991). </year> <title> Extending the Lexicon by Exploiting Subregularities. </title> <type> Tech. Report No. </type> <institution> UCB/CSD 91/618. Computer Science Division (EECS), Univ. of California, Berkeley. </institution>
Reference: <author> Yarowsky, D. </author> <year> (1992). </year> <title> Word-Sense Disambiguation Using Statistical Models of Roget's Categories Trained on Large Corpora. </title> <booktitle> Proceedings, COLING-92. </booktitle>
Reference: <author> Zernik, U. </author> <year> (1991). </year> <title> Train1 vs. Train 2: Tagging Word Senses in Corpus. </title> <editor> In U. Zernik (Ed.), </editor> <title> Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon, </title> <journal> pp. </journal> <pages> 91-112. </pages> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates, Inc. </publisher>
References-found: 29

