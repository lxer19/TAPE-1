URL: ftp://ftp.cs.toronto.edu/pub/yiming/ICMAS-LIOME.ps.gz
Refering-URL: http://www.cs.toronto.edu/~yiming/Research.html
Root-URL: http://www.cs.toronto.edu
Email: yiming@vis.toronto.edu tsotsos@vis.toronto.edu  
Phone: Tel: (416) 928-2090 (416) 978-3619  
Title: On the Collaborative Object Search Team: a Formulation  
Author: Yiming Ye and John K. Tsotsos 
Address: Toronto Ontario, Canada M5S 1A4  
Affiliation: Department of Computer Science University of Toronto  
Abstract: This paper gives a formulation of a collaborative object search team and studies the learning, interaction and organization within this multi-agent environment. Each team member is assumed to be a mobile platform equipped with an active camera that can take image of the environment and recognition algorithms that can analyze the resulted image and detect the target object within the image. The goal of the team is to find the target within a give time constraint. In order to do this, the agents must interact and collaborate with each other and must learn and modify the various cooperation styles based on the search results. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Hayes-Roth, B.; Brownston, L.; and Gen, R. </author> <year> 1995. </year> <title> Multiagent collabration in directed improvisation. </title> <booktitle> In Proceedings of the International Conference on Multi-Agent Systems (ICMAS-95). </booktitle>
Reference: <author> Kitano, H.; Asada, M.; Kuniyoshi, Y.; Noda, I.; and Osawa, E. </author> <year> 1995. </year> <title> The robot world cup initiative. </title> <booktitle> In Proceedings of IJCAI-95 Workshop on Entertainment and AI/Alife. </booktitle>
Reference-contexts: Such domains include virtual theater (Hayes-Roth, Brownston, & Gen 1995), realistic virtual training environments (Pimentel & Teixeira 1994)(Rao et al. 1993)(Tambe & Rosenbloom 1995), RoboCup robotic and virtual soccer <ref> (Kitano et al. 1995) </ref> and robotic collaboration by observation (Kuniyoshi et al. 1994), etc. This paper focuses on our recent research effort aimed at developing theories and systems for mul-tiagent object search |- the task of searching for a 3D object in a 3D environment by a group of robots.
Reference: <author> Kuniyoshi, Y.; Rougeaux, S.; Ishii, M.; Kita, N.; Sakane, S.; and Kakikura, M. </author> <year> 1994. </year> <title> Cooperation by observation: the framework and the basic task pattern. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation. </booktitle>
Reference-contexts: Such domains include virtual theater (Hayes-Roth, Brownston, & Gen 1995), realistic virtual training environments (Pimentel & Teixeira 1994)(Rao et al. 1993)(Tambe & Rosenbloom 1995), RoboCup robotic and virtual soccer (Kitano et al. 1995) and robotic collaboration by observation <ref> (Kuniyoshi et al. 1994) </ref>, etc. This paper focuses on our recent research effort aimed at developing theories and systems for mul-tiagent object search |- the task of searching for a 3D object in a 3D environment by a group of robots.
Reference: <author> Nickerson, S.; Jenkin, M.; Milios, E.; Down, B.; Ja-siobedzki, P.; Jepson, A.; Terzopoulos, D.; Tsotsos, J.; Wilkes, D.; Bains, N.; and Tran, K. </author> <year> 1993. </year> <title> Ark: Autonomous navigation of a mobile robot in a known environment. </title> <booktitle> In Intelligent Autonomous Systems-3, </booktitle> <pages> 288-296. </pages>
Reference-contexts: The model of the search agent (Figure 1 (a)(b))is assumed to be a mobile platform with a robotic head and a camera that can pan, tilt and zoom (Note: this model is based on the ARK robot and the Laser Eye <ref> (Nickerson et al. 1993) </ref>). The camera's image plane is assumed to be always coincident with its focal plane.
Reference: <author> Pimentel, K., and Teixeira, K. </author> <year> 1994. </year> <title> Virtual reality: through the new looking glass. Blue Ridge Summit: </title> <publisher> Windcrest/McGraw-Hill. </publisher>
Reference-contexts: Introduction Many Distributed Artificial Intelligence researchers begin to build agents that can work in a complex, dynamic multiagent domains (Tambe & Rosenbloom 1995). Such domains include virtual theater (Hayes-Roth, Brownston, & Gen 1995), realistic virtual training environments <ref> (Pimentel & Teixeira 1994) </ref>(Rao et al. 1993)(Tambe & Rosenbloom 1995), RoboCup robotic and virtual soccer (Kitano et al. 1995) and robotic collaboration by observation (Kuniyoshi et al. 1994), etc.
Reference: <author> Rao, A.; Lucas, A.; Morley, D.; M., S.; and G., M. </author> <year> 1993. </year> <title> Agent-oriented architecture for air-combat simulation. </title> <type> Technical Report Technical Note 42, </type> <institution> The Australian Artificial Intelligence Institute. </institution>
Reference: <author> Tambe, M., and Rosenbloom, P. </author> <year> 1995. </year> <title> Resc: An approach for real-time, dynamic agent tracking. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence. </booktitle>
Reference-contexts: Introduction Many Distributed Artificial Intelligence researchers begin to build agents that can work in a complex, dynamic multiagent domains <ref> (Tambe & Rosenbloom 1995) </ref>. Such domains include virtual theater (Hayes-Roth, Brownston, & Gen 1995), realistic virtual training environments (Pimentel & Teixeira 1994)(Rao et al. 1993)(Tambe & Rosenbloom 1995), RoboCup robotic and virtual soccer (Kitano et al. 1995) and robotic collaboration by observation (Kuniyoshi et al. 1994), etc.
Reference: <author> Ye, Y., and Tsotsos, J. K. </author> <year> 1995. </year> <title> Where to look next in 3d object search. </title> <booktitle> In 1995 IEEE International Symposium for Computer Vision. </booktitle>
Reference-contexts: Introduction Many Distributed Artificial Intelligence researchers begin to build agents that can work in a complex, dynamic multiagent domains (Tambe & Rosenbloom 1995). Such domains include virtual theater <ref> (Hayes-Roth, Brownston, & Gen 1995) </ref>, realistic virtual training environments (Pimentel & Teixeira 1994)(Rao et al. 1993)(Tambe & Rosenbloom 1995), RoboCup robotic and virtual soccer (Kitano et al. 1995) and robotic collaboration by observation (Kuniyoshi et al. 1994), etc. <p> Multi-agent object search system is quite different from the task of object search by a single robotic agent, on which we have done an extensive research and experiments <ref> (Ye & Tsotsos 1995) </ref> (Ye & Tsotsos 1996a) (Ye 1996) (Ye & Tsotsos 1996b). The multiagent team activities are not merely a union of simultaneous, coordinated individual activities |- each agent is not merely searching alone without considering other agent's action. <p> The Local Knowledge If only local knowledge is considered, the task is the same as object search by a single agent, on which we have done an extensive research. We have designed a strategy to select the best action such that P (f ) = P maximized <ref> (Ye & Tsotsos 1995) </ref>. But in multiagent environment, the P (f ) calculated this way does not perfectly reflect the real probability of detecting the target by action f . <p> The strategy of selecting the next agent position is straight forward. For each candidate position (x; y), there is a range of space that can be checked by the camera without occlusion. We call this range the sensed sphere SS (x; y) for position (x; y) (please refer to <ref> (Ye & Tsotsos 1995) </ref> (Ye 1996) for more detail). The sum of the probability of all the cells within the corresponding sensed sphere is called the sensible probability for this position S prob (x; y).
Reference: <author> Ye, Y., and Tsotsos, J. K. </author> <year> 1996a. </year> <title> Sensor planning in 3d object search: its formulation and complexity. </title> <booktitle> In The 4th International Symposium on Artificial Intelligence and Mathematics. </booktitle>
Reference-contexts: Multi-agent object search system is quite different from the task of object search by a single robotic agent, on which we have done an extensive research and experiments (Ye & Tsotsos 1995) <ref> (Ye & Tsotsos 1996a) </ref> (Ye 1996) (Ye & Tsotsos 1996b). The multiagent team activities are not merely a union of simultaneous, coordinated individual activities |- each agent is not merely searching alone without considering other agent's action. <p> 1 , find an effort allocation such that P [F ] is maximized and t (f a (1) ) + t (f a (2) ) + : : : + t (f (N a 1 ) ) K Since this simplified problem (m = 1) is NP-hard (please refer to <ref> (Ye & Tsotsos 1996a) </ref> for proofs), thus the multiagent object search problem is also NP-hard. Because of this, it is impractical to design a team search strategy that can always generate an effort allocation that maximizes the probability of detecting the target.
Reference: <author> Ye, Y., and Tsotsos, J. K. </author> <year> 1996b. </year> <title> Tracking with pan, tilt, </title> <journal> and zoom camera. </journal> <note> In In Preparation. </note>
Reference-contexts: Multi-agent object search system is quite different from the task of object search by a single robotic agent, on which we have done an extensive research and experiments (Ye & Tsotsos 1995) (Ye & Tsotsos 1996a) (Ye 1996) <ref> (Ye & Tsotsos 1996b) </ref>. The multiagent team activities are not merely a union of simultaneous, coordinated individual activities |- each agent is not merely searching alone without considering other agent's action.
Reference: <author> Ye, Y. </author> <year> 1996. </year> <title> Sensor planning in 3D object search. </title> <type> Ph.D. Dissertation, </type> <institution> Department of Computer Science, University of Toronto, Toronto, On-tario, Canada M5S 1A4. </institution>
Reference-contexts: Multi-agent object search system is quite different from the task of object search by a single robotic agent, on which we have done an extensive research and experiments (Ye & Tsotsos 1995) (Ye & Tsotsos 1996a) <ref> (Ye 1996) </ref> (Ye & Tsotsos 1996b). The multiagent team activities are not merely a union of simultaneous, coordinated individual activities |- each agent is not merely searching alone without considering other agent's action. <p> In general <ref> (Ye 1996) </ref>, b (a i ; c j ; f ) is determined by various factors, such as intensity, occlusion, and orientation, etc. <p> ) 2 )tan ( h 0 0 = arctan [tan () tan ( w 0 tan ( w ] ffi 0 = arctan [tan (ffi) tan ( w 0 tan ( w ] When the configuration of two operations are very similar, they might correlated with each other (refer to <ref> (Ye 1996) </ref> for detail). Repeated actions are avoided during the search process. When independence is assumed, b (a i ; c j ; f ) is calculated as following. <p> For each candidate position (x; y), there is a range of space that can be checked by the camera without occlusion. We call this range the sensed sphere SS (x; y) for position (x; y) (please refer to (Ye & Tsotsos 1995) <ref> (Ye 1996) </ref> for more detail). The sum of the probability of all the cells within the corresponding sensed sphere is called the sensible probability for this position S prob (x; y). The task is to find a position (x; y) such that the sensible probability is maximized.
References-found: 11

