URL: ftp://ftp.cs.washington.edu/homes/romer/isca95.paper.ps
Refering-URL: http://www.cs.washington.edu/homes/melody/os/memory.html
Root-URL: 
Email: fromer,ohlrich,karlin,bershadg@cs.washington.edu  
Title: Reducing TLB and Memory Overhead Using Online Superpage Promotion  
Author: Theodore H. Romer Wayne H. Ohlrich Anna R. Karlin Brian N. Bershad 
Address: Seattle, WA 98195  
Affiliation: Department of Computer Science and Engineering University of Washington  
Note: To appear in "Proceedings of the 22nd Annual International Symposiumon Computer Architecture," 1995.  
Abstract: Modern microprocessors contain small TLBs that maintain a cache of recently used translations. A TLB's coverage is the sum of the number of bytes mapped by each entry. Applications with working sets larger than the TLB coverage will perform poorly due to high TLB miss rates. Superpages have been proposed as a mechanism for increasing TLB coverage. A superpageis a virtual memory page with size and alignment that are a power of two multiple of the system's base page size. In this paper, we describe online policies for superpage management that monitor TLB miss traffic to decide when a superpage should be constructed. Our policies take into account both the benefit of a superpage promotion (potential for preventing future misses) and the cost (page copying). Although our approach increases the cost of each TLB miss, the net effect is to improve total execution time by eliminating a large number of misses without significantly increasing memory usage, thereby improving system performance. 
Abstract-found: 1
Intro-found: 1
Reference: [Appel & Li 91] <author> Appel, W. and Li, K. </author> <title> Virtual Memory Primitives for User Programs. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 96-107, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: If the replacement policy is a simulation of LRU using a two-handed clock, and the system is not paging, then the system only needs reference information about a small fraction of pages at any given time, and demotions will occur infrequently. More esoteric functions that require fine-grained reference information <ref> [Appel & Li 91] </ref>, such as write-trapping for a distributed shared memory [Carter et al. 91], will increase the frequency of page demotion. As a result, superpages may not be appropriate for applications that rely on such functions.
Reference: [Babaoglu & Joy 81] <author> Babaoglu, Ozalp. and Joy, W. </author> <title> Converting a Swap-Based System to do Paging in an Architecture Lacking Page-Referenced Bits. </title> <booktitle> In Proceedings of the Eighth Symposium on Operating Systems Principles, </booktitle> <pages> pages 78-86, </pages> <month> December </month> <year> 1981. </year>
Reference-contexts: There is a tension between superpages and other operating system mechanisms that rely on uniformly sized pages, such as the file system's buffer cache, copy-on-write virtual memory [Young et al. 87], and LRU-clock <ref> [Babaoglu & Joy 81] </ref>. To resolve this tension, su-perpage management can be concealed entirely within the machine-dependent layer of the operating system's virtual memory system (MD-VM) [Rashid et al. 87].
Reference: [Bala et al. 94] <author> Bala, K., Kaashoek, F., and Weihl, W. </author> <title> Software Prefetching and Caching for Translation Buffers. </title> <booktitle> In Proceedings of the 1st USENIX Symposium on Operating System Design and Implementation, </booktitle> <pages> pages 243-254, </pages> <month> Novem-ber </month> <year> 1994. </year>
Reference: [Blanck & Krueger 92] <author> Blanck, G. and Krueger, S. </author> <title> The SuperSPARC Microprocessor. </title> <booktitle> In COMPCON, </booktitle> <pages> pages 136-141, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: This requires that each TLB entry maintain additional bits that mask off the lower bits of the requested virtual page so that all base pages that are part of the same superpage are matched by the same TLB entry. This additional logic can be found in several contemporary processors <ref> [Kane & Heinrich 92, Blanck & Krueger 92, Dig 92] </ref>. There is a tension between superpages and other operating system mechanisms that rely on uniformly sized pages, such as the file system's buffer cache, copy-on-write virtual memory [Young et al. 87], and LRU-clock [Babaoglu & Joy 81].
Reference: [Cao et al. 94] <author> Cao, P., Felten, E., and Li, K. </author> <title> Implementation and Performance of Application-Controlled File Caching. </title> <booktitle> In Proceedings of the 1st USENIX Symposiumon Operating System Design andImplementation,pages 165-177, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: Competitive algorithms make online decisions that result in performance within a constant factor of an optimal offline algorithm. Prior research in this area has influenced, for example, the design of synchronization [Karlin et al. 91], paging [Sleator & Tarjan 85], and cache management algorithms <ref> [Cao et al. 94] </ref>. Others [Chen et al. 92, Mogul 93, Khalidi et al. 93] have described the potential positive impact of a system that supports superpages, although they do not describe policies for promotion or demotion.
Reference: [Carter et al. 91] <author> Carter, J., Bennett, J., and Zwaenepoel, W. </author> <title> Implementation and Performance of Munin. </title> <booktitle> In Proceedings of the Thirteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 152-164, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: More esoteric functions that require fine-grained reference information [Appel & Li 91], such as write-trapping for a distributed shared memory <ref> [Carter et al. 91] </ref>, will increase the frequency of page demotion. As a result, superpages may not be appropriate for applications that rely on such functions.
Reference: [Chambers 93] <author> Chambers, C. </author> <title> The Cecil Language: Specification and Rationale. </title> <type> Technical Report 93-03-05, </type> <institution> University of Washington, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: compress compress compressing a 977 KB input file. nasa7-5 Gaussian elimination for a 3.8 MB matrix. nasa7-4 Block tridiagonal matrix solver for a 131.8 KB matrix. fpga Logic bipartitioner targeted to FPGAs, using a 1626 KB input file [Hauck & Borriello 95]. cecil cecil compiling a 21 KB input file <ref> [Chambers 93] </ref>. atom atom instrumenting a 2.6 MB binary with our TLB simulator. fft Fast fourier transform of a 32 MB array. spice the spice circuit simulation benchmark on the 15 KB reference input set. gcc gcc compiling a 109 KB input file.
Reference: [Chen et al. 92] <author> Chen, J. B., Borg, A., and Jouppi, N. P. </author> <title> A Simulation-based Study of TLB Performance. </title> <booktitle> In Proceedings of the 19th Annual Symposium on Computer Architecture, </booktitle> <pages> pages 114-123, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Competitive algorithms make online decisions that result in performance within a constant factor of an optimal offline algorithm. Prior research in this area has influenced, for example, the design of synchronization [Karlin et al. 91], paging [Sleator & Tarjan 85], and cache management algorithms [Cao et al. 94]. Others <ref> [Chen et al. 92, Mogul 93, Khalidi et al. 93] </ref> have described the potential positive impact of a system that supports superpages, although they do not describe policies for promotion or demotion.
Reference: [Dig 92] <author> Digital Equipment Corporation. </author> <title> DECchip 21064-AA Microprocessor, Hardware Reference Manual, 1992. Order Number: </title> <publisher> EC-N0079-72. </publisher>
Reference-contexts: We also show that policies that do not consider previous reference patterns and promotion costs perform worse than those that do, in terms of TLB miss overhead, memory consumption, or both. Our online policies require modest architectural support which can already be found in modern systems <ref> [Kane & Heinrich 92, Dig 92] </ref>, namely a software-managed TLB with the ability to map entries of variable size. <p> This requires that each TLB entry maintain additional bits that mask off the lower bits of the requested virtual page so that all base pages that are part of the same superpage are matched by the same TLB entry. This additional logic can be found in several contemporary processors <ref> [Kane & Heinrich 92, Blanck & Krueger 92, Dig 92] </ref>. There is a tension between superpages and other operating system mechanisms that rely on uniformly sized pages, such as the file system's buffer cache, copy-on-write virtual memory [Young et al. 87], and LRU-clock [Babaoglu & Joy 81].
Reference: [Dutton et al. 92] <author> Dutton, T., Eiref, D., Kurth, H., Reisert, J., and Stewart, R. </author> <title> The Design of the DEC 3000 AXP Systems, Two High-Performance Workstations. </title> <journal> Digital Technical Journal, </journal> <volume> 4(4) </volume> <pages> 66-81, </pages> <year> 1992. </year> <note> Special Issue. </note>
Reference-contexts: Unfortunately, TLB coverage, which is the amount of virtual memory that can be directly accessed without incurring a TLB miss, has not scaled accordingly. Because modern systems typically incur a penalty of between 10 and 30 cycles per TLB miss <ref> [Kane & Heinrich 92, Dutton et al. 92] </ref>, any application with a working set larger than the TLB's coverage can spend a significant fraction of its time waiting for TLB misses to be serviced [Chen et al. 92, Bala et al. 94, Talluri et al. 92].
Reference: [Hauck & Borriello 95] <author> Hauck, S. and Borriello, G. </author> <title> An Evaluation of Bipartition-ing Techniques. </title> <journal> Submitted for publication to IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, </journal> <year> 1995. </year>
Reference-contexts: The Wisconsin coral database performing a nested join [Ramakrishnan et al. 93]. compress compress compressing a 977 KB input file. nasa7-5 Gaussian elimination for a 3.8 MB matrix. nasa7-4 Block tridiagonal matrix solver for a 131.8 KB matrix. fpga Logic bipartitioner targeted to FPGAs, using a 1626 KB input file <ref> [Hauck & Borriello 95] </ref>. cecil cecil compiling a 21 KB input file [Chambers 93]. atom atom instrumenting a 2.6 MB binary with our TLB simulator. fft Fast fourier transform of a 32 MB array. spice the spice circuit simulation benchmark on the 15 KB reference input set. gcc gcc compiling a
Reference: [Hosking & Moss 93] <author> Hosking, A. L. and Moss, J. E. B. </author> <title> Protection Traps and Alternatives for Memory Management of an Object Oriented Language. </title> <booktitle> In Proceedings of the Fourteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 106-119, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: As a result, superpages may not be appropriate for applications that rely on such functions. However, recent results indicate that the use of the virtual memory system to detect application-level accessescan be less efficient than strategies that rely on the compiler <ref> [Hosking & Moss 93, Zekaukas et al. 94] </ref>. 6 Policy design principles In this section, we discuss the principles underlying the design of effective online superpage construction policies.
Reference: [Kane & Heinrich 92] <author> Kane, G. and Heinrich, J. </author> <title> MIPS RISC Architecture. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1992. </year>
Reference-contexts: Unfortunately, TLB coverage, which is the amount of virtual memory that can be directly accessed without incurring a TLB miss, has not scaled accordingly. Because modern systems typically incur a penalty of between 10 and 30 cycles per TLB miss <ref> [Kane & Heinrich 92, Dutton et al. 92] </ref>, any application with a working set larger than the TLB's coverage can spend a significant fraction of its time waiting for TLB misses to be serviced [Chen et al. 92, Bala et al. 94, Talluri et al. 92]. <p> We also show that policies that do not consider previous reference patterns and promotion costs perform worse than those that do, in terms of TLB miss overhead, memory consumption, or both. Our online policies require modest architectural support which can already be found in modern systems <ref> [Kane & Heinrich 92, Dig 92] </ref>, namely a software-managed TLB with the ability to map entries of variable size. <p> This requires that each TLB entry maintain additional bits that mask off the lower bits of the requested virtual page so that all base pages that are part of the same superpage are matched by the same TLB entry. This additional logic can be found in several contemporary processors <ref> [Kane & Heinrich 92, Blanck & Krueger 92, Dig 92] </ref>. There is a tension between superpages and other operating system mechanisms that rely on uniformly sized pages, such as the file system's buffer cache, copy-on-write virtual memory [Young et al. 87], and LRU-clock [Babaoglu & Joy 81].
Reference: [Karlin et al. 88] <author> Karlin, A., Manasse, M., Rudolph, L., and Sleator, D. </author> <title> Competitive Snoopy Caching. </title> <journal> Algorithmica, </journal> <volume> 3(1) </volume> <pages> 70-119, </pages> <year> 1988. </year>
Reference-contexts: make this decision online, without knowledge of the number of times she will go skiing in the future, she would nevertheless prefer to know that she will not make a decision much worse than the 2 This analogy was originally suggested by Larry Rudolph in explanationof the results described in <ref> [Karlin et al. 88] </ref>. optimal offline decision. In this case, the right thing for her to do is to begin by renting skis. If she makes it to her eleventh excursion, she should then buy skis.
Reference: [Karlin et al. 91] <author> Karlin, A. R., Li, K., Manasse, M., and Owicki, S. </author> <title> Empirical Studies of Competitive Spinning for Shared Memory Multiprocessors. </title> <booktitle> In Proceedings of the Thirteenth ACM Symposium on Operating Systems Principles, </booktitle> <year> 1991. </year>
Reference-contexts: Competitive algorithms make online decisions that result in performance within a constant factor of an optimal offline algorithm. Prior research in this area has influenced, for example, the design of synchronization <ref> [Karlin et al. 91] </ref>, paging [Sleator & Tarjan 85], and cache management algorithms [Cao et al. 94]. Others [Chen et al. 92, Mogul 93, Khalidi et al. 93] have described the potential positive impact of a system that supports superpages, although they do not describe policies for promotion or demotion.
Reference: [Khalidi et al. 93] <author> Khalidi, Y. A., Talluri, M., Nelson, M., and Williams, D. </author> <title> Virtual Memory Support for Multiple Page Sizes. </title> <booktitle> In Proceedings of the Fourth Workshop on Workstation Operating Systems, </booktitle> <pages> pages 104-109, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Competitive algorithms make online decisions that result in performance within a constant factor of an optimal offline algorithm. Prior research in this area has influenced, for example, the design of synchronization [Karlin et al. 91], paging [Sleator & Tarjan 85], and cache management algorithms [Cao et al. 94]. Others <ref> [Chen et al. 92, Mogul 93, Khalidi et al. 93] </ref> have described the potential positive impact of a system that supports superpages, although they do not describe policies for promotion or demotion.
Reference: [Mogul 93] <author> Mogul, J. </author> <title> Big Memories on the Desktop. </title> <booktitle> In Proceedings of the Fourth Workshop on Workstation Operating Systems, </booktitle> <pages> pages 110-115, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Competitive algorithms make online decisions that result in performance within a constant factor of an optimal offline algorithm. Prior research in this area has influenced, for example, the design of synchronization [Karlin et al. 91], paging [Sleator & Tarjan 85], and cache management algorithms [Cao et al. 94]. Others <ref> [Chen et al. 92, Mogul 93, Khalidi et al. 93] </ref> have described the potential positive impact of a system that supports superpages, although they do not describe policies for promotion or demotion.
Reference: [Ramakrishnan et al. 93] <author> Ramakrishnan, R., Srivastava, D., Sudarshan, S., and Seshadri, P. </author> <title> Implementation of the CORAL Deductive Database System. </title> <booktitle> In Proceedings of ACM SIGMOD Internation Conference on Management of Data, </booktitle> <year> 1993. </year>
Reference-contexts: Our second performance metric is Memory Usage Overhead, which is the percentage increase in memory consumed due to internal fragmentation compared to a system with fixed-size 4 KB pages. Benchmark Description coral The Wisconsin coral database performing a nested join <ref> [Ramakrishnan et al. 93] </ref>. compress compress compressing a 977 KB input file. nasa7-5 Gaussian elimination for a 3.8 MB matrix. nasa7-4 Block tridiagonal matrix solver for a 131.8 KB matrix. fpga Logic bipartitioner targeted to FPGAs, using a 1626 KB input file [Hauck & Borriello 95]. cecil cecil compiling a 21
Reference: [Rashid et al. 87] <author> Rashid, R., Avadis Tevanian, J., Young, M., Golub, D., Baron, R., Black, D., Bolosky, W., and Chew, J. </author> <title> Machine-Independent Virtual Memory Management for Paged Uniprocessor and Multiprocessor Architectures. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 31-39, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: To resolve this tension, su-perpage management can be concealed entirely within the machine-dependent layer of the operating system's virtual memory system (MD-VM) <ref> [Rashid et al. 87] </ref>. When clients of the virtual memory system request operations on base pages that are component to super-pages, the MD-VM layer can demote any superpages containing the target base pages so that the requested operation can be performed.
Reference: [Sleator & Tarjan 85] <author> Sleator, D. D. and Tarjan, R. E. </author> <title> Amortized Efficiency of List Update and Paging Rules. </title> <journal> Communications of the ACM, </journal> <volume> 28 </volume> <pages> 202-208, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: Competitive algorithms make online decisions that result in performance within a constant factor of an optimal offline algorithm. Prior research in this area has influenced, for example, the design of synchronization [Karlin et al. 91], paging <ref> [Sleator & Tarjan 85] </ref>, and cache management algorithms [Cao et al. 94]. Others [Chen et al. 92, Mogul 93, Khalidi et al. 93] have described the potential positive impact of a system that supports superpages, although they do not describe policies for promotion or demotion.
Reference: [Srivastava & Eustace 94] <author> Srivastava, A. and Eustace, A. </author> <title> ATOM: A System for Building Customized Program Analysis Tools. </title> <booktitle> In Proceedings of the 1994 ACM Symposium on Programming Languages Design and Implementation. ACM, </booktitle> <year> 1994. </year>
Reference-contexts: Once the policy parameters were established, we augmented this training set with the remaining five benchmarks (coral, fpga, cecil, atom, and spice), but did not make any further changes to the parameters. We used ATOM, a binary rewriting tool from DEC WRL <ref> [Srivastava & Eustace 94] </ref>, to simulate the TLB behavior of the applications. The simulated system had two 32-entry fully-associative TLBs, one for instructions and one for data, and used an LRU replacement policy.
Reference: [Talluri & Hill 94] <author> Talluri, M. and Hill, M. D. </author> <title> Surpassing the TLB Performance of Su-perpages with Less Operating System Support. </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 171-182, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Instead, they suggest that the programmer or compiler offer the operating system a hint about the appropriate page size for a particular range of memory. Researchers at Wisconsin <ref> [Talluri & Hill 94] </ref> present a simple policy for page promotion in a system that supports two page sizes: 4 KB and 64 KB.
Reference: [Talluri et al. 92] <author> Talluri, M., Kong, S., Hill, M. D., and Patterson, D. </author> <title> Tradeoffs in Supporting Two Page Sizes. </title> <booktitle> In Proceedings of the 19th Annual Symposium on Computer Architecture, </booktitle> <pages> pages 415-424, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: We include ASAP because it is simple and offers a plausible alternative to the more sophisticated policies, and ASAP-4-64 because it is similar to a policy used in other studies <ref> [Talluri et al. 92] </ref>. We do not consider the impact of page reservation, so ASAP and ASAP-4-64 incur copy costs.
Reference: [Young et al. 87] <author> Young, M., Tevanian, A., Rashid, R., Golub, D., Eppinger, J., Chew, J., Bolosky, W., Black, D., and Baron, R. </author> <title> The Duality of Memory and Communication in the Implementation of a Multiprocessor Operating System. </title> <booktitle> In Proceedings of the Eleventh ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 63-76, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: This additional logic can be found in several contemporary processors [Kane & Heinrich 92, Blanck & Krueger 92, Dig 92]. There is a tension between superpages and other operating system mechanisms that rely on uniformly sized pages, such as the file system's buffer cache, copy-on-write virtual memory <ref> [Young et al. 87] </ref>, and LRU-clock [Babaoglu & Joy 81]. To resolve this tension, su-perpage management can be concealed entirely within the machine-dependent layer of the operating system's virtual memory system (MD-VM) [Rashid et al. 87].
Reference: [Zekaukas et al. 94] <author> Zekaukas, M., Sawdon, W., and Bershad, B. </author> <title> Software Write Detection for Distributed Shared Memory. </title> <booktitle> In Proceedings of the 1st USENIX Symposium on Operating System Design and Implementation, </booktitle> <pages> pages 87-100, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: As a result, superpages may not be appropriate for applications that rely on such functions. However, recent results indicate that the use of the virtual memory system to detect application-level accessescan be less efficient than strategies that rely on the compiler <ref> [Hosking & Moss 93, Zekaukas et al. 94] </ref>. 6 Policy design principles In this section, we discuss the principles underlying the design of effective online superpage construction policies.
References-found: 25

