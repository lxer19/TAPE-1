URL: http://www.cs.ucsb.edu/TRs/techreports/TRCS98-10.ps
Refering-URL: http://www.cs.ucsb.edu/TRs/
Root-URL: http://www.cs.ucsb.edu
Email: ambujg@cs.ucsb.edu  
Title: Dimensionality Reduction for Similarity Searching in Dynamic Databases  
Author: K. V. Ravi Kanth Divyakant Agrawal Amr El Abbadi Ambuj Singh fkravi, agrawal, 
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California at Santa Barbara  
Abstract: Databases are increasingly being used to store multi-media objects such as maps, images, audio and video. Storage and retrieval of these objects is accomplished using multi-dimensional index structures such as R fl -trees and SS-trees. As dimensionality increases, query performance in these index structures degrades. This phenomenon, generally referred to as the dimensionality curse, can be circumvented by reducing the dimensionality of the data. Such a reduction is however accompanied by a loss of precision of query results. Current techniques such as QBIC use SVD transform-based dimensionality reduction to ensure high query precision. The drawback of this approach is that SVD is expensive to compute, and therefore not readily applicable to dynamic databases. In this paper, we propose novel techniques for performing SVD-based dimensionality reduction in dynamic databases. When the data distribution changes considerably so as to degrade query precision, we recompute the SVD transform and incorporate it in the existing index structure. For recomputing the SVD-transform, we propose a novel technique that uses aggregate data from the existing index rather than the entire data. This technique reduces the SVD-computation time without compromising query precision. We then explore efficient ways to incorporate the recomputed SVD-transform in the existing index structure without degrading subsequent query response times. These techniques reduce the computation time by a factor of 20 in experiments on color and texture image vectors. The error due to approximate computation of SVD is less than 10%. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Beckmann, H. Kriegel, R. Schneider, and B. Seeger. </author> <title> The R* tree: An efficient and robust access method for points and rectangles. </title> <booktitle> Proc. of the ACM SIGMOD Intl. Conf. on Management of Data, </booktitle> <pages> pages 322331, </pages> <month> May 23-25 </month> <year> 1990. </year>
Reference-contexts: In this paper, we explore how to support this type of search efficiently for dynamic databases, where objects may be inserted and deleted frequently. Searching in multiple dimensions has been extensively researched in the database and computational geometry literature. Several data structures such as R-trees <ref> [1, 2, 13] </ref>, hB-trees [18], Bang files [7, 8, 9], TV-trees [17], SS-trees [24], and SR-trees [16] are designed for supporting fast searching in large multi-dimensional databases. These structures are quite efficient for small dimensions (of the order of 1-10). <p> However, as the data dimensionality increases, the query performance of these structures degrades rapidly. For instance, White and Jain [24] report that as the dimensionality increases from 5 to 10, the performance of a nearest-neighbor query in multi-dimensional structures such as the SS-tree [24] and the R fl -tree <ref> [1] </ref>, degrades by a factor of 12. This phenomenon, appropriately termed the dimensionality curse by Agrawal and Faloutsos [6], is a common characteristic of all multi-dimensional index structures. <p> The re-insertion parameter of the SS-tree is set to 30% of the node capacity and the minimum capacity to 40% of the node capacity. These are the same as in other implementations of SS-trees [24] and R*-trees <ref> [1] </ref>. To simulate real-database scenarios, only 25% nodes of an index are cached in memory in all our experiments. The caching strategy is simple and ensured that all the non-leaf nodes are in memory along with first few leaf nodes that are created.
Reference: [2] <author> S. Berchtold, D. A. Keim, and H. P. Kreigel. </author> <title> The X-tree: An index structure for high dimensional data. </title> <booktitle> Proceedings of the Int. Conf. on Very Large Data Bases, </booktitle> <year> 1996. </year>
Reference-contexts: In this paper, we explore how to support this type of search efficiently for dynamic databases, where objects may be inserted and deleted frequently. Searching in multiple dimensions has been extensively researched in the database and computational geometry literature. Several data structures such as R-trees <ref> [1, 2, 13] </ref>, hB-trees [18], Bang files [7, 8, 9], TV-trees [17], SS-trees [24], and SR-trees [16] are designed for supporting fast searching in large multi-dimensional databases. These structures are quite efficient for small dimensions (of the order of 1-10). <p> This phenomenon, appropriately termed the dimensionality curse by Agrawal and Faloutsos [6], is a common characteristic of all multi-dimensional index structures. In spite of the progress in the design and analysis of multi-dimensional structures such as the TV-trees [17], the X-trees <ref> [2] </ref>, the SS-trees [24], and the SR-trees [16], the dimensionality curse persists. The only known solution for achieving scalable query performance is by reducing the dimensionality of the data.
Reference: [3] <author> S. Chandrasekharan, B. S. Manjunath, Y. F. Wang, J. Winkeler, and H. Zhang. </author> <title> An eigenspace update algorithm for image analysis. CVGIP: Journal of graphical Models and image processing, </title> <year> 1997. </year>
Reference-contexts: We propose a novel technique to efficiently recompute SVD for such dynamic environments. Much research has been done on updating SVD as new vectors are added to, and old ones deleted from a database <ref> [3, 4, 12, 19] </ref>. A simple technique [11] for computing SVD after a new item is added to a database of n d-dimensional vectors has O (n fl d 2 ) time complexity. <p> A simple technique [11] for computing SVD after a new item is added to a database of n d-dimensional vectors has O (n fl d 2 ) time complexity. However, incremental techniques <ref> [3, 4] </ref> reduce this complexity to O (n fl r), where r is the rank of the matrix of the n d-dimensional vectors (r is usually much smaller than d).
Reference: [4] <author> R. Degroat and R. Roberts. </author> <title> Efficient numerically stabilized rank-one eigenstructure updating. </title> <journal> IEEE transactions on acoustic and signal processing (T-ASSP), </journal> <volume> 38(2):301316, </volume> <year> 1990. </year>
Reference-contexts: We propose a novel technique to efficiently recompute SVD for such dynamic environments. Much research has been done on updating SVD as new vectors are added to, and old ones deleted from a database <ref> [3, 4, 12, 19] </ref>. A simple technique [11] for computing SVD after a new item is added to a database of n d-dimensional vectors has O (n fl d 2 ) time complexity. <p> A simple technique [11] for computing SVD after a new item is added to a database of n d-dimensional vectors has O (n fl d 2 ) time complexity. However, incremental techniques <ref> [3, 4] </ref> reduce this complexity to O (n fl r), where r is the rank of the matrix of the n d-dimensional vectors (r is usually much smaller than d).
Reference: [5] <author> C. Faloutsos and K. Lin. </author> <title> Fastmap: A fast algorithm for indexing, data-mining and visualization of traditional and multimedia datasets. </title> <type> Technical Report CS-TR-3383, </type> <institution> Univ. of Maryland Institute for Advanced Computer Studies, </institution> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: The only known solution for achieving scalable query performance is by reducing the dimensionality of the data. Several research initiatives <ref> [5, 14, 17, 20, 21] </ref> including the QBIC project adopt this approach for supporting image retrieval based on their content. This approach for content-based retrieval first condenses most of the information in a dataset to a few dimensions by applying Singular Value Decomposition (SVD).
Reference: [6] <author> C. Faloutsos, M. Ranganathan, and Y. Manolopoulos. </author> <title> Fast subsequence matching in time-series databases. </title> <booktitle> In Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 419429, </pages> <address> Minneapolis, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: This phenomenon, appropriately termed the dimensionality curse by Agrawal and Faloutsos <ref> [6] </ref>, is a common characteristic of all multi-dimensional index structures. In spite of the progress in the design and analysis of multi-dimensional structures such as the TV-trees [17], the X-trees [2], the SS-trees [24], and the SR-trees [16], the dimensionality curse persists. <p> Of these, the SVD technique examines the entire data and rotates the axes to maximize variance along the first few dimensions. In contrast, DFT, DCT, Wavelets and Harr transforms process each individual data point separately. These transforms are used in the context of time series database <ref> [6] </ref> and highly correlated image databases [25]. However, for most data sets, SVD explicitly tries to maximize the variance in the first few dimensions, and therefore, achieves higher precision and recall than other transforms. Figure 3 illustrates this for a database of 144K 256-dimensional color histograms.
Reference: [7] <author> M. W. Freeston. </author> <title> The bang file: a new kind of grid file. </title> <booktitle> Proc. of the ACM SIGMOD Intl. Conf. on Management of Data, </booktitle> <pages> pages 260269, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: Searching in multiple dimensions has been extensively researched in the database and computational geometry literature. Several data structures such as R-trees [1, 2, 13], hB-trees [18], Bang files <ref> [7, 8, 9] </ref>, TV-trees [17], SS-trees [24], and SR-trees [16] are designed for supporting fast searching in large multi-dimensional databases. These structures are quite efficient for small dimensions (of the order of 1-10). However, as the data dimensionality increases, the query performance of these structures degrades rapidly.
Reference: [8] <author> M. W. Freeston. </author> <title> A general solution of the n-dimensional B-tree problem. </title> <booktitle> Proc. of the ACM SIGMOD Intl. Conf. on Management of Data, </booktitle> <month> May </month> <year> 1995. </year>
Reference-contexts: Searching in multiple dimensions has been extensively researched in the database and computational geometry literature. Several data structures such as R-trees [1, 2, 13], hB-trees [18], Bang files <ref> [7, 8, 9] </ref>, TV-trees [17], SS-trees [24], and SR-trees [16] are designed for supporting fast searching in large multi-dimensional databases. These structures are quite efficient for small dimensions (of the order of 1-10). However, as the data dimensionality increases, the query performance of these structures degrades rapidly.
Reference: [9] <author> M. W. Freeston. </author> <title> A new generic index technology. </title> <booktitle> Proc. NASA Goddard Conf. on Mass Storage Technologies, </booktitle> <month> September </month> <year> 1996. </year>
Reference-contexts: Searching in multiple dimensions has been extensively researched in the database and computational geometry literature. Several data structures such as R-trees [1, 2, 13], hB-trees [18], Bang files <ref> [7, 8, 9] </ref>, TV-trees [17], SS-trees [24], and SR-trees [16] are designed for supporting fast searching in large multi-dimensional databases. These structures are quite efficient for small dimensions (of the order of 1-10). However, as the data dimensionality increases, the query performance of these structures degrades rapidly.
Reference: [10] <author> J. H. Friedman, J. Bentley, and R. Finkel. </author> <title> An algorithm for finding best matches in logarithmic expected time. </title> <journal> ACM transactions on mathematical software, </journal> <volume> 3(3):209226, </volume> <year> 1977. </year>
Reference-contexts: This scheme called Reuse-Reconstruct performed much better in our experiments. The Reconstruct strategy reconstructs the entire index from the data entries. If the data can reside entirely in memory, this reconstruction can be accomplished efficiently using the techniques of in-memory index structures such as k-d trees and its variants <ref> [15, 10, 23] </ref>. For disk-resident datasets (like what we used in our experiments), the reconstruction has to be done a few data items at a time, leading to high insertion costs.
Reference: [11] <author> G. H. Golub and C. F. van Loan. </author> <title> Matrix Computations. </title> <publisher> The John Hopkins Press, </publisher> <year> 1989. </year>
Reference-contexts: We propose a novel technique to efficiently recompute SVD for such dynamic environments. Much research has been done on updating SVD as new vectors are added to, and old ones deleted from a database [3, 4, 12, 19]. A simple technique <ref> [11] </ref> for computing SVD after a new item is added to a database of n d-dimensional vectors has O (n fl d 2 ) time complexity.
Reference: [12] <author> M. Gu and S. C. Eisenstat. </author> <title> A stable and fast algorithm for updating the singular value decomposition. </title> <type> Technical Report YALEU/DCS/RR-966, </type> <institution> Yale University, </institution> <address> New Haven, CT, </address> <year> 1994. </year> <month> 22 </month>
Reference-contexts: We propose a novel technique to efficiently recompute SVD for such dynamic environments. Much research has been done on updating SVD as new vectors are added to, and old ones deleted from a database <ref> [3, 4, 12, 19] </ref>. A simple technique [11] for computing SVD after a new item is added to a database of n d-dimensional vectors has O (n fl d 2 ) time complexity.
Reference: [13] <author> A. Guttman. R-trees: </author> <title> A dynamic index structure for spatial searching. </title> <booktitle> Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 4757, </pages> <year> 1984. </year>
Reference-contexts: In this paper, we explore how to support this type of search efficiently for dynamic databases, where objects may be inserted and deleted frequently. Searching in multiple dimensions has been extensively researched in the database and computational geometry literature. Several data structures such as R-trees <ref> [1, 2, 13] </ref>, hB-trees [18], Bang files [7, 8, 9], TV-trees [17], SS-trees [24], and SR-trees [16] are designed for supporting fast searching in large multi-dimensional databases. These structures are quite efficient for small dimensions (of the order of 1-10).
Reference: [14] <author> D. Hull. </author> <title> Improving text retrieval for the routing problem using latent semantic indexing. </title> <booktitle> In Proc. of the 17th ACM-SIGIR Conference, </booktitle> <pages> pages 282291, </pages> <year> 1994. </year>
Reference-contexts: The only known solution for achieving scalable query performance is by reducing the dimensionality of the data. Several research initiatives <ref> [5, 14, 17, 20, 21] </ref> including the QBIC project adopt this approach for supporting image retrieval based on their content. This approach for content-based retrieval first condenses most of the information in a dataset to a few dimensions by applying Singular Value Decomposition (SVD). <p> We observe that SVD achieves around 50% higher precision than DFT. This explains why SVD is the default choice for dimensionality reduction of high-dimensional data in most research and commercial systems such as QBIC [21] and LSI <ref> [14] </ref>. Next, we describe SVD-transformation scheme in more detail and examine how it is incorporated in static databases. varied for SVD- and DFT-transformed data. Database: 144K color histograms. <p> Note that the time is linear in the number of points, but the constants involved are quite high. 2.2.2 Current Techniques for Incorporating SVD-transform in Index Structures Current techniques <ref> [20, 21, 14] </ref> for supporting content-based retrieval on text documents, time sequences, or color, texture, shape features of images employ the following approach to combine fast query response times with high accuracy of query results. First, the original d-dimensional data is transformed using SVD.
Reference: [15] <author> J.L.Bentley. </author> <title> Multi-dimensional binary search trees used for associative searching. </title> <journal> Communications of the ACM, </journal> <volume> 18:509517, </volume> <year> 1975. </year>
Reference-contexts: This scheme called Reuse-Reconstruct performed much better in our experiments. The Reconstruct strategy reconstructs the entire index from the data entries. If the data can reside entirely in memory, this reconstruction can be accomplished efficiently using the techniques of in-memory index structures such as k-d trees and its variants <ref> [15, 10, 23] </ref>. For disk-resident datasets (like what we used in our experiments), the reconstruction has to be done a few data items at a time, leading to high insertion costs.
Reference: [16] <author> N. Katayama and S. Satoh. </author> <title> The SR-tree: An index structure for high-dimensional nearest-neighbor queries. </title> <booktitle> Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 369380, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: Searching in multiple dimensions has been extensively researched in the database and computational geometry literature. Several data structures such as R-trees [1, 2, 13], hB-trees [18], Bang files [7, 8, 9], TV-trees [17], SS-trees [24], and SR-trees <ref> [16] </ref> are designed for supporting fast searching in large multi-dimensional databases. These structures are quite efficient for small dimensions (of the order of 1-10). However, as the data dimensionality increases, the query performance of these structures degrades rapidly. <p> This phenomenon, appropriately termed the dimensionality curse by Agrawal and Faloutsos [6], is a common characteristic of all multi-dimensional index structures. In spite of the progress in the design and analysis of multi-dimensional structures such as the TV-trees [17], the X-trees [2], the SS-trees [24], and the SR-trees <ref> [16] </ref>, the dimensionality curse persists. The only known solution for achieving scalable query performance is by reducing the dimensionality of the data. Several research initiatives [5, 14, 17, 20, 21] including the QBIC project adopt this approach for supporting image retrieval based on their content. <p> The first k dimensions are chosen since most information is concentrated in these dimensions. The reduced-dimensionality data are then indexed using multi-dimensional index structures such as R fl -trees, SS-trees [24], and SR-trees <ref> [16] </ref>. Queries are also transformed using the SVD transform matrix and and answered using the reduced-dimensional index structure. To illustrate this with an example, consider the example data of Figure 1. This figure shows five 2-dimensional points.
Reference: [17] <author> K.-I. Lin, H. V. Jagdish, and C. Faloutsos. </author> <title> The TV-tree: An index structure for high-dimensional data. </title> <journal> VLDB Journal, </journal> <volume> 3:517542, </volume> <year> 1994. </year>
Reference-contexts: Searching in multiple dimensions has been extensively researched in the database and computational geometry literature. Several data structures such as R-trees [1, 2, 13], hB-trees [18], Bang files [7, 8, 9], TV-trees <ref> [17] </ref>, SS-trees [24], and SR-trees [16] are designed for supporting fast searching in large multi-dimensional databases. These structures are quite efficient for small dimensions (of the order of 1-10). However, as the data dimensionality increases, the query performance of these structures degrades rapidly. <p> This phenomenon, appropriately termed the dimensionality curse by Agrawal and Faloutsos [6], is a common characteristic of all multi-dimensional index structures. In spite of the progress in the design and analysis of multi-dimensional structures such as the TV-trees <ref> [17] </ref>, the X-trees [2], the SS-trees [24], and the SR-trees [16], the dimensionality curse persists. The only known solution for achieving scalable query performance is by reducing the dimensionality of the data. <p> The only known solution for achieving scalable query performance is by reducing the dimensionality of the data. Several research initiatives <ref> [5, 14, 17, 20, 21] </ref> including the QBIC project adopt this approach for supporting image retrieval based on their content. This approach for content-based retrieval first condenses most of the information in a dataset to a few dimensions by applying Singular Value Decomposition (SVD).
Reference: [18] <author> D. B. Lomet and B. Salzberg. </author> <title> The hB-tree: A multi-attribute indexing method with good guaranteed performance. </title> <booktitle> Proc. ACM Symp. on Transactions of Database Systems, </booktitle> <address> 15(4):625658, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: In this paper, we explore how to support this type of search efficiently for dynamic databases, where objects may be inserted and deleted frequently. Searching in multiple dimensions has been extensively researched in the database and computational geometry literature. Several data structures such as R-trees [1, 2, 13], hB-trees <ref> [18] </ref>, Bang files [7, 8, 9], TV-trees [17], SS-trees [24], and SR-trees [16] are designed for supporting fast searching in large multi-dimensional databases. These structures are quite efficient for small dimensions (of the order of 1-10). However, as the data dimensionality increases, the query performance of these structures degrades rapidly.
Reference: [19] <author> G. Mathew, V. U. Reddy, and S. Dasgupta. </author> <title> Adaptive estimation of eigenspaces. </title> <journal> IEEE Transactions in Signal Processing, </journal> <volume> 43(2):401411, </volume> <year> 1995. </year>
Reference-contexts: We propose a novel technique to efficiently recompute SVD for such dynamic environments. Much research has been done on updating SVD as new vectors are added to, and old ones deleted from a database <ref> [3, 4, 12, 19] </ref>. A simple technique [11] for computing SVD after a new item is added to a database of n d-dimensional vectors has O (n fl d 2 ) time complexity.
Reference: [20] <author> R. Ng and A. Sedighian. </author> <title> Evaluating multi-dimensional indexing structures for images transformed by principle component analysis. </title> <booktitle> Proc. of the SPIE, </booktitle> <address> 2670:5061, </address> <year> 1994. </year>
Reference-contexts: The only known solution for achieving scalable query performance is by reducing the dimensionality of the data. Several research initiatives <ref> [5, 14, 17, 20, 21] </ref> including the QBIC project adopt this approach for supporting image retrieval based on their content. This approach for content-based retrieval first condenses most of the information in a dataset to a few dimensions by applying Singular Value Decomposition (SVD). <p> Note that the time is linear in the number of points, but the constants involved are quite high. 2.2.2 Current Techniques for Incorporating SVD-transform in Index Structures Current techniques <ref> [20, 21, 14] </ref> for supporting content-based retrieval on text documents, time sequences, or color, texture, shape features of images employ the following approach to combine fast query response times with high accuracy of query results. First, the original d-dimensional data is transformed using SVD.
Reference: [21] <author> W. Niblack, R. Barber, W. Equitz, M. Flickner, E. Glasman, D. Petkovic, and P. Yanker. </author> <title> The QBIC project: Querying images by content using color, texture and shape. </title> <booktitle> In Proc. of the SPIE Conf. 1908 on Storage and Retrieval for Image and Video Databases, volume 1908, </booktitle> <pages> pages 173187, </pages> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: The only known solution for achieving scalable query performance is by reducing the dimensionality of the data. Several research initiatives <ref> [5, 14, 17, 20, 21] </ref> including the QBIC project adopt this approach for supporting image retrieval based on their content. This approach for content-based retrieval first condenses most of the information in a dataset to a few dimensions by applying Singular Value Decomposition (SVD). <p> We observe that SVD achieves around 50% higher precision than DFT. This explains why SVD is the default choice for dimensionality reduction of high-dimensional data in most research and commercial systems such as QBIC <ref> [21] </ref> and LSI [14]. Next, we describe SVD-transformation scheme in more detail and examine how it is incorporated in static databases. varied for SVD- and DFT-transformed data. Database: 144K color histograms. <p> Note that the time is linear in the number of points, but the constants involved are quite high. 2.2.2 Current Techniques for Incorporating SVD-transform in Index Structures Current techniques <ref> [20, 21, 14] </ref> for supporting content-based retrieval on text documents, time sequences, or color, texture, shape features of images employ the following approach to combine fast query response times with high accuracy of query results. First, the original d-dimensional data is transformed using SVD.
Reference: [22] <author> G. Salton. </author> <title> Automatic Text Processing. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: In either case, there is a loss of proximity information as we move from 2 dimensions to 1 dimension. This loss in distance information due to dimensionality reduction is usually measured in terms of precision and recall of a random query point <ref> [22] </ref>. This is detailed next. Let A d denote a set of d-dimensional points. Let A k denote the set of points in k-dimensional space, where k d.
Reference: [23] <author> D. White and R. Jain. </author> <title> Algorithms and strategies for similarity retrieval. </title> <booktitle> Proc. of the SPIE Conference, </booktitle> <year> 1996. </year>
Reference-contexts: This scheme called Reuse-Reconstruct performed much better in our experiments. The Reconstruct strategy reconstructs the entire index from the data entries. If the data can reside entirely in memory, this reconstruction can be accomplished efficiently using the techniques of in-memory index structures such as k-d trees and its variants <ref> [15, 10, 23] </ref>. For disk-resident datasets (like what we used in our experiments), the reconstruction has to be done a few data items at a time, leading to high insertion costs. <p> Choosing a level close to the root leads to more memory requirements since a larger subtree of the index has to be manipulated in the memory. The reconstruction of a subtree is performed using the VAMSplit technique <ref> [23] </ref>. The set of data items in the subtree is partitioned recursively until each sub-partition fits in a single node (disk page). The partitioning is accomplished by determining the most varying dimension, and splitting the data along an appropriate place in this dimension. <p> Given n data items to be partitioned into two sub-partitions, the number of data items in the first sub-partition, m, is computed based on a node capacity of b as follows. m = b n b b n 2b + 0:5c otherwise: 18 White et al. <ref> [23] </ref> showed that this choice of m minimizes the number of nodes in the created index. They also showed that the resulting index supports fast queries.
Reference: [24] <author> D. White and R. Jain. </author> <title> Similarity indexing with the SS-tree. </title> <booktitle> Proc. Int. Conf. on Data Engineering, </booktitle> <pages> pages 516523, </pages> <year> 1996. </year>
Reference-contexts: Searching in multiple dimensions has been extensively researched in the database and computational geometry literature. Several data structures such as R-trees [1, 2, 13], hB-trees [18], Bang files [7, 8, 9], TV-trees [17], SS-trees <ref> [24] </ref>, and SR-trees [16] are designed for supporting fast searching in large multi-dimensional databases. These structures are quite efficient for small dimensions (of the order of 1-10). However, as the data dimensionality increases, the query performance of these structures degrades rapidly. For instance, White and Jain [24] report that as the <p> 9], TV-trees [17], SS-trees <ref> [24] </ref>, and SR-trees [16] are designed for supporting fast searching in large multi-dimensional databases. These structures are quite efficient for small dimensions (of the order of 1-10). However, as the data dimensionality increases, the query performance of these structures degrades rapidly. For instance, White and Jain [24] report that as the dimensionality increases from 5 to 10, the performance of a nearest-neighbor query in multi-dimensional structures such as the SS-tree [24] and the R fl -tree [1], degrades by a factor of 12. <p> However, as the data dimensionality increases, the query performance of these structures degrades rapidly. For instance, White and Jain <ref> [24] </ref> report that as the dimensionality increases from 5 to 10, the performance of a nearest-neighbor query in multi-dimensional structures such as the SS-tree [24] and the R fl -tree [1], degrades by a factor of 12. This phenomenon, appropriately termed the dimensionality curse by Agrawal and Faloutsos [6], is a common characteristic of all multi-dimensional index structures. <p> This phenomenon, appropriately termed the dimensionality curse by Agrawal and Faloutsos [6], is a common characteristic of all multi-dimensional index structures. In spite of the progress in the design and analysis of multi-dimensional structures such as the TV-trees [17], the X-trees [2], the SS-trees <ref> [24] </ref>, and the SR-trees [16], the dimensionality curse persists. The only known solution for achieving scalable query performance is by reducing the dimensionality of the data. Several research initiatives [5, 14, 17, 20, 21] including the QBIC project adopt this approach for supporting image retrieval based on their content. <p> The first k dimensions are chosen since most information is concentrated in these dimensions. The reduced-dimensionality data are then indexed using multi-dimensional index structures such as R fl -trees, SS-trees <ref> [24] </ref>, and SR-trees [16]. Queries are also transformed using the SVD transform matrix and and answered using the reduced-dimensional index structure. To illustrate this with an example, consider the example data of Figure 1. This figure shows five 2-dimensional points. <p> The re-insertion parameter of the SS-tree is set to 30% of the node capacity and the minimum capacity to 40% of the node capacity. These are the same as in other implementations of SS-trees <ref> [24] </ref> and R*-trees [1]. To simulate real-database scenarios, only 25% nodes of an index are cached in memory in all our experiments. The caching strategy is simple and ensured that all the non-leaf nodes are in memory along with first few leaf nodes that are created. <p> The number of such reinserted entries is further limited to 5% of the entries in a subtree. For the Reconstruct scheme, we assumed the tree is reconstructed using an SS-tree <ref> [24] </ref>. In all the experiments, we assumed that only 25% of the index nodes are cached in memory. Scheme Incorporation Query time time (s) (ms, disk I/O) Reconstruct 1363 (27, 154) Reuse 22 (52, 275) Reuse-Reconstruct 42 (30, 160) Table 3. Incorporation and 21-nearest-neighbor query response times for different schemes.
Reference: [25] <author> D. Wu, D. Agrawal, A. El Abbadi, A. Singh, and T. R. Smith. </author> <title> Efficient retrieval for browsing large image databases. </title> <booktitle> Proc. Conf. on Information and Knowledge Management, </booktitle> <pages> pages 1118, </pages> <month> Nov. </month> <year> 1996. </year> <month> 23 </month>
Reference-contexts: In contrast, DFT, DCT, Wavelets and Harr transforms process each individual data point separately. These transforms are used in the context of time series database [6] and highly correlated image databases <ref> [25] </ref>. However, for most data sets, SVD explicitly tries to maximize the variance in the first few dimensions, and therefore, achieves higher precision and recall than other transforms. Figure 3 illustrates this for a database of 144K 256-dimensional color histograms. <p> Next, we describe SVD-transformation scheme in more detail and examine how it is incorporated in static databases. varied for SVD- and DFT-transformed data. Database: 144K color histograms. Original dimen sionality: 256. 1 Alternative choices for dimensions such as the most dominating dimensions (DDFT) <ref> [25] </ref> achieve similar results to those using most varying dimensions. 5 2.2.1 Singular Value Decomposition A set A of n d-dimensional vectors can be transformed using SVD as follows. * Compute the d-by-d SVD-transformation Matrix V.
References-found: 25

