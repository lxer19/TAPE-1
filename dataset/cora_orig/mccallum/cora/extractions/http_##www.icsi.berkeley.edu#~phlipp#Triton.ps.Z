URL: http://www.icsi.berkeley.edu/~phlipp/Triton.ps.Z
Refering-URL: http://www.icsi.berkeley.edu/~phlipp/phlipp.publ.html
Root-URL: http://www.icsi.berkeley.edu
Title: 10 PROJECT TRITON: TOWARDS IMPROVED PROGRAMMABILITY OF PARALLEL COMPUTERS The main objective of Project Triton
Author: Michael Philippsen, Thomas M. Warschko, Walter F. Tichy, Christian G. Herter, Ernst A. Heinz, and Paul Lukowicz 
Keyword: Triton/1 Parallel Architecture.  
Note: Kluwer Academic Publishers, Boston, Dordrecht, London, 1994.  Modula-2*. This language extends Modula-2  Triton/1 is  
Address: Germany  
Affiliation: University of Karlsruhe Department of Informatics  
Abstract: This paper appeard in: David J. Lilja and Peter L. Bird, editors, The Interaction of Compilation Technology and Computer Architecture. The approach taken in the Project Triton is to let high-level, machine independent parallel programming languages drive the design of parallel hardware. This approach permits machine-independent parallel programs to be compiled into efficient machine code. The main results are as follows: Compilation Techniques. We present techniques for the efficient translation of Modula-2* and similar imperative languages for several modern parallel machines and derive recommen dations for future parallel architectures. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Selim G. Akl. </author> <title> The Design and Analysis of Parallel Algorithms. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1989. </year>
Reference-contexts: See [32] for a more detailed critique of 262 Chapter 10 C*. These difficulties in compiler and language design would vanish with a hardware-provided shared address space. 3.3 Benchmark Results Presently, our benchmark suite consists of thirteen problems collected from literature <ref> [1, 6, 8, 9, 16] </ref>. For each problem we implemented the same algorithms in Modula-2*, in sequential C, and in MPL 1 . Then we measured the runtimes of our implementations on a 16K MasPar MP-1 (SIMD) and a SUN-4 (SISD) for widely ranging problem sizes.
Reference: [2] <author> M. Auguin and F. Boeri. </author> <title> The OPSILA computer. </title> <editor> In M. Consard, editor, </editor> <booktitle> Parallel Languages and Architectures, </booktitle> <pages> pages 143-153. </pages> <publisher> Elsevier Science Publishers, Holland, </publisher> <year> 1986. </year>
Reference-contexts: It is even possible to run a subset of the processors in SIMD mode and the other in MIMD. Thus, Triton/1 is truly SAMD, i.e., mixed-mode, not just switched-mode. Only a few research prototypes of mixed-mode machines have been built: OPSILA, TRAC, AP1000, and PASM <ref> [2, 13, 27] </ref>. Triton/1 provides support for switching rapidly between the two modes. With Modula-2* we have a high-level language to control both modes effectively. Fast Barrier Synchronization. Fast barrier synchronization is supported by special synchronization hardware both in SIMD and MIMD mode.
Reference: [3] <author> N. G. De Bruijn. </author> <title> A combinatorial problem. </title> <booktitle> In Proc. of the Sect. of Science Akademie van Wetenschappen, </booktitle> <pages> pages 758-764, </pages> <address> Amsterdam, </address> <month> June 29, </month> <year> 1946. </year>
Reference-contexts: The frontend then releases the request prohibition in order to enable other groups to synchronize. 4.3 Communications Network The Triton/1 network is based on the generalized De Bruijn net <ref> [3, 15] </ref> that can be characterized by the following interconnection rule: assuming all nodes are labeled 0 through N 1, a node with label X has direct connections to the nodes with labels (2 fl X + ff) mod N where ff 2 f0::d 1g.
Reference: [4] <author> Peter Christy. </author> <title> Virtual processors considered harmful. </title> <booktitle> In Proc. of the 6th Distributed Memory Computing Conference, </booktitle> <pages> pages 99-103, </pages> <address> Portland, Oregon, </address> <month> April 28 May 2, </month> <year> 1991. </year>
Reference-contexts: PARALLEL H3 [i] := Y [p (i)] END; FORALL i:[1..N] IN PARALLEL Y [i] := H3 [i] END Although this transformation yields code that can be run on both SIMD and MIMD machines, it is not efficient because of the short virtualization loops that are a problem on SIMD machines <ref> [4] </ref>, and the large number of synchronization messages induced on current MIMD hardware. Our optimization is based on the insight that most of the synchronization barriers introduced by synchronous language constructs need not be implemented in real synchronous FORALLs to ensure the prescribed semantics [11].
Reference: [5] <author> William J. Dally and Charles L. Seitz. </author> <title> Deadlock-free message routing in multiprocessor interconnection networks. </title> <journal> IEEE Transactions on Computers, </journal> <note> C-36(5):547-553, 1987. 278 Chapter 10 </note>
Reference-contexts: A severe disadvantage of De Bruijn networks is that they are not deadlock free. If used as a self-routing packet switching network with a limited buffer size and no possibility of re-arranging the packets in the buffers, deadlock can occur. Dally et al. <ref> [5] </ref> show that a network is deadlock free if its dependency graph is free of cycles. This condition is easy to prove for hypercubes; it does not hold for De Bruijn nets.
Reference: [6] <author> John T. Feo, </author> <title> editor. A Comparative Study of Parallel Programming Languages: The Salishan Problems. </title> <publisher> Elsevier Science Publishers, Holland, </publisher> <year> 1992. </year>
Reference-contexts: See [32] for a more detailed critique of 262 Chapter 10 C*. These difficulties in compiler and language design would vanish with a hardware-provided shared address space. 3.3 Benchmark Results Presently, our benchmark suite consists of thirteen problems collected from literature <ref> [1, 6, 8, 9, 16] </ref>. For each problem we implemented the same algorithms in Modula-2*, in sequential C, and in MPL 1 . Then we measured the runtimes of our implementations on a 16K MasPar MP-1 (SIMD) and a SUN-4 (SISD) for widely ranging problem sizes.
Reference: [7] <author> Geoffrey Fox, Seema Hiranandani, Ken Kennedy, Charles Koelbel, Uli Kre-mer, Chau-Wen Tseng, and Min-You Wu. </author> <title> Fortran D language specification. </title> <type> Technical Report CRPC-TR90079, </type> <institution> Center for Research on Parallel Computation, Rice University, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: Triton/1 overcomes various deficiencies of current parallel machines, supports high-level parallel languages such as Modula-2*, and implements many of our recommendations. 2 MODULA-2* The majority of programming languages for parallel machines, including *LISP, C*, MPL,Fortran 90, Fortran D, HPF, Blaze, Dino, and Kali <ref> [7, 14, 17, 18, 25, 29, 30] </ref>, suffer from some or all of the following problems: Manual Virtualization. The programmer must write explicit code for mapping processes, whose number is problem dependent, onto the available processors, whose number is fixed.
Reference: [8] <author> Alan Gibbons and Wojciech Rytter. </author> <title> Efficient Parallel Algorithms. </title> <publisher> Cam-bridge University Press, </publisher> <year> 1988. </year>
Reference-contexts: See [32] for a more detailed critique of 262 Chapter 10 C*. These difficulties in compiler and language design would vanish with a hardware-provided shared address space. 3.3 Benchmark Results Presently, our benchmark suite consists of thirteen problems collected from literature <ref> [1, 6, 8, 9, 16] </ref>. For each problem we implemented the same algorithms in Modula-2*, in sequential C, and in MPL 1 . Then we measured the runtimes of our implementations on a 16K MasPar MP-1 (SIMD) and a SUN-4 (SISD) for widely ranging problem sizes.
Reference: [9] <author> Philipp J. Hatcher and Michael J. Quinn. </author> <title> Data-Parallel Programming on MIMD Computers. </title> <publisher> MIT Press Cambridge, </publisher> <address> Massachusetts, London, England, </address> <year> 1991. </year>
Reference-contexts: Both are presented in the next two sections. 256 Chapter 10 Elimination of Synchronization Barriers We have developed transformation schemes that map synchronous into (equivalent) asynchronous FORALL statements with temporary variables. These can be implemented on MIMD machines directly. Our transformations are more general than Hatcher's work <ref> [9] </ref> because they also account for nested parallelism and do not rely on having explicit communication instructions in the source program. Consider for example the following synchronous FORALL statement and its inefficient transformation into asynchronous FORALLs shown below. <p> See [32] for a more detailed critique of 262 Chapter 10 C*. These difficulties in compiler and language design would vanish with a hardware-provided shared address space. 3.3 Benchmark Results Presently, our benchmark suite consists of thirteen problems collected from literature <ref> [1, 6, 8, 9, 16] </ref>. For each problem we implemented the same algorithms in Modula-2*, in sequential C, and in MPL 1 . Then we measured the runtimes of our implementations on a 16K MasPar MP-1 (SIMD) and a SUN-4 (SISD) for widely ranging problem sizes.
Reference: [10] <author> Ernst A. Heinz. </author> <title> Modula-3*: An efficiently compilable extension of Modula-3 for explicitly parallel problem-oriented programming. </title> <booktitle> In Joint Symposium on Parallel Processing, </booktitle> <pages> pages 269-276, </pages> <institution> Waseda University, </institution> <address> Tokyo, </address> <month> May 17-19, </month> <year> 1993. </year>
Reference-contexts: Since spring 1992, optimizing Modula-2* compilers for the MasPar MP-1 and sequential machines are available. Modula-2* compilers for the KSR-1 and networks of workstations are under construction. Contact msc@ira.uka.de if interested. Further research will focus on Modula-3* <ref> [10] </ref>, nested and recursive parallelism, as well as other optimizations for latency hiding and parallel expression evaluation. The migration to a new compiler becomes necessary because our current implementation has already reached its limits of extensibility. This also offers the opportunity to move to a new language.
Reference: [11] <author> Ernst A. Heinz and Michael Philippsen. </author> <title> Synchronization barrier elimination in synchronous forall statements. </title> <type> Technical Report No. 13/93, </type> <institution> University of Karlsruhe, Department of Informatics, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: We use Modula-2* [31] as an example language (see section 2); similar extensions could easily be integrated into other imperative programming languages. Optimizing Compilers. We found effective optimization techniques that improve runtime on parallel machines dramatically <ref> [11, 21, 22, 23] </ref>. In general, however, compilation and optimization are severely hampered by current parallel hardware. Our experience with writing compilers for parallel machines has led us to formulate several recommendations for future parallel Project Triton: Programmability of Parallel Computers 251 architectures. <p> Our optimization is based on the insight that most of the synchronization barriers introduced by synchronous language constructs need not be implemented in real synchronous FORALLs to ensure the prescribed semantics <ref> [11] </ref>. To detect redundant synchronization barriers we apply data dependence analysis originally developed for parallelizing Fortran compilers. In the above example there are only three data dependences, one per assignment. After restructuring the program, a single synchronization barrier which cuts all three dependences at once suffices to ensure correctness.
Reference: [12] <author> Christian G. Herter, Thomas M. Warschko, Walter F. Tichy, and Michael Philippsen. Triton/1: </author> <title> A massively-parallel mixed-mode computer designed to support high level languages. </title> <booktitle> In 7th International Parallel Processing Symposium, Proc. of 2nd Workshop on Heterogeneous Processing, </booktitle> <pages> pages 65-70, </pages> <address> Newport Beach, CA, </address> <month> April 13-16, </month> <year> 1993. </year>
Reference-contexts: Optimization techniques, hardware recommendations, and performance results are given in section 3. Parallel Machine Architectures. We explore novel architectural paradigms of parallel computers by building a massively parallel computer called Triton/1 <ref> [12] </ref> that is presented in section 4. Triton/1 is a mixed-mode SIMD/MIMD computer (called SAMD, for "synchronous or asynchronous instruction, multiple data") with a highly efficient communications network.
Reference: [13] <author> Takeshi Horie, Hiroaki Ishihata, Toshiyuki Shimizu, Sadayuki Kato, Satoshi Inano, and Morio Ikesaka. </author> <title> AP1000 architecture and performance of LU decomposition. </title> <booktitle> In Proc. of the 1991 International Conference on Parallel Processing, </booktitle> <volume> volume I, </volume> <pages> pages 634-645, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: It is even possible to run a subset of the processors in SIMD mode and the other in MIMD. Thus, Triton/1 is truly SAMD, i.e., mixed-mode, not just switched-mode. Only a few research prototypes of mixed-mode machines have been built: OPSILA, TRAC, AP1000, and PASM <ref> [2, 13, 27] </ref>. Triton/1 provides support for switching rapidly between the two modes. With Modula-2* we have a high-level language to control both modes effectively. Fast Barrier Synchronization. Fast barrier synchronization is supported by special synchronization hardware both in SIMD and MIMD mode.
Reference: [14] <author> High Performance Fortran (HPF): </author> <title> Language specification. </title> <type> Technical report, </type> <institution> Center for Research on Parallel Computation, Rice University, </institution> <year> 1992. </year>
Reference-contexts: Triton/1 overcomes various deficiencies of current parallel machines, supports high-level parallel languages such as Modula-2*, and implements many of our recommendations. 2 MODULA-2* The majority of programming languages for parallel machines, including *LISP, C*, MPL,Fortran 90, Fortran D, HPF, Blaze, Dino, and Kali <ref> [7, 14, 17, 18, 25, 29, 30] </ref>, suffer from some or all of the following problems: Manual Virtualization. The programmer must write explicit code for mapping processes, whose number is problem dependent, onto the available processors, whose number is fixed.
Reference: [15] <author> Makoto Imase and Masaki Itoh. </author> <title> Design to minimize diameter on building-block network. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-30(6):439-442, </volume> <month> June </month> <year> 1981. </year>
Reference-contexts: The frontend then releases the request prohibition in order to enable other groups to synchronize. 4.3 Communications Network The Triton/1 network is based on the generalized De Bruijn net <ref> [3, 15] </ref> that can be characterized by the following interconnection rule: assuming all nodes are labeled 0 through N 1, a node with label X has direct connections to the nodes with labels (2 fl X + ff) mod N where ff 2 f0::d 1g.
Reference: [16] <author> Joseph JaJa. </author> <title> An Introduction to Parallel Algorithhms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1992. </year> <title> Project Triton: Programmability of Parallel Computers 279 </title>
Reference-contexts: See [32] for a more detailed critique of 262 Chapter 10 C*. These difficulties in compiler and language design would vanish with a hardware-provided shared address space. 3.3 Benchmark Results Presently, our benchmark suite consists of thirteen problems collected from literature <ref> [1, 6, 8, 9, 16] </ref>. For each problem we implemented the same algorithms in Modula-2*, in sequential C, and in MPL 1 . Then we measured the runtimes of our implementations on a 16K MasPar MP-1 (SIMD) and a SUN-4 (SISD) for widely ranging problem sizes.
Reference: [17] <author> MasPar Computer Corporation. </author> <title> MasPar Parallel Application Language (MPL) Reference Manual, </title> <month> September </month> <year> 1990. </year>
Reference-contexts: Triton/1 overcomes various deficiencies of current parallel machines, supports high-level parallel languages such as Modula-2*, and implements many of our recommendations. 2 MODULA-2* The majority of programming languages for parallel machines, including *LISP, C*, MPL,Fortran 90, Fortran D, HPF, Blaze, Dino, and Kali <ref> [7, 14, 17, 18, 25, 29, 30] </ref>, suffer from some or all of the following problems: Manual Virtualization. The programmer must write explicit code for mapping processes, whose number is problem dependent, onto the available processors, whose number is fixed. <p> We use optimized libraries wherever possible. In the following, we first compare the resource consumption of these three program classes. Secondly, we discuss their overall performance. The individual benchmark problems and their performance are presented in [21]. Finally, we show the quantitative effects of the optimization techniques. 1 MPL <ref> [17] </ref> is a data-parallel extension of C designed for the MasPar MP series. In MPL, the number of available processors, the SIMD architecture of the machine, its 2D mesh-connected processor network, and the distributed memory are visible.
Reference: [18] <author> Piyush Mehrotra and John Van Rosendale. </author> <title> The BLAZE language: A parallel language for scientific programming. </title> <journal> Parallel Computing, </journal> <volume> 5 </volume> <pages> 339-361, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: Triton/1 overcomes various deficiencies of current parallel machines, supports high-level parallel languages such as Modula-2*, and implements many of our recommendations. 2 MODULA-2* The majority of programming languages for parallel machines, including *LISP, C*, MPL,Fortran 90, Fortran D, HPF, Blaze, Dino, and Kali <ref> [7, 14, 17, 18, 25, 29, 30] </ref>, suffer from some or all of the following problems: Manual Virtualization. The programmer must write explicit code for mapping processes, whose number is problem dependent, onto the available processors, whose number is fixed.
Reference: [19] <author> David A. Patterson, Garth Gibons, and Randy H. Katz. </author> <title> A case for redundant arrays of inexpensive disks (RIAD). </title> <booktitle> In Proc. of the 1988 ACM-SIGMOD Conference on Management of Data, </booktitle> <pages> pages 109-116, </pages> <address> Chicago, </address> <month> June 1-3, </month> <year> 1988. </year>
Reference-contexts: The reconfiguration involves changing the PE numbers consistently and recomputing the routing tables in the network processors. The 72 disks are logically organized in 8 groups of 9 disks where each group contains 8 data and one parity disk. RAID level 3 <ref> [19] </ref> is used for error handling. The logical organization of Triton/1 is presented in the following diagram: Network PE PE PE PE . . . . . . . . . . .
Reference: [20] <author> Michael Philippsen. </author> <title> Automatic data distribution for nearest neighbor networks. </title> <booktitle> In Frontiers '92:The Fourth Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 178-185, </pages> <address> Mc Lean, Virginia, </address> <month> October 19-21, </month> <year> 1992. </year>
Reference-contexts: Layout is the assignment of aligned data structures and processes to the available processors. Desirable goals are (3) the exploitation of special hardware supported communication patterns and (4) simple address calculations. We use an automatic mapping <ref> [20] </ref> of arbitrary multidimensional arrays to processors. Thus we exploit grid communication if available and achieve efficient address calculations. To understand the techniques and advantages of automatic data and process distribution consider the following example.
Reference: [21] <author> Michael Philippsen, Ernst A. Heinz, and Paul Lukowicz. </author> <title> Compiling machine-independent parallel programs. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 28(8) </volume> <pages> 99-108, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: We use Modula-2* [31] as an example language (see section 2); similar extensions could easily be integrated into other imperative programming languages. Optimizing Compilers. We found effective optimization techniques that improve runtime on parallel machines dramatically <ref> [11, 21, 22, 23] </ref>. In general, however, compilation and optimization are severely hampered by current parallel hardware. Our experience with writing compilers for parallel machines has led us to formulate several recommendations for future parallel Project Triton: Programmability of Parallel Computers 251 architectures. <p> The sequential C programs implement the parallel algorithms on a single processor. We use optimized libraries wherever possible. In the following, we first compare the resource consumption of these three program classes. Secondly, we discuss their overall performance. The individual benchmark problems and their performance are presented in <ref> [21] </ref>. Finally, we show the quantitative effects of the optimization techniques. 1 MPL [17] is a data-parallel extension of C designed for the MasPar MP series. In MPL, the number of available processors, the SIMD architecture of the machine, its 2D mesh-connected processor network, and the distributed memory are visible.
Reference: [22] <author> Michael Philippsen and Markus U. Mock. </author> <title> Data and process alignment in Modula-2*. </title> <editor> In Christoph W. Kessler, editor, </editor> <title> Automatic Parallelization - New Approaches to Code Generation, Data Distribution, </title> <booktitle> and Performance Prediction, </booktitle> <pages> pages 171-191, </pages> <address> AP'93 Saarbrucken, Germany, March 1-3, 1993, 1994. </address> <publisher> Verlag Vieweg, Wiesbaden, </publisher> <address> Germany, </address> <institution> Advanced Studies in Computer Science. </institution>
Reference-contexts: We use Modula-2* [31] as an example language (see section 2); similar extensions could easily be integrated into other imperative programming languages. Optimizing Compilers. We found effective optimization techniques that improve runtime on parallel machines dramatically <ref> [11, 21, 22, 23] </ref>. In general, however, compilation and optimization are severely hampered by current parallel hardware. Our experience with writing compilers for parallel machines has led us to formulate several recommendations for future parallel Project Triton: Programmability of Parallel Computers 251 architectures. <p> Alignment is the task of finding an appropriate trade-off between the two conflicting goals of (1) data locality and (2) maximum degree of parallelism. Our automatic alignment algorithm is described in <ref> [22] </ref> and briefly sketched below by means of an example. Layout is the assignment of aligned data structures and processes to the available processors. Desirable goals are (3) the exploitation of special hardware supported communication patterns and (4) simple address calculations. <p> This results in local accesses that could not be achieved with a single FORALL. Cost estimation is necessary to trade-off the cost of splitting up of FORALLs and the cost of access to non-local data. See <ref> [22] </ref> for more details. Automatic data and process distribution as described here have been implemented in our compiler suite; quantitative results are given in section 3.3.
Reference: [23] <author> Michael Philippsen and Walter F. Tichy. </author> <title> Modula-2* and its compilation. </title> <booktitle> In First International Conference of the Austrian Center for Parallel Computation, </booktitle> <address> Salzburg, Austria, </address> <year> 1991, </year> <pages> pages 169-183. </pages> <publisher> Springer Verlag, Lecture Notes in Computer Science 591, </publisher> <year> 1992. </year>
Reference-contexts: We use Modula-2* [31] as an example language (see section 2); similar extensions could easily be integrated into other imperative programming languages. Optimizing Compilers. We found effective optimization techniques that improve runtime on parallel machines dramatically <ref> [11, 21, 22, 23] </ref>. In general, however, compilation and optimization are severely hampered by current parallel hardware. Our experience with writing compilers for parallel machines has led us to formulate several recommendations for future parallel Project Triton: Programmability of Parallel Computers 251 architectures.
Reference: [24] <author> Lutz Prechelt. </author> <title> Measurements of MasPar MP-1216A communication operations. </title> <type> Technical Report No. 1/93, </type> <institution> University of Karlsruhe, Department of Informatics, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: With some SIMD machines, the ratio of arithmetic operation time to packet delivery time is somewhat better: approximately 1:10 for neighbor communication and 1:40 for random communication <ref> [24] </ref>. But even that is not sufficient: the programmer is still forced to find good mappings of the data structures onto the topology of the network to exploit the faster neighbor communication.
Reference: [25] <author> M. Rosing, R. Schnabel, and R. Weaver. DINO: </author> <title> Summary and example. </title> <booktitle> In Proc. of the Third Conference on Hypercube Concurrent Computers and Applications, </booktitle> <pages> pages 472-481, </pages> <address> Pasadena, CA, 1988. </address> <publisher> ACM Press, </publisher> <address> New York. </address>
Reference-contexts: Triton/1 overcomes various deficiencies of current parallel machines, supports high-level parallel languages such as Modula-2*, and implements many of our recommendations. 2 MODULA-2* The majority of programming languages for parallel machines, including *LISP, C*, MPL,Fortran 90, Fortran D, HPF, Blaze, Dino, and Kali <ref> [7, 14, 17, 18, 25, 29, 30] </ref>, suffer from some or all of the following problems: Manual Virtualization. The programmer must write explicit code for mapping processes, whose number is problem dependent, onto the available processors, whose number is fixed.
Reference: [26] <author> David Sankoff and Joseph B. Kruskal (eds). </author> <title> Time Warps, String Edits, and Macromolecules: The Theory and Practice of Sequence Comparison. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1983. </year> <note> 280 Chapter 10 </note>
Reference-contexts: Although the semantics of Modula-2* prescribe that branching statements create independent groups of threads, it is permissible to combine these groups when they execute the same code. Identical segments in different branches can be found statically by determining the Longest Common Subsequence <ref> [26] </ref> of these branches.
Reference: [27] <author> H.J. Siegel, T. Schwederski, J.T. Kuehn, and N.J. Davis. </author> <title> An overview of the PASM parallel processing system. In D.D. Gajski, </title> <editor> V.M.Milutinovic, H.J.Siegel, and B.P. Furht, editors, </editor> <booktitle> Computer Architecture, </booktitle> <pages> pages 387-407. </pages> <publisher> IEEE Computer Society Press, </publisher> <address> Washington, DC, </address> <year> 1987. </year>
Reference-contexts: It is even possible to run a subset of the processors in SIMD mode and the other in MIMD. Thus, Triton/1 is truly SAMD, i.e., mixed-mode, not just switched-mode. Only a few research prototypes of mixed-mode machines have been built: OPSILA, TRAC, AP1000, and PASM <ref> [2, 13, 27] </ref>. Triton/1 provides support for switching rapidly between the two modes. With Modula-2* we have a high-level language to control both modes effectively. Fast Barrier Synchronization. Fast barrier synchronization is supported by special synchronization hardware both in SIMD and MIMD mode.
Reference: [28] <author> Burton J. Smith. </author> <title> Architecture and applications of the HEP multiprocessor computer system. In Real Time Signal Processing IV, </title> <booktitle> Proceedings of SPIE, </booktitle> <pages> pages 241-248. </pages> <booktitle> International Society for Optical Engineering, </booktitle> <year> 1981. </year>
Reference-contexts: The second method is a static packet insertion rule which prevents overloading of the network. The third method uses de-touring of packets if it detects contention. In case of starvation, we use a routing similar to the one used in Denelcor HEP <ref> [28] </ref> although without explicit packet priorities. The design of our network matches all the network related recommendations of section 3. The MCPS measure approaches the MIPS measure (0:8 MCPS vs. 0:8 MIPS). The network operates independently with asynchronous message delivery.
Reference: [29] <institution> Thinking Machines Corporation, Cambridge, Massachusetts. </institution> <note> *Lisp Reference Manual, Version 5.0, </note> <year> 1988. </year>
Reference-contexts: Triton/1 overcomes various deficiencies of current parallel machines, supports high-level parallel languages such as Modula-2*, and implements many of our recommendations. 2 MODULA-2* The majority of programming languages for parallel machines, including *LISP, C*, MPL,Fortran 90, Fortran D, HPF, Blaze, Dino, and Kali <ref> [7, 14, 17, 18, 25, 29, 30] </ref>, suffer from some or all of the following problems: Manual Virtualization. The programmer must write explicit code for mapping processes, whose number is problem dependent, onto the available processors, whose number is fixed.
Reference: [30] <institution> Thinking Machines Corporation, Cambridge, Massachusetts. </institution> <note> C* Language Reference Manual, </note> <month> April </month> <year> 1991. </year>
Reference-contexts: Triton/1 overcomes various deficiencies of current parallel machines, supports high-level parallel languages such as Modula-2*, and implements many of our recommendations. 2 MODULA-2* The majority of programming languages for parallel machines, including *LISP, C*, MPL,Fortran 90, Fortran D, HPF, Blaze, Dino, and Kali <ref> [7, 14, 17, 18, 25, 29, 30] </ref>, suffer from some or all of the following problems: Manual Virtualization. The programmer must write explicit code for mapping processes, whose number is problem dependent, onto the available processors, whose number is fixed.
Reference: [31] <author> Walter F. Tichy and Christian G. Herter. </author> <title> Modula-2*: An extension of Modula-2 for highly parallel, portable programs. </title> <type> Technical Report No. 4/90, </type> <institution> University of Karlsruhe, Department of Informatics, </institution> <month> January </month> <year> 1990. </year>
Reference-contexts: Triton couples the following sub-projects: Explicitly Parallel Language. We show simple language constructs that (a) avoid shortcomings of known parallel programming languages, (b) express parallel programs in a high-level, problem-oriented way, and (c) can be translated into efficient code for various parallel architectures. We use Modula-2* <ref> [31] </ref> as an example language (see section 2); similar extensions could easily be integrated into other imperative programming languages. Optimizing Compilers. We found effective optimization techniques that improve runtime on parallel machines dramatically [11, 21, 22, 23]. In general, however, compilation and optimization are severely hampered by current parallel hardware. <p> The execution of the entire statement terminates when all processes of all subsets have completed their branches. 254 Chapter 10 The semantics of other synchronous control statements are defined in a similar fashion. See the language definition <ref> [31] </ref> for more details. The synchronous version of our FORALL operates much like the (more recent) HPF FORALL, except that ours is fully orthogonal to the rest of the language. Any statement, including conditionals, loops, other FORALLs, and subroutine calls, may be placed in its body.
Reference: [32] <author> Walter F. Tichy, Michael Philippsen, and Phil Hatcher. </author> <title> A critique of the programming language C*. </title> <journal> Communications of the ACM, </journal> <volume> 35(6) </volume> <pages> 21-24, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: The result is that parallel pointers in old C* are exceedingly complicated to program with. It appears that the same complexities would arise in new C* and were omitted for this reason, resulting in severe non-orthogonalities and restrictions. See <ref> [32] </ref> for a more detailed critique of 262 Chapter 10 C*. These difficulties in compiler and language design would vanish with a hardware-provided shared address space. 3.3 Benchmark Results Presently, our benchmark suite consists of thirteen problems collected from literature [1, 6, 8, 9, 16].
Reference: [33] <author> Reinhard v. Hanxleden and Ken Kennedy. </author> <title> Relaxing SIMD control flow constraints using loop transformations. </title> <type> Technical Report CRPC-TR92207, </type> <institution> Center for Research on Parallel Computation, Rice University, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: Although the semantics of Modula-2* prescribe that branching statements create independent groups of threads, it is permissible to combine these groups when they execute the same code. Identical segments in different branches can be found statically by determining the Longest Common Subsequence [26] of these branches. Hanxleden <ref> [33] </ref> studies branch combining for the special case of parallel loops on SIMD machines. 3.2 Automatic Data and Process Distribution Because of slow and high latency communication networks on distributed memory machines, the distribution, i.e., alignment and layout, of data and processes over the available processors is a central problem.
References-found: 33

