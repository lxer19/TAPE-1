URL: http://www.cs.utexas.edu/users/lorenzo/papers/paralex/runtime.ps
Refering-URL: http://www.cs.utexas.edu/users/lorenzo/publications.html
Root-URL: 
Abstract: CM Run-time Support for Dynamic Load Balancing and Debugging in Paralex Ozalp Babao glu Lorenzo Alvisi Alessandro Amoroso Renzo Davoli Luigi Alberto Giachini Technical Report UBLCS-92-3 September 1992 Laboratory for Computer Science University of Bologna Piazza di Porta S. Donato, 5 40127 Bologna (Italy) 
Abstract-found: 1
Intro-found: 1
Reference: <institution> References </institution>
Reference: [1] <author> W. B. Ackerman. </author> <title> Data Flow Languages. </title> <booktitle> IEEE Computer, </booktitle> <month> February </month> <year> 1982, </year> <pages> pp. 15-22. </pages>
Reference-contexts: These components are integrated within a single programming environment that makes extensive use of graphics. Here we give a brief overview of Paralex. Details can be found in [5]. The programming paradigm supported by Paralex can be classified as static data flow <ref> [1] </ref>. A Paralex program is composed of nodes and links. Nodes correspond to computations (functions, procedures, programs) and the links indicate the flow of (typed) data.
Reference: [2] <author> R. Anand, D. Lea and D. W. Forslund. </author> <title> Using nigen++. </title> <type> Technical Report, </type> <institution> School of Computer and Information Science, Syracuse University, </institution> <month> January </month> <year> 1991. </year>
Reference: [3] <author> D. P. Anderson. </author> <title> The AERO Programmer's Manual. </title> <type> Technical Report, </type> <institution> CS Division, EECS Department, University of California, Berkeley, </institution> <month> October </month> <year> 1990. </year>
Reference: [4] <author> O. Babao glu, L. Alvisi, A. Amoroso and R. Davoli. </author> <title> Mapping Parallel Computations onto Distributed Systems in Paralex. </title> <booktitle> In Proc. IEEE CompEuro '91, </booktitle> <address> Bologna, Italy, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: Since an optimal solution to this problem is computationally intractable, Paralex bases its mapping decisions on simple heuristics described in <ref> [4] </ref>. The units of our mapping decision are chains defined as sequences of nodes that have to be executed sequentially due to data dependence constraints. The initial mapping decisions, as well as modifications during execution, try to keep all nodes of a chain mapped to the same host.
Reference: [5] <author> O. Babao glu, L. Alvisi, S. Amoroso, R. Davoli and L. A. Giachini. </author> <title> Paralex: An Environment for Parallel Programming in Distributed Systems. </title> <booktitle> In Proceedings of the 6th ACM International Conference on Supercomputing, </booktitle> <address> Washington, D.C., </address> <month> July </month> <year> 1992, </year> <pages> 178-187. </pages>
Reference-contexts: These components are integrated within a single programming environment that makes extensive use of graphics. Here we give a brief overview of Paralex. Details can be found in <ref> [5] </ref>. The programming paradigm supported by Paralex can be classified as static data flow [1]. A Paralex program is composed of nodes and links. Nodes correspond to computations (functions, procedures, programs) and the links indicate the flow of (typed) data.
Reference: [6] <author> O. Babao glu, L. Alvisi, A. Amoroso, A. Baronio, R. Davoli and L. A. Giachini. </author> <title> Parallel Scientific Computing in Distributed Systems: The Paralex Approach. </title> <booktitle> In Proceedings of Sixth International Symposium on Computer and Information Sciences, Side, Antalya, Turkey, </booktitle> <month> October </month> <year> 1991, </year> <pages> 1093-1103. </pages>
Reference-contexts: We have used the prototype to program parallel solutions to several important problems drawn from signal processing and thermodynamics application domains. This experience confirms our thesis that significant parallel programs not only can be developed rapidly by non-experts, but can also achieve acceptable performance with respect to speedup <ref> [6] </ref>. After all, the automatic support Paralex provides for rendering parallel programming painless would be of little value if the resulting program failed to match performances possible by hand coding.
Reference: [7] <author> R. G. Babb II. </author> <title> Parallel Processing with Large-Grain Data Flow Techniques. </title> <booktitle> IEEE Computer, </booktitle> <month> July </month> <year> 1984, </year> <pages> pp. 55-61. </pages>
Reference-contexts: Unlike classical data flow, the nodes of a Paralex program carry out significant computations. This so-called large-grain data flow model <ref> [7] </ref> is a consequence of the underlying distributed system architecture where we seek to keep the communication overhead via a high-latency, low-bandwidth network to reasonable levels.
Reference: [8] <author> A. Beguelin, J. J. Dongarra, G. A. Geist, R. Manchek and V. S. Sunderam. </author> <title> Graphical Development Tools for Network-Based Concurrent Supercomputing. </title> <booktitle> In Proc. Supercomputing '91, November 1991, </booktitle> <address> Albuquerque, New Mexico. </address>
Reference: [9] <author> T. Bemmerl, A. Bode, et al. </author> <title> TOPSYS Tools for Parallel Systems. </title> <institution> SFB-Bericht 342/9/90A, Technische Universitat M unchen, Munich, Germany, </institution> <month> January </month> <year> 1990. </year>
Reference: [10] <author> K. Birman and K. Marzullo. </author> <title> ISIS and the META Project. </title> <journal> Sun Technology, </journal> <volume> vol. 2, no. </volume> <month> 3 (Summer </month> <year> 1989), </year> <pages> pp. 90-104. </pages>
Reference: [11] <author> K. Birman, R. Cooper, T. Joseph, K. Marzullo, M. Makpangou, K. Kane, F. Schmuck and M. Wood. </author> <title> The ISIS System Manual, </title> <type> Version 2.1. </type> <institution> Department of Computer Science, Cornell University, </institution> <address> Ithaca, New York, </address> <month> September </month> <year> 1990. </year>
Reference: [12] <author> J. S. Chase, F. G. Amador, E. D. Lazowska, H. M. Levy and R. J. Littlefield. </author> <title> The Amber System: Parallel Programming on a Network of Multiprocessors. </title> <booktitle> In Proc. ACM Symposium on Operating Systems Principles, </booktitle> <address> Litchfield Park, Arizona, </address> <month> December </month> <year> 1989, </year> <pages> pp. 147-158. </pages>
Reference: [13] <author> J. Gait. </author> <title> A Debugger for Concurrent Programs. </title> <journal> Softw. Pract. Exper. </journal> <volume> vol. 15, no. 6, </volume> <year> 1985, </year> <pages> pp. 539-554. </pages>
Reference-contexts: The main reasons for this are the following: * Global Nondeterminism: Behavior of a program depends not only on the values of its inputs but also on the interaction with other processes. * Probe Effect: The debugger itself might interfere with the program and change its behavior <ref> [13] </ref>. When concurrent execution takes place in a distributed system, the debugging task becomes even more difficult. Additional issues that need to be addressed include random UBLCS-92-3 8 6 Debugging in Paralex communication delays, lack of instantaneous global state information [16], processor failures and lost messages.
Reference: [14] <author> A. S. Grimshaw. </author> <title> An Introduction to Parallel Object-Oriented Programming with Men-tat. </title> <type> Technical Report No. </type> <institution> TR-91-07, Department of Computer Science, University of Virginia, </institution> <month> April </month> <year> 1991. </year>
Reference: [15] <author> W. Hong Cheung, J. P. Black and E. Manning. </author> <title> A Framework for Distributed Debugging. </title> <journal> IEEE Software, </journal> <month> January </month> <year> 1990, </year> <pages> pp. 106-115. </pages>
Reference: [16] <author> K. M. Chandy and L. Lamport. </author> <title> Distributed Snapshots: Determining Global States in a Distributed System. </title> <journal> ACM Transaction on Computer Systems, </journal> <volume> vol. 3, no. 1, </volume> <month> February </month> <year> 1985, </year> <pages> pp. 63-75. </pages>
Reference-contexts: When concurrent execution takes place in a distributed system, the debugging task becomes even more difficult. Additional issues that need to be addressed include random UBLCS-92-3 8 6 Debugging in Paralex communication delays, lack of instantaneous global state information <ref> [16] </ref>, processor failures and lost messages. Our strategy in Paralex has been to select the programming abstractions and the automated support mechanisms in such a manner that most of the above concerns become non-issues.
Reference: [17] <author> C. Mcdowell and D.P. Helmbold. </author> <title> Debugging Concurrent Programs. </title> <journal> ACM Computing Surveys, </journal> <volume> vol. 21, no. 4, </volume> <month> December </month> <year> 1989, </year> <pages> pp. 593-623. </pages>
Reference: [18] <author> G. L. Steele Jr. </author> <title> Making Asynchronous Parallelism Safe for the World. </title> <booktitle> In. Proc. 17th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <year> 1990, </year> <pages> pp. 218-231. </pages> <address> UBLCS-92-3 12 </address>
Reference-contexts: This in turn facilitates reusability of existing sequential programs as building blocks UBLCS-92-3 3 2 Overview of Paralex for distributed parallel programs. We also note that this programming paradigm is in the spirit of that proposed by Steele <ref> [18] </ref> where a severely-restricted programming paradigm is advocated even for environments that support arbitrary asynchrony. Paralex programs are composed through an X-windows based graphics editor using nodes, filters and links as building blocks. Computations for the nodes and filters are specified through property panels.
References-found: 19

