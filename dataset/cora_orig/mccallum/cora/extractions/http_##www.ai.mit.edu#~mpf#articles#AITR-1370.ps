URL: http://www.ai.mit.edu/~mpf/articles/AITR-1370.ps
Refering-URL: 
Root-URL: 
Email: (email: vijayb@ai.mit.edu)  
Title: Equivalence and Reduction of Hidden Markov Models  
Author: Vijay Balasubramanian 
Note: Copyright c Massachusetts Institute of Technology, 1993  
Date: 1370 January, 1993  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY  
Pubnum: A.I. Technical Report No.  
Abstract: This report describes research done at the Artificial Intelligence Laboratory of the Massachusetts Institute of Technology. Support for the laboratory's artificial intelligence research is provided in part by the Advanced Research Projects Agency of the Department of Defense under Office of Naval Research contract N00014-91-J-4038. 
Abstract-found: 1
Intro-found: 1
Reference: [bahl88] <author> L.R.Bahl, P.F.Brown, P.V. de Souza, R.L.Mercer and M.A.Picheny, </author> <title> Acoustic Markov Models Used In The Tangora Speech Recognition System </title>
Reference: [bodreau68] <author> P.E.Bodreau, </author> <title> Functions of Finite Markov Chains and Exponential Type Processes, </title> <journal> Annals of Mathematical Statistics, Vol.39, No.3, </journal> <volume> pp.1020-1029, </volume> <year> 1968. </year>
Reference-contexts: Gilbert, in 1959, provided a more general, but still partial, answer to this question of "identifiability" of deterministic functions of Markov Chains.[gilbert59] The topic was studied further by several authors who elucidated various aspects of the problem. ([burke58], [dharma63a], [dharma63b], [dharma68], <ref> [bodreau68] </ref>, [rosenblatt71]) Functions of Markov Chains were also studied under the rubric "Grouped Markov Chains", and necessary and sufficient conditions were established for equivalence of a Grouped Chain to a traditional Markov Chain.([kemeney65], [iosifescu80]) Interest in functions of Markov Chains, and particularly, probabilistic functions of Markov Chains, has been revived recently
Reference: [burke58] <author> C.J.Burke and M.Rosenblatt, </author> <title> A Markovian Function of A Markov Chain, </title> <journal> Annals of Mathematical Statistics, </journal> <year> 1958. </year>
Reference: [chvatal80] <author> V.Chvatal, </author> <title> Linear Programming, </title> <publisher> W.H.Freeman and Company, </publisher> <address> New York, </address> <year> 1980. </year>
Reference: [dharma63a] <author> S.W.Dharmadhikari, </author> <title> Functions of Finite Markov Chains, </title> <journal> Annals of Mathematical Statistics, Vol.34, </journal> <volume> pp.1022-1032, </volume> <year> 1963. </year>
Reference-contexts: Gilbert, in 1959, provided a more general, but still partial, answer to this question of "identifiability" of deterministic functions of Markov Chains.[gilbert59] The topic was studied further by several authors who elucidated various aspects of the problem. ([burke58], <ref> [dharma63a] </ref>, [dharma63b], [dharma68], [bodreau68], [rosenblatt71]) Functions of Markov Chains were also studied under the rubric "Grouped Markov Chains", and necessary and sufficient conditions were established for equivalence of a Grouped Chain to a traditional Markov Chain.([kemeney65], [iosifescu80]) Interest in functions of Markov Chains, and particularly, probabilistic functions of Markov Chains, has
Reference: [dharma63b] <author> S.W.Dharmadhikari, </author> <title> Sufficient Conditions For A Stationary Process To Be A Function Of A Finite State Markov Chain, </title> <journal> Annalas of Mathematical Statistics, </journal> <volume> Vol.34, </volume> <year> 1963. </year>
Reference-contexts: Gilbert, in 1959, provided a more general, but still partial, answer to this question of "identifiability" of deterministic functions of Markov Chains.[gilbert59] The topic was studied further by several authors who elucidated various aspects of the problem. ([burke58], [dharma63a], <ref> [dharma63b] </ref>, [dharma68], [bodreau68], [rosenblatt71]) Functions of Markov Chains were also studied under the rubric "Grouped Markov Chains", and necessary and sufficient conditions were established for equivalence of a Grouped Chain to a traditional Markov Chain.([kemeney65], [iosifescu80]) Interest in functions of Markov Chains, and particularly, probabilistic functions of Markov Chains, has been
Reference: [dharma68] <author> S.W.Dharmadhikari, </author> <title> SPlitting A Single State Of A Stationary Process Into Markovian States, </title> <journal> Annals of Mathematical Statistics, </journal> <note> Vol.38, No.3, pp.1069-1077, 1968. 86 BIBLIOGRAPHY </note>
Reference-contexts: Gilbert, in 1959, provided a more general, but still partial, answer to this question of "identifiability" of deterministic functions of Markov Chains.[gilbert59] The topic was studied further by several authors who elucidated various aspects of the problem. ([burke58], [dharma63a], [dharma63b], <ref> [dharma68] </ref>, [bodreau68], [rosenblatt71]) Functions of Markov Chains were also studied under the rubric "Grouped Markov Chains", and necessary and sufficient conditions were established for equivalence of a Grouped Chain to a traditional Markov Chain.([kemeney65], [iosifescu80]) Interest in functions of Markov Chains, and particularly, probabilistic functions of Markov Chains, has been revived
Reference: [blackwell57] <author> D.Blackwell and L.Koopmans, </author> <title> On The Identifiability Problem for Functions of Finite Markov Chains, </title> <journal> Annals of Mathematical Statistics, Vol.28, </journal> <volume> pp.1011-1015, </volume> <year> 1957. </year>
Reference: [gilbert59] <author> E.Gilbert, </author> <title> On The Identifiability Problem For Functions of Finite Markov Chains, </title> <journal> Annals of Mathematical Statistics, Vol.30, </journal> <volume> pp.688-697, </volume> <year> 1959. </year>
Reference: [iosifescu80] <author> M.Iosifescu, </author> <title> Finite Markov Processes and Their Applications, </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1980. </year>
Reference-contexts: was studied further by several authors who elucidated various aspects of the problem. ([burke58], [dharma63a], [dharma63b], [dharma68], [bodreau68], [rosenblatt71]) Functions of Markov Chains were also studied under the rubric "Grouped Markov Chains", and necessary and sufficient conditions were established for equivalence of a Grouped Chain to a traditional Markov Chain.([kemeney65], <ref> [iosifescu80] </ref>) Interest in functions of Markov Chains, and particularly, probabilistic functions of Markov Chains, has been revived recently because of their successful applications in speech recognition.
Reference: [ito92] <author> H.Ito, S.Amari and K.Kobayashi, </author> <title> Identifiability of Hidden Markov Information Sources and Their Minimum Degrees of Freedom, </title> <journal> IEEE Transactions on Information Theory, Vol.38, No.2, </journal> <month> March </month> <year> 1992. </year>
Reference: [juang91] <author> B.H. Juang and L.R.Rabiner, </author> <title> Hidden Markov Models for Speech Recognition, </title> <journal> Technometrics, Vol.33, </journal> <volume> No.3, </volume> <month> August </month> <year> 1991. </year>
Reference: [kamp85] <author> Y.Kamp, </author> <title> State Reduction in Hidden Markov Chains Used for Speech Recognition, </title> <journal> IEEE Transactions of Acoustics, Speech and Signal Processing, Vol.ASSP-33, </journal> <volume> No.4, </volume> <month> October </month> <year> 1985. </year>
Reference: [karmarkar84] <author> N.Karmarkar, </author> <title> A New Polynomial Time Algorithm For Linear Programming, </title> <journal> Combinatorica, Vol.4, No.4, </journal> <volume> pp.373-395, </volume> <year> 1984. </year>
Reference: [kemeney65] <author> J.G.Kemeney and J.L.Snell, </author> <title> Finite Markov Chains, </title> <publisher> D.Van Nostrand Company Inc., </publisher> <address> Princeton, New Jersey, </address> <year> 1965. </year>
Reference: [kopec91] <author> G.E.Kopec and P.A.Chou, </author> <title> Document Image Decoding Using Markov Sources, </title> <journal> submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <year> 1992. </year>
Reference-contexts: For example, experiments in speech recognition have shown that HMMs can be useful tools in modelling the variability of human speech.([juang91],[lee88],[rabiner86],[bahl88]) Hidden Markov Models have also been used in computational linguistics [kupiec90], in document recognition <ref> [kopec91] </ref> and in such situations where intrinsic statistical variability in data must be accounted for in order to perform pattern recognition. HMMs are constructed by considering stochastic processes that are probabilistic functions of Markov Chains.
Reference: [kupiec90] <author> J.Kupiec, </author> <title> Part-of-Speech Tagging Using a Hidden Markov Model, </title> <institution> Xe-rox PARC System Sciences Lab Tech. </institution> <note> Report No. SSL-90-39, 1990. BIBLIOGRAPHY 87 </note>
Reference-contexts: For example, experiments in speech recognition have shown that HMMs can be useful tools in modelling the variability of human speech.([juang91],[lee88],[rabiner86],[bahl88]) Hidden Markov Models have also been used in computational linguistics <ref> [kupiec90] </ref>, in document recognition [kopec91] and in such situations where intrinsic statistical variability in data must be accounted for in order to perform pattern recognition. HMMs are constructed by considering stochastic processes that are probabilistic functions of Markov Chains.
Reference: [lee88] <author> Kai-Fu Lee, </author> <title> Large-Vocabulary Speaker Independent Continuous Speech Recognition: The SPHINX System, </title> <institution> Carneige-Mellon University Computer Science Department, </institution> <type> PhD Thesis, </type> <year> 1988. </year>
Reference: [levinson83] <author> S.E.Levinson, L.R.Rabiner and M.M.Sondhi. </author> <title> An Introduction to the Application of the Theory of Probabilistic Functions of a Markov Process to Automatic Speech Recognition, </title> <journal> The Bell System Technical Jounal, Vol.62, </journal> <volume> No.4, </volume> <month> April </month> <year> 1983. </year>
Reference: [niles90] <author> L.T.Niles, </author> <title> Modelling and Learning in Speech Recognition: The Relationship Between Stochastic Pattern Classifiers and Neural Networks, </title> <type> Technical Report LEMS-79, </type> <institution> Brown University, </institution> <month> August </month> <year> 1990. </year>
Reference-contexts: GENERALIZED MARKOV MODELS 45 manner. This thesis initially arose from an attempt to understand the properties of HMMs sufficiently well to facilitate comparison with other classification schemes. The Generalized Markov Models we will define in this chapter are a natural generalization of HMMs which follow the empirical lead in <ref> [niles90] </ref> suggesting that "negative parameters" may be a good idea. We are able to describe, in detail, the conections between GMMs and HMMs. Theoretical Reasons: We are also motivated to define Generalized Markov Models from a theoretical perspective. <p> Nonetheless, there are some options that come to mind immediately. First of all, we could use corrective training methods, such as gradient descent to minimize a squared error measure. ( Niles <ref> [niles90] </ref> suggests such a procedure in the context of his HMM-net.) Furthermore, despite their exotic underlying chains, GMMs still define true probability distributions on their output sequences.
Reference: [paz71] <author> A.Paz, </author> <title> Introduction to Probabilistic Automata, </title> <publisher> Aacademic Press, </publisher> <address> Lon-don, </address> <year> 1971. </year>
Reference-contexts: There has also been some recent work in the theory of Probabilistic Automata (PA) which uses methods similar to ours to study equivalence of PAs.[tzeng] Tzeng cites the work of Azaria Paz <ref> [paz71] </ref> and others as achieving the previous best results for testing equivalence of Probabilistic Automata. 2 Appendix A will define Probabilistic Automata and discuss their connections with HMMs.
Reference: [poggio89] <author> Tomaso Poggio and Federico Girosi, </author> <title> A Theory of Networks for Approximation and Learning, </title> <booktitle> Artificial Intelligence Laboratory, </booktitle> <publisher> M.I.T., </publisher> <address> A.I.Memo No.1140, </address> <month> July </month> <year> 1989 </year>
Reference-contexts: The literature also frequently uses models with continuously varying observables. These are easily defined by replacing the "ouput matrix" B by continuous output densities. HMMs with Gaussian output densities are related to the Radial Basis Functions of <ref> [poggio89] </ref>. 5 Some authors also designate "absorbing states" which, when entered, cause the model to terminate production of a string. 4 This is analogous to the equivalence of Moore and Mealy Finite State Machines 5 Suppose M is a Hidden Markov Model with states S = fs 1 ; s 2
Reference: [press90] <author> W.H.Press, B.P.Flannery, S.A.Teukolsky, and W.T.Vetterling, </author> <title> Numerical Recipes in C, </title> <publisher> Cambridge University Press, </publisher> <address> New York, </address> <year> 1990. </year>
Reference: [rabiner86] <author> L.R.Rabiner and B.H.Juang, </author> <title> An Introduction to Hidden Markov Models, </title> <journal> IEEE ASSP Magazine, </journal> <volume> pp.4-16, </volume> <month> January </month> <year> 1986. </year>
Reference: [rosenblatt71] <author> M.Rosenblatt, </author> <title> Markov Processes Structure and Asymptotic Be-haviour, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1971. </year>
Reference-contexts: Gilbert, in 1959, provided a more general, but still partial, answer to this question of "identifiability" of deterministic functions of Markov Chains.[gilbert59] The topic was studied further by several authors who elucidated various aspects of the problem. ([burke58], [dharma63a], [dharma63b], [dharma68], [bodreau68], <ref> [rosenblatt71] </ref>) Functions of Markov Chains were also studied under the rubric "Grouped Markov Chains", and necessary and sufficient conditions were established for equivalence of a Grouped Chain to a traditional Markov Chain.([kemeney65], [iosifescu80]) Interest in functions of Markov Chains, and particularly, probabilistic functions of Markov Chains, has been revived recently because
Reference: [tzeng] <author> W.Tzeng, </author> <title> A Polynomial Time Algorithm for the Equivalence of Probabilistic Automata, </title> <journal> SIAM Journal on Computing, </journal> <note> to appear. </note>
References-found: 26

