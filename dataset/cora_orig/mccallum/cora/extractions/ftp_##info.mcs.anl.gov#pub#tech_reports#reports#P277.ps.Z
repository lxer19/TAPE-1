URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P277.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts94.htm
Root-URL: http://www.mcs.anl.gov
Title: SCALABLE ITERATIVE SOLUTION OF SPARSE LINEAR SYSTEMS  
Phone: 60439  
Author: Mark T. Jones and Paul E. Plassmann 
Keyword: Key words: conjugate gradient methods, distributed-memory computers, graph coloring heuristics, incomplete Cholesky, parallel algorithms, sparse matrices  
Note: AMS(MOS) subject classifications: 65F10, 65F50, 65Y05, 68Q22 This work was supported by the Applied Mathematical Sciences subprogram of the Office of Energy Research, U.S. Department of Energy, under Contract W-31-109-Eng-38.  
Date: November 1991  
Address: 9700 South Cass Avenue Argonne, Illinois  Preprint MCS-P277-1191  
Affiliation: ARGONNE NATIONAL LABORATORY  Mathematics and Computer Science Division  
Abstract: The efficiency of a parallel implementation of the conjugate gradient method preconditioned by an incomplete Cholesky factorization can vary dramatically depending on the column ordering chosen. One method to minimize the number of major parallel steps is to choose an ordering based on a coloring of the symmetric graph representing the nonzero adjacency structure of the matrix. In this paper, we compare the performance of the preconditioned conjugate gradient method using these coloring orderings with a number of standard orderings on matrices arising from finite element models. Because optimal colorings for these systems may not be known a priori, we employ a graph coloring heuristic to obtain consistent colorings. Based on lower bounds obtained from the local structure of these systems, we find that the colorings determined by the heuristic are nearly optimal. For these problems, we find that the increase in parallelism afforded by the coloring-based orderings more than offsets any increase in the number of iterations required for the convergence of the conjugate gradient algorithm. We give results from the Intel iPSC/860 to support our claims. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. </author> <title> Bollob as, Graph Theory, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: In our demonstration of scalability, we have not chosen this approach. It is known that an optimal coloring can be obtained via a greedy heuristic if the vertices are visited in the correct order <ref> [1] </ref>. The basic structure of the greedy heuristic is the following. Greedy Heuristic. Compute a vertex ordering fv 1 ; : : : ; v n g for V . <p> For i = 1; : : : ; n, set oe (v i ) equal to the smallest available consistent color. The maximum degree of the graph determines an upper bound for the chromatic number <ref> [1] </ref>. Let (G) = max v2V deg (v), where deg (v) is the degree of vertex v in G. This upper bound is given by O (G) (G) + 1. Note that a greedy heuristic will always satisfy this bound.
Reference: [2] <author> D. Br elaz, </author> <title> New methods to color the vertices of a graph, </title> <journal> Comm. ACM, </journal> <volume> 22 (1979), </volume> <pages> pp. 251-256. 17 </pages>
Reference-contexts: Several strategies for obtaining this vertex 3 ordering have been proposed in work by other authors. Two of the most effective and efficient strategies proposed are orderings of the vertices by saturation degree and by incidence degree. The saturation degree ordering (SDO) heuristic was first proposed by Brelaz <ref> [2] </ref> and is defined as follows. Suppose that vertices v 1 ; : : : ; v i1 have been chosen.
Reference: [3] <author> T. F. Chan and H. C. Elman, </author> <title> Fourier analysis of iterative methods for elliptic boundary value problems, </title> <journal> SIAM Review, </journal> <volume> 31 (1989), </volume> <pages> pp. 20-49. </pages>
Reference-contexts: It is interesting to note that the number of iterations in each problem grows as predicted in <ref> [3] </ref>: linearly with the relative refinement. In the PLATE problem, when the problem size quadruples, the relative refinement doubles in the X and Y directions, and the number of iterations doubles.
Reference: [4] <author> T. F. Coleman and J. J. Mor e, </author> <title> Estimation of sparse Jacobian matrices and graph coloring problems, </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 20 (1983), </volume> <pages> pp. 187-209. </pages>
Reference-contexts: The SDO heuristic can be implemented to run in time proportional to P A modification of the SDO heuristic, the incidence degree ordering (IDO) heuristic, was suggested by Coleman and More in their work <ref> [4] </ref> on using coloring heuristics to obtain consistent partitions for use in Jacobian estimation. Again suppose that vertices v 1 ; : : : ; v i1 have been chosen. <p> The IDO heuristic has the desirable property that it can be implemented to run in a time proportional to v2V deg (v), or the number of nonzeros in the matrix. This heuristic was found by Coleman and More <ref> [4] </ref> to obtain the best colorings, for a linear time heuristic, over a wide variety of problems. The computational cost of these graph coloring heuristics is modest compared to the time required to compute the incomplete factors and repeatedly solve the resulting triangular systems.
Reference: [5] <author> I. S. Duff and G. A. Meurant, </author> <title> The effect of ordering on preconditioned conjugate gradients, </title> <journal> BIT, </journal> <volume> 29 (1989), </volume> <pages> pp. 635-657. </pages>
Reference-contexts: 1. Introduction. The preconditioned conjugate gradient method [13] is one of the most successful iterative methods for solving large, sparse, symmetric, positive-definite linear systems. A preconditioner that has been shown to be very effective for a wide variety of problems is the incomplete Cholesky factorization [18]. Recently, several authors <ref> [5, 7, 20, 22] </ref> have examined the effect of multicoloring based matrix orderings on the convergence properties of iterative methods. However, this work has considered only problems generated from regular grids, for which an optimal coloring is known a priori. <p> The reverse Cuthill-McKee (RCM) heuristic has been shown in numerous tests to be the best, or nearly the best, ordering for the convergence of the ICCG (0) algorithm <ref> [5] </ref>. The nested dissection heuristic has been shown to be effective when reordering a matrix to both reduce fill-in and increase the parallelism of a direct, sparse factorization. <p> A comparison of the colorings obtained by the IDO heuristic on problems from the test suite compared with the upper and lower bounds on the chromatic number for these problems 11 nested dissection heuristic was often near optimal <ref> [5] </ref>. The minimum degree ordering is the most commonly used fill reducing algorithm for direct sparse factorization; it is generally far from optimal in terms of convergence of ICCG (0) [5]. A good description of these heuristics can be found in [9]. <p> the upper and lower bounds on the chromatic number for these problems 11 nested dissection heuristic was often near optimal <ref> [5] </ref>. The minimum degree ordering is the most commonly used fill reducing algorithm for direct sparse factorization; it is generally far from optimal in terms of convergence of ICCG (0) [5]. A good description of these heuristics can be found in [9]. The objective in this section is to show that a good coloring heuristic, in combination with incomplete factorization, is a scalable algorithm whose parallel performance is superior to that of standard orderings. <p> This partitioning reduces the number and volume of messages that must be sent. The effect of orderings on the convergence ICCG must be taken into account <ref> [5] </ref>. For model grid problems, Elman and Agron [7] used a parameter study of a theoretical computational model to show that the cost of increased iterations needed for multicoloring was usually worth the benefit of increased parallelism. In our experiments we examine this benefit on the Intel iPSC/860. <p> In Figures 4 and 5 we give the number of iterations for both problems using all four orderings. For the PLATE problem, which is geometrically similar to a model grid problem, the iteration counts for each of the orderings are close to what we expect from <ref> [5] </ref>, with the exception of the iteration count for nested dissection which is higher than might be expected. This increase could result from an inability of the nested dissection heuristic to determine a good ordering because of the three-dimensional nature of this problem. <p> An examination of Figure 5 reveals that for the BUILDING problem, which is far from a model grid problem, the iteration counts are not similar to those from <ref> [5] </ref>.
Reference: [6] <author> T. H. Dunigan, </author> <title> Performance of the Intel iPSC/860 Hypercube, </title> <type> ORNL/TM 11491, </type> <institution> Oak Ridge National Laboratory, </institution> <year> 1990. </year>
Reference-contexts: The ordering of the matrix has a significant effect on the height of the DAG; depending on the ordering, the height could be as large as n or as small as the chromatic number. On all currently available message-passing computers, ff is significantly larger than o and fi <ref> [6] </ref>. Thus, the message volume contribution to the model is of secondary importance because of the relative sizes of ff and fi, and because, as we show below in Theorem 3.1, the message volume cannot vary greatly between orderings.
Reference: [7] <author> H. C. Elman and E. </author> <title> Agr on, Ordering techniques for the preconditioned conjugate gradient method on parallel computers, </title> <journal> Computer Physics Communications, </journal> <volume> 53 (1989), </volume> <pages> pp. 253-269. </pages>
Reference-contexts: 1. Introduction. The preconditioned conjugate gradient method [13] is one of the most successful iterative methods for solving large, sparse, symmetric, positive-definite linear systems. A preconditioner that has been shown to be very effective for a wide variety of problems is the incomplete Cholesky factorization [18]. Recently, several authors <ref> [5, 7, 20, 22] </ref> have examined the effect of multicoloring based matrix orderings on the convergence properties of iterative methods. However, this work has considered only problems generated from regular grids, for which an optimal coloring is known a priori. <p> This partitioning reduces the number and volume of messages that must be sent. The effect of orderings on the convergence ICCG must be taken into account [5]. For model grid problems, Elman and Agron <ref> [7] </ref> used a parameter study of a theoretical computational model to show that the cost of increased iterations needed for multicoloring was usually worth the benefit of increased parallelism. In our experiments we examine this benefit on the Intel iPSC/860.
Reference: [8] <author> M. R. Garey and D. S. Johnson, </author> <title> Computers and Intractability, </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: In this paper, we consider sparse linear systems that arise both from finite element models and standard grid problems. For many of the former problems, optimal mul-ticolorings are not known. In general, the determination of an optimal coloring is an NP-hard problem <ref> [8] </ref>. Thus, we have explored the use of graph coloring heuristics to obtain the desired orderings. Our experimental results show that the combination of incomplete factorization and coloring heuristics results in a parallel preconditioner that is applicable to the symmetric, positive-definite matrices arising in many applications. <p> The minimum possible value for s is known as the chromatic number of G (A), which we denote as O (G). The question of whether a general graph G (A) is s-colorable is NP-complete <ref> [8] </ref>. It is known that unless P = N P , there does not exist a polynomial approximation scheme for solving the graph coloring problem [8]. <p> The question of whether a general graph G (A) is s-colorable is NP-complete <ref> [8] </ref>. It is known that unless P = N P , there does not exist a polynomial approximation scheme for solving the graph coloring problem [8]. In fact, the best polynomial time heuristic known [14] can theoretically guarantee a coloring of only size c (n= log n) O (G), where 1 With a consistently ordered matrix, it is straightforward to determine the optimal relaxation parameter [12]. 2 c is some constant.
Reference: [9] <author> A. George and J. W.-H. Liu, </author> <title> Computer Solution of Large Sparse Positive Definite Systems, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1981. </year>
Reference-contexts: In this paper we compare the orderings produced by the IDO heuristic with three other standard orderings: minimum degree (MDO), nested dissection (NDO), and the reverse Cuthill-McKee ordering (RCM) <ref> [9] </ref>. If the problem partition on each processor is similar in structure, then the second assumption holds for the minimum degree ordering and the incidence degree ordering, because they are locally generated orderings that impose no global structure on the matrix. <p> The minimum degree ordering is the most commonly used fill reducing algorithm for direct sparse factorization; it is generally far from optimal in terms of convergence of ICCG (0) [5]. A good description of these heuristics can be found in <ref> [9] </ref>. The objective in this section is to show that a good coloring heuristic, in combination with incomplete factorization, is a scalable algorithm whose parallel performance is superior to that of standard orderings.
Reference: [10] <author> G. H. Golub and C. F. V. Loan, </author> <title> Matrix Computations, </title> <publisher> The Johns Hopkins University Press, </publisher> <address> Baltimore, </address> <year> 1983. </year>
Reference-contexts: Finally, a significant pitfall for the straightforward incomplete factorization algorithm is that it may fail to produce a positive-definite factorization, even though the matrix is positive definite. Because positive definiteness is required for the conjugate gradient method <ref> [10] </ref>, some mechanism must be included to deal with the detection of indefiniteness during the incomplete factorization process.
Reference: [11] <author> J. L. Gustafson, G. R. Montry, and R. E. Benner, </author> <title> Development of parallel methods for a 1024-processor hypercube, </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 9 (1988), </volume> <pages> pp. 609-638. </pages>
Reference-contexts: Thus, in our current implementation, we allow only the solution of diagonal systems between communication steps. The combination of graph coloring and incomplete factorization gives a parallel algorithm that is scalable as defined in <ref> [11] </ref>. In general, for graphs arising from physical models, the maximum degree of any node is bounded independently from the number of nodes. Because the number of colors is bounded by the maximum degree of a node, the number of parallel steps is also bounded independently from the problem size. <p> Specifically, we show two results: (1) for the problems considered, the parallel efficiency and the total solution time for the multi-coloring incomplete factorization approach is superior to other orderings, even though this ordering can have deleterious effects on convergence, and (2) the multicoloring algorithm is scalable as defined in <ref> [11] </ref>. To carry out our experiments, we selected the last two problems from Table 1, which could be scaled in size. Because of space considerations, we do not in every case present results for both problems, but generally the results are similar.
Reference: [12] <author> L. A. Hageman and D. M. Young, </author> <title> Applied Iterative Methods, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: In fact, the best polynomial time heuristic known [14] can theoretically guarantee a coloring of only size c (n= log n) O (G), where 1 With a consistently ordered matrix, it is straightforward to determine the optimal relaxation parameter <ref> [12] </ref>. 2 c is some constant. It is therefore rather surprising that a coloring heuristic could perform well in practice.
Reference: [13] <author> M. R. Hestenes and E. </author> <title> Stiefel, Methods of conjugate gradients for solving linear systems, </title> <journal> Journal of Research of the National Bureau of Standards, </journal> <volume> 49 (1952), </volume> <pages> pp. 409-436. </pages>
Reference-contexts: 1. Introduction. The preconditioned conjugate gradient method <ref> [13] </ref> is one of the most successful iterative methods for solving large, sparse, symmetric, positive-definite linear systems. A preconditioner that has been shown to be very effective for a wide variety of problems is the incomplete Cholesky factorization [18].
Reference: [14] <author> D. S. Johnson, </author> <title> Worst case behavior of graph coloring algorithms, </title> <booktitle> in Proceedings 5th Southeastern Conference on Combinatorics, Graph Theory, and Computing, </booktitle> <publisher> Utilitas Mathematica Publishing, </publisher> <address> Winnipeg, </address> <year> 1974, </year> <pages> pp. 513-527. </pages>
Reference-contexts: The question of whether a general graph G (A) is s-colorable is NP-complete [8]. It is known that unless P = N P , there does not exist a polynomial approximation scheme for solving the graph coloring problem [8]. In fact, the best polynomial time heuristic known <ref> [14] </ref> can theoretically guarantee a coloring of only size c (n= log n) O (G), where 1 With a consistently ordered matrix, it is straightforward to determine the optimal relaxation parameter [12]. 2 c is some constant.
Reference: [15] <author> M. T. Jones and P. E. Plassmann, </author> <title> Parallel iterative solution of sparse systems using order-ings from graph coloring heuristics, </title> <type> Preprint MCS-P198-1290, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <year> 1990. </year> <title> [16] , A parallel graph coloring heuristic, </title> <type> Preprint MCS-P246-0691, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <year> 1991. </year>
Reference-contexts: This discrepancy has been observed in other "non-model" problems; however, in general we find that the RCM and nested dissection orderings are superior to the coloring and minimum degree orderings in terms of convergence <ref> [15] </ref>. It is interesting to note that the number of iterations in each problem grows as predicted in [3]: linearly with the relative refinement. In the PLATE problem, when the problem size quadruples, the relative refinement doubles in the X and Y directions, and the number of iterations doubles. <p> Lastly, we note several topics possibly requiring additional study. The coloring produced by the heuristic may often leave a single color with very few nodes. One solution to this problem is to remove from the graph the constraining edges associated with those nodes <ref> [15] </ref> and use this smaller graph as the structure for the triangular system. However, a better approach would be an algorithm that could try to recolor a subset of the nodes to eliminate this problem.
Reference: [17] <author> C.-C. J. Kuo and B. C. Levy, </author> <title> A two-level four-color SOR method, </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 26 (1989), </volume> <pages> pp. 129-151. </pages>
Reference-contexts: It is important to note that the scalability results presented in this paper apply to most classical iterative methods. The successive overrelaxation (SOR) method with consistent ordering 1 could be implemented in a scalable multi-level algorithm using graph coloring, as briefly outlined in <ref> [17] </ref>. One could also use the symmetric successive overrelaxation method (SSOR) as a preconditioner for the conjugate gradient algorithm, or as a stand-alone iterative method, and obtain the same communication complexity.
Reference: [18] <author> T. A. Manteuffel, </author> <title> An incomplete factorization technique for positive definite linear systems, </title> <journal> Mathematics of Computation, </journal> <volume> 34 (1980), </volume> <pages> pp. 473-497. </pages>
Reference-contexts: 1. Introduction. The preconditioned conjugate gradient method [13] is one of the most successful iterative methods for solving large, sparse, symmetric, positive-definite linear systems. A preconditioner that has been shown to be very effective for a wide variety of problems is the incomplete Cholesky factorization <ref> [18] </ref>. Recently, several authors [5, 7, 20, 22] have examined the effect of multicoloring based matrix orderings on the convergence properties of iterative methods. However, this work has considered only problems generated from regular grids, for which an optimal coloring is known a priori. <p> When the incomplete Cholesky factorization failed, we use the shifted incomplete factorization method <ref> [18] </ref> and add 0:01 to the diagonal until the factorization succeeded. 4.1. Coloring Heuristic Results. We tested the performance of the IDO heuristic on the first nine, smaller problems in Table 1.
Reference: [19] <author> J. Meijerink and H. van der Vorst, </author> <title> An iterative solution method for linear systems of which the coefficient matrix is a symmetric M-matrix, </title> <journal> Mathematics of Computation, </journal> <volume> 31 (1977), </volume> <pages> pp. 148-162. </pages>
Reference-contexts: Recently, several authors [5, 7, 20, 22] have examined the effect of multicoloring based matrix orderings on the convergence properties of iterative methods. However, this work has considered only problems generated from regular grids, for which an optimal coloring is known a priori. These problems generate M-matrices <ref> [19] </ref> that are not representative of general systems of equations for which the straightforward incomplete Cholesky factorization may not exist. In this paper, we consider sparse linear systems that arise both from finite element models and standard grid problems. For many of the former problems, optimal mul-ticolorings are not known.
Reference: [20] <author> J. M. Ortega, </author> <title> Orderings for conjugate gradient preconditioning, </title> <journal> SIAM Journal on Optimization, </journal> <volume> 1 (1991), </volume> <pages> pp. 565-582. </pages>
Reference-contexts: 1. Introduction. The preconditioned conjugate gradient method [13] is one of the most successful iterative methods for solving large, sparse, symmetric, positive-definite linear systems. A preconditioner that has been shown to be very effective for a wide variety of problems is the incomplete Cholesky factorization [18]. Recently, several authors <ref> [5, 7, 20, 22] </ref> have examined the effect of multicoloring based matrix orderings on the convergence properties of iterative methods. However, this work has considered only problems generated from regular grids, for which an optimal coloring is known a priori.
Reference: [21] <author> R. Schreiber and W.-P. Tang, </author> <title> Vectorizing the conjugate gradient method. </title> <type> Unpublished manuscript, </type> <institution> Department of Computer Science, Stanford University, </institution> <year> 1982. </year>
Reference-contexts: The parallelism inherent in computing and applying the preconditioner is limited by the solution of the triangular systems generated by the incomplete Cholesky factors [22]. It was noted by Schreiber and Tang <ref> [21] </ref> that if the nonzero structure of the triangular factors is identical to that of the original matrix, the minimum number of major parallel steps possible in the solution of the triangular system is given by the chromatic number of the symmetric adjacency graph representing those nonzeros. <p> In the matrix A, unknowns associated with the same node in the finite element model are usually structurally identical. These q identical unknowns can be colored the same color if one is willing to solve block diagonal submatrices of L, rather than diagonal submatrices <ref> [21] </ref>. If this approach is used and each node in the model has q structurally identical unknowns, the minimum number of major parallel steps could be reduced to O (G)=q. In our demonstration of scalability, we have not chosen this approach.
Reference: [22] <author> H. A. van der Vorst, </author> <title> High performance preconditioning, </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 10 (1989), </volume> <pages> pp. 1174-1185. 18 </pages>
Reference-contexts: 1. Introduction. The preconditioned conjugate gradient method [13] is one of the most successful iterative methods for solving large, sparse, symmetric, positive-definite linear systems. A preconditioner that has been shown to be very effective for a wide variety of problems is the incomplete Cholesky factorization [18]. Recently, several authors <ref> [5, 7, 20, 22] </ref> have examined the effect of multicoloring based matrix orderings on the convergence properties of iterative methods. However, this work has considered only problems generated from regular grids, for which an optimal coloring is known a priori. <p> We also compare the effectiveness of the coloring heuristics to some standard orderings: minimum degree, reverse Cuthill-McKee, and nested dissection. The parallelism inherent in computing and applying the preconditioner is limited by the solution of the triangular systems generated by the incomplete Cholesky factors <ref> [22] </ref>.
References-found: 21

