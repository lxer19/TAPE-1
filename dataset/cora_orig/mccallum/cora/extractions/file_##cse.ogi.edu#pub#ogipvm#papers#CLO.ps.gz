URL: file://cse.ogi.edu/pub/ogipvm/papers/CLO.ps.gz
Refering-URL: http://www.cse.ogi.edu/DISC/projects/mist/papers.html
Root-URL: http://www.cse.ogi.edu
Email: o@ipncls.in2p3.fr  otto@cse.ogi.edu  
Title: Combining Simulated Annealing with Local Search Heuristics  
Author: Olivier C. Martin martin and Steve W. Otto 
Date: June 14, 1994  
Address: Orsay CEDEX 91406 France  20000 NW Walker Rd, PO Box 91000 Portland, Oregon, USA 97291-1000  
Affiliation: Division de Physique Theorique Institut de Physique Nucleaire,  Department of Computer Science and Engineering Oregon Graduate Institute of Science Technology  
Abstract: We introduce a meta-heuristic to combine simulated annealing with local search methods for CO problems. This new class of Markov chains leads to significantly more powerful optimization methods than either simulated annealing or local search. The main idea is to embed deterministic local search techniques into simulated annealing so that the chain explores only local optima. It makes large, global changes, even at low temperatures, thus overcoming large barriers in configuration space. We have tested this meta-heuristic for the traveling salesman and graph partitioning problems. Tests on instances from public libraries and random ensembles quantify the power of the method. Our algorithm is able to solve large instances to optimality, improving upon local search methods very significantly. For the traveling salesman problem with randomly distributed cities in a square, the procedure improves on 3-opt by 1.6%, and on Lin-Kernighan local search by 1.3%. For the partitioning of sparse random graphs of average degree equal to 5, the improvement over Kernighan-Lin local search is 8.9%. For both CO problems, we obtain new best heuristics. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> O. Martin, S.W. Otto, </author> <title> and E.W. Felten. Large-step Markov chains for the traveling salesman problem. </title> <journal> J. Complex Syst., </journal> <note> 5:3:299, 1991. 1 Send email to Steve Otto at otto@cse.ogi.edu if interested. 12 </note>
Reference-contexts: This meta-heuristic is very general since simulated annealing and local search are viable techniques for most CO problems. It is also flexible, enabling the incorporation of problem specific aspects of the CO problem. We have implemented the method <ref> [1, 2, 3] </ref> for two graph-based problems, the traveling salesman and the graph partitioning problems (TSP and GPP). The results are significant performance gains for both the TSP and the GPP. Our method improves the state of the art TSP and GPP local search heuristics, leading to new "champion" heuristics. <p> The algorithm did lead to some cost improvement, but the authors did not consider it a general optimization method. Also, contrary to their claim, the algorithm does not satisfy the symmetry constraint of detailed balance (see <ref> [1] </ref>), so the method is not a simulation of an annealing process and a Boltzmann distribution (e E=T ) of solutions is not obtained. Baum ([20] and unpublished) introduced the meta-heuristic as an optimization method applicable to CO problems exhibiting "ultrametric" structure. He called his method iterated descent. <p> In the earliest such work of which we are aware [11], Muhlenbein et. al. used 2-opt to improve children configurations in a TSP before evaluating the cost function. This enabled them to partly overcome the difficulty of combining two parents to create a child of good quality. In <ref> [1] </ref>, we show how the use of many parents can alleviate this difficulty. The method was called a "post reduction procedure" because it is not totally faithful to the GA approach. <p> It turns out that this choice of kick is very effective, not only for geometric graphs, but also for random graphs as discussed in section 6. 5 Results for the TSP We originally tested <ref> [1, 2] </ref> C-L-O on randomly generated instances with N points in a unit square. For N up to 200, we were able to determine the optimum tour using a branch and bound program. Then we ran chained local optimization using Lin-Kernighan as the embedded local search.
Reference: [2] <author> O. Martin, S.W. Otto, </author> <title> and E.W. Felten. Large-step Markov chains for the TSP incorpo-rating local search heuristics. </title> <journal> Oper. Res. Lett., </journal> <volume> 11 </volume> <pages> 219-24, </pages> <year> 1992. </year>
Reference-contexts: This meta-heuristic is very general since simulated annealing and local search are viable techniques for most CO problems. It is also flexible, enabling the incorporation of problem specific aspects of the CO problem. We have implemented the method <ref> [1, 2, 3] </ref> for two graph-based problems, the traveling salesman and the graph partitioning problems (TSP and GPP). The results are significant performance gains for both the TSP and the GPP. Our method improves the state of the art TSP and GPP local search heuristics, leading to new "champion" heuristics. <p> It turns out that this choice of kick is very effective, not only for geometric graphs, but also for random graphs as discussed in section 6. 5 Results for the TSP We originally tested <ref> [1, 2] </ref> C-L-O on randomly generated instances with N points in a unit square. For N up to 200, we were able to determine the optimum tour using a branch and bound program. Then we ran chained local optimization using Lin-Kernighan as the embedded local search.
Reference: [3] <author> O. Martin and S.W. Otto. </author> <title> Partitioning of unstructured meshes for load balancing. </title> <type> Technical report, </type> <year> 1993. </year> <note> Submitted to Concurrency: Practice and Experience. </note>
Reference-contexts: This meta-heuristic is very general since simulated annealing and local search are viable techniques for most CO problems. It is also flexible, enabling the incorporation of problem specific aspects of the CO problem. We have implemented the method <ref> [1, 2, 3] </ref> for two graph-based problems, the traveling salesman and the graph partitioning problems (TSP and GPP). The results are significant performance gains for both the TSP and the GPP. Our method improves the state of the art TSP and GPP local search heuristics, leading to new "champion" heuristics. <p> The columns labeled are the expected errors of the given means. C-L-O runs were with temperature set to zero. 6 Results for the GPP In <ref> [3] </ref>, we compare C-L-O to K-L and to improvements to K-L. K-L is known to be significantly better than simulated annealing for certain types of sparse graphs of relevance to load-balancing, while being less good for random graphs [17]. <p> K-L is known to be significantly better than simulated annealing for certain types of sparse graphs of relevance to load-balancing, while being less good for random graphs [17]. Here we give the performances of our algorithm for "geometric" graphs and for sparse random graphs. In <ref> [3] </ref>, we also compare with graphs obtained from real world load balancing instances. Again, the C-L-O algorithm improves significantly on local search. Performance on geometric graphs This ensemble of graphs is motivated by load balancing problems.
Reference: [4] <author> E.L. Lawler, J.K. Lenstra, A.H.G. Rinooy Kan, </author> <title> and D.B. Shmoys, editors. The Traveling Salesman Problem. </title> <publisher> John Wiley & and Sons, </publisher> <year> 1984. </year>
Reference-contexts: Finally, definitions of the TSP and the GPP, along with specific details concerning the local searches, can be found in two appendices. 2 Status of TSP and GPP heuristics Traveling salesman heuristics The important exact algorithms for TSP are branch and bound methods, and more recently branch and cut methods <ref> [4] </ref>. These methods have progressed tremendously in the last ten years, so that instances with N of several thousand have now been solved to optimality [5]. A library of solved instances is available electronically [6], enabling users to test their algorithms.
Reference: [5] <author> M.W. Padberg and G. Rinaldi. </author> <title> A branch and cut algorithm for the resolution of large-scale symmetric traveling salesman problems. </title> <journal> SIAM Review, </journal> <volume> 33:60, </volume> <year> 1991. </year>
Reference-contexts: These methods have progressed tremendously in the last ten years, so that instances with N of several thousand have now been solved to optimality <ref> [5] </ref>. A library of solved instances is available electronically [6], enabling users to test their algorithms. In terms of heuristics, many methods have been proposed, such as direct tour construction, local search [7, 8], simulated annealing [9, 10], genetic algorithms [11], and neural network approaches [12].
Reference: [6] <institution> A Library of TSP instances is electronically available. For further details, contact R. Bixby at bixby@rice.edu. </institution>
Reference-contexts: These methods have progressed tremendously in the last ten years, so that instances with N of several thousand have now been solved to optimality [5]. A library of solved instances is available electronically <ref> [6] </ref>, enabling users to test their algorithms. In terms of heuristics, many methods have been proposed, such as direct tour construction, local search [7, 8], simulated annealing [9, 10], genetic algorithms [11], and neural network approaches [12]. <p> Finally, we tested the C-L-O algorithm on large, specific instances solved to optimality by other groups and available <ref> [6] </ref>. These instances were: (1) LIN-318 [21]; (2) AT&T-532 [22]; and (3) RAT-783 [23]. The numbers denote the number of cities, and the references give the authors who first solved the problem to optimality using branch and cut methods.
Reference: [7] <author> S. Lin. </author> <title> Computer solutions of the traveling salesman problem. </title> <institution> Bell Syst. Tech. J., 44:2245, </institution> <year> 1965. </year>
Reference-contexts: A library of solved instances is available electronically [6], enabling users to test their algorithms. In terms of heuristics, many methods have been proposed, such as direct tour construction, local search <ref> [7, 8] </ref>, simulated annealing [9, 10], genetic algorithms [11], and neural network approaches [12]. The present consensus [13] is that the heuristic that leads to the best solutions is a local search method due to Lin and Kernighan [8] (L-K).
Reference: [8] <author> S. Lin and B. Kernighan. </author> <title> An effective heuristic algorithm for the traveling salesman problem. </title> <type> Oper. </type> <institution> Res., 21:498, </institution> <year> 1973. </year>
Reference-contexts: A library of solved instances is available electronically [6], enabling users to test their algorithms. In terms of heuristics, many methods have been proposed, such as direct tour construction, local search <ref> [7, 8] </ref>, simulated annealing [9, 10], genetic algorithms [11], and neural network approaches [12]. The present consensus [13] is that the heuristic that leads to the best solutions is a local search method due to Lin and Kernighan [8] (L-K). <p> The present consensus [13] is that the heuristic that leads to the best solutions is a local search method due to Lin and Kernighan <ref> [8] </ref> (L-K). L-K is essentially a breadth-first search (3-opt) followed by a depth-first search (using greedy 2-changes). It is the benchmark against which all heuristics are tested. Simulated annealing (S-A) also gives very good tours, but it is many times slower than L-K [13].
Reference: [9] <author> S. Kirkpatrick, C. Gelatt, and M. Vecchi. </author> <title> Optimization by simulated annealing. </title> <booktitle> Science, </booktitle> <address> 220:671, </address> <year> 1983. </year>
Reference-contexts: A library of solved instances is available electronically [6], enabling users to test their algorithms. In terms of heuristics, many methods have been proposed, such as direct tour construction, local search [7, 8], simulated annealing <ref> [9, 10] </ref>, genetic algorithms [11], and neural network approaches [12]. The present consensus [13] is that the heuristic that leads to the best solutions is a local search method due to Lin and Kernighan [8] (L-K). <p> Graph partitioning heuristics Exact methods for GPP are not as highly developed as for the TSP, and only recently has there been an efficient integer linear programming approach [14]. Numerous heuristic methods have been proposed, ranging from the general purpose simulated annealing <ref> [9] </ref> approach to methods such as the recursive spectral bisection [15] and compaction methods [16] that are best adapted to graphs that have a built-in geometric structure. For generic (random) graphs, the consensus 2 [17] is that the "best" heuristics are simulated annealing [9] and a variable depth search due to <p> ranging from the general purpose simulated annealing <ref> [9] </ref> approach to methods such as the recursive spectral bisection [15] and compaction methods [16] that are best adapted to graphs that have a built-in geometric structure. For generic (random) graphs, the consensus 2 [17] is that the "best" heuristics are simulated annealing [9] and a variable depth search due to Kernighan and Lin [18], hereafter referred to as K-L.
Reference: [10] <author> V. Cerny. </author> <title> Thermodynamical approach to the traveling salesman problem: an efficient simulation algorithm. </title> <journal> J. of Opt. Theo. and Appl., </journal> <volume> 45:41, </volume> <year> 1985. </year>
Reference-contexts: A library of solved instances is available electronically [6], enabling users to test their algorithms. In terms of heuristics, many methods have been proposed, such as direct tour construction, local search [7, 8], simulated annealing <ref> [9, 10] </ref>, genetic algorithms [11], and neural network approaches [12]. The present consensus [13] is that the heuristic that leads to the best solutions is a local search method due to Lin and Kernighan [8] (L-K).
Reference: [11] <author> H. Muhlenbein, M. Georges-Schleuter, and O. Kramer. </author> <title> Evolution algorithms in combinatorial optimization. </title> <booktitle> Parallel Computing, </booktitle> <address> 7:65, </address> <year> 1988. </year>
Reference-contexts: A library of solved instances is available electronically [6], enabling users to test their algorithms. In terms of heuristics, many methods have been proposed, such as direct tour construction, local search [7, 8], simulated annealing [9, 10], genetic algorithms <ref> [11] </ref>, and neural network approaches [12]. The present consensus [13] is that the heuristic that leads to the best solutions is a local search method due to Lin and Kernighan [8] (L-K). L-K is essentially a breadth-first search (3-opt) followed by a depth-first search (using greedy 2-changes). <p> In a different spirit, a number of authors have embedded local searches inside genetic algorithms (GA). In the earliest such work of which we are aware <ref> [11] </ref>, Muhlenbein et. al. used 2-opt to improve children configurations in a TSP before evaluating the cost function. This enabled them to partly overcome the difficulty of combining two parents to create a child of good quality.
Reference: [12] <author> J. Hopfield and D. Tank. </author> <title> Neural computation of decisions in optimization problems. </title> <journal> Biol. Cybern., </journal> <volume> 52:141, </volume> <year> 1985. </year>
Reference-contexts: A library of solved instances is available electronically [6], enabling users to test their algorithms. In terms of heuristics, many methods have been proposed, such as direct tour construction, local search [7, 8], simulated annealing [9, 10], genetic algorithms [11], and neural network approaches <ref> [12] </ref>. The present consensus [13] is that the heuristic that leads to the best solutions is a local search method due to Lin and Kernighan [8] (L-K). L-K is essentially a breadth-first search (3-opt) followed by a depth-first search (using greedy 2-changes).
Reference: [13] <author> D.S. Johnson, C.R. Aragon, L.A. McGeoch, and C. Schevon. </author> <title> Optimization by simulated annealing: An experimental evaluation, part III (the TSP). </title> <type> Technical report. </type> <institution> Bell Labs preprint. </institution>
Reference-contexts: A library of solved instances is available electronically [6], enabling users to test their algorithms. In terms of heuristics, many methods have been proposed, such as direct tour construction, local search [7, 8], simulated annealing [9, 10], genetic algorithms [11], and neural network approaches [12]. The present consensus <ref> [13] </ref> is that the heuristic that leads to the best solutions is a local search method due to Lin and Kernighan [8] (L-K). L-K is essentially a breadth-first search (3-opt) followed by a depth-first search (using greedy 2-changes). It is the benchmark against which all heuristics are tested. <p> L-K is essentially a breadth-first search (3-opt) followed by a depth-first search (using greedy 2-changes). It is the benchmark against which all heuristics are tested. Simulated annealing (S-A) also gives very good tours, but it is many times slower than L-K <ref> [13] </ref>. Graph partitioning heuristics Exact methods for GPP are not as highly developed as for the TSP, and only recently has there been an efficient integer linear programming approach [14]. <p> We find that chained local optimization improves 3-opt by over 1.6%, and improves L-K by 1.3%. Just how far C-L-O (with L-K) is from finding the true optimum is subject to debate, but the Held-Karp lower bound shows that the average excess length is at most 0.84% (see <ref> [13] </ref> and Table 1). Finally, we tested the C-L-O algorithm on large, specific instances solved to optimality by other groups and available [6]. These instances were: (1) LIN-318 [21]; (2) AT&T-532 [22]; and (3) RAT-783 [23]. <p> Minutes Excess Minutes Excess Minutes 1.71 791 1.75 30 1.72 10 1.42 3952 1.43 585 1.42 30 1.27 15806 1.29 2921 1.18 14600 0.98 237 0.86 1086 Table 1: A comparison of simulated annealing, Lin-Kernighan from random start, and C-L-O for an N = 1; 000 TSP (random cities, from <ref> [13] </ref>). The columns labeled "Excess" give the percentage excess above the Held-Karp lower bound, the columns labeled "Minutes" give running times in minutes. Comparable excesses were placed on the same rows; this caused blank entries in some cases. <p> A comparison of simulated annealing, Lin-Kernighan from random start, and C-L-O was done in <ref> [13] </ref>, for an N = 1; 000 instance of cities scattered randomly in the square. The results 7 are reproduced in Table 1. Table 2 gives results for our C-L-O algorithm applied to 10 instances of N = 10; 000 TSP, with the cities distributed randomly in the square.
Reference: [14] <author> F. Barahona and A. Casari. </author> <title> On the magnetisation of the ground states in two dimensional Ising spin glasses. </title> <journal> Comp. Phys. Communications, </journal> <volume> 49:417, </volume> <year> 1988. </year>
Reference-contexts: Simulated annealing (S-A) also gives very good tours, but it is many times slower than L-K [13]. Graph partitioning heuristics Exact methods for GPP are not as highly developed as for the TSP, and only recently has there been an efficient integer linear programming approach <ref> [14] </ref>. Numerous heuristic methods have been proposed, ranging from the general purpose simulated annealing [9] approach to methods such as the recursive spectral bisection [15] and compaction methods [16] that are best adapted to graphs that have a built-in geometric structure.
Reference: [15] <author> A. Pothen, H. Simon, and K.P. Liou. </author> <title> Partitioning sparse matrices with eigenvectors of graphs. </title> <journal> SIAM J. Mat. Anal. Appl., </journal> <volume> 11(3) </volume> <pages> 430-52, </pages> <year> 1990. </year>
Reference-contexts: Numerous heuristic methods have been proposed, ranging from the general purpose simulated annealing [9] approach to methods such as the recursive spectral bisection <ref> [15] </ref> and compaction methods [16] that are best adapted to graphs that have a built-in geometric structure. For generic (random) graphs, the consensus 2 [17] is that the "best" heuristics are simulated annealing [9] and a variable depth search due to Kernighan and Lin [18], hereafter referred to as K-L.
Reference: [16] <author> T. Bui, C. Heigham, C. Jones, and T. Leighton. </author> <title> Improving the performance of the Kernighan-Lin and simulated annealing graph bisection algorithms. </title> <booktitle> In 26'th ACM/IEEE Design Automation Conference, </booktitle> <pages> page 775, </pages> <year> 1989. </year>
Reference-contexts: Numerous heuristic methods have been proposed, ranging from the general purpose simulated annealing [9] approach to methods such as the recursive spectral bisection [15] and compaction methods <ref> [16] </ref> that are best adapted to graphs that have a built-in geometric structure. For generic (random) graphs, the consensus 2 [17] is that the "best" heuristics are simulated annealing [9] and a variable depth search due to Kernighan and Lin [18], hereafter referred to as K-L.
Reference: [17] <author> D.S. Johnson, C.R. Aragon, L.A. McGeoch, and C. Schevon. </author> <title> Optimization by simulated annealing: An experimental evaluation, part I (graph partitioning). </title> <journal> Oper. Res., </journal> <volume> 37 </volume> <pages> 865-92, </pages> <year> 1989. </year>
Reference-contexts: Numerous heuristic methods have been proposed, ranging from the general purpose simulated annealing [9] approach to methods such as the recursive spectral bisection [15] and compaction methods [16] that are best adapted to graphs that have a built-in geometric structure. For generic (random) graphs, the consensus 2 <ref> [17] </ref> is that the "best" heuristics are simulated annealing [9] and a variable depth search due to Kernighan and Lin [18], hereafter referred to as K-L. <p> K-L is known to be significantly better than simulated annealing for certain types of sparse graphs of relevance to load-balancing, while being less good for random graphs <ref> [17] </ref>. Here we give the performances of our algorithm for "geometric" graphs and for sparse random graphs. In [3], we also compare with graphs obtained from real world load balancing instances. Again, the C-L-O algorithm improves significantly on local search. <p> As R increases, the connectivity as measured by d, the average degree of a vertex, increases. Neglecting boundary effects, one has d = R 2 N . Johnson et. al. <ref> [17] </ref> did a thorough comparison of local search, K-L, and simulated annealing for these types of graphs. They found that a certain improvement to K-L, which they called Line-K-L (L-K-L), in which one starts K-L on a non-random partition, was by far the best method. <p> One can also compare the average performances, taking into account the different speeds of the algorithms. One run of 100 steps of C-L-O takes about the same computation time as 100 L-K-Ls. Thus from the 2000 L-K-L data points, we obtained, following the method described in <ref> [17] </ref>, the distribution of the best cut found in 100 independent trials. The mean and standard deviation were then compared with the corresponding moments of the best found in each of the C-L-O runs. <p> Thus we have chosen an intermediate value, d = 5, which leads to cut sizes that scale with N at large N and that enables us to compare our results with those in <ref> [17] </ref>. Denoting the cut size per vertex for the various algorithms by C (N ), we find C KL (500) = 0:49 0:01. The error is quite large because the fluctuations from instance to instance are important.
Reference: [18] <author> B. Kernighan and S. Lin. </author> <title> An effective heuristic procedure for partitioning graphs. </title> <institution> Bell Syst. Tech. J., 49:291, </institution> <year> 1970. </year>
Reference-contexts: For generic (random) graphs, the consensus 2 [17] is that the "best" heuristics are simulated annealing [9] and a variable depth search due to Kernighan and Lin <ref> [18] </ref>, hereafter referred to as K-L. Discussion For most CO problems, and certainly for the TSP and the GPP, as the characteristic size N of the instance grows, the number of configurations (feasible solutions) that are locally optimal under a given local search method grows very quickly with N .
Reference: [19] <author> Z. Li and H.A. Scheraga. </author> <title> Monte carlo-minimization approach to the multiple-minima problem in protein folding. </title> <journal> Proc. Natl. Acad. Sci., </journal> <volume> 84 </volume> <pages> 6611-6615, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: Comparable improvements should occur for other CO problems as long as the biased sampling of the Markov chain is more efficient than random sampling. Weaker forms of this meta-heuristic have been proposed. In <ref> [19] </ref>, Li and Scheraga imple 4 mented a Markov chain with a kick followed by a downhill search for a protein folding problem. The algorithm did lead to some cost improvement, but the authors did not consider it a general optimization method.
Reference: [20] <author> E.B. Baum. </author> <title> Towards practical `neural' computation for combinatorial optimization problems. </title> <editor> In J. Denker, editor, </editor> <booktitle> Neural Networks for Computing, 1986. AIP conference proceedings 151. </booktitle>
Reference: [21] <author> H. Crowder and M.W. Padberg. </author> <title> Solving large-scale symmetric traveling salesman problems to optimality. </title> <booktitle> Management Science, </booktitle> <address> 26:495, </address> <year> 1984. </year>
Reference-contexts: Finally, we tested the C-L-O algorithm on large, specific instances solved to optimality by other groups and available [6]. These instances were: (1) LIN-318 <ref> [21] </ref>; (2) AT&T-532 [22]; and (3) RAT-783 [23]. The numbers denote the number of cities, and the references give the authors who first solved the problem to optimality using branch and cut methods.
Reference: [22] <author> M.W. Padberg and G. Rinaldi. </author> <title> Optimization of a 532-city symmetric traveling salesman problem by branch and cut. </title> <journal> Oper. Res. Lett., </journal> <volume> 6(1) </volume> <pages> 1-7, </pages> <year> 1987. </year>
Reference-contexts: Finally, we tested the C-L-O algorithm on large, specific instances solved to optimality by other groups and available [6]. These instances were: (1) LIN-318 [21]; (2) AT&T-532 <ref> [22] </ref>; and (3) RAT-783 [23]. The numbers denote the number of cities, and the references give the authors who first solved the problem to optimality using branch and cut methods.
Reference: [23] <author> W. Cook, V. Chvatal, and D. </author> <title> Applegate. </title> <editor> In R. Bixby, editor, </editor> <volume> TSP 90, </volume> <year> 1992. </year> <institution> Workshop held at Rice University, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: Finally, we tested the C-L-O algorithm on large, specific instances solved to optimality by other groups and available [6]. These instances were: (1) LIN-318 [21]; (2) AT&T-532 [22]; and (3) RAT-783 <ref> [23] </ref>. The numbers denote the number of cities, and the references give the authors who first solved the problem to optimality using branch and cut methods.
Reference: [24] <author> A. L. Beguelin, J. J. Dongarra, A. Geist, R. J. Manchek, and V. S. Sunderam. </author> <title> Heterogeneous network computing. </title> <booktitle> In Sixth SIAM Conference on Parallel Processing, </booktitle> <year> 1993. </year>
Reference-contexts: Not surprisingly, this confirms that repeated random starts is ineffective as N becomes large. 7 Parallel C-L-O This section discusses a parallel version of the C-L-O algorithm. Through the use of PVM (Parallel Virtual Machine, <ref> [24, 25] </ref>), we regularly run the algorithm in parallel on a local network of workstations. In fact, our only code is parallel | the single processor results given earlier were simply the parallel code executing on only a single processor.
Reference: [25] <author> Jack Dongarra, Al Geist, Robert Manchek, and Vaidy Sunderam. </author> <title> Integrated PVM framework supports heterogeneous network computing. </title> <booktitle> Computers in Physics, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: Not surprisingly, this confirms that repeated random starts is ineffective as N becomes large. 7 Parallel C-L-O This section discusses a parallel version of the C-L-O algorithm. Through the use of PVM (Parallel Virtual Machine, <ref> [24, 25] </ref>), we regularly run the algorithm in parallel on a local network of workstations. In fact, our only code is parallel | the single processor results given earlier were simply the parallel code executing on only a single processor.
Reference: [26] <author> D.S. Johnson. </author> <title> Local optimization and the traveling salesman problem. </title> <booktitle> In 17'th Colloquium on Automata, Languages, and Progamming, 1990. </booktitle> <publisher> Springer-Verlag. </publisher>
Reference: [27] <author> S. Kirkpatrick. </author> <title> Optimization by simulated annealing: Quantitative studies. </title> <journal> J. Statis. Phys., </journal> <volume> 34:975, </volume> <year> 1984. </year>
Reference: [28] <author> M. Hanan and J.M. Kertzberg. </author> <title> A review of the placement and quadratic assignment problems. </title> <journal> SIAM Review, </journal> <volume> 14, No. 2:324, </volume> <year> 1972. </year>
Reference: [29] <author> B.W. Kernighan. </author> <title> Some graph partitioning problems related to program segmentation, 1969. </title> <type> Ph.D. Thesis. </type>
Reference: [30] <author> A.E. Dunlop and B.W. Kernighan. </author> <title> A procedure for placement of standard-cell VLSI circuits. </title> <journal> IEEE Transactions on Computer-Aided Design, CAD-4, </journal> <volume> No. 1:92, </volume> <year> 1985. </year>
Reference: [31] <author> Y. Fu and P.W. Anderson. </author> <title> Application of statistical mechanics to NP-complete problems in combinatorial optimization. </title> <journal> J. Phys. A: Math. Gen., </journal> <volume> 19:1605, </volume> <year> 1986. </year>
Reference: [32] <author> M.K. Goldberg and R. Gardner. </author> <title> On the minimal cut problem. </title> <booktitle> In Progress in Graph Theory, </booktitle> <pages> page 295, </pages> <year> 1984. </year> <editor> Ed. J.A. Bondy and U.S.R. </editor> <publisher> Murty. </publisher>
Reference: [33] <author> M. Berger and S. Bokhari. </author> <title> A partitioning strategy for non-uniform problems on multiprocessors. </title> <journal> IEEE Trans. Computers, </journal> <volume> C-36(5):570, </volume> <year> 1987. </year>
Reference: [34] <author> C.M. Fiduccia and R.M. Mattheyses. </author> <title> A linear-time heuristic for improving network partitions. </title> <booktitle> In Proceedings 19'th Design Automation Workshop, </booktitle> <pages> page 175, </pages> <year> 1982. </year> <month> 14 </month>
References-found: 34

