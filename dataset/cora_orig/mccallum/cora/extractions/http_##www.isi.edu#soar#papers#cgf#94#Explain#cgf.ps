URL: http://www.isi.edu/soar/papers/cgf/94/Explain/cgf.ps
Refering-URL: http://ai.eecs.umich.edu/ifor/papers/index.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: johnson@isi.edu  
Title: Agents that Explain Their Own Actions  
Author: W. Lewis Johnson 
Address: 4676 Admiralty Way Marina del Rey, CA 90292-6695  
Affiliation: USC Information Sciences Institute  
Abstract: Computer generated battlefield agents need to be able to explain the rationales for their actions. Such explanations make it easier to validate agent behavior, and can enhance the effectiveness of the agents as training devices. This paper describes an explanation capability called Debrief that enables agents implemented in Soar to describe and justify their decisions. Debrief determines the motivation for decisions by recalling the context in which decisions were made, and determining what factors were critical to those decisions. In the process Debrief learns to recognize similar situations where the same decision would be made for the same reasons. Debrief currently being used by the TacAir-Soar tactical air agent to explain its actions, and is being evaluated for incorporation into other reactive planning agents. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Arens, E.H. Hovy, and M. Vossers. </author> <title> On the knowledge underlying multimedia presentations. </title> <editor> In M. Maybury, editor, </editor> <title> Intelligent Multimedia Interfaces. </title> <publisher> AAAI Press, </publisher> <year> 1993. </year> <note> to appear. </note>
Reference-contexts: This presentation is performed via a hierarchical presentation planning process, initiated in the Present problem space shown in Figure 2. The planning process is similar to that of other multimedia generation systems <ref> [6, 1] </ref>, although its ability to coordinate text and graphics is somewhat limited. 8.1 Selecting information to present The first step in the presentation process is selecting what information should be presented.
Reference: [2] <author> W.J. Clancey. </author> <title> The advantages of abstract control knowledge in expert system design. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 74-78, </pages> <address> Washing-ton, DC, </address> <month> August </month> <year> 1983. </year>
Reference-contexts: It is necessary to abstract away from these details, and focus on the essential knowledge underlying the agent's decisions. Another approach might be to encode the underlying knowledge explicitly, either in a declarative form or as abstract meta-rules <ref> [2] </ref>. Such an approach has a number of potential problems. First of all, computer generated forces require a great variety of reasoning capabilities, including planning, plan recognition, learning, and geometric reasoning. The problem solving strategies and domain knowledge representations required for many of these capabilities are matters of current research.
Reference: [3] <author> W.J. Clancey. </author> <title> The epistemology of a rule-based expert system: A framework for explanation. </title> <journal> Artificial Intelligence, </journal> <volume> 20(3) </volume> <pages> 215-251, </pages> <year> 1983. </year>
Reference-contexts: The most obvious way to provide such explanations would be to generate English paraphrases of the rules and rule firing traces used by TacAir-Soar. Yet such techniques have proved to be ineffective for explaining expert system reasoning <ref> [4, 16, 3] </ref>, and are likely to be inappropriate in computer generated forces as well. They contain too many implementation details, and are too dependent upon the particulars of how knowledge is encoded in the system.
Reference: [4] <author> R. Davis. </author> <title> Applications of Meta-Level Knowledge to the Construction, Maintenance, and Use of Large Knowledge Bases. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1976. </year>
Reference-contexts: The most obvious way to provide such explanations would be to generate English paraphrases of the rules and rule firing traces used by TacAir-Soar. Yet such techniques have proved to be ineffective for explaining expert system reasoning <ref> [4, 16, 3] </ref>, and are likely to be inappropriate in computer generated forces as well. They contain too many implementation details, and are too dependent upon the particulars of how knowledge is encoded in the system.
Reference: [5] <author> R.B. Doorenbos. </author> <title> Matching 100,000 learned rules. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 290-296, </pages> <address> Washington, DC, </address> <month> August </month> <year> 1993. </year> <note> AAAI. </note>
Reference-contexts: One might therefore be concerned that the additional productions would lead to decreased performance. Fortunately, studies have shown that Soar systems can be run with as many as a million chunks in them without signficant slowdown <ref> [5] </ref>. 1 This number of chunks is far greater than Debrief has yet been required to produce. 7 Explaining Decisions and Beliefs Once the circumstances surrounding a decision has been recalled, it is then possible for Debrief to determine what aspects of those circumstances led to the decision.
Reference: [6] <author> S.K. Feiner and K.R. McKeown. </author> <title> Coordinating text and graphics in explanation generation. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 442-449, </pages> <address> Anaheim, CA, August 1990. </address> <publisher> MIT Press. </publisher>
Reference-contexts: This presentation is performed via a hierarchical presentation planning process, initiated in the Present problem space shown in Figure 2. The planning process is similar to that of other multimedia generation systems <ref> [6, 1] </ref>, although its ability to coordinate text and graphics is somewhat limited. 8.1 Selecting information to present The first step in the presentation process is selecting what information should be presented.
Reference: [7] <author> R.W. Hill and W.L. Johnson. </author> <title> Designing an intelligent tutoring system based on a reactive model of skill acquisition. </title> <booktitle> In Proceedings of the World Conference of Artificial Intelligence in Education, </booktitle> <pages> pages 273-281, </pages> <address> Edin-burgh, Scotland, </address> <year> 1993. </year>
Reference-contexts: TacAir-Soar is in the process of being adapted to handle air-to-ground operations; it is expected that these changes will little or no impact on Debrief. Plans are underway to apply Debrief to an entirely different domain, namely automated control of radar tracking stations in the NASA Deep Space Network <ref> [8, 7] </ref>. 3 An Example The following example scenario illustrates how Debrief is employed.
Reference: [8] <author> R.W. Hill and W.L. Johnson. </author> <title> Situated plan attribution for intelligent tutoring. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <address> Seattle, Washington, </address> <year> 1994. </year> <note> to appear. </note>
Reference-contexts: TacAir-Soar is in the process of being adapted to handle air-to-ground operations; it is expected that these changes will little or no impact on Debrief. Plans are underway to apply Debrief to an entirely different domain, namely automated control of radar tracking stations in the NASA Deep Space Network <ref> [8, 7] </ref>. 3 An Example The following example scenario illustrates how Debrief is employed.
Reference: [9] <author> W.L. Johnson. </author> <title> Agents that learn to explain themselves. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <publisher> page forthcoming, </publisher> <address> Seattle, WA, </address> <month> August </month> <year> 1994. </year> <note> AAAI. </note>
Reference-contexts: Implementation details internal to the Intercept problem space that caused the operator to be selected are automatically filtered out by the chunking process. The details of how this filtering occurs is beyond the scope of this paper, but please see <ref> [9] </ref>. Once it is determined that the recalled operator is applicable, the next step is to determine what would happen if the situation were slightly different from what was recalled. This helps to identify what the critical factors are in the state, and why they are critical.
Reference: [10] <author> W.G. Lehnert. </author> <title> The Process of Question Answering. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hills-dale, NJ, </address> <year> 1978. </year>
Reference-contexts: Questions were categorized into major semantic types, following the methodology that is common in question-answering systems <ref> [10] </ref>. Question types currently supported include: Describe-Event|describe an action or event and its circumstances; Explain-Action|explain why the agent performed a particular action; Explain-Conclusion|explain why the agent drew a particular conclusion; and Explain-Belief|explain why the agent believed that a particular fact was true.
Reference: [11] <author> K.R. McKeown and M. Elhadad. </author> <title> A Contrastive Evaluation of Functional Unification Grammar for Surface Language Generation: </title>
Reference-contexts: In the mean time, the presentations are in natural language instead. Natural language is produced using a simple sentence generator loosely based on Functional Unification Grammar <ref> [11] </ref>. 9 Status and Evaluation The Debrief system as it currently stands comprises thirteen problem spaces, implemented using eighty Soar operators and 1556 productions. It currently can describe and/or explain a total of 70 types of events. The natural language generation component has a vocabulary of 240 words and phrases.
References-found: 11

