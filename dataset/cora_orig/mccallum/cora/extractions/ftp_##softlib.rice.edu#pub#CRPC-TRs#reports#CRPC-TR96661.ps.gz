URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR96661.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Title: HIGHER-ORDER KRYLOV-NEWTON AND FAST KRYLOV-SECANT METHODS FOR SYSTEMS ON NONLINEAR PARTIAL DIFFERENTIAL EQUATIONS  
Author: H ECTOR KL IE MARCELO RAM E AND MARY F. WHEELER 
Abstract: Keywords: secant methods, Krylov subspace methods, nonlinear equations, Newton's method, Broyden's method AMS(MOS) subject classification: 3504, 35Q35, 35M10 
Abstract-found: 1
Intro-found: 1
Reference: <author> Fig. </author> <title> 23. Performance in accumulated nonlinear iterations of HOKN/2SGS, Newton/2SGS and New-ton/2SComb solvers after 100 time steps of simulation with T = :05 of a 16 fi 48 fi 48 problem size on 16 SP2 nodes. REFERENCES </title>
Reference: [1] <author> J. Bear. </author> <title> Dynamics of Fluids in Porous Media. </title> <publisher> Dover Publications, Inc, </publisher> <year> 1972. </year>
Reference-contexts: We also consider two variants of a more physical sound problem which arises in radiative heat transfer applications and modeled by the so-called Chandrasekhar H-equation (see [9, 28]): F (u) = H (u) 1 c R 1 uH (~) = 0; with u 2 <ref> [0; 1] </ref> : There are two solutions known for a c 2 (0; 1) and, as this value approaches one, the problem becomes harder to solve. <p> In our computational experiments we take c 0 = 0:25, which represents a typical value of the irreducible water content. See <ref> [1] </ref> for a comprehensive discussion of this model. The solution shows the effect of the heterogeneity in the resulting subsurface water content.
Reference: [2] <author> P.N. Brown. </author> <title> A theoretical comparison of the Arnoldi and GMRES algorithms. </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 20 </volume> <pages> 58-78, </pages> <year> 1992. </year>
Reference-contexts: It is important to remark, however, that the GMRES algorithm is still more robust an efficient than this approach <ref> [2] </ref>. 3.1. Updating the Arnoldi factorization. In Section x 2.2 we discussed the role that the Arnoldi process plays in GMRES. It is basically the vehicle to express the minimal residual approximation (??) in a more manageable way.
Reference: [3] <author> P.N. Brown and Y. Saad. </author> <title> Hybrid Krylov methods for nonlinear systems of equations. </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 11 </volume> <pages> 450-481, </pages> <year> 1990. </year>
Reference-contexts: The first of them is a nonlinear steady-state equation known as the (modified) Bratu problem. This is a model for the steady-state temperature distribution in reacting systems in two space dimensions and is included here because it has been used repeatedly as a test bed for inexact Newton methods <ref> [3, 22, 37] </ref>. The second example involves a simplification of Richards' equation, which is used to model groundwater transport in the unsaturated zone. This time-dependent model in two space dimensions serves as a window to observe the Krylov-secant algorithms in action for underground simulation applications.
Reference: [4] <author> P.N. Brown, Y. Saad, and H.F. Walker. </author> <title> Preconditioning with low rank updates. </title> <type> Private Communication, </type> <year> 1995. </year>
Reference-contexts: The idea can be easily taylored to the inexact Newton method in the form of a higher order procedure: the HOKN algorithm. Approaches that seek to combine both secant and inexact nonlinear methods has been matter of interest to some researchers <ref> [4, 32, 33, 29] </ref>. A more recent approach based on the combination of limited memory BFGS and truncated Newton methods is reported by Byrd, Nocedal and Zhu [8] in the context of unconstrained optimization.
Reference: [5] <author> C.G. </author> <title> Broyden. A class of methods for solving nonlinear simultaneous equations. </title> <journal> Mathematics of Computation, </journal> <volume> 19 </volume> <pages> 577-593, </pages> <year> 1965. </year>
Reference: [6] <author> C.G. </author> <title> Broyden. A new method for solving nonlinear simultaneous equations. </title> <journal> Computing Journal, </journal> <volume> 12 </volume> <pages> 94-99, </pages> <year> 1969. </year>
Reference-contexts: In summary, she suggests the "good Broyden's update" f i = M t i p i as the best option. Deuflhard, Freund and Walter [18] incorporate a line-search strategy to refine the proper step length for updating intermediate residuals and solutions. This feature was absent in Broyden's former algorithm <ref> [6] </ref>, making the method to terminate within at most 2n steps [24].
Reference: [7] <author> R.H. Byrd, J. Nocedal, and R.B. Schnabel. </author> <title> Representations of quasi-Newton matrices and their use in limited memory methods. </title> <journal> Math. Programming, </journal> <volume> 63 </volume> <pages> 129-156, </pages> <year> 1994. </year>
Reference: [8] <author> R.H. Byrd, J. Nocedal, and C. Zhu. </author> <title> Towards a discrete Newton method with memory for large-scale optimization. </title> <type> Technical Report TR OTC 95/01, </type> <institution> Optimization Technology Center, </institution> <year> 1995. </year>
Reference-contexts: Approaches that seek to combine both secant and inexact nonlinear methods has been matter of interest to some researchers [4, 32, 33, 29]. A more recent approach based on the combination of limited memory BFGS and truncated Newton methods is reported by Byrd, Nocedal and Zhu <ref> [8] </ref> in the context of unconstrained optimization. The Krylov-Broyden update to be described in this paper has been also instrumentary in generating hybrid Krylov-secant methods for solving systems of nonlinear equations.
Reference: [9] <author> S. </author> <title> Chandrasekhar. Radiative Transfer. </title> <publisher> Dover, </publisher> <address> New York, </address> <year> 1960. </year>
Reference-contexts: We also consider two variants of a more physical sound problem which arises in radiative heat transfer applications and modeled by the so-called Chandrasekhar H-equation (see <ref> [9, 28] </ref>): F (u) = H (u) 1 c R 1 uH (~) = 0; with u 2 [0; 1] : There are two solutions known for a c 2 (0; 1) and, as this value approaches one, the problem becomes harder to solve.
Reference: [10] <author> C. Dawson, H.M. Kl ie, C. San Soucie, and M.F. Wheeler. </author> <title> A parallel, implicit, cell-centered method for two-phase flow. </title> <note> In preparation, </note> <year> 1996. </year>
Reference-contexts: The first two sections of the chapter are devoted to analyze the performance of each one separately. The last section introduces ideas from these two approaches in a parallel black-oil reservoir simulator described by Wheeler and Smith in [46] and later improved by Dawson et al. in <ref> [10] </ref>. In this section we present numerical experiments to illustrate the effectiveness of the algorithms presented here, i.e., the nonlinear KEN and higher order Krylov-Newton (HOKN). <p> Therefore, matrix-vector products involves data communication of each node with its four lateral and four corner neighbors (refer to <ref> [10] </ref> for further details). In our particular implementation, the 2SGS preconditioner comprises the GMRES solution of each individual block of pressures and concentrations (i.e., the product of densities and saturations of a particular phase). A tridiagonal preconditioner is used to accelerate the convergence rate of this inner GMRES.
Reference: [11] <author> R.S. Dembo, S.C. Eisenstat, and T. Steihaug. </author> <title> Inexact Newton methods. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 19 </volume> <pages> 400-408, </pages> <year> 1982. </year>
Reference-contexts: The inexactness arises as consequence of solving the linear Jacobian equation by an iterative procedure (such as GMRES) to a specified tolerance. Hence, our development falls into the theory of Dembo, Eisenstat and Steihaug <ref> [11] </ref> which, was later extended in [21, 41, 17, 16] for secant methods. We propose to update the Arnoldi decomposition on which GMRES is based in order to perform two minimal residual approximation solutions per GMRES call. <p> Reference [21] is of particular interest since in there it shows the local q-superlinear rate of convergence is still attained for the inexact Broyden's method. In fact, those results are a generalization of the work previously developed by Dembo, Eisenstat and Steihaug in <ref> [11] </ref>. Since the same conditions stated in [21] can be also imposed upon the inexact nonlinear EN algorithm, it is straightforward to show that it produces q-superlinearly convergent iterates.
Reference: [12] <author> J. E. Dennis and R. B. Schnabel. </author> <title> Numerical methods for unconstrained optimization and nonlinear equations. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1983. </year>
Reference-contexts: Among several methods, Newton's method and Broyden's method have been two of the main choices to solve (1) <ref> [12, 28, 34, 35] </ref>. The former is very popular due to its robustness and well known q-quadratic local convergence. The latter is an alternative to the former when the computation of the Jacobian matrix is highly expensive or infeasible to obtain. <p> For instance, when g s, we obtain the "good Broyden's update" and when g M t [F + (u) F (u)], we have the "bad Broyden's update" <ref> [12] </ref> 1 . <p> M (k) s (k) = F (k) : 2.2 Update solution u (k+1) = u (k) + s (k) : 2.3 q (k) = F (k+1) F (k) : ( q (k) M (k) s (k) )( s (k) ) ( s (k) ) It has be shown (see e.g., <ref> [12, 28] </ref>) that Broyden's method iterates converge q-superlinearly to F fl = F (u fl ) = 0 under standard assumptions and given that lim k!1 u (k) = u fl ; u (k) 6= u fl if and only if lim fl fl M (k) J fl s (k) fl <p> u fl ; u (k) 6= u fl if and only if lim fl fl M (k) J fl s (k) fl fl fl Condition (8) is better known as the Dennis-More characterization and it is cornerstone in proving local q-superlinear convergence for general secant updates in optimization (see e.g., <ref> [12, 13] </ref>). 2.2. The nonlinear EN algorithm. provides a new direction based on generating new directions based on a approximation M i+1 rather than on M i at a given ith step. More precisely, the EN algorithm looks one step forward to generarte compared TWO-STAGE PRECONDITIONERS 5 to Broyden's method. <p> We momentarily look at convergence in terms of nonlinear iterations and leave the discussion on computational cost (i.e., in terms of floating point operations) to Chapter 5. Example 2.1. XXXXXXXXXXXXXXXXXXXXXXXXX We consider the extended versions of the Rosenbrock function and Powell function described in Appendix B of <ref> [12] </ref> with initial guesses u (0) = (0; 1; 0; 1; : : : ; 0; 1) t and u (0) = (0; 1; 0; 1; : : :; 0; 1; 0; 1) t ; respectively. <p> However, we quote that expression (21) can be efficiently performed by updating a given QR form of H m (see e.g., <ref> [12, 27] </ref>). This form is not readily available, instead most standard implementations of GMRES progressively compute a QR factorization of H (k) m as every new column enters the Arnoldi process (recall discussion in xx ??). <p> Basically, these situations lead to reset the current Jacobian approximation and restart the process with a new Jacobian approximation (usually obtained by finite differences). Discussion on this topic for the particular context of Broyden's method can be found in <ref> [12] </ref>. 4.2. A higher-order Krylov-Newton algorithm. The higher-order version of the nonlinear KEN algorithm can be attained by performing rank-one updates of the Hessenberg matrix as long as possible before making the next GMRES call.
Reference: [13] <author> J.E. Dennis and J.J. </author> <title> More. A characterization of superlinear convergence and its applications to quasi-Newton methods. </title> <journal> Math. Comp., </journal> <volume> 228 </volume> <pages> 549-560, </pages> <year> 1974. </year>
Reference-contexts: u fl ; u (k) 6= u fl if and only if lim fl fl M (k) J fl s (k) fl fl fl Condition (8) is better known as the Dennis-More characterization and it is cornerstone in proving local q-superlinear convergence for general secant updates in optimization (see e.g., <ref> [12, 13] </ref>). 2.2. The nonlinear EN algorithm. provides a new direction based on generating new directions based on a approximation M i+1 rather than on M i at a given ith step. More precisely, the EN algorithm looks one step forward to generarte compared TWO-STAGE PRECONDITIONERS 5 to Broyden's method.
Reference: [14] <author> J.E. Dennis and R.B.Schnabel. </author> <title> Least change secant updates for quasi-Newton methods. </title> <journal> SIAM Review, </journal> <volume> 21 </volume> <pages> 443-459, </pages> <year> 1979. </year>
Reference-contexts: This observation is key in the construction of least-change secant updates consistent with operators satisfying the standard secant condition and other property prescribed by a given affine subspace (e.g., sparsity pattern, positive definiteness) in IR nfin (see <ref> [14, 15] </ref>). The vectors z and w in (15) are arbitrary in IR m . <p> This interpretation is nothing more than a particular case of the general result established by Dennis and Schnabel in <ref> [14] </ref>. Fig. 2. Convergence comparison between Broyden's method (dotted line) and the Krylov-Broyden method (solid line).
Reference: [15] <author> J.E. Dennis and H.F. Walker. </author> <title> Convergence theorems for least-change secant updates methods. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 18 </volume> <pages> 949-987, </pages> <year> 1981. </year>
Reference-contexts: This observation is key in the construction of least-change secant updates consistent with operators satisfying the standard secant condition and other property prescribed by a given affine subspace (e.g., sparsity pattern, positive definiteness) in IR nfin (see <ref> [14, 15] </ref>). The vectors z and w in (15) are arbitrary in IR m .
Reference: [16] <author> J.E. Dennis and H.F. Walker. </author> <title> Inaccuracy in quasi-Newton methods: Local improvement theorems. </title> <booktitle> In Mathematical Programming Study 22: Mathematical Programming at Overwolfach. </booktitle> <publisher> North-Holland, </publisher> <year> 1984. </year> <note> REFERENCES 49 </note>
Reference-contexts: The inexactness arises as consequence of solving the linear Jacobian equation by an iterative procedure (such as GMRES) to a specified tolerance. Hence, our development falls into the theory of Dembo, Eisenstat and Steihaug [11] which, was later extended in <ref> [21, 41, 17, 16] </ref> for secant methods. We propose to update the Arnoldi decomposition on which GMRES is based in order to perform two minimal residual approximation solutions per GMRES call. In this way, we are able to come up with an improved nonlinear step at each nonlinear cycle.
Reference: [17] <author> J.E. Dennis and H.F. Walker. </author> <title> Least-change sparse secant updates with inaccurate secant conditions. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 22 </volume> <pages> 760-778, </pages> <year> 1985. </year>
Reference-contexts: The inexactness arises as consequence of solving the linear Jacobian equation by an iterative procedure (such as GMRES) to a specified tolerance. Hence, our development falls into the theory of Dembo, Eisenstat and Steihaug [11] which, was later extended in <ref> [21, 41, 17, 16] </ref> for secant methods. We propose to update the Arnoldi decomposition on which GMRES is based in order to perform two minimal residual approximation solutions per GMRES call. In this way, we are able to come up with an improved nonlinear step at each nonlinear cycle.
Reference: [18] <author> P. Deuflhard, R. Freund, and A. Walter. </author> <title> Fast secant methods for the iterative solution of large nonsymmetric linear systems. </title> <booktitle> IMPACT of Computing in Science and Engineering, </booktitle> <volume> 2 </volume> <pages> 244-276, </pages> <year> 1990. </year>
Reference-contexts: This procedure is better known as the EN algorithm and has been subject of theoretical study and implementation enhancements by several authors <ref> [18, 19, 43, 45, ?, 47] </ref>. These recent developments have shed light on new connections between secant methods and other well established iterative methods. <p> In summary, she suggests the "good Broyden's update" f i = M t i p i as the best option. Deuflhard, Freund and Walter <ref> [18] </ref> incorporate a line-search strategy to refine the proper step length for updating intermediate residuals and solutions. This feature was absent in Broyden's former algorithm [6], making the method to terminate within at most 2n steps [24]. <p> More precisely, the EN algorithm looks one step forward to generarte compared TWO-STAGE PRECONDITIONERS 5 to Broyden's method. Hence, the computational complexity of the EN algorithm approximately doubles both Broyden's and the GMRES algorithm <ref> [18, 47] </ref>. However, the it is about twice faster than the other two. Careful implementations in terms of memory management and computation (through restarts, truncation and implicit updates) give apparently slight advantage to the EN algorithm [47]. Algorithm 2.3. (Nonlinear EN) 1.
Reference: [19] <author> T. Eirola and O. Nevanlinna. </author> <title> Accelerating with rank-one updates. Linear Alg. </title> <journal> and its Appl., </journal> <volume> 121 </volume> <pages> 511-520, </pages> <year> 1989. </year>
Reference-contexts: In general, secant methods (those based on a secant condition) have play an important role in linear and nonlinear programming. Traditionally, Broyden's method has been considered impractical as a linear solver and consequently, almost forgotten throughout the iterative algorithms literature. Eirola and Nevanlinna <ref> [19] </ref> revitalized the interest on secant methods for solving iteratively nonsymmetric systems with an algorithm that provides variable approximation to the linear system matrix via rank-one updates which incidentally, it is competitive with the GMRES Krylov iterative solver. <p> This procedure is better known as the EN algorithm and has been subject of theoretical study and implementation enhancements by several authors <ref> [18, 19, 43, 45, ?, 47] </ref>. These recent developments have shed light on new connections between secant methods and other well established iterative methods.
Reference: [20] <author> S.C. Eisenstat, H.C. Elman, and M.H. Schultz. </author> <title> Variational iterative methods for nonsymmetric systems of linear equations. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 20 </volume> <pages> 345-357, </pages> <year> 1983. </year>
Reference-contexts: Eisenstat, El-man and Schultz <ref> [20] </ref> use this presentation to derive the generalized conjugate residual method (GCR) and other three closely related methods.
Reference: [21] <author> S.C. Eisenstat and T. Steihaug. </author> <title> Local analysis of inexact quasi-Newton methods. </title> <type> Technical Report MASC TR 82-7, </type> <institution> Dept. of Mathematical Sciences, Rice University, </institution> <year> 1982. </year>
Reference-contexts: The inexactness arises as consequence of solving the linear Jacobian equation by an iterative procedure (such as GMRES) to a specified tolerance. Hence, our development falls into the theory of Dembo, Eisenstat and Steihaug [11] which, was later extended in <ref> [21, 41, 17, 16] </ref> for secant methods. We propose to update the Arnoldi decomposition on which GMRES is based in order to perform two minimal residual approximation solutions per GMRES call. In this way, we are able to come up with an improved nonlinear step at each nonlinear cycle. <p> In this way, we are able to preserve much of the integrity of an inexact nonlinear EN algorithm and recover the efficiency that it promises compared to Newton's and Broyden's method. 2.3. Inexactness in secant methods. The issue of inexactness in quasi-Newton methods has been examined in <ref> [21, 41] </ref>. Reference [21] is of particular interest since in there it shows the local q-superlinear rate of convergence is still attained for the inexact Broyden's method. In fact, those results are a generalization of the work previously developed by Dembo, Eisenstat and Steihaug in [11]. <p> Inexactness in secant methods. The issue of inexactness in quasi-Newton methods has been examined in [21, 41]. Reference <ref> [21] </ref> is of particular interest since in there it shows the local q-superlinear rate of convergence is still attained for the inexact Broyden's method. In fact, those results are a generalization of the work previously developed by Dembo, Eisenstat and Steihaug in [11]. Since the same conditions stated in [21] can <p> Reference <ref> [21] </ref> is of particular interest since in there it shows the local q-superlinear rate of convergence is still attained for the inexact Broyden's method. In fact, those results are a generalization of the work previously developed by Dembo, Eisenstat and Steihaug in [11]. Since the same conditions stated in [21] can be also imposed upon the inexact nonlinear EN algorithm, it is straightforward to show that it produces q-superlinearly convergent iterates.
Reference: [22] <author> S.C. Eisenstat and H.F. Walker. </author> <title> Choosing the forcing terms in an inexact Newton method. </title> <journal> SIAM J. Sci. Comput., </journal> <volume> 17 </volume> <pages> 16-32, </pages> <year> 1996. </year>
Reference-contexts: The first of them is a nonlinear steady-state equation known as the (modified) Bratu problem. This is a model for the steady-state temperature distribution in reacting systems in two space dimensions and is included here because it has been used repeatedly as a test bed for inexact Newton methods <ref> [3, 22, 37] </ref>. The second example involves a simplification of Richards' equation, which is used to model groundwater transport in the unsaturated zone. This time-dependent model in two space dimensions serves as a window to observe the Krylov-secant algorithms in action for underground simulation applications. <p> Usually, this number of linear iterations is higher as the nonlinear solution is approached due to the tightening of linear tolerances (i.e., decrease of k ) prescribed by the Eisenstat and Walker criteria <ref> [22] </ref>. This fact shall be important to take into account for the convergence analysis of the HOKN and the nonlinear KEN in terms of floating point operations below. Finally, we remark that the nonlinear residuals norms delivered by the KEN algorithm are also smaller than those produced by Broyden's method.
Reference: [23] <author> A. Ern, V. Giovangigli, D.E. Keyes, and M. D. Smooke. </author> <title> Towards polyalgorithmic linear system solvers for nonlinear elliptic problems. </title> <journal> SIAM J. Sci. Comput., </journal> <volume> 15 </volume> <pages> 681-703, </pages> <year> 1994. </year>
Reference-contexts: Here, chord steps may be a plausible and an effective option. In particular, in simulations approaching the steady state (see e.g., <ref> [23] </ref>). However, in large scale implementations where iterative methods are virtually a must choice, the efficiency line described by the composite Newton's method and the nonlinear EN method seems to appear as a blur.
Reference: [24] <author> D. Gay. </author> <title> Some convergence properties of Broyden's method. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 16 </volume> <pages> 623-630, </pages> <year> 1979. </year>
Reference-contexts: Deuflhard, Freund and Walter [18] incorporate a line-search strategy to refine the proper step length for updating intermediate residuals and solutions. This feature was absent in Broyden's former algorithm [6], making the method to terminate within at most 2n steps <ref> [24] </ref>. <p> Moreover, current derivatives are estimated in terms of the previous derivative rather than two consecutive function values as it occurs with the secant method. It has been proven that the secant method for one-dimensional problem converges 2-step q-quadratically <ref> [24] </ref>. In terms of complexity, we can easily determine that the EN-algorithm requires one extra function evaluation and two extra floating point operations compared to Broyden's method. A key point can be made. Broyden's method is to Newton's method what the nonlinear EN method is to composite Newton's method.
Reference: [25] <author> D.M. Gay and R.B. Schnabel. </author> <title> Solving systems of nonlinear equations by Broyden's method with projected updates. In O.L. </title> <editor> Mangasarian, R.R. Meyer, and S.M. Robinson, editors, </editor> <booktitle> Nonlinear Programming 3, </booktitle> <pages> pages 245-281. </pages> <publisher> Academic Press, </publisher> <address> N.Y., </address> <year> 1978. </year>
Reference-contexts: This feature was absent in Broyden's former algorithm [6], making the method to terminate within at most 2n steps [24]. However, Broyden's update with projected updates can converge within at most n steps. (See <ref> [25, 47] </ref> for a detailed discussion on this.) Deuflhard, Freund and Walter found the best choice for this step length is ff i = i r i i q i which turns out to give a competitive procedure with GMRES in terms of convergence and floating point operations.
Reference: [26] <author> R. Glowinski, H.B. Keller, and L. Reinhart. </author> <title> Continuation-conjugate gradient methods for the least squares solution of nonlinear boundary value problems. </title> <journal> Siam J Sci. Stat. Comput., </journal> <volume> 4 </volume> <pages> 793-833, </pages> <year> 1985. </year>
Reference-contexts: When &gt; 0, there is a threshold value fl for which the equation has no solution for &gt; fl and at least one solution for fl . For more details, we refer the reader to <ref> [26, 31] </ref> and pointers therein. We solve this problem in the unit square with homogeneous Dirichlet boundary conditions. See, e.g., Glowinski, Keller and Reinhart proposed problem in [31] for a detailed description.
Reference: [27] <author> G.H. Golub and C.F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> John Hopkins University Press, </publisher> <year> 1989. </year>
Reference-contexts: However, we quote that expression (21) can be efficiently performed by updating a given QR form of H m (see e.g., <ref> [12, 27] </ref>). This form is not readily available, instead most standard implementations of GMRES progressively compute a QR factorization of H (k) m as every new column enters the Arnoldi process (recall discussion in xx ??). <p> Fortunately, there are efficient ways to perform the QR factorization of H (k) m by just deleting the last row of H m already factorized in QR form. This requires O floating point operations (see <ref> [27, pp. 596-597] </ref>). An even more efficient way to obtain this factorization consists of keeping an immediate copy of the QR factorization of H (k) m before applying all previous Givens rotations to the new entering column.
Reference: [28] <author> C.T. Kelley. </author> <title> Iterative methods for linear and nonlinear equations. </title> <booktitle> In Frontiers in Applied Mathematics. </booktitle> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1995. </year>
Reference-contexts: Among several methods, Newton's method and Broyden's method have been two of the main choices to solve (1) <ref> [12, 28, 34, 35] </ref>. The former is very popular due to its robustness and well known q-quadratic local convergence. The latter is an alternative to the former when the computation of the Jacobian matrix is highly expensive or infeasible to obtain. <p> M (k) s (k) = F (k) : 2.2 Update solution u (k+1) = u (k) + s (k) : 2.3 q (k) = F (k+1) F (k) : ( q (k) M (k) s (k) )( s (k) ) ( s (k) ) It has be shown (see e.g., <ref> [12, 28] </ref>) that Broyden's method iterates converge q-superlinearly to F fl = F (u fl ) = 0 under standard assumptions and given that lim k!1 u (k) = u fl ; u (k) 6= u fl if and only if lim fl fl M (k) J fl s (k) fl <p> The chord step is defined by fixing the Jacobian (its approximation in this case) for some iterations. Incidentally, Kelley presents an updated analysis of this method in <ref> [28] </ref>. <p> They pointed out that even higher-order methods can be built out of a longer sequence of chord steps alternated with regular Newton steps. In a more recent treatment, Kelley names those methods after Shamanskii and compares the particular case (11) numerically against Newton's method <ref> [28] </ref>. Here, we rather adopt the term composite Newton's method for referring to the recurrence (11). Along the lines of Gay's local convergence analysis for Broyden's method, Yang was able to show that the nonlinear EN algorithm converges n-step q-quadratically for n-dimensional problems [47]. <p> Kelley observes that this alternation of chord steps and Newton's steps are potentially attractive for large scale problems where the cost of building the Jacobian is computationally expensive compare to function evaluations <ref> [28] </ref>. The reader can infer that in the setting of large algebraic systems arising from transient problems (i.e., implicit formulation of parabolic equations) it is not unusual to have nearby initial Newton iterates to the root. Here, chord steps may be a plausible and an effective option. <p> We also consider two variants of a more physical sound problem which arises in radiative heat transfer applications and modeled by the so-called Chandrasekhar H-equation (see <ref> [9, 28] </ref>): F (u) = H (u) 1 c R 1 uH (~) = 0; with u 2 [0; 1] : There are two solutions known for a c 2 (0; 1) and, as this value approaches one, the problem becomes harder to solve. <p> Here, we closely follow the specifications given in <ref> [28] </ref>; that is, H (u) u; u (0) = (0; 0; 0; : : :; 0; 0) t and the composite midpoint rule to discretize the integral. The two variants of the H-equation are determined by setting TWO-STAGE PRECONDITIONERS 9 c = :9 and c = :999999.
Reference: [29] <author> J.M. Martnez. </author> <title> Theory of secant preconditioners. </title> <journal> Math. of Computation, </journal> <volume> 60 </volume> <pages> 699-718, </pages> <year> 1993. </year>
Reference-contexts: The idea can be easily taylored to the inexact Newton method in the form of a higher order procedure: the HOKN algorithm. Approaches that seek to combine both secant and inexact nonlinear methods has been matter of interest to some researchers <ref> [4, 32, 33, 29] </ref>. A more recent approach based on the combination of limited memory BFGS and truncated Newton methods is reported by Byrd, Nocedal and Zhu [8] in the context of unconstrained optimization.
Reference: [30] <author> J.M. Martnez. </author> <title> SOR-secant methods. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 31 </volume> <pages> 217-226, </pages> <year> 1994. </year>
Reference: [31] <author> J.J. </author> <title> More. A collection of nonlinear problems. </title> <editor> In E.L. Allgower and K. Georg, editors, </editor> <booktitle> Lectures in Applied Mathematics, </booktitle> <volume> Vol. 26, </volume> <pages> pages 723-762. </pages> <publisher> American Mathematical Society, </publisher> <year> 1990. </year>
Reference-contexts: When &gt; 0, there is a threshold value fl for which the equation has no solution for &gt; fl and at least one solution for fl . For more details, we refer the reader to <ref> [26, 31] </ref> and pointers therein. We solve this problem in the unit square with homogeneous Dirichlet boundary conditions. See, e.g., Glowinski, Keller and Reinhart proposed problem in [31] for a detailed description. <p> For more details, we refer the reader to [26, 31] and pointers therein. We solve this problem in the unit square with homogeneous Dirichlet boundary conditions. See, e.g., Glowinski, Keller and Reinhart proposed problem in <ref> [31] </ref> for a detailed description. In this work, the problem is discretized by a block-centered finite-difference scheme and no upwinding was used for the convective coefficient. The linear system generated by the Newton step becomes harder as ff and grow.
Reference: [32] <author> S.G. Nash. </author> <title> Newton-type minimization via the Lanczos method. </title> <journal> SIAM J. Num. Anal., </journal> <volume> 21 </volume> <pages> 770-778, </pages> <year> 1984. </year>
Reference-contexts: The idea can be easily taylored to the inexact Newton method in the form of a higher order procedure: the HOKN algorithm. Approaches that seek to combine both secant and inexact nonlinear methods has been matter of interest to some researchers <ref> [4, 32, 33, 29] </ref>. A more recent approach based on the combination of limited memory BFGS and truncated Newton methods is reported by Byrd, Nocedal and Zhu [8] in the context of unconstrained optimization.
Reference: [33] <author> S.G. Nash. </author> <title> Preconditioning of truncated-Newton methods. </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 6 </volume> <pages> 599-616, </pages> <year> 1985. </year>
Reference-contexts: The idea can be easily taylored to the inexact Newton method in the form of a higher order procedure: the HOKN algorithm. Approaches that seek to combine both secant and inexact nonlinear methods has been matter of interest to some researchers <ref> [4, 32, 33, 29] </ref>. A more recent approach based on the combination of limited memory BFGS and truncated Newton methods is reported by Byrd, Nocedal and Zhu [8] in the context of unconstrained optimization.
Reference: [34] <author> S.G. Nash and A. Sofer. </author> <title> Linear and Nonlinear programming. </title> <publisher> McGraw-Hill, </publisher> <year> 1996. </year>
Reference-contexts: Among several methods, Newton's method and Broyden's method have been two of the main choices to solve (1) <ref> [12, 28, 34, 35] </ref>. The former is very popular due to its robustness and well known q-quadratic local convergence. The latter is an alternative to the former when the computation of the Jacobian matrix is highly expensive or infeasible to obtain.
Reference: [35] <author> J. Nocedal. </author> <title> Theory of algorithms for unconstrained optimization. </title> <booktitle> In Acta Numerica, </booktitle> <pages> pages 199-242. </pages> <publisher> Cambridge University Press, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: Among several methods, Newton's method and Broyden's method have been two of the main choices to solve (1) <ref> [12, 28, 34, 35] </ref>. The former is very popular due to its robustness and well known q-quadratic local convergence. The latter is an alternative to the former when the computation of the Jacobian matrix is highly expensive or infeasible to obtain.
Reference: [36] <author> J.M. Ortega and W.C. Rheinboldt. </author> <title> Iterative Solution of Nonlinear Equations in Several Variables. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1970. </year>
Reference-contexts: Iterates generated by (11) converge q-superlinearly with q-order 3 <ref> [36] </ref>. These methods were studied by Shamanskii [40] and Traub [42]. They pointed out that even higher-order methods can be built out of a longer sequence of chord steps alternated with regular Newton steps. <p> Hence, the nonlinear EN algorithm converges q-quadratically as Newton's method in the one-dimensional case. Note that the method reduces to a forward finite differ ence method in 1-D [47] which is sometimes referred to as Steffensen's method <ref> [36] </ref>.
Reference: [37] <author> M. Pernice, L. Zhou, and H.F. Walker. </author> <title> Parallel solution of nonlinear partial differential equations using inexact Newton methods. </title> <type> Technical Report TR48-94, </type> <institution> Utah Supercomputing Institute, </institution> <year> 1994. </year>
Reference-contexts: The first of them is a nonlinear steady-state equation known as the (modified) Bratu problem. This is a model for the steady-state temperature distribution in reacting systems in two space dimensions and is included here because it has been used repeatedly as a test bed for inexact Newton methods <ref> [3, 22, 37] </ref>. The second example involves a simplification of Richards' equation, which is used to model groundwater transport in the unsaturated zone. This time-dependent model in two space dimensions serves as a window to observe the Krylov-secant algorithms in action for underground simulation applications. <p> The linear system generated by the Newton step becomes harder as ff and grow. In this particular situation, we consider = 97 and ff = 128 as suggested in <ref> [37] </ref>. A block Jacobi (with 8 blocks of approximately equal size) preconditioner was used for the Richardson iteration, except where indicated in the tables.
Reference: [38] <author> Y. Saad. </author> <title> An overview of Krylov subspace methods with applications to control problems. In M.A. Kaashoek, J.H. vam Schuppen, and A.C. </title> <editor> Ran, editors, </editor> <booktitle> Signal Processing, Scattering, Operator Theory and Numerical Methods, </booktitle> <pages> pages 401-410. </pages> <publisher> Birkhauser, </publisher> <year> 1990. </year>
Reference-contexts: This technique is applied once the Arnoldi process have delivered K m (A; v) as a small invariant subspace under A for a given vector v. Further details and pointers to this problem can be seen in <ref> [38] </ref>. The following theorem states that update (21) yields a modified version of Broy den's update for A (k) : Theorem 3.1.
Reference: [39] <author> Y. Saad. </author> <title> Iterative Methods for Sparse Linear Systems. </title> <publisher> PWS Publishing Company, </publisher> <year> 1996. </year>
Reference-contexts: Nonlinear EN Comp. Newton k RNR k LI RNR k LI 2 1.60e-02 8.80e-02 2 1.46e-02 1.00e-01 2 4 4.08e-04 1.00e-01 2 3.14e-04 1.00e-01 2 6 3.17e-06 1.00e-01 3 5.20e-06 1.00e-01 3 8 2.82e-08 4.01e-02 3 2.23e-10 1.93e-02 4 10 2.23e-11 3.57e-02 3 TWO-STAGE PRECONDITIONERS 11 iterative method <ref> [39] </ref> can be employed for the purposes underlined here. It is important to remark, however, that the GMRES algorithm is still more robust an efficient than this approach [2]. 3.1. Updating the Arnoldi factorization. In Section x 2.2 we discussed the role that the Arnoldi process plays in GMRES.
Reference: [40] <author> V.E. Shamanskii. </author> <title> A modification of Newton's method. </title> <journal> Ukran. Mat. Zh., </journal> <volume> 19 </volume> <pages> 133-138, </pages> <year> 1967. </year> <note> In Russian. </note>
Reference-contexts: Iterates generated by (11) converge q-superlinearly with q-order 3 [36]. These methods were studied by Shamanskii <ref> [40] </ref> and Traub [42]. They pointed out that even higher-order methods can be built out of a longer sequence of chord steps alternated with regular Newton steps. In a more recent treatment, Kelley names those methods after Shamanskii and compares the particular case (11) numerically against Newton's method [28].
Reference: [41] <author> T. Steihaug. </author> <title> Local and superlinear convergence for truncated iterated projection methods. </title> <journal> Mathematical Programming, </journal> <volume> 27 </volume> <pages> 176-190, </pages> <year> 1983. </year>
Reference-contexts: The inexactness arises as consequence of solving the linear Jacobian equation by an iterative procedure (such as GMRES) to a specified tolerance. Hence, our development falls into the theory of Dembo, Eisenstat and Steihaug [11] which, was later extended in <ref> [21, 41, 17, 16] </ref> for secant methods. We propose to update the Arnoldi decomposition on which GMRES is based in order to perform two minimal residual approximation solutions per GMRES call. In this way, we are able to come up with an improved nonlinear step at each nonlinear cycle. <p> In this way, we are able to preserve much of the integrity of an inexact nonlinear EN algorithm and recover the efficiency that it promises compared to Newton's and Broyden's method. 2.3. Inexactness in secant methods. The issue of inexactness in quasi-Newton methods has been examined in <ref> [21, 41] </ref>. Reference [21] is of particular interest since in there it shows the local q-superlinear rate of convergence is still attained for the inexact Broyden's method. In fact, those results are a generalization of the work previously developed by Dembo, Eisenstat and Steihaug in [11].
Reference: [42] <author> J.F. Traub. </author> <title> Iterative methods for the solution of equations. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, </address> <year> 1964. </year>
Reference-contexts: Iterates generated by (11) converge q-superlinearly with q-order 3 [36]. These methods were studied by Shamanskii [40] and Traub <ref> [42] </ref>. They pointed out that even higher-order methods can be built out of a longer sequence of chord steps alternated with regular Newton steps. In a more recent treatment, Kelley names those methods after Shamanskii and compares the particular case (11) numerically against Newton's method [28].
Reference: [43] <author> H.A. van der Vorst and C. Vuik. GMRESR: </author> <title> A Family of Nested GMRES Methods. </title> <type> Technical Report TR91-80, </type> <institution> Technological University of Delft, </institution> <year> 1991. </year>
Reference-contexts: This procedure is better known as the EN algorithm and has been subject of theoretical study and implementation enhancements by several authors <ref> [18, 19, 43, 45, ?, 47] </ref>. These recent developments have shed light on new connections between secant methods and other well established iterative methods.
Reference: [44] <author> C. Vuik. </author> <title> Further experiences with GMRESR. </title> <type> Technical Report TR92-12, </type> <institution> Technological University of Delft, </institution> <year> 1992. </year>
Reference: [45] <author> C. Vuik and H.A. van der Vorst. </author> <title> A comparison of some GMRES-like methods. Linear Alg. </title> <journal> and its Appl., </journal> <volume> 160 </volume> <pages> 131-162, </pages> <year> 1992. </year> <note> 50 REFERENCES </note>
Reference-contexts: This procedure is better known as the EN algorithm and has been subject of theoretical study and implementation enhancements by several authors <ref> [18, 19, 43, 45, ?, 47] </ref>. These recent developments have shed light on new connections between secant methods and other well established iterative methods.
Reference: [46] <author> J.A. Wheeler and R.A. Smith. </author> <title> Reservoir simulation on a hypercube. </title> <booktitle> In 64th Annual Technical Conference and Exhibition of the Society of Petroleum Engineers. SPE paper no. </booktitle> <address> 19804, San Antonio, Texas, </address> <year> 1989. </year>
Reference-contexts: The first two sections of the chapter are devoted to analyze the performance of each one separately. The last section introduces ideas from these two approaches in a parallel black-oil reservoir simulator described by Wheeler and Smith in <ref> [46] </ref> and later improved by Dawson et al. in [10]. In this section we present numerical experiments to illustrate the effectiveness of the algorithms presented here, i.e., the nonlinear KEN and higher order Krylov-Newton (HOKN).
Reference: [47] <author> U.M. Yang. </author> <title> A family of preconditioned iterative solvers for sparse linear systems. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, University of Illinois, Urbana-Champaign, </institution> <year> 1995. </year>
Reference-contexts: This procedure is better known as the EN algorithm and has been subject of theoretical study and implementation enhancements by several authors <ref> [18, 19, 43, 45, ?, 47] </ref>. These recent developments have shed light on new connections between secant methods and other well established iterative methods. <p> These recent developments have shed light on new connections between secant methods and other well established iterative methods. Yang in her doctoral thesis <ref> [47] </ref> provides an interpretation of the EN algorithm for solving nonlinear systems of equations which converge twice as fast as Broyden's method (this result also holds in the linear case). <p> As in the nonlinear case, there are several possible choices for f i : Yang cites a comprehensive list of choices for which we refer the interested reader to <ref> [47] </ref>. In summary, she suggests the "good Broyden's update" f i = M t i p i as the best option. Deuflhard, Freund and Walter [18] incorporate a line-search strategy to refine the proper step length for updating intermediate residuals and solutions. <p> This feature was absent in Broyden's former algorithm [6], making the method to terminate within at most 2n steps [24]. However, Broyden's update with projected updates can converge within at most n steps. (See <ref> [25, 47] </ref> for a detailed discussion on this.) Deuflhard, Freund and Walter found the best choice for this step length is ff i = i r i i q i which turns out to give a competitive procedure with GMRES in terms of convergence and floating point operations. <p> More precisely, the EN algorithm looks one step forward to generarte compared TWO-STAGE PRECONDITIONERS 5 to Broyden's method. Hence, the computational complexity of the EN algorithm approximately doubles both Broyden's and the GMRES algorithm <ref> [18, 47] </ref>. However, the it is about twice faster than the other two. Careful implementations in terms of memory management and computation (through restarts, truncation and implicit updates) give apparently slight advantage to the EN algorithm [47]. Algorithm 2.3. (Nonlinear EN) 1. <p> However, the it is about twice faster than the other two. Careful implementations in terms of memory management and computation (through restarts, truncation and implicit updates) give apparently slight advantage to the EN algorithm <ref> [47] </ref>. Algorithm 2.3. (Nonlinear EN) 1. Give an initial guess u (0) and Jacobian approximation M 0 : 2. <p> Here, we rather adopt the term composite Newton's method for referring to the recurrence (11). Along the lines of Gay's local convergence analysis for Broyden's method, Yang was able to show that the nonlinear EN algorithm converges n-step q-quadratically for n-dimensional problems <ref> [47] </ref>. Therefore, as in the linear case, the nonlinear EN method converges twice as fast as Broyden's method. Hence, the nonlinear EN algorithm converges q-quadratically as Newton's method in the one-dimensional case. Note that the method reduces to a forward finite differ ence method in 1-D [47] which is sometimes referred <p> q-quadratically for n-dimensional problems <ref> [47] </ref>. Therefore, as in the linear case, the nonlinear EN method converges twice as fast as Broyden's method. Hence, the nonlinear EN algorithm converges q-quadratically as Newton's method in the one-dimensional case. Note that the method reduces to a forward finite differ ence method in 1-D [47] which is sometimes referred to as Steffensen's method [36].
References-found: 48

