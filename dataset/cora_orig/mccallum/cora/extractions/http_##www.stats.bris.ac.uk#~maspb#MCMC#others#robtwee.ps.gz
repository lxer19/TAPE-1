URL: http://www.stats.bris.ac.uk/~maspb/MCMC/others/robtwee.ps.gz
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Exponential Convergence of Langevin Diffusions and Their Discrete Approximations  
Author: G. O. Roberts and R. L. Tweedie 
Keyword: 0 Keywords: Hastings algorithms, Metropolis algorithms, Markov chain Monte Carlo, diffusions, Langevin models, discrete approximations, posterior distributions, irreducible Markov processes, ge ometric ergodicity SHORT TITLE: CONVERGENCE OF LANGEVIN DIFFUSIONS  
Web: DMS-9504561  
Note: Work supported in part by NSF Grants DMS-9205687 and  
Date: September 11, 1995  
Affiliation: University of Cambridge and Colorado State University  
Abstract: In this paper we consider a continous time method of approximating a given distribution using the Langevin diffusion dL t = dW t + 1 2 r log (L t )dt: We find conditions under which this diffusion converges exponentially quickly to or does not: in one dimension, these are essentially that for distributions with exponential tails of the form (x) / exp(fljxj fi ), 0 &lt; fi &lt; 1, exponential convergence occurs if and only if fi 1. We then consider conditions under which the discrete approximations to the diffusion converge. We first show that even when the diffusion itself converges, naive discretisations need not do so. We then consider a "Metropolis-adjusted" version of the algorithm, and find conditions under which this also converges at an exponential rate: perhaps surprisingly, even the Metropolised version need not converge exponentially fast even if the diffusion does. We briefly discuss a truncated form of the algorithm which, in practice, should avoid the difficulties of the other forms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.E. Besag. </author> <title> Comments on "Representations of knowledge in complex systems" by U. Grenander and M.I. Miller. </title> <journal> J. Roy. Statist. Soc. Ser. B, </journal> <volume> 56, </volume> <year> 1994. </year>
Reference-contexts: Any naive algorithm using (11) might be constructed in this way, as in Parisi [18] or Grenander and Miller [7]. To form this chain, given U n1 , we simply construct U n according to N (U n1 + 1 As noted by Besag <ref> [1] </ref>, this chain only approximately maintains the invariance of : as a graphic example, if is itself N (0; 1) on IR, then when h = 2, we have each U n ~ N (0; 2) so that clearly if the discretisation step h is this coarse then we get immediate <p> MALA: the Metropolis-adjusted Langevin algorithm Following Besag <ref> [1] </ref>, we therefore introduce a further modification, and follow the structure in (1) and (2) to construct a Metropolis-adjusted Langevin algorithm (MALA). This is a Hastings-Metropolis chain M n which uses ULA to construct the candidate chain.
Reference: [2] <author> J.E. Besag and P.J. Green. </author> <title> Spatial statistics and Bayesian computation (with discussion). </title> <journal> J. Roy. Statist. Soc. Ser. B, </journal> <volume> 55 </volume> <pages> 25-38, </pages> <year> 1993. </year>
Reference-contexts: This is especially relevant when is the posterior distribution in a Bayesian context: see <ref> [2, 3, 12, 22, 24, 25] </ref> for a variety of approaches and properties of such methods, and their applications in statistical modelling. The class of Hastings-Metropolis algorithms is very broad.
Reference: [3] <author> J.E. Besag, P.J. Green, D. Higdon, and K.L. Mengersen. </author> <title> Bayesian computation and stochastic systems (with discussion). </title> <journal> Statistical Science, </journal> <volume> 10 </volume> <pages> 3-66, </pages> <year> 1995. </year>
Reference-contexts: This is especially relevant when is the posterior distribution in a Bayesian context: see <ref> [2, 3, 12, 22, 24, 25] </ref> for a variety of approaches and properties of such methods, and their applications in statistical modelling. The class of Hastings-Metropolis algorithms is very broad.
Reference: [4] <author> R.N. Bhattacharya. </author> <title> Criteria for recurrence and existence of invariant measures for multidimensional diffusions. </title> <journal> Ann. Probab., </journal> <volume> 6 </volume> <pages> 541-553, </pages> <year> 1978. </year>
Reference-contexts: From the conditions on and the constant diffusion coefficient we then have that the the diffusion drift is locally bounded. Therefore the chain is Leb -irreducible and strong Feller, by a straightforward extension (which is possible by non-explosivity) of Theorem 2.1 of Bhattacharya <ref> [4] </ref>, which is due to Stroock and Varadhan. The strong Feller result plus the irreducibility gives that all compact sets are small [26, Theorem 5.1]. The aperiodicity is then obvious since all skeleton chains are also Leb -irreducible.
Reference: [5] <author> M. H. A. Davis. </author> <title> Markov Models and Optimization. </title> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1993. </year>
Reference-contexts: norm convergence in (15) then follows from [15, Theorem 6.1] for all x and we have the result. ut The operator A L , over a domain that contains at least all functions satisfying (16), is easily checked to be the extended generator of L t as described in Davis <ref> [5] </ref>. For our purposes we do not need the exact form of the domain, but merely the form (16) of A L . Note that (14) is certainly not necessary for non-explosivity. However, it should be appropriate for virtually all commonly encountered target densities.
Reference: [6] <author> D. Down, S. P. Meyn, and R. L. Tweedie. </author> <title> Geometric and uniform ergodicity of Markov processes. </title> <journal> Ann. Probab. </journal> <note> (Accepted for publication). </note>
Reference-contexts: We now turn to new results in this area that ensure that the limit is exponentially fast. 2.2 Exponential ergodicity of L t We will use the following approach for exponential ergodicity (see <ref> [15, 6] </ref>). When V 1 is a measurable function on X, we define V -uniform ergodicity by requiring that for all x kP t for some R &lt; 1; &lt; 1. <p> We will use relationships between geometric ergodicity, "exponential recurrence" and the existence of an exponential form of "drift function" equation involving the generator of the process. Many more of these are given in <ref> [15, 6] </ref>, and the full force of (17) is described there in detail. <p> Proof Since C is small, (a) follows from Theorem 5.2 of <ref> [6] </ref> or Theorem 6.1 of [16]: note that since the chain is non-explosive from Theorem 2.1 (a) above, we do not need V to be "normlike" as in that theorem. To see (b) note that if (18) holds, then any ffi-skeleton is also geometrically ergodic.
Reference: [7] <author> U. Grenander and M.I. Miller. </author> <title> Representations of knowledge in complex systems (with discussion). </title> <journal> J. Roy. Statist. Soc. Ser. B, </journal> <volume> 56 </volume> <pages> 549-603, </pages> <year> 1994. </year>
Reference-contexts: We study the convergence properties of these algorithms; and as a precursor to this, we consider the convergence properties of the diffusions themselves, which have recently been suggested as a continuous-time method of approach to this simulation problem <ref> [7] </ref>. In this paper, our main aim will be to study geometric convergence properties of these algorithms. <p> Any naive algorithm using (11) might be constructed in this way, as in Parisi [18] or Grenander and Miller <ref> [7] </ref>.
Reference: [8] <author> W.K. Hastings. </author> <title> Monte Carlo sampling methods using Markov chains and their applications. </title> <journal> Biometrika, </journal> <volume> 57 </volume> <pages> 97-109, </pages> <year> 1970. </year>
Reference-contexts: We do not consider here the problem of how to choose the scaling of such discrete approximations to diffusions. This problem is considered in [19]. In order to describe the approach, it is useful to outline the standard construction of the Hastings and Metropolis algorithms <ref> [13, 8] </ref>. These first consider a candidate transition kernel with densities q (x; y); x; y 2 X, which generates potential transitions for a discrete time Markov chain evolving on X.
Reference: [9] <author> N. Ikeda and S. Watanabe. </author> <title> Stochastic Differential Equations and Diffusion Processes. </title> <publisher> Elsevier, </publisher> <address> Amsterdam, </address> <year> 1989. </year>
Reference-contexts: The strong Feller result plus the irreducibility gives that all compact sets are small [26, Theorem 5.1]. The aperiodicity is then obvious since all skeleton chains are also Leb -irreducible. Under these conditions it follows that is invariant for L t from Section 4 of Chapter 5 of <ref> [9] </ref>: that is, is invariant for P t since by construction it is invariant for the generator of the Langevin diffusion given by A L f (x) = 1 2 r 2 f (x) (16) for any twice continuously differentiable function f . (These functions form a distribution-determining class for a
Reference: [10] <author> J. Lamperti. </author> <title> Criteria for stochastic processes II: passage time moments. </title> <journal> J. Math. Anal. Appl., </journal> <volume> 7 </volume> <pages> 127-145, </pages> <year> 1963. </year>
Reference-contexts: So none of the chains above are geometrically ergodic. And yet in this case the ULA model is indeed ergodic. We take V (x) = x 2 in the Foster drift criterion [14, p. 262] to show this: following the argument in Lamperti <ref> [10] </ref> and being careful with truncations we see that ergodicity will follow if, writing k (x) = E [(U n+1 U n ) k jU n = x] , we can show 2x 1 (x) + 2 (x) " (33) for large enough x &gt; 0 and some " &gt; 0
Reference: [11] <author> H.R. Lerche. </author> <title> Boundary Crossings of Brownian Motion. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, Tokyo, London, </address> <year> 1986. </year>
Reference-contexts: Therefore, P y [t C &gt; t] P y [(Z) &gt; t] ( p ) e 2S (log ) 1=2 St (log ) 1=2 t (24) where denotes the standard normal distribution function, and the final inequality follows from the Bachelier-Levy formula (see for example Lerche <ref> [11] </ref>). Denoting the density of (B) by f , it is therefore easy to check that log f (t) ! 2 which contradicts (20).
Reference: [12] <author> K.L. Mengersen and R.L. Tweedie. </author> <title> Rates of convergence of the Hastings and Metropolis algorithms. </title> <journal> Annals of Statistics. </journal> <note> (To appear). </note>
Reference-contexts: This is especially relevant when is the posterior distribution in a Bayesian context: see <ref> [2, 3, 12, 22, 24, 25] </ref> for a variety of approaches and properties of such methods, and their applications in statistical modelling. The class of Hastings-Metropolis algorithms is very broad. <p> k := 1 A2B In this paper we consider special forms of the density q based on the Langevin diffusion model below, and find conditions leading to geometric convergence in (4): in the cases where q (x; y) = q (jx yj) (the Metropolis algorithm) this has been addressed in <ref> [12, 22] </ref> and our results for the Langevin-based models can be compared with those. <p> This is exactly similar behaviour to the symmetric or random walk algorithm as shown in Theorem 3.5 of <ref> [12] </ref>. <p> &lt; 1, the diffusion is exponentially ergodic by Theorem 2.3; (b) for 0 &lt; fi &lt; 1; jr log (x)j ! 0 so that by Theorem 2.4, the diffusion is not exponentially ergodic. 3 ULA: The unadjusted Langevin algorithm 9 This mimics exactly the behaviour found in Section 3 of <ref> [12] </ref> for Metropolis algorithms in one dimension: the exponential convergence is governed by the tails of the target density, and occurs if and only if those tails decrease at least exponentially quickly. The multidimensional class P m For higher dimensional models our results are not as complete. <p> we would expect that this might be null recurrent. rejection (d) For fi &gt; 2, when the tails are light, it follows from Theorem 3.2 that (perhaps surprisingly at first sight) the ULA chain is transient: this is in contrast to the case with the random walk Metropolis algorithm in <ref> [12] </ref>, where such chains are shown to be geometrically ergodic. In this situation the ULA over-corrects for the light tails by throwing the chain in increasing oscillations.
Reference: [13] <author> N. Metropolis, A. Rosenbluth, M. Rosenbluth, A. Teller, and E. Teller. </author> <title> Equations of state calculations by fast computing machines. </title> <journal> J. Chemical Physics, </journal> <volume> 21 </volume> <pages> 1087-1091, </pages> <year> 1953. </year>
Reference-contexts: We do not consider here the problem of how to choose the scaling of such discrete approximations to diffusions. This problem is considered in [19]. In order to describe the approach, it is useful to outline the standard construction of the Hastings and Metropolis algorithms <ref> [13, 8] </ref>. These first consider a candidate transition kernel with densities q (x; y); x; y 2 X, which generates potential transitions for a discrete time Markov chain evolving on X.
Reference: [14] <author> S. P. Meyn and R. L. Tweedie. </author> <title> Markov Chains and Stochastic Stability. </title> <publisher> Springer-Verlag, </publisher> <address> London, </address> <year> 1993. </year>
Reference-contexts: (x) = P (x; fxg) = q (x; y)[1 ff (x; y)]dy: (3) With this choice of ff we have that is invariant: that is, satisfies (A) = R (x)P (x; A)dx; x 2 X; A 2 B: Provided the chain is suitably irreducible and aperiodic, it is then standard <ref> [14, Chapter 13] </ref>, [21] that the n-step transition probabilities, defined for each n 1 by P n (x; A) = P ( n 2 Aj 0 = x); x 2 X; A 2 B; converge to in the total variation norm: that is, for for -a.e x kP n (x; ) <p> The hitting time on C for the ffi-skeleton is at least as large as t ffi C and since any compact non-empty C is small for the skeleton because L t is strong Feller, we have that (20) follows from Theorem 15.0.1 of <ref> [14] </ref>. ut We now use these results to classify the behaviour of L t in much more concrete terms. Theorem 2.3 Suppose there exists S &gt; 0 such that j (x)j is bounded for jxj S. <p> This is easily seen to be Leb -irreducible and weak Feller, provided r log (x) is continuous, and hence as in Chapter 6 of <ref> [14] </ref>, all compact sets are small, and it suffices for geometric ergodicity from Theorem 15.0.1 of [14] to find a function V 1 such that for some compact set C and some &lt; 1; b &lt; 1 Z Note that this is the discrete version of (19). <p> This is easily seen to be Leb -irreducible and weak Feller, provided r log (x) is continuous, and hence as in Chapter 6 of <ref> [14] </ref>, all compact sets are small, and it suffices for geometric ergodicity from Theorem 15.0.1 of [14] to find a function V 1 such that for some compact set C and some &lt; 1; b &lt; 1 Z Note that this is the discrete version of (19). Under some circumstances the discrete approximation is well behaved and under others it is not. <p> We can then show exactly as in the argument in pp. 318-319 of <ref> [14] </ref> that for some sufficiently small s the function V (y) = e sjyj satisfies (29), and geometric ergodicity follows. 3 ULA: The unadjusted Langevin algorithm 11 For d 2 (0; 1) the argument is virtually identical. <p> Now, rather than the random walk, the analogue we use in this case is the SETAR model in non-linear time-series. Following the proof of Proposition 11.4.5 of <ref> [14] </ref> (see also [14, p. 505]) let us choose V (x) = ax; x &gt; x 0 and V (x) = bjxj; x x 0 . <p> Now, rather than the random walk, the analogue we use in this case is the SETAR model in non-linear time-series. Following the proof of Proposition 11.4.5 of [14] (see also <ref> [14, p. 505] </ref>) let us choose V (x) = ax; x &gt; x 0 and V (x) = bjxj; x x 0 . <p> Again the formal verification follows the proof of transience for the SETAR model: see <ref> [14, p. 222] </ref>. The other case (a) requires rather more subtlety. To see the chain cannot be geometrically ergodic, we use Theorem 15.0.1 of [14]. <p> Again the formal verification follows the proof of transience for the SETAR model: see [14, p. 222]. The other case (a) requires rather more subtlety. To see the chain cannot be geometrically ergodic, we use Theorem 15.0.1 of <ref> [14] </ref>. Note first that for large x, from U 0 = x the expected increment is approximately S + d x d ! 0, 3 ULA: The unadjusted Langevin algorithm 12 x ! 1. <p> So none of the chains above are geometrically ergodic. And yet in this case the ULA model is indeed ergodic. We take V (x) = x 2 in the Foster drift criterion <ref> [14, p. 262] </ref> to show this: following the argument in Lamperti [10] and being careful with truncations we see that ergodicity will follow if, writing k (x) = E [(U n+1 U n ) k jU n = x] , we can show 2x 1 (x) + 2 (x) " (33) <p> Clearly other behaviour is possible for sufficiently pathologically constructed tail be haviour of : as in the SETAR examples in <ref> [14] </ref>, various combinations of null recurrence and positive recurrence may occur. We do not pursue this here: our goal was to show that the ULA model is not guaranteed to behave well, more or less independently in most cases of the choice of h. <p> Moreover, the second term asymptotically converges to zero since A () converges inwards in q. Hence lim sup P V s (x) &lt; 1 so that, noting that compact sets are small from [22], geometric convergence in V s norm is guaranteed by Theorem 15.0.1 of <ref> [14] </ref>. ut We note from the steps of the proof that condition (35) is far from necessary. <p> since we accept essentially all proposals in this case, the MALA chain from positive x is in effect just a random walk with negative drift on the positive half-line and with (more than) exponentially decreasing right tails; and this can be shown to be geometrically ergodic using the argument in <ref> [14, Section 16.1.3] </ref>. (c) For 1 &lt; fi &lt; 2 and for x &gt; 0, the candidate density q (x; y) is concentrated near x [hflfi=2]x fi1 , and this is a value between 0 and x for x large.
Reference: [15] <author> S. P. Meyn and R. L. Tweedie. </author> <title> Stability of Markovian processes II: Continuous time processes and sampled chains. </title> <journal> Adv. Appl. Probab., </journal> <volume> 25 </volume> <pages> 487-517, </pages> <year> 1993. </year>
Reference-contexts: For the concepts of Leb -irreducibility, aperiodicity and small sets, the reader should see <ref> [15] </ref>. <p> Since the process has a stationary distribution it is at least recurrent, from [26, Theorem 2.3 ], and the continuity of the sample paths ensures that this extends to Harris recurrence. The total variation norm convergence in (15) then follows from <ref> [15, Theorem 6.1] </ref> for all x and we have the result. ut The operator A L , over a domain that contains at least all functions satisfying (16), is easily checked to be the extended generator of L t as described in Davis [5]. <p> We now turn to new results in this area that ensure that the limit is exponentially fast. 2.2 Exponential ergodicity of L t We will use the following approach for exponential ergodicity (see <ref> [15, 6] </ref>). When V 1 is a measurable function on X, we define V -uniform ergodicity by requiring that for all x kP t for some R &lt; 1; &lt; 1. <p> When V 1 is a measurable function on X, we define V -uniform ergodicity by requiring that for all x kP t for some R &lt; 1; &lt; 1. As is shown in <ref> [15] </ref>, this strong form of exponential ergodicity is in fact implied (for some V 1) by the seemingly simpler requirement that kP t for some R x &lt; 1; &lt; 1 and all x. <p> We will use relationships between geometric ergodicity, "exponential recurrence" and the existence of an exponential form of "drift function" equation involving the generator of the process. Many more of these are given in <ref> [15, 6] </ref>, and the full force of (17) is described there in detail.
Reference: [16] <author> S. P. Meyn and R. L. Tweedie. </author> <title> Stability of Markovian processes III: Foster-Lyapunov criteria for continuous time processes. </title> <journal> Adv. Appl. Probab., </journal> <volume> 25 </volume> <pages> 518-548, </pages> <year> 1993. </year>
Reference-contexts: Proof Since C is small, (a) follows from Theorem 5.2 of [6] or Theorem 6.1 of <ref> [16] </ref>: note that since the chain is non-explosive from Theorem 2.1 (a) above, we do not need V to be "normlike" as in that theorem. To see (b) note that if (18) holds, then any ffi-skeleton is also geometrically ergodic.
Reference: [17] <author> R. Neal. </author> <title> An improved acceptance procedure for the hybrid Monte Carlo algorithm. </title> <journal> J. Comp. Phys, </journal> <volume> 11 </volume> <pages> 194-203, </pages> <year> 1994. </year>
Reference-contexts: Other recently proposed algorithms such as hybrid-Monte Carlo algorithms (see for example Neal <ref> [17] </ref>), are related to the class of Langevin algorithms, although in this paper we will content ourselves with a detailed study of the simplest kind of Langevin algorithm, constructed from the natural reversible diffusion process.
Reference: [18] <author> G. Parisi. </author> <title> Correlation functions and computer simulations. </title> <journal> Nuclear Physics B, </journal> <volume> 180 </volume> <pages> 378-384, </pages> <year> 1983. </year>
Reference-contexts: ULA: the Unadjusted Langevin Algorithm The Unadjusted Langevin Algorithm (ULA) is a discrete time Markov chain U n which is the natural discretisation of the ordinary Langevin diffusion L t . Any naive algorithm using (11) might be constructed in this way, as in Parisi <ref> [18] </ref> or Grenander and Miller [7]. <p> practice is to use the unadjusted Langevin algorithm (ULA): that is, use a first order Gaussian approxi mation to the diffusion distributions on a grid of size h and construct U n jU n1 ~ N (U n1 + 1 3 ULA: The unadjusted Langevin algorithm 10 as in Parisi <ref> [18] </ref>.
Reference: [19] <author> G.O. Roberts and J.S. Rosenthal. </author> <title> Optimal scaling of discrete approximations to langevin diffusions. </title> <note> (Submitted for publication). </note>
Reference-contexts: We indicate a truncated and "Metropolised" form of the discreti-sation which, in practical circumstances, will avoid such rather surprising pathologies. We do not consider here the problem of how to choose the scaling of such discrete approximations to diffusions. This problem is considered in <ref> [19] </ref>. In order to describe the approach, it is useful to outline the standard construction of the Hastings and Metropolis algorithms [13, 8]. <p> Moreover, since the algorithm behaves like MALA except in extreme situations, it will inherit most of the other desirable rapid convergence properties of MALA, and for example the complexity result of <ref> [19] </ref> for high dimensional MALA algorithms will also hold for MALTA.
Reference: [20] <author> G.O. Roberts and J.S. Rosenthal. </author> <title> Shift-coupling and convergence rates of ergodic averages. </title> <note> (Submitted for publication). </note>
Reference-contexts: In principle this should be a good choice of q, since even before being "Metropolised" using (1), the candidate chain approximates one with stationary distribution . The improvement in using this algorithm rather than a simple random walk candidate is also considered in <ref> [20] </ref>, from different perspectives. We assume that is everywhere non-zero and differentiable so that r log (x) is well defined.
Reference: [21] <author> G.O. Roberts and A.F.M. Smith. </author> <title> Simple conditions for the convergence of the Gibbs sampler and Hastings-Metropolis algorithms. </title> <journal> Stoch. Proc. Applns., </journal> <volume> 49 </volume> <month> 207-216 </month> <year> 1994. </year> <note> References 22 </note>
Reference-contexts: (x; fxg) = q (x; y)[1 ff (x; y)]dy: (3) With this choice of ff we have that is invariant: that is, satisfies (A) = R (x)P (x; A)dx; x 2 X; A 2 B: Provided the chain is suitably irreducible and aperiodic, it is then standard [14, Chapter 13], <ref> [21] </ref> that the n-step transition probabilities, defined for each n 1 by P n (x; A) = P ( n 2 Aj 0 = x); x 2 X; A 2 B; converge to in the total variation norm: that is, for for -a.e x kP n (x; ) k := 1
Reference: [22] <author> G.O. Roberts and R.L. Tweedie. </author> <title> Geometric convergence and central limit theorems for multidimensional Hastings and Metropolis algorithms. </title> <journal> Biometrika. </journal> <note> (To appear). </note>
Reference-contexts: This is especially relevant when is the posterior distribution in a Bayesian context: see <ref> [2, 3, 12, 22, 24, 25] </ref> for a variety of approaches and properties of such methods, and their applications in statistical modelling. The class of Hastings-Metropolis algorithms is very broad. <p> The former is easy to implement, and it can be demonstrated that the random walk algorithm has rather robust theoretical properties (see for example <ref> [22] </ref>). However, in practice, a more problem specific algorithm may converge more rapidly. We will be concerned here with one such class of algorithms. <p> In this paper, our main aim will be to study geometric convergence properties of these algorithms. For a discussion of some of the stability properties enjoyed by geometrically ergodic chains in simulation, which motivate our evaluations, we refer the reader to <ref> [22] </ref>: we note for example that such chains have Central Limit Theorems and the like available, which makes it much easier to assess the algorithms. <p> k := 1 A2B In this paper we consider special forms of the density q based on the Langevin diffusion model below, and find conditions leading to geometric convergence in (4): in the cases where q (x; y) = q (jx yj) (the Metropolis algorithm) this has been addressed in <ref> [12, 22] </ref> and our results for the Langevin-based models can be compared with those. <p> This is exactly similar behaviour to the symmetric or random walk algorithm as shown in Theorem 3.5 of [12]. The Multidimensional Exponential Class P m For higher dimensional models we consider the exponential family P m introduced and studied in the context of the random walk Metropolis algorithm in <ref> [22] </ref>, and consisting of sufficiently smooth densities with the form (at least for large jxj) (x) / e p (x) (8) where p is a polynomial of degree m of the following type. <p> We will see that there is exponential convergence of the multidimensional diffusion if 2 P m . This behaviour is identical to that exhibited by the multidimensional random walk algorithm, as shown in <ref> [22] </ref>. 1 The Langevin method for MCMC 4 1.4 Discrete Approximations to L t In practice, of course, one implements a discrete approximation to the diffusion L t , and we will also consider when such discrete approximations converge to , and when they do so geometrically fast. <p> construction as in (2) and (3), the MALA chain converges to , in the sense that kP n for -a.e x where we write P n M (x; A) = P (M n 2 AjM 0 = x): this follows since the chain is clearly Leb -irreducible and aperiodic from <ref> [22] </ref>. As a minor but useful byproduct 2 Exponential convergence of the Langevin diffusion algorithm 5 of our results we show that in the geometrically ergodic case the convergence holds from all starting points also. <p> With MALTA, the chain has much more robust geometric ergodicity properties. We do not pursue a detailed analysis of MALTA, merely pointing out that the methods employed in this paper and in <ref> [22] </ref> are readily transportable to the analysis of this algorithm. 2 Exponential convergence of the Langevin diffusion algorithm 2.1 General convergence results In this section we apply convergence properties of general diffusions to the Langevin diffusion. <p> Exponential convergence of the Langevin diffusion for all 2 P m therefore follows from Theorem 2.3. Continuing to follow the type of example contained in <ref> [22] </ref>, we examine the situation where has the exponential form (8), but where the positive definiteness condition does not hold. <p> Moreover, the second term asymptotically converges to zero since A () converges inwards in q. Hence lim sup P V s (x) &lt; 1 so that, noting that compact sets are small from <ref> [22] </ref>, geometric convergence in V s norm is guaranteed by Theorem 15.0.1 of [14]. ut We note from the steps of the proof that condition (35) is far from necessary. <p> Theorem 4.2 If is bounded, and lim inf jr log (x)j &gt; h then the MALA chain is not exponentially ergodic. Proof Let r (x) to be the rejection probability from each point as in (3): we know from <ref> [22] </ref> that if ess sup r (x) = 1 then the algorithm is not geometrically ergodic. <p> Then lim inf jr log (x)j = 1 so that MALA is not geometrically ergodic, no matter how small h is chosen to be. Note that in contrast, the random walk Metropolis algorithm is always geometric for 2 P m (see <ref> [22] </ref>). A slowly converging Bayesian algorithm The examples we have used so far are all simple, although they do indicate the range of good and bad behaviours we might expect.
Reference: [23] <author> S.-J. Sheu. </author> <title> Some estimates of the transition density of a non-degenerate diffusion Markov process. </title> <journal> Ann. Probab., </journal> <volume> 19 </volume> <pages> 538-561, </pages> <year> 1992. </year>
Reference-contexts: However, it is worth remarking that often methods induced by non reversible methods can be shown to converge quicker than their reversible counter parts (see for example <ref> [23] </ref>). 1.2 The Langevin diffusion The form of the candidate density which we study is derived from the Langevin diffusion, which is itself constructed so that in continuous time it converges to under suitable regularity conditions.
Reference: [24] <author> A.F.M. Smith and G.O. Roberts. </author> <title> Bayesian computation via the Gibbs sampler and related Markov chain Monte Carlo methods (with discussion). </title> <journal> J. Roy. Statist. Soc. Ser. B, </journal> <volume> 55 </volume> <pages> 3-24, </pages> <year> 1993. </year>
Reference-contexts: This is especially relevant when is the posterior distribution in a Bayesian context: see <ref> [2, 3, 12, 22, 24, 25] </ref> for a variety of approaches and properties of such methods, and their applications in statistical modelling. The class of Hastings-Metropolis algorithms is very broad.
Reference: [25] <author> L. Tierney. </author> <title> Markov chains for exploring posterior distributions (with discussion). </title> <journal> Ann. Statist., </journal> <volume> 22 </volume> <pages> 1701-1762, </pages> <year> 1994. </year>
Reference-contexts: This is especially relevant when is the posterior distribution in a Bayesian context: see <ref> [2, 3, 12, 22, 24, 25] </ref> for a variety of approaches and properties of such methods, and their applications in statistical modelling. The class of Hastings-Metropolis algorithms is very broad.
Reference: [26] <author> R. L. Tweedie. </author> <title> Topological conditions enabling use of Harris methods in discrete and continuous time. </title> <journal> Acta Applic. Math., </journal> <volume> 34 </volume> <pages> 175-188, </pages> <year> 1994. </year>
Reference-contexts: Therefore the chain is Leb -irreducible and strong Feller, by a straightforward extension (which is possible by non-explosivity) of Theorem 2.1 of Bhattacharya [4], which is due to Stroock and Varadhan. The strong Feller result plus the irreducibility gives that all compact sets are small <ref> [26, Theorem 5.1] </ref>. The aperiodicity is then obvious since all skeleton chains are also Leb -irreducible. <p> Since the process has a stationary distribution it is at least recurrent, from <ref> [26, Theorem 2.3 ] </ref>, and the continuity of the sample paths ensures that this extends to Harris recurrence.
References-found: 26

