URL: http://www.cs.duke.edu/~large/Papers/obdd.ps
Refering-URL: http://www.cs.duke.edu/~large/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: The I/O-Complexity of Ordered Binary-Decision Diagram Manipulation (Extended Abstract)  
Author: Lars Arge 
Address: Aarhus, Aarhus, Denmark  
Affiliation: BRICS Department of Computer Science, University of  
Abstract: We analyze the I/O-complexity of existing Ordered Binary-Decision Diagram manipulation algorithms and develop new efficient algorithms. We show that these algorithms are optimal in all realistic 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> A. Aggarwal, J.S. Vitter: </author> <title> The Input/Output Complexity of Sorting and Related Problems. </title> <journal> Communications of the ACM, </journal> <volume> 31 (9), </volume> <year> 1988. </year>
Reference-contexts: At present, technological advances are increasing CPU speed at an annual rate of 40-60% while disk transfer rates are only increasing by 7-10% annually [17]. 1.1 I/O-model and Previous Results In this paper we will be working in the parallel I/O-model introduced by Aggar-wal and Vitter <ref> [1] </ref> which models the I/O-system of many existing workstations. <p> Typical values for workstations and file servers in production today are on the order of 10 6 M 10 8 , B ' 10 3 and D ' 10 1 . Early work on external-memory algorithms concentrated on sorting and permutation-related problems <ref> [1, 20] </ref>. More recently researchers have designed external memory algorithms for a number of problems in different areas. Most notably I/O-efficient algorithms have been developed for a large number of computational geometry [3, 12] and graph problems [9]. <p> Some notes should be made about the typical bounds in the model. While N=(DB) is the number of I/Os needed to read all the input, fi ( N DB log M=B B ) = fi (sort (N )) is the number of I/Os needed to sort N elements <ref> [1] </ref>. Furthermore, the number of I/Os needed to rearrange N elements according to a given permutation is fi (minfN=D; sort (N )g) = fi (perm (N )).
Reference: 2. <author> L. Arge: </author> <title> The Buffer Tree: A New Technique for Optimal I/O-Algorithms. </title> <booktitle> In Proc. of 4th Workshop on Algorithms and Data Structures, </booktitle> <year> 1995. </year>
Reference-contexts: Most notably I/O-efficient algorithms have been developed for a large number of computational geometry [3, 12] and graph problems [9]. Also worth noticing in this context is [11] that addresses the problem of storing graphs in a paging-environment, but not the problem of performing computation on them, and <ref> [2] </ref> where a number of external (batched) dynamic data structures are developed. Finally, it is demonstrated in [8, 19] that the results obtained in the mentioned papers are not only of theoretical but also of great practical interest. Some notes should be made about the typical bounds in the model. <p> Every time we give a vertex v a new label, we insert an element in the I/O-efficient priority-queue developed in <ref> [2] </ref> for each of the immediate predecessors of v. <p> As the number of operations performed on the queue is linear in jGj, it follows from the O ((log M=B N=B)=(DB)) amortized I/O-bound on the insert and deletemin operation proven in <ref> [2] </ref> that we overall use O (sort (jGj)) I/Os to manipulate the queue. In the full paper we will give all the details in the algorithm and prove the following: Theorem 6. An OBDD with jGj vertices can be reduced in O (sort (jGj)) I/Os.
Reference: 3. <author> L. Arge, D.E. Vengroff, J.S. Vitter: </author> <title> External-Memory Algorithms for Processing Line Segments in Geographic Information Systems. </title> <booktitle> In Proc. of 3rd Annual European Symposium on Algorithms, </booktitle> <year> 1995. </year>
Reference-contexts: Early work on external-memory algorithms concentrated on sorting and permutation-related problems [1, 20]. More recently researchers have designed external memory algorithms for a number of problems in different areas. Most notably I/O-efficient algorithms have been developed for a large number of computational geometry <ref> [3, 12] </ref> and graph problems [9]. Also worth noticing in this context is [11] that addresses the problem of storing graphs in a paging-environment, but not the problem of performing computation on them, and [2] where a number of external (batched) dynamic data structures are developed.
Reference: 4. <author> P. Ashar, M. Cheong: </author> <title> Efficient Breadth-First Manipulation of Binary Decision Diagrams. </title> <booktitle> In Proc. of 1994 IEEE International Conference on CAD. </booktitle>
Reference-contexts: There exist implementations of OBDD software packages on a number of sequential and parallel machines <ref> [4, 5, 14, 15] </ref>. Even though there exist very different sized OBDD representations of the same boolean function, OBDDs in real applications tend to be very large. <p> There exist implementations of OBDD software packages on a number of sequential and parallel machines [4, 5, 14, 15]. Even though there exist very different sized OBDD representations of the same boolean function, OBDDs in real applications tend to be very large. In <ref> [4] </ref> for example OBDDs of Gigabyte size are manipulated in order to verify logic circuit designs, and researchers in this area would like to be able to manipulate orders of magnitude larger OBDDs. In such cases the Input/Output (I/O) communication becomes the bottleneck in the computation. <p> Very recently however, researchers have begun to consider I/O-issues arising when the OBDDs get larger than the available internal memory, and experimental results show that very large speedups can be achieved with algorithms that try to minimize the access to external storage as much as possible <ref> [4, 15] </ref>. These speedups can be achieved because of the extremely large access time of external storage medias, such as disks, compared to the access time of internal memory. <p> Existing apply and reduce algorithms run in O (jGj) and O (jG 1 j jG 2 j) time, respectively <ref> [4, 6, 7, 14, 15, 18] </ref>. Here jGj denote the size (the number of vertices) of the OBDD G. <p> Here jGj denote the size (the number of vertices) of the OBDD G. Even though the I/O-system (the size of the internal memory) seems to be the primary limitation on the size of the OBDD problems one is able to solve practically today <ref> [4, 5, 6, 7, 15] </ref>, it was only very recently that OBDD manipulation algorithms especially designed to minimize I/O was developed. <p> In <ref> [4] </ref> and [15] it is realized that the traditional algorithms working in a depth-first or breadth-first manner on the involved OBDDs does not perform well when the OBDDs are too large to fit in internal memory, and new level-wise algorithms are developed. 3 The general idea in these algorithms is to <p> Previous algorithms did not explicitly block the OBDDs. In <ref> [4, 15] </ref> speed-ups of several hundreds compared to the "traditional" algorithms are reported using this idea. In the rest of this paper we assume that an OBDD is stored as a number of vertices and that the edges are stored implicitly in these. <p> As discussed in section 1.1 this is asymptotically optimal for all realistic I/O-systems. We believe that the developed algorithms are of practical interest due to relatively small constants in the asymptotic bounds. 2 The Reduce Operation All the reduction algorithms <ref> [4, 6, 7, 14, 15] </ref> reported in the literature basically work in the same way. They all process the vertices level-wise from the sinks up to the root and assign a (new) unique integer label to each unique sub-OBDD root. <p> As mentioned in the introduction, Theorem 5 and Theorem 6 together means that for all realistic I/O-systems we have developed an asymptotically optimal reduction algorithm. 3 The Apply Algorithm The basic idea in all existing apply algorithms <ref> [4, 6, 7, 14, 15] </ref> is to use the recursive formula f 1 f 2 = x i (f 1 j x i =0 f 2 j x i =0 ) + x i (f 1 j x i =1 f 2 j x i =1 ) to design a recursive <p> Here fj x i =b denotes the function obtained from f when the argument x i is replaced by the boolean constant b, and is some binary operator. Using this formula Bryant [6] developed a recursive algorithm working in a depth-first manner on the involved OBDDs. In [14] and <ref> [4, 15] </ref> algorithms working in a breadth-first and in a level-wise manner are then developed. <p> discuss this in detail and show that all the known algorithms in the worst case use (jG 1 j jG 2 j) I/Os when trying to do an apply operation. 5 3.1 I/O-Efficient Apply Algorithm The main idea in our apply algorithm is to do the computation level-wise as in <ref> [4, 15] </ref>, but to use a priority-queue to control the recursion. Using a priority-queue we do not need to have a queue for each level. <p> However, we believe that one major reason for the experimental success in <ref> [4] </ref> is that the OBDDs in the experiments roughly are of the size of the internal memory of the machines used. This means that one level of the OBDDs actually fits in internal memory.
Reference: 5. <author> S.K. Brace, R.L. Rudell, R.E. Bryant: </author> <title> Efficient Implementation of a BDD Package. </title> <booktitle> In Proc. of 27'th ACM/IEEE Design Automation Conference, </booktitle> <year> 1990. </year>
Reference-contexts: There exist implementations of OBDD software packages on a number of sequential and parallel machines <ref> [4, 5, 14, 15] </ref>. Even though there exist very different sized OBDD representations of the same boolean function, OBDDs in real applications tend to be very large. <p> In such cases the Input/Output (I/O) communication becomes the bottleneck in the computation. Until recently most research, both theoretical and practical, have concentrated on finding small OBDD-representations of boolean functions appearing in specific problems <ref> [5, 7, 13, 16] </ref>, or on finding alternative succinct representations while maintaining the efficient manipulation algorithms [10]. <p> Here jGj denote the size (the number of vertices) of the OBDD G. Even though the I/O-system (the size of the internal memory) seems to be the primary limitation on the size of the OBDD problems one is able to solve practically today <ref> [4, 5, 6, 7, 15] </ref>, it was only very recently that OBDD manipulation algorithms especially designed to minimize I/O was developed.
Reference: 6. <author> R. Bryant: </author> <title> Graph-Based Algorithms for Boolean Function Manipulation. </title> <journal> IEEE Transactions on computers, </journal> <volume> C-35 (8), </volume> <year> 1986. </year>
Reference-contexts: 1 Introduction Ordered Binary-Decision Diagrams (OBDDs) <ref> [6, 7] </ref> are the state-of-the-art data structure for boolean function manipulation and they have been successfully used to solve problems from numerous areas like e.g. digital-systems design, verification and testing, mathematical logic, concurrent system design and artificial intelligence [7]. <p> There exist several algorithms (using heuristics) for choosing a variable-ordering that minimize the OBDD-representation of a given function [13, 16]. In <ref> [6] </ref> Bryant proved that for a given variable ordering and a given boolean function there is (up to isomorphism) exactly one OBDD | called the reduced OBDD | of minimal size. He also showed that the there are two fundamental operations on OBDDs | the reduce and the apply operation. <p> Existing apply and reduce algorithms run in O (jGj) and O (jG 1 j jG 2 j) time, respectively <ref> [4, 6, 7, 14, 15, 18] </ref>. Here jGj denote the size (the number of vertices) of the OBDD G. <p> Here jGj denote the size (the number of vertices) of the OBDD G. Even though the I/O-system (the size of the internal memory) seems to be the primary limitation on the size of the OBDD problems one is able to solve practically today <ref> [4, 5, 6, 7, 15] </ref>, it was only very recently that OBDD manipulation algorithms especially designed to minimize I/O was developed. <p> As discussed in section 1.1 this is asymptotically optimal for all realistic I/O-systems. We believe that the developed algorithms are of practical interest due to relatively small constants in the asymptotic bounds. 2 The Reduce Operation All the reduction algorithms <ref> [4, 6, 7, 14, 15] </ref> reported in the literature basically work in the same way. They all process the vertices level-wise from the sinks up to the root and assign a (new) unique integer label to each unique sub-OBDD root. <p> As mentioned in the introduction, Theorem 5 and Theorem 6 together means that for all realistic I/O-systems we have developed an asymptotically optimal reduction algorithm. 3 The Apply Algorithm The basic idea in all existing apply algorithms <ref> [4, 6, 7, 14, 15] </ref> is to use the recursive formula f 1 f 2 = x i (f 1 j x i =0 f 2 j x i =0 ) + x i (f 1 j x i =1 f 2 j x i =1 ) to design a recursive <p> Here fj x i =b denotes the function obtained from f when the argument x i is replaced by the boolean constant b, and is some binary operator. Using this formula Bryant <ref> [6] </ref> developed a recursive algorithm working in a depth-first manner on the involved OBDDs. In [14] and [4, 15] algorithms working in a breadth-first and in a level-wise manner are then developed.
Reference: 7. <author> R. Bryant: </author> <title> Symbolic Boolean Manipulation with Ordered Binary-Decision Diagrams. </title> <journal> ACM Computing Surveys, </journal> <volume> 24 (3), </volume> <year> 1992. </year>
Reference-contexts: 1 Introduction Ordered Binary-Decision Diagrams (OBDDs) <ref> [6, 7] </ref> are the state-of-the-art data structure for boolean function manipulation and they have been successfully used to solve problems from numerous areas like e.g. digital-systems design, verification and testing, mathematical logic, concurrent system design and artificial intelligence [7]. <p> 1 Introduction Ordered Binary-Decision Diagrams (OBDDs) [6, 7] are the state-of-the-art data structure for boolean function manipulation and they have been successfully used to solve problems from numerous areas like e.g. digital-systems design, verification and testing, mathematical logic, concurrent system design and artificial intelligence <ref> [7] </ref>. There exist implementations of OBDD software packages on a number of sequential and parallel machines [4, 5, 14, 15]. Even though there exist very different sized OBDD representations of the same boolean function, OBDDs in real applications tend to be very large. <p> In such cases the Input/Output (I/O) communication becomes the bottleneck in the computation. Until recently most research, both theoretical and practical, have concentrated on finding small OBDD-representations of boolean functions appearing in specific problems <ref> [5, 7, 13, 16] </ref>, or on finding alternative succinct representations while maintaining the efficient manipulation algorithms [10]. <p> Existing apply and reduce algorithms run in O (jGj) and O (jG 1 j jG 2 j) time, respectively <ref> [4, 6, 7, 14, 15, 18] </ref>. Here jGj denote the size (the number of vertices) of the OBDD G. <p> Here jGj denote the size (the number of vertices) of the OBDD G. Even though the I/O-system (the size of the internal memory) seems to be the primary limitation on the size of the OBDD problems one is able to solve practically today <ref> [4, 5, 6, 7, 15] </ref>, it was only very recently that OBDD manipulation algorithms especially designed to minimize I/O was developed. <p> As discussed in section 1.1 this is asymptotically optimal for all realistic I/O-systems. We believe that the developed algorithms are of practical interest due to relatively small constants in the asymptotic bounds. 2 The Reduce Operation All the reduction algorithms <ref> [4, 6, 7, 14, 15] </ref> reported in the literature basically work in the same way. They all process the vertices level-wise from the sinks up to the root and assign a (new) unique integer label to each unique sub-OBDD root. <p> As mentioned in the introduction, Theorem 5 and Theorem 6 together means that for all realistic I/O-systems we have developed an asymptotically optimal reduction algorithm. 3 The Apply Algorithm The basic idea in all existing apply algorithms <ref> [4, 6, 7, 14, 15] </ref> is to use the recursive formula f 1 f 2 = x i (f 1 j x i =0 f 2 j x i =0 ) + x i (f 1 j x i =1 f 2 j x i =1 ) to design a recursive
Reference: 8. <author> Y.-J. Chiang: </author> <title> Experiments on the Practical I/O Efficiency of Geometric Algorithms: Distribution Sweep vs. Plane Sweep. </title> <booktitle> In Proc. of 4th Workshop on Algorithms and Data Structures, </booktitle> <year> 1995. </year>
Reference-contexts: Also worth noticing in this context is [11] that addresses the problem of storing graphs in a paging-environment, but not the problem of performing computation on them, and [2] where a number of external (batched) dynamic data structures are developed. Finally, it is demonstrated in <ref> [8, 19] </ref> that the results obtained in the mentioned papers are not only of theoretical but also of great practical interest. Some notes should be made about the typical bounds in the model.
Reference: 9. <author> Y.-J. Chiang, M.T. Goodrich, E.F. Grove, R. Tamassia, D.E. Vengroff, J.S. Vitter: </author> <title> External-Memory Graph Algorithms. </title> <booktitle> In Proc. of 6th ACM/SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1995. </year>
Reference-contexts: Early work on external-memory algorithms concentrated on sorting and permutation-related problems [1, 20]. More recently researchers have designed external memory algorithms for a number of problems in different areas. Most notably I/O-efficient algorithms have been developed for a large number of computational geometry [3, 12] and graph problems <ref> [9] </ref>. Also worth noticing in this context is [11] that addresses the problem of storing graphs in a paging-environment, but not the problem of performing computation on them, and [2] where a number of external (batched) dynamic data structures are developed. <p> The precise assumption is that the new label is assigned to the original vertex, and that the sons are loaded into internal memory (if they are not there already) in order to obtain their new labels. In <ref> [9] </ref> the proximate neighbors problem is defined as follows: We are given N elements in external memory, each with a key that is a positive integer k N=2. For each possible value of k, exactly two elements have that key-value. <p> This problem is defined similar to the proximate neighbors problem, except that we require that the keys of the first N=2 elements in external memory (and consequently also the last N=2 elements) are distinct. Following the I/O-lower bound proof on the proximate neighbors problem in <ref> [9] </ref> we can prove the following: Lemma 1. Solving the SPN problem require (perm (N )) I/Os in the worst case. Using Lemma 1 we can now prove the lower bound by reducing the SPN problem to the reduction problem.
Reference: 10. <author> J. Gergov, C. Meinel: </author> <title> Frontiers of Feasible and Probabilistic Feasible Boolean Manipulation with Branching Programs. </title> <booktitle> In Proc. of 10th Symposium on Theoretical Aspects of Computer Science, LNCS 665, </booktitle> <year> 1993. </year>
Reference-contexts: Until recently most research, both theoretical and practical, have concentrated on finding small OBDD-representations of boolean functions appearing in specific problems [5, 7, 13, 16], or on finding alternative succinct representations while maintaining the efficient manipulation algorithms <ref> [10] </ref>. Very recently however, researchers have begun to consider I/O-issues arising when the OBDDs get larger than the available internal memory, and experimental results show that very large speedups can be achieved with algorithms that try to minimize the access to external storage as much as possible [4, 15].
Reference: 11. <author> M.T. Goodrich, M.H. Nodine, J.S. Vitter: </author> <title> Blocking for External Graph Searching. </title> <booktitle> In Proc. of 1993 ACM Symposium on Principles of Database Systems. </booktitle>
Reference-contexts: More recently researchers have designed external memory algorithms for a number of problems in different areas. Most notably I/O-efficient algorithms have been developed for a large number of computational geometry [3, 12] and graph problems [9]. Also worth noticing in this context is <ref> [11] </ref> that addresses the problem of storing graphs in a paging-environment, but not the problem of performing computation on them, and [2] where a number of external (batched) dynamic data structures are developed.
Reference: 12. <author> M.T. Goodrich, J.-J. Tsay, D.E. Vengroff, J.S. Vitter: </author> <title> External-Memory Computational Geometry. </title> <booktitle> In Proc. of 34th IEEE Foundations of Computer Science, </booktitle> <year> 1993. </year>
Reference-contexts: Early work on external-memory algorithms concentrated on sorting and permutation-related problems [1, 20]. More recently researchers have designed external memory algorithms for a number of problems in different areas. Most notably I/O-efficient algorithms have been developed for a large number of computational geometry <ref> [3, 12] </ref> and graph problems [9]. Also worth noticing in this context is [11] that addresses the problem of storing graphs in a paging-environment, but not the problem of performing computation on them, and [2] where a number of external (batched) dynamic data structures are developed.
Reference: 13. <author> S. Malik, A.R. Wang, R.K. Brayton, A. Sangiovanni-Vincentelli: </author> <title> Logic Verification using Binary Decision Diagrams in a Logic Synthesis Environment. </title> <booktitle> In Proc. of 1988 IEEE International Conference on CAD. </booktitle>
Reference-contexts: In such cases the Input/Output (I/O) communication becomes the bottleneck in the computation. Until recently most research, both theoretical and practical, have concentrated on finding small OBDD-representations of boolean functions appearing in specific problems <ref> [5, 7, 13, 16] </ref>, or on finding alternative succinct representations while maintaining the efficient manipulation algorithms [10]. <p> Note that an OBDD representing a boolean function of n variables can be of size 2 n , and that different variable orderings lead to representations of different size. There exist several algorithms (using heuristics) for choosing a variable-ordering that minimize the OBDD-representation of a given function <ref> [13, 16] </ref>. In [6] Bryant proved that for a given variable ordering and a given boolean function there is (up to isomorphism) exactly one OBDD | called the reduced OBDD | of minimal size.
Reference: 14. <author> H. Ochi, N. Ishiura, S. Yajima: </author> <title> Breadth-First Manipulation of SBDD of Boolean Functions for Vector Processing. </title> <booktitle> In Proc. of 28'th ACM/IEEE Design Automation Conference, </booktitle> <year> 1991. </year>
Reference-contexts: There exist implementations of OBDD software packages on a number of sequential and parallel machines <ref> [4, 5, 14, 15] </ref>. Even though there exist very different sized OBDD representations of the same boolean function, OBDDs in real applications tend to be very large. <p> Existing apply and reduce algorithms run in O (jGj) and O (jG 1 j jG 2 j) time, respectively <ref> [4, 6, 7, 14, 15, 18] </ref>. Here jGj denote the size (the number of vertices) of the OBDD G. <p> As discussed in section 1.1 this is asymptotically optimal for all realistic I/O-systems. We believe that the developed algorithms are of practical interest due to relatively small constants in the asymptotic bounds. 2 The Reduce Operation All the reduction algorithms <ref> [4, 6, 7, 14, 15] </ref> reported in the literature basically work in the same way. They all process the vertices level-wise from the sinks up to the root and assign a (new) unique integer label to each unique sub-OBDD root. <p> As mentioned in the introduction, Theorem 5 and Theorem 6 together means that for all realistic I/O-systems we have developed an asymptotically optimal reduction algorithm. 3 The Apply Algorithm The basic idea in all existing apply algorithms <ref> [4, 6, 7, 14, 15] </ref> is to use the recursive formula f 1 f 2 = x i (f 1 j x i =0 f 2 j x i =0 ) + x i (f 1 j x i =1 f 2 j x i =1 ) to design a recursive <p> Here fj x i =b denotes the function obtained from f when the argument x i is replaced by the boolean constant b, and is some binary operator. Using this formula Bryant [6] developed a recursive algorithm working in a depth-first manner on the involved OBDDs. In <ref> [14] </ref> and [4, 15] algorithms working in a breadth-first and in a level-wise manner are then developed.
Reference: 15. <author> H. Ochi, K. Yasuoka, S. Yajima: </author> <title> Breadth-First manipulation of Very Large Binary-Decision Diagrams. </title> <booktitle> In Proc. of 1993 IEEE International Conference on CAD. </booktitle>
Reference-contexts: There exist implementations of OBDD software packages on a number of sequential and parallel machines <ref> [4, 5, 14, 15] </ref>. Even though there exist very different sized OBDD representations of the same boolean function, OBDDs in real applications tend to be very large. <p> Very recently however, researchers have begun to consider I/O-issues arising when the OBDDs get larger than the available internal memory, and experimental results show that very large speedups can be achieved with algorithms that try to minimize the access to external storage as much as possible <ref> [4, 15] </ref>. These speedups can be achieved because of the extremely large access time of external storage medias, such as disks, compared to the access time of internal memory. <p> Existing apply and reduce algorithms run in O (jGj) and O (jG 1 j jG 2 j) time, respectively <ref> [4, 6, 7, 14, 15, 18] </ref>. Here jGj denote the size (the number of vertices) of the OBDD G. <p> Here jGj denote the size (the number of vertices) of the OBDD G. Even though the I/O-system (the size of the internal memory) seems to be the primary limitation on the size of the OBDD problems one is able to solve practically today <ref> [4, 5, 6, 7, 15] </ref>, it was only very recently that OBDD manipulation algorithms especially designed to minimize I/O was developed. <p> In [4] and <ref> [15] </ref> it is realized that the traditional algorithms working in a depth-first or breadth-first manner on the involved OBDDs does not perform well when the OBDDs are too large to fit in internal memory, and new level-wise algorithms are developed. 3 The general idea in these algorithms is to store the <p> Previous algorithms did not explicitly block the OBDDs. In <ref> [4, 15] </ref> speed-ups of several hundreds compared to the "traditional" algorithms are reported using this idea. In the rest of this paper we assume that an OBDD is stored as a number of vertices and that the edges are stored implicitly in these. <p> As discussed in section 1.1 this is asymptotically optimal for all realistic I/O-systems. We believe that the developed algorithms are of practical interest due to relatively small constants in the asymptotic bounds. 2 The Reduce Operation All the reduction algorithms <ref> [4, 6, 7, 14, 15] </ref> reported in the literature basically work in the same way. They all process the vertices level-wise from the sinks up to the root and assign a (new) unique integer label to each unique sub-OBDD root. <p> As mentioned in the introduction, Theorem 5 and Theorem 6 together means that for all realistic I/O-systems we have developed an asymptotically optimal reduction algorithm. 3 The Apply Algorithm The basic idea in all existing apply algorithms <ref> [4, 6, 7, 14, 15] </ref> is to use the recursive formula f 1 f 2 = x i (f 1 j x i =0 f 2 j x i =0 ) + x i (f 1 j x i =1 f 2 j x i =1 ) to design a recursive <p> Here fj x i =b denotes the function obtained from f when the argument x i is replaced by the boolean constant b, and is some binary operator. Using this formula Bryant [6] developed a recursive algorithm working in a depth-first manner on the involved OBDDs. In [14] and <ref> [4, 15] </ref> algorithms working in a breadth-first and in a level-wise manner are then developed. <p> discuss this in detail and show that all the known algorithms in the worst case use (jG 1 j jG 2 j) I/Os when trying to do an apply operation. 5 3.1 I/O-Efficient Apply Algorithm The main idea in our apply algorithm is to do the computation level-wise as in <ref> [4, 15] </ref>, but to use a priority-queue to control the recursion. Using a priority-queue we do not need to have a queue for each level.
Reference: 16. <author> R. Rudell: </author> <title> Dynamic Variable Ordering for Ordered Binary Decision Diagrams. </title> <booktitle> In Proc. of 1993 IEEE International Conference on CAD. </booktitle>
Reference-contexts: In such cases the Input/Output (I/O) communication becomes the bottleneck in the computation. Until recently most research, both theoretical and practical, have concentrated on finding small OBDD-representations of boolean functions appearing in specific problems <ref> [5, 7, 13, 16] </ref>, or on finding alternative succinct representations while maintaining the efficient manipulation algorithms [10]. <p> Note that an OBDD representing a boolean function of n variables can be of size 2 n , and that different variable orderings lead to representations of different size. There exist several algorithms (using heuristics) for choosing a variable-ordering that minimize the OBDD-representation of a given function <ref> [13, 16] </ref>. In [6] Bryant proved that for a given variable ordering and a given boolean function there is (up to isomorphism) exactly one OBDD | called the reduced OBDD | of minimal size.
Reference: 17. <author> C. Ruemmler, J. Wilkes: </author> <title> An introduction to disk drive modeling. </title> <journal> IEEE Computer, </journal> <volume> 27 (3), </volume> <year> 1994. </year>
Reference-contexts: This will however just increase the significance of the I/O-bottleneck since the development of disk technology lack behind developments in CPU technology. At present, technological advances are increasing CPU speed at an annual rate of 40-60% while disk transfer rates are only increasing by 7-10% annually <ref> [17] </ref>. 1.1 I/O-model and Previous Results In this paper we will be working in the parallel I/O-model introduced by Aggar-wal and Vitter [1] which models the I/O-system of many existing workstations.
Reference: 18. <author> D. Sieling, I. Wegener: </author> <title> Reduction of OBDDs in linear time. </title> <journal> Information Processing Letters, </journal> <volume> 48, </volume> <year> 1993. </year>
Reference-contexts: Existing apply and reduce algorithms run in O (jGj) and O (jG 1 j jG 2 j) time, respectively <ref> [4, 6, 7, 14, 15, 18] </ref>. Here jGj denote the size (the number of vertices) of the OBDD G.
Reference: 19. <author> D.E. Vengroff, J.S. Vitter: </author> <title> I/O-Efficient Scientific Computation Using TPIE. </title> <booktitle> In Proc. of 7th IEEE Symposium on Parallel and Distributed Processing, </booktitle> <year> 1995. </year>
Reference-contexts: Also worth noticing in this context is [11] that addresses the problem of storing graphs in a paging-environment, but not the problem of performing computation on them, and [2] where a number of external (batched) dynamic data structures are developed. Finally, it is demonstrated in <ref> [8, 19] </ref> that the results obtained in the mentioned papers are not only of theoretical but also of great practical interest. Some notes should be made about the typical bounds in the model.
Reference: 20. <author> J.S. Vitter, E.A.M Shrive: </author> <title> Algorithms for Parallel Memory I: Two-level Memories. </title> <journal> Algoritmica, </journal> <volume> 12 (2), </volume> <year> 1994. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: instance M = # of elements that can fit into main memory B = # of elements per disk block D = # of disks An I/O-operation in the model is the process of simultaneously reading or writing a block of data to or from each of the D disks <ref> [20] </ref>. The total amount of data transferred in one I/O is thus DB elements. The I/O-complexity of an algorithm is simply the number of I/Os it perform. Internal computation is free, and we always assume that the N elements initially are stored in the first N=(DB) blocks on each disk. <p> Typical values for workstations and file servers in production today are on the order of 10 6 M 10 8 , B ' 10 3 and D ' 10 1 . Early work on external-memory algorithms concentrated on sorting and permutation-related problems <ref> [1, 20] </ref>. More recently researchers have designed external memory algorithms for a number of problems in different areas. Most notably I/O-efficient algorithms have been developed for a large number of computational geometry [3, 12] and graph problems [9].
References-found: 20

