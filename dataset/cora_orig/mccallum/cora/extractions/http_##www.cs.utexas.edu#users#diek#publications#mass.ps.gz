URL: http://www.cs.utexas.edu/users/diek/publications/mass.ps.gz
Refering-URL: http://www.cs.utexas.edu/users/diek/publications/papers.html
Root-URL: 
Title: Stability and Chaos in an Inertial Two Neuron System  in Statistical Mechanics and Complex Systems  
Author: Diek W. Wheeler and W. C. Schieve and 
Keyword: PACS numbers: 05.45.+b, 84.35.+i.  
Date: Revised 17 September 1996  
Address: Austin, TX 78712  
Affiliation: Center for Studies  Physics Department, The University of Texas,  
Abstract: Inertia is added to a continuous-time, Hopfield [1], effective neuron system. We explore the effects on the stability of the fixed points of the system. A two neuron system with one or two inertial terms added is shown to exhibit chaos. The chaos is confirmed by Lyapunov exponents, power spectra, and phase space plots. Key words: chaos, Hopfield model, effective neurons, Lyapunov exponent, inertia. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> John J. </author> <title> Hopfield. Neurons with graded response have collective computational properties like those of two-state neurons. </title> <booktitle> Proceedings of the National Academy of Sciences (USA), </booktitle> <volume> 81 </volume> <pages> 3088-3092, </pages> <year> 1984. </year>
Reference-contexts: 1 Introduction Hopfield made popular his abstracted model of biological neural networks <ref> [1] </ref>. When the number of neurons in such a network grows large, so does the number of equations. As a method for circumventing this problem, Schieve, Bulsara, and Davis [2] developed the notion of effective neurons as a way of simplifying the study fl Reprint requests: W. C. <p> Both works deal with first order system equations that are of the form _ U = KU + J tanh (U ): (1) This equation is derived via Haken's slaving principle [3, 4] from the deterministic Hopfield model <ref> [1] </ref> i _ U i = K i U i + j6=i=1 J ij tanh (U j ): (2) It is assumed that K 1 for the master neuron is much smaller than the value of K i for the slaved neurons.
Reference: [2] <author> W. C. Schieve, A. R. Bulsara, and G. M. Davis. </author> <title> Single effective neuron. </title> <journal> Physical Review A, </journal> <volume> 43 </volume> <pages> 2613-2623, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction Hopfield made popular his abstracted model of biological neural networks [1]. When the number of neurons in such a network grows large, so does the number of equations. As a method for circumventing this problem, Schieve, Bulsara, and Davis <ref> [2] </ref> developed the notion of effective neurons as a way of simplifying the study fl Reprint requests: W. C. Schieve, Center for Studies in Statistical Mechanics and Complex Systems, The University of Texas, Austin, TX 78712. PH: (512) 471-7253. FAX: (512) 471-9637. email: wcs@mail.utexas.edu. 1 of large Hopfield neural networks.
Reference: [3] <author> H. Haken. </author> <title> Synergetics. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin; Heidelberg; New York, </address> <year> 1977. </year>
Reference-contexts: C. Schieve, Center for Studies in Statistical Mechanics and Complex Systems, The University of Texas, Austin, TX 78712. PH: (512) 471-7253. FAX: (512) 471-9637. email: wcs@mail.utexas.edu. 1 of large Hopfield neural networks. Their concept utilizes Haken's slaving principle <ref> [3, 4] </ref>, which describes the adiabatic elimination of fast-relaxing slave variables in favor of slow-varying master variables in solutions to the long-time dynamics of a system. The properties of a chaotic attractor in a network of four effective neurons have been explored previously [5, 6]. <p> Kwek and Li [8] later provided evidence for a Hopf bifurcation in the system. Both works deal with first order system equations that are of the form _ U = KU + J tanh (U ): (1) This equation is derived via Haken's slaving principle <ref> [3, 4] </ref> from the deterministic Hopfield model [1] i _ U i = K i U i + j6=i=1 J ij tanh (U j ): (2) It is assumed that K 1 for the master neuron is much smaller than the value of K i for the slaved neurons.
Reference: [4] <author> H. Haken. </author> <title> Advanced Synergetics. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin; Heidelberg; New York, </address> <year> 1993. </year> <month> 23 </month>
Reference-contexts: C. Schieve, Center for Studies in Statistical Mechanics and Complex Systems, The University of Texas, Austin, TX 78712. PH: (512) 471-7253. FAX: (512) 471-9637. email: wcs@mail.utexas.edu. 1 of large Hopfield neural networks. Their concept utilizes Haken's slaving principle <ref> [3, 4] </ref>, which describes the adiabatic elimination of fast-relaxing slave variables in favor of slow-varying master variables in solutions to the long-time dynamics of a system. The properties of a chaotic attractor in a network of four effective neurons have been explored previously [5, 6]. <p> Kwek and Li [8] later provided evidence for a Hopf bifurcation in the system. Both works deal with first order system equations that are of the form _ U = KU + J tanh (U ): (1) This equation is derived via Haken's slaving principle <ref> [3, 4] </ref> from the deterministic Hopfield model [1] i _ U i = K i U i + j6=i=1 J ij tanh (U j ): (2) It is assumed that K 1 for the master neuron is much smaller than the value of K i for the slaved neurons.
Reference: [5] <author> P. Das, W. Schieve, and Z. Zeng. </author> <title> Chaos in an effective four-neuron neural network. </title> <journal> Physics Letters A, </journal> <volume> 161 </volume> <pages> 60-66, </pages> <year> 1991. </year>
Reference-contexts: Their concept utilizes Haken's slaving principle [3, 4], which describes the adiabatic elimination of fast-relaxing slave variables in favor of slow-varying master variables in solutions to the long-time dynamics of a system. The properties of a chaotic attractor in a network of four effective neurons have been explored previously <ref> [5, 6] </ref>. In the paper by Zeng, Schieve, and Das [7], the complete behavior for a system of two effective neurons was worked out. The fixed point positions and behaviors were found for the system for all combinations of the system parameters. <p> By changing the value of one of the inertial terms, one can move the system in and out of the chaotic regimes. The inertia affects the stability of the fixed points of the system without altering relative positions of the fixed points in phase space. Das, et al. <ref> [5, 6] </ref> were able to find chaos in a network of four effective neurons. Our two neuron plus one inertial term network, however, has one less phase space dimension. This allows for better visualization of the two neuron system since all three phase space dimensions can be viewed at once.
Reference: [6] <author> Pranab K. Das II and William C. Schieve. </author> <title> A bifurcation analysis of the four dimensional generalized Hopfield neural network. </title> <journal> Physica D, </journal> <volume> 88 </volume> <pages> 14-28, </pages> <year> 1995. </year>
Reference-contexts: Their concept utilizes Haken's slaving principle [3, 4], which describes the adiabatic elimination of fast-relaxing slave variables in favor of slow-varying master variables in solutions to the long-time dynamics of a system. The properties of a chaotic attractor in a network of four effective neurons have been explored previously <ref> [5, 6] </ref>. In the paper by Zeng, Schieve, and Das [7], the complete behavior for a system of two effective neurons was worked out. The fixed point positions and behaviors were found for the system for all combinations of the system parameters. <p> By changing the value of one of the inertial terms, one can move the system in and out of the chaotic regimes. The inertia affects the stability of the fixed points of the system without altering relative positions of the fixed points in phase space. Das, et al. <ref> [5, 6] </ref> were able to find chaos in a network of four effective neurons. Our two neuron plus one inertial term network, however, has one less phase space dimension. This allows for better visualization of the two neuron system since all three phase space dimensions can be viewed at once.
Reference: [7] <author> Zhaojue Zeng, W. C. Schieve, and Pranab K. Das. </author> <title> Two neuron dynamics and adiabatic elimination. </title> <journal> Physica D, </journal> <volume> 67 </volume> <pages> 224-236, </pages> <year> 1993. </year>
Reference-contexts: The properties of a chaotic attractor in a network of four effective neurons have been explored previously [5, 6]. In the paper by Zeng, Schieve, and Das <ref> [7] </ref>, the complete behavior for a system of two effective neurons was worked out. The fixed point positions and behaviors were found for the system for all combinations of the system parameters. Kwek and Li [8] later provided evidence for a Hopf bifurcation in the system. <p> Coordinates U 1 and U 3 must be found numerically. From the equations above, it is evident that the locations of the fixed points are independent of the inertial terms. This means that the fixed points are the same as those found in previous works <ref> [7, 8] </ref>, relatively speaking, since the U 2 coordinate is always zero. Although the coordinates of the fixed points may be unchanged by the inertial term, their behavior is definitely modified.
Reference: [8] <author> Keng-Huat Kwek and Jibin Li. </author> <title> Periodic solution and dynamics in two neuron network system. Neural, Parallel, </title> & <journal> Scientific Computations, </journal> <volume> 3 </volume> <pages> 189-203, </pages> <year> 1995. </year>
Reference-contexts: In the paper by Zeng, Schieve, and Das [7], the complete behavior for a system of two effective neurons was worked out. The fixed point positions and behaviors were found for the system for all combinations of the system parameters. Kwek and Li <ref> [8] </ref> later provided evidence for a Hopf bifurcation in the system. <p> Coordinates U 1 and U 3 must be found numerically. From the equations above, it is evident that the locations of the fixed points are independent of the inertial terms. This means that the fixed points are the same as those found in previous works <ref> [7, 8] </ref>, relatively speaking, since the U 2 coordinate is always zero. Although the coordinates of the fixed points may be unchanged by the inertial term, their behavior is definitely modified.
Reference: [9] <author> K. L. Babcock and R. M. Westervelt. </author> <title> Dynamics of simple electronic neural networks. </title> <journal> Physica D, </journal> <volume> 428 </volume> <pages> 305-316, </pages> <year> 1987. </year>
Reference-contexts: The inertia can be considered a useful tool that is added to help in the generation of chaos in neural systems. Babcock and Westervelt <ref> [9] </ref> combined inertia and driving to explore chaos in one and two neuron systems. Tani, et al. [10, 11, 12] added inertia and a nonlinear oscillating resistance to neural equations as a way of chaotically searching for memories in neural networks. <p> Our two neuron plus one inertial term network, however, has one less phase space dimension. This allows for better visualization of the two neuron system since all three phase space dimensions can be viewed at once. Babcock and Westervelt <ref> [9] </ref> examined chaos in a neural system that was similar to ours but that differed in several key aspects. They looked at both one neuron and two neuron systems where all of the neurons had an added inertial term.
Reference: [10] <author> Jun Tani. </author> <title> Proposal of chaotic steepest descent method for neural networks and analysis of their dynamics. </title> <journal> Electronics and Communication in Japan, </journal> <volume> 75(4) </volume> <pages> 62-70, </pages> <year> 1992. </year>
Reference-contexts: The inertia can be considered a useful tool that is added to help in the generation of chaos in neural systems. Babcock and Westervelt [9] combined inertia and driving to explore chaos in one and two neuron systems. Tani, et al. <ref> [10, 11, 12] </ref> added inertia and a nonlinear oscillating resistance to neural equations as a way of chaotically searching for memories in neural networks. There is some biological support for the inclusion of an inductance term in a neural equation.
Reference: [11] <author> Jun Tani and Masahiro Fujita. </author> <title> Coupling of memory search and mental rotation by a nonequilibrium dynamics neural network. </title> <journal> IEICE Transactions on Fundamentals of Electronics, Communications and Computer Science, </journal> <volume> E75-A(5):578-585, </volume> <year> 1992. </year>
Reference-contexts: The inertia can be considered a useful tool that is added to help in the generation of chaos in neural systems. Babcock and Westervelt [9] combined inertia and driving to explore chaos in one and two neuron systems. Tani, et al. <ref> [10, 11, 12] </ref> added inertia and a nonlinear oscillating resistance to neural equations as a way of chaotically searching for memories in neural networks. There is some biological support for the inclusion of an inductance term in a neural equation.
Reference: [12] <author> Jun Tani. </author> <title> Model-based learning for mobile robot navigation from the dynamical systems perstective. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 26(3) </volume> <pages> 421-436, </pages> <year> 1996. </year>
Reference-contexts: The inertia can be considered a useful tool that is added to help in the generation of chaos in neural systems. Babcock and Westervelt [9] combined inertia and driving to explore chaos in one and two neuron systems. Tani, et al. <ref> [10, 11, 12] </ref> added inertia and a nonlinear oscillating resistance to neural equations as a way of chaotically searching for memories in neural networks. There is some biological support for the inclusion of an inductance term in a neural equation.
Reference: [13] <author> J. F. Ashmore and D. Attwell. </author> <title> Models for electrical tuning in hair cells. </title> <journal> Proceedings of the Royal Society of London B, </journal> <volume> 226 </volume> <pages> 325-344, </pages> <year> 1985. </year>
Reference-contexts: There is some biological support for the inclusion of an inductance term in a neural equation. The membrane of a hair cell in the semicircular canals of some animals can be described by equivalent circuits that contain an inductance <ref> [13, 14] </ref>. The squid axon can also be described as having a phenomenological inductance [15, 16].
Reference: [14] <author> D. E. Angelaki and M. J. Correia. </author> <title> Models of membrane resonance in pigeon semicircular canal type II hair cells. </title> <journal> Biological Cybernetics, </journal> <volume> 65 </volume> <pages> 1-10, </pages> <year> 1991. </year>
Reference-contexts: There is some biological support for the inclusion of an inductance term in a neural equation. The membrane of a hair cell in the semicircular canals of some animals can be described by equivalent circuits that contain an inductance <ref> [13, 14] </ref>. The squid axon can also be described as having a phenomenological inductance [15, 16].
Reference: [15] <author> A. Mauro, F. Conti, F. Dodge, and R. Schor. </author> <title> Subthreshold behavior and phenomenological impedance of the squid giant axon. </title> <journal> The Journal of General Physiology, </journal> <volume> 55 </volume> <pages> 497-523, </pages> <year> 1970. </year> <month> 24 </month>
Reference-contexts: The membrane of a hair cell in the semicircular canals of some animals can be described by equivalent circuits that contain an inductance [13, 14]. The squid axon can also be described as having a phenomenological inductance <ref> [15, 16] </ref>. Also, Koch [17] put forth the notion that under certain conditions neurons exhibit a quasi-active membrane that can be modeled by a phenomenological inductance that allows the membrane to behave like a bandpass filter, enabling electrical tuning, temporal differentiation, or spatio-temporal filtering.
Reference: [16] <author> E. Puil, B. Gimbarzevsky, and I. Spigelman. </author> <title> Primary involvement of K ++ conductance in membrane resonance of trigeminal root ganglion neurons. </title> <journal> Journal of Neurophysiology, </journal> <volume> 59(1) </volume> <pages> 77-89, </pages> <year> 1988. </year>
Reference-contexts: The membrane of a hair cell in the semicircular canals of some animals can be described by equivalent circuits that contain an inductance [13, 14]. The squid axon can also be described as having a phenomenological inductance <ref> [15, 16] </ref>. Also, Koch [17] put forth the notion that under certain conditions neurons exhibit a quasi-active membrane that can be modeled by a phenomenological inductance that allows the membrane to behave like a bandpass filter, enabling electrical tuning, temporal differentiation, or spatio-temporal filtering.
Reference: [17] <author> Cristof Koch. </author> <title> Cable theory in neurons with active, linearized membranes. </title> <journal> Biological Cybernetics, </journal> <volume> 50 </volume> <pages> 15-33, </pages> <year> 1984. </year>
Reference-contexts: The membrane of a hair cell in the semicircular canals of some animals can be described by equivalent circuits that contain an inductance [13, 14]. The squid axon can also be described as having a phenomenological inductance [15, 16]. Also, Koch <ref> [17] </ref> put forth the notion that under certain conditions neurons exhibit a quasi-active membrane that can be modeled by a phenomenological inductance that allows the membrane to behave like a bandpass filter, enabling electrical tuning, temporal differentiation, or spatio-temporal filtering.
Reference: [18] <author> Scott Rader, Diek W. Wheeler, W. C. Schieve, and Pranab Das. </author> <title> Nonlinear resonance in neuron dynamics. </title> <journal> Zeitschrift Fur Naturforschung A, </journal> <volume> 50 </volume> <pages> 718-726, </pages> <year> 1995. </year>
Reference-contexts: (6) The derivation of equation (6) is similar to that of equation (4) except for the added assumption that the inertia for the slaved neurons (M i6=1 ) must be small to prevent the development of oscillations that might inhibit the slaved neurons from achieving a time independent steady state <ref> [18] </ref>. The slaved neurons are still described by equation (3). The number of papers dealing with chaos in neural networks is growing so rapidly one cannot begin to reference them all. Dozens of papers have been published within the last year alone.
Reference: [19] <author> A. A. Andronov, A. A. Vitt, and S. E. Khaikin. </author> <title> Theory of Oscillators. </title> <publisher> Pergamon Press Ltd., Oxford, </publisher> <year> 1966. </year>
Reference-contexts: Equation (6) is second order, so it can be rewritten as _ U 1 = U 2 ; (7) U 2 M J tanh (U 1 ): (8) To find the fixed points of the system, _ U 1 and _ U 2 are zero <ref> [19, 20] </ref>, which results in the following, 0 = U 2 ; (9) K U 1 + M tanh (U 1 ) ) KU 1 = J tanh (U 1 ): (10) All fixed points occur at U 2 = 0. <p> The positions of the fixed points are independent of the inertia M . The stability of the fixed points, however, does depend on the value of the inertia. To explore the nature of the fixed points, the following 4 characteristic equation is evaluated <ref> [19] </ref>, fi fi fi fi 1 M U 1 + J M sech 2 (U 1 ) M fi fi fi fi This results in the equation M 2 + + [K J sech 2 (U 1 )] = 0; (12) which is solved for the roots = q 2 4M <p> in the equation M 2 + + [K J sech 2 (U 1 )] = 0; (12) which is solved for the roots = q 2 4M [K Jsech 2 (U 1 )] 2M The nature of the solutions for determines the type of behavior the fixed point will exhibit <ref> [19, 20] </ref>. If the non-trivial solution to equation (10) is assumed, then there are three fixed points, one of which lies at the origin. From equation (10) it can be seen that when U 1 6= 0, then J and K must have the same sign. <p> tanh (U 1 ) + J 13 tanh (U 3 ); (35) _ U 3 = 3 J 33 tanh (U 3 ) + J 31 tanh (U 1 ): (36) As with the single neuron case, the fixed points are found by setting the first time derivatives to zero <ref> [19, 20] </ref>, 0 = U 2 ; (37) 0 = K 1 U 1 + J 11 tanh (U 1 ) + J 13 tanh (U 3 ); (38) 0 = K 3 U 3 + J 33 tanh (U 3 ) + J 31 tanh (U 1 ): (39) All <p> 2 (U 1 ) 1 M 1 J 13 M 1 sech 2 (U 3 ) J 31 3 sech 2 (U 1 ) 0 K 3 3 U 1 + J 33 3 sech 2 (U 3 ) fi fi fi fi fi fi = 0; (40) is evaluated <ref> [19] </ref>.
Reference: [20] <author> Ferdinand Verhulst. </author> <title> Nonlinear Differential Equations and Dynamical Systems. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin; Heidelberg; New York, </address> <year> 1990. </year>
Reference-contexts: Equation (6) is second order, so it can be rewritten as _ U 1 = U 2 ; (7) U 2 M J tanh (U 1 ): (8) To find the fixed points of the system, _ U 1 and _ U 2 are zero <ref> [19, 20] </ref>, which results in the following, 0 = U 2 ; (9) K U 1 + M tanh (U 1 ) ) KU 1 = J tanh (U 1 ): (10) All fixed points occur at U 2 = 0. <p> in the equation M 2 + + [K J sech 2 (U 1 )] = 0; (12) which is solved for the roots = q 2 4M [K Jsech 2 (U 1 )] 2M The nature of the solutions for determines the type of behavior the fixed point will exhibit <ref> [19, 20] </ref>. If the non-trivial solution to equation (10) is assumed, then there are three fixed points, one of which lies at the origin. From equation (10) it can be seen that when U 1 6= 0, then J and K must have the same sign. <p> tanh (U 1 ) + J 13 tanh (U 3 ); (35) _ U 3 = 3 J 33 tanh (U 3 ) + J 31 tanh (U 1 ): (36) As with the single neuron case, the fixed points are found by setting the first time derivatives to zero <ref> [19, 20] </ref>, 0 = U 2 ; (37) 0 = K 1 U 1 + J 11 tanh (U 1 ) + J 13 tanh (U 3 ); (38) 0 = K 3 U 3 + J 33 tanh (U 3 ) + J 31 tanh (U 1 ): (39) All
Reference: [21] <author> Hideo Matsuda and Akihiko Uchiyama. </author> <title> A neural network model for generating intermittent chaos. </title> <journal> IEICE Transactions on Fundamentals of Electronics, Communications and Computer Science, </journal> <volume> E76-A(9):1544-1547, </volume> <year> 1993. </year>
Reference-contexts: Babcock and Westervelt also required that their connection matrix be symmetric since they were trying to keep the system as simple as possible while exploring its dynamic behavior. There has been some other work on small neural systems. Matsuda and Uchiyama <ref> [21] </ref> describe a network of three neurons that generates chaos. Each neuron is modeled by a single first order differential equation, however, the activation functions are modeled by piecewise linear functions.
Reference: [22] <author> C. M. Marcus, F. R. Waugh, and R. M. Westervelt. </author> <title> Nonlinear dynamics and stability of analog neural networks. </title> <journal> Physica D, </journal> <volume> 51 </volume> <pages> 234-247, </pages> <year> 1991. </year> <month> 25 </month>
Reference-contexts: There has been some other work on small neural systems. Matsuda and Uchiyama [21] describe a network of three neurons that generates chaos. Each neuron is modeled by a single first order differential equation, however, the activation functions are modeled by piecewise linear functions. Marcus, et al. <ref> [22] </ref> also model a three neuron network, but a time delay factor for one of the neurons is required for the system to generate chaos. To the best of our knowledge, the model presented here describes the lowest dimensional, autonomous, continuous-time, neural system that exhibits chaos.
References-found: 22

