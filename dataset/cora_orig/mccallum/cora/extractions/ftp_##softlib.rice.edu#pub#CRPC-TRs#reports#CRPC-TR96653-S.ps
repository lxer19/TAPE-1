URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR96653-S.ps
Refering-URL: http://www.cs.rice.edu:80/~roth/papers.html
Root-URL: 
Title: Dependence Analysis of Fortran90 Array Syntax  
Author: Gerald Roth Ken Kennedy 
Address: Houston, Texas, U.S.A.  
Affiliation: Department of Computer Science Rice University  
Abstract: Dependence analysis and dependence information are critical components of many optimizing and parallelizing compilers. And there exist many fast and precise dependence tests that work on scalar-subscripted array references. We have extended this analysis by adding tests that directly handle Fortran 90 array-section references. This paper describes our testing methodology and how we have extended direction vectors to contain the additional information. Keywords: dependence analysis, Fortran90, array syntax, direction vec tors, scalarization
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Adams, W. Brainerd, J. Martin, B. Smith, and J. Wagener. </author> <title> Fortran 90 Handbook. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1992. </year>
Reference-contexts: We also introduce a special class of dependences that arise from array syntax, and discuss some of their properties. Finally, we show how this additional information can be used to perform advanced program transformations. 1.1 Fortran 90 It is assumed that the reader is familiar with Fortran 90 <ref> [1] </ref>, especially with the execution semantics of array operations. In Fortran 90, operations deal with their operands as unitary objects, even when they are arrays. Thus all right-hand side elements of an array assignment statement are read before any left-hand side elements are stored.
Reference: [2] <author> J. R. Allen. </author> <title> Dependence Analysis for Subscripted Variables and Its Application to Program Transformations. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> April </month> <year> 1983. </year>
Reference-contexts: Data dependence is fundamental to compilers that attempt reordering transformations since it specifies statement orderings that must be preserved to maintain program semantics <ref> [2, 15, 17] </ref>. There are four types of data dependence. True dependence occurs when one statement writes a memory location that another statement later reads. Antidependence occurs when one statement reads a memory location that another statement later writes. <p> For each coupled group, apply a multiple script test. 5. If any test yields independence, no dependences exist. 6. Otherwise merge all the direction vectors computed by the previous steps into a single set of direction vectors for the two references. appear in other subscript positions <ref> [2, 7] </ref>. If different subscript positions contain the same index, they are said to be coupled [12]. The concept of separability is important when testing multidimensional arrays in that it allows dependence testing to proceed subscript-by-subscript without a loss of precision.
Reference: [3] <author> J. R. Allen and K. Kennedy. </author> <title> Automatic translation of Fortran programs to vector form. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(4) </volume> <pages> 491-542, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: An outline of the algorithm is given in Figure 1. This algorithm has been used with great success in the PFC compiler <ref> [3] </ref>, the ParaScope programming environment [11], and the Fortran D compiler [10, 14]. 2 Dependence Representation Data dependences are often represented using direction vectors and/or distance vectors [15]. <p> In this paper we will only discuss direction vectors, although the algorithms presented could easily be made to work with distance vectors. Direction vectors are useful in determining if a dependence is loop-carried or loop-independent <ref> [3] </ref>. For loop-carried dependences, the direction vector also tells us which loop carries the dependence and in which direction. The vectors contain an element for each loop which encloses both statements involved in the dependence.
Reference: [4] <author> J. R. Allen and K. Kennedy. </author> <title> Vector register allocation. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 41(10) </volume> <pages> 1290-1317, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Thus for scalarization dependences, it is no longer the case that a true dependence with a "&gt;" as the first non-"=" direction is equivalent to an antidependence with the direction reversed, as has been previously noted <ref> [4, 6] </ref>. By definition, scalarization dependences are loop-independent with regard to surrounding loops. This has several implications. <p> DO I=2, N END DO (a) array statement (b) naively scalarized code Fortunately, data dependence information can tell us when the scalarized loop is correct. Allen and Kennedy <ref> [4] </ref> have shown that a scalarized loop is correct if and only if it does not carry a true dependence. Using this fact, most compilers perform scalarization in the following manner: 1. Perform a naive scalarization of the array statement into scalar code. 2. <p> The code transformations that can be applied to handle the loop carried true dependences include loop reversal, loop interchange, prefetching, and as a last resort the generation of array temporaries. The interested reader is referred to Allen and Kennedy <ref> [4] </ref> for a complete discussion. Note that the above algorithm requires two passes over the code, one to perform the naive scalarization and another to perform code transformations to restore the semantics of the program if the initial scalarization was invalid.
Reference: [5] <author> U. Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1988. </year>
Reference-contexts: Output dependence occurs when one statement writes a memory location that another statement later writes. Input dependence occurs when one statement reads a memory location that another statement later reads. Dependence testing is the process of determining whether a data dependence exists between two statements <ref> [5] </ref>.
Reference: [6] <author> M. Burke and R. Cytron. </author> <title> Interprocedural dependence analysis and parallelization. </title> <booktitle> In Proceedings of the SIGPLAN '86 Symposium on Compiler Construction, </booktitle> <address> Palo Alto, CA, </address> <month> June </month> <year> 1986. </year>
Reference-contexts: Thus for scalarization dependences, it is no longer the case that a true dependence with a "&gt;" as the first non-"=" direction is equivalent to an antidependence with the direction reversed, as has been previously noted <ref> [4, 6] </ref>. By definition, scalarization dependences are loop-independent with regard to surrounding loops. This has several implications.
Reference: [7] <author> D. Callahan. </author> <title> Dependence testing in PFC: Weak separability. Supercomputer Software Newsletter 2, </title> <institution> Dept. of Computer Science, Rice University, </institution> <month> August </month> <year> 1986. </year>
Reference-contexts: For each coupled group, apply a multiple script test. 5. If any test yields independence, no dependences exist. 6. Otherwise merge all the direction vectors computed by the previous steps into a single set of direction vectors for the two references. appear in other subscript positions <ref> [2, 7] </ref>. If different subscript positions contain the same index, they are said to be coupled [12]. The concept of separability is important when testing multidimensional arrays in that it allows dependence testing to proceed subscript-by-subscript without a loss of precision.
Reference: [8] <author> G. Goff, K. Kennedy, and C.-W. Tseng. </author> <title> Practical dependence testing. </title> <booktitle> In Proceedings of the SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <address> Toronto, Canada, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Dependence testing is mostly concerned with determining dependences that arise from subscripted array references that appear within loop nests, since it is not always easy to determine if such references access the same memory location. 1.3 Partition-based Dependence Testing In the partition-based dependence testing algorithm <ref> [8] </ref> used in the analysis and transformation systems at Rice University, pairs of array references are classified before being tested. This allows us to chose the most efficient test for a given pair of references and lets us test the subscripts in the order of less expensive to more expensive.
Reference: [9] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran language specifica-tion. </title> <booktitle> Scientific Programming, </booktitle> <address> 2(1-2):1-170, </address> <year> 1993. </year>
Reference: [10] <author> S. Hiranandani, K. Kennedy, and C.-W. Tseng. </author> <title> Compiling Fortran D for MIMD distributed-memory machines. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 66-80, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: An outline of the algorithm is given in Figure 1. This algorithm has been used with great success in the PFC compiler [3], the ParaScope programming environment [11], and the Fortran D compiler <ref> [10, 14] </ref>. 2 Dependence Representation Data dependences are often represented using direction vectors and/or distance vectors [15]. These vectors are convenient methods for characterizing the relationship between the values of the loop indices of the two array references involved in the dependence.
Reference: [11] <author> K. Kennedy, K. S. M c Kinley, and C.-W. Tseng. </author> <title> Interactive parallel programming using the ParaScope Editor. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(3) </volume> <pages> 329-341, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: An outline of the algorithm is given in Figure 1. This algorithm has been used with great success in the PFC compiler [3], the ParaScope programming environment <ref> [11] </ref>, and the Fortran D compiler [10, 14]. 2 Dependence Representation Data dependences are often represented using direction vectors and/or distance vectors [15]. These vectors are convenient methods for characterizing the relationship between the values of the loop indices of the two array references involved in the dependence.
Reference: [12] <author> Z. Li, P. Yew, and C. Zhu. </author> <title> Data dependence analysis on multi-dimensional array references. </title> <booktitle> In Proceedings of the 1989 ACM International Conference on Supercomputing, </booktitle> <address> Crete, Greece, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: Otherwise merge all the direction vectors computed by the previous steps into a single set of direction vectors for the two references. appear in other subscript positions [2, 7]. If different subscript positions contain the same index, they are said to be coupled <ref> [12] </ref>. The concept of separability is important when testing multidimensional arrays in that it allows dependence testing to proceed subscript-by-subscript without a loss of precision. In contrast, coupled subscripts must be tested as a group to obtain exact results. <p> If the subscripts became coupled because corresponding triplets did not appear in matching subscript positions, then the linear functions generated for the corresponding triplets will share the same pseudo-induction variable. Once the triplets have been translated, we can exploit whichever multi-subscript test is available in our system <ref> [12, 13, 16] </ref>. 5 Advanced Scalarization Before an array statement can executed on the target architecture, it must be rewritten so that it accesses smaller chunks of data.
Reference: [13] <author> W. Pugh. </author> <title> A practical algorithm for exact array dependence analysis. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 102-114, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: If the subscripts became coupled because corresponding triplets did not appear in matching subscript positions, then the linear functions generated for the corresponding triplets will share the same pseudo-induction variable. Once the triplets have been translated, we can exploit whichever multi-subscript test is available in our system <ref> [12, 13, 16] </ref>. 5 Advanced Scalarization Before an array statement can executed on the target architecture, it must be rewritten so that it accesses smaller chunks of data.
Reference: [14] <author> C.-W. Tseng. </author> <title> An Optimizing Fortran D Compiler for MIMD Distributed-Memory Machines. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: An outline of the algorithm is given in Figure 1. This algorithm has been used with great success in the PFC compiler [3], the ParaScope programming environment [11], and the Fortran D compiler <ref> [10, 14] </ref>. 2 Dependence Representation Data dependences are often represented using direction vectors and/or distance vectors [15]. These vectors are convenient methods for characterizing the relationship between the values of the loop indices of the two array references involved in the dependence.
Reference: [15] <author> M. J. Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1989. </year>
Reference-contexts: Data dependence is fundamental to compilers that attempt reordering transformations since it specifies statement orderings that must be preserved to maintain program semantics <ref> [2, 15, 17] </ref>. There are four types of data dependence. True dependence occurs when one statement writes a memory location that another statement later reads. Antidependence occurs when one statement reads a memory location that another statement later writes. <p> An outline of the algorithm is given in Figure 1. This algorithm has been used with great success in the PFC compiler [3], the ParaScope programming environment [11], and the Fortran D compiler [10, 14]. 2 Dependence Representation Data dependences are often represented using direction vectors and/or distance vectors <ref> [15] </ref>. These vectors are convenient methods for characterizing the relationship between the values of the loop indices of the two array references involved in the dependence. In this paper we will only discuss direction vectors, although the algorithms presented could easily be made to work with distance vectors.
Reference: [16] <author> M. J. Wolfe and C.-W. Tseng. </author> <title> The Power test for data dependence. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(5) </volume> <pages> 591-601, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: If the subscripts became coupled because corresponding triplets did not appear in matching subscript positions, then the linear functions generated for the corresponding triplets will share the same pseudo-induction variable. Once the triplets have been translated, we can exploit whichever multi-subscript test is available in our system <ref> [12, 13, 16] </ref>. 5 Advanced Scalarization Before an array statement can executed on the target architecture, it must be rewritten so that it accesses smaller chunks of data.
Reference: [17] <author> H. Zima and B. Chapman. </author> <title> Supercompilers for Parallel and Vector Computers. </title> <publisher> Addison-Wesley, </publisher> <address> New York, NY, </address> <year> 1991. </year>
Reference-contexts: Data dependence is fundamental to compilers that attempt reordering transformations since it specifies statement orderings that must be preserved to maintain program semantics <ref> [2, 15, 17] </ref>. There are four types of data dependence. True dependence occurs when one statement writes a memory location that another statement later reads. Antidependence occurs when one statement reads a memory location that another statement later writes.
References-found: 17

