URL: http://www.eecs.umich.edu/~ashaikh/research/papers/CSE-TR-375-98.ps.Z
Refering-URL: http://www.eecs.umich.edu/~ashaikh/research/
Root-URL: http://www.cs.umich.edu
Email: fashaikh,zaher,zqwang,kgshing@eecs.umich.edu mehraa@watson.ibm.com  
Title: Realizing Services for Guaranteed-QoS Communication on a Microkernel Operating System  
Author: Ashish Mehra Anees Shaikh, Tarek Abdelzaher, Zhiqun Wang, and Kang G. Shin 
Address: Ann Arbor, MI 48109-2122 Yorktown Heights, NY 10598-0704  
Affiliation: Real-Time Computing Laboratory Server and Enterprise Networking University of Michigan IBM T.J. Watson Research Center  
Abstract: Provision of end-to-end QoS guarantees on communication necessitates appropriate support in the end systems (i.e., hosts) and network routers that form the communication fabric. Typically, the support is in the form of suitable extensions to the communication subsystem and the underlying operating system for specification and maintenance of QoS guarantees. This paper focuses on the architectural and implementation challenges involved in realizing QoS-sensitive host communication subsystems on contemporary microkernel operating systems with limited real-time support. We motivate and describe the components constituting our integrated service architecture that together ensure QoS-sensitive handling of network traffic at both sending and receiving hosts. We separate the policies from mechanisms in each component, demonstrating a communication framework that can implement alternative QoS models by applying appropriate policies. We also report the results of a detailed execution profile of the system to characterize communication costs for the purposes of admission control. An experimental evaluation in a controlled configuration demonstrates the efficacy with which QoS guarantees are maintained, despite limitations imposed by the underlying operating system. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Custer, </author> <title> Inside Windows NT, Microsoft Press, One Microsoft Way, </title> <address> Redmond, Washington 98052-6399, </address> <year> 1993. </year>
Reference-contexts: In this paper we explore QoS-sensitive communication subsystem design for contemporary operating systems. We describe the general architecture, implementation, and evaluation of a guaranteed QoS communication service for a microkernel operating system. Microkernel operating systems continue to play an important role in operating system design <ref> [1, 2] </ref>, and are being extended y The work of this author was performed at the University of Michigan. The work reported in this paper was supported in part by the National Science Foundation under grant MIP-9203895 and the Defense Advanced Research Project Agency under grant DOD-C-F30602-95-1-0044.
Reference: [2] <author> D. G. Korn, </author> <title> "Porting UNIX to windows NT," </title> <booktitle> in Proc. USENIX Winter Conference, </booktitle> <month> January </month> <year> 1997. </year>
Reference-contexts: In this paper we explore QoS-sensitive communication subsystem design for contemporary operating systems. We describe the general architecture, implementation, and evaluation of a guaranteed QoS communication service for a microkernel operating system. Microkernel operating systems continue to play an important role in operating system design <ref> [1, 2] </ref>, and are being extended y The work of this author was performed at the University of Michigan. The work reported in this paper was supported in part by the National Science Foundation under grant MIP-9203895 and the Defense Advanced Research Project Agency under grant DOD-C-F30602-95-1-0044.
Reference: [3] <author> S. Sommer and J. Potter, </author> <title> "Operating system extensions for dynamic real-time applications," </title> <booktitle> in Proc. 17th Real-Time Systems Symposium, </booktitle> <pages> pp. 45-50, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: Any opinions, findings, and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of NSF or DARPA. to support real-time and multimedia applications <ref> [3] </ref>. We describe how to map the architectural components of a QoS-sensitive communication subsystem onto the support furnished by the operating system in order to provide appropriate QoS guarantees. We discuss the difficulties in realizing real-time behavior on such platforms and our approach to providing predictability within platform limitations.
Reference: [4] <author> C. Maeda and B. N. Bershad, </author> <title> "Protocol service decomposition for high-performance networking," </title> <booktitle> in Proc. ACM Symp. on Operating Systems Principles, </booktitle> <pages> pp. 244-255, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: We realize this service as a user-level server, even though server-based protocol stacks perform poorly compared to user-level protocol libraries or in-kernel implementations <ref> [4, 5] </ref>, for a number of reasons. A server configuration considerably eases software development and debugging, particularly the location and correction of timing-related bugs. Also, since several applications can establish multiple QoS connections, admission control and run-time resource management of these connections must be localized within one resource management domain. <p> Our architecture generalizes and extends the path abstraction to provide dynamic allocation and management of communication resources according to application QoS requirements. Recently, processor capacity reserves in Real-Time Mach [6] have been combined with user-level protocol processing <ref> [4] </ref> for predictable protocol processing inside hosts [29]. However, no support is provided for traffic enforcement or the ability to control protocol processing priority separate from application priority. Several QoS-sensitive CPU scheduling policies have also been proposed recently [30-32]. <p> Server-based implementation: While a server-based implementation is natural for a microkernel operating system, it may perform poorly compared to user-level protocol libraries due to excessive data copying and context switching <ref> [4, 5] </ref>. Implementing the service as a protocol library, however, distributes the functions of admission control and run-time resource management among several address spaces. Since applications may each compete for communication resources, controlling system-wide resources is more effectively done when these functions are localized in a single domain.
Reference: [5] <author> C. A. Thekkath, T. D. Nguyen, E. Moy, and E. Lazowska, </author> <title> "Implementing network protocols at user level," </title> <journal> IEEE/ACM Trans. Networking, </journal> <volume> vol. 1, no. 5, </volume> <pages> pp. 554-565, </pages> <month> October </month> <year> 1993. </year> <month> 24 </month>
Reference-contexts: We realize this service as a user-level server, even though server-based protocol stacks perform poorly compared to user-level protocol libraries or in-kernel implementations <ref> [4, 5] </ref>, for a number of reasons. A server configuration considerably eases software development and debugging, particularly the location and correction of timing-related bugs. Also, since several applications can establish multiple QoS connections, admission control and run-time resource management of these connections must be localized within one resource management domain. <p> Server-based implementation: While a server-based implementation is natural for a microkernel operating system, it may perform poorly compared to user-level protocol libraries due to excessive data copying and context switching <ref> [4, 5] </ref>. Implementing the service as a protocol library, however, distributes the functions of admission control and run-time resource management among several address spaces. Since applications may each compete for communication resources, controlling system-wide resources is more effectively done when these functions are localized in a single domain.
Reference: [6] <author> C. W. Mercer, S. Savage, and H. Tokuda, </author> <title> "Processor capacity reserves for multimedia operating sys-tems," </title> <booktitle> in Proceedings of the IEEE International Conference on Multimedia Computing and Systems, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: We focus on QoS-sensitive communication subsystem design while recognizing that real-time performance cannot be fully guaranteed without additional support from the operating system kernel. Such support could be in the form of processor capacity reserves for the service <ref> [6] </ref> or appropriate system partitioning [7]. We envision a system structure with the communication subsystem distinct from the computation subsystem. The communication subsystem comprises all activities and resources that participate in transmitting data and processing received data from the network. <p> Our architecture generalizes and extends the path abstraction to provide dynamic allocation and management of communication resources according to application QoS requirements. Recently, processor capacity reserves in Real-Time Mach <ref> [6] </ref> have been combined with user-level protocol processing [4] for predictable protocol processing inside hosts [29]. However, no support is provided for traffic enforcement or the ability to control protocol processing priority separate from application priority. Several QoS-sensitive CPU scheduling policies have also been proposed recently [30-32].
Reference: [7] <author> G. Bollella and K. Jeffay, </author> <title> "Supporting co-resident operating systems," </title> <booktitle> in Proc. Real-Time Technology and Applications Symposium, </booktitle> <pages> pp. 4-14, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: We focus on QoS-sensitive communication subsystem design while recognizing that real-time performance cannot be fully guaranteed without additional support from the operating system kernel. Such support could be in the form of processor capacity reserves for the service [6] or appropriate system partitioning <ref> [7] </ref>. We envision a system structure with the communication subsystem distinct from the computation subsystem. The communication subsystem comprises all activities and resources that participate in transmitting data and processing received data from the network.
Reference: [8] <author> T. Barzilai, D. Kandlur, A. Mehra, D. Saha, and S. Wise, </author> <title> "Design and implementation of an RSVP-based quality of service architecture for integrated services Internet," </title> <booktitle> in Proc. Int'l Conf. on Distributed Computing Systems, </booktitle> <month> May </month> <year> 1997. </year>
Reference-contexts: Specifically, while we have focused on a microkernel operating system, we believe that our design approach and issues highlighted are equally applicable, although with necessary modifications, to the in-kernel protocol stacks of monolithic Unix-like operating systems <ref> [8, 9] </ref>. In the next section we note related work in the design of QoS-sensitive communication services. Section 3 presents the goals and architecture of the real-time (guaranteed-QoS) communication service. <p> Practical realization of QoS-A, however, would necessitate architectural mechanisms and extensions similar in flavor to the ones presented in this paper. A novel RSVP-based QoS architecture supporting integrated services in TCP/IP protocol stacks, running on legacy (e.g., Token Ring and Ethernet) and high-speed ATM LAN networks is described in <ref> [8] </ref>. A native-mode ATM transport layer has been designed and implemented in [22]. These architectures also provide support for traffic policing and shaping; however, no support is provided for scheduling protocol processing and incorporation of implementation overheads and constraints.
Reference: [9] <author> R. Engel, D. Kandlur, A. Mehra, and D. Saha, </author> <title> "Exploring the performance impact of QoS support in TCP/IP protocol stacks," </title> <booktitle> in Proc. IEEE INFOCOM, </booktitle> <address> San Francisco, CA, </address> <month> March </month> <year> 1998. </year>
Reference-contexts: Specifically, while we have focused on a microkernel operating system, we believe that our design approach and issues highlighted are equally applicable, although with necessary modifications, to the in-kernel protocol stacks of monolithic Unix-like operating systems <ref> [8, 9] </ref>. In the next section we note related work in the design of QoS-sensitive communication services. Section 3 presents the goals and architecture of the real-time (guaranteed-QoS) communication service.
Reference: [10] <author> A. T. Campbell, C. Aurrecoechea, and L. Hauw, </author> <title> "A review of QoS architectures," </title> <journal> Multimedia Systems Journal, </journal> <year> 1996. </year>
Reference-contexts: A number of approaches are being explored to realize QoS-sensitive communication and computation in the context of distributed multimedia systems. An extensive survey of QoS architectures is provided in <ref> [10] </ref>, which provides a comprehensive view of the state of the art in the provisioning of end-to-end QoS. In the discussion below, we highlight a subset of these approaches, focusing on enhancements and the associated implications for end hosts.
Reference: [11] <author> A. Banerjea, D. Ferrari, B. Mah, M. Moran, D. C. Verma, and H. Zhang, </author> <title> "The Tenet real-time protocol suite: Design, implementation, and experiences," </title> <journal> IEEE/ACM Trans. Networking, </journal> <volume> vol. 4, no. 1, </volume> <pages> pp. 1-11, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: We first highlight communication architectures for QoS, followed by related work in multimedia and real-time operating systems, and then discuss approaches to QoS negotiation and adaptation. Network and protocol support for QoS: The Tenet real-time protocol suite <ref> [11] </ref> is an implementation of real-time communication on wide-area networks (WANs), but it did not consider incorporation of protocol processing overheads into the network-level resource management policies. In particular, the above efforts do not address the problem of QoS-sensitive protocol processing inside hosts.
Reference: [12] <author> D. D. Clark, S. Shenker, and L. Zhang, </author> <title> "Supporting real-time applications in an integrated services packet network: Architecture and mechanism," </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 14-26, </pages> <month> August </month> <year> 1992. </year>
Reference: [13] <author> R. Braden, D. Clark, and S. Shenker, </author> <title> "Integrated services in the Internet architecture: An overview," Request for Comments RFC 1633, </title> <month> July </month> <year> 1994. </year> <note> Xerox PARC. </note>
Reference: [14] <author> J. Wroclawski, </author> <title> "Specification of the controlled-load network element service," Request for Comments (RFC 2211), </title> <month> September </month> <year> 1997. </year>
Reference: [15] <author> S. Blake, D. Black, M. Carlson, E. Davies, Z. Wang, and W. Weiss. </author> <title> An Architecture for Differentiated Services. Internet Draft (draft-ietf-diffserv-arch-01.txt), </title> <month> August </month> <year> 1998. </year>
Reference: [16] <author> S. Floyd and V. Jacobson, </author> <title> "Link-sharing and resource management models for packet networks," </title> <journal> IEEE/ACM Trans. Networking, </journal> <volume> vol. 3, no. 4, </volume> <pages> pp. 365-386, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: The expected QoS requirements of applications and issues involved in sharing link bandwidth across multiple classes of traffic are explored in <ref> [16] </ref>. The signalling required to set up reservations for application flows can be provided by RSVP [17], which initiates reservation setup at the receiver, or ST-II [18], which initiates reservation setup at the sender (similar to RTCOP).
Reference: [17] <author> L. Zhang, S. Deering, D. Estrin, S. Shenker, and D. Zappala, "RSVP: </author> <title> A new resource ReSerVation Protocol," </title> <journal> IEEE Network, </journal> <pages> pp. 8-18, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: The expected QoS requirements of applications and issues involved in sharing link bandwidth across multiple classes of traffic are explored in [16]. The signalling required to set up reservations for application flows can be provided by RSVP <ref> [17] </ref>, which initiates reservation setup at the receiver, or ST-II [18], which initiates reservation setup at the sender (similar to RTCOP). We note that the architectural approach, mechanisms, and extensions developed in this paper are applicable to unicast as well as multicast sessions, for both sender-initiated and receiver-initiated signalling.
Reference: [18] <author> L. Delgrossi and L. Berger, </author> <title> "Internet stream protocol version 2 (ST-2) protocol specification version ST2+," Request for Comments RFC 1819, </title> <month> August </month> <year> 1995. </year> <institution> ST2 Working Group. </institution>
Reference-contexts: The expected QoS requirements of applications and issues involved in sharing link bandwidth across multiple classes of traffic are explored in [16]. The signalling required to set up reservations for application flows can be provided by RSVP [17], which initiates reservation setup at the receiver, or ST-II <ref> [18] </ref>, which initiates reservation setup at the sender (similar to RTCOP). We note that the architectural approach, mechanisms, and extensions developed in this paper are applicable to unicast as well as multicast sessions, for both sender-initiated and receiver-initiated signalling.
Reference: [19] <author> K. Nahrstedt and J. M. Smith, </author> <title> "Design, implementation and experiences of the OMEGA end-point architecture," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 14, no. 7, </volume> <pages> pp. 1263-1279, </pages> <month> September </month> <year> 1996. </year>
Reference-contexts: We note that the architectural approach, mechanisms, and extensions developed in this paper are applicable to unicast as well as multicast sessions, for both sender-initiated and receiver-initiated signalling. QoS architectures: The OMEGA <ref> [19] </ref> end point architecture provides support for end-to-end QoS guarantees. The primary focus of OMEGA is development of an integrated framework for the specification and translation of application QoS requirements and allocation of the necessary resources.
Reference: [20] <author> K. Nahrstedt and J. M. Smith, </author> <title> "The QoS broker," </title> <journal> IEEE Multimedia, </journal> <volume> vol. 2, no. 1, </volume> <pages> pp. 53-67, </pages> <month> Spring </month> <year> 1995. </year>
Reference-contexts: The primary focus of OMEGA is development of an integrated framework for the specification and translation of application QoS requirements and allocation of the necessary resources. Application QoS requirements are translated to network QoS requirements by the QoS Broker <ref> [20] </ref>, which negotiates for the necessary host and network resources. The OMEGA approach assumes appropriate support from the operating system for QoS-sensitive application execution, and the network subsystem for provision of transport-to-transport layer guarantees (the subject of this paper).
Reference: [21] <author> A. T. Campbell, G. Coulson, and D. Hutchison, </author> <title> "A quality of service architecture," </title> <journal> Computer Communication Review, </journal> <month> April </month> <year> 1994. </year>
Reference-contexts: The OMEGA approach assumes appropriate support from the operating system for QoS-sensitive application execution, and the network subsystem for provision of transport-to-transport layer guarantees (the subject of this paper). QoS-A <ref> [21] </ref> is a layered architecture focusing on QoS provisioning within the communication subsystem and the network. It provides features such as end-to-end admission control, resource reservation, QoS translation between layers, and QoS monitoring and maintenance. QoS-A specifies a functionally rich and general architecture supporting networked multimedia applications.
Reference: [22] <author> R. Ahuja, S. Keshav, and H. Saran, </author> <title> "Design, implementation, and performance of a native mode ATM transport layer," </title> <booktitle> in Proc. IEEE INFOCOM, </booktitle> <pages> pp. 206-214, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: A novel RSVP-based QoS architecture supporting integrated services in TCP/IP protocol stacks, running on legacy (e.g., Token Ring and Ethernet) and high-speed ATM LAN networks is described in [8]. A native-mode ATM transport layer has been designed and implemented in <ref> [22] </ref>. These architectures also provide support for traffic policing and shaping; however, no support is provided for scheduling protocol processing and incorporation of implementation overheads and constraints.
Reference: [23] <author> R. Gopalakrishnan and G. M. Parulkar, </author> <title> "A real-time upcall facility for protocol processing with QoS guarantees," </title> <booktitle> in Proc. ACM Symp. on Operating Systems Principles, </booktitle> <address> p. 231, </address> <month> December </month> <year> 1995. </year>
Reference-contexts: A native-mode ATM transport layer has been designed and implemented in [22]. These architectures also provide support for traffic policing and shaping; however, no support is provided for scheduling protocol processing and incorporation of implementation overheads and constraints. Operating system support for QoS-sensitive communication: Real-time upcalls (RTUs) <ref> [23] </ref> are a mechanism to schedule protocol processing for networked multimedia applications via event-based upcalls [24]. Protocol processing activities are scheduled via an extended version of the rate monotonic (RM) scheduling policy [25]. Similar to our approach, delayed preemption is adopted to reduce the number of context switches.
Reference: [24] <author> D. D. Clark, </author> <title> "The structuring of systems using upcalls," </title> <booktitle> in Proc. ACM Symp. on Operating Systems Principles, </booktitle> <pages> pp. 171-180, </pages> <year> 1985. </year>
Reference-contexts: Operating system support for QoS-sensitive communication: Real-time upcalls (RTUs) [23] are a mechanism to schedule protocol processing for networked multimedia applications via event-based upcalls <ref> [24] </ref>. Protocol processing activities are scheduled via an extended version of the rate monotonic (RM) scheduling policy [25]. Similar to our approach, delayed preemption is adopted to reduce the number of context switches.
Reference: [25] <author> C. Liu and J. Layland, </author> <title> "Scheduling algorithms for multiprogramming in hard real-time environment," </title> <journal> Journal of the ACM, </journal> <volume> vol. 1, no. 20, </volume> <pages> pp. 46-61, </pages> <month> January </month> <year> 1973. </year>
Reference-contexts: Operating system support for QoS-sensitive communication: Real-time upcalls (RTUs) [23] are a mechanism to schedule protocol processing for networked multimedia applications via event-based upcalls [24]. Protocol processing activities are scheduled via an extended version of the rate monotonic (RM) scheduling policy <ref> [25] </ref>. Similar to our approach, delayed preemption is adopted to reduce the number of context switches. Our approach differs from RTUs in that we use a thread-based execution model for protocol processing, schedule threads via a modified earliest-deadline-first (EDF) policy [25], and extend resource management policies within the communication subsystem to <p> an extended version of the rate monotonic (RM) scheduling policy <ref> [25] </ref>. Similar to our approach, delayed preemption is adopted to reduce the number of context switches. Our approach differs from RTUs in that we use a thread-based execution model for protocol processing, schedule threads via a modified earliest-deadline-first (EDF) policy [25], and extend resource management policies within the communication subsystem to account for a number of implementation overheads and constraints. Similar to our approach, rate-based flow control of multimedia streams via kernel-based communication threads is also proposed in [26].
Reference: [26] <author> D. K. Y. Yau and S. S. Lam, </author> <title> "An architecture towards efficient OS support for distributed multimedia," </title> <booktitle> in Proc. Multimedia Computing and Networking (MMCN '96), </booktitle> <month> January </month> <year> 1996. </year> <month> 25 </month>
Reference-contexts: Similar to our approach, rate-based flow control of multimedia streams via kernel-based communication threads is also proposed in <ref> [26] </ref>. However, in contrast to our notion of per-connection threads, a coarser notion of per-process kernel threads is adopted. This scheme is clearly not suitable for an application with multiple QoS connections, each with different QoS requirements and traffic characteristics. <p> This scheme is clearly not suitable for an application with multiple QoS connections, each with different QoS requirements and traffic characteristics. Mechanisms for scheduling multiple communication threads, and the issues involved in reception side processing, are not considered. More importantly, the architecture outlined in <ref> [26] </ref> does not consider provision of signalling and resource management services within the communication subsystem. Explicit operating system support for communication is a focus of the Scout operating system, which uses the notion of paths as a fundamental operating system structuring technique [27].
Reference: [27] <author> D. Mosberger and L. L. Peterson, </author> <title> "Making paths explicit in the Scout operating system," </title> <booktitle> in Proc. USENIX Symp. on Operating Systems Design and Implementation, </booktitle> <pages> pp. 153-168, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: More importantly, the architecture outlined in [26] does not consider provision of signalling and resource management services within the communication subsystem. Explicit operating system support for communication is a focus of the Scout operating system, which uses the notion of paths as a fundamental operating system structuring technique <ref> [27] </ref>. A 4 path can be viewed as a logical channel through a multilayered system over which I/O data flows. <p> De-multiplexing incoming packets early and absorbing bursts in distinct per-connection queues is an attractive way to prevent receive livelock, an observation also made in the context of paths in Scout <ref> [27] </ref>. Our architectural approach facilitates provision of QoS guarantees while preventing receive livelock.
Reference: [28] <author> F.Travostino, E.Menze, and F.Reynolds, </author> <title> "Paths: Programming with system resources in support of real-time distributed applications," </title> <booktitle> in Proc. IEEE Workshop on Object-Oriented Real-Time Dependable Systems, </booktitle> <month> February </month> <year> 1996. </year>
Reference-contexts: A 4 path can be viewed as a logical channel through a multilayered system over which I/O data flows. As we demonstrate, the CORDS path abstraction <ref> [28] </ref>, which is similar to Scout paths, provides a rich framework for development of real-time communication services, especially communication resource management, for distributed applications. Paths in [28] are envisioned primarily as a static, relatively coarse-grain mechanism, while Scout paths are not associated with communication resources or assigned priorities via admission control. <p> As we demonstrate, the CORDS path abstraction <ref> [28] </ref>, which is similar to Scout paths, provides a rich framework for development of real-time communication services, especially communication resource management, for distributed applications. Paths in [28] are envisioned primarily as a static, relatively coarse-grain mechanism, while Scout paths are not associated with communication resources or assigned priorities via admission control. Our architecture generalizes and extends the path abstraction to provide dynamic allocation and management of communication resources according to application QoS requirements. <p> Specifically, though it provides only preemptive fixed-priority scheduling, the 7.2 release includes the CORDS (Communication Object for Real-time Dependable Systems) protocol environment <ref> [28] </ref> in which our implementation resides. CORDS is based on the x-kernel object-oriented networking framework originally developed at the University of Arizona [48], with some significant extensions for controlled allocation of system resources. <p> CORDS provides two abstractions, paths and allocators, for reservation and allocation of system resources within the CORDS framework. Resources associated with paths include dynamically allocated memory, input packet buffers, and input threads that shepherd messages up the protocol stack <ref> [28] </ref>. Paths, coupled with allocators, provide a capability for reserving and allocating resources at any protocol stack layer on behalf of a particular connection, or class of messages.
Reference: [29] <author> C. Lee, K. Yoshida, C. Mercer, and R. Rajkumar, </author> <title> "Predictable communication protocol processing in Real-Time Mach," </title> <booktitle> in Proc. of 2nd Real-Time Technology and Applications Symposium, </booktitle> <month> June </month> <year> 1996. </year>
Reference-contexts: Our architecture generalizes and extends the path abstraction to provide dynamic allocation and management of communication resources according to application QoS requirements. Recently, processor capacity reserves in Real-Time Mach [6] have been combined with user-level protocol processing [4] for predictable protocol processing inside hosts <ref> [29] </ref>. However, no support is provided for traffic enforcement or the ability to control protocol processing priority separate from application priority. Several QoS-sensitive CPU scheduling policies have also been proposed recently [30-32].
Reference: [30] <author> C. Waldspurger, </author> <title> Lottery and Stride Scheduling: Flexible Proportional-Share Resource Management, </title> <type> PhD thesis, Technical Report, </type> <institution> MIT/LCS/TR-667, Laboratory for CS, MIT, </institution> <month> September </month> <year> 1995. </year>
Reference: [31] <author> I. Stoica, H. Abdel-Wahab, K. Jeffay, S. K. Baruah, J. E. Gehrke, and C. G. Plaxton, </author> <title> "A proportional share resource allocation algorithm for real-time time-shared systems," </title> <booktitle> in Proc. 17th Real-Time Systems Symposium, </booktitle> <pages> pp. 288-299, </pages> <month> December </month> <year> 1996. </year>
Reference: [32] <author> P. Goyal, X. Guo, and H. M. Vin, </author> <title> "A hierarchical CPU scheduler for multimedia operating systems," </title> <booktitle> in Proc. 2nd OSDI Symposium, </booktitle> <pages> pp. 107-121, </pages> <month> October </month> <year> 1996. </year>
Reference: [33] <author> K. K. Ramakrishnan, </author> <title> "Performance considerations in designing network interfaces," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 11, no. 2, </volume> <pages> pp. 203-219, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: Several QoS-sensitive CPU scheduling policies have also been proposed recently [30-32]. These schemes can be utilized for network bandwidth allocation, but do not suffice for managing all available communication resources. Receive livelock elimination: Recent efforts have also addressed an important problem associated with data reception, namely, receive livelock <ref> [33] </ref>.
Reference: [34] <author> J. Mogul and K. K. Ramakrishnan, </author> <title> "Eliminating receive livelock in an interrupt-driven kernel," </title> <booktitle> in Winter USENIX Conference, </booktitle> <month> January </month> <year> 1996. </year>
Reference-contexts: These schemes can be utilized for network bandwidth allocation, but do not suffice for managing all available communication resources. Receive livelock elimination: Recent efforts have also addressed an important problem associated with data reception, namely, receive livelock [33]. Receive livelock has been addressed at length in <ref> [34] </ref> via a combination of techniques (such as limiting interrupt arrival rates, fair polling, processing packets to completion, and regulating CPU usage for protocol processing) to avoid receive livelock and maintain system throughput near the maximum system input capacity under high load.
Reference: [35] <author> K. Jeffay, F. D. Smith, A. Moorthy, and J. Anderson, </author> <title> "Proportional share scheduling of operating system services for real-time applications," </title> <booktitle> in Proc. Real-Time Technology and Applications Symposium, </booktitle> <address> Madrid, Spain, </address> <month> December </month> <year> 1998. </year>
Reference-contexts: Another approach is to schedule applications in a proportional share manner and use the cumulative rate to limit packet processing to solve the receive livelock problem <ref> [35] </ref>. Lazy receiver processing (LRP) [36], while not completely eliminating it, significantly reduces the likelihood of receive livelock even under high input load. In LRP, an incoming packet is classified and enqueued, but not processed, until the application receives the data.
Reference: [36] <author> P. Druschel and G. Banga, </author> <title> "Lazy receiver processing (LRP): A network subsystem architecture for server systems," </title> <booktitle> in Proc. 2nd OSDI Symposium, </booktitle> <pages> pp. 261-275, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: Another approach is to schedule applications in a proportional share manner and use the cumulative rate to limit packet processing to solve the receive livelock problem [35]. Lazy receiver processing (LRP) <ref> [36] </ref>, while not completely eliminating it, significantly reduces the likelihood of receive livelock even under high input load. In LRP, an incoming packet is classified and enqueued, but not processed, until the application receives the data.
Reference: [37] <author> L. Krishnamurthy, </author> <title> AQUA: An Adaptive Quality of Service Architecture for Distributed Multimedia Applications, </title> <type> PhD thesis, </type> <institution> University of Kentucky, </institution> <year> 1997. </year>
Reference-contexts: Dynamic QoS negotiation and adaptation: Since a broad class of multimedia applications are soft real-time in nature, i.e., can tolerate limited fluctuations in the delivered QoS, several research efforts have explored the issues involved in supporting QoS negotiation and adaptation functions at end hosts. The AQUA system <ref> [37] </ref> is one such effort which has developed QoS negotiation and adaptation support for allocation of CPU and network resources. Similarly, a QoS-adaptive transport system is described in [38] that incorporates a QoS-aware API and mechanisms to assist applications to adapt to fluctuations in the delivered network QoS.
Reference: [38] <author> A. T. Campbell and G. Coulson, </author> <title> "QoS adaptive transports: Delivering scalable media to the desktop," </title> <journal> IEEE Network Magazine, </journal> <pages> pp. 18-27, </pages> <month> March/April </month> <year> 1997. </year>
Reference-contexts: The AQUA system [37] is one such effort which has developed QoS negotiation and adaptation support for allocation of CPU and network resources. Similarly, a QoS-adaptive transport system is described in <ref> [38] </ref> that incorporates a QoS-aware API and mechanisms to assist applications to adapt to fluctuations in the delivered network QoS. A scheme for adaptive rate-controlled scheduling is presented in [39].
Reference: [39] <author> D. K. Y. Yau and S. S. Lam, </author> <title> "Adaptive rate-controlled scheduling for multimedia applications," </title> <booktitle> in Proc. of ACM Multimedia, </booktitle> <month> November </month> <year> 1996. </year>
Reference-contexts: Similarly, a QoS-adaptive transport system is described in [38] that incorporates a QoS-aware API and mechanisms to assist applications to adapt to fluctuations in the delivered network QoS. A scheme for adaptive rate-controlled scheduling is presented in <ref> [39] </ref>. QoS negotiation and adaptation support has also been developed for real-time applications [40], which provides support for specification of QoS compromises and supports graceful QoS degradation under overload or failure conditions.
Reference: [40] <author> T. Abdelzaher, E. Atkins, and K. Shin, </author> <title> "QoS negotiation in real-time systems and its application to automated flight control," </title> <booktitle> in Proc. Real-Time Technology and Applications Symposium, </booktitle> <pages> pp. 228-238, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: A scheme for adaptive rate-controlled scheduling is presented in [39]. QoS negotiation and adaptation support has also been developed for real-time applications <ref> [40] </ref>, which provides support for specification of QoS compromises and supports graceful QoS degradation under overload or failure conditions. While we do not consider dynamic QoS negotiation and adaptation in this paper, most of the architectural mechanisms and enhancements provided can be utilized for such scenarios. <p> A relaxed admission control policy, for example, coupled with these component mechanisms could be used to implement a statistical guarantee model. Similarly, changing the policy for expression of application QoS requirements, along with a suitable admission control policy, facilitates QoS negotiation and adaptation, as is demonstrated in <ref> [40] </ref>. 7 Routines Parameters Invoked By Function Performed Miscellaneous rtcInit none both service initialization rtcGetParameter chan id, param type both query parameter on specified real-time connection Signalling rtcRegisterPort local port, agent function receiver register local port and agent for signalling rtcUnRegisterPort local port receiver unregister local signalling port rtcCreateConnection remote host/port,
Reference: [41] <author> T. Abdelzaher, S. Dawson, W. Feng, S. Ghosh, F. Jahanian, S. Johnson, A. Mehra, T. Mitton, J. Norton, A. Shaikh, K. Shin, V. Vaidyan, Z. Wang, and H. Zou, </author> <title> "ARMADA middleware suite," </title> <booktitle> in Proc. of IEEE Workshop on Middleware for Distributed Real-Time Systems and Services, </booktitle> <pages> pp. 11-18, </pages> <address> San Francisco, CA, </address> <month> December </month> <year> 1997. </year>
Reference-contexts: In this section, we hilight the architectural components of unicast communication that, together with a set of user-specified policies, can implement several real-time communication models. The overall service is currently being utilized in the ARMADA project <ref> [41] </ref>, which aims to implement a set of communication and middleware services that provide support for end-to-end guarantees and fault-tolerance for embedded real-time distributed applications. 3.1 Architectural Requirements Common to QoS-sensitive communication service models are the following three architectural requirements: (i) maintenance of per-connection QoS guarantees, (ii) overload protection via per-connection
Reference: [42] <author> A. Mehra, A. Indiresan, and K. Shin, </author> <title> "Structuring communication software for quality of service guarantees," </title> <booktitle> in Proc. 17th Real-Time Systems Symposium, </booktitle> <pages> pp. 144-154, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: and middleware services that provide support for end-to-end guarantees and fault-tolerance for embedded real-time distributed applications. 3.1 Architectural Requirements Common to QoS-sensitive communication service models are the following three architectural requirements: (i) maintenance of per-connection QoS guarantees, (ii) overload protection via per-connection traffic enforcement, and (iii) fairness to best-effort traffic <ref> [42] </ref>. Earlier work in [42] presented and justified a high-level architectural design in the context of a specific communication service model. <p> provide support for end-to-end guarantees and fault-tolerance for embedded real-time distributed applications. 3.1 Architectural Requirements Common to QoS-sensitive communication service models are the following three architectural requirements: (i) maintenance of per-connection QoS guarantees, (ii) overload protection via per-connection traffic enforcement, and (iii) fairness to best-effort traffic <ref> [42] </ref>. Earlier work in [42] presented and justified a high-level architectural design in the context of a specific communication service model.
Reference: [43] <author> S. J. Le*er, M. K. McKusick, M. J. Karels, and J. S. Quarterman, </author> <title> The Design and Implementation of the 4.3BSD Unix Operating System, </title> <publisher> Addison Wesley, </publisher> <month> May </month> <year> 1989. </year>
Reference-contexts: Invocation via RTC API: Applications request establishment and teardown of guaranteed-QoS connections, and perform data transfer on these connections, by invoking routines exported by the RTC API. The design of the API has been significantly influenced by the structure of the sockets API in BSD Unix <ref> [43] </ref> and its variants.
Reference: [44] <author> T. Abdelzaher and K. Shin, </author> <title> "End-host architecture for QoS-adaptive communication," </title> <booktitle> in to appear in Proc. Real-Time Technology and Applications Symposium, </booktitle> <address> Denver, Colorado, </address> <month> June </month> <year> 1998. </year>
Reference-contexts: We use CLIPS to provide connection endpoints with QoS-sensitive allocation of CPU and link resources. The real-time communication service described in this paper uses a subset of CLIPS features: the complete library includes support for QoS adaptation and resource monitoring as detailed in <ref> [44] </ref>. Internal to CLIPS, each clip is provided with a message queue to buffer messages generated or received on the corresponding endpoint, a communication handler thread to process these messages, and a packet queue to stage packets waiting to be transmitted or received. <p> We plan to conduct further experiments with a number of stored video traces. We are also currently extending the communication architecture to allow for QoS-adaptation to available host and network resources. We have implemented an end-host architecture for adaptive-QoS communication services <ref> [44] </ref> and plan to use components of the architecture presented in this paper to implement an end-to-end adaptive QoS communication scheme. In Section 6 we described the complex process of parameterizing the overheads of the communication subsystem and target platform.
Reference: [45] <author> D. Ferrari and D. C. Verma, </author> <title> "A scheme for real-time channel establishment in wide-area networks," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 8, no. 3, </volume> <pages> pp. 368-379, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: We have implemented a communication paradigm amenable to such an abstraction, namely the real-time channels model <ref> [45, 46] </ref>. A real-time channel is a unicast virtual connection between a source and destination host with associated performance guarantees on message delay and available bandwidth.
Reference: [46] <author> D. D. Kandlur, K. G. Shin, and D. Ferrari, </author> <title> "Real-time communication in multi-hop networks," </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> vol. 5, no. 10, </volume> <pages> pp. 1044-1056, </pages> <month> October </month> <year> 1994. </year> <month> 26 </month>
Reference-contexts: We have implemented a communication paradigm amenable to such an abstraction, namely the real-time channels model <ref> [45, 46] </ref>. A real-time channel is a unicast virtual connection between a source and destination host with associated performance guarantees on message delay and available bandwidth. <p> The algorithm determines relative connection priority so that QoS requirements for all admitted connections are satisfied. Details on D order and subsequent extensions to account for CPU preemption costs and the relationship between CPU and link bandwidth are available in <ref> [46] </ref> and [47], respectively. 5 Service Implementation In this section we describe how the architectural components described in the preceding sections can be implemented on a realistic platform. Our experimental testbed and implementation environment is based on the MK 7.2 microkernel operating system from the Open Group Research Institute.
Reference: [47] <author> A. Mehra, A. Indiresan, and K. Shin, </author> <title> "Resource management for real-time communication: Making theory meet practice," </title> <booktitle> in Proc. 2nd Real-Time Technology and Applications Symposium, </booktitle> <pages> pp. 130-138, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: The algorithm determines relative connection priority so that QoS requirements for all admitted connections are satisfied. Details on D order and subsequent extensions to account for CPU preemption costs and the relationship between CPU and link bandwidth are available in [46] and <ref> [47] </ref>, respectively. 5 Service Implementation In this section we describe how the architectural components described in the preceding sections can be implemented on a realistic platform. Our experimental testbed and implementation environment is based on the MK 7.2 microkernel operating system from the Open Group Research Institute.
Reference: [48] <author> N. C. Hutchinson and L. L. Peterson, </author> <title> "The x-Kernel: An architecture for implementing network protocols," </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> vol. 17, no. 1, </volume> <pages> pp. 1-13, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Specifically, though it provides only preemptive fixed-priority scheduling, the 7.2 release includes the CORDS (Communication Object for Real-time Dependable Systems) protocol environment [28] in which our implementation resides. CORDS is based on the x-kernel object-oriented networking framework originally developed at the University of Arizona <ref> [48] </ref>, with some significant extensions for controlled allocation of system resources. CORDS is also available for Windows NT and, as such, serves as a justifiable vehicle for exploring the realization of communication services on modern microkernels with limited real-time support.
Reference: [49] <author> L. McVoy and C. Staelin, "lmbench: </author> <title> Portable tools for performance analysis," </title> <booktitle> in Proc. USENIX Winter Conference, </booktitle> <pages> pp. 279-295, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: Beyond the fixed overhead, the time spent in this routine increases with message size. RTC API copies application data into path-specific message buffers in order to preserve application data integrity in the worst case. For our platform, lmbench <ref> [49] </ref> reports a memory copy bandwidth of 40 MB/second; The increase in C a can be largely attributed to the time to copy in application data. An anomalous trend is observed for C r;w a .
Reference: [50] <author> J. C. Brustoloni and P. Steenkiste, </author> <title> "Effects of buffering semantics on I/O performance," </title> <booktitle> in Proc. USENIX Symp. on Operating Systems Design and Implementation, </booktitle> <pages> pp. 277-291, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: While the RTC API overheads are relatively high, these measurements are for an unoptimized implementation and can be improved substantially with careful performance optimizations. With appropriate buffer management and API buffering semantics <ref> [50, 51] </ref> it may even be possible to completely eliminate the copying of data within RTC API. However, more immediately we are concerned with ensuring that the overheads incurred in RTC API do not result in QoS-insensitive handling of data.
Reference: [51] <author> B. Murphy, S. Zeadally, and C. J. Adams, </author> <title> "An analysis of process and memory models to support high-speed networking in a UNIX environment," </title> <booktitle> in Proc. USENIX Winter Conference, </booktitle> <month> January </month> <year> 1996. </year>
Reference-contexts: While the RTC API overheads are relatively high, these measurements are for an unoptimized implementation and can be improved substantially with careful performance optimizations. With appropriate buffer management and API buffering semantics <ref> [50, 51] </ref> it may even be possible to completely eliminate the copying of data within RTC API. However, more immediately we are concerned with ensuring that the overheads incurred in RTC API do not result in QoS-insensitive handling of data.
Reference: [52] <author> T. Blackwell, </author> <title> "Speeding up protocols for small messages," </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 85-95, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: attributed to cache effects, which have been shown to affect protocol stack execution 18 Message Size Service Library Routine 1 byte 1k bytes 10k bytes 30k bytes rtcSendMessage 1170 1210 1480 2070 rtcRecvMessage (msg waiting) 870 894 1660 3210 Table 3: Application-level send and receive latencies (in s). latency significantly <ref> [52, 53] </ref>. In the receive path, the message reassembly cost is only incurred during the processing of the last packet of a message. The average reassembly cost increases roughly linearly with message size, from 17 s for message size of 1.4K to 239 s for message size of 28K.
Reference: [53] <author> E. Nahum, D. Yates, J. Kurose, and D. Towsley, </author> <title> "Cache behavior of network protocols," </title> <booktitle> in Proc. of ACM SIGMETRICS, </booktitle> <pages> pp. 169-180, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: attributed to cache effects, which have been shown to affect protocol stack execution 18 Message Size Service Library Routine 1 byte 1k bytes 10k bytes 30k bytes rtcSendMessage 1170 1210 1480 2070 rtcRecvMessage (msg waiting) 870 894 1660 3210 Table 3: Application-level send and receive latencies (in s). latency significantly <ref> [52, 53] </ref>. In the receive path, the message reassembly cost is only incurred during the processing of the last packet of a message. The average reassembly cost increases roughly linearly with message size, from 17 s for message size of 1.4K to 239 s for message size of 28K.
Reference: [54] <author> A. Mehra, Z. Wang, and K. Shin, </author> <title> "Self-parameterizing protocol stacks for guaranteed quality of service," </title> <note> available at ftp://rtcl.eecs.umich.edu/outgoing/ashish/selfparam.ps, </note> <month> June </month> <year> 1998. </year> <month> 27 </month>
Reference-contexts: The efforts involved in detailed manual profiling on each target platform illustrate the need for an automated approach to profiling and system parameterization. We have, therefore, also begun to explore self-parameterizing protocol stacks for QoS-sensitive communication subsystems <ref> [54] </ref>.
References-found: 54

