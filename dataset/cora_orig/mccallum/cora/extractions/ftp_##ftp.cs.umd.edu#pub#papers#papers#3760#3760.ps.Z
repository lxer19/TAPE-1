URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3760/3760.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Email: aporter@cs.umd.edu cat@intgp1.att.com harvey@cs.umd.edu votta@research.att.com  
Title: An Experiment to Assess the Cost-Benefits of Code Inspections in Large Scale Software Development  
Author: A. Porter C. A. Toman H. Siy L. G. Votta 
Address: College Park, Maryland 20742 Naperville, Illinois 60566  
Affiliation: Computer Science Department Software Production Research Department University of Maryland AT&T Bell Laboratories  
Abstract: We conducted a long-term experiment to compare the costs and benefits of several different software inspection methods. These methods were applied by professional developers to a commercial software product they were creating. Because the laboratory for this experiment was a live development effort, we took special care to minimize cost and risk to the project, while maximizing our ability to gather useful data. This article has several goals: (1) to describe the experiment's design and show how we used simulation techniques to optimize it, (2) to present our results and discuss their implications for both software practitioners and researchers, and (3) to discuss several new questions raised by our findings. For each inspection we randomly assigned 3 independent variables: (1) the number of reviewers on each inspection team (1, 2 or 4), (2) the number of teams inspecting the code unit (1 or 2), and (3) the requirement that defects be repaired between the first and second team's inspections. The reviewers for each inspection were randomly selected without replacement from a pool of 11 experienced software developers. The dependent variables for each inspection included inspection interval (elapsed time), total effort, and the defect detection rate. Our results are based on the observation of 88 inspections and challenge certain long-held beliefs about the most cost-effective ways to conduct inspections and raise some questions about the benefits of recently proposed methods.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Karla Ballman and Lawrence G. Votta. </author> <title> Organizational congestion in large scale software development. </title> <booktitle> In Third International Conference on Software Process, </booktitle> <pages> pages 123-134, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Additional sessions occur only if the original artifact or the inspection itself is believed to be seriously 1 As developer's calendars fill up, it becomes increasingly difficult to schedule meetings. This pushes meeting dates farther and farther into the future, increasing the development interval. <ref> [1] </ref> 2 flawed. But some authors have argued that multiple session inspections might be more effective. Tsai et al. [21] developed the N-fold inspection process, in which N teams each carry out independent inspections of the entire artifact.
Reference: [2] <author> Barry Boehm. </author> <title> Verifying and validating software requirements and design specifications. </title> <journal> IEEE Software, </journal> <volume> 1(1) </volume> <pages> 75-88, </pages> <month> January </month> <year> 1984. </year>
Reference-contexts: They are then sent to the artifact's author for repair. Under some conditions the entire process may be repeated one or more times. Many articles have been written about inspections. Most, however, are case studies describing their successful use <ref> [9, 10, 23, 20, 27, 14, 2] </ref> . Few critically analyze inspections or rigorously evaluate alternative inspection approaches.
Reference: [3] <author> F. O. Buck. </author> <title> Indicators of quality inspections. </title> <type> Technical Report 21.802, </type> <institution> IBM Systems Products Division, Kingston, </institution> <address> NY, </address> <month> September </month> <year> 1981. </year>
Reference-contexts: Team Size: Inspections are usually carried out by a team of four to six reviewers. Buck <ref> [3] </ref> provides data (from an uncontrolled experiment) that showed no difference in the effectiveness of three, four, and five-person teams. However, no studies have measured the effect of team size on inspection interval. Single-Session vs. Multiple-Session Inspections: Traditionally, inspections are carried out in a single session.
Reference: [4] <author> K P Burnham and W S Overton. </author> <title> Estimation of the size of a closed population when capture probabilities vary among animals. </title> <journal> Biometrika, </journal> <volume> 65 </volume> <pages> 625-633, </pages> <year> 1978. </year>
Reference: [5] <author> John M. Chambers, William S. Cleveland, Beat Kleiner, and Paul A. Tukey. </author> <title> Graphical Methods for Data Analysis. </title> <booktitle> Wadsworth International Group, </booktitle> <address> Belmont, California, </address> <year> 1983. </year>
Reference-contexts: The data's median is denoted by a bold line within the box. The dashed vertical lines attached to the box indicate the tails of the distribution; they extend to the standard range of the data (1.5 times the inter-quartile range). All other detached points are "outliers". <ref> [5] </ref> 16 Number of Sessions Totals 1 2 Team Size With Repair No Repair 1 7 5 18 30 4 13 0 0 13 Totals 46 9 33 88 Table 2: This table shows the number of inspections allocated to each treatment.
Reference: [6] <author> Stephen G. Eick, Clive R. Loader, M. David Long, Scott A. Vander Wiel, and Lawrence G. Votta. </author> <title> Estimating software fault content before coding. </title> <booktitle> In Proceedings of the 14th International Conference on Software Engineering, </booktitle> <pages> pages 59-65, </pages> <month> May </month> <year> 1992. </year>
Reference: [7] <author> Stephen G Eick, Clive R Loader, M. David Long, Scott A Vander Wiel, and Lawrence G Votta. </author> <title> Capture-recapture and other statistical methods for software inspection data. </title> <booktitle> In Computing Science and Statistics: Proceedings of the 25th Symposium on the Interface, </booktitle> <address> San Diego, California, </address> <month> March </month> <year> 1993. </year> <title> Interface Foundation of North America. </title>
Reference: [8] <author> M. E. Fagan. </author> <title> Design and code inspections to reduce errors in program development. </title> <journal> IBM Systems Journal, </journal> <volume> 15(3) </volume> <pages> 216-245, </pages> <year> 1976. </year>
Reference-contexts: Group-centered vs. Individual-centered Inspections: It is widely believed that most defects are first identified during the collection meeting as a result of group interaction <ref> [8] </ref> . Consequently, most research has focused on streamlining the collection meeting by determining who should attend, what roles they should play, how long the meeting should last, etc.
Reference: [9] <author> P. J. Fowler. </author> <title> In-process inspections of work products at at&t. </title> <journal> AT&T Technical Journal, </journal> <month> March-April </month> <year> 1986. </year>
Reference-contexts: They are then sent to the artifact's author for repair. Under some conditions the entire process may be repeated one or more times. Many articles have been written about inspections. Most, however, are case studies describing their successful use <ref> [9, 10, 23, 20, 27, 14, 2] </ref> . Few critically analyze inspections or rigorously evaluate alternative inspection approaches.
Reference: [10] <author> D. P. Freeman and G. M. Weinberg. </author> <title> Handbook of Walkthroughs, Inspections and Technical Reviews. Little, </title> <publisher> Brown, </publisher> <address> Boston, MA, </address> <year> 1982. </year>
Reference-contexts: They are then sent to the artifact's author for repair. Under some conditions the entire process may be repeated one or more times. Many articles have been written about inspections. Most, however, are case studies describing their successful use <ref> [9, 10, 23, 20, 27, 14, 2] </ref> . Few critically analyze inspections or rigorously evaluate alternative inspection approaches.
Reference: [11] <author> Watts Humphrey. </author> <title> Managing the Software Process. </title> <publisher> Addison-Wesley, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: On the other hand, several recent studies have concluded that most defects are actually found by individuals prior to the collection meeting. Humphrey <ref> [11] </ref> claims that the percentage of defects first discovered at the collection meeting ("meeting gain rate") averages about 25%. In an industrial case study of 50 design inspections, Votta [25] found far lower meeting gain rates (about 5%).
Reference: [12] <institution> IEEE Standard for software reviews and audits. Soft. Eng. Tech. Comm. of the IEEE Computer Society, </institution> <year> 1989. </year> <note> IEEE Std 1028-1988. </note>
Reference-contexts: Below, we review the relevant research literature, describe the various inspection approaches we examined, and present our experimental design, analysis, and conclusions. 1.1 Inspection Process Summary and Literature Review To eliminate defects, many organizations use an iterative, three-step inspection procedure: Preparation, Collection, Repair <ref> [12] </ref> . First, a team of reviewers each reads the artifact separately, detecting as many defects as possible. Next, these newly discovered defects are collected, usually at a team meeting. They are then sent to the artifact's author for repair.
Reference: [13] <author> Charles M. Judd, Eliot R. Smith, and Louise H. Kidder. </author> <title> Research Methods in Social Relations. </title> <publisher> Holt, Rinehart and Winston, Inc., </publisher> <address> Fort Worth, TX, sixth edition, </address> <year> 1991. </year>
Reference-contexts: Each study participant was given a simple "bill of rights", reminding them of their right to withdraw from the study at anytime with no recriminations from the researchers or his/her management <ref> [13] </ref> . Each participant acknowledged this right at the beginning of the experiment by signing a release form. <p> Because experiments that use professional developers creating professional products can have very strong validity, but can put the participated project at risk. A similar problem confronts medical researchers when assessing the efficacy of drug treatments for diseases <ref> [13] </ref> . They solve the problem like we did through an agreement with their subjects in the study. 9 2.3.5 Threats to Internal Validity Threats to internal validity are influences that can affect the dependent variable without the researcher's knowledge.
Reference: [14] <author> John C. Kelly, Joseph S. Sherif, and Jonathan Hops. </author> <title> An analysis of defect densities found during software inspecitons. </title> <booktitle> In SEL Workshop Number 15, </booktitle> <institution> Goddard Space Flight Center, Greenbelt, MD, </institution> <month> nov </month> <year> 1990. </year>
Reference-contexts: They are then sent to the artifact's author for repair. Under some conditions the entire process may be repeated one or more times. Many articles have been written about inspections. Most, however, are case studies describing their successful use <ref> [9, 10, 23, 20, 27, 14, 2] </ref> . Few critically analyze inspections or rigorously evaluate alternative inspection approaches.
Reference: [15] <author> John C. Knight and E. Ann Myers. </author> <title> An improved inspection technique. </title> <journal> Communications of the ACM, </journal> <volume> 36(11) </volume> <pages> 51-61, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: N-fold inspections will find more defects than regular inspections as long as the teams don't completely duplicate each other's work. However, they are far more expensive than a single team inspection. Parnas and Weiss' active design reviews (ADR) [17] and Knight and Myers' phased inspections (PI) <ref> [15] </ref> are also multiple-session inspection procedures. Each inspection is divided into several mini-inspections or "phases". ADR phases are independent, while PI phases are executed sequentially and all known defects are repaired after each phase.
Reference: [16] <author> K.E. Martersteck and A.E. Spencer. </author> <title> Introduction to the 5ESS(TM) switching system. </title> <journal> AT&T Technical Journal, </journal> <volume> 64(6 part </volume> 2):1305-1314, July-August 1985. 
Reference-contexts: However, this argument is simplistic for example, it doesn't consider the powerfully negative effect inspections have on schedule. We have observed that a typical release of AT&T's 5ESS R fl switch <ref> [16] </ref> ( .5M lines of added and changed code per release on a base of 5M lines) can require roughly 1500 inspections, each with four, five or even fl This work is supported in part by a National Science Foundation Faculty Early Career Development Award, CCR-9501354. Mr.
Reference: [17] <author> Dave L. Parnas and David M. Weiss. </author> <title> Active design reviews: </title> <booktitle> principles and practices. In Proceedings of the 8th International Conference on Software Engineering, </booktitle> <pages> pages 215-222, </pages> <month> Aug. </month> <year> 1985. </year>
Reference-contexts: N-fold inspections will find more defects than regular inspections as long as the teams don't completely duplicate each other's work. However, they are far more expensive than a single team inspection. Parnas and Weiss' active design reviews (ADR) <ref> [17] </ref> and Knight and Myers' phased inspections (PI) [15] are also multiple-session inspection procedures. Each inspection is divided into several mini-inspections or "phases". ADR phases are independent, while PI phases are executed sequentially and all known defects are repaired after each phase.
Reference: [18] <author> Kenneth H. Pollock. </author> <title> Modeling capture, recapture, and removal statistics for estimation of demographic parameters for fish and wildlife populations: Past, present, and future. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 86(413) </volume> <pages> 225-238, </pages> <month> March </month> <year> 1991. </year>
Reference: [19] <author> Adam A. Porter and Lawrence G. Votta. </author> <title> An experiment to assess different defect detection methods for software requirements inspections. </title> <booktitle> In Sixteenth International Conference on Software Engineering, </booktitle> <address> Sorrento, Italy, </address> <month> May </month> <year> 1994. </year> <month> 34 </month>
Reference-contexts: Humphrey [11] claims that the percentage of defects first discovered at the collection meeting ("meeting gain rate") averages about 25%. In an industrial case study of 50 design inspections, Votta [25] found far lower meeting gain rates (about 5%). Porter et al. <ref> [19] </ref> conducted a controlled experiment in which graduate students in computer science inspected several requirements specifications. Their results show meeting gain rates consistent with Votta's. They also show that these gains are offset by "meeting losses" (defects first discovered during preparation but never reported at the collection meeting). <p> For researchers this suggests that developing better defect detection techniques may be much more important than any of the organizational issues discussed in this article <ref> [19] </ref> . Meeting Gains. Only 30% of defects were meeting gains. One implication of this result is that it may be worthwhile to explore meeting-less inspections. For example, 2sX2pN inspections are about 33% more effective than 1sX4p inspections.
Reference: [20] <author> Glen W. Russel. </author> <title> Experience with inspections in ultralarge-scale developments. </title> <journal> IEEE Software, </journal> <volume> 8(1) </volume> <pages> 25-31, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: They are then sent to the artifact's author for repair. Under some conditions the entire process may be repeated one or more times. Many articles have been written about inspections. Most, however, are case studies describing their successful use <ref> [9, 10, 23, 20, 27, 14, 2] </ref> . Few critically analyze inspections or rigorously evaluate alternative inspection approaches.
Reference: [21] <author> G. Michael Schnieder, Johnny Martin, and W. T. Tsai. </author> <title> An experimental study of fault detection in user requirements. </title> <journal> ACM Trans. on Software Engineering and Methodology, </journal> <volume> 1(2) </volume> <pages> 188-204, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: This pushes meeting dates farther and farther into the future, increasing the development interval. [1] 2 flawed. But some authors have argued that multiple session inspections might be more effective. Tsai et al. <ref> [21] </ref> developed the N-fold inspection process, in which N teams each carry out independent inspections of the entire artifact. The results of each inspection are collated by a single moderator, who removes duplicate defect reports.
Reference: [22] <author> Sidney Siegel and Jr. N. John Castellan. </author> <title> Nonparametric Statistics For the Behavioral Sciences. </title> <publisher> McGraw-Hill Inc., </publisher> <address> New York, NY, </address> <note> second edition, </note> <year> 1988. </year>
Reference: [23] <author> T. A. Thayer, M. Lipow, and E. C. Nelson. </author> <title> Software reliability, a study of large project reality, </title> <booktitle> volume 2 of TRW series of Software Technology. </booktitle> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1978. </year>
Reference-contexts: They are then sent to the artifact's author for repair. Under some conditions the entire process may be repeated one or more times. Many articles have been written about inspections. Most, however, are case studies describing their successful use <ref> [9, 10, 23, 20, 27, 14, 2] </ref> . Few critically analyze inspections or rigorously evaluate alternative inspection approaches.
Reference: [24] <author> Scott A. Vander Wiel and Lawrence G. Votta. </author> <title> Assessing software design using capture-recapture methods. </title> <journal> IEEE Trans. Software Eng., </journal> <volume> SE-19:1045-1054, </volume> <month> November </month> <year> 1993. </year>
Reference: [25] <author> Lawrence G. Votta. </author> <booktitle> Does every inspection need a meeting? In Proceedings of ACM SIGSOFT '93 Symposium on Foundations of Software Engineering, </booktitle> <pages> pages 107-114. </pages> <institution> Association for Computing Machinery, </institution> <month> December </month> <year> 1993. </year>
Reference-contexts: Humphrey [11] claims that the percentage of defects first discovered at the collection meeting ("meeting gain rate") averages about 25%. In an industrial case study of 50 design inspections, Votta <ref> [25] </ref> found far lower meeting gain rates (about 5%). Porter et al. [19] conducted a controlled experiment in which graduate students in computer science inspected several requirements specifications. Their results show meeting gain rates consistent with Votta's. <p> For example, 2sX2pN inspections are about 33% more effective than 1sX4p inspections. Without a collection meeting 2sX2pN inspections would still be more effective, but might require less total effort and have a shorter interval. These meeting gain rates are higher than those reported by Votta <ref> [25] </ref> (5%). Since meetings without meeting gains are a large, unnecessary expense, it's important for researchers to better understand this issue. Also, it is extremely important that contradictory findings be examined and resolved.
Reference: [26] <author> Alexander L. Wolf and David S. Rosenblum. </author> <title> A study in software process data capture and analysis. </title> <booktitle> In Proceedings of the Second International Conference on Software Process, </booktitle> <pages> pages 115-124, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: In order to measure inspection interval and its various subintervals, we devised an inspection time model based on visible inspection events <ref> [26] </ref> .
Reference: [27] <author> E. Yourdon. </author> <title> Structured Walkthroughs. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood, NJ, </address> <year> 1979. </year> <month> 35 </month>
Reference-contexts: They are then sent to the artifact's author for repair. Under some conditions the entire process may be repeated one or more times. Many articles have been written about inspections. Most, however, are case studies describing their successful use <ref> [9, 10, 23, 20, 27, 14, 2] </ref> . Few critically analyze inspections or rigorously evaluate alternative inspection approaches.
References-found: 27

