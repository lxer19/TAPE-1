URL: ftp://hpsl.cs.umd.edu/pub/papers/ipps97-MC.ps.Z
Refering-URL: http://www.cs.umd.edu/projects/hpsl/papers.brandnew/LocalResources/tech-10-23.htm
Root-URL: 
Email: fedjlali,als,saltzg@cs.umd.edu  
Title: Interoperability of Data Parallel Runtime Libraries  
Author: Guy Edjlali, Alan Sussman and Joel Saltz 
Address: College Park, MD 20742  
Affiliation: Department of Computer Science University of Maryland  
Abstract: This paper describes a framework for providing the ability to use multiple specialized data parallel libraries and/or languages within a single application. The ability to use multiple libraries is required in many application areas, such as multidisciplinary complex physical simulations and remote sensing image database applications. An application can consist of one program or multiple programs that use different libraries to parallelize operations on distributed data structures. The framework is embodied in a runtime library called Meta-Chaos that has been used to exchange data between data parallel programs written using High Performance Fortran, the Chaos and Multiblock Parti libraries developed at Maryland for handling various types of unstructured problems, and the runtime library for pC++, a data parallel version of C++ from Indiana University. Experimental results show that Meta-Chaos is able to move data between libraries efficiently, and that Meta-Chaos provides effective support for complex applications. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Agrawal, A. Sussman, and J. Saltz. </author> <title> An integrated runtime and compile-time approach for parallelizing structured and block structured applications. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 6(7) </volume> <pages> 747-754, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: We call our runtime library Meta-Chaos. An implementation currently runs on the IBM SP2 multicomputer, an eight-node Digital Alpha cluster of SMPs and a cluster of workstations. The libraries and languages currently supported by Meta-Chaos include Fortran, C, HPF [12] , pC++ [3], Multiblock Parti <ref> [1] </ref> and Chaos [11]. Our results indicate that this approach is feasible and that the overhead of our general approach is acceptable. Our results also show that the data parallel library extensions required by the meta-library are not difficult to implement, even by someone other than the implementor of Meta-Chaos. <p> Hence the library builder must specify the Region type for a given library, so that the meta-library will be able to map elements in the source data parallel library to elements in the destination library. For example, High Performance Fortran (HPF) [12] and Multiblock Parti <ref> [1] </ref> utilize arrays as their main distributed data structure; therefore the Region type for them is a regularly distributed array section. Chaos [11] employs irregularly accessed arrays as its main distributed data structure, either through irregular data distributions or accesses through indirection arrays. <p> This scenario would occur, for example, in a multiblock computational fluid dynamics code, where inter-block boundaries must be updated at every time-step <ref> [1] </ref>. The copy operation can be completely expressed using Multiblock Parti functions, for both building the communication schedule and moving the data.
Reference: [2] <author> A. Birrell and B. Nelson. </author> <title> Implementing remote procedure calls. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(1) </volume> <pages> 39-59, </pages> <month> Feb. </month> <year> 1984. </year>
Reference-contexts: Such programs often use low level communication calls (e.g., sockets) to move data between separate address spaces. Building manageable distributed applications with these low level communication calls can be difficult. Therefore many distributed applications instead use the Remote Procedure Call (RPC) <ref> [2] </ref> paradigm to hide many communication details from the application programmer. RPC extends the notion of a procedure call in a sequential program by allowing the transfer of both data (parameters and return values) and control over a network from one process to another.
Reference: [3] <author> F. Bodin, P. Beckman, D. Gannon, S. Narayana, and S. X. Yang. </author> <title> Distributed pC++: Basic ideas for an object parallel language. </title> <journal> Scientific Programming, </journal> <volume> 2(3), </volume> <month> Fall </month> <year> 1993. </year>
Reference-contexts: Many parallel programming paradigms have been developed, with the most important one for large scale scientific applications being data parallelism. Data parallel applications can currently be written using a high level language, for example High Performance Fortran (HPF) [12] or pC++ <ref> [3] </ref>. Data parallel programs can also be written using a sequential programming language and runtime libraries for performing communication. <p> We call our runtime library Meta-Chaos. An implementation currently runs on the IBM SP2 multicomputer, an eight-node Digital Alpha cluster of SMPs and a cluster of workstations. The libraries and languages currently supported by Meta-Chaos include Fortran, C, HPF [12] , pC++ <ref> [3] </ref>, Multiblock Parti [1] and Chaos [11]. Our results indicate that this approach is feasible and that the overhead of our general approach is acceptable. <p> So far, implementations for several data parallel libraries have been completed, including the High Performance Fortran runtime library, the Maryland Chaos and Multiblock Parti libraries for various types of irregular computations, and the pC++ <ref> [3] </ref> runtime library, Tulip, from Indiana University. The pC++ implementation of the required functions was performed by the pC++ group at Indiana in a few days, using MPI as the underlying message passing layer, which shows that providing the required interface is not too onerous. 4.2. <p> The only constraint is that each library that supports non-array distributed data structures provide a method for linearizing the data structures it supports. For example, Meta-Chaos could be used to allow two C++ programs parallelized using pC++ constructs <ref> [3] </ref>, each containing compatible pointer-based data structures, to exchange parts of the data structures. More complex scenarios, with programs parallelized using different libraries and exchanging data between non-array data structures, can also be supported. 5.
Reference: [4] <author> K. M. Chandy, I. Foster, K. Kennedy, C. Koelbel, and C.-W. Tseng. </author> <title> Integrated support for task and data parallelism. </title> <journal> Journal of Supercomputing Applications, </journal> <volume> 8(2), </volume> <year> 1994. </year> <note> Also available as CRPC Technical Report CRPC-TR93430. </note>
Reference-contexts: Fx [17] adds compiler directives to HPF to specify task parallelism. Opus [10] is a set of HPF extensions that provides a mechanism for communication and synchronization through a shared data abstraction (SDA). Fortran M <ref> [4] </ref> extends Fortran77 for task parallel computations, and also introduces several data distribution statements. Braid [5] introduces data parallel extensions to the Mentat distributed object programming language.
Reference: [5] <author> E.West and A. Grishaw. </author> <title> Braid: Integrating Task and Data Parallelism. </title> <booktitle> In Proceedings of the Fifth Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 211-219. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> Feb. </month> <year> 1995. </year>
Reference-contexts: Opus [10] is a set of HPF extensions that provides a mechanism for communication and synchronization through a shared data abstraction (SDA). Fortran M [4] extends Fortran77 for task parallel computations, and also introduces several data distribution statements. Braid <ref> [5] </ref> introduces data parallel extensions to the Mentat distributed object programming language. Integrating task and data parallelism within one language is an active area of research, but does not address the problem that there are many existing parallel codes that have been written using different data parallel libraries.
Reference: [6] <author> I. Foster, D. Kohr, R. Krishnaiyer, and A. Choudary. </author> <title> Double standards: Bringing task parallelisn to HPF via the message passing interface. </title> <booktitle> In Proceedings Supercomputing '96. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <month> Nov. </month> <year> 1996. </year>
Reference-contexts: Related work The software tool that provides the closest functionality to that of Meta-Chaos is HPF/MPI <ref> [6] </ref>. The HPF/MPI library extends the MPI point-to-point message passing functions to allow multiple HPF programs to communicate using MPI calls. Communication between two HPF programs using either Meta-Chaos or HPF/MPI woud be written the same way, except for some syntactic differences.
Reference: [7] <author> A. Geist, A. Beguelin, J. Dongarra, W. Jiang, R. Manchek, and V. Sunderam. </author> <title> PVM 3 user's guide and reference manual. </title> <type> Technical Report ORNL/TM-12187, </type> <institution> Oak Ridge National Laboratory, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: Data parallel programs can also be written using a sequential programming language and runtime libraries for performing communication. These libraries can be low level communication libraries such as MPI [16] or PVM <ref> [7] </ref>, or application specific runtime libraries that encapsulate communication into higher level functions, such as Chaos [11] or LPARX [13].
Reference: [8] <author> U. Geuder, M. Hardtner, B. Worner, and R. </author> <title> Zin. Scalable execution control of grid-based scientific applications on parallel systems. </title> <booktitle> In Proceedings of the Scalable High Performance Computing Conference (SHPCC-94). </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1994. </year>
Reference-contexts: Integrating task and data parallelism within one language is an active area of research, but does not address the problem that there are many existing parallel codes that have been written using different data parallel libraries. The existence of many such data parallel libraries <ref> [8, 9, 11, 13, 14] </ref>, and their related applications, provides strong support for the claim that no single library or language is sufficient for all potential applications.
Reference: [9] <author> W. Gropp and B. Smith. </author> <title> Scalable, extensible, and portable numerical libraries. </title> <booktitle> In Proceedings of the 1994 Scalable Parallel Libraries Conference, </booktitle> <pages> pages 60-67. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1994. </year>
Reference-contexts: Integrating task and data parallelism within one language is an active area of research, but does not address the problem that there are many existing parallel codes that have been written using different data parallel libraries. The existence of many such data parallel libraries <ref> [8, 9, 11, 13, 14] </ref>, and their related applications, provides strong support for the claim that no single library or language is sufficient for all potential applications.
Reference: [10] <author> M. Haines, B. Hess, P. Mehrotra, J. V. Rosendale, and H. Zima. </author> <title> Runtime Support for Data Parallel Tasks. </title> <booktitle> In Proceedings of the Fifth Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 432-439. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> Feb. </month> <year> 1995. </year>
Reference-contexts: Several research efforts have been working on the enhancement of data parallel languages to integrate data parallelism and task parallelism. Fx [17] adds compiler directives to HPF to specify task parallelism. Opus <ref> [10] </ref> is a set of HPF extensions that provides a mechanism for communication and synchronization through a shared data abstraction (SDA). Fortran M [4] extends Fortran77 for task parallel computations, and also introduces several data distribution statements. Braid [5] introduces data parallel extensions to the Mentat distributed object programming language.
Reference: [11] <author> Y.-S. Hwang, B. Moon, S. D. Sharma, R. Ponnusamy, R. Das, and J. H. Saltz. </author> <title> Runtime and language support for compiling adaptive irregular programs. </title> <journal> Software-Practice and Experience, </journal> <volume> 25(6) </volume> <pages> 597-621, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Data parallel programs can also be written using a sequential programming language and runtime libraries for performing communication. These libraries can be low level communication libraries such as MPI [16] or PVM [7], or application specific runtime libraries that encapsulate communication into higher level functions, such as Chaos <ref> [11] </ref> or LPARX [13]. <p> We call our runtime library Meta-Chaos. An implementation currently runs on the IBM SP2 multicomputer, an eight-node Digital Alpha cluster of SMPs and a cluster of workstations. The libraries and languages currently supported by Meta-Chaos include Fortran, C, HPF [12] , pC++ [3], Multiblock Parti [1] and Chaos <ref> [11] </ref>. Our results indicate that this approach is feasible and that the overhead of our general approach is acceptable. Our results also show that the data parallel library extensions required by the meta-library are not difficult to implement, even by someone other than the implementor of Meta-Chaos. <p> For example, High Performance Fortran (HPF) [12] and Multiblock Parti [1] utilize arrays as their main distributed data structure; therefore the Region type for them is a regularly distributed array section. Chaos <ref> [11] </ref> employs irregularly accessed arrays as its main distributed data structure, either through irregular data distributions or accesses through indirection arrays. For Chaos the Region type would be a set of global array indices. A Region type is dependent on the requirements of the data parallel library. <p> Integrating task and data parallelism within one language is an active area of research, but does not address the problem that there are many existing parallel codes that have been written using different data parallel libraries. The existence of many such data parallel libraries <ref> [8, 9, 11, 13, 14] </ref>, and their related applications, provides strong support for the claim that no single library or language is sufficient for all potential applications.
Reference: [12] <author> C. Koelbel, D. Loveman, R. Schreiber, G. Steele, Jr., and M. Zosel. </author> <title> The High Performance Fortran Handbook. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: They are considered difficult to write, to maintain and to modify. Many parallel programming paradigms have been developed, with the most important one for large scale scientific applications being data parallelism. Data parallel applications can currently be written using a high level language, for example High Performance Fortran (HPF) <ref> [12] </ref> or pC++ [3]. Data parallel programs can also be written using a sequential programming language and runtime libraries for performing communication. <p> We call our runtime library Meta-Chaos. An implementation currently runs on the IBM SP2 multicomputer, an eight-node Digital Alpha cluster of SMPs and a cluster of workstations. The libraries and languages currently supported by Meta-Chaos include Fortran, C, HPF <ref> [12] </ref> , pC++ [3], Multiblock Parti [1] and Chaos [11]. Our results indicate that this approach is feasible and that the overhead of our general approach is acceptable. <p> Hence the library builder must specify the Region type for a given library, so that the meta-library will be able to map elements in the source data parallel library to elements in the destination library. For example, High Performance Fortran (HPF) <ref> [12] </ref> and Multiblock Parti [1] utilize arrays as their main distributed data structure; therefore the Region type for them is a regularly distributed array section. Chaos [11] employs irregularly accessed arrays as its main distributed data structure, either through irregular data distributions or accesses through indirection arrays.
Reference: [13] <author> S. Kohn and S. Baden. </author> <title> A robust parallel programming model for dynamic non-uniform scientific computations. </title> <booktitle> In Proceedings of the Scalable High Performance Computing Conference (SHPCC-94), </booktitle> <pages> pages 509-517. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> May </month> <year> 1994. </year>
Reference-contexts: These libraries can be low level communication libraries such as MPI [16] or PVM [7], or application specific runtime libraries that encapsulate communication into higher level functions, such as Chaos [11] or LPARX <ref> [13] </ref>. However, inter-application communication to allow multiple data parallel programs to cooperate to solve a single problem is rare, because such programs are difficult to write and there are few tools fl This research was supportedby NASA undergrant #NAG-1-1485 (ARPA Project Number 8874) and by ARPA under grant #F19628-94-C-0057. <p> Integrating task and data parallelism within one language is an active area of research, but does not address the problem that there are many existing parallel codes that have been written using different data parallel libraries. The existence of many such data parallel libraries <ref> [8, 9, 11, 13, 14] </ref>, and their related applications, provides strong support for the claim that no single library or language is sufficient for all potential applications.
Reference: [14] <author> A. Lain and P. Banerjee. </author> <title> Exploiting spatial regularity in irregular iterative applications. </title> <booktitle> In Proceedings of the Ninth International Parallel Processing Symposium, </booktitle> <pages> pages 820-826. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> Apr. </month> <year> 1995. </year>
Reference-contexts: Integrating task and data parallelism within one language is an active area of research, but does not address the problem that there are many existing parallel codes that have been written using different data parallel libraries. The existence of many such data parallel libraries <ref> [8, 9, 11, 13, 14] </ref>, and their related applications, provides strong support for the claim that no single library or language is sufficient for all potential applications.
Reference: [15] <author> Object Management Group. </author> <title> The Common Object Request Broker: Architecture and Specification, </title> <year> 1995. </year>
Reference-contexts: Two processes are involved in the RPC call: the client and the server. In addition, the CORBA object model <ref> [15] </ref> provides RPC-like capability for a distributed object model. RPC provides a simple, efficient programming model for heterogeneous sequential applications. <p> We plan to apply the framework-based approach to new application areas, and are currently studying ways to incorporate distributed data parallel objects into the CORBA <ref> [15] </ref> object model, so that data parallel programs could interoperate with distributed object systems. Meta-Chaos could be used as the underlying mechanism for such an extension.
Reference: [16] <author> M. Snir, S. W. Otto, S. Huss-Lederman, D. W. Walker, and J. Don-garra. </author> <title> MPI: The Complete Reference. Scientific and Engineering Computation Series. </title> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: Data parallel programs can also be written using a sequential programming language and runtime libraries for performing communication. These libraries can be low level communication libraries such as MPI <ref> [16] </ref> or PVM [7], or application specific runtime libraries that encapsulate communication into higher level functions, such as Chaos [11] or LPARX [13]. <p> In addition, suppose the array is distributed on the server in a block-cyclic fashion, to optimize the server computation. Because of the block-cyclic distribution of data on the server, the client process must communicate with every server process. This operation requires a collective communication operation <ref> [16] </ref>. The client must determine which parts of the matrix are going to be sent to each of the processes in the server. Similarly, each server process must determine which part of the array it will receive from the client, and the order in which the array elements will arrive.
Reference: [17] <author> J. Subhlok, J. M. Stichnoth, D. R. O'Hallaron, and T. Gross. </author> <title> Exploiting task and data parallelism on a multicomputer. </title> <booktitle> In Proceedings of the Fourth ACM SIGPLAN Symposium on Principles & Practice of Parallel Programming (PPOPP), </booktitle> <pages> pages 13-22, </pages> <month> May </month> <year> 1993. </year> <journal> ACM SIGPLAN Notices, </journal> <volume> Vol. 28, No. 7. </volume> <pages> 9 </pages>
Reference-contexts: Much effort has recently gone into languages and runtime libraries for combining task and data parallelism. For example, the data parallel language Fx <ref> [17] </ref> extended HPF to support task parallelism. However, none of that work addressed the problem of allowing programs written using different data parallel libraries or languages to inter-operate. <p> As HPF/MPI and other previous work has shown, integrating task and data parallelism can present significant advantages in both performance and ease of programming. Several research efforts have been working on the enhancement of data parallel languages to integrate data parallelism and task parallelism. Fx <ref> [17] </ref> adds compiler directives to HPF to specify task parallelism. Opus [10] is a set of HPF extensions that provides a mechanism for communication and synchronization through a shared data abstraction (SDA). Fortran M [4] extends Fortran77 for task parallel computations, and also introduces several data distribution statements.
References-found: 17

