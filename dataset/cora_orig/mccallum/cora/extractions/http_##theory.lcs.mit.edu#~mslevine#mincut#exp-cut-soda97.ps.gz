URL: http://theory.lcs.mit.edu/~mslevine/mincut/exp-cut-soda97.ps.gz
Refering-URL: http://theory.lcs.mit.edu/~mslevine/mincut/index.html
Root-URL: 
Email: chekuri@theory.stanford.edu.  avg@research.nj.nec.com  karger@theory.lcs.mit.edu.  mslevine@theory.lcs.mit.edu.  cliff@cs.dartmouth.edu.  
Title: Experimental Study of Minimum Cut Algorithms  
Author: Chandra S. Chekuri Andrew V. Goldberg David R. Karger Matthew S. Levine Cliff Stein 
Note: Supported by NSF Award CCR-9357849, with matching funds from IBM, Mitsubishi, Schlumberger Foundation, Shell Foundation, and Xerox Corporation.  Research partly supported by ARPA contract N00014-95-1-1246.  Research partly supported by a grant from the World Wide Web Consortium. Some of this work was done while visiting the second author  Research partly supported by NSF Award CCR-9308701, a Walter Burke Research Initiation Award and a Dartmouth College Research Initiation Award. Some of this work was done while visiting the second author at NEC, and while visiting Stanford University.  
Address: Stanford, CA 94305,  Princeton, NJ 08540,  MA 02139,  MA 02139,  Hanover, NH, 03755,  
Affiliation: Computer Science Department, Stanford University,  NEC Research Institute,  Laboratory for Computer Science, MIT, Cambridge,  Laboratory for Computer Science, MIT, Cambridge,  at NEC. Department of Computer Science, Dartmouth College,  
Abstract: Recently, several new algorithms have been developed for the minimum cut problem. These algorithms are very different from the earlier ones and from each other and substantially improve the worst-case time bounds for the problem. In this paper, we conduct experimental evaluation the relative performance of these algorithms. In the process, we develop heuristics and data structures that substantially improve the practical performance of the algorithms. We also develop problem families for testing minimum cut algorithms. Our work leads to a better understanding of the practical performance of minimum cut algorithms and produces very efficient codes for the problem. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. K. Ahuja, J. B. Orlin, and R. E. Tarjan. </author> <title> Improved Time Bounds for the Maximum Flow Problem. </title> <journal> SIAM J. Comput., </journal> <volume> 18 </volume> <pages> 939-954, </pages> <year> 1989. </year>
Reference-contexts: The classical Gomory-Hu algorithm [14] solves the minimum cut problem using n 1 minimum s-t cut computations. The fastest current algorithms for the s-t cut problem <ref> [1, 6, 7, 13, 21] </ref> use flow techniques, in particular the push-relabel method [13], and run in !(nm) time.
Reference: [2] <author> R. J. Anderson and J. C. Setubal. </author> <title> Goldberg's Algorithm for the Maximum Flow in Perspective: a Computational Study. </title> <editor> In D. S. Johnson and C. C. McGeoch, editors, </editor> <title> Network Flows and Matching: </title> <booktitle> First DIMACS Implementation Challenge, </booktitle> <pages> pages 1-18. </pages> <publisher> AMS, </publisher> <year> 1993. </year>
Reference-contexts: As a result, our code is always competitive with hybrid, and sometimes outperforms it by a wide margin. Implementations of the push-relabel method for the maximum flow problem have been well-studied, e.g. <ref> [2, 8, 10, 11, 24] </ref>. A maximum flow code of Cherkassky and Goldberg [8] was the starting point of our implementation of ho. The implementation uses the heuristics used in the maximum flow code global update and gap relabeling.
Reference: [3] <author> D. L. Applegate and W. J. Cook. </author> <type> Personal communication. </type> <year> 1996. </year>
Reference-contexts: This problem has many applications, including network reliability theory [18, 27], information retrieval [4], compilers for parallel languages [5], and as a subroutine in cutting-plane algorithms for the Traveling Salesman problem (TSP) <ref> [3] </ref>. The problem of finding a minimum capacity cut between two specified vertices, s and t, is called the minimum s-t cut problem, and is closely related to the minimum cut problem. The classical Gomory-Hu algorithm [14] solves the minimum cut problem using n 1 minimum s-t cut computations. <p> In order to perform meaningful comparisons, we develop problem generators and test families for evaluating and comparing performance of the minimum cut codes. We also run and analyze our algorithms on data that arises during the TSP algorithm of Applegate and Cook <ref> [3] </ref>. Our problem families are carefully selected and proved very useful for comparing and tuning minimum cut codes. The first efficient implementation of a minimum cut algorithm that we are aware of is due to Padberg and Rinaldi [25]. <p> In our final experiment, we used five different problem generators, and for each generator generated several different problem families, for a total of twelve different families. We also did experiments on minimum cut problems that arise in the solution of large TSP problems via cutting plane algorithms <ref> [3] </ref>. One of our generators, noigen, is an implementation of the generator of [23]. The remaining generators were designed and implemented from scratch. One of the contributions of our work is to introduce this useful collection of generators than can be used by others to test minimum cut algorithms.
Reference: [4] <author> R. A. Botafogo. </author> <title> Cluster Analysis for Hypertext Systems. </title> <booktitle> In Proc. of the 16-th Annual ACM SIGIR Conference of Res. and Dev. in Info. Retrieval, </booktitle> <pages> pages 116-125, </pages> <year> 1993. </year>
Reference-contexts: This problem has many applications, including network reliability theory [18, 27], information retrieval <ref> [4] </ref>, compilers for parallel languages [5], and as a subroutine in cutting-plane algorithms for the Traveling Salesman problem (TSP) [3].
Reference: [5] <author> S. Chatterjee, J. R. Gilbert, R. Schreiber, and T. J. She*er. </author> <title> Array Distribution in Data-Parallel Programs. </title> <booktitle> In Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 76-91. </pages> <booktitle> Lecture Notes in Computer Science series, </booktitle> <volume> vol. 896, </volume> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: This problem has many applications, including network reliability theory [18, 27], information retrieval [4], compilers for parallel languages <ref> [5] </ref>, and as a subroutine in cutting-plane algorithms for the Traveling Salesman problem (TSP) [3]. The problem of finding a minimum capacity cut between two specified vertices, s and t, is called the minimum s-t cut problem, and is closely related to the minimum cut problem.
Reference: [6] <author> J. Cheriyan and T. Hagerup. </author> <title> A randomized maximum flow algorithm. </title> <booktitle> In Proc. FOCS 30, </booktitle> <pages> pages 118-123, </pages> <year> 1989. </year>
Reference-contexts: The classical Gomory-Hu algorithm [14] solves the minimum cut problem using n 1 minimum s-t cut computations. The fastest current algorithms for the s-t cut problem <ref> [1, 6, 7, 13, 21] </ref> use flow techniques, in particular the push-relabel method [13], and run in !(nm) time.
Reference: [7] <author> J. Cheriyan, T. Hagerup, and K. Mehlhorn. </author> <title> Can a Maximum Flow be Computed in o(nm) Time? In Proc. </title> <booktitle> ICALP, </booktitle> <year> 1990. </year>
Reference-contexts: The classical Gomory-Hu algorithm [14] solves the minimum cut problem using n 1 minimum s-t cut computations. The fastest current algorithms for the s-t cut problem <ref> [1, 6, 7, 13, 21] </ref> use flow techniques, in particular the push-relabel method [13], and run in !(nm) time.
Reference: [8] <author> B. V. Cherkassky and A. V. Goldberg. </author> <title> On Implementing Push-Relabel Method for the Maximum Flow Problem. </title> <type> Technical Report STAN-CS-94-1523, </type> <institution> Department of Computer Science, Stanford University, </institution> <year> 1994. </year>
Reference-contexts: As a result, our code is always competitive with hybrid, and sometimes outperforms it by a wide margin. Implementations of the push-relabel method for the maximum flow problem have been well-studied, e.g. <ref> [2, 8, 10, 11, 24] </ref>. A maximum flow code of Cherkassky and Goldberg [8] was the starting point of our implementation of ho. The implementation uses the heuristics used in the maximum flow code global update and gap relabeling. <p> As a result, our code is always competitive with hybrid, and sometimes outperforms it by a wide margin. Implementations of the push-relabel method for the maximum flow problem have been well-studied, e.g. [2, 8, 10, 11, 24]. A maximum flow code of Cherkassky and Goldberg <ref> [8] </ref> was the starting point of our implementation of ho. The implementation uses the heuristics used in the maximum flow code global update and gap relabeling. In addition, we use the graph contraction data structures mentioned above, the PR heuristics, and several new heuristics. <p> The starting point for our implementation, described in this section, was a maximum flow code of <ref> [8] </ref>. We assume familiarity with these papers. 5.1 Implementation Details Graph representation.We use graph data structures similar to those used in ni, with additional fields to support variables needs for preflow-push algorithms, such as flow values on edges and distance labels and excess at nodes.
Reference: [9] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1990. </year>
Reference-contexts: An alternative way to contract an edge fu; vg is to use set-union contraction. In this implementation, each node in the current graph corresponds to a set of vertices of the input graph. The sets are represented using the disjoint-set union data structure <ref> [9] </ref>. An edge fu; vg is contracted, in constant time, by forming a union of of the vertex sets corresponding to u and v and appending the adjacency list of v to that of u. The advantage of the set-union contraction is in efficiency of the contraction operation.
Reference: [10] <author> U. Derigs and W. Meier. </author> <title> Implementing Gold-berg's Max-Flow Algorithm | A Computational Investigation. </title> <journal> ZOR | Methods and Models of Operations Research, </journal> <volume> 33 </volume> <pages> 383-403, </pages> <year> 1989. </year>
Reference-contexts: As a result, our code is always competitive with hybrid, and sometimes outperforms it by a wide margin. Implementations of the push-relabel method for the maximum flow problem have been well-studied, e.g. <ref> [2, 8, 10, 11, 24] </ref>. A maximum flow code of Cherkassky and Goldberg [8] was the starting point of our implementation of ho. The implementation uses the heuristics used in the maximum flow code global update and gap relabeling.
Reference: [11] <author> U. Derigs and W. Meier. </author> <title> An Evaluation of Algorithmic Refinements and Proper Data-Structures for the Preflow-Push Approach for Maximum Flow. </title> <booktitle> In ASI Series on Computer and System Sciences, </booktitle> <volume> volume 8, </volume> <pages> pages 209-223. NATO, </pages> <year> 1992. </year>
Reference-contexts: As a result, our code is always competitive with hybrid, and sometimes outperforms it by a wide margin. Implementations of the push-relabel method for the maximum flow problem have been well-studied, e.g. <ref> [2, 8, 10, 11, 24] </ref>. A maximum flow code of Cherkassky and Goldberg [8] was the starting point of our implementation of ho. The implementation uses the heuristics used in the maximum flow code global update and gap relabeling.
Reference: [12] <author> H. N. Gabow. </author> <title> A Matroid Approach to Finding Edge Connectivity and Packing Arborescences. </title> <journal> J. Comp. and Syst. Sci., </journal> <volume> 50 </volume> <pages> 259-273, </pages> <year> 1995. </year>
Reference-contexts: This leaves open many implementation options. We discuss the major ones below. Packing spanning trees.Karger suggests two entirely different ways to pack spanning trees. We chose to use Gabow's algorithm <ref> [12] </ref>. It would be interesting to try the alternative ([26]) too. Checking trees for 2-respecting cuts.

Reference: [14] <author> R. E. Gomory and T. C. Hu. </author> <title> Multi-terminal network flows. </title> <journal> J. SIAM, </journal> <volume> 9 </volume> <pages> 551-570, </pages> <year> 1961. </year>
Reference-contexts: The problem of finding a minimum capacity cut between two specified vertices, s and t, is called the minimum s-t cut problem, and is closely related to the minimum cut problem. The classical Gomory-Hu algorithm <ref> [14] </ref> solves the minimum cut problem using n 1 minimum s-t cut computations. The fastest current algorithms for the s-t cut problem [1, 6, 7, 13, 21] use flow techniques, in particular the push-relabel method [13], and run in !(nm) time. <p> Its disadvantages come from the parallel arcs and self-loops which remain in the graph and from the increased cost of finding the head node of an arc. Our algorithms will make use of both of these data structures at different times. 2.3 Gomory-Hu Algorithm Gomory and Hu <ref> [14] </ref> showed that a minimum cut can be computed in n 1 minimum s-t cut computations. The underlying idea is important for understanding other minimum cut algorithms. Consider a pair of distinct vertices s and t and a minimum s-t cut A.
Reference: [15] <author> J. Hao. </author> <title> A Faster Algorithm for Finding the Minimum Cut of a Graph. </title> <type> Unpublished manuscript, </type> <year> 1991. </year>
Reference-contexts: The fastest current algorithms for the s-t cut problem [1, 6, 7, 13, 21] use flow techniques, in particular the push-relabel method [13], and run in !(nm) time. For the minimum cut problem, Hao and Orlin <ref> [15, 16] </ref> have given an algorithm (ho), based on the push-relabel method, that shows how to perform all n 1 minimum s-t cuts in time asymptotically equal to that needed to perform one s-t minimum cut computation. This algorithm runs in O (nm log (n 2 =m)) time.
Reference: [16] <author> J. Hao and J. B. Orlin. </author> <title> A Faster Algorithm for Finding the Minimum Cut of a Graph. </title> <booktitle> In Proc. SODA 3, </booktitle> <pages> pages 165-174, </pages> <year> 1992. </year>
Reference-contexts: The fastest current algorithms for the s-t cut problem [1, 6, 7, 13, 21] use flow techniques, in particular the push-relabel method [13], and run in !(nm) time. For the minimum cut problem, Hao and Orlin <ref> [15, 16] </ref> have given an algorithm (ho), based on the push-relabel method, that shows how to perform all n 1 minimum s-t cuts in time asymptotically equal to that needed to perform one s-t minimum cut computation. This algorithm runs in O (nm log (n 2 =m)) time.
Reference: [17] <author> J. Hao and J. B. Orlin. </author> <title> A Faster Algorithm for Finding the Minimum Cut in a Directed Graph. </title> <journal> J. Algorithms, </journal> <volume> 17 </volume> <pages> 424-446, </pages> <year> 1994. </year>
Reference-contexts: Since the cost of each PR pass is linear, it is amortized by the cost of the preceding phase. 5 Hao-Orlin Algorithm Hao-Orlin algorithm <ref> [17] </ref> is based on the push-relabel method [13] for the maximum flow problem. The starting point for our implementation, described in this section, was a maximum flow code of [8]. <p> See the full paper for details. 5.2 Heuristics 5.2.1 Padberg-Rinaldi HeuristicsAs in all our algorithms, we apply PR preprocessing at the beginning. Our internal PR heuristic is based on the following fact that is easy to prove using <ref> [17] </ref>: If s is the source and the edge fs; wg passes one of the tests PR1, : : :, PR4, then we can saturate all arcs out of w, contract the edge, and continue. We use amortization to decide when to apply PR1 and PR2 to the source.
Reference: [18] <author> D. R. Karger. </author> <title> A randomized fully polynomial approximation scheme for the all terminal network reliability problem. </title> <booktitle> In Proc. STOC 27, </booktitle> <pages> pages 11-17, </pages> <year> 1995. </year>
Reference-contexts: 1 Introduction The minimum cut problem is the problem of partitioning the vertices of an n-vertex, m-edge weighted undirected graph into two sets so that the total weight of the set of edges with endpoints in different sets is minimized. This problem has many applications, including network reliability theory <ref> [18, 27] </ref>, information retrieval [4], compilers for parallel languages [5], and as a subroutine in cutting-plane algorithms for the Traveling Salesman problem (TSP) [3].
Reference: [19] <author> D. R. Karger. </author> <title> Minimum Cuts in Near-Linear Time. </title> <booktitle> In Proc. STOC 28, </booktitle> <pages> pages 56-63, </pages> <year> 1996. </year>
Reference-contexts: The algorithm of Nagamochi and Ibaraki [22] (ni) runs in O (n (m + n log n)) time. The algorithm of Karger and Stein [20] (ks) runs in O (n 2 log 3 n) expected time. Two closely related algorithms of Karger <ref> [19] </ref> (k) run in O (m log 3 n) and O (n 2 log n) expected time. These algorithms are based on new techniques which do not use flows. These algorithms do not extend to directed graphs, while the flow based algorithms, include ho, do. <p> In addition, we use the graph contraction data structures mentioned above, the PR heuristics, and several new heuristics. The Karger-Stein and Karger's algorithms are randomized. For these algorithms, we needed to develop somewhat different strategies for random edge selection than those that appeared in the original papers <ref> [20, 19] </ref>. These codes also benefit from the PR heuristics as well as new heuristics. We make significant progress in understanding practical performance of minimum cut algorithms and in establishing testing standards for future codes. Our study shows that no single algorithm dominates the others. <p> Therefore, we imagine that a new implementation of the code might use a "PR34-friendly" adjacency list data structure for preprocessing and then convert to our original representation for the actual Contraction Algorithm. See the full paper for details. 7 Karger's Algorithm Karger's algorithm is described in <ref> [19] </ref>. Karger's first finds a packing of spanning trees; then it examines the trees in the packing and for each tree finds the smallest cut that one or two tree edges. This leaves open many implementation options. We discuss the major ones below.
Reference: [20] <author> D. R. Karger and C. Stein. </author> <title> An ~ O(n 2 ) Algorithm for Minimum Cuts. </title> <booktitle> In Proc. STOC 25, </booktitle> <pages> pages 757-765, </pages> <year> 1993. </year>
Reference-contexts: The algorithm of Nagamochi and Ibaraki [22] (ni) runs in O (n (m + n log n)) time. The algorithm of Karger and Stein <ref> [20] </ref> (ks) runs in O (n 2 log 3 n) expected time. Two closely related algorithms of Karger [19] (k) run in O (m log 3 n) and O (n 2 log n) expected time. These algorithms are based on new techniques which do not use flows. <p> In addition, we use the graph contraction data structures mentioned above, the PR heuristics, and several new heuristics. The Karger-Stein and Karger's algorithms are randomized. For these algorithms, we needed to develop somewhat different strategies for random edge selection than those that appeared in the original papers <ref> [20, 19] </ref>. These codes also benefit from the PR heuristics as well as new heuristics. We make significant progress in understanding practical performance of minimum cut algorithms and in establishing testing standards for future codes. Our study shows that no single algorithm dominates the others. <p> Note that v can be either regular or frozen. The correctness proof for this heuristic is straight-forward. We call this heuristic excess detection. 6 Karger-Stein Algorithm The full description of the recursive contraction algorithm of Karger and Stein appears in <ref> [20] </ref>. The version we implemented differs slightly from the recursive contraction algorithm described in [20]. In that algorithm we repeatedly select and contract one edge at a time until the number of graph nodes is reduced to n= p 2. <p> The correctness proof for this heuristic is straight-forward. We call this heuristic excess detection. 6 Karger-Stein Algorithm The full description of the recursive contraction algorithm of Karger and Stein appears in <ref> [20] </ref>. The version we implemented differs slightly from the recursive contraction algorithm described in [20]. In that algorithm we repeatedly select and contract one edge at a time until the number of graph nodes is reduced to n= p 2. In our implementation, at each contraction phase we mark each edge fu; vg with probability 12 w (u;v)=W and contract the marked edges. <p> We conjecture that the new algorithm's performance is in fact equal to that of the old one's, but this remains to be proved. Our new implementation requires an analysis somewhat different from that of <ref> [20] </ref>. <p> We found that it is much wiser to randomly choose and contract sets of edges, as described above, rather than choosing and contracting the edges one by one, as is done in <ref> [20] </ref>. We needed to use an exponential distribution to sample each edge with probability exponential in its weight; this was not a significant part of the running time. It should be noted that our algorithm as stated makes no use of adjacency lists.
Reference: [21] <author> V. King, S. Rao, and R. Tarjan. </author> <title> A Faster Deterministic Maximum Flow Algorithm. </title> <journal> J. Algorithms, </journal> <volume> 17 </volume> <pages> 447-474, </pages> <year> 1994. </year>
Reference-contexts: The classical Gomory-Hu algorithm [14] solves the minimum cut problem using n 1 minimum s-t cut computations. The fastest current algorithms for the s-t cut problem <ref> [1, 6, 7, 13, 21] </ref> use flow techniques, in particular the push-relabel method [13], and run in !(nm) time.
Reference: [22] <author> H. Nagamochi and T. Ibaraki. </author> <title> Computing Edge-Connectivity in Multigraphs and Capacitated Graphs. </title> <journal> SIAM J. Disc. Meth., </journal> <volume> 5 </volume> <pages> 54-66, </pages> <year> 1992. </year>
Reference-contexts: This algorithm runs in O (nm log (n 2 =m)) time. Several new algorithms discovered recently are theoretically more efficient time bounds for these algorithms are competitive with or better than the best time bounds for the minimum s-t cut problem. The algorithm of Nagamochi and Ibaraki <ref> [22] </ref> (ni) runs in O (n (m + n log n)) time. The algorithm of Karger and Stein [20] (ks) runs in O (n 2 log 3 n) expected time. <p> The value of fi is higher for algorithms that use PR tests internally and lower for other algorithms. Note that the preprocessing runs in O (m log n) time. 4 Nagamochi-Ibaraki Algorithm We assume that the reader is familiar with the Nagamochi-Ibaraki algorithms (see <ref> [22, 23] </ref>) and describe our implementation of it. 4.1 Data Structures We implemented ni using both compact contraction and set-union contraction. We use amortization techniques to combine the two data structures. Recall that the algorithm operates in phases.
Reference: [23] <author> H. Nagamochi, T. Ono, and T. Ibaraki. </author> <title> Implementing an Efficient Minimum Capacity Cut Algorithm. </title> <journal> Math. Prog., </journal> <volume> 67 </volume> <pages> 297-324, </pages> <year> 1994. </year>
Reference-contexts: These contractions, which we call the PR heuristics, apply in the context of other algorithms and often lead to a big improvement in performance. Nagamochi et al. <ref> [23] </ref> describe an efficient implementation of nithat uses the PR heuristics. The data of [23] suggests that the hybrid code of Nagamochi et al. is more efficient than the Padberg-Rinaldi code. <p> These contractions, which we call the PR heuristics, apply in the context of other algorithms and often lead to a big improvement in performance. Nagamochi et al. <ref> [23] </ref> describe an efficient implementation of nithat uses the PR heuristics. The data of [23] suggests that the hybrid code of Nagamochi et al. is more efficient than the Padberg-Rinaldi code. The former code seems to be the fastest minimum cut code described in a paper published prior to our work. <p> We introduce algorithm-specific ways of using PR heuristics during execution of main subroutines of the algorithms. We also develop several new heuristics that significantly improve performance of our implementations. We now briefly detail the highlights of the implementations of our four codes. Our implementation of ni builds on hybrid <ref> [23] </ref>. However, we use a different strategy for applying the PR heuristics and develop a new technique for graph contraction. As a result, our code is always competitive with hybrid, and sometimes outperforms it by a wide margin. <p> Overall, ho is the best code. The second best code is ni. The push-relabel method has been extensively studied, and ho takes advantage what has been learned in the maximum flow context. Our code ni takes advantage of performance-improving ideas of <ref> [23] </ref>. Our implementations of ks and k, however, were developed from scratch. Our study shows how important data structures and heuristics are for the minimum cut algorithm performance. New ideas may improve performance. This is more likely for ks and k, which have been studied less. <p> For a fixed pair v; w, PR3 and PR4 can be checked in O (n) time. We always apply the two tests together, and compute the sum for PR4 while doing PR3. The Padberg-Rinaldi tests have been used previously <ref> [25, 23] </ref>. We propose new ways of using these tests with are both effective and efficient. 3.1 PR Passes We introduce the idea of PR passes. All our codes that use PR heuristic apply these passes as preprocessing. ni also applies the passes internally. Each pass takes linear time. <p> The value of fi is higher for algorithms that use PR tests internally and lower for other algorithms. Note that the preprocessing runs in O (m log n) time. 4 Nagamochi-Ibaraki Algorithm We assume that the reader is familiar with the Nagamochi-Ibaraki algorithms (see <ref> [22, 23] </ref>) and describe our implementation of it. 4.1 Data Structures We implemented ni using both compact contraction and set-union contraction. We use amortization techniques to combine the two data structures. Recall that the algorithm operates in phases. <p> Graph compaction is the additional overhead of the combination scheme, but the compaction takes linear time usually less time than the preceding phase. 4.2 Incorporating the Padberg-Rinaldi Heuristic Nagamochi et al. <ref> [23] </ref> show that the Nagamochi-Ibaraki algorithm can benefit from the PR heuristics. At the end of every phase, they take a node created by the last contraction of the phase and apply PR tests to "large capacity" edges adjacent to this node until a large capacity edge is not contracted. <p> We also did experiments on minimum cut problems that arise in the solution of large TSP problems via cutting plane algorithms [3]. One of our generators, noigen, is an implementation of the generator of <ref> [23] </ref>. The remaining generators were designed and implemented from scratch. One of the contributions of our work is to introduce this useful collection of generators than can be used by others to test minimum cut algorithms. <p> Due to the lack of space, we give data only for three problem families, and only the data that shows relative algorithm performance. The first family is NOI1, produced by noigen generator and is similar to the first problem family of <ref> [23] </ref>. Two other families are generated by the reggen generator, which produces unions of random cycles. Each REG2 problem contains 50 cycles; each REG3 problem contains 2 cycles. The full paper contains much more data, including data for other families and data that shows effectiveness of heuristics. <p> We also give data for hybrid, the Nagamochi et al. <ref> [23] </ref> implementation of the Nagamochi-Ibaraki algorithm with a PR heuristic. The most robust code in our study is ho, but it does not dominate all other algorithms. The second best code is ni. See the full paper for discussion of performance of individual and effectiveness of heuristics.
Reference: [24] <author> Q. C. Nguyen and V. Venkateswaran. </author> <title> Implementations of Goldberg-Tarjan Maximum Flow Algorithm. </title> <editor> In D. S. Johnson and C. C. McGeoch, editors, </editor> <title> Network Flows and Matching: </title> <booktitle> First DI-MACS Implementation Challenge, </booktitle> <pages> pages 19-42. </pages> <publisher> AMS, </publisher> <year> 1993. </year>
Reference-contexts: As a result, our code is always competitive with hybrid, and sometimes outperforms it by a wide margin. Implementations of the push-relabel method for the maximum flow problem have been well-studied, e.g. <ref> [2, 8, 10, 11, 24] </ref>. A maximum flow code of Cherkassky and Goldberg [8] was the starting point of our implementation of ho. The implementation uses the heuristics used in the maximum flow code global update and gap relabeling.
Reference: [25] <author> M. Padberg and G. Rinaldi. </author> <title> An Efficient Algorithm for the Minimum Capacity Cut Problem. </title> <journal> Math. Prog., </journal> <volume> 47 </volume> <pages> 19-36, </pages> <year> 1990. </year>
Reference-contexts: Our problem families are carefully selected and proved very useful for comparing and tuning minimum cut codes. The first efficient implementation of a minimum cut algorithm that we are aware of is due to Padberg and Rinaldi <ref> [25] </ref>. In order to reduce the number of maximum flow computations needed by the Gomory-Hu algorithm, they developed a set of heuristics which contract certain edges during the computation. <p> The improvements of Padberg and Rinaldi <ref> [25] </ref> are based on additional tests (PR tests) that allow contracting certain nodes without performing any maximum flow computations. Four of the tests are inexpensive enough to be of practical interest. Lemma 3.1. ([25]) Let ^ be an upper bound on (G). <p> For a fixed pair v; w, PR3 and PR4 can be checked in O (n) time. We always apply the two tests together, and compute the sum for PR4 while doing PR3. The Padberg-Rinaldi tests have been used previously <ref> [25, 23] </ref>. We propose new ways of using these tests with are both effective and efficient. 3.1 PR Passes We introduce the idea of PR passes. All our codes that use PR heuristic apply these passes as preprocessing. ni also applies the passes internally. Each pass takes linear time.
Reference: [26] <author> S. A. Plotkin, D. Shmoys, and E. Tardos. </author> <title> Fast Approximation Algorithms for Fractional Packing and Covering. </title> <booktitle> In Proc. FOCS 32, </booktitle> <year> 1991. </year>

References-found: 25

