URL: http://www.cs.colostate.edu/~ftppub/TechReports/1994/tr-110.ps.Z
Refering-URL: http://www.cs.colostate.edu/~ftppub/
Root-URL: 
Title: The Relationship Between Test Coverage and Reliability  
Author: Yashwant K. Malaiya, Naixin Li, Jim Bieman, Rick Karcich, Bob Skibbe 
Affiliation: Department of Computer Science  Colorado State University  
Abstract: Technical Report CS-94-110 March 15, 1994 
Abstract-found: 1
Intro-found: 1
Reference: [agr93] <author> H. Agrawal, J.R. Horgan, </author> <title> E.W. Krauser, S.A. London, "A testing-Based model and Risk Browser for C" Proc. </title> <booktitle> Int. Conf.on Rel., Qual.Control and Risk Asses., </booktitle> <month> Oct. </month> <year> 1993, </year> <pages> pp 1-7. </pages>
Reference-contexts: The second data set, DS2, is from a NASA supported project implementing sensor management in inertial navigation system [vou92]. For this program, 1196 test cases were applied and 9 defects were detected. The third data set, DS3, is for a simple program used to illustrate test coverage measures <ref> [agr93] </ref>. The fourth data set, DS4, is from an evolving software system containing a large number of modules. <p> However for testing of individual modules or for highly reliable software p-use may be a better measure. 3. Several researchers have suggested use of some form of a weighted risk measure <ref> [agr93, pos93, neu93] </ref>, where a weighted average is computed using some coverage measures. The weights are chosen on the basis of relative significance of each measure.
Reference: [bei90] <author> B. Beizer, </author> <title> Software Testing Techniques, </title> <publisher> Van Nostrand Reinhold, </publisher> <year> 1990, </year> <pages> pp. 74-75, 161-171. </pages>
Reference-contexts: The needs of early reliability measurement and modeling unfortunately are not met by common testing practices. The focus of testing is on finding defects, and defects can be often found much faster by non-random methods <ref> [bei90] </ref>. Testing is directed towards inputs and program components where errors are more likely. For example, testing may be conducted to insure that particular portions of the program and/or boundary cases are covered. Models that can measure and predict reliability based on the status of non-random testing are clearly needed. <p> The model given by Equation 8 fits the data very well. The data shows that C 1 &gt; C 2 &gt; C 4 . This relationship is expected. Complete decision coverage implies complete block coverage, and complete p-uses coverage implies complete decision coverage <ref> [bei90, fra88, n88] </ref>. The c-uses coverage has no such relation relative to the other metrics. Indeed the data shows that while C 3 &lt; C 1 at the beginning of testing, near the end of testing C 3 is almost equal to C 1 .
Reference: [bisc89] <author> J.M. Bieman and J.L. Schultz, </author> <title> "Estimating the Number of Test Cases Required to Satisfy the All-du-paths Testing Criterion," </title> <booktitle> Proc. ACM SIGSOFT, in Software Engineering Notes, </booktitle> <month> Dec. </month> <year> 1989, </year> <month> pp.179-186. </month>
Reference: [bisc92] <author> J.M. Bieman and J.L. Schultz, </author> <title> "An Empirical Evaluation (and Specification) of the All-du-paths Testing Criterion," </title> <journal> Software Engineering Journal, </journal> <month> Jan. </month> <year> 1992, </year> <pages> pp. 43-51. </pages>
Reference: [chm92] <author> M.H. Chen, J.R. Horgan, A.P. Mathur and V.J. Rego, </author> <title> "A time/structure based model for estimating software reliability," </title> <institution> SERC-TR-117-P, Purdue University, </institution> <month> Dec. </month> <year> 1992. </year>
Reference-contexts: Vouk's experimental results, however, support the use of a more general Weibull distribution. Using the Rayleigh model, Vouk computed that, in terms of error removal capability, the relative power of the coverage measures block:p-use:DUD-chains is 1:2:6. Chen et al <ref> [chm92] </ref> incorporate structural coverage into traditional time-based software reliability models (SRMs). Their model only includes test cases that increase coverage. The included test effort data is used to fit existing time-based models. Thus, they avoided the overestimation from traditional time-based SRMs due to the saturation effect of testing strategies.
Reference: [dhk93] <author> S.R. Dalal, J.R. Horgan and J.R. Kettenring, </author> <title> "Reliable Software and Communi cations: Software Quality, Reliability and Safety," </title> <booktitle> Proc. 15th Int. Conf. Software Engineering, </booktitle> <month> May </month> <year> 1993, </year> <pages> pp. 425-435 </pages>
Reference-contexts: Their results support the view that structural (procedure) coverage may be used as an indicator of testing thoroughness. However, they did not model the relation between test coverage and software reliability. Dalal et al <ref> [dhk93] </ref> also examined the correlation between test coverage and the error removal rate. They give a scatter plot of the number of faults detected during system testing versus the block coverages achieved during unit testing for 28 program modules.
Reference: [dun86] <author> J.R. Dunham, </author> <title> "Experiments in software reliability: Life Critical Applications," </title> <journal> IEEE Trans. Soft. Eng., </journal> <month> Jan. </month> <year> 1986, </year> <pages> pp. 110-123. </pages>
Reference-contexts: Notice that a detectability value of 0 is possible, since a branch might be infeasible, or a defect might not be testable because of redundancy in implementation. Detectability profiles of several digital circuits [mal84, wag87] and software systems <ref> [tra92, dun86] </ref> have been compiled by researchers. If the number of enumerables is very large, the discrete NDP above can be approximated by a continuous function defined below.
Reference: [fra88] <author> P.G. Frankl and E.J. Wayuker, </author> <title> "An Applicable Family of Data Flow Testing Criteria," </title> <journal> IEEE Trans. Soft. Eng., </journal> <month> Oct. </month> <year> 1988, </year> <pages> pp. 1483-1498. </pages>
Reference-contexts: The model given by Equation 8 fits the data very well. The data shows that C 1 &gt; C 2 &gt; C 4 . This relationship is expected. Complete decision coverage implies complete block coverage, and complete p-uses coverage implies complete decision coverage <ref> [bei90, fra88, n88] </ref>. The c-uses coverage has no such relation relative to the other metrics. Indeed the data shows that while C 3 &lt; C 1 at the beginning of testing, near the end of testing C 3 is almost equal to C 1 .
Reference: [fra93] <author> P.G.Frankl and N.Weiss, </author> <title> "An Experimental Comparison of the Effectiveness of Branch Testing and Data Flow Testing," </title> <journal> IEEE Trans. Soft. Eng., </journal> <month> Aug. </month> <year> 1993, </year> <pages> pp. 774-787. </pages>
Reference-contexts: They also derived an exponential model relating the covering frequency to the error removal ratio. However, the utility of the model relies on prior knowledge of the error distribution over different functional groups in a product. Frankl and Weiss <ref> [fra93] </ref> compared the fault exposing capability of branch coverage and data flow coverage criteria. They found that for 4 out of 7 programs, the effectiveness of a test in exposing an error is positively correlated with the two coverage measures.
Reference: [gra92] <author> R.E. Grady, </author> <title> Practical Software Metrics for Project Management and Process improvement, </title> <publisher> PTR prentice-Hall, </publisher> <year> 1992, </year> <pages> pp. 58-60. </pages>
Reference-contexts: The branch coverage shows saturation at about 84%. This may provide an explanation for why it is often considered quite adequate to achieve 80% branch coverage <ref> [gra92] </ref>. The computed values are obtained using the number of tests and Equation 8 (traditional reliability growth modeling), and using test coverage measures C 1 , C 2 , C 3 and C 4 using Equation 11. <p> If the requirements are such that 100% block coverage is not enough, branch or p-use coverage may be more appropriate. From prevailing practices in industry today, it appears that branch coverage may be an adequate measure in many cases, since about 80% branch 16 coverage often produces acceptable results <ref> [gra92] </ref>. However for testing of individual modules or for highly reliable software p-use may be a better measure. 3. Several researchers have suggested use of some form of a weighted risk measure [agr93, pos93, neu93], where a weighted average is computed using some coverage measures.
Reference: [hec94] <author> H. Hecht and P. Crane, </author> <title> "Rare Conditions and Their Effect on Software Failures," </title> <booktitle> Proceedings of Ann. reliability and maintainability Symp., </booktitle> <pages> pp. 334-337, </pages> <month> Jan. </month> <year> 1994. </year>
Reference: [lim93] <author> N. Li and Y. K. Malaiya, </author> <title> "Fault Exposure Ratio and Reliability Estimation," </title> <booktitle> Proc. 3rd Workshop on Issues in Software Reliability, </booktitle> <month> November </month> <year> 1993, </year> <pages> pp. </pages> <month> 6.3.1-6.3.18. </month>
Reference-contexts: An empirical method to estimate the initial fault exposure ratio K 0 (0) has been suggested by Li and Malaiya <ref> [lim93] </ref>. Estimation of a i remains an open problem. The second parameter is given by, b i = a 0 T s (13) The single test execution time T s depends on the program size and its structure.
Reference: [limi93] <author> N. Li and Y.K. Malaiya, </author> <title> "Enhancing Acuracy of Software reliability Prediction" IEEE Int. </title> <booktitle> Symp. on Software Reliability Engineering, </booktitle> <year> 1993. </year>
Reference: [lyu93] <author> M.R. Lyu, J.R. Horgan and S. </author> <title> London, "A coverage Analysis Tool for the Effec tiveness of Software Testing" IEEE Int. </title> <booktitle> Symp. on Software Reliability Engineering, </booktitle> <year> 1993, </year> <pages> pp. 25-34. </pages>
Reference-contexts: The first data set, DS1, is from a multiple-version automatic airplane landing system <ref> [lyu93] </ref>. The twelve versions have a total of 30,694 lines. The data used here is for integration and acceptance test phases, where 66 defects were found. One additional defect was found during operational testing.
Reference: [mal84] <author> Y.K. Malaiya and S. Yang, </author> <title> "The Coverage Problem for Random Testing," </title> <booktitle> Pro ceedings of Int. Test Conference, </booktitle> <pages> pp. 237-242, </pages> <month> October </month> <year> 1984. </year>
Reference-contexts: The distribution of detectability values in the system under test is given by the detectability profile. The detectability profile concept was introduced by Malaiya and Yang <ref> [mal84] </ref> and has been used to characterize testing of hardware [wag87] as well as software [mvs93]. A continuous version of the detectability profile was defined by Seth, Agrawal and Farhat [set90]. For convenience, we use the normalized detectability profile (NDP) as defined below. <p> Notice that P 1 j di = 1 since all fractions added will be unity. Notice that a detectability value of 0 is possible, since a branch might be infeasible, or a defect might not be testable because of redundancy in implementation. Detectability profiles of several digital circuits <ref> [mal84, wag87] </ref> and software systems [tra92, dun86] have been compiled by researchers. If the number of enumerables is very large, the discrete NDP above can be approximated by a continuous function defined below. <p> Hence it can be used to calculate expected coverage when a given number of tests have been applied. In this section, we will assume that testing is random, i.e. any single test is selected randomly with replacement. Malaiya and Yang <ref> [mal84] </ref>, and Wagner et al [wag87] have shown that 6 the expected coverage of the enumerables of type j is given by C j (n) = 1 i=1 j j provided testing is random.
Reference: [mkv92] <author> Y. K. Malaiya, N. Karunanithi and P. Verma, </author> <title> "Predictability of Software Relia bility Models," </title> <journal> IEEE Trans. Reliability, </journal> <month> Dec. </month> <year> 1992, </year> <pages> pp. 539-546. </pages>
Reference-contexts: The part of the data used here covers an intermediate phase of the process. The analysis of evolving programs is however more complex and is the subject of future research. 7 Model Parameters Researchers have noticed that the logarithmic model works best among other two-parameter models <ref> [mkv92] </ref>, however interpretation of its parameters has been difficult. One interpretation is given by Malaiya et al [mvs92], described by Equations 9 and 10. We can argue that the same interpretation may be applicable for enumerables other than defects.
Reference: [mus87] <author> J.D. Musa, A Iannino, K. Okumoto, </author> <title> Software Reliability, Measurement, Predic tion, Application, </title> <publisher> McGraw-Hill, </publisher> <year> 1987. </year>
Reference-contexts: This process makes actual testing more directed and hence more efficient than random testing. Malaiya, von Mayrhauser and Srimani [mvs92] show that this non-random process leads to a defect finding behavior described by the logarithmic growth model <ref> [mus87] </ref>. Their analysis gives an interpretation for the model parameters. The coverage growth of an enumerable-type depends on the detectability profile of the type and the test selection strategy.
Reference: [mvs92] <author> Y. K. Malaiya, A. von Mayrhauser and P. Srimani, </author> <title> "The Nature of Fault Expo sure Ratio," </title> <booktitle> Proc. IEEE Int. Symp. Soft. Rel. </booktitle> <address> Eng., </address> <month> Oct. </month> <year> 1992, </year> <pages> pp. 23-32. </pages>
Reference-contexts: In actual practice, a test case is selected in order to exercise a functionality or enumerable that has remained untested so far. This process makes actual testing more directed and hence more efficient than random testing. Malaiya, von Mayrhauser and Srimani <ref> [mvs92] </ref> show that this non-random process leads to a defect finding behavior described by the logarithmic growth model [mus87]. Their analysis gives an interpretation for the model parameters. The coverage growth of an enumerable-type depends on the detectability profile of the type and the test selection strategy. <p> The analysis of evolving programs is however more complex and is the subject of future research. 7 Model Parameters Researchers have noticed that the logarithmic model works best among other two-parameter models [mkv92], however interpretation of its parameters has been difficult. One interpretation is given by Malaiya et al <ref> [mvs92] </ref>, described by Equations 9 and 10. We can argue that the same interpretation may be applicable for enumerables other than defects. <p> A-priori estimation of model parameters remains a partly unsolved problem. Currently we must rely on curve fitting based approaches. 8 Defect density and reliability Since the failure intensity is proportional to the number of defects, we have <ref> [mvs92, mvs93] </ref>, 14 = T L Where K is the overall value of fault exposure ratio. Let N 0 be the total number of faults initially present in the program and there is no new fault introduced during testing process.
Reference: [mvs93] <author> Y. K. Malaiya, A. von Mayrhauser and P. Srimani, </author> <title> "An examination of Fault Exposure Ratio," </title> <note> to appear in IEEE Trans. </note> <institution> Software Engineering, </institution> <year> 1993. </year>
Reference-contexts: The distribution of detectability values in the system under test is given by the detectability profile. The detectability profile concept was introduced by Malaiya and Yang [mal84] and has been used to characterize testing of hardware [wag87] as well as software <ref> [mvs93] </ref>. A continuous version of the detectability profile was defined by Seth, Agrawal and Farhat [set90]. For convenience, we use the normalized detectability profile (NDP) as defined below. <p> With non-random testing assumption, it takes a finite, although possibly large, number of tests to achieve 100% coverage of the feasible enumerables. For defects (i = 0), the parameters fi 0 0 and fi 1 1 have the following interpretation <ref> [mvs93] </ref>. fi 0 K 0 (0)N 0 (0) (9) fi 0 where K 0 is the exposure ratio, T L is the linear execution time and a 0 is a parameter that describes the variation in the exposure ratio. <p> A-priori estimation of model parameters remains a partly unsolved problem. Currently we must rely on curve fitting based approaches. 8 Defect density and reliability Since the failure intensity is proportional to the number of defects, we have <ref> [mvs92, mvs93] </ref>, 14 = T L Where K is the overall value of fault exposure ratio. Let N 0 be the total number of faults initially present in the program and there is no new fault introduced during testing process.
Reference: [n88] <author> S.C. Ntafos, </author> <title> "A comparision of some structural testing strategies" IEEE Trans. </title> <journal> Software Engineering, </journal> <month> June </month> <year> 1988, </year> <month> pp.868-874. </month>
Reference-contexts: The model given by Equation 8 fits the data very well. The data shows that C 1 &gt; C 2 &gt; C 4 . This relationship is expected. Complete decision coverage implies complete block coverage, and complete p-uses coverage implies complete decision coverage <ref> [bei90, fra88, n88] </ref>. The c-uses coverage has no such relation relative to the other metrics. Indeed the data shows that while C 3 &lt; C 1 at the beginning of testing, near the end of testing C 3 is almost equal to C 1 .
Reference: [neu93] <author> A.M. Neufelder, </author> <title> Ensuring Software Reliability, </title> <publisher> Marcel Dekker Inc., </publisher> <year> 1993, </year> <pages> pp. 137-140. </pages>
Reference-contexts: Since the 7 programs they used are very small and they only considered subtle errors, the result can not be extrapolated to practical software. They did not model the relation between test coverage and fault coverage. The Leone test coverage model given in <ref> [neu93] </ref> is a weighted average of four different coverage metrics achieved during test phases: lines of executable code, independent test paths, functions/requirements, and hazard test cases. The weighted average is used as an indicator of software reliability. <p> However for testing of individual modules or for highly reliable software p-use may be a better measure. 3. Several researchers have suggested use of some form of a weighted risk measure <ref> [agr93, pos93, neu93] </ref>, where a weighted average is computed using some coverage measures. The weights are chosen on the basis of relative significance of each measure.
Reference: [poc93] <author> P. Piwowarski, M. Ohba and J. Caruso, </author> <title> "Coverage measurement experience dur ing function test," </title> <booktitle> Proc. 15th Int. Conf. Software Engineering, </booktitle> <month> May </month> <year> 1993, </year> <pages> pp. 287-300 </pages>
Reference-contexts: Thus, they avoided the overestimation from traditional time-based SRMs due to the saturation effect of testing strategies. They do not relate test coverage directly to the error removal process as we do here. Assuming random testing, Piwowarski, Ohba and Caruso <ref> [poc93] </ref> analyzed block coverage growth during function test, and derived an exponential model relating the number of tests to block coverage Their model is equivalent to the GO model attempted in [ram85]. They also derived an exponential model relating the covering frequency to the error removal ratio.
Reference: [pos93] <author> R.M. Poston, </author> <title> "The Power of Simple Software Testing Metrics", </title> <journal> Software Testing Times, </journal> <volume> Vol. 3, No. </volume> <year> 1993. </year>
Reference-contexts: The model assumes that full coverage of all four metrics implies that the software tested is 100% reliable. In reality, such software may have some remaining faults. A similar approach, but with different coverage metrics, was taken to provide a test quality report <ref> [pos93] </ref>. In this paper, we explore the connection between test coverage and reliability. We develop a model that relates test coverage to defect coverage. <p> However for testing of individual modules or for highly reliable software p-use may be a better measure. 3. Several researchers have suggested use of some form of a weighted risk measure <ref> [agr93, pos93, neu93] </ref>, where a weighted average is computed using some coverage measures. The weights are chosen on the basis of relative significance of each measure.
Reference: [ram85] <author> J. Ramsey and V.R.Basili, </author> <title> "Analyzing the Test Process Using Structural Cover age", </title> <booktitle> Proc. 8th Int. Conf. on Software Engineering, </booktitle> <month> August </month> <year> 1985, </year> <pages> pp. 306-312. </pages>
Reference-contexts: Intuition and empirical evidence suggests that test coverage must be related to reliability. Yet, the connection between structure based measurements, like test coverage, and reliability is still not well understood. Ramsey and Basili <ref> [ram85] </ref> experimented with different permutations of the same test set and collected data relating the number of tests to statement coverage growth. A variety of models were attempted to fit the data. The best fit was obtained using the Goel and Okumoto's exponential model (GO model). <p> Assuming random testing, Piwowarski, Ohba and Caruso [poc93] analyzed block coverage growth during function test, and derived an exponential model relating the number of tests to block coverage Their model is equivalent to the GO model attempted in <ref> [ram85] </ref>. They also derived an exponential model relating the covering frequency to the error removal ratio. However, the utility of the model relies on prior knowledge of the error distribution over different functional groups in a product.
Reference: [set90] <author> S.C. Seth, V.D. Agrawal and H. Farhat, </author> <title> "A Statistical Theory of Digital Circuit Testability," </title> <journal> IEEE Trans. Comp., </journal> <month> April, </month> <year> 1990, </year> <pages> pp. 582-586. </pages>
Reference-contexts: The detectability profile concept was introduced by Malaiya and Yang [mal84] and has been used to characterize testing of hardware [wag87] as well as software [mvs93]. A continuous version of the detectability profile was defined by Seth, Agrawal and Farhat <ref> [set90] </ref>. For convenience, we use the normalized detectability profile (NDP) as defined below. <p> Malaiya and Yang [mal84], and Wagner et al [wag87] have shown that 6 the expected coverage of the enumerables of type j is given by C j (n) = 1 i=1 j j provided testing is random. The same result can be obtained for continuous NDP <ref> [set90] </ref> C j (n) = 1 0 In practice, testing is more likely to be pseudo-random, when a test will not be repeated. In this cases random testing can be considered to be an approximation. This approximation can be fairly good, except when close to 100% coverage has been achieved. <p> The use of Equations 3 and 4 requires the knowledge of detectability profiles. Obtaining exact detectability profiles requires a lot of computation. Discrete detectability profiles have been calculated for several small and large combinational circuits. Continuous detectability profiles for some benchmark circuits have been estimated <ref> [set90] </ref>. However software systems are generally much more complex. Fortunately, it is possible to obtain reasonable approximation for the detectability profiles. When one test is applied, the probability that an enumerable with detectability d j i will not be covered is (1 d j i ).
Reference: [tra92] <author> M. Trachtenberg, </author> <title> "Why Failure Rates observe Zipf's Law in Operational Soft ware," </title> <journal> IEEE Trans. Reliability, </journal> <month> Sept. </month> <year> 1992, </year> <pages> pp. 386-389. </pages>
Reference-contexts: Notice that a detectability value of 0 is possible, since a branch might be infeasible, or a defect might not be testable because of redundancy in implementation. Detectability profiles of several digital circuits [mal84, wag87] and software systems <ref> [tra92, dun86] </ref> have been compiled by researchers. If the number of enumerables is very large, the discrete NDP above can be approximated by a continuous function defined below.
Reference: [voas92] <author> J. Voas and K. Miller, </author> <title> "Improving the Software Development Process Using Testability Research," </title> <booktitle> Proc. Int. Symp. on Software Reliability Engineering, </booktitle> <year> 1992, </year> <pages> pp. 114-121. </pages>
Reference-contexts: A statement which is reached more easily, is more testable. Such statements are likely to get covered (i.e. exercised at lease once) with only a small number of tests. Testability also depends on the likelihood that a fault that is reached actually causes a failure <ref> [voas92] </ref>. On the other hand a statement which gets executed in rare situations has low testability. It may not get exercised by most of the tests which would 5 normally be applied. As testing progresses, the distribution of testability values will shift.
Reference: [vou92] <author> M.A. </author> <title> Vouk "Using Reliability Models During Testing With Non-operational Pro files," </title> <booktitle> Proc. 2nd Bellcore/Purdue workshop on issues in Software Reliability Estimation, </booktitle> <month> Oct. </month> <year> 1992, </year> <pages> pp. 103-111 </pages>
Reference-contexts: They give a scatter plot of the number of faults detected during system testing versus the block coverages achieved during unit testing for 28 program modules. The plot clearly shows that modules covered more thoroughly during unit testing are much less likely to contain errors. 2 Vouk <ref> [vou92] </ref> found that the relation between structural coverage and fault coverage is a variant of the Rayleigh distribution. He assumed that the fault detection rate during testing is proportional to the number of faults present in the software and test coverage values including block, branch, data-flow, and functional group coverage. <p> The data used here is for integration and acceptance test phases, where 66 defects were found. One additional defect was found during operational testing. The second data set, DS2, is from a NASA supported project implementing sensor management in inertial navigation system <ref> [vou92] </ref>. For this program, 1196 test cases were applied and 9 defects were detected. The third data set, DS3, is for a simple program used to illustrate test coverage measures [agr93]. The fourth data set, DS4, is from an evolving software system containing a large number of modules.
Reference: [wag87] <author> K. Wagnor, C. Chin and E. McCluskey, </author> <title> "Pseudorandom Testing," </title> <journal> IEEE Trans. Comput., </journal> <volume> Vol. C-36, </volume> <pages> pp. 332-343, </pages> <month> March </month> <year> 1987. </year>
Reference-contexts: The distribution of detectability values in the system under test is given by the detectability profile. The detectability profile concept was introduced by Malaiya and Yang [mal84] and has been used to characterize testing of hardware <ref> [wag87] </ref> as well as software [mvs93]. A continuous version of the detectability profile was defined by Seth, Agrawal and Farhat [set90]. For convenience, we use the normalized detectability profile (NDP) as defined below. <p> Notice that P 1 j di = 1 since all fractions added will be unity. Notice that a detectability value of 0 is possible, since a branch might be infeasible, or a defect might not be testable because of redundancy in implementation. Detectability profiles of several digital circuits <ref> [mal84, wag87] </ref> and software systems [tra92, dun86] have been compiled by researchers. If the number of enumerables is very large, the discrete NDP above can be approximated by a continuous function defined below. <p> Hence it can be used to calculate expected coverage when a given number of tests have been applied. In this section, we will assume that testing is random, i.e. any single test is selected randomly with replacement. Malaiya and Yang [mal84], and Wagner et al <ref> [wag87] </ref> have shown that 6 the expected coverage of the enumerables of type j is given by C j (n) = 1 i=1 j j provided testing is random.
Reference: [weu84] <author> E.J. Weyuker, </author> <title> "More Experience with Data Flow Testing", </title> <journal> IEEE Trans. Software Engineering, </journal> <month> September </month> <year> 1993, </year> <pages> pp. 912-919. </pages>
Reference-contexts: If there is a directed path from criteria A to criteria B, then test sets that meet criteria A (complete coverage) are guaranteed to satisfy criteria B. Table 1 shows the upper bounds on the test length <ref> [weu84] </ref> to satisfy these criteria and the observed complexities [weu93] for some of the criteria. Such knowledge of complexities can be very useful for testers for selecting appropriate test coverage criteria. The upper bound for all-du-paths was reached in one subroutine out of 143 considered by Bieman and Schultz [bisc89,bisc92].
Reference: [weu93] <author> E.J. Weyuker, </author> <title> "An Empirical Study of the Complexity of Data Flow Testing," </title> <booktitle> 2nd Workshop on Software Testing, Verification, and Analysis, </booktitle> <month> July </month> <year> 1988. </year> <month> 19 </month>
Reference-contexts: The defect coverage in 4 software can be defined in an analogous manner, it is the fraction of actual defects initially present, that would be detected by a given test set. Table 1: The complexity (test length) for achieving different coverage criteria <ref> [weu93] </ref> Coverage Criterion Upper bound Observed All-Blocks d + 1 All-Branches d + 1 All-P-Uses 1 4 (d 2 + 4d + 3) 0:38d + 3:17 All-Defs m + (i fi n) All-P-Uses/Some-C-Uses 1 4 (d 2 + 4d + 3) All-C-Uses/Some-P-Uses 1 4 (t 2 + 4d + 3) 0:36d <p> If there is a directed path from criteria A to criteria B, then test sets that meet criteria A (complete coverage) are guaranteed to satisfy criteria B. Table 1 shows the upper bounds on the test length [weu84] to satisfy these criteria and the observed complexities <ref> [weu93] </ref> for some of the criteria. Such knowledge of complexities can be very useful for testers for selecting appropriate test coverage criteria. The upper bound for all-du-paths was reached in one subroutine out of 143 considered by Bieman and Schultz [bisc89,bisc92].
References-found: 31

