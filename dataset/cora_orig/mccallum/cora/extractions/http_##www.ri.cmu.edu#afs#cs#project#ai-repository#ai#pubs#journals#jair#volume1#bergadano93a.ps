URL: http://www.ri.cmu.edu/afs/cs/project/ai-repository/ai/pubs/journals/jair/volume1/bergadano93a.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs/project/ai-repository/ai/pubs/journals/jair/volume1/
Root-URL: 
Email: bergadan@di.unito.it  gunetti@di.unito.it  trincher@di.unito.it  
Title: The Difficulties of Learning Logic Programs with Cut  
Author: Francesco Bergadano Daniele Gunetti Umberto Trinchero 
Address: via Andrea Doria 6, 95100 Catania, Italy  corso Svizzera 185, 10149 Torino, Italy  
Affiliation: Universita di Catania, Dipartimento di Matematica,  Universita di Torino, Dipartimento di Informatica,  
Note: Journal of Artificial Intelligence Research 1 (1993) 91-107 Submitted 8/93; published 11/93  
Abstract: As real logic programmers normally use cut (!), an effective learning procedure for logic programs should be able to deal with it. Because the cut predicate has only a procedural meaning, clauses containing cut cannot be learned using an extensional evaluation method, as is done in most learning systems. On the other hand, searching a space of possible programs (instead of a space of independent clauses) is unfeasible. An alternative solution is to generate first a candidate base program which covers the positive examples, and then make it consistent by inserting cut where appropriate. The problem of learning programs with cut has not been investigated before and this seems to be a natural and reasonable approach. We generalize this scheme and investigate the difficulties that arise. Some of the major shortcomings are actually caused, in general, by the need for intensional evaluation. As a conclusion, the analysis of this paper suggests, on precise and technical grounds, that learning cut is difficult, and current induction techniques should probably be restricted to purely declarative logic languages.
Abstract-found: 1
Intro-found: 1
Reference: <author> Aha, D., Ling, C., Matwin, S., & Lapointe, S. </author> <year> (1993). </year> <title> Learning Singly Recursive Relations from Small Datasets. </title> <booktitle> In Proceedings of the IJCAI-93 workshop on ILP. </booktitle>
Reference: <author> Bergadano, F. </author> <year> (1993a). </year> <title> Inductive database relations. </title> <journal> IEEE Transactions on Data and Knowledge Engineering, </journal> <month> 5 (6). </month> <title> 106 The Difficulties of Learning Logic Programs with Cut Bergadano, </title> <editor> F. </editor> <year> (1993b). </year> <title> Test Case Generation by Means of Learning Techniques. </title> <booktitle> In Proceedings of ACM SIGSOFT-93. </booktitle>
Reference-contexts: The main difference is that standard approaches based on extensionality do not allow for backtracking and do not guarantee that a correct solution is found <ref> (Bergadano, 1993a) </ref>. As far as computational complexity is concerned, trace-based methods have a complexity standing between the search in a space of independent clauses (for the extensional methods) and the exhaustive search in a space of possible programs. <p> The only difference is that we do not have backtracking (problem 1), but the situation is probably worse, since extensional methods can fail to learn a complete program even if it exists in the hypothesis space. <ref> (Bergadano, 1993a) </ref>. Even if the ability to learn clauses containing procedural predicates like cut seems to be fundamental to learning "real" logic programs, in particular short and efficient programs, many problems influencing the complexity of the learning task must be faced.
Reference: <author> Bergadano, F., & Gunetti, D. </author> <year> (1993). </year> <title> An interactive system to learn functional logic programs. </title> <booktitle> In Proceedings of IJCAI-93. </booktitle>
Reference-contexts: Shapiro's MIS system (Shapiro, 1983) uses it when refining clauses, although it does not when backtracing inconsistencies. We have also used an extensional evaluation of clauses in the FILP system <ref> (Bergadano & Gunetti, 1993) </ref>. When learning programs with cut, clauses are no longer independent and their standalone extensional evaluation is meaningless. When a cut predicate is evaluated, other possible clauses for proving the same goal will be ignored. This changes the meaning of these other clauses. <p> Moreover, candidate recursive clauses must be designed so that no infinite chains of recursive calls can take place <ref> (Bergadano & Gunetti, 1993) </ref> (otherwise the learning task itself could be non-terminating). In general, the number of possible recursive calls must be kept small, in order to avoid too much backtracking when searching for possible traces. However, general constraints may not be sufficient.
Reference: <author> Coelho, H., & Cotta, J. C. </author> <year> (1988). </year> <title> Prolog by Example: how to learn teach and use it. </title> <publisher> Berlin: Springer-Verlag. </publisher>
Reference-contexts: Simplif y takes as input a list whose members may be lists, and transforms it into a "flattened" list of single members, containing no repetitions and no lists as members. This program appears as exercise number 25 in <ref> (Coelho & Cotta, 1988) </ref>, is composed of nine clauses (plus the clauses for append and member); six of them are recursive, one is doubly-recursive and cut is extensively used. Even if simplif y is a not a very complex logic program, it is more complex than usual ILP test cases. <p> Obviously, it is also possible to give negative examples as normal ground literals. The learning procedure outputs the program for simplif y reported below, which turns out to be substantially equivalent to the one described in <ref> (Coelho & Cotta, 1988) </ref> (we have kept clauses unflattened). simplify (L,NL) :- flatten (L,L1), remove (L1,NL). flatten (X,L) :- equal (X,[L1,T]), null (T), !, flatten (L1,X2), assign (X2,L). flatten (X,L) :- head (X,H), tail (X,L1), null (H), !, flatten (L1,X2), assign (X2,L). flatten (X,L) :- equal (X,[L1]), !, flatten (L1,X2), assign
Reference: <author> Cohen, W. </author> <year> (1993). </year> <title> Rapid Prototyping of ILP Systems Using Explicit Bias. </title> <booktitle> In Proceedings of the IJCAI-93 workshop on ILP. </booktitle>
Reference-contexts: In general, many kinds of constraints can be applied to keep a hypothesis space small, such as ij-determinism (Muggleton & Feng, 1990), rule sets and schemata (Kietz & Wrobel, 1991; Bergadano & Gunetti, 1993), determinations (Russell, 1988), locality <ref> (Cohen, 1993) </ref>, etc (in fact, some of these restrictions and others, such as those listed in Section 3, are available in the actual implementation of our procedure seethe Appendix 4 ).
Reference: <author> DeRaedt, L., Lavrac, N., & Dzeroski, S. </author> <year> (1993). </year> <title> Multiple predicate learning. </title> <booktitle> In Proceedings of IJCAI-93. </booktitle>
Reference: <author> Kietz, J. U., & Wrobel, S. </author> <year> (1991). </year> <title> Controlling the Complexity of Learning in Logic through Syntactic and Task-Oriented Models. </title> <editor> In Muggleton, S. (Ed.), </editor> <booktitle> Inductive Logic Programming. </booktitle> <address> London: </address> <publisher> Academic Press. </publisher>
Reference: <author> Lau, K. K., & Clement, T. (Eds.). </author> <year> (1993). </year> <title> Logic Program Synthesis and Transformation. </title> <publisher> Berlin: Springer-Verlag. </publisher>
Reference-contexts: Green cuts are also important, and less controversial. Once a correct program has been inferred via inductive methods, it could be made more efficient through the insertion of green cuts, either manually or by means of automated program transformation techniques <ref> (Lau & Clement, 1993) </ref>. 1.2 Why Standard Approaches Cannot be Used? Most Machine Learning algorithms generate rules or clauses one at a time and independently of each other: if a rule is useful (it covers some positive example) and correct (it does not cover any negative example), then it is added
Reference: <author> Ling, X. C. </author> <year> (1991). </year> <title> Learning from Good Examples. </title> <booktitle> In Proceedings of IJCAI-91. </booktitle>
Reference: <author> Muggleton, S. (Ed.). </author> <year> (1991). </year> <title> Inductive Logic Programming. </title> <publisher> London: Academic Press. </publisher>
Reference: <author> Muggleton, S., & Feng, C. </author> <year> (1990). </year> <title> Efficient Induction of Logic Programs. </title> <booktitle> In Proceedings of the first conference on Algorithmic Learning Theory. </booktitle>
Reference-contexts: Therefore, the learning system will decide whether to accept C as part of the final program P independently of the other clauses P will contain. The extensionality principle is found in Foil (Quinlan, 1990) and its derivatives, but is also used in bottom-up methods such as Golem <ref> (Muggleton & Feng, 1990) </ref>. Shapiro's MIS system (Shapiro, 1983) uses it when refining clauses, although it does not when backtracing inconsistencies. We have also used an extensional evaluation of clauses in the FILP system (Bergadano & Gunetti, 1993). <p> A small trace would also have a slight positive impact on the need to test for different literal orderings in clauses (problem 5). In general, many kinds of constraints can be applied to keep a hypothesis space small, such as ij-determinism <ref> (Muggleton & Feng, 1990) </ref>, rule sets and schemata (Kietz & Wrobel, 1991; Bergadano & Gunetti, 1993), determinations (Russell, 1988), locality (Cohen, 1993), etc (in fact, some of these restrictions and others, such as those listed in Section 3, are available in the actual implementation of our procedure seethe Appendix 4 ).
Reference: <author> Quinlan, R. </author> <year> (1990). </year> <title> Learning Logical Definitions from Relations. </title> <journal> Machine Learning, </journal> <volume> 5, </volume> <pages> 239-266. </pages>
Reference-contexts: For this reason, determining whether C covers e only depends on C and on the positive examples. Therefore, the learning system will decide whether to accept C as part of the final program P independently of the other clauses P will contain. The extensionality principle is found in Foil <ref> (Quinlan, 1990) </ref> and its derivatives, but is also used in bottom-up methods such as Golem (Muggleton & Feng, 1990). Shapiro's MIS system (Shapiro, 1983) uses it when refining clauses, although it does not when backtracing inconsistencies.
Reference: <editor> Rouveirol, C. (in press). </editor> <title> Flattening: a representation change for generalization. </title> <booktitle> Machine Learning. </booktitle>
Reference: <author> Russell, S. </author> <year> (1988). </year> <title> Tree-structured bias. </title> <booktitle> In Proceedings of AAAI-88. </booktitle>
Reference-contexts: In general, many kinds of constraints can be applied to keep a hypothesis space small, such as ij-determinism (Muggleton & Feng, 1990), rule sets and schemata (Kietz & Wrobel, 1991; Bergadano & Gunetti, 1993), determinations <ref> (Russell, 1988) </ref>, locality (Cohen, 1993), etc (in fact, some of these restrictions and others, such as those listed in Section 3, are available in the actual implementation of our procedure seethe Appendix 4 ).
Reference: <author> Shapiro, E. Y. </author> <year> (1983). </year> <title> Algorithmic Program Debugging. </title> <address> Cambridge, CA: </address> <publisher> MIT Press. </publisher> <pages> 107 </pages>
Reference-contexts: The extensionality principle is found in Foil (Quinlan, 1990) and its derivatives, but is also used in bottom-up methods such as Golem (Muggleton & Feng, 1990). Shapiro's MIS system <ref> (Shapiro, 1983) </ref> uses it when refining clauses, although it does not when backtracing inconsistencies. We have also used an extensional evaluation of clauses in the FILP system (Bergadano & Gunetti, 1993). When learning programs with cut, clauses are no longer independent and their standalone extensional evaluation is meaningless.
References-found: 15

