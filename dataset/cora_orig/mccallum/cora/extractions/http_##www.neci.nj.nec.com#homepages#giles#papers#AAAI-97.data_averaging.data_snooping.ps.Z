URL: http://www.neci.nj.nec.com/homepages/giles/papers/AAAI-97.data_averaging.data_snooping.ps.Z
Refering-URL: http://www.neci.nj.nec.com/homepages/giles/html/CLG_pub.html
Root-URL: 
Email: fgiles,lawrenceg@research.nj.nec.com  
Title: Averaging and Data Snooping  
Author: C. Lee Giles and Steve Lawrence 
Address: 4 Independence Way, Princeton NJ 08540  
Affiliation: NEC Research Institute,  
Note: Data  
Abstract: Presenting and Analyzing the Results of AI Experiments: Data Averaging and Data Snooping, Proceedings of the Fourteenth National Conference on Artificial Intelligence, AAAI-97, AAAI Press, Menlo Park, California, pp. 362367, 1997. Copyright AAAI. Presenting and Analyzing the Results of AI Experiments: Abstract Experimental results reported in the machine learning AI literature can be misleading. This paper investigates the common processes of data averaging (reporting results in terms of the mean and standard deviation of the results from multiple trials) and data snooping in the context of neural networks, one of the most popular AI machine learning models. Both of these processes can result in misleading results and inaccurate conclusions. We demonstrate how easily this can happen and propose techniques for avoiding these very important problems. For data averaging, common presentation assumes that the distribution of individual results is Gaussian. However, we investigate the distribution for common problems and find that it often does not approximate the Gaussian distribution, may not be symmetric, and may be multimodal. We show that assuming Gaussian distributions can significantly affect the interpretation of results, especially those of comparison studies. For a controlled task, we find that the distribution of performance is skewed towards better performance for smoother target functions and skewed towards worse performance for more complex target functions. We propose new guidelines for reporting performance which provide more information about the actual distribution (e.g. box-whiskers plots). For data snooping, we demonstrate that optimization of performance via experimentation with multiple parameters can lead to significance being assigned to results which are due to chance. We suggest that precise descriptions of experimental techniques can be very important to the evaluation of results, and that we need to be aware of potential data snooping biases when formulating these experimental techniques (e.g. selecting the test procedure). Additionally, it is important to only rely on appropriate statistical tests and to ensure that any assumptions made in the tests are valid (e.g. normality of the distribution). 
Abstract-found: 1
Intro-found: 1
Reference: <author> Back, A. </author> <year> 1992. </year> <title> New Techniques for Nonlinear System Identification: A Rapprochement Between Neural Networks and Linear Systems. </title> <type> Ph.D. Dissertation, </type> <institution> Department of Electrical Engineering, University of Queensland. </institution>
Reference-contexts: For the experiments reported here, we have chosen t = 30, and subsampled the series using T = 6. We consider predicting the series one step ahead. For this problem, the results of a number of architectures are compared: MLP, FIR MLP, and IIR MLP <ref> (Back 1992) </ref>. The FIR and IIR MLP networks are similar to the standard MLP except each synapse is replaced by FIR and IIR 2 filters respectively. <p> Each network had 5 hidden nodes and was trained for 200,000 updates. There were 1000 training patterns and 1000 test patterns. The FIR and IIR networks were tested both with and without synaptic gains <ref> (Back 1992) </ref>. It is interesting to observe the difference in the distribution of results in this case. When using synaptic gains an extra parameter is inserted into each synapse which multiplies the weighted sum of the individual filter outputs. <p> Altering a synaptic gain is equivalent to altering all of the weights corresponding to the filter taps. The addition of synaptic gains does not affect the representational power of the networks, however it does affect the error surface and the extra degrees of freedom may make optimization easier <ref> (Back 1992) </ref>. squared error (NMSE) results. It can be observed that the distribution varies significantly across the various models and that the distributions are often highly skewed and several are multimodal. Figure 3 shows box-whiskers plots and the usual mean and standard deviation plots for these models.
Reference: <author> Blum, A., and Rivest, R. </author> <year> 1992. </year> <title> Training a 3-node neural network is NP-complete. </title> <booktitle> Neural Networks 5(1):117127. </booktitle>
Reference: <author> Cohen, P. </author> <year> 1995. </year> <title> Empirical Methods for Artificial Intelligence. </title> <address> Cambridge, Massachussets: </address> <publisher> MIT Press. </publisher>
Reference-contexts: This section presents a case for providing more information about the experimental process, and using more information when formulating the experimental process, than is commonly done. Researchers are aware of many forms of experimental bias, e.g. ceiling and floor effects, regression effects, and order effects <ref> (Cohen 1995) </ref>. However, investigation of the machine learning AI literature shows that data snooping biases are often ignored. Data snooping commonly refers to the practice of assigning meaning to spurious correlations or patterns.
Reference: <author> Crane, R.; Fefferman, C.; Markel, S.; and Pearson, J. </author> <year> 1995. </year> <title> Characterizing neural network error surfaces with a sequential quadratic programming algorithm. In Machines That Learn. </title>
Reference-contexts: The bias weights are initialized to small random values in the range (0:01; 0:01). 3 The task is similar to the procedure used in <ref> (Crane et al. 1995) </ref>. case) for the Mackey-Glass task shown with the mean plus or minus one standard deviation (on the right in each case). For the box-whiskers plots the box corresponds to the IQR, the bar represents the median, and the whiskers extend to the minimum and maximum values.
Reference: <author> Darken, C., and Moody, J. </author> <year> 1991. </year> <title> Note on learning rate schedules for stochastic optimization. </title> <editor> In Lippmann, R.; Moody, J.; and Touretzky, D. S., eds., </editor> <booktitle> Advances in Neural Information Processing Systems, volume 3. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher> <pages> 832838. </pages>
Reference-contexts: time delay differential equation first proposed as a model of white blood cell production (Mackey & Glass 1977): dx = [1 + x c (t t )] 1 We have found this to result in similar performance to the search then converge learning rate schedules proposed by Darken and Moody <ref> (Darken & Moody 1991) </ref>. networks trained on the phoneme problem. The left hand graph shows the training distribution and the right hand graph shows the test distribution.
Reference: <author> Farago, A., and Lugosi, G. </author> <year> 1993. </year> <title> Strong universal consistency of neural network classifiers. </title> <journal> IEEE Transactions on Information Theory 39(4):11461151. </journal>
Reference: <author> Farmer, J. D. </author> <year> 1982. </year> <title> Chaotic attractors of an infinite-dimensional dynamical system. </title> <journal> Physica 4D:366. </journal>
Reference-contexts: The distribution is created from 200 individual simulations with random starting points. Note that the scales change between the graphs. where the constants are commonly chosen as a = 0:2, b = 0:1, and c = 10. The delay parameter t determines the behavior of the system <ref> (Farmer 1982) </ref>. For t &lt; 4:53 there is a stable fixed point attractor. For 4:53 &lt; t &lt; 13:3 there is a stable limit cycle attractor. Period doubling begins at t = 13:3 and continues until t = 16:8. For t &gt; 16:8 the system produces a chaotic attractor.
Reference: <author> Flexer, A. </author> <year> 1995. </year> <title> Statistical evaluation of neural network experiments: Minimum requirements and current practice. </title> <type> Technical Report OEFAI-TR-95-16, </type> <institution> The Austrian Research Institute for Artificial Intelligence, Schottengasse 3, A-1010 Vienna, Aus-tria. </institution>
Reference-contexts: Current recommendations include the fl Copyright 1997, American Association for Artificial Intelligence (www.aaai.org). All rights reserved. reporting of the mean and standard deviation of results from a number of trials (herein called data averaging), and the computation of statistical tests such as the t-test for performance comparisons <ref> (Flexer 1995) </ref>. However, these recommendations assume that the distribution of results from multiple trials is Gaussian, and that potential biases such as data snooping are taken into account. <p> Performance Measures The typical method of assessing performance (by running multiple simulations, each beginning from a different starting point in weight space, and reporting the mean and standard deviation of the results <ref> (Flexer 1995) </ref>) is most suitable when the distribution of the results is Gaussian. For example, if a particular network and training algorithm has a distribution of results which is skewed or multimodal, this will not be observed using the mean and standard deviation. <p> Conclusions Publications commonly report the performance of neural networks using the mean and variance of a number of simulations with different starting conditions. Other papers recommend reporting confidence intervals using Gaussian or t-distributions and testing the significance of comparisons using the t-test <ref> (Flexer 1995) </ref>. However, these as varied. types. sume symmetric distributions. The distribution of results for neural network simulations can vary widely depending on the architecture, data, and training algorithm.
Reference: <author> Haykin, S. </author> <year> 1994. </year> <title> Neural Networks, A Comprehensive Foundation. </title> <address> New York, NY: </address> <publisher> Macmillan. </publisher>
Reference-contexts: Training Details Standard backpropagation was used with stochastic update (update after every training point). Except when specified, all networks are MLPs. All inputs were normalized to zero mean and unit variance. The quadratic cost function was used <ref> (Haykin 1994) </ref>. The learning rate was reduced linearly to zero 1 over the training period from an initial value of 0.1. Performance is reported in terms of the percentage of examples incorrectly classified (for the classification problem) or normalized mean squared error (NMSE). <p> They are initialized on a node by node basis as uniformly distributed random numbers in the range (2:4=F i ; 2:4=F i ) where F i is the fan-in of neuron i <ref> (Haykin 1994) </ref>. Each network was trained for 200,000 updates. for the following four cases: K = 1; 5; 10; 15.
Reference: <author> Mackey, M., and Glass, L. </author> <year> 1977. </year> <title> Oscillation and chaos in physiological control systems. </title> <publisher> Science 197:287. </publisher>
Reference-contexts: The K-S test is not used in this case, because the underlying distribution (of classification error) is discrete rather than continuous. Mackey-Glass The Mackey-Glass equation is a time delay differential equation first proposed as a model of white blood cell production <ref> (Mackey & Glass 1977) </ref>: dx = [1 + x c (t t )] 1 We have found this to result in similar performance to the search then converge learning rate schedules proposed by Darken and Moody (Darken & Moody 1991). networks trained on the phoneme problem.
Reference: <author> Prechelt, L. </author> <year> 1996. </year> <title> A quantitative study of experimental evaluations of neural network learning algorithms. </title> <booktitle> Neural Networks 9:457462. </booktitle>
Reference: <author> Press, W.; Teukolsky, S.; Vetterling, W.; and Flannery, B. </author> <year> 1992. </year> <title> Numerical Recipes. </title> <address> Cambridge: Cambridge University Press, </address> <note> second edition. </note>
Reference-contexts: Box-whiskers plots incorporate the median, IQR, minimum and maximum values of a distribution (Tukey 1977). Kolmogorov-Smirnov Test We use the Kolmogorov-Smirnov test in order to test for normality of the distributions. The K-S statistic is <ref> (Press et al. 1992) </ref>: D = max 1&lt;x<1 jS (x) N (x)j where S (x) is an estimator of the cumulative distribution function of the distribution to test and N (x) is the cumulative distribution function for (in this case) the normal distribution (erf ( x p 2 )=2+0:5 for mean
Reference: <author> Tukey, J. </author> <year> 1977. </year> <title> Exploratory Data Analysis. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: The median, IQR, minimum and maximum values can provide more information about the distribution of results and, consequently, the nature of the optimization process. Box-whiskers plots incorporate the median, IQR, minimum and maximum values of a distribution <ref> (Tukey 1977) </ref>. Kolmogorov-Smirnov Test We use the Kolmogorov-Smirnov test in order to test for normality of the distributions.
Reference: <author> Verleysen, M.; Voz, J.; Thissen, P.; and Legat, J. </author> <year> 1995. </year> <title> A statistical neural network for high-dimensional vector classification. </title> <booktitle> In Proceedings of the IEEE International Conference on Neural Networks, ICNN 95. </booktitle> <address> Perth, Western Australia: </address> <publisher> IEEE. </publisher>
Reference-contexts: Performance is reported in terms of the percentage of examples incorrectly classified (for the classification problem) or normalized mean squared error (NMSE). Phoneme Data These experiments use a database from the ESPRIT ROARS project. The aim of the task is to distinguish between nasal and oral vowels <ref> (Verleysen et al. 1995) </ref>. There are 3600 training patterns, 1800 test patterns, five inputs provided by cochlear spectra, and two outputs. Using 10 hidden nodes and 250,000 iterations per trial, the distribution of results is shown in figure 1.
Reference: <author> Weiss, N., and Hassett, M. </author> <year> 1987. </year> <title> Introductory Statistics. </title> <address> Reading, Massachusetts: </address> <publisher> Addison-Wesley, second edition. </publisher>
Reference-contexts: Descriptive Statistics Median and Interquartile Range We will use the median and the interquartile range (IQR) in the following sections. The median and the interquartile range (IQR) are simple statistics which are not as sensitive to outliers as the commonly used mean and standard deviation <ref> (Weiss & Hassett 1987) </ref>. The median is the value in the middle when arranging the distribution in order from the smallest to the largest value. If we divide the data into two equal groups about the median, then the IQR is the difference between the medians of these groups.
References-found: 15

