URL: ftp://ftp.cs.rochester.edu/pub/u/nelson/1996_us_japan.ps.gz
Refering-URL: http://www.cs.rochester.edu/users/faculty/nelson/pubs/pubs.html
Root-URL: 
Email: ffuentes,nelsong@cs.rochester.edu  
Title: Learning Dextrous Manipulation Skills for Multifingered Robot Hands  
Author: Olac Fuentes and Randal C. Nelson 
Address: Rochester, New York 14627  
Affiliation: Computer Science Department University of Rochester  
Web: http://www.cs.rochester.edu/u/ffuentes,nelsong/  
Abstract: We present a method for autonomous learning of dextrous manipulation skills with robot hands. We use heuristics derived from observations made on human hands to reduce the degrees of freedom of the task and make learning tractable. Our approach consists of learning and storing a few manipulation primitives for a few prototypical objects and then using an associative memory to obtain the required parameters for new objects and/or manipulations. The parameter space of the robot is searched using a modified version of the evolution strategy. Our system does not rely on simulation; all the experimentation is performed by a physical robot, the 16-degree-of-freedom Utah/MIT hand. Experimental results show that accurate dextrous manipulation skills can be learned in a short period of time. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Arbib, T. Iberall, and D. Lyons. </author> <title> Coordinated control programs for movements of the hand. </title> <type> Technical Report 83-25, </type> <institution> Department of Computer and Information Science, University of Massachusetts at Amherst, Amherst, Mas-sachusetts, </institution> <year> 1983. </year>
Reference-contexts: Observations made on human hands offer some clues about how to deal with the problem of the high dimensionality of the parameter space of dextrous manipulators. Arbib et al. <ref> [1] </ref> introduced the concept of virtual fingers as a model for task representation at higher levels in the human central nervous system. In this model, a virtual finger is composed of one or more real fingers working together to solve a problem in a task.
Reference: [2] <author> R. E. Bellman. </author> <title> Dynamic Programming. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1957. </year>
Reference-contexts: Due to the large number of degrees of freedom of dextrous manipulators, machine learning approaches to this problem face the well-known "curse of dimensionality" <ref> [2] </ref>, which states that the number of samples required to learn a task grows exponentially with the number of parameters of the task.
Reference: [3] <author> O. Fuentes and R. C. Nelson. </author> <title> Experiments on dextrous manipulation without prior object models. </title> <type> Technical Report 606, </type> <institution> Computer Science Department, University of Rochester, Rochester, </institution> <address> New York, </address> <month> February </month> <year> 1996. </year>
Reference-contexts: Table 1 shows goal positions and errors for a few selected learned manipulations. Although few quantitative results for other systems have been reported, the quality of the manipulations seems comparable to the one obtained by other systems where the manipulations are programmed by hand, such as <ref> [3, 6, 10] </ref>. 4 Conclusions and Future Work We have presented a method for machine learning of dextrous manipulation skills.
Reference: [4] <author> O. Fuentes and R. C. Nelson. </author> <title> Learning dextrous manipulation skills for multifingered robot hands. </title> <type> Technical Report 613, </type> <institution> Computer Science Department, University of Rochester, Rochester, </institution> <address> New York, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: In the look-up phase we use a nearest-neighbors approach to obtain the appropriate virtual finger commands for a given object and goal. For details see <ref> [4] </ref>. 3 Experimental Results The algorithms described in the previous section were implemented in our vision and robotics lab using the Utah/MIT dextrous hand [5]. We used a magnetic sensor attached to the object being manipulated for position and orientation sensing.
Reference: [5] <author> S. Jacobsen, E. Iversen, D. Knutti, R. Johnson, and K. Bigger. </author> <title> Design of the Utah/MIT Dextrous Hand. </title> <booktitle> In Proceedings of the 1986 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 96-102, </pages> <year> 1986. </year>
Reference-contexts: In the look-up phase we use a nearest-neighbors approach to obtain the appropriate virtual finger commands for a given object and goal. For details see [4]. 3 Experimental Results The algorithms described in the previous section were implemented in our vision and robotics lab using the Utah/MIT dextrous hand <ref> [5] </ref>. We used a magnetic sensor attached to the object being manipulated for position and orientation sensing. For tactile sensing we used pressure-sensitive resistors, which were taped to the object. experimental setup is shown in figure 1.
Reference: [6] <author> P. Michelman and P. Allen. </author> <title> Compliant manipulation with a dexterous robot hand. </title> <booktitle> In Proceedings of the 1993 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 711-716, </pages> <address> At-lanta, Georgia, </address> <year> 1993. </year>
Reference-contexts: Table 1 shows goal positions and errors for a few selected learned manipulations. Although few quantitative results for other systems have been reported, the quality of the manipulations seems comparable to the one obtained by other systems where the manipulations are programmed by hand, such as <ref> [3, 6, 10] </ref>. 4 Conclusions and Future Work We have presented a method for machine learning of dextrous manipulation skills.
Reference: [7] <author> S. Narasimhan. </author> <title> Dexterous robot hands: Kinematics and control. </title> <type> Master's thesis, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <address> Cambridge, Mas-sachusetts, </address> <month> November </month> <year> 1988. </year>
Reference-contexts: We consider the following to be the most salient features of this work. 3 This observation has been used in other systems (e. g. <ref> [7] </ref>) for computing the inverse kinematics of the Utah/MIT hand.
Reference: [8] <author> I. Rechenberg. </author> <title> Evolutionsstrategie: Optimierung technischer Systeme nach Prinzipien der biolo-gischen Evolution. </title> <publisher> Frommann-Holzboog Verlag, Stuttgart, </publisher> <year> 1973. </year>
Reference-contexts: The choice of 1 5 as a constant to modify and is based on Rechenberg's 1/5 success rule <ref> [8] </ref> and was proven to be optimal for a restricted kind of object functions and has been observed to work well in practice. The learning algorithm is used to fill-up a table con taining virtual finger commands and indexed by object and perceptual goal.
Reference: [9] <author> H.-P. Schwefel. </author> <title> Numerical Optimization of Computer Models. </title> <publisher> John Wiley & Sons, Ltd., </publisher> <year> 1981. </year>
Reference-contexts: Therefore we have to resort to optimization techniques that are better at dealing with local minima and handling an apparently non-deterministic environment. The optimization method we use is a modification of the well-known evolution strategy <ref> [9] </ref>, an iterative probabilistic optimization algorithm loosely based on biological evolution.
Reference: [10] <author> T. H. Speeter. </author> <title> Primitive Based Control of the Utah/MIT Dextrous Hand. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 866-877, </pages> <address> Sacramento, Califor-nia, </address> <year> 1991. </year>
Reference-contexts: Euler angles azimuth, elevation and roll defining the object's orientation with respect to a hand-centered coordinate system, and p 1 ; : : : ; p n are the readings in the tactile sensors located at each of the n fingertips. 1 These primitives are analogous to Speeter's motion primitives <ref> [10] </ref>, but in his system the primitives were supplied by the programmer, while in ours they are learned automatically. Let g be a perceptual goal and x be a vector encoding virtual finger commands. <p> Table 1 shows goal positions and errors for a few selected learned manipulations. Although few quantitative results for other systems have been reported, the quality of the manipulations seems comparable to the one obtained by other systems where the manipulations are programmed by hand, such as <ref> [3, 6, 10] </ref>. 4 Conclusions and Future Work We have presented a method for machine learning of dextrous manipulation skills. <p> Goal Position Error Orientation Error [25, 0, 0, 0, 0, 0] 1.21 1.56 [0, 25, 0, 0, 0, 0] 2.08 6.64 <ref> [0, 0, 10, 0, 0, 0] </ref> 1.79 2.99 Table 1: Goal positions and errors for a few selected learned manipulations. * Heuristics derived form observations made on human hands were used to reduce the degrees of freedom of dextrous manipulation with robotic hands.
References-found: 10

