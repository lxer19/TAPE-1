URL: http://www.isr.ist.utl.pt/~jasv/vislab/publications/ps/97-PAMI.ps.gz
Refering-URL: http://www.isr.ist.utl.pt/~jasv/vislab/publications/publications.html
Root-URL: 
Title: Robust Egomotion Estimation from the Normal Flow using Search Subspaces  
Author: Cesar Silva Jose Santos-Victor 
Keyword: Index Terms: motion analysis, egomotion, optical flow, normal flow.  
Abstract: We address the problem of egomotion estimation for a monocular observer moving under arbitrary translation and rotation, in an unknown environment. The method we propose is uniquely based on the spatio-temporal image derivatives, or the normal flow. We introduce a search paradigm which is based on geometric properties of the normal flow field, and consists in considering a family of search subspaces to estimate the egomotion parameters. Various algorithms are proposed within this framework. In order to decrease the noise sensitivity of the estimation methods, we use statistical tools, based on robust regression theory. Finally, we present and discuss a wide variety of experiments with synthetic and real images, for various kinds of camera motion. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Aloimonos, I. Weiss, and A. Banddophaday. </author> <title> Active vision. </title> <journal> Int. Journal of Computer Vision, </journal> <volume> 1(4) </volume> <pages> 333-356, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: Usual approaches are based either on point correspondences [10]; on the estimation of the dense motion field, identified by the optical flow [6, 2]; or finally in the so-called direct methods [9, 3, 5]. The correspondence problem or the optical flow estimation are, in general, ill-posed <ref> [1] </ref>, and it is usually necessary to introduce very restrictive assumptions about the observed scenes. These solutions often require extensive amounts of computation. The direct methods are less demanding than the previous ones, and use the image brightness information directly to recover the motion parameters.
Reference: [2] <author> K. Daniilidis and I. Thomas. </author> <title> Decoupling the 3d motion space by fixation. </title> <booktitle> In ECCV96, </booktitle> <address> Cambridge, UK, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: The first step to estimate egomotion or structure from motion is the computation of displacement between consecutive frames. Usual approaches are based either on point correspondences [10]; on the estimation of the dense motion field, identified by the optical flow <ref> [6, 2] </ref>; or finally in the so-called direct methods [9, 3, 5]. The correspondence problem or the optical flow estimation are, in general, ill-posed [1], and it is usually necessary to introduce very restrictive assumptions about the observed scenes. These solutions often require extensive amounts of computation.
Reference: [3] <author> C. Fermuller. </author> <title> Passive navigation as a pattern recognition problem. </title> <journal> Int. Journal of Computer Vision, </journal> <volume> 14(2) </volume> <pages> 147-158, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: The first step to estimate egomotion or structure from motion is the computation of displacement between consecutive frames. Usual approaches are based either on point correspondences [10]; on the estimation of the dense motion field, identified by the optical flow [6, 2]; or finally in the so-called direct methods <ref> [9, 3, 5] </ref>. The correspondence problem or the optical flow estimation are, in general, ill-posed [1], and it is usually necessary to introduce very restrictive assumptions about the observed scenes. These solutions often require extensive amounts of computation. <p> Thus, direct methods are usually based on the normal flow or the spatio-temporal image derivatives [12]. Here we focus the approach developed by Fermuller and Aloimonos <ref> [3, 4, 5] </ref> who introduced a method based on a selection of image points that form global patterns in the image plane, using the orientation of global normal-flow vectors.
Reference: [4] <author> C. Fermuller. </author> <title> Qualitative egomotion. </title> <journal> IJCV, </journal> 15(1/2):7-29, June 1995. 
Reference-contexts: Thus, direct methods are usually based on the normal flow or the spatio-temporal image derivatives [12]. Here we focus the approach developed by Fermuller and Aloimonos <ref> [3, 4, 5] </ref> who introduced a method based on a selection of image points that form global patterns in the image plane, using the orientation of global normal-flow vectors. <p> This approach considers the complete egomotion estimation problem as a pattern recognition problem, introducing a set of geometric constraints that reveal a global structure hidden in normal-flow fields. Then, the use of global data favors the robustness of the algorithms. The approach we follow is related to previous work <ref> [4, 13] </ref>, and the method consists in searching the image for particular geometric properties of the normal flow, tightly connected to the egomotion parameters.
Reference: [5] <author> C. Fermuller and Y. Aloimonos. </author> <title> Direct perception of three-dimensional motion from patterns of visual motion. </title> <journal> Science, </journal> <volume> 270 </volume> <pages> 1973-1976, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: The first step to estimate egomotion or structure from motion is the computation of displacement between consecutive frames. Usual approaches are based either on point correspondences [10]; on the estimation of the dense motion field, identified by the optical flow [6, 2]; or finally in the so-called direct methods <ref> [9, 3, 5] </ref>. The correspondence problem or the optical flow estimation are, in general, ill-posed [1], and it is usually necessary to introduce very restrictive assumptions about the observed scenes. These solutions often require extensive amounts of computation. <p> Thus, direct methods are usually based on the normal flow or the spatio-temporal image derivatives [12]. Here we focus the approach developed by Fermuller and Aloimonos <ref> [3, 4, 5] </ref> who introduced a method based on a selection of image points that form global patterns in the image plane, using the orientation of global normal-flow vectors.
Reference: [6] <author> D. Heeger and A. Jepson. </author> <title> Subspace methods for recovering rigid motion i: Algorithm and implementation. </title> <journal> Int. Journal of Computer Vision, </journal> <volume> 7(2) </volume> <pages> 95-117, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: The first step to estimate egomotion or structure from motion is the computation of displacement between consecutive frames. Usual approaches are based either on point correspondences [10]; on the estimation of the dense motion field, identified by the optical flow <ref> [6, 2] </ref>; or finally in the so-called direct methods [9, 3, 5]. The correspondence problem or the optical flow estimation are, in general, ill-posed [1], and it is usually necessary to introduce very restrictive assumptions about the observed scenes. These solutions often require extensive amounts of computation. <p> Hence, rather than considering the whole set of image flow data, we use only the image sites, that have special geometric properties, which convey relevant information about the observer motion. As proposed by Heeger and Jepson <ref> [6] </ref>, one can solve separately the rotational and translational motion parameters due to bilinear nature of the image motion equations. We also subdivide the problem, but in a different way. <p> linear velocity t = [U V W ] T , angular velocity ! = [! 1 ! 2 ! 3 ] T and the scene depth at each point, Z, the motion field induced on the image plane, can be calculated at every pixel by the following well-known vector equation <ref> [6] </ref> : v (x) = (x)(x ) + B (x)! (1) where v (x) = [u (x) v (x)] T is the optical flow observed at a given image site, x = [x y] T ; = [ ] T = [f U=W; f V =W ] T is the Focus
Reference: [7] <author> B.K.P. Horn. </author> <title> Motion fields are hardly ever ambiguous. </title> <journal> International Journal of computer Vision, </journal> <volume> 1(3) </volume> <pages> 259-274, </pages> <year> 1987. </year>
Reference-contexts: Future research will address the following aspects: (a) development of more sophisticated estimation methods to increase the system robustness and performance; (b) pathological or degenerate cases <ref> [7] </ref>; (c) exceptional cases of increasing difficulty, such as when the FOE is outside the image plane, or when the translational vector is parallel to the image plane; (d) by considering an active observer, one can use further constraints in the egomotion estimation process, and the algorithms proposed can be used
Reference: [8] <author> B.K.P. Horn and B. Shunck. </author> <title> Determining optical flow. Art. </title> <journal> Intelligence, </journal> <volume> 17 </volume> <pages> 185-203, </pages> <year> 1981. </year>
Reference-contexts: Rovisco Pais, 1096 Lisboa Codex, Portugal. E-mail: fcesar,jasvg@isr.ist.utl.pt This work was partially funded by projects PRAXIS/3/3.1/TPR/23/94, JNICT-PBIC/TPR/2550/95, EC ESPRIT-LTR Narval and a grant from the PRAXIS-XXI research program. 1 that can be estimated based on local measurements, is the motion along the image gradient direction, the normal flow <ref> [8] </ref>. Thus, direct methods are usually based on the normal flow or the spatio-temporal image derivatives [12].
Reference: [9] <author> B.K.P. Horn and E.J. Weldon. </author> <title> Direct methods for recovering motion. </title> <journal> International Journal of computer Vision, </journal> <volume> 2(1) </volume> <pages> 51-76, </pages> <year> 1988. </year>
Reference-contexts: The first step to estimate egomotion or structure from motion is the computation of displacement between consecutive frames. Usual approaches are based either on point correspondences [10]; on the estimation of the dense motion field, identified by the optical flow [6, 2]; or finally in the so-called direct methods <ref> [9, 3, 5] </ref>. The correspondence problem or the optical flow estimation are, in general, ill-posed [1], and it is usually necessary to introduce very restrictive assumptions about the observed scenes. These solutions often require extensive amounts of computation. <p> the drawback that the minimization pro-cess involves searching the FOE in a given domain, which may be excessively time consuming; and the need to compute the motion field at a sufficiently large number of pixels. 2.2 The aperture problem constraint Due to the well known constraint of the aperture problem <ref> [9] </ref>, we can only observe the projection of the optical flow, v, on the direction of the image gradient, n.
Reference: [10] <author> F. Lustman O. Faugeras and G. Toscani. </author> <title> Motion and structure from motion from point and line matches. </title> <booktitle> In Proc. 1st Intern. Conf. Comput. Vision, </booktitle> <address> London, </address> <month> June </month> <year> 1987. </year>
Reference-contexts: The first step to estimate egomotion or structure from motion is the computation of displacement between consecutive frames. Usual approaches are based either on point correspondences <ref> [10] </ref>; on the estimation of the dense motion field, identified by the optical flow [6, 2]; or finally in the so-called direct methods [9, 3, 5].
Reference: [11] <author> P.J. Rousseeuw and A.M. Leroy. </author> <title> Robust Regression & Outlier Detection. </title> <publisher> John Wiley & Sons, Inc, </publisher> <year> 1987. </year>
Reference-contexts: introduction of a bounded search paradigm by using a subdivided search domain, based on geometric constraints of the flow field; the fact that it can cope with arbitrary linear and angular observer motion and the effort that it is made on robust estimation in order to decrease the noise sensitivity <ref> [11, 14] </ref>. 2 Problem Statement Given the camera linear velocity t = [U V W ] T , angular velocity ! = [! 1 ! 2 ! 3 ] T and the scene depth at each point, Z, the motion field induced on the image plane, can be calculated at every <p> We applied the parallel and sequential egomotion estimation algorithms. In the parallel approach, we used the least squares estimator to estimate the rotational values from the corresponding observations. In the sequential approach, we used a known robust estimator: the least median of squares estimator <ref> [11] </ref>. In the latter case the estimator is designed for a simple bidimensional estimation problem.
Reference: [12] <author> J. Santos-Victor, G. Sandini, F. Curotto, and S. Garibaldi. </author> <title> Divergent stereo in autonomous navigation : From bees to robots. </title> <journal> Int. Journal of Computer Vision, </journal> <volume> 14(2) </volume> <pages> 159-177, </pages> <year> 1995. </year>
Reference-contexts: Thus, direct methods are usually based on the normal flow or the spatio-temporal image derivatives <ref> [12] </ref>. Here we focus the approach developed by Fermuller and Aloimonos [3, 4, 5] who introduced a method based on a selection of image points that form global patterns in the image plane, using the orientation of global normal-flow vectors.
Reference: [13] <author> C. Silva and J. Santos-Victor. </author> <title> Direct egomotion estimation. </title> <booktitle> In Proc. of the 13th Int. Conference on Pattern Recognition, </booktitle> <address> Vienna,Austria, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: This approach considers the complete egomotion estimation problem as a pattern recognition problem, introducing a set of geometric constraints that reveal a global structure hidden in normal-flow fields. Then, the use of global data favors the robustness of the algorithms. The approach we follow is related to previous work <ref> [4, 13] </ref>, and the method consists in searching the image for particular geometric properties of the normal flow, tightly connected to the egomotion parameters.
Reference: [14] <author> C. Silva and J. Santos-Victor. </author> <title> Robust egomotion estimation from the normal flow using search subspaces. </title> <type> Technical Report 6/96, </type> <institution> ISR/Inst. Sup. Tecnico - VisLab, </institution> <year> 1996. </year> <month> 15 </month>
Reference-contexts: introduction of a bounded search paradigm by using a subdivided search domain, based on geometric constraints of the flow field; the fact that it can cope with arbitrary linear and angular observer motion and the effort that it is made on robust estimation in order to decrease the noise sensitivity <ref> [11, 14] </ref>. 2 Problem Statement Given the camera linear velocity t = [U V W ] T , angular velocity ! = [! 1 ! 2 ! 3 ] T and the scene depth at each point, Z, the motion field induced on the image plane, can be calculated at every <p> In the sequential approach, we used a known robust estimator: the least median of squares estimator [11]. In the latter case the estimator is designed for a simple bidimensional estimation problem. See <ref> [14] </ref> for more details about the estimation procedure. 4.1 The parallel algorithm We applied a parallel algorithm to Sequence 2, using a set of five -line algorithms, corresponding to five different families of parallel lines with different orientations.
References-found: 14

