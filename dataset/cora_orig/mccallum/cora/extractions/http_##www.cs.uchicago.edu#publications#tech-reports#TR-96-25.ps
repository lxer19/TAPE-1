URL: http://www.cs.uchicago.edu/publications/tech-reports/TR-96-25.ps
Refering-URL: http://cs-www.uchicago.edu/publications/tech-reports/
Root-URL: 
Title: Extractors for Kolmogorov Complexity  strings in easy sets have nearly optimal polynomial-time CD complexity.  
Author: Lance Fortnow Sophie Laplante 
Note: Most  This extends work of Sipser [Sip83] and Buhrman and Fortnow [BF97].  
Date: December 4, 1996  
Address: Chicago  
Affiliation: CWI The University of Chicago  University of  
Abstract: We show two sets of results applying the theory of extractors to resource-bounded Kolmogorov complexity: * We use extractors to extract the randomness of strings. In particular we show how to get a random string of high polynomial-time C complexity from a potentially nonrandom string of high polynomial-time CN D complexity.
Abstract-found: 1
Intro-found: 1
Reference: [BF97] <author> H. Buhrman and L. Fortnow. </author> <title> Resource-bounded kolmogorov complexity revisited. </title> <booktitle> In Proceedings of the 14th Symposium on Theoretical Aspects of Computer Science, Lecture Notes in Computer Science. </booktitle> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1997. </year> <note> To appear. </note>
Reference-contexts: Sipser [Sip83] shows that for every set A in P, for all strings x of length n in A, the CD p complexity of x given a "random" string r is bounded by log jAj + O (log n). Buhrman and Fortnow <ref> [BF97] </ref> remove the dependency on the random string but at a cost of only bounding the CD p complexity of x by 2 log jAj + O (log n). <p> We nearly achieve the optimal bound of Sipser without the random string by bounding the CD p complexity of most strings x in A by log jAj + log O (1) n. Following Buhrman and Fortnow <ref> [BF97] </ref>, we also establish a similar relationship between sets in N P and CN D complexity. We can also achieve Sipser's bound for most strings at the cost of only polylogarithmic random bits. <p> When y is the empty string, we write CN D t (x). For more information on Kolmogorov complexity we recommend the comprehensive book by Li and Vitanyi [LV93]. 3 Complexity Bounds on Easy Sets Our theorems improve upon the results of Sipser [Sip83] and Buhrman and Fortnow <ref> [BF97] </ref> in the sense that our bounds are stronger and the strings we obtain have high mutual information. The price we pay for these improvements is that our bounds apply only to "most" strings, not to all strings as in [Sip83, BF97]. <p> The price we pay for these improvements is that our bounds apply only to "most" strings, not to all strings as in <ref> [Sip83, BF97] </ref>. <p> Theorem 3.2 (Buhrman-Fortnow) For any set A 2 P, there is a polynomial p and a constant c such that for all strings x 2 A " n , CD p (x) 2 log (jA " n j) + c log n: We extend the work of Buhrman and Fortnow <ref> [BF97] </ref> by getting nearly the bound of Sipser [Sip83] without the random string used by Sipser. However, our result only works for most strings in A. <p> We refer the reader to the paper of Ko, Orponen, Schoning, and Watanabe [KOSW86] or to section 7.3.3 of the textbook by Li and Vitanyi [LV93] for more information on instance complexity. Note that this observation applies to the results of Buhrman and Fortnow <ref> [BF97] </ref> as well. Of particular interest are the sets in the class IC [log, poly], which is known to sit properly between the nonuniform classes P=log and P/poly. 6 Acknowledgments We would like to thank Stuart Kurtz, Amber Settle, Harry Buhrman and David Zuckerman for several helpful discussions.
Reference: [KOSW86] <author> K. Ko, P. Orponen, U. Schoning, and O. Watanabe. </author> <title> What is a hard instance of a computational problem? In A. </title> <editor> Selman, editor, </editor> <booktitle> Proc. Conference on Structure in Complexity Theory, </booktitle> <pages> pages 197-217. </pages> <publisher> Springer-Verlag, </publisher> <year> 1986. </year>
Reference-contexts: We refer the reader to the paper of Ko, Orponen, Schoning, and Watanabe <ref> [KOSW86] </ref> or to section 7.3.3 of the textbook by Li and Vitanyi [LV93] for more information on instance complexity. Note that this observation applies to the results of Buhrman and Fortnow [BF97] as well.
Reference: [LV93] <author> M. Li and P. Vitanyi. </author> <title> An Introduction to Kolmogorov Complexity and Its Applications. Texts and Monographs in Computer Science. </title> <publisher> Springer, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: For more information on extractors we recommend the survey paper by Nisan [Nis96]. 3 2.4 Kolmogorov and CD Complexity Several variants on Kolmogorov complexity are used in this paper. We give the definitions below, following the notation put forth in <ref> [LV93] </ref>. The time-bounded Kolmogorov complexity of a string x relative to a string y, written C t (xjy), is the length of the shortest program p which on input y, prints out the string x in time bounded by t (jxj + jyj). <p> The time taken on all inputs y; z; w must be bounded by t (jpj + jyj + jzj + jwj). When y is the empty string, we write CN D t (x). For more information on Kolmogorov complexity we recommend the comprehensive book by Li and Vitanyi <ref> [LV93] </ref>. 3 Complexity Bounds on Easy Sets Our theorems improve upon the results of Sipser [Sip83] and Buhrman and Fortnow [BF97] in the sense that our bounds are stronger and the strings we obtain have high mutual information. <p> We refer the reader to the paper of Ko, Orponen, Schoning, and Watanabe [KOSW86] or to section 7.3.3 of the textbook by Li and Vitanyi <ref> [LV93] </ref> for more information on instance complexity. Note that this observation applies to the results of Buhrman and Fortnow [BF97] as well.
Reference: [Nis96] <author> N. Nisan. </author> <title> Extracting randomness: How and why (a survey). </title> <booktitle> In Proceedings of the 11th IEEE Conference on Computational Complexity, </booktitle> <pages> pages 44-58. </pages> <publisher> IEEE, </publisher> <address> New York, </address> <year> 1996. </year>
Reference-contexts: We give more details in Section 2.2. We also recommend the excellent survey on extractors by Nisan <ref> [Nis96] </ref>. fl University of Chicago, Department of Computer Science, 1100 E. 58th St., Chicago, IL 60637. Email: fort-now@cs.uchicago.edu. URL: http://www.cs.uchicago.edu/~fortnow. Supported in part by NSF grant CCR 92-53582 and the Fulbright scholar program. y University of Chicago, Department of Computer Science, 1100 E. 58th St., Chicago, IL 60637. <p> We follow the presentation in Nisan's survey paper <ref> [Nis96] </ref>. An extractor can be thought of as a bipartite graph, whose first color class is larger than the second color class. By convention we think of the first color class as being on the left, and the second on the right. <p> This lower bound also gives a good indication as to the limits of the techniques described in this paper. For more information on extractors we recommend the survey paper by Nisan <ref> [Nis96] </ref>. 3 2.4 Kolmogorov and CD Complexity Several variants on Kolmogorov complexity are used in this paper. We give the definitions below, following the notation put forth in [LV93].
Reference: [NZ93] <author> N. Nisan and D. Zuckerman. </author> <title> More deterministic simulation in logspace. </title> <booktitle> In Proceedings of the 25th ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 235-244. </pages> <publisher> ACM, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: It is useful to compare these constructions to the current lower bound on extractors, due to Nisan and Zuckerman <ref> [NZ93] </ref>. Theorem 2.3 (Nisan-Zuckerman) There is a constant c such that for all n; m; k n 1; " &lt; 1=2, if there is an extractor whose parameters are (n; k; d; m; "); then it must be the case that d maxfm; c log (n=")g.
Reference: [Sip83] <author> M. Sipser. </author> <title> A complexity theoretic approach to randomness. </title> <booktitle> In Proceedings of the 15th ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 330-335. </pages> <publisher> ACM, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: Sipser <ref> [Sip83] </ref> shows that for every set A in P, for all strings x of length n in A, the CD p complexity of x given a "random" string r is bounded by log jAj + O (log n). <p> When y is the empty string, we write CN D t (x). For more information on Kolmogorov complexity we recommend the comprehensive book by Li and Vitanyi [LV93]. 3 Complexity Bounds on Easy Sets Our theorems improve upon the results of Sipser <ref> [Sip83] </ref> and Buhrman and Fortnow [BF97] in the sense that our bounds are stronger and the strings we obtain have high mutual information. The price we pay for these improvements is that our bounds apply only to "most" strings, not to all strings as in [Sip83, BF97]. <p> The price we pay for these improvements is that our bounds apply only to "most" strings, not to all strings as in <ref> [Sip83, BF97] </ref>. <p> P, there is a polynomial p and a constant c such that for all strings x 2 A " n , CD p (x) 2 log (jA " n j) + c log n: We extend the work of Buhrman and Fortnow [BF97] by getting nearly the bound of Sipser <ref> [Sip83] </ref> without the random string used by Sipser. However, our result only works for most strings in A. <p> We will only require that for most x, at least half of the edges from x map to a "good" y. Although this comes at the cost of only applying to "most" strings x, this improves upon the result of Sipser <ref> [Sip83] </ref> by reducing the length of the random string from n O (1) to log O (1) (n="). The proof is similar to that of Theorem 3.6; it requires only a slight modification to the the counting argument.
Reference: [Ta-96] <author> A. Ta-Shma. </author> <title> On extracting randomness from weak random sources (extended abstract). </title> <booktitle> In Proceedings of the 28th ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 276-285. </pages> <publisher> ACM, </publisher> <address> New York, </address> <year> 1996. </year>
Reference-contexts: We have stated our results in general terms so that new results on extractors will be immediately applicable. The current best known explicit constructions for extractors are due to Ta-Shma and Zuckerman <ref> [Ta-96, Zuc96] </ref>. They are described by the theorems below. <p> However, our result only works for most strings in A. Using the extractor construction of Ta-Shma <ref> [Ta-96] </ref> we get the following theorem. 4 Theorem 3.3 For any set A 2 P, " = "(n), there is a polynomial p such that for all n and for all but a 2" fraction of the x 2 A " n , CD p (x) log jA " n j <p> For the remainder of this section, we fix n and we let S = jA " n j. We use an ("; S) extractor G, for which M = S and d = O (log O (1) (n=")) <ref> [Ta-96] </ref>. In our setting, we will think of the set A " n as defining a distribution of min-entropy log S. The string x represents an element of A " n and y is one of its neighbors in the graph G.
Reference: [Zuc96] <author> D. Zuckerman. </author> <title> Randomness-optimal sampling, extractors, and constructive leader election. </title> <booktitle> In Proceedings of the 28th ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 286-295. </pages> <publisher> ACM, </publisher> <address> New York, </address> <year> 1996. </year> <month> 10 </month>
Reference-contexts: We have stated our results in general terms so that new results on extractors will be immediately applicable. The current best known explicit constructions for extractors are due to Ta-Shma and Zuckerman <ref> [Ta-96, Zuc96] </ref>. They are described by the theorems below. <p> P, " = "(n), there is a polynomial p such that for all n and for all but a 2" fraction of the x 2 A " n , CD p (x) log jA " n j + log O (1) (n="): Using a similar proof based on the Zuckerman <ref> [Zuc96] </ref> extractor construction we can get a slightly different bound. <p> C p (yjx) d + O (1) 3. C q (y) &gt; jyj O (1), provided there is an explicit extractor with parameters (n; k; d; m; ") where k = CND pD (x)O (log n) Theorem 4.1 follows by applying Theorem 4.2 with parameters obtained from Zuckerman's extractor <ref> [Zuc96] </ref>. Proof: (Sketch) The idea of the proof is to consider a family of extractors parameterized by n; k; m (k), and look at what happens in the extractor n; k; m (k) to strings x of length n.
References-found: 8

