URL: ftp://ftp.cs.indiana.edu/pub/techreports/TR399.ps.Z
Refering-URL: http://www.cs.indiana.edu/trindex.html
Root-URL: 
Title: A Formalization of the Turing Test  
Author: Phillip G. Bradford and Michael Wollowski 
Keyword: Turing Test, Interactive Proofs, Complexity Theory  
Note: Running Head: A Formalization of the Turing  
Address: 215 Lindley Hall Bloomington, Indiana 47405  
Affiliation: Indiana University Department of Computer Science  
Pubnum: (812) 855-2136  
Email: f bradford, wollowsk g@cs.indiana.edu  
Web: Test  
Date: February 1994  
Abstract: Struggling with the validity of long proofs, program correctness, computational complexity and cryptography, theoreticians developed interactive proof systems. By formalizing the Turing Test as an interactive proof system and by employing results from complexity theory, this paper investigates the power and limitations of the Turing Test. In particular, if human intelligence subsumes machine intelligence, and human intelligence is not simulatable by any bounded machine, then the Turing Test can distinguish humans and machines to within arbitrarily high probability. This paper makes no claim about the Turing Test's sufficiency to distinguish humans and machines. Rather, through its formalization this paper gives several ramifications involving the acceptance or rejection of the Turing Test as sufficient for making any such distinction. fl The authors names are in alphabetical order. An extended abstract of this paper appeared in the Proceedings of the 5th Midwest Artificial Intelligence and Cognitive Science Conference, T. E. Ahlswede Editor, 83-87, April 1993. This is Technical Report #399, Indiana University. Hardcopy is available or a postscript file is obtainable via internet: cs.indiana.edu:/usr/ftp/pub/techreports/TR399.ps.Z. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Arora, A. and S. </author> <title> Safra, </title> <booktitle> (1992) "Probabilistic Checking of Proofs; A New Characterization of N P ," Proceedings of the 33 rd Annual IEEE Symposium on the Foundations of Computer Science, </booktitle> <pages> 13 2-13. </pages>
Reference-contexts: We may view it as being able to generate extremely good heuristics, or as knowing the solution to some famous problem (such as P ? = N P). In fact, it has been shown that many challenging problems have no "good" heuristics <ref> (Arora and Safra, 1992) </ref>. In any event, it does all of its "arbitrarily bounded computations" in polynomial time for convenience. <p> On the other hand it is known that N P 6= N EX PTime: Recently, it has been shown that all problems in N P are interactively provable using a diploma of O (lg n) bits <ref> (Arora and Safra, 1992) </ref>.
Reference: <author> Babai, L. </author> <title> (1988) "Arthur-Merlin Games: A Randomized Proof System, and a Hierarchy of Complexity Classes," </title> <journal> J. of Computer and System Sciences, </journal> <volume> Vol. 36, </volume> <pages> 254-276. </pages>
Reference-contexts: In addition, the interrogator acts as a worst case adversary against the agents. 3 The Turing Test as an Interactive Proof System This section models the Turing Test as an interactive proof system. According to Babai, the class IP models "teacher-student" interactions <ref> (Babai, 1988) </ref>. For instance, when an apparently omnipotent instructor relates a theorem to disbelieving and possibly perplexed students, the students ask questions about it in an apparently probabilistic manner and each of their questions builds their confidence in the validity of the Theorem.
Reference: <author> Babai, L., L. Fortnow, and C. Lund, </author> <title> (1990) "Non-Deterministic Exponential Time has Two-Prover Interactive Proofs," </title> <booktitle> Proceedings of the 31 st Annual IEEE Symposium on the Foundations of Computer Science, </booktitle> <pages> 16-25. </pages>
Reference-contexts: The judge could interactively verify these subgraph isomorphisms independently with the other prover using interactive proofs, provided this other prover could solve the graph isomorphism problem. 8 Theorem 2 <ref> (Babai, et al. 1990) </ref> MIP = N EX PTime In summary, P N P PSpace = IP N EX PTime = MIP: In particular note that it is currently possible that PSpace = N EX PTime, although N P 6= N EX PTime.
Reference: <author> Brassard, G. and C. Crepeau, </author> <title> (1986) "Non-Transitive Transfer of Confidence: A Perfect Zero-Knowledge Interactive Protocol for SAT and Beyond," </title> <booktitle> Proceedings of the 27 th Annual IEEE Symposium on the Foundations of Computer Science, </booktitle> <pages> 188-195. </pages>
Reference: <author> Bylander, T. </author> <title> (1991) "Tractability and Artificial Intelligence," </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence, </journal> <volume> Vol. 3, </volume> <pages> 171-178. </pages>
Reference-contexts: However, there is a large literature on the philosophical implications of the Turing Test, for instance see (Searle, 1990; Epstein, 1992; Johnson, Harnad and Shapiro, 1992). While in a very different context complexity theory has become prominent in the study of artificial intelligence, <ref> (Bylander, 1991) </ref>. 1.4 The Structure of this Paper This paper assumes basic familiarity with complexity theory as in (Garey and Johnson, 1979). Also, throughout this paper we offer the same caveats regarding the size of constants hidden in asymptotic notation.
Reference: <author> Cai, J., A. Condon and R. Lipton, </author> <title> (1994) "PSPACE is Provable by Two Provers in One Round," </title> <journal> Journal of Computer and Systems Sciences, </journal> <volume> Vol. 48, </volume> <pages> 183-193, </pages> <year> 1994. </year>
Reference: <author> Dreyfus, H. </author> <title> (1992) What Computers Still Can't Do, </title> <publisher> MIT Press. </publisher>
Reference: <author> Editorial and Commentary, by Johnson, W. L., S. Harnad, and S. </author> <title> C. </title> <journal> Shapiro (1992) in SIGART Bulletin, </journal> <volume> Vol. 3 No. 4, </volume> <pages> 7-11. </pages>
Reference: <author> Epstein, R. </author> <title> (1992) "Can Machines Think?," </title> <journal> AI Magazine, </journal> <volume> Vol. 13, No. 2, </volume> <pages> 80-95. </pages>
Reference-contexts: We believe it would be interesting to quantify the complexity of interaction in additional classes of problems to shed more light on the Turing Test. In addition, more should be said about the consistency of humans in terms of the Turing Test <ref> (Epstein, 1992) </ref>. And for this reason "typing foibles" have been built into programs that take the Turing Test (Epstein, 1992). In fact, according to Epstein, such foibles may have helped a program win a recent variant of the Turing Test. <p> In addition, more should be said about the consistency of humans in terms of the Turing Test <ref> (Epstein, 1992) </ref>. And for this reason "typing foibles" have been built into programs that take the Turing Test (Epstein, 1992). In fact, according to Epstein, such foibles may have helped a program win a recent variant of the Turing Test.
Reference: <author> Garey, M. R. and Johnson, D. S. </author> <title> (1979) Computers and Intractability, </title> <editor> W. H. </editor> <publisher> Freeman. </publisher>
Reference-contexts: While in a very different context complexity theory has become prominent in the study of artificial intelligence, (Bylander, 1991). 1.4 The Structure of this Paper This paper assumes basic familiarity with complexity theory as in <ref> (Garey and Johnson, 1979) </ref>. Also, throughout this paper we offer the same caveats regarding the size of constants hidden in asymptotic notation. That is, say the best we can do to solve some problem is to use an algorithm that requires 3n 100 steps for any input of size n. <p> Even for inputs of size five, that is n = 5, no modern day computer run the above algorithm to completion in the next handful of centuries. Therefore, such solutions are typically not considered in complexity theory <ref> (Garey and Johnson, 1979) </ref>. We assume this situation holds for problems in other complexity classes as well. <p> It is taken for granted in complexity theory <ref> (Garey and Johnson, 1979) </ref> that given an algorithm to solve a problem, this algorithm is known to correctly solve the problem at hand. That is, we have a proof of correctness for this algorithm. <p> In addition, given the appropriate algorithm we can create a certificate of polynomial size for the solution of . Generally problems in the class P are considered to be "practical" for solution by computer <ref> (Garey and Johnson, 1979) </ref>. Therefore, this paper takes all computers as capable of only solving problems in P. The class of computable problems N P is all decision problems for which there exists a non-deterministic polynomially bounded computing machine that solves a given instance of of polynomial size.
Reference: <author> Goldreich O., S. Micali and A. Wigderson: </author> <title> "Proofs that Yield Nothing but their Validity and a Methodology of Cryptographic Protocol Design," </title> <booktitle> Proceedings of the 27 th IEEE Foundations of Computer Science Conference, </booktitle> <pages> 174-187, </pages> <year> 1986. </year>
Reference-contexts: One communication tape goes from I to A and the other goes from A to I. These communication tapes are for the interactions. Next is an example of an interactive proof system for the Graph Isomorphism problem based on <ref> (Goldreich, Micali and Wigderson, 1986) </ref>. Here the agent, A, claims to have an algorithm for determining whether or not any two graphs are isomorphic.
Reference: <author> Goldwasser, S., S. Micali, and C. Rackoff, </author> <title> (1989) "The Knowledge Complexity of Interactive Proof Systems," </title> <journal> SIAM J. on Computing, </journal> <volume> Vol. 18, No. 1, </volume> <pages> 186-208. </pages>
Reference-contexts: Interactive proofs are probabilistic proofs of validity that are done by repeatedly and interactively checking consistency <ref> (Goldwasser, Micali, and Rackoff 1989) </ref>. An interactive proof system, if used properly, allows an exponential increase in the probability that a statment is valid in a polynomial number of interactions.
Reference: <author> Hartmanis, J., R. Chang, D. Ranjan, and P. Rohatgi, </author> <title> (1990) "On IP = PSPACE and Theorems with Narrow Proofs," in The Structural Complexity Column, </title> <journal> EACTS Bulletin, </journal> <volume> No. 41, </volume> <pages> 166-174. </pages>
Reference-contexts: All problems in N P have certificates of polynomial size which also can be generated as in figure 2. In some sense N P contains all theorems with proofs of polynomial size in the number of symbols of their theorem's statements, given a specific type of formal system <ref> (Hartmanis, et al., 1990) </ref>. Following (Hartmanis, et al., 1990) we say that a theorem is in N P if it has a certificate or proof of polynomial size and a non-deterministic machine can generate the certificate or proof in polynomial time. <p> In some sense N P contains all theorems with proofs of polynomial size in the number of symbols of their theorem's statements, given a specific type of formal system <ref> (Hartmanis, et al., 1990) </ref>. Following (Hartmanis, et al., 1990) we say that a theorem is in N P if it has a certificate or proof of polynomial size and a non-deterministic machine can generate the certificate or proof in polynomial time.
Reference: <author> Johnson, D. S. </author> <title> (1990) "A Catalog of Complexity Classes," Chapter 2 in Handbook of Theoretical Computer Science, Vol. A, Algorithms and Complexity, </title> <editor> V. Van Leeuwen|editor, </editor> <publisher> Elsevier, </publisher> <pages> 67-161. </pages>
Reference-contexts: Some of the theorems or problems in N EX PTime require proofs of exponential size relative to their theorem statements. Examples of problems in N EX PTime can be found in <ref> (Johnson, 1990) </ref>. The class PSpace seems to contain problems that require exponentially long proofs in the size of a theorem's statement in a given formal system.
Reference: <author> Rawlins, Gregory J. E. </author> <title> (1992) Compared To What ? Computer Science Press/W. </title> <editor> H. </editor> <publisher> Freeman. </publisher>
Reference-contexts: This formalization lies right at the foundations of mathematics, a place that has recently seen the convergence of proofs, computability theory, and complexity theory, see for example <ref> (Rawlins, 1992) </ref>. In addition, knowing Alan Turing's theoretical work in computability, this formalization constitutes an interesting twist for the Turing Test. This paper attempts to naturally extend the Turing Test towards making distinctions between humans and machines through their interactions.
Reference: <author> Searle, J. R. </author> <title> (1980) "Minds, Brains and Programs," </title> <journal> Behavorial and Brain Sciences, </journal> <volume> Vol. 3, No. 3, </volume> <pages> 417-457. </pages>
Reference: <author> Searle, J. R. </author> <title> (January 1990) "Is the Brain's Mind a Computer Program?" Scientific American, </title> <journal> Vol. </journal> <volume> 262, No. 1, </volume> <pages> 26-31. </pages>
Reference: <author> Shamir, A. </author> <title> (1992) "IP = PSPACE," </title> <journal> Journal of the ACM, </journal> <volume> Vol. 39, No. 4, </volume> <pages> 869-877. </pages>
Reference-contexts: An instance of a problem is verifiable in IP iff it is computable in PSpace. ' $ ' $ ' $ ' $ P PSpace N EX PTime Theorem 1 <ref> (Shamir, 1992) </ref> IP = PSpace The class of problems that can be interactively proved using two provers and one verifier is MIP, where the two provers are arbitrarily bounded machines (1-CMs).
Reference: <author> Turing, A. M. </author> <booktitle> (1950) "Computing Machinery and Intelligence," Mind, </booktitle> <volume> Vol. 59, No. 236, </volume> <pages> 433-460. 14 </pages>
Reference-contexts: 1 Introduction Circumventing a discussion of what it means to "think," Alan Turing proposed what has become the Turing Test <ref> (Turing, 1950) </ref>. This test has a human, the interrogator, alternately converse with another human and a computer, the agents. Starting without knowing which agent is the human or which is the computer, the interrogator's task is to distinguish the human and the computer through conversation by symbolic interaction.
References-found: 19

