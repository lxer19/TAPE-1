URL: http://www.cs.columbia.edu/~zkazi/webdiff/papers/aide.ps.gz
Refering-URL: http://www.cs.columbia.edu/~zkazi/webdiff/biblio.html
Root-URL: http://www.cs.columbia.edu
Title: Tracking and Viewing Changes on the Web  
Author: Fred Douglis Thomas Ball 
Note: AT&T Bell Laboratories 1996 USENIX Technical Conference.  
Abstract: We describe a set of tools that detect when WorldWide-Web pages have been modified and present the modifications visually to the user through marked-up HTML. The tools consist of three components: w3newer, which detects changes to pages; snapshot, which permits a user to store a copy of an arbitrary Web page and to compare any subsequent version of a page with the saved version; and HtmlDiff, which marks up HTML text to indicate how it has changed from a previous version. We refer to the tools collectively as the AT&T Internet Difference Engine (AIDE). This paper discusses several aspects of AIDE, with an emphasis on systems issues such as scalability, security, and error conditions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Mic Bowman et al. Harvest: </author> <title> A scalable, customizable discovery and access system. </title> <type> Technical Report CU-CS-732-94, </type> <institution> Dept. of Computer Science, University of Colorado-Boulder, </institution> <month> March </month> <year> 1995. </year>
Reference-contexts: Even if servers had a mechanism to notify all interested parties when a page has changed, immediate notification might not be worth the overhead. Instead, one could envision using something like the Harvest replication and caching services <ref> [1] </ref> to notify interested parties in a lazy fashion. A user who expresses an interest in a page, or a browser that is currently caching a page, could register an interest in the page with its local caching service. <p> Several issues still need to be addressed. In particular, many of the complications of AIDE could be avoided by better integration with W 3 browsers and servers. The increasing availability of distributed, hierarchical HTTP repositories such as Harvest <ref> [1] </ref> will also be both an opportunity and a challenge for scalable notification mechanisms and version archives. For more information on AIDE, see URL http://www.research.att.com/orgs/ssr/people/doug-lis/aide. Acknowledgments Robin Chen, Steve Crandall, John Ellson, P. Krish-nan, Mark Rajcok, Herman Rao, and the USENIX referees provided comments on earlier drafts of this paper.
Reference: [2] <author> K. Church. Char align: </author> <title> A program for aligning parallel texts at the character level. </title> <booktitle> In Association for Computational Linguistics, </booktitle> <pages> pages 1-8, </pages> <year> 1993. </year>
Reference-contexts: However, there is much closely related work on heuristics for parallel document alignment and similarity measures between documents <ref> [2] </ref> that we benefit from. Line-based comparison utilities such as UNIX diff [10] clearly are ill-suited to the comparison of structured documents such as HTML. Most modern word processing programs have a revision mode that track additions and deletions on-line as an author modifies a document, graphically annotating the differences.
Reference: [3] <author> Ward Cunningham. WikiWikiWeb. </author> <note> http://c2.com/cgi-bin/wiki. </note>
Reference-contexts: While AIDE can help arbitrary users track pages of interest, it can be of particular use in a collaborative environment. One example of a collaborative environment on the W 3 is the WikiWikiWeb <ref> [3] </ref>, which allows multiple users to edit the content of documents dynamically. There is a RecentChanges page that sorts documents by modification date. Typically content is added to the end of a page and it is not difficult to determine visually what changes occurred since the last visit.
Reference: [4] <author> B. B. Cutter III. w3new. </author> <note> http://www.stuff.com/bcutter/programs/w3new/w3new.html. </note>
Reference-contexts: Several other tools read a user's hotlist and generate a report, in HTML, of recently changed pages. Examples include webwatch [16], a product for Windows; w3new <ref> [4] </ref>, a public-domain Perl script that runs on UNIX; and Katipo [13], which runs on the Macintosh. Another similar tool, URL-minder [19], runs as a service on the W 3 itself and sends email when a page changes.
Reference: [5] <author> Roome W. D. 3DFS: </author> <title> A time-oriented file server. </title> <booktitle> In Proceedings of the USENIX 1992 Winter Conference, </booktitle> <pages> pages 405-418, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: A CGI interface to RCS allows a user to request a URL at a particular date, from anywhere on the W 3 . This is similar in spirit to the time travel capability of file systems such as 3DFS <ref> [5] </ref> that transparently allow access to files at arbitrary dates.
Reference: [6] <author> David Goldberg, David Nichols, Brian M Oki, and Douglas Terry. </author> <title> Using collaborative filtering to weave an information tapestry. </title> <journal> Communications of the ACM, </journal> <volume> 35(12) </volume> <pages> 61-70, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: Merely sorting URLs by most recent modification dates is not satisfactory when the number of URLs grows into the hundreds. Instead, we are moving toward a user-specified prioritization of URLs along the lines of the Tapestry system, which prioritizes email and NetNews automatically <ref> [6] </ref>. So far, disk usage has not been a problem. There are over 500 URLs archived (many of these are for fixed collections of pages as described below in Section 8.2), and the archive uses under 8 Mbytes of disk storage (an average of 14.3 Kbytes/URL).
Reference: [7] <author> James S. Gwertzman and Margo Seltzer. </author> <title> The case for geographical push-caching. </title> <booktitle> In Proceedings of the Fifth Workshop in Hot Topics in Operating Systems (HOTOS-V), </booktitle> <pages> pages 51-55, </pages> <address> Orcas Island, WA, </address> <month> May </month> <year> 1995. </year> <note> IEEE. </note>
Reference-contexts: Either way, there would not be a large number of clients polling each interesting HTTP server. Moving intelligence about HTTP caching to the server has been proposed by Gwertzman and Seltzer <ref> [7] </ref> and others. One could also envision integrating the functionality of AIDE into file systems. Tools that can take actions when arbitrary files change are not widely available, though they do exist [15].
Reference: [8] <author> D. S. Hirschberg. </author> <title> Algorithms for the longest common subsequence problem. </title> <journal> Journal of the ACM, </journal> <volume> 24(4) </volume> <pages> 664-675, </pages> <month> October </month> <year> 1977. </year>
Reference-contexts: In the paragraph-to-list example, the comparison would show no change to content, but a change to the formatting. We apply Hirshberg's solution to the longest common subsequence (LCS) problem <ref> [8] </ref> (with several speed optimizations) to compare HTML documents. This is the well-known comparison algorithm used by the UNIX diff utility [10]. The LCS problem is to find a (not necessarily contiguous) common subsequence of two sequences of tokens that has the longest length (or greatest weight).
Reference: [9] <author> J. Howard et al. </author> <title> Scale and performance in a distributed file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 51-81, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: Dilbert is never checked because it will always be different. 3.1 System Issues Cache Consistency Determining when HTTP pages have changed is analogous to caching a file in a distributed file system and determining when the file has been modified. While file systems such as the Andrew File System <ref> [9] </ref> and Sprite [12] provide guarantees of cache consistency by issuing call-backs to hosts with invalid copies, HTTP access is closer to the traditional NFS approach, in which clients check back with servers periodically for each file they access.
Reference: [10] <author> J. W. Hunt and M. D. McIlroy. </author> <title> An algorithm for differential file comparison. </title> <type> Technical Report Computing Science TR #41, </type> <institution> Bell Laboratories, </institution> <address> Murray Hill, N.J., </address> <year> 1975. </year>
Reference-contexts: However, there is much closely related work on heuristics for parallel document alignment and similarity measures between documents [2] that we benefit from. Line-based comparison utilities such as UNIX diff <ref> [10] </ref> clearly are ill-suited to the comparison of structured documents such as HTML. Most modern word processing programs have a revision mode that track additions and deletions on-line as an author modifies a document, graphically annotating the differences. <p> We apply Hirshberg's solution to the longest common subsequence (LCS) problem [8] (with several speed optimizations) to compare HTML documents. This is the well-known comparison algorithm used by the UNIX diff utility <ref> [10] </ref>. The LCS problem is to find a (not necessarily contiguous) common subsequence of two sequences of tokens that has the longest length (or greatest weight). Tokens not in the LCS represent changes. In UNIX diff, a token is a textual line and each line has weight equal to 1.
Reference: [11] <author> Java. </author> <note> http://www.javasoft.com/. </note>
Reference-contexts: CGI is a problem because there is no way for snapshot to interact with the user and the user's browser, other than by sending HTML output. (The system does not currently assume the ability of a browser to support Java <ref> [11] </ref>, although moving to Java in the future is possible and might help address some of these issues.) When a CGI script is invoked, httpd sets up a default timeout, and if the script does not generate output for a full timeout interval, httpd will return an error to the browser.
Reference: [12] <author> M. Nelson, B. Welch, and J. Ousterhout. </author> <title> Caching in the Sprite network file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 134-154, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: While file systems such as the Andrew File System [9] and Sprite <ref> [12] </ref> provide guarantees of cache consistency by issuing call-backs to hosts with invalid copies, HTTP access is closer to the traditional NFS approach, in which clients check back with servers periodically for each file they access.
Reference: [13] <author> M. Newbery. Katipo. </author> <note> http://www.vuw.ac.nz/newbery/Katipo.html. </note>
Reference-contexts: Several other tools read a user's hotlist and generate a report, in HTML, of recently changed pages. Examples include webwatch [16], a product for Windows; w3new [4], a public-domain Perl script that runs on UNIX; and Katipo <ref> [13] </ref>, which runs on the Macintosh. Another similar tool, URL-minder [19], runs as a service on the W 3 itself and sends email when a page changes.
Reference: [14] <institution> A standard for robot exclusion. </institution> <note> http://web.nexor.co.uk/mak/doc/robots/norobots.html. </note>
Reference-contexts: Its site may disallow retrieval of this URL by robots, meaning that the administrator for its site has created a special file, robots.txt, and requested that automated programs such as web crawlers not retrieve the URL. Currently, programs only voluntarily follow the robot exclusion protocol <ref> [14] </ref>, the convention that defines the use of robots.txt. Although w3newer currently obeys this protocol, it is not clear that it should, at least for URLs the user would other wise access directly periodically.
Reference: [15] <author> David S. Rosenblum and Balachander Krishnamurthy. </author> <title> Generalized event-action handling. In Balachander Krishnamurthy, editor, Practical Reusable UNIX Software, chapter 9. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: Moving intelligence about HTTP caching to the server has been proposed by Gwertzman and Seltzer [7] and others. One could also envision integrating the functionality of AIDE into file systems. Tools that can take actions when arbitrary files change are not widely available, though they do exist <ref> [15] </ref>. Users might like to have a unified report of new files and W 3 pages, and w3newer supports the file: specification and can find out if a local file has changed. However, snapshot has no way to access a file on the user's (remote) file system.
Reference: [16] <editor> Specter, </editor> <publisher> Inc. </publisher> <address> Webwatch. http://www.specter.com/users/janos/webwatch/index.html. </address>
Reference-contexts: Smart Bookmarks have the advantage of being integrated directly with a user's hotlist, making a visual indication of what has changed available without resorting to a separate page. Several other tools read a user's hotlist and generate a report, in HTML, of recently changed pages. Examples include webwatch <ref> [16] </ref>, a product for Windows; w3new [4], a public-domain Perl script that runs on UNIX; and Katipo [13], which runs on the Macintosh. Another similar tool, URL-minder [19], runs as a service on the W 3 itself and sends email when a page changes.
Reference: [17] <author> Sun Microsystems. </author> <title> The HotJava Browser: </title> <note> A White Paper. Available as http://java.sun.com/1.0alpha3/doc/overview/hot-java/browser-whitepaper.ps. </note>
Reference-contexts: Moving functionality into the browser would allow individual users to take snapshots of files that are not already under the control of a versioning system such as RCS; this might be an appropriate use of a browser with client-side execution, such as HotJava <ref> [17] </ref> or recent versions of Netscape. Douglis and Ball 1996 USENIX Technical Conference Tracking and Viewing Changes on the Web 5 Error Conditions When a periodic task checks the status of a large number of URLs, a number of things can go wrong.
Reference: [18] <author> W. Tichy. RCS: </author> <title> a system for version control. </title> <journal> SoftwarePractice & Experience, </journal> <volume> 15(7) </volume> <pages> 637-654, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: which runs on an Internet server and checks pages with an arbitrary frequency that is guaranteed to be at least as often as some threshold, such as a week. (URL-minder's implementation is hidden behind a CGI interface.) 2.2 Version Repositories As discussed below, we use the Revision Control System (RCS) <ref> [18] </ref> to compactly maintain a history of documents, addressed by their URLs. A CGI interface to RCS allows a user to request a URL at a particular date, from anywhere on the W 3 . <p> However, if a server runs HtmlDiff and some perl scripts, it can provide a direct version-control interface and avoid the need to store copies of its HTML documents elsewhere. The perl scripts we have written provide an interface to RCS <ref> [18] </ref>. A CGI script (/cgi-bin/rlog) converts the output of rlog into HTML, showing the user a history of the document with links to view any specific version or to see the differences between two versions.
Reference: [19] <author> Url-minder. </author> <note> http://www.netmind.com/URL-minder/URL-minder.html. </note>
Reference-contexts: Several other tools read a user's hotlist and generate a report, in HTML, of recently changed pages. Examples include webwatch [16], a product for Windows; w3new [4], a public-domain Perl script that runs on UNIX; and Katipo [13], which runs on the Macintosh. Another similar tool, URL-minder <ref> [19] </ref>, runs as a service on the W 3 itself and sends email when a page changes. Unlike the tools that run on the user's host and use the hotlist to determine which URLs to check, URL-minder acts on URLs provided explicitly by a user via an HTML form.

References-found: 19

