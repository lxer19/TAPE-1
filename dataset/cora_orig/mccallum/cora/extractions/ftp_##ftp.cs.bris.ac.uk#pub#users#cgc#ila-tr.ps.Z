URL: ftp://ftp.cs.bris.ac.uk/pub/users/cgc/ila-tr.ps.Z
Refering-URL: http://www.cs.bris.ac.uk/~cgc/papers.ml.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: ILA: Combining Inductive Learning with Prior Knowledge and Reasoning  
Author: Christophe Giraud-Carrier and Tony Martinez 
Abstract: Much effort has been devoted to understanding learning and reasoning in artificial intelligence. However, very few models attempt to integrate these two complementary processes. Rather, there is a vast body of research in machine learning, often focusing on inductive learning from examples, quite isolated from the work on reasoning in artificial intelligence. Though these two processes may be different, they are very much interrelated. The ability to reason about a domain of knowledge is often based on rules about that domain, that must be learned somehow. And the ability to reason can often be used to acquire new knowledge, or learn. This paper introduces an Incremental Learning Algorithm (ILA) that attempts to combine inductive learning with prior knowledge and reasoning. ILA has many important characteristics useful for such a combination, including: 1) incremental, self-organizing learning, 2) nonuniform learning, 3) inherent non-monotonicity, 4) extensional and intensional capabilities, and 5) low order polynomial complexity. The paper describes ILA, gives simulation results for several applications, and discusses each of the above characteristics in detail. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Aha, D.W. </author> <year> (1991). </year> <title> A Study of Instance-Based Algorithms for Supervised Learning Tasks. </title> <type> Technical Report, </type> <institution> University of California, Irvine. </institution>
Reference-contexts: Note that D does not define a metric over the input space. However, it naturally accounts for the presence of don't-cares and for missing attributes in input vectors. Several alternatives for treating don't-know (or missing) attributes are in <ref> [1] </ref>. 2.3. ILA - Algorithmic Details ILA's learning consists of two phases: execution and adaptation. In the execution phase, the training pair is presented to the network and a winning node is identified.
Reference: [2] <author> Aha, D.W., Kibler, D., and Albert, M.K. </author> <year> (1991). </year> <title> Instance-Based Learning Algorithms. </title> <journal> Machine Learning, </journal> <volume> 6, </volume> <pages> 37-66. </pages>
Reference-contexts: ILA's reasoning power is more limited, but the system is able to learn from examples. ILA's inductive learning is similar to NGE [20], but ILA uses hyperplanes rather than hyperrectangles as generalized exemplars. ILA also bears some resemblance with IBL <ref> [2] </ref>, in the similarity measure used. However, ILA also incorporates prior knowledge and must provide mechanisms to support reasoning. Finally, if no rules are induced from the examples in learning, then ILA degenerates to a simplified form of MBR [21]. <p> Going further, one may consider extending ILA with some of the well established mechanisms of MBR to further improve ILA's performance in situations where only few rules are available. 10 The distance used by ILA is very similar to IBL's metric <ref> [2] </ref>. ILA's distance measure also deals with don't-care attributes (which are nonexistent in instance-based learners), and treats missing attributes somewhat differently. Where IBL considers them to be complete mismatch, ILA chooses a more middle-ground approach that may better capture the inherent notion of missing (or "don't-know") attributes. <p> The results given here were obtained with no precepts given a priori. That is, the rules used in execution/reasoning (reflected in PA) are all created during learning. These results compare favorably with results reported for other inductive learning algorithms (see <ref> [2, 3, 18, 25] </ref>). Note that LED is a noisy application, for which the Bayesian optimal is 74%. ILA handles the noise well, both by achieving high predictive accuracy, and by constructing a significantly small network.
Reference: [3] <author> Barker, J.C. </author> <year> (1994). </year> <title> Eclectic Machine Learning. </title> <type> Ph.D. Dissertation, </type> <institution> Brigham Young University, Department of Computer Science, Provo, UT. </institution>
Reference-contexts: The results given here were obtained with no precepts given a priori. That is, the rules used in execution/reasoning (reflected in PA) are all created during learning. These results compare favorably with results reported for other inductive learning algorithms (see <ref> [2, 3, 18, 25] </ref>). Note that LED is a noisy application, for which the Bayesian optimal is 74%. ILA handles the noise well, both by achieving high predictive accuracy, and by constructing a significantly small network.
Reference: [4] <author> Brewka, G. </author> <year> (1991). </year> <title> Nonmonotonic Reasoning: Logical Foundations of Commonsense. </title> <publisher> Cambridge University Press. </publisher>
Reference-contexts: The new piece of knowledge you gained invalidated the truth of the previously accepted fact. Such patterns of reasoning, often equated with commonsense reasoning by logicians (see, for example <ref> [4, 13] </ref>), are pervasive in the way humans deal with the inherent uncertainty and incompleteness of the world (or their representation thereof). The development of systems that effectively handle classical commonsense protocols, such as inheritance, is a first step in overcoming the brittleness bottleneck. Non-monotonicity is a consequence of incrementality.
Reference: [5] <author> Buntine, W.L. </author> <year> (1990). </year> <title> A Theory of Learning Classification Rules. </title> <type> Ph.D. Dissertation, </type> <institution> University of Technology, School of Computing Science, Sydney. </institution>
Reference-contexts: As a first attempt (and currently the only viable one), this prior knowledge can be obtained from an expert or teacher. It may be given to the system interactively or a priori, and can take many different forms (see, for example <ref> [5] </ref>). Once a learning system has been trained, it can use its knowledge to generalize on new situations. Generalization can be viewed as a limited form of reasoning since it uses existing knowledge to infer new knowledge.
Reference: [6] <author> Elman, J.L. </author> <year> (1991). </year> <title> Incremental learning, or The importance of starting small. </title> <type> CRL Technical Report 9101, </type> <institution> La Jolla, CA: University of California, </institution> <address> San Diego, </address> <note> Center for Research in Language. </note>
Reference-contexts: Rather, new pieces of information become available over time, and the knowledge base is constantly revised (i.e., evolves) based on the newly acquired information. In the context of learning grammar with a recurrent network, empirical evidence is given in <ref> [6] </ref> that the "network fails to learn the task when the entire data set is presented all at once, but succeeds when the data are presented incrementally [with an easy to hard ordering]." Humans never cease to learn, thus minimizing the impact of poor or atypical, temporary learning environments (i.e., "bad" <p> Foreign-language students first learn English rules (e.g., the plural of a noun is formed by tagging an s to the end of the singular form of that noun), and are then exposed to exceptions (e.g., geese instead of gooses, mice instead of mouses, etc.). It is suggested in <ref> [6] </ref> that this nonuniformity of knowledge in learning may actually be the result of an early handicap (e.g., limited memory and attention span characteristic of children). In other words, it may be that the learning system itself evolves over time, rather than the knowledge it is presented.
Reference: [7] <author> Giraud-Carrier, C., and Martinez, T.R. </author> <year> (1993). </year> <title> Using Precepts to Augment Training Set Learning. </title> <booktitle> In Proceedings of the 1993 International Conference on Artificial Neural Networks and Expert Systems (ANNES'93), </booktitle> <pages> 46-51. </pages>
Reference-contexts: In many cases, useful information is indeed available as, for example, an instantiation of domain knowledge or commonsense. Though such knowledge is not necessarily correct, it can beneficially be used as a learning bias to supplement inductive mechanisms (see, for example <ref> [7] </ref>). As a first attempt (and currently the only viable one), this prior knowledge can be obtained from an expert or teacher. It may be given to the system interactively or a priori, and can take many different forms (see, for example [5]). <p> Both learning and execution require only simple gather and broadcast mechanisms. Hence, ILA makes use of inherent parallelism in execution, and exhibits low-order polynomial complexity. Note that the use of a binary tree architecture is for purposes of consistency with previous models <ref> [7, 8] </ref>, and for the support of future extensions. For ILA, it is only necessary for the efficient identification of the node representing the best match with the training situation. 3 2.2. <p> Whatever the case, the ability to use rules and examples increases learning speed by pruning and constraining the search for generalizations in the input space, reduces memory requirements, and improves overall predictive accuracy (see, for example <ref> [7] </ref>). In practical situations, the rules can be viewed as some instantiation of domain knowledge available a priori and given to the system. They serve as learning biases that supplement the inductive mechanisms to increase the probability that known rules are available to the system in reasoning.
Reference: [8] <author> Giraud-Carrier, C., and Martinez, T.R. </author> <year> (1994a). </year> <title> An Incremental Learning Model for Commonsense Reasoning. </title> <booktitle> In Proceedings of the Seventh International Symposium on Artificial Intelligence (ISAI'94), </booktitle> <pages> 134-141. </pages>
Reference-contexts: Both learning and execution require only simple gather and broadcast mechanisms. Hence, ILA makes use of inherent parallelism in execution, and exhibits low-order polynomial complexity. Note that the use of a binary tree architecture is for purposes of consistency with previous models <ref> [7, 8] </ref>, and for the support of future extensions. For ILA, it is only necessary for the efficient identification of the node representing the best match with the training situation. 3 2.2. <p> Note that if the output of some of the new patterns were known, then ILA could continue to learn from them over time by simply executing the learning phase. 2.5. Comparison with Other Work ILA emerged as a result of extensions to PDL2 <ref> [8] </ref>. ILA does preserve the combination of rule-based and similarity-based reasoning mechanisms of PDL2. In ILA however, there is a closer match between the learning and the execution algorithms, and modifications to the knowledge base are confined to the winning node rather than extended to all nodes. <p> Because of their symbolic nature, the problems are first translated into their corresponding attribute-value language representation, where each predicate gives rise to a Boolean attribute, each class of objects gives rise to a multi-valued attribute, and each implication (or default) gives rise to a precept (see <ref> [8] </ref> for details). <p> Such is not always the case. Indeed, one may wish to have the flexibility of entering rules at any time during learning and expect the same outcome, regardless of the chosen ordering. This is a complex problem. It is partially solved by PDL2 <ref> [8] </ref> and ILA, as can be seen in the symmetry inherent to the algorithms. However, the systems remains sensitive to the ordering. One can argue that for large (and rich) enough training sets, the effects of ordering become more limited, as the current representation of the system eventually matches reality.
Reference: [9] <author> Giraud-Carrier, C., and Martinez, T.R. </author> <year> (1994b). </year> <title> An Efficient Metric for Heterogeneous Inductive Learning Applications in the Attribute-Value Language. </title> <booktitle> In Proceedings of the Third Golden West International Conference on Intelligent Systems (GWIC'94). </booktitle> <publisher> In press. </publisher>
Reference-contexts: The distance, computed from x to y, is defined as follows. where range (i) is the range of values of attribute i D is an extension of the heterogeneous distance measure proposed in <ref> [9] </ref>. A thorough treatment (motivation and justification) of some of the issues leading to the above definition is found in [9]. Note that D does not define a metric over the input space. However, it naturally accounts for the presence of don't-cares and for missing attributes in input vectors. <p> from x to y, is defined as follows. where range (i) is the range of values of attribute i D is an extension of the heterogeneous distance measure proposed in <ref> [9] </ref>. A thorough treatment (motivation and justification) of some of the issues leading to the above definition is found in [9]. Note that D does not define a metric over the input space. However, it naturally accounts for the presence of don't-cares and for missing attributes in input vectors. Several alternatives for treating don't-know (or missing) attributes are in [1]. 2.3. <p> It follows that ILA can deal with continuous inputs directly, without having to first discretize them. Moreover, ILA's measure preserves the notion of order while PDL2's does not, thus resulting in ILA's improved performance on datasets containing ordered data (see <ref> [9] </ref>). ILA and PDL2 exhibit similar performance in actual learning time, but ILA results in better predictive accuracy on average. ILA bears some similarity with NGE [20] as well.
Reference: [10] <author> Kaelbling, </author> <title> L.P. (1993). Reinforcement Learning. MLnet Workshop "Learning in Autonomous Agents," </title> <type> invited talk. [11] le Cun, Yann. </type> <year> (1989). </year> <title> Generalization and Network Design Strategies. </title> <editor> In Pfeifer, R., Schreter, Z., Fogelman-Souli, F., and Steels, L. (Eds.). </editor> <booktitle> Connectionism in Perspective. </booktitle> <publisher> Elsevier Science Publishers B.V. </publisher>
Reference-contexts: It is suggested that the ability to use either and to combine them offers the maximum flexibility. This combination has also been recognized as necessary in the design of practical embedded (autonomous) agents <ref> [10] </ref>. 4.6. Low Order Polynomial Complexity ILA has low order polynomial complexity in the number of training pairs.
Reference: [12] <author> Lifschitz, V. </author> <year> (1988). </year> <title> Benchmark Problems for Formal Nonmonotonic Reasoning. </title> <booktitle> In Proceedings of the 2nd International Workshop on Non-Monotonic Reasoning, </booktitle> <volume> LNCS 346, </volume> <pages> 202-219. 17 </pages>
Reference-contexts: This combination decreases the system's susceptibility to brittleness. It has also been shown to effectively account for many commonsense protocols, such as inheritance (see [22], Appendix A). Several problems, from the benchmark of nonmonotonic reasoning problems described in <ref> [12] </ref>, were presented to ILA.
Reference: [13] <author> Lukaszewicz, W. </author> <year> (1990). </year> <title> Non-Monotonic Reasoning: Formalization of Commonsense Reasoning. </title> <publisher> Ellis Horwood Limited. </publisher>
Reference-contexts: The new piece of knowledge you gained invalidated the truth of the previously accepted fact. Such patterns of reasoning, often equated with commonsense reasoning by logicians (see, for example <ref> [4, 13] </ref>), are pervasive in the way humans deal with the inherent uncertainty and incompleteness of the world (or their representation thereof). The development of systems that effectively handle classical commonsense protocols, such as inheritance, is a first step in overcoming the brittleness bottleneck. Non-monotonicity is a consequence of incrementality.
Reference: [14] <author> Martinez, T.R., Hughes, B., and Campbell, D.M. </author> <year> (1994). </year> <title> Priority ASOCS. </title> <journal> Journal of Artificial Neural Networks, </journal> <volume> Vol. 1, No. 3, </volume> <pages> 403-429. </pages>
Reference: [15] <author> Michalski, R.S. </author> <year> (1983). </year> <title> A Theory and Methodology of Inductive Learning. </title> <journal> Artificial Intelligence, </journal> <volume> 20, </volume> <pages> 111-161. </pages>
Reference-contexts: ILA induces rules by using the dropping condition generalization rule <ref> [15] </ref>. In the context of ILA's attribute-value representation language, it consists of setting to don't-care the value of one or more attributes in a pair. Only one attribute at a time may be set to don't-care. The decision of which attribute and when is made as follows.
Reference: [16] <author> Mitchell, T.M. </author> <year> (1980). </year> <title> The Need for Biases in Learning Generalizations. </title> <type> CBM-TR 5-110, </type> <institution> Rutgers University, </institution> <address> New Brunswick, NJ. </address>
Reference-contexts: In most inductive learning systems, human interaction is typically limited to the gathering and compilation of examples (i.e., instances of the application to be learned). As research on autonomous agents continues, this process itself may eventually become automated. However, the strong knowledge principle [24], and early work on bias <ref> [16] </ref> suggest that examples should be augmented by prior knowledge. Human learning, for example, is not the sole result of exposure to random examples. Rather, built-in mechanisms (e.g., pain), and social structures (e.g., the family, school) account for much of humans ability to efficiently learn complex problems.
Reference: [17] <author> Murphy, P.M., and Aha, D.W. </author> <year> (1992). </year> <title> UCI Repository of machine learning databases. </title> <address> Irvine, CA: </address> <institution> University of California, Department of Information and Computer Science. </institution>
Reference-contexts: Inductive Learning and Predictive Accuracy Several datasets from <ref> [17] </ref> were chosen. The selected applications and their essential attributes are given in Table 1. They represent a wide variety of situations. Note that except for the soybeansmall dataset, none of the continuous attributes are discretized.
Reference: [18] <author> Quinlan, J.R. </author> <year> (1986). </year> <title> Inductive Learning of Decision Trees. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 81-106. </pages>
Reference-contexts: The results given here were obtained with no precepts given a priori. That is, the rules used in execution/reasoning (reflected in PA) are all created during learning. These results compare favorably with results reported for other inductive learning algorithms (see <ref> [2, 3, 18, 25] </ref>). Note that LED is a noisy application, for which the Bayesian optimal is 74%. ILA handles the noise well, both by achieving high predictive accuracy, and by constructing a significantly small network.
Reference: [19] <author> Reiter, R., and Griscuolo, G. </author> <year> (1981). </year> <title> On Interacting Defaults. </title> <booktitle> In Proceedings of the 7th International Joint Conference on Artificial Intelligence, </booktitle> <pages> 270-276. </pages>
Reference-contexts: Essentially, it is limited to "one-step" forward plausible inferences. Also, there is no notion of time in ILA, so that reasoning about actions is not possible. ILA was also tested on its extensional abilities on two particular problems. The first is the Nixon diamond <ref> [19] </ref>. ILA solves it both intensionally (i.e., default rules and priorities given a priori), and extensionally from a set of examples. <p> In particular, it allows the system to retain the self-adaptivity inherent in human learning, while not having to unnecessarily suffer from poor or atypical learning environments. One useful application of the above is the case of conflicting defaults, such as the famous Nixon Diamond <ref> [19] </ref>. If the extensional and intensional approaches are combined, greater flexibility can be achieved.
Reference: [20] <author> Salzberg, S. </author> <year> (1991). </year> <title> A Nearest Hyperrectangle Learning Method. </title> <journal> Machine Learning, </journal> <volume> 6, </volume> <pages> 277-309. </pages>
Reference-contexts: However, this model only deals with representational issues, and not learning. ILA's reasoning power is more limited, but the system is able to learn from examples. ILA's inductive learning is similar to NGE <ref> [20] </ref>, but ILA uses hyperplanes rather than hyperrectangles as generalized exemplars. ILA also bears some resemblance with IBL [2], in the similarity measure used. However, ILA also incorporates prior knowledge and must provide mechanisms to support reasoning. <p> ILA and PDL2 exhibit similar performance in actual learning time, but ILA results in better predictive accuracy on average. ILA bears some similarity with NGE <ref> [20] </ref> as well. However, because ILA generalizes only by setting some attribute (s) to don't-care, the produced generalizations, or generalized exemplars [20], are hyperplanes, rather than hyperrectangles, in the input space. Hence, ILA can be viewed as a nearest-hyperplane learning algorithm. <p> ILA and PDL2 exhibit similar performance in actual learning time, but ILA results in better predictive accuracy on average. ILA bears some similarity with NGE <ref> [20] </ref> as well. However, because ILA generalizes only by setting some attribute (s) to don't-care, the produced generalizations, or generalized exemplars [20], are hyperplanes, rather than hyperrectangles, in the input space. Hence, ILA can be viewed as a nearest-hyperplane learning algorithm. Many of the mechanisms are similar, but ILA also allows static and dynamic priorities to break ties in equidistant generalizations.
Reference: [21] <author> Stanfill, C., and Waltz, D. </author> <year> (1986). </year> <title> Toward Memory-Based Reasoning. </title> <journal> Communications of the ACM, </journal> <volume> Vol. 29, No. 12, </volume> <pages> 1213-1228. </pages>
Reference-contexts: ILA also bears some resemblance with IBL [2], in the similarity measure used. However, ILA also incorporates prior knowledge and must provide mechanisms to support reasoning. Finally, if no rules are induced from the examples in learning, then ILA degenerates to a simplified form of MBR <ref> [21] </ref>. Section 2 introduces ILA, presents an example, and gives a comparison of ILA with other related work. Section 3 presents several simulation results on many real-world datasets. <p> Moreover, where it was shown that overlapping hyperrectangles may hinder performance [25], ILA allows overlapping hyperplanes for purposes of dealing with conflicting defaults. In the case that no generalizations are found, ILA degenerates into a restricted form of MBR <ref> [21] </ref>. This allows ILA to perform well, even with simple (and possibly weak) generalization mechanisms (see for example the soybeansmall dataset in Section 3).
Reference: [22] <author> Sun, R. </author> <year> (1992). </year> <title> A Connectionist Model for Commonsense Reasoning Incorporating Rules and Similarities. </title> <journal> Knowledge Acquisition, </journal> <volume> 4, </volume> <pages> 293-321. </pages>
Reference-contexts: The reasoning power of such systems is then characterized as (one-step forward) default reasoning. When such default, or rule-based, reasoning is enhanced with similarity-based reasoning (when no default applies), the system can perform useful plausible inferences, that account for several important commonsense protocols (see <ref> [22] </ref>, Appendix A). 2 This paper proposes an incremental learning algorithm (ILA) that augments inductive learning from examples with prior knowledge in the form of precepts (see Section 2.2), and supports many useful characteristics that can be exploited to combine learning and reasoning. <p> The model described in <ref> [22, 23] </ref> is a connectionist approach to implementing the form of reasoning discussed above (with forward chaining). However, this model only deals with representational issues, and not learning. ILA's reasoning power is more limited, but the system is able to learn from examples. <p> Where IBL considers them to be complete mismatch, ILA chooses a more middle-ground approach that may better capture the inherent notion of missing (or "don't-know") attributes. Finally, ILA's combination of default (i.e., rule-based) reasoning and similarity-based reasoning follows CONSYDERR <ref> [22] </ref>. However, CONSYDERR is strictly concerned with a connectionist approach to concept representation and (commonsense) reasoning. The resulting model is elegant, but it does not address the problem of learning. 3. <p> Once the rules have been learned, the system can be used to reason about them. Essentially, ILA's execution combines a form of default reasoning with similarity-based reasoning, as in <ref> [22] </ref>. This combination decreases the system's susceptibility to brittleness. It has also been shown to effectively account for many commonsense protocols, such as inheritance (see [22], Appendix A). Several problems, from the benchmark of nonmonotonic reasoning problems described in [12], were presented to ILA. <p> Essentially, ILA's execution combines a form of default reasoning with similarity-based reasoning, as in <ref> [22] </ref>. This combination decreases the system's susceptibility to brittleness. It has also been shown to effectively account for many commonsense protocols, such as inheritance (see [22], Appendix A). Several problems, from the benchmark of nonmonotonic reasoning problems described in [12], were presented to ILA.
Reference: [23] <author> Sun, R. </author> <year> (1993). </year> <title> An Efficient Feature-Based Connectionist Inheritance Scheme. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> Vol. 23, No. 2, </volume> <pages> 512-522. </pages>
Reference-contexts: The model described in <ref> [22, 23] </ref> is a connectionist approach to implementing the form of reasoning discussed above (with forward chaining). However, this model only deals with representational issues, and not learning. ILA's reasoning power is more limited, but the system is able to learn from examples.
Reference: [24] <author> Waterman, D.A. </author> <year> (1986). </year> <title> A Guide to Expert Systems. </title> <publisher> Addison Wesley. </publisher>
Reference-contexts: In most inductive learning systems, human interaction is typically limited to the gathering and compilation of examples (i.e., instances of the application to be learned). As research on autonomous agents continues, this process itself may eventually become automated. However, the strong knowledge principle <ref> [24] </ref>, and early work on bias [16] suggest that examples should be augmented by prior knowledge. Human learning, for example, is not the sole result of exposure to random examples.
Reference: [25] <author> Wettschereck, D., and Dietterich, T.G. </author> <year> (1994). </year> <title> An Experimental Comparison of the Nearest-Neighbor and Nearest-Hyperrectangle Algorithms. </title> <note> To appear in Machine Learning. </note>
Reference-contexts: Hence, ILA can be viewed as a nearest-hyperplane learning algorithm. Many of the mechanisms are similar, but ILA also allows static and dynamic priorities to break ties in equidistant generalizations. Moreover, where it was shown that overlapping hyperrectangles may hinder performance <ref> [25] </ref>, ILA allows overlapping hyperplanes for purposes of dealing with conflicting defaults. In the case that no generalizations are found, ILA degenerates into a restricted form of MBR [21]. <p> The results given here were obtained with no precepts given a priori. That is, the rules used in execution/reasoning (reflected in PA) are all created during learning. These results compare favorably with results reported for other inductive learning algorithms (see <ref> [2, 3, 18, 25] </ref>). Note that LED is a noisy application, for which the Bayesian optimal is 74%. ILA handles the noise well, both by achieving high predictive accuracy, and by constructing a significantly small network.
References-found: 24

