URL: http://www.cse.psu.edu/~barlow/ulv.ps
Refering-URL: http://www.cse.psu.edu/~barlow/papers.html
Root-URL: http://www.cse.psu.edu
Title: AN ALGORITHM AND A STABILITY THEORY FOR DOWNDATING THE ULV DECOMPOSITION V T where U
Author: JESSE L. BARLOW, PETER A. YOON, and HONGYUAN ZHA 
Keyword: Key words: Orthogonal decomposition, downdating, error analysis, subspaces  
Address: Park PA, 16802-6106, USA  
Affiliation: Department of Computer Science and Engineering, The Pennsylvania State University University  
Note: BIT  A U C  AMS subject classifications: (Primary) 65F20,65G05 (Secondary)  
Email: email: barlow@cse.psu.edu, payoon@cse.psu.edu, zha@cse.psu.edu  
Date: 35 (1995), 000-000.  
Web: 65F15.  
Abstract: which indicates a separation between two subspaces by the size of its columns. These subspaces are denoted by V = (V 1 ; V 2 ), where the columns of C are partitioned conformally into C = (C 1 ; C 2 ) with k C 2 k F * . Here * is some tolerance. In recent years, this has been called the ULVD. If the matrix A results from statistical observations, it is often desired to remove old observations, thus deleting a row from A and its ULVD. In matrix terms, this is called a downdate. A downdating algorithm is proposed that preserves the structure in the downdated matrix C to the extent possible. Strong stability results are proven for these algorithms based upon a new perturbation theory. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J.L. Barlow. </author> <title> Stability analysis of the G-algorithm and a note on its application to sparse least squares problems. </title> <journal> BIT, </journal> <volume> 25 </volume> <pages> 507-520, </pages> <year> 1985. </year>
Reference-contexts: Theorem 4.1 is proven in Appendix A of [4]. This theorem is somewhat similar to error bounds on orthogonal factorization of matrices with disproportionate rows <ref> [1, 3] </ref>. The following corollary gives the error bounds that we get if we use no structure of the problem (2) or the resulting matrix (6).
Reference: 2. <author> J.L. Barlow and J.W. Demmel. </author> <title> Computing accurate eigensystems of scaled diagonally dominant matrices. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 27 </volume> <pages> 762-791, </pages> <year> 1990. </year>
Reference-contexts: We note that the error bounds in Theorems 4.11 and 4.12 are relative gap bounds on the error in the subspaces similar to those in <ref> [2, 8] </ref>. If k L 1 kk G ko 1, these bounds are a significant improvement over those in Proposition 4.7. This is one of the reasons for maintaining the property (6). 5 Numerical Examples In this section, we present a few examples from numerical experiments.
Reference: 3. <author> J.L. Barlow and S.L. Handy. </author> <title> The direct solution of weighted and equality constrained least squares problems. </title> <journal> SIAM J. Sci. Stat. Computing, </journal> <volume> 9 </volume> <pages> 704-716, </pages> <year> 1988. </year>
Reference-contexts: Theorem 4.1 is proven in Appendix A of [4]. This theorem is somewhat similar to error bounds on orthogonal factorization of matrices with disproportionate rows <ref> [1, 3] </ref>. The following corollary gives the error bounds that we get if we use no structure of the problem (2) or the resulting matrix (6).

Reference: 5. <author> J.L. Barlow, H. Zha, </author> <title> and P.A. Yoon. Efficient and stable algorithms for modifying the singular value decomposition and partial singular value decomposition. </title> <type> Technical Report CSE-93-19, </type> <institution> Department of Computer Science and Engineering, The Pennsylvania State University, University Park, </institution> <address> PA, </address> <month> September </month> <year> 1993. </year> <note> Submitted to Numerische Mathematik. </note>
Reference-contexts: Our approach to downdating the ULVD (2) uses ideas from "chasing" algorithms [25] and from the downdating algorithm due to Saunders [14, 20]. These techniques are also similar to the updating and downdating algorithms given by Barlow, Zha, and Yoon <ref> [5] </ref>. The following are the main results of this paper: 1. A blockwise procedure for downdating the ULVD that yields C = B L 0 0 0 0 0 C L; G lower triangular k ( F G) kk (F G) k (6) where the blocks are conformal with (2).
Reference: 6. <author> A. Bjorck. </author> <title> Stability analysis of the method of semi-normal equations for linear least squares problems. </title> <journal> Lin. Alg. Appl., </journal> 88/89:31-48, 1987. 
Reference-contexts: ULV DECOMPOSITION 23 decomposition [24], that is, compute an orthogonal matrix ^ U such that ^ U L 0 ! 0 ~ G :(38) If it is still true that kak &gt; 1 even after the refinement, where ~ L T a = x, the corrected semi-normal equation (CSNE) approach <ref> [6] </ref> (indicated by '+' in the first plot) is used for computing a with higher accuracy.
Reference: 7. <author> A. Bjorck, H. Park, and L. Elden. </author> <title> Accurate downdating of least squares solutions. </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 15 </volume> <pages> 549-568, </pages> <year> 1994. </year>
Reference-contexts: + 1 "large" rows, thus the rank revealing nature of C may be lost. 2.2 The LINPACK downdating algorithm The following downdating procedure due to Saunders [14] is considered the most accurate downdating procedure that does not require information from the first row of DOWNDATING THE ULV DECOMPOSITION 5 U <ref> [7] </ref> (if we have that first row, we obtain a procedure that is backward stable in the strong sense). It is the procedure that is implemented in LINPACK [9]. Algorithm 2.1 (LINPACK downdating procedure). 1. <p> It is essentially the same as that used by Bjorck, Park, and Elden <ref> [7, 22] </ref> and is given by ~ Ly = a ~ L T ffia = V T 1 X T a = a + ffia ~ Lffiy = ffia t = t X j V 1 ffiy ff = ktk where X j = A j , the j th window
Reference: 8. <author> J.W. Demmel and K. Veselic. </author> <title> Jacobi's method is more accurate than QR. </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 13 </volume> <pages> 1204-1243, </pages> <year> 1992. </year>
Reference-contexts: We note that the error bounds in Theorems 4.11 and 4.12 are relative gap bounds on the error in the subspaces similar to those in <ref> [2, 8] </ref>. If k L 1 kk G ko 1, these bounds are a significant improvement over those in Proposition 4.7. This is one of the reasons for maintaining the property (6). 5 Numerical Examples In this section, we present a few examples from numerical experiments.
Reference: 9. <author> J.J. Dongarra, J.R. Bunch, C.B. Moler, and G.W. Stewart. </author> <title> LINPACK User's Guide. </title> <publisher> SIAM Publications, </publisher> <address> Philadelphia, </address> <year> 1979. </year>
Reference-contexts: It is the procedure that is implemented in LINPACK <ref> [9] </ref>. Algorithm 2.1 (LINPACK downdating procedure). 1. Solve C T a = z If k a k 1 declare C T C zz T indefinite and stop. Otherwise go to step 2. 2.
Reference: 10. <author> L. Elden and H. Park. </author> <title> Peturbation analysis of block downdating of a Cholesky decompostion. </title> <journal> Numerische Mathematik, </journal> <note> to appear, </note> <year> 1994. </year>
Reference-contexts: The condition number ! in (27) depends solely upon the L-block, the matrix C does not have to be well conditioned or even full rank for the downdating problem to be well conditioned as is required in previous analyses <ref> [21, 10] </ref>. If there is no rank change, that is if ` = k, we can get an even better bound as shown below. <p> 2 2 &lt; nfi (nk) then k W T ~ W 2 k F 2 k (n k) oe k oe k+1 C ): The effect of ffi C is, in fact, somewhat less critical than that of ffi z as has been stated in other analyses of this problem <ref> [23, 21, 10] </ref>. We note that the error bounds in Theorems 4.11 and 4.12 are relative gap bounds on the error in the subspaces similar to those in [2, 8]. If k L 1 kk G ko 1, these bounds are a significant improvement over those in Proposition 4.7.
Reference: 11. <author> R.D. Fierro. </author> <title> Perturbation analysis for two-sided (or complete) orthogonal decompositions. </title> <type> Technical Report 94-02, </type> <institution> Department of Mathematics, California State University, </institution> <address> San Marcos, CA, </address> <month> February </month> <year> 1994. </year>
Reference-contexts: Moreover, to prevent a from becoming too large, we track k F k F so that it remains under certain threshold, say, k L 1 kk F k F &lt; 0:01. This is similar to recommendations made by Fierro and Bunch <ref> [11, 12] </ref>. Only steps in Algorithm 3.1 that require to update k F k F are steps 2 and 5.
Reference: 12. <author> R.D. Fierro and J.R. Bunch. </author> <title> Bounding the subspaces from rank revealing two-sided orthogonal decompositions. </title> <type> Technical Report 94-05, </type> <institution> Department of Mathematics, California State University, </institution> <address> San Marcos, CA, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Moreover, to prevent a from becoming too large, we track k F k F so that it remains under certain threshold, say, k L 1 kk F k F &lt; 0:01. This is similar to recommendations made by Fierro and Bunch <ref> [11, 12] </ref>. Only steps in Algorithm 3.1 that require to update k F k F are steps 2 and 5.
Reference: 13. <author> R.D. Fierro and P. C. Hansen. </author> <title> Approximating the LS and TLS solutions by rank revealing two-sided orthogonal decomposition. </title> <type> Technical Report 93-16, </type> <institution> Department of Mathematics, University of California at Los Angeles, </institution> <address> Los Angeles, CA, </address> <year> 1993. </year>
Reference-contexts: However, as found by Fierro and Hansen <ref> [13] </ref>, if F in (2) and S in (13) satisfy k F kk S k and if inf kxk=1 k Rx k&gt; * &gt; max kyk=1 k Gy k (as would be expected) then the ULVD yields a more accurate approximation of the desired subspaces of A. 4 Error Analysis 4.1 <p> It turned out that log 10 (sin 3 ) was almost indistinguishable from log 10 (sin 1 ), so we did not plot it. sin 2 is the approximation error discussed by Fierro and Hansen <ref> [13] </ref>. 22 J.L. BARLOW, P.A. YOON, AND H. ZHA Finally, the TLS errors k x (SV D) x (ULV ) k are given in logarithm in the last plot. Here, x (SV D) and x (ULV ) are the TLS solutions using the SVD and the ULVD, respectively.
Reference: 14. <author> P.E. Gill, G.H. Golub, W. Murray, and M.A. Saunders. </author> <title> Methods for modifying matrix factorizations. </title> <journal> Math. Comp., </journal> <volume> 28 </volume> <pages> 505-535, </pages> <year> 1974. </year>
Reference-contexts: Our approach to downdating the ULVD (2) uses ideas from "chasing" algorithms [25] and from the downdating algorithm due to Saunders <ref> [14, 20] </ref>. These techniques are also similar to the updating and downdating algorithms given by Barlow, Zha, and Yoon [5]. The following are the main results of this paper: 1. <p> if the matrix C is from a rank revealing decomposition with k "large" rows and n k "small" rows, this algorithm can yield k + 1 "large" rows, thus the rank revealing nature of C may be lost. 2.2 The LINPACK downdating algorithm The following downdating procedure due to Saunders <ref> [14] </ref> is considered the most accurate downdating procedure that does not require information from the first row of DOWNDATING THE ULV DECOMPOSITION 5 U [7] (if we have that first row, we obtain a procedure that is backward stable in the strong sense).
Reference: 15. <author> G.H. Golub and C.F. Van Loan. </author> <title> Matrix Computations, Second Edition. </title> <publisher> The Johns Hopkins Press, </publisher> <address> Baltimore, </address> <year> 1989. </year>
Reference-contexts: The horizontal axis represents the window steps and the vertical axis the numerical rank of the window matrix. The distance between the subspaces is given in the next plot using the definition described in <ref> [15, pp.77-78,Corollary 2.6.2] </ref>. Let A j = Y j j W T be the SVD of A j computed by the one-sided Jacobi method at step j. Let A j = U j C j V T be the ULVD of A j computed by Algorithm 3.1.
Reference: 16. <author> S. Van Huffel and J. Vandewalle. </author> <title> The Total Least Squares Problem: Computational Aspects and Analysis. </title> <publisher> SIAM Publications, </publisher> <address> Philadelphia, </address> <year> 1991. </year>
Reference-contexts: m 0 fi 1, and k n, the minimum norm TLS solution is given by computing an (n + 1)-by-(n + 1) Householder transformation H such that V 2 H = Y d ! 1 If ffi 6= 0, the TLS solution ^x is given by ^x = d=ffi:(36) See <ref> [16] </ref> for details. Van Huffel and Zha [17] formulated the solution to the TLS problems based on the URVD or the ULVD without the explicit computation of the approximate null space basis V 2 .
Reference: 17. <author> S. Van Huffel and H. Zha. </author> <title> An efficient total least squares algorithm based on a rank revealing two-sided orthogonal decomposition. </title> <booktitle> Numerical Algorithms, </booktitle> <volume> 4 </volume> <pages> 101-133, </pages> <year> 1993. </year>
Reference-contexts: Van Huffel and Zha <ref> [17] </ref> formulated the solution to the TLS problems based on the URVD or the ULVD without the explicit computation of the approximate null space basis V 2 . However, with our approach we are given V 2 explicitly at every updating and downdating step.
Reference: 18. <author> T. Kato. </author> <title> A Short Introduction to Perturbation Theory for Linear Operators. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1982. </year> <title> DOWNDATING THE ULV DECOMPOSITION 29 </title>
Reference-contexts: From the Kato <ref> [18] </ref> expansion for eigenvectors we obtain j ~w T ~w T i (z (ffiz) T + (ffiz)z T + (ffiz)(ffiz) T ) ~w j ~oe 2 j j + O (k ffiz k 2 ) k ffiz k (jz T ~w i j + jz T ~w j j) ~oe 2 <p> Then for all i and j such that oe i 6= oe j we have j ~w T ffi z i ~oe 2 (k ~w j k jz T ~w i j+ k ~w i k jz T ~w j j) + O (ffi 2 Proof: From Kato <ref> [18] </ref>, we have that ~w T ~w T ~oe 2 j z ) where e is defined in (31). Taking norms we obtain (32). 2 Lemma 4.9. Assume the results and terminology from Theorem 4.1. <p> Then for all i and j such that oe i &gt; oe j we have jw T ffi C k L 1 k (oe j + k G k) + O (ffi 2 Proof: Again using the Kato <ref> [18] </ref> expansion w T w T i ( Cffi C + C T ffi C)w j oe 2 j C ): Using the definition of E in (31) we have w T w T j C T Ew j i oe 2 + O (ffi 2 Using norm inequalities we have
Reference: 19. <editor> C.L. Lawson and R.J. Hanson. </editor> <title> Solving Least Squares Problems. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliff, NJ, </address> <year> 1974. </year>
Reference-contexts: We use k k to denote Euclidean norm, and k k F to denote Frobenius norm. The ULVD was described by Stewart [25] who also gave a method for updating it. It is a particular case of what Lawson and Hanson <ref> [19] </ref> called HRK decompositions. Our version of ULVD separates out columns that are exactly zero. The downdating problem is that of obtaining the ULVD of A where A = r T ! and the ULVD of A is known.
Reference: 20. <author> C.-T. Pan. </author> <title> A modification to the LINPACK downdating algorithm. </title> <journal> BIT, </journal> <volume> 30 </volume> <pages> 707-722, </pages> <year> 1990. </year>
Reference-contexts: Our approach to downdating the ULVD (2) uses ideas from "chasing" algorithms [25] and from the downdating algorithm due to Saunders <ref> [14, 20] </ref>. These techniques are also similar to the updating and downdating algorithms given by Barlow, Zha, and Yoon [5]. The following are the main results of this paper: 1. <p> Pan <ref> [20] </ref> shows that for C upper triangular, this method can be sped up by combining the forward substitution phase with the application of the Givens rotations. 3 A Procedure for ULV downdating 3.1 Description of the Algorithm We introduce the following algorithm for downdating the ULVD.
Reference: 21. <author> C.-T. Pan. </author> <title> A perturbation analysis on the problem of downdating a Cholesky factorization. Linear Alg. </title> <journal> Appl., </journal> <volume> 183 </volume> <pages> 103-115, </pages> <year> 1993. </year>
Reference-contexts: C = C + ffi C:(26) It is also necessary to define ! by ! = maxf1; k [L (2) ] T x k; k L T x kg:(27) Note that the definition of ! involves only the L block and is related to the condition number given by Pan <ref> [21] </ref>. First, we need the following three technical lemmata. Lemma 4.3. The vector ~ h and scalar ae from Algorithm 3.1 satisfy k ae ! Proof: We note that k ae ! G V 1 kk G k Lemma 4.4. Let z be as in (8) resulting from Algorithm 3.1. <p> The condition number ! in (27) depends solely upon the L-block, the matrix C does not have to be well conditioned or even full rank for the downdating problem to be well conditioned as is required in previous analyses <ref> [21, 10] </ref>. If there is no rank change, that is if ` = k, we can get an even better bound as shown below. <p> 2 2 &lt; nfi (nk) then k W T ~ W 2 k F 2 k (n k) oe k oe k+1 C ): The effect of ffi C is, in fact, somewhat less critical than that of ffi z as has been stated in other analyses of this problem <ref> [23, 21, 10] </ref>. We note that the error bounds in Theorems 4.11 and 4.12 are relative gap bounds on the error in the subspaces similar to those in [2, 8]. If k L 1 kk G ko 1, these bounds are a significant improvement over those in Proposition 4.7.
Reference: 22. <author> H. Park and L. Elden. </author> <title> Downdating the rank-revealing URV decomposition. </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 16 </volume> <pages> 138-156, </pages> <year> 1995. </year>
Reference-contexts: DOWNDATING THE ULV DECOMPOSITION 3 2. Our technique maps back onto the original matrix A in a more satisfactory manner than the technique given by Park and Elden <ref> [22] </ref>. 3. An error analysis of this procedure showing that the singular subspaces of the downdated matrix are as good as can be expected. We also give some new perturbation results showing that the condition of the downdate is related only to the L block in (6). <p> U e 1 = e 1 , we have (10). 2 In section 4, we show that the results of Propositions 3.1 and 3.2 make Algorithm 3.1 a robust algorithm for tracking the ULV decomposition. 3.2 Relation to Park and Elden's URV procedure A recent report by Park and Elden <ref> [22] </ref> gives a method for downdating the URV decomposition. <p> BARLOW, P.A. YOON, AND H. ZHA 2. Find an orthogonal matrix U 2 and an upper triangular matrix T such that T = U 2 0 ! The downdated matrix B is B = R S ! as before. Park and Elden <ref> [22] </ref> recommend the use of hyperbolic rotations in (15). That can be avoided by a simple and well-known trick. Let (ff 1 ; a 1 ) T be the first column of U 1 as determined in (14). <p> It is essentially the same as that used by Bjorck, Park, and Elden <ref> [7, 22] </ref> and is given by ~ Ly = a ~ L T ffia = V T 1 X T a = a + ffia ~ Lffiy = ffia t = t X j V 1 ffiy ff = ktk where X j = A j , the j th window
Reference: 23. <author> G.W. Stewart. </author> <title> The effects of rounding error on an algorithm for downdating a Cholesky factorization. </title> <journal> J. Inst. Maths. Applics., </journal> <volume> 23 </volume> <pages> 203-213, </pages> <year> 1979. </year>
Reference-contexts: This is the so-called mixed stability criterion described by Stewart <ref> [23] </ref>. <p> 2 2 &lt; nfi (nk) then k W T ~ W 2 k F 2 k (n k) oe k oe k+1 C ): The effect of ffi C is, in fact, somewhat less critical than that of ffi z as has been stated in other analyses of this problem <ref> [23, 21, 10] </ref>. We note that the error bounds in Theorems 4.11 and 4.12 are relative gap bounds on the error in the subspaces similar to those in [2, 8]. If k L 1 kk G ko 1, these bounds are a significant improvement over those in Proposition 4.7.
Reference: 24. <author> G.W. Stewart. </author> <title> Two simple residual bounds for the eigenvalues of a Hermitian matrix. </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 12 </volume> <pages> 205-209, </pages> <year> 1991. </year>
Reference-contexts: A, can be obtained by computing its QL factorization A 0 = Q 0 L 0 ! where Q 0 is a m 0 fi m 0 orthogonal matrix and L 0 a n-by-n lower triangular, followed by computing the ULVD of L 0 using the deflation technique described in <ref> [24, 25] </ref>. <p> Since our downdating procedures use LINPACK downdating algorithm, it is not difficult to generate the cases where the algorithm breaks down when k a k&gt; 1, for instance, when deleting a row that contains outliers. In this case, we first refine the DOWNDATING THE ULV DECOMPOSITION 23 decomposition <ref> [24] </ref>, that is, compute an orthogonal matrix ^ U such that ^ U L 0 ! 0 ~ G :(38) If it is still true that kak &gt; 1 even after the refinement, where ~ L T a = x, the corrected semi-normal equation (CSNE) approach [6] (indicated by '+' in
Reference: 25. <author> G.W. Stewart. </author> <title> Updating a rank-revealing ULV decomposition. </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 14 </volume> <pages> 494-499, </pages> <year> 1993. </year>
Reference-contexts: We use k k to denote Euclidean norm, and k k F to denote Frobenius norm. The ULVD was described by Stewart <ref> [25] </ref> who also gave a method for updating it. It is a particular case of what Lawson and Hanson [19] called HRK decompositions. Our version of ULVD separates out columns that are exactly zero. <p> pk ; y 0 2 &lt; np :(4) Then A is given by A = J ~ U J T C ! where ~ V = V V ; ~ U = U diag ( U; I mn1 ); J = i j As in the updating routine of Stewart <ref> [25] </ref>, the matrices C and V can be produced using O (n) Givens rotations, thus downdating the factorization in O (n 2 ) operations. Our approach to downdating the ULVD (2) uses ideas from "chasing" algorithms [25] and from the downdating algorithm due to Saunders [14, 20]. <p> I mn1 ); J = i j As in the updating routine of Stewart <ref> [25] </ref>, the matrices C and V can be produced using O (n) Givens rotations, thus downdating the factorization in O (n 2 ) operations. Our approach to downdating the ULVD (2) uses ideas from "chasing" algorithms [25] and from the downdating algorithm due to Saunders [14, 20]. These techniques are also similar to the updating and downdating algorithms given by Barlow, Zha, and Yoon [5]. The following are the main results of this paper: 1. <p> + 1 : n; i + 1); cn; sn; n i); formrot (c (i + 1; i + 1); e; cn; sn; c (i + 1; i + 1)) ; applyrot (c (i + 1; 1 : i); c (i; 1 : i); cn; sn; i); endfor end lchase Stewart <ref> [25] </ref> points out that if the matrix C is from a rank revealing decomposition with k "large" rows and n k "small" rows, this algorithm can yield k + 1 "large" rows, thus the rank revealing nature of C may be lost. 2.2 The LINPACK downdating algorithm The following downdating procedure <p> This algorithm works if 0 0 is substituted for G and (y T ; y T 0 ) T is substituted for y. That is, it is not necessary to explicitly handle the zero block, it can be made part of G. That is the original formulation in <ref> [25] </ref>. However, if that is done, whenever y 0 6= 0, any zero diagonal will be chased to the g 11 position, all of (y; y 0 ) T will be treated as "noise". <p> A, can be obtained by computing its QL factorization A 0 = Q 0 L 0 ! where Q 0 is a m 0 fi m 0 orthogonal matrix and L 0 a n-by-n lower triangular, followed by computing the ULVD of L 0 using the deflation technique described in <ref> [24, 25] </ref>. <p> One such circumstance seems to be when an update or downdate cause a sudden change in the scale of the matrix. A necessary verifiable condition for refactoring is a subject for future research. 6 Conclusion The downdating algorithms presented here coupled with updating algorithm of Stew-art <ref> [25] </ref> show that the ULV decomposition can be updated and downdated in O (n 2 ) flops in a manner that preserves its structure. The backward error analysis and perturbation theory show that the downdate procedure satisfies a blockwise stability property.
References-found: 24

