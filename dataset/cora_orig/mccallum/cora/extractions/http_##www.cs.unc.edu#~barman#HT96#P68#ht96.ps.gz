URL: http://www.cs.unc.edu/~barman/HT96/P68/ht96.ps.gz
Refering-URL: http://www.cs.unc.edu/~barman/HT96/index.html
Root-URL: http://www.cs.unc.edu
Email: E-mail: rweiss@lcs.mit.edu  
Title: HyPursuit: A Hierarchical Network Search Engine that Exploits Content-Link Hypertext Clustering  
Author: Ron Weiss, Bienvenido Velez, Mark A. Sheldon Chanathip Namprempre, Peter Szilagyi, Andrzej Duda, David K. Gifford 
Keyword: Network Resource Discovery, Hypertext Clustering, Hyperlink Structures.  
Address: 545 Technology Square, Cambridge, MA 02139 USA  
Affiliation: Programming Systems Research Group MIT Laboratory for Computer Science  
Abstract: HyPursuit is a new hierarchical network search engine that clusters hypertext documents to structure a given information space for browsing and search activities. Our content-link clustering algorithm is based on the semantic information embedded in hyperlink structures and document contents. HyPursuit admits multiple, coexisting cluster hierarchies based on different principles for grouping documents, such as the Library of Congress catalog scheme and automatically created hypertext clusters. HyPursuit's abstraction functions summarize cluster contents to support scalable query processing. The abstraction functions satisfy system resource limitations with controlled information loss. The result of query processing operations on a cluster summary approximates the result of performing the operations on the entire information space. We constructed a prototype system comprising 100 leaf World Wide Web sites and a hierarchy of 42 servers that route queries to the leaf sites. Experience with our system suggests that abstraction functions based on hypertext clustering can be used to construct meaningful and scalable cluster hierarchies. We are also encouraged by preliminary results on clustering based on both document contents and hyperlink structures. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Bob Alberti, Farhad Anklesaria, Paul Linkner, Mark McCahill, and Daniel Torrey. </author> <title> The Internet Gopher protocol: A distributed document search and retrieval protocol. University of Minesota Microcomputer and Workstation Networks Center, </title> <note> Spring 1991. Revised Spring 1992. </note>
Reference-contexts: Furthermore, a HyPursuit system allows greater autonomy to each information provider and content router to tailor its indexing mechanisms and facilities using local knowledge. Veronica [15] is a discovery system that maintains an index of document titles from Gopher <ref> [1] </ref> menus, and it suffers from the same limitations as the Web search systems. HyPur-suit provides a coherent framework for the integration of diverse centralized search engines.
Reference: 2. <author> Rodrigo A. Botafogo. </author> <title> Cluster analysis for hypertext systems. </title> <booktitle> In ACM 16th Annual International SIGIR '93, </booktitle> <address> Pittsburgh, PA, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: The new clusters reveal their contents in more detail, since the total number of re-clustered documents is reduced. Unlike scatter/gather, HyPursuit defines a framework for information retrieval services, such as query routing and refinement, in a hierarchy of servers. Botafogo <ref> [2] </ref> proposes a hyperlink-based document clustering algorithm based on k-edge-components to generate clusters of hypertext documents. The similarity between hypertext nodes is proportional to the number of 1 http://white.nosc.mil/info.html 2 http://www.yahoo.com 3 http://www.ncsa.uiuc.edu/SDG/Software/Mosaic/ MetaIndex.html independent paths between them.
Reference: 3. <author> Rodrigo A. Botafogo and Ben Schneiderman. </author> <title> Identifying aggregates in hypertext structures. </title> <booktitle> In Hypertext '91, </booktitle> <month> December </month> <year> 1991. </year>
Reference-contexts: Botafogo [2] proposes a hyperlink-based document clustering algorithm based on k-edge-components to generate clusters of hypertext documents. The similarity between hypertext nodes is proportional to the number of 1 http://white.nosc.mil/info.html 2 http://www.yahoo.com 3 http://www.ncsa.uiuc.edu/SDG/Software/Mosaic/ MetaIndex.html independent paths between them. Botafogo et al. <ref> [3] </ref> use biconnected components and strongly connected components for hypertext clustering. First, the hypertext is converted into an undirected graph by adding links. Then, edges adjacent to so called reference and index nodes are removed.
Reference: 4. <author> C. Mic Bowman, Peter B. Danzig, Darren R. Hardy, Udi Manber, and Michael F. Schwartz. </author> <title> The harvest information discovery and access system. </title> <booktitle> In Proceedings of the Second International World Wide Web Conference, </booktitle> <pages> pages 763-771, </pages> <address> Chicago, Illinois, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: Hierarchical network search engines address issues of scalability in terms of storage requirements and network communication for the task of resource discovery. The three examples of hierarchical search engines that are known to the authors include Harvest <ref> [4] </ref>, GLOSS [14] and our work on content routing [8, 22, 21]. These systems reduce storage requirements at any of the distributed components by generating succinct descriptions (content labels) of the contents of leaf servers.
Reference: 5. <author> Donald B. Crouch, Carolyn J. Crouch, and Glenn Andreas. </author> <title> The use of cluster hierarchies in hypertext information retrieval. </title> <booktitle> In Hypertext '89, </booktitle> <month> November </month> <year> 1989. </year>
Reference-contexts: Finally, the section describes the services supported by HyPursuit together with their corresponding user interfaces. Hierarchical Organization of a HyPursuit System HyPursuit's architecture admits multiple, distributed, coexisting cluster hierarchies in a network resource discovery environment. Individual cluster hierarchies are useful for browsing and searching large document collections <ref> [5, 7] </ref> because they organize the information space. Because no single organization can meet all user needs, HyPursuit supports arbitrary cluster topologies, including multitrees [13]. Users browse through a hierarchy and perform searches that exploit its organizational structure. Each hierarchy corresponds to a method of grouping related documents into clusters.
Reference: 6. <author> Douglass R. Cutting, David R. Karger, and Jan O. Pedersen. </author> <title> Constant interaction-time scatter/gather browsing of very large document collections. </title> <booktitle> In 16th Annual International SIGIR'93, </booktitle> <address> Pittsburgh, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: Finally, we describe how term weights are factored into the computation of hypertext document similarities using a traditional term-weighting scheme. Similarity-Based Clustering Our clustering is based on the complete link method [19]. Although faster clustering algorithms exist <ref> [6] </ref>, we chose the complete link method because it was easy to implement. The complete link method starts with a set where each original document represents an independent cluster. The algorithm iteratively reduces the number of clusters by merging the two most similar clusters until max clusters clusters remain.
Reference: 7. <author> Douglass R. Cutting, David R. Karger, Jan O. Ped-ersen, and John W. Tukey. Scatter/gather: </author> <title> A cluster-based approach to browsing large document collections. </title> <booktitle> In 15th Annual International SIGIR, </booktitle> <pages> pages 318-329, </pages> <address> Denmark, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Document clustering has been previously studied as a mechanism to improve both searching and browsing. Salton [19] presents a summary of recent document clustering techniques that are used to improve collection searching. Scatter/gather <ref> [7] </ref> dynamically clusters collections of documents for browsing large information spaces. It presents summaries of clusters to the user, who can then select a subset of these clusters for further reclus-tering. The selected clusters are scattered into the original documents and re-clustered. <p> Finally, the section describes the services supported by HyPursuit together with their corresponding user interfaces. Hierarchical Organization of a HyPursuit System HyPursuit's architecture admits multiple, distributed, coexisting cluster hierarchies in a network resource discovery environment. Individual cluster hierarchies are useful for browsing and searching large document collections <ref> [5, 7] </ref> because they organize the information space. Because no single organization can meet all user needs, HyPursuit supports arbitrary cluster topologies, including multitrees [13]. Users browse through a hierarchy and perform searches that exploit its organizational structure. Each hierarchy corresponds to a method of grouping related documents into clusters. <p> In the current implementation, HyPursuit arbitrarily selects the sample list of documents. A future implementation may choose to select documents that are more representative of the sub-cluster. For example, the system can suggest pre-computed centroid documents <ref> [7] </ref> for each sub-cluster based on both the terms in the sub-cluster and the link structures. Result Set Expansion To improve recall, HyPursuit suggests additional related documents that, though not selected by the query, are collocated in sub-clusters with query-selected documents.
Reference: 8. <author> Andrzej Duda and Mark A. Sheldon. </author> <title> Content routing in networks of WAIS servers. </title> <booktitle> In Proceedings of the 14th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 124-132, </pages> <address> Poz-nan, Poland, </address> <month> June </month> <year> 1994. </year> <note> IEEE. </note>
Reference-contexts: Hierarchical network search engines address issues of scalability in terms of storage requirements and network communication for the task of resource discovery. The three examples of hierarchical search engines that are known to the authors include Harvest [4], GLOSS [14] and our work on content routing <ref> [8, 22, 21] </ref>. These systems reduce storage requirements at any of the distributed components by generating succinct descriptions (content labels) of the contents of leaf servers.
Reference: 9. <author> David Eichmann. </author> <title> The RBSE spider balancing effective search against web load. </title> <booktitle> In Proceedings of the First International Conference on the World Wide Web, </booktitle> <address> Geneva, Switzerland, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: GLOSS offers several alternatives for us ing the histogram data, but it does not support query refinement. Centralized Network search engines such as the Web Crawler [18], WWW Worm, ALIWEB [16], and the RBSE Spider <ref> [9] </ref>, gather information about resources on the Web for query-based access. However, these systems are not scalable because they use a global indexing strategy, i.e., they attempt to build one database that indexes everything.
Reference: 10. <author> David Filo and Jerry Yang. </author> <title> Yahoo frequently asked questions. World Wide Web Document. </title> <address> URL http://www.yahoo.com/faq.html. </address>
Reference-contexts: As the information content grows, it becomes cumbersome to browse them and discover relevant information in these systems without query routing and refinement. At present, these systems are rather ad hoc and static, requiring manual update and maintenance. Yahoo <ref> [10] </ref> classifies documents manually and supports content-based access to the collection of documents gathered from either users' submissions or web robots. Document clustering has been previously studied as a mechanism to improve both searching and browsing.
Reference: 11. <author> R. Forsyth and R. Rada. </author> <title> Machine Learning| Applications in Expert Systems and Information Retrieval. </title> <publisher> Ellis Horwood, </publisher> <year> 1986. </year>
Reference-contexts: They provide a means of exploring the information space. Narrower terms can improve precision by allowing specialization of queries. The thesaurus mechanism is based on the automatic construction of thesaurus classes built o*ine using a Forsyth-Rada algorithm <ref> [11] </ref> modified to consider sub-clusters rather than documents. For a given collection of sub-clusters, we generate a two-level hierarchy of term classes by gathering term frequencies, calculating weights and grouping high-frequency and low-frequency terms.
Reference: 12. <author> Mark E. Frisse. </author> <title> Searching for information in a hypertext medical handbook. </title> <journal> Comm. ACM, </journal> <volume> 31(7), </volume> <month> July </month> <year> 1988. </year>
Reference-contexts: The algorithm then finds bicon-nected subgraphs and the entire process is recursively applied to each resulting subgraph until no more bicon-nected components can be isolated. Each final bicon-nected component becomes a cluster. Neither approach uses term information or implements any information retrieval service exploiting hypertext clustering. <ref> [12] </ref> combines terms and hyperlinks to rank nodes that match a query in a hypertext document. In contrast, HyPursuit uses terms and hyperlinks to cluster large collections of hypertext documents. The strategy proposed by [12] represents a promising paradigm for ranking query results that may be incorporated in future implementations of <p> Neither approach uses term information or implements any information retrieval service exploiting hypertext clustering. <ref> [12] </ref> combines terms and hyperlinks to rank nodes that match a query in a hypertext document. In contrast, HyPursuit uses terms and hyperlinks to cluster large collections of hypertext documents. The strategy proposed by [12] represents a promising paradigm for ranking query results that may be incorporated in future implementations of HyPursuit. However, the algorithms require modification to handle arbitrary hyperlink structures such as cyclic graphs.
Reference: 13. <author> George W. Furnas and Jeff Zacks. Multitrees: </author> <title> Enriching and reusing hierarchical structure. </title> <booktitle> In CHI 94 Human Factors in Computing Systems: </booktitle> <address> Celebrating Inderdependence, Boston, </address> <month> April </month> <year> 1994. </year>
Reference-contexts: Individual cluster hierarchies are useful for browsing and searching large document collections [5, 7] because they organize the information space. Because no single organization can meet all user needs, HyPursuit supports arbitrary cluster topologies, including multitrees <ref> [13] </ref>. Users browse through a hierarchy and perform searches that exploit its organizational structure. Each hierarchy corresponds to a method of grouping related documents into clusters. Leaf nodes within the hierarchy are single documents, and interior nodes correspond to clusters of documents and clusters of clusters.
Reference: 14. <author> Luis Gravano, Anthony Tomasic, and Hector Garc ia-Molina. </author> <title> The efficacy of GlOSS for the text database discovery problem. </title> <type> Technical Report STAN-CS-TR-93-2, </type> <institution> Stanford University Department of Computer Science, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: Hierarchical network search engines address issues of scalability in terms of storage requirements and network communication for the task of resource discovery. The three examples of hierarchical search engines that are known to the authors include Harvest [4], GLOSS <ref> [14] </ref> and our work on content routing [8, 22, 21]. These systems reduce storage requirements at any of the distributed components by generating succinct descriptions (content labels) of the contents of leaf servers. <p> This requires every content router to keep term collocation information on a per document basis. HyPursuit supports query refinement based on term collocation on a per cluster basis. In addition, Hy-Pursuit scans entire documents for term information. GLOSS <ref> [14] </ref> uses a probabilistic scheme to predict the size of query result sets for each subsidiary server and forwards queries to those servers likely to have matching documents. The prediction is based on a histogram of the occurrences of words within a server.
Reference: 15. <author> Harley Hahn and Rick Stout. </author> <title> The Internet Complete Reference. </title> <publisher> Osborne McGraw-Hill, </publisher> <address> Berkeley, California, </address> <year> 1994. </year>
Reference-contexts: These systems overburden network resources by transmitting entire documents, rather than the index data, or better still, content labels. Furthermore, a HyPursuit system allows greater autonomy to each information provider and content router to tailor its indexing mechanisms and facilities using local knowledge. Veronica <ref> [15] </ref> is a discovery system that maintains an index of document titles from Gopher [1] menus, and it suffers from the same limitations as the Web search systems. HyPur-suit provides a coherent framework for the integration of diverse centralized search engines.
Reference: 16. <author> Martijn Koster. </author> <title> ALIWEB archie-like indexing in the web. </title> <booktitle> In Proceedings of the First International Conference on the World Wide Web, </booktitle> <address> Geneva, Switzerland, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: GLOSS offers several alternatives for us ing the histogram data, but it does not support query refinement. Centralized Network search engines such as the Web Crawler [18], WWW Worm, ALIWEB <ref> [16] </ref>, and the RBSE Spider [9], gather information about resources on the Web for query-based access. However, these systems are not scalable because they use a global indexing strategy, i.e., they attempt to build one database that indexes everything.
Reference: 17. <author> P. Mockapetris. </author> <title> Domain names concepts and facilities. </title> <type> RFC 1034, </type> <year> 1987. </year>
Reference-contexts: We have built an experimental HyPursuit prototype comprising 100 Web sites organized in a four-level hierarchy of 42 content routers. The hierarchy, shown in Figure 2, is constructed to reflect the structure of the domain name system (DNS) <ref> [17] </ref>. Experience with this configuration suggests that hierarchical clustering provides a valuable discovery service to end users, and our data supports the ability of the system to scale with modest increases in content label sizes. <p> We are investigating other approaches. that was constructed for our experimental system. The system consists of 100 leaf servers (that index particular Web sites) and a series of higher-level content routers organized in a hierarchy that resembles the structure of the Domain Name System <ref> [17] </ref>. For instance, the root router's name is "edu", and some of its children are "mit.edu" and "cmu.edu". The pattern follows until leaf servers with full domain names are reached (e.g. www.psrg.lcs.mit.edu). EXPERIENCE This section presents experience with the HyPursuit prototype.
Reference: 18. <author> Brian Pinkerton. </author> <title> Finding what people want: Experiences with the WebCrawler. </title> <booktitle> In Proceedings of the First International Conference on the World Wide Web, </booktitle> <address> Geneva, Switzerland, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: GLOSS's estimates are not accurate because they rely on the assumption that terms appear independently of other terms in documents. GLOSS offers several alternatives for us ing the histogram data, but it does not support query refinement. Centralized Network search engines such as the Web Crawler <ref> [18] </ref>, WWW Worm, ALIWEB [16], and the RBSE Spider [9], gather information about resources on the Web for query-based access. However, these systems are not scalable because they use a global indexing strategy, i.e., they attempt to build one database that indexes everything.
Reference: 19. <author> Gerard Salton and Jose Araya. </author> <title> On the use of clustered file organization in information search and retrieval. </title> <type> Technical Report TR 89-989, </type> <institution> Cornell University, </institution> <month> April </month> <year> 1989. </year>
Reference-contexts: Yahoo [10] classifies documents manually and supports content-based access to the collection of documents gathered from either users' submissions or web robots. Document clustering has been previously studied as a mechanism to improve both searching and browsing. Salton <ref> [19] </ref> presents a summary of recent document clustering techniques that are used to improve collection searching. Scatter/gather [7] dynamically clusters collections of documents for browsing large information spaces. It presents summaries of clusters to the user, who can then select a subset of these clusters for further reclus-tering. <p> Finally, we describe how term weights are factored into the computation of hypertext document similarities using a traditional term-weighting scheme. Similarity-Based Clustering Our clustering is based on the complete link method <ref> [19] </ref>. Although faster clustering algorithms exist [6], we chose the complete link method because it was easy to implement. The complete link method starts with a set where each original document represents an independent cluster.
Reference: 20. <author> Gerard Salton and Chris Buckley. </author> <title> Term weighting approaches in automatic text retrieval. </title> <type> Technical Report TR 87-881, </type> <institution> Cornell University, </institution> <month> November </month> <year> 1987. </year>
Reference-contexts: The term-weight function should favor terms that are representative of the documents, but should also discriminate between the documents and the servers that hold them. The best known term weighting approaches <ref> [20] </ref> use compound normalized weights with three factors: term frequency, inverse document frequency and a factor inversely proportional to the size of documents. Term frequency is the number of occurrences of a term in a document. <p> The weight function assigns a larger factor to terms with attributes title, header, keyword and address than the weight factor assigned to text terms. The total weight w ki of a term t i in document d k is calculated based on the term similarity function proposed by <ref> [20] </ref>, with the omission of the collection frequency factor, as follows: Let tf ki term frequency of t i in d k w ki contribution to weight from frequencytf ki w ds ki contribution to weight from size of d k w at ki contribution to weight from term attribute then
Reference: 21. <author> Mark A. Sheldon, Andrzej Duda, Ron Weiss, and David K. Gifford. </author> <title> Discover: A resource discovery system based on content routing. </title> <booktitle> In Proceedings of The Third International World Wide Web Conference. </booktitle> <publisher> Elsevier, North Holland, </publisher> <month> April </month> <year> 1995. </year> <note> To appear in a special issue of Computer Networks and ISDN Systems. </note>
Reference-contexts: Hierarchical network search engines address issues of scalability in terms of storage requirements and network communication for the task of resource discovery. The three examples of hierarchical search engines that are known to the authors include Harvest [4], GLOSS [14] and our work on content routing <ref> [8, 22, 21] </ref>. These systems reduce storage requirements at any of the distributed components by generating succinct descriptions (content labels) of the contents of leaf servers. <p> The succinct descriptions allow the resource discovery systems to selectively access manageable sets of information providers that are believed to contain information relevant to the user's needs. None of these systems exploit hypertext clustering to provide additional information retrieval services similar to the ones HyPursuit provides. Discover <ref> [21] </ref> implements query refinement using a refinement database that consists of WAIS document headlines. Discover suggests additional refinement terms for a given query based on term collocation in the document headlines. This requires every content router to keep term collocation information on a per document basis.
Reference: 22. <author> Mark A. Sheldon, Andrzej Duda, Ron Weiss, James W. O'Toole, Jr., and David K. Gifford. </author> <title> Content routing for distributed information servers. </title> <booktitle> In Fourth International Conference on Extending Database Technology, </booktitle> <pages> pages 109-122, </pages> <address> Cambridge, England, </address> <month> March </month> <year> 1994. </year> <note> Available as Springer-Verlag LNCS Number 779. </note>
Reference-contexts: Hierarchical network search engines address issues of scalability in terms of storage requirements and network communication for the task of resource discovery. The three examples of hierarchical search engines that are known to the authors include Harvest [4], GLOSS [14] and our work on content routing <ref> [8, 22, 21] </ref>. These systems reduce storage requirements at any of the distributed components by generating succinct descriptions (content labels) of the contents of leaf servers. <p> Query Routing HyPursuit's user interface allows the user to search for relevant information with query-based operations that automatically traverse the cluster hierarchy. Our previous work <ref> [22] </ref> describes in detail how these content routing operations prune the information space and provide progressively finer-grained views of the relevant information. Relevant information may be either clusters (i.e., content routers) or documents. the query processing operations.
References-found: 22

