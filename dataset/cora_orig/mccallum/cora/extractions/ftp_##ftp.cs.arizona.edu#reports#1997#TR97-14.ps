URL: ftp://ftp.cs.arizona.edu/reports/1997/TR97-14.ps
Refering-URL: http://www.cs.arizona.edu/research/reports.html
Root-URL: http://www.cs.arizona.edu
Title: Automated Verification of Mobile Code  
Author: by H. Dan Lam bright 
Degree: Submitted to the Department of Computer Science in partial fulfillment of the requirements for the degree of Master of Science in Computer Science at the  
Date: November 3, 1997  
Affiliation: UNIVERSITY OF ARIZONA  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> M. Accetta, R. Baron, W. Bolosky, D. Golub, R. Rashid, A. Tevanian, M. Young. </author> <title> "Mach: A New Kernel Foundation for UNIX Development". </title> <booktitle> Proceedings of the Summer 1986 USENIX Conference. </booktitle> <month> July, </month> <year> 1986. </year> <pages> pages. 93-112. </pages>
Reference-contexts: SFI is the process of inserting checks around memory accesses in the code. These checks ensure that the accesses to memory are safe. The disadvantage to SFI is that the checks incur a performance penalty [34]. Finally, virtual memory address domains can also be used to protect memory <ref> [1] </ref>. In this strategy, the address space visible to programs is controlled by a protected kernel-level memory manager. Changing the address space can only be done via protected system calls.
Reference: [2] <author> A. V. Aho, R. Sethi, J. D. Ullman. </author> <booktitle> Compilers Principles, Techniques and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: Complex security systems have more points of failure; recall that this is already a frequent complaint raised against Java [8]. In addition, complex dataflow analysis may incur performance penalities; for example, it is time consuming to compute dataflow structures such as gen and kill sets across method boundaries <ref> [2] </ref>. Coupling this analysis with just-in-time compilation could result in a visible delay to the user. 4.1.4 The Registry The job of the PA is to write a specification that explicitly states the sensitive parameters to trusted subsystems, and the valid trusted subsystems from which those parameters may be derived. <p> Two of the most important computations executed during the phase are: Determining the Control Flow Graph (CFG) The control flow graph depicts all of the posi-ble paths by which execution could flow within a method <ref> [2] </ref>. When performing dataflow verification, the graph is used to trace backwards in the code from the point that a variable is used to each point where it may have been defined. Performing Stack Simulation The Java bytecode instruction set is stack-based.
Reference: [3] <author> R. Anderson. </author> <title> "Why Cryptosystems Fail." </title> <booktitle> 1st Conference on Computer and Communication Security. </booktitle> <month> November, </month> <year> 1993. </year>
Reference-contexts: Hostile applets are beyond the scope of this work. 8 We assume the client's execution environment, including the virtual machine, API functions, and verifier, are completely free of implementation errors. If the security policy has an implementation bug, the entire system may become vulnerable to attack <ref> [3] </ref> [8]. In the next subsections we will lay down the design goals of the security in greater detail, and broadly discuss the architectural options. 2.2.1 Goals Several sets of criteria have been developed to evaluate and compare security policies [38] [24]. <p> Human error caused not only most of Java's security holes [8], but are to blame for other security systems breaches, such as those in ATM machines <ref> [3] </ref>. The luring, trojan horses, and spoofing attacks all rely on deceiving the user. All a malicious applet has to do to circumvent a browser guarded by digital signatures is fool the certification authority.
Reference: [4] <author> D. Bass. </author> <booktitle> "The Inpact of the Network Computer". </booktitle> <address> http://www2.netdoor.com/ dave-bass/NCSHIM.HTM. </address> <month> April </month> <year> 1997. </year>
Reference-contexts: Large-scale distributed computing may soon be possible, in which mobile code is embedded in everything from set-top-boxes to PDAs [36] [20]. Ultimately, many companies are banking that mobile code will make practical the long awaited network computer <ref> [4] </ref>, thereby driving down the cost of maintaining a PC. In reality, mobile code technologies have been widely deployed in Internet browsers for several years. But despite their promising applications and availability, they have not yet become widely employed by users.
Reference: [5] <author> B. Bershad, G. S. Emin, S. McDirmid. </author> <title> Kimera Architecture. </title> <address> http://kimera.cs.washington.edu/overview.html </address>
Reference-contexts: However, researchers are investigating o*ine verification, such as at the University of Washington's Kimera project <ref> [5] </ref>. The advantages are that it centralizes the information needed to perform verification into one place. For example, the third machine may contain a master list of applets which are known to be safe. Additionally, it reduces the size of the code needed to be maintained at the client. <p> Sun microsystems and Netscape provide the source code to their implementations to researchers who wish to study and improve its security properties [8] <ref> [5] </ref>. This feedback has resulted in numerous bug-fixes and many suggestions for improvements. 3.1 Bytecode Level Security: The Bytecode Verifier Java's bytecode verifier checks the code for the following problems. 1 The verifier is run on the client immediately after an applet is downloaded. 1.
Reference: [6] <author> B. Bershad, S. Savage, P. Pardyak, E. G. Sirer, D. Becker, M. Fiuczynski, C. Chambers, S. Eggers. </author> <title> "Extensibility, Safety, and Performance in the SPIN Operating System." </title> <booktitle> Proceedings of the 15th Symposium on Operating Systems Principles." </booktitle>
Reference-contexts: The Spin project at the University of Washington relies in part on Modula-3's type safety for security [26] <ref> [6] </ref>. Java's basic security also depends on type safety; this will be further discussed in chapter 3. Type safe languages may be unfamiliar to system programmers used to C, or incompatible with existing software systems written in C.
Reference: [7] <author> P. David. </author> <title> "Inferno Security." </title> <booktitle> Proceedings of IEEE COMPCON 1997 pages 97-102. </booktitle> <month> February </month> <year> 1997. </year>
Reference-contexts: Recently RSA-129 was broken in just one year [8]. Pure authentication is the name given to the security policies which use authentication and no other form of security. ActiveX [22] and Inferno <ref> [7] </ref> are examples of the pure authentication model. These systems will be further discussed in section 6. 13 2.4.3 Formal Verification The third verification technique is formal verification. In this strategy the downloaded applet is scanned by another program before it is run.
Reference: [8] <author> D. Dean, E. Felten, D. Wallach. </author> <title> "Java Security: From HotJava to Netscape and Beyond." </title> <booktitle> IEEE Symposium on Security and Privacy. </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Unfortunately, that is still too risky: how does one know that the site actually is the vendor's site it claims to be? On the Internet, there is the potential for a server to pretend to be something it is not, 3 and trick the client <ref> [8] </ref>. In a recent incident, Microsoft corporation took legal action to prevent a website called www.ms.com from operating. The operators of the site were taking advantage of the fact that many users would access their webpages thinking it was the real Microsoft site. <p> Hostile applets are beyond the scope of this work. 8 We assume the client's execution environment, including the virtual machine, API functions, and verifier, are completely free of implementation errors. If the security policy has an implementation bug, the entire system may become vulnerable to attack [3] <ref> [8] </ref>. In the next subsections we will lay down the design goals of the security in greater detail, and broadly discuss the architectural options. 2.2.1 Goals Several sets of criteria have been developed to evaluate and compare security policies [38] [24]. <p> Acquisition of the private keys would allow any entity to spoof the company's applets. Furthermore, massively parallel techniques and high speed computers may be beginning to make the factoring problem computationally feasible using brute force methods [11]. Recently RSA-129 was broken in just one year <ref> [8] </ref>. Pure authentication is the name given to the security policies which use authentication and no other form of security. ActiveX [22] and Inferno [7] are examples of the pure authentication model. <p> Sun microsystems and Netscape provide the source code to their implementations to researchers who wish to study and improve its security properties <ref> [8] </ref> [5]. This feedback has resulted in numerous bug-fixes and many suggestions for improvements. 3.1 Bytecode Level Security: The Bytecode Verifier Java's bytecode verifier checks the code for the following problems. 1 The verifier is run on the client immediately after an applet is downloaded. 1. <p> The disadvantage to complex analysis, however, is that those algorithms are difficult to implement, and can be buggy. Complex security systems have more points of failure; recall that this is already a frequent complaint raised against Java <ref> [8] </ref>. In addition, complex dataflow analysis may incur performance penalities; for example, it is time consuming to compute dataflow structures such as gen and kill sets across method boundaries [2]. <p> Finally, an additional area of future work may include experimenting with dataflow analysis techniques to detect hostile applets and covert channels. 7.2 Close History has shown that the weakest link in the security chain is the human component. Human error caused not only most of Java's security holes <ref> [8] </ref>, but are to blame for other security systems breaches, such as those in ATM machines [3]. The luring, trojan horses, and spoofing attacks all rely on deceiving the user. All a malicious applet has to do to circumvent a browser guarded by digital signatures is fool the certification authority.
Reference: [9] <author> E. W. Felten, Dirk Balfanz, Drew Dean, and Dan S. Wallach. </author> <title> "Web Spoofing: An Internet Con Game." </title> <type> Technical Report 540-96. </type> <institution> Department of Computer Science, Princeton University. </institution> <month> Decem-ber </month> <year> 1996. </year>
Reference: [10] <author> D. Flanagan. </author> <title> "Java in a Nutshell." </title> <publisher> O'Reilly & Associates, Inc. </publisher>
Reference-contexts: This is in contrast to static linking which binds object only at link time. This simplifies development and maintenance because it removes the link stage, and allows programs to be built up from multiple points on the network <ref> [10] </ref>. The disadvantage to dynamic linking is that it introduces new security problems. One problem with dynamically loading classes is that they must be prevented from overwriting system classes. <p> String fname; try - z=new int <ref> [10] </ref>; fname=trusted.getfilename (); z [11]=1; // ** throw exception ** FileOutputStream fp=trusted.openFile (fname); - catch (Exception e) - fname="Illegalfile"; // Change critical data. - In the prototype, a constraint was imposed stipulating that critical datapaths must contain throw clauses. Note that the clause must catch all exceptions. <p> Note that the clause must catch all exceptions. The only code in the throw clause is a call to a trusted exception handler. Thus, the example above must be modified to become: String fname; try - z=new int <ref> [10] </ref>; fname=trusted.getfilename (); z [11]=1; // ** throw exception ** FileOutputStream fp=trusted.openFile (fname); - catch (Exception e) - // Catch all exceptions. trusted.TrustedCatch (e); // Call trusted handler. - This solution is problematic because the TrustedCatch () routine must be standardized somehow.
Reference: [11] <author> G. Fox, W. Furmanski. </author> <title> "Computing on the Web New Approaches to Parallel Processing Petaop and Exaop Performance in the Year 2007." </title> <type> Technical Report SCCS-784, </type> <institution> Syracuse University, NPAC. </institution> <month> January </month> <year> 1997. </year>
Reference-contexts: Acquisition of the private keys would allow any entity to spoof the company's applets. Furthermore, massively parallel techniques and high speed computers may be beginning to make the factoring problem computationally feasible using brute force methods <ref> [11] </ref>. Recently RSA-129 was broken in just one year [8]. Pure authentication is the name given to the security policies which use authentication and no other form of security. ActiveX [22] and Inferno [7] are examples of the pure authentication model.
Reference: [12] <author> L. Gong. </author> <title> "New Security Architectural Directions for Java." </title> <booktitle> Proceedings of IEEE COMPCON 1997 pages 97-102. </booktitle> <month> February </month> <year> 1997. </year>
Reference-contexts: is lightweight in the sense that there is no guarantee that the API routines or other code will invoke the security manager at the right time, and no practical way to check that it does. 3.4 Future Security Features Sun Microsystems is in the process of improving Java's security model <ref> [12] </ref>. As described in Section 2.4.1, one new feature is a reference monitor that will allow users to customize the type of accesses to system resources they wish to give applets.
Reference: [13] <author> J. Hartman, U. Manber, L. Peterson, T. Proebsting. </author> <title> "Liquid Software: A New Paradigm for Net-worked Systems." </title> <type> Technical Report 96-11. </type> <institution> Dept. of Computer Science, The University of Arizona. </institution> <month> 36 </month>
Reference: [14] <author> C. Kaufman, R. Perlman, M. Speciner. </author> <title> "Network Security: Private Communication in a PUBLIC World." </title> <publisher> Prentice Hall, </publisher> <year> 1995. </year>
Reference-contexts: This problem is discussed further in the next section. 2.4.2 Digital Signatures A public key encryption (PKE) scheme allows a server to digitally encrypt information using a "private key." The client can then decrypt the information using the corresponding "public key" <ref> [14] </ref>. As long as the private key is not made public, it is computationally hard for a malicious entity to guess the private key [32]. Public key encryption is the underlying technology behind many security solutions used for networks, including secure communications (SSL), electronic transactions (SET), and email encoding (S/MIME).
Reference: [15] <author> M. Ladue. </author> <title> A Collection of Increasingly Hostile Applets. </title> <address> URL: http://www.math.gatech.edu/ mladue/HostileApplets.html </address>
Reference-contexts: Hostile applets deliberately abuse resources. This can be done by aquiring an inordinate percentage of CPU cycles, thereby denying the user access to the computer. Creating too many threads, using up all of the system's available file descriptors, or opening too many windows, are all examples of hostile applets <ref> [15] </ref>. In the worst case a hostile applet is written in a way such that the only recourse the user has is to reboot his machine. Hostile applets come in enormous varieties and are extremely difficult to detect and prevent [15]. <p> opening too many windows, are all examples of hostile applets <ref> [15] </ref>. In the worst case a hostile applet is written in a way such that the only recourse the user has is to reboot his machine. Hostile applets come in enormous varieties and are extremely difficult to detect and prevent [15]. What follows is a taxonomy of the principal components of a computer system that must be protected. Disk The client's permanent storage must be protected. The user may allow some subset of his storage, such as a directory, to be accessible to the applet. <p> Any level of access must be explicitly granted by the user. By fail-safe, we mean there is no way for a malicious applet to circumvent the verifier. Even a single flaw in the verifier might be enough to compromise the integrity of the entire system <ref> [15] </ref>. 2. The verifier should be psychologically acceptable to users accustomed to the simplicity of the World Wide Web. Ideally, the verifier should be a "black box" which accepts an input applet from the user, and outputs whether or not the applet is safe or not.
Reference: [16] <author> H. D. Lambright. </author> <title> "Java Bytecode Optimizations." </title> <booktitle> Proceedings of IEEE COMPCON 1997, </booktitle> <pages> pages 206-210, </pages> <month> February </month> <year> 1997. </year>
Reference-contexts: The software is standalone- i.e. it is not integrated into a browser. Its architecture most closely resembles "ahead-of-time online verification" in Figure 2.1. Significant portions of the verifier were derived from pre-existing projects such as Sumatra [31] and Bali <ref> [16] </ref>. The major components of the prototype are described below. registry compiler (391 lines) This is a small compiler that converts the textual representation of a security policy (the registry) into a table which can be read by the dataflow analysis subsection of the verifier. <p> The information used by the verifier includes the class's methods, code, the number of local variables used in a method, and exceptions [19]. code analysis (1431 lines) Large parts of the code analysis subsection of the verifier were taken from a Java bytecode optimizer, Bali <ref> [16] </ref>. This software was originally written in C and was a converted to Java to interoperate with the prototype. Bali takes the raw data from the class decomposer (code and variables) and identifies structures within it that can be later used to perform dataflow analysis. <p> It also has the property that at any point in the code the contents of the stack can be statically determined. 26 In the prototype, the stack simulation algorithm determines the contents of the stack at every instruction in the code <ref> [16] </ref>. This information is used to perform dataflow analysis. Note that code which was built by a malicious compiler would be caught by the byte-code verifier explained in Section 3.1.
Reference: [17] <author> B. W. Lampson. </author> <title> "Protection." </title> <booktitle> Proceedings of the 5th Priceton Symposium on Information Sciences and Systems. </booktitle> <address> Princeton University, </address> <month> March </month> <year> 1971. </year> <pages> page 437-443. </pages> <booktitle> Reprinted in Operating Systems Review, </booktitle> <volume> 8(1) </volume> <pages> 18-24, </pages> <month> January </month> <year> 1974. </year>
Reference-contexts: To determine 11 COM.javasoft file read path COM.javasoft net connect remote_IP:port COM.javasoft awt maketoplevelwindow number whether the request may be accepted or not, the monitor must refer to a set of criteria. Typically, this criteria is represented within an access matrix <ref> [17] </ref> which binds principals to targets. In the reference monitor model, there must exist a mechanism by which users can maintain and update access matrixes. Sun microsystems accomplishes this using a configuration file, as in Figure 2.2.
Reference: [18] <author> B. W. Lampson. </author> <title> "A note on the confinement problem." </title> <journal> Communications of the ACM 16, </journal> <pages> 10 pages 613-615. </pages> <month> October </month> <year> 1973. </year>
Reference-contexts: If the rate were cleverly controlled it could become a Morse code which could encode private information. Essentially, there are an unlimited number of ways that covert channels can be implemented <ref> [18] </ref>, and this property makes it extremely difficult for a verifier to detect them in arbitrary code. Many sophisticated techniques have been devised to prevent covert channels [28]. But despite these efforts, no general solution to the problem has been found [23].
Reference: [19] <author> T. Lindholdm, F. Yellin. </author> <title> The Java Virtual Machine Specification. </title> <publisher> Addison-Wesley, </publisher> <year> 1996. </year>
Reference-contexts: Any assignment and data conversions in the code are checked. 3. Any branches must be made to legal locations (not outside of a method or to the middle of an instruction.) 1 This list is not exaustive. For a complete description of the bytecode verifier, see <ref> [19] </ref>. 15 4. Any registers that are used must be "live," i.e. they have had values assigned to them earlier in the program. 5. Parameters sent to opcodes and methods must be of the correct type and number. <p> The decomposer takes as input a classfile and makes visible to the programmer all the information that the classfile contains. The information used by the verifier includes the class's methods, code, the number of local variables used in a method, and exceptions <ref> [19] </ref>. code analysis (1431 lines) Large parts of the code analysis subsection of the verifier were taken from a Java bytecode optimizer, Bali [16]. This software was originally written in C and was a converted to Java to interoperate with the prototype.
Reference: [20] <author> P. Madany. "JavaOS(tm): </author> <title> A Standalone Java Environment". </title> <address> http://www.javasoft.com/docs/white/index.html </address>
Reference-contexts: Mobile code proponents envision a plethora of exciting new applications: users will be able to download anything from real-money casino games to customized tax preparation programs. Large-scale distributed computing may soon be possible, in which mobile code is embedded in everything from set-top-boxes to PDAs [36] <ref> [20] </ref>. Ultimately, many companies are banking that mobile code will make practical the long awaited network computer [4], thereby driving down the cost of maintaining a PC. In reality, mobile code technologies have been widely deployed in Internet browsers for several years.
Reference: [21] <author> G. McGraw, Edward W. Felten. </author> <title> "Java Security: Hostile Applets, Holes and Antidotes." </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1996. </year>
Reference: [22] <author> Microsoft Corporation. </author> <title> Proposal for Authenticating Code over the Internet April 1996. </title> <address> http://www.microsoft.com/intdev/security/authcode </address>
Reference-contexts: The criteria used by certification authorities to determine safety may not take into account the quality of the code. For example, the criteria used by the CA for Microsoft's ActiveX components is merely the fiscal reputation of the company which provided the component <ref> [22] </ref>. The idea is that if an accounting firm has certified that a company is financially responsible, the client will be able to trust the provider. The problem is that this is analogous to allowing car manufacturers to build unsafe cars simply because they are fiscally responsible. <p> Recently RSA-129 was broken in just one year [8]. Pure authentication is the name given to the security policies which use authentication and no other form of security. ActiveX <ref> [22] </ref> and Inferno [7] are examples of the pure authentication model. These systems will be further discussed in section 6. 13 2.4.3 Formal Verification The third verification technique is formal verification. In this strategy the downloaded applet is scanned by another program before it is run.
Reference: [23] <author> I. Moskowitz, A.R. Miller. </author> <title> "Covert Channels Hereto Stay?". </title> <booktitle> Proceedings of the IEEE Symposium on Research in Security and Privacy. </booktitle> <address> Oakland, CA. </address> <year> 1994. </year>
Reference-contexts: Many sophisticated techniques have been devised to prevent covert channels [28]. But despite these efforts, no general solution to the problem has been found <ref> [23] </ref>. Any applet which has both a network connection and access to private data risks a covert channel. For example, if the ftp applet had opened a file that was meant to be private, and also sent a public file using ftp, there could have been a covert channel.
Reference: [24] <institution> National Computer Security Center. Department of Defense Trusted Computer System Evaluation Criteria (The Orange Book). </institution> <year> 1985. </year>
Reference-contexts: In the next subsections we will lay down the design goals of the security in greater detail, and broadly discuss the architectural options. 2.2.1 Goals Several sets of criteria have been developed to evaluate and compare security policies [38] <ref> [24] </ref>. This thesis will focus on the following subset of the criteria developed in those papers. 1. The verifier must have fail-safe defaults. This means that the default level of protection on the system gives the applet no access to system resources.
Reference: [25] <author> G. Necula. </author> <title> "Proof-Carrying Code." </title> <booktitle> Proceedings of the 24th Symposium on Principles and Programming Languages. </booktitle> <month> January, </month> <year> 1997. </year>
Reference-contexts: However, in general it is not possible for an arbitrary program to be verified because this reduces to the halting problem [35]. "Proof carrying code" (PCC) could facilitate formal specification of applets <ref> [25] </ref>. Over the network, along with the applet, extra data is sent representing the "proof" that the code is safe. This data is analogous to the "witness" in an NP problem: it is used to prove that the data is safe. Unfortunately, it is very difficult to build the proof.
Reference: [26] <author> G. Nelson. </author> <title> Systems Programming in Modula-3. </title> <publisher> Prentice Hall. </publisher> <year> 1991. </year>
Reference-contexts: For example, an arbitrary integer cannot be stored into a pointer, and the index of a cell accessed in an array must be within the bounds defined when the array was created. The Spin project at the University of Washington relies in part on Modula-3's type safety for security <ref> [26] </ref> [6]. Java's basic security also depends on type safety; this will be further discussed in chapter 3. Type safe languages may be unfamiliar to system programmers used to C, or incompatible with existing software systems written in C.
Reference: [27] <author> Netscape Corporation. </author> <title> Secure Sockets Layer. </title> <note> 1997. http://www.netscape.com/info/security-doc.html </note>
Reference-contexts: One is that it creates new opportunities for spoofing attacks. The client must be certain that the decision made by the o*ine verifier reaches the client untampered over the network. While the mechanics of doing so are well understood <ref> [27] </ref>, it introduces another degree of complication. Secondly, latency is introduced. There is additional overhead incurred by the extra exchanges over the network between the client and verifier.
Reference: [28] <author> N. Ogurtsov, H. Orman, R. Schroeppel, S. O'Malley. </author> <title> "Covert Channel Elimination Protocols." </title> <institution> TR96-14. The University of Arizona. </institution>
Reference-contexts: Essentially, there are an unlimited number of ways that covert channels can be implemented [18], and this property makes it extremely difficult for a verifier to detect them in arbitrary code. Many sophisticated techniques have been devised to prevent covert channels <ref> [28] </ref>. But despite these efforts, no general solution to the problem has been found [23]. Any applet which has both a network connection and access to private data risks a covert channel.
Reference: [29] <author> J. Ousterhout, J. Levy, B. Welch. </author> <title> "The Safe-Tcl Security Model." </title> <month> May </month> <year> 1997. </year> <note> http://www.sunlabs.com/techrep/1997/abstract-60.html </note>
Reference-contexts: It may be that the PA knows what connections the client may contact legally, and these could be hardcoded into the policy. 24 3. The PA can prevent a network connection from being made in applets that have access to private data. Such applets would be called inside applets <ref> [29] </ref> because the registry could give them unrestricted read access to the client but no access to the network. Alternatively, dataflow verification could be used to disallow any access to the private disk if the applet is detected to make a network connection. <p> Therefore, security controls may not have to be as strict because the client will be presumably more technically adept and, therefore, be able to take on security responsibilities. 6.3 Safe-Tcl Tcl is an interpreted scripting language that is popular for GUI development. In a recent paper <ref> [29] </ref> the Safe-Tcl model was introduced. In Safe-Tcl two types of interpretors are used. Safe interpretors have total access to system resources- i.e. they can use any of the API routines to open files, etc.
Reference: [30] <author> J. Postel, J. Reynolds. </author> <title> "File Transfer Protocol". Request for Comments 959. </title> <month> October, </month> <year> 1985. </year>
Reference-contexts: This problem will be discussed further in section 7.1. 22 4.2 Dataflow Verification's Limitations This section will describe dataflow verification's limitations. By way of illustration, this section will consider the registry required to implement the file transfer protocol (ftp) <ref> [30] </ref>. In the ftp problem, the verifier must ensure that the applet only sends allowed data out onto the network, and no other data. Only the file indicated by the user may be made public. The simplified registry for ftp might do the following: 1.
Reference: [31] <author> Proebsting, Todd. </author> <title> "The Sumatra Project". </title> <address> http://www.cs.arizona.edu/sumatra </address>
Reference-contexts: The software is standalone- i.e. it is not integrated into a browser. Its architecture most closely resembles "ahead-of-time online verification" in Figure 2.1. Significant portions of the verifier were derived from pre-existing projects such as Sumatra <ref> [31] </ref> and Bali [16]. The major components of the prototype are described below. registry compiler (391 lines) This is a small compiler that converts the textual representation of a security policy (the registry) into a table which can be read by the dataflow analysis subsection of the verifier. <p> Conceptually, just-in-time security policies, in which a PA dynamically changes the client's security policy, could be implemented. This would require the registry compiler to be moved into the verifier. classfile decomposition (6291 lines) The classfile decomposition software was built by the Sumatra group <ref> [31] </ref>. The decomposer takes as input a classfile and makes visible to the programmer all the information that the classfile contains.
Reference: [32] <author> R. Rivest. </author> <title> "Cryptography." </title> <booktitle> Handbook of Theoretical Computer Science. Chapter 13. </booktitle> <publisher> Elsevier Science Publishers. </publisher> <year> 1990. </year>
Reference-contexts: In the language used in the security literature, the principal is the entity making the request, and the target is the system resource that the principal desires to access <ref> [32] </ref>. When an applet accesses a system resource, a reference monitor receives a request from a principal for a target. <p> As long as the private key is not made public, it is computationally hard for a malicious entity to guess the private key <ref> [32] </ref>. Public key encryption is the underlying technology behind many security solutions used for networks, including secure communications (SSL), electronic transactions (SET), and email encoding (S/MIME). PKE can also be used to construct digital signatures. A digital signature is a unique, recognizable proof that data originated from a particular source.
Reference: [33] <author> J. Saltzer. </author> <title> "Protection and the Control of Information Sharing in Multics". </title> <journal> Communications of the ACM. </journal> <volume> 17(7) </volume> <pages> 388-402. </pages> <month> July </month> <year> 1974. </year> <month> 37 </month>
Reference-contexts: Users will have a high degree of control over what the applet can do. For example, the user could specify the ability to open new windows, access particular directories, or create network connections. 16 Newer security features will incorporate protection domains <ref> [33] </ref>. This will make explicit the dis-tinctions between local systems modules and remote mobile code, as well as protect different applets from each other. Sun's implementation will allow a thread to enter multiple protection domains during the course of its execution.
Reference: [34] <author> M. Seltzer, Y. Endo, C. Small, K. Smith. </author> <title> "Dealing With Disaster: Surviving Misbehaved Kernel Extensions". </title> <booktitle> Proceedings of the 1996 Symposium on Operating System Design and Implementation (OSDI II) </booktitle>
Reference-contexts: SFI is the process of inserting checks around memory accesses in the code. These checks ensure that the accesses to memory are safe. The disadvantage to SFI is that the checks incur a performance penalty <ref> [34] </ref>. Finally, virtual memory address domains can also be used to protect memory [1]. In this strategy, the address space visible to programs is controlled by a protected kernel-level memory manager. Changing the address space can only be done via protected system calls.
Reference: [35] <author> M. Sipser. </author> <title> "Introduction to the Theory of Computation". </title> <publisher> PWS Publishing Company. </publisher> <year> 1997. </year>
Reference-contexts: The basic problem would be simulating on the program all inputs to show that the code executes in a safe way. However, in general it is not possible for an arbitrary program to be verified because this reduces to the halting problem <ref> [35] </ref>. "Proof carrying code" (PCC) could facilitate formal specification of applets [25]. Over the network, along with the applet, extra data is sent representing the "proof" that the code is safe.
Reference: [36] <author> D. L. Tennenhouse, J. M. Smith, W. Sincoskie, D. J. Wetherall, G. J. </author> <title> Minde. </title> <journal> "A Survey of Active Network Research" IEEE Communications Magazine. </journal> <volume> Vol. 35, No. 1, pp.80-86. </volume> <month> January </month> <year> 1997. </year>
Reference-contexts: Mobile code proponents envision a plethora of exciting new applications: users will be able to download anything from real-money casino games to customized tax preparation programs. Large-scale distributed computing may soon be possible, in which mobile code is embedded in everything from set-top-boxes to PDAs <ref> [36] </ref> [20]. Ultimately, many companies are banking that mobile code will make practical the long awaited network computer [4], thereby driving down the cost of maintaining a PC. In reality, mobile code technologies have been widely deployed in Internet browsers for several years. <p> Currently, mobile code usage is dominated by the server-web browser model. In the near future, however, mobile code may begin to be used in embedded controllers <ref> [36] </ref>. In that scenario, a server may 7 have the ability to push malicious code onto client hardware. Today's mobile code systems must be robust enough to adapt to tomorrow's threat models in which the attacks cannot be as easily foreseen.
Reference: [37] <author> R. Wahbe, S. Lucco, T.E. Anderson, S. Graham. </author> <title> "Efficient Software-Based Fault Isolation." </title> <booktitle> Proceedings of the Fourteenth Symposium on Operating Systems Principles. </booktitle> <year> 1993. </year>
Reference-contexts: Type safe languages may be unfamiliar to system programmers used to C, or incompatible with existing software systems written in C. For situations where a low level language such as C or assembly is used, a technique called Software fault isolation <ref> [37] </ref> (SFI) can be employed. SFI is the process of inserting checks around memory accesses in the code. These checks ensure that the accesses to memory are safe. The disadvantage to SFI is that the checks incur a performance penalty [34].
Reference: [38] <author> D. S. Wallach, Dirk Balfanz, Drew Dean, and Edward W. Felten. </author> <title> "Extensible Security Architectures for Java." </title> <type> Technical Report 546-97, </type> <institution> Department of Computer Science, Princeton University. </institution> <month> April </month> <year> 1997. </year>
Reference-contexts: In the next subsections we will lay down the design goals of the security in greater detail, and broadly discuss the architectural options. 2.2.1 Goals Several sets of criteria have been developed to evaluate and compare security policies <ref> [38] </ref> [24]. This thesis will focus on the following subset of the criteria developed in those papers. 1. The verifier must have fail-safe defaults. This means that the default level of protection on the system gives the applet no access to system resources. <p> Version 4.0 of Netscape's browser will also implement a reference monitor. In order to support run-time monitoring, Netscape extensively modified its virtual machine <ref> [38] </ref>. In the new VM, the call stack is annotated with the the invoking class's privileges. For example, suppose the user configured the monitor such that IBM applets had disk access. When a method in an IBM applet was entered, the VM would record the disk privileges onto the callstack.
References-found: 38

