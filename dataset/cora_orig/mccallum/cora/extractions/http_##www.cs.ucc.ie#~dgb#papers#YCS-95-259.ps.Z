URL: http://www.cs.ucc.ie/~dgb/papers/YCS-95-259.ps.Z
Refering-URL: http://www.cs.ucc.ie/~dgb/publist.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Inductive Bias in Case-Based Reasoning Systems  
Author: A D Griffiths and D G Bridge 
Date: July 26, 1995  
Abstract: In order to learn more about the behaviour of case-based reasoners as learning systems, we form-alise a simple case-based learner as a PAC learning algorithm, using the case-based representation hCB; i. We first consider a `naive' case-based learning algorithm CB1( H ) which learns by collecting all available cases into the case-base and which calculates similarity by counting the number of features on which two problem descriptions agree. We present results concerning the consistency of this learning algorithm and give some partial results regarding its sample complexity. We are able to characterise CB1( H ) as a `weak but general' learning algorithm. We then consider how the sample complexity of case-based learning can be reduced for specific classes of target concept by the application of inductive bias, or prior knowledge of the class of target concepts. Following recent work demonstrating how case-based learning can be improved by choosing a similarity measure appropriate to the concept being learnt, we define a second case-based learning `algorithm' CB2 which learns using the best possible similarity measure that might be inferred for the chosen target concept. While CB2 is not an executable learning strategy (since the chosen similarity measure is defined in terms of a priori knowledge of the actual target concept) it allows us to assess in the limit the maximum possible contribution of this approach to case-based learning. Also, in addition to illustrating the role of inductive bias, the definition of CB2 simplifies the general problem of establishing which functions might be represented in the form hCB; i. Reasoning about the case-based representation in this special case has therefore been a little more straight-forward than in the general case of CB1( H ), allowing more substantial results regarding representable functions and sample complexity to be presented for CB2. In assessing these results, we are forced to conclude that case-based learning is not the best approach to learning the chosen concept space (the space of monomial functions). We discuss, however, how our study has demonstrated, in the context of case-based learning, the operation of concepts well known in machine learning such as inductive bias and the trade-off between computational complexity and sample complexity. 
Abstract-found: 1
Intro-found: 1
Reference: [AA91] <author> M K Albert and D W Aha. </author> <title> Analyses of instance-based learning algorithms. </title> <booktitle> In AAAI-91: Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 553-558, </pages> <year> 1991. </year>
Reference-contexts: Hence result follows from Theorem 4.3 since the number of distinct binary functions that can be defined on D N is 2 2 N indicating that the hypothesis space of CB1 () must be finite. fl The PAC-Learnability results given for case-based classifiers in [AKA91] and <ref> [AA91] </ref> hold for concepts defined on real valued attributes. As a result of dealing with an uncountable example space, Albert and Aha have to modify the PAC learning framework by introducing constraints on the probability distribution on the example space before PAC-learnability can be proven. <p> Then by considering two different concepts of a `covering net' <ref> [AA91, p 554] </ref> [KV94, pp 57-58], we are able to present various upper bounds on the sample complexity of CB2 (Corollary 5.23 & Corollary 5.26). <p> This is easily done by considering the `covering net' technique applied to case-based learning algorithms by Albert and Aha <ref> [AA91] </ref>. Definition 5.9 *-Net for CB2. A set of instances D X is an *-net for CB2 w.r.t a target concept t iff, except for a set of exceptions X 0 occurring with probability &lt; * (X 0 X s.t. <p> D is an *-net iff: fx * Xj8d * D w t (d; x) &lt; 1g &lt; * The more elaborate method of constructing a bound on the sample complexity shown in <ref> [AA91] </ref> and [AKA91] is not necessary in the case of the finite example space D N . In the current context, the definition of a covering net is sufficient in itself to guarantee a good hypothesis, so a bound on the sample complexity can be established without any further assumptions. <p> * XjCB2 (x t )(x) = t (x)g &gt; 1 * and er (CB2 (x t ); t) = fx * XjCB2 (x t )(x) 6= t (x)g &lt; *. fl The probability of drawing an *-net in a training sample of a fixed size is calculated exactly as in <ref> [AA91] </ref>. <p> Proposition 5.22 c.f. <ref> [AA91, Lemma 2.1] </ref> [AKA91, Lemma 1] The probability of drawing a sample which is not an *-net for CB2 wrt t * M N;k is &lt; 2 k e m* m fx * X m jE x is not an *-net wrt t g &lt; 2 k e 2 k Proof:
Reference: [AB92] <author> M Anthony and N Biggs. </author> <title> Computational Learning Theory. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: In essence, we apply recent formalisations of the knowledge content of a case memory system from a functional point of view [Jan92] [WG94] within the PAC learning model [Hau90] [Nat91] <ref> [AB92] </ref> [KV94], due originally to Valiant [Val84b]. The functional viewpoint sees the case-base as a representation of a mapping between input and output values. <p> Definition 2.1 Error of an hypothesis <ref> [AB92, p.21] </ref>. <p> Definition 2.2 PAC-Learning <ref> [AB92, p.22] </ref>. <p> The size of training sample required to guarantee that a hypothesis is PAC within given values of ffi&* is referred to as the sample complexity. Definition 2.3 Sample Complexity <ref> [AB92, p.41] </ref>. <p> predictive of a concept space C is sufficient to ensure that CB1 () is a PAC learning algorithm for C. 12 Proof: Any learning algorithm which is consistent with respect to some concept space and which learns using a finite hypothesis space is a PAC-learning algorithm for that concept space <ref> [AB92, p.41] </ref>. <p> Definition 4.5 Behaviours of S: H (S) <ref> [AB92, p.73] </ref> The set of behaviours of S realised by a function class H, denoted H (S), is the set of subsets S 0 S s.t. there is some function h * H whose set of positive instances intersects with S to give S 0 . <p> H (S) = fS 0 Sj9h * H 8s * S h (s) = 1 $ s * S 0 g Definition 4.6 Growth function H (m) <ref> [AB92, p.73] </ref>. <p> H (m) = maxfj H (S)j jSj = mg Definition 4.7 Shattering <ref> [AB92, p.74] </ref>. A sample of size m is shattered by a space of functions H if and only if there is a function in H giving each possible classification of the sample i.e. H (m) = 2 m . Definition 4.8 VC Dimension [AB92, p.74]. <p> (S)j jSj = mg Definition 4.7 Shattering <ref> [AB92, p.74] </ref>. A sample of size m is shattered by a space of functions H if and only if there is a function in H giving each possible classification of the sample i.e. H (m) = 2 m . Definition 4.8 VC Dimension [AB92, p.74]. <p> the hypothesis space are equal and equation (23) is directly applicable. 17 h 5 10 6 ~ 230 ~ 460 10 ~ 3560 ~ 7200 Table 1: Values of m 0 = h fi (2 N log e 2 + log e h) Proposition 4.8 Cardinality of B N . <ref> [AB92, p.6] </ref> The set of functions B N has cardinality 2 2 N . Proof: The functions of B N are defined on the domain D N which has cardinality 2 N . <p> Consider the following results. Proposition 4.9 Cardinality of M N . <ref> [AB92, p.12] </ref> The set of functions M N has cardinality 3 N . <p> Therefore any sample shattered by M N will be shattered by H CB1 ( H ) M N;k , and the VC dimension of H CB1 ( H ) M N;k will be at least that of M N , which is O (N ) <ref> [AB92, p.76] </ref> [Hau88, p.193]. fl In contrast to corollary 4.18, note the following results: Proposition 4.19 Upper bound on VC Dimension of M N;k . The VC Dimension of M N;k is no greater than 1 + log 2 k . <p> Z k;i ^= #fD D 2 j (8D 00 * D 2 D 00 * D $ 9d * D 00 (d; 0) * CB) ! h hCB; w t i = tg (73) Lemma 5.2 Pascal's Triangle. e.g. <ref> [AB92, p.78] </ref> 8a; b 0 a + 1 b + 1 + a Proposition 5.3 The value of Z k;i is defined for all 0 i k as follows: Z k;i = x=0 x :2 k x Proof: by induction on i. BaseCase i = 0.
Reference: [AKA91] <author> D W Aha, D Kibler, and M K Albert. </author> <title> Instance-based learning algorithms. </title> <journal> Machine Learning, </journal> <volume> 6 </volume> <pages> 37-66, </pages> <year> 1991. </year>
Reference-contexts: d + and we conclude h hCB; H i (d fl ) = 1 for any d fl lying on a direct path between d and d + 1 where d + 1 is any positive exemplar labelling d. fl 4 Case-Based Learning with Fixed Similarity Measures Aha et al <ref> [AKA91, p.40] </ref> suggest that a particular case-based system of the kind discussed here is defined by the specification of a similarity function, classification function (c.f. our `semantics') and concept description update function. <p> Therefore "there are three possibilities to improve a case-based system: * store new cases in the case base CB * change the measure of similarity [] * change CB and []" [WG94, p.79] Many `case-based learning' algorithms have been defined illustrating these options; IB2 <ref> [AKA91] </ref>, VS-CBR [WG94] and PEBLS [CS93] [YJL94] show a number of options for adjusting the represented hypothesis. The current section will study the situation where concepts are learnt using a single fixed similarity measure, and the hypothesis is updated by alterations to the case-base alone. <p> In contrast with algorithms such as IB2 <ref> [AKA91] </ref> and other `instance filtering methods', which are deliberately more economical about the exemplars they retain [Cam92] [Zha92] [Bib95], this has the result that for a given target concept t, all possible case-bases CB t are reachable by the learning algorithm. <p> It is not always desirable for an algorithm to be consistent. This is certainly the case in noisy domains; the noise tolerant learner IB3 <ref> [AKA91] </ref> attempts to disagree with the training sample on precisely those instances which are suspected to be noisy, and Turney [Tur93] gives a formalisation of the sense in which a consistent hypothesis which always agrees with the training sample may be sub-optimal in the presence of noise. <p> Hence result follows from Theorem 4.3 since the number of distinct binary functions that can be defined on D N is 2 2 N indicating that the hypothesis space of CB1 () must be finite. fl The PAC-Learnability results given for case-based classifiers in <ref> [AKA91] </ref> and [AA91] hold for concepts defined on real valued attributes. As a result of dealing with an uncountable example space, Albert and Aha have to modify the PAC learning framework by introducing constraints on the probability distribution on the example space before PAC-learnability can be proven. <p> 13 sample in turn is presented to the case-base as a test instance, the correctness of the classification noted and then the same instance is added to the case memory as specified by CB1 ( H ). (This corresponds to the interleaved testing/learning algorithm IB1 described by Aha et al <ref> [AKA91, p.42] </ref>.) This is repeated for a large number of different training concepts and the proportion of correctly classified training instances is calculated for each value of M (the number of instances taken so far from the training sample). <p> D is an *-net iff: fx * Xj8d * D w t (d; x) &lt; 1g &lt; * The more elaborate method of constructing a bound on the sample complexity shown in [AA91] and <ref> [AKA91] </ref> is not necessary in the case of the finite example space D N . In the current context, the definition of a covering net is sufficient in itself to guarantee a good hypothesis, so a bound on the sample complexity can be established without any further assumptions. <p> Proposition 5.22 c.f. [AA91, Lemma 2.1] <ref> [AKA91, Lemma 1] </ref> The probability of drawing a sample which is not an *-net for CB2 wrt t * M N;k is &lt; 2 k e m* m fx * X m jE x is not an *-net wrt t g &lt; 2 k e 2 k Proof: Let G =
Reference: [BEHW87] <author> A Blumer, A Ehrenfeucht, D Haussler, and M K Warmuth. </author> <title> Occam's razor. </title> <journal> Information Processing Letters, </journal> <volume> 24 </volume> <pages> 377-380, </pages> <year> 1987. </year>
Reference-contexts: Definition 2.3, the sample complexity of a learning algorithm, gives a worst case size of training sample needed for the algorithm to achieve an accurate hypothesis with some degree of confidence. The following equation, known as the Blumer Bound <ref> [BEHW87, Lemma 2.1] </ref> [Hau88, Lemma 2.2], gives one upper bound for the sample complexity of any consistent learning algorithm using a finite hypothesis space, in terms of 15 16 the cardinality of that hypothesis space: m 0 (ffi; *) O 1 log ffi log jHj Alternatively, an upper bound on sample <p> The general upper bounds on sample complexity in the PAC framework ( i.e. those in terms of the VC dimension [BEHW89, Thm 2.1] and the `Blumer bound' <ref> [BEHW87, Lemma 2.1] </ref> [BEHW89, Thm 2.2] ), however, use a different notion of `covering net' to bound the size of training sample needed, defined in terms of the effective hypothesis space of the learning algorithm being used. This depends on the notion of the `error regions' of a learning algorithm. <p> respect to a target concept t * M N;k is &lt; (jH t j 1)e *m . m fx * X m jE x is not an *-transveral for error regions of CB2 w. r. t. t * M N;k g &lt; (jH t j 1):e *m Proof: As in <ref> [BEHW87, Lemma 2.1] </ref>, take a specific r * * (t); since r *, the probability of a randomly drawn example not falling in r must be &lt; (1 *), and the probability that no example in an m-sample falls in r is &lt; (1 *) m .
Reference: [BEHW89] <author> A Blumer, A Ehrenfeucht, D Haussler, and M K Warmuth. </author> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> Journal of the ACM, </journal> <volume> 36(4) </volume> <pages> 929-965, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: The hypothesis space is determined by the representation used by the system to express its approximations. In many other presentations of PAC learning results, such as the results of <ref> [BEHW89] </ref>, the concept space is often conflated with the hypothesis space; it is assumed that H = C. <p> some sample of size m is shattered by H. d V C (H) = maxfmj H (m) = 2 m g As an alternative to the `Blumer Bound', the following result also applying to any consistent learning algorithm, gives a bound on sample complexity in terms of this `VC dimension' <ref> [BEHW89, Thm 2.1 (ii)(a)] </ref> [Hau88, Thm 4.4]. Note that in general, d V C (H) log 2 jHj [Nat91, Lemma 2.1] and that d V C (H) and log jHj will often be quantities of the same order. <p> Note that in general, d V C (H) log 2 jHj [Nat91, Lemma 2.1] and that d V C (H) and log jHj will often be quantities of the same order. Blumer et al do however note exceptions to this correlation <ref> [BEHW89, p. 938] </ref>. m 0 (ffi; *) O 1 log ffi d V C (H) log * (24) Sample Complexity for B N Equations (23) and (24) are given in terms of the cardinality of the hypothesis space (23) and its VC dimension (24). <p> Corollary 5.23 is a poor bound, however, increasing as it does in k:2 k . For a tighter bound, the following section considers a better definition of a `covering net', as used in the derivation of the sample complexity results of Blumer et al <ref> [BEHW89] </ref>. Upper bound on Sample Complexity of CB2 Definition 5.9, as used in the technique of Albert and Aha, requires the training sample to give an exhaustive coverage of the example space in order to guarantee a good approximation to the target concept. <p> The general upper bounds on sample complexity in the PAC framework ( i.e. those in terms of the VC dimension <ref> [BEHW89, Thm 2.1] </ref> and the `Blumer bound' [BEHW87, Lemma 2.1] [BEHW89, Thm 2.2] ), however, use a different notion of `covering net' to bound the size of training sample needed, defined in terms of the effective hypothesis space of the learning algorithm being used. <p> The general upper bounds on sample complexity in the PAC framework ( i.e. those in terms of the VC dimension [BEHW89, Thm 2.1] and the `Blumer bound' [BEHW87, Lemma 2.1] <ref> [BEHW89, Thm 2.2] </ref> ), however, use a different notion of `covering net' to bound the size of training sample needed, defined in terms of the effective hypothesis space of the learning algorithm being used. This depends on the notion of the `error regions' of a learning algorithm. <p> This depends on the notion of the `error regions' of a learning algorithm. This is developed in the following statements, which differ from the formulation of <ref> [BEHW89] </ref> and [KV94] only in that the set of error regions (t) is defined in terms of H t , the set of hypotheses that might be output on training samples for a specific target concept, instead of the hypothesis space as a whole. 53 Definition 5.10 Error Regions [KV94, p.57]. <p> target concept t with respect to a hypothesis space H are the error regions in (t) for which the probability that a random example, drawn according to the fixed probability distribution, would fall into that region, is at least *. * (t) = fr * (t)jr *g Definition 5.12 *-Transversal <ref> [BEHW89, p.952] </ref> [KV94, p.58].
Reference: [Bib95] <author> Y Biberman. </author> <title> The role of prototypicality in exemplar-based learning. </title> <editor> In Nada Lavrac and Stefan Wrobel, editors, </editor> <booktitle> Machine Learning: ECML-95 (Proc. 8th European Conf. on Machine Learning, 1995), Lecture Notes in Artificial Intelligence 914, </booktitle> <pages> pages 77-91, </pages> <address> Berlin, Heidelberg, New York, 1995. </address> <publisher> Springer Verlag. </publisher>
Reference-contexts: In contrast with algorithms such as IB2 [AKA91] and other `instance filtering methods', which are deliberately more economical about the exemplars they retain [Cam92] [Zha92] <ref> [Bib95] </ref>, this has the result that for a given target concept t, all possible case-bases CB t are reachable by the learning algorithm.
Reference: [Cam92] <author> R M Cameron-Jones. </author> <title> Minimum description length instance-based learning. </title> <booktitle> In Proceedings of the Fifth Australian Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 368-373. </pages> <publisher> World Scientific, </publisher> <year> 1992. </year> <month> 60 </month>
Reference-contexts: In contrast with algorithms such as IB2 [AKA91] and other `instance filtering methods', which are deliberately more economical about the exemplars they retain <ref> [Cam92] </ref> [Zha92] [Bib95], this has the result that for a given target concept t, all possible case-bases CB t are reachable by the learning algorithm.
Reference: [CCK93] <author> R T Chi, M D Chen, and M Y Kiang. </author> <title> Generalised case-based reasoning system for portfolio management. </title> <journal> Expert Systems with Applications, </journal> <volume> 6(1) </volume> <pages> 67-76, </pages> <year> 1993. </year>
Reference-contexts: This is sometimes seen as characteristic of case-based learning, a tendency reflected in descriptions of case-based reasoning as a paradigm suitable for knowledge-poor domains e.g. <ref> [CCK93] </ref>. This stance seems incorrect; in contrast, Wess and Globig have already pointed out and ably demonstrated that "the [similarity] measure (respectively the way to modify the measure) is the bias of case-based reasoning" [WG94, p.90].
Reference: [CS93] <author> S Cost and S Salzberg. </author> <title> A weighted nearest neighbour algorithm for learning with symbolic features. </title> <journal> Machine Learning, </journal> <volume> 10(1) </volume> <pages> 37-66, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: Therefore "there are three possibilities to improve a case-based system: * store new cases in the case base CB * change the measure of similarity [] * change CB and []" [WG94, p.79] Many `case-based learning' algorithms have been defined illustrating these options; IB2 [AKA91], VS-CBR [WG94] and PEBLS <ref> [CS93] </ref> [YJL94] show a number of options for adjusting the represented hypothesis. The current section will study the situation where concepts are learnt using a single fixed similarity measure, and the hypothesis is updated by alterations to the case-base alone.
Reference: [Dea95] <author> A M Dearden. </author> <title> The use of formal models in the design of interactive case memory systems. </title> <type> PhD thesis, </type> <institution> University of York, UK, </institution> <year> 1995. </year>
Reference-contexts: Using the terminology of Dearden's model <ref> [Dea95] </ref>, the case-base is modelled as a set of pairs of `descriptions' and `reports'. As indicated above, a description is an N -bit vector from the space D N .
Reference: [DF86] <author> W H E Day and D P Faith. </author> <title> A model in partial orders for comparing objects by dualistic measures. </title> <journal> Mathemetical Biosciences, </journal> <volume> 78(2) </volume> <pages> 179-192, </pages> <year> 1986. </year>
Reference-contexts: Results elsewhere [JL93, Lemma 3] [Tur93, Lemma 7] formalise the intuition that a `reasonable' similarity measure [Tur93], which recognises that an object is more similar to itself than any other object, will be sufficient for consistency. This property is here called `definiteness' after Day and Faith <ref> [DF86, p.183] </ref>. Definition 4.3 Definiteness of a Similarity Measure.
Reference: [Glo95] <author> C Globig. </author> <title> Fallbasiertes reprasentieren und lernen von begriffsmengen ("Case-based representation and concept learning"). In Fallbasiertes Schliessen - Grundlagen & Anwendungen, Workshop auf der 3. </title> <institution> Deutschen Expertensystemtagung (XPS-95), University of Kaiserslaut-ern, </institution> <month> March </month> <year> 1995. </year> <title> Report LSA-95-02, Centre for Learning Systems and Applications, </title> <institution> University of Kaiserslautern, </institution> <year> 1995. </year>
Reference-contexts: However, this will not be true in the case of case-based representations using the unweighted feature count H , nor will it be true in general of other formulations of case-based learning, e.g. <ref> [Glo95] </ref> [SDHK95]. The `stability' of representations of target concepts with respect to w t is one corollary of the simplified semantics of the case-based representation in this special case.
Reference: [GW94] <author> C Globig and S Wess. </author> <title> Symbolic learning and nearest-neighbour classification. </title> <editor> In H-H Bock, W Lenski, and M M Richter, editors, </editor> <booktitle> Information Systems and Data Analysis: Prospects, Foundations, Applications. Proceedings of the 17th Annual Conference of the Gesellschaft fur Klassification e.V. </booktitle> <institution> University of Kaiserslautern, </institution> <address> March 3-5, 1993. </address> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: That is, with some prior knowledge of the concept space to be learnt, the similarity measure can be manipulated so that the hypotheses output by the case-based learner are more likely to be close to the possible target concepts. Such strategies demonstrably improve efficiency with respect to sample size <ref> [GW94] </ref> [WG94], although performance will obviously be degraded outside the chosen concept space. <p> A similar effect is demonstrated over a number of different similarity measures in the learning of concepts defined on ordinal-valued attributes in work by Globig & Wess <ref> [GW94] </ref>. 5.4 Sample Complexity of CB2 Having addressed basic issues of representability and consistency for CB2, and explored briefly the average case behaviour by empirical testing, we can now focus on the primary issue of the sample complexity of CB2.
Reference: [Hau88] <author> D Haussler. </author> <title> Quantifying inductive bias: AI learning algorithms and Valiant's learning framework. </title> <journal> Artificial Intelligence, </journal> <volume> 36 </volume> <pages> 177-221, </pages> <year> 1988. </year>
Reference-contexts: Definition 2.3, the sample complexity of a learning algorithm, gives a worst case size of training sample needed for the algorithm to achieve an accurate hypothesis with some degree of confidence. The following equation, known as the Blumer Bound [BEHW87, Lemma 2.1] <ref> [Hau88, Lemma 2.2] </ref>, gives one upper bound for the sample complexity of any consistent learning algorithm using a finite hypothesis space, in terms of 15 16 the cardinality of that hypothesis space: m 0 (ffi; *) O 1 log ffi log jHj Alternatively, an upper bound on sample complexity may be <p> m is shattered by H. d V C (H) = maxfmj H (m) = 2 m g As an alternative to the `Blumer Bound', the following result also applying to any consistent learning algorithm, gives a bound on sample complexity in terms of this `VC dimension' [BEHW89, Thm 2.1 (ii)(a)] <ref> [Hau88, Thm 4.4] </ref>. Note that in general, d V C (H) log 2 jHj [Nat91, Lemma 2.1] and that d V C (H) and log jHj will often be quantities of the same order. <p> Therefore any sample shattered by M N will be shattered by H CB1 ( H ) M N;k , and the VC dimension of H CB1 ( H ) M N;k will be at least that of M N , which is O (N ) [AB92, p.76] <ref> [Hau88, p.193] </ref>. fl In contrast to corollary 4.18, note the following results: Proposition 4.19 Upper bound on VC Dimension of M N;k . The VC Dimension of M N;k is no greater than 1 + log 2 k . <p> M N;k (with respect to sample complexity) compared to a consistent learning algorithm which can represent only the functions M N;k . 30 We suggest that this is a natural corollary of the generality of CB1 ( H ); this seems a clear example of the concept of inductive bias <ref> [Hau88] </ref> [Sch94]. `Bias' refers to any prior information or knowledge that might be encoded in a learning algorithm that defines a preference for choosing a hypothesis from the many that might be available to account for the training data. "If a bias is strong and correct, then the concept-learning task is <p> be guided to the selection of the target concept" [Utg86, p.114], while "[if no inductive bias] is supplied for comparing competing hypotheses [consistent with the available exemplars], than all possible classifications of the unseen instances are equally possible and no inductive method can do better on average than random guessing" <ref> [Hau88, p.178] </ref>. Altering the `bias' of a learning algorithm allows a trade-off between generality and sample complexity to be managed; more bias will lead to greater accuracy for the same size of training sample, but the increased bias will only be correct for a small number of possible target concepts.
Reference: [Hau90] <author> D Haussler. </author> <title> Probably approximately correct learning. </title> <booktitle> In AAAI-90 Proceedings of the Eight National Conference on Artificial Intelligence, </booktitle> <address> Boston, MA, </address> <pages> pages 1101-1108. </pages> <booktitle> American Association for Artificial Intelligence, </booktitle> <year> 1990. </year>
Reference-contexts: 1 Introduction This report introduces a simple model that allows the analysis of the learning behaviour of a case-based reasoning system. In essence, we apply recent formalisations of the knowledge content of a case memory system from a functional point of view [Jan92] [WG94] within the PAC learning model <ref> [Hau90] </ref> [Nat91] [AB92] [KV94], due originally to Valiant [Val84b]. The functional viewpoint sees the case-base as a representation of a mapping between input and output values. <p> Equations (23) and (24) are taken as support for the intuition that, in general, the larger the hypothesis space, the more training examples the learner must see in order to discriminate between the available hypotheses, and choose a hypothesis that is accurate with high probability <ref> [Hau90, p.1103] </ref>. It is important to note that while arguments of this kind will be assumed in what follows, such a conclusion strictly depends on the specific properties of the learning algorithm using the hypothesis space. <p> We suggest that this is an example of a general trade-off between sample complexity and computational complexity that has been discovered in the PAC-learning framework <ref> [Hau90, p.1103] </ref>.
Reference: [Jan92] <editor> K P Jantke. </editor> <title> Case-based learning and inductive inference. </title> <type> GOSLER report 08/92, </type> <institution> FB Mathematik & Informatik, TH Leipzig, </institution> <year> 1992. </year>
Reference-contexts: 1 Introduction This report introduces a simple model that allows the analysis of the learning behaviour of a case-based reasoning system. In essence, we apply recent formalisations of the knowledge content of a case memory system from a functional point of view <ref> [Jan92] </ref> [WG94] within the PAC learning model [Hau90] [Nat91] [AB92] [KV94], due originally to Valiant [Val84b]. The functional viewpoint sees the case-base as a representation of a mapping between input and output values. <p> In contrast with the inductive inference approach of Jantke <ref> [Jan92] </ref> and the informal approach of Wess and Globig [WG94], this `probably approximate correct' approach has allowed us in some cases to set bounds on the number of exemplars needed to guarantee a good approximation to the domain relation. <p> of a training sample proven theoretically to guarantee a probably approximately correct hypothesis (for all target concepts and all probability distributions). m 0 may however be larger than the actual sample complexity due to approximations made in the proof. 3 Case-Based Representation of Classification Functions Following the work of Jantke <ref> [Jan92] </ref>, a case memory system is modelled as the pair hCB; i where CB is the case-base, or set of stored exemplars, assumed here to be free from observational error, and is a similarity measure defined for the space D N . <p> In relation to other semantics discussed by Jantke <ref> [Jan92] </ref>, this interpretation resolves `ties' between equally similar near neighbours by imposing a preference ordering on the `report' part of retrieved cases.
Reference: [JL93] <editor> K P Jantke and S Lange. </editor> <booktitle> Case-based representation and learning of pattern languages. In EWCBR-93 Working Notes of the first European Workshop on Case-Based Reasoning, </booktitle> <volume> volume 1, </volume> <pages> pages 139-144. </pages> <institution> University of Kaiserslautern, </institution> <year> 1993. </year>
Reference-contexts: of similarity between the two instances: : (D N fi D N ) ! [0; 1] The pair hCB; i is treated as the representation of a function from B N , according to the following interpretation related to the `standard semantics' for a case-based classifier of Jantke and Lange <ref> [JL93] </ref>. <p> The main result of this section, Theorem 4.3, gives necessary and sufficient conditions over to make CB1 () a consistent learning algorithm. This will be a valuable tool in making use of the sample complexity results for consistent learning algorithms. Results elsewhere <ref> [JL93, Lemma 3] </ref> [Tur93, Lemma 7] formalise the intuition that a `reasonable' similarity measure [Tur93], which recognises that an object is more similar to itself than any other object, will be sufficient for consistency. This property is here called `definiteness' after Day and Faith [DF86, p.183].
Reference: [KV94] <author> M J Kearns and U V Varizani. </author> <title> An Introduction to Computational Learning Theory. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: In essence, we apply recent formalisations of the knowledge content of a case memory system from a functional point of view [Jan92] [WG94] within the PAC learning model [Hau90] [Nat91] [AB92] <ref> [KV94] </ref>, due originally to Valiant [Val84b]. The functional viewpoint sees the case-base as a representation of a mapping between input and output values. <p> Then by considering two different concepts of a `covering net' [AA91, p 554] <ref> [KV94, pp 57-58] </ref>, we are able to present various upper bounds on the sample complexity of CB2 (Corollary 5.23 & Corollary 5.26). <p> This depends on the notion of the `error regions' of a learning algorithm. This is developed in the following statements, which differ from the formulation of [BEHW89] and <ref> [KV94] </ref> only in that the set of error regions (t) is defined in terms of H t , the set of hypotheses that might be output on training samples for a specific target concept, instead of the hypothesis space as a whole. 53 Definition 5.10 Error Regions [KV94, p.57]. <p> of [BEHW89] and [KV94] only in that the set of error regions (t) is defined in terms of H t , the set of hypotheses that might be output on training samples for a specific target concept, instead of the hypothesis space as a whole. 53 Definition 5.10 Error Regions <ref> [KV94, p.57] </ref>. <p> on which a hypothesis in H t H, i.e. a hypothesis in H that might be output on a training sample for t, will disagree with the target concept t. (t) = fh Xj9h * H t h = fx * Xjh (x) 6= t (x)gg Definition 5.11 *-Error Regions <ref> [KV94, p.57] </ref>. <p> t with respect to a hypothesis space H are the error regions in (t) for which the probability that a random example, drawn according to the fixed probability distribution, would fall into that region, is at least *. * (t) = fr * (t)jr *g Definition 5.12 *-Transversal [BEHW89, p.952] <ref> [KV94, p.58] </ref>. <p> <ref> [KV94, p.58] </ref>. An *-transversal for a set of error regions (t) is a set S X s.t. for every error region r with sum probability at least *, there is some element s * S which is also in r. 8r * * (t) S " r 6= Proposition 5.24 [KV94, p.58] Consider an hypothesis space H, a target concept t * B N and a training sample x s.t. the set of exemplars contained in x, E x = S 1im fx i g, is an *-transversal for the error regions of H w.r.t. t.
Reference: [LI93] <author> P Langley and W Iba. </author> <title> Average-case analysis of a nearest neighbour algorithm. </title> <editor> In R Bajcsy, editor, </editor> <booktitle> IJCAI-93: Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <volume> volume 2, </volume> <pages> pages 889-894. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: We wish to study this case from the point of view of inductive bias, since Langley & Iba's meticulous average case analysis of a `nearest neighbour algorithm for learning conjunctive concepts' <ref> [LI93] </ref> corresponds exactly to the case of learning M N;k by CB1 ( H ). The previous experiments were repeated for 250 instances of M N;k for values of k between 1 & 3, and for N = 6. Results from these experiments are shown in Figure 4.
Reference: [Mur71] <author> S Muroga. </author> <title> Threshold Logic and its Applications. </title> <publisher> John Wiley & Sons, </publisher> <year> 1971. </year>
Reference-contexts: Proposition 5.12 depends on the results of Propositions 5.10 and 5.11, while Proposition 5.15 builds on 5.13 and 5.14. The expression of these results also depends on some notions of minimal and irreducible boolean representations of functions which are stated immediately below. These are reproduced from <ref> [Mur71] </ref>, but equivalent statements should be found in any work on switching theory. 41 Definition 5.5 [Mur71, Defn 2.1.8] If there exists a disjunctive form for a function f * B N such that the literal u i does not appear in any term of this form, then f is said <p> The expression of these results also depends on some notions of minimal and irreducible boolean representations of functions which are stated immediately below. These are reproduced from [Mur71], but equivalent statements should be found in any work on switching theory. 41 Definition 5.5 <ref> [Mur71, Defn 2.1.8] </ref> If there exists a disjunctive form for a function f * B N such that the literal u i does not appear in any term of this form, then f is said to be positive in u i , u i is a positive variable of f and <p> to be negative in u i . (Note that f is both positive and negative in a variable u i if neither u i nor u i appear in a particular disjunctive form for f , or the value of f is otherwise independent of u i .) Definition 5.6 <ref> [Mur71, Defn 2.1.8] </ref> A function that is positive in all variables is a positive function. A function that is negative in all variables is a negative function. Definition 5.7 [Mur71, Defn 2.1.8] If f or a disjunctive form representing f is either positive or negative in a variable u i , <p> a particular disjunctive form for f , or the value of f is otherwise independent of u i .) Definition 5.6 <ref> [Mur71, Defn 2.1.8] </ref> A function that is positive in all variables is a positive function. A function that is negative in all variables is a negative function. Definition 5.7 [Mur71, Defn 2.1.8] If f or a disjunctive form representing f is either positive or negative in a variable u i , then f is said to be unate in u i . <p> A function (or a disjunctive form) which is unate in all variables is called a unate function (or a unate disjunctive form). Theorem 5.9 <ref> [Mur71, Thm 2.1.6] </ref> A unate function f has exactly one irreducible disjunctive form. Furthermore, the form is unate and consists of all prime implicants of the function.
Reference: [Nat91] <author> B K Natarajan. </author> <title> Machine Learning: A Theoretical Approach. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: 1 Introduction This report introduces a simple model that allows the analysis of the learning behaviour of a case-based reasoning system. In essence, we apply recent formalisations of the knowledge content of a case memory system from a functional point of view [Jan92] [WG94] within the PAC learning model [Hau90] <ref> [Nat91] </ref> [AB92] [KV94], due originally to Valiant [Val84b]. The functional viewpoint sees the case-base as a representation of a mapping between input and output values. <p> Note that in general, d V C (H) log 2 jHj <ref> [Nat91, Lemma 2.1] </ref> and that d V C (H) and log jHj will often be quantities of the same order.
Reference: [PV88] <author> L Pitt and L G Valiant. </author> <title> Computational limitations on learning from examples. </title> <journal> Journal of the ACM, </journal> <volume> 35(4) </volume> <pages> 965-984, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: We suggest that this is an example of a general trade-off between sample complexity and computational complexity that has been discovered in the PAC-learning framework [Hau90, p.1103]. Pitt and Valiant <ref> [PV88] </ref> present an example where one choice of representation makes the task of learning k-term DNF formulae computationally intractable, while a different representation (representing a larger class of functions) makes the learning task feasible at the cost of enlarging the hypothesis space and increasing the sample complexity.
Reference: [Sch94] <author> C Schaffer. </author> <title> A conservation law for generalization performance. </title> <booktitle> In ML94: Proceedings of the International Conference on Machine Learning, </booktitle> <address> New Brunswick, New Jersey, </address> <pages> pages 259-265. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1994. </year>
Reference-contexts: N;k (with respect to sample complexity) compared to a consistent learning algorithm which can represent only the functions M N;k . 30 We suggest that this is a natural corollary of the generality of CB1 ( H ); this seems a clear example of the concept of inductive bias [Hau88] <ref> [Sch94] </ref>. `Bias' refers to any prior information or knowledge that might be encoded in a learning algorithm that defines a preference for choosing a hypothesis from the many that might be available to account for the training data. "If a bias is strong and correct, then the concept-learning task is relatively
Reference: [SDHK95] <author> S Salzberg, A Delcher, D Heath, and S Kasif. </author> <title> Best-case results for nearest neighbour learning. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 17(6) </volume> <pages> 599-608, </pages> <month> June </month> <year> 1995. </year> <month> 61 </month>
Reference-contexts: However, this will not be true in the case of case-based representations using the unweighted feature count H , nor will it be true in general of other formulations of case-based learning, e.g. [Glo95] <ref> [SDHK95] </ref>. The `stability' of representations of target concepts with respect to w t is one corollary of the simplified semantics of the case-based representation in this special case.
Reference: [Tur93] <author> P Turney. </author> <title> Theoretical analyses of cross-validation error and voting in instance-based learn-ing. </title> <type> Technical Report NRC-35073, </type> <institution> Knowledge Systems Laboratory, Institute for Information Technology, National Research Council (Canada), </institution> <year> 1993. </year>
Reference-contexts: It is not always desirable for an algorithm to be consistent. This is certainly the case in noisy domains; the noise tolerant learner IB3 [AKA91] attempts to disagree with the training sample on precisely those instances which are suspected to be noisy, and Turney <ref> [Tur93] </ref> gives a formalisation of the sense in which a consistent hypothesis which always agrees with the training sample may be sub-optimal in the presence of noise. <p> The main result of this section, Theorem 4.3, gives necessary and sufficient conditions over to make CB1 () a consistent learning algorithm. This will be a valuable tool in making use of the sample complexity results for consistent learning algorithms. Results elsewhere [JL93, Lemma 3] <ref> [Tur93, Lemma 7] </ref> formalise the intuition that a `reasonable' similarity measure [Tur93], which recognises that an object is more similar to itself than any other object, will be sufficient for consistency. This property is here called `definiteness' after Day and Faith [DF86, p.183]. Definition 4.3 Definiteness of a Similarity Measure. <p> This will be a valuable tool in making use of the sample complexity results for consistent learning algorithms. Results elsewhere [JL93, Lemma 3] [Tur93, Lemma 7] formalise the intuition that a `reasonable' similarity measure <ref> [Tur93] </ref>, which recognises that an object is more similar to itself than any other object, will be sufficient for consistency. This property is here called `definiteness' after Day and Faith [DF86, p.183]. Definition 4.3 Definiteness of a Similarity Measure.
Reference: [Utg86] <author> P E Utgoff. </author> <title> Shift of bias for inductive concept learning. </title> <editor> In R S Michalski, J G Carbonell, and T M Mitchell, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach (Volume 2). </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1986. </year>
Reference-contexts: algorithm that defines a preference for choosing a hypothesis from the many that might be available to account for the training data. "If a bias is strong and correct, then the concept-learning task is relatively easy because the concept learner will be guided to the selection of the target concept" <ref> [Utg86, p.114] </ref>, while "[if no inductive bias] is supplied for comparing competing hypotheses [consistent with the available exemplars], than all possible classifications of the unseen instances are equally possible and no inductive method can do better on average than random guessing" [Hau88, p.178].
Reference: [Val84a] <author> L G Valiant. </author> <title> Deductive learning. </title> <journal> Philosophical Transactions of the Royal Philosophical Society of London A, </journal> <volume> 312 </volume> <pages> 441-446, </pages> <year> 1984. </year>
Reference-contexts: This apparently elaborate algorithm can be understood in relation to the `standard learning algorithm for monomials' <ref> [Val84a] </ref>. A single positive exemplar is kept as a `prototype' of the monomial concept. In the same fashion as in the standard monomial algorithm, the other positive exemplars are used to determine whether or not a specific bit is necessary to the definition of the concept. <p> Finally, consider a modification of VS-CBR (Definition 5.1) which infers a hypothesis h hCB; M U i rather than h hCB; w i . In this case the algorithm will be exactly congruent with the standard learning algorithm for monomial functions of <ref> [Val84a] </ref>; the hypothesis output by either algorithm will be identical for any training sample for a monomial target concept t * M N .
Reference: [Val84b] <author> L G Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27 </volume> <pages> 1134-1142, </pages> <year> 1984. </year>
Reference-contexts: In essence, we apply recent formalisations of the knowledge content of a case memory system from a functional point of view [Jan92] [WG94] within the PAC learning model [Hau90] [Nat91] [AB92] [KV94], due originally to Valiant <ref> [Val84b] </ref>. The functional viewpoint sees the case-base as a representation of a mapping between input and output values.
Reference: [WG94] <author> S Wess and C Globig. </author> <title> Case-based and symbolic classification algorithms A case study using version space. </title> <editor> In S Wess, K-D Althoff, and M M Richter, editors, </editor> <booktitle> Topics in CBR: Selected papers from the First European Workshop on Case-Based Reasoning - EWCBR-93, </booktitle> <address> Kaiserslautern, Germany, </address> <month> November '93, </month> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 837, </volume> <pages> pages 77-91. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: 1 Introduction This report introduces a simple model that allows the analysis of the learning behaviour of a case-based reasoning system. In essence, we apply recent formalisations of the knowledge content of a case memory system from a functional point of view [Jan92] <ref> [WG94] </ref> within the PAC learning model [Hau90] [Nat91] [AB92] [KV94], due originally to Valiant [Val84b]. The functional viewpoint sees the case-base as a representation of a mapping between input and output values. <p> In contrast with the inductive inference approach of Jantke [Jan92] and the informal approach of Wess and Globig <ref> [WG94] </ref>, this `probably approximate correct' approach has allowed us in some cases to set bounds on the number of exemplars needed to guarantee a good approximation to the domain relation. This has been our main means of comparing the different forms of case-based learning in the work reported below. <p> (u 1 u 2 + u 1 u 3 + u 2 u 3 ):u 3 u 4 + u 1 :u 2 u 4 7 It is clear that, in contrast with other symbolic AI approaches to machine learning, hCB; i is an implicit representation of the system's state <ref> [WG94, p.79] </ref>. That is, it is difficult to understand by inspection of the pair precisely what function is currently represented. A little experimentation with the representation shows that large changes to the boolean form of a function can result from small changes to the representing case-base and vice-versa. <p> Therefore "there are three possibilities to improve a case-based system: * store new cases in the case base CB * change the measure of similarity [] * change CB and []" <ref> [WG94, p.79] </ref> Many `case-based learning' algorithms have been defined illustrating these options; IB2 [AKA91], VS-CBR [WG94] and PEBLS [CS93] [YJL94] show a number of options for adjusting the represented hypothesis. <p> Therefore "there are three possibilities to improve a case-based system: * store new cases in the case base CB * change the measure of similarity [] * change CB and []" [WG94, p.79] Many `case-based learning' algorithms have been defined illustrating these options; IB2 [AKA91], VS-CBR <ref> [WG94] </ref> and PEBLS [CS93] [YJL94] show a number of options for adjusting the represented hypothesis. The current section will study the situation where concepts are learnt using a single fixed similarity measure, and the hypothesis is updated by alterations to the case-base alone. <p> In other words, two distinct objects may be assigned maximal similarity only if they are classified the same by all relevant classification functions f . This is recognised informally as a necessary condition by Wess and Globig <ref> [WG94, p.86] </ref>. We express it within our framework in our definition of predictivity and prove it a necessary and sufficient condition over to make CB1 () a consistent learning algorithm. Definition 4.4 Predictivity of a Similarity Measure with respect to a concept space C. <p> This stance seems incorrect; in contrast, Wess and Globig have already pointed out and ably demonstrated that "the [similarity] measure (respectively the way to modify the measure) is the bias of case-based reasoning" <ref> [WG94, p.90] </ref>. That is, with some prior knowledge of the concept space to be learnt, the similarity measure can be manipulated so that the hypotheses output by the case-based learner are more likely to be close to the possible target concepts. <p> Such strategies demonstrably improve efficiency with respect to sample size [GW94] <ref> [WG94] </ref>, although performance will obviously be degraded outside the chosen concept space. <p> An algorithm suitable for learning M N which both constructs a case-base and manipulates the similarity measure is presented by Globig & Wess <ref> [WG94, Fig 4] </ref>, given below as definition 5.1. The definition refers to the weighted feature sum w of definition 3.2. Definition 5.1 VS-CBR Learning Algorithm for Functions in M N c.f. [WG94, Fig 4] define the functions f i : f0; 1g ! f0; 1g, s.t. f i (n) = 1, <p> learning M N which both constructs a case-base and manipulates the similarity measure is presented by Globig & Wess <ref> [WG94, Fig 4] </ref>, given below as definition 5.1. The definition refers to the weighted feature sum w of definition 3.2. Definition 5.1 VS-CBR Learning Algorithm for Functions in M N c.f. [WG94, Fig 4] define the functions f i : f0; 1g ! f0; 1g, s.t. f i (n) = 1, 1 i N; n * f0; 1g set CB = ; if b i = 1 then if :9d * D N (d; 1) * CB then set CB = CB <p> As in <ref> [WG94] </ref>, let define an equivalence relation s.t. d 1 d 2 $ (d 1 ; d 2 ) = 1. <p> As in [WG94], let define an equivalence relation s.t. d 1 d 2 $ (d 1 ; d 2 ) = 1. As Wess and Globig <ref> [WG94, p.86] </ref> state, the same classification must be shared by all descriptions in each equivalence class in the partition hD N n i for any function defined by the similarity function , and in addition the similarity of two descriptions in such an equivalence class to any d * D N
Reference: [YJL94] <author> Yasubumi S, </author> <title> K P Jantke, and S Lange. Learning languages by collecting cases and tuning parameters. </title> <booktitle> In ALT94: Proceedings of Fifth International Conference on Algorithmic Learning Theory, </booktitle> <year> 1994. </year>
Reference-contexts: Therefore "there are three possibilities to improve a case-based system: * store new cases in the case base CB * change the measure of similarity [] * change CB and []" [WG94, p.79] Many `case-based learning' algorithms have been defined illustrating these options; IB2 [AKA91], VS-CBR [WG94] and PEBLS [CS93] <ref> [YJL94] </ref> show a number of options for adjusting the represented hypothesis. The current section will study the situation where concepts are learnt using a single fixed similarity measure, and the hypothesis is updated by alterations to the case-base alone.
Reference: [Zha92] <author> J Zhang. </author> <title> Selecting typical instances in instance-based learning. </title> <booktitle> In ML92: Proceedings of the 9th International Conference on Machine Learning, </booktitle> <pages> pages 470-479. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: In contrast with algorithms such as IB2 [AKA91] and other `instance filtering methods', which are deliberately more economical about the exemplars they retain [Cam92] <ref> [Zha92] </ref> [Bib95], this has the result that for a given target concept t, all possible case-bases CB t are reachable by the learning algorithm.
References-found: 31

