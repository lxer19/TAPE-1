URL: http://www.cs.iastate.edu/~lutz/p16.ps
Refering-URL: http://www.cs.iastate.edu/~lutz/papers.html
Root-URL: http://www.cs.iastate.edu
Title: The Complexity and Distribution of Hard Problems hard for E and other complexity classes. Tight
Author: David W. Juedes and Jack H. Lutz m -degree 
Note: m  similarly in E 2 This latter fact is seen to be  (e.g., the degree of all P m -complete languages for NP) has measure 0 in E and in E 2  
Address: Ames, IA 50011  
Affiliation: Department of Computer Science Iowa State University  
Abstract: Measure-theoretic aspects of the P m -reducibility structure of the exponential time complexity classes E=DTIME(2 linear ) and E 2 = DTIME(2 polynomial ) are investigated. Particular attention is given to the complexity (measured by the size of complexity cores) and distribution (abundance in the sense of measure) of languages that are P 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Ambos-Spies. </author> <title> Randomness, relativizations, and polynomial reducibilities. </title> <booktitle> In Proceedings of the First Structure in Complexity Theory Conference, </booktitle> <pages> pages 23-34, </pages> <year> 1986. </year>
Reference-contexts: This completes the proof of 1. The proof of 2 is identical. One need only note that, if A 2 E 2 , then d 2 p 2 . 2 Remark. Ambos-Spies <ref> [1] </ref> has shown that P m (A) has Lebesgue measure 0 whenever A 62 P. Lemma 5.2 obtains a stronger conclusion (resource-bounded measure 0) from a stronger hypothesis on A. It is now straightforward to derive consequences of these results for the structure of E and E 2 .
Reference: [2] <author> J. L. Balcazar, J. Daz, and J. Gabarro. </author> <title> Structural Complexity I. </title> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: We write E = c=1 DTIME (2 cn ) and 1 [ DTIME (2 n c ) for the classes of languages decidable in 2 linear time and 2 polynomial time, respectively. Other complexity classes that we use here, such as NP, PH, PSPACE, etc., have completely standard definitions <ref> [2, 3] </ref>. If A and B are languages, then a polynomial time, many-one reduction (briefly P m - reduction) of A to B is a function f 2 PF such that A = f 1 (B) = fx j f (x) 2 Bg.
Reference: [3] <author> J. L. Balcazar, J. Daz, and J. Gabarro. </author> <title> Structural Complexity II. </title> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: We write E = c=1 DTIME (2 cn ) and 1 [ DTIME (2 n c ) for the classes of languages decidable in 2 linear time and 2 polynomial time, respectively. Other complexity classes that we use here, such as NP, PH, PSPACE, etc., have completely standard definitions <ref> [2, 3] </ref>. If A and B are languages, then a polynomial time, many-one reduction (briefly P m - reduction) of A to B is a function f 2 PF such that A = f 1 (B) = fx j f (x) 2 Bg. <p> Thus F is the set of all strings that M "decides efficiently.") Remark. The above definition quantifies over all machines consistent with A, while the standard definition of complexity cores (cf. <ref> [3] </ref>) quantifies only over machines that decide A. For recursive languages A (and time-constructible bounds t), it is easy to see that the above definition is exactly equivalent to the standard definition. However, the above definition is stronger than the standard definition when A is not recursive. <p> For example, consider tally languages (i.e., languages A f0g fl ). Under our definition, every DTIME (n)-complexity core K of every tally language must satisfy jK f0g fl j &lt; 1. However, under the standard definition, complexity cores are only defined for recursive sets A (as in <ref> [3] </ref>), or else every set K f0; 1g fl is vacuously a complexity core for every nonrecursive language (tally or otherwise). Thus by quantifying over all machines consistent with A, our definition makes the notion of complexity core meaningful for nonrecursive languages A.
Reference: [4] <author> J. L. Balcazar and U. Schoning. </author> <title> Bi-immune sets for complexity classes. </title> <journal> Mathematical Systems Theory, </journal> <volume> 18 </volume> <pages> 1-10, </pages> <year> 1985. </year> <month> 23 </month>
Reference-contexts: Our first observation, an obvious generalization of a result of Balcazar and Schoning <ref> [4] </ref> (see Corollary 4.2 below), relates incompressibility to complexity cores. Lemma 4.1. If t : N ! N is time constructible, then every language that is incompressible by DTIME (t) m -reductions has f0; 1g fl as a DTIME (t)-complexity core. Proof. <p> Since F is infinite, at least one of the sets f 1 (fug), f 1 (fvg) is infinite, so the collision set C f is infinite. Thus A is not incompressible by DTIME (t) m -reductions. 2 Corollary 4.2. Let c 2 N. 1 (Balcazar and Schoning <ref> [4] </ref>). Every language that is incompressible by P m -reductions has f0; 1g fl as a P-complexity core. 2. Every language that is incompressible by DTIME (2 cn ) m -reductions has f0; 1g fl as a DTIME (2 cn )-complexity core. 3.
Reference: [5] <author> C. H. Bennett and J. Gill. </author> <title> Relative to a random oracle A, P A 6= NP A 6= co-NP A with probability 1. </title> <journal> SIAM Journal on Computing, </journal> <volume> 10 </volume> <pages> 96-113, </pages> <year> 1981. </year>
Reference-contexts: It is reasonable to conjecture that most of our results hold with P m replaced by P T , but investigating this may be difficult. For example, consider Theorem 5.3. Bennett and Gill <ref> [5] </ref> have shown that P 1 T (A) has (classical) measure 1 for all A 2 BPP. Thus we cannot prove that the P T -hard languages for E form a measure 0 set without also proving that E 6 BPP.
Reference: [6] <author> L. Berman. </author> <title> On the structure of complete sets: Almost everywhere complexity and infinitely often speedup. </title> <booktitle> In Proceedings of the Seventeenth Annual Conference on Foundations of Computer Science, </booktitle> <pages> pages 76-80, </pages> <year> 1976. </year>
Reference-contexts: Languages that are P m -hard for E are typically considered to be "at least as complex as" any element of E. Very early, Berman <ref> [6] </ref> established limits to this interpretation by proving that no P m -complete language is P-immune, even though E contains P-immune languages. (In fact, Mayordomo [25] has recently shown that almost every language in E is P-bi-immune.) In section 6 below we prove a very strong limitation on the complexity of <p> Corollary 5.4 (Mayordomo [25]). Let C E , C E 2 be the sets of languages that are P m -complete for E, E 2 , respectively. Then (C E jE) = (C E 2 jE 2 ) = 0. 2 (Mayordomo's proof of Corollary 5.4 used Berman's result <ref> [6] </ref>, that no P m -complete language for E is P-immune.) As it turns out, Corollary 5.4 is only a special case of the following general result. All P m -degrees have measure 0 in E and in E 2 . Theorem 5.5.
Reference: [7] <author> L. Berman and J. Hartmanis. </author> <title> On isomorphism and density of NP and other complete sets. </title> <journal> SIAM Journal on Computing, </journal> <volume> 6 </volume> <pages> 305-322, </pages> <year> 1977. </year>
Reference: [8] <author> R. Book and D.-Z. Du. </author> <title> The existence and density of generalized complexity cores. </title> <journal> Journal of the ACM, </journal> <volume> 34 </volume> <pages> 718-730, </pages> <year> 1987. </year>
Reference-contexts: We prove that P m -hard problems are rare, in the sense that they form a p-measure 0 set. We also prove that every P m -degree has measure 0 in exponential time. Complexity cores, first introduced by Lynch [24] have been studied extensively <ref> [8, 9, 10, 11, 12, 14, 27, 28, 29, etc.] </ref>. Intuitively, a complexity core of a language A is a fixed set K of inputs such that every machine whose decisions are consistent with A fails to decide efficiently on all but finitely many elements of K.
Reference: [9] <author> R. Book, D.-Z Du, and D. Russo. </author> <title> On polynomial and generalized complexity cores. </title> <booktitle> In Proceedings of the Third Structure in Complexity Theory Conference, </booktitle> <pages> pages 236-250, </pages> <year> 1988. </year>
Reference-contexts: We prove that P m -hard problems are rare, in the sense that they form a p-measure 0 set. We also prove that every P m -degree has measure 0 in exponential time. Complexity cores, first introduced by Lynch [24] have been studied extensively <ref> [8, 9, 10, 11, 12, 14, 27, 28, 29, etc.] </ref>. Intuitively, a complexity core of a language A is a fixed set K of inputs such that every machine whose decisions are consistent with A fails to decide efficiently on all but finitely many elements of K.
Reference: [10] <author> D.-Z. Du. </author> <title> Generalized complexity cores and levelability of intractable sets. </title> <type> PhD thesis, </type> <institution> University of California, Santa Barbara, </institution> <year> 1985. </year>
Reference-contexts: We prove that P m -hard problems are rare, in the sense that they form a p-measure 0 set. We also prove that every P m -degree has measure 0 in exponential time. Complexity cores, first introduced by Lynch [24] have been studied extensively <ref> [8, 9, 10, 11, 12, 14, 27, 28, 29, etc.] </ref>. Intuitively, a complexity core of a language A is a fixed set K of inputs such that every machine whose decisions are consistent with A fails to decide efficiently on all but finitely many elements of K.
Reference: [11] <author> D.-Z. Du and R. </author> <title> Book. On inefficient special cases of NP-complete problems. </title> <journal> Theoretical Computer Science, </journal> <volume> 63 </volume> <pages> 239-252, </pages> <year> 1989. </year>
Reference-contexts: We prove that P m -hard problems are rare, in the sense that they form a p-measure 0 set. We also prove that every P m -degree has measure 0 in exponential time. Complexity cores, first introduced by Lynch [24] have been studied extensively <ref> [8, 9, 10, 11, 12, 14, 27, 28, 29, etc.] </ref>. Intuitively, a complexity core of a language A is a fixed set K of inputs such that every machine whose decisions are consistent with A fails to decide efficiently on all but finitely many elements of K.
Reference: [12] <author> S. Even, A. Selman, and Y. Yacobi. </author> <title> Hard core theorems for complexity classes. </title> <journal> Journal of the ACM, </journal> <volume> 35 </volume> <pages> 205-217, </pages> <year> 1985. </year>
Reference-contexts: We prove that P m -hard problems are rare, in the sense that they form a p-measure 0 set. We also prove that every P m -degree has measure 0 in exponential time. Complexity cores, first introduced by Lynch [24] have been studied extensively <ref> [8, 9, 10, 11, 12, 14, 27, 28, 29, etc.] </ref>. Intuitively, a complexity core of a language A is a fixed set K of inputs such that every machine whose decisions are consistent with A fails to decide efficiently on all but finitely many elements of K.
Reference: [13] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-completeness. W.H. </title> <publisher> Freeman and Company, </publisher> <year> 1979. </year>
Reference-contexts: A language C is P m complete for C if C 2 C and C is P m -hard for C. If C = NP, this is the usual notion of NP-completeness <ref> [13] </ref>.
Reference: [14] <author> D. T. Huynh. </author> <title> On solving hard problems by polynomial-size circuits. </title> <journal> Information Processing Letters, </journal> <volume> 24 </volume> <pages> 171-176, </pages> <year> 1987. </year>
Reference-contexts: We prove that P m -hard problems are rare, in the sense that they form a p-measure 0 set. We also prove that every P m -degree has measure 0 in exponential time. Complexity cores, first introduced by Lynch [24] have been studied extensively <ref> [8, 9, 10, 11, 12, 14, 27, 28, 29, etc.] </ref>. Intuitively, a complexity core of a language A is a fixed set K of inputs such that every machine whose decisions are consistent with A fails to decide efficiently on all but finitely many elements of K.
Reference: [15] <author> R. M. Karp. </author> <title> Reducibility among combinatorial problems. </title> <editor> In R. E. Miller and J. W. Thatcher, editors, </editor> <booktitle> Complexity of Computer Computations, </booktitle> <pages> pages 85-104. </pages> <publisher> Plenum Press, </publisher> <year> 1972. </year>
Reference-contexts: The most common interpretation of "efficiently reducible" here is "polynomial time many-one reducible," abbreviated " P m -reducible." (See section 2 for notation and terminology used in this introduction.) For example, in most usages, "NP-complete" means " P m -complete for NP," the completeness notion introduced by Karp <ref> [15] </ref> and Levin [16]. fl This research was supported in part by National Science Foundation Grants CCR-8809238 and CCR-9157382, with matching funds from Rockwell International and Microware Systems Corporation, and in part by the Center for Discrete Mathematics and Theoretical Computer Science (DIMACS), where the second author was a visitor while
Reference: [16] <author> L. A. Levin. </author> <title> Universal sequential search problems. </title> <journal> Problems of Information Transmission, </journal> <volume> 9 </volume> <pages> 265-266, </pages> <year> 1973. </year>
Reference-contexts: most common interpretation of "efficiently reducible" here is "polynomial time many-one reducible," abbreviated " P m -reducible." (See section 2 for notation and terminology used in this introduction.) For example, in most usages, "NP-complete" means " P m -complete for NP," the completeness notion introduced by Karp [15] and Levin <ref> [16] </ref>. fl This research was supported in part by National Science Foundation Grants CCR-8809238 and CCR-9157382, with matching funds from Rockwell International and Microware Systems Corporation, and in part by the Center for Discrete Mathematics and Theoretical Computer Science (DIMACS), where the second author was a visitor while part of this
Reference: [17] <author> J. H. Lutz. </author> <title> Almost everywhere high nonuniform complexity. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 44 </volume> <pages> 220-258, </pages> <year> 1992. </year> <month> 24 </month>
Reference-contexts: paper, we investigate the complexity (measured by size of complexity cores) and distribution (i.e., abundance in the sense of measure) of languages that are P m -hard for E (equivalently, E 2 ) and other complexity classes, including NP. (By "measure" here, we mean resource-bounded measure as developed by Lutz <ref> [17] </ref> and described in section 3 of the present paper.) We give a tight lower bound and, perhaps surprisingly, a tight upper bound on the sizes of complexity cores of hard languages. More generally, we analyze measure-theoretic aspects of the P m -reducibility structure of exponential time complexity classes. <p> If C = NP, this is the usual notion of NP-completeness [13]. In this paper we are especially concerned with languages that are P m -hard or P m -complete for E or E 2 . 3 Resource-Bounded Measure Resource-bounded measure <ref> [17, 19] </ref> is a very general theory whose special cases include classical Lebesgue measure, the measure structure of the class REC of all recursive languages, and measure in various complexity classes. <p> In this paper we are interested only in measure in E and E 2 , so our discussion of measure is specific to these classes. The interested reader may consult section 3 of <ref> [17] </ref> for more discussion and examples. <p> It is shown in <ref> [17] </ref> that these definitions endow E and E 2 with internal measure structure. This structure justifies the intuition that, if (XjE) = 0, then X " E is a negligibly small subset of E (and similarly for E 2 ).
Reference: [18] <author> J. H. Lutz. </author> <title> Intrinsically pseudorandom sequences, </title> <note> in preparation. </note>
Reference-contexts: We conclude this section by noting two respects in which the Small Span Theorem cannot be improved. First, the hypotheses A 2 E and A 2 E 2 are essential for parts 1 and 2, respectively. For example, if A is p-random <ref> [18] </ref>, then p (fAg) 6= 0, so none of deg P m (A), m (A) can have p-measure 0. The second respect in which the Small Span Theorem cannot be improved involves the variety of small-span configurations.
Reference: [19] <author> J. H. Lutz. </author> <title> Resource-bounded measure, </title> <note> in preparation. </note>
Reference-contexts: If C = NP, this is the usual notion of NP-completeness [13]. In this paper we are especially concerned with languages that are P m -hard or P m -complete for E or E 2 . 3 Resource-Bounded Measure Resource-bounded measure <ref> [17, 19] </ref> is a very general theory whose special cases include classical Lebesgue measure, the measure structure of the class REC of all recursive languages, and measure in various complexity classes.
Reference: [20] <author> J. H. Lutz. </author> <title> The quantitative structure of exponential time. </title> <booktitle> In Proceedings of the Eighth Structure in Complexity Theory Conference, </booktitle> <pages> pages 158-175. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1993. </year>
Reference-contexts: This conclusion is much stronger than Orponen and Schoning's conclusion that every such language has a non-sparse polynomial complexity core, though it is achieved at the cost of a stronger hypothesis. This hypothesis, originally proposed by Lutz, is discussed at some length in <ref> [20, 22, 23] </ref>. <p> Then the language K = f (f0; 1g fl ) is a dense DTIME (2 n * )-complexity core of H. 2 Lutz has proposed the investigation of the consequences of the strong hypotheses (NP j E) 6= 0 and (NP j E 2 ) 6= 0 <ref> [20, 22, 23] </ref>. In this regard, we have the following. Corollary 4.10.
Reference: [21] <author> J. H. Lutz. </author> <title> Weakly hard problems. </title> <type> Technical Report 93-13, </type> <institution> Iowa State University, </institution> <year> 1993. </year> <note> Submitted. </note>
Reference-contexts: A language A is weakly P m hard for E if every element of some nonnegligible, i.e., non-measure 0, set of languages in E is reducible to A. Very recently, Lutz <ref> [21] </ref> has proven that "weakly P m -hard" is more general than " P m -hard.") Specifically, we prove that every language that is weakly P m -hard for E or E 2 has a dense exponential complexity core. <p> Thus a language A is weakly P m -hard for E if a nonnegligible subset of the languages in E are P m -reducible to A. Very recently, Lutz <ref> [21] </ref> has established the existence of languages that are weakly P m -complete, but not P m -complete, for E (and similarly for E 2 ). <p> But D is dense, so this implies that D K is dense, whence K c is dense. 2 Note that Theorem 5.3 follows from Corollary 4.6 and Theorem 6.2, but that Theorem 6.2 tells us more. The main construction of <ref> [21] </ref> shows that, for every c 2 N, there is a language H that is weakly P m -hard for E and has f0; 1g fl as a DTIME (2 cn )-complexity core.
Reference: [22] <author> J. H. Lutz and E. Mayordomo. </author> <title> Measure, stochasticity, and the density of hard languages. </title> <journal> SIAM Journal on Computing, </journal> <note> to appear. See also Proceedings of the Tenth Symposium on Theoretical Aspects of Computer Science, Springer-Verlag, </note> <year> 1993, </year> <pages> pp. 38-47. </pages>
Reference-contexts: This conclusion is much stronger than Orponen and Schoning's conclusion that every such language has a non-sparse polynomial complexity core, though it is achieved at the cost of a stronger hypothesis. This hypothesis, originally proposed by Lutz, is discussed at some length in <ref> [20, 22, 23] </ref>. <p> Then the language K = f (f0; 1g fl ) is a dense DTIME (2 n * )-complexity core of H. 2 Lutz has proposed the investigation of the consequences of the strong hypotheses (NP j E) 6= 0 and (NP j E 2 ) 6= 0 <ref> [20, 22, 23] </ref>. In this regard, we have the following. Corollary 4.10. <p> Fix such a language A. By Lemma 5.2, p (P 1 m (A)) = 0. Also, since A is sparse, the main result of <ref> [22] </ref> implies that p (P m (A)) = 0. (b) If A 2 P f;; f0; 1g fl g, then (P m (A) j E) = p (P m (A)) = 0, but p (P 1 m (A)) 6= 0 and m (A) j E) 6= 0. m -complete for E,
Reference: [23] <author> J. H. Lutz and E. Mayordomo. </author> <title> Cook versus Karp-Levin: Separating completeness notions if NP is not small. </title> <type> Technical Report 92-24, </type> <institution> Iowa State University, </institution> <year> 1992. </year> <note> Submitted. </note>
Reference-contexts: This conclusion is much stronger than Orponen and Schoning's conclusion that every such language has a non-sparse polynomial complexity core, though it is achieved at the cost of a stronger hypothesis. This hypothesis, originally proposed by Lutz, is discussed at some length in <ref> [20, 22, 23] </ref>. <p> Then the language K = f (f0; 1g fl ) is a dense DTIME (2 n * )-complexity core of H. 2 Lutz has proposed the investigation of the consequences of the strong hypotheses (NP j E) 6= 0 and (NP j E 2 ) 6= 0 <ref> [20, 22, 23] </ref>. In this regard, we have the following. Corollary 4.10.
Reference: [24] <author> N. Lynch. </author> <title> On reducibility to complex or sparse sets. </title> <journal> Journal of the ACM, </journal> <volume> 22 </volume> <pages> 341-345, </pages> <year> 1975. </year>
Reference-contexts: We prove that P m -hard problems are rare, in the sense that they form a p-measure 0 set. We also prove that every P m -degree has measure 0 in exponential time. Complexity cores, first introduced by Lynch <ref> [24] </ref> have been studied extensively [8, 9, 10, 11, 12, 14, 27, 28, 29, etc.].
Reference: [25] <author> E. Mayordomo. </author> <title> Almost every set in exponential time is P-bi-immune. </title> <booktitle> Theoretical Computer Science, to appear. See also Seventeenth International Symposium on Mathematical Foundations of Computer Science, </booktitle> <pages> pages 392-400. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Very early, Berman [6] established limits to this interpretation by proving that no P m -complete language is P-immune, even though E contains P-immune languages. (In fact, Mayordomo <ref> [25] </ref> has recently shown that almost every language in E is P-bi-immune.) In section 6 below we prove a very strong limitation on the complexity of P m -hard languages for E. <p> Let A be as in Corollary 4.5. Then H E P 1 m (A), so Lemma 5.2 tells us that p (H E ) = p (P 1 2 Theorem 5.3 immediately yields an alternate proof of the following result. Corollary 5.4 (Mayordomo <ref> [25] </ref>). Let C E , C E 2 be the sets of languages that are P m -complete for E, E 2 , respectively.
Reference: [26] <author> A. R. Meyer, </author> <year> 1977. </year> <note> reported in [7]. </note>
Reference-contexts: K is an exponential complexity core of A if there is a real number * &gt; 0 such that K is a DTIME (2 n * )-complexity core of A. 9 Much of our work here uses languages that are "incompressible by many-one reductions," an idea originally exploited by Meyer <ref> [26] </ref>. The following definitions develop this notion. Definition. <p> This implies that X c = k=0 is a p-union of p-measure 0 sets, whence p (X) = 1 by Lemma 3.3. 2 Corollary 4.4. Almost every language in E and almost every language in E 2 is incompress ible by P m -reductions. 2 Corollary 4.5 (Meyer <ref> [26] </ref>). There is a language A 2 E that is incompressible by P m - reductions. 2 12 Corollary 4.6. Let c 2 Z + . 1. Almost every language in E has f0; 1g fl as a DTIME (2 cn )-complexity core. 2. <p> In both E and E 2 , either one or both of the upper and lower spans of a language can in fact be small. We give examples for E. (a) It is well known <ref> [26] </ref> that there is a language A 2 E that is both sparse and incom pressible by P m -reductions. Fix such a language A. By Lemma 5.2, p (P 1 m (A)) = 0. <p> Proof. By Corollary 4.5, there is a language in E that is incompressible by P m -reductions. In fact, Meyer's construction <ref> [26] </ref> shows that there is a language A 2 DTIME (5 n ) that is incompressible by P m -reductions. As in Fact 4.7 and Theorem 4.9, this idea has often been used to establish lower bounds on the complexities of P m -hard languages.
Reference: [27] <author> P. Orponen. </author> <title> A classification of complexity core lattices. </title> <journal> Theoretical Computer Science, </journal> <volume> 70 </volume> <pages> 121-130, </pages> <year> 1986. </year>
Reference-contexts: We prove that P m -hard problems are rare, in the sense that they form a p-measure 0 set. We also prove that every P m -degree has measure 0 in exponential time. Complexity cores, first introduced by Lynch [24] have been studied extensively <ref> [8, 9, 10, 11, 12, 14, 27, 28, 29, etc.] </ref>. Intuitively, a complexity core of a language A is a fixed set K of inputs such that every machine whose decisions are consistent with A fails to decide efficiently on all but finitely many elements of K.
Reference: [28] <author> P. Orponen and U. Schoning. </author> <title> The density and complexity of polynomial cores for intractable sets. </title> <journal> Information and Control, </journal> <volume> 70 </volume> <pages> 54-68, </pages> <year> 1986. </year>
Reference-contexts: We prove that P m -hard problems are rare, in the sense that they form a p-measure 0 set. We also prove that every P m -degree has measure 0 in exponential time. Complexity cores, first introduced by Lynch [24] have been studied extensively <ref> [8, 9, 10, 11, 12, 14, 27, 28, 29, etc.] </ref>. Intuitively, a complexity core of a language A is a fixed set K of inputs such that every machine whose decisions are consistent with A fails to decide efficiently on all but finitely many elements of K. <p> The meaning of "efficiently" is a parameter of the definition that varies according to the context. (See section 4 for a precise definition.) Orponen and Schoning <ref> [28] </ref> have established two lower bounds on the sizes of complexity cores of hard languages. First, every P m -hard language for E has a dense P-complexity core. Second, if P 6= NP, then every P m -hard language for NP has a non-sparse polynomial complexity core. <p> If Z is a p i -union of the p i -measure 0 sets Z 0 ; Z 1 ; Z 2 ; , then Z has p i -measure 0. 2 4 Complexity Cores: Lower Bounds Orponen and Schoning <ref> [28] </ref> have shown that every P m -hard language for E has a dense polynomial complexity core. In this section we extend this result by proving that every weakly P m -hard language for E has a dense exponential complexity core. We begin by explaining our terminology. <p> Almost every language in E 2 has f0; 1g fl as a DTIME (2 n c )-complexity core. 2 We now consider complexity cores of P m -hard languages. Our starting point is the following two known facts. Fact 4.7 (Orponen and Schoning <ref> [28] </ref>). Every language that is P m -hard for E (equivalently, for E 2 ) has a dense P-complexity core. Fact 4.8 (Orponen and Schoning [28]). If P 6= NP, then every language that is P m -hard for NP has a nonsparse P-complexity core. We first extend Fact 4.7. <p> Our starting point is the following two known facts. Fact 4.7 (Orponen and Schoning <ref> [28] </ref>). Every language that is P m -hard for E (equivalently, for E 2 ) has a dense P-complexity core. Fact 4.8 (Orponen and Schoning [28]). If P 6= NP, then every language that is P m -hard for NP has a nonsparse P-complexity core. We first extend Fact 4.7. For this we need a definition.
Reference: [29] <author> D. A. Russo and P. Orponen. </author> <title> On P-subset structures. </title> <journal> Mathematical Systems Theory, </journal> <volume> 20 </volume> <pages> 129-136, </pages> <year> 1987. </year>
Reference-contexts: We prove that P m -hard problems are rare, in the sense that they form a p-measure 0 set. We also prove that every P m -degree has measure 0 in exponential time. Complexity cores, first introduced by Lynch [24] have been studied extensively <ref> [8, 9, 10, 11, 12, 14, 27, 28, 29, etc.] </ref>. Intuitively, a complexity core of a language A is a fixed set K of inputs such that every machine whose decisions are consistent with A fails to decide efficiently on all but finitely many elements of K.
References-found: 29

