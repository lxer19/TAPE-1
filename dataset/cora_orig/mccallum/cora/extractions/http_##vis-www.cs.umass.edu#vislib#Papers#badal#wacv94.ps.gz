URL: http://vis-www.cs.umass.edu/vislib/Papers/badal/wacv94.ps.gz
Refering-URL: http://vis-www.cs.umass.edu/vislib/Papers/badal/files.html
Root-URL: 
Title: A Practical Obstacle Detection and Avoidance System  
Author: Sumit Badal Srinivas Ravela Bruce Draper Allen Hanson 
Address: Amherst, MA 01002  
Affiliation: Computer Vision Research Laboratory University of Massachusetts,  
Abstract: A practical real-time system for passive obstacle detection and avoidance is presented. Range information is obtained from stereo images by first computing a disparity picture from the image pair and extracting points above the ground plane. Then these points are projected onto the ground plane and an Instantaneous Obstacle Map (IOM) is obtained. The IOM is transformed into a one dimensional steering vector that represents the hindrance associated with steering in a particular direction and then a one dimensional search is performed on the steering vector for an angle with least hindrance. The steering direction and hindrance value are used to set the speed of the vehicle. This system has been implemented on the Mobile Perception Lab (MPL) at University of Massachusetts at Amherst with considerable success, running at 2Hz for 256 fi 240 sized images. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. H. M.J. Daily and K. Reiser, </author> <title> "Detecting obstacles in range imagery," </title> <booktitle> Proc. of [ARPA] Image Understanding Workshop, </booktitle> <pages> pp. 87-97, </pages> <year> 1987. </year>
Reference-contexts: 1 Introduction Obstacle detection systems typically compute the position of obstacles relative to a mobile agent by using range information. Range information may be obtained from ladar (laser ranging) <ref> [1, 2] </ref>, sonar (sound ranging) [3, 4] or vision based techniques [5, 6, 7, 8]. Video technology has the advantages of low cost, low power consumption and a high degree of mechanical reliability. The speed and accuracy of vision algorithms typically scale with faster computing platforms. <p> Sections 3 and 4 describe the detection and avoidance algorithms respectively. Section 5 describes the implementation details and demonstrates experimental results. Section 6 presents conclusions and section 7 examines limitations of our approach. 2 Related Work A majority of work on obstacle detection uses active sensors <ref> [3, 4, 2, 1] </ref>. [9] uses an omni-directional conic mirror as a sensor. Optical flow forms the basis of obstacle detection in [5, 6, 7, 8].
Reference: [2] <author> P. Veatch and L. Davis, </author> <title> "Efficient algorithms for obstacle detection using range data," </title> <type> CVGIP 50, </type> <pages> pp. 50-74, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction Obstacle detection systems typically compute the position of obstacles relative to a mobile agent by using range information. Range information may be obtained from ladar (laser ranging) <ref> [1, 2] </ref>, sonar (sound ranging) [3, 4] or vision based techniques [5, 6, 7, 8]. Video technology has the advantages of low cost, low power consumption and a high degree of mechanical reliability. The speed and accuracy of vision algorithms typically scale with faster computing platforms. <p> Sections 3 and 4 describe the detection and avoidance algorithms respectively. Section 5 describes the implementation details and demonstrates experimental results. Section 6 presents conclusions and section 7 examines limitations of our approach. 2 Related Work A majority of work on obstacle detection uses active sensors <ref> [3, 4, 2, 1] </ref>. [9] uses an omni-directional conic mirror as a sensor. Optical flow forms the basis of obstacle detection in [5, 6, 7, 8].
Reference: [3] <author> B. Barshan and R. Kuc, </author> <title> "A bat-like sonar system for obstacle localization," </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics 22, </journal> <pages> pp. 636-646, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction Obstacle detection systems typically compute the position of obstacles relative to a mobile agent by using range information. Range information may be obtained from ladar (laser ranging) [1, 2], sonar (sound ranging) <ref> [3, 4] </ref> or vision based techniques [5, 6, 7, 8]. Video technology has the advantages of low cost, low power consumption and a high degree of mechanical reliability. The speed and accuracy of vision algorithms typically scale with faster computing platforms. <p> Sections 3 and 4 describe the detection and avoidance algorithms respectively. Section 5 describes the implementation details and demonstrates experimental results. Section 6 presents conclusions and section 7 examines limitations of our approach. 2 Related Work A majority of work on obstacle detection uses active sensors <ref> [3, 4, 2, 1] </ref>. [9] uses an omni-directional conic mirror as a sensor. Optical flow forms the basis of obstacle detection in [5, 6, 7, 8].
Reference: [4] <author> J. Borenstein and Y. Koren, </author> <title> "Obstacle avoidance with ultrasonic sensors," </title> <journal> IEEE J. Robotics Automation 4, </journal> <pages> pp. 213-218, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction Obstacle detection systems typically compute the position of obstacles relative to a mobile agent by using range information. Range information may be obtained from ladar (laser ranging) [1, 2], sonar (sound ranging) <ref> [3, 4] </ref> or vision based techniques [5, 6, 7, 8]. Video technology has the advantages of low cost, low power consumption and a high degree of mechanical reliability. The speed and accuracy of vision algorithms typically scale with faster computing platforms. <p> Sections 3 and 4 describe the detection and avoidance algorithms respectively. Section 5 describes the implementation details and demonstrates experimental results. Section 6 presents conclusions and section 7 examines limitations of our approach. 2 Related Work A majority of work on obstacle detection uses active sensors <ref> [3, 4, 2, 1] </ref>. [9] uses an omni-directional conic mirror as a sensor. Optical flow forms the basis of obstacle detection in [5, 6, 7, 8].
Reference: [5] <author> N. Ancona, </author> <title> "A fast obstacle detection method based on optical flow," </title> <booktitle> Proc. of European Conference on Computer Vision, </booktitle> <pages> pp. 267-271, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction Obstacle detection systems typically compute the position of obstacles relative to a mobile agent by using range information. Range information may be obtained from ladar (laser ranging) [1, 2], sonar (sound ranging) [3, 4] or vision based techniques <ref> [5, 6, 7, 8] </ref>. Video technology has the advantages of low cost, low power consumption and a high degree of mechanical reliability. The speed and accuracy of vision algorithms typically scale with faster computing platforms. <p> Section 6 presents conclusions and section 7 examines limitations of our approach. 2 Related Work A majority of work on obstacle detection uses active sensors [3, 4, 2, 1]. [9] uses an omni-directional conic mirror as a sensor. Optical flow forms the basis of obstacle detection in <ref> [5, 6, 7, 8] </ref>. Most of the flow based methods assume that the vehicle motion can be modelled as a pure translation, which may not be true in the general scenario.
Reference: [6] <author> W. Enkelmann, </author> <title> "Obstacle detection by evaluation of optical flow fields from image sequence," </title> <booktitle> Image and Vision Computing 9, </booktitle> <pages> pp. 160-168, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction Obstacle detection systems typically compute the position of obstacles relative to a mobile agent by using range information. Range information may be obtained from ladar (laser ranging) [1, 2], sonar (sound ranging) [3, 4] or vision based techniques <ref> [5, 6, 7, 8] </ref>. Video technology has the advantages of low cost, low power consumption and a high degree of mechanical reliability. The speed and accuracy of vision algorithms typically scale with faster computing platforms. <p> Section 6 presents conclusions and section 7 examines limitations of our approach. 2 Related Work A majority of work on obstacle detection uses active sensors [3, 4, 2, 1]. [9] uses an omni-directional conic mirror as a sensor. Optical flow forms the basis of obstacle detection in <ref> [5, 6, 7, 8] </ref>. Most of the flow based methods assume that the vehicle motion can be modelled as a pure translation, which may not be true in the general scenario.
Reference: [7] <author> M. H. G.S. Young, T.H. Hong and A. Yang, </author> <title> "Obstacle detection for a vehicle using optical flow," SAE Intelligent Vehicle. </title> <publisher> IEEE, </publisher> <year> 1992. </year>
Reference-contexts: 1 Introduction Obstacle detection systems typically compute the position of obstacles relative to a mobile agent by using range information. Range information may be obtained from ladar (laser ranging) [1, 2], sonar (sound ranging) [3, 4] or vision based techniques <ref> [5, 6, 7, 8] </ref>. Video technology has the advantages of low cost, low power consumption and a high degree of mechanical reliability. The speed and accuracy of vision algorithms typically scale with faster computing platforms. <p> Section 6 presents conclusions and section 7 examines limitations of our approach. 2 Related Work A majority of work on obstacle detection uses active sensors [3, 4, 2, 1]. [9] uses an omni-directional conic mirror as a sensor. Optical flow forms the basis of obstacle detection in <ref> [5, 6, 7, 8] </ref>. Most of the flow based methods assume that the vehicle motion can be modelled as a pure translation, which may not be true in the general scenario.
Reference: [8] <author> R. Nelson and J. Aloimonos, </author> <title> "Using flow field divergence for obstacle avoidance: towards qualitative vision," </title> <booktitle> Proc. of International Conference on Computer Vision, </booktitle> <pages> pp. 188-196, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction Obstacle detection systems typically compute the position of obstacles relative to a mobile agent by using range information. Range information may be obtained from ladar (laser ranging) [1, 2], sonar (sound ranging) [3, 4] or vision based techniques <ref> [5, 6, 7, 8] </ref>. Video technology has the advantages of low cost, low power consumption and a high degree of mechanical reliability. The speed and accuracy of vision algorithms typically scale with faster computing platforms. <p> Section 6 presents conclusions and section 7 examines limitations of our approach. 2 Related Work A majority of work on obstacle detection uses active sensors [3, 4, 2, 1]. [9] uses an omni-directional conic mirror as a sensor. Optical flow forms the basis of obstacle detection in <ref> [5, 6, 7, 8] </ref>. Most of the flow based methods assume that the vehicle motion can be modelled as a pure translation, which may not be true in the general scenario.
Reference: [9] <author> Y. Yagi and M. Yachida, </author> <title> "Real-time generation of environmental map and obstacle avoidance using omnidirectional image sensor with conic mirror," </title> <booktitle> Proc. of IEEE Computer Society Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 160-165, </pages> <year> 1991. </year>
Reference-contexts: Section 5 describes the implementation details and demonstrates experimental results. Section 6 presents conclusions and section 7 examines limitations of our approach. 2 Related Work A majority of work on obstacle detection uses active sensors [3, 4, 2, 1]. <ref> [9] </ref> uses an omni-directional conic mirror as a sensor. Optical flow forms the basis of obstacle detection in [5, 6, 7, 8]. Most of the flow based methods assume that the vehicle motion can be modelled as a pure translation, which may not be true in the general scenario. <p> Trinocular stereo is used to detect obstacles in [14]. The implementation in [14] requires three cameras to simplify matching, yet it falls short of our system by a speed factor of 5-10 for comparable resolutions even though it has custom modifications for its stereo hardware. <ref> [15, 14, 16, 9] </ref> address real time implementa tions. [15] and [17] discuss the application of potential fields for obstacle avoidance.
Reference: [10] <author> H. Sawhney and A. Hanson, </author> <title> "Affine trackability aids obstacle detection," </title> <booktitle> Proc. of IEEE Computer Society Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 418-424, </pages> <year> 1992. </year>
Reference-contexts: Most of the flow based methods assume that the vehicle motion can be modelled as a pure translation, which may not be true in the general scenario. The concept of 2D affine trackability of shallow structures is exploited in <ref> [10, 11] </ref> to characterize and hence detect obstacles.
Reference: [11] <author> H. Sawhney and A. Hanson, </author> <title> "Tracking detection and 3d representation of potential obstacles using affine constraints," </title> <booktitle> Proc. of [ARPA] Image Understanding Workshop, </booktitle> <pages> pp. 1009-1017, </pages> <year> 1992. </year>
Reference-contexts: Most of the flow based methods assume that the vehicle motion can be modelled as a pure translation, which may not be true in the general scenario. The concept of 2D affine trackability of shallow structures is exploited in <ref> [10, 11] </ref> to characterize and hence detect obstacles.
Reference: [12] <author> R. Z. Zhang and A. Hanson, </author> <title> "Qualitative obstacle detection," </title> <type> Tech. Report COMPSI TR94-20, </type> <year> 1994. </year>
Reference-contexts: The implementation of affine tracking is limited to objects with straight line boundaries and a minimal set of three lines need to be hypothesized as a shallow structure, which are selected manually. <ref> [12] </ref> presents three algorithms for obstacle detection, two of which are aimed at qualitative yes/no obstacle detection without indicating which points are obstacles. The third algorithm is based on partial 3D scene reconstruction and continuously estimates the ground plane. Its computational needs limits its applicability in real time applications.
Reference: [13] <author> R. C. B. H. H. Baker and M. J. Hannah, </author> <title> "The JISCT stereo evaluation," </title> <booktitle> Proc. of [ARPA] Image Understanding Workshop, </booktitle> <year> 1993. </year>
Reference-contexts: The third algorithm is based on partial 3D scene reconstruction and continuously estimates the ground plane. Its computational needs limits its applicability in real time applications. For an excellent survey of the effectiveness of stereo algorithms in the ARPA Unmanned Ground Vehicle program, see <ref> [13] </ref>. The stereo algorithm developed at INRIA aims at 3D scene reconstruction. The SRI algorithm attempts to produce a set of high quality matches using hierarchal techniques.
Reference: [14] <author> B. Ross, </author> <title> "A practical stereo vision system"," </title> <booktitle> Proc. of IEEE Computer Society Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 148-153, </pages> <year> 1993. </year>
Reference-contexts: The algorithm developed by TELEOS attempts to establish the correspondence of selected points at frame rate. Selection of these points is critical for obstacle detection applications, which we believe is still an open problem. Trinocular stereo is used to detect obstacles in <ref> [14] </ref>. The implementation in [14] requires three cameras to simplify matching, yet it falls short of our system by a speed factor of 5-10 for comparable resolutions even though it has custom modifications for its stereo hardware. [15, 14, 16, 9] address real time implementa tions. [15] and [17] discuss the <p> The algorithm developed by TELEOS attempts to establish the correspondence of selected points at frame rate. Selection of these points is critical for obstacle detection applications, which we believe is still an open problem. Trinocular stereo is used to detect obstacles in <ref> [14] </ref>. The implementation in [14] requires three cameras to simplify matching, yet it falls short of our system by a speed factor of 5-10 for comparable resolutions even though it has custom modifications for its stereo hardware. [15, 14, 16, 9] address real time implementa tions. [15] and [17] discuss the application of potential fields <p> Trinocular stereo is used to detect obstacles in [14]. The implementation in [14] requires three cameras to simplify matching, yet it falls short of our system by a speed factor of 5-10 for comparable resolutions even though it has custom modifications for its stereo hardware. <ref> [15, 14, 16, 9] </ref> address real time implementa tions. [15] and [17] discuss the application of potential fields for obstacle avoidance.
Reference: [15] <author> O. Khatib, </author> <title> "Real-time obstacle avoidance for manipulators and mobile robots," </title> <journal> International Journal of Robotics Research 5(1), </journal> <pages> pp. 90-99, </pages> <year> 1986. </year>
Reference-contexts: Trinocular stereo is used to detect obstacles in [14]. The implementation in [14] requires three cameras to simplify matching, yet it falls short of our system by a speed factor of 5-10 for comparable resolutions even though it has custom modifications for its stereo hardware. <ref> [15, 14, 16, 9] </ref> address real time implementa tions. [15] and [17] discuss the application of potential fields for obstacle avoidance. <p> The implementation in [14] requires three cameras to simplify matching, yet it falls short of our system by a speed factor of 5-10 for comparable resolutions even though it has custom modifications for its stereo hardware. [15, 14, 16, 9] address real time implementa tions. <ref> [15] </ref> and [17] discuss the application of potential fields for obstacle avoidance.
Reference: [16] <author> J. Kim and P. Khosla, </author> <title> "Real-time obstacle avoidance using harmonic potential functions," </title> <type> Tech. Report COMPSI T-RA 8, </type> <pages> pp. 338-349, </pages> <year> 1992. </year>
Reference-contexts: Trinocular stereo is used to detect obstacles in [14]. The implementation in [14] requires three cameras to simplify matching, yet it falls short of our system by a speed factor of 5-10 for comparable resolutions even though it has custom modifications for its stereo hardware. <ref> [15, 14, 16, 9] </ref> address real time implementa tions. [15] and [17] discuss the application of potential fields for obstacle avoidance. <p> This technique can also be used to generate robust models of the world incrementally. <ref> [16] </ref> also discusses real-time obstacle avoidance using harmonic potential functions. [20, 21] describe reflexive/reactive approaches to autonomous vehicle control. [20] is based on the construction of motor schemas, similar to the work on potential fields to generate robot commands. [21] describes an architecture for Autonomous Land Vehicle Navigation that at the
Reference: [17] <author> B. Krogh, </author> <title> "A generalized potential field approach to obstacle avoidance," </title> <booktitle> SME Conf. Proc. Robotics Research: The Next Five Years and Beyond,(ed),Bethlehem, </booktitle> <address> PA, SME, </address> <year> 1984. </year>
Reference-contexts: The implementation in [14] requires three cameras to simplify matching, yet it falls short of our system by a speed factor of 5-10 for comparable resolutions even though it has custom modifications for its stereo hardware. [15, 14, 16, 9] address real time implementa tions. [15] and <ref> [17] </ref> discuss the application of potential fields for obstacle avoidance. These approaches are reactive since the gradients of the potential field at any point determines the velocity of the manipulator towards a specified goal. [18, 19] discuss the application of harmonic functions to plan smooth paths with no local minima.
Reference: [18] <author> C. I. Connolly, </author> <title> "Harmonic control," </title> <booktitle> Proc. of the IEEE Intl. Conf. on Robotics and Automation, </booktitle> <year> 1992. </year>
Reference-contexts: These approaches are reactive since the gradients of the potential field at any point determines the velocity of the manipulator towards a specified goal. <ref> [18, 19] </ref> discuss the application of harmonic functions to plan smooth paths with no local minima.
Reference: [19] <author> C. I. Connolly and R. A. Grupen, </author> <title> "Applications of harmonic functions to robotics," </title> <type> Tech. Report UM-CS-1992-012, </type> <year> 1992. </year>
Reference-contexts: These approaches are reactive since the gradients of the potential field at any point determines the velocity of the manipulator towards a specified goal. <ref> [18, 19] </ref> discuss the application of harmonic functions to plan smooth paths with no local minima.
Reference: [20] <author> R. C. Arkin, </author> <title> "Motor schema based navigation for a mobile robot," </title> <booktitle> Proc. of the IEEE Intl. Conf. on Robotics and Automation, </booktitle> <year> 1987. </year>
Reference-contexts: This technique can also be used to generate robust models of the world incrementally. [16] also discusses real-time obstacle avoidance using harmonic potential functions. <ref> [20, 21] </ref> describe reflexive/reactive approaches to autonomous vehicle control. [20] is based on the construction of motor schemas, similar to the work on potential fields to generate robot commands. [21] describes an architecture for Autonomous Land Vehicle Navigation that at the lowest levels contains reflexive behaviors that in a broad sense <p> This technique can also be used to generate robust models of the world incrementally. [16] also discusses real-time obstacle avoidance using harmonic potential functions. [20, 21] describe reflexive/reactive approaches to autonomous vehicle control. <ref> [20] </ref> is based on the construction of motor schemas, similar to the work on potential fields to generate robot commands. [21] describes an architecture for Autonomous Land Vehicle Navigation that at the lowest levels contains reflexive behaviors that in a broad sense have a commitment to preserving the constitution of the
Reference: [21] <author> D. W. Payton, </author> <title> "An architecture for reflexive autonomous vehicle control," </title> <booktitle> Proc. of the IEEE Intl. Conf. on Robotics and Automation, </booktitle> <year> 1986. </year>
Reference-contexts: This technique can also be used to generate robust models of the world incrementally. [16] also discusses real-time obstacle avoidance using harmonic potential functions. <ref> [20, 21] </ref> describe reflexive/reactive approaches to autonomous vehicle control. [20] is based on the construction of motor schemas, similar to the work on potential fields to generate robot commands. [21] describes an architecture for Autonomous Land Vehicle Navigation that at the lowest levels contains reflexive behaviors that in a broad sense <p> also be used to generate robust models of the world incrementally. [16] also discusses real-time obstacle avoidance using harmonic potential functions. [20, 21] describe reflexive/reactive approaches to autonomous vehicle control. [20] is based on the construction of motor schemas, similar to the work on potential fields to generate robot commands. <ref> [21] </ref> describes an architecture for Autonomous Land Vehicle Navigation that at the lowest levels contains reflexive behaviors that in a broad sense have a commitment to preserving the constitution of the agent. One such behavior is obstacle avoidance.
Reference: [22] <author> S. S. Ravela, </author> <title> "A survey of reactivity," </title> <type> Tech. </type> <institution> Report COMPSCI TR-92-61, UMASS, </institution> <year> 1992. </year>
Reference-contexts: One such behavior is obstacle avoidance. For a survey of reactive systems, see <ref> [22] </ref>. [23] describes a generalized approach to reflex control for collision avoidance, introduced in [24].
Reference: [23] <author> M. S. B. Thomas C. Wikman and W. S. Newman, </author> <title> "Reflexive collision avoidance: A generalized approach," </title> <booktitle> Proc. of the IEEE Intl. Conf. on Robotics and Automation, </booktitle> <year> 1993. </year>
Reference-contexts: One such behavior is obstacle avoidance. For a survey of reactive systems, see [22]. <ref> [23] </ref> describes a generalized approach to reflex control for collision avoidance, introduced in [24].
Reference: [24] <author> W. S. Newman, </author> <title> "Automatic obstacle avoidance at high speeds via reflex control," </title> <type> PhD thesis, </type> <institution> Mas-sachusetts Institute of Technology, Department of Mechanical Engineering, </institution> <year> 1987. </year>
Reference-contexts: One such behavior is obstacle avoidance. For a survey of reactive systems, see [22]. [23] describes a generalized approach to reflex control for collision avoidance, introduced in <ref> [24] </ref>. In this paper the authors construct a reflex controller that examines the nearby C-space and rejects commands that would result in a collision. 3 Obstacle Detection The obstacle detection algorithm developed here simplify the task of detection. Further, certain justifiable assumptions are made to speed up the detection system.
Reference: [25] <author> R. M. Haralick and L. G. Shapiro, </author> <title> "Computer and robot vision Vol. I and II," </title> <publisher> Addison-Wesley Pub. Co., </publisher> <year> 1993. </year>
Reference-contexts: Note that most correlation based techniques make this as sumption. * Epipolarity: Image matching is a two dimensional search that can be reduced to a one dimensional search if constraints imposed by epipo-lar geometry inherent in an oriented image pair <ref> [25] </ref> are met. The detection algorithm exploits the epipolarity constraint by employing cameras with identical focal lengths that are aligned up to a scan line. * Identical camera/Digitizers: Identical cameras and digitizers are assumed to simplify the task of processing intensity images and finding correspondences.
Reference: [26] <author> D. Marr and T. Poggio, </author> <title> "A theory of human stereo vision," </title> <journal> Roy. Soc. London, </journal> <volume> vol B 204, </volume> <pages> pp. 301-328, </pages> <year> 1979. </year>
Reference-contexts: To eliminate this kind of salt and pepper noise, the popular constant-local-disparity constraint is exploited. This constraint enforces the disparities in a small window to have similar values. In the Marr-Poggio-Grimson approach <ref> [26, 27, 28] </ref>, matching ambiguity is resolved so that the chosen value is close to the majority disparity of unambiguous points in the neighborhood. We make use of the concept in a slightly different way.
Reference: [27] <author> D. Marr, </author> <title> "Vision," </title> <publisher> Freeman, </publisher> <year> 1982. </year>
Reference-contexts: To eliminate this kind of salt and pepper noise, the popular constant-local-disparity constraint is exploited. This constraint enforces the disparities in a small window to have similar values. In the Marr-Poggio-Grimson approach <ref> [26, 27, 28] </ref>, matching ambiguity is resolved so that the chosen value is close to the majority disparity of unambiguous points in the neighborhood. We make use of the concept in a slightly different way.
Reference: [28] <author> W. E. L. </author> <title> Grimson, "From images to surfaces," </title> <publisher> MIT press, </publisher> <year> 1981. </year>
Reference-contexts: To eliminate this kind of salt and pepper noise, the popular constant-local-disparity constraint is exploited. This constraint enforces the disparities in a small window to have similar values. In the Marr-Poggio-Grimson approach <ref> [26, 27, 28] </ref>, matching ambiguity is resolved so that the chosen value is close to the majority disparity of unambiguous points in the neighborhood. We make use of the concept in a slightly different way.
Reference: [29] <author> T. Lozano-Perez, </author> <title> "Spatial planning: A configuration space approach," </title> <journal> IEEE Trans. Computers, C-32, N0. </journal> <volume> 2, </volume> <pages> pp. 108-120, </pages> <year> 1983. </year>
Reference-contexts: Discretization and Relaxation: Each obstacle point expressed in a polar form is discretized to represent a location (i; j) in a discrete polar occupancy grid (POG). The POG is similar to a C-space map <ref> [29] </ref> and coarsely encodes the possible configurations that the vehicle can exist in.
Reference: [30] <author> D. A. Pomerleau, </author> <title> "Neuralnetwork perception for mobile robot guidance," </title> <publisher> Kluer Academic Publishing, </publisher> <address> Boston, </address> <year> 1983. </year>
Reference-contexts: However, we have conducted experiments in which the obstacle avoidance system coexists with other modules including a compass-based heading generator and a road follower <ref> [30] </ref>. Desirable behavior has been observed to emerge from a composition of these modules (for example, move along a particular heading while avoiding obstacles or follow a road while avoiding obstacles).
References-found: 30

