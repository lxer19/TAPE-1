URL: ftp://ftp.cs.rochester.edu/pub/papers/robotics/94.mccallum-aaai-ss.ps.Z
Refering-URL: http://www.cs.rochester.edu/u/mccallum/
Root-URL: 
Email: mccallum@cs.rochester.edu  
Title: Short-Term Memory in Visual Routines for "Off-Road Car Chasing"  
Author: R. Andrew McCallum 
Address: Rochester, NY 14627-0226  
Affiliation: Department of Computer Science University of Rochester  
Abstract: Using "off-road car chasing" as an example task, this paper explores the need for short-term memory (or "internal state") in visual routines. The driving domain involves dynamics, uncertainty and requires a tight sense-act loop. Some previous demonstrations of visual routines avoided the need for short-term memory by providing their agent with a bird's-eye view or a 360 ffi view [ Agre and Chapman, 1987; Chap-man, 1990; Reece, 1992 ] . In contrast, our SGI-rendered simulation provides a realistic, robot-centered view of the environment in which limited field of view and occlusions necessitate memory of past perceptions and actions. Our agent's action policy maintains a minimal, task-specific amounts of memory using a finite state machine. 
Abstract-found: 1
Intro-found: 1
Reference: [ Agre and Chapman, 1987 ] <author> Philip E. Agre and David Chapman. Pengi: </author> <title> an implementation of a theory of activity. </title> <booktitle> In AAAI, </booktitle> <pages> pages 268-272, </pages> <year> 1987. </year>
Reference: [ Agre, 1988 ] <author> Philip E. Agre. </author> <title> The Dynamic Structure of Everyday Life. </title> <type> PhD thesis, </type> <institution> MIT Artificial Intelligence Lab., </institution> <year> 1988. </year> <note> (Tech Report No. 1085). </note>
Reference: [ Ballard, 1989 ] <author> Dana H. Ballard. </author> <title> Reference frames for animate vision. </title> <booktitle> In Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1635-1641, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: In this paper I put machine learning aside, and concentrate on hand-built visual routines. 2 Selective Perception and Incomplete Perception An agent with selective perception focuses its sensors on those parts of the environment that are relevant to the task at hand <ref> [ Burt, 1988; Ballard, 1989 ] </ref> . Selective perception is enormously efficient because the agent does not have to process or represent features that are currently irrelevant.
Reference: [ Burt, 1988 ] <author> Peter J. Burt. </author> <title> Smart sensing within a pyramid vision machine. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 76(8) </volume> <pages> 1006-1015, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: In this paper I put machine learning aside, and concentrate on hand-built visual routines. 2 Selective Perception and Incomplete Perception An agent with selective perception focuses its sensors on those parts of the environment that are relevant to the task at hand <ref> [ Burt, 1988; Ballard, 1989 ] </ref> . Selective perception is enormously efficient because the agent does not have to process or represent features that are currently irrelevant.
Reference: [ Chapman, 1990 ] <author> David Chapman. </author> <title> Vision, Instruction, and Action. </title> <type> PhD thesis, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <year> 1990. </year>
Reference-contexts: eye-tracker.) 4 Visual Routines for the "Off-Road Chase" Task Visual routines [ Ullman, 1984 ] have had much success in domains similar to off-road car chasing: strategic suburban driving [ Reece, 1992 ] , the video game Pengo [ Agre and Chap-man, 1987 ] , and the video game Amazon <ref> [ Chapman, 1990 ] </ref> . All these domains involve Action Parameters Results Attend Feature Success, (e.g. color) Failure FoveateAttention SteerTowardsFoveation GasByFoveationHeight FoveateDirection angles SetGas 0-1 SetBrake 0-1 ClearAttentionMask AttentionMask Region, Feature AttentionIn Region Yes,No Table 1: The list of primitive instructions that have been implemented.
Reference: [ Chrisman et al., 1991 ] <author> Lonnie Chrisman, Rich Caruana, and Wayne Carriker. </author> <title> Intelligent agent design issues: Internal agent state and incomplete perception. </title> <booktitle> Working Notes of the AAAI Fall Symposium: Sensory Aspects of Robotic Intelligence, </booktitle> <year> 1991. </year>
Reference-contexts: When faced with incomplete perception the agent can often use internal state determined by past perceptions and actions in order to choose the correct action <ref> [ Chrisman et al., 1991; McCallum, 1993b; McCallum, 1993a ] </ref> . Examples will be given in section 3. We call this internal state "short-term memory" in or der to emphasize that our approach is based on building task-specific, minimal amounts of state, instead of building an all-inclusive world model.
Reference: [ McCallum, 1993a ] <author> R. Andrew McCallum. </author> <title> Learning with incomplete selective perception. </title> <type> Technical Report 453, </type> <institution> University of Rochester Computer Science Dept., </institution> <month> April </month> <year> 1993. </year> <type> PhD thesis proposal. </type>
Reference-contexts: When faced with incomplete perception the agent can often use internal state determined by past perceptions and actions in order to choose the correct action <ref> [ Chrisman et al., 1991; McCallum, 1993b; McCallum, 1993a ] </ref> . Examples will be given in section 3. We call this internal state "short-term memory" in or der to emphasize that our approach is based on building task-specific, minimal amounts of state, instead of building an all-inclusive world model.
Reference: [ McCallum, 1993b ] <author> R. Andrew McCallum. </author> <title> Overcoming incomplete perception with utile distinction memory. </title> <booktitle> In The Proceedings of the Tenth Internation Machine Learning Conference. </booktitle> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1993. </year>
Reference-contexts: When faced with incomplete perception the agent can often use internal state determined by past perceptions and actions in order to choose the correct action <ref> [ Chrisman et al., 1991; McCallum, 1993b; McCallum, 1993a ] </ref> . Examples will be given in section 3. We call this internal state "short-term memory" in or der to emphasize that our approach is based on building task-specific, minimal amounts of state, instead of building an all-inclusive world model.
Reference: [ Reece, 1992 ] <author> Douglas A. Reece. </author> <title> Selective Perception for Robot Driving. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <year> 1992. </year> <note> TR CMU-CS-92-139. </note>
Reference-contexts: to compare the eye movements of humans with the camera movements of our agent. (Our head-mounted display helmet has a built-in eye-tracker.) 4 Visual Routines for the "Off-Road Chase" Task Visual routines [ Ullman, 1984 ] have had much success in domains similar to off-road car chasing: strategic suburban driving <ref> [ Reece, 1992 ] </ref> , the video game Pengo [ Agre and Chap-man, 1987 ] , and the video game Amazon [ Chapman, 1990 ] .
Reference: [ Ullman, 1984 ] <author> Shimon Ullman. </author> <title> Visual routines. </title> <journal> Cognition, </journal> <volume> 18 </volume> <pages> 97-159, </pages> <year> 1984. </year> <title> (Also in: Visual Cognition, </title> <editor> S. Pinker ed., </editor> <year> 1985). </year>
Reference-contexts: Having a human perform the task in the same environment as our agent allows us to compare the eye movements of humans with the camera movements of our agent. (Our head-mounted display helmet has a built-in eye-tracker.) 4 Visual Routines for the "Off-Road Chase" Task Visual routines <ref> [ Ullman, 1984 ] </ref> have had much success in domains similar to off-road car chasing: strategic suburban driving [ Reece, 1992 ] , the video game Pengo [ Agre and Chap-man, 1987 ] , and the video game Amazon [ Chapman, 1990 ] .

References-found: 10

