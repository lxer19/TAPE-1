URL: http://www.cs.wustl.edu/~mas/Publications/UM-CS-1995-020.ps
Refering-URL: http://www.cs.wustl.edu/~mas/multiagent_learning.html
Root-URL: 
Title: What should be minimized in a decision tree: A re-examination  
Author: Neil C. Berkman and Tuomas W. Sandholm 
Abstract: Computer Science Department University of Massachusetts at Amherst CMPSCI Technical Report 95-20 September 6, 1995 
Abstract-found: 1
Intro-found: 1
Reference: <author> Blumer, A., Ehrenfeucht, A., Haussler, D., & Warmuth, M. K. </author> <year> (1987). </year> <title> Oc-cam's razor. </title> <journal> Information Processing Letters, </journal> <volume> 24, </volume> <pages> 377-380. </pages>
Reference: <author> Fayyad, U. M., & Irani, K. B. </author> <year> (1990). </year> <booktitle> What should be minimized in a decision tree? Proceedings of the Eighth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 749-754). </pages> <address> Boston, MA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Using this fact, Fayyad confines his analysis to binary trees. C4.5 (Quinlan, 1993) in such a way that performance on the training set is unchanged, trees more accurate than the original usually result. 4 The argument in the dissertation is an updated version of an argument appearing earlier <ref> (Fayyad & Irani, 1990) </ref>. 5 A data set is said to be ambiguous when it contains at least two examples that agree on the values of all the attributes but belong to different classes. [Fayyad's footnote] 5 The learning situation consists of a training set of m examples consistent with some
Reference: <author> Fayyad, U. M. </author> <year> (1991). </year> <title> On the induction of decision trees for multiple concept learning. </title> <type> Doctoral dissertation, </type> <institution> Computer Science and Engineering, University of Michigan. </institution>
Reference-contexts: The second justification for Occam's Razor assumes no such distribution. We claim that the second justification is questionable. We first discuss this in general and then analyze a specific example of an argument along these lines, a recent attempt <ref> (Fayyad, 1991) </ref> to justify formally a bias toward decision trees with few leaves. This line of reasoning relies on unsubstantiated assumptions and can be used to arrive at contradictory conclusions.
Reference: <author> Li, M., & Vitanyi, P. M. B. </author> <year> (1993). </year> <title> An introduction to Kolmogorov complexity and its applications. </title> <address> New York: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: This principle must be applied with care because it can easily lead to contradictions. A classic example is Bertrand's paradox <ref> (Li & Vitanyi, 1993) </ref>, where assuming a uniform distribution of the values of a quantity, and assuming a uniform distribution of the inverses of these values, leads to a contradiction. This paradox points out that uniformity assumptions applied to related distributions may be inconsistent with each other.
Reference: <author> Murphy, P., & Pazzani, M. </author> <year> (1994). </year> <title> Exploring the decision forest: An empirical investigation of Occam's Razor in decision tree induction. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1, </volume> <pages> 257-275. </pages>
Reference-contexts: This contradicts Fayyad's conclusion that ProbfP (T 1 ; *) &lt; P (T 2 ; *)g &gt; 1 2 . More complex examples of settings where trees with more leaves outperform trees with fewer leaves have been presented in <ref> (Murphy & Pazzani, 1994) </ref>. 4.2 Tightness of the bounds In Fayyad's argument, the purpose of the assumption that the bounds b 1 and b 2 are tight is to ensure that ProbfP (T 1 ; *) &lt; P (T 2 ; *)g &gt; 1 2 .
Reference: <author> Pearl, J. </author> <year> (1978). </year> <title> On the connection between the complexity and credibility of inferred models. </title> <journal> International Journal of General Systems, </journal> <volume> 4, </volume> <pages> 116-126. </pages> <note> 19 Quinlan, </note> <author> J. R. </author> <year> (1993). </year> <title> C4.5: Programs for machine learning. </title> <publisher> Morgan Kauf--mann. </publisher>
Reference-contexts: to prefer the partitioning of tree-space by size over any other, it is clear that the original result cannot be used to justify a bias toward decision trees with fewer leaves. 6 Counting trees vs. counting hypotheses Fayyad's argument for small trees differs from other examinations of the simplicity bias <ref> (Pearl, 1978) </ref> in that representations (in this case, decision trees) for hypotheses are counted rather than hypotheses themselves. One might suspect that the problems we demonstrate with Fayyad's analysis could be remedied by modifying the argument to count hypotheses, or equivalently, logically non-equivalent trees.
Reference: <author> Rao, R.B., Gordon, D. , & Spears, W. </author> <year> (1995). </year> <title> For every generalization action, is there really an equal and opposite reaction? Analysis of the Conservation Law for Generalization Performance. </title> <booktitle> Machine Learning: Proceedings of the Twelfth International Conference (pp. </booktitle> <pages> 115-121). </pages> <address> Tahoe City, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: To make an argument that such difficult problems occur in the real world for any algorithm, one needs to know something a priori about and the distribution of f's, as pointed out in Rao et al. <ref> (Rao, Gordon & Spears, 1995) </ref>. 3 The bias toward small decision trees has been questioned before. Murphy and Pazzani (1994) present example target concepts for which larger decision trees are more accurate. Webb (1995) shows that by systematically increasing the complexity of trees found by 4 distribution of f 's.
Reference: <author> Russell, S. J., & Norvig, P. </author> <year> (1995). </year> <title> Artificial intelligence: A modern approach. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall. </publisher>
Reference-contexts: Hence, other things being equal a simple hypothesis that is consistent with the observations is more likely to be correct than a complex one." <ref> (Russell & Norvig, 1995) </ref> In this paper, we do not dispute Occam's Razor. We believe that the first justification may well hold; that is, the phenomena that are studied in practice exhibit simplicity due to either inherent simplicity of natural problems or simplicity-directed biased sampling from among natural problems.
Reference: <author> Schaffer, C. </author> <year> (1993). </year> <title> Overfitting avoidance as bias. </title> <journal> Machine Learning, </journal> <volume> 10, </volume> <pages> 153-178. </pages>
Reference: <author> Schaffer, C. </author> <year> (1994). </year> <title> A conservation law for generalization performance. </title> <booktitle> Machine Learning: Proceedings of the Eleventh International Conference (pp. </booktitle> <pages> 259-265). </pages> <address> New Brunswick, NJ: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In the case where all hypotheses under consideration are consistent with the training set (which is usually the case for decision tree induction algorithms when no noise is present), any error must result from generalization error. Thus, Wolpert's results verify the above finding. Similarly, Schaffer's Conservation Law <ref> (Schaffer, 1994) </ref>, a restatement of some of the No Free Lunch theorems, demonstrates that expected generalization performance over all learning situations is zero.
Reference: <author> Webb, G. I. </author> <year> (1995). </year> <title> An experimental disproof of Occam's razor, (TR-C95-07), </title> <type> Geelong, </type> <institution> Australia: Deakin University, School of Computing and Mathematics. </institution>
Reference: <author> Wolpert, D. H. </author> <year> (1992). </year> <title> On the connection between in-sample testing and generalization error. </title> <journal> Complex Systems, </journal> <volume> 6, </volume> <pages> 47-94. </pages>
Reference-contexts: This argument casts severe doubts upon the second (rarity of simple theories) justification of Occam's Razor. Wolpert has presented similar results (the No Free Lunch theorems <ref> (Wolpert, 1992) </ref>) concerning generalization performance, accuracy on examples not found in the training set. In the case where all hypotheses under consideration are consistent with the training set (which is usually the case for decision tree induction algorithms when no noise is present), any error must result from generalization error.
Reference: <author> Wolpert, D. H. </author> <year> (1993). </year> <title> On overfitting avoidance as bias, </title> <type> (SFI TR 93-03-016), </type> <institution> Santa Fe, NM: The Santa Fe Institute. </institution>
Reference: <author> Wolpert, D. H. </author> <year> (1994a). </year> <title> On the Bayesian "Occam factors" argument for Oc-cam's Razor. </title> <editor> In Hanson, Drastal & Rivest (Eds.), </editor> <booktitle> Computational learning theory and natural learning systems: Volume III Natural learning systems. </booktitle> <address> Cambridge, MA: </address> <publisher> M.I.T. Press. </publisher>
Reference-contexts: These results call into question several previously published results. For example, Wolpert has shown that the Bayesian "Occam factors" argument for Occam's Razor is incorrect <ref> (Wolpert, 1994a) </ref>. The remainder of our paper is an examination of Fayyad's attempt to theoretically justify a bias toward small decision trees 3 .
Reference: <author> Wolpert, D. H. </author> <year> (1994b). </year> <title> The relationship between PAC, the statistical physics framework, the Bayesian framework, and the VC framework, </title> <type> (SFI TR 94-03-123), </type> <institution> Santa Fe, NM: The Santa Fe Institute. </institution>
Reference: <author> Wolpert, D. H. </author> <year> (1995). </year> <title> Off-training set error and a priori distinctions between learning algorithms, </title> <type> (SFI TR 95-01-003), </type> <institution> Santa Fe, NM: The Santa Fe Institute. </institution> <month> 20 </month>
References-found: 16

