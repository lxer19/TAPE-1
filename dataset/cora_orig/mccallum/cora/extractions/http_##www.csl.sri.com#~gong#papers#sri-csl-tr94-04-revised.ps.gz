URL: http://www.csl.sri.com/~gong/papers/sri-csl-tr94-04-revised.ps.gz
Refering-URL: http://www.csl.sri.com/~gong/papers/sri-csl-tr94-04-abs.html
Root-URL: 
Email: fgong,goldbergg@csl.sri.com  
Title: Implementing Adaptive Fault-Tolerant Services for Hybrid Faults  
Author: Li Gong and Jack Goldberg 
Keyword: Index Terms. Fault tolerance, primary backup, state machine, manifest faults, Byzantine faults, hybrid faults, adaptivity, distributed systems services, algorithm complexity.  
Date: March 22, 1994 (Revised September 30, 1994)  
Address: Menlo Park, California 94025 U.S.A.  
Affiliation: SRI International Computer Science Laboratory  
Abstract: The two major approaches to building fault-tolerant services are commonly known as the Primary-Backup approach (PB) and the State-Machine approach (SM). PB can tolerate crash and omission faults and runs more economically than SM, but SM can tolerate more serious faults, including arbitrary or Byzantine faults. Instead of selecting one or the other approach, thus either incurring a high running cost or risking the service becoming incorrect when unexpected faults occur, we advocate the approach of adaptive fault tolerance. We present algorithms that intelligently adapt between PB and SM, thus retaining (almost) the best of both worlds. Our adaptive approach is modular in that any PB or SM protocol can be used, and is also practical in that it can be easily incorporated into some existing systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P.A. Alsberg and J.D. Day. </author> <title> A Principle for Resilient Sharing of Distributed Resources. </title> <booktitle> In Proceedings of the 2nd International Conference on Software Engineering, </booktitle> <pages> pages 627-644, </pages> <month> October </month> <year> 1976. </year>
Reference-contexts: 1 Introduction In building fault tolerance services in a distributed system, there are two major approaches, namely, the Primary-Backup approach (PB) (e.g., <ref> [1, 9] </ref>) and the State-Machine approach (SM) (e.g., [19, 16]). Each approach has its distinctive advantages.
Reference: [2] <author> P. Berman, J.A. Garay, and K.J. Perry. </author> <title> Optimal Early Stopping in Distributed Consensus. </title> <booktitle> In Proceedings of the 6th International Workshop on Distributed Algorithms, volume 647 of Lecture Notes in Computer Science, </booktitle> <pages> pages 221-237, </pages> <address> Haifa, Israel, </address> <month> November </month> <year> 1992. </year> <note> Springer-Verlag. </note>
Reference-contexts: In contrast, our adaptive algorithms are much less expensive because for most of the time they merely attempt to detect arbitrary faults, and activate the heavy machinery to tolerate arbitrary faults only as they occur. Our adaptation strategy is in flavour similar to early-stopping protocols (e.g., <ref> [10, 7, 2] </ref>). The complexity (i.e., numbers of messages and rounds) of these protocols is proportional to the number of actual faults occurring instead of the maximum number of faults that can be tolerated. In other words, the protocols terminate earlier if fewer faults occur.
Reference: [3] <author> K.P. Birman. </author> <title> Replication and Availability in the ISIS System. </title> <booktitle> In Proceedings of the 10th ACM Symposium on Operating System Principles, volume 19(5) of ACM Operating Systems Review, </booktitle> <pages> pages 79-86, </pages> <month> December </month> <year> 1985. </year>
Reference-contexts: The backups simply follow the primary's lead. This arrangement satisfies the Replica Coordination requirement [16], and is crucial for keeping the cost down. This is in the same spirit of the coordinator-cohort scheme <ref> [3, 5] </ref>. Any additional ordering can be enforced with other methods, which are beyond the scope of this paper. Proof of correctness.
Reference: [4] <author> K.P. Birman. </author> <title> The Process Group Approach to Reliable Distributed Computing. </title> <journal> Communications of the ACM, </journal> <volume> 36(12) </volume> <pages> 37-53/103, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Our adaptive algorithms not only offer some theoretical insight into the relationship between the primary-backup and state-machine approaches to implementing fault-tolerant services, they also appear to be very practical. For example, given the existing support for process groups and virtual synchrony in the ISIS/Horus system <ref> [4] </ref>, it should not be difficult to add an adaptation facility so that non-manifest faults can be tolerated as needed.
Reference: [5] <author> K.P. Birman, T.A. Joseph, T. Raeuchle, and A. El Abadi. </author> <title> Implementing Fault-tolerant Distributed Objects. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 6(11) </volume> <pages> 502-508, </pages> <month> June </month> <year> 1985. </year>
Reference-contexts: The backups simply follow the primary's lead. This arrangement satisfies the Replica Coordination requirement [16], and is crucial for keeping the cost down. This is in the same spirit of the coordinator-cohort scheme <ref> [3, 5] </ref>. Any additional ordering can be enforced with other methods, which are beyond the scope of this paper. Proof of correctness.
Reference: [6] <author> N. Budhiraja. </author> <title> The Primary-Backup Approach: Lower and Upper Bounds. </title> <type> Ph.d. dissertation, </type> <institution> Cornell University, </institution> <address> Ithaca, New York, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: Moreover, we assume that the system is synchronous, and thus we can use a model of computation based on rounds. The reason for this limitation is that it is impossible to guarantee both safety and liveness in asynchronous systems <ref> [6, p.19] </ref>. <p> The schema for a server consists of three modules for: (1) deciding whether it is a primary or a backup, (2) processing requests, and (3) fault detection and recovery <ref> [6, p.56] </ref>. It is apparent that the PB approach can tolerate only manifest faults. For example, an incorrect primary can broadcast an incorrect state change and backup servers cannot detect this fact because they do not know the client's service request. <p> In addition, we have assumed that the client always expects to get the response a (r) from the primary. Some PB protocols are "pass-the-buck" in that the response always comes from a different server <ref> [6, p.100] </ref>. Our framework can also accommodate these protocols. If the primary has failed manifestly, the identity of the new primary is decided according to the PB protocol and is conveyed to the client. <p> We have made heavy use of materials on primary-backup protocols <ref> [9, 8, 6] </ref> and the state-machine approach [16]. In particular, our adaptive algorithms use those protocols as building blocks, in a modular fashion. <p> There have been efforts to evaluate the relative merits of various fault tolerance techniques for different applications (e.g., [18]), especially following the recent precise formulation and analysis of the widely used primary-backup approach <ref> [9, 8, 6] </ref>. Our work provides some insight in that one can adaptively use these different approaches and retain (almost) the best of both worlds. Finally, since our adaptation is modular in that it uses existing primary-backup and Byzantine agreement protocols as building blocks, our algorithms are conceptually simple.
Reference: [7] <author> N. Budhiraja, A. Gopal, and S. Toueg. </author> <title> Early Stopping Distributed Bidding and Applications. </title> <booktitle> In Proceedings of the 4th International Workshop on Distributed Algorithms, volume 486 of Lecture Notes in Computer Science, </booktitle> <pages> pages 304-320, </pages> <address> Haifa, Israel, </address> <month> September </month> <year> 1990. </year> <note> Springer-Verlag. </note>
Reference-contexts: In contrast, our adaptive algorithms are much less expensive because for most of the time they merely attempt to detect arbitrary faults, and activate the heavy machinery to tolerate arbitrary faults only as they occur. Our adaptation strategy is in flavour similar to early-stopping protocols (e.g., <ref> [10, 7, 2] </ref>). The complexity (i.e., numbers of messages and rounds) of these protocols is proportional to the number of actual faults occurring instead of the maximum number of faults that can be tolerated. In other words, the protocols terminate earlier if fewer faults occur.
Reference: [8] <author> N. Budhiraja, K. Marzullo, F.B. Schneider, and S. Toueg. </author> <title> Optimal Primary-Backup Protocols. </title> <booktitle> In Proceedings of the 6th International Workshop on Distributed Algorithms, volume 647 of Lecture Notes in Computer Science, </booktitle> <pages> pages 362-378, </pages> <address> Haifa, Israel, </address> <month> November </month> <year> 1992. </year> <note> Springer-Verlag. </note>
Reference-contexts: We have made heavy use of materials on primary-backup protocols <ref> [9, 8, 6] </ref> and the state-machine approach [16]. In particular, our adaptive algorithms use those protocols as building blocks, in a modular fashion. <p> There have been efforts to evaluate the relative merits of various fault tolerance techniques for different applications (e.g., [18]), especially following the recent precise formulation and analysis of the widely used primary-backup approach <ref> [9, 8, 6] </ref>. Our work provides some insight in that one can adaptively use these different approaches and retain (almost) the best of both worlds. Finally, since our adaptation is modular in that it uses existing primary-backup and Byzantine agreement protocols as building blocks, our algorithms are conceptually simple.
Reference: [9] <author> N. Budhiraja, K. Marzullo, F.B. Schneider, and S. Toueg. </author> <title> Primary-Backup Protocols: Lower Bounds and Optimal Implementations. </title> <booktitle> In Proc. 3rd IFIP Working Conference on Dependable Computing for Critical Applications, </booktitle> <pages> pages 187-196, </pages> <address> Sicily, Italy, </address> <month> September </month> <year> 1992. </year> <month> 12 </month>
Reference-contexts: 1 Introduction In building fault tolerance services in a distributed system, there are two major approaches, namely, the Primary-Backup approach (PB) (e.g., <ref> [1, 9] </ref>) and the State-Machine approach (SM) (e.g., [19, 16]). Each approach has its distinctive advantages. <p> We have made heavy use of materials on primary-backup protocols <ref> [9, 8, 6] </ref> and the state-machine approach [16]. In particular, our adaptive algorithms use those protocols as building blocks, in a modular fashion. <p> There have been efforts to evaluate the relative merits of various fault tolerance techniques for different applications (e.g., [18]), especially following the recent precise formulation and analysis of the widely used primary-backup approach <ref> [9, 8, 6] </ref>. Our work provides some insight in that one can adaptively use these different approaches and retain (almost) the best of both worlds. Finally, since our adaptation is modular in that it uses existing primary-backup and Byzantine agreement protocols as building blocks, our algorithms are conceptually simple.
Reference: [10] <author> D. Dolev, R. Reischuk, and H.R. </author> <title> Strong. Early Stopping in Byzantine Agreement. </title> <journal> Journal of the ACM, </journal> <volume> 37(4) </volume> <pages> 720-741, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: In contrast, our adaptive algorithms are much less expensive because for most of the time they merely attempt to detect arbitrary faults, and activate the heavy machinery to tolerate arbitrary faults only as they occur. Our adaptation strategy is in flavour similar to early-stopping protocols (e.g., <ref> [10, 7, 2] </ref>). The complexity (i.e., numbers of messages and rounds) of these protocols is proportional to the number of actual faults occurring instead of the maximum number of faults that can be tolerated. In other words, the protocols terminate earlier if fewer faults occur.
Reference: [11] <author> J.A. Garay and K.J. Perry. </author> <title> A Continuum of Failure Models for Distributed Computing. </title> <booktitle> In Proceedings of the 6th International Workshop on Distributed Algorithms, volume 647 of Lecture Notes in Computer Science, </booktitle> <pages> pages 153-165, </pages> <address> Haifa, Israel, </address> <month> November </month> <year> 1992. </year> <note> Springer-Verlag. </note>
Reference-contexts: Therefore, they are usually much more expensive than our algorithms, which take advantage of the common observation that in most applications Byzantine faults occur only infrequently. Nevertheless, our algorithms can use early-stopping Byzantine agreement protocols or those above for hybrid faults to further increase efficiency. Garay and Perry <ref> [11] </ref> recently proposed a continuum of failure models with crash-only faults and 10 Byzantine faults at the extremes. This can be taken as a combination of early stopping and dealing with hybrid faults.
Reference: [12] <author> J. Goldberg, I. Greenberg, and T.F. Lawrence. </author> <title> Adaptive Fault Tolerance. </title> <booktitle> In Proceedings of the IEEE Workshop on Advances in Parallel and Distributed Systems, </booktitle> <pages> pages 127-132, </pages> <address> Princeton, New Jersey, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: Instead of being forced to make a design choice between using SM or PB, thus either incurring a high running cost or risking system failure when unexpected faults occur, we advocate an approach of adaptive fault tolerance <ref> [12] </ref>. <p> However, if the client does not report error in Round 3, it can complete the protocol after Round 3, earlier than the servers. 4 Related Work Our work is undertaken within the general framework outlined in <ref> [12] </ref> and can be viewed as a realization of some of the principles of adaptive fault tolerance. We have made heavy use of materials on primary-backup protocols [9, 8, 6] and the state-machine approach [16]. In particular, our adaptive algorithms use those protocols as building blocks, in a modular fashion.
Reference: [13] <author> L. Lamport, R. Shostak, and M. Pease. </author> <title> The Byzantine Generals Problem. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 4(3) </volume> <pages> 382-401, </pages> <month> July </month> <year> 1982. </year>
Reference-contexts: Air Force under USAF contract F30602-92-C-0098. 1 faults 1 . Therefore, it is common practice for critical applications to run a SM protocol, possibly using Byzantine agreement <ref> [13] </ref>. The high cost of running such a protocol is compensated by the belief that all possible faults (up to a certain number) are adequately tolerated. <p> These algorithms typically can tolerate as many Byzantine faults as possible (bounded by one third of the number of processors <ref> [13] </ref>). However, when other non-manifest faults do not occur, the algorithm by Thambidurai and Park [17] cannot tolerate many manifest faults whereas our algorithms can tolerate a maximum number of manifest faults because they will be running a Primary-Backup protocol.
Reference: [14] <author> P. Lincoln and J. Rushby. </author> <title> A Formally Verified Algorithm for Interactive Consistency Under a Hybrid Fault Model. </title> <booktitle> In Proceedings of the 23rd Fault-Tolerant Computing Symposium, </booktitle> <pages> pages 402-411, </pages> <address> Toulouse, France, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: The reason for this limitation is that it is impossible to guarantee both safety and liveness in asynchronous systems [6, p.19]. Following the literature, we classify faults into three categories <ref> [14] </ref>: * Manifest fault one that produces detectably missing values (e.g., crash and omission faults) or that produces a value that all nonfaulty recipients can detect as bad (e.g., it fails checksum or format or typing tests). * Symmetric fault one that delivers the same wrong value to every nonfaulty receiver. <p> In particular, our adaptive algorithms use those protocols as building blocks, in a modular fashion. Previous work on handling hybrid faults appears to focus on extending protocols for Byzantine agreement so that they can tolerate a higher number of benign or hybrid faults (e.g., <ref> [14, 15, 17] </ref>) than a standard Byzantine agreement protocol. These algorithms typically can tolerate as many Byzantine faults as possible (bounded by one third of the number of processors [13]). <p> However, when other non-manifest faults do not occur, the algorithm by Thambidurai and Park [17] cannot tolerate many manifest faults whereas our algorithms can tolerate a maximum number of manifest faults because they will be running a Primary-Backup protocol. The algorithm by Lincoln and Rushby <ref> [14] </ref> can tolerate a maximum number of manifest faults but, like the algorithm by Thambidurai and Park [17], it is non-adaptive in that the number of rounds of each execution of the protocol is decided in advance so the complexity of the protocol does not decrease when no or fewer faults
Reference: [15] <author> F.J. Meyer and D.K. Pradhan. </author> <title> Consensus with Dual Failure Modes. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(2) </volume> <pages> 214-222, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: In particular, our adaptive algorithms use those protocols as building blocks, in a modular fashion. Previous work on handling hybrid faults appears to focus on extending protocols for Byzantine agreement so that they can tolerate a higher number of benign or hybrid faults (e.g., <ref> [14, 15, 17] </ref>) than a standard Byzantine agreement protocol. These algorithms typically can tolerate as many Byzantine faults as possible (bounded by one third of the number of processors [13]).
Reference: [16] <author> F.B. Schneider. </author> <title> Implementing Fault-Tolerant Services Using the State-Machine Approach: A Tutorial. </title> <journal> ACM Computing Surveys, </journal> <volume> 22(4) </volume> <pages> 299-319, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: 1 Introduction In building fault tolerance services in a distributed system, there are two major approaches, namely, the Primary-Backup approach (PB) (e.g., [1, 9]) and the State-Machine approach (SM) (e.g., <ref> [19, 16] </ref>). Each approach has its distinctive advantages. To tolerate simple faults such as crash and omission, PB protocols are generally significantly cheaper than SM protocols in terms of the numbers of processors, messages, and rounds (which directly affects the service response time). <p> Therefore, the client will decide on the correct response if a majority of the servers are nonfaulty. For correctness, all nonfaulty servers must process requests (possibly from multiple clients) in the same order. This requirement is called replica coordination <ref> [16] </ref> and is not necessary in a PB protocol. Satisfying this coordination requirement is quite expensive for example, a Byzantine agreement protocol is a typical solution. <p> The primary is free to choose the next request to process, as long as the order among requests from the same client is FIFO. The backups simply follow the primary's lead. This arrangement satisfies the Replica Coordination requirement <ref> [16] </ref>, and is crucial for keeping the cost down. This is in the same spirit of the coordinator-cohort scheme [3, 5]. Any additional ordering can be enforced with other methods, which are beyond the scope of this paper. Proof of correctness. <p> A subsequent BA protocol will mask this fault and the client can obtain the correct response by simple majority voting <ref> [16] </ref>. (4) If the primary is nonfaulty, then at most a minority of backup servers will report error (note that no protocol can tolerate a majority of servers being non-manifestly faulty), and these error messages are false alarms and rightly ignored. 2 Analysis of complexity. <p> When only manifest faults occur, it is still much cheaper than a full-fledged state-machine approach in that backup servers simply follow the lead by the primary in deciding the next request to process. This arrangement eliminates the need for extra effort to satisfy the Replica Coordination requirement <ref> [16] </ref>. When asymmetric faults occur, BOD-2 may use one more round than BOD-1, for example, when the backup servers have to wait till Round 4 to decide whether to switch to the BA protocol. <p> We have made heavy use of materials on primary-backup protocols [9, 8, 6] and the state-machine approach <ref> [16] </ref>. In particular, our adaptive algorithms use those protocols as building blocks, in a modular fashion. <p> They can run parallel to our algorithms. To reintegrate a repaired component, if only symmetric faults are possible, algorithms can be developed so that the repaired server obtains state information from a small number of existing servers. If asymmetric faults are possible, then those methods mentioned in <ref> [16] </ref> can be used. Other aspects 11 of adaptation, such as fault transparency to clients and the cost to repair damaged servers, may also be worth investigating.
Reference: [17] <author> P. Thambidurai and Y.K. Park. </author> <title> Interactive Consistency with Multiple Failure Modes. </title> <booktitle> In Proceedings of 7th IEEE Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 93-100, </pages> <address> Columbus, Ohio, </address> <month> October </month> <year> 1988. </year>
Reference-contexts: In particular, our adaptive algorithms use those protocols as building blocks, in a modular fashion. Previous work on handling hybrid faults appears to focus on extending protocols for Byzantine agreement so that they can tolerate a higher number of benign or hybrid faults (e.g., <ref> [14, 15, 17] </ref>) than a standard Byzantine agreement protocol. These algorithms typically can tolerate as many Byzantine faults as possible (bounded by one third of the number of processors [13]). <p> These algorithms typically can tolerate as many Byzantine faults as possible (bounded by one third of the number of processors [13]). However, when other non-manifest faults do not occur, the algorithm by Thambidurai and Park <ref> [17] </ref> cannot tolerate many manifest faults whereas our algorithms can tolerate a maximum number of manifest faults because they will be running a Primary-Backup protocol. The algorithm by Lincoln and Rushby [14] can tolerate a maximum number of manifest faults but, like the algorithm by Thambidurai and Park [17], it is <p> and Park <ref> [17] </ref> cannot tolerate many manifest faults whereas our algorithms can tolerate a maximum number of manifest faults because they will be running a Primary-Backup protocol. The algorithm by Lincoln and Rushby [14] can tolerate a maximum number of manifest faults but, like the algorithm by Thambidurai and Park [17], it is non-adaptive in that the number of rounds of each execution of the protocol is decided in advance so the complexity of the protocol does not decrease when no or fewer faults occur.
Reference: [18] <author> A. Waterworth, P.D. Ezhilchelvan, and S.K. Shrivastava. </author> <title> Understanding the Cost of Replication in Distributed Systems. </title> <type> Technical report, </type> <institution> Computing Laboratory, University of Newcastle upon Tyne, U.K., </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: In particular, the algorithms adapt between two different approaches, namely primary-backup and state-machine, and utilize to the maximum the efficiency of a primary-backup protocol. There have been efforts to evaluate the relative merits of various fault tolerance techniques for different applications (e.g., <ref> [18] </ref>), especially following the recent precise formulation and analysis of the widely used primary-backup approach [9, 8, 6]. Our work provides some insight in that one can adaptively use these different approaches and retain (almost) the best of both worlds.
Reference: [19] <author> J.H. Wensley, L. Lamport, J. Goldberg, M.W. Green, K.N. Levitt, P.M. Melliar-Smith, R.E. Shostak, and C.B. Weinstock. SIFT: </author> <title> Design and Analysis of a Fault-Tolerant Computer for Aircraft Control. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 66(10) </volume> <pages> 1240-1255, </pages> <month> October </month> <year> 1978. </year> <month> 13 </month>
Reference-contexts: 1 Introduction In building fault tolerance services in a distributed system, there are two major approaches, namely, the Primary-Backup approach (PB) (e.g., [1, 9]) and the State-Machine approach (SM) (e.g., <ref> [19, 16] </ref>). Each approach has its distinctive advantages. To tolerate simple faults such as crash and omission, PB protocols are generally significantly cheaper than SM protocols in terms of the numbers of processors, messages, and rounds (which directly affects the service response time).
References-found: 19

