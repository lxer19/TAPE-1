URL: http://www.cse.psu.edu/~bishop/ipps.ps
Refering-URL: http://www.cse.psu.edu/~bishop/
Root-URL: http://www.cse.psu.edu
Title: Aggressive Dynamic Execution of Multimedia Kernel Traces  
Author: Benjamin Bishop Robert Owens Mary Jane Irwin 
Address: Park, PA 16802  
Affiliation: Department of Computer Science and Engineering The Pennsylvania State University University  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> A Tour of the Pentium Pro Processor Microarchitecture http://www.intel.com/ procs/ppro/info/p6white/index.htm. </institution>
Reference-contexts: Simulation Methodology A simulator was designed to evaluate our multimedia processor. It uses single path trace storage and the two-part execution engine described above. Other details and features of the architecture are modeled after the Intel Pen-tium Pro processor <ref> [1] </ref>.
Reference: [2] <institution> The GCC Compiler Version 2.7.2 http://ftp.cs.umn.edu/pub/gnu/gcc-2.7.2.tar.gz. </institution>
Reference-contexts: The simulator was constructed by using a simple RISC ISA. The simulator was tested with a number of popular multimedia benchmarks compiled under an enhanced version of GCC <ref> [2] </ref>. 3.1. The Architectural Simulator The architecture of the simulator allows for superscalar dynamic instruction scheduling or trace execution mode as described in section 1.3. The simulator was further extended to include the ability to selectively disable trace execution mode in order to facilitate comparisons with typical architectures.
Reference: [3] <author> W.M. Hwu and Y.N. Patt, HPSm, </author> <title> A High Performance Restricted Data Flow Architecture Having Minimal Functionally Proc. </title> <booktitle> 24th Annual International Symposium on Computer Architecture, </booktitle> <address> Tokyo, </address> <year> 1986. </year>
Reference-contexts: However, the implementation of a dataflow processor can be difficult due to the complexity of scheduling a potentially very large pool of instructions. What has been called restrictive dataflow <ref> [3, 4, 12] </ref> can be viewed as a compromise between completely static and fully dynamic scheduling. Conceptually, in restrictive dataflow, the instructions of a statically scheduled instruction stream are first decoded and then added to a pool of now dynamically schedulable instructions.
Reference: [4] <author> S. Melvin, M. Shebanow, Y. Patt, </author> <title> Hardware Support for Large Atomic Units in Dynamically Scheduled Machines Proc. </title> <booktitle> 21th Ann. International Symposium on Microarchitecture, </booktitle> <month> December </month> <year> 1988. </year>
Reference-contexts: However, the implementation of a dataflow processor can be difficult due to the complexity of scheduling a potentially very large pool of instructions. What has been called restrictive dataflow <ref> [3, 4, 12] </ref> can be viewed as a compromise between completely static and fully dynamic scheduling. Conceptually, in restrictive dataflow, the instructions of a statically scheduled instruction stream are first decoded and then added to a pool of now dynamically schedulable instructions. <p> A number of prior works have proposed optimizations that can be used to improve dynamic scheduling. The following subsection discusses these works. 1.2. Prior work The fill unit, as proposed by Melvin, Shebanow, and Patt <ref> [4] </ref>, effectively deals with the problem of issuing a large number of simple instructions. In this scheme, complex in-structions are decomposed into RISC-like microoperations that are then stored in a fill unit. The fill unit then forms groups of indivisible or atomic microoperations.
Reference: [5] <author> M. Smotherman, M. Franklin, </author> <title> Improving CISC Instruction Decoding Performance Using a Fill Unit Proc. </title> <booktitle> 28th Ann. International Symposium on Microar-chitecture, </booktitle> <year> 1995. </year>
Reference-contexts: The fill unit then forms groups of indivisible or atomic microoperations. These VLIW-like groups can be more simply scheduled. The idea of the fill unit was later extended by Smoth-erman and Franklin <ref> [5] </ref> to allow for the reuse of decoded instructions. They noted that while CISC machines typically have reduced fetch bandwidth requirements, they suffer from difficult, high latency decoding. As a way to combat this problem, Smotherman and Franklin suggest using a fill unit to feed a decoded instruction buffer.
Reference: [6] <author> M. </author> <title> Hiraki et al.,Stage-Skip Pipeline: A Low Power Processor Architecture Using a Decoded Instruction Buffer Proc. </title> <booktitle> 1996 International Symposium on Low Power Electronics and Design, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: As a way to combat this problem, Smotherman and Franklin suggest using a fill unit to feed a decoded instruction buffer. When the buffer contains a pre-decoded version of a needed instruction, the instruction can be fetched directly from the buffer, bypassing the decode logic. Hiraki et al. <ref> [6] </ref> propose a similar strategy in order to reduce power consumption. The trace cache, as proposed by Rotenberg, Bennett, and Smith [7], decreases fetch/decode traffic by the use of a cache containing dynamically stored instruction traces.
Reference: [7] <author> E. Rotenberg et al., </author> <title> Trace Cache: a Low Latency Approach to High Bandwidth Instruction Fetching Proc. </title> <booktitle> 29th Annual International Symposium on Microarchi-tecture, </booktitle> <month> December </month> <year> 1996. </year>
Reference-contexts: When the buffer contains a pre-decoded version of a needed instruction, the instruction can be fetched directly from the buffer, bypassing the decode logic. Hiraki et al. [6] propose a similar strategy in order to reduce power consumption. The trace cache, as proposed by Rotenberg, Bennett, and Smith <ref> [7] </ref>, decreases fetch/decode traffic by the use of a cache containing dynamically stored instruction traces. They suggest that by storing segments of the dynamic instruction stream, a supplemental cache could lower latency and fetch bandwidth requirements.
Reference: [8] <author> M. Slater, </author> <title> The Land Beyond Benchmarks Comput. </title> <journal> Commun. OEM, Mag. </journal> <volume> 4, 31, </volume> <pages> pp. 6477, </pages> <month> September </month> <year> 1996. </year>
Reference-contexts: In the algorithm, these error approximations are used to judge the goodness of compression choices. With the rising popularity of multimedia applications, MPEG compression and decompression kernels are becoming very important. This is shown by the inclusion of MPEG decompression in the Intel Media Benchmark <ref> [8, 9] </ref>. 4.4. CPOLY Zeros of a Complex Polynomial Benchmark The CPOLY benchmark [15] finds all the zeros of a complex polynomial or equivalently finds the eigenvalues of the polynomial's characterization matrix.
Reference: [9] <author> A. Peleg, S. Wilkie, U. Weiser, </author> <booktitle> Intel MMX for Multimedia PCs Communications of the ACM, </booktitle> <volume> vol. 40, no. 1, </volume> <pages> pp. 2538, </pages> <month> Jan. </month> <year> 1997. </year>
Reference-contexts: The importance of solving these problems is illustrated by the incorporation of MMX <ref> [9] </ref> into the Intel processor line. In order to build an effective multimedia processor, it is necessary to understand the nature of the target application area. Upon examination, the codes for multimedia applications do not appear to readily fit into a class for which a benchmark suite exists. <p> Although multimedia instruction sets could be used in such an architecture. Like the Pentium Pro architecture, the simulator employs branch prediction when operating in either superscalar or trace mode. 4. Benchmarks As seen in industry <ref> [9] </ref>, there is a great demand for architectures specifically adapted for multimedia applications. In order to demonstrate the efficiency of our architecture for such applications, a variety of multimedia based benchmarks were evaluated. 4.1. LPC Speech Compression Benchmark This benchmark makes use of linear prediction kernels for speech encoding. <p> This had a very positive effect, as seen by its large performance gains in section 5. The importance of the Discrete Cosine Transform in multimedia applications can be seen by the discussion of it in <ref> [9] </ref>. 3 4.3. MPEG Video Compression Benchmark We used the Berkeley MPEG encoding benchmark [10] executed with the Find Best Match Exhaustive search algorithm. This algorithm finds the best match using an exhaustive spiral search. The program was used on a number of images with proportional results. <p> In the algorithm, these error approximations are used to judge the goodness of compression choices. With the rising popularity of multimedia applications, MPEG compression and decompression kernels are becoming very important. This is shown by the inclusion of MPEG decompression in the Intel Media Benchmark <ref> [8, 9] </ref>. 4.4. CPOLY Zeros of a Complex Polynomial Benchmark The CPOLY benchmark [15] finds all the zeros of a complex polynomial or equivalently finds the eigenvalues of the polynomial's characterization matrix.
Reference: [10] <author> L. Rowe et al., </author> <title> Berkeley MPEG Tools ftp://mm-ftp.cs.berkeley.edu/pub/multimedia/ mpeg/bmt1r1.tar.gz. </title>
Reference-contexts: This had a very positive effect, as seen by its large performance gains in section 5. The importance of the Discrete Cosine Transform in multimedia applications can be seen by the discussion of it in [9]. 3 4.3. MPEG Video Compression Benchmark We used the Berkeley MPEG encoding benchmark <ref> [10] </ref> executed with the Find Best Match Exhaustive search algorithm. This algorithm finds the best match using an exhaustive spiral search. The program was used on a number of images with proportional results.
Reference: [11] <author> G. Bergland, </author> <title> A Radix-eight Fast Fourier Transform Subroutine for Real-valued Series IEEE Transactions on Audio and Electro-acoustics, </title> <journal> vol. AU-17, pp. </journal> <volume> 138 144, </volume> <year> 1969. </year>
Reference-contexts: In order to perform the matrix operations associated with this benchmark, the daxpy routine for vector addition was borrowed from linpack. 4.2. DCT Discrete Cosine Transform Benchmark This benchmark uses an algorithm that implements a radix-eight Discrete Cosine Transform as described by Bergland <ref> [11] </ref>. An eight point kernel is used. Discrete Cosine Transforms typically use a great deal of looping, but the code used was unrolled except for the primary loop. This had a very positive effect, as seen by its large performance gains in section 5.
Reference: [12] <author> Y.N.Patt, W.M. Hwu and M.C. Shebanow, HPS, </author> <title> A New Microarchitecure: Rational and Introduction Proc. </title> <booktitle> 18th Annual International Symposium on Mi-croarchitecture, </booktitle> <month> December </month> <year> 1985, </year> <pages> pp. 103-108. </pages>
Reference-contexts: However, the implementation of a dataflow processor can be difficult due to the complexity of scheduling a potentially very large pool of instructions. What has been called restrictive dataflow <ref> [3, 4, 12] </ref> can be viewed as a compromise between completely static and fully dynamic scheduling. Conceptually, in restrictive dataflow, the instructions of a statically scheduled instruction stream are first decoded and then added to a pool of now dynamically schedulable instructions.
Reference: [13] <author> S. Vajapeyam and T. Mitra, </author> <title> Improving Superscalar Instruction Dispatch and Issue by Exploiting Dynamic Code Sequences Proc. </title> <booktitle> 24th Annual International Symposium on Computer Architecture, </booktitle> <address> Denver, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: 1. Introduction Recently, there has been a growing interest in aggressive dynamic execution through the use of cached dynamically formed VLIW-like instruction sequences <ref> [13, 14] </ref>. This research has focused mainly on applications in the realm of general purpose scientific computing. <p> High instruction throughput is maintained since it is constrained only by the width of the datapath and the branch predictor throughput. Rotenberg et al. report a performance gain of 28% for a reasonable size trace cache on the IBS and SPEC92 benchmarks. Vajapeyam and Mitra <ref> [13] </ref>, as well as Nair and Hopkins [14], have studied VLIW-style execution of dynamically formed traces. Both groups consider schemes to effectively deal with register renaming problems. Nair and Hopkins go on to give a detailed discussion of their two-part execution engine.
Reference: [14] <author> R. Nair and M. Hopkins, </author> <title> Exploiting Instruction Level Parallelism in Processors by Caching Scheduled Groups Proc. </title> <booktitle> 24th Annual International Symposium on Computer Architecture, </booktitle> <address> Denver, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: 1. Introduction Recently, there has been a growing interest in aggressive dynamic execution through the use of cached dynamically formed VLIW-like instruction sequences <ref> [13, 14] </ref>. This research has focused mainly on applications in the realm of general purpose scientific computing. <p> Rotenberg et al. report a performance gain of 28% for a reasonable size trace cache on the IBS and SPEC92 benchmarks. Vajapeyam and Mitra [13], as well as Nair and Hopkins <ref> [14] </ref>, have studied VLIW-style execution of dynamically formed traces. Both groups consider schemes to effectively deal with register renaming problems. Nair and Hopkins go on to give a detailed discussion of their two-part execution engine. Both works use the SPEC int benchmarks and are targeted at mainstream processors. 1.3.
Reference: [15] <author> M.A. Jenkins and J.F. Traub, </author> <title> Algorithm 419: </title> <journal> Zeros of a Complex Polynomial Communications of the ACM, </journal> <volume> vol. 15, no. 2, </volume> <editor> p. </editor> <volume> 97, </volume> <month> Feb. </month> <year> 1972. </year> <month> 7 </month>
Reference-contexts: With the rising popularity of multimedia applications, MPEG compression and decompression kernels are becoming very important. This is shown by the inclusion of MPEG decompression in the Intel Media Benchmark [8, 9]. 4.4. CPOLY Zeros of a Complex Polynomial Benchmark The CPOLY benchmark <ref> [15] </ref> finds all the zeros of a complex polynomial or equivalently finds the eigenvalues of the polynomial's characterization matrix. This is accomplished by iteratively finding a zero of roughly increasing modulus and reducing the degree of the polynomial. This algorithm has applications in general signal processing, especially speech processing. 5.
References-found: 15

