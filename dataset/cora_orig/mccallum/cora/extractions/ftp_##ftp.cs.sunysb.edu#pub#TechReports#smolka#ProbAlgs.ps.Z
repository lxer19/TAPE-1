URL: ftp://ftp.cs.sunysb.edu/pub/TechReports/smolka/ProbAlgs.ps.Z
Refering-URL: http://www.uni-paderborn.de/fachbereich/AG/agmadh/WWW/english/scripts.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: gupta@crd.ge.com sas@cs.sunysb.edu bhaskar@bnr.ca  
Phone: 8  
Title: On Randomization in Sequential and Distributed Algorithms Chaos umpire sits, And by decision more embroils
Author: Rajiv Gupta Scott A. Smolka Shaji Bhaskar Paradise Lost, John Milton 
Note: Ecclesiastes (King James Version)  CCR-9208585; and by the Air Force Office of Special Research under grant AFOSR F49620-93-1-0250DEF.  
Date: September 8, 1993  
Address: KW-C313, P.O. Box  35 Davis Drive Schenectady, NY 12301 Stony Brook, NY 11794 Res. Triangle Pk, NC 27709  
Affiliation: GE Corporate R&D Dept. of Computer Science Bell Northern Research  SUNY at Stony Brook  
Abstract: I returned, and saw under the sun, that the race is not to the swift, nor the battle to the strong, neither yet bread to the wise, nor yet riches to men of understanding, nor yet favor to men of skill; but time and chance happeneth to them all. 
Abstract-found: 1
Intro-found: 1
Reference: [AA88] <author> N. Alon and Y. Azar. </author> <title> The average complexity of deterministic and randomized parallel comparison-sorting algorithms. </title> <journal> SIAM Journal on Computing, </journal> <volume> 17 </volume> <pages> 1178-1192, </pages> <year> 1988. </year> <title> Even the average-case behavior of randomized parallel comparison-sorting algorithms is shown to be no better than the worst-case behavior of their deterministic counterparts. </title> <type> 84 </type>
Reference: [AAG + 89] <author> K. Abrahamson, A. Adler, R. Gilbart, L. Higham, and D. Kirkpatrick. </author> <title> The bit complexity of randomized leader election on a ring. </title> <journal> SIAM Journal on Computing, </journal> <volume> 18(1) </volume> <pages> 12-29, </pages> <month> Feb </month> <year> 1989. </year> <title> Under various assumptions about global knowledge, the bit complexity of leader election on asynchronous unidirectional rings is studied. </title>
Reference: [AAK90] <author> A. Aggarwal, R. J. Anderson, and M.-Y. Kao. </author> <title> Parallel depth-first search in general directed graphs. </title> <journal> SIAM Journal on Computing, </journal> <volume> 19(2) </volume> <pages> 397-409, </pages> <year> 1990. </year> <title> This paper gives the first randomized NC algorithm for depth-first search in a general directed graph. </title>
Reference: [AASS90] <author> P. K. Agarwal, B. Aronov, M. Sharir, and S. Suri. </author> <title> Selecting distances in the plane. </title> <booktitle> In Proc. Sixth Ann. ACM Symp. on Computational Geometry, </booktitle> <pages> pages 321-331, </pages> <address> Berkeley, CA, </address> <month> June </month> <year> 1990. </year> <title> The authors present a randomized algorithm for computing the kth smallest distance in a set of n points in the plane based on a parametric search technique of Megiddo. The algorithm's expected time is O(n 4=3 log 8=3 n). </title>

Reference: [Adl91] <author> L. M. Adleman. </author> <title> Factoring numbers using singular integers. </title> <booktitle> In Proc. 23rd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 64-71, </pages> <address> New Orleans, LA, </address> <month> May </month> <year> 1991. </year> <title> Generalizing earlier work of Coopersmith, </title> <editor> Odlyzko and Schroep-pel, </editor> <title> Adleman puts forward an efficient randomized algorithm for factoring the integers. </title> <type> 85 </type>
Reference: [AES90] <author> P. K. Agarwal, H. Edelsbrunner, and O. Schwarzkopf. </author> <title> Euclidean minimum spanning trees and bichromatic closest pairs. </title> <booktitle> In Proc. Sixth Ann. ACM Symp. on Computational Geometry, </booktitle> <pages> pages 203-210, </pages> <address> Berkeley, CA, </address> <month> June </month> <year> 1990. </year> <title> The authors present a randomized algorithm to compute a bichromatic closest pair in expected time O((nm log n log m) 2=3 + m log 2 n + n log 2 m) in Euclidean three-space, which yields an O(N 4=3 log 4=3 N ) expected time algorithm for computing a Euclidean minimum spanning tree of N points in Euclidean three-space. </title>
Reference: [AES92] <author> N. Alon, P. Erd-os, and J. H. Spencer. </author> <title> The Probabilistic Method. </title> <publisher> John Wiley and Sons, </publisher> <year> 1992. </year> <note> This paper describes the Probabilistic Method as developed by Paul Erd-os and its applications in Discrete Mathematics and Theoretical Computer Science. </note>
Reference: [Aga90a] <author> P. K. Agarwal. </author> <title> Partitioning arrangements of lines I: An efficient deterministic algorithm. </title> <journal> Discrete Computational Geometry, </journal> <volume> 5 </volume> <pages> 449-483, </pages> <year> 1990. </year> <title> Using derandomization techniques due to Chazelle and Friedman [CF90], Agarwal obtains a deterministic algorithm that, given a set L of n lines and a parameter 1 &lt; r &lt; n, partitions the plane into O(r 2 ) triangles, each of which meets at most O(n=r) lines of L. He shows that the algorithm is optimal up to a polylog factor. </title>
Reference-contexts: The beauty of derandomization is that the resulting deterministic algorithm retains the simplicity inherent to randomized algorithms, often outperforms all previously known deterministic algorithms (e.g., <ref> [CF90, Aga90a, Aga90b] </ref>), and is always correct. This last point is particularly appealing if the randomized algorithm that gave rise to the deterministic one is of the Monte Carlo variety. The idea of derandomization can be explained as follows [NN90]. Consider any randomized algorithm A .
Reference: [Aga90b] <author> P. K. Agarwal. </author> <title> Partitioning arrangements of lines II: </title> <journal> Applications. Discrete Computational Geometry, </journal> <volume> 5 </volume> <pages> 533-574, </pages> <year> 1990. </year> <title> Agarwal uses his partitioning algorithm of [Aga90a], which he derived through derandomization, to obtain efficient algorithms for a variety of problems involving line or line segments in the plane (e.g., computing incidence between points and lines, implicit point location, and spanning trees with low stabbing number). These algorithms are deterministic, faster than previously known algorithms, and optimal up to a polylog factor in many cases. </title>
Reference-contexts: The beauty of derandomization is that the resulting deterministic algorithm retains the simplicity inherent to randomized algorithms, often outperforms all previously known deterministic algorithms (e.g., <ref> [CF90, Aga90a, Aga90b] </ref>), and is always correct. This last point is particularly appealing if the randomized algorithm that gave rise to the deterministic one is of the Monte Carlo variety. The idea of derandomization can be explained as follows [NN90]. Consider any randomized algorithm A .
Reference: [AGHP90] <author> N. Alon, O. Goldreich, J. Hastad, and R. Peralta. </author> <title> Simple construction of almost k-wise independent random variables. </title> <booktitle> In Proc. 31st Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 544-553, </pages> <year> 1990. </year> <title> Three simple constructions of small probability spaces on n bits for which any k bits are almost independent are presented in this paper. </title>
Reference-contexts: Babai [Bab91] presents a randomized algorithm that constructs an efficient nearly uniform random generator for finite groups in a very general setting. Other interesting work on the random generation of combinatorial structures and sample spaces can be found in <ref> [JVV86, AGHP90] </ref>. Not all algorithms based on random search contain a verification step. If the search space is teeming with elements possessing the desired property, one can even dispense with checking the property. This is particularly useful if the property in question is not easily checked. <p> This property of random bit strings is known as k-wise independence and its use in the derandomization of probabilistic algorithms is discussed below. In <ref> [AGHP90] </ref>, three simple constructions of small probability spaces on n bits for which any k bits are almost independent are presented.
Reference: [AH87] <author> L. M. Adleman and M. A. Huang. </author> <title> Recognizing primes in polynomial time. </title> <booktitle> In Proc. 19th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 462-471, </pages> <year> 1987. </year> <title> 86 The probabilistic algorithms of Rabin [Rab76] and Solovay and Stassen [SS77] placed the problem of compositeness testing in the randomized complexity class RP , and thus the problem of primality testing in co-RP . Adleman and Huang show that primality testing is also in RP , thereby putting this problem in the intersection of RP and co-RP </title> . 
Reference-contexts: While it is easy to verify such a proof, unfortunately, there is no known method for coming up with the proof, or demonstrating the absence thereof, in polynomial time. Other algorithms utilizing different number theoretic properties for defining witnesses for compositeness and primality have also been discovered <ref> [Rab80a, Leh82, AH87, GK86, AH88] </ref>. For example, Adleman and Huang [AH88] have devised a new algorithm that, instead of deciding primality by the inability to demonstrate witnesses to compositeness, employs a separate Monte Carlo test for primality. <p> For example, by virtue of the probabilistic algorithms presented in Section 2.2, the problem of primality testing is in co-RP while the complementary problem, compositeness testing, is in RP . Interestingly, Adleman and Huang <ref> [AH87] </ref> showed that primality testing is also in RP , thereby putting this problem in the intersection of RP and co-RP . 74 Complexity classes for randomized algorithms extend beyond RP and include the classes PP (Probabilistic Polynomial time) and BPP (Bounded Probabilistic Polynomial time).
Reference: [AH88] <author> L. M. Adleman and M. A. Huang. </author> <title> Recognizing primes in random polynomial time. </title> <type> Technical report, </type> <institution> University of Souther California, </institution> <month> September </month> <year> 1988. </year> <title> The authors present a Las Vegas algorithm that looks for witnesses to composite-ness as well as those for primality. </title>
Reference-contexts: While it is easy to verify such a proof, unfortunately, there is no known method for coming up with the proof, or demonstrating the absence thereof, in polynomial time. Other algorithms utilizing different number theoretic properties for defining witnesses for compositeness and primality have also been discovered <ref> [Rab80a, Leh82, AH87, GK86, AH88] </ref>. For example, Adleman and Huang [AH88] have devised a new algorithm that, instead of deciding primality by the inability to demonstrate witnesses to compositeness, employs a separate Monte Carlo test for primality. <p> Other algorithms utilizing different number theoretic properties for defining witnesses for compositeness and primality have also been discovered [Rab80a, Leh82, AH87, GK86, AH88]. For example, Adleman and Huang <ref> [AH88] </ref> have devised a new algorithm that, instead of deciding primality by the inability to demonstrate witnesses to compositeness, employs a separate Monte Carlo test for primality. Thus, just like composite numbers, there exists a random polynomial time algorithm for the set of prime numbers.
Reference: [AH90] <author> J. Aspnes and M. Herlihy. </author> <title> Fast randomized consensus using shared memory. </title> <journal> Journal of Algorithms, </journal> <volume> 11(3), </volume> <year> 1990. </year> <title> An expected O(n 4 ) operations are needed for the solution presented. </title>
Reference: [AH91] <author> W. Aiello and J. Hastad. </author> <title> Perfect zero-knowledge languages can be recognized in two rounds. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 42 </volume> <pages> 327-345, </pages> <year> 1991. </year> <title> This paper shows that if L has a perfect zero-knowledge proof (see [FGM + 89] for a definition), then L has a two-round interactive proof if the verifier (of this new IP proof) is permitted a small probability of error in accepting a string w as being in a language L. </title> <note> An earlier version of this paper appeared in Proc. </note> <editor> 28th Ann. </editor> <booktitle> IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1987. </year>
Reference-contexts: Various notion of zero-knowledge, a classification of these notions, and several related topics appear in [Ore87, FLS90, KMO89]. Some complexity theoretic implications of systems that admit zero-knowledge proofs are discussed in <ref> [AH91, For87, GMW91] </ref>. Truly Zero-Knowledge and Multi-Prover Interactive Proofs Zero-knowledge proofs, in the traditional sense, reveal one bit of information to the verifier, viz. w 2 L or w 62 L.
Reference: [AKS87] <author> M. Ajtai, J. Komlos, and E. Szemeredi. </author> <title> Deterministic simulation in LOGSPACE. </title> <booktitle> In Proc. 19th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 132-140, </pages> <year> 1987. </year> <title> The authors present an explicit construction of multigraphs based on expanders for deterministic amplification. Using these multigraphs, Cohen and Wigderson [CW89] show that the error probability of any RP or BPP algorithm can be made exponentially small in the size of the input, with only a constant factor increase in the number of random bits used by the algorithm. </title>
Reference-contexts: The reduction in the error probability follows from the properties of the expander graph. It can also be shown that random bipartite multigraphs are sufficiently expanding. While Sipser's reduction assumes the constructability of expander graphs, Ajtai et al. <ref> [AKS87] </ref> show how to explicitly construct expanders for deterministic amplification.
Reference: [Ale82] <author> R. Aleliunas. </author> <title> Randomized parallel communication (preliminary version). </title> <booktitle> In Proc. First Ann. ACM Symp. on Principles of Distributed Computing, </booktitle> <pages> pages 60-72, </pages> <year> 1982. </year> <title> This paper presents a randomized algorithm for packet delivery that delivers a set of n packets traveling to unique targets from unique sources in O(log n) expected time on a finite degree interconnection network of n processors. </title> <type> 87 </type>
Reference-contexts: Input randomization is not restricted to sequential algorithms. Some randomized message routing algorithms, e.g., Valiant's algorithm for hypercubes [Val82] and Aleluinas's algorithm for b-way shu*e networks <ref> [Ale82] </ref>, exhibit what may be termed distributed input randomization. In the message routing problem, a set of messages must be routed from source nodes to destination nodes in a network of computers. Moreover, the routing must be done in a distributed manner, i.e., without the help of a central arbiter. <p> In the message routing problem, a set of messages must be routed from source nodes to destination nodes in a network of computers. Moreover, the routing must be done in a distributed manner, i.e., without the help of a central arbiter. In the algorithms of <ref> [Val82, Ale82] </ref>, each message is first sent to a randomly chosen intermediate node before being transmitted to its final destination. This randomization step eliminates "hot points" by distributing the traffic uniformly over the network. <p> In this section, we consider two algorithms that use randomization to break up such input dependencies: Valiant's [Val82] algorithm for the n-cube, and Aleluinas's <ref> [Ale82] </ref> algorithm for shu*e networks. A radically different approach, that of randomizing the interconnections between nodes, is also presented. This technique, when applied to multi-butterfly networks, has been shown to outperform conventional butterfly networks, particularly with respect to tolerance to node faults [Upf89, LM89, LLM90]. <p> Message Routing on Finite Degree Interconnection Networks Valiant's algorithm is designed for hypercubes, which have the drawback that the degree of each node increases with the number of nodes in the network. Aleluinas <ref> [Ale82] </ref> extended Valiant's results to the common b-way shu*e networks, where each node has a fixed degree b, regardless of the size of the network. For simplicity of exposition, let us assume b divides N , the number of nodes in the network. <p> However, the best deterministic routing algorithms known require O (log 2 N ) time [LPV81] in the worst case because an appropriate choice of sources and destinations can cause congestion on individual communication lines. Aleluinas <ref> [Ale82] </ref> uses randomization to overcome this input dependency. As in Valiant's algorithm, each node v chooses (with equal probability) an intermediate destination. However, the entire path to the intermediate destination is chosen by v from among the paths of length d log N log b e originating at v. <p> Aleluinas has also analyzed the delay for the more general situation where multiple messages originate at each node. The reader is referred to <ref> [Ale82] </ref> for further details. Both algorithms discussed above use the technique of distributed input randomization. By sending messages to randomly selected intermediate destinations, any pockets of congestions arising because of certain unfavorable permutations are avoided.
Reference: [All87] <author> E. W. Allender. </author> <title> Some consequences of the existence of pseudorandom genera-tors. </title> <booktitle> In Proc. 19th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 151-159, </pages> <year> 1987. </year> <title> Connections between pseudorandom generation, Kolmogorov complexity, and immunity properties of complexity classes are described. </title>
Reference-contexts: They also introduce a class of PRGs based on universal hashing functions. Some consequences of the existence of PRGs are discussed in <ref> [All87] </ref>. While most of the work in this area has concentrated on generation of pseudo-random strings, in [GGM86], Goldreich, Goldwasser, and Micali address the issue of generating random functions. They introduce a computational complexity measure of the randomness of functions.
Reference: [ALM + 92] <author> S. Arora, C. Lund, R. Motwani, M. Sundar, and M. Szegedy. </author> <title> Verification and hardness of approximation problems. </title> <booktitle> In Proc. 33rd Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 14-23, </pages> <year> 1992. </year> <title> This paper extends the results in [AS92] to show that unless P = N P , the size of the maximum clique cannot be approximated within a factor of n * for some * &gt; 0, unless P = N P </title> . 

Reference: [AN93] <author> N. Alon and M. Naor. </author> <title> Coin-flipping games immune against linear-sized coalitions. </title> <journal> SIAM Journal on Computing, </journal> <volume> 22(2) </volume> <pages> 403-417, </pages> <year> 1993. </year> <title> The authors consider the problem of distributed coin-flipping and leader-election algorithms where every process has complete information. They show that for every constant c &lt; 1 there are protocols involving n processes in which no group of cn processes can influence the outcome with probability greater than Kc, where K is a universal constant. </title>
Reference: [Ang80] <author> D. Angluin. </author> <title> Local and global properties in networks of processors. </title> <booktitle> In Proc. 12th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 82-93, </pages> <year> 1980. </year> <title> The capabilities of networks containing nodes with non-unique names are analyzed. It is shown that there exist networks in which it is not possible to elect a leader (For example, in a ring with four nodes). Other computations, such as determining topology, are also considered. </title> <type> 88 </type>
Reference-contexts: The problem of leader election is then reduced to the problem of picking the process with the smallest, or largest, name. See, for example, [CR79, Pet82]. Several authors <ref> [Ang80, IR81] </ref> have investigated the consequences of the absence of such totally ordered names on election algorithms. Angluin [Ang80] has shown that there exists no deterministic algorithm to carry out elections in a ring of identical processes. <p> The problem of leader election is then reduced to the problem of picking the process with the smallest, or largest, name. See, for example, [CR79, Pet82]. Several authors [Ang80, IR81] have investigated the consequences of the absence of such totally ordered names on election algorithms. Angluin <ref> [Ang80] </ref> has shown that there exists no deterministic algorithm to carry out elections in a ring of identical processes. Angluin's argument is based on the observation that, in a deterministic framework, it is possible for an adversary scheduler to force all processes to be in identical states at all times.
Reference: [AS89] <author> C. Aragon and R. Seidel. </author> <title> Randomized search trees. </title> <booktitle> In Proc. 30th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 540-545, </pages> <year> 1989. </year> <title> A simple randomized algorithm for maintaining balance in dynamic search trees is presented. The expected time for an update is O(log n) on a tree with n nodes, and involves fewer than two rotations to re-balance the tree. </title>
Reference: [AS91a] <author> P. K. Agarwal and M. Sharir. </author> <title> Counting circular arc intersections. </title> <booktitle> In Proc. Seventh Ann. ACM Symp. on Computational Geometry, </booktitle> <pages> pages 10-20, </pages> <address> North Conway, NH, </address> <month> June </month> <year> 1991. </year> <title> Two randomized algorithms are presented. The first counts intersections in a collection of n circles in expected time O(n 3=2+* ), for any * &gt; 0. The other counts intersections in a set of n circular arcs in expected time O(n 5=3+* ), for any * &gt; 0. If all arcs have the same radius, the expected time can be improved to O(n 3=2+* </title> ). 
Reference: [AS91b] <author> F. Aurenhammer and O. Schwarzkopf. </author> <title> A simple on-line randomized algorithm for computing higher order Voronoi diagrams. </title> <booktitle> In Proc. Seventh Ann. ACM Symp. on Computational Geometry, </booktitle> <pages> pages 142-151, </pages> <address> North Con-way, NH, </address> <month> June </month> <year> 1991. </year> <title> They present a simple on-line randomized algorithm that can compute the order-k Voronoi Diagram for n sites in expected time O(nk 2 log n + nk log 3 n) and optimal space O(k(n k)). </title>
Reference: [AS92] <author> S. Arora and S. Safra. </author> <title> Probabilistic checking proofs; a new characterization of NP. </title> <booktitle> In Proc. 33rd Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 2-11, </pages> <year> 1992. </year> <title> The class NP is shown to be the class of languages L for which membership can be verified probabilistically in polynomial time using a logarithmic number of random bits and sub-logarithmic number of queries. </title>
Reference: [Auw89] <author> B. Auwerbuch. </author> <title> Randomized distributed shortest path algorithms. </title> <booktitle> In Proc. 21st Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 490-500, </pages> <year> 1989. </year> <title> An algorithm that requires O(D 1+* ) time and O(E 1+* ) messages, for any * &gt; 0, is presented, where E is the number of edges in the graph and D is its diameter. The lower bounds are (D) and (E) respectively. The algorithm is extended to determine shortest paths when the edges have weights. </title>
Reference: [AUY83] <author> A. Aho, J. Ullman, and M. Yannakakis. </author> <title> On notations of information transfer in VLSI circuits. </title> <booktitle> In Proc. 15th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 133-139, </pages> <year> 1983. </year> <title> This paper presents an interesting result on probabilistic algorithms that admit no error: the communication complexity (measured in 89 bits) of the deterministic solution can be no more than the square of the message complexity of any randomized solution. </title>
Reference: [AV79] <author> D. Angluin and L. G. Valiant. </author> <title> Fast probabilistic algorithms for Hamiltonian circuits and matching. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 18(2) </volume> <pages> 82-93, </pages> <year> 1979. </year> <title> The authors present two algorithms with O(n(log n) 2 ) running time for Hamiltonian circuits and an O(n log n) algorithm to find perfect matching in random graphs with at least c n log n edges, where c is any positive constant. </title>
Reference: [AW89] <author> M. Ajtai and A. Wigderson. </author> <title> Deterministic solution of probabilistic constant depth circuits. </title> <editor> In S. Micali, editor, </editor> <booktitle> Advances in Computing Research 5: Randomness and Computation, </booktitle> <address> Greenwich, CT, </address> <year> 1989. </year> <title> JAI Press. A family of pseudo-random number generators which appear random to any polynomial size logic circuit of constant depth and unbounded fan-in is demonstrated. Such pseudorandom generators can be substituted for random-number generators in applications such as building simple approximations to complex boolean functions [Val84a]. </title>
Reference-contexts: A PRG is cryptographically secure if given a 80 small segment of its output, all subsequent output cannot be predicted in polynomial time. Otherwise, a PRG is said to be predictable. A number of PRGs, both predictable and secure, have been studied in the literature. Ajtai and Wigderson <ref> [AW89] </ref> have demonstrated a family of PRGs that appear random to any polynomial-size logic circuit of constant depth and unbounded fan-in. Such PRGs can be substituted for random number generators in applications such as building simple approximations to complex boolean functions [Val84a].
Reference: [AW92] <author> J. Aspnes and O. Waarts. </author> <title> Randomized consensus in O(n log 2 n) operations per processor. </title> <booktitle> In Proc. 33rd Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 137-146, </pages> <year> 1992. </year> <title> An asynchronous algorithm is presented that achieves randomized consensus using O(n log 2 n) read and write operations on shared-memory registers. This improves on the O(n 2 log n) worst-case complexity of the best previously-known algorithm. </title>
Reference: [Bab85] <author> L. Babai. </author> <title> Trading group theory for randomness. </title> <booktitle> In Proc. 17th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 421-429, </pages> <year> 1985. </year> <title> This paper developes interactive proofs to classify certain group-theoretic problems and introduces an alternative notion of interactive proofs for complexity-theoretic analysis. </title>
Reference-contexts: The objective of the verifier is to convince itself that the prover does in fact have a solution to the problem. Independent formalizations of interactive proof systems by Goldwasser, Micali and Rack-off [GMR89], and Babai and Moran <ref> [BM88, Bab85] </ref>, which have been shown to be equivalent [GS89], allow a polynomial-time verifier to toss coins and arbitrarily interact with the prover. In [GMR89], the outcomes of the coin tosses made by the verifier are hidden from the prover. <p> This latter property is crucial to the notion of zero-knowledge proofs described next. Zero-Knowledge Proofs Sometimes, an additional requirement is imposed on the prover, viz., that it completely hide the details of its solution from the verifier. In this case, the proof is referred to as a zero-knowledge proof <ref> [GMR89, BM88, Bab85, KMO89, GMW91] </ref> because, even though the verifier has an efficient means of verifying responses provided by the prover, at the end it has learned nothing except that the prover is right or wrong.
Reference: [Bab91] <author> L. Babai. </author> <title> Local expansion of vertex-transitive graphs and random generation in finite groups. </title> <booktitle> In Proc. 23rd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 164-174, </pages> <address> New Orleans, LA, </address> <month> May </month> <year> 1991. </year> <title> Babai presents a Monte Carlo algorithm that constructs an efficient nearly uniform random generator for finite groups in a very general setting. </title>
Reference-contexts: This particular problem was solved by Broder [Bro89] who presented a randomized algorithm with an expected running time of O (n log n) per generated tree for almost all graphs. In the worst case, the algorithm requires O (n 3 ) time per generated tree. Babai <ref> [Bab91] </ref> presents a randomized algorithm that constructs an efficient nearly uniform random generator for finite groups in a very general setting. Other interesting work on the random generation of combinatorial structures and sample spaces can be found in [JVV86, AGHP90].
Reference: [Bac91] <author> E. Bach. </author> <title> Realistic analysis of some randomized algorithms. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 42 </volume> <pages> 30-53, </pages> <year> 1991. </year> <title> Bach's analysis justifies the use of 90 pseudo-random substitutes for true random-number generators in a random primality tester and a probabilistic algorithm for computing square roots. </title>
Reference-contexts: Much research has been conducted on conserving the number of random bits used by specific PRG algorithms. An analysis justifying the use of pseudo-random substitutes for true random number generators in a randomized primality tester and a probabilistic algorithm for computing square roots is given in <ref> [Bac91] </ref>. There Bach shows that an exponentially small error can be obtained for these two problems by increasing the number of random bits by a constant factor. Karloff and Raghavan [KR88] study pseudo-random substitutes that use small seeds for purely random choices in sorting, selection and oblivious message routing.
Reference: [BB88] <author> G. Brassard and P. Bratley. </author> <title> Algorithmics: Theory and Practice. </title> <publisher> Prentice-Hall, </publisher> <year> 1988. </year> <title> This book contains a very nice chapter on probabilistic algorithms for a variety of problems such as numerical integration, sorting, and set equality. </title>
Reference-contexts: More recently, randomized algorithms have been the subject of an ACM Turing Award Lecture [Kar86], an ACM Distinguished Dissertation [Kil90], and of a number of surveys including <ref> [Wei78, Hop81, Wel83, Kro85, MSV85, Har87, Val87, BB88, Rag90, Kar90] </ref>. <p> More recently, randomized algorithms have been the subject of an ACM Turing Award Lecture [Kar86], an ACM Distinguished Dissertation [Kil90], and of a number of surveys including [Wei78, Hop81, Wel83, Kro85, MSV85, Har87, Val87, BB88, Rag90, Kar90]. Our survey is closest in spirit to <ref> [Har87, Val87, BB88, Kar90] </ref> in its extensive coverage of both sequential and distributed randomized algorithms. 4 A distinguishing aspect of our survey is the classification we present in Section 1.1 of gen-eral techniques used in the design of randomized algorithms. 2 In Section 1.2, we then identify certain tradeoffs one may <p> By first checking if a purported match is a valid match, the Karp-Rabin algorithm always gives a correct answer. Muthukrishnan [Mut93] gives an efficient parallel algorithm for exactly this problem. In <ref> [BB88] </ref>, Las Vegas algorithms possessing bounded time requirements are called Sher-wood algorithms. Randomized quicksort is an example of a Sherwood algorithm. It takes at most O (n 2 ) time on any problem instance.

Reference: [BBP91] <author> J. Boyar, G. Brassard, and R. Peralta. </author> <title> Subquadratic zero-knowledge. </title> <booktitle> In Proc. 32nd Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 69-78, </pages> <year> 1991. </year> <title> This work reduces the communication complexity of the boolean Satisfiability problem of size n to O(n 1+* n + k p 1+* n ) bits while providing a probability of undetected cheating not greater than 2 k , where * n tends to zero as n tends to infinity. </title>
Reference: [BBS86] <author> M. Blum, L. Blum, and M. Shub. </author> <title> A simple and secure pseudo-random number generator. </title> <journal> SIAM Journal on Computing, </journal> <volume> 15 </volume> <pages> 364-383, </pages> <year> 1986. </year> <title> Two pseudorandom sequence generators are presented which, from small seeds, generate long well-distributed sequences. The first, 1=P generator, is completely predictable from a small segment of its output. The second, x 2 (mod N ) generator, is cryptographically secure as its sequence is polynomial-time unpredictable (if quadratic residuacity problem is indeed hard). </title>
Reference-contexts: In [ILL89], the existence of one-way functions is shown to be necessary and sufficient for the existence of pseudo-random generators, and algorithms for pseudo-random generators that use one-way functions are provided. Blum et al. <ref> [BBS86] </ref> present two pseudo-random sequence generators that from small seeds, generate long well-distributed sequences. The first, the 1=P generator, is completely predictable from a small segment of its output. The second, the x 2 (modN ) generator, is cryptographically secure as its sequence is polynomial-time unpredictable.
Reference: [BC86] <author> G. Brassard and C. Crepeau. </author> <title> Zero-knowledge simulation of boolean circuits. </title> <booktitle> In Advances in Cryptology-CRYPTO 86, Lecture Notes in Computer Science, </booktitle> <volume> 91 Vol. 263, </volume> <pages> pages 223-233. </pages> <publisher> Springer-Verlag, </publisher> <year> 1986. </year> <title> An important result by Gol--dreich, Micali, and Wigderson in the design of cryptographic protocols asserts that if one-way functions exit then every language in NP has a minimum-knowledge confirming interactive proof. This paper proves a similar result under the assumption that certain number-theoretic computations are infeasible. </title>
Reference-contexts: The concept of zero-knowledge proof has turned out to be especially useful in complexity theory [For87, BHZ87] and cryptography <ref> [GMW87, CCD88, BOGW88, BC86] </ref>. Various notion of zero-knowledge, a classification of these notions, and several related topics appear in [Ore87, FLS90, KMO89]. Some complexity theoretic implications of systems that admit zero-knowledge proofs are discussed in [AH91, For87, GMW91].
Reference: [BCC88] <author> G. Brassard, D. Chaum, and C. Crepeau. </author> <title> Minimum disclosure proofs of knowledge. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 37 </volume> <pages> 156-189, </pages> <year> 1988. </year> <title> The authors present a generalized perfect zero-knowledge interactive proof scheme that is valid for any problem in NP . Contains protocols that allow "Peggy, the prover," to convince "Vic, the verifier," that she has a certifiable secret without disclosing it. The authors use a notion they call bit-commitment, to accomplish these minimum disclosure proofs. </title>
Reference: [BCD + 89] <author> A. Borodin, S. A. Cook, P. W. Dymond, W. L. Ruzzo, and M. Tompa. </author> <title> Two applications of inductive counting for complementation problems. </title> <journal> SIAM Journal on Computing, </journal> <volume> 18(3) </volume> <pages> 559-578, </pages> <month> June </month> <year> 1989. </year> <title> A probabilistic algorithm for s-t connectivity in undirected graphs is presented. </title>
Reference-contexts: For a study of this area, and the associated background in Markov chains and techniques for proving rapid mixing | informally, a Markov chain is rapidly mixing if it converges to its stationary distribution in a short time | the reader is referred to <ref> [KL85, Bro86, DLMV88, JS89, Bro89, KLM89, DFK91, BCD + 89] </ref>. 82 Derandomization A flurry of activity has recently emerged around the algorithmic design technique of deran-domization: the act of taking an efficient randomized algorithm and removing the coin flipping to obtain an deterministic algorithm.
Reference: [BCF + 91] <author> L. Babai, G. Cooperman, L. Finkelstein, E. Luks, and A. Seress. </author> <title> Fast Monte Carlo algorithms for permutation groups. </title> <booktitle> In Proc. 23rd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 90-100, </pages> <address> New Orleans, LA, </address> <month> May </month> <year> 1991. </year> <title> Nearly optimal randomized algorithms, of the Monte Carlo variety, are presented for basic permutation group manipulation. </title>
Reference: [BCW80] <author> M. Blum, A. Chandra, and M. Wegman. </author> <title> Equivalence of free boolean graphs can be decided probabilistically in polynomial time. </title> <journal> Information Processing Letters, </journal> <volume> 10 </volume> <pages> 80-82, </pages> <year> 1980. </year> <title> The technique used is reduction to a restricted case of the Straight-Line Program Equivalence Problem [MT85]. </title>
Reference: [BDBK + 90] <author> S. Ben-David, A. Borodin, R. M. Karp, G. Tardos, and A. Wigderson. </author> <title> On the power of randomization in online algorithms. </title> <booktitle> In Proc. 22nd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 379-386, </pages> <address> Baltimore, MD, </address> <month> May </month> <year> 1990. </year> <title> They prove the existence of an efficient "simulation" of randomized online algorithms by deterministic ones, which is the best possible in the presence of an adaptive adversary. </title> <type> 92 </type>
Reference: [BDMP91] <author> M. Blum, A. DeSantis, S. Micali, and G. Persiano. </author> <title> Noninteractive zero--knowledge. </title> <journal> SIAM Journal on Computing, </journal> <volume> 20(6) </volume> <pages> 1084-1118, </pages> <year> 1991. </year> <title> A key paper that summarizes the previous work on non-interactive zero-knowledge proofs. The concept of shared randomness is introduced, and how that can dispose of interaction between the prover and the verifier is illustrated. The authors show that non-interactive zero-knowledge proofs exist for some number-theoretic languages for which no efficient algorithms are known. They also show that if quadratic residuosity is computationally hard, satisfiability also has a noninteractive zero-knowledge proof. </title>
Reference-contexts: A related concept called shared randomness, which is weaker than both private and public coin tosses, is discussed in <ref> [BDMP91] </ref>. 17 small in n, SockSel2 can return a mismatched pair of socks. SockSel2 can be made foolproof by employing two counters, one for the number of red socks left in the drawer and one for the number of blue socks left in the drawer. <p> Finally, the prover has the ability to solve a hard problem that the verifier cannot solve directly. Thus, the prover embeds in its proof the computational difficulty of some other problem. As noted by Blum et al. in <ref> [BDMP91] </ref>, this requires a rather rich set of conditions to be present before a zero-knowledge interactive proof can be devised for a problem. Another notion that is gaining popularity is that of noninteractive zero-knowledge proofs first proposed by Blum, Feldman, and Micali [BFM88]. <p> A notion of non-interactive zero-knowledge proofs based on a weaker complexity assumption than that used in [BFM88] is presented in [DSMP87]. Most of the work to date is summarized in <ref> [BDMP91] </ref>. In interactive zero-knowledge proof-systems, the prover P interactively proves to the verifier V that a certain theorem is true without giving away the details of the proof. <p> While such a concept of "shared randomness" has been used by others (see, for example, [GS89]), shared random strings represent a much weaker requirement than most others (e.g., public coin tosses) used in the literature. As observed in <ref> [BDMP91] </ref>, proofs using shared randomness do not rely on foiling the adversary by the unpredictability of the coin tosses, as has been the case so far, but rather on the "well mixedness" of the bits of the shared random string. This concludes our survey of sequential randomized algorithms.
Reference: [BDS + 92] <author> J.-D. Boissonnat, O. Devillers, R. Schott, M. Teillaud, and M. Yvinec. </author> <title> Applications of random sampling to on-line algorithms in computational geometry. </title> <journal> Discrete Computational Geometry, </journal> <volume> 8 </volume> <pages> 51-71, </pages> <year> 1992. </year> <title> This paper treats the same kind of problems as in [CS89], but in a semi-dynamic way: the data can be initially unknown and added one by one. The analysis assumes that the points are inserted in a random order. </title>
Reference: [Bec82] <author> M. Becker. </author> <title> A probabilistic algorithm for vertex connectivity of graphs. </title> <journal> Information Processing Letters, </journal> <volume> 15(3) </volume> <pages> 135-136, </pages> <month> October </month> <year> 1982. </year> <title> A probabilistic algorithm is presented which computes the vertex connectivity of an undi-rected graph G = (V; E) in expected time O(( log *)jV j 3=2 jEj)) with error probability at most *, provided that jEj 1 2 djV j 2 , for some constant d &lt; 1. </title>
Reference: [Ben80] <author> J. Bentley. </author> <title> Multidimensional divide-and-conquer. </title> <journal> Communications of the ACM, </journal> <volume> 23 </volume> <pages> 214-229, </pages> <year> 1980. </year> <title> This paper contains an n log(n) deterministic algo rithm for finding nearest neighbors in two-dimensional space. </title>
Reference-contexts: We refer to the distance separating nearest neighbors in a set S as ffi min (S). A brute-force algorithm for Nearest Neighbors computes all the n (n 1)=2 relevant mutual distances and their minimum. A recursive algorithm in <ref> [Ben80] </ref> requires O (n log n) distance computations in both the average and worst case. Rabin's probabilistic algorithm, under a certain reasonable assumption about the problem input (discussed below), has an expected running time of O (n) and thus outperforms any known sequential algorithm.
Reference: [Ber70] <author> E. R. Berlekamp. </author> <title> Factoring polynomials over large finite fields. </title> <journal> Math. Comput., </journal> <volume> 24, </volume> <year> 1970. </year> <title> This paper presents algorithms for root-finding and factorization, two problems in finite fields. The latter problem is reduced to the root-finding problem, for which a probabilistic algorithm is given. </title> <note> This paper is a precursor of [Rab80b]. </note>
Reference-contexts: The randomized parallel algorithms of [KUW86, MVV87] do, however, place perfect matching in Random NC . One can also determine the actual perfect matching in parallel; see [KUW86, MVV87] for details. Random search has also been used in algorithms on finite fields <ref> [Rab80b, Ber70] </ref>. It can be shown (e.g., see [Ber70]) that one in about every n polynomials in Z p [x] (the field of residues (mod p), where p is prime) is an irreducible monic polynomial of degree n. This result has been reproved, using a different technique, in [Rab80b]. <p> One can also determine the actual perfect matching in parallel; see [KUW86, MVV87] for details. Random search has also been used in algorithms on finite fields [Rab80b, Ber70]. It can be shown (e.g., see <ref> [Ber70] </ref>) that one in about every n polynomials in Z p [x] (the field of residues (mod p), where p is prime) is an irreducible monic polynomial of degree n. This result has been reproved, using a different technique, in [Rab80b].
Reference: [Ber80] <author> A. J. Bernstein. </author> <title> Output guards and nondeterminism in CSP. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 2(2) </volume> <pages> 234-238, </pages> <month> April </month> <year> 1980. </year> <title> Bernstein presents a distributed algorithm for CSP output guards based on priority ordering of processes. </title> <type> 93 </type>
Reference-contexts: Several distributed implementations of guard scheduling have been proposed including <ref> [Sch78, Ber80, vdS81, Sch82, BS83] </ref>. Each of these algorithms must resort to some symmetry breaking technique such as priority ordering of processes [Sch78, Ber80, BS83], or timestamps [Sch78]. <p> Several distributed implementations of guard scheduling have been proposed including [Sch78, Ber80, vdS81, Sch82, BS83]. Each of these algorithms must resort to some symmetry breaking technique such as priority ordering of processes <ref> [Sch78, Ber80, BS83] </ref>, or timestamps [Sch78]. In fact, like the Dining Philosophers problem, the existence of a fully distributed and symmetric deterministic algorithm for guard scheduling can be shown to be an impossibility [FR80].

Reference: [BFL90] <author> L. Babai, L. Fortnow, and C. Lund. </author> <title> Non-deterministic exponential time has two-prover interactive protocols. </title> <booktitle> In Proc. 31st Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 16-25, </pages> <year> 1990. </year> <editor> Babai et al. </editor> <title> prove, using the two-prover interactive proof systems introduced in [BOGKW88], that the class of languages that have a two-prover interactive proof system is nondeterministic exponential time. </title>
Reference-contexts: Recent years have witnessed a multitude of such complexity theoretic results. For example, Ben-Or et al. in [BOGKW88] proposed a multi-prover interactive proof model. Using this model, Babai et al. <ref> [BFL90] </ref> proved that the class of languages that has a two-prover interactive proof system is non 42 deterministic exponential time. <p> A key result for proving IP = P SP ACE (and also, M IP = N EXP <ref> [BFL90] </ref>) is by Lund et al. [LFKN90] who presented a new algebraic technique for constructing interactive proof systems and proved that every language in the polynomial time hierarchy has an interactive proof system.
Reference: [BFM88] <author> M. Blum, P. Feldman, and S. Micali. </author> <title> Non-interactive zero-knowledge proof systems and applications. </title> <booktitle> In Proc. 20th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 103-112, </pages> <year> 1988. </year> <title> This paper introduces the notion of non-interactive zero-knowledge proofs where the interaction between the prover and the verifier is replaced by shared, random strings. </title>
Reference-contexts: As noted by Blum et al. in [BDMP91], this requires a rather rich set of conditions to be present before a zero-knowledge interactive proof can be devised for a problem. Another notion that is gaining popularity is that of noninteractive zero-knowledge proofs first proposed by Blum, Feldman, and Micali <ref> [BFM88] </ref>. A notion of non-interactive zero-knowledge proofs based on a weaker complexity assumption than that used in [BFM88] is presented in [DSMP87]. Most of the work to date is summarized in [BDMP91]. <p> Another notion that is gaining popularity is that of noninteractive zero-knowledge proofs first proposed by Blum, Feldman, and Micali <ref> [BFM88] </ref>. A notion of non-interactive zero-knowledge proofs based on a weaker complexity assumption than that used in [BFM88] is presented in [DSMP87]. Most of the work to date is summarized in [BDMP91]. In interactive zero-knowledge proof-systems, the prover P interactively proves to the verifier V that a certain theorem is true without giving away the details of the proof.
Reference: [BG81] <author> C. H. Bennett and J. Gill. </author> <title> Relative to a random oracle A, P A 6= N P A 6= CoN P A with probability 1. </title> <journal> SIAM Journal on Computing, </journal> <volume> 10(1) </volume> <pages> 96-113, </pages> <month> February </month> <year> 1981. </year> <title> Several relationships are given that hold with probability 1 for language classes relativized to a random oracle A, including the one mentioned in the title. </title>
Reference: [BG89a] <author> D. Beaver and S. Goldwasser. </author> <title> Multiparty computation with faulty majority. </title> <booktitle> In Proc. 30th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 468-473, </pages> <year> 1989. </year> <title> A variation of zero-knowledge proofs is considered, where slow revealing of knowledge to faulty processors is permitted. An algorithm for distributed boolean function computations in Byzantine networks where more than half the processors are faulty is presented. The constraint is that faulty processors should not be able to compute the function before the non-faulty ones do. </title> <type> 94 </type>
Reference: [BG89b] <author> M. Bellare and S. Goldwasser. </author> <title> A new paradigm for digital signatures and message identification based on non-interactive zero-knowledge proofs. </title> <booktitle> In Advances in Cryptology-CRYPTO 89, Lecture Notes in Computer Science, </booktitle> <volume> Vol. 435, </volume> <pages> pages 194-211. </pages> <publisher> Springer-Verlag, </publisher> <year> 1989. </year> <title> This paper shows how noninteractive zero-knowledge can be used to yield a new paradigm for secure digital signature schemes (also see [GMR88]). </title>
Reference: [BGG90] <author> M. Bellare, O. Goldreich, and S. Goldwasser. </author> <title> Randomness in interactive proofs. </title> <booktitle> In Proc. 31st Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 563-572, </pages> <year> 1990. </year> <title> The power of randomness in interactive proof systems, in quantitative terms, is considered. A randomness-efficient error reduction technique for converting one proof system into another one using the same number of rounds is presented. </title>
Reference: [BGLR93] <author> M. Bellare, S. Goldwasser, C. Lund, and A. Russell. </author> <title> Efficient probabilistically checkable proofs and applications to approximation. </title> <booktitle> In Proc. 25th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 294-304, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year> <editor> Bellare et al. </editor> <title> construct multi-prover proof systems for NP which use only a constant number of provers to simultaneously achieve low error, low randomness and low answer size. As a consequence, they obtain asymptotic improvements to approximation hardness results for a wide range of optimization problems. </title>
Reference: [BHZ87] <author> R. Boppana, J. Hastad, and S. Zachos. </author> <title> Does co-NP have short interactive proofs? Information Processing Letters, </title> <booktitle> 25 </booktitle> <pages> 127-132, </pages> <year> 1987. </year> <title> This is important paper, along with [For87], provides a method of gaining high confidence that certain languages are not NP-complete. </title>
Reference-contexts: The concept of zero-knowledge proof has turned out to be especially useful in complexity theory <ref> [For87, BHZ87] </ref> and cryptography [GMW87, CCD88, BOGW88, BC86]. Various notion of zero-knowledge, a classification of these notions, and several related topics appear in [Ore87, FLS90, KMO89]. Some complexity theoretic implications of systems that admit zero-knowledge proofs are discussed in [AH91, For87, GMW91].

Reference: [BK89] <author> M. Blum and S. Kannan. </author> <title> Designing programs that check their work. </title> <booktitle> In Proc. 21st Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 86-97, </pages> <month> May </month> <year> 1989. </year> <title> A more detailed version of [BR88]. Also see "Designing programs that check their work," </title> <type> Technical Report, </type> <institution> Computer Science Division, University of California, Berkeley, </institution> <address> CA 94720, </address> <month> Dec. </month> <year> 1988. </year>
Reference-contexts: Several properties of interactive proof systems concerning completeness and soundness, and methods for constructing them are investigated in [FGM + 89]. Clearly, ruling by probabilistic evidence means relaxing the completeness and correctness criteria. However, it does lead to interesting applications such as program testing <ref> [BR88, BK89, BLR90] </ref>. For an example of how of an interactive proof system | in particular, the verifier component of the proof | can be used to test the correctness of a program, consider the problem of graph isomorphism. <p> The following efficient procedure for checking the validity of a graph isomorphism program is due to Blum, Raghavan, and Kannan <ref> [BR88, BK89] </ref>. It is based on an interactive proof system for graph non-isomorphism by Goldreich, Micali and Wigderson [GMW91]. <p> The trick is so effective that it will catch P even if it is maliciously coded and is designed specifically to fool the verifier. The above example illustrates the power of input randomization in program testing and interactive proof systems. The reader is referred to <ref> [BR88, BK89] </ref> for more probabilistic checkers for problems such as matrix multiplication, sorting and several problems in group 45 theory. It is interesting to note that in the above example, GI-Verify was able to do its task without having to solve the graph isomorphism problem in any sense.

Reference: [BL92] <author> P. Beame and J. Lawry. </author> <title> Randomized vs. nondeterministic communication complexity. </title> <booktitle> In Proc. 24th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 188-199, </pages> <address> Victoria, B.C., Canada, </address> <month> May </month> <year> 1992. </year> <title> The authors show that the two complexities are not always the same. </title>
Reference: [BLR90] <author> M. Blum, M. Luby, and R. Rubinfeld. </author> <title> Self-testing/correcting with applications to numerical problems. </title> <booktitle> In Proc. 22nd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 73-83, </pages> <year> 1990. </year> <title> This paper is a more recent reference on the use of randomization in program testing and adds to the collection of interesting examples contained in [BR88, </title> <publisher> BK89]. </publisher>
Reference-contexts: Several properties of interactive proof systems concerning completeness and soundness, and methods for constructing them are investigated in [FGM + 89]. Clearly, ruling by probabilistic evidence means relaxing the completeness and correctness criteria. However, it does lead to interesting applications such as program testing <ref> [BR88, BK89, BLR90] </ref>. For an example of how of an interactive proof system | in particular, the verifier component of the proof | can be used to test the correctness of a program, consider the problem of graph isomorphism.
Reference: [Blu82] <author> M. Blum. </author> <title> Coin flipping by telephone. </title> <booktitle> In Proc. 1982 IEEE COMPCON, High Technology in the Information Age, </booktitle> <pages> pages 133-137, </pages> <year> 1982. </year> <title> This paper describes how two parties can use encryption and decryption keys in a public key cryp-tosystem to toss coins and exchange results in a distributed environment. </title>
Reference: [BM84] <author> M. Blum and S. Micali. </author> <title> How to generate cryptographically strong sequence of pseudo-random bits. </title> <journal> SIAM Journal on Computing, </journal> <volume> 13 </volume> <pages> 850-864, </pages> <year> 1984. </year> <title> This pa 96 per introduces the notion of cryptographically secure pseudo-random number generator. </title>
Reference-contexts: Karloff and Raghavan [KR88] study pseudo-random substitutes that use small seeds for purely random choices in sorting, selection and oblivious message routing. In their seminal paper, Blum and Micali <ref> [BM84] </ref> introduced the notion of cryptographically secure pseudo-random number generators. A PRG is cryptographically secure if given a 80 small segment of its output, all subsequent output cannot be predicted in polynomial time. Otherwise, a PRG is said to be predictable.
Reference: [BM88] <author> L. Babai and S. Moran. </author> <title> Arthur-Merlin games: A randomized proof system, and a hierarchy of complexity classes. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 36 </volume> <pages> 254-276, </pages> <year> 1988. </year> <title> The proof system is considered as a game played between two players, the verifier and the prover, called Arthur and Merlin, respectively. Arthur and Merlin can toss coins and can talk back and forth. In this type of proof-system, all coin tosses made by the verifier are seen by the prover. A hierarchy of complexity classes "just above NP "is derived. </title>
Reference-contexts: The objective of the verifier is to convince itself that the prover does in fact have a solution to the problem. Independent formalizations of interactive proof systems by Goldwasser, Micali and Rack-off [GMR89], and Babai and Moran <ref> [BM88, Bab85] </ref>, which have been shown to be equivalent [GS89], allow a polynomial-time verifier to toss coins and arbitrarily interact with the prover. In [GMR89], the outcomes of the coin tosses made by the verifier are hidden from the prover. <p> In [GMR89], the outcomes of the coin tosses made by the verifier are hidden from the prover. In <ref> [BM88] </ref>, the proof system is considered as a game played between two players called Arthur and Merlin. Once again, Arthur and Merlin (the verifier and the prover, respectively) can toss coins and can talk back and forth. <p> However, in this proof-system, unlike that in [GMR89], all coin tosses made by the verifier are seen by the prover. These formalizations have led to the emergence of a hierarchy of probabilistic complexity classes that generalizes NP <ref> [BM88] </ref>. One can also view an interactive proof system in complexity theoretic terms where the prover tries to convince a probabilistic verifier that a string w is in a language L. <p> This latter property is crucial to the notion of zero-knowledge proofs described next. Zero-Knowledge Proofs Sometimes, an additional requirement is imposed on the prover, viz., that it completely hide the details of its solution from the verifier. In this case, the proof is referred to as a zero-knowledge proof <ref> [GMR89, BM88, Bab85, KMO89, GMW91] </ref> because, even though the verifier has an efficient means of verifying responses provided by the prover, at the end it has learned nothing except that the prover is right or wrong.
Reference: [BM89] <author> M. Bellare and S. Micali. </author> <title> Non-interactive oblivious transfer and applications. </title> <booktitle> In Advances in Cryptology-CRYPTO 89, Lecture Notes in Computer Science, </booktitle> <volume> Vol. 435, </volume> <pages> pages 547-559. </pages> <publisher> Springer-Verlag, </publisher> <year> 1989. </year> <title> Based on a complexity assumption, Bellare and Micali show that it is possible to build public-key cryptosys-tems in which oblivious transfer is itself implemented without any interaction. </title>
Reference: [BMO90] <author> M. Bellare, S. Micali, and R. Ostrovsky. </author> <title> Perfect zero-knowledge in constant rounds. </title> <booktitle> In Proc. 22nd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 482-493, </pages> <year> 1990. </year> <title> This paper contains the first constant-round solutions with no unproven assumptions for the problems of graph isomorphism and quadratic residuosity. </title>
Reference: [BMS86] <author> E. Bach, G. Miller, and J. Shallit. </author> <title> Sums of divisors, perfect numbers and factoring. </title> <journal> SIAM Journal on Computing, </journal> <volume> 15(4) </volume> <pages> 1143-1154, </pages> <month> November </month> <year> 1986. </year> <title> The authors show that computing the sum of divisors of a number N is as hard as factoring N . They also give three natural sets which are in BPP (see [Gil77]) but are not known to be in RP </title> . 

Reference: [BNS89] <author> L. Babai, N. Nisan, and M. Szegedy. </author> <title> Multiparty protocols and logspace-hard pseudorandom sequences. </title> <booktitle> In Proc. 21st Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 1-11, </pages> <year> 1989. </year> <title> A lower bound is obtained for the bit complexity of computing functions of n variables, where the i th variable resides on processor i. The communication mechanism considered is a shared blackboard. Using this bound, algorithms are developed that generate, in polynomial time, pseudorandom sequences of length n from a seed of length exp(c p log n). These pseudorandom sequences cannot be distinguished from truly random sequences by any logspace Turing machine. </title>
Reference-contexts: The second, the x 2 (modN ) generator, is cryptographically secure as its sequence is polynomial-time unpredictable. The x 2 (modN ) generator is based on the hardness of the quadratic residuacity problem. Babai, Nisan and Szegedy <ref> [BNS89] </ref> obtain a lower bound for the bit complexity of computing functions of n variables, where the i th variable resides on processor i. The communication mechanism considered is a shared blackboard.

Reference: [BO85] <author> M. Ben-Or. </author> <title> Fast asynchronous Byzantine agreement (extended abstract). </title> <booktitle> In Proc. Fourth Ann. ACM Symp. on Principles of Distributed Computing, </booktitle> <pages> pages 149-151, </pages> <year> 1985. </year> <title> This work extends Bracha's [Bra85] algorithm to asynchronous networks, initially obtaining a polynomial expected-time protocol. This protocol is refined with the recursive use of Bracha's techniques to get an O(log k n) algorithm, where k is a large constant. </title>
Reference: [BOGKW88] <author> M. Ben-Or, S. Goldwasser, J. Kilian, and A. Wigderson. </author> <title> Multi-prover interactive proofs: How to remove the intractability assumptions. </title> <booktitle> In Proc. 20th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 113-131, </pages> <year> 1988. </year> <title> A multi-prover interactive proof model is proposed and its properties examined. </title>
Reference-contexts: Such a proof system yields probabilistic proofs since the verifier may accept or reject w based on overwhelming statistical evidence rather than on certainties. Recent years have witnessed a multitude of such complexity theoretic results. For example, Ben-Or et al. in <ref> [BOGKW88] </ref> proposed a multi-prover interactive proof model. Using this model, Babai et al. [BFL90] proved that the class of languages that has a two-prover interactive proof system is non 42 deterministic exponential time. <p> Thus, at the end of interaction, the verifier only gains knowledge about the state of prover's knowledge and no information about the original membership problem. Ben-Or et al. <ref> [BOGKW88] </ref> propose a multi-prover interactive-proof model. In their model, two provers jointly agree on a strategy and then try to convince the verifier, in a polynomially bounded number of interactions, that a certain statement is true. Communication between the provers is disallowed while they interact with the verifier.
Reference: [BOGW88] <author> M. Ben-Or, S. Goldwasser, and A. Wigderson. </author> <title> Completeness theorems for non-cryptographic fault-tolerant distributed computation. </title> <booktitle> In Proc. 20th Ann. 98 ACM Symp. on Theory of Computing, </booktitle> <pages> pages 1-10, </pages> <year> 1988. </year> <title> The problem is the same as that in [CCD88] and the results obtained are similar. </title>
Reference-contexts: The concept of zero-knowledge proof has turned out to be especially useful in complexity theory [For87, BHZ87] and cryptography <ref> [GMW87, CCD88, BOGW88, BC86] </ref>. Various notion of zero-knowledge, a classification of these notions, and several related topics appear in [Ore87, FLS90, KMO89]. Some complexity theoretic implications of systems that admit zero-knowledge proofs are discussed in [AH91, For87, GMW91].

Reference: [Bop89] <author> R. B. Boppana. </author> <title> Amplification of probabilistic boolean formulas. </title> <editor> In S. Micali, editor, </editor> <booktitle> Advances in Computing Research 5: Randomness and Computation, </booktitle> <pages> pages 27-45, </pages> <address> Greenwich, CT, </address> <year> 1989. </year> <title> JAI Press. Valiant's [Val84a] algorithm is shown to be the best possible. Also, an O(k 4:3 n log n) algorithm for computing the kth threshold function of n variables is given. </title>
Reference: [BP92] <author> M. Bellare and E. Petrank. </author> <title> Making zero-knowledge provers efficient. </title> <booktitle> In Proc. 24th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 711-722, </pages> <address> Victoria, B.C., Canada, </address> <month> May </month> <year> 1992. </year> <title> They prove that if a language possesses a statistical zero-knowledge proof then it also possesses a statistical zero-knowledge proof in which the prover runs in probabilistic polynomial time with an NP oracle. Previously, this was only known given the existence of one-way permutations. </title>
Reference: [BR88] <author> M. Blum and P. Raghavan. </author> <title> Program correctness: </title> <type> Can one test for it? Technical Report RC 14038 (#62902), </type> <institution> IBM T.J. Watson Research Center, </institution> <month> September </month> <year> 1988. </year> <title> They present "program checkers" for a number of interesting problems based on interactive proofs. </title>
Reference-contexts: Several properties of interactive proof systems concerning completeness and soundness, and methods for constructing them are investigated in [FGM + 89]. Clearly, ruling by probabilistic evidence means relaxing the completeness and correctness criteria. However, it does lead to interesting applications such as program testing <ref> [BR88, BK89, BLR90] </ref>. For an example of how of an interactive proof system | in particular, the verifier component of the proof | can be used to test the correctness of a program, consider the problem of graph isomorphism. <p> The following efficient procedure for checking the validity of a graph isomorphism program is due to Blum, Raghavan, and Kannan <ref> [BR88, BK89] </ref>. It is based on an interactive proof system for graph non-isomorphism by Goldreich, Micali and Wigderson [GMW91]. <p> The trick is so effective that it will catch P even if it is maliciously coded and is designed specifically to fool the verifier. The above example illustrates the power of input randomization in program testing and interactive proof systems. The reader is referred to <ref> [BR88, BK89] </ref> for more probabilistic checkers for problems such as matrix multiplication, sorting and several problems in group 45 theory. It is interesting to note that in the above example, GI-Verify was able to do its task without having to solve the graph isomorphism problem in any sense.
Reference: [BR89a] <author> L. Babai and L. Ronyai. </author> <title> Computing irreducible representations of finite groups. </title> <booktitle> In Proc. 30th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 93-98, </pages> <address> Research Triangle Park, NC, </address> <month> October </month> <year> 1989. </year> <title> IEEE Computer Society Press. In this paper, the authors give a randomized (Las Vegas) polynomial time algorithm for decomposing a given representation of a finite group over an algebraic number field into absolutely irreducible constituents. </title> <type> 99 </type>
Reference: [BR89b] <author> B. Berger and J. Rompel. </author> <title> Simulating (log c n)-wise independence in NC. </title> <booktitle> In Proc. 30th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <address> Research Triangle Park, NC, </address> <month> Oct </month> <year> 1989. </year> <title> IEEE Computer Science Press. A general framework for the derandomization of randomized NC algorithms whose analysis uses only polylogarithmic independence is presented. This framework allows the derivation of NC algorithms for many problems that were not previously known to be in NC </title> . 
Reference: [Bra85] <author> G. Bracha. </author> <title> An O(log n) expected rounds randomized Byzantine generals protocol. </title> <booktitle> In Proc. 17th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 316-326, </pages> <year> 1985. </year> <title> Bracha shows how to partition a set of n synchronous processes (of which at most a third are faulty) into overlapping groups of processes such that the number of faulty groups is at most the square root the total number of groups. Ben-Or's algorithm for Byzantine agreement (see Section 3.5) is then used to obtain an O(log n) protocol. </title>
Reference-contexts: The Byzantine Generals problem, known also as "Byzan-tine agreement," has received considerable attention in the literature, e.g., <ref> [PSL80, LSP82, Dol82, Rab83, CC85, Per85, Bra85] </ref>. This is due primarily to its fundamental relevance in distributed computation and its surprising complexity given the simplicity of the problem statement. <p> Ben-Or's algorithm, along with Rabin's [Rab83], was one of the first for reaching asynchronous Byzantine agreement, and it remains the simplest. Since then a number of more elaborate, in terms of efficiency or fault-resiliency, randomized algorithms for the problem have been developed, including <ref> [CC85, Per85, Bra85] </ref> (see also [CD89]). This concludes our survey of distributed randomized algorithms.
Reference: [Bro85] <author> A. Z. Broder. </author> <title> A provably secure polynomial approximation scheme for the distributed lottery problem (extended abstract). </title> <booktitle> In Proc. Fourth Ann. ACM Symp. on Principles of Distributed Computing, </booktitle> <pages> pages 136-148, </pages> <year> 1985. </year> <title> Rabin's classic Byzantine agreement algorithm [Rab83] uses a coin-toss whose outcome is available to all processes, but which cannot be predicted a priori, to reach Byzantine agreement in constant time. Broder demonstrates a polynomial-time distributed mechanism to implement such a coin toss in a Byzantine environment. </title>

Reference: [Bro89] <author> A. Z. Broder. </author> <title> Generating random spanning trees. </title> <booktitle> In Proc. 30th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 442-453, </pages> <month> Oct </month> <year> 1989. </year> <title> This 100 paper solves the problem of generating a spanning tree of a connected, undi--rected graph G which as the following special property: it is chosen uniformly at random from all possible spanning trees of G. The expected running time of the probabilistic algorithm is O(n log n) per generated tree for almost all graphs. It can be O(n 3 ) per generated tree in the worst case. </title>
Reference-contexts: For example, it is not immediately clear how one would pick one spanning tree, uniformly at random, from the space of all possible spanning trees of a connected, undirected graph. This particular problem was solved by Broder <ref> [Bro89] </ref> who presented a randomized algorithm with an expected running time of O (n log n) per generated tree for almost all graphs. In the worst case, the algorithm requires O (n 3 ) time per generated tree. <p> For a study of this area, and the associated background in Markov chains and techniques for proving rapid mixing | informally, a Markov chain is rapidly mixing if it converges to its stationary distribution in a short time | the reader is referred to <ref> [KL85, Bro86, DLMV88, JS89, Bro89, KLM89, DFK91, BCD + 89] </ref>. 82 Derandomization A flurry of activity has recently emerged around the algorithmic design technique of deran-domization: the act of taking an efficient randomized algorithm and removing the coin flipping to obtain an deterministic algorithm.
Reference: [BRS91a] <author> R. Beigel, N. Reingold, and D. Spielman. </author> <title> PP is closed under intersection. </title> <booktitle> In Proc. 23rd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 1-9, </pages> <address> New Orleans, LA, </address> <month> May </month> <year> 1991. </year> <title> The randomized complexity class PP is shown to be closed under intersection and union. </title>

Reference: [BS83] <author> G. N. Buckley and A. Silberschatz. </author> <title> An effective implementation for the generalized input-output construct of CSP. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 5(2), </volume> <year> 1983. </year> <title> They present a distributed algorithm for CSP output guards based on priority ordering of processes. Their algorithm has the property that two processes that can communicate and do not establish communication with a third process will communicate within a bounded time. </title>
Reference-contexts: Several distributed implementations of guard scheduling have been proposed including <ref> [Sch78, Ber80, vdS81, Sch82, BS83] </ref>. Each of these algorithms must resort to some symmetry breaking technique such as priority ordering of processes [Sch78, Ber80, BS83], or timestamps [Sch78]. <p> Several distributed implementations of guard scheduling have been proposed including [Sch78, Ber80, vdS81, Sch82, BS83]. Each of these algorithms must resort to some symmetry breaking technique such as priority ordering of processes <ref> [Sch78, Ber80, BS83] </ref>, or timestamps [Sch78]. In fact, like the Dining Philosophers problem, the existence of a fully distributed and symmetric deterministic algorithm for guard scheduling can be shown to be an impossibility [FR80].
Reference: [BT93] <author> J.-D. Boissonnat and M. Teillaud. </author> <title> On the randomized construction of the Delaunay tree. </title> <journal> Theoretical Computer Science, </journal> <volume> 112 </volume> <pages> 339-354, </pages> <year> 1993. </year> <title> An on-line randomized algorithm which computes Delaunay triangulation and Voronoi diagrams of points in any number of dimensions is given. The complexity of the algorithm is optimal provided that the points are inserted in a random order. </title>

Reference: [Car12] <author> R. D. </author> <title> Carmichael. On composite numbers p which satisfy the Fermat congruence a p1 p. </title> <journal> American Mathematical Monthly, </journal> <volume> 19 </volume> <pages> 22-27, </pages> <year> 1912. </year> <title> Let n = i=m i be the unique prime factorization of n, and let (n) = lcmfp -1 1 1 (p 1 1); . . . ; p -m 1 m (p m 1)g. Carmichael shows that n satisfies Fer mat's congruence if and only if (n) divides (n 1). </title>
Reference-contexts: Let n = i=m i be the unique prime factorization of n. Define (n) = lcmfp -1 1 1 (p 1 m (p m 1)g. It was shown by Carmichael <ref> [Car12] </ref>, of the Carmichael numbers fame, that n satisfies Fermat's congruence if and only if (n) divides (n 1). The reader can verify that (561) divides 560.
Reference: [CC85] <author> B. Chor and B. Coan. </author> <title> A simple and efficient randomized Byzantine agreement algorithm. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> SE-11(6):531-539, </volume> <month> June </month> <year> 1985. </year> <title> Chor and Coan present a randomized algorithm for synchronous Byzantine agreement when n 3t + 1, where n is the total number of processors and t is the number of faulty processors. Their algorithm reaches agreement in O(t= log n) expected rounds and O(n 2 t= log n) expected message bits, independently of the distribution of processor failures. </title>
Reference-contexts: The Byzantine Generals problem, known also as "Byzan-tine agreement," has received considerable attention in the literature, e.g., <ref> [PSL80, LSP82, Dol82, Rab83, CC85, Per85, Bra85] </ref>. This is due primarily to its fundamental relevance in distributed computation and its surprising complexity given the simplicity of the problem statement. <p> Ben-Or's algorithm, along with Rabin's [Rab83], was one of the first for reaching asynchronous Byzantine agreement, and it remains the simplest. Since then a number of more elaborate, in terms of efficiency or fault-resiliency, randomized algorithms for the problem have been developed, including <ref> [CC85, Per85, Bra85] </ref> (see also [CD89]). This concludes our survey of distributed randomized algorithms.
Reference: [CCD88] <author> D. Chaum, C. Crepeau, and I. Damgard. </author> <title> Multiparty unconditionally secure protocols. </title> <booktitle> In Proc. 20th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 11-19, </pages> <year> 1988. </year> <title> Assuming the existence of authenticated secrecy channels between each pair of participants (P i s), this paper shows that if at least 2n=3 P i s are honest then a function f (x 1 ; x 2 ; . . . x n ), where x i is known only to P i for each i, can be computed without any P i revealing its information. </title>
Reference-contexts: The concept of zero-knowledge proof has turned out to be especially useful in complexity theory [For87, BHZ87] and cryptography <ref> [GMW87, CCD88, BOGW88, BC86] </ref>. Various notion of zero-knowledge, a classification of these notions, and several related topics appear in [Ore87, FLS90, KMO89]. Some complexity theoretic implications of systems that admit zero-knowledge proofs are discussed in [AH91, For87, GMW91].
Reference: [CCT91] <author> K. L. Clarkson, R. Cole, and R. E. Tarjan. </author> <title> Randomized parallel algorithms for trapezoidal diagrams. </title> <booktitle> In Proc. Seventh Ann. ACM Symp. on Computational Geometry, </booktitle> <pages> pages 152-161, </pages> <address> North Conway, NH, </address> <month> June </month> <year> 1991. </year> <title> Describes randomized parallel CREW PRAM algorithms for building trapezoidal diagrams of line segments in the plane. For general segments, they give an algorithm 102 requiring optimal O(A + n log n) expected work and optimal O(log n) time, where A is the number of intersecting pairs of segments. </title>
Reference: [CD89] <author> B. Chor and C. Dwork. </author> <title> Randomization in Byzantine agreement. </title> <booktitle> In Advances in Computing Research 5: Randomness and Computation, </booktitle> <pages> pages 443-497. </pages> <publisher> JAI Press, </publisher> <year> 1989. </year> <title> A useful survey of the myriad of randomized distributed algorithms for Byzantine agreement. </title>
Reference-contexts: Ben-Or's algorithm, along with Rabin's [Rab83], was one of the first for reaching asynchronous Byzantine agreement, and it remains the simplest. Since then a number of more elaborate, in terms of efficiency or fault-resiliency, randomized algorithms for the problem have been developed, including [CC85, Per85, Bra85] (see also <ref> [CD89] </ref>). This concludes our survey of distributed randomized algorithms. The next section ad dresses some additional important aspects of randomized algorithms, and concludes. 73 4 Additional Topics of Interest and Conclusions We close our survey with a brief discussion of some additional important topics in randomized algorithms.
Reference: [CDRS90] <author> D. Coppersmith, P. Doyle, P. Raghavan, and M. Snir. </author> <title> Random walks on weighted graphs and applications to on-line algorithms (preliminary version). </title> <booktitle> In Proc. 22nd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 369-378, </pages> <address> Baltimore, MD, </address> <month> May </month> <year> 1990. </year> <title> They show that the problem of designing and analyzing randomized on-line algorithms is closely related to the synthesis of random walks on graphs with positive real costs on their edges. </title>
Reference: [CF86] <author> J. D. Cohen and M. J. Fischer. </author> <title> A robust and verifiable cryptographically secure election scheme. </title> <booktitle> In Proc. 27th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 372-381, </pages> <year> 1986. </year> <title> A cryptographic election scheme and an IP proof for convincing participants of the correctness of the election procedure. </title>


Reference: [CG88] <author> B. Chor and O. Goldreich. </author> <title> Unbiased bits from sources of weak randomness and probabilistic communication complexity. </title> <journal> SIAM Journal on Computing, </journal> <volume> 17 </volume> <pages> 230-261, </pages> <year> 1988. </year> <title> Given sources of stings in which no string is "too probable", a method of extracting almost unbiased random bits is presented. </title>
Reference: [CG90] <author> R. Canetti and O. Goldreich. </author> <title> Bounds on tradeoffs between randomness and communication complexity. </title> <booktitle> In Proc. 31st Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 766-775, </pages> <year> 1990. </year> <title> Instead of considering the qualitative question, Is an algorithm deterministic or randomized?, the authors try to determine, quantitatively, how much randomization does an algorithm use. Tight lower bounds on the length of the random input of parties computing a function f | depending on the number of bits communicated and the deterministic complexity of f | are derived. </title>
Reference: [CGMA85] <author> B. Chor, S. Goldwasser, S. Micali, and B. Auwerbuch. </author> <title> Verifiable secret sharing and achieving simultaneity in the presence of faults. </title> <booktitle> In Proc. 26th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 383-395, </pages> <year> 1985. </year> <title> The problems of verifiable secret-sharing and simultaneous broadcast are introduced. Many problems such as distributed coin flipping can be reduced to these problems. </title>

Reference: [Cha84] <author> C.C. Chang. </author> <title> The study of an ordered minimal perfect hashing scheme. </title> <journal> Communications of the ACM, </journal> <volume> 27(4) </volume> <pages> 384-387, </pages> <month> Apr </month> <year> 1984. </year> <title> Chang uses hash functions of the form h(x) = (C mod p(x)) where C is an integer constant and p(x) generates a different prime for each integer x. No general method for finding p(x) is given. </title>
Reference-contexts: Recently there has been a flurry of research activity in the areas of minimal and order preserving perfect hash functions <ref> [Cic80, Jae81, Cha84, LC88, CHM92, MWHC93] </ref>. Czech, Havas and Majewski [CHM92] present a probabilistic algorithm for generating order preserving, minimal perfect hash functions. This algorithm, which runs very fast in practice, uses expected linear time and requires a linear number of words to represent the hash function.
Reference: [Che93] <author> J. Cheriyan. </author> <title> Random weighted Laplacians, Lovasz minimum digraphs and finding minimum separators. </title> <booktitle> In Proc. Fourth Ann. ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 31-40, </pages> <address> Austin, TX, </address> <month> January </month> <year> 1993. </year> <title> Cheriyan gives an O(n 2:38 )-time randomized algorithm for the problem of finding a minimum X-Y separator in a digraph, and of finding a minimum vertex cover in a bipartite graph, thereby improving on the previous best bound of O(n 2:5 = log n). </title>

Reference: [Cic80] <author> R. Cichelli. </author> <title> Minimal perfect hash functions made simple. </title> <journal> Communications of the ACM, </journal> <volume> 23(1) </volume> <pages> 17-19, </pages> <month> Jan </month> <year> 1980. </year> <title> A heuristic for computing a simple, fast, and machine-independent hash function is presented. Because of these properties, </title> <note> several attempts have been made to extend this paper since its publication. </note>
Reference-contexts: Recently there has been a flurry of research activity in the areas of minimal and order preserving perfect hash functions <ref> [Cic80, Jae81, Cha84, LC88, CHM92, MWHC93] </ref>. Czech, Havas and Majewski [CHM92] present a probabilistic algorithm for generating order preserving, minimal perfect hash functions. This algorithm, which runs very fast in practice, uses expected linear time and requires a linear number of words to represent the hash function.

Reference: [CLR90] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> The MIT Press, </publisher> <year> 1990. </year> <title> This well-written encyclopedic introduction to algorithms covers a number of randomized algorithms including those for boolean matrix multiplication, binary search trees, primality testing, partitioning, uni versal hashing, and parallel prefix. </title>
Reference-contexts: Such n are known as the Carmichael numbers, the first three of which are 561, 1105, and 1729. Interestingly, as pointed out in <ref> [CLR90] </ref>, Carmichael numbers are extremely rare; there are, for example, only 255 of them less than 100,000,000. Furthermore, even if a composite n possesses a witness x, i.e., it is not a Carmichael number, there is no obvious way to locate x. <p> The probability that a number is composite, and conditions (2) and (3) are not satisfied is very small. In fact, Rabin [Rab76] has shown that more than half the values of x 2 f1; 2; :::; n1g satisfy (2) or (3) if n is indeed composite (see, also, <ref> [CLR90] </ref>, Theorem 33.38). Monier [Mon80] has subsequently strengthened this result by showing that at least 3=4 of the x are witnesses.
Reference: [CM91] <author> E. Cohen and N. Megiddo. </author> <title> Improved algorithms for linear inequalities with two variables per inequality. </title> <booktitle> In Proc. 23rd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 145-155, </pages> <address> New Orleans, LA, </address> <month> May </month> <year> 1991. </year> <title> A randomized polynomial time algorithm is given for solving a system of linear inequalities wherein every inequality the two nonzero coefficients have opposite signs. </title>
Reference: [CPV91] <author> P. Caspi, J. Piotrowski, and R. Velzaco. </author> <title> An a priori approach to the evaluation of signature analysis efficiency. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 40(9) </volume> <pages> 1068-1071, </pages> <month> Sept </month> <year> 1991. </year> <title> This paper presents an interesting application of control randomization for compressing the results from a digital circuit under test. Instead of imposing any distribution on the input sequence, the linear feedback shift register used for compression is chosen at random. </title>
Reference: [CR79] <author> E. Chang and R. Roberts. </author> <title> An improved algorithm for decentralized extrema-finding in circular configurations of processors. </title> <journal> Communications of the ACM, </journal> <volume> 22(5) </volume> <pages> 281-283, </pages> <month> May </month> <year> 1979. </year> <title> They present a deterministic distributed algorithm for finding the largest of a set of n uniquely numbered processes in a ring. The algorithm uses O(n log n) messages on the average and O(n 2 ) messages in the worst case, and does not assume that n is known a priori. </title>
Reference-contexts: The problem of leader election is then reduced to the problem of picking the process with the smallest, or largest, name. See, for example, <ref> [CR79, Pet82] </ref>. Several authors [Ang80, IR81] have investigated the consequences of the absence of such totally ordered names on election algorithms. Angluin [Ang80] has shown that there exists no deterministic algorithm to carry out elections in a ring of identical processes.

Reference: [CRS93] <author> S. Chari, P. Rohatgi, and A. Srinivasan. </author> <title> Randomness-optimal unique element isolation, with applications to perfect matching and related problems. </title> <booktitle> In Proc. 25th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 458-467, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year> <title> The authors give a randomness-efficient RN C 2 algorithm for perfect matching that uses O(log Z + log n) random bits, where Z is any given upper bound on the number of perfect matchings in the given graph. </title>
Reference: [CS89] <author> K. L. Clarkson and P. W. Shor. </author> <title> Applications of random sampling in computational geometry, II. </title> <journal> Discrete Computational Geometry, </journal> <volume> 4 </volume> <pages> 387-421, </pages> <year> 1989. </year> <title> Efficient probabilistic algorithms are presented for the problems of line segment intersection, convex hull, polygon triangulation, and halfspace partitions of point sets. Each algorithm is of the Las Vegas variety and uses the technique of random sampling. </title> <note> An earlier version of this paper appeared in Proc. Fourth ACM Symp. on Computational Geometry, </note> <year> 1988. </year>
Reference-contexts: This technique is usually called "random sampling." As a simple example, consider a set S of n real numbers, and a randomly chosen subset R of S of size r <ref> [CS89] </ref>. R contains a lot of information about S. For example, if we let S &gt; be the subset of numbers in S that are greater than the maximum value in R, then the expected size of S &gt; is O (n=r).
Reference: [CW79] <author> J. L. Carter and M. N. Wegman. </author> <title> Universal classes of hash functions. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 18 </volume> <pages> 143-154, </pages> <year> 1979. </year> <note> This paper contains the first discussion on universal hashing. An earlier version appeared in Proc. </note> <editor> Ninth Ann. </editor> <booktitle> ACM Symp. on Theory of Computing, </booktitle> <year> 1977, </year> <pages> pp. 106-112. </pages>
Reference-contexts: Universal hashing deals 34 with the possibility of biases in the input, which may result in the O (n) complexity, by randomizing over hashing functions. In universal hashing, first discussed in <ref> [CW79] </ref>, one works with an entire class, H, of hashing functions instead of picking any one single hashing function a priori and using it for every run. At the beginning of each run a function is randomly chosen from H and used for that run.

Reference: [Deu85] <author> D. Deutsch. </author> <title> Quantum theory, the Church-Turing principle and the universal quantum computer. </title> <journal> Proc. Royal Society of London, </journal> <volume> A400:97-117, </volume> <year> 1985. </year> <title> Deutsch introduces the quantum physical computer , later referred to as the 107 "quantum Turing Machine" in [BV93], which can be thought of as a quantum physical analogue of a probabilistic Turing Machine: it has an infinite tape, a finite state control, and, in its most general form, produces a random sample from a probability distribution on any given input. </title>
Reference-contexts: It is conjectured that these inclusions are strict. Empirical evidence includes the fact that, as of now, no one has discovered a polynomial-time randomized algorithm for any NP-complete problem. More recently, the quantum Turing machine has been proposed <ref> [Deu85] </ref> as a quantum physical analogue of the probabilistic Turing machine. A quantum Turing machine, in its most general form, produces a random sample from a probability distribution on any given input.
Reference: [Dev92] <author> O. Devillers. </author> <title> Randomization yields simple O(n log fl n) algorithms for difficult (n) problems. </title> <journal> International Journal of Computational Geometry and Applications, </journal> <volume> 2(1) </volume> <pages> 97-111, </pages> <year> 1992. </year> <title> This papers provides two O(n log fl n) randomized algorithms. One computes the skeleton of a simple polygon and the other the Delaunay triangulation of a set of points knowing the euclidean minimum spanning tree. The existence of deterministic O(n log n) algorithms for both problems is an open problem. </title>
Reference: [DFK91] <author> M. Dyer, A. Frieze, and R. Kannan. </author> <title> A random polynomial time algorithm for approximating the volume of a convex body. </title> <journal> Journal of the ACM, </journal> <volume> 38 </volume> <pages> 1-17, </pages> <year> 1991. </year> <title> A constant time oracle is assumed for determining if a point in space is inside or outside a convex body in n-dimensional Euclidean space. The algorithm runs in time bounded by a polynomial in n, the dimension of the body, and 1=*, where * is the relative error bound. With probability 3=4, it finds an approximation satisfying the error bound. </title>
Reference-contexts: For a study of this area, and the associated background in Markov chains and techniques for proving rapid mixing | informally, a Markov chain is rapidly mixing if it converges to its stationary distribution in a short time | the reader is referred to <ref> [KL85, Bro86, DLMV88, JS89, Bro89, KLM89, DFK91, BCD + 89] </ref>. 82 Derandomization A flurry of activity has recently emerged around the algorithmic design technique of deran-domization: the act of taking an efficient randomized algorithm and removing the coin flipping to obtain an deterministic algorithm.
Reference: [DGMP92] <author> M. Dietzfelbinger, J. Gil, Y. Matias, and N. Pippenger. </author> <title> Polynomial hash functions are reliable. </title> <booktitle> In Proc. 19th Int'l. Colloq. on Automata, Languages and Programming, Lecture Notes in Computer Science, </booktitle> <volume> Vol. 623, </volume> <pages> pages 235-246, </pages> <address> Vi-enna, Austria, </address> <month> July </month> <year> 1992. </year> <title> Springer-Verlag. This paper, along with [DMadH92], shows how to construct a perfect hash function in fi(n) time, which is suitable for real-time applications (Theorems 6.1 and 7.1). </title>
Reference-contexts: The FKS scheme considers only static sets where no updates to S are allowed. Another line of investigation by Dietzfelbinger 36 et al. <ref> [DKM + 88, DMadH92, DGMP92] </ref> attempts to use perfect hashing for maintaining dictionaries in real-time situations. By using certain classes of universal hash functions they show that the FKS probabilistic method can construct a perfect hash function in fi (n) time, with the probability 1O n * [DGMP92]. <p> By using certain classes of universal hash functions they show that the FKS probabilistic method can construct a perfect hash function in fi (n) time, with the probability 1O n * <ref> [DGMP92] </ref>. The perfect hash function can be used to support a real-time dictionary (i.e., a dictionary which allows insertions and deletions of keys, with no knowledge about subsequent events) in expected constant time.
Reference: [Dij71] <author> E. W. Dijkstra. </author> <title> Hierarchical ordering of sequential processes. </title> <journal> Acta Informatica, </journal> <volume> 1(2) </volume> <pages> 115-138, </pages> <year> 1971. </year> <title> Reprinted in Operating Systems Techniques, C.A.R. Hoare and R.H. </title> <editor> Perrot, Eds., </editor> <publisher> Academic Press, </publisher> <year> 1972, </year> <pages> pp. </pages> <month> 72-93. </month> <title> This paper introduces the classical synchronization problem of Dining Philosophers. </title>
Reference-contexts: The underlying communication medium is assumed to be faultless in that messages are received intact and in the order of transmission. 3.1 The Dining Philosophers Problem We describe the randomized algorithm of Lehmann and Rabin [LR81] for the well-known Dining Philosophers problem. The problem, posed originally in <ref> [Dij71] </ref>, is an anthropomorphized resource allocation problem, and is described in [Hoa85] essentially as follows: There once were n philosophers P 0 , P 1 , . . ., P n1 seated around a circular table in a clockwise fashion.
Reference: [DKM + 88] <author> M. Dietzfelbinger, A. Karlin, K. Mehlhorn, F. Meyer auf der Heide, H. Rohn-ert, and R. E. Tarjan. </author> <title> Dynamic perfect hashing: Upper and lower bounds. </title> <booktitle> In Proc. 29th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 524-531, </pages> <address> White Plains, NY, </address> <month> Oct </month> <year> 1988. </year> <title> A randomized algorithm for the dictionary problem based on perfect hashing is presented. </title> <type> 108 </type>
Reference-contexts: The FKS scheme considers only static sets where no updates to S are allowed. Another line of investigation by Dietzfelbinger 36 et al. <ref> [DKM + 88, DMadH92, DGMP92] </ref> attempts to use perfect hashing for maintaining dictionaries in real-time situations. By using certain classes of universal hash functions they show that the FKS probabilistic method can construct a perfect hash function in fi (n) time, with the probability 1O n * [DGMP92].
Reference: [DKS88] <author> C. Dwork, P. C. Kanellakis, and L. J. Stockmeyer. </author> <title> Parallel algorithms for term matching. </title> <journal> SIAM Journal on Computing, </journal> <volume> 17(4) </volume> <pages> 711-731, </pages> <year> 1988. </year> <title> In the context of a parallel algorithm for the term matching problem, this paper shows how randomization can be used to reduce the initial processor complexity from O(n 5 ) to O(M (n)), where M (n) is the processor complexity of multiplying two n fi n matrices. </title>
Reference: [DLMV88] <author> P. Dagum, M. Luby, M. Mihail, and U.V. Vazirani. </author> <title> Polytopes, permanents and graphs with large factors. </title> <booktitle> In Proc. 29th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 412-421, </pages> <year> 1988. </year> <title> Randomized algorithms for approximating the number of perfect matchings in a graph based on a geometric reasoning are presented. </title>
Reference-contexts: For a study of this area, and the associated background in Markov chains and techniques for proving rapid mixing | informally, a Markov chain is rapidly mixing if it converges to its stationary distribution in a short time | the reader is referred to <ref> [KL85, Bro86, DLMV88, JS89, Bro89, KLM89, DFK91, BCD + 89] </ref>. 82 Derandomization A flurry of activity has recently emerged around the algorithmic design technique of deran-domization: the act of taking an efficient randomized algorithm and removing the coin flipping to obtain an deterministic algorithm.
Reference: [dlVKS93] <author> F. de la Vega, S. Kannan, and M. Santha. </author> <title> Two probabilistic results on merging. </title> <journal> SIAM Journal on Computing, </journal> <volume> 22(2) </volume> <pages> 261-271, </pages> <year> 1993. </year> <title> Two probabilistic algorithms for merging two sorted lists are presented. When m &lt; n, the first algorithm has a worst-case time better than any deterministic algorithm for 1:618 &lt; n=m &lt; 3. The algorithm is extended to perform well for any value of n=m. </title>
Reference: [DMadH90] <editor> M. Dietzfelbinger and F. Meyer auf der Heide. </editor> <title> How to distribute a dictionary in a complete network. </title> <booktitle> In Proc. 22nd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 117-127, </pages> <address> Baltimore, MD, </address> <month> May </month> <year> 1990. </year> <title> A randomized algorithm is given for implementing a distributed dictionary on a complete network of p processors. The algorithm is based on hashing and uses O(n=p) expected time to execute n arbitrary instructions (insert, delete, lookup). The response time for each lookup is expected constant. </title>
Reference: [DMadH92] <editor> M. Dietzfelbinger and F. Meyer auf der Heide. </editor> <title> Dynamic hashing in real time. In Informatik Festschrift zum 60. </title> <editor> Geburtstag von Gunter Holtz, </editor> <booktitle> Teubner-Texte zur Informatik, </booktitle> <volume> Band 1, </volume> <pages> pages 95-119. </pages> <editor> B. G. </editor> <publisher> Teubner, </publisher> <address> Stuttgart, Germany, </address> <year> 1992. </year> <title> The FKS probabilistic procedure is extended to real-time. See Theorems 6.1 and 7.1 in [DGMP92]. A preliminary version of this paper appeared as "A new universal class of hash functions and, dynamic hashing in real time," </title> <booktitle> Proc. 17th Int'l. Colloq. on Automata, Languages and Programming, </booktitle> <year> 1990, </year> <pages> pp. 6-19. </pages>
Reference-contexts: The FKS scheme considers only static sets where no updates to S are allowed. Another line of investigation by Dietzfelbinger 36 et al. <ref> [DKM + 88, DMadH92, DGMP92] </ref> attempts to use perfect hashing for maintaining dictionaries in real-time situations. By using certain classes of universal hash functions they show that the FKS probabilistic method can construct a perfect hash function in fi (n) time, with the probability 1O n * [DGMP92].
Reference: [DMT92] <author> O. Devillers, S. Meiser, and M. Teillaud. </author> <title> Fully dynamic Delaunay triangulation in logarithmic expected time per operation. Computational Geometry: </title> <journal> Theory and Applications, </journal> <volume> 2(2) </volume> <pages> 55-80, </pages> <year> 1992. </year> <title> This paper extends the results of [BT93] by considering the deletion of points. The Delaunay triangulation of n points is updated in O(log n) expected time per insertion and O(log log n) expected time per deletion. The insertion sequence is assumed to be in a random order, and deletions are assumed to concern any currently present point with the same probability. </title>
Reference: [DoD83] <author> DoD (United States Dept. </author> <title> of Defense). Reference Manual for the Ada Programming Language, </title> <booktitle> MIL-STD 1815A, </booktitle> <month> February </month> <year> 1983. </year> <title> Section 3.2 of our survey discusses a randomized distributed algorithm for the scheduling of input and output guards. The designers of Ada chose only to allow nondeterministic choice among the accept alternatives of a select statement. This design decision makes the guard scheduling problem in Ada much easier and, in particular, obliviates the need for randomization. </title>
Reference-contexts: The lack of a fully distributed and symmetric deterministic algorithm for guard scheduling is indeed one of the reasons the designers of Ada <ref> [DoD83] </ref> chose an asymmetric rendezvous construct|nondeterministic choice in Ada exists only among the accept alternatives of a select statement.
Reference: [Dol82] <author> D. Dolev. </author> <title> The Byzantine generals strike again. </title> <journal> Journal of Algorithms, </journal> <volume> 3(1) </volume> <pages> 14-30, </pages> <year> 1982. </year> <title> This is the introductory paper on Byzantine Generals. Dolev proves that Byzantine agreement is achievable in any distributed system if and only if the number of faulty processors in the system is (1) less than one-third of the total number of processors; and (2) less than one-half the connectivity of the system's network. In cases where agreement is achievable, deterministic algorithms for obtaining it are given. </title>
Reference-contexts: The Byzantine Generals problem, known also as "Byzan-tine agreement," has received considerable attention in the literature, e.g., <ref> [PSL80, LSP82, Dol82, Rab83, CC85, Per85, Bra85] </ref>. This is due primarily to its fundamental relevance in distributed computation and its surprising complexity given the simplicity of the problem statement.
Reference: [DS90] <author> C. Dwork and L. Stockmeyer. </author> <title> The time complexity gap for 2-way probabilistic finite-state automata. </title> <journal> SIAM Journal on Computing, </journal> <volume> 19(6) </volume> <pages> 1011-1023, </pages> <year> 1990. </year> <title> Among other results, this paper shows that any 2-way probabilistic finite automaton recognizing a non-regular language must use exponential expected time infinitely often. Since any regular language can be recognized in linear time, a time-complexity gap is established. Similar results were published in the paper entitled "On the Power of 2-Way Probabilistic Finite Automata," </title> <booktitle> which appeared in Proc. 30th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1989. </year>
Reference: [DSMP87] <author> A. De Santis, S. Micali, and G. Persiano. </author> <title> Non-interactive zero-knowledge proof-systems. </title> <booktitle> In Advances in Cryptology-CRYPTO 87, Lecture Notes in 110 Computer Science, </booktitle> <volume> Vol. 293, </volume> <pages> pages 52-72. </pages> <publisher> Springer-Verlag, </publisher> <year> 1987. </year> <title> This pa-per introduces the notion of non-interactive zero-knowledge proofs based on a weaker complexity assumption than that used in [BFM88]. </title>
Reference-contexts: Another notion that is gaining popularity is that of noninteractive zero-knowledge proofs first proposed by Blum, Feldman, and Micali [BFM88]. A notion of non-interactive zero-knowledge proofs based on a weaker complexity assumption than that used in [BFM88] is presented in <ref> [DSMP87] </ref>. Most of the work to date is summarized in [BDMP91]. In interactive zero-knowledge proof-systems, the prover P interactively proves to the verifier V that a certain theorem is true without giving away the details of the proof.
Reference: [DSMP88] <author> A. De Santis, S. Micali, and G. Persiano. </author> <title> Non-interactive zero-knowledge proof-systems with preprocessing. </title> <booktitle> In Advances in Cryptology-CRYPTO 88, Lecture Notes in Computer Science, </booktitle> <volume> Vol. 403, </volume> <pages> pages 269-283. </pages> <publisher> Springer-Verlag, </publisher> <year> 1988. </year> <title> The authors show that if any one-way function exists after an interactive preprocessing stage then any sufficiently short theorem can be proven non-interactively in zero-knowledge. </title>
Reference: [DSS90] <author> C. Dwork, D. Shmoys, and L. Stockmeyer. </author> <title> Flipping persuasively in constant time. </title> <journal> SIAM Journal on Computing, </journal> <volume> 19(2) </volume> <pages> 472-499, </pages> <year> 1990. </year> <title> An efficient randomized protocol is presented that tolerates up to n=(log n) malicious processors that requires constant expected number of rounds to achieve a distributed coin toss. Also given is a Byzantine Generals algorithm that tolerates n=(log n) failures and runs in constant expected number of rounds. </title> <note> A preliminary version of this paper appeared in Proc. </note> <editor> 27th Ann. </editor> <booktitle> IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1986. </year>
Reference: [DSY90] <author> A. De Santis and M. Yung. </author> <title> Cryptographic applications of non-interactive metaproofs and many-prover systems. </title> <booktitle> In Advances in Cryptology-CRYPTO 90, Lecture Notes in Computer Science, </booktitle> <volume> Vol. 537. </volume> <publisher> Springer-Verlag, </publisher> <year> 1990. </year> <title> The authors show how many provers can share the same random string in proving multiple theorems non-interactively in zero-knowledge. </title>
Reference: [ER60] <author> P. Erd-os and A. Renyi. </author> <title> On the evolution of random graphs. </title> <journal> Publ. Math. Inst. Hung. Acad. Sci., </journal> <volume> 5 </volume> <pages> 17-61, </pages> <year> 1960. </year> <title> A seminal paper on random graphs. Reprinted in Paul Erd-os: The Art of Counting. Selected Writings, </title> <editor> J.H. Spencer, Ed., </editor> <volume> Vol. </volume> <booktitle> 5 of the series Mathematicians of Our Time, </booktitle> <publisher> MIT Press, </publisher> <year> 1973, </year> <pages> pp. 574-617. </pages>
Reference-contexts: The idea used is the following. Certain integer congruences that correspond to acyclic rgraphs can be solved in linear time. This uses a result in <ref> [ER60] </ref>, which states that the majority of random sparse 2graphs are acyclic. It is extended in [MWHC93] to rgraphs, with r &gt; 2. Perfect hash functions are obtained by randomly mapping a set of keys into an acyclic rgraph. The mapping is achieved via universal hashing.
Reference: [ES74] <author> P. Erd-os and J. Spencer. </author> <title> Probabilistic Methods in Combinatorics. </title> <publisher> Academic Press, </publisher> <address> New York and London, </address> <year> 1974. </year> <title> Recognized experts in the field present a small, power packed monograph on non-constructive probabilistic methods in combinatorics. Our algorithm for networks without large hierarchies is based on the discussion in Chapter 1 of this book. Other highlights include, Ramsey's theorems and evolution of random graphs. </title> <type> 111 </type>
Reference-contexts: For example, the problem NetHierarchy calls for constructing a network (a complete directed graph) on n nodes that does not contain a hierarchy on any subset of m nodes. A hierarchy, also known as a transitive tournament <ref> [ES74] </ref>, is a graph in which for all nodes x, y and z, if the directed edges (x; y) and (y; z) exist then the edge (x; z) also exists. <p> This algorithm, which is of the Las Vegas variety, will never declare a composite number to be prime or vice versa. However, it may not terminate in polynomial time for some inputs. The next problem we consider, which concerns the notion of transitive tournament due to Erd-os and Spencer <ref> [ES74] </ref>, again illustrates random search. In this case, however, the sample space is so abundant with good points that the "checking" step inherent to primality testing can be dispensed with. 2.3 Networks without Large Hierarchies Long ago, in a place called Confusion Land, there reigned an incompetent king called Nadir. <p> How will Nadir assign ranks to these thousand appointees in order to achieve his crooked objective? In this section we consider Nadir's problem in detail and provide a general solution, the key to which is a theorem of Erd-os and Spencer (Chapter 1 of <ref> [ES74] </ref>). To make this section self-contained, their result is proved here as Theorem 1. <p> A network T is a hierarchy if (x; y); (y; z) 2 T implies (x; z) 2 T , 8x; y; z 2 V . Networks and hierarchies are called tournaments and transitive tournaments, respectively, in <ref> [ES74] </ref>. Nadir's problem then, which we refer to as the NetHierarchy problem, is to construct a network that does not have "large" hierarchies. <p> Also, note that the full network is not a hierarchy because of the cycles among nodes f6; 3; 1g, f6; 3; 4g, and f6; 3; 5g. Erd-os and Spencer <ref> [ES74] </ref> have proved an important property concerning the size of hierarchies in arbitrary networks, which we now present. Define (n) to be the largest integer such that every network on n nodes contains a hierarchy of (n) nodes. Unless stated otherwise log denotes logarithms to the base 2. Theorem 1 ([ES74]) <p> In general, given values of l,r,d,k it is easy to prove or disprove the existence of an (l; r; d; k)-expander through probabilistic methods <ref> [ES74] </ref> or other non-constructive arguments. For example, the reader may enjoy proving, using a probabilistic argument, that there exists (m log m ; m; 2 log 2 m; m)-expanders for any m [Sip88].
Reference: [FCDH91] <author> E. Fox, Q.F. Chen, A. Daoud, and L.S. Heath. </author> <title> Order preserving minimal perfect hash functions and information retrieval. </title> <journal> ACM Trans. on Information Systems, </journal> <volume> 9(2) </volume> <pages> 281-308, </pages> <month> July </month> <year> 1991. </year> <title> This algorithm combines the techniques of embedding the keys into an rgraph and two-level hashing to design hash functions that are optimal in terms of hashing time and space utilization. The algorithm to generate the hash functions uses near-optimal space and time. Any desired order can be maintained. </title>
Reference-contexts: For other related developments in order preserving minimal perfect hash functions, which are practical for very large databases, see <ref> [FCDH91, FHCD92] </ref>. A considerable body of literature exists on minimal and order preserving hash functions and a complete discussion is beyond the scope of this survey. An overview of some of the results outlined above can be found in [MadH90].
Reference: [Fey82] <author> R. P. </author> <title> Feynman. Simulating physics with computers. </title> <journal> International Journal of Theoretical Physics, </journal> 21(6/7):467-488, 1982. Feynman points out the curious problem that it appears to be impossible to simulate a general quantum physical system on a probabilistic Turing Machine without an exponential slowdown, even if the quantum physical system to be simulated is discrete (like some kind of quantum cellular automaton). 
Reference-contexts: Quantum Turing machines give rise to the new complexity classes Quantum Polynomial time (QP) and Bounded Quantum Polynomial time (BQP) [BV93]. There is evidence to suggest that it is impossible to simulate a quantum Turing machine with a probabilistic Turing machine without incurring an exponential slowdown <ref> [Fey82] </ref>. Theory of Probabilistic Automata Just as there is a complexity theory of probabilistic algorithms which parallels the complexity theory of deterministic algorithms, there is a theory of probabilistic automata, e.g., [Rab63, Sal69, Paz71], which parallels the classical theory of nondeterministic automata.
Reference: [FFS87] <author> U. Feige, A. Fiat, and A. Shamir. </author> <title> Zero-knowledge proofs of identity. </title> <booktitle> In Proc. 19th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 210-217, </pages> <year> 1987. </year> <title> Zero-knowledge proofs, in the traditional sense, reveal 1 bit of information to the verifier, viz. w 2 L or w 62 L. This paper proposes the notion of "truly zero knowledge" proofs where the prover convinces the verifier that he/she knows whether w is or is not in L, without revealing any other information. An RSA-like scheme based on the difficulty of factoring, which is much more efficient than RSA, </title> <note> is also presented. </note>
Reference-contexts: Some complexity theoretic implications of systems that admit zero-knowledge proofs are discussed in [AH91, For87, GMW91]. Truly Zero-Knowledge and Multi-Prover Interactive Proofs Zero-knowledge proofs, in the traditional sense, reveal one bit of information to the verifier, viz. w 2 L or w 62 L. In <ref> [FFS87] </ref>, a notion of truly zero-knowledge proof is proposed where the prover convinces the verifier that it knows whether w is or is not in L, without revealing any other information.

Reference: [FH84] <author> V. A. Feldman and D. Harel. </author> <title> A probabilistic dynamic logic. </title> <journal> Journal of Com--puter and System Sciences, </journal> <volume> 28(2) </volume> <pages> 193-215, </pages> <year> 1984. </year> <title> This paper defines a formal logic PrDL to reason about probabilistic programs. It extends the semantics of Kozen [Koz81] formulas involving probabilistic programs. </title>
Reference: [FHCD92] <author> E. Fox, L.S. Heath, Q.F. Chen, and A. Daoud. </author> <title> Practical minimal perfect hash functions for large databases. </title> <journal> Communications of the ACM, </journal> <volume> 35(1) </volume> <pages> 105-121, </pages> <month> January </month> <year> 1992. </year> <title> This paper presents two randomized algorithm for minimal perfect hashing functions that are designed for use with data bases with as many as a million keys. The algorithms have been experimentally evaluated. The first algorithm generates hash functions that are less than O(n) computer words long, and the second generates functions that approach the theoretical lower bound of (n= log n) words. </title> <note> This work is a predecessor of [FCDH91]. </note>
Reference-contexts: For other related developments in order preserving minimal perfect hash functions, which are practical for very large databases, see <ref> [FCDH91, FHCD92] </ref>. A considerable body of literature exists on minimal and order preserving hash functions and a complete discussion is beyond the scope of this survey. An overview of some of the results outlined above can be found in [MadH90]. <p> The third category of perfect hashing schemes uses some kind of backtracking procedures to search through the space of all possible functions | typically an ordering heuristic is used to cut down the search space | in order to find a perfect hash function <ref> [FHCD92] </ref>. Finally, the fourth category consists of algorithms that map the given n keys into a n fi n matrix and use matrix packing algorithms to compress the 2-D array into linear space [Meh84a]. All four categories of perfect hashing algorithms are rich in probabilistic methods.
Reference: [FKS82] <author> M. L. Fredman, J. Komlos, and E. Szemeredi. </author> <title> Sorting a sparse table with O(1) worst case access time. </title> <booktitle> In Proc. 23rd Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 165-169, </pages> <year> 1982. </year> <title> This paper proves many fundamental results that are essential for constructing a perfect hashing function for a given set of keys. </title>
Reference-contexts: These two schemes are explored in the following sections. 30 2.4.1 Perfect Hashing Heuristic methods for perfect hashing were first introduced in [Spr77]. A recent overview of perfect hashing can be found in [GBY91]. Several seminal results that make perfect hashing possible were proved in <ref> [FKS82, Meh82] </ref>. The discussion in this section is based on Section 2.3 of [Meh84a]. A function h : U ! [0 . . . m 1] is called a perfect hash function for S U if 8x; y 2 S; h (x) 6= h (y) if x 6= y.
Reference: [FL82] <author> M. J. Fischer and N. Lynch. </author> <title> A lower bound for the time to assure interactive consistency. </title> <journal> Information Processing Letters, </journal> <volume> 14(4) </volume> <pages> 182-186, </pages> <year> 1982. </year> <title> They prove that no deterministic solution to the Byzantine Generals problem can reach agreement in less than t + 1 rounds, where t is the number of faulty processes. </title>
Reference-contexts: Yet if the number of faulty processes is O ( n), then the expected number of rounds is constant. This illustrates another advantage of tossing coins, since any deterministic solution to the Byzantine Generals problem cannot reach agreement in less than t + 1 rounds <ref> [FL82] </ref>. As for the per-round message complexity, every process sends a message to every other process in each round. Thus, assuming that faulty processes do not send more than O (n) messages each per round, the total number of messages transmitted per round is O (n 2 ).


Reference: [FLP85] <author> M. J. Fischer, N. Lynch, and M. Paterson. </author> <title> Impossibility of distributed consensus with one faulty process. </title> <journal> Journal of the ACM, </journal> <volume> 32(2), </volume> <month> April </month> <year> 1985. </year> <title> This paper proves that every completely asynchronous, deterministic algorithm for Byzan-tine agreement has the possibility of nontermination, even with only one faulty processor. This impossibility result does not hold in the synchronous case. For completely asynchronous probabilistic algorithms, the problem is avoided since termination is only required with probability 1. See Section 3.5 for an example of such a probabilistic algorithm for asynchronous Byzantine agreement. </title>
Reference-contexts: only if less than one-third of the total number of processes are faulty. (The problem of Byzantine agreement among synchronous processes that are not completely connected has also been studied [LSP82] and constraints on the connectivity required for a solution have been determined.) For the asynchronous case, Fischer et al. <ref> [FLP85] </ref> proved that Byzantine agreement is impossible for deterministic processes, even if the processes are not symmetric and there is only one faulty process. In particular, deterministic processes are susceptible to nontermi-nation.

Reference: [FLW92] <author> A. M. Ferrenberg, D. F. Landau, and Y. J. Wong. </author> <title> Monte Carlo simulations: Hidden errors from "good" random number generators. </title> <journal> Physical Review Letters, </journal> <volume> 69(23) </volume> <pages> 3382-3388, </pages> <month> December </month> <year> 1992. </year> <title> The authors unveil subtle correlations 114 in five widely used pseudo-random number generators. They undertook this investigation when a simple mathematical model of the behavior of atoms in a magnetic crystal failed to give the expected results. They traced the error to the pseudo-random number generator used in the simulation. </title>
Reference-contexts: Browne, New York Times, Tue., Jan. 12, 1993]. Browne goes on to point out the danger inherent in using PRGs, which was brought to light in a recent paper by Ferrenberg, Landau, and Wong <ref> [FLW92] </ref>. This paper recounts how the authors were puzzled when a simple mathematical model of the behavior of atoms in a magnetic crystal failed to give expected results. They traced the error to the PRG used in the simulation.
Reference: [FM85a] <author> P. Flajolet and G. N. Martin. </author> <title> Probabilistic counting algorithms for data base applications. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 25(31) </volume> <pages> 182-209, </pages> <year> 1985. </year> <title> This paper presents a probabilistic counting technique for determining the number of distinct records in a file. The technique requires O(1) storage and a single pass over the file. Also appeared as "Probabilistic counting," </title> <booktitle> Proc. 24th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1983, </year> <pages> pp. 76-84. </pages>
Reference: [FM85b] <author> P. Flajolet and G. N. Martin. </author> <title> Probabilistic counting algorithms for data base applications. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 31 </volume> <pages> 182-209, </pages> <year> 1985. </year> <title> Probabilistic Counting is a technique for estimating the cardinality (number of distinct elements) of a large file typically stored on disk. This problem naturally arises in query optimization of database systems. Using m words of in-core memory, probabilistic counting achieves an expected relative accuracy close to 0:78= p m. Moreover, it performs only a constant number of operations per element of the file. </title>
Reference: [FM88] <author> P. Feldman and S. Micali. </author> <title> Optimal algorithms for Byzantine agreement. </title> <booktitle> In Proc. 20th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 162-172, </pages> <year> 1988. </year> <title> The expected running time of this algorithm is constant in a synchronous network of n nodes if the number of faults is less than n=3, and in an asynchronous network of n nodes if the number of faults is less than n=4. </title>
Reference: [For87] <author> L. Fortnow. </author> <title> The complexity of perfect zero-knowledge. </title> <booktitle> In Proc. 19th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 204-209, </pages> <month> May </month> <year> 1987. </year> <title> The notion of perfect zero-knowledge requires that the verifier, no matter how powerful it is, not learn any additional information. Fortnow proves that for any language which has a perfect zero-knowledge protocol, its complement has a single round interactive protocol. This result implies that for NP-complete languages, there are no perfect zero-knowledge protocols (unless the polynomial time hierarchy collapses). </title>
Reference-contexts: The concept of zero-knowledge proof has turned out to be especially useful in complexity theory <ref> [For87, BHZ87] </ref> and cryptography [GMW87, CCD88, BOGW88, BC86]. Various notion of zero-knowledge, a classification of these notions, and several related topics appear in [Ore87, FLS90, KMO89]. Some complexity theoretic implications of systems that admit zero-knowledge proofs are discussed in [AH91, For87, GMW91]. <p> Various notion of zero-knowledge, a classification of these notions, and several related topics appear in [Ore87, FLS90, KMO89]. Some complexity theoretic implications of systems that admit zero-knowledge proofs are discussed in <ref> [AH91, For87, GMW91] </ref>. Truly Zero-Knowledge and Multi-Prover Interactive Proofs Zero-knowledge proofs, in the traditional sense, reveal one bit of information to the verifier, viz. w 2 L or w 62 L.

Reference: [FS89] <author> L. Fortnow and M. Sipser. </author> <title> Probabilistic computation in linear time. </title> <booktitle> In Proc. 21st Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 148-156, </pages> <year> 1989. </year> <title> An oracle is specified, under which all problems solvable in random polynomial time are solvable in random linear time, thus collapsing a number of randomized complexity classes into one. Analogous results in deterministic computations are demonstratably false. </title>
Reference: [FS92] <author> U. Feige and A. Shamir. </author> <title> Multiple oracle interactive proofs with constant space verifiers. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 44 </volume> <pages> 259-271, </pages> <year> 1992. </year> <title> The authors show that the expected payoff of reasonable games of incomplete information are undecidable. The Turing-machine simulation uses polynomial cost and stops with probability 1. </title>
Reference: [Fur87] <author> M. Furer. </author> <title> The power of randomness for computational complexity. </title> <booktitle> In Proc. 19th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 178-181, </pages> <year> 1987. </year> <title> This paper improves on the VLSI algorithm by Mehlhorn and Schmidt [MS82]. An O(n) average bit complexity algorithm with no probability of error is demonstrated. </title>
Reference: [Gaz91] <author> H. Gazit. </author> <title> An optimal randomized parallel algorithm for finding the connected components of a graph. </title> <journal> SIAM Journal on Computing, </journal> <volume> 20(6) </volume> <pages> 1046-1067, </pages> <year> 1991. </year> <title> The expected running time of this algorithm is O(log n) with O((m+n)= log n) processors, where n is the number of vertices and m is the number of edges. It uses O(m + n) space. The algorithm is optimal in the time-processor product sense, as well as in space complexity. </title>
Reference: [GBY91] <author> G.H. Gonnet and R. Baeza-Yates. </author> <title> Handbook of Algorithms and Data Structures. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1991. </year> <title> Section 3.3.16 gives an overview of perfect hashing. </title> <type> 116 </type>
Reference-contexts: These two schemes are explored in the following sections. 30 2.4.1 Perfect Hashing Heuristic methods for perfect hashing were first introduced in [Spr77]. A recent overview of perfect hashing can be found in <ref> [GBY91] </ref>. Several seminal results that make perfect hashing possible were proved in [FKS82, Meh82]. The discussion in this section is based on Section 2.3 of [Meh84a].
Reference: [GGK92] <author> M. Gereb-Graus and D. Krizanc. </author> <title> The average complexity of parallel com-parison merging. </title> <journal> SIAM Journal on Computing, </journal> <volume> 21 </volume> <pages> 43-47, </pages> <year> 1992. </year> <title> The authors establish a lower bound on the time complexity of randomized merging of two sorted lists in a parallel computation tree model. An earlier version of this paper, entitled "The Complexity of Parallel Comparison Merging," </title> <booktitle> appeared in Proc. 28th Symp. on Foundations of Computer Science, </booktitle> <year> 1987. </year>
Reference: [GGM86] <author> O. Goldreich, S. Goldwasser, and S. Micali. </author> <title> How to construct random functions. </title> <journal> Journal of the ACM, </journal> <volume> 33 </volume> <pages> 792-807, </pages> <year> 1986. </year> <title> A computational complexity measure of the randomness of functions is introduced, and, assuming the existence of one-way functions, a pseudo-random function generator is presented. </title>
Reference-contexts: They also introduce a class of PRGs based on universal hashing functions. Some consequences of the existence of PRGs are discussed in [All87]. While most of the work in this area has concentrated on generation of pseudo-random strings, in <ref> [GGM86] </ref>, Goldreich, Goldwasser, and Micali address the issue of generating random functions. They introduce a computational complexity measure of the randomness of functions. Assuming the existence of one-way functions, a pseudo-random function generator is presented.
Reference: [GHY89] <author> Z. Galil, S. Haber, and M. Yung. </author> <title> Minimum-knowledge interactive proofs for decision problems. </title> <journal> SIAM Journal on Computing, </journal> <volume> 18(4) </volume> <pages> 711-739, </pages> <month> Aug </month> <year> 1989. </year> <title> This paper extends the work of [GMR89], the concept of minimum knowledge is defined and a minimum-knowledge protocol for transferring the results of any fixed computation from one party to another (e.g. prover to verifier) is described. </title>

Reference: [GJ79] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-completeness. W.H. </title> <publisher> Freeman and Company, </publisher> <year> 1979. </year> <title> This well-known book on the theory of NP -completeness contains a section on the probabilistic analysis of approximation algorithms for NP -complete combinatorial optimization problems. </title>
Reference-contexts: Two major applications are the analysis of average-case behavior of sequential algorithms and data structures (see [VF90] for an excellent survey), and the analysis of approximation algorithms for coping with intractability of combinatorial optimization problems <ref> [GJ79] </ref>. For such problems, the goal is to prove that some simple and fast algorithm produces "good," near-optimal solutions. A classic example is Karp's divide-and-conquer algorithm for the Traveling Salesman problem in a plane [Kar86]. Bin packing is another problem for which very good approximation algorithms have been discovered.
Reference: [GK86] <author> S. Goldwasser and J. Kilian. </author> <title> Almost all primes can be quickly certified. </title> <booktitle> In Proc. 18th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 316-329, </pages> <year> 1986. </year> <title> The authors show that if Cramer's conjecture about the spacing of prime 117 numbers is true than there exists a random polynomial time algorithm for primality testing. </title>
Reference-contexts: While it is easy to verify such a proof, unfortunately, there is no known method for coming up with the proof, or demonstrating the absence thereof, in polynomial time. Other algorithms utilizing different number theoretic properties for defining witnesses for compositeness and primality have also been discovered <ref> [Rab80a, Leh82, AH87, GK86, AH88] </ref>. For example, Adleman and Huang [AH88] have devised a new algorithm that, instead of deciding primality by the inability to demonstrate witnesses to compositeness, employs a separate Monte Carlo test for primality.
Reference: [GKS92] <author> L. J. Guibas, D. E. Knuth, and M. Sharir. </author> <title> Randomized incremental construction of Delaunay and Voronoi diagrams. </title> <journal> Algorithmica, </journal> <volume> 7(4) </volume> <pages> 381-413, </pages> <year> 1992. </year> <title> They give a new randomized incremental algorithm for the construction of planar Voronoi diagrams and Delaunay triangulations. Their algorithm takes expected time O(n= log n) and space O(n), is very practical to implement, and along with the algorithm of [BT93], </title> <note> is more "on-line" than earlier similar methods. </note>
Reference: [GKS93] <author> W. Goddard, V. King, and L. Schulman. </author> <title> Optimal randomized algorithms for local sorting and set-maxima. </title> <journal> SIAM Journal on Computing, </journal> <volume> 22(2) </volume> <pages> 272-283, </pages> <month> April </month> <year> 1993. </year> <title> Nearly optimal randomized algorithms are presented for the local sorting problem (i.e., determining the relative order in every pair of adjacent vertices in a graph in which each vertex is assigned an element of a total order) and the set-maxima problem (i.e., determining the maximum element of each set in a collection of sets whose elements are drawn from a total order). </title>
Reference: [GL89] <author> R. I. Greenberg and C. E. Leiserson. </author> <title> Randomized routing on fat-trees. </title> <editor> In S. Micali, editor, </editor> <booktitle> Advances in Computing Research 5: Randomness and Computation, </booktitle> <pages> pages 345-374. </pages> <publisher> JAI Press, </publisher> <address> Greenwich, CT, </address> <year> 1989. </year> <title> Fat-Trees are a class of routing networks in parallel computation. Given a set of messages to send, the choice is made at random of which message is to be sent at what time. This approach is different from that of [Val82]. </title> <booktitle> See also Proc. 17th Ann. ACM Symp. on Theory of Computing, </booktitle> <year> 1985, </year> <pages> pp. 241-249. </pages>
Reference: [GM84] <author> S. Goldwasser and S. Macali. </author> <title> Probabilistic encryption. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 28(2) </volume> <pages> 270-299, </pages> <year> 1984. </year> <title> This paper introduces a new probabilistic encryption technique. It also contains an excellent introduction to other public key cryptosystems with discussion on objections to cryptosystems based on trapdoor functions. </title>
Reference-contexts: if n divides 2 n 2, 18 are wrong results which exemplify the mysteries enshrined in prime numbers. (For the latter, consider, for example, n = 341.) Of late extremely large prime numbers are in great demand because of their use in defining trap-door functions for public key cryptography systems <ref> [RSA78, Sch84, GM84, Smi83] </ref>. For example, in the Rivest-Shamir-Adleman (or RSA) cryptosystem [RSA78] the keys are 200-digit numbers. An encryption key is the product of two secret primes, having approximately 100 digits each, which are known only to the creator of the key.
Reference: [GMR88] <author> S. Goldwasser, S. Micali, and R. Rivest. </author> <title> A digital signature scheme secure against adaptive chosen-message attack. </title> <journal> SIAM Journal on Computing, </journal> <volume> 17 </volume> <pages> 281-308, </pages> <year> 1988. </year> <note> This is a companion paper of [KPU88]. 118 </note>
Reference: [GMR89] <author> S. Goldwasser, S. Macali, and C. Rackoff. </author> <title> The knowledge complexity of inter-active proof systems. </title> <journal> SIAM Journal on Computing, </journal> <pages> pages 186-208, </pages> <year> 1989. </year> <note> This paper first appeared in Proc. </note> <editor> 17th Ann. </editor> <booktitle> ACM Symp. on Theory of Computing, </booktitle> <year> 1985, </year> <pages> pp. </pages> <month> 291-304. </month> <title> It introduces the important notion of zero-knowledge interactive proofs. The authors show that it is possible to prove that certain theorems are true without divulging why this is so. </title>
Reference-contexts: The objective of the verifier is to convince itself that the prover does in fact have a solution to the problem. Independent formalizations of interactive proof systems by Goldwasser, Micali and Rack-off <ref> [GMR89] </ref>, and Babai and Moran [BM88, Bab85], which have been shown to be equivalent [GS89], allow a polynomial-time verifier to toss coins and arbitrarily interact with the prover. In [GMR89], the outcomes of the coin tosses made by the verifier are hidden from the prover. <p> Independent formalizations of interactive proof systems by Goldwasser, Micali and Rack-off <ref> [GMR89] </ref>, and Babai and Moran [BM88, Bab85], which have been shown to be equivalent [GS89], allow a polynomial-time verifier to toss coins and arbitrarily interact with the prover. In [GMR89], the outcomes of the coin tosses made by the verifier are hidden from the prover. In [BM88], the proof system is considered as a game played between two players called Arthur and Merlin. <p> In [BM88], the proof system is considered as a game played between two players called Arthur and Merlin. Once again, Arthur and Merlin (the verifier and the prover, respectively) can toss coins and can talk back and forth. However, in this proof-system, unlike that in <ref> [GMR89] </ref>, all coin tosses made by the verifier are seen by the prover. These formalizations have led to the emergence of a hierarchy of probabilistic complexity classes that generalizes NP [BM88]. <p> This latter property is crucial to the notion of zero-knowledge proofs described next. Zero-Knowledge Proofs Sometimes, an additional requirement is imposed on the prover, viz., that it completely hide the details of its solution from the verifier. In this case, the proof is referred to as a zero-knowledge proof <ref> [GMR89, BM88, Bab85, KMO89, GMW91] </ref> because, even though the verifier has an efficient means of verifying responses provided by the prover, at the end it has learned nothing except that the prover is right or wrong.
Reference: [GMV91] <author> J. Gil, Y. Matias, and U. Vishkin. </author> <title> Towards a theory of nearly constant-time parallel algorithms. </title> <booktitle> In Proc. 32nd Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 698-710, </pages> <year> 1991. </year> <title> This paper presents a paradigm for obtaining O(log fl n) running time for problems such as directory maintenance, load balancing and hashing using n= log fl n processors. </title>
Reference: [GMW87] <author> O. Goldreich, S. Micali, and A. Wigderson. </author> <title> How to play any mental game or a completeness theorem for protocols with honest majority. </title> <booktitle> In Proc. 19th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 218-229, </pages> <year> 1987. </year> <editor> Goldreich et al. </editor> <title> demonstrate the use of zero-knowledge proofs on proving the completeness theorem for protocols with honest majority. </title>
Reference-contexts: The concept of zero-knowledge proof has turned out to be especially useful in complexity theory [For87, BHZ87] and cryptography <ref> [GMW87, CCD88, BOGW88, BC86] </ref>. Various notion of zero-knowledge, a classification of these notions, and several related topics appear in [Ore87, FLS90, KMO89]. Some complexity theoretic implications of systems that admit zero-knowledge proofs are discussed in [AH91, For87, GMW91].

Reference: [Gol92] <author> M. Goldwurm. </author> <title> Probabilistic estimation of the number of prefixes of a trace. </title> <journal> Theoretical Computer Science, </journal> <volume> 92 </volume> <pages> 249-268, </pages> <year> 1992. </year> <title> The author uses the result to determine the behavior of several algorithms relating to trace languages. </title>
Reference: [Gon84] <author> G.H. Gonnet. </author> <title> Determining the equivalence of expressions in random polynomial time. </title> <booktitle> In Proc. 16th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 334-341, </pages> <year> 1984. </year> <title> Hashing functions are used to determine algebraic expression equivalence with a small probability of error. The probability of error can be 119 made arbitrarily small, depending on the number of iterations of the algorithm. See [Gon86] for some related work. </title>
Reference: [Gon86] <author> G.H. Gonnet. </author> <title> New results for random determination of equivalence of expressions. </title> <editor> In B.W. Char, editor, </editor> <booktitle> ISSAC '86: Proc. Int'l. Symp. on Symbolic and Algebraic Computation, </booktitle> <pages> pages 127-131. </pages> <publisher> ACM Press, </publisher> <year> 1986. </year> <title> Some open problems in the same general area as that covered by [Gon84] are solved in this paper. </title>

Reference: [GS89] <author> S. Goldwasser and M. Sipser. </author> <title> Private coins versus public coins in interactive proof systems. </title> <booktitle> Advances in Computing Research 5: Randomness and Computation, </booktitle> <year> 1989. </year> <title> This work establishes equivalence between the notions of interactive proofs introduced in [GMR89] and [BM88]. </title> <note> (A preliminary version appeared in Proc. </note> <editor> 18th Ann. </editor> <booktitle> ACM Symp. on Theory of Computing, </booktitle> <year> 1986, </year> <pages> pp. 59-68). </pages>
Reference-contexts: The way SockSel2 is formulated above, the latter problem does not completely go away even when the coin tosses are hidden from the drawer: with probability that is exponentially 4 For a discussion of private vs. public coin tosses, see the last paragraph of Section 2.6 and <ref> [GS89] </ref>. A related concept called shared randomness, which is weaker than both private and public coin tosses, is discussed in [BDMP91]. 17 small in n, SockSel2 can return a mismatched pair of socks. <p> The objective of the verifier is to convince itself that the prover does in fact have a solution to the problem. Independent formalizations of interactive proof systems by Goldwasser, Micali and Rack-off [GMR89], and Babai and Moran [BM88, Bab85], which have been shown to be equivalent <ref> [GS89] </ref>, allow a polynomial-time verifier to toss coins and arbitrarily interact with the prover. In [GMR89], the outcomes of the coin tosses made by the verifier are hidden from the prover. In [BM88], the proof system is considered as a game played between two players called Arthur and Merlin. <p> Instead of interaction, P and V are allowed to share a short random string. While such a concept of "shared randomness" has been used by others (see, for example, <ref> [GS89] </ref>), shared random strings represent a much weaker requirement than most others (e.g., public coin tosses) used in the literature.
Reference: [Gup93] <author> R. Gupta. </author> <title> -test: Perfect hashed index test for response validation. </title> <booktitle> In Proc. 1993 IEEE Int'l. Conf. on Computer Design, </booktitle> <address> Cambridge, MA, </address> <month> Oct </month> <year> 1993. </year> <title> A scheme for checking the fidelity of test responses generated by a specially tailored sequence of test inputs is described. Randomized search is used to compute a special perfect hashing function h(x) that map the expected test outcomes to the sequence [1 . . . m]. This sequence is checked by a hardware implementation of h(x) and an up-counter. </title>
Reference-contexts: Perfect hashing has recently found application in the area of hardware design. In [RP91], perfect hash functions are used to construct a simple associative memory. Gupta <ref> [Gup93] </ref> uses it for response checking in digital circuit test. In both cases, random search is used to compute a perfect hash function for a given set of keys.
Reference: [GW86] <author> A. G. Greenberg and A. Weiss. </author> <title> A lower bound for probabilistic algorithms for finite state machines. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 33(1):88, </volume> <month> 120 August </month> <year> 1986. </year> <title> A proof that the running time cannot be better than (2 n presented. </title>

Reference: [Had86] <author> V. Hadzilacos. </author> <title> Ben-Or's randomized protocol for consensus in asynchronous systems. Course notes: </title> <institution> Computer Science 2221F, Department of Computer Science, University of Toronto, </institution> <month> October </month> <year> 1986. </year> <title> An elegant proof of the correctness of Ben-Or's [BO83] probabilistic algorithm for Byzantine agreement is presented. </title>
Reference-contexts: THEN f x i := w IF &gt; 3t messages are of the form (P, r, w) THEN f decide w decided := TRUEg g ELSE set x i to 0 or 1 with equal probability r := r + 1 g The following lemmas and theorem, due to Hadzilacos <ref> [Had86] </ref>, provide additional insight into the behavior of the algorithm, and establish its correctness. Lemma 1 If a correct process proposes value v in round r, then no other correct process will propose the value v within the same round. <p> All correct process thus propose v in round r + 1. From Lemma 2, it follows that all correct processes will decide v in round r + 1. We now have the following correctness result for Ben-Or's algorithm <ref> [Had86] </ref>. Theorem 4 Assuming that n &gt; 5t, Ben-Or's algorithm guarantees Agreement, Validity, and, with probability 1, termination. Agreement follows from Lemma 3 and validity from Lemma 2, with r = 1. Consider now termination.
Reference: [Hag91] <author> T. Hagerup. </author> <title> Constant-time parallel integer sorting. </title> <booktitle> In Proc. 23rd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 299-306, </pages> <address> New Orleans, LA, </address> <month> May </month> <year> 1991. </year> <title> Standard sorting algorithms return the elements of an array in nondecreasing order. In the chain sorting problem, the elements of a linked list are returned in nondecreasing order. This problem can be viewed as more primitive than the standard sorting problem as it does not involve list ranking computation, which is implicit in the standard problem. Hagerup presents several efficient randomized parallel algorithms for the chain sorting problem, some of which require only constant expected time. </title>
Reference: [Har87] <author> D. Harel. </author> <title> Algorithmics: </title> <booktitle> The Spirit of Computing. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1987. </year> <title> This book contains a well-written chapter on probabilistic algorithms and their complexity theory. </title>
Reference-contexts: More recently, randomized algorithms have been the subject of an ACM Turing Award Lecture [Kar86], an ACM Distinguished Dissertation [Kil90], and of a number of surveys including <ref> [Wei78, Hop81, Wel83, Kro85, MSV85, Har87, Val87, BB88, Rag90, Kar90] </ref>. <p> More recently, randomized algorithms have been the subject of an ACM Turing Award Lecture [Kar86], an ACM Distinguished Dissertation [Kil90], and of a number of surveys including [Wei78, Hop81, Wel83, Kro85, MSV85, Har87, Val87, BB88, Rag90, Kar90]. Our survey is closest in spirit to <ref> [Har87, Val87, BB88, Kar90] </ref> in its extensive coverage of both sequential and distributed randomized algorithms. 4 A distinguishing aspect of our survey is the classification we present in Section 1.1 of gen-eral techniques used in the design of randomized algorithms. 2 In Section 1.2, we then identify certain tradeoffs one may <p> This class is called P for deterministic Turing machines and NP for nondeterministic Turing machines. For probabilistic Turing machines, the analogous class is called RP (or simply R by some writers), standing for Random Polynomial time, and is characterized in <ref> [Har87] </ref> as follows: The class RP is defined as the class of decision problems for which there is a polynomial-time probabilistic Turing machine with the following property.
Reference: [Has90] <author> J. Hastad. </author> <title> Pseudo-random generators under uniform assumptions. </title> <booktitle> In Proc. 22nd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 395-404, </pages> <address> Baltimore, MD, </address> <month> May </month> <year> 1990. </year> <title> Hastad proves that given a function f that is one-way in the uniform model (i.e., cannot be inverted except on a vanishing fraction of the inputs by a probabilistic polynomial time Turing machine), it is possible to construct a pseudo random bit-generator that passes all probabilistic polynomial time statistical tests. </title> <type> 121 </type>
Reference-contexts: Using this bound, they developed algorithms that generate, in polynomial time, pseudo-random sequences of length n from a seed of length exp (c p log n). These pseudo-random sequences cannot be distinguished from truly random sequences by any logspace Turing machine. Hastad <ref> [Has90] </ref> has extended the results of [ILL89] to the uniform case. As noted in [IZ89], cryptographically secure PRGs, though theoretically elegant, have several practical problems: they depend on the unproven assumption about the one-wayness of some function, become useful only asymptotically, and are inefficient when implemented.
Reference: [Her92] <author> T. Herman. </author> <title> Self-stabilization: randomness to reduce space. </title> <journal> Distributed Com--puting, </journal> <volume> 6(2) </volume> <pages> 95-98, </pages> <year> 1992. </year> <title> Herman uses randomization to convert Dijkstra's k-state mutual exclusion protocol for unidirectional rings to a 3-state protocol. </title>
Reference: [HM87] <author> A. Hajnal and W. Maass. </author> <title> Threshold circuits of bounded depth. </title> <booktitle> In Proc. 28th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 99-109, </pages> <year> 1987. </year> <title> Polynomial size threshold circuits of bounded depth are viewed as mechanisms for parallel computations, where elements of the circuit are threshold gates (output high if the weighted sum of inputs exceeds a set threshold). Probabilistic, deterministic, imprecise and unreliable threshold circuits are considered. </title>
Reference: [Hoa74] <author> C. A. R. Hoare. </author> <title> Monitors: An operating system structuring concept. </title> <journal> Communications of the ACM, </journal> <volume> 17(2) </volume> <pages> 549-557, </pages> <month> October </month> <year> 1974. </year> <journal> Erratum in Communications of the ACM, </journal> <volume> Vol. 18, No. 2, </volume> <year> 1975. </year> <title> This paper contains one of the first solutions to the Dining Philosophers problem. A probabilistic algorithm for this problem is the subject of Section 3.1. </title>
Reference-contexts: Additionally, any algorithm that coordinates the philosophers in the above-described manner must be deadlock free|if at any time there is a hungry philosopher, then eventually some philosopher will eat; and lockout free|every hungry philosopher eventually gets to eat. Many deterministic solutions based both on shared memory <ref> [Hoa74] </ref> and message-passing communication [Hoa85] have been proposed.
Reference: [Hoa78] <author> C. A. R. Hoare. </author> <title> Communicating Sequential Processes. </title> <journal> Communications of the ACM, </journal> <volume> 21 </volume> <pages> 666-677, </pages> <month> August </month> <year> 1978. </year> <title> Hoare's novel language CSP combined nondeterminism and synchronized message passing. Since its inception, various schemes have been proposed to add output guards to the language. In Section 3.2, we discuss a probabilistic algorithm for output guards. </title>
Reference-contexts: The next algorithm we consider, CommGuard , also illustrates the power of symmetry breaking through randomization. 3.2 Communication Guard Scheduling In this section we present the randomized algorithm of Francez and Rodeh [FR80] for scheduling communication guards in a CSP-like language. In CSP <ref> [Hoa78] </ref>, processes execute asynchronously and exchange data by a "handshaking" style of communication. There are two types of communication statements or commands (to use CSP terminology) in the language: input statements of the form P ? x and output statements of the form Q ! e.
Reference: [Hoa85] <author> C. A. R. Hoare. </author> <title> Communicating Sequential Processes. </title> <booktitle> Prentice-Hall International, </booktitle> <address> U.K., </address> <year> 1985. </year> <title> Hoare's book contains an elegant message-passing solution to the Dining Philosophers problem. A probabilistic algorithm for this problem is the subject of Section 3.1. </title>
Reference-contexts: The problem, posed originally in [Dij71], is an anthropomorphized resource allocation problem, and is described in <ref> [Hoa85] </ref> essentially as follows: There once were n philosophers P 0 , P 1 , . . ., P n1 seated around a circular table in a clockwise fashion. <p> Many deterministic solutions based both on shared memory [Hoa74] and message-passing communication <ref> [Hoa85] </ref> have been proposed. However, none of these algorithms are both: (1) fully distributed , i.e., devoid of central memory or a central process with which every other process can communicate; and (2) symmetric, i.e., all processes execute the same code and all variables, local and shared, are initialized identically.
Reference: [Hop81] <author> J. E. Hopcroft. </author> <title> Recent directions in algorithmic research. </title> <editor> In P. Deussen, editor, </editor> <booktitle> Proc. Fifth Conf. on Theoretical Computer Science, </booktitle> <pages> pages 123-134. </pages> <publisher> Springer-Verlag, </publisher> <year> 1981. </year> <title> This work is an early survey of probabilistic algorithms. </title>
Reference-contexts: More recently, randomized algorithms have been the subject of an ACM Turing Award Lecture [Kar86], an ACM Distinguished Dissertation [Kil90], and of a number of surveys including <ref> [Wei78, Hop81, Wel83, Kro85, MSV85, Har87, Val87, BB88, Rag90, Kar90] </ref>.
Reference: [HS85] <author> S. Hart and M. Sharir. </author> <title> Concurrent probabilistic programs, or: How to schedule if you must. </title> <journal> SIAM Journal on Computing, </journal> <volume> 14(4) </volume> <pages> 991-1012, </pages> <month> November </month> <year> 1985. </year> <title> The authors analyze the worst-case probability of termination of a set 122 of concurrently running processes. Each process may use randomization, and fair interleaving is assumed. </title>
Reference: [HT82] <author> J. H. Halton and R. Terada. </author> <title> A fast algorithm for the Euclidean Traveling Salesman problem, optimal with probability one. </title> <journal> SIAM Journal on Computing, </journal> <volume> 11(1), </volume> <month> Feb. </month> <year> 1982. </year> <title> Halton and Terada present an algorithm for the Travelling Salesman Problem over n points, which, for appropriate choice of a function takes less than n(n) time and asymptotically converges to the minimum length tour, with probability one, as n ! 1. </title>


Reference: [IR81] <author> A. Itai and M. Rodeh. </author> <title> The lord of the ring or probabilistic methods for breaking symmetry in distributed networks. </title> <type> Technical Report RJ 3110, </type> <institution> IBM, </institution> <address> San Jose, </address> <year> 1981. </year> <title> Itai and Rodeh consider the problems of choosing a leader and determining the size of a ring of indistinguishable processors. If the size of the ring is known, efficient probabilistic algorithms exit for choosing a leader. However, there exists no probabilistic solution to the problem of determining the 123 size of a ring that can guarantee both termination and a non-zero probability of correctness. </title>
Reference-contexts: If the leader fails, a new leader must be selected from among the surviving nodes of the network using an election algorithm. In this section we examine the randomized distributed algorithm of Itai and Rodeh <ref> [IR81] </ref> for leader election. The problem of electing a leader can be stated as follows. <p> The problem of leader election is then reduced to the problem of picking the process with the smallest, or largest, name. See, for example, [CR79, Pet82]. Several authors <ref> [Ang80, IR81] </ref> have investigated the consequences of the absence of such totally ordered names on election algorithms. Angluin [Ang80] has shown that there exists no deterministic algorithm to carry out elections in a ring of identical processes. <p> Thus any potential progress toward the completion of an election is thwarted by the symmetry of the ring. Thus, we once again need to toss coins to solve the problem. In the randomized algorithm LeadElect of Itai and Rodeh <ref> [IR81] </ref>, the pseudocode of which is given below, each process is equipped with an independent random number generator. Additionally, all processes know n, the size of the ring. <p> It is interesting to note that symmetric leader election in a ring with an unknown number of processes has no deterministic nor probabilistic solution that guarantees both termination and a non-zero probability of correctness. The reader is referred to Itai and Rabin <ref> [IR81] </ref> for a proof of this claim.
Reference: [IRM81] <author> O. H. Ibarra, L. Rosier, and S. Moran. </author> <title> Probabilistic algorithms and straight-line programs for some rank decision problems. </title> <journal> In Information Processing Letters, </journal> <volume> volume 12, </volume> <pages> pages 227-232, </pages> <year> 1981. </year> <title> Given a positive integer r and a matrix A with polynomial entries (where the polynomials are represented by arbitrarily parenthesized arithmetic expressions using +, -, *, and exponentiation to a positive constant), the problem of deciding whether A has rank r is reduced in polynomial time to the zero-equivalence problem (i.e., the problem of determining whether a program always outputs 0) of straight-line programs [MT85]. </title>
Reference: [IZ89] <author> E. Impagliazzo and D. Zuckerman. </author> <title> How to recycle random bits. </title> <booktitle> In Proc. 30th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 248-253, </pages> <year> 1989. </year> <title> This paper proves that two very simple pseudo-random number generators, which are minor modifications of linear congruential generator and the simple shift register generator, are good for amplifying the correctness of probabilistic algorithms. </title>
Reference-contexts: These pseudo-random sequences cannot be distinguished from truly random sequences by any logspace Turing machine. Hastad [Has90] has extended the results of [ILL89] to the uniform case. As noted in <ref> [IZ89] </ref>, cryptographically secure PRGs, though theoretically elegant, have several practical problems: they depend on the unproven assumption about the one-wayness of some function, become useful only asymptotically, and are inefficient when implemented. <p> By contrast, the most commonly used PRGs, which typically are based on linear-congruential generators and are not cryptographically secure, do quite well in practice. Impagliazzo and Zuckerman <ref> [IZ89] </ref> give a theoretical basis to this empirical finding. They prove that two very simple pseudo-random number generators, which are minor modifications of the linear-congruential generator and the simple shift register generator, are good for amplifying 81 the correctness of probabilistic algorithms.
Reference: [Jae81] <author> G. Jaeschke. </author> <title> Reciprocal hashing: A method for generating minimal perfect hashing functions. </title> <journal> Communications of the ACM, </journal> <volume> 24(12) </volume> <pages> 829-823, </pages> <month> Dec </month> <year> 1981. </year> <title> Hash functions, for a key x in a set S of positive integers, of the form h(x) = (C=(Dx+E)) mod N are considered. Though the existence of h is guaranteed, the scheme suffers from many practical problems because of exhaustive nature of the search for h. </title>
Reference-contexts: Recently there has been a flurry of research activity in the areas of minimal and order preserving perfect hash functions <ref> [Cic80, Jae81, Cha84, LC88, CHM92, MWHC93] </ref>. Czech, Havas and Majewski [CHM92] present a probabilistic algorithm for generating order preserving, minimal perfect hash functions. This algorithm, which runs very fast in practice, uses expected linear time and requires a linear number of words to represent the hash function. <p> The first category is comprised of algorithms that rely on number theoretic methods to determine a small number of numeric parameters. The very first discussion of perfect hashing, by Sprugnoli [Spr77], falls into this category. Jaeschke's reciprocal hashing is another example from this category <ref> [Jae81] </ref>. The second category consists of perfect hash functions that use segmentation of keys. In these algorithms, the keys are first distributed into buckets by a non-perfect hash function. Perfect hash functions are then computed and used for keys in each bucket.
Reference: [JKS84] <author> J. Ja'Ja', V. K. Prasanna Kumar, and J. Simon. </author> <title> Information transfer under different sets of protocols. </title> <journal> SIAM Journal on Computing, </journal> <volume> 13(4) </volume> <pages> 840-849, </pages> <month> November </month> <year> 1984. </year> <title> This paper is a study of the communication complexity of information transfer in deterministic, random, non-deterministic and probabilistic computation models. It is widely conjectured that P R N P P P for polynomial time complexity classes. The authors prove that exponential gaps exist among the corresponding communication complexity classes. </title>
Reference: [Joh90] <author> D. S. Johnson. </author> <title> A catalog of complexity classes. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, Volume A: Algorithms and Complexity, chapter 9, </booktitle> <pages> pages 67-161. </pages> <publisher> Elsevier and The MIT Press (co-publishers), </publisher> <month> 124 </month> <year> 1990. </year> <title> Johnson presents an extensive survey of computational complexity classes. Of particular interest here is his discussion of randomized, probabilistic, and stochastic complexity classes. </title>
Reference-contexts: It is not difficult to see that we have the following hierarchies of complexity classes: P RP NP and RP <ref> [ co-RP BPP PP (but see, e.g., [Gil77, Joh90] </ref> for more in-depth discussions of randomized complexity classes). In words, the former reveals that coin tossing is at least as powerful as deterministic computation, and nondeterminism is at least as powerful as coin tossing. <p> It is not difficult to see that we have the following hierarchies of complexity classes: P RP NP and RP [ co-RP BPP PP (but see, e.g., <ref> [Gil77, Joh90] </ref> for more in-depth discussions of randomized complexity classes). In words, the former reveals that coin tossing is at least as powerful as deterministic computation, and nondeterminism is at least as powerful as coin tossing. It is conjectured that these inclusions are strict.
Reference: [JS89] <author> M. R. Jerrum and A. Sinclair. </author> <title> Approximating the permanent. </title> <journal> SIAM Journal on Computing, </journal> <volume> 18(6) </volume> <pages> 1149-1178, </pages> <year> 1989. </year> <title> Broder [Bro86] related the task of approximating the permanent of a matrix to that of uniformly generating perfect matchings in a graph. This paper gives a randomized approximation scheme for the latter problem by simulating it as a Markov chain whose states are matchings in the graph. For this scheme to be efficient the Markov chain must be rapidly mixing, i.e. converge to its stationary distribution in a short time. </title>
Reference-contexts: Sampling From a Distribution There exists a large class of algorithms that are designed around the concept of a random walk. These algorithms, which borrow heavily from techniques in statistical physics, use random walks to facilitate random sampling for approximating hard counting problems. For example, Jerrum and Sinclair <ref> [JS89] </ref> give a randomized approximation scheme for approximating the permanent of a matrix by relating the problem to that of uniformly generating perfect matchings in a graph. The matching problem is solved by a Markov chain whose states are matchings in the graph. <p> For a study of this area, and the associated background in Markov chains and techniques for proving rapid mixing | informally, a Markov chain is rapidly mixing if it converges to its stationary distribution in a short time | the reader is referred to <ref> [KL85, Bro86, DLMV88, JS89, Bro89, KLM89, DFK91, BCD + 89] </ref>. 82 Derandomization A flurry of activity has recently emerged around the algorithmic design technique of deran-domization: the act of taking an efficient randomized algorithm and removing the coin flipping to obtain an deterministic algorithm.
Reference: [JVV86] <author> M. R. Jerrum, L. G. Valiant, and V. V. Vazirani. </author> <title> Random generation of combinatorial structures from a uniform distribution. </title> <journal> Theoretical Computer Science, </journal> <volume> 43 </volume> <pages> 169-188, </pages> <year> 1986. </year> <title> This paper considers the class of problems involving the random generation of combinatorial structures from a uniform distribution. It is shown that exactly uniform generation of `efficiently verifiable' combinatorial structures is reducible to approximate counting. </title>
Reference-contexts: Babai [Bab91] presents a randomized algorithm that constructs an efficient nearly uniform random generator for finite groups in a very general setting. Other interesting work on the random generation of combinatorial structures and sample spaces can be found in <ref> [JVV86, AGHP90] </ref>. Not all algorithms based on random search contain a verification step. If the search space is teeming with elements possessing the desired property, one can even dispense with checking the property. This is particularly useful if the property in question is not easily checked.
Reference: [Kal92] <author> G. Kalai. </author> <title> A subexponential randomized simplex algorithm. </title> <booktitle> In Proc. 24th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 475-482, </pages> <address> Victoria, B.C., Canada, </address> <month> May </month> <year> 1992. </year> <title> A randomized variant of the simplex algorithm is presented that, given a linear program with d variables and n constraints, uses an expected subexponential number of arithmetic operations. </title>
Reference: [Kam89] <author> M. Kaminski. </author> <title> A note on probabilistically verifying integer and polynomial products. </title> <journal> Journal of the ACM, </journal> <volume> 36(1) </volume> <pages> 845-876, </pages> <year> 1989. </year> <title> The author describes probabilistic algorithms for verifying the product of two n-bit integers in O(n) bit operations, and for verifying the product of two polynomials of degree n over integral domains in 4n + o(n) algebraic operations. The error probability is is o( 1 n 1* ) for any * &gt; 0. </title>
Reference: [Kar86] <author> R. M. Karp. </author> <title> Combinatorics, complexity and randomness. </title> <journal> Communications of the ACM, </journal> <volume> 29(2) </volume> <pages> 98-109, </pages> <month> February </month> <year> 1986. </year> <title> This is the 1985 Turing Award Lecture. It traces the development of combinatorial optimization and com putational complexity theory. It discusses probabilistic algorithms and prob-125 abilistic analysis of approximation algorithms for NP-complete optimization problems. </title>
Reference-contexts: A resurgence of interest in randomized algorithms occurred in the early 1980's with the discovery of the important role randomization can play in distributed computing, e.g., [FR80, LR81, BO83]. More recently, randomized algorithms have been the subject of an ACM Turing Award Lecture <ref> [Kar86] </ref>, an ACM Distinguished Dissertation [Kil90], and of a number of surveys including [Wei78, Hop81, Wel83, Kro85, MSV85, Har87, Val87, BB88, Rag90, Kar90]. <p> For such problems, the goal is to prove that some simple and fast algorithm produces "good," near-optimal solutions. A classic example is Karp's divide-and-conquer algorithm for the Traveling Salesman problem in a plane <ref> [Kar86] </ref>. Bin packing is another problem for which very good approximation algorithms have been discovered. Randomized Parallel Algorithms As with sequential and distributed algorithms, the performance of parallel algorithms can be improved through the introduction of randomized behavior, i.e., coin tossing.
Reference: [Kar90] <author> R. M. Karp. </author> <title> An introduction to randomized algorithms. </title> <type> Technical Report TR-90-024, </type> <institution> Computer Science Division, University of California, Berkeley, </institution> <address> CA 94704, </address> <year> 1990. </year> <title> A recent, comprehensive survey of randomized algorithms. </title>
Reference-contexts: More recently, randomized algorithms have been the subject of an ACM Turing Award Lecture [Kar86], an ACM Distinguished Dissertation [Kil90], and of a number of surveys including <ref> [Wei78, Hop81, Wel83, Kro85, MSV85, Har87, Val87, BB88, Rag90, Kar90] </ref>. <p> More recently, randomized algorithms have been the subject of an ACM Turing Award Lecture [Kar86], an ACM Distinguished Dissertation [Kil90], and of a number of surveys including [Wei78, Hop81, Wel83, Kro85, MSV85, Har87, Val87, BB88, Rag90, Kar90]. Our survey is closest in spirit to <ref> [Har87, Val87, BB88, Kar90] </ref> in its extensive coverage of both sequential and distributed randomized algorithms. 4 A distinguishing aspect of our survey is the classification we present in Section 1.1 of gen-eral techniques used in the design of randomized algorithms. 2 In Section 1.2, we then identify certain tradeoffs one may <p> In the sequential case, we examine: 1. Sock Selection (SockSel ) 2. Primality Testing (PrimeTest ) 3. Networks without Large Hierarchies (NetHierarchy) 4. Perfect Hashing (PerfHash) 5. Universal Hashing (UnivHash) 6. Nearest Neighbors (NearNeb) 7. Graph Isomorphism Program Testing (GI-Verify) 2 Karp's recent and excellent survey <ref> [Kar90] </ref> contains a slightly different classification. 5 The distributed randomized algorithms we consider are: 1. Dining Philosophers (DinPhil ) 2. Communication Guard Scheduling (CommGuard ) 3. Leader Election in a Ring (LeadElect ) 4. Message Routing in a Network (MsgRoute) 5.


Reference: [Kel92] <author> P. Kelsen. </author> <title> On the parallel complexity of computing a maximal independent set in a hypergraph. </title> <booktitle> In Proc. 24th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 339-350, </pages> <address> Victoria, B.C., Canada, </address> <month> May </month> <year> 1992. </year> <title> A maximal independent set in a hypergraph is a subset of vertices that is maximal with respect to the property of not containing any edge of the hypergraph. Kelsen derandomizes 126 the randomized algorithm of Beame and Luby to obtain the first sublinear time deterministic algorithm for hypergraphs with edges of size O(1). </title>
Reference: [KGY89] <author> M. Kharitonov, A. V. Goldberg, and M. Yung. </author> <title> Lower bounds for pseudorandom number generators. </title> <booktitle> In Proc. 30th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 242-247, </pages> <address> Research Triangle Park, NC, </address> <month> October </month> <year> 1989. </year> <title> IEEE Computer Society Press. A pseudorandom generator is a deterministic algorithm that expands a truly random seed into a longer pseudorandom string. Such generators play an important role in applications like cryptography. The authors provide lower bounds on the computational resources needed for the generation of pseudorandom strings. </title>
Reference: [Kil88] <author> J. Kilian. </author> <title> Zero-knowledge with log-space verifiers. </title> <booktitle> In Proc. 29th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 25-34, </pages> <year> 1988. </year> <title> Interactive proof systems where the verifiers are assumed to be log-space probabilistic automata are considered. The class of languages that are amenable to zero-knowledge proofs with such verifiers is described. </title>

Reference: [Kil92] <author> J. Kilian. </author> <title> A note on efficient zero-knowledge proofs and arguments. </title> <booktitle> In Proc. 24th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 723-732, </pages> <address> Victoria, B.C., Canada, </address> <month> May </month> <year> 1992. </year> <title> The standard definition of an interactive proof requires that the verifier accept a correct proof and reject an incorrect assertion with probability at least 2 3 . This paper shows how to efficiently reduce the 127 error probability to less than 2 k , where k is some easily adjustable security parameter. </title>
Reference: [KL85] <author> R. M. Karp and M. Luby. </author> <title> Monte-Carlo algorithms for planar multiterminal reliability problems. </title> <journal> Journal of Complexity, </journal> <volume> 1 </volume> <pages> 45-64, </pages> <year> 1985. </year> <title> They present a general Monte-Carlo technique for obtaining approximate solutions of several enumeration and reliability problems including counting the number of satisfying assignments of a propositional formula given in disjunctive normal form (a #P-complete problem) and estimating the failure probability of a system. </title> <note> An earlier version appeared in Proc. </note> <editor> 24th Ann. </editor> <booktitle> IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1983, </year> <pages> pp. 56-64. </pages> <note> See also [KLM89]. </note>
Reference-contexts: For a study of this area, and the associated background in Markov chains and techniques for proving rapid mixing | informally, a Markov chain is rapidly mixing if it converges to its stationary distribution in a short time | the reader is referred to <ref> [KL85, Bro86, DLMV88, JS89, Bro89, KLM89, DFK91, BCD + 89] </ref>. 82 Derandomization A flurry of activity has recently emerged around the algorithmic design technique of deran-domization: the act of taking an efficient randomized algorithm and removing the coin flipping to obtain an deterministic algorithm.
Reference: [KL93] <author> R. Klein and A. Lingas. </author> <title> A linear-time randomized algorithm for the bounded Voronoi diagram of a simple polygon. </title> <booktitle> In Proc. Ninth Ann. ACM Symp. on Computational Geometry, </booktitle> <pages> pages 124-132, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year> <title> For a polygon P , the bounded Voronoi diagram of P is a partition of P into regions assigned to the vertices of P . Klein and Lingas present a randomized algorithm that builds the bounded Voronoi diagram of a simple polygon in linear expected time. </title>
Reference: [KLM89] <author> R. M. Karp, M. Luby, and N. </author> <title> Madras. Monte-Carlo approximation algorithms for enumeration problems. </title> <journal> Journal of Algorithms, </journal> <volume> 10 </volume> <pages> 429-448, </pages> <year> 1989. </year> <note> A companion paper of [KL85]; an earlier version appeared in Proc. </note> <editor> 24th Ann. </editor> <booktitle> IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1983, </year> <pages> pp. 56-64. </pages>
Reference-contexts: For a study of this area, and the associated background in Markov chains and techniques for proving rapid mixing | informally, a Markov chain is rapidly mixing if it converges to its stationary distribution in a short time | the reader is referred to <ref> [KL85, Bro86, DLMV88, JS89, Bro89, KLM89, DFK91, BCD + 89] </ref>. 82 Derandomization A flurry of activity has recently emerged around the algorithmic design technique of deran-domization: the act of taking an efficient randomized algorithm and removing the coin flipping to obtain an deterministic algorithm.
Reference: [KLMadH92] <author> R. M. Karp, M. Luby, and F. Meyer auf der Heide. </author> <title> Efficient PRAM simulation on a distributed memory machine. </title> <booktitle> In Proc. 24th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 318-326, </pages> <address> Victoria, B.C., Canada, </address> <month> May </month> <year> 1992. </year> <title> They present a randomized simulation of an n log log(n) log fl (n)-processor shared memory machine (PRAM) on an n-processor distributed memory machine (DMM) with optimal expected delay O(log log(n) log fl (n)) per step of simulation. </title>


Reference: [KMP77] <author> D. E. Knuth, J. H. Morris, and V. R. Pratt. </author> <title> Fast pattern matching in strings. </title> <journal> SIAM Journal on Computing, </journal> <volume> 6 </volume> <pages> 323-350, </pages> <year> 1977. </year> <title> This paper presents a fast deterministic algorithm for the problem of determining if a given pattern of m symbols occurs in a text of length n. Their well-known algorithm runs in time O(n + m), making judicious use of a prefix function, which for a given pattern encapsulates knowledge about how the pattern matches against shifts of itself. </title>
Reference-contexts: As a result, the algorithm incurs the additional overhead needed to check that detected matches are actually valid. It is worth noting that a competitive alternative to the Karp-Rabin algorithm is the deterministic Knuth-Morris-Pratt algorithm <ref> [KMP77] </ref> which runs in time O (n + m). The main novel idea behind this algorithm is the calculation of the prefix function, which for a given pattern encapsulates knowledge about how the pattern matches against shifts of itself.
Reference: [KMRZ93] <author> E. Kushilevitz, Y. Mansour, M. O. Rabin, and D. Zuckerman. </author> <title> Lower bounds for randomized mutual exclusion (extended abstract). </title> <booktitle> In Proc. 25th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 154-163, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year> <title> The authors establish a lower bound of (log log n) bits on the size of the shared variable required by randomized mutual exclusion algorithms ensuring strong fairness. Slightly weakening the fairness condition results in an exponential reduction in the size of the required shared variable. </title>
Reference: [Knu73] <author> D. E. Knuth. </author> <booktitle> The Art of Computer Programming, </booktitle> <volume> Vol. </volume> <month> 3: </month> <title> Sorting and Searching. </title> <publisher> Addison-Wesley, </publisher> <year> 1973. </year> <title> This volume is a repository of sorting and searching algorithms and their analysis. It contains a detailed and thorough treatment of hashing. </title>
Reference-contexts: This technique can be effective on problems that have algorithms with good average running time but poor worst-case running time due to some unfavorable input patterns. A well-known example of this technique is randomized quicksort <ref> [Knu73] </ref>. Quicksort performs very well if the list of numbers to be sorted has a random order to it. However, quicksort degenerates to a comparison of every number with every other number if the input is already nearly sorted. One can think of randomized quicksort as a two step procedure.
Reference: [Ko82] <author> K. Ko. </author> <title> Some observations on probabilistic algorithms and NP-Hard problems. </title> <journal> Information Processing Letters, </journal> <volume> 14(1) </volume> <pages> 39-43, </pages> <month> March </month> <year> 1982. </year> <title> Ko shows 129 that if there is a probabilistic algorithm for an NP-hard problem with a small "two-sided error", then there is a probabilistic algorithm for any NP-complete problem with a small "one-sided error". </title>
Reference: [Koz81] <author> D. Kozen. </author> <title> Semantics of probabilistic programs. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 22(3) </volume> <pages> 328-350, </pages> <year> 1981. </year> <title> A novel attempt at defining the semantics of probabilistic programs. Two equivalent semantics are presented. </title>
Reference: [Koz85] <author> D. Kozen. </author> <title> A probabilistic PDL. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 30(2) </volume> <pages> 162-178, </pages> <year> 1985. </year> <title> Kozen defines a formalism for reasoning about probabilistic programs at the propositional level. Probabilistic Propositional Dynamic Logic (PPDL), which has an arithmetic extension for each logical construct in PDL, is presented along with some decision procedure formulas and a deductive calculus. </title>
Reference: [KPRR92] <author> Z. M. Kedem, K. V. Palem, M. O. Rabin, and A. Raghunathan. </author> <title> Efficient program transformations for resilient parallel computation via randomization. </title> <booktitle> In Proc. 24th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 306-317, </pages> <address> Victoria, B.C., Canada, </address> <month> May </month> <year> 1992. </year> <title> The authors show how randomization can be used to automatically transform an arbitrary program written for an ideal parallel machine to run on a completely asynchronous machine, such that the resulting program is work and space efficient relative to the ideal program from which it was derived. </title>
Reference: [KPS85] <author> R. M. Karp, N. Pippenger, and M. Sipser. </author> <title> A time randomness tradeoff. </title> <booktitle> In AMS Conf. on Probabilistic Computational Complexity, </booktitle> <address> Durham, New Hampshire, </address> <year> 1985. </year> <title> This paper gives the first example of deterministic amplification using expander graphs. </title>
Reference-contexts: However, this method "wastes randomness" as each random bit is used only once and then discarded. It turns out that A can be deterministically amplified using fewer random bits if certain types of expander graphs can be constructed. 77 In <ref> [KPS85] </ref>, Karp, Pippenger, and Sipser present the first example of deterministic am-plification. Using expander graphs, they show how the error probability of a randomized algorithm can be reduced to n c , for some constant c. Their technique requires no additional random bits.
Reference: [KPU88] <author> D. Krizanc, D. Peleg, and E. Upfal. </author> <title> A time-randomness tradeoffs for oblivious message routing. </title> <booktitle> In Proc. 20th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 93-102, </pages> <year> 1988. </year> <title> Given the probability Q that an algorithm fails to complete its task in T steps, a lower bound on the entropy of the random source used in the algorithm is obtained. Near-optimal algorithms for oblivious packet-routing in a bounded-degree network are included (see also [PU90]). </title>

Reference: [KR88] <author> H. Karloff and P. Raghavan. </author> <title> Randomized algorithms and pseudorandom numbers. </title> <booktitle> In Proc. 20th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 310-321, </pages> <year> 1988. </year> <title> Following up on Bach's work [Bac91], this paper studies pseudo-random substitutes (with small seeds) for purely random choices in sorting, selection and oblivious message routing. An interesting result is that the linear congruence pseudo-random number generator proposed by Knuth [Knu73] can interact with some quicksort algorithms. </title>
Reference-contexts: There Bach shows that an exponentially small error can be obtained for these two problems by increasing the number of random bits by a constant factor. Karloff and Raghavan <ref> [KR88] </ref> study pseudo-random substitutes that use small seeds for purely random choices in sorting, selection and oblivious message routing. In their seminal paper, Blum and Micali [BM84] introduced the notion of cryptographically secure pseudo-random number generators.
Reference: [Kro85] <author> L. Kronsjo. </author> <title> Computational Complexity of Sequential and Parallel Algorithms. </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1985. </year> <title> Chapter 5, Section 5.3, addresses probabilistic algorithms. Rabin's algorithms for primality and the Nearest Neighbors problem are described. </title>
Reference-contexts: More recently, randomized algorithms have been the subject of an ACM Turing Award Lecture [Kar86], an ACM Distinguished Dissertation [Kil90], and of a number of surveys including <ref> [Wei78, Hop81, Wel83, Kro85, MSV85, Har87, Val87, BB88, Rag90, Kar90] </ref>.
Reference: [KRR91] <author> H. Karloff, Y. Rabani, and Y. Ravid. </author> <title> Lower bounds for randomized k-server and motion planning. </title> <booktitle> In Proc. 23rd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 278-288, </pages> <address> New Orleans, LA, </address> <month> May </month> <year> 1991. </year> <title> Lower bounds are proved on the competitive ratio of randomized algorithms for the on-line k-server problem and an on-line motion-planning problem. </title>
Reference: [KRT93] <author> M.-Y. Kao, J. H. Reif, and S. R. Tate. </author> <title> Searching in an unknown environment: An optimal randomized algorithm for the cow-path problem. </title> <booktitle> In Proc. Fourth Ann. ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 441-447, </pages> <address> Austin, TX, </address> <month> January </month> <year> 1993. </year> <title> The first randomized algorithm for the w-lane cow-path problem, a problem of searching in an unknown environment, is given. The algo 131 rithm is optimal for w = 2 and evidence is supplied that it is optimal for larger values of w. </title>
Reference: [KS92] <author> P. N. Klein and S. Sairam. </author> <title> A parallel randomized approximation scheme for shortest paths. </title> <booktitle> In Proc. 24th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 750-758, </pages> <address> Victoria, B.C., Canada, </address> <month> May </month> <year> 1992. </year> <title> A randomized algorithm is given for approximate shortest path computation in an undirected weighted graph. </title>
Reference: [KS93] <author> D. R. Karger and C. Stein. </author> <title> An ~ O(n 2 ) algorithm for minimum cuts. </title> <booktitle> In Proc. 25th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 757-765, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year> <title> A minimum cut is a set of edges of minimum weight whose removal disconnects a given graph. Karger and Stein give a strongly polynomial randomized algorithm which finds a minimum cut with high probability in O(n 2 log 3 n) time. Their algorithm can be implemented in RNC using only n 2 processors, and is thus the first efficient RNC algorithm for the min-cut problem. </title>
Reference: [KST90] <author> P. Klein, C. Stein, and E. Tardos. </author> <title> Leighton-Rao might be practical: Faster approximation algorithms for concurrent flow with uniform capacities. </title> <booktitle> In Proc. 22nd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 310-321, </pages> <address> Baltimore, MD, </address> <month> May </month> <year> 1990. </year> <title> They give an O(m 2 log m) expected-time randomized algorithm for approximately solving the concurrent multicommodity flow problem with uniform capacities. </title>
Reference: [Kur87] <author> S. A. Kurtz. </author> <title> A note on random polynomial time. </title> <journal> SIAM Journal on Computing, </journal> <volume> 16(5) </volume> <pages> 852-853, </pages> <month> October </month> <year> 1987. </year> <title> Shows that P A " P B = BP P with probability 1 for independent random sets A and B. Here, A and B are sets consisting of strings chosen at random, and P A and P B are relativized to A and B respectively. See [Gil77] for additional notation. </title>
Reference: [KUW86] <author> R. M. Karp, E. Upfal, and A. Wigderson. </author> <title> Constructing a perfect matching in Random NC. </title> <journal> Combinatorica, </journal> <volume> 6 </volume> <pages> 35-48, </pages> <year> 1986. </year> <title> Perfect matching is a fundamental problem that is not known to be solvable by an NC algorithm, i.e., a parallel algorithm running in time polynomial in log n and using a number of processors polynomial in n. This paper proves that perfect matching is in random NC and gives a fast, parallel, randomized algorithm for finding a perfect matching in a simple graph. </title> <type> 132 </type>
Reference-contexts: The beauty of the above scheme is its simplicity. In addition, it can be efficiently parallelized: the parallel implementation has the same resource requirements as those for evaluating a determinant, viz., O (log 2 n) time using O (n 3:5 ) processors <ref> [KUW86, MVV87] </ref>. This is significant as perfect matching is a fundamental problem that is not known to be in NC , the class of problems having parallel algorithms that run in polylog time while using a polynomially bounded number of processors. The randomized parallel algorithms of [KUW86, MVV87] do, however, place <p> (n 3:5 ) processors <ref> [KUW86, MVV87] </ref>. This is significant as perfect matching is a fundamental problem that is not known to be in NC , the class of problems having parallel algorithms that run in polylog time while using a polynomially bounded number of processors. The randomized parallel algorithms of [KUW86, MVV87] do, however, place perfect matching in Random NC . One can also determine the actual perfect matching in parallel; see [KUW86, MVV87] for details. Random search has also been used in algorithms on finite fields [Rab80b, Ber70]. <p> The randomized parallel algorithms of <ref> [KUW86, MVV87] </ref> do, however, place perfect matching in Random NC . One can also determine the actual perfect matching in parallel; see [KUW86, MVV87] for details. Random search has also been used in algorithms on finite fields [Rab80b, Ber70].
Reference: [KVV90] <author> R. M. Karp, U. V. Vazirani, and V. V. Vazirani. </author> <title> An optimal algorithm for on-line bipartite matching. </title> <booktitle> In Proc. 22nd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 352-358, </pages> <address> Baltimore, MD, </address> <month> May </month> <year> 1990. </year> <title> An on-line algorithm receives a sequence of requests and must respond to each request as soon as it is received. In contrast, an off-line algorithm may wait until all requests have been received before determining its responses. The authors give a simple, randomized, optimal, on-line algorithm for bipartite matching. </title>
Reference: [KW85] <author> R. M. Karp and A. Wigderson. </author> <title> A fast parallel algorithm for the maximal independent set problem. </title> <journal> Journal of the ACM, </journal> <volume> 32(4) </volume> <pages> 762-773, </pages> <year> 1985. </year> <title> This important paper showed that the maximal independent set problem for graphs can be solved in polylogarithmic time using a polynomial number of processes on a PRAM in which concurrent reads and writes are disallowed. They derive their algorithm from a randomized one using a technique that has become known as derandomization via k-wise independence. </title>
Reference-contexts: Upon turning up such a point w, the algorithm A (I; w) is now deterministic and guaranteed to find the correct solution. The catch is, however, that the sample space is generally exponential in size, rendering exhaustive search infeasible. Karp and Wigderson <ref> [KW85] </ref> have devised a technique, based on the concept of k-wise independence, that can potentially avoid searching exponentially large sample sizes. A string of bits is said to be k-wise independent if any k of the bits in the sequence are mutually independent.
Reference: [KZ88] <author> R. M. Karp and Y. Zhang. </author> <title> A randomized parallel branch and bound procedure. </title> <booktitle> In Proc. 20th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 290-300, </pages> <year> 1988. </year> <title> A general technique assuming no special communication capabilities is presented. </title>
Reference: [Lak90] <author> Y. N. Lakshman. </author> <title> On the complexity of computing a Grobner basis for the radical of a zero dimensional ideal. </title> <booktitle> In Proc. 22nd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 555-562, </pages> <address> Baltimore, MD, </address> <month> May </month> <year> 1990. </year> <title> Lakshmanan shows that if a system of polynomials f 1 , f 2 ; . . . ; f r in n variables with deg(f i ) d over the rational numbers has only finitely many affine zeros, then all the affine zeros can be determined in time polynomial in d n by a Las Vegas type randomized algorithm. </title>
Reference: [LC88] <author> T.G. Lewis and C.R. Cook. </author> <title> Hashing for dynamic and static internal tables. </title> <journal> Computer, </journal> <volume> 21 </volume> <pages> 45-56, </pages> <year> 1988. </year> <title> The authors survey the classical hashing function approach to information retrieval and show how general hashing techniques exchange speed for memory. It is a tutorial paper that covers, among other topics, dynamic and static hash tables, perfect hashing, and minimal perfect hashing. </title>
Reference-contexts: Recently there has been a flurry of research activity in the areas of minimal and order preserving perfect hash functions <ref> [Cic80, Jae81, Cha84, LC88, CHM92, MWHC93] </ref>. Czech, Havas and Majewski [CHM92] present a probabilistic algorithm for generating order preserving, minimal perfect hash functions. This algorithm, which runs very fast in practice, uses expected linear time and requires a linear number of words to represent the hash function.
Reference: [Leh27] <author> D. H. </author> <title> Lehmer. </title> <journal> Bulletin of the American Mathematical Society, </journal> <volume> 33 </volume> <pages> 327-340, </pages> <year> 1927. </year> <title> This paper presents the Lucas-Lehmer heuristic for primality testing. </title> <type> 133 </type>
Reference-contexts: Furthermore, even if a composite n possesses a witness x, i.e., it is not a Carmichael number, there is no obvious way to locate x. One can also obtain a positive identification of composite numbers using the Lucas-Lehmer heuristic <ref> [Leh27] </ref>: n is prime if and only if x n1 1 (mod n) and x n1 (mod n), for each prime factor p of n 1. In general, the prime factors of n 1 may not be known.
Reference: [Leh82] <author> D. Lehmann. </author> <title> On primality tests. </title> <journal> SIAM Journal on Computing, </journal> <volume> 11(2), </volume> <month> May </month> <year> 1982. </year> <title> Lehmann presents two algorithms for testing primality based on the extended Riemann hypothesis. The second algorithm is faster than that proposed by [SS77] as it does not involve computing the Jacobi symbol. </title>
Reference-contexts: While it is easy to verify such a proof, unfortunately, there is no known method for coming up with the proof, or demonstrating the absence thereof, in polynomial time. Other algorithms utilizing different number theoretic properties for defining witnesses for compositeness and primality have also been discovered <ref> [Rab80a, Leh82, AH87, GK86, AH88] </ref>. For example, Adleman and Huang [AH88] have devised a new algorithm that, instead of deciding primality by the inability to demonstrate witnesses to compositeness, employs a separate Monte Carlo test for primality.
Reference: [Lei92] <author> T. Leighton. </author> <title> Methods for message routing on parallel machines. </title> <booktitle> In Proc. 24th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 77-96, </pages> <address> Victoria, B.C., Canada, </address> <month> May </month> <year> 1992. </year> <title> This survey includes the topic of randomized wiring. </title>
Reference: [LFKN90] <author> C. Lund, L. Fortnow, H. Karloff, and N. Nisan. </author> <title> Algebraic methods for interactive proof systems. </title> <booktitle> In Proc. 31st Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 2-10, </pages> <year> 1990. </year> <title> The authors present a new algebraic technique for constructing IP systems and prove that every language in the polynomial time hierarchy has an interactive proof system. This is a key paper essential for proving IP = P SP ACE [Sha92b] and M IP = N EXP [BFL90]. </title>
Reference-contexts: A key result for proving IP = P SP ACE (and also, M IP = N EXP [BFL90]) is by Lund et al. <ref> [LFKN90] </ref> who presented a new algebraic technique for constructing interactive proof systems and proved that every language in the polynomial time hierarchy has an interactive proof system.
Reference: [LLM90] <author> F. T. Leighton, D. Lisinski, and B. M. Maggs. </author> <title> Empirical evaluation of randomly-wired multistage networks. </title> <booktitle> In Proc. 1990 IEEE Int'l. Conf. on Computer Design, </booktitle> <pages> pages 380-385, </pages> <year> 1990. </year> <title> This paper presents simulation results comparing the fault-tolerance, delay and other characteristics of butterflies, dilated butterflies and randomly-wired multibutterflies. Randomly-wired multibutterflies perform better by many yardsticks. </title>
Reference-contexts: A radically different approach, that of randomizing the interconnections between nodes, is also presented. This technique, when applied to multi-butterfly networks, has been shown to outperform conventional butterfly networks, particularly with respect to tolerance to node faults <ref> [Upf89, LM89, LLM90] </ref>. Message Routing on an n-Cube Valiant [Val82] proposed the first permutation routing algorithm for an n-cube. His algorithm implemented any permutation, with high probability, in O (log N ) time. <p> This is where randomization of wiring becomes an advantage. Radomized wiring is exploited in multi-butterfly networks <ref> [Upf89, LM89, LLM90] </ref>. Multi-butterflies are a generalization of both the butterfly and the dilated butterfly. A butterfly network can be considered to be built from splitters, each of which in turn consist of three blocks of nodes and the edges interconnecting them. <p> Also, in a randomized multibutterfly, the exact wiring of the network is unknown, and therefore an adversary scheduler cannot force excessive queuing delays to occur. Simulation results from Leighton, Lisinski and Maggs <ref> [LLM90] </ref> indicate that multi-butterflies may, in practice, perform better than butterflies and dilated butterflies. A survey of efficient randomized message routing algorithms for mesh connected computers, a network architecture not addressed above, is given in [Raj91b]. In the next subsection, we consider the problem of Byzantine agreement.
Reference: [LLS87] <author> D. Lichtenstein, N. Linial, and M. Saks. </author> <title> Imperfect random sources and discrete controlled processes. </title> <booktitle> In Proc. 19th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 169-177, </pages> <year> 1987. </year> <title> Imperfect sources are modeled by discrete control processes where the output string of zeros and ones has been tampered with by a controller who can specify certain bits. Several questions concerning the membership of such a string in a prespecified set L are answered. </title>
Reference-contexts: Zuckerman [Zuc91] also shows how to simulate BPP and approximation algorithms in polynomial time using the output from a ffi-source. Another notion of an imperfect source of randomness is introduced in <ref> [LLS87] </ref>, where an imperfect source is modeled by a discrete control process. 79 Pseudo-random Number Generators In the absence of a true source of randomness, randomized algorithms almost always rely on pseudo-random number generators (PRGs) as their source of random bits.
Reference: [LLW88] <author> N. Linial, L. Lovasz, and A. Wigderson. </author> <title> Rubber bands, convex embeddings, and graph connectivity. </title> <journal> Combinatorica, </journal> <volume> 8 </volume> <pages> 91-102, </pages> <year> 1988. </year> <title> Several probabilistic algorithms for connectivity computation, both of the Monte Carlo and Las Vegas variety, are given, as is a formalization of the connectivity problem in terms of embedded graphs. Efficient parallel implementations are included. (First appeared under the title "A physical interpretation of graph connectivity and its algorithmic applications" in Proc. </title> <booktitle> 27th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1986, </year> <pages> pp. </pages> <address> 39-53.). </address> <month> 134 </month>
Reference: [LM89] <author> F. T. Leighton and B. M. Maggs. </author> <title> Expanders might be practical: fast algo-rithms for routing around faults in multibutterflies. </title> <booktitle> In Proc. 30th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 384-389, </pages> <year> 1989. </year> <title> This paper contains a simpler version of Upfal's results [Upf89] and algorithms for routing on randomized multibutterflies in the presence of faults. </title>
Reference-contexts: A radically different approach, that of randomizing the interconnections between nodes, is also presented. This technique, when applied to multi-butterfly networks, has been shown to outperform conventional butterfly networks, particularly with respect to tolerance to node faults <ref> [Upf89, LM89, LLM90] </ref>. Message Routing on an n-Cube Valiant [Val82] proposed the first permutation routing algorithm for an n-cube. His algorithm implemented any permutation, with high probability, in O (log N ) time. <p> This is where randomization of wiring becomes an advantage. Radomized wiring is exploited in multi-butterfly networks <ref> [Upf89, LM89, LLM90] </ref>. Multi-butterflies are a generalization of both the butterfly and the dilated butterfly. A butterfly network can be considered to be built from splitters, each of which in turn consist of three blocks of nodes and the edges interconnecting them. <p> However, at each node, a choice of d edges is available in a multi-butterfly. Routing on multi-butterflies is efficient, as shown by Upfal's [Upf89] algorithm that implements P permutations deterministically in O (log N + P ) time. Multi-butterflies also provide protection against failures <ref> [LM89] </ref>, since, unlike the butterfly and dilated butterfly, there are edge-disjoint and node-disjoint paths between inputs and outputs. Also, in a randomized multibutterfly, the exact wiring of the network is unknown, and therefore an adversary scheduler cannot force excessive queuing delays to occur.
Reference: [LM92a] <author> F. T. Leighton and B. M. Maggs. </author> <title> Fast algorithms for routing around faults in multibutterflies and randomly-wired splitter networks. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 41(5) </volume> <pages> 578-587, </pages> <month> May </month> <year> 1992. </year> <title> This paper describes simple deterministic O(log N )-step algorithms for routing permutations of packets in multibutter-flies and randomly-wired splitter networks. The algorithms are robust against faults (even in the worst case) and are efficient from a practical point of view. </title>
Reference: [LM92b] <author> F. T. Leighton and B. M. Maggs. </author> <title> The role of randomness in the design of interconnection networks. </title> <booktitle> Information Processing, </booktitle> <address> I:291-305, </address> <year> 1992. </year> <title> A survey of recent research on randomly wired interconnection networks, which have been found to be exceptionally fault-tolerant and well-suited for both packet-routing and circuit-switching applications. </title>
Reference: [LMP + 91] <author> F. T. Leighton, F. Makedon, S. Plotkin, C. Stein, E. Tardos, and S. Tragoudas. </author> <title> Fast approximation algorithms for multicommodity flow problems. </title> <booktitle> In Proc. 23rd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 101-111, </pages> <address> New Orleans, LA, </address> <month> May </month> <year> 1991. </year> <title> The paper presents randomized algorithms for approximately solving the multicommodity flow problem. The algorithms run in polynomial time with high probability. </title>
Reference: [Lov79] <author> L. Lovasz. </author> <title> On determinants, matchings and random algorithms. </title> <editor> In L. Budach, editor, </editor> <booktitle> Fundamentals of Computing Theory. </booktitle> <address> Akademia-Verlag, Berlin, </address> <year> 1979. </year> <title> Lovasz describes a probabilistic method for determining the perfect matching in a simple graph, if one exists, using Tutte's theorem. </title>
Reference-contexts: Otherwise, b ij = x ij if i &gt; j and b ij = x ij if i &lt; j. Tutte [Tut47] proved that G has a perfect matching if and only if det (B) is not identically equal to zero. It was first observed by Lovasz <ref> [Lov79] </ref> that since det (B) is a polynomial in the x ij 's, one can test for the validity of the polynomial identity det (B) = 0 using the probabilistic technique described above.
Reference: [LP90] <author> F. T. Leighton and C. G. Plaxton. </author> <title> A (fairly) simple circuit that (usually) sorts. </title> <booktitle> In Proc. 31st Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 264-274, </pages> <year> 1990. </year> <title> A k-round tournament over n = 2 k payers which has very good sorting properties is introduced. There properties are then exploited in a sorting network and two randomized algorithms. </title> <type> 135 </type>
Reference: [LPV81] <author> G. Lev, N. Pippenger, and L. Valiant. </author> <title> A fast parallel algorithm for routing in permutation networks. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-30(2):93-100, </volume> <month> February </month> <year> 1981. </year> <title> This paper presents deterministic algorithms for routing in permutation networks. The fastest algorithms require global knowledge and (log 2 N ) parallel time. </title>
Reference-contexts: Note that the communication paths are directed. In such a network, there exist paths of length d log N log b e between any pair of nodes. However, the best deterministic routing algorithms known require O (log 2 N ) time <ref> [LPV81] </ref> in the worst case because an appropriate choice of sources and destinations can cause congestion on individual communication lines. Aleluinas [Ale82] uses randomization to overcome this input dependency. As in Valiant's algorithm, each node v chooses (with equal probability) an intermediate destination.
Reference: [LR81] <author> D. Lehmann and M. O. Rabin. </author> <title> On the advantage of free choice: A symmetric and fully distributed solution to the Dining Philosophers problem (extended abstract). </title> <booktitle> In Proc. Eighth Ann. ACM Symp. on Principles of Programming Languages, </booktitle> <pages> pages 133-138, </pages> <year> 1981. </year> <title> A classic paper in the area of randomized distributed algorithms. They show there is no deterministic, deadlock-free, truly distributed and symmetric solution to the Dining Philosophers problem, and describe a simple probabilistic alternative. </title>
Reference-contexts: The probabilistic algorithm of Solovay and Strassen [SS77, SS78], also for primality testing, is another celebrated result in the field. A resurgence of interest in randomized algorithms occurred in the early 1980's with the discovery of the important role randomization can play in distributed computing, e.g., <ref> [FR80, LR81, BO83] </ref>. More recently, randomized algorithms have been the subject of an ACM Turing Award Lecture [Kar86], an ACM Distinguished Dissertation [Kil90], and of a number of surveys including [Wei78, Hop81, Wel83, Kro85, MSV85, Har87, Val87, BB88, Rag90, Kar90]. <p> The underlying communication medium is assumed to be faultless in that messages are received intact and in the order of transmission. 3.1 The Dining Philosophers Problem We describe the randomized algorithm of Lehmann and Rabin <ref> [LR81] </ref> for the well-known Dining Philosophers problem. <p> their process id with the id of another process. 49 P 1 P 3 P 5 B B B B B fork [1] fork [2] H H H H H H H H H fork [3] fi fi fi fi fork [4] fork [5] In fact, it is shown in <ref> [LR81] </ref> that no fully distributed and symmetric deterministic algorithm for Dining Philosophers is possible. Intuitively, this is due to the existence of an adversary scheduler that can continually thwart the philosophers in their attempts to reach agreement on who is to eat next, thereby leading to deadlock. <p> One pair allows P i to inform P i+1 of its desire to eat (and vice versa), and the other pair is used to indicate which of P i and P i+1 ate last. Details can be found in <ref> [LR81] </ref>. 51 Lehmann and Rabin's randomized algorithm was one of the first for distributed comput-ing, and clearly illustrated the importance of tossing coins in a new setting|without this capability, fully distributed and symmetric algorithms may not even exist for certain problems.
Reference: [LS91] <author> D. Lapidot and A. Shamir. </author> <title> Fully parallelized multi-prover protocols for NEXP-time. </title> <booktitle> In Proc. 32nd Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 13-18, </pages> <year> 1991. </year> <title> This paper presents a one-round, zero-knowledge protocol (without cryptographic assumptions) for every language in NEXP-time. In a multi-prover protocol, several provers try to convince a polynomial-time verifier that a string X belongs in language L. Provers cannot communicate among themselves or observe communications between the verifier and other provers. The protocol ensures that if X is not in L, the probability that the verifier accepts the string as belonging to L is exponentially small. </title>
Reference: [LS92] <author> L. Lovasz and M. Simonovits. </author> <title> On the randomized complexity of volume and diameter. </title> <booktitle> In Proc. 33rd Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 482-492, </pages> <year> 1992. </year> <title> The authors present an O(n 7 log 2 n) algorithm to approximate the volume of a convex body, and an O(n 6 log n) algorithm to sample a point from the uniform distribution over a convex body. </title>
Reference: [LS93] <author> J. Lutz and W. Schmidt. </author> <title> Circuit size relative to pseudo-random oracles. </title> <journal> Theoretical Computer Science, </journal> <volume> 107 </volume> <pages> 95-120, </pages> <year> 1993. </year> <title> Assuming pseudo-random oracles, circuit-size complexity is compared with deterministic and non-deterministic complexity. The paper also shows that for every p-space random oracle A and almost every oracle A in EP SP ACE, N P A is not contained in SIZE A (2 ffn ) for any real ff &lt; 1=3, and E A is not contained in SIZE A (2 n =n). </title> <type> 136 </type>
Reference: [LSP82] <author> L. Lamport, R. Shostak, and M. Pease. </author> <title> The Byzantine Generals problem. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 4(3) </volume> <pages> 382-401, </pages> <month> July </month> <year> 1982. </year> <title> They proved that Byzantine agreement (the subject of Section 3.5) cannot be reached unless fewer than one-third of the processes are faulty. This result assumes that authentication, i.e., the crypting of messages to make them unforgeable, is not used. With unforgeable messages, they show that the problem is solvable for any n t &gt; 0, where n is the total number of processes and t is the number of faulty processes. </title>
Reference-contexts: The Byzantine Generals problem, known also as "Byzan-tine agreement," has received considerable attention in the literature, e.g., <ref> [PSL80, LSP82, Dol82, Rab83, CC85, Per85, Bra85] </ref>. This is due primarily to its fundamental relevance in distributed computation and its surprising complexity given the simplicity of the problem statement. <p> their destinations in one computation step, Pease et al. [PSL80] have shown that there exists an algorithm for Byzantine agreement only if less than one-third of the total number of processes are faulty. (The problem of Byzantine agreement among synchronous processes that are not completely connected has also been studied <ref> [LSP82] </ref> and constraints on the connectivity required for a solution have been determined.) For the asynchronous case, Fischer et al. [FLP85] proved that Byzantine agreement is impossible for deterministic processes, even if the processes are not symmetric and there is only one faulty process.
Reference: [Lut92] <author> J. Lutz. </author> <title> On independent random oracles. </title> <journal> Theoretical Computer Science, </journal> <volume> 92 </volume> <pages> 301-307, </pages> <year> 1992. </year> <title> This paper shows that for every random language A B, P (A)"P (B) = BP P , where P (A) and P (B) are the class of languages in polynomial time relativized to A and B. This improves on the results of [Kur87]. </title>
Reference: [LV92] <author> J.-H. Lin and J. S. Vitter. </author> <title> *-approximations with minimum packing constraint violation. </title> <booktitle> In Proc. 24th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 771-782, </pages> <address> Victoria, B.C., Canada, </address> <month> May </month> <year> 1992. </year> <title> Efficient randomized and deterministic algorithms are presented for transforming optimal solutions for a type of relaxed integer linear program into provably good approximate solutions for the corresponding NP-hard discrete optimization problem. </title>
Reference: [MadH85] <editor> F. Meyer auf der Heide. </editor> <title> Simulating probabilistic by determining algebraic computation trees. </title> <journal> Theoretical Computer Science, </journal> <volume> 41 </volume> <pages> 325-330, </pages> <year> 1985. </year> <title> This paper overlaps with the paper "Nondeterministic Versus Probabilistic Linear Search Algorithms," </title> <booktitle> Proc. 26th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1985, </year> <pages> pp. </pages> <month> 65-73. </month> <title> It is shown that nondeterministic algorithms are less complex than their probabilistic counterparts even when the probabilistic choices are assigned zero cost and error is allowed in all computations. The specific algorithms considered are linear search algorithms. </title>
Reference: [MadH90] <editor> F. Meyer auf der Heide. </editor> <title> Dynamic hashing strategies. </title> <booktitle> In Proc. 15th Symp. on Mathematical Foundations of Computer Science, Lecture Notes in Computer Science, </booktitle> <volume> Vol. 452, </volume> <pages> pages 76-87, </pages> <address> Banska Bystrica, Czechoslovakia, </address> <month> August </month> <year> 1990. </year> <title> Springer-Verlag. This paper contains a survey of dynamic hashing techniques. It evaluates hashing algorithms with respect to probability of collisions, bucket sizes, evaluation time, and the time needed to construct a hash function. Parallel, distributed and sequential algorithms are considered. </title> <type> 137 </type>
Reference-contexts: A considerable body of literature exists on minimal and order preserving hash functions and a complete discussion is beyond the scope of this survey. An overview of some of the results outlined above can be found in <ref> [MadH90] </ref>. Majewski, Wormald, Havas and Czech [MWHC93] have classified numerous algorithms for perfect hashing into four different broad categories. The first category is comprised of algorithms that rely on number theoretic methods to determine a small number of numeric parameters.
Reference: [MC87] <author> D. Mitra and R. A. Cieslak. </author> <title> Randomized parallel communication on an exten-sion of the Omega network. </title> <journal> Journal of the ACM, </journal> <volume> 34(4) </volume> <pages> 802-824, </pages> <year> 1987. </year> <title> This is an extension of Valiant and Aleliunas' algorithm to eliminate the need for scheduling. This algorithm also works on networks of fixed degree nodes. </title>

Reference: [Meh84a] <author> K. Mehlhorn. </author> <title> Data Structures and Algorithms 1: Sorting and Searching, </title> <booktitle> volume 1 of EATCS Monographs on Theoretical Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1984. </year> <title> Volume 1 of this three-volume series is an excellent source for searching and sorting algorithms. It contains sections on quicksort (Section II.1.3), perfect hashing (Section III.2.3)and universal hashing (Sections III.2.3). </title>
Reference-contexts: A recent overview of perfect hashing can be found in [GBY91]. Several seminal results that make perfect hashing possible were proved in [FKS82, Meh82]. The discussion in this section is based on Section 2.3 of <ref> [Meh84a] </ref>. A function h : U ! [0 . . . m 1] is called a perfect hash function for S U if 8x; y 2 S; h (x) 6= h (y) if x 6= y. <p> In this section we consider the problem of finding a perfect hash function given the values of S, m and N . The use of random search, in a suitably constructed family of functions, will be the principal probabilistic technique used in the construction of such a function. Mehlhorn <ref> [Meh84a] </ref> has shown that there exists a program of length O (n 2 =m + log log N ) that computes a perfect hash function for a given set S U . This result, however, only demonstrates the existence of such a function. <p> Clearly, b (i; k) is one more than the number of collisions at T (i) when the hash function used is h k . Using elementary counting principles and properties of modulo arithmetic one can verify the following inequality <ref> [Meh84a] </ref>: N1 X " m1 X b (i; k) 2 n m The quantity P m1 i=0 b (i; k) 2 n, for any particular value of k (and thus for any particular h k (x)), is a measure of the number of collisions. <p> Under these assumptions it can be shown that the time taken by universal hashing to perform access, insert and delete operations, or any sequence of such operations, is the same as the expected time taken by hashing with chaining when all inputs are assumed to be equally-likely <ref> [Meh84a] </ref>. In fact this result holds for any c-universal class of functions. Thus, universal hashing, with no assumptions on the input distribution, should perform as well as hashing with chaining when the best possible input distribution (i.e., completely unbiased input) is assumed. <p> Finally, the fourth category consists of algorithms that map the given n keys into a n fi n matrix and use matrix packing algorithms to compress the 2-D array into linear space <ref> [Meh84a] </ref>. All four categories of perfect hashing algorithms are rich in probabilistic methods. For examples of algorithms from each category, we refer the reader to [MWHC93], an excellent guide to a whole panoply of perfect hashing schemes that have appeared in the literature.
Reference: [Meh84b] <author> K. Mehlhorn. </author> <title> Graph Algorithms and NP-Completeness, </title> <booktitle> volume 2 of EATCS Monographs on Theoretical Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1984. </year> <title> Section IV.9.2 gives a probabilistic algorithm for graph connectivity and Section VI.8 deals, in part, with primality testing. </title>
Reference: [Meh84c] <author> K. Mehlhorn. </author> <title> Multi-dimensional searching and computational geometry, </title> <booktitle> volume 3 of EATCS Monographs on Theoretical Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1984. </year> <note> This book is the last of three volmes. Chapter 7 is devoted to multi-dimensional data structures and Chapter 8 to problems in computational geometry. </note>
Reference: [Mig80] <author> M. Mignotte. </author> <title> Tests de primalite. </title> <journal> Theoretical Computer Science, </journal> <volume> 12 </volume> <pages> 109-117, </pages> <year> 1980. </year> <title> Surveys the field of primality testing from a computational complexity perspective. In French. </title>
Reference: [Mil76] <author> G. L. Miller. </author> <title> Reimann's Hypothesis and test for primality. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 13 </volume> <pages> 300-317, </pages> <year> 1976. </year> <title> A seminal paper in the devel 138 opment of primality testing algorithms. This paper presents two algorithms for primality testing. The first one runs in O(n 1 7 ) time. The second one, which is actually a polynomial time algorithm (O(log 4 n)), assumes the Extended Reimann Hypothesis. This paper also proves a certain class of functions is computationally equivalent to factoring integers. </title> <note> (This paper first appeared in Proc. </note> <editor> Seventh Ann. </editor> <booktitle> ACM Symp. on Theory of Computing, </booktitle> <year> 1975, </year> <pages> pp. </pages> <month> 234-239.). </month>
Reference-contexts: If an attempt to place a number in either category fails, it must be prime. A variation of the above strategy was employed by G. Miller in a paper that has proven to be very useful in primality testing <ref> [Mil76] </ref>. This paper defined the basic concepts that were later used by Rabin to derive a probabilistic algorithm for primality testing. To arrive at his algorithm for primality testing, Miller divided the composite numbers as suggested above.


Reference: [MNT93] <author> Y. Mansour, N. Nisan, and P. Tiwari. </author> <title> The computational complexity of universal hashing. </title> <journal> Theoretical Computer Science, </journal> <volume> 107 </volume> <pages> 121-133, </pages> <year> 1993. </year> <title> They prove that any implementation of universal hashing from n-bit strings to m-bit strings requires a time-space tradeoff of T S = (nm). </title> <type> 139 </type>
Reference: [Mon80] <author> L. Monier. </author> <title> Evaluation and comparison of two efficient probabilistic primality testing algorithms. </title> <journal> Theoretical Computer Science, </journal> <volume> 12 </volume> <pages> 97-108, </pages> <year> 1980. </year> <title> Monier presents an interesting comparison of the Miller-Rabin [Rab76] and Solovay-Strassen [SS77] primality testing algorithms, showing that the former is always more efficient than the latter. In the process, he proves that at least 3=4 of the numbers in the set f1; 2; :::; n 1g are witnesses to the compositeness of n, for n composite. </title> <note> This strengthens the bound given in [Rab76]. </note>
Reference-contexts: In fact, Rabin [Rab76] has shown that more than half the values of x 2 f1; 2; :::; n1g satisfy (2) or (3) if n is indeed composite (see, also, [CLR90], Theorem 33.38). Monier <ref> [Mon80] </ref> has subsequently strengthened this result by showing that at least 3=4 of the x are witnesses. <p> Once again, using the properties of quadratic residues modulo n, the witnesses for compositeness are defined in such a way that they are both easily checkable and abundant. An interesting comparison of the Miller-Rabin and Solovay-Strassen primality testing algorithms is given in <ref> [Mon80] </ref>, where it is shown that the former is always more efficient than the latter.
Reference: [MOOY92] <author> A. Mayer, Y. Ofek, R. Ostrovsky, and M. Yung. </author> <title> Self-stabilizing symmetry breaking in constant-space. </title> <booktitle> In Proc. 24th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 667-678, </pages> <address> Victoria, B.C., Canada, </address> <month> May </month> <year> 1992. </year> <title> A randomized protocol is presented for the problem of self-stabilizing round-robin token management scheme on an anonymous bidirectional ring of identical processors. </title>
Reference: [Mor82] <author> S. Moran. </author> <title> On accepting density hierarchy in NP. </title> <journal> SIAM Journal on Computing, </journal> <volume> 11(2), </volume> <month> May </month> <year> 1982. </year> <title> Moran investigates a characterization of sets in NP based on accepting density of a polynomial time nondeterministic algorithm. The accepting density is defined as the ratio between the accepting computations and the total number of computations. </title>
Reference: [MR89] <author> G. L. Miller and J. H. Reif. </author> <title> Parallel tree contraction, Part 1: Fundamentals. </title> <editor> In S. Micali, editor, </editor> <booktitle> Advances in Computing Research 5: Randomness and Computation. </booktitle> <publisher> JAI Press, </publisher> <address> Greenwich, CT, </address> <year> 1989. </year> <title> They exhibit a randomized parallel algorithm for subtree isomorphism that uses O(log n) time and O(n= log n) processors. This was the first polylog parallel algorithm for the problem. See also the related paper "Parallel tree contraction and its applications," </title> <booktitle> in Proc. 26th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1985, </year> <pages> pp. </pages> <note> 478-489; and the companion paper [MR91]. </note>
Reference-contexts: n log fl n) processors on an EREW PRAM. (Note that for all practical purposes, the poly-logarithmic term log fl n can be viewed as a constant.) Other examples of fast randomized parallel algorithms include the sorting algorithm of Reischuk [Rei81], the algorithm for subtree isomorphism by Miller and Reif <ref> [MR89] </ref>, as well as the numerous algorithms described in the annotated bibliography. Miller and Reif's algorithm uses O (log n) time and O (n= log n) processors, and was the first polylog parallel 76 algorithm for the subtree isomorphism problem.
Reference: [MR91] <author> G. L. Miller and J. H. Reif. </author> <title> Parallel tree contraction, Part 2: Further Applications. </title> <journal> SIAM Journal on Computing, </journal> <volume> 20(6) </volume> <pages> 1128-1147, </pages> <month> December </month> <year> 1991. </year> <title> In this follow-up of [MR89], the authors present many applications of their "parallel tree contraction technique," including algorithms for subexpression evaluation, tree and graph isomorphism, and building cononical forms of trees and planar graphs. </title>

Reference: [MS88] <author> S. Micali and A. Shamir. </author> <title> An improvement of the Fiat-Shamir identification and signature scheme. </title> <booktitle> In Advances in Cryptology-CRYPTO 88, Lecture Notes in Computer Science, </booktitle> <volume> Vol. 403. </volume> <publisher> Springer-Verlag, </publisher> <year> 1988. </year> <title> They speed up zero-knowledge based identification and digital signature schemes of Fiat and Shamir, which require only 10 to 30 modular multiplications per party. Their improved scheme reduces the verifier's complexity to less than 2 modular multiplications and leaves the prover's complexity unchanged. </title>
Reference: [MS92] <author> B. M. Maggs and R. K. Sitaraman. </author> <title> Simple algorithms for routing on butterfly networks with bounded queues. </title> <booktitle> In Proc. 24th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 150-161, </pages> <address> Victoria, B.C., Canada, </address> <month> May </month> <year> 1992. </year> <title> The authors present a simple, but non-pure, algorithm for routing a random problem on a fully loaded N -input butterfly with bounded-size queues in O(log N ) steps, with high-probability. </title>
Reference: [MSV85] <author> F. Maffioli, M. G. Speranza, and C. Vercellis. </author> <title> Randomized algorithms. </title> <booktitle> Combinatorial Optimization|Annotated Bibliographies, </booktitle> <pages> pages 89-105, </pages> <year> 1985. </year> <title> This is a useful annotated bibliography on randomized algorithms. </title>
Reference-contexts: More recently, randomized algorithms have been the subject of an ACM Turing Award Lecture [Kar86], an ACM Distinguished Dissertation [Kil90], and of a number of surveys including <ref> [Wei78, Hop81, Wel83, Kro85, MSV85, Har87, Val87, BB88, Rag90, Kar90] </ref>.
Reference: [MSW92] <author> J. Matousek, M. Sharir, and E. Welzl. </author> <title> A subexponential bound for linear programming. </title> <booktitle> In Proc. Eighth Ann. ACM Symp. on Computational Geometry, </booktitle> <pages> pages 1-8, </pages> <address> Berlin, Germany, </address> <month> June </month> <year> 1992. </year> <title> They present a simple randomized algorithm which solves linear programs with n constants and d variables in expected O(nde 4 p d ln(n+1) ) time in the unit cost model. </title>
Reference: [MT85] <author> U. Manber and M. Tompa. </author> <title> Probabilistic, nondeterministic and alternating decision trees. </title> <journal> Journal of the ACM, </journal> <volume> 32(3) </volume> <pages> 720-732, </pages> <month> July </month> <year> 1985. </year> <title> This paper compares lower bounds on the running times of algorithms that allow probabilistic, non-deterministic and alternating control on decision trees. Decision 141 trees that allow internal randomization at the expense of a small probability of error are shown to run no faster asymptotically than ordinary decision trees for a collection of problems. </title> <note> An earlier version of this publication appeared in Proc. </note> <editor> 14th Ann. </editor> <booktitle> ACM Symp. on Theory of Computing, </booktitle> <year> 1982, </year> <pages> pp. 234-244. </pages>
Reference: [Mul] <author> K. Mulmuley. </author> <title> Computational geometry: An introduction through randomized algorithms. This book, due out in Fall 1993, presents a number of randomized algorithms for problems in computational geometry. The book is meant to serve as an introduction to computational geometry; the author chooses randomized algorithms to do the job as they are usually simpler to understand than their deterministic counterparts. The book is divided into two parts, basics and applications. Application areas considered include arrangements of hyperplanes, convex polytopes, range search, </title> <journal> and computer graphics. </journal> <note> A chapter on derandomization is also given. </note>
Reference: [Mul89] <author> K. Mulmuley. </author> <title> On obstructions in relation to a fixed view point. </title> <booktitle> In Proc. 30th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 592-597, </pages> <month> Oct </month> <year> 1989. </year> <title> Randomized algorithms for the following computational geometry problems are given: (1) construction of levels of order 1 to k in an arrangement of hyperplanes; (2) construction of Voronoi diagrams of order 1 to k, and (3) hidden surface removal for a general scene. Both (1) and (2) are solved in any dimension, and (3) allows intersection of curved surfaces. </title>
Reference: [Mul91a] <author> K. Mulmuley. </author> <title> Randomized multidimensional search trees: Dynamic sampling. </title> <booktitle> In Proc. Seventh Ann. ACM Symp. on Computational Geometry, </booktitle> <pages> pages 121-131, </pages> <address> North Conway, NH, </address> <month> June </month> <year> 1991. </year> <title> This paper develops a general technique, called dynamic sampling, that can be used to "dynamize" randomized incremental algorithms, so to allow additions as well as deletions of objects from multidimensional search trees. </title>
Reference: [Mul91b] <author> K. Mulmuley. </author> <title> Randomized multidimensional search trees: Further results in dynamic sampling. </title> <booktitle> In Proc. 32nd Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 216-227, </pages> <year> 1991. </year> <title> This paper extends the approach presented in [Mul91c] to Nearest Neighbors and other problems. </title>
Reference: [Mul91c] <author> K. Mulmuley. </author> <title> Randomized multidimensional search trees: Lazy balancing and dynamic shu*ing. </title> <booktitle> In Proc. 32nd Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 180-196, </pages> <year> 1991. </year> <title> This paper presents a general randomized 142 algorithm for problems such as the construction and management of Convex Hulls and Voronoi Diagrams. </title>
Reference: [Mul92] <author> K. Mulmuley. </author> <title> Randomized geometric algorithms and pseudo-random generators. </title> <booktitle> In Proc. 33rd Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 90-100, </pages> <year> 1992. </year> <title> This paper shows that a generalization of the familiar linear congruential pseudo-random generator that uses O(log n) bits can be substituted for the random source in many randomized incremental algorithms used in computational geometry without affecting the order of complexity of the expected running time, thereby reducing the number of truly random bits needed. </title>

Reference: [MV91] <author> Y. Matias and U. Vishkin. </author> <title> Converting high probability into nearly constant time with applications to parallel hashing. </title> <booktitle> In Proc. 23rd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 307-316, </pages> <address> New Orleans, LA, </address> <month> May </month> <year> 1991. </year> <title> Randomized parallel algorithms are given for constructing a perfect hash function in expected polylogarithmic time and for generating a random permutation in polylogarithmic time. </title>
Reference: [MVN93] <author> Y. Matias, J. S. Vitter, and W.-C. Ni. </author> <title> Dynamic generation of discrete random variables. </title> <booktitle> In Proc. Fourth Ann. ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 361-370, </pages> <address> Austin, TX, </address> <month> January </month> <year> 1993. </year> <title> Efficient randomized algorithms are given to generate a random variate distributed according to a dynamically set of weights. The base version of each algorithm generates the discrete random variate in O(log fl N ) expected time and updates a weight in O(2 log fl N ) expected 143 time in the worst case. It is shown how to reduce the update time to O(log fl N ) amortized expected time. </title>
Reference: [MVO91] <author> A. Menezes, S. Vanstone, and T. Okamoto. </author> <title> Reducing elliptic curve logarithms to logarithms in a finite field. </title> <booktitle> In Proc. 23rd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 80-89, </pages> <address> New Orleans, LA, </address> <month> May </month> <year> 1991. </year> <title> They present a probabilistic polynomial-time algorithm for the elliptic curve logarithm problem, the first subexponential-time, general-purpose algorithm for the problem. </title>
Reference: [MVV87] <author> K. Mulmuley, U. V. Vazirani, and V. V. Vazirani. </author> <title> Matching is as easy as matrix inversion. </title> <journal> Combinatorica, </journal> <volume> 7 </volume> <pages> 105-113, </pages> <year> 1987. </year> <title> An elegant parallel, randomized algorithm for finding a perfect matching in a simple graph based on Tutte's matrix is presented. The algorithm, which is made possible by a probabilistic lemma called the isolation lemma, requires inversion of a single integer matrix which can be parallelized. </title>
Reference-contexts: The beauty of the above scheme is its simplicity. In addition, it can be efficiently parallelized: the parallel implementation has the same resource requirements as those for evaluating a determinant, viz., O (log 2 n) time using O (n 3:5 ) processors <ref> [KUW86, MVV87] </ref>. This is significant as perfect matching is a fundamental problem that is not known to be in NC , the class of problems having parallel algorithms that run in polylog time while using a polynomially bounded number of processors. The randomized parallel algorithms of [KUW86, MVV87] do, however, place <p> (n 3:5 ) processors <ref> [KUW86, MVV87] </ref>. This is significant as perfect matching is a fundamental problem that is not known to be in NC , the class of problems having parallel algorithms that run in polylog time while using a polynomially bounded number of processors. The randomized parallel algorithms of [KUW86, MVV87] do, however, place perfect matching in Random NC . One can also determine the actual perfect matching in parallel; see [KUW86, MVV87] for details. Random search has also been used in algorithms on finite fields [Rab80b, Ber70]. <p> The randomized parallel algorithms of <ref> [KUW86, MVV87] </ref> do, however, place perfect matching in Random NC . One can also determine the actual perfect matching in parallel; see [KUW86, MVV87] for details. Random search has also been used in algorithms on finite fields [Rab80b, Ber70].
Reference: [MW90] <author> B. McKay and N. Wormald. </author> <title> Uniform generation of random graphs of moderate degree. </title> <journal> Journal of Algorithms, </journal> <volume> 11 </volume> <pages> 52-67, </pages> <year> 1990. </year> <title> A randomized algorithm is given for generating k-regular graphs on n vertices, uniformly at random. The expected running time of the algorithm is O(nk 3 ) for k = O(n 1 3 ). Special cases, such as bipartite graphs with given degree sequences, are considered. </title>
Reference: [MWHC93] <author> B.S. Majewski, N.C. Wormald, G. Havas, and Z.J. </author> <title> Czech. Graphs, hyper-graphs and hashing. </title> <booktitle> In Proc. 19th Int'l. Workshop on Graph-Theoretic Concepts in Computer Science (WG'93), </booktitle> <address> Utrecht, The Netherlands, </address> <month> June </month> <year> 1993. </year> <title> The authors generalize the method presented in [CHM92] by mapping the input set into a hypergraph rather than a graph. This modification allows a reduction in the size of the program, while maintaining all other features of the method. Also, the hash function generation time is reduced. </title>
Reference-contexts: Recently there has been a flurry of research activity in the areas of minimal and order preserving perfect hash functions <ref> [Cic80, Jae81, Cha84, LC88, CHM92, MWHC93] </ref>. Czech, Havas and Majewski [CHM92] present a probabilistic algorithm for generating order preserving, minimal perfect hash functions. This algorithm, which runs very fast in practice, uses expected linear time and requires a linear number of words to represent the hash function. <p> Czech, Havas and Majewski [CHM92] present a probabilistic algorithm for generating order preserving, minimal perfect hash functions. This algorithm, which runs very fast in practice, uses expected linear time and requires a linear number of words to represent the hash function. The results of [CHM92] are further extended in <ref> [MWHC93] </ref> to a family of elegant probabilistic algorithms that generate minimal perfect hash functions allowing arbitrary arrangements of keys in the hash table. The idea used is the following. Certain integer congruences that correspond to acyclic rgraphs can be solved in linear time. <p> The idea used is the following. Certain integer congruences that correspond to acyclic rgraphs can be solved in linear time. This uses a result in [ER60], which states that the majority of random sparse 2graphs are acyclic. It is extended in <ref> [MWHC93] </ref> to rgraphs, with r &gt; 2. Perfect hash functions are obtained by randomly mapping a set of keys into an acyclic rgraph. The mapping is achieved via universal hashing. <p> A considerable body of literature exists on minimal and order preserving hash functions and a complete discussion is beyond the scope of this survey. An overview of some of the results outlined above can be found in [MadH90]. Majewski, Wormald, Havas and Czech <ref> [MWHC93] </ref> have classified numerous algorithms for perfect hashing into four different broad categories. The first category is comprised of algorithms that rely on number theoretic methods to determine a small number of numeric parameters. The very first discussion of perfect hashing, by Sprugnoli [Spr77], falls into this category. <p> All four categories of perfect hashing algorithms are rich in probabilistic methods. For examples of algorithms from each category, we refer the reader to <ref> [MWHC93] </ref>, an excellent guide to a whole panoply of perfect hashing schemes that have appeared in the literature. Perfect hashing has recently found application in the area of hardware design. In [RP91], perfect hash functions are used to construct a simple associative memory.

Reference: [Nat92] <author> B. K. Natarajan. </author> <title> Probably approximate learning over classes of distributions. </title> <journal> SIAM Journal on Computing, </journal> <volume> 21(3) </volume> <pages> 438-449, </pages> <month> June </month> <year> 1992. </year> <title> Natarajan generalizes the model of probably approximate learning proposed by Valiant [Val84b]. </title>
Reference: [Nis90] <author> N. Nisan. </author> <title> Pseudorandom generators for space-bounded computations. </title> <booktitle> In Proc. 22nd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 204-212, </pages> <address> Balti-more, MD, </address> <month> may </month> <year> 1990. </year> <title> Pseudorandom generators are constructed that convert O(S log R) truly random bits to R bits that appear random to any algorithm that runs in SPACE(S). In particular, any randomized polynomial time algorithm that runs in space S can be simulated using only O(S log n) random bits. Applications are given for "deterministic amplification," the problem of reducing the probability of error of randomized algorithms. </title>
Reference: [Nis93] <author> N. Nisan. </author> <title> On read-once vs. multiple access to randomness in logspace. </title> <journal> Theoretical Computer Science, </journal> <volume> 107 </volume> <pages> 135-144, </pages> <year> 1993. </year> <title> This paper shows that every language accepted with bounded two-sided error by a read-once randomized logspace machine can be accepted with zero error by a randomized logspace machine with multiple access to the random bits. Also, the class of languages accepted with two-sided error by a randomized logspace machine with multiple access to the random bits is shown to be the class of languages that are in logspace relative to almost every oracle. </title>
Reference: [NN90] <author> J. Naor and M. Naor. </author> <title> Small-bias probability spaces: Efficient constructions and applications. </title> <booktitle> In Proc. 22nd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 213-223, </pages> <address> Baltimore, MD, </address> <month> May </month> <year> 1990. </year> <title> This paper shows an efficient construction of a small probability space on n binary random variables such that for every subset, its parity is either zero or one with "almost" equal probability. Applications are shown in problems such as the derandomization of algorithms and reducing the number of random bits required by certain randomized algorithms. </title>
Reference-contexts: This last point is particularly appealing if the randomized algorithm that gave rise to the deterministic one is of the Monte Carlo variety. The idea of derandomization can be explained as follows <ref> [NN90] </ref>. Consider any randomized algorithm A . One can associate a probability space (; P ) with A , where is the sample space and P is some probability measure corresponding to the probabilistic choices that A makes during execution.
Reference: [NS93] <author> M. Naor and L. Stockmeyer. </author> <title> What can be computed locally? In Proc. </title> <booktitle> 25th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 184-193, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year> <title> In the context of a distributed network, Naor and Stockmeyer investigate Locally Checkable Labeling (LCL) problems, where the legality of a labeling (e.g., coloring) can be checked locally; i.e., within time (or distance) independent of the size of the network. Among their results they show that 145 randomization cannot make an LCL problem local; i.e., if a problem has a local randomized algorithm then it has a local deterministic algorithm. </title>
Reference: [NY90] <author> M. Naor and M. Yung. </author> <title> Public-key cryptosystems provably secure against chosen cypher-text attack. </title> <booktitle> In Proc. 22nd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 427-437, </pages> <year> 1990. </year> <title> The authors show how to construct a public-key cryptosystem secure against chosen ciphertest attacks, given a publi-key cryptosystem secure against passive eavesdropping and a noninteractive zero-knowledge proof system in the shared string model. </title>
Reference: [NZ93] <author> N. Nisan and D. Zuckerman. </author> <title> More deterministic simulation in logspace. </title> <booktitle> In Proc. 25th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 235-244, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year> <title> It is shown that any randomized space(S) algorithm that uses only poly(S) random bits can be simulated deterministically in space(S), for S(n) log n. </title>
Reference: [Ore87] <author> Y. Oren. </author> <title> On the cunning power of cheating verifiers: Some observations about zero knowledge proofs. </title> <booktitle> In Proc. 28th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 462-471, </pages> <year> 1987. </year> <title> Oren differentiates between auxiliary-input zero-knowledge and blackbox-simulation zero-knowledge. He shows that all known zero-knowledge proofs are in the latter category. In addition, it is proved that blackbox-simulation zero-knowledge implies auxiliary-input knowledge, and that the latter corresponds to the original definition given in [GMR89]. </title>
Reference-contexts: The concept of zero-knowledge proof has turned out to be especially useful in complexity theory [For87, BHZ87] and cryptography [GMW87, CCD88, BOGW88, BC86]. Various notion of zero-knowledge, a classification of these notions, and several related topics appear in <ref> [Ore87, FLS90, KMO89] </ref>. Some complexity theoretic implications of systems that admit zero-knowledge proofs are discussed in [AH91, For87, GMW91]. Truly Zero-Knowledge and Multi-Prover Interactive Proofs Zero-knowledge proofs, in the traditional sense, reveal one bit of information to the verifier, viz. w 2 L or w 62 L.
Reference: [Pac87] <author> J. Pachl. </author> <title> A lower bound for probabilistic distributed algorithms. </title> <journal> Journal of Algorithms, </journal> <volume> 8(1) </volume> <pages> 53-65, </pages> <year> 1987. </year> <title> The minimum number of messages required to find the extremal value of node ids in an asynchronous network deterministically is fi(n log n). This paper shows that this bound holds even for probabilistic algorithms. </title>
Reference: [Paz71] <author> A. Paz. </author> <title> Introduction to Probabilistic Automata. </title> <publisher> Academic Press, </publisher> <year> 1971. </year> <title> Paz develops a theory of equivalence among probabilistic automata. </title>
Reference-contexts: Theory of Probabilistic Automata Just as there is a complexity theory of probabilistic algorithms which parallels the complexity theory of deterministic algorithms, there is a theory of probabilistic automata, e.g., <ref> [Rab63, Sal69, Paz71] </ref>, which parallels the classical theory of nondeterministic automata. A seminal paper on probabilistic automata is [Rab63], where Rabin explored finite state probabilistic automata. He defined the notion of a language accepted by a probabilistic automaton relative to a cutpoint probability .

Reference: [Pel92] <author> M. Pellegrini. </author> <title> Incidence and nearest neighbor problems for lines in 3-space. </title> <booktitle> In Proc. Eighth Ann. ACM Symp. on Computational Geometry, </booktitle> <pages> pages 130-137, </pages> <address> Berlin, Germany, </address> <month> June </month> <year> 1992. </year> <title> Given a set of n lines in 3-space, this paper demonstrates a randomized algorithm that finds the shortest vertical segment between any pair of lines in randomized expected time O(n 8=5+* ) for every * &gt; 0. </title>
Reference: [Pel93] <author> M. Pellegrini. </author> <title> On line missing polyhedral sets in 3-space (extended abstract). </title> <booktitle> In Proc. Ninth Ann. ACM Symp. on Computational Geometry, </booktitle> <pages> pages 19-28, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year> <title> Pellegrini gives an O(n 1:5+* ) randomized expected time algorithm that tests the separation property: does there exist a direction v along which a set of n red lines can be translated away from a set of n blue lines without collisions? </title>
Reference: [Per85] <author> K. Perry. </author> <title> Randomized Byzantine agreement. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> SE-11(6):539-546, </volume> <month> June </month> <year> 1985. </year> <title> Perry presents randomized algorithms for Byzantine agreement that, like the algorithm of Rabin [Rab83], terminate in an expected number of rounds which is a small constant independent of n and t. As usual, n is the total number of processes and t is the number of faulty processes. However, Perry's algorithm can tolerate a greater number of faulty processes. He requires only that n 6t + 1 in the asynchronous case and n 3t + 1 in the synchronous case. </title>
Reference-contexts: The Byzantine Generals problem, known also as "Byzan-tine agreement," has received considerable attention in the literature, e.g., <ref> [PSL80, LSP82, Dol82, Rab83, CC85, Per85, Bra85] </ref>. This is due primarily to its fundamental relevance in distributed computation and its surprising complexity given the simplicity of the problem statement. <p> Ben-Or's algorithm, along with Rabin's [Rab83], was one of the first for reaching asynchronous Byzantine agreement, and it remains the simplest. Since then a number of more elaborate, in terms of efficiency or fault-resiliency, randomized algorithms for the problem have been developed, including <ref> [CC85, Per85, Bra85] </ref> (see also [CD89]). This concludes our survey of distributed randomized algorithms.
Reference: [Pet82] <author> G. L. Peterson. </author> <title> An O(n log n) unidirectional algorithm for the circular extrema problem. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 4(4) </volume> <pages> 758-762, </pages> <month> October </month> <year> 1982. </year> <title> Peterson presents a deterministic distributed algorithm for finding the largest of a set of n uniquely numbered processes in a ring. The algorithm requires O(n log n) messages in the worst case, and is unidirectional. The number of processes is not initially known. </title> <type> 147 </type>
Reference-contexts: The problem of leader election is then reduced to the problem of picking the process with the smallest, or largest, name. See, for example, <ref> [CR79, Pet82] </ref>. Several authors [Ang80, IR81] have investigated the consequences of the absence of such totally ordered names on election algorithms. Angluin [Ang80] has shown that there exists no deterministic algorithm to carry out elections in a ring of identical processes.
Reference: [Pit89] <author> L. Pitt. </author> <title> Probabilistic inductive inference. </title> <journal> Journal of the ACM, </journal> <volume> 36(2):383--433, </volume> <year> 1989. </year> <title> Inductive inference machines construct total recursive functions (x) given examples of the input and output of . Probabilistic inductive inference machines are permitted coin tosses while constructing , and are only required to construct with probability p, 0 &lt; p &lt; 1. This paper shows a discrete hierarchy of inferability parameterized by p, for p 1=2. Any machine that can be constructed by probabilistic inference with p &gt; 1=2 can also be constructed deterministically. </title>
Reference: [Pra75] <author> V. R. Pratt. </author> <title> Every prime has a succinct certificate. </title> <journal> SIAM Journal on Computing, </journal> <volume> 4(3) </volume> <pages> 214-220, </pages> <year> 1975. </year> <title> This paper proves, using the Lucas-Lehmer heuristic for testing primeness, that just like composite numbers, the primeness of a prime number n can be demonstrated by an O(log n) long proof. </title>
Reference-contexts: How can one demonstrate that a number n is prime? Certainly it can be done by showing all possible trial divisions, but that is not an efficient proof as it is exponentially long in the length of n. It was shown by Pratt <ref> [Pra75] </ref>, using the Lucas-Lehmer heuristic for primality testing, that one can give a succinct proof for primeness of a number n in O (log n) lines.
Reference: [PS83] <author> R. Paturi and J. Simon. </author> <title> Lower bounds on the time of probabilistic on-line simulations. </title> <booktitle> In Proc. 24th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 343-350, </pages> <year> 1983. </year> <title> They show that coin tossing cannot compensate for inadequate memory access. </title>
Reference: [PSL80] <author> M. Pease, R. Shostak, and L. Lamport. </author> <title> Reaching agreement in the presence of faults. </title> <journal> Journal of the ACM, </journal> <volume> 27(2) </volume> <pages> 228-234, </pages> <year> 1980. </year> <title> This paper is similar to their 1982 publication [LSP82], but contains a rigorous proof of the impossibility of Byzantine agreement for the case n = 3, t = 1. As usual, n is the total number of processes and t is the number of faulty processes. </title>
Reference-contexts: The Byzantine Generals problem, known also as "Byzan-tine agreement," has received considerable attention in the literature, e.g., <ref> [PSL80, LSP82, Dol82, Rab83, CC85, Per85, Bra85] </ref>. This is due primarily to its fundamental relevance in distributed computation and its surprising complexity given the simplicity of the problem statement. <p> The Byzantine Generals problem translates to one of consensus-building among a set of n 68 completely connected processes, some of which may be faulty. In the synchronous case, where messages are delivered to their destinations in one computation step, Pease et al. <ref> [PSL80] </ref> have shown that there exists an algorithm for Byzantine agreement only if less than one-third of the total number of processes are faulty. (The problem of Byzantine agreement among synchronous processes that are not completely connected has also been studied [LSP82] and constraints on the connectivity required for a solution
Reference: [PU90] <author> D. Peleg and E. Upfal. </author> <title> A time-randomness tradeoffs for oblivious routing. </title> <journal> SIAM Journal on Computing, </journal> <volume> 19 </volume> <pages> 256-266, </pages> <year> 1990. </year> <note> This is a companion paper of [KPU88]. </note>

Reference: [PZ86] <author> A. Pnueli and L. Zuck. </author> <title> Verification of multiprocess probabilistic protocols. </title> <journal> Distributed Computing, </journal> <volume> 1 </volume> <pages> 53-72, </pages> <year> 1986. </year> <title> They present a temporal logic for proving liveness properties of probabilistic concurrent programs based on the notion of "extreme fairness". </title>
Reference: [Rab63] <author> M. O. Rabin. </author> <title> Probabilistic automata. </title> <journal> Information and Control, </journal> <volume> 6 </volume> <pages> 230-245, </pages> <year> 1963. </year> <title> This is a seminal paper on the theory of probabilistic automata. Rabin defined the notion of a language being accepted by a probabilistic automaton relative to a cutpoint lambda. One of his key results was to show that there exist finite state probabilistic automata that define non-regular languages. </title>
Reference-contexts: Theory of Probabilistic Automata Just as there is a complexity theory of probabilistic algorithms which parallels the complexity theory of deterministic algorithms, there is a theory of probabilistic automata, e.g., <ref> [Rab63, Sal69, Paz71] </ref>, which parallels the classical theory of nondeterministic automata. A seminal paper on probabilistic automata is [Rab63], where Rabin explored finite state probabilistic automata. He defined the notion of a language accepted by a probabilistic automaton relative to a cutpoint probability . <p> Theory of Probabilistic Automata Just as there is a complexity theory of probabilistic algorithms which parallels the complexity theory of deterministic algorithms, there is a theory of probabilistic automata, e.g., [Rab63, Sal69, Paz71], which parallels the classical theory of nondeterministic automata. A seminal paper on probabilistic automata is <ref> [Rab63] </ref>, where Rabin explored finite state probabilistic automata. He defined the notion of a language accepted by a probabilistic automaton relative to a cutpoint probability .
Reference: [Rab76] <author> M. O. Rabin. </author> <title> Probabilistic algorithms. </title> <editor> In J.F. Traub, editor, </editor> <booktitle> Algorithms and Complexity: New Directions and Recent Results, </booktitle> <pages> pages 21-39. </pages> <publisher> Academic Press, </publisher> <year> 1976. </year> <title> This classic paper on probabilistic algorithms features algorithms for primality testing and nearest neighbors. </title>
Reference-contexts: An algorithm not having any coin tossing statements is said to be deterministic. Randomized algorithms entered the computer science spotlight with the publication of Michael Rabin's seminal paper "Probabilistic Algorithms" <ref> [Rab76] </ref>, although their existence can be traced back much further [Sha92a]. Rabin's paper presented surprisingly efficient randomized algorithms for two well-known problems, Nearest Neighbors|a problem in computational geometry, and Primality Testing|the problem of determining whether a given integer is divisible by any number other than itself and one. <p> For example, the Primality Testing algorithm of <ref> [Rab76] </ref>, which uses a technique we call "random search", outperforms all known deterministic algorithms for the problem, yet cannot, in general, guarantee absolutely that the answer produced is correct. <p> Monte Carlo integration becomes attractive if the function fails to be regular which is often the case for multidimensional integrals [Rub81]. A more involved use of random sampling will be seen in Rabin's <ref> [Rab76] </ref> algorithm for the nearest neighbors problem (NearNeb). <p> A key observation which makes randomized testing for primality feasible is that there is an abundance of witnesses for compositeness. The probability that a number is composite, and conditions (2) and (3) are not satisfied is very small. In fact, Rabin <ref> [Rab76] </ref> has shown that more than half the values of x 2 f1; 2; :::; n1g satisfy (2) or (3) if n is indeed composite (see, also, [CLR90], Theorem 33.38). Monier [Mon80] has subsequently strengthened this result by showing that at least 3=4 of the x are witnesses. <p> The Nearest Neighbors problem considered next illustrates the technique of random sampling, which is at the heart of many randomized algorithms in computational geometry. 2.5 The Nearest Neighbors Problem We describe Rabin's probabilistic algorithm for the Nearest Neighbors problem, one of two probabilistic algorithms Rabin presented in his seminal paper <ref> [Rab76] </ref>. The other, a probabilistic algorithm for primality testing, was the topic of Section 2.2. Consider a finite set S = fx 1 ; :::; x n g of points in l-dimensional space, i.e., S &lt; l , where &lt; denotes the reals. <p> The proof that this lattice-based technique for decomposing S works as advertised, is given in Lemma 1 of <ref> [Rab76] </ref>. An example of this proof, also from [Rab76], is shown in distance between them. Doubling ffi encloses the pair in a single square. <p> The proof that this lattice-based technique for decomposing S works as advertised, is given in Lemma 1 of <ref> [Rab76] </ref>. An example of this proof, also from [Rab76], is shown in distance between them. Doubling ffi encloses the pair in a single square. This argument generalizes to any dimensional space. 39 We now know that ffi, the initial mesh size, should be chosen large enough so that nearest neighbors at worst fall in adjacent squares. <p> (S 1 ), where S 1 is a randomly chosen subset of S such that jS 1 j = n 2=3 , then with a very high probability 6 the measure of the decomposition induced by the lattice of mesh-size ffi will be O (n) (Theorems 6 and 7 of <ref> [Rab76] </ref>). Intuitively, this random sample S 1 of S is large enough in size so that a grid of mesh-size ffi will contain a small number of points within any lattice square.
Reference: [Rab80a] <author> M. O. Rabin. </author> <title> A probabilistic algorithm for testing primality. </title> <journal> Journal of Number Theory, </journal> <volume> 12, </volume> <year> 1980. </year> <title> Rabin's paper introduces another celebrated algorithm for fast, randomized primality testing. This paper is based on a different number theoretic property than that used by Solovay and Strassen [SS77]. </title>
Reference-contexts: While it is easy to verify such a proof, unfortunately, there is no known method for coming up with the proof, or demonstrating the absence thereof, in polynomial time. Other algorithms utilizing different number theoretic properties for defining witnesses for compositeness and primality have also been discovered <ref> [Rab80a, Leh82, AH87, GK86, AH88] </ref>. For example, Adleman and Huang [AH88] have devised a new algorithm that, instead of deciding primality by the inability to demonstrate witnesses to compositeness, employs a separate Monte Carlo test for primality.
Reference: [Rab80b] <author> M. O. Rabin. </author> <title> Probabilistic algorithms in finite fields. </title> <journal> SIAM Journal on Computing, </journal> <volume> 9(2) </volume> <pages> 273-280, </pages> <month> May </month> <year> 1980. </year> <title> Rabin presents probabilistic algorithms for finding an irreducible polynomial of degree n over a finite field, the roots of a polynomial, and the irreducible factors of a polynomial. </title>
Reference-contexts: The randomized parallel algorithms of [KUW86, MVV87] do, however, place perfect matching in Random NC . One can also determine the actual perfect matching in parallel; see [KUW86, MVV87] for details. Random search has also been used in algorithms on finite fields <ref> [Rab80b, Ber70] </ref>. It can be shown (e.g., see [Ber70]) that one in about every n polynomials in Z p [x] (the field of residues (mod p), where p is prime) is an irreducible monic polynomial of degree n. This result has been reproved, using a different technique, in [Rab80b]. <p> It can be shown (e.g., see [Ber70]) that one in about every n polynomials in Z p [x] (the field of residues (mod p), where p is prime) is an irreducible monic polynomial of degree n. This result has been reproved, using a different technique, in <ref> [Rab80b] </ref>. Thus a plausible algorithm for finding an irreducible polynomial is to repeatedly pick one at random and test it for irreducibility. <p> Since it takes O (n 2 (log n) 2 log log n log p) steps to test for irreducibility, one can find an irreducible polynomial in a reasonable amount of time. Algorithms for finding 9 roots and irreducible factors based on random search are also given in <ref> [Rab80b] </ref>. There is a long history in number theory of using random search.
Reference: [Rab83] <author> M. O. Rabin. </author> <title> Randomized Byzantine Generals. </title> <booktitle> In Proc. 24th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 403-409, </pages> <year> 1983. </year> <title> Rabin presents a randomized algorithm for asynchronous Byzantine agreement that terminates in a constant expected number of rounds. Cryptography is used to simulate a trusted dealer that distributes random coin tosses before the start of the algorithm. Rabin's algorithm works only if less than one-tenth of all processes are faulty. </title>
Reference-contexts: The Byzantine Generals problem, known also as "Byzan-tine agreement," has received considerable attention in the literature, e.g., <ref> [PSL80, LSP82, Dol82, Rab83, CC85, Per85, Bra85] </ref>. This is due primarily to its fundamental relevance in distributed computation and its surprising complexity given the simplicity of the problem statement. <p> Thus, assuming that faulty processes do not send more than O (n) messages each per round, the total number of messages transmitted per round is O (n 2 ). Ben-Or's algorithm, along with Rabin's <ref> [Rab83] </ref>, was one of the first for reaching asynchronous Byzantine agreement, and it remains the simplest. Since then a number of more elaborate, in terms of efficiency or fault-resiliency, randomized algorithms for the problem have been developed, including [CC85, Per85, Bra85] (see also [CD89]).

Reference: [Rag88] <author> P. Raghavan. </author> <title> Probabilistic construction of deterministic algorithms: Approximating packing integer problems. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 37 </volume> <pages> 130-143, </pages> <year> 1988. </year> <title> Based on the derandomization technique of conditional probabilities, Raghavan develops a methodology for converting the probabilistic existence proof of a near-optimum integer solution to an integer program into a deterministic approximation algorithm. </title>
Reference-contexts: Applications of the method of conditional probabilities to derandomization include problems in combinatorial optimization <ref> [Rag88] </ref> and parallel algorithms [MNN89]. 83 On the Future of Randomized Algorithms These days, randomized algorithms are appearing in the literature almost as often as conventional algorithms.
Reference: [Rag90] <author> P. Raghavan. </author> <title> Lecture notes on randomized algorithms. </title> <type> Research Report RC 15340 (#68237), </type> <institution> IBM T.J. Watson Research Center, </institution> <month> January </month> <year> 1990. </year> <title> This Research Report consists of lecture notes from a course taught by the author. These notes give a thorough introduction to many randomized algorithms in computational geometry, graph theory, VLSI, and networks. The basic mathematical background essential for understanding these algorithms is presented in detail. </title>
Reference-contexts: More recently, randomized algorithms have been the subject of an ACM Turing Award Lecture [Kar86], an ACM Distinguished Dissertation [Kil90], and of a number of surveys including <ref> [Wei78, Hop81, Wel83, Kro85, MSV85, Har87, Val87, BB88, Rag90, Kar90] </ref>.
Reference: [Raj91a] <author> S. Rajasekaran. </author> <title> k k routing, k k sorting, and cut through routing on the mesh. </title> <type> Technical Report MS-CIS-91-93, </type> <institution> Dept. of Computer and Information Sciences, Univ. of Pennsylvania, </institution> <address> Philadelphia, PA, </address> <year> 1991. </year> <title> This paper presents randomized algorithms for k k routing, k k sorting, and cut through routing on mesh connected computers. The time bounds of these algorithms improve upon those of the best known algorithms prior to this paper. </title>
Reference: [Raj91b] <author> S. Rajasekaran. </author> <title> Randomized algorithms for packet routing on the mesh. </title> <type> Technical Report MS-CIS-91-92, </type> <institution> Dept. of Computer and Information Sciences, Univ. of Pennsylvania, </institution> <address> Philadelphia, PA, </address> <year> 1991. </year> <title> Efficient randomized algorithms for sore and forward, multipacket, and cut through routing of packets on a mesh connected computer are surveyed. The expected running times and queueing complexity of these algorithms are analyzed. </title>
Reference-contexts: Simulation results from Leighton, Lisinski and Maggs [LLM90] indicate that multi-butterflies may, in practice, perform better than butterflies and dilated butterflies. A survey of efficient randomized message routing algorithms for mesh connected computers, a network architecture not addressed above, is given in <ref> [Raj91b] </ref>. In the next subsection, we consider the problem of Byzantine agreement.
Reference: [Ram93] <author> H. Ramesh. </author> <title> On traversing layered graphs on-line. </title> <booktitle> In Proc. Fourth Ann. ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 412-421, </pages> <address> Austin, TX, </address> <month> January 150 </month> <year> 1993. </year> <title> A layered graph is a connected weighted graph whose vertices are par-titioned into sets (i.e., layers) L 0 , L 1 , L 2 ; . . ., and all edges connect vetices in consecutive layers. Ramesh presents a randomized on-line algorithm for traversing width-w layered graphs with a competitive ratio of O(w 15 ). His algorithm represents the first polynomially competitive randomized algorithm for layered graph traversal. </title>
Reference: [Rei80] <author> J. H. Reif. </author> <title> Logics for probabilistic programs. </title> <booktitle> In Proc. 12th Ann. ACM Symp. on Theory of Computing, </booktitle> <year> 1980. </year> <title> Reif presents yet another attempt at a formal logic, PROB-DL, for probabilistic programs. </title>
Reference: [Rei81] <author> R. Reischuk. </author> <title> A fast probabilistic parallel sorting algorithm. </title> <booktitle> In Proc. 22nd Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 212-219, </pages> <year> 1981. </year> <title> Reischuk considers the problems of selecting k smallest elements out of a set of n keys, and sorting the n elements using n processors in parallel. He shows that the former can be done in constant time with probability 1 2 cn 1 8 and the later in O(log n) time. This achieves the information theoretic lower-bound in terms of processor-time product as well as the optimal speed-up attainable using n processors. </title>
Reference-contexts: problem that runs in O (n=p) time using p n=(log n log fl n) processors on an EREW PRAM. (Note that for all practical purposes, the poly-logarithmic term log fl n can be viewed as a constant.) Other examples of fast randomized parallel algorithms include the sorting algorithm of Reischuk <ref> [Rei81] </ref>, the algorithm for subtree isomorphism by Miller and Reif [MR89], as well as the numerous algorithms described in the annotated bibliography. Miller and Reif's algorithm uses O (log n) time and O (n= log n) processors, and was the first polylog parallel 76 algorithm for the subtree isomorphism problem.
Reference: [Rei85a] <author> J. H. Reif. </author> <title> Optimal parallel algorithms for integer sorting and graph connectivity. </title> <booktitle> In Proc. 26th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1985. </year> <title> This paper contains some results on the use of randomization in parallel algorithms. </title>

Reference: [RP91] <author> M. V. Ramakrishna and G. A. Portice. </author> <title> Perfect hashing functions for hardware applications. </title> <booktitle> In Proc. Seventh Int'l. Conf. on Data Engineering, </booktitle> <month> April </month> <year> 1991. </year> <title> A 151 hardware scheme for constructing an associative memory using a perfect hash function is described. A simple trail and error scheme is used to find a perfect hash function. </title>
Reference-contexts: For examples of algorithms from each category, we refer the reader to [MWHC93], an excellent guide to a whole panoply of perfect hashing schemes that have appeared in the literature. Perfect hashing has recently found application in the area of hardware design. In <ref> [RP91] </ref>, perfect hash functions are used to construct a simple associative memory. Gupta [Gup93] uses it for response checking in digital circuit test. In both cases, random search is used to compute a perfect hash function for a given set of keys.
Reference: [RR89] <author> S. Rajasekaran and J. H. Reif. </author> <title> Optimal and sublogarithmic time randomized parallel sorting algorithm. </title> <journal> SIAM Journal on Computing, </journal> <volume> 18(3) </volume> <pages> 594-607, </pages> <month> June </month> <year> 1989. </year> <title> This paper presents an optimal, randomized, parallel algorithm for sorting n numbers in the range [1 . . . n] on a parallel random access machine that allows both concurrent reads and concurrent writes of a global memory. </title>
Reference: [RS82] <author> J. H. Reif and P. G. Spirakis. </author> <title> Real time resource allocation in distributed systems. </title> <booktitle> In Proc. First Ann. ACM Symp. on Principles of Distributed Computing, </booktitle> <pages> pages 84-94, </pages> <year> 1982. </year> <title> This paper considers a resource allocation problem in distributed systems and provides real-time solutions in the form of two probabilistic algorithms. </title>
Reference: [RS84] <author> J. H. Reif and P. G. Spirakis. </author> <title> Real time synchronization of interprocess communication. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 6 </volume> <pages> 215-238, </pages> <year> 1984. </year> <title> They present probabilistic distributed algorithms for the guard-scheduling problem (Section 3.2) that guarantee real-time response. A preliminary version of this paper appeared as "Distributed Algorithms for Synchronizing Interprocess Communication in Real Time," </title> <booktitle> in Proc. 13th Ann. ACM Symp. on Theory of Computing, </booktitle> <year> 1981. </year>
Reference-contexts: We now describe the fully distributed and symmetric randomized algorithm of Francez having one alternative. 53 and Rodeh [FR80]. (Other probabilistic algorithms for guard scheduling, which have "real time response", appear in <ref> [RS84] </ref>.) The algorithm is given here as the iterative procedure CommGuard, which a process P invokes upon reaching a guarded command in order to schedule itself in a communication.
Reference: [RS89] <author> J. H. Reif and S. Sen. </author> <title> Polling: A new random sampling technique for computational geometry. </title> <booktitle> In Proc. 21st Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 394-404, </pages> <year> 1989. </year> <title> A randomized sampling technique called polling is introduced. For the first time, this technique allows the calculation of `high likelihood bounds' rather than simply expected running time, in computational geometric randomized algorithms. The technique is illustrated using an algorithm for the intersection of half-spaces in three dimensions. </title>
Reference: [RS92] <author> J. H. Reif and S. Sen. </author> <title> Optimal parallel randomized algorithms for three-dimensional convex hulls and related problems. </title> <journal> SIAM Journal on Computing, </journal> <volume> 21(3) </volume> <pages> 466-485, </pages> <month> June </month> <year> 1992. </year> <title> An optimal parallel randomized algorithm for computing the intersection of half-spaces in 3-D is given. The algorithm provides efficient solution techniques for convex hulls in 3-D and Vornoi diagrams of point sites on a plane. An earlier version of the paper appeared as "Polling: 152 a new random sampling technique for computational geometry" in Proc. </title> <booktitle> 21st Ann. ACM Symp. on Theory of Computing, </booktitle> <year> 1989, </year> <pages> pp. 394-404. </pages>
Reference: [RSA78] <author> R. L. Rivest, A. Shamir, and L. Adleman. </author> <title> A method for obtaining digital signatures and public key cryptosystems. </title> <journal> Communications of the ACM, </journal> <volume> 21(2):120, </volume> <month> February </month> <year> 1978. </year> <title> The basics of trap-door functions and the famous RSA public key cryptosystem are presented in this paper. </title>
Reference-contexts: if n divides 2 n 2, 18 are wrong results which exemplify the mysteries enshrined in prime numbers. (For the latter, consider, for example, n = 341.) Of late extremely large prime numbers are in great demand because of their use in defining trap-door functions for public key cryptography systems <ref> [RSA78, Sch84, GM84, Smi83] </ref>. For example, in the Rivest-Shamir-Adleman (or RSA) cryptosystem [RSA78] the keys are 200-digit numbers. An encryption key is the product of two secret primes, having approximately 100 digits each, which are known only to the creator of the key. <p> For example, in the Rivest-Shamir-Adleman (or RSA) cryptosystem <ref> [RSA78] </ref> the keys are 200-digit numbers. An encryption key is the product of two secret primes, having approximately 100 digits each, which are known only to the creator of the key. The corresponding decryption key is computed from the same two prime numbers using a publicly known algorithm.
Reference: [Rub81] <author> R. Y. Rubinstein. </author> <title> Simulation and the Monte Carlo Method. </title> <publisher> John Wiley & Sons, </publisher> <year> 1981. </year> <title> This work is an in-depth look at the use of random sampling (the Monte Carlo method) in the context of simulation and numerical integration. </title>
Reference-contexts: Monte Carlo integration becomes attractive if the function fails to be regular which is often the case for multidimensional integrals <ref> [Rub81] </ref>. A more involved use of random sampling will be seen in Rabin's [Rab76] algorithm for the nearest neighbors problem (NearNeb).
Reference: [RV89] <author> M. Rabin and Vazirani V. </author> <title> Maximum matchings in general graphs through randomization. </title> <journal> Journal of Algorithms, </journal> <volume> 10 </volume> <pages> 557-567, </pages> <year> 1989. </year> <title> This paper presents a conceptually simple algorithm for maximal matching in a graph of n nodes with complexity O(M (n)n log log n), where M (n) is the number of operations needed to multiply two n fi n matrices. </title>
Reference: [RW89] <author> R. Raz and A. Wigderson. </author> <title> Probabilistic communication complexity of boolean relations. </title> <booktitle> In Proc. 30th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 562-567, </pages> <year> 1989. </year> <title> Exponential gaps are demonstrated between deterministic and probabilistic complexity, and between the probabilistic complexity of monotone and non-monotone relations. </title>
Reference: [Sal69] <author> A. Salomaa. </author> <title> Theory of Automata. </title> <publisher> Pergamon Press, </publisher> <year> 1969. </year> <title> Chapter 2 of this book discusses probabilistic automata and develops a general theory of stochastic languages. </title>
Reference-contexts: Theory of Probabilistic Automata Just as there is a complexity theory of probabilistic algorithms which parallels the complexity theory of deterministic algorithms, there is a theory of probabilistic automata, e.g., <ref> [Rab63, Sal69, Paz71] </ref>, which parallels the classical theory of nondeterministic automata. A seminal paper on probabilistic automata is [Rab63], where Rabin explored finite state probabilistic automata. He defined the notion of a language accepted by a probabilistic automaton relative to a cutpoint probability . <p> He defined the notion of a language accepted by a probabilistic automaton relative to a cutpoint probability . One of his key results was that there exists finite state probabilistic automata that define non-regular languages, even if the probabilities involved are all rational. Salomaa <ref> [Sal69] </ref> has expanded upon the work of Rabin to produce a general theory of stochastic languages. 75 Probabilistic Analysis of Conventional Algorithms Probabilistic analysis of a conventional, i.e., deterministic, algorithm starts with the assumption that the instances of a problem are drawn from a specified probability distribution.
Reference: [Sch78] <author> J. Schwartz. </author> <title> Distributed synchronization of communicating sequential processes. </title> <type> Technical report, DAI Research Report 56, </type> <institution> University of Edinburgh, </institution> <year> 1978. </year> <title> Schwartz presents a distributed algorithm for CSP output guards based on priority ordering of processes. A probabilistic algorithm for output guards is described in Section 3.2. </title>
Reference-contexts: Several distributed implementations of guard scheduling have been proposed including <ref> [Sch78, Ber80, vdS81, Sch82, BS83] </ref>. Each of these algorithms must resort to some symmetry breaking technique such as priority ordering of processes [Sch78, Ber80, BS83], or timestamps [Sch78]. <p> Several distributed implementations of guard scheduling have been proposed including [Sch78, Ber80, vdS81, Sch82, BS83]. Each of these algorithms must resort to some symmetry breaking technique such as priority ordering of processes <ref> [Sch78, Ber80, BS83] </ref>, or timestamps [Sch78]. In fact, like the Dining Philosophers problem, the existence of a fully distributed and symmetric deterministic algorithm for guard scheduling can be shown to be an impossibility [FR80]. <p> Several distributed implementations of guard scheduling have been proposed including [Sch78, Ber80, vdS81, Sch82, BS83]. Each of these algorithms must resort to some symmetry breaking technique such as priority ordering of processes [Sch78, Ber80, BS83], or timestamps <ref> [Sch78] </ref>. In fact, like the Dining Philosophers problem, the existence of a fully distributed and symmetric deterministic algorithm for guard scheduling can be shown to be an impossibility [FR80].
Reference: [Sch79] <author> J. T. Schwartz. </author> <title> Probabilistic algorithms for verification of polynomial identities. </title> <booktitle> In ISSAC '79: Proc. Int'l. Symp. on Symbolic and Algebraic Computation, Lecture Notes in Computer Science, </booktitle> <volume> Vol. 72. </volume> <publisher> Springer-Verlag, </publisher> <year> 1979. </year> <note> This paper, which also appeared in Journal of the ACM , 1980, pp. </note> <month> 701-717, </month> <title> 153 presents probabilistic methods for testing polynomial identities and properties of systems of polynomials. </title>
Reference-contexts: In particular, if S is a set with more than c deg (f ) elements from the field generated by the coefficients of f , then f can have at most 8 jSj n c zeros in S n , for some constant c <ref> [Sch79] </ref>. Thus every trial evaluation of f on a randomly picked element of S n will either prove the falsity of the identity, or yield credence to it with 1=c as the probability of being wrong. <p> Randomized algorithms for testing polynomial identities and properties of systems of polynomials are discussed in detail in <ref> [Sch79, Zip79] </ref>. The probabilistic test for polynomial identities can also be used for determining whether a given undirected graph G (V; E) has a perfect matching, i.e., a set of edges that covers each vertex exactly once.
Reference: [Sch82] <author> F. B. Schneider. </author> <title> Synchronization in distributed programs. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 4(2):1982, </volume> <month> April </month> <year> 1982. </year> <title> Schneider presents a timestamp-based distributed algorithm for CSP output guards. A probabilistic algorithm for output guards is described in Section 3.2. </title>
Reference-contexts: Several distributed implementations of guard scheduling have been proposed including <ref> [Sch78, Ber80, vdS81, Sch82, BS83] </ref>. Each of these algorithms must resort to some symmetry breaking technique such as priority ordering of processes [Sch78, Ber80, BS83], or timestamps [Sch78].
Reference: [Sch84] <author> M. R. Schroeder. </author> <title> Number Theory in Science and Communication with Applications in Cryptography, Physics, Biology, Digital Information and Computing. </title> <publisher> Springer-Verlag, </publisher> <year> 1984. </year> <title> Schroeder presents intuitive discussions on prime numbers, their distribution, fractions, congruences, etc. Several applications of number theory in such diverse fields as cryptography and Fraunhofer diffraction are discussed. A good source of basic number theory results for algorithm designers. </title>
Reference-contexts: if n divides 2 n 2, 18 are wrong results which exemplify the mysteries enshrined in prime numbers. (For the latter, consider, for example, n = 341.) Of late extremely large prime numbers are in great demand because of their use in defining trap-door functions for public key cryptography systems <ref> [RSA78, Sch84, GM84, Smi83] </ref>. For example, in the Rivest-Shamir-Adleman (or RSA) cryptosystem [RSA78] the keys are 200-digit numbers. An encryption key is the product of two secret primes, having approximately 100 digits each, which are known only to the creator of the key. <p> plausible strategy for generating large prime numbers might be: GenPrimef REPEATf Pick a large number at random; Test whether it is prime;g UNTIL a prime number of desired size is found g The mean distance between primes in the neighborhood of a number n is O (log n) (see, e.g., <ref> [Sch84] </ref>). Thus we do not have to test very many numbers before finding one in the desired range. For example, in order to find a prime number about 10 20 in size, we only have to test about 48 numbers. <p> Another fundamental result from number theory also appears promising. Pierre de Fer-mat, a French mathematician, showed that if a number n is prime then, for all x, n does not divide x implies n divides x n1 1 <ref> [Sch84] </ref>. This result has become known as Fermat's theorem, not to be confused with his last theorem. The condition n divides x n1 1 can be restated as x n1 1 (mod n), which we refer to as Fermat's congruence.
Reference: [Sch88] <author> A. Schonhage. </author> <title> Probabilistic computation of integer polynomial GCDs. </title> <journal> Journal of Algorithms, </journal> <volume> 9(3) </volume> <pages> 365-371, </pages> <month> September </month> <year> 1988. </year> <title> The GCD of two univariate integer polynomials of degree n, with their l 1 norms bounded by 2 n , is shown to be reducible to GCD computation for long integers. A probabilistic approach yields an expected complexity of O(n(n + h) 1+o(1) ) bit operations. </title>
Reference: [Sch91] <author> O. Schwarzkopf. </author> <title> Dynamic maintenance of geometric structures made easy. </title> <booktitle> In Proc. 32nd Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 180-196, </pages> <year> 1991. </year> <title> Schwarzkopf presents a randomized algorithm for maintaining Convex Hulls with m points that runs in expected time O(log m) per update for dimensions 2 and 3, O(m log m) for dimensions 4 and 5, and O(m bd=2c1 ) for dimensions greater than 5. </title>
Reference: [Sei90] <author> R. Seidel. </author> <title> Linear programming and convex hulls made easy. </title> <booktitle> In Proc. Sixth Ann. ACM Symp. on Computational Geometry, </booktitle> <pages> pages 211-215, </pages> <address> Berkeley, CA, </address> <month> June </month> <year> 1990. </year> <title> Seidel presents two simple randomized algorithms. One solves linear programs involving m constraints in d variables in expected time O(m). The other constructs convex hulls of n points in &lt; d , d &gt; 3 in expected time O(n bd=2c ). In both bounds, d is considered to be a constant. </title>
Reference: [Sei91] <author> R. Seidel. </author> <title> A simple and fast incremental randomized algorithm for computing trapezoidal decompositions and for triangulating polygons. Computational 154 Geometry: </title> <journal> Theory and Applications, </journal> <volume> 1 </volume> <pages> 51-64, </pages> <year> 1991. </year> <title> Seidel's randomized algo-rithm runs in O(n log fl n) expected time and is simpler than the deterministic O(n) algorithm due to B. </title> <type> Chazelle. </type>
Reference: [Sei92] <author> R. Seidel. </author> <title> On the all-pairs-shortest-path problem. </title> <booktitle> In Proc. 24th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 745-749, </pages> <address> Victoria, B.C., Canada, </address> <month> May </month> <year> 1992. </year> <title> Given an undirected, unweighted n-vertex graph, a simple randomized algorithm is presented that finds a shortest path between each pair of vertices in expected O(M (n) log n) time, where M (n) is the time necessary to multiply two n fi n matrices of small integers. </title>
Reference: [Sha92a] <author> J. Shallit. </author> <title> Randomized algorithms in "primitive cultures". </title> <journal> SIGACT News, </journal> <volume> 23(4) </volume> <pages> 77-80, </pages> <year> 1992. </year> <title> Shallit, in a slightly tongue-in-cheek manner, traces back some of the concepts of randomized algorithms to the native American society of the Naskapi and the central African society of the Azande. Roots in the works of Pierre Laplace and Lord Kelvin are also pointed out. </title>
Reference-contexts: An algorithm not having any coin tossing statements is said to be deterministic. Randomized algorithms entered the computer science spotlight with the publication of Michael Rabin's seminal paper "Probabilistic Algorithms" [Rab76], although their existence can be traced back much further <ref> [Sha92a] </ref>. Rabin's paper presented surprisingly efficient randomized algorithms for two well-known problems, Nearest Neighbors|a problem in computational geometry, and Primality Testing|the problem of determining whether a given integer is divisible by any number other than itself and one.
Reference: [Sha92b] <author> A. Shamir. </author> <title> IP = P SP ACE. </title> <journal> Journal of the ACM, </journal> <volume> 39(4), </volume> <year> 1992. </year> <title> This paper shows that the set of problems for which interactive protocols exist is precisely the set of problems which are solvable within polynomial space on a Turing machine. </title>
Reference-contexts: For example, Ben-Or et al. in [BOGKW88] proposed a multi-prover interactive proof model. Using this model, Babai et al. [BFL90] proved that the class of languages that has a two-prover interactive proof system is non 42 deterministic exponential time. In his paper entitled "IP = P SACE," Shamir <ref> [Sha92b] </ref> showed that the set of problems for which interactive protocols exist is precisely the set of problems which are solvable within polynomial space on a Turing machine.
Reference: [Sho93] <author> V. Shoup. </author> <title> Fast construction of irreducible polynomials over finite fields. </title> <booktitle> In Proc. Fourth Ann. ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 484-492, </pages> <address> Austin, TX, </address> <month> January </month> <year> 1993. </year> <title> A randomized algorithm is presented that constructs an irreducible polynomial of given degree n over a finite field F q . It uses an expected number of O ~ (n 2 + n log q) operations in F q , where the "soft-O" O ~ indicates an implicit factor of (log n) O(1) </title> . 
Reference: [Sie89] <author> A. Siegel. </author> <title> On universal classes of fast high performance hash functions, their time-space tradeoff, and their applications. </title> <booktitle> In Proc. 30th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 20-25, </pages> <month> Oct </month> <year> 1989. </year> <title> An algorithm for constructing log n-wise independent hash functions that can be evaluated in constant time is presented. </title>
Reference: [Sip88] <author> M. Sipser. Expanders, </author> <title> randomness, or time versus space. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 36, </volume> <year> 1988. </year> <title> Contains a discussion on efficiently reducing 155 the probability of error in randomized algorithms. It also describes a relation-ship between pseudorandomness, time and space used by certain algorithms if certain types of expander graphs can be explicitly constructed. </title>
Reference-contexts: For example, the reader may enjoy proving, using a probabilistic argument, that there exists (m log m ; m; 2 log 2 m; m)-expanders for any m <ref> [Sip88] </ref>. Replacing m by 2 q certifies the existence of (2 q 2 ; 2 q ; 2q 2 ; 2 q )-expanders. Sipser [Sip88] reduces the deterministic amplification problem to a graph theoretic problem involving expander graphs. <p> example, the reader may enjoy proving, using a probabilistic argument, that there exists (m log m ; m; 2 log 2 m; m)-expanders for any m <ref> [Sip88] </ref>. Replacing m by 2 q certifies the existence of (2 q 2 ; 2 q ; 2q 2 ; 2 q )-expanders. Sipser [Sip88] reduces the deterministic amplification problem to a graph theoretic problem involving expander graphs. <p> Under the hypothesis that G q (n) can be explicitly constructed, any randomized algorithm A utilizing q (n) random bits with 78 error probability 1 2 , can be converted into another algorithm B that uses q 2 (n) bits and has error probability 2 (q 2 (n)q (n)) <ref> [Sip88] </ref>. The reduction in the error probability follows from the properties of the expander graph. It can also be shown that random bipartite multigraphs are sufficiently expanding. While Sipser's reduction assumes the constructability of expander graphs, Ajtai et al. [AKS87] show how to explicitly construct expanders for deterministic amplification.
Reference: [Smi83] <author> J. Smith. </author> <title> Public key cryptography. </title> <journal> Byte, </journal> <pages> pages 198-218, </pages> <month> January </month> <year> 1983. </year> <title> This is a simple exposition of public key cryptography. </title>
Reference-contexts: if n divides 2 n 2, 18 are wrong results which exemplify the mysteries enshrined in prime numbers. (For the latter, consider, for example, n = 341.) Of late extremely large prime numbers are in great demand because of their use in defining trap-door functions for public key cryptography systems <ref> [RSA78, Sch84, GM84, Smi83] </ref>. For example, in the Rivest-Shamir-Adleman (or RSA) cryptosystem [RSA78] the keys are 200-digit numbers. An encryption key is the product of two secret primes, having approximately 100 digits each, which are known only to the creator of the key.
Reference: [Spe88] <author> J. Spencer. </author> <title> Ten lectures on the probabilistic method. </title> <journal> SIAM Journal on Computing, </journal> <year> 1988. </year> <title> Spencer presents a method of converting probabilistic proofs of existence of certain combinatorial structures into deterministic algorithms that construct these structures. </title>
Reference-contexts: Karp and Wigderson, in the same paper, take advantage of k-wise independence to derive a fast parallel algorithm for the maximal independent set problem. Another approach to derandomization is the method of conditional probabilities <ref> [Spe88] </ref>, which was originally introduced with the aim of converting probabilistic proofs of existence of combinatorial structures into deterministic algorithms that can actually construct these structures.
Reference: [Spi82] <author> P. G. Spirakis. </author> <title> Probabilistic Algorithms, Algorithms with Random Inputs and Random Combinatorial Structures. </title> <type> PhD thesis, </type> <institution> (UMI Order Number DA 8216206) Harvard University, </institution> <address> Cambridge, MA, </address> <year> 1982. </year> <title> This thesis puts forth a new model, `Random Independence Systems', for the probabilistic analysis of deterministic algorithms with random inputs, i.e., algorithms for which the space of all inputs has a known probability distribution. It also presents two probabilistic algorithms with real time response for the problem of communication guard scheduling. </title>
Reference: [Spr77] <author> R. Sprugnoli. </author> <title> Perfect hash functions: A single probe retrieval method for static sets. </title> <journal> Communications of the ACM, </journal> <volume> 20 </volume> <pages> 841-850, </pages> <year> 1977. </year> <title> This is the first discussion on perfect hashing; describes heuristics for constructing perfect hash functions. </title>
Reference-contexts: Another way of minimizing the risk due to biases in the input is to choose the hash function dynamically and at random. These two schemes are explored in the following sections. 30 2.4.1 Perfect Hashing Heuristic methods for perfect hashing were first introduced in <ref> [Spr77] </ref>. A recent overview of perfect hashing can be found in [GBY91]. Several seminal results that make perfect hashing possible were proved in [FKS82, Meh82]. The discussion in this section is based on Section 2.3 of [Meh84a]. <p> Majewski, Wormald, Havas and Czech [MWHC93] have classified numerous algorithms for perfect hashing into four different broad categories. The first category is comprised of algorithms that rely on number theoretic methods to determine a small number of numeric parameters. The very first discussion of perfect hashing, by Sprugnoli <ref> [Spr77] </ref>, falls into this category. Jaeschke's reciprocal hashing is another example from this category [Jae81]. The second category consists of perfect hash functions that use segmentation of keys. In these algorithms, the keys are first distributed into buckets by a non-perfect hash function.

Reference: [SS78] <author> R. Solovay and V. Strassen. </author> <title> Erratum: A fast Monte-Carlo test for primality. </title> <journal> SIAM Journal on Computing, </journal> <volume> 7(1), </volume> <month> Feb. </month> <year> 1978. </year> <title> A minor correction in the analysis presented in [SS77] is reported by the authors. The basic results of [SS77], however, still hold. </title> <type> 156 </type>
Reference-contexts: Rabin's paper presented surprisingly efficient randomized algorithms for two well-known problems, Nearest Neighbors|a problem in computational geometry, and Primality Testing|the problem of determining whether a given integer is divisible by any number other than itself and one. The probabilistic algorithm of Solovay and Strassen <ref> [SS77, SS78] </ref>, also for primality testing, is another celebrated result in the field. A resurgence of interest in randomized algorithms occurred in the early 1980's with the discovery of the important role randomization can play in distributed computing, e.g., [FR80, LR81, BO83].
Reference: [SS90] <author> J. P. Schmidt and A. Siegel. </author> <title> The spatial complexity of oblivious k-probe hash functions. </title> <journal> SIAM Journal on Computing, </journal> <volume> 19(5) </volume> <pages> 775-786, </pages> <year> 1990. </year> <title> This paper gives, among other results, a lower bound for the average space required by program for oblivious k-probe hash function. A probabilistic construction of a family of oblivious k-probe hash function that nearly match this bound is also given. </title>
Reference: [SSS93] <author> J. P. Schmidt, A. Siegel, and A. Srinivasan. </author> <title> Chernoff-Hoeffding bounds for applications with limited independence. </title> <booktitle> In Proc. Fourth Ann. ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 331-340, </pages> <address> Austin, TX, </address> <month> January </month> <year> 1993. </year> <title> Chernoff-Hoeffding bounds are frequently used in the design and analysis of randomized algorithms to bound the tail probabilities of the sums of bounded and independent random variables. The authors give a simple technique which gives slightly better bounds than these and which requires only limited independence among the random variables. </title>
Reference: [Sto85] <author> L. Stockmeyer. </author> <title> On approximation algorithms for #P. </title> <journal> SIAM Journal on Computing, </journal> <volume> 14(4) </volume> <pages> 849-861, </pages> <year> 1985. </year> <title> The author explores the effect of approximation and randomization on the complexity of counting problems (Valiant's class #P which has problems such as counting the number of perfect matchings in a graph, the size of backtrack search trees, </title> <publisher> etc.). </publisher>
Reference: [SV86] <author> M. Santha and U. V. Vazirani. </author> <title> Generating quasi-random sequences from semi-random sources. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 33(1) </volume> <pages> 75-87, </pages> <month> April </month> <year> 1986. </year> <title> The authors introduce the notion of semi-random sources where the next bit of the output is produced by an adversary by the flip of a coin of variable bias. The adversary can look at the previously output bits, and use them to set the bias in the coin. The bias, which helps model correlation among bits, is constrained to be between two limits. </title>
Reference-contexts: They also consider simulations of these algorithms with weak sources of random numbers. Simulating Probabilistic Algorithms by Weak Random Sources Since most physical sources of randomness suffer from correlation, it is natural to consider imperfect or weak sources of randomness. Such sources are called semi-random sources in <ref> [SV86] </ref>. In this model, each bit of the output is produced by an adversary by the flip of a coin of variable bias. The adversary can look at the previously output bits, and use these to set the bias in the coin.
Reference: [TN91] <author> T. Tokuyama and J. Nakano. </author> <title> Geometric algorithms for a minimum cost assignment problem. </title> <booktitle> In Proc. Seventh Ann. ACM Symp. on Computational Geometry, </booktitle> <pages> pages 262-271, </pages> <address> North Conway, NH, </address> <month> June </month> <year> 1991. </year> <title> An efficient randomized algorithm is given for the minimum cost -assignment problem, which is equivalent to the minimum weight one-to-many matching problem in a complete bipartite graph = (A; B). If A and B have n and k nodes respectively, then the algorithm requires O(kn + k 3:5 n 0:5 ) expected time. </title> <type> 157 </type>
Reference: [TO92] <author> S. Toda and M. Ogiwara. </author> <title> Counting classes are at least as hard as the polynomial-time hierarchy. </title> <journal> SIAM Journal on Computing, </journal> <volume> 21(2) </volume> <pages> 316-328, </pages> <month> April </month> <year> 1992. </year> <title> Many counting classes are shown to be computationally as hard as the polynomial time hierarchy, under a notion of randomized reducibility, unless the polynomial-time hierarchy collapses. </title>

Reference: [TW87] <author> M. Tompa and H. Woll. </author> <title> Random self-reducibility and zero-knowledge interactive proofs of possession of information. </title> <booktitle> In Proc. 28th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 472-482, </pages> <year> 1987. </year> <title> Tompa and Woll present a general theory, of which IP proofs for graph isomorphism, quadratic residuosity and knowledge of discrete logarithms are special cases. </title>
Reference: [Tze89] <author> W. G. Tzeng. </author> <title> The equivalence and learning of probabilistic automata. </title> <booktitle> In Proc. 30th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 268-273, </pages> <year> 1989. </year> <title> The equivalence problem of probabilistic automata is solvable in time O((n 1 + n 2 ) 4 ), where n 1 and n 2 are the number of states in the two automata. The problem of learning probabilistic automata by a system of queries in polynomial time is also presented. </title>
Reference: [Upf89] <author> E. Upfal. </author> <title> An O(log N ) deterministic packet routing scheme. </title> <booktitle> In Proc. 21st Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 241-250, </pages> <year> 1989. </year> <title> This paper presents the first deterministic O(log N ) permutation routing algorithm for a multibutterfly network. A multibutterfly network is a special instance of a delta network. Upfal also shows that P instances of the permutation problem can be routed in O(log N + P ) steps using a pipelining approach. </title>
Reference-contexts: A radically different approach, that of randomizing the interconnections between nodes, is also presented. This technique, when applied to multi-butterfly networks, has been shown to outperform conventional butterfly networks, particularly with respect to tolerance to node faults <ref> [Upf89, LM89, LLM90] </ref>. Message Routing on an n-Cube Valiant [Val82] proposed the first permutation routing algorithm for an n-cube. His algorithm implemented any permutation, with high probability, in O (log N ) time. <p> This is where randomization of wiring becomes an advantage. Radomized wiring is exploited in multi-butterfly networks <ref> [Upf89, LM89, LLM90] </ref>. Multi-butterflies are a generalization of both the butterfly and the dilated butterfly. A butterfly network can be considered to be built from splitters, each of which in turn consist of three blocks of nodes and the edges interconnecting them. <p> The edges traversed by a message follow the same logical sequence of up-and down-edges. However, at each node, a choice of d edges is available in a multi-butterfly. Routing on multi-butterflies is efficient, as shown by Upfal's <ref> [Upf89] </ref> algorithm that implements P permutations deterministically in O (log N + P ) time. Multi-butterflies also provide protection against failures [LM89], since, unlike the butterfly and dilated butterfly, there are edge-disjoint and node-disjoint paths between inputs and outputs.
Reference: [UY91] <author> J. D. Ullman and M. Yannakakis. </author> <title> High-probability parallel transitive closure algorithms. </title> <journal> SIAM Journal on Computing, </journal> <volume> 20(1) </volume> <pages> 100-125, </pages> <month> Feb </month> <year> 1991. </year> <title> Parallel transitive closure algorithms are presented for the case when the graph is sparse or only a single source information is desired. The algorithms presented can converted to the Las Vegas type. </title> <type> 158 </type>
Reference: [Val82] <author> L. G. Valiant. </author> <title> A scheme for fast parallel communication. </title> <journal> SIAM Journal on Computing, </journal> <volume> 11(2) </volume> <pages> 350-361, </pages> <month> May </month> <year> 1982. </year> <title> Valiant gives a distributed randomized algorithm for routing packets from unique sources to unique destinations in an n-dimensional binary cube in O(log N ) time, where N = 2 n is the number of nodes in the network, with high probability. </title>
Reference-contexts: Input randomization is not restricted to sequential algorithms. Some randomized message routing algorithms, e.g., Valiant's algorithm for hypercubes <ref> [Val82] </ref> and Aleluinas's algorithm for b-way shu*e networks [Ale82], exhibit what may be termed distributed input randomization. In the message routing problem, a set of messages must be routed from source nodes to destination nodes in a network of computers. <p> In the message routing problem, a set of messages must be routed from source nodes to destination nodes in a network of computers. Moreover, the routing must be done in a distributed manner, i.e., without the help of a central arbiter. In the algorithms of <ref> [Val82, Ale82] </ref>, each message is first sent to a randomly chosen intermediate node before being transmitted to its final destination. This randomization step eliminates "hot points" by distributing the traffic uniformly over the network. <p> In this section, we consider two algorithms that use randomization to break up such input dependencies: Valiant's <ref> [Val82] </ref> algorithm for the n-cube, and Aleluinas's [Ale82] algorithm for shu*e networks. A radically different approach, that of randomizing the interconnections between nodes, is also presented. <p> A radically different approach, that of randomizing the interconnections between nodes, is also presented. This technique, when applied to multi-butterfly networks, has been shown to outperform conventional butterfly networks, particularly with respect to tolerance to node faults [Upf89, LM89, LLM90]. Message Routing on an n-Cube Valiant <ref> [Val82] </ref> proposed the first permutation routing algorithm for an n-cube. His algorithm implemented any permutation, with high probability, in O (log N ) time. <p> This part of the proof involves the estimation of the probabilities at the tail end of a binomial distribution, and is one instance of the application of the powerful Chernoff bounds analysis technique. The reader is referred to <ref> [Val82] </ref> for the detailed probabilistic analysis, but the Chernoff bounds are repeated here for completeness.
Reference: [Val84a] <author> L. G. Valiant. </author> <title> Short monotone formulae for the majority function. </title> <journal> Journal of Algorithms, </journal> <volume> 5 </volume> <pages> 363-366, </pages> <year> 1984. </year> <title> A probabilistic approximation of a deterministic boolean function can yield simple circuits having a small proportion of inputs that cause wrong outputs. Independent probabilistic approximations of the same function can be combined to reduce the probability of error. In this paper Valiant uses such a technique to obtain O(n 5:3 ) size monotone formulas that compute the majority function of n boolean variables. </title>
Reference-contexts: Ajtai and Wigderson [AW89] have demonstrated a family of PRGs that appear random to any polynomial-size logic circuit of constant depth and unbounded fan-in. Such PRGs can be substituted for random number generators in applications such as building simple approximations to complex boolean functions <ref> [Val84a] </ref>. A strong connection exists between cryptographically secure PRGs and one-way functions. A one-way function F (x) is a function that is easily computed, but given F (x), it should not be possible to easily recover x, either with a small circuit or with a fast algorithm.
Reference: [Val84b] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27 </volume> <pages> 1134-1142, </pages> <year> 1984. </year> <title> Valiant introduces a formal framework for the probabilistic analysis of algorithms that learn sets defined on a predetermined universe. </title>
Reference: [Val87] <author> D. Valois. </author> <title> Algorithmes probabilistes: une anthologie. </title> <type> Master's thesis, </type> <institution> Departement d'informatique et de recherche operationnelle, Universite de Montreal, </institution> <year> 1987. </year> <title> In French, this paper covers a number of probabilistic algorithms including matrix multiplication and inversion, manipulation of polynomials, set equality, Byzantine Generals, and cryptography. </title>
Reference-contexts: More recently, randomized algorithms have been the subject of an ACM Turing Award Lecture [Kar86], an ACM Distinguished Dissertation [Kil90], and of a number of surveys including <ref> [Wei78, Hop81, Wel83, Kro85, MSV85, Har87, Val87, BB88, Rag90, Kar90] </ref>. <p> More recently, randomized algorithms have been the subject of an ACM Turing Award Lecture [Kar86], an ACM Distinguished Dissertation [Kil90], and of a number of surveys including [Wei78, Hop81, Wel83, Kro85, MSV85, Har87, Val87, BB88, Rag90, Kar90]. Our survey is closest in spirit to <ref> [Har87, Val87, BB88, Kar90] </ref> in its extensive coverage of both sequential and distributed randomized algorithms. 4 A distinguishing aspect of our survey is the classification we present in Section 1.1 of gen-eral techniques used in the design of randomized algorithms. 2 In Section 1.2, we then identify certain tradeoffs one may
Reference: [Vaz87] <author> U. V. Vazirani. </author> <title> Efficiency considerations in using semi-random sources. </title> <booktitle> In Proc. 19th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 160-168, </pages> <year> 1987. </year> <title> Efficient algorithms for using semi-random sources are presented. </title>
Reference-contexts: It has been shown that if a problem can be solved by a polynomial-time Monte Carlo algorithm that has access to a true source of randomness, then the same problem can be solved using an arbitrarily weak semi-random source [VV85]. In <ref> [Vaz87] </ref>, efficient algorithms for using semi-random sources are presented and a technique for producing a quasi-random sequence at an optimal rate, using two semi-random sources, is described. In [Zuc90], Zuckerman exhibits a pseudo-random generator that depends only on a weak random source called a ffi-source.
Reference: [VB81] <author> L. Valiant and G. Brebner. </author> <title> Universal schemes for parallel communication. </title> <booktitle> In Proc. 13th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 263-277, </pages> <year> 1981. </year> <title> This paper extends Valiant's message routing algorithm [Val82] to asynchronous networks. </title>
Reference-contexts: This restriction, however, can be relaxed <ref> [VB81] </ref>. 61 Also, note that the two phases run for F and G iterations, respectively. It is clear that if G is too small, all messages might not reach their final destinations.
Reference: [vdS81] <author> J. L. A. van de Snepscheut. </author> <title> Synchronous communication between asynchronous components. </title> <journal> Information Processing Letters, </journal> <volume> 13(3) </volume> <pages> 127-130, </pages> <month> Decem-ber </month> <year> 1981. </year> <title> Snepscheut presents a distributed algorithm for CSP output guards in which processes are related by a tree structure. A probabilistic algorithm for output guards is described in Section 3.2. </title> <type> 159 </type>
Reference-contexts: Several distributed implementations of guard scheduling have been proposed including <ref> [Sch78, Ber80, vdS81, Sch82, BS83] </ref>. Each of these algorithms must resort to some symmetry breaking technique such as priority ordering of processes [Sch78, Ber80, BS83], or timestamps [Sch78].

Reference: [Vis84] <author> U. Vishkin. </author> <title> Randomized speed-ups in parallel computation. </title> <booktitle> In Proc. 16th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 230-239, </pages> <year> 1984. </year> <title> Vishkin considers the problem of computing the position of each element of a linked list, given the length n of the list. He presents a probabilistic algorithm for this problem running time O(n=p + log n log fl n) using p processors. </title>
Reference-contexts: The benefits of randomization in parallel algorithms can perhaps be best illustrated by the results of Vishkin <ref> [Vis84] </ref> for the following problem: Given a linked list of length n, compute the distance of each element of the linked list from the end of the list.
Reference: [Vis90] <author> S. Vishwanathan. </author> <title> Randomized online graph coloring. </title> <booktitle> In Proc. 31st Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 464-469, </pages> <year> 1990. </year> <title> It shown that randomization helps in coloring a graph in an online manner and the randomized online algorithm is quite competitive with the best-known, deterministic, off-line algorithm. </title>
Reference: [VV85] <author> U. V. Vazirani and V. V. Vazirani. </author> <title> Random polynomial time is equal to semi-random polynomial time. </title> <booktitle> In Proc. 26th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 417-428, </pages> <year> 1985. </year> <title> This paper analyzes of the behavior of randomized algorithms where perfectly random sources are substituted with sources which have small bias and dependence. It shows that if a problem can be solved by a polynomial-time Monte Carlo algorithm which has access to a true source of randomness, the the same problem can be solved using an arbitrarily weak semi-random source. </title> <type> 160 </type>
Reference-contexts: It has been shown that if a problem can be solved by a polynomial-time Monte Carlo algorithm that has access to a true source of randomness, then the same problem can be solved using an arbitrarily weak semi-random source <ref> [VV85] </ref>. In [Vaz87], efficient algorithms for using semi-random sources are presented and a technique for producing a quasi-random sequence at an optimal rate, using two semi-random sources, is described. In [Zuc90], Zuckerman exhibits a pseudo-random generator that depends only on a weak random source called a ffi-source.
Reference: [VV89] <author> U. V. Vazirani and V. V. Vazirani. </author> <title> The two-processor scheduling problem is in random NC. </title> <journal> SIAM Journal on Computing, </journal> <volume> 18(6) </volume> <pages> 1140-1148, </pages> <year> 1989. </year> <title> An efficient, randomized, parallel solution to the well-studied two-processor scheduling problem is presented. </title>
Reference: [vzG89] <author> J. von zur Gathen. </author> <title> Testing permutation polynomials. </title> <booktitle> In Proc. 30th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 88-98, </pages> <address> Research Triangle Park, NC, </address> <month> October </month> <year> 1989. </year> <title> IEEE Computer Society Press. The author presents a randomized algorithm for testing whether a given polynomial over a finite field with q elements is a permutation polynomial in expected O(q) time. </title>
Reference: [vzG91] <author> J. von zur Gathen. </author> <title> Tests for permutation polynomials. </title> <journal> SIAM Journal on Computing, </journal> <volume> 20(3) </volume> <pages> 591-602, </pages> <month> June </month> <year> 1991. </year> <title> An element of a finite field F q [x] is called a permutation polynomial if the mapping F q ! F q induced by it is bijective. A probabilistic algorithm for testing this property is given. </title>
Reference: [vzGS92] <author> J. von zur Gathen and V. Shoup. </author> <title> Computing Frobenius maps and factoring polynomials. </title> <booktitle> In Proc. 24th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 97-105, </pages> <address> Victoria, B.C., Canada, </address> <month> May </month> <year> 1992. </year> <title> A probabilistic algorithm for factoring univariate polynomials over finite fields is presented whose asymptotic running time improves upon previous results. </title>
Reference: [Wei78] <author> B. W. Weide. </author> <title> Statistical Methods in Algorithmic Design and Analysis. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Carnegie-Mellon University, Pitts-burgh, PA, Report CMU-CS-78-142, </institution> <year> 1978. </year> <title> An early survey of probabilistic algorithms and analysis. </title>
Reference-contexts: More recently, randomized algorithms have been the subject of an ACM Turing Award Lecture [Kar86], an ACM Distinguished Dissertation [Kil90], and of a number of surveys including <ref> [Wei78, Hop81, Wel83, Kro85, MSV85, Har87, Val87, BB88, Rag90, Kar90] </ref>.
Reference: [Wel83] <author> D. J. A. Welsh. </author> <title> Randomized algorithms. </title> <journal> Discrete Appl. Math., </journal> <volume> 5 </volume> <pages> 133-146, </pages> <year> 1983. </year> <title> This is a well-written introduction to randomized algorithms. Welsh discusses probabilistic algorithms for checking polynomial identities, primality, matrix and polynomial multiplication, and deciding whether a graph has a perfect matching. The work also contains a nice discussion on random polynomial time, random log-space, and the probabilistic hierarchy. </title>
Reference-contexts: More recently, randomized algorithms have been the subject of an ACM Turing Award Lecture [Kar86], an ACM Distinguished Dissertation [Kil90], and of a number of surveys including <ref> [Wei78, Hop81, Wel83, Kro85, MSV85, Har87, Val87, BB88, Rag90, Kar90] </ref>.
Reference: [WVZT90] <author> K.-Y. Whang, B. T. Vander-Zanden, and H. M. Taylor. </author> <title> A linear-time probabilistic counting algorithm for database applications. </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 15(2) </volume> <pages> 208-229, </pages> <month> Sept </month> <year> 1990. </year> <title> A probabilistic technique called linear 161 counting, based on hashing, for counting the number of unique values in the presence of duplicates is presented in this paper. </title>
Reference: [Wyl79] <author> J. C. Wyllie. </author> <title> The complexity of parallel computation. </title> <type> Technical Report TR 79-387, </type> <institution> Department of Computer Science, Cornell University, </institution> <address> Ithaca, NY, </address> <year> 1979. </year> <title> Wyllie conjectures that there is no optimal speed-up parallel algorithm for n= log n processors for the problem: Given a linked list of length n, compute the distance of each element of the linked list from the end of the list. However, Vishkin showed that such optimal speed-up can be obtained via randomization (see Section 4). </title>
Reference-contexts: The problem has a trivial linear-time sequential algorithm but Wyllie <ref> [Wyl79] </ref> conjectured that there is no optimal speed-up parallel algorithm for n= log n processors.
Reference: [Yao79] <author> A. C. Yao. </author> <title> The complexity of pattern matching for a random string. </title> <journal> SIAM Journal on Computing, </journal> <volume> 8(3) </volume> <pages> 368-387, </pages> <month> August </month> <year> 1979. </year> <title> Yao proves that the minimum average number of characters which need be examined in a random string of length n for locating patterns of length m, in an alphabet with q symbols, is (dlog q ( nm ln m + 2)e) if m n 2m and ( dlog q me m n) if n &gt; 2m. </title> <note> This confirms Knuth, Morris, and Pratt's conjecture in [KMP77]. </note>
Reference: [Yao83] <author> A. C. Yao. </author> <title> Lower bounds by probabilistic arguments (extended abstract). </title> <booktitle> In Proc. 24th Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 420-428, </pages> <year> 1983. </year> <title> Though not a paper on probabilistic algorithms, this paper illustrates the power of probabilistic arguments by proving lower bounds for three important problems. </title>
Reference: [Yao91] <author> A. C. Yao. </author> <title> Lower bounds to randomized algorithms for graph properties. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 42 </volume> <pages> 267-287, </pages> <year> 1991. </year> <title> Yao shows that (n(log n) 1 12 ) edges must be examined by any randomized algorithm (as opposed to (n 2 ) by any deterministic algorithm) for determining any non-trivial monotone graph property. </title> <note> An earlier version of this paper appeared in Proc. </note> <editor> 28th Ann. </editor> <booktitle> IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1987. </year>

Reference: [Zac88] <author> S. Zachos. </author> <title> Probabilistic quantifiers and games. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 36 </volume> <pages> 433-451, </pages> <year> 1988. </year> <title> This paper attempts to give a uniform picture of the various polynomial time complexity classes. </title>
Reference: [Zip79] <author> R. Zippel. </author> <title> Probabilistic algorithms for sparse polynomials. </title> <booktitle> In ISSAC '79: Proc. Int'l. Symp. on Symbolic and Algebraic Computation, Lecture Notes in Computer Science, </booktitle> <volume> Vol. 72. </volume> <publisher> Springer-Verlag, </publisher> <year> 1979. </year> <title> Zippel discusses probabilistic methods for testing polynomial identities and properties of systems of polynomials. </title>
Reference-contexts: Randomized algorithms for testing polynomial identities and properties of systems of polynomials are discussed in detail in <ref> [Sch79, Zip79] </ref>. The probabilistic test for polynomial identities can also be used for determining whether a given undirected graph G (V; E) has a perfect matching, i.e., a set of edges that covers each vertex exactly once.

Reference: [Zuc91] <author> D. Zuckerman. </author> <title> Simulating BPP using a general weak random source. </title> <booktitle> In Proc. 32nd Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 79-89, </pages> <year> 1991. </year> <title> Using the weak random source defined in [Zuc90], this paper shows how to simulate BPP and approximation algorithms in polynomial time using the output from a such a source. </title> <type> 163 </type>
Reference-contexts: A ffi-source, unlike a semi-random source, is asked only once for R random bits and the source outputs an R-bit string such that no string has a probability more than 2 ffiR of being output, for some fixed ffi &gt; 0. Zuckerman <ref> [Zuc91] </ref> also shows how to simulate BPP and approximation algorithms in polynomial time using the output from a ffi-source.
References-found: 361

