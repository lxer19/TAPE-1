URL: http://www.cs.purdue.edu/coast/archive/clife/GA/papers/ki94.ps.gz
Refering-URL: http://www.cs.purdue.edu/coast/archive/clife/GA/papers/
Root-URL: http://www.cs.purdue.edu
Title: An Evolutionary Heuristic for the Minimum Vertex Cover Problem  
Author: Sami Khuri Thomas Back 
Address: One Washington Square San Jose, CA 95192-0103 U.S.A.  D-44221 Dortmund Germany  
Affiliation: San Jose State University Dept. of Mathematics Computer Science  University of Dortmund Dept. of Computer Science, LS XI  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> The MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1990. </year>
Reference: [2] <editor> L. J. Eshelman, R. A. Caruna, and J. D. Schaffer. </editor> <title> Biases in the crossover landscape. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proceedings of the 3rd International Conference on Genetic Algorithms, </booktitle> <pages> pages 10-19. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference-contexts: Experimental Results The experiments reported in this section are performed by using a genetic algorithm with a population size = 50, a mutation rate p m = 1=n, crossover rate p c = 0:6, proportional selection, and two-point crossover. As reported in <ref> [2, 12] </ref>, the latter is expected to perform better than the traditional one-point crossover. In order to apply the genetic algorithm to the minimum vertex cover problem, no component of this general genetic algorithm | except, of course, the fitness function | has to be modified.
Reference: [3] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability | A Guide to the Theory of NP-Completeness. </title> <publisher> Freemann & Co., </publisher> <address> San Francisco, CA, </address> <year> 1979. </year>
Reference-contexts: Introduction The minimum vertex cover problem (mvcp) belongs to the class of NP-hard problems. The maximum clique problem can be reduced to it <ref> [3] </ref>. Thus, the search for an optimal solution is intractable (unless of course P = NP). Due to its numerous applications, especially in various matching problems, the problem is not abandoned. The goal is to find heuristics: approximation algorithms that have polynomial running times that return near-optimal solutions.
Reference: [4] <author> D. E. Goldberg. </author> <title> Genetic algorithms in search, optimization and machine learning. </title> <publisher> Addison Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: Due to its numerous applications, especially in various matching problems, the problem is not abandoned. The goal is to find heuristics: approximation algorithms that have polynomial running times that return near-optimal solutions. In this work we describe the results of applying a genetic algorithm <ref> [6, 4] </ref> to the mvcp. The latter is a highly constrained combinatorial optimization problem. Unlike traditional approaches that use domain-specific knowledge, and specialized genetic operators, the approach presented here makes use of a graded penalty term incorporated in the fitness function to penalize infeasible solutions.
Reference: [5] <author> J. J. Grefenstette. </author> <title> Genesis: A system for using genetic search procedures. </title> <booktitle> In Proceedings of the 1984 Conference on Intelligent Systems and Machines, </booktitle> <pages> pages 161-165, </pages> <year> 1984. </year>
Reference-contexts: The fitness function itself is quite simple and needs to be added to GENEsYs, the genetic algorithm software package we use in this work. This package is based on Grefenstette's widely used GENESIS <ref> [5] </ref>. Following the formal introduction of the mvcp, the best known heuristic algorithm for that problem is introduced. The study then focuses on the genetic-based heuristic. Several problem instances are used with both algorithms and the results are compared.
Reference: [6] <author> J. H. Holland. </author> <title> Adaptation in natural and artificial systems. </title> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, MI, </address> <year> 1975. </year>
Reference-contexts: Due to its numerous applications, especially in various matching problems, the problem is not abandoned. The goal is to find heuristics: approximation algorithms that have polynomial running times that return near-optimal solutions. In this work we describe the results of applying a genetic algorithm <ref> [6, 4] </ref> to the mvcp. The latter is a highly constrained combinatorial optimization problem. Unlike traditional approaches that use domain-specific knowledge, and specialized genetic operators, the approach presented here makes use of a graded penalty term incorporated in the fitness function to penalize infeasible solutions.
Reference: [7] <author> S. Khuri, Th. Back, and J. Heitkotter. </author> <title> An evolutionary approach to combinatorial optimization problems. </title> <editor> In D. Cizmar, editor, </editor> <booktitle> Proceedings of the 22nd Annual ACM Computer Science Conference, </booktitle> <pages> pages 66-73, </pages> <address> Phoenix, 1994. </address> <publisher> ACM Press, </publisher> <address> New York. </address>
Reference-contexts: Consequently, the second term drops to zero for feasible solutions. The fitness function was developed according to the following design principles that are important for a successful penalty function approach <ref> [11, 13, 7] </ref>: * The penalty should be graded, i.e., fitness values should improve as solutions approach (in terms of the Hamming distance) feasible regions of the search space. * Infeasible binary vectors are guaranteed to yield fitness values which are inferior to fitness values of even the worst feasible solutions. <p> Moreover, the results found by the genetic algorithm are better than those obtained from the best known traditional heuristic, the vercov algorithm. These findings, in addition to other good results obtained on different, highly constrained combinatorial optimization problems such as the subset sum <ref> [7] </ref>, minimum tardy task [7], and multiple knapsack problems [8], give strong evidence that genetic algorithms can yield good solutions for a wide range of hard combinatorial optimization problems for which solutions can be represented by binary strings. <p> Moreover, the results found by the genetic algorithm are better than those obtained from the best known traditional heuristic, the vercov algorithm. These findings, in addition to other good results obtained on different, highly constrained combinatorial optimization problems such as the subset sum <ref> [7] </ref>, minimum tardy task [7], and multiple knapsack problems [8], give strong evidence that genetic algorithms can yield good solutions for a wide range of hard combinatorial optimization problems for which solutions can be represented by binary strings. Acknowledgements The first author was partially supported by the Cali-fornia State University research award GS850-851.
Reference: [8] <author> S. Khuri, Th. Back, and J. Heitkotter. </author> <title> The zero/one multiple knapsack problem and genetic algorithms. </title> <editor> In E. Deaton, D. Oppenheim, J. Urban, and H. Berghel, editors, </editor> <booktitle> Proceedings of the 1994 ACM Symposium on Applied Computing, </booktitle> <pages> pages 188-193. </pages> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: These findings, in addition to other good results obtained on different, highly constrained combinatorial optimization problems such as the subset sum [7], minimum tardy task [7], and multiple knapsack problems <ref> [8] </ref>, give strong evidence that genetic algorithms can yield good solutions for a wide range of hard combinatorial optimization problems for which solutions can be represented by binary strings. Acknowledgements The first author was partially supported by the Cali-fornia State University research award GS850-851.
Reference: [9] <author> C. H. Papadimitriou. </author> <title> Computational Complexity. </title> <publisher> Addison Wesley, </publisher> <address> Reading, MA, </address> <year> 1994. </year>

Reference: [11] <author> J. T. Richardson, M. R. Palmer, G. Liepins, and M. Hilliard. </author> <title> Some guidelines for genetic algorithms with penalty functions. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proceedings of the 3rd International Conference on Genetic Algorithms, </booktitle> <pages> pages 191-197. </pages> <publisher> Morgan Kauf-mann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference-contexts: Consequently, the second term drops to zero for feasible solutions. The fitness function was developed according to the following design principles that are important for a successful penalty function approach <ref> [11, 13, 7] </ref>: * The penalty should be graded, i.e., fitness values should improve as solutions approach (in terms of the Hamming distance) feasible regions of the search space. * Infeasible binary vectors are guaranteed to yield fitness values which are inferior to fitness values of even the worst feasible solutions.
Reference: [12] <author> J. D. Schaffer, R. A. Caruana, L. J. Eshelman, and R. Das. </author> <title> A study of control parameters affecting online performance of genetic algorithms for function optimization. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proceedings of the 3rd International Conference on Genetic Algorithms, </booktitle> <pages> pages 51-60. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference-contexts: Experimental Results The experiments reported in this section are performed by using a genetic algorithm with a population size = 50, a mutation rate p m = 1=n, crossover rate p c = 0:6, proportional selection, and two-point crossover. As reported in <ref> [2, 12] </ref>, the latter is expected to perform better than the traditional one-point crossover. In order to apply the genetic algorithm to the minimum vertex cover problem, no component of this general genetic algorithm | except, of course, the fitness function | has to be modified.
Reference: [13] <author> A. E. Smith and D. M. Tate. </author> <title> Genetic optimization using a penalty function. </title> <editor> In S. Forrest, editor, </editor> <booktitle> Proceedings of the 5th International Conference on Genetic Algorithms, </booktitle> <pages> pages 499-505. </pages> <publisher> Morgan Kauf-mann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: Consequently, the second term drops to zero for feasible solutions. The fitness function was developed according to the following design principles that are important for a successful penalty function approach <ref> [11, 13, 7] </ref>: * The penalty should be graded, i.e., fitness values should improve as solutions approach (in terms of the Hamming distance) feasible regions of the search space. * Infeasible binary vectors are guaranteed to yield fitness values which are inferior to fitness values of even the worst feasible solutions.
Reference: [14] <author> D. R. Stinson. </author> <title> An Introduction to the Design and Analysis of Algorithms. </title> <institution> The Charles Babbage Research Center, Winnipeg, Manitoba, </institution> <address> Canada, 2nd edition, </address> <year> 1987. </year>
Reference-contexts: V 0 is said to be a vertex cover of G. The following is a formal definition of the mvcp in which we make use of Stinson's terminology for combinatorial optimization problems <ref> [14] </ref>: Problem instance: A graph G = (V; E), where V = f1; 2; : : :; ng is the set of vertices and E V fiV the set of edges. An edge between vertices i, j is denoted by the pair hi; ji 2 E.
References-found: 13

