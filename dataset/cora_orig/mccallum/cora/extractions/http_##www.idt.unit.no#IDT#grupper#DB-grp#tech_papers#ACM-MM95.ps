URL: http://www.idt.unit.no/IDT/grupper/DB-grp/tech_papers/ACM-MM95.ps
Refering-URL: http://www.idt.unit.no/IDT/grupper/DB-grp/tech_papers/tech_papers.html
Root-URL: 
Email: olavsag@idt.unit.no  
Title: Integrated Video Archive Tools  
Author: Rune Hjelsvold, Stein Langtrgen, Roger Midtstraum, Olav Sandst-a frhj, steinl, roger, 
Keyword: Video databases, applications, content-based retrieval, browsing, digital libraries  
Address: N-7034 Trondheim, Norway  
Affiliation: Department of Computer Systems and Telematics The Norwegian Institute of Technology  
Abstract: In traditional video archives, video data are stored on analogue video tapes while meta-data, such as textual descriptions of the contents of the video tapes, are stored and handled digitally by computers. In a fully digital video archive, both video data and meta-data are managed by computers and, thus, more powerful tools can be developed. In this paper, we discuss what kind of tools a digital video archive should offer its users, and we describe an experimental video archive system which consists of tools for playing, browsing, searching and indexing video information. All tools in the system are based on a generic database platform called VideoSTAR (Video STorage And Retrieval) and they share video and meta-data via the common database. The tools are managed by a video archive tool manager which provides mechanisms for communication and cooperation between different tools. The system has been demonstrated to professional archivists and librarians who have given positive response, and as the next step we will have the system tested in a real video archive environment. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Arman et al. </author> <title> Content-Based Browsing of Video Sequences. </title> <booktitle> In Proceedings of ACM Multimedia '94, </booktitle> <address> San Francisco, USA, </address> <month> October </month> <year> 1994, </year> <pages> pp. 97-103. </pages>
Reference-contexts: These tools are interesting preprocessing tools in a video archive for segmenting video documents, especially when the edit decision list is not explicitly available. Some tools have also been proposed for temporal browsing of video <ref> [1, 4, 21] </ref>. These tools are best applicable when the structure of the video follow a stringent, predefined syntax; i.e., television news.
Reference: 2. <institution> Avid Technology Inc. </institution> <note> Avid Media Composer User's Guide, </note> <year> 1993. </year>
Reference-contexts: Parts of this problem could be reduced if the system had access to shot boundaries from editing tools like Avid <ref> [2] </ref>, or if shot detecting tools [7, 21] were employed as preprocessing tools. From the use of the video annotator, we have experienced that in most cases it is sensible to divide the registration process into two separate tasks: The first task consists of determining the structure components.
Reference: 3. <author> A. Bekkadal. </author> <title> Editing Tool for Digital Video. </title> <type> Master's thesis, </type> <institution> Norwegian Institute of Technology, </institution> <year> 1994. </year> <note> In Norwegian. </note>
Reference-contexts: In addition to these tools, we have also been studying how video editing tools can be integrated into the environment <ref> [3] </ref>, but no such tool has been integrated into the environment yet. 4.1 The Video Player This video player gives us the possibility to display digital video on a computer display.
Reference: 4. <author> G. Cruz and R. Hill. </author> <title> Capturing and Playing Multimedia Events with STREAMS. </title> <booktitle> In Proceedings of ACM Multimedia 94, </booktitle> <address> San Francisco, USA, </address> <month> October </month> <year> 1994, </year> <pages> pp. 193-200. </pages>
Reference-contexts: These tools are interesting preprocessing tools in a video archive for segmenting video documents, especially when the edit decision list is not explicitly available. Some tools have also been proposed for temporal browsing of video <ref> [1, 4, 21] </ref>. These tools are best applicable when the structure of the video follow a stringent, predefined syntax; i.e., television news.
Reference: 5. <author> D. Deloddere, W. Verbiest, and H. Verhille. </author> <title> Interactive Video On Demand. </title> <journal> IEEE Communications Magazine, </journal> <volume> 32(5) </volume> <pages> 82-88, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: 1 INTRODUCTION The most active research area for video databases today is Video-on-Demand (VOD). VOD services which will allow users to search for movies and videos stored on a digital video server <ref> [5, 13, 14, 18] </ref>. Today, many libraries and archives - e.g., television archives have huge amounts of videos and/or films.
Reference: 6. <author> T. Dyb-a, T. Holte, and A. Ster. </author> <title> LAVA Report: Analysis of Television Production. </title> <type> Technical report, </type> <institution> SINTEF DELAB, </institution> <month> December </month> <year> 1994. </year> <note> In Norwegian. </note>
Reference-contexts: In a project called LAVA, we are working together with several Norwegian research institutes, the Norwegian Broadcasting Corporation (NRK), TV2 Norway, and the Norwegian Folk Museum to identify what information and services a digital television archive should offer <ref> [6] </ref>. In the following subsections, we review some of the functionality that should be offered by a digital video archive. 2.1 Searching The primary service offered by a television archive is as 283 sisting reporters and directors in finding pieces of video from the archive.
Reference: 7. <author> A. Hampapur, R. Jain, and T. Weymouth. </author> <title> Digital Video Segmentation. </title> <booktitle> In Proceedings of ACM Multimedia '94, </booktitle> <address> San Francisco, USA, </address> <month> October </month> <year> 1994, </year> <pages> pp. 357-364. </pages>
Reference-contexts: In addition, the proposed annotation tools are based on unformatted, free text descriptions of the contents. A digital video archive serving different categories of users should offer a more structured way of describing video contents. Some researchers have tried to develop tools for automatic segmentation of video material <ref> [7, 21] </ref> - i.e., identifying cuts in a video document. These tools are interesting preprocessing tools in a video archive for segmenting video documents, especially when the edit decision list is not explicitly available. Some tools have also been proposed for temporal browsing of video [1, 4, 21]. <p> Parts of this problem could be reduced if the system had access to shot boundaries from editing tools like Avid [2], or if shot detecting tools <ref> [7, 21] </ref> were employed as preprocessing tools. From the use of the video annotator, we have experienced that in most cases it is sensible to divide the registration process into two separate tasks: The first task consists of determining the structure components.
Reference: 8. <author> R. Hjelsvold. </author> <title> Video Information Contents and Architecture. </title> <booktitle> In Proceedings of the 4th International Conference on Extending Database Technology, </booktitle> <address> Cam-bridge, UK, </address> <month> March </month> <year> 1994. </year> <pages> pp. 259-272. 292 </pages>
Reference-contexts: The archive could store this meta-data together with the video data, and the information could either be entered during production, or it could be registered afterwards. A reporter using the archive for background 1 These concepts are defined in <ref> [8] </ref>. research will usually be interested in having as much content information as possible about the video that he/she is viewing. 2.4 Video Annotation The librarians try to classify, describe, and annotate the contents of video documents and recordings to make searching and browsing possible in an efficient manner.
Reference: 9. <author> R. Hjelsvold and R. Midtstraum. </author> <title> Modelling and Querying Video Data. </title> <booktitle> In Proceedings of the 20th VLDB Conference, </booktitle> <address> Santiago, Chile, </address> <month> September </month> <year> 1994, </year> <pages> pp. 686-694. </pages>
Reference-contexts: Thus, there is a need for an integrated video archive environment allowing the users to run different applications towards a common database of video data and meta-data. In previous papers <ref> [9, 10, 12] </ref> we have presented database functionality for supporting video information sharing between different users and applications, and for querying and browsing the contents in a video archive/library. We have developed a number of video archive tools that illustrate the usability of our video database functionality.
Reference: 10. <author> R. Hjelsvold and R. Midtstraum. </author> <title> Databases for Video Information Sharing. </title> <booktitle> In Proceedings of the IS&T/SPIE Symposium on Electronic Imaging Science and Technology, Conference on Storage and Retrieval for Image and Video Databases III, </booktitle> <address> San Jose, CA, </address> <month> February </month> <year> 1995, </year> <pages> pp. 268-279. </pages>
Reference-contexts: Thus, there is a need for an integrated video archive environment allowing the users to run different applications towards a common database of video data and meta-data. In previous papers <ref> [9, 10, 12] </ref> we have presented database functionality for supporting video information sharing between different users and applications, and for querying and browsing the contents in a video archive/library. We have developed a number of video archive tools that illustrate the usability of our video database functionality. <p> Our work is aimed at developing a more complete video archive environment including a video database frame 284 work and video archive tools. The video database framework is called VideoSTAR (Video STorage And Re trieval) <ref> [10, 12] </ref> and its elements are (see Figure 1): * Database repositories for storing video documents and video footage (recordings). <p> To be able to do so, we have developed several experimental tools that interact with the video player and give the user access to the meta-data. We have identified three basic operations a user may want to perform against the meta-data in a video database <ref> [10] </ref>. The first operation is browsing of the meta-data related to a particular video document. As a second operation, the user might want to search after video documents covering a certain topic.
Reference: 11. <author> R. Hjelsvold, R. Midtstraum, and O. Sandst-a. </author> <title> A Temporal Foundation of Video Databases. </title> <booktitle> To appear in Proceedings of the International Workshop on Temporal Databases, </booktitle> <address> Zurich, Switzerland, </address> <month> Septem-ber </month> <year> 1995. </year>
Reference-contexts: It would, at this point, be fair to discuss some of the weaknesses as we see them at the time of writing: * First and most important we would like to have much more powerful query capabilities as we have thoroughly discussed in <ref> [11, 12] </ref>. * We do not have any good means of showing the relative size of pieces of video material, for instance in query results and during browsing. * Users may want to perform a free text search in structure component descriptions in addition to searching the content annotations. * The
Reference: 12. <author> R. Hjelsvold, R. Midtstraum, and O. Sandst-a. </author> <title> Searching and Browsing a Shared Video Database. </title> <booktitle> To appear in Proceedings of the First International Workshop on Multimedia Database Management Systems, </booktitle> <address> Blue Mountain Lake, NY, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: Thus, there is a need for an integrated video archive environment allowing the users to run different applications towards a common database of video data and meta-data. In previous papers <ref> [9, 10, 12] </ref> we have presented database functionality for supporting video information sharing between different users and applications, and for querying and browsing the contents in a video archive/library. We have developed a number of video archive tools that illustrate the usability of our video database functionality. <p> Our work is aimed at developing a more complete video archive environment including a video database frame 284 work and video archive tools. The video database framework is called VideoSTAR (Video STorage And Re trieval) <ref> [10, 12] </ref> and its elements are (see Figure 1): * Database repositories for storing video documents and video footage (recordings). <p> In Figure 4, the last item is selected and played. This piece of video is from the actual Nobel Peace Prize ceremony, and its structure is shown in Figure 3. Besides the Query tool shown in Figure 4, we are also experimenting with more powerful query capabilities <ref> [12] </ref>. 4.4 The Video Annotator Registration of meta-data related to pieces of a video document is an important, but time consuming task. Different users need to have registration tools tailored to their particular way of doing registration. <p> It would, at this point, be fair to discuss some of the weaknesses as we see them at the time of writing: * First and most important we would like to have much more powerful query capabilities as we have thoroughly discussed in <ref> [11, 12] </ref>. * We do not have any good means of showing the relative size of pieces of video material, for instance in query results and during browsing. * Users may want to perform a free text search in structure component descriptions in addition to searching the content annotations. * The
Reference: 13. <author> T.D.C. Little et al. </author> <title> A Digital On-Demand Video Service Supporting Content-Based Queries. </title> <booktitle> In Proceedings of ACM Multimedia 93, </booktitle> <address> Anaheim, USA, </address> <month> August </month> <year> 1993, </year> <pages> pp. 427-436. </pages>
Reference-contexts: 1 INTRODUCTION The most active research area for video databases today is Video-on-Demand (VOD). VOD services which will allow users to search for movies and videos stored on a digital video server <ref> [5, 13, 14, 18] </ref>. Today, many libraries and archives - e.g., television archives have huge amounts of videos and/or films. <p> The disadvantage with these tools is that, when applied to pieces of video with complex or vague structure, they do not manage to group frames and shots into semantically meaningful entities such as scenes and sequences. The Virtual Video Browser <ref> [13] </ref>, the Video Database Browser [18], and OVID [16] are experimental video database systems that provide content-based querying. Neither of these systems offers tools for structure and contents browsing in the way described in Section 2, and efficient annotation tools have not been proposed.
Reference: 14. <author> T.D.C. Little and D. Venkatesh. </author> <title> Prospects for Interactive Video-on-Demand. </title> <journal> IEEE Multimedia, </journal> <volume> 1(3) </volume> <pages> 14-24, </pages> <month> Fall </month> <year> 1994. </year>
Reference-contexts: 1 INTRODUCTION The most active research area for video databases today is Video-on-Demand (VOD). VOD services which will allow users to search for movies and videos stored on a digital video server <ref> [5, 13, 14, 18] </ref>. Today, many libraries and archives - e.g., television archives have huge amounts of videos and/or films.
Reference: 15. <author> W.E. Mackay and G. Davenport. </author> <title> Virtual Video Editing In Interactive Multimedia Applications. </title> <journal> Communications of the ACM, </journal> <volume> 32(7) </volume> <pages> 802-810, </pages> <year> 1989. </year>
Reference-contexts: None of these have yet described integrated solutions for video archives which support a range of users and applications. Researchers at MIT have developed ideas and tools for supporting video editing (e.g., Algebraic Video System [23]) and annotation (e.g., EVA <ref> [15] </ref> and Stratosphere [20]). From a general video archive point of view, the problems with these tools are the lack of support for managing video document structures. In addition, the proposed annotation tools are based on unformatted, free text descriptions of the contents.
Reference: 16. <author> E. Oomoto and K. Tanaka. OVID: </author> <title> Design and Implementation of a Video-Object Database System. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 5(4) </volume> <pages> 629-643, </pages> <year> 1993. </year>
Reference-contexts: The disadvantage with these tools is that, when applied to pieces of video with complex or vague structure, they do not manage to group frames and shots into semantically meaningful entities such as scenes and sequences. The Virtual Video Browser [13], the Video Database Browser [18], and OVID <ref> [16] </ref> are experimental video database systems that provide content-based querying. Neither of these systems offers tools for structure and contents browsing in the way described in Section 2, and efficient annotation tools have not been proposed.
Reference: 17. <institution> Parallax Graphics, Inc. </institution> <note> XVideo User's Guide, </note> <year> 1991. </year>
Reference-contexts: The video player is implemented on a Sun workstation. In the current version the videos are recorded as JPEG-compressed files [22]. To get an acceptable performance, we use a Parallax XVideo board <ref> [17] </ref> for video compression/decompression. 4.2 The Video Document Browser We have two main types of meta-data related to a video document: content annotations, and structure information. Both of these have temporal aspects - i.e., they are only applicable to a specific part of a video document.
Reference: 18. <author> L.A. Rowe, J.S. Boreczky, </author> <title> and C.A. Eads. Indexes for User Access to Large Video Databases. </title> <booktitle> In Proceedings of the IS&T/SPIE Symposium on Electronic Imaging Science and Technology, Conference on Storage and Retrieval for Image and Video Databases II, </booktitle> <address> San Jose, CA, </address> <month> February </month> <year> 1994. </year>
Reference-contexts: 1 INTRODUCTION The most active research area for video databases today is Video-on-Demand (VOD). VOD services which will allow users to search for movies and videos stored on a digital video server <ref> [5, 13, 14, 18] </ref>. Today, many libraries and archives - e.g., television archives have huge amounts of videos and/or films. <p> The disadvantage with these tools is that, when applied to pieces of video with complex or vague structure, they do not manage to group frames and shots into semantically meaningful entities such as scenes and sequences. The Virtual Video Browser [13], the Video Database Browser <ref> [18] </ref>, and OVID [16] are experimental video database systems that provide content-based querying. Neither of these systems offers tools for structure and contents browsing in the way described in Section 2, and efficient annotation tools have not been proposed.
Reference: 19. <author> P. Schnorf. </author> <title> Integrating Video into an Application Framework. </title> <booktitle> In Proceedings of ACM Multimedia 93, </booktitle> <address> Anaheim, USA, </address> <month> August </month> <year> 1993, </year> <pages> pp. 411-417. </pages>
Reference-contexts: This API provides a higher level interface than the one proposed by Schnorf <ref> [19] </ref>. * An API for searching, browsing, accessing, and ma nipulating the contents of the four repositories. The main reason for developing this framework is to provide a platform for development of video applications that share video information.
Reference: 20. <author> T.G.A. Smith and N.C. Pincever. </author> <title> Parsing Movies in Context. </title> <booktitle> In Proceedings of the 1991 Summer USENIX Conference, </booktitle> <address> Nashville, USA, </address> <year> 1991, </year> <pages> pp. 157-167. </pages>
Reference-contexts: None of these have yet described integrated solutions for video archives which support a range of users and applications. Researchers at MIT have developed ideas and tools for supporting video editing (e.g., Algebraic Video System [23]) and annotation (e.g., EVA [15] and Stratosphere <ref> [20] </ref>). From a general video archive point of view, the problems with these tools are the lack of support for managing video document structures. In addition, the proposed annotation tools are based on unformatted, free text descriptions of the contents.
Reference: 21. <author> S.W. Smoliar and H. Zhang. </author> <title> Content-Based Video Indexing and Retrieval. </title> <journal> IEEE Multimedia, </journal> <volume> 1(2) </volume> <pages> 62-72, </pages> <month> Summer </month> <year> 1994. </year>
Reference-contexts: In addition, the proposed annotation tools are based on unformatted, free text descriptions of the contents. A digital video archive serving different categories of users should offer a more structured way of describing video contents. Some researchers have tried to develop tools for automatic segmentation of video material <ref> [7, 21] </ref> - i.e., identifying cuts in a video document. These tools are interesting preprocessing tools in a video archive for segmenting video documents, especially when the edit decision list is not explicitly available. Some tools have also been proposed for temporal browsing of video [1, 4, 21]. <p> These tools are interesting preprocessing tools in a video archive for segmenting video documents, especially when the edit decision list is not explicitly available. Some tools have also been proposed for temporal browsing of video <ref> [1, 4, 21] </ref>. These tools are best applicable when the structure of the video follow a stringent, predefined syntax; i.e., television news. <p> Parts of this problem could be reduced if the system had access to shot boundaries from editing tools like Avid [2], or if shot detecting tools <ref> [7, 21] </ref> were employed as preprocessing tools. From the use of the video annotator, we have experienced that in most cases it is sensible to divide the registration process into two separate tasks: The first task consists of determining the structure components.
Reference: 22. <author> G.K. Wallace. </author> <title> The JPEG Still Picture Compression Standard. </title> <journal> Communications of the ACM, </journal> <volume> 34(4) </volume> <pages> 30-44, </pages> <year> 1991. </year>
Reference-contexts: The video player is implemented on a Sun workstation. In the current version the videos are recorded as JPEG-compressed files <ref> [22] </ref>. To get an acceptable performance, we use a Parallax XVideo board [17] for video compression/decompression. 4.2 The Video Document Browser We have two main types of meta-data related to a video document: content annotations, and structure information.
Reference: 23. <author> R. Weiss, A. Duda, and D.K. Gifford. </author> <title> Composition and Search with a Video Algebra. </title> <journal> IEEE MultiMedia, </journal> <volume> 2(1) </volume> <pages> 12-25, </pages> <month> Spring </month> <year> 1995. </year> <month> 293 </month>
Reference-contexts: None of these have yet described integrated solutions for video archives which support a range of users and applications. Researchers at MIT have developed ideas and tools for supporting video editing (e.g., Algebraic Video System <ref> [23] </ref>) and annotation (e.g., EVA [15] and Stratosphere [20]). From a general video archive point of view, the problems with these tools are the lack of support for managing video document structures. In addition, the proposed annotation tools are based on unformatted, free text descriptions of the contents.
References-found: 23

