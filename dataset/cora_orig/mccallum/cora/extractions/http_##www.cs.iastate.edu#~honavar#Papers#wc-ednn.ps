URL: http://www.cs.iastate.edu/~honavar/Papers/wc-ednn.ps
Refering-URL: http://www.cs.iastate.edu/~honavar/honavar.html
Root-URL: 
Email: balakris@cs.iastate.edu, honavar@cs.iastate.edu  
Title: Some Experiments in Evolutionary Synthesis of Robotic  
Author: Neurocontrollers Karthik Balakrishnan and Vasant Honavar 
Address: Ames, IA 50011  
Affiliation: Artificial Intelligence Research Group Iowa State University,  
Abstract: Artificial neural networks provide an attractive approach for design of control mechanisms in robots and autonomous agents. However, designing appropriate networks to realize task-specific behaviors is a difficult task. Evolutionary algorithms offer one approach to automating this task. In this paper, we explore a task requiring a robot to clear an arena by pushing boxes off to the sides. We show how evolution can be successfully used to discover high-fitness designs in task environments of differing properties and constraints. An analysis of the evolved networks sheds light on how the resulting designs are tailored to meet the constraints imposed by the environment.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Balakrishnan and V. Honavar, </author> <title> "Analysis of neurocontrollers designed by simulated evolution," </title> <booktitle> in Proceedings of IEEE International Conference on Neural Networks ICNN'96, </booktitle> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: Desirable properties of such mechanisms include efficiency, reliability, and robustness in the presence of faults and noise. Artificial neural networks are therefore offer an attractive paradigm for the design of such behavioral control mechanisms <ref> [5, 3, 1] </ref>. However, designing a good neurocontroller for a given robotic application is not an easy task, since we need to determine the appropriate network architecture (number of units, connectivity pattern, activation functions etc.), and also the the right connection strengths (weights). <p> Since Evolutionary Algorithms (EAs) are potentially useful procedures for searching large, complex, multi-modal, and deceptive search spaces [6, 4], a number of researchers have employed them for searching the space of neurocontroller designs <ref> [8, 3, 7, 1] </ref>. EAs offer the benefits of a population-based search (hence the possibility of avoiding local optima) and can potentially search the space of network architectures, in addition to the more common search in the space of weights within a-priori fixed network architectures. <p> In each trial, the robot was placed in a randomly chosen empty cell, facing a random direction and allowed to perform O (N 3 ) = 216 actions (where each action takes one time step). For reasons mentioned in <ref> [1] </ref>, Teller's simulation time estimate of O (N 2 ) = 80 was not used. At the end of 216 time steps each box against the wall was awarded one point, while boxes in the corners fetched one extra point. <p> Here evolution starts off with feedforward networks, but through low probability mutation, retains the ability to add recurrent links (if need be). We have found this approach to work well in designing networks with few recurrent links <ref> [1] </ref>. The absence of a link is represented by a zero value at the corresponding weight position (see Figure 2). <p> For the purposes of keeping the analysis simple and the discussion focused, we have chosen to explore networks without any hidden units, although the addition of hidden units is seen to improve performance considerably <ref> [1] </ref>. In addition, only one kind of sensor was simulated in our experiments. 4.1. No Feedback and No Faulty Sensors In this set of experiments, we followed the task specification of section 2. <p> This fitness figure, which we call corrected fitness, is 4:07 for the best network. This also happens to be the network with the best labeled fitness (5:03), and is shown in Figure 3. As observed in <ref> [1] </ref>, the evolved neurocontrollers have a large negative self-loop at the output unit coding for action (labeled A in the figure). <p> Such an arrangement biases the robots to interleave actions of moving forward and turning, thereby preventing them from getting into states in which they might be stuck till the end of simulation. This feature allows such robots to achieve high fitnesses on this simulation task <ref> [1] </ref>. Fig. 3: Evolution of neurocontroller alone. The figure on the left shows the eight active sensors. Also notice the large negative self-loop at the action unit A. 4.2.
Reference: [2] <author> K. Balakrishnan and V. Honavar, </author> <title> "On sensor evolution in robotics," </title> <booktitle> in Proceedings of Genetic Programming Conference - GP-96, </booktitle> <year> 1996. </year>
Reference-contexts: The model of sensor faults used in this paper is equivalent to introducing noise into the system, which helps the robots break out of fixed cycles. Recently we have also been looking at sensor evolution <ref> [2] </ref> | where the sensory systems of robots are also designed in addition to the usual practice of designing just their controllers. Our results indicate that such approaches lead to extremely efficient, yet highly fit designs.
Reference: [3] <author> D. Floreano and F. Mondada, </author> <title> "Automatic creation of an autonomous agent: Genetic evolution of a neural-network driven robot," </title> <booktitle> in From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior, </booktitle> <editor> (D. Cliff, P. Husbands, J.-A. Meyer, and S. Wilson, eds.), </editor> <address> (Cambridge, MA), </address> <pages> pp. 421-430, </pages> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: Desirable properties of such mechanisms include efficiency, reliability, and robustness in the presence of faults and noise. Artificial neural networks are therefore offer an attractive paradigm for the design of such behavioral control mechanisms <ref> [5, 3, 1] </ref>. However, designing a good neurocontroller for a given robotic application is not an easy task, since we need to determine the appropriate network architecture (number of units, connectivity pattern, activation functions etc.), and also the the right connection strengths (weights). <p> Since Evolutionary Algorithms (EAs) are potentially useful procedures for searching large, complex, multi-modal, and deceptive search spaces [6, 4], a number of researchers have employed them for searching the space of neurocontroller designs <ref> [8, 3, 7, 1] </ref>. EAs offer the benefits of a population-based search (hence the possibility of avoiding local optima) and can potentially search the space of network architectures, in addition to the more common search in the space of weights within a-priori fixed network architectures.
Reference: [4] <author> D. Goldberg, </author> <title> Genetic Algorithms in Search, Optimization, </title> <booktitle> and Machine Learning. </booktitle> <address> Reading, MA: </address> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: This design problem further worsens if one is additionally interested in optimizing other criteria like power consumption, space occupied etc. (if the neurocontroller is to be realized in hardware). Since Evolutionary Algorithms (EAs) are potentially useful procedures for searching large, complex, multi-modal, and deceptive search spaces <ref> [6, 4] </ref>, a number of researchers have employed them for searching the space of neurocontroller designs [8, 3, 7, 1]. <p> For reasons mentioned in section 1, we use EAs to search for such designs. Fig. 1: The operating environment. Shaded squares represent boxes and unshaded ones, empty space. Fig. 2: Genetic representation used. 3. Implementation Details In our simulations we use Genetic Algorithms (GAs) <ref> [6, 4] </ref> to evolve sensory and neurocontroller designs.
Reference: [5] <author> I. Harvey, P. Husbands, and D. Cliff, </author> <booktitle> "Issues in evolutionary robotics," in From Animals to Animats II: Proceedings of the Second International Conference on Simulation of Adaptive Behavior, </booktitle> <editor> (J. Meyer, H. Roitblat, and S. Wilson, eds.), </editor> <address> (Cambridge, MA), </address> <pages> pp. 364-373, </pages> <publisher> MIT Press-Bradford Books, </publisher> <year> 1992. </year>
Reference-contexts: Desirable properties of such mechanisms include efficiency, reliability, and robustness in the presence of faults and noise. Artificial neural networks are therefore offer an attractive paradigm for the design of such behavioral control mechanisms <ref> [5, 3, 1] </ref>. However, designing a good neurocontroller for a given robotic application is not an easy task, since we need to determine the appropriate network architecture (number of units, connectivity pattern, activation functions etc.), and also the the right connection strengths (weights).
Reference: [6] <author> J. Holland, </author> <booktitle> Adaptation in Natural and Artificial Systems. </booktitle> <address> Ann Arbor: </address> <publisher> The University of Michigan Press, </publisher> <year> 1975. </year>
Reference-contexts: This design problem further worsens if one is additionally interested in optimizing other criteria like power consumption, space occupied etc. (if the neurocontroller is to be realized in hardware). Since Evolutionary Algorithms (EAs) are potentially useful procedures for searching large, complex, multi-modal, and deceptive search spaces <ref> [6, 4] </ref>, a number of researchers have employed them for searching the space of neurocontroller designs [8, 3, 7, 1]. <p> For reasons mentioned in section 1, we use EAs to search for such designs. Fig. 1: The operating environment. Shaded squares represent boxes and unshaded ones, empty space. Fig. 2: Genetic representation used. 3. Implementation Details In our simulations we use Genetic Algorithms (GAs) <ref> [6, 4] </ref> to evolve sensory and neurocontroller designs.
Reference: [7] <author> O. Miglino, K. Nafasi, and C. Taylor, </author> <title> "Selection for wandering behavior in a small robot," </title> <journal> Artificial Life, </journal> <volume> vol. 2, no. 1, </volume> <pages> pp. 101-116, </pages> <year> 1994. </year>
Reference-contexts: Since Evolutionary Algorithms (EAs) are potentially useful procedures for searching large, complex, multi-modal, and deceptive search spaces [6, 4], a number of researchers have employed them for searching the space of neurocontroller designs <ref> [8, 3, 7, 1] </ref>. EAs offer the benefits of a population-based search (hence the possibility of avoiding local optima) and can potentially search the space of network architectures, in addition to the more common search in the space of weights within a-priori fixed network architectures.
Reference: [8] <author> S. Nolfi, J. Elman, and D. Parisi, </author> <title> "Learning and evolution in neural networks," </title> <booktitle> Adaptive Behavior, </booktitle> <volume> vol. 3, no. 1, </volume> <pages> pp. 5-28, </pages> <year> 1994. </year>
Reference-contexts: Since Evolutionary Algorithms (EAs) are potentially useful procedures for searching large, complex, multi-modal, and deceptive search spaces [6, 4], a number of researchers have employed them for searching the space of neurocontroller designs <ref> [8, 3, 7, 1] </ref>. EAs offer the benefits of a population-based search (hence the possibility of avoiding local optima) and can potentially search the space of network architectures, in addition to the more common search in the space of weights within a-priori fixed network architectures.
Reference: [9] <author> A. Teller, </author> <title> "The evolution of mental models," </title> <booktitle> in Advances in Genetic Programming, </booktitle> <editor> (K. Kinnear, </editor> <publisher> ed.), </publisher> <pages> pp. 199-219, </pages> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: The Task The robotic simulation we consider in this paper was proposed by Teller <ref> [9] </ref>. Here the robot is placed in a square arena of N fi N cells, in which M boxes are randomly scattered in the inner (N 2) fi (N 2) grid. The arena is enclosed by impenetrable walls as shown in Figure 1. <p> On a turn action, the actual direction of turn is given by the output of the turn unit (-1 for clockwise and +1 for anti-clockwise). The general framework for the simulation experiments was borrowed from <ref> [9] </ref> which describes Teller's attempts at evolving control programs using genetic programming. Thus we used 6 fi 6 arenas, with 6 boxes randomly distributed in the inner 4 fi 4 grid.
References-found: 9

