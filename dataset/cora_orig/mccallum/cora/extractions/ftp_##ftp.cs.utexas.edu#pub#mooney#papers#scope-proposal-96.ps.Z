URL: ftp://ftp.cs.utexas.edu/pub/mooney/papers/scope-proposal-96.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/ml/abstracts.html
Root-URL: 
Email: estlin@cs.utexas.edu  
Title: Integrating Explanation-Based and Inductive Learning Techniques to Acquire Search-Control for Planning  
Author: Tara A. Estlin 
Note: This research was supported by the NASA Graduate Student Researchers Program, grant number NGT 51332.  
Address: Austin, TX 78712  
Affiliation: Department of Computer Sciences University of Texas at Austin  
Abstract: Technical Report AI96-250 September 1996 Abstract Planning systems have become an important tool for automating a wide variety of tasks. Control knowledge guides a planner to find solutions quickly and is crucial for efficient planning in most domains. Machine learning techniques enable a planning system to automatically acquire domain-specific search-control knowledge for different applications. Past approaches to learning control information have usually employed explanation-based learning (EBL) to generate control rules. Unfortunately, EBL alone often produces overly complex rules that actually decrease rather than improve overall planning efficiency. This paper presents a novel learning approach for control knowledge acquisition that integrates explanation-based learning with techniques from inductive logic programming. In our learning system Scope, EBL is used to constrain an inductive search for control heuristics that help a planner choose between competing plan refinements. Scope is one of the few systems to address learning control information for newer, partial-order planners. Specifically, this proposal describes how Scope learns domain-specific control rules for the UCPOP planning algorithm. The resulting system is shown to produce significant speedup in two different planning domains, and to be more effective than a pure EBL approach. Future research will be performed in three main areas. First, Scope's learning algorithm will be extended to include additional techniques such as constructive induction and rule utility analysis. Second, Scope will be more thoroughly tested; several real-world planning domains have been identified as possible testbeds, and more in-depth comparisons will be drawn between Scope and other competing approaches. Third, Scope will be implemented in a different planning system in order to test its portability to other planning algorithms. This work should demonstrate that machine-learning techniques can be a powerful tool in the quest for tractable real-world planning. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Andrews, S., Kettler, B., Erol, K., & Hendler, J. </author> <year> (1995). </year> <title> UM Translog: A planning domain for the development and benchmarking of planning systems. </title> <type> Tech. rep. </type> <institution> CS-TR-3487, Institute for Advanced Computer Studies, University of Maryland. </institution>
Reference-contexts: Several domains have already been identified that would provide an interesting testbed for future experiments. The first is the UM Translog domain being developed at the University of Maryland. UM Translog <ref> (Andrews et al., 1995) </ref> was inspired by the logistics transportation domain used in Section 5, however, it is an order of magnitue larger in size (41 actions vs. 6) and provides more complex features and goal interactions.
Reference: <author> Barrett, A., & Weld, D. </author> <year> (1994). </year> <title> Partial order planning: Evaluating possible efficiency gains. </title> <journal> Artificial Intelligence, </journal> <volume> 67, </volume> <pages> 71-112. </pages>
Reference: <author> Barrett, A., Golden, K., Penberthy, S., & Weld, D. </author> <year> (1993). </year> <title> UCPOP: User's manual (version 2.0). </title> <type> Tech. rep. </type> <institution> 93-09-06, Department of Computer Science and Engineering, University of Washington. </institution>
Reference-contexts: The most significant difference is that our Prolog planner operates using a depth-first backtracking search with a depth bound, while UCPOP normally employs a best-first search strategy. 3 To evaluate the efficiency of our planner as compared to the standard LISP implementation of UCPOP (v2.0) <ref> (Barrett et al., 1993) </ref>, we ran several experiments using problem sets from two domains. These problem sets are also used for testing the learning algorithm, and are discussed in Section 5. In these tests, our planner performed comparably to UCPOP and in some cases, performed better.
Reference: <author> Bhatnagar, N., & Mostow, J. </author> <year> (1994). </year> <title> On-line learning from search failure. </title> <journal> Machine Learning, </journal> <volume> 15, </volume> <pages> 69-117. </pages>
Reference-contexts: Static (Etzioni, 1993) acquires control rules by analyzing the problem domain theory. This system uses EBL to analyze a graph structure that captures the precondition/effect depen 25 dencies between the actions in the domain. This analysis is then used to derive goal-ordering rules for the Prodigy state-based planner. Failsafe <ref> (Bhatnagar & Mostow, 1994) </ref> was designed to learn control rules in domains where the underlying domain theory was recursive. Failsafe uses a forward-searching state-based planner and learns by building incomplete explanations of its execution time failures. Not all learning approaches have relied on EBL.
Reference: <author> Borrajo, D., & Veloso, M. </author> <year> (1994a). </year> <title> Incremental learning of control knowledge for improvement of planning efficiency and plan quality. </title> <booktitle> In AAAI-94 Fall Symposium on Planning and Learning, </booktitle> <pages> pp. </pages> <address> 5-9 New Orleans, LA. </address>
Reference: <author> Borrajo, D., & Veloso, M. </author> <year> (1994b). </year> <title> Incremental learning of control knowledge for nonlinear problem solving. </title> <booktitle> In Proceedings of the European Conference on Machine Learning, ECML-94, </booktitle> <pages> pp. </pages> <publisher> 64-82 Springer Verlag. </publisher>
Reference-contexts: Removing the linearity assumption adds further complications for learning search-control not addressed by these early systems, since many more search paths must be considered. Unfortunately, very few systems have been built to acquire control knowledge for more modern planning techniques. Hamlet <ref> (Borrajo & Veloso, 1994b) </ref> is one more recent system, which learns control knowledge for the nonlinear planner underlying Prodigy4.0. Hamlet uses a combination of EBL with induction to acquire control rules. Hamlet first generates a bounded explanation of each planning decision and then incrementally refines any incomplete or inaccurate explanations. <p> It is thus unclear, how Hamlet would perform on a partial-order (or plan-space) planner. Hamlet has successfully improved the performance of the Prodigy4.0 planner in the blocksworld and logistics planning domains. When comparing to the results reported in <ref> (Borrajo & Veloso, 1994b) </ref>, Scope achieves a greater speedup factor in blocksworld (11.3 vs 1.8) and in the logistics domain (5.3 vs 1.8).
Reference: <author> Chase, M., Zweben, M., Piazza, R., Burger, J., Maglio, P., & Hirsh, H. </author> <year> (1989). </year> <title> Approximating learned search control knowledge. </title> <booktitle> In Proceedings of the Sixth International Workshop on Machine Learning, </booktitle> <pages> pp. </pages> <address> 40-42 Ithaca, NY. </address>
Reference-contexts: Scope, on the other hand, uses induction to select the most useful pieces of EBG generalizations. Some work has also been done on learning approximations to EBL rules. The ULS system <ref> (Chase et al., 1989) </ref> acquired conservative approximations to EBL rules by simply dropping one or two conditions. ULS was very limited in the rules it could generate, unlike Scope, which uses an inductive learning mechanism to build rules from scratch.
Reference: <author> Chien, S. </author> <year> (1989). </year> <title> Using and refining simplifications: Explanation-based learning of plans in intractable domains. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence Detroit, </booktitle> <address> MI. </address>
Reference-contexts: This situation is commonly known as the utility problem. EBL methods are also hard to apply in domains where it is difficult to construct a complete and tractable domain theory <ref> (Chien, 1989) </ref>. At the other extreme are inductive methods which learn through examining examples of positive and negative planning situations. These empirical methods build control rules by making inductive leaps based on some domain-independent bias such as an information-gain heuristic or Occam's razor (Quinlan, 1983).
Reference: <author> Chien, S., & DeJong, G. </author> <year> (1994). </year> <title> Incremental reasoning in explanation-based learning of plans. </title> <booktitle> In Proceedings of the Second International Conference of AI Planning Systems Chicago. </booktitle> <volume> 31 Chien, </volume> <editor> S., Hill, R., Wang, X., Estlin, T., Fayyad, K., & Mortensen, H. </editor> <year> (1995). </year> <title> Why real--world planning is difficult: A tale of two applications. </title> <booktitle> In Proceedings of the Third European Workshop on Planning, </booktitle> <pages> pp. </pages> <address> 305-317 Assisi Italy. </address>
Reference: <author> Cohen, W. W. </author> <year> (1990). </year> <title> Learning approximate control rules of high utility. </title> <booktitle> In Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 268-276 Austin, TX. </address>
Reference-contexts: More recently, it has been argued that ILP techniques can also be a useful tool for acquiring control information <ref> (Cohen, 1990) </ref>. Many different problem solving strategies can be easily coded as Prolog programs and learning mechanisms are also easily implemented in this framework. <p> In Prolog, depth-first search with backtracking is used to search for a proof. If during execution the current search path fails, then the last deterministic decision point is backtracked upon and a new path explored. Search control in a Prolog program can be viewed as a clause selection problem <ref> (Cohen, 1990) </ref>, where clause selection is the process of deciding what program clause should be used to reduce a particular subgoal during program execution. Different options in a program are represented using separate clauses which have equivalent heads but different clause bodies. <p> ULS was very limited in the rules it could generate, unlike Scope, which uses an inductive learning mechanism to build rules from scratch. A more closely related system is AxA-EBL <ref> (Cohen, 1990) </ref>, which integrates an induction mechanism to learn approximate EBL rules. AxA-EBL first learns a control rule by applying EBG to the proof of a correct control decision.
Reference: <author> DeJong, G. F., & Mooney, R. J. </author> <year> (1986). </year> <title> Explanation-based learning: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1 (2), </volume> <pages> 145-176. </pages> <note> Reprinted in Readings in Machine Learning, </note> <editor> J. </editor> <publisher> W. </publisher>
Reference: <editor> Shavlik and T. G. Dietterich (eds.), </editor> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference: <author> Erol, K., Nau, D., & Hendler, J. </author> <year> (1994a). </year> <title> HTN planning: Complexity and expressivity. </title> <booktitle> In Proceedings of the Eleventh National Conference on Ariticial Intelligence Seattle. </booktitle>
Reference-contexts: We intend to apply Scope to at least one different planning algorithm in hopes of achieving similar performance gains. There are several other types of planners besides partial-order that are prominent in the planning community today. One is an hierarchical-task network (HTN) planner <ref> (Erol et al., 1994a) </ref>. As opposed to most operator-based planners, HTN planners specify plan modifications in terms of task reduction rules. These reduction rules are then used to decompose abstract goals into lower level tasks.
Reference: <author> Erol, K., Nau, D., & Hendler, J. </author> <year> (1994b). </year> <title> UMCP: A sound and complete planning procedure for hierarchical task-network planning. </title> <booktitle> In Proceedings of the Second International Conference of AI Planning Systems Chicago. </booktitle>
Reference-contexts: HTN planners are argued by some researchers to be more useful for real-world applications since they offer more flexibility in expressing domain knowledge. There are several well-developed HTN algorithms that would be good testbeds for Scope. These include UMCP <ref> (Erol et al., 1994b) </ref>, developed at the University of Maryland, and COLLAGE (Lansky & Getoor, 1995), developed at the NASA Ames Research Center. Another breed of planners that we will consider are those that use a combination of plan-space and state-space techniques.
Reference: <author> Etzioni, O. </author> <year> (1993). </year> <title> Acquiring search control knowledge via static analysis. </title> <journal> Artificial Intelligence, </journal> <volume> 60 (2). </volume>
Reference-contexts: Rules are learned that can select, reject, or prefer refinement candidates for several different decision types. A number of other systems have also applied EBL to learn search-control for planning. Static <ref> (Etzioni, 1993) </ref> acquires control rules by analyzing the problem domain theory. This system uses EBL to analyze a graph structure that captures the precondition/effect depen 25 dencies between the actions in the domain. This analysis is then used to derive goal-ordering rules for the Prodigy state-based planner.
Reference: <author> Fargher, H., & Smith, R. </author> <year> (1994). </year> <title> Planning in a flexible semiconductor manufacturing environment. In Zweben, </title> <editor> M., & Fox, M. (Eds.), </editor> <booktitle> Intelligent Scheduling, </booktitle> <pages> pp. 545-580. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, CA. </address>
Reference-contexts: Given a set of goals, these systems are designed to output a list of actions that can be used by an execution agent to perform a task with little or no human intervention. Planning systems are currently used to perform a range of activities from manufacturing semiconductors <ref> (Fargher & Smith, 1994) </ref> to scheduling antenna communications with orbiting spacecraft (Chien et al., 1995). As the desire for automation grows more prevalent in today's society, the need for efficient planning systems grows as well.
Reference: <author> Fikes, R., & Nilsson, N. </author> <year> (1971). </year> <title> STRIPS: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 2 (3/4). </volume>
Reference-contexts: In most standard approaches to planning, domain actions (or operators) are represented in a STRIPS format <ref> (Fikes & Nilsson, 1971) </ref>, which consists of a list of preconditions, an add list and a delete list. For example, the four operator schemas from the well-known blocksworld domain (Nilsson, 1980) are shown in Figure 1. <p> Operators are specified using a representation similar to the well-known STRIPS format <ref> (Fikes & Nilsson, 1971) </ref>, where operators contain precondition, add and delete lists. 1 UCPOP searches in a space of partial plans, where each plan consists of a partial-ordering of actions.
Reference: <author> Gil, Y. </author> <year> (1991). </year> <title> A specification of manufacturing processes for planning. </title> <type> Tech. rep. </type> <institution> CMU-CS-91-179, School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA. </address>
Reference-contexts: The detailed set of operators in this domain provide for long plans (an average of 40 steps) with many possible solutions to the same problem. The Prodigy Process Planning domain <ref> (Gil, 1991) </ref> is another large-scale complex domain that could be used to further evaluate Scope's learning algorithm. This domain incorporates detailed knowledge about the automation of manufacturing processes and is one of the largest domains available for general-purpose planners. Actions include activites such as machining, joining and finishing of parts.
Reference: <author> Gratch, J., & DeJong, G. </author> <year> (1992). </year> <title> COMPOSER: A probabilistic solution to the utility problem in speed-up learning. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 235-240 San Jose, CA. </address>
Reference: <author> Greiner, R., & Likuski, J. </author> <year> (1989). </year> <title> Incorporating redundant learned rules: A preliminary formal analysis of ebl. </title> <booktitle> In Proceedings of the Eleventh International Conference on Ariticial Intelligence, </booktitle> <pages> pp. </pages> <address> 744-749 Detroit, MI. </address>
Reference: <author> Kambhampati, S., & Chen, J. </author> <year> (1993). </year> <title> Relative utility of EBG based plan reuse in partial ordering vs. total ordering. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 514-519 Washington, D.C. </address>
Reference: <author> Kambhampati, S., Katukam, S., & Qu, Y. </author> <year> (1996). </year> <title> Failure driven search control for partial order planners: An explanation based approach. </title> <journal> Artificial Intelligence, Forthcoming. </journal>
Reference-contexts: Further extensions to Scope should improve the overall accuracy of learned rules and further increase performance results in these domains. 5.3 Comparison to Other Systems Only one other learning system has been developed to learn search-control rules for a partial-order planner. UCPOP+EBL <ref> (Kambhampati et al., 1996) </ref> uses standard explanation-based learning to generate control rules in response to planning failures and is discussed in more detail in Section 6. To compare the two systems, we replicated an experiment used by Kamb-hampati et al. (1996). <p> Positive and negative examples of problem solver behavior are identified (Mitchell et al., 1983; Langley, 1985), and then control heuristics are learned to cover the positive examples and rule out the negatives. Several early approaches 7 In order to replicate the experiments of <ref> (Kambhampati et al., 1996) </ref>, the blocksworld domain theory used for these tests slightly differed from the one used for the experiments presented in Section 5. <p> However, since different problem distributions were used in these experiments and Hamlet is built upon a different planning platform, we can only draw a rough comparison between Hamlet and Scope. The only system besides Scope to learn control information for partial-order planning is UCPOP+EBL <ref> (Kambhampati et al., 1996) </ref>. This system also learns search control rules for UCPOP, but uses a purely explanation-based approach. Specifically, UCPOP+EBL employs the standard EBL techniques of regression, explanation propagation and rule generation to acquire search-control rules. Rules are learned only in response to past planning failures.
Reference: <author> Kambhampati, S., & Srivastava, B. </author> <year> (1995). </year> <title> Universal classical planner: An algorithm for unifying state-space and plan-space planning. </title> <booktitle> In Proceedings of the Third European Workshop on Planning, </booktitle> <pages> pp. </pages> <address> 81-94 Assisi Italy. </address> <note> 32 Katukam, </note> <author> S., & Kambhampati, S. </author> <year> (1994). </year> <title> Learning explanation-based search control for partial order planning. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 582-587 Seattle,WA. </pages>
Reference: <author> Keller, R. </author> <year> (1987). </year> <title> The Role of Explicit Contextual Knowledge in Learning Concepts to Improve Performance. </title> <type> Ph.D. thesis, </type> <institution> Rutgers University, </institution> <address> New Brunswick, N. </address> <note> Also appears as tech. report ML-TR-7. </note>
Reference-contexts: Both domains employed similar predicates however the Section 5 domain definition consists of four operators while the domain used here has only two. 24 also used a combination of induction and EBL to learn control information. The LEX-2 (Mitchell et al., 1983) and MetaLEX <ref> (Keller, 1987) </ref> systems constructed rules by inducing over complete explanation-based generalizations of problem-solving traces. Scope, on the other hand, uses induction to select the most useful pieces of EBG generalizations. Some work has also been done on learning approximations to EBL rules.
Reference: <author> Kijsirikul, B., Numao, M., & Shimura, M. </author> <year> (1992). </year> <title> Discrimination-based constructive induction of logic programs. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 44-49 San Jose, CA. </address>
Reference: <author> Langley, P. </author> <year> (1985). </year> <title> Learning to search: From weak methods to domain specific heuristics. </title> <journal> Cognitive Science, </journal> <volume> 9 (2), </volume> <pages> 217-260. </pages>
Reference: <author> Langley, P., & Allen, J. </author> <year> (1991). </year> <title> The acquisition of human planning expertise. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pp. 80-84 Evanston,IL. </pages>
Reference: <author> Lansky, A., & Getoor, L. </author> <year> (1995). </year> <title> Scope and abstraction: Two criteria for localized planning. </title> <booktitle> In Proceedings of the Fourteenth International Conference on Ariticial Intelligence, </booktitle> <pages> pp. </pages> <address> 1612-1618 Montreal, CA. </address>
Reference-contexts: There are several well-developed HTN algorithms that would be good testbeds for Scope. These include UMCP (Erol et al., 1994b), developed at the University of Maryland, and COLLAGE <ref> (Lansky & Getoor, 1995) </ref>, developed at the NASA Ames Research Center. Another breed of planners that we will consider are those that use a combination of plan-space and state-space techniques.
Reference: <editor> Lavrac, N., & Dzeroski, S. (Eds.). </editor> <year> (1994). </year> <title> Inductive Logic Programming: Techniques and Applications. </title> <publisher> Ellis Horwood. </publisher>
Reference: <author> Leckie, C., & Zuckerman, I. </author> <year> (1993). </year> <title> An inductive approach to learning search control rules for planning. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 1100-1105 Chamberry,France. </pages>
Reference-contexts: Failsafe (Bhatnagar & Mostow, 1994) was designed to learn control rules in domains where the underlying domain theory was recursive. Failsafe uses a forward-searching state-based planner and learns by building incomplete explanations of its execution time failures. Not all learning approaches have relied on EBL. Grasshopper <ref> (Leckie & Zuckerman, 1993) </ref> uses an inductive approach to learn planning control knowledge. Given a set of training examples, Grasshopper looks for sets of similar decisions that could form the basis for search-control rules.
Reference: <author> Markovitch, S., & Scott, P. D. </author> <year> (1989). </year> <title> Utilization filtering: A method for reducing the inherent harmfulness of deductively learning knowledge. </title> <booktitle> In Proceedings of the Eleventh International Conference on Ariticial Intelligence, </booktitle> <pages> pp. </pages> <address> 738-743 Detroit, MI. </address>
Reference: <author> McDermott, D. </author> <year> (1991). </year> <title> Regression planning. </title> <journal> International Journal of Intelligent Systems, </journal> <volume> 6, </volume> <pages> 357-416. </pages>
Reference: <author> Minton, S. </author> <year> (1988). </year> <title> Quantitative results concerning the utility of explanation-based learning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 564-569 St. Paul, MN. </address>
Reference-contexts: Most past systems have employed explanation-based learning (EBL) to acquire search-control information. Unfortunately, standard EBL often produces complex, overly-specific control rules that decrease rather than improve overall planning performance <ref> (Minton, 1988) </ref>. This proposal presents a novel learning algorithm for automatically acquiring search-control knowledge for planning systems. Our learning system Scope uses a unique combination of machine learning techniques to acquire effective search-control rules for planning. <p> Unfortunately, due to its reliance on a only a few examples, standard EBL can often produce complex, overly-specific control rules that do not generalize well to new planning situations <ref> (Minton, 1988) </ref>. Even though the learned rules are correct, the cost of testing their applicability on new planning situations often outweighs their savings. This situation is commonly known as the utility problem. <p> The utility of individual rules can often dramatically vary and too many rules of low utility can even lead to lower performance <ref> (Minton, 1988) </ref>. This occurence, commonly known as the utility problem, can be prevented by only including the most useful control rules in the final planner. Thus, we would like to incorporate a method into Scope that directly evaluates control-rule utility.
Reference: <author> Minton, S. </author> <year> (1989). </year> <title> Explanation-based learning: A problem solving perspective. </title> <journal> Artificial Intelligence, </journal> <volume> 40, </volume> <pages> 63-118. </pages>
Reference-contexts: Most of this research has concentrated on linear, state-based planners. For instance, the Prodigy planning and learning system <ref> (Minton, 1989) </ref> employs a version of EBL to learn control rules for a linear, state-based planner. Rules are learned that can select, reject, or prefer refinement candidates for several different decision types. A number of other systems have also applied EBL to learn search-control for planning.
Reference: <author> Minton, S., Drummond, M., Bresina, J. L., & Phillips, A. B. </author> <year> (1992). </year> <title> Total order vs. partial order planning: Factors influencing performance. </title> <booktitle> In Proceedings of the Third International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pp. </pages> <note> 83-92 Cambridge,CA. 33 Mitchell, </note> <author> T., Utgoff, T., & Banerji, R. </author> <year> (1983). </year> <title> Learning problem solving heuristics by exper-imentation. </title> <editor> In Michalski, R., Mitchell, T., & Carbonell, J. (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Palo Alto, CA. </address>
Reference: <author> Mitchell, T. M., Keller, R. M., & Kedar-Cabelli, S. T. </author> <year> (1986). </year> <title> Explanation-based generalization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1 (1), </volume> <pages> 47-80. </pages>
Reference: <author> Mooney, R. J., & Califf, M. E. </author> <year> (1995). </year> <title> Induction of first-order decision lists: Results on learning the past tense of English verbs. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 3, </volume> <pages> 1-24. </pages>
Reference-contexts: have successfully induced small programs for simple tasks such as sorting and list manipulation (Muggleton & Buntine, 1988; Quinlan & Cameron-Jones, 1993); as well as performing well on more complicated tasks such as learning properties of organic molecules (Muggleton et al., 1992) and predicting the past tense of English verbs <ref> (Mooney & Califf, 1995) </ref>. More recently, it has been argued that ILP techniques can also be a useful tool for acquiring control information (Cohen, 1990). Many different problem solving strategies can be easily coded as Prolog programs and learning mechanisms are also easily implemented in this framework. <p> Any predicates that can be used as rule antecedents must be introduced as background knowledge. Scope uses an intensional version of Foil where background predicates can be defined as Prolog programs instead of requiring an extensional representation <ref> (Mooney & Califf, 1995) </ref>. One major drawback to Foil (and other similar inductive algorithms) is that the hill-climbing search for a good antecedent can easily explode, especially when there are numerous background predicates with large numbers of arguments.
Reference: <author> Muggleton, S., & Buntine, W. </author> <year> (1988). </year> <title> Machine invention of first-order predicates by inverting resolution. </title> <booktitle> In Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 339-352 Ann Arbor, MI. </address>
Reference: <author> Muggleton, S., King, R., & Sternberg, M. </author> <year> (1992). </year> <title> Protein secondary structure prediction using logic-based machine learning. </title> <journal> Protein Engineering, </journal> <volume> 5 (7), </volume> <pages> 647-657. </pages>
Reference-contexts: ILP systems have successfully induced small programs for simple tasks such as sorting and list manipulation (Muggleton & Buntine, 1988; Quinlan & Cameron-Jones, 1993); as well as performing well on more complicated tasks such as learning properties of organic molecules <ref> (Muggleton et al., 1992) </ref> and predicting the past tense of English verbs (Mooney & Califf, 1995). More recently, it has been argued that ILP techniques can also be a useful tool for acquiring control information (Cohen, 1990).
Reference: <author> Muggleton, S. H. (Ed.). </author> <year> (1992). </year> <title> Inductive Logic Programming. </title> <publisher> Academic Press, </publisher> <address> New York, NY. </address>
Reference-contexts: ILP systems have successfully induced small programs for simple tasks such as sorting and list manipulation (Muggleton & Buntine, 1988; Quinlan & Cameron-Jones, 1993); as well as performing well on more complicated tasks such as learning properties of organic molecules <ref> (Muggleton et al., 1992) </ref> and predicting the past tense of English verbs (Mooney & Califf, 1995). More recently, it has been argued that ILP techniques can also be a useful tool for acquiring control information (Cohen, 1990).
Reference: <author> Nilsson, N. </author> <year> (1980). </year> <booktitle> Principles of Artificial Intelligence. </booktitle> <publisher> Tioga, </publisher> <address> Palo Alto, CA. </address>
Reference-contexts: In most standard approaches to planning, domain actions (or operators) are represented in a STRIPS format (Fikes & Nilsson, 1971), which consists of a list of preconditions, an add list and a delete list. For example, the four operator schemas from the well-known blocksworld domain <ref> (Nilsson, 1980) </ref> are shown in Figure 1. In order for an action to be executed, its preconditions must be satisfied in the current state of the world.
Reference: <author> Pazzani, M., & Kibler, D. </author> <year> (1992). </year> <title> The utility of background knowledge in inductive learning. </title> <journal> Machine Learning, </journal> <volume> 9, </volume> <pages> 57-94. </pages>
Reference-contexts: Second, Foil has a "most general" bias which tends to produce simple definitions. Such a bias is important for learning rules with a low match cost, which helps avoid the utility problem. Third, it is relatively easy to bias Foil with prior knowledge <ref> (Pazzani & Kibler, 1992) </ref>. In our case, we can utilize the information contained in the generalized proof trees of planning solution traces. 4.2.1 Foil Algorithm Foil attempts to learn a concept definition in terms of a given set of background predicates.
Reference: <author> Penberthy, J., & Weld, D. S. </author> <year> (1992). </year> <title> UCPOP: A sound, complete, partial order planner for ADL. </title> <booktitle> In Proceedings of the Third International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pp. 113-114 Cambridge,MA. </pages>
Reference-contexts: Scope is implemented in Prolog, which provides a good framework for learning control knowledge. Many different problem solvers can be easily coded as Prolog programs and control knowledge is easy to incorporate. A version of the UCPOP planning algorithm <ref> (Penberthy & Weld, 1992) </ref> was implemented as a Prolog program to provide a testbed for Scope. In this paper, experimental results are presented on two planning domains that demonstrate Scope can significantly increase partial-order planning efficiency. Scope is also shown to outperform a competing approach based only on EBL. <p> This type of approach is widely used in many current planning systems and we felt a partial-order planner would provide an good testbed for our control learning system. 3.1 The UCPOP Planner The base planner we chose for experimentation is UCPOP <ref> (Penberthy & Weld, 1992) </ref>, a partial-order planner whose step descriptions can include conditional effects and universal quantification. UCPOP has been proven sound and complete, and a significant amount of planning research has been based around its algorithm. <p> For more details on the use of these constructs see <ref> (Penberthy & Weld, 1992) </ref>. 3 Kambhampati et al. (1996) also run UCPOP in a depth-first search mode in their control-rule learning system.
Reference: <author> Pendault, E. </author> <year> (1989). </year> <title> ADL: Exploring the middle ground between strips and the situation calculus. </title> <booktitle> In Proceedings of the First International Conference on Principles of Knowledge Representation and Reasoning. </booktitle>
Reference-contexts: A partial plan is best described as a four-tuple hS,B,O,Li: where S is a set of actions, O is a set of ordering constraints over S, L is a set of causal links, and B is a set 1 More specifically, operators are represented in Pednault's Action Description Language (ADL) <ref> (Pendault, 1989) </ref>, which is actually more expressive then STRIPS since it allows several additional constructs such as conditional effects and universal quantification.
Reference: <author> Perez, M. A., & Carbonell, J. </author> <year> (1994). </year> <title> Control knowledge to improve the plan quality. </title> <booktitle> In Proceedings of the Second International Conference of AI Planning Systems Chicago, </booktitle> <address> IL. </address>
Reference: <author> Porter, B. W., & Kibler, D. F. </author> <year> (1986). </year> <title> Experimental goal regression: A method for learning problem-solving. </title> <journal> Machine Learning, </journal> <volume> 1 (3), </volume> <pages> 249-285. </pages>
Reference: <author> Quinlan, J. R. </author> <year> (1983). </year> <title> Learning efficient classification procedures and their application to chess end games. </title> <editor> In Michalski, R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA. </address>
Reference-contexts: At the other extreme are inductive methods which learn through examining examples of positive and negative planning situations. These empirical methods build control rules by making inductive leaps based on some domain-independent bias such as an information-gain heuristic or Occam's razor <ref> (Quinlan, 1983) </ref>. This type of approach obviates the need for a domain theory since rules are learned directly from empirical information. Inductive methods also tend to build more general control rules, and thus often acquire more useful control knowledge.
Reference: <author> Quinlan, J. R. </author> <year> (1991). </year> <title> Determinate literals in inductive logic programming. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning Evanston, </booktitle> <address> IL. </address> <note> 34 Quinlan, </note> <author> J. R., & Cameron-Jones, R. M. </author> <year> (1993). </year> <title> FOIL: A midterm report. </title> <booktitle> In Proceedings of the European Conference on Machine Learning, </booktitle> <pages> pp. 3-20 Vienna. </pages>
Reference: <author> Quinlan, J. </author> <year> (1990). </year> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5 (3), </volume> <pages> 239-266. </pages>
Reference: <author> Silverstein, G., & Pazzani, M. J. </author> <year> (1991). </year> <title> Relational cliches: Constraining constructive induction during relational learning. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pp. </pages> <address> 203-207 Evanston, IL. </address>
Reference: <author> Subramanian, D., & Feldman, R. </author> <year> (1990). </year> <title> The utility of EBL in recursive domains. </title> <booktitle> In Proceedings of the Eighth National Conference on Ariticial Intelligence, </booktitle> <pages> pp. </pages> <address> 942-949 Boston, MA. </address>
Reference: <author> Tadepalli, P. </author> <year> (1989). </year> <title> Lazy explanation-based learning: A solution to the intractable theory problem. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence Detroit, </booktitle> <address> MI. </address>
Reference: <author> Veloso, M., Carbonell, J., Perez, A., Borrajo, D., Fink, E., & Blythe, J. </author> <year> (1995). </year> <title> Integrated planning and learning: The PRODIGY architecture. </title> <journal> Journal of Theoretical and Experimental Artificial Intelligence Research, </journal> <volume> 7 (1). </volume>
Reference: <author> Veloso, M., & Stone, P. </author> <year> (1995). </year> <title> FLECS: Planning with a flexible commitment strategy. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 3, </volume> <pages> 25-52. </pages>
Reference: <author> Veloso, M. M. </author> <year> (1992). </year> <title> Learning by Analogical Reasoning in General Problem Solving. </title> <type> Ph.D. thesis, </type> <institution> School of Computer Science, Carnegie Mellon University. </institution>
Reference: <author> Warren, D. </author> <year> (1974). </year> <title> WARPLAN: A system for generating plans. </title> <type> Tech. rep. Memo No. 76, </type> <institution> Department of Computational Logic, University of Edinburgh. </institution>
Reference: <author> Zelle, J. M., & Mooney, R. J. </author> <year> (1993). </year> <title> Combining FOIL and EBG to speed-up logic programs. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 1106-1111 Chambery, France. </address>
Reference-contexts: This nondeterminism can be eliminated by learning a control rule for the first clause that will correctly predict when the item should be placed at the head of the list. by the Dolphin learning system <ref> (Zelle & Mooney, 1993) </ref>. The first insert clause has been "guarded" with control information so that attempts to use it inappropriately will fail immediately. <p> Scope can also make selection rules deterministic or nondeterministic depending on the accuracy of the learned rule. 4 The Scope Learning System Scope is based on the Dolphin speedup learning system <ref> (Zelle & Mooney, 1993) </ref>, which optimizes logic programs by learning clause-selection rules. Dolphin has been shown successful at improving program performance in several different domains, including planning domains which employed a simple state-based planner. <p> A second problem is that explanations for subgoals only consider the context of that particular subgoal. Often the conditions which cause a particular operator to fail, lie outside the proof of the specific subgoal to which that operator was applied. The Dolphin system <ref> (Zelle & Mooney, 1993) </ref> improves on AxA-EBL by using a more powerful induction algorithm (Foil) and analyzing proof trees of entire problems instead of only explaining individual subgoal successes.
Reference: <author> Zelle, J. M., & Mooney, R. J. </author> <year> (1994a). </year> <title> Combining top-down and bottom-up methods in inductive logic programming. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 343-351 New Brunswick, NJ. </address>
Reference: <author> Zelle, J. M., & Mooney, R. J. </author> <year> (1994b). </year> <title> Inducing deterministic Prolog parsers from treebanks: A machine learning approach. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 748-753 Seattle, WA. </address>
Reference: <author> Zweben, M., Davis, E., Daun, B., Drascher, E., Deale, M., & Eskey, M. </author> <year> (1992). </year> <title> Learning to improve constraint-based scheduling. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 58(1-3), 271-296. 35 </pages>
Reference-contexts: Most of these methods attempt to combine EBL with an inductive algorithm where the main goal is to retain the benefits of a domain theory while also having the flexibility to learn from the data. For example, instead of building a complete proof, plausible explanation-based learning (PEBL) <ref> (Zweben et al., 1992) </ref> first conjectures an example is a member of target concept, and then confirms the conjecture with empirical data.
References-found: 60

