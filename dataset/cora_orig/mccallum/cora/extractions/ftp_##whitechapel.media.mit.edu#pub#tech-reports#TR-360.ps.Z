URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-360.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: picard@media.mit.edu;  
Title: of Models for Video and Image Libraries  
Author: Rosalind W. Picard 
Web: http://www.media.mit.edu/~picard/  
Address: 20 Ames St., Cambridge, MA 02139  
Affiliation: MIT Media Lab;  
Note: A Society  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 360 Submitted to IBM Systems Journal; revised 4/23/96 Abstract The average person with a computer will soon have access to the world's collections of digital video and images. However, unlike text which can be alphabetized or numbers which can be ordered, image and video has no general language to aid in its organization. Although tools which can "see" and "understand" the content of imagery are still in their infancy, they are now at the point where they can provide substantial assistance to users in navigating through visual media. This paper describes new tools based on "vision texture" for modeling image and video. The focus of this research is the use of a society of low-level models for performing relatively high-level tasks, such as retrieval and annotation of image and video libraries. This paper surveys our recent and present research in this fast-growing area.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. J. Herrnstein, D. H. Loveland, and C. </author> <title> Cable, "Natural concepts in pigeons," </title> <journal> J. of Exp. Psych: Anim. Beh. Procs., </journal> <volume> vol. 2, </volume> <pages> pp. 285-302, </pages> <year> 1976. </year>
Reference-contexts: Studies have shown that even pigeons with their pea-sized brains can discriminate images of water and trees <ref> [1] </ref> as well as impressionist and cubist paintings [2]. Inspired by these kinds of successful behavior, we have been exploring the use of collective low-level features, such as texture and color, for making relatively high-level decisions about images.
Reference: [2] <author> S. Watanabe, J. Sakamoto, and M. Wakita, </author> <title> "Pigeons' discrimination of paintings by Monet and Picasso," </title> <journal> Journal of the Experimental Analysis of Behavior, </journal> <volume> vol. 63, </volume> <month> March </month> <year> 1995. </year>
Reference-contexts: Studies have shown that even pigeons with their pea-sized brains can discriminate images of water and trees [1] as well as impressionist and cubist paintings <ref> [2] </ref>. Inspired by these kinds of successful behavior, we have been exploring the use of collective low-level features, such as texture and color, for making relatively high-level decisions about images.
Reference: [3] <author> H. D. Hubel and T. N. Wiesel, </author> <title> "Receptive fields and functional architecture of monkey striate cortex," </title> <journal> J. Physiology, </journal> <volume> vol. 195, </volume> <pages> pp. 215-243, </pages> <year> 1968. </year>
Reference: [4] <author> W. T. Freeman and E. H. Adelson, </author> <title> "The design and use of steerable filters," </title> <journal> IEEE T. Patt. Analy. and Mach. Intell., </journal> <volume> vol. PAMI-13, </volume> <pages> pp. 891-906, </pages> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: Before proceeding, consider a computer solution to the scenario above. A simple measure of local orientation over scale, a low-level operation designed to mimic part of what scientists believe occurs in the human visual system ([3], <ref> [4] </ref>, [5]) was used with some simple decision rules for classifying a set of 98 vacation photos. Based on only a quick decision with the low-level orientation information, 91 out of 98 of the photos were correctly classified into the categories "city/suburb" or "other" [6].
Reference: [5] <author> R. W. Picard and M. Gorkani, </author> <title> "Finding perceptually dominant orientations in natural textures," Spatial Vision, </title> <journal> special Julesz birthday issue, </journal> <volume> vol. 8, no. 2, </volume> <pages> pp. 221-253, </pages> <year> 1994. </year>
Reference-contexts: Before proceeding, consider a computer solution to the scenario above. A simple measure of local orientation over scale, a low-level operation designed to mimic part of what scientists believe occurs in the human visual system ([3], [4], <ref> [5] </ref>) was used with some simple decision rules for classifying a set of 98 vacation photos. Based on only a quick decision with the low-level orientation information, 91 out of 98 of the photos were correctly classified into the categories "city/suburb" or "other" [6].
Reference: [6] <author> M. M. Gorkani and R. W. </author> <title> Picard, "Texture orientation for sorting photos at a glance," </title> <booktitle> in Proc. Int. Conf. Pat. Rec., vol. I, (Jerusalem, Israel), </booktitle> <pages> pp. 459-464, </pages> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: Based on only a quick decision with the low-level orientation information, 91 out of 98 of the photos were correctly classified into the categories "city/suburb" or "other" <ref> [6] </ref>.
Reference: [7] <author> M. J. Swain and D. H. Ballard, </author> <title> "Indexing via color histograms," </title> <booktitle> in Image Understanding Workshop, </booktitle> <address> (Pittsburgh, PA), </address> <pages> pp. 623-630, </pages> <month> Sept. </month> <year> 1990. </year>
Reference-contexts: Swain and Ballard <ref> [7] </ref> illustrated the use of simple color histograms for retrieving images from a diverse database, and Syeda-Mahmood has shown how a combination of color and texture features can speed up selection of items of interest in photos [8].
Reference: [8] <author> T. Syeda-Mahmood, </author> <title> "Model-driven selection using texture," </title> <booktitle> in Proc. 4th British Machine Vision Conference (J. </booktitle> <institution> Illingworth, ed.), (Univ. of Surrey, </institution> <month> Guild-ford), </month> <pages> pp. 65-74, </pages> <publisher> BMVA Press, </publisher> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: Swain and Ballard [7] illustrated the use of simple color histograms for retrieving images from a diverse database, and Syeda-Mahmood has shown how a combination of color and texture features can speed up selection of items of interest in photos <ref> [8] </ref>. Texture has also been shown to be powerful for recognition of motions [9]. 1.1 Texture: beyond the traditional definition There is much more texture in the world than most people realize.
Reference: [9] <author> R. Polana and R. Nelson, </author> <title> "Low level recognition of human motion," </title> <booktitle> in IEEE Workshop on Motion of Non-rigid and Articulated Objects, </booktitle> <address> (Austin, TX), </address> <year> 1994. </year>
Reference-contexts: Texture has also been shown to be powerful for recognition of motions <ref> [9] </ref>. 1.1 Texture: beyond the traditional definition There is much more texture in the world than most people realize.
Reference: [10] <author> C. B. Thaxton, W. L. Bradley, and R. L. Olsen, </author> <title> The Mystery of Life's Origin. </title> <address> New York: Philosoph. Lib., </address> <year> 1984. </year>
Reference-contexts: separated for easier discussion of how they influence applications. 1.1.1 Property 1: lack of specific complexity The first property is illustrated by considering three categories of patterns, illustrated by the 1-D strings of letters in Figure 2. (These strings were inspired by the discussion of different kinds of entropy in <ref> [10] </ref>.) The first string is a 1-D periodic texture. It has a basic primitive, a specific set of rules for replication of the primitive, and allowance for minor perturbations.
Reference: [11] <author> C. E. Shannon and W. Weaver, </author> <title> The Mathematical Theory of Communication. </title> <institution> Urbana and Chicago: University of Illinois Press, </institution> <year> 1963. </year>
Reference: [12] <author> B. B. Mandelbrot, </author> <title> The Fractal Geometry of Nature. </title> <address> New York: </address> <publisher> W. H. Freeman and Company, </publisher> <year> 1983. </year>
Reference-contexts: Note that extreme smoothness can still be considered to be a texture, especially in the tactile domain (feel the "silky smooth" texture of this garment) but in digital imagery, smooth regions generally are considered as non-textured. 1.1.3 Property 3: restricted range of scale Textures, unless they are truly fractal <ref> [12] </ref>, tend to exist over a finite range of scales. Tree bark may look smooth from a distance, grooved as you move in closer, and pitted when you press your nose to the trunk.
Reference: [13] <author> P. S. Stevens, </author> <title> Patterns in Nature. </title> <address> Boston, MA: </address> <publisher> Little, Brown and Co., </publisher> <year> 1974. </year>
Reference-contexts: Scaling similarity also shows up in a less obvious way across very different phenomena at different scales. In his delightful book on patterns in nature, Stevens <ref> [13] </ref> shows pictures of gas clouds and of milk poured into a black slate sink two different materials at scales ranging from a centimeter to over ten quintillion kilometers, both which can be generated as "turbulence" textures.
Reference: [14] <author> M. Minsky, </author> <booktitle> The Society of Mind. </booktitle> <address> New York, NY: </address> <publisher> Simon & Schuster, </publisher> <year> 1985. </year>
Reference-contexts: Instead of searching for one "best" model, the approach here is that it is important to study a variety of models, to learn what they do best, and to learn how they may be effectively combined. This approach shares the spirit of Minsky's Society of Mind <ref> [14] </ref>, whereby specialized agents, or models in this case, interact to make sense of what they see. Just because a model is capable of representing everything does not mean that it is best to use for everything.
Reference: [15] <author> R. Haralick, </author> <title> "Statistical and structural approaches to texture," </title> <journal> Proc. IEEE, </journal> <volume> vol. 67, </volume> <pages> pp. 786-804, </pages> <month> May </month> <year> 1979. </year>
Reference-contexts: Information on the other like these can be mimicked by digital texture models. In particular, reaction-diffusion models may be used for efficient description of most natural patterns involving spots and stripes. models in Figure 3 can be found in the references, especially overviews such as <ref> [15] </ref> and [16]. There is not space here for equations and details, but these are referenced for each model. The focus in the descriptions below is to familiarize the reader with each model, highlight some apparent strengths and weaknesses of each model, and point to important relations between the models.
Reference: [16] <author> M. Tuceryan and A. K. Jain, </author> <title> "Texture Analysis," in The Handbook of Pattern Recognition and Computer Vision (C. </title> <editor> H. Chen, L. F. Pau, and P. S. P. Wang, </editor> <booktitle> eds.), </booktitle> <pages> pp. 235-276, </pages> <publisher> World Scientific Pub. Co, </publisher> <year> 1993. </year>
Reference-contexts: Information on the other like these can be mimicked by digital texture models. In particular, reaction-diffusion models may be used for efficient description of most natural patterns involving spots and stripes. models in Figure 3 can be found in the references, especially overviews such as [15] and <ref> [16] </ref>. There is not space here for equations and details, but these are referenced for each model. The focus in the descriptions below is to familiarize the reader with each model, highlight some apparent strengths and weaknesses of each model, and point to important relations between the models.
Reference: [17] <author> A. M. </author> <title> Turing, "The chemical basis of morphogene-sis," </title> <journal> Phil Trans. R. Soc. Land., </journal> <volume> vol. B 237, </volume> <pages> pp. 37-72, </pages> <year> 1952. </year>
Reference-contexts: In a digital library of such imagery, one might expect a reaction-diffusion model to be powerful for both representation and retrieval. Figure 4 illustrates some of the variety of animal patterns which are well modeled by reaction-diffusion. Turing proposed in 1952 <ref> [17] </ref> that dappled patterns could be synthesized by a set of coupled nonlinear partial differential equations known as a "reaction-diffusion" system. Under certain conditions, reaction-diffusion models also can be used for analysis [18].
Reference: [18] <author> A. S. Sherstinsky, M-Lattice: </author> <title> A System for Signal Synthesis and Processing Based on Reaction-Diffusion. </title> <booktitle> ScD thesis, </booktitle> <publisher> MIT, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: Turing proposed in 1952 [17] that dappled patterns could be synthesized by a set of coupled nonlinear partial differential equations known as a "reaction-diffusion" system. Under certain conditions, reaction-diffusion models also can be used for analysis <ref> [18] </ref>. Inspired by Turing's work, we have developed a new nonlinear "M-Lattice" model which solves the biggest practical problem of the original Turing model (boundedness), and is still great at making spots and stripes. the representation of gray-level images by black spots on a white background [19].
Reference: [19] <author> A. Sherstinsky and R. W. Picard, "M-lattice: </author> <title> From morphogenesis to image processing," </title> <journal> IEEE Transactions on Image Processing, </journal> <note> 1995. To appear; Also appears as MIT Media Lab Perceptual Computing TR #299. </note>
Reference-contexts: Inspired by Turing's work, we have developed a new nonlinear "M-Lattice" model which solves the biggest practical problem of the original Turing model (boundedness), and is still great at making spots and stripes. the representation of gray-level images by black spots on a white background <ref> [19] </ref>. <p> Human fingerprints, which resemble bifurcating stripes on zebras, have recently been successfully modeled with the new M-Lattice for the purposes of enhancement and bi-narization. Instead of merely removing noise, the M-Lattice boosts the underlying fingerprint pattern, effectively suppressing unwanted noise and intensity variations <ref> [19] </ref>. The reaction-diffusion model has found applications in image processing [22], [19], computer vision, [23], and computer graphics [24] [25]. <p> Instead of merely removing noise, the M-Lattice boosts the underlying fingerprint pattern, effectively suppressing unwanted noise and intensity variations <ref> [19] </ref>. The reaction-diffusion model has found applications in image processing [22], [19], computer vision, [23], and computer graphics [24] [25]. In the latter, the emphasis has been on synthesis, although the synthesizing parameters could certainly be stored in a database of synthetic imagery and used for data manipulation, annotation, and retrieval.
Reference: [20] <author> R. Kelman, </author> <year> 1994. </year> <type> Dow Jones; Personal communication. </type>
Reference-contexts: 4 (a) (b) halftone, and (d) a binary enhanced fingerprint image from (c) an original noisy fingerprint image. 5 variety of nonlinear optimization problems, such as the creation of the "Wall Street Journal Style" halftone, that grows patterns along visually dominant directions, much like the hand-drawn versions made by artists <ref> [20] </ref>. The basic idea here is that the error introduced by halfton-ing gets pushed into perceptually-favorable directions, along lines that already exist in the image. We have also demonstrated the creation of color halftones with these effects using the M-Lattice [21].
Reference: [21] <author> A. Sherstinsky and R. W. </author> <title> Picard, "Color halfton-ing with M-lattice," </title> <booktitle> in IEEE Second Int. Conf. on Image Proc., </booktitle> <address> (Washington, DC), </address> <month> Oct. </month> <year> 1995. </year> <note> To appear; Also appears as MIT Media Lab Perceptual Computing TR #336. </note>
Reference-contexts: The basic idea here is that the error introduced by halfton-ing gets pushed into perceptually-favorable directions, along lines that already exist in the image. We have also demonstrated the creation of color halftones with these effects using the M-Lattice <ref> [21] </ref>. Stripes, such as on zebras and fish, are well-modeled by the nonlinear Turing and corresponding M-Lattice models. However, digital libraries of zebras and fish are not presently as abundant as those of fingerprints.
Reference: [22] <author> C. B. Price, P. Wambacq, and A. </author> <title> Oosterlinck, "Applications of reaction-diffusion equations to image processing," </title> <booktitle> in 3rd Int'l Conf. on Image Proc. and Its Appl., </booktitle> <pages> pp. 49-53, </pages> <year> 1989. </year>
Reference-contexts: Instead of merely removing noise, the M-Lattice boosts the underlying fingerprint pattern, effectively suppressing unwanted noise and intensity variations [19]. The reaction-diffusion model has found applications in image processing <ref> [22] </ref>, [19], computer vision, [23], and computer graphics [24] [25]. In the latter, the emphasis has been on synthesis, although the synthesizing parameters could certainly be stored in a database of synthetic imagery and used for data manipulation, annotation, and retrieval.
Reference: [23] <author> B. B. Kimia, A. R. Tannenbaum, and S. W. Zucker, </author> <title> "Shapes, shocks, and deformations I: The components of shape and the reaction-diffusion space," </title> <institution> Lab for Engineering Man/Machine Systems LEMS-105, Brown University, </institution> <month> June </month> <year> 1992. </year>
Reference-contexts: Instead of merely removing noise, the M-Lattice boosts the underlying fingerprint pattern, effectively suppressing unwanted noise and intensity variations [19]. The reaction-diffusion model has found applications in image processing [22], [19], computer vision, <ref> [23] </ref>, and computer graphics [24] [25]. In the latter, the emphasis has been on synthesis, although the synthesizing parameters could certainly be stored in a database of synthetic imagery and used for data manipulation, annotation, and retrieval.
Reference: [24] <author> G. Turk, </author> <title> "Generating textures on arbitrary surfaces using reaction-diffusion," </title> <journal> Computer Graphics, </journal> <volume> vol. 25, </volume> <pages> pp. 289-298, </pages> <month> July </month> <year> 1991. </year> <month> 17 </month>
Reference-contexts: Instead of merely removing noise, the M-Lattice boosts the underlying fingerprint pattern, effectively suppressing unwanted noise and intensity variations [19]. The reaction-diffusion model has found applications in image processing [22], [19], computer vision, [23], and computer graphics <ref> [24] </ref> [25]. In the latter, the emphasis has been on synthesis, although the synthesizing parameters could certainly be stored in a database of synthetic imagery and used for data manipulation, annotation, and retrieval.
Reference: [25] <author> A. Witkin and M. Kass, </author> <title> "Reaction-diffusion tex-tures," </title> <booktitle> in Siggraph, </booktitle> <year> 1991. </year>
Reference-contexts: Instead of merely removing noise, the M-Lattice boosts the underlying fingerprint pattern, effectively suppressing unwanted noise and intensity variations [19]. The reaction-diffusion model has found applications in image processing [22], [19], computer vision, [23], and computer graphics [24] <ref> [25] </ref>. In the latter, the emphasis has been on synthesis, although the synthesizing parameters could certainly be stored in a database of synthetic imagery and used for data manipulation, annotation, and retrieval.
Reference: [26] <author> J. D. Murray, </author> <title> Mathematical Biology. </title> <address> New York, NY: </address> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: The effectiveness of reaction-diffusion as a biological model, not just for animal coat pattern formation, but also for emergence of structure of all kinds, is an ongoing research topic in mathematical biology <ref> [26] </ref>. In the digital arena, the model has been most successful in the synthesis of textures or images comprised of spots and stripes. However, the model is still new and largely unexplored.
Reference: [27] <author> P. Brodatz, </author> <title> Textures: A Photographic Album for Artists and Designers. </title> <address> New York: </address> <publisher> Dover, </publisher> <year> 1966. </year>
Reference: [28] <author> M. Hassner and J. Sklansky, </author> <title> "The use of Markov random fields as models of texture," Comp. Graph. </title> <journal> and Img. Proc., </journal> <volume> vol. 12, </volume> <pages> pp. 357-370, </pages> <year> 1980. </year>
Reference-contexts: In computer vision and image processing, the MRF is touted for its ability to relate the Markov conditional probabilities to the Gibbs joint probability. It can be easily incorporated into a Bayesian framework, making it flexible for a variety of applications. Hassner and Sklansky <ref> [28] </ref> appear to have been the first to suggest the use of Markov/Gibbs models for image texture. Cross and Jain [29] conducted the first explorations of the MRF for gray-level texture modeling and showed that it generated natural appearing micro-textures such as grass or sand.
Reference: [29] <author> G. R. Cross and A. K. Jain, </author> <title> "Markov random field texture models," </title> <journal> IEEE T. Patt. Analy. and Mach. Intell., </journal> <volume> vol. PAMI-5, no. 1, </volume> <pages> pp. 25-39, </pages> <year> 1983. </year>
Reference-contexts: It can be easily incorporated into a Bayesian framework, making it flexible for a variety of applications. Hassner and Sklansky [28] appear to have been the first to suggest the use of Markov/Gibbs models for image texture. Cross and Jain <ref> [29] </ref> conducted the first explorations of the MRF for gray-level texture modeling and showed that it generated natural appearing micro-textures such as grass or sand. A Gaussian MRF has been applied to texture classification and modeling by Chellappa and Chatterjee [30], [31] and Cohen et al. [32].
Reference: [30] <author> R. Chellappa and S. Chatterjee, </author> <title> "Classification of textures using Markov random field models," </title> <booktitle> in Proc. ICASSP, </booktitle> <address> (San Diego), </address> <pages> pp. </pages> <address> 32.9.1-32.9.4, </address> <year> 1984. </year>
Reference-contexts: Cross and Jain [29] conducted the first explorations of the MRF for gray-level texture modeling and showed that it generated natural appearing micro-textures such as grass or sand. A Gaussian MRF has been applied to texture classification and modeling by Chellappa and Chatterjee <ref> [30] </ref>, [31] and Cohen et al. [32]. Given successful use in these small sets of data, the MRF should also be useful in large digital library problems, when the library data is well-described by the model.
Reference: [31] <author> R. Chellappa, S. Chatterjee, and R. Bag-dazian, </author> <title> "Texture synthesis and compression using Gaussian-Markov random field models," </title> <journal> IEEE T. Sys., Man and Cyber., </journal> <volume> vol. SMC-15, Mar/Apr. </volume> <year> 1985. </year>
Reference-contexts: Cross and Jain [29] conducted the first explorations of the MRF for gray-level texture modeling and showed that it generated natural appearing micro-textures such as grass or sand. A Gaussian MRF has been applied to texture classification and modeling by Chellappa and Chatterjee [30], <ref> [31] </ref> and Cohen et al. [32]. Given successful use in these small sets of data, the MRF should also be useful in large digital library problems, when the library data is well-described by the model.
Reference: [32] <author> F. S. Cohen, Z. Fan, and M. A. Patel, </author> <title> "Classification of rotated and scaled textured images using Gaussian Markov random field models," </title> <journal> IEEE T. Patt. Analy. and Mach. Intell., </journal> <volume> vol. PAMI-13, no. 2, </volume> <pages> pp. 192-202, </pages> <year> 1991. </year>
Reference-contexts: Cross and Jain [29] conducted the first explorations of the MRF for gray-level texture modeling and showed that it generated natural appearing micro-textures such as grass or sand. A Gaussian MRF has been applied to texture classification and modeling by Chellappa and Chatterjee [30], [31] and Cohen et al. <ref> [32] </ref>. Given successful use in these small sets of data, the MRF should also be useful in large digital library problems, when the library data is well-described by the model.
Reference: [33] <author> A. I. Mirza, </author> <title> "Spatial yield modeling for semiconductor wafers," </title> <type> Master's thesis, </type> <institution> MIT, </institution> <address> Cambridge, MA, </address> <month> May </month> <year> 1995. </year> <institution> EECS. </institution>
Reference-contexts: For example, the aura framework derived from an MRF model has been shown to be useful for characterizing spatial yields of semiconductor wafers <ref> [33] </ref>. Searches through a database of wafer-yield imagery might therefore favor this model for finding similar patterns. The interplay between microscopic dynamics and macroscopic force, such as that associated with a phase transition [34] triggered by temperature is an important factor in natural pattern formation.
Reference: [34] <author> E. Ben-Jacob and P. Garik, </author> <title> "The formation of patterns in non-equilibrium growth," </title> <journal> Nature, </journal> <volume> vol. 343, no. 6258, </volume> <pages> pp. 523-530, </pages> <year> 1990. </year>
Reference-contexts: Searches through a database of wafer-yield imagery might therefore favor this model for finding similar patterns. The interplay between microscopic dynamics and macroscopic force, such as that associated with a phase transition <ref> [34] </ref> triggered by temperature is an important factor in natural pattern formation. The effects of a temperature parameter on pattern formation with MRF's have been studied [35] revealing relationships between structuring models within mathematical morphology and the useful statistical features of co-occurrence [36].
Reference: [35] <author> R. W. Picard and A. P. Pentland, </author> <title> "Temperature and Gibbs image modeling," Media Laboratory, Perceptual Computing 254, </title> <publisher> MIT, </publisher> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference-contexts: The interplay between microscopic dynamics and macroscopic force, such as that associated with a phase transition [34] triggered by temperature is an important factor in natural pattern formation. The effects of a temperature parameter on pattern formation with MRF's have been studied <ref> [35] </ref> revealing relationships between structuring models within mathematical morphology and the useful statistical features of co-occurrence [36]. However, these relationships also indicate limitations on the patterns that can occur at low-temperature [37]. Although in theory the MRF can model anything, these low-temperature relationships point to weaknesses of the MRF model.
Reference: [36] <author> I. M. Elfadel and R. W. </author> <title> Picard, "Gibbs random fields, co-occurrences and texture modeling," </title> <journal> IEEE T. Patt. Analy. and Mach. Intell., </journal> <volume> vol. 16, </volume> <pages> pp. 24-37, </pages> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: The effects of a temperature parameter on pattern formation with MRF's have been studied [35] revealing relationships between structuring models within mathematical morphology and the useful statistical features of co-occurrence <ref> [36] </ref>. However, these relationships also indicate limitations on the patterns that can occur at low-temperature [37]. Although in theory the MRF can model anything, these low-temperature relationships point to weaknesses of the MRF model.
Reference: [37] <author> R. W. Picard and I. M. Elfadel, </author> <title> "Structure of aura and co-occurrence matrices for the Gibbs texture model," </title> <journal> J. of Mathematical Imaging and Vision, </journal> <volume> vol. 2, </volume> <pages> pp. 5-25, </pages> <year> 1992. </year>
Reference-contexts: The effects of a temperature parameter on pattern formation with MRF's have been studied [35] revealing relationships between structuring models within mathematical morphology and the useful statistical features of co-occurrence [36]. However, these relationships also indicate limitations on the patterns that can occur at low-temperature <ref> [37] </ref>. Although in theory the MRF can model anything, these low-temperature relationships point to weaknesses of the MRF model.
Reference: [38] <author> R. W. </author> <title> Picard, "Structured patterns from random fields," </title> <booktitle> in Asilomar Conference on Signals, Systems and Computers, </booktitle> <address> (Pacific Grove, CA), </address> <pages> pp. 1011-1015, </pages> <month> Oct </month> <year> 1992. </year>
Reference-contexts: In particular, although the MRF can make structures such as the stripes and spots favored by the reaction-diffusion model, it does not typically make such patterns unless coupled with an external structuring force, or forced into a low-temperature state <ref> [38] </ref>. For example, running at low-temperature on low-frequency structural cloud images was successful at simultaneously capturing cloud texture while preserving cloud shape [39].
Reference: [39] <author> L. Garand and J. A. Weinman, </author> <title> "A structural-stochastic model for the analysis and synthesis of cloud images," </title> <journal> J. of Climate and Appl. Meteorology, </journal> <volume> vol. 25, </volume> <pages> pp. 1052-1068, </pages> <year> 1986. </year>
Reference-contexts: For example, running at low-temperature on low-frequency structural cloud images was successful at simultaneously capturing cloud texture while preserving cloud shape <ref> [39] </ref>. In general, the expertise of the MRF does not seem to lie in large-scale structured patterns, except in a few special cases, and when careful temperature control is exercised. The strength of the MRF appears to lie with homogeneous microtextures and simple attractive-repulsive interactions.
Reference: [40] <author> R. W. </author> <title> Picard, "Random field texture coding," </title> <booktitle> in Soc. for Info. Disp. Int. Symp. Dig., (Boston,MA), </booktitle> <pages> pp. 685-688, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Figure 6 shows the use of an MRF model for synthesizing the microtexture of fur in two patches of a mandril image. Details how this was done, as well as its potential for model-based semantic image compression, are discussed in <ref> [40] </ref>. Although the model is successful for fur in this example, the reader should keep in mind that the model is not typically successful on nonhomogeneous or non-micro-textures, and was not found to be successful when trained on other parts of the mandril image.
Reference: [41] <author> K. Popat and R. W. </author> <title> Picard, "Novel cluster-based probability models for texture synthesis, classification, and compression," </title> <booktitle> in Proc. SPIE Visual Communication and Image Proc., vol. 2094, (Boston), </booktitle> <pages> pp. 756-768, </pages> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: The approach taken to make this model practical is described in <ref> [41] </ref>. To illustrate its power at capturing both microtexture features and higher-structured features, its parameters have been trained on six patterns shown in jointly model fourteen variables is a significant increase over the MRF; the latter is computationally tractable usually only for up to 3rd-order joint statistics.
Reference: [42] <author> K. Popat and R. W. </author> <title> Picard, "Cluster-based probability model and its application to image and texture processing," </title> <note> Submitted for Publication, </note> <year> 1995. </year>
Reference-contexts: The cluster-based probability model implemented here is related to several other models, such as Gaussian mixture models; these relations, along with the application of this model to image restoration and compression, are discussed further in <ref> [42] </ref>. One of the drawbacks of the model is that it presently requires a lot of parameters compared to other texture models. Research is underway to determine how the parameters can be leveraged across large classes of patterns, to make the model more efficient for use in digital libraries.
Reference: [43] <author> N. Saint-Arnaud and K. Popat, </author> <title> "Analysis and synthesis of sound textures," </title> <booktitle> in Proceedings of IJCAI-95 two-day workshop on Computational Auditory Scene Analysis, (Montreal), </booktitle> <pages> pp. 125-131, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: Research is underway to determine how the parameters can be leveraged across large classes of patterns, to make the model more efficient for use in digital libraries. The cluster-based probability model has recently been shown to be capable of realistic sound texture synthesis <ref> [43] </ref>, and to perform well on certain perceptual similarity comparisons of sounds [44]. Indeed, a truly effective society of models will include models that work not just for visual features, but also for arbitrary perceptual and semantic information features.
Reference: [44] <author> N. Saint-Arnaud, </author> <title> "Classification of sound textures," </title> <type> Master's thesis, </type> <institution> MIT, </institution> <address> Cambridge, MA, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: The cluster-based probability model has recently been shown to be capable of realistic sound texture synthesis [43], and to perform well on certain perceptual similarity comparisons of sounds <ref> [44] </ref>. Indeed, a truly effective society of models will include models that work not just for visual features, but also for arbitrary perceptual and semantic information features.
Reference: [45] <author> A. R. Rao and J. Lohse, </author> <title> "Identifying high level features of texture perception," </title> <institution> Computer Science RC17629 #77673, IBM, </institution> <year> 1992. </year>
Reference-contexts: media such as audio and image; models which can handle multiple media offer savings in design time, development time, and overall system cost. 2.4 A new Wold model for perceptual pattern matching What features are important to people when measuring similarity in pictures? A perceptual study by Rao and Lohse <ref> [45] </ref> has shown that the top three features may be described by 1) periodicity, 2) directionality, and 3) randomness. A model that explicitly gives control over these features would potentially provide more perceptual control over pattern formation and visual queries.
Reference: [46] <author> J. M. Francos, A. Z. Meiri, and B. Porat, </author> <title> "A unified texture model based on a 2-D Wold like decomposition," </title> <editor> IEEE T. Sig. </editor> <booktitle> Proc., </booktitle> <pages> pp. 2665-2678, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: As such, the Wold model is one of the few models that has intuitive parameters, or semantic "control knobs." An implementation of this model for analysis and synthesis of homogeneous textures can be found in <ref> [46] </ref>. For the purposes of image retrieval, we have developed a new implementation of the Wold model. This implementation facilitates the finding of perceptually-similar patterns in a database containing both homogeneous and non-homogeneous textured images [47].
Reference: [47] <author> F. Liu and R. W. </author> <title> Picard, "Periodicity, direction-ality, and randomness: Wold features for image modeling and retrieval," </title> <journal> IEEE T. Patt. Analy. and Mach. Intell., </journal> <note> To appear. Also MIT Media Laboratory Perceptual Computing TR#320. </note>
Reference-contexts: For the purposes of image retrieval, we have developed a new implementation of the Wold model. This implementation facilitates the finding of perceptually-similar patterns in a database containing both homogeneous and non-homogeneous textured images <ref> [47] </ref>. When the user selects a given image, similar-looking images are 8 upper left. 9 retrieved. Examples are shown in Figure 8. The upper left image in each of the two figures is the one selected by the user. <p> Although the images here are from the Brodatz database, they could just as well be from a large database of fabrics, tiles, wallcoverings, and other textiles, facilitating searches by consumers and designers. Although the Wold model was found to be the most successful of five texture models <ref> [47] </ref> for retrieval in the Brodatz database, it is not necessarily the best for an arbitrary set of imagery. To summarize, its strengths appear to lie in natural pattern similarity, especially when periodicity, directionality, and randomness are distinguishing features.
Reference: [48] <author> S. A. Niyogi and E. H. Adelson, </author> <title> "Analyzing and recognizing walking figures in XYT," </title> <booktitle> in CVPR, </booktitle> <address> (Seat-tle, WA), </address> <pages> pp. </pages> <month> 469-474, </month> <title> Computer Vision and Pattern Recognition, </title> <publisher> IEEE Computer Society Press, </publisher> <month> June </month> <year> 1994. </year>
Reference-contexts: Our work in this area has focused on treating video as a spatio-temporal image volume. Patterns in the volume show up as a result of periodic or random motions for example, a person walking across a scene results in a periodic braided pattern at leg-level <ref> [48] </ref>.
Reference: [49] <author> A. K. Jain, </author> <title> Fundamentals of Digital Image Processing. </title> <address> New Jersey: </address> <publisher> Prentice Hall, </publisher> <year> 1989. </year>
Reference-contexts: Like spatial texture, temporal texture will need to be augmented with other information before it can address relational queries such as "find dogs chasing cars." In an effort to first formulate a general temporal texture model, a linear auto-regressive model (of the auto-regressive moving average (ARMA) family in Figure 3) <ref> [49] </ref> was extended for stochastic temporal textures. The standard 2-D model was augmented to form a linear spatio-temporal auto-regressive (STAR) model, which predicts new image values based on a volume of values lagged in space and time [50].
Reference: [50] <author> M. Szummer and R. W. </author> <title> Picard, "Temporal texture modeling," </title> <booktitle> in Proceedings ICIP, </booktitle> <address> (Lausanne), </address> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: The standard 2-D model was augmented to form a linear spatio-temporal auto-regressive (STAR) model, which predicts new image values based on a volume of values lagged in space and time <ref> [50] </ref>. Using the STAR model, parameters for stochastic temporal textures were estimated, and the motions were resynthesized from the parameters. Resynthesis of motion textures such as steam, river water, and boiling water were found to look natural.
Reference: [51] <author> C. H. Perry and R. W. </author> <title> Picard, "Synthesizing flames and their spreading," </title> <booktitle> in Proceedings of the Fifth Eu-rograhics Workshop on Animation and Simulation, </booktitle> <address> (Oslo, Norway), </address> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: We have developed a model for synthesizing fires that look real, respond properly to wind and gravity, light their environment, spread over and char 3D objects, and compute in interactive time <ref> [51] </ref>. The flames are rendered using a technique based on modified particle systems each particle is a shaded translucent polygon, which combines with others to build the flickering flames. The flames are coupled with a physically-based spreading mechanisms to achieve realistic movement around polygonal 3-D objects.
Reference: [52] <author> W. Niblack, R. Barber, W. Equitz, M. Flickner, E. Glasman, D. Petkovic, P. Yanker, C. Falout-sos, and G. Taubin, </author> <title> "The QBIC project: Querying images by content using color, texture, and shape," in Storage and Retrieval for Image and Video Databases (W. Niblack, </title> <editor> ed.), </editor> <address> (San Jose, CA), </address> <pages> pp. 173-181, SPIE, </pages> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: Some of the earliest and largest research efforts have been at IBM Almaden <ref> [52] </ref>, ISS [53], and MIT [54]. Early results have already been made into products, and can be explored interactively on the world-wide web [55], [56]. The first system developed at the MIT Media Lab was Photobook.
Reference: [53] <author> H.-J. Zhang, S. W. Smoliar, J. H. Wu, C. Y. Low, and A. Kankanhalli, </author> <title> "A video database system for digital libraries." </title> <type> ISS, </type> <institution> Nat. Univ. Singapore, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: Some of the earliest and largest research efforts have been at IBM Almaden [52], ISS <ref> [53] </ref>, and MIT [54]. Early results have already been made into products, and can be explored interactively on the world-wide web [55], [56]. The first system developed at the MIT Media Lab was Photobook.
Reference: [54] <author> A. Pentland, R. Picard, and S. Sclaroff, "Photo-book: </author> <title> Tools for content-based manipulation of image databases," </title> <journal> Int'l Journal of Computer Vision, </journal> <note> 1996. in press. [55] "Virage," 1995. http://www.virage.com/. 18 [56] "IBM QBIC project." http://wwwqbic.almaden.ibm.com/~qbic/qbic.html. </note>
Reference-contexts: Some of the earliest and largest research efforts have been at IBM Almaden [52], ISS [53], and MIT <ref> [54] </ref>. Early results have already been made into products, and can be explored interactively on the world-wide web [55], [56]. The first system developed at the MIT Media Lab was Photobook.
Reference: [57] <author> R. W. </author> <title> Picard, "Light-years from Lena: Video and image libraries of the future," </title> <booktitle> in IEEE Second Int. Conf. on Image Proc., </booktitle> <address> (Washington, DC), </address> <month> Oct. </month> <year> 1995. </year> <note> To appear; Also appears as MIT Media Lab Perceptual Computing TR #339. </note>
Reference-contexts: The problems of what models to use for image representation, and how to measure image similarity are challenging research problems for the image processing community <ref> [57] </ref>. Photobook, like the systems of [55] and [56], allows the user to select manually from a variety of models and associated feature combinations. As a research tool, Photobook assists in rapid benchmarking of new pattern recognition and computer vision algorithms.
Reference: [58] <author> T. P. Minka and R. W. </author> <title> Picard, "Interactive learning using a `society of models'," </title> <note> Submitted for Publication, 1995. Also appears as MIT Media Lab Perceptual Computing TR#349. </note>
Reference-contexts: FourEyes can currently use one of several possible methods (e.g. set cover, decision list, or decision tree) to choose which groupings best cover the user's positive examples, cover none of their negative examples, and satisfy some additional criteria. (See <ref> [58] </ref> and [59] for details on the learning, as well as on other stages of processing in FourEyes.) The learner can select 12 shown at the top left? After searching a database of several hundred video keyframes, the result is the series of images shown here, ranked by similarity to the
Reference: [59] <author> T. P. Minka, </author> <title> "An image database browser that learns from user interaction," </title> <type> Master's thesis, </type> <institution> MIT, </institution> <address> Cambridge, MA, </address> <month> May </month> <year> 1996. </year> <institution> EECS. </institution>
Reference-contexts: FourEyes can currently use one of several possible methods (e.g. set cover, decision list, or decision tree) to choose which groupings best cover the user's positive examples, cover none of their negative examples, and satisfy some additional criteria. (See [58] and <ref> [59] </ref> for details on the learning, as well as on other stages of processing in FourEyes.) The learner can select 12 shown at the top left? After searching a database of several hundred video keyframes, the result is the series of images shown here, ranked by similarity to the query image <p> FourEyes gets faster as it sees problems similar to those it has seen before. ("Faster" is defined by an ability to retrieve or label the desired concepts given a smaller number of examples of what the user wants.) FourEyes has also demonstrated faster learning across new related (but different) problems <ref> [59] </ref>. Current research on FourEyes aims to improve its abilities as a "continuous learner," using knowledge from problems it has been trained on to improve its performance across new problems for which it has not been trained.
Reference: [60] <author> R. W. </author> <title> Picard, "Toward a visual thesaurus," </title> <note> in Springer-Verlag Workshops in Computing, 1995. To appear; Also appears as MIT Media Lab Perceptual Computing TR #358. </note>
Reference-contexts: Ideally, semantic annotations and perceptual image features work together, with annotations describing visual relations, and visual features helping propagate annotations to "visual synonyms" <ref> [60] </ref>. The first version of FourEyes was designed to use vision texture and a society of models to assist the user in annotation. In annotation, the user labels prototypes in a handful of images, and FourEyes then labels the rest of the database based on the examples of the user. <p> A benefit of building a learning algorithm into an annotation system is that the FourEyes system saves the most useful label-visual feature associations, essentially constructing a representation that acts as a "visual thesaurus" <ref> [60] </ref>. A cluster labeled "building" that looks like white buildings viewed from a sharp perspective can therefore get associated with a cluster labeled "building" that looks like white trimmed-red brick from a different perspective. Different prototypes of visual building get linked to the same semantic label.
Reference: [61] <author> R. W. Picard and T. P. Minka, </author> <title> "Vision texture for annotation," </title> <journal> Journal of Multimedia Systems, </journal> <volume> vol. 3, </volume> <pages> pp. 3-14, </pages> <year> 1995. </year>
Reference-contexts: In small-scale tests on a set of vacation photos, this power-assisted annotation process cut the cost of annotating by more than 80% <ref> [61] </ref>. Once images are partially annotated, retrieval systems can use semantic search criteria as well as the present visual-feature based criteria.
Reference: [62] <author> D. Romer, </author> <title> "The Kodak picture exchange," </title> <month> April </month> <year> 1995. </year> <institution> seminar at MIT Media Lab. </institution>
Reference-contexts: FourEye's reliance on the society of models means that it can simultaneously provide for many notions of similarity including color, texture, shape, motion, position, and even user-defined subjective associations. The latter are particularly important as many queries (indeed, the most common ones for stock photos in advertising <ref> [62] </ref>) are for images with a certain "mood." Giving computers the ability to learn about affect will make huge new demands on tools for learning and pattern modeling, but is essential for improving their performance in tasks involving human interaction [63]. 4 Summary This paper surveys recent research in the Vision
Reference: [63] <author> R. W. </author> <title> Picard, "Affective computing," Media Laboratory, Perceptual Computing 321, </title> <publisher> MIT, </publisher> <address> Cam-bridge, MA, </address> <year> 1995. </year> <title> Additional technical notes and computer code are available from our world wide web pages, </title> <note> http://www-white.media.mit.edu/vismod/vismod.html, and by anonymous FTP from whitechapel.media.mit.edu. 19 </note>
Reference-contexts: (indeed, the most common ones for stock photos in advertising [62]) are for images with a certain "mood." Giving computers the ability to learn about affect will make huge new demands on tools for learning and pattern modeling, but is essential for improving their performance in tasks involving human interaction <ref> [63] </ref>. 4 Summary This paper surveys recent research in the Vision Texture group of the MIT Media Laboratory.
References-found: 61

