URL: http://www.cs.unc.edu/~anderson/papers/tocstr97.ps.Z
Refering-URL: http://www.cs.unc.edu/~anderson/papers.html
Root-URL: http://www.cs.unc.edu
Title: Real-Time Computing with Lock-Free Shared Objects  
Author: James H. Anderson, Srikanth Ramamurthy, and Kevin Jeffay 
Keyword: Categories and Subject Descriptors: C.3 [Computer Systems Organization]: Special-Purpose and Application-Based Systems real-time systems; D.4.1 [Operating Systems]: Process Management concurrency, multiprocessing/multiprogramming, mutual exclusion, scheduling, synchronization; J.7 [Computer Applications]: Computers in Other Systems real-time General Terms: Design, Experimentation, Performance, Theory Additional Key Words and Phrases: Critical sections, deadline-monotonic, earliest-deadline-first, hard real-time, lock-free, rate-monotonic, scheduling, synchronization, wait-free.  
Date: June 1995  
Address: Chapel Hill, NC 27599-3175  
Affiliation: Department of Computer Science University of North Carolina  
Pubnum: Technical Report TR95-021  
Abstract: This paper considers the use of lock-free shared objects within hard real-time systems. As the name suggests, lock-free shared objects are distinguished by the fact that they are not locked. As such, they do not give rise to priority inversions, a key advantage over conventional, lock-based object-sharing approaches. Despite this advantage, it is not immediately apparent that lock-free shared objects can be employed if tasks must adhere to strict timing constraints. In particular, lock-free object implementations permit concurrent operations to interfere with each other, and repeated interferences can cause a given operation to take an arbitrarily long time to complete. The main contribution of this paper is to show that such interferences can be bounded by judicious scheduling. This work pertains to periodic, hard real-time tasks that share lock-free objects on a uniprocessor. In the first part of the paper, scheduling conditions are derived for such tasks, for both static and dynamic priority schemes. Based on these conditions, it is formally shown that lock-free object-sharing approaches typically incur much less overhead than approaches based on lock-based schemes. It is also shown that lock-free objects are surprisingly better suited for real-time computing on uniprocessors than are wait-free objects, even though operations on wait-free objects are guaranteed to complete in bounded time. These conclusions are validated experimentally through work involving a real-time desktop video-conferencing system. fl An abbreviated version of this paper has been submitted to the 1995 Real-Time Systems Symposium. The first two authors were supported by NSF contract CCR 9216421, and by a Young Investigator Award from the U.S. Army Research Office, grant number DAAHO4-95-1-0323. The third author was supported by grants from the Intel and IBM Corporations. Email: fanderson, ramamurt, jeffayg@cs.unc.edu. Phone: (919) 962-f1757,1806,1938g. Fax: (919) 962-1799. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Anderson and M. Moir, </author> <title> "Universal Constructions for Multi-Object Operations", </title> <booktitle> to appear in the Proceedings of the 14th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1995. </year>
Reference-contexts: It might be useful, for example, to nest two critical sections to transfer the contents of one shared buffer to another. Recently, Anderson and Moir presented algorithms for implementing multi-object operations that allow similar functionality in lock-free (and wait-free) implementations <ref> [1] </ref>. Using these algorithms, a buffer transfer can be accomplished in a lock-free (or wait-free) manner by simultaneously accessing both buffers.
Reference: [2] <author> J. Anderson and M. Moir, </author> <title> "Universal Constructions for Large Objects", </title> <booktitle> submitted to the Ninth International Workshop on Distributed Algorithms, </booktitle> <year> 1995. </year>
Reference-contexts: This retry loop can be expensive for certain large objects due to the overhead of copying. Fortunately, techniques have been recently developed that can be applied to substantially reduce this copying overhead <ref> [2] </ref>. Also, as shown in [16], many common objects, including most that would be of use in a real-time system, can be implemented with very short retry loops, such as that depicted in Figure 1.
Reference: [3] <author> B. Bershad, </author> <title> "Practical Considerations for Non-Blocking Concurrent Objects", </title> <booktitle> Proceedings of the 13th international Conference on Distributed Computing Systems, </booktitle> <month> May </month> <year> 1993, </year> <pages> pp. pages 264-274. </pages>
Reference-contexts: Although the PCP provides a general framework for real-time synchronization, this generality comes at a price, specifically operating system overhead that is sometimes excessive. In this paper, we consider interprocess communication in object-based, hard real-time systems. Our main contribution is to show that lock-free shared objects <ref> [3, 7, 16] </ref> | i.e., objects that are not critical-section-based | are a viable alternative to lock-based schemes such as the PCP in such systems. We establish this through a combination of formal analysis and experimentation. <p> In contrast, adding new tasks with lock-based schemes entails recomputing certain operating system tables (e.g., tables in the PCP that record the highest-priority task that locks each semaphore). Lock-free operations are usually implemented using "retry loops" <ref> [3, 6, 7, 11, 16] </ref>. Figure 1 depicts an example of such an operation, an enqueue taken from a shared queue implementation given in [16].
Reference: [4] <author> M. I. Chen and K. J. Lin, </author> <title> "Dynamic Priority Ceiling: A Concurrency Control Protocol for Real Time Systems", </title> <journal> Real-Time Systems Journal , Vol. </journal> <volume> 2, No. 1, </volume> <year> 1990, </year> <pages> pp. 325-346. 24 </pages>
Reference-contexts: We then compare the overhead of lock-free synchronization with that of several other approaches, on a formal basis in Section 6, and on an experimental basis in Section 7. In these comparisons, we consider lock-based objects implemented using the PCP [17], the dynamic PCP <ref> [4] </ref>, and the dynamic deadline modification scheme under EDF scheduling [8], and wait-free objects implemented using the constructions of [7]. We end with concluding remarks in Section 8. 2 Definitions and Notation We use the term task to refer to a sequential program that is invoked repeatedly. <p> In reality, a preempted task need not be accessing a shared object, and hence may not necessarily have a failed update as we have assumed. 6.2 Dynamic-Priority Scheduling We now compare the overhead of lock-free objects with two dynamic-priority schemes that use semaphore-based objects: the dynamic priority ceiling protocol (DPCP) <ref> [4] </ref>, and the dynamic deadline modification (DDM) scheme under EDF scheduling (EDF/DDM) [8]. Based on the analysis in [4], a sufficient condition for the schedulability of a set of periodic tasks under the DPCP, sched DPCP , can be defined as follows. sched DPCP P N (c j +block j ) <p> a failed update as we have assumed. 6.2 Dynamic-Priority Scheduling We now compare the overhead of lock-free objects with two dynamic-priority schemes that use semaphore-based objects: the dynamic priority ceiling protocol (DPCP) <ref> [4] </ref>, and the dynamic deadline modification (DDM) scheme under EDF scheduling (EDF/DDM) [8]. Based on the analysis in [4], a sufficient condition for the schedulability of a set of periodic tasks under the DPCP, sched DPCP , can be defined as follows. sched DPCP P N (c j +block j ) p j 1 In the above condition, block j is the maximum time for which task T j
Reference: [5] <author> B. O. Gallmeister and C. Lanier, </author> <title> "Early Experience With POSIX 1003.4 and POSIX 1003.4A", </title> <booktitle> Proceed--ings of the 12th IEEE Real-Time Systems Symposium, </booktitle> <year> 1991, </year> <pages> pp. 190-198. </pages>
Reference-contexts: As explained below, recent studies that evaluate the performance of lock-free objects [16] and lock-based objects <ref> [5] </ref> indicate that s is likely to be much smaller than r. This is confirmed by the experimental results presented in Section 7. 6.1 Static-Priority Scheduling We begin by comparing the overhead of lock-free synchronization under RM scheduling with the overhead of the lock-based priority ceiling protocol (PCP) [17]. <p> Massalin's conclusions are based on experiments run on a 25 MHz, one-wait-state memory, cold-cache 68030 CPU. In contrast, lock-based implementations fared much worse in a recent performance comparison of commercial real-time operating systems run on a 25 MHz, zero-wait-state memory 80386 CPU <ref> [5] </ref>. In this comparison, the implementation of semaphores on LynxOS took 154.4 microseconds to lock and unlock a semaphore in the worst case. The corresponding figure for POSIX mutex-style semaphores was 243.6 microseconds.
Reference: [6] <author> M. Herlihy, </author> <title> "Wait-Free Synchronization", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 13, No. 1, </volume> <year> 1991, </year> <pages> pp. 124-149. </pages>
Reference-contexts: In contrast, adding new tasks with lock-based schemes entails recomputing certain operating system tables (e.g., tables in the PCP that record the highest-priority task that locks each semaphore). Lock-free operations are usually implemented using "retry loops" <ref> [3, 6, 7, 11, 16] </ref>. Figure 1 depicts an example of such an operation, an enqueue taken from a shared queue implementation given in [16]. <p> Wait-free objects guarantee a strong form of lock-freedom that precludes all waiting dependencies among tasks (including potentially unbounded retry loops) <ref> [6, 7, 19] </ref>. 2 Although one motivation for work on wait-free objects has been their potential use in real-time systems, we show that lock-free objects are surprisingly better suited for real-time computing on uniprocessors, and incur much less overhead than their wait-free counterparts. <p> An important question, then, is how costly lock-free retry loops are likely to be. Any general methodology for constructing lock-free objects must be based on "universal" lock-free constructions <ref> [6, 7] </ref>. Such a construction can be employed to implement any object in a lock-free manner. Unfortunately, this generality can lead to expensive implementations. For example, in the universal lock-free construction of [7], numerous copies of the implemented object are kept. <p> Most wait-free universal constructions ensure termination by requiring each task to "help" every other task to complete any pending object access <ref> [6, 7] </ref>. To see how this works, consider the lock-free universal construction of Herlihy [7], which is described in Section 1. This construction does not guarantee termination because the store-conditional operation of each retry loop iteration may fail.
Reference: [7] <author> M. Herlihy, </author> <title> "A Methodology for Implementing Highly Concurrent Data Objects", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 15, No. 5, </volume> <year> 1993, </year> <pages> pp. 745-770. </pages>
Reference-contexts: Although the PCP provides a general framework for real-time synchronization, this generality comes at a price, specifically operating system overhead that is sometimes excessive. In this paper, we consider interprocess communication in object-based, hard real-time systems. Our main contribution is to show that lock-free shared objects <ref> [3, 7, 16] </ref> | i.e., objects that are not critical-section-based | are a viable alternative to lock-based schemes such as the PCP in such systems. We establish this through a combination of formal analysis and experimentation. <p> In contrast, adding new tasks with lock-based schemes entails recomputing certain operating system tables (e.g., tables in the PCP that record the highest-priority task that locks each semaphore). Lock-free operations are usually implemented using "retry loops" <ref> [3, 6, 7, 11, 16] </ref>. Figure 1 depicts an example of such an operation, an enqueue taken from a shared queue implementation given in [16]. <p> Wait-free objects guarantee a strong form of lock-freedom that precludes all waiting dependencies among tasks (including potentially unbounded retry loops) <ref> [6, 7, 19] </ref>. 2 Although one motivation for work on wait-free objects has been their potential use in real-time systems, we show that lock-free objects are surprisingly better suited for real-time computing on uniprocessors, and incur much less overhead than their wait-free counterparts. <p> An important question, then, is how costly lock-free retry loops are likely to be. Any general methodology for constructing lock-free objects must be based on "universal" lock-free constructions <ref> [6, 7] </ref>. Such a construction can be employed to implement any object in a lock-free manner. Unfortunately, this generality can lead to expensive implementations. For example, in the universal lock-free construction of [7], numerous copies of the implemented object are kept. <p> Any general methodology for constructing lock-free objects must be based on "universal" lock-free constructions [6, 7]. Such a construction can be employed to implement any object in a lock-free manner. Unfortunately, this generality can lead to expensive implementations. For example, in the universal lock-free construction of <ref> [7] </ref>, numerous copies of the implemented object are kept. The "current" copy is indicated by a shared object pointer. <p> In these comparisons, we consider lock-based objects implemented using the PCP [17], the dynamic PCP [4], and the dynamic deadline modification scheme under EDF scheduling [8], and wait-free objects implemented using the constructions of <ref> [7] </ref>. We end with concluding remarks in Section 8. 2 Definitions and Notation We use the term task to refer to a sequential program that is invoked repeatedly. We call a single execution of a task a job. <p> Most wait-free universal constructions ensure termination by requiring each task to "help" every other task to complete any pending object access <ref> [6, 7] </ref>. To see how this works, consider the lock-free universal construction of Herlihy [7], which is described in Section 1. This construction does not guarantee termination because the store-conditional operation of each retry loop iteration may fail. <p> Most wait-free universal constructions ensure termination by requiring each task to "help" every other task to complete any pending object access [6, 7]. To see how this works, consider the lock-free universal construction of Herlihy <ref> [7] </ref>, which is described in Section 1. This construction does not guarantee termination because the store-conditional operation of each retry loop iteration may fail. Herlihy extends this construction to be wait-free by requiring each task to "announce" any pending operation by recording it in a shared array. <p> We evaluated the system when the shared queues were implemented using lock-free algorithms, wait-free algorithms, and lock-based techniques. We implemented lock-free queues by using an algorithm given by Massalin in [16], and wait-free queues by using the wait-free universal construction given by Herlihy in <ref> [7] </ref>. Massalin's queue implementation requires CAS (for the dequeue) and CAS2 (for the enqueue), and Herlihy's 19 construction requires load-linked and store-conditional . We implemented these primitives by kernel calls, during which interrupts were disabled.
Reference: [8] <author> K. Jeffay, </author> <title> "Scheduling Sporadic Tasks with Shared Resources in Hard Real-Time Systems", </title> <booktitle> Proceedings of the 13 th IEEE Symposium on Real-Time Systems, </booktitle> <address> Phoenix, AZ, </address> <year> 1992, </year> <pages> pp. 89-99. </pages>
Reference-contexts: In these comparisons, we consider lock-based objects implemented using the PCP [17], the dynamic PCP [4], and the dynamic deadline modification scheme under EDF scheduling <ref> [8] </ref>, and wait-free objects implemented using the constructions of [7]. We end with concluding remarks in Section 8. 2 Definitions and Notation We use the term task to refer to a sequential program that is invoked repeatedly. We call a single execution of a task a job. <p> and hence may not necessarily have a failed update as we have assumed. 6.2 Dynamic-Priority Scheduling We now compare the overhead of lock-free objects with two dynamic-priority schemes that use semaphore-based objects: the dynamic priority ceiling protocol (DPCP) [4], and the dynamic deadline modification (DDM) scheme under EDF scheduling (EDF/DDM) <ref> [8] </ref>. <p> If r is 4, then the computational costs of the tasks are as follows: c 1 = 6; c 2 = 12, and c 3 = 5. This task set fails to satisfy sched DPCP . We now turn our attention to the EDF/DDM scheme presented in <ref> [8] </ref>. Under this scheme, tasks are divided into one or more phases. During each phase, a task accesses at most one shared resource. <p> Under the EDF/DDM scheme, r includes the cost of a system call to modify the task deadline before accessing an object, the cost of performing the shared-object operation, the cost of a system call to restore the task deadline after an access. Based on the analysis of <ref> [8] </ref>, a sufficient condition for the schedulability of a set of periodic tasks under the EDF/DDM scheme, sched DDM , can be defined as follows. 17 sched DDM ( P N u j +m j r P i1 j p j (u j + m j r) ti In the first
Reference: [9] <author> K. Jeffay and D. Stone, </author> <title> "Accounting for Interrupt Handling Costs in Dynamic Priority Task Systems", </title> <booktitle> Proceedings of the 14 th IEEE Symposium on Real-Time Systems, </booktitle> <address> Durham, NC, </address> <year> 1993, </year> <pages> pp. 212-221. </pages>
Reference-contexts: Note, however, that these conditions do not consider the cost of handling interrupts, and hence cannot be used directly. Fortunately, this problem can be overcome by using techniques derived in <ref> [9] </ref>. The idea is derive an expression that bounds the demand due to interrupt handlers in any given interval, and to then account for this demand in the scheduling conditions of Theorem 4.3 and [13]. Informally, we account for the cost of interrupt handlers as follows (see [9] for a more <p> techniques derived in <ref> [9] </ref>. The idea is derive an expression that bounds the demand due to interrupt handlers in any given interval, and to then account for this demand in the scheduling conditions of Theorem 4.3 and [13]. Informally, we account for the cost of interrupt handlers as follows (see [9] for a more formal version of this argument). First, we define the term F (t) to be the cost of handling interrupts over an interval of length t. <p> Our analysis of the system when lock-free objects are used is based upon the scheduling condition below. This condition is based upon the condition given in Theorem 5.2 and the techniques given in <ref> [9] </ref> for accounting 22 for the overhead of interrupt handlers. ( j=1 (c j + s)=p j + j=1 e j =v j 1) ^ P N j p j c j + j=1 t1l j +p j k P Q l v j e j ti In this expression, B <p> The first conjunct above is the condition of Theorem 5.2 augmented to include the utilization due to interrupt handlers. The second conjunct follows from the results of <ref> [9] </ref>. The three summation terms in this conjunct give the maximum demand due to the tasks, failed updates, and interrupt handlers, respectively, in an interval of length t. The right-hand side of the stated inequality gives the available processor time in that interval.
Reference: [10] <author> K. Jeffay, D.L. Stone, and F.D. Smith, </author> <title> "Kernel Support for Live Digital Audio and Video", </title> <journal> Computer Communications, </journal> <volume> Vol. 15, No. 6, </volume> <month> July/August </month> <year> 1992, </year> <pages> pp. 388-395. </pages>
Reference-contexts: This evidence comes from a set of experimental comparisons performed using a real-time desktop videoconferencing system implemented at UNC <ref> [10] </ref>. We modified this system to support lock-free shared objects implemented under both DM and EDF scheduling, semaphores implemented using the PCP under DM scheduling, and semaphores implemented under EDF/DDM scheduling. We also considered wait-free shared objects implemented under both DM and EDF scheduling.
Reference: [11] <author> T. Johnson and K. Harathi, </author> <title> "Interruptible Critical Sections", </title> <type> Technical Report TR94-007, </type> <institution> Department of Computer Science, University of Florida, </institution> <year> 1994. </year>
Reference-contexts: In contrast, adding new tasks with lock-based schemes entails recomputing certain operating system tables (e.g., tables in the PCP that record the highest-priority task that locks each semaphore). Lock-free operations are usually implemented using "retry loops" <ref> [3, 6, 7, 11, 16] </ref>. Figure 1 depicts an example of such an operation, an enqueue taken from a shared queue implementation given in [16]. <p> Unfortunately, the thread of research on wait-free and lock-free communication begun by Sorenson and Hamacher was lost in the real-time systems community for many years. Recently, however, this thread of research resurfaced in work presented by Kopetz and Reisinger in [12] and by Johnson and Harathi in <ref> [11] </ref>. In the former paper, a simple lock-free, one-writer, read/write buffer is presented, and scheduling conditions are given for tasks sharing the buffer. In the latter paper, the primary focus is implementations of lock-free algorithms rather than scheduling.
Reference: [12] <author> H. Kopetz and J. Reisinger, </author> <title> "The Non-Blocking Write Protocol NBW: A Solution to a Real-Time Synchronization Problem", </title> <booktitle> Proceedings of the IEEE Real-Time Systems Symposium, </booktitle> <year> 1993, </year> <pages> pp. 131-137. </pages>
Reference-contexts: Unfortunately, the thread of research on wait-free and lock-free communication begun by Sorenson and Hamacher was lost in the real-time systems community for many years. Recently, however, this thread of research resurfaced in work presented by Kopetz and Reisinger in <ref> [12] </ref> and by Johnson and Harathi in [11]. In the former paper, a simple lock-free, one-writer, read/write buffer is presented, and scheduling conditions are given for tasks sharing the buffer. In the latter paper, the primary focus is implementations of lock-free algorithms rather than scheduling.
Reference: [13] <author> J. Lehoczky, L. Sha, and Y. Ding, </author> <title> "The Rate Monotonic Scheduling Algorithm: Exact Characterization and Average Case Behavior", </title> <booktitle> Proceedings of the Tenth IEEE Real-Time Systems Symposium, </booktitle> <address> Santa Monica, CA, </address> <year> 1989, </year> <pages> pp. 166-171. </pages>
Reference-contexts: The resulting scheduling analysis is the same as that for independent tasks given in <ref> [13] </ref>. Hence, we only consider lock-free objects that have an access time that is larger than one time quantum. This is specified as follows. <p> The right 10 hand side gives the available processor time in that interval. Observe that this condition is similar to that given for independent tasks in <ref> [13] </ref>. 5 A formal proof within our model can be found in the appendix. <p> i (k) 1) can be replaced by (0; i) by Definition 3.7. ) h9i; k : k &gt; 0 : :miss i (r i (k) 1) ^ h8t : b i (k 1) t r i (k) 1 : P N 5 Our necessary condition differs slightly from that in <ref> [13] </ref> because we allow tasks to release their first jobs at arbitrary times. 11 d j (b i (k 1)) + n j (b i (k 1) + 1; t; (0; i)) c j ] + f (b i (k 1); t; (0; i)) s [t b i (k 1)] &gt; <p> In order to more formally compare lock-free and wait-free objects, let us assume that objects are imple mented using Herlihy's universal constructions. First, note that tasks that share wait-free objects can be 18 viewed as independent tasks, i.e., the scheduling conditions derived in <ref> [13] </ref> and [15] apply. These conditions are the same as those given in Theorems 4.2 and 5.2, respectively, when s = 0. <p> The data presented in these figures has been taken from [22]. The formal model of the experimental system can be analyzed by using the scheduling condition given in Theorem 4.3 when lock-free objects are used, and that given in <ref> [13] </ref> when lock-based objects are used. Note, however, that these conditions do not consider the cost of handling interrupts, and hence cannot be used directly. Fortunately, this problem can be overcome by using techniques derived in [9]. <p> Fortunately, this problem can be overcome by using techniques derived in [9]. The idea is derive an expression that bounds the demand due to interrupt handlers in any given interval, and to then account for this demand in the scheduling conditions of Theorem 4.3 and <ref> [13] </ref>. Informally, we account for the cost of interrupt handlers as follows (see [9] for a more formal version of this argument). First, we define the term F (t) to be the cost of handling interrupts over an interval of length t. <p> F (t) j=1 t m 21 Using (1), we can obtain a schedulability condition when the tasks synchronize using lock-based objects and the PCP. This involves modifying the condition presented in <ref> [13] </ref> to account for the demand placed by interrupt handlers, as given by (1). <p> This analysis departs from the norm by being carried out entirely within an assertional framework. This framework is quite general. For example, if s = 0, then our sufficient conditions for RM and EDF scheduling converge to those derived for independent tasks in <ref> [13] </ref> and [15], respectively. Our results show that lock-free objects have a number of advantages over lock-based schemes such as the PCP for real-time computing on uniprocessors. First, lock-free objects are easier to use, because their application does not require detailed knowledge of which tasks access which objects.
Reference: [14] <author> J.Y.T. Leung and J. Whitehead, </author> <title> "On the Complexity of Fixed-Priority Scheduling of Periodic, Real-Time Tasks", </title> <journal> Performance Evaluation, </journal> <volume> Vol. 2, No. 4, </volume> <year> 1982, </year> <pages> pp. 237-250. </pages>
Reference-contexts: We then derive scheduling conditions for the RM priority scheme in Section 4, and the EDF 2 priority scheme in Section 5; we also briefly present a slight variation of our RM condition that holds for the deadlock-monotonic (DM) priority scheme <ref> [14] </ref>. We then compare the overhead of lock-free synchronization with that of several other approaches, on a formal basis in Section 6, and on an experimental basis in Section 7. <p> For simplicity, we assume that tasks are indexed in nondecreasing order by relative deadline. With this change to our model, it is possible to prove the following static scheduling condition. This condition assumes that priority is assigned by the DM scheme <ref> [14] </ref>, in which tasks with smaller relative deadlines have higher priorities. The two summation terms in the stated expression below give the computational demand of T i and higher-priority tasks, and the additional computation required due to failed updates, respectively, in an interval of length t. <p> In both cases scheduling was performed using a DM scheduling algorithm <ref> [14] </ref>. Qualitatively, when queue synchronization was achieved using semaphores, approximately seven media samples were lost in the pipeline every second due to buffer overflow. In contrast, no media samples were lost when lock-free objects were used.
Reference: [15] <author> C. Liu and J. Layland, </author> <title> "Scheduling Algorithms for multiprogramming in a Hard Real-Time Environment", </title> <journal> Journal of the ACM , Vol 30., </journal> <month> Jan. </month> <year> 1973, </year> <pages> pp. 46-61. </pages>
Reference-contexts: We establish this through a combination of formal analysis and experimentation. We begin by establishing scheduling conditions for hard real-time, periodic tasks that share lock-free objects on a uniprocessor under either rate-monotonic (RM) or earliest-deadline-first (EDF) scheduling <ref> [15] </ref>. We then compare lock-free and lock-based approaches, both formally, based on our scheduling conditions, and experimentally, based on work involving a real-time desktop videoconferencing facility. Our formal analysis and experimental work both lead to the same conclusion: lock-free objects often require less overhead than conventional lock-based object-sharing approaches. <p> Hence, we do not specify the behavior of the system when it is overloaded. The next three definitions formalize the scheduling schemes we consider. Under the RM scheme, tasks with smaller periods have higher priorities <ref> [15] </ref>. If two tasks have equal periods, then we assume that the task with the smaller index has higher priority. To be precise, we should therefore define pr i (t) to be (p i ; i). <p> Note that the definition of a deadline can be arbitrary in the interval [1; r i (0)) since task T i has no unfulfilled demand in that interval. The next definition formalizes the notion of dynamic priorities in the EDF scheduling scheme <ref> [15] </ref>. Definition 3.9: Under the EDF scheme, pr i (t) (l i (t); i): 2 The above definition states that a task with an earlier deadline has a higher priority. Without loss of generality, we assume that jobs with the same deadlines are executed in the order of increasing indices. <p> This accounts for the subtraction of x (t o ; t; v). In <ref> [15] </ref>, it is shown that for independent tasks, the longest response time of a task occurs at a critical instant of time, at which jobs of that task and all higher-priority tasks are released. However, this is not necessarily the case if tasks synchronize using lock-free objects. <p> The following theorem gives a necessary scheduling condition for the EDF scheme. According to this theorem, a task set is schedulable only if processor utilization is at most one. This condition is the same as that given in <ref> [15] </ref> for independent tasks. A formal proof within our model is given in the appendix. Theorem 5.1: (Necessity under EDF) For a set of periodic tasks scheduled under the EDF scheme, sched ) P N c i The next theorem gives a sufficiency condition for schedulability under the EDF scheme. <p> In order to more formally compare lock-free and wait-free objects, let us assume that objects are imple mented using Herlihy's universal constructions. First, note that tasks that share wait-free objects can be 18 viewed as independent tasks, i.e., the scheduling conditions derived in [13] and <ref> [15] </ref> apply. These conditions are the same as those given in Theorems 4.2 and 5.2, respectively, when s = 0. <p> This analysis departs from the norm by being carried out entirely within an assertional framework. This framework is quite general. For example, if s = 0, then our sufficient conditions for RM and EDF scheduling converge to those derived for independent tasks in [13] and <ref> [15] </ref>, respectively. Our results show that lock-free objects have a number of advantages over lock-based schemes such as the PCP for real-time computing on uniprocessors. First, lock-free objects are easier to use, because their application does not require detailed knowledge of which tasks access which objects.
Reference: [16] <author> H. Massalin, </author> <title> Synthesis: An Efficient Implementation of Fundamental Operating System Services, </title> <type> Ph.D. Dissertation, </type> <institution> Columbia University, </institution> <year> 1992. </year>
Reference-contexts: Although the PCP provides a general framework for real-time synchronization, this generality comes at a price, specifically operating system overhead that is sometimes excessive. In this paper, we consider interprocess communication in object-based, hard real-time systems. Our main contribution is to show that lock-free shared objects <ref> [3, 7, 16] </ref> | i.e., objects that are not critical-section-based | are a viable alternative to lock-based schemes such as the PCP in such systems. We establish this through a combination of formal analysis and experimentation. <p> In contrast, adding new tasks with lock-based schemes entails recomputing certain operating system tables (e.g., tables in the PCP that record the highest-priority task that locks each semaphore). Lock-free operations are usually implemented using "retry loops" <ref> [3, 6, 7, 11, 16] </ref>. Figure 1 depicts an example of such an operation, an enqueue taken from a shared queue implementation given in [16]. <p> Lock-free operations are usually implemented using "retry loops" [3, 6, 7, 11, 16]. Figure 1 depicts an example of such an operation, an enqueue taken from a shared queue implementation given in <ref> [16] </ref>. <p> This retry loop can be expensive for certain large objects due to the overhead of copying. Fortunately, techniques have been recently developed that can be applied to substantially reduce this copying overhead [2]. Also, as shown in <ref> [16] </ref>, many common objects, including most that would be of use in a real-time system, can be implemented with very short retry loops, such as that depicted in Figure 1. <p> As explained below, recent studies that evaluate the performance of lock-free objects <ref> [16] </ref> and lock-based objects [5] indicate that s is likely to be much smaller than r. <p> task priority before accessing an object, the cost of actually performing the shared-object operation, and the cost of a system call to restore the task priority after an access. 16 What are typical values of s and r? A performance comparison of various lock-free objects is given by Massalin in <ref> [16] </ref>. Massalin reports that, given hardware support for primitives like compare-and-swap, s varies from 1.3 microseconds for a counter to 3.3 microseconds for a circular queue. In the absence of hardware support, such primitives can be simulated by a trap, adding an additional 4.2 microseconds. <p> For a more detailed description of this system, we refer the interested reader to [22]. We evaluated the system when the shared queues were implemented using lock-free algorithms, wait-free algorithms, and lock-based techniques. We implemented lock-free queues by using an algorithm given by Massalin in <ref> [16] </ref>, and wait-free queues by using the wait-free universal construction given by Herlihy in [7]. Massalin's queue implementation requires CAS (for the dequeue) and CAS2 (for the enqueue), and Herlihy's 19 construction requires load-linked and store-conditional . We implemented these primitives by kernel calls, during which interrupts were disabled.
Reference: [17] <author> Raghunathan Rajkumar, </author> <title> Synchronization In Real-Time Systems APriority Inheritance Approach, </title> <publisher> Kluwer Academic Publications, </publisher> <year> 1991. </year>
Reference-contexts: The main problem that arises in such approaches is that of priority inversion, i.e., the situation in which a given task waits on another task of lower priority to unlock a semaphore, releasing a critical section. Mechanisms such as the priority ceiling protocol (PCP) <ref> [17, 18] </ref> are used to solve this problem. The PCP requires the operating system to identify those tasks that may lock a semaphore. <p> We then compare the overhead of lock-free synchronization with that of several other approaches, on a formal basis in Section 6, and on an experimental basis in Section 7. In these comparisons, we consider lock-based objects implemented using the PCP <ref> [17] </ref>, the dynamic PCP [4], and the dynamic deadline modification scheme under EDF scheduling [8], and wait-free objects implemented using the constructions of [7]. <p> This is confirmed by the experimental results presented in Section 7. 6.1 Static-Priority Scheduling We begin by comparing the overhead of lock-free synchronization under RM scheduling with the overhead of the lock-based priority ceiling protocol (PCP) <ref> [17] </ref>. When tasks synchronize by locking, a higher-priority job can be blocked by a lower-priority job that accesses a common object; the maximum blocking time is called the blocking factor . Under the PCP, the worst-case blocking time equals the time required to execute the longest critical section. <p> Since we do not consider nested critical sections, the blocking factor equals r, the time to execute a single critical section. We denote the schedulability condition for periodic tasks using the PCP by the predicate sched PCP , which on the basis of the analysis in <ref> [17] </ref>, is defined as follows. sched PCP h8i 9t : 0 &lt; t p i : r + P i l p j (u j + m j r) = ti In the above equation, the first term on the left-hand side represents the blocking factor.
Reference: [18] <author> L. Sha, R. Rajkumar, and J. Lehoczky, </author> <title> "Priority Inheritance Protocols: An Approach to Real-Time System Synchronization", </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 39, No. 9, </volume> <year> 1990, </year> <pages> pp. 1175-1185. </pages>
Reference-contexts: The main problem that arises in such approaches is that of priority inversion, i.e., the situation in which a given task waits on another task of lower priority to unlock a semaphore, releasing a critical section. Mechanisms such as the priority ceiling protocol (PCP) <ref> [17, 18] </ref> are used to solve this problem. The PCP requires the operating system to identify those tasks that may lock a semaphore.
Reference: [19] <author> A. Singh, J. Anderson, and M. Gouda, </author> <title> "The Elusive Atomic Register", </title> <journal> Journal of the ACM , Vol. </journal> <volume> 41, No. 2, </volume> <month> March </month> <year> 1994, </year> <pages> pp. 311-339. </pages>
Reference-contexts: Wait-free objects guarantee a strong form of lock-freedom that precludes all waiting dependencies among tasks (including potentially unbounded retry loops) <ref> [6, 7, 19] </ref>. 2 Although one motivation for work on wait-free objects has been their potential use in real-time systems, we show that lock-free objects are surprisingly better suited for real-time computing on uniprocessors, and incur much less overhead than their wait-free counterparts.
Reference: [20] <author> P. Sorensen, </author> <title> A Methodology for Real-Time System Development , Ph.D. </title> <type> Thesis, </type> <institution> University of Toronto, </institution> <year> 1974. </year>
Reference-contexts: The lock-free approach to real-time object sharing that we espouse is actually rooted in work done by Sorenson and Hamacher in the real-time systems community some twenty years ago <ref> [20, 21] </ref>. Sorenson and Hamacher's work involved a real-time communication mechanism based on wait-free read/write buffers. In their approach, all buffer management is done within the operating system, so it suffers from many of the same shortcomings as conventional lock-based approaches.
Reference: [21] <author> P. Sorensen and V. Hemacher, </author> <title> "A Real-Time System Design Methodology", </title> <journal> INFOR, </journal> <volume> Vol. 13, No. 1, </volume> <month> February </month> <year> 1975, </year> <pages> pp. 1-18. </pages>
Reference-contexts: The lock-free approach to real-time object sharing that we espouse is actually rooted in work done by Sorenson and Hamacher in the real-time systems community some twenty years ago <ref> [20, 21] </ref>. Sorenson and Hamacher's work involved a real-time communication mechanism based on wait-free read/write buffers. In their approach, all buffer management is done within the operating system, so it suffers from many of the same shortcomings as conventional lock-based approaches.
Reference: [22] <author> D. Stone, </author> <title> Managing the Effect of Delay Jitter on the Display of Live Continuous Media, </title> <type> Doctoral Dissertation, </type> <institution> University of North Carolina, Chapel Hill, </institution> <year> 1995. </year> <month> 25 </month>
Reference-contexts: For a more detailed description of this system, we refer the interested reader to <ref> [22] </ref>. We evaluated the system when the shared queues were implemented using lock-free algorithms, wait-free algorithms, and lock-based techniques. We implemented lock-free queues by using an algorithm given by Massalin in [16], and wait-free queues by using the wait-free universal construction given by Herlihy in [7]. <p> The periods, relative deadlines, and the execution times of the tasks in our formal model are shown in Figure 5. The periods and execution times of the interrupt handlers are shown in Figure 6. The data presented in these figures has been taken from <ref> [22] </ref>. The formal model of the experimental system can be analyzed by using the scheduling condition given in Theorem 4.3 when lock-free objects are used, and that given in [13] when lock-based objects are used. <p> This is result is predicted by the formal analysis of the system, which we now present. Our analysis of the EDF/DDM scheme is based upon the following scheduling condition, which is proved in <ref> [22] </ref>.
References-found: 22

