URL: http://www.cs.bris.ac.uk/Tools/Reports/Ps/1998-bogacz.ps.gz
Refering-URL: http://www.cs.bris.ac.uk/Tools/Reports/Abstracts/1998-bogacz.html
Root-URL: 
Email: Email:  Email: cgc@cs.bris.ac.uk  
Title: LEARNING META-RULES OF SELECTION IN EXPERT SYSTEMS  
Author: Rafal Bogacz Christophe Giraud-Carrier 
Web: bogacz@ci-1.ci.pwr.wroc.pl  
Address: ul. Wybrzeze Wyspianskiego 27 50-370 Wroclaw, Poland  Woodland Road Bristol, BS8 1UB, England  
Affiliation: Department of Computer Science and Management Technical University of Wroclaw  Department of Computer Science University of Bristol  
Abstract: Rule selection in forward chaining is a critical factor in the performance of expert systems. Uninformed selection causes many rules to be fired, that are not useful in the attainment of the reasoning goal. As a result, users have to answer more questions than needed and the systems performance is degraded. Domainspecific meta-rules have been used to improve rule selection. However, in most instances, such meta-rules are elicited from experts and thus costly to obtain and difficult to validate. This paper describes a method for improving rule selection automatically and adaptively. The idea rests on the use of a neural network to (meta-)learn dynamically (i.e., whilst the expert system is run) in which situations which rules are worth applying. Prior meta-rules, if they exist, may also be improved by the neural network. Empirical results demonstrate that the (meta-)knowledge encoded in the neural network produces a reduction of the number of rules selected during forward chaining. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Charniak, E.; McDermott, D.; </author> <title> Introduction to artificialiIntelligence. </title> <publisher> Addison Wesley, </publisher> <year> 1985 </year>
Reference-contexts: Clearly, suboptimal solutions lead to inefficiencies, which become worse with the size of the knowledge base. To improve rule selection (i.e., reduce the number of rules being applied), heuristics are typically used <ref> [1] </ref>. There are two general families of heuristics, namely weak heuristics and strong heuristics [4]. Weak heuristics are domain-independent.
Reference: [2] <author> Hertz, J.; Krogh, A.; Palmer, R.G.; </author> <title> Introduction to the theory of neural computation. </title> <publisher> Addison Wesley, </publisher> <address> Amsterdam, </address> <year> 1991. </year>
Reference-contexts: GOAL unit: 1 if the corresponding statement is the reasoning goal and 0 otherwise. The networks output is determined by a kind of winner-take-all rule <ref> [2] </ref>, as follows.
Reference: [3] <author> Gallant, </author> <title> S.I.; Connectionist expert systems, </title> <journal> Communications of the ACM, </journal> <volume> 31(2), 152, </volume> <year> 1989. </year>
Reference-contexts: Furthermore, the system described here has a relatively high memory requirement, since 2*NUMFOR*NUMRUL weights must be stored. The algorithm can be used with knowledge-based neural networks <ref> [3] </ref>. Knowledge-based neural networks, using our algorithm, could be taught in such a way that they would answer not only: which rules are true, but also which are worth applying.
Reference: [4] <author> Luger, G.; Stubblefield, W.; </author> <title> Artificial intelligence: structures and strategies for complex problem solving. </title> <publisher> The Benjamin/Cummings Publishing Company, </publisher> <year> 1993. </year> <title> TABLE 1 Test Results Database Number of Description Efficiency Rules Stat. </title> <booktitle> Rand Occ Goal ML1 ML2 Soil science 30 29 Soil science knowledge base 31% 33% 61% 38% 92% Random1 25 80 NUMLAY=5, </booktitle> <volume> MAXIF=MAXTHEN=3 38% 34% 70% 83% 99% Random2 25 80 NUMLAY=5, MAXIF=4, MAXTHEN=2 42% 31% 44% 50% 84% Random3 25 80 NUMLAY=5, MAXIF=2, MAXTHEN=4 34% 48% 50% 68% 99% Random4 24 80 NUMLAY=3, MAXIF=MAXTHEN=3 22% 18% 37% 30% 94% </volume>
Reference-contexts: Clearly, suboptimal solutions lead to inefficiencies, which become worse with the size of the knowledge base. To improve rule selection (i.e., reduce the number of rules being applied), heuristics are typically used [1]. There are two general families of heuristics, namely weak heuristics and strong heuristics <ref> [4] </ref>. Weak heuristics are domain-independent.
References-found: 4

