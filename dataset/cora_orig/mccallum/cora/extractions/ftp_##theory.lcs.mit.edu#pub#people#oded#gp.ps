URL: ftp://theory.lcs.mit.edu/pub/people/oded/gp.ps
Refering-URL: http://theory.lcs.mit.edu/~oded/kc.html
Root-URL: 
Title: Quantifying Knowledge Complexity  
Author: Oded Goldreich Erez Petrank 
Date: July 17, 1997  
Abstract: One of the many contributions of the paper of Goldwasser, Micali and Rackoff is the introduction of the notion of knowledge complexity. Knowledge complexity zero (also known as zero-knowledge) have received most of the attention of the authors and all the attention of their followers. In this paper, we present several alternative definitions of knowledge complexity and investigate the relations between them. fl An extended abstract of this paper appeared in the 32nd Annual IEEE Symposium on the Foundations of Com puter Science (FOCS91) held in San Juan, Puerto Rico, October 1991. y Department of Computer Science and Applied Mathematics, Weizmann Institute of Science, Rehovot, Israel. E-mail: oded@wisdom.weizmann.ac.il. z Computer Science Department, Technion - Israel Institute of Technology, Haifa 32000, Israel. E-mail: erez@cs.technion.ac.il. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Aiello, W., M. Bellare, and R. Venkatesan, </author> <title> "Knowledge on the Average Perfect, Statistical, and Logarithmic", </title> <booktitle> Proc. 27th STOC, </booktitle> <pages> pp. 469-478, </pages> <year> 1995. </year>
Reference-contexts: The second direction, pursued by Aiello, Bellare and Venkatesan <ref> [1] </ref>, focuses on knowledge-complexity under the average oracle measure. Firstly, they introduced a more refined definition of average knowledge-complexity and related it to the notion defined in this paper. Secondly, they showed that the perfect and statistical average knowledge-complexity hierarchies of languages are close up to a negligible additive term. <p> Completeness: Suppose x 2 L (i.e., x 62 L). The construction of [2] guarantees that (P 00 ; V 00 ) accepts x with probability at least 1 (jxj) when P 00 and V 00 are given access to a proper simulator and where : N ! <ref> [0; 1] </ref> is some negligible fraction. However, by Claim 6.1, (P 00 ; V 00 ) accepts x with this probability also when P 00 and V 00 are given access to any probabilistic polynomial time machine (and not necessarily to a simulator for (P; V )).
Reference: [2] <author> Aiello, W., and J. H-astad, </author> <title> "Perfect Zero-Knowledge Languages can be Recognized in Two Rounds", </title> <journal> JCSS, </journal> <volume> Vol. 42, </volume> <pages> pages 327-345, </pages> <year> 1991. </year>
Reference-contexts: The resulting definition is called statistical (or almost perfect) zero-knowledge. For example, the results of Fortnow [10] and of Aiello and H-astad <ref> [2] </ref> on the "complexity of zero-knowledge" refer to this definition. 3. Most liberal is the requirement that the ensembles are indistinguishable by all probabilistic polynomial time tests. The resulting definition is called computational zero-knowledge. <p> These hopes should be abandoned if one believes, as us, that all languages in IP must have at most polynomial knowledge-complexity: In Section 6 we extend the work of Aiello and H-astad <ref> [2] </ref>, who in turn follow Fortnow's ideas [10], showing that languages having polynomial knowledge-complexity in the hint sense are in AM [2]. 4 Thus, languages having polynomial knowledge-complexity by the hint measure are unlikely to contain all of IP. 1.4 Relating the various definitions of Knowledge Complexity In order to summarize <p> be abandoned if one believes, as us, that all languages in IP must have at most polynomial knowledge-complexity: In Section 6 we extend the work of Aiello and H-astad <ref> [2] </ref>, who in turn follow Fortnow's ideas [10], showing that languages having polynomial knowledge-complexity in the hint sense are in AM [2]. 4 Thus, languages having polynomial knowledge-complexity by the hint measure are unlikely to contain all of IP. 1.4 Relating the various definitions of Knowledge Complexity In order to summarize our results concerning the relations between the various definitions, we present the following unsound notations. 5 Let kc strict oracle (); <p> polynomial p : N ! N , there exists a protocol such that kc oracle () = p (jxj) and kc strict oracle () kc 1=2 oracle () + log (log (jxj)) + c. 4 We also show that languages having logarithmic knowledge-complexity in the hint sense are in coAM <ref> [2] </ref>. 5 The notations below suggest that knowledge-complexity is a functional which assigns each protocol a unique function (i.e., upper bound). This is inaccurate since actually each protocol is assigned a (countable) set of functions; see Section 2. <p> In particular it was shown how to transform an interactive proof of statistical knowledge complexity k () (w.r.t. the honest verifier) into an interactive proof of perfect knowledge complexity k () + O (log ()) (w.r.t. the honest verifier). Petrank and Tardos [26] have extended <ref> [2] </ref> and [15] and showed that languages with logarithmic knowledge complexity are in AM " coAM. Thus, unless the polynomial time hierarchy collapses, N P-complete languages have super-logarithmic knowledge-complexity. <p> proof of Theorem 5.1, and so we may apply the same arguments here (i.e., to the function K (x) def 6 Knowledge complexity of languages in the hint sense In this section we investigate the "hint-knowledge complexity" hierarchy of languages and establish two results - KC hint (poly (jxj)) AM <ref> [2] </ref>, and KC hint (O (log (jxj)) coAM [2]. These results are obtained by extending the result proven for zero-knowledge by Fortnow [10] and Aiello and H-astad 30 [2]. In the sequel, we follow the construction of [2] 20 . <p> apply the same arguments here (i.e., to the function K (x) def 6 Knowledge complexity of languages in the hint sense In this section we investigate the "hint-knowledge complexity" hierarchy of languages and establish two results - KC hint (poly (jxj)) AM <ref> [2] </ref>, and KC hint (O (log (jxj)) coAM [2]. These results are obtained by extending the result proven for zero-knowledge by Fortnow [10] and Aiello and H-astad 30 [2]. In the sequel, we follow the construction of [2] 20 . One doesn't have to master the techniques used in that work in order to understand our proofs. <p> sense In this section we investigate the "hint-knowledge complexity" hierarchy of languages and establish two results - KC hint (poly (jxj)) AM <ref> [2] </ref>, and KC hint (O (log (jxj)) coAM [2]. These results are obtained by extending the result proven for zero-knowledge by Fortnow [10] and Aiello and H-astad 30 [2]. In the sequel, we follow the construction of [2] 20 . One doesn't have to master the techniques used in that work in order to understand our proofs. Yet, some properties of these techniques, explicitly stated below, are essential to the validity of our proofs. The construction in [2] considers <p> hierarchy of languages and establish two results - KC hint (poly (jxj)) AM <ref> [2] </ref>, and KC hint (O (log (jxj)) coAM [2]. These results are obtained by extending the result proven for zero-knowledge by Fortnow [10] and Aiello and H-astad 30 [2]. In the sequel, we follow the construction of [2] 20 . One doesn't have to master the techniques used in that work in order to understand our proofs. Yet, some properties of these techniques, explicitly stated below, are essential to the validity of our proofs. The construction in [2] considers the interactive proof (P; V ) for L and <p> 30 <ref> [2] </ref>. In the sequel, we follow the construction of [2] 20 . One doesn't have to master the techniques used in that work in order to understand our proofs. Yet, some properties of these techniques, explicitly stated below, are essential to the validity of our proofs. The construction in [2] considers the interactive proof (P; V ) for L and the simulator M of (P; V ) guaranteed by the hypothesis 21 . They use the simulator to build a new interactive proof (P 0 ; V 0 ) for L which is of constant number of rounds. <p> They use the simulator to build a new interactive proof (P 0 ; V 0 ) for L which is of constant number of rounds. A simple enhancement in the construction (see <ref> [2, 22] </ref>) produces also an interactive proof (P 00 ; V 00 ) for L (the complement of L) which also has a constant number of rounds. (Employing [21] and [5] they get that L and L are in AM [2].) We first note that the use of M in these <p> A simple enhancement in the construction (see [2, 22]) produces also an interactive proof (P 00 ; V 00 ) for L (the complement of L) which also has a constant number of rounds. (Employing [21] and [5] they get that L and L are in AM <ref> [2] </ref>.) We first note that the use of M in these proof systems is limited. The proof considers only the function f M;x which is defined so that f M;x (r) is the output of M on input x and random string r. <p> Namely, when x 62 L, the only property of f M;x () which is guaranteed by M being a simulator is that f M;x () is computable in polynomial time (in jxj). Returning to the proof systems in <ref> [10, 2] </ref>, we get that when x 62 L, the properties of these proof systems are maintained also in the case that they are given access to any polynomial time (in the length of their input x) computable function f () and not necessarily to f M;x (). <p> Theorem 6.2 Let L be a language that has an interactive proof with knowledge complexity k = poly (jxj) in the Hint sense, then L 2 AM <ref> [2] </ref>. Proof: We have a language L accepted by an interactive proof (P; V ), and a simulator M that on the input x, and the hint h (x), produces a conversation. If M gets the right hint, it produces a good simulation of (P; V ). <p> If M gets the right hint, it produces a good simulation of (P; V ). Otherwise, nothing is guaranteed about the behavior of M , except for polynomial running time. We use the interactive proof (P 0 ; V 0 ) for L given by <ref> [2] </ref> with a preliminary step. In this step, P 0 sends V 0 the hint h (x) associated with the input x. <p> After this step, P 0 and V 0 build a ma chine M 0 (x) def = M (x; h (x)) and proceed by running the protocol (P 0 ; V 0 ) on the input x using the simulator M 0 . 20 The AM <ref> [2] </ref> protocol built in [10] for a language L whose complement has a statistical zero-knowledge interactive proof has a flaw (see Appendix A in [15] for further details). However, the basic ideas in [10] were extended in [2] to construct an AM [2] protocol for a language L that has a <p> on the input x using the simulator M 0 . 20 The AM <ref> [2] </ref> protocol built in [10] for a language L whose complement has a statistical zero-knowledge interactive proof has a flaw (see Appendix A in [15] for further details). However, the basic ideas in [10] were extended in [2] to construct an AM [2] protocol for a language L that has a statistical zero-knowledge interactive proof. Furthermore, the additional machinery presented in [2] suffices also for proving Fortnow's result (see [22] details of how to use the machinery of [2] to prove Fortnow's result). <p> the simulator M 0 . 20 The AM <ref> [2] </ref> protocol built in [10] for a language L whose complement has a statistical zero-knowledge interactive proof has a flaw (see Appendix A in [15] for further details). However, the basic ideas in [10] were extended in [2] to construct an AM [2] protocol for a language L that has a statistical zero-knowledge interactive proof. Furthermore, the additional machinery presented in [2] suffices also for proving Fortnow's result (see [22] details of how to use the machinery of [2] to prove Fortnow's result). <p> However, the basic ideas in [10] were extended in <ref> [2] </ref> to construct an AM [2] protocol for a language L that has a statistical zero-knowledge interactive proof. Furthermore, the additional machinery presented in [2] suffices also for proving Fortnow's result (see [22] details of how to use the machinery of [2] to prove Fortnow's result). Alternatively, see [26]. 21 Note that though the zero-knowledge property implies the existence of many simulators (one for each possible verifier), [2] use only the simulator for the original <p> However, the basic ideas in [10] were extended in <ref> [2] </ref> to construct an AM [2] protocol for a language L that has a statistical zero-knowledge interactive proof. Furthermore, the additional machinery presented in [2] suffices also for proving Fortnow's result (see [22] details of how to use the machinery of [2] to prove Fortnow's result). Alternatively, see [26]. 21 Note that though the zero-knowledge property implies the existence of many simulators (one for each possible verifier), [2] use only the simulator for the original interactive proof (P; V ), where V is not cheating. 31 It is clear that if both <p> Furthermore, the additional machinery presented in <ref> [2] </ref> suffices also for proving Fortnow's result (see [22] details of how to use the machinery of [2] to prove Fortnow's result). Alternatively, see [26]. 21 Note that though the zero-knowledge property implies the existence of many simulators (one for each possible verifier), [2] use only the simulator for the original interactive proof (P; V ), where V is not cheating. 31 It is clear that if both prover and verifier act according to the protocol, then completeness is ensured. Claim 6.1 implies the soundness of the protocol. <p> Claim 6.1 implies the soundness of the protocol. The number of rounds is a constant, and using [5] and [21] we get L 2 AM <ref> [2] </ref> as desired. 2 Theorem 6.3 Let L be a language that has an interactive proof with knowledge complexity k = O (log (n)) in the Hint sense, then L 2 coAM [2]. Proof: Let us define 2 k (jxj) new simulators. <p> The number of rounds is a constant, and using [5] and [21] we get L 2 AM <ref> [2] </ref> as desired. 2 Theorem 6.3 Let L be a language that has an interactive proof with knowledge complexity k = O (log (n)) in the Hint sense, then L 2 coAM [2]. Proof: Let us define 2 k (jxj) new simulators. For each ff 2 f0; 1g k , let M 0 ff (x) = M (x; ff) where M is the hint machine which simulates the original interactive proof (P; V ). <p> Obviously, M 0 h (x) is a good simulating machine for (P; V ). The interactive proof we build runs (P 00 ; V 00 ), the protocol constructed in <ref> [2] </ref> for L, for 2 k times in parallel. The i th copy uses M 0 i as its black box simulator. Our new verifier will accept the input x iff all the sub-protocols end up accepting. Completeness: Suppose x 2 L (i.e., x 62 L). The construction of [2] guarantees <p> in <ref> [2] </ref> for L, for 2 k times in parallel. The i th copy uses M 0 i as its black box simulator. Our new verifier will accept the input x iff all the sub-protocols end up accepting. Completeness: Suppose x 2 L (i.e., x 62 L). The construction of [2] guarantees that (P 00 ; V 00 ) accepts x with probability at least 1 (jxj) when P 00 and V 00 are given access to a proper simulator and where : N ! [0; 1] is some negligible fraction.
Reference: [3] <author> W. Alexi, B. Chor, O. Goldreich, and C. P. Schnorr, </author> <title> "RSA/Rabin Functions: Certain Parts are As Hard As the Whole", </title> <journal> SIAM J. Comp., </journal> <volume> Vol. 17, No. 2, </volume> <month> April </month> <year> 1988, </year> <pages> pp. 194-209. </pages>
Reference-contexts: Example 5 Let N be as in Example 4. Suppose that Alice agrees to provide Bob with the least significant bit of the square root (mod N ) of any quadratic residue mod N of Bob's choice. By <ref> [20, 3] </ref> such an answer (by Alice) does yield knowledge to Bob and furthermore jN j answers of this form allow Bob to factor N . Thus, although each answer yields little knowledge (as can be argued analogously to Example 4), many answers yield substantial knowledge.
Reference: [4] <author> Alon, N., L., Babai and A. Itai, </author> <title> "A Fast and Simple Randomized Algorithm for the Maximal Independent Set Problem", </title> <journal> J. of Algorithms, </journal> <volume> Vol. 7, </volume> <year> 1986, </year> <pages> pp. 567-583. </pages>
Reference-contexts: Actually, our analysis becomes even easier if we use a sequence of 3-wise independent random variables. It will be most convenient to use the construction given in Alon et. al. <ref> [4] </ref> which works in the field GF (2 m ), since this field corresponds naturally to the set of m-bit strings. The construction uses t &lt; 2 m arbitrary elements of the field, denoted ff 1 ; ff 2 ; :::; ff t .
Reference: [5] <author> Babai, L., </author> <title> "Trading group theory for randomness", </title> <booktitle> Proc. 17th STOC, </booktitle> <year> 1985, </year> <pages> pp. 421-429. 32 </pages>
Reference-contexts: Furthermore, these protocols are in the public-coin (Arthur-Merlin) model of Babai <ref> [5] </ref>, and can be proven to have bounded knowledge complexity by using a black-box simulator. <p> A simple enhancement in the construction (see [2, 22]) produces also an interactive proof (P 00 ; V 00 ) for L (the complement of L) which also has a constant number of rounds. (Employing [21] and <ref> [5] </ref> they get that L and L are in AM [2].) We first note that the use of M in these proof systems is limited. <p> Claim 6.1 implies the soundness of the protocol. The number of rounds is a constant, and using <ref> [5] </ref> and [21] we get L 2 AM [2] as desired. 2 Theorem 6.3 Let L be a language that has an interactive proof with knowledge complexity k = O (log (n)) in the Hint sense, then L 2 coAM [2]. Proof: Let us define 2 k (jxj) new simulators.
Reference: [6] <author> Bar-Yehuda, R., B. Chor, and E. Kushilevitz, </author> <title> "Privacy, Additional Information, </title> <booktitle> and Commu--nication", 5th IEEE Structure in Complexity Theory, </booktitle> <month> July </month> <year> 1990, </year> <pages> pp. 55-65. </pages>
Reference-contexts: Hence, the amount of knowledge (in the hint sense) leaked by two executions of the same protocol on the same input, always equals the amount of knowledge leaked by a single execution. We note that the hint-length measure was suggested in <ref> [6] </ref>, and seems adequate in the information theoretic model discussed there. We have several reasons for objecting to the last measure of knowledge-complexity (i.e., the hint length measure).
Reference: [7] <author> Bellare M. and E. Petrank, </author> <title> "Making Zero Knowledge Provers Efficient", </title> <booktitle> Proc. 24th STOC, </booktitle> <year> 1992, </year> <pages> pp. 711-722. </pages>
Reference-contexts: The first direction, pursued in <ref> [7] </ref>, [15] and [26], focuses on the oracle (or, equivalently fraction) measure of knowledge complexity and is aimed at relating the knowledge complexity of languages to their computational complexity. The first step was taken by Bellare and Petrank [7] who showed that any language having a r ()-round interactive proof of <p> The first direction, pursued in <ref> [7] </ref>, [15] and [26], focuses on the oracle (or, equivalently fraction) measure of knowledge complexity and is aimed at relating the knowledge complexity of languages to their computational complexity. The first step was taken by Bellare and Petrank [7] who showed that any language having a r ()-round interactive proof of (statistical) knowledge complexity k (), where k (n) r (n) = O (log n), resides in BPP NP . <p> Subsequently, Goldreich, Ostrovsky and Pe-trank [15] showed that all languages that have logarithmic (statistical) knowledge complexity are in BPP NP . This was done by providing a refined analysis of a procedure in <ref> [7] </ref> and by relating the hierarchies of statistical and perfect knowledge-complexity with respect to the honest verifier 6 .
Reference: [8] <author> Ben-Or, M., O. Goldreich, S. Goldwasser, J. H-astad, J. Kilian, S. Micali, and P. Rogaway, </author> <title> "Everything Provable is Provable in Zero-Knowledge", </title> <booktitle> Advances in Cryptology - Crypto88 (proceedings), Springer-Verlag, Lecture Notes in Computer Science, </booktitle> <volume> Vol. 403, </volume> <pages> pp. 37-56, </pages> <year> 1990. </year>
Reference-contexts: As per the knowledge-complexity hierarchies of languages, under some reasonable assumptions, the hierarchy of computational knowledge-complexity is quite dull. That is, assuming the existence of secure bit commitment scheme (i.e., the existence of one-way functions), all languages having interactive proofs have interactive proofs of computational knowledge-complexity zero <ref> [8, 23] </ref>. 12 3.2 Analyzing the examples of the introduction Alice's behavior in Examples 1 and 2 is zero-knowledge and thus of knowledge-complexity zero under all our definitions. In general, it is easy to see that zero-knowledge coincides with knowledge-complexity zero under all our definitions.
Reference: [9] <author> T.M. Cover and G.A. Thomas, </author> <title> Elements of Information Theory, </title> <publisher> John Wiley & Sons, Inc., </publisher> <address> New-York, </address> <year> 1991. </year>
Reference-contexts: Knowledge complexity is intended to capture this increase in computing ability. Thus, knowledge complexity is a fundamental measure of interaction between parties, and it differs from other measures of interaction such as information entropy <ref> [27, 9] </ref> and communication complexity [28, 24]. The following examples may help to illustrate what we mean. In all these examples we assume that Bob is restricted to probabilistic polynomial-time (in the parameter n), whereas no computation restrictions are placed on Alice.
Reference: [10] <author> Fortnow, L., </author> <title> "The Complexity of Perfect Zero-Knowledge", </title> <booktitle> Advances in Computing Research: a research annual, Vol. 5 (Randomness and Computation, </booktitle> <editor> S. Micali, </editor> <publisher> ed.), </publisher> <pages> pages 327-343, </pages> <year> 1989. </year>
Reference-contexts: The resulting definition is called statistical (or almost perfect) zero-knowledge. For example, the results of Fortnow <ref> [10] </ref> and of Aiello and H-astad [2] on the "complexity of zero-knowledge" refer to this definition. 3. Most liberal is the requirement that the ensembles are indistinguishable by all probabilistic polynomial time tests. The resulting definition is called computational zero-knowledge. <p> These hopes should be abandoned if one believes, as us, that all languages in IP must have at most polynomial knowledge-complexity: In Section 6 we extend the work of Aiello and H-astad [2], who in turn follow Fortnow's ideas <ref> [10] </ref>, showing that languages having polynomial knowledge-complexity in the hint sense are in AM [2]. 4 Thus, languages having polynomial knowledge-complexity by the hint measure are unlikely to contain all of IP. 1.4 Relating the various definitions of Knowledge Complexity In order to summarize our results concerning the relations between the <p> These results are obtained by extending the result proven for zero-knowledge by Fortnow <ref> [10] </ref> and Aiello and H-astad 30 [2]. In the sequel, we follow the construction of [2] 20 . One doesn't have to master the techniques used in that work in order to understand our proofs. <p> Namely, when x 62 L, the only property of f M;x () which is guaranteed by M being a simulator is that f M;x () is computable in polynomial time (in jxj). Returning to the proof systems in <ref> [10, 2] </ref>, we get that when x 62 L, the properties of these proof systems are maintained also in the case that they are given access to any polynomial time (in the length of their input x) computable function f () and not necessarily to f M;x (). <p> After this step, P 0 and V 0 build a ma chine M 0 (x) def = M (x; h (x)) and proceed by running the protocol (P 0 ; V 0 ) on the input x using the simulator M 0 . 20 The AM [2] protocol built in <ref> [10] </ref> for a language L whose complement has a statistical zero-knowledge interactive proof has a flaw (see Appendix A in [15] for further details). However, the basic ideas in [10] were extended in [2] to construct an AM [2] protocol for a language L that has a statistical zero-knowledge interactive proof. <p> ; V 0 ) on the input x using the simulator M 0 . 20 The AM [2] protocol built in <ref> [10] </ref> for a language L whose complement has a statistical zero-knowledge interactive proof has a flaw (see Appendix A in [15] for further details). However, the basic ideas in [10] were extended in [2] to construct an AM [2] protocol for a language L that has a statistical zero-knowledge interactive proof. Furthermore, the additional machinery presented in [2] suffices also for proving Fortnow's result (see [22] details of how to use the machinery of [2] to prove Fortnow's result).
Reference: [11] <author> O. </author> <type> Goldreich, </type> <institution> Foundations of Cryptography Fragments of a Book Department of Computer Science and Applied Mathematics, Weizmann Institute of Science, Is-rael, </institution> <month> February </month> <year> 1995. </year> <note> Available from http://theory.lcs.mit.edu/~oded/frag.html and http://www.eccc.uni-trier.de/eccc/. </note>
Reference-contexts: The above discussion applies to many other protocols. In particular, we mention M. Blum's zero-knowledge interactive proof system (of soundness error 1=2) for Hamiltonicity <ref> [11, Chap. 6, Exer. 15] </ref>. Thus, assuming the existence of one-way functions (as in [13]), there are constant-round interactive proofs of super-logarithmic computational knowledge complexity for any language in 12 As in [13], any inappropriate response is interpreted as a canonical response, say the sequence 1; :::; 1. 13 NP.
Reference: [12] <author> Goldreich, O. and H. Krawczyk, </author> <title> "On the Composition of Zero-Knowledge Proof Systems", </title> <journal> SIAM Journal on Computing, </journal> <volume> Vol. 25, No. 1, </volume> <month> February </month> <year> 1996, </year> <pages> pp. 169-192. </pages>
Reference-contexts: Things become less robust when zero-knowledge is involved, since the latter is not known to be preserved under parallel repetitions (see negative results in <ref> [12] </ref>). Still, zero-knowledge (w.r.t. auxiliary-input) is preserved under sequential repetitions (see [14]). However, not all measures of knowledge complexity defined below are preserved under sequential repetitions. Thus, when talking about an interactive proof of certain knowledge complexity we must specify the error probability of the system. <p> In contrast, consider the protocol, denoted t GI , resulting from t (jxj) parallel repetition of the basic protocol. Indeed, t GI is also an interactive proof system (with negligible error) for Graph Isomorphism. However, unless Graph Isomorphism is in BPP, protocol t GI is unlikely to be zero-knowledge <ref> [12] </ref>. Still, we can bound the knowledge complexity of t GI by t. Proposition 3.1 kc fraction ( t GI ) t (). <p> Furthermore, these protocols are in the public-coin (Arthur-Merlin) model of Babai [5], and can be proven to have bounded knowledge complexity by using a black-box simulator. These protocols cannot be proven to be in zero-knowledge using a black-box simulator, unless N P BPP (cf., <ref> [12] </ref>). 3.4 The effect of sequential repetitions Recall that zero-knowledge is preserved under sequential repetitions, provided that the definition is augmented to allow for auxiliary inputs: See [12] for demonstration of the necessity of an augmentation, and [14] for a definition of auxiliary-input zero-knowledge and a proof that it is preserved <p> These protocols cannot be proven to be in zero-knowledge using a black-box simulator, unless N P BPP (cf., <ref> [12] </ref>). 3.4 The effect of sequential repetitions Recall that zero-knowledge is preserved under sequential repetitions, provided that the definition is augmented to allow for auxiliary inputs: See [12] for demonstration of the necessity of an augmentation, and [14] for a definition of auxiliary-input zero-knowledge and a proof that it is preserved under sequential repetitions. It should thus come at no surprise that we start by augmenting our definitions so to handle auxiliary-inputs.
Reference: [13] <author> Goldreich, O., S. Micali, and A. Wigderson, </author> <title> "Proofs that Yield Nothing But their Validity or All Languages in NP Have Zero-Knowledge proof Systems", </title> <journal> Jour. of ACM., </journal> <volume> Vol. 38, </volume> <year> 1991, </year> <pages> pp. 691-729. </pages>
Reference-contexts: Most liberal is the requirement that the ensembles are indistinguishable by all probabilistic polynomial time tests. The resulting definition is called computational zero-knowledge. For example, the result of <ref> [13] </ref> asserting that "all languages in NP have zero-knowledge proofs provided that commitment schemes exist" refers to this definition. 1.3 Defining Knowledge Complexity Unless otherwise indicated, the following discussion refers to the definitions of knowledge complexity in which the simulated conversations are close to the real one in the statistical sense. <p> In this case the best bound we can offer is the length of the prime factorization of N (again, save the last factor). 3.3 Another example: Parallel repetitions of some protocols Consider the basic zero-knowledge interactive proof system (of soundness error 1=2) for Graph Isomorphism <ref> [13] </ref>: On input x = (G 1 ; G 2 ), the prover generates a random isomorphic copy, denoted H, of G 1 and sends it to the verifier. The verifier uniformly selects 2 f1; 2g and the prover replies with the isomorphism between H and G . Example 7. <p> However, unless Graph Isomorphism is in BPP, protocol t GI is unlikely to be zero-knowledge [12]. Still, we can bound the knowledge complexity of t GI by t. Proposition 3.1 kc fraction ( t GI ) t (). Proof: Use the obvious simulator (a la <ref> [13] </ref>): Uniformly select 1 ; :::; t 2 f1; 2g and generate graphs H 1 ; :::; H t so that H i is a random isomorphic copy of G i . Send the sequence of graphs to the verifier. <p> The above discussion applies to many other protocols. In particular, we mention M. Blum's zero-knowledge interactive proof system (of soundness error 1=2) for Hamiltonicity [11, Chap. 6, Exer. 15]. Thus, assuming the existence of one-way functions (as in <ref> [13] </ref>), there are constant-round interactive proofs of super-logarithmic computational knowledge complexity for any language in 12 As in [13], any inappropriate response is interpreted as a canonical response, say the sequence 1; :::; 1. 13 NP. <p> In particular, we mention M. Blum's zero-knowledge interactive proof system (of soundness error 1=2) for Hamiltonicity [11, Chap. 6, Exer. 15]. Thus, assuming the existence of one-way functions (as in <ref> [13] </ref>), there are constant-round interactive proofs of super-logarithmic computational knowledge complexity for any language in 12 As in [13], any inappropriate response is interpreted as a canonical response, say the sequence 1; :::; 1. 13 NP. Furthermore, these protocols are in the public-coin (Arthur-Merlin) model of Babai [5], and can be proven to have bounded knowledge complexity by using a black-box simulator.
Reference: [14] <author> Goldreich, O. and Y. Oren, </author> <title> "Definitions and Properties of Zero-Knowledge Proof Systems", </title> <journal> Jour. of Cryptology, </journal> <volume> Vol. 7, </volume> <year> 1994, </year> <pages> pp. 1-32. </pages>
Reference-contexts: Things become less robust when zero-knowledge is involved, since the latter is not known to be preserved under parallel repetitions (see negative results in [12]). Still, zero-knowledge (w.r.t. auxiliary-input) is preserved under sequential repetitions (see <ref> [14] </ref>). However, not all measures of knowledge complexity defined below are preserved under sequential repetitions. Thus, when talking about an interactive proof of certain knowledge complexity we must specify the error probability of the system. <p> to be in zero-knowledge using a black-box simulator, unless N P BPP (cf., [12]). 3.4 The effect of sequential repetitions Recall that zero-knowledge is preserved under sequential repetitions, provided that the definition is augmented to allow for auxiliary inputs: See [12] for demonstration of the necessity of an augmentation, and <ref> [14] </ref> for a definition of auxiliary-input zero-knowledge and a proof that it is preserved under sequential repetitions. It should thus come at no surprise that we start by augmenting our definitions so to handle auxiliary-inputs. <p> This is easy when the possibly cheating verifier (in t ) "respects" the structure of t (i.e., its actions in the i th run of are independent of previous runs). However, this may not be true in general and overcoming the difficulties is done by adapting the ideas in <ref> [14] </ref>. Suppose 13 Alternatively, one may adopt a more liberal measure in which the hint may be a function of both the common input and the auxiliary input. We do not know whether Proposition 3.3 holds under this alternative definition.
Reference: [15] <author> Goldreich, O., R. Ostrovsky, and E. Petrank, </author> <title> "Computational Complexity and Knowledge Complexity", </title> <booktitle> 26th ACM Symp. on Theory of Computation, </booktitle> <month> May </month> <year> 1994. </year> <pages> pp. 534-543. </pages> <note> To appear in SIAM J. on Comput., </note> <year> 1998. </year>
Reference-contexts: The first direction, pursued in [7], <ref> [15] </ref> and [26], focuses on the oracle (or, equivalently fraction) measure of knowledge complexity and is aimed at relating the knowledge complexity of languages to their computational complexity. <p> The first step was taken by Bellare and Petrank [7] who showed that any language having a r ()-round interactive proof of (statistical) knowledge complexity k (), where k (n) r (n) = O (log n), resides in BPP NP . Subsequently, Goldreich, Ostrovsky and Pe-trank <ref> [15] </ref> showed that all languages that have logarithmic (statistical) knowledge complexity are in BPP NP . This was done by providing a refined analysis of a procedure in [7] and by relating the hierarchies of statistical and perfect knowledge-complexity with respect to the honest verifier 6 . <p> In particular it was shown how to transform an interactive proof of statistical knowledge complexity k () (w.r.t. the honest verifier) into an interactive proof of perfect knowledge complexity k () + O (log ()) (w.r.t. the honest verifier). Petrank and Tardos [26] have extended [2] and <ref> [15] </ref> and showed that languages with logarithmic knowledge complexity are in AM " coAM. Thus, unless the polynomial time hierarchy collapses, N P-complete languages have super-logarithmic knowledge-complexity. <p> (x)) and proceed by running the protocol (P 0 ; V 0 ) on the input x using the simulator M 0 . 20 The AM [2] protocol built in [10] for a language L whose complement has a statistical zero-knowledge interactive proof has a flaw (see Appendix A in <ref> [15] </ref> for further details). However, the basic ideas in [10] were extended in [2] to construct an AM [2] protocol for a language L that has a statistical zero-knowledge interactive proof.
Reference: [16] <author> Goldreich, O. and E. Petrank, </author> <title> "Quantifying Knowledge Complexity", </title> <booktitle> the 32nd Annual IEEE Symposium on the Foundations of Computer Science, </booktitle> <month> October </month> <year> 1991, </year> <pages> pp. 59-68. </pages>
Reference-contexts: Using Proposition 2.6, 18 the current proposition follows. 2 Remark 4.5 Our original proof of Proposition 4.3 (cf., <ref> [16] </ref>) used a more complicated construction of a "somewhat random" list with no apparent advantage. Furthermore, the additive constant achieved there (i.e., 11) is worse. 4.2 The oracle vs. average oracle measure Proposition 4.6 For any interactive proof , kc oracle () kc 1=2 oracle () + 2.
Reference: [17] <author> S. Goldwasser and S. Micali, </author> <title> "Probabilistic Encryption", </title> <journal> JCSS, </journal> <volume> Vol. 28, No. 2, </volume> <pages> pages 270-299, </pages> <year> 1984. </year> <note> Preliminary version in 14th STOC, </note> <year> 1982. </year>
Reference-contexts: Recall that one fourth of the elements of Z fl N are in QN R + N and that it is considered infeasible to distinguish elements of QN R + N from quadratic residues mod N <ref> [17] </ref>. Suppose that Alice uniformly selects a y 2 QN R + N and sends it to Bob. It seems that Bob has gained some knowledge (as we don't know how to uniformly sample QN R + N in polynomial-time when only given N ).
Reference: [18] <author> Goldwasser, S., S. Micali, and C. Rackoff, </author> <title> "The Knowledge Complexity of Interactive Proofs", </title> <booktitle> Proc. 17th STOC, </booktitle> <year> 1985, </year> <pages> pp. 291-304. </pages>
Reference-contexts: Knowledge complexity is intended to measure the computational advantage gained by interaction. Hence, something that can be obtained without interaction is not considered knowledge. The latter phrase is somewhat qualitative and supplies the intuition underlying the definition of zero-knowledge (i.e., knowledge complexity zero) given in <ref> [18] </ref>. <p> Thus, although each answer yields little knowledge (as can be argued analogously to Example 4), many answers yield substantial knowledge. Examples 3, 4 and 5 demonstrate that there is more to knowledge complexity than merely determining whether a protocol is zero-knowledge or not. Following Goldwasser, Micali and Rackoff <ref> [18] </ref>, we suggest that the knowledge gained by interaction can be quantified. The analogy to information theory and communication complexity is telling: none of these stops at a binary distinction between zero and positive. <p> The analogy to information theory and communication complexity is telling: none of these stops at a binary distinction between zero and positive. Goldwasser, Micali and Rackoff have suggested to characterize languages according to the knowledge complexity of their interactive proof systems <ref> [18] </ref>. The lowest class consists of languages having knowledge complexity zero. This class, also known as zero-knowledge, has received much attention in recent years. The following example may serve as a teaser for the low (non-zero) levels of the knowledge complexity hierarchy: Example 6 composing zero-knowledge languages. <p> Here we consider knowledge complexity in the context of interactive proof systems. The actual definitions apply to any pair of interactive machines. 3 A first attempt. An attempt to formalize the "amount of knowledge" (in case it is not zero) has appeared in the preliminary version of <ref> [18] </ref> but was omitted from the later version of this work [19] since the authors themselves found it inadequate (Micali, private communication). By the preliminary formulation of [18] the knowledge complexity of an interactive proof (P; V ) is said to be k (jxj) if there exists a simulator which can <p> An attempt to formalize the "amount of knowledge" (in case it is not zero) has appeared in the preliminary version of <ref> [18] </ref> but was omitted from the later version of this work [19] since the authors themselves found it inadequate (Micali, private communication). By the preliminary formulation of [18] the knowledge complexity of an interactive proof (P; V ) is said to be k (jxj) if there exists a simulator which can generate a distribution M (x) such that the variation distance 2 of M (x) and (P; V )(x) is bounded above by 1 2 k (jxj) + <p> Also note that Alice's behavior in Example 4 is clearly of knowledge complexity 1 according to the definition here. Interestingly, the definition of knowledge complexity as a "logarithm of the good fraction" agrees with the informal discussion in <ref> [18] </ref> (although the formal definition presented there was different see above). In fact, Micali (private communication) has independently discovered the "fraction" definition. We show that knowledge-complexity as per the fraction measure approximates (up to an additive constant) the oracle measure of knowledge-complexity.
Reference: [19] <author> Goldwasser, S., S. Micali, and C. Rackoff, </author> <title> "The Knowledge Complexity of Interactive Proof Systems", </title> <journal> SIAM Jour. on Computing, </journal> <volume> Vol. 18, </volume> <year> 1989, </year> <pages> pp. 186-208. </pages>
Reference-contexts: Similarity is interpreted in three possible ways yielding three different definitions of zero-knowledge. 1. The most conservative interpretation is that the ensembles are identical. The resulting definition is called perfect zero-knowledge. An example of a language having a perfect zero knowledge interactive proof is Quadratic Non-Residuosity <ref> [19] </ref>. 2. Slightly more liberal is the requirement that the ensembles are statistically close, namely that their variation distance (Norm-1 difference) is negligible (i.e., smaller than any polynomial fraction in the length of the common input). The resulting definition is called statistical (or almost perfect) zero-knowledge. <p> The actual definitions apply to any pair of interactive machines. 3 A first attempt. An attempt to formalize the "amount of knowledge" (in case it is not zero) has appeared in the preliminary version of [18] but was omitted from the later version of this work <ref> [19] </ref> since the authors themselves found it inadequate (Micali, private communication).
Reference: [20] <author> Goldwasser, S., S. Micali, and P. Tong, </author> <title> "Why and How to Establish a Private Code on a Public Network", </title> <booktitle> In 23rd FOCS, </booktitle> <pages> pages 134-144, </pages> <year> 1982. </year>
Reference-contexts: Example 5 Let N be as in Example 4. Suppose that Alice agrees to provide Bob with the least significant bit of the square root (mod N ) of any quadratic residue mod N of Bob's choice. By <ref> [20, 3] </ref> such an answer (by Alice) does yield knowledge to Bob and furthermore jN j answers of this form allow Bob to factor N . Thus, although each answer yields little knowledge (as can be argued analogously to Example 4), many answers yield substantial knowledge.
Reference: [21] <author> Goldwasser, S., and M. Sipser, </author> <title> "Private Coins vs. Public Coins in Interactive Proof Systems", Advances in Computing Research (ed. </title> <editor> S. Micali), </editor> <booktitle> 1989, </booktitle> <volume> Vol. 5, </volume> <pages> pp. 73-90. 33 </pages>
Reference-contexts: A simple enhancement in the construction (see [2, 22]) produces also an interactive proof (P 00 ; V 00 ) for L (the complement of L) which also has a constant number of rounds. (Employing <ref> [21] </ref> and [5] they get that L and L are in AM [2].) We first note that the use of M in these proof systems is limited. <p> Claim 6.1 implies the soundness of the protocol. The number of rounds is a constant, and using [5] and <ref> [21] </ref> we get L 2 AM [2] as desired. 2 Theorem 6.3 Let L be a language that has an interactive proof with knowledge complexity k = O (log (n)) in the Hint sense, then L 2 coAM [2]. Proof: Let us define 2 k (jxj) new simulators.
Reference: [22] <author> H-astad, J., </author> <title> Perfect Zero-Knowledge in AM " coAM. Unpublished (2-page) manuscript ex-plaining the underlying ideas behind [2]. </title> <year> 1994. </year>
Reference-contexts: They use the simulator to build a new interactive proof (P 0 ; V 0 ) for L which is of constant number of rounds. A simple enhancement in the construction (see <ref> [2, 22] </ref>) produces also an interactive proof (P 00 ; V 00 ) for L (the complement of L) which also has a constant number of rounds. (Employing [21] and [5] they get that L and L are in AM [2].) We first note that the use of M in these <p> However, the basic ideas in [10] were extended in [2] to construct an AM [2] protocol for a language L that has a statistical zero-knowledge interactive proof. Furthermore, the additional machinery presented in [2] suffices also for proving Fortnow's result (see <ref> [22] </ref> details of how to use the machinery of [2] to prove Fortnow's result).
Reference: [23] <author> Impagliazzo, R., and M. Yung, </author> <title> "Direct Minimum-Knowledge Computations", </title> <booktitle> Advances in Cryptology - Crypto87 (proceedings), Springer-Verlag, Lectures Notes in Computer Science, </booktitle> <volume> Vol. 293, </volume> <year> 1987, </year> <pages> pp. 40-51. </pages>
Reference-contexts: As per the knowledge-complexity hierarchies of languages, under some reasonable assumptions, the hierarchy of computational knowledge-complexity is quite dull. That is, assuming the existence of secure bit commitment scheme (i.e., the existence of one-way functions), all languages having interactive proofs have interactive proofs of computational knowledge-complexity zero <ref> [8, 23] </ref>. 12 3.2 Analyzing the examples of the introduction Alice's behavior in Examples 1 and 2 is zero-knowledge and thus of knowledge-complexity zero under all our definitions. In general, it is easy to see that zero-knowledge coincides with knowledge-complexity zero under all our definitions.
Reference: [24] <author> E. Kushilevitz and N. Nisan, </author> <title> Communication Complexity, </title> <publisher> Cambridge University Press, </publisher> <year> 1996. </year>
Reference-contexts: Knowledge complexity is intended to capture this increase in computing ability. Thus, knowledge complexity is a fundamental measure of interaction between parties, and it differs from other measures of interaction such as information entropy [27, 9] and communication complexity <ref> [28, 24] </ref>. The following examples may help to illustrate what we mean. In all these examples we assume that Bob is restricted to probabilistic polynomial-time (in the parameter n), whereas no computation restrictions are placed on Alice.
Reference: [25] <author> G. L. Miller, </author> <title> "Riemann's Hypothesis and Tests for Primality", </title> <journal> JCSS, </journal> <volume> Vol. 13, </volume> <year> 1976, </year> <pages> pp. 300-317. </pages>
Reference-contexts: The same holds with respect to the oracle measure (cf., Proposition 4.3). An obvious bound with respect to the hint measure is the length of the smallest element in QN R + N (which under ERH has length O (log jN j) <ref> [25] </ref>), and it is not clear if one can provide a better bound. As per Example 5, Alice sends a single bit which can be easily simulated by one oracle query (or by a good subspace of density 1/2).
Reference: [26] <author> E. Petrank and G. Tardos, </author> <title> "On the Knowledge Complexity of NP", </title> <booktitle> In 37th FOCS, </booktitle> <pages> pages 494-503, </pages> <year> 1996. </year>
Reference-contexts: The first direction, pursued in [7], [15] and <ref> [26] </ref>, focuses on the oracle (or, equivalently fraction) measure of knowledge complexity and is aimed at relating the knowledge complexity of languages to their computational complexity. <p> In particular it was shown how to transform an interactive proof of statistical knowledge complexity k () (w.r.t. the honest verifier) into an interactive proof of perfect knowledge complexity k () + O (log ()) (w.r.t. the honest verifier). Petrank and Tardos <ref> [26] </ref> have extended [2] and [15] and showed that languages with logarithmic knowledge complexity are in AM " coAM. Thus, unless the polynomial time hierarchy collapses, N P-complete languages have super-logarithmic knowledge-complexity. <p> Furthermore, the additional machinery presented in [2] suffices also for proving Fortnow's result (see [22] details of how to use the machinery of [2] to prove Fortnow's result). Alternatively, see <ref> [26] </ref>. 21 Note that though the zero-knowledge property implies the existence of many simulators (one for each possible verifier), [2] use only the simulator for the original interactive proof (P; V ), where V is not cheating. 31 It is clear that if both prover and verifier act according to the
Reference: [27] <author> Shannon, C.E., </author> <title> "A mathematical theory of communication", </title> <journal> Bell Sys. Tech. J., </journal> <volume> Vol. 27, </volume> <year> 1948, </year> <pages> pp. 623-656. </pages>
Reference-contexts: Knowledge complexity is intended to capture this increase in computing ability. Thus, knowledge complexity is a fundamental measure of interaction between parties, and it differs from other measures of interaction such as information entropy <ref> [27, 9] </ref> and communication complexity [28, 24]. The following examples may help to illustrate what we mean. In all these examples we assume that Bob is restricted to probabilistic polynomial-time (in the parameter n), whereas no computation restrictions are placed on Alice.
Reference: [28] <author> A.C. Yao, </author> <title> "Some complexity questions related to distributive computing", </title> <booktitle> In 11th STOC, </booktitle> <pages> pages 209-213, </pages> <year> 1979. </year>
Reference-contexts: Knowledge complexity is intended to capture this increase in computing ability. Thus, knowledge complexity is a fundamental measure of interaction between parties, and it differs from other measures of interaction such as information entropy [27, 9] and communication complexity <ref> [28, 24] </ref>. The following examples may help to illustrate what we mean. In all these examples we assume that Bob is restricted to probabilistic polynomial-time (in the parameter n), whereas no computation restrictions are placed on Alice.
Reference: [29] <author> A.C. Yao, </author> <title> "Theory and Application of Trapdoor Functions", </title> <booktitle> In 23rd FOCS, </booktitle> <pages> pages 80-91, </pages> <year> 1982. </year> <month> 34 </month>
References-found: 29

