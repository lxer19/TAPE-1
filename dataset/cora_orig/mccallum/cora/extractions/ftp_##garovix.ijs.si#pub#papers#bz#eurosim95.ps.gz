URL: ftp://garovix.ijs.si/pub/papers/bz/eurosim95.ps.gz
Refering-URL: http://www-ai.ijs.si/BlazZupan/papers.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: A Simulation and Optimization Environment for Models in Computational Neurobiology  
Author: Blaz Zupan a and John A. Halter b 
Address: Jamova 39, Ljubljana, Slovenia  One Baylor Plaza, Houston, TX 77030, U.S.A.  
Affiliation: a AI Laboratory, J. Stefan Institute,  b Div. Restorative Neurology and Human Neurobiology, Baylor College of Medicine,  
Abstract: Computational neurobiology is an emerging field which employs models to simulate the behavior of real neural systems. We present an environment that can be used to guide simulations using existing neural models. This environment is based on Perl, a powerful and standard script language. It also contains a standard library of routines for common simulation tasks. Included in the environment is an optimization package. Both simulation and optimization routines incorporate a novel approach to simulation data storage and retrieval. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J. A. Halter and J. W. Clark. </author> <title> A distributed-parameter model of the myelinated nerve fiber. </title> <journal> J. Theo. Biol., </journal> <volume> 148 </volume> <pages> 345-382, </pages> <year> 1991. </year>
Reference-contexts: 1. Introduction Contemporary simulation packages for modeling neural systems vary in complexity, flexibility, and performance. Such packages are used to model systems from a single nerve fiber <ref> [1] </ref> to a complex multicellular neural system [2,3]. To utilize these models, one usually has to provide extensive number of model parameters, do a series (several hundred or thousands, cf. [4-6]) of simulations and interpret the results.
Reference: 2. <author> M. A. Wilson, U. S. Bhalla, J. D. Uhley, and J. M. Bower. </author> <title> GENESIS: A system for simulating neural networks. </title> <editor> In D. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <pages> pages 485-492. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference: 3. <author> M. Hines. </author> <title> NEURON a program for simulation of nerve equations. </title> <editor> In F. Eeckman, editor, </editor> <booktitle> Neural Systems: Analysis and Modeling, </booktitle> <pages> pages 127-136. </pages> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year>
Reference: 4. <author> U. S. Bhalla and J. M. Bower. </author> <title> Exploring parameter space in detailed single neuron models: simulations of the mitral and granule cells of the olfactory bulb. </title> <journal> J. Neurophysiology, </journal> <volume> 69(6) </volume> <pages> 1948-1965, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Optimizer determined that such fiber should have diameter of 70.03% of that of the reference model. Optimizer executed 23 simulations and used 56 approximations. Optimization is based on the conjugate gradient method [9]. In contrast with similar packages (cf. <ref> [4] </ref> where the conjugate gradient method is combined with B-splines fitting to derive the local minima), ours utilizes the results of previous simulation runs. These are used for approximation of a criteria function every time the one has to be evaluated with a new set of parameters.
Reference: 5. <author> J. A. Halter, J. S. Carp, and J. W. Woplaw. </author> <title> Operantly conditioned motoneuron plasticity: possible role of sodium channels. </title> <journal> J. Neurophysiology, </journal> <volume> 73(2) </volume> <pages> 867-871, </pages> <year> 1995. </year> <month> 6 </month>
Reference-contexts: Both were observed to be substantial when we re-executed the experiments reported in <ref> [5] </ref> and in current experimentation with the influence of structural changes on nerve fiber behavior. Though the environment was initially used with a specific neurocomputational model, it is general enough to be fitted for other models.
Reference: 6. <author> J. A. Halter and J. W. Clark. </author> <title> The influence of nodal constriction on conduction velocity in myelinated nerve fibers. </title> <journal> Neuro Report, </journal> <volume> 4 </volume> <pages> 89-92, </pages> <year> 1993. </year>
Reference: 7. <author> J. A. Halter, D. Micci Barreca, and B. Zupan. </author> <title> Implementation of myelinated nerve fiber model on a MIMD computer. </title> <booktitle> In Proc. of the IFAC Symposium, </booktitle> <pages> pages 511-512, </pages> <address> Galveston, TX, </address> <year> 1994. </year>
Reference: 8. <author> L. Wall and R. L. Schwartz. </author> <title> Programming Perl. </title> <publisher> O'Reilly & Associates, Inc., </publisher> <address> Se-bastopol, CA, </address> <year> 1992. </year>
Reference-contexts: These are usually driven by the results of the previous simulation runs, each of which can take several minutes or more of CPU time. 2.1. Simulation The simulation environment is based on the standard script language Perl <ref> [8] </ref>. The user provides a script which drives a simulation such as a loop that reads the parameter specification file, modifies some of the parameters, executes the simulation, and extracts the results (cf. Fig.2).
Reference: 9. <author> W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery. </author> <title> Numerical Recipes in C: </title> <booktitle> The Art of Scientific Computing. </booktitle> <publisher> Cambridge University Press, </publisher> <address> 2nd edition, </address> <year> 1994. </year>
Reference-contexts: Optimizer determined that such fiber should have diameter of 70.03% of that of the reference model. Optimizer executed 23 simulations and used 56 approximations. Optimization is based on the conjugate gradient method <ref> [9] </ref>. In contrast with similar packages (cf. [4] where the conjugate gradient method is combined with B-splines fitting to derive the local minima), ours utilizes the results of previous simulation runs.
Reference: 10. <author> W. S. Cleveland and E. Grosse. </author> <title> Computational methods for local regression. </title> <journal> Statistics and Computing, </journal> <volume> 1 </volume> <pages> 47-62, </pages> <year> 1991. </year>
Reference-contexts: From other methods, our experiments showed a substantial reduction of overall optimization time when using a combination of nearest neighbors method with local regression. First method is used to select the data points, while the second builds a local regression using the techniques described in <ref> [10] </ref>. Starting with empty set of known experimental results and adding to this set a result of each simulation performed, we have observed that such techniques might save up to 50% of optimization time compared to the optimization that does not use past experimentation results. 3.
References-found: 10

