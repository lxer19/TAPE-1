URL: http://www.cs.ucsb.edu/TRs/techreports/TRCS96-14.ps
Refering-URL: http://www.cs.ucsb.edu/TRs/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Optimizing Parallel Bitonic Sort  
Author: by MIHAI FLORIN IONESCU Professor Martin C. Rinard Professor Ambuj K. Singh 
Degree: A thesis submitted in partial satisfaction of the requirements for the degree of Master of Science in Computer Science in the GRADUATE DIVISION of the  Committee in charge: Professor Klaus E. Schauser, Chair  
Date: August 1996  
Address: SANTA BARBARA  
Affiliation: UNIVERSITY of CALIFORNIA at  
Abstract-found: 0
Intro-found: 0
Reference: [ABK95] <author> M. Adler, J. W. Byers, and R. M. Karp. </author> <title> Parallel sorting with limited bandwidth. </title> <booktitle> In Proceedings the Symposium on Parallel Algorithms and Architectures, </booktitle> <month> July </month> <year> 1995. </year>
Reference-contexts: The problem is especially interesting because it fundamentally requires communication as well as computation, being an excellent area to investigate the effect of communication and computation on algorithm performance <ref> [ABK95] </ref>. One of the earliest parallel sorting algorithms is Bitonic Sort [Bat68], which is represented by a sorting network connected by multiple butterfly stages of increasing size. Since then, a wide range of sorting networks have been proposed, and their complexity and performance have been studied in great detail.
Reference: [ACS90] <author> A. Aggarwal, A. K. Chandra, and M. Snir. </author> <title> Communication Complexity of PRAMs. </title> <booktitle> In Theoretical Computer Science, </booktitle> <month> March </month> <year> 1990. </year>
Reference-contexts: Later research has shown, however, that processor-to-processor communication is the most important bottleneck in parallel computing (see <ref> [ACS90, CKP + 93, KRS90, PY88, Val90a, Val90b] </ref>). Therefore efficient parallel algorithms are more likely to be achieved on coarse-grain parallel systems and in most situations the original algorithm is substantially redesigned (see [AISS95]). As a parallel application, sorting is especially challenging because of the amount of communication it requires.
Reference: [AISS95] <author> A. Alexandrov, M. Ionescu, K. E. Schauser, and C. Scheiman. LogGP: </author> <title> Incorporating Long Messages into the LogP model | One step closer towards a realistic model for parallel computation. </title> <booktitle> In 7th Annual Symposium on Parallel Algorithms and Architectures, </booktitle> <month> July </month> <year> 1995. </year>
Reference-contexts: Therefore efficient parallel algorithms are more likely to be achieved on coarse-grain parallel systems and in most situations the original algorithm is substantially redesigned (see <ref> [AISS95] </ref>). As a parallel application, sorting is especially challenging because of the amount of communication it requires. Essentially, almost all data items may move from the processor they reside originally on to some other processor. <p> We also investigate the factors that influence communication in a remap-based parallel bitonic sort algorithm by analyzing the algorithm under the framework of realistic models for parallel computation such as LogP [CKP + 93] or LogGP <ref> [AISS95] </ref>. <p> Each remap operation involves an all-to-all communication of n words per processor, as opposed to a fixed data layout where each remote step involves exchanging n words between pairs of processors. The former can be implemented under the LogP [CKP + 93] or LogGP <ref> [AISS95] </ref> models nearly as efficiently as one-to-one communication. Periodic cyclic-blocked remapping has some limitations, however: it is dependent on the data size. <p> Modern parallel machines, however, have support for long message transfers, i.e., pack more elements that go on a processor in a single message and perform just one communication step (a long message transfer). Thus we can take advantage of the full bandwidth of the network (see <ref> [AISS95, SS95] </ref>) by grouping elements into long messages. In the following we will present a general method for remapping the data between two different data layouts using long messages based on the bit pattern of the absolute address for the respective data layouts. <p> computation which captures the existing overheads of modern hardware reveals that the important factors that influence the communication time are: * total number of remaps * total volume of elements transfered * total number of messages transfered For our study we have chosen the LogP [CKP + 93] and LogGP <ref> [AISS95] </ref> models of parallel computation. 3.4.1 The LogP and LogGP models The LogP model reflects the convergence of parallel machines towards systems formed by a collection of complete computers, each consisting of a microprocessor, cache and large DRAM memory, connected by a communication network [CKP + 93]. <p> Many existing parallel machines have special support for long messages which provide a much higher bandwidth than short messages (e.g., IBM SP-2 [BBB + 94], Paragon [Pie94], Meiko CS-2 [BCM94], Ncube/2 [SV94]) and this fact is captured by the LogGP model which is a refinement of the LogP model <ref> [AISS95] </ref>. LogGP extends the LogP model by introducing a new parameter to model long messages: * G: the Gap per byte for long messages, defined as the time per byte for a long message. <p> The algorithms for sample and radix sort used in [BLM + 91, CDMS94] were using short messages and were slower than our long message implementation of bitonic sort. The sample and radix sort versions that we have used were implemented using long messages <ref> [AISS95] </ref> and they were by our knowledge the fastest Split-C implementations of sample and radix sort. on 16 processors and Figure 5.8 on 32 processors. As we can see for 16 processors our implementation of bitonic sort performs better than radix sort. <p> The study also showed that by a careful analysis of the algorithm under a realistic parallel computation model we can eliminate design deficiencies and come up with efficient implementations . A more recent study <ref> [AISS95] </ref> showed that a large class of parallel algorithms (and in particular sorting algorithms) can be substantially improved when re-designed under a new model of parallel computation (LogGP) which captures the fact that modern parallel machines have support for long message transfers, therefore achieving a much higher bandwidth than short messages.
Reference: [AKE83] <author> M. Ajtai, Komlos K., and Szemeredi E. </author> <title> Sorting in c log n parallel steps. </title> <booktitle> In Combinatorica, </booktitle> <month> March </month> <year> 1983. </year>
Reference-contexts: Since then a lot of effort has been directed at fine-grain parallel sorting algorithms (e.g. see [BDHM84, Ja92, KR90, Rei93]). In 1983 it was shown <ref> [AKE83] </ref> that n elements can be sorted in O (lg n) time with an O (n lg n)-sized network.
Reference: [Bat68] <author> K. Batcher. </author> <title> Sorting Networks and their Applications. </title> <booktitle> In Proceedings of the AFIPS Spring Joint Computing Conference, </booktitle> <volume> volume 32, </volume> <year> 1968. </year>
Reference-contexts: The problem is especially interesting because it fundamentally requires communication as well as computation, being an excellent area to investigate the effect of communication and computation on algorithm performance [ABK95]. One of the earliest parallel sorting algorithms is Bitonic Sort <ref> [Bat68] </ref>, which is represented by a sorting network connected by multiple butterfly stages of increasing size. Since then, a wide range of sorting networks have been proposed, and their complexity and performance have been studied in great detail. <p> Chapter 5 presents experimental results collected on a 64 processor Meiko CS-2. Chapter 6 discusses related work, and Chapter 7 concludes and presents future work. 6 Chapter 2 Bitonic Sort In this section we describe the bitonic sort algorithm originally developed by Batcher three decades ago <ref> [Bat68] </ref>. <p> These comparisons suggests that for a small number of processors and for small data sets bitonic sort might be the fastest choice. 84 processors. processors. 85 Chapter 6 Related Work Bitonic sort and sorting networks have received special attention since Batcher <ref> [Bat68] </ref> in 1968 showed that fine-grained parallel sorting networks can sort in O (lg 2 n) time using O (n) processors. Since then a lot of effort has been directed at fine-grain parallel sorting algorithms (e.g. see [BDHM84, Ja92, KR90, Rei93]).
Reference: [BBB + 94] <author> V. Bala, J. Bruck, R. Bryant, R. Cypher, P. de Jong, P. Elustondo, D. Frye, A. Ho, C-T. Ho, G. Irwin, S. Kipnis, R. Lawrence, and M. Snir. </author> <title> The IBM external user interface for scalable parallel systems. </title> <journal> Parallel Computing, </journal> <volume> 20(4), </volume> <month> April </month> <year> 1994. </year>
Reference-contexts: Many existing parallel machines have special support for long messages which provide a much higher bandwidth than short messages (e.g., IBM SP-2 <ref> [BBB + 94] </ref>, Paragon [Pie94], Meiko CS-2 [BCM94], Ncube/2 [SV94]) and this fact is captured by the LogGP model which is a refinement of the LogP model [AISS95].
Reference: [BCM94] <author> E. Bartson, J. Cownie, and M. McLaren. </author> <title> Message passing on the Meiko CS-2. </title> <journal> Parallel Computing, </journal> <volume> 20(4), </volume> <month> April </month> <year> 1994. </year>
Reference-contexts: Many existing parallel machines have special support for long messages which provide a much higher bandwidth than short messages (e.g., IBM SP-2 [BBB + 94], Paragon [Pie94], Meiko CS-2 <ref> [BCM94] </ref>, Ncube/2 [SV94]) and this fact is captured by the LogGP model which is a refinement of the LogP model [AISS95].
Reference: [BDHM84] <author> D. Bitton, D. J. DeWitt, D. K. Hsiao, and J. Menon. </author> <title> A Taxonomy of Parallel Sorting. </title> <type> Technical Report TR84-601, </type> <institution> Cornell University, Computer Science Department, </institution> <month> April </month> <year> 1984. </year>
Reference-contexts: Parallel sorting is only one example of a parallel application for which the transition from a theoretical model to an efficient implementation is not straightforward. Most of the research on parallel algorithm design in the '70s and '80s has focused on fine-grain models of parallel computation (see <ref> [BDHM84, Ja92, KR90, Lei92, Rei93, Qui94, KGGK94] </ref>) where the ratio of memory to processors is relatively small. Later research has shown, however, that processor-to-processor communication is the most important bottleneck in parallel computing (see [ACS90, CKP + 93, KRS90, PY88, Val90a, Val90b]). <p> Since then a lot of effort has been directed at fine-grain parallel sorting algorithms (e.g. see <ref> [BDHM84, Ja92, KR90, Rei93] </ref>). In 1983 it was shown [AKE83] that n elements can be sorted in O (lg n) time with an O (n lg n)-sized network.
Reference: [BLM + 91] <author> G. E. Blelloch, C. E. Leiserson, B. M. Maggs, C. G. Plaxton, S. J. Smith, and M. Zagha. </author> <title> A Comparison of Sorting Algorithms for the Connection Machine CM-2. </title> <booktitle> In Proceedings of the Symposium on Parallel Architectures and Algorithms, </booktitle> <year> 1991. </year> <month> 91 </month>
Reference-contexts: Recent implementations and evaluations of parallel algorithms show that although bitonic sort is slow for large data sets (compared for example with radix sort or sample sort) it is more space-efficient and represents one of the fastest alternatives for small data sets (see <ref> [CDMS94, BLM + 91] </ref>). Earlier parallel sorting algorithms have being studied in the context of PRAM or network-based models. In both approaches, algorithms were developed under the assumption that the number of processors (P ) is comparable to the number of data elements (N ). <p> The first one is the Split-C implementation of bitonic sort used in one of the first studies of efficient parallel sorting algorithms <ref> [BLM + 91] </ref>. <p> Unpacking 128 0.35 0.15 0.15 512 0.38 0.16 0.14 Table 5.4: Breakdown of the execution time per key (in s) for the communication phase for the long messages version on 16 processors. 82 version on 16 processors. 83 5.5 Comparison with other Parallel Sorts We have previously mentioned two studies <ref> [BLM + 91, CDMS94] </ref> that compared the efficiency of several general-purpose parallel sorting algorithms on modern parallel machines (e.g. CM-2, CM-5). In both studies three parallel algorithms were analyzed and compared: bitonic sort, radix sort and sample sort. <p> Bitonic sort performed well only for small data sets and for a small number of processors. We have compared our implementation of bitonic sort with two highly optimized versions of sample and radix sort. The algorithms for sample and radix sort used in <ref> [BLM + 91, CDMS94] </ref> were using short messages and were slower than our long message implementation of bitonic sort. <p> Now the goal becomes to design a general-purpose parallel sort algorithm that is the fastest in practice. One of the first important studies of the performance of parallel sorting algorithms was conducted by Blelloch, Leiserson et al. <ref> [BLM + 91] </ref> which compared bitonic, radix and sample sort on CM-2. Several issues were emphasized like space, stability, portability 86 and simplicity. These comparisons were augmented by a new study by Culler et al. ([CDMS94, Dus94]).
Reference: [BN86] <author> G. Bilardi and A. Nicolau. </author> <title> Adaptive Bitonic Sorting: An Optimal Parallel Algorithm for Shared Memory Machines. </title> <type> Technical Report TR86-769, </type> <institution> Cornell University, Computer Science Department, </institution> <month> August </month> <year> 1986. </year>
Reference-contexts: Not surprisingly, bitonic sort has been studied extensively on parallel network topologies such as the hypercube and shu*e-exchange which provide an easy embedding of butterflies [Sto71]. Various properties of bitonic networks have been investigated, e.g. 2 <ref> [Knu73, HS82, BN86] </ref>. Recent implementations and evaluations of parallel algorithms show that although bitonic sort is slow for large data sets (compared for example with radix sort or sample sort) it is more space-efficient and represents one of the fastest alternatives for small data sets (see [CDMS94, BLM + 91]).
Reference: [CDG + 93] <author> D. E. Culler, A. Dusseau, S. C. Golstein, A. Krishnamurthy, S. Lumetta, T. von Eicken, and K. Yelick. </author> <title> Parallel Programming in Split-C. </title> <booktitle> In Proc. of Supercomputing, </booktitle> <month> November </month> <year> 1993. </year>
Reference-contexts: Compared with previous approaches our algorithm executes less communication steps and transfers less data. Furthermore, by taking advantage of the special format of the data input, we show how to optimize the local computation on each node. We develop an efficient implementation of our algorithm in Split-C <ref> [CDG + 93] </ref>, a simple parallel extension of the language C. Split-C provides a machine independent 4 SPMD programming model and is supported on a large variety of parallel architectures. Experimental results, collected on a 64 node Meiko CS-2, show that optimizing the communication obtains the most dramatic improvement. <p> For our implementation we used an optimized version of the Split-C parallel language implemented on Meiko CS-2 on top of Active Messages [vECGS92, SS95]. 75 5.2 The Split-C Programming Language We have implemented our algorithm in Split-C <ref> [CDG + 93] </ref>, a parallel extension of the C programming language designed for large, distributed-memory multiprocessors. The goal of the Split-C language was to combine the most valuable aspects of shared memory with the most valuable aspects of message passing and data parallel programming within a coherent framework. <p> Column sort was included and a more general class of machines was addressed by formalizing the algorithms under the LogP model. All algorithms were implemented in Split-C (a parallel language which provides a straightforward machine independent programming system) <ref> [CDG + 93] </ref> making them available to be ported and analyzed across a wide variety of parallel architectures. The conclusion of this study was that an "optimized" data layout across processors was a crucial factor in achieving fast algorithms.
Reference: [CDMS94] <author> D. E. Culler, A. Dusseau, R. Martin, and K. E. Schauser. </author> <title> Fast Parallel Sorting under LogP: from Theory to Practice. </title> <editor> In T. Hey and J. Ferrante, editors, </editor> <title> Portability and Performance for Parallel Processing. </title> <publisher> Wiley, </publisher> <year> 1994. </year>
Reference-contexts: Recent implementations and evaluations of parallel algorithms show that although bitonic sort is slow for large data sets (compared for example with radix sort or sample sort) it is more space-efficient and represents one of the fastest alternatives for small data sets (see <ref> [CDMS94, BLM + 91] </ref>). Earlier parallel sorting algorithms have being studied in the context of PRAM or network-based models. In both approaches, algorithms were developed under the assumption that the number of processors (P ) is comparable to the number of data elements (N ). <p> A shaded node designates an address where the minimum of the two keys is placed, the unshaded node designates an address where the maximum of the two keys is placed. The arrows indicate the monotonic ordered sequences, with the arrowhead pointing towards the largest key (From <ref> [CDMS94] </ref>). 13 2.2 Naive Parallel Implementation As presented above the bitonic sorting network consists of a series of butterfly networks of increasing size, where each butterfly node represents a comparison operation. <p> Since under a cyclic layout the first k steps of the stage lg n + k are completely local, we can reduce the communication requirements by periodically remapping the data from a blocked layout to a cyclic layout and vice versa. This approach was first suggested in <ref> [CKP + 93, CDMS94] </ref> and used for efficient implementations of parallel algorithms based on the butterfly network such as FFT [CKP + 93] or bitonic sort [CDMS94]. Thick arcs highlight where communication occurs, normal arcs indicate local accesses. Under this remapping strategy the algorithm starts with a blocked layout. <p> This approach was first suggested in [CKP + 93, CDMS94] and used for efficient implementations of parallel algorithms based on the butterfly network such as FFT [CKP + 93] or bitonic sort <ref> [CDMS94] </ref>. Thick arcs highlight where communication occurs, normal arcs indicate local accesses. Under this remapping strategy the algorithm starts with a blocked layout. There 17 fore, the first lg n stages are entirely local. <p> We will show in more detail why this is the case in the next chapter. The remapping strategy presented above was to our knowledge the most efficient technique used so far for the parallel bitonic sort (for implementation details and experimental results see <ref> [CDMS94] </ref>). The following chapters will show how an improved communication-efficient data layout and remapping strategy can be derived and how local computation can be optimized. 18 Chapter 3 Optimizing Communication In this chapter we discuss how to minimize the communication requirements. <p> The reciprocal of g corresponds to the available per processor communication bandwidth for short messages. * P: the number of processor/memory modules. As evidenced by experimental data collected on the CM-5 [TM94], this model can accurately predict communication performance when only fixed-sized short messages are sent <ref> [CKP + 93, CDMS94, LC94] </ref>. <p> Stage k consists of N=2 k alternating bitonic merges of size 2 k (BM 2 k or BM The output of a bitonic merge is a sorted sequence and the result follows. 2 sorted sequences. 61 The previous observation leads to straightforward optimizations (applied in <ref> [CDMS94] </ref>): the purpose of the first lg n stages is to form a monotonically increasing or decreasing sequence of n keys on each processor, thus we can replace all these stages with a single, highly optimized local sort. <p> After s steps, applying a bitonic split at each step, we obtain 2 lg Ns bitonic sequences of length 2 s . 2 The result of this lemma was applied in <ref> [CDMS94] </ref> for optimizing the local sort (under the blocked layout) for the last lg P stages. <p> The second implementation is the Cyclic-Blocked version presented in Section 2.3. The computation performed under the cyclic layout consists of bitonic merges, and 76 under the blocked layout of local radix sorts. This implementation was used to study parallel bitonic sort in another major study of parallel sorting algorithms <ref> [CDMS94] </ref> and was by our knowledge the fastest implementation of parallel bitonic sort. We will call this algorithm the Cyclic-Blocked bitonic sort. Our implementation uses the smart remapping strategy presented in Section 3.2. The local computation is also optimized as presented in Chapter 4. <p> Unpacking 128 0.35 0.15 0.15 512 0.38 0.16 0.14 Table 5.4: Breakdown of the execution time per key (in s) for the communication phase for the long messages version on 16 processors. 82 version on 16 processors. 83 5.5 Comparison with other Parallel Sorts We have previously mentioned two studies <ref> [BLM + 91, CDMS94] </ref> that compared the efficiency of several general-purpose parallel sorting algorithms on modern parallel machines (e.g. CM-2, CM-5). In both studies three parallel algorithms were analyzed and compared: bitonic sort, radix sort and sample sort. <p> Bitonic sort performed well only for small data sets and for a small number of processors. We have compared our implementation of bitonic sort with two highly optimized versions of sample and radix sort. The algorithms for sample and radix sort used in <ref> [BLM + 91, CDMS94] </ref> were using short messages and were slower than our long message implementation of bitonic sort.
Reference: [CKP + 93] <author> D. E. Culler, R. M. Karp, D. A. Patterson, A. Sahay, K. E. Schauser, E. Santos, R. Subramonian, and T. von Eicken. </author> <title> LogP: Towards a Realistic Model of Parallel Computation. </title> <booktitle> In Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: Later research has shown, however, that processor-to-processor communication is the most important bottleneck in parallel computing (see <ref> [ACS90, CKP + 93, KRS90, PY88, Val90a, Val90b] </ref>). Therefore efficient parallel algorithms are more likely to be achieved on coarse-grain parallel systems and in most situations the original algorithm is substantially redesigned (see [AISS95]). As a parallel application, sorting is especially challenging because of the amount of communication it requires. <p> We also investigate the factors that influence communication in a remap-based parallel bitonic sort algorithm by analyzing the algorithm under the framework of realistic models for parallel computation such as LogP <ref> [CKP + 93] </ref> or LogGP [AISS95]. <p> Since under a cyclic layout the first k steps of the stage lg n + k are completely local, we can reduce the communication requirements by periodically remapping the data from a blocked layout to a cyclic layout and vice versa. This approach was first suggested in <ref> [CKP + 93, CDMS94] </ref> and used for efficient implementations of parallel algorithms based on the butterfly network such as FFT [CKP + 93] or bitonic sort [CDMS94]. Thick arcs highlight where communication occurs, normal arcs indicate local accesses. Under this remapping strategy the algorithm starts with a blocked layout. <p> This approach was first suggested in [CKP + 93, CDMS94] and used for efficient implementations of parallel algorithms based on the butterfly network such as FFT <ref> [CKP + 93] </ref> or bitonic sort [CDMS94]. Thick arcs highlight where communication occurs, normal arcs indicate local accesses. Under this remapping strategy the algorithm starts with a blocked layout. There 17 fore, the first lg n stages are entirely local. <p> Each remap operation involves an all-to-all communication of n words per processor, as opposed to a fixed data layout where each remote step involves exchanging n words between pairs of processors. The former can be implemented under the LogP <ref> [CKP + 93] </ref> or LogGP [AISS95] models nearly as efficiently as one-to-one communication. Periodic cyclic-blocked remapping has some limitations, however: it is dependent on the data size. <p> a "realistic" model of parallel computation which captures the existing overheads of modern hardware reveals that the important factors that influence the communication time are: * total number of remaps * total volume of elements transfered * total number of messages transfered For our study we have chosen the LogP <ref> [CKP + 93] </ref> and LogGP [AISS95] models of parallel computation. 3.4.1 The LogP and LogGP models The LogP model reflects the convergence of parallel machines towards systems formed by a collection of complete computers, each consisting of a microprocessor, cache and large DRAM memory, connected by a communication network [CKP + <p> LogP <ref> [CKP + 93] </ref> and LogGP [AISS95] models of parallel computation. 3.4.1 The LogP and LogGP models The LogP model reflects the convergence of parallel machines towards systems formed by a collection of complete computers, each consisting of a microprocessor, cache and large DRAM memory, connected by a communication network [CKP + 93]. <p> The reciprocal of g corresponds to the available per processor communication bandwidth for short messages. * P: the number of processor/memory modules. As evidenced by experimental data collected on the CM-5 [TM94], this model can accurately predict communication performance when only fixed-sized short messages are sent <ref> [CKP + 93, CDMS94, LC94] </ref>.
Reference: [Col88] <author> R. Cole. </author> <title> Parallel merge sort. </title> <journal> SIAM J. Comput, </journal> <volume> 17(4), </volume> <year> 1988. </year>
Reference-contexts: In 1985 Leighton [Lei85] extended this result to show that one can produce an O (n)-node bounded-degree network capable of sorting in O (lg n) steps, based upon an algorithm called column sort. In 1988 Cole <ref> [Col88] </ref> gave simple methods for optimal sorting in the CREW and EREW PRAM models in O (lg n) time using O (n) processors based on a cascade mergesort using arrays. Therefore in a fine-grain parallel model like the one mentioned above, one can sort optimally.
Reference: [Dus94] <author> A. Dusseau. </author> <title> Modeling Parallel Sorts with LogP on the CM-5. </title> <type> Technical Report UCB/CSD 94/829, </type> <institution> UC Berkeley, </institution> <month> May </month> <year> 1994. </year>
Reference: [HM93] <author> M. Homewood and M. McLaren. </author> <title> Meiko CS-2 Interconnect Elan-Elite Design. </title> <booktitle> In Proc. of Hot Interconnects, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: bitonic sort algorithm, we analyze the impact of long messages on the algorithm efficiency and finally we compare our algorithm against other parallel sorts. 5.1 The Meiko CS-2 Parallel Computer Our experimental platform is the Meiko CS-2 which consists of Sparc based nodes connected via a fat tree communication network <ref> [HM93] </ref>. Running a slightly enhanced version of the Solaris 2.3 operating system on every node, it closely resembles a cluster of workstations connected by a fast network. Our machine is a 64 node CS-2.
Reference: [HS82] <author> Z. Hong and R. Sedgewick. </author> <title> Notes on merging networks. </title> <booktitle> In Proceedings of the 14th Annual Symposium on Theory of Computing, </booktitle> <month> May </month> <year> 1982. </year>
Reference-contexts: Not surprisingly, bitonic sort has been studied extensively on parallel network topologies such as the hypercube and shu*e-exchange which provide an easy embedding of butterflies [Sto71]. Various properties of bitonic networks have been investigated, e.g. 2 <ref> [Knu73, HS82, BN86] </ref>. Recent implementations and evaluations of parallel algorithms show that although bitonic sort is slow for large data sets (compared for example with radix sort or sample sort) it is more space-efficient and represents one of the fastest alternatives for small data sets (see [CDMS94, BLM + 91]).
Reference: [Ja92] <author> J. JaJa. </author> <title> An Introduction to Parallel Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1992. </year>
Reference-contexts: Parallel sorting is only one example of a parallel application for which the transition from a theoretical model to an efficient implementation is not straightforward. Most of the research on parallel algorithm design in the '70s and '80s has focused on fine-grain models of parallel computation (see <ref> [BDHM84, Ja92, KR90, Lei92, Rei93, Qui94, KGGK94] </ref>) where the ratio of memory to processors is relatively small. Later research has shown, however, that processor-to-processor communication is the most important bottleneck in parallel computing (see [ACS90, CKP + 93, KRS90, PY88, Val90a, Val90b]). <p> Since then a lot of effort has been directed at fine-grain parallel sorting algorithms (e.g. see <ref> [BDHM84, Ja92, KR90, Rei93] </ref>). In 1983 it was shown [AKE83] that n elements can be sorted in O (lg n) time with an O (n lg n)-sized network.
Reference: [KGGK94] <author> V. Kumar, A. Grama, A. Gupta, and G. Karypis. </author> <title> Introduction to Parallel Computing. </title> <publisher> Benjamin Cummings, </publisher> <year> 1994. </year>
Reference-contexts: Parallel sorting is only one example of a parallel application for which the transition from a theoretical model to an efficient implementation is not straightforward. Most of the research on parallel algorithm design in the '70s and '80s has focused on fine-grain models of parallel computation (see <ref> [BDHM84, Ja92, KR90, Lei92, Rei93, Qui94, KGGK94] </ref>) where the ratio of memory to processors is relatively small. Later research has shown, however, that processor-to-processor communication is the most important bottleneck in parallel computing (see [ACS90, CKP + 93, KRS90, PY88, Val90a, Val90b]). <p> The following basic definitions were adapted from <ref> [KGGK94] </ref>. 2.1.1 Bitonic Sequence Definition 1 (Bitonic Sequence) A bitonic sequence is a sequence of values a 0 ; : : : ; a n1 , with the property that (1) there exists an index i, where 0 i n 1, such that a 0 through a i is monotonically increasing <p> A bitonic split operation has two fundamental properties (for details see <ref> [KGGK94] </ref>): 1. s 1 and s 2 are bitonic sequences. 2. the elements of s 1 are all smaller than the elements of s 2 . <p> Using this primitive we can implement a bitonic split and a bitonic merge, and show that the algorithm actually sorts the input (for details we refer the interested reader to <ref> [KGGK94] </ref>). Since for the rest of the thesis we make extensive use of the network view of bitonic sort, we focus especially on it and describe its components in more detail. <p> Figure 2.3 shows the block structure of the bitonic sorting network. With BM k we have denoted the increasing bitonic merging networks of size k, and with BM k the decreasing merging networks. 11 k k we denote increasing, respectively decreasing, bitonic merging networks of size k (From <ref> [KGGK94] </ref>). For the rest of the thesis we consider N to be the data size, P the number of processors and n = N=P the number of elements which go on one processor.
Reference: [Knu73] <author> D. E. Knuth. </author> <booktitle> The Art of Computer Programming, </booktitle> <volume> volume 3. </volume> <publisher> Addison Wesley, </publisher> <address> Reading Massachusetts, </address> <year> 1973. </year>
Reference-contexts: key (in s) for the communication phase for the long messages version on 16 processors. : : : : : : : : : 81 1 Chapter 1 The Parallel Sorting Challenge 1.1 Overview Sorting is a popular Computer Science topic which received more attention than most any other problem. <ref> [Knu73] </ref>, for instance, found that computers devote approximately a quarter of their time to sorting. In the last decades parallel processing has added a new dimension to the sorting problem and stimulated the research on sorting algorithms. <p> Not surprisingly, bitonic sort has been studied extensively on parallel network topologies such as the hypercube and shu*e-exchange which provide an easy embedding of butterflies [Sto71]. Various properties of bitonic networks have been investigated, e.g. 2 <ref> [Knu73, HS82, BN86] </ref>. Recent implementations and evaluations of parallel algorithms show that although bitonic sort is slow for large data sets (compared for example with radix sort or sample sort) it is more space-efficient and represents one of the fastest alternatives for small data sets (see [CDMS94, BLM + 91]).
Reference: [KR90] <author> R. M. Karp and V. Ramachandran. </author> <title> Parallel Algorithms for Shared-Memory Machines. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science. </booktitle> <publisher> Elsevier Science Publishers, </publisher> <year> 1990. </year>
Reference-contexts: Parallel sorting is only one example of a parallel application for which the transition from a theoretical model to an efficient implementation is not straightforward. Most of the research on parallel algorithm design in the '70s and '80s has focused on fine-grain models of parallel computation (see <ref> [BDHM84, Ja92, KR90, Lei92, Rei93, Qui94, KGGK94] </ref>) where the ratio of memory to processors is relatively small. Later research has shown, however, that processor-to-processor communication is the most important bottleneck in parallel computing (see [ACS90, CKP + 93, KRS90, PY88, Val90a, Val90b]). <p> Since then a lot of effort has been directed at fine-grain parallel sorting algorithms (e.g. see <ref> [BDHM84, Ja92, KR90, Rei93] </ref>). In 1983 it was shown [AKE83] that n elements can be sorted in O (lg n) time with an O (n lg n)-sized network.
Reference: [KRS90] <author> C. Kruskal, L. Rudolph, and M. Snir. </author> <title> A complexity theory of efficient parallel algorithms. </title> <booktitle> In Theoretical Computer Science, </booktitle> <year> 1990. </year> <month> 92 </month>
Reference-contexts: Later research has shown, however, that processor-to-processor communication is the most important bottleneck in parallel computing (see <ref> [ACS90, CKP + 93, KRS90, PY88, Val90a, Val90b] </ref>). Therefore efficient parallel algorithms are more likely to be achieved on coarse-grain parallel systems and in most situations the original algorithm is substantially redesigned (see [AISS95]). As a parallel application, sorting is especially challenging because of the amount of communication it requires.
Reference: [LC94] <author> L. T. Liu and D. E. Culler. </author> <title> Measurements of Active Messages Performance on the CM-5. </title> <type> Technical Report UCB/CSD 94-807, </type> <institution> CS Div., UC Berkeley, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: The reciprocal of g corresponds to the available per processor communication bandwidth for short messages. * P: the number of processor/memory modules. As evidenced by experimental data collected on the CM-5 [TM94], this model can accurately predict communication performance when only fixed-sized short messages are sent <ref> [CKP + 93, CDMS94, LC94] </ref>.
Reference: [Lei85] <author> F. T. Leighton. </author> <title> Tight bounds on complexity of parallel sorting. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 34(4), </volume> <year> 1985. </year>
Reference-contexts: Since then a lot of effort has been directed at fine-grain parallel sorting algorithms (e.g. see [BDHM84, Ja92, KR90, Rei93]). In 1983 it was shown [AKE83] that n elements can be sorted in O (lg n) time with an O (n lg n)-sized network. In 1985 Leighton <ref> [Lei85] </ref> extended this result to show that one can produce an O (n)-node bounded-degree network capable of sorting in O (lg n) steps, based upon an algorithm called column sort. <p> One technique used (which is also described in this thesis) was packing the data into long messages at the sending site and unpacking it at the receiving site. It is also worth to mention the relationship of bitonic sort to column sort. Like bitonic sort, column sort <ref> [Lei85] </ref> alternates between local sort and key distribution phases, but only four phases of each are required. Two of the communication phases are similar to cyclic-to-blocked and blocked-to-cyclic remaps discussed in Chapter 2, the others are just a one-to-one communication.
Reference: [Lei92] <author> F. T. Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays, Trees, Hypercubes. </title> <publisher> Morgan Kaufman, </publisher> <year> 1992. </year>
Reference-contexts: Parallel sorting is only one example of a parallel application for which the transition from a theoretical model to an efficient implementation is not straightforward. Most of the research on parallel algorithm design in the '70s and '80s has focused on fine-grain models of parallel computation (see <ref> [BDHM84, Ja92, KR90, Lei92, Rei93, Qui94, KGGK94] </ref>) where the ratio of memory to processors is relatively small. Later research has shown, however, that processor-to-processor communication is the most important bottleneck in parallel computing (see [ACS90, CKP + 93, KRS90, PY88, Val90a, Val90b]).
Reference: [Pie94] <author> P. Pierce. </author> <title> The NX message passing interface. </title> <journal> Parallel Computing, </journal> <volume> 20(4), </volume> <month> April </month> <year> 1994. </year>
Reference-contexts: Many existing parallel machines have special support for long messages which provide a much higher bandwidth than short messages (e.g., IBM SP-2 [BBB + 94], Paragon <ref> [Pie94] </ref>, Meiko CS-2 [BCM94], Ncube/2 [SV94]) and this fact is captured by the LogGP model which is a refinement of the LogP model [AISS95].
Reference: [PY88] <author> C. H. Papadimitriou and M. Yannakakis. </author> <title> Towards an Architecture-Independent Analysis of Parallel Algorithms. </title> <booktitle> In Proceedings of the Twentieth Annual ACM Symposium of the Theory of Computing. ACM, </booktitle> <month> May </month> <year> 1988. </year>
Reference-contexts: Later research has shown, however, that processor-to-processor communication is the most important bottleneck in parallel computing (see <ref> [ACS90, CKP + 93, KRS90, PY88, Val90a, Val90b] </ref>). Therefore efficient parallel algorithms are more likely to be achieved on coarse-grain parallel systems and in most situations the original algorithm is substantially redesigned (see [AISS95]). As a parallel application, sorting is especially challenging because of the amount of communication it requires.
Reference: [Qui94] <author> M. J. Quinn. </author> <title> Parallel Computing. Theory and Practice. </title> <address> Mc-Graw Hill, </address> <year> 1994. </year>
Reference-contexts: Parallel sorting is only one example of a parallel application for which the transition from a theoretical model to an efficient implementation is not straightforward. Most of the research on parallel algorithm design in the '70s and '80s has focused on fine-grain models of parallel computation (see <ref> [BDHM84, Ja92, KR90, Lei92, Rei93, Qui94, KGGK94] </ref>) where the ratio of memory to processors is relatively small. Later research has shown, however, that processor-to-processor communication is the most important bottleneck in parallel computing (see [ACS90, CKP + 93, KRS90, PY88, Val90a, Val90b]).
Reference: [Rei93] <author> J. H. Reif. </author> <title> Synthesis of Parallel Algorithms. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: Parallel sorting is only one example of a parallel application for which the transition from a theoretical model to an efficient implementation is not straightforward. Most of the research on parallel algorithm design in the '70s and '80s has focused on fine-grain models of parallel computation (see <ref> [BDHM84, Ja92, KR90, Lei92, Rei93, Qui94, KGGK94] </ref>) where the ratio of memory to processors is relatively small. Later research has shown, however, that processor-to-processor communication is the most important bottleneck in parallel computing (see [ACS90, CKP + 93, KRS90, PY88, Val90a, Val90b]). <p> Since then a lot of effort has been directed at fine-grain parallel sorting algorithms (e.g. see <ref> [BDHM84, Ja92, KR90, Rei93] </ref>). In 1983 it was shown [AKE83] that n elements can be sorted in O (lg n) time with an O (n lg n)-sized network.
Reference: [SS95] <author> K. E. Schauser and C. J. Scheiman. </author> <title> Experience with Active Messages on the Meiko CS-2. </title> <booktitle> In 9th International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: Split-C provides a machine independent 4 SPMD programming model and is supported on a large variety of parallel architectures. Experimental results, collected on a 64 node Meiko CS-2, show that optimizing the communication obtains the most dramatic improvement. For the Meiko CS-2, which has special support for long messages <ref> [SS95] </ref>, we analyze the impact of long messages on the execution time and on the algorithm design and implementation. <p> Modern parallel machines, however, have support for long message transfers, i.e., pack more elements that go on a processor in a single message and perform just one communication step (a long message transfer). Thus we can take advantage of the full bandwidth of the network (see <ref> [AISS95, SS95] </ref>) by grouping elements into long messages. In the following we will present a general method for remapping the data between two different data layouts using long messages based on the bit pattern of the absolute address for the respective data layouts. <p> CS-2's communications co-processor has a DMA engine which allows efficient implementations of bulk transfers. For our implementation we used an optimized version of the Split-C parallel language implemented on Meiko CS-2 on top of Active Messages <ref> [vECGS92, SS95] </ref>. 75 5.2 The Split-C Programming Language We have implemented our algorithm in Split-C [CDG + 93], a parallel extension of the C programming language designed for large, distributed-memory multiprocessors.
Reference: [Sto71] <author> H. S. Stone. </author> <title> Parallel processing with the perfect shu*e. </title> <journal> IEEE Computer, </journal> <volume> C-20(2), </volume> <month> February </month> <year> 1971. </year>
Reference-contexts: The bitonic sort was the first network capable of sorting n elements in O (lg 2 n) time. Not surprisingly, bitonic sort has been studied extensively on parallel network topologies such as the hypercube and shu*e-exchange which provide an easy embedding of butterflies <ref> [Sto71] </ref>. Various properties of bitonic networks have been investigated, e.g. 2 [Knu73, HS82, BN86].
Reference: [SV94] <author> M. Schmidt-Voigt. </author> <title> Efficient parallel communication with the nCUBE 2S processor. </title> <journal> Parallel Computing, </journal> <volume> 20(4), </volume> <month> April </month> <year> 1994. </year>
Reference-contexts: Many existing parallel machines have special support for long messages which provide a much higher bandwidth than short messages (e.g., IBM SP-2 [BBB + 94], Paragon [Pie94], Meiko CS-2 [BCM94], Ncube/2 <ref> [SV94] </ref>) and this fact is captured by the LogGP model which is a refinement of the LogP model [AISS95].
Reference: [TM94] <author> L. W. Tucker and A. Mainwaring. </author> <title> CMMD: Active messages on the CM-5. </title> <journal> Parallel Computing, </journal> <volume> 20(4), </volume> <month> April </month> <year> 1994. </year>
Reference-contexts: The reciprocal of g corresponds to the available per processor communication bandwidth for short messages. * P: the number of processor/memory modules. As evidenced by experimental data collected on the CM-5 <ref> [TM94] </ref>, this model can accurately predict communication performance when only fixed-sized short messages are sent [CKP + 93, CDMS94, LC94].
Reference: [Val90a] <author> L. G. Valiant. </author> <title> A Bridging Model for Parallel Computation. </title> <journal> Communications of the ACM, </journal> <volume> 33(8), </volume> <month> August </month> <year> 1990. </year>
Reference-contexts: Later research has shown, however, that processor-to-processor communication is the most important bottleneck in parallel computing (see <ref> [ACS90, CKP + 93, KRS90, PY88, Val90a, Val90b] </ref>). Therefore efficient parallel algorithms are more likely to be achieved on coarse-grain parallel systems and in most situations the original algorithm is substantially redesigned (see [AISS95]). As a parallel application, sorting is especially challenging because of the amount of communication it requires.
Reference: [Val90b] <author> L. G. Valiant. </author> <title> Parallel Algorithms for Shared-Memory Machines. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science. </booktitle> <publisher> El-sevier Science Publishers, </publisher> <year> 1990. </year> <month> 93 </month>
Reference-contexts: Later research has shown, however, that processor-to-processor communication is the most important bottleneck in parallel computing (see <ref> [ACS90, CKP + 93, KRS90, PY88, Val90a, Val90b] </ref>). Therefore efficient parallel algorithms are more likely to be achieved on coarse-grain parallel systems and in most situations the original algorithm is substantially redesigned (see [AISS95]). As a parallel application, sorting is especially challenging because of the amount of communication it requires.
Reference: [vECGS92] <author> T. von Eicken, D. E. Culler, S. C. Goldstein, and K. E. Schauser. </author> <title> Active Messages: a Mechanism for Integrated Communication and Computation. </title> <booktitle> In Proc. of the 19th Int'l Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: CS-2's communications co-processor has a DMA engine which allows efficient implementations of bulk transfers. For our implementation we used an optimized version of the Split-C parallel language implemented on Meiko CS-2 on top of Active Messages <ref> [vECGS92, SS95] </ref>. 75 5.2 The Split-C Programming Language We have implemented our algorithm in Split-C [CDG + 93], a parallel extension of the C programming language designed for large, distributed-memory multiprocessors.
References-found: 36

