URL: http://www.cs.berkeley.edu/~dusseau/Papers/wiley.ps
Refering-URL: http://www.cs.berkeley.edu/~randit/cs267/assignment1.html
Root-URL: 
Title: Fast Parallel Sorting under LogP: from theory to practice  
Author: DAVID E. CULLER, ANDREA C. DUSSEAU, RICHARD P. MARTIN, KLAUS ERIK SCHAUSER 
Note: 1.2 INTRODUCTION Book title and editor name c fl1992 John Wiley Sons Ltd  
Abstract: 1.1 ABSTRACT The LogP model characterizes the performance of modern parallel machines with a small set of parameters: the communication latency (L), overhead (o), bandwidth (g), and the number of processors (P ). In this paper, we analyze four parallel sorting algorithms (bitonic, column, radix, and sample sort) under LogP. We develop implementations of these algorithms in a parallel extension to C and compare the actual performance on a CM-5 of 32 to 512 processors with that predicted by LogP using parameter values for this machine. Our experience was that the model served as a valuable guide throughout the development of the fast parallel sorts and revealed subtle defects in the implementations. The final observed performance matches closely with the prediction across a broad range of problem and machine sizes. Fast sorting is important in a wide variety of practical applications, is interesting to study from a theoretical viewpoint, and offers a wealth of novel parallel solutions. The richness of this particular problem arises, in part, because it fundamentally requires communication as well as computation. Thus, sorting is an excellent area in which to investigate the translation from theory to practice of novel parallel algorithms on large parallel systems. In current (1993) technology, "fast parallel sorting" corresponds to a practical performance target of "sorting a billion large keys on a thousand processors 
Abstract-found: 1
Intro-found: 1
Reference: [Akl89] <author> S. Akl. </author> <title> The Design and Analysis of Parallel Algorithms. </title> <publisher> Prentice Hall, </publisher> <year> 1989. </year>
Reference: [Bat68] <author> K. Batcher. </author> <title> Sorting networks and their applications. </title> <booktitle> In Proceedings of the AFIPS Spring Joint Computing Conference, </booktitle> <volume> Vol. 32, </volume> <year> 1968. </year>
Reference-contexts: We find that fast sorting algorithms under LogP alternate between phases of local computation and global communication, which may involve a general transformation of the entire data set. In the sections that follow, we examine four sorting algorithms: bitonic sort <ref> [Bat68] </ref>, column sort [Lei85], radix sort, and sample sort [Ble91]. <p> that each processor contains exactly n keys after the distribution phase. 7/10/1993 18:29|PAGE PROOFS for John Wiley & Sons Ltd (using jwcbmc01, Vers 01.01 MAY 1992)|sort FAST PARALLEL SORTING UNDER LOGP: FROM THEORY TO PRACTICE 7 1.5 BITONIC SORT In this section, we discuss a variant of Batcher's bitonic sort <ref> [Bat68] </ref>. After describing the general algorithm, we present a data layout that reduces the communication across processors and enables optimizations for the local computation. We then describe how the LogP model guides us to efficient implementations of the important communication operations: remaps between cyclic and blocked layouts.
Reference: [Ble91] <author> G. Blelloch, C. Leiserson, and B. Maggs. </author> <title> A Comparison of Sorting Algorithms for the Connection Machine CM-2. </title> <booktitle> In Symposium on Parallel Algorithms and Architectures, </booktitle> <month> July </month> <year> 1991. </year>
Reference-contexts: We find that fast sorting algorithms under LogP alternate between phases of local computation and global communication, which may involve a general transformation of the entire data set. In the sections that follow, we examine four sorting algorithms: bitonic sort [Bat68], column sort [Lei85], radix sort, and sample sort <ref> [Ble91] </ref>. We predict the execution time of each algorithm based on the four parameters of the LogP model and a small set of parameters that characterize the computational performance of the individual processing nodes, such as the time for a local sort. <p> Split-C, like C, provides a straight-forward machine independent programming system, without attempting to hide the underlying performance characteristics of the machine. We were strongly influenced in this study by a previous comparison of sorting algorithms, which examined bitonic, radix, and sample sort implemented in microcode on the CM-2 <ref> [Ble91] </ref>. That work developed an informal model of the CM-2 with a large number of small processors, a specific hypercube interconnection structure, and hardware support for scan operations. We augment the comparison to include column sort and address a more general setting, formalized by LogP. <p> As a result of the poorer accuracy of our model for very large numbers of processors, we may not be able to extrapolate our results to 1024 processors as well for radix sort as for the other sorts. 1.8 SAMPLE SORT An interesting recent algorithm, called sample (or splitter) sort <ref> [Ble91] </ref>, pushes the pattern of alternating phases of local computation, destination setup, and key distribution to the extreme | it performs only one of each. The key distribution phase in sample sort exhibits the most complicated structure of any in the four sorts: irregular unbalanced all-to-all communication. <p> Assuming a large sample size, a large number of keys per processor, and a random input key distribution, the expansion factor can be bounded by a small constant with high probability <ref> [Ble91] </ref>. The local sort time in sample sort is different than that in bitonic and column sort for two reasons.
Reference: [Cul93a] <author> D. E. Culler, R. M. Karp, D. A. Patterson, A. Sahay, K. E. Schauser, E. Santos, R. Subramonian, and T. von Eicken. </author> <title> LogP: Towards a Realistic Model of Parallel Computation. </title> <booktitle> In Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <month> May </month> <year> 1993. </year> <note> Also appears as UCB/CS/92 713 report. </note>
Reference-contexts: In this paper, we study fast parallel sorting from the perspective of a new "realistic" parallel model, LogP <ref> [Cul93a] </ref>, which attempts to capture the key performance characteristics of modern large scale multiprocessors. In particular, the model reflects the technological reality that these machines are essentially a collection of workstation-class nodes connected by a dedicated, high performance network. <p> The nodes are interconnected in two identical disjoint incomplete fat trees, and a broadcast/scan/prefix control network. The implementation of the sorting algorithms do not use the vector accelerators. In previous experiments on the CM-5 <ref> [VEi92, Cul93a] </ref> we determined that o 2:2s and, on an unloaded network, L 6s. The communication word size, w, is equal to four (32-bit) processor words. <p> The standard approach to implementing bitonic sort is to simply simulate the individual steps in the butterfly. However, we derive a more efficient data placement and work assignment that was inspired by the mapping used for large FFTs, as discussed in <ref> [Cul93a] </ref>. Consider two layouts: blocked and cyclic. Under a blocked layout, the first n = N=P keys are assigned to the first processor, the second n keys to the second processor, and so on.
Reference: [Cul93b] <author> D. E. Culler, A. Dusseau, S. C. Goldstein, A. Krishnamurthy, S. Lumetta, T. von Eicken, and K. Yelick. </author> <title> Parallel Programming in Split-C, </title> <booktitle> In Supercomputing 93. </booktitle>
Reference-contexts: The communication word size, w, is equal to four (32-bit) processor words. The bisection bandwidth is 5MB/s per processor, so we take g to be 4s. 2 1.3.4 Implementation Language Our sorting algorithms are written in Split-C <ref> [Cul93b] </ref>, a parallel extension of the C programming language that can express the capabilities offered by the LogP model. The language follows a SPMD (single program multiple data) model. Processors are distinguished by the value of the special constant, MYPROC.
Reference: [Karp93] <author> R. Karp, A. Sahay, and E. Santos. </author> <title> Optimal Broadcast and Summation in the LogP Model, </title> <booktitle> In 5th Symp. on Parallel Algorithms and Architectures, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: The capacity constraint would eventually cause processor 0 to slow to the forwarding rate. A simpler solution is to insert a delay into the sending loop on processor 0 so it only sends at the forwarding rate max (g; 2o + t add ). 7 In <ref> [Karp93] </ref> an optimal broadcast strategy is developed where the root sends each data element only once, but alternates among recipients in order to retain the logarithmic depth of a tree broadcast. 7/10/1993 18:29|PAGE PROOFS for John Wiley & Sons Ltd (using jwcbmc01, Vers 01.01 MAY 1992)|sort FAST PARALLEL SORTING UNDER LOGP:
Reference: [Len92] <author> D. Lenoski, J. Laudon, K. Gharachorloo, W.-D. Weber, A. Gupta, J. Hennessy, M. Horowitz, and M. Lam, </author> <booktitle> The Stanford Dash Multiprocessor IEEE Computer, </booktitle> <volume> 25(3) </volume> <pages> 63-79, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: After time L, each processor both sends and receives messages, so its sending rate slows to max (g; 2o). After all messages 1 On machines with hardware for shared memory access, the remote end may be serviced by an auxiliary processor that is part of the memory controller <ref> [Len92] </ref>. 7/10/1993 18:29|PAGE PROOFS for John Wiley & Sons Ltd (using jwcbmc01, Vers 01.01 MAY 1992)|sort FAST PARALLEL SORTING UNDER LOGP: FROM THEORY TO PRACTICE 5 have been sent, each processor receives messages at the sending rate. Therefore, the total time for this operation is 2L+2o+(n1L=g) max (g; 2o).
Reference: [Lei85] <author> T. Leighton. </author> <title> Tight bounds on the comlexity of parallel sorting. </title> <journal> In IEEE Transactions on Computers, </journal> <month> April </month> <year> 1985. </year>
Reference-contexts: We find that fast sorting algorithms under LogP alternate between phases of local computation and global communication, which may involve a general transformation of the entire data set. In the sections that follow, we examine four sorting algorithms: bitonic sort [Bat68], column sort <ref> [Lei85] </ref>, radix sort, and sample sort [Ble91]. We predict the execution time of each algorithm based on the four parameters of the LogP model and a small set of parameters that characterize the computational performance of the individual processing nodes, such as the time for a local sort. <p> to note that our predictions for the communication phases and for the local computation have roughly the same accuracy; however, most of the inaccuracy in modeling the local computation is in the bitonic merge sort which we model with only a constant time per key. 1.6 COLUMN SORT Column sort <ref> [Lei85] </ref>, like bitonic sort, alternates between local sort and key distribution phases, but only four phases of each are required. Two key distribution phases use an all-to-all communication pattern and two use a one-to-one pattern.
Reference: [Lei92] <editor> C. E. Leiserson, et al. </editor> <booktitle> The Network Architecture of the Connection Machine CM-5 In Symposium on Parallel Algorithms and Architectures, </booktitle> <month> April </month> <year> 1992. </year> <title> 7/10/1993 18:29|PAGE PROOFS for John Wiley & Sons Ltd (using jwcbmc01, </title> <note> Vers 01.01 MAY 1992)|sort 28 CULLER, DUSSEAU, MARTIN, SCHAUSER </note>
Reference: [Liu93] <author> P. Liu, W. Aiello, S. Bhatt. </author> <title> An atomic model for message-passing. </title> <booktitle> In Symposium on Parallel Algorithms and Architectures, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: Alternatively, we can simply tolerate the contention that occurs at the destinations. Determining the expected slow-down due to contention of a random permutation under LogP is an interesting open problem. Our simulations and recent theoretical results <ref> [Liu93] </ref> suggest that the slow-down is bounded by a small constant, but a thorough treatment of this problem is beyond the scope of this paper. For radix sort, an address calculation is performed before storing each element, and this local computation time further mitigates the effects of contention.
Reference: [Rei87] <author> J. H. Reif and L. G Valiant. </author> <title> A Logarithmic time Sort for Linear Size Networks, </title> <journal> Journal of the ACM, </journal> <volume> 34(1) </volume> <pages> 60-76, </pages> <month> January, </month> <year> 1987. </year>
Reference: [Sha49] <author> C. Shannon and W. Weaver. </author> <title> The Mathematical Theory of Communication, </title> <publisher> University of Illinois Press: </publisher> <address> Urbana, </address> <year> 1949. </year>
Reference: [The91] <author> K. Thearling and S. Smith. </author> <title> An improved supercomputer sorting benchmark. </title> <institution> Thinking Machines Corporation, </institution> <year> 1991. </year>
Reference: [VEi92] <author> T. von Eicken, D. E. Culler, S. C. Goldstein, and K. E. Schauser. </author> <title> Active messages: a mechanism for integrated communication and computation. </title> <booktitle> In International Symposium on Computer Architecture, </booktitle> <year> 1992. </year>
Reference-contexts: The nodes are interconnected in two identical disjoint incomplete fat trees, and a broadcast/scan/prefix control network. The implementation of the sorting algorithms do not use the vector accelerators. In previous experiments on the CM-5 <ref> [VEi92, Cul93a] </ref> we determined that o 2:2s and, on an unloaded network, L 6s. The communication word size, w, is equal to four (32-bit) processor words.
Reference: [Zag91] <author> M. Zagha and G. Blelloch. </author> <title> Radix Sort for Vector Multiprocessors, </title> <booktitle> In Supercomputing 91. </booktitle> <publisher> 7/10/1993 18:29|PAGE PROOFS for John Wiley & Sons Ltd (using jwcbmc01, </publisher> <address> Vers 01.01 MAY 1992)|sort </address>
References-found: 15

