URL: file://ftp.csd.uu.se/pub/papers/reports/0076.ps.gz
Refering-URL: http://www.csd.uu.se/~jb/
Root-URL: 
Email: Email: fbevemyr,thomasl,hakanmg@csd.uu.se  
Title: Reform Prolog: The Language and its Implementation  
Author: Johan Bevemyr Thomas Lindgren H-akan Millroth 
Address: Box 311, S-75105 Uppsala, Sweden  
Affiliation: Computing Science Dept., Uppsala University  
Abstract: Reform Prolog is an (dependent) AND-parallel system based on recursion-parallelism and Reform compilation. The system supports selective, user-declared, parallelization of binding-deterministic Prolog programs (nondeter-minism local to each parallel process is allowed). The implementation extends a convential Prolog machine with support for data sharing and process managment. Extensive global dataflow analysis is employed to facilitate par-allelization. Promising performance figures, showing high parallel efficiency and low overhead for parallelization, have been obtained on a 24 processor shared-memory multiprocessor. The high performance is due to efficient pro cess managment and scheduling, made possible by the execution model.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Bell, </author> <title> Ultracomputers: a Teraflop before its time, </title> <journal> Comm. ACM, </journal> <volume> Vol. 35, No. 8, </volume> <year> 1992. </year>
Reference: [2] <author> J. Bevemyr, </author> <title> A Recursion-Parallel Prolog Engine, </title> <type> PhL Thesis, </type> <institution> Computing Science Department, Uppsala University, </institution> <year> 1993. </year> <month> 15 </month>
Reference: [3] <author> J. Bevemyr, T. Lindgren & H. Millroth, </author> <title> Exploiting recursion-parallelism in Prolog, </title> <booktitle> Proc. PARLE'93, Lecture Notes in Computer Science, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: Local operations do not require suspension or locking unification; shared terms require locking unification but no suspension, while fragile terms may not be instantiated out of the sequential order. If the compiler were not to respect fragility, the system might stray from simulating sequential behavior <ref> [3] </ref>. The goal of locality analysis is to generate precisely WAM code for parallel operations on unshared data. When this is possible, there is no parallelization overhead once the parallel execution has started.
Reference: [4] <author> S.K. Debray & D.S. Warren, </author> <title> Automatic Mode Inference for Logic programs, </title> <journal> J. Logic Programming, </journal> <volume> Vol. 5, No. 3, </volume> <year> 1988. </year>
Reference-contexts: This is managed by combining three analyses: type inference, safeness analysis and locality analysis. The type inference domain is an extension of the Debray-Warren domain <ref> [4] </ref>, with the addition of support for lists and difference lists. The compiler uses both parallel and sequential types in code generation; parallel types hold at all times in the program, while sequential types hold when leftmost. Safeness analysis investigates when the computation is in a nondeterminate, parallel state.
Reference: [5] <author> T. Lindgren, </author> <title> The Compilation and Execution of Recursion-Parallel Prolog on Shared Memory Multiprocessors, </title> <type> PhL Thesis, </type> <institution> Computing Science Department, Uppsala University, </institution> <month> May, </month> <note> 1993 (expected). </note>
Reference: [6] <author> C.P. Kruskal & A. Weiss, </author> <title> Allocating Independent Subtasks on Parallel Processors, </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> Vol. 11, No. 10, </volume> <year> 1985. </year>
Reference-contexts: However, this is less a problem in a recursion-parallel Prolog system than in loop-parallel Fortran systems, since the granularity of a single recursion level typically is greater than the granularity of a single iteration of a parallel loop. More sophisticated dynamic algorithms has been proposed <ref> [6, 12, 7] </ref>. In these algorithms each processor is allocated a chunk of iterations at a time, instead of a single iteration. The chunk size may be fixed or variable. These algorithms have not yet been tested in Reform Prolog. Task switching.
Reference: [7] <author> E.P. Markatos & T.J. LeBlanc, </author> <title> Using Processor Affinity in Loop Scheduling on Shared-Memory Multiprocessors, </title> <type> Technical Report 410, </type> <institution> University of Rochester, </institution> <month> March </month> <year> 1992. </year>
Reference-contexts: However, this is less a problem in a recursion-parallel Prolog system than in loop-parallel Fortran systems, since the granularity of a single recursion level typically is greater than the granularity of a single iteration of a parallel loop. More sophisticated dynamic algorithms has been proposed <ref> [6, 12, 7] </ref>. In these algorithms each processor is allocated a chunk of iterations at a time, instead of a single iteration. The chunk size may be fixed or variable. These algorithms have not yet been tested in Reform Prolog. Task switching.
Reference: [8] <author> J.M. </author> <title> Mellor-Crummey & M.L. Scott, Algorithms for Scalable Synchronization on Shared-Memory Multiprocessors, </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol 9, Febr., </volume> <year> 1991. </year>
Reference-contexts: The other worker's binding must then be unified with this worker's, to ensure consistency. A similar method is used in the implementation of Parallel NU- Prolog [10]. We have found that in our system this method is significantly faster than spin locking <ref> [8] </ref>. 4.2 Creating shared structures When building a structure on the heap other workers should not have access to the structure until it has been fully initialized. In WAM a structure is built using either put instructions or get instructions.
Reference: [9] <author> H. Millroth, </author> <title> Reforming Compilation of Logic Programs, </title> <booktitle> Proc. Int. Symp. Logic Programming, </booktitle> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Each such invocation constitutes a process, which gives the programmer an easy way of estimating the control-flow and process granularity of a program. We refer to this variant of (dependent) AND-parallelism as recursion-parallelism. We implement recursion-parallelism by Reform compilation <ref> [9] </ref> (this can be viewed as an implementation technique for the Reform inference system [15]). This is a control-structure transformation that changes the control-flow of a recursive program quite dramatically.
Reference: [10] <author> L. Naish, </author> <title> Parallelizing NU-Prolog, </title> <booktitle> Proc. 5th Int. Conf. Symp. Logic Programming, </booktitle> <publisher> MIT Press, </publisher> <year> 1988. </year>
Reference-contexts: The unsafe argument has become sufficiently instantiated by another recursion level; or 2 2. The current call becomes leftmost. If neither par-safeness nor seq-safeness can be proven at compile-time, paralleliza-tion fails. The execution model described above has some similarities to the approach taken in Parallel NU-Prolog <ref> [10] </ref> in that both approaches parallelize a binding-deterministic subset of Prolog. However, Reform Prolog exploits recursion-parallelism when parallelizing this subset, whereas Parallel NU-Prolog exploits AND-parallelism. With Reform Prolog, as with Parallel NU-Prolog, it is straight-forward to call parallel subprograms from a nondeterministic program. <p> If another worker has managed to bind the variable ahead of this worker, then the exchange operation will return that binding. The other worker's binding must then be unified with this worker's, to ensure consistency. A similar method is used in the implementation of Parallel NU- Prolog <ref> [10] </ref>. We have found that in our system this method is significantly faster than spin locking [8]. 4.2 Creating shared structures When building a structure on the heap other workers should not have access to the structure until it has been fully initialized. <p> A new instruction has to be introduced after the last unify instruction (when the structure is complete) to bind the variable. This method is also discussed in Naish's paper on Parallel NU-Prolog <ref> [10] </ref>. 4.3 Trailing Variables must be trailed in the parallel phase, even though only safe programs are parallelized. There are two reasons for this. 1. There might be local nondeterminism within each recursion level. If that is the case, the worker must be able to backtrack locally.
Reference: [11] <author> D. Palmer & L. Naish, NUA-Prolog: </author> <title> An Extension to the WAM for Parallel Andorra, </title> <booktitle> Proc. 8th Int. Conf. Logic Programming, </booktitle> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference: [12] <author> C.D. Polychronopoulos & D.J. Kuck, </author> <title> Guided Self-Scheduling: A Practical Scheduling Scheme for Parallel Supercomputers, </title> <journal> IEEE Trans. Computers, </journal> <month> Dec. </month> <year> 1987. </year>
Reference-contexts: However, this is less a problem in a recursion-parallel Prolog system than in loop-parallel Fortran systems, since the granularity of a single recursion level typically is greater than the granularity of a single iteration of a parallel loop. More sophisticated dynamic algorithms has been proposed <ref> [6, 12, 7] </ref>. In these algorithms each processor is allocated a chunk of iterations at a time, instead of a single iteration. The chunk size may be fixed or variable. These algorithms have not yet been tested in Reform Prolog. Task switching.
Reference: [13] <author> R. Yang, T. Beaumont, I. Dutra, V.S. Costa, D.H.D. Warren, </author> <title> Performance of the Compiler-Based Andorra-I System, </title> <booktitle> Proc. 10th Int. Conf. Logic Programming, </booktitle> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: Nrev. (27.70 sec.) P T S R S N T S R S N 4 17.22 3.99 3.80 68.85 3.75 3.37 16 5.76 11.95 11.35 17.25 14.96 13.47 Match. (65.44 sec.) Tsp. (232.40 sec.) 8.4 Discussion We briefly compare our system with Andorra-I, another compiler-based implementation supporting deterministic dependent AND-parallelism <ref> [13] </ref>. Note, however, that Andorra-I parallelizes a wider class of computations than does Reform Pro-log. In particular, Andorra-I also supports OR-parallelism. The results reported for Andorra-I were obtained on a 10 processor Sequent Symmetry.
Reference: [14] <author> P. Tang & P.-C. Yew, </author> <title> Processor Self-Scheduling for Multiple Nested Parallel Loops, </title> <booktitle> Proc. 1986 Int. Conf. Parallel Processing , August 1986. </booktitle>
Reference-contexts: Dynamic scheduling. The goal of dynamic scheduling methods is to optimize the tradeoff between large process granularity and good load balance. The simplest dynamic algorithm for scheduling is self-scheduling <ref> [14] </ref>. In this algorithm each processor executes one recursion level at a time until all levels have been executed. This method achives almost perfect load balancing. The problem with self-scheduling is, not surprisingly, that it tends to create too many processes with too fine granularity.
Reference: [15] <author> S. A. </author> <title> Tarnlund, Reform, </title> <type> report, </type> <institution> Computing Science Dept., Uppsala University, </institution> <year> 1991. </year>
Reference-contexts: We refer to this variant of (dependent) AND-parallelism as recursion-parallelism. We implement recursion-parallelism by Reform compilation [9] (this can be viewed as an implementation technique for the Reform inference system <ref> [15] </ref>). This is a control-structure transformation that changes the control-flow of a recursive program quite dramatically. When invoking a recursive program with a call of size n (corresponding to a recursion depth n) a four-phase computation is initiated: 1.
Reference: [16] <author> D.H.D. Warren, </author> <title> An Abstract Prolog Instruction Set, </title> <type> SRI Tech. Note 309, </type> <institution> SRI International, Menlo Park, Calif., </institution> <year> 1983. </year> <month> 16 </month>
References-found: 16

