URL: http://www.cse.unsw.edu.au/~achim/PostScripts/Hoffmann-ECAI92.ps
Refering-URL: http://www.cse.unsw.edu.au/~achim/index.html
Root-URL: http://www.cse.unsw.edu.au
Email: E-mail: achim@cs.tu-berlin.de  
Title: Phenomenology, Representations and Complexity  
Author: Achim G. Hoffmann 
Address: FR 5-11 Franklinstr.28/29, W-1000 Berlin 10, Germany,  
Affiliation: Technische Universitat Berlin, Department of Computer Science,  
Abstract: The paper refutes the general phenomenological argument that knowledge cannot be completely represented by symbols and, hence, symbolic AI does not work. Moreover, the viewpoint of algorithmic information theory is introduced for considering the limitations of artificial intelligence. Based on the formal considerations of the notion of algorithm we will come to new conclusions from the phenomenological critic at the possibility of (symbolic) AI. Keywords: Phenomenology, Representations, Algorithmic information theory, Physical symbol systems 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. L. Dreyfus and S. E. Dreyfus. </author> <title> Mind over Machine The Power of Human Intuition and Expertise in the Era of the Computer. </title> <publisher> Free Press, </publisher> <year> 1986. </year>
Reference-contexts: 1 Introduction In this paper we consider some fundamental issues of artificial intelligence. Among these issues will be problems of formal limitations of AI, i.e. discussing the physical symbol system hypothesis [8]. We will respond to philosophical critics as these of Dreyfus (see e.g. <ref> [1] </ref>) or these of Winograd and Flores (see [12]). These critics are closely connected to the problem of knowledge representation. But most importantly, in section 4.3, we will advocate a new consequence from the phenomenological arguments against AI. The paper is organized as follows. <p> This claim is also called the physical symbol system hypothesis [8]. and has been heavily attacked by, e.g. Dreyfus <ref> [1] </ref> and Winograd & Flores [12] from a phenomenological point of view. We identify the physical symbol system hypothesis with the claim that the human mind can be adequately simulated by an appropriate Turing machine. <p> Dreyfus <ref> [1] </ref> or Winograd & Flores [12]. Phenomenology argues that human cognition and understanding is basically connected with social interaction. Moreover, the human mind only starts reflecting about objects and their relations in an outer world in situations of breakdowns.
Reference: [2] <author> R. Freivalds and A. G. Hoffmann. </author> <title> An inductive inference approach to classification. </title> <booktitle> In Proceedings of the 3 rd Workshop on Analogical and Inductive Inference, </booktitle> <publisher> Schlo Dagstuhl, </publisher> <address> Germany, </address> <month> October </month> <year> 1992. </year> <note> Springer-Verlag. (to appear.) </note>
Reference-contexts: See Figure 2. Roughly spoken, the semantic of the subject's representation turns out to be committed in a larger degree to the subject than to the object. First results on the complexity of possibly acquired mental structures in auto-organizative systems are obtained in <ref> [2] </ref>. These results indicate that simple auto-organizative principles are rather limited in producing meaningful mental structures. Quine's ontological relativism The logician and philosopher W.v.O. Quine rejected the model-theoretic absolute ontology in `real world applications'.
Reference: [3] <author> M. Frixione, G. Spinelli, and S. Gaglio. </author> <title> Symbols and subsymbols for representing knowledge: a catalogue raisonne. </title> <booktitle> In Proceedings of the 11 th International Joint Conference of Artificial Intelligence, </booktitle> <pages> pages 3-7, </pages> <year> 1989. </year>
Reference-contexts: In contrast to that, one has argued, computers have to represent `values' and `goals' as well as their `view' of the world explicitly by symbols and therewith computers cannot behave like humans. Similarly, Frixione et al. <ref> [3] </ref> claim that intelligent systems must have a subsymbolic level of activity.
Reference: [4] <author> A. G. Hoffmann. </author> <title> General limitations on machine learning. </title> <booktitle> In Proceedings of the 9 th European Conference on Artificial Intelligence, </booktitle> <pages> pages 345-347, </pages> <address> Stock-holm, Sweden, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: For example in inductive reasoning, usually there is an ambiguity among different hypotheses, when generalizing inferences should be performed. Thus, there is a need for expressing some preference relation among competing hypotheses. As indicated in, e.g. <ref> [4] </ref> for symbolic approaches and in [5] for non-symbolic approaches, there is no uniform inductive inference procedure, which describes human inductive reasoning behavior. The human inductive reasoning behavior contains some complex (implicit) preference relation on the competing hypotheses.
Reference: [5] <author> A. G. Hoffmann. </author> <title> On computational limitations of neural network architectures. </title> <booktitle> In Proceedings of the 2 nd IEEE Symposium on Parallel and Distributed Processing, </booktitle> <pages> pages 818-825, </pages> <address> Dallas, Texas, USA, De-cember 1990. </address> <publisher> IEEE. </publisher>
Reference-contexts: For example in inductive reasoning, usually there is an ambiguity among different hypotheses, when generalizing inferences should be performed. Thus, there is a need for expressing some preference relation among competing hypotheses. As indicated in, e.g. [4] for symbolic approaches and in <ref> [5] </ref> for non-symbolic approaches, there is no uniform inductive inference procedure, which describes human inductive reasoning behavior. The human inductive reasoning behavior contains some complex (implicit) preference relation on the competing hypotheses.
Reference: [6] <author> M. Li and P. M. B. Vitanyi. </author> <title> Two decades of applied Kolmogorov complexity. </title> <booktitle> In Proceedings of the 3 rd Annual Conference on Structure in Complexity Theory, </booktitle> <pages> pages 80-101, </pages> <year> 1988. </year>
Reference-contexts: We identify the physical symbol system hypothesis with the claim that the human mind can be adequately simulated by an appropriate Turing machine. In the following we will take a closer look to the Turing machine in connection with the Invariance theorem <ref> [6] </ref> of algorithmic information theory. 2.1 Universal Turing machines Following the introduction of the Turing machine by A.M. Turing [10] it has been recognized that there also exist various kinds of universal Turing machines. <p> The length of a binary encoded program p is denoted by jpj. Definition 1 The length of the shortest program for constructing s is called its Kolmogorov complexity K (s). According to the Invariance Theorem (see e.g. <ref> [6] </ref>) the particular kind of considered universal Turing machine U makes only a difference of a certain constant c. Moreover, there are 2 n different binary strings of length n.
Reference: [7] <author> H. R. Maturana and F. J. Varela. </author> <title> The Tree of Knowledge. The Biological Roots of Human Understanding. </title> <address> New Science Library, </address> <year> 1987. </year>
Reference-contexts: Particularly, Maturana and Varela <ref> [7] </ref> propell this auto-organizative tradition exploring the capability of biological systems to create their own world of experience. In their view, Environment system B C XF Auto-organizative auto-organizative system is conceived as completely autonomous.
Reference: [8] <author> A. Newell. </author> <title> Physical symbol systems. </title> <journal> Cognitive Science, </journal> <volume> 4 </volume> <pages> 135-183, </pages> <year> 1980. </year>
Reference-contexts: 1 Introduction In this paper we consider some fundamental issues of artificial intelligence. Among these issues will be problems of formal limitations of AI, i.e. discussing the physical symbol system hypothesis <ref> [8] </ref>. We will respond to philosophical critics as these of Dreyfus (see e.g. [1]) or these of Winograd and Flores (see [12]). These critics are closely connected to the problem of knowledge representation. <p> This claim is also called the physical symbol system hypothesis <ref> [8] </ref>. and has been heavily attacked by, e.g. Dreyfus [1] and Winograd & Flores [12] from a phenomenological point of view. We identify the physical symbol system hypothesis with the claim that the human mind can be adequately simulated by an appropriate Turing machine.
Reference: [9] <author> W. v. O. Quine. </author> <title> Ontological Relativity and Other Essays. </title> <publisher> Columbia University Press, </publisher> <address> New York, </address> <year> 1969. </year>
Reference-contexts: These results indicate that simple auto-organizative principles are rather limited in producing meaningful mental structures. Quine's ontological relativism The logician and philosopher W.v.O. Quine rejected the model-theoretic absolute ontology in `real world applications'. He advocates much more a relativistic viewpoint <ref> [9] </ref>: `To be is to be the value of a variable.' Which means, that ontological entities are determined by the structure of the language that is used for describing phenomena in a certain domain. However, there is always a choice which particular structure of language is used.
Reference: [10] <author> A. M. </author> <title> Turing. On computable numbers, with an application to the Entscheidungsproblem. </title> <journal> Proceedings of the London Mathematical Society, </journal> <volume> 2(42) </volume> <pages> 230-265 and (43) 544-546, </pages> <year> 1937. </year>
Reference-contexts: In the following we will take a closer look to the Turing machine in connection with the Invariance theorem [6] of algorithmic information theory. 2.1 Universal Turing machines Following the introduction of the Turing machine by A.M. Turing <ref> [10] </ref> it has been recognized that there also exist various kinds of universal Turing machines. A universal Turing machine U is a Turing machine that is able to simulate any particular Turing machine whose Turing machine table is provided on U 's input tape.
Reference: [11] <author> A. M. </author> <title> Turing. </title> <journal> Computing machinery and intelligence. Mind, </journal> <volume> 59 </volume> <pages> 433-460, </pages> <year> 1950. </year>
Reference-contexts: In contrast to the strings above, strings like `101100100111011001011101010' are more complex, i.e. require a longer program for getting printed, since the structure needs a particular description. 2.3 Algorithmic information for describing the mind According to Turing's paper Computing machinery and intelligence <ref> [11] </ref>, we assume that for considering intelligent behavior of agents our considerations can be restricted to agents which communicate with their environment through finite strings of symbols from a finite alphabet. 1 In other words, we can say that an agent behaves intelligent, if it shows a certain appropriate output to
Reference: [12] <author> T. Winograd and F. Flores. </author> <title> Understanding Computers and Cognition: A new Foundation for Design. </title> <publisher> Norwood Publisher, </publisher> <year> 1986. </year>
Reference-contexts: Among these issues will be problems of formal limitations of AI, i.e. discussing the physical symbol system hypothesis [8]. We will respond to philosophical critics as these of Dreyfus (see e.g. [1]) or these of Winograd and Flores (see <ref> [12] </ref>). These critics are closely connected to the problem of knowledge representation. But most importantly, in section 4.3, we will advocate a new consequence from the phenomenological arguments against AI. The paper is organized as follows. In the following section the formal framework for our viewpoint of AI is given. <p> This claim is also called the physical symbol system hypothesis [8]. and has been heavily attacked by, e.g. Dreyfus [1] and Winograd & Flores <ref> [12] </ref> from a phenomenological point of view. We identify the physical symbol system hypothesis with the claim that the human mind can be adequately simulated by an appropriate Turing machine. <p> Dreyfus [1] or Winograd & Flores <ref> [12] </ref>. Phenomenology argues that human cognition and understanding is basically connected with social interaction. Moreover, the human mind only starts reflecting about objects and their relations in an outer world in situations of breakdowns. That is, in situations where the usual acting cannot proceed as expected.
Reference: [13] <author> L. Wittgenstein. Tractatus logico-philosophicus. </author> <year> 1922. </year>
Reference-contexts: However, the general applicability of this model-theoretic approach has been rejected by phenomenology as well as by the late Wittgenstein [14] himself; once being a strong advocate of the model-theoretic idea <ref> [13] </ref>. 4.2 Alternative approaches Auto-organizative systems Another rather popular approach today, is the idea of emphasizing the auto-organizative capacities of biological systems, e.g. the human mind. Particularly, Maturana and Varela [7] propell this auto-organizative tradition exploring the capability of biological systems to create their own world of experience.
Reference: [14] <author> L. Wittgenstein. </author> <title> Philosophical Investigations. </title> <publisher> Macmillan, Oxford, </publisher> <year> 1953. </year>
Reference-contexts: The same problem exists for reasoning under uncertainty: Human reasoning incorporates a lot of interdependencies of subjective probabilities, when probability estimates of combined uncertain events are made. However, the general applicability of this model-theoretic approach has been rejected by phenomenology as well as by the late Wittgenstein <ref> [14] </ref> himself; once being a strong advocate of the model-theoretic idea [13]. 4.2 Alternative approaches Auto-organizative systems Another rather popular approach today, is the idea of emphasizing the auto-organizative capacities of biological systems, e.g. the human mind.
References-found: 14

