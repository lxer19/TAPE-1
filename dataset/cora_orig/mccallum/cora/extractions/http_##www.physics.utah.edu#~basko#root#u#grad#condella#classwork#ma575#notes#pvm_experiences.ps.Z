URL: http://www.physics.utah.edu/~basko/root/u/grad/condella/classwork/ma575/notes/pvm_experiences.ps.Z
Refering-URL: 
Root-URL: 
Email: geist@msr.epm.ornl.gov  vss@mathcs.emory.edu  
Title: Network Based Concurrent Computing on the PVM System*  
Author: G. A. Geist V. S. Sunderam 
Address: Oak Ridge, TN 37831  Atlanta, GA 30322  
Affiliation: Mathematical Sciences Section Engineering Physics and Mathematics Division Oak Ridge National Laboratory  Department of Math Computer Science Emory University  
Abstract: Concurrent computing environments based on loosely coupled networks have proven effective as resources for multiprocessing. Experiences with and enhancements to PVM (Parallel Virtual Machine) are described in this paper. PVM is a software system that allows the utilization of a heterogeneous network of parallel and serial computers as a single computational resource. This report also describes an interactive graphical interface to PVM, and porting and performance results from production applications. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Lenstra, M. Manasse, </author> <title> "The Number Field Sieve", </title> <booktitle> Proc. Symposium on the Theory of Computing, </booktitle> <address> Baltimore, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: 1. Introduction Concurrent computing environments based on networks of computers can be an effective, viable, and economically attractive complement to hardware multiprocessors. A case in point is the number field sieve project of Lenstra and Manasse <ref> [1] </ref>, whose most recent milestone is the factoring of the ninth Fermat number (148 digits) using over 1,000 computers worldwide. Although such large scale use of network-based concurrent computing may be rare, there exist many examples of this mode of multicomputing on a smaller scale.
Reference: [2] <author> G. Popek, B. Walker, </author> <title> "The LOCUS Distributed System Architecture", </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1985. </year>
Reference-contexts: Department of Energy, under contract DE-AC05-84OR21400 with Martin Marietta Energy Systems, Inc. - 2 - Some of these network-based concurrent computing environments are specialized, in that they are either based upon distributed operating systems (e.g. Locus <ref> [2] </ref>, the V-kernel [3]), or they support special-purpose programming paradigms (e.g. Linda [21], the Camelot transaction processing facility [17]). While these systems are highly effective, they impose many constraints and requirements on application end-users and resource administrators that are often difficult to meet.
Reference: [3] <author> D. Cheriton, </author> <title> "The V Distributed System", </title> <journal> Comm. ACM, </journal> <volume> Vol. 31, No. 3, </volume> <pages> pp. 314-333, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: Department of Energy, under contract DE-AC05-84OR21400 with Martin Marietta Energy Systems, Inc. - 2 - Some of these network-based concurrent computing environments are specialized, in that they are either based upon distributed operating systems (e.g. Locus [2], the V-kernel <ref> [3] </ref>), or they support special-purpose programming paradigms (e.g. Linda [21], the Camelot transaction processing facility [17]). While these systems are highly effective, they impose many constraints and requirements on application end-users and resource administrators that are often difficult to meet.
Reference: [4] <author> M. Sullivan, D. Anderson, "Marionette: </author> <title> A System for Parallel Distributed Programming Using the Master/Slave Model", </title> <booktitle> Proc. 9th Intl. Conf. on Distributed - 20 - Computing Systems, </booktitle> <pages> pp. 181-188, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Several design features distinguish PVM from other similar systems such as Cosmic [7], Marionette <ref> [4] </ref>, ISIS [22], and Dpup [5]. Among these are the combination of heterogeneity, scalability, multilanguage support, provisions for fault tolerance, the use of multiprocessors and scalar machines, an interactive graphical front end, and support for profiling, tracing, and visual analysis. 2.1.
Reference: [5] <author> T.J. Gardner, et.al., "DPUP: </author> <title> A Distributed Processing Utilities Package", </title> <institution> Computer Science technical report University of Colorado, </institution> <year> 1986. </year>
Reference-contexts: Several design features distinguish PVM from other similar systems such as Cosmic [7], Marionette [4], ISIS [22], and Dpup <ref> [5] </ref>. Among these are the combination of heterogeneity, scalability, multilanguage support, provisions for fault tolerance, the use of multiprocessors and scalar machines, an interactive graphical front end, and support for profiling, tracing, and visual analysis. 2.1.
Reference: [6] <author> R. Pike, et. al., </author> <title> "Plan 9 from Bell Labs", </title> <note> Research Note, </note> <month> July </month> <year> 1990. </year>
Reference-contexts: Typically, networked computing environments possess a variety of capabilities; the ability to execute subtasks of a computation on the processor most suited to a particular function both enhances performance and improves utilization. The Plan 9 distributed system from Bell Labs <ref> [6] </ref> is based entirely on this model, and initial results are very promising. But the implementation of Plan 9 appears to suffer from lack of flexibility and special requirements in terms of network characteristics and processing/storage elements.
Reference: [7] <author> C. Seitz, et. al., </author> <title> "The C Programmers Abbreviated Guide to Multicomputer Programming", </title> <institution> Caltech Computer Science Report CS-TR-88-1, </institution> <month> January </month> <year> 1988. </year>
Reference-contexts: Several design features distinguish PVM from other similar systems such as Cosmic <ref> [7] </ref>, Marionette [4], ISIS [22], and Dpup [5]. Among these are the combination of heterogeneity, scalability, multilanguage support, provisions for fault tolerance, the use of multiprocessors and scalar machines, an interactive graphical front end, and support for profiling, tracing, and visual analysis. 2.1.
Reference: [8] <author> R. Finkel, U. Manber, </author> <title> "DIB A Distributed Implementation of Backtracking", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 9, No. 2, </volume> <pages> pp. 235-256, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: Inter-instance communication constructs include those for the exchange of data structures as well as high-level primitives such as broadcast, barrier synchronization, mutual exclusion, global extrema, and rendezvous. PVM supports two general parallel programming models tree computations as supported by the DIB <ref> [8] </ref> and Schedule [9] packages, and crowd computations [11]. Supporting both paradigms increases the flexibility and power of the system significantly, especially since individual subtasks within either of these models may themselves be parallel programs expressed in the other.
Reference: [9] <author> J. Dongarra, D. Sorenson, </author> <title> "SCHEDULE: Tools for Developing and Analyzing Parallel Fortran Programs", in The Characteristics of Parallel Algorithms, </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1988. </year>
Reference-contexts: Inter-instance communication constructs include those for the exchange of data structures as well as high-level primitives such as broadcast, barrier synchronization, mutual exclusion, global extrema, and rendezvous. PVM supports two general parallel programming models tree computations as supported by the DIB [8] and Schedule <ref> [9] </ref> packages, and crowd computations [11]. Supporting both paradigms increases the flexibility and power of the system significantly, especially since individual subtasks within either of these models may themselves be parallel programs expressed in the other. <p> Application Execution The XPVM interface contains facilities for unstructured and regular crowd computation models. In addition, tree structured computations will be supported using the Schedule <ref> [9] </ref> system. In the regular crowd model, the XPVM interface permits the specification of an object module and the number of instances that are to be initiated; the specified number of processes are then executed automatically by the PVM system, thereby avoiding the need for a user-written driver program.
Reference: [10] <author> G. Fox, </author> <title> "Parallelism Comes of Age: Supercomputer Level Parallel Computations at Caltech", </title> <journal> Concurrency: Practice & Experience, </journal> <volume> Vol. 1, No. 1, </volume> <pages> pp. 63-104, </pages> <month> Sep-tember </month> <year> 1989. </year>
Reference: [11] <author> J. Postel, </author> <title> "User Datagram Protocol", Internet request for Comments RFC793, </title> <month> Sep-tember </month> <year> 1981. </year>
Reference-contexts: Inter-instance communication constructs include those for the exchange of data structures as well as high-level primitives such as broadcast, barrier synchronization, mutual exclusion, global extrema, and rendezvous. PVM supports two general parallel programming models tree computations as supported by the DIB [8] and Schedule [9] packages, and crowd computations <ref> [11] </ref>. Supporting both paradigms increases the flexibility and power of the system significantly, especially since individual subtasks within either of these models may themselves be parallel programs expressed in the other. <p> For example, Internet protocols may be used both on the DARPA Internetwork and on Ethernets. However, specialized low level protocols on Ethernet significantly improve performance and efficiency in distributed applications. The PVM system presently supports the Internet protocols <ref> [11] </ref>, low level Ethernet protocols [12], and the IMCS interface [13]. - 6 - 2.3. Other Aspects Multiprocessing on loosely coupled networks provides facilities that are normally not available on tightly coupled multiprocessors.
Reference: [12] <author> V. Sunderam, </author> <title> "A Fast Transaction Oriented protocol for Distributed Applications", </title> <booktitle> Proc. Winter Usenix Conference, </booktitle> <pages> pp. 79-87, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: For example, Internet protocols may be used both on the DARPA Internetwork and on Ethernets. However, specialized low level protocols on Ethernet significantly improve performance and efficiency in distributed applications. The PVM system presently supports the Internet protocols [11], low level Ethernet protocols <ref> [12] </ref>, and the IMCS interface [13]. - 6 - 2.3. Other Aspects Multiprocessing on loosely coupled networks provides facilities that are normally not available on tightly coupled multiprocessors.
Reference: [13] <author> K. Rader, </author> <title> "IMCS Programmers Guide Draft", </title> <institution> IBM Corporation, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: For example, Internet protocols may be used both on the DARPA Internetwork and on Ethernets. However, specialized low level protocols on Ethernet significantly improve performance and efficiency in distributed applications. The PVM system presently supports the Internet protocols [11], low level Ethernet protocols [12], and the IMCS interface <ref> [13] </ref>. - 6 - 2.3. Other Aspects Multiprocessing on loosely coupled networks provides facilities that are normally not available on tightly coupled multiprocessors.
Reference: [14] <author> G. Geist, M. T. Heath, B. W. Peyton, and P. H. Worley, </author> <title> "A Machine Independent Communications Library", </title> <booktitle> Proc. of the Fourth Conference on Hypercubes, Concurrent Computers, and Applications.ed. J.L. Gustafson, </booktitle> <publisher> Golden Gate Enterprises, </publisher> <address> Los Altos, CA, </address> <pages> pp. 565-568, </pages> <year> 1989. </year>
Reference-contexts: First, the XPVM interface is a graphical tool that eases many of the application tasks of specifying components, handling input and output, interacting with PVM during execution, managing multiple objects, and providing a debugging interface. Second, the PICL library <ref> [14] </ref> supports portable parallel programming and profiling. These components are discussed in the following sections. The PVM support software (a daemon process that executes on each participating host) is replicated for each user of the system.
Reference: [15] <author> M. Heath, </author> <title> "Visual Animation of Parallel Algorithms for Matrix Computations", </title> <booktitle> Proc. Fifth Distributed Memory Computing Conference, </booktitle> <editor> ed. D. Walker and Q. Stout, </editor> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 1213-1222, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Essentially, applications that are written in terms of this interface may optionally enable tracing, which globally logs all events including message transmission and reception, synchronization, and other distributed events. At present, these global logs may be analyzed visually using the ParaGraph tool <ref> [15] </ref>, which graphically displays events, their relationships, and (indirectly) parameters such as processor utilization and load imbalances. The monitoring facility of the XPVM interface will soon be able to display event information dynamically to assist in interactive debugging. 4.
Reference: [16] <author> G. Geist, et. al., </author> <title> "A User's Guide to PICL: A Portable Instrumented Communication Library", </title> <institution> Oak Ridge National Laboratory TM-11616, </institution> <month> September </month> <year> 1990. </year>
Reference-contexts: Portable Programming Using PICL PICL (Portable Instrumented Communication Library) is a collection of library routines that facilitates portable development of multiprocessor programs. A complete description of the PICL primitives may be found in <ref> [16] </ref>. The PICL libraries have been ported to the PVM system in order to allow applications also to be portable to a network-based multiprocessing system. The main issues in porting PICL to a heterogeneous environment are discussed in this section.
Reference: [17] <author> A. Spector, et. al., ""Camelot: </author> <title> A Flexible Distributed Transaction Processing System", </title> <booktitle> Proc. Spring Compcon 88 - 33rd IEEE CS Intl. Conf., </booktitle> <pages> pp. 432-437, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: Locus [2], the V-kernel [3]), or they support special-purpose programming paradigms (e.g. Linda [21], the Camelot transaction processing facility <ref> [17] </ref>). While these systems are highly effective, they impose many constraints and requirements on application end-users and resource administrators that are often difficult to meet.
Reference: [18] <author> Sun Microsystems, "XDR: </author> <title> External Data Representation Standard", Internet request for Comments RFC1057, </title> <month> June </month> <year> 1988. </year> <month> - 21 </month> - 
Reference-contexts: Typically, existing systems use the latter scheme (e.g. Sun XDR <ref> [18] </ref>); although conversion is performed twice, senders do not need to know the architecture type of the destination processor, nor do representations for every possible architecture have to be known at each sender.
Reference: [19] <author> D. L. Mills, </author> <title> "Network Time Protocal (version 2) specification and implementation", DARPA Network Working Group Report RFC-1119, </title> <month> September </month> <year> 1990. </year>
Reference-contexts: While clock synchronization is a problem even on machines such as commercial hypercubes, the granularity of synchronization attainable on local networks is coarser than hypercubes and continues to be an issue of concern in the PVM implementation. At present, a combination of the network time protocol <ref> [19] </ref> and internal PVM synchronization is used and is acceptable for short-running applications. 4.1. Portability in Heterogeneous Environments Two important issues in programming for heterogeneous network environments are the issue of data representation and byte ordering.
Reference: [20] <author> V. Sunderam, </author> <title> "PVM: A Framework for Parallel Distributed Computing", </title> <journal> Concurrency:Practice & Experience Vol. </journal> <volume> 2 No. 4, </volume> <month> Dec. </month> <year> 1990. </year>
Reference: [21] <author> M. Arango, D. Berndt, N. Carriero, D. Galernter, and D. Gilmore, </author> <title> "Adventures with Network Linda", </title> <journal> Supercomputing Review, </journal> <volume> Vol. 3 No. 10, </volume> <month> Oct. </month> <year> 1990. </year>
Reference-contexts: Department of Energy, under contract DE-AC05-84OR21400 with Martin Marietta Energy Systems, Inc. - 2 - Some of these network-based concurrent computing environments are specialized, in that they are either based upon distributed operating systems (e.g. Locus [2], the V-kernel [3]), or they support special-purpose programming paradigms (e.g. Linda <ref> [21] </ref>, the Camelot transaction processing facility [17]). While these systems are highly effective, they impose many constraints and requirements on application end-users and resource administrators that are often difficult to meet.
Reference: [22] <author> K. Birman and K. Marzullo, </author> <title> "ISIS and the META project", </title> <booktitle> Sun Technology Summer 1989, </booktitle> <pages> pp. 90-104. </pages>
Reference-contexts: Several design features distinguish PVM from other similar systems such as Cosmic [7], Marionette [4], ISIS <ref> [22] </ref>, and Dpup [5]. Among these are the combination of heterogeneity, scalability, multilanguage support, provisions for fault tolerance, the use of multiprocessors and scalar machines, an interactive graphical front end, and support for profiling, tracing, and visual analysis. 2.1.

References-found: 22

