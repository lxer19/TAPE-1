URL: http://www.icsi.berkeley.edu/~yairb/pubs/ABF-heat-n-dump.ps
Refering-URL: http://www.icsi.berkeley.edu/~yairb/
Root-URL: http://www.icsi.berkeley.edu
Title: Heat Dump: Competitive Distributed Paging competitive ratio is logarithmic in the total storage capacity of
Author: Baruch Awerbuch Yair Bartal Amos Fiat 
Note: Dump. The  
Abstract: This paper gives a randomized competitive distributed paging algorithm called Heat & 
Abstract-found: 1
Intro-found: 1
Reference: [ABF93] <author> Baruch Awerbuch, Yair Bartal, and Amos Fiat. </author> <title> Competitive distributed file allocation. </title> <booktitle> In Proc. 25th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 164-173, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: The correct treatment here would be to keep a running count of the number of times a file was requested, and to require a file replication when this count reaches the ratio between the two costs, as elaborated in <ref> [BFR92, ABF93] </ref>. The analysis of the randomized algorithm herein is sufficiently complicated so as to make these additional features of the model simply confusing. Thus, throughout this paper, we focus on the simplest possible setting (the basic memory management problem above).
Reference: [BBK + 90] <author> S. Ben-David, A. Borodin, R.M. Karp, G. Tardos, and A. Wigderson. </author> <title> On the power of randomization in on-line algorithms. </title> <booktitle> In Proc.of the 22nd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 379-386, </pages> <month> may </month> <year> 1990. </year>
Reference: [Bel92] <author> Gordon Bell. </author> <title> Ultracomputers: A Teraflop before its time. </title> <journal> Comm. of the ACM, </journal> <volume> 35(8), </volume> <year> 1992. </year>
Reference-contexts: In the context of parallel multiprocessors, this setting is referred to as Cache-Only Memory Architecture (COMA) [HALH91], and it has has been employed in a number of recently developed parallel machines such as the Data Diffusion Machine [HALH91] and in the new KSR1 machine <ref> [Bel92] </ref>, where it is referred to as AllCache Engine. This setting also corresponds to that of a homogeneous distributed file server, comprised of a collection of disk-less workstations. Previous results. Some systems work in a related setting has been reported in [LH86].
Reference: [BFR92] <author> Yair Bartal, Amos Fiat, and Yuval Rabani. </author> <title> Competitive algorithms for distributed data management. </title> <booktitle> In Proc. 24th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 39-50, </pages> <year> 1992. </year> <month> 28 </month>
Reference-contexts: This setting also corresponds to that of a homogeneous distributed file server, comprised of a collection of disk-less workstations. Previous results. Some systems work in a related setting has been reported in [LH86]. In theory community, this problem was first tackled in <ref> [BFR92] </ref> who give on-line algorithms with competitive factors that grow linearly with the memory capacity of the network. While linear competitive factor is proved [BFR92] to be optimal for deterministic algorithms considered in [BFR92], it is quite unsatisfactory as a performance guarantee in practice. <p> Previous results. Some systems work in a related setting has been reported in [LH86]. In theory community, this problem was first tackled in <ref> [BFR92] </ref> who give on-line algorithms with competitive factors that grow linearly with the memory capacity of the network. While linear competitive factor is proved [BFR92] to be optimal for deterministic algorithms considered in [BFR92], it is quite unsatisfactory as a performance guarantee in practice. The question of a randomized competitive ratio for this problem was left as an open problem in [BFR92]. <p> In theory community, this problem was first tackled in <ref> [BFR92] </ref> who give on-line algorithms with competitive factors that grow linearly with the memory capacity of the network. While linear competitive factor is proved [BFR92] to be optimal for deterministic algorithms considered in [BFR92], it is quite unsatisfactory as a performance guarantee in practice. The question of a randomized competitive ratio for this problem was left as an open problem in [BFR92]. This problem has been studied in the systems community; see for example [LH86]. [BFR92] defined this problem in the competitive framework (the <p> While linear competitive factor is proved <ref> [BFR92] </ref> to be optimal for deterministic algorithms considered in [BFR92], it is quite unsatisfactory as a performance guarantee in practice. The question of a randomized competitive ratio for this problem was left as an open problem in [BFR92]. This problem has been studied in the systems community; see for example [LH86]. [BFR92] defined this problem in the competitive framework (the constrained file allocation problem), and give optimal deterministic on-line algorithms for the uniform network with competitive factors that grow linearly with the memory capacity of the network. <p> to be optimal for deterministic algorithms considered in <ref> [BFR92] </ref>, it is quite unsatisfactory as a performance guarantee in practice. The question of a randomized competitive ratio for this problem was left as an open problem in [BFR92]. This problem has been studied in the systems community; see for example [LH86]. [BFR92] defined this problem in the competitive framework (the constrained file allocation problem), and give optimal deterministic on-line algorithms for the uniform network with competitive factors that grow linearly with the memory capacity of the network. <p> The question of a randomized competitive ratio for this problem was left as an open problem in <ref> [BFR92] </ref>. While considerable progress has been made in the competitive analysis of deterministic on-line algorithms, efficient randomized on-line algorithms against an oblivious adversary ([BBK + 90]) have been found for only very few problems. Main results of this paper. <p> The correct treatment here would be to keep a running count of the number of times a file was requested, and to require a file replication when this count reaches the ratio between the two costs, as elaborated in <ref> [BFR92, ABF93] </ref>. The analysis of the randomized algorithm herein is sufficiently complicated so as to make these additional features of the model simply confusing. Thus, throughout this paper, we focus on the simplest possible setting (the basic memory management problem above). <p> Thus, throughout this paper, we focus on the simplest possible setting (the basic memory management problem above). These restrictions are easily removed using the techniques used for the deterministic distributd paging algorithm in <ref> [BFR92] </ref>. 6 3 A Lower Bound The lower bound is stated in the general setting of the distributed paging on an arbitrary network topology. We show that this problem is strongly related to the k-server problem ([MMS88]). <p> for all i's we obtain: E t (N H (t e )) = O (nh log (m f) + N ON (t e ) + A (t e )): It now follows from Section 5.2 that the proof of Theorem 4.1 is complete. 6 Open Problems Bartal, Fiat and Rabani <ref> [BFR92] </ref> conjectured that the distributed paging problem has a deterministic competitive ratio of O (m) and the randomized (oblivious) competitive ratio O (log m) on arbitrary topologies. In this paper we prove an O (log m) randomized competitive ratio for the distributed paging problem on the uniform network.
Reference: [BIRS91] <author> Alan Borodin, Sandy Irani, Prabhakar Raghavan, and Baruch Schieber. </author> <title> Com--petitive paging with locality of reference. </title> <booktitle> In Proc.of the 23rd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 249-259, </pages> <month> may </month> <year> 1991. </year>
Reference-contexts: The local paging algorithm could be efficient competitive deterministic or randomized paging algorithms ([ST85, FKL + 91]), or other algorithms such as those based upon limiting the request sequences to reflect the locality of reference <ref> [BIRS91, IKP92] </ref>. We allow the local strategy to be any strategy. The focus of our paper is designing the randomized global memory management algorithm. The goal of global strategy is to capture the new constraints of the "distributed" environment, and to coordinate operations of different processors. <p> In fact, our results hold even if one wishes to use other possible variants of the competitive ratio, such as allowing requests made in a single processor only if they are adjacent in some locality of reference graph as defined in <ref> [BIRS91] </ref>. Thus, we really give a family of algorithms, that deal with a variety of definitions of the competitive ratio.
Reference: [CKP + 93] <author> David Culler, Richard Karp, David Patterson, Abhijit Sahay, Klaus Erik Schauser, Eunice Santos, Ramesh Subramonian, and Thorsten von Eiken. </author> <title> LogP: Towards a realistic model of parallel computation. </title> <booktitle> In Proc. of Fourth ACM SIGPLAN Symp. on PPOPP, </booktitle> <pages> pages 1-12, </pages> <address> San Diego, </address> <year> 1993. </year>
Reference-contexts: Uniform cost metric. For the purpose of performance evaluation, we are only distinguishing between local and remote (over-the-network) data accesses, in effect assuming "flat" 2 non-single file J to make place for the replicated file, F . communication cost between any pair of processors, as in LogP model <ref> [CKP + 93] </ref>. This assumption indicates that the communication bottleneck is in transmitting and processing the message rather than in delivering it thru the network. In other words, there is plenty of network bandwidth, but not enough processing power; this assumption is considered reasonable in existing multiprocessors [CKP + 93]. <p> in LogP model <ref> [CKP + 93] </ref>. This assumption indicates that the communication bottleneck is in transmitting and processing the message rather than in delivering it thru the network. In other words, there is plenty of network bandwidth, but not enough processing power; this assumption is considered reasonable in existing multiprocessors [CKP + 93]. Thus, the goal of the distributed paging algorithm is to minimize number of remote network accesses in the presence of dynamic and unpredictable access pattern. Uniform efficiency on all inputs.
Reference: [FKL + 91] <author> Amos Fiat, Richard Karp, Mike Luby, McGeoch, Daniel Sleator, and Young. </author> <title> Competitive paging algorithms. </title> <journal> J. of Algorithms, </journal> <volume> 12(4) </volume> <pages> 685-699, </pages> <year> 1991. </year>
Reference-contexts: In this case the problem is reduced to the problem of achieving efficient uni-processor paging algorithm, for which efficient solutions have been proposed <ref> [ST85, KMRS88, MS88, FKL + 91] </ref>. In contrast, we are dealing here with a completely homogeneous environment with distributed file service, where we do not distinguish between clients and servers, and the space sharing between clients is allowed. <p> Proof. The corollary follows from Theorem 3.1 using ` = n 1 if f m n + 1 and ` = m + 1 f otherwise. The (log k) lower bound follows from a lower bound of <ref> [FKL + 91] </ref> for uni-processor paging. It also follows from the result of [FKL + 91] that S (U ; m + 1 f ) = (log (m f )). <p> The corollary follows from Theorem 3.1 using ` = n 1 if f m n + 1 and ` = m + 1 f otherwise. The (log k) lower bound follows from a lower bound of <ref> [FKL + 91] </ref> for uni-processor paging. It also follows from the result of [FKL + 91] that S (U ; m + 1 f ) = (log (m f )). <p> The main theorem we prove is the following: Theorem 4.1 Algorithm Heat & Dump is O (maxflog (m f ); cg)-competitive against oblivious adversaries, where c is the maximal competitive ratio for any of the local paging algorithms in the network. In particular by using local paging algorithms of <ref> [MS88, FKL + 91] </ref> in all processors we get: Corollary 4.2 Algorithm Heat & Dump is O (maxflog (m f ); log kg)-competitive against oblivious adversaries. 5 Competitive Analysis of | Heat & Dump This section gives the proof that Heat & Dump is O (maxflog (m f ); cg) competitive.
Reference: [HALH91] <author> E. Hagersten, Par Andersson, Anders Landin, and Seif Haridi. </author> <title> Performance study of the DDM a cache-only memory architecture. </title> <type> Technical Report R91:17, </type> <institution> Swedish Institute of Computer Science, </institution> <year> 1991. </year>
Reference-contexts: The file server is thus replaced by the "aggregate cache", i.e. the conjunction of the local caches. In the context of parallel multiprocessors, this setting is referred to as Cache-Only Memory Architecture (COMA) <ref> [HALH91] </ref>, and it has has been employed in a number of recently developed parallel machines such as the Data Diffusion Machine [HALH91] and in the new KSR1 machine [Bel92], where it is referred to as AllCache Engine. <p> In the context of parallel multiprocessors, this setting is referred to as Cache-Only Memory Architecture (COMA) <ref> [HALH91] </ref>, and it has has been employed in a number of recently developed parallel machines such as the Data Diffusion Machine [HALH91] and in the new KSR1 machine [Bel92], where it is referred to as AllCache Engine. This setting also corresponds to that of a homogeneous distributed file server, comprised of a collection of disk-less workstations. Previous results. Some systems work in a related setting has been reported in [LH86].
Reference: [IKP92] <author> Sandy Irani, Anna Karlin, and Steven Phillips. </author> <title> Strongly competitive algorithms for paging with locality of reference. </title> <booktitle> In Proc. 3rd ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <month> January </month> <year> 1992. </year>
Reference-contexts: The local paging algorithm could be efficient competitive deterministic or randomized paging algorithms ([ST85, FKL + 91]), or other algorithms such as those based upon limiting the request sequences to reflect the locality of reference <ref> [BIRS91, IKP92] </ref>. We allow the local strategy to be any strategy. The focus of our paper is designing the randomized global memory management algorithm. The goal of global strategy is to capture the new constraints of the "distributed" environment, and to coordinate operations of different processors.
Reference: [KELS62] <author> T.Kilburn, D.Edwards, M.Lanigan, and F.Summer. </author> <title> One-level storage system. </title> <journal> IRE Transactions on Electronic Computers, </journal> <volume> 2 </volume> <pages> 223-235, </pages> <year> 1962. </year>
Reference-contexts: 1 Introduction The basic paradigm: Distributed Virtual Memory. Virtual addressing has the advantage that the physical address is separate from the logical address <ref> [KELS62] </ref>. Briefly, the name of a memory item is decoupled from its physical location in memory; moreover, physical location may dynamically change in the run-time.
Reference: [KMRS88] <author> Anna Karlin, Mark Manasse, Larry Rudolpoh, and Daniel Sleator. </author> <title> Competitive snoopy caching. </title> <journal> Algorithmica, </journal> <volume> 3(1) </volume> <pages> 79-119, </pages> <year> 1988. </year>
Reference-contexts: In this case the problem is reduced to the problem of achieving efficient uni-processor paging algorithm, for which efficient solutions have been proposed <ref> [ST85, KMRS88, MS88, FKL + 91] </ref>. In contrast, we are dealing here with a completely homogeneous environment with distributed file service, where we do not distinguish between clients and servers, and the space sharing between clients is allowed.
Reference: [LH86] <author> Kai Li and Paul Hudak. </author> <title> Memory coherence in shared virtual memory systems. </title> <booktitle> In Proceedings of 5th PODC, </booktitle> <pages> pages 229-239, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: This setting also corresponds to that of a homogeneous distributed file server, comprised of a collection of disk-less workstations. Previous results. Some systems work in a related setting has been reported in <ref> [LH86] </ref>. In theory community, this problem was first tackled in [BFR92] who give on-line algorithms with competitive factors that grow linearly with the memory capacity of the network. <p> The question of a randomized competitive ratio for this problem was left as an open problem in [BFR92]. This problem has been studied in the systems community; see for example <ref> [LH86] </ref>. [BFR92] defined this problem in the competitive framework (the constrained file allocation problem), and give optimal deterministic on-line algorithms for the uniform network with competitive factors that grow linearly with the memory capacity of the network.
Reference: [LLG + 90] <author> L. Lenoski, J. Laundo, K. Gharachorloo, A. Gupta, and J.Hennessy. </author> <title> The directory-based cache coherence protocol for the dash multiprocessor. </title> <booktitle> In Proc. of 17th Intern. Symp. on Computer Architecture, </booktitle> <pages> pages 148-159, </pages> <year> 1990. </year>
Reference-contexts: In other words, the programmer can use the convenient Parallel Random Access Machine (PRAM) abstraction to write the program, which will be then compiled automatically to run on message-passing network-based distributed memory machines. We consider the problem of distributed paging in a distributed-memory multi-processor <ref> [LLG + 90] </ref> (or a distributed file server [YR91]) configured on a message-passing network. Our goal is to design data management algorithms that exploit the locality of reference of the underlying program by replicating data at the locations where they are frequently requested, thus minimizing the number of network accesses.
Reference: [MMS88] <author> M.S. Manasse, L.A. McGeoch, and D.D. Sleator. </author> <title> Competitive Algorithms for OnLine Problems. </title> <booktitle> In Proc. of the 20th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 322-333, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: In fact we give a lower bound for the distributed paging problem in an arbitrary metric space that strongly connects between this problem and the k-server 4 problem <ref> [MMS88] </ref>. Our approach. The basic idea of the algorithm is to capture locality of the underlying distributed program by migrating and replicating files in a way that brings "most" of the files into the locations where they are "frequently" and "recently" requested.
Reference: [MS88] <author> L.A. McGeoch and D.D. Sleator. </author> <title> A Strongly Competitive Randomized Paging Algorithm. </title> <note> Submitted to Algorithmica. </note>
Reference-contexts: In this case the problem is reduced to the problem of achieving efficient uni-processor paging algorithm, for which efficient solutions have been proposed <ref> [ST85, KMRS88, MS88, FKL + 91] </ref>. In contrast, we are dealing here with a completely homogeneous environment with distributed file service, where we do not distinguish between clients and servers, and the space sharing between clients is allowed. <p> The main theorem we prove is the following: Theorem 4.1 Algorithm Heat & Dump is O (maxflog (m f ); cg)-competitive against oblivious adversaries, where c is the maximal competitive ratio for any of the local paging algorithms in the network. In particular by using local paging algorithms of <ref> [MS88, FKL + 91] </ref> in all processors we get: Corollary 4.2 Algorithm Heat & Dump is O (maxflog (m f ); log kg)-competitive against oblivious adversaries. 5 Competitive Analysis of | Heat & Dump This section gives the proof that Heat & Dump is O (maxflog (m f ); cg) competitive.
Reference: [ST85] <author> Sleator and Tarjan. </author> <title> Amortized efficiency of list update and paging rules. </title> <journal> Communication of the ACM, </journal> <volume> 28(2) </volume> <pages> 202-208, </pages> <year> 1985. </year>
Reference-contexts: In this case the problem is reduced to the problem of achieving efficient uni-processor paging algorithm, for which efficient solutions have been proposed <ref> [ST85, KMRS88, MS88, FKL + 91] </ref>. In contrast, we are dealing here with a completely homogeneous environment with distributed file service, where we do not distinguish between clients and servers, and the space sharing between clients is allowed. <p> Performance evaluation: the competitive framework. On any given input sequence, the competitiveness of the on-line algorithm is the ratio of the incurred cost with the cost expended by optimal off-line algorithm <ref> [ST85] </ref>. A competitive ratio of an algorithm is the worst-case such ratio, maximized over all input instances.
Reference: [YR91] <author> Wang Yongdong and Lawrence A. Rowe. </author> <title> Cache Consistency and Concurrency Control in a Client/Server DBMS Architecture. </title> <address> Clifford91, </address> <year> 1991. </year> <month> 29 </month>
Reference-contexts: We consider the problem of distributed paging in a distributed-memory multi-processor [LLG + 90] (or a distributed file server <ref> [YR91] </ref>) configured on a message-passing network. Our goal is to design data management algorithms that exploit the locality of reference of the underlying program by replicating data at the locations where they are frequently requested, thus minimizing the number of network accesses.
References-found: 17

