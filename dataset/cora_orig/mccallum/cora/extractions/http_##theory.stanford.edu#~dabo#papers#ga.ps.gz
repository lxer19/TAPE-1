URL: http://theory.stanford.edu/~dabo/papers/ga.ps.gz
Refering-URL: http://theory.stanford.edu/~dabo/publications.html
Root-URL: 
Email: eric@research.nj.nec.com dabo@cs.princeton.edu garrett@research.nj.nec.com  
Title: Where Genetic Algorithms Excel  
Author: Eric B. Baum Dan Boneh Charles Garrett 
Address: 4 Independence Way Princeton, NJ 08540  
Affiliation: NEC Research Institute  
Abstract: We analyze the performance of a Genetic Algorithm (GA) we call Culling and a variety of other algorithms on a problem we refer to as Additive Search Problem (ASP). ASP is closely related to several previously well studied problems, such as the game of Mastermind and additive fitness functions. We show that the problem of learning the Ising perceptron is reducible to a noisy version of ASP. Culling is efficient on ASP, highly noise tolerant, and the best known approach in some regimes. Noisy ASP is the first problem we are aware of where a Genetic Type Algorithm bests all known competitors. Standard GA's, by contrast, perform much more poorly on ASP than hillclimbing and other approaches even though the Schema theorem holds for ASP. We generalize ASP to k-ASP to study whether GA's will achieve `implicit parallelism' in a problem with many more schemata. GA's fail to achieve this implicit parallelism, but we describe an algorithm we call Explicitly Parallel Search that succeeds. We also compute the optimal culling point for selective breeding, which turns out to be independent of the fitness function or the population distribution. We also analyze a Mean Field Theoretic algorithm performing similarly to Culling on many problems. These results provide insight into when and how GA's can beat competing methods. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Alon, J. H. Spencer: </author> <title> The probabilistic Method. </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> (1992). </year> <month> 28 </month>
Reference-contexts: We obtain Pr [ A] N 1 Pr [ t Z 1 t + log N ] = N Pr [Y t + log N j Y t ] 2N The last inequality follows using the Hoeffding type bound stated in Theorem A.11 of <ref> [1, p. 237] </ref>, the assumption that 2 1 4 Np t (1 p t ) and the fact that Pr [Y t ] &gt; 1=4 which follows from the same result used in footnote 10. <p> The above lemma shows that X 1;i ; X 2;i ; : : : ; X t;i forms a submartingale and provides a bound on the gain between the different generations. We wish to prove a large deviation bound for this submartingale. This can be achieved using Azuma's inequality <ref> [1, p. 85] </ref>. However, since Azmua's bound holds for any martingale, the resulting bound is too weak. Thus, we need to prove an Azuma type inequality for our special submartingale. <p> The method by which s is chosen guarantees that j f j 1. Let A be the event that the random string s is chosen as the new CFS, then Pr [A] = Pr [ f = 1] Pr <ref> [ e &gt; 1] </ref> + Pr [ f = 0] Pr [ e &gt; 0] + Pr [ f = 1] Pr [ e &gt; 1] N f (x) Pr [ e &gt; 1] + N L f (x) Pr [ e &gt; 1] The expected gain in true fitness of <p> Let A be the event that the random string s is chosen as the new CFS, then Pr [A] = Pr [ f = 1] Pr <ref> [ e &gt; 1] </ref> + Pr [ f = 0] Pr [ e &gt; 0] + Pr [ f = 1] Pr [ e &gt; 1] N f (x) Pr [ e &gt; 1] + N L f (x) Pr [ e &gt; 1] The expected gain in true fitness of the new current favorite string is given by E [ f j A] = Pr [A] = Pr [A] N f (x) <p> the random string s is chosen as the new CFS, then Pr [A] = Pr [ f = 1] Pr <ref> [ e &gt; 1] </ref> + Pr [ f = 0] Pr [ e &gt; 0] + Pr [ f = 1] Pr [ e &gt; 1] N f (x) Pr [ e &gt; 1] + N L f (x) Pr [ e &gt; 1] The expected gain in true fitness of the new current favorite string is given by E [ f j A] = Pr [A] = Pr [A] N f (x) Pr [e s &gt; e c 1] + <p> then Pr [A] = Pr [ f = 1] Pr <ref> [ e &gt; 1] </ref> + Pr [ f = 0] Pr [ e &gt; 0] + Pr [ f = 1] Pr [ e &gt; 1] N f (x) Pr [ e &gt; 1] + N L f (x) Pr [ e &gt; 1] The expected gain in true fitness of the new current favorite string is given by E [ f j A] = Pr [A] = Pr [A] N f (x) Pr [e s &gt; e c 1] + N 11 There are two roughly equivalent versions of this
Reference: [2] <author> T. Back, H-P Schwefel, </author> <title> "An overview of evolutionary algorithms for parameter optimization", </title> <note> Evolutionary Computation 1(1) pp 1-23, </note> <year> (1993). </year>
Reference-contexts: We thank an anonymous COLT referee for calling our attention to <ref> [2] </ref> and references therein. 3 In x3.1 we calculate the optimal culling threshold, that is at which point one should cull to achieve the maximum gain in fitness per oracle query, i.e. `birth'. The result is that one should in fact cull all descendants of less than mean fitness. <p> Aside from application to `Genetic Algorithms' on computers, this result may interest those engaged in animal husbandry and horticulture. This result distinguishes culling from other Evolution Strategies, or truncation selection, where the optimal procedure is distribution dependent. For a recent review of the Evolution Strategies literature see <ref> [2] </ref>. Rechenberg [21] calculated convergence rates on some simple problems for a Culling-like algorithm with a population size of one, and proposed heuristics based on these results.
Reference: [3] <author> E. B. Baum. </author> <title> "On genetic algorithms", NEC Internal Report June 1994. </title>
Reference-contexts: These can lead to rather different outcomes. It is not obvious which would be better in practice, but culling can sometimes be easier to analyze, and seems to be easier to optimize, which may give it an edge. 3 Culling was discovered by one of us <ref> [3] </ref> in ignorance of this literature. We thank an anonymous COLT referee for calling our attention to [2] and references therein. 3 In x3.1 we calculate the optimal culling threshold, that is at which point one should cull to achieve the maximum gain in fitness per oracle query, i.e. `birth'.
Reference: [4] <author> E. B. Baum, D. Boneh, C. Garrett, </author> <booktitle> "On Genetic Algorithms", COLT '95: Proceedings of the Eighth Annual Conference on Computational Learning Theory, Association for Computing Machinery, </booktitle> <address> New York, </address> <note> (1995) pp 230-239. </note>
Reference-contexts: the performance of several algorithms on it. x5 analyzes the performance of Culling. x6 discusses the noisy ASP problem. x7 discusses two generalizations of ASP. x8 discusses an alternative method for solving ASP that we refer to as the Mean Field Approximation 4 Indeed our original intuition (reflected in reference <ref> [4] </ref>) was that one should cull all descendants less fit than a standard deviation above the mean. 4 (MFA) Algorithm. x9 reduces the problem of learning the Ising Perceptron problem to an ASP problem. x10 is a conclusion.
Reference: [5] <author> E. B. Baum, Y. Lyuu, </author> <title> "The Transition to Perfect Generalization in Perceptrons", </title> <booktitle> Neural computation 3, </booktitle> <pages> pp. 386-401. </pages>
Reference-contexts: The robustness of our genetic algorithm allows us to extend our results to in various directions. The problem of learning a half space with integer weights from examples drawn from a uniform distribution has been studied in <ref> [28, 29, 9, 5] </ref>. We show that this problem can be directly mapped into a noisy ASP problem, yielding some solution techniques. Alternatively consider the problem a "Classifier System"[12] faces in learning from interaction with a complex environment. <p> However the MFA algorithm, because it is oblivious, can be defeated by problems with less symmetry that the GA can solve. 9 Learning Half Spaces with integer weights In this section we consider the "Ising Perceptron Problem", aka the problem of learning half spaces of integer weight <ref> [28, 29, 9, 5] </ref>. Let t 2 f1; 1g N be an N-dimensional vector and let H t be the halfspace (x; t) 0.
Reference: [6] <author> V. Chvatal, "MasterMind", </author> <booktitle> Combinatorica 3 (1983), </booktitle> <pages> pp. 325-329. </pages>
Reference-contexts: Each time it is queried, the Oracle returns a number from 0 to N, the fitness. Thus the oracle returns at most log (N ) bits of information. Hence, any algorithm solving this problem must make at least N logL=logN queries. Chvatal <ref> [6] </ref> shows that with high probability a set of O (N log L= log N ) random queries will completely constrain the solution. This shows that the lower bound is tight, however it does not provide a polynomial time algorithm to find the target.
Reference: [7] <author> P. Deheuvels, M. Puri, S. Ralescu, </author> <title> "Asymptotic Expansions for Sums of Nonidentically Distributed Bernoulli Random Variables", </title> <journal> J. of Multivariate Analysis, </journal> <volume> Vol. 28, </volume> <pages> pp. 282-303, </pages> <year> 1989. </year>
Reference-contexts: Theorem 1.1 of <ref> [7] </ref> shows that since N 3=4 &lt; p t;i &lt; 1 N 3=4 (the population size is less than N 3=4 ) it follows that for large enough N Pr [Y t ] 1:1 (0) and Pr [Y t + 2 where (x) is the distribution function of a standard normal <p> This can be seen using the asymptotic behavior of sums of Bernoulli random variables (see e.g. <ref> [7] </ref>). <p> The second sum can readily be upper bounded by Pr [f (x) = ] P But by using the asymptotic approximation for sums of Bernoulli random variables by the normal distribution (see e.g. <ref> [7] </ref>) as we did before in Theorem 8, one can show that Pr [f (x) = ] &lt; 1=. Using E [e] = 0 one can readily show that P 2 2 e .
Reference: [8] <author> D. E. Goldberg: </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison Wesley, </publisher> <address> Reading MA, </address> <year> 1989. </year>
Reference-contexts: Let m (H ) denote the number of examples of H in P and m 0 (H ) denote the 5 The results of this section are due to [13]. A simple, clear presentation may be found in <ref> [8] </ref>, chapter 2. 5 expected number of examples of H in P 0 . Then one can readily see: m 0 (H) m (H ) ffi (H ) o H p m ] This is Holland's schema theorem.
Reference: [9] <author> D. Haussler, M. Kearns, S. Seung, N Tishby, </author> <title> "Rigorous Learning Curve Bounds from Statistical Mechanics", </title> <booktitle> Proceedings of COLT 1994, </booktitle> <pages> pp. 76-85. </pages>
Reference-contexts: The robustness of our genetic algorithm allows us to extend our results to in various directions. The problem of learning a half space with integer weights from examples drawn from a uniform distribution has been studied in <ref> [28, 29, 9, 5] </ref>. We show that this problem can be directly mapped into a noisy ASP problem, yielding some solution techniques. Alternatively consider the problem a "Classifier System"[12] faces in learning from interaction with a complex environment. <p> However the MFA algorithm, because it is oblivious, can be defeated by problems with less symmetry that the GA can solve. 9 Learning Half Spaces with integer weights In this section we consider the "Ising Perceptron Problem", aka the problem of learning half spaces of integer weight <ref> [28, 29, 9, 5] </ref>. Let t 2 f1; 1g N be an N-dimensional vector and let H t be the halfspace (x; t) 0. <p> The samples were chosen uniformly and independently in the unit ball. A result of <ref> [9] </ref> shows that 1:44N random samples suffice to uniquely determine t. Although t is uniquely determined, it is of course NP-hard in general to find a Boolean hyperplane consistent with a set of examples. [29] gave an algorithm that efficiently determined t using O (N log N ) random examples.
Reference: [10] <author> D. Hillis: </author> <title> "Co-evolving parasites improve simulated evolution as an optimization procedure." </title> <journal> Physica D 42 (1990) 228-234. </journal>
Reference-contexts: Appendix A comments briefly on the relationship of ASP to the Royal Road function of Mitchell et al. [17] and comments on their results. Appendix B is independent of the rest of the paper. It comments on the "Coevolving Parasites" mechanism of Hillis <ref> [10] </ref>. 2 Holland's Schema Theorem In this section we present the standard genetic algorithm approach and recall the original motivation for studying it 5 . Let A = fa 1 ; a 2 ; :::; a L g be an alphabet of size L.
Reference: [11] <author> W. Hoeffding: </author> <title> Probability inequalities for sums of bounded variables. </title> <journal> J. American Statistical Association, </journal> <volume> 58 </volume> <pages> 13-30, </pages> <year> 1963. </year>
Reference-contexts: Formally, we use Hoeffding's inequality to show that it is unlikely that t+1 is less than t + =40. Hoeffding's inequality <ref> [11] </ref> states that if Z 1 ; : : : ; Z r are independent and identically distributed random variables with B 1 Z i B 2 then for any &gt; 0 Pr 1 r X Z i &lt; E [Z 1 ] exp 2 2 r=(B 2 B 1 )
Reference: [12] <author> J. H. Holland: </author> <title> "Properties of the bucket brigade algorithm". </title> <booktitle> In Proceedings of the first international conference on genetic algorithms and their applications, </booktitle> <pages> pp 1-7, </pages> <publisher> Lawrence Erlbaum Associates (1985). </publisher>
Reference: [13] <author> J. H. Holland: </author> <title> Adaptation in natural and artificial systems, </title> <publisher> MIT Press, </publisher> <address> Cambridge MA, </address> <year> (1975). </year>
Reference-contexts: Let m (H ) denote the number of examples of H in P and m 0 (H ) denote the 5 The results of this section are due to <ref> [13] </ref>. A simple, clear presentation may be found in [8], chapter 2. 5 expected number of examples of H in P 0 . Then one can readily see: m 0 (H) m (H ) ffi (H ) o H p m ] This is Holland's schema theorem.
Reference: [14] <author> M. Kimura, J. Crow, </author> <title> Effect of overall phenotypic selection on genetic change at individual loci, </title> <journal> Proc. Natl. Acad. of Sci., USA, </journal> <volume> Vol. 75, No. 12, </volume> <pages> pp. 6168-6171, </pages> <month> December </month> <year> 1978. </year>
Reference-contexts: Schwefel [26] gave an expression for expected progress rate of related algorithms, but without recombination (crossover), and studied as well proposals for dynamically changing mutation rates. Kimura and Crow <ref> [14, 15] </ref> also studied truncation selection. In [15] they compare truncation selection to more gradual methods of selection. Their work is largely orthogonal to ours. They study an individual loci in a diploid model with no consideration of population size.
Reference: [15] <author> M. Kimura, J. Crow, </author> <title> Efficiency of truncation selection, </title> <journal> Proc. Natl. Acad. of Sci., USA, </journal> <volume> Vol. 76, No. 1, </volume> <pages> pp. 396-399, </pages> <month> January, </month> <year> 1979. </year>
Reference-contexts: Schwefel [26] gave an expression for expected progress rate of related algorithms, but without recombination (crossover), and studied as well proposals for dynamically changing mutation rates. Kimura and Crow <ref> [14, 15] </ref> also studied truncation selection. In [15] they compare truncation selection to more gradual methods of selection. Their work is largely orthogonal to ours. They study an individual loci in a diploid model with no consideration of population size. <p> Schwefel [26] gave an expression for expected progress rate of related algorithms, but without recombination (crossover), and studied as well proposals for dynamically changing mutation rates. Kimura and Crow [14, 15] also studied truncation selection. In <ref> [15] </ref> they compare truncation selection to more gradual methods of selection. Their work is largely orthogonal to ours. They study an individual loci in a diploid model with no consideration of population size. Muhlenbein and Schlierkamp-Voosen [18] have previously showed results similar to those we describe in x 3.
Reference: [16] <author> S-K Ma: </author> <title> Modern Theory of Critical Phenomena,W. A Benjamin, </title> <address> Reading MA 1976. </address>
Reference-contexts: The algorithm can easily be adapted to solve the k-ASP problem as well (with L k slowdown). We refer to this algorithm as the Mean Field Approximation or MFA since it is reminiscent of this approximation in physics <ref> [16, Ch. 7] </ref>. As before, the noisy fitness value will be denoted by ~ f (x) = f (x) + e (x), where f (x) is the true fitness, and e (x) the noise. For simplicity we assume the noise has expectation 0. Algorithm (MFA): 1.
Reference: [17] <author> M. Mitchell, J. H. Holland, S. </author> <title> Forrest : When will a genetic algorithm outperform hillclimbing. </title> <booktitle> in Advances in Neural Information Processing Systems 6, </booktitle> <editor> eds. J. D. Cowan, G. Tesauro, and J. Alspector, </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo CA, </address> <note> (1994) pp 51-58. </note>
Reference-contexts: The objective is to find t with as few queries as possible. For simplicity, we always assume N &gt; L. ASP is related to the "Royal Road Function" of <ref> [17] </ref> (c.f. our Appendix A). fl This paper is an expanded version of "On Genetic Algorithms"[4] that appeared in COLT'95 copyright 1995 by ACM Inc. We have now calculated the optimal culling point and rewritten the analysis from this point of view. <p> Our results clarify this issue. Standard genetic algorithms differ from our proposal in that they select `parents' with probability proportional to their fitness rather than culling offspring less fit than a threshold. They perform badly 1 C.f. <ref> [17] </ref> for a survey of the literature. 2 Another naive appeal of GA's is the analogy to biological evolution. We discount this. <p> Appendix A comments briefly on the relationship of ASP to the Royal Road function of Mitchell et al. <ref> [17] </ref> and comments on their results. Appendix B is independent of the rest of the paper. It comments on the "Coevolving Parasites" mechanism of Hillis [10]. 2 Holland's Schema Theorem In this section we present the standard genetic algorithm approach and recall the original motivation for studying it 5 . <p> Consider the Random Mutation Hill Climbing (RMHC) procedure <ref> [17] </ref>: 1. Query on a random string, called "CFS" (Current Favorite String). 2. Change a random site in CFS and query. 3. If mutated string is as good or better than CFS, then set CFS to this string. 4. If not yet optimal string, go to (2).
Reference: [18] <author> H. Muhlenbein and D. Schlierkamp-Voosen: </author> <title> Predictive models for the breeder genetic algorithm I Continuous parameter optimization, </title> <booktitle> Evolutionary Computation 1, </booktitle> <pages> pp 25-50 1993. </pages>
Reference-contexts: Kimura and Crow [14, 15] also studied truncation selection. In [15] they compare truncation selection to more gradual methods of selection. Their work is largely orthogonal to ours. They study an individual loci in a diploid model with no consideration of population size. Muhlenbein and Schlierkamp-Voosen <ref> [18] </ref> have previously showed results similar to those we describe in x 3. <p> For a similar result (described above in the introduction) regarding truncation selection, see also <ref> [18] </ref>. Let P be the current population and let f (i) denote the fitness of the ith string in the population. We denote by Pr [f (i) = x] the fraction of strings in P with fitness x.
Reference: [19] <author> Y. Rabinovich: </author> <title> Quadratic dynamical systems and theoretical aspects of genetic algorithm, </title> <type> Ph.D. Thesis, </type> <institution> Hebrew university of Jerusalem, </institution> <year> 1993. </year> <month> 29 </month>
Reference-contexts: They showed that for the ONEMAX fitness function (equivalent to ASP with L 2) truncation selection leads to an expected gain per generation of O ( p N), and thus leads to faster convergence than standard genetic algorithms. Standard genetic algorithms were first rigorously analyzed in <ref> [19, 23] </ref>. These authors view GA's as quadratic dynamical systems. The GA's we analyze use multiway breeding and hence can't be modeled as a QDS. In summary we have studied the behavior of a variety of algorithms on some natural search problems. <p> Rigorous arguments require complex analysis of fluctuations. We will engage in these in analyzing the culling approach, but will argue intuitively here regarding the standard GA. A full analysis (using different techniques) of the performance of this algorithm on a problem similar to ASP can be found in <ref> [19] </ref>. Since (by the argument sketched in x3) the expected gain in average fitness, N p t , per generation is of order 1, the standard GA requires T = (N ) generations to solve ASP.
Reference: [20] <author> I. Rechenberg: </author> <title> "Cybernetic solution path of an experimental problem", </title> <journal> ROy. Aircr. Establ., libr. transl. </journal> <volume> 1122. </volume> <publisher> Hants, </publisher> <address> UK.: </address> <month> Farnborough </month> <year> (1965) </year>
Reference: [21] <author> I. Rechenberg: </author> <title> "Evolutionsstrategie: Optimierung technischer Systeme nach Prinzipien der biol-ogischen Evolution", </title> <publisher> Stuttgart: </publisher> <month> Frommann-Holzboog </month> <year> (1973). </year>
Reference-contexts: Aside from application to `Genetic Algorithms' on computers, this result may interest those engaged in animal husbandry and horticulture. This result distinguishes culling from other Evolution Strategies, or truncation selection, where the optimal procedure is distribution dependent. For a recent review of the Evolution Strategies literature see [2]. Rechenberg <ref> [21] </ref> calculated convergence rates on some simple problems for a Culling-like algorithm with a population size of one, and proposed heuristics based on these results.
Reference: [22] <author> A. Renyi: </author> <booktitle> Collected works, </booktitle> <pages> pp. 633-638. </pages>
Reference-contexts: We will assume symmetry of the noise as necessary for convenience of the analysis, discussing it when we assume it. The EPS algorithm described in Section 4 can be made to work in the presence of noise using a result of Renyi <ref> [22] </ref>. Renyi shows how to perform binary search using an unreliable oracle. However, the performance of the algorithm degrades proportionally to the noise deviation. 6.1 RMHC and Noise In this subsection we we will see that the RMHC algorithm considered in Section 4.1 performs poorly in the presence of noise.
Reference: [23] <author> Y. Rabinovich, A. Sinclair, A. Wigderson: </author> <title> Quadratic dynamical systems, </title> <booktitle> Proceedings of the 33rd IEEE FOCS (1992), </booktitle> <pages> pp. 304-313. </pages>
Reference-contexts: They showed that for the ONEMAX fitness function (equivalent to ASP with L 2) truncation selection leads to an expected gain per generation of O ( p N), and thus leads to faster convergence than standard genetic algorithms. Standard genetic algorithms were first rigorously analyzed in <ref> [19, 23] </ref>. These authors view GA's as quadratic dynamical systems. The GA's we analyze use multiway breeding and hence can't be modeled as a QDS. In summary we have studied the behavior of a variety of algorithms on some natural search problems.
Reference: [24] <author> J. P. Ros: </author> <title> Learning Boolean functions with genetic algorithms: a PAC analysis, Foundations of Genetic Algorithms 2, </title> <editor> ed. L. Darrell Whitley, </editor> <month> pp257-275 </month> <year> (1993). </year>
Reference-contexts: Ties are broken arbitrarily. 10 5. Set t := t+1 and let be the new average fitness of strings in P . Set M = maxf4N t ; N g log 2 N and go to step 3. The breeding strategy we refer to as M -way breeding <ref> [24, 27] </ref> is the following: For all k, the k'th component of the child string is chosen by picking a string uniformly at random from P and using it's k'th component 9 . Thus, all strings in the population have a chance of contributing to the child.
Reference: [25] <author> C. E. </author> <title> Shannon (1951) Prediction and entropy of printed English, </title> <journal> Bell System Technical J. </journal> <volume> pp50-64, </volume> <month> January. </month>
Reference: [26] <author> H.-P. Schwefel. </author> <title> Numerical optimization of computer models. </title> <address> Chichester: </address> <publisher> Wiley. </publisher>
Reference-contexts: They do, however, perform worse in some less symmetric situations. Algorithms closely related to Culling 3 called "Evolution Strategies" have been proposed and studied by I. Rechenberg [20],[21] and H. P. Schwefel <ref> [26] </ref>. Evolution strategies use truncation selection. In truncation selection, one breeds only certain fraction of the best members of the population. In culling, one breeds only members better than a threshold. <p> For a recent review of the Evolution Strategies literature see [2]. Rechenberg [21] calculated convergence rates on some simple problems for a Culling-like algorithm with a population size of one, and proposed heuristics based on these results. Schwefel <ref> [26] </ref> gave an expression for expected progress rate of related algorithms, but without recombination (crossover), and studied as well proposals for dynamically changing mutation rates. Kimura and Crow [14, 15] also studied truncation selection. In [15] they compare truncation selection to more gradual methods of selection.
Reference: [27] <author> G. Syswerda: </author> <title> Simulated crossover in Genetic Algorithms, Foundations of Genetic Algorithms 2, </title> <editor> ed. L. Darrell Whitley, </editor> <month> pp239-255 </month> <year> (1993). </year>
Reference-contexts: Ties are broken arbitrarily. 10 5. Set t := t+1 and let be the new average fitness of strings in P . Set M = maxf4N t ; N g log 2 N and go to step 3. The breeding strategy we refer to as M -way breeding <ref> [24, 27] </ref> is the following: For all k, the k'th component of the child string is chosen by picking a string uniformly at random from P and using it's k'th component 9 . Thus, all strings in the population have a chance of contributing to the child.
Reference: [28] <author> S. Venkatesh: </author> <title> On learning binary weights for majority functions, </title> <booktitle> proceedings of COLT 1991. </booktitle>
Reference-contexts: The robustness of our genetic algorithm allows us to extend our results to in various directions. The problem of learning a half space with integer weights from examples drawn from a uniform distribution has been studied in <ref> [28, 29, 9, 5] </ref>. We show that this problem can be directly mapped into a noisy ASP problem, yielding some solution techniques. Alternatively consider the problem a "Classifier System"[12] faces in learning from interaction with a complex environment. <p> However the MFA algorithm, because it is oblivious, can be defeated by problems with less symmetry that the GA can solve. 9 Learning Half Spaces with integer weights In this section we consider the "Ising Perceptron Problem", aka the problem of learning half spaces of integer weight <ref> [28, 29, 9, 5] </ref>. Let t 2 f1; 1g N be an N-dimensional vector and let H t be the halfspace (x; t) 0.
Reference: [29] <author> S. Venkatesh: </author> <title> On the average tractability of binary integer programming and the curious transition to perfect generalization in learning majority functions, </title> <booktitle> Proceedings of COLT 1993, </booktitle> <pages> pp. 310-316. </pages>
Reference-contexts: The robustness of our genetic algorithm allows us to extend our results to in various directions. The problem of learning a half space with integer weights from examples drawn from a uniform distribution has been studied in <ref> [28, 29, 9, 5] </ref>. We show that this problem can be directly mapped into a noisy ASP problem, yielding some solution techniques. Alternatively consider the problem a "Classifier System"[12] faces in learning from interaction with a complex environment. <p> However the MFA algorithm, because it is oblivious, can be defeated by problems with less symmetry that the GA can solve. 9 Learning Half Spaces with integer weights In this section we consider the "Ising Perceptron Problem", aka the problem of learning half spaces of integer weight <ref> [28, 29, 9, 5] </ref>. Let t 2 f1; 1g N be an N-dimensional vector and let H t be the halfspace (x; t) 0. <p> The samples were chosen uniformly and independently in the unit ball. A result of [9] shows that 1:44N random samples suffice to uniquely determine t. Although t is uniquely determined, it is of course NP-hard in general to find a Boolean hyperplane consistent with a set of examples. <ref> [29] </ref> gave an algorithm that efficiently determined t using O (N log N ) random examples. We show that the Ising Perceptron problem can be reduced to a noisy ASP problem, and give some evidence that our GA can solve it using only O (N ) random examples.
References-found: 29

