URL: ftp://ftp.engr.orst.edu/pub/dambrosi/dx-92.ps.Z
Refering-URL: http://www.cs.orst.edu/~dambrosi/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Note: Abstract  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> M. Agosta. </author> <title> Conditional inter-causally interdependent node distributions ... In , pages 9-16. </title> <publisher> Morgan Kaufmann, Publishers, </publisher> <month> July </month> <year> 1991. </year>
Reference-contexts: However, a number of restricted interaction models have been identified which have lower space and time complexity than the full conditional. The noisy-or [21], [22], [13], [14], <ref> [1] </ref> for example, can be used to model independent causes of an event, and inference complexity is linear in both space and time in the number of antecedents for many inferences. Similarly, various asymmetric [25], [12] and logical relationships are inefficiently represented using a full conditional.
Reference: [2] <author> M. Boddy. </author> <title> Anytime problem solving using dynamic programming. In , pages 738-743. </title> <publisher> AAAI, </publisher> <month> July </month> <year> 1991. </year>
Reference-contexts: From another perspective, Horvitz have been developing bounded conditioning as an approach to anytime probabilistic inference [16], and Boddy has proposed an anytime approach to dynamic programming <ref> [2] </ref>.
Reference: [3] <author> G. Cooper. </author> <title> A method for using belief networks as influence diagrams. </title> <booktitle> In , pages 55-63. Association for Uncertainty in AI, </booktitle> <month> August </month> <year> 1988. </year>
Reference-contexts: Post the selected act as evidence in the belief net, prune unneeded old cycles from the net, and return selected action. The problem of computing the expected utility for action alternatives can be cast as a belief-net inference problem, as shown by Cooper <ref> [3] </ref>. However, most current belief net inference facilities provide poor support for the cycle described above.
Reference: [4] <author> B. D'Ambrosio. </author> <title> Process, structure, and modularity in reasoning under uncertainty. In , pages 64-72. </title> <publisher> AAAI, </publisher> <month> August </month> <year> 1988. </year>
Reference-contexts: Also, the services offered by current probabilistic reasoning systems are not well matched to the needs of higher-level problem solvers. As we discussed in <ref> [4] </ref> and [6], problem solvers typically interleave model construction, revision, and evaluation. As a specific example of this, consider the requirements posed by our formulation of the OLMA task: We must extend a model forward in time without discarding all previous inference and starting over.
Reference: [5] <author> B. D'Ambrosio. </author> <title> Symbolic probabilistic inference. </title> <type> Technical report, </type> <institution> CS Dept., Oregon State University, </institution> <year> 1989. </year>
Reference-contexts: When the graph is sparse, this will involve a much smaller set of numbers than the full joint. Equally important, the graphical structure can be used to guide processing to find efficient ways to evaluate queries against the model. For more details, see [21], <ref> [5] </ref>, [24], [19]. All is not as rosy at it might seem, though. The graphical level is not capable of representing all interesting structural information which might simplify representation or inference.
Reference: [6] <author> B. D'Ambrosio. </author> <title> Incremental evaluation and construction of defeasible probabilistic models. </title> , <month> July </month> <year> 1990. </year>
Reference-contexts: Also, the services offered by current probabilistic reasoning systems are not well matched to the needs of higher-level problem solvers. As we discussed in [4] and <ref> [6] </ref>, problem solvers typically interleave model construction, revision, and evaluation. As a specific example of this, consider the requirements posed by our formulation of the OLMA task: We must extend a model forward in time without discarding all previous inference and starting over.
Reference: [7] <author> B. D'Ambrosio. </author> <title> Term computation systems. </title> <type> Technical report, </type> <institution> CS dept., Oregon State University, </institution> <year> 1991. </year>
Reference-contexts: We have made this process incremental with respect to queries, evidence, and limited model reformulations (namely the extension and pruning operations needed to support the OLMA task). We omit discussion of these issues here due to lack of space. For a more complete discussion see <ref> [7] </ref>. We have sketched a process which is basically little more than heuristic search for the set of bindings across a set of variables that maximizes the posterior probability across those variables.
Reference: [8] <author> B. D'Ambrosio and T. Fountain. </author> <title> Reaction in real-time decision making. </title> <type> Technical report, </type> <institution> CS Dept, Oregon State University, </institution> <year> 1991. </year>
Reference-contexts: For further details of this architecture, see <ref> [8] </ref>. We are currently applying statistical techniques identify optimal single-level control policies for the OLMA domain. It is interesting that the search technique we present should work at all in a decision-making context.
Reference: [9] <author> B. D'Ambrosio and R. Shachter. </author> <title> Symbolic probabilistic inference. </title> <type> Technical report, </type> <institution> Oregon State Univ. CS dept., </institution> <year> 1992. </year>
Reference-contexts: However, simple, polynomial-time heuristics perform quite well, and are described in <ref> [9] </ref>, [19]. This previous work was performed in the context of exact query evaluation (that is, computation of all terms), but the theory remains applicable, and so will not be repeated in detail here. The process used in [19] is the basis for our current implementation.
Reference: [10] <author> J. de Kleer. </author> <title> Focusing on probable diagnoses. In , pages 842-848. </title> <publisher> AAAI, </publisher> <month> July </month> <year> 1991. </year>
Reference-contexts: We have sketched a process which is basically little more than heuristic search for the set of bindings across a set of variables that maximizes the posterior probability across those variables. In another context, deKleer has referred to this as the "Most Likely Composite Hypothesis" problem <ref> [10] </ref>, Henrion has described an algorithm for diagnosis in very large knowledge bases [15], and Pearl has discussed the problem of "Distributed Revision of Composite Beliefs" [20].
Reference: [11] <author> J. de Kleer and B. Williams. </author> <title> Diagnosis with behavioral modes. </title> <booktitle> In , pages 1324-1330. </booktitle> <address> IJ-CAI, </address> <month> August </month> <year> 1984. </year>
Reference-contexts: problem solver asks for refinement of the distribution for that node, and the root queries its immediate children for terms as needed. 10 7 7 2 n nlog n n log n n Term selection Term combination (marginalization) Complexity This selection criterion is similar to the techniques used by deKleer <ref> [11] </ref> and Henrion [15]. Both use search on restricted classes of networks for the diagnostic task of finding most likely composite hypotheses, with good results. One contribution of our work is to show how this technique can be used in a more general setting.
Reference: [12] <author> D. Geiger and D. Heckerman. </author> <booktitle> Advances in probabilistic reasoning. </booktitle> <pages> In , pages 118-126. </pages> <publisher> Morgan Kaufmann, Publishers, </publisher> <month> July </month> <year> 1991. </year>
Reference-contexts: The noisy-or [21], [22], [13], [14], [1] for example, can be used to model independent causes of an event, and inference complexity is linear in both space and time in the number of antecedents for many inferences. Similarly, various asymmetric [25], <ref> [12] </ref> and logical relationships are inefficiently represented using a full conditional. Finally, value models used in utility modeling are often factored, for example they may be additive. We have developed an algebraic extension to belief nets which permits conditional distributions to be defined as algebraic compositions of smaller distributions.
Reference: [13] <author> D. Heckerman, J. Breese, and E. Horvitz. </author> <title> The compilation of decision models. </title> <booktitle> In , pages 162-173, </booktitle> <month> August </month> <year> 1989. </year> <booktitle> 15 AAAI Workshop on the Principles of Diagnosis Proceedings of the Seventh Annual Conference on Uncertainty in Artificial Intelligence Proceedings of the Fifth Conference on Uncertainty in AI Journal of the Royal Statistical Society Proceedings of the Annual Canadian Artificial Intelligence Conference Artificial Intelligence Probabilistic Reasoning in Intelligent Systems IEEE Trans. on Systems, Man, and Cybernetics: special issue on diagnosis The Foundations of Statistics Proceedings Eighth National Conference on AI Sciences of the Artificial </booktitle>
Reference-contexts: The only mechanism available for describing antecedent interactions in typical general purpose belief net inference algorithms is the full conditional distribution across all antecedents. However, a number of restricted interaction models have been identified which have lower space and time complexity than the full conditional. The noisy-or [21], [22], <ref> [13] </ref>, [14], [1] for example, can be used to model independent causes of an event, and inference complexity is linear in both space and time in the number of antecedents for many inferences. Similarly, various asymmetric [25], [12] and logical relationships are inefficiently represented using a full conditional.
Reference: [14] <author> M. Henrion. </author> <title> Towards efficient probabilistic diagnosis with a very large knowledge-base. </title> <booktitle> In , 1990. </booktitle>
Reference-contexts: However, a number of restricted interaction models have been identified which have lower space and time complexity than the full conditional. The noisy-or [21], [22], [13], <ref> [14] </ref>, [1] for example, can be used to model independent causes of an event, and inference complexity is linear in both space and time in the number of antecedents for many inferences. Similarly, various asymmetric [25], [12] and logical relationships are inefficiently represented using a full conditional.
Reference: [15] <author> M. Henrion. </author> <title> Search-based methods to bound diagnostic probabilities in very large belief nets. In , pages 142-150. </title> <publisher> Morgan Kaufmann, Publishers, </publisher> <month> July </month> <year> 1991. </year>
Reference-contexts: One could construct a term computation system which merely enumerated elements of the full joint distribution across all variables in a network, as in our example. Indeed, existing proposals for anytime probabilistic inference essentially do this <ref> [15] </ref>, [16]. However, such an approach can be grossly inefficient. There are several sources for this inefficiency: First, there would be a time inefficiency due to unnecessary repetition of sub-computations (eg, the computation of ( ) ( ) in our example). <p> for refinement of the distribution for that node, and the root queries its immediate children for terms as needed. 10 7 7 2 n nlog n n log n n Term selection Term combination (marginalization) Complexity This selection criterion is similar to the techniques used by deKleer [11] and Henrion <ref> [15] </ref>. Both use search on restricted classes of networks for the diagnostic task of finding most likely composite hypotheses, with good results. One contribution of our work is to show how this technique can be used in a more general setting. <p> In another context, deKleer has referred to this as the "Most Likely Composite Hypothesis" problem [10], Henrion has described an algorithm for diagnosis in very large knowledge bases <ref> [15] </ref>, and Pearl has discussed the problem of "Distributed Revision of Composite Beliefs" [20]. From another perspective, Horvitz have been developing bounded conditioning as an approach to anytime probabilistic inference [16], and Boddy has proposed an anytime approach to dynamic programming [2].
Reference: [16] <author> E. Horvitz, H. J. Suermondt, and G. Cooper. </author> <title> Bounded conditioning: Flexible inference for decisions under scarce resources. </title> <note> In , August 1989. </note>
Reference-contexts: One could construct a term computation system which merely enumerated elements of the full joint distribution across all variables in a network, as in our example. Indeed, existing proposals for anytime probabilistic inference essentially do this [15], <ref> [16] </ref>. However, such an approach can be grossly inefficient. There are several sources for this inefficiency: First, there would be a time inefficiency due to unnecessary repetition of sub-computations (eg, the computation of ( ) ( ) in our example). <p> From another perspective, Horvitz have been developing bounded conditioning as an approach to anytime probabilistic inference <ref> [16] </ref>, and Boddy has proposed an anytime approach to dynamic programming [2].
Reference: [17] <author> S. Lauritzen and D. Spiegelhalter. </author> <title> Local computations with probabilities on graphical structures and their application to expert systems. , B 50, </title> <year> 1988. </year>
Reference-contexts: Despite the fact that current state-of-the-art algorithms exploit the independence information in a belief net to construct efficient computations for probabilistic inference [21], <ref> [17] </ref>, [24], in practice computational cost still grows rapidly [18], limiting application of these techniques to belief nets with a few hundred variables. Also, the services offered by current probabilistic reasoning systems are not well matched to the needs of higher-level problem solvers.
Reference: [18] <author> Z. Li. </author> <title> Experimental characterization of several algorithms for inference in belief nets. </title> <type> Technical report, Master's thesis, </type> <institution> CS Dept., Oregon State University, </institution> <year> 1990. </year>
Reference-contexts: Despite the fact that current state-of-the-art algorithms exploit the independence information in a belief net to construct efficient computations for probabilistic inference [21], [17], [24], in practice computational cost still grows rapidly <ref> [18] </ref>, limiting application of these techniques to belief nets with a few hundred variables. Also, the services offered by current probabilistic reasoning systems are not well matched to the needs of higher-level problem solvers. As we discussed in [4] and [6], problem solvers typically interleave model construction, revision, and evaluation.
Reference: [19] <author> Z. Li and B. D'Ambrosio. </author> <title> An efficient approach to probabilistic inference in belief nets. </title> <booktitle> In . Canadian Association for Artificial Intelligence, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: When the graph is sparse, this will involve a much smaller set of numbers than the full joint. Equally important, the graphical structure can be used to guide processing to find efficient ways to evaluate queries against the model. For more details, see [21], [5], [24], <ref> [19] </ref>. All is not as rosy at it might seem, though. The graphical level is not capable of representing all interesting structural information which might simplify representation or inference. <p> The expression for ( ) is: ( ) = ( ) ( ( ) ( )) It should be obvious that we can efficiently combine these two expressions into a single evalu ation poly-tree: Construction of an optimal evaluation poly-tree for an arbitrary query set is a hard problem <ref> [19] </ref>. However, simple, polynomial-time heuristics perform quite well, and are described in [9], [19]. This previous work was performed in the context of exact query evaluation (that is, computation of all terms), but the theory remains applicable, and so will not be repeated in detail here. The process used in [19] <p> ( ) ( )) It should be obvious that we can efficiently combine these two expressions into a single evalu ation poly-tree: Construction of an optimal evaluation poly-tree for an arbitrary query set is a hard problem <ref> [19] </ref>. However, simple, polynomial-time heuristics perform quite well, and are described in [9], [19]. This previous work was performed in the context of exact query evaluation (that is, computation of all terms), but the theory remains applicable, and so will not be repeated in detail here. The process used in [19] is the basis for our current implementation. <p> <ref> [19] </ref>. However, simple, polynomial-time heuristics perform quite well, and are described in [9], [19]. This previous work was performed in the context of exact query evaluation (that is, computation of all terms), but the theory remains applicable, and so will not be repeated in detail here. The process used in [19] is the basis for our current implementation. That method is essentially a greedy search through the space of partial evaluation trees . Given an evaluation poly-tree for a query set, the primitive operation at each node in the tree is generation of a term.
Reference: [20] <author> J. Pearl. </author> <title> Distributed revision of composite beliefs. </title> , <booktitle> 33(2) </booktitle> <pages> 173-216, </pages> <year> 1987. </year>
Reference-contexts: In another context, deKleer has referred to this as the "Most Likely Composite Hypothesis" problem [10], Henrion has described an algorithm for diagnosis in very large knowledge bases [15], and Pearl has discussed the problem of "Distributed Revision of Composite Beliefs" <ref> [20] </ref>. From another perspective, Horvitz have been developing bounded conditioning as an approach to anytime probabilistic inference [16], and Boddy has proposed an anytime approach to dynamic programming [2].
Reference: [21] <author> J. </author> <title> Pearl. </title> . <publisher> Morgan Kaufmann, </publisher> <address> Palo Alto, </address> <year> 1988. </year>
Reference-contexts: The key representational limitation is an inability to represent structure within a single conditional probability distribution. The key inferential problems can be described as lack of with respect to various task requirements. A belief net <ref> [21] </ref> is a compact, localized representation of a probabilistic model. <p> When the graph is sparse, this will involve a much smaller set of numbers than the full joint. Equally important, the graphical structure can be used to guide processing to find efficient ways to evaluate queries against the model. For more details, see <ref> [21] </ref>, [5], [24], [19]. All is not as rosy at it might seem, though. The graphical level is not capable of representing all interesting structural information which might simplify representation or inference. <p> The only mechanism available for describing antecedent interactions in typical general purpose belief net inference algorithms is the full conditional distribution across all antecedents. However, a number of restricted interaction models have been identified which have lower space and time complexity than the full conditional. The noisy-or <ref> [21] </ref>, [22], [13], [14], [1] for example, can be used to model independent causes of an event, and inference complexity is linear in both space and time in the number of antecedents for many inferences. Similarly, various asymmetric [25], [12] and logical relationships are inefficiently represented using a full conditional. <p> Despite the fact that current state-of-the-art algorithms exploit the independence information in a belief net to construct efficient computations for probabilistic inference <ref> [21] </ref>, [17], [24], in practice computational cost still grows rapidly [18], limiting application of these techniques to belief nets with a few hundred variables. Also, the services offered by current probabilistic reasoning systems are not well matched to the needs of higher-level problem solvers.
Reference: [22] <author> Y. Peng and J. Reggia. </author> <title> A probabilistic causal model for diagnostic problem solving part 1: Integrating symbolic causal inference with numeric probabilistic inference. </title> , <address> SMC-17(2):146-162, </address> <year> 1987. </year>
Reference-contexts: The only mechanism available for describing antecedent interactions in typical general purpose belief net inference algorithms is the full conditional distribution across all antecedents. However, a number of restricted interaction models have been identified which have lower space and time complexity than the full conditional. The noisy-or [21], <ref> [22] </ref>, [13], [14], [1] for example, can be used to model independent causes of an event, and inference complexity is linear in both space and time in the number of antecedents for many inferences. Similarly, various asymmetric [25], [12] and logical relationships are inefficiently represented using a full conditional.
Reference: [23] <author> L. </author> <title> Savage. </title> . <publisher> Dover Publications, </publisher> <year> 1972. </year>
Reference-contexts: Finally, the agent must act repeatedly, yet each action is in a new context: not only must a new set of input data be considered, but also a new set of beliefs about system state, based on prior information and computation. The infinite lookahead, or "small worlds" <ref> [23] </ref> problem has two subproblems, one for replacement actions and another for probe actions. We circumvent the first subproblem, that of infinite lookahead for replacement actions, as follows.
Reference: [24] <author> R. Shachter, B. D'Ambrosio, and B. DelFavero. </author> <title> Symbolic probabilistic inference in belief networks. In , pages 126-131. </title> <publisher> AAAI, </publisher> <month> August </month> <year> 1990. </year>
Reference-contexts: When the graph is sparse, this will involve a much smaller set of numbers than the full joint. Equally important, the graphical structure can be used to guide processing to find efficient ways to evaluate queries against the model. For more details, see [21], [5], <ref> [24] </ref>, [19]. All is not as rosy at it might seem, though. The graphical level is not capable of representing all interesting structural information which might simplify representation or inference. <p> Despite the fact that current state-of-the-art algorithms exploit the independence information in a belief net to construct efficient computations for probabilistic inference [21], [17], <ref> [24] </ref>, in practice computational cost still grows rapidly [18], limiting application of these techniques to belief nets with a few hundred variables. Also, the services offered by current probabilistic reasoning systems are not well matched to the needs of higher-level problem solvers.
Reference: [25] <author> R. Shachter and R. Fung. </author> <title> Contingent influence diagrams. </title> <type> Tech report, </type> <institution> Dept. of Engineering Economic Systems, Stanford University, </institution> <month> September </month> <year> 1990. </year> <note> In preparation. </note>
Reference-contexts: The noisy-or [21], [22], [13], [14], [1] for example, can be used to model independent causes of an event, and inference complexity is linear in both space and time in the number of antecedents for many inferences. Similarly, various asymmetric <ref> [25] </ref>, [12] and logical relationships are inefficiently represented using a full conditional. Finally, value models used in utility modeling are often factored, for example they may be additive. We have developed an algebraic extension to belief nets which permits conditional distributions to be defined as algebraic compositions of smaller distributions.
Reference: [26] <editor> H. Simon. </editor> . <publisher> MIT Press, </publisher> <year> 1974. </year> <month> 16 </month>
Reference-contexts: Early writings by at least some in AI (e.g., <ref> [26] </ref>) stress the necessity of recognizing both the limitations and embedded nature of realizable agents. Despite that, much work in AI has proceeded as if the demands placed by the environment are static.
References-found: 26

