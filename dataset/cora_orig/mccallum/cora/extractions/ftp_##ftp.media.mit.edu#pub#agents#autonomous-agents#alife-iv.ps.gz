URL: ftp://ftp.media.mit.edu/pub/agents/autonomous-agents/alife-iv.ps.gz
Refering-URL: http://agents.www.media.mit.edu/groups/agents/publications/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: aries/pattie/trevor@media.mit.edu  
Title: Evolving Visual Routines  
Author: Michael Patrick Johnson, Pattie Maes and Trevor Darrell 
Address: Cambridge, Mass.  
Affiliation: MIT Media Laboratory  
Abstract: Traditional machine vision assumes that the vision system recovers a a complete, labeled description of the world [ Marr, 1982 ] . Recently, several researchers have criticized this model and proposed an alternative model which considers perception as a distributed collection of task-specific, task-driven visual routines [ Aloimonos, 1993, Ullman, 1987 ] . Some of these researchers have argued that in natural living systems these visual routines are the product of natural selection [ Ramachandran, 1985 ] . So far, researchers have hand-coded task-specific visual routines for actual implementations (e.g. [ Chapman, 1993 ] ). In this paper we propose an alternative approach in which visual routines for simple tasks are evolved using an artificial evolution approach. We present results from a series of runs on actual camera images, in which simple routines were evolved using Genetic Programming techniques [ Koza, 1992 ] . The results obtained are promising: the evolved routines are able to correctly classify up to 93% of the images, which is better than the best algorithm we were able to write by hand. 
Abstract-found: 1
Intro-found: 1
Reference: [ Aloimonos, 1993 ] <author> Y. Aloimonos. </author> <title> Active Perception. </title> <publisher> Lawrence Erlbaum Associates, Inc., </publisher> <address> Hillsdale, </address> <note> 1993. </note> [ <author> Ballard and Whitehead, 1990 ] D. Ballard and S. Whitehead. </author> <title> Active perception and reinforcement learning. </title> <booktitle> Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <year> 1990. </year>
Reference-contexts: This turns out to be an extremely hard, if not impossible, problem to solve. Active vision is a new paradigm for doing machine vision that has received a lot of attention recently <ref> [ Ballard, 1989, Aloimonos, 1993 ] </ref> . The insight that active vision brings to the problem is that almost all of the time an intelligent agent doesn't even need all that information, since it is involved in a particular task that only requires specific knowledge of certain objects.
Reference: [ Ballard, 1989 ] <author> D. Ballard. </author> <title> Reference frames for animate vision. </title> <booktitle> Proceedings of IJCAI-89 Conference, </booktitle> <address> Detroit, </address> <year> 1989. </year>
Reference-contexts: This turns out to be an extremely hard, if not impossible, problem to solve. Active vision is a new paradigm for doing machine vision that has received a lot of attention recently <ref> [ Ballard, 1989, Aloimonos, 1993 ] </ref> . The insight that active vision brings to the problem is that almost all of the time an intelligent agent doesn't even need all that information, since it is involved in a particular task that only requires specific knowledge of certain objects.
Reference: [ Chapman, 1993 ] <author> D. Chapman. </author> <title> Vision, Instruction and Action. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1993. </year>
Reference-contexts: This person can design by hand visual routines that solve a given task, test them and refine them, hopefully reaching an optimal solution. This may be a reasonable approach in limited cases, such as the Sonja system by David Chapman <ref> [ Chapman, 1993 ] </ref> , which has a set of routines designed by Chapman for solving different visual tasks involved in playing a particular video game. The set of routines is fairly small and fixed, allowing a programmer to work them out by hand. <p> David Chapman applied similar operations to the domain of visual attention in his Sonja video game playing system <ref> [ Chapman, 1993 ] </ref> . Sonja can find gaps in a boundary (ostensibly doors), track moving pop-out objects (such as the player's icon) with a marker, color a region and cast rays, for instance 1 . In the game, characters move around a two-dimensional world full of impenetrable walls.
Reference: [ Cliff D. T. and I., 1993 ] <author> Husbands P. Cliff D. T. and Harvey I. </author> <title> Evolving visually guided robots. </title> <booktitle> Proceedings of the second international conference on Simulation of Adaptive Behavior (SAB 92), </booktitle> <publisher> MIT Press, </publisher> <year> 1993. </year> <editor> Ed. by J.-A. Meyer, H. Roitblat and S. </editor> <publisher> Wilson. </publisher>
Reference-contexts: Inspired by the way in which nature may have evolved a range of special-purpose visual routines [ Ra-machandran, 1985 ] , we try to automatically develop visual routines for particular tasks that are relevant to a system using artificial evolution. This work is related to the research described in <ref> [ Cliff D. T. and I., 1993 ] </ref> , which also evolves visually-guided behaviors.
Reference: [ Hillis, 1991 ] <author> D. Hillis. </author> <title> Co-evolving parasites improve simulated evolution as an optimization procedure. </title> <booktitle> Ar-tifical Life II, SFI Studies in the Sciences of Complexity, </booktitle> <volume> vol. X, </volume> <year> 1991. </year>
Reference-contexts: Even more interesting would be to use a different Genetic Algorithm to coevolve configurations of this model with the solutions. Coevolution has been shown to be faster and more robust than a fixed fitness function in some cases <ref> [ Koza, 1991, Hillis, 1991 ] </ref> . One might also want to add a weighting to the fitness cases based on some notion of their statistics; that is, more common postures should be focused on rather than contorted postures.
Reference: [ Koza, 1991 ] <author> J. R. Koza. </author> <title> Genetic evolution and coevolution of computer programs. </title> <booktitle> Artificial Life II, SFI Studies in the Sciences of Complexity, </booktitle> <volume> vol. X, </volume> <year> 1991. </year>
Reference-contexts: Even more interesting would be to use a different Genetic Algorithm to coevolve configurations of this model with the solutions. Coevolution has been shown to be faster and more robust than a fixed fitness function in some cases <ref> [ Koza, 1991, Hillis, 1991 ] </ref> . One might also want to add a weighting to the fitness cases based on some notion of their statistics; that is, more common postures should be focused on rather than contorted postures.
Reference: [ Koza, 1992 ] <editor> J. R. Koza. </editor> <booktitle> Genetic Programming. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1992. </year>
Reference-contexts: Also, it is difficult for the programmer to anticipate all cases in which the program should work. This paper describes a way of automatically producing a visual routine appropriate for a given task by using simulated evolution of computer programs in the style of John Koza <ref> [ Koza, 1992 ] </ref> . The paper is organized as follows. Section 2 discusses previous work on visual routines. <p> We refrain from a full discussion of GP here and give only salient points. Koza discusses this system and variations of it at great length in his book <ref> [ Koza, 1992 ] </ref> . The system used here is similar to Koza's except for the addition of the type specification described below and several other small improvements. The genetic operations used in this work are copying, crossover and mutation. <p> Crossover chooses two individuals at random, again roughly proportional to fitness, and swaps randomly chosen sub-trees. Mutation picks a random subtree and replaces it with a newly generated subtree. Better results were obtained using the tournament selection method described in <ref> [ Koza, 1992 ] </ref> , which picks k individuals at random and chooses the one with the best fitness (effectively a tournament between the individuals, hence tournament selection). This can be used for copying and for selecting the two individuals for crossover.
Reference: [ Maes et al., 1993 ] <author> P. Maes, B. Blumberg, T. Darrell, and S. Pentland. </author> <title> Alive: An artificial life interactive video environment. </title> <booktitle> Visual Proceedings of Siggraph '93, </booktitle> <publisher> ACM Press, </publisher> <year> 1993. </year>
Reference-contexts: The set of routines is fairly small and fixed, allowing a programmer to work them out by hand. Another similar example (and the one which we will focus on) is the simple vision system used by the ALIVE (Artificial Life Interactive Video Environment) virtual environment project <ref> [ Maes et al., 1994, Maes et al., 1993 ] </ref> . In this system, a user can interact in real-time with a computer graphics creature using gestures which are interpreted by a vision system.
Reference: [ Maes et al., 1994 ] <author> P. Maes, T. Darrell, B. Blumberg, and S. Pentland. </author> <title> The alive system: Full-body interaction with animated autonomous agents. </title> <note> Submitted for publication, </note> <year> 1994. </year>
Reference-contexts: The set of routines is fairly small and fixed, allowing a programmer to work them out by hand. Another similar example (and the one which we will focus on) is the simple vision system used by the ALIVE (Artificial Life Interactive Video Environment) virtual environment project <ref> [ Maes et al., 1994, Maes et al., 1993 ] </ref> . In this system, a user can interact in real-time with a computer graphics creature using gestures which are interpreted by a vision system. <p> A solution to this problem was actually necessary for the ALIVE virtual environment project <ref> [ Maes et al., 1994 ] </ref> (see Section 3.1). For ALIVE, a visual routine was written by hand for this task, applied when hand location was desired. We restrict the problem slightly for this study, to see if genetic programming can solve subgoals of the overall task.
Reference: [ Marr, 1982 ] <author> D. Marr. </author> <title> Vision. W.H. </title> <publisher> Freeman, </publisher> <address> San Fran-cisco, CA, </address> <year> 1982. </year>
Reference-contexts: 1 Introduction One of the hardest problems to be solved when building a real robotic autonomous agent is the perception problem. Traditional machine vision assumes that the vision system produces a labeled, perfectly resolved model of the world, distinguishing and representing all objects <ref> [ Marr, 1982 ] </ref> . This turns out to be an extremely hard, if not impossible, problem to solve. Active vision is a new paradigm for doing machine vision that has received a lot of attention recently [ Ballard, 1989, Aloimonos, 1993 ] .
Reference: [ Ramachandran, 1985 ] <author> V. S. Ramachandran. </author> <title> Apparent motion of subjective surfaces. </title> <journal> Perception, </journal> <volume> 14:127 - 134, </volume> <year> 1985. </year>
Reference-contexts: An obvious answer might be that the central system does some intelligent reasoning in order to determine their application. Ramachandran, a human vision researcher, disagrees with this solution and suggests the "utilitarian theory" of perception <ref> [ Ramachandran, 1985 ] </ref> . He argues that since many other systems in the human body are collections of ad hoc pieces that all function in their own way but tend to work together, perception is likely to be the same.
Reference: [ Ullman, 1987 ] <author> S. Ullman. </author> <title> Visual routines. </title> <booktitle> Readings in Computer Vision, </booktitle> <pages> pages 298 - 327, </pages> <year> 1987. </year> <editor> Ed. by Martin A. </editor> <publisher> Fischler and Oscar Firschein. </publisher>
Reference-contexts: Furthermore, that information will be different information than I might extract if I were intent on drawing the cup. Thus, active vision requires more work on the part of the central system. To explain how the internal active processing could be implemented, Shimon Ullman proposes the visual routines model <ref> [ Ullman, 1987 ] </ref> , which describes a set of primitive routines that can be applied to an input image in order to find certain spatial relations between objects as well as other useful information. <p> Section 4 discusses the actual Genetic Programming (GP) implementation used for the experiments. Section 5 discusses results of the GP runs. Section 6 lists possible future directions. Finally, section 7 gives a summary. 2 Visual Routines Ullman <ref> [ Ullman, 1987 ] </ref> breaks the visual system into three main areas: the base representation, the visual routines processor and the higher level components. The base representation is the result of initial, parallel processing of the retinal image. <p> What constitutes a boundary is a function of the task, so must be a parameter to the operation. For example, consider again the inside-outside task. People can still tell if a point is inside a circle with a dashed line for a border (see <ref> [ Ullman, 1987 ] </ref> ).
References-found: 12

