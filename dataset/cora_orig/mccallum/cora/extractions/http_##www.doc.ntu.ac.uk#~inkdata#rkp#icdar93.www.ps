URL: http://www.doc.ntu.ac.uk/~inkdata/rkp/icdar93.www.ps
Refering-URL: http://www.doc.ntu.ac.uk/HAND/Papers/index.html
Root-URL: 
Title: Multiple word segmentation with interactive look-up for cursive script recognition. Second Int. Conf. on Document
Author: R.K. Powalka, N. Sherkat, L.J. Evett, R.J. Whitrow. 
Keyword: on-line cursive script recognition, word segmentation, lexical look-up, word ending postulation.  
Note: pp.  Lexical look-up is used to postulate word endings for partially recognised words. This provides the means of  is described and evaluated.  
Address: City, Japan,  
Affiliation: Tsukuba Science  
Pubnum: ICDAR'93,  
Date: 196-199, October 1993  
Abstract: Cursive script recognition is commonly based on finding letters within a word and recognizing them separately. The segmentation process is ambiguous and difficult. This paper presents a method which combines word segmentation and letter recognition with lexical lookup in order to cope with segmentation ambiguity. Words are first segmented into small elements which are then put together using a database of their possible combinations to produce alternative segmentations. Letter recognition is performed on each letter candidate and lexical look-up is applied, interactively, to prune illegal word recognition results. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.W. Appel, G.J. Jacobson, </author> <title> The World's Fastest Scrabble Program, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 31, No. 5, </volume> <pages> pp. 572-584, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: A database of acceptable segmentations is used to disallow them at an early stage. While possible letters are being produced by the segmentation process, they could initiate the word look-up. The current system represents the vocabulary in a directed acyclic graph <ref> [1] </ref>. In practise, the word look-up is performed after segmentation and matching. Segmentation and matching are constrained as described above. It was not found to be necessary to guide the segmentation process to prevent unacceptable number of segmentations.
Reference: [2] <author> D.G. Elliman, </author> <title> I.T. Lancaster, A Review of Segmentation and Contextual Analysis Techniques for Text Recognition, </title> <journal> Pattern Recognition, </journal> <volume> Vol. 23, No. 3/4, </volume> <pages> pp. 337-346, </pages> <year> 1990. </year>
Reference-contexts: Only some of the possible letter combinations produce words in a language. A number of systems have taken advantage of this fact to rule out unacceptable letter strings from the recognition process. This can be achieved by using various forms of Markov modelling [8], n-grams [13], or lexical look-up <ref> [2] </ref>, [12]. Using some form of word look-up is preferable, because it reduces the number of candidates by a greater amount and it is more accurate. Its disadvantage is that it will reject any letter strings which are not in the vocabulary, which will not occur with Markov modelling.
Reference: [3] <author> L.J. Evett, C.J. Wells, F.G. Keenan, T. Rose, </author> <title> R.J. Whitrow, Using Linguistic Information to Aid Handwriting Recognition, From Pixels to Features III: Frontiers in Handwriting Recognition, </title> <publisher> Elsevier Science Publishers, </publisher> <year> 1992. </year>
Reference-contexts: The authors reported that further work would be required on this point. The presented recognizer is part of a larger system. Further improvement can be obtained by applying higher level syntactic and semantic information <ref> [3] </ref>. However, the performance of the pattern recognition stage still needs improvement.
Reference: [4] <author> H. Freeman, </author> <title> Computer Processing of Line-Drawing Images, </title> <journal> Computing Surveys, </journal> <volume> Vol. 6, No. 1, </volume> <pages> pp. 57-97, </pages> <year> 1974. </year>
Reference-contexts: The code is based on the Freeman encoding algorithm <ref> [4] </ref>. It segments the data into the smallest useful segments (referred to as clusters) and then attempts to combine them into letters. This is done by consulting a segmentation database and interacting between the segmentation, the letter recognition and the lexical look-up processes. An eight direction encoding method is used.
Reference: [5] <author> C.A. Higgins, </author> <title> D.M. Ford, A New Segmentation Method for Cursive Script Recognition, </title> <booktitle> Second Int. Workshop on Frontiers in Handwriting Recognition, Bonas, France, </booktitle> <pages> pp. 241-252, </pages> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: Segmentation is a much greater problem for cursive script than it is for printed text. Cursive script recognition systems use a number of methods in order to divide up the input patterns <ref> [5] </ref>. These methods generally attempt to segment patterns into smaller parts using information such as y-minima or common ligatures. Segments may be potential strokes, potential letters or possibly some higher level letter grouping. Recognition of the segments is then attempted.
Reference: [6] <author> C.A. Higgins, </author> <title> D.M. Ford, Stylus Driven Interfaces - The Electronic Paper Concept, </title> <booktitle> First Int. Conf. on Document Analysis and Recognition, Saint-Malo, France, </booktitle> <pages> pp. 853-862, </pages> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: A number of systems are reported to recognize both printed and cursive writing. None as yet are robust enough to be used in general applications. With rapid improvements in current technology it will not be long before the infrastructure for such systems is practically and economically feasible <ref> [6] </ref>. The reliability of handwriting recognition needs to be improved in order to enable its use in general applications. Experience shows that a generalised approach to recognition will not provide a satisfactory solution. A survey of the available literature supports this argument [11].
Reference: [7] <author> H. Oulhadj, E. Petit, J. Lemoine, M. Gaudaire, G. </author> <month> Lorette, </month>
Reference-contexts: Bigram statistics have been used for contextual disambiguation. Good recognition results (average 97% correct for three writers) have been reported with writers creating their own letter prototypes. However, writing samples were small and the use of bigram statistics to filter the output introduced errors into the system. Oulhadj <ref> [7] </ref> used a letter prediction-verification method with word look-up. Again, good results were reported (average 94% correct for four writers), but a small vocabulary was used (110 words) and it is not clear what was done when good letter matches were not obtained.
References-found: 7

