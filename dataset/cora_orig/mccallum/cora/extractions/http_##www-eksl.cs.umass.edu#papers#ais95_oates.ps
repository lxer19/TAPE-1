URL: http://www-eksl.cs.umass.edu/papers/ais95_oates.ps
Refering-URL: http://eksl-www.cs.umass.edu/publications.html
Root-URL: 
Title: Detecting Complex Dependencies in Categorical Data  
Author: Tim Oates, Matthew D. Schmill, Dawn E. Gregory and Paul R. Cohen 
Keyword: 1.1 Dependency Detection  
Address: Box 34610 Amherst, MA 01003-4610  
Affiliation: Computer Science Department, LGRC University of Massachusetts  
Abstract: Locating and evaluating relationships among values in multiple streams of data is a difficult and important task. Consider the data flowing from monitors in an intensive care unit. Readings from various subsets of the monitors are indicative and predictive of certain aspects of the patient's state. We present an algorithm that facilitates discovery and assessment of the strength of such predictive relationships called Multi-stream Dependency Detection (msdd). We use heuristic search to guide our exploration of the space of potentially interesting dependencies to uncover those that are significant. We begin by reviewing the dependency detection technique described in [3], and extend it to the multiple stream case, describing in detail our heuristic search over the space of possible dependencies. Quantitative evidence for the utility of our approach is provided through a series of experiments with artificially-generated data. In addition, we present results from the application of our algorithm to two real problem domains: feature-based classification and Consider a network of seaports, with ships carrying cargo between the ports according to a complex schedule. Unforeseen occurrences at a single port or a group of ports, such as severe weather or mechanical failures, can impact the schedule at adjacent ports. If the current state of the network can be used to predict future states of the network, it may be possible to adjust the schedule to minimize adverse effects of such unforeseen occurrences. Similarly, it would be very useful to determine how the future state of a patient, as indicated by various monitors in an Intensive Care Unit (ICU), depends on the current state of the patient. Note that data in the form of time series is not required for the discovery and exploitation of such predictive relationships. Machine learning algorithms that perform feature-based classification determine how a class label depends on various subsets of a feature vector. In all of the above examples, the goal is to determine whether one set of features can be used to predict another set of features. The two sets of features may be taken from the same source at different times (e.g. ICU monitors), or they may be taken from different sources with no notion of time (e.g. a feature vector and a class label). We will revisit both the shipping network and classification examples later in this paper. A dependency is an unexpectedly frequent or infrequent co-occurrence of events over time. Our goal is to find dependencies between tokens contained in multiple streams. A stream is a sequence of values produced over time, and a token is one of the finite set of values that a stream can produce. Dependencies across multiple streams may take many prediction of pathologies in a simulated shipping network.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bennett, K. P. and Mangasarian, O. L. </author> <title> Robust linear programming discrimination of two linearly inseparable sets. In Optimization Methods and Software 1, 1992, </title> <publisher> 23-34 (Gordon and Breach Science Publishers). </publisher>
Reference: [2] <author> Holte, Robert C. </author> <title> Very simple classification rules perform well on most commonly used datasets. </title> <booktitle> In Machine Learning, </booktitle> <volume> (11), </volume> <pages> pp. 63-91, </pages> <year> 1993. </year>
Reference-contexts: We compared msdd's performance with other published results for each dataset <ref> [2, 4, 7, 8] </ref>. On ten datasets for which we had multiple published results, msdd performance exceeds half of the reported results on six datasets. Only on the Soybean dataset did msdd perform badly.
Reference: [3] <author> Howe, Adele E. and Cohen, Paul R. </author> <title> Understanding Planner Behavior. </title> <note> To appear in AI Journal, </note> <month> Winter </month> <year> 1995. </year>
Reference-contexts: In general, if stream j contains t j distinct tokens, there are [ Q n j=1 t j + 1] 2 possible dependencies between two items. The dependency detection technique in <ref> [3] </ref> uses contingency tables to assess the significance of dependencies in a single stream of data. Let (t p ; t s ; ffi) denote a dependency. <p> The notion of dependencies between pairs of tokens introduced in <ref> [3] </ref> was extended to pairs of multi-tokens, where a multi-token describes the contents of several streams rather than just one. We introduced the Multi-Stream Dependency Detection (msdd) algorithm that performs a general-to-specific best-first search over the exponentially sized space of possible dependencies between multi-tokens.
Reference: [4] <author> Murphy, P. M., and Aha, D. W. </author> <title> UCI Repository of machine learning databases [Machine-readable data repository]. </title> <address> Irvine, CA: </address> <institution> University of California, Department of Information and Computer Science, </institution> <year> 1994. </year>
Reference-contexts: We compared msdd's performance with other published results for each dataset <ref> [2, 4, 7, 8] </ref>. On ten datasets for which we had multiple published results, msdd performance exceeds half of the reported results on six datasets. Only on the Soybean dataset did msdd perform badly.
Reference: [5] <author> Oates, Tim. </author> <title> MSDD as a Tool for Classification. </title> <type> Memo 94-29, </type> <institution> Experimental Knowledge Systems Laboratory, Department of Computer Science, University of Mas-sachusetts, Amherst, </institution> <year> 1994. </year>
Reference-contexts: Due to the high branching factor of the Soybean dataset (it contains 35 attributes), the node limit on the search tree was quickly reached. We are currently exploring solutions to this problem. For a more complete comparison than that shown in Table 1.1, refer to <ref> [5] </ref>. 1.4.2 Pathology Prediction We applied msdd to the task of predicting pathologies in a simulated shipping network called TransSim. When several ships attempt to dock at a single port at the same time, most will be queued to await a free dock, resulting in a bottleneck.
Reference: [6] <author> Oates, Tim and Cohen, Paul R. </author> <title> Toward a plan steering agent: Experiments with schedule maintenance. </title> <booktitle> In Proceedings of the Second International Conference on Artificial Intelligence Planning Systems, </booktitle> <pages> pp. 134-139, </pages> <year> 1994. </year>
Reference: [7] <author> Thrun, </author> <title> S.B. The MONK's problems: A performance comparison of different learning algorithms. </title> <institution> Carnegie Mellon University, CMU-CS-91-197, </institution> <year> 1991. </year>
Reference-contexts: The exceptions are NetTalk (training data was generated from a list of the 1000 most common English words, and accuracy was tested on the full 20,008 word corpus), Monks-2 (a single trial with 169 training instances and 432 test instances to facilitate comparison with results contained in <ref> [7] </ref>), Soybean (a single trial with 307 training instances and 376 test instances), and Mushroom (500 training instances and 7624 test instances). We compared msdd's performance with other published results for each dataset [2, 4, 7, 8]. <p> We compared msdd's performance with other published results for each dataset <ref> [2, 4, 7, 8] </ref>. On ten datasets for which we had multiple published results, msdd performance exceeds half of the reported results on six datasets. Only on the Soybean dataset did msdd perform badly.
Reference: [8] <author> Wirth, J. and Catlett, J. </author> <title> Experiments on the costs and benefits of windowing in ID3. </title> <booktitle> In Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <pages> pp. 87-99, </pages> <year> 1988. </year>
Reference-contexts: We compared msdd's performance with other published results for each dataset <ref> [2, 4, 7, 8] </ref>. On ten datasets for which we had multiple published results, msdd performance exceeds half of the reported results on six datasets. Only on the Soybean dataset did msdd perform badly.
Reference: [9] <author> Zheng, Zijian. </author> <title> A benchmark for classifier learning. </title> <institution> Basser Department of Computer Science, University of Sydney, NSW. </institution>
Reference-contexts: We present results for thirteen datasets from the UC Irvine collection. Twelve of those datasets were selected from a list of thirteen presented in <ref> [9] </ref> as being a minimal representative set that covers several important features that distinguish problem domains. The precursor multi-tokens were n-ary feature vectors and the successor "multi-tokens" contained only the class label. These pairs of multi-tokens serve as input to the msdd algorithm.
References-found: 9

