URL: ftp://ftp.cse.ogi.edu/pub/esr/reports/sigmod-91.ps.gz
Refering-URL: http://www.cse.ogi.edu/~calton/publication.html
Root-URL: http://www.cse.ogi.edu
Title: Replica Control in Distributed Systems: An Asynchronous Approach methods do not require users to refer
Author: Calton Pu and Avraham Leff 
Note: Various replica control methods that maintain ESR are described and analyzed. Because these  
Address: New York, NY 10027  
Affiliation: Department of Computer Science Columbia University  
Abstract: An asynchronous approach is proposed for replica control in distributed systems. This approach applies an extension of serializability called epsilon-serializability (ESR), a correctness criterion which allows temporary and bounded inconsistency in replicas to be seen by queries. Moreover, users can reduce the degree of inconsistency to the desired amount. In the limit, users see strict 1-copy serializability. Because the system maintains ESR correctness (1) replicas always converges to global serializability and (2) the system permits read access to object replicas before the system reaches a quiescent state. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Agrawal and S. Sengupta. </author> <title> Modular synchronization in multiversion databases: Version control and concurrency control. </title> <booktitle> In Proceedings of the 1989 ACM SIGMOD International Conference on Management of Data, </booktitle> <address> Portland, </address> <year> 1989. </year> <month> ACM/SIGMOD. </month>
Reference-contexts: The case of multiple versions assumes that each query should be synchronized at some fixed time (for all the reads). For simplicity of presentation, we use the Modular Synchronization Method <ref> [1] </ref> to maintain versions, which makes versions of objects visible to queries in such a way that no smaller version can be created by any active or future transactions. This visibility control, called a visible transaction number counter (VTNC), produces SR queries.
Reference: [2] <author> R. Alonso, D. Barbara, and H. Garcia-Molina. </author> <title> Data caching issues in an information retrieval systems. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 15(3) </volume> <pages> 359-384, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Sheth and Rusinkiewicz [23] have proposed a taxonomy for interdependent data management. They separate data consistency criteria into temporal and spatial dimensions. The temporal con sistency has two kinds: eventual consistency (anal-ogous to identity connections), and lagging consistency (analogous to quasi-copies <ref> [2] </ref>). The spatial consistency criteria are divided into three cases. Inconsistency is controlled by limiting either (1) the number of data items changed asynchronously, (2) the data value changed asynchronously, or (3) the number of allowed asynchronous operations. <p> ESR differs in two major ways from weak-consistency: first, it allows more interleaving (because query ETs are permitted to see local inconsistency), and, second, weak consistency does not incorporate methods that can tune the degree of inconsistency. Quasi-copies <ref> [2] </ref> offers a theoretical foundation for increased read-only availability, but require that all updates be 1SR. As a result, the primary copy is always consistent in the 1SR sense. Inconsistency is only introduced because quasi-copies may lag the primary copy.
Reference: [3] <author> D. Barbara and H. Garcia-Molina. </author> <title> The case for controlled inconsistency in replicated data. </title> <booktitle> In Proceedings of the Workshop on Management of Replicated Data, </booktitle> <pages> pages 35-42, </pages> <address> Houston, </address> <month> November </month> <year> 1990. </year>
Reference-contexts: An implementation of interdependent data management is described in [22]: it essentially corresponds to ORDUP. Replica control and divergence control can implement such criteria [26]. Another specification approach is Controlled Inconsistency proposed by Barbara and Garcia-Molina <ref> [3] </ref>, which generalizes their work on quasi-copies. Controlled Inconsistency specifies arithmetic consistency constraints, similar to the data value limit in interdependent data management. They constrain updates to be safe operations, defined by some semantic correctness criteria appropriate to the application.
Reference: [4] <author> P.A. Bernstein, V. Hadzilacos, and N. Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> first edition, </address> <year> 1987. </year>
Reference-contexts: On the other hand, a basic problem with asynchronous coherency control methods is that the system enters an inconsistent state in which replicas of a given object may not share the same value. Standard correctness criterion for coherency control such as 1-copy serializability (1SR) <ref> [4] </ref> are hard to attain with asynchronous coherency control. Epsilon-serializability (ESR) is a correctness criterion which offers the possibility of maintaining mutual consistency of replicated data asynchronously. First, ESR allows inconsistent data to be seen, but requires that data will eventually converge to a consistent (1SR) state. <p> In this paper we view the role of both coherency control and replica control as consistency maintenance among replicas of a given "logical" object. We therefore only discuss replica control methods: the replicated system is assumed to use standard (synchronous) concurrency control <ref> [4] </ref> or (asynchronous) divergence control methods [20] in order to maintain consistency among different objects in the system. In Section 2 we introduce the ESR terminology, model, and its properties. In Section 3, asynchronous replica control methods are described, analyzed, and are shown to provide ETs with ESR properties. <p> If update ETs are executed concurrently, we require them to be serializable (SR) <ref> [4] </ref>. However, ETs take advantage of operations which increase concurrency and allow more interleaving. For example, commutative operations can be interleaved more freely than reads and writes. Semantics-based consistency maintenance methods are in general termed divergence control methods. <p> ETs offer an additional benefit in situations such as time-critical applications where a 1SR update has not yet been propagated. The available values may then be too old to be useful. An early example of read-only redundancy is timestamped versions <ref> [4] </ref>. Queries that are serialized in the "past" do not block, and immutable versions can be replicated freely. Another early proposal using the idea of read-only redundancy is weak consistency [13] defined over the class of read-only transactions.
Reference: [5] <author> P.A. Bernstein, M. Hsu, and B. Mann. </author> <title> Implementing recoverable requests using queues. </title> <booktitle> In Proceedings of 1990 SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 112-122, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Each local system is responsible for applying its MSet and preserving internal consistency. Note that the propagation of MSets to each site is asynchronous. We assume the system maintains the unprocessed MSets in some stable storage, such as stable queues <ref> [5] </ref> and persistent pipes [16]. Each MSet is stored as an element in a stable queue. Due to the asynchronous propagation of MSets, replicas of a "logical" object can differ at any given moment. This is the source of inconsistency seen by the query ETs.
Reference: [6] <author> K. Birman and T. Joseph. </author> <title> Exploiting virtual synchrony in distributed systems. </title> <booktitle> In Proceedings of the Eleventh Symposium on Operating Systems Prin--ciples, </booktitle> <pages> pages 123-138. </pages> <address> ACM/SIGOPS, </address> <month> November </month> <year> 1987. </year>
Reference-contexts: In addition to directory/file-system propagation, asynchronous communication techniques have also been developed. An example of the latter is Lazy Replication [18]. It provides three classes of ordered messages, plus unordered delivery. This facility is at a much lower level of abstraction than transactions and ETs. Another example is Isis <ref> [6] </ref>, which provides four kinds of multicast and broadcast facilities, including causal broadcasts. These communications facilities have been used to provide replication in a way similar to ORDUP. 5 Conclusion Asynchronous updates have the potential of increasing performance and availability while allowing autonomy.
Reference: [7] <author> A.D. Birrell, R. Levin, R.M. Needham, and M.D. Schroeder. Grapevine: </author> <title> An exercise in distributed computing. </title> <journal> Communications of ACM, </journal> <volume> 25(4) </volume> <pages> 260-274, </pages> <month> April </month> <year> 1982. </year>
Reference-contexts: ESR differs principally by (1) providing a high-level and general (ET) interface and by (2) allowing fine-grained control over inconsistency through replica control methods. Grapevine <ref> [7] </ref> is an early example of directory systems developed at Xerox. It propagated the changes between replicas periodically. Its successor, Clearinghouse, has adopted a randomized algorithm [10] for update propagation. They show that random propagation converges quickly, but needs a reliable mechanism to recover from rare failures.
Reference: [8] <author> B.T. Blaustein and C.W. Kaufman. </author> <title> Updating replicated data during communication failures. </title> <booktitle> In Proceedings of the Eleventh International Conference on Very Large Data Bases, </booktitle> <pages> pages 49-58, </pages> <address> Stockholm, </address> <month> August </month> <year> 1985. </year>
Reference-contexts: He identifies 5 classes of methods: they can be roughly equated to the methods discussed in this paper. Class A is similar to RITU overwrite; classes B and C are similar to COMMU; and classes D and E are similar to COMPE. Another example, log transformation <ref> [8] </ref> is a method proposed to speed up the merging of updates from different partitions when they reconnect. They use operation properties such as com-mutativity and overwrite to merge independent updates. If some updates cannot be merged then they try backward recovery by rolling back some updates and redoing them.
Reference: [9] <author> S.B. Davidson, H. Garcia-Molina, and D. Skeen. </author> <title> Consistency in a partitioned network. </title> <journal> ACM Computing Surveys, </journal> <volume> 17(3) </volume> <pages> 341-370, </pages> <month> September </month> <year> 1985. </year>
Reference-contexts: Without such properties, the system in effect becomes partitioned as the replicas diverge more and more from one another <ref> [9] </ref>. These important properties are provided by ESR, which is a framework of constrained inconsistency/divergence [20]. <p> Quasi-copies uses a "closeness" specification in the trigger mechanism which propagates updates to quasi-copies. Replica control methods, in contrast, constrain the degree of inconsistency of ETs directly. 4.3 Network Partition Merging Communication failures cause divergence between object copies in different partitions. Davidson et al <ref> [9] </ref> have surveyed the approaches to data replication under network partitions. They divide the approaches into two groups: pessimistic and optimistic. Pessimistic algorithms are synchronous, since they use commit protocols to maintain replica mutual-consistency.
Reference: [10] <author> A. Demers, D. Greene, C. Hauser, W. Irish, J. Lar-son, S. Shenker, H. Sturgis, D. Swinehart, and D. Terry. </author> <title> Epidemic algorithms for replicated database maintenance. </title> <booktitle> In Proceedings of the Sixth Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 1-12, </pages> <month> August </month> <year> 1987. </year>
Reference-contexts: Grapevine [7] is an early example of directory systems developed at Xerox. It propagated the changes between replicas periodically. Its successor, Clearinghouse, has adopted a randomized algorithm <ref> [10] </ref> for update propagation. They show that random propagation converges quickly, but needs a reliable mechanism to recover from rare failures. Ficus distributed file system [15] uses a two-phase flooding algorithm to detect replica propagation stability and conflicts asynchronously. However, they neither prevent nor resolve conflicts.
Reference: [11] <author> A.R. Downing, I.B. Greenberg, and J.M. Peha. OSCAR: </author> <title> An architecture for weak-consistency replication. </title> <booktitle> In Proceedings of PARBASE-90 International Conference on Databases, Parallel Architectures, and Their Applications, </booktitle> <pages> pages 350-358, </pages> <year> 1990. </year>
Reference-contexts: This is an off-line algorithm that may be useful when logs grow long in prolonged partitions. More recent work has also focussed on optimizing the work needed for log-merging. One example of such a system is OSCAR <ref> [11] </ref>. Their architecture is based on two cooperating agents, called replicators and mediators. The replicators propagate replica updates and the mediators recover from replicator failures. Three methods in OSCAR can be used by the appropriate application using the so-called weak-consistency updates: commutative and associative, overwrite, and site-sequential.
Reference: [12] <author> S.Z. Faissol. </author> <title> Operation of Distributed Database Systems Under Network Partitions. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Cali-fornia, </institution> <address> Los Angeles, </address> <year> 1981. </year>
Reference-contexts: The replica control methods used by ETs differ principally in that they allow controlled divergence while queries and updates are in progress. That is, instead of processing logs at reconnection time, our methods control divergence dynamically. An early example of such off-line algorithm work is Faissol's thesis <ref> [12] </ref>. He identifies 5 classes of methods: they can be roughly equated to the methods discussed in this paper. Class A is similar to RITU overwrite; classes B and C are similar to COMMU; and classes D and E are similar to COMPE.
Reference: [13] <author> H. Garcia-Molina and G. Wiederhold. </author> <title> Read-only transactions in a distributed database. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 7(2) </volume> <pages> 209-234, </pages> <month> June </month> <year> 1982. </year>
Reference-contexts: An early example of read-only redundancy is timestamped versions [4]. Queries that are serialized in the "past" do not block, and immutable versions can be replicated freely. Another early proposal using the idea of read-only redundancy is weak consistency <ref> [13] </ref> defined over the class of read-only transactions. A read-only transaction satisfies weak consistency if it is locally consistent, but may cause non-SR results in the global log formed by the union of local logs.
Reference: [14] <author> D.K. Gifford. </author> <title> Weighted voting for replicated data. </title> <booktitle> In Proceedings of the Seventh Symposium on Operating Systems Principles, </booktitle> <pages> pages 150-162. </pages> <address> ACM/SIGOPS, </address> <month> December </month> <year> 1979. </year>
Reference-contexts: We are concerned here with the issue of implementing these methods in a replicated system. Traditional coherency control methods, such as weighted voting <ref> [14] </ref>, update a number of replicas (e.g., write quorum) in an atomic transaction. Similarly, replica control methods apply the updates in an update ET. We say that a coherency control method is synchronous because a distributed transaction requires a commit agreement protocol to synchronize the transaction outcome.
Reference: [15] <author> R.G. Guy, J.S. Heidemann, W. Mak, T.W. Page, G.J. Popek, and D. Rothmeier. </author> <title> Implementation of the Ficus replicated file system. </title> <booktitle> In Proceedings of 1990 Usenix Summer Conference, </booktitle> <pages> pages 63-71, </pages> <address> Anaheim, CA, June 1990. </address> <publisher> Usenix. </publisher>
Reference-contexts: It propagated the changes between replicas periodically. Its successor, Clearinghouse, has adopted a randomized algorithm [10] for update propagation. They show that random propagation converges quickly, but needs a reliable mechanism to recover from rare failures. Ficus distributed file system <ref> [15] </ref> uses a two-phase flooding algorithm to detect replica propagation stability and conflicts asynchronously. However, they neither prevent nor resolve conflicts. Coda distributed file system [21] provides optimistic replication through a manual repair tool [17]. The tool supports semantics-dependent rules for automatic recovery of specific applications such as directories.
Reference: [16] <author> M. Hsu and A. Silberschatz. </author> <title> Persistent transmission and unilateral commit. </title> <booktitle> In Proceedings of Workshop on Muldatabases and Semantic Interoperability, </booktitle> <pages> pages 48-52, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: Each local system is responsible for applying its MSet and preserving internal consistency. Note that the propagation of MSets to each site is asynchronous. We assume the system maintains the unprocessed MSets in some stable storage, such as stable queues [5] and persistent pipes <ref> [16] </ref>. Each MSet is stored as an element in a stable queue. Due to the asynchronous propagation of MSets, replicas of a "logical" object can differ at any given moment. This is the source of inconsistency seen by the query ETs.
Reference: [17] <author> P. Kumar. </author> <title> Coping with conflicts in an optimistically replicated file system. </title> <booktitle> In Proceedings of the Workshop on the Management of Replicated Data, </booktitle> <pages> pages 60-64, </pages> <address> Houston, </address> <month> November </month> <year> 1990. </year> <month> IEEE/TCOS. </month>
Reference-contexts: Ficus distributed file system [15] uses a two-phase flooding algorithm to detect replica propagation stability and conflicts asynchronously. However, they neither prevent nor resolve conflicts. Coda distributed file system [21] provides optimistic replication through a manual repair tool <ref> [17] </ref>. The tool supports semantics-dependent rules for automatic recovery of specific applications such as directories. No general rules are supplied. In addition to directory/file-system propagation, asynchronous communication techniques have also been developed. An example of the latter is Lazy Replication [18].
Reference: [18] <author> R. Ladin, B. Liskov, and L. Shrira. </author> <title> Lazy replication: Exploiting the semantics of distributed services. </title> <booktitle> In Proceedings of the Ninth ACM Symposium on Principles of Distributed Computing, </booktitle> <address> Que-bec City, </address> <month> August </month> <year> 1990. </year> <month> ACM/SIGACT-SIGOPS. </month>
Reference-contexts: The tool supports semantics-dependent rules for automatic recovery of specific applications such as directories. No general rules are supplied. In addition to directory/file-system propagation, asynchronous communication techniques have also been developed. An example of the latter is Lazy Replication <ref> [18] </ref>. It provides three classes of ordered messages, plus unordered delivery. This facility is at a much lower level of abstraction than transactions and ETs. Another example is Isis [6], which provides four kinds of multicast and broadcast facilities, including causal broadcasts.
Reference: [19] <author> L. Lamport. </author> <title> Time, clocks and ordering of events in a distributed system. </title> <journal> Communications of ACM, </journal> <volume> 21(7) </volume> <pages> 558-565, </pages> <month> July </month> <year> 1978. </year>
Reference-contexts: Each site simply waits for the next MSet in the execution sequence to show up before running other MSets. Although such ordering can be generated easily by a centralized order server, sometimes true distributed control is desired. In those cases we may use a Lamport-style global timestamp <ref> [19] </ref> to mark the ordering. In that case the MSets should somehow be delivered in order, since it is not easy to see whether there is another MSet coming in with just a slightly earlier timestamp.
Reference: [20] <author> C. Pu and A. Leff. Epsilon-serializability. </author> <type> Technical Report CUCS-054-90, </type> <institution> Department of Computer Science, Columbia University, </institution> <month> December </month> <year> 1990. </year> <note> An extended abstract was submitted to PODS. </note>
Reference-contexts: In this paper we view the role of both coherency control and replica control as consistency maintenance among replicas of a given "logical" object. We therefore only discuss replica control methods: the replicated system is assumed to use standard (synchronous) concurrency control [4] or (asynchronous) divergence control methods <ref> [20] </ref> in order to maintain consistency among different objects in the system. In Section 2 we introduce the ESR terminology, model, and its properties. In Section 3, asynchronous replica control methods are described, analyzed, and are shown to provide ETs with ESR properties. <p> Without such properties, the system in effect becomes partitioned as the replicas diverge more and more from one another [9]. These important properties are provided by ESR, which is a framework of constrained inconsistency/divergence <ref> [20] </ref>. The key idea is that asynchronous updates to replicas can be done approximately atomically, i.e., updates are atomic within certain time lags, but have the same value when completed. 2.1 ESR and ETs An ET is a sequence of operations on data objects. <p> ESR is a correctness criterion that allows bounded divergence. Replica control methods can enforce different divergence bounds. ESR is a general framework of controlled inconsistency <ref> [20] </ref>; this paper has applied it within the more limited domain of replica control. Other examples of specification methods have been proposed for this domain. Wiederhold and Qian [24] have introduced the notation called identity connection to specify the constraints binding the replicas of an object.
Reference: [21] <author> M. Satyanarayanan, J. Kistler, P. Kumar, M. Okasaki, E. Siegel, and D. Steere. Coda: </author> <title> A highly available file system for a distributed workstation environment. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-39(4):447-459, </volume> <month> April </month> <year> 1990. </year>
Reference-contexts: They show that random propagation converges quickly, but needs a reliable mechanism to recover from rare failures. Ficus distributed file system [15] uses a two-phase flooding algorithm to detect replica propagation stability and conflicts asynchronously. However, they neither prevent nor resolve conflicts. Coda distributed file system <ref> [21] </ref> provides optimistic replication through a manual repair tool [17]. The tool supports semantics-dependent rules for automatic recovery of specific applications such as directories. No general rules are supplied. In addition to directory/file-system propagation, asynchronous communication techniques have also been developed. An example of the latter is Lazy Replication [18].
Reference: [22] <author> A. Sheth and P. Krishnamurthy. </author> <title> Redundant data management in Bellcore and BCC databases. </title> <type> Technical Report TM-STS-015011/1, </type> <institution> Bell Communications Research, </institution> <month> December </month> <year> 1989. </year>
Reference-contexts: The spatial consistency criteria are divided into three cases. Inconsistency is controlled by limiting either (1) the number of data items changed asynchronously, (2) the data value changed asynchronously, or (3) the number of allowed asynchronous operations. An implementation of interdependent data management is described in <ref> [22] </ref>: it essentially corresponds to ORDUP. Replica control and divergence control can implement such criteria [26]. Another specification approach is Controlled Inconsistency proposed by Barbara and Garcia-Molina [3], which generalizes their work on quasi-copies. Controlled Inconsistency specifies arithmetic consistency constraints, similar to the data value limit in interdependent data management.
Reference: [23] <author> A. Sheth and M. Rusinkiewicz. </author> <title> Management of interdependent data: Specifying dependency and consistency requirements. </title> <booktitle> In Proceedings of the Workshop on Management of Replicated Data, </booktitle> <pages> pages 133-136, </pages> <address> Houston, </address> <month> November </month> <year> 1990. </year>
Reference-contexts: Although Wiederhold and Qian propose a temporal constraint resolver [25] to implement transaction processing satisfying these specifications, it would require considerable overhead to test their satisfia-bility. Replica control methods offer more efficient execution at the price of less concurrency. Sheth and Rusinkiewicz <ref> [23] </ref> have proposed a taxonomy for interdependent data management. They separate data consistency criteria into temporal and spatial dimensions. The temporal con sistency has two kinds: eventual consistency (anal-ogous to identity connections), and lagging consistency (analogous to quasi-copies [2]). The spatial consistency criteria are divided into three cases.
Reference: [24] <author> G. Wiederhold and X. Qian. </author> <title> Modeling asynchrony in distributed databases. </title> <booktitle> In Proceedings of the Third International Conference on Data Engineering, </booktitle> <pages> pages 246-250, </pages> <month> February </month> <year> 1987. </year>
Reference-contexts: Replica control methods can enforce different divergence bounds. ESR is a general framework of controlled inconsistency [20]; this paper has applied it within the more limited domain of replica control. Other examples of specification methods have been proposed for this domain. Wiederhold and Qian <ref> [24] </ref> have introduced the notation called identity connection to specify the constraints binding the replicas of an object. They classify the update propagation into four classes: immediate updates, deferred updates, independent updates, and potentially inconsistent updates.
Reference: [25] <author> G. Wiederhold and X. Qian. </author> <title> Consistency control of replicated data in federated databases. </title> <booktitle> In Proceedings of the Workshop on Management of Replicated Data, </booktitle> <pages> pages 130-132, </pages> <address> Houston, </address> <month> November </month> <year> 1990. </year>
Reference-contexts: Wiederhold and Qian [24] have introduced the notation called identity connection to specify the constraints binding the replicas of an object. They classify the update propagation into four classes: immediate updates, deferred updates, independent updates, and potentially inconsistent updates. Although Wiederhold and Qian propose a temporal constraint resolver <ref> [25] </ref> to implement transaction processing satisfying these specifications, it would require considerable overhead to test their satisfia-bility. Replica control methods offer more efficient execution at the price of less concurrency. Sheth and Rusinkiewicz [23] have proposed a taxonomy for interdependent data management.
Reference: [26] <author> K.L. Wu, P. S. Yu, and C. Pu. </author> <title> Divergence control for epsilon-serializability. </title> <type> Technical Report CUCS-002-91, </type> <institution> Department of Computer Science, Columbia University, </institution> <month> February </month> <year> 1991. </year> <note> Also available as IBM Tech Report No. RC16598. </note>
Reference-contexts: Table 1 lists some important characteristics of each of the replica control methods discussed in the paper. We have already discussed the issue of "forwards" versus "backwards" methods. The significance of the other dimensions will be discussed as each method is analyzed. 2.4 Framework for Replica Control In <ref> [26] </ref> formal arguments are given for the assertion that divergence control methods analogous to these replica control methods maintain ESR. We are concerned here with the issue of implementing these methods in a replicated system. <p> An implementation of interdependent data management is described in [22]: it essentially corresponds to ORDUP. Replica control and divergence control can implement such criteria <ref> [26] </ref>. Another specification approach is Controlled Inconsistency proposed by Barbara and Garcia-Molina [3], which generalizes their work on quasi-copies. Controlled Inconsistency specifies arithmetic consistency constraints, similar to the data value limit in interdependent data management.
References-found: 26

