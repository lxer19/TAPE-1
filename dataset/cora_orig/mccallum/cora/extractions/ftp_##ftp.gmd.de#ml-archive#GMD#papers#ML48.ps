URL: ftp://ftp.gmd.de/ml-archive/GMD/papers/ML48.ps
Refering-URL: http://nathan.gmd.de/projects/ml/lit/mlpublist.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Cooperation of Data-driven and Model-based Induction Methods for Relational Learning  
Author: Edgar Sommer, GMD 
Date: 1993  
Note: appears in: Proceedings Multistrategy Learning Workshop  
Abstract: Inductive learning in relational domains has been shown to be intractable in general. Many approaches to this task have been suggested nevertheless; all in some way restrict the hypothesis space searched. They can be roughly divided into two groups: data-driven, where the restriction is encoded into the algorithm, and model-based, where the restrictions are made more or less explicit with some form of declarative bias. This paper describes Incy, an inductive learner that seeks to combine aspects of both approaches. Incy is initially data-driven, using examples and background knowledge to put forth and specialize hypotheses based on the "connectivity" of the data at hand. It is model-driven in that hypotheses are abstracted into rule models, which are used both for control decisions in the data-driven phase and for model-guided induction. Key Words: Inductive learning in relational domains, cooperation of data-driven and model-guided methods, implicit and declarative bias. 
Abstract-found: 1
Intro-found: 1
Reference: [Cohen 92] <author> William Cohen. </author> <title> Compiling Prior Knowledge into an Explicit Bias. </title> <editor> In Derek Sleeman and Peter Edwards (eds.), </editor> <booktitle> Proc. ML92, </booktitle> <pages> pp. 102-110, </pages> <year> 1992. </year>
Reference-contexts: Additionally, the language in which the hypotheses are expressed is restricted. Data-driven methods, such as FOIL [Quinlan 90] and GOLEM [Muggleton/Feng 90], encode this restriction into the algorithm. In Model-based systems such as RDT [Kietz/Wrobel 92], GRENDEL <ref> [Cohen 92] </ref> and CLINT [Raedt 91], the restrictions are made more or less explicit with some form of declarative bias 1 .
Reference: [Emde et al. 83] <author> Werner Emde, Christopher Ha-bel, and Claus-Rainer Rollinger. </author> <title> The Discovery of the Equator or Concept Driven Learning. </title> <booktitle> In IJCAI-83, </booktitle> <pages> pp. 455-458, </pages> <address> Los Altos, CA, 1983. </address> <publisher> Morgan Kauf-man. </publisher>
Reference-contexts: Even if none of the hy 3 The use of rule models as declarative bias goes back to <ref> [Emde et al. 83] </ref>; a very similar approach is used in [Silverstein/Pazzani 91]. potheses are acceptable, or Incy's rules do not cover a sufficiently large subset of the known examples of the learning goal, a host of rule models are produced that directly reflect the structure of the data wrt to
Reference: [Kietz 93] <author> Jorg-Uwe Kietz. </author> <title> Some Lower Bounds for the Computational Complexity of Inductive Logic Programming. </title> <booktitle> In Proceedings of European Conference of ML 1993, </booktitle> <year> 1993. </year>
Reference-contexts: 1 Introduction Inductive learning in relational domains has been shown to be intractable in general fl German National Research Center for Computer Science, AI Division (I3.KI), P.O.Box 1316, D-5205 St. Augustin 1, Germany, email eddi@gmdzi.gmd.de <ref> [Kietz 93] </ref>. Many approaches to this task have been suggested nevertheless; all in some way restrict the hypothesis space searched. This is done first by restricting the language in which examples and background knowledge may be expressed. Additionally, the language in which the hypotheses are expressed is restricted.
Reference: [Kietz/Wrobel 92] <author> Jorg-Uwe Kietz and Stefan Wrobel. </author> <title> Controlling the Complexity of Learning in Logic through Syntactic and Task-Oriented Models. </title> <editor> In Stephen Mug-gleton (ed.), </editor> <booktitle> Inductive Logic Programming, chapter 16. </booktitle> <publisher> Academic Press, </publisher> <address> Lon-don, </address> <year> 1992. </year>
Reference-contexts: Additionally, the language in which the hypotheses are expressed is restricted. Data-driven methods, such as FOIL [Quinlan 90] and GOLEM [Muggleton/Feng 90], encode this restriction into the algorithm. In Model-based systems such as RDT <ref> [Kietz/Wrobel 92] </ref>, GRENDEL [Cohen 92] and CLINT [Raedt 91], the restrictions are made more or less explicit with some form of declarative bias 1 . <p> The work reported on this paper is an attempt at combining the speed of heuristically guided data-driven methods with the variability of model-based approaches. 2 Incy A rule model is a higher order expression similar to a rule, except that predicate variables appear at the place of predicates (refer to <ref> [Kietz/Wrobel 92] </ref> for a precise definition). A rule is so seen as being an instance of a corresponding rule model, where the model's predicate variables are instantiated with specific predicate names. <p> Hypothesis formation and test The 'hypothesis' thus reached is a conjunction of facts it is now turned into a true hypothesis by systematically substituting variables for constants. Testing procedures as described in <ref> [Kietz/Wrobel 92] </ref> are applied to this hypothesis. In this process, a rule model is abstracted from the hypothesis (in analogy to abstracting a rule from a conjunction of facts, here the predicate names are turned into variables). <p> A rule model is abstracted from a hypothesis and used to test hypotheses. This call structure influences Incy's behavior in several ways: * After abstracting a hypothesis to a rule model, the new model is compared to existing models by an extension of theta-subsumption <ref> [Kietz/Wrobel 92] </ref>.Redundant, i.e. structurally equivalent models are caught at this point, and this causes Incy to backtrack (search for a different specialization or select different conjucts for the preliminary hypothesis). * If the data-driven phase should discover a rule that is already known, this is discovered during the test and specialization <p> The rule models generated during Incy's pass over data can be used in a subsequent, more stringent analysis. During this model-based pass, the models are instantiated with fitting predicates from the knowledge base <ref> [Kietz/Wrobel 92] </ref>. This may result in two different types of rules: * Rules structurally equivalent to one of those discovered during the data-driven phase: each of those initial rules can be understood as being an example for a set of rules.
Reference: [Michalski 83] <author> Ryszard S. Michalski. </author> <title> A Theory and Methodology of Inductive Learning. </title> <booktitle> In Machine Learning | An Artificial Intelligence Approach, </booktitle> <volume> volume I, </volume> <pages> pp. 83-134. </pages> <publisher> Morgan Kaufman, </publisher> <address> Los Altos, CA, </address> <year> 1983. </year>
Reference-contexts: The INDUCE algorithms, though they are applied to structured objects rather than relational concepts, can be seen as relying on a pre-classification of candidates with additional heuristics <ref> [Michalski 83] </ref>. Incy takes a more basic approach, relying only on the connectivity information represented by the graph. It tries to select a candidate which is "most linked" to the other objects in the rule, and which preferably does not introduce a new object.
Reference: [Morik et al. 93] <author> K. Morik, S. Wrobel, J.-U. Ki-etz, and W. Emde. </author> <title> Knowledge Acquisition and Machine Learning Theory, Methods, and Applications. </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1993. </year> <note> to appear. </note>
Reference: [Morik 91] <author> Katharina Morik. </author> <title> Balanced Cooperative Modeling. </title> <editor> In Ryszard Michal-ski and Gheorghe Tecuci (eds.), </editor> <booktitle> Proc. Workshop on Multistrategy Learning, </booktitle> <address> Harpers Ferry, </address> <year> 1991. </year> <note> also to appear in the Machine Learning Journal. </note>
Reference-contexts: Despite the challenge, learning relational concepts has great practical relevance, as evidenced by the ESPRIT projects Machine Learning Toolbox (MLT) and Inductive Logic Programming (ILP) funded by the European Community 2 . The Mobal system for building knowledge based applications <ref> [Morik 91] </ref>[Morik et al. 93] has been used to develop several complex and practice-oriented applications. Experience has shown that both data-driven and model-based approaches offer advantages in such a knowledge engineering context [Sommer et al. ].
Reference: [Muggleton/Feng 90] <author> Stephen Muggleton and Cao Feng. </author> <title> Efficient Induction of Logic Programs. </title> <booktitle> In Proc. First Conf. on Algorithmic Learning Theory, </booktitle> <address> Tokyo, 1990. </address> <publisher> Ohmsha Publishers. </publisher>
Reference-contexts: This is done first by restricting the language in which examples and background knowledge may be expressed. Additionally, the language in which the hypotheses are expressed is restricted. Data-driven methods, such as FOIL [Quinlan 90] and GOLEM <ref> [Muggleton/Feng 90] </ref>, encode this restriction into the algorithm. In Model-based systems such as RDT [Kietz/Wrobel 92], GRENDEL [Cohen 92] and CLINT [Raedt 91], the restrictions are made more or less explicit with some form of declarative bias 1 .
Reference: [Quinlan 90] <author> J.R. Quinlan. </author> <title> Learning Logical Definitions from Relations. </title> <journal> Machine Learning, </journal> <volume> 5(3):239 - 266, </volume> <year> 1990. </year>
Reference-contexts: This is done first by restricting the language in which examples and background knowledge may be expressed. Additionally, the language in which the hypotheses are expressed is restricted. Data-driven methods, such as FOIL <ref> [Quinlan 90] </ref> and GOLEM [Muggleton/Feng 90], encode this restriction into the algorithm. In Model-based systems such as RDT [Kietz/Wrobel 92], GRENDEL [Cohen 92] and CLINT [Raedt 91], the restrictions are made more or less explicit with some form of declarative bias 1 . <p> The candidate must be among the facts about z: foobar (x,y,z) bar (v,z) The question is: which of these is the best new conjunct? Quinlan's FOIL <ref> [Quinlan 90] </ref> algorithm, for instance, uses the "information gain" heuristic to select a candidate, i.e. its value is measured in terms of the role it plays in all known examples of the goal.
Reference: [Raedt 91] <author> Luc de Raedt. </author> <title> Interactive Concept-Learning. </title> <type> PhD thesis, </type> <institution> Kath. Univ. Leu-ven, Leuven, Belgium, </institution> <month> February </month> <year> 1991. </year>
Reference-contexts: Additionally, the language in which the hypotheses are expressed is restricted. Data-driven methods, such as FOIL [Quinlan 90] and GOLEM [Muggleton/Feng 90], encode this restriction into the algorithm. In Model-based systems such as RDT [Kietz/Wrobel 92], GRENDEL [Cohen 92] and CLINT <ref> [Raedt 91] </ref>, the restrictions are made more or less explicit with some form of declarative bias 1 . Despite the challenge, learning relational concepts has great practical relevance, as evidenced by the ESPRIT projects Machine Learning Toolbox (MLT) and Inductive Logic Programming (ILP) funded by the European Community 2 .
Reference: [Silverstein/Pazzani 91] <author> Glenn Silverstein and Michael Pazzani. </author> <title> Relational Cliches: Constraining Constructive Induction During Relational Learning. </title> <editor> In Birn-baum and Collins (eds.), </editor> <booktitle> Procs. of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pp. 203-207, </pages> <address> San Ma-teo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: A model based learner such as RDT generates hypotheses by performing these instantiations in a systematic manner with predicates from the domain at hand 3 . Rule models can and do exist indepen-dantly of a specific domain (cf. "cliches" in <ref> [Silverstein/Pazzani 91] </ref>.). Naturally, such generic models will not fit arbitrary data. Incy is learning algorithm designed to make a somewhat frivolous pass through a given domain and generate example hypotheses and rule models based on the connectivity of the specific data at hand. <p> Even if none of the hy 3 The use of rule models as declarative bias goes back to [Emde et al. 83]; a very similar approach is used in <ref> [Silverstein/Pazzani 91] </ref>. potheses are acceptable, or Incy's rules do not cover a sufficiently large subset of the known examples of the learning goal, a host of rule models are produced that directly reflect the structure of the data wrt to connectivity, i.e., which arguments of which predicates appear at which places
Reference: [Sommer et al. ] <author> E. Sommer, K. Morik, J-M. An-dre, and M. Uszynski. </author> <title> What online Machine Learning can do for Knowledge Acquisition. </title> <note> submitted. </note>
Reference-contexts: The Mobal system for building knowledge based applications [Morik 91][Morik et al. 93] has been used to develop several complex and practice-oriented applications. Experience has shown that both data-driven and model-based approaches offer advantages in such a knowledge engineering context <ref> [Sommer et al. ] </ref>. Specifically, FOIL showed great speed in passing over the data discussed there, but the resulting rules where not satisfactory in coverage 1 For a comparison of GOLEM, RDT and CLINT see [Sutlic 92] 2 P2145 and P6020 respectively.
Reference: [Sutlic 92] <author> Irma Sutlic. </author> <title> Restricting the search space in inductive logic programming systems GOLEM, MOBAL and CLINT. </title> <booktitle> In Proc. ISSEK Workshop '92, </booktitle> <year> 1992. </year>
Reference-contexts: Specifically, FOIL showed great speed in passing over the data discussed there, but the resulting rules where not satisfactory in coverage 1 For a comparison of GOLEM, RDT and CLINT see <ref> [Sutlic 92] </ref> 2 P2145 and P6020 respectively. The work reported on here is funded in part through the latter. 1 E. Sommer: Cooperation of Data-driven and Model-based Methods 2 of the goal concept.
Reference: [Vere 77] <author> Steven A. Vere. </author> <title> Induction of relational productions in the presence of background information. </title> <booktitle> In Proc. of the 5th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 349-355, </pages> <year> 1977. </year>
Reference-contexts: In the example, Incy would give preferance to bar (y,z), because bar (v,z) would introduce a new object v (Fig. 1). Vere's Thoth-pb induction method for relational productions uses association chains to selectively augment examples with background information before generalization <ref> [Vere 77] </ref>. Rather than logical induction, the topic here is finding operators that describe change in discrete scenes, similar to string rewrite rules and STRIPS operators.
References-found: 14

