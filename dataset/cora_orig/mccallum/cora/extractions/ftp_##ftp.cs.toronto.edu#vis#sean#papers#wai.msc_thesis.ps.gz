URL: ftp://ftp.cs.toronto.edu/vis/sean/papers/wai.msc_thesis.ps.gz
Refering-URL: http://www.cs.toronto.edu/vis/publications/abstracts/waiMSc.html
Root-URL: 
Title: A Computational Model for Detecting Image Changes  
Author: by Winky Yan Kei Wai c flCopyright by Winky Yan Kei Wai 
Degree: A thesis submitted in conformity with the requirements for the Degree of Master of Science Graduate Department of Computer Science, in the  
Date: 1994  
Affiliation: University of Toronto  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Allport, A., </author> <title> "Visual Attention", </title> <booktitle> in Foundations of Cognitive Science, </booktitle> <publisher> MIT Press, </publisher> <address> Cam bridge, MA, </address> <year> 1989. </year>
Reference-contexts: This type of attention capture is also known as bottom-up or exogenous control of attention [58], [59]. In the past three decades, much of the work in studying visual attention has been dedicated to goal-directed selection <ref> [1] </ref>. The study of stimulus-driven selection is relatively new but its results are gaining more consideration [21], [37].
Reference: [2] <author> Anderson, A. and Nordlund, P., </author> <title> "Modelling, Matching and Tracking for the Stereovi sion II Project", </title> <type> Technical Report TRITA-NA-P9322, </type> <institution> Royal Institute of Technology, Stockholm, Sweden, </institution> <year> 1993. </year>
Reference-contexts: There have been several pieces of work on tracking object motions from different aspects. For example, model-based tracking ([19], [25], [32] and [49]), features tracking such as corners [39], contour tracking [6], lines tracking <ref> [2] </ref>, etc. The work suggested here is a mechanism in which tracking can be done by a simple means.
Reference: [3] <author> Anderson, C. H. and Van Essen, </author> <title> "Shifter Circuits: A Computational Strategy for Dynamic Aspects of Visual Processing", </title> <booktitle> in proceedings of The National Academy of Science, USA, </booktitle> <volume> Vol. 84, </volume> <pages> p. 6297-6301, </pages> <month> September </month> <year> 1987. </year>
Reference-contexts: The focus of attention is the part of the visual field to which attention is directed. It is known that biological vision systems can shift this focus rapidly to any part of the visual field. Anderson and Van Essen <ref> [3] </ref> hypothesize the attention effect in vision systems as routing information from any restricted portion of the visual field to an arbitrary high-level centre, which is the centre for attention. <p> The shift of attention can then be achieved efficiently by a "shifter circuit" in two major phases: a series of microshifts followed by a series of macroshifts <ref> [3] </ref>. The "shifter circuit" they proposed underlies a dynamic neural alignment process. The core of this circuit is a hierarchy of cell layers. In each layer, there are two inhibitory neurons to regulate the information flow. <p> A WTA process is initiated to combine results from different resolutions prior to the recognition process. A connectionist network is used for translation-invariant object recognition using the information routed up the attentional hierarchy. Feedback connections in this connectionist network are used to prime attention. However, as in <ref> [3] </ref>, Sandon did not explain in detail the mechanism of the inhibition of information flow when ascending the attentional hierarchy. The descending control of an attention model using the selective routing hypothesis is being addressed in detail by Olshausen, Anderson and Van Essen [36]. <p> Olshausen, Anderson and Van Essen proposed a model that first remaps the window of attention onto output nodes through a dynamic routing circuit, modified from the one proposed in <ref> [3] </ref>. The weights of connections in this circuit are determined by some control blocks. They are set to achieve the effect of a WTA process such that the most salient input blob is routed to the output units. <p> Besides serving as a hypothesis for the attention mechanism in biological vision, Anderson and Van Essen suggest that the "shifter circuit" hypothesis also provides the solution to problems of motion blur [52] and binocular integration <ref> [3] </ref>. However, this "shifter circuit" scheme has no apparent control for the size and shape of the attention focus. Although Sandon's model [40] has considered multiresolution aspects, it uses several data paths which is not in the "shifter circuit's" scheme. <p> The idea of stressing the biological plausibility of a computation model is also becoming popular in the computer vision community <ref> [3] </ref>, [36], [40], [46]. Among the attentional models present in the literature, the inhibitory attentional beam model proposed by 15 Tsotsos ([45],[46]) has the flexibility of allowing input of different representations. It uses an attentional beam and also permits the regulation of the size of the focus of attention.
Reference: [4] <author> Barron, J., </author> <title> "A Survey of Approaches of Determining Optical Flow, Environmental Layout and Egomotion", </title> <type> Technical Report RBCV-TR-84-5, </type> <institution> University of Toronto, </institution> <year> 1984. </year>
Reference-contexts: The difference technique has been used in a number of works, for example, by Jain and Nagel [20]. However, when there is noise in the image, this technique may not yield satisfactory results <ref> [4] </ref>. Furthermore, we would like our computational model to have as much biological resemblance as possible. Therefore, instead of looking at raw intensity values, we consider the response of applying a difference of Gaussian (DOG) operator to the raw image.
Reference: [5] <author> Birnbaum, L., Brand, M. and Cooper, P., </author> <title> "Using Causal Scene Analysis to Direct Focus of Attention", </title> <booktitle> IEEE Workshop on Qualitative Vision, </booktitle> <address> NY, p. 23-32, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: These works have placed more emphasis on the computational aspect of the mechanism rather than stressing its function to explain the biological attention system. Birnbaum, Brand and Cooper <ref> [5] </ref> have developed a system that uses causal scene analysis to direct attention.
Reference: [6] <author> Blake, A., Curwen, R. and Zisserman A., </author> <title> "Affine-Invariant Contour Tracking With Automatic Control of Spatiotemporal Scale", </title> <booktitle> in proceedings of Fourth International Conference on Computer Vision, p. </booktitle> <pages> 66-75, </pages> <year> 1993. </year>
Reference-contexts: There have been several pieces of work on tracking object motions from different aspects. For example, model-based tracking ([19], [25], [32] and [49]), features tracking such as corners [39], contour tracking <ref> [6] </ref>, lines tracking [2], etc. The work suggested here is a mechanism in which tracking can be done by a simple means.
Reference: [7] <author> Bundesen, C., </author> <title> "A Theory of Visual Attention", </title> <journal> Psychological Review, </journal> <volume> Vol. 97, p.523 547, </volume> <year> 1990. </year>
Reference-contexts: However, there are also similarities between the study of attention capture by abrupt onset and previous work on attention. The notation of the priority-tag model and the mechanism in which abrupt onsets are processed agree with the theories of two-stage models of visual attention <ref> [7] </ref>, [8], [14], [17], [23], [46]. According to this two-stage model, objects in a visual scene are first processed by a parallel process to assess the likelihood of each object as a target.
Reference: [8] <author> Cave, K. R. and Wolfe, J. M., </author> <title> "Modelling the Role of Parallel Processing in Visual Search", </title> <journal> Cognitive Psychology, </journal> <volume> Vol. 22, </volume> <pages> p. 225-271, </pages> <year> 1990. </year>
Reference-contexts: However, there are also similarities between the study of attention capture by abrupt onset and previous work on attention. The notation of the priority-tag model and the mechanism in which abrupt onsets are processed agree with the theories of two-stage models of visual attention [7], <ref> [8] </ref>, [14], [17], [23], [46]. According to this two-stage model, objects in a visual scene are first processed by a parallel process to assess the likelihood of each object as a target. <p> In this investigation, we will derive a computational model that can detect changes from a sequence of images in which no explicit prior knowledge is required. 2.3 Summary The attention theory being developed in the area of psychology ([7], <ref> [8] </ref>, [14], [17]) and attention models in the area of computer vision ([3], [23], [46]) has one common point that attention requires a two phase process: a forward pass to compute response and to direct information to a higher-level control centre; and a backward pass to localize the focus of attention.
Reference: [9] <author> Crick, F. and Koch, C., </author> <title> "Some Reflections on Visual Awareness", </title> <journal> Symposia on Quan titative Biology, </journal> <note> Cold Spring Harbor Press, </note> <author> p. </author> <month> 953-962, </month> <year> 1990. </year> <month> 86 </month>
Reference: [10] <author> Crick, F. and Koch, C., </author> <title> "Towards a Neurobiological Theory of Consciousness", Semi nars in the Neurosciences, </title> <booktitle> p. </booktitle> <pages> 1-36, </pages> <year> 1990. </year>
Reference-contexts: Therefore, it is not clear how the "shifter circuit" mechanism can adjust the attentional window to the proper size. 2.2.2 Oscillation Tagging Models Another class of attention model that has appeared in the literature is the oscillation-based attention model. Crick and Koch ([9], <ref> [10] </ref>) suggest that selective visual attention binds the neural activity of cells through temporal tagging, which is possibly mediated by the synchronized oscillatory neuronal activity. This idea leads to a type of model that hypothesizes attention control in terms of the firing rate of neurons [35]. <p> This idea leads to a type of model that hypothesizes attention control in terms of the firing rate of neurons [35]. In the model proposed by Niebur, Koch and Rosin in [35], neurons in V1 are "temporally tagged" (via frequency modulation) with different temporal structures of its discharge <ref> [10] </ref> and generate spikes with a Poisson distribution. A "saliency map" (as described by Koch and Ullman in [23]) is presumed to exist and is added as an attentional modulation to the area V1. Oscillations of cells in V1 are then induced by the existence of a stimulus.
Reference: [11] <author> Culhane, S. M., </author> <title> "Implementation of an Attentional Prototype for Early Vision", </title> <type> Mas ter's Thesis, </type> <institution> University of Toronto, </institution> <year> 1992. </year>
Reference-contexts: Some implementations have been done based on this attention model (<ref> [11] </ref>, [12], [13], [28]) and the results are satisfactory. These implementations have experimented with Tsotsos' model of guiding attention with respect to motion [28], brightness and edges [11], [12], [13]. This thesis will explore another computation model that computes another input to Tsotsos' model, so that attention can be guided by abrupt changes. This idea is motivated by recent findings in psychology that abrupt onsets capture visual attention [58], [59], [60], [61], [63]. <p> This hierarchical structure, together with the utilization of the attentional beam, provides an implementation that can be used as a front-end in the building of a real-time vision system <ref> [11] </ref>. One of the most novel contribution of Tsotsos' model is perhaps the proposal of the integration of data-directed and task-directed attentional processing within a biologically plausible framework. <p> Another advantage of the inhibitory attentional beam model over the others is that it does not assume the existence of a "saliency map". Implementations using Tsotsos' model have examined the possibility of using brightness, edges <ref> [11] </ref> and motion [28] as input, and results are shown to be satisfactory. <p> One possible solution to this problem is to apply operators of different ranges to the image, and then pick the size that gives the maximum response after some normalization process <ref> [11] </ref>, [28], [31]. A normalization process is necessary because when the spatial extent of an operator increases, a greater area will contribute to the operator. An operator of a larger scale may have a greater response over one with a smaller scale simply because of this increase in area. <p> If a small RF has a response of , and a larger RF has a response of ", the larger RF should be chosen for a sufficiently small ". Using this idea, Culhane <ref> [11] </ref> proposes a normalization function to weight all the response from RF of different sizes. <p> The parameter will affect the asymptote of the function, while fi will affect the steepness of the first part of the function. The implementation done by Culhane <ref> [11] </ref> and Lai [28] both use Equation (3.9) 5 as the weighting function among different RF sizes and yield satisfactory results. Although this normalization function is different from the one used by Lindeberg, both functions favour response from larger scales. <p> ) and m is the number of standard deviations for the cutoff for Equation (3.2), we can express the normalization function as: W (r) = + fi (2r+1) 2 + 1 ) W () = + fi (2m+1) Empirically, setting = 10 and fi = 1:3 (as suggested by Culhane <ref> [11] </ref>) seems to yield satisfactory results for our experiments. Figure 3.4 shows such a function with = 10, fi = 1:3 and m = 2 over different values of . As analyzed by Culhane [11], increasing the value of significantly above 10 will result in only small RFs winning, while decreasing <p> = + fi (2m+1) Empirically, setting = 10 and fi = 1:3 (as suggested by Culhane <ref> [11] </ref>) seems to yield satisfactory results for our experiments. Figure 3.4 shows such a function with = 10, fi = 1:3 and m = 2 over different values of . As analyzed by Culhane [11], increasing the value of significantly above 10 will result in only small RFs winning, while decreasing the value of significantly below 10 will cause large dull RFs winning over slightly smaller but significantly brighter RFs. <p> This new rule has been proved to converge quickly both theoretically [46] and practically <ref> [11] </ref>, [28]. In addition, it has the advantage of allowing multiple winners in the competition. For our model, we will have two WTA networks, one for each type of event. Units in each network represent the normalized response from all locations and spatial scales. <p> This selected region of attention is assumed to be decided by some higher order process that chooses between the most salient "on" and "off" events. Different from other prototypes that use Tsotsos' model (such as in <ref> [11] </ref>, [28]), the input to the lowest level will be refreshed every time after a region for attention is chosen. The reason is because we are interested in abrupt changes, therefore, changes that have occurred over a certain period of time will lose their priority for attention. <p> When deciding the location and scale of the most salient event, a normalization function is required to take a balance between the difference in size and the difference in magnitude of response. The normalization function we use is the one proposed by Culhane <ref> [11] </ref>. Responses from different RF sizes are weighted by this normalization function so that a small RF with slightly greater response will not be favoured over a larger RF with slightly smaller response. <p> The nodes in each of the WTA network represent the response from every location and all spatial scales of the corresponding event type. The WTA updating rule is the one presented by Tsotsos in [48]. The same updating rule has been used in other implementations such as <ref> [11] </ref> and [28] for guiding attention through a pyramid structure. This rule has been proved to converge within a few number of iterations and has much biological resemblance. The result from initiating the two WTA networks will give a winner for "on" events and a winner for "off" events. <p> However, most attention models in the literature work with a single static image to decide the focus of attention, for example, <ref> [11] </ref>, [28], [36], [40]. The computational model we propose is one of the few attention models that research into the area of directing attention based on dynamic scenes.
Reference: [12] <author> Culhane, S. M. and Tsotsos, J. K., </author> <title> "An Attentional Prototype for Early Vision", </title> <booktitle> ECCV, p. </booktitle> <pages> 551-560, </pages> <year> 1992. </year>
Reference-contexts: Tsotsos' model uses ideas that are analogous to psychological phenomena, and it has the flexibility to allow various measurements to be the input to the model, for example, motion, brightness, edges, etc. Some implementations have been done based on this attention model ([11], <ref> [12] </ref>, [13], [28]) and the results are satisfactory. These implementations have experimented with Tsotsos' model of guiding attention with respect to motion [28], brightness and edges [11], [12], [13]. <p> Some implementations have been done based on this attention model ([11], <ref> [12] </ref>, [13], [28]) and the results are satisfactory. These implementations have experimented with Tsotsos' model of guiding attention with respect to motion [28], brightness and edges [11], [12], [13]. This thesis will explore another computation model that computes another input to Tsotsos' model, so that attention can be guided by abrupt changes. This idea is motivated by recent findings in psychology that abrupt onsets capture visual attention [58], [59], [60], [61], [63]. <p> as the ones proposed by Koch and Ullman [23] and by Tsotsos [46], that areas are inhibited once they are attended to. 2.2 Review of Relevant Literature on Attention Model The role of attention model has aroused interest in the computer vision community recently, for example, the work done in <ref> [12] </ref>, [13], [36], [40], [45], [46] all stress the importance of an attentional mechanism in a computer vision system. Biologically, attention is the process to focus neural resources on a specific region within a scene ([3], [35],[36]) and control the amount of information flow through the visual system [34]. <p> Biologically, attention is the process to focus neural resources on a specific region within a scene ([3], [35],[36]) and control the amount of information flow through the visual system [34]. Computationally, it is to direct computation resources only on the relevant parts of the image ([11], <ref> [12] </ref>, [13], [28], [40]) and 8 is necessary to make computer vision systems more tractable [45]. In this section, we present a review on some attention models that have appeared in the literature. <p> However, without prior information about structures in the image, it is not a straight forward task to decide which operator scale should be used. The problem of selecting the right scale for the operator has been addressed by researchers like Koenderink [24], Lindeberg [31],[29], [30], Culhane and Tsotsos <ref> [12] </ref> and Witkin [56]. One possible solution to this problem is to apply operators of different ranges to the image, and then pick the size that gives the maximum response after some normalization process [11], [28], [31]. <p> Therefore, the response of scale-space blobs has to be normalized according to scale. In a related work [31], Lindeberg introduces a normalization factor which approaches the square root of the scale when the scale gets large. Culhane and Tsotsos in <ref> [12] </ref> also suggest a way of selecting receptive fields (RF) among different sizes. If a small RF has a response of , and a larger RF has a response of ", the larger RF should be chosen for a sufficiently small ".
Reference: [13] <author> Culhane, S. M. and Tsotsos, J. K., </author> <title> "A Prototype for Data-Driven Visual Attention", </title> <booktitle> International Conference on Pattern Recognition, Vol. A, p. </booktitle> <pages> 36-39, </pages> <year> 1992. </year>
Reference-contexts: Tsotsos' model uses ideas that are analogous to psychological phenomena, and it has the flexibility to allow various measurements to be the input to the model, for example, motion, brightness, edges, etc. Some implementations have been done based on this attention model ([11], [12], <ref> [13] </ref>, [28]) and the results are satisfactory. These implementations have experimented with Tsotsos' model of guiding attention with respect to motion [28], brightness and edges [11], [12], [13]. <p> Some implementations have been done based on this attention model ([11], [12], <ref> [13] </ref>, [28]) and the results are satisfactory. These implementations have experimented with Tsotsos' model of guiding attention with respect to motion [28], brightness and edges [11], [12], [13]. This thesis will explore another computation model that computes another input to Tsotsos' model, so that attention can be guided by abrupt changes. This idea is motivated by recent findings in psychology that abrupt onsets capture visual attention [58], [59], [60], [61], [63]. <p> the ones proposed by Koch and Ullman [23] and by Tsotsos [46], that areas are inhibited once they are attended to. 2.2 Review of Relevant Literature on Attention Model The role of attention model has aroused interest in the computer vision community recently, for example, the work done in [12], <ref> [13] </ref>, [36], [40], [45], [46] all stress the importance of an attentional mechanism in a computer vision system. Biologically, attention is the process to focus neural resources on a specific region within a scene ([3], [35],[36]) and control the amount of information flow through the visual system [34]. <p> Biologically, attention is the process to focus neural resources on a specific region within a scene ([3], [35],[36]) and control the amount of information flow through the visual system [34]. Computationally, it is to direct computation resources only on the relevant parts of the image ([11], [12], <ref> [13] </ref>, [28], [40]) and 8 is necessary to make computer vision systems more tractable [45]. In this section, we present a review on some attention models that have appeared in the literature.
Reference: [14] <author> Duncan, J. and Humphreys, G. W., </author> <title> "Visual Search and Stimulus Similarity", </title> <journal> Psycho logical Review, </journal> <volume> Vol. 96, </volume> <pages> p. 433-458, </pages> <year> 1989. </year>
Reference-contexts: However, there are also similarities between the study of attention capture by abrupt onset and previous work on attention. The notation of the priority-tag model and the mechanism in which abrupt onsets are processed agree with the theories of two-stage models of visual attention [7], [8], <ref> [14] </ref>, [17], [23], [46]. According to this two-stage model, objects in a visual scene are first processed by a parallel process to assess the likelihood of each object as a target. This is similar to the idea of the priority tag model where each element is assigned a priority value. <p> In this investigation, we will derive a computational model that can detect changes from a sequence of images in which no explicit prior knowledge is required. 2.3 Summary The attention theory being developed in the area of psychology ([7], [8], <ref> [14] </ref>, [17]) and attention models in the area of computer vision ([3], [23], [46]) has one common point that attention requires a two phase process: a forward pass to compute response and to direct information to a higher-level control centre; and a backward pass to localize the focus of attention.
Reference: [15] <author> Fleet, D. J., </author> <title> "The Early Processing of Spatio-Temporal Visual Information", </title> <type> Master's Thesis, </type> <institution> University of Toronto, </institution> <year> 1984. </year>
Reference-contexts: By varying the ratio c s and ff c ff s , the shape of DOG (~x) would be changed. A detailed analysis of how the shape of the DOG operator is affected by these parameters is given in <ref> [15] </ref>. 18 3.2 Extending the DOG Operator to Detect Changes In the study of neurobiology, researchers have found that the receptive field 1 in human retinal cells can be subdivided into two distinct regions: the centre and the surround. <p> The main parameters for the DOG operator are c , s , ff c and ff s . Varying the value of these parameters will affect the shape of the operator, and also the size of centre and surround regions. As Fleet pointed out <ref> [15] </ref>, it is sufficient to consider the ratio s = c and ff s =ff c . By keeping the ratio s = c fixed and varying c , the peak spatial frequency that the operator can detect is shifted. <p> The analysis of Equations (3.13) and (3.16) shows that in choosing the parameters ff c and ff s , only their ratio has to be considered. This agrees with Fleet's remark in <ref> [15] </ref>, that it is the ratio ff c =ff s that causes the major difference to the response of the DOG operator.
Reference: [16] <author> Gershon, R., </author> <title> "The Use of Colour in Computational Vision", </title> <type> PhD Thesis, </type> <institution> University of Toronto, </institution> <year> 1987. </year>
Reference-contexts: Under these situations, we assume that changes caused by shadows are equally worthy of attention as other changes with respect to objects. If the effect of shadow is undesirable, some colour processing could be applied to filter out shadows <ref> [16] </ref>. Thirdly, the correspondence problem is not being addressed by the model. Even if images are acquired from a stationary robot head, some objects may have changes at different times. However, there is no mechanism to identify the correspondence of these changes.
Reference: [17] <author> Hoffman, J. E., </author> <title> "A Two-Stage Model of Visual Search", </title> <journal> Perception and Psychophysics, </journal> <volume> Vol. 25, </volume> <pages> p. 319-327, </pages> <year> 1979. </year>
Reference-contexts: However, there are also similarities between the study of attention capture by abrupt onset and previous work on attention. The notation of the priority-tag model and the mechanism in which abrupt onsets are processed agree with the theories of two-stage models of visual attention [7], [8], [14], <ref> [17] </ref>, [23], [46]. According to this two-stage model, objects in a visual scene are first processed by a parallel process to assess the likelihood of each object as a target. This is similar to the idea of the priority tag model where each element is assigned a priority value. <p> In this investigation, we will derive a computational model that can detect changes from a sequence of images in which no explicit prior knowledge is required. 2.3 Summary The attention theory being developed in the area of psychology ([7], [8], [14], <ref> [17] </ref>) and attention models in the area of computer vision ([3], [23], [46]) has one common point that attention requires a two phase process: a forward pass to compute response and to direct information to a higher-level control centre; and a backward pass to localize the focus of attention.
Reference: [18] <author> Howarth, R. and Buxton, H., </author> <title> "Selective Attention in Dynamic Vision", </title> <booktitle> in proceedings of Thirteenth International Joint Conference on Artificial Intelligence, p. </booktitle> <pages> 1579-1584, </pages> <year> 1993. </year>
Reference-contexts: One of the common features among these examples of attention guidance (and other implementations based on the four categories of attention models mentioned above) is that they had been based on static scenes. Recently, Howarth and Buxton <ref> [18] </ref> use a dynamic Bayesian network to represent interesting features in a dynamic scene and use the information of this network to direct attention. Their work has been specialized to analyze a road traffic scene to find out if overtaking of vehicles has occurred.
Reference: [19] <author> Huttenlocher, D. P., Noh, J. J. and Rucklidge, W. J., </author> <title> "Tracking Non-Rigid Objects in Complex Scenes", </title> <booktitle> in proceedings of Fourth International Conference on Computer Vision, p. </booktitle> <pages> 93-101, </pages> <year> 1993. </year>
Reference: [20] <author> Jain, R. and Nagel, H.-H., </author> <title> "On the Analysis of Accumulative Difference Pictures from Image Sequence of Real World Scenes", </title> <journal> PAMI, </journal> <volume> Vol. 1, No. 2, </volume> <pages> p. 206-214, </pages> <year> 1979. </year>
Reference-contexts: The simplest way to perform such a task is by simple differencing. That is, for each pixel, the difference of its intensity value is taken from different image frames. The difference technique has been used in a number of works, for example, by Jain and Nagel <ref> [20] </ref>. However, when there is noise in the image, this technique may not yield satisfactory results [4]. Furthermore, we would like our computational model to have as much biological resemblance as possible.
Reference: [21] <author> Jonides, J., </author> <title> "Voluntary versus Automatic Control Over the Mind's Eye's Movement", in Attentional and Performance IX, </title> <booktitle> p. </booktitle> <pages> 187-203, </pages> <year> 1981. </year> <month> 87 </month>
Reference-contexts: In the past three decades, much of the work in studying visual attention has been dedicated to goal-directed selection [1]. The study of stimulus-driven selection is relatively new but its results are gaining more consideration <ref> [21] </ref>, [37].
Reference: [22] <author> Jonides, J. and Yantis, S., </author> <title> "Uniqueness of Abrupt Visual Onset in Capturing Atten tion", </title> <journal> Perception and Psychophysics, </journal> <volume> Vol. 43, </volume> <pages> p. 346-354, </pages> <year> 1988. </year>
Reference-contexts: Since test subjects did not intend to focus their attention on abrupt onsets in these experiments, abrupt onsets are said to capture attention in a stimulus-driven fashion <ref> [22] </ref>, [58]. Experiments and data reported by Krumhansl [26], Yantis and Jones [61] also support the fact that the advantage of onset stimuli in attentional capture increases with the complexity of the decision that was required.
Reference: [23] <author> Koch, C. and Ullman, S., </author> <title> "Shifts in Selective Visual Attention: Towards the Underlying Neural Circuitry", </title> <journal> Human Neurobiology, </journal> <volume> Vol. 4, </volume> <pages> p. 219-277, </pages> <year> 1985. </year>
Reference-contexts: However, there are also similarities between the study of attention capture by abrupt onset and previous work on attention. The notation of the priority-tag model and the mechanism in which abrupt onsets are processed agree with the theories of two-stage models of visual attention [7], [8], [14], [17], <ref> [23] </ref>, [46]. According to this two-stage model, objects in a visual scene are first processed by a parallel process to assess the likelihood of each object as a target. This is similar to the idea of the priority tag model where each element is assigned a priority value. <p> In particular, the idea that the priority of an element is set to zero once it is processed, is equivalent to mechanisms in attention models, such as the ones proposed by Koch and Ullman <ref> [23] </ref> and by Tsotsos [46], that areas are inhibited once they are attended to. 2.2 Review of Relevant Literature on Attention Model The role of attention model has aroused interest in the computer vision community recently, for example, the work done in [12], [13], [36], [40], [45], [46] all stress the <p> These models can be classified into four main categories: selective routing models, oscillation tagging models, connectionist models and selective tuning models. 2.2.1 Selective Routing Models One of the earlier works in the class of selective routing models is the one suggested by Koch and Ullman <ref> [23] </ref> that uses a winner-take-all (WTA) network to localize the most active unit in some precomputed "saliency map". A second network is used in their model to relay the properties of the selected location to the central representation. <p> In the model proposed by Niebur, Koch and Rosin in [35], neurons in V1 are "temporally tagged" (via frequency modulation) with different temporal structures of its discharge [10] and generate spikes with a Poisson distribution. A "saliency map" (as described by Koch and Ullman in <ref> [23] </ref>) is presumed to exist and is added as an attentional modulation to the area V1. Oscillations of cells in V1 are then induced by the existence of a stimulus. In addition, oscillations are only expected from neurons whose receptive fields overlap with the focus of attention. <p> They must be obtained by the tuning of computing units and through the input abstraction hierarchy. As mentioned in Section 2.2.1, the class of selective routing models does not provide a mechanism for controlling the attention window. In addition, the WTA scheme proposed by Koch and Ullman <ref> [23] </ref> is not guaranteed to converge when two or more inputs are exactly equal. In light of these shortcomings, Tsotsos recently proposed the inhibitory attentional beam model ([45], [46]) to improve the Koch and Ullman scheme. <p> investigation, we will derive a computational model that can detect changes from a sequence of images in which no explicit prior knowledge is required. 2.3 Summary The attention theory being developed in the area of psychology ([7], [8], [14], [17]) and attention models in the area of computer vision ([3], <ref> [23] </ref>, [46]) has one common point that attention requires a two phase process: a forward pass to compute response and to direct information to a higher-level control centre; and a backward pass to localize the focus of attention. <p> In our model, such a decision is made by initiating a winner-take-all (WTA) process after the normalization of scales. The WTA scheme is a parallel, iterative process that can be used to pick a winner among fully interconnected units. Such a scheme has been proposed by Koch and Ullman <ref> [23] </ref> to be used as a process for shifts in selective visual attention. However, their particular form of the WTA process has computational restrictions and is biologically implausible [46].
Reference: [24] <author> Koenderink, J. J., </author> <title> "The Structure of Images", </title> <journal> Biological Cybernetics, </journal> <volume> Vol. 50, </volume> <editor> p. </editor> <volume> 363 370, </volume> <year> 1984. </year>
Reference-contexts: However, without prior information about structures in the image, it is not a straight forward task to decide which operator scale should be used. The problem of selecting the right scale for the operator has been addressed by researchers like Koenderink <ref> [24] </ref>, Lindeberg [31],[29], [30], Culhane and Tsotsos [12] and Witkin [56]. One possible solution to this problem is to apply operators of different ranges to the image, and then pick the size that gives the maximum response after some normalization process [11], [28], [31]. <p> An operator of a larger scale may have a greater response over one with a smaller scale simply because of this increase in area. Therefore, a mechanism has to be found to take a balance between the difference in size and response. While Koenderink <ref> [24] </ref> and Witkin [56] introduced the 4 The resolution of events refers to how close two events can be without interference. 23 Define ImageResolution to be the set of pixels composing the image (i.e. the size of the image).
Reference: [25] <author> Koller, D., Daniilidis, K., Thorhallson, T. and Nagel, H.-H., </author> <title> "Model-Based Object Tracking in Traffic Scenes", </title> <booktitle> ECCV, p. </booktitle> <pages> 437-452, </pages> <year> 1992. </year>
Reference-contexts: Simulations of the model show that by detecting changes in a visual scene, the proposed model can track moving objects. There have been several pieces of work on tracking object motions from different aspects. For example, model-based tracking ([19], <ref> [25] </ref>, [32] and [49]), features tracking such as corners [39], contour tracking [6], lines tracking [2], etc. The work suggested here is a mechanism in which tracking can be done by a simple means.
Reference: [26] <author> Krumhansl, C. L., </author> <title> "Abrupt Changes in Visual Stimulation Enhance Processing of Form and Location Information", </title> <journal> Perception and Psychophysics, </journal> <volume> Vol. 32, p.511-523, </volume> <year> 1982. </year>
Reference-contexts: published a series of papers which propose the idea that the abrupt appearance of an object in the visual field draws attention [58], [59], [60], [61], [62], [63]. 2.1.1 Abrupt Onsets and Attention There are several lines of research in psychology that suggest abrupt onsets subserve attention, for example, in <ref> [26] </ref>, [42], [43] and [55]. Abrupt onsets are defined to be stimuli that appear abruptly in previously blank locations of a search display. On the contrary, no-onset stimuli are revealed by removing irrelevant line segments from camouflaged stimuli that are presented before the target display [42], [59], [61]. <p> Since test subjects did not intend to focus their attention on abrupt onsets in these experiments, abrupt onsets are said to capture attention in a stimulus-driven fashion [22], [58]. Experiments and data reported by Krumhansl <ref> [26] </ref>, Yantis and Jones [61] also support the fact that the advantage of onset stimuli in attentional capture increases with the complexity of the decision that was required. However, Yantis and Jonides [63] discovered that this attentional capture by abrupt onsets can be overridden by voluntary control.
Reference: [27] <author> Ku*er, S. W. and Nicholls, J. G., </author> <title> "From Neuron to Brain", </title> <publisher> Sinauer Associates, Inc. Publishers, </publisher> <address> Sunderland, Massachusetts, </address> <year> 1976. </year>
Reference-contexts: Therefore, if they are illuminated simultaneously, they cancel each other's contribution. The DOG operator introduced in Section 3.1 uses simple linear differences to model this centre-surround interaction. In addition, neurobiologists classify receptive fields into two basic types: the on centre and off centre <ref> [27] </ref>. The on centre receptive field excites a response during the period of illumination when the spot of light is shone onto its central part.
Reference: [28] <author> Lai, Y. Z., </author> <title> "A Prototype for Finding Motion Patterns in Optical Flow", </title> <type> Master's Thesis, </type> <institution> University of Toronto, </institution> <year> 1992. </year>
Reference-contexts: Tsotsos' model uses ideas that are analogous to psychological phenomena, and it has the flexibility to allow various measurements to be the input to the model, for example, motion, brightness, edges, etc. Some implementations have been done based on this attention model ([11], [12], [13], <ref> [28] </ref>) and the results are satisfactory. These implementations have experimented with Tsotsos' model of guiding attention with respect to motion [28], brightness and edges [11], [12], [13]. This thesis will explore another computation model that computes another input to Tsotsos' model, so that attention can be guided by abrupt changes. <p> Some implementations have been done based on this attention model ([11], [12], [13], <ref> [28] </ref>) and the results are satisfactory. These implementations have experimented with Tsotsos' model of guiding attention with respect to motion [28], brightness and edges [11], [12], [13]. This thesis will explore another computation model that computes another input to Tsotsos' model, so that attention can be guided by abrupt changes. This idea is motivated by recent findings in psychology that abrupt onsets capture visual attention [58], [59], [60], [61], [63]. <p> Biologically, attention is the process to focus neural resources on a specific region within a scene ([3], [35],[36]) and control the amount of information flow through the visual system [34]. Computationally, it is to direct computation resources only on the relevant parts of the image ([11], [12], [13], <ref> [28] </ref>, [40]) and 8 is necessary to make computer vision systems more tractable [45]. In this section, we present a review on some attention models that have appeared in the literature. <p> Another advantage of the inhibitory attentional beam model over the others is that it does not assume the existence of a "saliency map". Implementations using Tsotsos' model have examined the possibility of using brightness, edges [11] and motion <ref> [28] </ref> as input, and results are shown to be satisfactory. <p> Besides, Tsotsos' model has presented a more complete theoretical framework of integrating both data-driven and task-driven attentional control. By using several processing hierarchies, the model can be easily generalized to focus attention based on different features at different times. Previous work ([11], <ref> [28] </ref>) has explored the possibility of guiding attention with respect to motion, brightness and edges using Tsotsos' model and yield satisfactory results. As recent psychological experiments reveal that abrupt onsets capture attention, we would like to derive a computational model that can detect abrupt changes. <p> One possible solution to this problem is to apply operators of different ranges to the image, and then pick the size that gives the maximum response after some normalization process [11], <ref> [28] </ref>, [31]. A normalization process is necessary because when the spatial extent of an operator increases, a greater area will contribute to the operator. An operator of a larger scale may have a greater response over one with a smaller scale simply because of this increase in area. <p> The parameter will affect the asymptote of the function, while fi will affect the steepness of the first part of the function. The implementation done by Culhane [11] and Lai <ref> [28] </ref> both use Equation (3.9) 5 as the weighting function among different RF sizes and yield satisfactory results. Although this normalization function is different from the one used by Lindeberg, both functions favour response from larger scales. <p> This new rule has been proved to converge quickly both theoretically [46] and practically [11], <ref> [28] </ref>. In addition, it has the advantage of allowing multiple winners in the competition. For our model, we will have two WTA networks, one for each type of event. Units in each network represent the normalized response from all locations and spatial scales. <p> This selected region of attention is assumed to be decided by some higher order process that chooses between the most salient "on" and "off" events. Different from other prototypes that use Tsotsos' model (such as in [11], <ref> [28] </ref>), the input to the lowest level will be refreshed every time after a region for attention is chosen. The reason is because we are interested in abrupt changes, therefore, changes that have occurred over a certain period of time will lose their priority for attention. <p> The nodes in each of the WTA network represent the response from every location and all spatial scales of the corresponding event type. The WTA updating rule is the one presented by Tsotsos in [48]. The same updating rule has been used in other implementations such as [11] and <ref> [28] </ref> for guiding attention through a pyramid structure. This rule has been proved to converge within a few number of iterations and has much biological resemblance. The result from initiating the two WTA networks will give a winner for "on" events and a winner for "off" events. <p> However, most attention models in the literature work with a single static image to decide the focus of attention, for example, [11], <ref> [28] </ref>, [36], [40]. The computational model we propose is one of the few attention models that research into the area of directing attention based on dynamic scenes. <p> However, what aspects should be considered as relevant tasks for guiding vision and how they should interact with the existing model, requires further investigation. Another aspect of Tsotsos' inhibitory attentional beam model that we have not addressed is the inhibition of the winning area. For other prototypes ([11], <ref> [28] </ref>) that use Tsotsos' model, an area is inhibited once it is selected for attention. However, under the condition that attention is guided by abrupt changes, it is not clear if it is the area in the receptive field, or the object that was chosen for attention should be inhibited.
Reference: [29] <author> Lindeberg, T., </author> <title> "Discrete Scale-Space Theory and the Scale-Space Primal Sketch", </title> <institution> Dis sertation, Computer Vision and Active Perception Laboratory, Royal Institute of Technology, Stockholm, Sweden, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: Lindeberg [30] suggests the use of scale-space blobs to find the most salient location for focus of attention. His representation makes use of a scale-space primal sketch <ref> [29] </ref> in which the significance of features is based on the appearance and stability of scale-space blobs. One of the common features among these examples of attention guidance (and other implementations based on the four categories of attention models mentioned above) is that they had been based on static scenes. <p> On the contrary, the idea of how to select the right scale is discussed by Lindeberg, Culhane and Tsotsos. The scale selection technique developed by Lindeberg makes use of a scale-space primal sketch <ref> [29] </ref>. The significance of features at different scales is reflected by objects called scale-space blobs. The extraction of significant image features is then based on the appearance and stability of these objects over scales.
Reference: [30] <author> Lindeberg, T., </author> <title> "Detecting Salient Blob-Like Image Structures and Their Scales with a Scale-Space Primal Sketch: A Method for Focus-of-Attention", </title> <institution> Royal Institute of Technology, Stockholm, Sweden, </institution> <year> 1993. </year>
Reference-contexts: The theory behind this work is that the system uses causal semantics to determine which part of the scene should be explored next such that a meaningful explanation of what is happening in the environment can be given. Lindeberg <ref> [30] </ref> suggests the use of scale-space blobs to find the most salient location for focus of attention. His representation makes use of a scale-space primal sketch [29] in which the significance of features is based on the appearance and stability of scale-space blobs. <p> However, without prior information about structures in the image, it is not a straight forward task to decide which operator scale should be used. The problem of selecting the right scale for the operator has been addressed by researchers like Koenderink [24], Lindeberg [31],[29], <ref> [30] </ref>, Culhane and Tsotsos [12] and Witkin [56]. One possible solution to this problem is to apply operators of different ranges to the image, and then pick the size that gives the maximum response after some normalization process [11], [28], [31]. <p> When comparing which scale-space blob is more important, it is necessary to take into account from what scale the blob was extracted. Experimental results demonstrated that the response of scale-space blobs actually decreases at fine scales and increases at coarser scales <ref> [30] </ref>. Therefore, the response of scale-space blobs has to be normalized according to scale. In a related work [31], Lindeberg introduces a normalization factor which approaches the square root of the scale when the scale gets large.
Reference: [31] <author> Lindeberg, T., </author> <title> "On Scale Selection for Differential Operators", </title> <type> Technical Report TRITA-NA-P9312, </type> <institution> Royal Institute of Technology, Stockholm, Sweden, </institution> <year> 1993. </year>
Reference-contexts: has been addressed by researchers like Koenderink [24], Lindeberg <ref> [31] </ref>,[29], [30], Culhane and Tsotsos [12] and Witkin [56]. One possible solution to this problem is to apply operators of different ranges to the image, and then pick the size that gives the maximum response after some normalization process [11], [28], [31]. A normalization process is necessary because when the spatial extent of an operator increases, a greater area will contribute to the operator. An operator of a larger scale may have a greater response over one with a smaller scale simply because of this increase in area. <p> Experimental results demonstrated that the response of scale-space blobs actually decreases at fine scales and increases at coarser scales [30]. Therefore, the response of scale-space blobs has to be normalized according to scale. In a related work <ref> [31] </ref>, Lindeberg introduces a normalization factor which approaches the square root of the scale when the scale gets large. Culhane and Tsotsos in [12] also suggest a way of selecting receptive fields (RF) among different sizes.
Reference: [32] <author> Lowe, D. G., </author> <title> "Robust Model-Based Motion Tracking Through the Integration of Search and Estimation", </title> <journal> International Journal of Computer Vision, </journal> <volume> Vol. 8, No. 2, </volume> <pages> p. 113-122, </pages> <year> 1992. </year>
Reference-contexts: Simulations of the model show that by detecting changes in a visual scene, the proposed model can track moving objects. There have been several pieces of work on tracking object motions from different aspects. For example, model-based tracking ([19], [25], <ref> [32] </ref> and [49]), features tracking such as corners [39], contour tracking [6], lines tracking [2], etc. The work suggested here is a mechanism in which tracking can be done by a simple means.
Reference: [33] <author> Marr, D. and Hildreth, E. C., </author> <title> "Theory of Edge Detection", </title> <journal> Proc. Roy. Soc. Lond. B, </journal> <volume> Vol. 207, </volume> <pages> p. 187-217, </pages> <year> 1980. </year> <month> 88 </month>
Reference-contexts: Finally, we will discuss limitations and assumptions of the model. 3.1 Introduction to the DOG Model The DOG model is well known in the area of computational vision. As inspired by the resemblance of its response to cells in the biological vision system, Marr and Hildreth <ref> [33] </ref> first introduced it as a spatial intensity change detector. Due to its mathematical simplicity, it is also a common filter at the early stage of visual processing. <p> Due to its mathematical simplicity, it is also a common filter at the early stage of visual processing. Other examples in which 17 the DOG operator plays an important role are in solving problems such as edge-detection (for example, in Marr and Hildreth <ref> [33] </ref>) and detailed image reconstruction (for example, in Zucker and Hummel [64]). The model is composed of the difference of two impulse response functions that model the centre and surround mechanisms of retinal cells.
Reference: [34] <author> Mozer, M. C., </author> <title> "A Connectionist Model of Selective Attention in Visual Perception", </title> <booktitle> in proceedings of Tenth Conference of the Cognitive Science Society, p. </booktitle> <pages> 195-201, </pages> <year> 1988. </year>
Reference-contexts: A widely-accepted strategy is to apply processor-intensive parallel techniques at early stages of vision systems. Selected information is then passed to later stages where time-intensive serial techniques are used. This selection of information is termed attention <ref> [34] </ref>, [36], [40]. By focusing computational resources only on the relevant parts of the image, the amount of computation will be reduced tremendously. Attention mechanisms also play a critical role in robotic systems with active vision. <p> Biologically, attention is the process to focus neural resources on a specific region within a scene ([3], [35],[36]) and control the amount of information flow through the visual system <ref> [34] </ref>. Computationally, it is to direct computation resources only on the relevant parts of the image ([11], [12], [13], [28], [40]) and 8 is necessary to make computer vision systems more tractable [45]. In this section, we present a review on some attention models that have appeared in the literature. <p> In addition, they did not address the problem of selecting the size of receptive fields as in the class of selective routing models. 2.2.3 Connectionist Models Selective attention mechanism has also aroused interest in the connectionist community. Mozer <ref> [34] </ref> suggested that an attentional mechanism can help to reduce crosstalk in a recognition network. In his work, he described an attention mechanism using the design of a connectionist model, and integrated this mechanism into a connectionist network for two-dimensional object recognition. <p> For example, it allows receptive fields of different sizes to compete in the model, thus allowing automatic adjustment of the size of focus of attention. It also allows a winning region rather than just a winning unit. The idea of using an attentional beam instead of an "attentional spotlight" <ref> [34] </ref> permits the use of a hierarchical structure in the attention model. This hierarchical structure, together with the utilization of the attentional beam, provides an implementation that can be used as a front-end in the building of a real-time vision system [11].
Reference: [35] <author> Niebur, E., Koch, C. and Rosin, C. </author> <title> "An Oscillation-Based Model for the Neuronal Basis of Attention", </title> <note> submitted to: Vision Research, </note> <year> 1992. </year>
Reference-contexts: Crick and Koch ([9], [10]) suggest that selective visual attention binds the neural activity of cells through temporal tagging, which is possibly mediated by the synchronized oscillatory neuronal activity. This idea leads to a type of model that hypothesizes attention control in terms of the firing rate of neurons <ref> [35] </ref>. In the model proposed by Niebur, Koch and Rosin in [35], neurons in V1 are "temporally tagged" (via frequency modulation) with different temporal structures of its discharge [10] and generate spikes with a Poisson distribution. <p> This idea leads to a type of model that hypothesizes attention control in terms of the firing rate of neurons <ref> [35] </ref>. In the model proposed by Niebur, Koch and Rosin in [35], neurons in V1 are "temporally tagged" (via frequency modulation) with different temporal structures of its discharge [10] and generate spikes with a Poisson distribution. <p> The tagging mechanism of attending neurons is realized by synchronous oscillation and spatial information is lost when signals within the "attentional spotlight" are transmitted onto higher cortical areas. Niebur, Koch and Rosin <ref> [35] </ref> concentrated on investigating how signals are conveyed through some areas of the visual cortex, and did not suggest in detail how the "saliency map" can be derived.
Reference: [36] <author> Olshausen, B., Anderson, C. H. and Van Essen, </author> <title> D.C., "A Neural Model of Visual At tention and Invariant Pattern Recognition", CNS Memo 18, Computation and Neural Systems Program, </title> <institution> California Institute of Technology, </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: A widely-accepted strategy is to apply processor-intensive parallel techniques at early stages of vision systems. Selected information is then passed to later stages where time-intensive serial techniques are used. This selection of information is termed attention [34], <ref> [36] </ref>, [40]. By focusing computational resources only on the relevant parts of the image, the amount of computation will be reduced tremendously. Attention mechanisms also play a critical role in robotic systems with active vision. In active vision, several views have to be obtained in order to provide additional data. <p> ones proposed by Koch and Ullman [23] and by Tsotsos [46], that areas are inhibited once they are attended to. 2.2 Review of Relevant Literature on Attention Model The role of attention model has aroused interest in the computer vision community recently, for example, the work done in [12], [13], <ref> [36] </ref>, [40], [45], [46] all stress the importance of an attentional mechanism in a computer vision system. Biologically, attention is the process to focus neural resources on a specific region within a scene ([3], [35],[36]) and control the amount of information flow through the visual system [34]. <p> Some other examples of attention model that use the selective routing hypothesis are those described by Sandon [40], Sandon and Uhr [41], and Olshausen, Anderson and Van Essen <ref> [36] </ref>. In particular, the attention model proposed by Sandon [40] is a model for translation-invariant recognition. This model uses the idea of a "shifter circuit" to gate features from a particular region of the image up the attentional hierarchy in order to achieve translation-invariant recognition. <p> However, as in [3], Sandon did not explain in detail the mechanism of the inhibition of information flow when ascending the attentional hierarchy. The descending control of an attention model using the selective routing hypothesis is being addressed in detail by Olshausen, Anderson and Van Essen <ref> [36] </ref>. In [36], the authors describe a model for attention and invariant pattern recognition. <p> However, as in [3], Sandon did not explain in detail the mechanism of the inhibition of information flow when ascending the attentional hierarchy. The descending control of an attention model using the selective routing hypothesis is being addressed in detail by Olshausen, Anderson and Van Essen <ref> [36] </ref>. In [36], the authors describe a model for attention and invariant pattern recognition. <p> In general, the property of the above connectionist model for attention is that the activities of the units in the attention module vary with time. Although the attention models suggested in <ref> [36] </ref> and [40] use the result from a neural network to adjust the weights of connection, the process of routing the focus of attention is through a hierarchal structure of cell layers. This is different from the single attention network in a connectionist model. <p> The idea of stressing the biological plausibility of a computation model is also becoming popular in the computer vision community [3], <ref> [36] </ref>, [40], [46]. Among the attentional models present in the literature, the inhibitory attentional beam model proposed by 15 Tsotsos ([45],[46]) has the flexibility of allowing input of different representations. It uses an attentional beam and also permits the regulation of the size of the focus of attention. <p> However, most attention models in the literature work with a single static image to decide the focus of attention, for example, [11], [28], <ref> [36] </ref>, [40]. The computational model we propose is one of the few attention models that research into the area of directing attention based on dynamic scenes.
Reference: [37] <author> Posner, M. I., </author> <title> "Orienting of Attention", </title> <journal> Quarterly Journal of Experimental Psychology, </journal> <volume> Vol. 32, </volume> <pages> p. 2-25, </pages> <year> 1980. </year>
Reference-contexts: In the past three decades, much of the work in studying visual attention has been dedicated to goal-directed selection [1]. The study of stimulus-driven selection is relatively new but its results are gaining more consideration [21], <ref> [37] </ref>.
Reference: [38] <author> Posner, M. I. and Cohen, Y., </author> <title> "Components of Attention", in Attention and Perfor mance X, </title> <booktitle> p. </booktitle> <pages> 531-556, </pages> <year> 1984. </year>
Reference-contexts: Furthermore, if the attention model is directing the motion of a robot head, we have to acquire a new set of images every time the head has moved. But one aspect for an attention model that we have not addressed is the issue of inhibition of return <ref> [38] </ref>. It was found from psychological experiments that there is a temporary inhibition after attention shifts away from a position. However, there have been no experiments to study how receptive fields are inhibited when attention is guided by abrupt changes.
Reference: [39] <author> Reid, I. D. and Murray, D. W., </author> <title> "Tracking Foveated Corner Clusters Using Affine Structure", </title> <booktitle> in proceedings of Fourth International Conference on Computer Vision, p. </booktitle> <pages> 76-83, </pages> <year> 1993. </year>
Reference-contexts: Simulations of the model show that by detecting changes in a visual scene, the proposed model can track moving objects. There have been several pieces of work on tracking object motions from different aspects. For example, model-based tracking ([19], [25], [32] and [49]), features tracking such as corners <ref> [39] </ref>, contour tracking [6], lines tracking [2], etc. The work suggested here is a mechanism in which tracking can be done by a simple means.
Reference: [40] <author> Sandon, P. A., </author> <title> "Stimulating Visual Attention", </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> Vol. 2, No. 3, </volume> <pages> p. 213-231, </pages> <year> 1990. </year>
Reference-contexts: A widely-accepted strategy is to apply processor-intensive parallel techniques at early stages of vision systems. Selected information is then passed to later stages where time-intensive serial techniques are used. This selection of information is termed attention [34], [36], <ref> [40] </ref>. By focusing computational resources only on the relevant parts of the image, the amount of computation will be reduced tremendously. Attention mechanisms also play a critical role in robotic systems with active vision. In active vision, several views have to be obtained in order to provide additional data. <p> proposed by Koch and Ullman [23] and by Tsotsos [46], that areas are inhibited once they are attended to. 2.2 Review of Relevant Literature on Attention Model The role of attention model has aroused interest in the computer vision community recently, for example, the work done in [12], [13], [36], <ref> [40] </ref>, [45], [46] all stress the importance of an attentional mechanism in a computer vision system. Biologically, attention is the process to focus neural resources on a specific region within a scene ([3], [35],[36]) and control the amount of information flow through the visual system [34]. <p> Biologically, attention is the process to focus neural resources on a specific region within a scene ([3], [35],[36]) and control the amount of information flow through the visual system [34]. Computationally, it is to direct computation resources only on the relevant parts of the image ([11], [12], [13], [28], <ref> [40] </ref>) and 8 is necessary to make computer vision systems more tractable [45]. In this section, we present a review on some attention models that have appeared in the literature. <p> The advantage of using such a shifter network as an attentional mechanism is that spatial relationships can be preserved while information is passed to an "attention centre" at a higher level. Some other examples of attention model that use the selective routing hypothesis are those described by Sandon <ref> [40] </ref>, Sandon and Uhr [41], and Olshausen, Anderson and Van Essen [36]. In particular, the attention model proposed by Sandon [40] is a model for translation-invariant recognition. <p> Some other examples of attention model that use the selective routing hypothesis are those described by Sandon <ref> [40] </ref>, Sandon and Uhr [41], and Olshausen, Anderson and Van Essen [36]. In particular, the attention model proposed by Sandon [40] is a model for translation-invariant recognition. This model uses the idea of a "shifter circuit" to gate features from a particular region of the image up the attentional hierarchy in order to achieve translation-invariant recognition. There are also individual data paths, each representing a different processing scale. <p> In [36], the authors describe a model for attention and invariant pattern recognition. The design of this model is similar to the one described by Sandon <ref> [40] </ref> in the sense that the focus of attention is routed to a higher level of the model and fed to a neural network for the recognition process. <p> However, this "shifter circuit" scheme has no apparent control for the size and shape of the attention focus. Although Sandon's model <ref> [40] </ref> has considered multiresolution aspects, it uses several data paths which is not in the "shifter circuit's" scheme. <p> In general, the property of the above connectionist model for attention is that the activities of the units in the attention module vary with time. Although the attention models suggested in [36] and <ref> [40] </ref> use the result from a neural network to adjust the weights of connection, the process of routing the focus of attention is through a hierarchal structure of cell layers. This is different from the single attention network in a connectionist model. <p> The idea of stressing the biological plausibility of a computation model is also becoming popular in the computer vision community [3], [36], <ref> [40] </ref>, [46]. Among the attentional models present in the literature, the inhibitory attentional beam model proposed by 15 Tsotsos ([45],[46]) has the flexibility of allowing input of different representations. It uses an attentional beam and also permits the regulation of the size of the focus of attention. <p> However, most attention models in the literature work with a single static image to decide the focus of attention, for example, [11], [28], [36], <ref> [40] </ref>. The computational model we propose is one of the few attention models that research into the area of directing attention based on dynamic scenes.
Reference: [41] <author> Sandon, P. A. and Uhr, L. M., </author> <title> "An Adaptive Model for Viewpoint-Invariant Object Recognition", </title> <booktitle> in proceedings of Tenth Conference of the Cognitive Science Society, p. </booktitle> <pages> 209-215, </pages> <year> 1988. </year>
Reference-contexts: Some other examples of attention model that use the selective routing hypothesis are those described by Sandon [40], Sandon and Uhr <ref> [41] </ref>, and Olshausen, Anderson and Van Essen [36]. In particular, the attention model proposed by Sandon [40] is a model for translation-invariant recognition.
Reference: [42] <author> Todd, J. T. and Van Gelder, P., </author> <title> "Implications of a Sustained-Transient Dichotomy for the Measurement of Human Performance", </title> <journal> Journal of Experimental Psychology: Human Perception and Performance, </journal> <volume> Vol. 5, No. 4, </volume> <pages> p. 625-638, </pages> <year> 1979. </year>
Reference-contexts: a series of papers which propose the idea that the abrupt appearance of an object in the visual field draws attention [58], [59], [60], [61], [62], [63]. 2.1.1 Abrupt Onsets and Attention There are several lines of research in psychology that suggest abrupt onsets subserve attention, for example, in [26], <ref> [42] </ref>, [43] and [55]. Abrupt onsets are defined to be stimuli that appear abruptly in previously blank locations of a search display. On the contrary, no-onset stimuli are revealed by removing irrelevant line segments from camouflaged stimuli that are presented before the target display [42], [59], [61]. <p> subserve attention, for example, in [26], <ref> [42] </ref>, [43] and [55]. Abrupt onsets are defined to be stimuli that appear abruptly in previously blank locations of a search display. On the contrary, no-onset stimuli are revealed by removing irrelevant line segments from camouflaged stimuli that are presented before the target display [42], [59], [61]. Figure 2.1 gives an example of an onset stimulus versus a no-onset stimulus. "Onset" is a temporally punctated event defined by the unexpected appearance of an element that usually signals novel stimulus information. <p> Some of the experiments that suggest abrupt onsets are detected more rapidly are described by Todd and Van Gelder <ref> [42] </ref>, Yantis and Hillstrom [59], Yantis and Jonides [62], [63]. In these experiments of visual search, it was found that when the target was an abrupt onset, the display size effect 1 was not observed. This implies that the abrupt onset always gets the priority for processing.
Reference: [43] <author> Tolhurt, D. J., </author> <title> "Sustained and Transient Channel in Human Vision", </title> <journal> Vision Research, </journal> <volume> Vol. 15, </volume> <pages> p. 1151-1155, </pages> <year> 1975. </year>
Reference-contexts: series of papers which propose the idea that the abrupt appearance of an object in the visual field draws attention [58], [59], [60], [61], [62], [63]. 2.1.1 Abrupt Onsets and Attention There are several lines of research in psychology that suggest abrupt onsets subserve attention, for example, in [26], [42], <ref> [43] </ref> and [55]. Abrupt onsets are defined to be stimuli that appear abruptly in previously blank locations of a search display. On the contrary, no-onset stimuli are revealed by removing irrelevant line segments from camouflaged stimuli that are presented before the target display [42], [59], [61].
Reference: [44] <author> Tsotsos, J. K., </author> <title> "The Complexity of Perceptual Search Tasks", </title> <booktitle> in procceedings of In ternational Joint Conference on Artificial Intelligence, p. </booktitle> <pages> 1571-1577, </pages> <year> 1989. </year>
Reference-contexts: In the field of computer vision, researchers have been facing the problem that theoretical solutions scale up badly with the problem size. Whether this problem is caused by the improper implementation of algorithms or the inherent characteristic of vision problems was not known until Tsotsos <ref> [44] </ref> investigated the complexity of vision problems. Tsotsos has published a series of papers ([44], [45], [47]) in which he stresses the importance of analyzing vision at the complexity level. <p> Since visual search is a common, if not ubiquitous, subtask of machine vision algorithms, analyzing the complex 1 ity of visual search problems gives insights to the complexity of solving visual perception problems <ref> [44] </ref>. Visual search problems can be classified into two categories: bounded (or task-directed) visual search and unbounded (or bottom-up) visual search. In bounded visual search, a target image is given to assist the search for a subset of pixels from the test image. <p> This type of search has linear complexity in terms of the number of items in the display. In unbounded visual search, a target is not given to direct the search. Subimages of various sizes have to be examined, and it has been proven that this is an NP-Complete problem <ref> [44] </ref>. Tsotsos further explains that visual search will be present at some point when decomposing any visual task into subtasks. <p> Incorporating such a decision process may lead to a mechanism that exercises the aspect of top-down control of attention, which is also absent from the present implementation. Introducing a task-guidance component is beneficial because, as suggested by Tsotsos <ref> [44] </ref>, using task-driven guidance can reduce visual search to the class of polynomial time problems. Therefore, it will greatly enhance the process of attention. However, what aspects should be considered as relevant tasks for guiding vision and how they should interact with the existing model, requires further investigation.
Reference: [45] <author> Tsotsos, J. K., </author> <title> "Analyzing Vision at the Complexity Level", </title> <journal> Behavioural and Brain Science, </journal> <volume> No. 13, </volume> <pages> p. 423-469, </pages> <year> 1990. </year> <month> 89 </month>
Reference-contexts: Whether this problem is caused by the improper implementation of algorithms or the inherent characteristic of vision problems was not known until Tsotsos [44] investigated the complexity of vision problems. Tsotsos has published a series of papers ([44], <ref> [45] </ref>, [47]) in which he stresses the importance of analyzing vision at the complexity level. According to Tsotsos, visual search is a subtask in a large number of vision problems, for example, the bottom-up versions of region grouping, shape matching, structure from motion, general alignment problem and connectionist recognition procedures. <p> by Koch and Ullman [23] and by Tsotsos [46], that areas are inhibited once they are attended to. 2.2 Review of Relevant Literature on Attention Model The role of attention model has aroused interest in the computer vision community recently, for example, the work done in [12], [13], [36], [40], <ref> [45] </ref>, [46] all stress the importance of an attentional mechanism in a computer vision system. Biologically, attention is the process to focus neural resources on a specific region within a scene ([3], [35],[36]) and control the amount of information flow through the visual system [34]. <p> Computationally, it is to direct computation resources only on the relevant parts of the image ([11], [12], [13], [28], [40]) and 8 is necessary to make computer vision systems more tractable <ref> [45] </ref>. In this section, we present a review on some attention models that have appeared in the literature.
Reference: [46] <author> Tsotsos, J. K., </author> <title> "Localizing Stimuli in a Sensory Field Using an Inhibitory Attentional Beam", </title> <type> Technical Report RBCV-TR-91-37, </type> <institution> University of Toronto, </institution> <year> 1991. </year>
Reference-contexts: The work by [36],[40],<ref> [46] </ref>,[53] are some examples of computational models with biological relevance. 1.3 Thesis Objective Among different attention models appearing in the literature, the inhibitory attentional beam model proposed by Tsotsos [46] is one that scales up nicely with problem size. Tsotsos' model uses ideas that are analogous to psychological phenomena, and it has the flexibility to allow various measurements to be the input to the model, for example, motion, brightness, edges, etc. <p> However, there are also similarities between the study of attention capture by abrupt onset and previous work on attention. The notation of the priority-tag model and the mechanism in which abrupt onsets are processed agree with the theories of two-stage models of visual attention [7], [8], [14], [17], [23], <ref> [46] </ref>. According to this two-stage model, objects in a visual scene are first processed by a parallel process to assess the likelihood of each object as a target. This is similar to the idea of the priority tag model where each element is assigned a priority value. <p> In particular, the idea that the priority of an element is set to zero once it is processed, is equivalent to mechanisms in attention models, such as the ones proposed by Koch and Ullman [23] and by Tsotsos <ref> [46] </ref>, that areas are inhibited once they are attended to. 2.2 Review of Relevant Literature on Attention Model The role of attention model has aroused interest in the computer vision community recently, for example, the work done in [12], [13], [36], [40], [45], [46] all stress the importance of an attentional <p> Koch and Ullman [23] and by Tsotsos <ref> [46] </ref>, that areas are inhibited once they are attended to. 2.2 Review of Relevant Literature on Attention Model The role of attention model has aroused interest in the computer vision community recently, for example, the work done in [12], [13], [36], [40], [45], [46] all stress the importance of an attentional mechanism in a computer vision system. Biologically, attention is the process to focus neural resources on a specific region within a scene ([3], [35],[36]) and control the amount of information flow through the visual system [34]. <p> In addition, the WTA scheme proposed by Koch and Ullman [23] is not guaranteed to converge when two or more inputs are exactly equal. In light of these shortcomings, Tsotsos recently proposed the inhibitory attentional beam model ([45], <ref> [46] </ref>) to improve the Koch and Ullman scheme. In particular, Tsotsos presented an improved WTA updating process in [46] which is proved to converge even in the case of multiple winners. The basic structure of Tsotsos' model is composed of one or more processing hierarchies and an attentional beam. <p> In light of these shortcomings, Tsotsos recently proposed the inhibitory attentional beam model ([45], <ref> [46] </ref>) to improve the Koch and Ullman scheme. In particular, Tsotsos presented an improved WTA updating process in [46] which is proved to converge even in the case of multiple winners. The basic structure of Tsotsos' model is composed of one or more processing hierarchies and an attentional beam. The lowest level of the processing hierarchies is a common input level. <p> we will derive a computational model that can detect changes from a sequence of images in which no explicit prior knowledge is required. 2.3 Summary The attention theory being developed in the area of psychology ([7], [8], [14], [17]) and attention models in the area of computer vision ([3], [23], <ref> [46] </ref>) has one common point that attention requires a two phase process: a forward pass to compute response and to direct information to a higher-level control centre; and a backward pass to localize the focus of attention. <p> The idea of stressing the biological plausibility of a computation model is also becoming popular in the computer vision community [3], [36], [40], <ref> [46] </ref>. Among the attentional models present in the literature, the inhibitory attentional beam model proposed by 15 Tsotsos ([45],[46]) has the flexibility of allowing input of different representations. It uses an attentional beam and also permits the regulation of the size of the focus of attention. <p> Such a scheme has been proposed by Koch and Ullman [23] to be used as a process for shifts in selective visual attention. However, their particular form of the WTA process has computational restrictions and is biologically implausible <ref> [46] </ref>. In light of this, Tsotsos [46] introduced a 6 The number 1 is added to make the centre of the operator fall on a pixel instead of between pixels. 26 1 1.02 1.04 1.06 1.08 1.1 W () new WTA updating rule that is more biologically plausible. <p> Such a scheme has been proposed by Koch and Ullman [23] to be used as a process for shifts in selective visual attention. However, their particular form of the WTA process has computational restrictions and is biologically implausible <ref> [46] </ref>. In light of this, Tsotsos [46] introduced a 6 The number 1 is added to make the centre of the operator fall on a pixel instead of between pixels. 26 1 1.02 1.04 1.06 1.08 1.1 W () new WTA updating rule that is more biologically plausible. <p> This new rule has been proved to converge quickly both theoretically <ref> [46] </ref> and practically [11], [28]. In addition, it has the advantage of allowing multiple winners in the competition. For our model, we will have two WTA networks, one for each type of event. Units in each network represent the normalized response from all locations and spatial scales. <p> This is parallel to the idea of choosing among the winner of "on" and "off" events for attention. A thorough discussion of how to combine bottom-up and task-directed information in attention control can be found in Tsotsos <ref> [46] </ref>, and is beyond the scope of this thesis.
Reference: [47] <author> Tsotsos, J. K., </author> <title> "On the Relative Complexity of Active vs. Passive Visual Search", </title> <journal> International Journal of Computer Vision, 7:2, </journal> <volume> p. </volume> <pages> 127-141, </pages> <year> 1992. </year>
Reference-contexts: Whether this problem is caused by the improper implementation of algorithms or the inherent characteristic of vision problems was not known until Tsotsos [44] investigated the complexity of vision problems. Tsotsos has published a series of papers ([44], [45], <ref> [47] </ref>) in which he stresses the importance of analyzing vision at the complexity level. According to Tsotsos, visual search is a subtask in a large number of vision problems, for example, the bottom-up versions of region grouping, shape matching, structure from motion, general alignment problem and connectionist recognition procedures. <p> Tsotsos further explains that visual search will be present at some point when decomposing any visual task into subtasks. Since more complex visual tasks will have complexity consistent with the complexity of their worst subtask, it can be concluded that vision problems, in their most general form, are NP-Complete <ref> [47] </ref>. <p> With several views, it is believed that 2 problems that are due to viewpoint-related ambiguities, occlusions and coincidences can be solved [54]. Attention, in the application for active vision, can be used as part of the intelligent control for the data acquisition process <ref> [47] </ref>. The idea of incorporating an attentional mechanism into computer vision systems agrees with results in biology and psychology that humans can attend to the relevant and ignore the irrelevant.
Reference: [48] <author> Tsotsos, J. K., </author> <title> "An Inhibitory Beam for Attentional Selection", in Spatial Vision for Humans and Robots, </title> <publisher> Cambridge University Press, </publisher> <year> 1993. </year>
Reference-contexts: For our model, we will have two WTA networks, one for each type of event. Units in each network represent the normalized response from all locations and spatial scales. A winner is determined from each WTA network using the updating rule described by Tsotsos <ref> [48] </ref>. The most salient "on" and "off" event can then be represented by the winner from each of the networks respectively. 3.5 Determining Parameter Values In this section, we will look at the issue of choosing proper parameters for the DOG operator. <p> The nodes in each of the WTA network represent the response from every location and all spatial scales of the corresponding event type. The WTA updating rule is the one presented by Tsotsos in <ref> [48] </ref>. The same updating rule has been used in other implementations such as [11] and [28] for guiding attention through a pyramid structure. This rule has been proved to converge within a few number of iterations and has much biological resemblance.
Reference: [49] <author> Ueda, N. and Mase, K., </author> <title> "Tracking Moving Contours Using Energy-Minimizing Elastic Contour Models", </title> <booktitle> ECCV, p. </booktitle> <pages> 453-457, </pages> <year> 1992. </year>
Reference-contexts: Simulations of the model show that by detecting changes in a visual scene, the proposed model can track moving objects. There have been several pieces of work on tracking object motions from different aspects. For example, model-based tracking ([19], [25], [32] and <ref> [49] </ref>), features tracking such as corners [39], contour tracking [6], lines tracking [2], etc. The work suggested here is a mechanism in which tracking can be done by a simple means.
Reference: [50] <author> Ullman, S., </author> <title> "On Visual Detection of Light Sources", </title> <journal> Biological Cybernetics, </journal> <volume> Vol. 21, </volume> <pages> p. 205-212, </pages> <year> 1976. </year>
Reference-contexts: Furthermore, when the input image sequence presented to the model has changes caused by motions of objects, it is similar to the image sequences Ullman <ref> [50] </ref> used to study apparent motion 1 . Apparent motion is produced when two stimuli are presented in a properly timed succession such that a clear motion from the first to the second is perceived [51].
Reference: [51] <author> Ullman, S., </author> <title> "The Interpretation of Visual Motion", </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA and London, England, </address> <year> 1979. </year>
Reference-contexts: Apparent motion is produced when two stimuli are presented in a properly timed succession such that a clear motion from the first to the second is perceived <ref> [51] </ref>. As our model can detect the new positions of objects, it can be used as some preliminary stage to collect information related to apparent motion. This will particularly be useful to algorithms that require solving for motion correspondence.
Reference: [52] <author> Van Essen, D. C. and Anderson, C. H., </author> <title> "Reference Frames and Dynamic Remapping Process in Vision", in Computational Neuroscience, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, p. 278-294, </address> <year> 1990. </year>
Reference-contexts: Furthermore, the shifting process is controlled by inhibitory neurons that inhibit or excite the connection between cells. Besides serving as a hypothesis for the attention mechanism in biological vision, Anderson and Van Essen suggest that the "shifter circuit" hypothesis also provides the solution to problems of motion blur <ref> [52] </ref> and binocular integration [3]. However, this "shifter circuit" scheme has no apparent control for the size and shape of the attention focus. Although Sandon's model [40] has considered multiresolution aspects, it uses several data paths which is not in the "shifter circuit's" scheme.
Reference: [53] <author> Van Essen, D. C., Anderson, C. H., and Felleman, D. J., </author> <title> "Information Processing in the Primate Visual System: An Integrated Systems Perspective", </title> <journal> Science, </journal> <volume> Vol. 255, </volume> <pages> p. 419-423, </pages> <year> 1992. </year>
Reference: [54] <author> Wilkes, D., </author> <title> "Active Object Recognition", </title> <type> PhD Thesis, </type> <institution> University of Toronto, </institution> <year> 1994. </year>
Reference-contexts: Attention mechanisms also play a critical role in robotic systems with active vision. In active vision, several views have to be obtained in order to provide additional data. With several views, it is believed that 2 problems that are due to viewpoint-related ambiguities, occlusions and coincidences can be solved <ref> [54] </ref>. Attention, in the application for active vision, can be used as part of the intelligent control for the data acquisition process [47].
Reference: [55] <author> Wilson, H. R., </author> <title> "Quantitative Characterization of Two Types of Line-Spread Function Near the Fovea", </title> <journal> Vision Research, </journal> <volume> Vol. 18, </volume> <pages> p. 971-981, </pages> <year> 1978. </year>
Reference-contexts: papers which propose the idea that the abrupt appearance of an object in the visual field draws attention [58], [59], [60], [61], [62], [63]. 2.1.1 Abrupt Onsets and Attention There are several lines of research in psychology that suggest abrupt onsets subserve attention, for example, in [26], [42], [43] and <ref> [55] </ref>. Abrupt onsets are defined to be stimuli that appear abruptly in previously blank locations of a search display. On the contrary, no-onset stimuli are revealed by removing irrelevant line segments from camouflaged stimuli that are presented before the target display [42], [59], [61].
Reference: [56] <author> Witkin, A. P., </author> <title> "Scale-Space Filtering", </title> <booktitle> in proceedings of Eighth International Joint Conference on Artificial Intelligence, p. </booktitle> <pages> 1019-1022, </pages> <year> 1983. </year>
Reference-contexts: The problem of selecting the right scale for the operator has been addressed by researchers like Koenderink [24], Lindeberg [31],[29], [30], Culhane and Tsotsos [12] and Witkin <ref> [56] </ref>. One possible solution to this problem is to apply operators of different ranges to the image, and then pick the size that gives the maximum response after some normalization process [11], [28], [31]. <p> An operator of a larger scale may have a greater response over one with a smaller scale simply because of this increase in area. Therefore, a mechanism has to be found to take a balance between the difference in size and response. While Koenderink [24] and Witkin <ref> [56] </ref> introduced the 4 The resolution of events refers to how close two events can be without interference. 23 Define ImageResolution to be the set of pixels composing the image (i.e. the size of the image). Scale S represents a pair of values for c and s .
Reference: [57] <author> Yantis, S., </author> <title> "Stimulus-Driven Attentional Capture", Current Directions in Psychological Science, </title> <publisher> in press. </publisher>
Reference-contexts: It is widely believed that human visual attention capture can be classified into two distinct ways: goal-directed attentional guidance and stimulus-driven attentional capture [58], <ref> [57] </ref>. For the former case, observers are able to control what regions or objects in the visual field are selected for further visual processing. Attention is allocated based on the task to be performed or knowledge about the environment. <p> In addition, these features are considered to direct attention only when they are adopted into the attentional set of observers as singletons ([22], <ref> [57] </ref>) while abrupt onset is unique in the content of attention capture in a bottom-up fashion [58]. Some of the experiments that suggest abrupt onsets are detected more rapidly are described by Todd and Van Gelder [42], Yantis and Hillstrom [59], Yantis and Jonides [62], [63].
Reference: [58] <author> Yantis, S., </author> <title> "Observation: Stimulus-Driven Attentional Capture", Journal of Experi mental Psychology: Human Perception and Performance, </title> <booktitle> p. </booktitle> <pages> 676-681, </pages> <month> June </month> <year> 1993. </year> <month> 90 </month>
Reference-contexts: This thesis will explore another computation model that computes another input to Tsotsos' model, so that attention can be guided by abrupt changes. This idea is motivated by recent findings in psychology that abrupt onsets capture visual attention <ref> [58] </ref>, [59], [60], [61], [63]. We will concentrate on the derivation of a computational model that can detect interesting changes in a visual scene. <p> It is widely believed that human visual attention capture can be classified into two distinct ways: goal-directed attentional guidance and stimulus-driven attentional capture <ref> [58] </ref>, [57]. For the former case, observers are able to control what regions or objects in the visual field are selected for further visual processing. Attention is allocated based on the task to be performed or knowledge about the environment. This is also called top-down or endogenous control of attention [58], <p> <ref> [58] </ref>, [57]. For the former case, observers are able to control what regions or objects in the visual field are selected for further visual processing. Attention is allocated based on the task to be performed or knowledge about the environment. This is also called top-down or endogenous control of attention [58], [59]. For the case of stimulus-driven attentional capture, attention is directed by properties of stimuli. Attention may be drawn to objects or areas that are irrelevant to the observer's task. This type of attention capture is also known as bottom-up or exogenous control of attention [58], [59]. <p> endogenous control of attention <ref> [58] </ref>, [59]. For the case of stimulus-driven attentional capture, attention is directed by properties of stimuli. Attention may be drawn to objects or areas that are irrelevant to the observer's task. This type of attention capture is also known as bottom-up or exogenous control of attention [58], [59]. In the past three decades, much of the work in studying visual attention has been dedicated to goal-directed selection [1]. The study of stimulus-driven selection is relatively new but its results are gaining more consideration [21], [37]. <p> Among the new ideas of stimulus-driven attention, Yantis and several co-authors published a series of papers which propose the idea that the abrupt appearance of an object in the visual field draws attention <ref> [58] </ref>, [59], [60], [61], [62], [63]. 2.1.1 Abrupt Onsets and Attention There are several lines of research in psychology that suggest abrupt onsets subserve attention, for example, in [26], [42], [43] and [55]. <p> In addition, these features are considered to direct attention only when they are adopted into the attentional set of observers as singletons ([22], [57]) while abrupt onset is unique in the content of attention capture in a bottom-up fashion <ref> [58] </ref>. Some of the experiments that suggest abrupt onsets are detected more rapidly are described by Todd and Van Gelder [42], Yantis and Hillstrom [59], Yantis and Jonides [62], [63]. <p> Moreover, the response time to identify an abrupt onset is independent of the defining and reported attributes of the target <ref> [58] </ref>, and also of their identity and position [63]. Since test subjects did not intend to focus their attention on abrupt onsets in these experiments, abrupt onsets are said to capture attention in a stimulus-driven fashion [22], [58]. <p> abrupt onset is independent of the defining and reported attributes of the target <ref> [58] </ref>, and also of their identity and position [63]. Since test subjects did not intend to focus their attention on abrupt onsets in these experiments, abrupt onsets are said to capture attention in a stimulus-driven fashion [22], [58]. Experiments and data reported by Krumhansl [26], Yantis and Jones [61] also support the fact that the advantage of onset stimuli in attentional capture increases with the complexity of the decision that was required.
Reference: [59] <author> Yantis, S. and Hillstrom, A. P., </author> <title> "Stimulus-Driven Attentional Capture: Evidence From Equiluminant Visual Objects", Journal of Experimental Psychology: Human Perception Performance, </title> <publisher> in press. </publisher>
Reference-contexts: This thesis will explore another computation model that computes another input to Tsotsos' model, so that attention can be guided by abrupt changes. This idea is motivated by recent findings in psychology that abrupt onsets capture visual attention [58], <ref> [59] </ref>, [60], [61], [63]. We will concentrate on the derivation of a computational model that can detect interesting changes in a visual scene. <p> For the former case, observers are able to control what regions or objects in the visual field are selected for further visual processing. Attention is allocated based on the task to be performed or knowledge about the environment. This is also called top-down or endogenous control of attention [58], <ref> [59] </ref>. For the case of stimulus-driven attentional capture, attention is directed by properties of stimuli. Attention may be drawn to objects or areas that are irrelevant to the observer's task. This type of attention capture is also known as bottom-up or exogenous control of attention [58], [59]. <p> control of attention [58], <ref> [59] </ref>. For the case of stimulus-driven attentional capture, attention is directed by properties of stimuli. Attention may be drawn to objects or areas that are irrelevant to the observer's task. This type of attention capture is also known as bottom-up or exogenous control of attention [58], [59]. In the past three decades, much of the work in studying visual attention has been dedicated to goal-directed selection [1]. The study of stimulus-driven selection is relatively new but its results are gaining more consideration [21], [37]. <p> Among the new ideas of stimulus-driven attention, Yantis and several co-authors published a series of papers which propose the idea that the abrupt appearance of an object in the visual field draws attention [58], <ref> [59] </ref>, [60], [61], [62], [63]. 2.1.1 Abrupt Onsets and Attention There are several lines of research in psychology that suggest abrupt onsets subserve attention, for example, in [26], [42], [43] and [55]. Abrupt onsets are defined to be stimuli that appear abruptly in previously blank locations of a search display. <p> Abrupt onsets are defined to be stimuli that appear abruptly in previously blank locations of a search display. On the contrary, no-onset stimuli are revealed by removing irrelevant line segments from camouflaged stimuli that are presented before the target display [42], <ref> [59] </ref>, [61]. Figure 2.1 gives an example of an onset stimulus versus a no-onset stimulus. "Onset" is a temporally punctated event defined by the unexpected appearance of an element that usually signals novel stimulus information. <p> Some of the experiments that suggest abrupt onsets are detected more rapidly are described by Todd and Van Gelder [42], Yantis and Hillstrom <ref> [59] </ref>, Yantis and Jonides [62], [63]. In these experiments of visual search, it was found that when the target was an abrupt onset, the display size effect 1 was not observed. This implies that the abrupt onset always gets the priority for processing. <p> The experiments described above enunciate that abrupt onsets capture attention. However, it was not clear if attention was drawn by other attributes that accompany the appear 7 ance of the abrupt onset. In <ref> [59] </ref>, Yantis and Hillstrom argued that attentional capture by abrupt onset is triggered by the appearance of a new object in the visual scene. <p> We will present results in simulating our model to find changes with respect to brightness and motion. However, the derivation of the computational model is independent of the input representation. Finally, it is worth noting that although psychological experiments conducted by Yantis et al. ([58], <ref> [59] </ref>, [60], [61] [62], [63]) provide the novel idea that abrupt onsets capture attention, their experiments do not require head movements. That is, the test subjects are asked to keep their head position fixed, and attend to different elements only by eye movements. <p> As discussed in Chapter 3, the thresholds of the computational model depends on the maximum response of on and off-DOG operators, which is determined from the maximum and minimum intensity values. The results we obtain from the model are, therefore, luminance dependent. Although Yantis and Hillstrom <ref> [59] </ref> have demonstrated that luminance change is not required to reveal an abrupt onset, there are no experiments to examine how the degree of abruptness can be measured. Our model suggests that the abruptness of an element is measured by a change in pixel intensity.
Reference: [60] <author> Yantis, S. and Johnson, D. N., </author> <title> "Mechanisms of Attention Priority ", Journal of Exper imental Psychology: </title> <journal> Human Perception and Performance, </journal> <volume> Vol. 16, No. 4, </volume> <pages> p. 812-825, </pages> <year> 1990. </year>
Reference-contexts: This thesis will explore another computation model that computes another input to Tsotsos' model, so that attention can be guided by abrupt changes. This idea is motivated by recent findings in psychology that abrupt onsets capture visual attention [58], [59], <ref> [60] </ref>, [61], [63]. We will concentrate on the derivation of a computational model that can detect interesting changes in a visual scene. <p> Among the new ideas of stimulus-driven attention, Yantis and several co-authors published a series of papers which propose the idea that the abrupt appearance of an object in the visual field draws attention [58], [59], <ref> [60] </ref>, [61], [62], [63]. 2.1.1 Abrupt Onsets and Attention There are several lines of research in psychology that suggest abrupt onsets subserve attention, for example, in [26], [42], [43] and [55]. Abrupt onsets are defined to be stimuli that appear abruptly in previously blank locations of a search display. <p> Features such as colour or orientation are different from an abrupt onset in the sense that they are present as long as the object possessing them is present <ref> [60] </ref>. In addition, these features are considered to direct attention only when they are adopted into the attentional set of observers as singletons ([22], [57]) while abrupt onset is unique in the content of attention capture in a bottom-up fashion [58]. <p> These pieces of evidence reveal that attention captured by abrupt onsets is not strongly automatic and can be avoided at will. Other experiments were performed by Yantis and Johnson <ref> [60] </ref> to study attentional capture when several abrupt onsets were present in a search display. It was found that when multiple onset elements exist, a random number of abrupt onsets, which was affected by the search time, were processed before all other elements. <p> We will present results in simulating our model to find changes with respect to brightness and motion. However, the derivation of the computational model is independent of the input representation. Finally, it is worth noting that although psychological experiments conducted by Yantis et al. ([58], [59], <ref> [60] </ref>, [61] [62], [63]) provide the novel idea that abrupt onsets capture attention, their experiments do not require head movements. That is, the test subjects are asked to keep their head position fixed, and attend to different elements only by eye movements.
Reference: [61] <author> Yantis, S. and Jones, E., </author> <title> "Mechanisms of Attention Selection: Temporally Modulated Priority Tags", </title> <journal> Perception and Psychophysics, </journal> <volume> 50(2), p.166-178, </volume> <year> 1991. </year>
Reference-contexts: This thesis will explore another computation model that computes another input to Tsotsos' model, so that attention can be guided by abrupt changes. This idea is motivated by recent findings in psychology that abrupt onsets capture visual attention [58], [59], [60], <ref> [61] </ref>, [63]. We will concentrate on the derivation of a computational model that can detect interesting changes in a visual scene. <p> Among the new ideas of stimulus-driven attention, Yantis and several co-authors published a series of papers which propose the idea that the abrupt appearance of an object in the visual field draws attention [58], [59], [60], <ref> [61] </ref>, [62], [63]. 2.1.1 Abrupt Onsets and Attention There are several lines of research in psychology that suggest abrupt onsets subserve attention, for example, in [26], [42], [43] and [55]. Abrupt onsets are defined to be stimuli that appear abruptly in previously blank locations of a search display. <p> Abrupt onsets are defined to be stimuli that appear abruptly in previously blank locations of a search display. On the contrary, no-onset stimuli are revealed by removing irrelevant line segments from camouflaged stimuli that are presented before the target display [42], [59], <ref> [61] </ref>. Figure 2.1 gives an example of an onset stimulus versus a no-onset stimulus. "Onset" is a temporally punctated event defined by the unexpected appearance of an element that usually signals novel stimulus information. <p> Since test subjects did not intend to focus their attention on abrupt onsets in these experiments, abrupt onsets are said to capture attention in a stimulus-driven fashion [22], [58]. Experiments and data reported by Krumhansl [26], Yantis and Jones <ref> [61] </ref> also support the fact that the advantage of onset stimuli in attentional capture increases with the complexity of the decision that was required. However, Yantis and Jonides [63] discovered that this attentional capture by abrupt onsets can be overridden by voluntary control. <p> After the high priority elements were processed, the rest of the elements in the display were searched by a serial process. To describe this phenomenon, Yantis and Jones <ref> [61] </ref> proposed the temporally decaying priority tag model. According to this model, every element is associated with a priority tag. In order to be considered as a high-priority element, the priority value of an element has to exceed a certain threshold. <p> We will present results in simulating our model to find changes with respect to brightness and motion. However, the derivation of the computational model is independent of the input representation. Finally, it is worth noting that although psychological experiments conducted by Yantis et al. ([58], [59], [60], <ref> [61] </ref> [62], [63]) provide the novel idea that abrupt onsets capture attention, their experiments do not require head movements. That is, the test subjects are asked to keep their head position fixed, and attend to different elements only by eye movements.
Reference: [62] <author> Yantis, S. and Jonides, J., </author> <title> "Abrupt Visual Onsets and Selective Attention: Evidence from Visual Search ", Journal of Experimental Psychology: </title> <journal> Human Perception and Performance, </journal> <volume> Vol. 10, No. 5, </volume> <pages> p. 601-621, </pages> <year> 1984. </year>
Reference-contexts: Among the new ideas of stimulus-driven attention, Yantis and several co-authors published a series of papers which propose the idea that the abrupt appearance of an object in the visual field draws attention [58], [59], [60], [61], <ref> [62] </ref>, [63]. 2.1.1 Abrupt Onsets and Attention There are several lines of research in psychology that suggest abrupt onsets subserve attention, for example, in [26], [42], [43] and [55]. Abrupt onsets are defined to be stimuli that appear abruptly in previously blank locations of a search display. <p> Some of the experiments that suggest abrupt onsets are detected more rapidly are described by Todd and Van Gelder [42], Yantis and Hillstrom [59], Yantis and Jonides <ref> [62] </ref>, [63]. In these experiments of visual search, it was found that when the target was an abrupt onset, the display size effect 1 was not observed. This implies that the abrupt onset always gets the priority for processing. <p> We will present results in simulating our model to find changes with respect to brightness and motion. However, the derivation of the computational model is independent of the input representation. Finally, it is worth noting that although psychological experiments conducted by Yantis et al. ([58], [59], [60], [61] <ref> [62] </ref>, [63]) provide the novel idea that abrupt onsets capture attention, their experiments do not require head movements. That is, the test subjects are asked to keep their head position fixed, and attend to different elements only by eye movements.
Reference: [63] <author> Yantis, S. and Jonides, J., </author> <title> "Abrupt Visual Onsets and Selective Attention: Voluntary Versus Automatic Allocation", </title> <journal> Journal of Experimental Psychology: Human Perception and Performance, </journal> <volume> Vol. 16, No. 1, </volume> <pages> p. 121-134, </pages> <year> 1990. </year>
Reference-contexts: This thesis will explore another computation model that computes another input to Tsotsos' model, so that attention can be guided by abrupt changes. This idea is motivated by recent findings in psychology that abrupt onsets capture visual attention [58], [59], [60], [61], <ref> [63] </ref>. We will concentrate on the derivation of a computational model that can detect interesting changes in a visual scene. <p> Among the new ideas of stimulus-driven attention, Yantis and several co-authors published a series of papers which propose the idea that the abrupt appearance of an object in the visual field draws attention [58], [59], [60], [61], [62], <ref> [63] </ref>. 2.1.1 Abrupt Onsets and Attention There are several lines of research in psychology that suggest abrupt onsets subserve attention, for example, in [26], [42], [43] and [55]. Abrupt onsets are defined to be stimuli that appear abruptly in previously blank locations of a search display. <p> Some of the experiments that suggest abrupt onsets are detected more rapidly are described by Todd and Van Gelder [42], Yantis and Hillstrom [59], Yantis and Jonides [62], <ref> [63] </ref>. In these experiments of visual search, it was found that when the target was an abrupt onset, the display size effect 1 was not observed. This implies that the abrupt onset always gets the priority for processing. <p> Moreover, the response time to identify an abrupt onset is independent of the defining and reported attributes of the target [58], and also of their identity and position <ref> [63] </ref>. Since test subjects did not intend to focus their attention on abrupt onsets in these experiments, abrupt onsets are said to capture attention in a stimulus-driven fashion [22], [58]. <p> Experiments and data reported by Krumhansl [26], Yantis and Jones [61] also support the fact that the advantage of onset stimuli in attentional capture increases with the complexity of the decision that was required. However, Yantis and Jonides <ref> [63] </ref> discovered that this attentional capture by abrupt onsets can be overridden by voluntary control. When an effective cue is provided for the location of the target, attention of test subjects will be allocated to the cued position, rather than a position containing an abrupt onset. <p> We will present results in simulating our model to find changes with respect to brightness and motion. However, the derivation of the computational model is independent of the input representation. Finally, it is worth noting that although psychological experiments conducted by Yantis et al. ([58], [59], [60], [61] [62], <ref> [63] </ref>) provide the novel idea that abrupt onsets capture attention, their experiments do not require head movements. That is, the test subjects are asked to keep their head position fixed, and attend to different elements only by eye movements.
Reference: [64] <author> Zucker, S. W. and Hummel, R. A., </author> <title> "Receptive Fields and the Reconstruction of Visual Information", </title> <institution> McGill University Computer Vision and Robotics Laboratory Technical Report 83-17, </institution> <year> 1983. </year> <month> 91 </month>
Reference-contexts: Other examples in which 17 the DOG operator plays an important role are in solving problems such as edge-detection (for example, in Marr and Hildreth [33]) and detailed image reconstruction (for example, in Zucker and Hummel <ref> [64] </ref>). The model is composed of the difference of two impulse response functions that model the centre and surround mechanisms of retinal cells.
References-found: 64

