URL: http://www.medg.lcs.mit.edu/ftp/mpf/RAS-paper.ps
Refering-URL: http://www.medg.lcs.mit.edu/ftp/mpf/
Root-URL: 
Email: Email: mpf@lcs.mit.edu 1  
Title: Rational abstract search  
Author: Michael P. Frank 
Affiliation: MIT Lab for Computer Science  
Date: June 9, 1993 1  June 9, 1993  
Note: Rational abstract search  Draft,  
Abstract: Computer game-playing (CGP) is potentially a good arena for the investigation of planning techniques. However, most CGP methods developed so far take a very limited view of planning and reasoning. Specifically, they focus on state-space search, to the exclusion of more abstract kinds of reasoning about the future. In this paper, I motivate the use of abstraction in game-playing, describe various kinds of abstraction that might be useful in game-playing and planning, and show how they can all be subsumed under a unifying definition of abstractions. I propose a methodology for abstraction research that involves translating existing CGP methods into a language of abstraction networks before trying to generalize those methods to work with a variety of types of abstractions. I then summarize the results of my masters thesis work, in progress, on applying decision-theoretic techniques to do effective and efficient reasoning within the abstraction-network framework. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Eric B. Baum and Warren D. Smith. </author> <title> Best play for imperfect players and game tree search. </title> <type> Draft report, </type> <institution> NEC Research Institute, </institution> <month> May </month> <year> 1993. </year> <note> (Available for anonymous FTP from external.nj.nec.com in /pub/eric/papers/game.ps.Z.) </note>
Reference-contexts: I anticipate that decision-theoretic search-control techniques, such as those developed for ordinary state-space search by Russell & Wefald [6] and Baum & Smith <ref> [1] </ref>, will be even more important for controlling search in the more complex and exible space of abstractions. <p> Decision theory will be needed even more than in regular state-space search, where it is being used already: Some game-playing programs (see <ref> [1] </ref>, [4]) fruitfully use probabilistic inference to learn evaluation functions that inductively evaluate states based on past experience with an abstract class of similar states. Can these methods be used more generally, to use past experience with high-level abstractions to draw conclusions about lower-level abstractions that they subsume? Many researchers ([1], <p> them? Some game-playing programs (<ref> [1] </ref>, [7]) successfully apply concepts from decision the ory to control exploration of game-trees. Might it be helpful to do decision-theoretic search control in the much larger and more difficult space of abstractions? 7 Probabilities and utilities of abstractions Recent work in computer game-playing, such as [1] and [7], has begun to use the decision-theoretic concept of expected utility to define the value of game-states and the usefulness of reasoning actions, and to use probabilities to express uncertainty about the results of future state-space search and about the future decisions that agents will make.
Reference: [2] <author> Jon Doyle, Yoav Shoham and Michael P. Wellman. </author> <title> A logic of relative desire. </title> <editor> Z. W. Ras and M. Zemankova, eds., </editor> <booktitle> Methodologies for Intelligent Systems, 6. </booktitle> <address> Berlin: </address> <publisher> Springer-Verlag 1991, </publisher> <pages> pp. 16-31. </pages>
Reference-contexts: One approach, taken by Doyle et. al. in <ref> [2] </ref>, is to define preference among propositions in terms of preferences among the possible worlds that satisfy them. 8 June 9, 1993 Rational abstract search Similarly, we might try to define the utility of a proposition in terms of utilities of possible worlds (or in our case, world-histories) that satisfy it.
Reference: [3] <author> Michael P. Frank. </author> <title> Rational partial state-graph search. </title> <type> Draft report, </type> <institution> MIT Lab for Computer Science, </institution> <month> May </month> <year> 1993. </year> <note> (Available for anonymous FTP from medg.lcs.mit.- edu in /pub/mpf/term-paper.ps.) </note>
Reference-contexts: becomes seq () seq s 1 ( ) seq s 2 ( ) Where A Bfi means A subsumes B Game tree Abstraction net s 1 10 June 9, 1993 Rational abstract search rithms described by Pearl in [6], and by Baum and Smiths probabilistic game-tree methods ([1], reviewed in <ref> [3] </ref>). In the next few months, I plan to have the propagation algorithms specified well enough to implement them in a program to play the solitaire card game called spider.
Reference: [4] <author> Othar Hansson and Andrew Mayer. </author> <title> Probabilistic heuristic estimates. </title> <journal> Annals of Mathematics and Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 209-220, </pages> <year> 1990. </year>
Reference-contexts: Decision theory will be needed even more than in regular state-space search, where it is being used already: Some game-playing programs (see [1], <ref> [4] </ref>) fruitfully use probabilistic inference to learn evaluation functions that inductively evaluate states based on past experience with an abstract class of similar states.
Reference: [5] <author> Judea Pearl. </author> <title> Heuristics: Intelligent Search Strategies for Computer Problem Solving. </title> <booktitle> Addison-Wesley series in Artificial Intelligence. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1984. </year>
Reference-contexts: Can these methods be used more generally, to use past experience with high-level abstractions to draw conclusions about lower-level abstractions that they subsume? Many researchers ([1], <ref> [5] </ref>) have devised ways to treat information gained from a par tial game-tree search as probabilistic, and propagate this probabilistic information up the tree.
Reference: [6] <author> Judea Pearl. </author> <title> Probabilistic reasoning in intelligent systems: networks of plausible inference. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year> <title> Rational abstract search June 9, </title> <year> 1993 </year> <month> 11 </month>
Reference-contexts: I anticipate that decision-theoretic search-control techniques, such as those developed for ordinary state-space search by Russell & Wefald <ref> [6] </ref> and Baum & Smith [1], will be even more important for controlling search in the more complex and exible space of abstractions. <p> clarity of meaning. s L s 3 s 0 Note repeated states becomes seq () seq s 1 ( ) seq s 2 ( ) Where A Bfi means A subsumes B Game tree Abstraction net s 1 10 June 9, 1993 Rational abstract search rithms described by Pearl in <ref> [6] </ref>, and by Baum and Smiths probabilistic game-tree methods ([1], reviewed in [3]). In the next few months, I plan to have the propagation algorithms specified well enough to implement them in a program to play the solitaire card game called spider.
Reference: [7] <author> Stuart Russell and Eric Wefald. </author> <title> Principles of metareasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 49 </volume> <pages> 361-395, </pages> <year> 1991. </year>
Reference-contexts: Could we use similar techniques in general to propagate information from more-specific abstractions to less-specific ones that subsume them? Some game-playing programs ([1], <ref> [7] </ref>) successfully apply concepts from decision the ory to control exploration of game-trees. Might it be helpful to do decision-theoretic search control in the much larger and more difficult space of abstractions? 7 Probabilities and utilities of abstractions Recent work in computer game-playing, such as [1] and [7], has begun to <p> game-playing programs ([1], <ref> [7] </ref>) successfully apply concepts from decision the ory to control exploration of game-trees. Might it be helpful to do decision-theoretic search control in the much larger and more difficult space of abstractions? 7 Probabilities and utilities of abstractions Recent work in computer game-playing, such as [1] and [7], has begun to use the decision-theoretic concept of expected utility to define the value of game-states and the usefulness of reasoning actions, and to use probabilities to express uncertainty about the results of future state-space search and about the future decisions that agents will make.
Reference: [8] <author> Michael P. Wellman. </author> <title> Formulation of tradeoffs in planning under uncertainty. </title> <type> Tech report, </type> <institution> MIT Lab for Computer Science, MIT/LCS/TR-427, </institution> <month> August, </month> <year> 1988. </year>
Reference-contexts: Instead of building upwards from states, adding unnatural properties to them such as information about the history of previous states, I build top-down from abstract descriptions of possible entire histories of the world, adding restrictions to them, similarly to how Wellman defines abstract plans in <ref> [8] </ref>. Let us imagine there is some space of all the possible complete histories of the world (or of the micro-world of the current game). Then let us define an abstraction to be a description 1 of a class of world-histories. <p> For a reference on the use of description taxonomies for knowledge representation, see <ref> [8] </ref>. L A P A L Rational abstract search June 9, 1993 7 abstractions, and translate them to work on other kinds of abstraction as well. <p> We define the translation to be a network of abstractions, connected by arcs representing various kinds of relationships between abstractions, the primary one being a subsumption relationship. Abstraction networks are thus similar to Wellmans plan-specialization graphs <ref> [8] </ref>, except that we allow other kinds of relation a Ut a w - A a a w A a Ut a A A a Ut A - a a w A a = Rational abstract search June 9, 1993 9 ships between nodes besides subsumption, and nodes represent abstractions of
Reference: [9] <author> William A. Woods. </author> <title> Understanding subsumption and taxonomy: a framework for progress. </title> <type> Tech report, </type> <institution> Center for Research in Computing Technology, Harvard University, TR-19-90, </institution> <year> 1990. </year> <note> Also appears in Principles of Semantic Networks, </note> <editor> edited by John F. </editor> <publisher> Sowa. </publisher>
References-found: 9

