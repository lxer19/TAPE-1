URL: http://www-wavelet.eecs.berkeley.edu/~martin/Papers/Ramchandran_Vetterli.ps.gz
Refering-URL: http://www-wavelet.eecs.berkeley.edu/~martin/Papers/
Root-URL: http://www.cs.berkeley.edu
Title: Multiresolution Joint Source-Channel Coding for Wireless Channels  
Author: Kannan Ramchandran and Martin Vetterli 
Date: January 20, 1998  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> P. Haskell, D. G. Messerschmidt, and L. Yun, </author> <title> "Signal processing in wireless multimedia networks," in Wireless Communications: A Signal Processing Perspective (V. </title> <editor> Poor and G. Wor-nell, eds.), </editor> <address> (Englewood Cliffs, NJ), </address> <year> 1998. </year>
Reference-contexts: It is a more difficult problem due to the inherent complexity of the coding methods. Since we will specifically focus in this chapter on the image/video source, it is important to consider the end-to-end image communication problem very carefully (for multimedia networks see also <ref> [1] </ref>). Current communications link designs are primarily mismatched for wireless video, as they fail to take into account important considerations such as (i) highly time-varying source and channel characteristics, (ii) high source tolerance to channel loss, and (iii) unequal importance of transmitted bits. <p> In order to facilitate low-resolution (only) operation, low resolution reconstruction has to be possible on its own, and therefore this is the only state usable in the prediction loop (see also <ref> [1] </ref>). This leads in general to a suboptimal prediction for the full resolution mode of operation, and therefore a loss in full-resolution quality. The video coding standard MPEG [36] comes in two flavors, namely MPEG-1 for 1Mbits/sec, and MPEG-2 for the 5-10Mbits/sec range.
Reference: [2] <author> Lin and Costello, </author> <title> An Introduction to Error-Correcting Codes. </title> <publisher> Prentice-Hall, </publisher> <year> 1984. </year>
Reference-contexts: These requirements will influence the choice of error control coding strategies like Forward Error Correction (FEC) vs. Automatic Repeat ReQuest (ARQ) techniques, as well as more powerful hybrid FEC/ARQ choices <ref> [2] </ref>. Wireless image and video transmission comes in various application-driven flavors. Of particular interest are point-to-point transmission and broadcast/multicast scenarios. <p> Multiresolution channel codes offer unequal error protection. Unequal error protection channel codes have been studied extensively in the forward error correction coding literature over the past 10-20 years <ref> [2] </ref>, and there exist systematic ways of designing efficient unequal error protection codes for several families of channel codes, like block codes and convolutional codes. We are additionally interested in unequal error protection codes that are endowed with the "embedding" property.
Reference: [3] <author> C. E. Shannon, </author> <title> "A mathematical theory of communication," </title> <journal> Bell Syst. Tech. Journal, </journal> <volume> vol. 27, </volume> <pages> pp. 379-423, </pages> <year> 1948. </year>
Reference-contexts: The framework for both source coding and channel coding is of course Shannon's groundbreaking work on information theory <ref> [3] </ref>. <p> This approximation can be made for other carrier-to-noise ratio (CNR) distributions as well, as long as the channel is memoryless. channel model. 4 Multiresolution Joint Source-Channel Coding As mentioned, Shannon's pioneering result showing the separation without loss of optimality of source and channel coding <ref> [3] </ref> does not apply in practice in the face of finite delay and complexity constraints. <p> This fact, however, does not necessarily imply that this redundancy should necessarily be inserted in toto by channel coding techniques into a maximally compressed data stream. In his celebrated work <ref> [3] </ref>, Shannon has mentioned the possibility of using the redundancy left in the source to combat channel errors. For many practical image and video applications, it may well be better to "optimally" split the redundant information between source data and channel code parity.
Reference: [4] <author> T. Berger, </author> <title> Rate Distortion Theory. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall, </publisher> <year> 1971. </year> <title> 43 E s =N o = 17 dB. Perfect channel state information is assumed. Total rate is .2 channel usages per source symbol. </title>
Reference-contexts: That is, given a source with certain statistical characteristics, rate-distortion theory <ref> [4, 5] </ref> states that there exists a distortion-rate function D (R) such that, at a given bit rate per sample R 0 , it is possible to represent the source with a distortion D 0 = D (R 0 ) * with * &gt; 0 arbitrarily small. <p> Actually, linear one-to-one mapping (when the channel signal amplitude is determined by scaling the source sample amplitude) will achieve the optimal performance theoretically attainable (OPTA) for this source and AWGN channel with energy constraint <ref> [4] </ref>. <p> This leads to the obvious question of whether it is possible to get the "best of both worlds." As a prelude to addressing this interesting question, we consider a fundamental but surprisingly little-referenced result from Berger's book on rate-distortion theory <ref> [4] </ref> that is highly relevant to the modus operandi one might adopt in devising hybrid solutions. 4.5.1 Transmission of Gaussian Signals over Gaussian Noise Channels Shannon taught us that a theoertically optimal way of transmitting information from point to point is via the separation theorem. <p> In our discussion we suppress the issue of 37 distortion E [(X ^ X) 2 ] subject to variance of Y being fixed (the last constrains the transmitted energy). In <ref> [4] </ref> (p.162), Berger showed that: " The optimum PAM system for transmitting a memoryless N (0; s 2 ) source at the Nyquist rate over an ideal bandlimited channel with additive, zero mean, white Gaussian noise and an average input power constraint achieves the least MSE theoretically attainable with any communication
Reference: [5] <author> T. M. Cover and J. A. Thomas, </author> <title> Elements of Information Theory. </title> <address> New York, NY: </address> <publisher> Wiley Interscience, </publisher> <year> 1991. </year>
Reference-contexts: That is, given a source with certain statistical characteristics, rate-distortion theory <ref> [4, 5] </ref> states that there exists a distortion-rate function D (R) such that, at a given bit rate per sample R 0 , it is possible to represent the source with a distortion D 0 = D (R 0 ) * with * &gt; 0 arbitrarily small. <p> It is worthwhile pointing out that for channels with feedback, one can use Automatic Repeat reQuest (ARQ), which perfectly adapts to channel conditions. From an information theoretic standpoint (i.e. where infinite complexity and delay are permissible), there is surprisingly no advantage to having feedback when communicating over memoryless channels <ref> [5] </ref>, i.e. the capacity is unchanged 3 . In fact, ARQ scheme reaches channel capacity over a binary memoryless erasure 4 channel, irrespective of what the erasure probability actually is [5], i.e., it is a universal code for this channel. <p> where infinite complexity and delay are permissible), there is surprisingly no advantage to having feedback when communicating over memoryless channels <ref> [5] </ref>, i.e. the capacity is unchanged 3 . In fact, ARQ scheme reaches channel capacity over a binary memoryless erasure 4 channel, irrespective of what the erasure probability actually is [5], i.e., it is a universal code for this channel. This is a very powerful feature since without feedback, universality would be hard to achieve. <p> In the case of channels with memory, feedback is known to provide theoretical advantages even in the Shannon-sense, although feedback increases the capacity for a non-white (i.e. correlated) Gaussian additive noise channel by at most half a bit <ref> [5] </ref>. It is useful to note that if delay constraints are stringent, then feedback may be useless. <p> The discrete channel is characterized by the collection of transitional probability mass functions p Y jX (yjx), one for each x 2 X <ref> [5] </ref>. <p> Let P and D OP T A be the average energy and distortion per source sample. Then the optimal performance theoretically attainable is obtained by "inverse waterfilling" for source coding and "waterfilling" for channel capacity <ref> [5] </ref>, and in a low target distortion case can be shown to be: D OP T A = ( i=1 (1 + P=N 0 ) Unfortunately, the optimal PAM for each channel will not achieve this performance and the distor tion will increase by a factor K given by: K =
Reference: [6] <author> W. H. Equitz and T. M. </author> <title> Cover, "Successive refinement of information," </title> <journal> IEEE Trans. Inform. Th., </journal> <volume> vol. 37, </volume> <pages> pp. 269-275, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: &gt; R 1 , and ffi 12 = R 2 R 1 , then knowledge of the coded version at rate R 1 plus an additional information of ffi 12 bits is not enough in general to construct the coded version at rate R 2 that meets the rate-distortion bound <ref> [6] </ref>. This is because being able to construct the rate R 2 version incrementally from a rate R 1 version is an added constraint, which in general will decrease the quality. As a simple example, consider scalar quantizers. <p> See Fig. 11 (b). Note that in this case, the use of a multiresolution framework is not theoretically optimal (except if the source obeys a certain Markov property <ref> [6] </ref> see Section 2.1), but a multiresolution design is more flexible and attractive from an engineering perspective (architectural simplicity) with little loss in performance typically (see for example [75]), with the encoder and decoder both "picking off" the resolution they want to live at based on the channel state information.
Reference: [7] <author> P. J. Burt and E. H. Adelson, </author> <title> "The Laplacian pyramid as a compact image code," </title> <journal> IEEE Trans. Commun., </journal> <volume> vol. 31, </volume> <pages> pp. 532-540, </pages> <month> April </month> <year> 1983. </year>
Reference-contexts: We will therefore consider briefly a number of such successive approximation source codes. 2.2 Practical successive approximation source coders 2.2.1 Pyramid coding Pyramid coding is the first instance of hierarchical source coding that had an impact on compression practice. First formally proposed by Burt and Adelson <ref> [7] </ref>, pyramid coding codes two versions of the signal. First, a coarse version of the original signal or image is derived, for example using lowpass filtering and subsampling.
Reference: [8] <author> K. M. Uz, M. Vetterli, and D. LeGall, </author> <title> "Interpolative multiresolution coding of advanced television with compatible subchannels," </title> <journal> IEEE Trans. on CAS for Video Technology, Special Issue on Signal Processing for Advanced Television, </journal> <volume> vol. 1, </volume> <pages> pp. 86-99, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: While theoretically this extra redundancy can be removed through compression, it creates an additional burden. 6 The idea of pyramid coding can be applied to three-dimensional data as well, leading to video pyramids. This multiresolution representation of video is useful for compatibility and for robustness with unequal error protection <ref> [8] </ref>. 2.2.2 Subband coding The problem of overcompleteness is solved by subband coding. In that scheme, an orthonormal or biorthogonal expansion is calculated using filter banks [9], and the expansion coefficients are quantized appropriately. Subband coding is a generalization of transform coding, a popular method in image compression [10].
Reference: [9] <author> M. Vetterli and J. Kovacevic, </author> <title> Wavelets and Subband Coding. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall, </publisher> <year> 1995. </year>
Reference-contexts: This multiresolution representation of video is useful for compatibility and for robustness with unequal error protection [8]. 2.2.2 Subband coding The problem of overcompleteness is solved by subband coding. In that scheme, an orthonormal or biorthogonal expansion is calculated using filter banks <ref> [9] </ref>, and the expansion coefficients are quantized appropriately. Subband coding is a generalization of transform coding, a popular method in image compression [10]. Unlike transform coding, however, subband coding is not plagued by blocking artefacts. <p> (iii) what quantization should be applied to the subbands: scalar quantization, vector quantization, uniform or non-uniform (Lloyd-Max) quantization [17]? (iv) what are efficient lossless compression schemes to handle the quantized subband coefficients: static entropy codes, adaptive entropy codes? These issues are considered in the literature, and summarized for example in <ref> [9] </ref>. The idea of subband coding has been extended to video in [18] and has lead to interesting compression results recently [19, 20]. 2.2.3 Wavelet coding An important variant of subband coding is what is now popularly called wavelet coding [21, 22, 23].
Reference: [10] <author> A. K. Jain, </author> <title> Fundamentals of Digital Image Processing. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall, </publisher> <year> 1989. </year>
Reference-contexts: In that scheme, an orthonormal or biorthogonal expansion is calculated using filter banks [9], and the expansion coefficients are quantized appropriately. Subband coding is a generalization of transform coding, a popular method in image compression <ref> [10] </ref>. Unlike transform coding, however, subband coding is not plagued by blocking artefacts. Subband coding had been used in speech compession [11, 12] and was proposed for images in [13]. Practical coders followed [14, 15, 16] and the results spurred substantial work in subband image coding.
Reference: [11] <author> R. E. Crochiere, S. A. Webber, and J. L. Flanagan, </author> <title> "Digital coding of speech in sub-bands," </title> <journal> Bell System Technical Journal, </journal> <volume> vol. 55, </volume> <pages> pp. 1069-1085, </pages> <month> October </month> <year> 1976. </year> <month> 44 </month>
Reference-contexts: Subband coding is a generalization of transform coding, a popular method in image compression [10]. Unlike transform coding, however, subband coding is not plagued by blocking artefacts. Subband coding had been used in speech compession <ref> [11, 12] </ref> and was proposed for images in [13]. Practical coders followed [14, 15, 16] and the results spurred substantial work in subband image coding.
Reference: [12] <author> D. Esteban and C. Galand, </author> <title> "Application of quadrature mirror filters to split band voice coding schemes," </title> <booktitle> in Proc. IEEE Int. Conf. Acoust. Speech, and Signal Processing, </booktitle> <pages> pp. 191-195, </pages> <month> May </month> <year> 1977. </year>
Reference-contexts: Subband coding is a generalization of transform coding, a popular method in image compression [10]. Unlike transform coding, however, subband coding is not plagued by blocking artefacts. Subband coding had been used in speech compession <ref> [11, 12] </ref> and was proposed for images in [13]. Practical coders followed [14, 15, 16] and the results spurred substantial work in subband image coding.
Reference: [13] <author> M. Vetterli, </author> <title> "Multidimensional subband coding: Some theory and algorithms," </title> <booktitle> Signal Proc., </booktitle> <volume> vol. 6, </volume> <pages> pp. 97-112, </pages> <month> February </month> <year> 1984. </year>
Reference-contexts: Subband coding is a generalization of transform coding, a popular method in image compression [10]. Unlike transform coding, however, subband coding is not plagued by blocking artefacts. Subband coding had been used in speech compession [11, 12] and was proposed for images in <ref> [13] </ref>. Practical coders followed [14, 15, 16] and the results spurred substantial work in subband image coding.
Reference: [14] <author> J. W. Woods and S. D. O'Neil, </author> <title> "Sub-band coding of images," </title> <journal> IEEE Trans. Acoust., Speech, and Signal Proc., </journal> <volume> vol. 34, </volume> <pages> pp. 1278-1288, </pages> <month> May </month> <year> 1986. </year>
Reference-contexts: Subband coding is a generalization of transform coding, a popular method in image compression [10]. Unlike transform coding, however, subband coding is not plagued by blocking artefacts. Subband coding had been used in speech compession [11, 12] and was proposed for images in [13]. Practical coders followed <ref> [14, 15, 16] </ref> and the results spurred substantial work in subband image coding.
Reference: [15] <author> P. H. Westerink, J. Biemond, D. E. Boekee, and J. W. Woods, </author> <title> "Subband coding of images using vector quantization," </title> <journal> IEEE Trans. Commun., </journal> <volume> vol. 36, </volume> <pages> pp. 713-719, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: Subband coding is a generalization of transform coding, a popular method in image compression [10]. Unlike transform coding, however, subband coding is not plagued by blocking artefacts. Subband coding had been used in speech compession [11, 12] and was proposed for images in [13]. Practical coders followed <ref> [14, 15, 16] </ref> and the results spurred substantial work in subband image coding.
Reference: [16] <author> J. W. Woods, </author> <title> Subband Image Coding. </title> <address> New York: </address> <publisher> Kluwer Academic Press, </publisher> <year> 1991. </year>
Reference-contexts: Subband coding is a generalization of transform coding, a popular method in image compression [10]. Unlike transform coding, however, subband coding is not plagued by blocking artefacts. Subband coding had been used in speech compession [11, 12] and was proposed for images in [13]. Practical coders followed <ref> [14, 15, 16] </ref> and the results spurred substantial work in subband image coding.
Reference: [17] <author> A. Gersho and R. M. Gray, </author> <title> Vector Quantization and Signal Compression. </title> <publisher> Kluwer Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: is best suited to images: how many subbands, what frequency 7 split, what time resolution? (ii) what filters are best used: orthogonal or biorthogonal filters, linear phase filters, extension schemes at boundaries? (iii) what quantization should be applied to the subbands: scalar quantization, vector quantization, uniform or non-uniform (Lloyd-Max) quantization <ref> [17] </ref>? (iv) what are efficient lossless compression schemes to handle the quantized subband coefficients: static entropy codes, adaptive entropy codes? These issues are considered in the literature, and summarized for example in [9]. <p> Based on this, the optimization of source coders and/or mappings from source to channel alphabets was performed. This approach was advocated for example in [65], where an algorithm similar in spirit to the celebrated Lloyd-Max optimal scalar quantizer design algorithm <ref> [17] </ref> was proposed to design an optimal scalar quantizer for a discrete memoryless channel. Recall that the Lloyd-Max quantization algorithm consists of iterative optimizations of the encoder and decoder respectively while holding the other fixed. The encoder function deals with finding cell (or Voronoi region) partitions. <p> The framework in [58] was based on maximum a-posteriori estimation of the input source (based on tractable statistical signal models like autoregressive models, etc.). By considering appropriate extensions of the Generalized Lloyd's Algorithm <ref> [17] </ref> (which is a VQ extension to the scalar quantizer based Lloyd Max algorithm described earlier), an optimized signal constellation design was included in the optimization loop, leading to performance improvement over traditional separately designed systems.
Reference: [18] <author> G. Karlsson and M. Vetterli, </author> <title> "Three-dimensional subband coding of video," </title> <booktitle> in Proc. IEEE Int. Conf. Acoust., Speech, and Signal Proc., </booktitle> <address> (New York, NY), </address> <pages> pp. 1100-1103, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: The idea of subband coding has been extended to video in <ref> [18] </ref> and has lead to interesting compression results recently [19, 20]. 2.2.3 Wavelet coding An important variant of subband coding is what is now popularly called wavelet coding [21, 22, 23].
Reference: [19] <author> J.-R. Ohm, </author> <title> "Three-dimensional subband coding with motion compensation," </title> <journal> IEEE Trans. Image Processing, Special issue on Image Sequence Compression, </journal> <volume> vol. 3, </volume> <pages> pp. 559-571, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: The idea of subband coding has been extended to video in [18] and has lead to interesting compression results recently <ref> [19, 20] </ref>. 2.2.3 Wavelet coding An important variant of subband coding is what is now popularly called wavelet coding [21, 22, 23]. This variant uses an octave-band tree structure and filters that possess a regularity property (related to a notion of smoothness of an iterated function).
Reference: [20] <author> D. Taubman and A. Zakhor, </author> <title> "Multi-rate 3-D subband coding of video," </title> <journal> IEEE Trans. Image Processing, Special issue on Image Sequence Compression, </journal> <volume> vol. 3, </volume> <pages> pp. 572-588, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: The idea of subband coding has been extended to video in [18] and has lead to interesting compression results recently <ref> [19, 20] </ref>. 2.2.3 Wavelet coding An important variant of subband coding is what is now popularly called wavelet coding [21, 22, 23]. This variant uses an octave-band tree structure and filters that possess a regularity property (related to a notion of smoothness of an iterated function).
Reference: [21] <author> J. M. Shapiro, </author> <title> "An embedded wavelet hierarchical image coder," </title> <booktitle> in Proc. IEEE Int. Conf. Acoust., Speech, and Signal Proc., </booktitle> <address> (San Francisco), </address> <pages> pp. 657-660, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: The idea of subband coding has been extended to video in [18] and has lead to interesting compression results recently [19, 20]. 2.2.3 Wavelet coding An important variant of subband coding is what is now popularly called wavelet coding <ref> [21, 22, 23] </ref>. This variant uses an octave-band tree structure and filters that possess a regularity property (related to a notion of smoothness of an iterated function). Such schemes have the ability to compactly capture the space-frequency characterization of natural images.
Reference: [22] <author> A. S. Lewis and G. Knowles, </author> <title> "Image compression using the 2-D wavelet transform," </title> <journal> IEEE Trans. Image Proc., </journal> <volume> vol. 1, </volume> <pages> pp. 244-250, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: The idea of subband coding has been extended to video in [18] and has lead to interesting compression results recently [19, 20]. 2.2.3 Wavelet coding An important variant of subband coding is what is now popularly called wavelet coding <ref> [21, 22, 23] </ref>. This variant uses an octave-band tree structure and filters that possess a regularity property (related to a notion of smoothness of an iterated function). Such schemes have the ability to compactly capture the space-frequency characterization of natural images. <p> A new class of algorithms developed recently has achieved significantly improved performance over the previous class <ref> [22, 24, 25, 26, 27] </ref> by exploiting the wavelet's space-frequency compaction properties.
Reference: [23] <author> M. Antonini, M. Barlaud, P. Mathieu, and I. Daubechies, </author> <title> "Image coding using wavelet transform," </title> <journal> IEEE Trans. Image Proc., </journal> <volume> vol. 1, </volume> <pages> pp. 205-220, </pages> <month> April </month> <year> 1992. </year> <month> 45 </month>
Reference-contexts: The idea of subband coding has been extended to video in [18] and has lead to interesting compression results recently [19, 20]. 2.2.3 Wavelet coding An important variant of subband coding is what is now popularly called wavelet coding <ref> [21, 22, 23] </ref>. This variant uses an octave-band tree structure and filters that possess a regularity property (related to a notion of smoothness of an iterated function). Such schemes have the ability to compactly capture the space-frequency characterization of natural images.
Reference: [24] <author> J. M. Shapiro, </author> <title> "Embedded image coding using zerotrees of wavelet coefficients," </title> <journal> IEEE Transac--tions on Signal Processing, Special Issue on Wavelets and Signal Processing, </journal> <volume> vol. 41, </volume> <pages> pp. 3445-3462, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: A new class of algorithms developed recently has achieved significantly improved performance over the previous class <ref> [22, 24, 25, 26, 27] </ref> by exploiting the wavelet's space-frequency compaction properties. <p> The incorporation of a mechanism to exploit this spatial characterization is vital to improving efficiency: the most popular data-structure for this is the zerotree structure developed by Shapiro <ref> [24] </ref>. 8 A wavelet image representation can be thought of as a tree-structured spatial set of coefficients, providing a hierarchical data-structure for representing images, with each wavelet transform coefficient corresponding to a spatial area in the image. <p> Note that these are examples of separately designed systems that have state-of-the-art source and channel coding components. However, a subtle point is that the use of an embedded source representation, such as the wavelet coders of <ref> [24, 25] </ref>, results naturally in a gracefully degraded digital system, as 26 each succeeding bit effectively represents a resolution "layer." Decoding can be stopped when an uncorrectable error is detected, with the resulting quality depending on how far along the bitstream the error has occurred. <p> The method of detection, achieved by using an arithmetic codec, has the attractive feature that it can be combined very easily with an arithmetic-coding based source coder, as is very popular in state-of-the-art image coders <ref> [24, 25] </ref>. When this method of error detection is applied to ARQ protocols, significant gains in throughput performance (or equivalently, delivered image quality) are obtained over conventional ARQ schemes. Recent results [73] also indicate the gains of continuous error detection applied to serial concatenated coding schemes with convolutional codes.
Reference: [25] <author> A. Said and W. A. Pearlman, </author> <title> "A new fast and efficient image coder based on set partitioning in hierarchical trees," </title> <journal> IEEE Trans. Circuits and Systems for Video Technology, </journal> <pages> pp. 243-250, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: A new class of algorithms developed recently has achieved significantly improved performance over the previous class <ref> [22, 24, 25, 26, 27] </ref> by exploiting the wavelet's space-frequency compaction properties. <p> This is conceptually akin to the "analog" transmission philosphy introduced earlier. Binary Symmetric Channel transmission of still images with rate-compatible-punctured con-volustional (RCPC) codes [70] was addressed in [59] and more recently in [71], where a popular embedded wavelet-based zerotree coder <ref> [25] </ref> was combined with RCPC codes and a series-concatenated channel coder based on the "list Viterbi decoding" principle [72]. <p> By cascading this "sophisticated" channel coder trivially with a "sophisticated" embedded wavelet zerotree image source coder (such as <ref> [25] </ref>) as done in [71], one can obtain robust image transmission systems. With more powerful channel coders (such as that of [73]) and more powerful source coders (such as that of [30]), even better systems can result, as pointed out in [73]. <p> Note that these are examples of separately designed systems that have state-of-the-art source and channel coding components. However, a subtle point is that the use of an embedded source representation, such as the wavelet coders of <ref> [24, 25] </ref>, results naturally in a gracefully degraded digital system, as 26 each succeeding bit effectively represents a resolution "layer." Decoding can be stopped when an uncorrectable error is detected, with the resulting quality depending on how far along the bitstream the error has occurred. <p> The method of detection, achieved by using an arithmetic codec, has the attractive feature that it can be combined very easily with an arithmetic-coding based source coder, as is very popular in state-of-the-art image coders <ref> [24, 25] </ref>. When this method of error detection is applied to ARQ protocols, significant gains in throughput performance (or equivalently, delivered image quality) are obtained over conventional ARQ schemes. Recent results [73] also indicate the gains of continuous error detection applied to serial concatenated coding schemes with convolutional codes.
Reference: [26] <author> Z. Xiong, K. Ramchandran, and M. T. Orchard, </author> <title> "Joint optimization of scalar and tree-structured quantization of wavelet image decomposition," </title> <booktitle> in Proc. 27th Ann. Asilomar Conf. on Sig., Syst., and Comp., </booktitle> <volume> vol. </volume> <pages> 2, </pages> <address> (Pacific Grove, CA), </address> <pages> pp. 891-895, </pages> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: A new class of algorithms developed recently has achieved significantly improved performance over the previous class <ref> [22, 24, 25, 26, 27] </ref> by exploiting the wavelet's space-frequency compaction properties. <p> Also shown in Figure 4 is a rate-distortion (R-D) optimized version of Shapiro's zerotree coder, dubbed the Space-Frequency Quantization (SFQ) based zerotree coder in <ref> [26, 28] </ref> that gives up the embedding feature for attaining Rate-Distortion optimality (within the zerotree framework).
Reference: [27] <author> R. L. Joshi, V. J. Crump, and T. R. Fisher, </author> <title> "Image subband coding using arithmetic and trellis coded quantization," </title> <journal> IEEE Trans. Circuits and Systems for Video Technology, </journal> <note> 1994. Submitted. </note>
Reference-contexts: A new class of algorithms developed recently has achieved significantly improved performance over the previous class <ref> [22, 24, 25, 26, 27] </ref> by exploiting the wavelet's space-frequency compaction properties.
Reference: [28] <author> Z. Xiong, K. Ramchandran, and M. T. Orchard, </author> <title> "Space-frequency quantization for wavelet image coding," </title> <journal> IEEE Trans. on Image Proc., </journal> <volume> vol. 6, </volume> <pages> pp. 677-693, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: Also shown in Figure 4 is a rate-distortion (R-D) optimized version of Shapiro's zerotree coder, dubbed the Space-Frequency Quantization (SFQ) based zerotree coder in <ref> [26, 28] </ref> that gives up the embedding feature for attaining Rate-Distortion optimality (within the zerotree framework). <p> Thus, while a subset of the image decomposition is much better treated using the "compressed" mode above, its complementary subset can fairly accurately approximate the above assumptions for which PAM is theoretically optimal (see Section 4.5.1)! Taking as a platform the zerotree-based wavelet Space Frequency Quantization (SFQ) image coder of <ref> [28] </ref> (see Section 2.2.3), the coded data, consisting of the digital zerotree significance map information and the residue subband coefficients, is partitioned into two subsets, one of which is "compressed," using entropy-coding and unequally error-protected using appropriate RCPC channel coding, while the other component is transmitted "uncompressed" using a one-to-one PAM-mapping.
Reference: [29] <author> R. L. Joshi, T. R. Fisher, and R. H. Bamberger, </author> <title> "Optimum classification in subband coding of images," </title> <booktitle> in Proc. of ICIP'94, </booktitle> <address> (Austin, TX), </address> <pages> pp. 883-887, </pages> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: Efficient alternative structures which are complementary to, and often outperform, the zerotree structure include spatial classification based methods <ref> [29, 30, 31] </ref>, as well as a novel framework based on morphological dilation [32], which has the added advantage over the zerotree structure of being "object-oriented," [33] while also being capable of a flexible embedded/non-embedded mode of operation that may be suitable for many evolving multimedia-driven applications such as supporting object-indexing
Reference: [30] <author> S. LoPresto, K. Ramchandran, and M. T. Orchard, </author> <title> "Image coding based on mixture modeling of wavelet coefficients and a fast estimation-quantization framework," </title> <booktitle> in Data Compression Conference '97, (Snowbird, Utah), </booktitle> <pages> pp. 221-230, </pages> <year> 1997. </year>
Reference-contexts: Efficient alternative structures which are complementary to, and often outperform, the zerotree structure include spatial classification based methods <ref> [29, 30, 31] </ref>, as well as a novel framework based on morphological dilation [32], which has the added advantage over the zerotree structure of being "object-oriented," [33] while also being capable of a flexible embedded/non-embedded mode of operation that may be suitable for many evolving multimedia-driven applications such as supporting object-indexing <p> By cascading this "sophisticated" channel coder trivially with a "sophisticated" embedded wavelet zerotree image source coder (such as [25]) as done in [71], one can obtain robust image transmission systems. With more powerful channel coders (such as that of [73]) and more powerful source coders (such as that of <ref> [30] </ref>), even better systems can result, as pointed out in [73]. Note that these are examples of separately designed systems that have state-of-the-art source and channel coding components. <p> Further, the optimality of linear mappings does not hold for the case of composite or mixture sources even in the Gaussian case [84]. This case is of interest as Gaussian mixture distributions have been shown to be very accurate for modeling wavelet image coefficients <ref> [30] </ref>, where a coding algorithm based on this attains performance that ranks among the very best in the cited literature. We will consider a slightly simpler version here for clarity of the presentation.
Reference: [31] <author> Y.Yoo, A.Ortega, and B.Yu, </author> <title> "Adaptive quantization of image subbands with efficient overhead rate distortion," </title> <booktitle> in Int'l Conf. on Image Proc., ICIP'96, </booktitle> <volume> vol. </volume> <pages> 2, </pages> <address> (Lausanne, Switzerland), </address> <pages> pp. 361-364, </pages> <month> Sep. </month> <year> 1996. </year>
Reference-contexts: Efficient alternative structures which are complementary to, and often outperform, the zerotree structure include spatial classification based methods <ref> [29, 30, 31] </ref>, as well as a novel framework based on morphological dilation [32], which has the added advantage over the zerotree structure of being "object-oriented," [33] while also being capable of a flexible embedded/non-embedded mode of operation that may be suitable for many evolving multimedia-driven applications such as supporting object-indexing
Reference: [32] <author> S. Servetto, K. Ramchandran, and M. T. Orchard, </author> <title> "Morphological representation of wavelet data for image coding," </title> <booktitle> in Proc. of ICASSP'95, </booktitle> <address> (Detroit, MI), </address> <month> May </month> <year> 1995. </year>
Reference-contexts: Efficient alternative structures which are complementary to, and often outperform, the zerotree structure include spatial classification based methods [29, 30, 31], as well as a novel framework based on morphological dilation <ref> [32] </ref>, which has the added advantage over the zerotree structure of being "object-oriented," [33] while also being capable of a flexible embedded/non-embedded mode of operation that may be suitable for many evolving multimedia-driven applications such as supporting object-indexing etc. without giving up compression performance [34]. 2.3 Successive approximation source coding in
Reference: [33] <author> S. Servetto, K. Ramchandran, and M. T. Orchard, </author> <title> "Image coding based on a morphological representation of wavelet data," </title> <booktitle> in IEEE Trans. on Image Processing, </booktitle> <month> December </month> <year> 1996. </year> <note> Submitted. 46 </note>
Reference-contexts: Efficient alternative structures which are complementary to, and often outperform, the zerotree structure include spatial classification based methods [29, 30, 31], as well as a novel framework based on morphological dilation [32], which has the added advantage over the zerotree structure of being "object-oriented," <ref> [33] </ref> while also being capable of a flexible embedded/non-embedded mode of operation that may be suitable for many evolving multimedia-driven applications such as supporting object-indexing etc. without giving up compression performance [34]. 2.3 Successive approximation source coding in the context of standards 2.3.1 Scalability in JPEG The standard image compression method
Reference: [34] <author> S. Servetto, K. Ramchandran, and T. S. Huang, </author> <title> "Image and video coding with object indexing support," Journal on VLSI Signal Processing, 1998. To appear, Special Issue on Multimedia Signal Processing: </title> <type> Invited Paper. [35] "JPEG technical specification: Revision (DRAFT), </type> <institution> joint photographic experts group, ISO/IEC JTC1/SC2/WG8, CCITT SGVIII," </institution> <month> Aug. </month> <year> 1990. </year> <title> [36] "MPEG video simulation model three, ISO, coded representation of picture and audio information," </title> <year> 1990. </year>
Reference-contexts: novel framework based on morphological dilation [32], which has the added advantage over the zerotree structure of being "object-oriented," [33] while also being capable of a flexible embedded/non-embedded mode of operation that may be suitable for many evolving multimedia-driven applications such as supporting object-indexing etc. without giving up compression performance <ref> [34] </ref>. 2.3 Successive approximation source coding in the context of standards 2.3.1 Scalability in JPEG The standard image compression method JPEG [35] has a hierarchical mode. A multiresolution representation is obtained by scaling the size of the encoded image. The base layer carries the data for the lowest spatial resolution.
Reference: [37] <author> T. </author> <title> Cover, "Broadcast channels," </title> <journal> IEEE Trans. on Inform. Theory, </journal> <volume> vol. IT-18, </volume> <pages> pp. 2-14, </pages> <month> Jan. </month> <year> 1972. </year>
Reference-contexts: This has been shown to be superior to "naive multiplexing" using non-embedded unequal error protection codes <ref> [37, 38] </ref>. We shall see that the idea of multiresolution channel coding can be extended to cover modulation 13 and demodulation systems, for example in defining embedded modulation schemes like embedded QAM [38]. <p> However, multiplexing is inferior to embedding <ref> [37, 38] </ref>. In other words, the combined (n 1 + n 2 ; k 1 ; k 2 ; t 1 ; t 2 ) code above can be potentially outperformed by an (n; k 1 ; k 2 ; t 1 ; t 2 ) embedded code. <p> The justification for embedded transmission takes its roots from Cover's classic work on broadcast channels <ref> [37] </ref>. Let us consider a typical broadcast scenario, where a source wishes to convey information fr; s 1 g to a stronger receiver and fr; s 2 g to a weaker one. Note that r represents the common message to be conveyed to both receivers. <p> Recall that this category refers to the case where the receiver is informed of the channel state information, but the transmitter is not. 4.3.1 Broadcast: Embedded Modulation As stated earlier, the idea of embedded modulation derives its roots from Cover's information-theoretic results on broadcast channels <ref> [37] </ref>. The merging of the compression advantages of digital transmission systems with the natural robustness of analog systems was proposed in a novel hybrid analog-under-digital transmission scheme for the broadcast of HDTV by Schreiber [64].
Reference: [38] <author> K. Ramchandran, A. Ortega, K. M. Uz, and M. Vetterli, </author> <title> "Multiresolution broadcast for digital HDTV using joint source-channel coding," </title> <journal> IEEE J. on Sel. Areas in Comm., </journal> <volume> vol. 11, </volume> <pages> pp. 6-23, </pages> <month> Jan. </month> <year> 1993. </year>
Reference-contexts: This has been shown to be superior to "naive multiplexing" using non-embedded unequal error protection codes <ref> [37, 38] </ref>. We shall see that the idea of multiresolution channel coding can be extended to cover modulation 13 and demodulation systems, for example in defining embedded modulation schemes like embedded QAM [38]. <p> This has been shown to be superior to "naive multiplexing" using non-embedded unequal error protection codes [37, 38]. We shall see that the idea of multiresolution channel coding can be extended to cover modulation 13 and demodulation systems, for example in defining embedded modulation schemes like embedded QAM <ref> [38] </ref>. <p> However, multiplexing is inferior to embedding <ref> [37, 38] </ref>. In other words, the combined (n 1 + n 2 ; k 1 ; k 2 ; t 1 ; t 2 ) code above can be potentially outperformed by an (n; k 1 ; k 2 ; t 1 ; t 2 ) embedded code. <p> That is, the superior receiver 1, in an optimal scenario, necessarily has access to the information fr; s 2 g meant for the weaker receiver 2. While this is a theoeretical result (in the Shannon sense), a practical way of realizing this embedding gain was described in <ref> [38] </ref>. Cover's concept of embedding is generic in scope, and places no restrictions on the domain in which this embedding should be performed. The benefits of embedding in the modulation domain versus in the forward error protection channel coding domain were laid out in [38] in the form of a novel <p> this embedding gain was described in <ref> [38] </ref>. Cover's concept of embedding is generic in scope, and places no restrictions on the domain in which this embedding should be performed. The benefits of embedding in the modulation domain versus in the forward error protection channel coding domain were laid out in [38] in the form of a novel multiresolution embedded modulation structure that offers the embedded unequal error protection property directly in the modulation domain. <p> Thus the quality of the received video varies gracefully with the receiver type as well as its distance from the transmitter. The added attraction of the embedded modulation scheme comes from being able to combine it naturally with standard error correction techniques, as was proposed in <ref> [38] </ref> and later in [45], as well as with other techniques as described in the following section. 5 E.g., in the multiresolution-64 QAM example shown, for every 2 "important" cloud bits/symbol having increased protection, there are 4 "less important" satellite bits/symbol that get decreased protection. 17 3.4 Hybrid Embedded Options One <p> Examples include the combination of embedded modulation with unequal error protection channel codes (e.g. to increase the number of resolution layers), with Ungerboeck's Trellis Coded Modulation (TCM) [46] to achieve embedded TCM <ref> [38] </ref>, with multicarrier systems to attain embedded multicarrier modulation, etc. In order to illustrate the power of these hybrids, we will pick multicarrier modulation as a representative example [47]. We begin with a very brief review of multicarrier modulation, referring the reader to [48, 49, 50] for details. <p> We will dedicate Section 4.5 to this, but will provide a sneak preview here to underline the historical perspective. A practical hybrid analog/digital transmission scheme was first proposed by Schreiber [64] using a novel analog-under-digital scheme. An all-digital solution in the same spirit was proposed in <ref> [38] </ref>, where the goal was to merge the benefits of both ideologies, without giving up an all-digital representation, which has unthinkable political implications 6 . These methods enjoy the important embedding property covered in Section 3, making them ideally suited to applications like broadcast and multicast (see Section 4.3.3). <p> An all-digital solution in the same spirit which was aimed at more efficiently retaining the compression advantages of digital systems, and optimally matching the source and channel resolutions using a stepwise graceful degradation 29 philosophy was described in <ref> [38] </ref>. Embedding was done directly in the modulation domain, using the idea of clouds and satellites of Figure 10, offering unequal levels of protection in an efficient and in a continuously controllable way (through the parameter for a two-resolution system). <p> Significant gains of using a multiresolution embedded approach over "naive multiplexing" of the resolutions (using time-division-multiplexing or frequency-division-multiplexing methods) were established there for HDTV broadcast applications as a practical way of realizing the theoretical results of Cover. A modulation-domain based unequal error protection scheme similar to that of <ref> [38] </ref> has been considered for European digital audio and video broadcast [44]. Each layer of different error protection corresponds to the specific type of the receiving monitor (typically, there are three layers or resolutions) and have different bit error rate requirements.
Reference: [39] <author> A. R. Calderbank, </author> <title> "Multilevel codes and multistage decoding," </title> <journal> IEEE Trans. on Commun., </journal> <volume> vol. 37, </volume> <pages> pp. 222-229, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: They are also useful when dealing with time-varying channel conditions, where the degree of needed protection varies. Unequal error protection codes have been studied for both block codes (e.g. BCH codes <ref> [39] </ref>) and convolutional codes (e.g. Rate-Compatible-Punctured-Convolutional (RCPC) codes [40]). RCPC codes have become very popular due to their combination of flexibility and efficiency.
Reference: [40] <author> R. V. Cox, J. Hagenauer, N. Seshadri, and C. Sundberg, </author> <title> "Variable rate sub-band speech coding and matched convolutional channel coding for mobile radio channels," </title> <journal> IEEE Trans. on Signal Processing, </journal> <volume> vol. 39, </volume> <pages> pp. 1717-1731, </pages> <year> 1991. </year>
Reference-contexts: They are also useful when dealing with time-varying channel conditions, where the degree of needed protection varies. Unequal error protection codes have been studied for both block codes (e.g. BCH codes [39]) and convolutional codes (e.g. Rate-Compatible-Punctured-Convolutional (RCPC) codes <ref> [40] </ref>). RCPC codes have become very popular due to their combination of flexibility and efficiency. The basic idea is that one can define an array of codes of differing strengths by simply "puncturing" parity bits appropriately to control the rate of the code.
Reference: [41] <author> Y. H. Kim and J. Modestino, </author> <title> "Adaptive entropy coded subband coding of images," </title> <journal> IEEE Trans. on Image Proc., </journal> <volume> vol. 1, </volume> <pages> pp. 31-48, </pages> <month> Jan. </month> <year> 1992. </year>
Reference-contexts: Puncturing tables specifying the parity bits to be suppressed are used to control the rate of the code. RCPC codes have become popular of late for protecting image and video sources, where different components of the bitstream have different error sensitivities, and therefore deserving of different degrees of protection <ref> [41] </ref>. <p> For example, the idea of unequal error protection channel codes (such as unequal-strength convolutional codes) that are appropriately designed to unequally protect different source components having different error-sensitivites (e.g. quantized source bit-planes) goes back to <ref> [41] </ref>. More efficient frameworks fashioned after similar principles have become popular recently [59]. It should be noted that this "digital" ideology, while allowing higher source compression because of entropy coding, can also lead to increased risk of error propagation. The popular solution is to insert periodic resynchronization capabilities using packetization.
Reference: [42] <author> S. Lin and J. D. J. Costello, </author> <title> Error control coding: Fundamentals and applications. </title> <publisher> Prentice-Hall, </publisher> <year> 1983. </year>
Reference-contexts: As an example, consider a (63; 12; 24; 5; 3) binary cyclic unequal error protection embedded code listed in <ref> [42] </ref>. Alternatively, one can consider two smaller BCH codes with characteristics (31; 11; 5) and (31; 12; 3). Combining these codes to yield a (62; 11; 12; 5; 3) is clearly inferior to the embedded option. <p> While embedded unequal error protection codes are more efficient than those derived from separate foward error correction codes, unequal error protection codes are hard to find, and no structured method has been described to design them. Lin et al. <ref> [42] </ref> tabulate all possible embedded codes of odd lengths up to 65 using exhaustive computer search. The list is fairly sparse, meaning that only a limited discrete set of rates and correction capabilities exist with embedding in the error correction coding domain. <p> Indeed, ARQ can be used as a "universal channel coding" scheme, as pointed out in Section 3.2. One of the most effective ARQ schemes is called the Class 2 hybrid ARQ <ref> [42] </ref>, which basically uses an ARQ based scheme to alternately send "data" and "parity" (a half-rate "invertible" code is used from which, given the parity information, the data can be obtained by simple "inversion"). <p> There exists a very interesting tradeoff between delay and redundancy that can be explored in a "continuous" way using a novel arithmetic-coding based error-detection framework [82]. Typically, a 16-bit CRC code is used to perform error detection in ARQ protocols <ref> [42] </ref>. Though efficient, the CRC can detect errors only after an entire block of data is received. In [82], a method of error detection is used that provides a continuous tradeoff between the amount of redundancy added and the amount of time before an error is detected.
Reference: [43] <author> B. Chen and G. W. Wornell, </author> <title> "Efficient channel coding for analog sources using chaotic systems," </title> <booktitle> in Proc. IEEE Glob. Telecommun. Conf., </booktitle> <pages> pp. 131-135, </pages> <year> 1996. </year>
Reference-contexts: This is a very powerful feature since without feedback, universality would be hard to achieve. There are other coding schemes in the literature, e.g., <ref> [43] </ref>, which are 3 although the complexity needed to attain this capacity may well be significantly lower if feedback is present. 4 Recall that in an erasure channel, the receiver knows which symbols are erased: this is typical for example of packet losses in networks. 15 universal in the sense that <p> In <ref> [43] </ref>, chaotic sequences for encoding of analog sources were shown to be better (in the end-to-end MSE sense) than any digital (finite-alphabet) codes for AWGN channels in some power-bandwidth regimes.
Reference: [44] <author> R. Schafer, </author> <title> "Terrestrial transmission of DTVB signals the european specification," </title> <booktitle> in International Broadcasting Convention, </booktitle> <volume> no. 413, </volume> <month> September </month> <year> 1995. </year>
Reference-contexts: A modulation-domain based unequal error protection scheme similar to that outlined above, has been considered for European digital audio and video broadcast <ref> [44] </ref>. Each layer of different error protection corresponds to the specific type of the receiving monitor (typically, there are three layers or resolutions) and have different bit error rate requirements. <p> A modulation-domain based unequal error protection scheme similar to that of [38] has been considered for European digital audio and video broadcast <ref> [44] </ref>. Each layer of different error protection corresponds to the specific type of the receiving monitor (typically, there are three layers or resolutions) and have different bit error rate requirements.
Reference: [45] <author> K. Fazel and M. Ruf, </author> <title> "Combined multilevel coding and multiresolution modulation," </title> <booktitle> in Proc. of ICC'93, </booktitle> <address> (Geneva), </address> <month> May </month> <year> 1993. </year> <month> 47 </month>
Reference-contexts: The added attraction of the embedded modulation scheme comes from being able to combine it naturally with standard error correction techniques, as was proposed in [38] and later in <ref> [45] </ref>, as well as with other techniques as described in the following section. 5 E.g., in the multiresolution-64 QAM example shown, for every 2 "important" cloud bits/symbol having increased protection, there are 4 "less important" satellite bits/symbol that get decreased protection. 17 3.4 Hybrid Embedded Options One can combine the concept
Reference: [46] <author> G. Ungerboeck, </author> <title> "Channel coding with multilevel/phase signals," </title> <journal> IEEE Trans. on Info. Th., </journal> <volume> vol. IT-28, </volume> <pages> pp. 55-67, </pages> <month> Jan. </month> <year> 1982. </year>
Reference-contexts: Examples include the combination of embedded modulation with unequal error protection channel codes (e.g. to increase the number of resolution layers), with Ungerboeck's Trellis Coded Modulation (TCM) <ref> [46] </ref> to achieve embedded TCM [38], with multicarrier systems to attain embedded multicarrier modulation, etc. In order to illustrate the power of these hybrids, we will pick multicarrier modulation as a representative example [47].
Reference: [47] <author> S. S. Pradhan and K. Ramchandran, </author> <title> "Efficient layered video delivery over multicarrier systems using optimized embedded modulations," </title> <booktitle> in Proc. of IEEE ICIP'97, </booktitle> <year> 1997. </year>
Reference-contexts: In order to illustrate the power of these hybrids, we will pick multicarrier modulation as a representative example <ref> [47] </ref>. We begin with a very brief review of multicarrier modulation, referring the reader to [48, 49, 50] for details. <p> Figure 6 gives a toy example showing a 3-carrier embedded modulation system. An optimal way of designing the embedded modulation system based on a fast table-lookup based power allocation (or "loading") method has been described in <ref> [47] </ref> with performance gains of the order of 25% in actual delivered throughput (or equivalently 1-2 dB in delivered image quality for image transmission applications) for an embedded 2-resolution multicarrier system over "naive" multiplexing of the two priorities. 3.5 Channel models used in multiresolution channel coding An obviously important question is
Reference: [48] <author> W. L. Zou and Y. Wu, </author> <title> "COFDM : An overview," </title> <journal> IEEE Trans. on Broadcasting, </journal> <volume> vol. 41, </volume> <pages> pp. 1-8, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: In order to illustrate the power of these hybrids, we will pick multicarrier modulation as a representative example [47]. We begin with a very brief review of multicarrier modulation, referring the reader to <ref> [48, 49, 50] </ref> for details. Multicarrier modulation has become a topic of great interest recently due to the demand for high-speed data transmission over twisted-pair copper wiring, an environment where severe intersymbol interference (ISI) can occur.
Reference: [49] <author> J. A. C. </author> <title> Bingham, "Multicarrier modulation for data transmission: An idea whose time has come," </title> <journal> IEEE Communications Magazine, </journal> <pages> pp. 5-14, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: In order to illustrate the power of these hybrids, we will pick multicarrier modulation as a representative example [47]. We begin with a very brief review of multicarrier modulation, referring the reader to <ref> [48, 49, 50] </ref> for details. Multicarrier modulation has become a topic of great interest recently due to the demand for high-speed data transmission over twisted-pair copper wiring, an environment where severe intersymbol interference (ISI) can occur.
Reference: [50] <author> P. S. Chow, J. C. Tu, and J. M. Cioffi, </author> <title> "A discrete multitone receiver system for hdsl applications," </title> <journal> IEEE J. on Sel. Areas in Comm., </journal> <volume> vol. 9, </volume> <pages> pp. 895-908, </pages> <month> Aug. </month> <year> 1991. </year>
Reference-contexts: In order to illustrate the power of these hybrids, we will pick multicarrier modulation as a representative example [47]. We begin with a very brief review of multicarrier modulation, referring the reader to <ref> [48, 49, 50] </ref> for details. Multicarrier modulation has become a topic of great interest recently due to the demand for high-speed data transmission over twisted-pair copper wiring, an environment where severe intersymbol interference (ISI) can occur. <p> Current DMT systems [51] are channel-adaptive but are single-resolution based, 18 i.e. there is a notion of a single, fixed Quality of Service, which is typically measured by a single fixed bit error rate for the entire bitstream (e.g. typically 10 7 bit error rate for xDSL <ref> [50] </ref>). In keeping with the multiresolution theme of this chapter, it is both useful and interesting to consider extensions of the single bit error rate regime to a multiple bit error rate regime, equivalent to having multiple qualities of service.
Reference: [51] <author> J. M. Cioffi, </author> <title> "A multicarrier primer," </title> <booktitle> in ANSI T1E1.4 Committee Contribution, </booktitle> <pages> pp. 91-157, </pages> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: One multicarrier method in particular, discrete multitone modulation (DMT), has become extremely popular due to its efficient implementation which uses fast Fourier transforms (FFTs) to modulate and demodulate data. DMT has been adopted as the standard for Asymmetric Digital Subscriber Loop (ADSL) telecommunications transmission technology <ref> [51, 52] </ref>. The fundamental idea behind multicarrier modulation is to divide a single communications channel into a large number of QAM subchannels which could be treated as independent Additive Gaussian Noise (AGN) AGN channels but colored rather than white. <p> Adaptivity to changing channel conditions is relatively simple in multicarrier modulation, and involves periodic reloading. Thus, if a particular subchannel should become extremely noisy, it can be "shut down" very easily by allocating no power or bits to it, as the waterpouring algorithm would dictate. Current DMT systems <ref> [51] </ref> are channel-adaptive but are single-resolution based, 18 i.e. there is a notion of a single, fixed Quality of Service, which is typically measured by a single fixed bit error rate for the entire bitstream (e.g. typically 10 7 bit error rate for xDSL [50]).
Reference: [52] <author> I. Kalet, </author> <title> "The multitone channel," </title> <journal> IEEE Trans. on Comm., </journal> <year> 1989. </year>
Reference-contexts: One multicarrier method in particular, discrete multitone modulation (DMT), has become extremely popular due to its efficient implementation which uses fast Fourier transforms (FFTs) to modulate and demodulate data. DMT has been adopted as the standard for Asymmetric Digital Subscriber Loop (ADSL) telecommunications transmission technology <ref> [51, 52] </ref>. The fundamental idea behind multicarrier modulation is to divide a single communications channel into a large number of QAM subchannels which could be treated as independent Additive Gaussian Noise (AGN) AGN channels but colored rather than white.
Reference: [53] <author> R. G. Gallager, </author> <title> Information Theory and Reliable Communication. </title> <address> New York: </address> <publisher> Wiley, </publisher> <year> 1968. </year>
Reference-contexts: The "loading" problem of optimizing the power and deliverable bit rate per symbol for each QAM subchannel for a given total power budget can be done elegantly in theory using the "inverse water-pouring" principle <ref> [53] </ref>. The idea is to invert the multichannel SNR spectral profile and pour water into it. The optimal energy allocation in each subchannel is simply the amount of water it contains, with the water-level depending on the total energy budget.
Reference: [54] <author> H. S. Wang and N. Moayeri, </author> <title> "Finite-state Markov channel-a useful model for radio communication channels," </title> <journal> IEEE Trans. Veh. Technol., </journal> <volume> vol. 44, </volume> <pages> pp. 163-171, </pages> <month> Feb. </month> <year> 1995. </year>
Reference-contexts: Transition between states may be modeled as a Markov process <ref> [54] </ref>. Consider a typical fading channel for wireless communication as in Fig. 8. The distribution of the fading parameter a depends on the actual communication channel. For example, in cellular communications, a good model for a is Rayleigh distribution, while for line-of-sight communications, a Rice distribution is often used [55].
Reference: [55] <author> J. G. Proakis, </author> <title> Digital Communications. </title> <publisher> McGraw-Hill, </publisher> <year> 1989. </year>
Reference-contexts: Consider a typical fading channel for wireless communication as in Fig. 8. The distribution of the fading parameter a depends on the actual communication channel. For example, in cellular communications, a good model for a is Rayleigh distribution, while for line-of-sight communications, a Rice distribution is often used <ref> [55] </ref>. Then an AWGN sample N is added to the result to yield the received signal Y . Each particular channel state is modeled as a discrete-time continuous amplitude AWGN channel with a distinct noise variance, and it is assumed that all channels are statistically independent. <p> This could be done with a state-of-the-art image compression platform based on entropy coding (variable codelengths), such as the zerotree wavelet-based SFQ coder of Section 2.2.3, followed by a power-efficient modulation scheme such as BPSK <ref> [55] </ref>. The second class of methods involves the combined design of source quantizers without entropy-coding (fixed codelengths) jointly with a PAM modulation scheme (recall Section 4.5.1), with a view to minimizing the total distortion subject to a total transmission power constraint (lower leg in Fig. 14).
Reference: [56] <author> J. Modestino, D.G.Daut, and A. Vickers, </author> <title> "Combined source-channel coding of images using the block cosine transform," </title> <journal> IEEE Trans. on Commun., </journal> <volume> vol. </volume> <pages> COM-29, pp. 1261-1274, </pages> <month> Sept. </month> <year> 1981. </year>
Reference-contexts: The understanding of the superiority of a joint approach to source and channel coding 22 in such cases has recently initiated numerous research activities in this area, a partial list of which can be found among <ref> [56, 57, 58] </ref>. In keeping with the theme of this chapter, we will focus on multiresolution-based frameworks for joint source-channel coding.
Reference: [57] <author> N. Farvardin and V. Vaishampayan, </author> <title> "On the performance and complexity of channel-optimized vector quantizers," </title> <journal> IEEE Trans. on Inform. Theory, </journal> <volume> vol. IT-37, </volume> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: The understanding of the superiority of a joint approach to source and channel coding 22 in such cases has recently initiated numerous research activities in this area, a partial list of which can be found among <ref> [56, 57, 58] </ref>. In keeping with the theme of this chapter, we will focus on multiresolution-based frameworks for joint source-channel coding. <p> The idea is to do intelligent mappings of source codewords into channel constellation points, so as to have a similarity mapping between "distances" in the source coding domain and "distances" in the channel modulation domain <ref> [60, 61, 57, 62, 63] </ref>. Thus, large source distortions are effectively mapped to high noise immunity, i.e. to low probability error events, and vice versa, with intelligently chosen index assignments. The advantages of such an approach are increased robustness and graceful degradation.
Reference: [58] <author> F. H. Liu, P. Ho, and V. Cuperman, </author> <title> "Joint source and channel coding using a non-linear receiver," </title> <booktitle> in Proc. of ICC'93, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: The understanding of the superiority of a joint approach to source and channel coding 22 in such cases has recently initiated numerous research activities in this area, a partial list of which can be found among <ref> [56, 57, 58] </ref>. In keeping with the theme of this chapter, we will focus on multiresolution-based frameworks for joint source-channel coding. <p> Several joint source-channel coding schemes which include more basic communication channel parameters like transmission power and bandwidth have been studied. AWGN channels have been studied in [67, 68, 69], and extensions to Rayleigh channels were considered in <ref> [58] </ref> with a view to optimizing joint performance subject to an average transmission power constraint. The framework in [58] was based on maximum a-posteriori estimation of the input source (based on tractable statistical signal models like autoregressive models, etc.). <p> AWGN channels have been studied in [67, 68, 69], and extensions to Rayleigh channels were considered in <ref> [58] </ref> with a view to optimizing joint performance subject to an average transmission power constraint. The framework in [58] was based on maximum a-posteriori estimation of the input source (based on tractable statistical signal models like autoregressive models, etc.). <p> These schemes use fixed-length code-words, i.e. they sacrifice the increased performance of variable-length codewords (through entropy coding) for robustness. A relevant attribute of these schemes, e.g. the scalar quantizer design for binary symmetric channels in [65] and the VQ design for AWGN channels in <ref> [58] </ref> has to do with the notion of reducing the number of codewords when the channel gets noisier, i.e. to correctly match the source and channel "resolutions." This matching can be very efficiently performed with the multiresolution representations as will be described later.
Reference: [59] <author> N. Tanabe and N. Farvardin, </author> <title> "Subband image coding using entropy-coded quantization over noisy channels," </title> <journal> IEEE J. Sel. Areas Commun., </journal> <volume> vol. 10, </volume> <pages> pp. 926-943, </pages> <month> june </month> <year> 1992. </year> <month> 48 </month>
Reference-contexts: For example, the idea of unequal error protection channel codes (such as unequal-strength convolutional codes) that are appropriately designed to unequally protect different source components having different error-sensitivites (e.g. quantized source bit-planes) goes back to [41]. More efficient frameworks fashioned after similar principles have become popular recently <ref> [59] </ref>. It should be noted that this "digital" ideology, while allowing higher source compression because of entropy coding, can also lead to increased risk of error propagation. The popular solution is to insert periodic resynchronization capabilities using packetization. <p> This is conceptually akin to the "analog" transmission philosphy introduced earlier. Binary Symmetric Channel transmission of still images with rate-compatible-punctured con-volustional (RCPC) codes [70] was addressed in <ref> [59] </ref> and more recently in [71], where a popular embedded wavelet-based zerotree coder [25] was combined with RCPC codes and a series-concatenated channel coder based on the "list Viterbi decoding" principle [72].
Reference: [60] <author> H.Kumazawa, M. Kasahara, and T. Namekawa, </author> <title> "A construction of vector quantizers for noisy channels," </title> <journal> Electron. Eng. Japan, </journal> <volume> vol. 67-B, </volume> <pages> pp. 39-47, </pages> <year> 1984. </year>
Reference-contexts: The idea is to do intelligent mappings of source codewords into channel constellation points, so as to have a similarity mapping between "distances" in the source coding domain and "distances" in the channel modulation domain <ref> [60, 61, 57, 62, 63] </ref>. Thus, large source distortions are effectively mapped to high noise immunity, i.e. to low probability error events, and vice versa, with intelligently chosen index assignments. The advantages of such an approach are increased robustness and graceful degradation. <p> The joint design of channel-optimized vector quantizers (VQ), as well as the mapping of these VQ indices to channel alphabets was presented in <ref> [60] </ref> and later in [66], where the value of "intelligent" mappings between source and channel domains was demonstrated. Due to the use of a high-dimensional VQ framework, finding these intelligent mappings is however generally a very computationally intensive process which usually results in only locally optimal solutions.
Reference: [61] <author> K. A. Zeger and A. Gersho, </author> <title> "Zero redundancy channel coding in vector quantization," </title> <journal> IEEE Electron. Letters, </journal> <pages> pp. 654-655, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: The idea is to do intelligent mappings of source codewords into channel constellation points, so as to have a similarity mapping between "distances" in the source coding domain and "distances" in the channel modulation domain <ref> [60, 61, 57, 62, 63] </ref>. Thus, large source distortions are effectively mapped to high noise immunity, i.e. to low probability error events, and vice versa, with intelligently chosen index assignments. The advantages of such an approach are increased robustness and graceful degradation.
Reference: [62] <author> I. Kozintsev and K. Ramchandran, </author> <title> "Multiresolution joint source-channel coding using embedded constellations for power-constrained time-varying channels.," </title> <booktitle> in Proc. IEEE Int. Conf. Acoust., Speech, and Signal Proc., </booktitle> <pages> pp. 2345-2348, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: The idea is to do intelligent mappings of source codewords into channel constellation points, so as to have a similarity mapping between "distances" in the source coding domain and "distances" in the channel modulation domain <ref> [60, 61, 57, 62, 63] </ref>. Thus, large source distortions are effectively mapped to high noise immunity, i.e. to low probability error events, and vice versa, with intelligently chosen index assignments. The advantages of such an approach are increased robustness and graceful degradation. <p> Illustrative Toy Example <ref> [62] </ref> We will now use an illustrative example (from [62]) to show the usefulness of having a multires-olution approach to joint source-channel coding that incorporate the techniques advocated in the previous sections, i.e. multiresolution embedded signal constellations, a modified Lloyd design for source scalar quantization, and a multistate channel model. <p> Illustrative Toy Example <ref> [62] </ref> We will now use an illustrative example (from [62]) to show the usefulness of having a multires-olution approach to joint source-channel coding that incorporate the techniques advocated in the previous sections, i.e. multiresolution embedded signal constellations, a modified Lloyd design for source scalar quantization, and a multistate channel model. <p> The important message is that this is better than trying to decode at full-resolution at all times. The degradation in performance due to constraining the number of codebooks to a multireso-lution codebook, rather than having separate codebooks for each channel state, has been shown in <ref> [62] </ref> to be insignificant. This is because of the key observation that in "bad" channel conditions, 34 the optimal design naturally chooses a lower source codebook resolution, validating the simpler and more elegant multiresolution approach. <p> When the source is not Gaussian however (e.g. even Generalized Gaussian [83]), linear mappings are no longer optimal. For this case, optimal analytical mappings are not known, and one has to resort to numerical methods <ref> [62] </ref> as illustrated in Section 4.3.3. Further, the optimality of linear mappings does not hold for the case of composite or mixture sources even in the Gaussian case [84]. <p> The joint source-channel coding algorithm of <ref> [62] </ref> (see toy example of Section 4.3.3) based on energy-optimized multiresolution codebook design is a representative of this class. The intuition behind trying to integrate these classes comes from an understanding of the fundamental tradeoffs associated with a "mixed" mode of operation.
Reference: [63] <author> M. W. Marcellin and T. R. Fischer, </author> <title> "Joint trellis coded quantization and modulation," </title> <journal> IEEE Trans. on Comm., </journal> <month> Jan. </month> <year> 1993. </year>
Reference-contexts: The idea is to do intelligent mappings of source codewords into channel constellation points, so as to have a similarity mapping between "distances" in the source coding domain and "distances" in the channel modulation domain <ref> [60, 61, 57, 62, 63] </ref>. Thus, large source distortions are effectively mapped to high noise immunity, i.e. to low probability error events, and vice versa, with intelligently chosen index assignments. The advantages of such an approach are increased robustness and graceful degradation. <p> Let us now take a brief look at a few recent examples that consider source-channel coding in more "sophisticated" frameworks. An interesting combination involves the joint design of Trellis Coded Quantization (TCQ) and Trellis Coded Modulation (TCM) in <ref> [63] </ref> by exploiting the fact that the two frameworks are duals of each other, one in the modulation (channel) domain, and the other in the quantization (source) domain.
Reference: [64] <author> W. F. Schreiber, </author> <title> "All-digital HDTV terrestrial broadcasting in the U.S. : Some problems and possible solutions," </title> <booktitle> Workshop on Advanced Television, </booktitle> <address> ENST, Paris, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: We will dedicate Section 4.5 to this, but will provide a sneak preview here to underline the historical perspective. A practical hybrid analog/digital transmission scheme was first proposed by Schreiber <ref> [64] </ref> using a novel analog-under-digital scheme. An all-digital solution in the same spirit was proposed in [38], where the goal was to merge the benefits of both ideologies, without giving up an all-digital representation, which has unthinkable political implications 6 . <p> The merging of the compression advantages of digital transmission systems with the natural robustness of analog systems was proposed in a novel hybrid analog-under-digital transmission scheme for the broadcast of HDTV by Schreiber <ref> [64] </ref>. The idea was to have analog information "ride on top" of digital modulation information (to form analog "clouds") with the essential information being sent digitally (to ensure lossless delivery), and the detail information riding in the analog clouds.
Reference: [65] <author> N. Farvardin and V. Vaishampayan, </author> <title> "Optimal quantizer design for noisy channels:an approach to combined source-channel coding," </title> <journal> IEEE Trans. on Inform. Theory, </journal> <volume> vol. IT-33, </volume> <pages> pp. 827-838, </pages> <month> Nov. </month> <year> 1987. </year>
Reference-contexts: Based on this, the optimization of source coders and/or mappings from source to channel alphabets was performed. This approach was advocated for example in <ref> [65] </ref>, where an algorithm similar in spirit to the celebrated Lloyd-Max optimal scalar quantizer design algorithm [17] was proposed to design an optimal scalar quantizer for a discrete memoryless channel. <p> These schemes use fixed-length code-words, i.e. they sacrifice the increased performance of variable-length codewords (through entropy coding) for robustness. A relevant attribute of these schemes, e.g. the scalar quantizer design for binary symmetric channels in <ref> [65] </ref> and the VQ design for AWGN channels in [58] has to do with the notion of reducing the number of codewords when the channel gets noisier, i.e. to correctly match the source and channel "resolutions." This matching can be very efficiently performed with the multiresolution representations as will be described
Reference: [66] <author> K. Zeger and A. Gersho, </author> <title> "Pseudo-gray coding," </title> <journal> IEEE Trans. on Commun., </journal> <volume> vol. 38, </volume> <pages> pp. 2147-2158, </pages> <month> Dec. </month> <year> 1990. </year>
Reference-contexts: The joint design of channel-optimized vector quantizers (VQ), as well as the mapping of these VQ indices to channel alphabets was presented in [60] and later in <ref> [66] </ref>, where the value of "intelligent" mappings between source and channel domains was demonstrated. Due to the use of a high-dimensional VQ framework, finding these intelligent mappings is however generally a very computationally intensive process which usually results in only locally optimal solutions.
Reference: [67] <author> P. G. M. de Bot, </author> <title> "Multiresolution transmission over the AWGN channel. </title> <type> Technical report TN 181/92," tech. rep., </type> <institution> Philips Research Laboratories Eindhoven, </institution> <address> The Netherlands, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Several joint source-channel coding schemes which include more basic communication channel parameters like transmission power and bandwidth have been studied. AWGN channels have been studied in <ref> [67, 68, 69] </ref>, and extensions to Rayleigh channels were considered in [58] with a view to optimizing joint performance subject to an average transmission power constraint. The framework in [58] was based on maximum a-posteriori estimation of the input source (based on tractable statistical signal models like autoregressive models, etc.).
Reference: [68] <author> M. Polley, S. Wee, and W. Schreiber, </author> <title> "Hybrid channel coding for multiresolution hdtv terrestrial broadcasting," </title> <booktitle> in Proc. of ICIP'94, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: Several joint source-channel coding schemes which include more basic communication channel parameters like transmission power and bandwidth have been studied. AWGN channels have been studied in <ref> [67, 68, 69] </ref>, and extensions to Rayleigh channels were considered in [58] with a view to optimizing joint performance subject to an average transmission power constraint. The framework in [58] was based on maximum a-posteriori estimation of the input source (based on tractable statistical signal models like autoregressive models, etc.).
Reference: [69] <author> T. Ramstad, </author> <title> "Efficient and robust communication based on signal decomposition and approximative multidimensional mappings between source and channel spaces," </title> <booktitle> in NORSIG'96 tutorial, </booktitle> <year> 1996. </year>
Reference-contexts: Several joint source-channel coding schemes which include more basic communication channel parameters like transmission power and bandwidth have been studied. AWGN channels have been studied in <ref> [67, 68, 69] </ref>, and extensions to Rayleigh channels were considered in [58] with a view to optimizing joint performance subject to an average transmission power constraint. The framework in [58] was based on maximum a-posteriori estimation of the input source (based on tractable statistical signal models like autoregressive models, etc.). <p> In [74] a joint design was suggested using the distortion-rate characteristics of scalar wavelet-based source coder and RCPC channel coder. Joint source-channel coding schemes for images based on many-to-many mappings between source domain and modulation domain have also been studied, for example in <ref> [69] </ref>. 4.2 Basic infrastructure of Multiresolution Joint Source-Channel Coding We now turn our attention to multiresolution based techniques, and explore a basic high-level philosophy for multiresolution joint source channel coding, that is useful in addressing a number of relevant scenarios of interest. <p> This could be tackled with "vector" mappings from source domain to modulation domain as in <ref> [69] </ref>.
Reference: [70] <author> J. Hagenauer, N. Seshadri, and C.-E. W. Sundberg, </author> <title> "The performance of rate-compatible punctured convolutional codes for digital mobile radio," </title> <journal> IEEE Trans. on Comm., </journal> <volume> vol. 38, </volume> <pages> pp. 966-980, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: This is conceptually akin to the "analog" transmission philosphy introduced earlier. Binary Symmetric Channel transmission of still images with rate-compatible-punctured con-volustional (RCPC) codes <ref> [70] </ref> was addressed in [59] and more recently in [71], where a popular embedded wavelet-based zerotree coder [25] was combined with RCPC codes and a series-concatenated channel coder based on the "list Viterbi decoding" principle [72].
Reference: [71] <author> P. G. Sherwood and K. Zeger, </author> <title> "Progressive image coding on noisy channels," </title> <journal> IEEE Signal Proc. Letters, </journal> <volume> vol. 4, </volume> <pages> pp. 654-655, </pages> <month> July </month> <year> 1997. </year> <month> 49 </month>
Reference-contexts: This is conceptually akin to the "analog" transmission philosphy introduced earlier. Binary Symmetric Channel transmission of still images with rate-compatible-punctured con-volustional (RCPC) codes [70] was addressed in [59] and more recently in <ref> [71] </ref>, where a popular embedded wavelet-based zerotree coder [25] was combined with RCPC codes and a series-concatenated channel coder based on the "list Viterbi decoding" principle [72]. <p> By cascading this "sophisticated" channel coder trivially with a "sophisticated" embedded wavelet zerotree image source coder (such as [25]) as done in <ref> [71] </ref>, one can obtain robust image transmission systems. With more powerful channel coders (such as that of [73]) and more powerful source coders (such as that of [30]), even better systems can result, as pointed out in [73].
Reference: [72] <author> N. Seshadri and C.-E. W. Sundberg, </author> <title> "List viterbi decoding algorithms with applications," </title> <journal> IEEE Trans. on Comm., </journal> <volume> vol. 42, </volume> <pages> pp. 313-323, </pages> <month> February/March/April </month> <year> 1994. </year>
Reference-contexts: Binary Symmetric Channel transmission of still images with rate-compatible-punctured con-volustional (RCPC) codes [70] was addressed in [59] and more recently in [71], where a popular embedded wavelet-based zerotree coder [25] was combined with RCPC codes and a series-concatenated channel coder based on the "list Viterbi decoding" principle <ref> [72] </ref>. The list-Viterbi decoding paradigm is a conceptually simple but powerful extension of the conventional Viterbi decoding paradigm in that it keeps at each state of the trellis, a top-N list of best-metric paths, with the traditional Viterbi decoder having N = 1. The work in [72] reported substantial performance improvement <p> "list Viterbi decoding" principle <ref> [72] </ref>. The list-Viterbi decoding paradigm is a conceptually simple but powerful extension of the conventional Viterbi decoding paradigm in that it keeps at each state of the trellis, a top-N list of best-metric paths, with the traditional Viterbi decoder having N = 1. The work in [72] reported substantial performance improvement over the conventional Viterbi decoder by combining a first-stage list-Viterbi convolutional coder with a second-stage error-detection coder using a block Cyclic-Redundancy-Check (CRC) code, achieved by declaring the correct Viterbi path as the highest-ranked candidate Viterbi path in the trellis (from the ranked top N list) that
Reference: [73] <author> I.Kozintsev, J. Chou, and K. Ramchandran, </author> <title> "Image transmission using arithmetic coding based continuous error detection.," </title> <booktitle> in Data Compression Conference '94, </booktitle> <address> (Snowbird, Utah), </address> <month> April </month> <year> 1998. </year> <note> Submitted. </note>
Reference-contexts: A more sophisticated extension of the list-Viterbi framework has been recently considered in <ref> [73] </ref> through the use of a novel continuous-error-detection second stage based on arithmetic coding that "dynamically" checks the validity of subtrellis paths and maintains a "legal" top-N list at each state. <p> By cascading this "sophisticated" channel coder trivially with a "sophisticated" embedded wavelet zerotree image source coder (such as [25]) as done in [71], one can obtain robust image transmission systems. With more powerful channel coders (such as that of <ref> [73] </ref>) and more powerful source coders (such as that of [30]), even better systems can result, as pointed out in [73]. Note that these are examples of separately designed systems that have state-of-the-art source and channel coding components. <p> With more powerful channel coders (such as that of <ref> [73] </ref>) and more powerful source coders (such as that of [30]), even better systems can result, as pointed out in [73]. Note that these are examples of separately designed systems that have state-of-the-art source and channel coding components. <p> When this method of error detection is applied to ARQ protocols, significant gains in throughput performance (or equivalently, delivered image quality) are obtained over conventional ARQ schemes. Recent results <ref> [73] </ref> also indicate the gains of continuous error detection applied to serial concatenated coding schemes with convolutional codes. As mentioned in Section 4.1, continuous error detection can be integrated into list-Viterbi decoding to improve system performance in the face of limited memory/complexity constraints.
Reference: [74] <author> M. Ruf and J. Modestino, </author> <title> "Rate-distortion performance for joint source and channel coding of images," </title> <booktitle> in Proc. of ICIP'95, </booktitle> <pages> pp. 77-80, </pages> <year> 1995. </year>
Reference-contexts: This points to the advantages of having an embedded source representation (see Section 2.1). In <ref> [74] </ref> a joint design was suggested using the distortion-rate characteristics of scalar wavelet-based source coder and RCPC channel coder.
Reference: [75] <author> I. Kozintsev and K. Ramchandran, </author> <title> "Robust image transmission over energy-constrained time-varying channels using multiresolution joint source-channel coding," </title> <journal> IEEE Trans. on Signal Processing, </journal> <year> 1997. </year>
Reference-contexts: in this case, the use of a multiresolution framework is not theoretically optimal (except if the source obeys a certain Markov property [6] see Section 2.1), but a multiresolution design is more flexible and attractive from an engineering perspective (architectural simplicity) with little loss in performance typically (see for example <ref> [75] </ref>), with the encoder and decoder both "picking off" the resolution they want to live at based on the channel state information. <p> As noted earlier, the use of a mul-tiresolution framework is not theoretically optimal, but a multiresolution design is far more flexible and convenient, and in practice, there is little performance loss <ref> [75, 79] </ref>). The use of channel-matched hierarchical vector quantization for image transmission over noisy channels with feedback has been described in [79] building on the hierarchical VQ source coding framework of [80].
Reference: [76] <author> S. McCanne, M. Vetterli, and V. Jacobson, </author> <title> "Low-complexity video coding for receiver-driven layered multicast," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 15, </volume> <pages> pp. 983-1001, </pages> <month> Aug. </month> <year> 1997. </year>
Reference-contexts: More precisely, a multicast transmission can be conceptualized as living on a multiresolutin tree, that is a set of trees carrying various resolutions. Each user then reaches as many levels of the multiresolution tree as is possible given its access capabilities. Such a scheme was proposed in <ref> [76] </ref> for a heterogeneous packet environment, as for example the internet. Figure 12 succintly captures the basic idea. While currently mostly wired links are involved, it is clear that mobile components are becoming more and more important as well.
Reference: [77] <author> D. Bertsekas, </author> <title> Nonlinear programming. Belmont: </title> <publisher> Athena Scientific, </publisher> <year> 1995. </year>
Reference-contexts: These individual contributions are summed among all source symbols and averaged over two possible channel states yielding the total expected distortion. To solve the constrained problem of (1,3) we introduce the Lagrange multiplier <ref> [77] </ref> and solve the unconstrained problem of the form: min [J (M; ; T s ; C s ) = EfD (X; ^ X)g + E av ] (4) where parameter &gt; 0 is chosen to satisfy the energy constraint (3) and can be interpreted as a coefficient which trades off
Reference: [78] <author> P. Chou, T. Lookabaugh, and R. Gray, </author> <title> "Entropy-constrained vector quantization," </title> <journal> IEEE Trans. Acoust. Speech Signal Process., </journal> <volume> vol. 37, </volume> <pages> pp. 31-42, </pages> <month> Jan. </month> <year> 1989. </year>
Reference-contexts: It is insightful to note that the cost of assigning x to fl i in expression (5) is a weighted sum of distortion and energy associated with this decision, which is a variation of the entropy-constrained vector quantization (ECVQ) <ref> [78] </ref> problem in which an equivalent "entropy" term in ECVQ is replaced by an "energy" term. At this step, we find the optimal position for the boundary between regions fl i and fl i+1 , which minimizes the cost-function (4) with all other parameters being fixed.
Reference: [79] <author> H.Jafarkhani and N.Farvardin, </author> <title> "Channel-matched hierarchical table-lookup vector quantization for transmission of video over wireless channels," </title> <booktitle> in Int'l Conf. on Image Proc., ICIP'96, </booktitle> <volume> vol. </volume> <pages> 3, </pages> <address> (Lausanne, Switzerland), </address> <pages> pp. 755-758, </pages> <month> Sep. </month> <year> 1996. </year>
Reference-contexts: As noted earlier, the use of a mul-tiresolution framework is not theoretically optimal, but a multiresolution design is far more flexible and convenient, and in practice, there is little performance loss <ref> [75, 79] </ref>). The use of channel-matched hierarchical vector quantization for image transmission over noisy channels with feedback has been described in [79] building on the hierarchical VQ source coding framework of [80]. <p> The use of channel-matched hierarchical vector quantization for image transmission over noisy channels with feedback has been described in <ref> [79] </ref> building on the hierarchical VQ source coding framework of [80]. A big advantage of having feedback channels is that they can be used, for applications where 35 delay requirements are friendly, to signal errors in the received digital stream if additional redun-dancy is spent on error detection (ARQ schemes).
Reference: [80] <author> M. Vishwanath and P. Chou, </author> <title> "An efficient algorithm for hierarchical compression of video," </title> <booktitle> in Proc. of ICIP'94, </booktitle> <volume> vol. </volume> <pages> 3, </pages> <address> (Austin, TX), </address> <pages> pp. 275-279, </pages> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: The use of channel-matched hierarchical vector quantization for image transmission over noisy channels with feedback has been described in [79] building on the hierarchical VQ source coding framework of <ref> [80] </ref>. A big advantage of having feedback channels is that they can be used, for applications where 35 delay requirements are friendly, to signal errors in the received digital stream if additional redun-dancy is spent on error detection (ARQ schemes).
Reference: [81] <author> G. Buch, F. Burket, J. Hagenauer, and B. Kukla, </author> <title> "To compress or not to compress?," </title> <booktitle> in Proc. IEEE Glob. Telecommun. Conf., </booktitle> <year> 1996. </year>
Reference-contexts: This can be done, for example, very efficiently by using systematic versions of a family of UEP channel codes like RCPC, as was shown in <ref> [81] </ref>. The idea is simple. The data is sent first with a few parity bits (highest rate code). If this is acknowledged without error (as detected using a block CRC check), the next data packet is transmitted. <p> This approach was advocated in the [86], where the a priori information about the source was used to help the Viterbi decoder in estimating the correct path for RCPC-encoded data. This ideology was developed further in <ref> [81] </ref> where the usefulness of digital compression via entropy coding was questioned. It was demonstrated that for certain situations it pays to leave the redundancy in the source instead of trying to get rid of it using compression and than reinserting it with the channel coding.
Reference: [82] <author> J. Chou and K. Ramchandran, </author> <title> "Arithmetic-coding based continuous error detection for efficient arq-based image transmission," </title> <booktitle> in Proc. 31st Ann. Asilomar Conf. on Sig., Syst., and Comp., </booktitle> <address> (Pacific Grove, CA), </address> <month> Nov. </month> <year> 1997. </year> <note> To appear. </note>
Reference-contexts: There exists a very interesting tradeoff between delay and redundancy that can be explored in a "continuous" way using a novel arithmetic-coding based error-detection framework <ref> [82] </ref>. Typically, a 16-bit CRC code is used to perform error detection in ARQ protocols [42]. Though efficient, the CRC can detect errors only after an entire block of data is received. In [82], a method of error detection is used that provides a continuous tradeoff between the amount of redundancy <p> and redundancy that can be explored in a "continuous" way using a novel arithmetic-coding based error-detection framework <ref> [82] </ref>. Typically, a 16-bit CRC code is used to perform error detection in ARQ protocols [42]. Though efficient, the CRC can detect errors only after an entire block of data is received. In [82], a method of error detection is used that provides a continuous tradeoff between the amount of redundancy added and the amount of time before an error is detected.
Reference: [83] <author> K. A. Birney and T. R. Fischer, </author> <title> "On the modeling of DCT and subband image data for compression," </title> <journal> IEEE Trans. on Image Proc., </journal> <volume> vol. 4, </volume> <pages> pp. 186-193, </pages> <month> Feb. </month> <year> 1995. </year> <month> 50 </month>
Reference-contexts: Also observe that source and channel coding are not performed separately but in a joint linear mapping operation: this is a simple but powerful example of the potential of joint source-channel coding. When the source is not Gaussian however (e.g. even Generalized Gaussian <ref> [83] </ref>), linear mappings are no longer optimal. For this case, optimal analytical mappings are not known, and one has to resort to numerical methods [62] as illustrated in Section 4.3.3.
Reference: [84] <author> I.Kozintsev and K. Ramchandran, </author> <title> "Robust image transmission using multiresolution joint source-channel coding.," </title> <booktitle> in Information Theory Workshop'98, </booktitle> <address> (San Diego, CA), </address> <month> February </month> <year> 1998. </year> <note> To appear. </note>
Reference-contexts: For this case, optimal analytical mappings are not known, and one has to resort to numerical methods [62] as illustrated in Section 4.3.3. Further, the optimality of linear mappings does not hold for the case of composite or mixture sources even in the Gaussian case <ref> [84] </ref>. This case is of interest as Gaussian mixture distributions have been shown to be very accurate for modeling wavelet image coefficients [30], where a coding algorithm based on this attains performance that ranks among the very best in the cited literature. <p> this performance and the distor tion will increase by a factor K given by: K = D OP T A ( 1 P N ( i=1 i ) 2=N Nevertheless, K is small (empirical results reveal that it is typically about 0:5 dB for wavelet coefficients of typical natural images <ref> [84] </ref>), then considering the complexity needed to approach the theoretical upper bound using conventional Shannon-type arguments, the simplicity of a joint source-channel mapping approach becomes very attractive. 4.5.2 Applications to image transmission In order to be able to recover at least partially from channel errors, some amount of the communication link
Reference: [85] <author> I. Kozintsev and K. Ramchandran, </author> <title> "A hybrid compressed-uncompressed framework for wireless image transmission," </title> <booktitle> in Proc. of ICIP'97, </booktitle> <address> (Santa Barbara, California), </address> <month> Oct </month> <year> 1997. </year>
Reference-contexts: Indeed, the task of assigning all redundancy to the channel coder is a corollary of separation principle, and may well be suboptimal for finite complexity systems. We illustrate by a specific example the advantage of this approach <ref> [85] </ref>. <p> The question of efficient allocation of redundancy between source and channel coders for delivery of visual data over low power wireless channels has been recently addressed in <ref> [85] </ref> as the question of how to efficiently represent an image or video source into compressed and uncompressed subsets. The motivation is based on integrating the two classes of joint source-channel coding techniques (based on "analog" and "digital" transmission ideologies respectively) mentioned in Section 4.1. <p> This could be tackled with "vector" mappings from source domain to modulation domain as in [69]. An alternate and simpler method based on scalar mappings has been described in <ref> [85] </ref>, where the key idea is to elegantly dispense with the need to transmit N 2 coefficients through the use of the wavelet zerotree structure, and combine this with simple scalar quantization of the "significant" image wavelet coefficients. This results in a high-performance image coder for slow fading energy-constrained channels. <p> This results in a high-performance image coder for slow fading energy-constrained channels. The idea in <ref> [85] </ref> is to induce a source decomposition into two components, each suited to the appropriate mode of transmission outlined. <p> An interesting observation is that the lower the delay requirement (lower the rate of channel usage per source symbol), the higher the fraction of the uncompressed mode that is used by the optimal hybrid system <ref> [85] </ref>. See the reconstructed images of Fig. 15 and Fig. 16 for a subjective comparison of the conventional and hybrid systems respectively. corresponds to the conventional entropy-coded digital system (first approach).
Reference: [86] <author> J. Hagenauer, </author> <title> "Source-controlled channel decoding," </title> <journal> IEEE Trans. on Comm., </journal> <volume> vol. 43, </volume> <pages> pp. 2449-2457, </pages> <month> September </month> <year> 1995. </year> <month> 51 </month>
Reference-contexts: This approach was advocated in the <ref> [86] </ref>, where the a priori information about the source was used to help the Viterbi decoder in estimating the correct path for RCPC-encoded data. This ideology was developed further in [81] where the usefulness of digital compression via entropy coding was questioned.
References-found: 84

