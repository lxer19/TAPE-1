URL: ftp://ftp.speech.sri.com/pub/papers/eurospeech.95.sankar.ps.gz
Refering-URL: http://www.speech.sri.com/people/sankar/publications.html
Root-URL: 
Title: Training Data Clustering For Improved Speech Recognition  
Author: Ananth Sankar, Fran~coise Beaufays, and Vassilios Digalakis 
Address: 333 Ravenswood Avenue Menlo Park, CA 94025  
Affiliation: SRI International  
Note: To appear in Proceedings of EUROSPEECH, 1995, Madrid, Spain  
Abstract: We present an approach to cluster the training data for automatic speech recognition (ASR). A relative-entropy based distance metric between training data clusters is defined. This metric is used to hierarchically cluster the training data. The metric can also be used to select the closest training data clusters given a small amount of data from the test speaker. The selected clusters are then used to estimate a set of hidden Markov models (HMMs) for recognizing the speech from the test speaker. We present preliminary experimental results of the clustering algorithm and its application to ASR. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Sankar and C.-H. Lee, </author> <title> "Stochastic Matching for Robust Speech Recognition," </title> <journal> IEEE Signal Processing Letters, </journal> <volume> vol. 1, </volume> <pages> pp. 124-125, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: Current approaches to the problem of mismatch between the training and testing environments include adaptation methods based on maximum-likelihood (ML) estimation of the parameters of a hypothesized transformation from the training to the testing environment <ref> [1, 2] </ref>, and maximum a posteriori (MAP) estimation techniques [3]. The MAP approaches perform well with large amounts of adaptation data but poorly with limited adaptation data, since, in this case, they are biased in favor of the training data. <p> As opposed to the MAP approach of [3], the algorithm presented in this paper uses a relatively small amount of adaptation data while efficiently organizing the training data. No assumption is made about the underlying transformation between the training and testing data, as in the ML approaches of <ref> [1, 2] </ref>. Thus, the new method is a candidate for handling a wide range of possible mismatches. 2 Training Data Clustering The concept of clustering the training data is already used in a trivial sense in many ASR systems that use gender-dependent models.
Reference: [2] <author> V. Digalakis, D. Rtischev, and L. Neumeyer, </author> <title> "Speaker adaptation using constrained reestima-tion of gaussian mixtures," </title> <journal> IEEE Transactions on Speech and Audio Processing, </journal> <note> 1994. to appear. </note>
Reference-contexts: Current approaches to the problem of mismatch between the training and testing environments include adaptation methods based on maximum-likelihood (ML) estimation of the parameters of a hypothesized transformation from the training to the testing environment <ref> [1, 2] </ref>, and maximum a posteriori (MAP) estimation techniques [3]. The MAP approaches perform well with large amounts of adaptation data but poorly with limited adaptation data, since, in this case, they are biased in favor of the training data. <p> As opposed to the MAP approach of [3], the algorithm presented in this paper uses a relatively small amount of adaptation data while efficiently organizing the training data. No assumption is made about the underlying transformation between the training and testing data, as in the ML approaches of <ref> [1, 2] </ref>. Thus, the new method is a candidate for handling a wide range of possible mismatches. 2 Training Data Clustering The concept of clustering the training data is already used in a trivial sense in many ASR systems that use gender-dependent models. <p> Estimating a separate HMM model set for each cluster node in the tree would require storage of a large number of parameters. This may well become infeasible. To address this issue, we use the maximum-likelihood transformation-based adaptation algorithm of <ref> [2] </ref> to transform the speaker-independent (SI) HMMs to the HMMs corresponding to the cluster. <p> In <ref> [2] </ref>, a separate affine transformation is used for each cluster of Gaussian densities in the SI models. The number of such transformations for each set of template models fl i can be tuned to match the available data in the corresponding training cluster. <p> We first trained SI (speaker-independent) genonic acoustic models [9] using the 3 18722 utterances from the 142 male speakers. In an initial experiment, we then estimated a separate adapted template model set <ref> [2] </ref> for each of the 10 test speakers. Recall that only a small number of transformation parameters need to be stored for each template model. Equation 8 was then used to identify the closest template model for each of the 230 test sentences. <p> In all but 3 sentences, the algorithm identified the template model correctly, yielding a speaker identification error-rate of 1:3%. This shows the efficacy of using the relative-entropy measure described in Section 2. In a second experiment, we estimated 142 adapted template models <ref> [2] </ref>, one for each training speaker. For each test utterance, we computed the N closest template models using Equation 8, for several chosen values of N .
Reference: [3] <author> C.-H. Lee and J.-L. Gauvain, </author> <title> "Speaker Adaptation Based on MAP Estimation of HMM Parameters," </title> <booktitle> in Proceedings IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pp. </pages> <address> II-558-II-561, </address> <year> 1993. </year>
Reference-contexts: Current approaches to the problem of mismatch between the training and testing environments include adaptation methods based on maximum-likelihood (ML) estimation of the parameters of a hypothesized transformation from the training to the testing environment [1, 2], and maximum a posteriori (MAP) estimation techniques <ref> [3] </ref>. The MAP approaches perform well with large amounts of adaptation data but poorly with limited adaptation data, since, in this case, they are biased in favor of the training data. The ML-based transformation methods may be used with small amounts of adaptation data. <p> The ML-based transformation methods may be used with small amounts of adaptation data. However, their efficacy rests largely on the correctness of the hypothesized transformation, which, in most cases, is unknown. As opposed to the MAP approach of <ref> [3] </ref>, the algorithm presented in this paper uses a relatively small amount of adaptation data while efficiently organizing the training data. No assumption is made about the underlying transformation between the training and testing data, as in the ML approaches of [1, 2].
Reference: [4] <author> R. Duda and P. Hart, </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> John Wiley & Sons, </publisher> <year> 1973. </year>
Reference-contexts: We form the clusters of training data in the form of a hierarchical cluster tree. The leaves of the tree represent the N individual speakers in the training data, and the root represents all the training speakers. The cluster tree is built using an agglomerative clustering scheme <ref> [4] </ref>, based on a relative-entropy distance metric [5]. The models we use to compute the 1 distance metric are mixtures of gaussian densities. A similar distance metric for speaker clustering was considered in [6]. <p> Having computed all the inter-speaker distances, we build the tree by merging, at each iteration, the two clusters that are the closest according to some inter-cluster distance metric. Three such distance metrics <ref> [4] </ref> were considered: d min (C i ; C j ) = min D s (m; n); (4) m 2C i ; n 2C j d avg (C i ; C j ) = avg D s (m; n): (6) 3 Recognition Using Cluster Tree Once the cluster tree is built,
Reference: [5] <author> B.-H. Juang and L. R. Rabiner, </author> <title> "A Probabilistic Distance Measure for Hidden Markov Models," </title> <journal> AT&T Technical Journal, </journal> <volume> vol. 64, </volume> <pages> pp. 391-408, </pages> <month> February </month> <year> 1984. </year>
Reference-contexts: The leaves of the tree represent the N individual speakers in the training data, and the root represents all the training speakers. The cluster tree is built using an agglomerative clustering scheme [4], based on a relative-entropy distance metric <ref> [5] </ref>. The models we use to compute the 1 distance metric are mixtures of gaussian densities. A similar distance metric for speaker clustering was considered in [6]. However, in that work, the observations were assumed to be discrete, instead of continuous as in this work.
Reference: [6] <author> J. T. Foote and H. Silverman, </author> <title> "A Model Distance Measure For Talker Clustering And Identification," </title> <booktitle> in Proceedings IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 1, </volume> <pages> pp. 317-320, </pages> <year> 1994. </year>
Reference-contexts: The cluster tree is built using an agglomerative clustering scheme [4], based on a relative-entropy distance metric [5]. The models we use to compute the 1 distance metric are mixtures of gaussian densities. A similar distance metric for speaker clustering was considered in <ref> [6] </ref>. However, in that work, the observations were assumed to be discrete, instead of continuous as in this work. Furthermore, in [6], the models used to compute the relative entropy are discrete density HMMs, whereas in our work we use mixture gaussian models. <p> The models we use to compute the 1 distance metric are mixtures of gaussian densities. A similar distance metric for speaker clustering was considered in <ref> [6] </ref>. However, in that work, the observations were assumed to be discrete, instead of continuous as in this work. Furthermore, in [6], the models used to compute the relative entropy are discrete density HMMs, whereas in our work we use mixture gaussian models. Specifically, we first estimate the parameters of the mixture gaussian density models for each of the N training speakers.
Reference: [7] <author> J. R. Bellegarda, P. V. de Souza, D. Nahamoo, M. Padmanabhan, M. Picheny, and L. Bahl, </author> <title> "Experiments Using Data Augmentation For Speaker Adaptation," </title> <booktitle> in Proceedings IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 1, </volume> <pages> pp. 692-695, </pages> <year> 1995. </year>
Reference-contexts: During recognition, a small amount of data from the test speaker is used to select the best cluster. Then the HMM corresponding to this cluster is used for recognition. Alternately, we can augment the test data with the data from the closest cluster in a manner similar to <ref> [7] </ref> and estimate a new model for recognition. Estimating a separate HMM model set for each cluster node in the tree would require storage of a large number of parameters. This may well become infeasible.
Reference: [8] <author> G. Doddington, </author> <title> "CSR Corpus Development," </title> <booktitle> in Proc. DARPA SLS Workshop, </booktitle> <pages> pp. 363-366, </pages> <year> 1992. </year>
Reference-contexts: Equation 8 can be inter preted as finding fl that minimizes D fl X ;fl defined in Equation 2. 4 Experimental Results 4.1 Cluster Tree In this section, we present an experimental study of the clustering algorithm. We experimented on the Wall Street Journal (WSJ) continuous speech recognition corpus <ref> [8] </ref>. The training set consists 142 male and 142 female training speakers. Mixture gaussian models with 32 gaussians were trained for each of the 284 training speakers. We then used the agglomerative clustering algorithm described in Section 2 to group the training speakers.
Reference: [9] <author> V. Digalakis, P. Monaco, and H. Murveit, "Genones: </author> <title> Generalized mixture tying in continuous hidden markov model-based speech recogniz-ers," </title> <note> 1994. submitted to IEEE Transactions on Speech and Audio Processing. 4 </note>
Reference-contexts: We first trained SI (speaker-independent) genonic acoustic models <ref> [9] </ref> using the 3 18722 utterances from the 142 male speakers. In an initial experiment, we then estimated a separate adapted template model set [2] for each of the 10 test speakers. Recall that only a small number of transformation parameters need to be stored for each template model.
References-found: 9

