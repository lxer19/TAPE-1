URL: ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1531.ps.Z
Refering-URL: http://www.ai.mit.edu/projects/cbcl/course9.520-96/class-3.html
Root-URL: 
Title: Linear Object Classes and Image Synthesis from a Single Example Image  
Author: Thomas Vetter and Tomaso Poggio 
Note: This publication can be retrieved by anonymous ftp to publications.ai.mit.edu. Version  Copyright c Massachusetts Institute of Technology, 1994  
Date: 1531 March, 1995  119  revised December, 1995.  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY and CENTER FOR BIOLOGICAL AND COMPUTATIONAL LEARNING DEPARTMENT OF BRAIN AND COGNITIVE SCIENCES  
Pubnum: A.I. Memo No.  C.B.C.L. Paper No.  
Abstract: The need to generate new views of a 3D object from a single real image arises in several fields, including graphics and object recognition. While the traditional approach relies on the use of 3D models, we have recently introduced [11, 6, 5] techniques that are applicable under restricted conditions but simpler. The approach exploits image transformations that are specific to the relevant object class and learnable from example views of other "prototypical" objects of the same class. In this paper, we introduce such a new technique by extending the notion of linear class first proposed by Poggio and Vetter [12]. For linear object classes it is shown that linear transformations can be learned exactly from a basis set of 2D prototypical views. We demonstrate the approach on artificial objects and then show preliminary evidence that the technique can effectively "rotate" high-resolution face images from a single 2D view. This report describes research done at the Max-Planck-Institut fur biologische Kybernetik Tubingen, Germany and the Artificial Intelligence Laboratory and within the Center for Biological and Computational Learning in the Department of Brain and Cognitive Sciences at the Massachusetts Institute of Technology. This research is sponsored by grants from ONR under contract N00014-93-1-0385 and from ARPA-ONR under contract N00014-92-J-1879; and by a grant from the National Science Foundation under contract ASC-9217041 (this award includes funds from ARPA provided under the HPCC program). Additional support is provided by the North Atlantic Treaty Organization, ATR Audio and Visual Perception Research Laboratories, Mitsubishi Electric Corporation, Sumitomo Metal Industries, Kodak, Daimler-Benz and Siemens AG. Support for the A.I. Laboratory's artificial intelligence research is provided by ARPA-ONR contract N00014-91-J-4038. Tomaso Poggio is supported by the Uncas and Helen Whitaker Chair at MIT's Whitaker College. Thomas Vetter holds a Helmholtz fellowship from the BMFT Germany. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Beier and S. Neely. </author> <title> Feature-based image meta-morphosis. </title> <booktitle> In SIGGRAPH '92 proceedings, </booktitle> <pages> pages 35-42, </pages> <address> Chicago, IL, </address> <year> 1992. </year>
Reference-contexts: Three example faces are shown, each from two different viewpoints accordingly to a rotation of 22:5 ffi . Since the class of all faces has more than three dimensions a synthetic face image is used to test the method. This synthetic face is generated by a standard morphing technique <ref> [1] </ref> between the two upper left images. This ensures that the necessary requirements for the linear class assumption hold, that is the test image is a linear combination of the example images in texture and 2D-shape.
Reference: [2] <author> J.R. Bergen and E.H. Adelson. </author> <title> Hierarchical, computationally efficient motion estimation algorithm. </title> <address> 4:35, </address> <year> 1987. </year>
Reference-contexts: These conditions make it feasible to compare the images of the different objects with automatic techniques. Such algorithms are known from optical flow computation, in which points have to be tracked from one image to the other. We use a coarse-to-fine gradient-based gradient method <ref> [2] </ref> and follow an implementation described in [3].
Reference: [3] <author> J.R. Bergen and R. Hingorani. </author> <title> Hierarchical motionbased frame rate conversion. </title> <type> Technical report, </type> <institution> David Sarnoff Research Center Princeton NJ 08540, </institution> <year> 1990. </year>
Reference-contexts: Such algorithms are known from optical flow computation, in which points have to be tracked from one image to the other. We use a coarse-to-fine gradient-based gradient method [2] and follow an implementation described in <ref> [3] </ref>.
Reference: [4] <author> D. Beymer. </author> <title> Face recognition under varying pose. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1461, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1993. </year>
Reference-contexts: Our linear object class approach also assumes that the orientation of an object in an image is known. The orientation of faces can be approximated computing the correlation of a new image to templates of faces in various orientations <ref> [4] </ref>. It is not clear how precisely the orientation should be estimated to yield satisfactory results. Appendix A Decomposing objects into parts In the previous section we considered learning the appropriate transformation from full views. In this case, the examples (prototypes) must have the same dimensionality as a full view.
Reference: [5] <author> D. Beymer and T. Poggio. </author> <title> Face recognition from one model view. </title> <booktitle> In ICCV proceedings, </booktitle> <year> 1995. </year>
Reference-contexts: Prior information about bilateral symmetry allows the synthesis of new virtual views from a single real one, thereby simplifying the task of generalization in recognition of the new object under different poses. Bilateral symmetry has been used in face recognition systems <ref> [5] </ref> and psychophysical evidence supports its use by the human visual system [15, 13, 18]. <p> In all of these approaches the underlying representation of images of the new object are in terms of linear combinations of the shape of examples of representative other objects. Beymer, Shashua and Poggio [6] as well as Beymer and Poggio <ref> [5] </ref> have developed and demonstrated a more powerful version of this approach based on non-linear learning networks for generating new grey-level images of the same object or of objects of a known class. Beymer and Poggio [5] also demonstrated that new textures of an object can be generated by linear combinations <p> Beymer, Shashua and Poggio [6] as well as Beymer and Poggio <ref> [5] </ref> have developed and demonstrated a more powerful version of this approach based on non-linear learning networks for generating new grey-level images of the same object or of objects of a known class. Beymer and Poggio [5] also demonstrated that new textures of an object can be generated by linear combinations of textures of different objects. In this paper, we extend and introduce the technique of linear classes to generate new views of an object. <p> In this paper, we extend and introduce the technique of linear classes to generate new views of an object. The technique is similar to the approach of <ref> [5, 6] </ref> but more powerful since it relies less on correspondence between prototypical examples and the new image. The work described in this paper is based on the idea of linear object classes. <p> Key to our approach is a representation of an object view in terms of a shape vector and a texture vector (see also Jones and Poggio [9] and Beymer and Poggio <ref> [5] </ref>). The first gives the image-plane coordinates of feature points of the object surface; the second provides their colour or grey-level. <p> Here we are in the nice situation of a separate shape and texture space. In an application the coefficients ff i for the shape and coefficients fi i for the texture can be computed separately. In face recognition experiments <ref> [5] </ref> the coefficients fi i were already used to generate a new texture of a faces using textures of differnt faces. Figure 3 shows a test of this linear approach for a separated 2D-shape and texture space in combination with the approximated correspondence. <p> To overcome this problem, correspondence between images taken from different viewpoints should be used to map the specific texture on the new orientation <ref> [9, 5] </ref>. 5 Discussion Linear combinations of images of a single object have been already successfully used to create a new image of that object [16]. Here we created a new image of an object using linear combinations of images of different objects of the same class.
Reference: [6] <author> D. Beymer, A. Shashua, and T. Poggio. </author> <title> Examplebased image anaysis and synthesis. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1431, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1993. </year>
Reference-contexts: In all of these approaches the underlying representation of images of the new object are in terms of linear combinations of the shape of examples of representative other objects. Beymer, Shashua and Poggio <ref> [6] </ref> as well as Beymer and Poggio [5] have developed and demonstrated a more powerful version of this approach based on non-linear learning networks for generating new grey-level images of the same object or of objects of a known class. <p> In this paper, we extend and introduce the technique of linear classes to generate new views of an object. The technique is similar to the approach of <ref> [5, 6] </ref> but more powerful since it relies less on correspondence between prototypical examples and the new image. The work described in this paper is based on the idea of linear object classes.
Reference: [7] <author> David Beymer. </author> <title> Vectorizing face images by interleav-ing shape and texture computations. </title> <note> to appear as A.I. Memo, </note> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1995. </year>
Reference-contexts: In our implementation we used a general method for finding this correspondence. However, if the class of objects is known in advance, a method specific to this object class could be used <ref> [9, 7] </ref>. In this case the correspondence field is linearly modeled by a known set of deformations specific to that class of objects. A second problem, specific to our approach is the existence of linear object classes and the completeness of the available examples.
Reference: [8] <author> A. Hurlbert and T Poggio. </author> <title> Synthetizing a color algorithm from examples. </title> <journal> SCIENCE, </journal> <volume> 239 </volume> <pages> 482-485, </pages> <year> 1988. </year>
Reference: [9] <author> M. Jones and T. Poggio. </author> <title> Model-based matching of line drawings by linear combination of prototypes. </title> <booktitle> In ICCV proceedings, </booktitle> <year> 1995. </year>
Reference-contexts: Key to our approach is a representation of an object view in terms of a shape vector and a texture vector (see also Jones and Poggio <ref> [9] </ref> and Beymer and Poggio [5]). The first gives the image-plane coordinates of feature points of the object surface; the second provides their colour or grey-level. <p> To overcome this problem, correspondence between images taken from different viewpoints should be used to map the specific texture on the new orientation <ref> [9, 5] </ref>. 5 Discussion Linear combinations of images of a single object have been already successfully used to create a new image of that object [16]. Here we created a new image of an object using linear combinations of images of different objects of the same class. <p> In our implementation we used a general method for finding this correspondence. However, if the class of objects is known in advance, a method specific to this object class could be used <ref> [9, 7] </ref>. In this case the correspondence field is linearly modeled by a known set of deformations specific to that class of objects. A second problem, specific to our approach is the existence of linear object classes and the completeness of the available examples.
Reference: [10] <author> P. Kalocsai, I.Biederman, and E.E. Cooper. </author> <title> To what extent can the recognition of unfamiliar faces be accounted for by a representation of the direct output of simple cell. </title> <booktitle> In Annual Meeting of the Association for Research in Vision and Opthalmology, </booktitle> <address> Sarasota, Fl, </address> <year> 1994. </year>
Reference-contexts: Our visual system is certainly able to perform this task even if at performance levels that are likely to be lower than expected from our introspection <ref> [10, 15] </ref>. The obvious explanation is that we exploit prior information about how face images transform, learned through extensive experience with other faces.
Reference: [11] <author> T. Poggio and R. Brunelli. </author> <title> A novel approach to graphics. </title> <type> Technical report 1354, </type> <institution> MIT Media Laboratory Perceptual Computing Section, </institution> <year> 1992. </year>
Reference-contexts: Although our approach originates from the proposal of Poggio and Brunelli <ref> [11] </ref> and of Poggio and Vetter [12], for countering the curse-of-dimensionality in applications of supervised learning techniques, similar approaches with different motivations have been used in several different fields. <p> It also require correspondence between the new image and one of the prototypes in the same pose but does not need correspondence between different poses as in the parallel deformation technique of Poggio and Brunelli <ref> [11] </ref> and Beymer et al.[6]. The paper is organized as follows. The next section formally introduces linear object classes, first for objects defined only through their shape vector.
Reference: [12] <author> T. Poggio and T. Vetter. </author> <title> Recognition and structure from one 2D model view: observations on proto-types, object classes, and symmetries. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1347, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1992. </year>
Reference-contexts: The obvious explanation is that we exploit prior information about how face images transform, learned through extensive experience with other faces. Thus the key idea (see <ref> [12] </ref>), is to learn class-specific image-plane transformations from examples of objects of the same class and then to apply them to the real image of the new object in order to synthesize virtual views that can be used as additional examples in a view-based object recognition or graphic system. <p> Prior knowledge about a class of objects may be known in terms of invariance properties. Poggio and Vetter <ref> [12] </ref> examined in particular the case of bilateral symmetry of certain 3D objects, such as faces. Prior information about bilateral symmetry allows the synthesis of new virtual views from a single real one, thereby simplifying the task of generalization in recognition of the new object under different poses. <p> Although our approach originates from the proposal of Poggio and Brunelli [11] and of Poggio and Vetter <ref> [12] </ref>, for countering the curse-of-dimensionality in applications of supervised learning techniques, similar approaches with different motivations have been used in several different fields. In computer graphics, actor- based animation has been used to generate sequences of views of a character by warping an available sequence of a similar character. <p> We will derive the necessary and sufficient conditions for a set of objects to be a linear object class. 2.1 Shape of 3D objects Consider a 3D view of an three-dimensional object, which is defined in terms of pointwise features <ref> [12] </ref>. A 3D view can be represented by a vector X = (x 1 ; y 1 ; z 1 ; x 2 ; :::::; y n ; z n ) T , that is by the x; y; z- coordinates of its n feature points.
Reference: [13] <author> P.G. Schyns and H.H. Bulthoff. </author> <title> Sparse observations on cortical mechanisms for object recognition and learning. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1404, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1993. </year>
Reference-contexts: Bilateral symmetry has been used in face recognition systems [5] and psychophysical evidence supports its use by the human visual system <ref> [15, 13, 18] </ref>.
Reference: [14] <author> D.H. Cooper T.F. Cootes, C.J. Taylor and J. Graham. </author> <title> Active shape models their training and appli-cation. </title> <booktitle> Computer Vision and Image Understanding, </booktitle> <volume> 60 </volume> <pages> 38-59, </pages> <year> 1995. </year>
Reference-contexts: In computer graphics, actor- based animation has been used to generate sequences of views of a character by warping an available sequence of a similar character. In computer vision the approach closest to the first part of ours is the active shape models of Cootes, Taylor, Cooper and Graham <ref> [14] </ref>. They build flexible models of known rigid objects by linear combination of labeled examples for the task of image search recognition and localization.
Reference: [15] <author> N. Troje and H.H. Bulthoff. </author> <title> Face recognition un-der varying pose: The role of texture and shape. </title> <note> submitted, </note> <year> 1995. </year>
Reference-contexts: Our visual system is certainly able to perform this task even if at performance levels that are likely to be lower than expected from our introspection <ref> [10, 15] </ref>. The obvious explanation is that we exploit prior information about how face images transform, learned through extensive experience with other faces. <p> Bilateral symmetry has been used in face recognition systems [5] and psychophysical evidence supports its use by the human visual system <ref> [15, 13, 18] </ref>.
Reference: [16] <author> S. Ullman and R. Basri. </author> <title> Recognition by linear combinations of models. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13:9921006, </volume> <year> 1991. </year>
Reference-contexts: To overcome this problem, correspondence between images taken from different viewpoints should be used to map the specific texture on the new orientation [9, 5]. 5 Discussion Linear combinations of images of a single object have been already successfully used to create a new image of that object <ref> [16] </ref>. Here we created a new image of an object using linear combinations of images of different objects of the same class. Given only a single image of an object, we are able to generate additional synthetic images of this object under the assumption that the "linear class" property holds.
Reference: [17] <author> T. Vetter and T. Poggio. </author> <title> Symmetric 3D objects are an easy case for 2D object recognition. Spatial Vision, </title> <booktitle> 8(4) </booktitle> <pages> 443-453, </pages> <year> 1995. </year>
Reference: [18] <author> T. Vetter, T. Poggio, and H.H. Bulthoff. </author> <title> The im-portance of symmetry and virtual views in threedimensional object recognition. </title> <booktitle> Current Biology, </booktitle> <volume> 4 </volume> <pages> 18-23, </pages> <year> 1994. </year>
Reference-contexts: Bilateral symmetry has been used in face recognition systems [5] and psychophysical evidence supports its use by the human visual system <ref> [15, 13, 18] </ref>.
Reference: [19] <author> Georg Wolberg. </author> <title> Image Warping. </title> <publisher> IEEE Computer Society Press, </publisher> <address> Los Alamitos CA, </address> <year> 1990. </year> <month> 9 </month>
Reference-contexts: The new location generally does not coincide with the equally spaced grid of pixels of the destination image. A commonly used solution of this problem is known as forward warping <ref> [19] </ref>. For every new pixel, we use the nearest three points to linearly approximate the pixel intensity. 4 Is the linear class assumption valid for real objects? For man made objects, which often consist of cuboids, cylinders or other geometric primitives, the assumption of linear object classes seems almost natural.
References-found: 19

