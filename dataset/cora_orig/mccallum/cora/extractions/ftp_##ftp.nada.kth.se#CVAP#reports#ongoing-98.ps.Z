URL: ftp://ftp.nada.kth.se/CVAP/reports/ongoing-98.ps.Z
Refering-URL: http://www.nada.kth.se/cvap/index.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Computational Vision and Active Perception Laboratory, CVAP  
Author: JAN-OLOF EKLUNDH, STEFAN CARLSSON, TONY LINDEBERG, AND FREDRIK BERGHOLM 
Date: January 1998  
Abstract-found: 0
Intro-found: 1
Reference: <author> -Akerman, S., Lindeberg, T. and Roland, P. </author> <year> (1996). </year> <title> Surface model generation and segmentation of the human celebral cortex for the construction of unfolded cortical maps, </title> <booktitle> 2nd International Conference on Functional Mapping of the Human Brain, </booktitle> <address> Boston, Massachussetts, p. </address> <month> 126. </month> <title> In: </title> <journal> NeuroImage, </journal> <volume> vol. 3, no. 3. 5 Almansa, </volume> <editor> A. and Lindeberg, T. </editor> <year> (1996). </year> <title> Enhancement of fingerprint images by shape-adapted scale-space operators, </title> <editor> in J. Sporring, M. Nielsen, L. Florack and P. Johansen (eds), </editor> <title> Gaussian Scale-Space Theory: </title> <booktitle> Proc. PhD School on Scale-Space Theory, </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <address> Copenhagen, Denmark. </address>
Reference: <author> Argyros, A. and Orphanoudakis, S. </author> <year> (1997). </year> <title> Independent 3d motion detection based on depth elimination in normal flow fields, </title> <booktitle> Proc. IEEE Comp. Soc. Conf. on Computer Vision and Pattern Recognition, 1997, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <address> San Juan, Puerto Rico. </address>
Reference-contexts: We have so far mainly worked on navigation problems, 2 focusing on model based but correspondence free methods, see (Carlsson, 1994) and the thesis by Lundquist (1997). A problem related to obstacle avoidance is addressed in <ref> (Argyros and Orphanoudakis, 1997) </ref>, work performed at CVAP within one of our TMR exchange programs.
Reference: <author> Brautigam, C., G-arding, J. and Eklundh, J.-O. </author> <year> (1996). </year> <title> Seeing the obvious, </title> <booktitle> Proc. 13th International Conference on Pattern Recognition, </booktitle> <volume> Vol. I, </volume> <publisher> IEEE Computer Society Press, </publisher> <address> Vienna, Austria, </address> <pages> pp. 67-72. </pages>
Reference: <author> Bretzner, L. and Lindeberg, T. </author> <year> (1997). </year> <title> On the handling of spatial and temporal scales in feature tracking, </title> <editor> in ter Haar Romeny et al. (ed.), </editor> <booktitle> Proc. 1st Int. Conf. on Scale-Space Theory in Computer Vision, </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin, Utrecht, The Netherlands, </address> <pages> pp. 128-139. </pages>
Reference: <author> Bretzner, L. and Lindeberg, T. </author> <year> (1998). </year> <title> Feature tracking with automatic selection of spatial scales, Computer Vision and Image Understanding . (To appear). </title>
Reference: <author> Brunnstrom, K. </author> <year> (1993). </year> <title> Active Exploration of Static Scenes, </title> <publisher> Ph. </publisher> <address> D. </address> <institution> dissertation, Dept. of Numerical Analysis and Computing Science, KTH, Stockholm, Sweden. ISRN KTH/NA/P--93/29--SE. </institution>
Reference: <author> Brunnstrom, K., Eklundh, J.-O. and Uhlin, T. </author> <year> (1996). </year> <title> Active fixation for scene exploration, </title> <booktitle> Int. J. of Computer Vision 17: </booktitle> <pages> 137-162. </pages>
Reference-contexts: Future work will deal with coupling such processes to the computation of shape and motion characteristics of selected objects and also to recognition. Some results in this direction, althoughat low level, are given in <ref> (Brunnstrom et al., 1996) </ref>. The problem of cue integration has in particular been studied in the context of finding conspicuous planar surfaces, and especially the ground plane, without complete scene reconstruction and camera calibration; see (Fornland and Schnorr, 1997; Fornland, 1995; Brautigam et al., 1996).
Reference: <author> Carlsson, S. </author> <year> (1994). </year> <title> Sufficient image structure for 3-D motion and shape estimation, </title> <editor> in J.-O. Eklundh (ed.), </editor> <booktitle> Proc. 3rd European Conference on Computer Vision, Vol. 800 of Lecture Notes in Computer Science, </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin, Stockholm, Sweden, </address> <pages> pp. 83-91. </pages> <note> Also in ISRN KTH/NA/P--94/24 -SE, </note> <month> Aug. </month> <year> 1994. </year>
Reference-contexts: The longterm aim is of course to consider cased where the active observer actually performs some task, e.g. involving navigation or manipulation . We have so far mainly worked on navigation problems, 2 focusing on model based but correspondence free methods, see <ref> (Carlsson, 1994) </ref> and the thesis by Lundquist (1997). A problem related to obstacle avoidance is addressed in (Argyros and Orphanoudakis, 1997), work performed at CVAP within one of our TMR exchange programs. <p> In order for it to be possible to estimate 3D structure and motion from image data, a rigid curved structure must project a certain amount of variation in the image. This was analyzed in <ref> (Carlsson, 1994) </ref> where also an algorithm for estimation of 3D structure and motion of sufficiently variable curves was presented. The fact that the mapping from 3D to the image is in general described as a perspective projection implies that projective geometry is of central importance in vision problems.
Reference: <author> Carlsson, S. </author> <year> (1995). </year> <title> View variation and linear invariants in 2-D and 3-D, </title> <type> Technical Report ISRN KTH/NA/P--95/22--SE, </type> <institution> Dept. of Numerical Analysis and Computing Science, KTH, Stockholm, Sweden. </institution>
Reference-contexts: A central problem in the recognition of 3D objects from single image is the fact that complete view invariant descriptors cannot be computed. By considering qualitative image properties such as order and incidence structure <ref> (Carlsson, 1995) </ref>, restricted view invariant descriptors can be defined. This also allows for the definition of equivalence classes of objects that are related to categories instead of specific object instances. In (Carlsson, 1996) this was defined for line segment descriptors and is currently being extended to include curved segments.
Reference: <author> Carlsson, S. </author> <year> (1996). </year> <title> Projectively invariant decomposition and recognition of planar shapes, </title> <booktitle> Int. J. of Computer Vision 17: </booktitle> <pages> 193-209. </pages>
Reference-contexts: In order to solve vision problems independently of camera calibration, projectively invariant representations are necessary. Within the ESPRIT project VIVA, we studied projectively invariant representations of planar shapes using an algorithm for fitting conic primitives. This was used for planar object recognition <ref> (Carlsson, 1996) </ref> and compared with alternative methods in a joint work (Carlsson et al., 1996). Given multiple views of an object in 3D the fundamental questions that can be addressed are: 1. What is the structure of the object in 3D ? and 2. <p> Within the ESPRIT project VIVA, we studied projectively invariant representations of planar shapes using an algorithm for fitting conic primitives. This was used for planar object recognition (Carlsson, 1996) and compared with alternative methods in a joint work <ref> (Carlsson et al., 1996) </ref>. Given multiple views of an object in 3D the fundamental questions that can be addressed are: 1. What is the structure of the object in 3D ? and 2. <p> By considering qualitative image properties such as order and incidence structure (Carlsson, 1995), restricted view invariant descriptors can be defined. This also allows for the definition of equivalence classes of objects that are related to categories instead of specific object instances. In <ref> (Carlsson, 1996) </ref> this was defined for line segment descriptors and is currently being extended to include curved segments. The general problem of shape based view invariant recognition and its connection with various geometric representations ranging from metric to order and incidence is reviewed in (Carlsson, 1998).
Reference: <author> Carlsson, S. </author> <year> (1998). </year> <title> Geometric structure and view invariant recognition, </title> <journal> Philosophical Transactions of the Royal Society of London Series A . (To appear). </journal>
Reference-contexts: positions of the cameras relative to the object ? For uncalibrated perspective cameras it turns out that these problems are computationally dual for the case of imaging point sets in 3D, (i.e. they can be analyzed and solved in the same way with camera position and 3D point position exchanged.) <ref> (Carlsson and Weinshall, 1998) </ref>. A central problem in the recognition of 3D objects from single image is the fact that complete view invariant descriptors cannot be computed. By considering qualitative image properties such as order and incidence structure (Carlsson, 1995), restricted view invariant descriptors can be defined. <p> In (Carlsson, 1996) this was defined for line segment descriptors and is currently being extended to include curved segments. The general problem of shape based view invariant recognition and its connection with various geometric representations ranging from metric to order and incidence is reviewed in <ref> (Carlsson, 1998) </ref>.
Reference: <author> Carlsson, S., Mohr, R., Moons, T., Morin, L., Rothwell, C., van Dienst, M., van Gool, L., Veillon, F. and Zisserman, A. </author> <year> (1996). </year> <title> Semi-local projective invariants for the recognition of smooth plane curves, </title> <booktitle> Int. J. of Computer Vision 19(3): </booktitle> <pages> 211-236. </pages> <note> 6 Carlsson, </note> <author> S. and Weinshall, D. </author> <year> (1998). </year> <title> Dual computation of projective shape and camera positions from multiple images, </title> <booktitle> Int. J. of Computer Vision 27: </booktitle> <pages> 227-243. </pages>
Reference-contexts: In order to solve vision problems independently of camera calibration, projectively invariant representations are necessary. Within the ESPRIT project VIVA, we studied projectively invariant representations of planar shapes using an algorithm for fitting conic primitives. This was used for planar object recognition <ref> (Carlsson, 1996) </ref> and compared with alternative methods in a joint work (Carlsson et al., 1996). Given multiple views of an object in 3D the fundamental questions that can be addressed are: 1. What is the structure of the object in 3D ? and 2. <p> Within the ESPRIT project VIVA, we studied projectively invariant representations of planar shapes using an algorithm for fitting conic primitives. This was used for planar object recognition (Carlsson, 1996) and compared with alternative methods in a joint work <ref> (Carlsson et al., 1996) </ref>. Given multiple views of an object in 3D the fundamental questions that can be addressed are: 1. What is the structure of the object in 3D ? and 2. <p> By considering qualitative image properties such as order and incidence structure (Carlsson, 1995), restricted view invariant descriptors can be defined. This also allows for the definition of equivalence classes of objects that are related to categories instead of specific object instances. In <ref> (Carlsson, 1996) </ref> this was defined for line segment descriptors and is currently being extended to include curved segments. The general problem of shape based view invariant recognition and its connection with various geometric representations ranging from metric to order and incidence is reviewed in (Carlsson, 1998).
Reference: <author> Eklundh, J.-O. </author> <year> (1996). </year> <title> Machine vision research at CVAP an introduction, </title> <booktitle> Int. </booktitle>
Reference-contexts: In a general sense our longterm research deals with the principles of a seeing agent. As is pointed out in <ref> (Eklundh, Nordlund and Uhlin, 1996) </ref> and as also noted by Fermuller and Aloimonos (1995), such work require the development of systems that actually close the loop between perception and action.
Reference: <author> J. </author> <booktitle> of Computer Vision 17: </booktitle> <pages> 107-112. </pages>
Reference: <author> Eklundh, J.-O., Nordlund, P. and Uhlin, T. </author> <year> (1996). </year> <title> Issues in active vision: attention and cue integration/selection, </title> <booktitle> Proc. British Machine Vision Conference 1996, </booktitle> <pages> pp. 1-12. </pages>
Reference-contexts: In a general sense our longterm research deals with the principles of a seeing agent. As is pointed out in <ref> (Eklundh, Nordlund and Uhlin, 1996) </ref> and as also noted by Fermuller and Aloimonos (1995), such work require the development of systems that actually close the loop between perception and action.
Reference: <author> Eklundh, J.-O., Uhlin, T., Nordlund, P. and Maki, A. </author> <year> (1996). </year> <title> Active vision and seeing robots, </title> <editor> in G. Giralt and G. Hirzinger (eds), </editor> <booktitle> The 7th Symposium on Robotics Research, Lecture Notes in Computer Science, </booktitle> <publisher> Springer Verlag, Berlin, </publisher> <pages> pp. 416-427. </pages>
Reference-contexts: In a general sense our longterm research deals with the principles of a seeing agent. As is pointed out in <ref> (Eklundh, Nordlund and Uhlin, 1996) </ref> and as also noted by Fermuller and Aloimonos (1995), such work require the development of systems that actually close the loop between perception and action.
Reference: <author> Eriksson, B., Johansson, F., Lindeberg, T. and Roland, P. </author> <year> (1997). </year> <title> Automatic matching of brain images and brain atlases using multi-scale fusion algorithms, </title> <editor> in L. Friberg, A. Gjedde, S. Holm, N. Lassen and M. Novak (eds), </editor> <booktitle> Proc 3rd International Conference on Functional Mapping of the Human Brain, </booktitle> <publisher> Academic Press, </publisher> <address> Copenhagen, </address> <publisher> Denmark, </publisher> <editor> p. </editor> <volume> 419. Neuroimage vol. 5 no 4. p 419, </volume> <year> 1997. </year>
Reference-contexts: A method for analysing 3-D brain activation patternsis presented in (Lidberg et al., 1997) including the computation of the spatial extent and the significance of regional cerebral blood flow changes. In <ref> (Eriksson et al., 1997) </ref> we describe a method for automatic matching of 3-D brain images for brain atlases. Our more recent work concerns the extension of the scale-space theory to temporal image data.
Reference: <author> Fermuller, C. and Aloimonos, Y. </author> <year> (1995). </year> <title> Vision and action, </title> <booktitle> Image and Vision Computing 13(10): </booktitle> <pages> 725-744. </pages>
Reference: <author> Fornland, P. </author> <year> (1995). </year> <title> Direct obstacle detection and motion from spatio-temporal derivatives, </title> <editor> in V. Klavac and R. Sara (eds), </editor> <booktitle> Proc. 6th International Conf. on Computer Analysis of Images and Patterns, </booktitle> <address> Prague, Czech Republic, </address> <pages> pp. 874-879. </pages>
Reference: <author> Fornland, P. and Schnorr, C. </author> <year> (1997). </year> <title> A robust and convergent iterative approach for determining the dominant plane from two views without correspondence and calibration, </title> <booktitle> Proc. IEEE Comp. Soc. Conf. on Computer Vision and Pattern Recognition, 1997, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <address> San Juan, Puerto Rico, </address> <pages> pp. 508-513. </pages>
Reference: <author> Francisco, A. </author> <year> (1994). </year> <title> Active Structure Acquisition by Continous Fixation Movements, </title> <publisher> Ph. </publisher> <address> D. </address> <institution> dissertation, Dept. of Numerical Analysis and Computing Science, KTH, Stockholm, Sweden. ISRN KTH/NA/P--94/17--SE. </institution>
Reference: <author> Francisco, A. and Bergholm, F. </author> <year> (1998). </year> <title> On the importance of being asymmetric in stereopsis or why we should use skewed parallel cameras, </title> <note> Int. J. of Computer Vision . (To appear). </note>
Reference: <author> Frisby, J. P., Buckley, D., Wishart, K. A., Porrill, J., G-arding, J. and Mayhew, J. E. W. </author> <year> (1995). </year> <title> Interaction of stereo and texture cues in the perception of three-dimensional steps, </title> <booktitle> Vision Research 35(10): </booktitle> <pages> 1463-1472. </pages> <note> 7 G-arding, </note> <author> J. and Lindeberg, T. </author> <year> (1994). </year> <title> Direct estimation of local surface shape in a fixating binocular vision system, </title> <editor> in J.-O. Eklundh (ed.), </editor> <booktitle> Proc. 3rd European Conference on Computer Vision, Vol. 800 of Lecture Notes in Computer Science, </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin, Stockholm, Sweden, </address> <pages> pp. 365-376. </pages>
Reference-contexts: It can finally be added that our work within the INSIGHT-project in collaboration with researchers on human vision has provided important contributions on stereopsis (relevant for a fixating head-eye system and cue integration, see <ref> (Frisby et al., 1995) </ref> and (G-arding et al., 1995). 3 Scale-space theory for a visual front-end When constructing a computer vision system, a key problem concerns what types of operations should be performed on the image data.
Reference: <author> G-arding, J. and Lindeberg, T. </author> <year> (1996). </year> <title> Direct computation of shape cues using scale-adapted spatial derivative operators, </title> <booktitle> Int. J. of Computer Vision 17(2): </booktitle> <pages> 163-191. </pages>
Reference: <author> G-arding, J., Porrill, J., Mayhew, J. E. W. and Frisby, J. P. </author> <year> (1995). </year> <title> Stereopsis, vertical disparity and relief transformations, </title> <booktitle> Vision Research 35(5): </booktitle> <pages> 703-722. </pages>
Reference: <author> Koenderink, J. J. </author> <year> (1984). </year> <title> The structure of images, </title> <booktitle> Biological Cybernetics 50: </booktitle> <pages> 363-370. </pages>
Reference: <author> Li, M. </author> <year> (1997). </year> <title> Kinematic calibration of an active head-eye system, </title> <journal> IEEE Transactions on Robotics and Automation 14(2). </journal>
Reference-contexts: Our early work on this subject (Lindeberg and G-arding, 1993; Lindeberg and G-arding, 1994; G-arding and Lindeberg, 1994) has been refined to (G-arding and Lindeberg, 1996) to a uniform framework for computing local surface orientation from monocular texture cues and binocular disparities using second-moment descriptors. In <ref> (Lindeberg and G-arding, 1997) </ref> this methodology is complemented by a general mechanism for shape adaptation, which is necessary to obtain unbiased surface orientation estimates. <p> In ( -Akerman et al., 1996) we outline a method for computing a surface based atlas of the human brain for subsequent unfolding of the cortex. A method for analysing 3-D brain activation patternsis presented in <ref> (Lidberg et al., 1997) </ref> including the computation of the spatial extent and the significance of regional cerebral blood flow changes. In (Eriksson et al., 1997) we describe a method for automatic matching of 3-D brain images for brain atlases.
Reference: <author> Li, M. and Betsis, D. </author> <year> (1995). </year> <title> Head-eye calibration, </title> <booktitle> Proc. 5th International Conference on Computer Vision, </booktitle> <address> Cambridge, MA, </address> <pages> pp. 40-45. </pages>
Reference-contexts: We have in particular studied dynamic fixation for a mobile, binocular observer, (Pahlavan et al., 1996), and how it can be used to pick out objects in a complex world, as shown in e.g. <ref> (Uhlin et al., 1995) </ref>. As stressed in (Uhlin and Eklundh, 1995) such a system should be able to capitalize on whatever information is available in the scene and hence be based on multiple cues. The issue of integrating and selecting between cues then becomes central. <p> We have in particular studied dynamic fixation for a mobile, binocular observer, (Pahlavan et al., 1996), and how it can be used to pick out objects in a complex world, as shown in e.g. (Uhlin et al., 1995). As stressed in <ref> (Uhlin and Eklundh, 1995) </ref> such a system should be able to capitalize on whatever information is available in the scene and hence be based on multiple cues. The issue of integrating and selecting between cues then becomes central.
Reference: <author> Li, M. and Lavest, J.-M. </author> <year> (1996). </year> <title> Some aspects of zoom-lens camera calibration, </title> <journal> IEEE Trans. Pattern Analysis and Machine Intell. </journal> <volume> 18(11): </volume> <pages> 1105-1110. </pages>
Reference-contexts: In a general sense our longterm research deals with the principles of a seeing agent. As is pointed out in <ref> (Eklundh, Nordlund and Uhlin, 1996) </ref> and as also noted by Fermuller and Aloimonos (1995), such work require the development of systems that actually close the loop between perception and action. <p> The general mechanism for automatic scale selection has been tested and applied to a rich set of computer vision problems. Examples include the computation of shape abstractions of curves (Lindeberg and Li, 1997; Lindeberg and Olofsson, 1995; Olofsson, 1996) , the analysis of fingerprint images <ref> (Almansa and Lindeberg, 1996) </ref> and the classification of steel properties based on the local mi-crostructure of carbide distributions (Wiltschi et al., 1997). A domain we have studied over the last four years concerns the computation of cues to surface shape directly from visual front-end operations. <p> A domain we have studied over the last four years concerns the computation of cues to surface shape directly from visual front-end operations. Our early work on this subject (Lindeberg and G-arding, 1993; Lindeberg and G-arding, 1994; G-arding and Lindeberg, 1994) has been refined to <ref> (G-arding and Lindeberg, 1996) </ref> to a uniform framework for computing local surface orientation from monocular texture cues and binocular disparities using second-moment descriptors. In (Lindeberg and G-arding, 1997) this methodology is complemented by a general mechanism for shape adaptation, which is necessary to obtain unbiased surface orientation estimates. <p> In (Eriksson et al., 1997) we describe a method for automatic matching of 3-D brain images for brain atlases. Our more recent work concerns the extension of the scale-space theory to temporal image data. In <ref> (Lindeberg and Fagerstrom, 1996) </ref> we present an extension of scale-space models in (Lindeberg, 1990) to a fully time-recursive visual front-end.
Reference: <author> Lidberg, P., Lindeberg, T. and Roland, P. </author> <year> (1997). </year> <title> Analysis of brain activation patterns using a 3-D scale-space primal sketch, </title> <editor> in L. Friberg, A. Gjedde, S. Holm, N. Lassen and M. Novak (eds), </editor> <booktitle> Proc. 3rd International Conference on Functional Mapping of the Human Brain, </booktitle> <publisher> Academic Press, </publisher> <address> Copenhagen, </address> <publisher> Denmark, </publisher> <editor> p. </editor> <volume> 393. Neuroimage vol. 5 no. 4 p 393, </volume> <year> 1997. </year>
Reference-contexts: In ( -Akerman et al., 1996) we outline a method for computing a surface based atlas of the human brain for subsequent unfolding of the cortex. A method for analysing 3-D brain activation patternsis presented in <ref> (Lidberg et al., 1997) </ref> including the computation of the spatial extent and the significance of regional cerebral blood flow changes. In (Eriksson et al., 1997) we describe a method for automatic matching of 3-D brain images for brain atlases.
Reference: <author> Lindeberg, T. </author> <year> (1990). </year> <title> Scale-space for discrete signals, </title> <journal> IEEE Trans. Pattern Analysis and Machine Intell. </journal> <volume> 12(3): </volume> <pages> 234-254. </pages>
Reference-contexts: In (Eriksson et al., 1997) we describe a method for automatic matching of 3-D brain images for brain atlases. Our more recent work concerns the extension of the scale-space theory to temporal image data. In (Lindeberg and Fagerstrom, 1996) we present an extension of scale-space models in <ref> (Lindeberg, 1990) </ref> to a fully time-recursive visual front-end. An attractive property of this computational scheme is that the temporal multi-scale representation serves as complete memory of the past, and temporal derivatives/ differences can be computed without any need for additional temporal buffering.
Reference: <author> Lindeberg, T. </author> <year> (1993a). </year> <title> Detecting salient blob-like image structures and their scales with a scale-space primal sketch: A method for focus-of-attention, </title> <booktitle> Int. J. of Computer Vision 11(3): </booktitle> <pages> 283-318. </pages>
Reference: <author> Lindeberg, T. </author> <year> (1993b). </year> <title> On scale selection for differential operators, </title> <editor> in K. </editor> <publisher> A. </publisher>
Reference: <editor> Htgdra, B. Braathen and K. Heia (eds), </editor> <booktitle> Proc. 8th Scandinavian Conference on Image Analysis, Norwegian Society for Image Processing and Pattern Recognition, Tromst, Norway, </booktitle> <pages> pp. 857-866. </pages>
Reference: <author> Lindeberg, T. </author> <year> (1994). </year> <title> Scale-Space Theory in Computer Vision, </title> <booktitle> The Kluwer International Series in Engineering and Computer Science, </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <address> Dordrecht, Netherlands. 8 Lindeberg, T. </address> <year> (1995). </year> <title> Direct estimation of affine deformations of brightness patterns using visual front-end operators with automatic scale selection, </title> <booktitle> Proc. 5th International Conference on Computer Vision, </booktitle> <address> Cambridge, MA, </address> <pages> pp. 134-141. </pages>
Reference-contexts: If such modules are to be constructed withoutbuilt-in limitations that would restrict their applicability, then a natural requirement is that the first stages of processing should be generic and make as few irreversible decisions and be as uncommitted as possible <ref> (Lindeberg, 1994) </ref>. Interestingly, this problem of can be given a rather general formulation concerning the image operations at the lowest processing levels.
Reference: <author> Lindeberg, T. </author> <year> (1996a). </year> <title> Automatic scale selection as a pre-processing stage to interpreting real-world data, </title> <booktitle> Proc. 8th International Conference on Tools with Artificial Intelligence, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <address> Toulouse, France, p. </address> <month> 490. </month>
Reference: <author> Lindeberg, T. </author> <year> (1996b). </year> <title> Edge detection and ridge detection with automatic scale selection, </title> <booktitle> Proc. IEEE Comp. Soc. Conf. on Computer Vision and Pattern Recognition, 1996, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <address> San Francisco, California, </address> <pages> pp. 465-470. </pages>
Reference: <author> Lindeberg, T. </author> <year> (1996c). </year> <title> Scale-space theory: A framework for handling image structures at multiple scales, </title> <booktitle> Proc. CERN School of Computing, Egmond aan Zee, The Netherlands, </booktitle> <pages> pp. </pages> <month> 27-38. </month> <type> Tech. Rep. CERN 96-08. </type>
Reference: <author> Lindeberg, T. </author> <year> (1997a). </year> <title> Linear spatio-temporal scale-space, </title> <editor> in ter Haar Romeny et al. (ed.), </editor> <booktitle> Proc. 1st Int. Conf. on Scale-Space Theory in Computer Vision, </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin, Utrecht, The Netherlands. </address>
Reference-contexts: An attractive property of this computational scheme is that the temporal multi-scale representation serves as complete memory of the past, and temporal derivatives/ differences can be computed without any need for additional temporal buffering. We have also developed a more general scale-space representation for spatio-temporal data <ref> (Lindeberg, 1997a) </ref>, which includes non-separable receptive fields, and which agrees with a large number of recent results on temporal response properties of receptive fields in biological vision.
Reference: <author> Lindeberg, T. </author> <year> (1997b). </year> <title> On automatic selection of temporal scales in time-casual scale-space, </title> <editor> in G. Sommer and J. J. Koenderink (eds), </editor> <booktitle> Proc. AFPAC'97: Algebraic Frames for the Perception-Action Cycle, Vol. 1315 of Lecture Notes in Computer Science, </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin, Kiel, Germany, </address> <pages> pp. 94-113. </pages>
Reference-contexts: attention has been given to the domain of feature tracking, where we have developed and demonstrated the need for feature trackers with automatic scale selection (Bretzner and Lindeberg, 1997; Bretzner and Lindeberg, 1998) and initiated work on developing more general mechanisms for performing automatic scale selection in the temporal domain <ref> (Lindeberg, 1997b) </ref>. 4 4 Visual Geometry and applications Understanding the geometry of projections from 3D to an image is of central importance in computer vision. The geometric constraints imposed by the imaging process defines the framework within which visual computations must take place.
Reference: <author> Lindeberg, T. </author> <year> (1998a). </year> <title> Feature detection with automatic scale selection, </title> <note> Int. J. of Computer Vision . (To appear). </note>
Reference: <author> Lindeberg, T. </author> <year> (1998b). </year> <title> A scale selection principle for estimating image deformations, Image and Vision Computing . (To appear). </title>
Reference: <author> Lindeberg, T. and Fagerstrom, D. </author> <year> (1996). </year> <title> Scale-space with causal time direction, </title> <booktitle> Proc. 4th European Conference on Computer Vision, </booktitle> <volume> Vol. 1064, </volume> <publisher> Springer Verlag, </publisher> <address> Berlin, Cambridge, UK, </address> <pages> pp. 229-240. </pages>
Reference-contexts: The general mechanism for automatic scale selection has been tested and applied to a rich set of computer vision problems. Examples include the computation of shape abstractions of curves (Lindeberg and Li, 1997; Lindeberg and Olofsson, 1995; Olofsson, 1996) , the analysis of fingerprint images <ref> (Almansa and Lindeberg, 1996) </ref> and the classification of steel properties based on the local mi-crostructure of carbide distributions (Wiltschi et al., 1997). A domain we have studied over the last four years concerns the computation of cues to surface shape directly from visual front-end operations. <p> A domain we have studied over the last four years concerns the computation of cues to surface shape directly from visual front-end operations. Our early work on this subject (Lindeberg and G-arding, 1993; Lindeberg and G-arding, 1994; G-arding and Lindeberg, 1994) has been refined to <ref> (G-arding and Lindeberg, 1996) </ref> to a uniform framework for computing local surface orientation from monocular texture cues and binocular disparities using second-moment descriptors. In (Lindeberg and G-arding, 1997) this methodology is complemented by a general mechanism for shape adaptation, which is necessary to obtain unbiased surface orientation estimates. <p> In (Eriksson et al., 1997) we describe a method for automatic matching of 3-D brain images for brain atlases. Our more recent work concerns the extension of the scale-space theory to temporal image data. In <ref> (Lindeberg and Fagerstrom, 1996) </ref> we present an extension of scale-space models in (Lindeberg, 1990) to a fully time-recursive visual front-end.
Reference: <author> Lindeberg, T. and G-arding, J. </author> <year> (1993). </year> <title> Shape from texture from a multi-scale perspective, </title> <editor> in H.-H. Nagel (ed.), </editor> <booktitle> Proc. 4th International Conference on Computer Vision, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <address> Berlin, Germany, </address> <pages> pp. 683-691. </pages>
Reference: <author> Lindeberg, T. and G-arding, J. </author> <year> (1994). </year> <title> Shape-adapted smoothing in estimation of 3-D depth cues from affine distortions of local 2-D structure, </title> <editor> in J.- O. Eklundh (ed.), </editor> <booktitle> Proc. 3rd European Conference on Computer Vision, Vol. 800 of Lecture Notes in Computer Science, </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin, Stockholm, Sweden, </address> <pages> pp. 389-400. </pages> <note> 9 Lindeberg, </note> <author> T. and G-arding, J. </author> <year> (1997). </year> <title> Shape-adapted smoothing in estimation of 3-D depth cues from affine distortions of local 2-D structure, </title> <booktitle> Image and Vision Computing 15: </booktitle> <pages> 415-434. </pages>
Reference-contexts: If such modules are to be constructed withoutbuilt-in limitations that would restrict their applicability, then a natural requirement is that the first stages of processing should be generic and make as few irreversible decisions and be as uncommitted as possible <ref> (Lindeberg, 1994) </ref>. Interestingly, this problem of can be given a rather general formulation concerning the image operations at the lowest processing levels.
Reference: <author> Lindeberg, T. and Li, M. </author> <year> (1997). </year> <title> Segmentation and classification of edges using minimum description length approximation and complementary junction cues, </title> <booktitle> Computer Vision and Image Understanding 67(1): </booktitle> <pages> 88-98. </pages>
Reference-contexts: Our early work on this subject (Lindeberg and G-arding, 1993; Lindeberg and G-arding, 1994; G-arding and Lindeberg, 1994) has been refined to (G-arding and Lindeberg, 1996) to a uniform framework for computing local surface orientation from monocular texture cues and binocular disparities using second-moment descriptors. In <ref> (Lindeberg and G-arding, 1997) </ref> this methodology is complemented by a general mechanism for shape adaptation, which is necessary to obtain unbiased surface orientation estimates.
Reference: <author> Lindeberg, T. and Olofsson, G. </author> <year> (1995). </year> <note> in preparation. </note>
Reference: <author> Lindeberg, T. and ter Haar Romeny, B. </author> <year> (1994a). </year> <title> Linear scale-space I: Basic theory, </title> <editor> in B. ter Haar Romeny (ed.), </editor> <booktitle> Geometry-Driven Diffusion in Computer Vision, Series in Mathematical Imaging and Vision, </booktitle> <publisher> Kluwer Academic Publishers, Dordrecht, Netherlands, </publisher> <pages> pp. 1-41. </pages>
Reference: <author> Lindeberg, T. and ter Haar Romeny, B. </author> <year> (1994b). </year> <title> Linear scale-space II: Early visual operations, </title> <editor> in B. ter Haar Romeny (ed.), </editor> <booktitle> Geometry-Driven Diffusion in Computer Vision, Series in Mathematical Imaging and Vision, </booktitle> <publisher> Kluwer Academic Publishers, Dordrecht, Netherlands, </publisher> <pages> pp. 43-77. </pages>
Reference: <author> Lundquist, A. </author> <year> (1997). </year> <title> Line Based Visual Navigation Using Pose Clustering, </title> <institution> Licentiate dissertation, Dept. of Numerical Analysis and Computing Science, KTH, Stockholm, Sweden. </institution>
Reference: <author> Maki, A. </author> <year> (1996). </year> <title> Stereo Vision in Attentive Scene Analysis, </title> <publisher> Ph. </publisher> <address> D. </address> <institution> dissertation, Dept. of Numerical Analysis and Computing Science, KTH, Stockholm, Sweden. ISRN KTH/NA/P--96/07--SE. </institution>
Reference: <author> Maki, A., G-arding, J. and Eklundh, J.-O. </author> <year> (1994). </year> <title> 2-d phase-based ground plane obstacle detection, </title> <booktitle> Proc. The 33rd SICE (Society of Instrument and Control Engineers) Annual Conference: SICE, </booktitle> <address> Tokyo, Japan, </address> <pages> pp. 725-728. </pages>
Reference: <author> Maki, A., Nordlund, P. and Eklundh, J.-O. </author> <year> (1996). </year> <title> A computational model of depth-based attention, </title> <booktitle> Proc. 13th International Conference on Pattern Recognition, Vol. IV, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <address> Vienna, Austria, </address> <pages> pp. 734-739. </pages>
Reference: <author> Maki, A., Uhlin, T. and Eklundh, J.-O. </author> <year> (1994). </year> <title> Disparity selection in binocular pursuit, </title> <booktitle> Proc. 4th IAPR (International Association for Pattern Recognition) Workshop on Machine Vision Applications, </booktitle> <pages> pp. 182-185. </pages>
Reference: <author> Nordlund, P. and Eklundh, J.-O. </author> <year> (1997). </year> <title> Figure-ground segmentation as a step towards deriving object properties, </title> <booktitle> Proc. 3rd Int. Workshop on Visual Form, </booktitle> <address> Capri, Italy. </address> <note> (To appear). </note>
Reference: <author> Nordlund, P. and Uhlin, T. </author> <year> (1996). </year> <title> Closing the loop: Detection and pursuit of a moving object by a moving observer, </title> <booktitle> Image and Vision Computing 14(4): </booktitle> <pages> 265-275. </pages>
Reference-contexts: In a general sense our longterm research deals with the principles of a seeing agent. As is pointed out in <ref> (Eklundh, Nordlund and Uhlin, 1996) </ref> and as also noted by Fermuller and Aloimonos (1995), such work require the development of systems that actually close the loop between perception and action.
Reference: <author> Olofsson, G. </author> <year> (1996). </year> <title> Active Recognition of Geons, </title> <publisher> Ph. </publisher> <address> D. </address> <institution> dissertation, Dept. of Numerical Analysis and Computing Science, KTH, Stockholm, Sweden. </institution>
Reference: <author> Pahlavan, K., Uhlin, T. and Eklundh, J.-O. </author> <year> (1993). </year> <title> Active vision as a methodology, </title> <editor> in Y. Aloimonos (ed.), </editor> <title> Active Vision, </title> <booktitle> Advances in Computer Science, </booktitle> <publisher> Lawrence Erlbaum Associates, </publisher> <pages> pp. 19-46. </pages>
Reference-contexts: As is pointed out in (Eklundh, Nordlund and Uhlin, 1996) and as also noted by Fermuller and Aloimonos (1995), such work require the development of systems that actually close the loop between perception and action. Hence, our efforts have continued along the lines described in <ref> (Pahlavan et al., 1993) </ref>, and lead to several dissertations: Brunnstrom (1993), Francisco (1994) Maki (1996) Uhlin (1996) and Olofsson (1996).
Reference: <author> Pahlavan, K., Uhlin, T. and Eklundh, J.-O. </author> <year> (1996). </year> <title> Dynamic fixation and active perception, </title> <booktitle> Int. J. of Computer Vision 17: </booktitle> <pages> 113-135. </pages>
Reference-contexts: Hence, our efforts have continued along the lines described in (Pahlavan et al., 1993), and lead to several dissertations: Brunnstrom (1993), Francisco (1994) Maki (1996) Uhlin (1996) and Olofsson (1996). We have in particular studied dynamic fixation for a mobile, binocular observer, <ref> (Pahlavan et al., 1996) </ref>, and how it can be used to pick out objects in a complex world, as shown in e.g. (Uhlin et al., 1995).
Reference: <author> Sporring, J., Nielsen, M., Florack, L. and Johansen, P. </author> <title> (eds) (1996). Gaussian Scale-Space Theory: </title> <booktitle> Proc. PhD School on Scale-Space Theory, Series in Mathematical Imaging and Vision, </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <address> Copen-hagen, Denmark. </address> <note> ter Haar Romeny, </note> <editor> B. (ed.) </editor> <year> (1994). </year> <title> Geometry-Driven Diffusion in Computer Vision, Series in Mathematical Imaging and Vision, </title> <publisher> Kluwer Academic Publishers, Dordrecht, Netherlands. </publisher> <editor> ter Haar Romeny, B. M., Florack, L. M. J., Koenderink, J. J. and Viergever, M. A. (eds) (1997). </editor> <booktitle> Scale-Space Theory in Computer Vision: Proc. First Int. Conf. Scale-Space'97, Lecture Notes in Computer Science, </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin, Utrecht, Netherlands. </address>
Reference-contexts: Complementary descriptions can be found in the monographs edited by (ter Haar Romeny, 1994) and <ref> (Sporring et al., 1996) </ref>, as well as in the proceedings of the first international conference fully devoted to this topic (ter Haar Romeny et al., 1997).
Reference: <author> Uhlin, T. </author> <year> (1996). </year> <title> Fixation and Seeing Systems, </title> <publisher> Ph. </publisher> <address> D. </address> <institution> dissertation, Dept. of Numerical Analysis and Computing Science, KTH, Stockholm, Sweden. </institution>
Reference-contexts: In a general sense our longterm research deals with the principles of a seeing agent. As is pointed out in <ref> (Eklundh, Nordlund and Uhlin, 1996) </ref> and as also noted by Fermuller and Aloimonos (1995), such work require the development of systems that actually close the loop between perception and action.
Reference: <author> Uhlin, T. and Eklundh, J.-O. </author> <year> (1995). </year> <title> Animate vision in a rich environment, </title> <booktitle> Proc. 14th Int. Joint Conf. Artificial Intelligence, </booktitle> <address> Montreal, Canada, </address> <pages> pp. 27-33. </pages>
Reference-contexts: We have in particular studied dynamic fixation for a mobile, binocular observer, (Pahlavan et al., 1996), and how it can be used to pick out objects in a complex world, as shown in e.g. <ref> (Uhlin et al., 1995) </ref>. As stressed in (Uhlin and Eklundh, 1995) such a system should be able to capitalize on whatever information is available in the scene and hence be based on multiple cues. The issue of integrating and selecting between cues then becomes central. <p> We have in particular studied dynamic fixation for a mobile, binocular observer, (Pahlavan et al., 1996), and how it can be used to pick out objects in a complex world, as shown in e.g. (Uhlin et al., 1995). As stressed in <ref> (Uhlin and Eklundh, 1995) </ref> such a system should be able to capitalize on whatever information is available in the scene and hence be based on multiple cues. The issue of integrating and selecting between cues then becomes central.
Reference: <author> Uhlin, T., Nordlund, P., Maki, A. and Eklundh, J.-O. </author> <year> (1995). </year> <title> Towards an active visual observer, </title> <booktitle> Proc. 5th International Conference on Computer Vision, </booktitle> <address> Cambridge, MA, </address> <pages> pp. 679-686. </pages>
Reference-contexts: We have in particular studied dynamic fixation for a mobile, binocular observer, (Pahlavan et al., 1996), and how it can be used to pick out objects in a complex world, as shown in e.g. <ref> (Uhlin et al., 1995) </ref>. As stressed in (Uhlin and Eklundh, 1995) such a system should be able to capitalize on whatever information is available in the scene and hence be based on multiple cues. The issue of integrating and selecting between cues then becomes central. <p> We have in particular studied dynamic fixation for a mobile, binocular observer, (Pahlavan et al., 1996), and how it can be used to pick out objects in a complex world, as shown in e.g. (Uhlin et al., 1995). As stressed in <ref> (Uhlin and Eklundh, 1995) </ref> such a system should be able to capitalize on whatever information is available in the scene and hence be based on multiple cues. The issue of integrating and selecting between cues then becomes central.
Reference: <author> Wiltschi, K., Pinz, A. and Lindeberg, T. </author> <year> (1997). </year> <title> Classification of carbide distributions using scale selection and directional distributions, </title> <booktitle> Proc. 4th International Conference on Image Processing, Vol. II, IEEE, </booktitle> <address> Santa Barbara, California, </address> <pages> pp. 122-125. </pages>
Reference-contexts: Examples include the computation of shape abstractions of curves (Lindeberg and Li, 1997; Lindeberg and Olofsson, 1995; Olofsson, 1996) , the analysis of fingerprint images (Almansa and Lindeberg, 1996) and the classification of steel properties based on the local mi-crostructure of carbide distributions <ref> (Wiltschi et al., 1997) </ref>. A domain we have studied over the last four years concerns the computation of cues to surface shape directly from visual front-end operations.
Reference: <author> Witkin, A. P. </author> <year> (1983). </year> <title> Scale-space filtering, </title> <booktitle> Proc. 8th Int. Joint Conf. Art. Intell., </booktitle> <address> Karlsruhe, West Germany, </address> <pages> pp. 1019-1022. 11 </pages>
References-found: 65

