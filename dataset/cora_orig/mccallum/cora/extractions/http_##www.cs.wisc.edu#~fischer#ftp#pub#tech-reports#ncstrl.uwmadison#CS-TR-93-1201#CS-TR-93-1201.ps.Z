URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-93-1201/CS-TR-93-1201.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-93-1201/
Root-URL: http://www.cs.wisc.edu
Title: Analyzing the Behavior and Performance of Parallel Programs  
Author: Vikram S. Adve 
Abstract: Computer Sciences Technical Report #1201 University of Wisconsin-Madison December 1993 hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh A postscript version of this technical report is available via anonymous ftp from ftp.cs.wisc.edu. 
Abstract-found: 1
Intro-found: 1
Reference: [AdV] <author> V. S. ADVE and M. K. VERNON, </author> <title> Performance Analysis of Mesh Interconnection Networks with Deterministic Routing, </title> <note> IEEE Transactions on Parallel and Distributed Systems (to appear), . (Available as Computer Sciences Technical Report #1001b, </note> <month> July </month> <year> 1993, </year> <institution> University of Wisconsin-Madison). </institution>
Reference-contexts: c done Insert c in ready_task_list g For each free process p If Sched (ready_task_list,p) finds a task t to execute Add t to E set Update current state cur_state /* Delete task next_task_done and add newly started tasks */ - Total Program Execution Time = T total _______________________________________________________________ _______________________________________________________________ <ref> [AdV, VLZ88, WiE90] </ref>. The solution complexity of approximate MVA is relatively insensitive to the number of customers (indirectly, the number of iterations required for convergence can be affected by the customer population).
Reference: [ASH88] <author> A. AGARWAL, R. SIMONI, M. HOROWITZ and J. HENNESSY, </author> <title> An Evaluation of Directory Schemes for Cache Coherence, </title> <booktitle> Proc. 15th Annual International Symposium on Computer Architecture, </booktitle> <address> Honolulu, Hawaii, </address> <month> June </month> <year> 1988, </year> <pages> 280-289. </pages>
Reference-contexts: These measurements serve to test our conclusions under high communication overhead. We ran the simulator with a 64 kilobyte, 4-way set associative cache per node, and a full-directory non-broadcast invalidate cache coherence protocol <ref> [ASH88] </ref>.
Reference: [ALK90] <author> A. AGARWAL, B. LIM, D. KRANZ and J. KUBIATOWICZ, </author> <month> APRIL: </month> <title> A Processor Architecture for Multiprocessing, </title> <booktitle> 17th Annual International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1990, </year> <pages> 104-114. </pages>
Reference-contexts: Otherwise, the models remain unchanged. When processes do relinquish processors for remote communication or access to other shared resources (note that this would only be useful if there were more processes than processors), an even simpler modification suffices. Possible examples of such systems are multi-threaded processors <ref> [ALK90] </ref> or parallel applications with significant I/O requirements. Representing such a program with the model only requires modifying the system-level queueing network to represent the individual processes instead of the processors as customers, and to include the P processors as individual queueing centers with some appropriate scheduling discipline.
Reference: [Amd67] <author> G. M. </author> <title> AMDAHL, Validity of the Single Processor Approach to Achieving Large-Scale Computing Capabilities, </title> <booktitle> AFIPS Conference Proceedings 30(1967), </booktitle> <pages> 483-485. </pages>
Reference-contexts: basic principles about various aspects of system behavior and performance is well-established; for parallel programming, this ability can be exploited to derive - -- fundamental principles of program behavior and their impact on performance. (A simple and well-known example of an analytical model fulfilling such a role is Amdahl's Law <ref> [Amd67] </ref>.) Furthermore, because analytical models have the ability to view a program and the underlying system at a higher level of abstraction than measurement or simulation techniques, they can play an important complementary role to measurement and simulation tools in meeting the second and third of the goals above. <p> Amdahl's Law, based on the fraction of sequential work, is a well known example <ref> [Amd67] </ref>. Another important example is the set of bounds derived by Eager, Zahorjan and Lazowska, using primarily the average parallelism to characterize program parallelism [EZL89].
Reference: [AIA90] <author> H. H. AMMAR, S. M. R. ISLAM, M. AMMAR and S. DENG, </author> <title> Performance Modeling of Parallel Algorithms, </title> <booktitle> Proc. 1990 International Conference on Parallel Processing, </booktitle> <year> 1990, </year> <pages> III 68-71. </pages>
Reference-contexts: Summary of the State of the Art We can summarize what is known about the state of the art as follows. For fork-join programs, stochastic models with simplifying assumptions (particularly, i.i.d. task times and simplified task scheduling) have been developed that are efficient to solve <ref> [AIA90, DuB82, HeT83, KrW85, TRS90] </ref>. To our knowledge, these models have not been tested for accuracy using actual programs. Two efficient deterministic models [TsV90, VSS88] for restricted types of fork-join programs have also been developed, and shown to be accurate for several programs each. <p> However, significant errors can be introduced for programs where specific details of task skew, task ordering and the task scheduling algorithm cannot be represented by the simplified assumptions in the model. Furthermore, all such models are restricted to programs with the simplest task structures <ref> [AIA90, KrW85, MaS91] </ref>. 2. Stochastic models applying to more general classes of programs [KME89, MaL90, Moh84, ThB86], all of which assume exponentially distributed task times, have significant and sometimes large errors.
Reference: [BaL92] <author> T. BALL and J. R. LARUS, </author> <title> Optimally Profiling and Tracing Programs, </title> <booktitle> Conference Record of the 19th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1992, </year> <pages> 59-70. </pages>
Reference-contexts: The most convenient method is to measure these values directly in software using explicit system timers or using software instrumentation tools such as pixie and qpt <ref> [BaL92] </ref>. Note that some software timing techniques will implicitly include overheads due to communication or shared-resource contention, rather than purely the CPU requirements.
Reference: [Bro88a] <author> E. D. BROOKS III, PCP: </author> <title> A Parallel Extension of C that is 99% Fat Free, </title> <type> Computational Physics Division Technical Report, </type> <institution> Lawrence Livermore National Laboratory, </institution> <month> September </month> <year> 1988. </year>
Reference-contexts: The tasks are statically allocated to the processes in cyclic order (one of the cases supported directly in the deterministic model implementation). PSIM is an interconnection network simulator written in PCP, a parallel extension of C that supports efficient nested forking within programs <ref> [Bro88a] </ref>. PSIM is a fork-join program in which each parallel phase consists of 6 parallel loops with no intervening barriers (Figure 5.1 (b)). The - -- . . . . . . . . . START END . START END . . .
Reference: [Bro88b] <author> E. D. BROOKS III, </author> <title> The indirect k-ary n-cube network for a vector processing environment, </title> <booktitle> Parallel Computing 6(1988), </booktitle> <pages> 339-348. </pages>
Reference-contexts: Hydro is a parallel simulation of particle motion in viscous fluids, with efficient communication. [FuK92]. PSIM was developed at Lawrence Livermore Laboratories to simulate the indirect binary n-cube memory server network in a large parallel vector-processing environment <ref> [Bro88b] </ref>. Bicon is an implementation of a parallel algorithm to find the biconnected components of large graphs [TaV85]. We measured each of the programs running stand-alone, allowing us to characterize the non-determinism intrinsic in the program.
Reference: [BKL84] <author> R. M. BRYANT, A. E. KRZESINSKI, M. S. LAKSHMI and K. M. CHANDY, </author> <title> The MVA Priority Approximation, </title> <journal> ACM Trans. on Computer Systems 2, </journal> <month> 4 (November </month> <year> 1984), </year> <pages> 335-359. </pages>
Reference-contexts: The non-preemptive priority of the read responses is modeled using a standard MVA priority approximation (service-time-inflation) <ref> [BKL84] </ref>. The limit of three outstanding read requests is modeled using an additional delay center in the queueing network.
Reference: [CMM88] <author> R. C. COVINGTON, S. MADALA, V. MEHTA, J. R. JUMP and J. B. SINCLAIR, </author> <title> The Rice Parallel Processing Testbed, </title> <booktitle> Proc. 1988 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1988, </year> <pages> 4-11. </pages>
Reference-contexts: Measurement-based performance analysis tools such as Pablo [RAM92], IPS-2 [MCH90] and numerous others provide the ability to evaluate the performance of a given program on an existing system in detail. Simulation-based tools such as the Rice Parallel Processing Testbed <ref> [CMM88] </ref>, the Wisconsin Wind Tunnel [RHL93], and others provide the additional flexibility of evaluating an existing program on varying system sizes and configurations. Thus, these techniques collectively achieve at least partial success in addressing the second and third of the three goals of parallel program performance evaluation stated above.
Reference: [CKP93] <author> D. CULLER, R. KARP, D. PATTERSON, A. SAHAY, K. E. SCHAUSER, E. SANTOS, R. SUBRAMONIAN and T. EICKEN, </author> <title> LogP: Towards a Realistic Model of Parallel Computation, </title> <booktitle> Proc. Fifth ACM SIGPLAN Notices Symposium on Principles and Practices of Parallel Programming, </booktitle> <month> May </month> <year> 1993. </year>
Reference: [Cve87] <author> Z. CVETANOVIC, </author> <title> The Effects of Problem Partitioning, Allocation and Granularity on the Performance of Multiple-Processor Systems, </title> <journal> IEEE Trans. on Computers C-36, </journal> <month> 4 (April </month> <year> 1987), </year> <pages> 421-432. </pages>
Reference-contexts: In fact, reviewing the assumptions and solutions techniques of previous analytical models in Chapter 2, we find that many previous models apply only to programs with extremely simple synchronization structures <ref> [AIA91, Cve87, DuB82, KrW85, LCB92, MaS91, TsV90, VSS88] </ref>, while other models require complex and heuristic solution techniques to model programs with more sophisticated structures [KME89, MaL90, ThB86]. Furthermore, models in the latter class have to assume exponentially distributed task execution times to permit tractable solutions. <p> Models Restricted to Fork-Join Programs A number of previous models are restricted to programs with fork-join task graphs <ref> [AIA91, Cve87, DuB82, HeT83, KrW85, TRS90, TsV90, VSS88] </ref>, and are all much simpler than models described so far. Of these, perhaps the most general is the seminal model of Kruskal and Weiss [KrW85]. <p> This estimate is asymptotically exact as P fi and N /P fi , but has been shown to be fairly accurate compared to simulations for small values of P, for a number of task time distributions. The models of Vrsalovic et al. [VSS88], Cvetanovic <ref> [Cve87] </ref> and Tsuei and Vernon [TsV90] are the three deterministic models mentioned in Chapter 1. The models of Vrsalovic et al and Cvetanovic apply to iterative parallel programs in which the computational work as well as the hhhhhhhhhhhhhhh 3.
Reference: [DuB82] <author> M. DUBOIS and F. A. BRIGGS, </author> <title> Performance of Synchronized Iterative Processes in Multiprocessor Systems, </title> <journal> IEEE Trans. on Software Engineering SE-8, </journal> <month> 4 (July </month> <year> 1982), </year> <pages> 419-431. </pages> - -- 
Reference-contexts: Performance models of parallel programs and systems have typically used stochastic task execution times to represent non-determinism due to these various sources. In fact, most previous analytical models for parallel programs are stochastic models <ref> [AIA91, DuB82, HaM92, KME89, KrW85, LCB92, MaS91, MaL90, ThB86] </ref>. - -- Non-deterministic delays due to communication and resource contention increase the variability of process execution times (besides increasing the mean execution times), which in turn affects synchronization costs. <p> In fact, reviewing the assumptions and solutions techniques of previous analytical models in Chapter 2, we find that many previous models apply only to programs with extremely simple synchronization structures <ref> [AIA91, Cve87, DuB82, KrW85, LCB92, MaS91, TsV90, VSS88] </ref>, while other models require complex and heuristic solution techniques to model programs with more sophisticated structures [KME89, MaL90, ThB86]. Furthermore, models in the latter class have to assume exponentially distributed task execution times to permit tractable solutions. <p> Models Restricted to Fork-Join Programs A number of previous models are restricted to programs with fork-join task graphs <ref> [AIA91, Cve87, DuB82, HeT83, KrW85, TRS90, TsV90, VSS88] </ref>, and are all much simpler than models described so far. Of these, perhaps the most general is the seminal model of Kruskal and Weiss [KrW85]. <p> Summary of the State of the Art We can summarize what is known about the state of the art as follows. For fork-join programs, stochastic models with simplifying assumptions (particularly, i.i.d. task times and simplified task scheduling) have been developed that are efficient to solve <ref> [AIA90, DuB82, HeT83, KrW85, TRS90] </ref>. To our knowledge, these models have not been tested for accuracy using actual programs. Two efficient deterministic models [TsV90, VSS88] for restricted types of fork-join programs have also been developed, and shown to be accurate for several programs each. <p> Finally, stochastic models that allow general distributions of task-time have been applied using different specific distributions, including the normal distribution. <ref> [DuB82, Gre89, KrW85] </ref>. Dubois and Briggs [DuB82] as well as Greenberg [Gre89] argued that a task could be asymptotically normally distributed because it is the sum of a large number of (non-deterministic) instruction execution times. Our proof in Appendix A is essentially a formalization of this argument. 3.2. <p> Finally, stochastic models that allow general distributions of task-time have been applied using different specific distributions, including the normal distribution. [DuB82, Gre89, KrW85]. Dubois and Briggs <ref> [DuB82] </ref> as well as Greenberg [Gre89] argued that a task could be asymptotically normally distributed because it is the sum of a large number of (non-deterministic) instruction execution times. Our proof in Appendix A is essentially a formalization of this argument. 3.2. <p> Motivation for a Deterministic Model A fundamental limitation of a deterministic model is that it cannot account for the variance introduced by non-deterministic delays due to communication and resource contention. Although authors have cited such random delays as a primary argument for assuming non-deterministic task times <ref> [DuB82, KrW85] </ref>, the results of the previous chapter in fact motivate the use of a deterministic performance model for shared-memory parallel programs, as explained below.
Reference: [EZL89] <author> D. L. EAGER, J. ZAHORJAN and E. D. LAZOWSKA, </author> <title> Speedup versus Efficiency in Parallel Systems, </title> <journal> IEEE Trans. on Computers C-38, </journal> <month> 3 (March </month> <year> 1989), </year> <pages> 408-423. </pages>
Reference-contexts: The computational requirement of such models is also extremely high, precluding analysis even of programs with fairly small task graphs. g Comparing the deterministic model with the parametric speedup bounds of Eager, Zahorjan and Lazowska <ref> [EZL89] </ref>, we show that for essentially the same effort as that required to calculate parameters for the bounds, the deterministic model can be used to obtain estimates of the actual speedup. <p> Three of these programs are used to evaluate the efficiency and accuracy of representative stochastic models as well, and thus also to compare the deterministic and stochastic models. Chapter 6 compares the deterministic model with the parametric speedup bounds of Eager, Zahorjan and Lazowska <ref> [EZL89] </ref>, in terms of the complexity of applying the two techniques for specific programs and the qualitative and quantitative information provided by the two techniques. <p> The fundamental concepts are those of task and task graph. (Our definitions of these terms are similar to the sub-task and the graph model of parallel software used in <ref> [EZL89] </ref>.) A set of tasks for a program on a particular input represent inherent units of computation, because of two properties conferred by the definition: (1) A task is executed sequentially, i.e., by a single process, in any execution of the program, and (2) A precedence constraint between a pair of <p> Amdahl's Law, based on the fraction of sequential work, is a well known example [Amd67]. Another important example is the set of bounds derived by Eager, Zahorjan and Lazowska, using primarily the average parallelism to characterize program parallelism <ref> [EZL89] </ref>. One of four equivalent definitions of the average parallelism of a program is the speedup of the program on an unlimited number of processors. 4 Given the average parallelism, A, they derived the hhhhhhhhhhhhhhh 4. <p> Formally, this behavior is represented by a task graph. All their results require that the task graph be fixed, independent of the number of processors or the task scheduling algorithm used. Under these conditions, the average parallelism, defined above, is an intrinsic property of the task graph <ref> [EZL89] </ref>. - -- following bounds which hold for any work-conserving task scheduling discipline: P + A - 1 P A hhhhhhhhh Speedup (P) min-P,A- (2.1) Furthermore, when these bounds hold, the geometric mean of the bounds lies within 34% of the true speedup, and thus A provides not only bounds but <p> An important example of such techniques is the work of Eager, Zahorjan and Lazowska <ref> [EZL89] </ref>, described in Section 2.6. In general, these techniques compute upper and lower bounds on speedup from simple program metrics such as average and maximum parallelism.
Reference: [EaZ93] <author> D. L. EAGER and J. ZAHORJAN, Chores: </author> <title> Enhanced Run-Time Support for Shared-Memory Parallel Computing, </title> <journal> ACM Trans. on Computer Systems 11, </journal> <month> 1 (February </month> <year> 1993), </year> <pages> 1-32. </pages>
Reference-contexts: Some requisite infrastructure for program analysis is already available in parallelizing compilers such as Jade [RSL93] and others, and in run-time systems such as Chores <ref> [EaZ93] </ref>. In parallelizing compilers, the compiler automatically detects and enforces (a superset of) the data dependencies in a program, and implements the partitioning and scheduling of work.
Reference: [FuK92] <author> Y. O. FUENTES and S. KIM, </author> <title> Foundations of Parallel Computational Microhydrodynamics : Communication Scheduling Strategies, </title> <journal> A.I.Ch.E. J. </journal> <volume> 38(1992), </volume> <pages> 1059-1078. </pages>
Reference-contexts: The other three are also real applications in the sense that they were written to solve computationally intensive problems of interest to their authors. Hydro is a parallel simulation of particle motion in viscous fluids, with efficient communication. <ref> [FuK92] </ref>. PSIM was developed at Lawrence Livermore Laboratories to simulate the indirect binary n-cube memory server network in a large parallel vector-processing environment [Bro88b]. Bicon is an implementation of a parallel algorithm to find the biconnected components of large graphs [TaV85].
Reference: [Gre89] <author> A. GREENBAUM, </author> <title> Synchronization Costs on Multiprocessors, </title> <booktitle> Parallel Computing 10(1989), </booktitle> <pages> 3-14. </pages>
Reference-contexts: Finally, stochastic models that allow general distributions of task-time have been applied using different specific distributions, including the normal distribution. <ref> [DuB82, Gre89, KrW85] </ref>. Dubois and Briggs [DuB82] as well as Greenberg [Gre89] argued that a task could be asymptotically normally distributed because it is the sum of a large number of (non-deterministic) instruction execution times. Our proof in Appendix A is essentially a formalization of this argument. 3.2. <p> Finally, stochastic models that allow general distributions of task-time have been applied using different specific distributions, including the normal distribution. [DuB82, Gre89, KrW85]. Dubois and Briggs [DuB82] as well as Greenberg <ref> [Gre89] </ref> argued that a task could be asymptotically normally distributed because it is the sum of a large number of (non-deterministic) instruction execution times. Our proof in Appendix A is essentially a formalization of this argument. 3.2.
Reference: [HaM92] <author> F. HARTLEB and V. MERTSIOTAKIS, </author> <title> Bounds for the Mean Runtime of Parallel Programs, </title> <booktitle> Proceedings of the Sixth International Conference on Modelling Techniques and Tools for Computer Performance Evaluation, </booktitle> <month> September </month> <year> 1992, </year> <pages> 197-210. </pages>
Reference-contexts: Performance models of parallel programs and systems have typically used stochastic task execution times to represent non-determinism due to these various sources. In fact, most previous analytical models for parallel programs are stochastic models <ref> [AIA91, DuB82, HaM92, KME89, KrW85, LCB92, MaS91, MaL90, ThB86] </ref>. - -- Non-deterministic delays due to communication and resource contention increase the variability of process execution times (besides increasing the mean execution times), which in turn affects synchronization costs. <p> Parallel reduction combines 2 vertices V 1 and V 2 into a single vertex if V 1 and V 2 have exactly the same parents, as well as exactly the same children <ref> [HaM92] </ref>. This class includes fork-join graphs but excludes, for example, the task graphs in Figures 5.1 (d,e). _______________________________________________________________ _______________________________________________________________ the task graph provides a useful (though less elegant) representation of the parallelism structure. <p> We do so in Chapter 6. A second body of work also derives bounds on the execution time of a parallel program on a specific number of processors <ref> [HaM92, YaV91] </ref>. Unlike the bounds described above, these results are based on detailed inputs similar to those used in the stochastic models reviewed earlier, namely a full description of the task graph along with the distribution of the individual task execution times.
Reference: [HeT83] <author> P. HEIDELBERGER and K. S. TRIVEDI, </author> <title> Analytic Queueing Models for Programs with Internal Concurrency, </title> <journal> IEEE Trans. on Computers C-32, </journal> <month> 1 (Jan. </month> <year> 1983), </year> <pages> 73-82. </pages>
Reference-contexts: Models Restricted to Fork-Join Programs A number of previous models are restricted to programs with fork-join task graphs <ref> [AIA91, Cve87, DuB82, HeT83, KrW85, TRS90, TsV90, VSS88] </ref>, and are all much simpler than models described so far. Of these, perhaps the most general is the seminal model of Kruskal and Weiss [KrW85]. <p> We will not describe the other, less general, models for fork-join programs here, except to note that both the models of Heidelberger and Trivedi <ref> [HeT83] </ref> and Towsley et al [TRS90] apply to multiprogrammed parallel systems with multiple parallel jobs (each job is assumed to have the same number of tasks in each parallel phase and each task is exponentially distributed). <p> Summary of the State of the Art We can summarize what is known about the state of the art as follows. For fork-join programs, stochastic models with simplifying assumptions (particularly, i.i.d. task times and simplified task scheduling) have been developed that are efficient to solve <ref> [AIA90, DuB82, HeT83, KrW85, TRS90] </ref>. To our knowledge, these models have not been tested for accuracy using actual programs. Two efficient deterministic models [TsV90, VSS88] for restricted types of fork-join programs have also been developed, and shown to be accurate for several programs each.
Reference: [HoS84] <author> E. HOROWITZ and S. SAHNI, </author> <title> Fundamentals of Computer Algorithms, </title> <publisher> Computer Science Press International, Inc., </publisher> <address> Rockville, Maryland, </address> <year> 1984. </year>
Reference-contexts: this heuristic, called the Longest Processing Time (or LPT) rule, is optimal (among non-preemptive schedules) when there are at most twice as many tasks as processors, and in the general case its execution time is bounded to within 1 1 3 of that of the optimal schedule among non-preemptive schedules <ref> [HoS84] </ref>. - -- 1 3 5 7 9 11 13 15 17 19 21 23 0.0 10.0 20.0 30.0 TIME (seconds) PROCESS NUMBER 1 3 5 7 9 11 13 15 17 19 21 23 0.0 10.0 20.0 30.0 TIME (seconds) PROCESS NUMBER (a) Original ordering of tasks (b) LPT ordering
Reference: [KME89] <author> A. KAPELNIKOV, R. R. MUNTZ and M. D. ERCEGOVAC, </author> <title> A Modeling Methodology for the Analysis of Concurrent Systems and Computations, </title> <journal> Journal of Parallel and Distributed Computing 6(1989), </journal> <pages> 568-597. </pages>
Reference-contexts: Performance models of parallel programs and systems have typically used stochastic task execution times to represent non-determinism due to these various sources. In fact, most previous analytical models for parallel programs are stochastic models <ref> [AIA91, DuB82, HaM92, KME89, KrW85, LCB92, MaS91, MaL90, ThB86] </ref>. - -- Non-deterministic delays due to communication and resource contention increase the variability of process execution times (besides increasing the mean execution times), which in turn affects synchronization costs. <p> assumptions and solutions techniques of previous analytical models in Chapter 2, we find that many previous models apply only to programs with extremely simple synchronization structures [AIA91, Cve87, DuB82, KrW85, LCB92, MaS91, TsV90, VSS88], while other models require complex and heuristic solution techniques to model programs with more sophisticated structures <ref> [KME89, MaL90, ThB86] </ref>. Furthermore, models in the latter class have to assume exponentially distributed task execution times to permit tractable solutions. <p> Mohan [Moh84] earlier described a model equivalent to that of Thomasian and Bay, but used a stochastic simulation to find the average program completion time by sampling different execution paths, instead of analytically solving for the steady-state probability distribution of the Markov chain. Kapelnikov, Muntz and Ercegovac <ref> [KME89] </ref> also propose a very similar hierarchical model for evaluating programs on distributed systems. Their model assumes a computation control graph, a program representation that is more general than a task graph in that alternative control-flow paths can be represented in the graph. <p> Less restrictive analytical models, namely models that apply to non-fork-join programs and eliminate the above simplifying assumptions, have all assumed exponential task execution times for analytical tractability <ref> [KME89, MaL90, Moh84, ThB86] </ref>. Again, to our knowledge, none of these models has been tested for accuracy using actual programs, and validations against hypothetical task graphs have not tested the accuracy of the exponential task assumption. <p> We use these to compare the relative influence of the two sources of non-determinism, as well as to evaluate the overall variance and distribution of execution time. In subsequent chapters, we discuss what the results of this study imply for parallel program performance prediction models <ref> [KME89, KrW85, MaL90, Nel90, ThB86] </ref> as well as for more general stochastic models of parallel systems [BaL90, ChN91, LeV90, LeN91, LCB92, NTT88, Nel90, NTT90, SeT91, ZaM90]. <p> In Chapter 2, however, we saw that previous stochastic models that apply to any but the simplest program structures have had to assume exponentially distributed task execution times for analytical tractability. Even with this assumption, these models require extremely complex and heuristic solution techniques <ref> [KME89, MaL90, Moh84, ThB86] </ref>. It thus appears important to re-evaluate the usefulness of stochastic models for parallel program performance prediction, and perhaps to develop an alternative approach. Chapters 5, 6, 7 in this thesis explore these questions in some detail. <p> The actual choice of system-level model used to calculate the communication and queueing delays is strongly dependent both on the system under consideration, and perhaps also on the required accuracy of the modeling study. Therefore, unlike many previous authors <ref> [KME89, MaL90, ThB86] </ref>, we do not specify any particular queueing network framework to be used at the system level. <p> Furthermore, all such models are restricted to programs with the simplest task structures [AIA90, KrW85, MaS91]. 2. Stochastic models applying to more general classes of programs <ref> [KME89, MaL90, Moh84, ThB86] </ref>, all of which assume exponentially distributed task times, have significant and sometimes large errors. Furthermore, the models in this class appear too inefficient to use even for programs with relatively small task graphs of a few hundred tasks.
Reference: [KSR91] <author> KENDALL SQUARE RESEARCH, </author> <title> KSR1 Principles of Operation, Kendall Square Research, </title> <address> Waltham, MA, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: On a KSR1 with a 2-level network, i.e., up to 1024 processors, the average latencies of requests that cross both rings is about a factor of 4 higher than requests that use only one ring <ref> [KSR91] </ref>. Assume a higher ratio of 10, and assume requests at each level have exponentially distributed latencies (motivated by the measured values of CV C on the Sequent as well as the CM-5).
Reference: [KiS90] <author> J. KIM and A. C. SHAW, </author> <title> An Experiment on Predicting and Measuring the Deterministic Execution Times of Parallel Programs on a Multiprocessor, </title> <type> Technical Report 90-09-01, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> September </month> <year> 1990. </year>
Reference: [KrW85] <author> C. P. KRUSKAL and A. WEISS, </author> <title> Allocating Independent Subtasks on Parallel Processors, </title> <journal> IEEE Trans. on Software Engineering SE-11, </journal> <month> 10 (October </month> <year> 1985), </year> <pages> 1001-1016. </pages>
Reference-contexts: Performance models of parallel programs and systems have typically used stochastic task execution times to represent non-determinism due to these various sources. In fact, most previous analytical models for parallel programs are stochastic models <ref> [AIA91, DuB82, HaM92, KME89, KrW85, LCB92, MaS91, MaL90, ThB86] </ref>. - -- Non-deterministic delays due to communication and resource contention increase the variability of process execution times (besides increasing the mean execution times), which in turn affects synchronization costs. <p> In fact, reviewing the assumptions and solutions techniques of previous analytical models in Chapter 2, we find that many previous models apply only to programs with extremely simple synchronization structures <ref> [AIA91, Cve87, DuB82, KrW85, LCB92, MaS91, TsV90, VSS88] </ref>, while other models require complex and heuristic solution techniques to model programs with more sophisticated structures [KME89, MaL90, ThB86]. Furthermore, models in the latter class have to assume exponentially distributed task execution times to permit tractable solutions. <p> Models Restricted to Fork-Join Programs A number of previous models are restricted to programs with fork-join task graphs <ref> [AIA91, Cve87, DuB82, HeT83, KrW85, TRS90, TsV90, VSS88] </ref>, and are all much simpler than models described so far. Of these, perhaps the most general is the seminal model of Kruskal and Weiss [KrW85]. <p> Of these, perhaps the most general is the seminal model of Kruskal and Weiss <ref> [KrW85] </ref>. They consider a parallel program consisting of N independent parallel tasks executing on P processors, and make two simplifying assumptions about task behavior. <p> Summary of the State of the Art We can summarize what is known about the state of the art as follows. For fork-join programs, stochastic models with simplifying assumptions (particularly, i.i.d. task times and simplified task scheduling) have been developed that are efficient to solve <ref> [AIA90, DuB82, HeT83, KrW85, TRS90] </ref>. To our knowledge, these models have not been tested for accuracy using actual programs. Two efficient deterministic models [TsV90, VSS88] for restricted types of fork-join programs have also been developed, and shown to be accurate for several programs each. <p> We use these to compare the relative influence of the two sources of non-determinism, as well as to evaluate the overall variance and distribution of execution time. In subsequent chapters, we discuss what the results of this study imply for parallel program performance prediction models <ref> [KME89, KrW85, MaL90, Nel90, ThB86] </ref> as well as for more general stochastic models of parallel systems [BaL90, ChN91, LeV90, LeN91, LCB92, NTT88, Nel90, NTT90, SeT91, ZaM90]. <p> Finally, stochastic models that allow general distributions of task-time have been applied using different specific distributions, including the normal distribution. <ref> [DuB82, Gre89, KrW85] </ref>. Dubois and Briggs [DuB82] as well as Greenberg [Gre89] argued that a task could be asymptotically normally distributed because it is the sum of a large number of (non-deterministic) instruction execution times. Our proof in Appendix A is essentially a formalization of this argument. 3.2. <p> Models for fork-join programs have also required simplifying assumptions such as i.i.d. task times and simplified task scheduling, and even in this case, the best known solution is only asymptotically exact as the number of processors and the number of tasks per processor become large <ref> [KrW85] </ref>. In this chapter, we propose a deterministic model for parallel program performance prediction, in which task execution times are represented as deterministic quantities. <p> Motivation for a Deterministic Model A fundamental limitation of a deterministic model is that it cannot account for the variance introduced by non-deterministic delays due to communication and resource contention. Although authors have cited such random delays as a primary argument for assuming non-deterministic task times <ref> [DuB82, KrW85] </ref>, the results of the previous chapter in fact motivate the use of a deterministic performance model for shared-memory parallel programs, as explained below. <p> However, significant errors can be introduced for programs where specific details of task skew, task ordering and the task scheduling algorithm cannot be represented by the simplified assumptions in the model. Furthermore, all such models are restricted to programs with the simplest task structures <ref> [AIA90, KrW85, MaS91] </ref>. 2. Stochastic models applying to more general classes of programs [KME89, MaL90, Moh84, ThB86], all of which assume exponentially distributed task times, have significant and sometimes large errors.
Reference: [Lar93] <author> J. R. LARUS, </author> <title> Loop-Level Parallelism in Numeric and Symbolic Programs, </title> <journal> IEEE Trans. on Parallel and Distributed Systems 4, </journal> <month> 7 (July </month> <year> 1993), </year> <pages> 812-826. </pages>
Reference-contexts: Thus, as explained above, A can be derived from a single solution of the basic deterministic model ignoring communication. hhhhhhhhhhhhhhh 20. An interesting, related measurement-based technique has been developed by Larus and implemented in a tool called pp <ref> [Lar93] </ref>.
Reference: [LeN91] <author> S. T. LEUTENEGGER and R. D. NELSON, </author> <title> Analysis of Spatial and Temporal Scheduling Policies for Semi-Static and Dynamic Multiprocessor Environments, </title> <institution> IBM Research Report, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: In subsequent chapters, we discuss what the results of this study imply for parallel program performance prediction models [KME89, KrW85, MaL90, Nel90, ThB86] as well as for more general stochastic models of parallel systems <ref> [BaL90, ChN91, LeV90, LeN91, LCB92, NTT88, Nel90, NTT90, SeT91, ZaM90] </ref>. In the former case, the results motivate an approach to analytical parallel program performance prediction that is different from most previous models for this purpose. <p> Stochastic models are nevertheless important for the performance evaluation of high-level design issues in parallel systems including issues such as multiprogrammed multiprocessor scheduling policies, synchronization management policies within programs, and sometimes abstract models of parallel program behavior as well <ref> [ALL89, BaL90, ChN91, LeV90, LeN91, LCB92, NTT88, Nel90, NTT90, SeT91, ZaM90] </ref>. For example, the models in multiprocessor scheduling performance studies must represent complex workloads consisting of many different jobs (programs). Representing the characteristics (e.g., CPU demands, parallelism, etc.) of each individual workload member would be too tedious and sometimes impractical.
Reference: [LCB92] <author> G. LEWANDOWSKI, A. CONDON and E. BACH, </author> <title> Realistic Analysis of Parallel Dynamic Programming Algorithms, </title> <type> Computer Sciences Technical Report #1116, </type> <institution> University of Wisconsin-Madison, </institution> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: Performance models of parallel programs and systems have typically used stochastic task execution times to represent non-determinism due to these various sources. In fact, most previous analytical models for parallel programs are stochastic models <ref> [AIA91, DuB82, HaM92, KME89, KrW85, LCB92, MaS91, MaL90, ThB86] </ref>. - -- Non-deterministic delays due to communication and resource contention increase the variability of process execution times (besides increasing the mean execution times), which in turn affects synchronization costs. <p> In fact, reviewing the assumptions and solutions techniques of previous analytical models in Chapter 2, we find that many previous models apply only to programs with extremely simple synchronization structures <ref> [AIA91, Cve87, DuB82, KrW85, LCB92, MaS91, TsV90, VSS88] </ref>, while other models require complex and heuristic solution techniques to model programs with more sophisticated structures [KME89, MaL90, ThB86]. Furthermore, models in the latter class have to assume exponentially distributed task execution times to permit tractable solutions. <p> All other models to which we refer in this paper only consider systems with a single executing job. Finally, two previous models <ref> [LCB92, MaS91] </ref> are restricted to specific task graph structures. <p> the graph have i.i.d. execution times with arbitrary variance, but with the assumption that the number of processors exceeds the maximum parallelism, i.e., task scheduling can be ignored. (They also derive models for fork-join programs that are very similar to the results of Kruskal and Weiss.) Lewandowski, Condon and Bach <ref> [LCB92] </ref> propose a model applicable to - -- programs with pipelined task graphs and i.i.d. exponential task times. 2.5. Summary of the State of the Art We can summarize what is known about the state of the art as follows. <p> In subsequent chapters, we discuss what the results of this study imply for parallel program performance prediction models [KME89, KrW85, MaL90, Nel90, ThB86] as well as for more general stochastic models of parallel systems <ref> [BaL90, ChN91, LeV90, LeN91, LCB92, NTT88, Nel90, NTT90, SeT91, ZaM90] </ref>. In the former case, the results motivate an approach to analytical parallel program performance prediction that is different from most previous models for this purpose. <p> The only previous general analytical models that apply to such programs are the three Markov chain models. (Although the model of Lewandowski et al. <ref> [LCB92] </ref> does apply to DynProg, it was specifically developed for this program and is restricted to similar pipelined programs. Hence we do not consider it here.) The former three models are too complex to be used for these programs. <p> Stochastic models are nevertheless important for the performance evaluation of high-level design issues in parallel systems including issues such as multiprogrammed multiprocessor scheduling policies, synchronization management policies within programs, and sometimes abstract models of parallel program behavior as well <ref> [ALL89, BaL90, ChN91, LeV90, LeN91, LCB92, NTT88, Nel90, NTT90, SeT91, ZaM90] </ref>. For example, the models in multiprocessor scheduling performance studies must represent complex workloads consisting of many different jobs (programs). Representing the characteristics (e.g., CPU demands, parallelism, etc.) of each individual workload member would be too tedious and sometimes impractical.
Reference: [MaS91] <author> S. MADALA and J. B. SINCLAIR, </author> <title> Performance of Synchronous Parallel Algorithms with Regular Structures, </title> <journal> IEEE Trans. on Parallel and Distributed Systems 2, </journal> <month> 1 (January </month> <year> 1991), </year> <pages> 105-116. </pages>
Reference-contexts: Performance models of parallel programs and systems have typically used stochastic task execution times to represent non-determinism due to these various sources. In fact, most previous analytical models for parallel programs are stochastic models <ref> [AIA91, DuB82, HaM92, KME89, KrW85, LCB92, MaS91, MaL90, ThB86] </ref>. - -- Non-deterministic delays due to communication and resource contention increase the variability of process execution times (besides increasing the mean execution times), which in turn affects synchronization costs. <p> In fact, reviewing the assumptions and solutions techniques of previous analytical models in Chapter 2, we find that many previous models apply only to programs with extremely simple synchronization structures <ref> [AIA91, Cve87, DuB82, KrW85, LCB92, MaS91, TsV90, VSS88] </ref>, while other models require complex and heuristic solution techniques to model programs with more sophisticated structures [KME89, MaL90, ThB86]. Furthermore, models in the latter class have to assume exponentially distributed task execution times to permit tractable solutions. <p> All other models to which we refer in this paper only consider systems with a single executing job. Finally, two previous models <ref> [LCB92, MaS91] </ref> are restricted to specific task graph structures. <p> All other models to which we refer in this paper only consider systems with a single executing job. Finally, two previous models [LCB92, MaS91] are restricted to specific task graph structures. Madala and Sinclair <ref> [MaS91] </ref> propose a model that applies to divide-and-conquer task-graphs where tasks at each level in the graph have i.i.d. execution times with arbitrary variance, but with the assumption that the number of processors exceeds the maximum parallelism, i.e., task scheduling can be ignored. (They also derive models for fork-join programs that <p> However, significant errors can be introduced for programs where specific details of task skew, task ordering and the task scheduling algorithm cannot be represented by the simplified assumptions in the model. Furthermore, all such models are restricted to programs with the simplest task structures <ref> [AIA90, KrW85, MaS91] </ref>. 2. Stochastic models applying to more general classes of programs [KME89, MaL90, Moh84, ThB86], all of which assume exponentially distributed task times, have significant and sometimes large errors.
Reference: [MaL90] <author> V. W. MAK and S. F. LUNDSTROM, </author> <title> Predicting Performance of Parallel Computations, </title> <journal> IEEE Trans. on Parallel and Distributed Systems 1, </journal> <month> 3 (July </month> <year> 1990), </year> <pages> 257-270. </pages> - -- 
Reference-contexts: Performance models of parallel programs and systems have typically used stochastic task execution times to represent non-determinism due to these various sources. In fact, most previous analytical models for parallel programs are stochastic models <ref> [AIA91, DuB82, HaM92, KME89, KrW85, LCB92, MaS91, MaL90, ThB86] </ref>. - -- Non-deterministic delays due to communication and resource contention increase the variability of process execution times (besides increasing the mean execution times), which in turn affects synchronization costs. <p> assumptions and solutions techniques of previous analytical models in Chapter 2, we find that many previous models apply only to programs with extremely simple synchronization structures [AIA91, Cve87, DuB82, KrW85, LCB92, MaS91, TsV90, VSS88], while other models require complex and heuristic solution techniques to model programs with more sophisticated structures <ref> [KME89, MaL90, ThB86] </ref>. Furthermore, models in the latter class have to assume exponentially distributed task execution times to permit tractable solutions. <p> Mak and Lundstrom develop a heuristic and fairly complex graph reduction technique as their higher-level model component, to avoid considering the individual program states <ref> [MaL90] </ref>. This heuristic, however, restricts their model to programs that have series-parallel task graphs. <p> The authors test the accuracy of the heuristic approximations required to solve the model by simulating hypothetical task graphs with exponential task times and by measuring a synthetic program explicitly written with geometrically distributed task times. hhhhhhhhhhhhhhh 2. In their paper <ref> [MaL90] </ref>, Mak and Lundstrom mention that instead of assuming exponentially distributed task times, an Erlang distribution can be used to match the actual variance of task time if desired. <p> Less restrictive analytical models, namely models that apply to non-fork-join programs and eliminate the above simplifying assumptions, have all assumed exponential task execution times for analytical tractability <ref> [KME89, MaL90, Moh84, ThB86] </ref>. Again, to our knowledge, none of these models has been tested for accuracy using actual programs, and validations against hypothetical task graphs have not tested the accuracy of the exponential task assumption. <p> We use these to compare the relative influence of the two sources of non-determinism, as well as to evaluate the overall variance and distribution of execution time. In subsequent chapters, we discuss what the results of this study imply for parallel program performance prediction models <ref> [KME89, KrW85, MaL90, Nel90, ThB86] </ref> as well as for more general stochastic models of parallel systems [BaL90, ChN91, LeV90, LeN91, LCB92, NTT88, Nel90, NTT90, SeT91, ZaM90]. <p> In Chapter 2, however, we saw that previous stochastic models that apply to any but the simplest program structures have had to assume exponentially distributed task execution times for analytical tractability. Even with this assumption, these models require extremely complex and heuristic solution techniques <ref> [KME89, MaL90, Moh84, ThB86] </ref>. It thus appears important to re-evaluate the usefulness of stochastic models for parallel program performance prediction, and perhaps to develop an alternative approach. Chapters 5, 6, 7 in this thesis explore these questions in some detail. <p> The actual choice of system-level model used to calculate the communication and queueing delays is strongly dependent both on the system under consideration, and perhaps also on the required accuracy of the modeling study. Therefore, unlike many previous authors <ref> [KME89, MaL90, ThB86] </ref>, we do not specify any particular queueing network framework to be used at the system level. <p> Furthermore, all such models are restricted to programs with the simplest task structures [AIA90, KrW85, MaS91]. 2. Stochastic models applying to more general classes of programs <ref> [KME89, MaL90, Moh84, ThB86] </ref>, all of which assume exponentially distributed task times, have significant and sometimes large errors. Furthermore, the models in this class appear too inefficient to use even for programs with relatively small task graphs of a few hundred tasks.
Reference: [MCH90] <author> B. P. MILLER, M. CLARK, J. K. HOLLINGSWORTH, S. KIERSTEAD, S. LIM and T. TORZEWSKI, IPS-2: </author> <title> The Second Generation of a Parallel Program Measurement System, </title> <journal> IEEE Trans. on Parallel and Distributed Systems 1, </journal> <month> 2 (April </month> <year> 1990), </year> . 
Reference-contexts: Performance evaluation tools in use today for evaluating parallel program performance are based on measurement or simulation. Measurement-based performance analysis tools such as Pablo [RAM92], IPS-2 <ref> [MCH90] </ref> and numerous others provide the ability to evaluate the performance of a given program on an existing system in detail.
Reference: [Moh84] <author> J. MOHAN, </author> <title> Performance of Parallel Programs: Model and Analyses, </title> <type> Ph.D. Thesis, </type> <institution> Carnegie Mellon University, </institution> <month> July </month> <year> 1984. </year>
Reference-contexts: O (2 N ) in the worst case). The authors show the model to be accurate for a task graph with N = 6 tasks, compared to simulations that also assume exponential task times. Mohan <ref> [Moh84] </ref> earlier described a model equivalent to that of Thomasian and Bay, but used a stochastic simulation to find the average program completion time by sampling different execution paths, instead of analytically solving for the steady-state probability distribution of the Markov chain. <p> Less restrictive analytical models, namely models that apply to non-fork-join programs and eliminate the above simplifying assumptions, have all assumed exponential task execution times for analytical tractability <ref> [KME89, MaL90, Moh84, ThB86] </ref>. Again, to our knowledge, none of these models has been tested for accuracy using actual programs, and validations against hypothetical task graphs have not tested the accuracy of the exponential task assumption. <p> In Chapter 2, however, we saw that previous stochastic models that apply to any but the simplest program structures have had to assume exponentially distributed task execution times for analytical tractability. Even with this assumption, these models require extremely complex and heuristic solution techniques <ref> [KME89, MaL90, Moh84, ThB86] </ref>. It thus appears important to re-evaluate the usefulness of stochastic models for parallel program performance prediction, and perhaps to develop an alternative approach. Chapters 5, 6, 7 in this thesis explore these questions in some detail. <p> Furthermore, all such models are restricted to programs with the simplest task structures [AIA90, KrW85, MaS91]. 2. Stochastic models applying to more general classes of programs <ref> [KME89, MaL90, Moh84, ThB86] </ref>, all of which assume exponentially distributed task times, have significant and sometimes large errors. Furthermore, the models in this class appear too inefficient to use even for programs with relatively small task graphs of a few hundred tasks.
Reference: [NTT88] <author> R. NELSON, D. TOWSLEY and A. N. TANTAWI, </author> <title> Performance Analysis of Parallel Processing Systems, </title> <journal> IEEE Trans. on Software Engineering 14, </journal> <month> 4 (April </month> <year> 1988), </year> <pages> 532-540. </pages>
Reference-contexts: In subsequent chapters, we discuss what the results of this study imply for parallel program performance prediction models [KME89, KrW85, MaL90, Nel90, ThB86] as well as for more general stochastic models of parallel systems <ref> [BaL90, ChN91, LeV90, LeN91, LCB92, NTT88, Nel90, NTT90, SeT91, ZaM90] </ref>. In the former case, the results motivate an approach to analytical parallel program performance prediction that is different from most previous models for this purpose. <p> Stochastic models are nevertheless important for the performance evaluation of high-level design issues in parallel systems including issues such as multiprogrammed multiprocessor scheduling policies, synchronization management policies within programs, and sometimes abstract models of parallel program behavior as well <ref> [ALL89, BaL90, ChN91, LeV90, LeN91, LCB92, NTT88, Nel90, NTT90, SeT91, ZaM90] </ref>. For example, the models in multiprocessor scheduling performance studies must represent complex workloads consisting of many different jobs (programs). Representing the characteristics (e.g., CPU demands, parallelism, etc.) of each individual workload member would be too tedious and sometimes impractical. <p> A result that is not strongly dependent on the distribution assumption is as follows. Nelson et al <ref> [NTT88] </ref> showed that in an environment containing mixed sequential (interactive) and large parallel (batch) jobs, an unpartitioned parallel system yields better performance than one in which processors are statically partitioned among the two classes. They assumed that the parallel jobs consisted of tasks with exponentially distributed execution times.
Reference: [Nel90] <author> R. NELSON, </author> <title> A Performance Evaluation of a General Parallel Processing Model, </title> <booktitle> 1990 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems 18, 1 (1990), </booktitle> <pages> 14-26. </pages>
Reference-contexts: We use these to compare the relative influence of the two sources of non-determinism, as well as to evaluate the overall variance and distribution of execution time. In subsequent chapters, we discuss what the results of this study imply for parallel program performance prediction models <ref> [KME89, KrW85, MaL90, Nel90, ThB86] </ref> as well as for more general stochastic models of parallel systems [BaL90, ChN91, LeV90, LeN91, LCB92, NTT88, Nel90, NTT90, SeT91, ZaM90]. <p> In subsequent chapters, we discuss what the results of this study imply for parallel program performance prediction models [KME89, KrW85, MaL90, Nel90, ThB86] as well as for more general stochastic models of parallel systems <ref> [BaL90, ChN91, LeV90, LeN91, LCB92, NTT88, Nel90, NTT90, SeT91, ZaM90] </ref>. In the former case, the results motivate an approach to analytical parallel program performance prediction that is different from most previous models for this purpose. <p> Stochastic models are nevertheless important for the performance evaluation of high-level design issues in parallel systems including issues such as multiprogrammed multiprocessor scheduling policies, synchronization management policies within programs, and sometimes abstract models of parallel program behavior as well <ref> [ALL89, BaL90, ChN91, LeV90, LeN91, LCB92, NTT88, Nel90, NTT90, SeT91, ZaM90] </ref>. For example, the models in multiprocessor scheduling performance studies must represent complex workloads consisting of many different jobs (programs). Representing the characteristics (e.g., CPU demands, parallelism, etc.) of each individual workload member would be too tedious and sometimes impractical. <p> In contrast, one result that is significant for exponentially distributed tasks but weaker for tasks with lower variance is Nelson's result <ref> [Nel90] </ref> that higher variance of parallelism can yield - -- ___________________________________________________________ ___________________________________________________________ i a 1.0 0.6 0.2 1.00.80.60.40.20.0 Exponential Normal Distribution Distribution CV of Normal Distribution C to D Ratio of Response Time . Class Dist. <p> To show the effect of the choice of distribution, consider the two systems (A and B) that were compared in <ref> [Nel90] </ref>, each with 8 processors but different distributions of parallelism (b i ) as given in Figure 8.1. Both systems have mean parallelism of 2.4, but A has a higher variance of parallelism than B.
Reference: [PoK87] <author> C. D. POLYCHRONOPOLOUS and D. J. KUCK, </author> <title> Guided Self-Scheduling: A Practical Scheduling Scheme for Parallel Supercomputers, </title> <journal> IEEE Trans. on Computers C-36, </journal> <month> 12 (Dec. </month> <year> 1987), </year> . 
Reference-contexts: By our definitions, each iteration forms a task and the task graph for this loop consists of a single parallel phase with N tasks. Various scheduling functions are possible for such a loop (e.g., static scheduling in blocked or cyclic order, dynamic scheduling, guided self-scheduling <ref> [PoK87] </ref>, etc.), but the task graph is the same in all cases. In some programs, however, the task graph (or some portion thereof) may necessarily depend on the number of processes used during program execution.
Reference: [RAM92] <author> D. A. REED, R. A. AYDT, T. M. MADHYASTHA, R. J. NOE, K. A. SHIELDS and B. W. SCHWARTZ, </author> <title> An Overview of the Pablo Performance Analysis Environment, </title> <type> Technical Report, </type> <institution> University of Illinois, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: Performance evaluation tools in use today for evaluating parallel program performance are based on measurement or simulation. Measurement-based performance analysis tools such as Pablo <ref> [RAM92] </ref>, IPS-2 [MCH90] and numerous others provide the ability to evaluate the performance of a given program on an existing system in detail.
Reference: [RHL93] <author> S. K. REINHARDT, M. D. HILL, J. R. LARUS, A. R. LEBECK, J. C. LEWIS and D. A. WOOD, </author> <title> The Wisconsin Wind Tunnel: Virtual Prototyping of Parallel Computers, </title> <booktitle> Proc. 1993 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1993, </year> <pages> 48-60. </pages>
Reference-contexts: Measurement-based performance analysis tools such as Pablo [RAM92], IPS-2 [MCH90] and numerous others provide the ability to evaluate the performance of a given program on an existing system in detail. Simulation-based tools such as the Rice Parallel Processing Testbed [CMM88], the Wisconsin Wind Tunnel <ref> [RHL93] </ref>, and others provide the additional flexibility of evaluating an existing program on varying system sizes and configurations. Thus, these techniques collectively achieve at least partial success in addressing the second and third of the three goals of parallel program performance evaluation stated above. <p> Measurements on the CM-5 We were also able to measure two of the above programs on a 32-processor Thinking Machines CM-5, a system that is scalable to much larger numbers of processors. Since the CM-5 does not support shared memory, we used the Wisconsin Windtunnel <ref> [RHL93] </ref> to simulate the execution of the shared-memory applications. In this simulator, the application program executes most of the time at full hardware speed on the processing nodes of the CM-5, but traps into software on memory references to cache blocks that would not be in the target machine's cache.
Reference: [RSL93] <author> M. RINARD, D. J. SCALES and M. S. LAM, </author> <title> Jade: A High-Level Machine Independent Language for Parallel Programming, </title> <booktitle> Computer 26, </booktitle> <month> 6 (June </month> <year> 1993), </year> <pages> 28-38. </pages>
Reference-contexts: For the deterministic model to be integrated into automated performance tools, compiler or run-time support (and perhaps also programmer annotation) will be required for creating the task-graph of a given program. Some requisite infrastructure for program analysis is already available in parallelizing compilers such as Jade <ref> [RSL93] </ref> and others, and in run-time systems such as Chores [EaZ93]. In parallelizing compilers, the compiler automatically detects and enforces (a superset of) the data dependencies in a program, and implements the partitioning and scheduling of work.
Reference: [Sar89] <author> V. SARKAR, </author> <title> Determining Average Program Execution Times and their Variance, </title> <booktitle> Proc. 1989 SIGPLAN Notices Conference on Programming Language Design and Implementation, </booktitle> <year> 1989, </year> <pages> 298-312. </pages>
Reference-contexts: However, one previous paper focuses on estimating the mean and variance of the processing requirements of tasks in the presence of data-dependent effects such as conditional branch probabilities and loop frequencies <ref> [Sar89] </ref>. In that work, Sarkar describes a framework for determining the mean and variance of task execution times using frequency information from a counter-based execution profile of the program.
Reference: [Seq81] <institution> SEQUENT COMPUTER SYSTEMS, INC., </institution> <type> Symmetry Technical Summary, </type> <institution> Sequent Computer Systems, Inc., </institution> <year> 1988. </year>
Reference-contexts: For example, on the Sequent Symmetry, the cache miss rate alone provides useful information about the communication behavior of an application, and can be estimated directly from software by reading special hardware counters that monitor cache misses per processor <ref> [Seq81] </ref>.
Reference: [SeT91] <author> S. SETIA and S. K. TRIPATHI, </author> <title> An Analysis of Several Processor Partitioning Policies for Parallel Computers, </title> <institution> University of Maryland CS-Tech. Rep.-2684, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: In subsequent chapters, we discuss what the results of this study imply for parallel program performance prediction models [KME89, KrW85, MaL90, Nel90, ThB86] as well as for more general stochastic models of parallel systems <ref> [BaL90, ChN91, LeV90, LeN91, LCB92, NTT88, Nel90, NTT90, SeT91, ZaM90] </ref>. In the former case, the results motivate an approach to analytical parallel program performance prediction that is different from most previous models for this purpose. <p> Stochastic models are nevertheless important for the performance evaluation of high-level design issues in parallel systems including issues such as multiprogrammed multiprocessor scheduling policies, synchronization management policies within programs, and sometimes abstract models of parallel program behavior as well <ref> [ALL89, BaL90, ChN91, LeV90, LeN91, LCB92, NTT88, Nel90, NTT90, SeT91, ZaM90] </ref>. For example, the models in multiprocessor scheduling performance studies must represent complex workloads consisting of many different jobs (programs). Representing the characteristics (e.g., CPU demands, parallelism, etc.) of each individual workload member would be too tedious and sometimes impractical. <p> They assumed that the parallel jobs consisted of tasks with exponentially distributed execution times. But, in fact, Setia and Tripathi <ref> [SeT91] </ref> showed that the same conclusion holds with a completely different assumption about task times. Specifically, they assumed that each job consisted of tasks of equal size, while the total execution time of the jobs on any fixed number of processors was assumed to be exponentially distributed.
Reference: [Sev89] <author> K. C. SEVCIK, </author> <title> Characterizations of Parallelism in Applications and Their Use in Scheduling, </title> <booktitle> Proc. ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems 17, </booktitle> <month> 1 (May </month> <year> 1989), </year> <pages> 171-180. </pages>
Reference-contexts: In a later study, Sevcik argues that in a multiprogrammed parallel system under moderate to high load, better performance is possible if scheduling decisions are based not only on A but also on one or more additional parameters such as maximum parallelism, variance of parallelism and offered system load <ref> [Sev89] </ref>. We observe that the deterministic model provides an efficient technique for obtaining these various parameters for a particular program. In fact, all these parameters can be derived from the same solution of the deterministic model used above for calculating A. <p> Specifically, as noted above the parallelism profile of the application is derived as part of that solution, and all parameters of interest can be easily derived from this profile including the minimum, maximum, average and variance of parallelism, and the fractions of work in sequential and maximum parallel phases <ref> [Sev89] </ref>.
Reference: [ShN93] <author> A. SHATDAL and J. F. NAUGHTON, </author> <title> Using Shared Virtual Memory for Parallel Join Processing, </title> <type> Computer Sciences Technical Report #1139, </type> <institution> Univ. of Wisconsin-Madison, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: If successful, the model could yield a potentially important analytical evaluation technique for such programs. For example, the model might be useful for application areas such as parallel query processing in database systems where, again, significant partitioning and scheduling issues arise <ref> [ShN93] </ref>. A common workload characteristic complicating the problem of partitioning is data skew. In such cases, skewed task execution times would have to be represented as a set of (unequal) deterministic quantities, with the partitioning of work represented by the scheduling function.
Reference: [Sha90] <author> A. C. SHAW, </author> <title> Deterministic Timing Schema for Parallel Programs, </title> <type> Technical Report 90-05-06, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> May </month> <year> 1990. </year>
Reference: [SWG92] <author> J. P. SINGH, W. WEBER and A. GUPTA, </author> <title> SPLASH: Stanford Parallel Applications for Shared-Memory, Computer Architecture News 20, </title> <month> 1 (March </month> <year> 1992), </year> <pages> 5-44. </pages> - -- 
Reference-contexts: The Large input size is a somewhat more realistic data set than the Small size.) Four of the applications (MP3D, Locus Route, Water and Barnes) are from the Splash suite, which was developed to provide a realistic set of parallel applications for performance evaluation of parallel systems <ref> [SWG92] </ref>. The other three are also real applications in the sense that they were written to solve computationally intensive problems of interest to their authors. Hydro is a parallel simulation of particle motion in viscous fluids, with efficient communication. [FuK92]. <p> The highest estimated CV T | D on this system is 0.022 (for the Res-Move phase of MP3D) and this was obtained with a much smaller input size than expected in practice <ref> [SWG92] </ref>. To analyze these results further, we compare the measured parameters against regions of the parameter space in Figure 3.2 (recalling that Figure 3.2 is pessimistic for communication overhead less than or equal to 0.24). <p> In this table and the description below, we discuss in a little more detail the characteristics relevant to this study, particularly the task graphs, scheduling methods, and the nature of variations in the task times. The first program, MP3D, is taken from the SPLASH suite of parallel applications <ref> [SWG92] </ref>. It simulates the motion of particles in very low density fluids. The task graph for this program is shown in Figure 5.1 (a). It is an iterative fork-join task graph with five parallel phases (parallel loops) per iteration. <p> However, because of the processor-splitting between loops, significant performance degradation occurs when executing on an odd total number of processors since the even numbered processors have to accomplish a larger amount of work in this case. Locus Route, also a SPLASH application <ref> [SWG92] </ref>, is a commercial quality wire-router for VLSI standard cells. It is a fork-join program consisting of two iterations, with each iteration ending in a barrier (Figure 5.1 (c)). <p> However, two or more processes routing wires through overlapping regions of the chip must read and intermittently update common portions of the cost-array data structure, and this is the principal source of remote communication (cache misses) in the program <ref> [SWG92] </ref>. To reduce this communication requirement, Locus Route provides a semi-static task scheduling option called geographic scheduling in which separate task queues are maintained for tasks corresponding to wires in different regions of the chip. <p> To restrict the division to be based on information available to the program, we used the area of the bounding box of each wire (the smallest rectangle containing it) as a measure of the work required for the wire <ref> [SWG92] </ref>. We then divided the chip into rectangular regions containing approximately equal amounts of work, still using the leftmost pin of a wire to define its location on the chip.
Reference: [TaV85] <author> R. E. TARJAN and U. VISHKIN, </author> <title> An Efficient Parallel Biconnectivity Algorithm, </title> <journal> SIAM Journal of Computing 14, </journal> <volume> 4 (1985), </volume> <pages> 862-874. </pages>
Reference-contexts: PSIM was developed at Lawrence Livermore Laboratories to simulate the indirect binary n-cube memory server network in a large parallel vector-processing environment [Bro88b]. Bicon is an implementation of a parallel algorithm to find the biconnected components of large graphs <ref> [TaV85] </ref>. We measured each of the programs running stand-alone, allowing us to characterize the non-determinism intrinsic in the program.
Reference: [ThB86] <author> A. THOMASIAN and P. F. </author> <title> BAY, Analytic Queueing Network Models for Parallel Processing of Task Systems, </title> <journal> IEEE Trans. on Computers C-35, </journal> <month> 12 (December </month> <year> 1986), </year> <pages> 1045-1054. </pages>
Reference-contexts: Performance models of parallel programs and systems have typically used stochastic task execution times to represent non-determinism due to these various sources. In fact, most previous analytical models for parallel programs are stochastic models <ref> [AIA91, DuB82, HaM92, KME89, KrW85, LCB92, MaS91, MaL90, ThB86] </ref>. - -- Non-deterministic delays due to communication and resource contention increase the variability of process execution times (besides increasing the mean execution times), which in turn affects synchronization costs. <p> assumptions and solutions techniques of previous analytical models in Chapter 2, we find that many previous models apply only to programs with extremely simple synchronization structures [AIA91, Cve87, DuB82, KrW85, LCB92, MaS91, TsV90, VSS88], while other models require complex and heuristic solution techniques to model programs with more sophisticated structures <ref> [KME89, MaL90, ThB86] </ref>. Furthermore, models in the latter class have to assume exponentially distributed task execution times to permit tractable solutions. <p> Models Applicable to Arbitrary Task Graphs We begin our discussion of previous work with three models that apply to arbitrary task graphs, and which illustrate the above hierarchical framework as well as the principal difficulties of the general problem. Thomasian and Bay <ref> [ThB86] </ref> developed a 2-level hierarchical model in which task residence times are assumed to be exponentially distributed. <p> Less restrictive analytical models, namely models that apply to non-fork-join programs and eliminate the above simplifying assumptions, have all assumed exponential task execution times for analytical tractability <ref> [KME89, MaL90, Moh84, ThB86] </ref>. Again, to our knowledge, none of these models has been tested for accuracy using actual programs, and validations against hypothetical task graphs have not tested the accuracy of the exponential task assumption. <p> We use these to compare the relative influence of the two sources of non-determinism, as well as to evaluate the overall variance and distribution of execution time. In subsequent chapters, we discuss what the results of this study imply for parallel program performance prediction models <ref> [KME89, KrW85, MaL90, Nel90, ThB86] </ref> as well as for more general stochastic models of parallel systems [BaL90, ChN91, LeV90, LeN91, LCB92, NTT88, Nel90, NTT90, SeT91, ZaM90]. <p> In Chapter 2, however, we saw that previous stochastic models that apply to any but the simplest program structures have had to assume exponentially distributed task execution times for analytical tractability. Even with this assumption, these models require extremely complex and heuristic solution techniques <ref> [KME89, MaL90, Moh84, ThB86] </ref>. It thus appears important to re-evaluate the usefulness of stochastic models for parallel program performance prediction, and perhaps to develop an alternative approach. Chapters 5, 6, 7 in this thesis explore these questions in some detail. <p> The actual choice of system-level model used to calculate the communication and queueing delays is strongly dependent both on the system under consideration, and perhaps also on the required accuracy of the modeling study. Therefore, unlike many previous authors <ref> [KME89, MaL90, ThB86] </ref>, we do not specify any particular queueing network framework to be used at the system level. <p> Furthermore, all such models are restricted to programs with the simplest task structures [AIA90, KrW85, MaS91]. 2. Stochastic models applying to more general classes of programs <ref> [KME89, MaL90, Moh84, ThB86] </ref>, all of which assume exponentially distributed task times, have significant and sometimes large errors. Furthermore, the models in this class appear too inefficient to use even for programs with relatively small task graphs of a few hundred tasks.
Reference: [TRS90] <author> D. TOWSLEY, G. ROMMEL and J. A. STANKOVIC, </author> <title> Analysis of Fork-Join Program Response Times on Multiprocessors, </title> <journal> IEEE Trans. on Parallel and Distributed Systems 1, </journal> <month> 3 (July </month> <year> 1990), </year> . 
Reference-contexts: head of the edge must complete before any task in the vertex at the tail can begin execution). ddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddd Fork-join Task Graph: A task graph consisting of alternating sequential and parallel phases, where each parallel phase consists of a set of independent tasks and ends in a full barrier synchronization <ref> [TRS90] </ref>. <p> Models Restricted to Fork-Join Programs A number of previous models are restricted to programs with fork-join task graphs <ref> [AIA91, Cve87, DuB82, HeT83, KrW85, TRS90, TsV90, VSS88] </ref>, and are all much simpler than models described so far. Of these, perhaps the most general is the seminal model of Kruskal and Weiss [KrW85]. <p> We will not describe the other, less general, models for fork-join programs here, except to note that both the models of Heidelberger and Trivedi [HeT83] and Towsley et al <ref> [TRS90] </ref> apply to multiprogrammed parallel systems with multiple parallel jobs (each job is assumed to have the same number of tasks in each parallel phase and each task is exponentially distributed). All other models to which we refer in this paper only consider systems with a single executing job. <p> Summary of the State of the Art We can summarize what is known about the state of the art as follows. For fork-join programs, stochastic models with simplifying assumptions (particularly, i.i.d. task times and simplified task scheduling) have been developed that are efficient to solve <ref> [AIA90, DuB82, HeT83, KrW85, TRS90] </ref>. To our knowledge, these models have not been tested for accuracy using actual programs. Two efficient deterministic models [TsV90, VSS88] for restricted types of fork-join programs have also been developed, and shown to be accurate for several programs each.
Reference: [Tri82] <author> K. S. TRIVEDI, </author> <title> Probability and Statistics with Reliability, Queueing and Computer Science Applications, </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1982. </year>
Reference-contexts: In addition, the Kolmogorov-Smirnov statistic can be constructed from the measured samples and used to derive a confidence band for the actual parent distribution <ref> [Tri82] </ref>. This gives an error bound between the estimated and actual parent distribution at a certain level of confidence.
Reference: [TsA93] <author> J. TSAI and A. AGARWAL, </author> <title> Analyzing Multiprocessor Cache Behavior Through Data Reference Modeling, </title> <booktitle> Proc. 1993 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <year> 1993. </year>
Reference-contexts: In fact, for algorithms with simple, regular and fixed data-reference patterns, Tsai and Agarwal have shown that it is possible to derive precise analytical estimates of multiprocessor cache miss rates as functions of input size, cache block size, and the number of processors <ref> [TsA93] </ref>. Finally, when using a model in early stages of the design and development of a program, important parameter values, in particular CPU requirements and perhaps rough communication rates, may have to be estimated or measured from partially developed code. <p> Such techniques would enable the model to explore the impact of hypothetical system and algorithm design changes on communication costs in greater detail than is possible now. A preliminary step in this direction has recently been taken. Tsai and Agarwal <ref> [TsA93] </ref> describe a method for computing multiprocessor cache miss rates in shared-memory algorithms as a function of problem size, cache line size, and system size, for algorithms with simple, regular and fixed data reference patterns.
Reference: [TsV90] <author> T. TSUEI and M. K. VERNON, </author> <title> Diagnosing Parallel Program Speedup Limitations Using Resource Contention Models, </title> <booktitle> Proc. 1990 International Conference on Parallel Processing, </booktitle> <year> 1990, </year> <pages> II 185-189. </pages>
Reference-contexts: In fact, reviewing the assumptions and solutions techniques of previous analytical models in Chapter 2, we find that many previous models apply only to programs with extremely simple synchronization structures <ref> [AIA91, Cve87, DuB82, KrW85, LCB92, MaS91, TsV90, VSS88] </ref>, while other models require complex and heuristic solution techniques to model programs with more sophisticated structures [KME89, MaL90, ThB86]. Furthermore, models in the latter class have to assume exponentially distributed task execution times to permit tractable solutions. <p> Models Restricted to Fork-Join Programs A number of previous models are restricted to programs with fork-join task graphs <ref> [AIA91, Cve87, DuB82, HeT83, KrW85, TRS90, TsV90, VSS88] </ref>, and are all much simpler than models described so far. Of these, perhaps the most general is the seminal model of Kruskal and Weiss [KrW85]. <p> This estimate is asymptotically exact as P fi and N /P fi , but has been shown to be fairly accurate compared to simulations for small values of P, for a number of task time distributions. The models of Vrsalovic et al. [VSS88], Cvetanovic [Cve87] and Tsuei and Vernon <ref> [TsV90] </ref> are the three deterministic models mentioned in Chapter 1. The models of Vrsalovic et al and Cvetanovic apply to iterative parallel programs in which the computational work as well as the hhhhhhhhhhhhhhh 3. <p> For fork-join programs, stochastic models with simplifying assumptions (particularly, i.i.d. task times and simplified task scheduling) have been developed that are efficient to solve [AIA90, DuB82, HeT83, KrW85, TRS90]. To our knowledge, these models have not been tested for accuracy using actual programs. Two efficient deterministic models <ref> [TsV90, VSS88] </ref> for restricted types of fork-join programs have also been developed, and shown to be accurate for several programs each. <p> Comments on a Previous Deterministic Model Our comparisons above have focused on contrasting previous stochastic models with the deterministic model developed in Section 4. We have not directly compared the most relevant previous deterministic model, namely that of Tsuei and Vernon <ref> [TsV90] </ref>. The main reason is that their model has already been shown to be accurate for fork-join programs with good load-balance, and it is restricted to these programs. <p> We ignored other sources of overhead, namely lock contention and forking overhead, for our study. If these costs are also significant, Tsuei and Vernon have shown that each can be separately and accurately included <ref> [TsV90] </ref>. The Sequent Symmetry bus supports an invalidation-based snooping cache protocol.
Reference: [TsV92] <author> T. TSUEI and M. K. VERNON, </author> <title> A Multiprocessor Bus Design Model Validated by System Measurement, </title> <journal> IEEE Trans. on Parallel and Distributed Systems 3, </journal> <month> 6 (November </month> <year> 1992), </year> <pages> 712-727. </pages>
Reference-contexts: If these costs are also significant, Tsuei and Vernon have shown that each can be separately and accurately included [TsV90]. The Sequent Symmetry bus supports an invalidation-based snooping cache protocol. In a previous analytical modeling study of the Sequent bus <ref> [TsV92] </ref>, Tsuei and Vernon showed that two aspects of the bus protocol have a significant impact on performance: (1) at most three read requests can be outstanding at any time from all processors, with at most one per processor, and (2) responses to read requests have higher (non-preemptive) priority for the
Reference: [TuG89] <author> A. TUCKER and A. GUPTA, </author> <title> Process Control and Scheduling Issues for Multiprogrammed Shared-Memory Multiprocessors, </title> <booktitle> Proc. 12 th ACM Symposium on Operating Systems Principles, </booktitle> <month> December </month> <year> 1989, </year> <pages> 159-166. </pages>
Reference: [VLZ88] <author> M. K. VERNON, E. D. LAZOWSKA and J. ZAHORJAN, </author> <title> An Accurate and Efficient Performance Analysis Technique for Multiprocessor Snooping Cache-Consistency Protocols, </title> <booktitle> Proc. 15th International Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1988. </year>
Reference-contexts: c done Insert c in ready_task_list g For each free process p If Sched (ready_task_list,p) finds a task t to execute Add t to E set Update current state cur_state /* Delete task next_task_done and add newly started tasks */ - Total Program Execution Time = T total _______________________________________________________________ _______________________________________________________________ <ref> [AdV, VLZ88, WiE90] </ref>. The solution complexity of approximate MVA is relatively insensitive to the number of customers (indirectly, the number of iterations required for convergence can be affected by the customer population).
Reference: [VSS88] <author> D. F. VRSALOVIC, D. P. SIEWIOREK, Z. Z. SEGALL and E. F. GEHRINGER, </author> <title> Performance Prediction and Calibration for a Class of Multiprocessors, </title> <journal> IEEE Trans. on Computers 37, </journal> <volume> 11 (Nov. </volume> <year> 1988), </year> <pages> 1353-1365. </pages>
Reference-contexts: In fact, reviewing the assumptions and solutions techniques of previous analytical models in Chapter 2, we find that many previous models apply only to programs with extremely simple synchronization structures <ref> [AIA91, Cve87, DuB82, KrW85, LCB92, MaS91, TsV90, VSS88] </ref>, while other models require complex and heuristic solution techniques to model programs with more sophisticated structures [KME89, MaL90, ThB86]. Furthermore, models in the latter class have to assume exponentially distributed task execution times to permit tractable solutions. <p> Models Restricted to Fork-Join Programs A number of previous models are restricted to programs with fork-join task graphs <ref> [AIA91, Cve87, DuB82, HeT83, KrW85, TRS90, TsV90, VSS88] </ref>, and are all much simpler than models described so far. Of these, perhaps the most general is the seminal model of Kruskal and Weiss [KrW85]. <p> This estimate is asymptotically exact as P fi and N /P fi , but has been shown to be fairly accurate compared to simulations for small values of P, for a number of task time distributions. The models of Vrsalovic et al. <ref> [VSS88] </ref>, Cvetanovic [Cve87] and Tsuei and Vernon [TsV90] are the three deterministic models mentioned in Chapter 1. The models of Vrsalovic et al and Cvetanovic apply to iterative parallel programs in which the computational work as well as the hhhhhhhhhhhhhhh 3. <p> For fork-join programs, stochastic models with simplifying assumptions (particularly, i.i.d. task times and simplified task scheduling) have been developed that are efficient to solve [AIA90, DuB82, HeT83, KrW85, TRS90]. To our knowledge, these models have not been tested for accuracy using actual programs. Two efficient deterministic models <ref> [TsV90, VSS88] </ref> for restricted types of fork-join programs have also been developed, and shown to be accurate for several programs each.
Reference: [WiE90] <author> D. L. WILLICK and D. L. EAGER, </author> <title> An Analytic Model of Multistage Interconnection Networks, </title> <booktitle> Proc. ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1990, </year> <pages> 192-202. </pages>
Reference-contexts: c done Insert c in ready_task_list g For each free process p If Sched (ready_task_list,p) finds a task t to execute Add t to E set Update current state cur_state /* Delete task next_task_done and add newly started tasks */ - Total Program Execution Time = T total _______________________________________________________________ _______________________________________________________________ <ref> [AdV, VLZ88, WiE90] </ref>. The solution complexity of approximate MVA is relatively insensitive to the number of customers (indirectly, the number of iterations required for convergence can be affected by the customer population).
Reference: [Wol89] <author> R. W. WOLFF, </author> <title> Stochastic Modeling and the Theory of Queues, </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1989. </year>
Reference-contexts: A distribution F (t) is said to be IFR, or Increasing Failure Rate, if F (0) = 0 and if, for any t 0 &gt; 0, 1-F (t +t 0 ) hhhhhhhhhh is monotone increasing in t. IFR distributions are continuous and have decreasing mean residual life <ref> [Wol89] </ref>. For example, the Erlang and exponential are both IFR but the hy perexponential distribution is not. - -- communication demand in each iteration can be equally divided among (an arbitrary number of) available processors. <p> But (4) is just the definition of a renewal process generated by Pi: 1 i &lt; -; specifically, R (t) is the number of renewals by time t <ref> [Wol89] </ref>. The following expressions for m R (t) E [R (t)] and its ordinary Laplace transform are well known [Wol89]: m R (t) = F P (t) + m R (t) * F P (t), 1 - F P (s) hhhhhhhhh , (5) The corresponding expressions for m R 2 (t) <p> But (4) is just the definition of a renewal process generated by Pi: 1 i &lt; -; specifically, R (t) is the number of renewals by time t <ref> [Wol89] </ref>. The following expressions for m R (t) E [R (t)] and its ordinary Laplace transform are well known [Wol89]: m R (t) = F P (t) + m R (t) * F P (t), 1 - F P (s) hhhhhhhhh , (5) The corresponding expressions for m R 2 (t) E [R 2 (t)] and its Laplace transform are also not difficult to derive [Wol89]: m R 2 (t) <p> transform are well known <ref> [Wol89] </ref>: m R (t) = F P (t) + m R (t) * F P (t), 1 - F P (s) hhhhhhhhh , (5) The corresponding expressions for m R 2 (t) E [R 2 (t)] and its Laplace transform are also not difficult to derive [Wol89]: m R 2 (t) = m R (t) + 2 m R (t -x)dm R (x), t 0 ( 1 - F P (s) ) 2 hhhhhhhhhhhhhhhhhhh (6) where L (m R (t)) and L (m R 2 (t)) denote the ordinary Laplace transforms of m R (t) and m <p> Approximate expressions for mm T | D and ss T | D 2 Estimates for m R (t) and s R 2 (t) are given in the Central Limit Theorem for renewal processes <ref> [Wol89] </ref>, which states that as t fi , R (t) is asymptotically normal with mean 7 t /m P and variance ts P 3 . Therefore, we estimate s R 2 by Ds P 3 = (D /m P )CV P 2 . <p> We can, however, derive the form of the distribution in the special case when D is large. In that case, we show in Appendix A that it is possible to apply the version of the Central Limit Theorem for cumulative (regenerative) processes <ref> [Wol89] </ref> to prove: - -- T (D) fi Normal (m (D),s (D)) as D fi ,where m (D) = D + D m C hhhhh , (8) s 2 (D) = Ds C hhhhh + m P m C 2 hhhhhhhh , and fi denotes convergence in distribution. <p> 2 ] and E [W j 2 ] are finite, I (t /m) Var (W 1 - E [W 1 ]X 1 /m) O C (t) - 1 hh t E [W 1 ] hhhhhhhhhhhhhhhhhhhhhhhhhhhh fi Normal (0,1) as t fi . (A slightly more general case is proved in <ref> [Wol89, p. 124] </ref>.) In our model, let X i = P i , W i = C i . Then m = m P , E [W 1 ] = m C , and C (D) = S i =1 R (D) C i .
Reference: [YaV91] <author> N. YAZICI-PEKERGIN and J. VINCENT, </author> <title> Stochastic Bounds on Execution Times of Parallel Programs, </title> <journal> IEEE Trans. on Software Engineering 17, </journal> <month> 10 (October </month> <year> 1991), </year> <pages> 1005 1012. </pages>
Reference-contexts: We do so in Chapter 6. A second body of work also derives bounds on the execution time of a parallel program on a specific number of processors <ref> [HaM92, YaV91] </ref>. Unlike the bounds described above, these results are based on detailed inputs similar to those used in the stochastic models reviewed earlier, namely a full description of the task graph along with the distribution of the individual task execution times.
References-found: 57

