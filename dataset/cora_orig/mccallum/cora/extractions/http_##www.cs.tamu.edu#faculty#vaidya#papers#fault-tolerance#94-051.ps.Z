URL: http://www.cs.tamu.edu/faculty/vaidya/papers/fault-tolerance/94-051.ps.Z
Refering-URL: http://www.cs.tamu.edu/faculty/vaidya/Vaidya-ftc.html
Root-URL: http://www.cs.tamu.edu
Email: E-mail: vaidya@cs.tamu.edu  
Phone: Phone: 409-845-0512 Fax: 409-847-8578  
Title: Consistent Logical Checkpointing  
Author: Nitin H. Vaidya 
Date: July 1994  
Address: College Station, TX 77843-3112  
Affiliation: Department of Computer Science Texas A&M University  
Pubnum: Technical Report 94-051  
Abstract: The traditional consistent checkpointing algorithms require the different processes to save their state at about the same time. This causes contention for the stable storage, potentially resulting in large overheads. Staggering the checkpoints taken by various processes can reduce the overhead. Some techniques for staggering the checkpoints have been proposed previously [9], however, these techniques result in "limited staggering" in that not all processes' checkpoints can be staggered. Ideally, one would like to stagger the checkpoints arbitrarily. This report presents a simple approach to arbitrarily stagger the checkpoints. Our approach requires that the processes take consistent logical checkpoints, as compared to consistent physical checkpoints enforced by existing algorithms. This report discusses the proposed approach and the implementation issues. The proposed approach was discussed briefly in [11]. fl Section 5 (Related Work) revised October 1994.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. M. Chandy and L. Lamport, </author> <title> "Distributed snapshots: Determining global states in distributed systems," </title> <journal> ACM Trans. Comp. Syst., </journal> <volume> vol. 3, </volume> <pages> pp. 63-75, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: Unless some recovery techniques are utilized, a processor failure will require a restart of the application, resulting in significant loss of performance. Consistent checkpointing is a commonly used technique to prevent complete loss of computation upon a failure <ref> [1, 3, 7, 9, 12] </ref>. A "consistent checkpointing" algorithm saves a consistent view of the distributed system state on a stable storage. The loss of computation upon a failure is bounded by taking consistent checkpoints with adequate frequency. <p> This report discusses the proposed approach and the implementation issues. (These were discussed briefly in [11].) The report is organized as follows. Section 2 discusses the notion of a logical checkpoint. Section 3 presents a consistent checkpointing algorithm proposed by Chandy and Lamport <ref> [1] </ref>. Section 4 presents the basic principle behind the proposed approach; implementation issues are discussed in Section 6. Our approach is closely related to [1, 5, 9, 13], as discussed in Section 5. <p> Section 2 discusses the notion of a logical checkpoint. Section 3 presents a consistent checkpointing algorithm proposed by Chandy and Lamport [1]. Section 4 presents the basic principle behind the proposed approach; implementation issues are discussed in Section 6. Our approach is closely related to <ref> [1, 5, 9, 13] </ref>, as discussed in Section 5. Section 7 concludes the report. 2 2 A Logical Checkpoint A process is said to be deterministic if its state depends only on its initial state and the messages delivered to it [10]. <p> We have, as yet, not experimented with anti-messages. Therefore, practicality of this idea is open to debate. Note that a physical checkpoint is trivially a logical checkpoint, however, the converse 5 is not true. 3 Chandy-Lamport Algorithm <ref> [1] </ref> Chandy and Lamport [1] presented an algorithm for taking a consistent checkpoint of a distributed system. Although the proposed approach can potentially be used with any consistent checkpointing algorithm, for brevity, we limit our discussion to the Chandy-Lamport algorithm. <p> We have, as yet, not experimented with anti-messages. Therefore, practicality of this idea is open to debate. Note that a physical checkpoint is trivially a logical checkpoint, however, the converse 5 is not true. 3 Chandy-Lamport Algorithm <ref> [1] </ref> Chandy and Lamport [1] presented an algorithm for taking a consistent checkpoint of a distributed system. Although the proposed approach can potentially be used with any consistent checkpointing algorithm, for brevity, we limit our discussion to the Chandy-Lamport algorithm. <p> Assume that the processes communicate with each other using unidirectional communication channels; a bidirectional channel can be modeled as two unidirectional channels. The communication graph is assumed to be strongly connected. The algorithm presented next is essentially identical to Chandy-Lamport <ref> [1] </ref> and assumes that a certain process is designated as the coordinator. This algorithm is also presented in [9]. Algorithm: The coordinator process, say P, initiates the consistent checkpointing algorithm by sending marker messages on each channel, incident on, and directed away from P and immediately takes a checkpoint. <p> Consistent message logging phase: When the coordinator receives acknowledgement messages from all the processes indicating that they have taken a physical checkpoint, the coordinator initiates the consistent message logging phase, essentially, by initiating the Chandy-Lamport algorithm <ref> [1] </ref>. <p> failure, each process rolls back to its recent physical checkpoint and re-executes (using the logged messages) to restore the process state to the logical checkpoint that is a part of the most recent consistent recovery line. 8 5 Relation to Existing Work The algorithm presented above is closely related to <ref> [1, 5, 8, 9, 13] </ref>. Our algorithm is designed to bound the rollback distance, similar to the traditional coordinated checkpointing algorithms. It may be noted that, after a failure, a process rolls back to a physical checkpoint and then executes to restore a logical checkpoint. <p> These logical checkpoints are used to recover from a future failure. One consequence of this is that we do not need to log all messages, only those message are logged which make the logical 9 checkpoints consistent. Plank [9] presents two coordinated checkpointing algorithms (one similar to Chandy-Lamport <ref> [1] </ref>) that attempt to stagger the checkpoints. However, it is possible that some checkpoints taken by these algorithms cannot be staggered. The degree of staggering is affected by the timing of application message delivery. In contrast, our algorithm allows arbitrary staggering of the physical checkpoints.
Reference: [2] <author> C. J. Date, </author> <title> An Introduction to Database Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: For each relevant message (whose effect must be undone), an anti-message is saved on the stable storage. The notion of an anti-message here is similar to that used in time warp mechanism [4] (although the implementations could be very different) or that of UNDO records <ref> [2] </ref> in database systems. Anti-message M fl corresponding to a message M can be used to undo the state change caused by message M. at time t 1 . Process P delivers messages M4 and M5 between time t 1 and t 2 .
Reference: [3] <author> E. N. Elnozahy, D. B. Johnson, and W. Zwaenepoel, </author> <title> "The performance of consistent checkpointing," </title> <booktitle> in Symposium on Reliable Distributed Systems, </booktitle> <year> 1992. </year>
Reference-contexts: Unless some recovery techniques are utilized, a processor failure will require a restart of the application, resulting in significant loss of performance. Consistent checkpointing is a commonly used technique to prevent complete loss of computation upon a failure <ref> [1, 3, 7, 9, 12] </ref>. A "consistent checkpointing" algorithm saves a consistent view of the distributed system state on a stable storage. The loss of computation upon a failure is bounded by taking consistent checkpoints with adequate frequency.
Reference: [4] <author> D. Jefferson, </author> <title> "Virtual time," </title> <journal> ACM Trans. Prog. Lang. Syst., </journal> <volume> vol. 3, </volume> <pages> pp. 404-425, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: For each relevant message (whose effect must be undone), an anti-message is saved on the stable storage. The notion of an anti-message here is similar to that used in time warp mechanism <ref> [4] </ref> (although the implementations could be very different) or that of UNDO records [2] in database systems. Anti-message M fl corresponding to a message M can be used to undo the state change caused by message M. at time t 1 .
Reference: [5] <author> D. B. Johnson, </author> <title> "Efficient transparent optimistic rollback recovery for distributed application programs," </title> <booktitle> in Symposium on Reliable Distributed Systems, </booktitle> <pages> pp. 86-95, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Section 2 discusses the notion of a logical checkpoint. Section 3 presents a consistent checkpointing algorithm proposed by Chandy and Lamport [1]. Section 4 presents the basic principle behind the proposed approach; implementation issues are discussed in Section 6. Our approach is closely related to <ref> [1, 5, 9, 13] </ref>, as discussed in Section 5. Section 7 concludes the report. 2 2 A Logical Checkpoint A process is said to be deterministic if its state depends only on its initial state and the messages delivered to it [10]. <p> failure, each process rolls back to its recent physical checkpoint and re-executes (using the logged messages) to restore the process state to the logical checkpoint that is a part of the most recent consistent recovery line. 8 5 Relation to Existing Work The algorithm presented above is closely related to <ref> [1, 5, 8, 9, 13] </ref>. Our algorithm is designed to bound the rollback distance, similar to the traditional coordinated checkpointing algorithms. It may be noted that, after a failure, a process rolls back to a physical checkpoint and then executes to restore a logical checkpoint. <p> By enforcing staggering, our approach is expected to perform much better than [8]. Long et al. also assume synchronized communication, no such assumption is made in the proposed approach. Johnson <ref> [5] </ref> presents an algorithm that forces the processes to log message on the stable storage or to take a physical checkpoint. The goal of his algorithm is to make the state of a single process committable (primarily, to allow it to commit an output). <p> This 4 Johnson <ref> [5] </ref> suggested a scheme where each process uses a similar heuristic to decide whether to log messages or not. 5 Recollect that a physical checkpoint is also trivially a logical checkpoint.
Reference: [6] <author> S. Kaul (Advisor: N. Vaidya), </author> <title> M.S. </title> <type> thesis, </type> <institution> in progress, Texas A&M University. </institution>
Reference-contexts: The proposed approach ensures that the physical checkpoints taken by various processes are completely staggered to minimize the contention in accessing the stable storage. The report also suggests a number of variations of the proposed approach. Performance evaluation of the proposed algorithm is a subject of future work <ref> [6] </ref>. The experimental results will be made available in a future revision of this report.
Reference: [7] <author> R. Koo and S. Toueg, </author> <title> "Checkpointing and rollback-recovery for distributed systems," </title> <journal> IEEE Trans. Softw. Eng., </journal> <volume> vol. 13, </volume> <pages> pp. 23-31, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: Unless some recovery techniques are utilized, a processor failure will require a restart of the application, resulting in significant loss of performance. Consistent checkpointing is a commonly used technique to prevent complete loss of computation upon a failure <ref> [1, 3, 7, 9, 12] </ref>. A "consistent checkpointing" algorithm saves a consistent view of the distributed system state on a stable storage. The loss of computation upon a failure is bounded by taking consistent checkpoints with adequate frequency.
Reference: [8] <author> J. Long, B. Janssens, and W. K. Fuchs, </author> <title> "An evolutionary approach to concurrent checkpointing," </title> <journal> submitted to IEEE Transactions on Parallel and Distributed Systems. </journal> <volume> 16 </volume>
Reference-contexts: failure, each process rolls back to its recent physical checkpoint and re-executes (using the logged messages) to restore the process state to the logical checkpoint that is a part of the most recent consistent recovery line. 8 5 Relation to Existing Work The algorithm presented above is closely related to <ref> [1, 5, 8, 9, 13] </ref>. Our algorithm is designed to bound the rollback distance, similar to the traditional coordinated checkpointing algorithms. It may be noted that, after a failure, a process rolls back to a physical checkpoint and then executes to restore a logical checkpoint. <p> However, it is possible that some checkpoints taken by these algorithms cannot be staggered. The degree of staggering is affected by the timing of application message delivery. In contrast, our algorithm allows arbitrary staggering of the physical checkpoints. Long et al. <ref> [8] </ref> discuss an evolutionary checkpointing approach that is similar to consistent logical checkpointing. The fundamental difference between the two approaches is that our approach staggers the physical checkpoints, while the scheme in [8] does not allow staggering. By enforcing staggering, our approach is expected to perform much better than [8]. <p> In contrast, our algorithm allows arbitrary staggering of the physical checkpoints. Long et al. <ref> [8] </ref> discuss an evolutionary checkpointing approach that is similar to consistent logical checkpointing. The fundamental difference between the two approaches is that our approach staggers the physical checkpoints, while the scheme in [8] does not allow staggering. By enforcing staggering, our approach is expected to perform much better than [8]. Long et al. also assume synchronized communication, no such assumption is made in the proposed approach. <p> al. <ref> [8] </ref> discuss an evolutionary checkpointing approach that is similar to consistent logical checkpointing. The fundamental difference between the two approaches is that our approach staggers the physical checkpoints, while the scheme in [8] does not allow staggering. By enforcing staggering, our approach is expected to perform much better than [8]. Long et al. also assume synchronized communication, no such assumption is made in the proposed approach. Johnson [5] presents an algorithm that forces the processes to log message on the stable storage or to take a physical checkpoint.
Reference: [9] <author> J. S. Plank, </author> <title> Efficient Checkpointing on MIMD Architectures. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Princeton University, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: Unless some recovery techniques are utilized, a processor failure will require a restart of the application, resulting in significant loss of performance. Consistent checkpointing is a commonly used technique to prevent complete loss of computation upon a failure <ref> [1, 3, 7, 9, 12] </ref>. A "consistent checkpointing" algorithm saves a consistent view of the distributed system state on a stable storage. The loss of computation upon a failure is bounded by taking consistent checkpoints with adequate frequency. <p> The loss of computation upon a failure is bounded by taking consistent checkpoints with adequate frequency. The traditional consistent checkpointing algorithms require the different processes to save their state at about the same time. This causes contention for the stable storage, potentially resulting in significant performance degradation <ref> [9] </ref>. Staggering the checkpoints taken by various processes can reduce the overhead of consistent checkpointing. Some techniques for staggering the checkpoints have been previously proposed [9], however, these techniques result in "limited staggering" in that not all processes' checkpoints can be staggered. <p> This causes contention for the stable storage, potentially resulting in significant performance degradation <ref> [9] </ref>. Staggering the checkpoints taken by various processes can reduce the overhead of consistent checkpointing. Some techniques for staggering the checkpoints have been previously proposed [9], however, these techniques result in "limited staggering" in that not all processes' checkpoints can be staggered. Ideally, one would like to stagger the checkpoints arbitrarily. We assume that a processor does not have enough memory to make an "in-memory" copy of entire process state. <p> Section 2 discusses the notion of a logical checkpoint. Section 3 presents a consistent checkpointing algorithm proposed by Chandy and Lamport [1]. Section 4 presents the basic principle behind the proposed approach; implementation issues are discussed in Section 6. Our approach is closely related to <ref> [1, 5, 9, 13] </ref>, as discussed in Section 5. Section 7 concludes the report. 2 2 A Logical Checkpoint A process is said to be deterministic if its state depends only on its initial state and the messages delivered to it [10]. <p> The communication graph is assumed to be strongly connected. The algorithm presented next is essentially identical to Chandy-Lamport [1] and assumes that a certain process is designated as the coordinator. This algorithm is also presented in <ref> [9] </ref>. Algorithm: The coordinator process, say P, initiates the consistent checkpointing algorithm by sending marker messages on each channel, incident on, and directed away from P and immediately takes a checkpoint. <p> The above algorithm reduces the contention for the stable storage by completely staggering the physical checkpoints. However, contention is now introduced in the second phase of the algorithm when the processes coordinate message logging. This contention can be reduced by using the limited staggering techniques proposed in <ref> [9] </ref>. Our scheme will perform well if message volume is relatively small compared to checkpoint sizes. A few variations to the above algorithm are possible, as discussed in Section 6 and that at most one process can write to the stable storage at any time. <p> failure, each process rolls back to its recent physical checkpoint and re-executes (using the logged messages) to restore the process state to the logical checkpoint that is a part of the most recent consistent recovery line. 8 5 Relation to Existing Work The algorithm presented above is closely related to <ref> [1, 5, 8, 9, 13] </ref>. Our algorithm is designed to bound the rollback distance, similar to the traditional coordinated checkpointing algorithms. It may be noted that, after a failure, a process rolls back to a physical checkpoint and then executes to restore a logical checkpoint. <p> These logical checkpoints are used to recover from a future failure. One consequence of this is that we do not need to log all messages, only those message are logged which make the logical 9 checkpoints consistent. Plank <ref> [9] </ref> presents two coordinated checkpointing algorithms (one similar to Chandy-Lamport [1]) that attempt to stagger the checkpoints. However, it is possible that some checkpoints taken by these algorithms cannot be staggered. The degree of staggering is affected by the timing of application message delivery. <p> Staggering in the consistent message logging phase: During the consistent message logging phase, the processes will save their message logs to the stable storage at about the same time. To minimize stable storage contention during this phase, the technique presented by Plank <ref> [9] </ref> can be used. <p> In fact, different processes may simultaneously use different approaches for establishing a logical checkpoint. Details of the modified algorithm will be presented in a future revision of this report. Synchronizing pair of processes: Plank <ref> [9] </ref> suggests that staggered checkpoints can increase the overhead, if the application does a lot of synchronization.
Reference: [10] <author> R. E. Strom and S. A. Yemini, </author> <title> "Optimistic recovery: An asynchronous approach to fault-tolerance in distributed systems," </title> <booktitle> Digest of papers: The 14 th Int. Symp. Fault-Tolerant Comp., </booktitle> <pages> pp. 374-379, </pages> <year> 1984. </year>
Reference-contexts: Our approach is closely related to [1, 5, 9, 13], as discussed in Section 5. Section 7 concludes the report. 2 2 A Logical Checkpoint A process is said to be deterministic if its state depends only on its initial state and the messages delivered to it <ref> [10] </ref>. A deterministic process can take two types of checkpoints: a physical checkpoint or a logical checkpoint. A process is said to have taken a physical checkpoint at some time t 1 , if the process state at time t 1 is saved on the stable storage.
Reference: [11] <author> N. H. Vaidya, </author> <title> "Some thoughts on distributed recovery," </title> <type> Tech. Rep. 94-044, </type> <institution> Computer Science Department, Texas A&M University, College Station, </institution> <month> June </month> <year> 1994. </year> <note> Available via anonymous ftp from ftp.cs.tamu.edu in directory /pub/vaidya. </note>
Reference-contexts: This report presents a simple approach to "completely stagger" the checkpoints. Our approach requires that the processes take consistent logical checkpoints, as compared to consistent physical checkpoints enforced by existing algorithms. This report discusses the proposed approach and the implementation issues. (These were discussed briefly in <ref> [11] </ref>.) The report is organized as follows. Section 2 discusses the notion of a logical checkpoint. Section 3 presents a consistent checkpointing algorithm proposed by Chandy and Lamport [1]. Section 4 presents the basic principle behind the proposed approach; implementation issues are discussed in Section 6.
Reference: [12] <author> Y. M. Wang and W. K. Fuchs, </author> <title> "Lazy checkpoint coordination for bounding rollback propagation," </title> <booktitle> in Symposium on Reliable Distributed Systems, </booktitle> <pages> pp. 78-85, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Unless some recovery techniques are utilized, a processor failure will require a restart of the application, resulting in significant loss of performance. Consistent checkpointing is a commonly used technique to prevent complete loss of computation upon a failure <ref> [1, 3, 7, 9, 12] </ref>. A "consistent checkpointing" algorithm saves a consistent view of the distributed system state on a stable storage. The loss of computation upon a failure is bounded by taking consistent checkpoints with adequate frequency.
Reference: [13] <author> Y. M. Wang, Y. Huang, and W. K. Fuchs, </author> <title> "Progressive retry for software error recovery in distributed systems," </title> <booktitle> in Digest of papers: The 23 rd Int. Symp. Fault-Tolerant Comp., </booktitle> <pages> pp. 138-144, </pages> <year> 1993. </year>
Reference-contexts: Section 2 discusses the notion of a logical checkpoint. Section 3 presents a consistent checkpointing algorithm proposed by Chandy and Lamport [1]. Section 4 presents the basic principle behind the proposed approach; implementation issues are discussed in Section 6. Our approach is closely related to <ref> [1, 5, 9, 13] </ref>, as discussed in Section 5. Section 7 concludes the report. 2 2 A Logical Checkpoint A process is said to be deterministic if its state depends only on its initial state and the messages delivered to it [10]. <p> To the best of our knowledge, the term logical checkpoint was first introduced by Wang et al. <ref> [13, 14] </ref>, who also presented one approach for taking a logical checkpoint. Now we present three approaches for taking a logical checkpoint at time t 1 . Although the three approaches are equivalent, each approach may be more attractive for some applications than the other approaches. <p> log (on stable storage) all messages delivered to the process between time t 0 and t 1 . (For each message, the message log contains the receive sequence number for the message as well as the entire message.) This approach is essentially identical to that presented by Wang et al. <ref> [13] </ref>. Messages M1, M2 and M3 are delivered to process P by time t 1 . To establish a logical checkpoint of process P at time t 1 , messages M1, M2 and M3 are logged on the stable storage. <p> failure, each process rolls back to its recent physical checkpoint and re-executes (using the logged messages) to restore the process state to the logical checkpoint that is a part of the most recent consistent recovery line. 8 5 Relation to Existing Work The algorithm presented above is closely related to <ref> [1, 5, 8, 9, 13] </ref>. Our algorithm is designed to bound the rollback distance, similar to the traditional coordinated checkpointing algorithms. It may be noted that, after a failure, a process rolls back to a physical checkpoint and then executes to restore a logical checkpoint. <p> It may be noted that, after a failure, a process rolls back to a physical checkpoint and then executes to restore a logical checkpoint. Thus, the overhead of recovery (or rollback distance) is determined by when physical checkpoints are taken. Wang et al. <ref> [13, 14] </ref> introduced the notion of a logical checkpoint. They determine a recovery line consisting of consistent logical checkpoints, after a failure occurs. This recovery line is used to recover from the failure.
Reference: [14] <author> Y. M. Wang, A. Lowry, and W. K. Fuchs, </author> <title> "Consistent global checkpoints based on direct dependency tracking." To appear in Inform. Process. </title> <journal> Lett. </journal> <volume> 17 </volume>
Reference-contexts: To the best of our knowledge, the term logical checkpoint was first introduced by Wang et al. <ref> [13, 14] </ref>, who also presented one approach for taking a logical checkpoint. Now we present three approaches for taking a logical checkpoint at time t 1 . Although the three approaches are equivalent, each approach may be more attractive for some applications than the other approaches. <p> It may be noted that, after a failure, a process rolls back to a physical checkpoint and then executes to restore a logical checkpoint. Thus, the overhead of recovery (or rollback distance) is determined by when physical checkpoints are taken. Wang et al. <ref> [13, 14] </ref> introduced the notion of a logical checkpoint. They determine a recovery line consisting of consistent logical checkpoints, after a failure occurs. This recovery line is used to recover from the failure.
References-found: 14

