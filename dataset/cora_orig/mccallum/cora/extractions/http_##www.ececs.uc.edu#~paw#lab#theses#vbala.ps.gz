URL: http://www.ececs.uc.edu/~paw/lab/theses/vbala.ps.gz
Refering-URL: http://www.ececs.uc.edu/~paw/lab/theses.html
Root-URL: 
Title: A Framework for Performance Evaluation of Parallel Discrete Event Simulators.  by  
Author: Vijay Balakrishnan 
Degree: A thesis submitted to the  in partial fulfillment of the requirements for the degree of MASTER OF SCIENCE in the Department of Electrical and Computer Engineering and Computer Science of the College of Engineering  Bachelor of Engineering, Birla Institute of Technology, Mesra, Ranchi, India 1993 Thesis Advisor and Committee Chair: Dr. Philip A. Wilsey  
Date: March, 1997  
Note: 27th  
Affiliation: Division of Graduate Studies and Research of the University of Cincinnati  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Abrams, M. </author> <title> The object library for parallel simulation OLPS. </title> <booktitle> In Proceedings of the 1988 Winter Simulation Conference (1988), </booktitle> <pages> pp. 210-217. </pages>
Reference-contexts: This is done by writing code (e.g., C++) to create instances of the classes and calling various methods associated with these classes. This approach is taken by Marc Abrams in his CPS [2] methodology which is implemented using OLPS <ref> [1] </ref>. CPS uses a single representation to generate executables for different DES algorithms. Likewise Sim++ [48] uses a similar approach. Warped [57,58], a Time Warp simulation kernel, provides an environment where a simulation model can be written by deriving instances of the the classes defined by it.
Reference: [2] <author> Abrams, M. </author> <title> A Common Programming Structure for Bryant-Chandy-Misra, time warp, and sequential simulators. </title> <booktitle> In Proceedings of the Winter Simulation Conference (1989), </booktitle> <pages> pp. 661-666. </pages>
Reference-contexts: This is done by writing code (e.g., C++) to create instances of the classes and calling various methods associated with these classes. This approach is taken by Marc Abrams in his CPS <ref> [2] </ref> methodology which is implemented using OLPS [1]. CPS uses a single representation to generate executables for different DES algorithms. Likewise Sim++ [48] uses a similar approach.
Reference: [3] <author> Arlitt, M. F., Chen, Y., Gurski, R., and Williamson, C. L. </author> <title> ATM-TN traffic modelling. </title> <type> Tech. rep., </type> <institution> University of Calagary, </institution> <year> 1994. </year>
Reference-contexts: The TeleSim project [83] has used parallel simulation for implementing an Asynchronous Transfer Mode (ATM) network. The models have been implemented using the Time Warp protocol. Three different traffic input traffic patters have been implemented <ref> [3, 47] </ref>. In this case the traffic patterns generated are synthetic. The ATM model [26, 39] is made up of different simulation components that represent the various physical processes in an ATM network such as traffic sources, sinks, links, end nodes and switches.
Reference: [4] <author> Avril, H., and Tropper, C. </author> <title> Clustered Time Warp and logic simulation. </title> <booktitle> In Proceedings of the 9th Workshop on Parallel and Distributed Simulation (PADS '95) (1995), </booktitle> <pages> pp. 112-119. </pages>
Reference-contexts: The only restriction here is that the circuits should be large and have enough parallelism to justify parallel simulation. Parallel simulation of logic circuits has been studied extensively <ref> [4, 8, 15] </ref> even though no particular protocol has been proved to be more useful that the other. This also makes it an candidate for use as a benchmark.
Reference: [5] <author> Ayani, R. </author> <title> Parallel simulation. </title> <booktitle> Lecture Notes in Computer Science, Performance Evaluation of Computer and Communication Systems 729 (1993), </booktitle> <pages> 1-20. </pages>
Reference-contexts: Introduction Parallel Discrete Event Simulation (PDES) kernels have been developed using conservative and optimistic approaches <ref> [5, 34, 63] </ref>. The performance of both approaches is dependent on a large number of interrelated factors. Both approaches can be implemented using a number of different protocols [50, 63] and by using a variety of algorithms [17, 20-22, 50]. <p> Misra [63] has formally stated and showed the correctness of the sequential 8 simulation algorithm. Further discussions on discrete event simulation can be found in the open literature [31]. 2.3 Parallel Discrete Event Simulation 2.3.1 Introduction One alternative to sequential simulation is distributed or parallel simulation <ref> [5, 34, 63] </ref>. A parallel simulation partitions the single sequential process into multiple processes so that they can be executed on multiprocessor machine or on a network of computers. Each process executes events concurrently with other processes.
Reference: [6] <author> Bagrodia, R., Chandy, K. M., and Toh, L. W. </author> <title> Unifying framework for distributed simulation. </title> <booktitle> ACM Transaction on Modeling and Computer Simulation 1, </booktitle> <month> 4 (October </month> <year> 1991), </year> <pages> 348-385. </pages>
Reference-contexts: This language allows one to completely specify the model by defining the various processes and their interconnections. This language was supported by the Yaddes system and allows comparison of four different simulation algorithms. Both these approaches are used to evaluate the performance of different protocols (conservative or optimistic) <ref> [6, 72] </ref>. Another approach is to develop a set of object-oriented class libraries that could be used to write simulation models. This is done by writing code (e.g., C++) to create instances of the classes and calling various methods associated with these classes.
Reference: [7] <author> Bagrodia, R. L., and Liao, W. T. Maisie: </author> <title> A language and optimizing environment for distributed simulation. </title> <booktitle> In Proceedings of the SCS Multiconference on Distributed Simulation (1990), </booktitle> <pages> pp. 205-210. </pages>
Reference-contexts: This prevents us from using the same simulation models to compare the performance of the application on different 22 environments. With a view to developing a simple workload representation language we examined several discrete event simulation languages. The Maise programming environment <ref> [7] </ref> and Yaddes Specification Language [73] can be used only on the environments for which they are built. The main purpose of Maise was to enable writing of simulation models so that they can be simulated using different synchronization algorithms that the system supports.
Reference: [8] <author> Bailey, M. L., Briner, Jr., J. V., and Chamberlain, R. D. </author> <title> Parallel logic simulation of VLSI systems. </title> <journal> ACM Computing Surveys 26, </journal> <month> 3 (Sept. </month> <year> 1994), </year> <pages> 255-294. </pages>
Reference-contexts: Examples of such systems are weather forecasting, VLSI design, and communication networks. It is in these situations where simulation has helped investigators understand the behavior of the system, and predict its performance <ref> [8, 39] </ref>. Simulation can also be used to test models before they are actually built. The growing availability of affordable multiprocessor computers and network of computers has turned attention to parallel and distributed simulation [34, 63]. <p> The only restriction here is that the circuits should be large and have enough parallelism to justify parallel simulation. Parallel simulation of logic circuits has been studied extensively <ref> [4, 8, 15] </ref> even though no particular protocol has been proved to be more useful that the other. This also makes it an candidate for use as a benchmark. <p> This also makes it an candidate for use as a benchmark. Another reason why logic simulation can used used as a benchmark is because of the growing sizes of VLSI circuits that make it a good candidate for parallel simulation. Bailey's survey <ref> [8] </ref> has identified five parameters that affect the parallel simulation of logic circuits. These five parameters are the synchronization algorithm, circuit structure, timing granularity, the target architecture and partioning. These parameters not just basic to logic simulation but literally any parallel simulation model has equivalence to these five factors.
Reference: [9] <author> Barriga, L., Brorsson, M., and Ayani, R. </author> <title> A model for parallel simulation of distributed shared memory. </title> <booktitle> In The Proceedings of MASCOTS '96 (February 1996), </booktitle> <pages> pp. 179-184. </pages>
Reference-contexts: Popular simulations have been of the memory subsystems such as cache memories [43, 55]. The Wisconsin Wind Tunnel project [77] uses conservative techniques for parallel simulation of shared memory multiprocessor. Barriga provides a model for parallel simulation of distributed shared memory <ref> [9] </ref>. Even though some of these experiments have reported speedups on parallel simulation they do not necessarily become candidates for use as benchmarks. To be used as benchmarks they should have designs that are easily implementable on any platform.
Reference: [10] <author> Barriga, L., Ronngren, R., and Ayani, R. </author> <title> Benchmarking parallel simulation algorithms. </title> <booktitle> In Proc. of the IEEE 1st Intl. Conf. on Algorithms and Architectures for Parallel Processing (1995), </booktitle> <pages> pp. 611-620. </pages>
Reference-contexts: This work provides the PDES community with a mechanism to actually characterize the change in behavior of the simulator when a particular optimization is done or when a new algorithm is implemented. There have been numerous attempts to develop benchmarks for PDES systems <ref> [10, 11, 23, 27, 35, 36, 46, 68, 74] </ref>. <p> By varying each of the above parameters, the model can be used to study the effect of these parameters on speedup and efficiency. This is a very useful model to do performance analysis on a new implementation or a new optimization. Barriga, Ronngren and Ayani <ref> [10] </ref> developed three Ping models to measure latencies on a Time Warp system. Each of these models have well defined communication pattern and they are created to stress specific overheads. The first model is called the Self-Ping model. Every simulation object in the Selfping model sends messages only to itself.
Reference: [11] <author> Beckman, B., et al. </author> <title> Distributed simulation and Time Warp Part 1: </title> <booktitle> Design of colliding pucks. In Distributed Simulation 1988 (1988), Society for Computer Simulation. </booktitle>
Reference-contexts: This work provides the PDES community with a mechanism to actually characterize the change in behavior of the simulator when a particular optimization is done or when a new algorithm is implemented. There have been numerous attempts to develop benchmarks for PDES systems <ref> [10, 11, 23, 27, 35, 36, 46, 68, 74] </ref>. <p> These include: (i) the sharks world model [23], (ii) ISCAS'89 benchmarks [18] and (iii) Colliding Pucks <ref> [11, 46] </ref>. * Chapter 11 presents the performance results for models generated and developed using the system. <p> As in the sharks world, this model also limited connectivity and a fixed topology. 4.3.8 Scientific Application Colliding pucks developed by Beckman et al <ref> [11, 46] </ref> represents the motion of circular elastic bodies on a two dimensional surface. There are two approaches to model pucks. Modeling the pucks as simulation objects leads to high message complexity while modeling the table creates a sequential bottleneck.
Reference: [12] <author> Bellenot, S. </author> <title> Global virtual time algorithms. In Distributed Simulation (January 1990), </title> <booktitle> Society for Computer Simulation, </booktitle> <pages> pp. 122-127. </pages>
Reference-contexts: This process is called fossil collection. The frequency of GVT calculation affects performance of the simulation. Doing it too often slows down the simulation and doing it too rarely causes the memory to build up. The algorithm used <ref> [12, 56, 59] </ref> also determines the overhead of calculating the GVT.
Reference: [13] <author> Boyd, E. L., and Davidson, E. S. </author> <title> Communication in the KSR1 MPP: Performance evaluation using synthetic workload experiments. </title> <booktitle> In Proc. of the 1994 Intl. Conference on Supercomputing (1994), </booktitle> <pages> pp. 166-175. 89 </pages>
Reference-contexts: Any performance analysis method should take care of all the above factors so that the comparisons can be fair and performance estimate more accurate. 3.1.1 Synthetic Benchmarks Synthetic workloads (the terms workload and benchmark are used synonymously) can play an important role in the performance evaluation or measurement strategy <ref> [13, 38, 52, 64, 66, 84] </ref>. These workloads model the behavior of a real work load and affect the system being evaluated in the same manner as the real workload. <p> In the first stage, user supplied parameters such as MFLOPS rate, memory and CPU time etc are used to generate a synthetic program. In the second stage the synthetic program is run several times with varied to gather performance data. * Boyd <ref> [13] </ref> investigates communication latency and the amount of communication using a synthetic workload. A few basic parameters, such as number of processors, the ratio of computation to communication, degree of sharing of individual data, are captured in a automatically produced synthetic workload.
Reference: [14] <author> Brglez, F., Bryan, D., and Kozminski, K. </author> <title> Combinational profiles of sequential benchmark circuits. </title> <booktitle> In ISCAS'89 (1989), </booktitle> <pages> pp. 1929-1934. </pages>
Reference-contexts: The granularity of each process is very small and with the explosion in the size of digital circuits the distributed or parallel simulation becomes 63 an attractive option. The ISCAS'89 benchmark <ref> [14, 18] </ref> suite have been widely used for studies on digital circuits. All the ISCAS'89 circuits have been represented in the WSL. No intelligent partitioning has been done but as pointed out earlier the WSL description provides a framework for doing the partioning by changing the processor assignment and re-translating.
Reference: [15] <author> Briner Jr., J. </author> <title> Fast Parallel Simulation of Digital Systems. </title> <booktitle> In Proceedings of the SCS Multiconference on Advances in Parallel and Distributed Simulation (1991), </booktitle> <pages> pp. 71-77. </pages>
Reference-contexts: The only restriction here is that the circuits should be large and have enough parallelism to justify parallel simulation. Parallel simulation of logic circuits has been studied extensively <ref> [4, 8, 15] </ref> even though no particular protocol has been proved to be more useful that the other. This also makes it an candidate for use as a benchmark.
Reference: [16] <author> Brown, R. </author> <title> Calendar queues: A fast O(1) priority queue implementation for the simulation event set problem. </title> <journal> Communications of the ACM 31, </journal> <month> 10 (October </month> <year> 1988), </year> <pages> 1220-1227. </pages>
Reference: [17] <author> Bryant, R. E. </author> <title> Simulation on a distributed system. </title> <booktitle> In Proc. of the 16th Design Automation Conference (1979), </booktitle> <pages> pp. 544-552. </pages>
Reference-contexts: The performance of both approaches is dependent on a large number of interrelated factors. Both approaches can be implemented using a number of different protocols [50, 63] and by using a variety of algorithms <ref> [17, 20-22, 50] </ref>. Furthermore, various parts of the kernel can use different algorithms for accomplishing the same task. For example different algorithms can be used to implement how memory is allocated and de-allocated [88] and there are many ways to manage the event queues [16,81]. <p> In this work we will discuss the distributed event-list scenario even though most of the work regarding benchmarking 9 and performance evaluation will also be applicable to the central event-list implementations. There are two flavors to the distributed event-list approach, namely: (i) conservative <ref> [17, 20] </ref> and (ii) optimistic [34, 50]. The following paragraphs describes the Logical Process approach to DES and describes some of the terms associated with DES. The conservative and optimistic methods are described the the following sections. <p> Depending on method used to enforce the local causality constraint, there are two protocols used for distributed simulation. The first is the conservative protocol and the second is the optimistic protocol. 2.3.2 Conservative Methods Conservative mechanisms <ref> [17, 20] </ref> strictly avoid any causality errors, i.e., the event is not processed until the LP is sure that no event in the past (with a timestamp less than the one to be processed) will arrive at that LP.
Reference: [18] <institution> CAD Benchmarking Lab , NCSU. </institution> <note> ISCAS'89 and '85 Benchmark Information. (available at http://www.cbl.ncsu.edu/www/CBL Docs/). </note>
Reference-contexts: These include: (i) the sharks world model [23], (ii) ISCAS'89 benchmarks <ref> [18] </ref> and (iii) Colliding Pucks [11, 46]. * Chapter 11 presents the performance results for models generated and developed using the system. <p> The granularity of each process is very small and with the explosion in the size of digital circuits the distributed or parallel simulation becomes 63 an attractive option. The ISCAS'89 benchmark <ref> [14, 18] </ref> suite have been widely used for studies on digital circuits. All the ISCAS'89 circuits have been represented in the WSL. No intelligent partitioning has been done but as pointed out earlier the WSL description provides a framework for doing the partioning by changing the processor assignment and re-translating.
Reference: [19] <author> Calzarossa, M., and Serazzi, G. </author> <title> Workload characterization: A survey. </title> <booktitle> In Proceedings of the IEEE (August 1993), </booktitle> <volume> vol. 81, </volume> <pages> pp. 1136-1150. </pages>
Reference-contexts: Fer--rari and Serrazi [28, 29] and Calzarossa <ref> [19] </ref> have identified the process and techniques of workload characterization. The process involves an analysis of the workload and modeling the static and dynamic behavior of the real load. Calzarossa [19] also identifies the basic parameters for a parallel system that are similar to the ones presented in this work (Chapter <p> Fer--rari and Serrazi [28, 29] and Calzarossa <ref> [19] </ref> have identified the process and techniques of workload characterization. The process involves an analysis of the workload and modeling the static and dynamic behavior of the real load. Calzarossa [19] also identifies the basic parameters for a parallel system that are similar to the ones presented in this work (Chapter 5). Performance evaluation of a system is generally done at two levels. The first is to determine the performance (timing) under normal operating conditions.
Reference: [20] <author> Chandy, K. M., and Misra, J. </author> <title> Distributed simulation: A case study in design and verification of distributed programs. </title> <journal> IEEE Transactions on Software Engineering 5, </journal> <month> 5 (September </month> <year> 1979), </year> <pages> 440-452. </pages>
Reference-contexts: In this work we will discuss the distributed event-list scenario even though most of the work regarding benchmarking 9 and performance evaluation will also be applicable to the central event-list implementations. There are two flavors to the distributed event-list approach, namely: (i) conservative <ref> [17, 20] </ref> and (ii) optimistic [34, 50]. The following paragraphs describes the Logical Process approach to DES and describes some of the terms associated with DES. The conservative and optimistic methods are described the the following sections. <p> Depending on method used to enforce the local causality constraint, there are two protocols used for distributed simulation. The first is the conservative protocol and the second is the optimistic protocol. 2.3.2 Conservative Methods Conservative mechanisms <ref> [17, 20] </ref> strictly avoid any causality errors, i.e., the event is not processed until the LP is sure that no event in the past (with a timestamp less than the one to be processed) will arrive at that LP. <p> This causes two major problem which are characteristic of conservative mechanisms. Memory overflow is caused due to blocking of some process and deadlocks occur because of a circular dependency between LP's waiting for events from one another. Deadlock avoidance <ref> [20] </ref> and deadlock detection and recovery [21] are two of the asynchronous mechanisms used to overcome the problem of deadlocks. Misra [63] suggests a method of totally avoiding deadlocks by using null messages. The null message is basically a dummy message used for avoiding deadlocks. <p> Lookahead is a parameter that models the expected time before the output values on a simulation object change. Lookahead <ref> [20] </ref> has been shown to be an important performance parameter for conservative PDES mechanism. The model uses topology, and service times as model parameters besides calculating lookahead. Building queuing networks is a fairly simple task and they are scalable.
Reference: [21] <author> Chandy, K. M., and Misra, J. </author> <title> Asynchronous distributed simulation via a sequence of parallel computations. </title> <journal> Communications of the ACM 24, </journal> <month> 11 (April </month> <year> 1981), </year> <pages> 198-206. </pages>
Reference-contexts: This causes two major problem which are characteristic of conservative mechanisms. Memory overflow is caused due to blocking of some process and deadlocks occur because of a circular dependency between LP's waiting for events from one another. Deadlock avoidance [20] and deadlock detection and recovery <ref> [21] </ref> are two of the asynchronous mechanisms used to overcome the problem of deadlocks. Misra [63] suggests a method of totally avoiding deadlocks by using null messages. The null message is basically a dummy message used for avoiding deadlocks.
Reference: [22] <author> Chandy, K. M., and Sherman, R. </author> <title> Space-time and simulation. </title> <booktitle> In Distributed Simulation (1989), Society for Computer Simulation, </booktitle> <pages> pp. 53-57. </pages>
Reference: [23] <author> Conklin, D., Cleary, J., and Unger, B. </author> <title> The sharks world: (A study in distributed simulation design). </title> <booktitle> In Distributed Simulation (1990), SCS Simulation Series, </booktitle> <pages> pp. 157-160. </pages>
Reference-contexts: This work provides the PDES community with a mechanism to actually characterize the change in behavior of the simulator when a particular optimization is done or when a new algorithm is implemented. There have been numerous attempts to develop benchmarks for PDES systems <ref> [10, 11, 23, 27, 35, 36, 46, 68, 74] </ref>. <p> These include: (i) the sharks world model <ref> [23] </ref>, (ii) ISCAS'89 benchmarks [18] and (iii) Colliding Pucks [11, 46]. * Chapter 11 presents the performance results for models generated and developed using the system. <p> The lack of information on the exact behavior of a battlefield simulation is the main argument against building battlefield models for use as a benchmark. 4.3.7 Models Representing the Natural World The Sharks World model has been used by Conklin et al <ref> [23] </ref> and Presley et al [75] to benchmark discrete event simulation. The model divides the physical ocean up into different sectors. The creatures, sharks and fishes, move through these sectors. When the fish is within attacking range of a shark it is consumed by the shark. <p> The model divides the physical ocean up into different sectors. The creatures, sharks and fishes, move through these sectors. When the fish is within attacking range of a shark it is consumed by the shark. Different implementations for the modeling of the sharks world exist. Conklinat al <ref> [23] </ref> model sectors with overlapping whereas Presleyat al [75] have no overlapping sectors. The model, in general has the following advantages. It is easily scalable in terms of number of fishes, sharks, and number of sectors that affects memory requirements and system complexity. <p> The design of both these benchmarks and their performance is discussed in the following sections. 9.1 Sharks World The sharks world model has been implemented on the WARPED [57, 58] kernel as described by Conklin et al <ref> [23] </ref>. The model is a highly simplified version of the real world and as such is more synthetic than "real" but it has been proven to be a useful benchmark for PDES. The sharks and fishes move in straight lines on a flat two dimensional space.
Reference: [24] <author> Curnow, H. J., and Wichmann, B. A. </author> <title> A synthetic benchmark. </title> <journal> Computer Journal 19(1) (1976), </journal> <pages> 43-49. </pages>
Reference-contexts: The benchmark should be easy to use and be representative of the kind of applications that are used on the system being evaluated. Currently, there is no benchmark available for evaluating PDES systems that has all these properties. Computer performance comparisons have been done using benchmarks such as Whetstone <ref> [24] </ref>, Drystone [86] and more recently using benchmarks suites like SPEC [25]. For a complete discussion of these please refer to [41, 85]. The major lesson learned from the history of benchmarking is the fact that benchmark results must be carefully analyzed.
Reference: [25] <author> Dixit, K. SPECulations. </author> <booktitle> Parallel Computing 17 (1991), </booktitle> <pages> 1195-1209. </pages>
Reference-contexts: Currently, there is no benchmark available for evaluating PDES systems that has all these properties. Computer performance comparisons have been done using benchmarks such as Whetstone [24], Drystone [86] and more recently using benchmarks suites like SPEC <ref> [25] </ref>. For a complete discussion of these please refer to [41, 85]. The major lesson learned from the history of benchmarking is the fact that benchmark results must be carefully analyzed.
Reference: [26] <author> Dobosiewicz, W., and Gburzynski., P. </author> <title> Modeling ATM networks: a case study. </title> <booktitle> In Proceedings of MASCOTS'95 (January 1995), </booktitle> <pages> pp. 263-266. </pages>
Reference-contexts: The TeleSim project [83] has used parallel simulation for implementing an Asynchronous Transfer Mode (ATM) network. The models have been implemented using the Time Warp protocol. Three different traffic input traffic patters have been implemented [3, 47]. In this case the traffic patterns generated are synthetic. The ATM model <ref> [26, 39] </ref> is made up of different simulation components that represent the various physical processes in an ATM network such as traffic sources, sinks, links, end nodes and switches.
Reference: [27] <author> Ebling, M., Di Loreto, M., Presley, M., Wieland, F., and Jefferson, D. </author> <title> An Ant foraging model implemented on the Time Warp operating system. </title> <booktitle> In Distributed Simulation (1989), SCS Simulation Series, </booktitle> <pages> pp. 21-26. </pages>
Reference-contexts: This work provides the PDES community with a mechanism to actually characterize the change in behavior of the simulator when a particular optimization is done or when a new algorithm is implemented. There have been numerous attempts to develop benchmarks for PDES systems <ref> [10, 11, 23, 27, 35, 36, 46, 68, 74] </ref>. <p> This model has limited connectivity and a 28 fixed topology. Another model that partitions the physical world into sectors is the ant foraging model developed by Ebling et al <ref> [27] </ref>. The simulation environment consists of hexagons. These hexagons are used to simulate the ground on which the ants walk. Basic action of the ants is to go foraging for food which is distributed on the a fixed size grid segment containing a fixed number of hexagons.
Reference: [28] <author> Ferrari, D. </author> <title> Computer Systems Performance Evaluation. </title> <publisher> Prentice Hall, </publisher> <year> 1978. </year>
Reference-contexts: Synthetic workloads are usually constructed from a set 16 of parameters that are identified after workload characterization of the system being evaluated. The essential properties that any synthetic workload must satisfy have been identified by Fer-rari <ref> [28] </ref>. These properties must be met if any useful measurements using synthetic workloads are to be made. These properties are: * representativeness, * flexibility, * simplicity of construction, * compactness, * low usage costs, * system independence, * reproducibility, and * compatibility. <p> Fer--rari and Serrazi <ref> [28, 29] </ref> and Calzarossa [19] have identified the process and techniques of workload characterization. The process involves an analysis of the workload and modeling the static and dynamic behavior of the real load.
Reference: [29] <author> Ferrari, D., Serazzi, G., and Zeigner, A. </author> <title> Measurement and Tuning of Computer Systems. </title> <publisher> Prentice-Hall, </publisher> <year> 1983. </year>
Reference-contexts: These test workloads are used to measure performance criteria and to compare different systems and are referred to as benchmarks. As described by Jain [49] and Ferrari <ref> [29] </ref> the test workloads can be of two types: real workloads and synthetic workloads. Real workloads are basically the actual programs that will be used on the system under test. This generally considered to be the ideal approach, but it is sometimes unrealistic. <p> Fer--rari and Serrazi <ref> [28, 29] </ref> and Calzarossa [19] have identified the process and techniques of workload characterization. The process involves an analysis of the workload and modeling the static and dynamic behavior of the real load.
Reference: [30] <author> Ferscha, A., and Johnson, J. </author> <title> A testbed for parallel simulation performance predictions. </title> <booktitle> In 1996 Winter Simulation Conference Proceedings (December 1996). </booktitle>
Reference-contexts: This study definitely does not model many known parameters such as memory requirement. These parameters are important and their effect on the performance must not be overlooked. This study considered the Time Warp algorithm only and ignored many important factors. Ferscha <ref> [30] </ref> has developed a tool for performance prediction of Time Warp protocols and several of its optimizations. A Time Warp model can be built incrementally and decisions regarding different optimizations can be made early in the development stage.
Reference: [31] <author> Fishman, G. S. </author> <title> Principles of Discrete Event Simulation. </title> <publisher> John Wiley and Sons Inc., </publisher> <year> 1978. </year> <month> 90 </month>
Reference-contexts: Processing these events in some arbitrary order would give rise to inconsistencies in the simulation. Misra [63] has formally stated and showed the correctness of the sequential 8 simulation algorithm. Further discussions on discrete event simulation can be found in the open literature <ref> [31] </ref>. 2.3 Parallel Discrete Event Simulation 2.3.1 Introduction One alternative to sequential simulation is distributed or parallel simulation [5, 34, 63]. A parallel simulation partitions the single sequential process into multiple processes so that they can be executed on multiprocessor machine or on a network of computers.
Reference: [32] <author> Fleischmann, J., and Wilsey, P. A. </author> <title> Comparative analysis of periodic state saving tech-niques in time warp simulators. </title> <booktitle> In Proc. of the 9th Workshop on Parallel and Distributed Simulation (PADS 95) (June 1995), </booktitle> <pages> pp. 50-58. </pages>
Reference-contexts: The algorithm used [12, 56, 59] also determines the overhead of calculating the GVT. Some of the major concerns in Time Warp simulators are: * the costs involved in saving the state and event histories <ref> [32] </ref>. * the implementation of the event-list structure. * higher memory requirements as compared to sequential and conservative techniques. Since optimistic simulators force the maximum possible lookahead by aggressively processing events they can potentially give better performance in-spite of the above concerns.
Reference: [33] <author> Fujimoto, R. </author> <title> Performance measurements of distributed simulation strategies. </title> <type> Tech. Rep. </type> <institution> UU-CS-TR-87-026a, University Of Utah, </institution> <address> Salt Lake City, </address> <month> November </month> <year> 1987. </year>
Reference-contexts: Building queuing networks is a fairly simple task and they are scalable. The drawback is that the built in event generators (generally based on random number generators) may not be representative of any real model. PHOLD (Parallel HOLD) [36] is a parallel version of the HOLD <ref> [33] </ref> model used for evaluating the performance of event list implementations. The simulation model as described by Fujimoto [36] consists of a fully connected graph. As workload parameters the model includes, number of LPs, message population, time stamp increment function, movement function, computation grain and initial configuration.
Reference: [34] <author> Fujimoto, R. </author> <title> Parallel discrete event simulation. </title> <journal> Communications of the ACM 33, </journal> <month> 10 (October </month> <year> 1990), </year> <pages> 30-53. </pages>
Reference-contexts: Introduction Parallel Discrete Event Simulation (PDES) kernels have been developed using conservative and optimistic approaches <ref> [5, 34, 63] </ref>. The performance of both approaches is dependent on a large number of interrelated factors. Both approaches can be implemented using a number of different protocols [50, 63] and by using a variety of algorithms [17, 20-22, 50]. <p> Simulation can also be used to test models before they are actually built. The growing availability of affordable multiprocessor computers and network of computers has turned attention to parallel and distributed simulation <ref> [34, 63] </ref>. Considerable performance improvement is possible by partioning the simulation into different simulation objects and exploiting the potential parallelism. Over the years there has been two methodologies for simulation, the first referred as continuous time and the other discrete time. <p> Misra [63] has formally stated and showed the correctness of the sequential 8 simulation algorithm. Further discussions on discrete event simulation can be found in the open literature [31]. 2.3 Parallel Discrete Event Simulation 2.3.1 Introduction One alternative to sequential simulation is distributed or parallel simulation <ref> [5, 34, 63] </ref>. A parallel simulation partitions the single sequential process into multiple processes so that they can be executed on multiprocessor machine or on a network of computers. Each process executes events concurrently with other processes. <p> In this work we will discuss the distributed event-list scenario even though most of the work regarding benchmarking 9 and performance evaluation will also be applicable to the central event-list implementations. There are two flavors to the distributed event-list approach, namely: (i) conservative [17, 20] and (ii) optimistic <ref> [34, 50] </ref>. The following paragraphs describes the Logical Process approach to DES and describes some of the terms associated with DES. The conservative and optimistic methods are described the the following sections. The physical system being simulated is decomposed into a number of interacting physical processes. <p> The clock maintains the local virtual time (LVT) that indicates the simulation time up to which the simulation has progressed for that LP. The simulation can be guaranteed to proceed correctly if the events are processed in a strictly non-decreasing time-stamp order <ref> [34, 50, 54] </ref>. This constraint for correctness is called the Local Causality Constraint. This is a sufficient, though not always a necessary condition, that no causality violation will occur.
Reference: [35] <author> Fujimoto, R. </author> <title> Parallel and distributed discrete event simulation: </title> <booktitle> Algorithms and applications. In Proc. of the 1993 Winter Simulation Conference (1993), </booktitle> <pages> pp. 106-114. </pages>
Reference-contexts: The benchmark suite also helps to evaluate the suitability of discrete event simulation methodology for simulating specific problems. Several synthetic and real problems have been used as benchmarks to evaluate the performance of parallel simulation algorithms <ref> [35] </ref>. The application programs give us an indication of performance under real workloads, the synthetic workloads explore the performance space of the simulator in a systematic and controlled fashion. An integrated benchmark suite provides a common set of models that can be used for comparative analysis. <p> This work provides the PDES community with a mechanism to actually characterize the change in behavior of the simulator when a particular optimization is done or when a new algorithm is implemented. There have been numerous attempts to develop benchmarks for PDES systems <ref> [10, 11, 23, 27, 35, 36, 46, 68, 74] </ref>.
Reference: [36] <author> Fujimoto, R. </author> <title> Performance of Time Warp under synthetic workloads. </title> <booktitle> In Proc. of the SCS Multiconference on Distributed Simulation (90), SCS, </booktitle> <pages> pp. 23-28. </pages>
Reference-contexts: This work provides the PDES community with a mechanism to actually characterize the change in behavior of the simulator when a particular optimization is done or when a new algorithm is implemented. There have been numerous attempts to develop benchmarks for PDES systems <ref> [10, 11, 23, 27, 35, 36, 46, 68, 74] </ref>. <p> Building queuing networks is a fairly simple task and they are scalable. The drawback is that the built in event generators (generally based on random number generators) may not be representative of any real model. PHOLD (Parallel HOLD) <ref> [36] </ref> is a parallel version of the HOLD [33] model used for evaluating the performance of event list implementations. The simulation model as described by Fujimoto [36] consists of a fully connected graph. <p> PHOLD (Parallel HOLD) <ref> [36] </ref> is a parallel version of the HOLD [33] model used for evaluating the performance of event list implementations. The simulation model as described by Fujimoto [36] consists of a fully connected graph. As workload parameters the model includes, number of LPs, message population, time stamp increment function, movement function, computation grain and initial configuration. Both functions are statistical distributions that incorporate lookahead. <p> The event probabilities affect the event population and vice versa. The causality factor is also captured by this parameter. Event Delay: Every event in a simulation environment has an associated time stamp. Time stamps are necessary because they carry the simulation time of the event <ref> [36] </ref>. The event delay specifies the difference between the time of generation and the time of simulation of the event. This can be a dynamic value (changing with the communication behavior) or a constant. The delays along with the partitioning determine the number of rollback's in a optimistic system.
Reference: [37] <author> Gafni, A. </author> <title> Rollback mechanisms for optimistic distributed simulation systems. In Distributed Simulation (January 1988), </title> <booktitle> Society for Computer Simulation, </booktitle> <pages> pp. 61-67. </pages>
Reference-contexts: Furthermore, the receiving LP sends anti-messages to undo the effect of the messages with time-stamps greater than the straggler that it has already sent out. Undoing the effects of the previously sent messages is referred to as cancelation. There are two primary cancelation mechanisms lazy cancelation and aggressive cancelation <ref> [37] </ref>. Since 12 13 the rollback process is often the bottleneck in the optimistic simulation it is no surprise that the cancelation mechanism used can provide significant performance improvements. The simulation needs to keep track of the global virtual time (GVT) i.e., the minimum value of LVT in the simulation.
Reference: [38] <author> Ganger, G. R. </author> <title> Generating representative synthetic workloads | an unsolved problem. </title> <booktitle> In Proc. of the Computer Measurement Group Conference (December 1995), </booktitle> <pages> pp. 1263-1269. </pages>
Reference-contexts: Any performance analysis method should take care of all the above factors so that the comparisons can be fair and performance estimate more accurate. 3.1.1 Synthetic Benchmarks Synthetic workloads (the terms workload and benchmark are used synonymously) can play an important role in the performance evaluation or measurement strategy <ref> [13, 38, 52, 64, 66, 84] </ref>. These workloads model the behavior of a real work load and affect the system being evaluated in the same manner as the real workload. <p> These properties must be met if any useful measurements using synthetic workloads are to be made. These properties are: * representativeness, * flexibility, * simplicity of construction, * compactness, * low usage costs, * system independence, * reproducibility, and * compatibility. Representativeness <ref> [38] </ref> is perhaps the most important property since it reflects how accurately the synthetic workload matches the structure and behavior of the real workload. This is a difficult property to satisfy and is generally done using qualitative discussion rather than quantitative analysis. <p> A few basic parameters, such as number of processors, the ratio of computation to communication, degree of sharing of individual data, are captured in a automatically produced synthetic workload. This system has been used to evaluate communication performance of massively parallel processors such as the KSR1 [82]. * Ganger <ref> [38] </ref> uses synthetic workloads to evaluate the performance of storage subsystems. First set of statistics are collected by from a real system. These statistics are then fed into a trace synthesis tool that produces synthetic disk traces.
Reference: [39] <author> Gburzynski, P., Ono-Tesfaye, T., and Ramaswamy, S. </author> <title> Modelling ATM networks in a parallel simulation environment: A case study. </title> <booktitle> In Proceedings of the SCSC'95 (July 1994), </booktitle> <pages> pp. 869-874. </pages>
Reference-contexts: Examples of such systems are weather forecasting, VLSI design, and communication networks. It is in these situations where simulation has helped investigators understand the behavior of the system, and predict its performance <ref> [8, 39] </ref>. Simulation can also be used to test models before they are actually built. The growing availability of affordable multiprocessor computers and network of computers has turned attention to parallel and distributed simulation [34, 63]. <p> The TeleSim project [83] has used parallel simulation for implementing an Asynchronous Transfer Mode (ATM) network. The models have been implemented using the Time Warp protocol. Three different traffic input traffic patters have been implemented [3, 47]. In this case the traffic patterns generated are synthetic. The ATM model <ref> [26, 39] </ref> is made up of different simulation components that represent the various physical processes in an ATM network such as traffic sources, sinks, links, end nodes and switches.
Reference: [40] <author> Gilmer Jr, J. B. </author> <title> An assessment of Time Warp parallel discrete event simulation algorithm performance. </title> <booktitle> In Distribute Simulation (1988), SCS Simulation Series, </booktitle> <pages> pp. 45-49. </pages>
Reference-contexts: Therefore one cannot compare simulators developed by two different groups and is forced to use the mechanisms provided by SPECTRUM. The work presented in this thesis also uses these parameters. The difference is that the simulation models are built from the parameters that have been quantified. 21 John Gilmer <ref> [40] </ref> also identified some parameters that were used to build a simulation model. The parameters modeled include: * message destination, * message latency, * message period, and * messages by a process to itself. This study definitely does not model many known parameters such as memory requirement.
Reference: [41] <author> Grace, R. </author> <title> The Benchmark Book. </title> <publisher> Prentice Hall, </publisher> <year> 1996. </year>
Reference-contexts: Currently, there is no benchmark available for evaluating PDES systems that has all these properties. Computer performance comparisons have been done using benchmarks such as Whetstone [24], Drystone [86] and more recently using benchmarks suites like SPEC [25]. For a complete discussion of these please refer to <ref> [41, 85] </ref>. The major lesson learned from the history of benchmarking is the fact that benchmark results must be carefully analyzed. Comparison of the benchmark result can only be done after completely understanding what the benchmark does and what its limitations are.
Reference: [42] <author> Hao, F., Wilson, K., Fujimoto, R., and Zegura, E. </author> <title> Logical process size in parallel simulation. </title> <booktitle> In Proceedings of the 1996 Winter Simulation Conference (1996). </booktitle>
Reference-contexts: It influences all of the above parameters. Some simulators may fold multiple physical processes of low granularity to achieve better performance [60]. The number of physical processes whose behavior is unique also affects compile time. The logical process size is reported to affect efficiency and performance <ref> [42] </ref>. The size would be directly related to the number of physical processes and the number of logical processes. 34 Event Causality: This is a difficult attribute to define. It describes a relationship between the input event sequence and the resulting events on the output channels.
Reference: [43] <author> Heidelberger, P., and Stone, H. S. </author> <title> Parallel trace-driven cache simulation by time partitioning. </title> <booktitle> In Winter Simulation Conference (December 1990), </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 734-737. </pages>
Reference-contexts: Here the logical process models the CPU or memory systems. Popular simulations have been of the memory subsystems such as cache memories <ref> [43, 55] </ref>. The Wisconsin Wind Tunnel project [77] uses conservative techniques for parallel simulation of shared memory multiprocessor. Barriga provides a model for parallel simulation of distributed shared memory [9].
Reference: [44] <author> Hockney, R., and Berry, M. </author> <title> Public international benchmarks for parallel computers, </title> <type> PARKBENCH Committee Report 1. Tech. rep., </type> <institution> PARKBENCH COMMITTEE, </institution> <year> 1994. </year>
Reference-contexts: Workloads described in the language are then compiled by the synthetic workload generator (SWG) to produce a an executable workload. * Waser [84] argues against the use of huge sets of real-world applications (such as <ref> [44, 51] </ref>) for representing the workload. Instead he suggests building a synthetic load by modeling different classes of parallel algorithms.
Reference: [45] <author> Hockney, R. W. </author> <title> Parameterization of computer performance. </title> <booktitle> Parallel Computing 5 (1987), </booktitle> <pages> 97-103. </pages>
Reference-contexts: The objective is to reduce the value of N p so that efficiency is as close to unity as possible. Ef f iciency = (N t N p )=N t (10.7) There have been other innovative metrics such as synchronization overhead, communication overhead, and incremental-efficiency <ref> [45, 89] </ref> used by the general parallel processing community. Use of these metrics for PDES might be useful because they can be used to avoid reporting of lengthy tables of data and graphs. <p> Some new graph generation routines can be added which represent topologies such as a computer network. 2. Translators for other environments need to be built. This essential to the acceptance of the system. 3. Innovative performance metrics like synchronization-overhead and incremental-efficiency <ref> [45] </ref> can be defined which account for the influence of more factors. Support for automatically measuring these metrics can be embedded in the synthetic workload generated. 87 4. The benchmark suite needs additional benchmarks from other application domains e.g., com- puter networks, manufacturing systems, and so on. 88
Reference: [46] <author> Hontallas, P., et al. </author> <title> Performance of colliding pucks simulation on the Time Warp operating system. </title> <booktitle> In Distributed Simulation (1989), Society of Computer Simulation, </booktitle> <pages> pp. 3-7. </pages> <note> [47] itt, </note> <author> M. F. A., and Williamson, C. L. </author> <title> Synthetic workload model for internet Mosiac traffic. </title> <booktitle> In Proceedings of the SCSC'95 (1995), </booktitle> <pages> pp. 852-857. </pages>
Reference-contexts: This work provides the PDES community with a mechanism to actually characterize the change in behavior of the simulator when a particular optimization is done or when a new algorithm is implemented. There have been numerous attempts to develop benchmarks for PDES systems <ref> [10, 11, 23, 27, 35, 36, 46, 68, 74] </ref>. <p> These include: (i) the sharks world model [23], (ii) ISCAS'89 benchmarks [18] and (iii) Colliding Pucks <ref> [11, 46] </ref>. * Chapter 11 presents the performance results for models generated and developed using the system. <p> As in the sharks world, this model also limited connectivity and a fixed topology. 4.3.8 Scientific Application Colliding pucks developed by Beckman et al <ref> [11, 46] </ref> represents the motion of circular elastic bodies on a two dimensional surface. There are two approaches to model pucks. Modeling the pucks as simulation objects leads to high message complexity while modeling the table creates a sequential bottleneck.
Reference: [48] <institution> JADE Simulations International Corporation. SIM++: A Discrete-Event Simulation Language, </institution> <year> 1989. </year> <month> 91 </month>
Reference-contexts: This approach is taken by Marc Abrams in his CPS [2] methodology which is implemented using OLPS [1]. CPS uses a single representation to generate executables for different DES algorithms. Likewise Sim++ <ref> [48] </ref> uses a similar approach. Warped [57,58], a Time Warp simulation kernel, provides an environment where a simulation model can be written by deriving instances of the the classes defined by it. The user models the simulation as a set of simulation objects.
Reference: [49] <author> Jain, R. </author> <title> The Art of Computer Systems Performance Analysis. </title> <publisher> John Wiley and Sons Inc., </publisher> <year> 1991. </year>
Reference-contexts: These test workloads are used to measure performance criteria and to compare different systems and are referred to as benchmarks. As described by Jain <ref> [49] </ref> and Ferrari [29] the test workloads can be of two types: real workloads and synthetic workloads. Real workloads are basically the actual programs that will be used on the system under test. This generally considered to be the ideal approach, but it is sometimes unrealistic. <p> A standard method of calculating and presenting the results is an important part of the overall performance evaluation process. What may be finally presented need not be in the same format but all the information in the template must be considered essential. As Jain <ref> [49] </ref> points out the reason for performance evaluation is the need to make some kind of desicion based on the result. If the results presented do not convey what they are supposed to, a wrong desicion could result.
Reference: [50] <author> Jefferson, D. </author> <title> Virtual time. </title> <journal> ACM Transactions on Programming Languages and Systems 7, </journal> <month> 3 (July </month> <year> 1985), </year> <pages> 405-425. </pages>
Reference-contexts: Introduction Parallel Discrete Event Simulation (PDES) kernels have been developed using conservative and optimistic approaches [5, 34, 63]. The performance of both approaches is dependent on a large number of interrelated factors. Both approaches can be implemented using a number of different protocols <ref> [50, 63] </ref> and by using a variety of algorithms [17, 20-22, 50]. Furthermore, various parts of the kernel can use different algorithms for accomplishing the same task. <p> The performance of both approaches is dependent on a large number of interrelated factors. Both approaches can be implemented using a number of different protocols [50, 63] and by using a variety of algorithms <ref> [17, 20-22, 50] </ref>. Furthermore, various parts of the kernel can use different algorithms for accomplishing the same task. For example different algorithms can be used to implement how memory is allocated and de-allocated [88] and there are many ways to manage the event queues [16,81]. <p> In this work we will discuss the distributed event-list scenario even though most of the work regarding benchmarking 9 and performance evaluation will also be applicable to the central event-list implementations. There are two flavors to the distributed event-list approach, namely: (i) conservative [17, 20] and (ii) optimistic <ref> [34, 50] </ref>. The following paragraphs describes the Logical Process approach to DES and describes some of the terms associated with DES. The conservative and optimistic methods are described the the following sections. The physical system being simulated is decomposed into a number of interacting physical processes. <p> The clock maintains the local virtual time (LVT) that indicates the simulation time up to which the simulation has progressed for that LP. The simulation can be guaranteed to proceed correctly if the events are processed in a strictly non-decreasing time-stamp order <ref> [34, 50, 54] </ref>. This constraint for correctness is called the Local Causality Constraint. This is a sufficient, though not always a necessary condition, that no causality violation will occur. <p> Therefore, these mechanism need not determine if it is safe to process an event instead they process events as they occur and recovery mechanism is invoked if a causality error detected. One of the most popular optimistic mechanism is Time Warp <ref> [50] </ref>. It is based on the principle of Virtual Time introduced by Jefferson [50]. This mechanism consists of asynchronously operating LP's communicating through timestamped event messages (Figure 2.1). <p> One of the most popular optimistic mechanism is Time Warp <ref> [50] </ref>. It is based on the principle of Virtual Time introduced by Jefferson [50]. This mechanism consists of asynchronously operating LP's communicating through timestamped event messages (Figure 2.1). Time Warp allows an LP to proceed with the execution of events in its input queue without waiting for any kind of synchronization mechanism.
Reference: [51] <author> Kipp, L. </author> <title> Perfect benchmarks documentation suite 1. </title> <type> Tech. rep., </type> <institution> Board of trustees of the University of Illinois, </institution> <year> 1993. </year>
Reference-contexts: Workloads described in the language are then compiled by the synthetic workload generator (SWG) to produce a an executable workload. * Waser [84] argues against the use of huge sets of real-world applications (such as <ref> [44, 51] </ref>) for representing the workload. Instead he suggests building a synthetic load by modeling different classes of parallel algorithms.
Reference: [52] <author> Kiskis, D. L. </author> <title> Generation of Synthetic Workloads for Distributed Real-Time Computing Systems. </title> <type> PhD thesis, </type> <institution> University of Michigan, </institution> <year> 1992. </year>
Reference-contexts: Any performance analysis method should take care of all the above factors so that the comparisons can be fair and performance estimate more accurate. 3.1.1 Synthetic Benchmarks Synthetic workloads (the terms workload and benchmark are used synonymously) can play an important role in the performance evaluation or measurement strategy <ref> [13, 38, 52, 64, 66, 84] </ref>. These workloads model the behavior of a real work load and affect the system being evaluated in the same manner as the real workload. <p> synthetic workload since it is parameterized and therefore any set of workload characteristics that are being studied can be varied and the effect measured. 3.1.2 Previous Work on Synthetic Workloads The early work related to building and using synthetic workloads for performance evaluation of computer systems are summarized by Kiskis <ref> [52] </ref>. Whetstone and Dhrystone are perhaps the first widely used synthetic benchmarks are used purely for benchmarking purposes. Some of the recent work using synthetic workloads are summarized below. * Kiskis [52] uses a synthetic workload model to benchmark real-time computing systems. <p> early work related to building and using synthetic workloads for performance evaluation of computer systems are summarized by Kiskis <ref> [52] </ref>. Whetstone and Dhrystone are perhaps the first widely used synthetic benchmarks are used purely for benchmarking purposes. Some of the recent work using synthetic workloads are summarized below. * Kiskis [52] uses a synthetic workload model to benchmark real-time computing systems. His system allows the capture of the workload using a language called synthetic workload specification language [53].
Reference: [53] <author> Kiskis, D. L., and Shin, K. G. SWSL: </author> <title> A synthetic workload specification language for real time systems. </title> <journal> In IEEE Transactions on Software Engineering (October 1994), </journal> <volume> vol. </volume> <month> 20(10), </month> <pages> pp. 798-811. </pages>
Reference-contexts: Some of the recent work using synthetic workloads are summarized below. * Kiskis [52] uses a synthetic workload model to benchmark real-time computing systems. His system allows the capture of the workload using a language called synthetic workload specification language <ref> [53] </ref>. Workloads described in the language are then compiled by the synthetic workload generator (SWG) to produce a an executable workload. * Waser [84] argues against the use of huge sets of real-world applications (such as [44, 51]) for representing the workload.
Reference: [54] <author> Lamport, L. </author> <title> Time, clocks, and the ordering of events in a distributed system. </title> <journal> Communications of ACM (July 1978), </journal> <pages> 558-565. </pages>
Reference-contexts: The clock maintains the local virtual time (LVT) that indicates the simulation time up to which the simulation has progressed for that LP. The simulation can be guaranteed to proceed correctly if the events are processed in a strictly non-decreasing time-stamp order <ref> [34, 50, 54] </ref>. This constraint for correctness is called the Local Causality Constraint. This is a sufficient, though not always a necessary condition, that no causality violation will occur.
Reference: [55] <author> Lin, Y., Baer, J., E., and Lazowska. </author> <title> Tailoring a parallel trace-driven simulation technique to specific multiprocessor cache coherence protocols. </title> <booktitle> In Proceedings of the SCS Multiconference on Distributed Simulation 1989 (1989), </booktitle> <pages> pp. 185-190. </pages>
Reference-contexts: Here the logical process models the CPU or memory systems. Popular simulations have been of the memory subsystems such as cache memories <ref> [43, 55] </ref>. The Wisconsin Wind Tunnel project [77] uses conservative techniques for parallel simulation of shared memory multiprocessor. Barriga provides a model for parallel simulation of distributed shared memory [9].
Reference: [56] <author> Lin, Y.-B., and Lazowska, E. </author> <title> Determining the global virtual time in a distributed simulation. </title> <booktitle> In 1990 International Conference on Parallel Processing (1990), </booktitle> <pages> pp. </pages> <month> III-201-III-209. </month>
Reference-contexts: This process is called fossil collection. The frequency of GVT calculation affects performance of the simulation. Doing it too often slows down the simulation and doing it too rarely causes the memory to build up. The algorithm used <ref> [12, 56, 59] </ref> also determines the overhead of calculating the GVT.
Reference: [57] <author> Martin, D. E., McBrayer, T., and Wilsey, P. A. </author> <title> warped: A Time Warp simulation kernel for analysis and application development, </title> <note> 1995. (available on the www at http://www.ece.uc.edu/~paw/warped/). </note>
Reference-contexts: An example is presented and described. * Chapter 7 introduces the Synthetic Workload Generator (SWG). The SWG inputs a param eterized characterization of a model and which produces synthetic workloads in WSL. * Chapter 8 describes the WSL parser/translator. The translator described here targets the Warped <ref> [57, 58] </ref> simulation kernel. 5 * Chapter 9 describes a method to report performance results so that the results can be pre- sented in a uniform way. * Chapter 10 describes some of the real models which have been built using the WSL framework for WARPED. <p> One representation can be provided for each defined environment and the translator selects the required representation and converts it to a executable (or a high level language). The translator currently available for the language allows representation of Warped <ref> [57, 58] </ref> models. Figure 6.3 provides a feel for how native language code can be inserted into the WSL description. Refer to Appendix A for a complete grammar of the language. <p> The net-list is read into the NetList structure and checked for inconsistencies. The net-list can then translated to any desired format and printed out to appropriate files. The current implementation of PublishClass is called PublishWarped, the interface to convert the WSL descriptions to the C++ interface provided in Warped <ref> [57, 58] </ref>. 8.2 Description of the Translator Interface The parser calls predefined methods in the PublishClass to achieve translation. This enables writing translators for other environments. The two sets of functions available in the PublishClass are discussed in the following paragraphs. <p> The Sharks World and simulation of the ISCAS'89 digital circuit benchmarks were represented in WSL. The design of both these benchmarks and their performance is discussed in the following sections. 9.1 Sharks World The sharks world model has been implemented on the WARPED <ref> [57, 58] </ref> kernel as described by Conklin et al [23]. The model is a highly simplified version of the real world and as such is more synthetic than "real" but it has been proven to be a useful benchmark for PDES.
Reference: [58] <author> Martin, D. E., McBrayer, T. J., and Wilsey, P. A. </author> <title> warped: A time warp simulation kernel for analysis and application development. </title> <booktitle> In 29th Hawaii International Conference on System Sciences (HICSS-29) (January 1996). </booktitle> <publisher> (forthcoming). </publisher>
Reference-contexts: An example is presented and described. * Chapter 7 introduces the Synthetic Workload Generator (SWG). The SWG inputs a param eterized characterization of a model and which produces synthetic workloads in WSL. * Chapter 8 describes the WSL parser/translator. The translator described here targets the Warped <ref> [57, 58] </ref> simulation kernel. 5 * Chapter 9 describes a method to report performance results so that the results can be pre- sented in a uniform way. * Chapter 10 describes some of the real models which have been built using the WSL framework for WARPED. <p> One representation can be provided for each defined environment and the translator selects the required representation and converts it to a executable (or a high level language). The translator currently available for the language allows representation of Warped <ref> [57, 58] </ref> models. Figure 6.3 provides a feel for how native language code can be inserted into the WSL description. Refer to Appendix A for a complete grammar of the language. <p> The net-list is read into the NetList structure and checked for inconsistencies. The net-list can then translated to any desired format and printed out to appropriate files. The current implementation of PublishClass is called PublishWarped, the interface to convert the WSL descriptions to the C++ interface provided in Warped <ref> [57, 58] </ref>. 8.2 Description of the Translator Interface The parser calls predefined methods in the PublishClass to achieve translation. This enables writing translators for other environments. The two sets of functions available in the PublishClass are discussed in the following paragraphs. <p> The Sharks World and simulation of the ISCAS'89 digital circuit benchmarks were represented in WSL. The design of both these benchmarks and their performance is discussed in the following sections. 9.1 Sharks World The sharks world model has been implemented on the WARPED <ref> [57, 58] </ref> kernel as described by Conklin et al [23]. The model is a highly simplified version of the real world and as such is more synthetic than "real" but it has been proven to be a useful benchmark for PDES.
Reference: [59] <author> Mattern, F. </author> <title> Effecient algorithms for distributed snapshots and global virtual time approximation. </title> <journal> Journal of Parallel and Distributed Computing 18, </journal> <month> 4 (August </month> <year> 1993), </year> <pages> 423-434. </pages>
Reference-contexts: This process is called fossil collection. The frequency of GVT calculation affects performance of the simulation. Doing it too often slows down the simulation and doing it too rarely causes the memory to build up. The algorithm used <ref> [12, 56, 59] </ref> also determines the overhead of calculating the GVT.
Reference: [60] <author> McBrayer, T., and Wilsey, P. A. </author> <title> Process combination to increase event granularity in parallel logic simulation. </title> <booktitle> In 9th International Parallel Processing Symposium (April 1995), </booktitle> <pages> pp. 572-578. </pages>
Reference-contexts: Number of Physical Processes: A physical process is the basic unit of which the model is composed. The number of physical processes an important performance parameter. It influences all of the above parameters. Some simulators may fold multiple physical processes of low granularity to achieve better performance <ref> [60] </ref>. The number of physical processes whose behavior is unique also affects compile time. The logical process size is reported to affect efficiency and performance [42].
Reference: [61] <author> Mehlhorn, K., N aher, S., and Uhrig, C. </author> <title> The LEDA User Manual Version R 3.4.1, </title> <year> 1996. </year>
Reference-contexts: The final workload description is constructed from the outputs of the two generators (Figure 7.1). The graph generator is built using LEDA <ref> [61] </ref> (Library of Efficient Data types and Algorithms). This library has been implemented as a C++ class library and can be used with almost any C++ compiler that supports templates. This library provides a data-type graph with associated graph manipulation functionalities. <p> These loops allow easy traversal of the graph structure. It allows addition, deletion of nodes and edges and offers arrays and matrices indexed by nodes and edges. A full description of all the features is available in the LEDA Users Manual <ref> [61] </ref>. These functions can be used to write any graph construction routines which can be incorporated easily into the workload generator. Another feature of LEDA is the class GraphWin. This can be used to display and edit the graph which has been constructed.
Reference: [62] <author> Merrifield, B. C., Richardson, S. B., and Roberts, J. B. G. </author> <title> Quantitative studies of discrete event simulation modelling of road traffic. </title> <booktitle> In Proceedings of the SCS Multiconference on Distributed Simulation (1990), </booktitle> <pages> pp. 188-193. </pages>
Reference-contexts: But obtaining such a model and translating it to work on other environments would be a challenging task. 27 4.3.5 Business, Transportation and Manufacturing Systems Parallel simulation of a road transportation network has been studied before <ref> [62] </ref>. Manufacturing application models (e.g., [67]) are stable and have predictable behavior and make good candidates for a benchmark. They can also have dynamic behavior if the model includes processes coming online at different times of the day.
Reference: [63] <author> Misra, J. </author> <title> Distributed discrete-event simulation. </title> <journal> Computing Surveys 18, </journal> <month> 1 (March </month> <year> 1986), </year> <pages> 39-65. </pages>
Reference-contexts: Introduction Parallel Discrete Event Simulation (PDES) kernels have been developed using conservative and optimistic approaches <ref> [5, 34, 63] </ref>. The performance of both approaches is dependent on a large number of interrelated factors. Both approaches can be implemented using a number of different protocols [50, 63] and by using a variety of algorithms [17, 20-22, 50]. <p> Introduction Parallel Discrete Event Simulation (PDES) kernels have been developed using conservative and optimistic approaches [5, 34, 63]. The performance of both approaches is dependent on a large number of interrelated factors. Both approaches can be implemented using a number of different protocols <ref> [50, 63] </ref> and by using a variety of algorithms [17, 20-22, 50]. Furthermore, various parts of the kernel can use different algorithms for accomplishing the same task. <p> Simulation can also be used to test models before they are actually built. The growing availability of affordable multiprocessor computers and network of computers has turned attention to parallel and distributed simulation <ref> [34, 63] </ref>. Considerable performance improvement is possible by partioning the simulation into different simulation objects and exploiting the potential parallelism. Over the years there has been two methodologies for simulation, the first referred as continuous time and the other discrete time. <p> Another problem with sequential simulation has to do with events scheduled at the same time. Processing these events in some arbitrary order would give rise to inconsistencies in the simulation. Misra <ref> [63] </ref> has formally stated and showed the correctness of the sequential 8 simulation algorithm. Further discussions on discrete event simulation can be found in the open literature [31]. 2.3 Parallel Discrete Event Simulation 2.3.1 Introduction One alternative to sequential simulation is distributed or parallel simulation [5, 34, 63]. <p> Misra [63] has formally stated and showed the correctness of the sequential 8 simulation algorithm. Further discussions on discrete event simulation can be found in the open literature [31]. 2.3 Parallel Discrete Event Simulation 2.3.1 Introduction One alternative to sequential simulation is distributed or parallel simulation <ref> [5, 34, 63] </ref>. A parallel simulation partitions the single sequential process into multiple processes so that they can be executed on multiprocessor machine or on a network of computers. Each process executes events concurrently with other processes. <p> Memory overflow is caused due to blocking of some process and deadlocks occur because of a circular dependency between LP's waiting for events from one another. Deadlock avoidance [20] and deadlock detection and recovery [21] are two of the asynchronous mechanisms used to overcome the problem of deadlocks. Misra <ref> [63] </ref> suggests a method of totally avoiding deadlocks by using null messages. The null message is basically a dummy message used for avoiding deadlocks. The null message is used to announce the absence of messages upto time-stamp of the null message itself. <p> The second solution to deadlock is to allow the system to deadlock and then recover from it. Among the methods used to do this is the circulating marker <ref> [63] </ref> scheme. A marker continuously circulates among the LPs and checks to see if the LP has progressed in its last visit. This is done by marking a flag in the LPs. The marker detects a deadlock if finds that the last N LP's it visited have not progressed.
Reference: [64] <author> Nagel, W. E., and Linn, M. A. </author> <title> Benchmarking parallel programs in a multiprogramming environment: </title> <booktitle> The PAR-bench system. Parallel Computing 17 (1991), </booktitle> <pages> 1303-1321. 92 </pages>
Reference-contexts: Any performance analysis method should take care of all the above factors so that the comparisons can be fair and performance estimate more accurate. 3.1.1 Synthetic Benchmarks Synthetic workloads (the terms workload and benchmark are used synonymously) can play an important role in the performance evaluation or measurement strategy <ref> [13, 38, 52, 64, 66, 84] </ref>. These workloads model the behavior of a real work load and affect the system being evaluated in the same manner as the real workload. <p> Instead he suggests building a synthetic load by modeling different classes of parallel algorithms. The results of his work are available as the ParStone'93 benchmark suite. 18 * Nagel <ref> [64] </ref> describes a synthetic workload generator for parallel programs in a multiprogram-ming environment that is organized into two stages. In the first stage, user supplied parameters such as MFLOPS rate, memory and CPU time etc are used to generate a synthetic program.
Reference: [65] <author> Nance, R. E. </author> <title> A history of discrete event simulation programming languages. </title> <booktitle> In ACM SIGPLAN HOPL-II. 2nd ACM SIGPLAN History of Programming Languages Conference (Preprints) (New York, </booktitle> <address> NY, USA, </address> <month> March </month> <year> 1993), </year> <title> vol. 28(3), </title> <publisher> ACM Press, </publisher> <pages> pp. 149-175. </pages>
Reference-contexts: This type of language was developed by OverStreet and Nance [69]. This language was basically used to represent the model specification and has to be translated to any 23 other simulation language so that it can be executed. Discrete Event Simulation programming languages abound in literature <ref> [65] </ref> but they are generally unsuitable for performance evaluation of the simulation kernel. All these languages are useful in the context in which they are developed. When it comes to performance analysis of discrete event system they either prove inadequate or difficult to use.
Reference: [66] <author> Nanda, A., and Ni, L. M. </author> <title> Benchmark workload generation and performance characterization of multiprocessors. </title> <booktitle> In Proceedings of the IEEE conference on Super computing (1992), </booktitle> <pages> pp. 4-13. </pages>
Reference-contexts: Any performance analysis method should take care of all the above factors so that the comparisons can be fair and performance estimate more accurate. 3.1.1 Synthetic Benchmarks Synthetic workloads (the terms workload and benchmark are used synonymously) can play an important role in the performance evaluation or measurement strategy <ref> [13, 38, 52, 64, 66, 84] </ref>. These workloads model the behavior of a real work load and affect the system being evaluated in the same manner as the real workload. <p> First set of statistics are collected by from a real system. These statistics are then fed into a trace synthesis tool that produces synthetic disk traces. Many synthetic traces can be collected since these are synthetically generated by using statistical methods. * Nanda and Linonel Li <ref> [66] </ref> use synthetic workloads for evaluating the performance of shared memory multiprocessors. Using the same approach described by Ferrari they do workload characterization of the system under test, in their case a general purpose shared memory multiprocessor.
Reference: [67] <author> Nevison, C. </author> <title> Parallel simulation of manufacturing systems: Structural factors. </title> <booktitle> In Proceedings of the SCS Multiconference on Distributed Simualtion (1990), </booktitle> <pages> pp. 17-19. </pages>
Reference-contexts: But obtaining such a model and translating it to work on other environments would be a challenging task. 27 4.3.5 Business, Transportation and Manufacturing Systems Parallel simulation of a road transportation network has been studied before [62]. Manufacturing application models (e.g., <ref> [67] </ref>) are stable and have predictable behavior and make good candidates for a benchmark. They can also have dynamic behavior if the model includes processes coming online at different times of the day.
Reference: [68] <author> Nicol, D. M. </author> <title> Parallel discrete event simulation of FCFS stocastic queuing networks. </title> <booktitle> In Proc. of ACM SIGPLAN Symposium on Parallel Programming (September 1988), </booktitle> <volume> vol. 23(9), </volume> <pages> pp. 124-137. </pages>
Reference-contexts: This work provides the PDES community with a mechanism to actually characterize the change in behavior of the simulator when a particular optimization is done or when a new algorithm is implemented. There have been numerous attempts to develop benchmarks for PDES systems <ref> [10, 11, 23, 27, 35, 36, 46, 68, 74] </ref>. <p> Nicol <ref> [68] </ref> uses the properties of Queuing networks to develop a protocol that uses simulation specific information to compute lookahead, that gives much better performance than a protocol that does not use this information. <p> For example providing a larger number of processors does not always lead to increased performance because of increased communication costs between processors. Another method of improving performance are protocols that make use of the application behavior <ref> [68] </ref>. In these cases it is not possible to isolate one layer to evaluate performance. The performance of the protocols used depends on the algorithms and implementation of the different subsystems. Figure 5.2 shows some of these factors.
Reference: [69] <author> Overstreet, C. M., and Nance, R. E. </author> <title> A specification language to assist in analysis of discrete event simulation models. </title> <journal> Communications of the ACM 28, </journal> <month> 2 (Feb. </month> <year> 1985), </year> <pages> 190-201. </pages>
Reference-contexts: This specification could be tested for some types of errors and completeness before being translated to the executable form. This type of language was developed by OverStreet and Nance <ref> [69] </ref>. This language was basically used to represent the model specification and has to be translated to any 23 other simulation language so that it can be executed. Discrete Event Simulation programming languages abound in literature [65] but they are generally unsuitable for performance evaluation of the simulation kernel.
Reference: [70] <author> Palaniswamy, A., and Wilsey, P. A. </author> <title> Adaptive checkpoint intervals in an optimistically synchronized parallel digital system simulator. </title> <booktitle> In VLSI 93 (September 1993), </booktitle> <pages> pp. 353-362. </pages>
Reference-contexts: The performance of the protocols used depends on the algorithms and implementation of the different subsystems. Figure 5.2 shows some of these factors. Dynamic parameter adjustment refers to dynamic load balancing, dynamic cancelation [76], adaptive check-pointing <ref> [70, 80] </ref> and so on. 31 5.2 Workload Characterization The performance of any system is highly sensitive to the workload used. The workload exercises the system, produces resource demands and a specific execution behavior. This section characterizes DES workloads in terms of a few performance parameters.
Reference: [71] <author> Parr, T. J. </author> <title> Language Translation Using PCCTS and C++. A Reference Guide. </title> <publisher> Automata Publishing Company, </publisher> <year> 1996. </year>
Reference-contexts: The translator has been built using PCCTS (Purdue Compiler Construction Tool Set) <ref> [71] </ref>.
Reference: [72] <author> Preiss, B., Loucks, W., and Hamacher, V. </author> <title> A Unified Modeling Methodology for Performance Evaluation of Distributed Discrete Event Simulation Mechanism. </title> <booktitle> In In Proc. 1988 Winter Simulation Conference (1988), </booktitle> <pages> pp. 315-324. </pages>
Reference-contexts: This language allows one to completely specify the model by defining the various processes and their interconnections. This language was supported by the Yaddes system and allows comparison of four different simulation algorithms. Both these approaches are used to evaluate the performance of different protocols (conservative or optimistic) <ref> [6, 72] </ref>. Another approach is to develop a set of object-oriented class libraries that could be used to write simulation models. This is done by writing code (e.g., C++) to create instances of the classes and calling various methods associated with these classes. <p> All these languages are useful in the context in which they are developed. When it comes to performance analysis of discrete event system they either prove inadequate or difficult to use. The Yaddes language has been used for performance evaluation <ref> [72] </ref> but its drawback is that it can be used on the Yaddes system only. 4.3 Benchmarks This section describes some of the applications that have been built using the DES paradigm. The use of these applications as benchmarks is examined.
Reference: [73] <author> Preiss, B. R. </author> <title> The Yaddes distributed discrete event simulation specification language and execution environments. </title> <booktitle> In Proc. SCS Multiconf. on Distributed Simulation (1989), </booktitle> <pages> pp. 139-144. </pages>
Reference-contexts: This prevents us from using the same simulation models to compare the performance of the application on different 22 environments. With a view to developing a simple workload representation language we examined several discrete event simulation languages. The Maise programming environment [7] and Yaddes Specification Language <ref> [73] </ref> can be used only on the environments for which they are built. The main purpose of Maise was to enable writing of simulation models so that they can be simulated using different synchronization algorithms that the system supports.
Reference: [74] <author> Presley, M., Ebling, M., Wieland, F., and Jefferson, D. </author> <title> Benchmarking the Time Warp Operating System with a computer network simulation. </title> <booktitle> In Distributed Simulation (1989), Society for Computer Simulation, </booktitle> <pages> pp. 8-13. </pages>
Reference-contexts: This work provides the PDES community with a mechanism to actually characterize the change in behavior of the simulator when a particular optimization is done or when a new algorithm is implemented. There have been numerous attempts to develop benchmarks for PDES systems <ref> [10, 11, 23, 27, 35, 36, 46, 68, 74] </ref>. <p> Presley et al <ref> [74] </ref> used Warp-net that can simulate many network topologies. This model abstracts the underlying LP connectivity and message population to the network. This is one of the few exist 26 ing models which model topology as a parameter.
Reference: [75] <author> Presley, M. T., Reiher, P. L., and Bellenot, S. F. </author> <title> A Time Warp implementation of sharks world. </title> <booktitle> In Proceedings of the Winter Simulation Conference (1990), </booktitle> <pages> pp. 199-203. </pages>
Reference-contexts: The lack of information on the exact behavior of a battlefield simulation is the main argument against building battlefield models for use as a benchmark. 4.3.7 Models Representing the Natural World The Sharks World model has been used by Conklin et al [23] and Presley et al <ref> [75] </ref> to benchmark discrete event simulation. The model divides the physical ocean up into different sectors. The creatures, sharks and fishes, move through these sectors. When the fish is within attacking range of a shark it is consumed by the shark. <p> The creatures, sharks and fishes, move through these sectors. When the fish is within attacking range of a shark it is consumed by the shark. Different implementations for the modeling of the sharks world exist. Conklinat al [23] model sectors with overlapping whereas Presleyat al <ref> [75] </ref> have no overlapping sectors. The model, in general has the following advantages. It is easily scalable in terms of number of fishes, sharks, and number of sectors that affects memory requirements and system complexity. The model was developed because of its simplicity and potential parallelism.
Reference: [76] <author> Rajan, R., and Wilsey, P. A. </author> <title> Dynamically switching between lazy and aggressive cancellation in a Time Warp parallel simulator. </title> <booktitle> In Proc. of the 28th Annual Simulation Symposium (April 1995), </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 22-30. </pages>
Reference-contexts: In these cases it is not possible to isolate one layer to evaluate performance. The performance of the protocols used depends on the algorithms and implementation of the different subsystems. Figure 5.2 shows some of these factors. Dynamic parameter adjustment refers to dynamic load balancing, dynamic cancelation <ref> [76] </ref>, adaptive check-pointing [70, 80] and so on. 31 5.2 Workload Characterization The performance of any system is highly sensitive to the workload used. The workload exercises the system, produces resource demands and a specific execution behavior. This section characterizes DES workloads in terms of a few performance parameters.
Reference: [77] <author> Reinhardt, S. K., Hill, M. D., Larus, J. R., Lebeck, A. R., Lewis, J. C., and Wood, D. A. </author> <title> The Wisconsin Wind Tunnel: Virtual prototyping of parallel computers. </title> <booktitle> In Proceedings of the ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems (New York, </booktitle> <address> NY, USA, </address> <month> May </month> <year> 1993), </year> <editor> B. D. Gaither, Ed., </editor> <title> vol. 21-1 of Performance Evaluation Review, </title> <publisher> ACM Press, </publisher> <pages> pp. 48-60. </pages>
Reference-contexts: Here the logical process models the CPU or memory systems. Popular simulations have been of the memory subsystems such as cache memories [43, 55]. The Wisconsin Wind Tunnel project <ref> [77] </ref> uses conservative techniques for parallel simulation of shared memory multiprocessor. Barriga provides a model for parallel simulation of distributed shared memory [9]. Even though some of these experiments have reported speedups on parallel simulation they do not necessarily become candidates for use as benchmarks.
Reference: [78] <author> Reynolds, J. P. F. </author> <title> A spectrum of options for parallel simulation. </title> <booktitle> Proceedings 1988 Winter Simulation Conference (1989), </booktitle> <pages> 325-332. 93 </pages>
Reference-contexts: This framework should support comparison on a common basis. There have been some previous efforts to develop such a framework. One of the first attempts was by Reynolds <ref> [78] </ref>. This approach allows the experimenter to implement a particular protocol on the SPECTRUM Testbed [78, 79]. Some key application parameters were identified as affecting the protocol implementation. The testbed allowed the study of the effect of these parameters on different protocols. <p> This framework should support comparison on a common basis. There have been some previous efforts to develop such a framework. One of the first attempts was by Reynolds [78]. This approach allows the experimenter to implement a particular protocol on the SPECTRUM Testbed <ref> [78, 79] </ref>. Some key application parameters were identified as affecting the protocol implementation. The testbed allowed the study of the effect of these parameters on different protocols.
Reference: [79] <author> Reynolds Jr, P. F. </author> <title> Comparative analysis of parallel simulation protocols. </title> <booktitle> In Proc. of the 1989 Winter Simulation Conference (1989), </booktitle> <pages> pp. 671-678. </pages>
Reference-contexts: This framework should support comparison on a common basis. There have been some previous efforts to develop such a framework. One of the first attempts was by Reynolds [78]. This approach allows the experimenter to implement a particular protocol on the SPECTRUM Testbed <ref> [78, 79] </ref>. Some key application parameters were identified as affecting the protocol implementation. The testbed allowed the study of the effect of these parameters on different protocols.
Reference: [80] <author> R onngren, R., and Ayani, R. </author> <title> Adaptive checkpointing in Time Warp. </title> <booktitle> In Proc. of the 8th Workshop on Parallel and Distributed Simulation (PADS 94) (July 1994), Society for Computer Simulation, </booktitle> <pages> pp. 110-117. </pages>
Reference-contexts: The performance of the protocols used depends on the algorithms and implementation of the different subsystems. Figure 5.2 shows some of these factors. Dynamic parameter adjustment refers to dynamic load balancing, dynamic cancelation [76], adaptive check-pointing <ref> [70, 80] </ref> and so on. 31 5.2 Workload Characterization The performance of any system is highly sensitive to the workload used. The workload exercises the system, produces resource demands and a specific execution behavior. This section characterizes DES workloads in terms of a few performance parameters.
Reference: [81] <author> R onngren, R., Riboe, J., and Ayani, R. </author> <title> Lazy queue: An efficient implementation of the pending-event set. </title> <booktitle> In Proc. of the 24th Annual Simulation Symposium (April 1991), </booktitle> <pages> pp. 194-204. </pages>
Reference: [82] <author> Rosti, E., Smirni, E., Wager, T. D., Apon, A. W., and Dowdy, L. W. </author> <title> The KSR1: Experimentation and modeling of poststore. </title> <booktitle> In SIGMETRICS Conference on Performance Measurement and Modeling (May 1993), </booktitle> <pages> pp. 74-85. </pages>
Reference-contexts: A few basic parameters, such as number of processors, the ratio of computation to communication, degree of sharing of individual data, are captured in a automatically produced synthetic workload. This system has been used to evaluate communication performance of massively parallel processors such as the KSR1 <ref> [82] </ref>. * Ganger [38] uses synthetic workloads to evaluate the performance of storage subsystems. First set of statistics are collected by from a real system. These statistics are then fed into a trace synthesis tool that produces synthetic disk traces.
Reference: [83] <institution> University of Calagary. The Telesim Project- ATM Traffic and Network Simulation. </institution> <note> (available at http://www.wnet.ca/telesim/). </note>
Reference-contexts: This is perhaps one of the most important of all workload parameters in a distributed simulation. This application could be made change the topology dynamically as new computers and/or LAN are connected to the simulating network. The TeleSim project <ref> [83] </ref> has used parallel simulation for implementing an Asynchronous Transfer Mode (ATM) network. The models have been implemented using the Time Warp protocol. Three different traffic input traffic patters have been implemented [3, 47]. In this case the traffic patterns generated are synthetic.
Reference: [84] <author> Waser, S. E. </author> <title> Benchmarking Parallel Computers Using Algorithmic Classes. </title> <type> PhD thesis, </type> <institution> University of Basel, </institution> <year> 1993. </year>
Reference-contexts: Any performance analysis method should take care of all the above factors so that the comparisons can be fair and performance estimate more accurate. 3.1.1 Synthetic Benchmarks Synthetic workloads (the terms workload and benchmark are used synonymously) can play an important role in the performance evaluation or measurement strategy <ref> [13, 38, 52, 64, 66, 84] </ref>. These workloads model the behavior of a real work load and affect the system being evaluated in the same manner as the real workload. <p> His system allows the capture of the workload using a language called synthetic workload specification language [53]. Workloads described in the language are then compiled by the synthetic workload generator (SWG) to produce a an executable workload. * Waser <ref> [84] </ref> argues against the use of huge sets of real-world applications (such as [44, 51]) for representing the workload. Instead he suggests building a synthetic load by modeling different classes of parallel algorithms.
Reference: [85] <author> Weicker, R. P. </author> <title> A detailed look at some popular benchmarks. </title> <booktitle> Parallel Computing 17 (1991), </booktitle> <pages> 1153-1172. </pages>
Reference-contexts: Currently, there is no benchmark available for evaluating PDES systems that has all these properties. Computer performance comparisons have been done using benchmarks such as Whetstone [24], Drystone [86] and more recently using benchmarks suites like SPEC [25]. For a complete discussion of these please refer to <ref> [41, 85] </ref>. The major lesson learned from the history of benchmarking is the fact that benchmark results must be carefully analyzed. Comparison of the benchmark result can only be done after completely understanding what the benchmark does and what its limitations are.
Reference: [86] <author> Weicker, R. P., and Dhrystone, R. </author> <title> A synthetic systems programming benchmark. </title> <journal> In Communications of ACM (October 1984), </journal> <volume> vol. 27(10), </volume> <pages> pp. 1013-1030. </pages>
Reference-contexts: Currently, there is no benchmark available for evaluating PDES systems that has all these properties. Computer performance comparisons have been done using benchmarks such as Whetstone [24], Drystone <ref> [86] </ref> and more recently using benchmarks suites like SPEC [25]. For a complete discussion of these please refer to [41, 85]. The major lesson learned from the history of benchmarking is the fact that benchmark results must be carefully analyzed.
Reference: [87] <author> Wieland, F., et al. </author> <title> Distributed combat simulation and Time Warp: The model and its performance. </title> <booktitle> In Proceedings of the SCS Multiconference on Distributed Simulation (1989), </booktitle> <pages> pp. 14-20. </pages>
Reference-contexts: The behavior of these models is very dynamic in the sense that the event generation is never consistent. New processes are added at different times creating new patterns of communication among the processes. Weiland <ref> [87] </ref> implemented a combat simulation on Time Warp and reported a large speedup on parallel execution.
Reference: [88] <author> Wilson, P. R., Johnstone, M. S., Neely, M., and Boles, D. </author> <title> Dynamic storage allocation: A survey and critical review. </title> <booktitle> In Proceedings of the International Workshop on Memory Management (1995), </booktitle> <pages> pp. 1-113. </pages>
Reference-contexts: Furthermore, various parts of the kernel can use different algorithms for accomplishing the same task. For example different algorithms can be used to implement how memory is allocated and de-allocated <ref> [88] </ref> and there are many ways to manage the event queues [16,81]. Each of these options and their combinations affect performance of the simulator in different ways. It is important to be able to analyze the various tradeoffs with respect to the different options.
Reference: [89] <author> Worlton, J. </author> <title> Towards a taxonomy of performance metrics. </title> <booktitle> Parallel Computing 17 (1991), </booktitle> <pages> 1073-1092. </pages>
Reference-contexts: The objective is to reduce the value of N p so that efficiency is as close to unity as possible. Ef f iciency = (N t N p )=N t (10.7) There have been other innovative metrics such as synchronization overhead, communication overhead, and incremental-efficiency <ref> [45, 89] </ref> used by the general parallel processing community. Use of these metrics for PDES might be useful because they can be used to avoid reporting of lengthy tables of data and graphs.
References-found: 88

