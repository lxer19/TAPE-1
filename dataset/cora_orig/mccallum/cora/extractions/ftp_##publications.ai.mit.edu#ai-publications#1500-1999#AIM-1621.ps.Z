URL: ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1621.ps.Z
Refering-URL: http://www.ai.mit.edu/people/gideon/gideon.html
Root-URL: 
Email: gideon@ai.mit.edu  
Title: Direct Estimation of Motion and Extended Scene Structure from a Moving Stereo Rig  
Author: Gideon P. Stein Amnon Shashua 
Note: This publication can be retrieved by anonymous ftp to publications.ai.mit.edu. The pathname for this publication is: ai-publications/1500-1999/AIM-1621.ps.Z Copyright c Massachusetts Institute of Technology, 1995  
Web: http://www.cs.huji.ac.il/~ shashua/  
Address: Cambridge, MA 02139 Jerusalem 91904, Israel  
Date: 1621 December, 1998  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY  Artificial Intelligence Laboratory Institute of Computer Science MIT Hebrew University of Jerusalem  
Pubnum: A.I. Memo No.  
Abstract: We describe a new method for motion estimation and 3D reconstruction from stereo image sequences obtained by a stereo rig moving through a rigid world. We show that given two stereo pairs, one can compute the motion of the stereo rig directly from the image derivatives (spatial and temporal). Correspondences are not required. One can then use the images from both pairs combined, to compute a dense depth map. The motion estimates between stereo pairs enable us to combine depth maps from all the pairs in the sequence to form an extended scene reconstruction. We show results from a real image sequence. The motion computation is a linear least squares computation using all the pixels in the image. Areas with little or no contrast are implicitly weighted less, so one does not have to explicitly apply a confidence measure. This report describes research done at the Artificial Intelligence Laboratory of the Massachusetts Institute of Technology. Support for this research was provided in part by the Advanced Research Projects Agency of the Department of Defense under Office of Naval Research contract N00014-94-01-0994. G.S. would like acknowledge the financial support from ONR contracts N00014-94-1-0128 and DARPA contracts N00014-94-01-0994, N00014-97-0363 A.S. wishes acknowledge the financial support from US-IS Binational Science Foundation 94-00120/2, the European ACTS project AC074 "Vanguard", and from DARPA through ARL Contract DAAL01-97-0101. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. R. Bergen, P. Anandan, K. J. Hanna, and R. Hingorani. </author> <title> Hierarchical model-based motion estimation. </title> <booktitle> In Proceedings of the European Conference on Computer Vision, </booktitle> <address> Santa Margherita Ligure, Italy, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: This stabilizes regions where there is no image gradient. 5 3.3 Coarse to fine processing and iterative refinement In order to deal with image motions larger than 1 pixel we use a Gaussian pyramid for coarse to fine processing <ref> [1, 2] </ref>. For a 640 fi 480 image we used a 5 level pyramid. The linear solution can be thought of as a single iteration of Newton's method applied to the problem. At each level of the pyramid we iterate as follows: 1. Calculate motion (using equation 15). 2.
Reference: [2] <author> Peter J Burt and Edward H Adelson. </author> <title> The laplacian pyramid as a compact image code. </title> <journal> IEEE Transactions on Communications, </journal> <volume> 31 </volume> <pages> 532-540, </pages> <year> 1983. </year>
Reference-contexts: This stabilizes regions where there is no image gradient. 5 3.3 Coarse to fine processing and iterative refinement In order to deal with image motions larger than 1 pixel we use a Gaussian pyramid for coarse to fine processing <ref> [1, 2] </ref>. For a 640 fi 480 image we used a 5 level pyramid. The linear solution can be thought of as a single iteration of Newton's method applied to the problem. At each level of the pyramid we iterate as follows: 1. Calculate motion (using equation 15). 2.
Reference: [3] <author> Olivier Faugeras. </author> <title> Three Dimensional Computer Vision: a Geometric Viewpoint. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference: [4] <author> Olivier D. Faugeras and B. Mourrain. </author> <title> On the geometry and algebra of the point and line correspondences between N images. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 951-956, </pages> <address> Cambridge, MA, June 1995. </address> <publisher> IEEE Computer Society Press, IEEE Computer Society Press. </publisher>
Reference-contexts: Since the camera displacement from I 0 i to I 00 i is fixed and known (calibrated) the motion I 0 i to I 0 i+1 can be found. We have not used image I 00 i+1 . Theoretically it is not required since <ref> [4] </ref> show that there are no constraints among 4 (or more) images that are not simply 2 and 3 image constraints. But other image triplets can be used and the information combined in a least squares way.
Reference: [5] <author> Patrick Fua. </author> <title> Reconstructing complex surfaces from multiple stereo views. </title> <booktitle> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 1078-1085. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> June </month> <year> 1995. </year>
Reference-contexts: By concatenating these motion estimates one can bring all the depth maps into one coordinate frame. Combining incremental motion in this way will accumulate errors. To get a more accurate reconstruction one can use the results as a starting point for global reconstruction schemes such as <ref> [5, 6] </ref>. 1.1 Overview of the Camera Motion Estimation The 'Tensor Brightness Constraint' [15, 17] combines geometric and photometric constraints of three views. <p> The small spheres show the camera path. The large spheres show the camera positions of the four Euclidean reconstructions. 11 point we draw multiple 2 1 2 D surfaces. Better methods are described in <ref> [5] </ref>. The idea of using multiview geometric constraints to merge 3D reconstruction from a stereo sequence pair can also be applied in systems using feature correspondences.
Reference: [6] <author> Keith J. Hanna and Neil E. Okamoto. </author> <title> Combining stereo and motion analysis for direct estimation of scene structure. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <address> Berlin, Germany, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Stereo and motion together form a powerful combination <ref> [6, 20] </ref> with a variety of applications from ego motion estimation to extended scene reconstruction. We describe a new method for directly estimating the motion of the stereo rig thus greatly simplifying the process of combining the information from multiple image pairs. <p> The method is stable in the case of collinear motion, in the case of pure rotation and also for planar objects. There is no scale ambiguity since all motions are relative to the known baseline length <ref> [6] </ref>. After the motion has been found one can compute a dense depth map using information from the stereo pair and the motion (see fig. 1d). <p> By concatenating these motion estimates one can bring all the depth maps into one coordinate frame. Combining incremental motion in this way will accumulate errors. To get a more accurate reconstruction one can use the results as a starting point for global reconstruction schemes such as <ref> [5, 6] </ref>. 1.1 Overview of the Camera Motion Estimation The 'Tensor Brightness Constraint' [15, 17] combines geometric and photometric constraints of three views.
Reference: [7] <author> Berthold K.P. Horn and B.G. Schunk. </author> <title> Determining optical flow. </title> <journal> Artificial Intelligence, </journal> <volume> 17 </volume> <pages> 185-203, </pages> <year> 1981. </year>
Reference-contexts: In particular, let: S 0 = I x x 0 I x y 0 I y S 00 = I x x 00 I x y 00 I y (2) Now apply the 'optical flow constraint equation' <ref> [7] </ref>: u 0 I x + v 0 I y + I 0 where: u 0 = x x 0 to get: I y t xI x yI y S 00 = I x I 00 ! This results in the Tensor Brightness Constraint: p i s 00 j ff jk
Reference: [8] <author> B.K.P. Horn and E.J. Weldon. </author> <title> Direct methods for recovering motion. </title> <journal> International Journal of Computer Vision, </journal> <volume> 2 </volume> <pages> 51-76, </pages> <year> 1988. </year>
Reference-contexts: Thus for the first motion we get: ks &gt; t 0 + v &gt; w 0 + I 0 which first appeared in <ref> [8] </ref>.
Reference: [9] <author> M. Irani, B. Rousso, and S. Peleg. </author> <title> Recovery of ego-motion using image stabilization'. </title> <booktitle> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 454-460, </pages> <address> Seattle, Washington, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Calibration of the stereo pair is performed in two stages. First we take an image of a distant scene (the plane at infinity) and find the homography between Image 2 and Image 1 using the method described in <ref> [9] </ref>. Since the rotation angle is small we can assume an affine model rather than a full planar projective transformation. This stage takes into account both the rotation between the two cameras and also the variation in internal camera parameters.
Reference: [10] <author> T. Kanade, Okutomi, and Nakahara. </author> <title> A multiple-baseline stereo method. </title> <booktitle> In Proceedings of the ARPA Image Understanding Workshop, </booktitle> <pages> pages 409-426. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <month> January </month> <year> 1992. </year>
Reference-contexts: This can now be viewed as a multi baseline stereo system with all the advantages of such as system: it reduces aliasing, helps deal with occlusions and it extends the dynamic range of the system as detailed by <ref> [10] </ref> and others. Applying an edge detector to the depth map (fig. 1e) highlights possible areas of occlusion. In a traffic scene, for example, these are locations where a pedestrian might suddenly appear.
Reference: [11] <author> Reinhard Koch. </author> <title> 3-d surface reconstruction from stereoscopic image sequences. </title> <booktitle> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 109-114. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> June </month> <year> 1995. </year>
Reference: [12] <author> H.C. Longuet-Higgins and K. Prazdny. </author> <title> The interpretation of a moving retinal image. </title> <journal> Proceedings of the Royal Society of London B, </journal> <volume> 208 </volume> <pages> 385-397, </pages> <year> 1980. </year>
Reference-contexts: If we also use the Longuett-Higgins and Prazdny <ref> [12] </ref> small motion assumptions: t 0 w 0 f &lt;< 1 x y where f is the focal length, and w 0 x ; w 0 y are the rotations around the X and Y axes.
Reference: [13] <author> A. Shashua. </author> <title> Algebraic functions for recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 17(8) </volume> <pages> 779-789, </pages> <year> 1995. </year>
Reference-contexts: 0 and S 00 are related through the following equation: p i S 00 j ff jk where ff jk i is the 3 fi 3 fi 3 tensor representing a bilinear function of the camera matrices: ff jk i = t 0j b k i and first appeared in <ref> [13] </ref> and [14].
Reference: [14] <author> A. Shashua and M. Werman. </author> <title> Trilinearity of three perspective views and its associated tensor. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: S 00 are related through the following equation: p i S 00 j ff jk where ff jk i is the 3 fi 3 fi 3 tensor representing a bilinear function of the camera matrices: ff jk i = t 0j b k i and first appeared in [13] and <ref> [14] </ref>.
Reference: [15] <author> Amnon Shashua and Keith J. Hanna. </author> <title> The tensor brightness constraints: Direct estimation of motion revisited. </title> <type> Technical report, </type> <institution> Technion, Haifa, Israel, </institution> <month> November </month> <year> 1995. </year>
Reference-contexts: We show that given two stereo pairs one can compute the motion of the stereo rig directly from the image derivatives (spatial and temporal). Correspondences are not required. The core of the method is an application of the 'Tensor Brightness Constraint' <ref> [15, 17] </ref>, which combines geometric and photometric constraints of three views, to the case where the motion between one pair of views is known. <p> Combining incremental motion in this way will accumulate errors. To get a more accurate reconstruction one can use the results as a starting point for global reconstruction schemes such as [5, 6]. 1.1 Overview of the Camera Motion Estimation The 'Tensor Brightness Constraint' <ref> [15, 17] </ref> combines geometric and photometric constraints of three views.
Reference: [16] <author> G. Stein. </author> <title> Lens distortion calibration using point correspondences. </title> <booktitle> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> Puerto Rico, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: This does not affect the stability of the method but the accuracy of the motion estimates is reduced and the 3D reconstruction suffers non-projective distortion. Flat surfaces and straight line appear slightly curved. A variety of methods to compute lens distortion appear in the literature (see <ref> [16] </ref>). 3.2 Computing Depth To compute the depth at every point we use equations (11).
Reference: [17] <author> G. Stein and A. Shashua. </author> <title> Model based brightness constraints: On direct estimation of structure and motion. </title> <booktitle> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> Puerto Rico, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: We show that given two stereo pairs one can compute the motion of the stereo rig directly from the image derivatives (spatial and temporal). Correspondences are not required. The core of the method is an application of the 'Tensor Brightness Constraint' <ref> [15, 17] </ref>, which combines geometric and photometric constraints of three views, to the case where the motion between one pair of views is known. <p> Combining incremental motion in this way will accumulate errors. To get a more accurate reconstruction one can use the results as a starting point for global reconstruction schemes such as [5, 6]. 1.1 Overview of the Camera Motion Estimation The 'Tensor Brightness Constraint' <ref> [15, 17] </ref> combines geometric and photometric constraints of three views. <p> Section (3) describes some of the implementation details. In particular we describe a simple two step procedure to calibrate the stereo pair. Section (4.2) shows results for an extended scene reconstruction. 2 Mathematical Background 2.1 The Tensor Brightness Constraint The 'Tensor Brightness Constraint' is developed in <ref> [17] </ref>. We briefly derive it here. 1 (a) (b) (e) displaced vertically. Image (b) is the image from camera (a) taken at the next time instance. (d) the estimated depth map.. (e) shows the results of a Canny edge detector on the depth map. <p> The second stage is to find the translation between the two cameras. We move the whole stereo rig in pure translation. We then use equation (13) which gives accurate results under the assumption of pure translation <ref> [17] </ref> to compute both the translation of the rig and the displacement between the two cameras. 3.1.1 Lens Distortion Since we us are using a wide FOV lens there is noticeable lens distortion. <p> Compute a new motion and depth estimate. One cannot simply compute the incremental model from the previous iteration because as the iterations proceed the system of equations of the incremental model will become badly conditioned. We followed the procedure in <ref> [17] </ref>. At the finest level (640 fi 480) we performed 2 iterations and we recursively doubled the number of iterations at the coarser levels. We can afford to do this because the number of computations per iteration at each levels drops by a factor of 4.
Reference: [18] <author> Gideon Stein. </author> <title> Accurate internal camera calibration using rotation, with analysis of sources of error. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 230-236. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> June </month> <year> 1995. </year>
Reference-contexts: These can be found using methods described in <ref> [18] </ref>. For true Euclidean reconstruction an accurate estimate of the focal length is required but the whole process degrades gracefully when only approximate values are provided. Calibration of the stereo pair is performed in two stages.
Reference: [19] <author> Juyang Weng, Paul Cohen, and Nicolas Rebibo. </author> <title> Motion and structure estimation from stereo image sequnces. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 8(3) </volume> <pages> 362-382, </pages> <month> June </month> <year> 1992. </year>
Reference: [20] <author> Zhengyou Zhang and Olivier D. Faugeras. </author> <title> Three dimensional motion computation and segementation in a long sequnce of stereo frames. </title> <journal> International Journal of Computer Vision, </journal> <volume> 7(3) </volume> <pages> 211-241, </pages> <year> 1992. </year> <month> 12 </month>
Reference-contexts: 1 Introduction Stereo and motion together form a powerful combination <ref> [6, 20] </ref> with a variety of applications from ego motion estimation to extended scene reconstruction. We describe a new method for directly estimating the motion of the stereo rig thus greatly simplifying the process of combining the information from multiple image pairs.
References-found: 20

