URL: http://www.mli.gmu.edu/~iimam/papers/IAA96.ps
Refering-URL: http://www.mli.gmu.edu/~iimam/papers.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: email: iimam@verdi.iisd.sra.com  
Title: Adaptive Methodologies for Intelligent Agents  Machine Learning and Inference Laboratory,  
Author: Ibrahim F. Imam George Mason 
Note: Also Affiliate with the  
Address: 4300 Fair Lakes Court, FS-5 Fairfax, VA 22033  
Affiliation: SRA International  University  
Abstract: The performance of an agent depends highly on its ability to adapt its methodologies to solve different problems, or to solve the same problem in different situations. Such adaptations may (or may not) change the external behavior of the agent. This paper introduces two adaptive methodologies that utilized by intelligent agents for improving their performance. In the first methodology, the agent adapts existing knowledge-base to fit different decision making situations. The agent restructure the knowledge-base when the user requests information or a decision that can not be directly determined from the knowledge-base. The agent uses a set of cost functions and other parameters to describe different decision making situations. A simulated air-travel database is used to illustrate the adaptive methodology. The second agent generates optimized plans for object recognition. The goal of the agent is to recognize visual objects in order to conduct the appropriate actions. The agent should have many tools or classifiers, each utilizes different parameters or recognizes different characteristics of the objects. Initially, the agent generates a recognition plan. Then, it iteratively adjusts the plan until it satisfies a set of criteria that maximize the recognition rate. A set of real-world hand gesture images is used to illustrate the adaptive methodology. key words: intelligent agent, machine learning, decision tree, neural networks.
Abstract-found: 1
Intro-found: 1
Reference: <author> Baffes, P.T., and Mooney, </author> <title> R . J . , Symbolic Revision of Theories with M-of-N Rules, </title> <booktitle> Proceedings of the Second International Workshop on Multistrategy Learning, </booktitle> <pages> pp. 69-75, </pages> <address> Harpers Ferry, WV, </address> <month> May 26-29, </month> <year> 1993. </year>
Reference-contexts: can modify their knowledge-base to accomplish different tasks include: 1) systems that change the representation and the content of the knowledge (e.g., the AQDT-2 system for learning task-oriented decision structure from decision rulesMichalski & Imam, 1994); 2) systems that improve the performance of the learned knowledge without changing the representation <ref> (e.g., Baffes & Mooney, 1993) </ref>. Brodley (1993) addressed the problem of automatically selecting one or more algorithms or models from among a set of learning algorithms that will produce the best accuracy for a given task.
Reference: <author> Bloedorn, E., Wnek, J., Michalski, R.S., and Kaufman, K . , AQ17: </author> <title> A Multistrategy Learning System: The Method and Users Guide, Report of Machine Learning and Inference Labratory, </title> <institution> MLI-93-12, Center for AI, George Mason University, </institution> <year> 1993. </year> <title> Brodley, C . E . , Addressing the Selection Superiority Problem: Automatic Algorithm/Model Class Selection, </title> <booktitle> Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> pp. 17-24, </pages> <year> 1993. </year> <title> Gaines, B . , Exception DAGS as Knowledge Structures, </title> <booktitle> Proceedings of the AAAI International Workshop on Knowledge Discovery in Databases, </booktitle> <pages> pp. 13-24, </pages> <address> Seattle, WA, </address> <year> 1994. </year>
Reference-contexts: CAP acquires factual knowledge about each new attendee that appears on the calendar and uses this knowledge later to control the learned rules. Examples of other adaptive systems that optimize the representation space of a given problem include the AQ17-DCI <ref> (Bloedorn, et al, 1993) </ref>, and others (e.g., Rendell & Seshu, 1990). These approaches are very useful when the original representation space is inadequate for learning.

Reference: <author> Mitchell, M., </author> <title> Analogy-Making as Perception, </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1993. </year>
Reference-contexts: MCS uses a set of heuristic rules that describe the biases of learning algorithms and learning representations to solve the given problem. These rules represent an information guide in generating the hybrid tree. Another example is the Copycat agent <ref> (Mitchell, 1993) </ref>. Copycat was used to discover new analogies in alphabetic letter strings. Copycat consists of different agents that compete with one another to find the strongest analogy.
Reference: <author> Mitchell, T., Caruana, R., Freitag, D., McDermott, J., and Zabowski, </author> <title> D . , Experience with a Learning Personal Assistant, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 37, No. </volume> <pages> 7 , pp. 81-91, </pages> <month> July, </month> <year> 1994. </year> <title> Morik, K . , Balanced Cooperative Modeling in Machine Learning: A Multistrategy Approach Vol. IV, </title> <editor> Michalski, R.S. & Tecuci, G. </editor> <booktitle> (Eds.), </booktitle> <pages> pp. 259-318, </pages> <publisher> Morgan Kaufmann Pubs., </publisher> <address> San Francisco, CA, </address> <year> 1994. </year>
Reference-contexts: In the decision structure, nodes containing rules only represent common conditions to all of its children. Another example of an agent that has capabilities to adapt its knowledge is CAP (Calendar APprentice) <ref> (Mitchell, et al, 1994) </ref>. CAP assists the user in scheduling his/her calendar based on some background knowledge representing his/her own scheduling preferences. CAP is an intelligent agent that learns rules from a set of examples that describe previous meetings.
Reference: <author> Rendell, L., and Seshu, </author> <title> R . , Learning Hard Concept through Constructive Induction: Framework and Rationale, </title> <journal> Journal of Computational Intelligence, </journal> <volume> No. 6, </volume> <year> 1990 </year>
Reference-contexts: CAP acquires factual knowledge about each new attendee that appears on the calendar and uses this knowledge later to control the learned rules. Examples of other adaptive systems that optimize the representation space of a given problem include the AQ17-DCI (Bloedorn, et al, 1993), and others <ref> (e.g., Rendell & Seshu, 1990) </ref>. These approaches are very useful when the original representation space is inadequate for learning. AQ17-DCI, for example, searches the space of possible logical and mathematical combinations of the original attributes, then it reformulates the given database using only those attributes which improves the representation space.
References-found: 5

