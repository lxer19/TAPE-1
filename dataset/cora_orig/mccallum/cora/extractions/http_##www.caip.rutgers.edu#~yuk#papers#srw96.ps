URL: http://www.caip.rutgers.edu/~yuk/papers/srw96.ps
Refering-URL: 
Root-URL: 
Email: email: [cche, qlin, yuk]@caip.rutgers.edu  
Title: DEVELOPMENT OF CROWNS: CAIP RECOGNIZER OF WORDS 'N SENTENCES  
Author: ChiWei Che Qiguang Lin Dong-Suk Yuk 
Note: DRAFT  
Address: Piscataway, NJ 08855-1390, USA  
Affiliation: CAIP Center, Rutgers University  
Abstract: This paper describes the development/implementation of a speaker independent, large vocabulary continuous speech rec-ognizer, CROWNS. The acoustic modeling of CROWNS is based on continuous-density hidden Markov Models (HMM's), and the decoding is based on one pass frame-synchronized Viterbi search. The CROWNS system has been evaluated in the 1995 ARPA test (HUB3). In this paper, the official evaluation results, post-evaluation improvements of CROWNS, and additional recognition experiments using neural networks are also presented. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> E. Bocchieri, </author> <title> "Vector quantization for the efficient computation of continuous density likelihoods", </title> <booktitle> Proc. ICASSP 93, </booktitle> <pages> pp. 692-695, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Thirdly, macrophone may avoid creation of crossword triphone models. The disadvantage of this approach is the increase in computational time. Instead of computing one likelihood, there may be tens or hundreds of distributions to be evaluated. Several methods have been previously proposed <ref> [8, 1] </ref> for reducing Gaussian computations. They can be used to reduce the computation load. The computation can also be expedited by cashing the likelihood. Actually, we have found that the increased computational time is not severe. In Table 2, recognition performance of using macrophone and backoff monophone is compared.
Reference: 2. <author> C. Lee and J. Gauvain, </author> <title> "Speaker adaptation based on MAP estimation of HMM parameters," </title> <booktitle> Proc. </booktitle> <volume> IEEE-ICASSP 93, </volume> <pages> pp. </pages> <month> II558-II561. </month>
Reference: 3. <author> C. Lee, L. Rabiner, R. Pieraccini, J. Wilpon, </author> <title> "Acoustic Modeling for Large Vocabulary Speech Recognition", </title> <booktitle> Computer Speech and Language, </booktitle> <pages> pp 127-165, </pages> <month> April, </month> <year> 1990 </year>
Reference: 4. <author> K. Lee, </author> <title> Automatic Speech Recognition: The Development of the Sphinx System, </title> <publisher> Kluwer Academic Publisher, </publisher> <address> Boston, </address> <year> 1989. </year> <title> 75.0 65.0 55.0 45.0 Distant-Talking Additive Noise Microphone F Microphone G Mircrophone B Multi-Microphone Average Performance Gain (%) SNR (dB) method for three different environment; different micro phones (G:4dB, </title> <editor> F:12dB, B:13dB, average:9dB), distant-talking (13dB), </editor> <title> additive noise (20dB). Recognition is performed using the speech recognizer trained on clean speech. </title>
Reference-contexts: Language model and lexicon For the 1995 HUB3 evaluation, we used the language model (with 1-3 cutoff) developed at the CMU. We also used the "standard" lexicon of 60K vocabularies. 2.5. Search The search is accomplished by a frame-synchronized Viterbi algorithm. The implementation is quite similar to that in <ref> [4] </ref>. A static network of words with linear combination of the phonemes for the entire lexicon is generated with word identities being known. The incorporation of bigrams into such a network is straightforward thanks to its simple architecture.
Reference: 5. <author> Q. Lin, C. Che, B. de Vries, J. Pearson, J. Flana-gan, </author> <title> "Experiments on distant-talking speech recognition", </title> <booktitle> Proc ARPA Spoken Language Technology Workshop, </booktitle> <address> Austin, Texas, </address> <pages> pp. 187-192, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: A matched training and testing con dition is thereby approximated because most state-of-the-art speech recognition systems are designed to operate on close-talking speech. By using ARPA speech recognizers available to us, the MANN system has been evaluated on the distant-talking version of the ARPA Resource Management database <ref> [5] </ref>. The experimental results show that the MANN system is competitive to a retrained speech recognizer. <p> The additive noise experiment is performed on the ARPA Resource Management database (RM, bef0 3) after white Gaussian noise is digitally added to the speech waveform. The calculated signal-to-noise ratio (SNR) is 20 dB. The distant-talking experiment is performed on the RM distant-talking database (RMdt) <ref> [5] </ref>. The SNR of RMdt is approximately 13dB. The SNR of multi-microphone speech data is approximately 9dB on average (Mic B 13dB, Mic G 12 dB, and Mic F 4 dB). Performance is measured in terms of word recognition accuracy in Figure 2.
Reference: 6. <author> Q. Lin, C. Che, D. Yuk, J. Flanagan, </author> <title> "A microphone array and neural network system", </title> <booktitle> Proc of 15th Speech Research Symposium, </booktitle> <address> Baltimore, Maryland, </address> <pages> pp. 111-123, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Neural network compensation for dif ferent microphones We have proposed a neural network compensation method for feature adaptation to combat mismatched environments between the training and testing of a speech recognizer <ref> [6] </ref>. Fig ure 1 shows the block diagram of the neural network compensation method. Dotted lines in Figure 1 indicate the training data flow, and solid lines indicate the testing data flow. The speech recognizer is trained on clean speech.
Reference: 7. <author> R. Lippmann, </author> <title> "An introduction to computing with neural nets", </title> <journal> IEEE ASSP Magazine, </journal> <pages> pp. 4-22, </pages> <month> April </month> <year> 1987. </year>
Reference: 8. <author> H. Murveit, P. Monaco, V. Digalakis, J. Butzberger, </author> <title> "Techniques to achieve an accurate real-time large-vocabulary speech recognition system" Proc. </title> <booktitle> ARPA Human Language Technology Workshop, </booktitle> <address> Plainsboro, NJ, </address> <pages> pp. 393-398, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: Thirdly, macrophone may avoid creation of crossword triphone models. The disadvantage of this approach is the increase in computational time. Instead of computing one likelihood, there may be tens or hundreds of distributions to be evaluated. Several methods have been previously proposed <ref> [8, 1] </ref> for reducing Gaussian computations. They can be used to reduce the computation load. The computation can also be expedited by cashing the likelihood. Actually, we have found that the increased computational time is not severe. In Table 2, recognition performance of using macrophone and backoff monophone is compared.
Reference: 9. <author> Moreno, P., Raj, B., Stern, R., </author> <title> "A unified approach for robust speech recognition," </title> <booktitle> Proc. 1995 EuroSpeech, </booktitle> <address> Madrid, Spain, </address> <month> Sept. </month> <pages> 18-22, </pages> <year> 1995. </year>
Reference-contexts: The MANN system includes a component of speech enhancement by MA and a component of feature adaption by NN. We intend to incorporate another component of model adaptation to further elevate the recognition performance, especially when the signal-to-noise ratio (SNR) is low <ref> [9] </ref>. We also intend to develop a better cost function for training NN's than commonly-used mean-square-error between the NN tar get and the NN output. More specifically, recognition error of the back-end needs to be jointly considered during NN training.
Reference: 10. <author> L. Nguyen, R. Schwartz, F. Kubala, P. Placeway, </author> <title> "Search algorithm for software-only real-time recognition with very large vocabularies", </title> <booktitle> Proc. of ARPA Human Language Technology Workshop, </booktitle> <address> Princeton, NJ, </address> <pages> pp 91-95, </pages> <year> 1993. </year>
Reference-contexts: We believe that this source of error is one of the main causes for the unsatisfactory performance to be discussed below. We intend to implement and compare other search techniques, for instance, multi-pass word lattice rescoring <ref> [10, 16] </ref>, one pass with dynamic decoding [12]. 3. Results of 1995 HUB3 Evaluation This is the our first-time participation in ARPA annual evaluations. In fact, it is also the first time that the CROWNS system is bench-marked.
Reference: 11. <author> H. Ney, R. Haeb-Umbach, B. Tran, M. Oerder, </author> <title> "Improvements in beam search for 10,000 word continuous speech recognition," </title> <booktitle> Proc. ICASSP 92, </booktitle> <pages> pp I9-12, </pages> <month> March, </month> <year> 1992. </year>
Reference: 12. <author> J. Odell, V. Valtchev, P. Woodland, S. Young, </author> <title> "A one pass decoder design for large vocabulary recognition," </title> <booktitle> Proc ARPA Human Language Technology Workshop, </booktitle> <address> Plainsboro, NJ, </address> <pages> pp. 405-410, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: We believe that this source of error is one of the main causes for the unsatisfactory performance to be discussed below. We intend to implement and compare other search techniques, for instance, multi-pass word lattice rescoring [10, 16], one pass with dynamic decoding <ref> [12] </ref>. 3. Results of 1995 HUB3 Evaluation This is the our first-time participation in ARPA annual evaluations. In fact, it is also the first time that the CROWNS system is bench-marked.
Reference: 13. <author> L. Rabiner, B. Juang, S. Levinson, M. Sondhi, </author> <title> "Recognition of isolated digits using hidden Markov models with continuous mixture densities," </title> <journal> Bell Systems Tech Journal Vol. </journal> <volume> 64(6), </volume> <pages> pp. 1211-1234, </pages> <year> 1985. </year>
Reference-contexts: The present version of CROWNS does not incorporate duration models, and it does not support multiple pronunciations. 2.3. Training and tying The training of CROWNS is based on the well-known Baum-Welch forward/backward algorithm. The training procedure for a single-mixture system is well documented <ref> [13] </ref>. Similar strategies can be applied to multiple mixtures, with differences only in the number of Gaussian mixtures to be estimated.
Reference: 14. <author> S. Young, P. Woodland, </author> <title> "The use of state tying in continuous speech recognition", </title> <booktitle> Proc. EuroSpeech, </booktitle> <address> Berlin, </address> <pages> pp. 2203-2206, </pages> <year> 1993. </year>
Reference-contexts: Tying can be done either at state or model levels. In CROWNS, agglomerative tying is implemented at the state level because it provides better performance than tying at the model level <ref> [14] </ref>. The current system accommodates data-driven tying only. Other tying approaches (such as phonetic tree tying) will be included in the future. The CROWNS is trained on the WSJ0 and WSJ1 (SI284) speech databases. Gender-dependent CDHMM's are created.
Reference: 15. <author> S. Young, J. Odell, P. Woodland, </author> <title> "Tree-based state tying for high accuracy acoustic modeling," </title> <booktitle> Proc. ARPA Human Language Technology Workshop, </booktitle> <address> Plainsboro, NJ, </address> <pages> pp. 307-312, </pages> <month> March </month> <year> 1994. </year>
Reference: 16. <author> G. Zavaliagos et al, </author> <title> "Improved search, acoustic, and language modeling in the BBN Byblos large vocabulary CSR system," </title> <booktitle> Proc. ARPA Spoken Language Technology Workshop, </booktitle> <address> Plainsboro, NJ, </address> <pages> pp. 81-88, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: We believe that this source of error is one of the main causes for the unsatisfactory performance to be discussed below. We intend to implement and compare other search techniques, for instance, multi-pass word lattice rescoring <ref> [10, 16] </ref>, one pass with dynamic decoding [12]. 3. Results of 1995 HUB3 Evaluation This is the our first-time participation in ARPA annual evaluations. In fact, it is also the first time that the CROWNS system is bench-marked.
References-found: 16

