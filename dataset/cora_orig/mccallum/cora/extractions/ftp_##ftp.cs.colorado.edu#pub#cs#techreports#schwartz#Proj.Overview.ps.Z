URL: ftp://ftp.cs.colorado.edu/pub/cs/techreports/schwartz/Proj.Overview.ps.Z
Refering-URL: http://www.cs.gatech.edu/people/home/jmankoff/collab-immers-env.html
Root-URL: 
Title: Internet Resource Discovery at the University of Colorado  
Author: Michael F. Schwartz 
Keyword: General Terms: Design, Experimentation, Measurement Additional Key Words and Phrases: resource discovery, directory service, global distribution, administrative decentralization.  
Note: To appear, IEEE Computer Magazine  
Address: Boulder, Colorado 80309-0430  
Affiliation: Department of Computer Science University of Colorado  
Email: schwartz@cs.colorado.edu  
Phone: (303) 492-3902  
Date: October, 1992  
Abstract: Rapidly increasing global Internet connectivity offers tremendous opportunities for collaboration and information sharing. An important problem in this environment is how to discover resources of interest, such as documents, network services, and people. In this paper we discuss a number of aspects of the resource discovery problem, and summarize results from efforts to address these problems carried out in the Networked Resource Discovery Project at the University of Colorado. CR Categories and Subject Descriptors: C.2.4 [Computer-Communication Networks]: Distributed Systems distributed applications; H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing - indexing methods; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval retrieval models, search process, selection process; H.3.4 [Information Storage and Retrieval]: Systems and Software information networks; H.3.5 [Information Storage and Retrieval]: Online Information Services data bank sharing; H.3.6 [Information Storage and Retrieval]: Library Automation large text archives; H.4.3 [Information Systems Applications]: Communications Applications bulletin boards, electronic mail; K.4.1 [Computers And Society]: Public Policy Issues privacy. 
Abstract-found: 1
Intro-found: 1
Reference: <editor> Papers about the Networked Resource Discovery Project are available to Internet users by anonymous FTP from ftp.cs.colorado.edu, </editor> <title> in the directory pub/cs/techreports/schwartz. The files in this directory are also available via an electronic mail interface. For more information, send a mail message to infosrv@ftp.cs.colorado.edu, containing the message body (not subject line) "send HELP" (without quotes). The author of this paper can be reached by electronic mail at schwartz@cs.colorado.edu. </title>
Reference: 1. <author> V. Cerf. </author> <title> Networks. </title> <journal> Scientific American, </journal> <volume> 265(3), </volume> <pages> pp. 72-81, </pages> <month> September </month> <year> 1991. </year> <journal> Special Issue on Communications, Computers, and Networks. </journal>
Reference-contexts: Introduction The Internet is a collection of several thousand networks interconnecting millions of users at academic, industrial, and government institutions worldwide <ref> [1] </ref>. 1 As such, it offers tremendous potential for collaboration and sharing of resources, such as documents, software, data, and network services. In this environment, an increasingly important problem is how users can discover what resources are available.
Reference: 2. <author> K. Harrenstien, M. Stahl and E. Feinler. NICName/Whois. </author> <title> Request For Comments 954, </title> <booktitle> SRI International, </booktitle> <month> October </month> <year> 1985. </year>
Reference-contexts: Internet Resource Discovery Systems A number of Internet sites run centralized servers that support queries about people and other information across the Internet. One prominent example is the WHOIS service, used by Network Information Centers (NICs) and other organizations to maintain databases of registered users and network sites <ref> [2] </ref>. Because each WHOIS server collects geographically distributed information into a single database, it provides a good focal point for registrations and searches.
Reference: 3. <author> CCITT/ISO. </author> <title> The Directory, Part 1: Overview of Concepts, Models and Services. </title> <address> CCITT/ISO, Gloucester, England, </address> <month> December </month> <year> 1988. </year> <note> CCITT Draft Recommendation X.500/ISO DIS 9594-1. </note>
Reference-contexts: The Consultative Committee on International Telephony and Telegraphy (CCITT) and the International Organization for Standardization (ISO) have jointly developed a distributed directory service standard called X.500, which describes a hierarchical name space, with provisions for caching, authentication, and replication <ref> [3] </ref>. Each participating site maintains directory information about resources at that site, as well as administrative information needed for traversing the tree and maintaining proper distributed operation. There are a number of implementations of X.500 available, and field trials are underway to demonstrate interoperability between the implementations.
Reference: 4. <author> A. Emtage and P. Deutsch. </author> <title> Archie An Electronic Directory Service for the Internet. </title> <booktitle> Proceedings of the USENIX Winter Conference, </booktitle> <pages> pp. 93-110, </pages> <address> San Francisco, California, </address> <month> January </month> <year> 1992. </year>
Reference-contexts: This technique is the basis of the archie service, which maintains a list of approximately 1,100 "anonymous" FTP 2 archives worldwide, and builds a database of retrievable files by performing recursive directory listings at each site once per month <ref> [4] </ref>. These sites currently contain about 150 gigabytes of information, in approximately 2.6 million files. Users can query this database via several interfaces from any of 13 replicated archie servers worldwide, using regular expressions and other types of queries.
Reference: 5. <author> B. C. Neuman. Prospero: </author> <title> A Tool for Organizing Internet Resources. </title> <journal> Electronic Networking: Research, Applications, and Policy, </journal> <volume> 2(1), </volume> <pages> pp. 30-37, </pages> <publisher> Meckler Publications, </publisher> <address> Westport, Connecticut, </address> <month> Spring </month> <year> 1992. </year>
Reference-contexts: Some X.500 implementations support flat searches through parts of the tree, but not global searches. While archie allows users to search for files, the Prospero file system allows users to organize files according to their personal preferences, by creating views <ref> [5] </ref>. For example, a user might create a view concerning a particular research topic, and populate that view with links to relevant files distributed around the Internet. Other users can then browse this information.
Reference: 6. <author> T. Berners-Lee, R. Cailliau, J. Groff and B. Pollermann. </author> <title> World-Wide Web: The Information Universe . Electronic Networking: </title> <booktitle> Research, Applications and Policy , 2(1), </booktitle> <pages> pp. 52-58, </pages> <publisher> Meckler Publications, </publisher> <address> Westport Connecticut, </address> <month> Spring </month> <year> 1992. </year>
Reference-contexts: Other users can then browse this information. The World Wide Web (WWW) system also allows users to organize and access information without concern for its distribution <ref> [6] </ref>. However, WWW supports two separate discovery models. Part of the information space is based on a hypertext paradigm, where users can explore information by selecting hypertext links to other information. Other parts of the information space consist of indices, which the user encounters while exploring the hypertext space.
Reference: 7. <author> B. Kahle and A. Medlar. </author> <title> An Information System for Corporate Users: Wide Area Information Servers. </title> <journal> ConneXions The Interoperability Report, </journal> <volume> 5(11), </volume> <pages> pp. 2-9, </pages> <address> Interop, </address> <publisher> Inc., </publisher> <month> November </month> <year> 1991. </year>
Reference-contexts: The user accesses such indices using a flat search paradigm. The Wide Area Information Servers (WAIS) system allows users to deploy, search, and retrieve documents and many other types of information from indexed databases throughout the Internet <ref> [7] </ref>. While the archie index contains only file names, WAIS indices contain keywords for every word that appears in textual documents (other than common words like "the"). WAIS divides its indices among the servers that provide information, rather than using one global index.
Reference: 8. <author> M. McCahill. </author> <title> The Internet Gopher: A Distributed Server Information System. </title> <journal> ConneXions The Interoperability Report, </journal> <volume> 6(7), </volume> <pages> pp. 10-14, </pages> <address> Interop, </address> <publisher> Inc, </publisher> <month> July </month> <year> 1992. </year>
Reference-contexts: Instead, they must first search an index of servers, and then select a few servers to search. The Internet Gopher provides a uniform user interface to many different types of network information <ref> [8] </ref>. Users are presented with a hierarchical menu system, allowing them to access information from many of the systems listed above, plus various online telephone books, library catalogs, and other data.
Reference: 9. <author> R. E. Droms. </author> <title> Access to Heterogeneous Directory Services. </title> <booktitle> Proceedings of the Ninth Joint Conference of IEEE Computer and Communications Societies (InfoCom), </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: The Corporation for National Research Initiatives introduced the notion of a Knowbot TM (Knowledge Robot), which can launch searches for information in a network, possibly replicating itself onto other nodes. Droms implemented an Internet user directory service called the Knowbot Information Service <ref> [9] </ref>, which understands the input and output formats of a number of directory services (such as X.500 and WHOIS), and translates user hhhhhhhhhhhhhhhhhh 2 FTP is the Internet standard File Transfer Protocol.
Reference: 10. <author> M. F. Schwartz and P. G. Tsirigotis. </author> <title> Experience with a Semantically Cognizant Internet White Pages Directory Tool. </title> <journal> Journal of Internetworking: Research and Experience, </journal> <volume> 2(1), </volume> <pages> pp. 23-50, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: Internet User White Pages We have built and experimented extensively with a tool called Netfind, which locates electronic mail addresses and other information about Internet users, based on a number of widely distributed sources of simply structured information <ref> [10] </ref>. Using distributed information avoids difficult problems of consistency and transfer of authority that are inherent in mechanisms that rely on building centralized databases to hold the information.
Reference: 11. <author> M. F. Schwartz, D. R. Hardy, W. K. Heinzman and G. Hirschowitz. </author> <title> Supporting Resource Discovery Among Public Internet Archives Using a Spectrum of Information Quality. </title> <booktitle> Proceedings of the Eleventh IEEE International Conference on Distributed Computing Systems, </booktitle> <pages> pp. 82-89, </pages> <address> Arlington, Texas, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: Because of the labor intensity of this requirement, we explored an approach to Internet file archive discovery that allows incremental organization of the resources, based on the efforts of a geographically distributed collection of people, and a range of different information sources of varying degrees of quality <ref> [11] </ref>. In our prototype system, four levels of information quality are supported. At the lowest level, the system monitors USENET electronic bulletin board articles using some simple heuristics to recognize announcements about public archive sites. This information provides a simple keyword-based index of files throughout the Internet.
Reference: 12. <author> D. J. Ewing, R. S. Hall and M. F. Schwartz. </author> <title> A Measurement Study of Internet File Transfer Traffic. </title> <type> Technical Report CU-CS-571-92, </type> <institution> Department of Computer Science, University of Colorado, Boulder, Colorado, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: as trace inputs to simulations of distributed caching algorithms. - 7 - (Sidebar) How Many Times Do Popular Files Get Transferred Across Internet Links? From December 6-19, 1991 we measured file transfers between the University of Colorado and the rest of the Internet, to determine the extent of duplicate transmissions <ref> [12] </ref>. The measurement software sampled 20 bytes from each FTP file transfer, as a probabilistic test of file identity. (Equality cannot be established by file names, because they are not unique across Internet nodes.) During the monitoring period, 39,324 transfers of 23,622 different files were observed.
Reference: 13. <author> S. S. Coleman, D. C. M. Wood and M. F. Schwartz. Fremont: </author> <title> A System for Discovering Network Characteristics and Problems. To appear, </title> <booktitle> Proceedings of the USENIX Winter Conference, </booktitle> <address> San Diego, California, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: Using this type of formulation, a number of problems of network and system management can be cast as resource discovery problems. Our Fremont 3 project focuses on this aspect of resource discovery, allowing a user to discover information about network characteristics such as topology, congestion, routing, and protocol usage <ref> [13] </ref>. Like Netfind, Fremont uses a number of protocols and information sources, to support discovery in the absence of global agreement on any one protocol or information source. However, Fremont uses a much more extensive collection of protocols and information sources.
Reference: 14. <author> D. Hardy and M. F. Schwartz. </author> <title> Essence: A Resource Discovery System Based on Semantic File Indexing. To appear, </title> <booktitle> Proceedings of the USENIX Winter Conference, </booktitle> <address> San Diego, California, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: Similarly, our Fremont system, our Internet file archive discovery system, and our Essence file indexing system <ref> [14] </ref> each exploit semantics, redundancy, and context in the information they discover, to improve information quality. Below we discuss two Networked Resource Discovery Project efforts that illustrate the Two Phase Discovery paradigm in more depth.
Reference: 15. <author> M. F. Schwartz and D. C. M. Wood. </author> <title> Discovering Shared Interests Among People Using Graph Analysis of Global Electronic Mail Traffic. </title> <institution> Department of Computer Science, University of Colorado, Boulder, Colorado, </institution> <month> February </month> <year> 1992. </year> <note> To appear, Communications of the ACM. </note>
Reference-contexts: Unfortunately, doing so assumes one knows what lists should be built, and who should be included in each list. Therefore, we explored an approach that instead deduces interests from the history of electronic mail communication, using a set of heuristic graph algorithms <ref> [15] </ref>. Using this approach, a user could search for people by requesting a list of people whose interests are similar to several people known to have the interest in question. This technique can support a fine grained, dynamic means of locating people with related interests.
Reference: 16. <author> M. F. Schwartz. </author> <title> A Scalable, NonHierarchical Resource Discovery Mechanism Based on Probabilistic Protocols. </title> <type> Technical Report CU-CS-474-90, </type> <institution> Department of Computer Science, University of Colorado, Boulder, Colorado, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: Our approach involves the use of probabilistic algorithms for constructing and - 11 - searching a resource graph <ref> [16] </ref>. The goal is to locate a few resources that match a user's search request, rather than to support exhaustive searches. In a large network, users usually do not need exhaustive answers. We also assume that it is desirable to return different answers to the same query across search sessions.
Reference: 17. <author> M. F. Schwartz. </author> <title> A Measurement Study of Changes in Service-Level Reachability in the Global TCP/IP Internet: Goals, Experimental Design, Implementation, and Policy Considerations. Request For Comments 1273, </title> <institution> Department of Computer Science, University of Colorado, Boulder, Colorado, </institution> - <month> 15 - November </month> <year> 1991. </year>
Reference-contexts: Clearly, a study of this nature raises a number of potential concerns regarding privacy, security, and network/remote site load. We have published a study plan that discusses these and other issues <ref> [17] </ref>. Conclusions Resource discovery encompasses a range of problems that confront users of wide area networks in realizing the potential for remote collaboration and resource sharing. The Internet is a challenging environment in which to experiment with resource discovery, because of its scale, administrative decentralization, heterogeneity, and evolving commercialization.
References-found: 18

