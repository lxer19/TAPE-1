URL: file://ftp.cs.ucsd.edu/pub/baden/tr/cs94-386.ps.gz
Refering-URL: http://www.cs.ucsd.edu/~sfink/pub.html
Root-URL: http://www.cs.ucsd.edu
Note: To appear in Proceedings of the Seventh SIAM Conference on Parallel Processing for Scientific Computing  
Address: La Jolla, California 92093-0114  
Affiliation: Department of Computer Science and Engineering University of California, San Diego  
Abstract: Run-time Data Distribution for Block-Structured Applications on Distributed Memory Computers Stephen J. Fink & Scott B. Baden CSE Technical Report Number CS94-386 September 1994 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Agrawal, A. Sussman, and J. Saltz, </author> <title> Efficient runtime support for parallelizeing block structured applications, </title> <booktitle> in Proceedings of the 1994 Scalable High Performance Computing Conference, </booktitle> <address> Knoxville, Tenessee, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Under the message-passing programming model, the programmer must manage all aspects of data distribution by hand. Programming languages and run-time libraries that manage the low-level details of data distribution can alleviate the programmer's burden <ref> [10, 9, 8, 12, 1, 4, 11] </ref>. Perhaps the simplest strategy for managing distributed data is the mapping array, a many-to-one mapping of data elements to processors [9]. <p> This limits the programmer since templates cannot be defined at run-time nor passed across procedure boundaries [7]. To avoid these limitations, Vienna Fortran omits templates but includes a more general form of the block distribution directive [6]. The Multiblock PARTI library <ref> [1] </ref> and pC++ [4] implement distribution schemes similar to the HPF 3-stage model, but implement distribution and alignment with first-class, dynamic objects. <p> The sRegion is a Region with a stride in each dimension. This object is similar to the Fortran 90 array section specifier and the regular section employed in the Multiblock Parti run-time library <ref> [1] </ref>. The stride values for an n-dimensional sRegion can be represented by an n-dimensional Point. The expand and collapse functions relate Regions and sRegions.
Reference: [2] <author> M. J. Berger and S. H. Bokhari, </author> <title> A partitioning strategy for nonuniform problems on multiprocessors, </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36 (1987), </volume> <pages> pp. 570-580. </pages>
Reference-contexts: The BLOCK distribution directive does not describe the irregular block distributions that arise in applications such as adaptive mesh refinement [3] and partitions produced by load-balancing with irregular decompositions such as recursive bisection <ref> [2] </ref>. The LPARX library provides mechanisms for managing these irregular block distributions [11].
Reference: [3] <author> M. J. Berger and P. Colella, </author> <title> Local adaptive mesh refinement for shock hydrodynamics, </title> <journal> Journal of Comp. Physics, </journal> <volume> 82 (1989), </volume> <pages> pp. 64-84. </pages>
Reference-contexts: The Multiblock PARTI library [1] and pC++ [4] implement distribution schemes similar to the HPF 3-stage model, but implement distribution and alignment with first-class, dynamic objects. The BLOCK distribution directive does not describe the irregular block distributions that arise in applications such as adaptive mesh refinement <ref> [3] </ref> and partitions produced by load-balancing with irregular decompositions such as recursive bisection [2]. The LPARX library provides mechanisms for managing these irregular block distributions [11].
Reference: [4] <author> F. Bodin, P. Beckman, D. Gannon, S. Yang, S. Kesavan, A. Malony, and B.Mohr, </author> <title> Implementing a parallel C++ runtime system for scalable parallel systems, </title> <booktitle> in Proc. Supercomputing, </booktitle> <year> 1993, </year> <pages> pp. 588-597. </pages>
Reference-contexts: Under the message-passing programming model, the programmer must manage all aspects of data distribution by hand. Programming languages and run-time libraries that manage the low-level details of data distribution can alleviate the programmer's burden <ref> [10, 9, 8, 12, 1, 4, 11] </ref>. Perhaps the simplest strategy for managing distributed data is the mapping array, a many-to-one mapping of data elements to processors [9]. <p> This limits the programmer since templates cannot be defined at run-time nor passed across procedure boundaries [7]. To avoid these limitations, Vienna Fortran omits templates but includes a more general form of the block distribution directive [6]. The Multiblock PARTI library [1] and pC++ <ref> [4] </ref> implement distribution schemes similar to the HPF 3-stage model, but implement distribution and alignment with first-class, dynamic objects.
Reference: [5] <author> Z. Bozkus, A. Choudhary, G. Fox, T. Haupt, and S. Ranka, </author> <title> Compiling distribution directives in a fortran 90d compiler, </title> <type> Tech. Rep. </type> <institution> SCCS-388, Northeast Parallel Architectures Center, Syracuse, </institution> <address> NY, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: We define an operation XOwner (P; A) which returns the Point Q 2 region (A) such that P 2 region (A (Q)). If A has a regular block decomposition, it is simple to determine XOwner (P; A) in constant time as described in <ref> [5] </ref>. Furthermore, let R be a Region, and consider the Region [XOwner (lwb (R); A); XOwner (upb (R); A)]. This Region identifies the set of Grids in A that own some point p 2 R. Returning to algorithm 4.1, suppose X has a regular block decomposition.
Reference: [6] <author> B. Chapman, P. Mehrotra, H. Moritsch, and H. Zima, </author> <title> Dynamic data distributions in vienna fortran, </title> <type> Report 93-92, </type> <institution> ICASE, </institution> <month> Decemeger </month> <year> 1993. </year>
Reference-contexts: In HPF, templates are compile-time directives only and not first-class objects. This limits the programmer since templates cannot be defined at run-time nor passed across procedure boundaries [7]. To avoid these limitations, Vienna Fortran omits templates but includes a more general form of the block distribution directive <ref> [6] </ref>. The Multiblock PARTI library [1] and pC++ [4] implement distribution schemes similar to the HPF 3-stage model, but implement distribution and alignment with first-class, dynamic objects.
Reference: [7] <author> B. Chapman, P. Mehrotra, and H. Zima, </author> <title> High performance fortran without templates: an alternative model for distribution and alignment, </title> <booktitle> in Proceedings of the Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> San Diego, CA, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: In HPF, templates are compile-time directives only and not first-class objects. This limits the programmer since templates cannot be defined at run-time nor passed across procedure boundaries <ref> [7] </ref>. To avoid these limitations, Vienna Fortran omits templates but includes a more general form of the block distribution directive [6]. The Multiblock PARTI library [1] and pC++ [4] implement distribution schemes similar to the HPF 3-stage model, but implement distribution and alignment with first-class, dynamic objects.
Reference: [8] <author> D. E. Culler, A. Dusseau, S. C. Goldstein, A. Krishnamurthy, S. Lumetta, T. von Eicken, and K. Yelick, </author> <title> Parallel programming in split-c. </title> <type> Draft, </type> <month> May </month> <year> 1993. </year>
Reference-contexts: Under the message-passing programming model, the programmer must manage all aspects of data distribution by hand. Programming languages and run-time libraries that manage the low-level details of data distribution can alleviate the programmer's burden <ref> [10, 9, 8, 12, 1, 4, 11] </ref>. Perhaps the simplest strategy for managing distributed data is the mapping array, a many-to-one mapping of data elements to processors [9]. <p> In this distributed case, S and D may span multiple processor memories. 2 The get and put forms of Copy are coarse-grain operations, similar to the bulk get and bulk put library extensions to Split-C <ref> [8] </ref>. Run-time Data Distribution for Block-Structured Applications 5 Assuming no regular block structure in the distributions of X and Y , distributed block copy can be implemented as shown in algorithm 4.1.
Reference: [9] <author> G. Fox, S. Hiranandani, K. Kennedy, C. Koelbel, U. Kremer, C. Tseng, and M. Wu, </author> <title> Fortran D language specification, </title> <type> Tech. Rep. </type> <institution> TR90-141, Dept. of Computer Science, Rice University, Houston, TX, </institution> <month> December </month> <year> 1989. </year>
Reference-contexts: Under the message-passing programming model, the programmer must manage all aspects of data distribution by hand. Programming languages and run-time libraries that manage the low-level details of data distribution can alleviate the programmer's burden <ref> [10, 9, 8, 12, 1, 4, 11] </ref>. Perhaps the simplest strategy for managing distributed data is the mapping array, a many-to-one mapping of data elements to processors [9]. <p> Programming languages and run-time libraries that manage the low-level details of data distribution can alleviate the programmer's burden [10, 9, 8, 12, 1, 4, 11]. Perhaps the simplest strategy for managing distributed data is the mapping array, a many-to-one mapping of data elements to processors <ref> [9] </ref>. Mapping arrays provide the most flexibility of any data distribution scheme, but incur a large space overhead since one mapping element must be stored for each data element. <p> We present a small set of efficient geometric run-time primitives to manage dynamic regular and irregular block-structured data distributions. With these primitives, we show how to provide * A generalization of Fortran D's <ref> [9] </ref> three-stage distribution scheme for both regular and irregular block distributions, * first-class dynamic distribution objects, and * efficient support for block data movement. fl This work was supported by ONR contract N00014-93-1-0152. <p> Fink and Scott B. Baden 2 Previous work HPF [10] manages block-structured distributions with the 3-stage distribution scheme pioneered in Fortran D <ref> [9] </ref>. First, the programmer defines the shape of a logical processor array, which the implementation maps to the physical processor set. Then, a rectangular abstract index space called a template is distributed across the logical processor array.
Reference: [10] <author> High Performance Fortran Forum, </author> <title> High performance fortran language specification, </title> <institution> Rice Univeristy, Houston, Texas, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: Under the message-passing programming model, the programmer must manage all aspects of data distribution by hand. Programming languages and run-time libraries that manage the low-level details of data distribution can alleviate the programmer's burden <ref> [10, 9, 8, 12, 1, 4, 11] </ref>. Perhaps the simplest strategy for managing distributed data is the mapping array, a many-to-one mapping of data elements to processors [9]. <p> Fink and Scott B. Baden 2 Previous work HPF <ref> [10] </ref> manages block-structured distributions with the 3-stage distribution scheme pioneered in Fortran D [9]. First, the programmer defines the shape of a logical processor array, which the implementation maps to the physical processor set. Then, a rectangular abstract index space called a template is distributed across the logical processor array.
Reference: [11] <author> S. R. Kohn and S. B. Baden, </author> <title> A robust parallel programming model for dynamic, non-uniform scientific computation, </title> <booktitle> in Proceedings of the 1994 Scalable High Performance Computing Conference, </booktitle> <address> Knoxville, Tenessee, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Under the message-passing programming model, the programmer must manage all aspects of data distribution by hand. Programming languages and run-time libraries that manage the low-level details of data distribution can alleviate the programmer's burden <ref> [10, 9, 8, 12, 1, 4, 11] </ref>. Perhaps the simplest strategy for managing distributed data is the mapping array, a many-to-one mapping of data elements to processors [9]. <p> The BLOCK distribution directive does not describe the irregular block distributions that arise in applications such as adaptive mesh refinement [3] and partitions produced by load-balancing with irregular decompositions such as recursive bisection [2]. The LPARX library provides mechanisms for managing these irregular block distributions <ref> [11] </ref>. <p> The LPARX <ref> [11] </ref> class library implements geometric domain abstractions as first-class run-time objects. We shall use the following subset of LPARX primitives to implement dynamic data distribution. 3.1 LPARX primitives A Point is an n-tuple representing a point in Z n .
Reference: [12] <author> C. Lin and L. Snyder, ZPL: </author> <title> An array sublanguage, </title> <booktitle> in Languages and Compilers for Parallel Computation, 6th International Workshop Proceedings, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1994, </year> <pages> pp. 96-114. </pages>
Reference-contexts: Under the message-passing programming model, the programmer must manage all aspects of data distribution by hand. Programming languages and run-time libraries that manage the low-level details of data distribution can alleviate the programmer's burden <ref> [10, 9, 8, 12, 1, 4, 11] </ref>. Perhaps the simplest strategy for managing distributed data is the mapping array, a many-to-one mapping of data elements to processors [9]. <p> decompositions, nor a three-stage mapping strategy for aligning distributed arrays relative to each other. 3 Run-time primitives for data distribution Geometric primitives were introduced as first-class objects in FIDIL [13] as a means for managing index sets of arrays, and are employed by the ZPL language as compile-time iteration masks <ref> [12] </ref>. The LPARX [11] class library implements geometric domain abstractions as first-class run-time objects. We shall use the following subset of LPARX primitives to implement dynamic data distribution. 3.1 LPARX primitives A Point is an n-tuple representing a point in Z n .
Reference: [13] <author> L. Semenzato and P. Hilfinger, </author> <booktitle> Arrays in fidil, in Proceedings of the First International Workshop on Arrays, Functional Programming, and Parallel Systems, </booktitle> <month> July </month> <year> 1990. </year>
Reference-contexts: The LPARX library provides mechanisms for managing these irregular block distributions [11]. However, LPARX does not provide automatic regular BLOCK decompositions, nor a three-stage mapping strategy for aligning distributed arrays relative to each other. 3 Run-time primitives for data distribution Geometric primitives were introduced as first-class objects in FIDIL <ref> [13] </ref> as a means for managing index sets of arrays, and are employed by the ZPL language as compile-time iteration masks [12]. The LPARX [11] class library implements geometric domain abstractions as first-class run-time objects.
References-found: 13

