URL: http://www.cs.umd.edu/~reiko/aaai96.ps
Refering-URL: http://www.cs.umd.edu/projects/plus/umcp/manual/publications.html
Root-URL: 
Email: reiko@cs.umd.edu  hendler@cs.umd.edu  nau@cs.umd.edu  
Title: Commitment Strategies in Hierarchical Task Network Planning  
Author: Reiko Tsunetoy Kutluhan Erol** kutluhan@i-a-i.com James Hendleryz Dana Nauyz 
Address: College Park, MD 20742  College Park, MD 20742  Rockville, MD 20850  
Affiliation: yDept. of Computer Science University of Maryland  zInstitute for Systems Research University of Maryland  **Intelligent Automation, Inc. 2 Research Place  
Note: To appear in AAAI-96  
Abstract: This paper compares three commitment strategies for HTN planning: (1) a strategy that delays variable bindings as much as possible; (2) a strategy in which no non-primitive task is expanded until all variable constraints are committed; and (3) a strategy that chooses between expansion and variable instantiation based on the number of branches that will be created in the search tree. Our results show that while there exist planning domains in which the first two strategies do well, the third does well over a broader range of planning domains. 
Abstract-found: 1
Intro-found: 1
Reference: <author> S. Andrews, B. Kettler, K. Erol, and J. Hendler. </author> <title> UM translog: A planning domain for the development and benchmarking of planning systems. </title> <type> Technical report, </type> <institution> CS-TR-3487, University of Maryland, </institution> <year> 1995. </year>
Reference: <author> A. Barret and D. Weld. </author> <title> Partial-order planning: Evaluating possible efficiency gains. </title> <booktitle> Artificial Intelligence 67(1), </booktitle> <pages> pp. 71-112, </pages> <year> 1994. </year>
Reference: <author> D. Chapman. </author> <title> Planning for Conjunctive Goals. </title> <booktitle> Artificial Intelligence 32, </booktitle> <pages> pp. 333-377, </pages> <year> 1987. </year>
Reference: <author> K. Currie and A. Tate. O-plan: </author> <title> the open planning architecture. </title> <booktitle> Artificial Intelligence 52, </booktitle> <pages> pp. 49-86, </pages> <year> 1991. </year>
Reference: <author> K. Erol. </author> <title> HTN planning: Formalization, analysis, and implementation. </title> <type> Ph.D. dissertation, </type> <institution> Computer Science Dept., University of Maryland, </institution> <year> 1995. </year>
Reference: <author> E. Fink and M. Veloso. </author> <title> Prodigy planning algorithm. </title> <type> Technical report, </type> <institution> CMU-CS-94-123, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1994. </year>
Reference: <author> L. Ihrig and S. Kambhampati. </author> <title> Integrating replay with EBL to improve planning performance. </title> <type> ASE-CSE-TR 94-003, </type> <institution> Arizona State University, </institution> <year> 1995. </year>
Reference-contexts: One of our goals is to build a methodology which can automatically extract the domain knowledge useful for efficient commitment strategies. In particular, we hope to use AI learning techniques to develop domain-specific commitment strategies. Case-based reasoning (Veloso 1994) and explanation-based learning <ref> (Ihrig and Kambhampati 1995) </ref> are already used to learn search control for various planners, and we hope to extend this work to HTN planning. We also intend to explore the adjustment of dynamic heuristics such as DVCS based on feedback from experience in the domain.
Reference: <author> S. Kambhampati, C. Knoblock, and Q. Yang. </author> <title> Planning as refinement search: A unified framework for evaluating design tradeoffs in partial-order planning. </title> <booktitle> Artificial Intelligence 76, </booktitle> <pages> pp. 167-238, </pages> <year> 1995. </year>
Reference-contexts: One of our goals is to build a methodology which can automatically extract the domain knowledge useful for efficient commitment strategies. In particular, we hope to use AI learning techniques to develop domain-specific commitment strategies. Case-based reasoning (Veloso 1994) and explanation-based learning <ref> (Ihrig and Kambhampati 1995) </ref> are already used to learn search control for various planners, and we hope to extend this work to HTN planning. We also intend to explore the adjustment of dynamic heuristics such as DVCS based on feedback from experience in the domain.
Reference: <author> V. Kumar. </author> <title> Algorithms for constraint -satisfaction problems: A survey. </title> <journal> AI Magazine, </journal> <pages> pp. 32-44, </pages> <year> 1992. </year>
Reference: <author> S. Minton, J. Bresina, and M. Drummond. </author> <title> Commitment strategy in planning: A comparative analysis. </title> <booktitle> In IJCAI-91, </booktitle> <pages> pp. 259-265, </pages> <year> 1991. </year>
Reference: <author> J. S. Penberthy and D. Weld. UCPOP: </author> <title> A sound, complete, partial order planner for ADL. </title> <booktitle> Proceedings of KR-92, </booktitle> <year> 1992. </year>
Reference: <author> A. Tate. </author> <title> Generating project networks. </title> <booktitle> In IJCAI-77, </booktitle> <pages> pp. 888-893. </pages>
Reference: <author> M. Veloso and P. Stone. FLECS: </author> <title> Planning with a flexible commitment strategy. </title> <journal> Journal of Artificial Intelligence Research 3, </journal> <pages> pp. 25-52, </pages> <year> 1995. </year>
Reference: <author> M. Veloso. </author> <title> Flexible strategy learning: Analogical replay of problem solving episodes. </title> <booktitle> In AAAI-94, </booktitle> <pages> pp. 595-600, </pages> <year> 1994. </year>
Reference-contexts: One of our goals is to build a methodology which can automatically extract the domain knowledge useful for efficient commitment strategies. In particular, we hope to use AI learning techniques to develop domain-specific commitment strategies. Case-based reasoning <ref> (Veloso 1994) </ref> and explanation-based learning (Ihrig and Kambhampati 1995) are already used to learn search control for various planners, and we hope to extend this work to HTN planning. We also intend to explore the adjustment of dynamic heuristics such as DVCS based on feedback from experience in the domain.
Reference: <author> Q. Yang and A. Chan. </author> <title> Delaying variable binding commitments in planning. </title> <booktitle> In AIPS-94, </booktitle> <pages> pp. 182-187, </pages> <year> 1994. </year> <month> 7 </month>
References-found: 15

