URL: http://www.isi.edu/~muslea/PS/hwi_aa99.ps
Refering-URL: http://www.isi.edu/~muslea/papers.html
Root-URL: http://www.isi.edu
Email: fmuslea, minton, knoblockg@isi.edu  
Title: A Hierarchical Approach to Wrapper Induction  
Author: Ion Muslea, Steve Minton, and Craig Knoblock 
Address: 4676 Admiralty Way Marina del Rey, CA 90292-6695  
Affiliation: University of Southern California  
Abstract: With the tremendous amount of information that becomes available on the Web on a daily basis, the ability to quickly develop information agents has become a crucial problem. A vital component of any Web-based information agent is a set of wrappers that can extract the relevant data from semistructured information sources. Our novel approach to wrapper induction is based on the idea of hierarchical information extraction, which turns the hard problem of extracting data from an arbitrarily complex document into a series of easier extraction tasks. We introduce an inductive algorithm, stalker, that generates high accuracy extraction rules based on user-labeled training examples. Labeling the training data represents the major bottleneck in using wrapper induction techniques, and our experimental results show that stalker does significantly better then other approaches; on one hand, stalker requires up to two orders of magnitude fewer examples than other algorithms, while on the other hand it can handle information sources that could not be wrapped by existing techniques. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Ashish, N., and Knoblock, C. </author> <title> Semiautomatic wrapper generation for internet information sources. </title> <booktitle> Proceedings of Cooperative Information Systems (1997). </booktitle>
Reference-contexts: Any sequence S ::= T i <ref> [1] </ref>, T i [2], . . . , T i [Idx i 1] (i.e., any instance of P ref ix x (p)) represents a positive example, while any other sub-sequence or super-sequence of S represents a negative example. stalker tries to generate an SLG that accepts all positive examples and rejects <p> In order to help the users cope with these difficulties, Ashish and Knoblock <ref> [1] </ref> proposed an expert system approach that uses a fixed set of heuristics of the type "look for bold or italicized strings". The wrapper induction techniques introduced in wien [12] are better fit to frequent format changes because they rely on learning techniques to generate the extraction rules.
Reference: [2] <author> Atzeni, P., and Mecca, G. </author> <title> Cut and paste. </title> <booktitle> Proceedings of 16th ACM SIGMOD Symposion on Principles of Database Systems (1997). </booktitle>
Reference-contexts: Any sequence S ::= T i [1], T i <ref> [2] </ref>, . . . , T i [Idx i 1] (i.e., any instance of P ref ix x (p)) represents a positive example, while any other sub-sequence or super-sequence of S represents a negative example. stalker tries to generate an SLG that accepts all positive examples and rejects all negative ones. <p> learning curves for ListExtr (S3), ListExtr (S4), and ListIter (S1) are identical because all three learning tasks reach a 100% accuracy after seeing a single example. variety of languages have been developed for manually writing wrappers (i.e., where the extraction rules are written by a human expert), from procedural languages <ref> [2] </ref> and Perl scripts [7] to pattern matching [5] and LL (k) grammars [6].
Reference: [3] <author> Atzeni, P., Mecca, G., and Merialdo, P. </author> <title> Semi-structured and structured data in the web: going back and forth. </title> <booktitle> Proceedings of ACM SIGMOD Workshop on Management of Semi-structured Data (1997), </booktitle> <pages> 1-9. </pages>
Reference-contexts: Each wrapper consists of a set of extraction rules and the code required to apply those rules. Some systems, such as tsimmis [5] and araneus <ref> [3] </ref> depend on humans to write the necessary grammar rules. However, there are several reasons why this is undesirable. Writing extraction rules is tedious, time consuming and requires a high level of expertise.
Reference: [4] <author> Califf, M., and Mooney, R. </author> <title> Relational learning of pattern-match rules for information extraction. </title> <booktitle> Working Papers of the ACL-97 Workshop in Natural Language Learning (1997), </booktitle> <pages> 9-15. </pages>
Reference-contexts: In contrast to information agents, most general purpose information extraction systems are focused on unstructured text, and therefore the extraction techniques text are based on linguistic constraints. However, there are three such systems that are somewhat related to stalker: WHISK [15], Rapier <ref> [4] </ref>, and SRV [8]. The extraction rules induced by Rapier and SRV can use the landmarks that immediately precede and/or follow the item to be extracted, while WHISK is capable of using multiple landmarks.
Reference: [5] <author> Chawathe, S., Garcia-Molina, H., Hammer, J., Ireland, K., Papakonstantinou, Y., Ull-man, J., and Widom., J. </author> <title> The tsimmis project: integration of heterogeneous information sources. </title> <booktitle> 10th Meeting of the Information Processing Society of Japan (1994), </booktitle> <pages> 7-18. </pages>
Reference-contexts: Each wrapper consists of a set of extraction rules and the code required to apply those rules. Some systems, such as tsimmis <ref> [5] </ref> and araneus [3] depend on humans to write the necessary grammar rules. However, there are several reasons why this is undesirable. Writing extraction rules is tedious, time consuming and requires a high level of expertise. <p> ListIter (S1) are identical because all three learning tasks reach a 100% accuracy after seeing a single example. variety of languages have been developed for manually writing wrappers (i.e., where the extraction rules are written by a human expert), from procedural languages [2] and Perl scripts [7] to pattern matching <ref> [5] </ref> and LL (k) grammars [6]. Even though these systems offer fairly expressive extraction languages, the manual wrapper generation is a tedious, time consuming task that requires a high level of expertise; furthermore, the rules have to be rewritten whenever the sources suffer format changes.
Reference: [6] <author> Chidlovskii, B., Borghoff, U., and Chevalier, P. </author> <title> Towards sophisticated wrapping of web-based information repositories. </title> <booktitle> Proceedings of 5th International RIAO Conf. </booktitle> <year> (1997), </year> <pages> 123-35. </pages>
Reference-contexts: all three learning tasks reach a 100% accuracy after seeing a single example. variety of languages have been developed for manually writing wrappers (i.e., where the extraction rules are written by a human expert), from procedural languages [2] and Perl scripts [7] to pattern matching [5] and LL (k) grammars <ref> [6] </ref>. Even though these systems offer fairly expressive extraction languages, the manual wrapper generation is a tedious, time consuming task that requires a high level of expertise; furthermore, the rules have to be rewritten whenever the sources suffer format changes.
Reference: [7] <author> Cohen, W. </author> <title> A web-based information system that reasons with structured collections of text. </title> <booktitle> Proceedings of Autonomous Agents AA-98 (1998), </booktitle> <pages> 400-407. </pages>
Reference-contexts: However, the Web is based on a browsing paradigm that makes it difficult to retrieve and integrate data from multiple sources. The most recent generation of information agents (e.g., WHIRL <ref> [7] </ref>, Ariadne [11], and Information Manifold [10] ) address this problem by enabling information from pre-specified sets of Web sites to be accessed via database-like queries. For instance, consider the query "What seafood restaurants in L.A. have prices below $20 and accept the Visa credit-card?". <p> (S3), ListExtr (S4), and ListIter (S1) are identical because all three learning tasks reach a 100% accuracy after seeing a single example. variety of languages have been developed for manually writing wrappers (i.e., where the extraction rules are written by a human expert), from procedural languages [2] and Perl scripts <ref> [7] </ref> to pattern matching [5] and LL (k) grammars [6]. Even though these systems offer fairly expressive extraction languages, the manual wrapper generation is a tedious, time consuming task that requires a high level of expertise; furthermore, the rules have to be rewritten whenever the sources suffer format changes.
Reference: [8] <author> Freitag, D. </author> <title> Information extraction from html: Application of a general learning approach. </title> <booktitle> Proceedings of the Fifteenth Conference on Artificial Intelligence AAAI-98 (1998), </booktitle> <pages> 517-523. </pages>
Reference-contexts: In contrast to information agents, most general purpose information extraction systems are focused on unstructured text, and therefore the extraction techniques text are based on linguistic constraints. However, there are three such systems that are somewhat related to stalker: WHISK [15], Rapier [4], and SRV <ref> [8] </ref>. The extraction rules induced by Rapier and SRV can use the landmarks that immediately precede and/or follow the item to be extracted, while WHISK is capable of using multiple landmarks.
Reference: [9] <author> Hsu, C. </author> <title> Initial results on wrapping semistructured web pages with finite-state transducers and contextual rules. </title> <booktitle> AAAI-98 Workshop on AI and Information Integration (1998), </booktitle> <pages> 66-73. </pages>
Reference-contexts: Second, wien cannot wrap sources in which some items are missing or appearing in various orders. Last but not least, stalker can handle EC trees of arbitrary depths, while wien's approach to nested documents turned out to be prohibitive in terms of CPU time. SoftMealy <ref> [9] </ref> uses a wrapper induction algorithm that generates extraction rules expressed as finite transducers. The SoftMealy rules are more general than the wien ones because they use wildcards and they can handle both missing items and items appearing in various orders.
Reference: [10] <author> Kirk, T., Levy, A., SAgiv, Y., and Sri-vastava, D. </author> <title> The information manifold. </title> <booktitle> AAAI Spring Symposium: Information Gathering from Heterogeneous Distributed Environments (1995), </booktitle> <pages> 85-91. </pages>
Reference-contexts: However, the Web is based on a browsing paradigm that makes it difficult to retrieve and integrate data from multiple sources. The most recent generation of information agents (e.g., WHIRL [7], Ariadne [11], and Information Manifold <ref> [10] </ref> ) address this problem by enabling information from pre-specified sets of Web sites to be accessed via database-like queries. For instance, consider the query "What seafood restaurants in L.A. have prices below $20 and accept the Visa credit-card?".
Reference: [11] <author> Knoblock, C., Minton, S., Ambite, J., Ashish, N., Margulis, J., Modi, J., Muslea, I., Philpot, A., and Tejada, S. </author> <title> Modeling web sources for information integration. </title> <booktitle> Proceedings of the Fifteenth National Conference on ASrtificial Intelligence (1998), </booktitle> <pages> 211-218. </pages>
Reference-contexts: However, the Web is based on a browsing paradigm that makes it difficult to retrieve and integrate data from multiple sources. The most recent generation of information agents (e.g., WHIRL [7], Ariadne <ref> [11] </ref>, and Information Manifold [10] ) address this problem by enabling information from pre-specified sets of Web sites to be accessed via database-like queries. For instance, consider the query "What seafood restaurants in L.A. have prices below $20 and accept the Visa credit-card?".
Reference: [12] <author> Kushmerick, N. </author> <title> Wrapper induction for information extraction. </title> <type> PhD Thesis, </type> <institution> Dept. of Computer Science, U. of Washington, </institution> <note> TR UW-CSE-97-11-04 (1997). </note>
Reference-contexts: 57 S4 Quote Server 18 10 22 Table 1: Illustrative information sources. stalker completes its execution by returning the disjunctive rule either R1 or R7. 7 Experimental Results In Table 1, we present four illustrative information sources that were selected from the larger set of sources on which Kushmerick's wien <ref> [12] </ref> system was tested. 2 S1 and S2 are the hardest sources that wien could wrap (i.e., they required the largest number of training examples), while S3 and S4 were beyond wien's capabilities because they have missing items and/or items that appear in various orders. <p> In order to help the users cope with these difficulties, Ashish and Knoblock [1] proposed an expert system approach that uses a fixed set of heuristics of the type "look for bold or italicized strings". The wrapper induction techniques introduced in wien <ref> [12] </ref> are better fit to frequent format changes because they rely on learning techniques to generate the extraction rules.
Reference: [13] <author> RayChaudhuri, T., and Hamey, L. </author> <title> Active learning-approaches and issues. </title> <journal> Journal of Intelligent Systems 7 (1997), </journal> <pages> 205-243. </pages>
Reference-contexts: Second, the fact that even for the hardest items in S4 we can find a correct rule (remember that the low correctness comes from averaging correct rules with erroneous ones) means that we can try to improve stalker's behavior based on active learning techniques <ref> [13] </ref> that would allow the algorithm to select the few relevant cases that would lead to a correct rule. 8 Related Work Research on learning extraction rules has occurred mainly in two contexts: creating wrappers for information agents and developing general purpose information extraction systems for natural language text.
Reference: [14] <author> RISE. </author> <title> Rise: A repository of online information sources used in information extraction tasks. </title>
Reference-contexts: In Table 2 we show some illustrative figures for wien and stalker based on their respective performances on the four 2 All WIEN sources can be obtained from the RISE <ref> [14] </ref> repository. SR Missing Various wien stalker Items Orders Exs CPU Exs CPU S1 - 46 5 sec 1 19 sec S3 - 10 202 sec p Table 2: Experimental data. test domains. Note that these numbers can not be used for a rigorous comparison for several reason.
Reference: [http://www.isi.edu/ muslea/RISE/index.html] <institution> Information Sciences Institute / USC (1998). </institution>
Reference: [15] <author> Soderland, S. </author> <title> Learning information extraction rules for semi-structured and free text. </title> <note> http://www.cs.washington.edu/homes/soderlan/WHISK.ps (1998). </note>
Reference-contexts: In contrast to information agents, most general purpose information extraction systems are focused on unstructured text, and therefore the extraction techniques text are based on linguistic constraints. However, there are three such systems that are somewhat related to stalker: WHISK <ref> [15] </ref>, Rapier [4], and SRV [8]. The extraction rules induced by Rapier and SRV can use the landmarks that immediately precede and/or follow the item to be extracted, while WHISK is capable of using multiple landmarks.
References-found: 16

