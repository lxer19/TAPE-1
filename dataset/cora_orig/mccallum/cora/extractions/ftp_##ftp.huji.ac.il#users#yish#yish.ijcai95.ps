URL: ftp://ftp.huji.ac.il/users/yish/yish.ijcai95.ps
Refering-URL: http://www.cs.huji.ac.il/~yish/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: email: yish@cs.huji.ac.il, clag@cs.huji.ac.il, jeff@cs.huji.ac.il  
Phone: ph: 011-972-2-658-5353 fax: 011-972-2-658-5439  
Title: Learn Your Opponent's Strategy(in Polynomial Time)!  
Author: Yishay Mor and Claudia V. Goldman and Jeffrey S. Rosenschein 
Keyword: Distributed Artificial Intelligence, Learning, repeated games, automata  
Address: Givat Ram, Jerusalem, Israel  
Affiliation: Computer Science Department Hebrew University  
Abstract: This paper examines interactions among agents from a game theoretic perspective. In this context, learning has been assumed as a means to reach equilibrium. We analyze the complexity of this learning process. We start with a restricted two-agent model, in which agents are represented by finite automata, and one of the agents plays a fixed strategy. We show that even with this restrictions, the learning process may be exponential in time. We then suggest a criterion of simplicity, that induces a class of automata that are learnable in polynomial time.
Abstract-found: 1
Intro-found: 1
Reference: [ Aumann and Brandenburger, 1991 ] <author> R. Aumann and A. Brandenburger. </author> <title> Epistemic conditions for Nash equilibrium. </title> <type> Working Paper 91-042, </type> <institution> Harvard Business School, </institution> <year> 1991. </year>
Reference: [ Fortnow and Whang, 1994 ] <author> L. Fortnow and D. Whang. </author> <title> Optimality and domination in repeated games with bounded players. </title> <type> Technical report, </type> <institution> Department of Computer Science University of Chicago, Chicago, </institution> <year> 1994. </year>
Reference-contexts: This line of work is, in a sense, contrapositional to other common measures of complexity. Papadim-itriou [ Papadimitriou, 1992 ] has shown that as the bound on the number of states of the automaton becomes more restrictive, the problem of designing the optimal automaton becomes harder. Fortnow and Whang <ref> [ Fortnow and Whang, 1994 ] </ref> were the first to assume total ignorance of the opponent's automaton. They show that in zero-sum games, a rational player can discover an optimal strategy w.r.t. the opponent's automaton in polynomial time, but in non-zero-sum games this is not the general case. <p> C *-supports &lt; ff; fi &gt;. 1 In this we follow other researchers <ref> [ Gilboa and Samet, 1989; Fortnow and Whang, 1994 ] </ref> who used this restriction to avoid "infinitly vengeful" strategies. Connected automata are such that have no disjoint states, i.e. for any states i; j there is an input sequence that leads from i to j. <p> Denote it the consensus cycle. * Build the punishing chain, C pun that is based on the automaton presented in <ref> [ Fortnow and Whang, 1994 ] </ref> . The idea is to choose a random binary string of Cs and Ds and to construct the punishing chain so that B can escape from it only by following this string. It was shown in [ Fortnow and Whang, 1994 ] that C pun <p> that is based on the automaton presented in <ref> [ Fortnow and Whang, 1994 ] </ref> . The idea is to choose a random binary string of Cs and Ds and to construct the punishing chain so that B can escape from it only by following this string. It was shown in [ Fortnow and Whang, 1994 ] that C pun cannot be learnt in polynomial time. Therefore if B en ters C pun then T L B (A Q Lemma 2.1 B enters C pun with probability (1 ( 1 2 ) 2 ). Proof.
Reference: [ Gilboa and Samet, 1989 ] <author> I. Gilboa and D. Samet. </author> <title> Bounded vs. unbounded rationality: The tyranny of the weak. </title> <journal> Games and Economic Behavior, </journal> <volume> 1 </volume> <pages> 213-221, </pages> <year> 1989. </year>
Reference-contexts: C *-supports &lt; ff; fi &gt;. 1 In this we follow other researchers <ref> [ Gilboa and Samet, 1989; Fortnow and Whang, 1994 ] </ref> who used this restriction to avoid "infinitly vengeful" strategies. Connected automata are such that have no disjoint states, i.e. for any states i; j there is an input sequence that leads from i to j.
Reference: [ Kalai, 1990 ] <author> Ehud Kalai. </author> <title> Bounded rationality and strategic complexity in repeated games. </title> <editor> In T. Ichi-ishi, A. Neyman, and Y. Tauman, editors, </editor> <booktitle> Game Theory and Aplications, </booktitle> <pages> pages 131-157. </pages> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1990. </year>
Reference-contexts: An extensive survey of the relevant literature appears in <ref> [ Kalai, 1990 ] </ref> . The basic concept underlying this trend is that the players are rational, but are constrained to submit automata of limited size as their agents in the game. The number of states in the automata is accepted as a measure of their complexity.
Reference: [ Kearns and ???, 1994 ] <institution> David Kearns and ??? Learning ??? ??? MIT press, Cambridge, Massachusetts, </institution> <year> 1994. </year>
Reference-contexts: We do so for two reasons: on one hand, DFS strategies have been accepted widely as a model of bounded rationality. On the other hand, learning the structure of an automaton has been shown to be a very hard problem <ref> [ Kearns and ???, 1994 ] </ref> . We focused, as an example, on the repeated game of The Prisoner's Dilemma (Fig. 2). However, most, if not all, of our results can easily be generalized to a wider class of two-person non-zero-sum games. <p> In such a model, players have to learn non-fixed strategies. Furthermore, players may attempt to manipulate each other's learning process. We have shown the existence of a learning algorithm for the class of simple automata, but have not constructed an algorithm. The automata learning literature <ref> [ Rivest and Schapire, 1993; Kearns and ???, 1994 ] </ref> shows how to construct such algorithms, when "homing sequences" are available input sequences that guarantee a certain state is reached.
Reference: [ Mor and Rosenschein, 1994 ] <author> Yishay Mor and Jeffrey S. Rosenschein. </author> <title> Time and the prisoner's dilemma, </title> <booktitle> 1994. Submited to the 1995 International Conference on Multiagent Systems. </booktitle>
Reference-contexts: Connected automata are such that have no disjoint states, i.e. for any states i; j there is an input sequence that leads from i to j. Another way to avoid unrevertable actions is to allow players to opt out (see <ref> [ Mor and Rosenschein, 1994; Mor, 1995 ] </ref> ). 2 Notice that if &lt; ff; fi &gt; is not a Nash equilibrium point then it cannot be supported 3 Polynomial Time Design of an Automaton Strategy Theorem 1 9A Q Q i *-supports &lt; ff; fi &gt; .(where * = c
Reference: [ Mor, 1995 ] <author> Yishay Mor. </author> <title> Computational approaches to rational choice. </title> <type> Master's thesis, </type> <institution> Hebrew University, </institution> <year> 1995. </year> <note> In preparation. </note>
Reference-contexts: Connected automata are such that have no disjoint states, i.e. for any states i; j there is an input sequence that leads from i to j. Another way to avoid unrevertable actions is to allow players to opt out (see <ref> [ Mor and Rosenschein, 1994; Mor, 1995 ] </ref> ). 2 Notice that if &lt; ff; fi &gt; is not a Nash equilibrium point then it cannot be supported 3 Polynomial Time Design of an Automaton Strategy Theorem 1 9A Q Q i *-supports &lt; ff; fi &gt; .(where * = c
Reference: [ Neyman, 1985 ] <author> A. Neyman. </author> <title> Bounded complexity justifies cooperation in finitely repeated prisoner's dilemma. </title> <journal> Economic Letters, </journal> <pages> pages 227-229, </pages> <year> 1985. </year>
Reference-contexts: A D C P S T R 1.1 Related Work Finite automata players were suggested as a model of bounded rationality, and as a means of resolving the prisoner's dilemma paradox, by Rubinstein [ Rubinstein, 1985 ] and by Neyman <ref> [ Neyman, 1985 ] </ref> . An extensive survey of the relevant literature appears in [ Kalai, 1990 ] . The basic concept underlying this trend is that the players are rational, but are constrained to submit automata of limited size as their agents in the game. <p> We will always interpret the notion of equilibrium with respect to the set of strategies available to each player. For instance, in the repeated PD game, if all players are rational, the only equilibrium is mutual defection throughout the game. However Neyman <ref> [ Neyman, 1985 ] </ref> , Rubinstein [ Rubinstein, 1985 ] and others have shown that even if only one player is restricted to an Automaton with a limited number of states, any payoff pair in the Individually Rational Region (Fig. 4) can be accomplished as an equilibrium payoff.
Reference: [ Papadimitriou, 1992 ] <author> Christos H. Papadimitriou. </author> <title> On players with a bounded ,number of states. </title> <journal> Games and Economic Behavior, </journal> <volume> 4 </volume> <pages> 122-131, </pages> <year> 1992. </year>
Reference-contexts: This line of work is, in a sense, contrapositional to other common measures of complexity. Papadim-itriou <ref> [ Papadimitriou, 1992 ] </ref> has shown that as the bound on the number of states of the automaton becomes more restrictive, the problem of designing the optimal automaton becomes harder. Fortnow and Whang [ Fortnow and Whang, 1994 ] were the first to assume total ignorance of the opponent's automaton.
Reference: [ Rivest and Schapire, 1993 ] <author> R. Rivest and R. Schapire. </author> <title> Inference of finite automata using homing sequences. </title> <journal> Information and Computation, </journal> <volume> 103 </volume> <pages> 299-347, </pages> <year> 1993. </year>
Reference-contexts: In such a model, players have to learn non-fixed strategies. Furthermore, players may attempt to manipulate each other's learning process. We have shown the existence of a learning algorithm for the class of simple automata, but have not constructed an algorithm. The automata learning literature <ref> [ Rivest and Schapire, 1993; Kearns and ???, 1994 ] </ref> shows how to construct such algorithms, when "homing sequences" are available input sequences that guarantee a certain state is reached.
Reference: [ Roth et al., 1991 ] <author> Alvin E. Roth, Vesna Prasnikar, Mashiro Okuno-Fujiwara, and Shmuel Zamir. </author> <title> Bargin-ing and market behavior in jerusalem, ljubljana, pitts-burg, and tokyo: an experimantal study. </title> <booktitle> In ???, pages 1068-1095, </booktitle> ???, <year> 1991. </year> ??? 
Reference-contexts: But, if B would have played so, A could have taken advantage of that and play D 5 this observation coincides with empirical data on human behavior <ref> [ Roth et al., 1991 ] </ref> Learn (Q): Play C If payoff = S then LearnSR (Q) else LearnRT (Q) LearnSR (Q): For i=1 to 1 f Play C for 2 i times Play D for 4 i times g LearnRT (Q): K R = 0 Repeat f Play C for
Reference: [ Rubinstein, 1985 ] <author> A. Rubinstein. </author> <title> Finite automata play the repeated prisoner's dilemma. </title> <type> ST/ICERD Discussion Paper 85/109, </type> <institution> London School of Economics, </institution> <year> 1985. </year>
Reference-contexts: A D C P S T R 1.1 Related Work Finite automata players were suggested as a model of bounded rationality, and as a means of resolving the prisoner's dilemma paradox, by Rubinstein <ref> [ Rubinstein, 1985 ] </ref> and by Neyman [ Neyman, 1985 ] . An extensive survey of the relevant literature appears in [ Kalai, 1990 ] . <p> We will always interpret the notion of equilibrium with respect to the set of strategies available to each player. For instance, in the repeated PD game, if all players are rational, the only equilibrium is mutual defection throughout the game. However Neyman [ Neyman, 1985 ] , Rubinstein <ref> [ Rubinstein, 1985 ] </ref> and others have shown that even if only one player is restricted to an Automaton with a limited number of states, any payoff pair in the Individually Rational Region (Fig. 4) can be accomplished as an equilibrium payoff.
References-found: 12

