URL: ftp://ftp.isi.edu/pub/hpcc-papers/touch/prior/wpe2.ps.Z
Refering-URL: http://www.isi.edu/~touch/pubs/
Root-URL: http://www.isi.edu
Email: touch@cis.upenn.edu  
Title: Replication and Reduction in Multistage Interconnection Networks  
Author: Joseph D. Touch 
Note: This work supported by Bell Communications Research (Morristown, NJ), under the DAWN Project.  
Address: Philadelphia, PA 19104-6389  
Affiliation: Department of Computer and Information Science University of Pennsylvania  
Date: November 10, 1989  
Abstract: Multistage interconnection networks are conventionally composed of 2x2 switching elements which perform only permutation functions. A number of networks have been built which provide more powerful switch functions involving replication and reduction of information, including the NYU Ultracomputer and several copy networks. Here we investigate these machines as a group, to see how replication and reduction are interrelated, and what other issues they involve. 
Abstract-found: 1
Intro-found: 1
Reference: [ B a 6 8 ] <author> K.E. Batcher, </author> <title> Sorting Networks and Their Applications, </title> <booktitle> AFIPS Spring Joint Computer Conf. Proceedings, </booktitle> <year> 1968, </year> <month> p307-314. </month>
Reference: [ B e 6 2 ] <author> V.E. </author> <title> Benes, On Rearrangeable ThreeStage Connecting Networks, </title> <journal> Bell System Technical Journal, </journal> <month> Sept. </month> <year> 1962, </year> <month> p1481-1492. </month>
Reference: [ B r M W 8 5 ] <author> W.C. Brantley, K.P. McAuliffe, and J. Weiss, </author> <title> RP3 Processor-Memory Element, </title> <booktitle> IEEE Proc. 1985 Int'l. Conf. on Parallel Processing, </booktitle> <address> p782-789. </address>
Reference: [ B u T 8 9 ] <author> R.G. Bubenik and J.S. Turner, </author> <title> Performance of a Broadcast Packet Switch, </title> <journal> IEEE Transactions on Communications, </journal> <volume> Vol. 37 No. 1, </volume> <month> Jan. </month> <year> 1989, </year> <month> p60-69. </month>
Reference: [ C h 8 2 ] <author> E.J.H. Chang, </author> <title> Echo algorithms: depth parallel operations of graphs, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. SE-8 No. 4, </volume> <month> Jul. </month> <year> 1982, </year> <month> p310-400. </month>
Reference: [C hM8 4] <author> K.M. Chandy and J. Misera, </author> <title> The Drinking Philosophers Problem, </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol.6 No 4, </volume> <month> Oct. </month> <journal> 1984, </journal> <volume> p 6 3 2 - 6 4 6 </volume> . 
Reference: [ C l 5 3 ] <author> C. </author> <title> Clos, A Study of Non-Blocking Switching Networks, </title> <journal> Bell System Technical Journal, </journal> <month> Mar. </month> <year> 1953, </year> <month> p407-424. </month>
Reference: [DaT89] <author> G.E. Daddis and H.C. Torng, </author> <title> A Taxonomy of Broadband Integrated Switching Architectures, </title> <journal> IEEE Communications Magazine,Vol. </journal> <volume> 27 No. </volume> <month> 5,May </month> <year> 1989, </year> <month> p32-42. </month>
Reference-contexts: The design of these networks provides some of the functions of a completely-connected network (a crosspoint), with less overall switch elements (N log (N) for most MINs, v.s. N 2 for a crosspoint) <ref> [DaT89] </ref> [De89] [WuF80]. There are a few canonical organizations of these networks, including recursively factored topologies [Cl53] and self-routing organizations [Be62].
Reference: [ D e 8 9 ] <author> W. Denzel, </author> <title> Switching Fabrics for High Speed, </title> <booktitle> IBM European Summer Symposium on Very High Speed Networks - Garmisch FRG, </booktitle> <year> 1989. </year>
Reference: [ D i K 8 9 ] <author> D.M. Dias and M. Kumar, </author> <title> Preventing Congestion in Multistage Networks in the Presence of Hotspots, </title> <booktitle> IEEE Proc. 1989 Int'l. Conf. on Parallel Processing, </booktitle> <volume> Vol. 1, p 9 - 1 3 </volume> . 
Reference: [EdGK85] <author> J. Edler, A. Gottlieb, C.P. Kruskal, K.P. McAuliffe, L. Rudolph, M. Snir, P.J. Teller, and J. Wilson, </author> <title> Issues Related to MIMD Shared-memory Computers: the NYU Ultracomputer Approach, </title> <booktitle> IEEE Twelfth Annual Symposium on Computer Architecture, </booktitle> <year> 1985, </year> <month> p126-135. </month>
Reference-contexts: This is known as limited access [YewTL87], but also called a blocking request. Blocking requests is necessary in buffered combining networks, since otherwise requests could combine and pass each other in a way which would not be ultimately serializable <ref> [EdGK85] </ref>. 2.5. Consistency Central to the notion of the ability to reduce or multicast packets in a network is the definition of consistency. <p> Louis (WashU) [Tu88] incorporate multicast facilities. 3.1. The NYU Ultracomputer reduction network The NYU Ultracomputer [GotGK83] [Sc80] [Kr82] [GotLR83] [Got84] <ref> [EdGK85] </ref> [LegKK86] is a shared memory link-buffered network, supporting fetch-op memory access. The original design is based on an implementation of Schwartzs Ultracomputer model [Sc80]. The network combines requests of the fetch-op type. <p> The memory interface also provides the arithmetic facilities for supporting the fetch-op primiti ves. Later analyses of the design attempt to reduce the complexity of the switch element and provide extended network functions <ref> [EdGK85] </ref>. Some of the simplifications involve supporting only 1 7 combinations that do not require intermediate storage, such as store/store and store/fetch-op combines. Implementing combination only at later stages in the network and restricting combinations to pairs only (2-way combine) were also considered. <p> There were also analyses which note that 2-way combining is not sufficient for sample problems [LegKK86], and note that 3-way combining would suffice. Two extensions to the design were proposed <ref> [EdGK85] </ref>: reflection and refraction (Figure 14). Reflection uses a virtual address in a memory module and an active memory interface to redirect a request from a PE to that module to another PE, supporting automatic forwarding of a request.
Reference: [EnHY88] <author> K.Y. Eng, M.G. Hluchyj, and Y.S. Yeh, </author> <title> Multicast and Broadcast Services in a Knockout Packet Switch, </title> <booktitle> 1988 IEEE Infocom, </booktitle> <address> p29-34. </address>
Reference-contexts: The parent is acknowledged when all children have returned acknowledgements, a kind of broadcast/reduction algorithm on acknowledgements, such that broadcast atomicity is ensured. Other methods of multicasting are based on serial addressing and emission of packets at the source. Many assume multipoint connections, such as the Knockout <ref> [EnHY88] </ref>, or an Ethernet or token ring global-read bus [GopJ84]. A serial collection of acknowledgements, akin to the echo of the echo algorithm above, provides atomicity of the broadcast. Software algorithms for reduction have confirmed results from reduction network analyses. <p> Machines There are several other machines which analyze reduction and replication in processor networks. These include the BBN Butterfly, and the IBM RP3 reduction network, the Starlite which supports copying [HuaK84], and the Knockout [YehHA87] <ref> [EnHY88] </ref>. 4.3.1. The BBN Butterfly The BBN Butterfly is an unbuffered shared memory network [Th86] [HoE89] [Mel88]. While there is an extension of the Butterfly, known as the Monarch, which is suspected of having multicast capabilities, information on that system was not available in time for this report. <p> SORT MERGE SWAP ROUTE DATA PACKETS DUMMY PACKETS DELIVERED D A T A NACK's 4.3.4. The AT&T Bell Labs Knockout multicast-capable network The Knockout network is not a MIN network, but its design does incorporate multicast capability, and is useful for comparison [YehHA87] <ref> [EnHY88] </ref>. The network is fully connected, in a multiple bus configuration, and supports packet switched communication (Figure 28). Multicast Module Regular Module Multicast Module 3 5 The switch is composed of a set of busses, one from each PE, and a bus-collection device, a Knockout concentrator, one into each PE. <p> There has been an extension recently suggested for the Knockout network which would support multicast requests <ref> [EnHY88] </ref>. It is composed of multicast modules on the Knockout bus, much like concentrators with internal processors, but without host PEs (also Figure 28).
Reference: [ F l 6 6 ] <author> M.J. Flynn, </author> <booktitle> Very HighSpeed Computing Systems, Proc. of the IEEE, </booktitle> <volume> Vol. 54 No. 12, </volume> <month> Dec. </month> <year> 1966, p1901-1909. </year>
Reference: [GopJ84] <author> I.S. Gopal and J.M. Jaffe, </author> <title> Point-to-Multipoint Communication Over Broadcast Links, </title> <journal> IEEE Transactions on Communications, </journal> <volume> Vol. COM-32 No. 9, </volume> <booktitle> Sept. 1984, </booktitle> <volume> p 1 0 3 4 - 1 0 4 4 </volume> . 
Reference-contexts: Multicasts are often accompanied by reduction operations, in order to facilitate multiway group interaction [Tu87b], collect acknowledgements from the multicast receivers [Kat87], or support multicast flow control [Tu88]. These reduction operations can be reduction versions of Changs echo algorithm [Ch82], or a serial collection of replies <ref> [GopJ84] </ref>, as well as a hardware reduction as defined later. 1 0 In addition, some multicast methods provide for easy addition and deletion of members of a multicast set, called dynamic multicasting [Tu88]. Other schemes provide such updating at a much higher cost, or not at all (static multicast). 2.4. <p> Other methods of multicasting are based on serial addressing and emission of packets at the source. Many assume multipoint connections, such as the Knockout [EnHY88], or an Ethernet or token ring global-read bus <ref> [GopJ84] </ref>. A serial collection of acknowledgements, akin to the echo of the echo algorithm above, provides atomicity of the broadcast. Software algorithms for reduction have confirmed results from reduction network analyses.
Reference: [Got84] <author> A. Gottlieb, </author> <title> Avoiding Serial Bottlenecks in Ultraparallel MIMD Computers, </title> <booktitle> IEEE Compcon, 1984, p354-359. </booktitle> <volume> 4 0 </volume>
Reference-contexts: The distributed processing of central data can also benefit from the use of reduction, in a way which translates serial code into a parallelizable equivalent <ref> [Got84] </ref>. In this way, limitations in algorithm speedup proscribed by Amdahls Law * can be circumnavigated. In order to perform a reduction, a composition function must be defined at the switch level. <p> Louis (WashU) [Tu88] incorporate multicast facilities. 3.1. The NYU Ultracomputer reduction network The NYU Ultracomputer [GotGK83] [Sc80] [Kr82] [GotLR83] <ref> [Got84] </ref> [EdGK85] [LegKK86] is a shared memory link-buffered network, supporting fetch-op memory access. The original design is based on an implementation of Schwartzs Ultracomputer model [Sc80]. The network combines requests of the fetch-op type.
Reference: [GotGK83] <author> A. Gottlieb, R. Grishman, C.P. Kruskal, K.P. McAuliffe, L. Rudolph, and M. Snir, </author> <title> The NYU Ultracomputer- Designing an MIMD Shared Memory Parallel Computer, </title> <journal> IEEE Transactions on Computers,Vol. </journal> <volume> C-32 No. 2, </volume> <month> Feb. </month> <journal> 1983, </journal> <volume> p 1 7 5 - 1 8 9 </volume> . 
Reference-contexts: 1. Introduction Multistage interconnection networks are composed of series of stages of regularly connectioned switching elements (usually 2x2). In conventional architectures, these networks support only permutation functions in their switch elements, although several notable exceptions have capitalized on other switch functions. These include the reduction capability of the NYU Ultracomputer <ref> [GotGK83] </ref> and the replication capability of copy networks [Let88] [Tu88] [BuT89]. Here we investigate the two non-permutation functions of reduction and replication as a unified discipline, and consider the interrelationship between the two functions, as well as the common difficulties in their realization. <p> Shared memory can be considered message passing between memory and processors, so the distinctions are often not obvious. Some message passing systems include the Starlite and its descendants [HuaK84] [LetBA88] [Tu88], the Cosmic Cube, and the BBN Butterfly [Th86] [Mel88], whereas the NYU Ultracomputer <ref> [GotGK83] </ref> and RP3 [PfBG85] are shared memory systems. The Starlite (and its descendants) are actually developed as packet switched networks, but the principles of packet switching are similar to message passing in MIMD distributed systems. <p> Reduction, also known as network combining, is used for reducing hotspot memory contention in the NYU Ultracomputer <ref> [GotGK83] </ref>, distributed management of locks in the RP3 [PfN85], and eliminating serial access to distributed data structures. The distributed processing of central data can also benefit from the use of reduction, in a way which translates serial code into a parallelizable equivalent [Got84]. <p> It has been shown that for reasonable systems, 3-way combining is sufficient [HoE89], even though many systems support only 2-way combining, such as the NYU and RP3 <ref> [GotGK83] </ref> [Tz89] [LegKK86]. 1 2 Fetch-op (address,value) = Replace-op (address,value) op -1 value Replace-op (address,value) = Fetch-op (address,value) op value Store (address,value) * = Fetch- 2 ( a dd r e ss,v al u e) Load (address) value = Fetch- 1 ( ad dr ess,* ) where 1 (x,y)=x and 2 <p> A fixed delay is required for many fault tolerant voting schemes, which use timeout to assume the effective loss of communication. 1 4 3. Canonical reduction and multicast networks There have been several implementations of reduction and multicast networks; the NYU Ultracomputer <ref> [GotGK83] </ref> is the original reduction network, and only two recent networks, by Bell Communications Research (Bellcore) [Let88] and the University of Washington at St. Louis (WashU) [Tu88] incorporate multicast facilities. 3.1. The NYU Ultracomputer reduction network The NYU Ultracomputer [GotGK83] [Sc80] [Kr82] [GotLR83] [Got84] [EdGK85] [LegKK86] is a shared memory link-buffered <p> been several implementations of reduction and multicast networks; the NYU Ultracomputer <ref> [GotGK83] </ref> is the original reduction network, and only two recent networks, by Bell Communications Research (Bellcore) [Let88] and the University of Washington at St. Louis (WashU) [Tu88] incorporate multicast facilities. 3.1. The NYU Ultracomputer reduction network The NYU Ultracomputer [GotGK83] [Sc80] [Kr82] [GotLR83] [Got84] [EdGK85] [LegKK86] is a shared memory link-buffered network, supporting fetch-op memory access. The original design is based on an implementation of Schwartzs Ultracomputer model [Sc80]. The network combines requests of the fetch-op type. <p> Preliminary Ultracomputer documents support the superiority of fetch-op to replace-op [GotK81], since replace-op is always computable from fetch-op results, while the converse is true only for invertible op functions, but subsequent discussions assume use of replace-op functions [Kr82] [GotLR83], up until the final implementation described in <ref> [GotGK83] </ref>. The switch elements are composed of a buffer on each output port, and on each input port as well, to service reverse-flow multicast replies.
Reference: [GotK81] <author> A. Gottlieb and C.P. Kruskal, </author> <title> Coordinating Parallel Processors: A Partial Unification, </title> <journal> ACM Computer Architecture News, </journal> <volume> Vol.9, </volume> <month> Oct. </month> <year> 1981, </year> <month> p16-24. </month>
Reference-contexts: Replace-add operations are requests which replace a memory location with a sum, and return the new value (Figure 7). Fetch-add operations are similar, returning the previous memory value instead. While add is the function describing these operations, any associative operation (op) can be specified <ref> [GotK81] </ref>. The equivalent result of a replace-op can be computed from the result of a fetch-op, but the reverse (computing fetch-op from the result of a replace-op) is true only for functions with an inverse [GotK81]. <p> While add is the function describing these operations, any associative operation (op) can be specified <ref> [GotK81] </ref>. The equivalent result of a replace-op can be computed from the result of a fetch-op, but the reverse (computing fetch-op from the result of a replace-op) is true only for functions with an inverse [GotK81]. For example, replace-min can be computed from fetch-min, but fetch-min cannot be computed from replace-min, since min has no inverse. There are also equivalences for testand-set primitives and simple load and store operations in terms of either fetch-op or replace-op functions. <p> The original design is based on an implementation of Schwartzs Ultracomputer model [Sc80]. The network combines requests of the fetch-op type. Preliminary Ultracomputer documents support the superiority of fetch-op to replace-op <ref> [GotK81] </ref>, since replace-op is always computable from fetch-op results, while the converse is true only for invertible op functions, but subsequent discussions assume use of replace-op functions [Kr82] [GotLR83], up until the final implementation described in [GotGK83].
Reference: [GotLR83] <author> A. Gottlieb, B.D. Lubachevsky, and L. Rudolph, </author> <title> Basic Techniques for the Efficient Coordination of Very Large Numbers of Cooperating Sequential Processors, </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 5 No. 2, </volume> <month> Apr. </month> <journal> 1983, </journal> <volume> p 1 6 4 - 1 8 9 </volume> . 
Reference-contexts: Louis (WashU) [Tu88] incorporate multicast facilities. 3.1. The NYU Ultracomputer reduction network The NYU Ultracomputer [GotGK83] [Sc80] [Kr82] <ref> [GotLR83] </ref> [Got84] [EdGK85] [LegKK86] is a shared memory link-buffered network, supporting fetch-op memory access. The original design is based on an implementation of Schwartzs Ultracomputer model [Sc80]. The network combines requests of the fetch-op type. <p> The network combines requests of the fetch-op type. Preliminary Ultracomputer documents support the superiority of fetch-op to replace-op [GotK81], since replace-op is always computable from fetch-op results, while the converse is true only for invertible op functions, but subsequent discussions assume use of replace-op functions [Kr82] <ref> [GotLR83] </ref>, up until the final implementation described in [GotGK83]. The switch elements are composed of a buffer on each output port, and on each input port as well, to service reverse-flow multicast replies.
Reference: [HaMS86] <author> J.P. Hayes, T. Mudge, and Q.F. Stout, </author> <title> A Microprocessor-based Hypercube Supercomputer, </title> <booktitle> IEEE Micro, </booktitle> <month> Oct. </month> <year> 1986, </year> <month> p6-16. </month>
Reference-contexts: These two operations support distributed objects [Tu87d] and reduce the amount of memory accesses to retrieve global (common) information <ref> [HaMS86] </ref>. Note that in each case the MIN can be used to perform the desired operation, provided the replication occurs in a way which distinguishes the copies - completely identical copies would arrive at the same output port, where multicast delivers distinct copies to distinct addresses.
Reference: [HocJ86] <author> R.C. Hockney and C.R. Jessope, </author> <title> Parallel Computers, </title> <publisher> Adam Hilger Ltd., </publisher> <address> Bristol, </address> <year> 1986, </year> <month> p158-178,261-265. </month>
Reference-contexts: While the RAN proposed in [Let88] uses Nary electrical fanout to compute the sums in logN time, a binary fanout cascaded sum network can compute the same partial sum in logN time as well [To87] <ref> [HocJ86] </ref>.
Reference: [HoE89] <author> W.S. Ho and D.L. Eager, </author> <title> A Novel Strategy for Controlling Hot Spot Congestion, </title> <booktitle> IEEE Proc. 1989 Int'l. Conf. on Parallel Processing, </booktitle> <volume> Vol. 1, </volume> <month> p14-18. </month>
Reference-contexts: In the simplest case, the function is a selection - thus omitting one of the two packets, and presenting the other as output. This function is the method of reduction in some networks which approximate the effects of contention resolution via omission <ref> [HoE89] </ref>, and also used to explain the dropping of packets which occurs in unbuffered blocking networks, like the BBN Butterfly [ T h 8 6 ] . * Amdahls Law states that if k% of an algorithm is serial (not parallelizeable), then the optimal acceleration would reduce all parallel code to <p> This same buffering can retard the passage of the combined packet, providing the possibility of combining the result of a combine with another incoming packet, known as n-way combining. It has been shown that for reasonable systems, 3-way combining is sufficient <ref> [HoE89] </ref>, even though many systems support only 2-way combining, such as the NYU and RP3 [GotGK83] [Tz89] [LegKK86]. 1 2 Fetch-op (address,value) = Replace-op (address,value) op -1 value Replace-op (address,value) = Fetch-op (address,value) op value Store (address,value) * = Fetch- 2 ( a dd r e ss,v al u e) Load <p> Software algorithms for reduction have confirmed results from reduction network analyses. Among these, the need for at least 3-way combination at the switch element and the use of discarding as reduction have been studied in software <ref> [HoE89] </ref>. Some of these techniques do not implement a software multicast to distribute information from replies in reverse, as the hardware reduction schemes tend to. <p> These include the BBN Butterfly, and the IBM RP3 reduction network, the Starlite which supports copying [HuaK84], and the Knockout [YehHA87] [EnHY88]. 4.3.1. The BBN Butterfly The BBN Butterfly is an unbuffered shared memory network [Th86] <ref> [HoE89] </ref> [Mel88]. While there is an extension of the Butterfly, known as the Monarch, which is suspected of having multicast capabilities, information on that system was not available in time for this report. <p> So the comparison of these techniques is not valid, although several attempts have been made [Th86] <ref> [HoE89] </ref> [DiK89]. 2 9 4.3.2. The IBM RP3 reduction network The IBM RP3 is a shared memory reduction network, similar to the NYU Ultracomputer in its switch element design, but with special emphasis on the use of caches [PfN85] [PfBG85] [BrMW85] [DiK89].
Reference: [HuaK84] <author> A. Huang and S. Knauer, STARLITE: </author> <title> A Wideband Digital Switch, </title> <booktitle> IEEE Globecom, </booktitle> <year> 1984, </year> <month> p121-125. </month>
Reference-contexts: The number of 4 memory modules and processors need not be equal in either organization. Shared memory can be considered message passing between memory and processors, so the distinctions are often not obvious. Some message passing systems include the Starlite and its descendants <ref> [HuaK84] </ref> [LetBA88] [Tu88], the Cosmic Cube, and the BBN Butterfly [Th86] [Mel88], whereas the NYU Ultracomputer [GotGK83] and RP3 [PfBG85] are shared memory systems. <p> Another contention resolution scheme is to route one of the two packets to the wrong (idle) output port, assuming it will be stored in a shared internal buffer at some later point, and recirculated through the network via a feedback path, as in the Starlite <ref> [HuaK84] </ref>. A collision occurs when no internal buffering is provided, and one of the two packets is simply lost, as is done in the BBN Butterfly [Mel88]. <p> Buffering also destroys the relative alignment of packets, which can destroy consistency requirements of some multicasts (seen later). This prevents ganging the inputs together, which providing a greater bandwidth via parallel use of input lines <ref> [HuaK84] </ref>. The constant internal latency afforded by unbuffered networks permits such grouping without requiring downstream realignment of a set of grouped packets. Internally non-blocking networks are divided into two cases: completely non-blocking and rearrangeably non-blocking. <p> Other more complicated patterns include the combination of a copy and a reduce <ref> [HuaK84] </ref>, of which there are four configurations (the Starlite uses only the Z and inverse Z configurations [HuaK84]), and the two copies and two reduces resulting in a complete intermix of information in the packets. The lone latter configuration has never been observed in a switch design. <p> Other more complicated patterns include the combination of a copy and a reduce <ref> [HuaK84] </ref>, of which there are four configurations (the Starlite uses only the Z and inverse Z configurations [HuaK84]), and the two copies and two reduces resulting in a complete intermix of information in the packets. The lone latter configuration has never been observed in a switch design. Since there are 4 links in a switch element, there are 16 possible configurations. <p> The connectivity of a Batcher, however, is the same as that of a banyan, requiring more stages of the same topology <ref> [HuaK84] </ref>. The switch elements in an unbuffered network are very simple, but the WashU elements require an additional 240 Kilobits of storage per element, so the complexity gain by using buffering is not convincingly demonstrated. <p> The sequence sorts the packets by destination; if a packet has the same destination as the packet above it (a local computation), then that packet is tagged as a collision. These collisions can be filtered out by a trap network, and routed for recirculation, as in the Starlite <ref> [HuaK84] </ref>. The remaining packets (which thus cannot collide at the output ports) can be routed with a banyan network, also as in the Starlite. <p> While the TNT tables are thus larger than in the WashU design, Bellcores copy network is nonblocking and unbuffered; as a result, input port ganging <ref> [HuaK84] </ref> is possible in this network. In order to perform the copying without contention, each multicast request is translated to a request for a contiguous span of output ports by the Running Adder Network (RAN) and Dummy Address Encoder. <p> In fact, the observed complexity of the algorithm is identical to the hardware complexity of the Bellcore switch. This was also the earliest reference which notes that a banyan network performs a distribution routing on a set of sorted packets, an observation first implemented in the Starlite <ref> [HuaK84] </ref>. Some algorithms also use variations of Changs echo algorithm to distribute packet replicates [Ch82]. The echo algorithm was originally proposed as a way to provide software checkpointing in a distributed system, where packets are broadcast in a breadth-first tree through the network. <p> Machines There are several other machines which analyze reduction and replication in processor networks. These include the BBN Butterfly, and the IBM RP3 reduction network, the Starlite which supports copying <ref> [HuaK84] </ref>, and the Knockout [YehHA87] [EnHY88]. 4.3.1. The BBN Butterfly The BBN Butterfly is an unbuffered shared memory network [Th86] [HoE89] [Mel88]. <p> The AT&T Starlite multicast network The AT&T Starlite network is a packet network, similar to a message passing network. It is composed of a centrally-buffered recirculation network, the main path of which is an unbuffered Batcher-banyan network, as was seen in the related Bellcore network <ref> [HuaK84] </ref> (Figure 24).
Reference: [ H u i A 8 7 ] <author> J.Y. Hui and E. Arthurs, </author> <title> A Broadband Packet Switch for Integrated Transport, </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> Vol. SAC-5 No. 8, </volume> <month> Oct. </month> <journal> 1987, </journal> <volume> p 1 2 6 4 - 1 2 7 3 </volume> . 
Reference: [ J i P 8 5 ] <author> L. Jin and Y. Pan, </author> <title> A Kind of Interconnection Network with Mixed Static and Dynamic Topologies, </title> <booktitle> 1985 IEEE Int'l. Conf. on Distributed Computing Systems, </booktitle> <volume> p 1 6 0 - 1 6 6 </volume> . 
Reference: [KapK 89] <author> M.A. Kaplan and B. Kadaba, </author> <title> High Speed Networking at IBM Watson Research, </title> <booktitle> IBM European Summer Symposium on Very High Speed Networks - Garmisch FRG, </booktitle> <volume> 1 9 8 9 </volume> . 
Reference: [ K a t 8 7 ] <author> H.P. Katseff, </author> <title> Flow-Controlled Multicast In Microprocessor Systems, </title> <booktitle> 1987 IEEE Phoenix Conf. on Computers and Communications, </booktitle> <address> p8-13. </address>
Reference: [ K h T 8 7 ] <author> S. Khakoo and J.S. Turner, </author> <title> System Testing of a Broadcast Packet Switch, </title> <institution> Washington University Technical Report WUCS-87-4, </institution> <month> Apr. </month> <year> 1987. </year>
Reference: [ K r 8 2 ] <author> C.P. Kruskal, </author> <title> Algorithms for Replace-Add Based Paracomputers, </title> <booktitle> IEEE Proc. 1982 Int'l. Conf. on Parallel Processing, </booktitle> <address> p219-223. </address>
Reference: [ K u P 8 6 ] <author> M. Kumar and G.F. Pfister, </author> <title> The Onset of Hot Spot Contention, </title> <booktitle> IEEE Proc. 1986 Int'l. Conf. on Parallel Processing, </booktitle> <address> p28-34. </address>
Reference: [LegKK86] <author> G. Lee, </author> <title> C.P. Kruskal, and D.J. Kuck, The Effectiveness of Combining in Shared Memory Parallel Computers in the Presence of Hot Spots, </title> <booktitle> IEEE Proc. 1986 Int'l. Conf. on Parallel Processing, p35-41. </booktitle> <volume> 4 1 </volume>
Reference-contexts: It has been shown that for reasonable systems, 3-way combining is sufficient [HoE89], even though many systems support only 2-way combining, such as the NYU and RP3 [GotGK83] [Tz89] <ref> [LegKK86] </ref>. 1 2 Fetch-op (address,value) = Replace-op (address,value) op -1 value Replace-op (address,value) = Fetch-op (address,value) op value Store (address,value) * = Fetch- 2 ( a dd r e ss,v al u e) Load (address) value = Fetch- 1 ( ad dr ess,* ) where 1 (x,y)=x and 2 (x,y)=y Some <p> Louis (WashU) [Tu88] incorporate multicast facilities. 3.1. The NYU Ultracomputer reduction network The NYU Ultracomputer [GotGK83] [Sc80] [Kr82] [GotLR83] [Got84] [EdGK85] <ref> [LegKK86] </ref> is a shared memory link-buffered network, supporting fetch-op memory access. The original design is based on an implementation of Schwartzs Ultracomputer model [Sc80]. The network combines requests of the fetch-op type. <p> There were also analyses which note that 2-way combining is not sufficient for sample problems <ref> [LegKK86] </ref>, and note that 3-way combining would suffice. Two extensions to the design were proposed [EdGK85]: reflection and refraction (Figure 14).
Reference: [ L e r 8 5 ] <author> R. Lee, </author> <title> On hot spot contention, </title> <journal> ACM Computer Architecture News, </journal> <volume> Vol. 13, </volume> <month> Dec. </month> <year> 1985, </year> <month> p15-20. </month>
Reference: [ L e t 8 8 ] <author> T.T. Lee, </author> <title> Nonblocking Copy Networks for Multicast Packet Switching, </title> <journal> IEEE Journal on Selected Areas of Communications, </journal> <volume> Vol. 6 No. 9, </volume> <month> Dec. </month> <journal> 1988, </journal> <volume> p 1 4 5 5 - 1 4 6 7 </volume> . 
Reference: [LetBA88] <author> T.T. Lee, R. Boorstyn, and E. Arthurs, </author> <title> The Architecture of a Multicast Broadband Packet Switch, </title> <booktitle> 1988 IEEE Infocom, </booktitle> <address> p1-8. </address>
Reference-contexts: The number of 4 memory modules and processors need not be equal in either organization. Shared memory can be considered message passing between memory and processors, so the distinctions are often not obvious. Some message passing systems include the Starlite and its descendants [HuaK84] <ref> [LetBA88] </ref> [Tu88], the Cosmic Cube, and the BBN Butterfly [Th86] [Mel88], whereas the NYU Ultracomputer [GotGK83] and RP3 [PfBG85] are shared memory systems. The Starlite (and its descendants) are actually developed as packet switched networks, but the principles of packet switching are similar to message passing in MIMD distributed systems. <p> A Batcher sorter can precede the banyan router, resulting in a Batcher-banyan, so that the Batcher maintains the monotonicity and gap-free constraints required for the banyan router to be non 7 blocking, and the router delivers the sorted packets to their final destinations [Let88] <ref> [LetBA88] </ref>. In a buffered banyan, buffers are included in the switch elements, where packets are stored when contention occurs, and retransmitted when the desired output port is otherwise idle. <p> The Bell Communications Research multicast network The Bell Communications Research (Bellcore) multicast switch is composed of a two-phase unbuffered banyan copy network followed by an unbuffered Batcher-banyan routing network [Let88] [HuiA87] <ref> [LetBA88] </ref> (Figure 17). This switch, like the WashU switch, is a packet network, and is not intended for direct MIMD multiprocessor systems, although the principles are similar. <p> Other extensions and modifications of the network have been proposed, which include the use of two distinct classes of traffic (reserved, connection / unreserved, connectionless), where there are separate copy networks for each traffic type <ref> [LetBA88] </ref>. Since connection-oriented traffic avoids copy network overflow at call setup time, its network can be simpler and faster, and can avoid overflow loss completely.
Reference: [ M e l 8 8 ] <author> J.M. Mellor-Crummey, </author> <title> Experiences with the BBN Butterfly, </title> <booktitle> IEEE Compcon, </booktitle> <year> 1988, </year> <month> p101-104. </month>
Reference: [MenBL87] <author> B. Menezes, D. Brant, D. Loewi, A. Dale, and R. Jenevein,, </author> <title> An Interconnection Network Supporting Relational Join Operations, </title> <booktitle> 1987 IEEE Int'l. Conf. on Distributed Computing Systems, </booktitle> <address> p128-135. </address>
Reference-contexts: Other kinds of networks define the copy and reduce functions to facilitate the purposes of the packets, such as join networks for database manipulations. In these networks, the interconnection networks are structured in a way which facilitates reductions based on database combinations, and the switch elements perform joins internally <ref> [MenBL87] </ref>. Some reduction networks are designed specifically to perform the cascaded sum of the RAN in the Bellcore switch, or other arithmetic tree reductions. These networks are used in fast matrix and vector computers. Although these organizations are not strictly reduction networks, the principles are identical. 3 8 5.
Reference: [ M o 7 9 ] <author> H.P. Moravec, </author> <title> Fully Interconnecting Multiple Computers with Pipelined Sorting Nets, </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol.C-28 No. 10, </volume> <month> Oct. </month> <journal> 1979, </journal> <volume> p 7 9 5 - 7 9 8 </volume> . 
Reference: [NaS81] <author> D. Nassimi and S. Sahni, </author> <title> Data Broadcasting in SIMD Computers, </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. C-30 No. 2, </volume> <month> Feb. </month> <year> 1981, </year> <month> p101-106. </month>
Reference-contexts: This algorithm is named the Boolean Interval Splitting Algorithm therein, and was first described in SIMD multicasting systems <ref> [NaS81] </ref>. The complete sequence of operations in the Bellcore network is similar to that performed in software in this SIMD network, as will be described later. <p> Broadcasting is a facility assumed in most distributed, fault tolerant operating system designs, and many such studies directly address the issue [Wa82]. Examples of multicasting algorithms have been developed for SIMD architectures as well <ref> [NaS81] </ref>. Some of these are related to Bellcores switch, such as [NaS81], while most others use a variation of Changs echo algorithm to distribute replicates [Ch82] [Kat87]. <p> Broadcasting is a facility assumed in most distributed, fault tolerant operating system designs, and many such studies directly address the issue [Wa82]. Examples of multicasting algorithms have been developed for SIMD architectures as well <ref> [NaS81] </ref>. Some of these are related to Bellcores switch, such as [NaS81], while most others use a variation of Changs echo algorithm to distribute replicates [Ch82] [Kat87]. <p> The analysis of the overlap of these spanning trees for simultaneous multicasts and broadcasts [Wa82] is similar to the Boolean Interval Splitting Algorithm of the Bellcore switch [Let88]. In the case of software SIMD multicasting algorithms, there is correlation between the algorithm <ref> [NaS81] </ref> and the current hardware implementation of the Bellcore copy network [Let88] (Figure 21). Even the Boolean Interval Splitting Algorithm is effectively described in [NaS81], as well as the sort-tag-trap-route sequence of the Starlite network, which is also included in the Bellcore switch. <p> In the case of software SIMD multicasting algorithms, there is correlation between the algorithm <ref> [NaS81] </ref> and the current hardware implementation of the Bellcore copy network [Let88] (Figure 21). Even the Boolean Interval Splitting Algorithm is effectively described in [NaS81], as well as the sort-tag-trap-route sequence of the Starlite network, which is also included in the Bellcore switch. In fact, the observed complexity of the algorithm is identical to the hardware complexity of the Bellcore switch.
Reference: [PfBG85] <author> G.F. Pfister, W.C. Brantley, and D.A. George, et.al., </author> <title> The IBM Research Parallel Processor Prototype (RP3): Introduction and Architecture, </title> <booktitle> IEEE Proc. 1985 Int'l. Conf. on Parallel Processing, </booktitle> <address> p764-771. </address>
Reference-contexts: Shared memory can be considered message passing between memory and processors, so the distinctions are often not obvious. Some message passing systems include the Starlite and its descendants [HuaK84] [LetBA88] [Tu88], the Cosmic Cube, and the BBN Butterfly [Th86] [Mel88], whereas the NYU Ultracomputer [GotGK83] and RP3 <ref> [PfBG85] </ref> are shared memory systems. The Starlite (and its descendants) are actually developed as packet switched networks, but the principles of packet switching are similar to message passing in MIMD distributed systems. <p> The IBM RP3 reduction network The IBM RP3 is a shared memory reduction network, similar to the NYU Ultracomputer in its switch element design, but with special emphasis on the use of caches [PfN85] <ref> [PfBG85] </ref> [BrMW85] [DiK89]. The RP3 attempts to justify the use of combining in an unique way, with respect to hotspots. They claim that previous studies have assumed hotspots, and attempted to reduce their effect on the processors contributing to the hotspot contention. <p> In order to cache data, it is assumed that the status of a variable (hot/cool) is known at load time <ref> [PfBG85] </ref>.
Reference: [ P f N 8 5 ] <author> G.F. Pfister and V.A. Norton, </author> <title> Hot Spot Contention and Combining in Multistage Interconnection Networks, </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. C-34 No. 10, </volume> <month> Oct. </month> <year> 1985, </year> <month> p943-948. </month>
Reference: [ R o 8 7 ] <author> G.H. Robbert, </author> <title> Design of a Broadcast Translation Chip, </title> <institution> Washington University Technical Report WUCS-87-9, </institution> <month> Apr. </month> <year> 1987. </year>
Reference: [ S c 8 0 ] <author> J.T. Schwartz, </author> <title> Ultracomputers, </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 2 No. 4, </volume> <month> Oct. </month> <year> 1980, </year> <month> p484-521. </month>
Reference: [ S u B 7 7 ] <author> H. Sullivan and T.R. Bashkow, </author> <title> A Large Scale, Homogeneous, Fully Distributed Parallel Machine, I, </title> <booktitle> IEEE Fourth Annual Symposium on Computer Architecture, </booktitle> <year> 1977, </year> <month> p105-117. </month>
Reference: [SuBK77] <author> H. Sullivan, T.R. Bashkow, and D. Klappholz, </author> <title> A Large Scale, Homogeneous, Fully Distributed Parallel Machine, II, </title> <booktitle> IEEE Fourth Annual Symposium on Computer Architecture, </booktitle> <year> 1977, </year> <month> p118-124. </month>
Reference-contexts: So the MIN copy networks have both packet replication and fast packet filters in their designs. 4.3.5. The Columbia ChoPP multicast-capable network The Columbia ChoPP (Columbia Homogeneous Parallel Processor) is a message passing network which introduces the concept of a multicast as a partitioned broadcast [SuB77] <ref> [SuBK77] </ref>. Multicasts are described as dynamically partitioned broadcast, and broadcast regions. This is notable as the earliest network implementation found which indicates the potential of multicast capability. 4.3.6. The Louisiana combining network The University of Southwestern Louisiana is developing a unique shared memory combining network [Tz89] (Figure 29).
Reference: [ T h 8 6 ] <author> R.E. Thomas, </author> <title> Behavior of the Butterfly Parallel Processor in the Presence of Memory Hot Spots, </title> <booktitle> IEEE Proc. 1986 Int'l. Conf. on Parallel Processing, </booktitle> <address> p46-50. </address>
Reference-contexts: This function is the method of reduction in some networks which approximate the effects of contention resolution via omission [HoE89], and also used to explain the dropping of packets which occurs in unbuffered blocking networks, like the BBN Butterfly <ref> [ T h 8 6 ] </ref> . * Amdahls Law states that if k% of an algorithm is serial (not parallelizeable), then the optimal acceleration would reduce all parallel code to one timestep, increasing the algorithm speed by a factor of 1/(k%). 1 1 Any function which reduces the product of
Reference: [ T o 8 7 ] <author> J.D. </author> <title> Touch, [proprietary documents], </title> <journal> Bell Communications Research, </journal> <year> 1987. </year>
Reference: [T u87 a] <author> J.S. Turner, </author> <title> Specification of Integrated Circuits for Broadcast Packet Network, </title> <institution> Washington University Technical Report WUCS-87-5, </institution> <month> Apr. </month> <year> 1987. </year> <pages> 4 2 </pages>
Reference: [ T u 8 7 b ] <author> J.S. Turner, </author> <title> The Challenge of Multipoint Communication, </title> <booktitle> Proc. of the ITC Seminar on Traffic Engineering for ISDN Design and Planning, </booktitle> <month> May </month> <year> 1987. </year>
Reference: [ T u 8 7 c ] <author> J.S. Turner, </author> <title> Fluid Flow Loading Analysis of Packet Switching Networks, </title> <institution> Washington University Technical Report WUCS-87-16, </institution> <year> 1987. </year>
Reference: [T u87 d] <author> J.S. Turner, </author> <note> Notes on Extensions to Starlite, private note to T.T. Lee. </note>
Reference: [ T u 8 8 ] <author> J.S. Turner, </author> <title> Design of a Broadcast Packet Switching Network, </title> <journal> IEEE Transactions on Communications, </journal> <volume> Vol. 36 No. 6, </volume> <month> June </month> <year> 1988, </year> <month> p734-743. </month>
Reference: [ T z 8 9 ] <author> N.F. Tzeng, </author> <title> Design of a Novel Combining Structure for Shared-Memory Multiprocessors, </title> <booktitle> IEEE Proc. 1989 Int'l. Conf. on Parallel Processing, </booktitle> <volume> Vol. 1, p 1 - 8 </volume> . 
Reference: [ W a 8 2 ] <author> D.W. Wall, </author> <title> Selective Broadcast in PacketSwitched Networks, </title> <booktitle> Proc. Sixth Berkeley Workshop on Distributed Data Management and Computer Networks, </booktitle> <year> 1982, </year> <month> p239-258. </month>
Reference: [ W u F 8 0 ] <author> C.L. Wu and T.Y. Feng, </author> <title> On a Class of Multistage Interconnection Networks, </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. C-29 No. 8, </volume> <month> Aug. </month> <year> 1980, </year> <month> p694-702. </month>
Reference: [YehHA87] <author> Y.S. Yeh, M.G. Hluchyj, </author> <title> and A.S. Acampora, The Knockout Switch: A Simple, Modular Architecture for High-Performance Packet Switching, </title> <journal> IEEE Journal on Selected Areas of Communications, </journal> <volume> Vol. SAC-5 No. 8, </volume> <month> Oct. </month> <year> 1987, </year> <month> p1274-1283. </month>
Reference-contexts: Machines There are several other machines which analyze reduction and replication in processor networks. These include the BBN Butterfly, and the IBM RP3 reduction network, the Starlite which supports copying [HuaK84], and the Knockout <ref> [YehHA87] </ref> [EnHY88]. 4.3.1. The BBN Butterfly The BBN Butterfly is an unbuffered shared memory network [Th86] [HoE89] [Mel88]. While there is an extension of the Butterfly, known as the Monarch, which is suspected of having multicast capabilities, information on that system was not available in time for this report. <p> SORT MERGE SWAP ROUTE DATA PACKETS DUMMY PACKETS DELIVERED D A T A NACK's 4.3.4. The AT&T Bell Labs Knockout multicast-capable network The Knockout network is not a MIN network, but its design does incorporate multicast capability, and is useful for comparison <ref> [YehHA87] </ref> [EnHY88]. The network is fully connected, in a multiple bus configuration, and supports packet switched communication (Figure 28).
Reference: [YewTL87] <author> P.C. Yew, N.F. Tzeng, and D.H. Lawrie, </author> <title> Distributed Hot-Spot Addressing in Large-Scale Multiprocesors, </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. C-36 No. 4, </volume> <month> Apr. </month> <year> 1987, </year> <month> p338-395. </month>
Reference-contexts: In some systems, once a hotspot has been sent a packet, no further requests to any hotspot may occur. This is known as limited access <ref> [YewTL87] </ref>, but also called a blocking request. Blocking requests is necessary in buffered combining networks, since otherwise requests could combine and pass each other in a way which would not be ultimately serializable [EdGK85]. 2.5. <p> This is used for synchronization, where counters are decremented by a fixed, static set of PEs. In this case, a central counter of 10 can be split into 5 counters of 2 each. When each count reaches zero,. it signals the central count, and decrements it by 2 <ref> [YewTL87] </ref>. Combining fails when contention is the result of a hot or popular memory module, not arising from a single memory element in common [Ler85]. <p> Some of these are related to Bellcores switch, such as [NaS81], while most others use a variation of Changs echo algorithm to distribute replicates [Ch82] [Kat87]. Software reduction has also been studied, in its ability to move virtual copies of a memory location out into the network <ref> [YewTL87] </ref>. 2 6 Most software multicast algorithms are based on the use of a spanning tree to send packet copies to distinct locations in a system, without overlap of effort [Wa82]. <p> This research also verified the distinction between blocking hotspot requests (which inhibit subsequent hotspot requests), and nonblocking requests, calling them limited and unlimited. 2 7 SORT RANK CONCENTRATE DISTRIBUTE TRAP TNT's DAE COPY ROUTE CONCENTRATE DISTRIBUTE GENERALIZE SORT SOFTWARE HARDWARE One notable exception is <ref> [YewTL87] </ref>, which notes that hotspots can be reduced in cases of synchronization variables by moving copies of the variable out into the network, and distributing the access through the virtual copies. <p> This reduces traffic when only local writes are performed. Other techniques were considered to optimize the network design. The use of a software combine was suggested, specifically to reduce the hotspots caused by global summation operations. The algorithm suggested is essentially a partial sum operation <ref> [YewTL87] </ref>. The design implemented used a two-level network, where one level performs combines (slow) and the other only routes (fast) (Figure 23). This assumes both that a processor knows the status of an access (hot/cool), in order to route the request.
References-found: 55

