URL: http://www.isi.edu/~marcu/papers/summar-book98.ps
Refering-URL: http://www.isi.edu/~marcu/papers.html
Root-URL: http://www.isi.edu
Email: marcu@isi.edu  
Title: Discourse trees are good indicators of importance in text  
Author: Daniel Marcu 
Address: 4676 Admiralty Way Marina del Rey, CA 90292-6695  
Affiliation: Information Sciences Institute University of Southern California  
Abstract: Researchers in computational linguistics have long speculated that the nuclei of the rhetorical structure tree of a text form an adequate "summary" of the text for which that tree was built. However, to my knowledge, there has been no experiment to confirm how valid this speculation really is. In this paper, I describe a psycholinguistic experiment that shows that the concepts of discourse structure and nuclearity can be used effectively in text summarization. More precisely, I show that there is a strong correlation between the nuclei of the discourse structure of a text and what readers perceive to be the most important units in that text. In addition, I propose and evaluate the quality of an automatic, discourse-based summarization system that implements the methods that were validated by the psycholinguistic experiment. The evaluation indicates that although the system does not match yet the results that would be obtained if discourse trees had been built manually, it still significantly outperforms both a baseline algorithm and Microsoft's Office97 summarizer. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Barzilay, R., and Elhadad, M. </author> <year> 1997. </year> <title> Using lexical chains for text summarization. </title> <booktitle> In Proceedings of the ACL'97/EACL'97 Workshop on Intelligent Scalable Text Summarization, </booktitle> <pages> 10-17. </pages>
Reference: <author> Baxendale, P. </author> <year> 1958. </year> <title> Machine-made index for technical literature | an experiment. </title> <journal> IBM Journal of Research and Development 2 </journal> <pages> 354-361. </pages>
Reference-contexts: or more of the following assumptions: * important sentences in a text contain words that are used frequently (Luhn 1958; Edmundson 1968); * important sentences contain words that are used in the title and section headings (Edmundson 1968); * important sentences are located at the beginning or end of paragraphs <ref> (Baxendale 1958) </ref>; * important sentences are located at positions in a text that are genre dependent, and these positions can be determined automatically, through training techniques (Kupiec, Pedersen, & Chen 1995; Lin & Hovy 1997; Teufel & Moens 1997); * important sentences use bonus words such as "greatest" and "significant" or
Reference: <author> Boguraev, B., and Kennedy, C. </author> <year> 1997. </year> <title> Salience-based content characterisation of text documents. </title> <booktitle> In Proceedings of the ACL'97/EACL'97 Workshop on Intelligent Scalable Text Summarization, </booktitle> <pages> 2-9. </pages>
Reference: <author> Chou Hare, V., and Borchardt, K. </author> <year> 1984. </year> <title> Direct instruction of summarization skills. </title> <journal> Reading Research Quarterly 20(1) </journal> <pages> 62-78. </pages>
Reference: <author> Cochran, W. </author> <year> 1950. </year> <title> The comparison of percentages in matched samples. </title> <journal> Biometrika 37 </journal> <pages> 256-266. </pages>
Reference-contexts: To compute a reliability figure, I followed the same methodology as Passonneau and Litman (1993) and Hearst (1997) and applied Cochran's Q summary statistics to the data <ref> (Cochran 1950) </ref>. Cochran's test assumes that a set of judges make binary decisions with respect to a dataset. The null hypothesis is that the number of judges that take the same decision is randomly distributed.
Reference: <author> Edmundson, H. </author> <year> 1968. </year> <title> New methods in automatic extracting. </title> <journal> Journal of the Association for Computing Machinery 16(2) </journal> <pages> 264-285. </pages>
Reference-contexts: assumed that the salient parts of a text can be determined by applying one or more of the following assumptions: * important sentences in a text contain words that are used frequently (Luhn 1958; Edmundson 1968); * important sentences contain words that are used in the title and section headings <ref> (Edmundson 1968) </ref>; * important sentences are located at the beginning or end of paragraphs (Baxendale 1958); * important sentences are located at positions in a text that are genre dependent, and these positions can be determined automatically, through training techniques (Kupiec, Pedersen, & Chen 1995; Lin & Hovy 1997; Teufel &
Reference: <author> Fox, B. </author> <year> 1987. </year> <title> Discourse Structure and Anaphora. </title> <booktitle> Cambridge Studies in Linguistics; 48. </booktitle> <publisher> Cambridge University Press. </publisher>
Reference-contexts: It is likely that by exploiting the relationship between discourse structure and anaphora <ref> (Fox 1987) </ref>, one can provide an elegant solution to this problem.
Reference: <author> Gale, W.; Church, K.; and Yarowsky, D. </author> <year> 1992. </year> <title> Estimating upper and lower bounds on the performance of word-sense disambiguation programs. </title> <booktitle> In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics (ACL-92), </booktitle> <pages> 249-256. </pages>
Reference: <author> Garner, R. </author> <year> 1982. </year> <title> Efficient text summarization: costs and benefits. </title> <journal> Journal of Educational Research 75 </journal> <pages> 275-279. </pages>
Reference: <author> Hearst, M. </author> <year> 1997. </year> <title> TextTiling: Segmenting text into multi-paragraph subtopic passages. </title> <booktitle> Computational Linguistics 23(1) </booktitle> <pages> 33-64. </pages>
Reference: <author> Hobbs, J. </author> <year> 1993. </year> <title> Summaries from structure. </title> <booktitle> In Working Notes of the Dagstuhl Seminar on Summarizing Text for Intelligent Communication. </booktitle>
Reference: <author> Hoey, M. </author> <year> 1991. </year> <title> Patterns of Lexis in Text. </title> <publisher> Oxford University Press. </publisher>
Reference: <author> Johnson, R. </author> <year> 1970. </year> <title> Recall of prose as a function of structural importance of linguistic units. </title> <journal> Journal of Verbal Learning and Verbal Behaviour 9 </journal> <pages> 12-20. </pages>
Reference-contexts: The percent agreements computed for each of the five texts and each level of importance are given in table 3. The agree ments among judges for my experiment seem to follow the same pattern as those described by other researchers in summarization <ref> (Johnson 1970) </ref>. That is, the judges are quite consistent with respect to what they perceive as being very important and unimportant, but less consistent with respect to what they perceive as being less important.
Reference: <author> Krippendorff, K. </author> <year> 1980. </year> <title> Content analysis: An Introduction to its Methodology. </title> <address> Beverly Hills, CA: </address> <publisher> Sage Publications. </publisher>
Reference: <author> Kupiec, J.; Pedersen, J.; and Chen, F. </author> <year> 1995. </year> <title> A trainable document summarizer. </title> <booktitle> In Proceedings of the 18th ACM/SIGIR Annual Conference on Research and Development in Information Retrieval, </booktitle> <pages> 68-73. </pages>
Reference: <author> Lin, C., and Hovy, E. </author> <year> 1997. </year> <title> Identifying topics by position. </title> <booktitle> In Proceedings of the Fifth Conference on Applied Natural Language Processing (ANLP-97), </booktitle> <pages> 283-290. </pages>
Reference: <author> Lin, C. </author> <year> 1995. </year> <title> Knowledge-based automatic topic identification. </title> <booktitle> In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics (ACL-95), </booktitle> <pages> 308-310. </pages>
Reference: <author> Luhn, H. </author> <year> 1958. </year> <title> The automatic creation of literature abstracts. </title> <journal> IBM Journal of Research and Development 2(2) </journal> <pages> 159-165. </pages>
Reference: <author> Mani, I., and Bloedorn, E. </author> <year> 1997. </year> <title> Multi-document summarization by graph search and matching. </title> <booktitle> In Proceedings of the Fourteenth National Conference on Artificial Intelligence (AAAI-97), </booktitle> <pages> 622-628. </pages>
Reference: <author> Mann, W., and Thompson, S. </author> <year> 1988. </year> <title> Rhetorical struc-ture theory: Toward a functional theory of text organization. </title> <booktitle> Text 8(3) </booktitle> <pages> 243-281. </pages>
Reference-contexts: To this end, I first review briefly the Rhetorical Structure Theory <ref> (Mann & Thompson 1988) </ref> and the rhetorical parsing algorithm proposed by Marcu (1997a), which takes as input an unrestricted text and derives its discourse structure (see (Marcu 1997b) for details). <p> the discourse structures derived by the rhetorical parser (Marcu 1997a) and with a broader analysis of the summarization and evaluation methodologies that I employed. 2 From discourse structures to text summaries A short review of Rhetorical Structure Theory Driven mostly by research in natural language generation, Rhetorical Structure Theory (RST) <ref> (Mann & Thompson 1988) </ref> has become one of the most popular discourse theories of the last decade.
Reference: <author> Marcu, D. </author> <year> 1996. </year> <title> Building up rhetorical structure trees. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence (AAAI-96), </booktitle> <volume> volume 2, </volume> <pages> 1069-1074. </pages>
Reference: <author> Marcu, D. </author> <year> 1997a. </year> <title> The rhetorical parsing of natural language texts. </title> <booktitle> In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics (ACL-97), </booktitle> <pages> 96-103. </pages>
Reference-contexts: I end the paper with an evaluation of an implemented summarization system that uses the discourse structures derived by the rhetorical parser <ref> (Marcu 1997a) </ref> and with a broader analysis of the summarization and evaluation methodologies that I employed. 2 From discourse structures to text summaries A short review of Rhetorical Structure Theory Driven mostly by research in natural language generation, Rhetorical Structure Theory (RST) (Mann & Thompson 1988) has become one of the <p> However, since this algorithm constructs trees that are not always correct <ref> (Marcu 1997a) </ref>, such an evaluation would not assess the appropriateness of the discourse-based method for text summarization.
Reference: <author> Marcu, D. </author> <year> 1997b. </year> <title> The rhetorical parsing, summarization, and generation of natural language texts. </title> <type> Ph.D. Dissertation, </type> <institution> Department of Computer Science, University of Toronto. </institution>
Reference-contexts: To this end, I first review briefly the Rhetorical Structure Theory (Mann & Thompson 1988) and the rhetorical parsing algorithm proposed by Marcu (1997a), which takes as input an unrestricted text and derives its discourse structure (see <ref> (Marcu 1997b) </ref> for details). I then show how one can use discourse structures in order to assign to each textual unit an importance score and to determine the most important units of the corresponding text.
Reference: <author> Marcu, D. </author> <year> 1998a. </year> <title> Improving summarization through rhetorical parsing tuning. </title> <note> In preparation. </note>
Reference-contexts: Dealing with these issues is, however, beyond the scope of this paper. The results presented here confirm the suitability of using discourse structures for summarizing texts from the Scientific American genre. In <ref> (Marcu 1998a) </ref>, I show that the same techniques can be applied successfully for summarizing texts from the newspaper genre as well and provide a methodology for integrating the discourse-based approach to summarization with position-, title-, and semantic-similarity-based approaches.
Reference: <author> Marcu, D. </author> <year> 1998b. </year> <title> To build text summaries of high quality, nuclearity is not sufficient. </title> <booktitle> In Working Notes of the AAAI-98 Spring Symposium on Intelligent Text Summarization, </booktitle> <pages> 1-8. </pages>
Reference: <author> Matthiessen, C., and Thompson, S. </author> <year> 1988. </year> <title> The structure of discourse and `subordination'. </title> <editor> In Haiman, J., and Thompson, S., eds., </editor> <title> Clause combining in grammar and discourse, </title> <booktitle> volume 18 of Typological Studies in Language. </booktitle> <publisher> John Benjamins Publishing Company. </publisher> <pages> 275-329. </pages>
Reference: <author> Ono, K.; Sumita, K.; and Miike, S. </author> <year> 1994. </year> <title> Abstract generation based on rhetorical structure extraction. </title> <booktitle> In Proceedings of the International Conference on Computational Linguistics (Coling-94), </booktitle> <pages> 344-348. </pages>
Reference: <author> Passonneau, R., and Litman, D. </author> <year> 1993. </year> <title> Intention-based segmentation: human reliability and correlation with linguistic cues. </title> <booktitle> In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics (ACL-93), </booktitle> <pages> 148-155. </pages>
Reference: <author> Polanyi, L. </author> <year> 1993. </year> <title> Linguistic dimensions of text summarization. </title> <booktitle> In Working Notes of the Dagstuhl Seminar on Summarizing Text for Intelligent Communication. </booktitle>
Reference: <author> Rush, J.; Salvador, R.; and Zamora, A. </author> <year> 1971. </year> <title> Automatic abstracting and indexing. Production of indicative abstracts by application of contextual inference and syntactic coherence criteria. </title> <journal> Journal of American Society for Information Sciences 22(4) </journal> <pages> 260-274. </pages>
Reference: <author> Sherrard, C. </author> <year> 1989. </year> <title> Teaching students to summarize: Applying textlinguistics. System 17(1). </title>
Reference: <author> Skorochodko, E. </author> <year> 1971. </year> <title> Adaptive method of automatic abstracting and indexing. </title> <booktitle> In Information Processing, </booktitle> <volume> volume 2, </volume> <pages> 1179-1182. </pages> <publisher> North-Holland Publishing Company. </publisher>
Reference: <author> Sparck Jones, K. </author> <year> 1993a. </year> <title> Summarising: analytic framework, key component, experimental method. </title> <booktitle> In Working Notes of the Dagstuhl Seminar on Summarizing Text for Intelligent Communication. </booktitle>
Reference: <author> Sparck Jones, K. </author> <year> 1993b. </year> <title> What might be in a summary? In Information Retrieval 93: Von der Model-lierung zur Anwendung, </title> <type> 9-26. </type>
Reference: <author> Sumita, K.; Ono, K.; Chino, T.; Ukita, T.; and Amano, S. </author> <year> 1992. </year> <title> A discourse structure analyzer for Japanese text. </title> <booktitle> In Proceedings of the International Conference on Fifth Generation Computer Systems, </booktitle> <volume> volume 2, </volume> <pages> 1133-1140. </pages>
Reference: <author> Teufel, S., and Moens, M. </author> <year> 1997. </year> <title> Sentence extraction as a classification task. </title> <booktitle> In Proceedings of the ACL'97/EACL'97 Workshop on Intelligent Scalable Text Summarization, </booktitle> <pages> 58-65. </pages>
Reference: <author> Winograd, P. </author> <year> 1984. </year> <title> Strategic difficulties in summarizing texts. </title> <booktitle> Reading Research Quaterly 19(4) </booktitle> <pages> 404-425. </pages>
Reference-contexts: Chou Hare & Borchardt 1984; Sherrard 1989) that there exists a certain degree of disagreement between readers with respect to the importance that they assign to various textual units and that the disagreement is dependent on the quality of the text and the comprehension and summarization skills of the readers <ref> (Winograd 1984) </ref>. In an attempt to produce an adequate reference set of data, I selected for my experiment five short texts from Scientific American that I considered to be well-written. The texts ranged in size from 161 to 725 words. The shortest text was that shown in (1).
References-found: 37

