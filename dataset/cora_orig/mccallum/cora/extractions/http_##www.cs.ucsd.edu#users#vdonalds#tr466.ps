URL: http://www.cs.ucsd.edu/users/vdonalds/tr466.ps
Refering-URL: http://www.cs.ucsd.edu/users/vdonalds/
Root-URL: http://www.cs.ucsd.edu
Email: fvdonalds,ferranteg@cs.ucsd.edu  
Title: Determining Asynchronous Acyclic Pipeline Execution Times  
Author: Val Donaldson and Jeanne Ferrante 
Address: La Jolla, California 92093-0114  
Affiliation: Computer Science and Engineering Department University of California, San Diego  
Abstract: Technical Report CS96-466, CSE Dept., UCSD, January 1996 Abstract Pipeline execution is a form of parallelism in which subcomputations of a repeated computation, such as statements in the body of a loop, are executed in parallel. A measure of the execution time of a pipeline is needed to determine if pipelining is an effective form of parallelism for a loop, and to evaluate alternative scheduling choices. We derive a formula for precisely determining the asynchronous pipeline execution time of a loop modeled as iterated execution of an acyclic task graph. The formula can be evaluated in time linear in the number of tasks and edges in the graph. We assume that computation and communication times are fixed and known, interprocessor communication and buffering capability are unbounded, and each task is assigned to a distinct processor. The formula may be applied to obtain more accurate (faster) pipeline execution times for recent examples from the literature.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Sati Banerjee, Takeo Hamada, Paul M. Chau, and Ronald D. Fellman. </author> <title> Macro pipelining based scheduling on high performance heterogeneous multiprocessor systems. </title> <journal> IEEE Transactions on Signal Processing 43:8 (June 1995), </journal> <pages> pp. 1468-1484. </pages>
Reference-contexts: Given a pipeline schedule, it is important to be able to predict the execution time of the schedule, to determine whether or not the loop should be pipelined, and to chose between alternative schedules. Existing pipeline scheduling algorithms <ref> [1, 2, 3, 5] </ref> use conservative estimates of the execution time of a schedule. We derive a formula which precisely characterizes the execution time of an asynchronous pipeline schedule when the loop body is represented as an acyclic task graph, and each task is assigned to a distinct processor. <p> Our primary contribution is a formula for exactly determining the pipeline execution time of a loop represented as repeated execution of an acyclic task graph, which can be evaluated 7 Processor Assignment from <ref> [1, 3] </ref> Hoang and Rabaey [3] Banerjee et al. [1] Theorem 1 Execution Time Estimate 30 + 10n 40 + 10n 29 + 9n Number of Processors 5 5 5 Asymptotic Improvement | | 10% (a) Processor Assignment from [5] Optimal Proc. <p> Our primary contribution is a formula for exactly determining the pipeline execution time of a loop represented as repeated execution of an acyclic task graph, which can be evaluated 7 Processor Assignment from [1, 3] Hoang and Rabaey [3] Banerjee et al. <ref> [1] </ref> Theorem 1 Execution Time Estimate 30 + 10n 40 + 10n 29 + 9n Number of Processors 5 5 5 Asymptotic Improvement | | 10% (a) Processor Assignment from [5] Optimal Proc. <p> Figure 4a shows the estimated execution times for this example as assumed in <ref> [1, 3] </ref>, as well as the result of applying Theorem 1; the actual time is asymptotically 10% faster than the estimated times. from [5] for execution on three processors is shown in the first column.
Reference: [2] <author> Franco Gasperoni and Uwe Schwiegelshohn. </author> <title> Scheduling loops on parallel processors: a simple algorithm with close to optimum performance. </title> <booktitle> Second Joint International Conference on Vector and Parallel Processing (Parallel Processing: CONPAR 92-VAPP V), </booktitle> <address> Lyon, France, </address> <month> September </month> <year> 1992, </year> <pages> pp. 625-636. </pages>
Reference-contexts: Given a pipeline schedule, it is important to be able to predict the execution time of the schedule, to determine whether or not the loop should be pipelined, and to chose between alternative schedules. Existing pipeline scheduling algorithms <ref> [1, 2, 3, 5] </ref> use conservative estimates of the execution time of a schedule. We derive a formula which precisely characterizes the execution time of an asynchronous pipeline schedule when the loop body is represented as an acyclic task graph, and each task is assigned to a distinct processor.
Reference: [3] <author> Phu D. Hoang and Jan M. Rabaey. </author> <title> Scheduling of DSP programs onto multiprocessors for maximum throughput. </title> <journal> IEEE Transactions on Signal Processing 41:6 (June 1993), </journal> <pages> pp. 2225-2235. </pages>
Reference-contexts: Given a pipeline schedule, it is important to be able to predict the execution time of the schedule, to determine whether or not the loop should be pipelined, and to chose between alternative schedules. Existing pipeline scheduling algorithms <ref> [1, 2, 3, 5] </ref> use conservative estimates of the execution time of a schedule. We derive a formula which precisely characterizes the execution time of an asynchronous pipeline schedule when the loop body is represented as an acyclic task graph, and each task is assigned to a distinct processor. <p> Our primary contribution is a formula for exactly determining the pipeline execution time of a loop represented as repeated execution of an acyclic task graph, which can be evaluated 7 Processor Assignment from <ref> [1, 3] </ref> Hoang and Rabaey [3] Banerjee et al. [1] Theorem 1 Execution Time Estimate 30 + 10n 40 + 10n 29 + 9n Number of Processors 5 5 5 Asymptotic Improvement | | 10% (a) Processor Assignment from [5] Optimal Proc. <p> Our primary contribution is a formula for exactly determining the pipeline execution time of a loop represented as repeated execution of an acyclic task graph, which can be evaluated 7 Processor Assignment from [1, 3] Hoang and Rabaey <ref> [3] </ref> Banerjee et al. [1] Theorem 1 Execution Time Estimate 30 + 10n 40 + 10n 29 + 9n Number of Processors 5 5 5 Asymptotic Improvement | | 10% (a) Processor Assignment from [5] Optimal Proc. <p> Theorem 1 can be used to show that several example pipeline schedules from the literature execute in less time than otherwise estimated. the algorithm of Hoang and Rabaey <ref> [3] </ref> generate nearly identical schedules for this example, although there is a minor difference. <p> Figure 4a shows the estimated execution times for this example as assumed in <ref> [1, 3] </ref>, as well as the result of applying Theorem 1; the actual time is asymptotically 10% faster than the estimated times. from [5] for execution on three processors is shown in the first column.
Reference: [4] <author> David A. Padua and Michael J. Wolfe. </author> <title> Advanced compiler optimizations for supercomputers. </title> <journal> Communications of the ACM 29:12 (December 1986), </journal> <pages> pp. 1184-1201. </pages>
Reference-contexts: Statements or groups of statements in the loop are the pipeline tasks. There are several different representations of the loop body which can be used for pipeline analysis. One common representation of a loop body is a data dependence graph (DDG) <ref> [4] </ref>. Figures 1a and Figure 1b are an example loop and its corresponding DDG. The edges in a DDG represent data dependences between statements, where for example, one statement defines a value used by another statement.
Reference: [5] <author> Tao Yang, Cong Fu, Apostolos Gerasoulis, and Vivek Sarkar. </author> <title> Mapping iterative task graphs on distributed memory machines. </title> <booktitle> Proc. 24th International Conference on Parallel Processing, </booktitle> <address> Oconomowoc, WI, </address> <month> August </month> <year> 1995, </year> <booktitle> Vol II, </booktitle> <pages> pp. 151-158. 9 </pages>
Reference-contexts: Given a pipeline schedule, it is important to be able to predict the execution time of the schedule, to determine whether or not the loop should be pipelined, and to chose between alternative schedules. Existing pipeline scheduling algorithms <ref> [1, 2, 3, 5] </ref> use conservative estimates of the execution time of a schedule. We derive a formula which precisely characterizes the execution time of an asynchronous pipeline schedule when the loop body is represented as an acyclic task graph, and each task is assigned to a distinct processor. <p> acyclic task graph, which can be evaluated 7 Processor Assignment from [1, 3] Hoang and Rabaey [3] Banerjee et al. [1] Theorem 1 Execution Time Estimate 30 + 10n 40 + 10n 29 + 9n Number of Processors 5 5 5 Asymptotic Improvement | | 10% (a) Processor Assignment from <ref> [5] </ref> Optimal Proc. Assignment Yang et al. [5] Simulation Theorem 1 Simulation Execution Time Estimate 25 + 45n (n odd ) 30 + 40n 50 + 40n 30 + 40n 20 + 45n (n even) Number of Processors 3 3 2 2 Asymptotic Improvement | 11% 11% 11% (b) in linear <p> 7 Processor Assignment from [1, 3] Hoang and Rabaey [3] Banerjee et al. [1] Theorem 1 Execution Time Estimate 30 + 10n 40 + 10n 29 + 9n Number of Processors 5 5 5 Asymptotic Improvement | | 10% (a) Processor Assignment from <ref> [5] </ref> Optimal Proc. Assignment Yang et al. [5] Simulation Theorem 1 Simulation Execution Time Estimate 25 + 45n (n odd ) 30 + 40n 50 + 40n 30 + 40n 20 + 45n (n even) Number of Processors 3 3 2 2 Asymptotic Improvement | 11% 11% 11% (b) in linear time. <p> Figure 4a shows the estimated execution times for this example as assumed in [1, 3], as well as the result of applying Theorem 1; the actual time is asymptotically 10% faster than the estimated times. from <ref> [5] </ref> for execution on three processors is shown in the first column.
References-found: 5

