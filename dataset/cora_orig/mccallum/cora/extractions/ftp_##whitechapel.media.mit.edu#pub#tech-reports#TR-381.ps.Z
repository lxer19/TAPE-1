URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-381.ps.Z
Refering-URL: http://www.media.mit.edu/~szummer/
Root-URL: http://www.media.mit.edu
Email: szummer@media.mit.edu, picard@media.mit.edu  
Title: Temporal Texture Modeling  
Author: Martin Szummer and Rosalind W. Picard 
Web: http://www-white.media.mit.edu/~szummer/  
Address: Rm E15-384; 20 Ames St; Cambridge MA 02139; USA  
Affiliation: MIT Media Lab  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 381 Also appearing: IEEE Int. Conf. on Image Proc., Lausanne, Sep. 1996. Abstract Temporal textures are textures with motion. Examples include wavy water, rising steam and fire. We model image sequences of temporal textures using the spatio-temporal autoregressive model (STAR). This model expresses each pixel as a linear combination of surrounding pixels lagged both in space and in time. The model provides a base for both recognition and synthesis. We show how the least squares method can accurately estimate model parameters for large, causal neighborhoods with more than 1000 parameters. Synthesis results show that the model can adequately capture the spatial and temporal characteristics of many temporal textures. A 95% recognition rate is achieved for a 135 element database with 15 texture classes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Randal C. Nelson and Ramprasad Polana. </author> <title> Qualitative recognition of motion using temporal texture. Comp. Vis., Graph., </title> <journal> and Img. Proc., </journal> <volume> 56(1) </volume> <pages> 78-89, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Temporal textures are textures with motion. Good examples are fire, wavy water and leaves fluttering in the wind. They are characterized by an indeterminate extent both in space and time <ref> [1] </ref>. This class of motions can be contrasted with two others: activities are temporally periodic but spatially restricted (such as a person walking or swimming). Motion events are single events that do not repeat in space or time (such as opening a door or throwing a ball). <p> Motion events are single events that do not repeat in space or time (such as opening a door or throwing a ball). Temporal textures have previously been studied for recognition applications (e.g. detecting forest fires) <ref> [1] </ref> and for synthesis in computer graphics (e.g. artificial fire and smoke). Unlike previous work, we focus on a representation that can be acquired directly from image sequences, and that is effective both for recognition and synthesis. Our representation is the linear spatio-temporal au-toregressive model (STAR) [2].
Reference: [2] <author> Phillip E. Pfeifer and Stuart Jay Deutsch. </author> <title> A three-stage iterative procedure for space-time modeling. </title> <journal> Technomet-rics, </journal> <volume> 22(1) </volume> <pages> 35-47, </pages> <month> February </month> <year> 1980. </year>
Reference-contexts: Unlike previous work, we focus on a representation that can be acquired directly from image sequences, and that is effective both for recognition and synthesis. Our representation is the linear spatio-temporal au-toregressive model (STAR) <ref> [2] </ref>. It is a three-dimensional extension of autoregressive models (AR), which are among the best models for recognition and synthesis of image textures [3, 4]. <p> Note periodicity in time. 2 Model selection Before parameter estimation, we must select neighborhood size and topology and ensure that the data is wide sense stationary. The autocorrelation function (ACF) is a useful tool for analyzing the correlation structure of autoregressive processes and for model identification <ref> [2] </ref>. Direct computation of the ACF in the spatio-temporal domain is not feasible due to the large amount of data in an image sequence. Instead, the ACF is computed as the inverse Fourier transform of the power spectrum. <p> In traditional time series analysis, model selection is done by examining the patterns of the ACF and PACF (partial autocorrelation function). STAR models have large, three-dimensional neighborhoods which generate very complex patterns that cannot be identified easily <ref> [2] </ref>. Instead, we begin by fitting a large STAR model to the texture. We got the best synthesis results from causal half-sphere neighborhoods with radius between 4 and 7 (with between 128 and 709 parameters).
Reference: [3] <author> Michael Grunkin. </author> <title> On the Analysis of Image Data Using Simultaneous Interaction Models. </title> <type> PhD thesis, </type> <institution> Inst. of Mathematical Modeling and Operations Research, Technical University of Denmark, Lyngby, </institution> <month> August </month> <year> 1993. </year> <note> no. 67. </note>
Reference-contexts: Our representation is the linear spatio-temporal au-toregressive model (STAR) [2]. It is a three-dimensional extension of autoregressive models (AR), which are among the best models for recognition and synthesis of image textures <ref> [3, 4] </ref>. Autoregressive models are also This work was supported in part by BT, NEC and Hewlett Packard Labs. widely used in speech modeling and time series analysis. <p> Image data is often nonstationary due to nonuniform illumination of the image. These nonstationarities can be removed using unsharp masking. One approach is to median-filter each frame and subtract the filter output from the frame <ref> [3] </ref>. We used a purely spatial 21 fi 21 median filter for all image sequences. The illumination gradients were reduced and the ACF decayed to zero exponentially instead of linearly (which indicated non-stationarity). Finding a good neighborhood size and topology is a difficult task for STAR models. <p> Fortunately, our data sets have extents 170 fi 115 fi 120. Thus, there are at least 2000 data points per parameter, reducing the risk for overfitting. The large models are already useful, and can be improved by pruning insignificant parameters. The pruning algorithm <ref> [3] </ref> iteratively discards the least significant parameters as long as the Schwartz's Bayesian Criterion (SBC) decreases. Let jj be the data set size, p be the number of parameters, and ^ 2 a be the estimated innova tion variance. <p> Then SBC = jj ln ^ 2 The significance of a parameter is determined by the t-test (the parameter value divided by its standard deviation). For static image textures, the pruning algorithm typically reduces 80 parameter models to 50 parameters while maintaining the visual quality of the simulated texture <ref> [3] </ref>. 3 Parameter estimation Parameters of the STAR model are determined by minimizing the mean square prediction error. We have used the conditional least squares estimator (CLS). The estimate is conditioned on the unknown values outside the boundary.
Reference: [4] <author> Jianchang Mao and Anil K. Jain. </author> <title> Texture classification and segmentation using multiresolution simultaneous au-toregressive models. </title> <journal> Pattern Recognition, </journal> <volume> 25(2) </volume> <pages> 173-188, </pages> <year> 1992. </year>
Reference-contexts: Our representation is the linear spatio-temporal au-toregressive model (STAR) [2]. It is a three-dimensional extension of autoregressive models (AR), which are among the best models for recognition and synthesis of image textures <ref> [3, 4] </ref>. Autoregressive models are also This work was supported in part by BT, NEC and Hewlett Packard Labs. widely used in speech modeling and time series analysis. <p> We used still images of the textures and applied a purely spatial autoregressive model (SAR) at three different scales <ref> [4] </ref>. Thus, the recognition is motion-invariant, which is desirable in many applications. For a given texture, we find other examples with the most similar autoregressive parameters, according to the Mahalanobis distance metric. The recognition performance is very good. 95% of the top 8 matches belong to the correct texture class. <p> Hence, estimation and synthesis must be coordinated across scales. For recognition applications, we must design features invariant to motion direction and magnitude. One possibility is to use features of STAR parameters, e.g. averages of parameters at the same distance from the origin <ref> [4] </ref>. A challenging problem is to model nonstationary temporal textures. For this task, nonlinear models are likely to be needed.
Reference: [5] <author> Martin Szummer. </author> <title> Temporal texture modeling. </title> <type> Technical Report 346, </type> <institution> MIT Media Lab Perceptual Computing, </institution> <year> 1995. </year> <title> http://www-white.media.mit.edu/vismod/ cgi-bin/tr_pagemaker#TR346. 3 the size of neighborhoods are river (1270), boiling water (128), steam (1270) and spiraling water (128) (number of parameters in parentheses). </title> <type> 4 </type>
Reference-contexts: The methods give significantly different results, probably because most visual textures are close to nonstationarity and hence are sensitive to initial conditions. The covariance method gives more accurate estimates <ref> [5] </ref>. The system of normal equations is then solved using Cholesky decomposition. The accuracy of the estimation can be determined by first estimating parameters from an image sequence, then synthesizing a texture based on them, and finally estimating the parameters of the synthesized texture.
References-found: 5

