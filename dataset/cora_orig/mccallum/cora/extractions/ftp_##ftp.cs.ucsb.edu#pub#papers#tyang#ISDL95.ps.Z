URL: ftp://ftp.cs.ucsb.edu/pub/papers/tyang/ISDL95.ps.Z
Refering-URL: http://www.cs.ucsb.edu/~tyang/papers/
Root-URL: http://www.cs.ucsb.edu
Email: E-mail: smithtr@cs.ucsb.edu  
Phone: Phone: 805-893-7665; Fax: 805-893-3045;  
Title: The WWW Prototype of the Alexandria Digital Library  
Author: D.Andresen, L.Carver, R.Dolin, C.Fischer, J.Frew, M.Goodchild, O.Ibarra, R. Kothuri, M.Larsgaard, B.Manjunath, D.Nebert, J.Simpson, T.Smith, T.Yang, Q.Zheng 
Keyword: digital library, spatial information, metadata, prototype, World-Wide-Web  
Address: Santa Barbara, CA 93106, USA  
Affiliation: Alexandria Digital Library, University of California at Santa Barbara  
Abstract: The Alexandria Digital Library (ADL) is focussed on providing broad access to distributed collections of spatially-indexed information. ADL has a four-component architecture involving collections, catalog, interfaces, and ingest facilities. The first stage in the construction of ADL resulted in the design and implementation of a rapid prototype (RP) system. The second stage, which is described in this paper, involves an expansion of the functionality of the RP and its extension to the World-Wide-Web (WWW). We describe issues arising in each of the components of the architecture in extending the library to WWW as well as our current resolution of these issues. We also discuss an extension of the class of supportable queries to include simple, content-based queries involving geographic "features" and image textures. The metadata of ADL has been extended to include gazetteer information supporting the first class of extended queries. We discuss image processing and parallel computing support for ADL. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> American Library Association. Anglo-American cataloguing rules. 2nd ed., </editor> <address> rev., Chicago, </address> <year> 1988. </year>
Reference-contexts: While the traditional library community has established well-defined sets of terms and procedures relating to cataloging issues <ref> [1] </ref>, there is no generally accepted conceptualization of metadata for DL's. Hence the current design of metadatabases and catalogs for DL's is essentially an ad hoc procedure.
Reference: [2] <author> D. Andresen, O. Egecioglu, O. Ibarra, A. Poulakidas, A. Srinivasan, and T. Yang. </author> <title> Parallel processing support for high performance digital libraries, </title> <type> Technical Report, </type> <institution> CS Department, UCSB, </institution> <year> 1995. </year>
Reference-contexts: The Alexandria Project, like many other projects, is investigating parallel computation <ref> [2] </ref> to address performance issues, for example, scheduling on multiprocessors and parallel I/O, parallel forward wavelet transform in image ingest, and parallel reverse wavelet transform for efficient browsing of multi-scale images.
Reference: [3] <author> K. Bohm and T. C. Rakow. </author> <title> Metadata for Multimedia documents. </title> <booktitle> Sigmod Record, </booktitle> <volume> Vol. 23, </volume> <pages> pp. 21-26, </pages> <year> 1994. </year>
Reference-contexts: One may construct an unlimited number of informal interpretations, and it may be possible to form compositions of such mappings. As noted by many other researchers (see, for example, <ref> [3] </ref>), it is useful to distinguish content-independent and content-dependent informal interpretations. Examples of the former include the author catalog and more general "lineage" information about items.
Reference: [4] <institution> Environmental Systems Research Institute Inc. ArcView 2.0c software, </institution> <note> Alpha/OSF1 version. </note> <institution> Redlands, California, </institution> <year> 1978. </year>
Reference-contexts: The RP supported the first three of these functions, using an implementation based on the GIS software package Arcview <ref> [4] </ref>. In adapting the system to the WWW environment, however, and in augmenting the functionality of the RP, a number of significant issues arise. 5.1 User Interface Issues Many of the mechanisms employed in the RP interface are not well supported in the (currently available) standard WWW/HTTP/HTML envi ronment.
Reference: [5] <author> C. Fischer, J.Frew, M. Larsgaard, T.R. Smith and Q.Zheng. </author> <title> Alexandria Digital Library: Rapid Prototype and Metadata Schema. </title> <booktitle> Proceedings of ADL95 Conference, </booktitle> <year> 1995. </year>
Reference-contexts: Different users need different ways to formulate search queries and have different expectations of, and requirements for, search results. An initial, and now completed, increment in the development of ADL involved the design and construction of a stand-alone "rapid prototype" (RP) system <ref> [5] </ref> 3 . The second increment involves providing an augmented version of the functionality of the RP over the World-Wide-Web (WWW). We term this the "WWW prototype" (WP) 4 . The third increment will focus on developing a catalog component that is based on a general model of metadata. <p> The initial collections of ADL (i.e. the "data" of the DOBJ's) are focused on spatially-referenced materials such as digitized maps, digitized air photos, and images from many domains of application <ref> [5] </ref>. Such items are typically characterized by a spatial footprint, which is a set of points characterizing the spatial extent of the item in the space over which the item is defined 6 . <p> It is necessary, however, to generalize this model for DLs, such as ADL, that contain spatially-indexed materials. The catalog component of the RP incorporated a generalization based on a new metadata schema for spatially-indexed information that combines the Federal Geographic Data Committee (FGDC) and USMARC standards <ref> [5] </ref> 9 .
Reference: [6] <institution> Internet Engineering Task Force. </institution> <address> http://www.ietf.cnri.reston.va.us/ids.by.wg/ uri.html, </address> <year> 1995. </year>
Reference-contexts: An important issue in distributed Internet applications is that there is currently no accepted standard for oid's. There are a number of alternative suggestions relating, for example, to URx's of various forms (where the "x" is an identifier, locator, or name) or handles <ref> [6] </ref>. 3.2 Storage Implementation ADL is employing distributed hierarchical storage to store its own collections. The storage and management of the data is simplified by the fact that it is predominantly "write-once".
Reference: [7] <author> R. Kahn and R. Wilensky. </author> <note> http://WWW.CNRI.Reston.VA.US/home/ cstr/arch/k-w.html, </note> <year> 1995. </year>
Reference-contexts: In cases in which a user does not require information at all levels of resolution in an image, the user need only transmit information down to the levels of resolution required. We are employing an initial resolution of the issue of oid's for DOBJ's, based on suggestions of <ref> [7] </ref>, in a test of interoperability between ADL and the UC Berkeley DL 8 .
Reference: [8] <author> E.D. Katz, M. Butler and R. McGrath. </author> <title> A Scalable HTTP Server: the NCSA Prototype. </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> Vol 27, </volume> <pages> pp. 155-164, </pages> <year> 1994. </year>
Reference-contexts: For example, in 1993 alone, the weekly access rate for NCSA's HTTP server at UIUC increased from 91K to 1.5M. The peak request arrival rate at NCSA exceeds 20 requests/second, while current high-end workstations can handle only about 4 requests/second <ref> [8] </ref>. The requests to the NCSA server typically involve only simple file retrieval operations, whereas requests to the ADL server will involve much more intensive I/O and CPU activities with, for example, the use of run-time wavelet transforms and content-based searching on metadata and images. <p> We have observed similar speedups using a multi-node server when varying the size of image files. #proc2 rps4 rps8 rps 16 rps20 rps 1 5.1 24.3 142.5283.7 448.4 4 3.2 3.7 6.6 32.2 45.4 NCSA <ref> [8] </ref> has built a multi-workstation HTTP server based on round-robin domain name resolution to assign requests to workstations. This technique is effective when HTTP requests return relatively uniform-sized chunks of HTML.
Reference: [9] <author> R. Kothuri and A. K. Singh. </author> <title> Indexing Hierarchical Data. </title> <type> Technical Report TR95-14, </type> <institution> CS Department, UCSB, </institution> <year> 1995. </year>
Reference-contexts: As the size of the metadatabase grows, it is critical to provide efficient support for different types of queries over the footprints with the use of appropriate spatial indexing methods. We have been exploring new methods of indexing multiply-nested spatial data <ref> [9] </ref> such as footprints. In particular, we have extended B-trees to "IB-trees" for handling data objects that span a range of values (intervals) rather than single-valued points in the data space. This allows two distinct approaches for indexing multidimensional hierarchical data.
Reference: [10] <author> B. S. Manjunath and W. Y. Ma. </author> <title> Texture Features for browsing and retrieval of image data. </title> <type> Technical Report CIPR-TR-95-06, </type> <institution> ECE Department, UCSB, </institution> <year> 1995. </year>
Reference-contexts: We have made considerable progress in developing algorithms for texture-based search <ref> [10] </ref>. We are currently investigating augmenting the ADL catalog with indices based on texture features. The basic idea is to extract texture information from the images as they are ingested. This is done using Gabor filters, which are modulated Gaussians.
Reference: [11] <author> M. Vitterli and C. Herley. </author> <title> Wavelets and filter banks: theory and design. </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> Vol. 40, </volume> <pages> pp. 2207-2232, </pages> <year> 1992. </year>
Reference-contexts: The general solution is to have access to hierarchical, multiscale representations of image data. An obvious solution to this requirement is the use of wavelet transforms, which provide mul-tiscale decompositions of the image data <ref> [11] </ref>. Wavelets have been widely used in many image-processing applications, including compression, enhancement, reconstruction, and image analysis. Fast algorithms exist for computing the forward and inverse wavelet transforms, and desired intermediate levels can be easily reconstructed. The transformed images (wavelet coefficients) also map naturally into hierarchical storage structures. <p> Instead of Gabor filters, one may also use the same orthogonal wavelet transform that was used for storing the image data. However, experiments on a large set of textured images have shown that the retrieval performance of conventional orthogonal wavelets is not as good as that of Gabor filters <ref> [11] </ref>. Unfortunately, Gabor transforms are awkward for storage applications. In particular, they do not form an orthogonal basis set. Many researchers have used Gabor transforms for image compression, mainly for lossy compression.
References-found: 11

