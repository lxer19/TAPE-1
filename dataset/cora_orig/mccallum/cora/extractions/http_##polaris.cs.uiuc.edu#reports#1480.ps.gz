URL: http://polaris.cs.uiuc.edu/reports/1480.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Email: lchoi@csrd.uiuc.edu  yew@cs.umn.edu  
Title: Eliminating Stale Data References through Array Data-Flow Analysis  
Author: Lynn Choi Pen-Chung Yew 
Address: 1308 West Main Street Urbana, IL 61801-1351  200 Union Street, SE Minneapolis, MN 55455-0519  
Affiliation: University of Illinois at Urbana-Champaign Center for Supercomputing R D  University of Minnesota Department of Computer Science  
Abstract: In this paper, we develop a compiler algorithm for detecting references to stale data in shared-memory multiprocessors. The algorithm consists of two key analysis techniques, stale reference detection and locality preserving analysis. While the stale reference detection finds the memory reference patterns that may violate cache coherence, the locality preserving analysis minimizes the number of such stale references by analyzing both temporal and spatial reuses. By computing the regions referenced by arrays inside loops, we extend the previous scalar algorithms [7, 9] for more precise analysis. We have implemented the algorithm on the Polaris parallelizing compiler [19], and using execution-driven simulations on Perfect Perfect benchmarks we demonstrate how unnecessary cache misses can be eliminated by the automatic stale reference detection. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. V. Adve, M. D. Hill, and M. K. Vernon. </author> <title> Comparison of hardware and software cache coherence schemes. </title> <booktitle> Proceedings of the 18th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 298-308, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: In this approach, cache coherence is maintained locally without directory hardware, avoiding the complexity and the overhead associated with the hardware directories. Although the performance of such schemes have been demonstrated through simulations, most of those studies assume either perfect compile-time analysis or analytic models without real compiler implementations <ref> [1, 18] </ref>. It is still unknown how effectively the compiler can detect potential stale references and what kind of performance can be obtained by using a real compiler.
Reference: [2] <author> A. Agarwal and et al. </author> <title> The mit alewife machine: A large-scale distributed-memory multiprocessor. </title> <booktitle> Proceedings of Workshop on Scalable Shared Memory Multiprocessors, </booktitle> <year> 1991. </year>
Reference-contexts: 1. Introduction Directory-based hardware coherence protocols have been studied to enforce the cache coherence in several large-scale research machines <ref> [2, 17] </ref>. However, due to complex and expensive hardware cache/directory controllers required by such schemes, most of recent MPP systems do not provide hardware coherent caches, which prohibits the usefulness of caches for remote memory access.
Reference: [3] <author> R. Ballance, A. Maccabe, and K. Ottenstein. </author> <title> The program dependence web: a representation supporting control data-and demand-driven interpretation of imperative languages. </title> <booktitle> Proceedings of the Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 257-271, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: To obtain more precise array access information, we compute the array region referenced by each array reference. For symbolic analysis involving arrays, we use the gated single assignment (GSA) <ref> [3] </ref>. Two key analysis techniques are used to identify potential stale references: (1) stale reference detection, and (2) locality preserving analysis. The stale reference detection algorithm finds memory reference sequences that may violate cache coherence by using a def-use chain analysis.
Reference: [4] <author> M. Berry et al. </author> <title> The perfect club benchmarks: Effective performance evaluation of supercomputers. </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 3(3) </volume> <pages> 5-40, </pages> <month> Fall </month> <year> 1989. </year>
Reference-contexts: All these compiler algorithms have been implemented in the Polaris parallelizing compiler, and experimentation results on Perfect benchmarks <ref> [4] </ref> are discussed. 1.1. Stale reference condition Memory event ordering Let's first define the ordering of events which leads to a stale reference. <p> Since inlining is most effective for small procedures, we selectively inline a procedure whenever its size (determined in terms of references) is less than a threshold value. 4. Experimentation We have implemented these compiler algorithms in the Polaris compiler [19]. Perfect benchmark suites <ref> [4] </ref> are chosen as our target applications. They are first parallelized by the Polaris compiler. Then, we process the parallelized source codes using both scalar and array flow analysis version of the algorithms given in section 3.
Reference: [5] <author> D. Callahan and K. Kennedy. </author> <title> Analysis of interprocedural side effects in a parallel programming environment. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5 </volume> <pages> 517-550, </pages> <year> 1988. </year>
Reference-contexts: There have been many studies on array data-flow algorithms. Granston proposed algorithms to detect redundant array references [15]. Feautrier [14] gave an algorithm to calculate them exactly. Pugh [21] developed some exact techniques that are substantially faster than Feautrier's. Our implementation is based on the regular section analysis <ref> [5] </ref>, which is less accurate but allows large programs to be analyzed efficiently. In [10], we discuss how our algorithm can be applied to existing compiler-directed coherence schemes [6, 9]. 6.
Reference: [6] <author> H. Cheong. </author> <title> Life span strategy a compiler-based approach to cache coherence. </title> <booktitle> Proceedings of the 1992 International Conference on Supercomputing, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: For example in Cray T3D, lack of cache coherence mechanism forces each cache line loaded by a remote read not to be cached (by an un-cacheable load instruction) or to be flushed [16]. Several compiler-directed coherence schemes have been proposed <ref> [6, 8, 9, 12, 18] </ref>. In this approach, cache coherence is maintained locally without directory hardware, avoiding the complexity and the overhead associated with the hardware directories. <p> In a scalar analysis, even a write to a single element of an array is interpreted as a write to the entire array. This conservative scalar analysis often creates unnecessary cache misses either through invalidations or by redundant accesses to main memory <ref> [6, 8, 9] </ref>. These unnecessary memory accesses can be avoided by a more precise analysis. In the following, we will demonstrate how array access information can refine the stale reference detection. First, we describe our framework for array data-flow analysis such as GSA and subarray descriptors in section 2. <p> Pugh [21] developed some exact techniques that are substantially faster than Feautrier's. Our implementation is based on the regular section analysis [5], which is less accurate but allows large programs to be analyzed efficiently. In [10], we discuss how our algorithm can be applied to existing compiler-directed coherence schemes <ref> [6, 9] </ref>. 6. Conclusion Private caches can greatly improve the performance of large-scale shared-memory multiprocessors if they can be used to cache remote shared data. However, maintaining cache coherence for such systems is still a challenge. Hardware directories can be used to maintain coherence but require complicated hardware directory/cache controllers.
Reference: [7] <author> H. Cheong and A. Veidenbaum. </author> <title> Stale data detection and coherence enforcement using flow analysis. </title> <booktitle> Proceedings of the 1988 International Conference on Parallel Processing, I, </booktitle> <address> Architecture:138-145, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: Assuming only DOALL types of parallelism (no dependences among concurrent tasks), the memory events (1) to (3) should occur in different epochs. Otherwise, there are dependences among concurrent tasks. To detect stale data reference from a source program, the previous compiler algorithms <ref> [7, 9, 23] </ref> look for the following memory reference patterns that consist of (a) a read or a write, (b) one or more epoch boundaries, (c) a write, (d) one or more epoch boundaries, and (e) a read. <p> We call this sequence of events a stale reference sequence. 1.2. Array data-flow analysis Previous compiler algorithms <ref> [7, 9] </ref> treat an entire array as a single variable, which leads to conservative estimation of potential stale references. <p> Previous work There have been several studies on the compiler algorithms for stale reference detection <ref> [7, 9] </ref>. Among them, only Cheong and Veidenbaum included a compiler implementation study using Parafrase [7]. They pioneered a com bination of scalar data-flow analysis and graph algorithms to find potential stale references. <p> Previous work There have been several studies on the compiler algorithms for stale reference detection [7, 9]. Among them, only Cheong and Veidenbaum included a compiler implementation study using Parafrase <ref> [7] </ref>. They pioneered a com bination of scalar data-flow analysis and graph algorithms to find potential stale references. In [9], we proposed a simpler algorithm that also produces additional information for a new compiler-directed cache coherence scheme. That algorithm eliminates the graph construction phase of [7], but it may overestimate the <p> compiler implementation study using Parafrase <ref> [7] </ref>. They pioneered a com bination of scalar data-flow analysis and graph algorithms to find potential stale references. In [9], we proposed a simpler algorithm that also produces additional information for a new compiler-directed cache coherence scheme. That algorithm eliminates the graph construction phase of [7], but it may overestimate the potential stale references by summarizing information from multiple control flow paths. Both algorithms treat each array as a single variable. There have been many studies on array data-flow algorithms. Granston proposed algorithms to detect redundant array references [15].
Reference: [8] <author> T. Chiueh. </author> <title> A generational approach to software-controlled multiprocessor cache coherence. </title> <booktitle> Proceedings of the International Conference on Parallel Processing, </booktitle> <year> 1993. </year>
Reference-contexts: For example in Cray T3D, lack of cache coherence mechanism forces each cache line loaded by a remote read not to be cached (by an un-cacheable load instruction) or to be flushed [16]. Several compiler-directed coherence schemes have been proposed <ref> [6, 8, 9, 12, 18] </ref>. In this approach, cache coherence is maintained locally without directory hardware, avoiding the complexity and the overhead associated with the hardware directories. <p> In a scalar analysis, even a write to a single element of an array is interpreted as a write to the entire array. This conservative scalar analysis often creates unnecessary cache misses either through invalidations or by redundant accesses to main memory <ref> [6, 8, 9] </ref>. These unnecessary memory accesses can be avoided by a more precise analysis. In the following, we will demonstrate how array access information can refine the stale reference detection. First, we describe our framework for array data-flow analysis such as GSA and subarray descriptors in section 2.
Reference: [9] <author> L. Choi and P.-C. Yew. </author> <title> A compiler-directed cache coherence scheme with improved intertask locality. </title> <booktitle> Proceedings of the ACM/IEEE Supercomputing'94, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: For example in Cray T3D, lack of cache coherence mechanism forces each cache line loaded by a remote read not to be cached (by an un-cacheable load instruction) or to be flushed [16]. Several compiler-directed coherence schemes have been proposed <ref> [6, 8, 9, 12, 18] </ref>. In this approach, cache coherence is maintained locally without directory hardware, avoiding the complexity and the overhead associated with the hardware directories. <p> Assuming only DOALL types of parallelism (no dependences among concurrent tasks), the memory events (1) to (3) should occur in different epochs. Otherwise, there are dependences among concurrent tasks. To detect stale data reference from a source program, the previous compiler algorithms <ref> [7, 9, 23] </ref> look for the following memory reference patterns that consist of (a) a read or a write, (b) one or more epoch boundaries, (c) a write, (d) one or more epoch boundaries, and (e) a read. <p> We call this sequence of events a stale reference sequence. 1.2. Array data-flow analysis Previous compiler algorithms <ref> [7, 9] </ref> treat an entire array as a single variable, which leads to conservative estimation of potential stale references. <p> In a scalar analysis, even a write to a single element of an array is interpreted as a write to the entire array. This conservative scalar analysis often creates unnecessary cache misses either through invalidations or by redundant accesses to main memory <ref> [6, 8, 9] </ref>. These unnecessary memory accesses can be avoided by a more precise analysis. In the following, we will demonstrate how array access information can refine the stale reference detection. First, we describe our framework for array data-flow analysis such as GSA and subarray descriptors in section 2. <p> Similarly, by representing the subarray fields in the GSA form, we can perform subarray operations involving symbolic loop bounds. example. 3. Algorithms 3.1. Stale reference detection The algorithm for stale reference detection is an improved version of the algorithm shown in <ref> [9] </ref>. We refine the algorithm both to accommodate multi-word cache blocks as well as to refine analysis for array regions. <p> in a loop accesses the same location in different iterations guarded self-spatial a reference in a loop accesses the execution same cache line in different iterations group-temporal different references access the same location upwardly group-spatial different references access the exposed same cache line uses preserving analysis techniques. epoch flow graph <ref> [9] </ref>. Figure 3 shows the epoch flow graph and STALE (S) computed by the algorithm for the program example in Figure 2. 3.2. Locality Preserving analysis Not all the stale reference patterns lead to a stale reference at runtime. <p> Previous work There have been several studies on the compiler algorithms for stale reference detection <ref> [7, 9] </ref>. Among them, only Cheong and Veidenbaum included a compiler implementation study using Parafrase [7]. They pioneered a com bination of scalar data-flow analysis and graph algorithms to find potential stale references. <p> Previous work There have been several studies on the compiler algorithms for stale reference detection [7, 9]. Among them, only Cheong and Veidenbaum included a compiler implementation study using Parafrase [7]. They pioneered a com bination of scalar data-flow analysis and graph algorithms to find potential stale references. In <ref> [9] </ref>, we proposed a simpler algorithm that also produces additional information for a new compiler-directed cache coherence scheme. That algorithm eliminates the graph construction phase of [7], but it may overestimate the potential stale references by summarizing information from multiple control flow paths. <p> Pugh [21] developed some exact techniques that are substantially faster than Feautrier's. Our implementation is based on the regular section analysis [5], which is less accurate but allows large programs to be analyzed efficiently. In [10], we discuss how our algorithm can be applied to existing compiler-directed coherence schemes <ref> [6, 9] </ref>. 6. Conclusion Private caches can greatly improve the performance of large-scale shared-memory multiprocessors if they can be used to cache remote shared data. However, maintaining cache coherence for such systems is still a challenge. Hardware directories can be used to maintain coherence but require complicated hardware directory/cache controllers.
Reference: [10] <author> L. Choi and P.-C. Yew. </author> <title> Hardware and compiler support for cache coherence in large-scale multiprocessors. </title> <type> Technical Report, </type> <institution> University of Illinois, Computer Science Department, </institution> <type> Ph.D. Thesis, </type> <month> Feb. </month> <year> 1996. </year>
Reference-contexts: Feautrier [14] gave an algorithm to calculate them exactly. Pugh [21] developed some exact techniques that are substantially faster than Feautrier's. Our implementation is based on the regular section analysis [5], which is less accurate but allows large programs to be analyzed efficiently. In <ref> [10] </ref>, we discuss how our algorithm can be applied to existing compiler-directed coherence schemes [6, 9]. 6. Conclusion Private caches can greatly improve the performance of large-scale shared-memory multiprocessors if they can be used to cache remote shared data. However, maintaining cache coherence for such systems is still a challenge.
Reference: [11] <author> R. Cytron, J. Ferrante, and B. K. Rosen. </author> <title> Efficiently computing static single assignment form and the control dependence graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 451-490, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: A framework for array data-flow analysis 2.1. Gated Single Assignment (GSA) form To perform effective array analysis, the symbolic manipulation of expressions is necessary since the computation of array regions often involves the equality and comparison tests between symbolic expressions. static single assignment (SSA) <ref> [11] </ref> is a representation of a program in which each use of a variable is reached by exactly a single definition of the variable. It allows us to track the value of a variable by its name. <p> A backward demand-driven symbolic analysis is used next to compute values and conditions across the confluence points of the control flow graph [22]. In addition to the above 3 functions, another function called ff (array, subscript, value) <ref> [11] </ref> is used to replace the PROGRAM example PROGRAM example DOUBLE PRECISION x, y DOUBLE PRECISION x, y INTEGER*4 i, num INTEGER*4 i, num DIMENSION x (200), y (200) DIMENSION x (200), y (200) S1 PRINT *, 'PROGRAM START' PRINT *, 'PROGRAM START' S2 XDOALL i = 1, 100, 1 XDOALL
Reference: [12] <author> E. Darnell, K. Kennedy, and Mellor-Crummey. </author> <title> Automatic software cache coherence through vectorization. </title> <booktitle> Proceedings of the International Conference on Supercomputing, </booktitle> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: For example in Cray T3D, lack of cache coherence mechanism forces each cache line loaded by a remote read not to be cached (by an un-cacheable load instruction) or to be flushed [16]. Several compiler-directed coherence schemes have been proposed <ref> [6, 8, 9, 12, 18] </ref>. In this approach, cache coherence is maintained locally without directory hardware, avoiding the complexity and the overhead associated with the hardware directories.
Reference: [13] <author> S. J. Eggers and R. H. Katz. </author> <title> A characterization of sharing in parallel programs and its application to coherency protocol evaluation. </title> <booktitle> Proceedings of the 15th Annual International Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1988. </year>
Reference-contexts: However, with multi-word cache lines, there can be implicit dependences due to false sharing <ref> [13] </ref>. Let's look at the program example in Figure 1 (a) and the corresponding memory events (Figure 1 (b)) at runtime. The figure also shows the content for each cache. It assumes two-word cache lines and a write-allocate policy. All caches are empty at the beginning of epoch 1.
Reference: [14] <author> P. Feautrier. </author> <title> Dataflow analysis of array and scalar references. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 20(1), </volume> <month> Feb. </month> <year> 1991. </year>
Reference-contexts: Both algorithms treat each array as a single variable. There have been many studies on array data-flow algorithms. Granston proposed algorithms to detect redundant array references [15]. Feautrier <ref> [14] </ref> gave an algorithm to calculate them exactly. Pugh [21] developed some exact techniques that are substantially faster than Feautrier's. Our implementation is based on the regular section analysis [5], which is less accurate but allows large programs to be analyzed efficiently.
Reference: [15] <author> E. D. Granston and A. V. Veidenbaum. </author> <title> Detecting redundant accesses to array data. </title> <booktitle> Proceedings of the Supercomputing '91, </booktitle> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: Both algorithms treat each array as a single variable. There have been many studies on array data-flow algorithms. Granston proposed algorithms to detect redundant array references <ref> [15] </ref>. Feautrier [14] gave an algorithm to calculate them exactly. Pugh [21] developed some exact techniques that are substantially faster than Feautrier's. Our implementation is based on the regular section analysis [5], which is less accurate but allows large programs to be analyzed efficiently.
Reference: [16] <author> C. R. Inc. </author> <title> Cray T3D System Architecture Overview. </title> <month> Mar. </month> <year> 1993. </year>
Reference-contexts: For example in Cray T3D, lack of cache coherence mechanism forces each cache line loaded by a remote read not to be cached (by an un-cacheable load instruction) or to be flushed <ref> [16] </ref>. Several compiler-directed coherence schemes have been proposed [6, 8, 9, 12, 18]. In this approach, cache coherence is maintained locally without directory hardware, avoiding the complexity and the overhead associated with the hardware directories.
Reference: [17] <author> D. Lenoski, J. Laudon, K. Gharachorloo, A. Gupta, and J. Hennessy. </author> <title> The directory-based cache coherence protocol for the dash computer. </title> <booktitle> Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 148-159, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: 1. Introduction Directory-based hardware coherence protocols have been studied to enforce the cache coherence in several large-scale research machines <ref> [2, 17] </ref>. However, due to complex and expensive hardware cache/directory controllers required by such schemes, most of recent MPP systems do not provide hardware coherent caches, which prohibits the usefulness of caches for remote memory access.
Reference: [18] <author> S. L. Min and J.-L. Baer. </author> <title> Design and analysis of a scalable cache coherence scheme based on clocks and timestamps. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(1) </volume> <pages> 25-44, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: For example in Cray T3D, lack of cache coherence mechanism forces each cache line loaded by a remote read not to be cached (by an un-cacheable load instruction) or to be flushed [16]. Several compiler-directed coherence schemes have been proposed <ref> [6, 8, 9, 12, 18] </ref>. In this approach, cache coherence is maintained locally without directory hardware, avoiding the complexity and the overhead associated with the hardware directories. <p> In this approach, cache coherence is maintained locally without directory hardware, avoiding the complexity and the overhead associated with the hardware directories. Although the performance of such schemes have been demonstrated through simulations, most of those studies assume either perfect compile-time analysis or analytic models without real compiler implementations <ref> [1, 18] </ref>. It is still unknown how effectively the compiler can detect potential stale references and what kind of performance can be obtained by using a real compiler.
Reference: [19] <author> D. A. Padua and et al. </author> <title> Polaris: A new-generation paral-lelizing compiler for mpps. </title> <journal> CSRD Rept. </journal> <volume> No. </volume> <pages> 1306. </pages> <institution> Univ. of Illinois at Urbana-Champaign, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: It is still unknown how effectively the compiler can detect potential stale references and what kind of performance can be obtained by using a real compiler. In this paper, we develop and implement a compiler algorithm on Polaris <ref> [19] </ref> parallelizing compiler to test the feasibility and the performance of a compiler scheme, which can be easily incorporated to implement cache coherence for existing MPP systems that do not have hardware directories. <p> Since inlining is most effective for small procedures, we selectively inline a procedure whenever its size (determined in terms of references) is less than a threshold value. 4. Experimentation We have implemented these compiler algorithms in the Polaris compiler <ref> [19] </ref>. Perfect benchmark suites [4] are chosen as our target applications. They are first parallelized by the Polaris compiler. Then, we process the parallelized source codes using both scalar and array flow analysis version of the algorithms given in section 3.
Reference: [20] <author> D. K. Poulsen and P.-C. Yew. </author> <title> Execution-driven tools for parallel simulation of parallel architectures and applications. </title> <booktitle> Proceedings of the Supercomputing 93, </booktitle> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: Then, we process the parallelized source codes using both scalar and array flow analysis version of the algorithms given in section 3. Cache invalidate operations are inserted at the beginning of procedures and after each call site, while inlining is used selectively. Simulation Execution-driven simulations <ref> [20] </ref> are used to verify the compiler algorithms and to determine the performance of the stale reference detection. All the simulations assume a 16-processor, distributed shared-memory architecture similar to Cray T3D. Each processor contains a 64-KB direct-mapped cache with 4-word cache lines.
Reference: [21] <author> W. Pugh and D. Wonnacott. </author> <title> An evaluation of exact methods for analysis of value-based array data dependences. </title> <booktitle> Sixth Annual Workshop on Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: Both algorithms treat each array as a single variable. There have been many studies on array data-flow algorithms. Granston proposed algorithms to detect redundant array references [15]. Feautrier [14] gave an algorithm to calculate them exactly. Pugh <ref> [21] </ref> developed some exact techniques that are substantially faster than Feautrier's. Our implementation is based on the regular section analysis [5], which is less accurate but allows large programs to be analyzed efficiently.
Reference: [22] <author> P. Tu. </author> <title> Automatic array privatization and demand-driven symbolic analysis. </title> <type> Technical report, </type> <institution> Univ. of Illinois at Urbana-Champaign, Dept. of Computer Science, </institution> <type> Ph.D. Thesis, </type> <year> 1995. </year>
Reference-contexts: We use two symbolic analysis techniques. Global symbolic forward substitution propagates information until it terminates at the confluence points in the control flow graph. A backward demand-driven symbolic analysis is used next to compute values and conditions across the confluence points of the control flow graph <ref> [22] </ref>. <p> When the bounds are omitted, the innermost loop and the outermost loop enclosing the reference is used for the range. Because we only consider do loops, the aggregation is a relatively straightforward interpretation of the index and the boundaries of the loops <ref> [22] </ref>. These operators are called subarray operators and are applied to data descriptors with the same variable name. It will generate a single data descriptor of the variable by taking the subarray operations on their corresponding subarray fields.
Reference: [23] <author> A. V. Veidenbaum. </author> <title> A compiler-assisted cache coherence solution for multiprocessors. </title> <booktitle> Proceedings of the 1986 International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1986. </year>
Reference-contexts: All these compiler algorithms have been implemented in the Polaris parallelizing compiler, and experimentation results on Perfect benchmarks [4] are discussed. 1.1. Stale reference condition Memory event ordering Let's first define the ordering of events which leads to a stale reference. The following sequence of events <ref> [23] </ref> creates a stale reference at runtime: (1) Processor P i reads/writes to a memory location x at time T a ; (2) Another processor P j (j 6= i) writes to x at time T b (&gt; T a ); (3) Processor P i reads the copy of x in <p> Assuming only DOALL types of parallelism (no dependences among concurrent tasks), the memory events (1) to (3) should occur in different epochs. Otherwise, there are dependences among concurrent tasks. To detect stale data reference from a source program, the previous compiler algorithms <ref> [7, 9, 23] </ref> look for the following memory reference patterns that consist of (a) a read or a write, (b) one or more epoch boundaries, (c) a write, (d) one or more epoch boundaries, and (e) a read.
Reference: [24] <author> M. E. Wolf. </author> <title> Improving locality and parallelism in nested loops. </title> <type> Technical report, </type> <institution> Stanford University, Dept. of Computer Science, </institution> <type> Ph.D. Thesis., </type> <month> August </month> <year> 1992. </year>
Reference-contexts: The algorithm is based on a new condition for a stale access. It considers implicit RAW (read-after-write) and WAW (write-after-write) dependences caused by multi-word cache lines (see section 1.1). To further refine reference marking, two locality preserving analysis techniques are used to exploit both temporal and spatial reuses <ref> [24] </ref> in a program. To refine reference marking for both group temporal and spatial reuses, we mark the initial occurrence of upwardly-exposed uses in a program region for potential stale data references. <p> Since each potential stale reference implies a remote memory access instead of a cache hit, we should minimize the number of potential stale references marked at compile time by utilizing both the temporal and spatial locality in a program as much as possible. Wolf <ref> [24] </ref> discussed 4 different types of reuses in a loop as shown in Table 5. Note that the self reuses are inherently loop-specific while group reuses are not.
References-found: 24

