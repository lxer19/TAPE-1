URL: http://ai.eecs.umich.edu/people/wrayre/pubs/aaai-98.ps
Refering-URL: http://ai.eecs.umich.edu/soar/soar8/research.html
Root-URL: 
Email: frobert.wray,lairdg@umich.edu  
Title: Maintaining Consistency in Hierarchical Reasoning  
Author: Robert E. Wray, III and John Laird 
Address: 1101 Beal Ave. Ann Arbor, MI 48109-2110  
Affiliation: Artificial Intelligence Laboratory The University of Michigan  
Abstract: We explore techniques for maintaining consistency in reasoning when employing dynamic hierarchical task decompositions. In particular, we consider the difficulty of maintaining consistency when an agent non-monotonically modifies an assumption in one level of the task hierarchy and that assumption depends upon potentially dynamic assertions higher in the hierarchy. The hypothesis of our work is that reasoning maintenance can be extended to hierarchical systems such that consistency is maintained across all levels of the hierarchy. We introduce two novel extensions to standard reason maintenance approaches, assumption justification and dynamic hierarchical justification, both of which provide the necessary capabilities. The key difference between the two methods is whether a particular assumption (assumption justification) or an entire level of the hierarchy (dynamic hierarchical justification) is disabled when an inconsistency is found. Our investigations suggest that dynamic hierarchical justification has advantages over assumption justification, especially when the task decomposition is well-constructed. Agents using dynamic hierarchical justification also compare favorably to agents using less complete methods for reasoning consistency, improving the reactivity of hierarchical architectures while eliminating the need for knowledge that otherwise would be required to maintain reasoning consistency. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Doyle, J. </author> <year> 1979. </year> <title> A truth maintenance system. </title> <booktitle> Artificial Intelligence 12 </booktitle> <pages> 231-272. </pages>
Reference: <author> Firby, R. J. </author> <year> 1987. </year> <title> An investigation into reactive planning in complex domains. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> 202-206. </pages>
Reference: <author> Forbus, K. D., and deKleer, J. </author> <year> 1993. </year> <title> Building Problem Solvers. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Georgeff, M., and Lansky, A. L. </author> <year> 1987. </year> <title> Reactive reasoning and planning. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> 677-682. </pages>
Reference-contexts: These support sets, in effect, form justifications for levels in the hierarchy. When an assertion in a support set is removed (e.g., a 22 ), the agent responds by removing the level. Architectures such as PRS <ref> (Georgeff & Lansky 1987) </ref> and Soar (Laird, Newell, & Rosenbloom 1987) use architectural mechanisms to retract complete levels of the hierarchy when the support set no longer holds.
Reference: <author> Laird, J. E.; Newell, A.; and Rosenbloom, P. S. </author> <year> 1987. </year> <title> Soar: An architecture for general intelligence. </title> <booktitle> Artificial Intelligence 33 </booktitle> <pages> 1-64. </pages>
Reference-contexts: These support sets, in effect, form justifications for levels in the hierarchy. When an assertion in a support set is removed (e.g., a 22 ), the agent responds by removing the level. Architectures such as PRS (Georgeff & Lansky 1987) and Soar <ref> (Laird, Newell, & Rosenbloom 1987) </ref> use architectural mechanisms to retract complete levels of the hierarchy when the support set no longer holds. A significant disadvantage of the support set is that it is fixed, computed when the subtask is initiated but not updated as problem solving progresses.
Reference: <author> Mitchell, T. M.; Allen, J.; Chalasani, P.; Cheng, J.; Etzioni, O.; Ringuette, M.; and Schlimmer, J. C. </author> <year> 1991. </year> <title> Theo: A framework for self-improving systems. </title>
Reference-contexts: In this case, regular truth maintenance can provide reasoning consistency in hierarchical architectures. Theo <ref> (Mitchell et al. 1991) </ref> is an extreme example of this approach where all reasoning is derived from the entailments of sensors. The drawback of this approach is that assumptions cannot be deliberately modified within subtasks.
Reference: <editor> In VanLehn, K., ed., </editor> <booktitle> Architectures for Intelligence. </booktitle> <publisher> Lawrence Erlbaum Associates. </publisher> <pages> chapter 12, 323-355. </pages>
Reference: <author> Pearson, D. J.; Huffman, S. B.; Willis, M. B.; Laird, J. E.; and Jones, R. M. </author> <year> 1993. </year> <title> A symbolic solution to intelligent real-time control. </title> <booktitle> Robotics and Autonomous Systems 11 </booktitle> <pages> 279-291. </pages>
Reference-contexts: Thus, the longer a particular subtask is active, the more likely assumption justification will begin to severely impact overall performance due to its complexity. Further, when we added assumption justification to Soar, and tested it in Air-Soar <ref> (Pearson et al. 1993) </ref>, a flight simulator domain, the overhead of maintaining all prior assumptions in a level negatively impacted agent performance. In this domain, assumption justification had significant computational cost, requiring 50% more time than the original for the same task.
Reference: <author> Stallman, R. M., and Sussman, G. J. </author> <year> 1977. </year> <title> Forward reasoning and dependency-directed backtracking in a system for computer aided circuit analysis. </title> <booktitle> Artificial Intelligence 9(2) </booktitle> <pages> 135-196. </pages>
Reference-contexts: In (a), assumptions 1 and 2 each depend upon orthogonal sets of assertions. With assumption justification, removal of any assertion in 1's justification will result in the retraction of 1; 2 is unchanged. Thus, assumption justification supports dependency-directed backtracking <ref> (Stallman & Suss-man 1977) </ref> at the level of individual assumptions. On the other hand, with DHJ, the entire level is removed in this situation because all the dependent assertions are collected in the support set for the level.
Reference: <author> Tambe, M.; Johnson, W. L.; Jones, R. M.; Koss, F.; Laird, J. E.; Rosenbloom, P. S.; and Schwamb, K. </author> <year> 1995. </year> <title> Intelligent agents for interactive simulation environments. </title> <journal> AI Magazine 16(1) </journal> <pages> 15-39. </pages>
Reference-contexts: Such hierarchical decomposition has been used in many agent architectures (Firby 1987; Georgeff & Lansky 1987; Copyright c fl1998, American Association for Artificial Intelligence (www.aaai.org). All rights reserved. Laird, Newell, & Rosenbloom 1987) for execution tasks in complex, dynamic environments. For example, TacAir-Soar <ref> (Tambe et al. 1995) </ref>, which has been successfully used to simulate human pilots in large-scale distributed simulations, has over 450 tasks and subtasks in hierarchies that can grow to over 10 levels.
References-found: 10

