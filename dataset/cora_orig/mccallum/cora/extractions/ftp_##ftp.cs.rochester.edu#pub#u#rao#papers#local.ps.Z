URL: ftp://ftp.cs.rochester.edu/pub/u/rao/papers/local.ps.Z
Refering-URL: http://www.cs.rochester.edu/u/rao/papers.html
Root-URL: 
Email: frao,danag@cs.rochester.edu  
Title: Localized Receptive Fields May Mediate Transformation-Invariant Recognition in the Visual Cortex  
Author: Rajesh P. N. Rao and Dana H. Ballard 
Address: Rochester, NY 14627  
Affiliation: Department of Computer Science University of Rochester  
Abstract: Technical Report 97.2 National Resource Laboratory for the Study of Brain and Behavior Department of Computer Science, University of Rochester May 1997 Abstract Neurons in the visual cortex are known to possess localized, oriented receptive fields. It has previously been suggested that these distinctive properties may reflect an efficient image encoding strategy based on maximizing the sparseness of the distribution of output neuronal activities or alternately, extracting the independent components of natural image ensembles. Here, we show that a relatively simple neural solution to the problem of transformation-invariant visual recognition also causes localized, oriented receptive fields to be learned from natural images. These receptive fields, which code for various transformations in the image plane, allow a pair of cooperating neural networks, one estimating object identity (what) and the other estimating object transformations (where), to simultaneously recognize an object and estimate its pose by jointly maximizing the a posteriori probability of generating the observed visual data. We provide experimental results demonstrating the ability of these networks to factor retinal stimuli into object-centered features and object-invariant transformations. The resulting neuronal architecture suggests concrete computational roles for the neuroanatomical connections known to exist between the dorsal and ventral visual pathways.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.J. Bell and T.J. Sejnowski. </author> <title> The `independent components' of natural scenes are edge filters. </title> <note> Submitted to Vision Research, </note> <year> 1996. </year>
Reference-contexts: Similar results were also obtained using an algorithm that extracts the independent components of natural images <ref> [1] </ref>. These algorithms are concerned with the primary task of encoding image features with certain constraints such as sparseness, but do not address the problem of transformation-invariance of these features.
Reference: [2] <author> M.J. Black and A.D. Jepson. Eigentracking: </author> <title> Robust matching and tracking of articulated objects using a view-based representation. </title> <booktitle> In Proc. of ECCV, </booktitle> <pages> pages 329342, </pages> <year> 1996. </year>
Reference-contexts: Note that the above arrangement allows one to approximate the Jacobian for an arbitrary image using the basis vectors in D without having to store image-specific Jacobians for each object. 1 Taylor series expansions have previously been used in computer vision for tasks such as motion processing [8] and tracking <ref> [2] </ref>. 3 Our goal is to estimate the coefficients r and the transformation vector x for a given image and, on a longer time scale, learn appropriate basis vectors in U and D directly from the input image stream. <p> This motivates the need for hierarchical, multiscale methods for transformation estimation (see text). scales than lower ones (see also <ref> [2] </ref>). In such a scheme, top-down signals from a higher level module are fed back and integrated with bottom-up signals to produce reliable estimates of object identity and object transformation at each hierarchical level. A given transformation is represented in a hierarchical and distributed fashion within the various levels.
Reference: [3] <author> C.J. Duffy and R.H. Wurtz. </author> <title> Sensitivity of MST neurons to optic flow stimuli. I. A continuum of response selectivity to large field stimuli. </title> <journal> Journal of Neurophysiology, </journal> <volume> 65:13291345, </volume> <year> 1991. </year> <month> 8 </month>
Reference-contexts: On the other hand, neurons in the dorsal occipitoparietal stream appear to be coding for various types of transformations, irrespective of stimulus-specific properties. For example, cells in the area MSTd have been shown to respond to transformations such as translations, rotations, and expansions/contractions <ref> [3] </ref>. Thus, the neurobiological data strongly suggest that the visual system factors retinal stimuli into object-centered features and their relative transformations. It is also known that visual cortical neurons, especially those in primary visual cortex, possess localized, oriented receptive fields.
Reference: [4] <author> J. Duhamel, C.L. Colby, and M.E. Goldberg. </author> <title> The updating of the representation of visual space in parietal cortex by intended eye movements. </title> <booktitle> Science, </booktitle> <address> 255:9092, </address> <year> 1992. </year>
Reference-contexts: This updating of internal spatial representations by intended movements has been observed in the parietal cortex <ref> [4] </ref> and has inspired numerous models based on the notion of gain fields [16]. The work presented here suggests a possible neural mechanism for converting the raw retinal information to spatial location estimates, which can be modulated by eye movements and other motor activities.
Reference: [5] <author> D.J. Felleman and D.C. Van Essen. </author> <title> Distributed hierarchical processing in the primate cerebral cortex. Cerebral Cortex, </title> <address> 1:147, </address> <year> 1991. </year>
Reference-contexts: The functional dichotomy between object recognition and transformation estimation utilized by this extended model parallels the well-known dichotomy between the dorsal and ventral streams in the primate visual cortex <ref> [5] </ref>. In particular, the architecture of the model suggests concrete computational roles for the neuroanatomical connections known to exist between these two visual pathways [5]. 2 THE OPTIMIZATION FUNCTION Assume that an image, denoted by a vector I of n pixels, can be represented as a linear combination of a set <p> between object recognition and transformation estimation utilized by this extended model parallels the well-known dichotomy between the dorsal and ventral streams in the primate visual cortex <ref> [5] </ref>. In particular, the architecture of the model suggests concrete computational roles for the neuroanatomical connections known to exist between these two visual pathways [5]. 2 THE OPTIMIZATION FUNCTION Assume that an image, denoted by a vector I of n pixels, can be represented as a linear combination of a set of k basis vectors U 1 ; U 2 ; : : : ; U k : I = j=1 2 The coefficients r <p> The dotted lines indicate connections conveying information between the two otherwise parallel networks. These connections suggest a similar computational role for the neuroanatomical connections known to exist between the dorsal and ventral visual pathways <ref> [5] </ref>. estimate x, the residual is filtered via the matrix (DI) T . Note that both the object network and the transformation network use the same residual signal to correct their estimates r and x, and both contribute to it.
Reference: [6] <author> C.G. Gross, C.E. Rocha-Miranda, </author> <title> and D.B. Bender. Visual properties of neurons in inferotem-poral cortex of the macaque. </title> <journal> Journal of Neurophysiology, </journal> <volume> 35:96111, </volume> <year> 1972. </year>
Reference-contexts: Neurons invariant to position and size over receptive fields of several degrees of visual angle have also been reported in higher visual areas such as IT in the ventral oc-cipitotemporal pathway <ref> [6] </ref>. On the other hand, neurons in the dorsal occipitoparietal stream appear to be coding for various types of transformations, irrespective of stimulus-specific properties. For example, cells in the area MSTd have been shown to respond to transformations such as translations, rotations, and expansions/contractions [3].
Reference: [7] <author> G.E. Hinton. </author> <title> A parallel computation that assigns canonical object-based frames of reference. </title> <booktitle> In 7th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 683685, </pages> <year> 1981. </year>
Reference-contexts: Such a property has also been the goal of some previously proposed models such as <ref> [7, 11, 13] </ref>.
Reference: [8] <author> B.K.P. Horn and B.G. Schunck. </author> <title> Determining optical flow. </title> <journal> Artificial Intelligence, </journal> <volume> 17:185203, </volume> <year> 1981. </year>
Reference-contexts: 7 7 (6) Note that the above arrangement allows one to approximate the Jacobian for an arbitrary image using the basis vectors in D without having to store image-specific Jacobians for each object. 1 Taylor series expansions have previously been used in computer vision for tasks such as motion processing <ref> [8] </ref> and tracking [2]. 3 Our goal is to estimate the coefficients r and the transformation vector x for a given image and, on a longer time scale, learn appropriate basis vectors in U and D directly from the input image stream.
Reference: [9] <author> D.H. Hubel and T.N. Wiesel. </author> <title> Receptive fields and functional architecture of monkey striate cortex. </title> <journal> Journal of Physiology (London), </journal> <volume> 195:215243, </volume> <year> 1968. </year>
Reference-contexts: 1 INTRODUCTION A central problem faced by the visual system is that of recognizing objects irrespective of transformations such as translations, rotations, and scale changes. Neurophysiological studies during the past several decades have provided some important clues regarding the neural mechanisms underlying this invariance to transformations. Hubel and Wiesel <ref> [9] </ref> first reported the existence of fl This research was supported by NIH/PHS research grant 1-P41-RR09283. 1 complex cells in the primary visual cortex whose responses remained invariant to the location of stimuli in their receptive field. <p> Thus, the neurobiological data strongly suggest that the visual system factors retinal stimuli into object-centered features and their relative transformations. It is also known that visual cortical neurons, especially those in primary visual cortex, possess localized, oriented receptive fields. It was first suggested by Hubel and Wiesel <ref> [9] </ref> that these neurons could be coding for edges and bars in input images at different orientations.
Reference: [10] <author> M.I. Jordan and D.E. Rumelhart. </author> <title> Forward models: Supervised learning with a distal teacher. </title> <booktitle> Cognitive Science, </booktitle> <address> 16:307354, </address> <year> 1992. </year>
Reference-contexts: (and relatively constant) negative correlations with the left translation vectors supports the hypothesis that transformation estimates in the model are object-invariant. used to drive a motor routine such as a saccadic eye movement, the resulting efference copy of the motor signal can be used to update the transformation estimate x <ref> [10] </ref>. This updating of internal spatial representations by intended movements has been observed in the parietal cortex [4] and has inspired numerous models based on the notion of gain fields [16].
Reference: [11] <author> B.A. Olshausen, C.H. Anderson, and D.C. Van Essen. </author> <title> A multiscale dynamic routing circuit for forming size- and position-invariant object representations. </title> <journal> Journal of Computational Neuroscience, </journal> <volume> 2:4562, </volume> <year> 1995. </year>
Reference-contexts: Such a property has also been the goal of some previously proposed models such as <ref> [7, 11, 13] </ref>.
Reference: [12] <author> B.A. </author> <title> Olshausen and D.J. Field. Emergence of simple-cell receptive field properties by learning a sparse code for natural images. </title> <booktitle> Nature, </booktitle> <address> 381:607609, </address> <year> 1996. </year>
Reference-contexts: More recently, it has been shown that a neural network that maximizes the sparseness of the distribution of output activities develops, when trained on natural images, synaptic weights with localized, oriented receptive fields <ref> [12] </ref>. Similar results were also obtained using an algorithm that extracts the independent components of natural images [1]. These algorithms are concerned with the primary task of encoding image features with certain constraints such as sparseness, but do not address the problem of transformation-invariance of these features. <p> We can additionally add to E 1 the terms relating to prior distributions for the parameters. Here, we use zero-mean Gaussian distributions for the model priors (see <ref> [12] </ref> for other alternatives), yielding the optimization function: E = E 1 + ffjjrjj 2 + fijjxjj 2 + fljjU jj 2 + jjDjj 2 (11) where the operator jjjj 2 denotes the sum of squares of the elements of the vector or matrix argument.
Reference: [13] <author> W. Pitts and W.S. McCulloch. </author> <title> How we know universals: the perception of auditory and visual forms. </title> <journal> Bulletin of Mathematical Biophysics, </journal> <volume> 9:127147, </volume> <year> 1947. </year>
Reference-contexts: Such a property has also been the goal of some previously proposed models such as <ref> [7, 11, 13] </ref>.
Reference: [14] <author> R.P.N. Rao and D.H. Ballard. </author> <title> A class of stochastic models for invariant recognition, motion, and stereo. </title> <type> Technical Report 96.1, </type> <institution> National Resource Laboratory for the Study of Brain and Behavior, Department of Computer Science, University of Rochester, </institution> <month> June </month> <year> 1996. </year>
Reference-contexts: One way of approximating the Jacobian J is to simply use a fixed matrix U 0 learned from a set of training images <ref> [14] </ref>. Unfortunately, this does not acknowledge the fact that the Jacobian is a function of the current image. A better method is to approximate the Jacobian as a linear function of the image I. Let J i be the ith column of the Jacobian matrix J . <p> The results presented here involved small translations of retinal stimuli. Other transformations such as scaling, rotation, swing, and tilt can also be handled if these are included in the training data <ref> [14] </ref>. Larger transformations can be handled by the model up to a certain degree of accuracy (Figure 4) but the error E in image reconstruction gradually increases due to the insufficiencies of a first-order Taylor series approximation.
Reference: [15] <author> R.P.N. Rao and D.H. Ballard. </author> <title> Dynamic model of visual recognition predicts neural response properties in the visual cortex. </title> <booktitle> Neural Computation, </booktitle> <address> 9(4):721763, </address> <year> 1997. </year>
Reference-contexts: The model described herein extends the previously proposed Kalman filter model of the visual cortex <ref> [15] </ref> by including a first-order component that represents transformations of input features, in addition to the zeroth order component that represents object-centered features. <p> It is easy to show that minimizing E 1 is equivalent to maximizing the log likelihood of generating the observed data I (x) with respect to the model parameters U , D, r, and x (see, for example, <ref> [15] </ref>). We can additionally add to E 1 the terms relating to prior distributions for the parameters. <p> The coefficients ff, fi, fl, and are parameters related to the variances of the prior distributions. Minimizing E is thus equivalent to maximizing the a posteriori probability of generating the observed data I (x) (see, for example, <ref> [15] </ref>). 3 NETWORK DYNAMICS AND SYNAPTIC LEARNING RULES For the purposes of stability, we minimize E with respect to r and x for fixed values of U and D. The basis vectors U and D are learned on a slower time scale for fixed values of r and x. <p> In the case of the object identity estimate r, the residual is filtered using the feedforward matrix (U + XU ) T where as in the case of the transformation 4 <ref> [15] </ref> that estimates the zeroth order component of the input. The bottom unshaded portion of the figure shows the transformation estimating (Where) network that computes the first order transformations in the input. <p> Fortunately, this problem can be addressed using a hierarchical estimation scheme (such as in <ref> [15] </ref>), wherein higher levels operate over larger spatiotemporal 7 A set of 100 randomly selected natural image patches (vectors I normalized to length 1) were translated in two different directions (leftwards and rightwards), and the values of the optimization function E, representing the image reconstruction error, were used to plot the
Reference: [16] <author> D. Zipser and R.A. Andersen. </author> <title> A back-propagation programmed network that simulates response properties of a subset of posterior parietal neurons. </title> <booktitle> Nature, </booktitle> <address> 331:679684, </address> <year> 1988. </year> <month> 9 </month>
Reference-contexts: This updating of internal spatial representations by intended movements has been observed in the parietal cortex [4] and has inspired numerous models based on the notion of gain fields <ref> [16] </ref>. The work presented here suggests a possible neural mechanism for converting the raw retinal information to spatial location estimates, which can be modulated by eye movements and other motor activities. The results presented here involved small translations of retinal stimuli.
References-found: 16

