URL: http://www.demo.cs.brandeis.edu/papers/ieeenn.ps.gz
Refering-URL: http://www.demo.cs.brandeis.edu/papers/long.html
Root-URL: http://www.cs.brandeis.edu
Email: pja@cis.ohio-state.edu saunders@cis.ohio-state.edu pollack@cis.ohio-state.edu  
Title: An Evolutionary Algorithm that Constructs Recurrent Neural Networks  
Author: Peter J. Angeline, Gregory M. Saunders and Jordan B. Pollack 
Note: To Appear in: IEEE Transactions on Neural Networks  
Address: Columbus, Ohio 43210  
Affiliation: Laboratory for Artificial Intelligence Research Computer and Information Science Department The Ohio State University  
Abstract: Standard methods for inducing both the structure and weight values of recurrent neural networks fit an assumed class of architectures to every task. This simplification is necessary because the interactions between network structure and function are not well understood. Evolutionary computation, which includes genetic algorithms and evolutionary programming, is a population-based search method that has shown promise in such complex tasks. This paper argues that genetic algorithms are inappropriate for network acquisition and describes an evolutionary program, called GNARL, that simultaneously acquires both the structure and weights for recurrent networks. This algorithms empirical acquisition method allows for the emergence of complex behaviors and topologies that are potentially excluded by the artificial architectural constraints imposed in standard network induction methods. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. G. Barto. </author> <title> Connectionist learning for control. </title> <editor> In W. T. Miller III, R. S. Sutton, and P. J. Werbos, editors, </editor> <booktitle> Neural Networks for Control, chapter 1, </booktitle> <pages> pages 558. </pages> <publisher> MIT Press, </publisher> <address> Cam bridge, </address> <year> 1990. </year>
Reference-contexts: 1.0 Introduction In its complete form, network induction entails both parametric and structural learning <ref> [1] </ref>, i.e., learning both weight values and an appropriate topology of nodes and links. Current methods to solve this task fall into two broad categories. <p> The number of initial links is chosen similarly from a second user-supplied range. The incident nodes for each link are chosen in accordance with the structural mutations described below. Once a topology has been chosen, all links are assigned random weights, selected uniformly from the range <ref> [-1, 1] </ref>. There is nothing in this initialization procedure that forces a node to have any incident links, let alone for a path to exist between the input and output nodes. <p> Generating an offspring involves three steps: copying the parent, determining the severity of the mutations to be performed, and finally mutating the copy. Network mutations are separated into two classes, corresponding with the types of learning discussed in <ref> [1] </ref>. <p> To compensate, GNARL updates weights using a variant of equation 3. First, the instantaneous temperature of the network is computed: (EQ 4) where U (0, 1) is a uniform random variable over the interval <ref> [0, 1] </ref>. This new temperature, varying from 0 to T (h), is then substituted into equation 3: (EQ 5) In essence, this modification lessens the frequency of large parametric mutations without disallowing them completely.
Reference: [2] <author> T. Ash. </author> <title> Dynamic node creation in backpropagation networks. </title> <booktitle> Connection Science, </booktitle> <address> 1(4):365375, </address> <year> 1989. </year>
Reference-contexts: This is a form of structural hill climbing, which is susceptible to becoming trapped at structural local minima. In addition, constructive and destructive algorithms make simplifying architectural assumptions to facilitate network induction. For example, Ash <ref> [2] </ref> allows only feedforward networks; Fahlman [6] assumes a restricted form of recurrence, and Chen et al. [7] explore only fully connected topologies. This creates a situation in which the task is forced into the architecture rather than the architecture being fit to the task.
Reference: [3] <author> M. Frean. </author> <title> The upstart algorithm: A method for constructing and training feed-forward neu ral networks. </title> <type> Technical Report Preprint 89/469, </type> <institution> Edinburgh Physics Dept, </institution> <year> 1990. </year>
Reference: [4] <author> S. J. Hanson. </author> <title> Meiosis networks. </title> <editor> In D. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <pages> pages 533541. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference: [5] <author> S. E. Fahlman and C. Lebiere. </author> <title> The cascade-correlation architecture. </title> <editor> In D. S. Touretsky, editor, </editor> <booktitle> Advances in Neural Information Processing Structures 2, </booktitle> <pages> pages 524532. </pages> <publisher> Morgan Kauf mann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference: [6] <author> S. Fahlman. </author> <title> The recurrent cascade-correlation architecture. </title> <editor> In R. Lippmann, J. Moody, and D. Touretzky, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 3, </booktitle> <pages> pages 190 196. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: This is a form of structural hill climbing, which is susceptible to becoming trapped at structural local minima. In addition, constructive and destructive algorithms make simplifying architectural assumptions to facilitate network induction. For example, Ash [2] allows only feedforward networks; Fahlman <ref> [6] </ref> assumes a restricted form of recurrence, and Chen et al. [7] explore only fully connected topologies. This creates a situation in which the task is forced into the architecture rather than the architecture being fit to the task.
Reference: [7] <author> D. Chen, C. Giles, G. Sun, H. Chen, Y. Less, and M. Goudreau. </author> <title> Constructive learning of recurrent neural networks. </title> <booktitle> IEEE International Conference on Neural Networks, </booktitle> <volume> 3:1196 1201, </volume> <year> 1993. </year>
Reference-contexts: In addition, constructive and destructive algorithms make simplifying architectural assumptions to facilitate network induction. For example, Ash [2] allows only feedforward networks; Fahlman [6] assumes a restricted form of recurrence, and Chen et al. <ref> [7] </ref> explore only fully connected topologies. This creates a situation in which the task is forced into the architecture rather than the architecture being fit to the task.
Reference: [8] <author> M. R. Azimi-Sadjadi, S. Sheedvash, and F. O. Trujillo. </author> <title> Recursive dynamic node creation in multilayer neural networks. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 4(2):242256, </volume> <year> 1993. </year>
Reference: [9] <author> M. Mozer and P. Smolensky. </author> <title> Skeletonization: A technique for trimming the fat from a network via relevance assessment. </title> <editor> In D. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems 1, </booktitle> <pages> pages 107115. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference: [10] <author> Y. L. Cun, J. Denker, and S. Solla. </author> <title> Optimal brain damage. </title> <editor> In D. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems 2. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year> <institution> The Ohio State University July 16, </institution> <year> 1993 </year> <month> 25 </month>
Reference: [11] <author> B. Hassibi and D. G. Stork. </author> <title> Second order derivatives for network pruning: Optimal brain surgeon. </title> <editor> In S. J. Hanson, J. D. Cowan, and C. L. Giles, editors, </editor> <booktitle> Advances in Neural Infor mation Processing Systems 5, </booktitle> <pages> pages 164171. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference: [12] <author> C. W. Omlin and C. L. Giles. </author> <title> Pruning recurrent neural networks for improved generalization performance. </title> <type> Technical Report Tech Report No 93-6, </type> <institution> Computer Science Department, Rens selaer Polytechnic Institute, </institution> <month> April </month> <year> 1993. </year>
Reference: [13] <author> L. J. Fogel, A. J. Owens, and M. J. Walsh. </author> <title> Artificial Intelligence through Simulated Evolu tion. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1966. </year>
Reference-contexts: This paper presents GNARL, a network induction algorithm that simultaneously acquires both network topology and weight values while making minimal architectural restrictions and avoiding structural hill climbing. The algorithm, described in section 3, is an instance of evolutionary programming <ref> [13, 14] </ref>, a class of evolutionary computation that has been shown to perform well at function optimization. Section 2 argues that this class of evolutionary computation is better suited for evolving neural networks than genetic algorithms [15, 16], a more popular class of evolutionary computation.
Reference: [14] <author> D. B. Fogel. </author> <title> Evolving Artificial Intelligence. </title> <type> Ph.D. thesis, </type> <institution> University of California, </institution> <address> San Diego, </address> <year> 1992. </year>
Reference-contexts: This paper presents GNARL, a network induction algorithm that simultaneously acquires both network topology and weight values while making minimal architectural restrictions and avoiding structural hill climbing. The algorithm, described in section 3, is an instance of evolutionary programming <ref> [13, 14] </ref>, a class of evolutionary computation that has been shown to perform well at function optimization. Section 2 argues that this class of evolutionary computation is better suited for evolving neural networks than genetic algorithms [15, 16], a more popular class of evolutionary computation. <p> Fogel et al. [35] investigate training feedforward networks on some classic connectionist problems. McDonnell and Waagen [36] use EP to evolve the connectivity of feedforward networks with a constant number of hidden units by evolving both a weight matrix and a connectivity matrix. Fogel <ref> [14] </ref>, [37] uses EP to induce three-layer fully-connected feedforward networks with a variable number of hidden units that employ good strategies for playing Tic-Tac-Toe. <p> The structural mutation used in <ref> [14, 37] </ref> adds or deletes a single hidden unit with equal probability Evolutionary programming provides distinct advantages over genetic algorithms when evolving networks. First, EP manipulates networks directly, thus obviating the need for a dual representation and the associated interpretation function. <p> Networks scoring in the top 50% are designated as the parents of the next generation; all other networks are discarded. This selection method is used in many EP algorithms although competitive methods of selection have also been investigated <ref> [14] </ref>. Generating an offspring involves three steps: copying the parent, determining the severity of the mutations to be performed, and finally mutating the copy. Network mutations are separated into two classes, corresponding with the types of learning discussed in [1]. <p> allows a coarse-grained search initially, and a progressively finer-grained search as a network approaches a solution to the task, a process described more concretely below. 3.1.2 Parametric Mutation of Networks Parametric mutations are accomplished by perturbing each weight w of a network h with gaussian noise, a method motivated by <ref> [37, 14] </ref>. In that body of work, weights are modified as follows: (EQ 3) f h ( ) -= The Ohio State University July 16, 1993 9 where a is a user-defined proportionality constant, and N (m, s 2 ) is a gaussian random variable as before. <p> Biasing the link selection process in this way is necessary when there is a large differential between the number of hidden nodes and the number of input or output nodes. This parameter was set to 0.2 in the experiments described in the next section. Research in <ref> [14] </ref> and [37] uses the heuristic of adding or deleting at most a single fully connected node per structural mutation.
Reference: [15] <author> J. H. Holland. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, MI, </address> <year> 1975. </year>
Reference-contexts: The algorithm, described in section 3, is an instance of evolutionary programming [13, 14], a class of evolutionary computation that has been shown to perform well at function optimization. Section 2 argues that this class of evolutionary computation is better suited for evolving neural networks than genetic algorithms <ref> [15, 16] </ref>, a more popular class of evolutionary computation. Finally, section 4 demonstrates GNARLs ability to create recurrent networks for a variety of problems of interest. 2.0 Evolving Connectionist Networks Evolutionary computation provides a promising collection of algorithms for structural and parametric learning of recurrent networks [17]. <p> New population members, called offspring, are created using specialized reproduction heuristics. Using the population, reproduction heuristics, and fitness function, evolutionary computation implements a nonmonotonic search that performs well in complex multimodal environments. Classes of evolutionary computation can be distinguished by examining the specific reproduction heuristics employed. Genetic algorithms (GAs) <ref> [15, 16] </ref> are a popular form of evolutionary computation that rely chiey on the reproduction heuristic of crossover. 1 This operator forms offspring by recombining representational components from two members of the population without regard to content. <p> Characterizing tasks for which crossover is a beneficial operator is an open question. Current theory suggests that crossover will tend to recombine short, connected substrings of the bit string representation that correspond to above-average task solutions when evaluated <ref> [16, 15] </ref>. These substrings are called building blocks, making explicit the intuition that larger structures with high fitness are built out of smaller structures with moderate fitness.
Reference: [16] <author> D. E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addi son-Wesley Publishing Company, Inc., </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: The algorithm, described in section 3, is an instance of evolutionary programming [13, 14], a class of evolutionary computation that has been shown to perform well at function optimization. Section 2 argues that this class of evolutionary computation is better suited for evolving neural networks than genetic algorithms <ref> [15, 16] </ref>, a more popular class of evolutionary computation. Finally, section 4 demonstrates GNARLs ability to create recurrent networks for a variety of problems of interest. 2.0 Evolving Connectionist Networks Evolutionary computation provides a promising collection of algorithms for structural and parametric learning of recurrent networks [17]. <p> New population members, called offspring, are created using specialized reproduction heuristics. Using the population, reproduction heuristics, and fitness function, evolutionary computation implements a nonmonotonic search that performs well in complex multimodal environments. Classes of evolutionary computation can be distinguished by examining the specific reproduction heuristics employed. Genetic algorithms (GAs) <ref> [15, 16] </ref> are a popular form of evolutionary computation that rely chiey on the reproduction heuristic of crossover. 1 This operator forms offspring by recombining representational components from two members of the population without regard to content. <p> Characterizing tasks for which crossover is a beneficial operator is an open question. Current theory suggests that crossover will tend to recombine short, connected substrings of the bit string representation that correspond to above-average task solutions when evaluated <ref> [16, 15] </ref>. These substrings are called building blocks, making explicit the intuition that larger structures with high fitness are built out of smaller structures with moderate fitness.
Reference: [17] <author> D. B. Fogel. </author> <title> An introduction to simulated evolutionary optimization. </title> <note> This issue. </note>
Reference-contexts: Finally, section 4 demonstrates GNARLs ability to create recurrent networks for a variety of problems of interest. 2.0 Evolving Connectionist Networks Evolutionary computation provides a promising collection of algorithms for structural and parametric learning of recurrent networks <ref> [17] </ref>. These algorithms are distinguished by their reliance on a population of search space positions, rather than a single position, to locate extrema of a function defined over the search space.
Reference: [18] <author> A. P. Wieland. </author> <title> Evolving neural network controllers for unstable systems. </title> <booktitle> In IEEE International Joint Conference on Neural Networks, pages II-667 II-673, </booktitle> <publisher> IEEE Press, </publisher> <address> Seattle, WA, </address> <year> 1990. </year>
Reference: [19] <author> D. Montana and L. Davis. </author> <title> Training feedforward neural networks using genetic algorithms. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 762767, </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference: [20] <author> D. Whitley, T. Starkweather, and C. Bogart. </author> <title> Genetic algorithms and neural networks: Opti mizing connections and connectivity. </title> <booktitle> Parallel Computing, </booktitle> <address> 14:347361, </address> <year> 1990. </year>
Reference: [21] <author> R. D. Beer and J. C. Gallagher. </author> <title> Evolving dynamical neural networks for adaptive behavior. Adaptive Behavior, </title> <address> 1(1):91122, </address> <year> 1992. </year>
Reference: [22] <author> G. F. Miller, P. M. Todd, and S. U. Hegde. </author> <title> Designing neural networks using genetic algorithms. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 379384. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference-contexts: Other work allows a variable topology, but disassociates structure acquisition from acquisition of weight values by interweaving a GA search for network topology with a traditional parametric training algorithm (e.g., backpropagation) over weights (e.g., <ref> [22, 23] </ref>). Some studies attempt to coevolve both the topology and weight values within the GA framework, but as in the connectionist systems described above, the network architectures are restricted (e.g., [24 - 26]).
Reference: [23] <author> R. K. Belew, J. McInerney, and N. N. Schraudolf. </author> <title> Evolving networks: Using the genetic algorithm with connectionist learning. </title> <type> Technical Report CS90-174, </type> <institution> University of Califor nia, </institution> <address> San Diego, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Other work allows a variable topology, but disassociates structure acquisition from acquisition of weight values by interweaving a GA search for network topology with a traditional parametric training algorithm (e.g., backpropagation) over weights (e.g., <ref> [22, 23] </ref>). Some studies attempt to coevolve both the topology and weight values within the GA framework, but as in the connectionist systems described above, the network architectures are restricted (e.g., [24 - 26]).
Reference: [24] <author> J. Torreele. </author> <title> Temporal processing with recurrent networks: An evolutionary approach. </title> <editor> In R. K. Belew and L. B. Booker, editors, </editor> <booktitle> Fourth International Conference on Genetic Algo rithms, </booktitle> <pages> pages 555561. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1991. </year>
Reference: [25] <author> M. A. Potter. </author> <title> A genetic cascade-correlation learning algorithm. </title> <booktitle> In Proceedings of COGANN-92 International Workshop on Combinations of Genetic Algorithms and Neural Networks, </booktitle> <year> 1992. </year>
Reference: [26] <author> N. Karunanithi, R. Das, and D. Whitley. </author> <title> Genetic cascade learning for neural networks. </title> <booktitle> In Proceedings of COGANN-92 International Workshop on Combinations of Genetic Algo rithms and Neural Networks, </booktitle> <year> 1992. </year> <institution> The Ohio State University July 16, </institution> <year> 1993 </year> <month> 26 </month>
Reference: [27] <author> D. E. Goldberg. </author> <title> Genetic algorithms and Walsh functions: Part 2, Deception and its analysis. </title> <journal> Complex Systems, </journal> <volume> 3:153171, </volume> <year> 1989. </year>
Reference-contexts: Crossover tends to be most effective in environments where the fitness of a member of the population is reasonably correlated with the expected ability of its representational components <ref> [27] </ref>. Environments where this is not true are called deceptive [28]. There are three forms of deception when using crossover to evolve connectionist networks. The first involves networks that share both a common topology and common weights.
Reference: [28] <author> D. E. Goldberg. </author> <title> Genetic algorithms and Walsh functions: Part 1, A gentle introduction. </title> <journal> Complex Systems, </journal> <volume> 3:129152, </volume> <year> 1989. </year>
Reference-contexts: Crossover tends to be most effective in environments where the fitness of a member of the population is reasonably correlated with the expected ability of its representational components [27]. Environments where this is not true are called deceptive <ref> [28] </ref>. There are three forms of deception when using crossover to evolve connectionist networks. The first involves networks that share both a common topology and common weights. Because the interpretation function may be many-to-one, two such networks need not have the same bit string representation (see Figure 2).
Reference: [29] <editor> J. D. Schaffer, D. Whitley, and L. J. Eshelman. </editor> <title> Combinations of genetic algorithms and neural networks: A survey of the state of the art. </title> <booktitle> In Proceedings of COGANN-92 International Workshop on Combinations of Genetic Algorithms and Neural Networks, </booktitle> <year> 1992. </year>
Reference-contexts: The Ohio State University July 16, 1993 5 resulting networks will tend to perform worse than their parents because they do not possess key computational components for the task. Schaffer et al. <ref> [29] </ref> term this the competing conventions problem, and point out that the number of competing conventions grows exponentially with the number of hidden units. The second form of deception involves two networks with identical topologies but different weights.
Reference: [30] <author> G. E. Hinton, J. L. McClelland, and D. E. Rumelhart. </author> <title> Distributed representations. </title> <editor> In D. E. Rumelhart and J. L. McClelland, editors, </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition, volume 1: Foundations, </booktitle> <pages> pages 77109. </pages> <publisher> MIT Press, </publisher> <address> Cam bridge, MA, </address> <year> 1986. </year>
Reference-contexts: The second form of deception involves two networks with identical topologies but different weights. It is well known that for a given task, a single connectionist topology affords multiple solutions for a task, each implemented by a unique distributed representation spread across the hidden units <ref> [30, 31] </ref>. While the removal of a small number of nodes has been shown to effect only minor alterations in the performance of a trained network [30, 31], the computational role each node plays in the overall representation of the task solution is determined purely by the presence and strengths of <p> given task, a single connectionist topology affords multiple solutions for a task, each implemented by a unique distributed representation spread across the hidden units <ref> [30, 31] </ref>. While the removal of a small number of nodes has been shown to effect only minor alterations in the performance of a trained network [30, 31], the computational role each node plays in the overall representation of the task solution is determined purely by the presence and strengths of its interconnections. Furthermore, there need be no correlation between distinct distributed representations over a particular network architecture for a given task.
Reference: [31] <author> T. J. Sejnowski and C. R. Rosenberg. </author> <title> Parallel networks that learn to pronounce english text. </title> <journal> Complex Systems, </journal> <volume> 1:145168, </volume> <year> 1987. </year>
Reference-contexts: The second form of deception involves two networks with identical topologies but different weights. It is well known that for a given task, a single connectionist topology affords multiple solutions for a task, each implemented by a unique distributed representation spread across the hidden units <ref> [30, 31] </ref>. While the removal of a small number of nodes has been shown to effect only minor alterations in the performance of a trained network [30, 31], the computational role each node plays in the overall representation of the task solution is determined purely by the presence and strengths of <p> given task, a single connectionist topology affords multiple solutions for a task, each implemented by a unique distributed representation spread across the hidden units <ref> [30, 31] </ref>. While the removal of a small number of nodes has been shown to effect only minor alterations in the performance of a trained network [30, 31], the computational role each node plays in the overall representation of the task solution is determined purely by the presence and strengths of its interconnections. Furthermore, there need be no correlation between distinct distributed representations over a particular network architecture for a given task.
Reference: [32] <author> J. Koza and J. Rice. </author> <title> Genetic generation of both the weights and architecture for a neural network. </title> <booktitle> In IEEE International Joint Conference on Neural Networks, </booktitle> <address> pages II-397 II-404, Seattle, WA, </address> <publisher> IEEE Press, </publisher> <year> 1991. </year>
Reference-contexts: This point has been tacitly validated in the genetic algorithm literature by a trend towards a reduced reliance on binary representations when evolving networks (e.g. <ref> [32, 33] </ref>). Crossover, however, is still commonplace. 2.2 Networks and Evolutionary Programming Unlike genetic algorithms, evolutionary programming (EP) [14,34] defines representation-dependent mutation operators that create offspring within a specific locus of the parent (see Figure 3).
Reference: [33] <author> R. Collins and D. Jefferson. </author> <title> An artificial neural network representation for artificial organisms. </title> <editor> In H. P. Schwefel and R. Manner, editors, </editor> <title> Parallel Problem Solving from Nature. </title> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: This point has been tacitly validated in the genetic algorithm literature by a trend towards a reduced reliance on binary representations when evolving networks (e.g. <ref> [32, 33] </ref>). Crossover, however, is still commonplace. 2.2 Networks and Evolutionary Programming Unlike genetic algorithms, evolutionary programming (EP) [14,34] defines representation-dependent mutation operators that create offspring within a specific locus of the parent (see Figure 3).
Reference: [34] <author> D. B. Fogel. </author> <title> A brief history of simulated evolution. </title> <editor> In D. B. Fogel and W. Atmar, editors, </editor> <booktitle> Proceedings of the First Annual Conference on Evolutionary Programming, Evolutionary Programming Society, </booktitle> <address> La Jolla, CA., </address> <year> 1992. </year>
Reference: [35] <author> D. B. Fogel, L. J. Fogel, and V. W. Porto. </author> <title> Evolving neural networks. </title> <journal> Biological Cybernetics, </journal> <volume> 63:487493, </volume> <year> 1990. </year>
Reference-contexts: Relatively few previous EP systems have addressed the problem of evolving connectionist networks. Fogel et al. <ref> [35] </ref> investigate training feedforward networks on some classic connectionist problems. McDonnell and Waagen [36] use EP to evolve the connectivity of feedforward networks with a constant number of hidden units by evolving both a weight matrix and a connectivity matrix.
Reference: [36] <editor> J. R. McDonnell and D. Waagen. </editor> <title> Determining neural network connectivity using evolutionary programming. </title> <booktitle> In Twenty-fifth Asilomar Conferences on Signals, Systems, and Comput ers, </booktitle> <address> Monterey, CA, </address> <year> 1992. </year>
Reference-contexts: Relatively few previous EP systems have addressed the problem of evolving connectionist networks. Fogel et al. [35] investigate training feedforward networks on some classic connectionist problems. McDonnell and Waagen <ref> [36] </ref> use EP to evolve the connectivity of feedforward networks with a constant number of hidden units by evolving both a weight matrix and a connectivity matrix. <p> The implementations of structural mutations in these studies differ somewhat. McDonnell and Waagen <ref> [36] </ref> randomly select a set of weights and alters their values with a probability based on the variance of the incident nodes activation over the training set; connections from nodes with a high variance having less of a chance of being altered.
Reference: [37] <author> D. B. Fogel. </author> <title> Using evolutionary programming to create neural networks that are capable of playing Tic-Tac-Toe. </title> <booktitle> In International Conference on Neural Networks, </booktitle> <pages> pages 875880. </pages> <publisher> IEEE Press, </publisher> <address> San Francisco, CA, </address> <year> 1993. </year>
Reference-contexts: Fogel et al. [35] investigate training feedforward networks on some classic connectionist problems. McDonnell and Waagen [36] use EP to evolve the connectivity of feedforward networks with a constant number of hidden units by evolving both a weight matrix and a connectivity matrix. Fogel [14], <ref> [37] </ref> uses EP to induce three-layer fully-connected feedforward networks with a variable number of hidden units that employ good strategies for playing Tic-Tac-Toe. <p> The structural mutation used in <ref> [14, 37] </ref> adds or deletes a single hidden unit with equal probability Evolutionary programming provides distinct advantages over genetic algorithms when evolving networks. First, EP manipulates networks directly, thus obviating the need for a dual representation and the associated interpretation function. <p> allows a coarse-grained search initially, and a progressively finer-grained search as a network approaches a solution to the task, a process described more concretely below. 3.1.2 Parametric Mutation of Networks Parametric mutations are accomplished by perturbing each weight w of a network h with gaussian noise, a method motivated by <ref> [37, 14] </ref>. In that body of work, weights are modified as follows: (EQ 3) f h ( ) -= The Ohio State University July 16, 1993 9 where a is a user-defined proportionality constant, and N (m, s 2 ) is a gaussian random variable as before. <p> Biasing the link selection process in this way is necessary when there is a large differential between the number of hidden nodes and the number of input or output nodes. This parameter was set to 0.2 in the experiments described in the next section. Research in [14] and <ref> [37] </ref> uses the heuristic of adding or deleting at most a single fully connected node per structural mutation.
Reference: [38] <author> S. Kirkpatrick, C. D. Gelatt, and M. P. Vecchi. </author> <title> Optimization by simulated annealing. </title> <institution> Sci ence, 220:671680, </institution> <year> 1983. </year>
Reference-contexts: This measure of the networks performance is used to anneal the structural and parametric similarity between parent and offspring, so that networks with a high temperature are mutated severely, and those with a low temperature are mutated only slightly (cf. <ref> [38] </ref>).
Reference: [39] <author> R. J. Williams. </author> <title> Adaptive State Representation and Estimation Using Recurrent Connection ist Networks, </title> <booktitle> chapter 4, </booktitle> <pages> pages 97114. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: The various parameter values for the program are set as described above unless otherwise noted. 4.1 Williams Trigger Problem As an initial test, GNARL induced a solution for the enable-trigger task proposed in <ref> [39] </ref>. Consider the finite state generator shown in Figure 5. At each time step the system receives two input bits, (a, b), representing enable and trigger signals, respectively. This system begins in state S 1 , and switches to state S 2 only when enabled by a=1.
Reference: [40] <author> J. B. Pollack. </author> <title> The induction of dynamical recognizers. </title> <booktitle> Machine Learning, </booktitle> <address> 7:227252, </address> <year> 1991. </year>
Reference-contexts: The oscillations between different network architectures throughout the run reects the development of such competing architectures in the population. 4.2 Inducing Regular Languages A current topic of research in the connectionist community is the induction of finite state automata (FSAs) by networks with second-order recurrent connections. For instance, Pollack <ref> [40] </ref> trains sequential cascaded networks (SCNs) over a test set of languages, provided in [41] and Input Target Output Input Target Output -(0, 0), (0, 0) -0, 0 -(1, 0), (0, 0) -0, 0 -(0, 0), (1, 0) -0, 0 -(1, 0), (1, 0) -0, 0 -(0, 1), (0, 0) -0, <p> However, not all evolved network behaviors are so simple as to approximate an FSA <ref> [40] </ref>. In a second run (1595 generations) GNARL induced a network that cleared 82 grid points within the 200 time steps. Figure 15 demonstrates the behavior of this network. Once again, the food attractor, shown in Figure 15a, is a single point in the space that always executes Move.
Reference: [41] <author> M. Tomita. </author> <title> Dynamic construction of finite automata from examples using hill-climbing. </title> <booktitle> In Proceedings of the Fourth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 105 108, </pages> <address> Ann Arbor, MI, </address> <year> 1982. </year> <institution> The Ohio State University July 16, </institution> <year> 1993 </year> <month> 27 </month>
Reference-contexts: For instance, Pollack [40] trains sequential cascaded networks (SCNs) over a test set of languages, provided in <ref> [41] </ref> and Input Target Output Input Target Output -(0, 0), (0, 0) -0, 0 -(1, 0), (0, 0) -0, 0 -(0, 0), (1, 0) -0, 0 -(1, 0), (1, 0) -0, 0 -(0, 1), (0, 0) -0, 0 -(1, 1), (0, 0) -0, 0 -(0, 1), (1, 0) -0, 0 -(1, <p> The Ohio State University July 16, 1993 13 shown in Table 2, using a variation of backpropagation. An interesting result of this work is that the number of states used by the network to implement finite state behavior is potentially infinite. Other studies using the training sets in <ref> [41] </ref> have investigated various network architectures and training methods, as well as algorithms for extracting FSAs from the trained architectures [42 - 45]. An explicit collection of positive and negative examples, shown in Table 3, that pose specific difficulties for inducing the intended languages is offered in [41]. <p> training sets in <ref> [41] </ref> have investigated various network architectures and training methods, as well as algorithms for extracting FSAs from the trained architectures [42 - 45]. An explicit collection of positive and negative examples, shown in Table 3, that pose specific difficulties for inducing the intended languages is offered in [41]. Notice that the training sets are unbalanced, incomplete and vary widely in their ability to strictly define the intended regular language. GNARLs ability to learn and generalize from these training sets was compared against the training results reported for the second-order architecture used in [42]. <p> Training sets for the languages of Table 2 from <ref> [41] </ref>. The Ohio State University July 16, 1993 15 length 10 or less that are correctly classified by the network. For comparison, the table lists both the average and best performance of the five runs reported in [42].
Reference: [42] <author> R. L. Watrous and G. M. Kuhn. </author> <title> Induction of finite-state automata using second-order recurrent networks. </title> <booktitle> In Advances in Neural Information Processing 4. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference-contexts: Notice that the training sets are unbalanced, incomplete and vary widely in their ability to strictly define the intended regular language. GNARLs ability to learn and generalize from these training sets was compared against the training results reported for the second-order architecture used in <ref> [42] </ref>. Notice that all the languages in Table 2 require recurrent network connections in order to induce the language completely. The type of recurrence needed for each language varies widely. <p> The arrow designates the point of transition between the first two training sets. The Ohio State University July 16, 1993 14 vidual inputs, potentially changing state from accept to reject or vice versa on each successive input. The results obtained in <ref> [42] </ref> are summarized in Table 4. The table shows the number of networks evaluated to learn the training set and the accuracy of generalization for the learned network to the intended regular language. <p> Training sets for the languages of Table 2 from [41]. The Ohio State University July 16, 1993 15 length 10 or less that are correctly classified by the network. For comparison, the table lists both the average and best performance of the five runs reported in <ref> [42] </ref>. This experiment used a population of 50 networks, each limited to at most eight hidden units. Each run lasted at most 1000 generations, allowing a maximum of 25050 networks to be evaluated for a single data set. <p> The concatenation of the trailing null symbols was used to identify the end of the string and allow input of the null string, a method also used in <ref> [42] </ref>. Each network had a single input and output and no bias node was provided. The three possible logical inputs for this task, 0, 1, and null, were represented by activations of -1, 1, and 0, respectively. The tolerance for the output value was 0.1, as in [42]. <p> also used in <ref> [42] </ref>. Each network had a single input and output and no bias node was provided. The three possible logical inputs for this task, 0, 1, and null, were represented by activations of -1, 1, and 0, respectively. The tolerance for the output value was 0.1, as in [42]. Table 5 shows for both fitness functions the number of evaluations until convergence and the accuracy of the best evolved network. <p> Both of the uncompleted runs using SSE successfully separated the data sets but had not done so to the 0.1 tolerance within the 1000 generation limit. Figure 8 compares the number of evaluations by GNARL to the average number of evaluations reported in <ref> [42] </ref>. As the graph shows, GNARL consistently evaluates more networks, but not a disproportionate number. Considering that the space of networks being searched by GNARL is much larger than the space being searched by [42], these numbers appear to be within a tolerable increase. <p> 8 compares the number of evaluations by GNARL to the average number of evaluations reported in <ref> [42] </ref>. As the graph shows, GNARL consistently evaluates more networks, but not a disproportionate number. Considering that the space of networks being searched by GNARL is much larger than the space being searched by [42], these numbers appear to be within a tolerable increase. The graph of Figure 9compares the accuracy of the GNARL networks to the average accuracy found in [42] over five runs. The GNARL networks consistently exceeded the average accuracy found in [42]. <p> Considering that the space of networks being searched by GNARL is much larger than the space being searched by <ref> [42] </ref>, these numbers appear to be within a tolerable increase. The graph of Figure 9compares the accuracy of the GNARL networks to the average accuracy found in [42] over five runs. The GNARL networks consistently exceeded the average accuracy found in [42]. Language Average evaluations Average % accuracy Fewest evaluations Best % accuracy 1 3033.8 88.98 28 100.0 3 12326.8 64.87 442 78.31 5 1587.2 44.94 368 66.83 7 2969.0 36.97 373 55.74 Table 4. <p> is much larger than the space being searched by <ref> [42] </ref>, these numbers appear to be within a tolerable increase. The graph of Figure 9compares the accuracy of the GNARL networks to the average accuracy found in [42] over five runs. The GNARL networks consistently exceeded the average accuracy found in [42]. Language Average evaluations Average % accuracy Fewest evaluations Best % accuracy 1 3033.8 88.98 28 100.0 3 12326.8 64.87 442 78.31 5 1587.2 44.94 368 66.83 7 2969.0 36.97 373 55.74 Table 4. Speed and generalization results reported by [42] for learning the data sets of Table 3. <p> The GNARL networks consistently exceeded the average accuracy found in <ref> [42] </ref>. Language Average evaluations Average % accuracy Fewest evaluations Best % accuracy 1 3033.8 88.98 28 100.0 3 12326.8 64.87 442 78.31 5 1587.2 44.94 368 66.83 7 2969.0 36.97 373 55.74 Table 4. Speed and generalization results reported by [42] for learning the data sets of Table 3. <p> Speed and generalization results for GNARL to train recurrent networks to recognize the data sets of Table 3. Result from <ref> [42] </ref> SSE fitness SAE fitness Key Evaluations Training Set both SAE and SSE fitness measures) compared to the average number of evaluations for the five runs described in [42]. <p> Speed and generalization results for GNARL to train recurrent networks to recognize the data sets of Table 3. Result from <ref> [42] </ref> SSE fitness SAE fitness Key Evaluations Training Set both SAE and SSE fitness measures) compared to the average number of evaluations for the five runs described in [42]. The Ohio State University July 16, 1993 17 4.3 The Ant Problem GNARL was tested on a complex search and collection task the Tracker task described in [46], and further investigated in [47]. <p> To understand how the network traverses the path of food, consider the simple FSA shown in Figure 13, hand-crafted in [46] as an approximate solution to the problem. This simple machine receives a score of 81 in the allotted Result from <ref> [42] </ref> SSE fitness SAE fitness Key % Accuracy Language fitness measures) compared to average accuracy of the five runs in [42]. The Ohio State University July 16, 1993 18 200 time steps, and clears the entire trail only five time steps faster than the network in Figure 12b. <p> This simple machine receives a score of 81 in the allotted Result from <ref> [42] </ref> SSE fitness SAE fitness Key % Accuracy Language fitness measures) compared to average accuracy of the five runs in [42]. The Ohio State University July 16, 1993 18 200 time steps, and clears the entire trail only five time steps faster than the network in Figure 12b. A step by step comparison indicates there is only a slight difference between the two.
Reference: [43] <author> C. L. Giles, G. Z. Sun, H. H. Chen, Y. C. Lee, and D. Chen. </author> <title> Higher order recurrent networks & grammatical inference. </title> <editor> In D. S. Touretsky, editor, </editor> <booktitle> Advances in Neural Information Pro cessing Systems 2, </booktitle> <pages> pages 380-387. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference: [44] <author> C. L. Giles, C. B. Miller, D. Chen, G. Z. Sun, H. H. Chen, and Y. C. Lee. </author> <title> Extracting and learning an unknown grammar with recurrent neural networks. </title> <booktitle> In Advances in Neural Infor mation Processing 4. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference: [45] <author> Z. Zeng, R. M. Goodman, and P. Smyth. </author> <title> Learning finite state machines with self-clustering recurrent networks. Neural Computation, </title> <note> to appear. </note>
Reference: [46] <author> D. Jefferson, R. Collins, C. Cooper, M. Dyer, M. Flowers, R. Korf, C. Taylor, and A. Wang. </author> <title> Evolution as a theme in artificial life: The genesys/tracker system. </title> <editor> In C. G. Langton, C. Tay-lor, J. D. Farmer, and S. Rasmussen, editors, </editor> <booktitle> Artificial Life II: Proceedings of the Workshop on Artificial Life, </booktitle> <pages> pages 549577. </pages> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: The Ohio State University July 16, 1993 17 4.3 The Ant Problem GNARL was tested on a complex search and collection task the Tracker task described in <ref> [46] </ref>, and further investigated in [47]. In this problem, a simulated ant is placed on a two-dimensional toroidal grid that contains a trail of food. The ant traverses the grid, collecting any food it contacts along the way. <p> The ant traverses the grid, collecting any food it contacts along the way. The goal of the task is to discover an ant which collects the maximum number of pieces of food in a given time period. (Figure 10). Following <ref> [46] </ref>, each ant is controlled by a network with two input nodes and four output nodes (Figure 11). <p> Each of the four output units corresponds to a unique action: move forward one step, turn left 90, turn right 90, or no-op. At each step, the action whose corresponding output node has maximum activation is performed. As in the original study <ref> [46] </ref>, no-op allows the ant to remain at a fixed position while activation ows along recurrent connections. Fitness is defined as the number of grid positions cleared within 200 time steps. <p> When this ant is run for an additional 119 time steps, it successfully clears the entire trail. To understand how the network traverses the path of food, consider the simple FSA shown in Figure 13, hand-crafted in <ref> [46] </ref> as an approximate solution to the problem. This simple machine receives a score of 81 in the allotted Result from [42] SSE fitness SAE fitness Key % Accuracy Language fitness measures) compared to average accuracy of the five runs in [42]. <p> Positions B and C indicate the only two positions along the trail where the ant discovered in run 1 behaves differently from the 5-state FSA of <ref> [46] </ref> (see Figure 13). Food No food No-op Move Left Right in the square directly in front of the ant; the second denotes the absence of food in this same square. <p> The placement of the D is in the Move / Right corner of the space and encodes a complex alternation between these two operations (see Figure 15d). In contrast, research in <ref> [46] </ref> uses a genetic algorithm on a population of 65,536 bit strings with a direct encoding to evolve only the weights of a neural network with five hidden units to solve this task. The particular network architecture in [46] uses Boolean threshold logic for the hidden units and an identity activation <p> In contrast, research in <ref> [46] </ref> uses a genetic algorithm on a population of 65,536 bit strings with a direct encoding to evolve only the weights of a neural network with five hidden units to solve this task. The particular network architecture in [46] uses Boolean threshold logic for the hidden units and an identity activation function for the output units. The first GNARL network was discovered after evaluating a total of 104,600 networks while the second was found after evaluating 79,850. The experiment reported in [46] discovered a comparable network after about 17 <p> The particular network architecture in <ref> [46] </ref> uses Boolean threshold logic for the hidden units and an identity activation function for the output units. The first GNARL network was discovered after evaluating a total of 104,600 networks while the second was found after evaluating 79,850. The experiment reported in [46] discovered a comparable network after about 17 generations. Given [46] used a population size of 65,536 and replaced 95% of the population each generation, the total number of network evaluations to acquire the equivalent network was 1,123,942. <p> The first GNARL network was discovered after evaluating a total of 104,600 networks while the second was found after evaluating 79,850. The experiment reported in <ref> [46] </ref> discovered a comparable network after about 17 generations. Given [46] used a population size of 65,536 and replaced 95% of the population each generation, the total number of network evaluations to acquire the equivalent network was 1,123,942. This is 10.74 and 14.07 times the number of networks evaluated by GNARL in the two runs.
Reference: [47] <author> J. Koza. </author> <title> Genetic evolution and co-evolution of computer programs. </title> <editor> In J. D. F. Christopher G. Langton, Charles Taylor and S. Rasmussen, editors, </editor> <booktitle> Artificial Life II. </booktitle> <publisher> Addison Wesley Publishing Company, </publisher> <address> Reading Mass., </address> <year> 1992. </year>
Reference-contexts: The Ohio State University July 16, 1993 17 4.3 The Ant Problem GNARL was tested on a complex search and collection task the Tracker task described in [46], and further investigated in <ref> [47] </ref>. In this problem, a simulated ant is placed on a two-dimensional toroidal grid that contains a trail of food. The ant traverses the grid, collecting any food it contacts along the way.
Reference: [48] <author> P. J. Angeline and J. B. Pollack. </author> <title> Competitive environments evolve better solutions for complex tasks. </title> <editor> In S. Forrest, editor, </editor> <booktitle> Genetic Algorithms: Proceedings of the Fifth International Conference (GA93), </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: Other criteria could also be introduced, including specific structural constraints (e.g., minimal number of hidden units or links) as well as constraints on generalization. In some cases, strong task restrictions can even be implicit in simple fitness functions <ref> [48] </ref>. The dynamics of the algorithms guided by the task constraints represented in the fitness function allow GNARL to empirically determine an appropriate architecture. Over time, the continual cycle of test-prune-reproduce will constrain the population to only those architectures that have acquired the task most rapidly.
References-found: 48

