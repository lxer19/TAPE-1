URL: ftp://ftpipr.ira.uka.de/pub/conferences/EWLR-4/PROCEEDINGS/ewlr4_berns.ps.gz
Refering-URL: http://wwwipr.ira.uka.de/~kaiser/events/ewlr4program.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: e-mail: berns@fzi.de  
Title: Requirements and use of neural networks for industrial appli-  
Author: cations Karsten Berns 
Keyword: Key Words. Neural network, industrial applications  
Address: Haid-und-Neu-Str. 10-14, 76131 Karlsruhe, Germany  
Affiliation: Research center for computer science at the University of Karlsruhe  
Abstract: Modern industry of today needs flexible, adaptive and fault-tolerant methods for information processing. Several applications have shown that neural networks fulfill these requirements. In this paper application areas, in which neural networks have been successfully used, are presented. Then a kind of check list is described, which mentioned the different steps, when applying neural networks. The paper finished with a discussion of some neural networks projects done in the research group Interactive Planning at the Research Center for Computer Science (FZI). 
Abstract-found: 1
Intro-found: 1
Reference: <author> Barto, Andrew G., Richard S. Sutton and Charles W. </author> <month> An-derson </month> <year> (1983). </year> <title> Neuronlike adaptive elements that can solve difficult learning control problems. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics SMC-13, </journal> <pages> 834-846. </pages>
Reference-contexts: Especially for the control tasks several experience are also done using reinforcement learning algorithms like Q-learning (Whitehead, 1991) and the AHC-algorithm <ref> (Barto et al., 1983) </ref>. For teaching a tracking behaviour of our autonomous vehicle PRIAMOS experiments are done with backpropagation networks (Berns et al., 1991) and with reinforcement learning (Berns et al., 1992).
Reference: <author> Berns, K. </author> <year> (1994). </year> <editor> Steuerungsanstze auf der Basis Neu-ronaler Netze fr sechsbeinige Laufmaschinen. </editor> <publisher> Infix-Verlag. </publisher>
Reference-contexts: In table 1 several application fields are presented in which neural networks are successfully used. A detailed overview about the use of neural networks in commercial an industrial applications can be found in <ref> (Berns and Kolb, 1994) </ref>, an introduction to neural networks is given in (Hertz et al., 1991). 2 9 PHASES WHEN APPLY ING NEURAL NETWORKS In the following 9 phases are presented, which have to be considered when applying neural networks to a special application problem. <p> In our research group we build up the six-legged walking machine LAURON, which has 18 actors and about 100 sensors. The tests done in the last four years focus on the learning of leg control (Berns et al., 1993; Ilg, 1994) leg coordination <ref> (Berns, 1994) </ref> and the teaching of a reactive behaviour, which decides if an obstacle could be crossed over or avoided (Piekenbrock and Montesinos, 1994). LAURON. For the analysis of NMR spectroscopy samples the use of automatic processing is needed.
Reference: <author> Berns, K. and T. </author> <month> Kolb </month> <year> (1994). </year> <editor> Neuronale Netze fr technis-che Anwendungen. </editor> <publisher> Springer Verlag. </publisher>
Reference-contexts: In table 1 several application fields are presented in which neural networks are successfully used. A detailed overview about the use of neural networks in commercial an industrial applications can be found in <ref> (Berns and Kolb, 1994) </ref>, an introduction to neural networks is given in (Hertz et al., 1991). 2 9 PHASES WHEN APPLY ING NEURAL NETWORKS In the following 9 phases are presented, which have to be considered when applying neural networks to a special application problem. <p> In our research group we build up the six-legged walking machine LAURON, which has 18 actors and about 100 sensors. The tests done in the last four years focus on the learning of leg control (Berns et al., 1993; Ilg, 1994) leg coordination <ref> (Berns, 1994) </ref> and the teaching of a reactive behaviour, which decides if an obstacle could be crossed over or avoided (Piekenbrock and Montesinos, 1994). LAURON. For the analysis of NMR spectroscopy samples the use of automatic processing is needed.
Reference: <author> Berns, K., B. Mller and R. </author> <month> Dillmann </month> <year> (1993). </year> <title> Dynamic Control of a Robot Leg with Self-Organizing Feature Maps. </title> <booktitle> In: Proceedings of the 1993 IEEE/RSJ International Conference on Intelligent Robots and Systems. </booktitle> <address> Yokohama, Japan. </address> <pages> pp. 553-560. </pages>
Reference: <author> Berns, K., R. Dillmann and R. </author> <month> Hofstetter </month> <year> (1991). </year> <title> The application of a backpropagation algorithm for the control of a tracking behavior. </title> <booktitle> In: Proceedings of the 1991 IEEE International Conference on Robotics and Automation. </booktitle> <address> Sacramento, CA. </address> <pages> pp. 2426-2431. </pages>
Reference-contexts: Especially for the control tasks several experience are also done using reinforcement learning algorithms like Q-learning (Whitehead, 1991) and the AHC-algorithm (Barto et al., 1983). For teaching a tracking behaviour of our autonomous vehicle PRIAMOS experiments are done with backpropagation networks <ref> (Berns et al., 1991) </ref> and with reinforcement learning (Berns et al., 1992). The tracking behaviour is defined as follows: the autonomous vehicle is required to follow another vehicle in a distance of 50 cm behind without hidding other obstacles of the environment.
Reference: <author> Berns, K., R. Dillmann and U. </author> <month> Zachmann </month> <year> (1992). </year> <title> Reinforcement-learning for the control of an autonomous mobile robot. </title> <booktitle> In: Proceedings of the 1992 IEEE/RSJ International Conference on Intelligent Robots and Systems. </booktitle> <address> Raleigh, NC. </address> <pages> pp. 1808-1815. </pages>
Reference-contexts: Especially for the control tasks several experience are also done using reinforcement learning algorithms like Q-learning (Whitehead, 1991) and the AHC-algorithm (Barto et al., 1983). For teaching a tracking behaviour of our autonomous vehicle PRIAMOS experiments are done with backpropagation networks (Berns et al., 1991) and with reinforcement learning <ref> (Berns et al., 1992) </ref>. The tracking behaviour is defined as follows: the autonomous vehicle is required to follow another vehicle in a distance of 50 cm behind without hidding other obstacles of the environment.
Reference: <author> Elman, Jeffrey L. </author> <year> (1991). </year> <title> Distributed representations, simple recurrent networks, and grammatical structure. </title> <booktitle> Machine Learning. </booktitle>
Reference-contexts: Depending on the task and on the information which exist for the training process, different networks types where used like Kohonen Maps (Kohonen, 1984), RBF networks (Moody and Darken, 1989), Backpropagation networks with different learning functions (Riedmiller and Braun, 1993) as well as Elman networks <ref> (Elman, 1991) </ref>. Especially for the control tasks several experience are also done using reinforcement learning algorithms like Q-learning (Whitehead, 1991) and the AHC-algorithm (Barto et al., 1983).
Reference: <author> Hertz, John, Anders Krogh and Richard G. </author> <title> Palmer (1991). Introduction to the Theory of Neural Computation. </title> <publisher> Addison-Wesley Publishing Company. </publisher>
Reference-contexts: In table 1 several application fields are presented in which neural networks are successfully used. A detailed overview about the use of neural networks in commercial an industrial applications can be found in (Berns and Kolb, 1994), an introduction to neural networks is given in <ref> (Hertz et al., 1991) </ref>. 2 9 PHASES WHEN APPLY ING NEURAL NETWORKS In the following 9 phases are presented, which have to be considered when applying neural networks to a special application problem.
Reference: <author> Ilg, W. </author> <year> (1994). </year> <institution> Eine Lernarchitektur zur adaptiven Steuerung der Laufmaschine LAURON. Diplomar-beit. Forschungszentrum Informatik an der Universitt Karlsruhe. </institution>
Reference: <author> Kohonen, T. </author> <year> (1984). </year> <title> Self-Organisation and Associative Memory. </title> <booktitle> Vol. Springer Series in Information Science 8. </booktitle>
Reference-contexts: In the first three applications neural networks are used to approximate a unknown function, the last two are classification problems. Depending on the task and on the information which exist for the training process, different networks types where used like Kohonen Maps <ref> (Kohonen, 1984) </ref>, RBF networks (Moody and Darken, 1989), Backpropagation networks with different learning functions (Riedmiller and Braun, 1993) as well as Elman networks (Elman, 1991). Especially for the control tasks several experience are also done using reinforcement learning algorithms like Q-learning (Whitehead, 1991) and the AHC-algorithm (Barto et al., 1983).
Reference: <author> Moody, J. and Ch. </author> <month> Darken </month> <year> (1989). </year> <title> Fast learning in networks of locally-tuned processing units. </title> <booktitle> Neural Computation 1, </booktitle> <pages> 281-294. </pages>
Reference-contexts: In the first three applications neural networks are used to approximate a unknown function, the last two are classification problems. Depending on the task and on the information which exist for the training process, different networks types where used like Kohonen Maps (Kohonen, 1984), RBF networks <ref> (Moody and Darken, 1989) </ref>, Backpropagation networks with different learning functions (Riedmiller and Braun, 1993) as well as Elman networks (Elman, 1991). Especially for the control tasks several experience are also done using reinforcement learning algorithms like Q-learning (Whitehead, 1991) and the AHC-algorithm (Barto et al., 1983).
Reference: <author> Piekenbrock, St. and E. </author> <month> Montesinos </month> <year> (1994). </year> <title> Adaptive reactive control of a six-legged walking machine in unknown environments. </title> <booktitle> In: Proceedings of the Irish Neural Networks Conference' 94. </booktitle> <address> University College Dublin. </address> <pages> pp. 189-193. </pages>
Reference-contexts: The tests done in the last four years focus on the learning of leg control (Berns et al., 1993; Ilg, 1994) leg coordination (Berns, 1994) and the teaching of a reactive behaviour, which decides if an obstacle could be crossed over or avoided <ref> (Piekenbrock and Montesinos, 1994) </ref>. LAURON. For the analysis of NMR spectroscopy samples the use of automatic processing is needed. For instance this problem arises in medicine NMR spectroscopy of body fluids. The main problem of an automatic sample processing is the need for an fully automatic phase correction.
Reference: <author> Riedmiller, Martin and Heinrich Braun (1993). </author> <title> A direct adaptive method for faster backpropagation learning: The rprop algorithm. </title> <booktitle> In: International Conference on Neural Networks. The Institut of Electrical and Electronics Engineers. </booktitle> <address> San Francisco, USA. </address> <pages> pp. 586-591. </pages>
Reference-contexts: Depending on the task and on the information which exist for the training process, different networks types where used like Kohonen Maps (Kohonen, 1984), RBF networks (Moody and Darken, 1989), Backpropagation networks with different learning functions <ref> (Riedmiller and Braun, 1993) </ref> as well as Elman networks (Elman, 1991). Especially for the control tasks several experience are also done using reinforcement learning algorithms like Q-learning (Whitehead, 1991) and the AHC-algorithm (Barto et al., 1983).
Reference: <author> Suna, R., K. Berns and K. </author> <month> Germerdonk </month> <year> (1995a). </year> <title> Pipeline-diagnosis with hybrid neural networks. In: Condition Monitoring and Diagnostic Engineering Management. Vol. </title> <type> 8. </type> <institution> Department of Mechanical Engineering, Queen's University, Kingston, </institution> <address> Ontario, Canada K7L3N6. </address>
Reference-contexts: The idea of the NeuroPipe system is to learn from the human operator the classification of defect candidates. Beside the defect classification a lot of effort have to be done for preprocessing. The preprocessing routines deliver regions which pinpoints the possible defects (see <ref> (Suna et al., 1995a) </ref>). pig.
Reference: <author> Suna, Robert, Karsten Berns and Klaus Heimannsfeld (1995b). </author> <title> Estimation of phase parameters in 1d ft-nmr spectroscopy. </title> <booktitle> In: Australian Conference on Neural Networks. </booktitle> <volume> Vol. </volume> <pages> 6. </pages> <institution> Department of Electrical Enge-neering, University of Sydney NSW 2006, </institution> <address> Australia. </address> <pages> pp. 164-167. </pages>
Reference-contexts: The reason why we use neural networks was that the phase correction could be done by a human operator but was not describable with rule-based or analytical methods. With the huge amount of training data the phase correction system was successfully taught in and tested (see <ref> (Suna et al., 1995b) </ref>). At regular intervals gas, oil and other pipelines need to be inspected for corrosion and other defects. In cooperation with the Pipetronix company a pipeline inspection tool was implemented, which use a hybride network architecture consisting of a RBF-network and several Backpropagation networks.
Reference: <author> Whitehead, Steven D. </author> <year> (1991). </year> <title> A study of cooperative mechanisms for faster reinforcement learning. </title> <type> Technical Report 365. </type> <institution> University of Rochester, Computer Science Department. </institution>
Reference-contexts: Especially for the control tasks several experience are also done using reinforcement learning algorithms like Q-learning <ref> (Whitehead, 1991) </ref> and the AHC-algorithm (Barto et al., 1983). For teaching a tracking behaviour of our autonomous vehicle PRIAMOS experiments are done with backpropagation networks (Berns et al., 1991) and with reinforcement learning (Berns et al., 1992).
References-found: 16

