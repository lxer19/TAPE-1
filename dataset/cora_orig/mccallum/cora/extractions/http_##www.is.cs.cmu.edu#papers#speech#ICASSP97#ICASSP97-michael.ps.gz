URL: http://www.is.cs.cmu.edu/papers/speech/ICASSP97/ICASSP97-michael.ps.gz
Refering-URL: http://www.is.cs.cmu.edu/ISL.speech.publications.html
Root-URL: 
Title: WIDE CONTEXT ACOUSTIC MODELING IN READ VS. SPONTANEOUS SPEECH  
Author: Michael Finke Ivica Rogina 
Address: Germany  
Affiliation: Interactive Systems Laboratories 1 Carnegie Mellon University, USA 2 University of Karlsruhe,  
Abstract: speech recognition research for many years, and have been shown to increase the recognition accuracy significantly. The most common approach is to use triphones. Recently, several speech recognition groups have started investigating the use of larger phonetic context windows when building acoustic models. In this paper we discuss some of the computational problems arising from wide context modeling (polyphonic modeling) and present methods to cope with these problems. A two stage decision tree based polyphonic clustering approach is described which implements a more flexible parameter tying scheme. The new clustering approach gave us significant improvement across all tasks - WSJ, SWB, and Spontaneous Scheduling Task and across all languages involved (German, Spanish, English). We report recognition results based on the JANUS speech recognition toolkit [2, 8] on two tasks comparing acoustic context phenomena in English read versus spontaneous speech. We used our WSJ 60K recognizer and the JANUS SWB 10K polyphonic recognizer. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L.R. Bahl, P.V. de Souza, P.S. Gopalakrishnan, D. Nah-moo, and M.A. Picheny. </author> <title> Decision Trees for Phonological Rules in Continuous Speech. </title> <booktitle> In IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Toronto, 1991. </address> <publisher> IEEE. </publisher>
Reference-contexts: There has been some research towards using wider contexts by allowing questions in the decision tree clustering approach to refer to phonetic contexts two or more phones to the left or right of the phone to be modeled (polyphonic models) <ref> [1, 5] </ref>. In this paper we examine the effect of the width of the context on the speech recognition process in the JANUS recognition toolkit [2, 8], especially on computational effort to train and cluster the models and on the resulting error rate.
Reference: [2] <author> Michael Finke, Petra Geutner, Hermann Hild, Thomas Kemp, Klaus Ries, and Martin Westphal. </author> <title> The Karlsruhe-Verbmobil Speech Recognition Engine. </title> <booktitle> In IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Munich, Germany, 1997. </address> <publisher> IEEE. </publisher>
Reference-contexts: In this paper we examine the effect of the width of the context on the speech recognition process in the JANUS recognition toolkit <ref> [2, 8] </ref>, especially on computational effort to train and cluster the models and on the resulting error rate. We will see that the error rate can be reduced significantly by increasing the context width. <p> EXPERIMENTS We have conducted recognition experiments with the JANUS recognizer <ref> [2, 8] </ref> on three tasks: the Wall Street Journal task (WSJ) the Switchboard LVCSR task, and the German spontaneous scheduling task. The two English tasks use the same phoneme set and the same set of questions, to make them better comparable. All recognizers use approximately the same number of parameters.
Reference: [3] <author> Michael Finke, Torsten Zeppenfeld, Martin Maier, Laura Mayfield, Klaus Ries, Puming Zhan, John Laf-ferty, and Alex Waibel. </author> <title> Switchboard April 1996 Evaluation Report. </title> <booktitle> In Proceedings of LVCSR Hub 5 Workshop, </booktitle> <month> April </month> <year> 1996. </year>
Reference-contexts: A similar improvement was achieved on the German, Spanish and English Spontaneous Scheduling tasks. Our currently best performance on the WSJ task (evaluation set Nov. 1994) is at 9.0% errors. The SWB recognizer was top ranking in DARPA's spring 96 LVCSR evaluation <ref> [3, 9] </ref> and currently has an error rate of 36%. Task Context 1 Context 2 Context 3 WSJ 20.9% WE 20.2% WE 19.9% WE Table 2. Results on different context width. 6.
Reference: [4] <author> M.Y. Hwang. </author> <title> Subphonetic Acoustic Modeling for Speaker-Independent Continuous Speech Recognition. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1993. </year>
Reference-contexts: Different methods of clustering have been proposed <ref> [6, 4, 7] </ref>. The greater the number of models to be clustered, the more infeasible it will become to do agglomerative clustering. Divisive clustering methods are usually implemented as decision trees, using a predefined set of questions for making decisions. <p> Attached to each leaf there is a polyphonic tree containing all the observed polyphones that fall into that leaf. All Polyphones within a polyphonic tree share a single codebook. 3.3. Splitting Criterion We then develop a decision tree as described in <ref> [4, 7] </ref>, allowing questions about arbitrary contexts. These questions are based on 80 different subsets (e.g. vowels, syllabics, voiced phones...) of our set of phones.
Reference: [5] <author> R. Kuhn, A. Lazadrides, Y. Normandin, and J. Brousseau. </author> <title> Improved Decision Trees for Phonetic Modeling. </title> <booktitle> In IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 552-555, </pages> <address> De-troit, Michigan, 1995. </address> <publisher> IEEE. </publisher>
Reference-contexts: There has been some research towards using wider contexts by allowing questions in the decision tree clustering approach to refer to phonetic contexts two or more phones to the left or right of the phone to be modeled (polyphonic models) <ref> [1, 5] </ref>. In this paper we examine the effect of the width of the context on the speech recognition process in the JANUS recognition toolkit [2, 8], especially on computational effort to train and cluster the models and on the resulting error rate.
Reference: [6] <author> Kai-Fu Lee. </author> <title> Large-Vocabulary Speaker-Independent Continuous Speech Recognition: The SPHINX System. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <month> April </month> <year> 1988. </year>
Reference-contexts: Therefore, using acoustic models which make effective use of the information about the preceding phone (F) and the following phone (N) leads to a significant improvement in terms of speech recognition performance <ref> [6] </ref>. But this approach ignores the strong influence that may be exerted by phones that are further away than the immediately preceding and following one. <p> Different methods of clustering have been proposed <ref> [6, 4, 7] </ref>. The greater the number of models to be clustered, the more infeasible it will become to do agglomerative clustering. Divisive clustering methods are usually implemented as decision trees, using a predefined set of questions for making decisions. <p> The distance metric defining the gain received by splitting a tree node is measured as the loss of entropy as described in <ref> [6] </ref>. i = fl l m2L X fl m i = fl r m2R X fl m H l = p l i X i log p r where fl m are the counts for model m, ff mi counts for com ponent i of model m.
Reference: [7] <author> Julian James Odell. </author> <title> The Use of Context in Large Vocabulary Speech Recognition. </title> <type> PhD thesis, </type> <institution> University of Cambridge, </institution> <month> March </month> <year> 1995. </year>
Reference-contexts: Different methods of clustering have been proposed <ref> [6, 4, 7] </ref>. The greater the number of models to be clustered, the more infeasible it will become to do agglomerative clustering. Divisive clustering methods are usually implemented as decision trees, using a predefined set of questions for making decisions. <p> Attached to each leaf there is a polyphonic tree containing all the observed polyphones that fall into that leaf. All Polyphones within a polyphonic tree share a single codebook. 3.3. Splitting Criterion We then develop a decision tree as described in <ref> [4, 7] </ref>, allowing questions about arbitrary contexts. These questions are based on 80 different subsets (e.g. vowels, syllabics, voiced phones...) of our set of phones.
Reference: [8] <author> A. Waibel, M. Finke, D. Gates, M. Gavalda, T. Kemp, A. Lavie, M. Maier, L. Mayfield, A. McNair, I. Rogina, K. Shima, T. Sloboda, , M. Woszczyna, and P.Zhan. </author> <title> JANUS II Advances in Spontaneous Speech Translation. </title> <booktitle> In IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Atlanta, 1996. </address> <publisher> IEEE. </publisher>
Reference-contexts: In this paper we examine the effect of the width of the context on the speech recognition process in the JANUS recognition toolkit <ref> [2, 8] </ref>, especially on computational effort to train and cluster the models and on the resulting error rate. We will see that the error rate can be reduced significantly by increasing the context width. <p> EXPERIMENTS We have conducted recognition experiments with the JANUS recognizer <ref> [2, 8] </ref> on three tasks: the Wall Street Journal task (WSJ) the Switchboard LVCSR task, and the German spontaneous scheduling task. The two English tasks use the same phoneme set and the same set of questions, to make them better comparable. All recognizers use approximately the same number of parameters.
Reference: [9] <author> Torsten Zeppenfeld, Michael Finke, Klaus Ries, Martin Westphal, and Alex Waibel. </author> <title> Recognition of Conversational Telephone Speech using the JANUS Speech Engine. </title> <booktitle> In IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Munich, Germany, 1997. </address> <publisher> IEEE. </publisher>
Reference-contexts: A similar improvement was achieved on the German, Spanish and English Spontaneous Scheduling tasks. Our currently best performance on the WSJ task (evaluation set Nov. 1994) is at 9.0% errors. The SWB recognizer was top ranking in DARPA's spring 96 LVCSR evaluation <ref> [3, 9] </ref> and currently has an error rate of 36%. Task Context 1 Context 2 Context 3 WSJ 20.9% WE 20.2% WE 19.9% WE Table 2. Results on different context width. 6.
References-found: 9

