URL: ftp://coast.cs.purdue.edu/pub/COAST/papers/sandeep-kumar/kumar-intdet-phddiss.ps.Z
Refering-URL: http://www.cs.purdue.edu/coast/coast-library.html
Root-URL: http://www.cs.purdue.edu
Title: CLASSIFICATION AND DETECTION OF COMPUTER INTRUSIONS  
Author: by Sandeep Kumar 
Degree: A Thesis Submitted to the Faculty of  In Partial Fulfillment of the Requirements for the Degree of Doctor of Philosophy  
Date: August 1995  
Affiliation: Purdue University  
Abstract-found: 0
Intro-found: 1
Reference: <institution> 131 BIBLIOGRAPHY [8lg] 8lgm electronic mailing list. </institution> <note> Can be retrieved from fileserv@bagpuss.demon.co.uk. </note>
Reference: [A + 76] <author> R. P. Abbott et al. </author> <title> Security Analysis and Enhancements of Computer Operating Systems. </title> <type> Technical Report NBSIR 76-1041, </type> <institution> Institute for Computer Science and Technology, National Bureau of Standards, </institution> <year> 1976. </year>
Reference-contexts: By being aware of the nature and statistics of flaws at different stages of the software life cycle, engineers can take efforts to minimize their occurrence. Work has also been done to use pattern directed approaches to detect vulnerabilities in source code, for example, in the RISOS project <ref> [A + 76] </ref>. Whereas published literature contains analyses of vulnerabilities in terms of their origin and their possible prevention, we have focused on the runtime exploitation of vulnerabilities. Thus, we use the term signature, or intrusion instead of vulnerabilities to denote entities populating our classification scheme. <p> Two faults that are a result of improper or incomplete parameter checking may result in very different manifestations and thus should be classified in different categories. Studies that have focused on penetration analysis, for example the RISOS project study <ref> [A + 76] </ref> and the study by Landwehr et al. [LBMC93] have attempted to develop a syntax-directed approach to the detection of security flaws. The aim of these studies is to develop patterns indicative of flaws that can be matched in system source code.
Reference: [Aho90] <author> Alfred V. Aho. </author> <title> Algorithms for Finding Patterns in Strings. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science - VOL A, Chapter 5, </booktitle> <pages> pages 256-300. </pages> <publisher> Elsevier Science Publishers, </publisher> <year> 1990. </year>
Reference-contexts: Property 1: Pattern Matching with Unification is NP Complete. We show that the problem is NP Complete by reducing the problem of vertex-cover in arbitrary graphs to the problem of pattern matching with unification. This proof is a recast of the proof presented by Aho in <ref> [Aho90, Section 6] </ref>. 83 The vertex-cover problem for an arbitrary graph G and an integer k is to determine if there is a subset of vertices in G of cardinality at most k such that every edge in G is incident on at least one vertex in the selected subset.
Reference: [AHU74] <author> Alfred V. Aho, John E. Hopcroft, and Jeffrey D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mas-sachusetts, </address> <year> 1974. </year>
Reference-contexts: = t 3 Context: if (U == U 0 == U 00 ^ t 3 t 1 &lt; 2m)raise audit level (U ); 54 Matching in the presence of context is more difficult than matching where only the order of occurrence of events is specified, as in regular expression matching <ref> [AHU74] </ref>. If the evaluation of the context is linear in its size (of representation) then matching is NP-Complete [KS94]. This means that in general there are no known deterministic algorithms that perform significantly better than trying all possible ways of matching the pattern. Follows Semantics. <p> The steps in the non-deterministic match of the CPA against the event sequence are described in Table 4.1. Non-deterministic matching is used in the sense of computing using an oracle, similar to that used in matching non-deterministic finite automata as described by Aho, Hopcroft and Ullman <ref> [AHU74] </ref>. Step Input Token Configuration Comment 1: :abac fs1; s4g 2: a:bac fs2; s4g The CPA non-deterministically chooses to move token s1. 3: ab:ac fs3; s4g 5: abac: fs7g The two tokens are merged to one.
Reference: [And80] <author> J. P. Anderson. </author> <title> Computer Security Threat Monitoring and Surveillance. </title> <type> Technical report, </type> <institution> James P Anderson Co., </institution> <address> Fort Washington, Pennsylvania, </address> <month> April </month> <year> 1980. </year>
Reference-contexts: An earlier study done by Anderson <ref> [And80] </ref> uses the term "threat" in this same sense and defines it to be the potential possibility of a deliberate unauthorized attempt to access information, manipulate information, or render a system unreliable or unusable. An intrusion is a violation of the security policy of the system. <p> Anomaly detection attempts to quantify the usual or acceptable behavior and flags other irregular behavior as potentially intrusive. One of the earliest reports that outlines how intrusions may be detected by identifying "abnormal" behavior is the work by Anderson <ref> [And80] </ref>. In his influential report, Anderson presents a threat model that classifies threats as external penetrations, internal penetrations, and misfeasance and uses this classification to develop a security monitoring surveillance system based on detecting anomalies in user behavior. <p> Vulnerability. A vulnerability is defined in [LS87] as a weakness in automated system security procedures, administrative controls, internal controls etc. that could be 12 exploited by a threat to gain unauthorized access to information or to disrupt critical processing. Anderson <ref> [And80] </ref> defines a vulnerability in a less abstract way as a known or suspected flaw in the hardware or software design or operation of a system that exposes it to penetration of its information. 1.4 A Note on the Use of Examples The basic goal of all operating systems is to <p> No such structuring insights have emerged from the field itself. This may partly be a result of a lack of common agreement on the techniques for detecting intrusions and partly because intrusion detection is a young field of study, initiated by Anderson in 1980 <ref> [And80] </ref>. Efficiency. Systems have often attempted to detect every conceivable intrusion and have not done well in practice. Anomaly detection, for example, is computa-tionally expensive because all profiles maintained by the system may need to be updated for every event.
Reference: [Asl95] <author> Taimur Aslam. </author> <title> A Taxonomy of Security Faults in the Unix Operating System. </title> <type> Master's Thesis, </type> <institution> Purdue University, Department of Computer Sciences, </institution> <month> August </month> <year> 1995. </year>
Reference-contexts: Using this scheme, new intrusions can be understood and characterized in terms of the structure of events needed to detect them. This classification scheme is presented in Section 3.1. 2 A good description of their work can be found in the study by Aslam <ref> [Asl95] </ref>. 14 To represent and detect computer intrusions efficiently we have devised a model. This model uses the classification scheme of Section 3.1 to group intrusions and instantiates the generic requirements that we propose and defend in this thesis.
Reference: [ASU86] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1986. </year>
Reference-contexts: This has a linear time solution in the deterministic case (ignoring preprocessing) and polynomial time solution when simulating the non-deterministic pattern. These results can be found in the book by Aho et al. <ref> [ASU86] </ref>. Specification of Actions. The patterns should be able to specify the execution of arbitrary code fragments, both within the pattern's context and when the pattern is matched. For example, it might be desirable to increase the amount of data audited for a user when a suspicious pattern is matched. <p> The approach is to evaluate constant subexpressions involving event data only once and using these values when they are referenced again. However, because guard expressions can involve short-circuited expressions that cannot be compiled into a basic block <ref> [ASU86] </ref> we have modified the traditional notion of common subexpression elimination to work across basic blocks by using a virtual machine that understands the semantics of operations used in guard expressions. <p> In summary, the following properties are used to ensure the semantic consistency of the expressions or simplify the CSE on the generated code. For a treatment of these and other compiler optimization issues, see the book by Aho et al. <ref> [ASU86] </ref> or the book by Fischer and LeBlanc [FL88]. 1 Some states may be specified nodup [Section 6.3.1], but such states are rare. 99 1.
Reference: [Bez83] <author> Boris Bezier. </author> <title> Software Testing Techniques. </title> <booktitle> Electrical Engineering/Computer Science and Engineering Series. </booktitle> <publisher> Van Nostrand Reinhold, </publisher> <year> 1983. </year>
Reference-contexts: In this section we justify why this is more meaningful from the viewpoint of detection. Cataloging of software bugs has been of keen interest to software engineers. The rationale for this interest is summarized by Bezier <ref> [Bez83] </ref> as: It is important to establish categories for bugs if you take the goal of bug prevention seriously.
Reference: [Bib77] <author> K. J. Biba. </author> <title> Integrity Constraints for Secure Computer Systems. </title> <type> Technical Report ESD-TR-76-372, </type> <institution> USAF Electronic Systems Division, Bedford, Massachussetts, </institution> <month> April </month> <year> 1977. </year>
Reference-contexts: This often requires that users understand the protection mechanisms offered by the systems and how to achieve the desired security using these mechanisms. Information flow can be controlled to enhance security by applying models such as the Bell and LaPadula model [BL73] to provide secrecy, or the Biba model <ref> [Bib77] </ref> 1 For an account of a real intrusion that originated in Europe and targeted several military computers in the U.S. see the book by Cliff Stoll [Sto88]. 4 to provide integrity. However, security comes at the expense of convenience.
Reference: [Bis83] <author> Matthew Bishop. </author> <title> Security Problems with the UNIX Operating System. </title> <type> Confidential Technical Memo, </type> <institution> Department of Computer Sciences, Purdue University, </institution> <month> January </month> <year> 1983. </year> <month> 132 </month>
Reference-contexts: Examples of these patterns include intrusion signatures that often specify several activities to be done jointly, but in any order. Such signatures can be written using the AND primitive. For example, attack scenario number four described by Bishop <ref> [Bis83] </ref> provides a root shell by exploiting /bin/mail. /bin/mail is the local mail delivery program that worked in earlier versions of UNIX by changing the user id of the mail file to that of the recipient's uid, 3 IFS, or the internal field separator, is a user assignable variable in some <p> These requirements were derived from a study of computer security vulnerabilities described in Bishop <ref> [Bis83] </ref>, CERT advisories [CER], and the COPS security tool [FS90]. The examples are illustrated using UNIX vulnerabilities and a C2 audit trail. This is only because of our familiarity with them and should not be construed as a limitation of this approach. Context Representation. <p> Different intrusion detection systems may make different tradeoffs among these requirements but all systems will have to address all the requirements to some degree. These requirements were empirically derived from a study of commonly occurring intrusions described by Bishop <ref> [Bis83] </ref>, made public via advisories such as those put out by CERT [CER], and embedded in tools like COPS [FS90]. We also outlined some system considerations that might be useful when implementing these requirements in a practical system. <p> We have been successful in achieving these goals. We have been able to represent 88% of the intrusions described in <ref> [Bis83, CER, FS90] </ref> that have occurred in UNIX systems. We could not detect 12% of those vulnerabilities but we argue that signature detection is not a good choice for such vulnerabilities. Some require more sophisticated anomaly detection while others, such as passive wiretapping, do not exhibit a detectable signature [cf.
Reference: [Bis95] <author> Mathew Bishop. </author> <title> UNIX Security: Threats and Solutions. Invited talk given at the 1995 System Administration, </title> <booktitle> Networking, and Security Conference, </booktitle> <month> April 24-29, </month> <year> 1995. </year>
Reference-contexts: Although the focus of our classification is to categorize signatures, not vulnerabilities, an extension of existence patterns can also be used to detect vulnerabilities in systems. A study conducted by Bishop on UNIX vulnerabilities <ref> [Bis95] </ref> revealed that as many as 95% of all vulnerabilities in his study originated from configuration problems. These can be modeled and detected using existence patterns. Checks performed by static analysis tools such as COPS [FS90] and TIGER [SSH93] can also be modeled by existence patterns.
Reference: [BK88] <author> David S. Bauer and Michael E. Koblentz. </author> <title> NIDX An Expert System for Real-Time Network Intrusion Detection. </title> <booktitle> In Proceedings of the Computer Networking Symposium, </booktitle> <pages> pages 98-106. </pages> <publisher> IEEE, </publisher> <address> New York, New York, </address> <month> April </month> <year> 1988. </year>
Reference-contexts: Most of them derive from the statistical intrusion detection model of Dorothy Denning [Den87]. Some of them, for example NIDX <ref> [BK88] </ref>, Haystack [Sma88], IDES [LJL + 89], MIDAS [SSHW88], Wisdom and Sense [LV89] and CMDS [Pro94] use the audit trail generated by a C2 or higher rated computer, for input. <p> Approaches to misuse intrusion detection include language-based approaches to represent and detect intrusions such as ASAX [HCMM92], developing an Application Programming Interface, i.e., a set of library function calls employed for representing and detecting intrusions, such as in STALKER [Sma95], expert systems such as MIDAS [SSHW88] and NIDX <ref> [BK88] </ref>, and high level state machines to encode and match signatures such as STAT [PK92] and USTAT [Ilg92]. A promising approach for future intrusion detection systems might involve Bayes-ia-n classification, currently implemented in Autoclass [CKS + 88, CHS91].
Reference: [BK89] <author> Morris I. Bolsky and David G. Korn. </author> <title> The KornShell Command and Programming Language. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1989. </year>
Reference-contexts: Furthermore, without a semantic analysis of the keystrokes, aliases provided in user shells such as the Korn shell <ref> [BK89] </ref> can easily defeat this technique. User login shells often provide the facility of associating parameterized shorthand names for command sequences. These are called aliases and are similar to macro definitions. <p> /bin/mail is the local mail delivery program that worked in earlier versions of UNIX by changing the user id of the mail file to that of the recipient's uid, 3 IFS, or the internal field separator, is a user assignable variable in some user shells, such as the Korn shell <ref> [BK89] </ref>, that determines how an input line is separated into command words. 4 PATH is a user assignable variable provided in most user shells that defines the search path to look for commands to be executed. 47 but failed to clear the setuid bit on the file.
Reference: [BL73] <author> D. E. Bell and L. J. LaPadula. </author> <title> Secure Computer Systems: Mathematical Foundations and Model. </title> <type> Technical Report M74-244, </type> <institution> The MITRE Corporation, Bedford, Massachussetts, </institution> <month> May </month> <year> 1973. </year>
Reference-contexts: This often requires that users understand the protection mechanisms offered by the systems and how to achieve the desired security using these mechanisms. Information flow can be controlled to enhance security by applying models such as the Bell and LaPadula model <ref> [BL73] </ref> to provide secrecy, or the Biba model [Bib77] 1 For an account of a real intrusion that originated in Europe and targeted several military computers in the U.S. see the book by Cliff Stoll [Sto88]. 4 to provide integrity. However, security comes at the expense of convenience.
Reference: [BN84] <author> Andrew D. Birrell and Bruce Jay Nelson. </author> <title> Implementing Remote Procedure Calls. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(1) </volume> <pages> 39-59, </pages> <month> Febru-ary </month> <year> 1984. </year>
Reference-contexts: That is, the patterns, the server and the event sources may all reside on physically different machines. The server can then retrieve events by using any of several well-known techniques such as remote procedure calls <ref> [BN84] </ref> or distributed objects [Par90] and dispatch them to patterns. Although our current implementation is single host based, a distributed implementation should be straightforward. Our current implementation requires that patterns be exercised sequentially on events. It does not permit more than one event to be exercised concurrently within a pattern.
Reference: [Bug] <institution> Bugtraq electronic mailing list. </institution> <note> Issued electronically from bugtraq@cri-melab.com. </note>
Reference-contexts: Our choice of using UNIX as a vehicle to illustrate how security vulnerabilities can be classified, represented, and detected is incidental. It is because we are most familiar with UNIX, and because most publicly discussed vulnerabilities such as those in the bugtraq mailing list <ref> [Bug] </ref>, the 8lgm advisories [8lg], and the CERT advisories [CER] have historically dealt predominantly with UNIX vulnerabilities. It is therefore easy to use these examples to illustrate our ideas because details of these vulnerabilities are public. <p> This can result in unauthorized accesses to arbitrary objects in the system. An example of this attack is the lpr attack 2 discussed on the bugtraq <ref> [Bug] </ref> mailing list by Jeremy Epstein on 10/21/94: For example, if lpr checks whether you have access to a file being queued (using the access () system call), but lpd fails to verify that the file is still what it was before (i.e., if its a symbolic link it hasn't been <p> A difficult problem, however, is the identification and extraction of the core crucial elements from exploitation descriptions, such as those described in the bugtraq <ref> [Bug] </ref> and 8lgm [8lg] mailing lists, and turning them into general descriptions for detecting variations and permutations of the vulnerabilities. Currently it requires human expertise to do the translation and there is no easy way to automate the process.
Reference: [BYG89] <author> R. A. Baeza-Yates and G. H. Gonnet. </author> <title> A New Approach to Text Searching. </title> <booktitle> In Proceedings of the 12th Annual ACM-SIGIR Conference on Information Retrieval, </booktitle> <pages> pages 168-175, </pages> <address> Cambridge, Massachusetts, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: Discrete approximate matching has been extensively studied by Wagner and Fischer [WF74], Myers and Miller [MM89], Yates and Gonnet <ref> [BYG89] </ref>, Man-ber and Wu [WM91] and Knight [Kni93]. Matching with the follows semantics 55 without context representation has the same complexity as matching regular expressions. This has a linear time solution in the deterministic case (ignoring preprocessing) and polynomial time solution when simulating the non-deterministic pattern.
Reference: [CER] <author> CERT Advisories. </author> <note> Available by anonymous ftp from cert.sei.cmu.edu:/pub/cert advisories. </note>
Reference-contexts: It is because we are most familiar with UNIX, and because most publicly discussed vulnerabilities such as those in the bugtraq mailing list [Bug], the 8lgm advisories [8lg], and the CERT advisories <ref> [CER] </ref> have historically dealt predominantly with UNIX vulnerabilities. It is therefore easy to use these examples to illustrate our ideas because details of these vulnerabilities are public. Other operating systems, such as VAX/VMS and VM/CMS are proprietary and their source code has not been available for wide-spread scrutiny. <p> These can be modeled and detected using existence patterns. Checks performed by static analysis tools such as COPS [FS90] and TIGER [SSH93] can also be modeled by existence patterns. Example vulnerabilities: * Cert Advisory 93:03 <ref> [CER] </ref>. The default permissions on a number of files and directories in SunOS 4.1 were being set incorrectly. <p> Because UNIX 1 Both setuid and setgid. 43 models devices as files, incorrect permissions may permit kernel memory to be read for passwords or devices read from or written to. * Cert Advisory 93:15 <ref> [CER] </ref>. The device /dev/audio was world readable so any user with an account on the system could listen to any conversation that was within audible range of the built-in microphone. An existence signature to detect these vulnerabilities checks to see if the permissions on the relevant files are set incorrectly. <p> condition at a lower level as the race condition between the access check by lpr and printing by lpd. 46 changed, if it was a file when spooled it hasn't become a symbolic link), then you could get printouts of files you have no rights to... * Cert Advisory 93:18 <ref> [CER] </ref> which address a vulnerability in /usr/etc/m-odload and $OPENWINHOME/bin/loadmodule in some Sun Microsystems, Inc. architectures. In these architectures loadmodule runs as setuid root without resetting IFS 3 . It calls a program with the absolute name starting with /bin and does it using a call to system (). <p> These requirements were derived from a study of computer security vulnerabilities described in Bishop [Bis83], CERT advisories <ref> [CER] </ref>, and the COPS security tool [FS90]. The examples are illustrated using UNIX vulnerabilities and a C2 audit trail. This is only because of our familiarity with them and should not be construed as a limitation of this approach. Context Representation. <p> These requirements were empirically derived from a study of commonly occurring intrusions described by Bishop [Bis83], made public via advisories such as those put out by CERT <ref> [CER] </ref>, and embedded in tools like COPS [FS90]. We also outlined some system considerations that might be useful when implementing these requirements in a practical system. The pattern matching approach should be viewed as a technique specifically tailored for intrusion detection. <p> The kernel long divide emulation code in some Sun operating systems that failed to check the address of the remainder may be detected using such a signature <ref> [CER, CA-92:15] </ref>. A simplied signature to handle this case is shown in Figure 4.4. When a process is started (the transition labeled with exec), its user id is stored in the pattern local variable UID. <p> We have been successful in achieving these goals. We have been able to represent 88% of the intrusions described in <ref> [Bis83, CER, FS90] </ref> that have occurred in UNIX systems. We could not detect 12% of those vulnerabilities but we argue that signature detection is not a good choice for such vulnerabilities. Some require more sophisticated anomaly detection while others, such as passive wiretapping, do not exhibit a detectable signature [cf. <p> It is nontrivial to translate advisories, for example CERT advisories <ref> [CER] </ref>, into patterns that can reliably detect those and similar incidents. The process requires a good understanding of the key essentials of the exploitation to enable the problem to be abstracted and represented in a generic, alias-free manner. Writing efficient signatures may require knowledge of the underlying matching model.
Reference: [Cha91] <author> Eugene Charniak. </author> <title> Bayesian Networks Without Tears. </title> <journal> AI Magazine, </journal> <pages> pages 50-63, </pages> <month> Winter </month> <year> 1991. </year>
Reference-contexts: However, in general it is not trivial to determine the a priori probability values of the root nodes and the link matrices for each directed arc. For a good introduction to Bayesian Networks see the article by Charniak <ref> [Cha91] </ref>. 2.2.4 Predictive Pattern Generation Predictive pattern generation is a technique of anomaly detection that is based on the hypothesis that sequences of events are not random but follow a discernible pattern. This results in better intrusion detection because it takes into account the interrelationship and ordering among events.
Reference: [Che88] <author> K. Chen. </author> <title> An Inductive Engine for the Acquisition of Temporal Knowledge. </title> <type> Ph.D. Thesis, </type> <institution> Department of Computer Science, University of Illi-nois at Urbana-Champaign, </institution> <year> 1988. </year>
Reference-contexts: This results in better intrusion detection because it takes into account the interrelationship and ordering among events. The approach of time-based inductive generalization described by Teng and Chen <ref> [Che88, TCL90] </ref> uses time-based rules that characterize the normal behavior patterns of users. The rules, generated inductively, are modified dynamically during the learning phase and only "good" rules, i.e., rules with a high accuracy of prediction and a high level of confidence remain in the system.
Reference: [CHS91] <author> Peter Cheeseman, Robin Hanson, and John Stutz. </author> <title> Bayesian Classification with Correlation and Inheritance. </title> <booktitle> In 12th International Joint Conference on Artificial Intelligence, </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: Neural nets cope well with noisy data. 3. Neural nets can automatically account for correlations between the various mea sures that affect the output. 25 2.2.6 Bayesian Classification Bayesian classification, described by Cheeseman <ref> [CHS91] </ref>, is a technique of unsupervised classification of data. Its implementation, Autoclass [CKS + 88], searches for classes in the given data using Bayesian statistical techniques. This technique attempts to determine the most likely processes that generate the data. <p> A promising approach for future intrusion detection systems might involve Bayes-ia-n classification, currently implemented in Autoclass <ref> [CKS + 88, CHS91] </ref>. Audit trail reduction and browsing is described by Wetmore [Wet93] and Moitra [Moi], while a non-parametric pattern recognition technique is discussed by Lankewicz [Lan92].
Reference: [CKS + 88] <author> Peter Cheeseman, James Kelly, Matthew Self, John Stutz, Will Taylor, and Don Freeman. </author> <title> Autoclass: A Bayesian Classification System. </title> <booktitle> In Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <pages> pages 54-64. </pages> <publisher> Morgan Kaufmann, </publisher> <month> June </month> <year> 1988. </year> <month> 133 </month>
Reference-contexts: Neural nets cope well with noisy data. 3. Neural nets can automatically account for correlations between the various mea sures that affect the output. 25 2.2.6 Bayesian Classification Bayesian classification, described by Cheeseman [CHS91], is a technique of unsupervised classification of data. Its implementation, Autoclass <ref> [CKS + 88] </ref>, searches for classes in the given data using Bayesian statistical techniques. This technique attempts to determine the most likely processes that generate the data. <p> A promising approach for future intrusion detection systems might involve Bayes-ia-n classification, currently implemented in Autoclass <ref> [CKS + 88, CHS91] </ref>. Audit trail reduction and browsing is described by Wetmore [Wet93] and Moitra [Moi], while a non-parametric pattern recognition technique is discussed by Lankewicz [Lan92].
Reference: [Coh87] <author> Fred Cohen. </author> <title> Computer Viruses Theory and Experiments. </title> <journal> Computers & Security, </journal> <volume> 6 </volume> <pages> 22-35, </pages> <year> 1987. </year>
Reference-contexts: They frequently use several levels of indirection before breaking into target systems and rarely indulge in sudden bursts of suspicious or anomalous activity. They also cover their tracks so that their activity on the penetrated system is not easily discovered 1 . Threats such as viruses <ref> [Coh87] </ref> and worms [SH82] do not need human supervision and are capable of replicating and traveling to connected computer systems. Unleashed at one computer, by the time they are discovered it may be impossible to trace their origin or the extent of infection.
Reference: [Com91] <author> Douglas E. Comer. </author> <title> Internetworking with TCP/IP, Volume I. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <note> Second edition, </note> <year> 1991. </year>
Reference-contexts: A TCP connection (an rlogin connection is a TCP connection to a specific port) setup between the initiator S and the recipient D involves a three-way handshake <ref> [Com91] </ref>. The first segment of the handshake involves sending an IP datagram from S to D with the SYN bit set in the code field. In response to this SYN packet D sends a datagram that acknowledges the SYN packet and sets the SYN bit to continue the handshake.
Reference: [CS70] <author> J. Cocke and J. T. Schwartz. </author> <title> Programming Languages and Their Compilers: </title> <note> Preliminary Notes, Second Revised Version. </note> <institution> Courant Institute of Mathematical Sciences, </institution> <address> New York, </address> <year> 1970. </year>
Reference-contexts: RETURN 41. L3: 42. T15 15 AND T13 13 , XOTH 43. IFFALSE T15 15 , L4 44. RES 1 45. RETURN 46. EXIT: L4: 47. RES 0 48. RETURN The superscripted numbers in the instructions above correspond to their value numbers as outlined in Cocke and Schwartz <ref> [CS70] </ref>. Associating a number with each 93 expression, called its value number, allows the efficient determination of common subexpressions within an expression or in the three address code that corresponds to a basic block. These are compile-time optimizations. <p> This prevents undesired side effects while ensuring that all subexpressions are evaluated and reside in their appropriate temporary variables. Following the procedure of common subexpression elimination outlined in Cocke and Schwartz <ref> [CS70] </ref>, the code for both the guard expressions is as shown here: 1. THIS LINK 2.
Reference: [CW89] <author> David D. Clark and David A. Wilson. </author> <title> Evolution of a Model for Computer Integrity. </title> <booktitle> Report of the Invitational Workshop on Data Integrity, </booktitle> <month> September </month> <year> 1989. </year>
Reference-contexts: any intrusion detector using a 50 pattern matching approach must satisfy when run in the current paradigm of audit trail generation. 3.2.1 Intrusion Signatures as Patterns to be Matched To show the likeness of intrusion signatures and patterns in the sense of classical pattern matching, consider the monitoring of Clarke-Wilson <ref> [CW89] </ref> integrity triples in a computer system using the system generated audit trail. Clarke-Wilson triples are devised to ensure the integrity of important data and specify that only authorized programs running as specific user ids are permitted to write to files whose integrity must be preserved.
Reference: [Den82] <author> Dorothy E. Denning. </author> <title> Cryptography and Data Security. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1982. </year>
Reference-contexts: However, this only limits whether access to an object in the system is permitted but does not model or restrict what a subject may do with the object itself if it has the access to manipulate it <ref> [Den82] </ref>. Access control therefore does not model and cannot prevent unauthorized information flow through the system because such flow can take place with authorized accesses to the objects. Moreover, in systems where access controls are discretionary, the responsibility of protecting data rests on the end user.
Reference: [Den87] <author> Dorothy E. Denning. </author> <title> An Intrusion-Detection Model. </title> <journal> In IEEE Transactions on Software Engineering, </journal> <volume> Number 2, </volume> <pages> page 222, </pages> <month> February </month> <year> 1987. </year>
Reference-contexts: RELATED WORK IN INTRUSION DETECTION This chapter describes the architecture of several prior intrusion detection systems. None of them uses pattern matching directly to represent and detect intrusions. We also describe the generic model of intrusion detection proposed by Dorothy Denning <ref> [Den87] </ref>, which is still accurate as an abstract model of most intrusion detection systems. <p> For a thorough treatment of reasoning in the presence of uncertainty see the book by Judea Pearl [Pea88]. 2.4 A Generic Intrusion Detection Model Dorothy Denning, in 1987, established a model of intrusion detection independent of the system, type of input, and the specific intrusions to be monitored <ref> [Den87] </ref>. A brief description of the generic model is helpful in relating specific examples of intrusion detection systems presented in earlier sections to the model and viewing how these systems fit into or enhance it. <p> The Rule Set represents a generic inferencing mechanism and uses event records, anomaly records, and time expirations, among others, to control the activity of the other components and to update their state. Denning <ref> [Den87] </ref>, however, uses rule-based systems to explain the inferencing mechanism and the nature of interaction with the other components. Comparison with Other Systems The primary differences between the generic model described above and actual systems described in previous sections are: How the rules comprising the Rule Set are determined. <p> Most of them derive from the statistical intrusion detection model of Dorothy Denning <ref> [Den87] </ref>. Some of them, for example NIDX [BK88], Haystack [Sma88], IDES [LJL + 89], MIDAS [SSHW88], Wisdom and Sense [LV89] and CMDS [Pro94] use the audit trail generated by a C2 or higher rated computer, for input.
Reference: [Doa92] <author> Justin Doak. </author> <title> Intrusion Detection: The Application of Feature Selection </title>
Reference-contexts: The method assumes that combining higher predictability measure subsets allows searching the space of metrics more efficiently than other heuristic techniques. For a survey of other feature selection techniques see Doak <ref> [Doa92] </ref>. 2.2.3 Combining Individual Anomaly Measures to Get a Single Measure If we assume that the right set of anomaly metrics can somehow be determined, how do we then combine the anomaly values of all the metrics to get a single number? One method is to use Bayesian statistics, applied either
References-found: 29

