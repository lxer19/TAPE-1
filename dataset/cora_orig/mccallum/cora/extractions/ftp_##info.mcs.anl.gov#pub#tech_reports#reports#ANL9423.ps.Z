URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/ANL9423.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts94.htm
Root-URL: http://www.mcs.anl.gov
Phone: 60439  
Title: Distribution Category:  A Parallel Genetic Algorithm for the Set Partitioning Problem  
Author: Mathematics and by David Levine 
Date: May 1994  
Address: 9700 South Cass Avenue Argonne, IL  
Affiliation: Computer Science (UC-405) ARGONNE NATIONAL LABORATORY  Mathematics and Computer Science Division  
Abstract: This work was supported by the Office of Scientific Computing, U.S. Department of Energy, under Contract W-31-109-Eng-38. It was submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy in Computer Science in the Graduate School of the Illinois Institute of Technology, May 1994 (thesis adviser: Dr. Tom Christopher). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Anbil, E. Gelman, B. Patty, and R. Tanga. </author> <title> Recent Advances in Crew Pairing Optimization at American Airlines. </title> <journal> INTERFACES, </journal> <volume> 21 </volume> <pages> 62-74, </pages> <year> 1991. </year>
Reference-contexts: The operations research (OR) literature contains numerous references to the airline crew scheduling problem [2, 3, 4, 7, 25, 36, 46, 47]. Estimates of over a billion dollars a year for pilot and flight attendant expenses have been reported <ref> [1, 7] </ref>. Even a small improvement over existing solutions can have a large economic benefit. At one time solutions to the SPP were generated manually. However, airline crew scheduling problems have grown significantly in size and complexity. <p> The first step is to pick a random string, x random , and apply a local search heuristic (Section 2.3) to it. Next, two parent strings, x 1 and x 2 , are selected (Section 2.4.4), and a random number, r 2 <ref> [0; 1] </ref>, is generated. If r is less than the crossover probability, p c , we create two new offspring via crossover (Section 2.4.6) and randomly select one of them, x new , to insert in the population.
Reference: [2] <author> R. Anbil, R. Tanga, and E. Johnson. </author> <title> A Global Approach to Crew Pairing Optimization. </title> <journal> IBM Systems Journal, </journal> <volume> 31(1) </volume> <pages> 71-78, </pages> <year> 1992. </year>
Reference-contexts: The operations research (OR) literature contains numerous references to the airline crew scheduling problem <ref> [2, 3, 4, 7, 25, 36, 46, 47] </ref>. Estimates of over a billion dollars a year for pilot and flight attendant expenses have been reported [1, 7]. Even a small improvement over existing solutions can have a large economic benefit. At one time solutions to the SPP were generated manually. <p> However, in recent years it has been noted that as SPP problems grow in size, fractional solutions occur more frequently, and simply rounding or performing a "small" branch-and-bound tree search may not be effective <ref> [2, 7, 25] </ref>. Marsten [46] noted twenty years ago that for most algorithms in use at that time, solving the linear programming relaxation to the SPP was the computational bottleneck. This is because the LP relaxation is highly degenerate. <p> This is because the LP relaxation is highly degenerate. The past several years have seen a number of advances in linear programming algorithms and the application of that technology to solving the LP relaxation of very large SPP problems <ref> [2, 9] </ref>. One of the oldest exact methods is implicit enumeration. In this method partial solutions are generated by taking the columns one at a time and exploring logical implications of their assignments. Both Garfinkel and Nemhauser [24] and Marsten [46] developed implicit enumeration algorithms.
Reference: [3] <author> J. Arabeyre, J. Fearnley, F. Steiger, and W. Teather. </author> <title> The Airline Crew Scheduling Problem: A Survey. </title> <journal> Transportation Science, </journal> <volume> 3(2) </volume> <pages> 140-163, </pages> <year> 1969. </year>
Reference-contexts: The operations research (OR) literature contains numerous references to the airline crew scheduling problem <ref> [2, 3, 4, 7, 25, 36, 46, 47] </ref>. Estimates of over a billion dollars a year for pilot and flight attendant expenses have been reported [1, 7]. Even a small improvement over existing solutions can have a large economic benefit. At one time solutions to the SPP were generated manually. <p> More traditional methods may have trouble accommodating the addition of new constraints as easily. Also, at any iteration genetic algorithms contain a population of possible solutions. As noted by Arabeyre et al. <ref> [3] </ref>, The knowledge of a family of good solutions is far more important than obtaining an isolated optimum. 13 This reality has been noted also by many operations research practitioners.
Reference: [4] <author> E. Baker and M. Fisher. </author> <title> Computational Results for Very Large Air Crew Scheduling Problems. </title> <journal> OMEGA, </journal> <volume> 9(6) </volume> <pages> 613-618, </pages> <year> 1981. </year>
Reference-contexts: The operations research (OR) literature contains numerous references to the airline crew scheduling problem <ref> [2, 3, 4, 7, 25, 36, 46, 47] </ref>. Estimates of over a billion dollars a year for pilot and flight attendant expenses have been reported [1, 7]. Even a small improvement over existing solutions can have a large economic benefit. At one time solutions to the SPP were generated manually.
Reference: [5] <author> J. Baker. </author> <title> Reducing bias and inefficiency in the selection algorithm. </title> <editor> In J. Grefenstette, editor, </editor> <booktitle> Proceedings of the Second International Conference on Genetic Algorithms and Their Applications, </booktitle> <pages> pages 14-21, </pages> <address> Hillsdale, New Jersey, 1987. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: Our choice of b (t) is intended to interfere with the selective pressure as little as possible, while still converting the minimization of f into the maximization of u. We also tested a linear rank fitness function <ref> [5, 66] </ref> given by u (x) = M in + (M ax M in) rank (x; t) 1 N 1 where rank (x; t) is the index of x in a list sorted in order of decreasing evaluation function value. <p> We compared two choices for the selection algorithm: stochastic universal selection and tournament selection. Baker's stochastic universal selection (SUS) is an optimal sampling algorithm <ref> [5] </ref>. SUS may be thought of as constructing a roulette wheel using fitness proportionate selection and then spinning the wheel once, where the number of equally 31 Table 2.10 Comparison of Fitness Techniques in SSGAROW Problem Cmax Ranking Name Opt. Trials Opt.
Reference: [6] <author> E. Balas and M. Padberg. </author> <title> Set Partitioning: A Survey. </title> <journal> SIAM Review, </journal> <volume> 18(4) </volume> <pages> 710-760, </pages> <year> 1976. </year>
Reference-contexts: A partial list of these applications includes crew scheduling, tanker routing, switching circuit design, assembly line balancing, capital equipment decisions, and location of offshore drilling platforms <ref> [6] </ref>. The best-known application of the SPP is airline crew scheduling. In this formulation each row (i = 1; : : : ; m) represents a flight leg (a takeoff and landing) that must be flown. <p> Both Garfinkel and Nemhauser [24] and Marsten [46] developed implicit enumeration algorithms. Another traditional method is the use of cutting planes (additional constraints) in conjunction with the simplex method. Balas and Padberg <ref> [6] </ref> note that cutting plane algorithms were moderately successful even while using general-purpose cuts and not taking advantage of the shape of the SPP polytope.
Reference: [7] <author> J. Barutt and T. Hull. </author> <title> Airline Crew Scheduling: Supercomputers and Algorithms. </title> <journal> SIAM News, </journal> <volume> 23(6), </volume> <year> 1990. </year>
Reference-contexts: The operations research (OR) literature contains numerous references to the airline crew scheduling problem <ref> [2, 3, 4, 7, 25, 36, 46, 47] </ref>. Estimates of over a billion dollars a year for pilot and flight attendant expenses have been reported [1, 7]. Even a small improvement over existing solutions can have a large economic benefit. At one time solutions to the SPP were generated manually. <p> The operations research (OR) literature contains numerous references to the airline crew scheduling problem [2, 3, 4, 7, 25, 36, 46, 47]. Estimates of over a billion dollars a year for pilot and flight attendant expenses have been reported <ref> [1, 7] </ref>. Even a small improvement over existing solutions can have a large economic benefit. At one time solutions to the SPP were generated manually. However, airline crew scheduling problems have grown significantly in size and complexity. <p> In the LP relaxation, the integrality restriction on x j is relaxed, but the lower and upper bounds of zero and one are kept. A number of authors <ref> [7, 25, 47] </ref> have noted that for "small" SPP problems the solution to the LP relaxation is either all integer, in which case it is also the optimal integer solution, or has only a few fractional values that are easily resolved. <p> However, in recent years it has been noted that as SPP problems grow in size, fractional solutions occur more frequently, and simply rounding or performing a "small" branch-and-bound tree search may not be effective <ref> [2, 7, 25] </ref>. Marsten [46] noted twenty years ago that for most algorithms in use at that time, solving the linear programming relaxation to the SPP was the computational bottleneck. This is because the LP relaxation is highly degenerate. <p> For solving the large SPP problems that arise in the airline industry <ref> [7, 9] </ref>, data structures that are memory efficient and lend themselves to efficient computation are necessary. In the SPP, both the A matrix and the solution vector are binary, and it is possible to devise special data structures that make efficient use of memory.
Reference: [8] <author> M. Berkelaar. </author> <title> lp solve, 1993. A public domain linear and integer programming program. </title> <note> Available by anonymous ftp from ftp.es.ele.tue.nl in directory pub/lp solve, file lp solve.tar.Z. </note>
Reference-contexts: We can also gain some insight into the difficulty of the test problems by solving them with a traditional operations research algorithm. y The test problems have been solved using the public-domain lp solve program <ref> [8] </ref>. lp solve solves linear programming problems using the simplex method and solves integer programming (IP) problems using the branch-and-bound algorithm. The results are given in Table 2.2.
Reference: [9] <author> R. Bixby, J. Gregory, I. Lustig, R. Marsten, and D. Shanno. </author> <title> Very Large-Scale Linear Programming: A Case Study in Combining Interior Point and Simplex Methods. </title> <type> Technical Report CRPC, </type> <institution> Rice University, </institution> <year> 1991. </year>
Reference-contexts: In 1981 problems with 400 rows and 30,000 columns were described as "very large" [47]. Today, problems with hundreds of thousands of columns are "very large," and one benchmark problem has been generated with 837 rows and 12,753,313 columns <ref> [9] </ref>. 1.1.3 Previous Algorithms. Because of the widespread use of the SPP (and often the difficulty of its solution) a number of algorithms have been developed. <p> This is because the LP relaxation is highly degenerate. The past several years have seen a number of advances in linear programming algorithms and the application of that technology to solving the LP relaxation of very large SPP problems <ref> [2, 9] </ref>. One of the oldest exact methods is implicit enumeration. In this method partial solutions are generated by taking the columns one at a time and exploring logical implications of their assignments. Both Garfinkel and Nemhauser [24] and Marsten [46] developed implicit enumeration algorithms. <p> For solving the large SPP problems that arise in the airline industry <ref> [7, 9] </ref>, data structures that are memory efficient and lend themselves to efficient computation are necessary. In the SPP, both the A matrix and the solution vector are binary, and it is possible to devise special data structures that make efficient use of memory.
Reference: [10] <author> L. Booker. </author> <title> Improving Search in Genetic Algorithms. </title> <booktitle> In Genetic Algorithms and Simulated Annealing, </booktitle> <pages> pages 61-73. </pages> <publisher> Pitman Publishing, </publisher> <address> London, </address> <year> 1987. </year>
Reference-contexts: In the past several years, however, GA researchers have preferred either two-point or uniform crossover. It is these, along with a specialized two-point "block crossover" we developed for the SPP problem, that we compared. 2.4.6.1 Two-Point Crossover. Booker <ref> [10] </ref> cites DeJong [17] who noted that one-point crossover is really a special form of two-point crossover where the second "cut" point is always fixed at the zero location. Figure 2.9 illustrates two-point crossover. <p> Two-point crossover (and one-point crossover) are special cases of n-point crossover operators. In the n-point crossover operators, more than one crosspoint is selected, and several substrings from each parent may be exchanged. Experiments by Booker <ref> [10] </ref> showed a significant improvement in off-line performance at the expense of online performance when using two randomly generated crossover points. In the case of function optimization, off-line performance is the more important measure. 2.4.6.2 Two-Point Block Crossover.
Reference: [11] <author> R. Butler and E. Lusk. </author> <title> Monitors, Messages, and Clusters: The p4 Parallel Programming System. </title> <journal> Parallel Computing, </journal> <volume> 20, </volume> <year> 1994. </year>
Reference-contexts: Each node ran its own copy of the AIX operating system. The SP1 makes use of a high-performance switch for connecting the nodes. 49 The parallel program was initially developed on Unix workstations making use of the message passing capabilities of the p4 <ref> [11] </ref> parallel programming system. For the parallel experiments on the SP1, the code was ported to the Chameleon [34] message-passing system. Chameleon is designed to provide a portable, high-performance message-passing system. Chameleon runs on top of many other message passing systems, both vendor-specific and third party, allowing widespread portability.
Reference: [12] <author> V. Chavatal. </author> <title> A Greedy Heuristic for the Set Covering Problem. </title> <journal> Mathematics of Operations Research, </journal> <volume> 4(3) </volume> <pages> 233-235, </pages> <year> 1979. </year>
Reference-contexts: This method is a modification of a heuristic proposed by Chavatal <ref> [12] </ref> for the set covering problem. For the set covering problem Chavatal notes: Intuitively, it seems the desirability of including j in an optimal cover increases with the ratio jP j j=c j which counts the number of points covered by P j per unit cost.
Reference: [13] <author> J. Cohoon, W. Martin, and D. Richards. </author> <title> Genetic algorithms and punctuated equilibria in VLSI. </title> <editor> In H. Schwefel and R. Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature, </booktitle> <pages> pages 134-144, </pages> <address> Berlin, 1991. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Two interesting properties of their problem are that (1) the minimum occurs on a boundary point of the feasible region, and (2) the penalty function is monotonically growing. They report that a variable penalty coefficient outperforms the fixed coefficient penalty. Cohoon, Martin, and Richards <ref> [13] </ref> use a penalty term when solving the K-partition problem. The penalty is exponentially increasing with the degree of constraint violation. <p> The more distributed the GA, the more often adaptive mutation was invoked, since smaller sub-populations converge more rapidly than larger ones. Their experiments also indicate that migrating strings too often, or not often enough, degrade performance. Cohoon, Martin, and Richards <ref> [13] </ref> applied the CPGA to the K-partition problem using a 16-processor hypercube. Each processor had its own subpopulation of eighty strings, and fifty iterations were run between migrations.
Reference: [14] <author> L. Davis. </author> <title> Adapting operator probabilities in genetic algorithms. </title> <editor> In J. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 61-69, </pages> <address> San Mateo, 1989. </address> <publisher> Morgan Kaufmann. </publisher> <pages> 72 </pages>
Reference-contexts: One possibility is to use an adaptive mutation rate that changes based on the value of some GA statistic such as population diversity or the Hamming distance between two parent strings [68]. Several researchers <ref> [14, 64] </ref> make the case for a high mutation rate when mutation is separated from crossover, as it is in our implementation.
Reference: [15] <author> L. Davis. </author> <title> Handbook of Genetic Algorithms. </title> <publisher> Van Nostrand Reinhold, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: The basic outline of the GRGA is given in Figure 1.1. The GRGA allows the possibility that the best strings in the population do not survive to the next generation. Also, as Davis points out <ref> [15] </ref>, many of the best strings may not be allocated any reproductive trials. It is also possible that mutation or crossover destroy or alter important bit values so that they are not propagated into the next generation by the parent's offspring. <p> Alternatively, we can also make the first move found that improves the current solution. We refer to these two choices as best-improving and first-improving, respectively. The experimental evidence of many researchers <ref> [15, 39, 40, 48] </ref> is that hybridizing a genetic algorithm with a local search heuristic is beneficial. It combines the GAs ability to widely sample a search space with a local search heuristic's hill-climbing ability. There are, however, theoretical objections to the use of a local search heuristic. <p> With respect to genetic algorithms this is not surprising; several leading GA researchers have pointed out that GAs are general-purpose tools that will usually be outperformed when specialized algorithms for a problem exist <ref> [15, 18] </ref>. Comparing SSGAROW with the branch-and-bound approach as implemented by lp solve, we find that lp solve fares better for many but not all of the test problems.
Reference: [16] <author> M. de la Maza and B. Tidor. </author> <title> An analysis of procedures with particular attention paid to proportional and Boltzmann selection. </title> <editor> In S. Forrest, editor, </editor> <booktitle> Proceedings of the Fifth International Conference on Genetic Algorithms, </booktitle> <pages> pages 124-131, </pages> <address> San Mateo, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: We tested two choices for the fitness function. A dynamic linear fitness function [26, 30] is given by u (x) = af (x) + b (t): We used a = 1 and b (t) = 1:1 maxff (x)jx 2 P (t)g. De la Maza and Tidor <ref> [16] </ref> point out that the choice of b (t) can significantly affect the selective pressure. Our choice of b (t) is intended to interfere with the selective pressure as little as possible, while still converting the minimization of f into the maximization of u.
Reference: [17] <author> K. DeJong. </author> <title> An Analysis of the Behavior of a Class of Genetic Adaptive Systems. </title> <type> PhD thesis, </type> <institution> University of Michigan, Ann Arbor, 1975. Department of Computer and Communication Sciences. </institution>
Reference-contexts: In the past several years, however, GA researchers have preferred either two-point or uniform crossover. It is these, along with a specialized two-point "block crossover" we developed for the SPP problem, that we compared. 2.4.6.1 Two-Point Crossover. Booker [10] cites DeJong <ref> [17] </ref> who noted that one-point crossover is really a special form of two-point crossover where the second "cut" point is always fixed at the zero location. Figure 2.9 illustrates two-point crossover. <p> Further studies show a decreasing crossover rate as the population size increases. Some classical results using generational replacement GAs have suggested N = 50-100 and p c = 0:6 (DeJong <ref> [17] </ref>), and N = 80 and p c = 0:45 (Grefenstette [30]) as good values for o*ine performance. More recently, steady-state GAs have become prominent; but no set of parameter values is yet a default.
Reference: [18] <author> K. DeJong. </author> <title> Genetic algorithms are NOT function optimizers. </title> <editor> In D. Whitley, editor, </editor> <booktitle> Foundations of Genetic Algorithms -2-, </booktitle> <pages> pages 5-17. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, </address> <year> 1993. </year>
Reference-contexts: With respect to genetic algorithms this is not surprising; several leading GA researchers have pointed out that GAs are general-purpose tools that will usually be outperformed when specialized algorithms for a problem exist <ref> [15, 18] </ref>. Comparing SSGAROW with the branch-and-bound approach as implemented by lp solve, we find that lp solve fares better for many but not all of the test problems.
Reference: [19] <author> K. DeJong and W. Spears. </author> <title> An analysis of the interacting roles of population size and crossover in genetic algorithms. </title> <editor> In H. Schwefel and R. Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature, </booktitle> <pages> pages 38-47, </pages> <address> New York, 1991. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Testing by Syswerda showed that uniform crossover performed significantly better than one-or two-point crossover on most problems. DeJong and Spears <ref> [19] </ref> present empirical results on a set of n-peak problems (those with one global optima, but n 1 local optima) comparing two-point and uniform crossover with varying population sizes.
Reference: [20] <author> J. Eckstein. </author> <title> Parallel Branch-and-Bound Algorithms for General Mixed Integer Programming on the CM-5. </title> <type> Technical Report TMC-257, </type> <institution> Thinking Machines Corp., </institution> <year> 1993. </year>
Reference-contexts: Applying a generic branch-and-bound program is also possible. Various bounding strategies have been used, including linear programming and Lagrangian relaxation. Fischer and Kedia [21] use continuous analogs 3 of the greedy and 3 opt methods to provide improved lower bounds. Of recent inter-est is the work of Eckstein <ref> [20] </ref>, who has developed a general-purpose mixed-integer programming system for use on the CM-5 parallel computer and applied it to, among other problems, set partitioning. At the time of this writing the most successful approach appears to be the work of Hoffman and Padberg [36].
Reference: [21] <author> M. Fischer and P. Kedia. </author> <title> Optimal Solution of Set Covering/Partitioning Problems Using Dual Heuristics. </title> <journal> Management Science, </journal> <volume> 36(6) </volume> <pages> 674-688, </pages> <year> 1990. </year>
Reference-contexts: Applying a generic branch-and-bound program is also possible. Various bounding strategies have been used, including linear programming and Lagrangian relaxation. Fischer and Kedia <ref> [21] </ref> use continuous analogs 3 of the greedy and 3 opt methods to provide improved lower bounds. Of recent inter-est is the work of Eckstein [20], who has developed a general-purpose mixed-integer programming system for use on the CM-5 parallel computer and applied it to, among other problems, set partitioning. <p> VI. We might also be able to take advantage of operations research work. One example might be to revisit the use of the solution to the LP relaxation to initialize (perhaps just some of) the population. Both Fischer and Kedia <ref> [21] </ref> and Hoffman and Padberg [36] suggest heuristics for finding integer solutions to SPP problems that might also be incorporated in the initial population. A number of methods for preprocessing a set partitioning problem and using logical reductions to reduce the number of constraints and/or variables have been suggested.
Reference: [22] <author> M. Flynn. </author> <title> Some Computer Organizations and Their Effectiveness. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 21 </volume> <pages> 948-960, </pages> <year> 1972. </year>
Reference-contexts: They report optimal solutions for a large set of real-world SPP problems. 1.2 Parallel Computers Traditionally, parallel computers are classified according to Flynn's taxonomy <ref> [22] </ref>. Flynn's classification distinguishes parallel computers according to the number of instruction streams and data operands being computed on simultaneously. There are three main classifications of interest: single-instruction single-data (SISD) computers, single-instruction multiple-data (SIMD) computers, and multiple-instruction multiple-data (MIMD) computers. The SISD model is the traditional sequential computer.
Reference: [23] <author> T. Fogarty and R. Huang. </author> <title> Implementing the genetic algorithm on transputer based parallel processing systems. </title> <editor> In H. Schwefel and R. Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature, </booktitle> <pages> pages 145-149, </pages> <address> Berlin, 1991. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: The algorithm was applied to the TSP problem, using a population size of 64 and a neighborhood size of eight. Results 12 showed that, with a small neighborhood size, communication costs were negligible, and linear speedup was achieved. 1.3.2.3 Other Parallel Genetic Algorithms. Fogarty and Huang <ref> [23] </ref> used a transputer array for the parallel evaluation of a population of 250 strings applied to a real-time control problem. For this problem, evaluating the fitness of a member of the population takes a relatively long time.
Reference: [24] <author> R. Garfinkel and G. Nemhauser. </author> <title> Integer Programming. </title> <publisher> John Wiley & Sons Inc., </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: The following notation is common in the literature <ref> [24, 46] </ref> y and motivates the name "set partitioning problem." Let I = f1; : : : ; mg be a set of row indices, J = f1; : : : ; ng a set of column indices, and P = fP 1 ; : : : ; P n g, <p> One of the oldest exact methods is implicit enumeration. In this method partial solutions are generated by taking the columns one at a time and exploring logical implications of their assignments. Both Garfinkel and Nemhauser <ref> [24] </ref> and Marsten [46] developed implicit enumeration algorithms. Another traditional method is the use of cutting planes (additional constraints) in conjunction with the simplex method.
Reference: [25] <author> I. Gershkoff. </author> <title> Optimizing Flight Crew Schedules. </title> <journal> INTERFACES, </journal> <volume> 19 </volume> <pages> 29-43, </pages> <year> 1989. </year>
Reference-contexts: The operations research (OR) literature contains numerous references to the airline crew scheduling problem <ref> [2, 3, 4, 7, 25, 36, 46, 47] </ref>. Estimates of over a billion dollars a year for pilot and flight attendant expenses have been reported [1, 7]. Even a small improvement over existing solutions can have a large economic benefit. At one time solutions to the SPP were generated manually. <p> In the LP relaxation, the integrality restriction on x j is relaxed, but the lower and upper bounds of zero and one are kept. A number of authors <ref> [7, 25, 47] </ref> have noted that for "small" SPP problems the solution to the LP relaxation is either all integer, in which case it is also the optimal integer solution, or has only a few fractional values that are easily resolved. <p> However, in recent years it has been noted that as SPP problems grow in size, fractional solutions occur more frequently, and simply rounding or performing a "small" branch-and-bound tree search may not be effective <ref> [2, 7, 25] </ref>. Marsten [46] noted twenty years ago that for most algorithms in use at that time, solving the linear programming relaxation to the SPP was the computational bottleneck. This is because the LP relaxation is highly degenerate.
Reference: [26] <author> D. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization and Machine Learning. </title> <publisher> Addison-Wesley Publishing Company, Inc., </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: This work is at an extreme from most CPGAs, because strings are exchanged every generation and always with the same neighbors. These conditions explain the apparent increased likelihood of premature convergence. Gordon and Whitley [28] compare eight different parallel genetic algorithms and a version of Goldberg's Simple Genetic Algorithm <ref> [26] </ref> on several function optimization test problems. Among their conclusions is that island models (CPGAs) perform well, particularly on the hardest problems in their test suite. 1.3.2.2 Fine-Grained Parallel Genetic Algorithms. In a fine-grained parallel genetic algorithm (FPGA) exactly one string is assigned to each processor. <p> Two choices, at extremes from each other, are common in the literature. The first, the generational replacement genetic algorithm (GRGA), replaces the entire population each generation and is the traditional genetic algorithm as defined by Holland [37] and popularized by Goldberg <ref> [26] </ref>. The second, the steady-state genetic algorithm (SSGA), replaces only one or two strings each generation and is a more recent development [61, 66, 69]. In the GRGA the entire population is replaced each generation by their offspring. <p> In the GRGA the entire population is replaced each generation by their offspring. The hope is that the offspring of the best strings carry the important "building blocks" <ref> [26] </ref> from the best strings forward to the next generation. The basic outline of the GRGA is given in Figure 1.1. The GRGA allows the possibility that the best strings in the population do not survive to the next generation. <p> If selection is to be done by calculating the expected number of reproductive trials and then sampling those, however, the choice of fitness function can play a significant role. We tested two choices for the fitness function. A dynamic linear fitness function <ref> [26, 30] </ref> is given by u (x) = af (x) + b (t): We used a = 1 and b (t) = 1:1 maxff (x)jx 2 P (t)g. De la Maza and Tidor [16] point out that the choice of b (t) can significantly affect the selective pressure. <p> This method guarantees that each string is allocated bexpectedvaluec reproductive trials and no more than dexpectedvaluee. In binary tournament selection <ref> [26, 27] </ref> two strings are chosen randomly from the population. The more fit string is then allocated a reproductive trial. In order to produce an offspring, two binary tournaments are held, each of which produces one parent string. These two parent strings then recombine to produce an offspring.
Reference: [27] <author> D. Goldberg and K. Deb. </author> <title> A comparative analysis of selection schemes used in genetic algorithms. </title> <editor> In G. Rawlins, editor, </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <pages> pages 69-93. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, </address> <year> 1991. </year> <month> 73 </month>
Reference-contexts: This method guarantees that each string is allocated bexpectedvaluec reproductive trials and no more than dexpectedvaluee. In binary tournament selection <ref> [26, 27] </ref> two strings are chosen randomly from the population. The more fit string is then allocated a reproductive trial. In order to produce an offspring, two binary tournaments are held, each of which produces one parent string. These two parent strings then recombine to produce an offspring. <p> IV. Additional work in determining good choices for the parameters of the island model is another area for further research. Selecting the string to migrate or delete seems closest to what has been studied for sequential genetic algorithms (see, for example, Goldberg and Deb's <ref> [27] </ref> comments about deleting the worst-ranked string in Genitor, and compare that with our empirical findings in Section 3.2.2). However, the appropriate choice of migration interval remains an open question.
Reference: [28] <author> S. Gordon and D. Whitley. </author> <title> Serial and parallel genetic algorithms as function optimizers. </title> <editor> In S. Forrest, editor, </editor> <booktitle> Proceedings of the Fifth International Conference on Genetic Algorithms, </booktitle> <pages> pages 177-183, </pages> <address> San Mateo, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: They believe their results indicate an increased likelihood of premature convergence. This work is at an extreme from most CPGAs, because strings are exchanged every generation and always with the same neighbors. These conditions explain the apparent increased likelihood of premature convergence. Gordon and Whitley <ref> [28] </ref> compare eight different parallel genetic algorithms and a version of Goldberg's Simple Genetic Algorithm [26] on several function optimization test problems. Among their conclusions is that island models (CPGAs) perform well, particularly on the hardest problems in their test suite. 1.3.2.2 Fine-Grained Parallel Genetic Algorithms.
Reference: [29] <author> M. Gorges-Schleuter. </author> <title> Explicit parallelism of genetic algorithms through population structures. </title> <editor> In H. Schwefel and R. Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature, </booktitle> <pages> pages 150-159, </pages> <address> New York, 1991. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: The parent string was replaced if the offspring was at least as good as the worst string in the neighborhood. A small neighborhood size in conjunction with a large population size gave the best results. In <ref> [29] </ref> Gorges-Schleuter implemented an FPGA on a 64-processor Parsytec trans-puter system using a sparse graph as the population topology. An elitist strategy was used whereby offspring are accepted for the next generation only if they were more fit than the local parent.
Reference: [30] <author> J. Grefenstette. </author> <title> Optimization of Control Parameters for Genetic Algorithms. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 16(1) </volume> <pages> 122-128, </pages> <year> 1986. </year>
Reference-contexts: If selection is to be done by calculating the expected number of reproductive trials and then sampling those, however, the choice of fitness function can play a significant role. We tested two choices for the fitness function. A dynamic linear fitness function <ref> [26, 30] </ref> is given by u (x) = af (x) + b (t): We used a = 1 and b (t) = 1:1 maxff (x)jx 2 P (t)g. De la Maza and Tidor [16] point out that the choice of b (t) can significantly affect the selective pressure. <p> Further studies show a decreasing crossover rate as the population size increases. Some classical results using generational replacement GAs have suggested N = 50-100 and p c = 0:6 (DeJong [17]), and N = 80 and p c = 0:45 (Grefenstette <ref> [30] </ref>) as good values for o*ine performance. More recently, steady-state GAs have become prominent; but no set of parameter values is yet a default. To try to determine a good crossover rate, we tested three crossover probabilities, 0.3, 0.6, and 0.9, in conjunction with the three crossover operators described earlier.
Reference: [31] <author> J. Grefenstette and J. Baker. </author> <title> How genetic algorithms work: A critical look at implicit parallelism. </title> <editor> In J. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 20-27, </pages> <address> San Mateo, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: As has been pointed out, however, the evaluation function value itself is not an "exact" measure of fitness [66]. The mapping from the evaluation function to the fitness function "should be considered a design parameter of the genetic algorithm, not a feature of the optimization problem" <ref> [31] </ref>. In general, the fitness function is given by u (x) = g (f (x)). If selection is done via a binary tournament (see below), any fitness function that reflects the monotonicity of the evaluation function will suffice.
Reference: [32] <author> J. Gregory. </author> <title> Private communication, </title> <year> 1991. </year>
Reference-contexts: The difference is that the criterion used to decide which column to next set to one in Figure 2.6 is to use min j f j 1 jx j = 0g instead of min j 0g. 2.4.5.3 Gregory's Heuristic. Gregory's heuristic <ref> [32] </ref> is a generalization of the Vogel approximation method for generating a starting solution to a Hitchcock 33 while ( 9 i s.t. r i = ; ) for ( i = 1; m) k 1 = min f j 1 jj 2 R i g j d i l 1 <p> The algorithm is given in Figure 2.7. 2.4.5.4 Random Initialization. Random initialization sets x j 1, for all columns j, with probability 0.5. 2.4.5.5 Block Random Initialization. Block random initialization, based on a suggestion of Gregory <ref> [32] </ref>, uses information about the expected structure of an SPP solution. A solution to the SPP typically contains only a few "ones" and is mostly zeros. We can use this knowledge by randomly setting to one approximately the same number of columns estimated to be one in the final solution.
Reference: [33] <author> J. Gregory. </author> <title> Private communication, </title> <year> 1994. </year>
Reference-contexts: Comparing SSGAROW with lp solve, we see that neither can solve the aa problems: lp solve does better than SSGAROW on most (but not all) of the nw problems, and SSGAROW does better than lp solve on the two kl problems. John Gregory has suggested <ref> [33] </ref> that the nw models, while "real world," are not indicative of the SPP problems most airlines would like to be able to solve, in that they are relatively easy to solve with little branching and that more difficult models may be in production use now, being "solved" by heuristics rather
Reference: [34] <author> W. Gropp and B. Smith. </author> <title> Chameleon Parallel Programming Tools Users Manual. </title> <type> Technical Report ANL-93/23, </type> <institution> Argonne National Laboratory, </institution> <year> 1993. </year>
Reference-contexts: For the parallel experiments on the SP1, the code was ported to the Chameleon <ref> [34] </ref> message-passing system. Chameleon is designed to provide a portable, high-performance message-passing system. Chameleon runs on top of many other message passing systems, both vendor-specific and third party, allowing widespread portability.
Reference: [35] <author> F. Gruau and D. Whitley. </author> <title> Adding Learning to the Cellular Development of Neural Networks: Evolution and the Baldwin Effect. </title> <journal> Evolutionary Computation, </journal> <volume> 1(3) </volume> <pages> 213-233, </pages> <year> 1993. </year>
Reference-contexts: There are, however, theoretical objections to the use of a local search heuristic. An important one is that changing the "genetic material" in the population in a nonevolutionary manner will affect the schema represented in the population and undermine the GA. Gruau and Whitley <ref> [35] </ref> comment: Changing the coding of an offspring's bit string alters the statistical information about hyperplane subpartitions that is implicitly contained in the population. Theoretically, applying local optimization to improve each offspring undermines the genetic algorithm's ability to search via hyperplane sampling.
Reference: [36] <author> K. Hoffman and M. Padberg. </author> <title> Solving Airline Crew-Scheduling Problems by Branch-and-Cut. </title> <journal> Management Science, </journal> <volume> 39(6) </volume> <pages> 657-682, </pages> <year> 1993. </year>
Reference-contexts: The operations research (OR) literature contains numerous references to the airline crew scheduling problem <ref> [2, 3, 4, 7, 25, 36, 46, 47] </ref>. Estimates of over a billion dollars a year for pilot and flight attendant expenses have been reported [1, 7]. Even a small improvement over existing solutions can have a large economic benefit. At one time solutions to the SPP were generated manually. <p> At the time of this writing the most successful approach appears to be the work of Hoffman and Padberg <ref> [36] </ref>. They present an exact approach based on the use of branch-and-cut|a branch-and-bound-like scheme where, however, additional preprocessing and constraint generation take place at each node in the search tree. <p> Finally, Section 2.5 summarizes the results. 2.1 Test Problems The test problems used in this chapter are given in Table 2.1 where they are sorted by increasing number of columns. These problems are a subset of those used by Hoffman and Padberg in <ref> [36] </ref>. They are "real" set partitioning problems provided by the airline industry. <p> the others (except aa04), indicate (at least for lp solve) it is a hard problem. aa04 was the most difficult|lp solve was not able to solve the associated LP relaxation and, in fact, aborted after over 7,000 simplex iterations. aa04 seems to be a difficult problem for others as well <ref> [36] </ref>. We conclude that the seven smaller problems are "relatively easy," nw18 is more difficult, and aa04 is very difficult. 2.2 The Genetic Algorithm One way to classify genetic algorithms is by the percentage of the population that is replaced each generation. <p> For the random number generator in [45] each unique seed gives rise to an independent sequence of random numbers of size 10 30 [38]. 3.4 Test Problems To test the parallel genetic algorithm we selected a subset of forty problems from the Hoffman and Padberg test set <ref> [36] </ref>. This included the nine problems used in Chapter II and thirty-one others. The test problems are given in Table 3.4, where they have been sorted according to increasing numbers of columns. <p> Table 3.11 compares the solution value found (the subcolumn Result) and time in CPU seconds (the subcolumn Secs.) of lp solve, the work of Hoffman and Padberg <ref> [36] </ref> (the column HP), and our work (the column SSGAROW). <p> These times include the time to convert from the standard MPS format used in linear programming to lp solve's input format. The timings for Hoffman and Padberg's work are from Tables 3 and 8 in <ref> [36] </ref>. These runs were made on an IBM RS/6000 Model 550 workstation. The results for SSGAROW are the CPU time charged to processor zero in a run that used the number of processors given in the Nprocs column. <p> VI. We might also be able to take advantage of operations research work. One example might be to revisit the use of the solution to the LP relaxation to initialize (perhaps just some of) the population. Both Fischer and Kedia [21] and Hoffman and Padberg <ref> [36] </ref> suggest heuristics for finding integer solutions to SPP problems that might also be incorporated in the initial population. A number of methods for preprocessing a set partitioning problem and using logical reductions to reduce the number of constraints and/or variables have been suggested.
Reference: [37] <author> J. Holland. </author> <booktitle> Adaption in Natural and Artificial Systems. </booktitle> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, </address> <year> 1975. </year>
Reference-contexts: For the model of a parallel genetic algorithm we use, a distributed-memory MIMD computer is the most natural choice for implementation and the one we pursued. 1.3 Genetic Algorithms Genetic algorithms (GAs) are search algorithms. They were developed by Holland <ref> [37] </ref> and are based on an analogy with natural selection and population genetics. <p> Two choices, at extremes from each other, are common in the literature. The first, the generational replacement genetic algorithm (GRGA), replaces the entire population each generation and is the traditional genetic algorithm as defined by Holland <ref> [37] </ref> and popularized by Goldberg [26]. The second, the steady-state genetic algorithm (SSGA), replaces only one or two strings each generation and is a more recent development [61, 66, 69]. In the GRGA the entire population is replaced each generation by their offspring.
Reference: [38] <author> F. James. </author> <title> A Review of Pseudorandom Number Generators. </title> <journal> Computer Physics Communication, </journal> <volume> 60 </volume> <pages> 329-344, </pages> <year> 1990. </year>
Reference-contexts: Random number generation was done using an implementation of the universal random number generator proposed by Marsaglia, Zaman, and Tseng [45], and translated to C from James' version <ref> [38] </ref>. Each time a parallel run was made, all sub-populations were randomly seeded. This was done by having processor zero get and broadcast the microsecond portion of the Unix gettimeofday system call. <p> Each processor then added its processor id to the value returned by the Unix gettimeofday and used this unique value as its random number seed. For the random number generator in [45] each unique seed gives rise to an independent sequence of random numbers of size 10 30 <ref> [38] </ref>. 3.4 Test Problems To test the parallel genetic algorithm we selected a subset of forty problems from the Hoffman and Padberg test set [36]. This included the nine problems used in Chapter II and thirty-one others.
Reference: [39] <author> P. Jog, J. Suh, and D. Gucht. </author> <title> Parallel Genetic Algorithms Applied to the Traveling Salesman Problem. </title> <type> Technical Report No. 314, </type> <institution> Indiana University, </institution> <year> 1990. </year>
Reference-contexts: The idea is to degrade the fitness of infeasible strings but not throw away valuable information contained in the cost term of the fitness function. Below we discuss some examples of the second and third approaches. Jog, Suh, and Gucht <ref> [39] </ref> summarize many of the crossover operators used for the traveling salesperson problem (TSP). In general, these operators try to include as much of the parent strings as possible in the offspring, subject to the constraint that the offspring contain a valid tour. <p> Parallel genetic algorithms can be classified according to the granularity of the distributed population, coarse grained vs. fine grained, and the manner in which the GA operators are applied <ref> [39] </ref>. In a coarse-grained PGA the population is divided into several subpopulations, each of which runs a traditional GA independently and in parallel on its own subpopulation. Occasionally, fit strings migrate from one subpopulation to another. <p> Alternatively, we can also make the first move found that improves the current solution. We refer to these two choices as best-improving and first-improving, respectively. The experimental evidence of many researchers <ref> [15, 39, 40, 48] </ref> is that hybridizing a genetic algorithm with a local search heuristic is beneficial. It combines the GAs ability to widely sample a search space with a local search heuristic's hill-climbing ability. There are, however, theoretical objections to the use of a local search heuristic.
Reference: [40] <author> T. Kido, H. Kitano, and M. Nakanishi. </author> <title> A hybrid search for genetic algorithms: Combining genetic algorithms, tabu search, and simulated annealing. </title> <editor> In S. Forrest, editor, </editor> <booktitle> Proceedings of the Fifth International Conference on Genetic Algorithms, </booktitle> <pages> page 614, </pages> <address> San Mateo, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Alternatively, we can also make the first move found that improves the current solution. We refer to these two choices as best-improving and first-improving, respectively. The experimental evidence of many researchers <ref> [15, 39, 40, 48] </ref> is that hybridizing a genetic algorithm with a local search heuristic is beneficial. It combines the GAs ability to widely sample a search space with a local search heuristic's hill-climbing ability. There are, however, theoretical objections to the use of a local search heuristic.
Reference: [41] <author> B. Kroger, P. Schwenderling, and O. Vornberger. </author> <title> Parallel genetic packing of rectangles. </title> <editor> In H. Schwefel and R. Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature, </booktitle> <pages> pages 160-164, </pages> <address> Berlin, 1991. </address> <publisher> Springer-Verlag. </publisher> <pages> 74 </pages>
Reference-contexts: In the other, each processor chose a value for uniformly on the interval (0,1). When the metric "best observed fitness" was applied, the runs with uniformly distributed were consistently better than those with fixed at one in each processor. Kroger, Schwenderling, and Vornberger <ref> [41] </ref> used a CPGA on a network of 32 transputers to solve the two-dimensional bin packing problem. At "irregular intervals" a processor received strings from neighboring processors.
Reference: [42] <author> T. Kuo and S. Hwang. </author> <title> A genetic algorithm with disruptive selection. </title> <editor> In S. Forrest, editor, </editor> <booktitle> Proceedings of the Fifth International Conference on Genetic Algorithms, </booktitle> <pages> pages 65-69, </pages> <address> San Mateo, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The fitness function is used during the selection phase to determine the expected number of reproductive trials to allocate to a string. Genetic algorithms require that the fitness function be nonnegative and that the more highly fit a string, the larger its fitness function value (although see <ref> [42] </ref> for 30 a discussion of the use of a nonmonotonic fitness function). For the SPP this requires a mapping from the evaluation function to the fitness function. As has been pointed out, however, the evaluation function value itself is not an "exact" measure of fitness [66].
Reference: [43] <author> D. Levine. </author> <title> A genetic algorithm for the set partitioning problem. </title> <editor> In S. Forrest, editor, </editor> <booktitle> Proceedings of the Fifth International Conference on Genetic Algorithms, </booktitle> <pages> pages 481-487, </pages> <address> San Mateo, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: However, the most obvious result from Table 2.3 is the lack of optimal solutions found, even on the smaller problems. The main difficulty was the population's premature convergence, so that all the strings in the population were duplicates and no new search was occurring (see also <ref> [43] </ref> for more on our earlier work). <p> This reliance could result in less global exploration of the search space because it is hyperplane sampling that is the basis for the claim that genetic algorithms globally sample a search space. Our early experience with the GRGA <ref> [43] </ref>, as well as subsequent experience with the SSGA, was that both methods had trouble finding optimal (sometimes even feasible) solutions (the SSGA was better than the GRGA, but still not satisfactory). <p> The advantages of ROW relative to a best-improving 1-opt heuristic we also implemented <ref> [43] </ref> are its ability to make moves in large neighborhoods such as when 42 jr i j &gt; 1, its willingness to move downhill to escape infeasibilities, and the random-ness introduced by the first-improving strategy. Even with ROW we detected a convergence in the population after some period of time.
Reference: [44] <author> G. Liepins and S. Baluja. apGA: </author> <title> An Adaptive Parallel Genetic Algorithm. </title> <type> Technical report, </type> <institution> Oak Ridge National Laboratory, </institution> <year> 1991. </year>
Reference-contexts: Maximum speedups in the range of 25-27 were obtained on 40-72 processors. The incremental improvement in speedup was slightly sublinear up to about 16-20 processors, but then fell off quickly. Liepens and Baluja <ref> [44] </ref> used a parallel GA with a central processor phase. In parallel, 15 subpopulations of ten strings each run a GA on their own subpopulations. Next, during the central processor phase, the most fit string from each subpopulation is gathered along with an additional 15 randomly generated strings.
Reference: [45] <author> G. Marsaglia, A. Zaman, and W. Tseng. </author> <title> Stat. </title> <journal> Prob. Letter, </journal> <volume> 9(35), </volume> <year> 1990. </year>
Reference-contexts: A number of statistical calculations, not part of the algorithm but used for periodic report writing, are handled by collective (global) operations. Random number generation was done using an implementation of the universal random number generator proposed by Marsaglia, Zaman, and Tseng <ref> [45] </ref>, and translated to C from James' version [38]. Each time a parallel run was made, all sub-populations were randomly seeded. This was done by having processor zero get and broadcast the microsecond portion of the Unix gettimeofday system call. <p> Each processor then added its processor id to the value returned by the Unix gettimeofday and used this unique value as its random number seed. For the random number generator in <ref> [45] </ref> each unique seed gives rise to an independent sequence of random numbers of size 10 30 [38]. 3.4 Test Problems To test the parallel genetic algorithm we selected a subset of forty problems from the Hoffman and Padberg test set [36].
Reference: [46] <author> R. Marsten. </author> <title> An Algorithm for Large Set Partitioning Problems. </title> <journal> Management Science, </journal> <volume> 20 </volume> <pages> 774-787, </pages> <year> 1974. </year>
Reference-contexts: The following notation is common in the literature <ref> [24, 46] </ref> y and motivates the name "set partitioning problem." Let I = f1; : : : ; mg be a set of row indices, J = f1; : : : ; ng a set of column indices, and P = fP 1 ; : : : ; P n g, <p> The operations research (OR) literature contains numerous references to the airline crew scheduling problem <ref> [2, 3, 4, 7, 25, 36, 46, 47] </ref>. Estimates of over a billion dollars a year for pilot and flight attendant expenses have been reported [1, 7]. Even a small improvement over existing solutions can have a large economic benefit. At one time solutions to the SPP were generated manually. <p> However, in recent years it has been noted that as SPP problems grow in size, fractional solutions occur more frequently, and simply rounding or performing a "small" branch-and-bound tree search may not be effective [2, 7, 25]. Marsten <ref> [46] </ref> noted twenty years ago that for most algorithms in use at that time, solving the linear programming relaxation to the SPP was the computational bottleneck. This is because the LP relaxation is highly degenerate. <p> One of the oldest exact methods is implicit enumeration. In this method partial solutions are generated by taking the columns one at a time and exploring logical implications of their assignments. Both Garfinkel and Nemhauser [24] and Marsten <ref> [46] </ref> developed implicit enumeration algorithms. Another traditional method is the use of cutting planes (additional constraints) in conjunction with the simplex method. Balas and Padberg [6] note that cutting plane algorithms were moderately successful even while using general-purpose cuts and not taking advantage of the shape of the SPP polytope.
Reference: [47] <author> R. Marsten and F. Shepardson. </author> <title> Exact Solution of Crew Scheduling Problems Using the Set Partitioning Model: Recent Successful Applications. </title> <journal> Networks, </journal> <volume> 11 </volume> <pages> 165-177, </pages> <year> 1981. </year>
Reference-contexts: The operations research (OR) literature contains numerous references to the airline crew scheduling problem <ref> [2, 3, 4, 7, 25, 36, 46, 47] </ref>. Estimates of over a billion dollars a year for pilot and flight attendant expenses have been reported [1, 7]. Even a small improvement over existing solutions can have a large economic benefit. At one time solutions to the SPP were generated manually. <p> Even a small improvement over existing solutions can have a large economic benefit. At one time solutions to the SPP were generated manually. However, airline crew scheduling problems have grown significantly in size and complexity. In 1981 problems with 400 rows and 30,000 columns were described as "very large" <ref> [47] </ref>. Today, problems with hundreds of thousands of columns are "very large," and one benchmark problem has been generated with 837 rows and 12,753,313 columns [9]. 1.1.3 Previous Algorithms. <p> In the LP relaxation, the integrality restriction on x j is relaxed, but the lower and upper bounds of zero and one are kept. A number of authors <ref> [7, 25, 47] </ref> have noted that for "small" SPP problems the solution to the LP relaxation is either all integer, in which case it is also the optimal integer solution, or has only a few fractional values that are easily resolved.
Reference: [48] <author> H. Muhlenbein. </author> <title> Parallel Genetic Algorithms and Combinatorial Optimization. </title> <editor> In O. Balci, R. Sharda, and S. Zenios, editors, </editor> <booktitle> Computer Science and Operations Research, </booktitle> <pages> pages 441-456. </pages> <publisher> Pergamon Press, </publisher> <year> 1992. </year>
Reference-contexts: In the TSP, since all cities are connected to all other cities, it is relatively easy to `fix up" an offspring that contains either an invalid tour or a partial tour, by adding missing cities and removing duplicate cities. As an example, Muhlenbein <ref> [48] </ref> uses a specialized crossover operator for the TSP called the maximal preservative crossover operator (MPX). The idea is to retain as many valid edges from the parent strings as possible. MPX works by randomly selecting an arbitrary length string from one of the parents to initialize the offspring. <p> In the FPGA the model is of one population in which the strings have only local interactions and neighborhoods, as opposed to global ones. Choices in an FPGA include neighborhood size, processor connection topology, and string replacement scheme. Muhlenbein <ref> [48] </ref> applied an FPGA to the traveling salesperson problem and the graph partitioning problem. Each string selected a mate from within a small neighborhood of its own processor. Within its neighborhood each processor performed selection, crossover, and mutation without any central control. <p> Alternatively, we can also make the first move found that improves the current solution. We refer to these two choices as best-improving and first-improving, respectively. The experimental evidence of many researchers <ref> [15, 39, 40, 48] </ref> is that hybridizing a genetic algorithm with a local search heuristic is beneficial. It combines the GAs ability to widely sample a search space with a local search heuristic's hill-climbing ability. There are, however, theoretical objections to the use of a local search heuristic.
Reference: [49] <author> G. Nemhauser and L. Wolsey. </author> <title> Integer and Combinatorial Optimization. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: Current real-world SPP problems have been generated of almost arbitrary length. Even many smaller problems have posed significant difficulties for traditional methods. Also, in the general case, just finding a feasible solution to the SPP is NP-complete <ref> [49] </ref>. We wished to see how well a GA could perform on such a problem. We also wished to identify characteristics of SPP problems that were hard for a genetic algorithm. The SPP is both tightly constrained and, in many cases, very large. <p> In the GA approach, however, the GA operators often produce infeasible solutions. In fact, since just finding a feasible solution to the SPP is NP-complete <ref> [49] </ref>, it may be that many or most strings in the population are infeasible. Therefore, we need an evaluation function that takes into account the degree of infeasibility of the string.
Reference: [50] <author> R. Parker and R. Rardin. </author> <title> Discrete Optimization. </title> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1988. </year>
Reference-contexts: Whenever the neighboring solution is better than the current solution, it replaces the current solution. When no better neighbor solution can be found, the search terminates. Parker and Rardin <ref> [50] </ref> describe two important neighborhoods. In the k-change neighborhood, up to k bits are complemented at a time. In the k-interchange neighborhood, up to k bits are changed at a time, but in a complementary manner.
Reference: [51] <author> C. Pettey, M. Leuze, and J. Grefenstette. </author> <title> A parallel genetic algorithm. </title> <editor> In J. Grefenstette, editor, </editor> <booktitle> Proceedings of the Second International Conference on Genetic Algorithms and Their Applications, </booktitle> <pages> pages 155-161, </pages> <address> Hillsdale, New Jersey, 1987. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: The best results were found with a "medium size" neighborhood and a local population of ten strings. Pettey, Leuze, and Grefenstette <ref> [51] </ref> ran a CPGA on an Intel iPSC hypercube. Each generation each processor sent its best strings to each neighbor and received its neighbor's best strings. These were then inserted into each processor's subpopulation by using a replacement scheme.
Reference: [52] <author> J. Pierce. </author> <title> Application of Combinatorial Programming to a Class of All-Zero-One Integer Programming Problems. </title> <journal> Management Science, </journal> <volume> 15 </volume> <pages> 191-209, </pages> <year> 1968. </year>
Reference-contexts: A useful initial step is the ordering of the SPP matrix into block "staircase" form <ref> [52] </ref>. Block B i is the set of columns that have their first one in row i. B i is defined for all rows but may be empty for some. Within B i the columns are sorted in order of increasing c j .
Reference: [53] <author> D. Powell and M. Skolnick. </author> <title> Using genetic algorithms in engineering design optimization with non-linear constraints. </title> <editor> In S. Forrest, editor, </editor> <booktitle> Proceedings of the Fifth International Conference on Genetic Algorithms, </booktitle> <pages> pages 424-431, </pages> <address> San Mateo, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The severity of their penalty varies and depends on the best solution and best feasible solution found so far. Their intent is to favor solutions that are near feasibility over solutions that are more fit but less feasible. 8 In conjunction with rank-based selection, Powell and Skolnick <ref> [53] </ref> scale the ob-jective function for their problem so that all the feasible points always have higher fitness than the infeasible points. This approach avoids difficulties with choosing an appropriate penalty function, but still allows infeasible solutions into the population. 1.3.2 Parallel Genetic Algorithms. <p> For three of those, and several others for which optimal solutions were found but with degraded performance, the penalty function was not strong enough. A number of possibilities exist for additional research in this area, including stronger penalty terms (e.g., quadratic), the ranking approach of Powell and Skolnick <ref> [53] </ref>, and revisiting the ST penalty term for which we had mixed results. However, for the aa problems, we are less optimistic. Table 3.10 appears to indicate diminishing returns with respect to the reduction in infeasibilities in these problems as additional subpopulations are added to the computation.
Reference: [54] <author> N. Radcliffe. </author> <title> Private communication, </title> <year> 1993. </year>
Reference-contexts: These two parent strings then recombine to produce an offspring. A variation of binary tournament selection is probabilistic binary tournament selection where the more fit string is selected with a probability p b , :5 p b &lt; 1. <ref> [54] </ref> Probabilistic binary tournament selection does allow for the possibility that the best string in the population may be lost. Its advantage is a reduction in the selective pressure. Table 2.11 contains the results comparing SUS to tournament selection using the SSGAROW.
Reference: [55] <author> J. Richardson, M. Palmer, G. Liepins, and M. Hilliard. </author> <title> Some Guidelines for Genetic Algorithms with Penalty Functions. </title> <editor> In J. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 191-197, </pages> <address> San Mateo, 1989. </address> <publisher> Morgan Kaufmann. </publisher> <pages> 75 </pages>
Reference-contexts: A generic evaluation function is of the form c (x) + p (x); where c (x) is a cost term (often the objective function of the problem of interest) and p (x) is a penalty term. Richardson et al. <ref> [55] </ref> provide advice and experimental results for constructing penalty functions. The authors suggest not making the penalty too harsh, since infeasible solutions contain information that should not be ignored. <p> If the penalty term is too harsh, infeasible strings that carry useful information but lie outside the feasible region will be ignored and their information lost. If the penalty term is not strong enough, the GA may search only among infeasible strings <ref> [55] </ref>. We investigated three penalty terms. The countinfz penalty term is m X i i (x); (2.2) where i (x) = 1 if constraint i is infeasible, 0 otherwise. 28 The countinfz penalty term indicates whether a constraint is infeasible, but does not measure the magnitude of the infeasibility. <p> In Equation (2.2) (and Equation (2.3) below), i is a scalar weight that penalizes the violation of constraint i. Choosing a suitable value for i is a difficult problem. In <ref> [55] </ref> Richardson et al. studied the choice of i for the set covering problem (SCP). In the SCP, the equality in Equation (1.2) is replaced by a constraint. <p> We know of no method to calculate an optimal value for i . Therefore, we made the empirical choice of i = max j fc j jj 2 R i g. This choice is similar to the "P2" penalty in <ref> [55] </ref>, where it provided an upper bound on the cost to satisfy the violated constraints of the SCP.
Reference: [56] <author> W. Siedlecki and J. Sklansky. </author> <title> Constrained genetic optimization via dynamic reward-penalty balancing and its use in pattern recognition. </title> <editor> In J. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 141-150, </pages> <address> San Mateo, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Using a similar argument, they note that a single, one-bit mutation can produce the optimal solution from an infeasible one. They suggest that the cost of the penalty term reflect the cost of making an infeasible solution into a feasible one. Siedlecki and Sklansky <ref> [56] </ref> use a dynamically calculated penalty coefficient in a GA applied to a pattern recognition problem. Two interesting properties of their problem are that (1) the minimum occurs on a boundary point of the feasible region, and (2) the penalty function is monotonically growing.
Reference: [57] <author> A. Smith and D. Tate. </author> <title> Genetic optimization using a penalty function. </title> <editor> In S. Forrest, editor, </editor> <booktitle> Proceedings of the Fifth International Conference on Genetic Algorithms, </booktitle> <pages> pages 499-505, </pages> <address> San Mateo, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: They observe that the GA tends to "exploit" the penalty term by concentrating its search in a particular part of the search space, willingly incurring a small penalty if the scalar multiplier of the penalty term is not too large. Smith and Tate <ref> [57] </ref> suggest a dynamic penalty function for highly constrained problems. They apply this to the unequal area facility layout problem. The severity of their penalty varies and depends on the best solution and best feasible solution found so far. <p> ST penalty term (<ref> [57] </ref>) is m X ( i (x)=2) [z feas z best ] : (2.4) Here, z feas is the best feasible objective function value found so far, and z best is the best objective function value (feasible or infeasible) found so far. According to Smith and Tate [57] : : : the explicit goal of our penalty function is to favor solutions which are near a feasible solution over more highly-fit solutions which are far from any feasible solution. 29 Following Smith and Tate, we used a distance-from-feasibility metric which was de-pendent on the number of violated constraints,
Reference: [58] <author> W. Spears and K. DeJong. </author> <title> An Analysis of Multi-Point Crossover. </title> <editor> In G. Rawlins, editor, </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <pages> pages 301-315. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, </address> <year> 1991. </year>
Reference-contexts: Their results show that uniform crossover is better than two-point crossover for smaller values of n and for smaller values of the population size N . In <ref> [58] </ref>, however, Spears and DeJong note just the opposite effect as both n and N increase: This suggests a way to understand the role of multi-point crossover.
Reference: [59] <author> W. Spears and K. DeJong. </author> <title> On the virtues of parameterized uniform crossover. </title> <editor> In R. Belew and L. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 230-236. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: The bit-string is then complemented and the process repeated to create the second child string. Spears and DeJong <ref> [59] </ref> and Syswerda [61] give evidence to support the claim that uniform crossover has a better recombination potential|the ability to combine smaller building blocks into larger ones|than do other crossover operators. Testing by Syswerda showed that uniform crossover performed significantly better than one-or two-point crossover on most problems. <p> Trials Opt. Trials Opt. Trials nw41 24 142 24 141 26 142 nw40 5 142 8 142 6 143 nw15 25 140 22 140 21 141 nw33 3 141 1 143 3 100 nw18 0 143 0 141 0 22 Spears and DeJong <ref> [59] </ref> suggest parameterizing uniform crossover with a parameter p u that is the probability of swapping two parents bit values.
Reference: [60] <author> T. Starkweather, D. Whitley, and K. Mathias. </author> <title> Optimization Using Distributed Genetic Algorithms. </title> <editor> In H. Schwefel and R. Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature, </booktitle> <pages> pages 176-185, </pages> <address> New York, 1991. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Each processor generated extra offspring during a migration generation and selected migrants uniformly from among the "overfull" population. Often the partitioned GA found fitter strings than the CPGA with migration. Best results were achieved with a migration rate such as 20% of each subpopulation migrating every 20 iterations. In <ref> [60] </ref> Starkweather, Whitley, and Mathias describe another CPGA. Each processor sent copies of its best strings to one of its neighbors, which replaced its worst string with these.
Reference: [61] <author> G. Syswerda. </author> <title> Uniform crossover in genetic algorithms. </title> <editor> In J. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 2-9, </pages> <address> San Mateo, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The second, the steady-state genetic algorithm (SSGA), replaces only one or two strings each generation and is a more recent development <ref> [61, 66, 69] </ref>. In the GRGA the entire population is replaced each generation by their offspring. The hope is that the offspring of the best strings carry the important "building blocks" [26] from the best strings forward to the next generation. <p> Two-point block crossover can, however, still introduce infeasibilities into other blocks. 2.4.6.3 Uniform Crossover. One way to think of uniform crossover is as randomly generating a bit-mask that indicates from which parent string to take the next bit when creating the offspring <ref> [61] </ref>. Figure 2.10 illustrates uniform crossover. Starting with two parent strings of length n = 8, the bit-mask 01101001 is randomly generated. <p> The bit-string is then complemented and the process repeated to create the second child string. Spears and DeJong [59] and Syswerda <ref> [61] </ref> give evidence to support the claim that uniform crossover has a better recombination potential|the ability to combine smaller building blocks into larger ones|than do other crossover operators. Testing by Syswerda showed that uniform crossover performed significantly better than one-or two-point crossover on most problems. <p> However, with larger populations, less disruptive crossover operators (twopoint) are more likely to work better, as suggested by the theoretical analysis. Syswerda <ref> [61] </ref> notes that uniform crossover replaces the need for the inversion operator. Inversion moves bits around so that related sets of bits are less likely to 38 be disrupted and more likely to be grouped with similar bit groupings.
Reference: [62] <author> R. Tanese. </author> <title> Parallel genetic algorithms for a hypercube. </title> <editor> In J. Grefenstette, editor, </editor> <booktitle> Proceedings of the Second International Conference on Genetic Algorithms and Their Applications, </booktitle> <pages> pages 177-183, </pages> <address> Hillsdale, New Jersey, 1987. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: Processors exchange strings from their subpopulation with other processors. Some important choices in a CPGA are which other processors a processor exchanges strings with, how often processors exchange strings, how many strings processors exchange with each other, and what strategy is used when selecting strings to exchange. Tanese <ref> [62] </ref> applied a CPGA to the optimization of Walsh-like functions using a 64-processor Ncube computer. Periodically, fit strings were selected and sent to neighboring processors for possible inclusion in their future generations. Exchanges took place only among a processor's neighbors in the hypercube.
Reference: [63] <author> R. Tanese. </author> <title> Distributed genetic algorithms. </title> <editor> In J. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 434-440, </pages> <address> San Mateo, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In most cases Tanese's main metric, the average of which generation the global maximum was found on, preferred eight as the optimal number of subpopulations. Tanese also experimented with variable mutation and crossover rates among the subpopulations and found these results at least as good as earlier results. In <ref> [63] </ref> Tanese experimented with the partitioned genetic algorithm (a CPGA with no migration between processors allowed). A total population size of 256 was partitioned into various power-of-two subpopulation sizes.
Reference: [64] <author> D. Tate and A. Smith. </author> <title> Expected allele coverage and the role of mutation in genetic algorithms. </title> <editor> In S. Forrest, editor, </editor> <booktitle> Proceedings of the Fifth International Conference on Genetic Algorithms, </booktitle> <pages> pages 31-37, </pages> <address> San Mateo, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: One possibility is to use an adaptive mutation rate that changes based on the value of some GA statistic such as population diversity or the Hamming distance between two parent strings [68]. Several researchers <ref> [14, 64] </ref> make the case for a high mutation rate when mutation is separated from crossover, as it is in our implementation. <p> A high mutation rate may also be more successful in an SSGA since, although it may disrupt important schemata in the offspring, those schemata remain intact in the parent strings that remain in the population <ref> [64] </ref>. We found that the random choice of variables to add or delete to the current string that the ROW heuristic made when constraints were infeasible helped the GA sample new areas of the search space. However, when all constraints are feasible, ROW no longer introduces any randomness.
Reference: [65] <author> G. von Laszewsski and H. Muhlenbein. </author> <title> Partitioning a graph with a parallel genetic algorithm. </title> <editor> In H. Schwefel and R. Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature, </booktitle> <pages> pages 165-169, </pages> <address> Berlin, 1991. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Otherwise, the next city in one of the parent strings is added. The aim of MPX is to preserve as much of the parent's subtours as possible. 7 Von Laszewsski and Muhlenbein <ref> [65] </ref> define a structural crossover operator for the graph partitioning problem that copies whole partitions from one solution to another. <p> The topology used was a two-dimensional circular ladder with two strings per "step." A neighborhood size of eight was used by each string. Some overlap occurred among neighborhoods, enabling fit strings to propagate through the population. In <ref> [65] </ref> an FPGA was applied to the graph partitioning problem. Strings were mapped to a 64-processor transputer system. Selection was done independently by each string within a small neighborhood of the two-dimensional population structure.
Reference: [66] <author> D. Whitley. </author> <title> The GENITOR algorithm and selection pressure: Why rank-based allocation of reproductive trials is best. </title> <editor> In J. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 116-121, </pages> <address> San Mateo, 1989. </address> <publisher> Morgan Kaufmann. </publisher> <pages> 76 </pages>
Reference-contexts: Whitley notes <ref> [66] </ref>: Many of the various parameters that are used to "tune" genetic search are really indirect means of affecting selective pressure and population diversity. As selective pressure is increased, the search focuses on the top individuals in the population, but because of this "exploitation" genetic diversity is lost. <p> The second, the steady-state genetic algorithm (SSGA), replaces only one or two strings each generation and is a more recent development <ref> [61, 66, 69] </ref>. In the GRGA the entire population is replaced each generation by their offspring. The hope is that the offspring of the best strings carry the important "building blocks" [26] from the best strings forward to the next generation. <p> For the SPP this requires a mapping from the evaluation function to the fitness function. As has been pointed out, however, the evaluation function value itself is not an "exact" measure of fitness <ref> [66] </ref>. The mapping from the evaluation function to the fitness function "should be considered a design parameter of the genetic algorithm, not a feature of the optimization problem" [31]. In general, the fitness function is given by u (x) = g (f (x)). <p> Our choice of b (t) is intended to interfere with the selective pressure as little as possible, while still converting the minimization of f into the maximization of u. We also tested a linear rank fitness function <ref> [5, 66] </ref> given by u (x) = M in + (M ax M in) rank (x; t) 1 N 1 where rank (x; t) is the index of x in a list sorted in order of decreasing evaluation function value.
Reference: [67] <author> D. Whitley. </author> <title> An executable model of a simple genetic algorithm. </title> <editor> In D. Whitley, editor, </editor> <booktitle> Foundations of Genetic Algorithms -2-, </booktitle> <pages> pages 45-62. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, </address> <year> 1993. </year>
Reference-contexts: First, it allows the distribution and sharing of above average schemata via the strings that migrate. This serves to increase the overall selective pressure since additional reproductive trials are allocated to those strings that are fit enough to migrate <ref> [67] </ref>. At the same time, the introduction of migrant strings into the local population helps to maintain genetic diversity, since the migrant string arrives from a different sub-population which has evolved independently.
Reference: [68] <author> D. Whitley and T. Hanson. </author> <title> Optimizing neural networks using faster, more accurate genetic search. </title> <editor> In J. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 391-396, </pages> <address> San Mateo, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: One possibility is to use an adaptive mutation rate that changes based on the value of some GA statistic such as population diversity or the Hamming distance between two parent strings <ref> [68] </ref>. Several researchers [14, 64] make the case for a high mutation rate when mutation is separated from crossover, as it is in our implementation.
Reference: [69] <author> D. Whitley and J. Kauth. </author> <title> GENITOR: A different genetic algorithm. </title> <booktitle> In Rocky Mountain Conference on Artificial Intelligence, </booktitle> <pages> pages 118-130, </pages> <address> Denver, </address> <year> 1988. </year> <month> 77 </month>
Reference-contexts: The second, the steady-state genetic algorithm (SSGA), replaces only one or two strings each generation and is a more recent development <ref> [61, 66, 69] </ref>. In the GRGA the entire population is replaced each generation by their offspring. The hope is that the offspring of the best strings carry the important "building blocks" [26] from the best strings forward to the next generation.
References-found: 69

