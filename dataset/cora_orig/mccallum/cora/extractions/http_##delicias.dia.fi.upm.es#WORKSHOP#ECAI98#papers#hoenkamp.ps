URL: http://delicias.dia.fi.upm.es/WORKSHOP/ECAI98/papers/hoenkamp.ps
Refering-URL: http://delicias.dia.fi.upm.es/WORKSHOP/ECAI98/papers.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: (hoenkamp@acm.org)  
Title: Spotting Ontological Lacunae through Spectrum Analysis of Retrieved Documents  
Author: E. Hoenkamp 
Affiliation: Nijmegen Institute for Cognition and Information (NICI)  
Abstract: The world-wide-web has produced a potentially unlimited flow of information of varying quality, the so-called "information overload". Information filters have been designed in hopes of letting only the relevant part be delivered to the user. Such filters require that the user formulate a more or less stable information need(s. Often, however, an `anomalous state of knowledge' occurs: the user needs information but is not aware of this need. With the rapid growth of information available on-line, it is likely that this need could be filled, if only there were a system to detect it on the user's behalf. As part of our project involving ontology based proactive information filtering ('Profile'), we designed such a system. It consists of: (1) an ontology in which a user's more or less stable information need is represented, (2) WordNet, to translate concepts in the ontology into a `spectrum' of keywords, and (3) a component to analyze the spectrum of a set of retrieved documents (e.g. through latent semantic indexing). The two spectra are compared, and if a mismatch is found, the latter spectrum is fed back through WordNet to the ontology component. We show an example of how this mechanism leads to the detection of an anomalous state of knowledge, resulting in a new concept to augment the ontology. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ali, S. </author> <year> (1993). </year> <title> Subject relationship between articles determined by cooccurrence of keywords in citing and cited titles. </title> <journal> Journal of Information Science, </journal> <volume> 19 (3), </volume> <pages> 225-231. </pages>
Reference-contexts: The latter, so-called `vocabulary problem' appears in two ways: (1) articles (or web pages) about the same subject may have very few keywords in common <ref> (Ali, 1993) </ref>, and (2) when experts were asked to describe objects in their domain, chances were less than 20% that they used the same wording (Furnas, Landauer, Gomez, & Du-mais, 1987). The LSI approach seems to ameliorate this situation.
Reference: <author> Avgerinos, A., & Theofilos, T. </author> <year> (1995). </year> <title> A Linguistic Approach in Information Retrieval. </title> <type> Master's thesis, </type> <institution> University of Nijmegen, the Netherlands. </institution>
Reference: <author> Banerjee, S., & Mittal, V. </author> <year> (1994). </year> <title> On the use of linguistic ontologies for accessing and indexing distributed digital libraries. </title> <booktitle> In Proceedings of the First Annual Conference on the Theory and Practice of Digital Libraries. </booktitle> <address> Retrieved June 1997 from WWW, http://abgen.cvm.tamu.edu/DL94. </address>
Reference-contexts: It does not exclude the `speed high train' hit, however. One approach to this problem is to first retrieve documents using the original search string, and when this results in too many hits, suggesting to the user several alternatives for the keywords. One source for these suggestions (e.g. <ref> (Banerjee & Mittal, 1994) </ref>) is WordNet. WordNet is an on-line lexical reference system for use under program control. English nouns, verbs, adjectives and adverbs are organized into synonym sets 2 , each representing one underlying lexical concept (Miller, 1995). WordNet contains about 120,000 word forms and 90,000 word senses.
Reference: <author> Belkin, N. J., & Kwasnik, B. H. </author> <year> (1986). </year> <title> Using structural representations of anomalous states of knowledge for choosing document retrieval strategies. </title> <booktitle> In Proc. of the 9th International Conference on Research and Development in Information Retrieval (pp. </booktitle> <pages> 11-22). </pages> <publisher> ACM. </publisher>
Reference-contexts: The examples above illustrate the opposite situation: information exists somewhere, but users do not know they need it. This is an example of a so-called anomalous state of knowledge <ref> (Belkin & Kwasnik, 1986) </ref>: the users don't know they don't know.
Reference: <author> Borko, H., & Bernick, M. D. </author> <year> (1963). </year> <title> Automatic document classification. </title> <journal> Journal of the ACM, </journal> <volume> 10, </volume> <pages> 151-162. </pages>
Reference-contexts: One direction is to compute the correlation coefficients be 2 tween documents based on their word-coordinates and then perform a factor analysis <ref> (Borko & Bernick, 1963) </ref>. In this fashion, the initially high dimension (the number of words) may be reduced, and the factors thus represent some underlying structure in the collection of documents. A related direction is to find a new basis for the document space by applying principle component analysis.
Reference: <author> Croft, W., B. </author> <year> (1995). </year> <title> Effective text retrieval based on combining evidence from the corpus and users. </title> <journal> IEEE Expert, </journal> <volume> 10 (6), </volume> <pages> 59-63. </pages>
Reference: <author> Farquhar, A., Fikes, R., Pratt, W., & Rice, J. </author> <year> (1997). </year> <title> Collaborative ontology construction for information integration (Tech. </title> <institution> Rep.). Knowledge System Laboratory, Stanford. </institution> <note> Retrieved May 1997 from WWW, http://ontolingua.nici.kun.nl/. </note>
Reference-contexts: To implement the ontology, we run a mirror 4 of the ontology server developed at the Stanford Knowledge Systems Laboratory. The server supplies us with many of the tools that we need to implement our project <ref> (Farquhar, Fikes, Pratt, & Rice, 1997) </ref>.
Reference: <author> Furnas, G., Landauer, T., Gomez, L., & Dumais, S. </author> <year> (1987). </year> <title> The vocabulary problem in human-system communication. </title> <journal> Communications of the ACM, </journal> <volume> 30, </volume> <pages> 964-971. </pages>
Reference-contexts: The latter, so-called `vocabulary problem' appears in two ways: (1) articles (or web pages) about the same subject may have very few keywords in common (Ali, 1993), and (2) when experts were asked to describe objects in their domain, chances were less than 20% that they used the same wording <ref> (Furnas, Landauer, Gomez, & Du-mais, 1987) </ref>. The LSI approach seems to ameliorate this situation. The problems that go with a purely linguistic approach were recognized in the Profile project since its inception. Part of that project therefore concentrates on ways to represent the user's information need on the conceptual level.
Reference: <author> Hoenkamp, E. </author> <year> (1997). </year> <title> Semantic expansion for proactive information filtering. </title> <booktitle> In Proc. of the 19th Annual Conference of the Cognitive Science Society (p. </booktitle> <volume> 951). </volume> <publisher> Ablex. </publisher>
Reference: <author> Hoenkamp, E., Schomaker, L., van Bommel, P., Koster, C., & van der Weide, T. </author> <year> (1996). </year> <title> Profile A Proactive Information Filter (Tech. </title> <type> Rep. No. 9602). </type> <institution> Computer Science Institute, University of Nijmegen, the Nether-lands. </institution>
Reference: <author> Landauer, T. K., & Dumais, S. T. </author> <year> (1997). </year> <title> A solution to plato's problem: the latent semantic analysis theory of acquisition, induction and representation of knowledge. </title> <journal> Psychological Review, </journal> <volume> 104 (2), </volume> <pages> 211-240. </pages>
Reference-contexts: A related direction is to find a new basis for the document space by applying principle component analysis. Especially noteworthy is the newer so-called `latent for the phrase `high-speed trains' reveals clusters of interconnected concepts. semantic indexing' or LSI <ref> (Landauer & Dumais, 1997) </ref>, which seems successful in capturing the content underlying the documents. These techniques represent the mappings they employ (e.g. derived from the word to document mapping) in terms of the mapping's eigenvalues (privileging the larger values). <p> on the conceptual level (i.e. not, or only partially, verbalized), * the intended information sources can only be retrieved using variations on lexical items * the burden is on the user to find lexical material that adequately expresses the conceptual level. 3 The spectrum was derived through `single value decomposition' <ref> (Landauer & Dumais, 1997) </ref>, followed by cluster analysis on the basis of correlations.
Reference: <author> Lenat, D. </author> <year> (1995). </year> <title> Cyc: A large-scale investment in knowledge infrastructure. </title> <journal> Communications of the ACM, </journal> <volume> 38 (11), </volume> <pages> 33-38. </pages>
Reference-contexts: Fortunately we are not confronted with the daunting task that Cyc aspires to, namely to codify all everyday objects and actions. We borrow, however, the concept of microtheory, representing a particular domain of knowledge <ref> (Lenat, 1995) </ref>. In our `high-speed train' figure 1. example, the user model is comparable to a microtheory about transportation including environmental impact of vehicles. Users are characterized by their microtheories. These can differ in several respects: * Users differ in their factual knowledge about a domain.
Reference: <author> Miller, G. </author> <year> (1995). </year> <title> Wordnet: A lexical database for english. </title> <journal> Communications of the ACM, </journal> <volume> 38 (11), </volume> <pages> 39-41. </pages>
Reference-contexts: One source for these suggestions (e.g. (Banerjee & Mittal, 1994)) is WordNet. WordNet is an on-line lexical reference system for use under program control. English nouns, verbs, adjectives and adverbs are organized into synonym sets 2 , each representing one underlying lexical concept <ref> (Miller, 1995) </ref>. WordNet contains about 120,000 word forms and 90,000 word senses. The relationship between the two is depicted in table 1.
Reference: <author> Rosch, E., Mervis, C., Gray, W. D., Johnson, D., & Boyes-Bream, P. </author> <year> (1976). </year> <title> Basic objects in natural categories. </title> <journal> Cognitive Psychology, </journal> <volume> 8, </volume> <pages> 382-439. </pages>
Reference-contexts: For example, we found it useful to have an extra iteration of retrieval before the feedback from WordNet to the ontology occurs. In the case of our 5 For a related project about retrieving pictures, we chose words of the nearest `basic category' <ref> (Rosch, Mervis, Gray, Johnson, & Boyes-Bream, 1976) </ref> because that allowed us to connect words and shapes 4 running example, the spectrum also highlighted words such as `Hopfield network', and `backpropagation'. This could be traced to the interpretation of `train' as a verb, as it pertains to neural networks.
Reference: <author> Salton, G. </author> <year> (1988). </year> <title> Automatic text processing: the transformation, analysis and retrieval of information by computer. </title> <address> Reading, Mass.: </address> <publisher> Addison-Wesley. </publisher> <pages> 5 </pages>
Reference-contexts: Some systems take larger structures than phrases. `Spectrum analysis' of documents First, let me briefly digress for the user with little background in information retrieval. At the heart of most search engines lies the vector space model <ref> (Salton, 1988) </ref>, where documents consist of vectors (or points) in a space and words are the coordinates. Stated differently, the values (`weights') on these word-coordinates are mapped to documents. For such a mapping to be successful, two related documents have to be located near each other in the vector space.
References-found: 15

