URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-407.ps.Z
Refering-URL: http://www.cs.gatech.edu/computing/classes/cs7322_98_spring/readings.html
Root-URL: 
Email: brand,nuria,sandy@media.mit.edu  
Title: Coupled hidden Markov models for complex action recognition  
Author: Matthew Brand, Nuria Oliver, and Alex Pentland 
Address: Cambridge, MA 02139, USA  
Affiliation: Vision and Modeling Group, MIT Media Lab  
Abstract: c flMIT Media Lab Perceptual Computing / Learning and Common Sense Technical Report 407 20nov96 Abstract We present algorithms for coupling and training hidden Markov models (HMMs) to model interacting processes, and demonstrate their superiority to conventional HMMs in a vision task classifying two-handed actions. HMMs are perhaps the most successful framework in perceptual computing for modeling and classifying dynamic behaviors, popular because they offer dynamic time warping, a training algorithm, and a clear Bayesian semantics. However, the Markovian framework makes strong restrictive assumptions about the system generating the signalthat it is a single process having a small number of states and an extremely limited state memory. The single-process model is often inappropriate for vision (and speech) applications, resulting in low ceilings on model performance. Coupled HMMs provide an efficient way to resolve many of these problems, and offer superior training speeds, model likelihoods, and robustness to initial conditions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Azarbayejani and A. Pentland. </author> <title> Real-time self-calibrating stereo person-tracker using 3-D shape estimation from blob features. </title> <booktitle> In Proceedings, International Conference on Pattern Recognition, </booktitle> <address> Vienna, </address> <month> August </month> <year> 1996. </year> <note> IEEE. </note>
Reference-contexts: A simple way to decompose upper-body gestures is to treat each arm as a process. The arms are neither independent nor wholly mutually determined; some form of interactional modeling is appropriate. 4.1. Data collection and preprocessing Using a self-calibrating stereo blob tracker <ref> [1] </ref>, we obtained 3D hand tracking data for three T'ai Chi gestures involving arm-motions: the left 1 single whip, the left cobra, and the left brush knee. Figure 4.1 illustrates the gestures, the blob-tracking, and the feature vectors. We collected 52 sequences, roughly 17 of each gesture.
Reference: [2] <author> M. Brand. </author> <title> Coupled hidden markov models for modeling interacting processes. Forthcoming (under review), </title> <month> November </month> <year> 1996. </year> <note> Also available as MIT Media Lab Vision and Modeling TR #405. </note>
Reference-contexts: The linked HMM excepted, these algorithms use mean-field approximations from statistical mechanics. Appears in Proceedings of CVPR97, San Juan, PR. BRAND, OLIVER, PENTLAND We present an algorithm for coupling two HMMs with causal (temporal), possibly asymmetric influences. Theoretical and empirical arguments for this architecture's advantages can be found in <ref> [2] </ref>. <p> Here we introduce a coupling algorithm is based on projections between component HMMs and a joint HMM; while performing the experiments described below we also perfected an algorithm with superior performance and complexity, based on an approximation to dynamic programming. Both algorithms are detailed in <ref> [2] </ref>; here we will describe the inferior algorithm because that is the basis of of the empirical focus of this paper. We note that in principle it is also possible to derive an approximation algorithm in the mean field framework or an exact algorithm using junction-tree representations [6]. <p> Because it has O (N 2 ) rather than O (N 4 ) free parameters, it also requires substantially less data for training, thus ameliorating a bottleneck often faced by HMM modelers. A newer algorithm in <ref> [2] </ref> preserves all these advantages and also offers substantially lower complexity. 4. Experiments T'ai Chi Ch'uan is a Chinese martial art and meditative exercise, consisting of stylized full-body and upper-body 2 COUPLED HMMS FOR ACTION RECOGNITION gestures.
Reference: [3] <author> M. Brand. </author> <title> The Inverse Hollywood Problem: From video to scripts and storyboards via causal analysis. </title> <booktitle> In Proceedings, </booktitle> <address> AAAI97, </address> <year> 1997. </year>
Reference-contexts: This accounts for some of the robustness the CHMMs achieve despite unusually small training samples; it is demonstrated more emphatically in another project where CHMMs are used to identify complex actions in video from the varying spatial relations between hands, tools, and objects <ref> [3] </ref>. 5 BRAND, OLIVER, PENTLAND respectively. The CHMM produces the most likely models with a high consistency, indicated by the rightmost distributions. 5. Conclusion Hidden Markov models (HMMs) are used widely in perceptual computing as trainable, time-flexible classifiers of signals that originate from processes like speech and gesture.
Reference: [4] <author> L. W. Campbell, D. A. Becker, A. Azarbayjani, A. F. Bobick, and A. Pentland. </author> <title> Invariant features for 3-D gesture recognition. </title> <booktitle> In Proceedings, International Conferenceon Automatic Face and Gesture Recognition, </booktitle> <pages> pages 157-162, </pages> <address> Killington, VT, 1996. </address> <publisher> IEEE. </publisher>
Reference-contexts: The frame rate of the vision system varied from 10-20 Hz. We resampled the data using time-stamped frames and cubic spline interpolation to produce a 30Hz signal, then low-pass filtered with a 3Hz cutoff. Similar preprocessing is used by Campbell et al. <ref> [4] </ref>, who go on to convert the feature vector to head-centered cylindrical coordinates velocities (dr; d; dz) for rotation and shift invariance; we remain with raw 3D (x; y; z) coordinates. <p> This is because the LHMM model of the cobra did not not correctly model its temporal structure; having a very low discrimination power, it claimed nearly all sequences. In fact, the LHMM performed significantly better than the HMM on the other two gestures. We note that Campbell et al. <ref> [4] </ref> were able train conventional HMMs with (x l ; y l ; z l ; x r ; y r ; z r ) feature vectors to classify 18 different T'ai Chi gestures with accuracies as high as 94%.
Reference: [5] <author> Z. Ghahramani and M. I. Jordan. </author> <title> Factorial hidden Markov models. </title> <editor> In D. S. Touretzky, M. C. Mozer, and M. Hasselmo, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, volume 8, </booktitle> <address> Cambridge, MA, 1996. </address> <publisher> MIT Press. </publisher>
Reference-contexts: We are interested in systems that have compositional state in space, e.g., more than one simultaneous state variable. Recently, Jordan, Saul, and Ghahramani have developed a variety of multiple-HMM classifiers, including factorial HMMs <ref> [5] </ref> for independent processes; linked HMMs [8] that model noncausal (contemporaneous) symmetrical influences; and hidden Markov decision trees [7] that feature a cascade of noncausal influences from master to slave HMMs.
Reference: [6] <author> F. V. Jensen, S. L. Lauritzen, and K. G. Olesen. </author> <title> Bayesian updating in recursive graphical models by local computations. </title> <journal> Computational Statistical Quarterly, </journal> <volume> 4 </volume> <pages> 269-282, 190. </pages>
Reference-contexts: We note that in principle it is also possible to derive an approximation algorithm in the mean field framework or an exact algorithm using junction-tree representations <ref> [6] </ref>. Our experiences with these methods have led to somewhat inferior models and extremely long computations, respectively. 3. Coupling and Factoring HMMs Two HMMs are coupled by introducing tables conditional probabilities between their state variables.
Reference: [7] <author> M. I. Jordan, Z. Ghahramani, and L. K. Saul. </author> <title> Hidden Markov decision trees. </title> <editor> In D. S. Touretzky, M. C. Mozer, and M. Has-selmo, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, volume 8, </booktitle> <address> Cambridge, MA, 1996. </address> <publisher> MIT Press. </publisher>
Reference-contexts: Recently, Jordan, Saul, and Ghahramani have developed a variety of multiple-HMM classifiers, including factorial HMMs [5] for independent processes; linked HMMs [8] that model noncausal (contemporaneous) symmetrical influences; and hidden Markov decision trees <ref> [7] </ref> that feature a cascade of noncausal influences from master to slave HMMs. The training algorithms are based on an equivalence between HMMs and a class of Boltzmann machine architectures with tied weights [9, 10]. The linked HMM excepted, these algorithms use mean-field approximations from statistical mechanics.
Reference: [8] <author> L. K. Saul and M. I. Jordan. </author> <title> Boltzmann chains and hidden Markov models. </title> <editor> In G. Tesauro, D. S. Touretzky, and T. Leen, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, volume 7, </booktitle> <address> Cambridge, MA, 1995. </address> <publisher> MIT Press. </publisher>
Reference-contexts: We are interested in systems that have compositional state in space, e.g., more than one simultaneous state variable. Recently, Jordan, Saul, and Ghahramani have developed a variety of multiple-HMM classifiers, including factorial HMMs [5] for independent processes; linked HMMs <ref> [8] </ref> that model noncausal (contemporaneous) symmetrical influences; and hidden Markov decision trees [7] that feature a cascade of noncausal influences from master to slave HMMs. The training algorithms are based on an equivalence between HMMs and a class of Boltzmann machine architectures with tied weights [9, 10].
Reference: [9] <author> P. Smyth, D. Heckerman, and M. Jordan. </author> <title> Probabilistic independence networks for hidden Markov probability models. AI memo 1565, </title> <publisher> MIT, </publisher> <address> Cambridge, MA, </address> <month> Feb. </month> <year> 1996. </year>
Reference-contexts: The training algorithms are based on an equivalence between HMMs and a class of Boltzmann machine architectures with tied weights <ref> [9, 10] </ref>. The linked HMM excepted, these algorithms use mean-field approximations from statistical mechanics. Appears in Proceedings of CVPR97, San Juan, PR. BRAND, OLIVER, PENTLAND We present an algorithm for coupling two HMMs with causal (temporal), possibly asymmetric influences.
Reference: [10] <author> C. Williams and G. E. Hinton. </author> <title> Mean field networks that learn to discriminate temporally distorted strings. </title> <booktitle> In Proceedings, Connectionist models summer school, </booktitle> <pages> pages 18-22, </pages> <address> San Ma-teo, CA, 1990. </address> <publisher> Morgan Kaufmann. </publisher> <pages> 6 </pages>
Reference-contexts: The training algorithms are based on an equivalence between HMMs and a class of Boltzmann machine architectures with tied weights <ref> [9, 10] </ref>. The linked HMM excepted, these algorithms use mean-field approximations from statistical mechanics. Appears in Proceedings of CVPR97, San Juan, PR. BRAND, OLIVER, PENTLAND We present an algorithm for coupling two HMMs with causal (temporal), possibly asymmetric influences.
References-found: 10

