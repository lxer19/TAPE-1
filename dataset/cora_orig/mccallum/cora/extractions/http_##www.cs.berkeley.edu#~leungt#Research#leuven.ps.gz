URL: http://www.cs.berkeley.edu/~leungt/Research/leuven.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~leungt/publications.html
Root-URL: 
Email: fburl, perona, mweberg@vision.caltech.edu leungt@cs.berkeley.edu  
Title: Recognition of Visual Object Classes  
Author: M.C. Burl T.K. Leung M. Weber and P. Perona yx 
Address: Pasadena, CA 91125, USA Berkeley, CA 94720, USA  
Affiliation: California Institute of Technology U.C. Berkeley Dept. of Electrical Engineering, MSC 136-93 Computer Science Division  Universita di Padova, Italy  
Date: (July 1996)  
Note: This is page i Printer: Opaque this University of Leuwen Book Chapter  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Y. Amit and A. Kong. </author> <title> "Graphical Templates for Image Matching". </title> <type> Technical Report 373, </type> <institution> Department of Statistics, University of Chicago, </institution> <month> August </month> <year> 1993. </year>
Reference-contexts: The advantage of our approach is that instead of using an ad hoc energy function, we encode the allowed deformations with a probability density estimated from actual data. The difference between our work and that of Yuille [45], Amit <ref> [2, 1] </ref>, and Graf [21] falls along similar lines. Lanitis, Cootes, et al [31, 13, 12] have developed a system that uses a shape description based on eigenmodes. <p> Using the first assumption, we can write P (WjH) = P H (W (H)) Q H (W ( H)) (0.12) where P H denotes the joint probability density for the locations of all object features present in the hypothesis H. For example, if H = <ref> [2; 5; 0; 7; 1] </ref>, then P H would be the joint density for the locations of object features 1, 2, 4, and 5. Similarly, Q H is the (joint) probability density for all the other candidate locations (hypothesized to be false alarms). <p> the 2N fi 2N matrix L T defined below: L T = I 1e T 0 I 1e T In this equation I and 0 are the N fi N identity and zero matrices, respectively, 1 is a N fi 1 vector of ones, and e 1 is the vector <ref> [1; 0; : : : ; 0] </ref> T .
Reference: [2] <author> Yali Amit, Donald Geman, and Ken Wilder. </author> <title> "Recognizing Shapes from Simple Queries about Geometry". source unknown, </title> <month> July </month> <year> 1995. </year>
Reference-contexts: The advantage of our approach is that instead of using an ad hoc energy function, we encode the allowed deformations with a probability density estimated from actual data. The difference between our work and that of Yuille [45], Amit <ref> [2, 1] </ref>, and Graf [21] falls along similar lines. Lanitis, Cootes, et al [31, 13, 12] have developed a system that uses a shape description based on eigenmodes. <p> Using the first assumption, we can write P (WjH) = P H (W (H)) Q H (W ( H)) (0.12) where P H denotes the joint probability density for the locations of all object features present in the hypothesis H. For example, if H = <ref> [2; 5; 0; 7; 1] </ref>, then P H would be the joint density for the locations of object features 1, 2, 4, and 5. Similarly, Q H is the (joint) probability density for all the other candidate locations (hypothesized to be false alarms).
Reference: [3] <author> H. Barman, G. H. Granlund, and H. Knutsson. </author> <title> Tensor field filtering and curvature estimation. </title> <booktitle> In SSAB Symposium on Image Analysis, </booktitle> <month> March </month> <year> 1990. </year> <note> This is page xxvi Printer: Opaque this </note>
Reference-contexts: The idea of processing the orientation map representation was introduced by G.H. Granlund in his important work from 1978 entitled "In Search of a General Picture Processing Operator", [22]. Using what Granlund refers to as "transformations of higher-level complex fields," one can proceed to search for curvature <ref> [3] </ref>, boundaries between differently oriented regions (e.g., between cloth and woodgrain textures) [29, 34, 24], circular symmetries [23] and a number of other highly descriptive image features.
Reference: [4] <author> M. Bichsel. </author> <title> Strategies of Robust Object Recognition for the Automatic Identification of Human Faces. </title> <type> PhD thesis, </type> <institution> ETH Zurich, </institution> <year> 1991. </year>
Reference-contexts: Freeman and Roth [18] and Freeman and Weiss-man [19] make use of essentially the same technique for the task of locating This is page v Printer: Opaque this a human hand in front of a white background, and Bichsel <ref> [4] </ref> employs dot products between orientation maps for purposes of face recognition. Bichsel in particular provides a large platform of support | both computational and biological | for the use of orientation maps for feature detection. <p> He cites evidence that measures of local orientation are robust to "the most important object transformations" (aside from global rotation) which include both local and global illumination/brightness changes and minor variations in object size and shape <ref> [4] </ref>. We will now discuss our approach to the estimation of local orientation, which is essentially equivalent to the method of Kass & Witkin, as described in [26]. The first step is to smooth the image with an isotropic filter such as a Gaussian or a difference of Gaussians.
Reference: [5] <author> F.L. Bookstein. </author> <title> "A Statistical Method for Biological Shape Comparison". </title> <journal> J. Theor. Biol., </journal> <volume> 107 </volume> <pages> 475-520, </pages> <year> 1984. </year>
Reference-contexts: Similarly, handwriting consists of lines, loops, cusps, crossings, etc. arranged in a deformable pattern. In our approach, the allowed object deformations are represented through shape statistics, which are learned from examples. The word "shape" is used here in the sense of Kendall [27, 28], Bookstein <ref> [5, 6] </ref>, and others [15, 20]. That is, "shape" refers to properties of a set of labeled points that are invariant with respect to some group of transformations. <p> Using the first assumption, we can write P (WjH) = P H (W (H)) Q H (W ( H)) (0.12) where P H denotes the joint probability density for the locations of all object features present in the hypothesis H. For example, if H = <ref> [2; 5; 0; 7; 1] </ref>, then P H would be the joint density for the locations of object features 1, 2, 4, and 5. Similarly, Q H is the (joint) probability density for all the other candidate locations (hypothesized to be false alarms).
Reference: [6] <author> F.L. Bookstein. </author> <title> "Size and Shape Spaces for Landmark Data in Two Dimensions". </title> <journal> Statistical Science, </journal> <volume> 1(2) </volume> <pages> 181-242, </pages> <year> 1986. </year>
Reference-contexts: Similarly, handwriting consists of lines, loops, cusps, crossings, etc. arranged in a deformable pattern. In our approach, the allowed object deformations are represented through shape statistics, which are learned from examples. The word "shape" is used here in the sense of Kendall [27, 28], Bookstein <ref> [5, 6] </ref>, and others [15, 20]. That is, "shape" refers to properties of a set of labeled points that are invariant with respect to some group of transformations.
Reference: [7] <author> Fred L. Bookstein. </author> <title> "The Morphometric Synthesus for Landmarks and Edge-Elements in Images". </title> <journal> Terra Nova, </journal> <volume> 7(4) </volume> <pages> 393-407, </pages> <year> 1995. </year>
Reference-contexts: The work by Pope and Lowe [38, 37] is similar in flavor to ours, but our approach is more rigorous and general, especially the use of joint distributions to model spatial arrangements. The use of shape statistics in computer vision applications has also been examined by <ref> [43, 7] </ref>. 2 Local Feature Detectors The initial step in our object recognition algorithm is to identify candidate locations for various object parts using simple local detectors. There are several advantages to this approach. First, a variety of visual cues can serve as features. <p> Using the first assumption, we can write P (WjH) = P H (W (H)) Q H (W ( H)) (0.12) where P H denotes the joint probability density for the locations of all object features present in the hypothesis H. For example, if H = <ref> [2; 5; 0; 7; 1] </ref>, then P H would be the joint density for the locations of object features 1, 2, 4, and 5. Similarly, Q H is the (joint) probability density for all the other candidate locations (hypothesized to be false alarms).
Reference: [8] <author> R. Brunelli and T. Poggio. </author> <title> "Face Recognition: Features versus Templates". </title> <journal> IEEE Trans. Pattern Anal. Mach. Intell., </journal> <volume> 15(10) </volume> <pages> 1042-1052, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: However, since the underlying assumption that "the signal is known exactly" rarely holds true, considerable effort has been devoted to extending this method to handle variability in the target signal. For example, approaches based on eigenfeatures <ref> [42, 8, 35, 10] </ref> encode the variability using linear combinations of a set of basis templates. Other approaches, including neural networks [9, 40], response-space matching [25, 33], and deformable templates [45, 36], also can be viewed as generalized template-matching schemes. <p> Although the features are stylized and do not look like photographs of the corresponding human parts, one still obtains a strong perception of a face. Purely appearance-based approaches, such as principal components <ref> [42, 8, 35, 10] </ref>, will not work on this type of problem. By decoupling the local appearance of the object parts from the global spatial arrangement, certain types of geometrical invariances can be more easily enforced. For example, it is easier to guarantee translation, rotation, and scale invariance.
Reference: [9] <author> G. Burel and D. Carel. </author> <title> "Detection and Localization of Faces on Digital Images". </title> <journal> Pattern Recognition Letters, </journal> <pages> pages 963-967, </pages> <month> Oct </month> <year> 1994. </year>
Reference-contexts: For example, approaches based on eigenfeatures [42, 8, 35, 10] encode the variability using linear combinations of a set of basis templates. Other approaches, including neural networks <ref> [9, 40] </ref>, response-space matching [25, 33], and deformable templates [45, 36], also can be viewed as generalized template-matching schemes.
Reference: [10] <author> M.C. Burl, U.M. Fayyad, P. Perona, P. Smyth, </author> <title> and M.P. Burl. Automating the hunt for volcanoes on venus. </title> <booktitle> In Proc. IEEE Comput. Soc. Conf. Comput. Vision and Pattern Recogn., </booktitle> <address> Seattle, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: However, since the underlying assumption that "the signal is known exactly" rarely holds true, considerable effort has been devoted to extending this method to handle variability in the target signal. For example, approaches based on eigenfeatures <ref> [42, 8, 35, 10] </ref> encode the variability using linear combinations of a set of basis templates. Other approaches, including neural networks [9, 40], response-space matching [25, 33], and deformable templates [45, 36], also can be viewed as generalized template-matching schemes. <p> Although the features are stylized and do not look like photographs of the corresponding human parts, one still obtains a strong perception of a face. Purely appearance-based approaches, such as principal components <ref> [42, 8, 35, 10] </ref>, will not work on this type of problem. By decoupling the local appearance of the object parts from the global spatial arrangement, certain types of geometrical invariances can be more easily enforced. For example, it is easier to guarantee translation, rotation, and scale invariance.
Reference: [11] <author> P.J. Burt. </author> <title> A multiscale face recognition system. </title> <note> unpublished. </note>
Reference-contexts: Features may also come at different scales of resolution: a low-resolution version of an entire face is as much a feature as a high resolution version of an eye corner <ref> [11] </ref>. Candidate locations of object parts are identified by local feature detectors. The basic problem is that local detectors will not be perfectly reliable. <p> For handwriting, the features could be quite different: locations of pen lifts and drops, cusps, humps, crossings, etc. Features can come at different scales of resolution: a low-resolution version of the whole face is as much a feature as a high resolution version of an eye corner <ref> [11] </ref>. Another advantage of a feature-based approach is that stylized features can be accomodated more easily. In cartoons and children's drawings, the eyes on a face are often drawn as dots or small circles, the mouth is drawn as a curved line in the appropriate position, etc.
Reference: [12] <author> T.F. Cootes et al. </author> <title> "Use of Active Shape Models for Locating Structures in Medical Images". </title> <journal> Image and Vision Computing, </journal> <volume> 12(6) </volume> <pages> 355-365, </pages> <month> July/Aug </month> <year> 1994. </year>
Reference-contexts: The difference between our work and that of Yuille [45], Amit [2, 1], and Graf [21] falls along similar lines. Lanitis, Cootes, et al <ref> [31, 13, 12] </ref> have developed a system that uses a shape description based on eigenmodes.
Reference: [13] <author> T.F. Cootes and C.J. Taylor. </author> <title> "Combining Point Distribution Models with Shape Models Based on Finite Element Analysis". </title> <journal> Image and Vision Computing, </journal> <volume> 13(5) </volume> <pages> 403-409, </pages> <month> Jun </month> <year> 1995. </year>
Reference-contexts: The difference between our work and that of Yuille [45], Amit [2, 1], and Graf [21] falls along similar lines. Lanitis, Cootes, et al <ref> [31, 13, 12] </ref> have developed a system that uses a shape description based on eigenmodes.
Reference: [14] <author> A.P. Dempster, N.M. Laird, and D.B. Rubin. </author> <title> "maximum likelihood from incomplete data via the em algorithm". </title> <journal> J. Royal Stat. Soc. B, </journal> <volume> 39 </volume> <pages> 1-38, </pages> <year> 1977. </year>
Reference-contexts: Under these conditions, the Gaussian (or Gaussian mixture) assumption is probably reasonable. For the simple Gaussian, estimation of the mean and covariance is straightforward, while for mixture models, the EM algorithm must be used <ref> [14, 39] </ref> to estimate the parameters. 4.4 The Background Distribution Recall that the likelihood ratio (Equation 0.19) contains the term P (S)=Q (S), where P is the shape density given object and Q is the shape density given background.
Reference: [15] <author> I.L. Dryden and K.V. Mardia. </author> <title> "General Shape Distributions in a Plane". </title> <journal> Adv. Appl. Prob., </journal> <volume> 23 </volume> <pages> 259-276, </pages> <year> 1991. </year>
Reference-contexts: Similarly, handwriting consists of lines, loops, cusps, crossings, etc. arranged in a deformable pattern. In our approach, the allowed object deformations are represented through shape statistics, which are learned from examples. The word "shape" is used here in the sense of Kendall [27, 28], Bookstein [5, 6], and others <ref> [15, 20] </ref>. That is, "shape" refers to properties of a set of labeled points that are invariant with respect to some group of transformations. <p> What density is induced upon the shape vector U? Dryden and Mardia have solved this problem in closed-form <ref> [15] </ref> for the case when X follows a general 2N - dimensional Gaussian distribution: X = [x 1 ; : : : ; x N ; y 1 ; : : : ; y N ] T ~ N 2N (-; ) (0.24) The transformation of the first figure point (x <p> ; N ) u i = (x fl 2 + y fl 2 ) = x fl 2 2 i x fl i y fl 2 + y fl 2 (0.29) The joint probability density function (pdf) of U is given in the following theorem: Theorem 1 (Dryden-Mardia Shape Density <ref> [15] </ref>) Under the multi variate Gaussian model for the figure-space coordinates (Equation 0.24), the joint probability density function of the shape vector U is: p U (U) = (2) N2 jj (N 2)!(2 2 where q = i=0 1 2 ( 1 i fr 2 ( 1 N2i fr 2 g <p> The primary result of this section is a derivation of the joint probability distribution for affine-invariant shape variables derived from a multivari-ate Gaussian figure space density [32]. This result generalizes the work of Dryden and Mardia <ref> [15] </ref>. 5.1 Derivation We begin with the assumption that the figure space variables (x i ; y i ), for i = 1; : : : ; N are distributed according to a general 2N -dimensional Gaussian distribution as in Equation 0.24. Translation is eliminated as in the TRS-invariant case.
Reference: [16] <author> R.O. Duda and P.E. Hart. </author> <title> "Pattern Classification and Scene Analysis". </title> <publisher> Wiley, </publisher> <year> 1973. </year>
Reference-contexts: 1 Introduction Many early pattern recognition algorithms were based on template matching <ref> [16] </ref>, which is optimal for detecting a known signal in white noise. However, since the underlying assumption that "the signal is known exactly" rarely holds true, considerable effort has been devoted to extending this method to handle variability in the target signal.
Reference: [17] <author> J.N. Franklin. </author> <title> Matrix Theory. </title> <publisher> Prentice-Hall, </publisher> <year> 1968. </year>
Reference-contexts: definite, there exists a nonsingular matrix F such that: F T BF = fl (0.69) where fl = diagf 1 ; : : : ; 4 g consists of the eigenvalues of CB and I is the 4 fi 4 identity matrix. (See, for example, Theorem 2, p. 106 in <ref> [17] </ref>.) Upon introducing the following substitution: Fr = q (0.71) Equation 0.68 simplifies to = (2) 3N jCj e g Z Z jr T flrj N3 N = (2) 3N jCj e g n 1 + + 4 r 2 o where the r i 's are independent Gaussian random variables
Reference: [18] <author> W. T. Freeman and M. Roth. </author> <title> Orientation histograms for hand gesture recognition. </title> <type> Technical Report TR-94-03a, </type> <institution> Mitsubishi Electric Research Laboratories, </institution> <address> Cambridge, MA, </address> <month> December </month> <year> 1994. </year> <note> This is page xxvii Printer: Opaque this </note>
Reference-contexts: A review of the literature will reveal that OTC as described above is not a new idea, however. Freeman and Roth <ref> [18] </ref> and Freeman and Weiss-man [19] make use of essentially the same technique for the task of locating This is page v Printer: Opaque this a human hand in front of a white background, and Bichsel [4] employs dot products between orientation maps for purposes of face recognition.
Reference: [19] <author> W. T. Freeman and C. D. Weissman. </author> <title> Television control by hand gestures. </title> <type> Technical Report TR-94-24, </type> <institution> Mitsubishi Electric Research Laboratories, </institution> <address> Cambridge, MA, </address> <month> December </month> <year> 1994. </year>
Reference-contexts: A review of the literature will reveal that OTC as described above is not a new idea, however. Freeman and Roth [18] and Freeman and Weiss-man <ref> [19] </ref> make use of essentially the same technique for the task of locating This is page v Printer: Opaque this a human hand in front of a white background, and Bichsel [4] employs dot products between orientation maps for purposes of face recognition.
Reference: [20] <author> C.R. Goodall and K.V. Mardia. </author> <title> "Multivariate Aspects of Shape Theory". </title> <journal> The Annals of Statistics, </journal> <volume> 21(2) </volume> <pages> 848-866, </pages> <year> 1993. </year>
Reference-contexts: Similarly, handwriting consists of lines, loops, cusps, crossings, etc. arranged in a deformable pattern. In our approach, the allowed object deformations are represented through shape statistics, which are learned from examples. The word "shape" is used here in the sense of Kendall [27, 28], Bookstein [5, 6], and others <ref> [15, 20] </ref>. That is, "shape" refers to properties of a set of labeled points that are invariant with respect to some group of transformations.
Reference: [21] <author> Hans Peter Graf et al. </author> <title> "Locating Faces and Facial Parts". </title> <booktitle> In International Workshop on Automatic Face- and Gesture-Recognition, </booktitle> <pages> pages 41-46, </pages> <year> 1995. </year>
Reference-contexts: The advantage of our approach is that instead of using an ad hoc energy function, we encode the allowed deformations with a probability density estimated from actual data. The difference between our work and that of Yuille [45], Amit [2, 1], and Graf <ref> [21] </ref> falls along similar lines. Lanitis, Cootes, et al [31, 13, 12] have developed a system that uses a shape description based on eigenmodes.
Reference: [22] <author> G. H. Granlund. </author> <title> In search of a general picture processing operator. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 8 </volume> <pages> 155-173, </pages> <year> 1978. </year>
Reference-contexts: An example of an orientation map is shown in Figure 1. The idea of processing the orientation map representation was introduced by G.H. Granlund in his important work from 1978 entitled "In Search of a General Picture Processing Operator", <ref> [22] </ref>. Using what Granlund refers to as "transformations of higher-level complex fields," one can proceed to search for curvature [3], boundaries between differently oriented regions (e.g., between cloth and woodgrain textures) [29, 34, 24], circular symmetries [23] and a number of other highly descriptive image features.
Reference: [23] <author> G. H. Granlund and H. Knutsson. </author> <title> Signal Processing for Computer Vision. </title> <publisher> Kluwer Academic Press, </publisher> <year> 1995. </year>
Reference-contexts: Using what Granlund refers to as "transformations of higher-level complex fields," one can proceed to search for curvature [3], boundaries between differently oriented regions (e.g., between cloth and woodgrain textures) [29, 34, 24], circular symmetries <ref> [23] </ref> and a number of other highly descriptive image features. For the purposes at hand, we are interested in reliably locating specific objects (namely, facial features) based on their appearance in the orientation map representation.
Reference: [24] <author> H. Greenspan, S. Belongie, R. Goodman, and P. Perona. </author> <title> Rotation invariant texture recognition using a steerable pyramid. </title> <booktitle> In Proc. 12 th Int. Conf. Pattern Recognition, </booktitle> <address> Jerusalem, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: Granlund in his important work from 1978 entitled "In Search of a General Picture Processing Operator", [22]. Using what Granlund refers to as "transformations of higher-level complex fields," one can proceed to search for curvature [3], boundaries between differently oriented regions (e.g., between cloth and woodgrain textures) <ref> [29, 34, 24] </ref>, circular symmetries [23] and a number of other highly descriptive image features. For the purposes at hand, we are interested in reliably locating specific objects (namely, facial features) based on their appearance in the orientation map representation.
Reference: [25] <author> D. Jones and J. Malik. </author> <title> A computational framework for determining stereo correspondence from a set of linear spatial filters. </title> <type> UCB-CSD 91-655, </type> <institution> U.C.Berkeley - CS dept., </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: For example, approaches based on eigenfeatures [42, 8, 35, 10] encode the variability using linear combinations of a set of basis templates. Other approaches, including neural networks [9, 40], response-space matching <ref> [25, 33] </ref>, and deformable templates [45, 36], also can be viewed as generalized template-matching schemes.
Reference: [26] <author> Michael Kass and Andrew Witkin. </author> <title> Analyzing oriented patterns. </title> <booktitle> Computer Vision Graphics and Image Processing, </booktitle> <volume> 37 </volume> <pages> 362-385, </pages> <year> 1987. </year>
Reference-contexts: We will now discuss our approach to the estimation of local orientation, which is essentially equivalent to the method of Kass & Witkin, as described in <ref> [26] </ref>. The first step is to smooth the image with an isotropic filter such as a Gaussian or a difference of Gaussians.
Reference: [27] <author> D.G. Kendall. </author> <title> "Shape Manifolds, Procrustean Metrics, and Complex Projective Spaces". </title> <journal> Bull. London Math Soc., </journal> <volume> 16 </volume> <pages> 81-121, </pages> <year> 1984. </year>
Reference-contexts: Similarly, handwriting consists of lines, loops, cusps, crossings, etc. arranged in a deformable pattern. In our approach, the allowed object deformations are represented through shape statistics, which are learned from examples. The word "shape" is used here in the sense of Kendall <ref> [27, 28] </ref>, Bookstein [5, 6], and others [15, 20]. That is, "shape" refers to properties of a set of labeled points that are invariant with respect to some group of transformations.
Reference: [28] <author> D.G. Kendall. </author> <title> "A Survey of the Statistical Theory of Shape". </title> <journal> Statistical Science, </journal> <volume> 4(2) </volume> <pages> 87-120, </pages> <year> 1989. </year>
Reference-contexts: Similarly, handwriting consists of lines, loops, cusps, crossings, etc. arranged in a deformable pattern. In our approach, the allowed object deformations are represented through shape statistics, which are learned from examples. The word "shape" is used here in the sense of Kendall <ref> [27, 28] </ref>, Bookstein [5, 6], and others [15, 20]. That is, "shape" refers to properties of a set of labeled points that are invariant with respect to some group of transformations.
Reference: [29] <author> H. Knutsson and G. H. Granlund. </author> <title> Texture analysis using two-dimensional quadrature filters. </title> <booktitle> In Workshop on Computer Architecture for Pattern Analysis and Image Database Management, </booktitle> <pages> pages 206-213. </pages> <publisher> IEEE Computer Society, </publisher> <year> 1983. </year>
Reference-contexts: Granlund in his important work from 1978 entitled "In Search of a General Picture Processing Operator", [22]. Using what Granlund refers to as "transformations of higher-level complex fields," one can proceed to search for curvature [3], boundaries between differently oriented regions (e.g., between cloth and woodgrain textures) <ref> [29, 34, 24] </ref>, circular symmetries [23] and a number of other highly descriptive image features. For the purposes at hand, we are interested in reliably locating specific objects (namely, facial features) based on their appearance in the orientation map representation.
Reference: [30] <author> Martin Lades et al. </author> <title> "Distortion Invariant Object Recognition in the Dynamic Link Architecture". </title> <journal> IEEE Transactions on Computers, </journal> <volume> 42(3) </volume> <pages> 300-311, </pages> <month> mar </month> <year> 1993. </year>
Reference-contexts: This is the key to obtaining invariance to different instances from the same object class, without making the model so loose that false positives are admitted. A similar recognition method that uses deformable meshes instead of shape statistics has been developed by Lades, von der Malsburg, and colleagues <ref> [30, 44] </ref>. In their approach, a mesh is overlaid on incoming images and adjusted to obtain the best match between the mesh node descriptors and the image, subject to a penalty on the amount of deformation.
Reference: [31] <author> A. Lanitis, C.J. Taylor, T.F. Cootes, and T. Ahmed. </author> <title> "Automatic Interpretation of Human Faces and Hand Gestures Using Flexible Models". </title> <booktitle> In International Workshop on Automatic Face- and Gesture-Recognition, </booktitle> <pages> pages 90-103, </pages> <year> 1995. </year>
Reference-contexts: The difference between our work and that of Yuille [45], Amit [2, 1], and Graf [21] falls along similar lines. Lanitis, Cootes, et al <ref> [31, 13, 12] </ref> have developed a system that uses a shape description based on eigenmodes.
Reference: [32] <author> T.K. Leung. </author> <title> "Affine Shape Statistics". </title> <type> Technical report, </type> <institution> U.C. Berke-ley, </institution> <month> Nov </month> <year> 1995. </year> <note> This is page xxviii Printer: Opaque this </note>
Reference-contexts: However, 3-D rotations of planar objects and objects viewed under a weak perspective camera model can be adequately treated using affine invariance. The primary result of this section is a derivation of the joint probability distribution for affine-invariant shape variables derived from a multivari-ate Gaussian figure space density <ref> [32] </ref>.
Reference: [33] <author> T.K. Leung, M.C. Burl, and P. Perona. </author> <title> "Finding Faces in Cluttered Scenes using Random Labeled Graph Matching". </title> <booktitle> Proc. 5th Int. Conf. Computer Vision, </booktitle> <year> 1995. </year>
Reference-contexts: For example, approaches based on eigenfeatures [42, 8, 35, 10] encode the variability using linear combinations of a set of basis templates. Other approaches, including neural networks [9, 40], response-space matching <ref> [25, 33] </ref>, and deformable templates [45, 36], also can be viewed as generalized template-matching schemes.
Reference: [34] <author> J. Malik and P. Perona. </author> <title> Preattentive texture discrimination with early vision mechanisms. </title> <journal> Journal of the Optical Society of Amerika A, </journal> <volume> 7(5) </volume> <pages> 923-932, </pages> <year> 1990. </year> <note> Also appeared as a chapter in Computer vision: advances and applications, </note> <editor> Ed. R. Kasturi and R. Jain, </editor> <publisher> IEEE Computer Society Press, </publisher> <year> 1991. </year>
Reference-contexts: Granlund in his important work from 1978 entitled "In Search of a General Picture Processing Operator", [22]. Using what Granlund refers to as "transformations of higher-level complex fields," one can proceed to search for curvature [3], boundaries between differently oriented regions (e.g., between cloth and woodgrain textures) <ref> [29, 34, 24] </ref>, circular symmetries [23] and a number of other highly descriptive image features. For the purposes at hand, we are interested in reliably locating specific objects (namely, facial features) based on their appearance in the orientation map representation.
Reference: [35] <author> Hiroshi Murase and Shree Nayar. </author> <title> "Visual Learning and Recognition of 3-D Objects from Appearance". </title> <journal> Int J. of Comp. Vis., </journal> <volume> 14 </volume> <pages> 5-24, </pages> <year> 1995. </year>
Reference-contexts: However, since the underlying assumption that "the signal is known exactly" rarely holds true, considerable effort has been devoted to extending this method to handle variability in the target signal. For example, approaches based on eigenfeatures <ref> [42, 8, 35, 10] </ref> encode the variability using linear combinations of a set of basis templates. Other approaches, including neural networks [9, 40], response-space matching [25, 33], and deformable templates [45, 36], also can be viewed as generalized template-matching schemes. <p> Although the features are stylized and do not look like photographs of the corresponding human parts, one still obtains a strong perception of a face. Purely appearance-based approaches, such as principal components <ref> [42, 8, 35, 10] </ref>, will not work on this type of problem. By decoupling the local appearance of the object parts from the global spatial arrangement, certain types of geometrical invariances can be more easily enforced. For example, it is easier to guarantee translation, rotation, and scale invariance.
Reference: [36] <author> D.B Philips and A.F.M. Smith. </author> <title> "bayesian faces via hierarchical template matching". </title> <journal> Journal of the American Statistical Association, </journal> <volume> 89(428) </volume> <pages> 1151-1163, </pages> <month> dec </month> <year> 1994. </year>
Reference-contexts: For example, approaches based on eigenfeatures [42, 8, 35, 10] encode the variability using linear combinations of a set of basis templates. Other approaches, including neural networks [9, 40], response-space matching [25, 33], and deformable templates <ref> [45, 36] </ref>, also can be viewed as generalized template-matching schemes.
Reference: [37] <author> Arthur R. Pope and David G. Lowe. </author> <title> "Modeling Positional Uncertainty in Object Recognition". </title> <type> Technical report, </type> <institution> Department of Computer Science, University of British Columbia, </institution> <year> 1994. </year> <type> Technical Report # 94-32. </type>
Reference-contexts: Although this approach can be viewed as an approximation of the probability density over feature positions, it is not This is page iii Printer: Opaque this clear that their snake-based features will work in cluttered scenes or with occlusion. The work by Pope and Lowe <ref> [38, 37] </ref> is similar in flavor to ours, but our approach is more rigorous and general, especially the use of joint distributions to model spatial arrangements.
Reference: [38] <author> Arthur R. Pope and David G. Lowe. </author> <title> "Learning Feature Uncertainty Models for Object Recognition". </title> <booktitle> In IEEE International Symposium on Computer Vision, </booktitle> <year> 1995. </year>
Reference-contexts: Although this approach can be viewed as an approximation of the probability density over feature positions, it is not This is page iii Printer: Opaque this clear that their snake-based features will work in cluttered scenes or with occlusion. The work by Pope and Lowe <ref> [38, 37] </ref> is similar in flavor to ours, but our approach is more rigorous and general, especially the use of joint distributions to model spatial arrangements.
Reference: [39] <author> R. A. Redner and H. F. Walker. </author> <title> Mixture densities, maximum likelihood and the em algorithm. </title> <journal> SIAM Review, </journal> <volume> 26(2) </volume> <pages> 195-239, </pages> <year> 1984. </year>
Reference-contexts: Under these conditions, the Gaussian (or Gaussian mixture) assumption is probably reasonable. For the simple Gaussian, estimation of the mean and covariance is straightforward, while for mixture models, the EM algorithm must be used <ref> [14, 39] </ref> to estimate the parameters. 4.4 The Background Distribution Recall that the likelihood ratio (Equation 0.19) contains the term P (S)=Q (S), where P is the shape density given object and Q is the shape density given background.
Reference: [40] <author> Henry A. Rowley, Shumeet Baluja, and Takeo Kanade. </author> <title> "Human Face Detection in Visual Scenes". source unknown, </title> <month> July </month> <year> 1995. </year>
Reference-contexts: For example, approaches based on eigenfeatures [42, 8, 35, 10] encode the variability using linear combinations of a set of basis templates. Other approaches, including neural networks <ref> [9, 40] </ref>, response-space matching [25, 33], and deformable templates [45, 36], also can be viewed as generalized template-matching schemes.
Reference: [41] <author> H.L. </author> <title> Van Trees. Detection, Estimation, and Modulation Theory:Part 1. </title> <publisher> John Wiley and Sons, </publisher> <year> 1968. </year>
Reference-contexts: We synthesized orientation template detectors for five features (eyes, nose and mouth corners), and evaluated their performance on a database of facial images. The results are shown as receiver operating characteristics <ref> [41] </ref> or ROC curves in Figure 2. Each ROC curve shows the trade-off between the probability of detecting the target feature and the average number of false alarms per image as the detection threshold t 0 is varied.
Reference: [42] <author> M. Turk and A. Pentland. </author> <title> "Eigenfaces for Recognition". </title> <journal> J. of Cognitive Neurosci., </journal> <volume> 3(1), </volume> <year> 1991. </year>
Reference-contexts: However, since the underlying assumption that "the signal is known exactly" rarely holds true, considerable effort has been devoted to extending this method to handle variability in the target signal. For example, approaches based on eigenfeatures <ref> [42, 8, 35, 10] </ref> encode the variability using linear combinations of a set of basis templates. Other approaches, including neural networks [9, 40], response-space matching [25, 33], and deformable templates [45, 36], also can be viewed as generalized template-matching schemes. <p> Although the features are stylized and do not look like photographs of the corresponding human parts, one still obtains a strong perception of a face. Purely appearance-based approaches, such as principal components <ref> [42, 8, 35, 10] </ref>, will not work on this type of problem. By decoupling the local appearance of the object parts from the global spatial arrangement, certain types of geometrical invariances can be more easily enforced. For example, it is easier to guarantee translation, rotation, and scale invariance.
Reference: [43] <author> A. Wilson. </author> <title> title not available. </title> <type> PhD thesis, </type> <institution> Duke, </institution> <year> 1995. </year>
Reference-contexts: The work by Pope and Lowe [38, 37] is similar in flavor to ours, but our approach is more rigorous and general, especially the use of joint distributions to model spatial arrangements. The use of shape statistics in computer vision applications has also been examined by <ref> [43, 7] </ref>. 2 Local Feature Detectors The initial step in our object recognition algorithm is to identify candidate locations for various object parts using simple local detectors. There are several advantages to this approach. First, a variety of visual cues can serve as features.
Reference: [44] <author> L. Wiskott and C. von der Malsburg. </author> <title> "A Neural System for the Recognition of Partially Occluded Objects in Cluttered Scenes". </title> <booktitle> 7(4) </booktitle> <pages> 935-948, </pages> <year> 1993. </year>
Reference-contexts: This is the key to obtaining invariance to different instances from the same object class, without making the model so loose that false positives are admitted. A similar recognition method that uses deformable meshes instead of shape statistics has been developed by Lades, von der Malsburg, and colleagues <ref> [30, 44] </ref>. In their approach, a mesh is overlaid on incoming images and adjusted to obtain the best match between the mesh node descriptors and the image, subject to a penalty on the amount of deformation.
Reference: [45] <author> A.L. Yuille. </author> <title> "Deformable Templates for Face Recognition". </title> <journal> J. of Cognitive Neurosci., </journal> <volume> 3(1) </volume> <pages> 59-70, </pages> <year> 1991. </year>
Reference-contexts: For example, approaches based on eigenfeatures [42, 8, 35, 10] encode the variability using linear combinations of a set of basis templates. Other approaches, including neural networks [9, 40], response-space matching [25, 33], and deformable templates <ref> [45, 36] </ref>, also can be viewed as generalized template-matching schemes. <p> The advantage of our approach is that instead of using an ad hoc energy function, we encode the allowed deformations with a probability density estimated from actual data. The difference between our work and that of Yuille <ref> [45] </ref>, Amit [2, 1], and Graf [21] falls along similar lines. Lanitis, Cootes, et al [31, 13, 12] have developed a system that uses a shape description based on eigenmodes.
References-found: 45

