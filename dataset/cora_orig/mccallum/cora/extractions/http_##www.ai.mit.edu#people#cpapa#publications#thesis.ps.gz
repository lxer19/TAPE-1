URL: http://www.ai.mit.edu/people/cpapa/publications/thesis.ps.gz
Refering-URL: http://www.ai.mit.edu/people/cpapa/publications.html
Root-URL: 
Title: Object and Pattern Detection in Video Sequences  
Author: by Constantine Phaedon Papageorgiou 
Degree: Submitted to the  in partial fulfillment of the requirements for the Degree of Master of Science in Electrical Engineering and Computer Science Thesis Supervisor: Professor Tomaso Poggio  
Date: May 14, 1997  
Affiliation: Department of Electrical Engineering and Computer Science  Department of Brain and Cognitive Sciences  
Abstract: This thesis presents a general trainable framework for object detection in static images of cluttered scenes and a novel motion based extension that enhances performance over video sequences. The detection technique we develop is based on a wavelet representation of an object class derived from a statistical analysis of the class instances. By learning an object class in terms of a subset of an overcomplete dictionary of wavelet basis functions, we derive a compact representation of an object class which is used as input to a support vector machine classifier. The paradigm we present successfully handles the major difficulties of object detection: overcoming the in-class variability of complex classes such as faces and pedestrians and providing a very low false detection rate, even in unconstrained environments. We demonstrate the capabilities of the technique in two domains whose inherent information content differs significantly. The first system is face detection; we extend the methodology to the domain of people which, unlike faces, vary greatly in color, texture, and patterns. Unlike previous approaches, this system learns from examples and does not rely on any a priori (hand-crafted) models or motion-based segmentation. The thesis also introduces a motion-based extension to enhance the performance of the detection algorithm over video sequences. This module is based on the realization that in regions of motion, the likely classes of objects are limited, so we can relax the strictness of the classifier. This does not compromise performance over non-moving objects. The results presented here suggest that this architecture may be extended to other domains. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.R. Bergen and R. Hingorani. </author> <title> Hierarchical motion-based frame rate conversion, </title> <month> April </month> <year> 1990. </year>
Reference-contexts: This approximation is accurate for displacements of less than one pixel, so the optical flow algorithm we use for our system (Bergen and Hingorani, 1990 <ref> [1] </ref>) uses a coarse-to-fine strategy where flow fields are iteratively estimated for higher resolutions of a Gaussian pyramid representation of the image. This type of strategy enables facilitates the efficient computation of flow fields where the image-to-image displacements are quite large.
Reference: [2] <author> M. Betke and N. Makris. </author> <title> Fast object recognition in noisy images using simulated annealing. </title> <booktitle> In Proceedings of the Fifth International Conference on Computer Vision, </booktitle> <pages> pages 523-20, </pages> <year> 1995. </year>
Reference-contexts: Typically, the systems that have been developed fall into one of two categories: template-based approaches that attempt to match or fit a prototype template to different parts of the image (Betke and Makris, 1995 <ref> [2] </ref>, Yuille et al., 1992 [31]) or image invariance methods that base a matching on a set of image pattern relationships (eg. brightness levels) that, ideally, uniquely determine the objects being searched for (Sinha, 1994 [22][23]).
Reference: [3] <author> B. Boser, I. Guyon, and V. Vapnik. </author> <title> A training algorithm for optim margin classifier. </title> <booktitle> In Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, </booktitle> <pages> pages 144-52. </pages> <publisher> ACM, </publisher> <year> 1992. </year>
Reference-contexts: The detection architecture is not hardcoded to use the support vector machinery; indeed, we could use any classification algorithm but choose the SVM because of its solid theoretical foundations and its initial success when applied to tasks such as handwritten digit recognition (Boser et al., 1992 <ref> [3] </ref>) and face detection (Osuna et al., 1997 [17]). It should also be observed, that from the viewpoint of the classification task, we could use the whole set of coefficients as a feature vector.
Reference: [4] <author> L. Campbell and A. Bobick. </author> <title> Recognition of human body motion using phase space constraints. </title> <type> Technical Report 309, </type> <institution> Media Laboratory, Massachusetts Institute of Technology, </institution> <year> 1995. </year>
Reference-contexts: The 18 authors highlight, as future work, investigating object detection with this algorithm. An important aspect of this system is that, unlike other systems described in this section, this technique does not assume a stationary camera. Campbell and Bobick, 1995 <ref> [4] </ref> take a different approach to analyzing human body motion. They present a system for recognizing different body motions using constraints on the movements of different body parts. Motion data is gathered using ballet dancers with different body parts marked with sensors.
Reference: [5] <author> E.R. Dougherty. </author> <title> An Introduction to Morphological Image Processing, volume TT9. </title> <publisher> SPIE Press, </publisher> <year> 1992. </year>
Reference-contexts: To accomplish this we make use of some simple concepts from mathematical morphology, under the assumption that there will be some moving areas (arms, etc.) within the boundaries of a moving region. Mathematical morphology (Serra, 1982 [21], Dougherty, 1992 <ref> [5] </ref>, Korn et al., 1996 [9]) is a quantitative theory that formalizes notions of shape and structure of objects. We use some simple transforms from mathematical morphology to process the image to yield a representation where pixel values of one indicate motion, not just the boundary of a motion/non-motion region.
Reference: [6] <author> B. Heisele, U. Kressel, and W. Ritter. </author> <title> Tracking non-rigid, moving objects based on color cluster flow. </title> <note> In CVPR '97, 1997. to appear. </note>
Reference-contexts: They use a Kalman filter to track the different people and implement a radial basis function network to detect the faces. As noted, the system assumes a fixed camera and may have problems detecting people that are not moving. To track moving objects, Heisele et al., 1997 <ref> [6] </ref> use the clusters of consistent color to track moving objects. Initially, the system computes the color clusters for the first image in a sequence. The system recomputes the cluster centroids for subsequent images, assuming a fixed number of clusters. <p> All of the systems assume a static camera, clearly a severe restriction for a practical system that might be integrated in a driver assistance system, for instance; the one system that does not assume a static camera, that of Heisele et al., 1997 <ref> [6] </ref>, is actually only doing tracking of manually labeled color blobs, so is not yet a viable pedestrian detection system. Since these systems heavily rely on motion to determine the location of pedestrians in the images, they would also have problems finding pedestrians that are not moving.
Reference: [7] <author> D. Hogg. </author> <title> Model-based vision: a program to see a walking person. </title> <journal> Image and Vision Computing, </journal> <volume> 1(1) </volume> <pages> 5-20, </pages> <year> 1983. </year>
Reference-contexts: The use of 3D models has been prominent in finding people in video sequences. This type of system, while adequate for specific, well-defined domains, involves using a lot of domain specific information in the development of the model and is not 17 easily portable to new domains. Hogg, 1983 <ref> [7] </ref> describes a system that is based on modeling a human figure as a hierarchical decomposition of 3D cylinders, using dynamic constraints on the movement of the limbs as well. <p> This method has been used in several systems (Hogg, 1983 <ref> [7] </ref>, Wren et al., 1995 [30]) that also assume that the only moving objects will be people. It is easy to see that this is a trivial case; we can exactly recover where motion has occurred very easily.
Reference: [8] <author> C.E. Jacobs, A. Finkelstein, and D.H. Salesin. </author> <title> Fast multiresolution image querying. </title> <address> SIGGRAPH95, </address> <month> August </month> <year> 1995. </year> <institution> University of Washington, TR-95-01-06. </institution>
Reference-contexts: The Haar wavelet representation has also been used for image database retrieval, Ja-cobs et al., 1995 <ref> [8] </ref>, where the largest wavelet coefficients are used as a measure of similarity between two images. Our results on object detection using the wavelet representation demonstrate that it may be a promising framework for computer vision applications.
Reference: [9] <author> F. Korn, N. Sidiropoulos, C. Faloutsos, E. Siegel, and Z. Protopapas. </author> <title> Fast nearest neighbor search in medical image databases. </title> <institution> Computer Science Technical Report CS-TR-3613, University of Maryland, </institution> <month> March </month> <year> 1996. </year>
Reference-contexts: To accomplish this we make use of some simple concepts from mathematical morphology, under the assumption that there will be some moving areas (arms, etc.) within the boundaries of a moving region. Mathematical morphology (Serra, 1982 [21], Dougherty, 1992 [5], Korn et al., 1996 <ref> [9] </ref>) is a quantitative theory that formalizes notions of shape and structure of objects. We use some simple transforms from mathematical morphology to process the image to yield a representation where pixel values of one indicate motion, not just the boundary of a motion/non-motion region.
Reference: [10] <author> H. Lakany and G. Hayes. </author> <title> An algorithm for recognising walkers. </title> <editor> In J. Bigun, G. Chollet, and G. Borgefors, editors, </editor> <booktitle> Audio- and Video-based Biometric Person Authentication, </booktitle> <pages> pages 112-118. </pages> <address> IAPR, </address> <publisher> Springer, </publisher> <year> 1997. </year>
Reference-contexts: Motion data is gathered using ballet dancers with different body parts marked with sensors. The system uses correlations between different part motions to determine the "best" recognizer of the high-level motion. They use this system to classify different ballet motions. Lakany and Hayes, 1997 <ref> [10] </ref> also use moving light displays (MLDs) combined with a 2D FFT for feature extraction to train a neural network to recognize a walker from his/her gait.
Reference: [11] <author> M.K. Leung and Y-H. Yang. </author> <title> Human body motion segmentation in a complex scene. </title> <journal> Pattern Recognition, </journal> <volume> 20(1) </volume> <pages> 55-64, </pages> <year> 1987. </year> <month> 60 </month>
Reference: [12] <author> M.K. Leung and Y-H. Yang. </author> <title> A region based approach for human body analysis. </title> <journal> Pattern Recognition, </journal> <volume> 20(3) </volume> <pages> 321-39, </pages> <year> 1987. </year>
Reference: [13] <author> S.G. Mallat. </author> <title> A theory for multiresolution signal decomposition: The wavelet representation. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 11(7) </volume> <pages> 674-93, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: 8 summarizes the results of the thesis, presents several potential applications of the technique, and describes directions for future work. 23 Chapter 2 Wavelets This section describes the underlying representation that we use for extracting object features, the Haar wavelet; a more detailed treatment can be found in Mallat, 1989 <ref> [13] </ref>. We also describe a denser (redundant) transform that we use to achieve the spatial resolution we need to accomplish detection and define the wavelet basis. 2.1 The Haar Wavelet Wavelets provide a natural mathematical structure for describing our patterns.
Reference: [14] <author> S. McKenna and S. Gong. </author> <title> Non-intrusive person authentication for access control by visual tracking and face recognition. </title> <editor> In J. Bigun, G. Chollet, and G Borgefors, editors, </editor> <booktitle> Audio- and Video-based Biometric Person Authentication, </booktitle> <pages> pages 177-183. </pages> <address> IAPR, </address> <publisher> Springer, </publisher> <year> 1997. </year>
Reference-contexts: This system relies on two key assumptions: that the camera and background are fixed and that there is a single person in the image. These are clearly restrictive assumptions for a general purpose person tracker. McKenna and Gong, 1997 <ref> [14] </ref> describe a system that tracks people in video and automatically detects a face for each person found in the images. The algorithm assumes a fixed camera and, after detecting motion, clusters the motion information to separate different bodies of motion.
Reference: [15] <author> B. Moghaddam and A. Pentland. </author> <title> Probabilistic visual learning for object detection. </title> <type> Technical Report 326, </type> <institution> Media Laboratory, Massachusetts Institute of Technology, </institution> <year> 1995. </year> <note> also in 5th ICCV June 1995. </note>
Reference-contexts: More recently, systems for detecting unoccluded vertical frontal views of human faces in images have been developed using example-based approaches by Sung and Poggio, 1994 [26], Moghaddam and Pentland, 1995 <ref> [15] </ref>, Rowley et al., 1995 [20], Vail-lant et al., 1994 [28], and Osuna et al., 1997 [17]. These view-based approaches can handle detecting faces in cluttered scenes and have shown a reasonable degree of success when extended to handle non-frontal views.
Reference: [16] <author> M. Oren, C. Papageorgiou, P. Sinha, E. Osuna, and T. Poggio. </author> <title> Pedestrian detection using wavelet templates. </title> <booktitle> In CVPR '97, </booktitle> <year> 1997. </year>
Reference-contexts: Another important feature of our work is the use of an overcomplete, or redundant, set of basis functions; this is important in capturing global constraints on the object shape and for providing adequate spatial resolution. We introduced this idea in <ref> [16] </ref>, where we applied the idea of using wavelets for detection for the first time and showed how the wavelet based representation is both efficiently learnable and provides a model of an object class that has significant discriminative power; the application domain was pedestrian detection in static images.
Reference: [17] <author> E. Osuna, R. Freund, and F. Girosi. </author> <title> Support vector machines: Training and applications. A.I. </title> <type> Memo 1602, </type> <institution> MIT A. I. Lab., </institution> <year> 1997. </year>
Reference-contexts: More recently, systems for detecting unoccluded vertical frontal views of human faces in images have been developed using example-based approaches by Sung and Poggio, 1994 [26], Moghaddam and Pentland, 1995 [15], Rowley et al., 1995 [20], Vail-lant et al., 1994 [28], and Osuna et al., 1997 <ref> [17] </ref>. These view-based approaches can handle detecting faces in cluttered scenes and have shown a reasonable degree of success when extended to handle non-frontal views. The system of Sung and Poggio models a set of faces and non-faces as clusters in a high-dimensional space. <p> These images are all scaled to the dimensions 19 fi 19 and show the face from above the eyebrows to below the lips; typical images from the database are shown in Figure 3-1. Databases of this size and composition have been used extensively in face detection [25] [20] <ref> [17] </ref> and we keep this data format for comparison purposes. <p> not hardcoded to use the support vector machinery; indeed, we could use any classification algorithm but choose the SVM because of its solid theoretical foundations and its initial success when applied to tasks such as handwritten digit recognition (Boser et al., 1992 [3]) and face detection (Osuna et al., 1997 <ref> [17] </ref>). It should also be observed, that from the viewpoint of the classification task, we could use the whole set of coefficients as a feature vector.
Reference: [18] <author> F. Riesz and B. Sz.-Nagy. </author> <title> Functional Analysis. </title> <publisher> Ungar, </publisher> <address> New York, </address> <year> 1955. </year>
Reference-contexts: An interesting aspect of the SVM is that its decision surface depends only on the inner product of the feature vectors. This leads to an important extension since we can replace the Euclidean inner product by any symmetric positive-definite kernel K (x; y) <ref> [18] </ref>. Instead of working in the original feature space of variables, x, the SVM uses this nonlinear kernel to project the original set of variables into a high dimensional feature space in which the problem has a greater chance of being linearly separable.
Reference: [19] <author> K. Rohr. </author> <title> Incremental recognition of pedestrians from image sequences. </title> <journal> Computer Vision and Pattern Recognition, </journal> <pages> pages 8-13, </pages> <year> 1993. </year>
Reference-contexts: Edge detection is used to determine the possible locations of body parts and a search tree is used to determine the location that maximizes a "plausibility" measure, indicating the likelihood that there is a person at this location. Rohr, 1993 <ref> [19] </ref> develops a system using similar 3D cylindrical models of the human body and kinematic motion data. Model contours are matched with edges that are found in an image using a grid search method.
Reference: [20] <author> H.A. Rowley, S. Baluja, and T. Kanade. </author> <title> Human face detection in visual scenes. </title> <type> Technical Report CMU-CS-95-158, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> July/November </month> <year> 1995. </year>
Reference-contexts: More recently, systems for detecting unoccluded vertical frontal views of human faces in images have been developed using example-based approaches by Sung and Poggio, 1994 [26], Moghaddam and Pentland, 1995 [15], Rowley et al., 1995 <ref> [20] </ref>, Vail-lant et al., 1994 [28], and Osuna et al., 1997 [17]. These view-based approaches can handle detecting faces in cluttered scenes and have shown a reasonable degree of success when extended to handle non-frontal views. <p> These images are all scaled to the dimensions 19 fi 19 and show the face from above the eyebrows to below the lips; typical images from the database are shown in Figure 3-1. Databases of this size and composition have been used extensively in face detection [25] <ref> [20] </ref> [17] and we keep this data format for comparison purposes.
Reference: [21] <author> J. Serra. </author> <title> Image Analysis and Mathematical Morphology. </title> <publisher> Academic Press, </publisher> <year> 1982. </year>
Reference-contexts: To accomplish this we make use of some simple concepts from mathematical morphology, under the assumption that there will be some moving areas (arms, etc.) within the boundaries of a moving region. Mathematical morphology (Serra, 1982 <ref> [21] </ref>, Dougherty, 1992 [5], Korn et al., 1996 [9]) is a quantitative theory that formalizes notions of shape and structure of objects.
Reference: [22] <author> P. Sinha. </author> <title> Object Recognition via Image Invariants: A Case Study. </title> <booktitle> In Investigative Ophthalmology and Visual Science, </booktitle> <volume> volume 35, </volume> <pages> pages 1735-1740. </pages> <address> Sarasota, Florida, </address> <month> May </month> <year> 1994. </year>
Reference: [23] <author> Pawan Sinha. </author> <title> Qualitative image-based representations for object recognition. </title> <journal> MIT AI Lab-Memo, </journal> <volume> No. 1505, </volume> <year> 1994. </year>
Reference: [24] <author> E.J. Stollnitz, T.D. DeRose, and D.H. Salesin. </author> <title> Wavelets for computer graphics: A primer. </title> <type> Technical Report 94-09-11, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> September </month> <year> 1994. </year>
Reference-contexts: Since the wavelets that the standard transform generates have irregular support, we use the non-standard 2D DWT where, at a given scale, the transform is applied to each dimension sequentially before proceeding to the next scale (Stollnitz et al., 1994 <ref> [24] </ref>). The results are Haar wavelets with square support at all scales.
Reference: [25] <author> K-K. Sung. </author> <title> Learning and Example Selection for Object and Pattern Detection. </title> <type> PhD thesis, </type> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <month> December </month> <year> 1995. </year> <month> 61 </month>
Reference-contexts: These images are all scaled to the dimensions 19 fi 19 and show the face from above the eyebrows to below the lips; typical images from the database are shown in Figure 3-1. Databases of this size and composition have been used extensively in face detection <ref> [25] </ref> [20] [17] and we keep this data format for comparison purposes.
Reference: [26] <author> K-K. Sung and T. Poggio. </author> <title> Example-based learning for view-based human face detection. A.I. </title> <type> Memo 1521, </type> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: More recently, systems for detecting unoccluded vertical frontal views of human faces in images have been developed using example-based approaches by Sung and Poggio, 1994 <ref> [26] </ref>, Moghaddam and Pentland, 1995 [15], Rowley et al., 1995 [20], Vail-lant et al., 1994 [28], and Osuna et al., 1997 [17]. These view-based approaches can handle detecting faces in cluttered scenes and have shown a reasonable degree of success when extended to handle non-frontal views. <p> The main idea in overcoming this problem of defining this extremely large negative class is the use of "bootstrapping" training (Sung and Poggio, 1994 <ref> [26] </ref>). In the context of the pedestrian detection system, after the initial training, we run the system over arbitrary images that do not contain any people.
Reference: [27] <author> T. Tsukiyama and Y. Shirai. </author> <title> Detection of the movements of persons from a sparse sequence of tv images. </title> <journal> Pattern Recognition, </journal> 18(3/4):207-13, 1985. 
Reference-contexts: We describe several relevant systems here. Most early systems that detect objects in video sequences have focused on using motion and simple shapes or constraints to find people. Tsukiyama and Shirai, 1985 <ref> [27] </ref> use simple shape descriptions to determine the location of leg motion against a white background and a distance measure is utilized to determine the correspondences between moving regions in consecutive images.
Reference: [28] <author> R. Vaillant, C. Monrocq, and Y. Le Cun. </author> <title> Original approach for the localisation of objects in images. </title> <booktitle> IEE Proc.-Vis. Image Signal Processing, </booktitle> <volume> 141(4), </volume> <month> August </month> <year> 1994. </year>
Reference-contexts: More recently, systems for detecting unoccluded vertical frontal views of human faces in images have been developed using example-based approaches by Sung and Poggio, 1994 [26], Moghaddam and Pentland, 1995 [15], Rowley et al., 1995 [20], Vail-lant et al., 1994 <ref> [28] </ref>, and Osuna et al., 1997 [17]. These view-based approaches can handle detecting faces in cluttered scenes and have shown a reasonable degree of success when extended to handle non-frontal views. The system of Sung and Poggio models a set of faces and non-faces as clusters in a high-dimensional space.
Reference: [29] <author> V. Vapnik. </author> <title> The Nature of Statistical Learning Theory. </title> <publisher> Springer Verlag, </publisher> <year> 1995. </year>
Reference: [30] <author> C. Wren, A. Azarbayejani, T. Darrell, and A. Pentland. Pfinder: </author> <title> Real-time tracking of the human body. </title> <type> Technical Report 353, </type> <institution> Media Laboratory, Massachusetts Institute of Technology, </institution> <address> 20 Ames Street, Cambridge, MA 02139, </address> <year> 1995. </year>
Reference-contexts: A Kalman filter is used to determine the exact position and pose of the walking person across multiple frames. Both these architectures assume a fixed camera and a single moving person in the image. Wren et al., 1995 <ref> [30] </ref> describe a system for the real-time tracking of the human body. The model of the person they develop uses a maximum a posterior (MAP) approach to segment a person into blobs corresponding to different regions of the body. <p> This method has been used in several systems (Hogg, 1983 [7], Wren et al., 1995 <ref> [30] </ref>) that also assume that the only moving objects will be people. It is easy to see that this is a trivial case; we can exactly recover where motion has occurred very easily. In the case of moving camera or moving background, a simple change detection strategy will not work.
Reference: [31] <author> A. Yuille, P. Hallinan, and D. Cohen. </author> <title> Feature Extraction from Faces using Deformable Templates. </title> <journal> International Journal of Computer Vision, </journal> <volume> 8(2) </volume> <pages> 99-111, </pages> <year> 1992. </year>
Reference-contexts: Typically, the systems that have been developed fall into one of two categories: template-based approaches that attempt to match or fit a prototype template to different parts of the image (Betke and Makris, 1995 [2], Yuille et al., 1992 <ref> [31] </ref>) or image invariance methods that base a matching on a set of image pattern relationships (eg. brightness levels) that, ideally, uniquely determine the objects being searched for (Sinha, 1994 [22][23]).
References-found: 31

