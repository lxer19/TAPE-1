URL: file://ftp.cis.ohio-state.edu/pub/tech-report/1997/TR48.ps.gz
Refering-URL: ftp://ftp.cis.ohio-state.edu/pub/tech-report/TRList.html
Root-URL: 
Email: fyangy,singhalg@cis.ohio-state.edu  
Title: A Comprehensive Survey of Join Techniques in Relational Databases dra-matical performance improvement of three major
Author: Yuping Yang, Mukesh Singhal 
Keyword: approach: parallel join, join index, composite index, and layered database. Key words: Relational database, query execution, join, join index, equijoin, band join, selection, index, access path, disk I/O, performance.  
Note: The main contribution of the paper is that it confirms the believe that no  radical  
Address: Columbus, OH 43210  
Affiliation: Department of Computer and Information Science, The Ohio State University  
Abstract: Equijoin between two relations is one of the basic operations in relational database and a large volume of research have been devoted to it. However, in recent years, there hasn't been a survey which objectively compares a wide spectrum of various join techniques in their relative performances. This survey compares performance and practicality between various join techniques. Main criteria for performance comparisons are disk I/Os. For comparing of practicality, criteria used are easiness and flexibility of implementation. When comparing join techniques, each join technique is evaluated in its full potential, which means that if other techniques are available to enhance this join technique while retaining the main philosophy of it, the later techniques are applied. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Knuth. </author> <title> The Art of Computer Programming: Sorting and Searching, </title> <journal> Vol. </journal> <volume> 3, </volume> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass, </address> <year> 1973. </year>
Reference-contexts: The factor 2 in the first two terms reflects the fact that the sorted relations have to be written back to disk before merging. Read and write are done mostly sequentially. If M &gt; q j S j=2, a faster sorting technique <ref> [1] </ref> can be used. Both R and S can be sorted into runs of approximately size of 2M by a sequential scan. Then these runs are merged.
Reference: [2] <author> Gotlieb L. R., </author> <title> Computing Joins of Relations. </title> <booktitle> ACM SIGMOD Conf., </booktitle> <address> San Jose, Cali-fornia, </address> <month> May </month> <year> 1975. </year>
Reference-contexts: The places marked with triangles are possible places to design new join techniques or some join techniques have already been in existence but this survey doesn't cover or simply it is not yet published at all. 4 Nested Loops Join Simple nested loops join: In this technique <ref> [2] </ref>, tuples of R are read sequentially from disks into memory. For each tuple of R, all tuples of S are read in memory at least once to have their join attribute values compared. R is called the outer relation and S is called the inner relation.
Reference: [3] <author> Blasgen M., Eswaran K.. </author> <title> On the evaluation of queries in a data base system. </title> <institution> IBM Res. Lab., </institution> <address> San Jose, CA, </address> <institution> Res. Report RJ1745, </institution> <year> 1976. </year>
Reference-contexts: Otherwise, the tuple with the smaller attribute value between the two is dropped because it has no hope to be joined with other tuples. A study by M. W. Blasgenm and K. P. Eswaran <ref> [3] </ref> shows that the sort-merge join can almost always outperform the nested loops join when no index is used. However, if there are too many duplicated join attribute values, sort-merge join can degenerate to the performance of nested loops join [41].
Reference: [4] <author> Blasgen, M. W., and Eswaran, K. P. </author> <title> Storage and access in relational databases. </title> <journal> IBM Systems Journal. </journal> <volume> Vol 16, No. 4, </volume> <year> 1977. </year>
Reference-contexts: In [46], two kinds of applications were given as examples of such applications. One is the fuzzy comparison between names or addresses, the other is the document recognition [46]. 5 Sort-Based Join sort-merge join This join technique <ref> [4, 17] </ref> sorts both joining relations on the join attributes into two sorted lists and then merges these two sorted lists. Tuples are joined on the fly in the merging phase.
Reference: [5] <author> F.P. Preparata. </author> <title> New parallel-sorting schemes. </title> <journal> IEEE. Trans. Comput. </journal> <month> C-27 (July </month> <year> 1978). </year>
Reference-contexts: In case of small data sizes, parallel sort-merge join often perform inferior to parallel nested loops join <ref> [5] </ref> because in this case, the system is not communication bounded and 27 the parallel sort-merge join cannot fully utilize all processors and memories at the later stage of joining.
Reference: [6] <author> Theo Haerder. </author> <title> Implementing a Generalized Access Path Structure for a Relational Database System. </title> <journal> ACM TODS, Vol3, </journal> <volume> N3, </volume> <month> Sept. </month> <year> 1978, </year> <pages> p 285-298. </pages>
Reference-contexts: However, this practice add extra processing time if data skew is not severe in R. 9 Structures Specially Designed for Join 9.1 Generalized Access Path Structure Idea to design special indexing structure to help join operation came as early as 1978 <ref> [6] </ref> in the form of a binary link. A binary link connects together matching tuples from both operand relations and often be implemented as chains of TIDs or physical pointers (storage addresses). <p> In a sense, a binary link is a data structure of a pre-computed join. Let R be a relation with attribute A 1 , ... , A n . In <ref> [6] </ref>, an image is defined on a individual attribute A i as "a mapping from values in A i to those tuples in R which have those values for the ith attribute". An image is implemented by an (clustered or inverted) index. In [6] the concept of image and binary link <p> In <ref> [6] </ref>, an image is defined on a individual attribute A i as "a mapping from values in A i to those tuples in R which have those values for the ith attribute". An image is implemented by an (clustered or inverted) index. In [6] the concept of image and binary link were combined to propose a combined access path structure and a generalized access path structure. <p> To further speed up the performance, each copy can be implemented by an index, for example, a B + -tree. The difference between a binary link and a join index is that in the binary link, the connection between the matching tuples are, as claimed in <ref> [6] </ref>, often implemented by chaining of TIDs or physical pointers while join index does not restrict the form of implementation. Join index can be characterized as a concept at an appropriate abstraction level. Th join index does not restrict the implementation details. <p> many relations that are mutually joinable in a relational database, join attribute values has to be duplicated many times over. 9.5 Composite B+ Tree A composite B+ tree, also called a B c tree by author [33], can be seen as a generalization of the generalized access path structure approach <ref> [6] </ref> and this approach is an improvement over the domain based internal schema approach. The idea is to create one B+ tree for each data domain. Many attributes in the database share the same data domain, so values in these attributes are indexed by the same B+ tree.
Reference: [7] <author> Babb E., </author> <title> Implementing a Relational Database by Means of Specialized hardware. </title> <journal> ACM TODS, </journal> <volume> V4, </volume> <pages> N1, </pages> <month> March </month> <year> 1979, </year> <pages> pp. 1-29. </pages>
Reference-contexts: Hash join can generally expect to outperform sort-merge join <ref> [7, 14, 17, 19, 23, 26] </ref>. However, mostly their performances differ by percentages rather than factors [54]. In [54], Graefe et al. presented a quite detailed comparison between sort based join and hash join. <p> Bit vector filtering: Join execution can be improved by using bit vectors <ref> [7, 16, 21, 25, 38] </ref> for small or medium sized joins. Before performing join, an vector of n bits is initialized and each bit is set to 0. <p> The effect of this filtering depends on data quantity, data distribution, the choice of hash function, and whether it is implemented in hardware or software (bit vectors as arrays in memory). If only one or a few bit vectors are used and implemented in hardware <ref> [7] </ref>, the filtering may be very effective for small or medium sized data files, and may not be effective if the sizes of two relations or the number of distinct attribute values are too large. <p> For large data, array of bit vector can be used to do the filtering and this array can be kept in memory while scanning S. This method actually has another name called signature method [11, 20]. This is slower than implementing filtering using special hardware <ref> [7] </ref>. Still, using signature method can achieve significant reduction of the size of S and hence speed up the join execution. A special type of bit vector is called Babb array [7]. <p> This is slower than implementing filtering using special hardware <ref> [7] </ref>. Still, using signature method can achieve significant reduction of the size of S and hence speed up the join execution. A special type of bit vector is called Babb array [7]. A boolean array is built while scan R and each bit in the array corresponds to a hash bucket. The bit is set when there 22 are tuples of R be hashed into its corresponding bucket.
Reference: [8] <author> W. Kim. </author> <title> A new way to compute the product and join of relations. </title> <booktitle> In Proc of the 1980 ACM SIGMOD Int'l Conf. on the Management of Data, </booktitle> <pages> pp. 179-187, </pages> <year> 1980. </year>
Reference-contexts: The hash table of B r needs only to be built once for the entire S. Usually, the extra CPU cost of hashing can be well justified by the savings in number of comparisons. Using rocking to reduce I/O: Rocking is proposed by Kim <ref> [8] </ref>. In nested block join, the entire inner relation S is read from disk into buffer B s each time the buffer B r is refreshed with tuples from R.
Reference: [9] <author> Bernstein, A. P., et al. </author> <title> Query Processing in a system for distributed databases (SDD-1). </title> <journal> ACM Transactions on Database Systems, </journal> <volume> Vol. 6, No. 4, </volume> <month> December </month> <year> 1981, </year> <pages> pp. 602-625. </pages>
Reference-contexts: While scan S, tuples are checked against the bits in the Babb array and dropped if the corresponding bit is not set. Semijoin: Semijoin is initially proposed in the distributed database environment to reduce the transmission of data between sites when performing join <ref> [9] </ref>. However, it can be applied to centralized system as well. The semijoin of S with R is performed as follows: 1. project R on its join attribute, obtain (R). 2. join (R) with S.
Reference: [10] <author> J. R. Goodman. </author> <title> An investigation of Multiprocessor Structures and Algorithms for Database Management. </title> <type> Technical Report ECB/ERL, </type> <institution> M81/33, University of Califor-nia at Berkeley, </institution> <year> 1981. </year> <month> 46 </month>
Reference-contexts: The performance of simple hash join is slightly better than the nested block join because of saving in CPU executions and in memory moves of data, but disk I/O cost of the two techniques are the same. Grace hash join: A Grace hash join <ref> [10, 14] </ref> technique clearly separates two phases of hash join. In the first phase, each of two relations R and S is partitioned into the same number (N ) of buckets by hashing on the join attribute and using the same hash function 1 . These buckets form N pairs.
Reference: [11] <author> G. H. Gonnet, P. A. Larson. </author> <title> External hashing with with limited internal storage. </title> <booktitle> Proc. of the ACM Symposium on Principles of Database Systems, ACM, </booktitle> <address> New York, </address> <year> 1982, </year> <pages> pp. 256-261. </pages>
Reference-contexts: For large data, array of bit vector can be used to do the filtering and this array can be kept in memory while scanning S. This method actually has another name called signature method <ref> [11, 20] </ref>. This is slower than implementing filtering using special hardware [7]. Still, using signature method can achieve significant reduction of the size of S and hence speed up the join execution. A special type of bit vector is called Babb array [7].
Reference: [12] <author> Missikoff, M. </author> <title> A domain based internal schema for relational database machines. </title> <booktitle> In ACM SIGMOD Int'l Conf. on Management of Data, </booktitle> <address> Orlando, Fla., June 2-4, 1982. </address> <publisher> ACM, </publisher> <address> New York, </address> <year> 1982, </year> <pages> pp. 215-224. </pages>
Reference-contexts: Domain Based Internal Schema Another special data structure designed to facilitate join execution is a data structure to store each join attribute domain values separately, and store pointers associated with the values in this data structure pointing to tuples of relations that have this value in attributes of this domain <ref> [12] </ref>. This data structure can achieve speed up of join execution slightly more than a join index do. However, this method favors join operation at the expense of other operations.
Reference: [13] <author> Nicholas Roussopoulos. </author> <title> View Indexing in Relational Databases. </title> <journal> ACM Transactions on Database Systems Vol. </journal> <volume> 7, No. 2, </volume> <month> June </month> <year> 1982. </year>
Reference: [14] <author> M. Kitsuregawa, H. Tanaka, and T. Moto-oka. </author> <title> Application of Hash to Data Base Machine and its Architecture. </title> <journal> New Generation Computing, </journal> <volume> vol 1, No.1, </volume> <pages> pp. 66-74, </pages> <year> 1983. </year>
Reference-contexts: The performance of simple hash join is slightly better than the nested block join because of saving in CPU executions and in memory moves of data, but disk I/O cost of the two techniques are the same. Grace hash join: A Grace hash join <ref> [10, 14] </ref> technique clearly separates two phases of hash join. In the first phase, each of two relations R and S is partitioned into the same number (N ) of buckets by hashing on the join attribute and using the same hash function 1 . These buckets form N pairs. <p> Hash join can generally expect to outperform sort-merge join <ref> [7, 14, 17, 19, 23, 26] </ref>. However, mostly their performances differ by percentages rather than factors [54]. In [54], Graefe et al. presented a quite detailed comparison between sort based join and hash join.
Reference: [15] <author> R. Sacks-Davis, K. Ramamohanarao. </author> <title> A two level superimposed coding scheme for a partial match retrieval. </title> <journal> Information Systems, </journal> <volume> Vol. 8, No. 4, </volume> <year> 1983, </year> <pages> pp. 273-280. </pages>
Reference-contexts: There have been much discussions on their relative merits. Some new database architectures and join techniques have been proposed in recent years which hold hopes to further improve the performance of join execution in relational database. These techniques include signature method <ref> [15, 31, 34] </ref>, clustering of data tuples and partition of relations [59], join index [28, 61], composite index [33], layered relational database [52], etc.
Reference: [16] <author> Bratbergsengen, Kjell. </author> <title> Hashing Methods and Relational Algebra Operations. </title> <booktitle> Proc. of the 1984 Very Large Database Conf., </booktitle> <year> 1984. </year>
Reference-contexts: Bit vector filtering: Join execution can be improved by using bit vectors <ref> [7, 16, 21, 25, 38] </ref> for small or medium sized joins. Before performing join, an vector of n bits is initialized and each bit is set to 0.
Reference: [17] <author> DeWitt, D. J., Katz, R., Olken, F., Shapiro, L., Stonebraker, M. and D. Wood. </author> <title> Implementation Techniques for Main Memory Database Systems. </title> <booktitle> Proc of the 1984 ACM SIGMOD Int'l Conf. on Management of Data, </booktitle> <pages> pp. 1-8, </pages> <address> Boston, MA, USA, </address> <month> June </month> <year> 1984. </year>
Reference-contexts: In [46], two kinds of applications were given as examples of such applications. One is the fuzzy comparison between names or addresses, the other is the document recognition [46]. 5 Sort-Based Join sort-merge join This join technique <ref> [4, 17] </ref> sorts both joining relations on the join attributes into two sorted lists and then merges these two sorted lists. Tuples are joined on the fly in the merging phase. <p> Simple hash join: This is the simplest implementation of hash join <ref> [17] </ref> and is basically a nested block join with modification that hashing is used for the in-memory processing. To be specific, first as many tuples of R as possible are read in memory an built into a hash table. <p> R j +2 j S j, and may very well outperform the Grace hash join because the Grace hash join has the extra cost of partitioning. 15 Hybrid-hash join: Instead of using extra memory space to set up more buffers as in a Grace hash join, a hybrid hash join <ref> [17] </ref> uses extra memory to do joining while partitioning. The outer relation R is hashed on the join attribute and be partitioned into N buckets R i , 0 i N 1. <p> Hash join can generally expect to outperform sort-merge join <ref> [7, 14, 17, 19, 23, 26] </ref>. However, mostly their performances differ by percentages rather than factors [54]. In [54], Graefe et al. presented a quite detailed comparison between sort based join and hash join. <p> This is shown in Figure 5. It is a well known fact that for equijoin, hash based algorithms are in general better than sort-merge join and nested block join <ref> [17, 23, 26] </ref>. The truncating-hash band join is an attempt trying to carry this performance advantage over to the band join and analytical comparisons show that this approach is successful [49]. In essence, this is a hash join facilitated by truncating.
Reference: [18] <author> W. Kiessling. </author> <title> Tunable dynamic filter algorithms for high performance database systems. </title> <booktitle> Proc. of the Int'l Workshop on High Level Computer Architecture, </booktitle> <month> May 84, 6.10-6.20. </month>
Reference-contexts: Not only join attribute values themselves, but also signatures made from join attribute values can be used to filter out unmatchable tuples of S while scan S. This is a similar but more generalized method than semijoin. Other more general methods of semijoins can be found in <ref> [18, 26] </ref>. Eliminating random I/O: Hash join has two phases: partitioning and joining phases. In [62], disk I/Os are divided into four phases: PR, PW, JR, JW. PR represents partitioning phase read, PW represents partitioning phase write, JR represents joining phase read, and JW represents joining phase write.
Reference: [19] <author> K. Bratbergsengen. </author> <title> Hashing methods and relational algebra operations. </title> <booktitle> In Proc. of the Tenth Int'l Conf. on Very Large Data Bases, </booktitle> <pages> pp. 323-333, </pages> <address> Singapore, </address> <month> August </month> <year> 1984. </year>
Reference-contexts: Hash join can generally expect to outperform sort-merge join <ref> [7, 14, 17, 19, 23, 26] </ref>. However, mostly their performances differ by percentages rather than factors [54]. In [54], Graefe et al. presented a quite detailed comparison between sort based join and hash join.
Reference: [20] <author> P. A. Larson, A. Kaila. </author> <title> File organization: Implementation of a method guaranteeing retrieval in one access. </title> <journal> Commun. ACM 27, </journal> <volume> 7(1984), </volume> <pages> pp. 670-677. </pages>
Reference-contexts: For large data, array of bit vector can be used to do the filtering and this array can be kept in memory while scanning S. This method actually has another name called signature method <ref> [11, 20] </ref>. This is slower than implementing filtering using special hardware [7]. Still, using signature method can achieve significant reduction of the size of S and hence speed up the join execution. A special type of bit vector is called Babb array [7].
Reference: [21] <author> P. Valduriez, G. Gardarin. </author> <title> Join and Semi-Join Algorithms for a Multiprocessor Database Machine, </title> <journal> ACM Transactions on Database Systems, </journal> <volume> Vol 9, No. 1, </volume> <year> 1984. </year> <month> 47 </month>
Reference-contexts: Bit vector filtering: Join execution can be improved by using bit vectors <ref> [7, 16, 21, 25, 38] </ref> for small or medium sized joins. Before performing join, an vector of n bits is initialized and each bit is set to 0.
Reference: [22] <author> P. Valduriez, G. Gardarin. </author> <title> Join and Semijoin Algorithms for a Multiprocessor Database Machine. </title>
Reference-contexts: It is assumed that each processor has its own local memory and disk <ref> [22] </ref> as shown in Figure 2, and pairwise interprocessor communication cost (P ICC) is significant enough to be considered in the overall join cost. <p> So in case that the system tends to be communication bandwidth bounded, parallel hash join performs even better. Parallel hash join is the best among three major classes of parallel join techniques <ref> [22] </ref> in case of large data and little data skew.
Reference: [23] <author> D. J. DeWitt, R. Gerber. </author> <title> Multiprocessor Hash-Based Join Algorithms. </title> <booktitle> Proc. of the 11th Int'l Conf. on Very Large Data Bases, </booktitle> <address> Stockholm, </address> <year> 1985, </year> <pages> pp. 151-164. </pages>
Reference-contexts: Hash join can generally expect to outperform sort-merge join <ref> [7, 14, 17, 19, 23, 26] </ref>. However, mostly their performances differ by percentages rather than factors [54]. In [54], Graefe et al. presented a quite detailed comparison between sort based join and hash join. <p> This is shown in Figure 5. It is a well known fact that for equijoin, hash based algorithms are in general better than sort-merge join and nested block join <ref> [17, 23, 26] </ref>. The truncating-hash band join is an attempt trying to carry this performance advantage over to the band join and analytical comparisons show that this approach is successful [49]. In essence, this is a hash join facilitated by truncating.
Reference: [24] <author> Arie Segev. </author> <title> Optimization of join operations in horizontally partitioned database systems. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> Vol. 11, No. 1, </volume> <month> March </month> <year> 1986, </year> <pages> Pages 48-80. </pages>
Reference: [25] <author> L. Mackert and G. Lohman. </author> <title> "R* Optimizer Validation and Performance Evaluation for Local Queries", </title> <booktitle> Proc. of 1986 ACM SIGMOD Conf., </booktitle> <address> Washington, DC, </address> <month> May </month> <year> 1986. </year>
Reference-contexts: Bit vector filtering: Join execution can be improved by using bit vectors <ref> [7, 16, 21, 25, 38] </ref> for small or medium sized joins. Before performing join, an vector of n bits is initialized and each bit is set to 0.
Reference: [26] <author> L. D. Shapiro. </author> <title> Join Processing in Database Systems with Large Main Memories. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> Vol. 11, No. 3, </volume> <month> September </month> <year> 1986, </year> <pages> pp. 239-264. </pages>
Reference-contexts: Hash join can generally expect to outperform sort-merge join <ref> [7, 14, 17, 19, 23, 26] </ref>. However, mostly their performances differ by percentages rather than factors [54]. In [54], Graefe et al. presented a quite detailed comparison between sort based join and hash join. <p> Not only join attribute values themselves, but also signatures made from join attribute values can be used to filter out unmatchable tuples of S while scan S. This is a similar but more generalized method than semijoin. Other more general methods of semijoins can be found in <ref> [18, 26] </ref>. Eliminating random I/O: Hash join has two phases: partitioning and joining phases. In [62], disk I/Os are divided into four phases: PR, PW, JR, JW. PR represents partitioning phase read, PW represents partitioning phase write, JR represents joining phase read, and JW represents joining phase write. <p> This is shown in Figure 5. It is a well known fact that for equijoin, hash based algorithms are in general better than sort-merge join and nested block join <ref> [17, 23, 26] </ref>. The truncating-hash band join is an attempt trying to carry this performance advantage over to the band join and analytical comparisons show that this approach is successful [49]. In essence, this is a hash join facilitated by truncating.
Reference: [27] <author> Sacco, G. M. </author> <title> Fragmentation: A technique for efficient query processing. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> Vol. 11, No. 2, </volume> <year> 1986, </year> <pages> pp. 113-133. </pages>
Reference: [28] <author> Patrick Valduriez. </author> <title> Join Indexes. </title> <journal> ACM TODS, V12, </journal> <volume> N2, </volume> <month> June </month> <year> 1987, </year>
Reference-contexts: Some new database architectures and join techniques have been proposed in recent years which hold hopes to further improve the performance of join execution in relational database. These techniques include signature method [15, 31, 34], clustering of data tuples and partition of relations [59], join index <ref> [28, 61] </ref>, composite index [33], layered relational database [52], etc. <p> heavy data structure: each node of it contains a lot of information and in the worst case, the number of nodes could be the cross product of the numbers of tuples in two joining relations. 35 9.2 Join Index Similar idea re-appeared in 1987 in the form of join index <ref> [28] </ref>, which is simpler than the generalized access path structure. Join index is a relation with only two attributes. Each tuple in the join index contains two TIDs of two matching tuples from the two operand relations. <p> These PIDs are stored along with the tuples of this relation and such is the case for both relations. Each tuple can have multiple PIDs. Let this PID data structure be called the join page index to emphasis the similarity with the join index <ref> [28] </ref>. Of course, join page index can be stored separately from the relations, just like a join index. Each of nested loops join, sort-merge join and hybrid hash join has its own counterparts in page indexing join techniques.
Reference: [29] <author> A. Kumar and M. Stonebraker. </author> <title> The Effect of Join Selectivities on Optimal Nesting Order. </title> <booktitle> SIGMOD Record, Vol16, N1, </booktitle> <pages> p 28-41. </pages> <month> March </month> <year> 1987. </year>
Reference: [30] <author> H. Kang, N. Roussopoulos. </author> <title> Using 2-way Semijoins in Distributed Query Processing. </title> <booktitle> IEEE. Proc. of 3rd Int'l Conf on Data Engineering, </booktitle> <year> 1987. </year>
Reference: [31] <author> R. Sacks-Davis, A. Kent, K. Ramamohanarao. </author> <title> Multikey Access Methods Based on Superimposed Coding Techniques. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> Vol. 12, No.4, </volume> <year> 1987, </year> <pages> pp. 655-696. </pages>
Reference-contexts: There have been much discussions on their relative merits. Some new database architectures and join techniques have been proposed in recent years which hold hopes to further improve the performance of join execution in relational database. These techniques include signature method <ref> [15, 31, 34] </ref>, clustering of data tuples and partition of relations [59], join index [28, 61], composite index [33], layered relational database [52], etc.
Reference: [32] <author> M. Nakayama, M. Kitsuregawa, and M. Takagi. </author> <title> Hash-partitioned join method using dynamic destaging strategy. </title> <booktitle> In Proc of the 14th Int'l Conf. on Very Large Data Bases, </booktitle> <pages> pp. 468-478, </pages> <address> Los Angeles, California, USA, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: This strategy could have problem since the anchor bucket may be too large to fit in memory or too small to be effective. Because usually the data distribution is unknown before join, the decision to choose the anchor bucket should be delayed as much as possible <ref> [32] </ref>. In DDS, the intended bucket size is chosen to be much smaller than the intended partitions to avoid bucket overflow. <p> memory in the joining phase is [62]: H s X C (read write group of t) = H s ( j R j + 1) fl A seq (20) It is claimed in [62] that the performance of their technique is several times better than that of Dynamic-Hashing GRACE Hash-join <ref> [32, 35] </ref>. Orders of executions: It has long been accepted that if a query has projection, selection and join operations, it is usually more efficient to perform projection and selection before performing join.
Reference: [33] <author> B. C. Desai. </author> <title> Performance of a Composite Attribute and Join Index. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. 15, No. 2, </volume> <year> 1989. </year>
Reference-contexts: These techniques include signature method [15, 31, 34], clustering of data tuples and partition of relations [59], join index [28, 61], composite index <ref> [33] </ref>, layered relational database [52], etc. <p> Not only that, if there are many relations that are mutually joinable in a relational database, join attribute values has to be duplicated many times over. 9.5 Composite B+ Tree A composite B+ tree, also called a B c tree by author <ref> [33] </ref>, can be seen as a generalization of the generalized access path structure approach [6] and this approach is an improvement over the domain based internal schema approach. The idea is to create one B+ tree for each data domain.
Reference: [34] <author> Dik Lun Lee, Chun-wu Leng. </author> <title> Partitioned Signature File: Design Issues and Performance Evaluation. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> Vol. 7, </volume> <pages> No.2, </pages> <month> April </month> <year> 1989, </year> <pages> pp. 158 - 180. </pages>
Reference-contexts: There have been much discussions on their relative merits. Some new database architectures and join techniques have been proposed in recent years which hold hopes to further improve the performance of join execution in relational database. These techniques include signature method <ref> [15, 31, 34] </ref>, clustering of data tuples and partition of relations [59], join index [28, 61], composite index [33], layered relational database [52], etc.
Reference: [35] <author> M. Kitsuregawa, M. Nakayama, and M. Takagi. </author> <title> The effect of bucket size tuning in the dynamic hybrid grace hash join method. </title> <booktitle> Proc. of the 15th Int'l Conf. on Very Large Data Bases, </booktitle> <pages> pp. 257-266, </pages> <address> Amsterdam, </address> <year> 1989. </year>
Reference-contexts: memory in the joining phase is [62]: H s X C (read write group of t) = H s ( j R j + 1) fl A seq (20) It is claimed in [62] that the performance of their technique is several times better than that of Dynamic-Hashing GRACE Hash-join <ref> [32, 35] </ref>. Orders of executions: It has long been accepted that if a query has projection, selection and join operations, it is usually more efficient to perform projection and selection before performing join.
Reference: [36] <author> K. Li, P. Hudak. </author> <title> Memory coherence in shared virtual memory systems. </title> <journal> ACM Transaction on Computer Systems, </journal> <volume> 7(4), </volume> <month> November </month> <year> 1989. </year>
Reference-contexts: Compared with [39], the insensitivity to data skew reported in [55] not only comes from the difference between architectures of SM and SN , but also comes from the fact the in [55], fewer processors are used in the parallel machine. 8.3 Shared Virtual Memory Shared virtual memory <ref> [36, 42] </ref> SV M provides a single virtual address space in a shared nothing parallel machine. The main reasons that SV M is useful are [51]: 1. ease of coding 2. ease of conceptualization of shared data structures.
Reference: [37] <author> M. S. Lakshmi, P. S. Yu. </author> <title> Limiting Factors of Join Performance on Parallel Processors. </title> <booktitle> IEEE. Proc. of 5th Int'l Conf. on Data Engineering, </booktitle> <year> 1989. </year>
Reference-contexts: These factors can be analyzed in static. Other important factors are sensitivity to data skew in the join attribute values and the stochastic nature of join executions <ref> [37] </ref>. These factors are statistic in nature and are usually analyzed through simulations. Comparisons of three classes of parallel joins: The nested loops join can be fully parallelized. The speed up of join execution is almost linear with respect to the number of processors. <p> In <ref> [37] </ref>, it is shown that with 5% data skew, even if the collective processing power of a multiprocessor architecture is 10 times that of a single processor architecture, there can be no performance advantage of using parallel hash join. In [37], total of 300 processors and each processor has 2 MIPS <p> In <ref> [37] </ref>, it is shown that with 5% data skew, even if the collective processing power of a multiprocessor architecture is 10 times that of a single processor architecture, there can be no performance advantage of using parallel hash join. In [37], total of 300 processors and each processor has 2 MIPS were used in a parallel architecture. This is compared to a processor of 60 MIPS in a single processor architecture. <p> The stochastical join processing time also exact a similar penalty on performance of parallel hash join. One needs to be cautious about the conclusion of very high performance sensitivity to data skew and variations of processing time obtained in <ref> [37] </ref>. They used a large number of very small processor to compare with a very fast processor. If the number of processors be lowered and the number of processing capacity of each processor be increased, the sensitivity as shown in their experiment can be much reduced.
Reference: [38] <author> D. Schneider and D. DeWitt. </author> <title> A Performance Evaluation of Four Parallel Join Algorithms in a Shared-Nothing Multiprocessor Environment. </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <year> 1989. </year>
Reference-contexts: Bit vector filtering: Join execution can be improved by using bit vectors <ref> [7, 16, 21, 25, 38] </ref> for small or medium sized joins. Before performing join, an vector of n bits is initialized and each bit is set to 0.
Reference: [39] <author> M. S. Lakshmi, P. S. Yu. </author> <title> Effectiveness of Parallel Joins. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> Vol. 2, No. 4, </volume> <month> December </month> <year> 1990. </year>
Reference-contexts: Effects of using semijoin as preprocessing: Semijoin used in a shared-nothing parallel machine for preprocessing in parallel hash join can be implemented as follows <ref> [39] </ref>. Let R and S be two relations in the join and j R jj S j. In disk of each processor i resides R i which is a partition of R and S i which is a partition of S. <p> Otherwise, the second approach wins. The benefit of using semijoin preprocessing is also very sensitive to data skew. It is shown that with even 5% data skew, the use of semijoin has only a marginal effect (figure 14 in <ref> [39] </ref>). The reason for this is that data skew tends to move the bottleneck of processing from communication network to individual processors that are overburdened. Again, here one needs to be cautious about the conclusion made in [39] since it is drawn upon a parallel machine with a large number of <p> skew, the use of semijoin has only a marginal effect (figure 14 in <ref> [39] </ref>). The reason for this is that data skew tends to move the bottleneck of processing from communication network to individual processors that are overburdened. Again, here one needs to be cautious about the conclusion made in [39] since it is drawn upon a parallel machine with a large number of very small processors. <p> Compared with <ref> [39] </ref>, the insensitivity to data skew reported in [55] not only comes from the difference between architectures of SM and SN , but also comes from the fact the in [55], fewer processors are used in the parallel machine. 8.3 Shared Virtual Memory Shared virtual memory [36, 42] SV M provides
Reference: [40] <author> E. J. Shekita, M. J. Carey. </author> <title> A Performance Evaluation of Pointer-Based Joins. </title> <booktitle> Proc. of 1990 ACM SIGMOD Int'l Conf. on Management of Data, </booktitle> <year> 1990. </year>
Reference-contexts: However, the drawback is that both the generalized access path structure and the join index could require very large storage space. 9.3 Join Page Index This technique is a generalization and modification of the pointer-based join techniques proposed in <ref> [40] </ref>. Though pointer-based join techniques are mostly be considered for Object-oriented databases, they could be used to improve the performance of relational databases. In relational databases, a pointer to a tuple can be just the physical address of the tuple. <p> In relational databases, a pointer to a tuple can be just the physical address of the tuple. Let this address be called a physical TID, or simply TID. Such pointers could exist in forms of foreign key-primary key relationship. In <ref> [40] </ref>, it is claimed that pointer-based join techniques are not suited for select-project joins in which the selection 36 predicate on one of the relation is a more restrictive one, since in this case, the most efficient way to execute join is first to perform selection, and then travel opposite to <p> Page indexing PID-partitioning join (P P P ): To use this technique <ref> [40] </ref>, the PIDs of tuples of S need to be stored separately from S. First the PIDs of S are read into memory and sorted, and then partitioned into B + 1 partitions L i (0 i B) by their PID values.
Reference: [41] <author> H. Zeller and J. Gray. </author> <title> An adaptive hash join algorithm for multiuser environments. </title> <booktitle> In Proc of the 16th Int'l Conf. on Very Large Data Bases, </booktitle> <pages> pp. 186-197, </pages> <address> Brisbane, Australia, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: W. Blasgenm and K. P. Eswaran [3] shows that the sort-merge join can almost always outperform the nested loops join when no index is used. However, if there are too many duplicated join attribute values, sort-merge join can degenerate to the performance of nested loops join <ref> [41] </ref>. In sort-merge join, it is possible to take advantage of prefetching in the merging phase since tuples are sorted. This feature makes difference in performance if the memory space of the computer is large and fast disk devices are deployed. <p> Adaptive hash join (ADH): This method is proposed by Zeller and Gray <ref> [41] </ref> and is similar to DDS, and can be considered to be a generalization of it. This method allows change of memory size during join execution. In ADH, the number of buckets is fixed and is quite large. <p> This is because in hash base join, for all the individual partitions of one relation to be fit in memory, the maximal partition of that relation must be able to fit in the memory. This is not a concern for sort based join. * number of duplicated values <ref> [41] </ref>. If there are a large number of duplicated join attribute values, at least the sort-merge join is able to degenerate to the performance of the nested block join while hash join can perform even worse than nested block join due to high overhead caused by heavy hash collisions.
Reference: [42] <author> J.B. Carter, J.K. Bennet, W. Zwaenepoel. </author> <title> Implementation and performance of Munin. </title> <booktitle> Proc. of the 1991 Symp. on Operating System Principles, </booktitle> <year> 1991. </year>
Reference-contexts: Compared with [39], the insensitivity to data skew reported in [55] not only comes from the difference between architectures of SM and SN , but also comes from the fact the in [55], fewer processors are used in the parallel machine. 8.3 Shared Virtual Memory Shared virtual memory <ref> [36, 42] </ref> SV M provides a single virtual address space in a shared nothing parallel machine. The main reasons that SV M is useful are [51]: 1. ease of coding 2. ease of conceptualization of shared data structures.
Reference: [43] <author> D. DeWitt, J. Naughton, D. Schneider. </author> <title> An Evaluation of Non-Equijoin Algorithms. </title> <booktitle> Proc. of 17th Int'l Conf. on Very Large Data Bases, </booktitle> <address> Barcelona, Spain, </address> <month> September </month> <year> 1991, </year> <pages> pp. 443-542. </pages>
Reference-contexts: Main criterion for performance comparison is the amount of disk I/Os for each join technique and the criterion for practicality is the easiness and flexibility (which often means stability in a dynamic environment) of implementation. Band join as a terminology was introduced in 1991 <ref> [43] </ref> and can be regarded as an extension of equijoin in ordered data domain. This is discussed in Section 10 due to its similarity to equijoin. 2 2 Assumptions When comparing and evaluating join techniques, many techniques are evaluated according to their principal philosophies. <p> As band join is very similar to the equijoin both in concept and in execution, it is likely that band join will become a standard operation in future commercial relational databases. While a large number of papers have been presented for processing equijoins, only a few papers <ref> [43, 49, 60] </ref> are devoted for processing band joins. Most of the band join algorithms require sorting of at least one of the relation. Truncating-hash band join [49] is an attempt trying to do away with the sorting and has considerably improved the speed of band join processing.
Reference: [44] <author> J. Cheng, D. Haderle, R. Hedges, B. R. Iyer, T. Messinger, C. Mohan, Y. Wang. </author> <title> An Efficient Hybrid Join Algorithm: A DB2 Prototype. </title> <booktitle> IEEE. 7th Int'l Conf. on Data Engineering, </booktitle> <year> 1991. </year>
Reference-contexts: Compared with formula 11 and 12, it is clear that distributive join outperforms sort-merge join if memory is less than q j R j and R is much smaller than S. Combining indexing with sorting A hybrid join technique was proposed <ref> [44] </ref> to combine the advantages of indexing and sorting. It is assumed that R is unsorted and there is an index on the join attribute of S. The basic idea is to sort R and access S via index. TIDs are fetched along with join attribute values of the S.
Reference: [45] <author> Eugene Shekita. </author> <title> High-Performance Implementation Techniques for Next-Generation Database Systems. </title> <type> Ph.D thesis, </type> <institution> Computer Science Technical Report #1026, 1990, University of Wisconsin at Madison. </institution> <month> 49 </month>
Reference: [46] <author> Joel L. Wolf, Balakrishna R. lyer, Krishna R. Pattipati, John Turek. </author> <title> Optimal Buffer Partitioning for the Nested Block Join Algorithm. </title> <booktitle> IEEE. Proc. of 7th International Conference on Data Engineering. </booktitle> <address> April 8-12, 1991, Kobe, Japan. </address>
Reference-contexts: There are many improvements of it have been proposed and major improvements have been discussed in the rest of this section. Blocked nested loops join: It is sometimes called the nested block join <ref> [46] </ref>. It is a very effective and straightforward improvement over the simple nested loops join. The number of times the inner relation S is read into memory is equal to the number of times the memory is refreshed with tuples of the outer relation R. <p> When the available memory of the computer is large but not so large to hold any of the joining relations, this technique can significantly reduce the disk I/Os over that of the nested loops join <ref> [46] </ref>. The word "block" in nested block join refers to the chunk of tuples from either relation that are read and reside in memory in batch, and should not be confused with the block that is the unit of disk storage. <p> Also, nested loops join (or nested block join) is the only well-known join technique that works for complex join predicates <ref> [46] </ref>. For many applications, there is no partial order among values of join attributes, therefore neither sort-merge join nor hash join, nor any indexing scheme can be effectively 10 used, and in this case the nested loops (block) join is the only available method. In [46], two kinds of applications were <p> works for complex join predicates <ref> [46] </ref>. For many applications, there is no partial order among values of join attributes, therefore neither sort-merge join nor hash join, nor any indexing scheme can be effectively 10 used, and in this case the nested loops (block) join is the only available method. In [46], two kinds of applications were given as examples of such applications. One is the fuzzy comparison between names or addresses, the other is the document recognition [46]. 5 Sort-Based Join sort-merge join This join technique [4, 17] sorts both joining relations on the join attributes into two sorted lists and <p> In <ref> [46] </ref>, two kinds of applications were given as examples of such applications. One is the fuzzy comparison between names or addresses, the other is the document recognition [46]. 5 Sort-Based Join sort-merge join This join technique [4, 17] sorts both joining relations on the join attributes into two sorted lists and then merges these two sorted lists. Tuples are joined on the fly in the merging phase. <p> This feature makes difference in performance if the memory space of the computer is large and fast disk devices are deployed. Sort-merge join is useful for joins between large relations without indexing supports <ref> [46] </ref>, especially when the join predicate does not offer much filtering (the join result is large). Sort-merge join technique has an additional advantage over nested loops join in that it can efficiently handle inequality join.
Reference: [47] <author> M. Negri and G. Pelagatti. </author> <title> Distributive Join: A New Algorithm for Joining Relations. </title> <journal> ACM Transactions on Databases, </journal> <volume> Vol. 16, No. 4, </volume> <month> December </month> <year> 1991, </year> <pages> pp. 655-669. </pages>
Reference-contexts: Negri and G. Pelagatti <ref> [47] </ref>. This method tries to save some sorting work by only sorting one of the relations completely, and the other relation is only partitioned.
Reference: [48] <author> D.J. DeWitt, J.F. Naughton, D.A. Schneider et al. </author> <title> The Gamma database machine project. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2(1), </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: To reduce the effect of data skew in the partitioning phase, in building relation R, Shatdal et al. suggested to use the idea proposed in <ref> [48] </ref>, which is to use range partitioning instead of hashing. The cutoff values that ensures approximate equal number of tuples in each range can be obtained by sampling.
Reference: [49] <author> Valery Soloviev. </author> <title> A Truncating Hash Algorithm for Processing Band-Join Queries. </title> <booktitle> IEEE. Proc. 9th Int'l Conf. on Data Engineering, </booktitle> <year> 1993. </year>
Reference-contexts: As band join is very similar to the equijoin both in concept and in execution, it is likely that band join will become a standard operation in future commercial relational databases. While a large number of papers have been presented for processing equijoins, only a few papers <ref> [43, 49, 60] </ref> are devoted for processing band joins. Most of the band join algorithms require sorting of at least one of the relation. Truncating-hash band join [49] is an attempt trying to do away with the sorting and has considerably improved the speed of band join processing. <p> While a large number of papers have been presented for processing equijoins, only a few papers [43, 49, 60] are devoted for processing band joins. Most of the band join algorithms require sorting of at least one of the relation. Truncating-hash band join <ref> [49] </ref> is an attempt trying to do away with the sorting and has considerably improved the speed of band join processing. The essential idea of the truncating-hash band join is to group 41 data values that are near one another. <p> As its counterpart equijoin, truncating-hash band join has two phases: the building phase and the joining phase. In the building phase, a tuple t R from R first has its join attribute value t R :A be truncated <ref> [49] </ref>: r i = t R :A ((t R :A)mod (c 1 + c 2 )) (38) into bucket h i of a hash table. Collisions are resolved by chaining values in the same bucket. <p> The truncating-hash band join is an attempt trying to carry this performance advantage over to the band join and analytical comparisons show that this approach is successful <ref> [49] </ref>. In essence, this is a hash join facilitated by truncating. A later improvement of the sort-merge band join [60] by H. Lu and K.-L. Tan appeared to offer competitive performance. It is essentially a sort-merge technique.
Reference: [50] <author> H. Pang, M. J. Carey, and M. Livny. </author> <title> Partially preemptible hash joins. </title> <booktitle> In Proc of the 1993 ACM SIGMOD Int'l Conf. on the Management of Data, </booktitle> <pages> pp. 59-68, </pages> <address> Washington, DC, USA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: ADH basically follows the same philosophy as that of DDS. Split of buffers is the main new feature added. Partially preemptible hash join (P P HJ ): A class of partially preemptible hash joins were proposed in <ref> [50] </ref>. DDS and ADH can be regarded as restricted versions of P P HJ. Here we only discuss the most sophisticated version of it, i.e., with dynamic expansion and contraction of memory buffers and prioritized spooling policy, and name it P P HJ. <p> Experiments <ref> [50] </ref> shows that if memory availability fluctuates, hybrid hash does not have a satisfactory performance. Unless memory availability fluctuates too fast, P P HJ has a substantial better performance than DDS and ADH in a wide variety of parameter settings.
Reference: [51] <author> A. Shatdal and J. F. Naughton. </author> <title> Using Shared Virtual Memory for Parallel Join Processing. </title> <booktitle> Proc. of 1993 ACM SIGMOD Int'l Conf. on Management of Data, </booktitle> <year> 1993, </year> <pages> pp. 119-128. </pages>
Reference-contexts: The current trend in technology is that the share-nothing architecture is wining up hand among different parallel architectures because the easiness in scalability and the high bandwidth (up to 200MB/s) in interprocessor network <ref> [51] </ref>. In analyzing parallel join, we distinguish between I/O cost and time cost. <p> The main reasons that SV M is useful are <ref> [51] </ref>: 1. ease of coding 2. ease of conceptualization of shared data structures. Knowing the sensitivity of parallel hash join to data skew, Shatdal et al. proposed a parallel join technique using shared virtual memory [51] to alleviate the effect of data skew in S, the probing relation. <p> The main reasons that SV M is useful are <ref> [51] </ref>: 1. ease of coding 2. ease of conceptualization of shared data structures. Knowing the sensitivity of parallel hash join to data skew, Shatdal et al. proposed a parallel join technique using shared virtual memory [51] to alleviate the effect of data skew in S, the probing relation. The novice is in the joining phase. For a processor p 1 finished its own share of work ahead of others, it randomly pick a busy processor, say p 2 , to help out.
Reference: [52] <author> J. Han, Y. Fu and R.T. Ng. </author> <title> Cooperative Query Answering Using Multiple Layered Databases. </title> <booktitle> Proc. of the 2nd Int'l Conf. on Cooperative Information Systems, </booktitle> <address> Toronto, Canada, </address> <month> May </month> <year> 1994. </year> <pages> pp. 47-58. </pages>
Reference-contexts: These techniques include signature method [15, 31, 34], clustering of data tuples and partition of relations [59], join index [28, 61], composite index [33], layered relational database <ref> [52] </ref>, etc. Essentially, the improvements these new techniques made are either better organizing of physical storage of data on the disk to take advantage of some special cases such as sequential disk accesses, or adding some new clever indexing schemes to gain faster access to specified data values.
Reference: [53] <author> Goetz Graefe. Sort-Merge-Join: </author> <title> An Idea Whose Time Has(h) Passed ? IEEE. </title> <booktitle> 10th Int'l Conf. on Data Engineering, </booktitle> <year> 1994. </year>
Reference: [54] <author> G. Graefe, A. Linville, L. Shapiro. </author> <title> Sort vs. Hash Revisited. </title> <journal> IEEE. Transactions on Knowledge and Data Engineering, Vol.6, </journal> <volume> No.6, </volume> <month> December, </month> <year> 1994. </year>
Reference-contexts: All other join techniques in the left column assume either order exist among attribute values or grouping or partition is possible. The distinct advantage of the hybrid hash join is that it utilizes memory buffer as much as possible. Since hashing and sorting are complimentary methods, in <ref> [54] </ref>, the same idea used in hybrid hash join was applied to sort based join techniques. <p> Hash join can generally expect to outperform sort-merge join [7, 14, 17, 19, 23, 26]. However, mostly their performances differ by percentages rather than factors <ref> [54] </ref>. In [54], Graefe et al. presented a quite detailed comparison between sort based join and hash join. Their conclusion is that these two classes of join techniques are to a large extent complimentary to each other. The duality stems from the fact that hashing is the opposition of merging. <p> Hash join can generally expect to outperform sort-merge join [7, 14, 17, 19, 23, 26]. However, mostly their performances differ by percentages rather than factors <ref> [54] </ref>. In [54], Graefe et al. presented a quite detailed comparison between sort based join and hash join. Their conclusion is that these two classes of join techniques are to a large extent complimentary to each other. The duality stems from the fact that hashing is the opposition of merging.
Reference: [55] <author> T.P. Martin, P.-A. Larson, and V. Deshpande. </author> <title> Parallel Hash-Based Join Algorithms for a Shared-Everything Environment. </title> <journal> IEEE Transactions on Knowledge and Data Engineering. </journal> <volume> Vol. 6, No. 5, </volume> <month> October </month> <year> 1994. </year>
Reference-contexts: The above analysis shows that with or without sufficient communication bandwidth, parallel hash join generally outperforms other two major parallel join techniques. So here we concentrate our attention only on parallel hash join. In <ref> [55] </ref> a SM with up to 10 processors was used to test parallel join techniques. Three parallel hash join techniques were tried: Hash loops, Grace and Hybrid hash. Parallel Hash loops join reads as many blocks of R (the smaller relation) as possible in memory. <p> The similar explanation can be given to the second term. The third term is the time to write the join results. 32 Shared I/O channels Although CPU time were considered in <ref> [55] </ref>, it is still the I/O time that dominate the overall time of join. <p> The join execution is for most part I/O bounded due to high combined processing capacity of using many processors. This is confirmed by <ref> [55] </ref>. With their parameter setting, they found that there is little effect on performance in increasing number of processors-of course, it is I/O bounded. <p> The response time of Hash loops join and Hybrid hash join reduced substantially when the amount of memory increases while this increase has virtually no effects on Grace hash join- this is exact as the behavior of a single processor machine. Nevertheless, some very useful observations from <ref> [55] </ref> are worth mentioning with regard to their influences on performance: * it is important to use pointers as much as possible to reduce moving tuples in the memory. * locking granularity is an extremely important issue in SM . <p> Compared with [39], the insensitivity to data skew reported in <ref> [55] </ref> not only comes from the difference between architectures of SM and SN , but also comes from the fact the in [55], fewer processors are used in the parallel machine. 8.3 Shared Virtual Memory Shared virtual memory [36, 42] SV M provides a single virtual address space in a shared <p> Compared with [39], the insensitivity to data skew reported in <ref> [55] </ref> not only comes from the difference between architectures of SM and SN , but also comes from the fact the in [55], fewer processors are used in the parallel machine. 8.3 Shared Virtual Memory Shared virtual memory [36, 42] SV M provides a single virtual address space in a shared nothing parallel machine.
Reference: [56] <author> D. K. Shin, A. C. Meltzer. </author> <title> A New Join Algorithm. </title> <journal> ACM SIGMOD Record, </journal> <volume> Vol. 23, No. 4, </volume> <month> December </month> <year> 1994. </year> <month> 50 </month>
Reference-contexts: The reduction of execution time comes mostly from dynamic expansion and contraction of buffers. The priority spooling also has some effect on reduction of execution time. Shin's join algorithm:(SHIN ) In SHIN <ref> [56] </ref>, both joining relations are repeatedly divided by up to five statistically independent hash functions. The number five is not a magic number and it can be adjusted to other appropriate numbers. <p> For example, if each hash table has 256 buckets and there are five hash functions, then 256 5 is a sufficiently large number. Because SHIN uses an extensive and repeated hashing process, in <ref> [56] </ref> it is recommended to use linked list instead of array data structure for tuple storage in buckets. SHIN does not need preprocess to estimate hash table sizes. It sets up the fixed number of fixed hash table buckets.
Reference: [57] <author> J. Vaghani, K. Ramamohanarao, D. B. Kemp, Z. Somogyi, P. J. Stuckey, T. S. Leask, and J. Harland. </author> <title> The Aditi deductive database system. </title> <journal> The VLDB journal, </journal> <volume> 3(2) </volume> <pages> 245-288, </pages> <year> 1994. </year>
Reference: [58] <author> W. P. Yan, P.-A. Larson. </author> <title> Performing Group-By before Join. </title> <booktitle> IEEE Proc. of 10th Int'l Conf. on Data Engineering, </booktitle> <year> 1994. </year>
Reference-contexts: This practice may greatly reduce the size of data entering join 24 and since join is the most expensive operations among all relational algebraic operations, the overall execution time of query may be greatly reduced. Only recently the order of executions between join and group-by has been investigated <ref> [58] </ref>. The benefit to push down group-by is similar to push down executions of selection and projection. <p> A difficulty that is special to exchange order of group-by and join is that the exchange may not always be valid and the condition under which the exchange is valid could be very expensive and even impossible to test <ref> [58] </ref>. So, in [58] a fast algorithm to test a sufficient condition of the validity of order exchange is developed. 8 Parallelism and Multiprocessors The parallel join techniques can be employed depends very much on the hardware architectures. <p> A difficulty that is special to exchange order of group-by and join is that the exchange may not always be valid and the condition under which the exchange is valid could be very expensive and even impossible to test <ref> [58] </ref>. So, in [58] a fast algorithm to test a sufficient condition of the validity of order exchange is developed. 8 Parallelism and Multiprocessors The parallel join techniques can be employed depends very much on the hardware architectures.
Reference: [59] <author> Evan Philip Harris. </author> <title> Towards Optimal Storage Design for Efficient Query Processing in Relational Database Systems. </title> <type> PhD thesis, </type> <institution> 1995, Department of Computer Science, The University of Melbourne, </institution> <address> Parkville, Victoria 3052, Australia. </address>
Reference-contexts: Some new database architectures and join techniques have been proposed in recent years which hold hopes to further improve the performance of join execution in relational database. These techniques include signature method [15, 31, 34], clustering of data tuples and partition of relations <ref> [59] </ref>, join index [28, 61], composite index [33], layered relational database [52], etc. <p> The name rocking comes from the fact that the reading of S file is done alternatively from the top and from the bottom. Another implementation of the rocking technique <ref> [59] </ref> is to read S file in a circular manner. This implementation could be useful if forward access is more efficient than backward access, or if backward access is simply impossible. Assume there are m blocks in S file and buffer B s can hold up to 100 blocks.
Reference: [60] <author> H. Lu and K.-L. Tan. </author> <title> On Sort-Merge Algorithm for Band Joins. </title> <journal> IEEE. Transactions on Knowledge and Data Engineering, </journal> <volume> Vol. 7, No. 3, </volume> <month> June </month> <year> 1995. </year>
Reference-contexts: As band join is very similar to the equijoin both in concept and in execution, it is likely that band join will become a standard operation in future commercial relational databases. While a large number of papers have been presented for processing equijoins, only a few papers <ref> [43, 49, 60] </ref> are devoted for processing band joins. Most of the band join algorithms require sorting of at least one of the relation. Truncating-hash band join [49] is an attempt trying to do away with the sorting and has considerably improved the speed of band join processing. <p> The truncating-hash band join is an attempt trying to carry this performance advantage over to the band join and analytical comparisons show that this approach is successful [49]. In essence, this is a hash join facilitated by truncating. A later improvement of the sort-merge band join <ref> [60] </ref> by H. Lu and K.-L. Tan appeared to offer competitive performance. It is essentially a sort-merge technique. <p> The criterion to decide the window relation is <ref> [60] </ref>: R if jjRjj D R jjSjj D S jjRjj D R &gt; jjSjj D S RjS; otherwise where jj : jj represents number of tuples, not pages. For R, the number of tuples in the band is about jjRjj D R fi (c 1 + c 2 ).
Reference: [61] <author> Z. Li, K. A. Ross. </author> <title> Fast Joins Using Join Indices. </title> <type> Technical Report, </type> <institution> CUCS-032-96, 1996, Columbia University. </institution>
Reference-contexts: Some new database architectures and join techniques have been proposed in recent years which hold hopes to further improve the performance of join execution in relational database. These techniques include signature method [15, 31, 34], clustering of data tuples and partition of relations [59], join index <ref> [28, 61] </ref>, composite index [33], layered relational database [52], etc.
Reference: [62] <author> Ming-Ling Lo and Chinya V. Ravishankar. </author> <title> Towards Eliminating Random I/O in Hash Joins. </title> <booktitle> IEEE. Proc. of 12th Int'l Conf. on Data Engineering, </booktitle> <year> 1996. </year>
Reference-contexts: This is a similar but more generalized method than semijoin. Other more general methods of semijoins can be found in [18, 26]. Eliminating random I/O: Hash join has two phases: partitioning and joining phases. In <ref> [62] </ref>, disk I/Os are divided into four phases: PR, PW, JR, JW. PR represents partitioning phase read, PW represents partitioning phase write, JR represents joining phase read, and JW represents joining phase write. For convenience of comparison, in this paper we assume PW and JR are sequential. <p> For convenience of comparison, in this paper we assume PW and JR are sequential. Actually, this assumption is not totally true. The proposed optimization targets reducing random disk I/Os on two phases: PW and JR. In <ref> [62] </ref>, hash buckets are comprised of bucket segments. Each bucket segment is a physically contiguous storage area. Several bucket segments can form a write group. 23 The memory for performing join operation are divided into three parts: IB, the input buffer, SB, the staging buffer, and OB, the output buffer. <p> When a new tuple is hashed to a full bucket and no free memory pages are available for allocation, some pages in some buckets have to be written out to disk so that those memory pages can be reclaimed for further allocation. The key technique adopted in <ref> [62] </ref> is to write out as much a collection of contiguous buckets as possible so that during the joining phase read, as much blocks as possible can be read sequentially. All buckets are organized into write groups. Each write group may have one or more buckets. <p> For convenience of analysis, it is assumed that all write groups are about the same size. Then, the cost to read one write group into memory in the joining phase is <ref> [62] </ref>: A ran + ( n wg Let = A ran =A seq . The cost to read relation R into memory in the joining phase is [62]: H s X C (read write group of t) = H s ( j R j + 1) fl A seq (20) It <p> Then, the cost to read one write group into memory in the joining phase is <ref> [62] </ref>: A ran + ( n wg Let = A ran =A seq . The cost to read relation R into memory in the joining phase is [62]: H s X C (read write group of t) = H s ( j R j + 1) fl A seq (20) It is claimed in [62] that the performance of their technique is several times better than that of Dynamic-Hashing GRACE Hash-join [32, 35]. <p> The cost to read relation R into memory in the joining phase is <ref> [62] </ref>: H s X C (read write group of t) = H s ( j R j + 1) fl A seq (20) It is claimed in [62] that the performance of their technique is several times better than that of Dynamic-Hashing GRACE Hash-join [32, 35]. Orders of executions: It has long been accepted that if a query has projection, selection and join operations, it is usually more efficient to perform projection and selection before performing join.
Reference: [63] <author> Raghu Ramakrishnan. </author> <title> Database Management Systems. Beta Edition, </title> <booktitle> 1996, </booktitle> <address> ISBN 0-07-052522-6. </address> <publisher> McGraw-Hill Companies, Inc. </publisher> <pages> 51 </pages>
Reference-contexts: Sort-merge join technique has an additional advantage over nested loops join in that it can efficiently handle inequality join. The I/O cost of the sort-merge join is <ref> [63] </ref>: C merge = 2 j R j log j R j +2 j S j log j S j + j R j + j S j +fffi j R j (10) The first two terms are the cost to sort the two relations and the last two terms are
References-found: 63

