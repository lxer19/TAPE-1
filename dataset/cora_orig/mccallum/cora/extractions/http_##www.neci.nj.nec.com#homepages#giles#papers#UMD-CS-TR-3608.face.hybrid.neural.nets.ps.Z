URL: http://www.neci.nj.nec.com/homepages/giles/papers/UMD-CS-TR-3608.face.hybrid.neural.nets.ps.Z
Refering-URL: http://www.neci.nj.nec.com/homepages/giles/papers/
Root-URL: 
Title: Face Recognition: A Hybrid Neural Network Approach  
Author: Steve Lawrence ;fl C. Lee Giles y Ah Chung Tsoi Andrew D. Back 
Keyword: Convolutional Networks, Hybrid Systems, Face Recognition, Self-Organizing Map  
Note: http://www.neci.nj.nec.com/homepages/lawrence, http://www.elec.uq.edu.au/~lawrence Also with the  
Address: 4 Independence Way, Princeton, NJ 08540  St. Lucia, Australia  College Park, MD 20742  College Park, MD 20742.  
Affiliation: NEC Research Institute,  Electrical and Computer Engineering, University of Queensland,  Institute for Advanced Computer Studies University of Maryland  Institute for Advanced Computer Studies, University of Maryland,  
Pubnum: Technical Report UMIACS-TR-96-16 and CS-TR-3608  
Email: flawrence,act,backg@elec.uq.edu.au, giles@research.nj.nec.com  
Phone: 1  2  
Date: April 1996 (Revised August 1996)  
Abstract: Faces represent complex, multidimensional, meaningful visual stimuli and developing a computational model for face recognition is difficult (Turk and Pentland, 1991). We present a hybrid neural network solution which compares favorably with other methods. The system combines local image sampling, a self-organizing map neural network, and a convolutional neural network. The self-organizing map provides a quantization of the image samples into a topological space where inputs that are nearby in the original space are also nearby in the output space, thereby providing dimensionality reduction and invariance to minor changes in the image sample, and the convolutional neural network provides for partial invariance to translation, rotation, scale, and deformation. The convolutional network extracts successively larger features in a hierarchical set of layers. We present results using the Karhunen-Loeve transform in place of the self-organizing map, and a multilayer perceptron in place of the convolutional network. The Karhunen-Loeve transform performs almost as well (5.3% error versus 3.8%). The multilayer perceptron performs very poorly (40% error versus 3.8%). The method is capable of rapid classification, requires only fast, approximate normalization and preprocessing, and consistently exhibits better classification performance than the eigenfaces approach (Turk and Pentland, 1991) on the database considered as the number of images per person in the training database is varied from 1 to 5. With 5 images per person the proposed method and eigenfaces result in 3.8% and 10.5% error respectively. The recognizer provides a measure of confidence in its output and classification error approaches zero when rejecting as few as 10% of the examples. We use a database of 400 images of 40 individuals which contains quite a high degree of variability in expression, pose, and facial details. We analyze computational complexity and discuss how new classes could be added to the trained recognizer. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Arya, S. and Mount, D. </author> <year> (1993), </year> <title> Algorithms for fast vector quantization, </title> <editor> in J. A. Storer and M. Cohn, eds, </editor> <booktitle> `Proceedings of DCC 93: Data Compression Conference', </booktitle> <publisher> IEEE Press, </publisher> <pages> pp. 381390. </pages>
Reference-contexts: Note that the constant associated with the log factors may increase exponentially in the worst case (cf. neighbor searching in high dimensional spaces <ref> (Arya and Mount, 1993) </ref>).
Reference: <author> Bauer, H.-U. and Pawelzik, K. R. </author> <year> (1992), </year> <title> `Quantifying the neighborhood preservation of Self-Organizing Feature Maps', </title> <journal> IEEE Transactions on Neural Networks 3(4), </journal> <volume> 570579. </volume>
Reference-contexts: The degree of invariance can be modified by adjusting the weight w ij ( 0) connected to the central intensity component. 4.3 The Self-Organizing Map 4.3.1 Overview Maps are an important part of both natural and artificial neural information processing systems <ref> (Bauer and Pawelzik, 1992) </ref>.
Reference: <author> Bengio, Y., Le Cun, Y. and Henderson, D. </author> <year> (1994), </year> <title> Globally trained handwritten word recognizer using spatial representation, space displacement neural networks and hidden Markov models, </title> <booktitle> in `Advances in Neural Information Processing Systems 6', </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo CA. </address> <note> 24 Blue, </note> <author> J., Candela, G., Grother, P., Chellappa, R. and Wilson, C. </author> <year> (1994), </year> <title> `Evaluation of pattern classifiers for fingerprint and OCR applications', </title> <journal> Pattern Recognition 27(4), </journal> <volume> 485501. </volume>
Reference: <author> Bottou, L., Cortes, C., Denker, J., Drucker, H., Guyon, I., Jackel, L., Le Cun, Y., Muller, U., Sackinger, E., Simard, P. and Vapnik, V. </author> <year> (1994), </year> <title> Comparison of classifier methods: A case study in handwritten digit recognition, </title> <booktitle> in `Proceedings of the International Conference on Pattern Recognition', </booktitle> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA. </address>
Reference: <author> Brunelli, R. and Poggio, T. </author> <year> (1993), </year> <title> `Face recognition: Features versus templates', </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence 15(10), </journal> <volume> 10421052. </volume>
Reference-contexts: However, it may be limited because optimal performance requires a high degree of correlation between the pixel intensities of the training and test images. This limitation has been addressed by using extensive preprocessing to normalize the images. 3.3 Template Matching Template matching methods such as <ref> (Brunelli and Poggio, 1993) </ref> operate by performing direct correlation of image segments (e.g. by computing the Euclidean distance).
Reference: <author> Burton, D. K. </author> <year> (1987), </year> <title> `Text-dependent speaker verification using vector quantization source coding', </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing 35(2), </journal> <volume> 133. </volume>
Reference-contexts: 1 Introduction The requirement for reliable personal identification in computerized access control has resulted in an increased interest in biometrics 1 . Biometrics being investigated include fingerprints (Blue, Candela, Grother, Chellappa and Wilson, 1994), speech <ref> (Burton, 1987) </ref>, signature dynamics (Qi and Hunt, 1994), and face recognition (Chellappa, Wilson and Sirohey, 1995). Sales of identity verification products exceed $100 million (Miller, 1994). Face recognition has the benefit of being a passive, non-intrusive system for verifying personal identity.
Reference: <author> Chellappa, R., Wilson, C. and Sirohey, S. </author> <year> (1995), </year> <title> `Human and machine recognition of faces: A survey', </title> <booktitle> Proceedings of the IEEE 83(5), </booktitle> <pages> 705740. </pages>
Reference-contexts: 1 Introduction The requirement for reliable personal identification in computerized access control has resulted in an increased interest in biometrics 1 . Biometrics being investigated include fingerprints (Blue, Candela, Grother, Chellappa and Wilson, 1994), speech (Burton, 1987), signature dynamics (Qi and Hunt, 1994), and face recognition <ref> (Chellappa, Wilson and Sirohey, 1995) </ref>. Sales of identity verification products exceed $100 million (Miller, 1994). Face recognition has the benefit of being a passive, non-intrusive system for verifying personal identity. The techniques used in the best face recognition systems may depend on the application of the system. <p> The goal is to identify particular people in real-time (e.g. in a security monitoring system, location tracking system, etc.), or to allow access to a group of people and deny access to all others (e.g. access to a building, computer, etc.) <ref> (Chellappa et al., 1995) </ref>. Multiple images per person are often available for training and real-time recognition is required. This paper is primarily concerned with the second case 2 . This work considers recognition with varying facial detail, expression, pose, etc. <p> Each face is represented by 30 manually extracted distances. Systems which employ precisely measured distances between features may be most useful for finding possible matches in a large mugshot database (a mugshot database typically contains side views where the performance of feature point methods is known to improve <ref> (Chellappa et al., 1995) </ref>). For other applications, automatic identification of these points would be required, and the resulting system would be dependent on the accuracy of the feature location algorithm.
Reference: <author> Cox, I. J., Ghosn, J. and Yianilos, P. N. </author> <year> (1995), </year> <title> Feature-based face recognition using mixture-distance, </title> <type> Technical report, </type> <institution> NEC Research Institute, Princeton, NJ. </institution>
Reference-contexts: Template matching is only effective when the query images have the same scale, orientation, and illumination as the training images <ref> (Cox et al., 1995) </ref>. 3.4 Neural Network Approaches Much of the present literature on face recognition with neural networks presents results with only a small number of classes (often below 20).
Reference: <author> DeMers, D. and Cottrell, G. </author> <year> (1993), </year> <title> Non-linear dimensionality reduction, </title> <editor> in S. Hanson, J. Cowan and C. L. Giles, eds, </editor> <booktitle> `Advances in Neural Information Processing Systems 5', </booktitle> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <pages> pp. 580587. </pages>
Reference-contexts: For example, in <ref> (DeMers and Cottrell, 1993) </ref> the first 50 principal components of images are extracted and reduced to 5 dimensions using an autoassociative neural network. The resulting representation is classified using a standard multilayer perceptron.
Reference: <author> Dony, R. and Haykin, S. </author> <year> (1995), </year> <title> `Neural network approaches to image compression', </title> <booktitle> Proceedings of the IEEE 83(2), </booktitle> <pages> 288303. </pages>
Reference-contexts: PCA appears to be involved in some biological processes, e.g. edge segments are principal components and edge segments are among the first features extracted in the primary visual cortex (Hubel and Wiesel, 1962). Mathematically, the KL transform can be written as <ref> (Dony and Haykin, 1995) </ref>: y = Wx (3) where x is an N dimensional input vector, y is an M dimensional output vector (M N ), and W is an M fi N dimensional transformation matrix. <p> The transformation matrix, W, consists of M rows of the eigenvectors which correspond to the M largest eigenvalues of the sample autocovariance matrix, <ref> (Dony and Haykin, 1995) </ref>: = xx T ff where &lt;&gt; represents expectation. The KL transform is used here for comparison with the SOM in the dimensionality reduction of the local image samples.
Reference: <author> Drucker, H., Cortes, C., Jackel, L., Le Cun, Y. and Vapnik, V. </author> <year> (1994), </year> <title> `Boosting and other ensemble methods', </title> <booktitle> Neural Computation 6, </booktitle> <pages> 12891301. </pages>
Reference: <author> Fukunaga, K. </author> <year> (1990), </year> <title> Introduction to Statistical Pattern Recognition, Second Edition, </title> <publisher> Academic Press, </publisher> <address> Boston, MA. </address>
Reference-contexts: here. 4 This assumes that the topological order is optimal prior to each doubling step. 8 4.4 Karhunen-Lo eve Transform The optimal linear method (in the least mean squared error sense) for reducing redundancy in a dataset is the Karhunen-Loeve (KL) transform or eigenvector expansion via Principle Components Analysis (PCA) <ref> (Fukunaga, 1990) </ref>. The basic idea behind the KL transform is to transform possibly correlated variables in a data set into uncorrelated variables. The transformed variables will be ordered so that the first one describes most of the variation of the original data set.
Reference: <author> Fukushima, K. </author> <year> (1980), </year> <title> `Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position', </title> <journal> Biological Cybernetics 36, 193202. </journal>
Reference: <author> Fukushima, K. </author> <year> (1995), </year> <title> Neocognitron: A model for visual pattern recognition, </title> <editor> in M. A. Arbib, ed., </editor> <title> `The Handbook of Brain Theory and Neural Networks', </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <pages> pp. 613617. </pages>
Reference-contexts: However, in the Neocognitron, the C-cell layers respond to the most active input S-cell as opposed to performing an averaging operation. The Neocognitron can be trained using either unsupervised or supervised approaches <ref> (Fukushima, 1995) </ref>. 10 5 System Details The system used for face recognition in this paper is a combination of the preceding parts a high-level block diagram is shown in figure 6 and figure 7 shows a breakdown of the various subsystems that are experimented with or discussed. paper.
Reference: <author> Fukushima, K., Miyake, S. and Ito, T. </author> <year> (1983), </year> <title> `Neocognitron: A neural network model for a mechanism of visual pattern recognition', </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics 13. </journal>
Reference: <author> Haykin, S. </author> <year> (1994), </year> <title> Neural Networks, A Comprehensive Foundation, </title> <publisher> Macmillan, </publisher> <address> New York, NY. </address>
Reference-contexts: The network is trained with the usual backpropagation gradient descent procedure <ref> (Haykin, 1994) </ref>. A connection strategy can be used to reduce the number of weights in the network. <p> The number of planes in each layer, the dimensions of the planes, and the dimensions of the receptive fields are shown in table 1. The network was trained with backpropagation <ref> (Haykin, 1994) </ref> for a total of 20,000 updates. Weights in the network were updated after each pattern presentation, as opposed to batch update where weights are only updated once per pass through the training set. All inputs were normalized to lie in the range minus one to one. <p> Weights were initialized on a node by node basis as uniformly distributed random numbers in the range (2:4=F i ; 2:4=F i ) where F i is the fan-in of neuron i <ref> (Haykin, 1994) </ref>. Target outputs were -0.8 and 0.8 using the tanh output activation function 5 . The quadratic cost function was 5 This helps avoid saturating the sigmoid function.
Reference: <author> Haykin, S. </author> <year> (1996), </year> <type> `Personal communication'. </type>
Reference-contexts: Note that it may be considered fairer to compare against an MLP 16 KL SOM CN 5.33% 3.83% Table 7. Error rate comparison of the various feature extraction and classification methods. Each result is the average of three simulations. with multiple hidden layers <ref> (Haykin, 1996) </ref>, however selection of the appropriate number of nodes in each layer and training is difficult (e.g. trying a network with two hidden layers containing 100 and 50 nodes respectively resulted in an error rate of 90%). 7.
Reference: <author> Hubel, D. and Wiesel, T. </author> <year> (1962), </year> <title> `Receptive fields, binocular interaction, and functional architecture in the cat's visual cortex', </title> <journal> Journal of Physiology (London) 160, </journal> <volume> 106154. </volume>
Reference-contexts: This continues until all the variation is described by the new transformed variables, which are called principal components. PCA appears to be involved in some biological processes, e.g. edge segments are principal components and edge segments are among the first features extracted in the primary visual cortex <ref> (Hubel and Wiesel, 1962) </ref>. Mathematically, the KL transform can be written as (Dony and Haykin, 1995): y = Wx (3) where x is an N dimensional input vector, y is an M dimensional output vector (M N ), and W is an M fi N dimensional transformation matrix.
Reference: <author> Hummel, J. </author> <year> (1995), </year> <title> Object recognition, </title> <editor> in M. A. Arbib, ed., </editor> <title> `The Handbook of Brain Theory and Neural Networks', </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <pages> pp. 658660. </pages>
Reference: <author> Jacobs, R. </author> <year> (1995), </year> <title> `Methods for combining experts' probability assessments', </title> <booktitle> Neural Computation 7, </booktitle> <pages> 867888. </pages>
Reference: <author> Kanade, T. </author> <year> (1973), </year> <title> Picture Processing by Computer Complex and Recognition of Human Faces, </title> <type> PhD thesis, </type> <institution> Kyoto University. </institution>
Reference: <author> Kita, H. and Nishikawa, Y. </author> <year> (1993), </year> <title> Neural network model of tonotopic map formation based on the temporal theory of auditory sensation, </title> <booktitle> in `Proc. WCNN 93, World Congress on Neural Networks', </booktitle> <volume> Vol. II, </volume> <publisher> Lawrence Erlbaum, </publisher> <address> Hillsdale, NJ, </address> <pages> pp. 413418. </pages>
Reference-contexts: Examples of maps in the nervous system are retinotopic maps in the visual cortex 6 created at each location. (Obermayer, Blasdel and Schulten, 1991), tonotopic maps in the auditory cortex <ref> (Kita and Nishikawa, 1993) </ref>, and maps from the skin onto the somatosensoric cortex (Obermayer, Ritter and Schulten, 1990). The self-organizing map, or SOM, introduced by Teuvo Kohonen (1990; 1995) is an unsupervised learning process which learns the distribution of a set of patterns without any class information.
Reference: <author> Kohonen, T. </author> <year> (1990), </year> <title> `The self-organizing map', </title> <booktitle> Proceedings of the IEEE 78, </booktitle> <pages> 14641480. </pages>
Reference: <author> Kohonen, T. </author> <year> (1995), </year> <title> Self-Organizing Maps, </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, Germany. </address>
Reference-contexts: image sample classification, for example, there may be a very large number of classes in which the transition from one class to the next is practically continuous (making it difficult to define hard class boundaries). 4.3.2 Algorithm We give a brief description of the SOM algorithm, for more details see <ref> (Kohonen, 1995) </ref>. The SOM defines a mapping from an input space R n onto a topologically ordered set of nodes, usually in a lower dimensional space. An example of a two-dimensional SOM is shown in figure 4. <p> Note that (t) should not be reduced too far as the map will lose its topographical order if neighboring nodes are not updated along with the closest node. The SOM can be considered a non-linear projection of the probability density, p (x) <ref> (Kohonen, 1995) </ref>. size to h ci (t 3 ) over time. 4.3.3 Improving the Basic SOM The original self-organizing map is computationally expensive because: 1. In the early stages of learning, many nodes are adjusted in a correlated manner.
Reference: <author> Le Cun, Y. </author> <year> (1989), </year> <title> Generalisation and network design strategies, </title> <type> Technical Report CRG-TR-89-4, </type> <institution> Department of Computer Science, University of Toronto. </institution>
Reference: <author> Le Cun, Y. and Bengio, Y. </author> <year> (1995), </year> <title> Convolutional networks for images, speech, and time series, </title> <editor> in M. A. Arbib, ed., </editor> <title> `The Handbook of Brain Theory and Neural Networks', </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <pages> pp. 255258. </pages>
Reference-contexts: Additionally, for MLP networks with the 2D images as input, there is no invariance to translation or local deformation of the images <ref> (Le Cun and Bengio, 1995) </ref>. Convolutional networks (CN) incorporate constraints and achieve some degree of shift and deformation invariance using three ideas: local receptive fields, shared weights, and spatial subsampling. The use of shared weights also reduces the number of parameters in the system aiding generalization. <p> The idea of connecting units to 9 local receptive fields dates back to the 1960s with the perceptron and Hubel and Wiesel's (1962) discovery of locally sensitive, orientation-selective neurons in the visual system of a cat <ref> (Le Cun and Bengio, 1995) </ref>. The weights forming the receptive field for a plane are forced to be equal at all points in the plane.
Reference: <author> Le Cun, Y., Boser, B., Denker, J., Henderson, D., Howard, R., Hubbard, W. and Jackel, L. </author> <year> (1990), </year> <title> Handwritten digit recognition with a backpropagation neural network, </title> <editor> in D. Touretzky, ed., </editor> <booktitle> `Advances in Neural Information Processing Systems 2', </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <pages> pp. 396404. </pages>
Reference-contexts: A typical convolutional network is shown in figure 5 <ref> (Le Cun, Boser, Denker, Henderson, Howard, Hubbard and Jackel, 1990) </ref>. The network consists of a set of layers each of which contains one or more planes. Images which are approximately centered and normalized enter at the input layer. <p> This can reduce training time and improve performance <ref> (Le Cun, Boser, Denker, Henderson, Howard, Hubbard and Jackel, 1990) </ref>. Convolutional networks are similar to the Neocognitron (Fukushima, 1980; Fukushima, Miyake and Ito, 1983; Hummel, 1995) which is a neural network model of deformation-resistant pattern recognition. The Neocognitron is similar to the convolutional neural network. <p> It is expected that an optimized version could be significantly faster. 9 Further Research The following topics for further research could improve performance: 1. More careful selection of the convolutional network architecture, e.g. by using the Optimal Brain Damage algorithm <ref> (Le Cun, Denker and Solla, 1990) </ref> as used by Le Cun et al. (1990) to improve generalization and speed up handwritten digit recognition. 2. More precise normalization of the images to account for translation, rotation, and scale changes. Any normalization would be limited by the desired recognition speed. 3.
Reference: <author> Le Cun, Y., Denker, J. and Solla, S. </author> <year> (1990), </year> <title> Optimal Brain Damage, </title> <editor> in D. Touretzky, ed., </editor> <booktitle> `Advances in Neural Information Processing Systems', </booktitle> <volume> Vol. </volume> <pages> 2, </pages> <address> (Denver 1989), </address> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, </address> <pages> pp. 598605. </pages>
Reference-contexts: A typical convolutional network is shown in figure 5 <ref> (Le Cun, Boser, Denker, Henderson, Howard, Hubbard and Jackel, 1990) </ref>. The network consists of a set of layers each of which contains one or more planes. Images which are approximately centered and normalized enter at the input layer. <p> This can reduce training time and improve performance <ref> (Le Cun, Boser, Denker, Henderson, Howard, Hubbard and Jackel, 1990) </ref>. Convolutional networks are similar to the Neocognitron (Fukushima, 1980; Fukushima, Miyake and Ito, 1983; Hummel, 1995) which is a neural network model of deformation-resistant pattern recognition. The Neocognitron is similar to the convolutional neural network. <p> It is expected that an optimized version could be significantly faster. 9 Further Research The following topics for further research could improve performance: 1. More careful selection of the convolutional network architecture, e.g. by using the Optimal Brain Damage algorithm <ref> (Le Cun, Denker and Solla, 1990) </ref> as used by Le Cun et al. (1990) to improve generalization and speed up handwritten digit recognition. 2. More precise normalization of the images to account for translation, rotation, and scale changes. Any normalization would be limited by the desired recognition speed. 3.
Reference: <author> Leen, T. K. </author> <year> (1991), </year> <title> `From data distributions to regularization in invariant learning', </title> <booktitle> Neural Computation 3(1), </booktitle> <pages> 135143. </pages>
Reference: <author> Luttrell, S. P. </author> <year> (1989), </year> <title> Hierarchical self-organizing networks, </title> <booktitle> in `Proc. 1st IEE Conf. of Artificial Neural Networks', British Neural Network Society, </booktitle> <address> London, UK, </address> <pages> pp. 26. </pages> <address> 25 Marr, D. </address> <year> (1982), </year> <title> Vision, </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> San Francisco. </address>
Reference: <author> Miller, B. </author> <year> (1994), </year> <title> `Vital signs of identity', </title> <journal> IEEE Spectrum pp. </journal> <volume> 2230. </volume>
Reference-contexts: Biometrics being investigated include fingerprints (Blue, Candela, Grother, Chellappa and Wilson, 1994), speech (Burton, 1987), signature dynamics (Qi and Hunt, 1994), and face recognition (Chellappa, Wilson and Sirohey, 1995). Sales of identity verification products exceed $100 million <ref> (Miller, 1994) </ref>. Face recognition has the benefit of being a passive, non-intrusive system for verifying personal identity. The techniques used in the best face recognition systems may depend on the application of the system. There are at least two broad categories of face recognition systems: 1.
Reference: <author> Moghaddam, B. and Pentland, A. </author> <year> (1994), </year> <title> Face recognition using view-based and modular eigenspaces, in `Automatic Systems for the Identification and Inspection of Humans, </title> <booktitle> SPIE', </booktitle> <volume> Vol. </volume> <pages> 2257. </pages>
Reference-contexts: It is difficult to draw broad conclusions as many of the images of the same people look very similar (in the sense that there is little difference in expression, hairstyle, etc.), and the database has accurate registration and alignment <ref> (Moghaddam and Pentland, 1994) </ref>. In Moghaddam and Pentland (1994), very good results are reported with the US Army FERET database database only one mistake was made in classifying 150 frontal view images.
Reference: <author> Obermayer, K., Blasdel, G. G. and Schulten, K. </author> <year> (1991), </year> <title> A neural network model for the formation and for the spatial structure of retinotopic maps, orientation and ocular dominance columns, </title> <editor> in T. Kohonen, K. Makisara, O. Simula and J. Kangas, eds, </editor> <booktitle> `Artificial Neural Networks', </booktitle> <publisher> Elsevier, </publisher> <address> Amsterdam, Netherlands, </address> <pages> pp. 505511. </pages>
Reference-contexts: Examples of maps in the nervous system are retinotopic maps in the visual cortex 6 created at each location. <ref> (Obermayer, Blasdel and Schulten, 1991) </ref>, tonotopic maps in the auditory cortex (Kita and Nishikawa, 1993), and maps from the skin onto the somatosensoric cortex (Obermayer, Ritter and Schulten, 1990).
Reference: <author> Obermayer, K., Ritter, H. and Schulten, K. </author> <year> (1990), </year> <title> Large-scale simulation of a self-organizing neural network: Formation of a somatotopic map, </title> <editor> in R. Eckmiller, G. Hartmann and G. Hauske, eds, </editor> <booktitle> `Parallel Processing in Neural Systems and Computers', </booktitle> <publisher> North-Holland, </publisher> <address> Amsterdam, Netherlands, </address> <pages> pp. 7174. </pages>
Reference-contexts: Examples of maps in the nervous system are retinotopic maps in the visual cortex 6 created at each location. (Obermayer, Blasdel and Schulten, 1991), tonotopic maps in the auditory cortex (Kita and Nishikawa, 1993), and maps from the skin onto the somatosensoric cortex <ref> (Obermayer, Ritter and Schulten, 1990) </ref>. The self-organizing map, or SOM, introduced by Teuvo Kohonen (1990; 1995) is an unsupervised learning process which learns the distribution of a set of patterns without any class information.
Reference: <author> Pentland, A., Moghaddam, B. and Starner, T. </author> <year> (1994), </year> <title> View-based and modular eigenspaces for face recognition, </title> <booktitle> in `IEEE Conference on Computer Vision and Pattern Recognition'. </booktitle>
Reference-contexts: It is difficult to draw broad conclusions as many of the images of the same people look very similar (in the sense that there is little difference in expression, hairstyle, etc.), and the database has accurate registration and alignment <ref> (Moghaddam and Pentland, 1994) </ref>. In Moghaddam and Pentland (1994), very good results are reported with the US Army FERET database database only one mistake was made in classifying 150 frontal view images.
Reference: <author> Pentland, A., Starner, T., Etcoff, N., Masoiu, A., Oliyide, O. and Turk, M. </author> <year> (1993), </year> <title> Experiments with eigenfaces, </title> <booktitle> in `Looking at People Workshop, International Joint Conference on Artificial Intelligence 1993', </booktitle> <address> Chamberry, France. </address> <month> Perret, </month> <title> Rolls and Caan (1982), `Visual neurones responsive to faces in the monkey temporal cortex', Experimental Brain Research 47, </title> <type> 329342. </type>
Reference-contexts: There are at least two broad categories of face recognition systems: 1. The goal is to find a person within a large database of faces (e.g. in a police database). These systems typically return a list of the most likely people in the database <ref> (Pentland, Starner, Etcoff, Masoiu, Oliyide and Turk, 1993) </ref>. Often only one image is available per person. It is usually not necessary for recognition to be done in real-time. 2.
Reference: <author> Qi, Y. and Hunt, B. </author> <year> (1994), </year> <title> `Signature verification using global and grid features', </title> <journal> Pattern Recognition 27(12), </journal> <volume> 16211629. </volume>
Reference-contexts: 1 Introduction The requirement for reliable personal identification in computerized access control has resulted in an increased interest in biometrics 1 . Biometrics being investigated include fingerprints (Blue, Candela, Grother, Chellappa and Wilson, 1994), speech (Burton, 1987), signature dynamics <ref> (Qi and Hunt, 1994) </ref>, and face recognition (Chellappa, Wilson and Sirohey, 1995). Sales of identity verification products exceed $100 million (Miller, 1994). Face recognition has the benefit of being a passive, non-intrusive system for verifying personal identity.
Reference: <author> Rowley, H. A., Baluja, S. and Kanade, T. </author> <year> (1995), </year> <title> Human face detection in visual scenes, </title> <type> Technical Report CMU-CS-95-158, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA. </address>
Reference: <author> Samaria, F. </author> <year> (1994), </year> <title> Face Recognition using Hidden Markov Models, </title> <type> PhD thesis, </type> <institution> Trinity College, University of Cambridge, Cam-bridge. </institution>
Reference-contexts: Good results are reported but the database is quite simple: the pictures are manually aligned and there is no lighting variation, rotation, or tilting. There are 20 people in the database. 3.5 The ORL Database and Application of HMM and Eigenfaces Methods In <ref> (Samaria and Harter, 1994) </ref> a HMM-based approach is used for classification of the ORL database images. HMMs are typically used for the stochastic modeling of non-stationary vector time series. <p> Around 10% error was also observed in this work when implementing the eigenfaces algorithm. In <ref> (Samaria, 1994) </ref> Samaria extends the top-down HMM of (Samaria and Harter, 1994) with pseudo two-dimensional HMMs. The pseudo-2D HMMs are obtained 5 by linking one dimensional HMMs to form vertical superstates. The network is not fully connected in two dimensions (hence pseudo). <p> Around 10% error was also observed in this work when implementing the eigenfaces algorithm. In (Samaria, 1994) Samaria extends the top-down HMM of <ref> (Samaria and Harter, 1994) </ref> with pseudo two-dimensional HMMs. The pseudo-2D HMMs are obtained 5 by linking one dimensional HMMs to form vertical superstates. The network is not fully connected in two dimensions (hence pseudo).
Reference: <author> Samaria, F. and Harter, A. </author> <year> (1994), </year> <title> Parameterisation of a stochastic model for human face identification, </title> <booktitle> in `Proceedings of the 2nd IEEE workshop on Applications of Computer Vision', </booktitle> <address> Sarasota, Florida. </address>
Reference-contexts: Good results are reported but the database is quite simple: the pictures are manually aligned and there is no lighting variation, rotation, or tilting. There are 20 people in the database. 3.5 The ORL Database and Application of HMM and Eigenfaces Methods In <ref> (Samaria and Harter, 1994) </ref> a HMM-based approach is used for classification of the ORL database images. HMMs are typically used for the stochastic modeling of non-stationary vector time series. <p> Around 10% error was also observed in this work when implementing the eigenfaces algorithm. In <ref> (Samaria, 1994) </ref> Samaria extends the top-down HMM of (Samaria and Harter, 1994) with pseudo two-dimensional HMMs. The pseudo-2D HMMs are obtained 5 by linking one dimensional HMMs to form vertical superstates. The network is not fully connected in two dimensions (hence pseudo). <p> Around 10% error was also observed in this work when implementing the eigenfaces algorithm. In (Samaria, 1994) Samaria extends the top-down HMM of <ref> (Samaria and Harter, 1994) </ref> with pseudo two-dimensional HMMs. The pseudo-2D HMMs are obtained 5 by linking one dimensional HMMs to form vertical superstates. The network is not fully connected in two dimensions (hence pseudo).
Reference: <author> Sung, K.-K. and Poggio, T. </author> <year> (1995), </year> <title> Learning human face detection in cluttered scenes, in `Computer Analysis of Images and Patterns', </title> <journal> pp. </journal> <volume> 432439. </volume>
Reference: <author> Sutherland, K., Renshaw, D. and Denyer, P. </author> <year> (1992), </year> <title> Automatic face recognition, </title> <booktitle> in `First International Conference on Intelligent Systems Engineering', </booktitle> <publisher> IEEE Press, </publisher> <address> Piscataway, NJ, </address> <pages> pp. 2934. </pages>
Reference-contexts: For other applications, automatic identification of these points would be required, and the resulting system would be dependent on the accuracy of the feature location algorithm. Current algorithms for automatic location of feature points do not consistently provide a high degree of accuracy <ref> (Sutherland, Renshaw and Denyer, 1992) </ref>. 3.2 Eigenfaces High-level recognition tasks are typically modeled with many stages of processing as in the Marr paradigm of progressing from images to surfaces to three-dimensional models to matched models (Marr, 1982).
Reference: <author> Turk, M. and Pentland, A. </author> <year> (1991), </year> <title> `Eigenfaces for recognition', </title> <journal> J. of Cognitive Neuroscience 3, </journal> <volume> 7186. </volume> <pages> 26 </pages>
Reference-contexts: In this case, they are applied to images and a sampling window is passed over the image to generate a vector at each step. The best model resulted in a 13% error rate. Samaria also performed extensive tests using the popular eigenfaces algorithm <ref> (Turk and Pentland, 1991) </ref> on the ORL database and reported a best error rate of around 10% when the number of eigenfaces was between 175 and 199. Around 10% error was also observed in this work when implementing the eigenfaces algorithm. <p> Substitution of the Karhunen-Loeve transform for the self-organizing map produced similar but slightly worse results. The method is capable of rapid classification, requires only fast, approximate normalization and preprocessing, and consistently exhibits better classification performance than the eigen-faces approach <ref> (Turk and Pentland, 1991) </ref> on the database considered as the number of images per person in the training database is varied from 1 to 5. With 5 images per person the proposed method and eigenfaces result in 3.8% and 10.5% error respectively.
References-found: 43

