URL: http://www.cs.wisc.edu/~pmd/papers/vldb96/Article.PS
Refering-URL: http://www.cs.wisc.edu/~pmd/olapreferences.html
Root-URL: 
Title: On the Computation of Multidimensional Aggregates  
Author: Sameet Agarwal Rakesh Agrawal Prasad M. Deshpande Ashish Gupta Jeffrey F. Naughton Raghu Ramakrishnan Sunita Sarawagi 
Abstract: At the heart of all OLAP or multidimensional data analysis applications is the ability to simultaneously aggregate across many sets of dimensions. Computing multidimensional aggregates is a performance bottleneck for these applications. This paper presents fast algorithms for computing a collection of group-bys. We focus on a special case of the aggregation problem | computation of the CUBE operator. The CUBE operator requires computing group-bys on all possible combinations of a list of attributes, and is equivalent to the union of a number of standard group-by operations. We show how the structure of CUBE computation can be viewed in terms of a hierarchy of group-by operations. Our algorithms extend sort-based and hash-based grouping methods with several optimizations, like combining common operations across multiple group-bys, caching, and using pre-computed group-bys for computing other group-bys. Empirical evaluation shows that the resulting algorithms give much better performance compared to straightforward methods. This paper combines work done concurrently on computing the data cube by two different teams as reported in [SAG96] and [DANR96].
Abstract-found: 1
Intro-found: 1
Reference: [CM89] <author> M.C. Chen and L.P. McNamee. </author> <title> The data model and access method of summary data management. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 1(4) </volume> <pages> 519-29, </pages> <year> 1989. </year>
Reference-contexts: Aggregate pre-computation is quite common in statistical databases [Sho82]. Research in this area has considered various aspects of the problem starting from developing a model for aggregate computation <ref> [CM89] </ref>, indexing pre-computed aggregates [STL89] and incrementally maintaining them [Mic92]. However, to the best of our knowledge, there is no published work in the statistical database literature on methods for optimizing the computation of related aggregates.
Reference: [GBLP96] <author> Jim Gray, Adam Bosworth, Andrew Layman and Hamid Pirahesh. </author> <title> Data Cube: A Relational Operator Generalizing Group-By, </title> <booktitle> Cross-Tab and Sub-Totals. Proc. of the 12th Int. Conf. on Data Engineering, </booktitle> <pages> pp 152-159, </pages> <year> 1996. </year>
Reference-contexts: Speed is critical for this precomputation as well, since the cost and speed of precomputation influences how frequently the aggregates are brought up-to-date. 1.1 What is a CUBE? Recently, <ref> [GBLP96] </ref> introduced the CUBE operator for conveniently supporting multiple aggregates in OLAP databases. The CUBE operator is the n-dimensional generalization of the group-by operator. It computes group-bys corresponding to all possible combinations of a list of attributes. <p> There are several ways in which this simple solution can be improved. In this paper, we present fast algorithms for computing the data cube. We assume that the aggregating functions are distributive <ref> [GBLP96] </ref>, that is, they allow the input set to be partitioned into disjoint sets that can be aggregated separately and later combined. Examples of distributive functions include max, min, count, and sum. The proposed algorithms are also applicable to the algebraic aggregate functions [GBLP96], such as average, that can be expressed <p> assume that the aggregating functions are distributive <ref> [GBLP96] </ref>, that is, they allow the input set to be partitioned into disjoint sets that can be aggregated separately and later combined. Examples of distributive functions include max, min, count, and sum. The proposed algorithms are also applicable to the algebraic aggregate functions [GBLP96], such as average, that can be expressed in terms of other distributive functions (sum and count in the case of average). However, as pointed out in [GBLP96], there are some aggregate functions (holistic functions of [GBLP96]) e.g., median, that cannot be computed in parts and combined. <p> Examples of distributive functions include max, min, count, and sum. The proposed algorithms are also applicable to the algebraic aggregate functions <ref> [GBLP96] </ref>, such as average, that can be expressed in terms of other distributive functions (sum and count in the case of average). However, as pointed out in [GBLP96], there are some aggregate functions (holistic functions of [GBLP96]) e.g., median, that cannot be computed in parts and combined. Related Work Methods of computing single group-bys have been well-studied (see [Gra93] for a survey), but little work has been done on optimizing a collection of related aggregates. [GBLP96] gives some <p> The proposed algorithms are also applicable to the algebraic aggregate functions <ref> [GBLP96] </ref>, such as average, that can be expressed in terms of other distributive functions (sum and count in the case of average). However, as pointed out in [GBLP96], there are some aggregate functions (holistic functions of [GBLP96]) e.g., median, that cannot be computed in parts and combined. Related Work Methods of computing single group-bys have been well-studied (see [Gra93] for a survey), but little work has been done on optimizing a collection of related aggregates. [GBLP96] gives some rules of thumb to be used in an efficient <p> out in <ref> [GBLP96] </ref>, there are some aggregate functions (holistic functions of [GBLP96]) e.g., median, that cannot be computed in parts and combined. Related Work Methods of computing single group-bys have been well-studied (see [Gra93] for a survey), but little work has been done on optimizing a collection of related aggregates. [GBLP96] gives some rules of thumb to be used in an efficient implementation of the cube operator. These include the smallest parent optimization and partitioning of data by attribute values, which we adopt in our algorithms. However, the primary focus in [GBLP96] is on defining the semantics of the cube operator <p> been done on optimizing a collection of related aggregates. <ref> [GBLP96] </ref> gives some rules of thumb to be used in an efficient implementation of the cube operator. These include the smallest parent optimization and partitioning of data by attribute values, which we adopt in our algorithms. However, the primary focus in [GBLP96] is on defining the semantics of the cube operator [GBLP96]. <p> These include the smallest parent optimization and partitioning of data by attribute values, which we adopt in our algorithms. However, the primary focus in <ref> [GBLP96] </ref> is on defining the semantics of the cube operator [GBLP96]. There are reports of on-going research related to the data cube in directions complementary to ours: [HRU96, GHRU96] presents algorithms for deciding what group-bys to pre-compute and index; [SR96] and [JS96] discuss methods for indexing pre-computed summaries to allow efficient querying. <p> We will adapt these methods to compute multiple group-bys by incorporating the following optimizations: 1. Smallest-parent: This optimization, first proposed in <ref> [GBLP96] </ref>, aims at computing a group-by from the smallest previously computed group-by. In general, each group-by can be computed from a number of other group-bys. Figure 1 shows a four attribute cube (ABCD) and the options for computing a group-by from a group-by having one more attribute called its parent. <p> Naughton and Raghu Ramakrish-nan; fpmd, sameet, naughton, raghug@cs.wisc.edu, University of Wisconsin-Madison. It was supported by a grant from IBM under the University Partnership Programand NSF grant IRI-9157357 be represented as a k + 1 attribute relation by using the special value ALL for the remaining k j attributes <ref> [GBLP96] </ref>. The CUBE on attribute set X is the union of cuboids on all subsets of attributes of X. The cuboid (or group-by) on all attributes in X is called the base cuboid. To compute the CUBE we need to compute all the cuboids that together form the CUBE.
Reference: [GJ79] <author> M.R. Garey and D.S. Johnson. </author> <title> Computers and Intractability, </title> <editor> pages 45-76,65,96,208-209,247. W. H. </editor> <publisher> Freeman, </publisher> <address> San Francisco, </address> <year> 1979. </year>
Reference-contexts: We have ex Page 2 tended these algorithms to two important real-life OLAP cases. The first deals with the useful case of computing a specified subset of the group-bys in a cube. For this case, we identify a reduction of the problem to the minimum steiner tree <ref> [GJ79] </ref> problem. This enables us to find plans that consider computation of intermediate group-bys that are not part of the specified subset but can lead to smaller total cost. The second extension handles the case in which attributes have hierarchies defined on them. <p> This problem is similar to well-known NP-complete partitioning problems <ref> [GJ79] </ref>. Hence, we resort to using a heuristic solution. Later (in Section 5) we show that our solution is very close to empirically estimated lower bounds for several datasets.
Reference: [GLS94] <author> G. Graefe, A. Linville, and L. D. Shapiro. </author> <title> Sort versus hash revisited. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 6(1) </volume> <pages> 934-944, </pages> <year> 1994. </year>
Reference-contexts: For Dataset-D, PipeSort is almost a factor of two better than PipeHash. Based on results in <ref> [GLS94] </ref>, we had expected the hash-based method to be comparable or better than the sort-based method.
Reference: [Gra93] <author> G. Graefe. </author> <title> Query evaluation techniques for large databases. </title> <journal> ACM Computing Surveys, </journal> <volume> 25(2) </volume> <pages> 73-170, </pages> <month> Jun </month> <year> 1993. </year>
Reference-contexts: However, as pointed out in [GBLP96], there are some aggregate functions (holistic functions of [GBLP96]) e.g., median, that cannot be computed in parts and combined. Related Work Methods of computing single group-bys have been well-studied (see <ref> [Gra93] </ref> for a survey), but little work has been done on optimizing a collection of related aggregates. [GBLP96] gives some rules of thumb to be used in an efficient implementation of the cube operator. <p> Part I 1 1 This part presents work done by Sunita Sarawagi, Rakesh Agrawal and Ashish Gupta at IBM Almaden Research Center, San Jose. 2 Optimizations Possible There are two basic methods for computing a group-by: (1) the sort-based method and (2) the hash-based method <ref> [Gra93] </ref>. We will adapt these methods to compute multiple group-bys by incorporating the following optimizations: 1. Smallest-parent: This optimization, first proposed in [GBLP96], aims at computing a group-by from the smallest previously computed group-by. In general, each group-by can be computed from a number of other group-bys. <p> Our experiments reported in Section 5 also show that our solution is very close to empirically estimated lower bounds for several datasets. Further Enhancements Our implementation of PipeSort includes the usual optimizations of aggregating and removing duplicates while sorting, instead of doing aggregation as a different phase after sorting <ref> [Gra93] </ref>. Often we can reduce the sorting cost by taking advantage of the partial sorting order. <p> This can significantly reduce the number of I/Os required. The details of this scheme are explained in Section 8. 7.1 Computing the Group-bys using Sorting In relational query processing, there are various methods for computing a group-by, such as sorting or hashing <ref> [EPST79, Gra93, SN95] </ref>. These methods can be used to compute one cuboid from another. We concentrate on sorting based methods in this paper, though we believe that hashing could also be used similarly. Computing a CUBE requires computation of a number of cuboids (group-bys).
Reference: [HNSS95] <author> P.J. Haas, J.F. Naughton, S. Seshadri, and L. </author> <title> Stokes. Sampling-based estimation of the number of distinct values of an attribute. </title> <booktitle> In Proceedings of the Eighth International Conference on Very Large Databases (VLDB), </booktitle> <pages> pages 311-22, </pages> <address> Zurich, Switzerland, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: During the course of execution of a pipeline we need to keep only one tuple per group-by in the pipeline in memory. Algorithm PipeSort Assume that for each group-by we have an estimate of the number of distinct values. A number of statistical procedures (e.g., <ref> [HNSS95] </ref>) can be used for this purpose. The input to the algorithm is the search lattice defined as follows. Search Lattice A search lattice [HRU96] for a data cube is a graph where a vertex represents a group-by of the cube.
Reference: [JS96] <author> T. Johnson and D. Shasha. </author> <title> Hierarchically split cube forests for decision support: </title> <booktitle> description and tuned design, </booktitle> <year> 1996. </year> <note> Working Paper. </note>
Reference-contexts: However, the primary focus in [GBLP96] is on defining the semantics of the cube operator [GBLP96]. There are reports of on-going research related to the data cube in directions complementary to ours: [HRU96, GHRU96] presents algorithms for deciding what group-bys to pre-compute and index; [SR96] and <ref> [JS96] </ref> discuss methods for indexing pre-computed summaries to allow efficient querying. Aggregate pre-computation is quite common in statistical databases [Sho82]. Research in this area has considered various aspects of the problem starting from developing a model for aggregate computation [CM89], indexing pre-computed aggregates [STL89] and incrementally maintaining them [Mic92].
Reference: [PS82] <author> C.H. Papadimitriou and K. Steiglitz. </author> <title> Combinatorial Optimization: Algorithms and Complexity, </title> <booktitle> chapter 11, </booktitle> <pages> pages 247-254. </pages> <address> Englewood Cliffs, N.J., </address> <publisher> Prentice Hall, </publisher> <year> 1982. </year>
Reference-contexts: For each level k, it finds the best way of computing level k from level k + 1 by reducing the problem to a weighted bipartite matching problem 2 <ref> [PS82] </ref> as follows. 2 The weighted bipartite matching problems is defined as follows: We are given a graph with two disjoint sets of vertices V 1 and V 2 and a set of edges E that connect vertices in set V 1 to vertices in set V 2 . <p> Similarly, since C is connected to AC by an A () edge, AC will be generated in the attribute order CA. Since, BC is not matched to any level-1 group-by, BC can be computed in any order. We use the algorithm in <ref> [PS82] </ref> for finding the minimum cost matching in a bipartite graph 4 . The complexity of this algorithm is O (((k + 1)M k+1 ) 3 ), where M k+1 is the number of group-bys in level k + 1.
Reference: [FELL57] <author> William Feller. </author> <title> An Introduction to Probability Theory and Its Applications, Vol. I, page 241. </title> <publisher> John Wiley & Sons, </publisher> <year> 1957. </year>
Reference: [HRU96] <author> Venky Harinarayan, Anand Rajaraman and Jeff Ullman. </author> <title> Implementing Data Cubes Efficiently. </title> <booktitle> In Proc. of the 1996 ACM-SIGMOD Conference, </booktitle> <year> 1996. </year>
Reference-contexts: However, the primary focus in [GBLP96] is on defining the semantics of the cube operator [GBLP96]. There are reports of on-going research related to the data cube in directions complementary to ours: <ref> [HRU96, GHRU96] </ref> presents algorithms for deciding what group-bys to pre-compute and index; [SR96] and [JS96] discuss methods for indexing pre-computed summaries to allow efficient querying. Aggregate pre-computation is quite common in statistical databases [Sho82]. <p> Algorithm PipeSort Assume that for each group-by we have an estimate of the number of distinct values. A number of statistical procedures (e.g., [HNSS95]) can be used for this purpose. The input to the algorithm is the search lattice defined as follows. Search Lattice A search lattice <ref> [HRU96] </ref> for a data cube is a graph where a vertex represents a group-by of the cube. A directed edge connects group-by i to group-by j whenever j can be generated from i and j has exactly one attribute less than i (i is called the parent of j).
Reference: [GHRU96] <author> Himanshu Gupta, Venky Harinarayan, Anand Rajaraman and Jeffrey D. Ullman. </author> <title> Index Selection for OLAP Working Paper, </title> <year> 1996. </year>
Reference-contexts: However, the primary focus in [GBLP96] is on defining the semantics of the cube operator [GBLP96]. There are reports of on-going research related to the data cube in directions complementary to ours: <ref> [HRU96, GHRU96] </ref> presents algorithms for deciding what group-bys to pre-compute and index; [SR96] and [JS96] discuss methods for indexing pre-computed summaries to allow efficient querying. Aggregate pre-computation is quite common in statistical databases [Sho82].
Reference: [EPST79] <author> Robert Epsteinr. </author> <title> Techniques for Processing of Aggregates in Relational Database Systems. </title> <institution> Memo UCB/ERL M79/8, E.R.L., College of Engg., U. of California, Berkeley, </institution> <month> Feb </month> <year> 1979. </year>
Reference-contexts: This can significantly reduce the number of I/Os required. The details of this scheme are explained in Section 8. 7.1 Computing the Group-bys using Sorting In relational query processing, there are various methods for computing a group-by, such as sorting or hashing <ref> [EPST79, Gra93, SN95] </ref>. These methods can be used to compute one cuboid from another. We concentrate on sorting based methods in this paper, though we believe that hashing could also be used similarly. Computing a CUBE requires computation of a number of cuboids (group-bys).
Reference: [SN95] <author> Ambuj Shatdal and Jeffrey F. Naughton. </author> <title> Adaptive Parallel Aggregation Algorithms. </title> <booktitle> Proc. of the 1995 ACM-SIGMOD Conference, </booktitle> <address> San Jose, CA, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: This can significantly reduce the number of I/Os required. The details of this scheme are explained in Section 8. 7.1 Computing the Group-bys using Sorting In relational query processing, there are various methods for computing a group-by, such as sorting or hashing <ref> [EPST79, Gra93, SN95] </ref>. These methods can be used to compute one cuboid from another. We concentrate on sorting based methods in this paper, though we believe that hashing could also be used similarly. Computing a CUBE requires computation of a number of cuboids (group-bys).
Reference: [SDNR96] <author> Amit Shukla, Prasad M. Deshpande, Jeffrey F. Naughton and Karthik Ramasamy. </author> <title> Storage Estimation for Multidimensional Aggregates in the Presence of Hierarchies. </title> <booktitle> To appear in Proc. of the 22nd VLDB Conference, </booktitle> <year> 1996. </year>
Reference: [SAG96] <author> Sunita Sarawagi, Rakesh Agrawal, and Ashish Gupta. </author> <title> On computing the data cube. </title> <type> Research Report RJ 10026, </type> <institution> IBM Almaden Research Center, </institution> <address> San Jose, California, </address> <year> 1996. </year> <note> Available from http://www.almaden.ibm.com/cs/quest. </note>
Reference-contexts: However, to the best of our knowledge, there is no published work in the statistical database literature on methods for optimizing the computation of related aggregates. This paper is in two parts and combines work done concurrently on computing the data cube. Part I presents the methods proposed by <ref> [SAG96] </ref>, whereas the methods proposed by [DANR96] are described in Part II. Section 10 presents a summary and brief comparison of the two approaches. <p> The second extension handles the case in which attributes have hierarchies defined on them. Due to space limitation, we have not included these extensions in this paper, and we refer the reader to <ref> [SAG96] </ref> for them. 3 Sort-based methods In this section, we present the sort-based algorithm that incorporates the optimizations listed earlier. We include the optimization share-sort by using data sorted in a particular order to compute all group-bys that are prefixes of that order. <p> A sales transaction here consists of four attributes: the customer identifier (213972), the order date (2589), the product identifier (15836), and the catalog used for ordering (214). 5 Refer <ref> [SAG96] </ref> for a discussion of how we handle the problems of data skew and incorrect size estimates in allocating hash tables NH:NaiveHash PH:PipeHash NS:NaiveSort PS:PipeSort on the five real life datasets. <p> Performance results Figure 5 shows the performance of the proposed PipeHash and PipeSort relative to the corresponding naive algorithms and estimated lower bounds. The total execution time is normalized by the time taken by the NaiveHash algorithm for each dataset to enable presentation on the same scale. In <ref> [SAG96] </ref> we discuss the methods we used for estimating the size of each group-by and the hashing function used with NaiveHash and PipeHash. <p> Our proposed extension considers intermediate group-bys that are not in the desired subset for generating the best plan. We also extended our algorithms for computing aggregations in the presence of hierarchies on attributes. These extensions are discussed in <ref> [SAG96] </ref>. 10.2 Summary of Part II In this part we have examined various schemes to implement the CUBE operator. Sorting-based methods exploit the existing ordering to reduce the number of sorts.
Reference: [DANR96] <author> Prasad M. Deshpande, Sameet Agarwal, Jef-frey F. Naughton and Raghu Ramakrish-nan. </author> <title> Computation of Multidimensional Aggregates. </title> <type> Technical Report-1314, </type> <institution> University of Wisconsin-Madison, </institution> <year> 1996. </year>
Reference-contexts: This paper is in two parts and combines work done concurrently on computing the data cube. Part I presents the methods proposed by [SAG96], whereas the methods proposed by <ref> [DANR96] </ref> are described in Part II. Section 10 presents a summary and brief comparison of the two approaches. <p> Computations of different cuboids are overlapped and all cuboids are computed in sorted order. In this paper we give only a short description of our method. More details can be found in <ref> [DANR96] </ref>. We first define some terms which will be used frequently. Sorted Runs : Consider a cuboid on j attributes fA 1 ; A 2 ; : : : ; A j g. <p> This decides the sort order in which the other cuboids get computed. The sort orders for the other cuboids of fA; B; C; Dg are shown in the Figure 7. A few heuristics for choosing this sort order are mentioned in <ref> [DANR96] </ref>. Computation of each cuboid requires some amount of memory. If there is enough to memory to hold all the cuboids, then the entire CUBE can be computed in one scan of the input relation. But often, this is not the case. <p> To compute a cuboid in memory, we need memory equal to the size of its partition. We assume that we have estimates of sizes of the cuboids. The partition sizes can be estimated from these using uniform distribution assumption <ref> [DANR96] </ref>. If this much memory can be allocated, the cuboid will be marked to be in Partition state. For some other cuboids it may be possible to allocate one page of memory. These cuboids will be SortRun state. <p> We have shown that finding an overall optimal allocation scheme for our cuboid tree is NP-hard <ref> [DANR96] </ref> . So, instead of trying to find the optimal allocation we do the allocation by using the heuristic of traversing the tree in a breadth first (BF) search order: * Cuboids to the left have smaller partition sizes, and require less memory. <p> Performance was measured in terms of I/Os by counting the number of page read and page write requests generated by the algorithm and is thus independent of the OS. A detailed performance study is described in <ref> [DANR96] </ref>. We mention only a few important experiments here. Unless otherwise mentioned, the data for the input relation was generated randomly. The values for each attribute is independently chosen uniformly from a domain of values for that attribute.
Reference: [Mic92] <author> Z. Michalewicz. </author> <title> Statistical and Scientific Databases. </title> <publisher> Ellis Horwood, </publisher> <year> 1992. </year>
Reference-contexts: Aggregate pre-computation is quite common in statistical databases [Sho82]. Research in this area has considered various aspects of the problem starting from developing a model for aggregate computation [CM89], indexing pre-computed aggregates [STL89] and incrementally maintaining them <ref> [Mic92] </ref>. However, to the best of our knowledge, there is no published work in the statistical database literature on methods for optimizing the computation of related aggregates. This paper is in two parts and combines work done concurrently on computing the data cube.
Reference: [NC95] <author> Pendse, Nigel and Richard Creeth. </author> <title> The OLAP Report. </title> <booktitle> Business Intelligence, </booktitle> <address> London, Eng-land, </address> <year> 1995. </year>
Reference: [CODD93] <author> E. F. Codd. </author> <title> Providing OLAP: An IT Mandate Unpublished Manuscript, </title> <publisher> E.F. Codd and Associates, </publisher> <year> 1993. </year>
Reference-contexts: Speed is a primary goal in these class of applications called On-Line Analytical Processing (OLAP) applications <ref> [CODD93] </ref>. To make interactive analysis (response time in seconds) possible, OLAP databases often precompute aggregates at various levels of detail and on various combinations of attributes.
Reference: [FINK] <author> Richard Finkelstein. </author> <title> Understanding the Need for On-Line Analytical Servers. Unpublished Manuscript, Performance Computing, </title> <publisher> Inc. </publisher>
Reference-contexts: To copy otherwise, or to republish, requires a fee and/or special permission from the Endowment. Proceedings of the 22nd VLDB Conference Mumbai (Bombay), India, 1996 ness data analysis, it is often necessary to aggregate data across many dimensions (attributes) <ref> [FINK, WELD95] </ref>. For example, in a retail application, one might have a table Transactions with attributes Product (P), Date (D), Customer (C) and Sales (S).
Reference: [Sho82] <author> A. Shoshani. </author> <title> Statistical databases: Characteristics, problems and some solutions. </title> <booktitle> In Proceedings of the Eighth International Conference on Very Large Databases (VLDB), </booktitle> <pages> pages 208-213, </pages> <address> Mexico City, Mexico, </address> <month> September </month> <year> 1982. </year>
Reference-contexts: There are reports of on-going research related to the data cube in directions complementary to ours: [HRU96, GHRU96] presents algorithms for deciding what group-bys to pre-compute and index; [SR96] and [JS96] discuss methods for indexing pre-computed summaries to allow efficient querying. Aggregate pre-computation is quite common in statistical databases <ref> [Sho82] </ref>. Research in this area has considered various aspects of the problem starting from developing a model for aggregate computation [CM89], indexing pre-computed aggregates [STL89] and incrementally maintaining them [Mic92].
Reference: [SR96] <author> B. Salzberg and A. Reuter. </author> <title> Indexing for aggregation, </title> <note> 1996. Working Paper. </note>
Reference-contexts: However, the primary focus in [GBLP96] is on defining the semantics of the cube operator [GBLP96]. There are reports of on-going research related to the data cube in directions complementary to ours: [HRU96, GHRU96] presents algorithms for deciding what group-bys to pre-compute and index; <ref> [SR96] </ref> and [JS96] discuss methods for indexing pre-computed summaries to allow efficient querying. Aggregate pre-computation is quite common in statistical databases [Sho82].
Reference: [STG95] <institution> Designing the Data Warehouse on Relational Databases. </institution> <type> Unpublished Manuscript, </type> <institution> Stanford Technology Group, Inc, </institution> <year> 1995. </year>
Reference: [STL89] <author> J. Srivastava, J.S.E. Tan, and V.Y. Lum. TB-SAM: </author> <title> An access method for efficient processing of statistical queries. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 1(4), </volume> <year> 1989. </year>
Reference-contexts: Aggregate pre-computation is quite common in statistical databases [Sho82]. Research in this area has considered various aspects of the problem starting from developing a model for aggregate computation [CM89], indexing pre-computed aggregates <ref> [STL89] </ref> and incrementally maintaining them [Mic92]. However, to the best of our knowledge, there is no published work in the statistical database literature on methods for optimizing the computation of related aggregates. This paper is in two parts and combines work done concurrently on computing the data cube.
Reference: [WELD95] <author> Jay-Louise Weldon. </author> <title> Managing Multidimensional Data: Harnessing the Power. </title> <type> Unpublished Manuscript, </type> <year> 1995. </year> <pages> Page 16 </pages>
Reference-contexts: To copy otherwise, or to republish, requires a fee and/or special permission from the Endowment. Proceedings of the 22nd VLDB Conference Mumbai (Bombay), India, 1996 ness data analysis, it is often necessary to aggregate data across many dimensions (attributes) <ref> [FINK, WELD95] </ref>. For example, in a retail application, one might have a table Transactions with attributes Product (P), Date (D), Customer (C) and Sales (S).
References-found: 25

