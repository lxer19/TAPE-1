URL: http://www.cs.huji.ac.il/papers/IP/disambiguation.ps.gz
Refering-URL: http://www.cs.huji.ac.il/papers/IP/index.html
Root-URL: 
Title: On View Likelihood and Stability  
Author: Daphna Weinshall and Michael Werman 
Keyword: generic views, characteristic views, canonical views, view likelihood, view stability, object recognition, 3D reconstruction, Bayesian vision  
Address: 91904 Jerusalem, Israel  
Affiliation: Institute of Computer Science, The Hebrew University of Jerusalem  
Note: To appear in IEEE Transactions on Pattern Analysis Machine Intelligence,  
Email: contact email: daphna@cs.huji.ac.il  
Date: 1997  
Abstract: We define two measures on views: view likelihood and view stability. View likelihood measures the probability that a certain view of a given 3D object is observed; it may be used to identify typical, or "characteristic", views. View stability measures how little the image changes as the viewpoint is slightly perturbed; it may be used to identify "generic" views. Both definitions are shown to be identical up to the prior probability of camera orientations, and determined by the 2D metric used to compare images. We analytically derive the stability and likelihood measures for two feature-based 2D metrics, where the most stable and most likely view is shown to be the flattest view of the 3D shape. Incorporating view likelihood or stability in 3D object recognition and 3D reconstruction increases the chance of robust performance. In particular, we propose to use these measures to enhance 3D object recognition and 3D reconstruction algorithms, by adding a second step where the most likely solution is selected among all feasible solutions. These applications are demonstrated using simulated and real images. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F. Attneave. </author> <title> Some informational aspects of visual perception. </title> <journal> Psychol. Rev., </journal> <pages> pages 183-193, </pages> <year> 1954. </year>
Reference: [2] <author> R. Basri and D. Weinshall. </author> <title> Distance metric between 3D models and 2D images for recognition and classification. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 18(4) </volume> <pages> 465-470, </pages> <year> 1996. </year>
Reference-contexts: Since each camera orientation corresponds to a point on the viewing sphere, all the object's images are completely parameterized by two angles. In the following, ' denotes the azimuth (longitude) and # denotes the elevation (colatitude). The range # 2 <ref> [0; 2 ] </ref>; ' 2 [0; 2] parameterizes half the viewing sphere. Let V #;' denote a viewpoint on the viewing sphere with elevation # and azimuth '. Let I #;';O denote the 2D image (or view) of object O obtained from viewpoint V #;' . <p> Since each camera orientation corresponds to a point on the viewing sphere, all the object's images are completely parameterized by two angles. In the following, ' denotes the azimuth (longitude) and # denotes the elevation (colatitude). The range # 2 [0; 2 ]; ' 2 <ref> [0; 2] </ref> parameterizes half the viewing sphere. Let V #;' denote a viewpoint on the viewing sphere with elevation # and azimuth '. Let I #;';O denote the 2D image (or view) of object O obtained from viewpoint V #;' . <p> In order to predict which objects each system finds without simulating the actual algorithm, we perform the following meta-analysis: We compute the model-to-image distances 3 described in <ref> [2] </ref> to evaluate how well each object fits each image. The objects which achieve a small model-to-image distance are feasible matches for these geometrical object recognition methods. We therefore assume that all objects which achieve a sub-threshold model-to-image distance are chosen by the object recognition method of choice. <p> Using the algorithm described in <ref> [2] </ref>, we compute the view (up to similarity transformation) of the flat box closest to the left image. <p> This equation has a unique solution in the range # 2 [0; ]; ' 2 <ref> [0; 2] </ref>, since we started with a matrix p which is a real projection after rotation of the matrix P. The simplest way to compute #; ' is to solve for the matrix equality above element-by-element.

Reference: [4] <author> T.O. Binford and T.S. Levitt. Quasi-invariants: </author> <title> Theory and exploitation. </title> <booktitle> Image Understanding Workshop, </booktitle> <pages> pages 819-829, </pages> <year> 1993. </year>
Reference-contexts: Below we provide a simple expression which can be used to numerically estimate the stability and likelihood profiles of general objects, and identify the most likely and stable views of any object. Measuring stability: Binford & Levitt <ref> [4] </ref> defined the concept of quasi-invariants, or the local minima of the change in the image when changing the viewing parameters. Other studies proposed to measure stability via the Lie derivatives of the group of transformations describing the motion of the camera [15].
Reference: [5] <author> H. H. Bulthoff and H. A. Mallot. </author> <title> Interaction of different modules in depth perception. </title> <booktitle> In Proceedings of the 1st International Conference on Computer Vision, </booktitle> <pages> pages 295-305, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: This results in choosing a flatter ellipsoid with parameters 1; 2; 3:2 instead of 1; 2; 5. This flattening effect is consistent with psychological evidence in humans <ref> [5] </ref>. (Note that human judgment takes into account many other priors and heuristics on the kind of shapes one is likely to encounter; thus we only expect to see correspondence between human performance and the most stable views under rather simple and impoverished conditions, such as the images of Lambertian ellipsoids.)
Reference: [6] <author> J.B. Burns, R. Weiss, and E. Riseman. </author> <title> View variation of point-set and line segment features. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15(1) </volume> <pages> 51-68, </pages> <year> 1993. </year>
Reference-contexts: Using this observation, our likelihood measure can be incorporated into Freeman's Bayesian probabilistic scheme by taking the role of conditional image probability. Measuring likelihood: View likelihood of angles was computed using numerical simulations by Ben-Arie [3] and Burns et al. <ref> [6] </ref>. Dickinson et al. [8] empirically found the more likely views of particular objects decomposed into geons. In this earlier work, the analysis of likelihood was carried out for simple image measurements: either discrete (qualitative) or 1-dimensional (angles). <p> Note, however, that the general problem requires the numerical estimation of likelihood when the image measurements change continuously with the viewing parameters; this computation is harder, as it requires the numerical estimation of limits. Thus the simulation work described in <ref> [3, 6, 8] </ref> cannot be readily generalized to compute view likelihood of general objects. Below we provide a simple expression which can be used to numerically estimate the stability and likelihood profiles of general objects, and identify the most likely and stable views of any object.
Reference: [7] <author> I. Chakravarty and H. Freeman. </author> <title> Characteristic views as a basis for three-dimensional object recognition. </title> <booktitle> In Proc. SPIE Conf. on Robot Vision, </booktitle> <volume> volume 336, </volume> <pages> pages 37-45, </pages> <year> 1982. </year>
Reference-contexts: The concept of characteristic views appears in viewer-centered approaches to 3D shape representation, where three dimensional information is not represented explicitly. Rather, the shape of object is represented implicitly by a list of 2D characteristic views (e.g., <ref> [7] </ref>). Our study is the first to give a computational analysis of what makes images characteristic. 3 Stability and likelihood of views: general We define measures of view likelihood and stability, assigned to a general 3D object denoted O and its projection along a specific viewing direction.
Reference: [8] <author> S. J. Dickinson, A. P. Pentland, and A. Rosenfeld. </author> <title> 3-D shape recovery using distributed aspect matching. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(2) </volume> <pages> 174-198, </pages> <year> 1992. </year>
Reference-contexts: Using this observation, our likelihood measure can be incorporated into Freeman's Bayesian probabilistic scheme by taking the role of conditional image probability. Measuring likelihood: View likelihood of angles was computed using numerical simulations by Ben-Arie [3] and Burns et al. [6]. Dickinson et al. <ref> [8] </ref> empirically found the more likely views of particular objects decomposed into geons. In this earlier work, the analysis of likelihood was carried out for simple image measurements: either discrete (qualitative) or 1-dimensional (angles). <p> Note, however, that the general problem requires the numerical estimation of likelihood when the image measurements change continuously with the viewing parameters; this computation is harder, as it requires the numerical estimation of limits. Thus the simulation work described in <ref> [3, 6, 8] </ref> cannot be readily generalized to compute view likelihood of general objects. Below we provide a simple expression which can be used to numerically estimate the stability and likelihood profiles of general objects, and identify the most likely and stable views of any object.
Reference: [9] <author> Attneave F and M.D. Arnoult. </author> <title> The quantitative study of shape and pattern perception. </title> <journal> Psychol. Bull., </journal> <pages> pages 452-471, </pages> <year> 1956. </year>
Reference: [10] <author> W. T. Freeman. </author> <title> Exploiting the generic view assumption to estimate scene parameters. </title> <booktitle> In Proceedings of the 4th International Conference on Computer Vision, </booktitle> <pages> pages 347-356, </pages> <address> Berlin, Germany, 1993. </address> <publisher> IEEE, </publisher> <address> Washington, DC. </address>
Reference-contexts: are: (1) easy to use, and (2) 3 enhance performance when incorporated into existing 3D reconstruction and object recognition techniques. 2 Previous work: review and comparison A few recent studies attempted to approach in a formal way issues related to the ones discussed in this paper: Bayesian image understanding: Freeman <ref> [10, 11] </ref> suggested to use a measure of view stability in the interpretation of ambiguous scenes (see also [21]). In his Bayesian scheme, an interpretation which involves the more stable, or more generic, viewpoint is preferred. <p> Another line of work, that may superficially appear similar to ours, addresses a very different question. Practically all the probabilistic approaches to image understanding do not take into 4 account image likelihood as defined here (with the exception of <ref> [10] </ref>). Rather, their goal is to transform an optimization problem to a maximum likelihood problem. <p> where a = b = c = 1, all the images of such an object are equally likely). 5.3 Maximum likelihood reconstruction: When there exist cues for 3D structure, but many reconstructions are feasible, the view likelihood may be used to select the best among the solutions under consideration (cf. <ref> [10] </ref>). We will describe below 2 examples of such a process: one with an object with fiducial points, the other with a shaded smooth object.
Reference: [11] <author> W. T. Freeman. </author> <title> The generic viewpoint assumption in a framework for visual perception. </title> <journal> Nature, </journal> <volume> 368(6471) </volume> <pages> 542-545, </pages> <month> April 7 </month> <year> 1994. </year>
Reference-contexts: are: (1) easy to use, and (2) 3 enhance performance when incorporated into existing 3D reconstruction and object recognition techniques. 2 Previous work: review and comparison A few recent studies attempted to approach in a formal way issues related to the ones discussed in this paper: Bayesian image understanding: Freeman <ref> [10, 11] </ref> suggested to use a measure of view stability in the interpretation of ambiguous scenes (see also [21]). In his Bayesian scheme, an interpretation which involves the more stable, or more generic, viewpoint is preferred.
Reference: [12] <author> Y. Gdalyahu and D. Weinshall. </author> <title> Measures for silhouettes resemblance and the most representative silhouette of a curved object. </title> <booktitle> In Proceedings of the 4th European Conference on Computer Vision, </booktitle> <address> Cambridge, UK, 1996. </address> <publisher> Springer-Verlag. </publisher>
Reference: [13] <author> E. C. Hildreth, N. M. Grzywacz, E. H. Adelson, and V. K. Inada. </author> <title> The perceptual buildup of three-dimensional structure from motion. </title> <journal> Perception & Psychophysics, </journal> <volume> 48(1) </volume> <pages> 19-36, </pages> <year> 1990. </year>
Reference-contexts: In fact, this heuristic is typically employed by iterative reconstruction algorithms which assign depth 0 as the default value in the first iteration (e.g., <ref> [13] </ref>). 5 Applications: enhanced object recognition and reconstruction The following examples illustrate various applications of view likelihood in object recognition and 3D reconstruction. We start by computing some characteristic views in Section 5.1. In Section 5.2 we demonstrate maximum likelihood 3D object recognition using simulated images.
Reference: [14] <author> D. P. Huttenlocher and S. Ullman. </author> <title> Recognizing solid objects by alignment with an image. </title> <journal> International Journal of Computer Vision, </journal> <volume> 5 </volume> <pages> 195-212, </pages> <year> 1990. </year>
Reference-contexts: To recognize the 3 images shown at the top row of Fig. 1, we proceed as follows: 15 Step 1: geometrical object recognition A feature-based object recognition technique (e.g., alignment <ref> [14] </ref> or geometric hashing [16]) is first used to compute a list of candidate objects which match the given images. <p> We first compute the model-to-image distance between each model and the picture. This gives us the function shown in Fig. 10. A picture of the correct model, which obtains a small image error, is shown in Fig. 11-left. coordinates are drawn in log scale in the ranges d 2 <ref> [14; 86] </ref>; h 2 [14:5 41]. the image of the original vertices of the charger. Right: the view of the most likely model, super-imposed on the original vertices. Clearly, both interpretations match the data reasonably well. 22 2.
Reference: [15] <author> K. Kanatani. </author> <title> Group Theoretical Methods in Image Understanding. </title> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1990. </year>
Reference-contexts: Measuring stability: Binford & Levitt [4] defined the concept of quasi-invariants, or the local minima of the change in the image when changing the viewing parameters. Other studies proposed to measure stability via the Lie derivatives of the group of transformations describing the motion of the camera <ref> [15] </ref>. In most of this earlier work, the analysis of stability rarely went beyond the basic definitions (which were different from our definition). Another line of work, that may superficially appear similar to ours, addresses a very different question.
Reference: [16] <author> Y. Lamdan and H. Wolfson. </author> <title> Geometric hashing: a general and efficient recognition scheme. </title> <booktitle> In Proceedings of the 2nd International Conference on Computer Vision, </booktitle> <pages> pages 238-251, </pages> <address> Tarpon Springs, FL, 1988. </address> <publisher> IEEE, </publisher> <address> Washington, DC. </address>
Reference-contexts: To recognize the 3 images shown at the top row of Fig. 1, we proceed as follows: 15 Step 1: geometrical object recognition A feature-based object recognition technique (e.g., alignment [14] or geometric hashing <ref> [16] </ref>) is first used to compute a list of candidate objects which match the given images.
Reference: [17] <author> I. Rigoutsos and R. Hummel. </author> <title> Distributed bayesian object. </title> <booktitle> In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 180-186, </pages> <year> 1993. </year>
Reference-contexts: Rather, their goal is to transform an optimization problem to a maximum likelihood problem. This is achieved by defining a probability function which is large when the error is small, and vice versa (see, e.g., <ref> [17] </ref>); thus the most likely solution, which is selected at the end, is the solution which minimizes the measurement error.
Reference: [18] <author> S. Ullman and R. Basri. </author> <title> Recognition by linear combinations of models. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(10) </volume> <pages> 992-1006, </pages> <year> 1991. </year> <month> 24 </month>
Reference-contexts: Whenever the numbers are small, it means that there exists a viewpoint from which the object appears similar to the image up to 2D rotation and scale. It follows that an affine-based recognition algorithm, such as geometric hashing or linear combination <ref> [18] </ref>, will produce the set of all 3 objects as feasible matches for each image.
Reference: [19] <author> D. Weinshall and R. Basri. </author> <title> Distance metric between 3d models and 2d images for recognition and classification. </title> <booktitle> In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 220-225, </pages> <address> New-York City, NY, 1993. </address> <publisher> IEEE, </publisher> <address> Washington, DC. </address>
Reference: [20] <author> M. Werman and D. Weinshall. </author> <title> Similarity and affine distance between point sets. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 17(8) </volume> <pages> 810-814, </pages> <year> 1995. </year>
Reference-contexts: To show the usefulness of this general approach, we now derive explicit forms for the view likelihood and stability given two specific feature-based 2D matching metrics. Given objects composed of feature points, there exist natural 2D metrics to compare the images of such objects <ref> [20] </ref>: affine metric d aff : the two images are first aligned with each other with the best 2D affine transformation, and then the sum of the squared distances between each pair of matching feature points is taken. similarity metric d sim : the two images are first aligned with each <p> We therefore assume w.l.o.g. that the images are centered at the centroid of the object, so that the first moment of each image is 0. In <ref> [20] </ref> we defined image metrics, which compare the images P and Q while taking into account the desired image equivalences discussed above.
Reference: [21] <author> A. P. Witkin and J. M. Tenenbaum. </author> <title> On the role of structure in vision. </title> <editor> In J. Beck, B. Hope, and A. Rosenfeld, editors, </editor> <booktitle> Human and Machine Vision, </booktitle> <pages> pages 481-544. </pages> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1983. </year> <month> 25 </month>
Reference-contexts: recognition techniques. 2 Previous work: review and comparison A few recent studies attempted to approach in a formal way issues related to the ones discussed in this paper: Bayesian image understanding: Freeman [10, 11] suggested to use a measure of view stability in the interpretation of ambiguous scenes (see also <ref> [21] </ref>). In his Bayesian scheme, an interpretation which involves the more stable, or more generic, viewpoint is preferred.
References-found: 20

