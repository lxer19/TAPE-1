URL: ftp://ftp.cs.ucsd.edu/pub/grad/jmilosta/newsletter/edit_final.ps.gz
Refering-URL: http://www.cs.ucsd.edu/users/jmilosta/
Root-URL: http://www.cs.ucsd.edu
Title: Connectionist Modeling of the Fast Mapping Phenomenon  
Author: Jeanne Milostan 
Date: December 7, 1994  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Bates, E., Bretherton, I. & Snyder, L. </author> <year> (1988). </year> <title> Acquisition of a novel concept at 20 months. From First Words to Grammar: Individual Differences and Dissociable Mechanisms, </title> <address> 124-134. Cambridge, NY: </address> <publisher> Cambridge University Press. </publisher>
Reference-contexts: In examining the question of what characteristics of language are dissociable, Bates et al. <ref> [1] </ref> also performed a study examining the acquisition of a novel concept in young children. In this study, a novel object was given both a novel name ("fiffin") and a novel associated action ("glooping").
Reference: [2] <author> Carey, S. </author> <title> (1978) The child as word learner. </title> <editor> In M. Halle, G. Miller & J. Bresnan (Eds.), </editor> <booktitle> Linguistic Theory and Psychological Reality, </booktitle> <pages> 264-293. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: 1 Introduction The average child learns some 14,000 words before the age of 6, which represents the daunting task of acquiring 9 new words per day; about one each waking hour <ref> [2] </ref>. Researchers examining the process by which this is accomplished have time and again encountered an interesting effect: often the child can acquire a new word from only one or a small number of exposures to that word. <p> We then speculate on what is missing from the constellation of models available and propose directions for future research in this area. 2 Fast Mapping 2.1 Studies Susan Carey <ref> [2] </ref> began by asking the question "What is learned when a word is added to a child's vocabulary? Where does the process of word learning begin?" In her study, she examined the preschool child's limits on word learning capacity.
Reference: [3] <author> Dollaghan, C. </author> <year> (1985). </year> <title> Child meets word: "Fast Mapping" in preschool children. </title> <journal> Journal of Speech and Hearing Research, </journal> <volume> 28, </volume> <pages> 449-454. </pages>
Reference-contexts: In a study intended to explore what aspects of a word are developed upon fast mapping, Chris Dollaghan <ref> [3] </ref> tracked acquisition and use of a nonsense word, "koob".
Reference: [4] <author> Hecht-Nielsen, R. </author> <year> (1990). </year> <title> Neurocomputing. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher> <pages> 13 </pages>
Reference: [5] <author> Hertz, J. A., Krogh, A. S. & Palmer, R. G. </author> <year> (1991). </year> <title> Introduction to the Theory of Neural Computation. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference: [6] <author> Hinton, G. E. & Plaut, D. C. </author> <year> (1987). </year> <title> Using fast weights to deblur old memories. </title> <booktitle> Proceedings of the Ninth Annual Conference of the Cognitive Science Society, </booktitle> <pages> 177-186. </pages>
Reference-contexts: For a closer examination of what recurrent network may have to offer on this point, see the discussion of generalization and novelty in section 4.5 below. 4.2 Attempts to Address "Fast" Mapping Fast Weights Hinton and Plaut <ref> [6] </ref> modified a standard backpropagation network to have two connections between each unit: one with a slow, stable weight and one with a fast, elastic weight. The slow weights function much as they would in a regular connectionist model: they change slowly and hold the long-term knowledge of the network.
Reference: [7] <author> Kohonen, T. </author> <year> (1984). </year> <title> Self Organization and Associative Memory, Second Edition. </title> <publisher> Berlin: Springer-Verlag. </publisher>
Reference-contexts: One very useful member of this class is the Kohonen network <ref> [7] </ref>. In this model, the network consists of a number of processing elements each of the same dimensionality as the input.
Reference: [8] <author> McClelland, J. L. & Rumelhart, D. E. </author> <year> (1986). </year> <booktitle> Parallel Distributed Processing (Vol. 2). </booktitle> <address> Cam-bridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: [9] <author> Metcalfe, J. </author> <year> (1991). </year> <title> Recognition failure and the composite memory trace in CHARM. </title> <journal> Psychological Review, </journal> <volume> 98, </volume> <pages> 529-553. </pages>
Reference: [10] <author> Metcalfe Eich, J. </author> <year> (1982). </year> <title> A composite holographic associative recall model. </title> <journal> Psychological Review, </journal> <volume> 89, </volume> <pages> 627-661. </pages>
Reference: [11] <author> Metcalfe, J. & Murdock, B. B. </author> <year> (1981). </year> <title> An encoding and retrieval model of single-trial free recall. </title> <journal> Journal of Verbal Learning and Verbal Behavior, </journal> <volume> 20, </volume> <pages> 161-189. </pages>
Reference: [12] <author> Miikkulainen, R. </author> <year> (1993). </year> <title> Subsymbolic Natural Language Processing: An Integrated Model of Scripts, Lexicon and Memory. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: This system holds much promise in its future applicability as a model of fast mapping. 4.3 The DISCERN Model Description The DISCERN model (DIstributed SCript processing and Episodic memoRy Network), developed by Risto Miikkulainen <ref> [12] </ref>, is a distributed artificial neural network system which learns to process simple stories which follow a stereotypic framework. As such, it combines the traditional symbolic artificial intelligence paradigms of scripts and frames with more realistic cognitive modeling and neurocomputation methodology. <p> The proposed system combines aspects of the DISCERN model to represent episodic memory, the sentence gestalt network to provide an attention mechanism, and a recurrent network as described above to represent long-term memory. The DISCERN model <ref> [12] </ref> representation of episodic memory has as its largest drawback an inability to represent truly novel inputs due in part to its basis in symbolic script theory but mostly due to the nature of the autoassociative networks used.
Reference: [13] <author> Nelson, K. E. & Bonvillian, J. D. </author> <year> (1978). </year> <title> Early semantic development: Conceptual growth and related processes between 2 and 4 1/2 years of age. </title> <editor> In K. E. Nelson (Ed.), </editor> <booktitle> Children's Language (Vol. </booktitle> <volume> 1), </volume> <pages> 467-556. </pages> <address> New York: </address> <publisher> Gardner Press. </publisher>
Reference-contexts: Other children adopted the Odd-Color-Odd-Name strategy; these children demonstrated comprehension of the word, but for production named another color from their lexicon which also did not have a stable referent, thus again demonstrating they knew that olive had a separate name. Earlier, Nelson and Bonvillian <ref> [13] </ref> had performed a study in which children were exposed to 18 new concepts, of which 9 were made-up words and 9 were were actual English words which the children had not yet acquired (7 control children also did not acquire these words by the end of the study). <p> The amount and manifestation of the effect was seen to vary with gender, age, and cognitive style whether the child favors one word, telegraphic speech versus whole-phrase speech. Additionally, the effect varied with birth order and sibling constellation. Nelson and Bonvillian <ref> [13] </ref> found that children whose next-older sibling was less than 24 months older gained the most words, with firstborn children close behind while lagging last were those children whose next-older sibling was more than 24 months older.
Reference: [14] <author> Nelson, K. E. </author> <year> (1987). </year> <title> Some observations from the perspective of the rare event cognitive comparison theory of language acquisition. </title> <editor> In K. E. Nelson & A. van Kleek (Eds.), </editor> <booktitle> Children's Language (Vol. </booktitle> <volume> 6), </volume> <pages> 289-331. </pages> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: Conversely, the longer-lag children do not have this benefit, and also do not receive parental attention to the extent that first-born children do. 2.3 Theory Rare Event Cognitive Comparison Theory In <ref> [14] </ref>, Nelson explores how current language and cognitive levels facilitate and limit what will be learned next. The overall acquisition mechanism depends on cognitive comparisons between old and new structures in order for the child to determine when the current language structure is insufficient.
Reference: [15] <author> Plaut, D. C., McClelland, J. L., Seidenberg, M. S. & Patterson, K. E. </author> <year> (1994). </year> <title> Understanding normal and impaired word reading: Computational principles in quasi-regular domains. </title> <note> Submitted to Psychological Review. </note>
Reference-contexts: to make appropriate balances between word order and semantic constraints for determining the meaning and roles of words in a sentence, for example, without this knowledge being 10 otherwise coded into the system by the others. 4.5 Generalization and Novelty Although the linguistic processing model developed by Plaut et al. <ref> [15] </ref> focuses mainly on learning to read (bold connections in Figure 4), the system they have developed demonstrates some interesting behavior which may be applicable to modeling fast mapping. <p> John and McClelland be used to determine which input features deserve the most attention. These feature vectors may then be used as the basis for a system similar to the DISCERN model. Finally, we propose a recurrent system similar to the one used by Plaut et al. <ref> [15] </ref> to represent the long term memory. This type of system provides the necessary generalization and ability to represent novel inputs which is necessary for the representation of memory.
Reference: [16] <author> Rice, M. L. & Woodsmall, L. </author> <year> (1988). </year> <title> Lessons from television: Children's word learning when viewing. Child Development, </title> <booktitle> 59, </booktitle> <pages> 420-429. </pages>
Reference-contexts: Additionally, through analysis Bates demonstrated that the type of knowledge the child demonstrated was correlated with language "style"; that is, fiffin comprehension was related to early comprehension, while fiffin imitation was related to early production. Mabel Rice <ref> [16] </ref> addressed word acquisition from television viewing, thus offering evidence that neither lexical acquisition nor fast mapping in particular are limited to interactive exchanges. In one study, Rice exposed a number of children to short cartoon segments which were designed to introduce new words.
Reference: [17] <author> Rice, M. L., Huston, A. C., Truglio, R. & Wright, J. </author> <year> (1990). </year> <title> Words from "Sesame Street": Learning vocabulary while viewing. </title> <journal> Developmental Psychology, </journal> <volume> 26, </volume> <pages> 421-428. </pages>
Reference-contexts: Additionally, this study demonstrated that words other than object names and attributes were also subject to fast mapping, and that the new words need not be presented in the exact same context each time in order to learn. Rice did additional work <ref> [17] </ref> in a more naturalistic home environment, where it was demonstrated that children learn new words rapidly from educational programs such as "Sesame Street" even with the environmental distractions associated with home television viewing.
Reference: [18] <author> Rumelhart, D. E. & McClelland, J. L. </author> <year> (1986). </year> <booktitle> Parallel Distributed Processing (Vol. 1). </booktitle> <address> Cam-bridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: [19] <author> Rumelhart, D. E., Hinton, G. E. & Williams, R. J. </author> <year> (1986). </year> <title> Learning internal representations by error propagation. </title> <editor> In D. E. Rumelhart & J. L. McClelland (Eds.), </editor> <booktitle> Parallel Distributed Processing (Vol. </booktitle> <volume> 1), </volume> <pages> 318-362. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: This is followed by an examination of a handful of larger systems which attempt to more adequately address human performance issues. 4.1 Basic Connectionist Models Backpropagation The backpropagation neural network <ref> [19] </ref> is a multilayer architecture consisting of fully interconnected, feed forward layers of processing units. Input vectors are presented to the elements of the input layer, and activation is propagated forward through the network to the output layer.
Reference: [20] <author> St. John, M. F. & McClelland, J. L. </author> <year> (1990). </year> <title> Learning and applying contextual constraints in sentence comprehension. </title> <journal> Artificial Intelligence, </journal> <volume> 46, </volume> <pages> 217-257. 14 </pages>
Reference-contexts: Several suggestions for extensions to the system (including those suggested by the author) addressing this limitation will be examined in Section 5 below. 4.4 Attentional Mechanisms The "sentence gestalt" model of St. John and McClelland <ref> [20] </ref> was developed as an attempt to create a model which learns to convert a sentence to a conceptual representation of the event which the sentence describes. Their model is intended to disambiguate ambiguous words, instantiate vague words, assign thematic roles, and elaborate implied roles. <p> We propose also that if the input feature vectors, rather than being handcoded to represent the scripts, were learned by an additional network system, this network would become a more accurate model of episodic memory. The sentence gestalt model developed by St. John and McClelland <ref> [20] </ref> is an ideal candidate for the role of just such an additional network. As described above, this network has demonstrated the ability to develop a form of attentional mechanism. We propose that a network similar to that of St.
References-found: 20

