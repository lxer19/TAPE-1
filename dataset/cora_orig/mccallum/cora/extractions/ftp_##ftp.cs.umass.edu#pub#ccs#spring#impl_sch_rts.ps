URL: ftp://ftp.cs.umass.edu/pub/ccs/spring/impl_sch_rts.ps
Refering-URL: http://www-ccs.cs.umass.edu/stankovic/home.html
Root-URL: 
Author: John A. Stankovic, Marco Spuri, Marco Di Natale, and Giorgio Buttazzo 
Keyword: scheduling theory, real-time, uniprocessor scheduling, multiprocessor scheduling  
Date: June 23, 1994  
Address: via Carducci, 40 56100 Pisa (Italy)  
Affiliation: Real-Time Systems  Scuola Superiore "S.Anna"  
Abstract: Implications of Classical Scheduling Results For Abstract Important classical scheduling theory results for real-time computing are identified. Implications of these results from the perspective of a real-time systems designer are discussed. Uni-processor and multiprocessor results are addressed as well as important issues such as future release times, precedence constraints, shared resources, task value, overloads, static versus dynamic scheduling, preemption versus non-preemption, multiprocessing anomalies, and metrics. Examples of what scheduling algorithms are used in actual applications are given. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Audsley, A. Burns, M. Richardson, and A. Wellings, </author> <title> "Hard Real-Time Scheduling: The Deadline Monotonic Approach," </title> <booktitle> IEEE Workshop on Real-Time Operating Systems, </booktitle> <year> 1992. </year>
Reference-contexts: The rate monotonic algorithm has been extended in many ways the most important of which deals 6 with shared resources (see Section 3.3), and schedulability tests have been formulated for the deadline monotonic algorithm <ref> [1] </ref>. The rate monotonic scheduling algorithm has been chosen for the Space Station Freedom Project, the FAA Advanced Automation System (AAS), and has influenced the specification of the IEEE Futurebus+.
Reference: [2] <author> T.P. Baker, </author> <title> "Stack-Based Scheduling of Real-time Processes," </title> <journal> Journal of Real-Time Systems, </journal> <volume> 3, </volume> <year> 1991. </year>
Reference-contexts: If preemption is allowed, classical results go further in providing solutions for general precedence constraints. Preemption reduces the complexity of the scheduling problem of precedence related tasks with different arrival times. The problem is, in fact, solvable in O (n 2 ) by Baker's algorithm <ref> [2] </ref> 9 1 j prec; pmtn; r i j L max : Baker's procedure is recursive and because of its computational complexity it seems suited for off-line scheduling. Due to the difficulty of describing the algorithm and space limitations, we do not describe the algorithm here. <p> At this point several choices are possible. One of them, followed by Mok, is to enforce the use of mutually exclusive scheduling blocks having the same computation time, and another, followed, for example, by Sha et al. [27] and Baker <ref> [2] </ref>, is to efficiently find a suboptimal solution with a clever allocation policy, guaranteeing at the same time a minimum level of performance. The former solution is called Kernelized Monitor. <p> The following properties have been shown: * A job can be blocked at most once before it enters its first critical section. * The PCP prevents the occurrence of deadlocks. 12 Of course, the former property is used to evaluate the worst case blocking times of the jobs. In <ref> [2] </ref> Baker describes a similar protocol, the Stack Resource Policy (SRP), that handles a more general situation in which multiunit resources, both static and dynamic priority schemes, and sharing of runtime stacks are all allowed.
Reference: [3] <author> S. Baruah, G. Koren, D. Mao, B. Mishra, A. Raghunathan, L. Rosier, D. Shasha, and F. Wang, </author> <title> "On the Competitiveness of On-Line Real-Time Task Scheduling," </title> <booktitle> Proceedings of Real-Time Systems Symposium, </booktitle> <month> December </month> <year> 1991. </year>
Reference-contexts: A number of heuristic algorithms have also been proposed to deal with overloads [30] [13] which improve the performance of EDF. Baruah, et al. <ref> [3] </ref> have shown that there exists an upper bound on the performance of any on-line (preemptive) algorithm working in overload conditions. <p> According to this metric, they proved the following theorem: Theorem 3.10 (Baruah, et. al. <ref> [3] </ref>) There does not exist an on-line scheduling algorithm with a competitive factor greater than 0.25. 14 What the theorem says is that no on-line scheduling algorithm can guarantee a cumu-lative value greater than 1=4th the value obtainable by a clairvoyant scheduler. <p> Let the system operate in both normal and overload conditions. Let there be 2 processors. Theorem 4.12 (Baruah, et. al. <ref> [3] </ref>). No on-line scheduling algorithm can guarantee a cumulative value greater than one-half for the dual processor case. 2 As for the bounds results for the uni-processor case (presented in Section 3.4), the implications of this theorem are very pessimistic.
Reference: [4] <author> J. Blazewicz, </author> <title> "Scheduling Dependent Tasks with Different Arrival Times to Meet Deadlines," </title> <editor> In E. Gelenbe, H. Beilner (eds), </editor> <booktitle> Modeling and Performance Evaluation of Computer Systems, </booktitle> <address> Amsterdam, </address> <publisher> North-Holland, </publisher> <year> 1976. </year>
Reference-contexts: We rarely see this issue addressed in classical scheduling theory. In the above solutions, a scheduling list is explicitly created. Another technique is to encode the precedence relations into the parameters used by the scheduling algorithm, for example, into deadlines and release times. Blazewicz <ref> [4] </ref> shows how to adjust deadlines so that precedence constraints are encoded in the deadlines a priori, and at run time you simply use EDF scheduling. <p> His result comes from the fact that task deadlines depend on their deadlines and successors' deadlines, while task start times depend on their own start time and predecessors' start times. The theorem assumes no shared resources among tasks. Theorem 3.5 (Blazewicz <ref> [4] </ref>) EDF is optimal for tasks that have a general precedence relation and different release dates if deadlines and start times are revised according to the following formulas: d fl i = minfd i ; min (d fl j p j ; S i ! S j )g starting from the
Reference: [5] <author> M. Chen and K. Lin, </author> <title> "Dynamic Priority Ceilings: A Concurrency Control Protocol for Real-Time Systems," </title> <journal> Journal of Real-Time Systems, </journal> <volume> 2, </volume> <year> 1990. </year>
Reference-contexts: Successively Chen and Lin <ref> [5] </ref> extend the utilization of the protocol to an EDF scheduler.
Reference: [6] <author> S. Cheng, J. Stankovic, and K. Ramamritham, </author> <title> "Dynamic Scheduling of Groups of Tasks with Precedence Constraints in Distributed Hard Real-Time Systems, </title> " <booktitle> Real-Time Systems Symposium, </booktitle> <month> December </month> <year> 1986. </year> <month> 22 </month>
Reference-contexts: A heuristic was proposed in the Spring project, where deadline and cost driven algorithms are combined together with rules to dynamically revise values and deadlines in accordance with the precedence relations <ref> [6] </ref>. A number of heuristic algorithms have also been proposed to deal with overloads [30] [13] which improve the performance of EDF. Baruah, et al. [3] have shown that there exists an upper bound on the performance of any on-line (preemptive) algorithm working in overload conditions.
Reference: [7] <author> H. Chetto, M. Silly, and T. Bouchentouf, </author> <title> "Dynamic Scheduling of Real-Time Tasks Under Precedence Constraints," </title> <journal> Real-Time Systems Journal, </journal> <volume> 2, </volume> <year> 1990. </year>
Reference-contexts: The optimality of the technique of the revised deadlines and arrival dates has been used in both on-line <ref> [7] </ref> and off-line algorithms [24]. Unfortunately, the optimality of this technique is again lost if tasks with precedence constraints also share resources in an exclusive way.
Reference: [8] <author> E.G. Coffman and R. Graham, </author> <title> "Optimal Scheduling for Two-Processor Systems," </title> <journal> ACTA Informat., </journal> <volume> 1, </volume> <year> 1972. </year>
Reference-contexts: The metric used in the following theorems is the amount of computation time required for determining a schedule which satisfies the partial order and resource constraints, and completes all required processing before a given fixed deadline. Theorem 4.1 (Coffman and Graham <ref> [8] </ref>). The multiprocessor scheduling problem with 2 processors, no resources, arbitrary partial order relations, and every task has unit computation time is polynomial. 2 Theorem 4.2 (Garey and Johnson [10]).
Reference: [9] <author> M.L. Dertouzos, </author> <title> "Control Robotics: the Procedural Control of Physical Processes," </title> <booktitle> Information Processing 74, </booktitle> <publisher> North-Holland Publishing Company, </publisher> <year> 1974. </year>
Reference-contexts: The proof obtained in this way is very similar to the "time slice swapping" technique used in <ref> [9] </ref> and [24] to show the optimality of the earliest deadline first (EDF from now on) and the least laxity first (LLF) algorithms, respectively.
Reference: [10] <author> R. Garey and D. Johnson, </author> <title> "Complexity Results for Multiprocessor Scheduling Under Resource Constraints," </title> <journal> SIAM Journal of Computing, </journal> <year> 1975. </year>
Reference-contexts: Theorem 4.1 (Coffman and Graham [8]). The multiprocessor scheduling problem with 2 processors, no resources, arbitrary partial order relations, and every task has unit computation time is polynomial. 2 Theorem 4.2 (Garey and Johnson <ref> [10] </ref>). The multiprocessor scheduling problem with 2 processors, no resources, independent tasks, and arbitrary computation times is NP-complete. 2 Theorem 4.3 (Garey and Johnson [10]). <p> scheduling problem with 2 processors, no resources, arbitrary partial order relations, and every task has unit computation time is polynomial. 2 Theorem 4.2 (Garey and Johnson <ref> [10] </ref>). The multiprocessor scheduling problem with 2 processors, no resources, independent tasks, and arbitrary computation times is NP-complete. 2 Theorem 4.3 (Garey and Johnson [10]). The multiprocessor scheduling problem with 2 processors, no resources, arbitrary partial order, and task computation times are either 1 or 2 units of time is NP-complete. 2 16 Proc. Res. Ordering Comp T. Complexity 2 0 Arbitrary Unit Polynomial 2 0 Independ. <p> Arbitrary NP-Comp 2 0 Arbitrary 1 or 2 Units NP-Comp 2 1 Forest Unit NP-Comp 3 1 Independ. Unit NP-Comp N 0 Forest Unit Polynomial N 0 Arbitrary Unit NP-Comp Table 1: Summary of Basic Multiprocessor Scheduling Theorems Theorem 4.4 (Garey and Johnson <ref> [10] </ref>). The multiprocessor scheduling problem with 2 processors, 1 resource, a forest partial order, and each computation time of every task equal to 1 is NP-complete. 2 Theorem 4.5 (Garey and Johnson [10]). <p> N 0 Arbitrary Unit NP-Comp Table 1: Summary of Basic Multiprocessor Scheduling Theorems Theorem 4.4 (Garey and Johnson <ref> [10] </ref>). The multiprocessor scheduling problem with 2 processors, 1 resource, a forest partial order, and each computation time of every task equal to 1 is NP-complete. 2 Theorem 4.5 (Garey and Johnson [10]). The multiprocessor scheduling problem with 3 or more processors, one resource, all independent tasks, and each tasks computation time equal to 1 is NP-complete. 2 Theorem 4.6 (Hu [15]).
Reference: [11] <author> M.R. Garey, D.S. Johnson, B.B. Simons, and R.E. Tarjan, </author> <title> "Scheduling Unit-Time Tasks with Arbitrary Release Times and Deadlines," </title> <journal> SIAM Journal Comput., </journal> <volume> 10(2), </volume> <month> May </month> <year> 1981. </year>
Reference-contexts: Moreover, if we add precedence constraints and we want to minimize the maximum completion time (makespan), that is, we want to solve 1 j nopmtn; prec; r j ; p j = 1 j C max ; 11 the problem is still easy <ref> [11] </ref>. The algorithm that solves it makes use of forbidden regions, intervals of time during which no task can start if the schedule is to be feasible.
Reference: [12] <author> R. Graham, </author> <title> Bounds on the Performance of Scheduling Algorithms, chapter in Computer and Job Shop Scheduling Theory, </title> <publisher> John Wiley and Sons, </publisher> <pages> pp. 165-227, </pages> <year> 1976. </year>
Reference-contexts: Assume that a set of tasks are scheduled optimally on a multiprocessor with some priority order, a fixed number of processors, fixed execution times, and precedence constraints. Theorem 4.13 (Graham <ref> [12] </ref>). <p> Theoretical bounds exist to describe, e.g., the minimum number of bins required. The worst case bounds for FF and BF for large task sets are (17=10)Lfl where Lfl is the optimal (minimum) number of bins <ref> [12] </ref>. For FFD the bound is (11=9)Lfl and it is known that the bound of BFD is less than or equal to the FFD bound [12]. <p> The worst case bounds for FF and BF for large task sets are (17=10)Lfl where Lfl is the optimal (minimum) number of bins <ref> [12] </ref>. For FFD the bound is (11=9)Lfl and it is known that the bound of BFD is less than or equal to the FFD bound [12]. This work is of limited value for real-time systems since we have only a single deadline and other issues such as precedence constraints and other real considerations are not taken into account.
Reference: [13] <author> J. R. Haritsa, M. Livny, and M. J. Carey, </author> <title> "Earliest Deadline Scheduling for Real-Time Database Systems," </title> <booktitle> Proceedings of Real-Time Systems Symposium, </booktitle> <month> December </month> <year> 1991. </year>
Reference-contexts: A heuristic was proposed in the Spring project, where deadline and cost driven algorithms are combined together with rules to dynamically revise values and deadlines in accordance with the precedence relations [6]. A number of heuristic algorithms have also been proposed to deal with overloads [30] <ref> [13] </ref> which improve the performance of EDF. Baruah, et al. [3] have shown that there exists an upper bound on the performance of any on-line (preemptive) algorithm working in overload conditions.
Reference: [14] <author> W. Horn, </author> <title> "Some Simple Scheduling Algorithms," </title> <journal> Naval Research Logistics Quarterly, </journal> <volume> 21, </volume> <pages> pp. 177-185, </pages> <year> 1974. </year>
Reference-contexts: However, if we schedule T 3 first, on P1, then T 1 and T 2 on P2, all tasks make their deadlines. An optimal algorithm does exist for the static version of this problem (all tasks exist at the same time) if one considers both deadlines and computation time <ref> [14] </ref>, but this algorithm is too complicated to present here. Now, if dynamic earliest deadline scheduling for multiprocessors is not optimal, the next question is whether any dynamic algorithm is optimal, in general. Again, the answer is no. Theorem 4.11 (Mok [24]).
Reference: [15] <author> T. C. Hu, </author> <title> "Parallel Scheduling and Assembly Line Problems," </title> <journal> Operations Research, </journal> <volume> 9, </volume> <year> 1961. </year>
Reference-contexts: The multiprocessor scheduling problem with 3 or more processors, one resource, all independent tasks, and each tasks computation time equal to 1 is NP-complete. 2 Theorem 4.6 (Hu <ref> [15] </ref>). The multiprocessor scheduling problem with n processors, no resources, a forest partial order, and each task having a unit computation time is polynomial. 2 Theorem 4.7 (Ullman [31]).
Reference: [16] <author> J.R. Jackson, </author> <title> "Scheduling a Production Line to Minimize Maximum Tardiness," </title> <type> Research Report 43, </type> <institution> Management Science Research Project, University of California, </institution> <address> Los Angeles, </address> <year> 1955. </year>
Reference-contexts: 1 j nopmtn j L max where "1" stands for single machine, "nopmtn" stands for nonpreemption and the objective function to minimize is L max = max fL j g: A very simple solution to this problem, the earliest due date (EDD) algorithm is as follows: Theorem 3.1 (Jackson's Rule <ref> [16] </ref>). Any sequence is optimal that puts the jobs in order of nondecreasing due dates. 2 The proof of the theorem can be given by a simple interchange argument [18], but presenting that argument here is beyond the scope of this paper.
Reference: [17] <author> E.L. Lawler, </author> <title> "Optimal Sequencing of a Single Machine Subject to Precedence Constraints," </title> <journal> Management Science, </journal> <volume> 19, </volume> <year> 1973. </year>
Reference-contexts: The simple scheduling problem of a set of tasks with no-preemption, identical arrival time and a precedence relation among them, described as, 1 j prec; nopmtn j L max was solved by Lawler <ref> [17] </ref> with an EDF-like algorithm that works backwards, starting from the leaf tasks in the precedence graph.
Reference: [18] <author> E.L. Lawler, </author> <title> "Recent Results in the Theory of Machine Scheduling," Mathematical Programming: the State of the Art, </title> <editor> A. Bachen et al. (eds.), </editor> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: A recognition or optimization problem R is NP-hard if all problems in N P are polynomial transformable to R, but we can't show that R 2 N P . 3 Uni-processor Systems In general we follow the notation of <ref> [18] </ref>, in which the problem definition has the form ff j fi j fl, where ff indicates the machine environment (in this section of the paper ff = 1, indicating a uni-processor machine), fi indicates the job characteristics (preemptable, nonpreemptable, independent, precedence constrained, deadline, etc.) and fl indicates the optimality criterion <p> Any sequence is optimal that puts the jobs in order of nondecreasing due dates. 2 The proof of the theorem can be given by a simple interchange argument <ref> [18] </ref>, but presenting that argument here is beyond the scope of this paper. At first, this result may not seem too useful to a real-time systems designer because we often require that no task miss its deadline. <p> Efficient solutions exist for series-parallel graphs, but they do not exist for a Z graph. Unfortunately, Z graphs arise in practice. Details on these results follow. Theorem 3.4 (Lawler <ref> [18] </ref>) Given any set of tasks related by a series-parallel precedence graph an optimal solution exists for every cost function that admits a string interchange relation. 2 Formally, a cost function has a string interchange relation if, given two strings of jobs ff and fi and a quasi total order among <p> scheduling blocks which have different computation times." A confirmation of this point of view is that the problem of minimizing the maximum lateness of n independent unit-time jobs with arbitrary release times, that is, 1 j nopmtn; r j ; p j = 1 j L max ; is easy <ref> [18] </ref>. Moreover, if we add precedence constraints and we want to minimize the maximum completion time (makespan), that is, we want to solve 1 j nopmtn; prec; r j ; p j = 1 j C max ; 11 the problem is still easy [11]. <p> This result can have an important implication when creating a static schedule; we certainly prefer to minimize preemption for practical reasons at run time, so knowing that there is no advantage to preemption, a designer would not create a static schedule with any preemptions. Theorem 4.9 (Lawler <ref> [18] </ref>).
Reference: [19] <author> J.K. Lenstra and A.H.G. </author> <title> Rinnooy Kan "Optimization and Approximation in Deterministic Sequencing and Scheduling: A Survey," </title> <journal> Ann. Discrete Math. </journal> <volume> 5, </volume> <pages> pp. 287-326, </pages> <year> 1977. </year>
Reference-contexts: We say that a job j has release time r j if its execution cannot start before time r j . Unfortunately, the problem above extended with release times, that is 1 j nopmtn; r j j L max is NP-hard <ref> [19] </ref>. In this case we obtain a great benefit if we permit jobs to be preempted at any instant. In fact, the problem 1 j pmtn; r j j L max is easy, that is, an algorithm for its solution exists and has polynomial complexity. <p> of non-preemptive scheduling of jobs with different release times and general precedence constraints is not a simple one, in fact, the problem 1 j nopmtn; r i j L max 7 and the corresponding 1 j prec; nopmtn; r i j L max were proven to be NP-hard by Lenstra <ref> [19] </ref>. The NP hardness of the general precedence constrained problem is a major obstacle for non-preemptive scheduling, in spite of the fact that optimal results or polynomial algorithms exist for similar problems, where some of the general assumptions are constrained. <p> However, it is not sufficient to solve the problem of scheduling with general precedence constraints. The problems 1 j prec j X 1 j d j j w j C j turn out to be NP complete <ref> [19] </ref> and the same is true even for the simpler ones 1 j prec j X 1 j prec; p j = 1 j X Interesting solutions had been found for particular kind of precedence relations, in fact, optimal polynomial algorithm had been found for the problems 1 j chain j
Reference: [20] <author> J. Leung and J. Whitehead, </author> <title> "On the Complexity of Fixed Priority Scheduling of Periodic, Real-Time Tasks," Performance Evaluation, </title> <booktitle> 2(4), </booktitle> <pages> pp. 237-250, </pages> <year> 1982. </year>
Reference-contexts: This is often referred to as the schedulability test. If deadlines of periodic tasks can be less than the period the above rule is no longer optimal. Rather we must use a deadline monotonic policy <ref> [20] </ref> where the periodic process with the shortest deadline is assigned the highest priority. This scheme is optimal in the sense that if any static priority scheme can schedule this set of periodic processes then the deadline monotonic algorithm can.
Reference: [21] <author> C.L. Liu, J.W. Layland, </author> <title> "Scheduling Algorithms for Multiprogramming in a Hard-Real-Time Environment," </title> <journal> Journal of the ACM, </journal> <volume> 20(1), </volume> <year> 1973. </year>
Reference-contexts: Another implication of these theorems is that the minimization of maximum lateness implies optimality even when all deadlines must be met, because the maximum lateness can be required to be less than or equal to zero. In fact, the very well-known paper by Liu and Layland <ref> [21] </ref> focussed on this aspect of EDF scheduling for a set of independent periodic processes, showing that a full processor utilization is always achievable and giving a very simple necessary and sufficient condition for the schedulability of the tasks: X p j 1 where T j is the period of the <p> This algorithm assigns to each task a static priority inversely proportional to its period, i.e., tasks with the shortest periods get the highest priority. For a fixed set of independent periodic tasks with deadlines the same as the periods, we know: Theorem 3.3 (Liu and Layland <ref> [21] </ref>) A set of n independent periodic jobs can be scheduled by the rate monotonic policy if P n i=1 p i =T i n (2 1=n 1) where T i and p i are the period and worst case execution time, respectively.
Reference: [22] <author> C. D. Locke, </author> <title> "Best-effort Decision Making for Real-Time Scheduling," </title> <type> PhD thesis, </type> <institution> Computer Science Department, Carnegie-Mellon University, </institution> <year> 1986. </year> <month> 23 </month>
Reference-contexts: However, in overload conditions, these algorithms perform very poorly. Experiments carried out by Locke <ref> [22] </ref> and others have shown that both EDF and LLF rapidly degrade their performance during overload intervals. This is due to the fact that such algorithms give the highest priority to those processes that are close to missing their deadlines.
Reference: [23] <author> R. McNaughton, </author> <title> "Scheduling With Deadlines and Loss Functions," </title> <journal> Management Science, </journal> <volume> 6, </volume> <pages> pp. 1-12, </pages> <year> 1959. </year>
Reference-contexts: The following classical results pertain to multiprocessing scheduling where tasks are preemptable, i.e., P j pmtn j X w j C j : Theorem 4.8 (McNaughton <ref> [23] </ref>).
Reference: [24] <author> A.K. Mok, </author> <title> "Fundamental Design Problems of Distributed Systems for the Hard-Real-Time Environment," </title> <type> Ph.D. Thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, Massachusetts, </institution> <month> May </month> <year> 1983. </year>
Reference-contexts: The proof obtained in this way is very similar to the "time slice swapping" technique used in [9] and <ref> [24] </ref> to show the optimality of the earliest deadline first (EDF from now on) and the least laxity first (LLF) algorithms, respectively. <p> The optimality of the technique of the revised deadlines and arrival dates has been used in both on-line [7] and off-line algorithms <ref> [24] </ref>. Unfortunately, the optimality of this technique is again lost if tasks with precedence constraints also share resources in an exclusive way. <p> Defining a run-time scheduler as totally on-line if it has no knowledge about the future arrival times of the tasks, the following has been proven: Theorem 3.6 (Mok <ref> [24] </ref>). When there are mutual exclusion constraints, it is impossible to find a totally on-line optimal run-time scheduler. 2 The proof is simply given by an adversary argument. Furthermore, the same author showed a much more negative result: Theorem 3.7 (Mok [24]). <p> tasks, the following has been proven: Theorem 3.6 (Mok <ref> [24] </ref>). When there are mutual exclusion constraints, it is impossible to find a totally on-line optimal run-time scheduler. 2 The proof is simply given by an adversary argument. Furthermore, the same author showed a much more negative result: Theorem 3.7 (Mok [24]). The problem of deciding whether it is possible to schedule a set of periodic processes which use semaphores only to enforce mutual exclusion is NP-hard. 2 A transformation of the 3-partition problem to this scheduling problem is shown to prove the theorem. <p> Furthermore, the ready times and the deadlines of the tasks can be previously modified according to some partial order on the tasks. Adjusting the EDF scheduler with the technique of the forbidden regions mentioned above, the following theorem can be proven: Theorem 3.8 (Mok <ref> [24] </ref>). <p> First, consider that under certain conditions in a uni-processor, dynamic earliest deadline scheduling is optimal. Is this algorithm optimal in a multiprocessor? The answer is no. Theorem 4.10 (Mok <ref> [24] </ref>). Earliest deadline scheduling is not optimal in the multiprocessor case. 2 To illustrate why this is true consider the following example. We have 3 tasks to execute on 2 processors. <p> Now, if dynamic earliest deadline scheduling for multiprocessors is not optimal, the next question is whether any dynamic algorithm is optimal, in general. Again, the answer is no. Theorem 4.11 (Mok <ref> [24] </ref>).
Reference: [25] <author> J. Moore, </author> <title> "An n Job, One Machine Sequencing Algorithm for Minimizing the Number of Late Jobs," </title> <journal> Management Science, </journal> <volume> Vol. 15, No. 1, </volume> <pages> pp. 102-109, </pages> <month> September </month> <year> 1968. </year>
Reference: [26] <author> K. Ramamritham, J. Stankovic, and P. Shiah, </author> <title> "Efficient Scheduling Algorithms For Real-Time Multiprocessor Systems," </title> <journal> IEEE Transactions on Parallel and Distributed Computing, </journal> <volume> Vol. 1, No. 2, </volume> <pages> pp. 184-194, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: An example is given by the algorithm by Xu and Parnas [32] where on every step a sub-optimal schedule is obtained. There are even examples of on-line systems driven by heuristics as the Spring system <ref> [26] </ref> where the scheduling list is built on-line. 3.3 Shared Resources Shared resources are commonly used in multitasking applications. While in general purpose systems this is a well-known problem solved, for example, with mutual exclusion primitives, in real-time systems a straightforward application of this solution does not hold. <p> The classical results given in this section provide a good means for handling resources in a uniprocessor. Many researchers feel that these techniques do not work well in multiprocessors nor in distributed systems. For such systems shared resources are typically addressed by on-line planning algorithms <ref> [26, 28, 33] </ref>, or by static schedules developed with off-line heuristics. Both of these alternative approaches avoid blocking over shared resources by scheduling competing tasks at different points in time. 3.4 Overload and Value EDF and LLF algorithms have been shown to be optimal with respect to different metrics. <p> For example, even though the system operates stochastically and non-optimally, it might be able to provide a minimum level of guaranteed performance. As mentioned, various heuristics exist for real-time multiprocessor scheduling with resource constraints <ref> [26] </ref>. However, in general, these heuristics use a non-preemptive model. The advantages of a non-preemptive model are few context switches, higher understandability and easier testing than for the preemptive model, and avoidance of blocking is possible.
Reference: [27] <author> L. Sha, R. Rajkumar, J.P. Lehoczky, </author> <title> "Priority Inheritance Protocols: An Approach to Real-Time Synchronization," </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(9), </volume> <year> 1990. </year>
Reference-contexts: At this point several choices are possible. One of them, followed by Mok, is to enforce the use of mutually exclusive scheduling blocks having the same computation time, and another, followed, for example, by Sha et al. <ref> [27] </ref> and Baker [2], is to efficiently find a suboptimal solution with a clever allocation policy, guaranteeing at the same time a minimum level of performance. The former solution is called Kernelized Monitor. <p> If a feasible schedule exists for an instance of the process model with precedence constraints and critical sections, then the kernelized monitor scheduler can be used to produce a feasible schedule. 2 In <ref> [27] </ref> Sha et al. introduce the Priority Ceiling Protocol (PCP), an allocation policy for shared resources which works with a Rate Monotonic scheduler. Successively Chen and Lin [5] extend the utilization of the protocol to an EDF scheduler.
Reference: [28] <author> C. Shen, K. Ramamritham, and J. Stankovic, </author> <title> "Resource Reclaiming in Multiprocessor Real-Time Systems," </title> <journal> IEEE Transactions on Parallel and Distributed Computing, </journal> <volume> Vol. 4, No. 4, </volume> <month> April </month> <year> 1993. </year>
Reference-contexts: The classical results given in this section provide a good means for handling resources in a uniprocessor. Many researchers feel that these techniques do not work well in multiprocessors nor in distributed systems. For such systems shared resources are typically addressed by on-line planning algorithms <ref> [26, 28, 33] </ref>, or by static schedules developed with off-line heuristics. Both of these alternative approaches avoid blocking over shared resources by scheduling competing tasks at different points in time. 3.4 Overload and Value EDF and LLF algorithms have been shown to be optimal with respect to different metrics. <p> A simple solution 20 that avoids the anomaly is to have tasks that complete early simply idle, but this can often be very inefficient. However, algorithms such as <ref> [28] </ref> strive to reclaim this idle time, but carefully address the anomalies so that they will not occur. 4.4 Similarity to Bin Packing Another tremendously active area of scheduling research is in bin packing algorithms. <p> On-line multiprocessing scheduling must rely on heuristics and would be substantially 21 helped by special scheduling chips. Any such heuristics must avoid Richard's anomalies <ref> [28] </ref>. Better results for operation in overloads, better bounds which account for typical a priori knowledge found in real-time systems, and algorithms which can guarantee various levels of performance are required.
Reference: [29] <author> W. Smith, </author> <title> "Various Optimizers for Single Stage Production," </title> <journal> Naval Research Logistics Quarterly, </journal> <volume> 3, </volume> <pages> pp. 59-66, </pages> <year> 1956. </year>
Reference-contexts: In order to gain control over the tardy tasks in overload conditions, a value is usually associated with each task, reflecting the importance of that task within the set. When dealing with task sets with values, tasks can be scheduled by the Smith' rule. 13 Theorem 3.9 (Smith's rule <ref> [29] </ref>) Finding an optimal schedule for 1 jj w j C j is given by any sequence that puts jobs in order of non decreasing ratios j = p j =w j .
Reference: [30] <author> P. Thambidurai and K. S. Trivedi, </author> <title> "Transient Overloads in Fault-Tolerant Real-Time Systems," </title> <booktitle> Proceedings of Real-Time Systems Symposium, </booktitle> <month> December </month> <year> 1989. </year>
Reference-contexts: A heuristic was proposed in the Spring project, where deadline and cost driven algorithms are combined together with rules to dynamically revise values and deadlines in accordance with the precedence relations [6]. A number of heuristic algorithms have also been proposed to deal with overloads <ref> [30] </ref> [13] which improve the performance of EDF. Baruah, et al. [3] have shown that there exists an upper bound on the performance of any on-line (preemptive) algorithm working in overload conditions.
Reference: [31] <author> J. D. Ullman, </author> <title> "Polynomial Complete Scheduling Problems," </title> <booktitle> Proc. 4th Symp. on Operating System Principles, </booktitle> <year> 1973. </year>
Reference-contexts: The multiprocessor scheduling problem with n processors, no resources, a forest partial order, and each task having a unit computation time is polynomial. 2 Theorem 4.7 (Ullman <ref> [31] </ref>). The multiprocessing scheduling problem with n processors, no resources, arbitrary partial order, and each task having a unit computation time is NP-complete. 2 From these theorems we can see that for non-preemptive multiprocessing scheduling almost all problems are NP-complete implying that heuristics must be used for such problems.
Reference: [32] <author> J. Xu and D. Parnas, </author> <title> "Scheduling Processes with Release Times, Deadlines, Precedence, and Exclusion Relations," </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. 16, No. 3, pp.360-369, </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: Some off-line algorithms face the NP hardness of the general problem trying to find acceptable solutions by means of heuristics, branch and bound techniques and so on. An example is given by the algorithm by Xu and Parnas <ref> [32] </ref> where on every step a sub-optimal schedule is obtained. There are even examples of on-line systems driven by heuristics as the Spring system [26] where the scheduling list is built on-line. 3.3 Shared Resources Shared resources are commonly used in multitasking applications.
Reference: [33] <author> W. Zhao, K. Ramamritham, and J. Stankovic, </author> <title> "Preemptive Scheduling Under Time and Resource Constraints," </title> <journal> Special Issue of IEEE Transactions on Computers on Real-Time Systems, </journal> <volume> Vol. C-36, No. 8, </volume> <pages> pp. 949-960, </pages> <month> August </month> <year> 1987. </year> <month> 24 </month>
Reference-contexts: The classical results given in this section provide a good means for handling resources in a uniprocessor. Many researchers feel that these techniques do not work well in multiprocessors nor in distributed systems. For such systems shared resources are typically addressed by on-line planning algorithms <ref> [26, 28, 33] </ref>, or by static schedules developed with off-line heuristics. Both of these alternative approaches avoid blocking over shared resources by scheduling competing tasks at different points in time. 3.4 Overload and Value EDF and LLF algorithms have been shown to be optimal with respect to different metrics. <p> The advantages of a non-preemptive model are few context switches, higher understandability and easier testing than for the preemptive model, and avoidance of blocking is possible. The main disadvantage of the non-preemptive model is the (usually) less efficient utilization of the processor. Heuristics also exist for a preemptive model <ref> [33] </ref>. The advantages of a preemptive model are high utilizations and low latency at reacting to newly invoked work. The disadvantages are many context switches, difficulty in understanding the run time execution and its testing, and blocking is common.
References-found: 33

