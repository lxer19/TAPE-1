URL: http://graphics.lcs.mit.edu/~seth/pubs/AIM-1593.ps.Z
Refering-URL: http://graphics.lcs.mit.edu/~seth/pubs/pubs.html
Root-URL: 
Title: Dense Depth Maps from Epipolar Images  
Author: J.P. Mellor, Seth Teller and Tom as Lozano-P erez 
Note: This publication can be retrieved by anonymous ftp to publications.ai.mit.edu. Copyright c 1996, by  
Date: 1593 November 1996  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY  Massachusetts Institute of Technology  
Pubnum: A.I. Memo No.  
Abstract: Recovering three-dimensional information from two-dimensional images is the fundamental goal of stereo techniques. The problem of recovering depth (three-dimensional information) from a set of images is essentially the correspondence problem: Given a point in one image, find the corresponding point in each of the other images. Finding potential correspondences usually involves matching some image property. If the images are from nearby positions, they will vary only slightly, simplifying the matching process. Once a correspondence is known, solving for the depth is simply a matter of geometry. Real images are composed of noisy, discrete samples, therefore the calculated depth will contain error. This error is a function of the baseline or distance between the images. Longer baselines result in more precise depths. This leads to a conflict: short baselines simplify the matching process but produce imprecise results; long baselines produce precise results but complicate the matching process. In this paper, we present a method for generating dense depth maps from large sets (1000's) of images taken from arbitrary positions. Long baseline images improve the accuracy. Short baseline images and the large number of images greatly simplifies the correspondence problem, removing nearly all ambiguity. The algorithm presented is completely local and for each pixel generates an evidence versus depth and surface normal distribution. In many cases, the distribution contains a clear and distinct global maximum. The location of this peak determines the depth and its shape can be used to estimate the error. The distribution can also be used to perform a maximum likelihood fit of models directly to the images. We anticipate that the ability to perform maximum likelihood estimation from purely local calculations will prove extremely useful in constructing three dimensional models from large sets of images. This report describes research done at the Artificial Intelligence Laboratory of the Massachusetts Institute of Technology. Support for the laboratory's artificial intelligence research is provided in part by Advanced Research Projects Agency of the Department of Defense under Office of Naval Research contract N00014-91-J-4038. The authors were also supported by the Advanced Research Projects Agency of the Department of Defense under Rome Laboratory contract F3060-94-C-0204. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Robert C. Bolles, H. Harlyn Baker, and David H. Marimont. </author> <title> Epipolar-plane image analysis: An approach to determining structure from motion. </title> <journal> International Journal of Computer Vision, </journal> <volume> 1(1):755, </volume> <year> 1987. </year>
Reference-contexts: These techniques don't always converge and don't always recover the correct correspondences. Another approach is to use multiple images. Several researchers, such as Yachida [11], have proposed trinocular stereo algorithms. Others have also used special camera configurations to aid in the correspondence problem, <ref> [10, 1, 8] </ref>. Bolles, Baker and Marimont [1] proposed constructing an epipolar-plane image from a large number of images. In some cases, analyzing the epipolar-plane image is much simpler than analyzing the original set of images. The epipolar-plane image, however, is only defined for a limited set of camera positions. <p> Another approach is to use multiple images. Several researchers, such as Yachida [11], have proposed trinocular stereo algorithms. Others have also used special camera configurations to aid in the correspondence problem, [10, 1, 8]. Bolles, Baker and Marimont <ref> [1] </ref> proposed constructing an epipolar-plane image from a large number of images. In some cases, analyzing the epipolar-plane image is much simpler than analyzing the original set of images. The epipolar-plane image, however, is only defined for a limited set of camera positions. <p> This work attempts to explicitly model occlusions, although, in a somewhat ad hoc manner. It uses a few global constraints and small sets of images. The work presented here also uses multiple images and draws its major inspiration from Bolles, Baker and Marimont <ref> [1] </ref>. We define a construct called an epipolar image and use it to analyze evidence about depth. Like Tsai [10] and Okutomi and Kanade [8] we define a cost function that is applied across multiple images, and like Cox [2] we model the occlusion process. <p> Given any point p on epipolar line ` 1 e in image 1 i , if the corresponding point is visible in image 2 i , then it must lie on the corresponding epipolar line ` 2 e . 2.2 Epipolar-Plane Images Bolles, Baker and Marimont <ref> [1] </ref> used the epipo lar constraint to construct a special image which they called an epipolar-plane image. As noted earlier, an epipolar line ` i e contains all of the information about the epipolar plane e that is present in the i th image i i .
Reference: [2] <author> Ingemar J. Cox, Sunita L. Hingorani, Satish B. Rao, and Bruce M. Maggs. </author> <title> A maximum likelihood stereo algorithm. Computer Vision and Image Understanding, </title> <address> 63(3):542567, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: Both methods used small sets of images, typically about ten. They also limited camera positions to special configurations. Tsai used a localized planar configuration with parallel optic axes; and Okutomi and Kanade used short linear configurations. Cox et al <ref> [2] </ref> proposed a maximum-likelihood framework for stereo pairs, which they have extended to multiple images. This work attempts to explicitly model occlusions, although, in a somewhat ad hoc manner. It uses a few global constraints and small sets of images. <p> We define a construct called an epipolar image and use it to analyze evidence about depth. Like Tsai [10] and Okutomi and Kanade [8] we define a cost function that is applied across multiple images, and like Cox <ref> [2] </ref> we model the occlusion process. There are several important differences, 1 For a more complete and detailed analysis of this and other techniques see [5, 7, 4]. 1 however. The epipolar image we define is valid for arbitrary camera positions and models some forms of occlusion.
Reference: [3] <author> Richard O. Duda and Peter E. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> John Wi-ley & Sons, </publisher> <address> New York, NY, </address> <year> 1973. </year>
Reference-contexts: In most cases, depth can be recovered using purely local information, avoiding the computational costs of global constraints. Where depth cannot be recovered using purely local information, the depth evidence from the epipolar image provides a principled distribution for use in a maximum-likelihood approach <ref> [3] </ref>. 2 Our Approach In this section, we review epipolar geometry and epipolar-plane images, then define a new construct called an epipolar image. We also discuss the construction and analysis of epipolar images. Stereo techniques typically assume that relative camera positions and internal camera calibrations are known.
Reference: [4] <author> Olivier Faugeras. </author> <title> Three-Dimensional Computer Vision. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: Like Tsai [10] and Okutomi and Kanade [8] we define a cost function that is applied across multiple images, and like Cox [2] we model the occlusion process. There are several important differences, 1 For a more complete and detailed analysis of this and other techniques see <ref> [5, 7, 4] </ref>. 1 however. The epipolar image we define is valid for arbitrary camera positions and models some forms of occlusion. Our method is intended to recover dense depth maps of built geometry (architectural facades) using thousands of images acquired from within the scene.
Reference: [5] <author> Berthold Klaus Paul Horn. </author> <title> Robot Vision. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: Like Tsai [10] and Okutomi and Kanade [8] we define a cost function that is applied across multiple images, and like Cox [2] we model the occlusion process. There are several important differences, 1 For a more complete and detailed analysis of this and other techniques see <ref> [5, 7, 4] </ref>. 1 however. The epipolar image we define is valid for arbitrary camera positions and models some forms of occlusion. Our method is intended to recover dense depth maps of built geometry (architectural facades) using thousands of images acquired from within the scene.
Reference: [6] <author> D. Marr and T. Poggio. </author> <title> A computational theory of human stereo vision. </title> <journal> Proceedings of the Royal Society of London, </journal> <volume> B(204):301 328, </volume> <year> 1979. </year>
Reference-contexts: This leads to a conflict: short baselines simplify the matching process, but produce uncertain results; long baselines produce precise results, but complicate the matching process. One popular set of approaches for dealing with this problem are relaxation techniques 1 <ref> [6, 9] </ref>. These methods are generally used on a pair of images; start with an educated guess for the correspondences; then update them by propagating constraints. These techniques don't always converge and don't always recover the correct correspondences. Another approach is to use multiple images.
Reference: [7] <author> John E. W. Mayhew and John P. </author> <title> Frisby, editors. 3D Model Recognition from Stereoscopic Cues. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: Like Tsai [10] and Okutomi and Kanade [8] we define a cost function that is applied across multiple images, and like Cox [2] we model the occlusion process. There are several important differences, 1 For a more complete and detailed analysis of this and other techniques see <ref> [5, 7, 4] </ref>. 1 however. The epipolar image we define is valid for arbitrary camera positions and models some forms of occlusion. Our method is intended to recover dense depth maps of built geometry (architectural facades) using thousands of images acquired from within the scene.
Reference: [8] <author> Masatoshi Okutomi and Takeo Kanade. </author> <title> A muliple-baseline stereo. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15(4):353363, </volume> <month> April </month> <year> 1993. </year>
Reference-contexts: These techniques don't always converge and don't always recover the correct correspondences. Another approach is to use multiple images. Several researchers, such as Yachida [11], have proposed trinocular stereo algorithms. Others have also used special camera configurations to aid in the correspondence problem, <ref> [10, 1, 8] </ref>. Bolles, Baker and Marimont [1] proposed constructing an epipolar-plane image from a large number of images. In some cases, analyzing the epipolar-plane image is much simpler than analyzing the original set of images. The epipolar-plane image, however, is only defined for a limited set of camera positions. <p> In some cases, analyzing the epipolar-plane image is much simpler than analyzing the original set of images. The epipolar-plane image, however, is only defined for a limited set of camera positions. Tsai [10] and Okutomi and Kanade <ref> [8] </ref> defined a cost function which was applied directly to a set of images. The extremum of this cost function was then taken as the correct correspondence. Occlusion is assumed to be negligible. In fact, Okutomi and Kanade state that they invariably obtained better results by using relatively short baselines. <p> The work presented here also uses multiple images and draws its major inspiration from Bolles, Baker and Marimont [1]. We define a construct called an epipolar image and use it to analyze evidence about depth. Like Tsai [10] and Okutomi and Kanade <ref> [8] </ref> we define a cost function that is applied across multiple images, and like Cox [2] we model the occlusion process. There are several important differences, 1 For a more complete and detailed analysis of this and other techniques see [5, 7, 4]. 1 however.
Reference: [9] <author> S. B. Pollard, J. E. W. Mayhew, and J. P. Frisby. Pmf: </author> <title> A stereo correspondence algorithm using a disparity gradient constraint. </title> <journal> Perception, </journal> <volume> 14:449470, </volume> <year> 1985. </year>
Reference-contexts: This leads to a conflict: short baselines simplify the matching process, but produce uncertain results; long baselines produce precise results, but complicate the matching process. One popular set of approaches for dealing with this problem are relaxation techniques 1 <ref> [6, 9] </ref>. These methods are generally used on a pair of images; start with an educated guess for the correspondences; then update them by propagating constraints. These techniques don't always converge and don't always recover the correct correspondences. Another approach is to use multiple images.
Reference: [10] <author> Roger Y. Tsai. </author> <title> Multiframe image point matching and 3-d surface reconstruction. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 5(2):159174, </volume> <month> March </month> <year> 1983. </year>
Reference-contexts: These techniques don't always converge and don't always recover the correct correspondences. Another approach is to use multiple images. Several researchers, such as Yachida [11], have proposed trinocular stereo algorithms. Others have also used special camera configurations to aid in the correspondence problem, <ref> [10, 1, 8] </ref>. Bolles, Baker and Marimont [1] proposed constructing an epipolar-plane image from a large number of images. In some cases, analyzing the epipolar-plane image is much simpler than analyzing the original set of images. The epipolar-plane image, however, is only defined for a limited set of camera positions. <p> Bolles, Baker and Marimont [1] proposed constructing an epipolar-plane image from a large number of images. In some cases, analyzing the epipolar-plane image is much simpler than analyzing the original set of images. The epipolar-plane image, however, is only defined for a limited set of camera positions. Tsai <ref> [10] </ref> and Okutomi and Kanade [8] defined a cost function which was applied directly to a set of images. The extremum of this cost function was then taken as the correct correspondence. Occlusion is assumed to be negligible. <p> It uses a few global constraints and small sets of images. The work presented here also uses multiple images and draws its major inspiration from Bolles, Baker and Marimont [1]. We define a construct called an epipolar image and use it to analyze evidence about depth. Like Tsai <ref> [10] </ref> and Okutomi and Kanade [8] we define a cost function that is applied across multiple images, and like Cox [2] we model the occlusion process. There are several important differences, 1 For a more complete and detailed analysis of this and other techniques see [5, 7, 4]. 1 however.
Reference: [11] <author> M. Yachida. </author> <title> 3d data acquisition by multiple views. </title> <editor> In O. D. Faugeras and G. Giralt, editors, </editor> <booktitle> Robotics Research: the Third International Symposium, </booktitle> <pages> pages 1118. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year> <month> 12 </month>
Reference-contexts: These methods are generally used on a pair of images; start with an educated guess for the correspondences; then update them by propagating constraints. These techniques don't always converge and don't always recover the correct correspondences. Another approach is to use multiple images. Several researchers, such as Yachida <ref> [11] </ref>, have proposed trinocular stereo algorithms. Others have also used special camera configurations to aid in the correspondence problem, [10, 1, 8]. Bolles, Baker and Marimont [1] proposed constructing an epipolar-plane image from a large number of images.
References-found: 11

