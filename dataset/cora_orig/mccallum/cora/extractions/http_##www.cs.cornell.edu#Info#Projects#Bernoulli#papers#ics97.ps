URL: http://www.cs.cornell.edu/Info/Projects/Bernoulli/papers/ics97.ps
Refering-URL: http://www.cs.cornell.edu/Info/Projects/Bernoulli/
Root-URL: http://www.cs.cornell.edu
Email: EMail: fnikosc,prakas,pingalig@cs.cornell.edu  
Title: Compiler and run-time support for semi-structured applications  
Author: Nikos Chrisochoides, Induprakas Kodukula, and Keshav Pingali 
Address: Ithaca, NY 14853.  
Affiliation: Department of Computer Science, Cornell University,  
Abstract: Adaptive mesh refinement (AMR) is a very important scientific application. Several libraries implementing specific distribution policies have been written for AMR. In this paper, we present a "fully general block distribution" which subsumes these distributions, and discuss compiler and run-time tools for supporting these distributions efficiently in the context of a restructuring compiler. We also present performance numbers which suggest that in comparison with library code written for a particular distribution policy, the overhead arising from the generality of our approach is small. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Gagan Agrawal, Alan Sussman, and Joel Saltz. </author> <title> On efficient runtime support for multiblock and multigrid applications: Regular section analysis. </title> <institution> Technical Report CS-TR-3140 and UMIACS-TR-93-92, University of Maryland, Department of Computer Science and UMI-ACS, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: Due to the irregular nature of this con nectivity, communication patterns are irregular. Because of the inadequacy of present compiler technology, several libraries have been developed to make the application programmer's job easier. The most important of these are Multi-block PARTI <ref> [1] </ref>, P++/AMR++ [3], LPARX [2], DAGH [14]. All these libraries hide the nature of the data distribution from the application programmer as much as possible. They provide constructs such as forall loops to enable application writing at a high level, and provide library calls to take care of parallelization issues. <p> They provide constructs such as forall loops to enable application writing at a high level, and provide library calls to take care of parallelization issues. Each of these libraries makes certain assumptions regarding how the underlying data is distributed, which affects application performance. Multi-block PARTI <ref> [1] </ref> uses block-cyclic distributions as in HPF, but allows data arrays to be mapped to a subspace of all the computing processors. This works well for Multigrid codes, but for adaptive mesh refinement, the limitations of HPF apply here as well.
Reference: [2] <author> Scott B. Baden, Scott R. Kohn, and Stephen J. Fink. </author> <title> Programming with lparx. </title> <type> Technical Report CS94-377, </type> <institution> Department of Computer Science, University of San Diego, </institution> <year> 1994. </year>
Reference-contexts: Due to the irregular nature of this con nectivity, communication patterns are irregular. Because of the inadequacy of present compiler technology, several libraries have been developed to make the application programmer's job easier. The most important of these are Multi-block PARTI [1], P++/AMR++ [3], LPARX <ref> [2] </ref>, DAGH [14]. All these libraries hide the nature of the data distribution from the application programmer as much as possible. They provide constructs such as forall loops to enable application writing at a high level, and provide library calls to take care of parallelization issues. <p> AMR++ treats P++ as a black box and uses the distributions that P++ provides. These distributions reduce load-imbalance by allowing arrays to be distributed by columns of variable size, but are still limited in expressiveness. LPARX <ref> [2] </ref> allows data arrays to be distributed in irregularly shaped and irregularly sized blocks onto processors. While in principle it is possible in LPARX for multiple blocks of data to be assigned to one processor, in practice there is only one data block per processor.
Reference: [3] <author> D Balsara, M Lemke, and D Quinlan. AMR++, </author> <title> a c++ object oriented class library for parallel adaptive refinement fluid dynamics applications. </title> <booktitle> In American Society of Mechanical Engineers, Winter Annual Meeting, An-naheim, CA, </booktitle> <volume> volume 157, </volume> <pages> pages 413-433, </pages> <year> 1992. </year>
Reference-contexts: Due to the irregular nature of this con nectivity, communication patterns are irregular. Because of the inadequacy of present compiler technology, several libraries have been developed to make the application programmer's job easier. The most important of these are Multi-block PARTI [1], P++/AMR++ <ref> [3] </ref>, LPARX [2], DAGH [14]. All these libraries hide the nature of the data distribution from the application programmer as much as possible. They provide constructs such as forall loops to enable application writing at a high level, and provide library calls to take care of parallelization issues. <p> Multi-block PARTI [1] uses block-cyclic distributions as in HPF, but allows data arrays to be mapped to a subspace of all the computing processors. This works well for Multigrid codes, but for adaptive mesh refinement, the limitations of HPF apply here as well. AMR++ <ref> [3] </ref> is an AMR class library layered on top of a parallel array library P++. AMR++ treats P++ as a black box and uses the distributions that P++ provides. These distributions reduce load-imbalance by allowing arrays to be distributed by columns of variable size, but are still limited in expressiveness.
Reference: [4] <author> Matthew W. Choptuik, Scott Klasky, and Manish Parashar. </author> <title> Parallel multigrid with the dagh package: Specifications and applications. </title> <type> Draft, </type> <month> September </month> <year> 1995. </year>
Reference-contexts: We implemented a 2-D multigrid solver using the DAGH library with published code <ref> [4] </ref>. This is the line labeled "execution time for multigrid solver" in Figure 12. Next, we created a version of this solver which was augmented with the actual intersection queries the compiler would insert to determine the communication sets at run time.
Reference: [5] <author> Nikos Chrisochoides, Animesh Chatterjee, Rajani Vaidyanathan, and Geoffery Fox. </author> <title> An evaluation of data mapping approaches for parallel multi-block eu-ler solvers. </title> <note> Accepted for publication in Parallel CFD 1994. </note>
Reference-contexts: solve the first four problems listed above for the case of fully general block distributions. 3 Parallelization in the static case In this section, we examine the static case (i.e., when the parameters of the distribution are known at compile time), which is relevant in codes like multi-block Euler solvers <ref> [5] </ref>. A more general treatment of some of the material of this section can be found in [11]. Code executed by processor 4 f 1: Atp1 and A are N-by-N matrices 2: do I = 2, 127 4: If I'm data-centric w.r.t.
Reference: [6] <author> Greg Cook, Steve Brandt, Joan Masso, John Shalf, Paul Walker, Matt Choptuik, Mijan Huq, and Manish Parashar. </author> <title> 2d wave equation application. </title>
Reference-contexts: This is a simplified version of the actual relaxation code that is used in the solution to the 2-D wave equation using the DAGH library <ref> [14, 6] </ref>, and illustrates all the principles behind our approach. 2.2 Issues for a Parallelizing Compiler Given a program with data distribution specifications, a restructuring compiler performs the following tasks: * Assignment of computations to processors. * Generation of code to enumerate local iteration sets. * Local storage allocation for distributed
Reference: [7] <author> High Performance Fortran Forum. </author> <title> High performance fortran language specification vertion 1.0, </title> <year> 1993. </year>
Reference-contexts: The general block distributions described in the literature <ref> [7, 8, 9, 17] </ref> are special cases of this distributions. 2.1 Distribution descriptor We introduce the notion of a distribution descriptor that is associated with each distributed data item. This descriptor is a data structure which provides information about the distribution of the associated data item in a structured form. <p> For dense programs, block and cyclic distributions (as in HPF <ref> [7] </ref>) are standard, and a simple rule like the owner-computes rule [15] is used to determine the iterations to be performed on each processor.
Reference: [8] <author> High Performance Fortran Forum. </author> <title> High performance fortran language specification, </title> <note> version 2, specification. http://www.crpc.rice.edu/HPFF/hpf2/index.html, Oc-tober 1996. </note>
Reference-contexts: Successful compiler support here would be of benefit to the application writers as well as library writers. To this end, there have been some generalizations of the distributions allowed in HPF, the most general of which is the generalized block distribution in HPF-2 <ref> [8] </ref>. The generalized block distribution for an array is defined by a cartesian product of intervals, where each interval partitions one dimension of the array. <p> The general block distributions described in the literature <ref> [7, 8, 9, 17] </ref> are special cases of this distributions. 2.1 Distribution descriptor We introduce the notion of a distribution descriptor that is associated with each distributed data item. This descriptor is a data structure which provides information about the distribution of the associated data item in a structured form.
Reference: [9] <author> G. Fox, M. Johnson, G. Lyzenga, S. Otto, J. Salmon, and D. Walker. </author> <title> Solving problems on Concurrent Processors, volume 1. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1988. </year>
Reference-contexts: The general block distributions described in the literature <ref> [7, 8, 9, 17] </ref> are special cases of this distributions. 2.1 Distribution descriptor We introduce the notion of a distribution descriptor that is associated with each distributed data item. This descriptor is a data structure which provides information about the distribution of the associated data item in a structured form.
Reference: [10] <author> Hans Michael Gerndt. </author> <title> Automatic Parallelization for Distributed-Memory Multiprocessor Systems. </title> <type> PhD thesis, </type> <institution> Universitat Bonn, </institution> <year> 1990. </year>
Reference-contexts: The smallest rectangle that encloses the union of these five view sets is the set f ([64; 63]; [34; 34])g. This is precisely what the ghost region support in the libraries such as LPARX and DAGH do and is a generalization of overlap analysis introduced by Gerndt <ref> [10] </ref>. Note that this storage can be determined automatically given the data distribution. In particular, no information about the type of stencils used, etc need be conveyed to the compiler, since the data usage information can be extracted from the input code.
Reference: [11] <author> Vladimir Kotlyar, Keshav Pingali, and Paul Stodghill. </author> <title> Unified framework for sparse and dense smpd code generation. </title> <type> Technical Report TR97-1627, </type> <institution> Cornell University, </institution> <year> 1997. </year>
Reference-contexts: A more general treatment of some of the material of this section can be found in <ref> [11] </ref>. Code executed by processor 4 f 1: Atp1 and A are N-by-N matrices 2: do I = 2, 127 4: If I'm data-centric w.r.t. A (I,J+1) 5: if ((97 I 128) && (97 J+1 128)) 7: A (I-1,J)+A (I+1,J) - 4.0*A (I,J)) 8: endif g being data-centric w.r.t.
Reference: [12] <author> Ketan Mulmuley. </author> <title> Computation Geometry An Introduction Through Randomized Algorithms, chapter 2. </title> <publisher> Prentice-Hall. </publisher>
Reference-contexts: This is a variant of the well known multidimensional range-search problem in computational geometry <ref> [12] </ref>. The rectangles representing data ownership correspond to input rectangles and the rectangle representing the per-reference per-block view set is called the query rectangle.
Reference: [13] <author> Ketan Mulmuley. </author> <title> Computational Geometry An Introduction Through Randomized Algorithms. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1994. </year>
Reference-contexts: Pre-processing the input set of rectangles representing ownership information, as described below, allows us to answer each query in time (log d (N ) + k) time <ref> [13] </ref>, where k is the number of rectangles that intersect. In other words, given a certain number of input rectangles, the query time grows as the size of the actual number of positive results for the given query, rather than the size of the input set. <p> A more detailed discussion of this procedure and a generalization to d-dimensions is presented in <ref> [13] </ref> How does this relate to doing sends and receives? We show the relationship in one-dimension. The relationship in higher dimensions is similar. Figure 11 shows how the results of the range search problem can be used to generate recv calls for a single block of data. <p> Segments can be deleted and inserted into the skip list very efficiently. This allows for incremental maintenance of distribution information in the skip list when data distribution changes at run time. The following theorem (stated without proof) is crucial to the efficient dynamic behavior of the skip list <ref> [13] </ref>. Theorem 2 A single point can be inserted into or deleted from a skip list in time O (log m), where m is the number of points in the skip list. 6 Performance In this section, we present some preliminary performance measurements, shown in Figure 12.
Reference: [14] <author> Manish Parashar and James C. Browne. </author> <title> Distributed dynamic data-structures for parallel adaptive mesh refinement. </title> <booktitle> In HiPC, </booktitle> <year> 1995. </year>
Reference-contexts: Due to the irregular nature of this con nectivity, communication patterns are irregular. Because of the inadequacy of present compiler technology, several libraries have been developed to make the application programmer's job easier. The most important of these are Multi-block PARTI [1], P++/AMR++ [3], LPARX [2], DAGH <ref> [14] </ref>. All these libraries hide the nature of the data distribution from the application programmer as much as possible. They provide constructs such as forall loops to enable application writing at a high level, and provide library calls to take care of parallelization issues. <p> For adaptive mesh refinement, LPARX helps in reducing the communication between grid components at the same level, but the communication between grid components at different levels increases. Finally, DAGH <ref> [14] </ref> uses a space-filling curve enumeration to distribute the blocks of an array onto processors. Space filling curves ensure spatial locality, which means that this distribution policy reduces com munication between grid components at different levels of the grid hierarchy. <p> This is a simplified version of the actual relaxation code that is used in the solution to the 2-D wave equation using the DAGH library <ref> [14, 6] </ref>, and illustrates all the principles behind our approach. 2.2 Issues for a Parallelizing Compiler Given a program with data distribution specifications, a restructuring compiler performs the following tasks: * Assignment of computations to processors. * Generation of code to enumerate local iteration sets. * Local storage allocation for distributed
Reference: [15] <author> A. Rogers and K. Pingali. </author> <title> Process decomposition through locality of reference. </title> <booktitle> In SIGPLAN89 conference on Programming Languages, Design and Implementation, </booktitle> <month> Jun </month> <year> 1989. </year>
Reference-contexts: For dense programs, block and cyclic distributions (as in HPF [7]) are standard, and a simple rule like the owner-computes rule <ref> [15] </ref> is used to determine the iterations to be performed on each processor. In this case, closed form linear integer constraints can be used to express the local storage requirements, the local iteration sets, communication sets as well as the placement of communication. <p> Note that this code is still written in a shared-memory style, because the indices used to access the elements of all the arrays are global indices. This code is similar to that produced by run-time resolution <ref> [15] </ref> for distributed memory multiprocessors. We refer to such conditionals introduced to limit a specific access to a specific block as localization constraints.
Reference: [16] <author> M. Wolfe. </author> <title> High Performance Compilers for Parallel Computing. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1995. </year>
Reference-contexts: Let A pj denote block j of A on processor p. Let R be the reference to A which we have chosen to be data-centric. Let F (r) be the access matrix <ref> [16] </ref> for any reference r, i.e. iteration ~ i touches data item F (r) fl ~ i through reference r. We define the following concepts: Definition 1 The per-block owned data OB (p; A pj ) of a block is the elements of the data item it contains.
Reference: [17] <author> H. Zima, H. Bast, and M. gerndt. </author> <title> Superb, a tool for semiautomatic mimd/simd parallelization. </title> <booktitle> In Parallel Comput., </booktitle> <pages> pages 1-18, </pages> <year> 1986. </year>
Reference-contexts: The general block distributions described in the literature <ref> [7, 8, 9, 17] </ref> are special cases of this distributions. 2.1 Distribution descriptor We introduce the notion of a distribution descriptor that is associated with each distributed data item. This descriptor is a data structure which provides information about the distribution of the associated data item in a structured form.
References-found: 17

