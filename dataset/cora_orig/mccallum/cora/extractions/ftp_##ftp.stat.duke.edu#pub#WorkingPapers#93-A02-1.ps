URL: ftp://ftp.stat.duke.edu/pub/WorkingPapers/93-A02-1.ps
Refering-URL: http://www.isds.duke.edu/~mw/papers.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Hierarchical priors and mixture models, with application in regression and density estimation  
Author: MIKE WEST PETER M ULLER and MICHAEL D ESCOBAR 
Abstract-found: 0
Intro-found: 1
Reference: <author> Antoniak, C.E. </author> <title> (1974) Mixtures of Dirichlet processes with applications to nonparametric problems. </title>
Reference-contexts: is completed by specifying an appropriate hyperprior distribution for : Dirichlet process mixture models are based on Dirichlet process priors for the primary parameters i : Such a model assumes that the prior distribution function G itself is uncertain, drawn from a Dirichlet process G ~ D (ffG 0 ) <ref> (in standard notation, such as in Antoniak 1974) </ref>. Here E (G) = G 0 is the base prior, and ff &gt; 0 the scalar precision parameter. <p> the prior expectation G 0 : In this section we suppress dependence on both and in the notation, for clarity; it should be borne in mind that the following discussion is all conditional on both and : The following properties and reinterpretation of this model clearly elucidate the resulting structure <ref> (see Antoniak 1974, and West 1990) </ref>. (i) Any realisation of n case specific parameters i generated from G lie in a set of k n distinct values, denoted by = f 1 ; : : : ; k g: (ii) The i are a random sample from G 0 (:): (iii)
Reference: <editor> Ann. Statist., </editor> <volume> 2, </volume> <pages> 1152-1174. </pages>
Reference: <author> DuMouchel, W.M. and Harris, </author> <title> J.E. (1983) Bayes methods for combining the results of cancer studies in humans and other species (with discussion). </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 78, </volume> <pages> 293-315. </pages>
Reference: <author> Erkanli, A., Muller, P., and West, M. </author> <title> (1992) Curve fitting using mixtures models. Invited revision for Biometrika. </title>
Reference-contexts: Mixture priors, especially Dirichlet mixtures (Antoniak 1974; Escobar and West 1991), have also opened the way to serious Bayesian developments in (so-called) non-parametric modelling and density estimation, and smooth regression estimation <ref> (Erkanli, Muller and West 1992) </ref>. It is our purpose in this paper to exhibit a general framework for hierarchical linear modelling and density estimation, to show how posterior computations via Markov chain simulations can be routinely applied, and to provide illustrations in each context. <p> note here that the posterior reflects very little uncertainty about the locations i of the suggested three clusters; Figure 4 provides some insight by displaying the first two components of just a few of the sampled i : Some applications of these models are more concerned with smooth regression estimation <ref> (Erkanli, Muller and West 1992) </ref> rather than density estimation per se. Regression estimation simply involves summarising inferences about conditional predictive distributions, and so is trivially obtained within the existing mixture analysis.
Reference: <author> Escobar, </author> <title> M.D. (1988) Estimating the means of several normal populations by nonparametric estimation of the distribution of the means. </title> <type> Unpublished PhD dissertation, </type> <institution> Yale University. </institution>
Reference: <author> Escobar, M.D., and West, M. </author> <title> (1991) Bayesian density estimation and inference using mixtures. </title>
Reference: <institution> Invited revision for J. </institution> <note> Amer. Statist. Assoc. 12 Hierarchical Priors and Mixture Models February 9, 1994 Escobar, M.D. </note> <author> and West, M. </author> <title> (1992) Computing Bayesian nonparametric hierarchical models. ISDS Discussion Paper #92-A20, </title> <institution> Duke University. </institution>
Reference: <author> Gelfand, A.E., and Smith, A.F.M. </author> <title> (1990) Sampling based approaches to calculating marginal densities. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 85, </volume> <pages> pp. 398-409. </pages>
Reference: <author> Gelfand, A.E., Hills, S.E., Racine-Poon, A., and Smith, A.F.M. </author> <year> (1990), </year> <title> Illustration of Bayesian inference in normal data models using Gibbs sampling. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 85, </volume> <pages> 972-985. </pages>
Reference: <author> Kuo, L., and Smith, A.F.M. </author> <title> (1992) Bayesian computations in survival models via the Gibbs sampler. </title>
Reference: <editor> In Survival Analysis: </editor> <title> State of the Art, </title> <editor> J.P. Klein and P.K. Goel (eds.) </editor> <publisher> Kluwer. </publisher>
Reference: <author> Lindley, D.V. </author> <title> (1972) Bayesian Statistics, A Review, </title> <publisher> SIAM, </publisher> <address> Philadelphia. </address>
Reference-contexts: 1 Introduction In his 1972 review of Bayesian statistics, Dennis Lindley identified as a success story for Bayesian ideas the advances made in problems of many parameters and the growth of what is now referred to as Bayesian hierarchical modelling <ref> (Lindley 1972 section 8) </ref>. In that same monograph, Lindley identified non-parametrics as an area notable for lack of Bayesian progress, bemoaning the fact that non-parametric statistics was a "subject about which the Bayesian method is embarrassingly silent" (Lindley 1972 section 12.2). <p> In that same monograph, Lindley identified non-parametrics as an area notable for lack of Bayesian progress, bemoaning the fact that non-parametric statistics was a "subject about which the Bayesian method is embarrassingly silent" <ref> (Lindley 1972 section 12.2) </ref>. Our purpose here is to develop and review recent work with mixture priors that has substantially contributed to both hierarchical modelling and non-parametrics, the latter focussed on problems usually referred to as non-parametric density estimation.
Reference: <author> Lindley, D.V. and Smith, A.F.M. </author> <title> (1972) Bayes' estimates for the linear model (with discussion). </title>
Reference-contexts: 1 Introduction In his 1972 review of Bayesian statistics, Dennis Lindley identified as a success story for Bayesian ideas the advances made in problems of many parameters and the growth of what is now referred to as Bayesian hierarchical modelling <ref> (Lindley 1972 section 8) </ref>. In that same monograph, Lindley identified non-parametrics as an area notable for lack of Bayesian progress, bemoaning the fact that non-parametric statistics was a "subject about which the Bayesian method is embarrassingly silent" (Lindley 1972 section 12.2). <p> In that same monograph, Lindley identified non-parametrics as an area notable for lack of Bayesian progress, bemoaning the fact that non-parametric statistics was a "subject about which the Bayesian method is embarrassingly silent" <ref> (Lindley 1972 section 12.2) </ref>. Our purpose here is to develop and review recent work with mixture priors that has substantially contributed to both hierarchical modelling and non-parametrics, the latter focussed on problems usually referred to as non-parametric density estimation.
Reference: <author> J. Roy. </author> <title> Statist. </title> <journal> Soc. (Ser B), </journal> <volume> 34, </volume> <pages> 1-41. </pages>
Reference: <author> Lubischew, A. </author> <year> (1962), </year> <title> On the use of discriminant functions in taxonomy, </title> <journal> Biometrics, </journal> <volume> 18, </volume> <pages> 455-477. </pages>
Reference: <author> MacEachern, </author> <title> S.M. (1992) Estimating normal means with a conjugate style Dirichlet process prior. </title> <type> Technical report No 487, </type> <institution> Department of Statistics, The Ohio State University. </institution>
Reference: <author> MacEachern, S.M. and Muller, P. </author> <title> (1994) Estimating mixture of Dirichlet process models. </title> <institution> ISDS Discussion Paper , Duke University. </institution>
Reference: <author> O'Hagan, A. </author> <title> (1988) Modelling with heavy tails. In Bayesian Statistics 3, </title> <editor> J.M. Bernardo, M.H. De Groot, D.V. Lindley and A.F.M. Smith (eds.) </editor> <publisher> Oxford. </publisher>
Reference: <author> Smith, A.F.M. </author> <title> (1983) Comment on article by DuMouchel and Harris, </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 78, </volume> <pages> 293-315. </pages>
Reference: <author> Turner, D.A.T. and West, M. </author> <note> (1993) Statistical analysis of mixtures applied to postsynpotential fluctuations. Journal of Neuroscience Methods (to appear). </note>
Reference: <author> West, M. </author> <title> (1984) Outlier models and prior distributions in Bayesian linear regression. </title> <journal> J. Roy. Statist. Soc. (Ser. B), </journal> <volume> 46, </volume> <pages> 431-439. </pages>
Reference: <author> West, M. </author> <title> (1985) Generalised linear models: scale parameters, outlier accommodation and prior distributions. In Bayesian Statistics 2, </title> <editor> J.M. Bernardo, M.H. De Groot, D.V. Lindley and A.F.M. Smith (eds.) </editor> <publisher> North Holland, Amsterdam. </publisher>
Reference: <author> West, M. </author> <title> (1990) Bayesian kernel density estimation. ISDS Discussion Paper #90-A02, </title> <institution> Duke University. </institution>
Reference: <author> West, M. </author> <title> (1992) Hyperparameter estimation in Dirichlet process mixture models. ISDS Discussion Paper #92-A03, </title> <institution> Duke University. </institution>
Reference-contexts: For example, long-suffered constraints to conjugate prior distributions in hierarchical models (Smith, in discussion of DuMouchel and Harris 1983; West 1984, 1985) can be relieved by the use of mixtures of conjugate priors with ease <ref> (Escobar and West 1992) </ref>. Mixture priors, especially Dirichlet mixtures (Antoniak 1974; Escobar and West 1991), have also opened the way to serious Bayesian developments in (so-called) non-parametric modelling and density estimation, and smooth regression estimation (Erkanli, Muller and West 1992). <p> Mixture priors, especially Dirichlet mixtures (Antoniak 1974; Escobar and West 1991), have also opened the way to serious Bayesian developments in (so-called) non-parametric modelling and density estimation, and smooth regression estimation <ref> (Erkanli, Muller and West 1992) </ref>. It is our purpose in this paper to exhibit a general framework for hierarchical linear modelling and density estimation, to show how posterior computations via Markov chain simulations can be routinely applied, and to provide illustrations in each context. <p> Early implementations by the authors use this structure <ref> (Escobar and West 1992) </ref>, which is illustrated in Section 4 below, often fixing fl at specified prior values. Realistically, uncertainty about these quantities is almost surely evident, so we turn to the issue of suitable priors for fl: In all cases, we assume s to be specified. <p> note here that the posterior reflects very little uncertainty about the locations i of the suggested three clusters; Figure 4 provides some insight by displaying the first two components of just a few of the sampled i : Some applications of these models are more concerned with smooth regression estimation <ref> (Erkanli, Muller and West 1992) </ref> rather than density estimation per se. Regression estimation simply involves summarising inferences about conditional predictive distributions, and so is trivially obtained within the existing mixture analysis.
Reference: <author> West, M. and Cao, G. </author> <title> (1993) Assessing mechanisms of neural synaptic activity. In Bayesian Statistics in Science and Technology: Case Studies, </title> <editor> C. Gatsonis, J. Hodges, R. Kass and N. Singpur-walla (eds.) </editor> <booktitle> (to appear). </booktitle> <pages> 13 </pages>
References-found: 25

