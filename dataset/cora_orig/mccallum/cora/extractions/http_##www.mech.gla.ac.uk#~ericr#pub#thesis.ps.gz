URL: http://www.mech.gla.ac.uk/~ericr/pub/thesis.ps.gz
Refering-URL: http://www.ph.tn.tudelft.nl/PRInfo/reports/msg00387.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: INCREMENTAL POLYNOMIAL CONTROLLER NETWORKS: two self-organising non-linear controllers  
Author: Eric Ronco Eric Ronco 
Degree: A dissertation submitted to the Faculty  for the degree of Doctor of Philosophy By  All right Reserved  
Note: c flCopyright 1997 by  
Date: September 1997  
Affiliation: of Mechanical Engineering of Glasgow University  
Abstract-found: 0
Intro-found: 1
Reference: <author> Agarwal, M. </author> <year> (1997). </year> <title> A systematic classification of neural-network-based control. </title> <journal> Ieee Control Systems Magazine 17, </journal> <pages> 75-93. </pages>
Reference-contexts: Therefore, the weights (1.7) of any perceptron can be updated by determining the error gradient (1.8) from the last layer to the first one. 1.2.2 Neuro-control approaches Neural networks have been used for different purposes in the context of control (see for details <ref> (Agarwal, 1997) </ref>). We are only interested in the different existing methods used to develop a neuro-controller. Most of these methods are based on inverse control. <p> The neural training consists simply of learning the mapping between the sensory information received by the human controller and the control input (see figure 1.4). The problem with this method is that it is sometimes difficult to determine the information used by the expert to control a system <ref> (Agarwal, 1997) </ref>. Note that X is the vector of the network inputs. A similar approach entails training a neuro-controller to mimic the behaviour of an other controller designed with a conventional method (see figure 1.5). This can be useful when the conventional control approach requires too many computations.
Reference: <author> Arbib, M.A. </author> <year> (1987). </year> <title> Brain, Machine and Mathematics. </title> <publisher> Springer-Verlag. </publisher>
Reference: <author> Astrom, Karl J. </author> <booktitle> and Bjorn Wittenmark (1990). Computer-Controlled Systems: Theory and Design. Prentice-Hall International, </booktitle> <publisher> inc. </publisher>
Reference: <author> Berthier, N. E., Singh S. P., Barto A. G. and Houk J. C. </author> <year> (1993). </year> <title> Distributed representation of limb motor programs in array of adjustable pattern generators. </title> <journal> Journal of Cognitive Neuroscience 5(1), </journal> <pages> 56-78. </pages>
Reference: <author> Bottou, L. and P. </author> <month> Galliinari </month> <year> (1991). </year> <title> A framework for the cooperation of learning algorithms. In: Neural Information Processing Systems 3 (Lippmann and al., </title> <editor> Eds.). </editor> <volume> Vol. 3. </volume> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Brashers-Krug, T., R. Shadmehr and E. </author> <month> Todorov </month> <year> (1995). </year> <title> Catastrophic interference in human motor learning. </title> <booktitle> Advances in Neural Information Processing Systems. </booktitle>
Reference: <author> Butler, </author> <title> Hans (1992). Model reference Adaptive Control: From Theory to Practice. </title> <publisher> Prentice-Hall International Ltd. </publisher>
Reference-contexts: Only the type of controller used during this thesis will be presented in this section. This controller is known as the Model Reference Adaptive Controller (MRAC). There is a considerable literature on MRAC since this design method is widely applied for adaptive control (see <ref> (Butler, 1992) </ref> for an introduction book). This algorithm has been used here because of its simplicity of implementation rather than for any theoretical reason. <p> Hence, for details about more conventional MRAC, the reader is suggested to refer to <ref> (Butler, 1992) </ref>. A MRAC is very appealing since it is a very intuitive way of designing a controller. <p> These MRAC are attempting to overcome the problem of instability of the system inverse. However these controllers are not efficient enough to handle most of the linear systems. The main problem comes from the difficulty to find a compromise between on-line controller parametrisation and control stability (see <ref> (Butler, 1992) </ref> for a discussion). No attempt to overcome this limitation has been made in this thesis since the emphases was on the problems related to system non-linearity rather than on problems involved by system dynamics.
Reference: <author> Canudas de Wit, Carlos A. </author> <year> (1988). </year> <title> Adaptive Control for Partially Known Systems. </title> <publisher> Elbevier Science Publishers B.V. </publisher>
Reference-contexts: here to deal further with discrete time models but rather adopt a continuous time modelling approach. 2.2.2 Continuous Time Modelling As seen in the previous section, a discrete time model is some time too sensitive to the sampling interval to be relevant for the modelling of a continuous time system <ref> (Canudas de Wit, 1988) </ref>. There are other reasons why it is preferable to use a continuous time approach to model a continuous time system.
Reference: <author> Carmon, A. </author> <year> (1986). </year> <title> Applying self-tuning control to plant. </title> <booktitle> Control and Instumentation 18, </booktitle> <pages> 81-83. </pages>
Reference: <author> Carpenter, G. A. and S. </author> <title> Grossberg (1988). The art of adaptive pattern recognition by a self-organising neural network. </title> <booktitle> IEEE Computer 21(3), </booktitle> <pages> 77-88. </pages>
Reference-contexts: This is due to the existence of flat areas and/or local minima in the error surface (Rumulhart and McClelland, 1986; LeCun, 1987; Choi and Choi, 1992; Hecht-Nielsen, 1991). Another cause for the learning failure is the "stability-plasticity dilemma" <ref> (Carpenter and Gross-berg, 1988) </ref>. This is typical of problems where more than one task has to be learned by the same network (two different tasks can be simply two different non-linear regions of the system). <p> However this is going to increase the problem that is most serious while applying linear adaptive controller to the control of non-linear systems. This is a basic design problem for learning machine emphasised by <ref> (Carpenter and Grossberg, 1988) </ref>: the"stability-plasticity dilemma"; while the controller is adapting to an operating region of the system it is forgetting previous adaptations concerning other regions. This effect appears during the third control sequence (see figure 2.13). <p> This makes these approaches very suitable for online control purposes. Another advantage of these algorithms is that they do not suffer from the "stability-plasticity dilemma" which is a basic design problem for learning machine as emphasised by <ref> (Carpenter and Grossberg, 1988) </ref>: while the model is adapting to an operating region of the system it is forgetting previous adaptations regarding other regions. The LCN and MSM are not exposed to this dilemma because each model-controller is specially adapted for a different operating region of the system. <p> This resulted in a control performance worse than during the second sequence. This effect is a basic machine learning problem referred as the "stability-plasticity dilemma" <ref> (Carpenter and Grossberg, 1988) </ref>. A simple way to avoid the "stability-plasticity dilemma" is to use a number of controllers each valid for a different operating region of the system. <p> If the function is discontinuous, adaptive control cannot be applied. In addition, the slowness of such an adaptation may result in a large transient error (Narendra et al., 1995). A more serious problem is the basic design problem for learning machines emphasised by <ref> (Carpenter and Grossberg, 1988) </ref>: the "stability-plasticity dilemma". While the controller is adapting to an operating region of the system it is forgetting previous adaptations concerning other regions.
Reference: <author> Carpenter, R.H.S. </author> <year> (1984). </year> <title> Neurophysiology. </title> <publisher> London. </publisher>
Reference: <author> Carson, E. R. </author> <year> (1990). </year> <booktitle> Measurement and control in medicine. Measurement and Control 23, </booktitle> <pages> 260-262. </pages>
Reference-contexts: It sounds like "the brain plays on spinal cord not as one plays piano, but rather as one selects a disc from a juke box" <ref> (Carson, 1990) </ref>. Another very important statement is that, with practice, biological control systems can develop an accurate internal model of the plant under control (Shadmehr and Mussa-Ivaldi, 1994; Brashers-Krug et al., 1995; Keele et al., 1995; Kawato, 1989). This has been nicely demonstrated by (Shadmehr and Mussa-Ivaldi, 1994).
Reference: <author> Chen, S., S. A. Billings and P. M. </author> <title> Grant (1990). Non-linear system identification using neural networks. </title>
Reference-contexts: This way the MLP can be interpreted as a NARMAX model (Non-linear Auto-Regressive model, with Moving Average part and eXogenous input) of the system <ref> (Chen et al., 1990) </ref>. The NARMAX model is the lagged version of the NARX model.
Reference: <editor> Int. J. </editor> <booktitle> Control 51, </booktitle> <pages> 1191-1214. </pages>
Reference: <author> Choi, Chong-Ho and Jin Young Choi (1992). </author> <title> Partially trained neural networks based on partition of unity. </title> <booktitle> In: Proceeding of the International Joint Conference on Neural Networks (IJCN92). </booktitle>
Reference-contexts: It appears that the number of parameters seems excessive and the unclear correlation between architecture and learning abilities make it difficult to set up optimal multi-CALM model (Francesco, 1994). Another example of such a self-clustering approach was given by <ref> (Choi and Choi, 1992) </ref>. The learning procedure implies two stages. First, the centre of each partition is found by unsupervised learning. Following this stage, a supervised learning is used to train the models connected to each partitioning unit.
Reference: <author> Clarke, D. W., C. Mohtadi and P. S. </author> <month> Tuffs </month> <year> (1987). </year> <title> Generalized predictive control-i. the basic algorithm. </title> <type> Automatica 23, </type> <pages> 137-148. </pages>
Reference-contexts: This is the basis of predictive control: the control is achieved according to the predicted output of the plant given by its forward model. This idea has been generalised by <ref> (Clarke et al., 1987) </ref> to deal with plant with complex dynamics (e.g. unstable inverse systems, time-varying time delay, etc), and plant model mismatch (Rusnak et al., 1996). (Clarke et al., 1987) coined this controller as the "generalised predictive control" (GPC). <p> This idea has been generalised by <ref> (Clarke et al., 1987) </ref> to deal with plant with complex dynamics (e.g. unstable inverse systems, time-varying time delay, etc), and plant model mismatch (Rusnak et al., 1996). (Clarke et al., 1987) coined this controller as the "generalised predictive control" (GPC). The GPC is the main design method of a model based predictive controller (MBPC). A MBPC is composed of three main components: the system, its model and a function optimiser (see figure 1.10).
Reference: <author> Clarke, David (1994). </author> <title> Advances in Model-Based Predictive Control. </title> <publisher> Oxford university press. </publisher>
Reference-contexts: Moreover, there is at least an other controller that is thought to have a much higher potential to handle most of the linear systems: the "Model-Based Predictive Controller" (see for a review <ref> (Clarke, 1994) </ref>). Hence, it is very likely that future work in this area will imply such a controller rather than a MRAC. 54 CHAPTER 2. LINEAR SELF-ADAPTIVE CONTROL 2.5 Illustration In order to make clear the different concepts introduced so far two different examples are going to be presented.
Reference: <author> Cybenko, G. </author> <year> (1988). </year> <title> Continuous valued neural networks with two hidden layers are sufficient. </title> <type> Technical report. </type> <institution> Departement of computer science, Tufts University. </institution> <address> Medford, MA. </address> <note> 125 126 BIBLIOGRAPHY Cybenko, </note> <author> G. </author> <year> (1989). </year> <title> Approximation by superposition of a sigmoidal function. </title> <booktitle> Mathematics of Control, Signal and Systems 2, </booktitle> <pages> 303-314. </pages>
Reference: <author> Dorf, R.C. </author> <year> (1989). </year> <title> Modern Control Systems. </title> <publisher> Addison Wesley. </publisher>
Reference: <author> Feldman, J.A. </author> <year> (1989). </year> <title> Neural representation of conceptual knowledge. In: Neural connections, mental computation (Nadel and al., </title> <editor> Eds.). </editor> <publisher> MIT Press. </publisher> <address> Cambridge, MA. </address>
Reference-contexts: Modularity is a natural way to ease the learning of complex behaviour. Mountcastle (Mountcastle, 1978) and many others (Karmiloff-Smith, 1994; Houk and Wise, 1995; Carpenter, 1984) argue that modularity is a brain organising principle. <ref> (Feldman, 1989) </ref> and (Simon, 1981) highlight the fact that a complex behaviour requires the bringing together of several different kinds of knowledge and processing, which is not possible without structure (i.e. modularity). Moreover, and according to Marr such a modularity can enable a learning economy.
Reference: <author> Fogelman-Soulie, F. </author> <year> (1993). </year> <title> Multi-modular neural network-hybrid architectures: a review. </title> <booktitle> In: Proceedings of 1993 International Joint Conference on Neural Networks. </booktitle>
Reference: <author> Francesco, M. </author> <year> (1994). </year> <title> Functional Networks. </title> <type> PhD thesis. </type> <institution> Faculte des Sciences de l'Universite de Geneve. </institution>
Reference-contexts: This model is named "CALM" for Categorising And Learning Module. A CALM module tends to autonomously cluster stimuli belonging to the same region by way of inhibitory connections between neurons involving competition in the CALM module. Note that <ref> (Francesco, 1994) </ref> highlights the fact that this model was developed with psychological and neurological considerations. Thus this model is very interesting from a life science point of view but seems to have some limitation considering its usefulness. <p> Thus this model is very interesting from a life science point of view but seems to have some limitation considering its usefulness. It appears that the number of parameters seems excessive and the unclear correlation between architecture and learning abilities make it difficult to set up optimal multi-CALM model <ref> (Francesco, 1994) </ref>. Another example of such a self-clustering approach was given by (Choi and Choi, 1992). The learning procedure implies two stages. First, the centre of each partition is found by unsupervised learning. Following this stage, a supervised learning is used to train the models connected to each partitioning unit. <p> Having chosen the value of we can work out the value of ! from the settling time. The duration of the error, define as the deviation of y from the set point, is essentially decided by the transient exponential e !t <ref> (Francesco, 1994) </ref>. Hence, if we define the settling time t s as that value of t s when the decaying exponential reaches 1% (i.e. e !t = 0:01) we have 52 CHAPTER 2.
Reference: <author> Franklin, Gene F., J. David Powell and Abbas Emami-Naeini (1994). </author> <title> Feedback Control of Dynamic Systems. </title> <publisher> Addison-Wesley Publishing Company. </publisher>
Reference-contexts: In figure 2.8 is depicted the behaviour of a system with different values of . Now the question is how to determine the values of the natural frequency ! and the damping ratio . Without details (that you can found in <ref> (Franklin et al., 1994) </ref>), for 0 &lt; 1 we have the percentage of overshoot define as M p = e p 1 2 . From the plot of this equation (see figure 2.9), we can determine the value of according to the desired percentage of overshoot. <p> However, this is usually only be an approximation since it is difficult to have a general way of determining the rise time whatever the system dynamic is <ref> (Franklin et al., 1994) </ref>. All the curves rising in roughly the same time we consider the curve corresponding to = 0:5 be an average.
Reference: <author> Gawthrop, Peter J. </author> <year> (1987). </year> <title> Continuous-Time Self-Tuning Control. </title> <publisher> research studies press ltd ed.. Research Studies Press LTD, </publisher> <address> England. Letchworth, Hertfordshire, England. </address>
Reference: <author> Gawthrop, Peter J. </author> <year> (1995). </year> <title> Continuous-time local state local model networks. In: </title> <journal> IEEE Systems, man and cybernetics. Vancouver. </journal>
Reference-contexts: Embedding modularity into Neural Networks (NN) gives many advantages over the use of single NN (see below and for further details <ref> (Ronco and Gawthrop, 1995) </ref>). "Modular Neural Network" (MNN) refers here to a network performing a local computation of the information. That is to say that only one part of the network is involved in computing each input vector. <p> That is to say that only one part of the network is involved in computing each input vector. This definition is certainly loose but because currently there is no real definition of a MNN, this is the one adopted in this study (for a discussion about this issue see <ref> (Ronco and Gawthrop, 1995) </ref>). Modularity is a natural way to ease the learning of complex behaviour. <p> The main issues to develop a MNN are the modular organisation in the network architecture and the decomposition of a task (problem, environment) into sub-tasks <ref> (Ronco and Gawthrop, 1995) </ref>. A sensible way to decompose a task is to do so according to the computation capability of the modules. In fact, the modules should also be built according to the task they would have to perform. <p> CONCLUSION 35 1.4 Conclusion In this chapter was reviewed the main existing neuro-control techniques. Two different neuro-control approaches has been distinguished. One entails developing a single controller from a neural network and the other one intends to embed a number of controllers inside a neural network <ref> (Gawthrop, 1995) </ref>. The single controller approach is more conventional in the sense that in control engineering first a model of the plant is conceived and then a controller is designed. The main single neuro-control approaches find in the literature have been described.
Reference: <author> Gawthrop, Peter J. </author> <year> (1996). </year> <title> Self-tuning pid control structure. </title> <booktitle> In: IEE Colloqium. </booktitle> <address> London. </address>
Reference-contexts: If a controller is due to be adaptive for all its life time (indeed not indefinitely but hopefully for a significantly long period) this would certainly overload the computer's memory. To avoid this problem the method described in <ref> (Gawthrop and Ronco, 1996) </ref> has been applied here. This method can be thought of the SVD solution to the least error square of (2.22). <p> 6 6 6 6 6 6 6 6 6 6 4 s N y P odd 2 s N y 3 s N1 y P odd 2 s N1 y 3 y P odd ::: 3 7 7 7 7 7 7 7 7 7 7 7 7 7 Following <ref> (Gawthrop and Ronco, 1996) </ref>, to find ^ p , we minimise the mean squared error from time t t to time t given by: Z t ^e 2 dt = ^ pT S ^ p (4.15) where S = tt t dt (4.16) To avoid the trivial solution ^ p =
Reference: <author> Gawthrop, Peter J. and Eric Ronco (1996). </author> <title> Local model networks and self-tuning predictive control. </title> <booktitle> In: IEEE Mediterranean Symposium on New Directions in Control and Automation. </booktitle>
Reference-contexts: If a controller is due to be adaptive for all its life time (indeed not indefinitely but hopefully for a significantly long period) this would certainly overload the computer's memory. To avoid this problem the method described in <ref> (Gawthrop and Ronco, 1996) </ref> has been applied here. This method can be thought of the SVD solution to the least error square of (2.22). <p> 6 6 6 6 6 6 6 6 6 6 4 s N y P odd 2 s N y 3 s N1 y P odd 2 s N1 y 3 y P odd ::: 3 7 7 7 7 7 7 7 7 7 7 7 7 7 Following <ref> (Gawthrop and Ronco, 1996) </ref>, to find ^ p , we minimise the mean squared error from time t t to time t given by: Z t ^e 2 dt = ^ pT S ^ p (4.15) where S = tt t dt (4.16) To avoid the trivial solution ^ p =
Reference: <author> Gollee, H. and D. J. </author> <title> Murray-Smith (1997). Validation of an empirical model structure by analysing model properties. </title> <booktitle> In: International Conference on Engineering Applications of Neural Networks. </booktitle> <address> Stockholm, Sweden. </address>
Reference-contexts: Each local model being linear the "learning" is straightforward using least squares like methods. The interaction between local models introduces non-linearity into the structure. This tends to prohibit the use of least square like method. A gradient descent would have to be used in the global case as in <ref> (Gollee and Murray-Smith, 1997) </ref>. In this case the convergence to a global minima is no more ensured and the training time is much more longer. * A local learning can enable model switching i.e. selection at each instant of one local model only.
Reference: <author> Gollee, H. and K. J. </author> <title> Hunt (1997). Nonlinear modelling and control of electrically stimulated muscle: a local model network approach. </title> <journal> Int J Control. </journal> <note> To appear. </note>
Reference-contexts: Each local model being linear the "learning" is straightforward using least squares like methods. The interaction between local models introduces non-linearity into the structure. This tends to prohibit the use of least square like method. A gradient descent would have to be used in the global case as in <ref> (Gollee and Murray-Smith, 1997) </ref>. In this case the convergence to a global minima is no more ensured and the training time is much more longer. * A local learning can enable model switching i.e. selection at each instant of one local model only.
Reference: <author> Golub, Gene H. and Charles F. Van Loan (1989). </author> <title> Matrix Computations. </title> <publisher> The John Hopkins University Press. </publisher>
Reference-contexts: Note that proofs concerning all the above can be found in <ref> (Golub and Van Loan, 1989) </ref>. Although this diagnosis is of primordial importance while estimating parameters we wish more from the SVD.
Reference: <author> Gomi, </author> <title> Hiroaki and Mitsuo Kawato (1993). Neural network for a closed-loop system using feedback-error-control. </title> <booktitle> Neural Networks pp. </booktitle> <pages> 933-946. </pages>
Reference-contexts: For instance the use of the system output can produce an exact inverse even when the forward model is inexact; this is not the case when the forward model is used (Jordan and Rumelhart, 1992). The approach studied by (Narendra and Parthasarathy, 1990) and latter by <ref> (Gomi and Kawato, 1993) </ref> was slightly different from the one just discussed. A reference model was injected into the structure to give a desired transient system output y rather than a simple desired output r not varying with time (see figure 1.9).
Reference: <author> Gomm, J. B., J. T. Evans and D. </author> <title> Williams (1997). Development and performance of a neural-network predictive controller. </title> <journal> Control Engineering Practice 5, </journal> <pages> 49-59. </pages>
Reference-contexts: This way of introducing dynamics into a static network has the advantage of being simple to implement but it has restricted dynamics properties compared to a recurrent neural network <ref> (Gomm et al., 1997) </ref>. In the other hand a recurrent neural network tends to further complicate the learning (Venugopal and al., 1994).
Reference: <author> Gorinevsky, Dimitry M. </author> <year> (1993). </year> <title> Modelling of direct motor program learning in fast human arm motions. </title> <booktitle> Biological Cybernetics 69, </booktitle> <pages> 219-228. </pages>
Reference-contexts: NEURAL NETWORKS FOR MODELLING AND CONTROL inconsistency which can not be overcome without feedback. It is not trivial at all to learn the inverse dynamics of highly delayed and noisy systems that are widespread in the real world <ref> (Gorinevsky, 1993) </ref>. However, even if one can get a true inverse model of the system, this controller is still going to be very sensitive to system disturbances and delays.
Reference: <author> Grossberg, S. </author> <year> (1973). </year> <title> Contour enhancement, short term memory and constancies in reverberating neural networks. </title> <booktitle> Studies in Applied Mathematics 52, </booktitle> <pages> 217-57. </pages>
Reference: <author> Grossberg, S. </author> <year> (1978). </year> <title> A theory of visual coding, memory and development. In: Formal theories of visual perception. </title> <publisher> Wiley, </publisher> <address> New York. </address>
Reference: <author> Happel, B.L.M. </author> <title> and J.M.J Murre (1994). Design and evolution of modular neural network architectures. </title> <booktitle> Neural Networks 7, </booktitle> <pages> 985-1004. </pages>
Reference-contexts: Each of these elements itself only has a simple function. Complex functions are obtained as emergent behaviour of the dynamic interactions of the simple elements" <ref> (Happel and Murre, 1994) </ref>. The first attempt to build such a computing system was made by (McCulloch and Pitts, 1943) in 1943. They developed an analogous system composed of interconnected simple computing units based on the model of a neuron.
Reference: <author> Hasan, W. M. and E. </author> <title> Viola (1997). Use of the singular value decomposition method to detect ill-conditioning structural identification problems. </title> <booktitle> Computers and Structures 63(2), </booktitle> <pages> 267-275. </pages> <note> BIBLIOGRAPHY 127 Hecht-Nielsen, </note> <author> R. </author> <year> (1991). </year> <title> Neurocomputing. </title> <publisher> Addison Wesley. </publisher> <editor> Hernandez, Evelio and Yaman Arkun (1993). </editor> <title> Control of nonlinear systems using polynomial arma models. </title> <booktitle> Process Systems Engineering 39(3), </booktitle> <pages> 446-460. </pages>
Reference-contexts: Moreover there are cases where you have got fewer equations than parameters (M &lt; N ). An other problem is that if the data are ill-conditioned by noise the perturbation is going to be increased by a matrix inversion <ref> (Hasan and Viola, 1997) </ref>. In all these cases, the use of the least square method (2.19) to determine ^ would not give a satisfactory solution or no solution at all.
Reference: <author> Hopfield, J.J. </author> <year> (1982). </year> <title> Neural networks and physical systems with emergent collective computational abilities. </title> <booktitle> In: Proceeding of the National Acadamy of Sciences of the U.S.A.. </booktitle> <volume> Vol. 79. </volume> <pages> pp. 2554-2558. </pages>
Reference-contexts: Early work of Grossberg dealt with the problem of cooperation and competition among cells (Grossberg, 1973; Grossberg, 1978). However a real resurgence of this field started in the eighties with the work on recurrent neural network done by Hopfield <ref> (Hopfield, 1982) </ref> and the model of self-organising map developed by Kohonen (Kohonen, 1982). A strong impulse to the connexionnist models was given in 1986 when (Rumulhart and McClelland, 1986; LeCun, 1987) rediscovered the back-propagation learning algorithm developed in first place by (Werbos, 1974).
Reference: <author> Hornik, K. </author> <year> (1993). </year> <title> Some new results on neural network approximation. </title> <booktitle> Neural Networks 6, </booktitle> <pages> 1069-1072. </pages>
Reference: <author> Houk, James C. and Steven P. </author> <title> Wise (1995). Distributed modular architectures linking basal ganglia, cerebellum, and cerebral cortex: Their role in planning and controlling action. </title> <type> Cerebral Cortex 2, </type> <pages> 95-110. </pages>
Reference: <author> Hsia, Tien C. </author> <year> (1977). </year> <title> System identification. </title> <address> D.C. </address> <publisher> Heath and Company. </publisher>
Reference-contexts: The details of the calculation and statistical properties of the least-squares estimator can be found in <ref> (Hsia, 1977) </ref>. The main problem to compute (2.19) is that the estimation can fail if one or more of the M equations is a linear combination of the others or if all equations contain certain variables in exactly the same linear combination (see (Press et al., 1992) for further details).
Reference: <author> Hunt, K. J. and T. A. </author> <title> Johansen (1996). Adaptive local controller networks. </title> <note> In preparation. </note>
Reference: <author> Hunt, K.J., D. Sbarbaro, R. Zbikowski and P.J. </author> <month> Gawthrop </month> <year> (1992). </year> <title> Neural networks for control systems-a survey. </title> <type> Automatica 28(6), </type> <pages> 1083-1112. </pages>
Reference-contexts: The important non-linear diversity is the primary reason why no systematic and generally applicable theory for non-linear control design has yet evolved. It is the ability of neural networks to model non-linear systems which is the feature to be most readily exploited in the synthesis of non-linear controllers <ref> (Hunt et al., 1992) </ref>. "A connectionnist model (i.e. artificial neural network) consists of many interconnected, autonomous basic elements. Each of these elements itself only has a simple function. Complex functions are obtained as emergent behaviour of the dynamic interactions of the simple elements" (Happel and Murre, 1994). <p> SINGLE NEURAL NETWORKS FOR CONTROL 15 method to develop a neuro-controller involved trying to replicate a human controller. (Widrow and Smith, 1964) applied this technic to control the inverted pendulum. This can be useful for plants controlled by humans for which it is difficult to design a standard controller <ref> (Hunt et al., 1992) </ref>. The neural training consists simply of learning the mapping between the sensory information received by the human controller and the control input (see figure 1.4).
Reference: <author> Jacobs, R.A. and M.I. </author> <title> Jordan (1991). A competitive modular connectionist architecture. In: Neural Information Processing Systems 3 (Lippman and al., </title> <editor> Eds.). </editor> <volume> Vol. </volume> <pages> 3. </pages>
Reference: <author> Jacobs, R.A. and M.I. </author> <title> Jordan (1993). Learning piecewise control strategies in a modular neural network architecture. </title> <journal> IEEE Transaction on Systems, Man, and Cybernetics 23(2), </journal> <pages> 337-345. </pages>
Reference-contexts: The use of multiple models to control non-linear systems has had a long history starting with gain scheduling (see for instance (Shamma and Athans, 1990)) and going through the concept of partitioning (Lainiotis, 1976a; Lainiotis, 1976b) to more recent ideas of Modular Neural Networks <ref> (Jacobs and Jordan, 1993) </ref>, Local Model Networks (Johansen and Foss, 1992; Johansen and Foss, 1993), and Multiple Switched Models (MSM) (a review and recent results appear in references (Narendra et 1 2 al., 1995; Narendra and Balakrishan, 1997). Control theory is well developed and understood for linear systems. <p> These are important restrictions of the usefulness of this algorithm. It is difficult to use this scheme for control purposes as we can not easily design controllers out of the unclear modular representations. Note however that this algorithm has been used in <ref> (Jacobs and Jordan, 1993) </ref> to develop an inverse controller of a two joint robot's arm using the method of (Kawato et al., 1987) described earlier. The use of "linear in parameters functions" (e.g. polynomial functions) as expert and gating networks could be used to avoid the above drawbacks. <p> This is however a common feature with another neural network which also applies a gating approach to select different computing modules at each instant: the "Hierarchical Mixture of Experts" algorithm developed by <ref> (Jacobs and Jordan, 1993) </ref> and extensively described in chapter 1. 3.4.3 Illustration In order to illustrate the capability of the INC associated to the CCN we will consider the control of the first order system (3.1) used in the first section of this chapter.
Reference: <author> Jacobs, R.A., M.I. Jordan and A.G. </author> <title> Barto (1991a). Task decomposition competition in a modular connectionist architecture: The what and where vision tasks. </title> <booktitle> Cognitive Science 15, </booktitle> <pages> 219-250. </pages>
Reference: <author> Jacobs, R.A., M.I. Jordan, S.J. Nowlan and G.E. </author> <title> Hinton (1991b). Adaptive mixture of local experts. </title> <booktitle> Neural Computation pp. </booktitle> <pages> 79-87. </pages>
Reference: <author> Johansen, T. A. and B. A. </author> <title> Foss (1992). A narmax model representation for adaptive control based on local model. Modeling, Identification, </title> <booktitle> and control 13(1), </booktitle> <pages> 25-39. </pages>
Reference: <author> Johansen, T. A. and B. A. </author> <title> Foss (1993). Constructing NARMAX models using ARMAX models. </title> <booktitle> Int. </booktitle>
Reference-contexts: Simple local models are used to describe the system within each region. A global model is formed by interpolating the local models using interpolation functions w, depending on the operating condition <ref> (Johansen and Foss, 1993) </ref>. An important advantage of this method is the facility to transform the LMN into a local controller network. <p> GATED MODULAR NEURAL NETWORKS FOR SYSTEM MODELLING AND CONTROL29 * There are proofs of theoretical capabilities to approximate any functions (Park and Sandberg, 1991). In addition, it has been established in <ref> (Johansen and Foss, 1993) </ref> that the LMN can uniformly approximate a NARMAX function (1.4) given a sufficient number of local models. * It is possible to introduce a priori knowledge in the LMN by using different sorts of local models and by determining the operating regions of each model. * Weak <p> This is to avoid the normalisation of the clustering space (as it is achieved when applying the local models network or local controller network (see for instance <ref> (Johansen and Foss, 1993) </ref>). The parameter ff in the variable p is the coefficient that drives the sharpness of the sigmoid. ff = 10 was used in this study, which leads to the sigmoid shape depicted in figure 3.8. <p> The INC is used for the construction of the architecture of these two controller networks. Further details regarding these algorithms are provided in chapter 3 of this thesis. 4.2.1 Clustered Controller Network The CCN is a simplified version of the LCN <ref> (Johansen and Foss, 1993) </ref>. It is composed of linear controllers (see figure 4.1). It performs a clustering of a single order operating space in order to select the controller (s) that are going to be used for controlling the system at a certain operating condition. <p> This is to avoid to normalise the clustering space (as it is achieved when applying the Local Controller Network (see for instance <ref> (Johansen and Foss, 1993) </ref>)). The parameter ff in the variable p is the coefficient that drives the sharpness of the sigmoid.
Reference: <author> J. </author> <booktitle> Control 58, </booktitle> <pages> 1125-1153. </pages>
Reference: <author> Johansen, T. A. and B. A. </author> <title> Foss (1995). Identification of non-linear system structure and parameters using regime decomposition. </title> <type> Automatica 31(2), </type> <pages> 321-326. </pages>
Reference: <author> Jones, R. D. and al. </author> <year> (1991). </year> <title> Nonlinear adaptive networks: A little theory, a few applications. </title> <type> Technical Report 91-273. </type> <institution> Los Alamos National Lab, NM. </institution>
Reference: <author> Jordan, M.I. and R.A. </author> <title> Jacobs (1994). Hierarchical mixtures of experts and the em algorithm. </title> <booktitle> Neural Computation 6, </booktitle> <pages> 181-214. </pages>
Reference-contexts: Rather than a spatial clustering approach a very interesting criteria has been used by Jacobs and Jordan when they conceived the "Adaptive Mixture of Experts" (AME) (Jacobs et al., 1991b; Jacobs and Jordan, 1991; Jacobs et al., 1991a) (see figure 1.18) and further improved it in <ref> (Jordan and Jacobs, 1994) </ref> using the EM algorithm to enable a self-hierarchical decomposition of the problem. The idea involves gating the input vectors according to the approximation (learning) capability of each module. Two types of systems are used that are both multi-layer perceptron neural networks.
Reference: <author> Jordan, Michael I. and David E. </author> <title> Rumelhart (1992). Forward models: Supervised learning with a distal teacher. </title> <journal> Cognitive Science pp. </journal> <pages> 307-354. </pages>
Reference-contexts: Indeed this method can not be generalised to many systems. Back-propagation through time neuro-control learning To avoid the problem of the specialised inverse control learning a number of researchers (Nguyen and Widrow, 1990; Narendra and Parthasarathy, 1990; Jordan and Rumelhart, 1992) have independently developed the "back-propagation through time" <ref> (Jordan and Rumelhart, 1992) </ref> neuro-control leaning method. The problem of the specialised inverse control learning is that the performance error 1.2. SINGLE NEURAL NETWORKS FOR CONTROL 17 e y = r y is not reliable because it is not directly related to the neuro-controller output u. <p> However the use of the system output should give better results. For instance the use of the system output can produce an exact inverse even when the forward model is inexact; this is not the case when the forward model is used <ref> (Jordan and Rumelhart, 1992) </ref>. The approach studied by (Narendra and Parthasarathy, 1990) and latter by (Gomi and Kawato, 1993) was slightly different from the one just discussed.
Reference: <author> Karmiloff-Smith, </author> <title> Annette (1994). Precis of beyond modularity: A developmental perspective on cognitive science. </title> <booktitle> Behavioral and Brain Sciences 17, </booktitle> <pages> 693-745. </pages>
Reference: <author> Kawato, M., K. Furukawa and R. </author> <title> Suzuki (1987). Forward models: Supervised learning with a distal teacher. </title> <journal> CBiological Cybernetics pp. </journal> <month> 169-185. </month> <title> 128 BIBLIOGRAPHY Kawato, Mitsuo (1989). Adaptation and learning in control of voluntary movement by the central nervous system. </title> <booktitle> Advanced Robotics 3(3), </booktitle> <pages> 229-249. </pages>
Reference-contexts: Note however that this algorithm has been used in (Jacobs and Jordan, 1993) to develop an inverse controller of a two joint robot's arm using the method of <ref> (Kawato et al., 1987) </ref> described earlier. The use of "linear in parameters functions" (e.g. polynomial functions) as expert and gating networks could be used to avoid the above drawbacks. This possibility was not explored in this thesis.
Reference: <author> Keele, Steven W., Peggy Jennings, Steven Jones, David Caulton and Asher Cohen (1995). </author> <title> On the modularity of sequence representation. </title> <journal> Journal of Motor Behavior 27(1), </journal> <pages> 17-30. </pages>
Reference: <author> Kohonen, T. </author> <year> (1982). </year> <title> Self-organized formation of topologically correct feature maps. </title> <booktitle> Biological Cybernetics 43, </booktitle> <pages> 59-69. </pages>
Reference-contexts: However a real resurgence of this field started in the eighties with the work on recurrent neural network done by Hopfield (Hopfield, 1982) and the model of self-organising map developed by Kohonen <ref> (Kohonen, 1982) </ref>. A strong impulse to the connexionnist models was given in 1986 when (Rumulhart and McClelland, 1986; LeCun, 1987) rediscovered the back-propagation learning algorithm developed in first place by (Werbos, 1974). <p> Note that this neighbour relationship between rbfs leads to an architecture that could be related to a Kohonen's neural network (see <ref> (Kohonen, 1982) </ref> for details about this neural network). Now, by relating a different controller to each rbf we end up with a Clustered Controller Network (CCN) (see figure 3.6). Since at each instant only two rbfs are selected, the two controllers attached to those rbfs are activated as well.
Reference: <author> Lainiotis, D.G. </author> <year> (1976a). </year> <title> Partitioning: A unifying framework for adaptive systems. I. estimation. </title> <booktitle> Proc. IEEE 64, </booktitle> <pages> 1126-1143. </pages>
Reference: <author> Lainiotis, D.G. </author> <year> (1976b). </year> <title> Partitioning: A unifying framework for adaptive systems. II. control. </title> <booktitle> Proc. IEEE 64, </booktitle> <pages> 1182-1197. </pages>
Reference: <author> Lancaster, Peter and Kestutis Salkauskas (1986). </author> <title> Curve and Surface Fitting: An Introduction. </title> <publisher> Academic press, Harcourt Brace Jovanovich. </publisher>
Reference-contexts: The interpolation between points is catastrophic for the polynomial function of order 12 (see graph "Poly12 approximation"). In addition to this oscillation problem, when the functions to be identified are not smooth, polynomial functions are not really suitable for the modelling. Hence, as emphasised by <ref> (Lancaster and Salkauskas, 1986) </ref>, it is much more efficient to use piecewise polynomial functions of low order to obtain an accurate and flexible fit of an unknown function, rather than trying to find a single polynomial func tion fitting the data.
Reference: <author> Lapedes, A. and R. </author> <title> Farber (1987). How neural nets work. </title> <booktitle> In: Neural Information Processing Systems (Anderson, Ed.). </booktitle> <pages> pp. 442-456. </pages> <institution> New-York: American Institute of Physics. </institution>
Reference: <author> LeCun, I. </author> <year> (1987). </year> <title> Modeles connexionnistes de l'apprentissage. </title> <type> PhD thesis. </type> <institution> Universite Paris VI. Paris, France. </institution>
Reference: <author> Luenberg, David G. </author> <year> (1979). </year> <title> Introduction to Dynamic Systems. </title> <publisher> John Wiley and Sons. </publisher>
Reference: <author> Martinez, D. </author> <year> (1992). </year> <title> OFFSET: une methode de construction incrementale de reseaux de neurones multicouche et son application a la conception d'un autopilote automobile.. </title> <type> PhD thesis. </type> <institution> Universite Paul Sabatier. Toulouse, France. </institution>
Reference-contexts: CONTROL 1.3 Gated modular neural networks for system modelling and con trol "The challenge of the next generation of neural networks is not learning by individual weight updating, but the composing of network modules and how to resolve the competi tion" and the cooperation "of the different modules" (Muhlenbein in <ref> (Martinez, 1992) </ref>). Embedding modularity into Neural Networks (NN) gives many advantages over the use of single NN (see below and for further details (Ronco and Gawthrop, 1995)). "Modular Neural Network" (MNN) refers here to a network performing a local computation of the information.
Reference: <author> McCulloch, W.S. and W. </author> <title> Pitts (1943). A logical calculus of the ideas immanent in nervous activity. </title> <journal> Bulletin of Mathematical Biophysics 5, </journal> <pages> 115-133. </pages>
Reference-contexts: Each of these elements itself only has a simple function. Complex functions are obtained as emergent behaviour of the dynamic interactions of the simple elements" (Happel and Murre, 1994). The first attempt to build such a computing system was made by <ref> (McCulloch and Pitts, 1943) </ref> in 1943. They developed an analogous system composed of interconnected simple computing units based on the model of a neuron. This algorithm was revised some twenty years later by (Rosenblatt, 1960; Widrow and Hoff, 1960). They respectively called their algorithm "perceptron" and "adaline".
Reference: <author> Middleton, R. H., G. C. Goodwin, D. J. Hill and D. Q. </author> <title> Mayne (1988). Design issues in adaptive control. </title> <booktitle> IEEE Transaction on Automatic Control 33(1), </booktitle> <pages> 50-58. </pages>
Reference-contexts: Thus the selection of the controller according to the modelling error is feasible. This idea has been used by (Narendra et al., 1995; Narendra and Balakrishan, 1997) to develop the "multiple switched models" (MSM) scheme. However, such a multiple controllers scheme was prior introduced by <ref> (Middleton et al., 1988) </ref> and further extended in (Morse, 1990; Morse et al., 1992; Weller and Goodwin, 1994) and coined as the "hysteresis switching algorithm". <p> The control version of the LMN is the "Local Controller Network" (LCN). The idea underlying the other network was introduced in <ref> (Middleton et al., 1988) </ref> and further extended in (Morse, 1990; Morse et al., 1992; Weller and Goodwin, 1994) and coined as the "hysteresis switching algorithm". <p> INCREMENTAL MODEL-CONTROLLER NETWORK 77 activated to determine their performance. This actually implies far more computations than the selection of the controller using the clustering approach described in the previous section. Note that the "hysteresis" feature, introduced in <ref> (Middleton et al., 1988) </ref> and use also in the MSM, is not involved in the MCN. The hysteresis is a time delay between the selection of a new controller and its activation. This is to avoid instability that could arise from a quick change of controllers. <p> The control version of the LMN is the "Local Controller Network" (LCN). The concept underlying the other controller network has been introduced in <ref> (Middleton et al., 1988) </ref> and further extended in (Morse, 1990; Morse et al., 1992; Weller and Goodwin, 1994) and is know as the "hysteresis switching algorithm".
Reference: <author> Middleton, Richard H. and Graham C. </author> <title> Goodwin (1990). Digital control and estimation: a unified approach. </title> <publisher> Prentice-Hall, Inc. </publisher>
Reference-contexts: There are other ways of modelling a discrete time system. However, most of the discrete time models have a very undesirable feature that argues for prohibiting their use while dealing with continuous time systems: such a model is heavily dependent on the sampling interval <ref> (Middleton and Goodwin, 1990) </ref>. These authors have shown that moreover, as ! 0, the significant poles and zeros of the discrete time model converge to the point i + j0 independently of the underlying systems. <p> The demonstration of this phenomena requires several notions that will not be used in the reminder of this thesis. Hence I suggest to the reader interested in the demonstration is refered to <ref> (Middleton and Goodwin, 1990) </ref>. However, to illustrate this limitation affecting discrete time models a more intuitive approach is proposed. Let us consider an arbitrary first order continuous time system described by the following differential equation: 2.2. <p> Note that Middleton and Goodwin propose an alternative approach which is the "ffi modelling". This apporach has not been sufficiently investigated to expose it here, thus the reader should refer to <ref> (Middleton and Goodwin, 1990) </ref> for details. The second problem of (2.8) is vital. This equation assumes that the system states are available. In practice there are always disturbances affecting the system and the system output is often the only measurable state variable.
Reference: <author> Miikkulainen, R. and M.G. </author> <title> Dyer (1991). Natural language processing with modular pdp networks and distributed lexicon. </title> <booktitle> Cognitive Science 15, </booktitle> <pages> 343-399. </pages>
Reference-contexts: The learning procedure implies two stages. First, the centre of each partition is found by unsupervised learning. Following this stage, a supervised learning is used to train the models connected to each partitioning unit. A similar method to automaticly cluster the input space but using more sophisticated models (see <ref> (Miikkulainen and Dyer, 1991) </ref>) consists of using a Kohonen algorithm to cluster the input space and then connect to each local region a NN.
Reference: <author> Miller, W. T., R. S. Sutton and P. J. </author> <title> Werbos (1990). Neural Networks for Control. </title> <publisher> MIT Press. </publisher> <address> Cambridge, Massachusetts. </address>
Reference-contexts: However this leads as well to a system inverse based neuro-controller since this is the desired output y that drives the neuro-controller. Biological control and neuro-control based on system inverse Neuro-control methods based on system inverse, although applied, mostly in robotics (see for some examples <ref> (Miller et al., 1990) </ref>), have serious drawbacks. The most important concerns the lack of feedback. If the neuro-controller is not a true inverse model of the system this can lead to control 18 CHAPTER 1. NEURAL NETWORKS FOR MODELLING AND CONTROL inconsistency which can not be overcome without feedback.
Reference: <author> Mills, P. M., A. Y. Zomaya and M. O. </author> <month> Tade </month> <year> (1994). </year> <title> Adaptive model-based control using neural networks. </title> <journal> International J. Control 60, </journal> <pages> 1163-1192. </pages>
Reference: <author> Minski, </author> <title> M.L. and S.A. Papert (1969). Perceptron. </title> <publisher> MIT press. </publisher> <address> Cambridge, MA. </address>
Reference-contexts: They respectively called their algorithm "perceptron" and "adaline". Their major contribution concerns the implementation of a learning rule based on the minimisation of the quadratic approximation error. A total blackout occurred several years later as <ref> (Minski and Papert, 1969) </ref> demonstrated the very poor mapping potential of these algorithms. Note that at this period the machine of Turing (i.e. the sequential computer with located memory and so on) was seen as the model of the brain.
Reference: <author> Monrocq, C. </author> <year> (1993). </year> <title> A probabilistic approach which provides a modular and adaptive neural network architecture for discrimination. </title> <booktitle> In: Third International Conference on Artificial Neural Networks. </booktitle> <volume> Vol. 372. </volume> <pages> pp. 252-256. </pages>
Reference: <author> Moody, J. and C. </author> <month> Darken </month> <year> (1989). </year> <title> Fast-learning in networks of locally-tuned processing units. </title> <booktitle> Neural Computation 1, </booktitle> <pages> 281-294. </pages> <note> BIBLIOGRAPHY 129 Morse, </note> <author> A. S. </author> <year> (1990). </year> <title> Toward a unified theory of parameter adaptive control-tunability. </title> <booktitle> IEEE Transaction on Automatic Control 35(9), </booktitle> <pages> 1002-1012. </pages>
Reference-contexts: A similar method to automaticly cluster the input space but using more sophisticated models (see (Miikkulainen and Dyer, 1991)) consists of using a Kohonen algorithm to cluster the input space and then connect to each local region a NN. In <ref> (Moody and Darken, 1989) </ref> the centres of the RBFs are also placed using a self-organising method. (Roberts and Tarassenko, 1994) proposed a constructive method to develop the LMN structure.
Reference: <author> Morse, A. S., D. Q. Mayne and G. C. </author> <title> Goodwin (1992). Applications of hysteresis switching in parameter adaptive control. </title> <booktitle> IEEE Transaction on Automatic Control 37(9), </booktitle> <pages> 1343-1354. </pages>
Reference: <author> Mountcastle, Vernon B. </author> <year> (1978). </year> <title> An organizing principle for cerebral function: The unit module and the distributed system. In: The Mindfull Brain (Edelman and Mountcastle, </title> <editor> Eds.). </editor> <publisher> MIT press. </publisher>
Reference-contexts: This definition is certainly loose but because currently there is no real definition of a MNN, this is the one adopted in this study (for a discussion about this issue see (Ronco and Gawthrop, 1995)). Modularity is a natural way to ease the learning of complex behaviour. Mountcastle <ref> (Mountcastle, 1978) </ref> and many others (Karmiloff-Smith, 1994; Houk and Wise, 1995; Carpenter, 1984) argue that modularity is a brain organising principle. (Feldman, 1989) and (Simon, 1981) highlight the fact that a complex behaviour requires the bringing together of several different kinds of knowledge and processing, which is not possible without structure
Reference: <author> Mure, J.M.J., R.H. Phaf and G. </author> <title> Wolters (1992). Calm: Categorizing and learning module. Neural Networks 5, 55-82. Murray-Smith, Roderick (1994). A Local Model Network Approach to Nonlinear Modelling. </title> <type> PhD thesis. </type> <institution> Dept. of Computer Science: U. of Strathclyde. </institution> <address> Glasgow, Scotland, UK. Murray-Smith, </address> <month> Roderik. </month> <title> and Henrik Gollee (1994). A constructive learning algorithm for local model networks. </title> <booktitle> In: IEEE Worshop on Computer-intensive methods in control and signal processing. </booktitle> <pages> pp. 21-29. </pages>
Reference-contexts: Some self-organising methods to cluster the input space have been developed. The operating space is partitioned using a binary tree approach in (Stoelting, 1990). A more sophisticated approach can be found in the model developed by <ref> (Mure et al., 1992) </ref>. This model is named "CALM" for Categorising And Learning Module. A CALM module tends to autonomously cluster stimuli belonging to the same region by way of inhibitory connections between neurons involving competition in the CALM module.
Reference: <author> Narendra, K. S. and J. </author> <month> Balakrishan </month> <year> (1997). </year> <title> Adaptive control using multiple models. </title> <journal> IEEE transactions on Automatic Control 42(2), </journal> <pages> 171-187. </pages>
Reference-contexts: The use of instantaneous and long term measures of the modelling error makes this index a reliable estimate modelling performance <ref> (Narendra and Balakrishan, 1997) </ref>. <p> This small "parametric distance" ensures a fast adaptation. Hence, this scheme enables the overall controller to handle fast changes in the plant whilst ensuring a small steady state error. This scheme has another fundamental advantage. The authors have studied and proved the stability properties of the overall network <ref> (Narendra and Balakrishan, 1997) </ref>. If all the models are adaptive the overall system is stable provided a small and fixed interval is allowed between switches. If all the models are fixed the stability can be achieved if at least one model is sufficiently close to the plant. <p> This stability is therefore highly dependent on the modelling accuracy that cannot be ensured. However, the use of fixed models and one adaptive model (reinitialisable or not) ensures overall stability. Hence, this compromise yields again very desirable properties. In <ref> (Narendra and Balakrishan, 1997) </ref> it is shown also that the number and locations of the models in the operating space must be related to the "sensitivity region" (i.e. the region where the models and plant parameters differ the most) and not be uniformly distributed. <p> The modelling performance index used to select the controllers is much simpler than the one used in the MSM. Another difference is that in the MCN all the model-controller pairs are adaptive. Referring to the stability results obtained and described in <ref> (Narendra and Balakrishan, 1997) </ref>, an important advantage of this scheme is the insurance of stability. However one must be careful with this result.
Reference: <author> Narendra, K. S. and K. </author> <title> Parthasarathy (1990). Identification and control of dynamic systems using neural networks. </title> <journal> IEEE Transactions on Neural Networks 1, </journal> <pages> 4-27. </pages>
Reference-contexts: For instance the use of the system output can produce an exact inverse even when the forward model is inexact; this is not the case when the forward model is used (Jordan and Rumelhart, 1992). The approach studied by <ref> (Narendra and Parthasarathy, 1990) </ref> and latter by (Gomi and Kawato, 1993) was slightly different from the one just discussed. A reference model was injected into the structure to give a desired transient system output y rather than a simple desired output r not varying with time (see figure 1.9).
Reference: <author> Narendra, Kumpati S., Jeyendran Balakrishnan and Kemal M. </author> <month> Ciliz </month> <year> (1995). </year> <title> Adaptation and learning using multiple models, switching, and tuning. </title> <journal> IEEE Control Systems 3, </journal> <pages> 37-51. </pages>
Reference-contexts: Hence, this scheme implies the selection of only one controller at each instant The authors show, according to control simulations of linear plants having their parameters changing abruptly over time, that the model-controller pairs should not all be fixed or adaptive <ref> (Narendra et al., 1995) </ref>. On one hand fixed controllers are computationally more efficient than adaptive ones since adaptation implies intensive computation at each instant. Moreover an adaptive controller has difficulty to cope with abrupt changes in the plant (e.g. external disturbances, variation of the system 32 CHAPTER 1. <p> On the other hand a very large number of fixed models could be required to achieve desired control performances (e.g. small steady state error) where only one adaptive controller could suffice. Hence, the best compromise according to the authors <ref> (Narendra et al., 1995) </ref> is the use of fixed models and one or few adaptive models that can be reinitialised to fit the currently selected controller. <p> This algorithm is constructive and shares very similar features with the one developed in this thesis (see chapter 3). The idea is to add a new adaptive model-controller pair as soon the control error exceeds a certain threshold. During a simulation reported in <ref> (Narendra et al., 1995) </ref> this method leaded to an optimum placement and determination of the required number of model-controller pairs. So far, the multiple switched model control capability has been discussed in the context of linear systems. Surprisingly the authors are not using linear models to deal with non-linear systems. <p> Surprisingly the authors are not using linear models to deal with non-linear systems. Instead they use Multi-Layer Perceptron (MLP) as model-controller pairs. Although they highlighted positive features of the MLP this network should not be suitable in the context of control due at least to its unclear function representation. <ref> (Narendra et al., 1995) </ref> themselves highlight a serious weakness of the MLP as an adaptive algorithm. <p> Otherwise a linear controller is required to stabilise the system and therefore the MLP can only be used to improve performance <ref> (Narendra et al., 1995) </ref>. In brief, the multiple model switched scheme has proved to be capable of handling plants with abrupt or rapid changes of parameters value. This method is not sensitive to the input space dimension as the gating system is clustering free. <p> The use of linear in parameters modules could overcome these two problems. The idea of using the module performances for their own gating has been further extended in the "multiple switched models" <ref> (Narendra et al., 1995) </ref>. The idea is to use the performance of various models to select their connected controllers. The gating is therefore clustering free and thus does not 34 CHAPTER 1. <p> By adapting the linear controller to changes in parameters due to system's non-linearity we wish to improve the control performance. To be efficient this method requires the parameters changes to be rather slow <ref> (Narendra et al., 1995) </ref>. Moreover, since the controller must have some initial values during the first control steps, prior the 2.5. <p> The LCN and MSM are not exposed to this dilemma because each model-controller is specially adapted for a different operating region of the system. Hence, and as highlighted by <ref> (Narendra et al., 1995) </ref>, these two schemes can be adapted for different discontinuities of the system. However, to make the LCN and MSM self-organising requires a general and systematic method to automatically construct their network architecture. <p> Such a method can only be effective if the dynamics of the system are changing smoothly and quite slowly through time. Therefore, if the function is discontinuous adaptive control can not be applied. In addition, the slowness of such an adaptation may result in a large transient error <ref> (Narendra et al., 1995) </ref>. This is illustrated in figure 3.2. The adaptive controller has been preadapted from a linearisation of the system around y = 0 (see left bottom plot of this figure). Hence the controller performs well in the operating region where the linearisation is valid. <p> INCREMENTAL CONTROLLER NETWORKS necessary to be implemented to control real systems. By removing the INC one makes the MCN entering a generalisation stage. Note also that a technique similar to the INC is reported in <ref> (Narendra et al., 1995) </ref>. However, their method contains no pruning feature. <p> Such a method can only be effective if the dynamics of the system are changing smoothly and quite slowly through time. If the function is discontinuous, adaptive control cannot be applied. In addition, the slowness of such an adaptation may result in a large transient error <ref> (Narendra et al., 1995) </ref>. A more serious problem is the basic design problem for learning machines emphasised by (Carpenter and Grossberg, 1988): the "stability-plasticity dilemma". While the controller is adapting to an operating region of the system it is forgetting previous adaptations concerning other regions. <p> Another advantage of these algorithms is that they do not suffer from the "stability-plasticity dilemma". These two approaches are not exposed to this dilemma because each model-controller is specially adapted for a different operating region of the system. Hence, as highlighted by <ref> (Narendra et al., 1995) </ref>, the LMN and MSM can be adapted for the control of a non-linear discontinuous system.
Reference: <author> Nguyen, D. H. and B. </author> <title> Widrow (1990). Neural Networks for Self-learning Control Systems. </title> <journal> IEEE Control Systems Magazine 10, </journal> <pages> 18-23. </pages>
Reference: <author> Norman, S. </author> <month> Nise </month> <year> (1995). </year> <title> Control Systems Engineering. </title> <publisher> The Benjamin/Cummings Publishing Company, Inc. </publisher>
Reference: <author> Nowlan, S.J. Hinton, G.E. </author> <year> (1991). </year> <title> Evaluation of adaptive mixtures of competing experts. </title> <booktitle> In: Neural Information Processing Systems 3 (Lippmann, Ed.). </booktitle> <volume> Vol. 3. </volume> <booktitle> Omatu, Sigeru, Marzuki Khalid and Rubiyah Yussof (1990). Neuro-Control and its Applications. </booktitle> <publisher> Springer. </publisher>
Reference: <author> Ortega, J. Gomez and Camacho E.F. </author> <year> (1996). </year> <title> Mobile robot navigation in a partially structured static environment, using neural predictive control. </title> <journal> Control Engineering Practice 4(12), </journal> <pages> 1669-1679. </pages>
Reference-contexts: This gives a neuro-model based predictive controller corresponding to figure 1.11. Neural network could be used as well as a controller. For instance, in <ref> (Ortega and E.F., 1996) </ref>, a neural network is used to implement the cost function and hence increase the computing speed for a robotics path tracking problem.
Reference: <author> Park, J. and I.W. </author> <title> Sandberg (1991). Universal approximation using radial-basis-function networks. </title> <booktitle> Neural Computation 3, </booktitle> <pages> 246-257. </pages>
Reference-contexts: GATED MODULAR NEURAL NETWORKS FOR SYSTEM MODELLING AND CONTROL29 * There are proofs of theoretical capabilities to approximate any functions <ref> (Park and Sandberg, 1991) </ref>.
Reference: <author> Park, M. G. and N. Z. </author> <title> Cho (1995). Self-tuning control of a nuclear-reactor using a gaussian function neural-network. </title> <booktitle> Nuclear Technology 110, </booktitle> <pages> 285-293. </pages>
Reference: <author> Platt, J. </author> <year> (1991). </year> <title> A resource-allocating network for function interpolation. </title> <booktitle> Neural Computation 3, </booktitle> <pages> 213-225. </pages>
Reference-contexts: However, to achieve the best clustering implies taking into account the approximation capability of the local models. Thus, clustering and local model identification should not be separated but rather be an interactive process. An early attempt at doing this was carried out by <ref> (Platt, 1991) </ref>. He proposed to add a new model when a pattern presented to the LMN caused an error larger than a given threshold. This does not resolve the problem of determining the region of activity of each local model which is vital especially whilst applying local learning.
Reference: <author> Poggio, T. and F. </author> <title> Girosi (1990). Networks for approximation and learning. </title> <booktitle> Proceedings of the IEEE 78, </booktitle> <pages> 1481-1497. </pages>
Reference-contexts: Therefore the non-linear overall model developed by those networks can be easily transformed into a non-linear controller. This is perhaps the only general and systematic approach to designing a non-linear controller out of a non-linear model. One of these neural networks is the "Local Model Network" (LMN) introduced in <ref> (Poggio and Girosi, 1990) </ref> and further extended for modelling and control purposes by (Johansen and Foss, 1993; Jo-hansen and Foss, 1992). The control version of the LMN is the "Local Controller Network" (LCN). <p> This is closely related to the control strategy known as gain scheduling. There are a couple of algorithms that have been recently developed for this purpose. One of them is the "Local Model Network" (LMN) introduced in <ref> (Poggio and Girosi, 1990) </ref> and further extended for modelling and control purposes by (Johansen and Foss, 1993; Johansen and Foss, 1992). The control version of the LMN is the "Local Controller Network" (LCN).
Reference: <author> Powell, M. J. D. </author> <year> (1987). </year> <title> Radial basis functions for multivariable interpolation: a review. </title> <booktitle> In: Algorithms for approximation. </booktitle> <pages> pp. 143-167. </pages> <publisher> Clarendon, press. 130 BIBLIOGRAPHY Press, </publisher> <editor> William H., Saul A. Teukolsky, William T. Vetterling and Brian P. </editor> <booktitle> Flannery (1992). NUMERICAL RECIPIES in C. 2 ed.. </booktitle> <publisher> Cambridge University Press. </publisher>
Reference-contexts: Note that the LMN is a generalisation of the basis function neural network <ref> (Powell, 1987) </ref> that was developed in first place for classification purposes. Moreover it has very close connections to the fuzzy model developed by (Takagi and Sugeno, 1985; Sugeno and Kang, 1986). 1.3.
Reference: <author> Psaltis, D., A. Sideris and A. A. </author> <title> Yamamura (1988). A multilayered neural network controller. </title> <journal> IEEE Control Systems Magazine 8, </journal> <pages> 17-21. </pages>
Reference-contexts: The main difficulty in applying this learning method is to choosing the training signal u. The system must be brought into the desired operating region where the controller will have to operate. This is difficult to achieve without strong a priori knowledge about the system. Specialised inverse neuro-control learning <ref> (Psaltis et al., 1988) </ref> proposed a "specialised inverse learning". This is a goal directed neuro-control approach. This feature is the fundamental difference between specialised inverse learning and direct inverse learning. The network is trained on-line in order to minimise the control performance e y = ry (see figure 1.7). <p> It is so because e y is not directly related to the model output as it should be. Hence, e y can be totally uncorrelated to the relevant neuro-controller learning performance e u = u u. The error can be of inverse sign or of a completely different magnitude. <ref> (Psaltis et al., 1988) </ref> argue that to apply this method the Jacobian of the process is necessary. However it seems that even a crude approximation of the error e u can allow convergence of the neuro-controller learning.
Reference: <author> Reilly, D.L., L.N. Cooper and Elbaum C. </author> <year> (1982). </year> <title> A neural model for category learning. </title> <booktitle> Biological Cybernetics 45, </booktitle> <pages> 35-41. </pages>
Reference-contexts: Although some euristics are used to speed this decomposition process it is clear that it is highly computation demanding. It is therefore not suitable for online modelling/control purposes. The algorithm conceived by Relly, Cooper and Elbaum, the RCE <ref> (Reilly et al., 1982) </ref>, is interesting for on-line decompositions purposes. It was developed some 15 years ago for binary classification purposes. This algorithm is somehow only a gating system but capable of non-convex clustering. This gating system is a feed-forward network composed of two different unit layers (see figure 1.16).
Reference: <author> Roberts, S. and L. </author> <month> Tarassenko </month> <year> (1994). </year> <title> A probalistic resource allocating network for novelty detection. </title> <booktitle> Neural Computation 6, </booktitle> <pages> 270-284. </pages>
Reference-contexts: In (Moody and Darken, 1989) the centres of the RBFs are also placed using a self-organising method. <ref> (Roberts and Tarassenko, 1994) </ref> proposed a constructive method to develop the LMN structure. They add a new model whenever an input occurs which is not near the centre of any of the RBFs' receptive fields.
Reference: <author> Ronco, </author> <title> Eric (1994). Apprentissage a complexite progressive dans les systemes connexionnistes. </title> <type> Master's thesis. </type> <institution> Institut National Polytechnique de Grenoble. Grenoble, France. </institution>
Reference: <author> Ronco, Eric and Peter J. </author> <month> Gawthrop </month> <year> (1995). </year> <title> Modular neural networks: a state of the art. </title> <type> Technical Report CSC-95026. </type> <institution> Centre for System and Control. Faculty of mechanical Engineering, University of Glasgow, Uk. </institution> <note> Available at www.mech.gla.ac.uk/~ericr/pub/surveyMNN.ps. </note>
Reference-contexts: Embedding modularity into Neural Networks (NN) gives many advantages over the use of single NN (see below and for further details <ref> (Ronco and Gawthrop, 1995) </ref>). "Modular Neural Network" (MNN) refers here to a network performing a local computation of the information. That is to say that only one part of the network is involved in computing each input vector. <p> That is to say that only one part of the network is involved in computing each input vector. This definition is certainly loose but because currently there is no real definition of a MNN, this is the one adopted in this study (for a discussion about this issue see <ref> (Ronco and Gawthrop, 1995) </ref>). Modularity is a natural way to ease the learning of complex behaviour. <p> The main issues to develop a MNN are the modular organisation in the network architecture and the decomposition of a task (problem, environment) into sub-tasks <ref> (Ronco and Gawthrop, 1995) </ref>. A sensible way to decompose a task is to do so according to the computation capability of the modules. In fact, the modules should also be built according to the task they would have to perform.
Reference: <author> Ronco, Eric and Peter J. </author> <month> Gawthrop </month> <year> (1996). </year> <title> Incremental linear controllers network. </title> <type> Technical Report CSC-96008. </type> <institution> Centre for system and control, U. of glasgow, UK. </institution> <note> (Available at www.mech.gla.ac.uk/~ericr/pub/ilcn pcd.ps.gz). </note>
Reference-contexts: If a controller is due to be adaptive for all its life time (indeed not indefinitely but hopefully for a significantly long period) this would certainly overload the computer's memory. To avoid this problem the method described in <ref> (Gawthrop and Ronco, 1996) </ref> has been applied here. This method can be thought of the SVD solution to the least error square of (2.22). <p> 6 6 6 6 6 6 6 6 6 6 4 s N y P odd 2 s N y 3 s N1 y P odd 2 s N1 y 3 y P odd ::: 3 7 7 7 7 7 7 7 7 7 7 7 7 7 Following <ref> (Gawthrop and Ronco, 1996) </ref>, to find ^ p , we minimise the mean squared error from time t t to time t given by: Z t ^e 2 dt = ^ pT S ^ p (4.15) where S = tt t dt (4.16) To avoid the trivial solution ^ p =
Reference: <author> Ronco, Eric and Peter J. </author> <month> Gawthrop </month> <year> (1997a). </year> <title> Gated modular neural networks for modelling and control. </title> <type> Technical Report CSC-97008. </type> <institution> Centre for system and control, U. of glasgow, UK. </institution> <note> (Available at www.mech.gla.ac.uk/~ericr/pub/gmnn.ps.gz). </note>
Reference-contexts: There are few modular networks that apply systematic methods to do so. Those modular neural networks use a gating system to dispatch the information to the adequate modules. <ref> (Ronco and Gawthrop, 1997a) </ref> refer to them as the "gated modular neural networks". In brief, there are two main types of neural networks. In one hand there are the single neural networks best represented by the MLP.
Reference: <author> Ronco, Eric and Peter J. </author> <month> Gawthrop </month> <year> (1997b). </year> <title> Incremental linear controllers network. </title> <booktitle> In: Proceeding of the American Control Conference (ACC'97). </booktitle> <address> Albuquerque, USA. </address>
Reference: <author> Ronco, Eric and Peter J. </author> <month> Gawthrop </month> <year> (1997c). </year> <title> Incremental model reference adaptive polynomial controllers network. </title> <type> Technical Report CSC-96008. </type> <institution> Centre for system and control, U. of glasgow, UK. </institution> <note> (Available at www.mech.gla.ac.uk/~ericr/pub/ipmracn.ps.gz). </note>
Reference-contexts: regression method such as the singular value decomposition (SVD) (see chapter 2 for details about this algorithm), it is possible to make a low order polynomial model (e.g. a cubic polynomial model) approximate any polynomial function of the same or lower order than its own (for some illustrative results see <ref> (Ronco and Gawthrop, 1997c) </ref>). For instance, whilst approximating a linear function, the singular value decomposition can deduce that only the parameters related to the first order polynomial terms are crucial. Hence, the other parameters are identified as zero.
Reference: <author> Ronco, Eric and Peter J. </author> <month> Gawthrop </month> <year> (1997d). </year> <title> Incremental model reference adaptive polynomial controllers network. </title> <booktitle> In: Proceeding of the IEEE Conference on Decision and Control (CDC'97). </booktitle> <publisher> (In Press). </publisher>
Reference: <author> Ronco, Eric and Peter J. Gawthrop (submitteda). </author> <title> Incremental model reference adaptive polynomial controllers network. </title> <journal> International Journal of Systems Science. </journal>
Reference: <author> Ronco, Eric and Peter J. Gawthrop (submittedb). </author> <title> Polynomial models network for system modelling and control. Neural Computing Survey. </title>
Reference: <author> Ronco, Eric, Henrik Gollee and Peter J. </author> <month> Gawthrop </month> <year> (1996a). </year> <title> Modular neural network and self decomposition. </title> <type> Technical Report CSC-96012. </type> <institution> Centre for system and control, U. of glasgow, UK. </institution> <note> Available at www.mech.gla.ac.uk/~ericr/pub/mnnsd.ps.Z. </note>
Reference-contexts: Similarly to the LMN, the selection of the controllers in the CCN is achieved through a clustering of the operating space. As discussed in <ref> (Ronco et al., 1996a) </ref> and extensively in the previous chapter, the use of radial basis functions (rbfs) for the clustering is most effective for single dimensional space. A compromise between approximation and clustering quality has to be found for clustering spaces of dimensions superior to one.
Reference: <author> Ronco, Eric, Peter J. Gawthrop and Mohamed Abderrahim (1996b). </author> <title> Progressive local control. </title> <booktitle> In: World Automatic Conference. </booktitle> <pages> pp. 637-642. </pages>
Reference: <author> Ronco, Eric, Peter J. Gawthrop and Yasmine Mather (1996c). </author> <title> Incremental modular controllers network. </title> <booktitle> In: Proceeding of the International Conference on Intelligent and Cognitive Systems (ICICS'96). </booktitle>
Reference: <author> Rosenblatt, F. </author> <year> (1960). </year> <title> Perceptron simulation experiments. In: Proceeding of the IRE. BIBLIOGRAPHY 131 Rueckl, J.G., K.R. Cave and Kosslyn S.M. (1989). Why are 'what' and 'where' processed by separate cortical visual systems? a computational investigation. </title> <journal> Journal of Cognitive Neuroscience 1, </journal> <pages> 171-186. </pages>
Reference: <author> Rumulhart, D.E. and J.L. </author> <title> McClelland (1986). </title> <booktitle> Parallel Distributed Processing. </booktitle> <volume> Vol. 1. </volume> <publisher> MIT press. </publisher> <address> Cambridge. </address>
Reference: <author> Rusnak, A., M. Fikar, K. Najim and A. </author> <month> Meszaros </month> <year> (1996). </year> <title> Generalized predictive control based on neural networks. </title> <booktitle> Neural Processing Letters 4, </booktitle> <pages> 107-112. </pages>
Reference-contexts: This idea has been generalised by (Clarke et al., 1987) to deal with plant with complex dynamics (e.g. unstable inverse systems, time-varying time delay, etc), and plant model mismatch <ref> (Rusnak et al., 1996) </ref>. (Clarke et al., 1987) coined this controller as the "generalised predictive control" (GPC). The GPC is the main design method of a model based predictive controller (MBPC). A MBPC is composed of three main components: the system, its model and a function optimiser (see figure 1.10).
Reference: <author> Sanger, Terence D. </author> <year> (1991). </year> <title> A tree-structured adaptive network for function approximation in high-dimensional spaces. </title> <booktitle> IEEE transaction on Neural Networks 2(2), </booktitle> <pages> 285-293. </pages>
Reference-contexts: Ideally we would wish to reduce a high order input space into a single dimensional one. Unfortunately there are many cases where this is not possible. Hence, the clustering of multi-dimensional input spaces appears to be the main issue to enable a systematic use of LMN. Note that <ref> (Sanger, 1991) </ref> reports a technique to reduce a n dimentional input space into separate lower dimensional spaces. The problem of this method is that it assumes that many quantities are uncoupled and redundant. This requirement should unfortunatly rarely be fulfilled.
Reference: <author> Sanner, R. M. and D. L. </author> <title> Akin (1990). Neuromorphic pitch attitude regulation of an underwater telerobot. </title> <journal> IEEE Control Systems Magazine 10, </journal> <pages> 62-67. </pages>
Reference: <author> Saridis, </author> <title> George N (1977). Self-Organizing control of stochastic systems. </title> <publisher> Marcel Dekker, Inc. </publisher>
Reference-contexts: This area, called self-organising control systems, has been originally defined to treat all systems with completely or partially unknown plant description" <ref> (Saridis, 1977) </ref>. This definition unfortunatly applies to most of the adaptive controllers. In this thesis this definition is extended.
Reference: <author> Schmidt, Richard A. </author> <year> (1982). </year> <title> Motor Control and Learning. Human Kinetics Publishers. </title> <institution> Champaign, Illinois. </institution>
Reference-contexts: For example the bat swing in hitting a baseball requires 100msec although 150-200msec seem to be required when information processing is involved. Other examples of insufficient time to perform a motor problem by high level system are given in <ref> (Schmidt, 1982) </ref>. In addition, (Schmidt, 1982) has shown, according to a review of experiences carried out on deafferented animals, that sensory feedback is not required to perform complex control tasks. <p> For example the bat swing in hitting a baseball requires 100msec although 150-200msec seem to be required when information processing is involved. Other examples of insufficient time to perform a motor problem by high level system are given in <ref> (Schmidt, 1982) </ref>. In addition, (Schmidt, 1982) has shown, according to a review of experiences carried out on deafferented animals, that sensory feedback is not required to perform complex control tasks. For instance (Taub, 1976) describes cases of deafferented monkeys that do not seem to be affected when climbing, swinging, eating, etc. <p> For instance (Taub, 1976) describes cases of deafferented monkeys that do not seem to be affected when climbing, swinging, eating, etc. In brief, closed loop system would be used to make action more precise but would not be the primary cause of it <ref> (Schmidt, 1982) </ref>. Closed loop system will be important when process is slow and regulation is important as for the homeostasis behaviour.
Reference: <author> Schwarzenbach, J. and K.F. </author> <title> Gill (1992). System Modelling and Control. </title> <publisher> Edward Arnold. </publisher>
Reference-contexts: Thus, assumption of system linearity has been made to develop a control theory on a solid basis. In reality most of the systems are non-linear. However many systems can be represented without significant loss of accuracy by an equivalent linear representation <ref> (Schwarzenbach and Gill, 1992) </ref>. Control design from system linearisation is a widely applied technique in the industry. The other systems, having their numbers drastically increasing, are characterised by complex non-linear dynamics (e.g. high non-linearity, fast parameter variations, external disturbances). <p> It is overdamped for other cases. Indeed, we would not wish to have any overshoot while controlling a system but often the reduction of the overshoots is at the expense of an increase of the settling time <ref> (Schwarzenbach and Gill, 1992) </ref>. * The insurance of stability and robustness. To be stable a system must have a natural response (i.e. the response of the system while no control input his affecting it) that decays to zero as time approaches infinity. <p> roots of the characteristic equation s 2 + 2!s + ! 2 = 0 (i.e. the poles of the reference model) where A 1 = 1 2 p , A 2 = 1 2 2 1 p 1 = ! + 2 1 and p 2 = ! 2 1 <ref> (Schwarzenbach and Gill, 1992) </ref>. The value of the damping factor determines the shape of the transient system response. The response will be overdamped if &gt; 1 (no overshoot but a slow transient) and underdamped if &lt; 1 (overshoots but fast transient).
Reference: <author> Shadmehr, Reza and Ferdinando A. </author> <month> Mussa-Ivaldi </month> <year> (1994). </year> <title> Adaptive representation of dynamics during learning of a motor task. </title> <journal> The Journal Of Neuroscience 14(5), </journal> <pages> 3208-3224. </pages>
Reference-contexts: Another very important statement is that, with practice, biological control systems can develop an accurate internal model of the plant under control (Shadmehr and Mussa-Ivaldi, 1994; Brashers-Krug et al., 1995; Keele et al., 1995; Kawato, 1989). This has been nicely demonstrated by <ref> (Shadmehr and Mussa-Ivaldi, 1994) </ref>. Subjects have to practice a reaching movement in a force field. At the beginning of the learning the movement of the hand is highly affected by the force field.
Reference: <author> Shadmehr, Reza, Tom Brashers-Krug and Ferdinando Mussa-Ivaldi (1995). </author> <title> Interference in learning internal models of inverse dynamics in humans. </title> <booktitle> Advances in Neural Information Processing Systems. </booktitle>
Reference: <author> Shamma, J. S. and M. </author> <month> Athans </month> <year> (1992). </year> <title> Gain scheduling: Potential hazards and possible remedies. </title> <journal> IEEE Control Systems Magazine 12(3), </journal> <pages> 101-107. </pages>
Reference: <author> Shamma, J.S. and M. </author> <month> Athans </month> <year> (1990). </year> <title> Analysis of gain scheduled control for nonlinear plants. </title> <booktitle> IEEE Transaction on Automatic Control 35, </booktitle> <pages> 898-907. </pages>
Reference-contexts: This neural network embodies a number of models inside its architecture. This is totally different from the previous approach where the neural network embodies a single controller. The use of multiple models to control non-linear systems has had a long history starting with gain scheduling (see for instance <ref> (Shamma and Athans, 1990) </ref>) and going through the concept of partitioning (Lainiotis, 1976a; Lainiotis, 1976b) to more recent ideas of Modular Neural Networks (Jacobs and Jordan, 1993), Local Model Networks (Johansen and Foss, 1992; Johansen and Foss, 1993), and Multiple Switched Models (MSM) (a review and recent results appear in references
Reference: <author> Shorten, Robert (1997). </author> <title> Issues in the control of hybrid dynamical systems. In: Centre for Systems and Control Seminar. </title> <institution> Faculty of Engineering, University of Glasgow, </institution> <address> Scotland. </address>
Reference-contexts: If the models are only interpretable globally, due to interaction between each local models, the analysis is difficult and the risk of instability is high <ref> (Shorten, 1997) </ref>. * A local learning enables the use of different function structure for each of the local models. This could be important if one wishes to introduce a priori knowledge in the LMN through the use of different local models more suited to different operating regions.
Reference: <author> Simon, H. </author> <year> (1981). </year> <booktitle> The sciences of the artificial. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT press. </publisher>
Reference-contexts: Modularity is a natural way to ease the learning of complex behaviour. Mountcastle (Mountcastle, 1978) and many others (Karmiloff-Smith, 1994; Houk and Wise, 1995; Carpenter, 1984) argue that modularity is a brain organising principle. (Feldman, 1989) and <ref> (Simon, 1981) </ref> highlight the fact that a complex behaviour requires the bringing together of several different kinds of knowledge and processing, which is not possible without structure (i.e. modularity). Moreover, and according to Marr such a modularity can enable a learning economy.
Reference: <author> Slotine, Jean-Jacques E. </author> <year> (1985). </year> <title> The robust control of robot manipulators. </title> <journal> The International Journal of Robotics Research 4, </journal> <pages> 49-64. </pages>
Reference-contexts: However, even if one can get a true inverse model of the system, this controller is still going to be very sensitive to system disturbances and delays. Actually <ref> (Slotine, 1985) </ref> showed that with an accurate model of a robot manipulator, the average tracking error of a desired target quickly degrades as uncertainty (e.g. disturbances) increases, with the system eventually becoming unstable. <p> This is actually very unlikely, especially at high speed, since strong coupling effects between joints occur that are sources of high disturbances <ref> (Slotine, 1985) </ref>. The high sensitivity of inverse controller to disturbances makes them unsuitable for fast control action. In summary we have a biological control system that mainly acts in an open-loop manner in order to ensure fast control actions.
Reference: <author> Steck, J.E., K Rokhsaz and S.P. </author> <month> Shue </month> <year> (1996). </year> <title> Linear and neural netwok feedback for flight control decoupling. </title> <journal> IEEE Control Systems Magazine 16(4), </journal> <pages> 22-30. </pages>
Reference: <author> Stoelting, R. K. </author> <year> (1990). </year> <note> Pharmacology and Physiology in Anesthetic Practice. Lippincott Press. </note>
Reference-contexts: Hence, more advance methods should be used to tackle the problem of determining the optimum size of the RBFs. Some self-organising methods to cluster the input space have been developed. The operating space is partitioned using a binary tree approach in <ref> (Stoelting, 1990) </ref>. A more sophisticated approach can be found in the model developed by (Mure et al., 1992). This model is named "CALM" for Categorising And Learning Module.
Reference: <author> Stokbro, K., J. A. Hertz and D. K. </author> <month> Umberger </month> <year> (1990). </year> <title> Exploiting neurons with localized receptive fields to learn chaos. </title> <journal> Journal of Complex Systems 4, 603-. </journal>
Reference: <author> Sugeno, M. and G. T. </author> <title> Kang (1986). Fuzzy modelling and control of multilayer incinerator. </title> <journal> Fuzzy Sets and Systems 18, </journal> <pages> 329-346. </pages>
Reference: <author> Szilas, N. and E. </author> <month> Ronco </month> <year> (1995). </year> <title> Action for learning in non-symbolic systems. </title> <booktitle> In: Europeen Conference on Cognitive Science. 132 BIBLIOGRAPHY Takagi, </booktitle> <editor> T. and M. </editor> <title> Sugeno (1985). Fuzzy identification of systems and its application to modeling and control. </title> <journal> IEEE Trans. on Systems, Man and Cybernetics 15(1), </journal> <pages> 116-132. </pages> <month> Taub, </month> <title> E (1976). Movements in nonhuman primates deprived of somatosensory feedback. </title> <journal> Exercise and Sport Sciences Reviews 4, </journal> <pages> 335-374. </pages>
Reference: <author> Temeng, K. O., P. D. Schnelle and T. J. </author> <month> McAvoy </month> <year> (1995). </year> <title> Model-predictive control of an industrial packed-bed reactor using neural networks. </title> <journal> J. Process Control 5, </journal> <pages> 19-27. </pages>
Reference: <author> Toates, F.M. </author> <year> (1975). </year> <title> Control theory in biology and experimental psychology. </title> <publisher> London. </publisher>
Reference: <author> Venugopal, K.P and al. </author> <year> (1994). </year> <title> A recurrent neural network controller and learning algorithm for the on-line learning control of autonomous underwater vehicles. </title> <booktitle> Neural Networks 7(5), </booktitle> <pages> 833-846. </pages>
Reference-contexts: This way of introducing dynamics into a static network has the advantage of being simple to implement but it has restricted dynamics properties compared to a recurrent neural network (Gomm et al., 1997). In the other hand a recurrent neural network tends to further complicate the learning <ref> (Venugopal and al., 1994) </ref>.
Reference: <author> Weller, S. R. and G. C. </author> <title> Goodwin (1994). Hysteresis switching adaptive control of linear multivariable systems. </title> <booktitle> IEEE Transaction on Automatic Control 39(7), </booktitle> <pages> 1360-1375. </pages>
Reference: <author> Werbos, P. J. </author> <year> (1974). </year> <title> Beyond Regression: New Tools for Prediction and Analysis in the Behavior Sciences. </title> <type> Ph.D. Thesis. </type> <institution> Harvard University, Committee on Applied Mathematics. </institution>
Reference-contexts: A strong impulse to the connexionnist models was given in 1986 when (Rumulhart and McClelland, 1986; LeCun, 1987) rediscovered the back-propagation learning algorithm developed in first place by <ref> (Werbos, 1974) </ref>. It enabled the use of the multi-layer perceptron which superseded the poor modelling capability of its single layer ancestor, the perceptron.
Reference: <author> Widrow, B. and F.W. </author> <title> Smith (1964). </title> <booktitle> Pattern-recognizing control systems. In: Proceeding of Computer and Information Sciences. </booktitle>
Reference-contexts: As seen with the MLP a supervised neural network is naturally fitted to mimic the behaviour of another system. The first 1.2. SINGLE NEURAL NETWORKS FOR CONTROL 15 method to develop a neuro-controller involved trying to replicate a human controller. <ref> (Widrow and Smith, 1964) </ref> applied this technic to control the inverted pendulum. This can be useful for plants controlled by humans for which it is difficult to design a standard controller (Hunt et al., 1992).
Reference: <author> Widrow, B. </author> <title> and M.E. Hoff (1960). Adaptive switching circuits. </title> <booktitle> WESCON Conv. Rec. </booktitle> <pages> pp. 96-140. </pages>
Reference: <author> Widrow, B. and S. D. </author> <title> Stearns (1985). Adaptive Signal Processing. </title> <publisher> Prentice-Hall. </publisher> <address> Englewood Cliffs. </address>
Reference: <author> Young, Peter C. </author> <year> (1966). </year> <title> Process parameter estimation and self adaptive control. Theory of self adaptive control system pp. </title> <type> 118-140. </type>
Reference: <author> Zhang, Y., P. Sen and G.E. </author> <title> Hearn (1995). An on-line trained adaptive neural controller. </title> <journal> IEEE Control Systems Magazine 15, </journal> <pages> 67-75. </pages>
Reference-contexts: However it seems that even a crude approximation of the error e u can allow convergence of the neuro-controller learning. For instance, from the sign of the plant derivative, efficient neuro-control learning has been obtained <ref> (Zhang et al., 1995) </ref>. Indeed this method can not be generalised to many systems.
References-found: 134

