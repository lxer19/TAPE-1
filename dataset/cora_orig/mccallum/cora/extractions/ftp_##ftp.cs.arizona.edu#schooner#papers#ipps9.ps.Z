URL: ftp://ftp.cs.arizona.edu/schooner/papers/ipps9.ps.Z
Refering-URL: http://www.cs.arizona.edu/schooner/html-files/publications.html
Root-URL: http://www.cs.arizona.edu
Title: Monitoring and Controlling Remote Parallel Computations Using Schooner  
Author: Zhanliang Chen and Richard D. Schlichting 
Address: Tucson, AZ 85721  
Affiliation: Department of Computer Science University of Arizona  
Abstract: Scientific visualization systems such as AVS have the potential to help users of parallel systems monitor and control their computations. Unfortunately, the machines most suitable for visualization systems are not the parallel systems on which the computation executes, often leading to the use of two distinct machines and the viewing of results only after the computation has completed. Here, an approach to solving this problem is presented in which AVS and a remote parallel computation are incorporated into a single metacomputation using the Schooner software interconnection system. This scheme gives the user enhanced control, including the ability to dynamically select the parallel platform to be used, monitor the progress of the computation, and modify parameters. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> AVS. </author> <title> AVS Developer's Guide (Release 4.0). Advanced Visual Systems Inc., </title> <address> Waltham, MA, </address> <month> May </month> <year> 1992. </year> <title> Part number: </title> <publisher> 320-0013-02, Rev B. </publisher>
Reference-contexts: Enhanced facilities for monitoring and steering the execution, which can be based on visualization systems fl This work supported in part by the National Science Foundation under grants ASC-9204021 and ASC-9318169. such as AVS <ref> [1] </ref>, allow the user to view results and make appropriate parameter changes in a convenient way. The problemand the focus of this paperis that the machines most suitable for visualization systems are not the parallel systems on which the computation executes.
Reference: [2] <author> R. Butler and E. Lusk. </author> <title> User's guide to the p4 parallel programming system. </title> <type> Technical Report ANL-92/17, </type> <institution> Argonne National Laboratory, </institution> <month> Oct </month> <year> 1992. </year>
Reference-contexts: However, these two options are actually orthogonal, so that, if necessary, uts index could still be changed to make its operation linear in time for homogeneous arrays. 5 Conclusions A number of other software systems are available for interconnecting processes running on heterogeneous hosts. PVM [9], p4 <ref> [2] </ref>, and APPL [8] are all message passing systems. Their goal is to allow execution of parallel algorithms on workstation clusters, with multiple threads of control executing simultaneously on different processors.
Reference: [3] <author> Andrew S. Grimshaw, William A. Wulf, James C. French, Alfred C. Weaver, and Paul F. Reynolds Jr. Legion: </author> <title> the next logical step toward a nationwide virtual computer. </title> <type> Technical Report CS-94-21, </type> <institution> University Of Virginia, </institution> <month> June 94. </month>
Reference-contexts: Thus, Schooner presents a higher-level model that complements PVM by allowing parallel computations written using PVM to be configured into larger metacomputations. Legion <ref> [3] </ref> is an on-going project that attempts to combine the advantages of parallel message passing systems like PVM and heterogeneous RPC facilities like Schooner. It provides heterogeneous parallel computation support at the high-level language level by using the Mentat Program ming Language, an object-oriented programming language based on C++.
Reference: [4] <author> R. Hayes. UTS: </author> <title> A Type System for Facilitating Data Communication. </title> <type> PhD thesis, </type> <institution> Dept of Computer Science, University of Arizona, </institution> <address> Tucson, AZ, </address> <year> 1989. </year>
Reference-contexts: An intermediate data representation, which specifies how data is represented as it is transmitted from one component to another. The interface specification language and the intermediate data representation used in Schooner are collectively called the Universal Type Sys tem (UTS) <ref> [4] </ref>. 3. Stub compilers, which convert the import and export specifications into C or Fortran stub routines. These stub routines automatically handle the encoding and decoding of data between the UTS intermediate representation and the representation of the host machine. 4.
Reference: [5] <author> P. Homer and R.D. Schlichting. </author> <title> A software platform for constructing scientific applications from heterogeneous resources. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 21(3) </volume> <pages> 301-315, </pages> <month> June </month> <year> 1994. </year> <note> (Special Issue on Heterogeneous Processing). </note>
Reference-contexts: The programming model can be easily adapted to work with a wide variety of parallel computations. An earlier paper demonstrates similar conclusions for sequential and vector computations <ref> [5] </ref>. 2 Background 2.1 Schooner Interconnection System Schooner is a software interconnection system designed to facilitate the construction of scientific applications that require access to heterogeneous software and hardware resources in the Internet.
Reference: [6] <author> P. Homer and R.D. Schlichting. </author> <title> Using Schooner to support distribution and heterogeneity in the Numerical Propulsion System Simulation project. </title> <journal> Concurrency-Practice and Experience, </journal> <volume> 6(4) </volume> <pages> 271-287, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: This decouples the computation from the visualization system, thereby limiting the ability of the user to monitor and control the computation. Our approach involves incorporating the visualization system and parallel computation into a single heterogeneous distributed program or metacomputation [7] using the Schooner software interconnection system <ref> [6] </ref>.
Reference: [7] <author> A.A. Khokhar, V.K. Prasanna, M.E. Shaaban, and C. Wang. </author> <title> Heterogeneous computing: Challenges and opportunities. </title> <journal> IEEE Computer, </journal> <volume> 26(6) </volume> <pages> 18-27, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: This decouples the computation from the visualization system, thereby limiting the ability of the user to monitor and control the computation. Our approach involves incorporating the visualization system and parallel computation into a single heterogeneous distributed program or metacomputation <ref> [7] </ref> using the Schooner software interconnection system [6].
Reference: [8] <author> A. Quealy, G. L. Cole, and R. A. Blech. </author> <title> Portable programming on parallel/networked computers using the Application Portable Parallel Library (APPL). </title> <type> Technical Report 106238, </type> <institution> NASA, </institution> <month> Jul </month> <year> 1993. </year>
Reference-contexts: PVM [9], p4 [2], and APPL <ref> [8] </ref> are all message passing systems. Their goal is to allow execution of parallel algorithms on workstation clusters, with multiple threads of control executing simultaneously on different processors.
Reference: [9] <author> V.S. Sunderam. </author> <title> PVM: A framework for parallel distributed computing. </title> <journal> Concurrency-Practice and Experience, </journal> <volume> 2(4) </volume> <pages> 315-339, </pages> <month> Dec </month> <year> 1990. </year> <month> 620 </month>
Reference-contexts: Parallelism is, of course, widely recognized as a technique for reducing the execution time of scientific computations, either by using parallel hardware such as an Intel Paragon or virtual parallel machines with software systems such as PVM <ref> [9] </ref>. <p> However, these two options are actually orthogonal, so that, if necessary, uts index could still be changed to make its operation linear in time for homogeneous arrays. 5 Conclusions A number of other software systems are available for interconnecting processes running on heterogeneous hosts. PVM <ref> [9] </ref>, p4 [2], and APPL [8] are all message passing systems. Their goal is to allow execution of parallel algorithms on workstation clusters, with multiple threads of control executing simultaneously on different processors.
References-found: 9

