URL: http://http.cs.berkeley.edu/~asah/papers/other/to-read/houtsma.wmrd2.accepted.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~asah/papers/other/to-read/
Root-URL: http://www.cs.berkeley.edu
Title: The Case for Independent Updates  
Author: Stefano Ceri Maurice A.W. Houtsma Arthur M. Keller Pierangela Samarati 
Affiliation: Politecnico di Milano  University of Twente  Stanford University  Universita' di Milano  
Abstract: We present the case for allowing independent updates on replicated databases. In autonomous, heterogeneous, or large scale systems, using two-phase commit for updates may be infeasible. Instead, we propose that a site may perform updates independently. Sites that are available can receive these updates immediately. But sites that are unavailable, or otherwise do not participate in the update transaction, receive these updates later through propagation, rather than preventing the execution of the update transaction until sufficient sites can participate. Two or more sites come to agreement using an reconciliation procedure that uses reception vectors to determine how much of the history log should be transferred from one site to another. We also consider what events can initiate a reconciliation procedure. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Agrawal and A. El Abbadi, </author> <title> "The tree quorum protocol: an efficient approach for managing replicated data," </title> <booktitle> in Proc. 16th Int. Conf. on VLDB, </booktitle> <address> Brisbane, </address> <month> Aug. </month> <year> 1990, </year> <pages> pp. 243-254. </pages>
Reference-contexts: 1 Introduction Many recent papers have studied the applicability of replicated databases, and many strategies have been developed to deal with updates in such an environment <ref> [1, 6, 7] </ref>. An overview of such strategies has been given by us in [4]; that analysis shows that read performance may increase enormously by allowing replicated data, but that update performance may also dramatically decrease, especially if two-phase commit is required to synchronize updates on the replicas.
Reference: [2] <author> D. Barbara and H. Garcia-Molina, </author> <title> "The case for controlled inconsistency in replicated data," </title> <booktitle> Proc. of the Workshop on Management of Replicated Data, </booktitle> <address> Houston, TX, </address> <month> Nov. </month> <year> 1990. </year>
Reference-contexts: This does, of course, imply that global serializability is lost; but in many applications this seems perfectly acceptable according to several researchers <ref> [2] </ref>. It also reflects the common practice in applications written for commercial database systems, where the user has to indicate if whether support for global serializability is desired or whether the user can instead accept practical, potentially inconsistent solutions.
Reference: [3] <author> D. Barbara and H. Garcia-Molina, </author> <title> The demarcation protocol: a technique for maintaining arithmetic constraints in distributed database systems, </title> <institution> CS-TR-320-91, Princeton University, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: Of course, when allowing independent updates, global constraints may no longer be fully supported. However, several proposals already exist to rewrite at least some global constraints into local ones; in this way important constraints may still be enforced <ref> [3] </ref>. 2 Independent updates We study situations where a number of database systems are integrated in a network, be it wide area, local area, or even closely coupled. We suppose that the database systems are relatively autonomous, and update applications cannot afford to wait for all sites to be available.
Reference: [4] <author> S. Ceri, M.A.W. Houtsma, A.M. Keller, and P. Samarati, </author> <title> "A Classification of Update Methods for Replicated Databases," </title> <institution> STAN-CS-91-1932, Stanford University, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Many recent papers have studied the applicability of replicated databases, and many strategies have been developed to deal with updates in such an environment [1, 6, 7]. An overview of such strategies has been given by us in <ref> [4] </ref>; that analysis shows that read performance may increase enormously by allowing replicated data, but that update performance may also dramatically decrease, especially if two-phase commit is required to synchronize updates on the replicas.
Reference: [5] <author> S. Ceri, M.A.W. Houtsma, A.M. Keller, and P. Samarati, </author> <title> "Achieving Incremental Consistency among Autonomous Replicated Databases," </title> <booktitle> in Proc. DS-5 (Semantics of Interoper-able Database Systems), IFIP, </booktitle> <address> Lorne, Australia, </address> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: In the context of autonomous, heterogeneous systems, two-phase commit may not be feasible at all. For these reasons, research is focusing on delayed propagation of updates from one copy to another <ref> [5, 8] </ref>. To allow such a delayed propagation of updates, we introduce the notion of independent updates. We particularly address the problems that arise in an environment where database systems are relatively autonomous, and do not wish to depend on other sites being available while accepting updates. <p> Several options exist, with different choices of communication and control (e.g., one central coordinator or distributed coordination). We have also given formal proofs that the reconciliation procedure briefly sketched here is indeed correct <ref> [5] </ref>. Also, protocols have been developed that precisely indicate what messages are required for the reconciliation procedure, what happens if failures appear during the reconciliation process, etc. Detection of partitions is a problem in itself, but can usually be entrusted to the underlying communication system.
Reference: [6] <author> J.N. Gray and M. Anderton, </author> <title> "Distributed computer systems: four case studies," </title> <journal> Proc. of the IEEE, </journal> <volume> Vol. 75, No. 5, </volume> <month> May </month> <year> 1987. </year>
Reference-contexts: 1 Introduction Many recent papers have studied the applicability of replicated databases, and many strategies have been developed to deal with updates in such an environment <ref> [1, 6, 7] </ref>. An overview of such strategies has been given by us in [4]; that analysis shows that read performance may increase enormously by allowing replicated data, but that update performance may also dramatically decrease, especially if two-phase commit is required to synchronize updates on the replicas.
Reference: [7] <author> A. Kumar and A. Segev, </author> <title> "Optimizing voting-type algorithms for replicated data," </title> <booktitle> in Advances in Database Technology-EDBT'88, </booktitle> <editor> J.W. Schmidt, S. Ceri, and M. Missikoff (Eds.), </editor> <volume> LNCS 303, </volume> <year> 1988, </year> <pages> pp. 428-442. </pages>
Reference-contexts: 1 Introduction Many recent papers have studied the applicability of replicated databases, and many strategies have been developed to deal with updates in such an environment <ref> [1, 6, 7] </ref>. An overview of such strategies has been given by us in [4]; that analysis shows that read performance may increase enormously by allowing replicated data, but that update performance may also dramatically decrease, especially if two-phase commit is required to synchronize updates on the replicas.
Reference: [8] <author> C. Pu and A. Leff, </author> <title> "Replica control in distributed systems: an asynchronous approach," </title> <booktitle> Proc. ACM SIGMOD 91, </booktitle> <address> Denver, CO, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: In the context of autonomous, heterogeneous systems, two-phase commit may not be feasible at all. For these reasons, research is focusing on delayed propagation of updates from one copy to another <ref> [5, 8] </ref>. To allow such a delayed propagation of updates, we introduce the notion of independent updates. We particularly address the problems that arise in an environment where database systems are relatively autonomous, and do not wish to depend on other sites being available while accepting updates.
References-found: 8

