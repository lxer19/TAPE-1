URL: http://mays.cs.brandeis.edu:8080/~dang/papers/aaai96.ps
Refering-URL: http://mays.cs.brandeis.edu:8080/~dang/
Root-URL: http://www.cs.brandeis.edu
Title: Abstract use adapted case retriever Improving Case Retrieval by Remembering Questions Blind  
Abstract-found: 0
Intro-found: 1
Reference: <author> Carpenter, T., and Alterman, R. </author> <year> 1994. </year> <title> A reading agent. </title> <booktitle> In </booktitle> . 
Reference: <author> Croft, B., and Turtle, H. </author> <year> 1992. </year> <title> Text retrieval and inference. </title> <editor> In Jacobs, P., ed., </editor> . <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher> <pages> 127-155. </pages>
Reference-contexts: The problem of retrieving relevant documents has been a research area in the field of information retrieval (IR) for many years <ref> (Croft and Turtle, 1992) </ref>. The use-adapted retrieval model developed in this work complements standard IR techniques, potentially improving system performance by allowing the system to gain skill, after it has been deployed, for the questions that are most frequently asked.
Reference: <author> Fisher, D. H. </author> <year> 1987. </year> <title> Knowledge acquisition via incremental conceptual clustering. </title> <booktitle> 2 </booktitle> <pages> 139-172. </pages>
Reference-contexts: The notion of remembering answered questions is different from other approaches to learning that have been applied to case retrieval. Where incremental clusterers, e.g. CYRUS (Kolodner, 1983), UNIMEM (Lebowitz, 1987), and COBWEB <ref> (Fisher, 1987) </ref>, update and re-organize a case-base with the addition of each new case by comparing cases, the model we propose attempts to improve retrieval performance of the system on cases already existing in the case-base by acquiring information about the usage of those cases.
Reference: <author> Fox, S., and Leake, D. B. </author> <year> 1995. </year> <title> Using introspective reasoning to refine indexing. </title> <note> In , 391-397. </note>
Reference: <author> Hammond, K. J. </author> <year> 1990. </year> <title> Case-based planning: A framework for planning from experience. </title> <booktitle> 14 </booktitle> <pages> 385-443. </pages>
Reference: <author> Hersh, W. R., and Molnar, A. </author> <year> 1995. </year> <title> Towards new measures of information retrieval evaluation. </title> <note> In , 164-170. </note>
Reference-contexts: The evaluation criteria precision and recall are borrowed from the information retrieval (IR) community basically because of the IR-like nature of our system. It is of note, however, that these criteria are not the end-all for system evaluation <ref> (Hersh & Molnar 1995) </ref>, especially when the system is to be evaluated for its . Aspects such as user effort, ease of use and other equally hard to quantify system characteristics are also of obvious import and in our experiments we discuss such an aspect; .
Reference: <author> Kolodner, J. L. </author> <year> 1983. </year> <title> Reconstructive memory: A computer model. </title> <booktitle> 7 </booktitle> <pages> 281-328. </pages>
Reference-contexts: The notion of remembering answered questions is different from other approaches to learning that have been applied to case retrieval. Where incremental clusterers, e.g. CYRUS <ref> (Kolodner, 1983) </ref>, UNIMEM (Lebowitz, 1987), and COBWEB (Fisher, 1987), update and re-organize a case-base with the addition of each new case by comparing cases, the model we propose attempts to improve retrieval performance of the system on cases already existing in the case-base by acquiring information about the usage of those
Reference: <author> Leake, D. B. </author> <year> 1991. </year> <title> An indexing vocabulary for case-based explanation. </title> <editor> In Dean, T., and McKeown, K., eds., </editor> . <publisher> AAAI. </publisher>

Reference: <author> Quinlan, J. R. </author> <year> 1986. </year> <title> Induction of decision trees. </title> <booktitle> 1 </booktitle> <pages> 81-106. </pages>
Reference-contexts: We identified a list of about 348 keywords used in the description of cases. We used the ID3 algorithm <ref> (Quinlan 1986) </ref> to build a clustering of the cases over the keywords. The usage of the base retrieval system can be described as follows. A user specifies a question or information need from which a list of keywords are extracted by the system .
Reference: <author> Ram, A., and Hunter, L. </author> <year> 1992. </year> <title> The use of explicit goals for knowledge to guide inference and learning. </title> <booktitle> 2 </booktitle> <pages> 47-73. </pages>
Reference-contexts: Others have explored the role of `unanswered' questions in directing learning <ref> (Ram & Hunter, 1992) </ref> or reading (Ram, 1991; Carpenter & Alterman, 1994), our interest here is in retaining and using a memory of previously `answered' questions. The notion of remembering answered questions is different from other approaches to learning that have been applied to case retrieval. Where incremental clusterers, e.g.
Reference: <author> Ram, A. </author> <year> 1991. </year> <title> A theory of questions and question asking. </title> <booktitle> 1 </booktitle> <pages> 273-318. </pages>
Reference: <author> Rissland, E., and Ashley, K. </author> <year> 1986. </year> <title> Hypotheticals as heuristic device. </title> <booktitle> In </booktitle> . 
Reference-contexts: Hammond, 1990; Leake 1991); others have proposed a standard indexing vocabulary that could be used to index cases across a wide selection of domains (Schank et. al, 1990); and still others suggest that features can be ranked or refined dynamically <ref> (Rissland & Ashley, 1986, Fox & Leake 1995) </ref>. After a indexing vocabulary has been established, additional work must be done in identifying synonyms. Next, each of the cases must be indexed; indexing can be done either by hand or automatically using some clustering algorithm.
Reference: <author> Rissland, E. L., and Daniels, J. J. </author> <year> 1995. </year> <title> Using cbr to drive ir. </title> <editor> In , Salton, G., and Buckley, C. </editor> <year> 1990. </year> <title> Improving retrieval performance with relevance feedback. </title> <editor> 41(4):288 Schank, R. </editor> <address> 1982. . Cambridge: </address> <publisher> Cambridge University Press. </publisher>
Reference: <author> Schank, R. </author> <year> 1990. </year> <title> Toward a general content theory of indices. </title> <note> In , 36-40. </note>
Reference-contexts: Several vocabularies have touted for specific kinds of domains (see e.g. Hammond, 1990; Leake 1991); others have proposed a standard indexing vocabulary that could be used to index cases across a wide selection of domains <ref> (Schank et. al, 1990) </ref>; and still others suggest that features can be ranked or refined dynamically (Rissland & Ashley, 1986, Fox & Leake 1995). After a indexing vocabulary has been established, additional work must be done in identifying synonyms. <p> The view that cases have "right indices" is inherent to the various vocabularies that have been touted for specific kinds of domains (see e.g. Hammond, 1990; Leake 1991) or specific indexing schemes that are claimed to apply to a wide selection of domains <ref> (Schank et. al, 1990) </ref>. Systems that do indexing based on a clustering of the cases can also end up with a single index for a given case.
Reference: <author> Shardanand, U., and Maes, P. </author> <year> 1995. </year> <title> Social information filtering: Algorithms for automating "word of mouth". </title> <note> In , 210-217. </note>
Reference-contexts: By separating questions from cases, the case retriever can view cases from the perspective of their usage | in principle each question for which the case is relevant is potentially another index for the case. Recently the work by Shardanand and Maes <ref> (Shardanand & Maes 1995) </ref> has focussed on using similar user preferences to automate "word of mouth" for the purpose of information filtering.
Reference: <author> Sparch-Jones, K. </author> <year> 1992. </year> <title> Assumptions and issues in text-based retrieval. </title> <editor> In Jacobs, P., ed., </editor> . <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher> <pages> 157-177. </pages>
Reference: <author> Veloso, M., and Carbonell, J. </author> <year> 1993. </year> <title> Derivational analogy in prodigy: Automating case acquisition, storage, </title> <journal> and utilization. </journal> <volume> 10 </volume> <pages> 249-278. </pages>
References-found: 17

