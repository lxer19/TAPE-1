URL: http://www.cs.uoregon.edu/~harrop/papers/ETPSC96/etpsc96.ps.gz
Refering-URL: http://www.cs.uoregon.edu/~harrop/pubs.html
Root-URL: http://www.cs.uoregon.edu
Title: BUILDING DOMAIN-SPECIFIC ENVIRONMENTS FOR COMPUTATIONAL SCIENCE: A CASE STUDY IN SEISMIC TOMOGRAPHY  
Author: JANICE E. CUNY ROBERT DUNN STEVE T. HACKSTADT CHRISTOPHER HARROP HAROLD HERSEY ALLEN D. MALONY AND DOUGLAS R. TOOMEY 
Abstract: We report on our experiences in building a computational environment for tomo-graphic image analysis for marine seismologists studying the structure and evolution of mid-ocean ridge volcanism. The computational environment is determined by an evolving set of requirements for this problem domain and includes needs for high-performance parallel computing, large data analysis, model visualization, and computation interaction and control. Although these needs are not unique in scientific computing, the integration of techniques for seismic tomography with tools for parallel computing and data analysis into a computational environment was (and continues to be) an interesting, important learning experience for researchers in both disciplines. For the geologists, the use of the environment led to fundamental geologic discoveries on the East Pacific Rise, the improvement of parallel ray tracing algorithms, and a better regard for the use of computational steering in aiding model convergence. The computer scientists received valuable feedback on the use of programming, analysis, and visualization tools in the environment. In particular, the tools for parallel program data query (DAQV) and visualization programming (Viz) were demonstrated to be highly adaptable to the problem domain. We discuss the requirements and the components of the environment in detail. Both accomplishments and limitations of our work are presented. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> Message Passing Interface (MPI). </institution> <note> http://www.arc.unm.edu/workshop/mpi/mpi.html. </note>
Reference-contexts: The obvious reason is that tremendous efforts have been made in recent years to advance technology for parallel scientific problem solving in general. Developed technologies include parallel languages (e.g., HPF [9]), communications libraries (e.g., MPI <ref> [1] </ref>), parallel performance analyzers (e.g., Paradyn [7]), parallel debuggers (e.g., Ariadne [20]), and visualization systems (e.g., ParaGraph [15]). Solving a particular computational science problem, though, involves a combination of several technologies with a domain-specific purpose.
Reference: [2] <author> MATLAB: </author> <title> High Performance Numeric Computation and Visualization Spftware Reference Guide, </title> <year> 1992. </year>
Reference: [3] <author> M. Berry, </author> <title> Large Scale Singular Value Computations, </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 6 (1992), </volume> <pages> pp. 13-49. </pages> <note> 16 Domain-Specific Environments for Computational Science </note>
Reference-contexts: We want a parallel SVD (Singular Value Decomposition) method for computing pseudo-inverses of the G matrix, also yielding information and resolution matrices that will provide statistical information regarding the resolution and quality of the data. We are considering the use of SVD Pack <ref> [3] </ref>. We are also considering parallelization across our array of SGI Power Challenges (cur rently we run on a single cabinet). 6. Portability. We would like the environment to be portable for several reasons.
Reference: [4] <author> D. Brown, S. Hackstadt, A. Malony, and B. Mohr, </author> <title> Program Analysis Environments for Parallel Language Systems: The TAU Environment, </title> <booktitle> in Proc. of the Workshop on Environments and Tools for Parallel Scientific Computing, </booktitle> <month> May </month> <year> 1994, </year> <pages> pp. 162-171. </pages>
Reference-contexts: Second, since complete functional requirements are difficult to anticipate, we constructed tools that could be extended with new functionality. This is principally an issue of tool architecture. For the t (TAU, Tuning and Analysis Utilities) program analysis environment <ref> [4] </ref>, as an example, we developed a toolkit architecture where individually distinct tools work together based on a common system infrastructure. <p> Third, we developed tools to interoperate by specifying their programming and communications interfaces. Again, t provides a good example of this feature as tools can evoke integrated behavior via synchronized, communicated actions <ref> [4] </ref>. Often the need for interoperability also necessitates extension of the architecture infrastructure, as in the case of t 's program and interaction control infrastructure [26]. The three general features of programmability, extensibility, and interoperability have proven to be effective in our performance and debugging tools [22].
Reference: [5] <author> C. Cook and C. Pancake, </author> <title> What Users Need in Parallel Tool Support: Survey Results and Analysis, </title> <booktitle> in Proc. of the Scalable High Performance Computing Conference, </booktitle> <editor> I. C. S. </editor> <publisher> Press, ed., </publisher> <year> 1994, </year> <pages> pp. 40-47. </pages>
Reference-contexts: Technology for Domain-Specific Environments. There is now suitable HPC hardware and software technology for developing computational science applications, but scientists often lack sufficient background in parallel processing to understand and apply that technology. Experience has shown that it is difficult to make programming and analysis tools easy to use <ref> [5] </ref>. Generally, difficulties arise when the scientist's conceptual and operational models of the application are not well supported by the tool.
Reference: [6] <author> I. B. M. Corporation, </author> <title> IBM Visualization Data Explorer, User's Guide, </title> <editor> 2nd Ed, </editor> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: For a more detailed discussion of DAQV, see [12]. 3.2. Viz: A Visualization Programming System. Creating meaningful visualizations for use in scientific problem solving is difficult [28]. General purpose visualization tools, such as Iris Explorer [24], AVS [21], and Data Explorer <ref> [6] </ref>, have been well received, but do not always provide the flexibility and robustness required for visualization design and specialization. Viz was created to support rapid visualization prototyping in a system that could be extended with application-specific visualization abstractions.
Reference: [7] <author> B. M. et. al., </author> <title> The Paradyn Parallel Performance Measurement Tool, </title> <journal> IEEE Computer, </journal> <volume> 28 (1995), </volume> <pages> pp. 37-46. </pages>
Reference-contexts: The obvious reason is that tremendous efforts have been made in recent years to advance technology for parallel scientific problem solving in general. Developed technologies include parallel languages (e.g., HPF [9]), communications libraries (e.g., MPI [1]), parallel performance analyzers (e.g., Paradyn <ref> [7] </ref>), parallel debuggers (e.g., Ariadne [20]), and visualization systems (e.g., ParaGraph [15]). Solving a particular computational science problem, though, involves a combination of several technologies with a domain-specific purpose. That is, an "environment" for a computational science application must address problem solving requirements that are unique to that application domain.
Reference: [8] <author> M. Feeley, Gambit-C, </author> <title> A Portable Scheme Implementation, </title> <month> Apr. </month> <year> 1996. </year> <note> Version 2.3. </note>
Reference-contexts: Viz was created to support rapid visualization prototyping in a system that could be extended with application-specific visualization abstractions. Our original application domain was parallel program and performance data visualization [11, 13, 16, 17]. Viz is a visualization programming environment built on an interpreted, high-level language (Scheme <ref> [19, 8] </ref>) with object extensions (Meroon [25]). It embeds a 3D graphics library (Open Inventor [30]), adding higher-level abstractions for glyphs, composition, and data representations.
Reference: [9] <author> H. P. F. Forum, </author> <title> High Performance Fortran Language Specification, Version 1.0, </title> <type> Tech. Report CRPC-TR92225, </type> <note> Center for Research on Parallel Computation, </note> <month> May </month> <year> 1993. </year>
Reference-contexts: The obvious reason is that tremendous efforts have been made in recent years to advance technology for parallel scientific problem solving in general. Developed technologies include parallel languages (e.g., HPF <ref> [9] </ref>), communications libraries (e.g., MPI [1]), parallel performance analyzers (e.g., Paradyn [7]), parallel debuggers (e.g., Ariadne [20]), and visualization systems (e.g., ParaGraph [15]). Solving a particular computational science problem, though, involves a combination of several technologies with a domain-specific purpose.
Reference: [10] <author> E. Gallopoulos, E. Houstis, and J. Rice, </author> <title> Problem-Solving Environments for Computational Science, </title> <booktitle> IEEE Computational Science and Engineering, Summer (1994), </booktitle> <pages> pp. 11-22. </pages>
Reference-contexts: We believe that domain-specific environments for computational science represent a challenging research problem area for computer science. It includes many of the motivations and characteristics of problem-solving environments (PSE's) <ref> [10] </ref>, but with an important difference: the leading-edge science applications we are concerned about are exploratory and experimental in nature. Most PSE's target applications which are "well understood and standardized" [10]. Our applications demand domain-specific support that can adapt to changing requirements. <p> It includes many of the motivations and characteristics of problem-solving environments (PSE's) <ref> [10] </ref>, but with an important difference: the leading-edge science applications we are concerned about are exploratory and experimental in nature. Most PSE's target applications which are "well understood and standardized" [10]. Our applications demand domain-specific support that can adapt to changing requirements. Thus, it is our belief that computer science research needs to develop methods, tools, and infrastructure that utilize capabilities of programmability, extensibil ity, and interoperability to build domain-specific environments for leading-edge scientific applications. <p> We speculate that these same capabilities will be useful in addressing the domain-specific aspects of computational science applications. Recommendations from the PSE community arguing for new environment architectures, supporting software infrastructure, and tool components are consistent with this view <ref> [10] </ref>. For our environments, they will be even more critical because the evolving nature of more exploratory work requires tools that can not only accommodate domain-specific abstractions but also adapt to changing requirements.
Reference: [11] <author> S. Hackstadt and A. Malony, </author> <title> Next-Generation Parallel Performance Visualization: A Pro-totyping Environment for Visualization Development, </title> <booktitle> in Proc. Parallel Architectures and Languages Europe (PARLE) Conference, </booktitle> <month> July </month> <year> 1994, </year> <pages> pp. </pages> <month> 192-201. </month> <title> [12] , Distributed Array Query and Visualization for High Performance Fortran, </title> <booktitle> in Proc. of Euro-Par '96, </booktitle> <month> Aug. </month> <year> 1996. </year>
Reference-contexts: Viz was created to support rapid visualization prototyping in a system that could be extended with application-specific visualization abstractions. Our original application domain was parallel program and performance data visualization <ref> [11, 13, 16, 17] </ref>. Viz is a visualization programming environment built on an interpreted, high-level language (Scheme [19, 8]) with object extensions (Meroon [25]). It embeds a 3D graphics library (Open Inventor [30]), adding higher-level abstractions for glyphs, composition, and data representations.
Reference: [13] <author> S. Hackstadt, A. Malony, and B. Mohr, </author> <title> Scalable Performance Visualization for Data-Parallel Programs, </title> <booktitle> in Proc. of the Scalable High Performance Computing Conference, </booktitle> <editor> I. C. S. </editor> <publisher> Press, ed., </publisher> <month> May </month> <year> 1994, </year> <pages> pp. 342-349. </pages>
Reference-contexts: Viz was created to support rapid visualization prototyping in a system that could be extended with application-specific visualization abstractions. Our original application domain was parallel program and performance data visualization <ref> [11, 13, 16, 17] </ref>. Viz is a visualization programming environment built on an interpreted, high-level language (Scheme [19, 8]) with object extensions (Meroon [25]). It embeds a 3D graphics library (Open Inventor [30]), adding higher-level abstractions for glyphs, composition, and data representations.
Reference: [14] <author> L. Hansen, FFIGEN: </author> <title> Foreign Function Interface GENerator, </title> <note> release 1, 1996. available from http://www.cs.uoregon.edu/ ~ lth/ffigen. </note>
Reference-contexts: Viz also provides mechanisms for "wrapping" visualizations into stand-alone tools that can communicate with other components (e.g., data sources), enabling interoperability in a larger environment. In addition to extension through new abstractions, Viz system comes with powerful facilities for extending functionality through foreign function interfaces <ref> [14] </ref>; the Open Inventor API, the socket support, and a Viz module for Iris Explorer Domain-Specific Environments for Computational Science 9 Fig. 1. Seismic Tomography Computational Environment were implemented in this manner. We are actively defining new abstraction layers to support, for instance, interaction, animation abstractions, and distributed operation.
Reference: [15] <author> M. Heath and J. Etheridge, </author> <title> Visualizing the Performance of Parallel Programs, </title> <journal> IEEE SOFTWARE, </journal> <year> (1991), </year> <pages> pp. 29-39. </pages>
Reference-contexts: Developed technologies include parallel languages (e.g., HPF [9]), communications libraries (e.g., MPI [1]), parallel performance analyzers (e.g., Paradyn [7]), parallel debuggers (e.g., Ariadne [20]), and visualization systems (e.g., ParaGraph <ref> [15] </ref>). Solving a particular computational science problem, though, involves a combination of several technologies with a domain-specific purpose. That is, an "environment" for a computational science application must address problem solving requirements that are unique to that application domain. <p> Experience has shown that it is difficult to make programming and analysis tools easy to use [5]. Generally, difficulties arise when the scientist's conceptual and operational models of the application are not well supported by the tool. A simple example was seen in early versions of ParaGraph <ref> [15] </ref> where displays of communication behavior clearly showed performance bottlenecks, but users found it difficult to relate those bottlenecks back to specific source code.
Reference: [16] <author> M. Heath, A. Malony, and D. </author> <title> Rover, Parallel Performance Visualization: From Practice to Theory, </title> <journal> IEEE Parallel and Distributed Technology, </journal> <volume> 3 (1995), </volume> <pages> pp. </pages> <month> 44-60. </month> <title> [17] , The Visual Display of Parallel Performance Data, </title> <journal> IEEE Computer, </journal> <volume> 28 (1995), </volume> <pages> pp. 21-28. </pages>
Reference-contexts: Viz was created to support rapid visualization prototyping in a system that could be extended with application-specific visualization abstractions. Our original application domain was parallel program and performance data visualization <ref> [11, 13, 16, 17] </ref>. Viz is a visualization programming environment built on an interpreted, high-level language (Scheme [19, 8]) with object extensions (Meroon [25]). It embeds a 3D graphics library (Open Inventor [30]), adding higher-level abstractions for glyphs, composition, and data representations.
Reference: [18] <author> H. Hersey, S. Hackstadt, L. Hansen, and A. Malony, Viz: </author> <title> A Visualization Programming System, </title> <type> Tech. Report CIS-TR-96-05, </type> <institution> University of Oregon, Department of Computer and Information Science, </institution> <month> Apr. </month> <year> 1996. </year>
Reference-contexts: Seismic Tomography Computational Environment were implemented in this manner. We are actively defining new abstraction layers to support, for instance, interaction, animation abstractions, and distributed operation. For a more detailed discussion of Viz, see <ref> [18] </ref>. 4. A Domain-Specific Environment for Seismic Tomography. The current experimental environment for the marine seismology application is shown in a high-performance multiprocessor platform. Our platform, an SGI Power Challenge (SGI-PC) with 8 processors, provides parallelizing compilers and parallel languages, with support for dynamic program interaction and 3D visualization.
Reference: [19] <author> IEEE, </author> <title> IEEE Standard 1178-1990. Standard for the Scheme Programming Language, </title> <year> 1991. </year>
Reference-contexts: Viz was created to support rapid visualization prototyping in a system that could be extended with application-specific visualization abstractions. Our original application domain was parallel program and performance data visualization [11, 13, 16, 17]. Viz is a visualization programming environment built on an interpreted, high-level language (Scheme <ref> [19, 8] </ref>) with object extensions (Meroon [25]). It embeds a 3D graphics library (Open Inventor [30]), adding higher-level abstractions for glyphs, composition, and data representations.
Reference: [20] <author> J. Kundu and J. Cuny, </author> <title> The Integration of Event- and State-Based Debugging in Ariadne, </title> <booktitle> in Proceedings of the 1995 International Conference on Parallel Processing, </booktitle> <year> 1995, </year> <pages> pp. II 130-134. </pages>
Reference-contexts: The obvious reason is that tremendous efforts have been made in recent years to advance technology for parallel scientific problem solving in general. Developed technologies include parallel languages (e.g., HPF [9]), communications libraries (e.g., MPI [1]), parallel performance analyzers (e.g., Paradyn [7]), parallel debuggers (e.g., Ariadne <ref> [20] </ref>), and visualization systems (e.g., ParaGraph [15]). Solving a particular computational science problem, though, involves a combination of several technologies with a domain-specific purpose. That is, an "environment" for a computational science application must address problem solving requirements that are unique to that application domain. <p> As an example, the event-based Ariadne debugger matches user-specified models of intended program behavior against actual execution behavior as captured in event traces <ref> [20] </ref>. Ariadne is, in essence, "programmed" to work with an application by specifying appropriate behavior models and enabling instrumentation. Second, since complete functional requirements are difficult to anticipate, we constructed tools that could be extended with new functionality. This is principally an issue of tool architecture.
Reference: [21] <author> B. Lucas, G. Abram, N. Collins, D. Epstein, D. Gresh, and K. McAuliffe, </author> <title> An Architecture for a Scientific Visualization System, </title> <booktitle> in Proc. of Visualization '92, </booktitle> <month> Oct. </month> <year> 1992, </year> <pages> pp. 107-114. </pages>
Reference-contexts: For a more detailed discussion of DAQV, see [12]. 3.2. Viz: A Visualization Programming System. Creating meaningful visualizations for use in scientific problem solving is difficult [28]. General purpose visualization tools, such as Iris Explorer [24], AVS <ref> [21] </ref>, and Data Explorer [6], have been well received, but do not always provide the flexibility and robustness required for visualization design and specialization. Viz was created to support rapid visualization prototyping in a system that could be extended with application-specific visualization abstractions.
Reference: [22] <author> A. Malony, B. Mohr, P. Beckman, and D. Gannon, </author> <title> Program Analysis and Tuning Tools for a Parallel Object-Oriented Language: An Experiment with the TAU System, </title> <booktitle> in Proc. of the Workshop on Parallel Scientific Computing, </booktitle> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: Often the need for interoperability also necessitates extension of the architecture infrastructure, as in the case of t 's program and interaction control infrastructure [26]. The three general features of programmability, extensibility, and interoperability have proven to be effective in our performance and debugging tools <ref> [22] </ref>. We speculate that these same capabilities will be useful in addressing the domain-specific aspects of computational science applications. Recommendations from the PSE community arguing for new environment architectures, supporting software infrastructure, and tool components are consistent with this view [10].
Reference: [23] <author> T. Moser, </author> <title> Shortest Path Calculation of Seismic Rays, </title> <journal> Geophysics, </journal> <volume> 56 (1991), </volume> <pages> pp. 59-67. </pages>
Reference-contexts: The edges are assigned weights equal to the calculated travel times between their end points for the current velocity model. An adaptation of Dijkstra's shortest path algorithm <ref> [23] </ref> is used to find the minimum travel times between each seismic receiver location and all other nodes.
Reference: [24] <author> L. </author> <title> Numerical Algorithms Group, IRIS Explorer User's Guide, Release 3.0, </title> <year> 1995. </year>
Reference-contexts: For a more detailed discussion of DAQV, see [12]. 3.2. Viz: A Visualization Programming System. Creating meaningful visualizations for use in scientific problem solving is difficult [28]. General purpose visualization tools, such as Iris Explorer <ref> [24] </ref>, AVS [21], and Data Explorer [6], have been well received, but do not always provide the flexibility and robustness required for visualization design and specialization. Viz was created to support rapid visualization prototyping in a system that could be extended with application-specific visualization abstractions. <p> Two approaches were pursued: enhanced visualization and on-line analysis. Originally, models were evaluated using 2D visualizations produced by MatLab. The seismologists could gain a more comprehensive view of the models and more easily adjust constraints with 3D volumetric visualizations. We applied NAG's Iris Explorer <ref> [24] </ref> to generate model isosurfaces, but found that data model and formatting incompatibilities between Iris Explorer and MatLab made it difficult to merge the two tools. 5 We began using Viz to overcome these difficulties, and quickly found that its programming flexibility and abstraction capabilities allowed the seismologists to be even
Reference: [25] <author> C. Queinnec, </author> <title> Meroon V3: A Small, Efficient, and Enhanced Object System, </title> <type> Tech. Report URA 1439, </type> <institution> Ecole Polytechnique & INRIA-Rocquencourt, </institution> <year> 1996. </year>
Reference-contexts: Our original application domain was parallel program and performance data visualization [11, 13, 16, 17]. Viz is a visualization programming environment built on an interpreted, high-level language (Scheme [19, 8]) with object extensions (Meroon <ref> [25] </ref>). It embeds a 3D graphics library (Open Inventor [30]), adding higher-level abstractions for glyphs, composition, and data representations.
Reference: [26] <author> S. Shende, J. Cuny, L. Hansen, J. Kundu, S. McLaughry, and O. Wolf, </author> <title> Event- and State-Based Debugging in TAU: A Prototype, </title> <booktitle> in Proc. of SPDT'96: Sigmetrics Symp. on Parallel and Distributed Tools, </booktitle> <month> May </month> <year> 1996, </year> <pages> pp. 21-30. </pages>
Reference-contexts: Again, t provides a good example of this feature as tools can evoke integrated behavior via synchronized, communicated actions [4]. Often the need for interoperability also necessitates extension of the architecture infrastructure, as in the case of t 's program and interaction control infrastructure <ref> [26] </ref>. The three general features of programmability, extensibility, and interoperability have proven to be effective in our performance and debugging tools [22]. We speculate that these same capabilities will be useful in addressing the domain-specific aspects of computational science applications.
Reference: [27] <author> D. Toomey, S. Solomon, and G. M. Purdy, </author> <title> Tomographic Imaging of the East Pacific Rise Shallow Crustal Structure at 9 ffi 30 0 n, </title> <journal> Journal of Geophysical Research, </journal> <volume> 99 (1994), </volume> <pages> pp. </pages> <month> 135-24,152. </month>
Reference-contexts: For the forward calculation, we determine synthetic travel times and seismic ray paths through a velocity model represented as a 3D grid of nodes <ref> [27] </ref>. The grid is used to construct a graph by imposing an adjacency template (or "forward star" of edges) at each of its nodes. The edges are assigned weights equal to the calculated travel times between their end points for the current velocity model.
Reference: [28] <author> L. Treinish, D. Butler, H. Senay, G. Grinstein, and S. Bryson, </author> <title> Grand Challenge Problems in Visualization Software, </title> <booktitle> in Proc. of Visualization '92, </booktitle> <editor> I. C. S. </editor> <publisher> Press, ed., </publisher> <month> Nov. </month> <year> 1992, </year> <pages> pp. 366-371. </pages>
Reference-contexts: For a more detailed discussion of DAQV, see [12]. 3.2. Viz: A Visualization Programming System. Creating meaningful visualizations for use in scientific problem solving is difficult <ref> [28] </ref>. General purpose visualization tools, such as Iris Explorer [24], AVS [21], and Data Explorer [6], have been well received, but do not always provide the flexibility and robustness required for visualization design and specialization.
Reference: [29] <author> E. Vera, </author> <title> The Structure of 0 to 0:2m:y: Old Oceanic Crust at 9 ffi n on the East Pacific Rise from Expqanded Spread Profiles, </title> <journal> Journal of Geophysical Research, </journal> <volume> 95 (1990), </volume> <pages> pp. </pages> <month> 15,529-15,556. </month>
Reference-contexts: Requirement: None. Initial models come from a collection of pre-existing models as determined by prior studies. Ours come from an earlier experiment that was able to produce fairly accurate 1D velocity profiles <ref> [29] </ref>. The environment could provide some facility for managing the associated input files for the initial model, but typically there are only a few such files and the needed support is not significant. Step 3: Verification of Experimental Setup.

References-found: 27

