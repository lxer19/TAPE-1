URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1993/tr-93-021.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1993.html
Root-URL: http://www.icsi.berkeley.edu
Title: CNS-1 Architecture Specication A Connectionist Network Supercomputer A Collaboration of the  
Author: Krste Asanovic-, James Beck, Tim Callahan Jerry Feldman, Bertrand Irissou, Brian Kingsbury Phil Kohn, John Lazzaro, Nelson Morgan, David Stoutamire and John Wawrzynek 
Date: April 1, 1993  
Affiliation: University of California, Berkeley and the International Computer Science Institute  
Pubnum: TR-93-021  
Abstract-found: 0
Intro-found: 1
Reference: [Asa93a] <author> K. Asanovic-. </author> <title> Torrent Architecture Manual, Internal document. </title> <institution> International Computer Science Institute and UC Berkeley, </institution> <year> 1993 </year>
Reference-contexts: Torrent also includes a serial diagnostic network interface used for bootstrapping and debugging. The Torrent processor for the CNS-1 is an instance of a more general design, described in the Torrent Architecture Manual <ref> [Asa93a] </ref>. Another instance of the same architecture is T0, to be fabricated before Torrent [Asa93b].
Reference: [Asa93b] <author> K. Asanovic-. </author> <title> T0 Reference Manual, Internal document. </title> <institution> International Computer Science Institute and UC Berkeley, </institution> <year> 1993 </year>
Reference-contexts: Torrent also includes a serial diagnostic network interface used for bootstrapping and debugging. The Torrent processor for the CNS-1 is an instance of a more general design, described in the Torrent Architecture Manual [Asa93a]. Another instance of the same architecture is T0, to be fabricated before Torrent <ref> [Asa93b] </ref>. T0 is designed without a network interface and will use conventional SRAM storage on a compute accelerator board for a workstation. 2.1.2 Instruction Execution Torrent initiates the execution of a 32b instruction every 8 ns (for a 125 MHz clock rate).
Reference: [Cal93] <author> T. Callahan. </author> <title> Network Interface Manual, Internal document. </title> <institution> UC Berkeley and International Computer Science Institute, </institution> <year> 1993. </year>
Reference: [CSS+91] <author> D. Culler, A. Sah, K. E. Schauser, T. von Eicken, and J. Wawrzynek. </author> <title> Fine-grain Parallelism with Minimal Hardware Support: A Compiler-Controlled Threaded Abstract Machine. </title> <booktitle> Proc. Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 164 175, </pages> <year> 1991. </year>
Reference-contexts: The context for compute threads is saved in call frames allocated from the heap. The Torrent hardware can support a variety of scheduling disciplines; we describe a scheme based on the TAM model <ref> [CSS+91] </ref>.
Reference: [Dal90] <author> W. J. Dally. </author> <title> Virtual-Channel Flow Control. </title> <booktitle> Proc. IEEE 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 60 68, </pages> <year> 1990. </year>
Reference-contexts: packets traveling vertically encounter slight delays, since on average there is less traffic in that direction. 2.3.7 Performance Although the concept of virtual channels was originally useful in preventing deadlock, Dally also showed that the use of virtual channels increases the utilization of the physical links, thereby increasing network throughput <ref> [Dal90] </ref>. Simulation of CNS-1 systems from 128 to 1024 nodes and with various traffic distributions have shown that the simple output buffering scheme described here has throughput and latency characteristics at least as good as the virtual channel/wormhole routing scheme described by Dally.
Reference: [DS86] <author> W. J. Dally and C. Seitz. </author> <title> The torus routing chip. </title> <journal> Journal of Distributed Computing, </journal> <volume> I(3):187 196, </volume> <year> 1986. </year>
Reference-contexts: However, the connection of the nodes into rings in the horizontal dimension makes deadlock possible unless proper precautions are taken, since there are now cycles present in the channel dependency graph <ref> [DS86] </ref>. The method recommended by Dally and Seitz in this situation is to map two or more virtual channels onto each physical channel, and then connect the virtual channels in such a way that no cycle is formed.
Reference: [DW89] <author> W. J. Dally and D. S. Wills. </author> <title> Universal Mechanisms for Concurrency. </title> <booktitle> PARLE-89, </booktitle> <pages> pages 19 33, </pages> <editor> Goos and Hartmanis, eds., </editor> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: This event handling is based on the active message model [vEC+92], with an arriving message triggering execution of a local event handler routine. This mechanism is similar in spirit to message-driven architectures <ref> [DW89] </ref>, but requires simpler hardware and decouples message handling from computation. A host computer and other devices connect to the processors of the CNS-1 through custom VLSI I/O nodes attached to an edge of the communications mesh.
Reference: [FLR92] <author> J. Feldman, C-C. Lim and T. Rauber. </author> <title> The Shared-Memory Language pSather on a Distributed-Memory Multiprocessor. </title> <booktitle> Second Workshop on Languages, Compilers and Run-Time Environments for Distributed-Memory Multiprocessors, </booktitle> <address> Boulder, CO, </address> <year> 1992. </year>
Reference-contexts: In addition, a Torrent assembler filter will be written to help in the development of the optimized libraries. Support for parallel languages on distributed memory machines is still very much a research issue. Current efforts to port our parallel version of Sather, called pSather <ref> [FLR92] </ref>, to the CM-5 should provide valuable lessons in this area. The CNS-1 hardware is simple, fast, and flexible, and should prove an interesting vehicle for further research into parallel languages.
Reference: [Ham90] <author> D. </author> <note> Hammerstrom. </note>
Reference-contexts: Implementations of this machine consist of 4 to 40 Texas Instruments TMS320C30 floating-point DSP chips connected via a ring of Xilinx programmable gate arrays, each implementing a simple two-register data pipeline. Several related efforts are underway to construct programmable digital neurocomputers, most notably the CNAPS chip from Adaptive Solutions <ref> [Ham90] </ref> and the MA-16 chip from Siemens [RBR+91]. Adaptive Solutions provides a SIMD array with 64 processing elements per chip, in a system with four chips on a board controlled by a common microcode sequencer.
References-found: 9

