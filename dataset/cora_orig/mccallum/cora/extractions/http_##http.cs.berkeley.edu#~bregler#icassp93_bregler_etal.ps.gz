URL: http://http.cs.berkeley.edu/~bregler/icassp93_bregler_etal.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~bregler/vaspeech.html
Root-URL: http://www.cs.berkeley.edu
Title: the task to recognize 10 isolated letters and used artificial markers on the lips. No
Author: Dodd and Campbell [], and Demorest and Bernstein Christian Benoit, Tahar Lallouache, Tayeb Moham-adi, and Christian Abry. [] M.E. Demorest and L.E. Bernstein. [] B. Dodd and R. Campbell. [] P. Haffner and A. Waibel. [] H. Hild and A. Waibel. K. Mase and A. Pentland. [] H. Ney. [] E. Petajan, B. Bischoff, D. Bodoff, . [] D.A. Pomerleau. [] D.E. Rumelhart, G.E. Hinton, and R.J. W illiams. Press, . [] David G. Stork, Greg Wolff, and Earl Levine. [] A. Waibel, T. Hanazawa, G. Hinton, K. Shikano, and K. Lang. [] B.P. Yuhas, M.H. Goldstein, and T.J. Sejnowski. Magazine, [] John B. Hampshire II and Alexander H. W aibel. 
Keyword: ACKNOWLEDGEMENTS  
Date: April 1992.  February 1992.  March 1989.  
Note: This measurements could also be  [2] did some valuable work in this area. 7. CONCLUSION AND FUTURE WORK  REFERENCES [1]  Hearing by Eye: The Psychology fo Lipreading. Lawrence Erlbaum Press, 1987.  (NIPS 4). Morgan Kaufmann,  To appear in Neural Information Processing Systems (NIPS 5). [7]  and N.M. Brooke.  PhD Thesis, CMU. CMU-CS-92-115,  IEEE Transactions on Neural Networks 1(2), June 1990.  
Pubnum: 37(3):328-339,  
Abstract: We have shown how a state-of-the-art speech recognition system can be improved by considering additional visual information for the recognition process. This is true for optimal recording conditions but even more for non-optimal recording conditions as they usually exist in real world applications. Experiments were performed on the connected letter recognition task, but similar results can be expected for continuous speech recognition as well. Work is in progress to integrate not only the time independent weight sharing but also position independent weight sharing for the visual TDNN, in order to locate and track the lips. We are also on the way to largely increase our database in order to achieve better recognition rates and to train speaker independently. Investigations of different approaches are still in progress in order to combine visual and acoustic features and to apply different preprocessing to the visual data. We appreciate the help from the DEC on campus research center (CEC) for the initial data acquisition. This research is sponsored in part by the Land Baden Wrttem-berg (Landesschwerpunktprogramm Neuroinformatik), and the National Science Foundation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Christian Benoit, Tahar Lallouache, Tayeb Moham-adi, and Christian Abry. </author> <title> A Set of French Visemes for Visual Speech Synthesis. Talking Machines: Theories, Models, and Designs, </title> <year> 1992. </year>
Reference: [2] <author> M.E. Demorest and L.E. Bernstein. </author> <title> Computational Explorations of Speechreading. </title> <booktitle> In Submission. </booktitle>
Reference: [3] <author> B. Dodd and R. Campbell. </author> <title> Hearing by Eye: The Psychology fo Lipreading. </title> <publisher> Lawrence Erlbaum Press, </publisher> <year> 1987. </year>
Reference: [4] <author> C.G. Fischer. </author> <title> Confusion among visually perceived consonants. </title> <journal> J. Speech Hearing Res., </journal> <volume> 11, </volume> <year> 1968. </year>
Reference: [5] <author> P. Haffner and A. Waibel. </author> <title> Multi-State Time Delay Neural Networks for Continuous Speech Recognition. </title> <booktitle> In Neural Information Processing Systems (NIPS 4). </booktitle> <publisher> Morgan Kaufmann, </publisher> <month> April </month> <year> 1992. </year>
Reference: [6] <author> H. Hild and A. Waibel. </author> <title> Connected Letter Recognition with a Multi-State Time Delay Neural Network. </title> <note> To appear in Neural Information Processing Systems (NIPS 5). </note>
Reference: [7] <author> K. Mase and A. Pentland. </author> <title> LIP READING: Automatic Visual Recognition of Spoken Words. </title> <booktitle> Proc. Image Understanding and Machine Vision, Optical Society of America, </booktitle> <month> June </month> <year> 1989. </year>
Reference: [8] <author> H. Ney. </author> <title> The Use of a OneStage Dynamic Programming Algorithm for Connected Word Recognition. </title> <booktitle> IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <month> April </month> <year> 1984. </year>
Reference: [9] <author> E. Petajan, B. Bischoff, D. Bodoff, </author> <title> and N.M. Brooke. An Improved Automatic Lipreading System to enhance Speech Recognition. </title> <booktitle> In ACM SIGCHI, </booktitle> <year> 1988. </year>
Reference: [10] <author> D.A. Pomerleau. </author> <title> Neural Network Perception for Mobile Robot Guidance. </title> <type> PhD Thesis, </type> <address> CMU. CMU-CS-92-115, </address> <month> February </month> <year> 1992. </year>
Reference: [11] <author> P.W. Rander. </author> <title> Facetracking Using a Template Based Approach. </title> <type> Personal Communication. </type>
Reference: [12] <author> D.E. Rumelhart, G.E. Hinton, and R.J. W illiams. </author> <title> Learning Internal Representations by Error Propagation. </title> <booktitle> Parallel Distributed Processing Vol. </booktitle> <volume> 1. </volume> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference: [13] <author> David G. Stork, Greg Wolff, and Earl Levine. </author> <title> Neural Network Lipreading System for Improved Speech Recognition. </title> <booktitle> In IJCNN, </booktitle> <month> June </month> <year> 1992. </year>
Reference: [14] <author> A. Waibel, T. Hanazawa, G. Hinton, K. Shikano, and K. Lang. </author> <title> Phoneme Recognition Using T ime-Delay Neural Networks. </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> 37(3) </volume> <pages> 328-339, </pages> <month> March </month> <year> 1989. </year>
Reference: [15] <author> B.P. Yuhas, M.H. Goldstein, and T.J. Sejnowski. </author> <title> Integration of Acoustic and Visual Speech Signals using Neural Networks. </title> <journal> IEEE Communications Magazine, </journal>

References-found: 15

