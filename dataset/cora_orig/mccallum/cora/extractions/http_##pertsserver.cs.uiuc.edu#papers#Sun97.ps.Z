URL: http://pertsserver.cs.uiuc.edu/papers/Sun97.ps.Z
Refering-URL: http://pertsserver.cs.uiuc.edu/papers/
Root-URL: http://www.cs.uiuc.edu
Title: c  
Author: flCopyright by Jun Sun 
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> C. L. Liu and J. W. Layland. </author> <title> Scheduling algorithms for multiprogramming in a hard-real-time environment. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 20(1) </volume> <pages> 46-61, </pages> <month> January </month> <year> 1973. </year>
Reference-contexts: describes a suite of schedulability analysis algorithms to determine whether every timing requirement of the system is met when threads in the system are scheduled via these techniques. 1.1 Background and Motivation The multiple concurrent execution threads in a real-time system are often modeled as a set of periodic tasks <ref> [1] </ref>. In a single-processor system, a periodic task is an infinite stream of execution requests with the interval between any two consecutive requests being no shorter than the period of the task. <p> In the context of fixed-priority scheduling, a rich set of solutions exist for scheduling uniprocessor real-time systems. There are several priority assignment methods that are optimal for various kinds of uniprocessor systems <ref> [1, 2, 3] </ref> and various schedulability analysis algorithms that verify if a system of periodic tasks scheduled according to a fixed-priority algorithm is schedulable [1, 4, 5, 6, 7, 8]. However, none of this work is suitable to solve the end-to-end scheduling problem. <p> There are several priority assignment methods that are optimal for various kinds of uniprocessor systems [1, 2, 3] and various schedulability analysis algorithms that verify if a system of periodic tasks scheduled according to a fixed-priority algorithm is schedulable <ref> [1, 4, 5, 6, 7, 8] </ref>. However, none of this work is suitable to solve the end-to-end scheduling problem. For example, according to the rate-monotonic priority assignment [1], all subtasks in a same parent task have the same priority, which is inversely proportional to the period. <p> However, none of this work is suitable to solve the end-to-end scheduling problem. For example, according to the rate-monotonic priority assignment <ref> [1] </ref>, all subtasks in a same parent task have the same priority, which is inversely proportional to the period. By doing so, we lose the freedom of assigning different priorities to different subtasks, and potentially decrease the schedulability of the system. <p> This is especially true for the solutions of the priority assignment problem and the schedulability analysis problem. 9 2.1.1 Uniprocessor Scheduling Theories Two related problems arise on fixed-priority scheduling of periodic tasks in a uniprocessor system: priority assignment and schedulability analysis. In their classic paper <ref> [1] </ref>, Liu and Layland proposed the rate-monotonic priority assignment for tasks with relative deadlines equal to their periods. <p> Since we focus on tasks with relative deadlines shorter than their periods, we can take a short-cut by only bounding the response time of the first instance of T i;j in a i;j -level busy period <ref> [1] </ref>. If the bound is smaller than the relative deadline, which is no greater than the period of T i;j , and all other tasks are schedulable, the bound is correct. <p> Due to the property of sporadic servers, doing so does not hurt the response times of other subtasks. 5.5 Schedulability Analysis for the DS Protocol In a system that uses the DS protocol, the time demand analysis for periodic task systems <ref> [1, 5, 6] </ref> cannot be used directly to obtain a bound on the response time of each subtask. Several instances 63 of a higher-priority subtask may execute back-to-back consecutively or rather closely together in time, a phenomenon called the clumping effect. <p> According to the MPCP, the blocking time of a task due to both local resource contention and global resource contention is bounded, and the schedulability of the system can be determined by applying a schedulability analysis method for single-processor systems <ref> [1, 5] </ref> on each individual processor. 100 8.2 System Model In Rajkumar's system model, every resource and every task has a host processor. (In [21], the host processor of a global resource is called a synchronization processor of the global resource.) Later in this chapter, when we say a task T <p> 1 3 2 1 0 0 0 T 3 P 2 3 0 0 0 0 3 Table 8.3: Blocking Times of Tasks in Example 1 8.3.3 Schedulability Analysis The schedulability analysis of the MPCP approach is based on the single-processor schedulability analysis, which can be the utilization bound analysis <ref> [1] </ref> or the more accurate time demand 107 analysis [5, 17]. According to the time demand analysis, the upper bound R i on the response time of T i can be obtained from the following equation. <p> different priorities and the priority of a subtask instance may change during the course of its execution. (In practice, the second case of the dynamic-priority scheduling rarely happens because of the overhead of such an algorithm.) The first case of the dynamic-priority scheduling, such as the Earliest Deadline First (EDF) <ref> [1] </ref>, is commonly used on a single-processor system. In a distributed real-time system, Kao et al. [11, 12] have studied various issues in the context where tasks have soft (end-to-end) deadlines and are scheduled on a dynamic-priority basis. Many problems arise when tasks have hard end-to-end deadlines.
Reference: [2] <author> J. Leung and J. Whitehead. </author> <title> On the complexity of fixed-priority scheduling of periodic, real-time tasks. Performance Evaluation, </title> <booktitle> 2 </booktitle> <pages> 237-250, </pages> <year> 1982. </year>
Reference-contexts: In the context of fixed-priority scheduling, a rich set of solutions exist for scheduling uniprocessor real-time systems. There are several priority assignment methods that are optimal for various kinds of uniprocessor systems <ref> [1, 2, 3] </ref> and various schedulability analysis algorithms that verify if a system of periodic tasks scheduled according to a fixed-priority algorithm is schedulable [1, 4, 5, 6, 7, 8]. However, none of this work is suitable to solve the end-to-end scheduling problem. <p> The schedulability can be verified by comparing the sum of the total utilization factor of the tasks with a single utilization bound. Leung and Whithead <ref> [2] </ref> looked into the cases where tasks may have arbitrary relative deadlines. They proposed deadline-monotonic priority assignment, which is an optimal priority assignment among fixed-priority assignments as long as the relative deadlines are shorter than their respective periods. <p> The optimum priority assignment method for an MPCP system is deadline-monotonic assignment, i.e., the priority of a task is inversely proportional to its relative deadline <ref> [2] </ref>. In the rest of this chapter, we assume deadline-monotonic priority assignment for tasks in an MPCP system. According to the MPCP, each global critical section of a task, accessing either local global resources or remote resources, corresponds to a GCS server. The GCS servers have fixed priorities as well.
Reference: [3] <author> N. C. Audsley. </author> <title> Optimal priority assignment and feasibility of static priority tasks with arbitrary start times. </title> <type> Technical Report YCS 164, </type> <institution> Dept. of Computer Science, University of York, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: In the context of fixed-priority scheduling, a rich set of solutions exist for scheduling uniprocessor real-time systems. There are several priority assignment methods that are optimal for various kinds of uniprocessor systems <ref> [1, 2, 3] </ref> and various schedulability analysis algorithms that verify if a system of periodic tasks scheduled according to a fixed-priority algorithm is schedulable [1, 4, 5, 6, 7, 8]. However, none of this work is suitable to solve the end-to-end scheduling problem. <p> They proposed deadline-monotonic priority assignment, which is an optimal priority assignment among fixed-priority assignments as long as the relative deadlines are shorter than their respective periods. For tasks with relative deadlines longer than their periods, both the rate-monotonic assignment and deadline-monotonic assignment are not optimal. Audsley <ref> [3] </ref> devised a pseudo-polynomial algorithm that finds a feasible priority assignment if one exists. On schedulability analysis, Joseph and Pandya [4] proposed an algorithm to compute the response time of a task instance which is released at the same time as the instances of all other tasks. <p> A budget replenishment is scheduled at time 7 with 0.5 time unit. We then decrease s f b (t) by 0.5 for t 2 <ref> [3; 4] </ref>, and time 4 becomes the first non-zero point in the free budget function. Since we still have 1.5 time units of "undeclared" request, we repeat the above process and eventually schedule another budget replenishment with 0.5 time unit at time 8.
Reference: [4] <author> M. Joseph and P. Pandya. </author> <title> Finding response times in a real-time system. </title> <journal> The Computer Journal of the British Computer Society, </journal> <volume> 29(5) </volume> <pages> 390-395, </pages> <month> October </month> <year> 1986. </year>
Reference-contexts: There are several priority assignment methods that are optimal for various kinds of uniprocessor systems [1, 2, 3] and various schedulability analysis algorithms that verify if a system of periodic tasks scheduled according to a fixed-priority algorithm is schedulable <ref> [1, 4, 5, 6, 7, 8] </ref>. However, none of this work is suitable to solve the end-to-end scheduling problem. For example, according to the rate-monotonic priority assignment [1], all subtasks in a same parent task have the same priority, which is inversely proportional to the period. <p> For tasks with relative deadlines longer than their periods, both the rate-monotonic assignment and deadline-monotonic assignment are not optimal. Audsley [3] devised a pseudo-polynomial algorithm that finds a feasible priority assignment if one exists. On schedulability analysis, Joseph and Pandya <ref> [4] </ref> proposed an algorithm to compute the response time of a task instance which is released at the same time as the instances of all other tasks. This response time is the worst-case response time of the task if it is no greater than the period. <p> A budget replenishment is scheduled at time 7 with 0.5 time unit. We then decrease s f b (t) by 0.5 for t 2 <ref> [3; 4] </ref>, and time 4 becomes the first non-zero point in the free budget function. Since we still have 1.5 time units of "undeclared" request, we repeat the above process and eventually schedule another budget replenishment with 0.5 time unit at time 8.
Reference: [5] <author> J. Lehoczky, L. Sha, and Y. Ding. </author> <title> The rate monotonic scheduling algorithm: Exact characterization and average case behavior. </title> <booktitle> In IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 166-171, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: There are several priority assignment methods that are optimal for various kinds of uniprocessor systems [1, 2, 3] and various schedulability analysis algorithms that verify if a system of periodic tasks scheduled according to a fixed-priority algorithm is schedulable <ref> [1, 4, 5, 6, 7, 8] </ref>. However, none of this work is suitable to solve the end-to-end scheduling problem. For example, according to the rate-monotonic priority assignment [1], all subtasks in a same parent task have the same priority, which is inversely proportional to the period. <p> This response time is the worst-case response time of the task if it is no greater than the period. Lehoczky <ref> [5] </ref> proposed a sufficient and necessary test to verify the schedulability of tasks if the relative deadline of the task is no greater than its period. <p> In the second half of this chapter, we present an algorithm that bounds the EER times of tasks in a system using the DS protocol. All these algorithms are based on a technique called busy period analysis, which was first proposed by Lehoczky <ref> [5, 6] </ref> and later extended by Audsley [7], Tindell [8, 19, 53], and Burns [17]. <p> Due to the property of sporadic servers, doing so does not hurt the response times of other subtasks. 5.5 Schedulability Analysis for the DS Protocol In a system that uses the DS protocol, the time demand analysis for periodic task systems <ref> [1, 5, 6] </ref> cannot be used directly to obtain a bound on the response time of each subtask. Several instances 63 of a higher-priority subtask may execute back-to-back consecutively or rather closely together in time, a phenomenon called the clumping effect. <p> According to the MPCP, the blocking time of a task due to both local resource contention and global resource contention is bounded, and the schedulability of the system can be determined by applying a schedulability analysis method for single-processor systems <ref> [1, 5] </ref> on each individual processor. 100 8.2 System Model In Rajkumar's system model, every resource and every task has a host processor. (In [21], the host processor of a global resource is called a synchronization processor of the global resource.) Later in this chapter, when we say a task T <p> P 2 3 0 0 0 0 3 Table 8.3: Blocking Times of Tasks in Example 1 8.3.3 Schedulability Analysis The schedulability analysis of the MPCP approach is based on the single-processor schedulability analysis, which can be the utilization bound analysis [1] or the more accurate time demand 107 analysis <ref> [5, 17] </ref>. According to the time demand analysis, the upper bound R i on the response time of T i can be obtained from the following equation.
Reference: [6] <author> J. Lehoczky. </author> <title> Fixed priority scheduling of periodic task sets with arbitrary deadlines. </title> <booktitle> In 11th IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 201-209, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: There are several priority assignment methods that are optimal for various kinds of uniprocessor systems [1, 2, 3] and various schedulability analysis algorithms that verify if a system of periodic tasks scheduled according to a fixed-priority algorithm is schedulable <ref> [1, 4, 5, 6, 7, 8] </ref>. However, none of this work is suitable to solve the end-to-end scheduling problem. For example, according to the rate-monotonic priority assignment [1], all subtasks in a same parent task have the same priority, which is inversely proportional to the period. <p> Lehoczky [5] proposed a sufficient and necessary test to verify the schedulability of tasks if the relative deadline of the task is no greater than its period. For tasks whose response times and relative deadlines are longer than the periods, Lehoczky <ref> [6] </ref> formulated the concept of an i-level busy period to analyze the worst-case behavior of a task. <p> In the second half of this chapter, we present an algorithm that bounds the EER times of tasks in a system using the DS protocol. All these algorithms are based on a technique called busy period analysis, which was first proposed by Lehoczky <ref> [5, 6] </ref> and later extended by Audsley [7], Tindell [8, 19, 53], and Burns [17]. <p> In this thesis, we assume that the response time of a subtask may be longer than its period, unless stated otherwise. Given a set of periodic subtasks on each processor, the busy period analysis <ref> [6] </ref> can be readily applied to obtain an upper bound on the response time of each subtask. In [6], Lehoczky presented an analysis algorithm as a sufficient condition. Below we describe his algorithm in consistency with the busy period analysis method presented in the previous section. <p> Given a set of periodic subtasks on each processor, the busy period analysis <ref> [6] </ref> can be readily applied to obtain an upper bound on the response time of each subtask. In [6], Lehoczky presented an analysis algorithm as a sufficient condition. Below we describe his algorithm in consistency with the busy period analysis method presented in the previous section. In the following discussion, we focus on T i;j , the subtask whose response time is to be bounded. <p> bounds on task EER times by using an improved algorithm, called Algorithm SA/IPM, rather than by using Algorithm SA/PM. * Some tasks are recurrent. * The relative deadline of each task is shorter than or equal to its period. 2 This example is extracted and modified from an example in <ref> [6] </ref> by Lehoczky. 46 Algorithm SA/PM Input : Subtask set fT i;j g and the subtask parameters. Output : For each task T i , the bound R i on its end-to-end response time. Algorithm : 1. <p> Due to the property of sporadic servers, doing so does not hurt the response times of other subtasks. 5.5 Schedulability Analysis for the DS Protocol In a system that uses the DS protocol, the time demand analysis for periodic task systems <ref> [1, 5, 6] </ref> cannot be used directly to obtain a bound on the response time of each subtask. Several instances 63 of a higher-priority subtask may execute back-to-back consecutively or rather closely together in time, a phenomenon called the clumping effect. <p> This requirement is rather demanding and brings down the usable processor utilization in order satisfy it. Lehoczky found similar phenomena in <ref> [6] </ref>. For example, in his study, if tasks have deadlines equal to 1/4 of their periods, the schedulable utilization bound drops to 25%. For configurations with nonzero success rates, we list the worst-case schedulability index ratios in Table 7.5 and the average schedulability index ratios in Table 7.6. <p> The above method for computing the upper bound on the response time of a task gives the correct answer if the upper bound is less than the period. It may give a wrong answer if the upper bound is greater than the period <ref> [6] </ref>. For the purpose of verifying the schedulability of a task, however, we obtain the same conclusion as if we would with the correct upper bound, because this incorrect upper bound is greater than the period of the task and hence the relative deadline of the task.
Reference: [7] <author> N. Audsley, A. Burns, K. Tindell, M. Richardson, and A. Wellings. </author> <title> Applying new scheduling theory to static priority pre-emptive scheduling. </title> <journal> Software Engineering Journal, </journal> <volume> 8(5) </volume> <pages> 284-292, </pages> <year> 1993. </year>
Reference-contexts: There are several priority assignment methods that are optimal for various kinds of uniprocessor systems [1, 2, 3] and various schedulability analysis algorithms that verify if a system of periodic tasks scheduled according to a fixed-priority algorithm is schedulable <ref> [1, 4, 5, 6, 7, 8] </ref>. However, none of this work is suitable to solve the end-to-end scheduling problem. For example, according to the rate-monotonic priority assignment [1], all subtasks in a same parent task have the same priority, which is inversely proportional to the period. <p> For tasks whose response times and relative deadlines are longer than the periods, Lehoczky [6] formulated the concept of an i-level busy period to analyze the worst-case behavior of a task. The busy period analysis method was further extended by Audsley et al. <ref> [7, 8, 17] </ref> to account for bursty activities, various blocking times, and release jitters. 2.1.2 End-to-End Scheduling Theories We have not seen much work on fixed-priority scheduling of periodic tasks with end-to-end deadlines. <p> All these algorithms are based on a technique called busy period analysis, which was first proposed by Lehoczky [5, 6] and later extended by Audsley <ref> [7] </ref>, Tindell [8, 19, 53], and Burns [17]. <p> In their approach, the irregular release times are called release jitters, and the extra interference to a target subtask caused by release jitters is counted in their extended busy period analysis method <ref> [7, 8] </ref>. The release jitters are propagated along the subtask chains. The response time of each subtask is thus bounded and the bound on the EER time of each task is simply the sum of the bounds on the response times of all its subtasks.
Reference: [8] <author> K. W. Tindell, A. Burns, and A. J. Wellings. </author> <title> An extendible approach for analyzing fixed priority hard real-time tasks. </title> <booktitle> Real-Time Systems, </booktitle> <volume> 6(2) </volume> <pages> 133-152, </pages> <month> March </month> <year> 1994. </year> <month> 157 </month>
Reference-contexts: There are several priority assignment methods that are optimal for various kinds of uniprocessor systems [1, 2, 3] and various schedulability analysis algorithms that verify if a system of periodic tasks scheduled according to a fixed-priority algorithm is schedulable <ref> [1, 4, 5, 6, 7, 8] </ref>. However, none of this work is suitable to solve the end-to-end scheduling problem. For example, according to the rate-monotonic priority assignment [1], all subtasks in a same parent task have the same priority, which is inversely proportional to the period. <p> For tasks whose response times and relative deadlines are longer than the periods, Lehoczky [6] formulated the concept of an i-level busy period to analyze the worst-case behavior of a task. The busy period analysis method was further extended by Audsley et al. <ref> [7, 8, 17] </ref> to account for bursty activities, various blocking times, and release jitters. 2.1.2 End-to-End Scheduling Theories We have not seen much work on fixed-priority scheduling of periodic tasks with end-to-end deadlines. <p> All these algorithms are based on a technique called busy period analysis, which was first proposed by Lehoczky [5, 6] and later extended by Audsley [7], Tindell <ref> [8, 19, 53] </ref>, and Burns [17]. Before we present the schedulability analysis algorithms, we introduce the notation used in the busy period analysis and describe this technique under the context of the end-to-end scheduling. 40 5.1 Busy Period Analysis The busy period analysis method is also called time demand analysis. <p> In their approach, the irregular release times are called release jitters, and the extra interference to a target subtask caused by release jitters is counted in their extended busy period analysis method <ref> [7, 8] </ref>. The release jitters are propagated along the subtask chains. The response time of each subtask is thus bounded and the bound on the EER time of each task is simply the sum of the bounds on the response times of all its subtasks. <p> However, although the release jitters of the interfering subtasks (i.e., subtasks that are in H i;j ) are correctly taken into account in their approach, release jitters of the target subtask are not taken into account. Tindell et al. assumed that the target subtask is periodic <ref> [8] </ref>. This is only true for the first subtask in each end-to-end task. When a target subtask (T i;j ) is not the first subtask, T i;j itself has release jitter. <p> In an extreme case, several instances of T i;j may be released closely together in time, and the worst-case response time of T i;j is longer than the one when T i;j is periodic, which is obtained by the method in <ref> [8] </ref>. Since the approach proposed in [19] uses the 74 method in [8] to obtain an upper bound on the response time of a subtask, we expect that in general Tindell's approach will not yield correct upper bounds on the end-to-end response times of tasks. 5.6 Summary In a system using <p> case, several instances of T i;j may be released closely together in time, and the worst-case response time of T i;j is longer than the one when T i;j is periodic, which is obtained by the method in <ref> [8] </ref>. Since the approach proposed in [19] uses the 74 method in [8] to obtain an upper bound on the response time of a subtask, we expect that in general Tindell's approach will not yield correct upper bounds on the end-to-end response times of tasks. 5.6 Summary In a system using a synchronization protocol with execution control, (e.g., one of the PM, MPM,
Reference: [9] <author> K. Tindell, A. Burns, and A. Wellings. </author> <title> Allocating real-time tasks. An NP-hard problem made easy. </title> <journal> Real-Time Systems Journal, </journal> <volume> 4(2), </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: Existing work on fixed-priority end-to-end scheduling either does not address these problems together or addresses them inadequately. For example, Tindell et al. <ref> [9, 10] </ref> discussed the priority assignment problem in an end-to-end system, but they ignored the execution synchronization and schedulability analysis problems. Kao et al. [11, 12] studied the end-to-end scheduling problem in soft real-time systems, where the possibility of a task missing deadlines is minimized but allowed. <p> Optimization-Based Methods In recent years, we have seen several research efforts on the priority assignment problem in an end-to-end system. Tindell et al. <ref> [9] </ref> used the simulated annealing technique to find a feasible priority assignment and a feasible load partition at the same time. An improved algorithm, in terms of efficiency and the likelihood of finding a feasible solution, was proposed by Garcia and Harbour [10]. Their algorithm is called Algorithm HOPA.
Reference: [10] <author> J. Garcia and M. Harbour. </author> <title> Optimized priority assignment for tasks and messages in distributed hard real-time systems. </title> <booktitle> In The Third Workshop on Parallel and Distributed Real-Time Systems, </booktitle> <pages> pages 124-132, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: Existing work on fixed-priority end-to-end scheduling either does not address these problems together or addresses them inadequately. For example, Tindell et al. <ref> [9, 10] </ref> discussed the priority assignment problem in an end-to-end system, but they ignored the execution synchronization and schedulability analysis problems. Kao et al. [11, 12] studied the end-to-end scheduling problem in soft real-time systems, where the possibility of a task missing deadlines is minimized but allowed. <p> Our approach, presented in Chapter 5, takes this factor into account, and yields correct results. Tindell et al. [19] studied the priority assignment problem in a distributed system where tasks have end-to-end deadlines. Garcia and Harbour <ref> [10] </ref> proposed a refined solution to a similar problem. This work complements our work on heuristic priority assignment methods. Bettati [13] studied the problem of scheduling a set of tasks with arbitrary release times and end-to-end deadlines in a flow-shop system. <p> Tindell et al. [9] used the simulated annealing technique to find a feasible priority assignment and a feasible load partition at the same time. An improved algorithm, in terms of efficiency and the likelihood of finding a feasible solution, was proposed by Garcia and Harbour <ref> [10] </ref>. Their algorithm is called Algorithm HOPA. Both approaches start with a random priority assignment or a priority assignment according to a basic assignment method, and then continually adjust the assignment until a feasible solution is found. A certain criterion is used in directing the adjustment of priorities. <p> The performance of deadline-based methods were studied by Kao and Garcia-Molina [11] in the context of soft real-time scheduling. In Chapter 7, we will compare their performance in the 81 context of end-to-end scheduling. In <ref> [10] </ref>, Garcia and Harbour provided some insight into the performance of optimization-based methods. 82 Chapter 7 Performance of End-to-End Scheduling Algorithms From the previous three chapters, we see that end-to-end scheduling is a family of scheduling algorithms. We described four deadline-based heuristic methods to assign priorities to subtasks.
Reference: [11] <author> B. Kao and H. Garcia-Molina. </author> <title> Deadline assignment in a distributed soft real-time system. </title> <booktitle> In The 13th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 428-437, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Existing work on fixed-priority end-to-end scheduling either does not address these problems together or addresses them inadequately. For example, Tindell et al. [9, 10] discussed the priority assignment problem in an end-to-end system, but they ignored the execution synchronization and schedulability analysis problems. Kao et al. <ref> [11, 12] </ref> studied the end-to-end scheduling problem in soft real-time systems, where the possibility of a task missing deadlines is minimized but allowed. Consequently, the schedulability of a system is expressed by a statistical value rather than a true/false assertion. Bettati addressed all three problems in his Ph.D. dissertation [13]. <p> Obviously, this assignment is not optimal. As a matter of fact, as we will see in Chapter 7, the performance of this assignment is in general inferior to other heuristic methods. 78 Deadline-based methods Kao and Garcia-Molina <ref> [11] </ref> studied the deadline-based priority assignment in the context of a soft real-time system. According to the deadline-based method, we assign a relative deadline to each subtask and then assign to a subtask a priority inversely proportional to its relative deadline. A shorter relative deadline implies a higher priority. <p> Heuristic methods are thus developed. These methods can be classified into three categories: rate-based method, deadline-based methods and optimization-based methods. The performance of deadline-based methods were studied by Kao and Garcia-Molina <ref> [11] </ref> in the context of soft real-time scheduling. In Chapter 7, we will compare their performance in the 81 context of end-to-end scheduling. <p> In a distributed real-time system, Kao et al. <ref> [11, 12] </ref> have studied various issues in the context where tasks have soft (end-to-end) deadlines and are scheduled on a dynamic-priority basis. Many problems arise when tasks have hard end-to-end deadlines.
Reference: [12] <author> B. Kao, H. Garcia-Molina, and B. Adelberg. </author> <title> On building distributed soft real-time systems. </title> <booktitle> In The Third Workshop on Parallel and Distributed Real-Time Systems, </booktitle> <pages> pages 13-19, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: Existing work on fixed-priority end-to-end scheduling either does not address these problems together or addresses them inadequately. For example, Tindell et al. [9, 10] discussed the priority assignment problem in an end-to-end system, but they ignored the execution synchronization and schedulability analysis problems. Kao et al. <ref> [11, 12] </ref> studied the end-to-end scheduling problem in soft real-time systems, where the possibility of a task missing deadlines is minimized but allowed. Consequently, the schedulability of a system is expressed by a statistical value rather than a true/false assertion. Bettati addressed all three problems in his Ph.D. dissertation [13]. <p> In a distributed real-time system, Kao et al. <ref> [11, 12] </ref> have studied various issues in the context where tasks have soft (end-to-end) deadlines and are scheduled on a dynamic-priority basis. Many problems arise when tasks have hard end-to-end deadlines.
Reference: [13] <author> R. Bettati. </author> <title> End-to-End Scheduling to Meet Deadlines in Distributed Systems. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1994. </year>
Reference-contexts: Consequently, the schedulability of a system is expressed by a statistical value rather than a true/false assertion. Bettati addressed all three problems in his Ph.D. dissertation <ref> [13] </ref>. He proposed a solution for the execution synchronization problem, together with schedulability analysis algorithms, but full exploration of these problems is left open in his thesis. <p> We demonstrate that in the context of end-to-end scheduling the priority assignment problem is "NP-hard". We then propose several heuristic assignment methods. We present five synchronization protocols that govern the release and the execution of subtasks, including the one proposed by Bettati <ref> [13] </ref>, as solutions to the execution synchronization problem. Several schedulability analysis algorithms are developed for end-to-end systems that use different priority assignment methods and different synchronization protocols. <p> Tindell et al. [19] studied the priority assignment problem in a distributed system where tasks have end-to-end deadlines. Garcia and Harbour [10] proposed a refined solution to a similar problem. This work complements our work on heuristic priority assignment methods. Bettati <ref> [13] </ref> studied the problem of scheduling a set of tasks with arbitrary release times and end-to-end deadlines in a flow-shop system. He then extended this work to the scheduling of periodic flow-shop tasks. His Phase Modification technique is incorporated as one of the synchronization protocols in this thesis. <p> However, the performance of the MPCP is sometimes poor. Bettati recognized that the problem addressed by the MPCP can be solved by an end-to-end scheduling based approach <ref> [13] </ref>, but did not explore this direction of research further. <p> A similar but more restricted model, called the flow-shop model, where all tasks have the same orders, was studied and extended to end-to-end real-time scheduling by Bettati <ref> [13] </ref>. Like many other works in classical scheduling, efforts on job-shop scheduling problems have concentrated on minimizing the length of the schedule for a static workload. Johnson [41] provided an algorithm to find a minimum length schedule for a flow-shop system with two processors in O (n log n) time. <p> These shortcomings motivated us to design new protocols presented in the rest of this section. 27 4.2.2 Phase Modification (PM) Protocol The Phase Modification protocol was proposed by Bettati <ref> [13] </ref> to schedule periodic flow-shop tasks. The Phase Modification protocol, or the PM protocol, requires that we first bound the worst-case response time of each subtask T i;j . Let R i;j denote an upper bound on the response time of T i;j . <p> We now describe how to compute the interference function M i;j i (t) of a parent task to its subtask T i;j , or more accurately speaking, the interference from the sibling subtasks of T i;j . In <ref> [13] </ref>, Bettati argued that if T i is schedulable, no instances of sibling subtasks of T i;j can be released in the interval between the release and completion of an instance of T i;j . <p> It is easy to verify that according to every synchronization protocol and applicable schedulability analysis algorithm proposed in this thesis, we obtain the same upper bound on the EER time of T 1 , which 1 This proof was inspired by a similar proof given by Bettati in <ref> [13] </ref>. 77 is S + S i 2fS i gA S i , and the same upper bound on the EER time of T 2 , which is S + P Given that P S j 2A S i = S=2, both bounds are equal 1:5S, and both tasks will be
Reference: [14] <author> R. Rajkumar. </author> <title> Real-time synchronization protocols for shared memory multiprocessors. </title> <booktitle> In Proceedings: The 10th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 116-123, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: In this thesis we propose an end-to-end scheduling based approach to the resource contention problem. Compared with the existing solution, known as the Multiprocessor Priority Ceiling Protocol (MPCP) <ref> [14] </ref>, the end-to-end scheduling approach is more flexible and yields better performance in most cases. 1.3 Organization of the Thesis In Chapter 2, we provide an overview of the related work.
Reference: [15] <author> L. Sha, R. Rajkumar, and J. P. Lehoczky. </author> <title> Priority inheritance protocols: An approach to real-time synchronization. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(9) </volume> <pages> 1175-1185, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Specifically, the schedulability analysis algorithms in this thesis owe their fundamental techniques to those for uniprocessor systems. The end-to-end scheduling approach to the resource contention problem builds on the Priority Ceiling Protocol (PCP) <ref> [15] </ref> and the Stack Based Protocol (SBP) [16] for a uniprocessor system, and is related to the MPCP for a distributed or multiprocessor system. <p> This is closely related to previous work on the resource contention problem in a uniprocessor system or a multiprocessor system. In a real-time system, the exclusive access to a resource is typically achieved by semaphore-like operations. Sha <ref> [15] </ref> and Rajkumar [20] have shown that careless use of semaphores can lead to unpredictable timing behavior in a real-time system and a resource access control protocol 11 is needed to keep the blocking times of tasks bounded. <p> Moreover, the blocking times of tasks can be easily taken into account in the schedulability analysis. For a uniprocessor system, Sha et al. <ref> [15] </ref> developed the Priority Ceiling Protocol (PCP). According to the PCP, the blocking time that each task instance can experience is no more than the duration of one critical section of a lower-priority task. <p> Finally, we conclude this chapter by comparing the performance of these two approaches. 8.1 Background Semaphore-like operations are typically used to control the access to a shared resource by tasks in order to guarantee mutually-exclusive accesses to critical sections. Sha et al. <ref> [15] </ref> have shown that careless use of semaphore operations can cause uncontrolled priority inversion, which occurs when a high-priority task is blocked by some low-priority tasks for an unpredictable amount of time. <p> To ensure predictability, it is imperative to keep the blocking time of each task bounded from above [20]. Several effective solutions have been proposed for single-processor systems; two well-known examples are the Priority Ceiling Protocol (PCP) <ref> [15] </ref> and the Stack Based Protocol (SBP) [16]. By using either one of the protocols, the blocking time of each task is guaranteed to be no more than the duration of one critical section of some other tasks. <p> A resource access control protocol for single-processor systems, such as the PCP <ref> [15] </ref> or the SBP [16], is used to control their accesses to the resources.
Reference: [16] <author> T. P. Baker. </author> <title> A stack-based resource allocation policy for real-time processes. </title> <booktitle> In 11th IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 191-200, </pages> <year> 1990. </year>
Reference-contexts: Specifically, the schedulability analysis algorithms in this thesis owe their fundamental techniques to those for uniprocessor systems. The end-to-end scheduling approach to the resource contention problem builds on the Priority Ceiling Protocol (PCP) [15] and the Stack Based Protocol (SBP) <ref> [16] </ref> for a uniprocessor system, and is related to the MPCP for a distributed or multiprocessor system. <p> For a uniprocessor system, Sha et al. [15] developed the Priority Ceiling Protocol (PCP). According to the PCP, the blocking time that each task instance can experience is no more than the duration of one critical section of a lower-priority task. Baker <ref> [16] </ref> developed the Stack Based Protocol (SBP) which gives the same upper bound on the blocking time of each task as with the PCP. In addition, the SBP is applicable to both fixed-priority scheduling and dynamic-priority scheduling. <p> To ensure predictability, it is imperative to keep the blocking time of each task bounded from above [20]. Several effective solutions have been proposed for single-processor systems; two well-known examples are the Priority Ceiling Protocol (PCP) [15] and the Stack Based Protocol (SBP) <ref> [16] </ref>. By using either one of the protocols, the blocking time of each task is guaranteed to be no more than the duration of one critical section of some other tasks. In multiprocessor or distributed systems, concurrency and distribution complicate the resource contention problem. <p> A resource access control protocol for single-processor systems, such as the PCP [15] or the SBP <ref> [16] </ref>, is used to control their accesses to the resources. As a consequence of using such a resource access control protocol, we can bound the blocking time that a GCS server can experience due to global resource contention or that a task can experience due to local resource contention.
Reference: [17] <author> A. Burns, K. Tindell, and A. J. Wellings. </author> <title> Fixed priority scheduling with deadlines prior to completion. </title> <booktitle> In Sixth Euromicro Workshop on Real-Time Systems, </booktitle> <pages> pages 138-142, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: For tasks whose response times and relative deadlines are longer than the periods, Lehoczky [6] formulated the concept of an i-level busy period to analyze the worst-case behavior of a task. The busy period analysis method was further extended by Audsley et al. <ref> [7, 8, 17] </ref> to account for bursty activities, various blocking times, and release jitters. 2.1.2 End-to-End Scheduling Theories We have not seen much work on fixed-priority scheduling of periodic tasks with end-to-end deadlines. <p> All these algorithms are based on a technique called busy period analysis, which was first proposed by Lehoczky [5, 6] and later extended by Audsley [7], Tindell [8, 19, 53], and Burns <ref> [17] </ref>. Before we present the schedulability analysis algorithms, we introduce the notation used in the busy period analysis and describe this technique under the context of the end-to-end scheduling. 40 5.1 Busy Period Analysis The busy period analysis method is also called time demand analysis. <p> P 2 3 0 0 0 0 3 Table 8.3: Blocking Times of Tasks in Example 1 8.3.3 Schedulability Analysis The schedulability analysis of the MPCP approach is based on the single-processor schedulability analysis, which can be the utilization bound analysis [1] or the more accurate time demand 107 analysis <ref> [5, 17] </ref>. According to the time demand analysis, the upper bound R i on the response time of T i can be obtained from the following equation.
Reference: [18] <author> S. Chatterjee and J. Strosnider. </author> <title> Distributed pipeline scheduling: End-to-end analysis of heterogeneous, </title> <booktitle> multi-resource real-time systems. In The 15th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 204-211, </pages> <month> May </month> <year> 1995. </year> <month> 158 </month>
Reference-contexts: A common approach to this problem is to decompose an end-to-end system into a set of uniprocessor systems <ref> [18] </ref> and then apply some existing real-time scheduling algorithms for uniprocessor systems. By doing so, an integrated end-to-end scheduling framework is not needed. However, two issues are not addressed. The first issue is how subtasks in the same task 10 communicate and synchronize with each other.
Reference: [19] <author> K. Tindell and J. Clark. </author> <title> Holistic schedulability analysis for distributed hard real-time sys-tems. </title> <journal> Microprocessing and Microprogramming, </journal> <volume> 50(2) </volume> <pages> 117-134, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: The other issue is how to guarantee that tasks meet their end-to-end deadlines, especially when adjacent subtasks are loosely synchronized. The existing answers to this question are generally pessimistic. Various aspects of the end-to-end scheduling problems have been examined by people in different contexts. For example, Tindell et al. <ref> [19] </ref> attempted to compute upper bounds on the end-to-end response times when the Direct Synchronization protocol is used (This protocol will be defined in Chapter 4.). However, the interference of instances of the same subtask is ignored in Tindell's work, and the result in [19] is not correct. <p> For example, Tindell et al. <ref> [19] </ref> attempted to compute upper bounds on the end-to-end response times when the Direct Synchronization protocol is used (This protocol will be defined in Chapter 4.). However, the interference of instances of the same subtask is ignored in Tindell's work, and the result in [19] is not correct. Our approach, presented in Chapter 5, takes this factor into account, and yields correct results. Tindell et al. [19] studied the priority assignment problem in a distributed system where tasks have end-to-end deadlines. Garcia and Harbour [10] proposed a refined solution to a similar problem. <p> However, the interference of instances of the same subtask is ignored in Tindell's work, and the result in <ref> [19] </ref> is not correct. Our approach, presented in Chapter 5, takes this factor into account, and yields correct results. Tindell et al. [19] studied the priority assignment problem in a distributed system where tasks have end-to-end deadlines. Garcia and Harbour [10] proposed a refined solution to a similar problem. This work complements our work on heuristic priority assignment methods. <p> All these algorithms are based on a technique called busy period analysis, which was first proposed by Lehoczky [5, 6] and later extended by Audsley [7], Tindell <ref> [8, 19, 53] </ref>, and Burns [17]. Before we present the schedulability analysis algorithms, we introduce the notation used in the busy period analysis and describe this technique under the context of the end-to-end scheduling. 40 5.1 Busy Period Analysis The busy period analysis method is also called time demand analysis. <p> To bound the extra interference precisely, we end up with a mutually dependent system to analyze <ref> [19] </ref>. Furthermore, since many instances of the same subtask can be released almost simultaneously, they may interfere with each other (because later instances need to wait until previous instances complete before they can start). <p> In this case, we can set up an additional termination condition for Algorithm SA/DS so that it terminates either when a solution is obtained or when the bounds exceed the relative deadlines. 5.5.6 Relation with Previous Work Tindell et al. proposed a solution in <ref> [19] </ref> for a very similar problem. In their approach, the irregular release times are called release jitters, and the extra interference to a target subtask caused by release jitters is counted in their extended busy period analysis method [7, 8]. The release jitters are propagated along the subtask chains. <p> In an extreme case, several instances of T i;j may be released closely together in time, and the worst-case response time of T i;j is longer than the one when T i;j is periodic, which is obtained by the method in [8]. Since the approach proposed in <ref> [19] </ref> uses the 74 method in [8] to obtain an upper bound on the response time of a subtask, we expect that in general Tindell's approach will not yield correct upper bounds on the end-to-end response times of tasks. 5.6 Summary In a system using a synchronization protocol with execution control,
Reference: [20] <author> Ragunathan Rajkumar. </author> <title> Synchronization in Real-Time Systems APriority Inheritance Approach. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year>
Reference-contexts: This is closely related to previous work on the resource contention problem in a uniprocessor system or a multiprocessor system. In a real-time system, the exclusive access to a resource is typically achieved by semaphore-like operations. Sha [15] and Rajkumar <ref> [20] </ref> have shown that careless use of semaphores can lead to unpredictable timing behavior in a real-time system and a resource access control protocol 11 is needed to keep the blocking times of tasks bounded. <p> On a single-processor system, we refer to the total length of time during which a task is blocked by lower-priority tasks due to resource contention as its blocking time. To ensure predictability, it is imperative to keep the blocking time of each task bounded from above <ref> [20] </ref>. Several effective solutions have been proposed for single-processor systems; two well-known examples are the Priority Ceiling Protocol (PCP) [15] and the Stack Based Protocol (SBP) [16].
Reference: [21] <author> R. Rajkumar, L. Sha, and J. P. Lehoczky. </author> <title> Real-time synchronization protocols for multiprocessors. </title> <booktitle> In IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 259-269, </pages> <month> December </month> <year> 1988. </year>
Reference-contexts: Baker [16] developed the Stack Based Protocol (SBP) which gives the same upper bound on the blocking time of each task as with the PCP. In addition, the SBP is applicable to both fixed-priority scheduling and dynamic-priority scheduling. In a distributed system, Rajkumar et al. <ref> [21] </ref> looked at the case where tasks execute locally on their host processors but need to access resources on remote processors. They extended the PCP to the Multiprocessor Priority Ceiling Protocol (MPCP) and developed a way to compute an upper bound on the blocking time of each task. <p> Accordingly, in a multiprocessor or distributed system the blocking time of a task includes the time when the task is blocked by both local lower-priority tasks and remote tasks. Rajkumar et al. <ref> [21] </ref> extended the PCP for single-processor systems to multiprocessor systems and provided a solution for this problem. The extended protocol is known as the Multiprocessor Priority Ceiling Protocol (MPCP). <p> resource contention and global resource contention is bounded, and the schedulability of the system can be determined by applying a schedulability analysis method for single-processor systems [1, 5] on each individual processor. 100 8.2 System Model In Rajkumar's system model, every resource and every task has a host processor. (In <ref> [21] </ref>, the host processor of a global resource is called a synchronization processor of the global resource.) Later in this chapter, when we say a task T i (or a resource R i ) is on a processor P j , we mean that P j is the host processor of <p> According to the MPCP, the execution thread on the host processor of the global resource is called a global critical section (GCS) server <ref> [21] </ref>. The GCS server accesses the resource according to the given resource access protocol. Once the GCS server completes on the host processor of the global resource, it terminates and sends back the results; its corresponding task resumes the execution on its host processor. <p> B i = LB i + GB i + RW i + DB i + GCSB i (8.6) The deferred blocking time is termed differently in <ref> [21] </ref>. In [21], for any task T i and any task T k 2 LH i , the extra interference from T k due to execution suspension/resumption is minfffi k ; I k g, where I k is the maximum amount of time that T k suspends itself. <p> B i = LB i + GB i + RW i + DB i + GCSB i (8.6) The deferred blocking time is termed differently in <ref> [21] </ref>. In [21], for any task T i and any task T k 2 LH i , the extra interference from T k due to execution suspension/resumption is minfffi k ; I k g, where I k is the maximum amount of time that T k suspends itself. <p> i DB i GCSB i T 1 P 1 3 2 1 0 0 0 T 3 P 2 6 0 0 0 0 6 Table 8.8: Blocking Times of Tasks in Example 1 According to the Improved MPCP In later discussion, we will refer to the formula introduced in <ref> [21] </ref> as the original formula of computing task blocking times, the formula described in Section 8.3.4 as the corrected formula of computing task blocking times, and the formula described in this subsection as the improved formula of computing task blocking times.
Reference: [22] <author> H. Zhang and D. Ferrari. </author> <title> Rate-controlled service disciplines. </title> <journal> Journal of High Speed Networks, </journal> <volume> 3(4), </volume> <year> 1994. </year>
Reference-contexts: To achieve these objectives, real-time scheduling techniques, such as prioritized messages and rate-based scheduling, are used to schedule the messages at each switch. A service discipline refers to a message scheduling scheme used to switch the packets or cells. Zhang and Ferrari <ref> [22] </ref> divided service disciplines into two categories, work-conserving disciplines, 12 which never allow an outgoing link to idle when there are messages waiting to be sent on the link, and non-work-conserving disciplines, which may allow outgoing links to be idle in the presence of waiting messages. <p> Many similar schemes have been proposed, including Delay Earliest-Due-Date (Delay-EDD) [25, 26, 27], Virtual Clock [28], Fair Queuing [29], and Generalized Processor Sharing [30, 31]. On the other side, non-work-conserving disciplines include Jitter Earliest-Due-Date (Jitter-EDD) [32], Stop-and-Go [33], Hierarchical Round Robin (HRR) [34], and Rate-Controlled Static Priority (RCSP) <ref> [22] </ref>. In most of the above-mentioned schemes, each message stream is assumed to satisfy certain burstiness constraints, such as the (; ) burstiness constraint 1 and the leaky bucket constraint, when it enters the network.
Reference: [23] <author> R. Cruz. </author> <title> A calculus for network delay, Part I: Network elements in isolation. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 37(1) </volume> <pages> 114-131, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Rene <ref> [23, 24] </ref> proposed a rate-controlled service discipline by using a (; )- regulator. This work-conserving scheme yields good performance in terms of the end-to-end delay and the buffer size.
Reference: [24] <author> R. Cruz. </author> <title> A calculus for network delay, Part II: Network analysis. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 37(1) </volume> <pages> 132-141, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Rene <ref> [23, 24] </ref> proposed a rate-controlled service discipline by using a (; )- regulator. This work-conserving scheme yields good performance in terms of the end-to-end delay and the buffer size.
Reference: [25] <author> D. Ferrari and D. Verma. </author> <title> A scheme for real-time channel establishment in wide-area networks. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 8(3) </volume> <pages> 368-379, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Rene [23, 24] proposed a rate-controlled service discipline by using a (; )- regulator. This work-conserving scheme yields good performance in terms of the end-to-end delay and the buffer size. Many similar schemes have been proposed, including Delay Earliest-Due-Date (Delay-EDD) <ref> [25, 26, 27] </ref>, Virtual Clock [28], Fair Queuing [29], and Generalized Processor Sharing [30, 31]. On the other side, non-work-conserving disciplines include Jitter Earliest-Due-Date (Jitter-EDD) [32], Stop-and-Go [33], Hierarchical Round Robin (HRR) [34], and Rate-Controlled Static Priority (RCSP) [22].
Reference: [26] <author> D. D. Kandlur, K. Shin, and D. Ferrari. </author> <title> Real-time communication in multi-hop networks. </title> <booktitle> In Proceedings of 11th International Conference on Distributed Computer Systems, </booktitle> <pages> pages 300-307, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Rene [23, 24] proposed a rate-controlled service discipline by using a (; )- regulator. This work-conserving scheme yields good performance in terms of the end-to-end delay and the buffer size. Many similar schemes have been proposed, including Delay Earliest-Due-Date (Delay-EDD) <ref> [25, 26, 27] </ref>, Virtual Clock [28], Fair Queuing [29], and Generalized Processor Sharing [30, 31]. On the other side, non-work-conserving disciplines include Jitter Earliest-Due-Date (Jitter-EDD) [32], Stop-and-Go [33], Hierarchical Round Robin (HRR) [34], and Rate-Controlled Static Priority (RCSP) [22].
Reference: [27] <author> Q. Zheng and K. Shin. </author> <title> On the ability of establishing real-time channels in point-to-point packet-switching networks. </title> <journal> IEEE Transactions on Communications, </journal> <volume> 42(2-4):1096-1105, </volume> <month> March </month> <year> 1994. </year>
Reference-contexts: Rene [23, 24] proposed a rate-controlled service discipline by using a (; )- regulator. This work-conserving scheme yields good performance in terms of the end-to-end delay and the buffer size. Many similar schemes have been proposed, including Delay Earliest-Due-Date (Delay-EDD) <ref> [25, 26, 27] </ref>, Virtual Clock [28], Fair Queuing [29], and Generalized Processor Sharing [30, 31]. On the other side, non-work-conserving disciplines include Jitter Earliest-Due-Date (Jitter-EDD) [32], Stop-and-Go [33], Hierarchical Round Robin (HRR) [34], and Rate-Controlled Static Priority (RCSP) [22].
Reference: [28] <author> L. Zhang. </author> <title> Virtual clock: A new traffic control algorithm for packet switching networks. </title> <booktitle> In Proceedings of ACM SIGCOMM'90, </booktitle> <pages> pages 19-29, </pages> <address> Philadelphia, Pennsylvania, </address> <month> September </month> <year> 1990. </year>
Reference-contexts: Rene [23, 24] proposed a rate-controlled service discipline by using a (; )- regulator. This work-conserving scheme yields good performance in terms of the end-to-end delay and the buffer size. Many similar schemes have been proposed, including Delay Earliest-Due-Date (Delay-EDD) [25, 26, 27], Virtual Clock <ref> [28] </ref>, Fair Queuing [29], and Generalized Processor Sharing [30, 31]. On the other side, non-work-conserving disciplines include Jitter Earliest-Due-Date (Jitter-EDD) [32], Stop-and-Go [33], Hierarchical Round Robin (HRR) [34], and Rate-Controlled Static Priority (RCSP) [22].
Reference: [29] <author> A. Demers, S. Keshav, and S. Shenker. </author> <title> Analysis and simulation of a fair queueing algorithm. </title> <journal> Journal of Inernetworking Research and Experience, </journal> <volume> 1(1) </volume> <pages> 3-26, </pages> <month> October </month> <year> 1990. </year> <month> 159 </month>
Reference-contexts: Rene [23, 24] proposed a rate-controlled service discipline by using a (; )- regulator. This work-conserving scheme yields good performance in terms of the end-to-end delay and the buffer size. Many similar schemes have been proposed, including Delay Earliest-Due-Date (Delay-EDD) [25, 26, 27], Virtual Clock [28], Fair Queuing <ref> [29] </ref>, and Generalized Processor Sharing [30, 31]. On the other side, non-work-conserving disciplines include Jitter Earliest-Due-Date (Jitter-EDD) [32], Stop-and-Go [33], Hierarchical Round Robin (HRR) [34], and Rate-Controlled Static Priority (RCSP) [22].
Reference: [30] <author> A. K. Parekh and R. G. Gallager. </author> <title> A generalized processor sharing approach to flow control in integrated services networks: the single-node case. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 1(3) </volume> <pages> 344-357, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: This work-conserving scheme yields good performance in terms of the end-to-end delay and the buffer size. Many similar schemes have been proposed, including Delay Earliest-Due-Date (Delay-EDD) [25, 26, 27], Virtual Clock [28], Fair Queuing [29], and Generalized Processor Sharing <ref> [30, 31] </ref>. On the other side, non-work-conserving disciplines include Jitter Earliest-Due-Date (Jitter-EDD) [32], Stop-and-Go [33], Hierarchical Round Robin (HRR) [34], and Rate-Controlled Static Priority (RCSP) [22].
Reference: [31] <author> A. K. Parekh and R. G. Gallager. </author> <title> A generalized processor sharing approach to flow control in integrated services networks: the multiple node case. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 2(2) </volume> <pages> 137-150, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: This work-conserving scheme yields good performance in terms of the end-to-end delay and the buffer size. Many similar schemes have been proposed, including Delay Earliest-Due-Date (Delay-EDD) [25, 26, 27], Virtual Clock [28], Fair Queuing [29], and Generalized Processor Sharing <ref> [30, 31] </ref>. On the other side, non-work-conserving disciplines include Jitter Earliest-Due-Date (Jitter-EDD) [32], Stop-and-Go [33], Hierarchical Round Robin (HRR) [34], and Rate-Controlled Static Priority (RCSP) [22].
Reference: [32] <author> D. Verma, H. Zhang, and D. Ferrari. </author> <title> Guaranteeing delay jitter bounds in packet switching networks. </title> <booktitle> In Proceedings of Tricomm'91, </booktitle> <pages> pages 35-46, </pages> <address> Chapel Hill, North Carolina, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: Many similar schemes have been proposed, including Delay Earliest-Due-Date (Delay-EDD) [25, 26, 27], Virtual Clock [28], Fair Queuing [29], and Generalized Processor Sharing [30, 31]. On the other side, non-work-conserving disciplines include Jitter Earliest-Due-Date (Jitter-EDD) <ref> [32] </ref>, Stop-and-Go [33], Hierarchical Round Robin (HRR) [34], and Rate-Controlled Static Priority (RCSP) [22]. In most of the above-mentioned schemes, each message stream is assumed to satisfy certain burstiness constraints, such as the (; ) burstiness constraint 1 and the leaky bucket constraint, when it enters the network.
Reference: [33] <author> S. J. Golestani. </author> <title> A stop-and-go queueing framework for congestion management. </title> <booktitle> In Proceedings of ACM SIGCOMM'90, </booktitle> <pages> pages 8-18, </pages> <address> Philadelphia, Pennsylvania, </address> <month> September </month> <year> 1990. </year>
Reference-contexts: Many similar schemes have been proposed, including Delay Earliest-Due-Date (Delay-EDD) [25, 26, 27], Virtual Clock [28], Fair Queuing [29], and Generalized Processor Sharing [30, 31]. On the other side, non-work-conserving disciplines include Jitter Earliest-Due-Date (Jitter-EDD) [32], Stop-and-Go <ref> [33] </ref>, Hierarchical Round Robin (HRR) [34], and Rate-Controlled Static Priority (RCSP) [22]. In most of the above-mentioned schemes, each message stream is assumed to satisfy certain burstiness constraints, such as the (; ) burstiness constraint 1 and the leaky bucket constraint, when it enters the network.
Reference: [34] <author> C. R. Kalmanek, H. Kanakia, and S. Keshav. </author> <title> Rate controlled servers for very high-speed networks. </title> <booktitle> In IEEE Global Telecommunications Conference, </booktitle> <pages> pages 12-20, </pages> <address> San Diego, Cali-fornia, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: Many similar schemes have been proposed, including Delay Earliest-Due-Date (Delay-EDD) [25, 26, 27], Virtual Clock [28], Fair Queuing [29], and Generalized Processor Sharing [30, 31]. On the other side, non-work-conserving disciplines include Jitter Earliest-Due-Date (Jitter-EDD) [32], Stop-and-Go [33], Hierarchical Round Robin (HRR) <ref> [34] </ref>, and Rate-Controlled Static Priority (RCSP) [22]. In most of the above-mentioned schemes, each message stream is assumed to satisfy certain burstiness constraints, such as the (; ) burstiness constraint 1 and the leaky bucket constraint, when it enters the network.
Reference: [35] <author> E. L. Lawler, J. K.Lenstra, A. H. G. Rinnooy, and D. B. Shmoys. </author> <title> Sequencing and scheduling: Algorithms and complexity. </title> <type> Technical Report BS-R8909, </type> <institution> Center for Mathematics and Computer Science, Erasmus University, Rotterdam, </institution> <month> June </month> <year> 1989. </year>
Reference-contexts: In this context, the problem is how to schedule a set of jobs on a set of machines, and the goal of scheduling is to maximize the productivity. An excellent survey was done by Lawler et al. <ref> [35] </ref>, who classified the problems and provided an overview of the known solutions. Many topics are also covered in [36] by Blazewicz. Xu and Parnas [37] gave insights on how classical scheduling theories can be used to solve real-time scheduling problems.
Reference: [36] <author> J. Blazewicz. </author> <title> Selected topics in scheduling theory. </title> <journal> Annals of Discrete Mathematics, </journal> <volume> 31(1) </volume> <pages> 1-59, </pages> <year> 1987. </year>
Reference-contexts: An excellent survey was done by Lawler et al. [35], who classified the problems and provided an overview of the known solutions. Many topics are also covered in <ref> [36] </ref> by Blazewicz. Xu and Parnas [37] gave insights on how classical scheduling theories can be used to solve real-time scheduling problems. Recently, Stankovic et al. [38] pointed out some implications of classical scheduling theories in the design of real-time systems.
Reference: [37] <author> J. Xu and D. L. Parnas. </author> <title> On satisfying timing constraints in hard-real-time systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 19(1) </volume> <pages> 70-84, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: An excellent survey was done by Lawler et al. [35], who classified the problems and provided an overview of the known solutions. Many topics are also covered in [36] by Blazewicz. Xu and Parnas <ref> [37] </ref> gave insights on how classical scheduling theories can be used to solve real-time scheduling problems. Recently, Stankovic et al. [38] pointed out some implications of classical scheduling theories in the design of real-time systems.
Reference: [38] <author> J. A. Stankovic, M. Spuri, M. D. Natale, and G. C. Buttazzo. </author> <title> Implications of classical scheduling results for real-time systems. </title> <journal> Computer, </journal> <volume> 28(6) </volume> <pages> 16-25, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Many topics are also covered in [36] by Blazewicz. Xu and Parnas [37] gave insights on how classical scheduling theories can be used to solve real-time scheduling problems. Recently, Stankovic et al. <ref> [38] </ref> pointed out some implications of classical scheduling theories in the design of real-time systems. Nevertheless, classical scheduling theories are in general not directly applicable to real-time scheduling due to different assumptions.
Reference: [39] <author> R. Graham. </author> <title> Bounds on the performance of scheduling algorithms. </title> <editor> In E. G. Goffman, editor, </editor> <booktitle> Computer and Job Shop Scheduling Theory, </booktitle> <pages> pages 165-227. </pages> <publisher> John Wiley and Sons, </publisher> <year> 1976. </year>
Reference-contexts: Two issues still need to be addressed. First, a periodic task may 14 not be released periodically, and thus a definite transformation is impossible. Secondly, even if this transformation is possible, we need to consider Graham's anomalies <ref> [39] </ref> when trying to determine whether every task instance will meet its deadline. Because the task instances have variable execution times, examining the schedule where each task has its maximum execution time may not be sufficient to draw a conclusion about the schedulability of tasks.
Reference: [40] <author> R. Ha. </author> <title> Validating Timing Constraints in Multiprocessor and Distributed Systems. </title> <type> PhD thesis, </type> <institution> University of Illinois, Urbana-Champaign, Department of Computer Science, </institution> <year> 1995. </year> <month> 160 </month>
Reference-contexts: The general problem of predicting the completion times of task instances in the presence of anomalies has not been solved <ref> [40] </ref>. The end-to-end scheduling problem studied in this thesis resembles the classical job-shop scheduling problem. In the job-shop model, each task needs to execute on a set of processors in a certain order, and each task may require a different order.
Reference: [41] <author> S. M. Johnson. </author> <title> Optimal two- and three-stage production schedules with setup times included. </title> <journal> Naval Research Logistics Quarterly, </journal> <volume> 1 </volume> <pages> 61-68, </pages> <year> 1954. </year>
Reference-contexts: Like many other works in classical scheduling, efforts on job-shop scheduling problems have concentrated on minimizing the length of the schedule for a static workload. Johnson <ref> [41] </ref> provided an algorithm to find a minimum length schedule for a flow-shop system with two processors in O (n log n) time. A simple extension provided by Jackson [42] yields a solution to the 2-processor job-shop scheduling problem with the same time complexity.
Reference: [42] <author> J. R. Jackson. </author> <title> An extension of Johnson's results on job lot scheduling. </title> <journal> Naval Research Logistics Quarterly, </journal> <volume> 3 </volume> <pages> 201-203, </pages> <year> 1956. </year>
Reference-contexts: Johnson [41] provided an algorithm to find a minimum length schedule for a flow-shop system with two processors in O (n log n) time. A simple extension provided by Jackson <ref> [42] </ref> yields a solution to the 2-processor job-shop scheduling problem with the same time complexity. Hefetz and Adiri [43] provided an algorithm for computing a minimum length schedule for a two-processor job-shop system with unit-length tasks in linear time.
Reference: [43] <author> N. Hefetz and I. Adiri. </author> <title> An efficient optimal algorithm for the two-machines unit-time jobshop schedule-length problem. </title> <journal> Mathematics of Operations Research, </journal> <volume> 7 </volume> <pages> 354-360, </pages> <year> 1982. </year>
Reference-contexts: Johnson [41] provided an algorithm to find a minimum length schedule for a flow-shop system with two processors in O (n log n) time. A simple extension provided by Jackson [42] yields a solution to the 2-processor job-shop scheduling problem with the same time complexity. Hefetz and Adiri <ref> [43] </ref> provided an algorithm for computing a minimum length schedule for a two-processor job-shop system with unit-length tasks in linear time. Brucker solved the similar problem of 2-processor unit-time job-shop scheduling to minimize the maximum lateness [44, 45].
Reference: [44] <author> P. Brucker. </author> <title> Minimizing maximum lateness in a two-machine unit-time job shop. </title> <journal> Computing, </journal> <volume> 27 </volume> <pages> 367-370, </pages> <year> 1981. </year>
Reference-contexts: Hefetz and Adiri [43] provided an algorithm for computing a minimum length schedule for a two-processor job-shop system with unit-length tasks in linear time. Brucker solved the similar problem of 2-processor unit-time job-shop scheduling to minimize the maximum lateness <ref> [44, 45] </ref>. However, the problems of scheduling of any non-trivial job-shops with more than two processors are NP-hard [46, 47, 48].
Reference: [45] <author> P. Brucker. </author> <title> A linear time algorithm to minimize maximum lateness for the two-machine, unit-time, job-shop, scheduling problem. </title> <editor> In R. F. Drenick and F. Kozin, editors, </editor> <booktitle> Lecture Notes in Control and Information Sciences 38, </booktitle> <pages> pages 566-571. </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1982. </year>
Reference-contexts: Hefetz and Adiri [43] provided an algorithm for computing a minimum length schedule for a two-processor job-shop system with unit-length tasks in linear time. Brucker solved the similar problem of 2-processor unit-time job-shop scheduling to minimize the maximum lateness <ref> [44, 45] </ref>. However, the problems of scheduling of any non-trivial job-shops with more than two processors are NP-hard [46, 47, 48].
Reference: [46] <author> J. K. Lenstra, A. H. G. Rinnooy Kan, and P. Brucker. </author> <title> Complexity of machine scheduling problem. </title> <journal> Annals of Discrete Mathematics, </journal> <volume> 1 </volume> <pages> 343-362, </pages> <year> 1977. </year>
Reference-contexts: Brucker solved the similar problem of 2-processor unit-time job-shop scheduling to minimize the maximum lateness [44, 45]. However, the problems of scheduling of any non-trivial job-shops with more than two processors are NP-hard <ref> [46, 47, 48] </ref>.
Reference: [47] <author> T. Gonzalez and S. Sahni. </author> <title> Flowshop and jobshop schedules: Complexity and approximation. </title> <journal> Operations Research, </journal> <volume> 26 </volume> <pages> 36-52, </pages> <year> 1978. </year>
Reference-contexts: Brucker solved the similar problem of 2-processor unit-time job-shop scheduling to minimize the maximum lateness [44, 45]. However, the problems of scheduling of any non-trivial job-shops with more than two processors are NP-hard <ref> [46, 47, 48] </ref>.
Reference: [48] <author> J. K. Lenstra and A. H. G. Rinnooy Kan. </author> <title> Computational complexity of discrete optimization problems. </title> <journal> Annals of Discrete Mathematics, </journal> <volume> 4 </volume> <pages> 121-140, </pages> <year> 1979. </year>
Reference-contexts: Brucker solved the similar problem of 2-processor unit-time job-shop scheduling to minimize the maximum lateness [44, 45]. However, the problems of scheduling of any non-trivial job-shops with more than two processors are NP-hard <ref> [46, 47, 48] </ref>.
Reference: [49] <author> M. G. Harbour, M. H. Klein, and J. P. Lehoczky. </author> <title> Timing analysis for fixed-priority scheduling of hard real-time systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 20(1) </volume> <pages> 13-28, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: In practice, we can hardly find a reason for doing so. Adjacent subtasks on the same processor can always be treated as one, and performance will be better. Harbour et 18 al. <ref> [49] </ref> studied the case, in which subtasks with different fixed priorities executing on a single processor, and developed schedulability analysis algorithms for bounding the task response times. In the previous list of assumptions, we deliberately avoided issues on resource contention. <p> In addition, if we use an appropriate schedulability analysis algorithm, we will obtain a tighter bound on the response time of the whole subtask group. Harbour et al. <ref> [49] </ref> proposed a schedulability analysis algorithm for such a case. In their model, a single-processor system has a set of periodic tasks, each of which is a chain of subtasks which may have different priorities. The DS protocol is used to synchronize the execution of subtasks.
Reference: [50] <author> B. </author> <title> Hunting. The solution's in the CAN | Part 1. </title> <booktitle> Circuit Cellar, </booktitle> <pages> pages 14-20, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Provided that this is true, the following examples show how to capture communication overhead within the model. Prioritized Bus In the case when the communication link is a prioritized bus, such as CAN <ref> [50] </ref>, each message has a fixed priority. Processors that want to send messages compete for the bus by putting the priorities of the messages on the bus, and the processor with highest message priority gains the control over the bus.
Reference: [51] <author> N. Malcolm and W. Zhao. </author> <title> The timed-token protocol for real-time communications. </title> <journal> IEEE Computer, </journal> <volume> 27(1) </volume> <pages> 35-41, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: After such care is taken, our schedulability analysis algorithms will remain correct. Other Cases In the case of networks, such as FDDI <ref> [51] </ref>, where the maximum delay of each message transmission is bounded but the networks are neither prioritized buses nor dedicated links, we again model the communication link as a "link" processor and the message transmissions as the subtasks on the "link" processor. <p> However, a fixed priority scheduling algorithm cannot be used on this "network" processor. Furthermore, the underlying scheduling support, such as timer interrupts, release guard variables, and etc., does not exist on the "network" processor either. Nevertheless, since timing guarantee can be provided by the FDDI network <ref> [51] </ref>, the whole system can be used to schedule tasks with end-to-end deadlines. In general, we call scheduling of such a system, where different scheduling paradigms may be used on different processors, the hybrid end-to-end scheduling.
Reference: [52] <author> B. Sprunt, L. Sha, and J. P. Lehoczky. </author> <title> Aperiodic task scheduling for hard real-time systems. </title> <journal> Journal of Real-Time Systems, </journal> <volume> 1 </volume> <pages> 27-60, </pages> <year> 1989. </year> <month> 161 </month>
Reference-contexts: At most two context switches are associated with each subtask instance. 35 4.2.5 Sporadic Server (SS) Protocol The sporadic server was initially proposed by Sprunt et al. <ref> [52] </ref> to handle sporadic requests in a periodic environment. From the schedulability analysis point of view, a sporadic server is just another periodic task with its own period and execution time. At run-time, however, the execution of the sporadic server may exhibit no periodicity. <p> At run-time, however, the execution of the sporadic server may exhibit no periodicity. Instead, its execution depends on the arrivals of the sporadic requests and a set of rules regarding its eligibility for execution at any time instant. The original sporadic server algorithm proposed in <ref> [52] </ref> is not correct. In Appendix A, we give an example to illustrate the mistake in the original algorithm. <p> We also did not evaluate the SS protocol for the following reasons. 1. The original sporadic server algorithm proposed in <ref> [52] </ref> contains a mistake. In Appendix A, we point out the mistake and give the corrections. We also illustrate that the idea of a sporadic server encompasses a family of algorithms. However, it is not clear which implementation is the most efficient one. <p> More general cases of dynamic-priority, end-to-end scheduling need further investigation. 135 Appendix A Sporadic Server Algorithms The notion of Sporadic Server was first introduced by Sprunt et al. <ref> [52, 56] </ref>. Like a periodic task, a sporadic server is specified by its period and its (maximum) execution time. We say that a periodic task and a sporadic server have the same size if they have the same period and the same execution time.
Reference: [53] <author> K. W. Tindell. </author> <title> Fixed Priority Scheduling of Hard Real-Time Systems. </title> <type> PhD thesis, </type> <institution> University of York, Department of Computer Science, </institution> <year> 1994. </year>
Reference-contexts: All these algorithms are based on a technique called busy period analysis, which was first proposed by Lehoczky [5, 6] and later extended by Audsley [7], Tindell <ref> [8, 19, 53] </ref>, and Burns [17]. Before we present the schedulability analysis algorithms, we introduce the notation used in the busy period analysis and describe this technique under the context of the end-to-end scheduling. 40 5.1 Busy Period Analysis The busy period analysis method is also called time demand analysis.
Reference: [54] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. W. II. </title> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: Theorem 3 Every subproblem of the priority assignment problem for the case of any synchronization protocol and schedulability analysis algorithm proposed in this thesis is NP-hard. Proof : We prove this theorem by reducing a SET-PARTITION problem <ref> [54] </ref> to a priority assignment problem. 1 The SET-PARTITION problem can be stated as follows: for a given set fS i g of numbers, partition them into two subsets such that sums of the numbers in both subsets are equal.
Reference: [55] <author> D. Gillies and J. Liu. </author> <title> Scheduling tasks with and/or precedence constraints. </title> <journal> SIAM Journal on Computing, </journal> <volume> 24(4) </volume> <pages> 797-810, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: An example of such a task is shown in Figure 9.1. If a subtask has two predecessors, such as subtask T 1;4 in Figure 9.1, then the subtask can be either an AND subtask or an OR subtask, a case which was studied by Gillies and Liu <ref> [55] </ref>. If T 1;4 is an AND subtask, then an instance of T 1;4 cannot be released until both corresponding instances of T 1;2 and T 1;3 complete.
Reference: [56] <author> B. Sprunt. </author> <title> Aperiodic Task Scheduling for Real-Time Systems. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, Department of Electrical and Computer Engineering, </institution> <address> Pittsburgh, PA, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: More general cases of dynamic-priority, end-to-end scheduling need further investigation. 135 Appendix A Sporadic Server Algorithms The notion of Sporadic Server was first introduced by Sprunt et al. <ref> [52, 56] </ref>. Like a periodic task, a sporadic server is specified by its period and its (maximum) execution time. We say that a periodic task and a sporadic server have the same size if they have the same period and the same execution time. <p> In this appendix, we will focus on single-processor systems with periodic tasks and sporadic servers. We first show that the sporadic server algorithm proposed by Sprunt in <ref> [56] </ref> is not correct. A sporadic server implemented according to that algorithm is too aggressive in competing for the processor, and lower priority tasks may miss their deadlines while they would not if the server were indeed a periodic task with the same size. <p> A sporadic request can be served only when the server has (nonzero) budget. The budget gets consumed when the server serves requests and gets replenished at some time later. The following two rules regarding budget replenishment are copied from <ref> [56] </ref>. 1. (a) If the server has execution time available, the replenishment time, RT , is set when priority level P becomes active. (b) If, on the other hand, the server capacity has been exhausted, then RT cannot be set until the SS's capacity becomes greater than zero and P is <p> In Figure A.1 time 0 is a critical instant for task T 2 . If T s is implemented according to a correct sporadic server algorithm, we can conclude that T 2 must be schedulable. This is not true with the implementation proposed by Sprunt et al. in <ref> [56] </ref>. A schedule of the system is shown in Figure A.2, where T s is implemented according to the rules described above. <p> At time 8, task T 2 misses its deadline, since it still has 0.5 time unit to execute. From this example, we see clearly that the sporadic server algorithm proposed in <ref> [56] </ref> is not correct. The replenishment rules in this algorithm are too "greedy." A.2 The Structure of a Sporadic Server Again, like a periodic task, each sporadic server has a period s P eriod, an execution time s ExecT ime, and a fixed priority s P riority.
Reference: [57] <author> S. Ramos-Thuel and J. Lehoczky. </author> <title> Algorithms for scheduling hard aperiodic tasks in fixed-priority systems using slack stealing. </title> <booktitle> In Real-Time System Symposium, </booktitle> <pages> pages 22-33, </pages> <year> 1994. </year> <month> 162 </month>
Reference-contexts: Hence a sporadic server can achieve a better performance. For example, in Figure A.4, time 7.5 is an idle point. We can reset the server budget to 1, and the second request can complete 0.5 time unit earlier. Multiple Sporadic Servers in a System Unlike slack stealing algorithms <ref> [57] </ref>, which exploit the capacity of the system, sporadic server algorithms exploit the capacity of a periodic task to serve sporadic requests. As a consequence, multiple sporadic servers can co-exist in the same system without interference. Certain desirable attributes of sporadic servers still hold in this case.
References-found: 57

