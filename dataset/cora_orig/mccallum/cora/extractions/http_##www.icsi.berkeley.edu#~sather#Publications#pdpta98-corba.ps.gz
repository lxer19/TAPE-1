URL: http://www.icsi.berkeley.edu/~sather/Publications/pdpta98-corba.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/~borisv/
Root-URL: http://www.icsi.berkeley.edu
Email: jacobsen@wiwi.hu-berlin.de  borisv@icsi.berkeley.edu  
Title: Towards High-Performance Multithreaded CORBA Servers  
Author: Hans Arno Jacobsen Boris Weissman 
Keyword: High-performance object request brokers, CORBA, mutlithreaded servers.  
Address: D-10178 Berlin  1947 Center Street Berkeley, CA 94703  
Affiliation: Humboldt-Universitaet zu Berlin Institut fuer Wirtschaftsinformatik  International Computer Science Institute  
Abstract: Parallel platforms have become widely available. Moderately priced commodity SMPs are now manufactured by most major hardware vendors. Platform independent software environments, emphasizing a transparent programming model for building distributed applications, are rapidly emerging. In this paper we demonstrate how to combine the transparency characteristics of these environments with the high-performance features of the affordable server technology. We integrate the thread-per-request concurrency model into CORBA servers while providing high-performance. We demonstrate that thread creation overhead can be minimal and is merely attribute to the thread package used. We introduce and evaluate optimization techniques for increasing overall server performance. These techniques are based on increasing locality of reference for the client-server interaction. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> OMG. </author> <title> The Common Object Request Broker Architecture and Specification. Revision 2.1. </title> <type> Technical Report, </type> <institution> Object Management Group, </institution> <year> 1997. </year>
Reference-contexts: 1 Introduction With advances in microprocessor technology, parallel platforms have become widely available. Moderately priced commodity SMPs are now manufactured by most major hardware vendors. At the same time platform independent software environments, such as CORBA <ref> [1] </ref>, DCOM [2], and DCE [3], are rapidly emerging. These platforms aim at providing a transparent programming model for the development of portable and interoperable distributed applications while enabling efficient client-server computing. <p> As we will show later the thread-per-request scheme provides sufficient performance, and, at the same time, a clean programming abstraction. 2.2 The CORBA specification The Common Object Request Broker Architecture (CORBA) is a standard for distributed computing which has been developed by the Object Management Group (OMG) <ref> [1] </ref>, a consortium of independent companies. CORBA aims at providing a uniform communication infrastructure for building distributed applications. It supplies a unifying framework for interoperating software components, operating on various hardware platforms, running different operating systems. Furthermore, CORBA aims at providing programming language transparency. <p> This functionality is usually already handled by the thread system and should not be dupli cated. Our implementation is based on the MICO CORBA ORB [10] and its implementation of request level interceptors <ref> [1, 15] </ref>. MICO is adopting interceptors as they are specified in [15]. Interceptors are application objects whose operations are invoked by the ORB in a pre-defined order. Thus they may be used to invoke operations at different stages of the processing of a remote method invocation.
Reference: [2] <author> Microsoft and Digital Equipment Corporatio. </author> <title> Distributed Component Object Model Specification. </title> <type> Technical Report, </type> <institution> Microsoft, </institution> <month> October </month> <year> 1996. </year> <note> Draft version 1.0 edition. </note>
Reference-contexts: 1 Introduction With advances in microprocessor technology, parallel platforms have become widely available. Moderately priced commodity SMPs are now manufactured by most major hardware vendors. At the same time platform independent software environments, such as CORBA [1], DCOM <ref> [2] </ref>, and DCE [3], are rapidly emerging. These platforms aim at providing a transparent programming model for the development of portable and interoperable distributed applications while enabling efficient client-server computing.
Reference: [3] <author> Open Software Foundation. </author> <title> OSF Distributed Computing Environment Rationale. </title> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: 1 Introduction With advances in microprocessor technology, parallel platforms have become widely available. Moderately priced commodity SMPs are now manufactured by most major hardware vendors. At the same time platform independent software environments, such as CORBA [1], DCOM [2], and DCE <ref> [3] </ref>, are rapidly emerging. These platforms aim at providing a transparent programming model for the development of portable and interoperable distributed applications while enabling efficient client-server computing.
Reference: [4] <author> D. C. Schmidt and S Vinoski. </author> <title> Object interconnections. comparing alternative programming techniques for multi-threaded servers. SIGS C++ Report, </title> <journal> February-August 1996. </journal> <volume> Columns 5, 6, </volume> <pages> 7. </pages>
Reference-contexts: It is therefore difficult to exploit the high-performance features of current server technology. CORBA offers language bindings for C, C++, SmallTalk, Java, Ada, and Eiffel, but does not leave room to integrate parallel extensions into the language binding in a non-proprietary and portable manner. Some work has emerged <ref> [4, 5] </ref> that surveys implementation techniques for designing multithreaded servers based on the features CORBA provides. Proprietary extensions to support multithreaded CORBA servers have also been implemented for several commercial ORBs [6, 7]. An engineering solution for multithread-ing CORBA clients has been proposed by Hellemans et al. [8]. <p> We have ex tended the MICO CORBA ORB [10] implementation to concurrently process client requests. We demonstrate that thread creation overhead can be minimal and is merely attribute to the thread package used. Thus user-exposed thread-pooling techniques, proposed by Schmidt and Vinoski <ref> [4] </ref> need not be applied. We feel that such exposure does not support an intuitive parallel programming model and is not necessary at this level of abstraction. As our performance study shows, a thread-per-request style of invocation is fully satisfactory. <p> As our performance study shows, a thread-per-request style of invocation is fully satisfactory. This latter point is often neglected which led to the proposal of using pre-spawned thread-pools to reduce thread creation overhead (cf. <ref> [4, 11] </ref>). Furthermore, we propose and investigate techniques for increasing multithreaded server performance. These techniques are based on increasing locality of reference for the client-server interaction. <p> It exploits the parallelism and high-performance fea tures of SMPs. Several alternative client-server interaction schemes have been proposed in the literature, e.g., <ref> [12, 4] </ref>, for multithreading servers, such as: * thread-per-request: a thread is associated with each incoming request * thread-per-session: a thread is associated with each connecting client * thread-per-transaction: a thread is associated with each individual transaction * thread-per-object: a thread is associated with each ob ject on the server-side * <p> thread-per-transaction: a thread is associated with each individual transaction * thread-per-object: a thread is associated with each ob ject on the server-side * thread-per-service: a thread is associated with each ser vice provided on the server-side Advantages and disadvantages of a number of these alternative interaction schemes is discussed in <ref> [12, 4] </ref>. <p> In all experiments, the server is using a thread-per-request concurrency model | a separate server thread is created for each incoming request <ref> [4] </ref>. In the base case, the server threads are scheduled over the processors on the server SMP in the first-come-first-serve (FCFS) order. We then examine the performance implications of scheduling the requests from the same stream to execute on the same server processor, if possible. <p> Section 3). Many sources dismiss this model based on performance and resource utilization considerations <ref> [4] </ref>. We, however, argue that the poor thread creation, synchronization, and scalability properties are merely artifacts of the particular implementations rather than the features inherent in the model.
Reference: [5] <author> R. Orfalli, D. Harkey, and J. Edwards. </author> <title> Client Server programming with Java and CORBA. </title> <publisher> John Wiley & Sons, INC., </publisher> <year> 1997. </year>
Reference-contexts: It is therefore difficult to exploit the high-performance features of current server technology. CORBA offers language bindings for C, C++, SmallTalk, Java, Ada, and Eiffel, but does not leave room to integrate parallel extensions into the language binding in a non-proprietary and portable manner. Some work has emerged <ref> [4, 5] </ref> that surveys implementation techniques for designing multithreaded servers based on the features CORBA provides. Proprietary extensions to support multithreaded CORBA servers have also been implemented for several commercial ORBs [6, 7]. An engineering solution for multithread-ing CORBA clients has been proposed by Hellemans et al. [8].
Reference: [6] <institution> Iona Technologies. Orbix/orbixweb. </institution> <note> http://www.iona.com/Orbix/index.html. </note>
Reference-contexts: Some work has emerged [4, 5] that surveys implementation techniques for designing multithreaded servers based on the features CORBA provides. Proprietary extensions to support multithreaded CORBA servers have also been implemented for several commercial ORBs <ref> [6, 7] </ref>. An engineering solution for multithread-ing CORBA clients has been proposed by Hellemans et al. [8]. Attempts at extending the CORBA object model to handle data parallel computations have been introduced by Keahey and Gannon [9].
Reference: [7] <author> OOC. Omnibroker. </author> <note> http://www.ooc.com/ob.html. </note>
Reference-contexts: Some work has emerged [4, 5] that surveys implementation techniques for designing multithreaded servers based on the features CORBA provides. Proprietary extensions to support multithreaded CORBA servers have also been implemented for several commercial ORBs <ref> [6, 7] </ref>. An engineering solution for multithread-ing CORBA clients has been proposed by Hellemans et al. [8]. Attempts at extending the CORBA object model to handle data parallel computations have been introduced by Keahey and Gannon [9].
Reference: [8] <author> P. Hellemans, F. Steegmans, H. Vanderstraeten, and H. Zuidweg. </author> <title> Implementation of hidden concurrency in CORBA clients. </title> <editor> In O. Spaniol, C. Linnhoff-Popien, and B. Meyer, editors, </editor> <booktitle> Trends in Distributed Systems: CORBA and Beyond, </booktitle> <pages> pages 30-42. </pages> <publisher> Springer Verlag, </publisher> <month> Oc-tober </month> <year> 1996. </year>
Reference-contexts: Proprietary extensions to support multithreaded CORBA servers have also been implemented for several commercial ORBs [6, 7]. An engineering solution for multithread-ing CORBA clients has been proposed by Hellemans et al. <ref> [8] </ref>. Attempts at extending the CORBA object model to handle data parallel computations have been introduced by Keahey and Gannon [9]. Despite this growing interest, no attempt, has so far, been made to explicitly quantify the performance improvements obtained from different server implementation techniques.
Reference: [9] <author> K. Keahey and D. Gannon. Pardis: </author> <title> A parallel approach to corba. </title> <booktitle> In International Symposium on High Performance Distributed Computing, </booktitle> <pages> pages 31-9, </pages> <address> Los Alami-tos, CA, USA, </address> <month> Aug </month> <year> 1997. </year> <institution> IEEE Comput. Soc. </institution>
Reference-contexts: An engineering solution for multithread-ing CORBA clients has been proposed by Hellemans et al. [8]. Attempts at extending the CORBA object model to handle data parallel computations have been introduced by Keahey and Gannon <ref> [9] </ref>. Despite this growing interest, no attempt, has so far, been made to explicitly quantify the performance improvements obtained from different server implementation techniques. No optimizations have been investigated to combine the transparency characteristics of CORBA with the high-performance features of SMPs to enable high-performance computational servers for distributed environments.
Reference: [10] <author> A. Puder and K. Romer. </author> <title> MICO is CORBA | A CORBA 2.0 compliant implementation. </title> <address> dpunkt.verlag, Heidelberg, </address> <year> 1998. </year>
Reference-contexts: In this model each incoming request is associated with a separate thread. The implementation is based on CORBA interceptors and is therefore fully portable. We have ex tended the MICO CORBA ORB <ref> [10] </ref> implementation to concurrently process client requests. We demonstrate that thread creation overhead can be minimal and is merely attribute to the thread package used. Thus user-exposed thread-pooling techniques, proposed by Schmidt and Vinoski [4] need not be applied. <p> This functionality is usually already handled by the thread system and should not be dupli cated. Our implementation is based on the MICO CORBA ORB <ref> [10] </ref> and its implementation of request level interceptors [1, 15]. MICO is adopting interceptors as they are specified in [15]. Interceptors are application objects whose operations are invoked by the ORB in a pre-defined order.
Reference: [11] <author> S. Baker. </author> <title> Corba Distributed Objects : Using Orbix. </title> <publisher> Ad-dison Wesley, </publisher> <year> 1997. </year>
Reference-contexts: As our performance study shows, a thread-per-request style of invocation is fully satisfactory. This latter point is often neglected which led to the proposal of using pre-spawned thread-pools to reduce thread creation overhead (cf. <ref> [4, 11] </ref>). Furthermore, we propose and investigate techniques for increasing multithreaded server performance. These techniques are based on increasing locality of reference for the client-server interaction.
Reference: [12] <author> Jr. H. W. Lockhart. </author> <title> OSF DCE. Guide to developing distributed applications. </title> <publisher> McGraw-Hill Inc., </publisher> <year> 1994. </year>
Reference-contexts: It exploits the parallelism and high-performance fea tures of SMPs. Several alternative client-server interaction schemes have been proposed in the literature, e.g., <ref> [12, 4] </ref>, for multithreading servers, such as: * thread-per-request: a thread is associated with each incoming request * thread-per-session: a thread is associated with each connecting client * thread-per-transaction: a thread is associated with each individual transaction * thread-per-object: a thread is associated with each ob ject on the server-side * <p> thread-per-transaction: a thread is associated with each individual transaction * thread-per-object: a thread is associated with each ob ject on the server-side * thread-per-service: a thread is associated with each ser vice provided on the server-side Advantages and disadvantages of a number of these alternative interaction schemes is discussed in <ref> [12, 4] </ref>.
Reference: [13] <author> S. Vinoski. </author> <title> CORBA Integrating Diverse Applications Within Distributed heterogeneous Environments. </title> <journal> IEEE Communications Magazine, </journal> <volume> 14(2), </volume> <month> Feb </month> <year> 1997. </year>
Reference: [14] <author> B. Weissman. </author> <title> Active Threads: An extensible and portable light-weight thread system. </title> <type> Technical Report, </type> <institution> ICSI TR-97-036, </institution> <month> Nov </month> <year> 1997. </year>
Reference-contexts: A oneway invocation scheme is additionally provided. It allows a client to send off a request and continue processing. No knowledge about the successful completion of the request is communicated back to the client. Transfer semantic of such invocations is best effort. 2.3 Active Threads Active Threads <ref> [14] </ref> is an extensible and portable high-performance thread system. It is based on an event driven architecture capable of supporting different scheduling policies. Active Threads supports user-extensible scheduling that exploits temporal and spatial locality. Active Threads hide hardware dependencies such as the number of CPUs. <p> Section 3). Many sources dismiss this model based on performance and resource utilization considerations [4]. We, however, argue that the poor thread creation, synchronization, and scalability properties are merely artifacts of the particular implementations rather than the features inherent in the model. For instance, with Active Threads <ref> [14] </ref>, it is possible to achieve thread creation and synchronization latencies of a few microseconds on a variety of different architectures. This is usually only a fraction of a percent of the TCP/IP protocol handling cost.
Reference: [15] <institution> Alcatel, Hewlett-Packarad Company, Lucent technology Inc., et al. </institution> <type> Realtime corba. Technical Report, </type> <institution> Object Managment Group, </institution> <month> January 19 </month> <year> 1998. </year> <title> OMG document number orbos/98-01-08. </title>
Reference-contexts: This functionality is usually already handled by the thread system and should not be dupli cated. Our implementation is based on the MICO CORBA ORB [10] and its implementation of request level interceptors <ref> [1, 15] </ref>. MICO is adopting interceptors as they are specified in [15]. Interceptors are application objects whose operations are invoked by the ORB in a pre-defined order. Thus they may be used to invoke operations at different stages of the processing of a remote method invocation. <p> This functionality is usually already handled by the thread system and should not be dupli cated. Our implementation is based on the MICO CORBA ORB [10] and its implementation of request level interceptors [1, 15]. MICO is adopting interceptors as they are specified in <ref> [15] </ref>. Interceptors are application objects whose operations are invoked by the ORB in a pre-defined order. Thus they may be used to invoke operations at different stages of the processing of a remote method invocation. This feature can for example be used for logging, authentication, and message transformation, among others.
Reference: [16] <author> Intel Corporation. </author> <title> Pentium Pro Family Developer's Manual. </title> <publisher> Intel Corporation, </publisher> <month> December </month> <year> 1995. </year> <title> Volume 3: Operating System Writer's Guide. </title>
Reference-contexts: Many modern processors such as Pen-tiumPro <ref> [16] </ref>, UltraSPARC [17], RS6000 [18] have performance monitoring hardware that enables user-level access to the external cache miss counters. We have instrumented our server code to read the performance instrumentation counters (PICs) of the Ul-traSPARC processor [17].
Reference: [17] <author> Sun Microsystems. </author> <note> UltraSPARC-1 User's Manual, </note> <year> 1996. </year>
Reference-contexts: Many modern processors such as Pen-tiumPro [16], UltraSPARC <ref> [17] </ref>, RS6000 [18] have performance monitoring hardware that enables user-level access to the external cache miss counters. We have instrumented our server code to read the performance instrumentation counters (PICs) of the Ul-traSPARC processor [17]. <p> Many modern processors such as Pen-tiumPro [16], UltraSPARC <ref> [17] </ref>, RS6000 [18] have performance monitoring hardware that enables user-level access to the external cache miss counters. We have instrumented our server code to read the performance instrumentation counters (PICs) of the Ul-traSPARC processor [17]. We then repeated our experiments on the Sun Enterprise 5000 server with 8 167Mhz UltraSPARC-1 cpus. Figure 6 corresponds to the following configuration p=8, c=64, s=64.
Reference: [18] <author> E. H. Welbon, C. C. Chan-Nui, D. J. Shippy, and D. A. Hicks. </author> <title> The power2 performance monitor. IBM internal paper. </title>
Reference-contexts: Many modern processors such as Pen-tiumPro [16], UltraSPARC [17], RS6000 <ref> [18] </ref> have performance monitoring hardware that enables user-level access to the external cache miss counters. We have instrumented our server code to read the performance instrumentation counters (PICs) of the Ul-traSPARC processor [17]. We then repeated our experiments on the Sun Enterprise 5000 server with 8 167Mhz UltraSPARC-1 cpus.
Reference: [19] <author> Sun Microsystems. </author> <title> The ultra enterprise 1 and 2 server architecture. </title> <type> Technical Report, </type> <institution> Sun Microsystems, </institution> <month> April </month> <year> 1996. </year> <type> Technical White Paper. </type>
Reference-contexts: However, since the secondary caches of the modern servers tend to be fairly large, locality scheduling is likely to be a significant factor for many applications. For instance, the E-cache of Sun Enterprise server can be up to 4Mb <ref> [19] </ref>, B-cache of DEC AlphaServer 4100 is also up to 4Mb [20], the external cache of HP Exemplar is 1Mb [21]. 5 Conclusion We have quantified the performance gains exploiting request locality in a distributed system.
Reference: [20] <author> M. B. Steinman, G. J. Harris, A. Kocev, V. C. Lamere, and R. D. Pannell. </author> <title> The alphaserver 4100 cached processor module architecture and design. </title> <journal> Digital Technical Journal, </journal> <month> April </month> <year> 1997. </year>
Reference-contexts: For instance, the E-cache of Sun Enterprise server can be up to 4Mb [19], B-cache of DEC AlphaServer 4100 is also up to 4Mb <ref> [20] </ref>, the external cache of HP Exemplar is 1Mb [21]. 5 Conclusion We have quantified the performance gains exploiting request locality in a distributed system.
Reference: [21] <institution> Hewlett Packard. </institution> <type> Hp exemplar technical servers. Tech nical report, </type> <institution> Hewlett Packard, </institution> <year> 1998. </year> <note> Technical Spec ifica-tion. Available at http://www.hp.com/wsg/products/ servers/servhome.html. </note>
Reference-contexts: For instance, the E-cache of Sun Enterprise server can be up to 4Mb [19], B-cache of DEC AlphaServer 4100 is also up to 4Mb [20], the external cache of HP Exemplar is 1Mb <ref> [21] </ref>. 5 Conclusion We have quantified the performance gains exploiting request locality in a distributed system. The distributed applications that may benefit the most from this scheme are transaction processing systems, where many clients interact with a server through heavy weight transactions.
References-found: 21

