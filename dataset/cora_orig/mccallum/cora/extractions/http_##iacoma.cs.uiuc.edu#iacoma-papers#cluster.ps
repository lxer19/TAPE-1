URL: http://iacoma.cs.uiuc.edu/iacoma-papers/cluster.ps
Refering-URL: http://iacoma.cs.uiuc.edu/papers.html
Root-URL: http://www.cs.uiuc.edu
Email: venkat,torrella@cs.uiuc.edu  
Title: A Clustered Approach to Multithreaded Processors  
Author: Venkata Krishnan and Josep Torrellas 
Web: http://iacoma.cs.uiuc.edu/iacoma/  
Address: IL 61801  
Affiliation: Department of Computer Science University of Illinois at Urbana-Champaign,  
Abstract: With aggressive superscalar processors delivering diminishing returns, alternate designs that make good use of the increasing chip densities are actively being explored. One such approach is simultaneous multithreading (SMT), where a conventional superscalar supports multiple threads such that instructions from different threads may be issued in a single cycle. Another approach is the on-chip multiprocessor and its variants. Unlike the SMT approach, all the resources have fixed assignment (FA) in this architecture. The design simplicity of the FA approach enables high clock frequencies, while the flexibility of the SMT approach allows it to adapt to the specific thread- and instruction-level parallelism of the application. Unfortunately, the strict partitioning of resources among various processors in the FA architecture may result in under-utilization of the chip, while the fully centralized structure of the SMT may result in a longer clock cycle-time. In this paper, we explore a hybrid design, where a chip is composed of a set of SMT processors. We evaluate such a clustered architecture running parallel applications. We consider both a low-end machine with only one processor chip on which to run multiple threads as well as a high-end machine with several processor chips working on the same application. Overall, we conclude that such a hybrid processor represents a good performance-complexity design point. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W. Blume, R. Doallo, R. Eigenmann, J. Grout, J. Hoe-flinger, T. Lawrence, J. Lee, D. Padua, Y. Paek, B. Pot-tenger, L. Rauchwerger, and P. Tu. </author> <title> Parallel Programming with Polaris. </title> <journal> IEEE Computer, </journal> <volume> 29(12) </volume> <pages> 78-82, </pages> <month> De-cember </month> <year> 1996. </year>
Reference-contexts: A natural solution to compensate for the lack of ILP in a single thread is to divide the application into multiple control flows or threads and exploit ILP across them. An application can be divided into multiple threads by the compiler <ref> [1, 5] </ref> or by user hand-parallelization. In addition, several proposed software and hardware features can enable even sequential applications to execute in multithreaded mode [3, 4, 7, 13]. Once we have multiple threads, different architectures can be used. <p> The two SPLASH-2 applications are explicitly-parallel programs written in C and use ANL m4 macros [10] for parallel constructs. The SPEC95 benchmarks and the NASA7 kernel are sequential programs written in Fortran. We use the Polaris automatic paralleliz-ing compiler <ref> [1] </ref> to identify parallel sections of the code. Po-laris uses several techniques, such as inter-procedural symbolic program analysis, scalar and array privatization, symbolic dependence analysis, advanced induction and reduction variable recognition and elimination, to parallelize a Fortran application.
Reference: [2] <author> The 21264: </author> <title> A Superscalar Alpha Processor with Out-of-Order Execution. Microprocessor Forum, </title> <month> October </month> <year> 1996. </year>
Reference-contexts: IPC/cluster (int/ld-st/fp) & Reorder buffer (int/fp) per Cluster [Chip] per Cluster [Chip] per Cluster [Chip] F A 8 8, 1 1 [8] 1/1/1 [8/8/8] 16 [128] 16/16 [128/128] F A 2 2, 4 1 <ref> [2] </ref> 4/4/4 [8/8/8] 64 [128] 64/64 [128/128] SM T 4 4, 2 2 [8] 2/2/2 [8/8/8] 32 [128] 32/32 [128/128] SM T 1 1, 8 8 [8] 6/4/4 [6/4/4] 128 [128] 128/128 [128/128] Table 2: Description of the different types of architectures evaluated. <p> This is because the F A 2 architecture has largely the same cycle-time as SM T 2 . The reason is that both architectures have 4-issue superscalar clusters. These 4-issue superscalars do not have as much cycle-time constraints as higher-issue processors [12]. In addition, with current technology <ref> [2] </ref>, the difference in cycle-time between 4-issue processors and lower-issue processors (F A 4 and F A 8 ) is very unlikely to be significant enough to make up for the large difference in performance shown in the figure. <p> Furthermore, the 4-issue and the lower-issue clusters (represented by SM T 4 and SM T 8 ) would have similar clock frequencies with current technology <ref> [2] </ref>. Consequently, SM T 2 is the most cost-effective organization. 6 Conclusions Since aggressive superscalar processors are becoming so complex, there is much interest in alternate designs that exploit thread-level parallelism. With future applications likely to be multithreaded, this is a very promising approach.
Reference: [3] <author> P. Dubey, K. O'Brien, K. O'Brien, and C. Barton. </author> <title> Single-Program Speculative Multithreading (SPSM) Architecture: Compiler-assisted Fine-grained Multithreading. </title> <booktitle> In Proceedings of the IFIP WG 10.3 Working Conference on Parallel Architectures and Compilation Techniques, PACT '95, </booktitle> <pages> pages 109-121, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: An application can be divided into multiple threads by the compiler [1, 5] or by user hand-parallelization. In addition, several proposed software and hardware features can enable even sequential applications to execute in multithreaded mode <ref> [3, 4, 7, 13] </ref>. Once we have multiple threads, different architectures can be used. A promising approach is the on-chip multiprocessor [11] and its variants such as the Multiscalar [14], and the Superthreaded architectures [15].
Reference: [4] <author> M. Franklin and G. Sohi. ARB: </author> <title> A Hardware Mechanism for Dynamic Memory Disambiguation. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 45(5) </volume> <pages> 552-571, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: An application can be divided into multiple threads by the compiler [1, 5] or by user hand-parallelization. In addition, several proposed software and hardware features can enable even sequential applications to execute in multithreaded mode <ref> [3, 4, 7, 13] </ref>. Once we have multiple threads, different architectures can be used. A promising approach is the on-chip multiprocessor [11] and its variants such as the Multiscalar [14], and the Superthreaded architectures [15].
Reference: [5] <author> M. Hall, J. Anderson, S. Amarasinghe, B. Murphy, S.- W. Liao, E. Bugnion, and M. Lam. </author> <title> Maximizing Multiprocessor Performance with the SUIF Compiler. </title> <journal> IEEE Computer, </journal> <volume> 29(12) </volume> <pages> 84-89, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: A natural solution to compensate for the lack of ILP in a single thread is to divide the application into multiple control flows or threads and exploit ILP across them. An application can be divided into multiple threads by the compiler <ref> [1, 5] </ref> or by user hand-parallelization. In addition, several proposed software and hardware features can enable even sequential applications to execute in multithreaded mode [3, 4, 7, 13]. Once we have multiple threads, different architectures can be used.
Reference: [6] <author> V. Krishnan and J. Torrellas. </author> <title> Efficient Use of Processing Transistors for Larger On-Chip Storage: Multithreading. In Workshop on Mixing Logic and DRAM: Chips that Compute and Remember, </title> <month> June </month> <year> 1997. </year>
Reference-contexts: Tullsen et al [16] describe a fully centralized SMT architecture with a relatively small impact on a conventional superscalar design. Evaluation of this architecture when running multiprogrammed and parallel workloads <ref> [6, 9, 16] </ref> has shown significant speedups. However, a drawback of this approach is that it may inherit all the complexity of existing superscalars and, in addition, add extra hardware.
Reference: [7] <author> V. Krishnan and J. Torrellas. </author> <title> Executing Sequential Binaries on a Clustered Multithreaded Architecture with Speculation Support. </title> <booktitle> In 4th High Performance Computer Architecture (HPCA) Workshop on Multi-Threaded Execution, Architecture and Compilation (MTEAC'98), </booktitle> <month> February </month> <year> 1998. </year>
Reference-contexts: An application can be divided into multiple threads by the compiler [1, 5] or by user hand-parallelization. In addition, several proposed software and hardware features can enable even sequential applications to execute in multithreaded mode <ref> [3, 4, 7, 13] </ref>. Once we have multiple threads, different architectures can be used. A promising approach is the on-chip multiprocessor [11] and its variants such as the Multiscalar [14], and the Superthreaded architectures [15].
Reference: [8] <author> D. Lenoski, J. Laudon, K. Gharachorloo, A. Gupta, and J. Hennessy. </author> <title> The Directory-based Cache Coherence Protocol for the DASH Multiprocessor. </title> <booktitle> In 17th International Symposium on Computer Architecture, </booktitle> <pages> pages 148-159, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: IPC/cluster (int/ld-st/fp) & Reorder buffer (int/fp) per Cluster [Chip] per Cluster [Chip] per Cluster [Chip] F A 8 8, 1 1 <ref> [8] </ref> 1/1/1 [8/8/8] 16 [128] 16/16 [128/128] F A 2 2, 4 1 [2] 4/4/4 [8/8/8] 64 [128] 64/64 [128/128] SM T 4 4, 2 2 [8] 2/2/2 [8/8/8] 32 [128] 32/32 [128/128] SM T 1 1, 8 8 [8] 6/4/4 [6/4/4] 128 [128] 128/128 [128/128] Table 2: Description of the <p> IPC/cluster (int/ld-st/fp) & Reorder buffer (int/fp) per Cluster [Chip] per Cluster [Chip] per Cluster [Chip] F A 8 8, 1 1 <ref> [8] </ref> 1/1/1 [8/8/8] 16 [128] 16/16 [128/128] F A 2 2, 4 1 [2] 4/4/4 [8/8/8] 64 [128] 64/64 [128/128] SM T 4 4, 2 2 [8] 2/2/2 [8/8/8] 32 [128] 32/32 [128/128] SM T 1 1, 8 8 [8] 6/4/4 [6/4/4] 128 [128] 128/128 [128/128] Table 2: Description of the different types of architectures evaluated. <p> Cluster [Chip] per Cluster [Chip] F A 8 8, 1 1 <ref> [8] </ref> 1/1/1 [8/8/8] 16 [128] 16/16 [128/128] F A 2 2, 4 1 [2] 4/4/4 [8/8/8] 64 [128] 64/64 [128/128] SM T 4 4, 2 2 [8] 2/2/2 [8/8/8] 32 [128] 32/32 [128/128] SM T 1 1, 8 8 [8] 6/4/4 [6/4/4] 128 [128] 128/128 [128/128] Table 2: Description of the different types of architectures evaluated. <p> Consequently, we assume a perfect instruction cache. Finally, the 512-entry TLB is shared by all threads and is fully associative and uses random replacement. For the low-end machine, we model a simple workstation. For the high-end machine, we model a scalable shared-memory multiprocessor similar to DASH <ref> [8] </ref> as shown in Figure 3. Each node has a portion of the global shared memory and directory. The remote latencies, specified in Table 3, are low because we only model a 4-node machine. 4 Evaluation Environment Our simulation environment is built upon the MINT [18] execution-driven simulation environment.
Reference: [9] <author> J. Lo, S. Eggers, J. Emer, H. Levy, R. Stamm, and D. Tullsen. </author> <title> Converting Thread-Level Parallelism Into Instruction-Level Parallelism via Simultaneous Multi-threading. </title> <journal> ACM Transactions on Computer Systems, </journal> <pages> pages 322-354, </pages> <month> August </month> <year> 1997. </year>
Reference-contexts: Tullsen et al [16] describe a fully centralized SMT architecture with a relatively small impact on a conventional superscalar design. Evaluation of this architecture when running multiprogrammed and parallel workloads <ref> [6, 9, 16] </ref> has shown significant speedups. However, a drawback of this approach is that it may inherit all the complexity of existing superscalars and, in addition, add extra hardware.
Reference: [10] <editor> E. Lusk et al. </editor> <title> Portable Programs for Parallel Processors. </title> <publisher> Holt, Rinehart and Winston Inc., </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: We choose six applications. Three applications are SPEC95 benchmarks, namely, swim, tomcatv and mgrid ; one is a NASA7 kernel, vpenta, and the remaining two are SPLASH-2 applications [19], namely fmm and ocean. The two SPLASH-2 applications are explicitly-parallel programs written in C and use ANL m4 macros <ref> [10] </ref> for parallel constructs. The SPEC95 benchmarks and the NASA7 kernel are sequential programs written in Fortran. We use the Polaris automatic paralleliz-ing compiler [1] to identify parallel sections of the code.
Reference: [11] <author> K. Olukotun, B. Nayfeh, L. Hammond, K. Wilson, and K. Chang. </author> <title> The Case for a Single-Chip Multiprocessor. </title> <booktitle> In 7th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 2-11, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: In addition, several proposed software and hardware features can enable even sequential applications to execute in multithreaded mode [3, 4, 7, 13]. Once we have multiple threads, different architectures can be used. A promising approach is the on-chip multiprocessor <ref> [11] </ref> and its variants such as the Multiscalar [14], and the Superthreaded architectures [15].
Reference: [12] <author> S. Palacharla, N. Jouppi, and J. Smith. </author> <title> Complexity-Effective Superscalar Processors. </title> <booktitle> In 24th International Symposium on Computer Architecture, </booktitle> <pages> pages 206-218, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: However, a drawback of this approach is that it may inherit all the complexity of existing superscalars and, in addition, add extra hardware. In fact, with the delays in the register bypass network dictating the cycle-time of future high-issue processors <ref> [12] </ref>, a fully centralized SMT processor will likely have a slower clock frequency. A very intuitive alternative to these two architectures is a hybrid of the FA and the centralized SMT approaches, namely a clustered SMT architecture. <p> Specifi cally, one of the major bottlenecks in the architecture is the large interconnection network between the functional units and the register file. Part of this network, namely the bypass network, may actually determine the clock cycle-time of high-issue processors <ref> [12] </ref>. 3.3 Fixed Assignment Architectures To alleviate the bypass delay problem and also reduce the resource centralization, we partition the SMT processor into several clusters. For instance, SM T 2 has 2 clusters where each cluster is a SMT processor that supports 4 threads. <p> Similarly, the SM T 4 processor has 4 clusters, each supporting 2 threads and able to issue 2 instructions per cycle (Table 2). Note that the cycle-time of these clustered architectures is much smaller than that of the centralized SMT. Indeed, Palacharla and Jouppi <ref> [12] </ref> estimate that the cycle-time for an 8-issue processor will be twice as long as a 4-issue processor when using 0.18 technology. In the light of their observations, SM T 2 , with two 4-issue clusters, may have a frequency that is twice higher than SM T 1 . <p> In terms of cycle-time and space requirements, SM T 2 is similar to F A 2 , while SM T 4 is similar to F A 4 . This is because, unlike in a 8-issue superscalar, the register bypass delay does not decide the cycle-time in a 4-issue superscalar <ref> [12] </ref>. Details on the configuration of the various processor archi Number of Threads per Number of Entries in Number of Processor Clusters, Cluster [Chip] Functional Units Instruction Queue Renaming Registers Type Max. <p> This is because the F A 2 architecture has largely the same cycle-time as SM T 2 . The reason is that both architectures have 4-issue superscalar clusters. These 4-issue superscalars do not have as much cycle-time constraints as higher-issue processors <ref> [12] </ref>. In addition, with current technology [2], the difference in cycle-time between 4-issue processors and lower-issue processors (F A 4 and F A 8 ) is very unlikely to be significant enough to make up for the large difference in performance shown in the figure. <p> Finally, F A 1 , which is a conventional superscalar, is likely to have a larger cycle-time than F A 2 or SM T 2 <ref> [12] </ref>. (a) Low-end machine. (b) High-end machine. letter in its name. 5.1.1 Comparing the Results to the Model We now qualitatively compare the results obtained to the performance predicted by our model of parallelism in Section 2. For each application, we estimate the thread parallelism and the ILP roughly. <p> Therefore, the conclusions for the low-end system apply fully here. The SM T 2 architecture is again only slightly slower than SM T 1 . If we now consider the differences in clock cycle-time, the picture changes dramatically in favor of the SM T 2 architecture. According to <ref> [12] </ref>, 4-issue clusters are likely to have a factor of 2 in clock frequency advantage over the centralized 8-issue cluster. This gives a very large clock frequency advantage to SM T 2 over SM T 1 .
Reference: [13] <author> E. Rotenberg, S. Bennett, and J. Smith. </author> <title> Trace Cache: A Low Latency Approach to High Bandwidth Instruction Fetching. </title> <booktitle> In 29th International Symposium on Microar-chitecture, </booktitle> <month> December </month> <year> 1996. </year>
Reference-contexts: An application can be divided into multiple threads by the compiler [1, 5] or by user hand-parallelization. In addition, several proposed software and hardware features can enable even sequential applications to execute in multithreaded mode <ref> [3, 4, 7, 13] </ref>. Once we have multiple threads, different architectures can be used. A promising approach is the on-chip multiprocessor [11] and its variants such as the Multiscalar [14], and the Superthreaded architectures [15].
Reference: [14] <author> G. Sohi, S. Breach, and T. Vijayakumar. </author> <title> Multiscalar Processors. </title> <booktitle> In 22nd International Symposium on Computer Architecture, </booktitle> <pages> pages 414-425, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: In addition, several proposed software and hardware features can enable even sequential applications to execute in multithreaded mode [3, 4, 7, 13]. Once we have multiple threads, different architectures can be used. A promising approach is the on-chip multiprocessor [11] and its variants such as the Multiscalar <ref> [14] </ref>, and the Superthreaded architectures [15].
Reference: [15] <author> J. Tsai and P. Yew. </author> <title> The Superthreaded Architecture: Thread Pipelining with Run-Time Data Dependence Checking and Control Speculation. </title> <booktitle> In Proceedings of International Conference on Parallel Architectures and Compilation Techniques (PACT '96), </booktitle> <pages> pages 35-46, </pages> <month> Oc-tober </month> <year> 1996. </year>
Reference-contexts: Once we have multiple threads, different architectures can be used. A promising approach is the on-chip multiprocessor [11] and its variants such as the Multiscalar [14], and the Superthreaded architectures <ref> [15] </ref>.
Reference: [16] <author> D. Tullsen, S. Eggers, J. Emer, H. Levy, J. Lo, and R. Stamm. </author> <title> Exploiting Choice: Instruction Fetch and Issue on an implementable Simultaneous Multithreading Processor. </title> <booktitle> In 23rd International Symposium on Computer Architecture, </booktitle> <pages> pages 191-202, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: The major advantage of this approach is that the resources tend to be highly utilized. If, in a given cycle, a thread is not using a resource, that resource can, typically, be utilized by another thread. Tullsen et al <ref> [16] </ref> describe a fully centralized SMT architecture with a relatively small impact on a conventional superscalar design. Evaluation of this architecture when running multiprogrammed and parallel workloads [6, 9, 16] has shown significant speedups. <p> Tullsen et al [16] describe a fully centralized SMT architecture with a relatively small impact on a conventional superscalar design. Evaluation of this architecture when running multiprogrammed and parallel workloads <ref> [6, 9, 16] </ref> has shown significant speedups. However, a drawback of this approach is that it may inherit all the complexity of existing superscalars and, in addition, add extra hardware. <p> In this architecture, the chip has several independent processing units, with each unit having the capability to perform simultaneous multi-threading. Given that the effort to enhance a conventional dynamic superscalar to perform simultaneous multithreading is small <ref> [16] </ref>, a low-issue SMT processor is feasible. A clustered SMT architecture would be a simple design as it would involve replicating several such low-issue SMT processors on a die. However, it might be argued that this separation of processing units would restrict the sharing of resources. <p> Caches are non-blocking with up to 32 outstanding loads allowed with full load bypassing enabled. Table 1 gives details on the functional units and the instructions that they handle. 3.2 Centralized and Clustered SMT Ar chitectures The fully centralized SMT architecture is on the lines of <ref> [16] </ref>. It can support up to 8 threads and can issue up to 8 instructions per cycle (Table 2). The instruction fetch unit is shared by all threads, with each thread having a program counter. The fetch unit fetches instructions from a different thread every cycle in a round-robin fashion. <p> For example, instructions issued by a thread may remain in the queue for a long time waiting on a cache miss. Since they clog the queue, other threads are unable to fetch instructions. This fetch bottleneck has been discussed in great detail by Tullsen et al <ref> [16] </ref>. They suggest several alternatives, such as partitioning the fetch unit or using instruction count feedback techniques to use the fetch unit more intelligently. The centralized SMT is more susceptible to this problem than the clustered SMTs.
Reference: [17] <author> D. Tullsen, S. Eggers, and H. Levy. </author> <title> Simultaneous Multi-threading: Maximizing on-chip Parallelism. </title> <booktitle> In 22nd International Symposium on Computer Architecture, </booktitle> <pages> pages 392-403, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: To utilize the resources better, we can design a more centralized architecture, where threads can share all the resources. This is the approach taken by Simultaneous Mul-tithreading (SMT) <ref> [17] </ref>. In this scheme, the processor can support multiple threads such that, in a given cycle, instructions from different threads can be issued. The major advantage of this approach is that the resources tend to be highly utilized.
Reference: [18] <author> J. Veenstra and R. Fowler. MINT: </author> <title> A Front End for Efficient Simulation of Shared-Memory Multiprocessors. </title> <booktitle> In Proceedings of the Second International Workshop on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS'94), </booktitle> <pages> pages 201-207, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: Each node has a portion of the global shared memory and directory. The remote latencies, specified in Table 3, are low because we only model a 4-node machine. 4 Evaluation Environment Our simulation environment is built upon the MINT <ref> [18] </ref> execution-driven simulation environment. MINT captures both application and library code execution and generates events by instrumenting binaries. We have modified the MINT front-end to handle MIPS2 binaries as well as instrument basic block boundaries. The application is executed through MINT, which generates basic block and memory events.
Reference: [19] <author> S. Woo, M. Ohara, E. Torrie, J. Singh, and A. Gupta. </author> <title> The SPLASH-2 Programs: Characterization and Methodological Considerations. </title> <booktitle> In 22nd International Symposium on Computer Architecture, </booktitle> <pages> pages 24-36, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: For F A 8 as well as for SMT processors, 8 threads are created. We choose six applications. Three applications are SPEC95 benchmarks, namely, swim, tomcatv and mgrid ; one is a NASA7 kernel, vpenta, and the remaining two are SPLASH-2 applications <ref> [19] </ref>, namely fmm and ocean. The two SPLASH-2 applications are explicitly-parallel programs written in C and use ANL m4 macros [10] for parallel constructs. The SPEC95 benchmarks and the NASA7 kernel are sequential programs written in Fortran.
References-found: 19

