URL: ftp://ftp.cs.utexas.edu/pub/mooney/papers/pac-bkchapter-94.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/ml/abstracts.html
Root-URL: 
Email: mooney@cs.utexas.edu  
Title: A Preliminary PAC Analysis of Theory Revision  
Author: Raymond J. Mooney 
Date: October 13, 1993  
Address: Austin, TX 78712  
Affiliation: Department of Computer Sciences University of Texas  
Abstract: This paper presents a preliminary analysis of the sample complexity of theory revision within the framework of PAC (Probably Approximately Correct) learnability theory. By formalizing the notion that the initial theory is "close" to the correct theory we show that the sample complexity of an optimal propositional Horn-clause theory revision algorithm is O((ln 1=ffi + d ln(s 0 + d + n))=*), where d is the syntactic distance between the initial and correct theories, s 0 is the size of initial theory, n is the number of observable features, and * and ffi are the standard PAC error and probability bounds. The paper also discusses the problems raised by the computational complexity of theory revision. fl This research was supported by the National Science Foundation under grant IRI-9102926, the NASA Ames Research Center under grant NCC 2-629, the Texas Advanced Research Program under grant 003658114. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Birnbaum, L. A., and Collins, G. C., </author> <title> editors (1991). </title> <booktitle> Proceedings of the Eighth International Workshop on Machine Learning: Section on Learning From Theory and Data. </booktitle> <address> Evanston, IL. </address>
Reference: <author> Blumer, A., Ehrenfeucht, A., Haussler, D., and Warmuth, M. </author> <year> (1987). </year> <title> Occam's razor. </title> <journal> Information Processing Letters, </journal> <volume> 24 </volume> <pages> 377-380. </pages>
Reference-contexts: An analysis of the VC-dimension of this hypothesis space, would provide such a lower bound (Ehrenfeucht et al., 1989). The above results are closely related to previous results on the sample complexity of learning concepts representable with a limited number of bits <ref> (Blumer et al., 1987) </ref>. With respect to pure induction, the term s c ln (s c + n) in Equation 7 is proportional to the number of bits needed to represent a theory with s c literals. <p> If an algorithm is guaranteed to find a consistent hypothesis that is within a polynomial factor of the simplest one, its sample complexity is still polynomial <ref> (Blumer et al., 1987) </ref>. In particular, a greedy algorithm for simple conjunctive concepts is known to find a hypothesis that is within a logarithmic factor of optimal (Haussler, 1988).
Reference: <author> Cain, T. </author> <year> (1991). </year> <title> The DUCTOR: A theory revision system for propositional domains. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> 485-489. </pages> <address> Evanston, IL. </address>
Reference: <author> Clark, K. </author> <year> (1978). </year> <title> Negation as failure. </title> <editor> In Gallaire, H., and Minker, J., editors, </editor> <booktitle> Logic and Data Bases. </booktitle> <address> New York, NY: </address> <publisher> Plenum Press. </publisher>
Reference-contexts: An instance is classified as a positive example of the target concept if and only if, given its features as facts, C can be derived using normal Prolog-style deduction (SLD resolution). A closed-world assumption is also made <ref> (Clark, 1978) </ref>, so that if C cannot be derived, an example is classified as negative (:C). For propositional Horn-clause theories, a simple set of primitive syntactic modifications is the addition and deletion of individual literals.
Reference: <author> Ehrenfeucht, A., Haussler, D., Kearns, M., and Valiant, L. </author> <year> (1989). </year> <title> A general lower bound on the number of examples needed for learning. </title> <journal> Information and Computation, </journal> <volume> 82 </volume> <pages> 267-284. </pages>
Reference-contexts: Of course, a guarantee that the sample complexity of theory refinement is lower would require a lower bound on the sample complexity of pure induction of theories with at most s c literals. An analysis of the VC-dimension of this hypothesis space, would provide such a lower bound <ref> (Ehrenfeucht et al., 1989) </ref>. The above results are closely related to previous results on the sample complexity of learning concepts representable with a limited number of bits (Blumer et al., 1987).
Reference: <author> Ginsberg, A. </author> <year> (1990). </year> <title> Theory reduction, theory revision, </title> <booktitle> and retranslation. In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> 777-782. </pages> <address> Detroit, MI. </address>
Reference: <author> Ginsberg, A., Weiss, S. M., and Politakis, P. </author> <year> (1988). </year> <title> Automatic knowledge based refinement for classification systems. </title> <journal> Artificial Intelligence, </journal> <volume> 35 </volume> <pages> 197-226. </pages>
Reference-contexts: One way to use prior knowledge to bias learning is to revise an existing imperfect domain theory to fit empirical data. This approach has important applications to automatically refining knowledge bases for expert systems <ref> (Ginsberg et al., 1988) </ref>. This paper presents a preliminary analysis of theory revision within the framework of PAC (probably approximately correct) learnability theory (Valiant, 1984). Specifically, this paper analyzes the sample complexity (the number of examples required to learn a PAC concept) of propositional Horn-clause theory revision.
Reference: <author> Haussler, D. </author> <year> (1988). </year> <title> Quantifying inductive bias: </title> <journal> Artificial intelligence learning algorithms and Valiant's learning framework. Artificial Intelligence, </journal> <volume> 26 </volume> <pages> 177-221. </pages>
Reference-contexts: Typical examples are pure conjunctive, 3 which is the minimum number of examples m such that for any target concept h 2 H and any distribution on X, given m random examples of h, L produces a hypothesis that, with probability at least 1 ffi, has error at most * <ref> (Haussler, 1988) </ref>. A learning algorithm L is said to use a hypothesis space H consistently if it always returns a hypothesis in H that is consistent with the training set or else correctly indicates that no hypothesis in H is consistent with the given examples. <p> S L 1 (ln ffi This result clearly indicates that the number of examples needed to learn a PAC concept description is directly related to the size of the restricted space of concepts in which the target concept is known to belong, and hence formalizes the notion of inductive bias <ref> (Haussler, 1988) </ref>. 3 An Approach to PAC Analysis of Theory Revision In order to analyze the sample complexity of a theory revision algorithm, we need to formally specify the restricted space of hypotheses that are explored by such an algorithm. <p> In particular, a greedy algorithm for simple conjunctive concepts is known to find a hypothesis that is within a logarithmic factor of optimal <ref> (Haussler, 1988) </ref>. Consequently, its sample and computational complexity are both O (s log (n)) where s is the size of the concept to be learned. The sample complexity of such approximation algorithms is determined by the size of their effective hypothesis space. <p> The effective hypothesis space for a learning algorithm L for a concept class C, denoted H L C (m), is the set of all hypotheses produced by L from samples of size m of target concepts in C <ref> (Haussler, 1988) </ref>.
Reference: <author> Matwin, S., and Plante, B. </author> <year> (1991). </year> <title> A deductive-inductive method for theory revision. </title> <booktitle> In Proceedings of the International Workshop on Multistrategy Learning, </booktitle> <pages> 160-174. </pages> <address> Harper's Ferry, W.Va. </address> <note> 13 Mooney, </note> <author> R., and Ourston, D. </author> <title> (in press). A multistrategy approach to theory refinement. </title> <editor> In Michalski, R. S., and Teccuci, G., editors, </editor> <title> Machine Learning: A Multistrategy Approach, </title> <booktitle> Vol. IV. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference: <author> Ourston, D. </author> <year> (1991). </year> <title> Using Explanation-Based and Empirical Methods in Theory Revision. </title> <type> PhD thesis, </type> <institution> University of Texas, Austin, TX. </institution> <note> Also appears as Artificial Intelligence Laboratory Technical Report AI 91-164. </note>
Reference: <author> Ourston, D., and Mooney, R. </author> <year> (1990). </year> <title> Changing the rules: A comprehensive approach to theory refinement. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> 815-820. </pages> <address> Detroit, MI. </address>
Reference-contexts: Theory revision systems generally syntactically modify the initial theory to make it fit the training data. Sample modifications include adding and deleting rules and their antecedents <ref> (Ourston and Mooney, 1990) </ref>. Therefore, one way of measuring the distance between two theories is to determine the minimum number of primitive syntactic modifications needed to transform one theory into the other.
Reference: <author> Quinlan, J. R. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106. </pages>
Reference-contexts: It compares classification accuracy on novel test data for the Either theory refinement system (Ourston and Mooney, 1990; Ourston, 1991; Mooney and Ourston, in press) and the ID3 inductive system <ref> (Quinlan, 1986) </ref>. Since Either uses ID3 as an inductive component, Either's performance without an initial theory is the same as ID3's. It clearly show the advantage of theory refinement over pure induction.
Reference: <editor> Segre, A., editor (1989). </editor> <booktitle> Proceedings of the Sixth International Workshop on Machine Learning: Section on Combining Empirical and Explanation-Based Learning. </booktitle> <address> Ithaca, NY. </address>
Reference: <author> Shavlik, J., and Dietterich, T. </author> <year> (1990). </year> <title> Inductive learning from preclassified examples: Introduction. </title> <editor> In Shavlik, J., and Dietterich, T., editors, </editor> <booktitle> Readings in Machine Learning, </booktitle> <pages> 45-56. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: This is a common problem in machine learning polynomial approximation algorithms for minimum decision trees and minimum three-layer neural networks are also open problems <ref> (Shavlik and Dietterich, 1990) </ref>.
Reference: <author> Towell, G. G. </author> <year> (1991). </year> <title> Symbolic Knowledge and Neural Networks: Insertion, Refinement, and Extraction. </title> <type> PhD thesis, </type> <institution> University of Wisconsin, Madison, WI. </institution>
Reference: <author> Towell, G. G., Shavlik, J. W., and Noordewier, M. O. </author> <year> (1990). </year> <title> Refinement of approximate domain theories by knowledge-based artificial neural networks. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> 861-866. </pages> <address> Boston, MA. </address>
Reference-contexts: For example, Figure 1 shows learning curves for revising a theory for recognizing promoter sequences in DNA, a problem introduced by <ref> (Towell et al., 1990) </ref>. It compares classification accuracy on novel test data for the Either theory refinement system (Ourston and Mooney, 1990; Ourston, 1991; Mooney and Ourston, in press) and the ID3 inductive system (Quinlan, 1986). <p> Further evidence that purely semantic criteria do not adequately measure the goodness of a theory is the observation that many useful initial theories have very poor accuracy. For example, the DNA promoter theory used in many recent experiments in theory revision <ref> (Towell et al., 1990) </ref> has an accuracy no better than random chance. Despite this fact, it is syntactically close to the correct theory and revising it produces a more accurate theory than pure induction. Consequently, it seems the characterization of the ideal revision must incorporate both semantic and syntactic criteria.
Reference: <author> Valiant, L. G. </author> <year> (1984). </year> <title> A theory of the learnable. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 27(11) </volume> <pages> 1134-1142. </pages>
Reference-contexts: This approach has important applications to automatically refining knowledge bases for expert systems (Ginsberg et al., 1988). This paper presents a preliminary analysis of theory revision within the framework of PAC (probably approximately correct) learnability theory <ref> (Valiant, 1984) </ref>. Specifically, this paper analyzes the sample complexity (the number of examples required to learn a PAC concept) of propositional Horn-clause theory revision.
Reference: <author> Winston, P. H., Binford, T. O., Katz, B., and Lowry, M. </author> <year> (1983). </year> <title> Learning physical descriptions from functional definitions, examples, and precedents. </title> <booktitle> In Proceedings of the Third National Conference on Artificial Intelligence, </booktitle> <pages> 433-439. </pages> <address> Washington, D.C. </address> <month> 14 Footnotes 1. </month> <title> A hypothesis space is also frequently referred to as a concept class. Typical examples are pure conjunctive, DNF, k-DNF, etc.. 2. This is a direct consequence of a result in Blumer et al. (1987). 15 Figure Captions * Figure 1: Learning Curves for the DNA Promoter Problem. * Figure 2: Restricted Hypothesis Space for Theory Revision. </title> <type> 16 17 18 </type>
Reference-contexts: A Horn clause is a disjunction of literals, of which at most one is positive. They are normally written in the form of backward-chaining rules (as in Prolog). An example of a propositional Horn-clause theory for the standard "cup" concept <ref> (Winston et al., 1983) </ref> is shown in Figure 1.
References-found: 18

