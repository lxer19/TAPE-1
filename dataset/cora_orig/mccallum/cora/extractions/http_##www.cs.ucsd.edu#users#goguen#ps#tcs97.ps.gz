URL: http://www.cs.ucsd.edu/users/goguen/ps/tcs97.ps.gz
Refering-URL: http://www.cs.ucsd.edu/users/goguen/new.html
Root-URL: http://www.cs.ucsd.edu
Title: Tossing Algebraic Flowers down the Great Divide  
Author: Joseph Goguen 
Affiliation: Dept. Computer Science Engineering, University of California at San Diego  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Jon Barwise. </author> <title> Mathematical proofs of computer system correctness. </title> <type> Technical Report CSLI-89-136, </type> <institution> Center for the Study of Language and Information, Stanford University, </institution> <month> August </month> <year> 1989. </year>
Reference-contexts: Finally, as noted in the first paragraph of Section 2.4, correctness of code is the wrong problem to solve. (An overview of some recent debates on philosophical foundations of formal methods may be found in <ref> [1] </ref>.) A further difficulty with formal methods is that they tend to be very brittle, in the sense that slight changes in a specification can lead to drastic changes in what must be done to achieve that spec.
Reference: [2] <author> Gregory Bateson. </author> <title> Mind and Nature: A Necessary Unity. </title> <address> Bantam, </address> <year> 1980. </year>
Reference-contexts: of components that produces the components that: (i) through their interactions and transformations continuously regenerate the network of processes that produced them; and (ii) constitute it as a concrete unity in the space in which they exist by specifying the topological domain of its realization as such a network. (See <ref> [2, 167, 143, 145] </ref> for more on this area, and see [171, 112] for some possibly ill-advised attempts to formalize this notion; also cf. footnote 4.
Reference: [3] <author> D.E. Bell and L.J. LaPadula. </author> <title> Secure computer systems: Mathematical foundations and model. </title> <type> Technical report, </type> <institution> MITRE, </institution> <year> 1974. </year>
Reference-contexts: I encountered some examples of this in the area of computer security, in connection with the so-called Bell-LaPadula security model <ref> [3, 91, 93] </ref>.
Reference: [4] <author> Matthew Bickerton and Jawed Siddiqi. </author> <title> The classification of requirements engineering methods. </title> <editor> In Stephen Fickas and Anthony Finkelstein, editors, </editor> <booktitle> Requirements Engineering '93, </booktitle> <pages> pages 182-186. </pages> <publisher> IEEE, </publisher> <year> 1993. </year>
Reference-contexts: The first was a case study in requirements elicitation using techniques from sociology and linguistics, particularly interaction (video) analysis, but also discourse and conversation analyses [118, 136]. The second was a classification of methods and tools used for requirements <ref> [4] </ref>. The first project built on early work with Linde on requirements elicitation [81], which was followed by a critical survey of elicitation methods [83]. The second project was in part inspired by work of Lyotard [138] on post-modernism.
Reference: [5] <author> Barry Boehm. </author> <title> Software Engineering Economics. </title> <publisher> Prentice-Hall, </publisher> <year> 1981. </year>
Reference-contexts: But we now know, and even then many suspected, that this is not where the leverage lies for real applications; in fact, most debugging effort goes into fixing errors in requirements, specifications and designs, and very little into fixing errors in coding (around 5%) <ref> [5] </ref>. Moreover, the problems that arise for large programs are qualitatively very different from those that arise for small programs. <p> in general, the greater the accuracy, the greater the difficulty. 3.2 Requirements Engineering Case studies and experience suggest that flawed requirements may be the most significant source of errors in system development; moreover, it has been shown that requirements errors are the most expensive to correct 11 at later stages <ref> [5] </ref>. Case studies and experience also suggest that social, political and cultural factors are very often responsible for the flaws in requirements; however, this area has been little studied. It follows that studying social aspects of requirements engineering has great leverage.
Reference: [6] <author> Geoffrey Bowker, Leigh Star, William Turner, and Les Gasser. </author> <title> Social Science, Technical Systems and Cooperative Work: Beyond the Great Divide. </title> <publisher> Erlbaum, </publisher> <year> 1997. </year>
Reference-contexts: practice in computing, mainly using various kinds of algebra, as well as to bridge the "even greater divide" between technical and social aspects of computing, which in turn is but a small part of the huge rift between science and technology on one side, and society on the other (see <ref> [6] </ref> for more on this). <p> This is not an appropriate place for details, but we should recall that understanding values can be crucial for getting requirements that match user needs. Other perspectives on the "great divide" can be found in the book <ref> [6] </ref> in which the paper [69] appears. A more radical view appears in [119], where Heidegger considers Western civilization to be fundamentally entangled with a separation of technology from ethics, based on an untenable instrumental conception of technology; see also the discussions in [61] and [63].
Reference: [7] <author> Rod Burstall and Razvan Diaconescu. </author> <title> Hiding and behaviour: an institutional approach. </title> <editor> In A. William Roscoe, editor, </editor> <title> A Classical Mind: </title> <booktitle> Essays in Honour of C.A.R. Hoare, </booktitle> <pages> pages 75-92. </pages> <publisher> Prentice Hall, </publisher> <year> 1994. </year>
Reference-contexts: In collaboration with Razvan Diaconescu, Rod Burstall, and most recently especially Grant Malcolm, this work has developed into a new hidden algebra approach <ref> [54, 58, 77, 7, 87, 140, 89] </ref>, intended to facilitate proving properties of designs, as opposed to code, and in particular, to facilitate refinement proofs, that one level of design is correctly realized by another.
Reference: [8] <author> Rod Burstall and Joseph Goguen. </author> <title> Putting theories together to make specifications. </title> <editor> In Raj Reddy, editor, </editor> <booktitle> Proceedings, Fifth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1045-1058. </pages> <institution> Department of Computer Science, Carnegie-Mellon University, </institution> <year> 1977. </year>
Reference-contexts: Of course, things weren't entirely straightforward it seems they never are! but Rod Burstall and I succeeded in designing the Clear specification language <ref> [8, 9, 10] </ref>, which integrated initial and loose semantics with generic modules using "data constraints" 7 by extending an idea of Horst Reichel [161]. Clear seems to have been the first specification language with a rigorous semantic definition, and its modules seemed promising as a way to handle large systems.
Reference: [9] <author> Rod Burstall and Joseph Goguen. </author> <title> The semantics of Clear, a specification language. </title> <editor> In Dines Bjorner, editor, </editor> <booktitle> Proceedings, 1979 Copenhagen Winter School on Abstract Software Specification, </booktitle> <pages> pages 292-332. </pages> <publisher> Springer, </publisher> <year> 1980. </year> <booktitle> Lecture Notes in Computer Science, Volume 86; based on unpublished notes handed out at the Symposium on Algebra and Applications, </booktitle> <institution> Stefan Banach Center, Warsaw, Poland, </institution> <year> 1978. </year>
Reference-contexts: Of course, things weren't entirely straightforward it seems they never are! but Rod Burstall and I succeeded in designing the Clear specification language <ref> [8, 9, 10] </ref>, which integrated initial and loose semantics with generic modules using "data constraints" 7 by extending an idea of Horst Reichel [161]. Clear seems to have been the first specification language with a rigorous semantic definition, and its modules seemed promising as a way to handle large systems.
Reference: [10] <author> Rod Burstall and Joseph Goguen. </author> <title> An informal introduction to specifications using Clear. </title> <editor> In Robert Boyer and J Moore, editors, </editor> <booktitle> The Correctness Problem in Computer Science, </booktitle> <pages> pages 185-213. </pages> <publisher> Academic, </publisher> <year> 1981. </year> <title> Reprinted in Software Specification Techniques, </title> <editor> Narain Gehani and Andrew McGettrick, editors, </editor> <publisher> Addison-Wesley, </publisher> <year> 1985, </year> <pages> pages 363-390. </pages>
Reference-contexts: Of course, things weren't entirely straightforward it seems they never are! but Rod Burstall and I succeeded in designing the Clear specification language <ref> [8, 9, 10] </ref>, which integrated initial and loose semantics with generic modules using "data constraints" 7 by extending an idea of Horst Reichel [161]. Clear seems to have been the first specification language with a rigorous semantic definition, and its modules seemed promising as a way to handle large systems.
Reference: [11] <author> Manuel Clavel and Jose Meseguer. </author> <title> Reflection and strategies in rewriting logic. </title> <editor> In Jose Meseguer, editor, </editor> <booktitle> Proceedings, First International Workshop on Rewriting Logic and its Applications. Elsevier Science, 1996. Volume 4, Electronic Notes in Theoretical Computer Science. </booktitle>
Reference-contexts: Despite all the interest once shown in declarative programming, the Fifth Generation, etc., there seems to be little interest in precise explications for declarative and logical programming and reflection, or in general purpose declarative architectures. See <ref> [11] </ref> for the latest on reflective logic and its applications. 2.10 Hidden Algebra While (order sorted) equational logic works well for unchanging (immutable or "Platonic") data types like the numbers, it can be awkward for software modules having an internal state that changes over time.
Reference: [12] <editor> Steven Collins. Selfless Persons. </editor> <address> Cambridge, </address> <year> 1983. </year>
Reference-contexts: In the early 1970s, there was no precise semantics for ADTs, so it was impossible to verify the correctness 4 The concept of interdependent origination goes back over 2,500 years to the Buddha; in the Pali language, it is called pat . icca-samuppada <ref> [12] </ref>.
Reference: [13] <author> Corina C^rstea. </author> <title> A semantic study of the object paradigm, 1996. </title> <type> Transfer thesis, </type> <institution> Programming Research Group, Oxford University. </institution>
Reference-contexts: A hidden Herbrand theorem which unifies the object and logic paradigms at the logical level is proved in [90]. There is now an excellent hidden group at Oxford, including Grant Malcolm, Corina C^rstea, James Worrell, and Simone Veglioni <ref> [139, 13, 14, 172] </ref>; the recent proof that categories of hidden algebras are topoi [142] is especially exciting.
Reference: [14] <author> Corina C^rstea. </author> <title> Coalgebra semantics for hidden algebra: parameterized objects and inheritance, </title> <booktitle> 1997. Paper presented at 12th Workshop on Algebraic Development Techniques. </booktitle>
Reference-contexts: A hidden Herbrand theorem which unifies the object and logic paradigms at the logical level is proved in [90]. There is now an excellent hidden group at Oxford, including Grant Malcolm, Corina C^rstea, James Worrell, and Simone Veglioni <ref> [139, 13, 14, 172] </ref>; the recent proof that categories of hidden algebras are topoi [142] is especially exciting.
Reference: [15] <author> Razvan Diaconescu. </author> <title> Category-based Semantics for Equational and Constraint Logic Programming. </title> <type> PhD thesis, </type> <institution> Programming Research Group, Oxford University, </institution> <year> 1994. </year>
Reference-contexts: Although successful in this sense within the algebraic specification community, OSA seems to have had little influence elsewhere, and retracts have not been taken up anywhere. 8 2.8 Semantics of Logic Programming Eqlog <ref> [95, 15] </ref> combines (equality based) functional programming with (predicate based) logic programming, by combining their logics, which are equational and Horn clause logic respectively, to get Horn clause logic with equality (actually the order sorted version). <p> The initial model idea appears in a new guise in [96], to handle the semantics of logic programming over builtin types and algorithms as free extensions of the given builtin model. This idea also features in the elegant semantics for so called constraint based programming developed by Diaconescu <ref> [15, 16] </ref>. However initiality is not the right semantics for every logical language. Programming paradigms can be combined by viewing them as logical programming languages and then combining their logics [49, 74, 96].
Reference: [16] <author> Razvan Diaconescu. </author> <title> A category-based equational logic semantics to constraint programming. </title> <editor> In Magne Haver-aaen, Olaf Owe, and Ole-Johan Dahl, editors, </editor> <booktitle> Recent Trends in Data Type Specification, </booktitle> <pages> pages 200-222. </pages> <publisher> Springer, </publisher> <year> 1996. </year> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> Volume 389. </volume>
Reference-contexts: The initial model idea appears in a new guise in [96], to handle the semantics of logic programming over builtin types and algorithms as free extensions of the given builtin model. This idea also features in the elegant semantics for so called constraint based programming developed by Diaconescu <ref> [15, 16] </ref>. However initiality is not the right semantics for every logical language. Programming paradigms can be combined by viewing them as logical programming languages and then combining their logics [49, 74, 96].
Reference: [17] <author> Razvan Diaconescu. </author> <title> Extra theory morphisms for institutions: logical semantics for multi-paradigm languages. </title> <type> Technical Report IS-RR-96-0024S, </type> <institution> Japan Institute of Science and Technology, </institution> <year> 1996. </year> <note> To appear, J. Applied Categorical Structures. 18 </note>
Reference-contexts: There is now a rather large literature on institutions, with applications to many different areas, e.g., <ref> [17] </ref> concerns multi-institutional specification.
Reference: [18] <author> Razvan Diaconescu. </author> <title> Foundations of behavioural specification in rewriting logic. </title> <editor> In Jose Meseguer, editor, Pro--ceedings, </editor> <booktitle> First International Workshop on Rewriting Logic and its Applications. Elsevier Science, 1996. Volume 4, Electronic Notes in Theoretical Computer Science. </booktitle>
Reference-contexts: There is also an exciting flurry of hidden activity around the CafeOBJ project at the Japan Institute of Science and Technology, which includes Razvan Diaconescu, Kokichi Futatsugi, Shusaku Iida, Dorel Lucanu and Michihiro Matsumoto <ref> [18, 19, 20, 121] </ref>. 2.11 Distributed Cooperative Engineering with tatami Typical software engineering projects have multiple workers with multiple tasks that interleave in complex ways, often working at multiple sites with different schedules, so that it is difficult to share information and coordinate tasks; documentation is often hard to find, out
Reference: [19] <author> Razvan Diaconescu and Kokichi Futatsugi. </author> <title> Logical semantics for CafeOBJ. </title> <type> Technical Report IS-RR-96-0024S, </type> <institution> Japan Institute of Science and Technology, </institution> <year> 1996. </year>
Reference-contexts: There is also an exciting flurry of hidden activity around the CafeOBJ project at the Japan Institute of Science and Technology, which includes Razvan Diaconescu, Kokichi Futatsugi, Shusaku Iida, Dorel Lucanu and Michihiro Matsumoto <ref> [18, 19, 20, 121] </ref>. 2.11 Distributed Cooperative Engineering with tatami Typical software engineering projects have multiple workers with multiple tasks that interleave in complex ways, often working at multiple sites with different schedules, so that it is difficult to share information and coordinate tasks; documentation is often hard to find, out
Reference: [20] <author> Razvan Diaconescu and Kokichi Futatsugi. </author> <title> CafeOBJ Report: The Language, Proof Techniques, and Methodologies for Object-Oriented Algebraic Specification, volume 6. </title> <publisher> World Scientific, </publisher> <year> 1998. </year> <note> To appear, AMAST Series in Computing. </note>
Reference-contexts: The CafeOBJ consortium includes several large Japanese companies, and is supported by MITI (the Japanese Ministry of Industry and Technology); more information on this project can be obtained from http://ldl-www.jaist.ac.jp:8080/cafeobj and from <ref> [20] </ref>. 4. CoFI is another large effort to design and build an algebraic specification language. It is a highly collaborative multinational project with a distinctively European flavor, much influenced by the success of OBJ; see http://www.brics.dk/Projects/CoFI. <p> There is also an exciting flurry of hidden activity around the CafeOBJ project at the Japan Institute of Science and Technology, which includes Razvan Diaconescu, Kokichi Futatsugi, Shusaku Iida, Dorel Lucanu and Michihiro Matsumoto <ref> [18, 19, 20, 121] </ref>. 2.11 Distributed Cooperative Engineering with tatami Typical software engineering projects have multiple workers with multiple tasks that interleave in complex ways, often working at multiple sites with different schedules, so that it is difficult to share information and coordinate tasks; documentation is often hard to find, out
Reference: [21] <author> Razvan Diaconescu, Joseph Goguen, and Petros Stefaneas. </author> <title> Logical support for modularisation. </title> <editor> In Gerard Huet and Gordon Plotkin, editors, </editor> <booktitle> Logical Environments, </booktitle> <pages> pages 83-130. </pages> <address> Cambridge, </address> <year> 1993. </year>
Reference-contexts: The notion of inclusion system was introduced in <ref> [21] </ref> to axiomatize the notion of inclusion morphism in categorical terms, and then used to study some mathematical properties of specification modules, including the relation between pushouts preserving (various kinds of) conservative extension, Craig style interpolation properties, and some distributive laws for information hiding.
Reference: [22] <author> Edsger Dijkstra. </author> <title> Guarded commands, nondeterminacy and formal derivation of programs. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 18 </volume> <pages> 453-457, </pages> <year> 1975. </year>
Reference-contexts: Theoretical computer scientists need not look so far afield for examples of excessive modernism. What might be called the "error free" school of formal methods aims for programs that have no bugs at all. For example, <ref> [22] </ref> claims we have ... "a calculus" for a formal discipline a set of rules such that, if applied successfully: 14 (1) it will have derived a correct program; and (2) it will tell us that we have reached such a goal.
Reference: [23] <author> Hans-Dieter Ehrich, Joseph Goguen, and Amilcar Sernadas. </author> <title> A categorial theory of objects as observed processes. </title> <editor> In Jaco de Bakker, Willem de Roever, and Gregorz Rozenberg, editors, </editor> <booktitle> Foundations of Object Oriented Languages, </booktitle> <pages> pages 203-228. </pages> <publisher> Springer, </publisher> <year> 1991. </year> <note> Lecture Notes in Computer Science, Volune 489. </note>
Reference-contexts: A general theory of objects based on sheaf theory [40] arose from this work, and has been applied (for example) to the semantics of concurrent systems, including concurrent object based languages [62], hardware description languages [166], and semantics for object based concurrent information systems <ref> [23] </ref>. Sheaves can express the kind of local causality combined with global non-determinism that characterizes many different kinds of model, from partial differential equations to automata.
Reference: [24] <author> Hartmut Ehrig, Werner Fey, and Horst Hansen. </author> <title> act one: An algebraic specification language with two levels of semantics. </title> <type> Technical Report 83-03, </type> <institution> Technical University of Berlin, Fachbereich Informatik, </institution> <year> 1983. </year>
Reference-contexts: Many other languages have followed OBJ's lead, including act one <ref> [24] </ref>, which was used in the well known lotos hardware description language.
Reference: [25] <author> Samuel Eilenberg and Saunders Mac Lane. </author> <title> General theory of natural equivalences. </title> <journal> Transactions of the American Mathematical Society, </journal> <volume> 58 </volume> <pages> 231-294, </pages> <year> 1945. </year>
Reference-contexts: The journey through this paper has already encountered several cases where morphisms are important: initial extensions for constraint programming (in Section 2.9); data constraints (in Section 2.4); and inclusion systems (Section 2.4). Eilenberg and Mac Lane <ref> [25] </ref> gave this insight a more definite and systematic form with the invention of category theory. 12 explanations.
Reference: [26] <author> Gilles Fauconnier and Mark Turner. </author> <title> Conceptual projection and middle spaces. </title> <type> Technical Report 9401, </type> <institution> University of California at San Diego, 1994. Dept. of Cognitive Science. </institution>
Reference-contexts: Unfortunately there seem to be at least as many approaches to semiotics as there are authors who have considered it, and many other fields with different names also cover the same or closely related ground, e.g., cognitive linguistics <ref> [127, 26, 170] </ref>. Algebraic semiotics [70, 68] is one more: it tries to combine insights from both sides of the divide, to obtain a precise formulation of certain problems about meaning and to allow the construction of supporting technology. <p> In [70, 68], techniques are also given for comparing the quality of semiotic morphisms, and a new version of categorical colimits, developed in collaboration with Grigore Ro~su, is used for combining meanings and for studying the effect of context on meaning; this includes "blends" in the sense of <ref> [26] </ref>. The potential to connect diverse areas on both sides of the great divide and to enter new application areas, such as user interface design, seems very exciting.
Reference: [27] <author> Kokichi Futatsugi, Joseph Goguen, Jean-Pierre Jouannaud, and Jose Meseguer. </author> <title> Principles of OBJ2. </title> <editor> In Brian Reid, editor, </editor> <booktitle> Proceedings, Twelfth ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 52-66. </pages> <institution> Association for Computing Machinery, </institution> <year> 1985. </year>
Reference-contexts: The final OBJ3 9 [114] version of OBJ was implemented by a team led by Jose Meseguer, including contributions by Kokichi Futatsugi, Jean-Pierre Jouannaud, Claude and Helene Kirchner, David Plaisted, Joseph Tardo, and others <ref> [104, 100, 27, 114] </ref>; this system provided both loose and initial semantics, rewriting modulo equations, generic modules, order sorted algebra with retracts, and user definable builtins 10 ; OBJ2 was heavily used in designing OBJ3 [125], and I think greatly speeded up this effort, by facilitating team communication and documenting interfaces. <p> However, it did take nine years (!) for the basic paper on institutions to be published in journal form [75]; this is the longest refereeing and editorial delay of which I ever heard. 7 2.6 Parameterized Programming and Generic Modules Parameterized programming <ref> [48, 52, 27, 28] </ref> makes the advantages of the Clear module system available for real programming languages, as well as for more practical specification languages.
Reference: [28] <author> Kokichi Futatsugi, Joseph Goguen, Jose Meseguer, and Koji Okada. </author> <title> Parameterized programming in OBJ2. </title> <editor> In Robert Balzer, editor, </editor> <booktitle> Proceedings, Ninth International Conference on Software Engineering, </booktitle> <pages> pages 51-60. </pages> <publisher> IEEE Computer Society, </publisher> <month> March </month> <year> 1987. </year>
Reference-contexts: However, it did take nine years (!) for the basic paper on institutions to be published in journal form [75]; this is the longest refereeing and editorial delay of which I ever heard. 7 2.6 Parameterized Programming and Generic Modules Parameterized programming <ref> [48, 52, 27, 28] </ref> makes the advantages of the Clear module system available for real programming languages, as well as for more practical specification languages.
Reference: [29] <author> Kokichi Futatsugi and Ataru Nakagawa. </author> <title> An overview of Cafe specification environment. </title> <booktitle> In Proceedings, </booktitle> <institution> ICFEM'97. University of Hiroshima, </institution> <year> 1997. </year>
Reference-contexts: Maude also has an efficient implementation and a number of interesting new features, including a logical and operational foundation in membership equational logic [149]. 3. The CafeOBJ project <ref> [29] </ref> aims to make algebraic formal methods accessible to practicing software engineers. The CafeOBJ language is similar to OBJ, but enriched with features for both rewriting logic (as in Maude) and hidden algebra (see Section 2.10), to help specify and verify distributed concurrent systems.
Reference: [30] <author> W. Wyat Gibbs. </author> <title> Software's chronic crisis. </title> <publisher> Scientific American, </publisher> <pages> pages 72-81, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: IBM software to deliver real time sports data to the media at the 1996 Olympic Games in Atlanta, the $2 billion loss of the European Ariane 5 satellite, and the failure of theUnited Airlines baggage delivery system at Denver International Airport, delaying its opening by one and a half years <ref> [30] </ref>. What these examples have in common is that they were hard to hide.
Reference: [31] <author> Joseph Goguen. </author> <title> L-fuzzy sets. </title> <journal> Journal of Mathematical Analysis and Applications, </journal> <volume> 18(1) </volume> <pages> 145-174, </pages> <year> 1967. </year>
Reference-contexts: This is what I did for fuzzy sets in my thesis [32, 34, 39]; earlier papers concerned other aspects of fuzzy sets, e.g., extending them to more general values than the unit interval <ref> [31, 33] </ref>. This was the first foundational work on fuzzy sets and fuzzy logic. Later I set up the Fuzzy Robot Users Group at UCLA, and did some early empirical work on fuzzy algorithms, though it was never properly published (but see [103] for an abstract).
Reference: [32] <author> Joseph Goguen. </author> <title> Categories of Fuzzy Sets. </title> <type> PhD thesis, </type> <institution> Department of Mathematics, University of California at Berkeley, </institution> <year> 1968. </year>
Reference-contexts: In the late 1960s, it was fashionable to give axioms on the category of things having some structure (with structure preserving morphisms) to characterize that category up to natural equivalence. This is what I did for fuzzy sets in my thesis <ref> [32, 34, 39] </ref>; earlier papers concerned other aspects of fuzzy sets, e.g., extending them to more general values than the unit interval [31, 33]. This was the first foundational work on fuzzy sets and fuzzy logic.
Reference: [33] <author> Joseph Goguen. </author> <title> The logic of inexact concepts. </title> <journal> Synthese, </journal> <volume> 19 </volume> <pages> 325-373, 1968-69. </pages>
Reference-contexts: Confidence values in the unit interval are associated with project tasks instead of Boolean truth values; this fuzzy logic (following <ref> [33] </ref>) allows critical path analysis to aid task allocation, taking account of different levels of formality and criticality. tatami is supported by a truth maintenance protocol that resolves inconsistencies while updating local databases, allowing multiple versions at multiple sites, including incomplete and even incorrect proofs. <p> This is what I did for fuzzy sets in my thesis [32, 34, 39]; earlier papers concerned other aspects of fuzzy sets, e.g., extending them to more general values than the unit interval <ref> [31, 33] </ref>. This was the first foundational work on fuzzy sets and fuzzy logic. Later I set up the Fuzzy Robot Users Group at UCLA, and did some early empirical work on fuzzy algorithms, though it was never properly published (but see [103] for an abstract).
Reference: [34] <author> Joseph Goguen. </author> <title> Categories of V-sets. </title> <journal> Bulletin of the American Mathematical Society, </journal> <volume> 75(3) </volume> <pages> 622-624, </pages> <year> 1969. </year>
Reference-contexts: In the late 1960s, it was fashionable to give axioms on the category of things having some structure (with structure preserving morphisms) to characterize that category up to natural equivalence. This is what I did for fuzzy sets in my thesis <ref> [32, 34, 39] </ref>; earlier papers concerned other aspects of fuzzy sets, e.g., extending them to more general values than the unit interval [31, 33]. This was the first foundational work on fuzzy sets and fuzzy logic.
Reference: [35] <author> Joseph Goguen. </author> <title> Mathematical representation of hierarchically organized systems. </title> <editor> In E. Attinger, editor, </editor> <booktitle> Global Systems Dynamics, </booktitle> <pages> pages 112-128. </pages> <editor> S. Karger, </editor> <year> 1971. </year>
Reference-contexts: Systems were taken to be diagrams in a category, behaviors were given by their limits, and interconnections were given by colimits of diagrams; some very general laws about interconnection and behavior hold in this setting <ref> [35, 37, 78] </ref>.
Reference: [36] <author> Joseph Goguen. </author> <title> Minimal realization of machines in closed categories. </title> <journal> Bulletin of the American Mathematical Society, </journal> <volume> 78(5) </volume> <pages> 777-783, </pages> <year> 1972. </year>
Reference-contexts: In the early 1970s, I formulated the minimal realization of automata as an adjoint functor [38]; this soon evolved into much more general results about the minimal realization of machines in categories, which gave a neat unification of system theory (in the sense of electrical engineering) with automaton theory <ref> [36] </ref>. I consider this a major vindication of the categorical approach to systems. 2.3 Abstract Data Types and Algebraic Semantics The history of programming languages, and to a large extent of software engineering as a whole, can be seen as a succession of ever more powerful abstraction mechanisms.
Reference: [37] <author> Joseph Goguen. </author> <title> Categorical foundations for general systems theory. </title> <editor> In F. Pichler and R. Trappl, editors, </editor> <booktitle> Advances in Cybernetics and Systems Research, </booktitle> <pages> pages 121-130. </pages> <publisher> Transcripta Books, </publisher> <year> 1973. </year>
Reference-contexts: Systems were taken to be diagrams in a category, behaviors were given by their limits, and interconnections were given by colimits of diagrams; some very general laws about interconnection and behavior hold in this setting <ref> [35, 37, 78] </ref>.
Reference: [38] <author> Joseph Goguen. </author> <title> Realization is universal. </title> <journal> Mathematical System Theory, </journal> <volume> 6 </volume> <pages> 359-374, </pages> <year> 1973. </year>
Reference-contexts: There is now a slow but steady stream of research on sheaf theory in computer science, though there is not as yet a coherent community. In the early 1970s, I formulated the minimal realization of automata as an adjoint functor <ref> [38] </ref>; this soon evolved into much more general results about the minimal realization of machines in categories, which gave a neat unification of system theory (in the sense of electrical engineering) with automaton theory [36]. <p> In 9 1982, Meseguer and I developed a theory of abstract machines [92] for this purpose, and proved minimal (final) and initial realization theorems for them; this theory naturally generalizes algebraic ADTs as well as classical automata. The minimal realization adjunction for automata <ref> [38] </ref> helped inspire this work, and it was also pleasant to realize that many intuitions from John Guttag's early work could be vindicated [116, 117].
Reference: [39] <author> Joseph Goguen. </author> <title> Concept representation in natural and artificial languages: Axioms, extensions and applications for fuzzy sets. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 6 </volume> <pages> 513-561, </pages> <year> 1974. </year>
Reference-contexts: In the late 1960s, it was fashionable to give axioms on the category of things having some structure (with structure preserving morphisms) to characterize that category up to natural equivalence. This is what I did for fuzzy sets in my thesis <ref> [32, 34, 39] </ref>; earlier papers concerned other aspects of fuzzy sets, e.g., extending them to more general values than the unit interval [31, 33]. This was the first foundational work on fuzzy sets and fuzzy logic.
Reference: [40] <author> Joseph Goguen. </author> <title> Objects. </title> <journal> International Journal of General Systems, </journal> <volume> 1(4) </volume> <pages> 237-243, </pages> <year> 1975. </year>
Reference-contexts: Still, this categorical GST has had a significant indirect impact on computer science: its application to the Clear and OBJ module systems influenced some important programming languages, including Ada, ML and C++ (see Section 2.6). A general theory of objects based on sheaf theory <ref> [40] </ref> arose from this work, and has been applied (for example) to the semantics of concurrent systems, including concurrent object based languages [62], hardware description languages [166], and semantics for object based concurrent information systems [23].
Reference: [41] <author> Joseph Goguen. </author> <title> Semantics of computation. </title> <editor> In Ernest Manes, editor, </editor> <booktitle> Proceedings, First International Symposium on Category Theory Applied to Computation and Control, </booktitle> <pages> pages 151-163. </pages> <publisher> Springer, </publisher> <address> 1975. (San Fransisco, </address> <month> February </month> <year> 1974.) </year> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> Volume 25. </volume> <pages> 19 </pages>
Reference-contexts: Initial algebra semantics provided the first rigorous formulation of these problems, with solutions that were useful, although they have been improved (see Section 2.10). Initial algebra semantics was born in <ref> [41] </ref>, which (among other things) formulated (Knuthian) attribute semantics as a homomorphism from an initial many sorted syntactic algebra generated by a context free grammar, to a semantic algebra 5 .
Reference: [42] <author> Joseph Goguen. </author> <title> Abstract errors for abstract data types. </title> <editor> In Eric Neuhold, editor, </editor> <booktitle> Proceedings, First IFIP Working Conference on Formal Description of Programming Concepts, pages 21.1-21.32. </booktitle> <publisher> MIT, </publisher> <year> 1977. </year> <title> Also in Formal Description of Programming Concepts, </title> <editor> Peter Neuhold, Ed., </editor> <publisher> North-Holland, </publisher> <pages> pages 491-522, </pages> <year> 1979. </year>
Reference-contexts: Around 1974, I conceived the OBJ language for this purpose, using order sorted algebra 8 with mixfix syntax, and with term rewriting as operational semantics <ref> [42] </ref>; the goal was to make specifications as readable and testable as possible. <p> These include the raising and handling of exceptions, overloaded operators, subtypes, inheritance, coercions, and multiple representations. Error algebra <ref> [42] </ref> was a first crack at some of these problems, although it didn't work out. The second try was order sorted algebra (hereafter, OSA) [44], which reached fruition in joint work with Meseguer [99, 151]. <p> Sorry for the confusing prose in this quote.) The relevance of this to software engineering is discussed in <ref> [42] </ref>: Anyone familiar with large software projects knows that there is a sense in which they "have a life of their own," in that some projects seem healthy and vibrant from the start, and overcome even unexpected obstacles with enthusiasm and intelligence, while others always seem disorganized and depressed, suffering from
Reference: [43] <author> Joseph Goguen. </author> <title> Complexity of hierarchically organized systems and the structure of musical experiences. </title> <journal> International Journal of General Systems, </journal> <volume> 3(4) </volume> <pages> 237-251, </pages> <year> 1977. </year>
Reference-contexts: This motivated using categorical GST for a complexity based information theory, which was then applied to music <ref> [43] </ref>; here the information content of a behavior is the minimum value of the sum of weights of (hierarchical) interconnected components whose behavior is the given one.
Reference: [44] <author> Joseph Goguen. </author> <title> Order sorted algebra. </title> <type> Technical Report 14, </type> <institution> UCLA Computer Science Department, </institution> <year> 1978. </year> <title> Semantics and Theory of Computation Series. </title>
Reference-contexts: These include the raising and handling of exceptions, overloaded operators, subtypes, inheritance, coercions, and multiple representations. Error algebra [42] was a first crack at some of these problems, although it didn't work out. The second try was order sorted algebra (hereafter, OSA) <ref> [44] </ref>, which reached fruition in joint work with Meseguer [99, 151]. This approach provides a partial ordering relation on sorts, interpreted semantically as subset inclusion among model carriers.
Reference: [45] <author> Joseph Goguen. </author> <title> Fuzzy sets and the social nature of truth. </title> <editor> In M.M. Gupta and Ronald Yager, editors, </editor> <booktitle> Advances in Fuzzy Set Theory and Applications, </booktitle> <pages> pages 49-68. </pages> <publisher> North-Holland, </publisher> <year> 1979. </year>
Reference-contexts: Some applications to philosophy and the social sciences, and some limitations of fuzzy set theory were discussed in <ref> [45] </ref>. Today fuzzy sets and fuzzy logic are very popular areas. <p> Several Oxford students did experiments in this area for their MSc theses, but again it became clear that no purely formal approach, however abstract and general, could deal with human meaning in any deep sense [63] (see also <ref> [45] </ref>). Recently I returned to this area, but from the opposite side of the great divide, defining information in social terms [69]: An item of information is an interpretation of a configuration of signs for which members of some social group are accountable.
Reference: [46] <author> Joseph Goguen. </author> <title> Some ideas in algebraic semantics. In Ken Hirose, editor, </title> <booktitle> Mathematical Logic and Computer Science. IBM Japan, 1979. Proceedings, Third IBM Symposium on Mathematical Foundations of Computer Science. </booktitle>
Reference-contexts: The reason that the computability notion associated with Scott-style denotational semantics doesn't work for algebras is explained in <ref> [46] </ref>. This field was pioneered in a series of papers by Jan Bergstra and John Tucker, surveyed in [150], which also explains basic many sorted algebra and abstract machines. Some conjectures from [150] were solved with Meseguer and Moss in [153].
Reference: [47] <author> Joseph Goguen. </author> <title> How to prove algebraic inductive hypotheses without induction, with applications to the correctness of data type representations. </title> <editor> In Wolfgang Bibel and Robert Kowalski, editors, </editor> <booktitle> Proceedings, Fifth Conference on Automated Deduction, </booktitle> <pages> pages 356-373. </pages> <publisher> Springer, </publisher> <year> 1980. </year> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> Volume 87. </volume>
Reference-contexts: splendid that computability properties worked out so well: an algebraic version of the Turing-Church thesis says that an algebra is computable iff it is a reduct of a finitely presented initial algebra with an equationally definable equality; these are also the algebras for which so-called "inductionless induction" proofs are valid <ref> [47] </ref>. Moreover, an algebra is: semicomputable iff it is a reduct of a finitely presented initial algebra; cosemicomputable iff it is a reduct of a finitely presented final algebra; and computable iff a reduct of a finitely presented algebra that is both initial and final. <p> Complete rules of deduction for many sorted conditional equational logic are given in [92]. The first rigorous proof of correctness for the inductionless induction proof technique that was originally suggested by David Musser, is given in <ref> [47] </ref>. The formulation of inductionless induction in [47] is more general than in some later work, which was restricted to just constructors; [47] also pointed out that the essence of inductionless induction is "proof by consistency," and gave the simple but fundamental result that for an equational specification that is canonical <p> Complete rules of deduction for many sorted conditional equational logic are given in [92]. The first rigorous proof of correctness for the inductionless induction proof technique that was originally suggested by David Musser, is given in <ref> [47] </ref>. The formulation of inductionless induction in [47] is more general than in some later work, which was restricted to just constructors; [47] also pointed out that the essence of inductionless induction is "proof by consistency," and gave the simple but fundamental result that for an equational specification that is canonical (i.e., terminating and Church-Rosser) as a set <p> The first rigorous proof of correctness for the inductionless induction proof technique that was originally suggested by David Musser, is given in <ref> [47] </ref>. The formulation of inductionless induction in [47] is more general than in some later work, which was restricted to just constructors; [47] also pointed out that the essence of inductionless induction is "proof by consistency," and gave the simple but fundamental result that for an equational specification that is canonical (i.e., terminating and Church-Rosser) as a set of rewrite rules, the normal forms of ground terms form an initial algebra.
Reference: [48] <author> Joseph Goguen. </author> <title> Parameterized programming. </title> <journal> Transactions on Software Engineering, </journal> <volume> SE-10(5):528-543, </volume> <month> Sep-tember </month> <year> 1984. </year>
Reference-contexts: However, it did take nine years (!) for the basic paper on institutions to be published in journal form [75]; this is the longest refereeing and editorial delay of which I ever heard. 7 2.6 Parameterized Programming and Generic Modules Parameterized programming <ref> [48, 52, 27, 28] </ref> makes the advantages of the Clear module system available for real programming languages, as well as for more practical specification languages.
Reference: [49] <author> Joseph Goguen. </author> <title> One, none, a hundred thousand specification languages. </title> <editor> In H.-J. Kugler, editor, </editor> <booktitle> Information Processing '86, </booktitle> <pages> pages 995-1003. </pages> <publisher> Elsevier, </publisher> <year> 1986. </year> <booktitle> Proceedings of 1986 IFIP Congress. </booktitle>
Reference-contexts: Each can be considered a kind of logical programming <ref> [49] </ref>, where a logical programming language is characterized as follows: * its statements are sentences in some logic; * its computation is deduction in that logic; and * its denotational semantics is given by models in the logic. <p> For example, higher order functional programming is (or can be) based on higher order equational logic, and OBJ is based on order sorted first-order conditional equational logic. Similarly, logic programming is based on Horn clause logic. This approach can be made precise using institutions <ref> [96, 74, 49] </ref>, and it has been enriched and extended by Meseguer with his theory of "general logics" [146]. <p> This idea also features in the elegant semantics for so called constraint based programming developed by Diaconescu [15, 16]. However initiality is not the right semantics for every logical language. Programming paradigms can be combined by viewing them as logical programming languages and then combining their logics <ref> [49, 74, 96] </ref>.
Reference: [50] <author> Joseph Goguen. </author> <title> Reusing and interconnecting software components. </title> <journal> Computer, </journal> <volume> 19(2) </volume> <pages> 16-28, </pages> <month> February </month> <year> 1986. </year> <note> Reprinted in Tutorial: Software Reusability, </note> <editor> Peter Freeman, editor, </editor> <publisher> IEEE Computer Society, </publisher> <year> 1987, </year> <pages> pages 251-263, </pages> <booktitle> and in Domain Analysis and Software Systems Modelling, </booktitle> <editor> Ruben Prieto-Daz and Guillermo Arango, editors, </editor> <publisher> IEEE Computer Society, </publisher> <year> 1991, </year> <pages> pages 125-137. </pages>
Reference-contexts: These ideas were first implemented in OBJ3. Although I'm happy that some of this influenced the languages Ada, ML, and C++, it can still be distressing to see the compromises involved. LIL <ref> [50] </ref> extends parameterized programming to handle programs and specs together, by giving each module a specification "header" as well as implementations.
Reference: [51] <author> Joseph Goguen. </author> <title> Memories of ADJ. </title> <journal> Bulletin of the European Association for Theoretical Computer Science, </journal> <volume> 36 </volume> <pages> 96-102, </pages> <month> October </month> <year> 1989. </year> <title> Guest column in the `Algebraic Specification Column.' </title> <booktitle> Also in Current Trends in Theoretical Computer Science: Essays and Tutorials, World Scientific, </booktitle> <year> 1993, </year> <pages> pages 76-81. </pages>
Reference-contexts: most complete exposition is in [62], which has full proofs of all results. 3 The ADJ group, fGoguen, Thatcher, Wagner, Wrightg, was formed during my tenure as Research Fellow in the Mathematical Sciences at IBM Research, Yorktown Heights, initially to study the relationship between category theory and computer science; see <ref> [51] </ref> for many historical details; for some reason, I wrote all of the initial reports, but in compensation, had very little role in some of the final reports. 3 One especially nice feature of this approach is that it does not build in any notion of causality, and therefore can capture <p> As a young researcher at this time, I was really shocked by the attempts of certain senior colleagues to reconfigure the history of this period to their own advantage; this is why I wrote the paper <ref> [51] </ref>.
Reference: [52] <author> Joseph Goguen. </author> <title> Principles of parameterized programming. </title> <editor> In Ted Biggerstaff and Alan Perlis, editors, </editor> <booktitle> Software Reusability, Volume I: Concepts and Models, </booktitle> <pages> pages 159-225. </pages> <publisher> Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: However, it did take nine years (!) for the basic paper on institutions to be published in journal form [75]; this is the longest refereeing and editorial delay of which I ever heard. 7 2.6 Parameterized Programming and Generic Modules Parameterized programming <ref> [48, 52, 27, 28] </ref> makes the advantages of the Clear module system available for real programming languages, as well as for more practical specification languages.
Reference: [53] <author> Joseph Goguen. </author> <title> What is unification? A categorical view of substitution, equation and solution. </title> <editor> In Maurice Nivat and Hassan At-Kaci, editors, </editor> <title> Resolution of Equations in Algebraic Structures, </title> <booktitle> Volume 1: Algebraic Techniques, </booktitle> <pages> pages 217-261. </pages> <publisher> Academic, </publisher> <year> 1989. </year>
Reference-contexts: Later I wrote "A Categorical Manifesto" [56] to provide for each basic concept of category theory a "doctrine" of how to use it in practice, and still later, <ref> [53] </ref> developed category theory from scratch while proposing a general theory of unification.
Reference: [54] <author> Joseph Goguen. </author> <title> An algebraic approach to refinement. In Dines Bjorner, C.A.R. Hoare, </title> <editor> and Hans Langmaack, editors, </editor> <booktitle> Proceedings, VDM'90: VDM and Z Formal Methods in Software Development, </booktitle> <pages> pages 12-28. </pages> <publisher> Springer, </publisher> <year> 1990. </year> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> Volume 428. </volume>
Reference-contexts: In collaboration with Razvan Diaconescu, Rod Burstall, and most recently especially Grant Malcolm, this work has developed into a new hidden algebra approach <ref> [54, 58, 77, 7, 87, 140, 89] </ref>, intended to facilitate proving properties of designs, as opposed to code, and in particular, to facilitate refinement proofs, that one level of design is correctly realized by another.
Reference: [55] <author> Joseph Goguen. Hyperprogramming: </author> <title> A formal approach to software environments. </title> <booktitle> In Proceedings, Symposium on Formal Approaches to Software Environment Technology. Joint System Development Corporation, </booktitle> <address> Tokyo, Japan, </address> <month> January </month> <year> 1990. </year>
Reference-contexts: A formal semantics is given for all this in [111], using a concrete set theoretic exposition of institutions; some general "laws of software engineering" are given showing how various module operations relate. Hyperprogramming <ref> [55] </ref> extends the idea of organizing information around a specification header to support requirements as well as specs and code, with traceability, controlled evolution, and management of configurations, versions, families, documentation, etc., as well as system generation and software reuse.
Reference: [56] <author> Joseph Goguen. </author> <title> A categorical manifesto. </title> <booktitle> Mathematical Structures in Computer Science, </booktitle> <volume> 1(1) </volume> <pages> 49-67, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: Our original goal was to write one or more comprehensive books, something like what Bourbaki did for mathematics, but ADJ fell apart before we got any further than these reports. Later I wrote "A Categorical Manifesto" <ref> [56] </ref> to provide for each basic concept of category theory a "doctrine" of how to use it in practice, and still later, [53] developed category theory from scratch while proposing a general theory of unification.
Reference: [57] <author> Joseph Goguen. </author> <title> Semantic specifications for the Rewrite Rule Machine. </title> <editor> In Aki Yonezawa and Takayasu Ito, editors, </editor> <booktitle> Concurrency: Theory, Language and Architecture, </booktitle> <pages> pages 216-234, </pages> <year> 1991. </year> <booktitle> Proceedings of a U.K.-Japan Workshop; Springer, Lecture Notes in Computer Science, </booktitle> <volume> Volume 491. </volume>
Reference-contexts: All implementations of these systems were built on top of OBJ3. This research direction went so far as designing and prototyping special purpose hardware, the Rewrite Rule Machine, for executing declarative languages efficiently, based on term rewriting chips <ref> [98, 133, 57] </ref>. Despite all the interest once shown in declarative programming, the Fifth Generation, etc., there seems to be little interest in precise explications for declarative and logical programming and reflection, or in general purpose declarative architectures.
Reference: [58] <author> Joseph Goguen. </author> <title> Types as theories. </title> <editor> In George Michael Reed, Andrew William Roscoe, and Ralph F. Wachter, editors, </editor> <booktitle> Topology and Category Theory in Computer Science, </booktitle> <pages> pages 357-390. </pages> <address> Oxford, </address> <year> 1991. </year> <booktitle> Proceedings of a Conference held at Oxford, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: In collaboration with Razvan Diaconescu, Rod Burstall, and most recently especially Grant Malcolm, this work has developed into a new hidden algebra approach <ref> [54, 58, 77, 7, 87, 140, 89] </ref>, intended to facilitate proving properties of designs, as opposed to code, and in particular, to facilitate refinement proofs, that one level of design is correctly realized by another.
Reference: [59] <author> Joseph Goguen. </author> <title> The denial of error. </title> <editor> In Christiane Floyd, Heinz Zullighoven, Reinhard Budde, and Reinhard Keil-Slawik, editors, </editor> <booktitle> Software Development and Reality Construction, </booktitle> <pages> pages 193-202. </pages> <publisher> Springer Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Autopoietic systems are about as far as we know how to get from rigid top-down hierarchical goal-driven control systems; autopoietic systems thrive on error, and reconstruct themselves on the basis of what they learn from their mistakes. Autopoiesis can be considered an implementation technique for postmodernism. See <ref> [59] </ref> for more on attitudes towards errors in computer science. 4.4 Ethics One aspect of the great divide that seems especially troubling in the late twentieth century is the separation of technology and science from ethics.
Reference: [60] <author> Joseph Goguen. </author> <title> The dry and the wet. </title> <editor> In Eckhard Falkenberg, Colette Rolland, and El-Sayed Nasr-El-Dein El-Sayed, editors, </editor> <booktitle> Information Systems Concepts, </booktitle> <pages> pages 1-17. </pages> <publisher> Elsevier North-Holland, </publisher> <year> 1992. </year> <booktitle> Proceedings, IFIP Working Group 8.1 Conference (Alexandria, Egypt). </booktitle> <pages> 20 </pages>
Reference-contexts: This was applied in [81] as part of a study to determine requirements for a system to computerize a small headhunting firm, by collecting stories and jokes told during breaks and at lunch, and then collating them into a "value system tree" for the firm, as described in <ref> [60, 86] </ref>; this work also showed how to extract dataflow diagrams from task oriented discourse. For some reason, linguistics seems stuck on the syntax of sentences, despite the fact that there are important applications at higher levels.
Reference: [61] <author> Joseph Goguen. </author> <title> Hermeneutics and path. </title> <editor> In Christiane Floyd, Heinz Zullighoven, Reinhard Budde, and Reinhard Keil-Slawik, editors, </editor> <booktitle> Software Development and Reality Construction, </booktitle> <pages> pages 39-44. </pages> <publisher> Springer Verlag, </publisher> <year> 1992. </year>
Reference-contexts: A more radical view appears in [119], where Heidegger considers Western civilization to be fundamentally entangled with a separation of technology from ethics, based on an untenable instrumental conception of technology; see also the discussions in <ref> [61] </ref> and [63]. Heidegger [119] further claims that by questioning deeply enough into the essence of technology, perhaps in desperation, we may find what we need to go beyond the current impasse.
Reference: [62] <author> Joseph Goguen. </author> <title> Sheaf semantics for concurrent interacting objects. </title> <booktitle> Mathematical Structures in Computer Science, </booktitle> <volume> 11 </volume> <pages> 159-191, </pages> <year> 1992. </year>
Reference-contexts: Systems were taken to be diagrams in a category, behaviors were given by their limits, and interconnections were given by colimits of diagrams; some very general laws about interconnection and behavior hold in this setting [35, 37, 78]. The most complete exposition is in <ref> [62] </ref>, which has full proofs of all results. 3 The ADJ group, fGoguen, Thatcher, Wagner, Wrightg, was formed during my tenure as Research Fellow in the Mathematical Sciences at IBM Research, Yorktown Heights, initially to study the relationship between category theory and computer science; see [51] for many historical details; for <p> A general theory of objects based on sheaf theory [40] arose from this work, and has been applied (for example) to the semantics of concurrent systems, including concurrent object based languages <ref> [62] </ref>, hardware description languages [166], and semantics for object based concurrent information systems [23]. Sheaves can express the kind of local causality combined with global non-determinism that characterizes many different kinds of model, from partial differential equations to automata. <p> Sheaves can express the kind of local causality combined with global non-determinism that characterizes many different kinds of model, from partial differential equations to automata. They can capture not only variation over time, but also over space and over space-time <ref> [62] </ref>; and they can embrace the incompleteness of observation that is characteristic of all real empirical work. This can be helpful at the philosophical level in dispelling the illusion that models fully capture reality (see the discussion in Section 4.1).
Reference: [63] <author> Joseph Goguen. </author> <title> Truth and meaning beyond formalism. </title> <editor> In Christiane Floyd, Heinz Zullighoven, Reinhard Budde, and Reinhard Keil-Slawik, editors, </editor> <booktitle> Software Development and Reality Construction, </booktitle> <pages> pages 353-362. </pages> <publisher> Springer Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Several Oxford students did experiments in this area for their MSc theses, but again it became clear that no purely formal approach, however abstract and general, could deal with human meaning in any deep sense <ref> [63] </ref> (see also [45]). Recently I returned to this area, but from the opposite side of the great divide, defining information in social terms [69]: An item of information is an interpretation of a configuration of signs for which members of some social group are accountable. <p> My preference is for phenomenology, which starts with experience, disallowing any external distinctions; it then proceeds with a careful analysis of experience and its ground; however, this paper isn't the place to consider such issues; some further discussion and references may be found in <ref> [63] </ref>. 4.2 Modernism Modernism can be defined as belief in the adequacy of hierarchy, formalization and control to achieve desired ends without error. <p> A more radical view appears in [119], where Heidegger considers Western civilization to be fundamentally entangled with a separation of technology from ethics, based on an untenable instrumental conception of technology; see also the discussions in [61] and <ref> [63] </ref>. Heidegger [119] further claims that by questioning deeply enough into the essence of technology, perhaps in desperation, we may find what we need to go beyond the current impasse.
Reference: [64] <author> Joseph Goguen. </author> <title> Social issues in requirements engineering. </title> <editor> In Stephen Fickas and Anthony Finkelstein, editors, </editor> <booktitle> Requirements Engineering '93, </booktitle> <pages> pages 194-195. </pages> <publisher> IEEE, </publisher> <year> 1993. </year>
Reference-contexts: The second project was in part inspired by work of Lyotard [138] on post-modernism. Other work from the Centre included a book [124] consisting of (revised) papers from a workshop organized by the Centre, some more papers <ref> [64, 123] </ref>, and the toor object oriented tool for tracing requirements [160].
Reference: [65] <author> Joseph Goguen. </author> <title> Requirements engineering as the reconciliation of social and technical issues. </title> <editor> In Marina Jirotka and Joseph Goguen, editors, </editor> <booktitle> Requirements Engineering: Social and Technical Issues, </booktitle> <pages> pages 165-200. </pages> <publisher> Academic, </publisher> <year> 1994. </year>
Reference-contexts: The view that the essence of requirements engineering is to reconcile social and technical aspects of system design was proposed in <ref> [65] </ref> and elaborated in later work [66, 69]; it amounts to saying that requirements engineering consists of building bridges across the divide.
Reference: [66] <author> Joseph Goguen. </author> <title> Formality and informality in requirements engineering. </title> <booktitle> In Proceedings, International Conference on Requirements Engineering, </booktitle> <pages> pages 102-108. </pages> <publisher> IEEE Computer Society, </publisher> <month> April </month> <year> 1996. </year>
Reference-contexts: The view that the essence of requirements engineering is to reconcile social and technical aspects of system design was proposed in [65] and elaborated in later work <ref> [66, 69] </ref>; it amounts to saying that requirements engineering consists of building bridges across the divide.
Reference: [67] <author> Joseph Goguen. </author> <title> Parameterized programming and software architecture. </title> <booktitle> In Proceedings, Reuse'96, </booktitle> <pages> pages 2-11. </pages> <publisher> IEEE Computer Society, </publisher> <month> April </month> <year> 1996. </year>
Reference-contexts: All this is of course intended to ease the development of large systems, and in particular, to make reuse more effective in practice. An approach to software architecture based on these ideas is given in <ref> [67] </ref>, where module expressions provide a module connection (also called an architecture description) language. Any mixture of architectural styles can be supported, and modules can involve information hiding.
Reference: [68] <author> Joseph Goguen. </author> <title> Semiotic morphisms. </title> <type> Technical Report CS97-553, UCSD, </type> <institution> Dept. Computer Science & Eng., </institution> <year> 1997. </year> <note> Early version in Proc., Conf. Intelligent Systems: A Semiotic Perspective, Vol. </note> <editor> II, ed. J. Albus, A. Meystel and R. </editor> <address> Quintero, </address> <institution> Nat. Inst. Science & Technology (Gaithersberg MD, </institution> <month> 20-23 October </month> <year> 1996), </year> <pages> pages 26-31. </pages>
Reference-contexts: Unfortunately there seem to be at least as many approaches to semiotics as there are authors who have considered it, and many other fields with different names also cover the same or closely related ground, e.g., cognitive linguistics [127, 26, 170]. Algebraic semiotics <ref> [70, 68] </ref> is one more: it tries to combine insights from both sides of the divide, to obtain a precise formulation of certain problems about meaning and to allow the construction of supporting technology. <p> In <ref> [70, 68] </ref>, techniques are also given for comparing the quality of semiotic morphisms, and a new version of categorical colimits, developed in collaboration with Grigore Ro~su, is used for combining meanings and for studying the effect of context on meaning; this includes "blends" in the sense of [26]. <p> The potential to connect diverse areas on both sides of the great divide and to enter new application areas, such as user interface design, seems very exciting. When applied to user interface design, algebraic semiotics can model the content and structure of information through its representation <ref> [68, 80, 101, 102] </ref>; it is now being used to design interfaces for the tatami system (see Section 2.11). <p> Both kinds of research straddle the great divide, and both are risky. It is much safer to stay within the confines of a single discipline, and if possible work on a single well defined problem of recognized practical importance. Few people want to read a paper like <ref> [68] </ref> in a serious way, because it requires familiarity with diverse areas of philosophy, mathematics, linguistics, literature and computer science; so the author isn't likely to get much recognition, and it will be hard to publish. But the safe way can also be a painful way.
Reference: [69] <author> Joseph Goguen. </author> <title> Towards a social, ethical theory of information. </title> <editor> In Geoffrey Bowker, Leigh Star, William Turner, and Les Gasser, editors, </editor> <booktitle> Social Science, Technical Systems and Cooperative Work: Beyond the Great Divide, </booktitle> <pages> pages 27-56. </pages> <publisher> Erlbaum, </publisher> <year> 1997. </year>
Reference-contexts: Two other discourse types are stories [126] and jokes [162], which are interesting because they embed values of the speaker and audience, and can therefore be used to study those values <ref> [69, 86] </ref>. <p> The view that the essence of requirements engineering is to reconcile social and technical aspects of system design was proposed in [65] and elaborated in later work <ref> [66, 69] </ref>; it amounts to saying that requirements engineering consists of building bridges across the divide. <p> Recently I returned to this area, but from the opposite side of the great divide, defining information in social terms <ref> [69] </ref>: An item of information is an interpretation of a configuration of signs for which members of some social group are accountable. The goal is to get a theory of information adequate for understanding and designing systems that process information. <p> The goal is to get a theory of information adequate for understanding and designing systems that process information. This research draws on ideas from ethnomethodology [163], semiotics, logic, and the sociology of science. The paper <ref> [69] </ref> also presents some case studies and makes the perhaps surprising argument that because of its social situatedness, information has an intrinsic ethical dimension. 4 Philosophy of Computing It is usually thought that philosophy has little to do with the practical engineering concerns that dominate computer science today. <p> Of course, there is a huge philosophical literature on ethics, but little of it directly addresses technology. My own concern is to bridge the gap between technology and ethics on intellectual grounds. In <ref> [69] </ref>, I argue for an inherent ethical dimension to information (but not mere data), through its being embedded in a context of concern by some social group (see the definition of information in Section 3.4). <p> This is not an appropriate place for details, but we should recall that understanding values can be crucial for getting requirements that match user needs. Other perspectives on the "great divide" can be found in the book [6] in which the paper <ref> [69] </ref> appears. A more radical view appears in [119], where Heidegger considers Western civilization to be fundamentally entangled with a separation of technology from ethics, based on an untenable instrumental conception of technology; see also the discussions in [61] and [63].
Reference: [70] <author> Joseph Goguen. </author> <title> An introduction to algebraic semiotics, with applications to user interface design. </title> <editor> In Chrystopher Nehaniv, editor, </editor> <title> Proceedings, Computation for Metaphors, Analogy and Agents. </title> <institution> University of Aizu, 1998. Aizu-Wakamatsu, </institution> <address> Japan, </address> <month> 6-10 April </month> <year> 1998. </year>
Reference-contexts: Unfortunately there seem to be at least as many approaches to semiotics as there are authors who have considered it, and many other fields with different names also cover the same or closely related ground, e.g., cognitive linguistics [127, 26, 170]. Algebraic semiotics <ref> [70, 68] </ref> is one more: it tries to combine insights from both sides of the divide, to obtain a precise formulation of certain problems about meaning and to allow the construction of supporting technology. <p> In <ref> [70, 68] </ref>, techniques are also given for comparing the quality of semiotic morphisms, and a new version of categorical colimits, developed in collaboration with Grigore Ro~su, is used for combining meanings and for studying the effect of context on meaning; this includes "blends" in the sense of [26].
Reference: [71] <author> Joseph Goguen. </author> <title> Theorem Proving and Algebra. MIT, </title> <note> to appear. </note>
Reference-contexts: For me, the frontier of research in this area is the use of systems like OBJ3 for theorem proving, e.g., in first order logic with equalities as atoms <ref> [71] </ref>, or for verifying distributed concurrent systems (see [89] and see Section 2.10).
Reference: [72] <author> Joseph Goguen and Rod Burstall. </author> <title> CAT, a system for the structured elaboration of correct programs from structured specifications. </title> <type> Technical Report Report CSL-118, </type> <institution> SRI Computer Science Lab, </institution> <month> October </month> <year> 1980. </year>
Reference-contexts: LIL [50] extends parameterized programming to handle programs and specs together, by giving each module a specification "header" as well as implementations. LIL provides "two dimensional" module composition following the "CAT" ideas <ref> [72] </ref>, where vertical structure refers to the layering of software to use capabilities from lower layers, while horizontal structure refers to a single layer.
Reference: [73] <author> Joseph Goguen and Rod Burstall. </author> <title> Introducing institutions. </title> <editor> In Edmund Clarke and Dexter Kozen, editors, </editor> <booktitle> Proceedings, Logics of Programming Workshop, </booktitle> <pages> pages 221-256. </pages> <publisher> Springer, </publisher> <year> 1984. </year> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> Volume 164. </volume>
Reference-contexts: the mice! 2.5 Institutions Because Clear is based on colimits of theories, Burstall and I were able to give it a very general semantics independent of the underlying logic in which theories are expressed, provided that logic has certain simple and very usual properties, which constitute the notion of institution <ref> [73, 75] </ref>. The basic feature of institutions is a duality between models and the (logical) sentences used in specifications arising through a relation of satisfaction that is parameterized by the signature involved.
Reference: [74] <author> Joseph Goguen and Rod Burstall. </author> <title> A study in the foundations of programming methodology: Specifications, </title> <editor> institutions, charters and parchments. In David Pitt, Samson Abramsky, Axel Poigne, and David Rydeheard, editors, </editor> <booktitle> Proceedings, Conference on Category Theory and Computer Programming, </booktitle> <pages> pages 313-333. </pages> <publisher> Springer, </publisher> <year> 1986. </year> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> Volume 240. </volume>
Reference-contexts: So institutions give a way to deal with issues in programming and specification languages (as well as databases and other kinds of system) independently of their underlying logic; I really love this kind of generality. The theory of institutions was developed further in <ref> [74] </ref>, showing how to generate institutions from the simpler structures of charters and parchments, how to put institutions together, and how to greatly generalize them; in particular, morphisms of sentences are introduced to support proof theory. <p> For example, higher order functional programming is (or can be) based on higher order equational logic, and OBJ is based on order sorted first-order conditional equational logic. Similarly, logic programming is based on Horn clause logic. This approach can be made precise using institutions <ref> [96, 74, 49] </ref>, and it has been enriched and extended by Meseguer with his theory of "general logics" [146]. <p> This idea also features in the elegant semantics for so called constraint based programming developed by Diaconescu [15, 16]. However initiality is not the right semantics for every logical language. Programming paradigms can be combined by viewing them as logical programming languages and then combining their logics <ref> [49, 74, 96] </ref>.
Reference: [75] <author> Joseph Goguen and Rod Burstall. Institutions: </author> <title> Abstract model theory for specification and programming. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 39(1) </volume> <pages> 95-146, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: the mice! 2.5 Institutions Because Clear is based on colimits of theories, Burstall and I were able to give it a very general semantics independent of the underlying logic in which theories are expressed, provided that logic has certain simple and very usual properties, which constitute the notion of institution <ref> [73, 75] </ref>. The basic feature of institutions is a duality between models and the (logical) sentences used in specifications arising through a relation of satisfaction that is parameterized by the signature involved. <p> There is now a rather large literature on institutions, with applications to many different areas, e.g., [17] concerns multi-institutional specification. However, it did take nine years (!) for the basic paper on institutions to be published in journal form <ref> [75] </ref>; this is the longest refereeing and editorial delay of which I ever heard. 7 2.6 Parameterized Programming and Generic Modules Parameterized programming [48, 52, 27, 28] makes the advantages of the Clear module system available for real programming languages, as well as for more practical specification languages.
Reference: [76] <author> Joseph Goguen and Lee Carlson. </author> <title> Axioms for discrimination information. </title> <journal> IEEE Transactions on Information Theory, </journal> <pages> pages 572-574, </pages> <month> September </month> <year> 1975. </year>
Reference-contexts: In the late 1960s, I taught a course at the University of Chicago on traditional Shannon-style information theory <ref> [76] </ref>, and encountered great difficulty trying to extend it to human situations; in fact this theory does not apply to meaning, but rather to data compression and transmission after all, it was developed for the (then) Bell Telephone Company because it ignores the crucial human aspects that underlie meaning.
Reference: [77] <author> Joseph Goguen and Razvan Diaconescu. </author> <title> Towards an algebraic semantics for the object paradigm. </title> <editor> In Hartmut Ehrig and Fernando Orejas, editors, </editor> <booktitle> Proceedings, Tenth Workshop on Abstract Data Types, </booktitle> <pages> pages 1-29. </pages> <publisher> Springer, </publisher> <year> 1994. </year> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> Volume 785. </volume>
Reference-contexts: In collaboration with Razvan Diaconescu, Rod Burstall, and most recently especially Grant Malcolm, this work has developed into a new hidden algebra approach <ref> [54, 58, 77, 7, 87, 140, 89] </ref>, intended to facilitate proving properties of designs, as opposed to code, and in particular, to facilitate refinement proofs, that one level of design is correctly realized by another. <p> Hidden algebra has also opened intriguing new perspectives on nondeterminism and concurrency: nondeterminism arises naturally simply by not specifying some behaviors [89]; and concurrency is described by an elegant universal 11 construction on hidden theories <ref> [77] </ref>. A hidden Herbrand theorem which unifies the object and logic paradigms at the logical level is proved in [90].
Reference: [78] <author> Joseph Goguen and Susanna Ginali. </author> <title> A categorical approach to general systems theory. </title> <editor> In George Klir, editor, </editor> <booktitle> Applied General Systems Research, </booktitle> <pages> pages 257-270. </pages> <publisher> Plenum, </publisher> <year> 1978. </year>
Reference-contexts: Systems were taken to be diagrams in a category, behaviors were given by their limits, and interconnections were given by colimits of diagrams; some very general laws about interconnection and behavior hold in this setting <ref> [35, 37, 78] </ref>.
Reference: [79] <author> Joseph Goguen, Jean-Pierre Jouannaud, and Jose Meseguer. </author> <title> Operational semantics of order-sorted algebra. </title> <editor> In Wilfried Brauer, editor, </editor> <booktitle> Proceedings, 1985 International Conference on Automata, Languages and Programming. Springer, 1985. Lecture Notes in Computer Science, </booktitle> <volume> Volume 194. </volume>
Reference-contexts: A good deal of theory was done to support Eqlog, including: complete rules of deduction, and Herbrand and initiality theorems, both for order sorted Horn clause logic with equality <ref> [79, 96] </ref>; order sorted unification [152]; order sorted narrowing and resolution [79, 152]; correctness criteria for builtin algorithms; and an initial model semantics generalizing and subsuming the traditional Herbrand universe construction. <p> A good deal of theory was done to support Eqlog, including: complete rules of deduction, and Herbrand and initiality theorems, both for order sorted Horn clause logic with equality [79, 96]; order sorted unification [152]; order sorted narrowing and resolution <ref> [79, 152] </ref>; correctness criteria for builtin algorithms; and an initial model semantics generalizing and subsuming the traditional Herbrand universe construction.
Reference: [80] <author> Joseph Goguen, Kai Lin, Akira Mori, Grigore Ro~su, and Akiyoshi Sato. </author> <title> Distributed cooperative formal methods tools. </title> <editor> In Michael Lowry, editor, </editor> <booktitle> Proceedings, Automated Software Engineering, </booktitle> <pages> pages 55-62. </pages> <publisher> IEEE, </publisher> <address> 1997. Lake Tahoe CA, </address> <month> 3-5 November </month> <year> 1997. </year> <month> 21 </month>
Reference-contexts: Recent work at the UCSD Meaning and Computation Lab seeks to address the distributed cooperative aspect of software engineering with an environment called tatami <ref> [80, 102] </ref> for CafeOBJ, having the capability (but not the necessity) for complete formal verification. <p> The potential to connect diverse areas on both sides of the great divide and to enter new application areas, such as user interface design, seems very exciting. When applied to user interface design, algebraic semiotics can model the content and structure of information through its representation <ref> [68, 80, 101, 102] </ref>; it is now being used to design interfaces for the tatami system (see Section 2.11).
Reference: [81] <author> Joseph Goguen and Charlotte Linde. </author> <title> Cost-benefit analysis of a proposed computer system. </title> <type> Technical report, Structural Semantics, </type> <year> 1978. </year>
Reference-contexts: Two other discourse types are stories [126] and jokes [162], which are interesting because they embed values of the speaker and audience, and can therefore be used to study those values [69, 86]. This was applied in <ref> [81] </ref> as part of a study to determine requirements for a system to computerize a small headhunting firm, by collecting stories and jokes told during breaks and at lunch, and then collating them into a "value system tree" for the firm, as described in [60, 86]; this work also showed how <p> The second was a classification of methods and tools used for requirements [4]. The first project built on early work with Linde on requirements elicitation <ref> [81] </ref>, which was followed by a critical survey of elicitation methods [83]. The second project was in part inspired by work of Lyotard [138] on post-modernism.
Reference: [82] <author> Joseph Goguen and Charlotte Linde. </author> <title> Linguistic methodology for the analysis of aviation accidents. </title> <type> Technical report, Structural Semantics, </type> <month> December </month> <year> 1983. </year> <type> NASA Contractor Report 3741, </type> <institution> Ames Research Center. </institution>
Reference-contexts: Several types of discourse have a definite regular structure, including planning [134], explanation [113] and command and control discourse <ref> [82, 85] </ref>. The latter was developed in studies supported by NASA, on statistical properties of aviation discourse in emergency situations, for application to aviation safety.
Reference: [83] <author> Joseph Goguen and Charlotte Linde. </author> <title> Techniques for requirements elicitation. </title> <editor> In Stephen Fickas and Anthony Finkelstein, editors, </editor> <booktitle> Requirements Engineering '93, </booktitle> <pages> pages 152-164. </pages> <publisher> IEEE, </publisher> <year> 1993. </year> <note> Reprinted in Software Requirements Engineering (Second Edition), </note> <editor> ed. Richard Thayer and Merlin Dorfman, </editor> <publisher> IEEE Computer Society, </publisher> <year> 1996. </year>
Reference-contexts: So this work remains largely unknown. A critical overview of techniques for gathering information about social situations is given in <ref> [83] </ref>; in general, the greater the accuracy, the greater the difficulty. 3.2 Requirements Engineering Case studies and experience suggest that flawed requirements may be the most significant source of errors in system development; moreover, it has been shown that requirements errors are the most expensive to correct 11 at later stages <p> The second was a classification of methods and tools used for requirements [4]. The first project built on early work with Linde on requirements elicitation [81], which was followed by a critical survey of elicitation methods <ref> [83] </ref>. The second project was in part inspired by work of Lyotard [138] on post-modernism. Other work from the Centre included a book [124] consisting of (revised) papers from a workshop organized by the Centre, some more papers [64, 123], and the toor object oriented tool for tracing requirements [160].
Reference: [84] <author> Joseph Goguen, Charlotte Linde, and Tora Bikson. </author> <title> Optimal structures for multimedia instruction. </title> <type> Technical report, </type> <institution> Computer Science Lab, SRI International, </institution> <month> July </month> <year> 1985. </year>
Reference-contexts: The latter was developed in studies supported by NASA, on statistical properties of aviation discourse in emergency situations, for application to aviation safety. Later work on multi-media instruction supported by the Office of Naval Research involved naturalistic experiments and ideas from semiotics, for application to human-computer interface design <ref> [84] </ref>; this later led to the work discussed in Section 3.3. Two other discourse types are stories [126] and jokes [162], which are interesting because they embed values of the speaker and audience, and can therefore be used to study those values [69, 86].
Reference: [85] <author> Joseph Goguen, Charlotte Linde, and Miles Murphy. </author> <title> Crew communication as a factor in aviation accidents. </title> <editor> In E. James Hartzell and Sandra Hart, editors, </editor> <booktitle> Papers from the 20th Annual Conference on Manual Control. </booktitle> <institution> NASA Ames Research Center, </institution> <year> 1984. </year>
Reference-contexts: Several types of discourse have a definite regular structure, including planning [134], explanation [113] and command and control discourse <ref> [82, 85] </ref>. The latter was developed in studies supported by NASA, on statistical properties of aviation discourse in emergency situations, for application to aviation safety.
Reference: [86] <author> Joseph Goguen and Luqi. </author> <title> Formal methods and social context in software development. </title> <editor> In Peter Mosses, Mogens Nielsen, and Michael Schwartzbach, editors, </editor> <booktitle> Proceedings, Sixth International Joint Conference on Theory and Practice of Software Development (TAPSOFT 95), </booktitle> <pages> pages 62-81. </pages> <publisher> Springer, </publisher> <year> 1995. </year> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> Volume 915. </volume>
Reference-contexts: Two other discourse types are stories [126] and jokes [162], which are interesting because they embed values of the speaker and audience, and can therefore be used to study those values <ref> [69, 86] </ref>. <p> This was applied in [81] as part of a study to determine requirements for a system to computerize a small headhunting firm, by collecting stories and jokes told during breaks and at lunch, and then collating them into a "value system tree" for the firm, as described in <ref> [60, 86] </ref>; this work also showed how to extract dataflow diagrams from task oriented discourse. For some reason, linguistics seems stuck on the syntax of sentences, despite the fact that there are important applications at higher levels.
Reference: [87] <author> Joseph Goguen and Grant Malcolm. </author> <title> Proof of correctness of object representation. </title> <editor> In A. William Roscoe, </editor> <publisher> editor, </publisher>
Reference-contexts: In collaboration with Razvan Diaconescu, Rod Burstall, and most recently especially Grant Malcolm, this work has developed into a new hidden algebra approach <ref> [54, 58, 77, 7, 87, 140, 89] </ref>, intended to facilitate proving properties of designs, as opposed to code, and in particular, to facilitate refinement proofs, that one level of design is correctly realized by another.
References-found: 87

