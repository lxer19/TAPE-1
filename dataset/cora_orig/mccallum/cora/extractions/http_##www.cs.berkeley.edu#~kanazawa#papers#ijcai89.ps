URL: http://www.cs.berkeley.edu/~kanazawa/papers/ijcai89.ps
Refering-URL: http://www.cs.berkeley.edu/~kanazawa/papers/ijcai89.html
Root-URL: 
Email: kgk@cs.brown.edu tld@cs.brown.edu  
Title: A Model for Projection and Action  
Author: Keiji Kanazawa and Thomas Dean 
Keyword: formance in dynamic situations.  
Address: Box 1910 Providence, RI 02912  
Affiliation: Department of Computer Science Brown University,  
Abstract: In designing autonomous agents that deal competently with issues involving time and space, there is a tradeoff to be made between guaranteed response-time reactions on the one hand, and flexibility and expressiveness on the other. We propose a model of action with probabilistic reasoning and decision analytic evaluation for use in a layered control architecture. Our model is well suited to tasks that require reasoning about the interaction of behaviors and events in a fixed temporal horizon. Decisions are continuously reevaluated, so that there is no problem with plans becoming obsolete as new information becomes available. In this paper, we are particularly interested in the tradeoffs required to guarantee a fixed reponse time in reasoning about nondeterministic cause-and- effect relationships. By exploiting approximate decision making processes, we are able to trade accuracy in our predictions for speed in decision making in order to improve expected per 
Abstract-found: 1
Intro-found: 1
Reference: [ Boddy and Dean, 1989 ] <author> Mark Boddy and Thomas Dean. </author> <title> Solving time dependent planning problems. </title> <booktitle> In Proceedings IJCAI-89, </booktitle> <year> 1989. </year> <note> (In this volume). </note>
Reference-contexts: Later in this section, we examine a method of causal model reduction which produces substantial performance improvements. A special class of approximation algorithms receiving attention are anytime algorithms <ref> [ Dean and Boddy, 1988, Boddy and Dean, 1989 ] </ref> : algorithms that iteratively improve the quality of their answers relative to a given query.
Reference: [ Brooks, 1985 ] <author> Rodney A. Brooks. </author> <title> A robust layered con-trol system for a mobile robot. </title> <editor> A. I. </editor> <volume> Memo 864, </volume> <publisher> MIT Artificial Intelligence Laboratory, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1985. </year>
Reference-contexts: A plan in our model is just a sequence of behaviors where a behavior corresponds to a mode of operation for a subsystem in a layered control architecture <ref> [ Brooks, 1985, Kaelbling, 1987 ] </ref> . Each behavior in a plan has a condition attached to it called its task completion criterion that specifies when to terminate the behavior.
Reference: [ Cooper, 1988 ] <author> Gregory F. Cooper. </author> <title> The computational complexity of probabilistic inference using belief net-works. </title> <institution> Memo KSL-87-27, Knowledge Systems Lab, Stanford University, </institution> <year> 1988. </year>
Reference-contexts: Unfortunately, it has been shown <ref> [ Cooper, 1988 ] </ref> , that that computing a probability distribution for a general belief network is an NP-Hard problem.
Reference: [ Dean and Boddy, 1988 ] <author> Thomas Dean and Mark Boddy. </author> <title> An analysis of time depen-dent planning. </title> <booktitle> In Proceedings AAAI-88, </booktitle> <year> 1988. </year>
Reference-contexts: To make the tradeoffs involved in compilation precise, we need to consider the overall utility of a run-time system including the practical utility associated with the time that is spent in computing an answer <ref> [ Dean and Boddy, 1988, Horvitz, 1988 ] </ref> . <p> Later in this section, we examine a method of causal model reduction which produces substantial performance improvements. A special class of approximation algorithms receiving attention are anytime algorithms <ref> [ Dean and Boddy, 1988, Boddy and Dean, 1989 ] </ref> : algorithms that iteratively improve the quality of their answers relative to a given query.
Reference: [ Dean and Kanazawa, 1988a ] <author> Thomas Dean and Keiji Kanazawa. </author> <title> Probabilistic causal reasoning. </title> <booktitle> In Proceedings of the Canadian Society for Computational Studies of Intelligence. CSCSI, </booktitle> <year> 1988. </year>
Reference-contexts: Our methods depend upon being able to perform experiments at design time in order to determine the optimal tradeoff. The model that we adopt is an extension of our previous work in probabilistic temporal reasoning <ref> [ Dean and Kanazawa, 1988a, Dean and Kanazawa, 1988b ] </ref> . It is a model of reasoning well suited to tasks such as detecting simple interactions among behaviors and coping with uncertain events.
Reference: [ Dean and Kanazawa, 1988b ] <author> Thomas Dean and Keiji Kanazawa. </author> <title> Probabilistic temporal reasoning. </title> <booktitle> In Proceedings AAAI-88. AAAI, </booktitle> <year> 1988. </year>
Reference-contexts: Our methods depend upon being able to perform experiments at design time in order to determine the optimal tradeoff. The model that we adopt is an extension of our previous work in probabilistic temporal reasoning <ref> [ Dean and Kanazawa, 1988a, Dean and Kanazawa, 1988b ] </ref> . It is a model of reasoning well suited to tasks such as detecting simple interactions among behaviors and coping with uncertain events.
Reference: [ Henrion, 1988 ] <author> Max Henrion. </author> <title> Propagating uncertainty by logic sampling in bayes' networks. </title> <editor> In John F. Lemmer and Laveen F. Kanal, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 2, </booktitle> <pages> pages 149-163. </pages> <publisher> North-Holland, </publisher> <year> 1988. </year>
Reference: [ Horvitz et al., 1989 ] <author> Eric J. Horvitz, Gregory F. Cooper, and David E. Heckerman. </author> <title> Reflection and ac-tion under scarce resources: Theoretical principles and empirical study. </title> <booktitle> In Proceedings IJCAI-89, </booktitle> <year> 1989. </year> <note> (In this volume). </note>
Reference-contexts: Within that context, anytime algorithms are just as applicable for us as for systems with more complex run-time deliberation scheduling. Applicable anytime algorithms for causal models include Monte Carlo simulation algorithms [ Hen- rion, 1988, Pearl, 1988 ] , and bounding algorithms such as bounded cutset conditioning <ref> [ Horvitz et al., 1989 ] </ref> . So far, we have not said much about the plan selection decision itself. As we noted before, the causal model decision problem involves selecting the plan with the highest expected utility.
Reference: [ Horvitz, 1988 ] <author> Eric J. Horvitz. </author> <title> Reasoning about beliefs and actions under computational resource constraints. </title> <booktitle> In Proceedings AAAI-88, </booktitle> <pages> pages 111-116, </pages> <year> 1988. </year>
Reference-contexts: To make the tradeoffs involved in compilation precise, we need to consider the overall utility of a run-time system including the practical utility associated with the time that is spent in computing an answer <ref> [ Dean and Boddy, 1988, Horvitz, 1988 ] </ref> .
Reference: [ Howard and Matheson, 1984 ] <author> Ron A. Howard and James E. Matheson. </author> <title> Influence diagrams. </title> <editor> In Ron A. Howard and James E. Matheson, editors, </editor> <title> The Principles and Applications of Decision Analysis. Strategic Decisions Group, </title> <address> Menlo Park, CA 94025, </address> <year> 1984. </year>
Reference-contexts: knowledge, a system based on our model should be able to respond to changing conditions in the world in a timely manner. 2 Our Model of Projection and Action In our model, an agent has a fixed representation of knowledge about the world in the form of an influence diagram <ref> [ Howard and Matheson, 1984 ] </ref> . An influence diagram is a compact graphical representation of a probabilistic causal theory including the effects of deterministic decisions and preferences over possible world states (see Figure 1).
Reference: [ Howard, 1960 ] <author> Ron A. Howard. </author> <title> Dynamic Programming and Markov Decision Processes. </title> <publisher> MIT Press, </publisher> <year> 1960. </year>
Reference-contexts: We say that our value function is time separable if the total value V is given by V = t In that case, we say that V t is the objective value at time t. These two properties essentially define a Markov decision process 1 <ref> [ Howard, 1960 ] </ref> . As far as decisions in causal models are concerned, within the scope of this work, causal models contain only one decision: the plan selection decision.
Reference: [ Kaelbling, 1987 ] <author> Leslie Pack Kaelbling. </author> <title> An architec-ture for intelligence reactive systems. </title> <editor> In Michael P. Georgeff and Amy L. Lansky, editors, </editor> <booktitle> Reasoning About Actions and Plans, </booktitle> <pages> pages 395-410. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1987. </year>
Reference-contexts: A plan in our model is just a sequence of behaviors where a behavior corresponds to a mode of operation for a subsystem in a layered control architecture <ref> [ Brooks, 1985, Kaelbling, 1987 ] </ref> . Each behavior in a plan has a condition attached to it called its task completion criterion that specifies when to terminate the behavior.
Reference: [ Lauritzen and Spiegelhalter, 1988 ] <author> Stephen L. Lauritzen and David J. Spiegelhalter. </author> <title> Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> Journal of the Royal Statistical Society Series B, </journal> <volume> 50(2) </volume> <pages> 157-194, </pages> <year> 1988. </year>
Reference-contexts: Unfortunately, it has been shown [ Cooper, 1988 ] , that that computing a probability distribution for a general belief network is an NP-Hard problem. Even the most efficient known algorithm for computing an exact distribution in a belief net <ref> [ Lauritzen and Spiegelhalter, 1988 ] </ref> has a time complexity exponential in the size of the largest clique in the belief net graph 2 .
Reference: [ McDermott, 1982 ] <author> Drew V. McDermott. </author> <title> A temporal logic for reasoning about processes and plans. </title> <journal> Cognitive Science, </journal> <volume> 6 </volume> <pages> 101-155, </pages> <year> 1982. </year>
Reference-contexts: It is often important to keep information from the past for various purposes, for example, for incorporating sensor data from the past. Within a causal model, a special class of influences describe persistence <ref> [ McDermott, 1982 ] </ref> of propositions. We may, for example, have knowledge such as, "The energy at a given source is likely to diminish by 10% every hour".
Reference: [ Pearl, 1988 ] <author> Judea Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufman, </publisher> <year> 1988. </year>
Reference-contexts: do so is not likely to be as useful as a system that computes approximate, but close to accurate answers very 2 There is a known efficient polynomial time algorithm for computing the probability distribution for a belief net if the underlying undirected graph of the net has no cycles <ref> [ Pearl, 1988 ] </ref> . fast. Our goal in compilation is to maximize the overall utility. As an illustration of a simple compilation method, consider the following. Assume that we have a number of algorithms available to us for computing an answer to the problem of what to do next. <p> Within that context, anytime algorithms are just as applicable for us as for systems with more complex run-time deliberation scheduling. Applicable anytime algorithms for causal models include Monte Carlo simulation algorithms <ref> [ Hen- rion, 1988, Pearl, 1988 ] </ref> , and bounding algorithms such as bounded cutset conditioning [ Horvitz et al., 1989 ] . So far, we have not said much about the plan selection decision itself.
Reference: [ Rosenschein and Kaelbling, 1986 ] <author> Stanley J. Rosenschein and Leslie Pack Kaelbling. </author> <title> The synthesis of digital machines with provable epistemic properties. </title> <booktitle> In Proceedings Conference on Theoretical Aspects of Reasoning About Knowledge, </booktitle> <pages> pages 83-98, </pages> <address> Asilomar, California, </address> <year> 1986. </year>
Reference-contexts: The consequences of this observation for traditional methods of representation and reasoning in AI are profound. In the situated automata approach [ Rosenschein, 1987 ] , traditional run-time symbolic reasoning is bypassed in favor of highly specific condition-action relations that have been compiled into circuit-like systems <ref> [ Rosenschein and Kaelbling, 1986 ] </ref> . However, in domains with complex causal dependencies, particularly nondeterministic ones, the space of possible conditions is large.
Reference: [ Rosenschein, 1987 ] <author> Stanley J. Rosenschein. </author> <title> Formal the-ories of knowledge in ai and robotics. Report No. CSLI-87-84, Center for Study of Language and Information, </title> <publisher> Stanford, </publisher> <address> California, </address> <year> 1987. </year>
Reference-contexts: The field is grudgingly coming to accept that systems embedded in the world must be engineered to respond to external events in a timely manner. The consequences of this observation for traditional methods of representation and reasoning in AI are profound. In the situated automata approach <ref> [ Rosenschein, 1987 ] </ref> , traditional run-time symbolic reasoning is bypassed in favor of highly specific condition-action relations that have been compiled into circuit-like systems [ Rosenschein and Kaelbling, 1986 ] . However, in domains with complex causal dependencies, particularly nondeterministic ones, the space of possible conditions is large.
Reference: [ Shachter, 1986 ] <author> Ross D. Shachter. </author> <title> Evaluating influ-ence diagrams. </title> <journal> Operations Research, </journal> <volume> 34(6) </volume> <pages> 871-882, </pages> <month> November/December </month> <year> 1986. </year>
Reference-contexts: An influence diagram is a compact graphical representation of a probabilistic causal theory including the effects of deterministic decisions and preferences over possible world states (see Figure 1). In the following, we follow Shachter's presentation of influence diagrams in <ref> [ Shachter, 1986 ] </ref> . An influence diagram is a directed graph G = (N; A), consisting of a set of nodes N , and a set of arcs A. <p> Therefore, there is nothing conceptually to bar us from reducing our causal model to this form (see Figure 3). There is a well known method <ref> [ Shachter, 1986 ] </ref> for eliminating a chance node in an influence diagram when it is neither an input node, nor a node for which we are explicitly computing a conditional probability distribu tion.
References-found: 18

