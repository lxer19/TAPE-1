URL: http://www.cs.duke.edu/~jsv/Papers/ViS94.sorting_io.ps.gz
Refering-URL: http://www.cs.duke.edu/~jsv/Papers/catalog/node4.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: CS-1993-01 Algorithms for Parallel Memory I: Two-Level Memories  
Author: Jeffrey Scott Vitter, Elizabeth A. M. Shriver 
Date: January 20, 1993  
Address: 27708-0129  
Affiliation: Department of Computer Science Duke University Durham, North Carolina  
Abstract-found: 0
Intro-found: 1
Reference: [AgV] <author> A. Aggarwal and J. S. Vitter, </author> <title> "The Input/Output Complexity of Sorting and Related Problems," </title> <journal> Communications of the ACM (September 1988), </journal> <pages> 1116-1127. </pages>
Reference-contexts: Efficient algorithms for multilevel hierarchical memory are considered in the companion paper [ViS]. In previous work, Aggarwal and Vitter <ref> [AgV] </ref> presented optimal upper and lower bounds on the I/O needed for sorting-related problems of size N using a two-level memory model where internal memory can store M records and the secondary memory size is limitless. <p> Their results generalized the groundbreaking work done by Floyd [Flo], who gave optimal bounds for sorting, realized by standard two-way merge sort, for the special case P = 1 and M = 2B = p N . The model in <ref> [AgV] </ref> is somewhat unrealistic, however, because secondary storage is usually partitioned into separate physical devices, each capable of transferring only one block per I/O. We are interested in optimal algorithms for realistic two-level storage systems that allow P simultaneous data transfers. <p> That is, only one track per disk can be accessed, but there is no constraint on which track is accessed on each disk. The restriction that only one block can be accessed per disk during an I/O is what distinguishes our model from the less realistic model of <ref> [AgV] </ref>. This distinction is akin to the difference in parallel computation between the MPC (module parallel computer) model and the less realistic PRAM model. However, general PRAM simulation techniques use logarithmic time per step; if they were applied to the algorithms in [AgV], the resulting 5 B records D 1 Disks <p> our model from the less realistic model of <ref> [AgV] </ref>. This distinction is akin to the difference in parallel computation between the MPC (module parallel computer) model and the less realistic PRAM model. However, general PRAM simulation techniques use logarithmic time per step; if they were applied to the algorithms in [AgV], the resulting 5 B records D 1 Disks Tracks algorithms would not be optimal in terms of I/O. The algorithms we develop on our model use the same number of I/Os as those in [AgV] for the less realistic model. 3 Problem Definitions The problems we consider in this paper <p> simulation techniques use logarithmic time per step; if they were applied to the algorithms in <ref> [AgV] </ref>, the resulting 5 B records D 1 Disks Tracks algorithms would not be optimal in terms of I/O. The algorithms we develop on our model use the same number of I/Os as those in [AgV] for the less realistic model. 3 Problem Definitions The problems we consider in this paper have been well described in the literature. Most of the following definitions are those from [AgV], with suitable modifications. <p> The algorithms we develop on our model use the same number of I/Os as those in <ref> [AgV] </ref> for the less realistic model. 3 Problem Definitions The problems we consider in this paper have been well described in the literature. Most of the following definitions are those from [AgV], with suitable modifications. Sorting Problem Instance: The internal memory is empty, and the N records are stored in the first N locations of secondary storage. Goal: The internal memory is empty, and the N records are stored in sorted non-decreasing order in the first N locations of secondary storage. <p> The logarithmic factors that multiply the N=P B term in the above expressions indicate the degree of nonlinearity. The I/O lower bounds for Theorems 1-4 follow from the lower bounds proved in <ref> [AgV] </ref> for the less realistic model in which P tracks can be accessed on the same disk in a single I/O. Since any algorithm in our model automatically applies to the model in [AgV], the same lower bounds apply. The I/O lower bounds proved in [AgV] are based only on routing <p> The I/O lower bounds for Theorems 1-4 follow from the lower bounds proved in <ref> [AgV] </ref> for the less realistic model in which P tracks can be accessed on the same disk in a single I/O. Since any algorithm in our model automatically applies to the model in [AgV], the same lower bounds apply. The I/O lower bounds proved in [AgV] are based only on routing concerns and thus hold for an arbitrarily powerful adversary, except in the case of sorting for the extreme case mentioned in Theorem 1 when M and B are extremely small, in which case <p> the lower bounds proved in <ref> [AgV] </ref> for the less realistic model in which P tracks can be accessed on the same disk in a single I/O. Since any algorithm in our model automatically applies to the model in [AgV], the same lower bounds apply. The I/O lower bounds proved in [AgV] are based only on routing concerns and thus hold for an arbitrarily powerful adversary, except in the case of sorting for the extreme case mentioned in Theorem 1 when M and B are extremely small, in which case the comparison model is used. <p> The algorithms, which consist of a series of shu*e-merges, are the ones described in <ref> [AgV] </ref>, except that the disk placement of the blocks of the merged runs must be done in a staggered way so that the merging in the next pass can be done using full parallelism. <p> After the Phase 2 partitioning, each bucket will have at most M records and can be sorted internally, as described in Section 6.3. An alternative to the Phase 2 technique for small N is the deterministic approach based on Leighton's Columnsort algorithm [Lei], as mentioned in <ref> [AgV] </ref> and described in detail in [NoVc, Theorem 6]. However, we use Phase 2 here because it complements Phase 1 nicely in approach and has fairly small constant factors. As noted above, we assume for simplicity that N , M , P , and B are powers of 2. <p> The condition (S 1) 2 2M in Lemma 3 is satisfied by the setting S p M=B= ln 2 (M=B) + 1 for Phase 1, and we have pN=M = (S 1)N=4M N=2 (S 1). 6.5 Permuting for Very Small P and B Aggarwal and Vitter <ref> [AgV] </ref> show in their one-disk model with P block transfers per I/O that the optimal way to permute when P and B are very small is the nave method of repeatedly moving P records in each I/O from their inputed positions to the desired final positions.
Reference: [BFP] <author> M. Blum, R. W. Floyd, V. Pratt, R. Rivest, and R. E. Tarjan, </author> <title> "Time Bounds for Selection," in Complexity of Computer Calculations, </title> <editor> Miller and Thatcher, eds., </editor> <publisher> Plenum, </publisher> <address> NY, </address> <year> 1973, </year> <pages> 105-109. </pages>
Reference-contexts: We pick the median record from each of these sorted sets and find the median of the medians using the linear-time sequential algorithm developed in <ref> [BFP] </ref>. The number of I/Os required for these operations is O (n=P B + n=M ) = O (n=P B). We use the key value of this median record to partition the n records into two sets.
Reference: [CaW] <author> J. L. Carter and M. N. Wegman, </author> <title> "Universal Classes of Hash Functions," </title> <journal> Journal of Computer and System Sciences 18 (April 1979), </journal> <pages> 143-154. </pages>
Reference-contexts: Applications of these techniques to obtain optimal algorithms for the P-HMM and P-BT hierarchical memory models are developed in the companion paper [ViS]. Preliminary work suggests that the amount of randomness in our distribution sort algorithm can be greatly reduced by applying universal hashing <ref> [CaW] </ref> in an interesting way. But the problem of removing randomness completely from this technique is more difficult. The study of I/O efficiency has many applications besides the ones we studied in this paper. For example, graphics applications, multidimensional search problems, and iterated lattice computations often involve I/O-bound tasks.
Reference: [Flo] <author> R. W. Floyd, </author> <title> "Permuting Information in Idealized Two-Level Storage," in Complexity of Computer Calculations, </title> <editor> R. Miller and J. Thatcher, ed., </editor> <publisher> Plenum, </publisher> <year> 1972, </year> <pages> 105-109. </pages>
Reference-contexts: In their model, an I/O can simultaneously transfer P physical blocks, each consisting of B contiguous records. Their results generalized the groundbreaking work done by Floyd <ref> [Flo] </ref>, who gave optimal bounds for sorting, realized by standard two-way merge sort, for the special case P = 1 and M = 2B = p N .
Reference: [HGK] <author> L. Hellerstein, G. Gibson, R. M. Karp, R. H. Katz, and D. A. Patterson, </author> <title> "Coding Techniques for Handling Failures in Large Disk Arrays," </title> <journal> Algorithmica, </journal> <note> this issue. </note>
Reference-contexts: This bottleneck is accentuated as processors get faster and parallel computers are used. The remedy we explore in this paper is to use secondary storage systems with parallel capabilities <ref> [HGK, Jil, Mag, PGK, Uni] </ref>. We restrict our attention in this paper to two-level storage systems with random access secondary storage.
Reference: [Jil] <author> W. Jilke, </author> <title> "Disk Array Mass Storage Systems: The New Opportunity," </title> <publisher> Amperif Corporation, </publisher> <month> September </month> <year> 1986. </year>
Reference-contexts: This bottleneck is accentuated as processors get faster and parallel computers are used. The remedy we explore in this paper is to use secondary storage systems with parallel capabilities <ref> [HGK, Jil, Mag, PGK, Uni] </ref>. We restrict our attention in this paper to two-level storage systems with random access secondary storage.
Reference: [Kle] <author> L. Kleinrock, </author> <title> Queueing Systems, Volume I: Theory, </title> <publisher> Wiley and Sons, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: To bound (9), we use Chernoff's bound <ref> [Kle] </ref>: Lemma 1 If X is a nonnegative random variable and r 0 we have PrfX ug E (e rX ) Before we apply Chernoff's bound, we must construct the appropriate scenario.
Reference: [Knu] <author> D. Knuth, </author> <title> The Art of Computer Programming, Volume 3: Sorting and Searching, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1973. </year>
Reference-contexts: 1 Introduction Sorting is the canonical information-processing application. It accounts for roughly 20-25 percent of the computing resources on large-scale computers <ref> [Knu, LiV] </ref>. In applications where the file of records cannot fit into internal memory, the records must be stored on (external) secondary storage, usually in the form of disks. Sorting in this framework is called external sorting. <p> Sorting in this framework is called external sorting. The bottleneck in external sorting and many other applications is the time for the input/output (I/O) between internal memory and the disks <ref> [Knu, LiV] </ref>. This bottleneck is accentuated as processors get faster and parallel computers are used. The remedy we explore in this paper is to use secondary storage systems with parallel capabilities [HGK, Jil, Mag, PGK, Uni]. <p> Permutation Networks The problem instance and goal are the same as for the FFT problem, except that the permutation network digraph (see below) is pebbled instead of the FFT digraph. A permutation network is a sorting network <ref> [Knu] </ref> consisting of comparator modules or switches that can be set by external controls so that any desired permutation of the inputs can be realized at the output level of the network. It consists of J + 1 levels, for some J log N , each containing N nodes. <p> Thus the hard part of sorting in the non-extreme case is the routing of the records, not the determination of the records' order. The well-known technique of key sorting <ref> [Knu] </ref>, which attempts to reduce sorting to permutation routing by using a special-purpose method of determining the order of the records, is therefore not going to use significantly fewer I/Os than will general sorting algorithms.
Reference: [Lei] <author> F. T. Leighton, </author> <title> "Tight Bounds on the Complexity of Parallel Sorting," </title> <journal> IEEE Transactions on Computers C-34 (April 1985), </journal> <pages> 344-354. </pages>
Reference-contexts: After the Phase 2 partitioning, each bucket will have at most M records and can be sorted internally, as described in Section 6.3. An alternative to the Phase 2 technique for small N is the deterministic approach based on Leighton's Columnsort algorithm <ref> [Lei] </ref>, as mentioned in [AgV] and described in detail in [NoVc, Theorem 6]. However, we use Phase 2 here because it complements Phase 1 nicely in approach and has fairly small constant factors.
Reference: [LiV] <author> E. E. Lindstrom and J. S. Vitter, </author> <title> "The Design and Analysis of BucketSort for Bubble Memory Secondary Storage," </title> <journal> IEEE Transactions on Computers C-34 (March 1985), </journal> <pages> 218-233. </pages>
Reference-contexts: 1 Introduction Sorting is the canonical information-processing application. It accounts for roughly 20-25 percent of the computing resources on large-scale computers <ref> [Knu, LiV] </ref>. In applications where the file of records cannot fit into internal memory, the records must be stored on (external) secondary storage, usually in the form of disks. Sorting in this framework is called external sorting. <p> Sorting in this framework is called external sorting. The bottleneck in external sorting and many other applications is the time for the input/output (I/O) between internal memory and the disks <ref> [Knu, LiV] </ref>. This bottleneck is accentuated as processors get faster and parallel computers are used. The remedy we explore in this paper is to use secondary storage systems with parallel capabilities [HGK, Jil, Mag, PGK, Uni].
Reference: [Mag] <author> N. B. Maginnis, </author> <title> "Store More, Spend Less: Mid-Range Options Around," </title> <month> Computer-world (November 16, </month> <year> 1986), </year> <month> 71. </month>
Reference-contexts: This bottleneck is accentuated as processors get faster and parallel computers are used. The remedy we explore in this paper is to use secondary storage systems with parallel capabilities <ref> [HGK, Jil, Mag, PGK, Uni] </ref>. We restrict our attention in this paper to two-level storage systems with random access secondary storage.
Reference: [NoVa] <author> M. H. Nodine and J. S. Vitter, </author> <title> "Optimal Deterministic Sorting on Parallel Memory Hierarchies," </title> <institution> Department of Computer Science, Duke University, </institution> <type> Technical Report, </type> <month> January </month> <year> 1993. </year>
Reference-contexts: No-dine and Vitter have subsequently developed an optimal distribution sort algorithm that is deterministic and that does generalize to give optimal deterministic parallel hierarchy algorithms <ref> [NoVa, NoVb] </ref>. Acknowledgments. We thank Bowen Alpern, Larry Carter, Tom Cormen, Mike Goodrich, and Mark Nodine for several helpful comments.
Reference: [NoVb] <author> M. H. Nodine and J. S. Vitter, </author> <title> "Optimal Deterministic Sorting on Parallel Disks," </title> <institution> Department of Computer Science, Duke University, </institution> <note> Technical Report , January 1993. 34 REFERENCES </note>
Reference-contexts: No-dine and Vitter have subsequently developed an optimal distribution sort algorithm that is deterministic and that does generalize to give optimal deterministic parallel hierarchy algorithms <ref> [NoVa, NoVb] </ref>. Acknowledgments. We thank Bowen Alpern, Larry Carter, Tom Cormen, Mike Goodrich, and Mark Nodine for several helpful comments.
Reference: [NoVc] <author> M. H. Nodine and J. S. Vitter, </author> <title> "Large-Scale Sorting in Parallel Memories," </title> <booktitle> Proceedings of the 3rd Annual ACM Symposium on Parallel Algorithms and Architectures (July 1991). </booktitle>
Reference-contexts: An alternative to the Phase 2 technique for small N is the deterministic approach based on Leighton's Columnsort algorithm [Lei], as mentioned in [AgV] and described in detail in <ref> [NoVc, Theorem 6] </ref>. However, we use Phase 2 here because it complements Phase 1 nicely in approach and has fairly small constant factors. As noted above, we assume for simplicity that N , M , P , and B are powers of 2. <p> At the beginning of Section 6 we gave some "intuitions" as to why merge sort seemed especially hard to implement with an optimal number of I/Os in our two-level disk model. Oddly enough, a practical and optimal deterministic sorting algorithm was recently developed by Nodine and Vitter <ref> [NoVc] </ref> using a "greedy" merge sort. Unfortunately this merge sort algorithm does not seem to lead to optimal deterministic sorting algorithms in most cases of the P-HMM, P-BT, and other parallel hierarchical memory models.
Reference: [PGK] <author> D. A. Patterson, G. Gibson, and R. H. Katz, </author> <title> "A Case for Redundant Arrays of Inexpensive Disks (RAID)," </title> <booktitle> Proceedings of the 1988 ACM SIGMOD International Conference on Management of Data (June 1988), </booktitle> <pages> 109-116. </pages>
Reference-contexts: This bottleneck is accentuated as processors get faster and parallel computers are used. The remedy we explore in this paper is to use secondary storage systems with parallel capabilities <ref> [HGK, Jil, Mag, PGK, Uni] </ref>. We restrict our attention in this paper to two-level storage systems with random access secondary storage.
Reference: [SaV] <author> J. Savage and J. S. Vitter, </author> <title> "Parallelism in Space-Time Tradeoffs," </title> <booktitle> in Advances in Computing Research, </booktitle> <volume> Volume 4 , F. </volume> <editor> P. Preparata, ed., </editor> <publisher> JAI Press, </publisher> <year> 1987, </year> <pages> 117-146. </pages>
Reference-contexts: The lower bound in Theorem 5 for standard matrix multiplication follows by taking the bound for the case P = 1 in <ref> [SaV] </ref> and dividing by P . The algorithms that meet the lower bounds of Theorems 1-5 will be described and analyzed in the following sections.
Reference: [Sto] <author> H. S. Stone, </author> <title> "Parallel Processing with the Perfect Shu*e," </title> <journal> IEEE Transactions on Computers C-20 (February 1971), </journal> <pages> 153-161. </pages>
Reference-contexts: Without loss of generality, we assume for simplicity of exposition that N , M , P , and B are powers of 2. The operation of shu*e-merge consists of performing a perfect shu*e <ref> [Sto] </ref> on the elements of M=B runs of r records each, and the result is a single shu*ed run of rM=B elements.
Reference: [Uni] <institution> University of California at Berkeley, "Massive Information Storage, Management, and Use (NSF Institutional Infrastructure Proposal)," </institution> <note> Technical Report No. UCB/CSD 89/493, </note> <month> January </month> <year> 1989. </year>
Reference-contexts: This bottleneck is accentuated as processors get faster and parallel computers are used. The remedy we explore in this paper is to use secondary storage systems with parallel capabilities <ref> [HGK, Jil, Mag, PGK, Uni] </ref>. We restrict our attention in this paper to two-level storage systems with random access secondary storage.
Reference: [ViF] <author> J. S. Vitter and Ph. Flajolet, </author> <title> "Average-Case Analysis of Algorithms and Data Structures," </title> <booktitle> in Handbook of Theoretical Computer Science, </booktitle> <editor> Jan van Leeuwen, ed., </editor> <publisher> North-Holland, </publisher> <year> 1990. </year>
Reference-contexts: It can be thought of intuitively as a hashing approach to distribute the blocks of each bucket among the disks. It works effectively when the "hash function" distributes the records evenly, and by analogy to the maximum bucket occupancy problem in hashing <ref> [ViF] </ref>, the distribution is even when the expected number of blocks per disk for each bucket is at least a logarithmic amount. However, if N is not much larger than M , the distribution using the hashing approach can be quite uneven, resulting in nonoptimal performance.
Reference: [ViS] <author> J. S. Vitter and E. A. Shriver, </author> <title> "Algorithms for Parallel Memory II: Hierarchical Multilevel Memories," </title> <journal> Algorithmica, </journal> <note> this issue. </note>
Reference-contexts: Magnetic disks, for example, provide the functionality needed in our model of secondary storage, so for simplicity we shall refer to secondary storage as disk storage, consisting of one or more disk drives. Efficient algorithms for multilevel hierarchical memory are considered in the companion paper <ref> [ViS] </ref>. In previous work, Aggarwal and Vitter [AgV] presented optimal upper and lower bounds on the I/O needed for sorting-related problems of size N using a two-level memory model where internal memory can store M records and the secondary memory size is limitless. <p> The partitioning is done by a combination of two interesting probabilistic techniques in order to guarantee that the accesses are spread uniformly over the disks. Applications of these techniques to obtain optimal algorithms for the P-HMM and P-BT hierarchical memory models are developed in the companion paper <ref> [ViS] </ref>. Preliminary work suggests that the amount of randomness in our distribution sort algorithm can be greatly reduced by applying universal hashing [CaW] in an interesting way. But the problem of removing randomness completely from this technique is more difficult.
Reference: [WuF] <author> C. Wu and T. Feng, </author> <title> "The Universality of the Shu*e-Exchange Network," </title> <journal> IEEE Transactions on Computers C-30 (May 1981), </journal> <pages> 324-332. </pages>
Reference-contexts: can be realized by three passes through an FFT network, by an appropriate setting of the switches in the FFT network that depends on the permu 10 5 SHUFFLE-MERGE AND ITS APPLICATIONS The M pebbles can be slid forward log M levels before the pebbles have to be regrouped. tation <ref> [WuF] </ref>. So we can get optimal I/O strategies for an FFT-based permutation network by getting optimal I/O strategies for FFT digraphs. The FFT digraph is defined in Section 3. For simplicity, we assume that log M divides log N evenly.
References-found: 21

