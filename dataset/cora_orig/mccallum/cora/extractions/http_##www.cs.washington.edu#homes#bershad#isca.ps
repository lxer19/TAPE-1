URL: http://www.cs.washington.edu/homes/bershad/isca.ps
Refering-URL: http://www.cs.washington.edu/homes/ohlrich/
Root-URL: 
Email: fromer,ohlrich,karlin,bershadg@cs.washington.edu  
Title: Reducing TLB and Memory Overhead Using Online Superpage Promotion  
Author: Theodore H. Romer Wayne H. Ohlrich Anna R. Karlin Brian N. Bershad 
Date: December 19, 1994  
Address: Seattle, WA 98195  
Affiliation: Department of Computer Science and Engineering University of Washington  
Abstract: Modern microprocessors contain small TLBs that maintain a cache of recently used translations. A TLB's coverage is the product of the number of entries and the number of bytes mapped by each entry. Applications with working sets larger than the TLB coverage will perform poorly due to high TLB miss rates. Superpages have been proposed as a mechanism for increasing TLB coverage. A superpage is a virtual memory page that has a size which is a multiple of the system's base page size. In this paper, we describe online policies for superpage management that monitor TLB miss traffic to decide when a superpage should be constructed. Our policies take into account both the benefit of a superpage promotion (potential for eliminating future misses) and the cost (page copying). Although our approach increases the cost of each TLB miss, the overall effect is to substantially reduce the overall number of misses, thereby improving system performance.
Abstract-found: 1
Intro-found: 1
Reference: [Appel & Li 91] <author> Appel, W. and Li, K. </author> <title> Virtual Memory Primitives for User Programs. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-IV), </booktitle> <pages> pages 96-107, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: During periods of heavy memory use, where reference bits, and therefore frequent demotions, are necessary to drive the VM replacement policies, page faults, and not TLB misses, represent the primary system performance problem, so frequent demotions are unlikely to be another. Esoteric functions that require fine-grained reference information <ref> [Appel & Li 91] </ref>, such as write-trapping for a distributed shared memory [Carter et al. 91], will obviously increase the frequency of page demotion. As a result, superpages may not be appropriate for applications that rely on such functions.
Reference: [Babaoglu & Joy 81] <author> Babaoglu, Ozalp. and Joy, W. </author> <title> Converting a Swap-Based System to do Paging in an Architecture Lacking Page-Referenced Bits. </title> <booktitle> In Proceedings of the Eighth Symposium on Operating Systems Principles, </booktitle> <pages> pages 78-86, </pages> <month> December </month> <year> 1981. </year>
Reference-contexts: For simplicity, we assume a software managed TLB, although our accounting strategy could be implemented in hardware. 2.2 Software Many operating systems mechanisms, such as the file system's buffer cache, copy-on-write virtual memory [Young et al. 87], and LRU-clock <ref> [Babaoglu & Joy 81] </ref> assume pages are of a fixed size. With super-pages, though, this assumption can be violated, potentially complicating all clients of the virtual memory system [Talluri & Hill 94].
Reference: [Bala et al. 94] <author> Bala, K., Kaashoek, F., and Weihl, W. </author> <title> Software Prefetching and Caching for Translation Buffers. </title> <booktitle> In Proceedings of the 1st USENIX Symposium on Operating System Design and Implementation (OSDI-I), </booktitle> <pages> pages 243-254, </pages> <month> November </month> <year> 1994. </year>
Reference: [Blanck & Krueger 92] <author> Blanck, G. and Krueger, S. </author> <title> The SuperSPARC Microprocessor. </title> <booktitle> In COMPCON, </booktitle> <pages> pages 136-141, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: This additional logic can now be found in several contemporary processor architectures <ref> [Kane & Heinrich 92, Blanck & Krueger 92] </ref>.
Reference: [Cao et al. 94] <author> Cao, P., Felten, E., and Li, K. </author> <title> Implementation and Performance of Application-Controlled File Caching. </title> <booktitle> In Proceedings of the 1st USENIX Symposium on Operating System Design and Implementation (OSDI-I), </booktitle> <pages> pages 165-177, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Competitive algorithms make online decisions that result in performance within a constant factor of an optimal o*ine algorithm. Prior research in this area has influenced, for example, the design of synchronization [Karlin et al. 91], paging [Sleator & Tarjan 85], and cache management algorithms <ref> [Cao et al. 94] </ref>. 4 The impact of page size on application performance In this section we describe the effect that page size has on system performance and motivate the use of variable-sized superpages to improve performance.
Reference: [Carter et al. 91] <author> Carter, J., Bennett, J., and Zwaenepoel, W. </author> <title> Implementation and performance of Munin. </title> <booktitle> In Proceedings of the Thirteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 152-164, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Esoteric functions that require fine-grained reference information [Appel & Li 91], such as write-trapping for a distributed shared memory <ref> [Carter et al. 91] </ref>, will obviously increase the frequency of page demotion. As a result, superpages may not be appropriate for applications that rely on such functions.
Reference: [Chen et al. 92] <author> Chen, J. B., Borg, A., and Jouppi, N. P. </author> <title> A Simulation-based Study of TLB Performance. </title> <booktitle> In Proceedings of the 19th Annual International Symposium On Computer Architecture, </booktitle> <pages> pages 114-123, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: However, recent results indicate that use of the virtual memory system to detect application-level accesses can be less efficient than strategies that rely on the compiler [Hosking & Moss 93, Zekaukas et al. 94]. 3 Related Work Chen et al. <ref> [Chen et al. 92] </ref>, Mogul [Mogul 93], and Khalidi et al. [Khalidi et al. 93] have described the potential positive impact of a system that supports superpages, although they do not describe policies for promotion or demotion.
Reference: [Dutton et al. 92] <author> Dutton, T., Eiref, D., Kurth, H., Reisert, J., and Stewart, R. </author> <title> The Design of the DEC 3000 AXP Systems, Two High-Performance Workstations. </title> <journal> Digital Technical Journal, </journal> <volume> 4(4) </volume> <pages> 66-81, </pages> <year> 1992. </year> <note> Special Issue. </note>
Reference-contexts: Unfortunately, TLB coverage, which is the number of virtual addresses that can be directly accessed without incurring a TLB miss, has not scaled accordingly. Because modern systems typically incur a penalty of between 10 and 30 cycles per TLB miss <ref> [Kane & Heinrich 92, Dutton et al. 92] </ref>, any application with a working set larger than the TLB's coverage can spend a significant fraction of its time waiting for TLB misses to be serviced [Chen et al. 92, Bala et al. 94, Talluri et al. 92].
Reference: [Hosking & Moss 93] <author> Hosking, A. L. and Moss, J. E. B. </author> <title> Protection Traps and Alternatives for Memory Management of an Object Oriented Language. </title> <booktitle> In Proceedings of the 14th ACM Symposium on Operating System Principles, </booktitle> <pages> pages 106-119, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: As a result, superpages may not be appropriate for applications that rely on such functions. However, recent results indicate that use of the virtual memory system to detect application-level accesses can be less efficient than strategies that rely on the compiler <ref> [Hosking & Moss 93, Zekaukas et al. 94] </ref>. 3 Related Work Chen et al. [Chen et al. 92], Mogul [Mogul 93], and Khalidi et al. [Khalidi et al. 93] have described the potential positive impact of a system that supports superpages, although they do not describe policies for promotion or demotion.
Reference: [Kane & Heinrich 92] <author> Kane, G. and Heinrich, J. </author> <title> MIPS RISC Architecture. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1992. </year>
Reference-contexts: Unfortunately, TLB coverage, which is the number of virtual addresses that can be directly accessed without incurring a TLB miss, has not scaled accordingly. Because modern systems typically incur a penalty of between 10 and 30 cycles per TLB miss <ref> [Kane & Heinrich 92, Dutton et al. 92] </ref>, any application with a working set larger than the TLB's coverage can spend a significant fraction of its time waiting for TLB misses to be serviced [Chen et al. 92, Bala et al. 94, Talluri et al. 92]. <p> We also show that policies that do not consider previous reference patterns and promotion costs perform worse when compared to those that do, in terms of TLB miss overhead, memory consumption, or both. Our online policies require modest architectural support that can already be found in modern systems <ref> [Kane & Heinrich 92] </ref>, namely a software-managed TLB with the ability to map entries of variable size. <p> This additional logic can now be found in several contemporary processor architectures <ref> [Kane & Heinrich 92, Blanck & Krueger 92] </ref>.
Reference: [Karlin et al. 88] <author> Karlin, A., Manasse, M., Rudolph, L., and Sleator, D. </author> <title> Competitive snoopy caching. </title> <journal> Algorithmica, </journal> <volume> 3(1) </volume> <pages> 70-119, </pages> <year> 1988. </year>
Reference-contexts: An online policy that promotes when the miss charges to a page reach R is guaranteed to deliver performance no worse than twice the optimal o*ine with respect to 1 This analogy was originally suggested by Larry Rudolph in explanation of the results described in <ref> [Karlin et al. 88] </ref>. 9 a single superpage. If m R, then both the online and o*ine policies pay for m TLB misses.
Reference: [Karlin et al. 91] <author> Karlin, A. R., Li, K., Manasse, M., and Owicki, S. </author> <title> Empirical Studies of Competitive Spinning for Shared Memory Multiprocessors. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating System Principles, </booktitle> <year> 1991. </year>
Reference-contexts: Aspects of our online policies can be traced to theoretical work in competitive algorithms. Competitive algorithms make online decisions that result in performance within a constant factor of an optimal o*ine algorithm. Prior research in this area has influenced, for example, the design of synchronization <ref> [Karlin et al. 91] </ref>, paging [Sleator & Tarjan 85], and cache management algorithms [Cao et al. 94]. 4 The impact of page size on application performance In this section we describe the effect that page size has on system performance and motivate the use of variable-sized superpages to improve performance.
Reference: [Khalidi et al. 93] <author> Khalidi, Y. A., Talluri, M., Nelson, M., and Williams, D. </author> <title> Virtual Memory Support for Multiple Page Sizes. </title> <booktitle> In Proceedings of the Fourth Workshop on Workstation Operating Systems, </booktitle> <pages> pages 104-109, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: recent results indicate that use of the virtual memory system to detect application-level accesses can be less efficient than strategies that rely on the compiler [Hosking & Moss 93, Zekaukas et al. 94]. 3 Related Work Chen et al. [Chen et al. 92], Mogul [Mogul 93], and Khalidi et al. <ref> [Khalidi et al. 93] </ref> have described the potential positive impact of a system that supports superpages, although they do not describe policies for promotion or demotion.
Reference: [Mogul 93] <author> Mogul, J. </author> <title> Big Memories on the Desktop. </title> <booktitle> In Proceedings of the Fourth Workshop on Workstation Operating Systems, </booktitle> <pages> pages 110-115, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: However, recent results indicate that use of the virtual memory system to detect application-level accesses can be less efficient than strategies that rely on the compiler [Hosking & Moss 93, Zekaukas et al. 94]. 3 Related Work Chen et al. [Chen et al. 92], Mogul <ref> [Mogul 93] </ref>, and Khalidi et al. [Khalidi et al. 93] have described the potential positive impact of a system that supports superpages, although they do not describe policies for promotion or demotion.
Reference: [Rashid et al. 87] <author> Rashid, R., Avadis Tevanian, J., Young, M., Golub, D., Baron, R., Black, D., Bolosky, W., and Chew, J. </author> <title> Machine-Independent Virtual Memory Management for Paged Uniprocessor and Multiprocessor Architectures. </title> <booktitle> In Proceedings of the 2nd International Conference On Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 31-39, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: With super-pages, though, this assumption can be violated, potentially complicating all clients of the virtual memory system [Talluri & Hill 94]. This complexity can be eliminated by concealing superpage management entirely within the machine-dependent layer of the operating system's virtual memory system (MD-VM) <ref> [Rashid et al. 87] </ref>. The MD-VM layer continues to export to the rest of the operating system an interface to virtual memory pages faithful to the base page size. This approach has the advantage of isolating the majority of the system from the nuances of superpage management.
Reference: [Sleator & Tarjan 85] <author> Sleator, D. D. and Tarjan, R. E. </author> <title> Amortized Efficiency of List Update and Paging Rules. </title> <journal> Communications of the ACM, </journal> <volume> 28 </volume> <pages> 202-208, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: Competitive algorithms make online decisions that result in performance within a constant factor of an optimal o*ine algorithm. Prior research in this area has influenced, for example, the design of synchronization [Karlin et al. 91], paging <ref> [Sleator & Tarjan 85] </ref>, and cache management algorithms [Cao et al. 94]. 4 The impact of page size on application performance In this section we describe the effect that page size has on system performance and motivate the use of variable-sized superpages to improve performance.
Reference: [Srivastava & Eustace 94] <author> Srivastava, A. and Eustace, A. </author> <title> Atom: A system for building customized program analysis tools. </title> <booktitle> In Proceedings of the 1994 ACM Symposium on Programming Languages Design and Implementation (PLDI). ACM, </booktitle> <year> 1994. </year>
Reference-contexts: As we reveal in this section, and demonstrate in those following, superpages offer the best of both worlds. 4.1 Methodology We rely on trace-driven simulation of a collection of benchmarks, described in Table 1, to determine system behavior. We use ATOM, a binary rewriting tool from DEC WRL <ref> [Srivastava & Eustace 94] </ref>, to perform on-the-fly TLB simulation of the applications. We simulate the performance of the programs running on a system with separate fully-associative TLBs for instructions and data. Each TLB has 32 entries and uses an LRU replacement policy.
Reference: [Talluri & Hill 94] <author> Talluri, M. and Hill, M. D. </author> <title> Surpassing the TLB Performance of Superpages with Less Operating System Support. </title> <booktitle> In Proceedings of the 6th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VI), </booktitle> <pages> pages 171-182, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: With super-pages, though, this assumption can be violated, potentially complicating all clients of the virtual memory system <ref> [Talluri & Hill 94] </ref>. This complexity can be eliminated by concealing superpage management entirely within the machine-dependent layer of the operating system's virtual memory system (MD-VM) [Rashid et al. 87]. <p> Instead, they suggest that the programmer or compiler offer the operating system a hint about the appropriate page size for a particular range of memory. Talluri and Hill <ref> [Talluri & Hill 94] </ref> present a simple policy for page promotion in a system that supports two page sizes: 4KB and 64KB. They are primarily concerned with minimizing the software complexity of superpage management, and propose hardware that allows the operating system to declare invalid subpages within a superpage.
Reference: [Talluri et al. 92] <author> Talluri, M., Kong, S., Hill, M. D., and Patterson, D. </author> <title> Tradeoffs in Supporting Two Page Sizes. </title> <booktitle> In Proceedings of the 19th Annual Symposium on Computer Architecture, </booktitle> <pages> pages 415-424, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: For example, the TLB overhead for gcc is low even with small pages, indicating that a large fixed page size for that application would consume an excessive amount of memory. These observations are in line with those made by others <ref> [Talluri et al. 92] </ref>. handling TLB misses as the page size increases. The TLB has 32 instruction entries and 32 data entries, and maps fixed size pages. As the page size increases, TLB coverage increases, and the number of TLB misses falls. <p> Once at least half of the pages in a potential superpage of size 64KB have been referenced, ASAP-4-64 directly promotes those pages. We include ASAP because its simplicity offers a plausible alternative to the more sophisticated policies. In addition, ASAP-4-64 has been the policy used in other studies <ref> [Talluri et al. 92] </ref>. 7 Performance In this section we describe the performance of the policies described above. We first discuss the space and time overhead of our bookkeeping strategy.
Reference: [Young et al. 87] <author> Young, M., Tevanian, A., Rashid, R., Golub, D., Eppinger, J., Chew, J., Bolosky, W., Black, D., and Baron, R. </author> <title> The Duality of Memory and Communication in the Implementation of a Multiprocessor Operating System. </title> <booktitle> In Proceedings of the Eleventh ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 63-76, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: For simplicity, we assume a software managed TLB, although our accounting strategy could be implemented in hardware. 2.2 Software Many operating systems mechanisms, such as the file system's buffer cache, copy-on-write virtual memory <ref> [Young et al. 87] </ref>, and LRU-clock [Babaoglu & Joy 81] assume pages are of a fixed size. With super-pages, though, this assumption can be violated, potentially complicating all clients of the virtual memory system [Talluri & Hill 94].
Reference: [Zekaukas et al. 94] <author> Zekaukas, M., Sawdon, W., and Bershad, B. </author> <title> Software Write Detection for Distributed Shared Memory. </title> <booktitle> In Proceedings of the 1st USENIX Symposium on Operating System Design and Implementation (OSDI-I), </booktitle> <pages> pages 87-100, </pages> <month> November </month> <year> 1994. </year> <month> 18 </month>
Reference-contexts: As a result, superpages may not be appropriate for applications that rely on such functions. However, recent results indicate that use of the virtual memory system to detect application-level accesses can be less efficient than strategies that rely on the compiler <ref> [Hosking & Moss 93, Zekaukas et al. 94] </ref>. 3 Related Work Chen et al. [Chen et al. 92], Mogul [Mogul 93], and Khalidi et al. [Khalidi et al. 93] have described the potential positive impact of a system that supports superpages, although they do not describe policies for promotion or demotion.
References-found: 21

