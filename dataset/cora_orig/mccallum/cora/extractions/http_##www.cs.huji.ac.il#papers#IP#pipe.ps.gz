URL: http://www.cs.huji.ac.il/papers/IP/pipe.ps.gz
Refering-URL: http://www.cs.huji.ac.il/labs/vision/demos/mosaic/mosaic.html
Root-URL: http://www.cs.huji.ac.il
Email: Contact E-Mail: peleg@cs.huji.ac.il  E-Mail: pe leg@cs.huji.ac.il  
Title: Universal Mosaicing Using Pipe Projection pipe projection enables to define high-quality mosaicing even for the
Author: Benny Rousso Shmuel Peleg Ilan Finci Alex Rav-Acha 
Address: 91904 Jerusalem, ISRAEL  
Affiliation: Institute of Computer Science The Hebrew University of Jerusalem  
Note: Accepted to ICCV'98 1  The  This research was partially funded by DARPA through ARL Contract DAAL01-97-0101 and by the European ACTS project AC074 "Vanguard". Contact  
Abstract: Video mosaicing is commonly used to increase the visual field of view by pasting together many video frames. Existing mosaicing methods are effective only in very limited cases where the image motion is almost a uniform translation or the camera performs a pure pan. Forward camera motion or camera zoom are very problematic for traditional mosaicing. A mosaicing methodology to allow image mosaicing in the most general cases is presented, where frames in the video sequence are transformed such that the optical flow becomes parallel. This transformation is an oblique projection of the image into a viewing pipe whose central axis is the trajectory of the camera. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P.J. Burt and E.H. Adelson. </author> <title> A multiresolution spline with application to image mosaics. </title> <journal> ACM Trans. on Graphics, </journal> <volume> 2(4) </volume> <pages> 217-236, </pages> <month> October </month> <year> 1983. </year>
Reference-contexts: A more common solution is photo-mosaicing: aligning, and pasting, frames in a video sequence, which enables a more complete view. Digital photography enabled new implementations for mosaicing <ref> [13, 14, 15, 1, 20, 19] </ref>, which were first applied to aerial and satellite images, and later used for scene and object representation. The simplest mosaics are created from a set of images whose mutual displacements are pure image-plane translations. This is approximately the case with some satellite images.
Reference: [2] <author> P.J. Burt and P. Anandan. </author> <title> Image stabilization by registration to a reference mosaic. </title> <booktitle> In ARPA Image Understanding Workshop, </booktitle> <pages> pages 457-465, </pages> <address> Monterey, California, November 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: But the limitations to motion which is a pure rotation about the optical center limits the applicability of this approach. In more general camera motions, that may include both camera translations and small camera rotations, more general transformation for image alignment are used <ref> [2, 5, 9, 17, 7] </ref>. In all cases images are aligned pairwise, using a parametric transformation like an affine transformation or planar-projective transformation. A reference frame is selected, and all images are aligned with this reference frame and combined to create the panoramic mosaic.
Reference: [3] <author> S.E. Chen and L. Williams. </author> <title> View interpolation for image synthesis. </title> <booktitle> In SIGGRAPH, </booktitle> <pages> pages 279-288, </pages> <address> Anahiem, California, </address> <month> August </month> <year> 1993. </year> <note> ACM. </note>
Reference-contexts: For example, we can take a collection of N strips, each with a width of one pixel, from interpolated camera views in between the original camera positions. In order to synthesize new views we can use various methods, such as optical flow interpolation <ref> [3, 18] </ref>, trilinear tensor methods [16], and others. In most cases approximate methods will give good results.
Reference: [4] <author> T.R. Halfhill. </author> <title> See you around. </title> <journal> Byte Magazine, </journal> <pages> pages 85-90, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Such translations can either be computed by manually pointing to corresponding points, or by image correlation methods. Other simple mosaics are created by rotating the camera around its optical center using a special device, and creating a panoramic image which represents the projection of the scene onto a cylinder <ref> [4, 12, 11, 10] </ref>. But the limitations to motion which is a pure rotation about the optical center limits the applicability of this approach.
Reference: [5] <author> M. Hansen, P. Anandan, K. Dana, G. van der Wal, and P.J. Burt. </author> <title> Real-time scene stabilization and mosaic construction. </title> <booktitle> In ARPA Image Understanding Workshop, </booktitle> <pages> pages 457-465, </pages> <address> Monterey, California, November 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: But the limitations to motion which is a pure rotation about the optical center limits the applicability of this approach. In more general camera motions, that may include both camera translations and small camera rotations, more general transformation for image alignment are used <ref> [2, 5, 9, 17, 7] </ref>. In all cases images are aligned pairwise, using a parametric transformation like an affine transformation or planar-projective transformation. A reference frame is selected, and all images are aligned with this reference frame and combined to create the panoramic mosaic.
Reference: [6] <author> R. Hartley and R. Gupta. </author> <title> Linear pushbroom cameras. </title> <editor> In J.O. Eklundh, editor, </editor> <booktitle> Third European Conference on Computer Vision, </booktitle> <pages> pages 555-566, </pages> <address> Stockholm, Sweden, May 1994. </address> <publisher> Springer. </publisher>
Reference-contexts: The strip collection process allows the introduction of a mechanism to overcome the effects of parallax by generating dense intermediate views. In some cases mosaics generated in this manner can be considered as linear push-broom cameras <ref> [6] </ref>.
Reference: [7] <author> M. Irani, P. Anandan, and S. Hsu. </author> <title> Mosaic based representations of video sequences and their applications. </title> <booktitle> In Fifth International Conference on Computer Vision, </booktitle> <pages> pages 605-611, </pages> <address> Cambridge, MA, </address> <month> June </month> <year> 1995. </year> <pages> IEEE-CS. </pages>
Reference-contexts: But the limitations to motion which is a pure rotation about the optical center limits the applicability of this approach. In more general camera motions, that may include both camera translations and small camera rotations, more general transformation for image alignment are used <ref> [2, 5, 9, 17, 7] </ref>. In all cases images are aligned pairwise, using a parametric transformation like an affine transformation or planar-projective transformation. A reference frame is selected, and all images are aligned with this reference frame and combined to create the panoramic mosaic.
Reference: [8] <author> M. Irani, B. Rousso, and S. Peleg. </author> <title> Detecting and tracking multiple moving objects using temporal integration. </title> <editor> In G. Sandini, editor, </editor> <booktitle> Second European Conference on Computer Vision, </booktitle> <pages> pages 282-287, </pages> <address> Santa Margherita, Italy, May 1992. </address> <publisher> Springer. </publisher>
Reference-contexts: Numerous methods exist to recover the parameters of an affine transformation <ref> [8, 17] </ref>.
Reference: [9] <author> P. Jaillon and A. Montanvert. </author> <title> Image mosaicking applied to three-dimensional surfaces. </title> <booktitle> In 12th International Conference on Pattern Recognition, </booktitle> <pages> pages 253-257, </pages> <address> Jerusalem, Israel, </address> <month> October </month> <year> 1994. </year> <title> IEEE-CS. 19 a c (a) Two original images. (b) Mosaicing without view interpolation. Distant objects are duplicated, and close objects are truncated. (c) Using view interpolation reduces the distortions. </title> <type> 20 </type>
Reference-contexts: But the limitations to motion which is a pure rotation about the optical center limits the applicability of this approach. In more general camera motions, that may include both camera translations and small camera rotations, more general transformation for image alignment are used <ref> [2, 5, 9, 17, 7] </ref>. In all cases images are aligned pairwise, using a parametric transformation like an affine transformation or planar-projective transformation. A reference frame is selected, and all images are aligned with this reference frame and combined to create the panoramic mosaic.
Reference: [10] <author> A. Krishnan and N. Ahuja. </author> <title> Panoramic image acquisition. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 379-384, </pages> <address> San Fransisco, California, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: Such translations can either be computed by manually pointing to corresponding points, or by image correlation methods. Other simple mosaics are created by rotating the camera around its optical center using a special device, and creating a panoramic image which represents the projection of the scene onto a cylinder <ref> [4, 12, 11, 10] </ref>. But the limitations to motion which is a pure rotation about the optical center limits the applicability of this approach.
Reference: [11] <author> S. Mann and R. </author> <title> Picard. Virtual bellows: Constructing high quality stills from video. </title> <booktitle> In First IEEE International Conference on Image Processing, </booktitle> <address> Austin, Texas, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: Such translations can either be computed by manually pointing to corresponding points, or by image correlation methods. Other simple mosaics are created by rotating the camera around its optical center using a special device, and creating a panoramic image which represents the projection of the scene onto a cylinder <ref> [4, 12, 11, 10] </ref>. But the limitations to motion which is a pure rotation about the optical center limits the applicability of this approach.
Reference: [12] <author> L. McMillan and G. Bishop. </author> <title> Plenoptic modeling: An image-based rendering system. </title> <booktitle> In SIGGRAPH, </booktitle> <address> Los Angeles, California, </address> <month> August </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: Such translations can either be computed by manually pointing to corresponding points, or by image correlation methods. Other simple mosaics are created by rotating the camera around its optical center using a special device, and creating a panoramic image which represents the projection of the scene onto a cylinder <ref> [4, 12, 11, 10] </ref>. But the limitations to motion which is a pure rotation about the optical center limits the applicability of this approach.
Reference: [13] <author> D.L. Milgram. </author> <title> Computer methods for creating photomosaics. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-24:1113-1119, </volume> <year> 1975. </year>
Reference-contexts: A more common solution is photo-mosaicing: aligning, and pasting, frames in a video sequence, which enables a more complete view. Digital photography enabled new implementations for mosaicing <ref> [13, 14, 15, 1, 20, 19] </ref>, which were first applied to aerial and satellite images, and later used for scene and object representation. The simplest mosaics are created from a set of images whose mutual displacements are pure image-plane translations. This is approximately the case with some satellite images.
Reference: [14] <author> D.L. Milgram. </author> <title> Adaptive techniques for photomosaicking. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-26:1175-1180, </volume> <year> 1977. </year>
Reference-contexts: A more common solution is photo-mosaicing: aligning, and pasting, frames in a video sequence, which enables a more complete view. Digital photography enabled new implementations for mosaicing <ref> [13, 14, 15, 1, 20, 19] </ref>, which were first applied to aerial and satellite images, and later used for scene and object representation. The simplest mosaics are created from a set of images whose mutual displacements are pure image-plane translations. This is approximately the case with some satellite images.
Reference: [15] <author> S. Peleg. </author> <title> Elimination of seams from photomosaics. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 16 </volume> <pages> 90-94, </pages> <month> May </month> <year> 1981. </year>
Reference-contexts: A more common solution is photo-mosaicing: aligning, and pasting, frames in a video sequence, which enables a more complete view. Digital photography enabled new implementations for mosaicing <ref> [13, 14, 15, 1, 20, 19] </ref>, which were first applied to aerial and satellite images, and later used for scene and object representation. The simplest mosaics are created from a set of images whose mutual displacements are pure image-plane translations. This is approximately the case with some satellite images.
Reference: [16] <author> B. Rousso, S. Avidan, A. Shashua, and S. Peleg. </author> <title> Robust recovery of camera rotation from three frames. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 796-802, </pages> <address> San Fransisco, Califor-nia, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: In general camera motion, the optical flow is induced by camera translation and by camera rotation. The rotational part can be recovered and compensated for if needed, as it does not depend on the structure of the scene (see, for example, <ref> [16] </ref>). The translation (and zoom) induce radial optical flow which emerges from the FOE (Focus Of Expansion), except for the singular case of sideways translation in which the optical flow is parallel. <p> For example, we can take a collection of N strips, each with a width of one pixel, from interpolated camera views in between the original camera positions. In order to synthesize new views we can use various methods, such as optical flow interpolation [3, 18], trilinear tensor methods <ref> [16] </ref>, and others. In most cases approximate methods will give good results.
Reference: [17] <author> H.S. Sawhney, S. Ayer, and M. Gorkani. </author> <title> Model-based 2D & 3D dominant motion estimation for mosaicing and video representation. </title> <booktitle> In Fifth International Conference on Computer Vision, </booktitle> <pages> pages 583-590, </pages> <address> Cam-bridge, MA, </address> <month> June </month> <year> 1995. </year> <pages> IEEE-CS. </pages>
Reference-contexts: But the limitations to motion which is a pure rotation about the optical center limits the applicability of this approach. In more general camera motions, that may include both camera translations and small camera rotations, more general transformation for image alignment are used <ref> [2, 5, 9, 17, 7] </ref>. In all cases images are aligned pairwise, using a parametric transformation like an affine transformation or planar-projective transformation. A reference frame is selected, and all images are aligned with this reference frame and combined to create the panoramic mosaic. <p> Numerous methods exist to recover the parameters of an affine transformation <ref> [8, 17] </ref>.
Reference: [18] <author> S. Seitz and C. Dyer. </author> <title> Physically valid view synthesis by image interpolation. </title> <booktitle> In Proc. IEEE Workshop on Representation of Visual Scenes, </booktitle> <address> Cambridge, MA, </address> <month> June </month> <year> 1995. </year> <pages> IEEE-CS. </pages>
Reference-contexts: For example, we can take a collection of N strips, each with a width of one pixel, from interpolated camera views in between the original camera positions. In order to synthesize new views we can use various methods, such as optical flow interpolation <ref> [3, 18] </ref>, trilinear tensor methods [16], and others. In most cases approximate methods will give good results.
Reference: [19] <author> R. Szeliski. </author> <title> Video mosaics for virtual environments. </title> <journal> IEEE Computer Graphics and Applications, </journal> <pages> pages 22-30, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: A more common solution is photo-mosaicing: aligning, and pasting, frames in a video sequence, which enables a more complete view. Digital photography enabled new implementations for mosaicing <ref> [13, 14, 15, 1, 20, 19] </ref>, which were first applied to aerial and satellite images, and later used for scene and object representation. The simplest mosaics are created from a set of images whose mutual displacements are pure image-plane translations. This is approximately the case with some satellite images.
Reference: [20] <author> R. Szeliski and S.B. Kang. </author> <title> Direct methods for visual scene reconstruction. </title> <booktitle> In Proc. IEEE Workshop on Representation of Visual Scenes, </booktitle> <pages> pages 26-33, </pages> <address> Cambridge, MA, </address> <month> June </month> <year> 1995. </year> <note> IEEE-CS. 21 </note>
Reference-contexts: A more common solution is photo-mosaicing: aligning, and pasting, frames in a video sequence, which enables a more complete view. Digital photography enabled new implementations for mosaicing <ref> [13, 14, 15, 1, 20, 19] </ref>, which were first applied to aerial and satellite images, and later used for scene and object representation. The simplest mosaics are created from a set of images whose mutual displacements are pure image-plane translations. This is approximately the case with some satellite images.
References-found: 20

