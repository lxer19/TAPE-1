URL: http://www.cc.gatech.edu/faculty/ashwin/papers/git-cc-92-02.ps.Z
Refering-URL: http://www.cs.gatech.edu/faculty/ashwin/ABSTRACTS-summary.html
Root-URL: 
Email: E-mail: ashwin@cc.gatech.edu  
Phone: (404) 853-9372  
Title: A theory of questions and question asking  
Author: Ashwin Ram 
Note: The Journal of the Learning Sciences, 1(3&4):273-318, 1991.  
Address: Atlanta, Georgia 30332-0280  
Affiliation: College of Computing Georgia Institute of Technology  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [Alterman, 1985] <author> R. Alterman. </author> <title> A Dictionary Based on Concept Coherence. </title> <journal> Artificial Intelligence, </journal> <volume> 25:153 186, </volume> <year> 1985. </year>
Reference-contexts: At some level, of course, the task of the understanding process is to integrate the components of the text with the relevant components of the understander's memory into a coherent whole, given some suitable definition of coherence, for example, "event concept coherence" <ref> [Alterman, 1985] </ref>. However, in an active reader, this integration is directed by the goals, or questions, of the system. Questions, then, should be used to focus attention on those aspects of the story that would allow the understander to learn something of interest to its needs.
Reference: [Birnbaum and Collins, 1984] <author> L. Birnbaum and G. Collins. </author> <title> Opportunistic Planning and Freudian Slips. </title> <booktitle> In Proceedings of the Sixth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 124-127, </pages> <address> Boulder, CO, </address> <year> 1984. </year> <institution> Institute of Cognitive Science and University of Colorado, Boulder. </institution>
Reference: [Birnbaum, 1986] <author> L. Birnbaum. </author> <title> Integrated Processing in Planning and Understanding. </title> <type> Ph.D. thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, CT, </address> <month> December </month> <year> 1986. </year> <note> Research Report #489. </note>
Reference: [Cullingford, 1978] <author> R. Cullingford. </author> <title> Script Application: Computer Understanding of Newspaper Stories. </title> <type> Ph.D. thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, CT, </address> <year> 1978. </year> <note> Research Report #116. </note>
Reference-contexts: I consider these situations in turn. 12 3.2 Knowledge structures are not perfect Conventional script, frame or schema-based theories assume that understanding means finding an appropriate script, frame or schema 3 in memory and fitting it to the story (e.g., <ref> [Cullingford, 1978; DeJong, 1979] </ref>). Schemas in memory are assumed to be "correct" in the sense that they are completely understood and constitute a correct model of the domain.
Reference: [Dehn, 1989] <author> N. Dehn. </author> <title> Computer Story Writing: The Role of Reconstructive and Dynamic Memory. </title> <type> Ph.D. thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, CT, </address> <year> 1989. </year> <note> Research Report #792. </note>
Reference: [DeJong, 1979] <author> G. F. DeJong. </author> <title> Prediction and Substantiation: A New Approach to Natural Language Un derstanding. </title> <journal> Cognitive Science, </journal> <volume> 3 </volume> <pages> 251-273, </pages> <year> 1979. </year>
Reference-contexts: I consider these situations in turn. 12 3.2 Knowledge structures are not perfect Conventional script, frame or schema-based theories assume that understanding means finding an appropriate script, frame or schema 3 in memory and fitting it to the story (e.g., <ref> [Cullingford, 1978; DeJong, 1979] </ref>). Schemas in memory are assumed to be "correct" in the sense that they are completely understood and constitute a correct model of the domain. <p> Typical story understanding systems are usually designed either to read stories in depth (e.g., BORIS [Dyer, 1982; Lehnert et al., 1983]) or to skim stories (e.g., FRUMP <ref> [DeJong, 1979] </ref>). However, these systems cannot decide the depth to which the story should be processed or which inferences should be drawn during the understanding process because they do not maintain an explicit model of their learning goals.
Reference: [DeJong, 1983] <author> G. F. DeJong. </author> <title> An Approach to Learning from Observation. </title> <editor> In R. S. Michalski, editor, </editor> <booktitle> Proceedings of the 1983 International Machine Learning Workshop, </booktitle> <pages> pages 171-176, </pages> <address> Monticello, IL, </address> <month> June </month> <year> 1983. </year> <institution> Department of Computer Science, University of Illinois, Urbana-Champaign. </institution>
Reference: [Dyer, 1982] <author> M. G. Dyer. </author> <title> In-Depth Understanding: A Computer Model of Integrated Processing for Narrative Comprehension. </title> <type> Ph.D. thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, CT, </address> <month> May </month> <year> 1982. </year> <note> Research Report #116. </note>
Reference-contexts: There is a static notion of what it means to "understand" a story, usually defined in terms of coherence relationships at some arbitrary level of detail. Typical story understanding systems are usually designed either to read stories in depth (e.g., BORIS <ref> [Dyer, 1982; Lehnert et al., 1983] </ref>) or to skim stories (e.g., FRUMP [DeJong, 1979]). However, these systems cannot decide the depth to which the story should be processed or which inferences should be drawn during the understanding process because they do not maintain an explicit model of their learning goals.
Reference: [Hammond, 1988] <author> K. J. Hammond. </author> <title> Opportunistic Memory: </title> <editor> Storing and Recalling Suspended Goals. In J. L. Kolodner, editor, </editor> <booktitle> Proceedings of a Workshop on Case-Based Reasoning, </booktitle> <pages> pages 154-168, </pages> <address> Clearwater Beach, FL, May 1988. </address> <publisher> Morgan Kaufmann, Inc., </publisher> <address> San Mateo, CA. </address>
Reference: [Hayes-Roth and Hayes-Roth, 1979] <author> B. Hayes-Roth and F. Hayes-Roth. </author> <title> A Cognitive Model of Planning. </title> <journal> Cognitive Science, </journal> <volume> 2 </volume> <pages> 275-310, </pages> <year> 1979. </year>
Reference: [Hayes-Roth and Lesser, 1976] <author> F. Hayes-Roth and V. Lesser. </author> <title> Focus of attention in a distributed logic speech understanding system. </title> <booktitle> In Proceedings of the IEEE International Conference on Accoustics, Speech and Signal Processing, </booktitle> <pages> pages 416-420, </pages> <address> Philadephia, PA, April 1976. </address> <publisher> IEEE, </publisher> <address> New York, NY. </address>
Reference: [Hunter, 1989] <author> L. E. Hunter. </author> <title> Knowledge Acquisition Planning: Gaining Expertise Through Experience. </title> <type> Ph.D. thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, CT, </address> <month> January </month> <year> 1989. </year> <note> Research Report #678. </note>
Reference: [Hunter, 1990] <author> L. E. Hunter. </author> <title> Knowledge Acquisition Planning for Inference from Large Datasets. </title> <editor> In B. D. Shriver, editor, </editor> <booktitle> Proceedings of the Twenty Third Annual Hawaii International Conference on System Sciences, </booktitle> <pages> pages 35-45, </pages> <address> Kona, HI, 1990. </address> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA. </address>
Reference-contexts: In AQUA, each anomaly in a story, along with the corresponding set of explanatory hypotheses, can be used as a case. 11 1989] and for scientific discovery in molecular biology <ref> [Hunter, 1990] </ref>. In addition to modelling reasoning tasks, my theory can also help in the design of educational environments. For example, Scardamalia and Bereiter [1991] examine concrete issues that have arisen from their attempts to implement a particular innovative educational environment.
Reference: [Kass et al., 1986] <author> A. Kass, D. Leake, and C. Owens. SWALE: </author> <title> A Program That Explains, </title> <address> pages 232-254. </address> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1986. </year>
Reference-contexts: First, a content theory of volitional explanations for motivational analysis is proposed. Second, a graph-based representation of the structure of explanation patterns is introduced. Third, the process of case-based explanation, while similar to that used by the SWALE program <ref> [Kass et al., 1986] </ref>, is formulated in a question-based framework. My emphasis is on the questions that underly the creation, verification, and learning of explanations, and not on the creative adaptation process described in Kass, Leake and Owens [1986].
Reference: [Kintsch, 1988] <author> W. Kintsch. </author> <title> The Role of Knowledge in Discourse Comprehension: A Construction Integration Model. </title> <journal> Psychological Review, </journal> <volume> 95(2) </volume> <pages> 163-182, </pages> <year> 1988. </year> <month> 29 </month>
Reference: [Kolodner, 1984] <author> J. L. Kolodner. </author> <title> Retrieval and Organizational Strategies in Conceptual Memory: A Com puter Model. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1984. </year>
Reference-contexts: Thus, questions, with suspended understanding tasks that gave rise to them, must be indexed in memory. AQUA's memory model is based on the theory of dynamic memory <ref> [Kolodner, 1984; Lebowitz, 1983; Schank, 1982] </ref>. Rather than build an independent representation, which then has to be integrated into memory and related to previous episodes as a separate stage in the understanding process, an understander parses text directly into memory and relates it to its questions. <p> The underlying memory model is based on the theory of dynamic memory [Schank, 1982], such as that used by IPP [Lebowitz, 1983] or CYRUS <ref> [Kolodner, 1984] </ref>. In addition to MOP-based episodic structures similar to these programs, AQUA's memory contains XPs indexed by situation, character stereotype, and anomaly category indices. The memory also contains questions indexed with the concepts in memory, each with its own reason for being asked.
Reference: [Lebowitz, 1983] <author> M. Lebowitz. </author> <title> Generalization from Natural Language Text. </title> <journal> Cognitive Science, </journal> <volume> 7(1) </volume> <pages> 1-40, </pages> <year> 1983. </year>
Reference-contexts: Thus, questions, with suspended understanding tasks that gave rise to them, must be indexed in memory. AQUA's memory model is based on the theory of dynamic memory <ref> [Kolodner, 1984; Lebowitz, 1983; Schank, 1982] </ref>. Rather than build an independent representation, which then has to be integrated into memory and related to previous episodes as a separate stage in the understanding process, an understander parses text directly into memory and relates it to its questions. <p> The underlying memory model is based on the theory of dynamic memory [Schank, 1982], such as that used by IPP <ref> [Lebowitz, 1983] </ref> or CYRUS [Kolodner, 1984]. In addition to MOP-based episodic structures similar to these programs, AQUA's memory contains XPs indexed by situation, character stereotype, and anomaly category indices. The memory also contains questions indexed with the concepts in memory, each with its own reason for being asked.
Reference: [Lehnert et al., 1983] <author> W. G. Lehnert, M. G. Dyer, P. N. Johnson, C. Yang, and S. Harley. </author> <title> BORIS | An Experiment in In-Depth Understanding of Narratives. </title> <journal> Artificial Intelligence, </journal> <volume> 20 </volume> <pages> 15-62, </pages> <year> 1983. </year>
Reference-contexts: There is a static notion of what it means to "understand" a story, usually defined in terms of coherence relationships at some arbitrary level of detail. Typical story understanding systems are usually designed either to read stories in depth (e.g., BORIS <ref> [Dyer, 1982; Lehnert et al., 1983] </ref>) or to skim stories (e.g., FRUMP [DeJong, 1979]). However, these systems cannot decide the depth to which the story should be processed or which inferences should be drawn during the understanding process because they do not maintain an explicit model of their learning goals.
Reference: [Lehnert, 1978] <author> W. G. Lehnert. </author> <title> The Process of Question Answering. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1978. </year>
Reference-contexts: Also presented is a computer program that asks intelligent questions in an attempt to reason and to learn about its domain. Story understanding programs are often designed to answer questions to demonstrate that they have adequately understood a story (e.g., <ref> [Lehnert, 1978] </ref>). In contrast, I claim that asking questions is central to understanding. The underlying theme of this research is the goals of the reasoner and the interaction of these goals with reasoning processes.
Reference: [Lenat and Brown, 1984] <author> D. B. Lenat and J. S. Brown. </author> <title> Why AM and EURISKO appear to work. </title> <journal> Artificial Intelligence, </journal> <volume> 23 </volume> <pages> 269-294, </pages> <year> 1984. </year>
Reference-contexts: Learning, in turn, is viewed an incremental process of both question generation and question answering. I have demonstrated that this model is viable by implementing a computer program, AQUA, whose source of power (to borrow a term from Lenat <ref> [Lenat and Brown, 1984] </ref>) resides in its question-asking capabilities. The learning process in AQUA is incremental and dynamic, involving both goal-driven (top-down or active) and data-driven (bottom-up or opportunistic) processes. AQUA gradually evolves its understanding of a domain through experience with different situations.
Reference: [Ng and Bereiter, 1991] <author> E. Ng and C. Bereiter. </author> <title> Three Levels of Goal Orientation in Learning. </title> <journal> The Journal of the Learning Sciences, </journal> <volume> 1(3), </volume> <year> 1991. </year> <note> To appear. </note>
Reference-contexts: This is supported by the fact that my model is consistent with psychological data on question asking reported by Scardamalia and Bereiter [Scardamalia and Bereiter, 1991]. My goal-based approach is also consistent with psychological data on goal orientation in learning (e.g., <ref> [Ng and Bereiter, 1991] </ref>) and in focus of attention and inferencing (cf. review by Zukier [1986]). I propose the following taxonomy of knowledge goals for story understanding: Text goals: Knowledge goals of a text analysis program, arising from text-level tasks.
Reference: [Ram and Hunter, 1992] <author> A. Ram and L. Hunter. </author> <title> The Use of Explicit Goals for Knowledge to Guide Inference and Learning. </title> <journal> Applied Intelligence, </journal> <note> 1992. To appear. Also available as Technical Report GIT-CC-92/04, </note> <institution> College of Computing, Georgia Institute of Technology, </institution> <address> Atlanta, GA. </address>
Reference-contexts: Any such rule must make a statement about the goals of the program, not just about the content of the domain. A similar argument can be made for the use of knowledge goals, or questions, to focus inference generation for understanding, explanation or diagnosis <ref> [Ram, 1990c; Ram and Hunter, 1992; Ram and Leake, 1991] </ref>. In the following sections, I argue that a goal-based model of learning is a plausible account of human behavior, and has computational advantages for the design of learning programs as well.
Reference: [Ram and Leake, 1991] <author> A. Ram and D. Leake. </author> <title> Evaluation of Explanatory Hypotheses. </title> <booktitle> In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society, </booktitle> <address> Chicago, IL, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: Any such rule must make a statement about the goals of the program, not just about the content of the domain. A similar argument can be made for the use of knowledge goals, or questions, to focus inference generation for understanding, explanation or diagnosis <ref> [Ram, 1990c; Ram and Hunter, 1992; Ram and Leake, 1991] </ref>. In the following sections, I argue that a goal-based model of learning is a plausible account of human behavior, and has computational advantages for the design of learning programs as well.
Reference: [Ram, 1987] <author> A. Ram. </author> <title> AQUA: Asking Questions and Understanding Answers. </title> <booktitle> In Proceedings of the Sixth Annual National Conference on Artificial Intelligence, </booktitle> <pages> pages 312-316, </pages> <address> Seattle, WA, July 1987. </address> <publisher> Morgan Kaufman Publishers, Inc., </publisher> <address> Los Altos, CA. </address>
Reference-contexts: AQUA (Asking Questions and Understanding Answers) is a question-driven story understanding program that learns about terrorism by reading newspaper stories covering unusual terrorist incidents in the Middle East <ref> [Ram, 1987; Ram, 1989; Schank and Ram, 1988] </ref>. AQUA builds causal and motivational explanations for the events in the story in order to understand why the characters acted as they did or why certain events did or did not occur.
Reference: [Ram, 1989] <author> A. Ram. </author> <title> Question-driven understanding: An integrated theory of story understanding, memory and learning. </title> <type> Ph.D. thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, CT, </address> <month> May </month> <year> 1989. </year> <note> Research Report #710. </note>
Reference-contexts: AQUA (Asking Questions and Understanding Answers) is a question-driven story understanding program that learns about terrorism by reading newspaper stories covering unusual terrorist incidents in the Middle East <ref> [Ram, 1987; Ram, 1989; Schank and Ram, 1988] </ref>. AQUA builds causal and motivational explanations for the events in the story in order to understand why the characters acted as they did or why certain events did or did not occur. <p> As the system reads new stories, it is reminded of past cases, and of old explanations. In attempting to apply these explanations to the new situation, it also remembers previously unanswered questions. The system's understanding of its cases gradually gets refined as these questions get answered <ref> [Ram, 1989; Ram, 1990b; Ram, 1992] </ref>. Much of real-world learning is an incremental process of this type. A reasoner learns by modifying what it already knows using pieces of new information that it acquires during its experiences.
Reference: [Ram, 1990a] <author> A. Ram. </author> <title> Decision Models: A Theory of Volitional Explanation. </title> <booktitle> In Proceedings of the Twelvth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 198-205, </pages> <address> Cambridge, MA, July 1990. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: [Ram, 1990b] <author> A. Ram. </author> <title> Incremental Learning of Explanation Patterns and their Indices. </title> <editor> In B. W. Porter and R. J. Mooney, editors, </editor> <booktitle> Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <pages> pages 313-320, </pages> <address> Austin, TX, June 1990. </address> <publisher> Morgan Kaufman Publishers, Inc. </publisher>
Reference-contexts: As the system reads new stories, it is reminded of past cases, and of old explanations. In attempting to apply these explanations to the new situation, it also remembers previously unanswered questions. The system's understanding of its cases gradually gets refined as these questions get answered <ref> [Ram, 1989; Ram, 1990b; Ram, 1992] </ref>. Much of real-world learning is an incremental process of this type. A reasoner learns by modifying what it already knows using pieces of new information that it acquires during its experiences. <p> In addition to asking questions, therefore, AQUA can learn from answers to these questions. As implemented, AQUA improves its explanatory knowledge of its domain by incremental refinement of this knowledge using answers to questions that arise from the explanation process <ref> [Ram, 1990b; Ram, 1992] </ref>. In this section, we describe the underlying model of question-driven text interpretation and explanation that form the basis for the AQUA program. 6 A MOP is a memory structure which contains information about how other memory structures are linked together in frequently occurring combinations.
Reference: [Ram, 1990c] <author> A. Ram. </author> <title> Knowledge Goals: A Theory of Interestingness. </title> <booktitle> In Proceedings of the Twelvth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 206-214, </pages> <address> Cambridge, MA, July 1990. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: Any such rule must make a statement about the goals of the program, not just about the content of the domain. A similar argument can be made for the use of knowledge goals, or questions, to focus inference generation for understanding, explanation or diagnosis <ref> [Ram, 1990c; Ram and Hunter, 1992; Ram and Leake, 1991] </ref>. In the following sections, I argue that a goal-based model of learning is a plausible account of human behavior, and has computational advantages for the design of learning programs as well. <p> XPs have four main components: 7 To improve on this even further, AQUA tries to determine which of its questions are interesting and worth pursuing. This decision is made using a set of interestingness heuristics. Details of these heuristics are beyond the scope of this article (see <ref> [Ram, 1990c] </ref>). For the purposes of this article, we may assume that AQUA pursues all its questions. Even this simplified heuristic is more efficient than pursuing all possible inferences. 18 which then results in an outcome (a collection of states).
Reference: [Ram, 1992] <author> A. Ram. </author> <title> Indexing, Elaboration and Refinement: Incremental Learning of Explanatory Cases. </title> <booktitle> Machine Learning, </booktitle> <year> 1992. </year> <note> To appear. Also available as Technical Report GIT-CC-92/03, </note> <institution> College of Computing, Georgia Institute of Technology, </institution> <address> Atlanta, GA. </address>
Reference-contexts: This leads the reasoner to focus on what he or she needs to know, to formulate questions in acquiring this knowledge, and to learn by pursuing these questions. Rather than presenting details of learning algorithms (see <ref> [Ram, 1992] </ref>), this article is concerned more with the relationship between questions and learning and with the nature of the questions themselves. I discuss the sources of questions, the types of questions arising from different reasoning tasks, the process of generating questions, and the process of learning by answering questions. <p> explanation if that explanation was not detailed enough to deal with the new situation; or it could be used to reorganize or reindex knowledge in memory to allow the reasoner to use what it already knows in novel situations to which that piece of knowledge had not been applied before <ref> [Ram, 1992] </ref>. Each type of learning leaves the system a little closer to a complete understanding of its domain. <p> As the system reads new stories, it is reminded of past cases, and of old explanations. In attempting to apply these explanations to the new situation, it also remembers previously unanswered questions. The system's understanding of its cases gradually gets refined as these questions get answered <ref> [Ram, 1989; Ram, 1990b; Ram, 1992] </ref>. Much of real-world learning is an incremental process of this type. A reasoner learns by modifying what it already knows using pieces of new information that it acquires during its experiences. <p> In addition to asking questions, therefore, AQUA can learn from answers to these questions. As implemented, AQUA improves its explanatory knowledge of its domain by incremental refinement of this knowledge using answers to questions that arise from the explanation process <ref> [Ram, 1990b; Ram, 1992] </ref>. In this section, we describe the underlying model of question-driven text interpretation and explanation that form the basis for the AQUA program. 6 A MOP is a memory structure which contains information about how other memory structures are linked together in frequently occurring combinations.
Reference: [Scardamalia and Bereiter, 1991] <author> M. Scardamalia and C. Bereiter. </author> <title> Higher Levels of Agency for Children in Knowledge Building: A Challenge for the Design of New Knowledge Media. </title> <journal> The Journal of the Learning Sciences, </journal> <volume> 1(1) </volume> <pages> 37-68, </pages> <year> 1991. </year>
Reference-contexts: The basic process in AQUA is one of question transformation (figure 4). The questions that AQUA asks, and the hypotheses that it formulates, change as it reads. As AQUA learns more about the domain, it asks better and more detailed questions, both "basic information questions" and "wonderment questions" <ref> [Scardamalia and Bereiter, 1991] </ref>. AQUA also gets "bored" if a story does not raise any new questions that it finds interesting by virtue of its interestingness criteria. Curiosity and interest are fundamental components of human learning; AQUA's question transformation process is an attempt to model this kind of learning. <p> Thus, I hypothesize that my theory, although intended as a computational model of an active reader, is also a plausible cognitive model. This is supported by the fact that my model is consistent with psychological data on question asking reported by Scardamalia and Bereiter <ref> [Scardamalia and Bereiter, 1991] </ref>. My goal-based approach is also consistent with psychological data on goal orientation in learning (e.g., [Ng and Bereiter, 1991]) and in focus of attention and inferencing (cf. review by Zukier [1986]).
Reference: [Schank and Ram, 1988] <author> R. C. Schank and A. Ram. </author> <title> Question-driven Parsing: A New Approach to Natural Language Understanding. </title> <journal> Journal of Japanese Society for Artificial Intelligence, </journal> <volume> 3(3) </volume> <pages> 260-270, </pages> <month> May </month> <year> 1988. </year> <month> 30 </month>
Reference-contexts: AQUA (Asking Questions and Understanding Answers) is a question-driven story understanding program that learns about terrorism by reading newspaper stories covering unusual terrorist incidents in the Middle East <ref> [Ram, 1987; Ram, 1989; Schank and Ram, 1988] </ref>. AQUA builds causal and motivational explanations for the events in the story in order to understand why the characters acted as they did or why certain events did or did not occur.
Reference: [Schank, 1978] <author> R. C. Schank. </author> <title> Predictive Understanding. </title> <editor> In R. Campbell and P. Smith, editors, </editor> <booktitle> Recent Advances in the Psychology of Language | Formal and Experimental Approaches, </booktitle> <pages> pages 91-101. </pages> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1978. </year>
Reference-contexts: This approach is in contrast to top-down approaches in which language analysis proceeds in a top-down predictive manner, and bottom-up processing is invoked only when expectations fail (e.g., <ref> [Schank, 1978] </ref>). However, these theories do not take into account the learning goals of the understander. There is a static notion of what it means to "understand" a story, usually defined in terms of coherence relationships at some arbitrary level of detail.
Reference: [Schank, 1982] <author> R. C. Schank. </author> <title> Dynamic Memory: A Theory of Learning in Computers and People. </title> <publisher> Cambridge University Press, </publisher> <address> New York, NY, </address> <year> 1982. </year>
Reference-contexts: Thus, questions, with suspended understanding tasks that gave rise to them, must be indexed in memory. AQUA's memory model is based on the theory of dynamic memory <ref> [Kolodner, 1984; Lebowitz, 1983; Schank, 1982] </ref>. Rather than build an independent representation, which then has to be integrated into memory and related to previous episodes as a separate stage in the understanding process, an understander parses text directly into memory and relates it to its questions. <p> MOPs are composed of scenes which describe how and where a particular set of actions take place, which in turn can point to scripts that embody specific aspects of these scenes <ref> [Schank, 1982] </ref>. 16 4.1 Question-driven interpretation of natural language text In my theory, reading is viewed as a "plan" to learn more about the world. The understander's world model grows more complete as it reads a story and relates it to gaps and questions in memory. <p> The underlying memory model is based on the theory of dynamic memory <ref> [Schank, 1982] </ref>, such as that used by IPP [Lebowitz, 1983] or CYRUS [Kolodner, 1984]. In addition to MOP-based episodic structures similar to these programs, AQUA's memory contains XPs indexed by situation, character stereotype, and anomaly category indices.
Reference: [Schank, 1986] <author> R. C. Schank. </author> <title> Explanation Patterns: Understanding Mechanically and Creatively. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1986. </year>
Reference-contexts: Previously encountered explanations are represented as stereotypical patterns of causality, known as explanation patterns (XPs; <ref> [Schank, 1986] </ref>). AQUA builds on Schank's theory of explanation patterns in three ways. First, a content theory of volitional explanations for motivational analysis is proposed. Second, a graph-based representation of the structure of explanation patterns is introduced.
Reference: [Shute et al., 1988] <author> V. Shute, R. Glaser, and K. Raghavan. </author> <title> Inference and Discovery in an Exploratory Laboratory. </title> <type> Technical Report 10, </type> <institution> Learning Research and Development Center, University of Pittsburgh, </institution> <address> Pittsburgh, PA, </address> <month> February </month> <year> 1988. </year>
Reference-contexts: Understanding and problem solving tasks may also be combined (e.g., teaching economics in the context of a market situation <ref> [Shute et al., 1988] </ref>). In this paper, I focus on an analysis of understanding tasks from a point of view of question generation. A similar approach could be used for the analysis for problem solving or design tasks as well.
Reference: [Sperber and Wilson, 1986] <author> D. Sperber and D. Wilson. </author> <title> Relevance: Communication and Cognition. </title> <booktitle> Language and Thought Series. </booktitle> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: These principles make sense because cognitive processes are geared to achieving a large cognitive effect for a small effort. To achieve this, the understander must focus its attention on what seems to it to be the most relevant information available <ref> [Sperber and Wilson, 1986] </ref>. Why would an understander need to find something out in the first place? Ultimately, the point of reading is to learn more about the world. Questions arise when reading a story reveals gaps or inconsistencies in the world model.
Reference: [Vallone et al., 1985] <author> R. P. Vallone, L. Ross, and M. R. Lepper. </author> <title> The Hostile Media Phenomenon: Biased Perception And Perceptions Of Media Bias In Coverage Of The Beirut Massacre. </title> <journal> Journal Of Personality And Social Psychology, </journal> <volume> 49(3) </volume> <pages> 577-585, </pages> <year> 1985. </year>
Reference-contexts: The interaction between the two is complex. For example, there is some evidence that the subjective bias of the reader may cause the reader to perceive biases on the part of the author (e.g., the "hostile media phenomenon" <ref> [Vallone et al., 1985] </ref>).
Reference: [Zeigernik, 1927] <editor> B. Zeigernik. Das Behalten Erledigter und Unerledigter Handlungen. Psychologische Forschungen, </editor> <volume> 9 </volume> <pages> 1-85, </pages> <year> 1927. </year> <note> Reported in Birnbaum [1986]. </note>
Reference: [Zukier, 1986] <author> H. Zukier. </author> <title> The Paradigmatic and Narrative Modes in Goal-Guided Inference. </title> <editor> In R. Sorrentino and E. Higgins, editors, </editor> <booktitle> Handbook of Motivation and Cognition: Foundations of Social Behavior, </booktitle> <pages> pages 465-502. </pages> <publisher> Guilford Press, </publisher> <address> Guilford, CT, </address> <year> 1986. </year> <month> 31 </month>
Reference-contexts: In other words, the understander should use its knowledge goals to focus its attention on the interesting aspects of the story, where "interesting" can be defined as "relating to something the understander wants to find out about." 4 This idea is similar to that of "goal-guided inference" in social cognition <ref> [Zukier, 1986] </ref>, to the 4 Clearly, the author of a story also has control over what the understander finds interesting at any point. There is a tension between the conveyance of the story and the subjective bias of the reader in reading the story (Alterman, personal communication, March 15, 1991).
References-found: 39

