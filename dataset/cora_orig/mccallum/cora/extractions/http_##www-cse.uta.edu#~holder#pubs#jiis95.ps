URL: http://www-cse.uta.edu/~holder/pubs/jiis95.ps
Refering-URL: http://www-cse.uta.edu/~holder/pubs.html
Root-URL: 
Email: Email: cook, holder, djoko@cse.uta.edu  
Title: Knowledge Discovery from Structural Data  
Author: Diane J. Cook, Lawrence B. Holder and Surnjani Djoko 
Keyword: machine discovery, data mining, data compression, inexact graph match, scene anal ysis, chemical analysis  
Note: Supported by NASA grant NAS5-32337.  
Address: Arlington  
Affiliation: Department of Computer Science Engineering University of Texas at  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> H. Bunke and G. Allermann. </author> <title> Inexact graph matching for structural pattern recognition. </title> <journal> Pattern Recognition Letters, </journal> <volume> 1(4) </volume> <pages> 245-253, </pages> <year> 1983. </year>
Reference-contexts: We adopt the approach to inexact graph match given by Bunke and Allermann <ref> [1] </ref>. In this inexact match approach, each distortion of a graph is assigned a cost. A distortion is described in terms of basic transformations such as deletion, insertion, and substitution of vertices and edges.
Reference: [2] <author> P. Cheeseman, J. Kelly, M. Self, J. Stutz, W. Taylor, and D. Freeman. </author> <title> Autoclass: A bayesian classification system. </title> <booktitle> In Proceedings of the Fifth International Workshop on Machine Learning, </booktitle> <pages> pages 54-64, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction The large amount of data collected today is quickly overwhelming researchers' abilities to interpret the data and discover interesting patterns within the data. In response to this problem, a number of researchers have developed techniques for discovering concepts in databases <ref> [2, 5, 15] </ref>. These techniques work well for data expressed in a non-structural, attribute-value representation, and address issues of data relevance, missing data, noise and uncertainty, and utilization of domain knowledge. However, recent data acquisition projects are collecting structural data describing the relationships among the data objects.
Reference: [3] <author> D. Conklin, S. Fortier, J. Glasgow, and F. Allen. </author> <title> Discovery of spatial concepts in crystallographic databases. </title> <booktitle> In Proceedings of the ML92 Workshop on Machine Discovery, </booktitle> <pages> pages 111-116, </pages> <year> 1992. </year>
Reference-contexts: In addition, Subdue is distinct in using the minimum description length principle as a primary evaluation measure and in allowing the use of both domain-independent and domain-dependent heuristics. Conklin et al. <ref> [3] </ref> have developed the i-mem system for constructing an image hierarchy, similar to that of Labyrinth, used for discovering common substructures in a set of images and for efficient retrieval of images similar to a given image. <p> This same view can be constructed by Subdue using multiple passes over the graph after replacing portions of the input graph with substructures discovered during previous passes. i-mem has performed well in a simple chess domain and molecular chemistry domains <ref> [3] </ref>. However, i-mem requires domain-specific relations for expressing images in order for the hierarchy to find relevant substructures and for image matching to be efficient. Again, maintaining the concepts (images, graphs) in a partially-ordered hierarchy improves the efficiency of matching and retrieval, and suggests a possible improvement to Subdue.
Reference: [4] <author> M. Derthick. </author> <title> A minimal encoding approach to feature discovery. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 565-571, </pages> <year> 1991. </year>
Reference-contexts: The MDL principle has been used for decision tree induction [16], image processing [13, 14, 10], concept learning from relational data <ref> [4] </ref>, and learning models of non-homogeneous engineering domains [17]. We demonstrate how the minimum description length principle can be used to discover substructures in complex data. In particular, a substructure is evaluated based on how well it can compress the entire dataset using the minimum description length.
Reference: [5] <author> D. Fisher. </author> <title> Knowledge acquisition via incremental conceptual clustering. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 139-172, </pages> <year> 1987. </year>
Reference-contexts: 1 Introduction The large amount of data collected today is quickly overwhelming researchers' abilities to interpret the data and discover interesting patterns within the data. In response to this problem, a number of researchers have developed techniques for discovering concepts in databases <ref> [2, 5, 15] </ref>. These techniques work well for data expressed in a non-structural, attribute-value representation, and address issues of data relevance, missing data, noise and uncertainty, and utilization of domain knowledge. However, recent data acquisition projects are collecting structural data describing the relationships among the data objects. <p> As with Levinson's approach, graphs are processed incrementally, and substructure is found across several graphs, not within a single graph as in Subdue. The Labyrinth system [22] extends the Cobweb incremental conceptual clustering system <ref> [5] </ref> to handle structured objects. Labyrinth uses Cobweb to form hierarchical concepts of the individual objects in the domain based on their primitive attributes. Concepts of structured objects are formed in a similar manner using the individual objects as attributes.
Reference: [6] <author> K. S. Fu. </author> <title> Syntactic Pattern Recognition and Applications. </title> <publisher> Prentice-Hall, </publisher> <year> 1982. </year>
Reference-contexts: These differences in CLiP suggest possible enhancements to Subdue. Research in pattern recognition has begun to investigate the use of graphs and graph grammars as an underlying representation for structural problems [20]. Many results in grammatical inference are applicable to constrained classes of graphs (e.g., trees) <ref> [6, 12] </ref>. The approach begins with a set of sample graphs and produces a generalized graph grammar capable of deriving the original sample graphs and many others. The production rules of this general grammar capture regularities (substructures) in the sample graphs.
Reference: [7] <author> L. Holder, D. J. Cook, and S. Djoko. </author> <title> Substructure discovery in the subdue system. </title> <booktitle> In Proceedings of the Workshop on Knowledge Discovery in Databases, </booktitle> <pages> pages 169-180, </pages> <year> 1994. </year>
Reference-contexts: This hierarchy provides varying levels of interpretation that can be accessed based on the goals of the data analysis. We introduce a system that discovers interesting substructures in structural data called Subdue <ref> [7] </ref>. The Subdue system discovers substructures that compress that original database and represent interesting structural concepts in the data. By replacing previously-discovered substructures in the data, multiple passes of Subdue produce a hierarchical description of the structural regularities in the data.
Reference: [8] <author> L. B. Holder, D. J. Cook, and H. Bunke. </author> <title> Fuzzy substructure discovery. </title> <booktitle> In Proceedings of the Ninth International Machine Learning Conference, </booktitle> <pages> pages 218-223, </pages> <year> 1992. </year>
Reference-contexts: In the original version of the Subdue system, four domain-independent heuristics were used to evaluate a substructure: cognitive savings, compactness, connectivity and coverage <ref> [8] </ref>. Cognitive savings measures the amount of data compression obtained by describing the original database in terms of the discovered substructure. Complexity represents the size or complexity of the discovered substructure.
Reference: [9] <author> E. Jeltsch and H. J. Kreowski. </author> <title> Grammatical inference based on hyperedge replacement. </title> <booktitle> In Fourth International Workshop on Graph Grammars and Their Application to Computer Science, </booktitle> <pages> pages 461-474, </pages> <year> 1991. </year>
Reference-contexts: The approach begins with a set of sample graphs and produces a generalized graph grammar capable of deriving the original sample graphs and many others. The production rules of this general grammar capture regularities (substructures) in the sample graphs. Jeltsch and Kreowski <ref> [9] </ref> describe an approach that begins with a maximally-specific grammar and iteratively identifies common subgraphs in the right-hand sides of the production rules. These common subgraphs are used to form new, more general production rules.
Reference: [10] <author> Y. G. Leclerc. </author> <title> Constructing simple stable descriptions for image partitioning. </title> <journal> International journal of Computer Vision, </journal> <volume> 3(1) </volume> <pages> 73-102, </pages> <year> 1989. </year>
Reference-contexts: The MDL principle has been used for decision tree induction [16], image processing <ref> [13, 14, 10] </ref>, concept learning from relational data [4], and learning models of non-homogeneous engineering domains [17]. We demonstrate how the minimum description length principle can be used to discover substructures in complex data.
Reference: [11] <author> R. Levinson. </author> <title> A self-organizing retrieval system for graphs. </title> <booktitle> In Proceedings of the Second National Conference on Artificial Intelligence, </booktitle> <pages> pages 203-206, </pages> <year> 1984. </year>
Reference-contexts: For instance, the sequence discovery method looks for supported-by and in-front-of relations only. Subdue's substructure discovery method is domain independent, although the inclusion of domain-specific knowledge would improve Subdue's performance. Motivated by the need to construct a knowledge base of chemical structures, Levinson <ref> [11] </ref> developed a system for storing labeled graphs in which individual graphs are represented by the set of vertices in a universal graph. In addition, the individual graphs are maintained in a partial ordering defined by the subgraph-of relation, which improves the performance of graph comparisons.
Reference: [12] <author> L. Miclet. </author> <title> Structural Methods in Pattern Recognition. </title> <publisher> Chapman and Hall, </publisher> <year> 1986. </year>
Reference-contexts: These differences in CLiP suggest possible enhancements to Subdue. Research in pattern recognition has begun to investigate the use of graphs and graph grammars as an underlying representation for structural problems [20]. Many results in grammatical inference are applicable to constrained classes of graphs (e.g., trees) <ref> [6, 12] </ref>. The approach begins with a set of sample graphs and produces a generalized graph grammar capable of deriving the original sample graphs and many others. The production rules of this general grammar capture regularities (substructures) in the sample graphs.
Reference: [13] <author> E. P. D. Pednault. </author> <title> Some experiments in applying inductive inference principles to surface reconstruction. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1603-1609, </pages> <year> 1989. </year>
Reference-contexts: The MDL principle has been used for decision tree induction [16], image processing <ref> [13, 14, 10] </ref>, concept learning from relational data [4], and learning models of non-homogeneous engineering domains [17]. We demonstrate how the minimum description length principle can be used to discover substructures in complex data.
Reference: [14] <author> A. Pentland. </author> <title> Part segmentation for object recognition. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 82-91, </pages> <year> 1989. </year>
Reference-contexts: The MDL principle has been used for decision tree induction [16], image processing <ref> [13, 14, 10] </ref>, concept learning from relational data [4], and learning models of non-homogeneous engineering domains [17]. We demonstrate how the minimum description length principle can be used to discover substructures in complex data.
Reference: [15] <author> G. Piatetsky-Shapiro. </author> <title> Knowledge Discovery in Databases. </title> <publisher> AAAI Press, </publisher> <year> 1991. </year>
Reference-contexts: 1 Introduction The large amount of data collected today is quickly overwhelming researchers' abilities to interpret the data and discover interesting patterns within the data. In response to this problem, a number of researchers have developed techniques for discovering concepts in databases <ref> [2, 5, 15] </ref>. These techniques work well for data expressed in a non-structural, attribute-value representation, and address issues of data relevance, missing data, noise and uncertainty, and utilization of domain knowledge. However, recent data acquisition projects are collecting structural data describing the relationships among the data objects.
Reference: [16] <author> J. R. Quinlan and R. L. Rivest. </author> <title> Inferring decision trees using the minimum description length principle. </title> <journal> Information and Computation, </journal> <volume> 80 </volume> <pages> 227-248, </pages> <year> 1989. </year>
Reference-contexts: The MDL principle has been used for decision tree induction <ref> [16] </ref>, image processing [13, 14, 10], concept learning from relational data [4], and learning models of non-homogeneous engineering domains [17]. We demonstrate how the minimum description length principle can be used to discover substructures in complex data. <p> Therefore, a typical row in the adjacency matrix will have much fewer than v 1s, where v is the total number of vertices in the graph. We apply a variant of the coding scheme used by <ref> [16] </ref> to encode bit strings with length n consisting of k 1s and (n k) 0s, where k t (n k). In our case, row i (1 i v) can be represented as a bit string of length v containing k i 1s.
Reference: [17] <author> R. B. Rao and S. C. Lu. </author> <title> Learning engineering models with the minimum description length principle. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 717-722, </pages> <year> 1992. </year>
Reference-contexts: The MDL principle has been used for decision tree induction [16], image processing [13, 14, 10], concept learning from relational data [4], and learning models of non-homogeneous engineering domains <ref> [17] </ref>. We demonstrate how the minimum description length principle can be used to discover substructures in complex data. In particular, a substructure is evaluated based on how well it can compress the entire dataset using the minimum description length.
Reference: [18] <author> E. Rich and K. Knight. </author> <booktitle> Artificial Intelligence. </booktitle> <publisher> McGraw-Hill, </publisher> <year> 1991. </year>
Reference-contexts: Vertices are considered for pairings in order from the most heavily connected vertex to the least connected, as this constrains the remaining 10 match. Because branch-and-bound search guarantees that the first solution found is the least-cost solution <ref> [18] </ref>, the search ends as soon as the first complete mapping is found. In the best case, the complexity of the improved inexact graph match is linear in the number of vertices in the larger graph.
Reference: [19] <author> J. Rissanen. </author> <title> Stochastic Complexity in Statistical Inquiry. </title> <publisher> World Scientific Publishing Company, </publisher> <year> 1989. </year>
Reference-contexts: Domain-dependent knowledge can be added to the process to direct the system toward substructures of particular interest in a given domain. 4 Minimum Description Length Encoding of Graphs The minimum description length (MDL) principle introduced by Rissanen <ref> [19] </ref> states that the best theory to describe a set of data is that theory which minimizes the description length of the entire data set.
Reference: [20] <author> R. J. Schalkoff. </author> <title> Pattern Recognition: Statistical, Structural and Neural Approaches. </title> <publisher> John Wiley & Sons, </publisher> <year> 1992. </year>
Reference-contexts: These differences in CLiP suggest possible enhancements to Subdue. Research in pattern recognition has begun to investigate the use of graphs and graph grammars as an underlying representation for structural problems <ref> [20] </ref>. Many results in grammatical inference are applicable to constrained classes of graphs (e.g., trees) [6, 12]. The approach begins with a set of sample graphs and produces a generalized graph grammar capable of deriving the original sample graphs and many others.
Reference: [21] <author> J. Segen. </author> <title> Graph clustering and model learning by data compression. </title> <booktitle> In Proceedings of the Seventh International Machine Learning Workshop, </booktitle> <pages> pages 93-101, </pages> <year> 1990. </year>
Reference-contexts: Finally, the subgraph-of partial ordering used by Levinson's system is not included in Subdue, but maintaining this partial ordering would improve the performance of the graph matching procedure by pruning the number of possible matching graphs. Segen <ref> [21] </ref> describes a system for storing graphs using a probabilistic graph model to represent subsets of the graph. Alternative models are evaluated based on a minimum description length measure of the information needed to represent the stored graphs using the model.
Reference: [22] <author> K. Thompson and P. Langley. </author> <title> Concept formation in structured domains. </title> <editor> In D. H. Fisher and M. Pazzani, editors, </editor> <title> Concept Formation: Knowledge and Experience in Unsupervised Learning, chapter 5. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1991. </year>
Reference-contexts: As with Levinson's approach, graphs are processed incrementally, and substructure is found across several graphs, not within a single graph as in Subdue. The Labyrinth system <ref> [22] </ref> extends the Cobweb incremental conceptual clustering system [5] to handle structured objects. Labyrinth uses Cobweb to form hierarchical concepts of the individual objects in the domain based on their primitive attributes. Concepts of structured objects are formed in a similar manner using the individual objects as attributes.
Reference: [23] <author> D. Waltz. </author> <title> Understanding line drawings of scenes with shadows. </title> <editor> In P. H. Winston, editor, </editor> <booktitle> The Psychology of Computer Vision. </booktitle> <publisher> McGraw-Hill, </publisher> <year> 1975. </year>
Reference-contexts: The graph representation consists of eight types of vertices and two types of arcs (edge and space). The vertex labels (f , a, l, t, k, x, p, and m) follow the Waltz labelings <ref> [23] </ref> of junctions of edges in the image and represent the types of vertices shown in Figure 10. An edge arc represents the edge of an object in the image, and a space arc links non-connecting objects together.
Reference: [24] <author> P. H. Winston. </author> <title> Learning structural descriptions from examples. </title> <editor> In P. H. Winston, editor, </editor> <booktitle> The Psychology of Computer Vision, </booktitle> <pages> pages 157-210. </pages> <publisher> McGraw-Hill, </publisher> <year> 1975. </year>
Reference-contexts: Section 9 concludes with directions for future work. 2 Related Work Several approaches to substructure discovery have been developed. Winston's Arch program <ref> [24] </ref> discovers substructures in order to deepen the hierarchical description of a scene and to group objects into more general concepts. The Arch program searches for two types of substructure in the blocks-world domain. The first type involves a sequence of objects connected by a chain of similar relations.
Reference: [25] <author> K. Yoshida, H. Motoda, and N. Indurkhya. </author> <title> Unifying learning methods by colored digraphs. </title> <booktitle> In Proceedings of the Learning and Knowledge Acquisition Workshop at IJCAI-93, </booktitle> <year> 1993. </year> <month> 21 </month>
Reference-contexts: Again, maintaining the concepts (images, graphs) in a partially-ordered hierarchy improves the efficiency of matching and retrieval, and suggests a possible improvement to Subdue. The CLiP system <ref> [25] </ref> for graph-based induction is more similar to Subdue than the previous systems. CLiP iteratively discovers patterns in graphs by expanding and combining patterns discovered in previous iterations. Patterns are grouped into views based on their collective ability to compress the original input graph.
References-found: 25

