URL: ftp://ftp.cs.bham.ac.uk/pub/tech-reports/1996/CSRP-96-14.ps.gz
Refering-URL: http://www.cs.bham.ac.uk/~rmp/eebic/index.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: E-mail: R.Poli@cs.bham.ac.uk  
Title: Discovery of Symbolic, Neuro-Symbolic and Neural Networks with Parallel Distributed Genetic Programming  
Author: Riccardo Poli 
Address: Birmingham B15 2TT United Kingdom  
Affiliation: School of Computer Science The University of Birmingham  
Abstract: Technical Report: CSRP-96-14 August 1996 Abstract Genetic Programming is a method of program discovery consisting of a special kind of genetic algorithm capable of operating on parse trees representing programs and an interpreter which can run the programs being optimised. This paper describes Parallel Distributed Genetic Programming (PDGP), a new form of genetic programming which is suitable for the development of parallel programs in which symbolic and neural processing elements can be combined a in free and natural way. PDGP is based on a graph-like representation for parallel programs which is manipulated by crossover and mutation operators which guarantee the syntactic correctness of the offspring. The paper describes these operators and reports some results obtained with the exclusive-or problem. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> Late Breaking Papers at the Genetic Programming 1996 Conference, Stanford University, </institution> <address> July 1996. </address> <publisher> Stanford Bookstore. </publisher>
Reference-contexts: T can include: variables, constants, 0-arity functions with side effects, random constants, etc. This form of GP has been applied successfully to a large number of difficult problems like automated design, pattern recognition, robot control, symbolic regression, music generation, image compression, image analysis, etc. <ref> [7, 8, 5, 6, 1, 11] </ref>. When appropriate terminals, functions and/or interpreters are defined, standard GP can go beyond the production of sequential tree-like programs. <p> the figures in the paper, as the order of evaluation can be easily inferred given the simplicity of the examples reported. 8 programs. 4.3 Neuro-Algebraic solutions In these experiments we used the same function set and terminal set as in Section 4.2, but we added random weights in the range <ref> [1; 1] </ref> to the links. The weights act as pre-multipliers for the arguments of the functions in F . neuro-algebraic operators.
Reference: [2] <author> Forrest H. Bennett III. </author> <title> Automatic creation of an efficient multi-agent architecture using genetic programming with architecture-altering operations. </title> <editor> In John R. Koza, David E. Goldberg, David B. Fogel, and Rick L. Riolo, editors, </editor> <booktitle> Genetic Programming 1996: Proceedings of the First Annual Conference, </booktitle> <pages> page 30, </pages> <address> Stanford University, CA, USA, 28-31 July 1996. </address> <publisher> MIT Press. </publisher> <pages> 12 </pages>
Reference-contexts: Also, in conjunction with an interpreter implementing a parallel virtual-machine, GP can be used to develop special kinds of parallel programs <ref> [2, 14] </ref> or to translate sequential programs into parallel ones [15].
Reference: [3] <author> F Gruau and D. Whitley. </author> <title> Adding learning to the cellular development process: a comparative study. </title> <journal> Evolutionary Computation, </journal> <volume> 1(3) </volume> <pages> 213-233, </pages> <year> 1993. </year>
Reference-contexts: When appropriate terminals, functions and/or interpreters are defined, standard GP can go beyond the production of sequential tree-like programs. For example using cellular encoding GP can be used to develop structures, like neural nets <ref> [3, 4] </ref> or electronic circuits [10, 9], which can be thought of as performing some form of parallel computation.
Reference: [4] <author> Frederic Gruau. </author> <title> Genetic micro programming of neural networks. </title> <editor> In Kenneth E. Kinnear, Jr., editor, </editor> <booktitle> Advances in Genetic Programming, chapter 24. </booktitle> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: When appropriate terminals, functions and/or interpreters are defined, standard GP can go beyond the production of sequential tree-like programs. For example using cellular encoding GP can be used to develop structures, like neural nets <ref> [3, 4] </ref> or electronic circuits [10, 9], which can be thought of as performing some form of parallel computation.
Reference: [5] <editor> K. E. Kinnear, Jr., editor. </editor> <booktitle> Advances in Genetic Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: T can include: variables, constants, 0-arity functions with side effects, random constants, etc. This form of GP has been applied successfully to a large number of difficult problems like automated design, pattern recognition, robot control, symbolic regression, music generation, image compression, image analysis, etc. <ref> [7, 8, 5, 6, 1, 11] </ref>. When appropriate terminals, functions and/or interpreters are defined, standard GP can go beyond the production of sequential tree-like programs.
Reference: [6] <editor> J. R. Koza, D. E. Goldberg, D. B. Fogel, and R. L. Riolo, editors. </editor> <booktitle> Proceedings of the First International Conference on Genetic Programming, </booktitle> <address> Stenford University, July 1996. </address> <publisher> MIT Press. </publisher>
Reference-contexts: T can include: variables, constants, 0-arity functions with side effects, random constants, etc. This form of GP has been applied successfully to a large number of difficult problems like automated design, pattern recognition, robot control, symbolic regression, music generation, image compression, image analysis, etc. <ref> [7, 8, 5, 6, 1, 11] </ref>. When appropriate terminals, functions and/or interpreters are defined, standard GP can go beyond the production of sequential tree-like programs.
Reference: [7] <author> John R. Koza. </author> <title> Genetic Programming: On the Programming of Computers by Means of Natural Selection. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: 1 Introduction Genetic Programming (GP) is an extension of Genetic Algorithms (GAs) in which the structures that make up the population to be optimised are not fixed-length character strings that encode possible solutions to a problem, but programs that, when executed, are the candidate solutions to the problem <ref> [7, 8] </ref>. Programs are expressed in GP as parse trees, rather than as lines of code. <p> T can include: variables, constants, 0-arity functions with side effects, random constants, etc. This form of GP has been applied successfully to a large number of difficult problems like automated design, pattern recognition, robot control, symbolic regression, music generation, image compression, image analysis, etc. <ref> [7, 8, 5, 6, 1, 11] </ref>. When appropriate terminals, functions and/or interpreters are defined, standard GP can go beyond the production of sequential tree-like programs.
Reference: [8] <author> John R. Koza. </author> <title> Genetic Programming II: Automatic Discovery of Reusable Programs. </title> <publisher> MIT Pres, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1994. </year>
Reference-contexts: 1 Introduction Genetic Programming (GP) is an extension of Genetic Algorithms (GAs) in which the structures that make up the population to be optimised are not fixed-length character strings that encode possible solutions to a problem, but programs that, when executed, are the candidate solutions to the problem <ref> [7, 8] </ref>. Programs are expressed in GP as parse trees, rather than as lines of code. <p> T can include: variables, constants, 0-arity functions with side effects, random constants, etc. This form of GP has been applied successfully to a large number of difficult problems like automated design, pattern recognition, robot control, symbolic regression, music generation, image compression, image analysis, etc. <ref> [7, 8, 5, 6, 1, 11] </ref>. When appropriate terminals, functions and/or interpreters are defined, standard GP can go beyond the production of sequential tree-like programs.
Reference: [9] <author> John R. Koza, David Andre, Forrest H. Bennett III, and Martin A. Keane. </author> <title> Use of automatically defined functions and architecture-altering operations in automated circuit synthesis using genetic programming. </title> <editor> In John R. Koza, David E. Goldberg, David B. Fogel, and Rick L. Riolo, editors, </editor> <booktitle> Genetic Programming 1996: Proceedings of the First Annual Conference, </booktitle> <pages> page 132, </pages> <address> Stanford University, CA, USA, 28-31 July 1996. </address> <publisher> MIT Press. </publisher>
Reference-contexts: When appropriate terminals, functions and/or interpreters are defined, standard GP can go beyond the production of sequential tree-like programs. For example using cellular encoding GP can be used to develop structures, like neural nets [3, 4] or electronic circuits <ref> [10, 9] </ref>, which can be thought of as performing some form of parallel computation. Also, in conjunction with an interpreter implementing a parallel virtual-machine, GP can be used to develop special kinds of parallel programs [2, 14] or to translate sequential programs into parallel ones [15].
Reference: [10] <author> John R. Koza, Forrest H. Bennett III David Andre, and Martin A. Keane. </author> <title> Automated WYWIWYG design of both the topology and component values of electrical circuits using genetic programming. </title> <editor> In John R. Koza, David E. Goldberg, David B. Fogel, and Rick L. Riolo, editors, </editor> <booktitle> Genetic Programming 1996: Proceedings of the First Annual Conference, </booktitle> <pages> page 123, </pages> <address> Stanford University, CA, USA, 28-31 July 1996. </address> <publisher> MIT Press. </publisher>
Reference-contexts: When appropriate terminals, functions and/or interpreters are defined, standard GP can go beyond the production of sequential tree-like programs. For example using cellular encoding GP can be used to develop structures, like neural nets [3, 4] or electronic circuits <ref> [10, 9] </ref>, which can be thought of as performing some form of parallel computation. Also, in conjunction with an interpreter implementing a parallel virtual-machine, GP can be used to develop special kinds of parallel programs [2, 14] or to translate sequential programs into parallel ones [15].
Reference: [11] <author> Riccardo Poli. </author> <title> Genetic programming for image analysis. </title> <editor> In John R. Koza, David E. Goldberg, David B. Fogel, and Rick L. Riolo, editors, </editor> <booktitle> Genetic Programming 1996: Proceedings of the First Annual Conference, </booktitle> <pages> page 363, </pages> <address> Stanford University, CA, USA, 28-31 July 1996. </address> <publisher> MIT Press. </publisher>
Reference-contexts: T can include: variables, constants, 0-arity functions with side effects, random constants, etc. This form of GP has been applied successfully to a large number of difficult problems like automated design, pattern recognition, robot control, symbolic regression, music generation, image compression, image analysis, etc. <ref> [7, 8, 5, 6, 1, 11] </ref>. When appropriate terminals, functions and/or interpreters are defined, standard GP can go beyond the production of sequential tree-like programs.
Reference: [12] <author> Riccardo Poli. </author> <title> Some steps towards a form of parallel distributed genetic programming. </title> <booktitle> In Proceedings of the First On-line Workshop on Soft Computing, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: In some experiments we also extended the representation by associating labels to links. If the labels are real numbers, this technique allows the direct development of neural networks. 3 Genetic Operators With the representations described in the previous section, several kinds of crossover and mutation can be defined (see <ref> [12] </ref> for a more complete description). The crossover operator most similar to the one used in standard GP is called Sub-graph Active-Active Node (SAAN) crossover. It works as follows: 1. A random active node is selected in the first parent. 2. <p> We call this form of mutation global mutation. It is also possible to define another form of mutation, link mutation, which makes local modifications to the connection topology of the graph <ref> [12] </ref>. 4 Experimental Results In this section we report on some preliminary experimental results obtained by applying PDGP to the exclusive-or problem.
Reference: [13] <editor> D.E. Rumelhart and J.L. McClelland, editors. </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition, </booktitle> <volume> Vol. </volume> <pages> 1-2. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: In the following sections the representation and operators used in PDGP are described and some results obtained by applying this paradigm to the XOR problem are reported. 2 Representation Taking inspiration from the parallel distributed processing performed in neural nets <ref> [13] </ref>, we represent fine-grained parallel programs as graphs with labelled nodes and oriented links.
Reference: [14] <author> Astro Teller and Manuela Veloso. </author> <title> Neural programming and an internal reinforcement policy. </title> <editor> In John R. Koza, editor, </editor> <booktitle> Late Breaking Papers at the Genetic Programming 1996 Conference Stanford University July 28-31, </booktitle> <year> 1996, </year> <pages> pages 186-192, </pages> <address> Stanford University, CA, USA, 28-31 July 1996. </address> <publisher> Stanford Bookstore. </publisher>
Reference-contexts: Also, in conjunction with an interpreter implementing a parallel virtual-machine, GP can be used to develop special kinds of parallel programs <ref> [2, 14] </ref> or to translate sequential programs into parallel ones [15].
Reference: [15] <author> Paul Walsh and Conor Ryan. </author> <title> Paragen: A novel technique for the autoparallelisation of sequential programs using genetic programming. </title> <editor> In John R. Koza, David E. Goldberg, David B. Fogel, and Rick L. Riolo, editors, </editor> <booktitle> Genetic Programming 1996: Proceedings of the First Annual Conference, </booktitle> <pages> page 406, </pages> <address> Stanford University, CA, USA, 28-31 July 1996. </address> <publisher> MIT Press. </publisher> <pages> 14 </pages>
Reference-contexts: Also, in conjunction with an interpreter implementing a parallel virtual-machine, GP can be used to develop special kinds of parallel programs [2, 14] or to translate sequential programs into parallel ones <ref> [15] </ref>. This paper describes Parallel Distributed Genetic Programming (PDGP), a new form of genetic programming which is specialised in the development of parallel programs in which symbolic, numeric and neural processing elements can be combined in totally free and natural way.
References-found: 15

