URL: http://ftp.eecs.umich.edu/people/neuhoff/OtherAsymptThy.ps
Refering-URL: http://ftp.eecs.umich.edu/people/neuhoff/
Root-URL: http://www.eecs.umich.edu
Title: THE OTHER ASYMPTOTIC THEORY OF LOSSY SOURCE CODING  
Author: D. L. NEUHOFF 
Abstract: Rate-distortion theory, as initiated by Shannon in his celebrated 1948 paper, is a well known theory of lossy source coding. It is an asymptotic theory in the sense that the performance it prescribes is approachable only in the limit as code dimension increases. Less well known is the "other" asymptotic theory of lossy source coding, which goes by the names of high-rate, high-resolution and asymptotic quantization theory. This theory prescribes the performance of codes with a given dimension and asymptotically large rate. The purpose of the present paper is to compare and contrast the two theories, and to highlight some recent results in high-rate quantization theory. It is the thesis of this paper that high-rate quantization theory has surpassed rate-distortion theory in its relevance to practical code design, because of its ability to identify key characteristics of good codes and to analyze the performance of codes with complexity-reducing structure. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> C.E. Shannon, </author> <title> "A mathematical theory of communication," </title> <journal> Bell Syst. Tech. J., </journal> <volume> vol. 27, </volume> <pages> pp. 397-423, 623-656, </pages> <year> 1948. </year>
Reference-contexts: Rate-Distortion Theory Shannon's rate-distortion theorem, the third theorem of his celebrated 1948 paper <ref> [1] </ref> (and expanded upon in his 1959 paper [2] and generalized by others [3, 4]) achieves the first goal by showing that for stationary, ergodic sources (satisfying a moment finiteness condition) ffi (R) = D (R) where D (R) is the information theoretic distortion-rate function (DRF) 3 , defined as follows <p> That is, ffi k (R) = D (R) for large k and any R Z k (R) for large R and any k. (2) History: Both theories originated in 1948. Rate-distortion theory had a spectacular beginning and rapidly became well known. It was mostly developed by Shannon <ref> [1, 2] </ref> and is now fairly mature. See [5] (pp.291,293) for a survey of other early contributors, and [12] for a survey of more recent work.
Reference: 2. <author> C.E. Shannon, </author> <title> "Coding theorems for a discrete source with a fidelity criterion," </title> <journal> IRE Nat'l. Conv. Rec. </journal> <volume> part 4, </volume> <pages> pp. 142-163, </pages> <year> 1959. </year>
Reference-contexts: Rate-Distortion Theory Shannon's rate-distortion theorem, the third theorem of his celebrated 1948 paper [1] (and expanded upon in his 1959 paper <ref> [2] </ref> and generalized by others [3, 4]) achieves the first goal by showing that for stationary, ergodic sources (satisfying a moment finiteness condition) ffi (R) = D (R) where D (R) is the information theoretic distortion-rate function (DRF) 3 , defined as follows (c.f. [3, 5, 6]): D (R) = lim <p> That is, ffi k (R) = D (R) for large k and any R Z k (R) for large R and any k. (2) History: Both theories originated in 1948. Rate-distortion theory had a spectacular beginning and rapidly became well known. It was mostly developed by Shannon <ref> [1, 2] </ref> and is now fairly mature. See [5] (pp.291,293) for a survey of other early contributors, and [12] for a survey of more recent work.
Reference: 3. <author> R.G. Gallager, </author> <title> Information Theory and Reliable Communication, </title> <address> New York: </address> <publisher> Wiley, </publisher> <year> 1968. </year>
Reference-contexts: Rate-Distortion Theory Shannon's rate-distortion theorem, the third theorem of his celebrated 1948 paper [1] (and expanded upon in his 1959 paper [2] and generalized by others <ref> [3, 4] </ref>) achieves the first goal by showing that for stationary, ergodic sources (satisfying a moment finiteness condition) ffi (R) = D (R) where D (R) is the information theoretic distortion-rate function (DRF) 3 , defined as follows (c.f. [3, 5, 6]): D (R) = lim D k (R) : where <p> expanded upon in his 1959 paper [2] and generalized by others [3, 4]) achieves the first goal by showing that for stationary, ergodic sources (satisfying a moment finiteness condition) ffi (R) = D (R) where D (R) is the information theoretic distortion-rate function (DRF) 3 , defined as follows (c.f. <ref> [3, 5, 6] </ref>): D (R) = lim D k (R) : where D k (R) = inf 1 EkX Y k 2 ; where Y = (Y 1 : : : Y k ) is the output of the test channel q with X as the input, where Q k (R)
Reference: 4. <author> T. Berger, </author> <title> "Rate distortion theory for sources with abstract alphabets and memory," </title> <journal> Information and Control, </journal> <volume> vol. 13, </volume> <pages> pp. 254-273, </pages> <year> 1968. </year>
Reference-contexts: Rate-Distortion Theory Shannon's rate-distortion theorem, the third theorem of his celebrated 1948 paper [1] (and expanded upon in his 1959 paper [2] and generalized by others <ref> [3, 4] </ref>) achieves the first goal by showing that for stationary, ergodic sources (satisfying a moment finiteness condition) ffi (R) = D (R) where D (R) is the information theoretic distortion-rate function (DRF) 3 , defined as follows (c.f. [3, 5, 6]): D (R) = lim D k (R) : where
Reference: 5. <author> T. Berger, </author> <title> Rate Distortion Theory, </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall, </publisher> <year> 1971. </year>
Reference-contexts: expanded upon in his 1959 paper [2] and generalized by others [3, 4]) achieves the first goal by showing that for stationary, ergodic sources (satisfying a moment finiteness condition) ffi (R) = D (R) where D (R) is the information theoretic distortion-rate function (DRF) 3 , defined as follows (c.f. <ref> [3, 5, 6] </ref>): D (R) = lim D k (R) : where D k (R) = inf 1 EkX Y k 2 ; where Y = (Y 1 : : : Y k ) is the output of the test channel q with X as the input, where Q k (R) <p> In other words, rate-distortion theory relates the operational quantity ffi (R) that we wish to know to the information theoretic quantity D (R). The latter can be evaluated analytically (c.f. <ref> [5, 6] </ref>) or numerically [7]. It is well known that, except for degenerate cases, ffi k (R) &gt; D k (R) : For small k, this bound is usually rather weak, and the kth-order distortion-rate function cannot be viewed as having much operational significance. <p> There are several well-known bounds to D (R) and D k (R) (c.f. <ref> [5, 6] </ref>). An upper bound derives from known parametric formulas for D k (R) and D (R) for Gaussian sources and from the fact that among sources with a given covariance function, the Gaussian distortion-rate function is largest. <p> Rate-distortion theory had a spectacular beginning and rapidly became well known. It was mostly developed by Shannon [1, 2] and is now fairly mature. See <ref> [5] </ref> (pp.291,293) for a survey of other early contributors, and [12] for a survey of more recent work. High-rate quantization theory had humble beginnings in Bennett's paper for scalar quantizers [10], developed slowly through the years through the efforts of many [13-21,9,22-29], and is not so well known. <p> More generally, the points can be uniformly distributed in the region of typical sequences, where the source density is approximately uniform (see the asymptotic equipartition property (AEP) <ref> [5] </ref>). <p> One can use this fact to learn something about the error process resulting from an optimal high-dimensional VQ. For example, for a Gaussian source with memory, one discovers how the spectrum of the noise relates to that of the source (c.f. <ref> [5] </ref>). 6 It is likely that the originally perceived need for high dimensions (based on the AEP) delayed the serious consideration of vector quantizers. The breakthrough was the paper by Linde, Buzo and Gray [33], which showed that VQ's with moderate dimension were both good and feasible. 8 D. L.
Reference: 6. <author> R.M.Gray, </author> <title> Source Coding Theory, </title> <address> Boston: </address> <publisher> Kluwer, </publisher> <year> 1990. </year>
Reference-contexts: expanded upon in his 1959 paper [2] and generalized by others [3, 4]) achieves the first goal by showing that for stationary, ergodic sources (satisfying a moment finiteness condition) ffi (R) = D (R) where D (R) is the information theoretic distortion-rate function (DRF) 3 , defined as follows (c.f. <ref> [3, 5, 6] </ref>): D (R) = lim D k (R) : where D k (R) = inf 1 EkX Y k 2 ; where Y = (Y 1 : : : Y k ) is the output of the test channel q with X as the input, where Q k (R) <p> In other words, rate-distortion theory relates the operational quantity ffi (R) that we wish to know to the information theoretic quantity D (R). The latter can be evaluated analytically (c.f. <ref> [5, 6] </ref>) or numerically [7]. It is well known that, except for degenerate cases, ffi k (R) &gt; D k (R) : For small k, this bound is usually rather weak, and the kth-order distortion-rate function cannot be viewed as having much operational significance. <p> There are several well-known bounds to D (R) and D k (R) (c.f. <ref> [5, 6] </ref>). An upper bound derives from known parametric formulas for D k (R) and D (R) for Gaussian sources and from the fact that among sources with a given covariance function, the Gaussian distortion-rate function is largest.
Reference: 7. <author> R.E. Blahut, </author> <title> "Computation of channel capacity and rate-distortion functions," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-18, </volume> <pages> pp. 460-473, </pages> <month> July </month> <year> 1972. </year> <title> THE OTHER ASYMPTOTIC THEORY OF LOSSY SOURCE CODING 9 </title>
Reference-contexts: In other words, rate-distortion theory relates the operational quantity ffi (R) that we wish to know to the information theoretic quantity D (R). The latter can be evaluated analytically (c.f. [5, 6]) or numerically <ref> [7] </ref>. It is well known that, except for degenerate cases, ffi k (R) &gt; D k (R) : For small k, this bound is usually rather weak, and the kth-order distortion-rate function cannot be viewed as having much operational significance.
Reference: 8. <author> P. Zador, </author> <title> "Development and Evaluation of Procedures for Quantizing Multivariate Distributions," </title> <type> Ph.D. dissertation, </type> <institution> Stanford Univ., Stanford, </institution> <address> CA, </address> <year> 1964. </year>
Reference-contexts: L. NEUHOFF Both of these bounds are asymptotically tight in the sense that the ratio of the DRF to the lower bound goes to one as R tends to infinity. 4. High-Rate Quantization Theory The central result of high-rate quantization theory is Zador's theorem <ref> [8, 9] </ref>, which shows that lim ffi k (R) = 1 (4.1) where Z k (R) is the Zador-Gersho function, defined as Z k (R) = c k ff k 2 2R (4.2) where ff k R (k+2)=k depends on the source distribution and c k , called the tiling moment <p> High-rate quantization theory is, fundamentally, a theory devoted to finite-dimensional random vectors, as opposed to random processes. However, for stationary sources, one may let dimension increase and obtain nice limiting formulas. Both theories give nice analytical formulas for Gaussian sources. 5 Zador <ref> [8] </ref> found the form of (4.2); Gersho [9] recognized that the multiplicative constant is c k . 6 D. L. NEUHOFF (7) Code structures: Rate-distortion theory applies primarily to vector quan-tizers, or block codes as they were originally called.
Reference: 9. <author> A. Gersho, </author> <title> "Asymptotically optimal block quantization," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-23, </volume> <pages> pp. 373-380, </pages> <month> July </month> <year> 1979. </year>
Reference-contexts: L. NEUHOFF Both of these bounds are asymptotically tight in the sense that the ratio of the DRF to the lower bound goes to one as R tends to infinity. 4. High-Rate Quantization Theory The central result of high-rate quantization theory is Zador's theorem <ref> [8, 9] </ref>, which shows that lim ffi k (R) = 1 (4.1) where Z k (R) is the Zador-Gersho function, defined as Z k (R) = c k ff k 2 2R (4.2) where ff k R (k+2)=k depends on the source distribution and c k , called the tiling moment <p> It is natural, then, to seek the best inertial profile and point density. Although never formally proved, there is a widely believed conjecture due to Gersho <ref> [9] </ref> that, for large N , most cells of the best k-dimensional quantizers are congruent, approximately, to the tesselating polytope with minimum normalized moment of inertia. Assuming this to be the case, the best inertial profile is the constant function m (x) = c k . <p> High-rate quantization theory is, fundamentally, a theory devoted to finite-dimensional random vectors, as opposed to random processes. However, for stationary sources, one may let dimension increase and obtain nice limiting formulas. Both theories give nice analytical formulas for Gaussian sources. 5 Zador [8] found the form of (4.2); Gersho <ref> [9] </ref> recognized that the multiplicative constant is c k . 6 D. L. NEUHOFF (7) Code structures: Rate-distortion theory applies primarily to vector quan-tizers, or block codes as they were originally called.
Reference: 10. <author> W.R. Bennett, </author> <title> "Spectra of quantized signals," </title> <journal> B.S.T.J., </journal> <volume> vol. 27, </volume> <pages> pp. 446-472, </pages> <month> July </month> <year> 1948. </year>
Reference-contexts: It follows from (4.1) that lim ffi (R) = 1 where Z (R) = lim Z k (R) : Another important result of high-rate quantization theory is Bennett's integral for scalar quantizers <ref> [10] </ref> and its recent extension to VQ's [11]. The latter shows that for a VQ with many, mostly small cells, and neighboring cells having similar sizes and shapes D = N 2=k m (x) where (x) is the point density and m (x) is the inertial profile of the VQ. <p> It was mostly developed by Shannon [1, 2] and is now fairly mature. See [5] (pp.291,293) for a survey of other early contributors, and [12] for a survey of more recent work. High-rate quantization theory had humble beginnings in Bennett's paper for scalar quantizers <ref> [10] </ref>, developed slowly through the years through the efforts of many [13-21,9,22-29], and is not so well known. Recent results have significantly expanded its usefulness [11,30-32], and it is still developing. (3) Underlying Principles: Rate-distortion theory is a deep and elegant theory based on the law of large numbers. <p> For example, one can design essentially optimal scalar quantizers by choosing y i = F 1 ((2i 1)=2N ) <ref> [10, 13, 27] </ref>, where F (x) = R x k (u)du is the distribution function corresponding to the optimal point density. These two design philosophies are not inconsistent.
Reference: 11. <author> S. Na and D.L. Neuhoff, </author> <title> "Bennett's integral for vector quantizers, </title> <booktitle> and applications," 1990 IEEE Int'l Symp. on Inform. Theory, </booktitle> <month> Jan. </month> <year> 1990. </year>
Reference-contexts: It follows from (4.1) that lim ffi (R) = 1 where Z (R) = lim Z k (R) : Another important result of high-rate quantization theory is Bennett's integral for scalar quantizers [10] and its recent extension to VQ's <ref> [11] </ref>. The latter shows that for a VQ with many, mostly small cells, and neighboring cells having similar sizes and shapes D = N 2=k m (x) where (x) is the point density and m (x) is the inertial profile of the VQ. <p> Assuming this to be the case, the best inertial profile is the constant function m (x) = c k . Assuming a constant inertial profile such as this, either calculus of variations or 4 Eq. (4.3) is made precise <ref> [11] </ref> by showing that N 2=k D N converges to the integral in (4.3), where fD N g are the distortions of a sequence of quantizers whose point densities and inertial profiles converge to and m, respectively, as the size N increases to infinity.
Reference: 12. <author> J.C. Kieffer, </author> <title> "A survey of the theory of source coding," </title> <note> to appear in IEEE Trans. Inform. Theory. </note>
Reference-contexts: Rate-distortion theory had a spectacular beginning and rapidly became well known. It was mostly developed by Shannon [1, 2] and is now fairly mature. See [5] (pp.291,293) for a survey of other early contributors, and <ref> [12] </ref> for a survey of more recent work. High-rate quantization theory had humble beginnings in Bennett's paper for scalar quantizers [10], developed slowly through the years through the efforts of many [13-21,9,22-29], and is not so well known. <p> Both, however, provide the most results for the squared-error distortion measure. Each requires the source to satisfy a finite moment condition, related to the specific distortion measure. (6) Sources: Rate-distortion theory is intended primarily for stationary, ergodic sources, although there are generalizations to asymptotically stationary and noner-godic sources (c.f. <ref> [12] </ref>). High-rate quantization theory is, fundamentally, a theory devoted to finite-dimensional random vectors, as opposed to random processes. However, for stationary sources, one may let dimension increase and obtain nice limiting formulas.
Reference: 13. <author> P.F. Panter and W. Dite, </author> <title> "Quantization distortion in pulse count modulation with nonuniform spacing of levels," </title> <journal> Proc. IRE, </journal> <volume> vol. 39, </volume> <pages> pp. 44-48, </pages> <month> Jan. </month> <year> 1951. </year>
Reference-contexts: For example, one can design essentially optimal scalar quantizers by choosing y i = F 1 ((2i 1)=2N ) <ref> [10, 13, 27] </ref>, where F (x) = R x k (u)du is the distribution function corresponding to the optimal point density. These two design philosophies are not inconsistent.
Reference: 14. <author> S.P. Lloyd, </author> <title> "Least squares quantization in PCM," </title> <journal> Bell Laboratories Memorandum 1957, also published in IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-28, </volume> <pages> pp. 129-137, </pages> <month> March </month> <year> 1982. </year>
Reference: 15. <author> M.P. Schutzenberger, </author> <title> "On the quantization of finite-dimensional messges," </title> <journal> Inform. and Control, </journal> <volume> vol. 1, </volume> <pages> pp. 153-158, </pages> <year> 1958. </year>
Reference: 16. <author> J.J.Y. Huang and P.M. Schultheiss, </author> <title> "Block quantization of correlated Gaussian variables," </title> <journal> IEEE Trans. Commun., </journal> <volume> vol. COM-11, </volume> <pages> pp. 289-296, </pages> <month> Sept. </month> <year> 1963. </year>
Reference: 17. <author> V.R. Algazi, </author> <title> "Useful approximations to optimum quantization, </title> <journal> "IEEE Trans. Commun., </journal> <volume> vol. COM-14, </volume> <pages> pp. 297-301, </pages> <month> June </month> <year> 1966. </year>
Reference: 18. <author> H. Gish and J.R. Pierce, </author> <title> "Asymptotically efficient quantizing," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-14, </volume> <pages> pp. 676-683, </pages> <month> Sept. </month> <year> 1968. </year>
Reference: 19. <author> P. Elias, </author> <title> "Bounds on performance of optimum quantizers," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-16, </volume> <pages> pp. 172-184, </pages> <month> March </month> <year> 1970. </year>
Reference: 20. <author> I. Csiszar, </author> <title> "Generalized entropy and quantization problems," </title> <booktitle> 6th Prague Conference, </booktitle> <year> 1973. </year>
Reference: 21. <author> R.M. Gray and A.H. Gray, </author> <title> "Asymptotically optimal quantizers," </title> <journal> IEEE Trans. Inform. Theory, </journal> <pages> pp. 143-144, </pages> <month> Jan. </month> <year> 1977. </year>
Reference: 22. <author> J.A. Bucklew and N.C. Gallagher, </author> <title> "Some properties of uniform step size quantizers," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-26, </volume> <pages> pp. 610-613, </pages> <month> Sept. </month> <year> 1980. </year>
Reference: 23. <author> Y. Yamada, S. Tazaki and R.M. Gray, </author> <title> "Asymptotic performance of block quantizers with difference distortion measures," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-26, </volume> <pages> pp. 6-14, </pages> <month> Jan. </month> <year> 1980. </year>
Reference: 24. <author> J. A. Bucklew, </author> <title> "Companding and random quantization in several dimensions," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-27, </volume> <pages> pp. 207-211, </pages> <month> March </month> <year> 1981. </year>
Reference: 25. <author> J.A. Bucklew and G.W. Wise, </author> <title> "Multidimensional asymptotic quantization theory with r th power distortion measures," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> Vol. IT-28, </volume> <pages> pp. 239-247, </pages> <month> Mar. </month> <year> 1982. </year>
Reference: 26. <author> N.C. Gallagher, J.A. Bucklew, </author> <title> "Properties of minimum mean squared error block quantizers," </title> <journal> IEEE Trans. Inform. Thy., </journal> <volume> vol. IT-28, </volume> <pages> pp. 105-107, </pages> <month> Jan. </month> <year> 1983. </year>
Reference: 27. <author> S. Cambanis and N. Gerr, </author> <title> "A simple class of asymptotically optimal quantizers," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-29, </volume> <pages> pp. 664-676, </pages> <month> Sept. </month> <year> 1983. </year>
Reference-contexts: For example, one can design essentially optimal scalar quantizers by choosing y i = F 1 ((2i 1)=2N ) <ref> [10, 13, 27] </ref>, where F (x) = R x k (u)du is the distribution function corresponding to the optimal point density. These two design philosophies are not inconsistent.
Reference: 28. <author> J.A. Bucklew, </author> <title> "A note on optimal multidimensional companders," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-29, </volume> <pages> pp. 279, </pages> <month> March </month> <year> 1983. </year>
Reference: 29. <author> J.A. Bucklew, </author> <title> "Two results on the asymptotic performance of quantizers," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-30, </volume> <pages> pp. 341-348, </pages> <month> Mar. </month> <year> 1984. </year>
Reference: 30. <author> D.H. Lee and D.L. Neuhoff, </author> <title> "The asymptotic distribution of the error in scalar and vector quantizers," </title> <booktitle> 1990 IEEE Int'l Symp. Inform. Theory, </booktitle> <address> San Diego, </address> <month> Jan. </month> <year> 1990. </year>
Reference-contexts: L. NEUHOFF Recently, in high-rate theory there has been developed an asymptotic formula for the density of the error that results from a VQ with many mostly small cells, with neighboring cells having similar sizes and shapes <ref> [30] </ref>. Taking the second moment of this density yields, of course, Bennett's integral. The form of the density depends intimately on the point density and the cell shapes.
Reference: 31. <author> D.L. Neuhoff and D.H. Lee, </author> <title> "On the Performance of Tree-Structured Vector Quantization," </title> <journal> ICAASP91, </journal> <volume> vol. 4, </volume> <pages> pp. 2277-2280, </pages> <address> Toronto, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: It has also been used to analyze lattice codes. And the recent extension of Bennett's integral to vector quantizers has lead to finding the ODRF's for tree-structured VQ <ref> [31] </ref> and two-stage VQ [32]. (8) Performance vs. complexity: Rate-distortion theory specifies the fundamental limits to the performance of lossy source coding without regard to cost or complexity. <p> For example, in lattice quantization, the point density is a constant (far from optimal), in TSVQ the point density is good but the cell shapes are no better than cubes <ref> [31] </ref>, and in two-stage VQ, the point density is affected but the cell shapes are optimal [32]. (9) Relationships: The following relations hold between distortion-rate functions and Zador-Gersho functions (c.f.[6]). The inequalities marked with "*" become tight as dimension k increases. Those marked with "+" become tight as R increases. <p> It has also been found that Bennett's integral and other asymptotic analyses are accurate for roughly the same range of rates (c.f. <ref> [31] </ref>). Thus, one may say that high-rate quantization theory is accurate for rates 3 and up. Moreover, it is generally accurate enough at rate 2 to give indicative results. (11) Code design: Each theory leads to its own design philosophy. <p> It turned out that the formula is very sensitive to the shapes of the quantization cells. Thus, it has also proved useful in understanding the cell shapes of other VQ's, for example TSVQ <ref> [31] </ref>. 13. Succesive approximation: Many vector quantizers operate in a successive approximation or progressive fashion, whereby a low-rate coarse quantization is followed by a sequence of finer and finer quantizations, which add to the rate. Tree-structured, multi-stage and hierarchical VQ's are examples of such. <p> On the one hand, a recent rate-distortion theory analysis [35] has shown there are situations where successive approximation can be done without loss of optimality. On the other hand, recent high-rate analyses of TSVQ <ref> [31] </ref> and two-stage VQ [32] have quantified the loss of these particular codes. Thus, both theories have something to say about successive refinement. 6.
Reference: 32. <author> D.H. Lee and D.L. Neuhoff, </author> <title> "An Asymptotic Analysis of Two-Stage Vector Quantization," </title> <booktitle> 1991 IEEE Int'l Symp. on Inform. Theory, </booktitle> <address> p. 316, Budapest, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: It has also been used to analyze lattice codes. And the recent extension of Bennett's integral to vector quantizers has lead to finding the ODRF's for tree-structured VQ [31] and two-stage VQ <ref> [32] </ref>. (8) Performance vs. complexity: Rate-distortion theory specifies the fundamental limits to the performance of lossy source coding without regard to cost or complexity. <p> For example, in lattice quantization, the point density is a constant (far from optimal), in TSVQ the point density is good but the cell shapes are no better than cubes [31], and in two-stage VQ, the point density is affected but the cell shapes are optimal <ref> [32] </ref>. (9) Relationships: The following relations hold between distortion-rate functions and Zador-Gersho functions (c.f.[6]). The inequalities marked with "*" become tight as dimension k increases. Those marked with "+" become tight as R increases. <p> Taking the second moment of this density yields, of course, Bennett's integral. The form of the density depends intimately on the point density and the cell shapes. The original motivation for finding the asymptotic error density was a high-rate analysis of two-stage VQ <ref> [32] </ref>, where a second stage VQ is fed the error resulting from a first-stage VQ. With knowledge of the first-stage error density, Bennett's integral may be used to determine the overall distortion. It turned out that the formula is very sensitive to the shapes of the quantization cells. <p> On the one hand, a recent rate-distortion theory analysis [35] has shown there are situations where successive approximation can be done without loss of optimality. On the other hand, recent high-rate analyses of TSVQ [31] and two-stage VQ <ref> [32] </ref> have quantified the loss of these particular codes. Thus, both theories have something to say about successive refinement. 6.
Reference: 33. <author> Y. Linde, A. Buzo and R.M. Gray, </author> <title> "An algorithm for vector quantizer design," </title> <journal> IEEE Trans. Commun., </journal> <volume> vol. COM-28, </volume> <pages> pp. 84-95, </pages> <month> Jan. </month> <year> 1980. </year>
Reference-contexts: We now examine how large these parameters must be for the predictions to be reasonably accurate. Consider the case of an IID Gaussian source. By designing VQ's with the LBG algorithm <ref> [33] </ref> at low rates and by using high-rate theory at high rates, we find that a dimension of 8 to 14 is needed to give distortion within 1 dB of D (R) . <p> The breakthrough was the paper by Linde, Buzo and Gray <ref> [33] </ref>, which showed that VQ's with moderate dimension were both good and feasible. 8 D. L.
Reference: 34. <author> A. Balamesh and D. L. Neuhoff, </author> <note> unpublished notes, </note> <year> 1992. </year>
Reference-contexts: In this case, at moderate to large rates (say rate 10), after choosing the diameter of the support region to minimize this lower bound to distortion, it has been found <ref> [34] </ref> that the dimension k must be larger than 250 in order that the mean squared error is within 1dB of the distortion-rate function.
Reference: 35. <author> W.H.R. </author> <title> Equitz and T.M. Cover, "Successive refinement of information," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-37, </volume> <pages> pp. 268-275, </pages> <month> Mar. </month> <year> 1991. </year> <institution> Department of Electrical Engineering and Computer Science, Ann Arbor, Michigan 48109 E-mail address: neuhoff@eecs.umich.edu </institution>
Reference-contexts: An important question is whether the distortion of a successive refinement code will be larger than a one shot code. On the one hand, a recent rate-distortion theory analysis <ref> [35] </ref> has shown there are situations where successive approximation can be done without loss of optimality. On the other hand, recent high-rate analyses of TSVQ [31] and two-stage VQ [32] have quantified the loss of these particular codes. Thus, both theories have something to say about successive refinement. 6.
References-found: 35

