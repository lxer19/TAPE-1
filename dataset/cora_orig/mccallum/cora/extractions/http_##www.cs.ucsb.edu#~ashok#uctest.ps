URL: http://www.cs.ucsb.edu/~ashok/uctest.ps
Refering-URL: http://www.cs.ucsb.edu/~ashok/
Root-URL: http://www.cs.ucsb.edu
Title: Computational Issues in the Solution of Liquid Crystalline Polymer Flow Problems  
Degree: A dissertation submitted in partial satisfaction of the requirements for the degree of Doctor of Philosophy in Computer Science by Ashok Srinivasan Committee in charge: Professor Omer Egecioglu, Chair Professor Oscar Ibarra Professor Alan Konheim Professor Alan Laub Professor Gary Leal  
Date: August 1996  
Affiliation: UNIVERSITY OF CALIFORNIA Santa Barbara  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> I.S. Abramson. </author> <title> On bandwidth variation in kernel estimates-a square root law. </title> <journal> Annals of Statistics, </journal> <volume> 10 </volume> <pages> 1217-1223, </pages> <year> 1982. </year>
Reference-contexts: This is consistent with our formula if we let ~ approach 0 as the sample size increases, since we are in a two dimensional domain. It has however 27 been suggested by others <ref> [1, 60] </ref> that it may be better to use h (r) 2 / (r) 1 in any dimension, since the bias can be shown in this case to be of a smaller order than in the case of a fixed width kernel.
Reference: [2] <author> D. Avis. </author> <title> A survey of heuristics for the weighted matching problem. </title> <journal> Networks, </journal> <volume> 13 </volume> <pages> 475-493, </pages> <year> 1983. </year>
Reference-contexts: The results are presented in Figure 3.8. Experiment 4: Our final comparison is with the distribution given by: cos () fi (; 6; 2) where the fi distribution is similar to the beta distribution, with the range scaled to <ref> [0; 2] </ref>. The value of h was taken to be 0:3. This is non-uniform in both the latitude and the longitude. It should be noted that most of the points are concentrated near the equator of the sphere due to the cos () term. <p> This problem has been well studied <ref> [14, 2, 29, 55] </ref> and there are polynomial algorithms that yield the optimal matching. However, these algorithms are still too slow for our purposes. <p> The selection of P k can, for example, be based on the point that has the highest i . Out matching algorithm can be considered a modification of the strip heuristic <ref> [2] </ref>. We project the points on the sphere onto a plane that passes through the center of the sphere. The choice of the plane will be explained later.
Reference: [3] <author> S.T. Barnard and H. Simon. </author> <title> A parallel implementation of multilevel recursive spectral bisection for application to adaptive unstructured meshes. </title> <booktitle> In Proceedings of the Seventh SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <pages> pages 627-632, </pages> <year> 1995. </year>
Reference: [4] <author> J. Barnes and P. Hut. </author> <title> A hierarchical o(n log n) force-calculation algorithm. </title> <journal> Nature, </journal> <volume> 3 </volume> <pages> 446-449, </pages> <year> 1986. </year>
Reference-contexts: Thus the computational structure of these computations is the same as that of particle methods with short-range interactions. We next describe particle methods and relate their computational structure to that of the kernel method for density estimation. Particle methods are widely used in several applications <ref> [4, 23, 44, 71] </ref>. These typically involve a set of particles represented as points in some space, and a function that describes the interaction between pairs of particles.
Reference: [5] <author> M.J. Berger and S.H. Bokhari. </author> <title> A partitioning strategy for nonuniform problems on multiprocessor. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36:570-580, </volume> <year> 1987. </year>
Reference-contexts: The outline of the rest of this chapter is as follows. Section 3.1 describes graph-theoretical and geometric domain decomposition strategies as they apply to particle methods on the sphere. The algorithm we present in Section 3.2 is essentially a geometric partitioning based on Orthogonal Recursive Bisection <ref> [5] </ref>. However, we take advantage of the geometry of the sphere to produce partitions with quality comparable to sophisticated methods such as spectral partitioning. Experimental results and comparisons with other popular schemes available in Chaco, version 2.0 [25] and Metis, version 2.0.3 [33] are presented in Section 3.3.
Reference: [6] <author> P.K. Bhattacharya. </author> <title> Estimation of a probability density function and its derivatives. </title> <journal> Sankhya Ser. A, </journal> <volume> 29 </volume> <pages> 373-382, </pages> <year> 1967. </year>
Reference-contexts: Generally, convergence of the derivative requires stronger conditions. It can be shown that the conditions for convergence of the derivatives require a slower rate of decrease of the window width than for the estimate of the density <ref> [66, 47, 6] </ref>. 2.4 Smoothed Particle Hydrodynamics In the following section we show how the above methods of nonparamet-ric density estimation can be incorporated into a dynamical simulation. <p> It converges if and only if m 2r+1 ( log n n ) ! 0 as n ! 0. This ends the proof of 4.17. To complete the proof of the theorem, we need to prove 4.18. The trick we use is a generalization of an identity of <ref> [6] </ref>: If ; 2 C r (IR) have uniformly continuous r-th derivatives then it can be shown that (r) (x u) (u) = (x u) (r) (u) du s=0 75 where the superscripts on refer to derivatives with respect to x.
Reference: [7] <author> M.G. </author> <title> Bulmer. </title> <booktitle> Principles of Statistics. </booktitle> <publisher> Dover Publications, </publisher> <address> New York, </address> <year> 1979. </year>
Reference: [8] <author> B.M. Chazelle and H. Edelsbrunner. </author> <title> Optimal solutions for a class of point retrieval problems. </title> <type> Technical Report CS-84-16, Tech. Rep. </type> <institution> CS-84-16, Dept. of Computer Science, Brown University, </institution> <year> 1984. </year> <month> 144 </month>
Reference-contexts: Since we are required to perform updates such as insertion and deletion, we can use any of the dynamic update methods reviewed in [10]. Algorithms also exist for searching on a disc <ref> [8] </ref>. However, often simpler procedures are sufficient. For example, a simple range searching strategy that fits in with the rest of the computations, is to project the data onto one dimension [17]. Then we can sort this projected data and perform a range search based on the projected coordinates.
Reference: [9] <author> N.N. Chentsov. </author> <title> Estimation of unknown probability density based on observations. </title> <journal> Dokl. Akad. Nauk SSSR, </journal> <volume> 147 </volume> <pages> 45-48, </pages> <year> 1962. </year>
Reference-contexts: Early contributors to the theory of non-parametric estimation include N.V. Smirnov [61], M. Rosenblatt [56], E. Parzen [49], and N.N. Chentsov <ref> [9] </ref>. Extensive descriptions of various approaches to non-parametric estimation along with a comprehensive bibliography can be found in books by B.W. Silverman [60], and E.A. Nadaraya [47]. More recent developments are presented in books by Scott [58] and Wand and Jones [66].
Reference: [10] <author> Y. Chiang and R. Tamassia. </author> <title> Dynamic algorithms in computational geometry. </title> <booktitle> In Proceedings of the IEEE, </booktitle> <volume> volume 80, </volume> <pages> pages 1412-1434, </pages> <year> 1992. </year>
Reference-contexts: Range search in 2-D can be done in time O (n log n + K) time using the Willard-Lueker modification of the range tree [53]. Since we are required to perform updates such as insertion and deletion, we can use any of the dynamic update methods reviewed in <ref> [10] </ref>. Algorithms also exist for searching on a disc [8]. However, often simpler procedures are sufficient. For example, a simple range searching strategy that fits in with the rest of the computations, is to project the data onto one dimension [17].
Reference: [11] <author> D.L. Hicks, J.W. Swegle and S.W. Attaway. </author> <title> Smoothed particle hydrodynamics stability analysis. </title> <journal> J. Comp. Phys., </journal> <volume> 116 </volume> <pages> 123-134, </pages> <year> 1995. </year>
Reference-contexts: It has been observed in some situations that clustering of particles occurs at distances of the order of the window width <ref> [11] </ref>. We too observed this initially. This is due to the fact that most of the popular kernels have a continuous derivative which vanishes at the sample point. For example, we originally used the following kernel.
Reference: [12] <author> M. Doi and S.F. Edwards. </author> <title> The Theory of Polymer Dynamics. </title> <publisher> Oxford Press, </publisher> <address> New York, New York, </address> <year> 1986. </year>
Reference-contexts: The degree to which the molecules are mutually aligned can be characterized by an order parameter, which is usually a scalar measure of this alignment. The most successful kinetic theory model describing the behavior of LCPs is the one due to Doi <ref> [12] </ref>. The basic element of this model is a rigid axi-symmetric rod; the forces acting on the rods are of three types: hydrodynamic, Brownian, and nematic. The hydrodynamic forces account for the effect of the fluid flow. The Brownian forces tend to make the orientation distribution function uniform. <p> The change in the orientations of the polymer rods is given by the theory due to Doi <ref> [12] </ref> and can be written in the following form: @u = F H + F B + F N (5.7) where F H is the hydrodynamic effect due to the fluid flow and is given by F H = (rv : uu)rv u (5.8) F B is the effect of the
Reference: [13] <author> R.O. Duda and P.E. Hart. </author> <title> Pattern classification and scene analysis. </title> <publisher> John Wiley and sons, Inc., </publisher> <address> New York, New York, </address> <year> 1973. </year>
Reference-contexts: The form of Equation 5.13 suggests a simple scheme for choosing the new set of points. If we need to choose N rods, we can randomly select i N rods from each of the points P i . The expected value of thus obtained will satisfy Equation 5.13 <ref> [13] </ref>. However, this scheme suffers from two drawbacks. One of the problems with this scheme is that though the expected value may satisfy the desired equation, it may not actually give good results for small samples. <p> We specify a density function X that varies according to spatial 125 coordinate X in a prescribed manner. In our tests, we choose two points P 1 and P 2 at which we have a set of N rods drawn using the rejection-acceptance method <ref> [13] </ref>. We interpolate at a point P midway between these two point. We can estimate the density through the kernel estimator used in the experiments of Chapter 4. We characterize the error by the M ISE, since we know the underlying distribution P .
Reference: [14] <author> J. Edmonds. </author> <title> Paths, trees and flowers. </title> <journal> Canad. J. Math., </journal> <volume> 17 </volume> <pages> 449-467, </pages> <year> 1965. </year>
Reference-contexts: This problem has been well studied <ref> [14, 2, 29, 55] </ref> and there are polynomial algorithms that yield the optimal matching. However, these algorithms are still too slow for our purposes.
Reference: [15] <author> O Egecioglu and A. Srinivasan. </author> <title> Efficient nonparametric estimation of probability density functions. </title> <type> Technical Report TRCS95-21, </type> <institution> University of California at Santa Barbara, Santa Barbara, California, </institution> <year> 1995. </year>
Reference-contexts: Orthogonal series methods can be considered as being along these lines, since they use a series expansion for the function. However, their disadvantages are as mentioned earlier. In Chapter 4 an almost linear algorithm <ref> [15, 16] </ref> will be described for density estimation on the sphere, which is conceptually similar to some fast algorithms used in nbody calculations. <p> Geometry of phase space The domain of our problem is the surface of the unit sphere. Most of the convergence results in the existing literature are for Euclidean domains, though there has also been some work specifically for the sphere <ref> [64, 22, 15, 16] </ref>. However, we can still use the types of kernels used in Euclidean space since density is a local phenomenon, and a sphere is locally Euclidean. In addition, since our phase space is closed upon itself, boundary conditions are not present in this problem. <p> Thus, one may take the weight to be proportional to the density. If such data is not available, one may use non-parametric density estimation techniques to estimate the density <ref> [15, 16] </ref>. In our implementation of the domain decomposition algorithm on the sphere we have used positive integral weights, though using floating point weights does not present any additional difficulty.
Reference: [16] <author> O Egecioglu and A. Srinivasan. </author> <title> A fast nonparametric density estimation algorithm. </title> <note> Communications in Numerical Methods in Engineering, in review. </note>
Reference-contexts: Orthogonal series methods can be considered as being along these lines, since they use a series expansion for the function. However, their disadvantages are as mentioned earlier. In Chapter 4 an almost linear algorithm <ref> [15, 16] </ref> will be described for density estimation on the sphere, which is conceptually similar to some fast algorithms used in nbody calculations. <p> Geometry of phase space The domain of our problem is the surface of the unit sphere. Most of the convergence results in the existing literature are for Euclidean domains, though there has also been some work specifically for the sphere <ref> [64, 22, 15, 16] </ref>. However, we can still use the types of kernels used in Euclidean space since density is a local phenomenon, and a sphere is locally Euclidean. In addition, since our phase space is closed upon itself, boundary conditions are not present in this problem. <p> Thus, one may take the weight to be proportional to the density. If such data is not available, one may use non-parametric density estimation techniques to estimate the density <ref> [15, 16] </ref>. In our implementation of the domain decomposition algorithm on the sphere we have used positive integral weights, though using floating point weights does not present any additional difficulty.
Reference: [17] <author> F. Baskett, J.H. Friedman and L.J. Shustek. </author> <title> An algorithm for finding nearest neighbors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-24:1000-1006, </volume> <year> 1975. </year>
Reference-contexts: Algorithms also exist for searching on a disc [8]. However, often simpler procedures are sufficient. For example, a simple range searching strategy that fits in with the rest of the computations, is to project the data onto one dimension <ref> [17] </ref>. Then we can sort this projected data and perform a range search based on the projected coordinates. Due to the triangle inequality, this will retrieve a superset of the true set.
Reference: [18] <author> J. Fan and J.S. Marron. </author> <title> Fast implementations of nonparametric curve estimators. </title> <journal> Journal of Computational and Graphical Statistics, </journal> <volume> 3 </volume> <pages> 35-56, </pages> <year> 1994. </year>
Reference-contexts: One of the drawbacks of the kernel method is the computational cost involved. Even though it is possible to reduce the cost in the 1-dimensional case using the expansion of a polynomial kernel and an updating strategy [30], this strategy cannot be easily extended to higher dimensions <ref> [18] </ref>. Binning methods [18] can be used in any dimension. However, since the density in this case is evaluated on a uniform grid, this method is not suitable for the Lagrangian fluid flow calculations we are interested in. <p> Even though it is possible to reduce the cost in the 1-dimensional case using the expansion of a polynomial kernel and an updating strategy [30], this strategy cannot be easily extended to higher dimensions <ref> [18] </ref>. Binning methods [18] can be used in any dimension. However, since the density in this case is evaluated on a uniform grid, this method is not suitable for the Lagrangian fluid flow calculations we are interested in. <p> We shall see later that the cosine estimator is significantly faster than the kernel method when the underlying distribution is not very non-uniform. Note that there appears to be no natural generalization of the update strategy for higher dimensions <ref> [18] </ref>, and so this efficient implementation does not seem likely on the sphere.
Reference: [19] <author> C.A.J. Fletcher. </author> <title> Computational Techniques for Fluid Dynamics. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, Germany, </address> <year> 1991. </year>
Reference-contexts: Further information on computing the derivatives on a mesh in the solution of differential equations arising in fluid flow calculations can be found in <ref> [19, 50] </ref>. It should be noted that we should avoid the temptation to define the pressures at the centers. It is tempting to do this for the following reason. We require the divergence of the velocity in order to compute the pressure. <p> We can obtain t N too using Equation 5.3. We update the pressure as follows <ref> [19, 50, 70] </ref> based on the artificial compressibility method: @P = *r v (5.11) The time used in this equation is a fictitious time and has nothing to do with the time step used in the main iteration.
Reference: [20] <author> R.A. Gingold and J.J. Monaghan. </author> <title> Kernel estimates as a basis for general particle methods in hydrodynamics. </title> <journal> J. Comput. Phys., </journal> <volume> 46 </volume> <pages> 429-453, </pages> <year> 1982. </year> <month> 145 </month>
Reference-contexts: We shall later also discuss the accuracy of the gradient calculations in Section 2.4.3. In order to overcome this difficulty with distortion in a mesh based La-grangian scheme, several so-called "particle methods" were invented for fluid flow [23, 41, 65]. Most of these methods shared a common feature <ref> [20] </ref>, namely, the use of a combination of an Eulerian mesh, and a set of Lagrangian points, or "particles". An early example of these schemes was the Particle In Cell (PIC) method [23]. <p> The disadvantages of this scheme is the extra memory required for the Eulerian mesh, and the inaccuracy of the interpolation from the particles to the Eulerian mesh. Smoothed Particle Hydrodynamics <ref> [20, 45] </ref> can be considered a generalization of PIC. One can consider this scheme conceptually as an extension of PIC with a more sophisticated density estimation technique, namely, the kernel method. <p> Although a Gaussian form for K has been found to give good results <ref> [20] </ref>, a desirable property for the kernel to posses is that it have bounded support, which implies that it becomes identically zero when its argument is sufficiently large.
Reference: [21] <author> I.S. Gradshteyn and I.M. Ryzhik. </author> <title> Table of Integrals Series, and Products. </title> <publisher> Academic Press, Inc., </publisher> <address> Orlando, </address> <year> 1980. </year>
Reference-contexts: Making use of a table of integrals such as Gradshteyn/Ryzhik <ref> [21] </ref> and by using Stirling's formula, it can be shown that A m = 2 2m1 2m ! 2 m We wish to find sufficient conditions under which the sequence of estimators f n converges to f in the Mean Integrated Square Error (MISE) sense.
Reference: [22] <author> G.S. Watson, P. Hall and J. Cabrera. </author> <title> Kernel density estimation with spherical data. </title> <journal> J. Comput. Phys., </journal> <volume> 74 </volume> <pages> 751-762, </pages> <year> 1987. </year>
Reference-contexts: Geometry of phase space The domain of our problem is the surface of the unit sphere. Most of the convergence results in the existing literature are for Euclidean domains, though there has also been some work specifically for the sphere <ref> [64, 22, 15, 16] </ref>. However, we can still use the types of kernels used in Euclidean space since density is a local phenomenon, and a sphere is locally Euclidean. In addition, since our phase space is closed upon itself, boundary conditions are not present in this problem. <p> The kernel method for nonparametric density estimation for directional 68 and axial data is discussed in <ref> [64, 22] </ref>. <p> W n (P; P i ) plays the role of K (x X i ) of Equation 4.1. Hall, Watson and Cabrera <ref> [22] </ref> analyze estimators for directional data with the x X i term of Equation 4.1 replaced by 1 x T X i .
Reference: [23] <author> F.H. Harlow. </author> <title> The particle-in-cell computing method for fluid dynamics. </title> <booktitle> Methods in Computational Physics, </booktitle> <volume> 3 </volume> <pages> 319-343, </pages> <year> 1964. </year>
Reference-contexts: We shall later also discuss the accuracy of the gradient calculations in Section 2.4.3. In order to overcome this difficulty with distortion in a mesh based La-grangian scheme, several so-called "particle methods" were invented for fluid flow <ref> [23, 41, 65] </ref>. Most of these methods shared a common feature [20], namely, the use of a combination of an Eulerian mesh, and a set of Lagrangian points, or "particles". An early example of these schemes was the Particle In Cell (PIC) method [23]. <p> Most of these methods shared a common feature [20], namely, the use of a combination of an Eulerian mesh, and a set of Lagrangian points, or "particles". An early example of these schemes was the Particle In Cell (PIC) method <ref> [23] </ref>. This method involves an interpolation between a Lagrangian set of particles and an Eulerian grid, then certain calculations on the Eulerian grid, and finally an interpolation between the Eulerian grid and the Lagrangian particles at each iteration. The histogram method of density estimation forms the basis for PIC. <p> Thus the computational structure of these computations is the same as that of particle methods with short-range interactions. We next describe particle methods and relate their computational structure to that of the kernel method for density estimation. Particle methods are widely used in several applications <ref> [4, 23, 44, 71] </ref>. These typically involve a set of particles represented as points in some space, and a function that describes the interaction between pairs of particles.
Reference: [24] <author> B. Hendrickson and R. Leland. </author> <title> A multilevel algorithm for partitioning graphs. </title> <type> Technical Report SAND93-1301, </type> <institution> Sandia National Laboratories, </institution> <year> 1993. </year>
Reference-contexts: We show how our domain decomposition strategy facilitates efficient implementation of other operations on the data. Conclusions are given in Section 3.5. 3.1 Domain Decomposition Domain decomposition has been widely studied <ref> [25, 24, 33, 69, 34] </ref> and several types of methods for its solution have been proposed: graph-theoretical and geometric, for example. Graph-theoretical schemes ignore coordinate information and treat domain decomposition as a general graph partitioning problem. <p> Graph-theoretical algorithms such as spectral methods produce high quality partitions especially when combined with a local refinement strategy [34], but require too much time. When combined with multilevel methods, these give good partitions much faster <ref> [24] </ref>, however, they are still not fast enough to be used frequently. Since the distribution of the points could change significantly in the types of application we are considering, the quality of the partitions may degrade quickly. <p> We chose a value of h such that it gave a reasonably good estimate when using kernels for non-parametric estimation of the probability density. We compared our algorithm with general graph partitioning algorithms, since these have been found to give good quality partitions <ref> [24] </ref>. We also compared our scheme with the Inertial Method, since this is a geometric method which is much faster than the general graph partitioning methods. For problems of large size, even the multilevel graph partitioning algorithms were at least two orders of magnitude slower than our algorithm.
Reference: [25] <author> B. Hendrickson and R. Leland. </author> <title> The Chaco user's guide, version 2.0. </title> <type> Technical Report SAND95-2344, </type> <institution> Sandia National Laboratories, </institution> <year> 1995. </year>
Reference-contexts: However, we take advantage of the geometry of the sphere to produce partitions with quality comparable to sophisticated methods such as spectral partitioning. Experimental results and comparisons with other popular schemes available in Chaco, version 2.0 <ref> [25] </ref> and Metis, version 2.0.3 [33] are presented in Section 3.3. These experiments show that our algorithm is an order of magnitude faster than even the relatively fast inertial method for large problem sizes, and demonstrate the high quality of the partitions obtained. <p> We show how our domain decomposition strategy facilitates efficient implementation of other operations on the data. Conclusions are given in Section 3.5. 3.1 Domain Decomposition Domain decomposition has been widely studied <ref> [25, 24, 33, 69, 34] </ref> and several types of methods for its solution have been proposed: graph-theoretical and geometric, for example. Graph-theoretical schemes ignore coordinate information and treat domain decomposition as a general graph partitioning problem. <p> With cut-through routing being widely prevalent, this criterion seems justified. However, it should be noted that too many messages in the system could cause network congestion and the number of links traversed could affect the true communication cost <ref> [25] </ref>. Our communication measure also differs from the commonly used edge-cut metric in graph partitioning which tries to minimize the number of edges cut.
Reference: [26] <author> L. Hernquist and N. Katz. TREESPH: </author> <title> A unification of SPH with the heirar-chical tree method. Astrophys. </title> <journal> J. </journal> <volume> suppl., 70 </volume> <pages> 419-446, </pages> <year> 1989. </year>
Reference-contexts: It should be noted that in some computations, especially in those involving gravitational forces, a tree-code similar to the Barnes-Hut scheme has been tried <ref> [26] </ref>, since it fits in with the rest of the computations. 2.6 Test Results In this section we present results of our numerical simulations. We consider the following cases: (i) uniaxial elongational flow, and (ii) simple shear flow, both with various values for the nematic potential strength.
Reference: [27] <author> C.C. Hua and J.D. Schieber. </author> <title> Nonequilibrium Brownian dynamics simulations of Hookean and FENE dumbbells with internal viscosity. </title> <journal> Journal of Non-Newtonian Fluid Mechanics, </journal> <volume> 3 </volume> <pages> 307-332, </pages> <year> 1995. </year>
Reference-contexts: It is also informative to compare SPH method as applied to kinetic theory with other methods of simulating complex fluids. A popular alternative to our approach is using Brownian Dynamics. These techniques, however, typically require vast numbers of particles, anywhere from 10 4 to 10 5 <ref> [37, 27] </ref>. Whether this actually results in shorter computations would again depend on the development of efficient algorithms.
Reference: [28] <author> J. Hwang. </author> <title> Nonparametric multivariate density estimation: A comparative study. </title> <journal> IEEE Trans. Signal Processing, </journal> <volume> 42 </volume> <pages> 2795-2810, </pages> <year> 1994. </year>
Reference-contexts: This problem of nonparametric density estimation has been well studied. Good descriptions of various methods and their analyses can be found in [60, 47]. Results of the comparison of some widely used methods is also given in <ref> [28, 54] </ref>. Various methods have been proposed for nonparametric density estimation, for example, histograms, kernel methods [49, 51, 67], orthogonal series methods [57, 36], the nearest neighbor method [60], etc. The Histogram method is the simplest to implement. It divides the domain into a number of cells. <p> Silverman [60], and E.A. Nadaraya [47]. More recent developments are presented in books by Scott [58] and Wand and Jones [66]. Results of the experimental comparison of some widely used methods appear in <ref> [28, 54] </ref>. Along with applications in data analysis, an important application of density estimation is in computational fluid mechanics as in the application we have been considering.
Reference: [29] <author> C. Imielinska and B. Kalantari. </author> <title> A generalized hypergreedy algorithm for weighted perfect matching. </title> <journal> BIT, </journal> <volume> 33 </volume> <pages> 178-189, </pages> <year> 1993. </year>
Reference-contexts: This problem has been well studied <ref> [14, 2, 29, 55] </ref> and there are polynomial algorithms that yield the optimal matching. However, these algorithms are still too slow for our purposes.
Reference: [30] <author> J. Engel, B. Seifert, M. Brockmann and T. Gasser. </author> <title> Fast algorithms for nonpara-metric curve estimation. </title> <journal> Journal of Computational and Graphical Statistics, </journal> <volume> 3 </volume> <pages> 192-213, </pages> <year> 1994. </year>
Reference-contexts: One of the drawbacks of the kernel method is the computational cost involved. Even though it is possible to reduce the cost in the 1-dimensional case using the expansion of a polynomial kernel and an updating strategy <ref> [30] </ref>, this strategy cannot be easily extended to higher dimensions [18]. Binning methods [18] can be used in any dimension. However, since the density in this case is evaluated on a uniform grid, this method is not suitable for the Lagrangian fluid flow calculations we are interested in. <p> Note that the worst case complexity remains as in Equation 4.56. For the 1-dimensional case, we can consider an efficient algorithm using polynomial kernels and updating <ref> [30] </ref> that uses a linear time after an initial O (n log n) sorting step. Thus we can take fi = 0 and fl = 1 to get C = E 1:25 (4.58) and then the kernel method has a much better asymptotic complexity than the cosine kernel.
Reference: [31] <author> J.M. Rallison, O.G. Harlen and P. Szabo. </author> <title> A split Lagrangian Eulerian method for simulating transient viscoelastic flows. </title> <journal> Journal of Non-Newtonian Fluid Mechanics, </journal> <volume> 60 </volume> <pages> 81-104, </pages> <year> 1995. </year> <month> 146 </month>
Reference-contexts: Our mesh consists of triangular elements <ref> [31] </ref>. As our initial mesh, we start with a rectangular grid as shown by the thick lines in Figure 5.2, and then triangulate it. The input to our algorithms will specify the number of rows and columns in this rectangular grid.
Reference: [32] <author> M.C. Jones and H.W. Lotwick. </author> <title> A remark on algorithm as 176. kernel density estimation using the fast Fourier transform. </title> <journal> Appl. Statist., </journal> <volume> 33 </volume> <pages> 120-122, </pages> <year> 1984. </year>
Reference: [33] <author> G. Karypis and V. Kumar. Metis, </author> <title> unstructured graph partitioning and sparse matrix ordering system, version 2.0. </title> <type> Technical report, </type> <institution> Dept. of Computer Science, University of Minnesota, </institution> <year> 1995. </year>
Reference-contexts: However, we take advantage of the geometry of the sphere to produce partitions with quality comparable to sophisticated methods such as spectral partitioning. Experimental results and comparisons with other popular schemes available in Chaco, version 2.0 [25] and Metis, version 2.0.3 <ref> [33] </ref> are presented in Section 3.3. These experiments show that our algorithm is an order of magnitude faster than even the relatively fast inertial method for large problem sizes, and demonstrate the high quality of the partitions obtained. <p> We show how our domain decomposition strategy facilitates efficient implementation of other operations on the data. Conclusions are given in Section 3.5. 3.1 Domain Decomposition Domain decomposition has been widely studied <ref> [25, 24, 33, 69, 34] </ref> and several types of methods for its solution have been proposed: graph-theoretical and geometric, for example. Graph-theoretical schemes ignore coordinate information and treat domain decomposition as a general graph partitioning problem.
Reference: [34] <author> B.W. Kernighan and S. Lin. </author> <title> An efficient heuristic procedure for partitioning graphs. </title> <journal> Bell System Technical Journal, </journal> <year> 1970. </year>
Reference-contexts: We show how our domain decomposition strategy facilitates efficient implementation of other operations on the data. Conclusions are given in Section 3.5. 3.1 Domain Decomposition Domain decomposition has been widely studied <ref> [25, 24, 33, 69, 34] </ref> and several types of methods for its solution have been proposed: graph-theoretical and geometric, for example. Graph-theoretical schemes ignore coordinate information and treat domain decomposition as a general graph partitioning problem. <p> The processor that receives the data can store this and reuse it when needed. In contrast to the edge-cut metric, our communication cost takes this factor into account as well. Graph-theoretical algorithms such as spectral methods produce high quality partitions especially when combined with a local refinement strategy <ref> [34] </ref>, but require too much time. When combined with multilevel methods, these give good partitions much faster [24], however, they are still not fast enough to be used frequently.
Reference: [35] <author> D.E. Knuth. </author> <booktitle> The Art of Computer Programming, </booktitle> <volume> Vol. 2, </volume> <booktitle> Seminumerical Algorithms. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Menlo Park, Massachusetts, </address> <year> 1968. </year>
Reference: [36] <author> R. Kronmal and M. Tarter. </author> <title> The estimation of probability densities and cu-mulatives by Fourier series methods. </title> <journal> American Statist. Association J., </journal> <pages> pages 925-952, </pages> <year> 1968. </year>
Reference-contexts: Good descriptions of various methods and their analyses can be found in [60, 47]. Results of the comparison of some widely used methods is also given in [28, 54]. Various methods have been proposed for nonparametric density estimation, for example, histograms, kernel methods [49, 51, 67], orthogonal series methods <ref> [57, 36] </ref>, the nearest neighbor method [60], etc. The Histogram method is the simplest to implement. It divides the domain into a number of cells. The probability density function of a cell is taken to be proportional to the number of samples in the cell. <p> In general, it is expected that the noise will be less in flow calculations than in samples drawn at random from a probability density function. However, it is preferable to use a scheme that is less sensitive to noise. Yet another approach is the orthogonal series method <ref> [57, 36] </ref> which approximates the density by a series expansion, and determines the coefficients from the locations of the sample points. One of the problems that could occur in these methods is that the series approximation can give a negative density estimate in low density regions. <p> Otherwise, we deal with directional data. Various methods have been proposed for non-parametric density estimation 66 in mathematical statistics, such as the kernel [49, 51, 67] and the orthogonal series methods <ref> [57, 36] </ref>. The kernel method has been extensively studied, and it is probably the most popular scheme in applications such as SPH.
Reference: [37] <author> R.G. Larson and H.C. Ottinger. </author> <title> Effect of molecular elasticity on out-of-plane orientations in shearing flows of liquid crystalline polymers. </title> <journal> Macromolecules, </journal> <volume> 24 </volume> <pages> 6270-6282, </pages> <year> 1991. </year>
Reference-contexts: It is also informative to compare SPH method as applied to kinetic theory with other methods of simulating complex fluids. A popular alternative to our approach is using Brownian Dynamics. These techniques, however, typically require vast numbers of particles, anywhere from 10 4 to 10 5 <ref> [37, 27] </ref>. Whether this actually results in shorter computations would again depend on the development of efficient algorithms. <p> This demonstrates the procedure for obtaining convergence by simultaneously changing h and n described earlier. The results of our study indicate that good results can be obtained for around 600 points. In comparison, a simulation performed on a slightly different LCP model using Brownian Dynamics required 10 4 points <ref> [37] </ref>.
Reference: [38] <author> S.S. Lavenberg. </author> <title> Computer Performance Modeling Handbook. </title> <publisher> Academic Press Inc., </publisher> <address> New York, New York, </address> <year> 1983. </year>
Reference: [39] <author> F.T. Leighton. </author> <title> Introduction to parallel algorithms and architectures : arrays, trees, hypercubes. </title> <editor> M. </editor> <publisher> Kaufmann Publishers, </publisher> <address> San Mateo, California, </address> <year> 1992. </year>
Reference-contexts: Our algorithm produces a mapping for a tree topology, with the processors located at the leaves of the tree. This is not unduly restrictive since efficient schemes exist for embedding trees into other topologies <ref> [39] </ref>. We use a recursive bisection procedure. At each stage, we first consider a cut on the subregion along the latitude that gives a balanced load, and also a longitudinal cut that gives a balanced load.
Reference: [40] <author> M. Loeve. </author> <title> Probability Theory. </title> <address> D. </address> <publisher> Van Nostrand Co. Inc., </publisher> <address> Princeton, New Jersey, </address> <year> 1963. </year>
Reference: [41] <author> B.M. Marder. </author> <title> GAP a PIC-type fluid code. </title> <journal> Mathematics of Computation, </journal> <volume> 29 </volume> <pages> 434-446, </pages> <year> 1975. </year>
Reference-contexts: We shall later also discuss the accuracy of the gradient calculations in Section 2.4.3. In order to overcome this difficulty with distortion in a mesh based La-grangian scheme, several so-called "particle methods" were invented for fluid flow <ref> [23, 41, 65] </ref>. Most of these methods shared a common feature [20], namely, the use of a combination of an Eulerian mesh, and a set of Lagrangian points, or "particles". An early example of these schemes was the Particle In Cell (PIC) method [23].
Reference: [42] <author> A.I. Markushevich. </author> <title> Theory of Functions of a Complex Variable, volume 2. </title> <publisher> Chelsea Publishing Company, </publisher> <address> New York, New York, </address> <year> 1985. </year> <month> 147 </month>
Reference: [43] <author> M.J. Crochet, A.R. Davies and K. Walters. </author> <title> Numerical SImulation of Non-Newtonian Flow. </title> <publisher> Elsevier, </publisher> <address> Amsterdam, Netherlands, </address> <year> 1984. </year>
Reference-contexts: Thus this computational strategy is infeasible. It has been conjectured that a good discretization will have half the number of pressures as velocity components <ref> [43] </ref>; a requirement our discretization satisfies. The orientation distribution function depends on the velocity gradient, and hence it is convenient to place the polymer rods at the centers for the reasons mentioned above.
Reference: [44] <author> J.J. Monaghan. </author> <title> Particle methods for hydrodynamics. </title> <journal> Computer Physics Reports, </journal> <volume> 3 </volume> <pages> 71-124, </pages> <year> 1985. </year>
Reference-contexts: Generally, it has been suggested that h (r) d / (r) 1 be used <ref> [44] </ref> in a d dimensional domain. This is consistent with our formula if we let ~ approach 0 as the sample size increases, since we are in a two dimensional domain. <p> Thus the computational structure of these computations is the same as that of particle methods with short-range interactions. We next describe particle methods and relate their computational structure to that of the kernel method for density estimation. Particle methods are widely used in several applications <ref> [4, 23, 44, 71] </ref>. These typically involve a set of particles represented as points in some space, and a function that describes the interaction between pairs of particles. <p> There are different options available to obtain a reasonable estimate of what the weight should be. A large class of problems involves compressible fluid flow calculations in which the density of the fluid has to be determined <ref> [44] </ref>. For sufficiently small h, the number of points within 44 a distance h of any point is approximately proportional to the density at the point. Thus, one may take the weight to be proportional to the density.
Reference: [45] <author> J.J. Monaghan. </author> <title> Smoothed particle hydrodynamics. Annu. </title> <journal> Rev. Astron. Astro-phys, </journal> <volume> 30 </volume> <pages> 543-574, </pages> <year> 1992. </year>
Reference-contexts: The disadvantages of this scheme is the extra memory required for the Eulerian mesh, and the inaccuracy of the interpolation from the particles to the Eulerian mesh. Smoothed Particle Hydrodynamics <ref> [20, 45] </ref> can be considered a generalization of PIC. One can consider this scheme conceptually as an extension of PIC with a more sophisticated density estimation technique, namely, the kernel method. <p> The equations used in SPH algorithms are most often given in the context of astrodynamical calculations <ref> [46, 45] </ref>. Here, we give them in the context of our particular problem; each particular application would involve slightly different versions.
Reference: [46] <author> J.J. Monaghan and J.C. Lattanzio. </author> <title> A refined particle method for astrophysical problems. </title> <journal> Astron. Astrophys, </journal> <volume> 149 </volume> <pages> 135-143, </pages> <year> 1985. </year>
Reference-contexts: The equations used in SPH algorithms are most often given in the context of astrodynamical calculations <ref> [46, 45] </ref>. Here, we give them in the context of our particular problem; each particular application would involve slightly different versions. <p> However, in a parallel implementation, the sorting step for the linear kernel algorithm may be slow and then one may wish to consider the cosine estimator. The following kernel <ref> [46] </ref> was chosen for the comparisons: K (x) = &gt; &gt; &gt; &lt; 1 1 0 otherwise where A is the normalization constant, and the ratio of the distance between two points along the surface of the sphere to h is given as the argument to the kernel function.
Reference: [47] <author> E.A. Nadaraya. </author> <title> Nonparametric Estimation of Probability Densities and Regression Curves, </title> <booktitle> volume 1 of Mathematics and Applications (Soviet Series). </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <address> Reading, Massachusetts, </address> <year> 1989. </year>
Reference-contexts: This problem of nonparametric density estimation has been well studied. Good descriptions of various methods and their analyses can be found in <ref> [60, 47] </ref>. Results of the comparison of some widely used methods is also given in [28, 54]. Various methods have been proposed for nonparametric density estimation, for example, histograms, kernel methods [49, 51, 67], orthogonal series methods [57, 36], the nearest neighbor method [60], etc. <p> Generally, convergence of the derivative requires stronger conditions. It can be shown that the conditions for convergence of the derivatives require a slower rate of decrease of the window width than for the estimate of the density <ref> [66, 47, 6] </ref>. 2.4 Smoothed Particle Hydrodynamics In the following section we show how the above methods of nonparamet-ric density estimation can be incorporated into a dynamical simulation. <p> Early contributors to the theory of non-parametric estimation include N.V. Smirnov [61], M. Rosenblatt [56], E. Parzen [49], and N.N. Chentsov [9]. Extensive descriptions of various approaches to non-parametric estimation along with a comprehensive bibliography can be found in books by B.W. Silverman [60], and E.A. Nadaraya <ref> [47] </ref>. More recent developments are presented in books by Scott [58] and Wand and Jones [66]. Results of the experimental comparison of some widely used methods appear in [28, 54].
Reference: [48] <author> H.C. Ottinger. </author> <title> Stochastic Processes in Polymeric Fluids. </title> <publisher> Springer, </publisher> <address> Berlin, Germany, </address> <year> 1996. </year>
Reference-contexts: We also present results where the solution is not known analytically, and the results match the expected trends. We also wish to mention that alternative approaches to solving the problem we have studied can be based on methods explained in <ref> [48] </ref>. 141 Chapter 6 Conclusions In this section, we summarize the results of our work and provide suggestions for future work. This thesis was concerned with the computational issues that frequently arise in several scientific computing problems, such as parallelization, irregular computations, etc.
Reference: [49] <author> E. Parzen. </author> <title> On estimation of a probability density function and mode. </title> <journal> Ann. Math. Statist., </journal> <volume> 33 </volume> <pages> 1065-1076, </pages> <year> 1962. </year>
Reference-contexts: Good descriptions of various methods and their analyses can be found in [60, 47]. Results of the comparison of some widely used methods is also given in [28, 54]. Various methods have been proposed for nonparametric density estimation, for example, histograms, kernel methods <ref> [49, 51, 67] </ref>, orthogonal series methods [57, 36], the nearest neighbor method [60], etc. The Histogram method is the simplest to implement. It divides the domain into a number of cells. <p> This is in contrast to parametric estimation in which the density is assumed to come from a given family, and the parameters are then estimated by various statistical methods. Early contributors to the theory of non-parametric estimation include N.V. Smirnov [61], M. Rosenblatt [56], E. Parzen <ref> [49] </ref>, and N.N. Chentsov [9]. Extensive descriptions of various approaches to non-parametric estimation along with a comprehensive bibliography can be found in books by B.W. Silverman [60], and E.A. Nadaraya [47]. More recent developments are presented in books by Scott [58] and Wand and Jones [66]. <p> Otherwise, we deal with directional data. Various methods have been proposed for non-parametric density estimation 66 in mathematical statistics, such as the kernel <ref> [49, 51, 67] </ref> and the orthogonal series methods [57, 36]. The kernel method has been extensively studied, and it is probably the most popular scheme in applications such as SPH.
Reference: [50] <author> R. Peyret and T.D. Taylor. </author> <title> Computational Methods for Fluid Flow. </title> <publisher> Springer-Verlag, </publisher> <address> New York, New York, </address> <year> 1990. </year>
Reference-contexts: Further information on computing the derivatives on a mesh in the solution of differential equations arising in fluid flow calculations can be found in <ref> [19, 50] </ref>. It should be noted that we should avoid the temptation to define the pressures at the centers. It is tempting to do this for the following reason. We require the divergence of the velocity in order to compute the pressure. <p> We can obtain t N too using Equation 5.3. We update the pressure as follows <ref> [19, 50, 70] </ref> based on the artificial compressibility method: @P = *r v (5.11) The time used in this equation is a fictitious time and has nothing to do with the time step used in the main iteration.
Reference: [51] <author> P.J. Bickel and M. Rosenblatt. </author> <title> On some global measures of the deviations of density function estimates. </title> <journal> Annals of Statistics, </journal> <volume> 1 </volume> <pages> 1071-1095, </pages> <year> 1973. </year>
Reference-contexts: Good descriptions of various methods and their analyses can be found in [60, 47]. Results of the comparison of some widely used methods is also given in [28, 54]. Various methods have been proposed for nonparametric density estimation, for example, histograms, kernel methods <ref> [49, 51, 67] </ref>, orthogonal series methods [57, 36], the nearest neighbor method [60], etc. The Histogram method is the simplest to implement. It divides the domain into a number of cells. <p> Otherwise, we deal with directional data. Various methods have been proposed for non-parametric density estimation 66 in mathematical statistics, such as the kernel <ref> [49, 51, 67] </ref> and the orthogonal series methods [57, 36]. The kernel method has been extensively studied, and it is probably the most popular scheme in applications such as SPH.
Reference: [52] <author> S. Plimpton. </author> <title> Fast parallel algorithms for short-range molecular dynamics. </title> <journal> J. Comp. Phys., </journal> <volume> 117 </volume> <pages> 1-19, </pages> <year> 1995. </year>
Reference-contexts: This method produces partitions which are usually of a higher quality than those produced by ORB, at the expense of a slight increase in the computational effort required to produce the partitions. Alternate approaches to parallelization of particle methods can be found in <ref> [52] </ref>. Our scheme resembles ORB, but takes advantage of certain metric properties of the surface of the sphere to give good partitions.
Reference: [53] <author> F.P. Preparata and M.I. Shamos. </author> <title> Computational Geometry. </title> <publisher> Springer-Verlag, </publisher> <address> New York, New York, </address> <year> 1985. </year>
Reference-contexts: We wish to determine the contribution of only those points within a certain cut-off distance. This is the problem of range searching. Several algorithms have been proposed in computational geometry literature <ref> [53] </ref> for effective range searching. The more sophisticated algorithms are faster than the cruder methods only when the number of particles is much larger than we consider in our application. Hence simpler algorithms can be used when the number of particles is reasonable. <p> We require two searches if the required region spans the 0 longitude. Range search in 2-D can be done in time O (n log n + K) time using the Willard-Lueker modification of the range tree <ref> [53] </ref>. Since we are required to perform updates such as insertion and deletion, we can use any of the dynamic update methods reviewed in [10]. Algorithms also exist for searching on a disc [8]. However, often simpler procedures are sufficient.
Reference: [54] <author> R. Vio, G. Fasano, M. Lazzarin and O. Lessi. </author> <title> Probability density estimation in astronomy. </title> <journal> Astron. Astrophys., </journal> <volume> 289 </volume> <pages> 640-648, </pages> <year> 1994. </year> <month> 148 </month>
Reference-contexts: This problem of nonparametric density estimation has been well studied. Good descriptions of various methods and their analyses can be found in [60, 47]. Results of the comparison of some widely used methods is also given in <ref> [28, 54] </ref>. Various methods have been proposed for nonparametric density estimation, for example, histograms, kernel methods [49, 51, 67], orthogonal series methods [57, 36], the nearest neighbor method [60], etc. The Histogram method is the simplest to implement. It divides the domain into a number of cells. <p> Silverman [60], and E.A. Nadaraya [47]. More recent developments are presented in books by Scott [58] and Wand and Jones [66]. Results of the experimental comparison of some widely used methods appear in <ref> [28, 54] </ref>. Along with applications in data analysis, an important application of density estimation is in computational fluid mechanics as in the application we have been considering.
Reference: [55] <author> E.M. Reingold and R.E. Tarjan. </author> <title> On a greedy heuristic for complete matching. </title> <journal> SIAM J. Comput., </journal> <volume> 10 </volume> <pages> 676-681, </pages> <year> 1981. </year>
Reference-contexts: This problem has been well studied <ref> [14, 2, 29, 55] </ref> and there are polynomial algorithms that yield the optimal matching. However, these algorithms are still too slow for our purposes.
Reference: [56] <author> M. Rosenblatt. </author> <title> Remarks on some non-parametric estimates of a density function. </title> <journal> Ann. Math. Statist., </journal> <volume> 27 </volume> <pages> 832-837, </pages> <year> 1956. </year>
Reference-contexts: This is in contrast to parametric estimation in which the density is assumed to come from a given family, and the parameters are then estimated by various statistical methods. Early contributors to the theory of non-parametric estimation include N.V. Smirnov [61], M. Rosenblatt <ref> [56] </ref>, E. Parzen [49], and N.N. Chentsov [9]. Extensive descriptions of various approaches to non-parametric estimation along with a comprehensive bibliography can be found in books by B.W. Silverman [60], and E.A. Nadaraya [47]. More recent developments are presented in books by Scott [58] and Wand and Jones [66].
Reference: [57] <author> S.C. Schwartz. </author> <title> Estimation of probability density by an orthogonal series. </title> <journal> Ann. Math. Statist., </journal> <volume> 38 </volume> <pages> 1261-1265, </pages> <year> 1967. </year>
Reference-contexts: Good descriptions of various methods and their analyses can be found in [60, 47]. Results of the comparison of some widely used methods is also given in [28, 54]. Various methods have been proposed for nonparametric density estimation, for example, histograms, kernel methods [49, 51, 67], orthogonal series methods <ref> [57, 36] </ref>, the nearest neighbor method [60], etc. The Histogram method is the simplest to implement. It divides the domain into a number of cells. The probability density function of a cell is taken to be proportional to the number of samples in the cell. <p> In general, it is expected that the noise will be less in flow calculations than in samples drawn at random from a probability density function. However, it is preferable to use a scheme that is less sensitive to noise. Yet another approach is the orthogonal series method <ref> [57, 36] </ref> which approximates the density by a series expansion, and determines the coefficients from the locations of the sample points. One of the problems that could occur in these methods is that the series approximation can give a negative density estimate in low density regions. <p> There are also results for some series estimators suggesting that stronger conditions on the true density are required for them to give the same optimal convergence rates as kernel estimators <ref> [57] </ref>. <p> Otherwise, we deal with directional data. Various methods have been proposed for non-parametric density estimation 66 in mathematical statistics, such as the kernel [49, 51, 67] and the orthogonal series methods <ref> [57, 36] </ref>. The kernel method has been extensively studied, and it is probably the most popular scheme in applications such as SPH.
Reference: [58] <author> D.W. Scott. </author> <title> Multivariate Density Estimation. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, New York, </address> <year> 1992. </year>
Reference-contexts: Smirnov [61], M. Rosenblatt [56], E. Parzen [49], and N.N. Chentsov [9]. Extensive descriptions of various approaches to non-parametric estimation along with a comprehensive bibliography can be found in books by B.W. Silverman [60], and E.A. Nadaraya [47]. More recent developments are presented in books by Scott <ref> [58] </ref> and Wand and Jones [66]. Results of the experimental comparison of some widely used methods appear in [28, 54]. Along with applications in data analysis, an important application of density estimation is in computational fluid mechanics as in the application we have been considering.
Reference: [59] <author> B.W. Silverman. </author> <title> Kernel density estimation using the fast Fourier transform. </title> <journal> Appl. Statist., </journal> <volume> 31 </volume> <pages> 93-99, </pages> <year> 1982. </year>
Reference-contexts: Lemma 1 Suppose f 2 C 1 [; ] and let f n (x) be as given in Equation 4.4. Then Ef n (x) ! f (x) as m ! 1 uniformly, independently of n. Proof Ef n (x) = as shown in Silverman <ref> [59] </ref>, and Whittle [68]. By a change of variable Z c m (x s)f (s)ds = x Z x+ c m (y)f (x + y)dy (4.8) since c m (y) = c m (y).
Reference: [60] <author> B.W. Silverman. </author> <title> Density Estimation for Statistics and Data Analysis. </title> <publisher> Chap-man and Hall, </publisher> <address> London, U.K., </address> <year> 1993. </year>
Reference-contexts: This problem of nonparametric density estimation has been well studied. Good descriptions of various methods and their analyses can be found in <ref> [60, 47] </ref>. Results of the comparison of some widely used methods is also given in [28, 54]. Various methods have been proposed for nonparametric density estimation, for example, histograms, kernel methods [49, 51, 67], orthogonal series methods [57, 36], the nearest neighbor method [60], etc. <p> Results of the comparison of some widely used methods is also given in [28, 54]. Various methods have been proposed for nonparametric density estimation, for example, histograms, kernel methods [49, 51, 67], orthogonal series methods [57, 36], the nearest neighbor method <ref> [60] </ref>, etc. The Histogram method is the simplest to implement. It divides the domain into a number of cells. The probability density function of a cell is taken to be proportional to the number of samples in the cell. <p> So, this method estimates the true density as a function of the distance from the k- th nearest neighboring sample point. One of the drawbacks of this method is that it has discontinuous derivatives and so we may expect sensitivity to local noise <ref> [60] </ref>. In the context of iterative calculations, one can consider the noise to be errors in the discretization, and also 12 due to the precision of the arithmetic. <p> As the sample size approaches infinity, we need to ensure that the M ISE approaches 0. This criterion for the convergence of the estimate to the true density is satisfied under the following condition <ref> [60] </ref>: h ! 0 and nh d ! 1 as n ! 1 (2.6) where d is the dimension of the domain. On the surface of the sphere, d = 2. <p> The equation for the bound on the M ISE suggests a form for an ideal kernel, referred to as the Epanechnikov kernel. However, it can be shown that most of the kernels that have been considered are close to this kernel in their effectiveness in estimating the density <ref> [60] </ref>. Therefore we may choose a kernel based on factors other than accuracy, such as the ease of evaluation. Nevertheless, we shall later mention some constraints based on the type of application in which the kernel method is used. <p> This is consistent with our formula if we let ~ approach 0 as the sample size increases, since we are in a two dimensional domain. It has however 27 been suggested by others <ref> [1, 60] </ref> that it may be better to use h (r) 2 / (r) 1 in any dimension, since the bias can be shown in this case to be of a smaller order than in the case of a fixed width kernel. <p> Early contributors to the theory of non-parametric estimation include N.V. Smirnov [61], M. Rosenblatt [56], E. Parzen [49], and N.N. Chentsov [9]. Extensive descriptions of various approaches to non-parametric estimation along with a comprehensive bibliography can be found in books by B.W. Silverman <ref> [60] </ref>, and E.A. Nadaraya [47]. More recent developments are presented in books by Scott [58] and Wand and Jones [66]. Results of the experimental comparison of some widely used methods appear in [28, 54].
Reference: [61] <author> M.V. Smirnov. </author> <title> On the approximation of probability densities of random variables. </title> <journal> Scholarly Notes of Moscow State Polytechnical Institute, </journal> <volume> 16 </volume> <pages> 69-96, </pages> <year> 1951. </year>
Reference-contexts: This is in contrast to parametric estimation in which the density is assumed to come from a given family, and the parameters are then estimated by various statistical methods. Early contributors to the theory of non-parametric estimation include N.V. Smirnov <ref> [61] </ref>, M. Rosenblatt [56], E. Parzen [49], and N.N. Chentsov [9]. Extensive descriptions of various approaches to non-parametric estimation along with a comprehensive bibliography can be found in books by B.W. Silverman [60], and E.A. Nadaraya [47].
Reference: [62] <author> G.D. Smith. </author> <title> Numerical solution of partial differential equations : finite difference methods. </title> <publisher> Oxford University Press, </publisher> <address> New York, New York, </address> <year> 1978. </year>
Reference: [63] <author> A. Szeri and L.G. Leal. </author> <title> A new computational method for the solution of flow problems of microstructured fluids. Part 2. inhomogeneous shear flow of a suspension. </title> <journal> Journal of Fluid Mechanics, </journal> <volume> 262 </volume> <pages> 171-204, </pages> <year> 1994. </year>
Reference-contexts: An 15 advantage of the Lagrangian mesh is that there are more points in regions with high density, thus providing high resolution in regions where we need a high resolution. This method was utilized by Szeri and Leal to solve a problem related to the current one <ref> [63] </ref>. There is a difficulty, however, with mesh-based Lagrangian schemes. As the flow evolves with time, the mesh can get distorted and the grid can become meaningless since the points that are the neighbors of any point on the mesh may move apart, rendering the finite difference calculations inaccurate. <p> However, this overhead takes only linear time, and so will be negligible for sufficiently large data. It should also be mentioned that for an important class of applications, it has been shown <ref> [63] </ref> that using spherical coordinates is not numerically stable for solving the differential equations arising in those applications and Cartesian coordinates are recommended.
Reference: [64] <author> T. Lewis, N.I. Fisher and B.J.J. Embleton. </author> <title> Statistical Analysis of Spherical Data. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1993. </year>
Reference-contexts: Geometry of phase space The domain of our problem is the surface of the unit sphere. Most of the convergence results in the existing literature are for Euclidean domains, though there has also been some work specifically for the sphere <ref> [64, 22, 15, 16] </ref>. However, we can still use the types of kernels used in Euclidean space since density is a local phenomenon, and a sphere is locally Euclidean. In addition, since our phase space is closed upon itself, boundary conditions are not present in this problem. <p> The kernel method for nonparametric density estimation for directional 68 and axial data is discussed in <ref> [64, 22] </ref>. <p> The kernel method for nonparametric density estimation for directional 68 and axial data is discussed in [64, 22]. While dealing with directional data, Fisher <ref> [64] </ref> recommends using the following kernel W n (P; P i ) = C n 4 sinh (C n ) h i For axial data he recommends the kernel given below W n (P; P i ) = A (C n ) exp C n (x T X i ) (4.3)
Reference: [65] <author> T. Tajima, J.N. Leboeuf and J.M. Dawson. </author> <title> A magnetohydrodynamic particle code for fluid simulation of plasmas. </title> <journal> Journal of Computational Physics, </journal> <volume> 31 </volume> <pages> 379-408, </pages> <year> 1979. </year> <month> 149 </month>
Reference-contexts: We shall later also discuss the accuracy of the gradient calculations in Section 2.4.3. In order to overcome this difficulty with distortion in a mesh based La-grangian scheme, several so-called "particle methods" were invented for fluid flow <ref> [23, 41, 65] </ref>. Most of these methods shared a common feature [20], namely, the use of a combination of an Eulerian mesh, and a set of Lagrangian points, or "particles". An early example of these schemes was the Particle In Cell (PIC) method [23].
Reference: [66] <author> M.P. Wand and M.C. Jones. </author> <title> Kernel Smoothing. </title> <publisher> Chapman and Hall, </publisher> <address> London, U.K., </address> <year> 1995. </year>
Reference-contexts: Generally, convergence of the derivative requires stronger conditions. It can be shown that the conditions for convergence of the derivatives require a slower rate of decrease of the window width than for the estimate of the density <ref> [66, 47, 6] </ref>. 2.4 Smoothed Particle Hydrodynamics In the following section we show how the above methods of nonparamet-ric density estimation can be incorporated into a dynamical simulation. <p> Rosenblatt [56], E. Parzen [49], and N.N. Chentsov [9]. Extensive descriptions of various approaches to non-parametric estimation along with a comprehensive bibliography can be found in books by B.W. Silverman [60], and E.A. Nadaraya [47]. More recent developments are presented in books by Scott [58] and Wand and Jones <ref> [66] </ref>. Results of the experimental comparison of some widely used methods appear in [28, 54]. Along with applications in data analysis, an important application of density estimation is in computational fluid mechanics as in the application we have been considering.
Reference: [67] <author> G.S. Watson and M.R. Leadbetter. </author> <title> On the estimation of the probability density, I. </title> <journal> Ann. Math. Statist., </journal> <volume> 34 </volume> <pages> 480-491, </pages> <year> 1963. </year>
Reference-contexts: Good descriptions of various methods and their analyses can be found in [60, 47]. Results of the comparison of some widely used methods is also given in [28, 54]. Various methods have been proposed for nonparametric density estimation, for example, histograms, kernel methods <ref> [49, 51, 67] </ref>, orthogonal series methods [57, 36], the nearest neighbor method [60], etc. The Histogram method is the simplest to implement. It divides the domain into a number of cells. <p> Otherwise, we deal with directional data. Various methods have been proposed for non-parametric density estimation 66 in mathematical statistics, such as the kernel <ref> [49, 51, 67] </ref> and the orthogonal series methods [57, 36]. The kernel method has been extensively studied, and it is probably the most popular scheme in applications such as SPH. <p> We propose a cosine based weight function c m (x) for non-parametric density estimation, which is a special case of the class of estimators that form a ffi sequence <ref> [67] </ref>. This estimator is similar to the kernel estimator, but has the ease of evaluation of a series expansion.
Reference: [68] <author> P. Whittle. </author> <title> On the smoothing of probability density functions. </title> <journal> J. Roy. Statist. Soc. B, </journal> <volume> 20 </volume> <pages> 334-343, </pages> <year> 1958. </year>
Reference-contexts: Lemma 1 Suppose f 2 C 1 [; ] and let f n (x) be as given in Equation 4.4. Then Ef n (x) ! f (x) as m ! 1 uniformly, independently of n. Proof Ef n (x) = as shown in Silverman [59], and Whittle <ref> [68] </ref>. By a change of variable Z c m (x s)f (s)ds = x Z x+ c m (y)f (x + y)dy (4.8) since c m (y) = c m (y). <p> Then var f n (x) ! 0 uniformly as n ! 1 provided m ! 1 as n ! 1, and m = o (n 2 ). Proof var f n (x) = n 1 Z c m (x s)f (s)ds as shown in Whittle <ref> [68] </ref>. As a consequence of Lemma 1 Z c m (x s)f (s)ds ! f (x) ; as m ! 1 72 uniformly. It follows that 1 Z c m (x s)f (s)ds ! 0 as n ! 0 since f is bounded. <p> If m ! 1 as n ! 1, and m = o (n 2 ), then MISE = Z E (f n (x) f (x)) 2 dx ! 0 Proof Z Z Z as shown in Whittle <ref> [68] </ref>. From Lemma 1 and Lemma 2, each of the integrals approaches 0. Hence the M ISE converges to 0. In fact, the M ISE is of the form given below. <p> F n (x) = n 74 For the proof of 4.17, we use the integral expression for the expectation from Whittle <ref> [68] </ref> and integration by parts to get sup jf (r) n (x)j = sup j c (r) Z m (x u)dF (u)j x2IR jF n (u) F (u)jjdc (r) m (x u)j u2IR m where the last inequality is obtained by differentiation of c m , and k 2 (r) is
Reference: [69] <author> R.D. Williams. </author> <title> Performance of dynamic load balancing algorithms for unstructured mesh calculations. </title> <journal> Concurrency, </journal> <volume> 3 </volume> <pages> 457-481, </pages> <year> 1991. </year>
Reference-contexts: We show how our domain decomposition strategy facilitates efficient implementation of other operations on the data. Conclusions are given in Section 3.5. 3.1 Domain Decomposition Domain decomposition has been widely studied <ref> [25, 24, 33, 69, 34] </ref> and several types of methods for its solution have been proposed: graph-theoretical and geometric, for example. Graph-theoretical schemes ignore coordinate information and treat domain decomposition as a general graph partitioning problem.
Reference: [70] <author> X.F. Yuan, </author> <title> R.C. Ball and S.F. Edwards. A new approach to modelling vis-coelastic flow. </title> <journal> Journal of Non-Newtonian Fluid Mechanics, </journal> <volume> 46 </volume> <pages> 331-350, </pages> <year> 1993. </year>
Reference-contexts: We can consider the difference in these two frameworks as follows. In an Eulerian framework the mesh would be at fixed points in space. In a Lagrangian framework the mesh will move with the fluid. We use a Lagrangian framework because it has been postulated <ref> [70] </ref> that certain difficulties in the simulation of polymer flows that arise at high "Deborah" numbers can be avoided in a Lagrangian framework. <p> We calculate the fluid velocity at the vertices and keep track of the orientation distribution function at 104 the centers of the triangles. The reason for calculating these quantities at different points will become apparent later, and is standardly used in calculations similar to ours <ref> [70] </ref>. <p> We can obtain t N too using Equation 5.3. We update the pressure as follows <ref> [19, 50, 70] </ref> based on the artificial compressibility method: @P = *r v (5.11) The time used in this equation is a fictitious time and has nothing to do with the time step used in the main iteration.
Reference: [71] <author> W.S. Young and C.L. Brooks III. </author> <title> Implementation of a data parallel, logical domain decomposition method for interparticle interaction in molecular dynamics of structured molecular fluids. </title> <journal> Journal of Computational Chemistry, </journal> <volume> 15 </volume> <pages> 44-53, </pages> <year> 1994. </year> <month> 150 </month>
Reference-contexts: Thus the computational structure of these computations is the same as that of particle methods with short-range interactions. We next describe particle methods and relate their computational structure to that of the kernel method for density estimation. Particle methods are widely used in several applications <ref> [4, 23, 44, 71] </ref>. These typically involve a set of particles represented as points in some space, and a function that describes the interaction between pairs of particles. <p> In many applications such as molecular dynamics, the interacting forces between the particles are short range and the effect of particles that are farther away than a certain cut-off distance can be ignored <ref> [71] </ref>. This leads to an irregular computational problem in which the set of particles which interacts with 39 any given particle changes with time in an unpredictable manner.
References-found: 71

