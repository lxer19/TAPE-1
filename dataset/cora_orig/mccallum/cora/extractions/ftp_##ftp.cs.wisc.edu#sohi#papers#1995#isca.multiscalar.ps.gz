URL: ftp://ftp.cs.wisc.edu/sohi/papers/1995/isca.multiscalar.ps.gz
Refering-URL: http://www.cs.wisc.edu/~sohi/sohi.html
Root-URL: 
Email: sohi@cs.wisc.edu breach@cs.wisc.edu vijay@cs.wisc.edu  
Title: Multiscalar Processors  
Author: Gurindar S. Sohi Scott E. Breach T.N. Vijaykumar 
Address: Madison, WI 53706  
Affiliation: Computer Sciences Department University of Wisconsin-Madison  
Abstract: Multiscalar processors use a new, aggressive implementation paradigm for extracting large quantities of instruction level parallelism from ordinary high level language programs. A single program is divided into a collection of tasks by a combination of software and hardware. The tasks are distributed to a number of parallel processing units which reside within a processor complex. Each of these units fetches and executes instructions belonging to its assigned task. The appearance of a single logical register file is maintained with a copy in each parallel processing unit. Register results are dynamically routed among the many parallel processing units with the help of compiler-generated masks. Memory accesses may occur speculatively without knowledge of preceding loads or stores. Addresses are disambiguated dynamically, many in parallel, and processing waits only for true data dependences. This paper presents the philosophy of the multiscalar paradigm, the structure of multiscalar programs, and the hardware architecture of a multiscalar processor. The paper also discusses performance issues in the multiscalar model, and compares the multiscalar paradigm with other paradigms. Experimental results evaluating the performance of a sample of multiscalar organizations are also presented. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. E. Breach, T. N. Vijaykumar, and G. S. Sohi, </author> <title> ``The Anatomy of the Register File in a Multiscalar Processor,'' </title> <booktitle> Proc. MICRO-27, </booktitle> <pages> pp. 181-190, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: As a task executes and consumes values, it waits for a particular value only if the value has not yet been produced (by an active predecessor task). Otherwise, it finds the value within local storage <ref> [1] </ref>. The value present within local storage is the product of an earlier task that has forwarded a value around the ring. multiple basic blocks whose execution is governed by (dynamically resolved) control conditions, it is not possible to determine statically which register values will be created dynamically. <p> The processing units are connected via a uni directional ring which is used to forward information (reservations, values, etc.) from one unit to the next <ref> [1] </ref>. The data cache banks and the associated interconnect (between the data cache banks and the units) are straightforward (except for the scale). Updates of the data cache are not performed speculatively.
Reference: [2] <author> D. K. Chen, H. M. Su, and P. C. Yew, </author> <title> ``The Impact of Synchronization and Granularity on Parallel Systems,'' </title> <booktitle> Proc. 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 239-248, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Whereas a multiprocessor requires a compiler to divide a program into tasks where all dependence relations between tasks are known (or are conservatively provided for) <ref> [2] </ref>, a multiscalar processor requires no such knowledge of control and data independence. If a compiler can divide a program into tasks that are guaranteed to be independent (for example iterations of a vectorizable loop), of course a multiscalar processor can execute them in parallel.
Reference: [3] <author> M. Franklin and G. S. Sohi, ``ARB: </author> <title> A Hardware Mechanism for Dynamic Memory Disambiguation,'' </title> <note> submitted to IEEE Transactions on Computers. </note>
Reference: [4] <author> M. Franklin and G. S. Sohi, </author> <title> ``The Expandable Split Window Paradigm for Exploiting Fine-Grain Parallelism,'' </title> <booktitle> in Proc. 19th Annual Symposium on Computer Architecture, </booktitle> <address> Queensland, Australia, </address> <pages> pp. 58-67, </pages> <month> May </month> <year> 1992. </year>
Reference: [5] <author> M. Franklin, ``The Multiscalar Architecture,'' Ph. D. </author> <type> Thesis, </type> <institution> Computer Sciences Technical Report #1196, University of Wisconsin-Madison, Madison, WI 53706, </institution> <month> November </month> <year> 1993. </year>
Reference: [6] <author> R. E. Hank, S. A. Mahlke, R. A. Bringmann, J. C. Gyllenhaal, and W. W. Hwu, </author> <title> ``Superblock Formation Using Static Program Analysis,'' </title> <booktitle> Proc. MICRO-26, </booktitle> <pages> pp. 247-255, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: than standard and/or modifications indicated in parentheses): compress, eqntott, espresso (ti.in), gcc (integrate.i), sc (loada1), and xlisp (6 queens) from the SPECint92 suite, tomcatv (N=129) from the SPECfp92 suite, wc from the GNU textutils1.9 and cmp from the GNU diffu-tils2.6 (two Unix utilities used as benchmarks by the IMPACT group <ref> [6] </ref>, with inputs provided by them), as well as the example from Figure 3 (with an input file of 16 tokens, each appearing 450 times in the file). iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii Instruction Count Percent iiiiiiiiiiiiiiiiiiiiiiii Program Scalar Multiscalar Increase iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii Compress 71.04M 81.21M 14.3% Eqntott 1077.50M 1237.73M 14.9% Espresso 526.50M 615.95M 17.0%
Reference: [7] <author> P. Y.-T. Hsu and E. S. Davidson, </author> <title> ``Highly Concurrent Scalar Processing,'' </title> <booktitle> Proc. 13th Annual Symposium on Computer Architecture, </booktitle> <pages> pp. 386-395, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: The ability of a multiscalar processor to selectively bypass branches possibly obviates the need for techniques such as guarded execution, whose net result is also avoiding the prediction of ``bad'' branches (albeit non-loop branches), but at the expense of executing extra instructions <ref> [7, 9, 10] </ref>. A wide window of pending instructions requires the complexity of concurrently monitoring the issue state of all individual instructions in this window. In general, instructions from a wide window are selected for execution in parallel and often out-of-order with respect to the sequential program.
Reference: [8] <author> R. M. Keller, </author> <title> ``Look-Ahead Processors,'' </title> <journal> ACM Computing Surveys, </journal> <volume> vol. 7, </volume> <pages> pp. 66-72, </pages> <month> December </month> <year> 1975. </year>
Reference-contexts: Generally, this examination is done to extract and process branch instructions, to identify instruction types so that they may be routed to the proper instruction buffers or reservation stations, and to do some processing to alleviate data dependences, e.g., register renaming <ref> [8, 11] </ref>. A typical VLIW processor relies on the compiler to perform statically these same functions performed by the superscalar processor dynami-cally.
Reference: [9] <author> S. A. Mahlke, D. C. Liu, W. Y. Chen, R. E. Hank, and R. A. Bringmann, </author> <title> ``Effective Compiler Support for Predicated Execution Using the Hyperblock,'' </title> <booktitle> in MICRO-25, Portland, Oregon, </booktitle> <pages> pp. 45-54, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: The ability of a multiscalar processor to selectively bypass branches possibly obviates the need for techniques such as guarded execution, whose net result is also avoiding the prediction of ``bad'' branches (albeit non-loop branches), but at the expense of executing extra instructions <ref> [7, 9, 10] </ref>. A wide window of pending instructions requires the complexity of concurrently monitoring the issue state of all individual instructions in this window. In general, instructions from a wide window are selected for execution in parallel and often out-of-order with respect to the sequential program.
Reference: [10] <author> D. N. Pnevmatikatos and G. S. Sohi, </author> <title> ``Guarded Execution and Branch Prediction in Dynamic ILP Processors,'' </title> <booktitle> in Proc. 21th Annual International Symposium on Computer Architecture, </booktitle> <address> Chicago, </address> <publisher> Illinois, </publisher> <pages> pp. 120-129, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: The ability of a multiscalar processor to selectively bypass branches possibly obviates the need for techniques such as guarded execution, whose net result is also avoiding the prediction of ``bad'' branches (albeit non-loop branches), but at the expense of executing extra instructions <ref> [7, 9, 10] </ref>. A wide window of pending instructions requires the complexity of concurrently monitoring the issue state of all individual instructions in this window. In general, instructions from a wide window are selected for execution in parallel and often out-of-order with respect to the sequential program.
Reference: [11] <author> G. S. Tjaden and M. J. Flynn, </author> <title> ``Detection and Parallel Execution of Independent Instructions,'' </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. C-19, </volume> <pages> pp. 889-895, </pages> <month> Oc-tober </month> <year> 1970. </year>
Reference-contexts: Generally, this examination is done to extract and process branch instructions, to identify instruction types so that they may be routed to the proper instruction buffers or reservation stations, and to do some processing to alleviate data dependences, e.g., register renaming <ref> [8, 11] </ref>. A typical VLIW processor relies on the compiler to perform statically these same functions performed by the superscalar processor dynami-cally.
Reference: [12] <author> T.-Y. Yeh and Y. N. Patt, </author> <title> ``A Comparison of Dynamic Branch Predictors that Use Two Levels of Branch History,'' </title> <booktitle> in Proc. 20th Annual International Symposium on Computer Architecture, </booktitle> <address> San Diego, </address> <publisher> Califor-nia, </publisher> <pages> pp. 257-266, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: The control flow prediction of the sequencer uses a PAs configuration <ref> [12] </ref> with 4 targets per prediction and 6 outcome histories.
References-found: 12

