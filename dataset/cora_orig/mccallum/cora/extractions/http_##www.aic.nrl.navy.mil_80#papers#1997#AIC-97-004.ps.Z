URL: http://www.aic.nrl.navy.mil:80/papers/1997/AIC-97-004.ps.Z
Refering-URL: http://www.cs.cmu.edu/~mcox/CBR/Read-group/
Root-URL: 
Email: faha,breslowg@aic.nrl.navy.mil  
Title: Refining Conversational Case Libraries  
Author: David W. Aha and Leonard A. Breslow 
Address: DC 20375 USA  
Affiliation: Navy Center for Applied Research in Artificial Intelligence Naval Research Laboratory, Washington,  
Abstract: Conversational case-based reasoning (CBR) shells (e.g., Inference's CBR Express) are commercially successful tools for supporting the development of help desk and related applications. In contrast to rule-based expert systems, they capture knowledge as cases rather than more problematic rules, and they can be incrementally extended. However, rather than eliminate the knowledge engineering bottleneck, they refocus it on case engineering, the task of carefully authoring cases according to library design guidelines to ensure good performance. Designing complex libraries according to these guidelines is difficult; software is needed to assist users with case authoring. We describe an approach for revising case libraries according to design guidelines, its implementation in Clire, and empirical results showing that, under some conditions, this approach can improve conversational CBR performance.
Abstract-found: 1
Intro-found: 1
Reference: <author> Auriol, E., Wess. S., Manago, M., Althoff, K. -D., & Traphoner, R. </author> <year> (1995). </year> <title> Inreca: A seamlessly integrated system based on inductive inference and case-based reasoning. </title> <booktitle> Proceedings of the First ICCBR (pp. </booktitle> <pages> 371-380). </pages> <address> Sesimbra, Portugal: </address> <publisher> Springer. </publisher>
Reference-contexts: Clire could benefit from using a failure-driven process to modify case indices. Many CBR systems use decision trees to index and retrieve cases. For example, this includes IBPRS (Ku & Suh, 1996), which uses K-trees, and INRECA <ref> (Auriol et al., 1995) </ref>, which integrates decision trees and k-d trees. Manago et al. (1993) describe how INRECA incrementally processes unknown values. Questions are automatically selected by reading the decision tree, induced from the cases, in a top-down manner.
Reference: <author> Breslow, L., & Aha, D. W. </author> <year> (1997). </year> <title> Simplifying decision trees: A survey. </title> <note> To appear in Knowledge Engineering Review. </note>
Reference: <author> Cardie, C. </author> <year> (1993). </year> <title> Using decision trees to improve case-based learning. </title> <booktitle> Proceedings of the Tenth ICML (pp. </booktitle> <pages> 25-32). </pages> <address> Amherst, MA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Domingos, P. </author> <year> (1997). </year> <title> Context-sensitive feature selection for lazy learners. </title> <journal> Artificial Intelligence Review, </journal> <volume> 11, </volume> <pages> 227-253. </pages>
Reference-contexts: Specifically, Clire deletes questions in c j that do not appear on paths leading to leaves containing c j . Although case-specific feature selection algorithms exist <ref> (e.g., Domingos, 1997) </ref>, they assume that cases are all described by the same questions, which is not true for CCBR libraries. This research is limited in that we have no models of expected retrieval behavior for these libraries.
Reference: <author> Fox, S., & Leake, D. L. </author> <year> (1995). </year> <title> Using introspective reasoning to refine indexing. </title> <booktitle> Proceedings of the Fourteenth IJCAI (pp. </booktitle> <pages> 391-397). </pages> <address> Montreal: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Unlike CCBR, these question-answering processes are not user-driven, and they do not use trees to revise case indices. Clire would require extension for tasks where feature evaluation has nonzero cost. ROBBIE <ref> (Fox & Leake, 1995) </ref> is a failure-driven CBR system that re-indexes cases by selecting alternative indices for cases in a planning task. It uses introspective analysis to encourage the retrieval of more easily adaptable cases. Efficiency is measured in the context of a traditional rather than a conversational CBR context.
Reference: <author> Heider, R., Auriol, E., Tartarin, E., & Manago, M. </author> <year> (1997). </year> <title> Improving the quality of case bases for building better decision support systems. </title> <editor> In R. Bergmann & W. Wilke (Eds.) </editor> <booktitle> Fifth German Workshop on CBR: Foundations, Systems, </booktitle> <institution> and Applications (Technical Report LSA-97-01E). University of Kaiserslautern, Department of Computer Science. Inference Corporation (1995). </institution> <month> CBR2: </month> <title> Designing CBR Express Case Bases. </title> <note> Unpublished. </note>
Reference: <author> Kitano H., Shimazu H., & Shibata A. </author> <year> (1993). </year> <title> Case-method: A methodology for building large-scale case-based systems. </title> <booktitle> Proceedings of the Eleventh NCAI (pp. </booktitle> <pages> 303-308). </pages> <address> Washington, DC: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Ku, S., & Suh, Y.-H. </author> <year> (1996). </year> <title> An investigation of the K-tree search algorithm for efficient case representation and retrieval. </title> <journal> Expert Systems with Applications, </journal> <volume> 11, </volume> <pages> 571-581. </pages>
Reference-contexts: In contrast, our approach works on the entire library simultaneously, without knowledge of specific retrieval failures. Clire could benefit from using a failure-driven process to modify case indices. Many CBR systems use decision trees to index and retrieve cases. For example, this includes IBPRS <ref> (Ku & Suh, 1996) </ref>, which uses K-trees, and INRECA (Auriol et al., 1995), which integrates decision trees and k-d trees. Manago et al. (1993) describe how INRECA incrementally processes unknown values. Questions are automatically selected by reading the decision tree, induced from the cases, in a top-down manner.
Reference: <author> Manago, M., Althoff, K.-D., Auriol, E., Traphoner, R., Wess, S., Conruyt, N., & Maurer, F. </author> <year> (1993). </year> <title> Induction and reasoning from cases. </title> <booktitle> Proceedings of the First EWCBR (pp. </booktitle> <pages> 313-318). </pages> <address> Kaiserslautern, Germany: </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Nguyen, T., Czerwinsksi, M., & Lee, D. </author> <year> (1993). </year> <title> COMPAQ QuickSource: Providing the consumer with the power of artificial intelligence. </title> <booktitle> Proceedings of the Fifth IAAI (pp. </booktitle> <pages> 142-150). </pages> <address> Washington, DC: </address> <publisher> AAAI Press. </publisher>
Reference-contexts: These cases are assumed to be among the most relevant to the user's query. Therefore, the displayed 1 In some applications, the customer interacts with the system directly <ref> (e.g., Nguyen et al., 1993) </ref>. questions are taken from these cases (i.e., those questions not already answered during the current conversation). They are ordered according to their potential for distinguishing the best case to retrieve.
Reference: <author> Quinlan, J. R. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 81-106. </pages>
Reference: <author> Quinlan, J. R. </author> <year> (1989). </year> <title> Unknown attribute values in induction. </title> <booktitle> Proceedings of the Sixth IWML (pp. </booktitle> <pages> 164-168). </pages> <address> Ithaca, NY: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: TDIDT algorithms recursively apply a selection criterion to choose an index question for partitioning a node's cases. Most selection criteria assume that cases are defined by the same set of questions, although several methods exist for tolerating missing values <ref> (Quinlan, 1989) </ref>. They also assume that cases have been clustered (e.g., by class). These assumptions are violated here. CCBR libraries typically have few, if any, questions answered in all of its cases, and each case's solution (i.e., action sequence) can be unique.
Reference: <author> Smyth, B., & Cunningham, P. </author> <year> (1994). </year> <title> A comparison of incremental CBR and inductive learning. </title> <editor> In M. Keane, J. P. Haton, & M. Manago (Eds.) </editor> <booktitle> Working Papers of the Second EWCBR. </booktitle> <address> Chantilly, France: </address> <note> Unpublished. </note>
Reference: <author> Tan, M., & Schlimmer, J. C. </author> <year> (1990). </year> <title> Two case studies in cost-sensitive concept acquisition. </title> <booktitle> Proceedings of the Eighth NCAI (pp. </booktitle> <pages> 854-860). </pages> <address> Boston, MA: </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Kitano et al. (1993) also describe a general methodology for building case bases. However, these publications do not target conversational CBR systems, nor describe computational approaches for revising case libraries. Some previous research investigates case-based tasks in which queries are derived incrementally. For example, CS-IBL <ref> (Tan & Schlimmer, 1990) </ref> incrementally evaluates features that have non-zero evaluation cost; it selects features to evaluate that maximize the ratio of expected match success to cost. Smyth and Cunningham (1994) instead focus on tasks where features have either zero or a fixed nonzero evaluation cost.
References-found: 14

