URL: http://www.speech.sri.com/people/konig/papers/ijcnn.ps
Refering-URL: http://www.speech.sri.com/people/konig/papers/welcome.html
Root-URL: 
Title: GDNN: A Gender-Dependent Neural Network for Continuous Speech Recognition  
Author: Yochai Konig, and Nelson Morgan 
Address: Institute,Berkeley CA  
Affiliation: EECS Department, University of California at Berkeley International Computer Science  
Abstract: Conventional speaker-independent speech recognition systems do not consider speaker-dependent parameters in the probability estimation of phonemes. These recognition systems are instead tuned to the ensemble statistics over many speakers. Most parametric representations of speech, however, are highly speaker dependent, and probability distributions suitable for a certain speaker may not perform as well for other speakers. It would be desirable to incorporate constraints on analysis that rely on the same speaker producing all the frames in an utterance. Our experiments take a first step towards this speaker consistency modeling by using a classification network to help generate gender-dependent phonetic probabilities for a statistical recognition system. Our results show a good classification rate for the gender classification net. Simple use of such a model to augment an existing larger network that estimates phonetic probabilities does not help speech recognition performance. However, when the new net is properly integrated in an HMM recognizer, it provides significant improvement in word accuracy.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Morgan, N., H. Bourlard, </author> " <title> Merging Multilayer Perceptrons and Hidden Markov Models: Some Experiments in Continuous Speech Recognition", Neural Networks: </title> <booktitle> Advances and Applications, </booktitle> <publisher> Elsevier Science Publishers B.V., North Holland, </publisher> <year> 1991. </year>
Reference: [2] <author> Murveit, H., Weintraub, M., and Cohen, M., </author> <title> Training Set Issues in SRI's DECIPHER Speech Recognition System, </title> <booktitle> Proc. Speech and Natural Language Workshop, </booktitle> <month> June </month> <year> 1990, </year> <note> pp.337-340 6 </note>
References-found: 2

