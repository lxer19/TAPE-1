URL: http://ftp.eecs.umich.edu/people/mslyz/nn_pred/DCC94_nn_pred.ps.gz
Refering-URL: http://ftp.eecs.umich.edu/people/mslyz/nn_pred/
Root-URL: http://www.eecs.umich.edu
Title: A Nonlinear VQ-based Predictive Lossless Image Coder  
Author: Marko J. Slyz David L. Neuhoff 
Address: Ann Arbor, MI 48109  
Affiliation: Electrical Engineering and Computer Science University of Michigan  
Abstract: A new lossless predictive image coder is introduced and tested. The predictions are made with a nonlinear, vector quantizer based, adaptive predictor. The prediction errors are losslessly compressed with an arithmetic coder that presumes they are Laplacian distributed with variances that are estimated during the prediction process, as in the approach of Howard and Vitter. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Howard, J. Vitter, </author> <title> "New Methods for Lossless Image Compression Using Arithmetic Coding", </title> <booktitle> Proc. Data Compression Conference, </booktitle> <editor> J. Storer and J. Reif, eds., </editor> <address> Snowbird, Utah, </address> <month> Apr. </month> <year> 8-11,1991, </year> <pages> pp. 257-266. </pages> <note> A more complete version appeared in Inform. Proc. </note> & <editor> Management, </editor> <volume> vol. 28, no. 5, </volume> <pages> pp. 765-779, </pages> <year> 1992. </year>
Reference-contexts: IV. Howard & Vitter's Error Coding Method After we make a prediction, we must still code the error between it and the actual pixel value. To do this we implemented a method similar to that described in <ref> [1] </ref>. In this method the prediction errors are encoded using arithmetic coding, which requires that we supply a 6 probability distribution for each error. As prediction errors have often been found to be Laplacian, the probability distributions are assumed to be discretized Laplacians (symmetric twosided exponential). <p> The variance is then quantized to one of 37 values which, together with the actual error, are fed to an arithmetic coder that generates the coded representation. Our variance estimation technique is somewhat similar to the one used in the PPPM method of <ref> [1] </ref>. One difference is that the distance measure in [1] is less discriminating since two contexts which match in their high-order bits would be considered to be equivalent by the [1] distance measure, but might still be meaningfully distinguished by a Euclidean measure. <p> Our variance estimation technique is somewhat similar to the one used in the PPPM method of <ref> [1] </ref>. One difference is that the distance measure in [1] is less discriminating since two contexts which match in their high-order bits would be considered to be equivalent by the [1] distance measure, but might still be meaningfully distinguished by a Euclidean measure. <p> Our variance estimation technique is somewhat similar to the one used in the PPPM method of <ref> [1] </ref>. One difference is that the distance measure in [1] is less discriminating since two contexts which match in their high-order bits would be considered to be equivalent by the [1] distance measure, but might still be meaningfully distinguished by a Euclidean measure. On the other hand, we are not aware of a theoretical reason why the context classification performed in [1] is worse than any other, and doing it explicitly this way allows for lazy updating of context statistics, which <p> less discriminating since two contexts which match in their high-order bits would be considered to be equivalent by the <ref> [1] </ref> distance measure, but might still be meaningfully distinguished by a Euclidean measure. On the other hand, we are not aware of a theoretical reason why the context classification performed in [1] is worse than any other, and doing it explicitly this way allows for lazy updating of context statistics, which may improve variance estimation. V. <p> V. Results and Future Work Table 1 contains the results in bits per pixel for running three different coders on the 7 bands of the Landsat Thematic Mapper data set originally used in <ref> [1] </ref>. PPPM is [1]'s method. It is the best performing lossless image coder that we are aware of. JPEG is the Joint Photographic Experts Group Coder being run in its lossless mode. The data for the PPPM and JPEG columns both come from [1]. <p> Thematic Mapper data set originally used in <ref> [1] </ref>. PPPM is [1]'s method. It is the best performing lossless image coder that we are aware of. JPEG is the Joint Photographic Experts Group Coder being run in its lossless mode. The data for the PPPM and JPEG columns both come from [1]. VQ-pred is the algorithm described in this article being run with cell populations of size 26. <p> These are also quite successful in compressing images and, when used with sufficiently high-order predictors, can obtain compression ratios as good as the nonlinear systems discussed here. The advantage of the contextsearch type methods in this paper and in <ref> [1] </ref> over linear predictors is in complexity: our nonlinear VQ coders obtain their results significantly faster than an adaptive linear coder set for this quality level.
Reference: [2] <author> P. Howard and J. Vitter, </author> <title> "Error Modeling for Hierarchical Lossless Image Compression," </title> <booktitle> Proceedings of 1992 Data Compression Conference, </booktitle> <editor> J. Storer and M. Cohen, </editor> <booktitle> eds., </booktitle> <pages> pp. 269-278. </pages>
Reference: [3] <author> A. Gersho, </author> <title> "Optimal Nonlinear Interpolative Vector Quantization", </title> <journal> IEEE Trans. on Communications, </journal> <volume> vol. 38, no. 9, </volume> <month> Sept. </month> <year> 1990. </year>
Reference: [4] <author> S. Wang, E. Paksoy, A. Gersho, </author> <title> "Performance of Nonlinear Prediction of Speech," </title> <booktitle> 8 Proc. Int. Conf. Spoken Language Processing, </booktitle> <address> Kobe, Japan, </address> <month> Nov. </month> <year> 1990, </year> <pages> pp. 29-32. </pages>
Reference: [5] <author> A. Gersho and R. Gray, </author> <title> Vector Quantization and Signal Compression, </title> <address> Boston, </address> <publisher> Kluwer Academic Publishers, </publisher> <year> 1992. </year>
Reference-contexts: Fortunately, there is an idea from a structured VQ technique called Shape-Gain VQ (c.f. <ref> [5] </ref>) which applies here. The idea is that contexts that have different amplitudes, but which are otherwise similar, can be counted together after being normalized in the obvious way.
Reference: [6] <author> A. Gersho, </author> <title> "Optimal Vector Quantized Nonlinear Estimation," </title> <booktitle> Proc. 1993 IEEE Int. Symp. on Information Theory, </booktitle> <month> Jan. </month> <pages> 17-22, </pages> <year> 1993, </year> <month> p.170. </month>
Reference-contexts: Furthermore, there exist techniques, some of which are similar to the hashing done for context matching in PPPM, that can potentially speed this up. We hope to further improve the performance of this nonlinear VQ method by using better cell shapes, perhaps with a variant of the method in <ref> [6] </ref>. We are also studying the performance of these nonlinear predictors on other kinds of data. Images are well modeled by autoregressive sources and so may be especially well suited to linear prediction.
References-found: 6

