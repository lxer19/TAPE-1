URL: ftp://ftp.cs.rochester.edu/pub/papers/systems/93.tr465.Mercury_users_manual.ps.Z
Refering-URL: http://www.cs.rochester.edu/trs/systems-trs.html
Root-URL: 
Title: The Mercury User's Manual  
Author: Leonidas Kontothanassis 
Note: supported this work.  
Date: August 1993  
Address: Rochester, New York 14627  
Affiliation: The University of Rochester Computer Science Department  The University of Rochester Computer Science Department  
Pubnum: Technical Report 465  
Abstract: larger than the number of processors provided by the underlying hardware. Using heavyweight (Unix style) processes to implement those threads of control is prohibitively expensive. Mercury is an environment for writing object-oriented parallel programs in C++ that provides the user with simple primitives for inexpensive thread creation and blocking and spinning synchronization. If required, Mercury primitives allow the user to control scheduling decisions in order to achieve good locality of reference in non uniform memory access (NUMA) multiprocessors. This paper describes the basic Mercury primitives and provides examples of their use. 
Abstract-found: 1
Intro-found: 1
Reference: [Bershad et al., 1988] <author> B. N. Bershad, E. D. Lazowska, and H. M. Levy, </author> <title> "PRESTO: A system for Object-oriented Parallel Programming," </title> <journal> Software Practice and Experience, </journal> <pages> pages 713-732, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction Mercury is a library package for writing object-oriented parallel programs in shared memory multiprocessors. It runs on the Mips based Silicon Graphics multiprocessor using the 3.10 release of the C compiler and is derived from the PRESTO library package <ref> [Bershad, 1988; Bershad et al., 1988] </ref> with which it is upwards compatible 1 .
Reference: [Bershad, 1988] <author> Brian N. Bershad, </author> <title> "The PRESTO User's Manual," </title> <type> Technical report, </type> <institution> Department of Computer Science, University of Washington, </institution> <year> 1988. </year>
Reference-contexts: 1 Introduction Mercury is a library package for writing object-oriented parallel programs in shared memory multiprocessors. It runs on the Mips based Silicon Graphics multiprocessor using the 3.10 release of the C compiler and is derived from the PRESTO library package <ref> [Bershad, 1988; Bershad et al., 1988] </ref> with which it is upwards compatible 1 . <p> The existence of these two types is largely due to the PRESTO <ref> [Bershad, 1988] </ref> ancestry of Mercury. 2.3 Objects All other Mercury objects are derived from this basic class called Object. // objects.h class Object - int o_type; char *o_name; Object *o_next; Object *o_prev; Object (int t=0, char* n=0) virtual void error (char* s); int& type (); char* name (); -; Instances of
Reference: [Cox et al., 1990] <author> A. L. Cox, R. J. Fowler, and J. E. Veenstra, </author> <title> "Interprocessor invocation on a NUMA multiprocessor," </title> <type> Technical report, </type> <institution> Department of Computer Science, University of Rochester, </institution> <year> 1990. </year>
Reference-contexts: This can be useful in discarding long chains of procedure calls when returning to the caller is no longer necessary. The continuation structure can be used to build complicated control graphs or synchronization structures. It can also be used to implement remote invocation <ref> [Cox et al., 1990] </ref> by casting a task in the form of a template and joining on it. For a detailed description of the use of the continuation data structures see [Fowler and Kontothanassis, 1992]. A complete list of the continuation interface routines can be found in Appendix A. <p> In the case where threads need to access a locked centralized data structure it is beneficial to put the data structure on one processor and have threads dispatch requests for access to that processor using the remote invocation method <ref> [Cox et al., 1990; Fowler and Kontothanassis, 1992] </ref>.
Reference: [Eager and Zahorjan, 1991] <author> Derek L. Eager and John Zahorjan, "Chores: </author> <title> Enhanced Run-Time Support for Shared-Memory Parallel Computing," </title> <type> Technical Report 91-08-05, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: Templates are most efficient when the programming style involves run-to-completion tasks, in which case several optimizations can be performed <ref> [Fowler and Kontothanassis, 1992; Eager and Zahorjan, 1991] </ref>. Such optimizations include stack hand-off to subsequent threads, thus avoiding the need for queue operations to reuse the stack and elimination of context switching to the scheduler thread that is to determine the next runnable user thread.
Reference: [Fowler and Kontothanassis, 1992] <author> R. J. Fowler and L. I. Kontothanassis, </author> <title> "Improving Processor and Cache Locality in Fine-Grained Parallel Computations using Object-Affinity Scheduling and Continuation Passing," </title> <type> Technical Report TR411, </type> <institution> Department of Computer Science, University of Rochester, </institution> <month> June </month> <year> 1992. </year>
Reference-contexts: Templates are most efficient when the programming style involves run-to-completion tasks, in which case several optimizations can be performed <ref> [Fowler and Kontothanassis, 1992; Eager and Zahorjan, 1991] </ref>. Such optimizations include stack hand-off to subsequent threads, thus avoiding the need for queue operations to reuse the stack and elimination of context switching to the scheduler thread that is to determine the next runnable user thread. <p> It can also be used to implement remote invocation [Cox et al., 1990] by casting a task in the form of a template and joining on it. For a detailed description of the use of the continuation data structures see <ref> [Fowler and Kontothanassis, 1992] </ref>. A complete list of the continuation interface routines can be found in Appendix A. Grouping templates It is possible to combine templates into groups so that they can be joined with one operation. The combination of templates defines a new class called P continuation. <p> We call this technique Object Affinity Scheduling (OAS). A detailed description of object affinity scheduling and its effects on program performance can be found in <ref> [Fowler and Kontothanassis, 1992] </ref>. <p> In the case where threads need to access a locked centralized data structure it is beneficial to put the data structure on one processor and have threads dispatch requests for access to that processor using the remote invocation method <ref> [Cox et al., 1990; Fowler and Kontothanassis, 1992] </ref>.
Reference: [Lampson and Redell, 1980] <author> B. W. Lampson and D. D. Redell, </author> <title> "Experiences with Processes and Monitors in Mesa," </title> <journal> Communications of the ACM, </journal> <pages> pages 104-117, </pages> <year> 1980. </year> <month> 18 </month>
Reference-contexts: Mercury has a rich set of synchronization constructs that the programmer can choose from, including spinning and blocking locks, a simple kind of Mesa semantics monitors with condition queues <ref> [Lampson and Redell, 1980] </ref> and blocking and spinning barriers. Spinlocks Spinlocks are the most basic form of non relinquishing synchronization available in the Mercury runtime. Spinlocks can be constructed, locked, unlocked, conditionally locked and queried for their value. The following example demonstrates the use of Spinlocks.
References-found: 6

