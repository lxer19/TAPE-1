URL: http://www.cs.cmu.edu/afs/cs/project/theo-11/www/kamal/www/papers/webkb-aaai98s.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs/project/theo-11/www/kamal/www/resume.html
Root-URL: 
Title: Learning to Extract Symbolic Knowledge from the World Wide Web Tracking Number: A354 Content Areas:
Abstract: The World Wide Web is a vast source of information accessible to computers, but understandable only to humans. The goal of the research described here is to automatically create a computer understandable world wide knowledge base whose content mirrors that of the World Wide Web. Such a knowledge base would enable much more effective retrieval of Web information, and promote new uses of the Web to support knowledge-based inference and problem solving. Our approach is to develop a trainable information extraction system that takes two inputs: an ontology defining the classes and relations of interest, and a set of training data consisting of labeled regions of hypertext representing instances of these classes and relations. Given these inputs, the system learns to extract information from other pages and hyperlinks on the Web. This paper describes our general approach, several machine learning algorithms for this task, and promising initial results with a prototype system. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Anonymous. </author> <year> 1998. </year> <title> Learning to extract symbolic knowledge from the World Wide Web. </title> <type> Technical report. </type>
Reference-contexts: We discuss each of these tasks in the main sections of the paper. Additional details concerning the methods and experiments described in this paper can be found elsewhere <ref> (Anonymous 1998) </ref>. After describing approaches to these three tasks, we describe experiments with a system that in-corporates learned classifiers for each task. Experimental Testbed As a testbed for our initial research, we have investigated the task of building a knowledge base describing computer science departments.
Reference: <author> Cestnik, B. </author> <year> 1990. </year> <title> Estimating probabilities: A crucial task in machine learning. </title> <editor> In Aiello, L., ed., </editor> <booktitle> Proc. of the 9th European Conference on Artificial Intelligence, </booktitle> <pages> 147-150. </pages> <publisher> Pitman. </publisher>
Reference-contexts: We do not learn a description of the Other class, but instead treat it as a default class. When classifying test instances, we calculate an associated measure of confidence along with each prediction. The confidence of a prediction is determined by an m-estimate <ref> (Cestnik 1990) </ref> of the error-rate of the clause making the prediction. The resulting Accuracy/Coverage plot is shown in Figure 3.
Reference: <author> Dzeroski, S., and Bratko, I. </author> <year> 1992. </year> <title> Handling noise in inductive logic programming. </title> <booktitle> In Proc. of the 2nd International Workshop on Inductive Logic Programming, </booktitle> <pages> 109-125. </pages>
Reference-contexts: Test Set: 371 Pos, 4 Neg Our algorithm for constructing the path part of a clause is a variant of Richards and Mooney's (1992) relational pathfinding method. Whereas Foil uses an information-theoretic measure to guide its hill-climbing search, our method, like Dzeroski and Bratko's m-Foil <ref> (Dzeroski & Bratko 1992) </ref>, uses m-estimates of a clause's error to guide its construction. We have found that using this evaluation function results in fewer, more general clauses than Foil's information gain measure. the Members.Of.Project and Department.Of.Person relations.
Reference: <author> Quinlan, J. R., and Cameron-Jones, R. M. </author> <year> 1993. </year> <title> FOIL: A midterm report. </title> <booktitle> In Proc. of the 12th Eu-ropean Conference on Machine Learning, </booktitle> <pages> 3-20. </pages>
Reference-contexts: In this section, we consider the task of learning to classify pages using an algorithm that is able to induce first-order rules. The learning algorithm that we use in this section is Foil <ref> (Quinlan & Cameron-Jones 1993) </ref>. Foil is a greedy covering algorithm for learning function-free Horn clauses.
Reference: <author> Richards, B. L., and Mooney, R. J. </author> <year> 1992. </year> <title> Learning relations by pathfinding. </title> <booktitle> In Proc. of the 10th National Conference on Artificial Intelligence, </booktitle> <pages> 50-55. </pages> <address> San Jose, CA: </address> <publisher> AAAI/MIT Press. </publisher>
Reference: <author> Spertus, E. </author> <year> 1997. </year> <title> ParaSite: Mining structural information on the Web. </title> <booktitle> In Proc. of the Sixth International World Wide Web Conference. </booktitle>
Reference: <author> Witten, I. H., and Bell, T. C. </author> <year> 1991. </year> <title> The zero-frequence problem: Estimating the probabilities of novel events in adaptive text compression. </title> <journal> IEEE Transactions on Inoformation Theory 37(4). </journal>
References-found: 7

