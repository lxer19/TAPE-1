URL: http://www.cc.gatech.edu/faculty/ashwin/papers/er-92-06.ps.Z
Refering-URL: http://www.cs.gatech.edu/faculty/ashwin/ABSTRACTS-summary.html
Root-URL: 
Email: email: cox@cc.gatech.edu; ashwin@cc.gatech.edu  
Title: AN EXPLICIT REPRESENTATION OF FORGETTING  
Author: Michael T. Cox and Ashwin Ram 
Keyword: Machine learning; knowledge representation; meta-reasoning; case-based reasoning; blame assignment.  
Address: Atlanta, GA 30332-0280  
Affiliation: College of Computing Georgia Institute of Technology,  
Abstract: A pervasive, yet much ignored, factor in the analysis of processing-failures is the problem of misorganized knowledge. If a systems knowledge is not indexed or organized correctly, it may make an error, not because it does not have either the general capability or specific knowledge to solve a problem, but rather because it does not have the knowledge sufficiently organized so that the appropriate knowledge structures are brought to bear on the problem at the appropriate time. In such cases, the system can be said to have forgotten the knowledge, if only in this context. This is the problem of forgetting or retrieval failure. This research presents an analysis along with a declarative representation of a number of types of forgetting errors. Such representations can extend the capability of introspective failure-driven learning systems, allowing them to reduce the likelihood of repeating such errors. Examples are presented from the Meta-AQUA program, which learns to improve its performance on a story understanding task through an introspective meta-analysis of its knowledge, its organization of its knowledge, and its reasoning processes. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Birnbaum, L. and Collins, G. </author> <booktitle> (1984); Opportunistic Planning and Freudian Slips; Proceedings of the Sixth Annual Conference of the Cognitive Science Society; University of Colorado, Boulder, </booktitle> <pages> CO (pp. 124-127) Carbonell, </pages> <editor> J. G. </editor> <title> (1983); Learning by Analogy: Formulating and Generalizing Plans from Past Experience; Machine Learning: </title> <booktitle> An Artificial Intelligence Approach, </booktitle> <volume> Vol. 1 (eds. </volume> <editor> R. Michalski, J. Carbonell and T. </editor> <publisher> Mitchell); Morgan Kaufmann Publishers, Inc., </publisher> <address> Los Altos , CA. </address>
Reference: <author> Cox, M. T., and Ram, A. </author> <title> (1992); Multistrategy Learning with Introspective Meta-Explanations; Machine Learning: </title> <booktitle> Proceedings of the Ninth International Conference (ML92), </booktitle> <editor> (eds. D. Sleeman and P. </editor> <publisher> Edwards); Morgan Kaufmann, </publisher> <address> Los Altos, CA. </address>
Reference-contexts: J. W. Brahan and G. E. Lasker (eds.), Proceedings of the Sixth Inernational Conference on Systems Research, Infor-matics and Cybernetics, Baden-Baden, Germany (August, 1992), pp 115-120. 116 The solution for this type of learning is to represent the reasoning process explicitly in structures called Meta-XPs <ref> (Ram and Cox, 1992) </ref>. A Trace Meta-XP (TMXP) is a structure that records a reasoning trace and explains how solutions were generated, whereas an Introspective Meta-XP (IMXP) is a causal pattern that, when applied to a TMXP, explains why these solutions fail. <p> This can occur either because there never was a concept in memory to be retrieved, or because the item was previously deleted from memory. Ostensibly there is no difference between the two in this representation. For example, in the Meta-AQUA story understanding system <ref> (Cox and Ram, 1992) </ref>, a novel situation (marked as an absent memory in Table 1) exists when trying to explain a police dog barking at a passengers luggage in the airport.
Reference: <author> Doyle, J. </author> <booktitle> (1979); A Truth Maintenance System; Artificial Intelligence, </booktitle> <volume> Vol. 12, </volume> <pages> (pp. 231-272) Hammond, </pages> <editor> K. </editor> <booktitle> (1988); Opportunistic Memory: Storing and Recalling Suspended Goals; Proceedings of the Workshop on Case-Based Reasoning (DARPA); Morgan Kaufmann Publishers, </booktitle> <publisher> Inc., </publisher> <address> San Mateo, CA. </address>
Reference: <author> Kolodner, J. L. </author> <title> (1984); Retrieval and Organizational Strategies in Conceptual Memory: </title> <publisher> A computer model; Lawrence Erlbaum Associates, Publishers, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Kolodner, J. L. </author> <note> (to appear); Case-Based Reasoning; Morgan Kaufmann Publishers. </note>
Reference: <author> McDermott, D. </author> <title> (1989); A General Framework for Reason Maintenance; Technical Report 691, </title> <institution> Yale University, Department of Computer Science. </institution>
Reference: <author> Markovitch, S. and Scott, P. D. </author> <booktitle> (1988); The Role of Forgetting in Learning; Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <address> Ann Arbor, MI. </address>
Reference-contexts: This example does not exactly represent forgetting, since there never was a memory item in its experience to be retrieved. In systems that delete memory items in order to facilitate learning <ref> (e.g., Markovitch and Scott, 1988) </ref>, however, trying to remember a deleted item is equivalent to a novel situation.
Reference: <author> McClelland, J. L. and Rumelhart, D. E. </author> <title> (1986); A Distributed Model of Human Learning and Memory; Parallel Distributed Processing: </title> <journal> Explorations in the Microstructure of Cognition, </journal> <volume> Vol. 2, </volume> <editor> (eds. J. L. McClelland and D. E. Rumelhart), </editor> <title> (pp. 170- 215) Ram, </title> <journal> A. (1991); A Theory of Questions and Question Asking; Journal of the Learning Sciences, </journal> <volume> Vol. 1, No. 3 & 4. </volume>
Reference: <author> Ram, A., and Cox, M. T. </author> <title> (1992); Introspective Reasoning Using Meta-Explanations for Multistrategy Learning. Machine Learning: A Multistrategy Approach IV, </title> <editor> (eds. R. S. Michalski. and Tecuci, G.); </editor> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: J. W. Brahan and G. E. Lasker (eds.), Proceedings of the Sixth Inernational Conference on Systems Research, Infor-matics and Cybernetics, Baden-Baden, Germany (August, 1992), pp 115-120. 116 The solution for this type of learning is to represent the reasoning process explicitly in structures called Meta-XPs <ref> (Ram and Cox, 1992) </ref>. A Trace Meta-XP (TMXP) is a structure that records a reasoning trace and explains how solutions were generated, whereas an Introspective Meta-XP (IMXP) is a causal pattern that, when applied to a TMXP, explains why these solutions fail. <p> This can occur either because there never was a concept in memory to be retrieved, or because the item was previously deleted from memory. Ostensibly there is no difference between the two in this representation. For example, in the Meta-AQUA story understanding system <ref> (Cox and Ram, 1992) </ref>, a novel situation (marked as an absent memory in Table 1) exists when trying to explain a police dog barking at a passengers luggage in the airport.
Reference: <author> Schank, R. C. </author> <title> (1982); Dynamic Memory: A theory of reminding and learning in computers and people; Cambridge University Press, </title> <address> Cambridge, MA. </address>
Reference-contexts: Memory reindexing can then be performed in light of the reasoning that gave rise to the failure. Discussion The analysis above can be expanded to more complicated situations, but space limitation does not permit adequate review here. Briey though, given a reconstructive memory <ref> (Schank, 1982) </ref> such that memory items are not retrieved as whole objects but must be reconstructed from partial memories, there may be partial matches. For example, John may have remembered that he had planned to do something (i.e., he had a goal), but could not remember what the goal was.
Reference: <author> Schank, R. C., and Osgood, R. </author> <title> (1990); A Content Theory of Memory Indexing; Technical Report 2. </title> <institution> Institute for the Learning Sciences, Northwestern University, </institution> <address> Evanston, IL. </address>
Reference: <author> Schneider, W. and Pressley, </author> <title> M (1989); Memory Development Between Two and Twenty; Springer-Verlag. </title>
Reference: <author> Tambe, M, Newell, A. and Rosenbloom, P. S. </author> <title> (1990); The Problem of Expensive Chunks and Its Solution by Restricting Expressiveness; Machine Learning, </title> <journal> Vol. </journal> <volume> 5, </volume> <pages> (pp. </pages> <editor> 299-348) Veloso and Carbonell, J. G. </editor> <title> (1991); Automating Case Generation, </title> <booktitle> Storage and Retrieval in PRODIGY; Proceedings of the 1st International Workshop on Multi-Strategy Learning, </booktitle> <editor> (eds. R. S. Michalski, and G. Tecuci, G.), </editor> <publisher> (pp.363-377) </publisher>
References-found: 13

