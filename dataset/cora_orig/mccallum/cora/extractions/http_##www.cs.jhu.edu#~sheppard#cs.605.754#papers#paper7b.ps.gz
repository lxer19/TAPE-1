URL: http://www.cs.jhu.edu/~sheppard/cs.605.754/papers/paper7b.ps.gz
Refering-URL: http://www.cs.jhu.edu/~sheppard/cs.605.754/sched.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: wray@ptolemy.arc.nasa.gov  
Phone: Phone: +1 (415) 604-3389  
Title: Theory Refinement on Bayesian Networks  
Author: Wray Buntine 
Address: Moffet Field, CA 94035, USA  
Affiliation: RIACS and AI Research Branch NASA Ames Research Center, Mail Stop 244-17  
Abstract: Theory refinement is the task of updating a domain theory in the light of new cases, to be done automatically or with some expert assistance. The problem of theory refinement under uncertainty is reviewed here in the context of Bayesian statistics, a theory of belief revision. The problem is reduced to an incremental learning task as follows: the learning system is initially primed with a partial theory supplied by a domain expert, and thereafter maintains its own internal representation of alternative theories which is able to be interrogated by the domain expert and able to be incrementally refined from data. Algorithms for refinement of Bayesian networks are presented to illustrate what is meant by "partial theory", "alternative theory representation", etc. The algorithms are an incremental variant of batch learning algorithms from the literature so can work well in batch and incremental mode.
Abstract-found: 1
Intro-found: 1
Reference: <author> Amemiya, T. </author> <year> (1985). </year> <title> Advanced Econometrics. </title> <publisher> Har-vard University Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: here: (1) How do you learn parameters for a specific conditional distribution? (2) How do you then patch the distribution learnt into the broad framework given previously? There are many ways of representing restricted conditional probability distributions: trees (Buntine, 1990a), logistic regression and other qualitative models popular in economic statistics <ref> (Amemiya, 1985) </ref>, and the noisy-or gate popular in AI (Pearl, 1988). The noisy-or gate is described as follows. Suppose boolean variable x is conditioned on boolean variables x 1 ; : : : ; x n . <p> So with a dominant likelihood term, the posterior on the parameters is unimodal and the maximum posterior parameters can be found using search methods such as scoring, Newton-Raphson, or conjugate gradient <ref> (Amemiya, 1985) </ref>. A multivariate normal approximation for the posterior at this point (Berger, 1985, p224) can then be used to marginal-ize out the parameters and approximate the posterior probability that the noisy-or function of the logistic regression function is "true".
Reference: <author> Berger, J. O. </author> <year> (1985). </year> <title> Statistical Decision Theory and Bayesian Analysis. </title> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference-contexts: We assume is independent of and E given so develop a prior for P r ( j ). We choose a prior that is a conjugate prior (it yields a posterior in the same functional form, so makes the mathematics simple <ref> (Berger, 1985) </ref>) and assumes the least amount of information is known about the conditional probability tables. <p> The solution to the integral follows by using standard properties of the Dirichlet integral (Buntine, 1990b). The counts n x=ijj are the only parameters in the posterior affected by the training sample and they are referred to as sufficient statistics <ref> (Berger, 1985) </ref>; these need to be maintained during incremental learning. Finally, each reasonable parent structure also has esti-mates for the parameters specifying the conditional probability tables. The estimated table for the variable x is given by E jSample; . <p> So with a dominant likelihood term, the posterior on the parameters is unimodal and the maximum posterior parameters can be found using search methods such as scoring, Newton-Raphson, or conjugate gradient (Amemiya, 1985). A multivariate normal approximation for the posterior at this point <ref> (Berger, 1985, p224) </ref> can then be used to marginal-ize out the parameters and approximate the posterior probability that the noisy-or function of the logistic regression function is "true". Notice that because the numeric search algorithms are iterative, they are readily placed in an incremental framework.
Reference: <author> Buntine, W. </author> <year> (1990a). </year> <title> Learning classification trees. </title> <type> Technical Report FIA-90-12-19-01, </type> <institution> RIACS and NASA Ames Research Center, Moffett Field, </institution> <address> CA. </address> <booktitle> Paper presented at Third International Workshop on Artificial Intelligence and Statistics. </booktitle>
Reference-contexts: Simple learning approaches approximate this space of alternative theories by taking a single high posterior structure (Cooper and Herskovits, 1991; Buntine, 1990a) however experiments show that averaging over a larger sized space yields considerable improvement <ref> (Buntine, 1990a) </ref> 1 . This improved performance corresponds to the improved accuracy gained in the T OP N system when the system approximates posteriors using a thousand alternative disease sets instead of a single disease set (Henrion, 1990). <p> To generate a space of reasonable alternatives, it does a search of the space of high posteriors in a similar style and with the same motivation as the T OP N system and the Bayesian averaging method for trees <ref> (Buntine, 1990a) </ref>. The theory refinement approach is developed here for Bayesian networks. These networks are first introduced and then the representation of partial theories and their transformation to a prior is described. The representation for alternative theories is described, and then the theory refinement and interrogation algorithms are presented. <p> To ensure these are truly representative networks, we can return a collection of networks together in a compressed format corresponding to a single Bayesian network, denoted a smoothed Bayesian network. A similar operation has been presented for class probability trees <ref> (Buntine, 1990a) </ref>. For each variable x, we choose a leaf L x 2 P x from the parent lattice for x using a probabilistic method described later. This provides one potential parent set for x. <p> We have two issues to consider here: (1) How do you learn parameters for a specific conditional distribution? (2) How do you then patch the distribution learnt into the broad framework given previously? There are many ways of representing restricted conditional probability distributions: trees <ref> (Buntine, 1990a) </ref>, logistic regression and other qualitative models popular in economic statistics (Amemiya, 1985), and the noisy-or gate popular in AI (Pearl, 1988). The noisy-or gate is described as follows. Suppose boolean variable x is conditioned on boolean variables x 1 ; : : : ; x n .
Reference: <author> Buntine, W. </author> <year> (1990b). </year> <title> A Theory of Learning Classification Rules. </title> <type> PhD thesis, </type> <institution> University of Technology, </institution> <address> Sydney. </address> <publisher> Forthcoming. </publisher>
Reference-contexts: The solution to the integral follows by using standard properties of the Dirichlet integral <ref> (Buntine, 1990b) </ref>. The counts n x=ijj are the only parameters in the posterior affected by the training sample and they are referred to as sufficient statistics (Berger, 1985); these need to be maintained during incremental learning.
Reference: <author> Cooper, G. and Herskovits, E. </author> <year> (1991). </year> <title> A Bayesian method for the induction of probabilistic networks from data. </title> <type> Technical Report KSL-91-02, </type> <institution> Knowledge Systems Laboratory, Medical Computer Science, Stanford University. </institution>
Reference-contexts: An analogous approximation for class probability trees significantly outperformed standard statistical and AI methods (Bun-tine, 1990a) on a large range of problems. A weaker approximation for batch learning (which finds a single high posterior network) has been reported to work well empirically <ref> (Cooper and Her-skovits, 1991) </ref>, and the parameter updating com ponent of the algorithm corresponds to previous work (Spiegelhalter and Lauritzen, 1989). * There is an incremental algorithm that allows any-time return for varied processing times between receipt of new examples.
Reference: <author> Crawford, S. </author> <year> (1989). </year> <title> Extensions to the CART algorithm. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 31(2) </volume> <pages> 197-217. </pages>
Reference-contexts: Some nodes may oscillate on and off Alive-list and Open-list because the posterior ordering of parent sets will oscillate as the training samples increases and the posteriors are modified. This is the problem of repeated restructuring reported by Crawford to occur in incremental learning algorithms <ref> (Crawford, 1989) </ref>.
Reference: <author> Dempster, A., Laird, N., and Rubin, D. </author> <year> (1977). </year> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> J. Roy. Statist. Soc. B, </journal> <volume> 39 </volume> <pages> 1-38. </pages>
Reference-contexts: Further extensions would be the handling of "missing values", where some examples have variable values missing, and the handling of expert designated "hidden variables" in the structure. Both problems can be handled the EM algorithm <ref> (Dempster et al., 1977) </ref>. While full conditional joint distributions are more general than any other model, their specification requires an exponential number of parameters. When estimating parameter values from data, this can be a severe problem as it is when trying to elicit the same probabilities from an expert.
Reference: <author> Geiger, D., Paz, A., and Pearl, J. </author> <year> (1990). </year> <title> Learning causal trees from dependence information. </title> <booktitle> In Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 770-771, </pages> <address> Boston, Massachusetts. </address>
Reference: <author> Ginsberg, A., Weiss, S., and Politakis, P. </author> <year> (1988). </year> <title> Automatic knowledge base refinement for classification systems. </title> <journal> Artificial Intelligence, </journal> <volume> 35(2) </volume> <pages> 197-226. </pages>
Reference-contexts: Shapiro (Shapiro, 1983), for instance, developed a comprehensive theory and suite of algorithms for the task of refining Horn clause theories (logic programs). Ginsberg et al. applied a more heuristic approach to the refinement of a rule base in the context of medical diagnosis <ref> (Ginsberg et al., 1988) </ref>.
Reference: <author> Haussler, D. </author> <year> (1991). </year> <title> A decision theoretic generalization of the PAC learning model and its application to some feed-forward neural networks. </title> <journal> Information and Control. </journal> <note> To appear. </note>
Reference-contexts: Another popular learning framework in the computing area is uniform convergence, of which the PAC model is an instance <ref> (Haussler, 1991) </ref>. This is an approach that approximates the normative Bayesian approach when sample sizes are large. Several researchers have reported (unsurprisingly) that the Bayesian approach is superior with smaller size training samples (Buntine, 1990b; Opper and Haus-sler, 1991) in a range of batch learning problems.
Reference: <author> Henrion, M. </author> <year> (1990). </year> <title> Towards efficient inference in multiply connected belief networks. </title> <editor> In Oliver, R. and Smith, J., editors, </editor> <title> Influence Diagrams, </title> <booktitle> Belief Nets and Decision Analysis, </booktitle> <pages> pages 385-407. </pages> <publisher> Wiley. </publisher>
Reference-contexts: This improved performance corresponds to the improved accuracy gained in the T OP N system when the system approximates posteriors using a thousand alternative disease sets instead of a single disease set <ref> (Henrion, 1990) </ref>. A space of alternative theories is difficult to present to a domain expert but can be readily summarized in several ways for expert interrogation during theory refinement: two approaches are described here. The theory refinement algorithm of course applies Bayes theorem to this space of alternatives.
Reference: <author> Lauritzen, S. and Spiegelhalter, D. </author> <year> (1988). </year> <title> Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> J. Roy. Statist. Soc. B, </journal> <volume> 50(2) </volume> <pages> 240-265. </pages>
Reference-contexts: batch learning (starting with a non-informative theory, and assuming learning occurs from just one batch of cases), to incremental learning (assuming new cases come in smaller batches and the theory is gradually refined)? A second recent example of theory refinement is of Bayesian networks sometimes used in medical expert systems <ref> (Lauritzen and Spiegelhalter, 1988) </ref>. While experts can set up an appropriate graphical structure and estimate the needed probabilities, new examples may arrive on a daily basis so the expert system needs to be refined. <p> Given the parent structure specifying the network and the conditional prob ability tables, methods exist for computing arbitrary conditional and marginal likelihoods between variables <ref> (Lauritzen and Spiegelhalter, 1988) </ref>. The following notation is used here. A Bayesian network consists of a set of discrete variables X where each variable x 2 X has a set of parent variables x . The full parent structure is denoted .
Reference: <author> Mitchell, T. </author> <year> (1982). </year> <title> Generalization as search. </title> <journal> Artificial Intelligence, </journal> <volume> 18(2) </volume> <pages> 203-226. </pages>
Reference-contexts: For each possible parent structure , we also have to know its posterior probability and sufficient information to update this given new examples. This space of parent structures and the additional information can be thought of as similar to a version space <ref> (Mitchell, 1982) </ref>. However, because of the inherent uncertainty of the theories considered here, the "version space" cannot be updated by considering consistency with the training sample, most specific generalizations, etc.
Reference: <author> Opper, M. and Haussler, D. </author> <year> (1991). </year> <title> Generalised performance of Bayes optimal classification algorithm for learning a perceptron. </title> <booktitle> In COLT'91: 1991 Workshop on Computational Learning Theory. </booktitle> <publisher> Morgan Kaufmann. Manuscript. </publisher>
Reference: <author> Ourston, D. and Mooney, R. </author> <year> (1990). </year> <title> Changing the rules: A comprehensive approach to theory refinement. </title> <booktitle> In Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 815-820, </pages> <address> Boston, Massachusetts. </address>
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan and Kauffman. </publisher>
Reference-contexts: Some of these algorithms also make the assumption (Geiger et al., 1990; Spirtes and Glymour, 1990; Verma and Pearl, 1990) that the unknown probability distribution is a DAG-isomorph <ref> (Pearl, 1988) </ref>. This means all independencies in the problem must be perfectly captured by some Bayesian network, which may not be the case in a particular problem (for instance, all non-chordal Markov networks are not DAG-isomorphic). <p> specific conditional distribution? (2) How do you then patch the distribution learnt into the broad framework given previously? There are many ways of representing restricted conditional probability distributions: trees (Buntine, 1990a), logistic regression and other qualitative models popular in economic statistics (Amemiya, 1985), and the noisy-or gate popular in AI <ref> (Pearl, 1988) </ref>. The noisy-or gate is described as follows. Suppose boolean variable x is conditioned on boolean variables x 1 ; : : : ; x n .
Reference: <author> Quinlan, J. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106. </pages>
Reference: <author> Shapiro, E. </author> <year> (1983). </year> <title> Algorithmic Program Debugging. </title> <publisher> MIT Press. </publisher>
Reference-contexts: The key idea is to use the expert's prior domain knowledge to prime a learning system during the knowledge acquisition process. Subsequent refinement of theory proceeds by having the learning system accept examples or ask key questions of the expert. Shapiro <ref> (Shapiro, 1983) </ref>, for instance, developed a comprehensive theory and suite of algorithms for the task of refining Horn clause theories (logic programs). Ginsberg et al. applied a more heuristic approach to the refinement of a rule base in the context of medical diagnosis (Ginsberg et al., 1988).
Reference: <author> Spiegelhalter, D. and Lauritzen, S. </author> <year> (1989). </year> <title> Sequential updating of conditional probabilities on directed graphical structures. </title> <institution> Research Report R-89-10, Institute of Electronic Systems, Aalborg University, Aalborg, Denmark. </institution>
Reference-contexts: Spiegelhalter et al. argue that the expert's experience and confidence in setting up the initial model needs to be quantified <ref> (Spiegelhalter and Lauritzen, 1989) </ref> (for instance, how many examples was it based on) in order to do refinement carefully. <p> A weaker approximation for batch learning (which finds a single high posterior network) has been reported to work well empirically (Cooper and Her-skovits, 1991), and the parameter updating com ponent of the algorithm corresponds to previous work <ref> (Spiegelhalter and Lauritzen, 1989) </ref>. * There is an incremental algorithm that allows any-time return for varied processing times between receipt of new examples.
Reference: <author> Spirtes, P. and Glymour, C. </author> <year> (1990). </year> <title> An algorithm for fast recovery of sparse causal graphs. </title> <type> Report CMU-LCL-90-4, </type> <institution> Laboratory for Computational Linguistics, Carnegie Mellon University. </institution>
Reference-contexts: They describe probabilistic models useful for nondirected classification. That is, one can predict (and 1 Similar results are reported in <ref> (Spirtes et al., 1990) </ref>, although their justification is different. compute likelihoods for) one subset of variables from any other.
Reference: <author> Spirtes, P., Scheines, R., and Glymour, C. </author> <year> (1990). </year> <title> Simulation studies of the reliability of computer-aided model specification using TETRAD II. EQS and LISREL programs. </title> <journal> Socialogical Methods and Research, </journal> <volume> 19(1) </volume> <pages> 3-66. </pages>
Reference-contexts: They describe probabilistic models useful for nondirected classification. That is, one can predict (and 1 Similar results are reported in <ref> (Spirtes et al., 1990) </ref>, although their justification is different. compute likelihoods for) one subset of variables from any other.
Reference: <author> Srinivas, S., Russell, S., and Agogino, A. </author> <year> (1990). </year> <title> Automated construction of sparse Bayesian networks. </title> <editor> In Henrion, M., Schachter, R., Kanal, L., and Lemmer, J., editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 5, </booktitle> <pages> pages 295-308. </pages> <publisher> Elsevier Science Publishers, Amster-dam. </publisher>
Reference-contexts: Furthermore, the partial theory is such that it can initially be null, and that it incorporates a quantification of the expert's experience so that the "right" amount of refinement is done given new cases. Another approach to learning networks that incorporates a partial theory is given by by <ref> (Srinivas et al., 1990) </ref>. The general approach developed here is based on Bayesian principles for belief updating that form the basis of several learning algorithms (Buntine, 1990b; Cooper and Herskovits, 1991). The principles specify precisely a "normative" approach to theory refinement, and the approach suggested here approximates this. <p> These have the following important properties: * The representation can be initiated with a partial Bayesian network that quantifies the expert's experience and confidence. A similar approach was suggested in <ref> (Srinivas et al., 1990) </ref>. There after the representation maintains several reason able hypotheses in a form of version space. * The algorithms approximate the normative Bayesian solution to the corresponding batch learning problem.
Reference: <author> Towell, G., Shavlik, J., and Noordewier, M. </author> <year> (1990). </year> <title> Refinement of approximate domain theories by knowledge-based neural networks. </title> <booktitle> In Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 861-866, </pages> <address> Boston, Massachusetts. </address>
Reference-contexts: But this research faces the problems of "imperfect and uncertain domain theories" and "noisy training cases" not well handled by analytic methods. A recent example of this hybrid learning approach is as follows <ref> (Towell et al., 1990) </ref>: a rule-base of knowledge about the domain is transcribed into a neural network to initialize the network; the new training cases are then run in a back-propagation algorithm to refine the network.
Reference: <author> Verma, T. and Pearl, J. </author> <year> (1990). </year> <title> Equivalence and synthesis of causal models. </title> <booktitle> In Sixth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <address> Cambridge, MA. </address>
Reference-contexts: A particular Bayesian network is often equivalent to a set of other Bayesian networks with some arc directions changed <ref> (Verma and Pearl, 1990) </ref>.
References-found: 24

