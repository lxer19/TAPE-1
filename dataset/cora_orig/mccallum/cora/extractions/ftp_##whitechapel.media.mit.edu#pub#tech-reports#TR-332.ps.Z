URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-332.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Title: Detecting Kinetic Occlusion  
Author: Sourabh A. Niyogi 
Address: 20 Ames Street, Cambridge, MA 02139  
Affiliation: Department of Electrical Engineering and Computer Science MIT Media Laboratory,  
Abstract: Visual motion boundaries provide a powerful cue for the perceptual organization of scenes. Motion boundaries are present when surfaces in motion occlude one another. Conventional approaches to motion analysis have relied on assumptions of data conservation and smoothness, which has made analysis of motion boundaries difficult. We show that a common source of motion boundary, kinetic occlusion, can be detected using spatiotemporal junction analysis. Junction analysis is accomplished by utilizing distributed representations of motion used in models of human visual motion sensing. By detecting changes in the direction of motion in these representations, spatiotempo-ral junctions are detected in a manner which differentiates accretion from deletion. We demonstrate successful occlusion detection on spatiotemporal imagery containing occluding surfaces in motion. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Adelson and J. Bergen. </author> <title> Spatiotemporal energy models for the perception of motion. </title> <journal> JOSA A, </journal> <volume> 2 </volume> <pages> 284-299, </pages> <year> 1985. </year>
Reference-contexts: In motion shear, for example, surface motions ~v 1 and ~v 2 move tangent to the motion boundary, but neither surface is occluded. Because motion and kinetic occlusion possess a rich structure both in the spatiotemporal domain and in the spatiotemporal frequency domain <ref> [1, 10, 14] </ref>, we can develop filtering methods with simple non-linearities to analyze kinetic occlusion. <p> ); sin ( m )] T m + ~v t ~v n ~v n - ~v m m m 6 ~v t ~v n ~v 2 @I 6 1 ~v t can construct distributed representations of motion with spatiotemporally oriented filters tuned to portions of the line in (x; t) <ref> [1] </ref> or plane in (x; y; t) [13, 14, 34]. The task of second order motion analysis is to deduce as much information as possible about the attenuation mask M (x). <p> (x) = R ~v 1 (x) (c) E ~v 2 (x) (e) ~ E ~v 2 (x) fl Q ~v 2 (x) = R ~v 2 (x) motion energy E ~v n (x) is possible by filtering the stimulus I (x) with banks of spatiotemporal filters centered on the line/plane <ref> [1, 13, 14] </ref>. XT Energy extraction. <p> By squaring their responses, a phase-invariant "motion energy" signal E ~v n (x) can be obtained <ref> [1] </ref>: E ~v n (x) = (I (x) fl G (x)) + (I (x) fl H (x)) (11) Gabor functions and derivative of Gaussians are convenient forms for energy extraction; we use derivatives of Gaussians because they are steerable [12]. XYT Energy extraction. <p> In (a), we depict an idealized segmenta tion of the random dot stimulus shown in (b). There are three dominant motions (k = 3) corresponding to the three layers of the background, the square, and the circle (~v 1 = [0; 0] T ; ~v 2 = <ref> [1; 0] </ref> T ; ~v 3 = [1; 0] T ). present in regions where the motion is not dominant. <p> There are three dominant motions (k = 3) corresponding to the three layers of the background, the square, and the circle (~v 1 = [0; 0] T ; ~v 2 = <ref> [1; 0] </ref> T ; ~v 3 = [1; 0] T ). present in regions where the motion is not dominant.
Reference: [2] <author> J. Allman, F. Miezin, and E. McGuiness. </author> <title> Direction and velocity-specific responses from beyond the classical receptive field in MT. </title> <journal> Perception, </journal> <volume> 14 </volume> <pages> 105-126, </pages> <year> 1985. </year>
Reference-contexts: We should recognize, of course, that motion boundary extraction can be based on both relative motion cues and occlusion cues. Mechanisms which may process relative motion cues, such as the center-surround mechanisms proposed by [26], have been found (c.f. <ref> [2] </ref>), thus complicating interpretations of physiological data. While V1 and MT cells are not selective to the orientation of kinetic boundaries, a considerable percentage of cells in V2 and V3 possess identical orientation selectivity for both luminance and kinetic-defined boundaries [22, 29].
Reference: [3] <author> J. R. Bergen, P. Burt, K. Hanna, R. Hingorani, and S. Peleg. </author> <title> A three-frame algorithm for estimating two-component image motion. </title> <journal> IEEE PAMI, </journal> <volume> 14 </volume> <pages> 886-896, </pages> <year> 1992. </year>
Reference-contexts: Recently, many have proposed algorithms to counter these assumptions: regularizing with line processes [30, 36], generalizing local models [21, 33], using global parametric motion models <ref> [3, 5, 18, 40] </ref>, and using robust estimation [4]. But all of these approaches pursue the goal of flow field estimation; few consider the spatiotemporal structure of kinetic occlusion. <p> Any parametric scheme (c.f. <ref> [3, 5, 18] </ref>) could easily be substituted. both of which occlude a static background. Two representative (x; y) frames, and an (x; t) slice are shown in each part. In (a), we depict an idealized segmenta tion of the random dot stimulus shown in (b).
Reference: [4] <author> M. Black and P. Anandan. </author> <title> A framework for the robust estimation of optical flow. </title> <booktitle> In ICCV, </booktitle> <pages> pages 231-236, </pages> <address> Berlin, Germany, </address> <year> 1993. </year>
Reference-contexts: Recently, many have proposed algorithms to counter these assumptions: regularizing with line processes [30, 36], generalizing local models [21, 33], using global parametric motion models [3, 5, 18, 40], and using robust estimation <ref> [4] </ref>. But all of these approaches pursue the goal of flow field estimation; few consider the spatiotemporal structure of kinetic occlusion.
Reference: [5] <author> M. Black and A. Jepson. </author> <title> Estimating optical flow in segmented images using variable order parametric models with local deformations. In Workshop on Non-Rigid Motion and Articulated Objects, </title> <address> Austin, TX, </address> <year> 1994. </year>
Reference-contexts: Recently, many have proposed algorithms to counter these assumptions: regularizing with line processes [30, 36], generalizing local models [21, 33], using global parametric motion models <ref> [3, 5, 18, 40] </ref>, and using robust estimation [4]. But all of these approaches pursue the goal of flow field estimation; few consider the spatiotemporal structure of kinetic occlusion. <p> Any parametric scheme (c.f. <ref> [3, 5, 18] </ref>) could easily be substituted. both of which occlude a static background. Two representative (x; y) frames, and an (x; t) slice are shown in each part. In (a), we depict an idealized segmenta tion of the random dot stimulus shown in (b).
Reference: [6] <author> R. Bolles, H. Baker, and D. Marimont. </author> <title> Epipolar-plane image analysis: An approach to determining structure from motion. </title> <journal> IJCV, </journal> <volume> 1(1) </volume> <pages> 7-56, </pages> <year> 1987. </year>
Reference-contexts: That is, whenever spatiotemporal orientation stops, there is a strong cue to occlusion, i.e. deletion of surface texture; and, whenever spatiotemporal orientation starts, there is a strong cue to disocclusion, i.e. accretion of surface texture <ref> [6] </ref>. We have developed methods to detect kinetic occlusion and differentiate accretion and deletion. With a detected motion boundary, interpretation of kinetic occlusion is straightforward: if the motion boundary moves consistently with either of the surfaces that define it, then that surface is the occluding surface [37]. <p> But all of these approaches pursue the goal of flow field estimation; few consider the spatiotemporal structure of kinetic occlusion. Exceptions are Zetsche et al. [41], who apply 3-d curvature operators directly to image sequences, and Bolles et al. <ref> [6] </ref>, who bypass the detection problem that we address here, and offer a global, feature-based analysis of kinetic occlusion. Distributed representations of motion, as used by biological visual systems, do not suffer from the problems of explicit velocity field construction.
Reference: [7] <author> G. DeAngelis, I. Ohzawa, and R. Freeman. </author> <title> Spatiotemporal organization of simple-cell receptive fields in the cat's striate cortex I. General characteristics and postnatal development. </title> <journal> Journal of Neurophysiology, </journal> <volume> 69(4) </volume> <pages> 1091-1117, </pages> <year> 1993. </year>
Reference-contexts: The second stage pools the squared responses of these filters to construct units tuned to velocity. The above operations model the V1-MT "Fourier" motion pathway: simple cells in V1 are modeled with spatiotemporally oriented filters, complex cells in V1 are modeled by squaring operations <ref> [7, 8] </ref>; velocity-tuned cells in MT are modeled by summing the response of complex cells with frequency selectivities centered on a plane in the frequency domain for a given velocity [14, 34].
Reference: [8] <author> R. Emerson, J. Bergen, and E. Adelson. </author> <title> Directionally selective complex cells and the computation of motion energy in cat visual cortex. </title> <journal> Vision Research, </journal> <volume> 32(2) </volume> <pages> 203-18, </pages> <year> 1992. </year>
Reference-contexts: The second stage pools the squared responses of these filters to construct units tuned to velocity. The above operations model the V1-MT "Fourier" motion pathway: simple cells in V1 are modeled with spatiotemporally oriented filters, complex cells in V1 are modeled by squaring operations <ref> [7, 8] </ref>; velocity-tuned cells in MT are modeled by summing the response of complex cells with frequency selectivities centered on a plane in the frequency domain for a given velocity [14, 34].
Reference: [9] <author> L. Finkel and P. Sajda. </author> <title> Object discrimination based on depth-from-occlusion. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 901-921, </pages> <year> 1992. </year>
Reference-contexts: By detecting motion boundaries, other visual modules may be aided: motion estimation can be improved by indicating where smoothing of motion estimates should not occur; and, as spatiotemporal junction analysis yields information similar to spatial junction analysis, our module can be used for surface segregation processes <ref> [9, 17, 27] </ref>. <p> Furthermore, with a detected ordinal cue to depth, we can determine the depth ordering of surfaces locally: our detected occlusion can be used to activate direction of figure representations, as is done in the models of <ref> [9, 17] </ref>. A global depth ordering of surfaces can also be attempted from these local cues [40]. Finally, the detection of motion boundaries can allow for improved motion estimation: in addition to activating line processes due to velocity gradients, we can activate them by detecting kinetic occlusion.
Reference: [10] <author> D. Fleet and K. Langley. </author> <title> Computational analysis of non-Fourier motion. </title> <booktitle> Vision Research, </booktitle> <address> 34(22):3057, </address> <year> 1994. </year>
Reference-contexts: In motion shear, for example, surface motions ~v 1 and ~v 2 move tangent to the motion boundary, but neither surface is occluded. Because motion and kinetic occlusion possess a rich structure both in the spatiotemporal domain and in the spatiotemporal frequency domain <ref> [1, 10, 14] </ref>, we can develop filtering methods with simple non-linearities to analyze kinetic occlusion. <p> An asymmetry in detecting appearance and disappearance is expected; considering the temporal dynamics of distributed winner-take all mechanisms could handle this asymmetry in part. Third, while we have explored occlusion exclusively here, other motion stimuli, such as multiplicative transparency, can also be considered as second order motion stimuli <ref> [10] </ref>; providing a general model of second order motion analysis is desirable. Most importantly, our current analysis is purely local; no spatiotempo-ral propagation has been attempted. Solutions to spatial contour completion [17, 27] are likely to be extendable to spatiotemporal surface completion.
Reference: [11] <author> W. Freeman. </author> <title> Steerable filters and the local analysis of image structure. </title> <type> PhD thesis, </type> <institution> MIT Dept. Media Arts and Sciences, </institution> <month> September </month> <year> 1992. </year>
Reference-contexts: (x) fi (1 M (x)) = I 2 (x)(1 M (x)) I (x) I 1 (x) fi M (x) = I 1 (x)M (x) I 2 (x) fi (1 M (x)) = I 2 (x)(1 M (x)) I (x) (x; t); (b,d) where x = (x; y; t). junction analysis <ref> [11, 16, 31] </ref> to space-time. <p> First, considerable improvements can be made on the details of our detection methods alone. Other mechanisms which signal the presence of a given orientation and motion can be easily constructed. Combining techniques used in spatial junction analysis <ref> [11, 16, 31] </ref> and our spa-tiotemporal junction analysis in a unified framework is in order. Second, we are currently using non-causal operations. An asymmetry in detecting appearance and disappearance is expected; considering the temporal dynamics of distributed winner-take all mechanisms could handle this asymmetry in part.
Reference: [12] <author> W. Freeman and E. Adelson. </author> <title> The design and use of steerable filters. </title> <journal> IEEE PAMI, </journal> <volume> 13(9) </volume> <pages> 891-906, </pages> <year> 1991. </year>
Reference-contexts: phase-invariant "motion energy" signal E ~v n (x) can be obtained [1]: E ~v n (x) = (I (x) fl G (x)) + (I (x) fl H (x)) (11) Gabor functions and derivative of Gaussians are convenient forms for energy extraction; we use derivatives of Gaussians because they are steerable <ref> [12] </ref>. XYT Energy extraction. In (x; y; t), distributed representations of motion are constructed via a two-stage process, as suggested by [24]. The first stage involves filtering an image sequence with spatiotemporally oriented filters. The second stage pools the squared responses of these filters to construct units tuned to velocity. <p> We utilize the method developed in [34] to extract en ergy along planes in the frequency domain using tools of steerable filtering <ref> [12, 20] </ref>. We summarize the method be low. <p> Given signals E ~v n (x) which respond only if motion ~v n is dominant locally, we construct a signal R ~v n (x) which signals the disappearance or appearance of first order motion ~v n : where Q ~v n (x) is a first derivative of a Gaussian steered <ref> [12] </ref> orthogonally to the direction of motion. In (x; t): Q ~v n (x) = [G x (x); G t (x)] n ~v n (17) and G x (x) and G t (x) are derivatives of 2-d Gaussians in the x, y, and t directions.
Reference: [13] <author> N. Grzywacz and A. Yuille. </author> <title> A model for the estimate of local image velocity by cells in the visual cortex. </title> <journal> Proceedings Royal Society London B, </journal> <volume> 239 </volume> <pages> 129-61, </pages> <year> 1990. </year>
Reference-contexts: Distributed representations of motion, as used by biological visual systems, do not suffer from the problems of explicit velocity field construction. Rather than representing velocities explicitly, models of human visual motion sensing <ref> [13, 14, 34] </ref> use combinations of spatiotem-porally oriented filters to construct distributed representations of velocity-tuned units. We utilize the flexibility of these representations to extract motion boundaries defined by kinetic occlusion. By constructing mechanisms which observe how distributed representations of motion change over time, we can detect kinetic occlusion. <p> + ~v t ~v n ~v n - ~v m m m 6 ~v t ~v n ~v 2 @I 6 1 ~v t can construct distributed representations of motion with spatiotemporally oriented filters tuned to portions of the line in (x; t) [1] or plane in (x; y; t) <ref> [13, 14, 34] </ref>. The task of second order motion analysis is to deduce as much information as possible about the attenuation mask M (x). This involves: (1) detection of occlusion; (2) determining the motion ~v n m . 3 Detecting Occlusion We focus on the detection problem exclusively here. <p> (x) = R ~v 1 (x) (c) E ~v 2 (x) (e) ~ E ~v 2 (x) fl Q ~v 2 (x) = R ~v 2 (x) motion energy E ~v n (x) is possible by filtering the stimulus I (x) with banks of spatiotemporal filters centered on the line/plane <ref> [1, 13, 14] </ref>. XT Energy extraction.
Reference: [14] <author> D. Heeger. </author> <title> Model for the extraction of image flow. </title> <journal> JOSA A, </journal> <volume> 4 </volume> <pages> 1455-1471, </pages> <year> 1987. </year>
Reference-contexts: Distributed representations of motion, as used by biological visual systems, do not suffer from the problems of explicit velocity field construction. Rather than representing velocities explicitly, models of human visual motion sensing <ref> [13, 14, 34] </ref> use combinations of spatiotem-porally oriented filters to construct distributed representations of velocity-tuned units. We utilize the flexibility of these representations to extract motion boundaries defined by kinetic occlusion. By constructing mechanisms which observe how distributed representations of motion change over time, we can detect kinetic occlusion. <p> In motion shear, for example, surface motions ~v 1 and ~v 2 move tangent to the motion boundary, but neither surface is occluded. Because motion and kinetic occlusion possess a rich structure both in the spatiotemporal domain and in the spatiotemporal frequency domain <ref> [1, 10, 14] </ref>, we can develop filtering methods with simple non-linearities to analyze kinetic occlusion. <p> + ~v t ~v n ~v n - ~v m m m 6 ~v t ~v n ~v 2 @I 6 1 ~v t can construct distributed representations of motion with spatiotemporally oriented filters tuned to portions of the line in (x; t) [1] or plane in (x; y; t) <ref> [13, 14, 34] </ref>. The task of second order motion analysis is to deduce as much information as possible about the attenuation mask M (x). This involves: (1) detection of occlusion; (2) determining the motion ~v n m . 3 Detecting Occlusion We focus on the detection problem exclusively here. <p> (x) = R ~v 1 (x) (c) E ~v 2 (x) (e) ~ E ~v 2 (x) fl Q ~v 2 (x) = R ~v 2 (x) motion energy E ~v n (x) is possible by filtering the stimulus I (x) with banks of spatiotemporal filters centered on the line/plane <ref> [1, 13, 14] </ref>. XT Energy extraction. <p> pathway: simple cells in V1 are modeled with spatiotemporally oriented filters, complex cells in V1 are modeled by squaring operations [7, 8]; velocity-tuned cells in MT are modeled by summing the response of complex cells with frequency selectivities centered on a plane in the frequency domain for a given velocity <ref> [14, 34] </ref>. We utilize the method developed in [34] to extract en ergy along planes in the frequency domain using tools of steerable filtering [12, 20]. We summarize the method be low.
Reference: [15] <author> D. Heeger. </author> <title> Normalization of cell responses in cat striate cortex. </title> <journal> Visual Neuroscience, </journal> <volume> 9 </volume> <pages> 181-197, </pages> <year> 1992. </year>
Reference-contexts: At high contrasts, division by neighboring orientations results in contrast invariance. At low contrasts, dominates, so the response is near zero. We have found that a winner-take-all scheme is necessary; simple normalization by local energy, such as in the model of <ref> [15] </ref>, does not provide the level of inhibition that we need. Choosing the neighborhood of ~v n + ffi~v is straightforward.
Reference: [16] <author> F. Heitger, L. Rosenthaler, R. von der Heydt, E. Peterhans, and O. Kubler. </author> <title> Simulation of neural contour mechanisms: From simple to end-stopped cells. </title> <journal> Vision Research, </journal> <volume> 32(5) </volume> <pages> 963-981, </pages> <year> 1992. </year>
Reference-contexts: (x) fi (1 M (x)) = I 2 (x)(1 M (x)) I (x) I 1 (x) fi M (x) = I 1 (x)M (x) I 2 (x) fi (1 M (x)) = I 2 (x)(1 M (x)) I (x) (x; t); (b,d) where x = (x; y; t). junction analysis <ref> [11, 16, 31] </ref> to space-time. <p> First, considerable improvements can be made on the details of our detection methods alone. Other mechanisms which signal the presence of a given orientation and motion can be easily constructed. Combining techniques used in spatial junction analysis <ref> [11, 16, 31] </ref> and our spa-tiotemporal junction analysis in a unified framework is in order. Second, we are currently using non-causal operations. An asymmetry in detecting appearance and disappearance is expected; considering the temporal dynamics of distributed winner-take all mechanisms could handle this asymmetry in part.
Reference: [17] <author> F. Heitger and R. von der Heydt. </author> <title> A computational model of neural contour processing: Figure-ground segregation and illusory contours. </title> <booktitle> In ICCV, </booktitle> <pages> pages 32-40, </pages> <address> Berlin, Germany, </address> <year> 1993. </year>
Reference-contexts: By detecting motion boundaries, other visual modules may be aided: motion estimation can be improved by indicating where smoothing of motion estimates should not occur; and, as spatiotemporal junction analysis yields information similar to spatial junction analysis, our module can be used for surface segregation processes <ref> [9, 17, 27] </ref>. <p> Most importantly, our current analysis is purely local; no spatiotempo-ral propagation has been attempted. Solutions to spatial contour completion <ref> [17, 27] </ref> are likely to be extendable to spatiotemporal surface completion. <p> Furthermore, with a detected ordinal cue to depth, we can determine the depth ordering of surfaces locally: our detected occlusion can be used to activate direction of figure representations, as is done in the models of <ref> [9, 17] </ref>. A global depth ordering of surfaces can also be attempted from these local cues [40]. Finally, the detection of motion boundaries can allow for improved motion estimation: in addition to activating line processes due to velocity gradients, we can activate them by detecting kinetic occlusion.
Reference: [18] <author> M. Irani, B. Rousso, and S. Peleg. </author> <title> Computing occluding and transparent motions. </title> <journal> IJCV, </journal> <volume> 12(1) </volume> <pages> 1-16, </pages> <year> 1994. </year>
Reference-contexts: Recently, many have proposed algorithms to counter these assumptions: regularizing with line processes [30, 36], generalizing local models [21, 33], using global parametric motion models <ref> [3, 5, 18, 40] </ref>, and using robust estimation [4]. But all of these approaches pursue the goal of flow field estimation; few consider the spatiotemporal structure of kinetic occlusion. <p> Any parametric scheme (c.f. <ref> [3, 5, 18] </ref>) could easily be substituted. both of which occlude a static background. Two representative (x; y) frames, and an (x; t) slice are shown in each part. In (a), we depict an idealized segmenta tion of the random dot stimulus shown in (b).
Reference: [19] <author> G. A. Kaplan. </author> <title> Kinetic disruption of optical texture: The perception of depth at an edge. </title> <journal> Perception and Psychophysics, </journal> <volume> 6(4) </volume> <pages> 193-198, </pages> <year> 1969. </year>
Reference-contexts: 1 Introduction With motion boundaries as the sole cue, surfaces can easily be segmented, recognized, and perceived as having a distinct ordering in depth <ref> [19, 32] </ref>. Under natural conditions, motion boundaries are formed by occluding surfaces in motion. Relative motion of occluding surfaces generically results in accretion or deletion of surface texture of the occluded surface by the occluding surface. This basic phenomena, which we will call kinetic occlusion, is illustrated in Figure 1.
Reference: [20] <author> J. Koenderink. </author> <title> Generic neighborhood operators. </title> <journal> IEEE PAMI, </journal> <volume> 14(6) </volume> <pages> 597-605, </pages> <year> 1992. </year>
Reference-contexts: We utilize the method developed in [34] to extract en ergy along planes in the frequency domain using tools of steerable filtering <ref> [12, 20] </ref>. We summarize the method be low.
Reference: [21] <author> K. Langley, D. Fleet, and T. Atherton. </author> <title> Multiple motions from instantaneous frequency. </title> <booktitle> In CVPR, </booktitle> <pages> pages 846-849, </pages> <year> 1992. </year>
Reference-contexts: Recently, many have proposed algorithms to counter these assumptions: regularizing with line processes [30, 36], generalizing local models <ref> [21, 33] </ref>, using global parametric motion models [3, 5, 18, 40], and using robust estimation [4]. But all of these approaches pursue the goal of flow field estimation; few consider the spatiotemporal structure of kinetic occlusion.
Reference: [22] <author> V. Marcar and A. Cowey. </author> <title> Do cells in area V2 respond to the orientation of kinetic boundaries? In Society of Neuroscience Abstracts, </title> <booktitle> volume 18, </booktitle> <pages> page 1275, </pages> <year> 1992. </year>
Reference-contexts: While V1 and MT cells are not selective to the orientation of kinetic boundaries, a considerable percentage of cells in V2 and V3 possess identical orientation selectivity for both luminance and kinetic-defined boundaries <ref> [22, 29] </ref>. Furthermore, cells in ventral MST have been shown to have their responses modulated by accretion and deletion cues [35].
Reference: [23] <author> V. Marcar and A. Cowey. </author> <title> The effect of removing superior temporal cortical motion areas in the macaque monkey: II. Motion discrimination using random dot displays. </title> <journal> European Journal of Neuroscience, </journal> <volume> 4 </volume> <pages> 1228-1238, </pages> <year> 1992. </year>
Reference-contexts: Lesion studies in monkeys and humans offer a means of deducing which visual areas might be involved in detecting motion boundaries. Ablation of area MT causes monkeys' performance on motion-defined shape discrimination tasks to be severely impaired <ref> [23] </ref>, while psychophysical experiments on humans with parietotemporal lesions indicates a double disassociation between motion discontinuity detection and motion coherence discrimination [38]. This evidence suggests that there are separate neural substrates for representing discontinuities and computing motion, probably involving MT/MST.
Reference: [24] <author> A. Movshon, E. Adelson, M. Gizzi, and W. Newsome. </author> <title> The analysis of moving visual patterns. </title> <journal> Experimental Brain Research, </journal> <volume> 11 </volume> <pages> 117-152, </pages> <year> 1986. </year>
Reference-contexts: XYT Energy extraction. In (x; y; t), distributed representations of motion are constructed via a two-stage process, as suggested by <ref> [24] </ref>. The first stage involves filtering an image sequence with spatiotemporally oriented filters. The second stage pools the squared responses of these filters to construct units tuned to velocity.
Reference: [25] <author> K. Mutch and W. Thompson. </author> <title> Analysis of accretion and deletion at boundaries in dynamic scenes. </title> <journal> IEEE PAMI, </journal> <volume> 7(2) </volume> <pages> 133-138, </pages> <year> 1985. </year>
Reference-contexts: First, surfaces can be segregated on the basis of kinetic occlusion. Detecting edges in velocity fields [37] and detecting appearance and disappearance in token-tracking schemes <ref> [25] </ref> is difficult; we offer an alternate possibility. Second, by discontinuing use of optical flow upon occlusion detec tion, and continuing use of optical flow upon disocclusion detection, we can potentially track surfaces through occlusion.
Reference: [26] <author> K. Nakayama and J. Loomis. </author> <title> Optical velocity patterns, velocity-sensitive neurons, and space perception: A hypothesis. </title> <journal> Perception, </journal> <volume> 3 </volume> <pages> 63-80, </pages> <year> 1974. </year>
Reference-contexts: We should recognize, of course, that motion boundary extraction can be based on both relative motion cues and occlusion cues. Mechanisms which may process relative motion cues, such as the center-surround mechanisms proposed by <ref> [26] </ref>, have been found (c.f. [2]), thus complicating interpretations of physiological data. While V1 and MT cells are not selective to the orientation of kinetic boundaries, a considerable percentage of cells in V2 and V3 possess identical orientation selectivity for both luminance and kinetic-defined boundaries [22, 29].
Reference: [27] <author> M. Nitzberg, D. Mumford, and S. Shiota. </author> <title> Filtering, Segmentation and Depth, volume 622. </title> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: By detecting motion boundaries, other visual modules may be aided: motion estimation can be improved by indicating where smoothing of motion estimates should not occur; and, as spatiotemporal junction analysis yields information similar to spatial junction analysis, our module can be used for surface segregation processes <ref> [9, 17, 27] </ref>. <p> Most importantly, our current analysis is purely local; no spatiotempo-ral propagation has been attempted. Solutions to spatial contour completion <ref> [17, 27] </ref> are likely to be extendable to spatiotemporal surface completion.
Reference: [28] <author> S. Niyogi. </author> <title> Kinetic occlusion. </title> <type> Technical Report 319, </type> <institution> MIT Media Lab Vision and Modeling, </institution> <year> 1995. </year> <month> ftp://whitechapel.media.mit.edu/pub/tech-reports </month>
Reference-contexts: Filter coefficients used in all of our experiments can be found in <ref> [28] </ref>. <p> By detecting changes in the direction of motion, the sign of R ~v n (x) differentiates accretion from deletion. Deletion of surface texture is reflected by negative responses in R ~v n (x); accretion of surface texture is reflected by positive responses. In <ref> [28] </ref>, we provide an in depth interpretation of this occlusion model and detection algorithm. We show that the image formation model involves modulation of information about the mask M (x) along the line/plane corresponding to the occluded surface I 1 (x). <p> Further experimentation is reported in <ref> [28] </ref>. In our experiments, simulations were simplified tremendously by only detecting kinetic occlusion for k dominant motions.
Reference: [29] <author> E. Peterhans and J. Baumann. </author> <title> Elements of form processing from motion in monkey prestriate cortex. </title> <journal> In Society of Neu-roscience Abstracts, </journal> <volume> volume 20, </volume> <pages> page 1053, </pages> <year> 1994. </year>
Reference-contexts: While V1 and MT cells are not selective to the orientation of kinetic boundaries, a considerable percentage of cells in V2 and V3 possess identical orientation selectivity for both luminance and kinetic-defined boundaries <ref> [22, 29] </ref>. Furthermore, cells in ventral MST have been shown to have their responses modulated by accretion and deletion cues [35].
Reference: [30] <author> T. Poggio, V. Torre, and C. Koch. </author> <title> Computational vision and regularization theory. </title> <journal> Nature, </journal> <volume> 317(26) </volume> <pages> 314-319, </pages> <year> 1985. </year>
Reference-contexts: Recently, many have proposed algorithms to counter these assumptions: regularizing with line processes <ref> [30, 36] </ref>, generalizing local models [21, 33], using global parametric motion models [3, 5, 18, 40], and using robust estimation [4]. But all of these approaches pursue the goal of flow field estimation; few consider the spatiotemporal structure of kinetic occlusion.
Reference: [31] <author> L. Rosenthaler, F. Heitger, O. Kubler, and R. von der Heydt. </author> <title> Detection of general edges and keypoints. </title> <booktitle> In ECCV, </booktitle> <pages> pages 78-86, </pages> <year> 1992. </year>
Reference-contexts: (x) fi (1 M (x)) = I 2 (x)(1 M (x)) I (x) I 1 (x) fi M (x) = I 1 (x)M (x) I 2 (x) fi (1 M (x)) = I 2 (x)(1 M (x)) I (x) (x; t); (b,d) where x = (x; y; t). junction analysis <ref> [11, 16, 31] </ref> to space-time. <p> First, considerable improvements can be made on the details of our detection methods alone. Other mechanisms which signal the presence of a given orientation and motion can be easily constructed. Combining techniques used in spatial junction analysis <ref> [11, 16, 31] </ref> and our spa-tiotemporal junction analysis in a unified framework is in order. Second, we are currently using non-causal operations. An asymmetry in detecting appearance and disappearance is expected; considering the temporal dynamics of distributed winner-take all mechanisms could handle this asymmetry in part.
Reference: [32] <author> C. S. Royden, J. F. Baker, and J. Allman. </author> <title> Perceptions of depth elicited by occluded and shearing motions of random dots. </title> <journal> Perception, </journal> <volume> 17 </volume> <pages> 289-296, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction With motion boundaries as the sole cue, surfaces can easily be segmented, recognized, and perceived as having a distinct ordering in depth <ref> [19, 32] </ref>. Under natural conditions, motion boundaries are formed by occluding surfaces in motion. Relative motion of occluding surfaces generically results in accretion or deletion of surface texture of the occluded surface by the occluding surface. This basic phenomena, which we will call kinetic occlusion, is illustrated in Figure 1.
Reference: [33] <author> M. Shizawa and K. Mase. </author> <title> A unified computational theory for motion transparency and motion boundaries based on eigenen-ergy analysis. </title> <booktitle> In IEEE CVPR, </booktitle> <year> 1991. </year>
Reference-contexts: Recently, many have proposed algorithms to counter these assumptions: regularizing with line processes [30, 36], generalizing local models <ref> [21, 33] </ref>, using global parametric motion models [3, 5, 18, 40], and using robust estimation [4]. But all of these approaches pursue the goal of flow field estimation; few consider the spatiotemporal structure of kinetic occlusion.
Reference: [34] <author> E. Simoncelli. </author> <title> Distributed Representations of Motion. </title> <type> PhD thesis, </type> <institution> MIT Dept. of Electrical Engineering, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: Distributed representations of motion, as used by biological visual systems, do not suffer from the problems of explicit velocity field construction. Rather than representing velocities explicitly, models of human visual motion sensing <ref> [13, 14, 34] </ref> use combinations of spatiotem-porally oriented filters to construct distributed representations of velocity-tuned units. We utilize the flexibility of these representations to extract motion boundaries defined by kinetic occlusion. By constructing mechanisms which observe how distributed representations of motion change over time, we can detect kinetic occlusion. <p> + ~v t ~v n ~v n - ~v m m m 6 ~v t ~v n ~v 2 @I 6 1 ~v t can construct distributed representations of motion with spatiotemporally oriented filters tuned to portions of the line in (x; t) [1] or plane in (x; y; t) <ref> [13, 14, 34] </ref>. The task of second order motion analysis is to deduce as much information as possible about the attenuation mask M (x). This involves: (1) detection of occlusion; (2) determining the motion ~v n m . 3 Detecting Occlusion We focus on the detection problem exclusively here. <p> pathway: simple cells in V1 are modeled with spatiotemporally oriented filters, complex cells in V1 are modeled by squaring operations [7, 8]; velocity-tuned cells in MT are modeled by summing the response of complex cells with frequency selectivities centered on a plane in the frequency domain for a given velocity <ref> [14, 34] </ref>. We utilize the method developed in [34] to extract en ergy along planes in the frequency domain using tools of steerable filtering [12, 20]. We summarize the method be low. <p> We utilize the method developed in <ref> [34] </ref> to extract en ergy along planes in the frequency domain using tools of steerable filtering [12, 20]. We summarize the method be low.
Reference: [35] <author> Y. Sugita and K. Tanaka. </author> <title> Occlusion-related cue used for analysis of motion in visual cortex. </title> <journal> NeuroReport, </journal> <volume> 2 </volume> <pages> 751-754, </pages> <year> 1991. </year>
Reference-contexts: Furthermore, cells in ventral MST have been shown to have their responses modulated by accretion and deletion cues <ref> [35] </ref>.
Reference: [36] <author> D. Terzopoulos. </author> <title> Regularization of inverse problems involving discontinuities. </title> <journal> IEEE PAMI, </journal> <volume> 8 </volume> <pages> 413-424, </pages> <year> 1986. </year>
Reference-contexts: Recently, many have proposed algorithms to counter these assumptions: regularizing with line processes <ref> [30, 36] </ref>, generalizing local models [21, 33], using global parametric motion models [3, 5, 18, 40], and using robust estimation [4]. But all of these approaches pursue the goal of flow field estimation; few consider the spatiotemporal structure of kinetic occlusion.
Reference: [37] <author> W. Thompson, K. Mutch, and V. Berzins. </author> <title> Dynamic occlusion analysis in optical flow fields. </title> <journal> IEEE PAMI, </journal> <volume> 7(4) </volume> <pages> 374-383, </pages> <year> 1985. </year>
Reference-contexts: We have developed methods to detect kinetic occlusion and differentiate accretion and deletion. With a detected motion boundary, interpretation of kinetic occlusion is straightforward: if the motion boundary moves consistently with either of the surfaces that define it, then that surface is the occluding surface <ref> [37] </ref>. If motion could be estimated accurately near motion boundaries, then edges could be detected in the velocity field. <p> Biological modeling considerations aside, we have demonstrated feasibility of detecting motion boundaries defined by kinetic occlusion, and offer a new tool which can be used in a variety of computer vision tasks. First, surfaces can be segregated on the basis of kinetic occlusion. Detecting edges in velocity fields <ref> [37] </ref> and detecting appearance and disappearance in token-tracking schemes [25] is difficult; we offer an alternate possibility. Second, by discontinuing use of optical flow upon occlusion detec tion, and continuing use of optical flow upon disocclusion detection, we can potentially track surfaces through occlusion.
Reference: [38] <author> L. Vaina, N. Grzywacz, and R. Kikinis. </author> <title> Segregation of computations underlying perception of motion discontinuity and coherence. </title> <address> NeuroReport, 5(17):2289, </address> <year> 1994. </year>
Reference-contexts: Ablation of area MT causes monkeys' performance on motion-defined shape discrimination tasks to be severely impaired [23], while psychophysical experiments on humans with parietotemporal lesions indicates a double disassociation between motion discontinuity detection and motion coherence discrimination <ref> [38] </ref>. This evidence suggests that there are separate neural substrates for representing discontinuities and computing motion, probably involving MT/MST. Selectivity for the orientation of motion boundaries, defined by kinetic occlusion and relative motion, has been tested in visual areas V1, V2, V3, and MT through single cell recordings.
Reference: [39] <author> D. C. van Essen, C. Anderson, and D. Felleman. </author> <title> Information processing in the primate visual system. </title> <journal> Science, </journal> <volume> 255(5043) </volume> <pages> 419-422, </pages> <year> 1992. </year>
Reference-contexts: Since our models of first order motion analysis are based on models of human visual motion sensing, we suggest that we have modeled the computations necessary for one of the interactions between the motion and form processing streams in primate vision (c.f. <ref> [39] </ref>). Lesion studies in monkeys and humans offer a means of deducing which visual areas might be involved in detecting motion boundaries.
Reference: [40] <author> J. Y. A. Wang and E. H. Adelson. </author> <title> Representing moving images with layers. </title> <journal> IEEE Image Processing, </journal> <volume> 3(5) </volume> <pages> 625-638, </pages> <year> 1994. </year>
Reference-contexts: Recently, many have proposed algorithms to counter these assumptions: regularizing with line processes [30, 36], generalizing local models [21, 33], using global parametric motion models <ref> [3, 5, 18, 40] </ref>, and using robust estimation [4]. But all of these approaches pursue the goal of flow field estimation; few consider the spatiotemporal structure of kinetic occlusion. <p> models of biological motion processing, we provide a model for one of most salient interactions between the motion processing pathway and the form processing pathway in biological visual systems. 2 Modeling Occlusion We model the local structure present in occlusions directly by applying the "layers" model of Wang and Adelson <ref> [40] </ref>: a layer I n (x) attenuates the luminance of the layer I n1 (x) beneath it by a factor ff n (x) (0 ff (x) 1), and contributes its own emission e n (x). <p> Further experimentation is reported in [28]. In our experiments, simulations were simplified tremendously by only detecting kinetic occlusion for k dominant motions. Dominant motions ~v n (x) are extracted via the k means clustering technique used in <ref> [40] </ref>; the technique uses k-means clustering to local affine parameter fits of optical flow to find k dominant motions described by: ~v n (x) = a x (t) + a xx (t)x + a xy (t)y i where ~a n (t) = [a x ; a xx ; a xy ; <p> A global depth ordering of surfaces can also be attempted from these local cues <ref> [40] </ref>. Finally, the detection of motion boundaries can allow for improved motion estimation: in addition to activating line processes due to velocity gradients, we can activate them by detecting kinetic occlusion. Motion estimation algorithms, relying on "constant intensity" and "single velocity" assumptions, have always had difficulty near motion boundaries.
Reference: [41] <author> C. Zetzsche, E. Barth, and J. Berkmann. </author> <title> Spatiotemporal curvature measures for flow field analysis. </title> <booktitle> In SPIE Geometric Methods in Computer Vision, </booktitle> <volume> volume 1570, </volume> <pages> pages 337-350, </pages> <year> 1991. </year>
Reference-contexts: But all of these approaches pursue the goal of flow field estimation; few consider the spatiotemporal structure of kinetic occlusion. Exceptions are Zetsche et al. <ref> [41] </ref>, who apply 3-d curvature operators directly to image sequences, and Bolles et al. [6], who bypass the detection problem that we address here, and offer a global, feature-based analysis of kinetic occlusion.
References-found: 41

