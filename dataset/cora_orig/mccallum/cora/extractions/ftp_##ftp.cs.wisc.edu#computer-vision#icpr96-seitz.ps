URL: ftp://ftp.cs.wisc.edu/computer-vision/icpr96-seitz.ps
Refering-URL: http://www.cs.wisc.edu/computer-vision/pubs.html
Root-URL: 
Email: seitz@cs.wisc.edu dyer@cs.wisc.edu  
Title: Toward Image-Based Scene Representation Using View Morphing  
Author: Steven M. Seitz Charles R. Dyer 
Date: 1996.  
Note: To appear in Proc. 13th Intl. Conf. on Pattern Recognition, Vienna,  
Address: Madison, WI 53706  
Affiliation: Department of Computer Sciences University of Wisconsin  
Abstract: The question of which views may be inferred from a set of basis images is addressed. Under certain conditions, a discrete set of images implicitly describes scene appearance for a continuous range of viewpoints. In particular, it is demonstrated that two basis views of a static scene determine the set of all views on the line between their optical centers. Additional basis views further extend the range of predictable views to a two- or three-dimensional region of viewspace. These results are shown to apply under perspective projection subject to a generic visibility constraint called mono-tonicity. In addition, a simple scanline algorithm is presented for actually generating these views from a set of basis images. The technique, called view morphing may be applied to both calibrated and uncalibrated images. At a minimum, two basis views and their fundamental matrix are needed. Experimental results are presented on real images. This work provides a theoretical foundation for image-based representations of 3D scenes by demonstrating that perspective view synthesis is a theoretically well-posed problem. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. E. Chen. </author> <title> Quicktime VR An image-based approach to virtual environment navigation. </title> <booktitle> In Proc. SIGGRAPH 95, </booktitle> <pages> pages 29-38, </pages> <year> 1995. </year>
Reference-contexts: 1 Introduction Image-based representations of 3D scenes are currently being developed by many researchers in the computer vision and computer graphics communities (see, for example, <ref> [4, 5, 1, 3, 13] </ref>). These representations encode scene appearance with a set of images that may be adaptively combined to produce new views of a scene. Image-based techniques are especially attractive because they provide photometric information which has proven very valuable for recognition tasks.
Reference: [2] <author> S. E. Chen and L. Williams. </author> <title> View interpolation for image synthesis. </title> <booktitle> In Proc. SIGGRAPH 93, </booktitle> <pages> pages 279-288, </pages> <year> 1993. </year>
Reference-contexts: It is not clear, how The support of the National Science Foundation under Grant Nos. IRI-9220782 and CDA-9222948 is gratefully acknowledged. ever, that a more complete coverage of viewspace is theoretically possible. A number of view synthesis techniques have been developed recently <ref> [4, 2, 5, 7] </ref> to extend the range of predictable views. However, those methods require solving ill-posed correspondence tasks, suggesting that the view synthesis problem is inherently ill-posed.
Reference: [3] <author> R. Kumar, P. Anandan, M. Irani, J. Bergen, and K. Hanna. </author> <title> Representation of scenes from collections of images. </title> <booktitle> In Proc. IEEE Workshop on Representations of Visual Scenes, </booktitle> <pages> pages 10-17, </pages> <year> 1995. </year>
Reference-contexts: 1 Introduction Image-based representations of 3D scenes are currently being developed by many researchers in the computer vision and computer graphics communities (see, for example, <ref> [4, 5, 1, 3, 13] </ref>). These representations encode scene appearance with a set of images that may be adaptively combined to produce new views of a scene. Image-based techniques are especially attractive because they provide photometric information which has proven very valuable for recognition tasks.
Reference: [4] <author> S. Laveau and O. Faugeras. </author> <title> 3-D scene representation as a collection of images. </title> <booktitle> In Proc. International Conference on Pattern Recognition, </booktitle> <pages> pages 689-691, </pages> <year> 1994. </year>
Reference-contexts: 1 Introduction Image-based representations of 3D scenes are currently being developed by many researchers in the computer vision and computer graphics communities (see, for example, <ref> [4, 5, 1, 3, 13] </ref>). These representations encode scene appearance with a set of images that may be adaptively combined to produce new views of a scene. Image-based techniques are especially attractive because they provide photometric information which has proven very valuable for recognition tasks. <p> It is not clear, how The support of the National Science Foundation under Grant Nos. IRI-9220782 and CDA-9222948 is gratefully acknowledged. ever, that a more complete coverage of viewspace is theoretically possible. A number of view synthesis techniques have been developed recently <ref> [4, 2, 5, 7] </ref> to extend the range of predictable views. However, those methods require solving ill-posed correspondence tasks, suggesting that the view synthesis problem is inherently ill-posed. <p> One solution is to have the user provide the homography directly or indirectly by specification of a small number of image points <ref> [4, 12] </ref>. Another method is to simply interpolate the components of H 1 0 and H 1 1 , resulting in a continuous transition from I 0 to I 1 [11]. Both methods for choosing the postwarp transforms generally result in the synthesis of projective views.
Reference: [5] <author> L. McMillan and G. Bishop. </author> <booktitle> Plenoptic modeling. In Proc. SIGGRAPH 95, </booktitle> <pages> pages 39-46, </pages> <year> 1995. </year>
Reference-contexts: 1 Introduction Image-based representations of 3D scenes are currently being developed by many researchers in the computer vision and computer graphics communities (see, for example, <ref> [4, 5, 1, 3, 13] </ref>). These representations encode scene appearance with a set of images that may be adaptively combined to produce new views of a scene. Image-based techniques are especially attractive because they provide photometric information which has proven very valuable for recognition tasks. <p> It is not clear, how The support of the National Science Foundation under Grant Nos. IRI-9220782 and CDA-9222948 is gratefully acknowledged. ever, that a more complete coverage of viewspace is theoretically possible. A number of view synthesis techniques have been developed recently <ref> [4, 2, 5, 7] </ref> to extend the range of predictable views. However, those methods require solving ill-posed correspondence tasks, suggesting that the view synthesis problem is inherently ill-posed.
Reference: [6] <author> Y. Ohta and T. Kanade. </author> <title> Stereo by intra- and inter-scanline search using dynamic programming. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 7(2) </volume> <pages> 139-154, </pages> <year> 1985. </year>
Reference-contexts: The monotonicity constraint dictates that all visible scene points appear in the same order along conjugate epipolar lines of I 0 and I 1 . This constraint is used commonly in stereo matching <ref> [6] </ref> because the fixed relative ordering of points along epipolar lines simplifies the correspondence problem. Despite its usual definition with respect to epipolar lines and images, monotonicity constrains only the location of the optical centers with respect to points in the scenethe image planes may be chosen arbitrarily. <p> The mannequin is an example of an object for which it is difficult to reconstruct but relatively easy to synthesize views due to lack of texture. In this example, image correspondences were automatically determined using a dynamic programming technique <ref> [6] </ref> that exploits monotonicity. Even with the monotonicity constraint, obtaining reliable correspondences with large baselines is a formidable challenge. However, incorporating limited user interaction [12] or domain knowledge can significantly improve the results and is a promising line of future research.
Reference: [7] <author> T. Poggio and D. Beymer. </author> <title> Learning networks for face analysis and synthesis. </title> <booktitle> In Proc. Intl. Workshop on Automatic Face- and Gesture-Recognition, </booktitle> <pages> pages 160-165, </pages> <address> Zurich, </address> <year> 1995. </year>
Reference-contexts: It is not clear, how The support of the National Science Foundation under Grant Nos. IRI-9220782 and CDA-9222948 is gratefully acknowledged. ever, that a more complete coverage of viewspace is theoretically possible. A number of view synthesis techniques have been developed recently <ref> [4, 2, 5, 7] </ref> to extend the range of predictable views. However, those methods require solving ill-posed correspondence tasks, suggesting that the view synthesis problem is inherently ill-posed.
Reference: [8] <author> T. Poggio, V. Torre, and C. Koch. </author> <title> Computational vision and regularization theory. </title> <journal> Nature, </journal> <volume> 317 </volume> <pages> 314-319, </pages> <year> 1985. </year>
Reference-contexts: This conclusion is especially unfortunate in light of the fact that 3D reconstruction from sparse images is generally ambiguousa number of different scenes may be consistent with a given set of images; it is an ill-posed problem <ref> [8] </ref>. This suggests that view synthesis is also ill-posed. In this section we present an alternate paradigm for view synthesis that avoids 3D reconstruction and dense correspondence as intermediate steps, instead relying only on measurable quantities, computable from a set of basis images. <p> Hence, all views along C 0 C 1 are determined from I 0 and I 1 . This result demonstrates that view synthesis under monotonicity is an inherently well-posed problemand is therefore much easier than 3D reconstruction and related motion analysis tasks requiring smoothness conditions and regularization techniques <ref> [8] </ref>. A final question concerns the measurability of mono-tonicity. Under the monotonicity assumption we have established that view synthesis is feasible and relies only on measurable image correspondence information.
Reference: [9] <author> L. Robert, C. Zeller, O. Faugeras, and M. Hebert. </author> <title> Applications of non-metric vision to some visually guided robotics tasks. </title> <type> Technical Report 2584, </type> <institution> INRIA, Sophia-Antipolis, France, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: This procedure is identical to rectification techniques used in stereo vision <ref> [9] </ref>. This sug gests a three-step procedure for view synthesis: 1. Prewarp: ^ I 0 = H 1 0 I 0 , ^ I 1 = H 1 2. <p> Although the particular plane can be chosen arbitrarily, certain planes may be more suitable due to image sampling considerations. Methods of choosing the rectification parameters that minimize image distortion with uniform sampling are discussed in <ref> [9] </ref>. 4 Uncalibrated View Morphing In order to use the view morphing algorithm presented in Section 3, we must find a way to rectify the images without knowing the projection matrices. <p> In terms of F the con dition on H 0 and H 1 is H 1 FH 0 = ^ F (2) Specific solutions to Eq. (2) are discussed in <ref> [11, 9] </ref>. We have established that two images can be rectified, and therefore interpolated, without knowing their projection matrices. As in Section 3, interpolation of the prewarped images results in new views along C 0 C 1 .
Reference: [10] <author> S. M. Seitz and C. R. Dyer. </author> <title> Physically-valid view synthesis by image interpolation. </title> <booktitle> In Proc. IEEE Workshop on Representations of Visual Scenes, </booktitle> <pages> pages 18-25, </pages> <year> 1995. </year>
Reference-contexts: Furthermore, all processing occurs at the scanline level, effectively reducing the original 3D synthesis problem to a set of simple 1D transformations that may be implemented efficiently on existing graphics workstations. The work presented here extends to perspective projection previous results on the orthographic case <ref> [10] </ref>. In addition, this paper discusses extensions to three or more basis views, an important generalization not considered in [10]. We begin by introducing the monotonicity constraint and describing its implications for view synthesis in Section 2. <p> The work presented here extends to perspective projection previous results on the orthographic case <ref> [10] </ref>. In addition, this paper discusses extensions to three or more basis views, an important generalization not considered in [10]. We begin by introducing the monotonicity constraint and describing its implications for view synthesis in Section 2.
Reference: [11] <author> S. M. Seitz and C. R. Dyer. </author> <title> Scene appearance representation by perspective view synthesis. </title> <type> Technical Report CS-TR-1298, </type> <institution> University of Wisconsin, Madison, WI, </institution> <month> May </month> <year> 1996. </year>
Reference-contexts: Towards this end, it can be shown <ref> [11] </ref> that two images are in the parallel configuration when their fundamental matrix is given, up to scalar multiplication, by ^ F = 4 0 0 1 3 We seek a pair of homographies H 0 and H 1 such that the prewarped images ^ I 0 = H 1 1 <p> In terms of F the con dition on H 0 and H 1 is H 1 FH 0 = ^ F (2) Specific solutions to Eq. (2) are discussed in <ref> [11, 9] </ref>. We have established that two images can be rectified, and therefore interpolated, without knowing their projection matrices. As in Section 3, interpolation of the prewarped images results in new views along C 0 C 1 . <p> Another method is to simply interpolate the components of H 1 0 and H 1 1 , resulting in a continuous transition from I 0 to I 1 <ref> [11] </ref>. Both methods for choosing the postwarp transforms generally result in the synthesis of projective views. A projective view is a perspective view warped by a 2D affine transformation. 5 Three Views and Beyond The paper up to this point has focused on image synthesis from exactly two basis views. <p> However, the prediction of any range of view-space depends on the assumption that all possible pairs of views within that space satisfy monotonicity. In particular, a monotonic range may span no more than a single aspect of an aspect graph <ref> [11] </ref>, thus limiting the range of views that may be predicted. Nevertheless, it is clear that a discrete set of views implicitly describes scene appearance from a continuous range of viewpoints.
Reference: [12] <author> S. M. Seitz and C. R. Dyer. </author> <title> View morphing. </title> <booktitle> In Proc. </booktitle> <volume> SIG-GRAPH 96, </volume> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: If this condition is not satisfied, it is still possible to apply the procedure if the prewarped images are never explicitly constructed, i.e., if the prewarp, morph, and postwarp transforms are concatenated into a pair of aggregate warps <ref> [12] </ref>. The prewarp step implicitly requires selection of a particular epipolar plane on which to reproject the basis images. Although the particular plane can be chosen arbitrarily, certain planes may be more suitable due to image sampling considerations. <p> One solution is to have the user provide the homography directly or indirectly by specification of a small number of image points <ref> [4, 12] </ref>. Another method is to simply interpolate the components of H 1 0 and H 1 1 , resulting in a continuous transition from I 0 to I 1 [11]. Both methods for choosing the postwarp transforms generally result in the synthesis of projective views. <p> For the most part monotonicity is satisfied, except in the region of the right ear, nose, and far sides of the face. A sparse set of user-specified feature correspondences was used to determine the correspondence map, using an image morphing technique <ref> [12] </ref>. The synthesized image represents a view from a camera viewpoint halfway between the two basis views. The image gives the convincing impression that the subject has turned his head, despite the fact that only 2D image operations have been performed. <p> In this example, image correspondences were automatically determined using a dynamic programming technique [6] that exploits monotonicity. Even with the monotonicity constraint, obtaining reliable correspondences with large baselines is a formidable challenge. However, incorporating limited user interaction <ref> [12] </ref> or domain knowledge can significantly improve the results and is a promising line of future research. As in the previous example, some artifacts occur where monotonicity is violated, such as near the left foot and the left thigh. <p> The problem may be ameliorated by super-sampling the intermediate images or by concatenating the multiple image transforms into two aggregate warps and resampling only once <ref> [12] </ref>. 7 Conclusion In this paper we considered the question of which views of a static scene may be predicted from a set of two or more basis views, under perspective projection.
Reference: [13] <author> J. Y. A. Wang and E. H. Adelson. </author> <title> Layered representation for motion analysis. </title> <booktitle> In Proc. Computer Vision and Pattern Recognition, </booktitle> <pages> pages 361-366, </pages> <year> 1993. </year> <month> 6 </month>
Reference-contexts: 1 Introduction Image-based representations of 3D scenes are currently being developed by many researchers in the computer vision and computer graphics communities (see, for example, <ref> [4, 5, 1, 3, 13] </ref>). These representations encode scene appearance with a set of images that may be adaptively combined to produce new views of a scene. Image-based techniques are especially attractive because they provide photometric information which has proven very valuable for recognition tasks.
References-found: 13

