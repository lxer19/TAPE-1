URL: http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume3/broggi95a.ps.Z
Refering-URL: http://www.cs.washington.edu/research/jair/abstracts/broggi95a.html
Root-URL: 
Email: broggi@ce.unipr.it  simona@ce.unipr.it  
Title: Vision-Based Road Detection in Automotive Systems: A Real-Time Expectation-Driven Approach  
Author: Alberto Broggi Simona Berte 
Address: I-43100 Parma, Italy  
Affiliation: Dipartimento di Ingegneria dell'Informazione Universita di Parma Viale delle Scienze  
Note: Journal of Artificial Intelligence Research 3 (1995) 325-348 Submitted 5/95; published 12/95  
Abstract: The main aim of this work is the development of a vision-based road detection system fast enough to cope with the difficult real-time constraints imposed by moving vehicle applications. The hardware platform, a special-purpose massively parallel system, has been chosen to minimize system production and operational costs. This paper presents a novel approach to expectation-driven low-level image segmentation, which can be mapped naturally onto mesh-connected massively parallel Simd architectures capable of handling hierarchical data structures. The input image is assumed to contain a distorted version of a given template; a multiresolution stretching process is used to reshape the original template in accordance with the acquired image content, minimizing a potential function. The distorted template is the process output.
Abstract-found: 1
Intro-found: 1
Reference: <author> Adorni, G., Broggi, A., Conte, G., & D'Andrea, V. </author> <year> (1993). </year> <title> A self-tuning system for real-time Optical Flow detection. </title> <booktitle> In Proceedings IEEE System, Man, and Cybernetics Conf, </booktitle> <volume> Vol. 3, </volume> <pages> pp. 7-12. </pages>
Reference: <author> Adorni, G., Broggi, A., Conte, G., & D'Andrea, V. </author> <year> (1995). </year> <title> Real-Time Image Processing for Automotive Applications. </title> <editor> In Laplante, P. A., & Stoyenko, A. D. (Eds.), </editor> <booktitle> Real-Time Image Processing: Theory, Techniques and Applications. </booktitle> <publisher> IEEE and SPIE Press. In press. </publisher>
Reference: <author> Annaratone, M., Arnould, E., T.Gross, H.Kung, </author> & <month> J.Webb </month> <year> (1987). </year> <title> The Warp Computer: Architecture, Implementation and Performance. </title> <journal> IEEE Trans on Computers, </journal> <volume> C-36 (12), </volume> <pages> 1523-1538. </pages>
Reference: <author> Ballard, D. H., & Brown, C. M. </author> <year> (1982). </year> <title> Computer Vision. </title> <publisher> Prentice Hall. </publisher>
Reference: <author> Blake, A., & Yuille, A. </author> <year> (1993). </year> <title> Active Vision. </title> <publisher> MIT Press. </publisher>
Reference: <author> Borgefors, G. </author> <year> (1986). </year> <title> Distance Transformations in Digital Images. </title> <booktitle> In Computer Vision, Graphics and Image Processing, </booktitle> <volume> Vol. 34, </volume> <pages> pp. 344-371. </pages>
Reference-contexts: This shows that the potential image can be generated by the application of a Distance Transform, DT <ref> (Borgefors, 1986) </ref> to the binary thresholded image. Due to a more efficient implementation-dependent data handling, the final version of the potential image DT is obtained by adding a constant to every coefficient, so as to work with only positive values: represents the maximum value allowed for grey-tone images 1 .
Reference: <author> Broggi, A. </author> <year> (1994). </year> <title> Performance Optimization on Low-Cost Cellular Array Processors. </title> <booktitle> In Proceedings IEEE Intl Conf on Massively Parallel Computing Systems, </booktitle> <pages> pp. 334-338. </pages>
Reference-contexts: architectures have been developed recently to support this computational paradigm (Cantoni & Ferretti, 1993; Cantoni, Ferretti, & Savini, 1990; Fountain, 1987; Cantoni & Levialdi, 1986): where the computing architecture contains a number of processing elements which is smaller than the number of image pixels and an external processor virtualization mechanism <ref> (Broggi, 1994) </ref> is used. A useful side effect due to resolution reduction is a decrease in the number of computations to be performed.
Reference: <author> Broggi, A. </author> <year> (1995a). </year> <title> A Massively Parallel Approach to Real-Time Vision-Based Road Markings Detection. </title> <editor> In Masaky, I. (Ed.), </editor> <booktitle> Proceedings IEEE Intelligent Vehicles'95, </booktitle> <pages> pp. 84-89. </pages>
Reference-contexts: In this case both the thresholded gradient (b) and the perspective-based filtered (c) images can be used as input to the DT. a b c d e (b) and the perspective-based filtered (c) images can be used as input to the DT. In a recent work <ref> (Broggi, 1995a) </ref> an approach based on the removal of the perspective effect is presented and its performances discussed. <p> Due to their constant width within the overall image, the road markings can now be easily enhanced and extracted by extremely simple morphological filters <ref> (Broggi, 1995a) </ref> (Figures 10.c). Finally the perspective effect is reintroduced (Figures 10.d). a b c d e caused by shadows. <p> The extended version of the Dbs filter is shown in Figure 15. Since the removal (and reintroduction) of the perspective effect can be reduced to a mere image resampling and the filter is based on simple morphological operators <ref> (Broggi, 1995a) </ref>, the implementation on the Paprica system is straightforward. The preliminary results obtained by the current test version of the system are encouraging both for the output quality (the problems caused by shadows are now resolved) and for computation 3. <p> The improvement of the Dbs process by means of the perspective-based filter, in addition to allowing correct road (or lane) detection in presence of shadows, can be implemented extremely efficiently on the Paprica system, taking advantage of a specific hardware extension designed explicitly for this purpose (non uniform-resampling) <ref> (Broggi, 1995a) </ref>. Figures 11, 12, 13, and 14 show the results of the processing in different conditions: straight and curved road, with shadows and other vehicles in the path, respectively 4 . <p> The presence of an obstacle in the vehicle path is still an open problem, which is currently being approached using stereo vision <ref> (Broggi, 1995a) </ref>. The algorithm has been implemented on the Paprica system, a massively parallel low-cost Simd architecture; because of its specific hardware features, Paprica is capable of processing about 10 frames per second. Appendix A.
Reference: <author> Broggi, A. </author> <year> (1995b). </year> <title> A Novel Approach to Lossy Real-Time Image Compression: Hierarchical Data Reorganization on a Low-Cost Massively Parallel System. </title> <journal> Real-Time Imaging Journal, </journal> <volume> 1 (2). </volume>
Reference: <author> Broggi, A. </author> <year> (1995c). </year> <title> Parallel and Local Feature Extraction: a Real-Time Approach to Road Boundary Detection. </title> <journal> IEEE Trans on Image Processing, </journal> <volume> 4 (2), </volume> <pages> 217-223. </pages>
Reference-contexts: All rights reserved. Alberto Broggi, Simona Bert e the processing results (b) current Led-based output Starting from the experience gained in the development of a different approach <ref> (Broggi, 1995c) </ref> based on the parallel detection of image edges pointing to the Focus of Expansion, this work presents a model-driven low-level processing technique aimed at road detection and enhancement of the road (or lane) image acquired from a moving vehicle.
Reference: <author> Broggi, A., Conte, G., Gregoretti, F., Sansoe, C., & Reyneri, L. M. </author> <year> (1995). </year> <title> The Evolution of the PAPRICA System. </title> <journal> Integrated Computer-Aided Engineering Journal Special Issue on Massively Parallel Computing. </journal> <note> In press. 345 Alberto Broggi, </note> <author> Simona Bert e Broggi, A., Conte, G., Gregoretti, F., Sansoe, C., & Reyneri, L. M. </author> <year> (1994). </year> <title> The PAPRICA Massively Parallel Processor. </title> <booktitle> In Proceedings IEEE Intl Conf on Massively Parallel Computing Systems, </booktitle> <pages> pp. 16-30. </pages>
Reference-contexts: It is for this reason that the execution of low-level computations (efficiently performed by massively parallel systems) has usually been implemented on general purpose processors, as in the case of VaMoRs. The design and implementation of special-purpose application-oriented architectures <ref> (like Paprica, Broggi, Conte, Gregoretti, Sansoe, & Reyneri, 1995, 1994) </ref>, on the other hand, keep the production costs down, while delivering very high performance levels.
Reference: <author> Cantoni, V., & Ferretti, M. </author> <year> (1993). </year> <title> Pyramidal Architectures for Computer Vision. </title> <publisher> Plenum Press, London. </publisher>
Reference: <author> Cantoni, V., Ferretti, M., & Savini, M. </author> <year> (1990). </year> <title> Compact Pyramidal Architectures. </title> <editor> In Tou, J., & Balchen, J. (Eds.), </editor> <title> Highly Redundant Sensing in Robotic Systems, </title> <journal> Vol. </journal> <volume> 58, </volume> <pages> pp. 157-174. </pages> <publisher> NATO ASI Series F. </publisher>
Reference: <author> Cantoni, V., & Levialdi, S. </author> <year> (1986). </year> <title> Pyramidal Systems for Computer Vision. </title> <publisher> Springer Verlag, </publisher> <address> Berlin. </address>
Reference: <author> Chandrakasan, A., Sheng, S., & Brodersen, R. </author> <year> (1992). </year> <title> Low-Power CMOS Digital Design. </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> 27 (4), </volume> <pages> 473-484. </pages>
Reference: <author> Cohen, L. D. </author> <year> (1991). </year> <title> Note on Active Contour Models and Balloons. </title> <booktitle> CGVIP: Image Understanding, </booktitle> <volume> 53 (2), </volume> <pages> 211-218. </pages>
Reference: <author> Cohen, L. D., & Cohen, I. </author> <year> (1993). </year> <title> Finite-Element Methods for Active Contour Models and Balloons for 2-D and 3-D Images. </title> <journal> IEEE Trans on PAMI, </journal> <volume> 15 (11), </volume> <pages> 1131-1147. </pages>
Reference: <author> Courtois, B. </author> <year> (1993). </year> <title> CAD and Testing of ICs and systems: Where are we going?. </title> <type> Tech. rep., </type> <institution> TIMA & CMP. </institution>
Reference: <author> Crisman, J., & Thorpe, C. </author> <year> (1990). </year> <title> Color Vision for Road Following. </title> <editor> In Thorpe, C. E. (Ed.), </editor> <booktitle> Vision and Navigation. The Carnegie Mellon Navlab, </booktitle> <pages> pp. 9-24. </pages> <publisher> Kluwer Academic Publishers. </publisher>
Reference: <author> Crisman, J., & Thorpe, C. </author> <year> (1991). </year> <title> UNSCARF, A Color Vision System for the Detection of Unstructured Roads. </title> <booktitle> In Proceedings IEEE Intl Conf on Robotics and Automation, </booktitle> <pages> pp. 2496-2501. </pages>
Reference: <author> Crisman, J., & Thorpe, C. </author> <year> (1993). </year> <title> SCARF: A Color Vision System that Tracks Roads and Intersections. </title> <journal> IEEE Trans on Robotics and Automation, </journal> <volume> 9 (1), </volume> <pages> 49-58. </pages>
Reference: <author> Crisman, J. D., & Webb, J. A. </author> <year> (1991). </year> <title> The Warp Machine on Navlab. </title> <journal> IEEE Trans on PAMI, </journal> <volume> 13 (5), </volume> <pages> 451-465. </pages>
Reference: <author> Dickmans, E. D., & Mysliwetz, B. D. </author> <year> (1992). </year> <title> Recursive 3-D Road and Relative Ego-State Recognition. </title> <journal> IEEE Trans on PAMI, </journal> <volume> 14, </volume> <pages> 199-213. </pages>
Reference-contexts: The windowing techniques are supported by strong road and vehicles models to predict features in incoming images <ref> (Dickmans & Mysliwetz, 1992) </ref>. In this case, the vehicle was driven at high speeds (up to 100 kph) on German autobahns, which have constant lane width, and where the road has specific shapes: straight, constant curvature, or clothoidal.
Reference: <author> Folli, A. </author> <year> (1994). </year> <title> Elaborazione parallela di immagini per applicazioni in tempo reale su autoveicolo. </title> <type> Master's thesis, </type> <institution> Universita degli Studi di Parma, Facolta di Ingegneria. </institution>
Reference-contexts: Then, as shown in Figure 5, a threshold is applied to the gradient image, in order to keep only the most significant edges. The threshold value is now fixed, but its automatic tuning based on median filtering is currently being tested <ref> (Folli, 1994) </ref>. 331 Alberto Broggi, Simona Bert e More precisely, two different threshold values are computed for the left and right halves of the image, in order to detect both road boundaries even under different illumination conditions.
Reference: <author> Forman, G. H., & Zahorjan, J. </author> <year> (1994). </year> <title> The Challenge of Mobile Computing. </title> <journal> Computer, </journal> <volume> 27 (4), </volume> <pages> 38-47. </pages>
Reference-contexts: The power consumption of dynamic systems can be considered proportional to Cf V 2 , where C represents the capacitance of the circuit, f is the clock frequency, and V is the voltage swing. Power can be saved in three different ways <ref> (Forman & Zahorjan, 1994) </ref>, by minimizing C, f , and V respectively: * using a greater level of Vlsi integration, thus reducing the capacitance C; * trading computer speed (with a lower clock frequency f ) for lower power consumption (already implemented on many portable PCs); * reducing the supply voltage
Reference: <author> Fountain, T. </author> <year> (1987). </year> <title> Processor Arrays: Architectures and applications. </title> <address> Academic-Press, London. </address>
Reference: <author> Graefe, V., & Kuhnert, K.-D. </author> <year> (1991). </year> <title> Vision-based Autonomous Road Vehicles. </title> <editor> In Masaki, I. (Ed.), </editor> <booktitle> Vision-based Vehicle Guidance, </booktitle> <pages> pp. 1-29. </pages> <publisher> Springer Verlag. </publisher>
Reference-contexts: al., 1988) to process only the regions of interest, thus implementing a Focus of Attention mechanism (Wolfe & Cave, 1990; Neumann & Stiehl, 1990). * As an example, in VaMoRs (developed at Universitat der Bundeswehr, Munchen) monochromatic images are processed by custom hardware, focusing only on the regions of interest <ref> (Graefe & Kuhnert, 1991) </ref>. The windowing techniques are supported by strong road and vehicles models to predict features in incoming images (Dickmans & Mysliwetz, 1992).
Reference: <author> Gregoretti, F., Reyneri, L. M., Sansoe, C., Broggi, A., & Conte, G. </author> <year> (1993). </year> <title> The PAPRICA SIMD array: critical reviews and perspectives. </title> <editor> In Dadda, L., & Wah, B. (Eds.), </editor> <booktitle> Proceedings ASAP'93 IEEE Intl Conf on Application Specific Array Processors, </booktitle> <pages> pp. </pages> <address> 309-320 Venezia, Italy. </address> <note> 346 Vision-Based Road Detection Hamey, </note> <author> L. G. C., Web, J. A., & Wu, I. </author> <year> (1988). </year> <title> Low-level vision on Warp and the Apply Programming Model. </title> <editor> In Kowalik, J. S. (Ed.), </editor> <booktitle> Parallel Computations and Computers for Artificial Intelligence, </booktitle> <pages> pp. 185-200. </pages> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: board (a single 6U Vme board integrating the Processor Array, the Image and Program Memories, and a frame grabber device for the direct acquisition of images for the Paprica Image Memory) is the result of the full reengineering of the first Paprica prototype which has been extensively analyzed and tested <ref> (Gregoretti, Reyneri, Sansoe, Broggi, & Conte, 1993) </ref> for several years.
Reference: <author> Haralick, R. M., Sternberg, S. R., & Zhuang, X. </author> <year> (1987). </year> <title> Image Analysis Using Mathematical Morphology. </title> <journal> IEEE Trans on PAMI, </journal> <volume> 9 (4), </volume> <pages> 532-550. </pages>
Reference-contexts: Detection where S (n) e represents the binary image at step n, the subscript e indicates that the rule for the external edge is being considered, and finally L = fl 2 E 3 j l = (u; ); 8 u 2 E 2 g : (11) As shown in <ref> (Haralick et al., 1987) </ref>, in order to compute the minimum value of a grey-tone image K (n) e in a 4-connected neighborhood, the following grey-scale morphological erosion should be used: M (n) e Q ; (12) where Q = f (1; 0; 0); (1; 0; 0); (0; 1; 0); (0; 1; <p> x) &lt; V (B; x)g ; (15) where V : E 3 fi E 2 ! E is defined as V (A; x) = a if 9 a 2 E j (x; a) 2 T (A) 1 otherwise : (16) In equation (16), T (A) represents the top of A <ref> (Haralick et al., 1987) </ref>, here defined as T (A) = ft 2 A; t = (u; v) j 6 9 t 0 = (x; v 0 ) 2 A for which v 0 &gt; vg : (17) The set of elements which will be included in set S (n+1) e is
Reference: <author> Hillis, W. D. </author> <year> (1985). </year> <title> The Connection Machine. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Ma. </address>
Reference-contexts: The complete processing, first tested on a Connection Machine CM-2 <ref> (Hillis, 1985) </ref>, is now implemented on the special-purpose massively parallel Simd architecture Paprica. 336 Vision-Based Road Detection The Paprica system (PArallel PRocessor for Image Checking and Analysis), based on a hierarchical morphology computational model, has been designed as a specialized coprocessor to be attached to a general purpose host workstation: the <p> Images acquired in many different conditions and environments have been used for extensive experimentation, which was performed first off-line on a functional simulator implemented on an 8k processor Connection Machine CM-2 <ref> (Hillis, 1985) </ref> and then in real-time on the Paprica hardware itself on Mob-Lab.
Reference: <author> Jochem, T. M., & Baluja, S. </author> <year> (1993). </year> <title> A Massively Parallel Road Follower. </title> <editor> In Bayoumi, M. A., Davis, L. S., & Valavanis, K. P. (Eds.), </editor> <booktitle> Proceedings Computer Architectures for Machine Perception '93, </booktitle> <pages> pp. 2-12. </pages>
Reference-contexts: The high performance offered by such a powerful hardware platform is limited by its low I/O bandwidth; therefore a simpler reduced version (processing 128 fi 128 images) has been implemented, working at a rate of 2.5 Hz <ref> (Jochem & Baluja, 1993) </ref>. Due to the high amount of data (2 color images) and to the complex operations involved (segmentation, clustering, Hough transform, etc.) the system discussed, even if implemented on extremely powerful hardware machines, achieve a low processing rate.
Reference: <author> Jochem, T. M., Pomerleau, D. A., & Thorpe, C. E. </author> <year> (1993). </year> <title> MANIAC: A Next Generation Neurally Based Autonomous Road Follower. </title> <booktitle> In Proceedings of the Intl Conf on Intelligent Autonomous Systems: </booktitle> <address> IAS -3 Pittsburgh, Pennsylvania, USA. </address>
Reference-contexts: The high performance offered by such a powerful hardware platform is limited by its low I/O bandwidth; therefore a simpler reduced version (processing 128 fi 128 images) has been implemented, working at a rate of 2.5 Hz <ref> (Jochem & Baluja, 1993) </ref>. Due to the high amount of data (2 color images) and to the complex operations involved (segmentation, clustering, Hough transform, etc.) the system discussed, even if implemented on extremely powerful hardware machines, achieve a low processing rate.
Reference: <author> Kass, M., Witkin, A., & Terzopolous, D. </author> <year> (1987). </year> <title> Snakes: Active Contour Models. </title> <journal> Intl Journal of Computer Vision, </journal> <volume> 1, </volume> <pages> 321-331. </pages>
Reference: <author> Kenue, S. K. </author> <year> (1990). </year> <title> LANELOK: detection of lane boundaries and vehicle tracking using image-processing techniques. </title> <booktitle> In Proceedings of SPIE Mobile Robots IV, </booktitle> <volume> Vol. 1195, </volume> <pages> pp. 221-233. </pages>
Reference: <author> Kenue, S. K. </author> <year> (1991). </year> <title> LANELOK: An Algorithm for Extending the Lane Sensing Operating Range to 100 Feet. </title> <booktitle> In Proceedings of SPIE Mobile Robots V, </booktitle> <volume> Vol. 1388, </volume> <pages> pp. 222-233. </pages>
Reference: <author> Kenue, S. K. </author> <year> (1994). </year> <title> Correction of Shadow Artifacts for Vision-based Vehicle Guidance. </title> <booktitle> In Proceedings of SPIE Mobile Robots VIII, </booktitle> <volume> Vol. </volume> <year> 2058, </year> <pages> pp. 12-26. </pages>
Reference-contexts: In addition to being disturbed by the presence of vehicles close to the road markings, lane detection generally fails in shadow conditions. An extension for the correct interpretation of shadows has therefore been introduced <ref> (Kenue, 1994) </ref>; unfortunately this technique relies on fixed brightness thresholds which is far from being a robust and general approach. 328 Vision-Based Road Detection The main aim of the approach discussed in this paper, on the other hand, is to build a low-cost system capable of achieving real-time performance in the
Reference: <author> Kenue, S. K., & Bajpayee, S. </author> <year> (1993). </year> <title> LANELOK: Robust Line and Curvature Fitting of Lane Boundaries. </title> <booktitle> In Proceedings of SPIE Mobile Robots VII, </booktitle> <volume> Vol. 1831, </volume> <pages> pp. 491-503. </pages>
Reference: <author> Kluge, K., & Thorpe, C. E. </author> <year> (1990). </year> <title> Explicit Models for Robot Road Following. </title> <editor> In Thorpe, C. E. (Ed.), </editor> <booktitle> Vision and Navigation. The Carnegie Mellon Navlab, </booktitle> <pages> pp. 25-38. </pages> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: In addition to its heavy computational load, the main problems with this approach are found in the implicit models assumed: if the road curves sharply or if it changes width, the assumed shape model becomes invalid and detection fails <ref> (Kluge & Thorpe, 1990) </ref>. * The Vits system (tested on the Alv vehicle and developed at Martin Marietta) also relies on two color cameras. It uses a combination of the red and blue color bands to segment the image, in an effort to reduce the artifacts caused by shadows. <p> This approach is disturbed in shadow conditions, when the overall illumination changes, or when road imperfections are found <ref> (Kluge & Thorpe, 1990) </ref>. * The Lanelok system (developed at General Motors) also relies on strong road models: it estimates the location of lane boundaries with a curve fitting method (Kenue & Bajpayee, 1993; Kenue, 1991, 1990), using a quadratic equation model.
Reference: <author> Kluge, K. </author> <year> (1994). </year> <title> Extracting Road Curvature and Orientation from Image Edge Points without Perceptual Grouping into Features. </title> <booktitle> In Proceedings IEEE Intelligent Vehicles'94. </booktitle> <institution> MasPar Computer Corporation, Sunnyvale, California (1990). MP-1 Family Data-Parallel Computers. </institution>
Reference: <author> Neumann, H., & Stiehl, H. </author> <year> (1990). </year> <title> Toward a computational architecture for monocular preattentive segmentation. </title> <editor> In G.Hartmann, R., & G.Hauske (Eds.), </editor> <booktitle> Parallel Processing in Neural Systems and Computers. </booktitle> <publisher> Elsevier (North Holland). </publisher>
Reference: <author> Newman, W. M., & Sproull, R. F. </author> <year> (1981). </year> <title> Principles of Interactive Computer Graphics. </title> <publisher> McGraw-Hill, </publisher> <address> Tokyo. </address>
Reference: <author> Pomerleau, D. A. </author> <year> (1990). </year> <title> Neural Network Based Autonomous Navigation. </title> <editor> In Thorpe, C. E. (Ed.), </editor> <booktitle> Vision and Navigation. The Carnegie Mellon Navlab, </booktitle> <pages> pp. 83-93. </pages> <publisher> Kluwer Academic Publishers. </publisher>
Reference: <author> Pomerleau, D. A. </author> <year> (1993). </year> <title> Neural Network Perception for Mobile Robot Guidance. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston. </address>
Reference: <author> Pratt, W. K. </author> <year> (1978). </year> <title> Digital Image Processing. </title> <publisher> John Wiley & Sons. 347 Alberto Broggi, </publisher> <editor> Simona Bert e Rosenfeld, A. </editor> <year> (1984). </year> <title> Multiresolution Image Processing and Analysis. </title> <publisher> Springer Verlag, </publisher> <address> Berlin. </address>
Reference-contexts: Algorithm Structure As shown in Figure 4, before each subsampling the natural image is filtered. In this way it is possible to decrease both the influence of noise and redundant details, and the distortion due to aliasing <ref> (Pratt, 1978) </ref> introduced by the subsampling process. The image is partitioned into non-overlapping square subsets of 2fi2 pixels each; the filter comprises a simple average of the pixels values for a given subset, which reduces the signal bandwidth. The set of resulting values forms the subsampled image.
Reference: <author> Serra, J. </author> <year> (1982). </year> <title> Image Analysis and Mathematical Morphology. </title> <publisher> Academic Press, London. </publisher>
Reference: <author> Shoji, M. </author> <year> (1988). </year> <title> CMOS Digital Circuit Technology. </title> <publisher> Prentice Hall. </publisher>
Reference-contexts: Recently, new technological solutions have been exploited to reduce the IC supply voltage from 5 V to 3.3 V. Unfortunately, there is a speed penalty to pay for this reduction: for a Cmos gate <ref> (Shoji, 1988) </ref>, the device delay T d (following a first order approximation) is proportional to V DD (V DD V T ) 2 , which shows that the reduction of V DD determines a quasi linear increment (until the device threshold value V T ) of the circuit delay T d
Reference: <author> Tanimoto, S. L., & Kilger, K. </author> <year> (1980). </year> <title> Structured Computer Vision: Machine Perception trough Hierarchical Compuation Structures. </title> <publisher> Academic Press, </publisher> <address> NY. </address>
Reference: <author> Thorpe, C. </author> <year> (1989). </year> <title> Outdoor Visual Navigation for Autonomous Robots. </title> <editor> In Kanada, T., Groen, F. C. A., & Hertzberger, L. O. (Eds.), </editor> <booktitle> Intelligent Autonomous Systems, </booktitle> <volume> Vol. 2, </volume> <pages> pp. 530-544. </pages>
Reference: <author> Tsai, R. </author> <year> (1986). </year> <title> An Efficient and Accurate Camera Calibration Technique for 3D Machine Vision. </title> <booktitle> In Proceedings IEEE Intl Conf on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 364-374. </pages>
Reference: <author> Turk, M. A., Morgenthaler, D. G., Gremban, K. D., & Marra, M. </author> <year> (1988). </year> <title> VITS A Vision System for Autonomous Land Vehicle Navigation. </title> <journal> IEEE Trans on PAMI, </journal> <volume> 10 (3). </volume>
Reference-contexts: Information on vehicle motion is also used to aid the segmentation process. Tested successfully 327 Alberto Broggi, Simona Bert e on straight, single lane roads, it runs faster than Scarf, sacrificing general capability for speed <ref> (Turk, Morgenthaler, Gremban, & Marra, 1988) </ref>. * Alvinn (tested on Navlab, Cmu) is a neural network based 30 fi 32 video retina designed, like Scarf, to detect unstructured roads, but it does not have any road model: it learns associations between visual patterns and steering wheel angles, without considering the road <p> Many different methods have been considered to speed-up the processing, including the processing of monochromatic images and the use of windowing techniques <ref> (Turk et al., 1988) </ref> to process only the regions of interest, thus implementing a Focus of Attention mechanism (Wolfe & Cave, 1990; Neumann & Stiehl, 1990). * As an example, in VaMoRs (developed at Universitat der Bundeswehr, Munchen) monochromatic images are processed by custom hardware, focusing only on the regions of
Reference: <author> Wolfe, J. M., & Cave, K. R. </author> <year> (1990). </year> <title> Deploying visual attention: the guided model. </title> <booktitle> In AI and the eye, </booktitle> <pages> pp. 79-103. </pages> <note> A.Blake and T.Troscianko. </note>
Reference: <author> Zavidovique, B., & Fiorini, P. </author> <year> (1994). </year> <title> A Control View to Vision Architectures. </title> <editor> In Cantoni, V. (Ed.), </editor> <booktitle> Human and Machine Vision: Analogies and Divergencies, </booktitle> <pages> pp. 13-56. </pages> <publisher> Plenum Press. </publisher> <pages> 348 </pages>
References-found: 52

