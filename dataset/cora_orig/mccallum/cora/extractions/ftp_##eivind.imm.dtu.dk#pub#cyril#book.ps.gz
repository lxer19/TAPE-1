URL: ftp://eivind.imm.dtu.dk/pub/cyril/book.ps.gz
Refering-URL: http://eivind.imm.dtu.dk/staff/goutte/PUBLIS/thesis.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: TH presentee par STATISTICAL LEARNING AND REGULARISATION FOR REGRESSION Application to system identification and time
Author: ESE DE DOCTORAT DE L'UNIVERSIT E PARIS Specialite Cyril Goutte chronologiques soutenue le juillet devant le jury compose de Sylvie THIRIA President Anne GU ERIN-DUGU E Rapporteur Gerard GOVAERT Rapporteur Jan LARSEN Examinateur Patrick GALLINARI Examinateur 
Date: Titre  
Address: PARIS 6.  
Affiliation: Informatique  pour obtenir le grade de DOCTEUR DE l'UNIVERSIT E  
Abstract-found: 0
Intro-found: 1
Reference: <author> Svarer, C., Hansen, L., and Larsen, J. </author> <year> (1993). </year> <title> On design and evaluation of tapped-delay neural network architectures. </title> <editor> In et al., H. B., editor, </editor> <booktitle> IEEE International Conference on Neural Networks, ICNN, </booktitle> <pages> pages 46-51, </pages> <address> Piscataway, NJ. </address> <publisher> IEEE. </publisher>
Reference: <author> Thodberg, H. H. </author> <year> (1993). </year> <title> Ace of Bayes: application of neural network with pruning. </title> <type> Technical Report 1132-E, </type> <institution> Danish meat research institute, Roskilde, Danmark. </institution>
Reference: <author> Thodberg, H. H. </author> <year> (1996). </year> <title> A review of bayesian neural networks with an application to near infrared spectroscopy. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 7(1) </volume> <pages> 56-72. </pages>
Reference: <author> Tibshirani, R. </author> <year> (1996). </year> <title> Bias, variance and prediction error for classification rules. </title> <type> Technical report, </type> <institution> University of Toronto. </institution> <note> http://utstat.toronto.edu/pub/tibs/biasvar.ps. </note>
Reference: <author> Touretzky, D. S., Mozer, M. C., and Hasselmo, M. E., </author> <title> editors (1996). </title> <booktitle> Advances in Neural Information Processing Systems, number 8 in NIPS. </booktitle> <publisher> MIT Press. </publisher>
Reference: <author> Tsypkin, Y. Z. and Nikolic, Z. J. </author> <year> (1971). </year> <title> Adaptation and learning in automatic systems, </title> <booktitle> volume 73 of Mathematics in science and engineering. </booktitle> <publisher> Academic Press, </publisher> <address> New York and London. </address>
Reference: <author> Usui, S., Tohkura, Y., Katagiri, S., and Wilson, E., </author> <title> editors (1996). </title> <booktitle> Neural Networks for Signal Processing VI Proceedings of the 1996 IEEE Workshop, number VI in NNSP, </booktitle> <address> Piscataway, New Jersey. </address> <publisher> IEEE. </publisher>
Reference: <author> Vapnik, V. N. </author> <year> (1995). </year> <title> The Nature of Statistical Learning Theory. </title> <publisher> Springer. </publisher>
Reference: <author> Wahba, G. </author> <year> (1990). </year> <title> Spline Models for Observational Data. </title> <booktitle> Number 59 in CBMS-NSF Regional Conference Series in Applied Mathematics. </booktitle> <publisher> SIAM. </publisher>
Reference: <author> Wand, M. and Jones, M. </author> <year> (1995). </year> <title> Kernel Smoothing. Number 60 in Monographs on Statistics and Applied Probability. </title> <publisher> Chapman & Hall, London. </publisher>

Reference: <author> Rasmussen, C. E. </author> <year> (1993). </year> <title> Generalization in neural networks. </title> <type> Master's thesis, </type> <institution> Electronics institute, Technical University of Denmark. </institution>
Reference: <author> Ripley, B. D. </author> <year> (1996). </year> <title> Pattern Recognition and Neural Networks. </title> <publisher> Cam-bridge University Press. </publisher>
Reference: <author> Robbins, H. and Munro, S. </author> <year> (1951). </year> <title> A stochastic approximation method. </title> <journal> Annals of Math. Stat., </journal> <volume> 22 </volume> <pages> 400-407. </pages>
Reference: <author> Robert, C. </author> <year> (1992). </year> <note> L'analyse statistique Bayesienne. Economica, Paris. </note>
Reference: <author> Rumelhart, D., Hinton, G., and Williams, R. </author> <year> (1986). </year> <title> Learning internal representation by error propagation. </title> <editor> In Rumelhart, D. and McClellan, J., editors, </editor> <booktitle> Parallel Distributed Processing : exploring the microstructure of cognition, </booktitle> <volume> volume 1, </volume> <pages> pages 318-362. </pages> <publisher> MIT Press. </publisher>
Reference: <author> Savit, R. and Green, M. </author> <year> (1991). </year> <title> Time series and dependent variables. </title> <journal> Physica D, </journal> <volume> 50(1) </volume> <pages> 95-116. </pages>
Reference: <author> Scales, J. A. and Smith, M. L. </author> <year> (1994). </year> <title> Introductory Geophysical Inverse Theory. </title> <note> Samizdat Press, available via FTP from hilbert.mines.colorado.edu. </note>
Reference: <author> Schwartz, G. </author> <year> (1978). </year> <title> Estimating the dimension of a model. </title> <journal> The Annals of Statistics, </journal> <volume> 6(2) </volume> <pages> 461-464. </pages>
Reference: <author> Sjoberg, J. and Ljung, L. </author> <year> (1995). </year> <title> Overtraining, regularization and searching for minimum with application to neural nets. </title> <journal> International Journal of Control. </journal>
Reference: <author> Strensen, P. H., Ntrg-ard, M., Hansen, L. K., and Larsen, J. </author> <year> (1996). </year> <title> Cross-validation with LULOO. </title> <booktitle> In Proceedings of 1996 International Conference on Neural Information Processing, </booktitle> <address> ICONIP'96. </address>
Reference: <author> Specht, D. F. </author> <year> (1991). </year> <title> A general regression neural network. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 2(6) </volume> <pages> 568-576. </pages>
Reference: <author> Stone, M. </author> <year> (1974). </year> <title> Cross-validatory choice and assessment of statistical predictions. </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> 36 </volume> <pages> 111-147. </pages> <note> with discussion. 178 Bibliography Mtller, </note> <author> M. </author> <year> (1993a). </year> <title> Efficient Training of Feed-Forward Neural Networks. </title> <type> PhD thesis, </type> <institution> Computer Science department, Aarhus University. </institution>
Reference: <author> Mtller, M. </author> <year> (1993b). </year> <title> A scaled conjugate gradient algorithm for fast supervised learning. </title> <booktitle> Neural Networks, </booktitle> <volume> 6(4) </volume> <pages> 525-533. </pages>
Reference: <author> Mtller, M. </author> <year> (1993c). </year> <title> Supervised learning on large redundant training sets. </title> <journal> International Journal of Neural Systems, </journal> <volume> 4(1) </volume> <pages> 15-25. </pages>
Reference: <author> Moody, J. </author> <year> (1991). </year> <title> Note on generalization, regularization and architecture selection in nonlinear learning systems. </title> <editor> In Juang, B. H., Kung, S. Y., and Kamm, C. A., editors, </editor> <booktitle> Proceedings of the first IEEE Workshop on Neural Networks for Signal Processing, number I in NNSP, </booktitle> <pages> pages 1-10, </pages> <address> Piscataway, New Jersey. </address> <publisher> IEEE. </publisher>
Reference: <author> Murata, N., Yoshizawa, S., and Amari, S. </author> <year> (1994). </year> <title> Network Information Criterion|determining the number of hidden units for an artificial neural network model. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 5(6) </volume> <pages> 865-872. </pages>
Reference: <author> Neal, R. M. </author> <year> (1992). </year> <title> Bayesian training of backpropagation network by the hybrid monte carlo method. </title> <type> Technical Report CRG-TR-92-1, </type> <institution> Connectionist Research Group, Department of Computer Science, University of Toronto. </institution>
Reference: <author> Ntrgaard, P. M. </author> <year> (1996). </year> <title> System identification and control with neural networks. </title> <type> PhD thesis, </type> <institution> Department of Automation, Technical University of Denmark. </institution>
Reference: <author> Parzen, E. </author> <year> (1962). </year> <title> On estimation of a probability density and mode. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 33 </volume> <pages> 1065-76. </pages>
Reference: <author> Pedersen, M. W., Hansen, L. K., and Larsen, J. </author> <year> (1996). </year> <title> Pruning with generalization based weight saliencies: </title> <editor> flOBD, flOBS. In Touretzky et al. </editor> <year> (1996). </year>
Reference: <author> Pi, H. and Peterson, C. </author> <year> (1994). </year> <title> Finding the embedding dimension and variable dependences in time series. </title> <journal> Neural Computation, </journal> <volume> 6(3) </volume> <pages> 509-520. </pages>

Reference: <author> Le Cun, Y., Denker, J. S., and Solla, S. A. </author> <year> (1990). </year> <title> Optimal brain damage. </title> <editor> In Touretzky, D. S., editor, </editor> <booktitle> Advances in Neural Information Processing Systems, number 2 in NIPS, </booktitle> <pages> pages 598-605. </pages> <publisher> Morgan-Kaufmann. </publisher>
Reference: <author> Leray, P. and Gallinari, P. </author> <year> (1997). </year> <title> Report on variable selection. Neu-rosat Project Report ENV4-CT96-0314, D 1-1-1, Environment and Climate DG III, </title> <booktitle> Science, Research and Development. </booktitle>
Reference: <author> Ljung, L., Sjoberg, J., and McKelvey, T. </author> <year> (1992). </year> <title> On the use of regularization in system identification. </title> <type> Technical Report 1379, </type> <institution> Department of Electrical Engineering, Linkoping University, S-581 83 Linkoping, Sweden. </institution>
Reference: <author> Lowe, D. </author> <year> (1995). </year> <title> Similarity metric learning for a variable-kernel classifier. </title> <journal> Neural Computation, </journal> <volume> 7(1) </volume> <pages> 72-85. </pages>
Reference: <author> Mack, Y. P. </author> <year> (1981). </year> <title> Local properties of k-nn regression estimates. </title> <journal> SIAM Journal on Algorithm and Discrete Methods, </journal> <volume> 2 </volume> <pages> 311-323. </pages>
Reference: <author> MacKay, D. </author> <year> (1992a). </year> <title> Bayesian interpolation. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 415-447. </pages>
Reference: <author> MacKay, D. </author> <year> (1992b). </year> <title> A practical bayesian framework for backprop networks. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 448-472. </pages>
Reference: <author> MacKay, D. </author> <year> (1993). </year> <title> Hyperparameters: Optimize or integrate out? In Heidbreder, </title> <editor> G., editor, </editor> <title> Maximum entropy and Bayesian Methods. </title> <publisher> Kluwer, Dordrecht. </publisher>
Reference: <author> Mallows, C. </author> <year> (1973). </year> <title> Some comments on C p . Technometrics, </title> <booktitle> 15 </booktitle> <pages> 661-675. </pages>
Reference: <author> McLeod, A. I. </author> <year> (1994). </year> <title> Diagnostic checking of periodic autoregres-sion models with application. </title> <journal> Journal of Time Series Analysis, </journal> <volume> 15(2) </volume> <pages> 221-233. </pages>
Reference: <author> Molina, C., Sampson, N., Fitzgerald, W. J., and Niranjan, M. </author> <year> (1996). </year> <title> Geometrical techniques for finding the embedding dimension of time series. </title> <editor> In Usui et al. </editor> <year> (1996), </year> <pages> pages 161-169. </pages> <note> 176 Bibliography Hocking, </note> <author> R. R. </author> <year> (1976). </year> <title> The analysis and selection of variables in linear regression. </title> <journal> Biometrics, </journal> <volume> 32 </volume> <pages> 1-49. </pages>
Reference: <author> Hornik, K., Stinchcombe, M., and White, H. </author> <year> (1989). </year> <title> Multilayer feed-forward networks are universal approximators. </title> <booktitle> Neural Networks, </booktitle> <volume> 2 </volume> <pages> 359-368. </pages>
Reference: <author> Jaynes, E. T. </author> <year> (1985). </year> <title> Bayesian methods: general background. </title> <editor> In Justice, J., editor, </editor> <booktitle> Maximum Entropy and Bayesian Methods in Applied Statistics, </booktitle> <pages> pages 1-25. </pages> <publisher> Cambridge University Press. </publisher>
Reference: <author> Kearns, M. </author> <year> (1996). </year> <title> A bound on the error of cross validation using the approximation and estimation rates, with consequences for the training-test split. </title> <editor> In Touretzky et al. </editor> <year> (1996). </year>
Reference: <author> Kouam, A. </author> <year> (1993). </year> <institution> Approches connexionnistes pour la prevision des series temporelles. </institution> <type> PhD thesis, </type> <institution> Universite de Paris Sud. </institution>
Reference: <author> Krogh, A. and Hertz, J. A. </author> <year> (1992). </year> <title> A simple weight decay can improve generalization. </title> <editor> In Moody, J. E., Hanson, S. J., and Lippman, R. P., editors, </editor> <booktitle> Advances in Neural Information Processing Systems, volume 4 of NIPS. </booktitle>
Reference: <author> Lai, S. L. </author> <year> (1977). </year> <title> Large sample properties of k-nearest neighbor procedures. </title> <type> PhD thesis, </type> <institution> Department of Mathematics, UCLA, </institution> <address> Los Angeles. </address>
Reference: <author> Larsen, J. </author> <year> (1992). </year> <title> A generalization error estimate for nonlinear systems. </title> <editor> In Kung, S. Y., Fallside, F., and Strensen, J. A., editors, </editor> <booktitle> Neural Networks for Signal Processing Proceedings of the 1992 IEEE Workshop, number II in NNSP, </booktitle> <pages> pages 29-38, </pages> <address> Piscataway, New Jersey. </address> <publisher> IEEE. </publisher>
Reference: <author> Larsen, J. and Hansen, L. K. </author> <year> (1994). </year> <title> Generalized performance of regularized neural networks models. </title> <editor> In Vlontzos, J., Hwang, J. N., and Wilson, E., editors, </editor> <booktitle> Neural Networks for Signal Processing IV Proceedings of the 1994 IEEE Workshop, number IV in NNSP, </booktitle> <pages> pages 42-51, </pages> <address> Piscataway, New Jersey. </address> <publisher> IEEE. </publisher>


Reference: <author> Goutte, C. </author> <year> (1997c). </year> <title> Note on free lunches and cross-validation. </title> <journal> Neural Computation, </journal> <volume> 9(6) </volume> <pages> 1245-9. </pages>
Reference: <author> Goutte, C. and Hansen, L. K. </author> <year> (1997). </year> <title> Regularization with a pruning prior. Neural Networks. </title> <publisher> in press. </publisher>
Reference: <author> Goutte, C. and Ledoux, C. </author> <year> (1995). </year> <title> Synthese des techniques de com-mande connexionniste. </title> <type> Technical Report 95/02, </type> <institution> LAFORIA. </institution>
Reference: <author> Grandvalet, Y. </author> <year> (1995). </year> <title> Injection de bruit dans les perceptrons mul-ticouches. </title> <type> PhD thesis, </type> <institution> Universite Technologique de Compiegne, France. </institution>
Reference: <author> Hadamard, J. </author> <year> (1902). </year> <editor> Sur les problemes aux derivees partielles et leur signification physique. Bul. </editor> <publisher> Univ. Princeton, </publisher> <pages> 13(49). </pages>
Reference: <author> Hansen, L. K. and Larsen, J. </author> <year> (1996). </year> <title> Linear unlearning for cross-validation. </title> <booktitle> Advances in Computational Mathematics, </booktitle> <address> 5(2,3):269-280. </address>
Reference: <author> Hansen, L. K. and Rasmussen, C. E. </author> <year> (1994). </year> <title> Pruning from adaptive regularization. </title> <journal> Neural Computation, </journal> <volume> 6 </volume> <pages> 1223-1232. </pages>
Reference: <author> Hansen, P. C. </author> <year> (1996). </year> <title> Rank-Deficient and Discrete Ill-Posed Problems. </title> <type> Doctoral Dissertation. </type> <institution> Polyteknisk Forlag, Lyngby (Denmark). </institution>
Reference: <author> Hardle, W. </author> <year> (1990). </year> <title> Applied nonparametric regression. Number 19 in Econometric Society Monographs. </title> <publisher> Cambridge University Press. </publisher>
Reference: <author> Hassibi, B. and Stork, D. G. </author> <year> (1993). </year> <title> Second order derivatives for network pruning: Optimal brain surgeon. </title> <editor> In Hanson, S., Cowan, J., and Giles, C., editors, </editor> <booktitle> Advances in Neural Information Processing Systems, volume 5 of NIPS, </booktitle> <pages> pages 164-171. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> He, X. and Asada, H. </author> <year> (1993). </year> <title> A new method for identifying orders of input-output models for nonlinear dynamic systems. </title> <booktitle> In American Conference on Control, </booktitle> <address> San Francisco, California. </address>
Reference: <author> Hertz, J., Krogh, A., and Palmer, R. G. </author> <year> (1991). </year> <title> Introduction to the theory of neural computation. </title> <publisher> Addison-Wesley. 174 Bibliography Bryson, </publisher> <editor> A., Denham, W., and Dreyfuss, S. </editor> <year> (1963). </year> <title> Optimal programming problem with inequality constraints. I: Necessary conditions for extremal solutions. </title> <journal> AIAA journal, </journal> <volume> 1 </volume> <pages> 25-44. </pages>
Reference: <author> Charton, F. </author> <year> (1994). </year> <title> Discussion sur l'"exemple de Denker". </title> <type> Personal communication. </type>
Reference: <author> Cibas, T., Fogelman Soulie, F., Gallinari, P., and Raudys, S. </author> <year> (1994). </year> <title> Variable selection with Optimal Cell Damage. </title> <booktitle> In Proceedings of ICANN'94, </booktitle> <pages> pages 727-730. </pages>
Reference: <author> Denker, J., Schwartz, D., Wittner, B., Solla, S., Howard, R., Jackel, L., and Hopfield, J. </author> <year> (1987). </year> <title> Large automatic learning, rule extraction, and generalization. </title> <journal> Complex Systems, </journal> <volume> 1(5) </volume> <pages> 877-922. </pages>
Reference: <author> Dontchev, A. L. and Zolezzi, T. </author> <year> (1992). </year> <title> Well-posed optimization problems. </title> <booktitle> Number 1543 in Lecture notes in mathematics. </booktitle> <publisher> Springer, </publisher> <address> Berlin. </address>
Reference: <author> Efron, B. </author> <year> (1986). </year> <title> Why isn't everyone a Bayesian? The American Statistician, 40(1) 1-11. with comments. </title>
Reference: <author> Efron, B. E. </author> <year> (1982). </year> <title> The Jacknife, the Bootstrap and Other Resampling plans, </title> <booktitle> volume 38 of CBMS-NSF Regional Conference Series in Applied Mathematics. </booktitle> <publisher> SIAM. </publisher>
Reference: <author> Fletcher, R. </author> <year> (1987). </year> <title> Practical Methods of Optimization. </title> <publisher> Wiley. </publisher>
Reference: <author> Friedman, J. H. </author> <year> (1996). </year> <title> On bias, variance, 0/1 loss, and the curse-of-dimensionality. </title> <type> Technical report, </type> <institution> Department of Statistics, Stanford University. ftp://playfair.stanford.edu/pub/friedman/curse.ps.Z. </institution>
Reference: <author> Geman, S., Bienenstock, E., and Doursat, R. </author> <year> (1992). </year> <title> Neural networks and the bias/variance dilemna. </title> <journal> Neural Computation, </journal> <volume> 4(1) </volume> <pages> 1-58. </pages>
Reference: <author> Goutte, C. </author> <year> (1996). </year> <title> On the use of a pruning prior for neural networks. </title>
Reference: <editor> In Usui et al. </editor> <year> (1996), </year> <pages> pages 52-61. </pages>
Reference: <author> Goutte, C. </author> <year> (1997a). </year> <title> Extracting the relevant delays in time series mod-elling. </title> <booktitle> In Neural Networks for Signal Processing VII Proceedings of the 1997 IEEE Workshop, number VII in NNSP, </booktitle> <address> Piscataway, New Jersey. </address> <publisher> IEEE. </publisher>
References-found: 74

