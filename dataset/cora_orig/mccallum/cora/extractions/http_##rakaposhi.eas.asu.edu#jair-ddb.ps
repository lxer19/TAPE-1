URL: http://rakaposhi.eas.asu.edu/jair-ddb.ps
Refering-URL: http://rakaposhi.eas.asu.edu/yochan.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: rao@asu.edu  
Title: Relations between IB EBL in Planning and CSP On the relations between Intelligent Backtracking and
Author: ASU CSE TR - Subbarao Kambhampati 
Address: Tempe, AZ 85287.  
Affiliation: Department of Computer Science and Engineering Arizona State University,  
Abstract: The ideas of intelligent backtracking (IB) and explanation based learning (EBL) have developed independently in constraint satisfaction, planning, machine learning and problem solving communities. The variety of approaches developed for IB and EBL in the various communities have hither-to been incomparable. In this paper, I formalize and unify these ideas under the task-independent framework of refinement search, which can model the search strategies used in both planning and constraint satisfaction (CSP). I show that both IB and EBL depend upon the common theory of explanation analysis- which involves explaining search failures, and regressing them to higher levels of the search tree. My comprehensive analysis shows that most of the differences between the CSP and planning approaches to EBL and DDB revolve around different solutions to: (a) How the failure explanations are computed (b) How they are contextualized (Contextualization involves deciding whether or not to keep the flaw description and the description of the violated problem constraints) and (c) How the storage of explanations is managed. The differences themselves can be understood in terms of the differences between planning and CSP problems as instantiations of refinement search. This unified understanding is expected to support a greater cross-fertilization of ideas among CSP, Planning and EBL communities.
Abstract-found: 1
Intro-found: 1
Reference: <author> Baker, A. </author> <year> (1995). </year> <title> Intelligent backtracking on constraint satisfaction problems: Experimental and Theoretical results. </title> <type> Ph.D. thesis, </type> <institution> University of Oregon. </institution>
Reference: <author> Bayardo, R., & Miranker, D. </author> <year> (1996). </year> <title> A complexity analysis of space-bounded learning algorithms for the constraint satisfaction problem. </title> <booktitle> In Proc. AAAI-96. </booktitle>
Reference-contexts: Although the emphasis shifted to non-systematic search strategies such as GSAT (Selman, Levesque, & Mitchel, 1992) in the recent past, there is now new evidence (c.f. <ref> (Bayardo & Schrag, 1996, 1997) </ref>) that systematic search algo 1. I use the term EDB rather than the more common "dependency directed backtracking" since the latter has been used by some authors to refer to both intelligent backtracking and learning from failures. <p> A minor exception is the work of Verfaillie and Schiex (1994), who consider using the nogoods when the CSP problem is modified by adding and deleting constraints 29 Kambhampati eventually be re-learned again 20 ). Bayardo and Miranker <ref> (Bayardo & Miranker, 1996) </ref> discuss a family of relevance based learning schemes. A k th -order relevance based learning scheme keeps a nogood as long as it differs in at most k variable-value pairs from the current partial assignment.
Reference: <author> Bayardo, R., & Schrag, R. </author> <year> (1996). </year> <title> Using csp look-back techniques to solve exceptionally hard sat instances. </title> <booktitle> In Ppls of Constraint Programming Languages (lecture notes in CS, v. </booktitle> <pages> 1118). </pages>
Reference-contexts: Although the emphasis shifted to non-systematic search strategies such as GSAT (Selman, Levesque, & Mitchel, 1992) in the recent past, there is now new evidence (c.f. <ref> (Bayardo & Schrag, 1996, 1997) </ref>) that systematic search algo 1. I use the term EDB rather than the more common "dependency directed backtracking" since the latter has been used by some authors to refer to both intelligent backtracking and learning from failures. <p> A minor exception is the work of Verfaillie and Schiex (1994), who consider using the nogoods when the CSP problem is modified by adding and deleting constraints 29 Kambhampati eventually be re-learned again 20 ). Bayardo and Miranker <ref> (Bayardo & Miranker, 1996) </ref> discuss a family of relevance based learning schemes. A k th -order relevance based learning scheme keeps a nogood as long as it differs in at most k variable-value pairs from the current partial assignment.
Reference: <author> Bayardo, R., & Schrag, R. </author> <year> (1997). </year> <title> Using csp look-back techniques to solve real-world sat instances. </title> <note> In Proc. AAAI-97 (to appear). </note>
Reference: <author> Bhatnagar, N., & Mostow, J. </author> <year> (1994). </year> <title> On-line learning from search failures. </title> <journal> Machine Learning, </journal> <volume> 15, </volume> <pages> 69-117. </pages>
Reference-contexts: This latter is motivated by the fact that although proving that a partial plan is inconsistent is hard, often we may know that the presence of a set of features is losely "indicative" of the unpromising nature of then partial plan. For example, FAILSAFE system <ref> (Bhatnagar & Mostow, 1994) </ref> constructs explanations that explicate why the current node is not the goal node, inspite of many refinements. Relaxing soundness requirement on failure explanations will allow EBL to learn with incomplete explanations, thus improving the number of learning opportunities.
Reference: <author> Blum, A., & Furst, M. </author> <year> (1995). </year> <title> Fast planning through plan-graph analysis. </title> <booktitle> In Proc. IJCAI-95. </booktitle>
Reference-contexts: Yang's WATPLAN (Yang, 1992) and Kambhampati and Yang's (1996) UCPOP-D pose the problem of checking a single plans linearizations for solutions as a CSP, while the more recent research efforts including Graphplan <ref> (Blum & Furst, 1995) </ref> and SATPLAN (Kautz & Selman, 1996), and Descartes (Joslin & Pollack, 1997) encode the problem of sorting through the linearizations of a large set of partial plans (represented in a disjunctive fashion) as a CSP. <p> In all these cases, the usual search tradeoffs in CSP apply (Frost & Dechter, 1994c). For example, the CSP (solution extraction) phase of Graphplan <ref> (Blum & Furst, 1995) </ref> uses a combination of constraint propagation (propagation of 2-sized mutex constraints) and a form of EBL (memoizing higher-order mutex constraints learned through search failures ) to improve performance. 6. <p> Here, we are not considering the use of constraint propagation and EBL in planners like WATPLAN (Yang, 1992) and Graphplan <ref> (Blum & Furst, 1995) </ref> since as we discussed in Section 5.3, since in these planners, the techniques are employed in the solution extraction phase, which is cast as a CSP problem directly.
Reference: <author> Bruynooghe, M. </author> <year> (1981). </year> <title> Solving combinatorial search problems by intelligent backtracking. </title> <journal> Information processing letters, </journal> <volume> 12, </volume> <pages> 36-39. </pages> <note> 37 Kambhampati Daniel, </note> <author> L. </author> <year> (1977). </year> <title> Planning: Modifying non-linear plans. </title> <type> Tech. rep. DAI Working Paper: 24, </type> <institution> University Of Edinburgh,. </institution>
Reference: <author> Dechter, R. </author> <year> (1990). </year> <title> Enhancement schemes for learning: Back-jumping, learning and cutset decomposition. </title> <journal> Artificial Intelligence, </journal> <volume> 41, </volume> <pages> 273-312. </pages>
Reference-contexts: Although this similarity has sometimes been noted in earlier literature (c.f. <ref> (Dechter, 1990) </ref>), a thorough analysis has been impeded by the many superficial differences between the existing approaches in CSP and Planning. <p> Similar points are raised by Minton and Etzioni (Etzioni & Minton, 1992). This phenomenon is also similar to the "bridging effect" that Prosser talks about (Prosser, 1993) 15. Dechter <ref> (Dechter, 1990) </ref> uses multiple failure explanations for leaf node failures -but she never propagates them upwards or simplifies them (since she is getting the minimal explanations to begin with). So, the implicit disjunction involved in multiple failure explanation is not a problem for her. 16. <p> This special structure of BCSP problems has facilitated specialized versions of EDB algorithm such as "Graph-based back jumping" <ref> (Dechter, 1990) </ref> that use the constraint graphs to help in deciding which decision to backtrack to. In planning, no one-to-one correspondence exists between decisions and the constraints in the node. <p> Traditional EBL does not consider direct resolution of stored explanations. In contrast, some approaches, such as the NR fl (Schiex & Verfaille, 1994; Schiex & Verfaillie, 1993) allow combining ("resolving") any set of stored failure explanations. They can thus derive more implicit constraints than traditional EBL. 23 Dechter <ref> (Dechter, 1990) </ref>, describes an even more eager approach which does nogood learning by just analyzing the failing leaf nodes, without reasoning about interior nodes. In particular, the approach enumerates all failure explanations of the node that violate either explicitly stated constraints or implied constraints. <p> Thus, in theory we can avoid regression and propagation procedures all together <ref> (Dechter, 1990) </ref>. While all the approaches are explicating the implicit constraints, the tradeoffs between eager and lazy (or "example-directed") approaches are related to the utility problem.
Reference: <author> Dechter, R., & Dechter, A. </author> <year> (1988). </year> <title> Belief maintainance in dynamic constraint networks. </title> <booktitle> In Proc. AAAI-88. </booktitle>
Reference: <author> DeJong, G. </author> <year> (1996). </year> <booktitle> The Computer Science and Engineering Handbook, chap. 21. Explanation-based learning. </booktitle> <publisher> CRC Press. </publisher>
Reference: <author> Estlin, T., & Mooney, R. </author> <year> (1996). </year> <title> Multi-strategy learning for search control for partial order planning. </title> <booktitle> In Proc. AAAI-96. </booktitle>
Reference-contexts: Similarly, within the planning and problem-solving communities, EBL approaches are finding continued uses in learning search control (Kambhampati et al., 1996), case-based planning (Ihrig & Kambhampati, 1996; Munoz-Avila & Weberskirsch, 1996), plan quality control <ref> (Estlin & Mooney, 1996) </ref>. Moreover, recent work in planning has amply emphasized the role of constraint satisfaction in plan synthesis (Kautz & Selman, 1996; Kambhampati & Yang, 1996; Joslin & Pollack, 1997). <p> When we regress the explanation of node H over the demotion decision 9. In some ways, this is misleading as it seems to suggest that only explanation based learning can suffer from utility problem. Any approach for learning control information, whether it is explanation based or inductive (c.f. <ref> (Estlin & Mooney, 1996) </ref>, could suffer from the utility problem. 10.
Reference: <author> Etzioni, O. </author> <year> (1993). </year> <title> A structural theory of explanation-based learning. </title> <journal> Artificial Intelligence, </journal> <volume> 60(1). </volume>
Reference-contexts: In fact, some approaches for handling EBL utility problem (see Section 4.5) explicitly prohibit learning from looping failures for this very reason <ref> (Etzioni, 1993) </ref>. Ultimately, if there is a significant amount of looping, failure based approaches do not help enough in controlling the search of a planner (c.f. (Kambhampati et al., 1996)). One idea is to find other types of failures that have smaller explanations.
Reference: <author> Etzioni, O., & Minton, S. </author> <year> (1992). </year> <title> Why ebl produces overly-specific knowledge: A critique of the prodigy approaches. </title> <booktitle> In Proc. Machine Learning Conference. </booktitle>
Reference-contexts: Similar points are raised by Minton and Etzioni <ref> (Etzioni & Minton, 1992) </ref>. This phenomenon is also similar to the "bridging effect" that Prosser talks about (Prosser, 1993) 15. Dechter (Dechter, 1990) uses multiple failure explanations for leaf node failures -but she never propagates them upwards or simplifies them (since she is getting the minimal explanations to begin with). <p> Etzioni and Minton <ref> (Etzioni & Minton, 1992) </ref> argue that often EBL produces overly-specific knowledge that leads to inefficient inter-problem transfer, precisely because it is guided purely by examples. They suggest using hybrid techniques that use both direct inferencing and example driven learning to improve the generality of learned knowledge.
Reference: <author> Frost, D., & Dechter, R. </author> <year> (1994a). </year> <title> Dead-end driven learning. </title> <booktitle> In Proc. AAAI-94. </booktitle>
Reference: <author> Frost, D., & Dechter, R. </author> <year> (1994b). </year> <title> In search of best constraint satisfaction search. </title> <booktitle> In Proc. AAAI-94. </booktitle>
Reference: <author> Frost, D., & Dechter, R. </author> <year> (1994c). </year> <title> In search of the best constraint satisfactions earch. </title> <booktitle> In Proc. AAAI-94. </booktitle>
Reference-contexts: In all these cases, the usual search tradeoffs in CSP apply <ref> (Frost & Dechter, 1994c) </ref>. For example, the CSP (solution extraction) phase of Graphplan (Blum & Furst, 1995) uses a combination of constraint propagation (propagation of 2-sized mutex constraints) and a form of EBL (memoizing higher-order mutex constraints learned through search failures ) to improve performance. 6.
Reference: <author> Gaschnig, J. </author> <year> (1977). </year> <title> A general backtrack algorithm tha teliminates most redundant tests. </title> <booktitle> In Proc. </booktitle> <address> IJCAI-77. </address>
Reference-contexts: Similarly, the term backjumping has been used originally by Gaschnig <ref> (Gaschnig, 1977) </ref> to refer to the act of backtracking intelligently from the leaf nodes alone-in other words, there was no propagation, and computation of interior node failure explanations. However, some recent descriptions use the term to refer to the process of propagation and interior node failure explanation.
Reference: <author> Ginsberg, M. </author> <year> (1993). </year> <title> Dynamic backtracking. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1, </volume> <pages> 25-46. </pages>
Reference-contexts: Section 6 summarizes the contributions of the paper, and speculates on how the improved understanding of EDB/EBL can suggest potentially fruitful avenues of research. Appendix A discusses ways of extending the basic framework to support more flexible backtracking regimes such as dynamic backtracking <ref> (Ginsberg, 1993) </ref>. 2. Refinement Search Preliminaries The refinement search (also called split-and-prune search (Pearl, 1984)) paradigm is useful for modeling search problems in which it is possible to enumerate all potential solutions (called candidates) and verify if one of them is a solution for the problem.
Reference: <author> Ginsberg, M., & McAllester, D. </author> <year> (1994). </year> <title> Gsat and dynamic backtracking. </title> <booktitle> In Proc. </booktitle> <address> KRR. </address>
Reference-contexts: In addition, I will discuss how ideas such as "constraint propagation" (Tsang, 1993) and "dynamic backtracking" <ref> (Ginsberg & McAllester, 1994) </ref> are related to the ideas of IB and EBL.
Reference: <author> Gratch, J., & DeJong, G. </author> <year> (1992). </year> <title> Composer: A probabilistic solution to the utility problem in speed-up learning. </title> <booktitle> In Proc. AAAI-92, </booktitle> <pages> pp. 235-240. </pages>
Reference: <author> Greiner, R. </author> <year> (1996). </year> <title> Palo: a probabilistic hill-climbing algorithm. </title> <journal> Artificial Intelligence, </journal> <volume> 84, </volume> <pages> 177-208. </pages>
Reference: <author> Ihrig, L., & Kambhampati, S. </author> <year> (1996). </year> <title> Design and implementation of a derivational replay system based on a partial order planner. </title> <booktitle> In Proc. AAAI-96. </booktitle>
Reference: <author> Jiang, Y., Richards, T., & Richards, B. </author> <year> (1994). </year> <title> No-good backmarking with min-conflict repair in constraint satisfaction and optimization. </title> <booktitle> In Proc. 2nd Principles and Practice of Constraint Programming workshop. </booktitle>
Reference-contexts: The two schemes above are static in that once a nogood is remembered, it will never be forgotten. Another class of approaches forget some of the stored nogoods as the search progresses. Jiang et. al. <ref> (Jiang, Richards, & Richards, 1994) </ref> propose forgetting previously stored nogoods that are subsumed by (i.e., are less general than ) the newly learned nogoods.
Reference: <author> Joslin, D., & Pollack, M. </author> <year> (1997). </year> <title> Is least commitment always a good idea?. In Proc. AAAI-96. 38 Relations between IB & EBL in Planning and CSP Kambhampati, </title> <editor> S. </editor> <year> (1995). </year> <title> Admissible pruning strategies for plan-space planners. </title> <booktitle> In Proc. IJCAI-95. </booktitle>
Reference-contexts: Yang's WATPLAN (Yang, 1992) and Kambhampati and Yang's (1996) UCPOP-D pose the problem of checking a single plans linearizations for solutions as a CSP, while the more recent research efforts including Graphplan (Blum & Furst, 1995) and SATPLAN (Kautz & Selman, 1996), and Descartes <ref> (Joslin & Pollack, 1997) </ref> encode the problem of sorting through the linearizations of a large set of partial plans (represented in a disjunctive fashion) as a CSP. In all these cases, the usual search tradeoffs in CSP apply (Frost & Dechter, 1994c).
Reference: <author> Kambhampati, S. </author> <year> (1996). </year> <title> Formalizing dependency directed backtracking and explanation-based learning in refinement search. </title> <booktitle> In Proceedings of AAAI-96. </booktitle>
Reference-contexts: Similarly, within the planning and problem-solving communities, EBL approaches are finding continued uses in learning search control <ref> (Kambhampati et al., 1996) </ref>, case-based planning (Ihrig & Kambhampati, 1996; Munoz-Avila & Weberskirsch, 1996), plan quality control (Estlin & Mooney, 1996). Moreover, recent work in planning has amply emphasized the role of constraint satisfaction in plan synthesis (Kautz & Selman, 1996; Kambhampati & Yang, 1996; Joslin & Pollack, 1997). <p> The modified refinement search template is shown in Figure 6. The procedure Propagate (which works as a co-routine to refinement 5. There does exist a rather high-level constraint propagation in planning. In <ref> (Kambhampati & Yang, 1996) </ref>, we argue for separating the notions of splitting and narrowing of candidate sets in the context of planning, and show that traditional plan refinement strategies narrow the candidate set of the plan, even if we choose not to split the result of the refinement into multiple partial <p> In some ways, this is misleading as it seems to suggest that only explanation based learning can suffer from utility problem. Any approach for learning control information, whether it is explanation based or inductive (c.f. (Estlin & Mooney, 1996), could suffer from the utility problem. 10. See <ref> (Kambhampati et al., 1996) </ref> for a more comprehensive treatment of EBL/EDB in partial order planning. 19 Kambhampati that was used to resolve the unsafe causal link flaw involving 0 Cool (A) ! 2 and the effects of step 1 (demotion (ef f ect (1; :Cool (A)); 0 Cool (A) ! 2)), <p> then since the initial state changes from problem to problem, we must add a clause to the effect that initial state does not give the condition Q2 (alternately, we must do counter-factual search to see if the failure would have occurred even if the initial state gave the condition Q2 <ref> (Kambhampati et al., 1996) </ref>). <p> So, all step-names other than initial step name can be generalized without worrying about losing soundness. (Even initial step can be generalized if an ordering involving it is never regressed over a step-addition decision that added it, see <ref> (Kambhampati et al., 1996) </ref>). Traditionally, the treatments of EBL in machine learning focused heavily on the generalization phase (Minton et al., 1989). This tends to mask the essential similarities between them and the learning approaches in CSP (e.g. (Dechter, 1990; Frost & Dechter, 1994a)). <p> In fact, some approaches for handling EBL utility problem (see Section 4.5) explicitly prohibit learning from looping failures for this very reason (Etzioni, 1993). Ultimately, if there is a significant amount of looping, failure based approaches do not help enough in controlling the search of a planner (c.f. <ref> (Kambhampati et al., 1996) </ref>). One idea is to find other types of failures that have smaller explanations. Part of the reason for the lack of detectable failures in planning, as contrasted to CSP problems, is a lack of global problem/domain constraints. <p> However, it is possible to pose subparts of the planning problem as CSP problems. In particular, the problem of "finding if any of the minimal candidates (linearizations) of a set of partial plans corresponds to a solution" can be posed as a CSP problem <ref> (Kambhampati & Yang, 1996) </ref>. <p> Since planning can also be cast as a refinement search, it is reasonable to expect that similar techniques work well for planning too. As we mentioned, to our knowledge, the only planner that uses EDB techniques is UCPOP+EBL <ref> (Kambhampati et al., 1996) </ref>. <p> I thank them for them for their insights. I also thank Suresh Katukam and Terry Zimmerman for their critical comments on a previous draft, and Steve Minton for his encouragement on this line of work. A preliminary version of this paper was presented at AAAI-96 <ref> (Kambhampati, 1996) </ref>. The comments of the JAIR reviewers, as well as those of Roberto Bayardo were helpful in revising the paper.
Reference: <author> Kambhampati, S., Katukam, S., & Qu, Y. </author> <year> (1996). </year> <title> Failure driven dynamic search control for partial order planners: An explanation-based approach. </title> <journal> Artificial Intelligence, </journal> <volume> 88. </volume>
Reference-contexts: Similarly, within the planning and problem-solving communities, EBL approaches are finding continued uses in learning search control <ref> (Kambhampati et al., 1996) </ref>, case-based planning (Ihrig & Kambhampati, 1996; Munoz-Avila & Weberskirsch, 1996), plan quality control (Estlin & Mooney, 1996). Moreover, recent work in planning has amply emphasized the role of constraint satisfaction in plan synthesis (Kautz & Selman, 1996; Kambhampati & Yang, 1996; Joslin & Pollack, 1997). <p> The modified refinement search template is shown in Figure 6. The procedure Propagate (which works as a co-routine to refinement 5. There does exist a rather high-level constraint propagation in planning. In <ref> (Kambhampati & Yang, 1996) </ref>, we argue for separating the notions of splitting and narrowing of candidate sets in the context of planning, and show that traditional plan refinement strategies narrow the candidate set of the plan, even if we choose not to split the result of the refinement into multiple partial <p> In some ways, this is misleading as it seems to suggest that only explanation based learning can suffer from utility problem. Any approach for learning control information, whether it is explanation based or inductive (c.f. (Estlin & Mooney, 1996), could suffer from the utility problem. 10. See <ref> (Kambhampati et al., 1996) </ref> for a more comprehensive treatment of EBL/EDB in partial order planning. 19 Kambhampati that was used to resolve the unsafe causal link flaw involving 0 Cool (A) ! 2 and the effects of step 1 (demotion (ef f ect (1; :Cool (A)); 0 Cool (A) ! 2)), <p> then since the initial state changes from problem to problem, we must add a clause to the effect that initial state does not give the condition Q2 (alternately, we must do counter-factual search to see if the failure would have occurred even if the initial state gave the condition Q2 <ref> (Kambhampati et al., 1996) </ref>). <p> So, all step-names other than initial step name can be generalized without worrying about losing soundness. (Even initial step can be generalized if an ordering involving it is never regressed over a step-addition decision that added it, see <ref> (Kambhampati et al., 1996) </ref>). Traditionally, the treatments of EBL in machine learning focused heavily on the generalization phase (Minton et al., 1989). This tends to mask the essential similarities between them and the learning approaches in CSP (e.g. (Dechter, 1990; Frost & Dechter, 1994a)). <p> In fact, some approaches for handling EBL utility problem (see Section 4.5) explicitly prohibit learning from looping failures for this very reason (Etzioni, 1993). Ultimately, if there is a significant amount of looping, failure based approaches do not help enough in controlling the search of a planner (c.f. <ref> (Kambhampati et al., 1996) </ref>). One idea is to find other types of failures that have smaller explanations. Part of the reason for the lack of detectable failures in planning, as contrasted to CSP problems, is a lack of global problem/domain constraints. <p> However, it is possible to pose subparts of the planning problem as CSP problems. In particular, the problem of "finding if any of the minimal candidates (linearizations) of a set of partial plans corresponds to a solution" can be posed as a CSP problem <ref> (Kambhampati & Yang, 1996) </ref>. <p> Since planning can also be cast as a refinement search, it is reasonable to expect that similar techniques work well for planning too. As we mentioned, to our knowledge, the only planner that uses EDB techniques is UCPOP+EBL <ref> (Kambhampati et al., 1996) </ref>. <p> I thank them for them for their insights. I also thank Suresh Katukam and Terry Zimmerman for their critical comments on a previous draft, and Steve Minton for his encouragement on this line of work. A preliminary version of this paper was presented at AAAI-96 <ref> (Kambhampati, 1996) </ref>. The comments of the JAIR reviewers, as well as those of Roberto Bayardo were helpful in revising the paper.
Reference: <author> Kambhampati, S., Knoblock, C., & Yang, Q. </author> <year> (1995). </year> <title> Planning as refinement search: A unified framework for evaluating design tradeoffs in partial order planning. </title> <journal> Artificial Intelligence (special issue on Planning and Scheduling), </journal> <volume> 76, </volume> <pages> 167-238. </pages>
Reference-contexts: To this end, I consider all backtracking and learning algorithms within the context of general refinement search <ref> (Kambhampati, Knoblock, & Yang, 1995) </ref>. Refinement search involves starting with the set of all potential solutions for the problem, and repeatedly splitting the set until a solution for the problem can be extracted from one of the sets. <p> Thus, initial state is specified as Cool (A) and the goal state is specified as P olished (A) ^ Cylindrical (A). Search nodes in planning can be represented (see <ref> (Kambhampati et al., 1995) </ref>) as 6-tuples hS; O; B; L; E; Ci; where S is the set of steps, O is the set of orderings between the steps, E is the set of effects of the steps in S, C is the set of preconditions of the steps in S, B <p> P , and s 1 and s 2 are the i th and j th elements in G, then none of the actions G [i + 1]; G [i + 2]; G [j 1] must have an effect :p). 4 There are several types of complete refinement operators in planning <ref> (Kambhampati & Srivastava, 1995) </ref>, including plan space, state-space, and task reduction refinements. As an example, plan-space refinement proceeds by picking a goal condition and considering different ways of making that condition true in different branches. <p> Things are actually slightly more complicated than this since two steps in P may be instances of the same action. To handle this, we need to think in terms of a mapping between steps of P and elements of G, and check the constraints under that mapping <ref> (Kambhampati et al., 1995) </ref> 8 Relations between IB & EBL in Planning and CSP s 0 p 0 p 00 2 effects of s n Effects: S S + s n L L + s n ! s d B B + maximalgeneralunif ier (p 0 ; p 00 ) + <p> The task knowledge is knowledge about planning tasks in general, and will include axioms such as "no step can precede as well as follow another step", "no variable can have two values" etc, as well as theories of looping <ref> (Kambhampati, 1995) </ref>. The domain knowledge is domain level resource and capacity constraints, such as "no block can have more than one block on top of it". In the case of CSP, problem and domain knowledge consists of constraints on compound labels. <p> Since there is no detectable inconsistency in the search node or (partial plan) at the depth limit, it is hard to recognize or explain dead-ends in such situations, which severely inhibits the effectiveness of EDB and EBL. Although it is possible to provide a theory of loop-detection and pruning <ref> (Kambhampati, 1995) </ref>, and use it to explain why it is sound to prune the plan, the explanations constructed in this way tend to be rather long, and are thus of limited utility in EDB and EBL.
Reference: <author> Kambhampati, S., & Srivastava, B. </author> <year> (1995). </year> <title> Universal classical planner: An algorithm for unifying state-space and plan-space planning. </title> <booktitle> In Proc. 3rd European Workshop on Planning Systems. </booktitle>
Reference-contexts: To this end, I consider all backtracking and learning algorithms within the context of general refinement search <ref> (Kambhampati, Knoblock, & Yang, 1995) </ref>. Refinement search involves starting with the set of all potential solutions for the problem, and repeatedly splitting the set until a solution for the problem can be extracted from one of the sets. <p> Thus, initial state is specified as Cool (A) and the goal state is specified as P olished (A) ^ Cylindrical (A). Search nodes in planning can be represented (see <ref> (Kambhampati et al., 1995) </ref>) as 6-tuples hS; O; B; L; E; Ci; where S is the set of steps, O is the set of orderings between the steps, E is the set of effects of the steps in S, C is the set of preconditions of the steps in S, B <p> P , and s 1 and s 2 are the i th and j th elements in G, then none of the actions G [i + 1]; G [i + 2]; G [j 1] must have an effect :p). 4 There are several types of complete refinement operators in planning <ref> (Kambhampati & Srivastava, 1995) </ref>, including plan space, state-space, and task reduction refinements. As an example, plan-space refinement proceeds by picking a goal condition and considering different ways of making that condition true in different branches. <p> Things are actually slightly more complicated than this since two steps in P may be instances of the same action. To handle this, we need to think in terms of a mapping between steps of P and elements of G, and check the constraints under that mapping <ref> (Kambhampati et al., 1995) </ref> 8 Relations between IB & EBL in Planning and CSP s 0 p 0 p 00 2 effects of s n Effects: S S + s n L L + s n ! s d B B + maximalgeneralunif ier (p 0 ; p 00 ) + <p> The task knowledge is knowledge about planning tasks in general, and will include axioms such as "no step can precede as well as follow another step", "no variable can have two values" etc, as well as theories of looping <ref> (Kambhampati, 1995) </ref>. The domain knowledge is domain level resource and capacity constraints, such as "no block can have more than one block on top of it". In the case of CSP, problem and domain knowledge consists of constraints on compound labels. <p> Since there is no detectable inconsistency in the search node or (partial plan) at the depth limit, it is hard to recognize or explain dead-ends in such situations, which severely inhibits the effectiveness of EDB and EBL. Although it is possible to provide a theory of loop-detection and pruning <ref> (Kambhampati, 1995) </ref>, and use it to explain why it is sound to prune the plan, the explanations constructed in this way tend to be rather long, and are thus of limited utility in EDB and EBL.
Reference: <author> Kambhampati, S., & Yang, X. </author> <year> (1996). </year> <title> Role of disjunctive representations and constraint propagation in planning. </title> <booktitle> In Proc. </booktitle> <address> KR-96. </address>
Reference-contexts: Similarly, within the planning and problem-solving communities, EBL approaches are finding continued uses in learning search control <ref> (Kambhampati et al., 1996) </ref>, case-based planning (Ihrig & Kambhampati, 1996; Munoz-Avila & Weberskirsch, 1996), plan quality control (Estlin & Mooney, 1996). Moreover, recent work in planning has amply emphasized the role of constraint satisfaction in plan synthesis (Kautz & Selman, 1996; Kambhampati & Yang, 1996; Joslin & Pollack, 1997). <p> The modified refinement search template is shown in Figure 6. The procedure Propagate (which works as a co-routine to refinement 5. There does exist a rather high-level constraint propagation in planning. In <ref> (Kambhampati & Yang, 1996) </ref>, we argue for separating the notions of splitting and narrowing of candidate sets in the context of planning, and show that traditional plan refinement strategies narrow the candidate set of the plan, even if we choose not to split the result of the refinement into multiple partial <p> In some ways, this is misleading as it seems to suggest that only explanation based learning can suffer from utility problem. Any approach for learning control information, whether it is explanation based or inductive (c.f. (Estlin & Mooney, 1996), could suffer from the utility problem. 10. See <ref> (Kambhampati et al., 1996) </ref> for a more comprehensive treatment of EBL/EDB in partial order planning. 19 Kambhampati that was used to resolve the unsafe causal link flaw involving 0 Cool (A) ! 2 and the effects of step 1 (demotion (ef f ect (1; :Cool (A)); 0 Cool (A) ! 2)), <p> then since the initial state changes from problem to problem, we must add a clause to the effect that initial state does not give the condition Q2 (alternately, we must do counter-factual search to see if the failure would have occurred even if the initial state gave the condition Q2 <ref> (Kambhampati et al., 1996) </ref>). <p> So, all step-names other than initial step name can be generalized without worrying about losing soundness. (Even initial step can be generalized if an ordering involving it is never regressed over a step-addition decision that added it, see <ref> (Kambhampati et al., 1996) </ref>). Traditionally, the treatments of EBL in machine learning focused heavily on the generalization phase (Minton et al., 1989). This tends to mask the essential similarities between them and the learning approaches in CSP (e.g. (Dechter, 1990; Frost & Dechter, 1994a)). <p> In fact, some approaches for handling EBL utility problem (see Section 4.5) explicitly prohibit learning from looping failures for this very reason (Etzioni, 1993). Ultimately, if there is a significant amount of looping, failure based approaches do not help enough in controlling the search of a planner (c.f. <ref> (Kambhampati et al., 1996) </ref>). One idea is to find other types of failures that have smaller explanations. Part of the reason for the lack of detectable failures in planning, as contrasted to CSP problems, is a lack of global problem/domain constraints. <p> However, it is possible to pose subparts of the planning problem as CSP problems. In particular, the problem of "finding if any of the minimal candidates (linearizations) of a set of partial plans corresponds to a solution" can be posed as a CSP problem <ref> (Kambhampati & Yang, 1996) </ref>. <p> Since planning can also be cast as a refinement search, it is reasonable to expect that similar techniques work well for planning too. As we mentioned, to our knowledge, the only planner that uses EDB techniques is UCPOP+EBL <ref> (Kambhampati et al., 1996) </ref>. <p> I thank them for them for their insights. I also thank Suresh Katukam and Terry Zimmerman for their critical comments on a previous draft, and Steve Minton for his encouragement on this line of work. A preliminary version of this paper was presented at AAAI-96 <ref> (Kambhampati, 1996) </ref>. The comments of the JAIR reviewers, as well as those of Roberto Bayardo were helpful in revising the paper.
Reference: <author> Kautz, H., & Selman, B. </author> <year> (1996). </year> <title> Pushing the envelope: Plannng, propositional logic and stochastic search. </title> <booktitle> In Proc. AAAI-96. </booktitle>
Reference-contexts: When we consider CSP problems where domain constraints are described in "constraint schemas", each of whose instantiations correspond to specific constraints, there is a scope for generalization. Examples of such CSP problems include CSP instances corresponding to finding k-length solutions to a planning problem <ref> (Kautz, Selman, & McAllester, 1996) </ref> (see also Section 5.3). 4.3 Selecting a Failure Explanation In our discussion of EDB and EBL in the previous section, we did not go into the details of how a failure explanation is selected for a dead-end leaf node. <p> Yang's WATPLAN (Yang, 1992) and Kambhampati and Yang's (1996) UCPOP-D pose the problem of checking a single plans linearizations for solutions as a CSP, while the more recent research efforts including Graphplan (Blum & Furst, 1995) and SATPLAN <ref> (Kautz & Selman, 1996) </ref>, and Descartes (Joslin & Pollack, 1997) encode the problem of sorting through the linearizations of a large set of partial plans (represented in a disjunctive fashion) as a CSP. In all these cases, the usual search tradeoffs in CSP apply (Frost & Dechter, 1994c). <p> Furthermore, traditional CSPs start with completely instantiated constraints. In many problems, we can see the individual constraints to be instantiations of specific constraint schemas, obtained by substituting specific object names into the schema (c.f. <ref> (Kautz et al., 1996) </ref>). In such cases, there is going to be a large amount of shared structure between problems making inter-problem learning as well as generalization very attractive.
Reference: <author> Kautz, H., Selman, B., & McAllester, D. </author> <year> (1996). </year> <title> Encoding plans in propositional logic. </title> <booktitle> In Proc. </booktitle> <address> KR-96. </address>
Reference-contexts: When we consider CSP problems where domain constraints are described in "constraint schemas", each of whose instantiations correspond to specific constraints, there is a scope for generalization. Examples of such CSP problems include CSP instances corresponding to finding k-length solutions to a planning problem <ref> (Kautz, Selman, & McAllester, 1996) </ref> (see also Section 5.3). 4.3 Selecting a Failure Explanation In our discussion of EDB and EBL in the previous section, we did not go into the details of how a failure explanation is selected for a dead-end leaf node. <p> Yang's WATPLAN (Yang, 1992) and Kambhampati and Yang's (1996) UCPOP-D pose the problem of checking a single plans linearizations for solutions as a CSP, while the more recent research efforts including Graphplan (Blum & Furst, 1995) and SATPLAN <ref> (Kautz & Selman, 1996) </ref>, and Descartes (Joslin & Pollack, 1997) encode the problem of sorting through the linearizations of a large set of partial plans (represented in a disjunctive fashion) as a CSP. In all these cases, the usual search tradeoffs in CSP apply (Frost & Dechter, 1994c). <p> Furthermore, traditional CSPs start with completely instantiated constraints. In many problems, we can see the individual constraints to be instantiations of specific constraint schemas, obtained by substituting specific object names into the schema (c.f. <ref> (Kautz et al., 1996) </ref>). In such cases, there is going to be a large amount of shared structure between problems making inter-problem learning as well as generalization very attractive.
Reference: <author> Kondrak, G., & vanBeek, P. </author> <year> (1995). </year> <title> A theoretical evaluation of selected backtracking algorithms. </title> <booktitle> In Proc. IJCAI-95. </booktitle>
Reference: <author> Letovsky, S. </author> <year> (1990). </year> <title> Operationality criteria for recursive predicates. </title> <booktitle> In Proc. AAAI-90. </booktitle>
Reference: <author> McAllester, D., & Rosenblitt, D. </author> <year> (1991). </year> <title> Systematic nonlinear planning. </title> <booktitle> In Proc. 9th AAAI. </booktitle>
Reference-contexts: This is because resolving an open condition may introduce new steps into the plan whose preconditions become new open condition flaws. Example: We shall now illustrate refinement search process in planning (specifically, partial order causal-link planning, of the type used in SNLP <ref> (McAllester & Rosenblitt, 1991) </ref>). jobshop domain, discussed earlier. The planner starts with the null plan, and picks up the open condition flaw Cylindrical (A)@G. This flaw is resolved by adding the step 1: Roll (A) which has an effect Cylindrical (A).
Reference: <author> Minton., S. </author> <year> (1990). </year> <title> Quantitative results concerning the utility of explanation based learning. </title> <journal> Artificial Intelligence, </journal> <volume> 42, </volume> <pages> 363-391. </pages>
Reference: <author> Minton, S., Carbonell, J., Knoblock, C., Kuokka, D., Etzioni, O., & Gil, Y. </author> <year> (1989). </year> <title> Explanation-based learning: A problem solving perspective. </title> <journal> Artificial Intelligence, </journal> <volume> 40, </volume> <pages> 63-118. </pages>
Reference-contexts: A variation of this approach involves learning search control rules <ref> (Minton et al., 1989) </ref> which recommend rejection of individual decisions of a refinement operator if they lead to a failing node. <p> Traditionally, the treatments of EBL in machine learning focused heavily on the generalization phase <ref> (Minton et al., 1989) </ref>. This tends to mask the essential similarities between them and the learning approaches in CSP (e.g. (Dechter, 1990; Frost & Dechter, 1994a)). Our treatment here shows that the "object generalization" is only a small variation on the basic EBL/EDB theme.
Reference: <author> Mittal, S., & Falkenhainer, B. </author> <year> (1990). </year> <title> Dynamic constraint satisfaction problems. </title> <booktitle> In Proc. AAAI-90. </booktitle>
Reference-contexts: This new constraint can be added to N 3 , effectively narrowing its candidate set. 2.1.1 Dynamic CSP as refinement search There is generalization of CSP problems called Dynamic CSPs <ref> (Mittal & Falkenhainer, 1990) </ref> that we will find useful in comparing CSP and Planning problems 3 . Just like CSPs, Dynamic CSPs contain variables, their domains, and constraints on legal compound la bels. <p> Dynamic CSPs were originally proposed to model "configuration" tasks <ref> (Mittal & Falkenhainer, 1990) </ref>. As we shall see below, they can also model planning tasks. 2.2 Planning as Refinement Search A planning problem is specified by an initial state description I, a goal state description G, and a set of actions A. <p> This argument does not hold if we are dealing with any of the following variations of standard CSP problems: 1. Dynamic constraint satisfaction problems <ref> (Mittal & Falkenhainer, 1990) </ref> (see Sec tion 2.1.1) where flaw structure evolves as refinements take place. 2. Incremental or evolving CSPs, where the constraints are dynamically added or removed as the problem evolves (Dechter & Dechter, 1988; Schiex & Verfaillie, 1993; Verfaillie & Schiex, 1994) 3.
Reference: <author> Munoz-Avila, H., & Weberskirsch, F. </author> <year> (1996). </year> <title> Planning for manufacturing workpieces by storing, indexing and replaying planning decisions. </title> <booktitle> In Proc. 3rd Intl. Conference on AI Planning Systems. </booktitle>
Reference: <author> Muscettola, N., Smith, S., Cesta, A., & D'Aloisi, D. </author> <year> (1991). </year> <title> Coordinating space telescope operations in an integrated planning and scheduling architecture. </title> <booktitle> In Proc. IEEE Intl. Conf. on Robotics and Automation. </booktitle>
Reference-contexts: This suggests planning search spaces that have more uniform representations are perhaps more amenable to backtrack techniques. One idea would be to "compile" plan representations down to a more uniform language before applying EDB and EBL. State-variable based state representations provide a promising avenue <ref> (Muscettola et al., 1991) </ref>. Acknowledgements The ideas described here developed over the course of my interactions with Suresh Katukam, Gopi Bulusu and Yong Qu. I thank them for them for their insights.
Reference: <author> Nilsson, N. </author> <year> (1980). </year> <booktitle> Principles of Artificial Intelligence. </booktitle> <publisher> Tioga press, </publisher> <address> Palo Alto. </address> <note> 39 Kambhampati Pearl, J. </note> <year> (1984). </year> <title> Heuristics: Intelligent Search Strategies for Computer Problem Solving. </title> <publisher> Addison-Wesley. </publisher>
Reference-contexts: The preconditions 14 Relations between IB & EBL in Planning and CSP with backward application of STRIPS-type operators (with add, delete, and precondition lists), and is quite well-understood (see <ref> (Nilsson, 1980) </ref>). There are two changes that we need to impose to make it useful in our situation. First, we need to adapt regression to refinement decisions (as against actions). This should be straightforward given our characterization of refinement decisions in terms of preconditions and effects.
Reference: <author> Petrie, C. </author> <year> (1992). </year> <title> Constrained decision revision. </title> <booktitle> In Proc. 10th AAAI. </booktitle>
Reference-contexts: In a way, constraint graphs and decision graphs attempt to solve the same problem that is solved by regression. However, the semantics of these structures are often problem dependent, and storing and maintaining them can be quite complex <ref> (Petrie, 1992) </ref>. In contrast, the notion of regression and propagation is problem independent and explicates the dependencies between decisions on an as-needed basis.
Reference: <author> Prosser, P. </author> <year> (1993). </year> <title> Domain filtering can degrade intelligent backtracking search. </title> <booktitle> In Proc. IJCAI-93. </booktitle>
Reference-contexts: Similar points are raised by Minton and Etzioni (Etzioni & Minton, 1992). This phenomenon is also similar to the "bridging effect" that Prosser talks about <ref> (Prosser, 1993) </ref> 15. Dechter (Dechter, 1990) uses multiple failure explanations for leaf node failures -but she never propagates them upwards or simplifies them (since she is getting the minimal explanations to begin with). So, the implicit disjunction involved in multiple failure explanation is not a problem for her. 16. <p> The CSP backtracking idea that is closest to our EDB formalization is the "conflict directed backjumping" (CBJ) approach proposed by Prosser <ref> (Prosser, 1993) </ref>. This algorithm is originally proposed for binary CSP problems.
Reference: <author> Schiex, T., & Verfaille, G. </author> <year> (1994). </year> <title> Stubbornness: a posible enhancement for backjumping and nogood recordings. </title> <booktitle> In Proc. 11th ECAI. </booktitle>
Reference: <author> Schiex, T., & Verfaillie, G. </author> <year> (1993). </year> <title> Nogood recording for static and dynamic constraint satisfaction problems. </title> <booktitle> In Proc. 5th intl. conference on tools with artificial intelligence. </booktitle>
Reference: <author> Selman, B., Levesque, H., & Mitchel, D. </author> <year> (1992). </year> <title> Gsat: A new method for solving hard satisfiability problems. </title> <booktitle> In In Proc. AAAI-92. </booktitle>
Reference-contexts: A variety of empirical studies (c.f. (Prosser, 1993; Frost & Dechter, 1994c, 1994a)) have consistently shown that EDB and EBL techniques are often part of the winning constraint satisfaction search algorithms. Although the emphasis shifted to non-systematic search strategies such as GSAT <ref> (Selman, Levesque, & Mitchel, 1992) </ref> in the recent past, there is now new evidence (c.f. (Bayardo & Schrag, 1996, 1997)) that systematic search algo 1. <p> We shall see that these ideas are best studied separately. 2 Relations between IB & EBL in Planning and CSP rithms, armed with EDB and EBL mechanisms 2 can outperform non-systematic searchers such as GSAT and WALKSAT <ref> (Selman et al., 1992) </ref> on several hard real and artificial satisfiability instances. Similarly, within the planning and problem-solving communities, EBL approaches are finding continued uses in learning search control (Kambhampati et al., 1996), case-based planning (Ihrig & Kambhampati, 1996; Munoz-Avila & Weberskirsch, 1996), plan quality control (Estlin & Mooney, 1996).
Reference: <author> Smith, D., & Peot, M. </author> <year> (1996). </year> <title> Suspending recursion in planning. </title> <booktitle> In Proc. 3rd Intl. AI Planning Systems Conference. </booktitle>
Reference: <author> Stallman, R., & Sussman, G. </author> <year> (1977). </year> <title> Forward reasoning and dependency-directed backtracking in a system for computer aided circuit analysis. </title> <journal> Artificial Intelligence, </journal> <volume> 9, </volume> <pages> 135-196. </pages>
Reference-contexts: 1. Introduction One of the main-stays of AI literature is the idea of "intelligent backtracking" as an antidote for the inefficiencies of chronological backtracking <ref> (Stallman & Sussman, 1977) </ref>. However, there is a considerable confusion and variation regarding the various implementations of intelligent backtracking. Many apparently different ideas, such as back jumping, nogood-based learning and dynamic backtracking are all concerned with the general notion of intelligent backtracking. <p> In our CSP example, after computing the explanation of failure of N 4 to be x = A ^ y = B ^ needsAssignment (w), we can remember this as a learned failure explanation (aka nogood <ref> (Stallman & Sussman, 1977) </ref>), and use it to prune nodes in other parts of the search tree. Unlike EDB, whose overheads are generally negligible compared to chronological backtracking, learning failure explanations through EBL has two types of hidden costs. First, there is the storage cost. <p> Early formalizations of dependency directed backtracking (e.g. <ref> (Stallman & Sussman, 1977) </ref>) have made the rather strong assumption that all failure explanations would be stored.
Reference: <author> Tsang, E. </author> <year> (1993). </year> <title> Foundations of Constraint Satisfaction. </title> <publisher> Academic Press, </publisher> <address> San Diego, </address> <publisher> California. </publisher> <editor> van Harmelen, F., & Bundy, A. </editor> <year> (1988). </year> <title> Explanation-based generalisation = partial evaluation. </title> <journal> Artificial Intelligence, </journal> <volume> 36, </volume> <pages> 401-412. </pages>
Reference-contexts: I will show how approaches for CSP and planning differ in these aspects, and justify these differences in terms of the characteristics of CSP and Planning problems, when seen as instantiations of refinement search. In addition, I will discuss how ideas such as "constraint propagation" <ref> (Tsang, 1993) </ref> and "dynamic backtracking" (Ginsberg & McAllester, 1994) are related to the ideas of IB and EBL. <p> Figure 2 shows how planning and CSP problems can be modeled in terms of refinement search. The next two subsections elaborate this formulation. 2.1 Constraint Satisfaction as Refinement Search A constraint satisfaction problem (CSP) <ref> (Tsang, 1993) </ref> is specified by a set of n variables, x 1 ; x 2 x n , their respective value domains, D 1 ; D 2 D n and a set of constraints. <p> Inferred constraints come into refinement search when refinements are interspersed with constraint propagation (such as forward checking or local consistency enforcement <ref> (Tsang, 1993) </ref>). decision "w E" that leads to N 5 , resulting in x = A (since w = E is the only constraint that is added by the decision). <p> Examples of this type of learning include "partial evaluation" techniques used in program optimization (van Harmelen & Bundy, 1988), and the constraint propagation (local consistency enforcement) techniques used in CSP <ref> (Tsang, 1993) </ref>. The utility problem that we discussed in the context of EBL (Section 4.5) applies equally well to the constraints derived by these direct-inferencing approaches.
Reference: <author> Verfaillie, G., & Schiex, T. </author> <year> (1994). </year> <title> Solution reuse in dynamic constraint satisfaction problems. </title> <booktitle> In Proc. AAAI-94. </booktitle>
Reference: <author> Yang, Q. </author> <year> (1992). </year> <title> A theory of conflict resolution in planning. </title> <journal> Artificial Intelligence, </journal> <volume> 58, </volume> <pages> 361-392. </pages>
Reference-contexts: In particular, the problem of "finding if any of the minimal candidates (linearizations) of a set of partial plans corresponds to a solution" can be posed as a CSP problem (Kambhampati & Yang, 1996). Yang's WATPLAN <ref> (Yang, 1992) </ref> and Kambhampati and Yang's (1996) UCPOP-D pose the problem of checking a single plans linearizations for solutions as a CSP, while the more recent research efforts including Graphplan (Blum & Furst, 1995) and SATPLAN (Kautz & Selman, 1996), and Descartes (Joslin & Pollack, 1997) encode the problem of sorting <p> Here, we are not considering the use of constraint propagation and EBL in planners like WATPLAN <ref> (Yang, 1992) </ref> and Graphplan (Blum & Furst, 1995) since as we discussed in Section 5.3, since in these planners, the techniques are employed in the solution extraction phase, which is cast as a CSP problem directly.
Reference: <author> Zimmerman, T., & Kambhampati, S. </author> <year> (1997). </year> <title> Using unsound failure explanations to imr-prove the effectiveness of ebl. In preparation. 40 Relations between IB & EBL in Planning and CSP </title>
Reference-contexts: We are currently experimenting with a variant of this approach, where such partial explanations of failure are associated with numerical certainty factors between 0 and 1 (to signify their level of soundness) <ref> (Zimmerman & Kambhampati, 1997) </ref>. The explanation of failure of an interior node will have a certainty factor that depends on the certainty factors of the explanations of failure of its children nodes.
References-found: 51

