URL: http://www.cs.umn.edu/Users/dept/users/bmiller/adb.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/bmiller/
Root-URL: http://www.cs.umn.edu
Title: A Zoomable DBMS for Brain Structure, Function and Behavior  
Author: J. Carlis, J. Riedl, A. Georgopoulos, G.Wilcox, R. Elde, J. Pardo, K. Ugurbil, E. Retzel, J. Maguire, B. Miller, M. Claypool, T.Brelje, C. Honda 
Affiliation: University of Minnesota Computer Science Department and Medical School  
Abstract: We have begun a long-term project to build a new kind of database and its enhanced, supporting database management system (DBMS) for international neuroscience research. Because brain research occurs world-wide, our database will be distributed, encouraging rapid, open dissemination of results to a broad audience of neuroscientists. It will conjoin information and experimental results from many disciplines. We envision a zoomable database of the brain tissue itself, in large part embedded in three dimensions (3D), through which one can "fly." Within this coarse structure, the database will also organize fine-structural, functional and behavioral data. As often as possible, the database will express experimental data in its purest, least analyzed form, so that expensive raw data can be analyzed and reanalyzed by researchers worldwide. We believe that our project will profoundly effect the way in which neu-roscience is done, while providing key areas for database research and distributed computing. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> L. Barnett and J. Carlis. </author> <title> Feature information support and the sdts conceptual data model: Clarification and extension. </title> <booktitle> In Proceedings AUTO-CARTO 11, Eleventh International Symposium on Computer Assisted Cartography, </booktitle> <year> 1993. </year>
Reference-contexts: Furthermore, our model must separate this common conception of the brain's structure from particular images of the brain. 2.3 Preliminary Design We assume that readers are familiar with data modeling using a logical data structure, or LDS <ref> [20, 9, 14, 1, 8] </ref>. The model in Figure 1 focuses on MRI and Confocal notions plus their "Connections." To save space we have not displayed some straightforward types of data, and have used acronyms liberally.
Reference: 2. <author> P. Bernstein and N. Goodman. </author> <title> An algorithm for concurrency control and recovery in replicated distributed databases. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 9(4) </volume> <pages> 596-615, </pages> <month> December </month> <year> 1984. </year>
Reference-contexts: It is appropriate for applications that cannot tolerate any inconsistency in their data, no matter how modest or short-lived. Examples include financial databases and medical records databases. 1-copy serializability is implemented using powerful concurrency control techniques such as two-phase locking [13] or timestamp ordering <ref> [2] </ref> in conjunction with a distributed commit protocol such as two-phase commit [22] or three-phase commit [21]. These protocols involve rounds of messages exchanged between all the sites of the distributed system. During the time the messages are being exchanged, no access may be made to affected data.
Reference: 3. <author> P. Bernstein, V. Hadzilacos, and N. Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: Strict consistency would require that all stations wait until the data had propagated completely, making the system inaccessible to users for large periods of time [12, 4]. 3. Strict consistency is not essential. Traditional distributed database systems maintain a consistency requirement called 1-copy serializability <ref> [3] </ref>. 1-copy serializability means that no user can observe even temporary inconsistencies caused by multiple users accessing and updating data on multiple replicas. 1-copy serializability is a theoretically [17, 15] and practically [7] well-understood consistency model.
Reference: 4. <author> P. Bernstein and Goodman N. </author> <title> An algorithm for concurrency control and recovery in replicated distributed databases. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 9(4) </volume> <pages> 596-615, </pages> <year> 1984. </year>
Reference-contexts: Each update is on the order of 100 Mbytes. 100 MB takes a significant amount of time to transmit from one station to another. Strict consistency would require that all stations wait until the data had propagated completely, making the system inaccessible to users for large periods of time <ref> [12, 4] </ref>. 3. Strict consistency is not essential.
Reference: 5. <author> Ken Birman. </author> <title> Replication and availability in the ISIS system. </title> <journal> Operating System Review, </journal> <volume> 19(5) </volume> <pages> 79-86, </pages> <month> December </month> <year> 1985. </year>
Reference-contexts: Each update operation consists of a globally-unique timestamp and a database identifier for the actual data. The timestamps reflect causal ordering: an update with a larger timestamp cannot have depended on an update with a smaller timestamp <ref> [16, 5] </ref>. Each replica contains an update table to keep track of which update operations it has performed. For example, Figure 2 includes replica A, with an update table. Timestamp 54 corresponds to the first Add operation, and timestamp 55 corresponds to the second Add operation.
Reference: 6. <author> A.D. Birrell, R. Levin, R.M. Needham, and M. Schroeder. Grapevine: </author> <title> An exercise in distributed computing. </title> <journal> Communications of the ACM, </journal> <volume> 25 </volume> <pages> 260-274, </pages> <month> April </month> <year> 1982. </year>
Reference-contexts: Accepted data will be of high quality, and will seldom need to be modified after acceptance. 4.3 Preliminary Design Distributed naming is an application domain that shares the high availability and eventual consistency characteristics of the zoomable neural database application <ref> [6, 10] </ref>. We borrow the basic update model from naming systems such as Grapevine [6], modifying it as necessary for the neuroscience application domain. <p> We borrow the basic update model from naming systems such as Grapevine <ref> [6] </ref>, modifying it as necessary for the neuroscience application domain. The methods work on any of the types of data that will be stored in the zoomable database; we explore the model with image data as an example because its large size renders it the most difficult to handle.
Reference: 7. <author> Michael Carey and Michael Stonebraker. </author> <title> The performance of concurrency control algorithms for database management systems. </title> <booktitle> In Proceedings of the Tenth International Conference on Very Large Data Bases, </booktitle> <address> Singapore, </address> <month> August </month> <year> 1984. </year>
Reference-contexts: Strict consistency is not essential. Traditional distributed database systems maintain a consistency requirement called 1-copy serializability [3]. 1-copy serializability means that no user can observe even temporary inconsistencies caused by multiple users accessing and updating data on multiple replicas. 1-copy serializability is a theoretically [17, 15] and practically <ref> [7] </ref> well-understood consistency model. It is appropriate for applications that cannot tolerate any inconsistency in their data, no matter how modest or short-lived.
Reference: 8. <author> J. Carlis. </author> <title> Data Modeling. 1994. Book manuscript, </title> <publisher> in press. </publisher>
Reference-contexts: Furthermore, our model must separate this common conception of the brain's structure from particular images of the brain. 2.3 Preliminary Design We assume that readers are familiar with data modeling using a logical data structure, or LDS <ref> [20, 9, 14, 1, 8] </ref>. The model in Figure 1 focuses on MRI and Confocal notions plus their "Connections." To save space we have not displayed some straightforward types of data, and have used acronyms liberally.
Reference: 9. <author> J. Carlis and S. </author> <month> March. </month> <title> Multi-level model of physical database design problems and solutions. </title> <booktitle> In IEEE COMPDEC Conference, </booktitle> <month> February </month> <year> 1984. </year>
Reference-contexts: Furthermore, our model must separate this common conception of the brain's structure from particular images of the brain. 2.3 Preliminary Design We assume that readers are familiar with data modeling using a logical data structure, or LDS <ref> [20, 9, 14, 1, 8] </ref>. The model in Figure 1 focuses on MRI and Confocal notions plus their "Connections." To save space we have not displayed some straightforward types of data, and have used acronyms liberally. <p> There are four parts to our local zoomable database solution: 1. Data Model. We will modify our techniques of mapping an LDS to schema and access paths, as put forth in <ref> [10, 18, 9, 11] </ref>. 2. Chunks. To effectively and efficiently store and process the zoomable database, we will develop DBMS extensions to support transparent (to the program or human user) chunking of multi-dimensional data with several alternatives available for intra-chunk element order and with several alternative indexing schemes available.
Reference: 10. <author> J. Carlis, S. </author> <month> March, </month> <title> and G Dickson. Physical database design: A dss approach. </title> <booktitle> Information and Management, </booktitle> <month> August </month> <year> 1983. </year>
Reference-contexts: There are four parts to our local zoomable database solution: 1. Data Model. We will modify our techniques of mapping an LDS to schema and access paths, as put forth in <ref> [10, 18, 9, 11] </ref>. 2. Chunks. To effectively and efficiently store and process the zoomable database, we will develop DBMS extensions to support transparent (to the program or human user) chunking of multi-dimensional data with several alternatives available for intra-chunk element order and with several alternative indexing schemes available. <p> Accepted data will be of high quality, and will seldom need to be modified after acceptance. 4.3 Preliminary Design Distributed naming is an application domain that shares the high availability and eventual consistency characteristics of the zoomable neural database application <ref> [6, 10] </ref>. We borrow the basic update model from naming systems such as Grapevine [6], modifying it as necessary for the neuroscience application domain.
Reference: 11. <author> S. M. Carlton, C. C. Lamotte, C. N. Honda, D. J. Surmeier, N. Delanerolle, and W. D. Willis. </author> <title> Ultrastructural analysis of axosomatic contacts on functionally identified primate spinothalamic tract neurons. </title> <journal> J Comp Neurol, </journal> <volume> 281(4) </volume> <pages> 555-66, </pages> <year> 1989. </year>
Reference-contexts: There are four parts to our local zoomable database solution: 1. Data Model. We will modify our techniques of mapping an LDS to schema and access paths, as put forth in <ref> [10, 18, 9, 11] </ref>. 2. Chunks. To effectively and efficiently store and process the zoomable database, we will develop DBMS extensions to support transparent (to the program or human user) chunking of multi-dimensional data with several alternatives available for intra-chunk element order and with several alternative indexing schemes available.
Reference: 12. <author> Jim Gray. </author> <title> The transaction concept: Virtues and limitations. </title> <booktitle> In Proc of the VLDB Conference, </booktitle> <address> Cannes, France, </address> <month> September </month> <year> 1981. </year>
Reference-contexts: Each update is on the order of 100 Mbytes. 100 MB takes a significant amount of time to transmit from one station to another. Strict consistency would require that all stations wait until the data had propagated completely, making the system inaccessible to users for large periods of time <ref> [12, 4] </ref>. 3. Strict consistency is not essential.
Reference: 13. <author> J.N. Gray, R.A. Lorie, </author> <title> G.F. Putzolu, and I.L. Traiger. Granularity of locks and degrees of consistency in a shared data base. </title> <editor> In G.M. Nijssen, editor, </editor> <booktitle> Modeling in Data Base Management Systems. </booktitle> <publisher> North Holland, </publisher> <address> Amsterdam, </address> <year> 1976. </year>
Reference-contexts: It is appropriate for applications that cannot tolerate any inconsistency in their data, no matter how modest or short-lived. Examples include financial databases and medical records databases. 1-copy serializability is implemented using powerful concurrency control techniques such as two-phase locking <ref> [13] </ref> or timestamp ordering [2] in conjunction with a distributed commit protocol such as two-phase commit [22] or three-phase commit [21]. These protocols involve rounds of messages exchanged between all the sites of the distributed system.
Reference: 14. <author> J. Held and J. Carlis. </author> <title> Conceptual data modeling of an expert system. </title> <journal> IEEE Expert, </journal> <month> Spring </month> <year> 1989. </year>
Reference-contexts: Furthermore, our model must separate this common conception of the brain's structure from particular images of the brain. 2.3 Preliminary Design We assume that readers are familiar with data modeling using a logical data structure, or LDS <ref> [20, 9, 14, 1, 8] </ref>. The model in Figure 1 focuses on MRI and Confocal notions plus their "Connections." To save space we have not displayed some straightforward types of data, and have used acronyms liberally.
Reference: 15. <author> P. Kanellakis and C. Papadimitriou. </author> <title> The complexity of distributed concurrency control. </title> <journal> SIAM J. Comput., </journal> <volume> 14(1) </volume> <pages> 52-74, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: Strict consistency is not essential. Traditional distributed database systems maintain a consistency requirement called 1-copy serializability [3]. 1-copy serializability means that no user can observe even temporary inconsistencies caused by multiple users accessing and updating data on multiple replicas. 1-copy serializability is a theoretically <ref> [17, 15] </ref> and practically [7] well-understood consistency model. It is appropriate for applications that cannot tolerate any inconsistency in their data, no matter how modest or short-lived.
Reference: 16. <author> L. Lamport. </author> <title> Time, clocks, and the ordering of events in a distributed system. </title> <journal> Communications of the ACM, </journal> <volume> 21(7) </volume> <pages> 558-565, </pages> <month> July </month> <year> 1978. </year>
Reference-contexts: Each update operation consists of a globally-unique timestamp and a database identifier for the actual data. The timestamps reflect causal ordering: an update with a larger timestamp cannot have depended on an update with a smaller timestamp <ref> [16, 5] </ref>. Each replica contains an update table to keep track of which update operations it has performed. For example, Figure 2 includes replica A, with an update table. Timestamp 54 corresponds to the first Add operation, and timestamp 55 corresponds to the second Add operation.
Reference: 17. <author> C. Papadimitriou. </author> <title> The Theory of Database Concurrency Control. </title> <publisher> Computer Science Press, </publisher> <year> 1986. </year>
Reference-contexts: Strict consistency is not essential. Traditional distributed database systems maintain a consistency requirement called 1-copy serializability [3]. 1-copy serializability means that no user can observe even temporary inconsistencies caused by multiple users accessing and updating data on multiple replicas. 1-copy serializability is a theoretically <ref> [17, 15] </ref> and practically [7] well-understood consistency model. It is appropriate for applications that cannot tolerate any inconsistency in their data, no matter how modest or short-lived.
Reference: 18. <author> K. Ryan and J. Carlis. </author> <title> Automatic generation of representative query sets. </title> <booktitle> In Proceedings of the 1984 Trends and Applications Conference, N.B.S., </booktitle> <month> May </month> <year> 1984. </year>
Reference-contexts: There are four parts to our local zoomable database solution: 1. Data Model. We will modify our techniques of mapping an LDS to schema and access paths, as put forth in <ref> [10, 18, 9, 11] </ref>. 2. Chunks. To effectively and efficiently store and process the zoomable database, we will develop DBMS extensions to support transparent (to the program or human user) chunking of multi-dimensional data with several alternatives available for intra-chunk element order and with several alternative indexing schemes available.
Reference: 19. <author> S. Sarawagi and M. Stonebraker. </author> <title> Efficient organization of large multidimensional arrays. </title> <booktitle> In Proceedings of the International Conference on Data Engineering, </booktitle> <address> Hous-ton, TX, </address> <month> February </month> <year> 1994. </year>
Reference-contexts: To effectively and efficiently store and process the zoomable database, we will develop DBMS extensions to support transparent (to the program or human user) chunking of multi-dimensional data with several alternatives available for intra-chunk element order and with several alternative indexing schemes available. Chunks will be allowed to overlap <ref> [19] </ref>. 3. Commercial, extensible DBMS. We are now implementing our zoomable DBMS using the new Montage DBMS [24], [23]. 4. Tools. As we proceed with this project we will develop migration tools to convert neuroscience data that is in file format into a DBMS-loadable form.
Reference: 20. <author> M. Senko. </author> <title> Data Structures and Accessing in Data-Base Systems. </title> <institution> IBM Systems, </institution> <month> January </month> <year> 1973. </year>
Reference-contexts: Furthermore, our model must separate this common conception of the brain's structure from particular images of the brain. 2.3 Preliminary Design We assume that readers are familiar with data modeling using a logical data structure, or LDS <ref> [20, 9, 14, 1, 8] </ref>. The model in Figure 1 focuses on MRI and Confocal notions plus their "Connections." To save space we have not displayed some straightforward types of data, and have used acronyms liberally.
Reference: 21. <author> D. Skeen. </author> <title> Nonblocking commit protocols. </title> <booktitle> In Proceedings of the 1981 ACM-SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 133-142, </pages> <address> Ann Arbor, Michigan, </address> <year> 1981. </year>
Reference-contexts: Examples include financial databases and medical records databases. 1-copy serializability is implemented using powerful concurrency control techniques such as two-phase locking [13] or timestamp ordering [2] in conjunction with a distributed commit protocol such as two-phase commit [22] or three-phase commit <ref> [21] </ref>. These protocols involve rounds of messages exchanged between all the sites of the distributed system. During the time the messages are being exchanged, no access may be made to affected data. <p> During the time the messages are being exchanged, no access may be made to affected data. Further, even the best such protocols must sometimes block access to part of the database if computer or network failures occur during the commit process <ref> [21] </ref>. For these reasons, we look to explore less strict consistency rules for the neural database. 4. Most operations are insertions. The most common operation on the database is adding new information. The collaborative review process will delete data rejected on grounds of scientific merit.
Reference: 22. <author> D. Skeen and M. Stonebraker. </author> <title> A formal model of crash recovery in a distributed system. </title> <journal> IEEE Transaction on Software Engineering, </journal> <volume> SE-9(3):219-227, </volume> <month> May </month> <year> 1983. </year>
Reference-contexts: Examples include financial databases and medical records databases. 1-copy serializability is implemented using powerful concurrency control techniques such as two-phase locking [13] or timestamp ordering [2] in conjunction with a distributed commit protocol such as two-phase commit <ref> [22] </ref> or three-phase commit [21]. These protocols involve rounds of messages exchanged between all the sites of the distributed system. During the time the messages are being exchanged, no access may be made to affected data. <p> For example, in Figure 3 replica B is identical to replica A. However, authors may submit updates directly to the replicas, or replicas may receive updates from other replicas. As in Figure 3, a globally inconsistent state may develop <ref> [22] </ref>. Replicas A and B exchange update information. The entire update tables are exchanged. Because the updates do not include image data, this exchange is fast. Upon receiving the update table, each replica determines which updates it does not have using an efficient set difference algorithm.
Reference: 23. <author> Michael Stonebraker. </author> <title> An overview of the sequoia 2000 project. </title> <type> Sequoia 2000 Technical Report 91/5, </type> <institution> University of California, Berkeley, </institution> <address> CA, </address> <month> December </month> <year> 1991. </year>
Reference-contexts: Chunks will be allowed to overlap [19]. 3. Commercial, extensible DBMS. We are now implementing our zoomable DBMS using the new Montage DBMS [24], <ref> [23] </ref>. 4. Tools. As we proceed with this project we will develop migration tools to convert neuroscience data that is in file format into a DBMS-loadable form.
Reference: 24. <author> Michael Stonebraker, James Frew, and Jeff Dozier. </author> <title> The sequoia 2000 architecture and implementation strategy. </title> <type> Sequoia 2000 Technical Report 93/23, </type> <institution> University of California, Berkeley, </institution> <address> CA, </address> <month> April </month> <year> 1993. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: Chunks will be allowed to overlap [19]. 3. Commercial, extensible DBMS. We are now implementing our zoomable DBMS using the new Montage DBMS <ref> [24] </ref>, [23]. 4. Tools. As we proceed with this project we will develop migration tools to convert neuroscience data that is in file format into a DBMS-loadable form.
References-found: 24

