URL: http://ciir.cs.umass.edu/info/psfiles/irpubs/callan794.ps.gz
Refering-URL: http://ciir.cs.umass.edu/info/psfiles/irpubs/irnew.html
Root-URL: 
Email: callan@cs.umass.edu  
Title: Passage-Level Evidence in Document Retrieval  
Author: James P. Callan 
Note: To appear in Proceedings of the Seventeenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, July, 1994, Dublin, Ireland.  
Address: Amherst, MA 01003-4610, USA  
Affiliation: Computer Science Department, University of Massachusetts  
Abstract: The increasing lengths of documents in full-text collections encourages renewed interest in the ranking and retrieval of document passages. Past research showed that evidence from passages can improve retrieval results, but it also raised questions about how passages are defined, how they can be ranked efficiently, and what is their proper role in long, structured documents. This paper reports on experiments with passages in INQUERY, a probabilistic information retrieval system. Experiments were conducted with passages based on paragraphs, and with passages based on text windows of various sizes. Experimental results are given for three homogeneous and two heterogeneous document collections, ranging in size from three megabytes to two gigabytes. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> N. J. Belkin, C. Cool, W. B. Croft, and J. P. Callan. </author> <title> The effect of multiple query representations on information retrieval system performance. </title> <editor> In R. Korfhage, E. Rasmussen, and P. Willett, editors, </editor> <booktitle> Proceedings of the Sixteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 339-346, </pages> <address> Pittsburgh, PA, </address> <month> June </month> <year> 1993. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: Previous research showed that INQUERY's performance, as measured by precision and recall, generally improved with the amount of evidence available. This result held for collections of short documents [16], a collection of large documents [7], and a heterogeneous collection <ref> [1] </ref>. INQUERY's effectiveness at using multiple sources of evidence is consistent with the view of IR as a task of retrieving structured documents. Multiple sources of evidence can be obtained by applying a query to various levels of a document, or by applying different queries to different levels.
Reference: 2. <author> C. Buckley, J. Allan, and G. Salton. </author> <title> Automatic routing and ad-hoc retrieval using SMART: </title> <editor> TREC-2. In D. Harman, editor, </editor> <booktitle> Proceedings of the Second Text REtrieval Conference (TREC-2). </booktitle> <institution> National Institute of Standards and Technology Special Publication 500-215, </institution> <year> 1994. </year>
Reference-contexts: Discourse passages have been found to work well with highly structured and edited encyclopedia text [14; 13]. However, in experiments with the TIPSTER collection [8], which contains short, long, structured, and news summary documents, discourse passages sometimes worked well and sometimes did not <ref> [2; 10] </ref>. In spite of the intuitive appeal of passages, and in spite of the evidence in their favor, it remains unclear how important they are and how to use them effectively.
Reference: 3. <author> J. P. Callan and W. B. Croft. </author> <title> An evaluation of query processing strategies using the TIPSTER collection. </title> <editor> In R. Korfhage, E. Rasmussen, and P. Willett, editors, </editor> <booktitle> Proceedings of the Sixteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 347-356, </pages> <address> Pittsburgh, PA, </address> <month> June </month> <year> 1993. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: Finally, the issue of efficiently ranking passages is discussed briefly. The work described in this paper differs from earlier work with INQUERY in which "paragraph-level" constraints were expressed with a proximity operator <ref> [3; 5] </ref>. The advantages of that approach were its precision, efficiency, and simplicity. The disadvantage was the all-or-nothing nature of the operator, which restricted its use to simple constraints formed manually. <p> NPL collection. The passage size was 50 words. Recall Precision <ref> (93 queries) </ref> Document Window Combined (D) (W) (D+2flW) 10 57.5 61.1 (+6.3) 62.2 (+8.3) 30 39.0 39.7 (+1.6) 41.7 (+6.8) 50 25.2 26.4 (+4.9) 27.1 (+7.8) 70 13.4 14.6 (+9.0) 14.8 (+10.5) 90 6.3 6.5 (+3.2) 6.6 (+4.9) avg 29.5 30.4 (+3.3) 31.4 (+6.7) passage-level evidence yielded a 7.1% improvement.
Reference: 4. <author> J. P. Callan, W. B. Croft, and S. M. Harding. </author> <title> The INQUERY retrieval system. </title> <booktitle> In Proceedings of the Third International Conference on Database and Expert Systems Applications, </booktitle> <pages> pages 78-83, </pages> <address> Valencia, Spain, 1992. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: How to use this source of evidence, and how to use it efficiently, are nontrivial problems. This paper describes progress in adding passages to INQUERY, a probabilistic information retrieval system based upon a Bayesian inference network model <ref> [16; 4] </ref>. Two types of passages, discourse and window, are investigated. The issue of how best to use passage-level evidence, alone or in combination with document-level evidence, is also addressed. Finally, the issue of efficiently ranking passages is discussed briefly.
Reference: 5. <author> W. B. Croft, J. Callan, and J. Broglio. </author> <title> TREC-2 routing and ad-hoc retrieval evaluation using the INQUERY system. </title> <editor> In D. Harman, editor, </editor> <booktitle> Proceedings of the Second Text REtrieval Conference (TREC-2). </booktitle> <institution> National Institute of Standards and Technology Special Publication 500-215, </institution> <year> 1994. </year>
Reference-contexts: Finally, the issue of efficiently ranking passages is discussed briefly. The work described in this paper differs from earlier work with INQUERY in which "paragraph-level" constraints were expressed with a proximity operator <ref> [3; 5] </ref>. The advantages of that approach were its precision, efficiency, and simplicity. The disadvantage was the all-or-nothing nature of the operator, which restricted its use to simple constraints formed manually.
Reference: 6. <author> Cary Griffith. </author> <title> WESTLAW's winning ways. </title> <journal> Law Office Computing, </journal> <pages> pages 31-38, </pages> <month> February/March </month> <year> 1993. </year>
Reference-contexts: Whether this feature is necessary or merely helpful was unclear from research using short and medium length documents. Recent work using long documents with complex internal structure suggests that passage-level evidence is an important part of document retrieval <ref> [14; 13; 15; 10; 6] </ref>. Long documents, documents with complex structure, and even short documents summarizing many subjects, are a challenge for algorithms that do not distinguish where in a document the text matches a query.
Reference: 7. <author> David Haines and W. B. Croft. </author> <title> Relevance feedback and inference networks. </title> <editor> In R. Korfhage, E. Ras--mussen, and P. Willett, editors, </editor> <booktitle> Proceedings of the Sixteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 2-11, </pages> <address> Pittsburgh, PA, </address> <month> June </month> <year> 1993. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: Previous research showed that INQUERY's performance, as measured by precision and recall, generally improved with the amount of evidence available. This result held for collections of short documents [16], a collection of large documents <ref> [7] </ref>, and a heterogeneous collection [1]. INQUERY's effectiveness at using multiple sources of evidence is consistent with the view of IR as a task of retrieving structured documents.
Reference: 8. <author> D. Harman. </author> <title> The DARPA Tipster project. </title> <journal> SIGIR Forum, </journal> <volume> 26(2) </volume> <pages> 26-28, </pages> <year> 1992. </year>
Reference-contexts: If writers are sloppy or rushed, or if discourse boundaries are introduced for visual presentation, then dividing documents by textual discourse boundaries may be inappropriate. Discourse passages have been found to work well with highly structured and edited encyclopedia text [14; 13]. However, in experiments with the TIPSTER collection <ref> [8] </ref>, which contains short, long, structured, and news summary documents, discourse passages sometimes worked well and sometimes did not [2; 10].
Reference: 9. <author> M. A. Hearst and C. Plaunt. </author> <title> Subtopic structuring for full-length document access. </title> <editor> In R. Korfhage, E. Rasmussen, and P. Willett, editors, </editor> <booktitle> Proceedings of the Sixteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 59-68, </pages> <address> Pittsburgh, PA, </address> <month> June </month> <year> 1993. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: One can view information retrieval as a task of retrieving passages instead of documents [11]. During indexing, a document is divided into passages, perhaps with links maintained between its components, and each passage is stored as if it were a distinct entity <ref> [10; 9] </ref>. This approach has the advantage of simplicity, because no new algorithms are necessary. However, it creates a problem of how to recognize a small portion of relevant text that spans two passages [15]. <p> The types of passages explored by researchers can be grouped into three classes: discourse, semantic, and window. Discourse passages are based upon textual discourse units (e.g. sentences, paragraphs and sections). Semantic passages are based upon the subject or content of the text (e.g. TextTiling <ref> [9] </ref>). Window passages are based upon a number of words. One might expect discourse passages to be the most effective, because discourse boundaries organize material by content. However, discourse passages also require more consistency from writers than do semantic or window passages. <p> No extra memory is required. Preliminary experiments suggested that the best results could be obtained by recording only the contribution provided by a document's best passage. Others have found that adding the scores of several passages is effective <ref> [9; 17] </ref>, but that was not the case in our experiments. Ignorance of how best to divide documents into passages discouraged the use of special indices. Instead, experiments were conducted by reading the usual document-level indices and dividing documents into passages "on-the-fly" during retrieval. <p> One possibility is that the length-based criteria used for merging and dividing paragraphs produced passages that did not sufficiently organize text by content. An approach to reconstructing paragraphs based on semantic considerations (e.g. TextTiling <ref> [9] </ref>) might yield better results. 2.3 Window Passages Discourse and semantic passages are based on the assumption that there is a single "good" organization of the information in a document. The difference between the two approaches is whether the writer is trusted to reveal that organization. <p> NPL collection. The passage size was 50 words. Recall Precision <ref> (93 queries) </ref> Document Window Combined (D) (W) (D+2flW) 10 57.5 61.1 (+6.3) 62.2 (+8.3) 30 39.0 39.7 (+1.6) 41.7 (+6.8) 50 25.2 26.4 (+4.9) 27.1 (+7.8) 70 13.4 14.6 (+9.0) 14.8 (+10.5) 90 6.3 6.5 (+3.2) 6.6 (+4.9) avg 29.5 30.4 (+3.3) 31.4 (+6.7) passage-level evidence yielded a 7.1% improvement.
Reference: 10. <author> A. Moffat, R. Sacks-Davis, R. Wilkinson, and J. Zobel. </author> <title> Retrieval of partial documents. </title> <editor> In D. Har-man, editor, </editor> <booktitle> Proceedings of the Second Text REtrieval Conference (TREC-2). </booktitle> <institution> National Institute of Standards and Technology Special Publication 500-215, </institution> <year> 1994. </year>
Reference-contexts: Whether this feature is necessary or merely helpful was unclear from research using short and medium length documents. Recent work using long documents with complex internal structure suggests that passage-level evidence is an important part of document retrieval <ref> [14; 13; 15; 10; 6] </ref>. Long documents, documents with complex structure, and even short documents summarizing many subjects, are a challenge for algorithms that do not distinguish where in a document the text matches a query. <p> One can view information retrieval as a task of retrieving passages instead of documents [11]. During indexing, a document is divided into passages, perhaps with links maintained between its components, and each passage is stored as if it were a distinct entity <ref> [10; 9] </ref>. This approach has the advantage of simplicity, because no new algorithms are necessary. However, it creates a problem of how to recognize a small portion of relevant text that spans two passages [15]. <p> It may also be unsuitable for very long queries, because chances are lower that short passages can match many of the query terms. Information retrieval can also be viewed as a task of retrieving documents that have a hierarchical internal structure <ref> [14; 10] </ref>. For example, documents may contain sections, paragraphs and sentences. Each element of the document structure is a source of evidence that can be used in retrieval. Document-level matches are global evidence, while sentence-level matches are very local. <p> Discourse passages have been found to work well with highly structured and edited encyclopedia text [14; 13]. However, in experiments with the TIPSTER collection [8], which contains short, long, structured, and news summary documents, discourse passages sometimes worked well and sometimes did not <ref> [2; 10] </ref>. In spite of the intuitive appeal of passages, and in spite of the evidence in their favor, it remains unclear how important they are and how to use them effectively.
Reference: 11. <author> J. O'Connor. </author> <title> Answer-passage retrieval by text searching. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 31(4) </volume> <pages> 227-239, </pages> <year> 1980. </year>
Reference-contexts: 1 Introduction It is sometimes better to apply retrieval algorithms to portions of a document text than to all of the text. If each portion of text, or passage, is ranked, an interface can quickly direct a user to the relevant information in a document <ref> [11; 12] </ref>. Whether this feature is necessary or merely helpful was unclear from research using short and medium length documents. Recent work using long documents with complex internal structure suggests that passage-level evidence is an important part of document retrieval [14; 13; 15; 10; 6]. <p> If the algorithm cannot distinguish a few matches scattered across a document from a dense region of matches, it may have difficulty retrieving long documents and newswire "news summaries". One can view information retrieval as a task of retrieving passages instead of documents <ref> [11] </ref>. During indexing, a document is divided into passages, perhaps with links maintained between its components, and each passage is stored as if it were a distinct entity [10; 9]. This approach has the advantage of simplicity, because no new algorithms are necessary.
Reference: 12. <author> J. S. Ro. </author> <title> An evaluation of the applicability of ranking algorithms to improve the effectiveness of full-text retrieval. I. On the effectiveness of full-text retrieval. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 39(2) </volume> <pages> 73-78, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction It is sometimes better to apply retrieval algorithms to portions of a document text than to all of the text. If each portion of text, or passage, is ranked, an interface can quickly direct a user to the relevant information in a document <ref> [11; 12] </ref>. Whether this feature is necessary or merely helpful was unclear from research using short and medium length documents. Recent work using long documents with complex internal structure suggests that passage-level evidence is an important part of document retrieval [14; 13; 15; 10; 6].
Reference: 13. <author> G. Salton, J. Allan, and C. Buckley. </author> <title> Approaches to passage retrieval in full text information systems. </title> <editor> In R. Korfhage, E. Rasmussen, and P. Willett, editors, </editor> <booktitle> Proceedings of the Sixteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <address> Pittsburgh, PA, </address> <month> June </month> <year> 1993. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: Whether this feature is necessary or merely helpful was unclear from research using short and medium length documents. Recent work using long documents with complex internal structure suggests that passage-level evidence is an important part of document retrieval <ref> [14; 13; 15; 10; 6] </ref>. Long documents, documents with complex structure, and even short documents summarizing many subjects, are a challenge for algorithms that do not distinguish where in a document the text matches a query. <p> If writers are sloppy or rushed, or if discourse boundaries are introduced for visual presentation, then dividing documents by textual discourse boundaries may be inappropriate. Discourse passages have been found to work well with highly structured and edited encyclopedia text <ref> [14; 13] </ref>. However, in experiments with the TIPSTER collection [8], which contains short, long, structured, and news summary documents, discourse passages sometimes worked well and sometimes did not [2; 10].
Reference: 14. <author> G. Salton and C. Buckley. </author> <title> Automatic text structuring and retrieval Experiments in automatic enclopedia searching. </title> <editor> In A. Bookstein, Y. Chiaramella, G. Salton, and V. V. Raghavan, editors, </editor> <booktitle> Proceedings of the Fourteenth Annual International ACM/SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <address> Chicago, IL, </address> <month> October </month> <year> 1991. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: Whether this feature is necessary or merely helpful was unclear from research using short and medium length documents. Recent work using long documents with complex internal structure suggests that passage-level evidence is an important part of document retrieval <ref> [14; 13; 15; 10; 6] </ref>. Long documents, documents with complex structure, and even short documents summarizing many subjects, are a challenge for algorithms that do not distinguish where in a document the text matches a query. <p> It may also be unsuitable for very long queries, because chances are lower that short passages can match many of the query terms. Information retrieval can also be viewed as a task of retrieving documents that have a hierarchical internal structure <ref> [14; 10] </ref>. For example, documents may contain sections, paragraphs and sentences. Each element of the document structure is a source of evidence that can be used in retrieval. Document-level matches are global evidence, while sentence-level matches are very local. <p> Each element of the document structure is a source of evidence that can be used in retrieval. Document-level matches are global evidence, while sentence-level matches are very local. Combining evidence from different levels of a document's structure may provide more accurate retrieval than will evidence from any single level <ref> [14] </ref>. The types of passages explored by researchers can be grouped into three classes: discourse, semantic, and window. Discourse passages are based upon textual discourse units (e.g. sentences, paragraphs and sections). Semantic passages are based upon the subject or content of the text (e.g. TextTiling [9]). <p> If writers are sloppy or rushed, or if discourse boundaries are introduced for visual presentation, then dividing documents by textual discourse boundaries may be inappropriate. Discourse passages have been found to work well with highly structured and edited encyclopedia text <ref> [14; 13] </ref>. However, in experiments with the TIPSTER collection [8], which contains short, long, structured, and news summary documents, discourse passages sometimes worked well and sometimes did not [2; 10]. <p> The cost of ranking passages for 50 queries on TIPSTER volume 1 is about 25% higher than the cost of ranking documents. One can avoid ranking every passage by ranking every document and then ranking passages for only those documents that exceed some threshold <ref> [14] </ref>. However, this technique runs the risk of missing a highly relevant passage in a long, mostly irrelevant document. One might expect this problem to become more serious as document length increases.
Reference: 15. <author> C. Stanfill and D. L. Waltz. </author> <title> Statistical methods, </title> <booktitle> Artificial Intelligence, and Information Retrieval. </booktitle> <editor> In P. S. Jacobs, editor, </editor> <booktitle> Text-based intelligent systems, </booktitle> <pages> pages 215-225. </pages> <publisher> Lawrence Erlbaum, </publisher> <year> 1992. </year>
Reference-contexts: Whether this feature is necessary or merely helpful was unclear from research using short and medium length documents. Recent work using long documents with complex internal structure suggests that passage-level evidence is an important part of document retrieval <ref> [14; 13; 15; 10; 6] </ref>. Long documents, documents with complex structure, and even short documents summarizing many subjects, are a challenge for algorithms that do not distinguish where in a document the text matches a query. <p> This approach has the advantage of simplicity, because no new algorithms are necessary. However, it creates a problem of how to recognize a small portion of relevant text that spans two passages <ref> [15] </ref>. It may also be unsuitable for very long queries, because chances are lower that short passages can match many of the query terms. Information retrieval can also be viewed as a task of retrieving documents that have a hierarchical internal structure [14; 10]. <p> The use of overlapping passages reduces the chance that a small block of relevant text is split among two passages; it is similar in spirit to passage blurring <ref> [15] </ref>. If passage locations vary from query to query, then the formulae used to determine the evidence contributed by a term t to a document d cannot be used directly for passages.
Reference: 16. <author> H. R. Turtle and W. B. Croft. </author> <title> Evaluation of an inference network-based retrieval model. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 9(3) </volume> <pages> 187-222, </pages> <year> 1991. </year>
Reference-contexts: How to use this source of evidence, and how to use it efficiently, are nontrivial problems. This paper describes progress in adding passages to INQUERY, a probabilistic information retrieval system based upon a Bayesian inference network model <ref> [16; 4] </ref>. Two types of passages, discourse and window, are investigated. The issue of how best to use passage-level evidence, alone or in combination with document-level evidence, is also addressed. Finally, the issue of efficiently ranking passages is discussed briefly. <p> Previous research showed that INQUERY's performance, as measured by precision and recall, generally improved with the amount of evidence available. This result held for collections of short documents <ref> [16] </ref>, a collection of large documents [7], and a heterogeneous collection [1]. INQUERY's effectiveness at using multiple sources of evidence is consistent with the view of IR as a task of retrieving structured documents.
Reference: 17. <author> R. Wilkinson. </author> <title> Effective retrieval of structured documents. </title> <booktitle> In Proceedings of the Seventeenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <address> Dublin, Ireland, </address> <month> July </month> <year> 1994. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: No extra memory is required. Preliminary experiments suggested that the best results could be obtained by recording only the contribution provided by a document's best passage. Others have found that adding the scores of several passages is effective <ref> [9; 17] </ref>, but that was not the case in our experiments. Ignorance of how best to divide documents into passages discouraged the use of special indices. Instead, experiments were conducted by reading the usual document-level indices and dividing documents into passages "on-the-fly" during retrieval.
Reference: 18. <author> P. Willett. </author> <title> A nearest neighbor search algorithm for bibliographic retrieval from multilist files. </title> <journal> Information Technology, </journal> <volume> 3(2) </volume> <pages> 78-83, </pages> <year> 1984. </year>
Reference-contexts: Treating passages like documents would require at least an order of magnitude more memory. 2 INQUERY now reads inverted lists in blocks, in parallel, computing a complete score for one document before proceeding to the next. This approach is known to slow I/O <ref> [18] </ref>, but scales well, and enables optimizations that are impossible with the previous "term at a time" approach. Several commercial IR vendors also use this technique. 3 The window-based approach to passages described above requires that a document be divided into passages after the query is available.
References-found: 18

