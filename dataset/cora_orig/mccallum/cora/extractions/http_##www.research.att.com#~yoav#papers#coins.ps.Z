URL: http://www.research.att.com/~yoav/papers/coins.ps.Z
Refering-URL: http://www.research.att.com/~yoav/publications.html
Root-URL: 
Title: Learning to model sequences generated by switching distributions  
Author: Yoav Freund Dana Ron 
Address: 600 Mountain Ave. Murray Hill, NJ, USA  Jerusalem, Israel  
Affiliation: AT&T Bell Labs  Computer Science Institute. Hebrew University  
Abstract: We study efficient algorithms for solving the following problem, which we call the switching distributions learning problem. A sequence S = 1 2 : : : n , over a finite alphabet S is generated in the following way. The sequence is a concatenation of K runs, each of which is a consecutive subsequence. Each run is generated by independent random draws from a distribution ~p i over S, where ~p i is an element in a set of distributions f~p 1 ; : : : ; ~p N g. The learning algorithm is given this sequence and its goal is to find approximations of the distributions ~p 1 ; : : : ; ~p N , and give an approximate segmentation of the sequence into its constituting runs. We give an efficient algorithm for solving this problem and show conditions under which the algorithm is guaranteed to work with high probability.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Abe and M. K. Warmuth. </author> <title> On the computational complexity of approximating distributions by probabilistic automata. </title> <journal> Machine Learning, </journal> <volume> 9(2/3), </volume> <year> 1992. </year> <note> Special issue for COLT90. </note>
Reference-contexts: The theoretical results regarding the problem of learning HMMs of which we are aware are mostly negative, Abe and Warmuth <ref> [1] </ref> and Gill-man and Sipser [5] show that learning HMMs is NP-hard under various conditions. The model of sequences that we consider is similar to the HMM with the restriction that the transition probabilities assign a high probability to the transition from each hidden state to itself. <p> For j 2 <ref> [1; : : : ; N ] </ref> set p t+1 j to the empirical distribution of the elements of S for which t (i) = j. 3. Output the segmentation T 1 , and the distributions p T 1 ; : : : ; p T by a single distribution. <p> We shall show that this threshold need not depend on the approximation parameter *, but rather is of the order of the smallest distance between any pair of target distributions. 4 Summary of Results Before we present our results, we add the following notation. For j 2 <ref> [1; : : : ; N ] </ref>, we use n j to denote the number of elements in S corresponding to the distribution ~p j , and define fl = min j (n j )=M . <p> D 1 =2, the length M of the sequence S satisfies M ffi ) ; then with probability at least 1 ffi, there exists a one-to-one mapping : f1; 2g ! f1; 2g such that for j 2 f1; 2g, k p 0 Proof: For a given index i 2 <ref> [1; : : : ; M ` + 1] </ref>, let S i;i+`1 = i : : : i+`1 , and let ff i be such that the fraction of symbols in S i;i+l1 that were generated by ~p 1 and ~p 2 are (1 ff i ) and ff i respectively. <p> Set ` = flM=K. (If L, the minimum length of any run in S, is known, set ` = max (flM=K; L)). 2. For each i 2 <ref> [1; : : : ; M ` + 1] </ref> and each 2 [1; : : : ; D], let f i () be the fraction of the elements in i i+1 : : : i+`1 which are equal to . <p> Set ` = flM=K. (If L, the minimum length of any run in S, is known, set ` = max (flM=K; L)). 2. For each i 2 [1; : : : ; M ` + 1] and each 2 <ref> [1; : : : ; D] </ref>, let f i () be the fraction of the elements in i i+1 : : : i+`1 which are equal to . Let ~ f i denote the vector hf i (1); f i (2); : : : ; f i (D)i. 3. <p> In the third lemma we show that if the segmentation t has a small number of errors, then good new estimates of ~p 1 and ~p 2 can be computed using t . Lemma 10 (Reevaluation error for two distributions) Suppose : <ref> [1; : : : ; N ] </ref> ! [1; : : : ; N ] is a one to one mapping such that fi = max (n 1;(2) ( t ); n 2;(1) ( t ))=M ; and fi &lt; fl. <p> Lemma 10 (Reevaluation error for two distributions) Suppose : <ref> [1; : : : ; N ] </ref> ! [1; : : : ; N ] is a one to one mapping such that fi = max (n 1;(2) ( t ); n 2;(1) ( t ))=M ; and fi &lt; fl. <p> Thus step 4 generates a set of distributions with one representative per target distribution, as required in the statement of the lemma. Lemma 12 (Segmentation error for general N ) Let = min max k p t where ranges over all one-to-one mappings from <ref> [1; : : :; N ] </ref> to [1; : : : ; N ]. Assume that is the mapping that achieves the minimum. <p> Lemma 12 (Segmentation error for general N ) Let = min max k p t where ranges over all one-to-one mappings from [1; : : :; N ] to <ref> [1; : : : ; N ] </ref>. Assume that is the mapping that achieves the minimum. <p> Set ` = 1 2. Set = 2 2 (ln M+D ln (`+1)+ln 1 ` . 3. For each i 2 1 : : : M ` + 1 and each 2 <ref> [1; : : : ; D] </ref>, let f i () be the fraction of the elements in i ; i+1 ; : : : ; i+`1 which are equal to . <p> The cost difference is a sum of the cost differences in the places where the segmentations disagree. These are independent random variables. It is easy to check that the coordinates of any cost vector are bounded in the range <ref> [0; 1] </ref> and thus the cost difference is bounded in [1; 1]. <p> The cost difference is a sum of the cost differences in the places where the segmentations disagree. These are independent random variables. It is easy to check that the coordinates of any cost vector are bounded in the range [0; 1] and thus the cost difference is bounded in <ref> [1; 1] </ref>. <p> Combining this with the last equation we get the statement of the lemma. Lemma 13 (Reevaluation error for general N ) Suppose : <ref> [1; : : : ; N ] </ref> ! [1; : : : ; N ] is a one to one mapping such that fi = M If fi &lt; fl, then with probability at least 1 ffi, there exists a one-to-one mapping : [1; : : : ; N ] ! <p> Combining this with the last equation we get the statement of the lemma. Lemma 13 (Reevaluation error for general N ) Suppose : <ref> [1; : : : ; N ] </ref> ! [1; : : : ; N ] is a one to one mapping such that fi = M If fi &lt; fl, then with probability at least 1 ffi, there exists a one-to-one mapping : [1; : : : ; N ] ! [1; : : : ; N ], such <p> error for general N ) Suppose : <ref> [1; : : : ; N ] </ref> ! [1; : : : ; N ] is a one to one mapping such that fi = M If fi &lt; fl, then with probability at least 1 ffi, there exists a one-to-one mapping : [1; : : : ; N ] ! [1; : : : ; N ], such that for every j 2 [1; : : : ; N ] k p t+1 fi D 2 + var ; where var = 2 (K ln (N M ) + D ln (M + <p> : : : ; N ] ! <ref> [1; : : : ; N ] </ref> is a one to one mapping such that fi = M If fi &lt; fl, then with probability at least 1 ffi, there exists a one-to-one mapping : [1; : : : ; N ] ! [1; : : : ; N ], such that for every j 2 [1; : : : ; N ] k p t+1 fi D 2 + var ; where var = 2 (K ln (N M ) + D ln (M + 1) + ln (1=ffi) : The Proof of <p> ] is a one to one mapping such that fi = M If fi &lt; fl, then with probability at least 1 ffi, there exists a one-to-one mapping : <ref> [1; : : : ; N ] </ref> ! [1; : : : ; N ], such that for every j 2 [1; : : : ; N ] k p t+1 fi D 2 + var ; where var = 2 (K ln (N M ) + D ln (M + 1) + ln (1=ffi) : The Proof of Lemma 13 is the same as the proof of Lemma 10 except for <p> Where A is a constant independent of the hypothesis. The range of all of the c (i)'s is <ref> [0; 1] </ref> and they are independent random variables.
Reference: [2] <author> Leonard E. Baum and J. A. Eagon. </author> <title> An inequality with applications to statistical estimation for probabilistic functions of markov processes and to a model for ecology. </title> <journal> Bulletin of the American Mathematical Society, </journal> <volume> 73 </volume> <pages> 360-363, </pages> <year> 1967. </year>
Reference-contexts: COLT95 Santa Cruz, USA c fl1995 ACM 0-89723-5/95/0007. The Baum-Welch algorithm <ref> [2] </ref> is the predominant algorithm for learning HMMs from examples and produces. In many real-world cases, this algorithm produces accurate hypotheses after a small number of iterations. 1 There is almost no theory for explaining why Baum-Welch performs so well in some cases and badly in others.
Reference: [3] <author> Avrim Blum and Prasad Chalasani. </author> <title> Learning switching concepts. </title> <booktitle> In Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, </booktitle> <pages> pages 231-242, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: This problem is related to the problem of learning switching concepts studied by Blum and Chalasani <ref> [3] </ref>. However, in their setup the switching entities are concepts, i.e., mappings from some domain to f0; 1g, while in our setup the switching entities are distributions over a single space. In this work we give an efficient algorithm for learning switching distributions.
Reference: [4] <author> Thomas M. Cover and Joy A. Thomas. </author> <title> Elements of Information Theory. </title> <publisher> Wiley, </publisher> <year> 1991. </year>
Reference: [5] <author> David Gillman and Michael Sipser. </author> <title> Inference and minimization of hidden markov chains. </title> <booktitle> In Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, </booktitle> <pages> pages 147-158, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: The theoretical results regarding the problem of learning HMMs of which we are aware are mostly negative, Abe and Warmuth [1] and Gill-man and Sipser <ref> [5] </ref> show that learning HMMs is NP-hard under various conditions. The model of sequences that we consider is similar to the HMM with the restriction that the transition probabilities assign a high probability to the transition from each hidden state to itself.
Reference: [6] <author> Nick Littlestone. </author> <title> Notes on the derivation of chernoff-type bounds for sums of random variables. </title> <type> Unpublished Manuscript, </type> <year> 1990. </year>
Reference-contexts: Our analysis does not support such a claim, and we shall later discuss this question briefly. 5 Useful Inequalities In the proofs of our theorems and lemmas we apply several well known inequalities that are given here as lemmas. The first is a Chernoff/Hoeffding type bound, derived by Little-stone <ref> [6] </ref>, and the second is due to Sanov ([4],page 292). Lemma 5 For m &gt; 0, let X 1 ; X 2 ; :::X m be m independent random variables where a i X i b i . Let p = P i E [X i ]=m.
Reference: [7] <author> L. R. Rabiner and B. H. Juang. </author> <title> An introduction to hidden markov models. </title> <journal> IEEE ASSP Magazine, </journal> <volume> 3(1) </volume> <pages> 4-16, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: The learner receives a single sequence S of length M , that is generated by the target, and its goal is 1 For an introduction on HMMs and their use in speech analysis and the use of Hidden Markov Model see Rabiner and Juang <ref> [7] </ref>. to generate a hypothesis segmentation and a set of hypothesis distributions which are close to those of the target. This problem is related to the problem of learning switching concepts studied by Blum and Chalasani [3].
Reference: [8] <author> A.J. </author> <title> Viterbi. Error bounds for convulutional codes and an asymptotically optimal decoding algorithm. </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> 13 </volume> <pages> 260-269, </pages> <year> 1967. </year>
Reference-contexts: Finding the segmentation with at most K runs that minimizes the total cost for a given set of cost vectors can be performed in time O (log (K)M 3 ) using a dynamic programming technique, which is essentially the same as the well known Viterbi algorithm <ref> [8] </ref>. The cost vectors are chosen so that with high probability the segmentation with the lowest total cost does not differ significantly from the target segmentation.
References-found: 8

