URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-91-1046/CS-TR-91-1046.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-91-1046/
Root-URL: http://www.cs.wisc.edu
Title: Optimal Tilings for Parallel Database Design  
Author: Jonathan Yackel Robert R. Meyer 
Abstract: The computing time benefits of parallelism in database systems (achieved by using multiple processors to execute a query) must be weighed against communication, startup, and termination overhead costs that increase as a function of the number of processors used. We consider problems of allocating data among the processors so as to optimize the execution time for certain type of queries. We present lower bounds for these combinatorial problems and demonstrate how processors may be optimally assigned by "tiling" the partitioned data grid with optimal configurations.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Boral, W. Alexander, L. Clay, G. Copeland, S. Danforth, M. Franklin, B. Hart, M. Smith, and P. Valduriez, </author> <title> Prototyping Bubba, a highly parallel database system, </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2 (1990), </volume> <pages> pp. 4-21. </pages>
Reference-contexts: 1 Introduction In highly-parallel database machines (e.g., Gamma [2], Bubba <ref> [1] </ref>, Non-Stop SQL [11], XPRS [10] and Volcano [6]) relations are "partitioned" (see Livny et al [8] and Ries and Epstein [9] for early partitioning strategies) across multiple processors.
Reference: [2] <author> D. DeWitt, S. Ghandeharizadeh, D. Schneider, A. Bricker, H. Hsiao, and R. Rasmussen, </author> <title> The Gamma database machine project, </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2 (1990), </volume> <pages> pp. 44-63. </pages>
Reference-contexts: 1 Introduction In highly-parallel database machines (e.g., Gamma <ref> [2] </ref>, Bubba [1], Non-Stop SQL [11], XPRS [10] and Volcano [6]) relations are "partitioned" (see Livny et al [8] and Ries and Epstein [9] for early partitioning strategies) across multiple processors. <p> Science Foundation under grants CCR-8907671 and DCR-8512862. y Center for Parallel Optimization, Computer Sciences Department, University of Wisconsin, Madison, Wisconsin 53706. 1 a query. (This overhead is primarily in the form of additional messages to control the execution of the query on additional processors and, in the Gamma database machine <ref> [2] </ref>, increases linearly with the number of employed processors.) In order to balance the workload among the processors, Multi-Attribute GrId deClustering (MAGIC), as introduced by Ghandeharizadeh [3], partitions a relation by assigning ranges of several attribute values to each processor in the system. <p> In section 3, we develop lower bounds on the optimal value. Section 4 develops optimal configurations of cells for individual processors, and section 5 provides combinations of these configurations producing optimal assignments 1 The Gamma database machine results presented in <ref> [2] </ref> justify this assertion. 2 that attain the lower bounds.
Reference: [3] <author> S. Ghandeharizadeh, </author> <title> Physical Database Design in Multiprocessor Systems, </title> <type> PhD thesis, </type> <institution> Computer Sciences Department, University of Wisconsin - Madison, </institution> <year> 1990. </year>
Reference-contexts: is primarily in the form of additional messages to control the execution of the query on additional processors and, in the Gamma database machine [2], increases linearly with the number of employed processors.) In order to balance the workload among the processors, Multi-Attribute GrId deClustering (MAGIC), as introduced by Ghandeharizadeh <ref> [3] </ref>, partitions a relation by assigning ranges of several attribute values to each processor in the system. To illustrate MAGIC consider the partitioning of the Employee relation EMP in figure 1.
Reference: [4] <author> S. Ghandeharizadeh, L. Ramos, Z. Asad, and W. Qureshi, </author> <title> Object placement in parallel hypermedia systems, </title> <booktitle> in Proceedings of the 1991 Very Large Data Bases Conference, </booktitle> <address> Barcelona, Spain, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: In addition, we would like to deal with more general objective functions and load balancing constraints as presented in Ghande-harizadeh et al [5]. Finally, it would be interesting to consider other applications that fit into the task assignment/parallel computing framework developed here (see, e.g., Ghandeharizadeh et al <ref> [4] </ref>).
Reference: [5] <author> S. Ghandeharizadeh, G. L. Schultz, R. R. Meyer, and J. Yackel, </author> <title> Optimal balanced assignments and a parallel database application, </title> <type> Computer Sciences Technical Report 986, </type> <institution> University of Wisconsin - Madison, Madison, WI, </institution> <month> Decem-ber </month> <year> 1990. </year>
Reference-contexts: On the other hand if (3) does not hold, then by theorem 3 there is a configuration of L cells with a smaller D-perimeter. In section 3 of Ghandeharizadeh et al <ref> [5] </ref>, we derived an alternate bound on P: P D L 1=D : This expression is equivalent to P fl (L) and therefore is the best possible lower bound when D = 2, but for higher dimensions (D 3), P fl (L) provides a better lower bound than for some values <p> In this section we exhibit classes of grids for which assignments which minimize various objective functions can be constructed by such tilings. Conditions under which assignments that minimize total also minimize max and other objective functions are also developed. These results generalize optimal assignments developed in Ghandeharizadeh et al <ref> [5] </ref>. 5.1 Optimal Tilings for total One class of problems for which the minimum-perimeter results of section 3 yield optimal solutions are instances in which the grid can be tiled with hyper-rectangular blocks that are perimeter-optimal for each processor. <p> We have developed an algorithm that constructs optimal assignments for such problem instances <ref> [5] </ref>. Figure 5 (a) shows the assignment produced by our algorithm when N = 7. Note that for any processor the slices in figure 5 (a) may be permuted so that the set of cells occupied has the following optimal configuration: . <p> Besides the above N fi N grid case, other tilings which are optimal for both max and total can be developed. In Ghandeharizadeh et al <ref> [5] </ref>, we showed that max achieves its lower bound for D dimensions if the grid can be tiled with hyper-rectangles whose proportions are the same as the proportions of the grid (i.e., there are N 1=D subdivisions along each dimension). <p> In fact, lemma 8 shows that any tiling by perimeter-optimal configurations that results in the same chromatic index for each slice must be optimal for both max and total . This observation also generalizes the N fiN grid result of Ghandeharizadeh et al <ref> [5] </ref> (illustrated by Figure 5). A second case in which both objective functions can be simultaneously minimized is when the grid can be tiled by perimeter-optimal configurations so that i slices have a chromatic index of k and the other j have an index of k 1. <p> We also have a nonconvex nonlinear programming formulation of the problem that suggests other solution techniques. In addition, we would like to deal with more general objective functions and load balancing constraints as presented in Ghande-harizadeh et al <ref> [5] </ref>. Finally, it would be interesting to consider other applications that fit into the task assignment/parallel computing framework developed here (see, e.g., Ghandeharizadeh et al [4]).
Reference: [6] <author> G. Graefe, Volcano: </author> <title> An extensible and parallel dataflow query processing system, </title> <institution> computer science technical report, Oregon Graduate Center, Beaverton, </institution> <address> OR, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: 1 Introduction In highly-parallel database machines (e.g., Gamma [2], Bubba [1], Non-Stop SQL [11], XPRS [10] and Volcano <ref> [6] </ref>) relations are "partitioned" (see Livny et al [8] and Ries and Epstein [9] for early partitioning strategies) across multiple processors. This allows each processor to execute a portion of a query in parallel with the other processors, resulting in a lower response time for the query.
Reference: [7] <author> P. Helman, </author> <title> A family of NP-complete data aggregation problems, </title> <journal> Acta Informat-ica, </journal> <volume> 26 (1989), </volume> <pages> pp. 485-499. 16 </pages>
Reference-contexts: For example, given a 5 fi 5 grid, 5 processors, and a load of 5 for each processor, there are more than 623 fi 10 12 assignments that satisfy the balancing constraint. A similar class of data aggregation problems was studied by Helman <ref> [7] </ref>.
Reference: [8] <author> M. Livny, S. Khoshafian, and H. Boral, </author> <title> Multi-disk management algo-rithms, </title> <booktitle> in Proceedings of the 1987 ACM SIGMETRICS Int'l Conf. on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1987. </year>
Reference-contexts: 1 Introduction In highly-parallel database machines (e.g., Gamma [2], Bubba [1], Non-Stop SQL [11], XPRS [10] and Volcano [6]) relations are "partitioned" (see Livny et al <ref> [8] </ref> and Ries and Epstein [9] for early partitioning strategies) across multiple processors. This allows each processor to execute a portion of a query in parallel with the other processors, resulting in a lower response time for the query.
Reference: [9] <author> D. Ries and R. Epstein, </author> <title> Evaluation of distribution criteria for distributed database systems, </title> <type> UCB/ERL Technical Report M78/22, </type> <institution> UC Berkeley, </institution> <month> May </month> <year> 1987. </year>
Reference-contexts: 1 Introduction In highly-parallel database machines (e.g., Gamma [2], Bubba [1], Non-Stop SQL [11], XPRS [10] and Volcano [6]) relations are "partitioned" (see Livny et al [8] and Ries and Epstein <ref> [9] </ref> for early partitioning strategies) across multiple processors. This allows each processor to execute a portion of a query in parallel with the other processors, resulting in a lower response time for the query.
Reference: [10] <author> M. Stonebraker, D. Patterson, and J. Ousterhout, </author> <booktitle> The design of XPRS, in Proceedings of the 1988 Very Large Data Bases Conference, </booktitle> <address> Los Angeles, CA, </address> <month> September </month> <year> 1988. </year>
Reference-contexts: 1 Introduction In highly-parallel database machines (e.g., Gamma [2], Bubba [1], Non-Stop SQL [11], XPRS <ref> [10] </ref> and Volcano [6]) relations are "partitioned" (see Livny et al [8] and Ries and Epstein [9] for early partitioning strategies) across multiple processors. This allows each processor to execute a portion of a query in parallel with the other processors, resulting in a lower response time for the query.
Reference: [11] <author> Tandem Performance Group, </author> <title> A benchmark non-stop SQL on the debit credit transaction, </title> <booktitle> in Proceedings of the 1988 SIGMOD Conference, </booktitle> <address> Chicago, IL, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: 1 Introduction In highly-parallel database machines (e.g., Gamma [2], Bubba [1], Non-Stop SQL <ref> [11] </ref>, XPRS [10] and Volcano [6]) relations are "partitioned" (see Livny et al [8] and Ries and Epstein [9] for early partitioning strategies) across multiple processors.
References-found: 11

