URL: http://ftp.eecs.umich.edu/people/peter/ijcai95-context.ps
Refering-URL: http://ftp.eecs.umich.edu/people/peter/
Root-URL: http://www.eecs.umich.edu
Email: peter@umich.edu  
Title: Use of Context in an Automatic Lexical Acquisition System  
Author: Peter M. Hastings ()-(voice) ()-(fax) 
Address: 1101 Beal Avenue Ann Arbor, MI 48109  
Affiliation: Artificial Intelligence Lab The University of Michigan  
Abstract: In order to infer the meanings of unknown words from example sentences, Camille (Contextual Acquisition Mechanism for Incremental Lexeme LEarning) concentrates primarily on the context provided by the argument structure and known lexemes within the example sentences. Previous lexical acquisition systems focused on the larger discourse context. This paper shows how Camille was able to make significant inferences using only single utterances in isolation. Then it describes the implementation of a script mechanism which enabled Camille to use inter-sentential context. Finally it provides an analysis of the differences between the knowledge provided by the different contexts and describes how script-based systems help and hurt the lexical acquisition task. 
Abstract-found: 1
Intro-found: 1
Reference: [ Brent, 1993a ] <author> M. Brent. </author> <title> From grammar to lexicon: Unsupervised learning of lexical syntax. </title> <booktitle> Computational Linguistics, </booktitle> <year> 1993. </year>
Reference: [ Brent, 1993b ] <author> M. Brent. </author> <title> Surface cues and robust inference as a basis for the early acquisition of subcategorization frames. </title> <type> Lingua, </type> <year> 1993. </year>
Reference: [ Cardie, 1993 ] <author> C. Cardie. </author> <title> A case-based approach to knowledge acquisition for domain-specific sentence analysis. </title> <booktitle> In Proceedings of the 11 th National Conference on Artificial Intelligence, </booktitle> <pages> pages 798-803, </pages> <year> 1993. </year>
Reference-contexts: These principles set Camille apart from other lexical acquisition systems. Many early systems were only tested on small sets of data [ Salveter, 1979, Granger, 1977, Zernik, 1987, Siskind, 1991 ] . More recent systems have been applied to real-world texts, but have required the assistance of a trainer <ref> [ Riloff, 1993, Cardie, 1993 ] </ref> . There have also been statistical approaches which use large corpora but infer little or no information about word meaning [ Brent, 1993a, Brent, 1993b, Church and Hanks, 1990, Hindle, 1990, Resnik, 1992, Yarowsky, 1992, Zernik, 1991 ] .
Reference: [ Chinchor, 1992 ] <author> N. Chinchor. </author> <title> MUC-4 evaluation met-rics. </title> <booktitle> In Proceedings of the Fourth Message Understanding Conference, </booktitle> <address> San Mateo, CA, 1992. </address> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: The sentences were then processed in turn by Camille, and the resulting word definitions written to a file. A suite of measures was used to evaluate Camille's performance. The scoring system was adapted from the MUC conferences <ref> [ Chinchor, 1992 ] </ref> .
Reference: [ Church and Hanks, 1990 ] <author> K. Church and P. Hanks. </author> <title> Word association norms, mutual information, and lexicography. </title> <journal> Computational Linguistics, </journal> <volume> 16, </volume> <year> 1990. </year>
Reference: [ Cullingford, 1977 ] <author> R. Cullingford. </author> <title> Organizing World Knowledge for Story Understanding by Computer. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <address> New Haven, CT, </address> <year> 1977. </year> [ <editor> Gleitman and Gillette, 1995 ] L. Gleitman and J. Gillette. </editor> <title> The role of syntax in verb learning. </title> <publisher> Forthcoming, </publisher> <year> 1995. </year>
Reference-contexts: In order to extend the system's knowledge | and thereby extend the inferences that it could make about unknown words | knowledge about sequences of actions was added to the semantics in the form of scripts <ref> [ Schank and Abelson, 1977, Cullingford, 1977 ] </ref> . Scripts specify common sequences of events or scenes. The classic example of a script describes what happens in a restaurant: the patron enters, is seated, gets a menu, orders, eats, pays, and leaves.
Reference: [ Granger, 1977 ] <author> R. Granger. Foul-up: </author> <title> A program that figures out meanings of words from context. </title> <booktitle> In Proceedings of Fifth International Joint Conference on Artificial Intelligence, </booktitle> <year> 1977. </year>
Reference-contexts: This linguistic context consisted of the syntactic structure of the example sentences along with the syntax, semantics, and associated semantic constraints of the known lexemes. Two of the foundational lexical acquisition systems <ref> [ Granger, 1977, Zernik, 1987 ] </ref> used primarily discourse information. They each used a script-type mechanism to analyze sets of sentences from rather limited domains, and they required significant special-purpose knowledge to provide their inferences. <p> The system is also automatic | it doesn't require the help of a human trainer. These principles set Camille apart from other lexical acquisition systems. Many early systems were only tested on small sets of data <ref> [ Salveter, 1979, Granger, 1977, Zernik, 1987, Siskind, 1991 ] </ref> . More recent systems have been applied to real-world texts, but have required the assistance of a trainer [ Riloff, 1993, Cardie, 1993 ] . <p> Although the use of scripts did help the lexical inference process, the mechanism was not as useful as had been reported by other authors. As mentioned earlier, scripts were the primary knowledge source for lexical acquisition for two of the more prominent earlier systems, Foul-Up and Rina <ref> [ Granger, 1977, Zernik, 1987 ] </ref> . Unfortunately, neither Granger's work nor Zernik's was systematically applied to real-world texts. It is no surprise that these systems performed well when the authors wrote the scripts and the texts that their systems processed.
Reference: [ Hastings and Lytinen, 1994 ] <author> P. Hastings and S. Lyti-nen. </author> <title> The ups and downs of lexical acquisition. </title> <booktitle> In Proceedings of the 12 th National Conference on Artificial Intelligence, </booktitle> <pages> pages 754-759, </pages> <address> Cambridge, MA, 1994. </address> <publisher> MIT Press. </publisher>
Reference-contexts: 1 Introduction As reported in <ref> [ Hastings and Lytinen, 1994 ] </ref> and [ Hast-ings, 1994 ] , the Camille (Contextual Acquisition Mechanism for Incremental Lexical LEarning) system implements an algorithm for learning the meanings of words from example sentences without the help of a human trainer. <p> In the example given above, Camille would infer that "frooble" means Arson. In contrast to classification systems, Camille is frequently faced with large sets of concepts which are consistent with a particular example. Thus Camille is forced to make guesses to limit hypothesis sets. As described above and in <ref> [ Hastings and Lytinen, 1994 ] </ref> , different classes of words provide different types of constraints to the system, forcing Camille to infer the most specific consistent concept for a verb's meaning, and the most general for a noun's.
Reference: [ Hastings, 1994 ] <author> P. Hastings. </author> <title> Automatic Acquisition of Word Meaning from Context. </title> <type> PhD thesis, </type> <institution> University of Michigan, </institution> <address> Ann Arbor, MI, </address> <year> 1994. </year>
Reference-contexts: The mechanism is completely described in <ref> [ Hastings, 1994 ] </ref> , but the gist of the process is described here: As LINK processes a sentence with an unknown word, it enters a definition for each sense of each word into the parse. For unknown words, it enters generic definitions of several lexical categories.
Reference: [ Hindle, 1990 ] <author> D. Hindle. </author> <title> Noun classification from predicate-argument structures. </title> <booktitle> In Proceedings of the 28 th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 268-275, </pages> <year> 1990. </year>
Reference: [ Lytinen, 1991 ] <author> S. Lytinen. </author> <title> A unification-based, integrated natural language processing system. Computers and Mathematics with Applications, </title> <address> 23(6-9):403-418, </address> <year> 1991. </year>
Reference-contexts: Next it details the script mechanism that was added to take advantage of the larger discourse context. It concludes with a discussion of the issues related to context that Camille brings to light. 2 Camille As previously mentioned, Camille was implemented as an extension of Lytinen's LINK parser <ref> [ Lytinen, 1991 ] </ref> for use in an information extraction task. This particular task had a strong influence on Camille's design. It also provided the primary motivation: Because an information extraction system must deal with complex, real-world texts, the system requires huge amounts of linguistic knowledge.
Reference: [ MacGregor, 1990 ] <author> R. MacGregor. </author> <title> The evolving technology of classification-based knowledge representation systems. </title> <editor> In J. Sowa, editor, </editor> <booktitle> Principles of Semantic Nets: Explorations in the Representation of Knowledge. </booktitle> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Ma-teo, CA, </address> <year> 1990. </year>
Reference-contexts: The basic operation of Camille's lexical acquisition mechanism is rather similar to classification systems like Loom <ref> [ MacGregor, 1990 ] </ref> . Given a sentence with an unknown word, Camille searches the existing concept hierarchy for a concept which adequately matches the current example.
Reference: [ Resnik, 1992 ] <author> P. </author> <title> Resnik. A class-based approach to lexical discovery. </title> <booktitle> In Proceedings of the 30 th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 327-329, </pages> <year> 1992. </year>
Reference: [ Riloff, 1993 ] <author> E. Riloff. </author> <title> Automatically constructing a dictionary for information extraction tasks. </title> <booktitle> In Proceedings of the 11 th National Conference on Artificial Intelligence, </booktitle> <pages> pages 811-816, </pages> <year> 1993. </year>
Reference-contexts: These principles set Camille apart from other lexical acquisition systems. Many early systems were only tested on small sets of data [ Salveter, 1979, Granger, 1977, Zernik, 1987, Siskind, 1991 ] . More recent systems have been applied to real-world texts, but have required the assistance of a trainer <ref> [ Riloff, 1993, Cardie, 1993 ] </ref> . There have also been statistical approaches which use large corpora but infer little or no information about word meaning [ Brent, 1993a, Brent, 1993b, Church and Hanks, 1990, Hindle, 1990, Resnik, 1992, Yarowsky, 1992, Zernik, 1991 ] .
Reference: [ Salveter, 1979 ] <author> S. Salveter. </author> <title> Inferring conceptual graphs. </title> <journal> Cognitive Science, </journal> <volume> 3 </volume> <pages> 141-166, </pages> <year> 1979. </year>
Reference-contexts: The system is also automatic | it doesn't require the help of a human trainer. These principles set Camille apart from other lexical acquisition systems. Many early systems were only tested on small sets of data <ref> [ Salveter, 1979, Granger, 1977, Zernik, 1987, Siskind, 1991 ] </ref> . More recent systems have been applied to real-world texts, but have required the assistance of a trainer [ Riloff, 1993, Cardie, 1993 ] .
Reference: [ Schank and Abelson, 1977 ] <author> R. Schank and R. Abelson. </author> <title> Scripts, plans, goals, and understanding. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1977. </year>
Reference-contexts: In order to extend the system's knowledge | and thereby extend the inferences that it could make about unknown words | knowledge about sequences of actions was added to the semantics in the form of scripts <ref> [ Schank and Abelson, 1977, Cullingford, 1977 ] </ref> . Scripts specify common sequences of events or scenes. The classic example of a script describes what happens in a restaurant: the patron enters, is seated, gets a menu, orders, eats, pays, and leaves.
Reference: [ Schank, 1973 ] <author> R. Schank. </author> <title> Identification of conceptualizations underlying natural language. </title> <editor> In Roger Schank and K.M. Colby, editors, </editor> <booktitle> Computer Models of Thought and Language. W.H. </booktitle> <publisher> Freeman, </publisher> <address> San Francisco, </address> <year> 1973. </year>
Reference-contexts: Each script had certain trigger words defined for it, many of which were verbs. For example, trigger words for the restaurant script might be "went out", "dined", "restaurant", or "ordered". After a script was selected, SAM invoked a Conceptual Dependency <ref> [ Schank, 1973 ] </ref> analyzer on each sentence and matched the constituents of the sentence with the expectations of one of the scenes in the script. The integration process filled in the slots of the script and created pointers between the sentences in a form of anaphora resolution.
Reference: [ Siskind, 1991 ] <author> J. Siskind. </author> <title> Dispelling myths about language bootstrapping. </title> <editor> In D. Powers and L. Reeker, editors, </editor> <booktitle> Proceedings of the AAAI Spring Symposium on Machine Learning of Natural Language and Ontology, Document D-91-09, </booktitle> <institution> University of Kaiserslautern, </institution> <address> FRG, </address> <year> 1991. </year> <note> DFKI. </note>
Reference-contexts: The system is also automatic | it doesn't require the help of a human trainer. These principles set Camille apart from other lexical acquisition systems. Many early systems were only tested on small sets of data <ref> [ Salveter, 1979, Granger, 1977, Zernik, 1987, Siskind, 1991 ] </ref> . More recent systems have been applied to real-world texts, but have required the assistance of a trainer [ Riloff, 1993, Cardie, 1993 ] .
Reference: [ Sundheim, 1992 ] <author> B. Sundheim. </author> <title> Overview of the fourth message understanding evaluation and conference. </title> <booktitle> In Proceedings of the Fourth Message Understanding Conference, </booktitle> <address> San Mateo, CA, 1992. </address> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: Given a sentence with an unknown word, Camille searches the existing concept hierarchy for a concept which adequately matches the current example. Figure 1 shows a subset of the hierarchy that was used in the terrorism domain of the MUC-3 and MUC-4 conferences <ref> [ Sundheim, 1992 ] </ref> . Each node shows its name and the semantic constraints on its slot fillers.
Reference: [ Yarowsky, 1992 ] <author> D. Yarowsky. </author> <title> Word-sense disambiguation using statistical models of roget's categories trained on large corpora. </title> <booktitle> In Proceedings, COLING-92, </booktitle> <year> 1992. </year>
Reference: [ Zernik, 1987 ] <author> Uri Zernik. </author> <title> How do machine language paradigms fare in language acquisition. </title> <booktitle> In Proceedings of the Fourth International Workshop on Machine Learning, </booktitle> <address> Los Altos, CA, 1987. </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: This linguistic context consisted of the syntactic structure of the example sentences along with the syntax, semantics, and associated semantic constraints of the known lexemes. Two of the foundational lexical acquisition systems <ref> [ Granger, 1977, Zernik, 1987 ] </ref> used primarily discourse information. They each used a script-type mechanism to analyze sets of sentences from rather limited domains, and they required significant special-purpose knowledge to provide their inferences. <p> The system is also automatic | it doesn't require the help of a human trainer. These principles set Camille apart from other lexical acquisition systems. Many early systems were only tested on small sets of data <ref> [ Salveter, 1979, Granger, 1977, Zernik, 1987, Siskind, 1991 ] </ref> . More recent systems have been applied to real-world texts, but have required the assistance of a trainer [ Riloff, 1993, Cardie, 1993 ] . <p> Although the use of scripts did help the lexical inference process, the mechanism was not as useful as had been reported by other authors. As mentioned earlier, scripts were the primary knowledge source for lexical acquisition for two of the more prominent earlier systems, Foul-Up and Rina <ref> [ Granger, 1977, Zernik, 1987 ] </ref> . Unfortunately, neither Granger's work nor Zernik's was systematically applied to real-world texts. It is no surprise that these systems performed well when the authors wrote the scripts and the texts that their systems processed.
Reference: [ Zernik, 1991 ] <author> U. Zernik. </author> <title> Train1 vs. train2: Tagging word senses in corpus. </title> <editor> In U. Zernik, editor, </editor> <title> Lexical Acquisition: Exploiting On-line Resources to Build a Lexicon. </title> <publisher> Lawrence Erlbaum Associates, Inc, </publisher> <address> Hillsdale, NJ, </address> <year> 1991. </year>
References-found: 22

