URL: ftp://ftp.cc.gatech.edu/pub/gvu/tr/1998/98-15.ps.Z
Refering-URL: http://www.cs.gatech.edu/gvu/reports/1998/
Root-URL: 
Email: stire@cps.msu.edu spencer@cc.gatech.edu  
Title: Automating UI Generation by Model Composition  
Author: Kurt Stirewalt Spencer Rugaber 
Keyword: Model-based user-interface generation,  
Note: Submitted to: Automated Software Engineering (ASE'98) 13th IEEE International Conference  conjunction as composition, Lotos.  
Address: East Lansing, Michigan 48824 Atlanta, Georgia 30332-0280  
Affiliation: Department of Computer Science College of Computing Michigan State University Georgia Institute of Technology  
Abstract: Automated user-interface generation environments have been criticized for their failure to deliver rich and powerful interactive applications[24]. To specify more powerful systems, designers need multiple specialized modeling notations[17, 19]. The model composition problem is concerned with automatically deriving powerful, correct, and efficient user interfaces from multiple models specified in different notations. Solutions balance the advantages of separating code generation into specialized code generators with deep, model-specific knowledge against the correctness and efficiency obstacles that result from such separation. We present a solution that maximizes the advantage of separating code generation. In our approach, highly specialized, model-specific code generators synthesize run-time modules from individual models. We address the correctness and efficiency obstacles by formalizing composition mechanisms that code generators may assume and that are guaranteed by a run-time infra-structure. The mechanisms operate to support run-time module composition as conjunction in the sense defined by Zave and Jackson[28]. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. D. Abowd. </author> <title> Formal Aspects of Human Computer Interaction. </title> <type> PhD thesis, </type> <institution> University of Oxford, </institution> <month> June </month> <year> 1991. </year>
Reference-contexts: A recurring characteristic of all model-based approaches to UI generation is that models are specified using diverse and often incompatible notations. This characteristic complicates the formal definition of model composition (Section 2.1). Researchers in the Human Computer Interaction (HCI) community <ref> [2, 1] </ref> address this obstacle by representing models as agents defined in a process algebra (Section 2.2). Researchers in the Software Engineering community [27, 28] address similar problems with multi-paradigm specifications and describe a technique called composition by conjunction that solves the problem. These approaches deal with specifications only. <p> These approaches deal with specifications only. Our solution to the model composition problem uses the agent-based representation of models, suggested by Alexander [2] and Abowd <ref> [1] </ref>, to extend conjunction into a run-time mechanism for composing generated modules. The solution makes some assumptions about the class of applications being modeled. <p> A number of researchers, including Abowd <ref> [1] </ref> and Alexander [2], suggest that decomposing interactive systems into a collection of specialized agents illuminates usability and correctness properties. Often properties of a whole system can be described as properties of a single agent. <p> Dialogue existed only implicitly in Alexander's framework. With an explicit dialogue agent, presentation and application may be specified more independently of each other. There are other uses of the agents in this domain. Abowd <ref> [1] </ref>, for example, decomposes interactive systems into four cooperating agents in order to test for usability properties.
Reference: [2] <author> H. Alexander. </author> <title> Structuring dialogues using CSP. </title> <booktitle> In Formal Methods in Human-Computer Interaction[11], </booktitle> <pages> pages 273-295. </pages> <publisher> Cambridge University Press, </publisher> <year> 1990. </year>
Reference-contexts: A recurring characteristic of all model-based approaches to UI generation is that models are specified using diverse and often incompatible notations. This characteristic complicates the formal definition of model composition (Section 2.1). Researchers in the Human Computer Interaction (HCI) community <ref> [2, 1] </ref> address this obstacle by representing models as agents defined in a process algebra (Section 2.2). Researchers in the Software Engineering community [27, 28] address similar problems with multi-paradigm specifications and describe a technique called composition by conjunction that solves the problem. These approaches deal with specifications only. <p> Researchers in the Software Engineering community [27, 28] address similar problems with multi-paradigm specifications and describe a technique called composition by conjunction that solves the problem. These approaches deal with specifications only. Our solution to the model composition problem uses the agent-based representation of models, suggested by Alexander <ref> [2] </ref> and Abowd [1], to extend conjunction into a run-time mechanism for composing generated modules. The solution makes some assumptions about the class of applications being modeled. <p> A number of researchers, including Abowd [1] and Alexander <ref> [2] </ref>, suggest that decomposing interactive systems into a collection of specialized agents illuminates usability and correctness properties. Often properties of a whole system can be described as properties of a single agent. Alexander [2] decomposes dialogue specifications into presentation and application agents that represent the two parties of the user-computer conversation. <p> A number of researchers, including Abowd [1] and Alexander <ref> [2] </ref>, suggest that decomposing interactive systems into a collection of specialized agents illuminates usability and correctness properties. Often properties of a whole system can be described as properties of a single agent. Alexander [2] decomposes dialogue specifications into presentation and application agents that represent the two parties of the user-computer conversation. Each of these agents are defined formally as processes in the CSP [13] notation, and they cooperate as prescribed by the synchronous parallel composition operator (k) of CSP.
Reference: [3] <author> L. Bass and J. Coutaz. </author> <title> Developing Software for the User Interface. SEI Series in Software Engineering. </title> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: A distinguishing characteristic of Mastermind is that the model-specific code generators work independently of one another. Composing the code generated from multiple models is difficult. A model, by design, represents some aspects of a system and is neutral with respect to others <ref> [3] </ref>. Inevitably, however, functionality specified by one model overlaps with or is dependent upon Page 1 functionality specified by another. <p> Page 3 2.3 GUI Architecture Frameworks Mastermind generates software modules from declarative models. Modules must inter-operate in the context of an underlying run-time environment. Currently, there is no single run-time environment architecture that fits all user-interface problems <ref> [3] </ref>. There are, however, two frameworks that seem to capture most cases: SmallTalk's Model-View-Controller (MVC)[14] and Coutaz's Presentation-Abstraction-Control (PAC)[8]. Both of these cast a system into a collection of cooperating agents. An agent is a complete information processing unit with attributes from each model.
Reference: [4] <author> T. Bolognesi and E. Brinksma. </author> <title> Introduction to the ISO specification language Lotos. </title> <journal> Computer Network ISDN Systems, </journal> <volume> 14(1), </volume> <year> 1987. </year>
Reference-contexts: A process is an entity whose internal structure can only be discovered by observing the actions in which it participates. Processes are often denoted by formal notations called process algebras. The CSP notation mentioned above is one example of a process algebra. In this paper, we use the Lotos <ref> [4] </ref> notation, which uses temporal operators to specify permissible orderings and dependences over actions. A process defined in Lotos performs actions and interacts with other, concurrently executing, processes. Actions are built up out of atomic units called events. <p> This is useful because, when multiple processes synchronize on the same action, each process can be thought of as adding a constraint to the occurrence of that action <ref> [4] </ref>. This style of expressing behavior is often called constraint-oriented specification. Constraint-oriented specification has been used to rigorously define composition in multi-paradigm specifications [27]. A multi-paradigm specification is one in which a system is described by multiple partial specifications written in different notations.
Reference: [5] <author> T. P. Browne et al. </author> <title> Using declarative descriptions to model user interfaces with Mastermind. </title> <editor> In F. Paterno and P. Palanque, editors, </editor> <title> Formal Methods in Human Computer Interaction. </title> <publisher> Springer-Verlag, </publisher> <year> 1997. </year>
Reference-contexts: The model-based approach to interactive system development addresses this deficiency by decomposing UI design into the construction of separate models, each of which is declaratively specified <ref> [5] </ref>. Once specified, automated tools integrate the models and generate an efficient system from them. The model composition problem is the need to efficiently implement and automatically integrate interactive software from separate declarative models. This paper introduces the model composition problem and presents a solution. <p> By focusing attention on a single aspect of an interactive system, a model can be expressed in a highly-specialized notation. This property makes systems developed using the model-based approach easier to develop and maintain than systems produced using other approaches. The Mastermind project <ref> [5, 17] </ref> is concerned with the automatic generation of user interfaces from three kinds of models: * Presentation models specifying the appearance of user interfaces in terms of their widgets and how the widgets behave. * Application models specifying which parts (func tions and data) of applications are accessible from the <p> The first issue is a function of the expressive power of the modeling notations. In Mastermind, special-purpose modeling notations were cho 1 Not to be confused with our use of the word model. 2 Not to be confused with Mastermind Presentation. sen to overcome this deficiency <ref> [17, 5] </ref>. This paper is concerned with generating correct implementations with maximal efficiency while preserving the expressive power of Mastermind models. 3 Design Requirements Recall from Figure 1 that each class of model has a code generator that synthesizes run-time modules for models in that class.
Reference: [6] <editor> H. J. Bullinger and B. Schackel, editors. </editor> <booktitle> Human Computer Interaction - INTERACT'87. </booktitle> <publisher> North Holland, </publisher> <address> Amsterdam, </address> <year> 1987. </year>
Reference: [7] <author> P. Castells, P. Szekely, and E. Salcher. </author> <title> Declara tive models of presentation. </title> <booktitle> In IUI'97: International Conference on Intelligent User Interfaces, </booktitle> <pages> pages 137-144, </pages> <year> 1997. </year>
Reference-contexts: One characteristic of model-based approaches is that, by restricting the focus of a model to a single attribute of the system, modeling notations can be specialized and highly declarative. The Mastermind Presentation Model <ref> [7] </ref>, for example, combines concepts and terminology from graphic design with mechanisms for composing complex presentations through functional constraints. Dialogue models often use state and event constructs to describe the user-computer conversation. Example notations include StateCharts [10] and Petri nets [18]. <p> This new code generator is incorporating state-space reduction technology described in [22] and will improve interaction time that, in the prototype, is a function of the depth of a dialogue expression with constant time interaction. We are also working on adapting the presentation model code generator described in <ref> [7] </ref> to cooperate work within our infrastructure. Page 9 6 Conclusions We began this work investigating the feasibility of generating user-interface code from multiple declarative models and quickly discovered that generating code for a specific model is easy; whereas integrating the code generated from these models is difficult.
Reference: [8] <author> J. Coutaz. </author> <title> PAC, an object-oriented model for dialog design. </title> <booktitle> In Human Computer Interaction - INTERACT'87 [6], </booktitle> <pages> pages 431-436. </pages> <address> North Hol-land, Amsterdam, </address> <year> 1987. </year>
Reference: [9] <author> W. K. Edwards, S. E. Hudson, R. Rodenstein, T. Rodriguez, and I. E. Smith. </author> <title> Systematic output modification in a 2d user interface toolkit. </title> <booktitle> In UIST'97: ACM Symposium on User Interface Software Technology, </booktitle> <year> 1997. </year>
Reference-contexts: The PAC framework faithfully represents the modularity decisions of object-oriented user-interface toolkits like Artkit [12] and subArctic <ref> [9] </ref>. These toolkits package input and output together into reusable widgets called interactors. Interactive systems tend to be structured using either the MVC or PAC frameworks, with the choice depending on the nature of the application.
Reference: [10] <author> D. Harel. </author> <title> On visual formalisms. </title> <journal> Communica tions of the ACM, </journal> <volume> 31(5), </volume> <year> 1988. </year>
Reference-contexts: The Mastermind Presentation Model [7], for example, combines concepts and terminology from graphic design with mechanisms for composing complex presentations through functional constraints. Dialogue models often use state and event constructs to describe the user-computer conversation. Example notations include StateCharts <ref> [10] </ref> and Petri nets [18]. These schemes have a variety of composition mechanisms that include state hierarchy, orthogonality (concurrency), and alternation. The Mastermind Application Model combines concepts and terminology from object-oriented design techniques [20] with mechanisms for composing complex behavior based on method invocation.
Reference: [11] <author> M. Harrison and H. Thimbleby, </author> <title> editors. Formal Methods in Human-Computer Interaction. </title> <publisher> Cam-bridge University Press, </publisher> <year> 1990. </year>
Reference: [12] <author> T. R. Henry, S. E. Hudson, and G. L. Newell. </author> <title> Integrating gesture and snapping into a user interface toolkit. </title> <booktitle> In Third Annual Symposium on User Interface Software and Technology. Proceedings of the ACM SIGGRAPH Symposium, </booktitle> <pages> pages 112-122, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: The PAC framework faithfully represents the modularity decisions of object-oriented user-interface toolkits like Artkit <ref> [12] </ref> and subArctic [9]. These toolkits package input and output together into reusable widgets called interactors. Interactive systems tend to be structured using either the MVC or PAC frameworks, with the choice depending on the nature of the application.
Reference: [13] <author> C. A. R. Hoare. </author> <title> Communicating Sequential Pro cesses. </title> <booktitle> Prentice/Hall International, </booktitle> <address> Englewood Cliffs, New Jersey, </address> <year> 1985. </year>
Reference-contexts: Often properties of a whole system can be described as properties of a single agent. Alexander [2] decomposes dialogue specifications into presentation and application agents that represent the two parties of the user-computer conversation. Each of these agents are defined formally as processes in the CSP <ref> [13] </ref> notation, and they cooperate as prescribed by the synchronous parallel composition operator (k) of CSP. This decomposition, while nice conceptually, often distributes global behavior into complex protocols of local behavior.
Reference: [14] <author> G. E. Krasner and S. T. Pope. </author> <title> A cookbook for using the model view controller user interface paradigm in smalltalk. </title> <journal> Journal of Object Oriented Programming, </journal> <volume> 1(3), </volume> <month> August </month> <year> 1988. </year>
Reference: [15] <author> B. A. Myers et al. </author> <title> The Amulet environment: New models for effective user interface software development. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 23(6) </volume> <pages> 347-365, </pages> <month> June </month> <year> 1997. </year> <pages> Page 10 </pages>
Reference-contexts: Inter-model composition is concerned with managing this latter inter-model behavior. Some behavior is highly model specific and neither influences nor is affected by behavior specified in other models. In the presentation model, for example, objects are implemented using graphical primitives in the Amulet toolkit <ref> [15] </ref>, and attribute relations are implemented as declarative formulas that, at run-time, eagerly propagate attribute changes to dependent attributes. As long as changes in these attributes do not trigger behavior in the dialogue or application models, these aspects can be ignored when considering model composition.
Reference: [16] <author> B. A. Myers and M. B. Rosson. </author> <title> Survey on user interface programming. </title> <booktitle> In SIGCHI'92: Human Factors in Computing Systems, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Building user interfaces (UIs) is time consuming and costly. Myers and Rosson <ref> [16] </ref> found that in systems with graphical UIs (GUIs), nearly 50% of source code lines and development time could be attributed to the UI. GUIs are usually built from a fixed set of modules composed in regular ways.
Reference: [17] <author> R. Neches et al. </author> <title> Knowledgeable development en vironments using shared design models. </title> <booktitle> In Intelligent Interfaces Workshop, </booktitle> <pages> pages 63-70, </pages> <year> 1993. </year>
Reference-contexts: By focusing attention on a single aspect of an interactive system, a model can be expressed in a highly-specialized notation. This property makes systems developed using the model-based approach easier to develop and maintain than systems produced using other approaches. The Mastermind project <ref> [5, 17] </ref> is concerned with the automatic generation of user interfaces from three kinds of models: * Presentation models specifying the appearance of user interfaces in terms of their widgets and how the widgets behave. * Application models specifying which parts (func tions and data) of applications are accessible from the <p> The first issue is a function of the expressive power of the modeling notations. In Mastermind, special-purpose modeling notations were cho 1 Not to be confused with our use of the word model. 2 Not to be confused with Mastermind Presentation. sen to overcome this deficiency <ref> [17, 5] </ref>. This paper is concerned with generating correct implementations with maximal efficiency while preserving the expressive power of Mastermind models. 3 Design Requirements Recall from Figure 1 that each class of model has a code generator that synthesizes run-time modules for models in that class.
Reference: [18] <author> P. Palanque, R. Bastide, and V. Senges. </author> <title> Validat ing interactive system design through the verification of formal task and system models. </title> <booktitle> In Working Conference on Engineering for Human Computer Interaction, </booktitle> <year> 1995. </year>
Reference-contexts: The Mastermind Presentation Model [7], for example, combines concepts and terminology from graphic design with mechanisms for composing complex presentations through functional constraints. Dialogue models often use state and event constructs to describe the user-computer conversation. Example notations include StateCharts [10] and Petri nets <ref> [18] </ref>. These schemes have a variety of composition mechanisms that include state hierarchy, orthogonality (concurrency), and alternation. The Mastermind Application Model combines concepts and terminology from object-oriented design techniques [20] with mechanisms for composing complex behavior based on method invocation.
Reference: [19] <author> A. Puerta. </author> <title> The Mecano project: Comprehensive and integrated support for model-based user interface development. </title> <booktitle> In [25], </booktitle> <pages> pages 19-36. </pages> <publisher> Na-mur University Press, </publisher> <year> 1996. </year>
Reference: [20] <author> J. Rumbaugh et al. </author> <title> Object-Oriented Modeling and Design. </title> <publisher> Prentice-Hall, </publisher> <year> 1991. </year>
Reference-contexts: Example notations include StateCharts [10] and Petri nets [18]. These schemes have a variety of composition mechanisms that include state hierarchy, orthogonality (concurrency), and alternation. The Mastermind Application Model combines concepts and terminology from object-oriented design techniques <ref> [20] </ref> with mechanisms for composing complex behavior based on method invocation. These examples illustrate how modeling notations provide intra-model composition mechanisms that vary among the different models. It is not clear that any one of these mechanisms are sufficient for inter-model composition, the subject of this paper. <p> The design refines the notions of action and synchronization, which form the basis of inter-module communication in Figure 4, into run-time objects that implement these constraints. 4.1 Run-time Control One concern in designing a system is the implementation of software control <ref> [20] </ref>. Control can be implemented in many ways. In procedural systems, for example, control is synonymous with location in the code; whereas in concurrent systems, control is distributed and managed by multiple objects concurrently. <p> We now describe the Action object, a run-time entity that encapsulates the status (enabled or disabled) of an observable action with an activation procedure that can be specialized by model-specific code generators to implement desired functionality. Figure 5 shows our design as an OMT <ref> [20] </ref> object model. The first thing to note about our design is that the class Action is abstract. Specifically, it contains an abstract method called enable () that must be supplied by a subclass.
Reference: [21] <author> R. E. K. Stirewalt. </author> <title> Automatic Generation of In teractive Systems from Declarative Models. </title> <type> PhD thesis, </type> <institution> Georgia Institute of Technology, </institution> <year> 1997. </year>
Reference-contexts: Once all of the synchronization requirements have been met, the Event issues the appropriate activate, get, and set methods and then instructs the dialogue module to compute the next state. This process is described in greater detail in <ref> [21] </ref>. 5 Results and Status Automatic approaches to user-interface software generation have been criticized for their failure to deliver rich and powerful interactive applications [24]. This deficiency has been addressed by incorporating more and more powerful models into the development process. <p> Power We were able to express the UI's in several case studies using our modeling notations. We tested the quality of user interfaces on two specific examples: the Print/Save widget described in Section 3.3 and an airspace- and runway-executive that supports an air-traffic controller (ATC) in a busy airport <ref> [21] </ref>. The former demonstrates the ability to generate common, highly reusable, tasks for standard graphical user-interfaces. The latter demonstrates the ability to support a complex task using a direct-manipulation interface. The ATC example testifies to the power of our approach. <p> In such a deployment, these signals would be connected to External rather than Eager actions and would fit into the framework without change. For more details on this case study and the print/save dialogue, see Stirewalt <ref> [21] </ref>. Correctness In addition to being able to generate and manage powerful user-interfaces, the composition of our modules is correct. Two aspects of our approach require justification on these grounds. First is the design of run-time action synchronization. This paper addresses the theoretical issues involved here. <p> As we mentioned earlier, the Mastermind Dialogue model notation can be thought of as a syntactic sugaring for a subset of Full Lotos. We implemented a prototype dialogue model code generator whose correctness was validated in Stirewalt <ref> [21] </ref> (also described in [22]). Efficiency We measured efficiency empirically by applying our prototype code generator on the ATC example. We generated dialogue modules and connected these with hand-coded presentation and application modules. On the examples we tried, we observed no time delays between interactions.
Reference: [22] <author> R. E. K. Stirewalt and G. D. Abowd. </author> <title> Composi tion property analysis: a new strategy for model checking user-interface designs. </title> <booktitle> In Sixth International SIGSOFT Symposium on the Foundations of Software Engineering (FSE'98), </booktitle> <year> 1998. </year> <note> Submitted for publication. </note>
Reference-contexts: As we mentioned earlier, the Mastermind Dialogue model notation can be thought of as a syntactic sugaring for a subset of Full Lotos. We implemented a prototype dialogue model code generator whose correctness was validated in Stirewalt [21] (also described in <ref> [22] </ref>). Efficiency We measured efficiency empirically by applying our prototype code generator on the ATC example. We generated dialogue modules and connected these with hand-coded presentation and application modules. On the examples we tried, we observed no time delays between interactions. <p> We have presented an infra-structure of run-time support for multi-model composition. The OMT design model provides guidance to developers of model-specific code generators. We are currently completing a new industrial-strength, dialogue code generator. This new code generator is incorporating state-space reduction technology described in <ref> [22] </ref> and will improve interaction time that, in the prototype, is a function of the depth of a dialogue expression with constant time interaction. We are also working on adapting the presentation model code generator described in [7] to cooperate work within our infrastructure.
Reference: [23] <author> P. Szekely et al. </author> <title> Declarative interface mod els for user interface construction tools : The Mastermind approach. </title> <editor> In L. Bass and C. Unger, editors, </editor> <title> Engineering for Human-Computer Interaction. </title> <publisher> Chapman & Hall, </publisher> <year> 1996. </year>
Reference-contexts: Model-based UI generation works on the premise that development and support environments may be built around declarative models of a system. Developers using this paradigm build interfaces by specifying models that describe the desired interface, rather than writing a program that exhibits the behavior <ref> [23] </ref>. One characteristic of model-based approaches is that, by restricting the focus of a model to a single attribute of the system, modeling notations can be specialized and highly declarative.
Reference: [24] <author> Pedro Szekely, Ping Luo, and Robert Neches. </author> <title> Beyond interface builders: Model-based interface tools. In Bridges Between Worlds: </title> <booktitle> Human Factors in Computing Systems: INTERCHI'93, </booktitle> <pages> pages 383-390. </pages> <publisher> Addison Wesley, </publisher> <month> April </month> <year> 1993. </year>
Reference-contexts: This process is described in greater detail in [21]. 5 Results and Status Automatic approaches to user-interface software generation have been criticized for their failure to deliver rich and powerful interactive applications <ref> [24] </ref>. This deficiency has been addressed by incorporating more and more powerful models into the development process. This led to the model composition problem and our present work. We validated our approach on three points: power, correctness, and efficiency.
Reference: [25] <author> J. M. Vanderdonckt, </author> <title> editor. Computer Aided De sign of User Interfaces. </title> <publisher> Namur University Press, </publisher> <address> Namur, </address> <year> 1996. </year>
Reference: [26] <institution> Visual Edge Software Ltd., Cupertino, CA. Ex tending and Customizing UIMX, </institution> <year> 1993. </year>
Reference-contexts: GUIs are usually built from a fixed set of modules composed in regular ways. Hence, GUI construction is a natural target for automation, and many commercial and research tools exist for that purpose <ref> [26] </ref>. While these tools have been successful in supporting the presentation aspect of GUI functionality, they provide only limited support for specifying behavior and the interaction of the UI with the underlying application functionality.
Reference: [27] <author> P. Zave. </author> <title> A compositional approach to mul tiparadigm programming. </title> <booktitle> IEEE Computer, </booktitle> <month> September </month> <year> 1989. </year>
Reference-contexts: This characteristic complicates the formal definition of model composition (Section 2.1). Researchers in the Human Computer Interaction (HCI) community [2, 1] address this obstacle by representing models as agents defined in a process algebra (Section 2.2). Researchers in the Software Engineering community <ref> [27, 28] </ref> address similar problems with multi-paradigm specifications and describe a technique called composition by conjunction that solves the problem. These approaches deal with specifications only. <p> This style of expressing behavior is often called constraint-oriented specification. Constraint-oriented specification has been used to rigorously define composition in multi-paradigm specifications <ref> [27] </ref>. A multi-paradigm specification is one in which a system is described by multiple partial specifications written in different notations. Zave and Jackson [28] represent partial specifications as constraints in first-order predicate logic and note how logical conjunction specifies the simultaneous solution of these constraints.
Reference: [28] <author> P. Zave and M. Jackson. </author> <title> Conjunction as com position. </title> <journal> ACM Transactions on Software Engineering and Methodology, </journal> <volume> 2(4) </volume> <pages> 371-411, </pages> <year> 1993. </year> <pages> Page 11 </pages>
Reference-contexts: This characteristic complicates the formal definition of model composition (Section 2.1). Researchers in the Human Computer Interaction (HCI) community [2, 1] address this obstacle by representing models as agents defined in a process algebra (Section 2.2). Researchers in the Software Engineering community <ref> [27, 28] </ref> address similar problems with multi-paradigm specifications and describe a technique called composition by conjunction that solves the problem. These approaches deal with specifications only. <p> This style of expressing behavior is often called constraint-oriented specification. Constraint-oriented specification has been used to rigorously define composition in multi-paradigm specifications [27]. A multi-paradigm specification is one in which a system is described by multiple partial specifications written in different notations. Zave and Jackson <ref> [28] </ref> represent partial specifications as constraints in first-order predicate logic and note how logical conjunction specifies the simultaneous solution of these constraints. Specifications written in this style use mathematical free variables to represent values to be filled in by other specifications.
References-found: 28

