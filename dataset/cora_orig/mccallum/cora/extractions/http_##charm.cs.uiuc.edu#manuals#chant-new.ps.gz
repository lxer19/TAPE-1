URL: http://charm.cs.uiuc.edu/manuals/chant-new.ps.gz
Refering-URL: http://charm.cs.uiuc.edu/manuals/
Root-URL: http://www.cs.uiuc.edu
Title: Chant: Lightweight Threads in a Distributed Memory Environment  
Author: Matthew Haines Piyush Mehrotra David Cronk 
Keyword: Index Terms Lightweight threads, interprocess communication, pthreads, MPI, dis tributed computing, parallel computing.  
Date: May 17, 1995  
Address: Mail Stop 132C Hampton, VA 23681-0001  
Affiliation: Institute for Computer Applications in Science and Engineering NASA Langley Research Center,  
Abstract: Lightweight threads are becoming increasingly useful in supporting parallelism and asynchronous events in applications and language implementations. Traditionally, lightweight threads are supported only within the single address space of a process, or in shared memory environments with multiple processes. We introduce and describe the design of Chant, a runtime system supporting lightweight threads in a distributed memory environment. In addition to communication between any two threads in the system, Chant provides support for remote service requests, remote thread operations, and collective communication between thread groups called ropes. Chant provides the first implementation of lightweight threads for a distributed memory platform whose design incorporates existing standards for lightweight threads and interprocess communication. This paper details the issues that arise in extending a standard threads package to support distributed memory execution, and the solutions that are provided by the Chant system. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Thomas E. Anderson, Brian N. Bershad, Edward D. Lazowska, and Henry M. Levy. </author> <title> Scheduler activations: Effective kernel support for the user-level management of parallelism. </title> <booktitle> In ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 95-109, </pages> <year> 1991. </year>
Reference-contexts: In light of their increasing use, the IEEE committee for Portable Operating System Interfaces for Computer Environments (POSIX) has adopted a standard interface for lightweight threads within a Unix process [25], and numerous thread libraries have been designed and implemented for workstations and shared memory multiprocessors <ref> [1, 6, 17, 27, 33, 42] </ref>. Despite their popularity and utility in shared memory systems, lightweight thread packages designed for distributed memory systems have received little attention.
Reference: [2] <author> Maurice J. Bach. </author> <title> The Design of the UNIX Operating System. Software Series. </title> <publisher> Prentice-Hall, </publisher> <year> 1986. </year>
Reference-contexts: For example, the context of a Unix process includes the hardware registers, kernel stack, user-level stack, interrupt vectors, page tables, and more <ref> [2] </ref>. The time required to switch this large context is typically on the order of thousands of microseconds, and therefore a Unix processes represents a heavyweight thread.
Reference: [3] <author> Henri E. Bal, M. Frans Kaashoek, and Andrew S. Tanenbaum. Orca: </author> <title> A language for parallel programming of distributed systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 18(3) </volume> <pages> 190-205, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Addressing for communication is ports-based, rather than thread-based, so a global name server is required to hand out the port identifiers. * Nexus [15] and Panda [7], support task-level parallelism for several parallel languages, including Fortran-M [14] and Orca <ref> [3] </ref> respectively.
Reference: [4] <author> John K. Bennett, John B. Carter, and Willy Zwaenepoel. Munin: </author> <title> Distributed shared memory based on type-specific memory coherence. </title> <institution> Technical Report Rice COMP TR89-98, Rice University, </institution> <month> November </month> <year> 1989. </year>
Reference-contexts: Therefore we replicate this information and keep a copy of the table on each participating context for the rope. Figure 6 depicts the data structure for the local rope list. 19 Again, borrowing from earlier work in area of page coherence for distributed shared memory systems <ref> [4] </ref>, we adopt two options for keeping the distributed translation tables consistent: new information is broadcast so that all tables are kept up-to-date at all times (strong consistency), or tables are allowed to remain out-of-date until a reference for a thread is generated, causing the information to be retrieved and stored
Reference: [5] <author> John K. Bennett, John B. Carter, and Willy Zwaenepoel. </author> <title> Adaptive software cache management for distributed shared memory architectures. </title> <institution> Technical Report Rice COMP TR90-109, Rice University, </institution> <month> March </month> <year> 1990. </year> <note> Appears in Proceedings of ISCA 17. </note>
Reference-contexts: However, a centralized solution for naming and updating ropes will certainly cause hot-spots. Therefore, our initial design uses a two-level approach, derived from the idea of two-level page management schemes for distributed shared memory systems <ref> [5] </ref>, that allows the user to control the contention among the servers by dividing the work between two types of centralized servers: 1. a single, global name server used to allot identifiers for new ropes, and 2. a separate rope server associated with each rope that is responsible for maintaining the
Reference: [6] <author> Brian N. Bershad, Edward D. Lazowska, Henry M. Levy, and David B. Wagner. </author> <title> An open environment for building parallel programming systems. </title> <type> Technical Report 88-01-03, </type> <institution> Department of Computer Science, University of Washington, </institution> <month> January </month> <year> 1988. </year>
Reference-contexts: In light of their increasing use, the IEEE committee for Portable Operating System Interfaces for Computer Environments (POSIX) has adopted a standard interface for lightweight threads within a Unix process [25], and numerous thread libraries have been designed and implemented for workstations and shared memory multiprocessors <ref> [1, 6, 17, 27, 33, 42] </ref>. Despite their popularity and utility in shared memory systems, lightweight thread packages designed for distributed memory systems have received little attention.
Reference: [7] <author> Raoul Bhoedjang, Tim Ruhl, Rutger Hofman, Koen Langendoen, Henri Bal, and Frans Kaashoek. Panda: </author> <title> A portable platform to support parallel programming languages. </title> <booktitle> In Symposium on Experiences with Distributed and Multiprocessor Systems IV, </booktitle> <pages> pages 213-226, </pages> <address> San Diego, CA, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: Collective operations are supported at the context level by the underlying communication system, MPI, using a scoping mechanism called groups. However, support for grouping threads within processes is not currently supported by either MPI or related thread-based runtime systems <ref> [7, 15] </ref> yet such support is clearly needed if threads are to perform collective 15 operations within a subset of the threads in the system. Relative indexing allows the programmer to specify spatial relationships among the parallel execution units, which express the natural "neighboring" relationships in data parallel algorithms. <p> Addressing for communication is ports-based, rather than thread-based, so a global name server is required to hand out the port identifiers. * Nexus [15] and Panda <ref> [7] </ref>, support task-level parallelism for several parallel languages, including Fortran-M [14] and Orca [3] respectively.
Reference: [8] <author> Ralph Butler and Ewing Lusk. </author> <title> User's guide to the p4 parallel programming system. </title> <type> Technical Report ANL-92/17, </type> <institution> Argonne National Laboratory, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: Chant is capable of supporting 2 point-to-point communication between any two threads in the system using standard lightweight thread and interprocess communication libraries. Point-to-point primitives [13] are needed to support programs using portable communication libraries <ref> [8, 44] </ref> and those generated by parallelizing compilers [24, 28, 47]. In addition, Chant can support remote service request primitives, used for RPC communications [38, 45] client-server applications, and irregular codes. Finally, Chant provides direct support for data parallel applications in the form of thread groups called ropes. <p> In response to the increasing demands of portability, several communication libraries have been established that provide a portable message passing interface over a wide variety of systems. Among these libraries, p4 <ref> [8] </ref> and PVM [44] have received the most attention.
Reference: [9] <author> T. C. K. Chou and J. A. Abraham. </author> <title> Load balancing in distributed systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-8(4), </volume> <month> July </month> <year> 1982. </year>
Reference-contexts: This is unfortunate: in a distributed memory system, lightweight threads can overlap communication with computation [11, 12, 19]; they can emulate virtual processors [29, 35]; and they can permit dynamic scheduling and load balancing <ref> [9] </ref>. However, there is no widely accepted implementation of a distributed memory threads package. We introduce the term talking threads to represent the notion of two threads in direct communication with each other, regardless of whether they exist in the same address space or not.
Reference: [10] <author> D. E. Culler, A. Sah, K. E. Schauser, T. von Eicken, and J. Wawrzynek. </author> <title> Fine-grain parallelism with minimal hardware support: A compiler-controlled threaded abstract machine. </title> <booktitle> In 4 th International Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <year> 1991. </year> <month> 29 </month>
Reference-contexts: direct communication between threads is not possible. * Proposed MPI extensions [41], supporting long-lived threads capable of executing user code and using the full range of MPI primitives. 27 * Various application-specific runtime systems, including a runtime system supporting parallel simula- tions [35] and runtime systems supporting parallel functional languages <ref> [10, 19] </ref>. The term "rope" was first coined in the pthreads++ system [43], in which a rope is a C++ class that provides support for data parallel execution of a task in a shared memory environment, and later extended to a distributed memory environment.
Reference: [11] <author> Thomas Fahringer, Matthew Haines, and Piyush Mehrotra. </author> <title> On the utility of threads for data parallel programming. </title> <booktitle> In Proceedings of The ACM International Conference on Supercomputing, </booktitle> <address> Barcelona, Spain, </address> <month> July </month> <year> 1995. </year> <note> Also appears as ICASE Technical Report 95-35. </note>
Reference-contexts: Despite their popularity and utility in shared memory systems, lightweight thread packages designed for distributed memory systems have received little attention. This is unfortunate: in a distributed memory system, lightweight threads can overlap communication with computation <ref> [11, 12, 19] </ref>; they can emulate virtual processors [29, 35]; and they can permit dynamic scheduling and load balancing [9]. However, there is no widely accepted implementation of a distributed memory threads package. <p> memory environment are still virtually non-existent, although recent efforts in the Ports [37] and Pablo [36] groups are directed at alleviating this shortcoming. 28 Currently, Chant is being used both as a compiler target for parallel language implementations [20, 22] and as a stand-alone system for supporting multithreaded applications research <ref> [11] </ref>. Additional areas of research, including parallel graphics rendering, parallel PDE applications, and parallel I/O are all currently being considered for integration with the Chant system, and we hope to report on the application of Chant to these problem domains in the future.
Reference: [12] <author> Edward W. Felton and Dylan McNamee. </author> <title> Improving the performance of message-passing applications by multithreading. </title> <booktitle> In Proceedings of the Scalable High Performance Computing Conference, </booktitle> <pages> pages 84-89, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: Despite their popularity and utility in shared memory systems, lightweight thread packages designed for distributed memory systems have received little attention. This is unfortunate: in a distributed memory system, lightweight threads can overlap communication with computation <ref> [11, 12, 19] </ref>; they can emulate virtual processors [29, 35]; and they can permit dynamic scheduling and load balancing [9]. However, there is no widely accepted implementation of a distributed memory threads package. <p> remote service request message. 26 5 Related Work There are a variety of packages and systems supporting lightweight threads in a single address space, including [17, 27, 30, 32, 33, 42], but only a few systems support any form of communication between threads in a distributed address space: * NewThreads <ref> [12] </ref>, which supports a C++ thread class on the Intel iPSC/860 with blocking send and receive member functions.
Reference: [13] <author> Message Passing Interface Forum. </author> <title> Document for a Standard Message Passing Interface, </title> <type> draft edition, </type> <month> November </month> <year> 1993. </year>
Reference-contexts: In this paper, we describe the design of a runtime system for talking threads called Chant. Chant is capable of supporting 2 point-to-point communication between any two threads in the system using standard lightweight thread and interprocess communication libraries. Point-to-point primitives <ref> [13] </ref> are needed to support programs using portable communication libraries [8, 44] and those generated by parallelizing compilers [24, 28, 47]. In addition, Chant can support remote service request primitives, used for RPC communications [38, 45] client-server applications, and irregular codes. <p> The result is the message passing interface standard (MPI) <ref> [13] </ref>. The minimal functionality required by the Chant system interface for an interprocess communication system include nonblocking send and receive (send, recv), message polling (test), collective communication (bcast, barrier, reduce), and process management (rank, nprocs).
Reference: [14] <author> I. T. Foster and K. M. Chandy. </author> <title> Fortran M: A language for modular parallel programming. </title> <type> Technical Report MCS-P327-0992 Revision 1, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: Addressing for communication is ports-based, rather than thread-based, so a global name server is required to hand out the port identifiers. * Nexus [15] and Panda [7], support task-level parallelism for several parallel languages, including Fortran-M <ref> [14] </ref> and Orca [3] respectively.
Reference: [15] <author> Ian Foster, Carl Kesselman, Robert Olson, and Steven Tuecke. </author> <title> Nexus: An interoperability layer for parallel and distributed computer systems. </title> <type> Technical Report Version 1.3, </type> <institution> Argonne National Labs, </institution> <month> December </month> <year> 1993. </year>
Reference-contexts: 1 are used in simulation systems [17, 40] to represent asynchronous events that can be mapped onto single or multiple processors; they are used in language implementations to provide support for coroutines [39], Ada tasks [32], and parallel C++ method invocations [31]; and they are used in generic runtime systems <ref> [15, 20, 46] </ref> to support fine-grain parallelism, multithreading, and language interoperability. <p> Collective operations are supported at the context level by the underlying communication system, MPI, using a scoping mechanism called groups. However, support for grouping threads within processes is not currently supported by either MPI or related thread-based runtime systems <ref> [7, 15] </ref> yet such support is clearly needed if threads are to perform collective 15 operations within a subset of the threads in the system. Relative indexing allows the programmer to specify spatial relationships among the parallel execution units, which express the natural "neighboring" relationships in data parallel algorithms. <p> Addressing for communication is ports-based, rather than thread-based, so a global name server is required to hand out the port identifiers. * Nexus <ref> [15] </ref> and Panda [7], support task-level parallelism for several parallel languages, including Fortran-M [14] and Orca [3] respectively.
Reference: [16] <author> Seth Copen Goldstein, Klaus Erik Schauser, and David Culler. </author> <title> Lazy threads, stacklets, and synchronizers: Enabling primitives for compiling parallel languages. </title> <booktitle> In Proceedings of the Third Workshop on Languages, Compilers, and Run-Time Systems for Scalable Computers, </booktitle> <address> Troy, NY, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: There are still many areas in which this research can be extended, including improved support for lightweight threads and debugging/performance-analysis tools. Improving support for lightweight threads is already an active area of research, including ideas for better stack management <ref> [16, 18] </ref>, support for reentrant system libraries [37], and support for threads within MPI [41].
Reference: [17] <author> Dirk Grunwald. </author> <title> A users guide to AWESIME: An object oriented parallel programming and simulation system. </title> <type> Technical Report CU-CS-552-91, </type> <institution> Department of Computer Science, University of Colorado at Boulder, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: Threads fl Research supported by the National Aeronautics and Space Administration under NASA Contract No. NASA-19480, while the authors were in residence at ICASE, NASA Langley Research Center, Hampton, VA 23681. 1 are used in simulation systems <ref> [17, 40] </ref> to represent asynchronous events that can be mapped onto single or multiple processors; they are used in language implementations to provide support for coroutines [39], Ada tasks [32], and parallel C++ method invocations [31]; and they are used in generic runtime systems [15, 20, 46] to support fine-grain parallelism, <p> In light of their increasing use, the IEEE committee for Portable Operating System Interfaces for Computer Environments (POSIX) has adopted a standard interface for lightweight threads within a Unix process [25], and numerous thread libraries have been designed and implemented for workstations and shared memory multiprocessors <ref> [1, 6, 17, 27, 33, 42] </ref>. Despite their popularity and utility in shared memory systems, lightweight thread packages designed for distributed memory systems have received little attention. <p> an inexpensive operation when the translation information is cached locally, and doubles the exchange time when the information is stored remotely, accounting for the extra remote service request message. 26 5 Related Work There are a variety of packages and systems supporting lightweight threads in a single address space, including <ref> [17, 27, 30, 32, 33, 42] </ref>, but only a few systems support any form of communication between threads in a distributed address space: * NewThreads [12], which supports a C++ thread class on the Intel iPSC/860 with blocking send and receive member functions.
Reference: [18] <author> Dirk Grunwald, Brad Calder, Suvas Vajracharya, and Harini Srinivasan. </author> <title> Heaps o' stacks: Combined heap-based activation allocation for parallel programs. </title> <type> Technical report, </type> <institution> Computer Science Department, University of Colorado, </institution> <month> April </month> <year> 1994. </year>
Reference-contexts: There are still many areas in which this research can be extended, including improved support for lightweight threads and debugging/performance-analysis tools. Improving support for lightweight threads is already an active area of research, including ideas for better stack management <ref> [16, 18] </ref>, support for reentrant system libraries [37], and support for threads within MPI [41].
Reference: [19] <author> Matthew Haines and Wim Bohm. </author> <title> An evaluation of software multithreading in a conventional distributed memory multiprocessor. </title> <booktitle> In IEEE Symposium on Parallel and Distributed Processing, </booktitle> <pages> pages 106-113, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Despite their popularity and utility in shared memory systems, lightweight thread packages designed for distributed memory systems have received little attention. This is unfortunate: in a distributed memory system, lightweight threads can overlap communication with computation <ref> [11, 12, 19] </ref>; they can emulate virtual processors [29, 35]; and they can permit dynamic scheduling and load balancing [9]. However, there is no widely accepted implementation of a distributed memory threads package. <p> direct communication between threads is not possible. * Proposed MPI extensions [41], supporting long-lived threads capable of executing user code and using the full range of MPI primitives. 27 * Various application-specific runtime systems, including a runtime system supporting parallel simula- tions [35] and runtime systems supporting parallel functional languages <ref> [10, 19] </ref>. The term "rope" was first coined in the pthreads++ system [43], in which a rope is a C++ class that provides support for data parallel execution of a task in a shared memory environment, and later extended to a distributed memory environment.
Reference: [20] <author> Matthew Haines and Wim Bohm. </author> <title> On the design of distributed memory Sisal. </title> <journal> Journal of Programming Languages, </journal> <volume> 2(1) </volume> <pages> 209-240, </pages> <month> Spring </month> <year> 1993. </year>
Reference-contexts: 1 are used in simulation systems [17, 40] to represent asynchronous events that can be mapped onto single or multiple processors; they are used in language implementations to provide support for coroutines [39], Ada tasks [32], and parallel C++ method invocations [31]; and they are used in generic runtime systems <ref> [15, 20, 46] </ref> to support fine-grain parallelism, multithreading, and language interoperability. <p> Debugging and performance-analysis tools for lightweight threads in a distributed memory environment are still virtually non-existent, although recent efforts in the Ports [37] and Pablo [36] groups are directed at alleviating this shortcoming. 28 Currently, Chant is being used both as a compiler target for parallel language implementations <ref> [20, 22] </ref> and as a stand-alone system for supporting multithreaded applications research [11].
Reference: [21] <author> Matthew Haines, David Cronk, and Piyush Mehrotra. </author> <title> On the design of Chant: A talking threads package. </title> <booktitle> In Proceedings of Supercomputing 94, </booktitle> <pages> pages 350-359, </pages> <address> Washington, D.C., </address> <month> November </month> <year> 1994. </year> <note> Also appears as ICASE Technical Report 94-25. </note>
Reference-contexts: for both point-to-point communication and remote service requests, to provide support for collective operations among threads, and and to experiment with the issues and algorithms involved in providing an efficient implementation of "talking threads." An earlier version of this paper, prior to the work on ropes, appeared in Supercomputing 94 <ref> [21] </ref>. 6 Conclusions and Future work Chant provides a solution to the problem of supporting lightweight threads in a distributed memory environment by extending existing the standards for lightweight threads and interprocess communication to create a "talking threads" package.
Reference: [22] <author> Matthew Haines, Bryan Hess, Piyush Mehrotra, John Van Rosendale, and Hans Zima. </author> <title> Runtime support for data parallel tasks. </title> <booktitle> In Proceedings of The Fifth Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 432-439, </pages> <address> McLean, VA, </address> <month> February </month> <year> 1995. </year> <note> Also appears as ICASE Technical Report 94-26 and Technical Report TR 94-2, </note> <institution> Institute for Software Technology and Parallel Systems, University of Vienna. </institution>
Reference-contexts: This system is being uses to support, among other things, our extensions to the High Performance Fortran standard for integrating task and data parallelism <ref> [22] </ref>. The remainder of the paper is organized as follows: Section 2 provides background on lightweight thread and interprocess communication systems. Section 3 details the design of Chant. Section 4 provides performance results describing the overhead of Chant as compared with the underlying systems. <p> Debugging and performance-analysis tools for lightweight threads in a distributed memory environment are still virtually non-existent, although recent efforts in the Ports [37] and Pablo [36] groups are directed at alleviating this shortcoming. 28 Currently, Chant is being used both as a compiler target for parallel language implementations <ref> [20, 22] </ref> and as a stand-alone system for supporting multithreaded applications research [11].
Reference: [23] <author> Matthew Haines, Piyush Mehrotra, and David Cronk. Ropes: </author> <title> Support for collective operations among distributed threads. </title> <type> ICASE Report 95-36, </type> <institution> Institute for Computer Applications in Science and Engineering, NASA Langley Research Center, </institution> <address> Hampton, VA 23681, </address> <month> May </month> <year> 1995. </year> <month> 30 </month>
Reference-contexts: Instead of targeting 0 to p 1 processes, the compiler requires minor changes to target 0 to p 1 threads spread across a set of contexts <ref> [23] </ref>. Appendix A.4 lists the Chant operations supporting ropes. A system for implementing thread collections (i.e. ropes) must satisfy the following requirements: 1. The collections are entities whose members can span contexts, and thus their identifiers must be unique within the system. 2.
Reference: [24] <author> Seema Hiranandani, Ken Kennedy, and Chau-Wen Tseng. </author> <title> Compiling Fortran D for MIMD distributed--memory machines. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 66-80, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Chant is capable of supporting 2 point-to-point communication between any two threads in the system using standard lightweight thread and interprocess communication libraries. Point-to-point primitives [13] are needed to support programs using portable communication libraries [8, 44] and those generated by parallelizing compilers <ref> [24, 28, 47] </ref>. In addition, Chant can support remote service request primitives, used for RPC communications [38, 45] client-server applications, and irregular codes. Finally, Chant provides direct support for data parallel applications in the form of thread groups called ropes.
Reference: [25] <author> IEEE. </author> <title> Threads Extension for Portable Operating Systems (Draft 7), </title> <month> February </month> <year> 1992. </year>
Reference-contexts: In light of their increasing use, the IEEE committee for Portable Operating System Interfaces for Computer Environments (POSIX) has adopted a standard interface for lightweight threads within a Unix process <ref> [25] </ref>, and numerous thread libraries have been designed and implemented for workstations and shared memory multiprocessors [1, 6, 17, 27, 33, 42]. Despite their popularity and utility in shared memory systems, lightweight thread packages designed for distributed memory systems have received little attention.
Reference: [26] <institution> Intel Corporation, Beaverton, OR. </institution> <note> Paragon OSF/1 User's Guide, </note> <month> April </month> <year> 1993. </year>
Reference-contexts: This functionality is supported by pthreads, ports0, and most other lightweight thread packages. Chant can also accommodate both preemptive and non-preemptive thread scheduling policies. 2.2 Interprocess Communication Communication systems for distributed memory architectures have traditionally been provided by the vendors, such as the Intel NX primitives <ref> [26] </ref> and nCUBE Vertex primitives [34]. In response to the increasing demands of portability, several communication libraries have been established that provide a portable message passing interface over a wide variety of systems. Among these libraries, p4 [8] and PVM [44] have received the most attention.
Reference: [27] <author> David Keppel. </author> <title> Tools and techniques for building fast portable threads packages. </title> <type> Technical Report UWCSE 93-05-06, </type> <institution> University of Washington, </institution> <year> 1993. </year>
Reference-contexts: In light of their increasing use, the IEEE committee for Portable Operating System Interfaces for Computer Environments (POSIX) has adopted a standard interface for lightweight threads within a Unix process [25], and numerous thread libraries have been designed and implemented for workstations and shared memory multiprocessors <ref> [1, 6, 17, 27, 33, 42] </ref>. Despite their popularity and utility in shared memory systems, lightweight thread packages designed for distributed memory systems have received little attention. <p> 60 pthreads [32], provides a library implementation of the POSIX pthreads standard interface, draft 6. 1260 43 The Sun Lightweight Process (LWP) library [42], provides a comprehensive set of thread routines supporting priorities, user-defined contexts, and stack management routines; only available under the SunOS 4x operating system. 400 25 Quickthreads <ref> [27] </ref>, provides a low-level, portable set of stack primitives for writing efficient thread packages. 440 21 Table 1: Performance (in s) of several thread packages on a Sun SparcStation 10 The minimal functionality required by the Chant system interface for a lightweight thread package includes thread creation (create), thread preemption (yield), <p> an inexpensive operation when the translation information is cached locally, and doubles the exchange time when the information is stored remotely, accounting for the extra remote service request message. 26 5 Related Work There are a variety of packages and systems supporting lightweight threads in a single address space, including <ref> [17, 27, 30, 32, 33, 42] </ref>, but only a few systems support any form of communication between threads in a distributed address space: * NewThreads [12], which supports a C++ thread class on the Intel iPSC/860 with blocking send and receive member functions.
Reference: [28] <author> C. Koelbel and P. Mehrotra. </author> <title> Compiling global name-space parallel loops for distributed execution. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4) </volume> <pages> 440-451, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Chant is capable of supporting 2 point-to-point communication between any two threads in the system using standard lightweight thread and interprocess communication libraries. Point-to-point primitives [13] are needed to support programs using portable communication libraries [8, 44] and those generated by parallelizing compilers <ref> [24, 28, 47] </ref>. In addition, Chant can support remote service request primitives, used for RPC communications [38, 45] client-server applications, and irregular codes. Finally, Chant provides direct support for data parallel applications in the form of thread groups called ropes.
Reference: [29] <author> Ravi Konuru, Jeremy Casas, Robert Prouty, Steve Otto, and Jonathan Walpole. </author> <title> A user-level process package for PVM. </title> <booktitle> In Proceedings of Scalable High Performance Computing Conference, </booktitle> <year> 1994. </year>
Reference-contexts: Despite their popularity and utility in shared memory systems, lightweight thread packages designed for distributed memory systems have received little attention. This is unfortunate: in a distributed memory system, lightweight threads can overlap communication with computation [11, 12, 19]; they can emulate virtual processors <ref> [29, 35] </ref>; and they can permit dynamic scheduling and load balancing [9]. However, there is no widely accepted implementation of a distributed memory threads package.
Reference: [30] <author> Jeff Kramer, Jeff Magee, Morris Sloman, Naranker Dulay, S. C. Cheung, Stephen Crane, and Kevin Twindle. </author> <title> An introduction to distributed programming in REX. </title> <booktitle> In Proceedings of ESPRIT-91, </booktitle> <pages> pages 207-222, </pages> <address> Brussels, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: established a minimal pthreads interface, called ports0, that can be easily ported to any of the thread-based systems listed in Figure 1. 5 Thread Package Create Switch cthreads [33], originally developed as the Mach user-level threads package; has been ported to many machines. 423 81 The REX lightweight process library <ref> [30] </ref>, defines a minimal, non-preemptive, priority-based threads package for a number of workstations and shared memory multiprocessors. 230 60 pthreads [32], provides a library implementation of the POSIX pthreads standard interface, draft 6. 1260 43 The Sun Lightweight Process (LWP) library [42], provides a comprehensive set of thread routines supporting priorities, <p> an inexpensive operation when the translation information is cached locally, and doubles the exchange time when the information is stored remotely, accounting for the extra remote service request message. 26 5 Related Work There are a variety of packages and systems supporting lightweight threads in a single address space, including <ref> [17, 27, 30, 32, 33, 42] </ref>, but only a few systems support any form of communication between threads in a distributed address space: * NewThreads [12], which supports a C++ thread class on the Intel iPSC/860 with blocking send and receive member functions.
Reference: [31] <author> Jenq Kuen Lee and Dennis Gannon. </author> <title> Object oriented parallel programming experiments and results. </title> <booktitle> In Proceedings of Supercomputing 91, </booktitle> <pages> pages 273-282, </pages> <address> Albuquerque, NM, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: at ICASE, NASA Langley Research Center, Hampton, VA 23681. 1 are used in simulation systems [17, 40] to represent asynchronous events that can be mapped onto single or multiple processors; they are used in language implementations to provide support for coroutines [39], Ada tasks [32], and parallel C++ method invocations <ref> [31] </ref>; and they are used in generic runtime systems [15, 20, 46] to support fine-grain parallelism, multithreading, and language interoperability.
Reference: [32] <author> Frank Mueller. </author> <title> A library implementation of POSIX threads under UNIX. </title> <booktitle> In Winter USENIX, </booktitle> <pages> pages 29-41, </pages> <address> San Diego, CA, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: while the authors were in residence at ICASE, NASA Langley Research Center, Hampton, VA 23681. 1 are used in simulation systems [17, 40] to represent asynchronous events that can be mapped onto single or multiple processors; they are used in language implementations to provide support for coroutines [39], Ada tasks <ref> [32] </ref>, and parallel C++ method invocations [31]; and they are used in generic runtime systems [15, 20, 46] to support fine-grain parallelism, multithreading, and language interoperability. <p> Figure 1. 5 Thread Package Create Switch cthreads [33], originally developed as the Mach user-level threads package; has been ported to many machines. 423 81 The REX lightweight process library [30], defines a minimal, non-preemptive, priority-based threads package for a number of workstations and shared memory multiprocessors. 230 60 pthreads <ref> [32] </ref>, provides a library implementation of the POSIX pthreads standard interface, draft 6. 1260 43 The Sun Lightweight Process (LWP) library [42], provides a comprehensive set of thread routines supporting priorities, user-defined contexts, and stack management routines; only available under the SunOS 4x operating system. 400 25 Quickthreads [27], provides a <p> This result is significant because some underlying lightweight thread packages won't allow modification of the scheduler's activities <ref> [32] </ref>, but the thread-polls policy can be safely implemented on all packages. 3.3 Remote Service Requests Having established a mechanism by which lightweight threads located in different contexts can directly communicate, we now address the issue of supporting remote service requests. <p> an inexpensive operation when the translation information is cached locally, and doubles the exchange time when the information is stored remotely, accounting for the extra remote service request message. 26 5 Related Work There are a variety of packages and systems supporting lightweight threads in a single address space, including <ref> [17, 27, 30, 32, 33, 42] </ref>, but only a few systems support any form of communication between threads in a distributed address space: * NewThreads [12], which supports a C++ thread class on the Intel iPSC/860 with blocking send and receive member functions.
Reference: [33] <author> Bodhisattwa Mukherjee, Greg Eisenhauer, and Kaushik Ghosh. </author> <title> A machine independent interface for lightweight threads. </title> <type> Technical Report CIT-CC-93/53, </type> <institution> College of Computing, Georgia Institute of Technology, Atlanta, Georgia, </institution> <year> 1993. </year> <title> [34] nCUBE, Beaverton, OR. nCUBE/2 Technical Overview, </title> <booktitle> PROGRAMMING, </booktitle> <year> 1990. </year>
Reference-contexts: In light of their increasing use, the IEEE committee for Portable Operating System Interfaces for Computer Environments (POSIX) has adopted a standard interface for lightweight threads within a Unix process [25], and numerous thread libraries have been designed and implemented for workstations and shared memory multiprocessors <ref> [1, 6, 17, 27, 33, 42] </ref>. Despite their popularity and utility in shared memory systems, lightweight thread packages designed for distributed memory systems have received little attention. <p> Therefore, in cooperation with the Portable Runtime Systems (PORTS) consortium [37], we have established a minimal pthreads interface, called ports0, that can be easily ported to any of the thread-based systems listed in Figure 1. 5 Thread Package Create Switch cthreads <ref> [33] </ref>, originally developed as the Mach user-level threads package; has been ported to many machines. 423 81 The REX lightweight process library [30], defines a minimal, non-preemptive, priority-based threads package for a number of workstations and shared memory multiprocessors. 230 60 pthreads [32], provides a library implementation of the POSIX pthreads <p> an inexpensive operation when the translation information is cached locally, and doubles the exchange time when the information is stored remotely, accounting for the extra remote service request message. 26 5 Related Work There are a variety of packages and systems supporting lightweight threads in a single address space, including <ref> [17, 27, 30, 32, 33, 42] </ref>, but only a few systems support any form of communication between threads in a distributed address space: * NewThreads [12], which supports a C++ thread class on the Intel iPSC/860 with blocking send and receive member functions.
Reference: [35] <author> David M. Nicol and Philip Heidelberger. </author> <title> Optimistic parallel simulation of continuous time markov chains using uniformization. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 18(4) </volume> <pages> 395-410, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: Despite their popularity and utility in shared memory systems, lightweight thread packages designed for distributed memory systems have received little attention. This is unfortunate: in a distributed memory system, lightweight threads can overlap communication with computation [11, 12, 19]; they can emulate virtual processors <ref> [29, 35] </ref>; and they can permit dynamic scheduling and load balancing [9]. However, there is no widely accepted implementation of a distributed memory threads package. <p> based on a remote service request mechanism - direct communication between threads is not possible. * Proposed MPI extensions [41], supporting long-lived threads capable of executing user code and using the full range of MPI primitives. 27 * Various application-specific runtime systems, including a runtime system supporting parallel simula- tions <ref> [35] </ref> and runtime systems supporting parallel functional languages [10, 19].
Reference: [36] <institution> The pablo performance analysis group. </institution> <note> http://bugle.cs.uiuc.edu/Pablo.html. </note>
Reference-contexts: Debugging and performance-analysis tools for lightweight threads in a distributed memory environment are still virtually non-existent, although recent efforts in the Ports [37] and Pablo <ref> [36] </ref> groups are directed at alleviating this shortcoming. 28 Currently, Chant is being used both as a compiler target for parallel language implementations [20, 22] and as a stand-alone system for supporting multithreaded applications research [11].
Reference: [37] <institution> Portable runtime systems (ports) consortium. </institution> <note> http://www.cs.uoregon.edu:80/paracomp/ports/. </note>
Reference-contexts: Although the POSIX committee has established a standard interface for lightweight threads, the actual implementations are limited to a few systems. Therefore, in cooperation with the Portable Runtime Systems (PORTS) consortium <ref> [37] </ref>, we have established a minimal pthreads interface, called ports0, that can be easily ported to any of the thread-based systems listed in Figure 1. 5 Thread Package Create Switch cthreads [33], originally developed as the Mach user-level threads package; has been ported to many machines. 423 81 The REX lightweight <p> There are still many areas in which this research can be extended, including improved support for lightweight threads and debugging/performance-analysis tools. Improving support for lightweight threads is already an active area of research, including ideas for better stack management [16, 18], support for reentrant system libraries <ref> [37] </ref>, and support for threads within MPI [41]. Debugging and performance-analysis tools for lightweight threads in a distributed memory environment are still virtually non-existent, although recent efforts in the Ports [37] and Pablo [36] groups are directed at alleviating this shortcoming. 28 Currently, Chant is being used both as a compiler <p> is already an active area of research, including ideas for better stack management [16, 18], support for reentrant system libraries <ref> [37] </ref>, and support for threads within MPI [41]. Debugging and performance-analysis tools for lightweight threads in a distributed memory environment are still virtually non-existent, although recent efforts in the Ports [37] and Pablo [36] groups are directed at alleviating this shortcoming. 28 Currently, Chant is being used both as a compiler target for parallel language implementations [20, 22] and as a stand-alone system for supporting multithreaded applications research [11].
Reference: [38] <author> Matthew Rosing and Joel Saltz. </author> <title> Low latency messages on distributed memory multiprocessors. </title> <type> Technical Report ICASE Report No. 93-30, </type> <institution> Institute for Computer Applications in Science and Engineering, NASA LaRC, Hampton, Virginia, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: Point-to-point primitives [13] are needed to support programs using portable communication libraries [8, 44] and those generated by parallelizing compilers [24, 28, 47]. In addition, Chant can support remote service request primitives, used for RPC communications <ref> [38, 45] </ref> client-server applications, and irregular codes. Finally, Chant provides direct support for data parallel applications in the form of thread groups called ropes. <p> Neither of these solutions are desirable. Blocking the entire process eliminates the opportunity to execute other (ready) threads, effectively disabling a primary feature of using threads (i.e. multithreading). User-level interrupts can be disruptive to processor pipelines and caches <ref> [38] </ref>, and are problematic for programmers using a non-preemptive threads package, since interrupts effectively make the system preemptive. Finally, many message passing libraries, including the proposed MPI standard, do not support interrupt-driven message reception.
Reference: [39] <author> Carl Schmidtmann, Michael Tao, and Steven Watt. </author> <title> Design and implmentation of a multithreaded Xlib. </title> <booktitle> In Winter USENIX, </booktitle> <pages> pages 193-203, </pages> <address> San Diego, CA, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: NASA-19480, while the authors were in residence at ICASE, NASA Langley Research Center, Hampton, VA 23681. 1 are used in simulation systems [17, 40] to represent asynchronous events that can be mapped onto single or multiple processors; they are used in language implementations to provide support for coroutines <ref> [39] </ref>, Ada tasks [32], and parallel C++ method invocations [31]; and they are used in generic runtime systems [15, 20, 46] to support fine-grain parallelism, multithreading, and language interoperability.
Reference: [40] <author> H. Schwetman. </author> <title> CSIM Reference Manual (Revision 9). </title> <institution> Microelectronics and Computer Technology Corperation, 9430 Research Blvd, Austin, TX, </institution> <year> 1986. </year> <month> 31 </month>
Reference-contexts: Threads fl Research supported by the National Aeronautics and Space Administration under NASA Contract No. NASA-19480, while the authors were in residence at ICASE, NASA Langley Research Center, Hampton, VA 23681. 1 are used in simulation systems <ref> [17, 40] </ref> to represent asynchronous events that can be mapped onto single or multiple processors; they are used in language implementations to provide support for coroutines [39], Ada tasks [32], and parallel C++ method invocations [31]; and they are used in generic runtime systems [15, 20, 46] to support fine-grain parallelism,
Reference: [41] <author> Anthony Skjellum, Nathan E. Doss, Kishore Viswanathan, Aswini Chowdappa, and Purushotham V. </author> <title> Bangalore. Extending the message passing interface (MPI). </title> <type> Technical report, </type> <institution> Computer Science Department and NSF Engineering Research Center, Mississippi State University, </institution> <year> 1994. </year>
Reference-contexts: Threads are used to represent parallel task invocations, and all communication between address spaces is based on a remote service request mechanism - direct communication between threads is not possible. * Proposed MPI extensions <ref> [41] </ref>, supporting long-lived threads capable of executing user code and using the full range of MPI primitives. 27 * Various application-specific runtime systems, including a runtime system supporting parallel simula- tions [35] and runtime systems supporting parallel functional languages [10, 19]. <p> The only other mention of collective communication among threads is in <ref> [41] </ref>, which suggests altering the role and functionality of communicators to allow for multiple threads per communicator, thus permitting collective operations among the threads. <p> Improving support for lightweight threads is already an active area of research, including ideas for better stack management [16, 18], support for reentrant system libraries [37], and support for threads within MPI <ref> [41] </ref>.
Reference: [42] <author> Sun Microsystems, Inc. </author> <title> Lightweight Process Library, sun release 4.1 edition, </title> <month> January </month> <year> 1990. </year>
Reference-contexts: In light of their increasing use, the IEEE committee for Portable Operating System Interfaces for Computer Environments (POSIX) has adopted a standard interface for lightweight threads within a Unix process [25], and numerous thread libraries have been designed and implemented for workstations and shared memory multiprocessors <ref> [1, 6, 17, 27, 33, 42] </ref>. Despite their popularity and utility in shared memory systems, lightweight thread packages designed for distributed memory systems have received little attention. <p> many machines. 423 81 The REX lightweight process library [30], defines a minimal, non-preemptive, priority-based threads package for a number of workstations and shared memory multiprocessors. 230 60 pthreads [32], provides a library implementation of the POSIX pthreads standard interface, draft 6. 1260 43 The Sun Lightweight Process (LWP) library <ref> [42] </ref>, provides a comprehensive set of thread routines supporting priorities, user-defined contexts, and stack management routines; only available under the SunOS 4x operating system. 400 25 Quickthreads [27], provides a low-level, portable set of stack primitives for writing efficient thread packages. 440 21 Table 1: Performance (in s) of several thread <p> an inexpensive operation when the translation information is cached locally, and doubles the exchange time when the information is stored remotely, accounting for the extra remote service request message. 26 5 Related Work There are a variety of packages and systems supporting lightweight threads in a single address space, including <ref> [17, 27, 30, 32, 33, 42] </ref>, but only a few systems support any form of communication between threads in a distributed address space: * NewThreads [12], which supports a C++ thread class on the Intel iPSC/860 with blocking send and receive member functions.
Reference: [43] <author> Neelakantan Sundaresan and Linda Lee. </author> <title> An object-oriented thread model for parallel numerical ap-plicaitons. </title> <booktitle> In Proceedings of the Second Annual Object-Oriented Numerics Conference, </booktitle> <pages> pages 291-308, </pages> <address> Sunriver, OR, </address> <month> April </month> <year> 1994. </year>
Reference-contexts: The term "rope" was first coined in the pthreads++ system <ref> [43] </ref>, in which a rope is a C++ class that provides support for data parallel execution of a task in a shared memory environment, and later extended to a distributed memory environment.
Reference: [44] <author> Vaidy Sunderam. </author> <title> PVM: A framework for parallel distributed computing. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 2(4) </volume> <pages> 315-339, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: Chant is capable of supporting 2 point-to-point communication between any two threads in the system using standard lightweight thread and interprocess communication libraries. Point-to-point primitives [13] are needed to support programs using portable communication libraries <ref> [8, 44] </ref> and those generated by parallelizing compilers [24, 28, 47]. In addition, Chant can support remote service request primitives, used for RPC communications [38, 45] client-server applications, and irregular codes. Finally, Chant provides direct support for data parallel applications in the form of thread groups called ropes. <p> In response to the increasing demands of portability, several communication libraries have been established that provide a portable message passing interface over a wide variety of systems. Among these libraries, p4 [8] and PVM <ref> [44] </ref> have received the most attention.
Reference: [45] <author> Thorsten von Eicken, David E. Culler, Seth Copen Goldstein, and Klaus Erik Schauser. </author> <title> Active messages: A mechanism for integrated communications and computation. </title> <booktitle> In Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 256-266, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Point-to-point primitives [13] are needed to support programs using portable communication libraries [8, 44] and those generated by parallelizing compilers [24, 28, 47]. In addition, Chant can support remote service request primitives, used for RPC communications <ref> [38, 45] </ref> client-server applications, and irregular codes. Finally, Chant provides direct support for data parallel applications in the form of thread groups called ropes. <p> The tradeoffs of these approaches and their influence on response time to remote service requests is an area of future research for Chant. If the underlying architecture supports a low-latency remote service request mechanism, such as Active 13 Messages <ref> [45] </ref>, in addition to the point-to-point primitives, then Chant would ideally shortcut the remote service request mechanism just described to take advantage of these low-level primitives.
Reference: [46] <author> Mark Weiser, Alan Demers, and Carl Hauser. </author> <title> The portable common runtime approach to interoperability. </title> <booktitle> ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 114-122, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: 1 are used in simulation systems [17, 40] to represent asynchronous events that can be mapped onto single or multiple processors; they are used in language implementations to provide support for coroutines [39], Ada tasks [32], and parallel C++ method invocations [31]; and they are used in generic runtime systems <ref> [15, 20, 46] </ref> to support fine-grain parallelism, multithreading, and language interoperability.
Reference: [47] <author> Hans P. Zima and Barbara M. Chapman. </author> <title> Compiling for distributed memory systems. </title> <journal> Proceedings of the IEEE, </journal> <note> Special Section on Languages and Compilers for Parallel Machines (To appear 1993), 1993. Also: Technical Report ACPC/TR 92-16, Austrian Center for Parallel Computation (November 1992). 32 </note>
Reference-contexts: Chant is capable of supporting 2 point-to-point communication between any two threads in the system using standard lightweight thread and interprocess communication libraries. Point-to-point primitives [13] are needed to support programs using portable communication libraries [8, 44] and those generated by parallelizing compilers <ref> [24, 28, 47] </ref>. In addition, Chant can support remote service request primitives, used for RPC communications [38, 45] client-server applications, and irregular codes. Finally, Chant provides direct support for data parallel applications in the form of thread groups called ropes.
References-found: 46

