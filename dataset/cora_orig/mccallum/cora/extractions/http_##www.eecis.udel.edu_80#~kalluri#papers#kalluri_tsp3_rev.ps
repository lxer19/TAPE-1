URL: http://www.eecis.udel.edu:80/~kalluri/papers/kalluri_tsp3_rev.ps
Refering-URL: http://www.eecis.udel.edu:80/~kalluri/resume.html
Root-URL: http://www.cis.udel.edu
Email: e-mail: kalluri@ee.udel.edu and arce@ee.udel.edu  
Phone: phone: (302) 831-8030 fax: (302) 831-4316  
Title: A General Class of Nonlinear Normalized Adaptive Filtering Algorithms 1 EDICS Paper Category: SP 2.1.5
Author: Sudhakar Kalluri and Gonzalo R. Arce 
Note: Submitted to the IEEE Transactions on Signal Processing  Permission to publish this abstract separately is granted  
Address: Newark, Delaware 19716  
Affiliation: Department of Electrical and Computer Engineering University of Delaware  
Abstract: The Normalized Least Mean Square (NLMS) algorithm is an important variant of the classical LMS algorithm for adaptive linear filtering. It possesses many advantages over the LMS algorithm, including having a faster convergence and providing for an automatic time-varying choice of the LMS step-size parameter which affects the stability, steady-state mean square error (MSE) and convergence speed of the algorithm. An auxiliary fixed step-size that is often introduced in the NLMS algorithm has the advantage that its stability region (step-size range for algorithm stability) is independent of the signal statistics. In this paper, we generalize the NLMS algorithm by deriving a class of Nonlinear Normalized LMS-type (NLMS-type) Algorithms that are applicable to a wide variety of nonlinear filter structures. We obtain a general nonlinear NLMS-type algorithm by choosing an optimal time-varying step-size which minimizes the next-step MSE at each iteration of the general nonlinear LMS-type algorithm. As in the linear case, we introduce a dimensionless auxiliary step-size whose stability range is independent of the signal statistics. The stability region could therefore be determined empirically for any given nonlinear filter type. We present computer simulations of these algorithms for two specific nonlinear filter structures: Volterra Filters, and the recently proposed class of Myriad Filters. These simulations indicate that the NLMS-type algorithms, in general, converge faster than their LMS-type counterparts. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Haykin, </author> <title> Adaptive Filter Theory. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall, </publisher> <year> 1996. </year>
Reference-contexts: 1 Introduction The Least Mean Square (LMS) algorithm <ref> [1] </ref> is widely used for adapting the weights of a linear FIR filter that minimizes the mean square error (MSE) between the filter output and a desired signal. <p> In an environment of unknown or time-varying signal statistics, the standard LMS algorithm <ref> [1] </ref> continually attempts to reduce the MSE by updating the weight vector, at each time instant n, as w (n + 1) = w (n) e (n) x (n); (1) where &gt; 0 is the so-called step-size of the update. <p> The computational simplicity of the LMS algorithm has made it an attractive choice for several applications in linear signal processing, including noise cancellation, channel equalization, adaptive control, and system identification <ref> [1] </ref>. However, it suffers from a slow rate of convergence. Further, its implementation requires the choice of an appropriate value for the step-size which affects the stability, steady-state MSE and convergence speed of the algorithm. The stability (convergence) of the LMS algorithm has been extensively studied in the literature [1]. <p> identification <ref> [1] </ref>. However, it suffers from a slow rate of convergence. Further, its implementation requires the choice of an appropriate value for the step-size which affects the stability, steady-state MSE and convergence speed of the algorithm. The stability (convergence) of the LMS algorithm has been extensively studied in the literature [1]. The stability region for mean-square convergence of the LMS algorithm is given by 0 &lt; &lt; (2 = trace (R)) [1], where R = Efx (n)x T (n)g is the correlation matrix of the input vector x (n). <p> The stability (convergence) of the LMS algorithm has been extensively studied in the literature <ref> [1] </ref>. The stability region for mean-square convergence of the LMS algorithm is given by 0 &lt; &lt; (2 = trace (R)) [1], where R = Efx (n)x T (n)g is the correlation matrix of the input vector x (n). When the input signal statistics are unknown or the environment is nonstationary, it is difficult to choose a step-size that is guaranteed to lie within the stability region. <p> When the input signal statistics are unknown or the environment is nonstationary, it is difficult to choose a step-size that is guaranteed to lie within the stability region. The so-called Normalized LMS (NLMS) algorithm <ref> [1] </ref> addresses the problem of step-size design by choosing a time-varying step-size (n) in (1) such that the next-step MSE, J n+1 = Efe 2 (n + 1)g, is minimized at each iteration. <p> This algorithm can be developed from several different points of view; we shall focus on the criterion of minimization of the 1 next-step MSE (see <ref> [1] </ref>, Problem 14), since this will be the most convenient interpretation when we later consider the case of a general nonlinear filter. <p> After incorporating an auxiliary step-size ~ &gt; 0, the NLMS algorithm is written as w (n + 1) = w (n) kx (n)k The theoretical bounds on the stability of the NLMS algorithm are given by 0 &lt; ~ &lt; 2 <ref> [1] </ref>. A significant advantage here is that, unlike the LMS step-size of (1), the auxiliary step-size ~ is dimensionless and the stability region for ~ is independent of the signal statistics. This allows for an easier step-size design with guaranteed stability (convergence) of the algorithm. <p> optimal step-size, 5 denoted by o (n), that minimizes J n+1 J n+1 (): o (n) = arg min J n+1 (): (12) As mentioned in Section 1, the criterion of minimization of the next-step MSE is one of the several interpretations of the normalized LMS algorithm of (2) (see <ref> [1] </ref>, Problem 14). We use this criterion here since, out of all the interpretations, this extends most easily to the case of a general nonlinear filter. To determine o (n), we need an expression for the derivative function (@=@)J n+1 (). <p> Therefore, it is reasonable to expect the stability region for ~ to be the same as in the linear case, where it is 0 &lt; ~ &lt; 2 <ref> [1] </ref>.
Reference: [2] <author> M. Rupp, </author> <title> "The behavior of LMS and NLMS algorithms in the presence of spherically invariant processes," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 41, </volume> <pages> pp. 1149-1160, </pages> <month> Mar. </month> <year> 1993. </year>
Reference-contexts: This allows for an easier step-size design with guaranteed stability (convergence) of the algorithm. Further, the NLMS algorithm has a potentially faster convergence than the LMS algorithm <ref> [2] </ref>. The NLMS algorithm can also be alternatively interpreted as a modification of the LMS algorithm of (1), where the update term is divided (normalized) by the squared-norm kx (n)k so that the update stays bounded even when the input vector x (n) becomes large in magnitude.
Reference: [3] <author> S. Kalluri and G. R. Arce, </author> <title> "A general class of nonlinear normalized LMS-type adaptive algorithms," </title> <booktitle> in Proc. of the 1998 CISS, </booktitle> <address> (Princeton, NJ), </address> <month> Mar. </month> <year> 1998. </year>
Reference-contexts: In this paper, we generalize the NLMS algorithm of (2) by deriving a class of nonlinear Normalized LMS-type (NLMS-type) algorithms <ref> [3] </ref> that are applicable to a wide variety of nonlinear filter structures. Although linear filters are useful in a number of applications, several practical situations exist in which nonlinear processing of the signals involved is essential in order to maintain an acceptable level of performance.
Reference: [4] <author> M. Schetzen, </author> <title> The Volterra and Wiener Theories of Nonlinear Systems. </title> <address> New York: </address> <publisher> Wiley, </publisher> <year> 1980. </year>
Reference-contexts: Applications of nonlinear models and filtering include polynomial (Volterra) filters used in nonlinear channel equalization and system identification <ref> [4, 5, 6] </ref>, and the class of order statistic filters used in image processing [7, 8]. Several adaptive nonlinear filters have also been developed based on Volterra and order statistic filters [9, 10, 11]. <p> Included in this class are linear filters, Ll filters based on order statistics [12, 13], permutation filters (which are generalizations of both linear and order statistic filters) [14], and Volterra filters <ref> [4] </ref>, among others.
Reference: [5] <author> S. Benedetto, E. Biglieri, and V. Castellani, </author> <title> Digital Transmission Theory. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall, </publisher> <year> 1987. </year>
Reference-contexts: Applications of nonlinear models and filtering include polynomial (Volterra) filters used in nonlinear channel equalization and system identification <ref> [4, 5, 6] </ref>, and the class of order statistic filters used in image processing [7, 8]. Several adaptive nonlinear filters have also been developed based on Volterra and order statistic filters [9, 10, 11].
Reference: [6] <author> T. Koh and E. J. </author> <title> Powers, "Second-order Volterra filtering and its application to nonlinear system identification," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. ASSP-33, </volume> <pages> pp. 1445-1455, </pages> <month> Dec. </month> <year> 1985. </year>
Reference-contexts: Applications of nonlinear models and filtering include polynomial (Volterra) filters used in nonlinear channel equalization and system identification <ref> [4, 5, 6] </ref>, and the class of order statistic filters used in image processing [7, 8]. Several adaptive nonlinear filters have also been developed based on Volterra and order statistic filters [9, 10, 11]. <p> Consider now the special case of the Volterra filter, which has found wide-spread use in nonlinear signal processing <ref> [6, 9] </ref>.
Reference: [7] <author> I. Pitas and A. N. Venetsanopoulos, </author> <title> Non-linear Digital Filters Principles and Applications. </title> <address> Boston, MA: </address> <publisher> Kluwer, </publisher> <year> 1990. </year> <month> 25 </month>
Reference-contexts: Applications of nonlinear models and filtering include polynomial (Volterra) filters used in nonlinear channel equalization and system identification [4, 5, 6], and the class of order statistic filters used in image processing <ref> [7, 8] </ref>. Several adaptive nonlinear filters have also been developed based on Volterra and order statistic filters [9, 10, 11]. Consider now the case of an arbitrary nonlinear filter whose output is given by y y (w; x).
Reference: [8] <author> I. Pitas and A. Venetsanopoulos, </author> <title> "Order statistics in digital image processing," </title> <journal> Pro--ceedings of the IEEE, </journal> <volume> vol. 80, </volume> <month> Dec. </month> <year> 1992. </year>
Reference-contexts: Applications of nonlinear models and filtering include polynomial (Volterra) filters used in nonlinear channel equalization and system identification [4, 5, 6], and the class of order statistic filters used in image processing <ref> [7, 8] </ref>. Several adaptive nonlinear filters have also been developed based on Volterra and order statistic filters [9, 10, 11]. Consider now the case of an arbitrary nonlinear filter whose output is given by y y (w; x).
Reference: [9] <author> V. J. Mathews, </author> <title> "Adaptive polynomial filters," </title> <journal> Signal Processing Magazine, </journal> <volume> vol. 8, </volume> <pages> pp. 10-26, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Applications of nonlinear models and filtering include polynomial (Volterra) filters used in nonlinear channel equalization and system identification [4, 5, 6], and the class of order statistic filters used in image processing [7, 8]. Several adaptive nonlinear filters have also been developed based on Volterra and order statistic filters <ref> [9, 10, 11] </ref>. Consider now the case of an arbitrary nonlinear filter whose output is given by y y (w; x). <p> Consider now the special case of the Volterra filter, which has found wide-spread use in nonlinear signal processing <ref> [6, 9] </ref>.
Reference: [10] <author> I. Pitas and A. Venetsanopoulos, </author> <title> "Adaptive filters based on order statistics," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 39, </volume> <month> Feb. </month> <year> 1991. </year>
Reference-contexts: Applications of nonlinear models and filtering include polynomial (Volterra) filters used in nonlinear channel equalization and system identification [4, 5, 6], and the class of order statistic filters used in image processing [7, 8]. Several adaptive nonlinear filters have also been developed based on Volterra and order statistic filters <ref> [9, 10, 11] </ref>. Consider now the case of an arbitrary nonlinear filter whose output is given by y y (w; x).
Reference: [11] <author> D. W. Griffith and G. R. Arce, </author> <title> "Partially decoupled Volterra filters: Formulation and LMS adaptation," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 45, </volume> <month> June </month> <year> 1997. </year>
Reference-contexts: Applications of nonlinear models and filtering include polynomial (Volterra) filters used in nonlinear channel equalization and system identification [4, 5, 6], and the class of order statistic filters used in image processing [7, 8]. Several adaptive nonlinear filters have also been developed based on Volterra and order statistic filters <ref> [9, 10, 11] </ref>. Consider now the case of an arbitrary nonlinear filter whose output is given by y y (w; x).
Reference: [12] <author> F. Palmieri and C. G. Boncelet, Jr., </author> <title> "Ll filters Anew class of order statistic filters," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 37, </volume> <month> May </month> <year> 1989. </year>
Reference-contexts: Included in this class are linear filters, Ll filters based on order statistics <ref> [12, 13] </ref>, permutation filters (which are generalizations of both linear and order statistic filters) [14], and Volterra filters [4], among others.
Reference: [13] <author> P. Ghandi and S. A. Kassam, </author> <title> "Design and performance of combination filters," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 39, </volume> <month> July </month> <year> 1991. </year>
Reference-contexts: Included in this class are linear filters, Ll filters based on order statistics <ref> [12, 13] </ref>, permutation filters (which are generalizations of both linear and order statistic filters) [14], and Volterra filters [4], among others.
Reference: [14] <author> Y.-T. Kim and G. R. Arce, </author> <title> "Permutation filter lattices: A general order-statistic filtering framework," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 42, </volume> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: Included in this class are linear filters, Ll filters based on order statistics [12, 13], permutation filters (which are generalizations of both linear and order statistic filters) <ref> [14] </ref>, and Volterra filters [4], among others.
Reference: [15] <author> J. G. Gonzalez and G. R. Arce, </author> <title> "Weighted myriad filters: A robust filtering framework derived from ff-stable distributions," </title> <booktitle> in Proc. of the 1996 IEEE ICASSP, </booktitle> <address> (Atlanta, GA), </address> <year> 1996. </year>
Reference-contexts: Our simulations confirm this fact for the case of the second order Volterra filter (see Section 5). 4.2 Myriad Filters As a second example of nonlinear NLMS-type adaptive filtering, we consider the class of Weighted Myriad Filters, which have recently been developed for robust signal processing in impulsive environments <ref> [15, 16, 17, 18] </ref>. These filters have been derived based on the properties of the heavy-tailed class of ff-stable distributions [19], which accurately model impulsive processes. Nonlinear LMS-type adaptive algorithms have also been derived for the optimization of these filters [17].
Reference: [16] <author> J. G. Gonzalez and G. R. Arce, </author> <title> "Weighted myriad filters: A powerful framework for efficient filtering in impulsive environments," </title> <journal> IEEE Transactions on Signal Processing. </journal> <note> Manuscript in review. </note>
Reference-contexts: Our simulations confirm this fact for the case of the second order Volterra filter (see Section 5). 4.2 Myriad Filters As a second example of nonlinear NLMS-type adaptive filtering, we consider the class of Weighted Myriad Filters, which have recently been developed for robust signal processing in impulsive environments <ref> [15, 16, 17, 18] </ref>. These filters have been derived based on the properties of the heavy-tailed class of ff-stable distributions [19], which accurately model impulsive processes. Nonlinear LMS-type adaptive algorithms have also been derived for the optimization of these filters [17].
Reference: [17] <author> S. Kalluri and G. R. Arce, </author> <title> "Adaptive weighted myriad filter algorithms for robust signal processing in ff-stable noise environments," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 46, </volume> <pages> pp. 322-334, </pages> <month> Feb. </month> <year> 1998. </year> <month> 26 </month>
Reference-contexts: Our simulations confirm this fact for the case of the second order Volterra filter (see Section 5). 4.2 Myriad Filters As a second example of nonlinear NLMS-type adaptive filtering, we consider the class of Weighted Myriad Filters, which have recently been developed for robust signal processing in impulsive environments <ref> [15, 16, 17, 18] </ref>. These filters have been derived based on the properties of the heavy-tailed class of ff-stable distributions [19], which accurately model impulsive processes. Nonlinear LMS-type adaptive algorithms have also been derived for the optimization of these filters [17]. <p> These filters have been derived based on the properties of the heavy-tailed class of ff-stable distributions [19], which accurately model impulsive processes. Nonlinear LMS-type adaptive algorithms have also been derived for the optimization of these filters <ref> [17] </ref>.
Reference: [18] <author> S. Kalluri and G. R. Arce, </author> <title> "Robust frequency-selective filtering using weighted myriad filters admitting real-valued weights," </title> <journal> IEEE Transactions on Signal Processing. </journal> <note> Submitted for publication. </note>
Reference-contexts: Our simulations confirm this fact for the case of the second order Volterra filter (see Section 5). 4.2 Myriad Filters As a second example of nonlinear NLMS-type adaptive filtering, we consider the class of Weighted Myriad Filters, which have recently been developed for robust signal processing in impulsive environments <ref> [15, 16, 17, 18] </ref>. These filters have been derived based on the properties of the heavy-tailed class of ff-stable distributions [19], which accurately model impulsive processes. Nonlinear LMS-type adaptive algorithms have also been derived for the optimization of these filters [17]. <p> Now, it can be shown <ref> [18] </ref> that @y = where ffi i = i and N X jh j j j 1 + jh j j u 2 2 ; with u i = sgn (h i ) y x i ; i = 1; 2; : : : ; N: Substituting (46) into (8) and
Reference: [19] <author> C. L. Nikias and M. Shao, </author> <title> Signal Processing with Alpha-Stable Distributions and Applications. </title> <address> New York: </address> <publisher> Wiley, </publisher> <year> 1995. </year> <month> 27 </month>
Reference-contexts: These filters have been derived based on the properties of the heavy-tailed class of ff-stable distributions <ref> [19] </ref>, which accurately model impulsive processes. Nonlinear LMS-type adaptive algorithms have also been derived for the optimization of these filters [17]. <p> The desired signal d (n), also shown in the figure, is the sinusoid at the highest frequency, f 2 . The additive noise process v (n) was chosen to have a zero-mean symmetric ff-stable distribution <ref> [19] </ref> with a characteristic exponent ff = 1:6 and a dispersion fl = 0:02. Impulsive noise is well-modeled by the heavy-tailed class of ff-stable distributions, which includes the Gaussian distribution as the special case when ff = 2.
References-found: 19

