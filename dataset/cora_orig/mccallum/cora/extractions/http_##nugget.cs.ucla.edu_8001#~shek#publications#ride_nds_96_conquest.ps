URL: http://nugget.cs.ucla.edu:8001/~shek/publications/ride_nds_96_conquest.ps
Refering-URL: http://nugget.cs.ucla.edu:8001/~shek/publications/index.html
Root-URL: http://www.cs.ucla.edu
Title: On Heterogeneous Distributed Geoscientific Query Processing  
Author: Eddie C. Shek yz Edmond Mesrobian and Richard R. Muntz 
Address: Los Angeles, CA 90024 Malibu, CA 90265  
Affiliation: Computer Science Department Information Sciences Laboratory University of California Hughes Research Laboratories  
Abstract: Geoscience studies produce data from various observations, experiments, and simulations at an enormous rate. With proliferation of geographic applications, scientific data formats, and storage systems, interoperability remains an important geoscientific data management issue that is often overlooked in current geoscientific query processing research. In this paper, we present how some issues concerning interoperability in geoscientific query processing are addressed in the Conquest parallel geoscientific query processing system under development at UCLA. The design of Conquest is based on the Volcano extensive query processing system which encapsulates parallel computation through the exchange operator. Conquest extends the exchange operator to support multicasting of data streams and hide the heterogeneity in hardware and operating system platforms from users developing parallel geoscientific applications. The Conquest data model captures some important structural and semantic properties of common geoscientific datasets and is used as a canonical model for a wide variety of scientific and non-scientific datasets. In addition, Conquest supports a uniform interface to a variety of scientific data sources. Access to data managed by a remote data repository is optimized by "pushing" Conquest operators into data repositories to maximize use of local database capability and reduce the volume of data transfer between the data repositories and Conquest. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D.M. Butler and S. Bryson. </author> <title> Vector-bundle classes form powerful tool for scientific visualization. </title> <journal> Computers in Physics, </journal> <volume> 6(6) </volume> <pages> 576-584, </pages> <month> Nov/Dec </month> <year> 1992. </year>
Reference-contexts: Most notably, the differential geometry notion of fiber bundle has been recognized by several researchers as a useful abstraction for an object-oriented scientific visualization data model <ref> [1] </ref>. In brief, a fiber bundle is a space constructed by attaching a copy of a fiber space to each point in a base space. The field model borrowed this concept of space "bundling".
Reference: [2] <author> D.J. DeWitt, N. Kabra, J. Luo, J.M. Patel, and J. Yu. </author> <title> Client-server Paradise. </title> <booktitle> In Proc. 20th Int'l Conf. on VLDB, </booktitle> <pages> pages 558-569, </pages> <year> 1994. </year>
Reference-contexts: Geo fl This research supported by NASA under HPCC grant NAG-2225. graphic information systems such as ARC/INFO, geo-scientific database systems like Paradise <ref> [2] </ref>, and extensible database systems exemplified by Postgres [20] have made great strides towards effective management of a wide variety of spatial and scientific data objects.
Reference: [3] <author> W. Du, R. Krishnamurthy, and M.C. Shan. </author> <title> Query optimization in heterogeneous DBMSs. </title> <booktitle> In Proc. 18th Int'l Conf. on VLDB, </booktitle> <pages> pages 277-291, </pages> <year> 1992. </year>
Reference-contexts: Some work has been done on estimating the cost of query execution in autonomous database systems <ref> [3] </ref>. However, the problem remains an open one, especially for non-traditional data servers supporting spatio-temporal geoscientific data.
Reference: [4] <editor> A. Elmagarmid and C. Pu (eds.). </editor> <title> Special issue on heterogeneous distributed database systems. </title> <journal> ACM Computing Surveys, </journal> <volume> 22(3), </volume> <month> Sep </month> <year> 1990. </year>
Reference-contexts: Section 4 discusses techniques for optimizing access to heterogeneous data repositories. Finally, Section 5 concludes the paper with a brief summary and our outlook on future research in interoperability in geoscientific query processing. 2 Data Modeling An important issue in heterogeneous database system research <ref> [4] </ref> is that of the choice of a canonical data model into which data in heterogeneous repositories are mapped. This issue also exists for heterogeneous scientific databases.
Reference: [5] <author> J.C. </author> <title> French. Support for scientific database management. </title> <editor> In Z. Michalewicz, editor, </editor> <title> Statistical and Scientific Databases, </title> <booktitle> chapter 4, </booktitle> <pages> pages 51-82. </pages> <publisher> Ellis Horwood, </publisher> <address> New York, NY, </address> <year> 1991. </year>
Reference-contexts: 1 Introduction Research interest in problems presented by geosci-entific data and the unique data management requirements of scientific applications <ref> [5, 19] </ref> has significantly increased over the last few years. The importance of scientific database technology is expected to increase as geoscience studies continue to produce data from various observations, experiments, and simulations at an enormous rate.
Reference: [6] <author> G.A. Geist and V.S. Sunderam. </author> <title> Experiences with network-based concurrent computing on the PVM system. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 4(4), </volume> <month> Jun </month> <year> 1992. </year>
Reference-contexts: Conquest's extended-exchange operator extends the functionality of the exchange operator in several ways. * Heterogeneous supercomputing. Conquest deals with hardware heterogeneity by implementing interprocess communication using the portable message passing library PVM <ref> [6] </ref>. PVM enables a network of heterogeneous Unix machines to behave as a single parallel computer by transparently resolving architecture dependence in interprocess communication. The Conquest parallel query execution server has been ported to run on the IBM SP1 and SP2, the Intel Paragon, and Sun workstation farms.
Reference: [7] <author> G. Graefe. </author> <title> Query evaluation techniques for large databases. </title> <journal> ACM Computing Surveys, </journal> <volume> 25(2), </volume> <month> Jun </month> <year> 1993. </year>
Reference-contexts: In addition, many problems do not fit the stream paradigm (e.g., many matrix operations such as transformations used in linear algebra, Laplace or fast Fourier Transform, and slab multi-dimensional subarray extraction), and fit better into the storage management subsystem rather than the query execution engine <ref> [7] </ref>. As a result, it is often advantageous to optimize extraction of data from external data sources by pushing operations and filters into the data source to take advantage of efficient processing and reduce the amount of data that needs to be extracted out of the data source.
Reference: [8] <author> G. Graefe. </author> <title> Volcano an extensible and parallel query evaluation system. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 6(1) </volume> <pages> 120-135, </pages> <month> Feb </month> <year> 1994. </year>
Reference-contexts: A set of general purpose algebraic operators are defined for the model; among them are those whose main purpose is to resolve the heterogeneity in geosci entific data representations (e.g., interpolation). * Parallel Query Execution Environment. Similar to the Volcano extensible query processing system <ref> [8] </ref>, Conquest encapsulates parallel computation through the use of a "paralleliz-ing" operator. Conquest extends the Volcano exchange operator to support multicasting of data streams. In addition, inter-process communication in Conquest's extended-exchange operator masks the heterogeneity in hardware and operating system platforms from users developing parallel geoscientific applications. <p> of partitioned parallelism for different access patterns and to reduce the I/O bottleneck by allowing reading and writing of data in parallel. 3.1 The Conquest Extensible Parallel Query Execution System The design of the Conquest Parallel Query Execution System is based on that of the Volcano extensible query execution system <ref> [8] </ref>.
Reference: [9] <author> G. Graefe and W.J. McKenna. </author> <title> The Volcano optimizer generator: Extensibility and efficient search. </title> <booktitle> In Proc. 9th Int'l Conf. on Data Engineering, </booktitle> <pages> pages 209-218, </pages> <year> 1993. </year>
Reference-contexts: One notable exception can be found in [21] which describes a prototype scientific query optimizer constructed using the Volcano optimizer generator <ref> [9] </ref>. It focused on the optimization of computations over three bulk types: sets, time series, and spectra. Scientific operators considered include random sampling, digital filtering, interpolation, time series/spectra merging, spectra filtering, and FFT.
Reference: [10] <author> T. Y. C. Leung and R. R. Muntz. </author> <title> Temporal query processing and optimization in multiprocessor database machines. </title> <booktitle> In Proc. 18th Int'l Conf. on VLDB, </booktitle> <pages> pages 383-394, </pages> <year> 1992. </year>
Reference-contexts: Pipeline parallelism naturally supports stream query processing techniques which take advantage of data ordering to deliver excellent performance for many queries. A well-known class of such queries includes various parallel temporal join operations on multi-processor systems <ref> [10] </ref>. They provide good response time and minimize intermediate storage during parallel query execution. Most geo-scientific data have a time component, and scientists are often interested in studying the variation of data in time. As a result, dataflow processing promises to be an attractive evaluation paradigm for scientific queries.
Reference: [11] <author> C.R. Mechoso and J.D. </author> <title> Farrara an J.A. Spahr. Achieving superlinear speedup on a heterogeneous, distributed system. </title> <journal> IEEE Parallel and Distributed Technology: Systems and Applications, </journal> <volume> 2(2) </volume> <pages> 57-61, </pages> <month> Summer </month> <year> 1994. </year>
Reference-contexts: Operators in a query execution plan can be executed on processors with different architectures. Applications in which different phases can take advantage of the special benefits offered by the different architectures, su-perlinear speedup has been reported despite la tency and communication overheads <ref> [11] </ref>. * Data marshalling. Volcano's exchange operator assumes that data streams between operators are simple byte streams, with the interpretation left to the implementation of operators. However, complex geoscientific data structures have to be packaged before transfer to ensure correct transfer between platforms.
Reference: [12] <author> C.R. Mechoso, C.C. Ma, J.D. Farrara, and J.A. Spahr. </author> <title> Simulations of interannual variability with a coupled atmosphere-ocean general circulation model. </title> <booktitle> In Proceedings of 5th Conference on Climate Variations. American Meteorology Society, </booktitle> <year> 1991. </year>
Reference-contexts: For example, NASA EOS expects to produce over 1 TByte of raw data and scientific products per day by the year 2000, and a 100-year UCLA AGCM simulation <ref> [12] </ref> running at a resolution of 1 ffi fi 1:25 ffi with 57 levels generates approximately 30 TBytes of data when the model's output is written out to the database every 12 simulated hours.
Reference: [13] <author> E. Mesrobian, R.R. Muntz, E.C. Shek, S. Nit-tel, M. LaRouche, and M. Kreiger. OASIS: </author> <title> An open architecture scientific information system. </title> <booktitle> In Proc. of Sixth International Workshop on Research Issues in Data Engineering: Interoperability of Nontraditional Database Systems, </booktitle> <year> 1996. </year>
Reference-contexts: implemented scan operators which interface to a number of vastly different data repositories including: * Popular scientific data formats such as HDF [15] and netCDF containing multi-dimensional raster datasets. * Extended relational DBMS Postgres which us used as both a storage and an external content based index server. * OASIS <ref> [13] </ref> CORBA distributed objects encapsulating OGIS-compliant geographic objects such as multi-dimensional cellular grid coverages (i.e., arrays) and feature buckets (which are collections of complex spatial data objects). * A "live" scientific data generation application. <p> include automatic optimization of geoscientific queries in both MPP and heterogeneous supercomputing (mixed workstation and MPP) environments, systematic characterization and classification of user-defined scientific operators for paral-lelization, adaptive reconfiguration of query execution plan at run-time, and the application of Distributed Object Management technology such as CORBA in geoscientific query processing <ref> [13] </ref>. Extensibility, heterogeneity, and high performance are not characteristics unique for geoscientific database applications. Instead, they exist in a wide spectrum of advanced applications to which the approaches we develop in this research to address heterogeneous distributed geoscientific query processing should also be applicable.
Reference: [14] <author> E. Mesrobian, R.R. Muntz, E.C. Shek, J.R. San-tos, J. Yi, K. Ng, S.Y. Chien, C.R. Mechoso, J.D. Farrara, P. Stolorz, and H. Nakamura. </author> <title> Exploratory data mining and analysis using Conquest. </title> <booktitle> In Proc. of IEEE Pacific Rim Conference on Communications, Computers, Visualization, and Signal Processing, </booktitle> <year> 1995. </year>
Reference-contexts: At UCLA, we are developing an extensible parallel geoscientific query processing system called Conquest. Conquest is designed to handle complex scientific queries on large geoscientific datasets (such as those found in geoscientific data mining <ref> [14] </ref>) in a potentially heterogeneous environment. In this paper, we discuss how the design of Conquest addresses issues of interoperability without losing sight of the need for extensibility and high-performance. * Data Modeling.
Reference: [15] <institution> National Center for Supercomputing Applications. </institution> <note> HDF User's Guide, Version 3.2, </note> <year> 1993. </year>
Reference-contexts: Conquest supports access to a number of databases, file formats, and legacy data sources by means data repository specific access operators. Currently, we have implemented scan operators which interface to a number of vastly different data repositories including: * Popular scientific data formats such as HDF <ref> [15] </ref> and netCDF containing multi-dimensional raster datasets. * Extended relational DBMS Postgres which us used as both a storage and an external content based index server. * OASIS [13] CORBA distributed objects encapsulating OGIS-compliant geographic objects such as multi-dimensional cellular grid coverages (i.e., arrays) and feature buckets (which are collections of
Reference: [16] <author> The OGIS Project Participants. </author> <title> The Open Geo-data Interoperability Specification. </title> <type> Technical report, </type> <institution> OGIS, </institution> <year> 1994. </year>
Reference-contexts: The field model borrowed this concept of space "bundling". However, research in scientific visualization modeling concentrates mainly on the mathematical basis of data models and typically ignores physical data management issues like query optimization, parallelization, and storage layout. The Open Geodata Interoperability Specification (OGIS) <ref> [16] </ref> specifies a data model for geographic data, as well as an application programming model aiming to enable communication and interoperability between geographic applications. It defines an object-oriented model of geographic information which covers at most 3 spatial dimensions and a temporal dimension.
Reference: [17] <institution> Research Systems, Inc. </institution> <note> IDL User's Guide (Version 3.1), </note> <year> 1993. </year>
Reference-contexts: to encompass the wide variety of scientific observation and simulation data. 2.1 Related Work The formulation of the Conquest data model is similar to existing geoscientific data models (e.g., the Spatial Archive and Interchange Format [18], and those defined in popular scientific data analysis and visualization systems such as IDL <ref> [17] </ref>) since our ultimate goal is for the model to be used as a canonical model in a heterogeneous geoscientific query processing environment. Most notably, the differential geometry notion of fiber bundle has been recognized by several researchers as a useful abstraction for an object-oriented scientific visualization data model [1].
Reference: [18] <author> SAIF. </author> <title> Spatial archive and interchange format: Formal definition (release 3.1). </title> <type> Technical report, </type> <institution> Surveys and Resource Mapping Branch, Ministry of Environment, Lands and Parks,, British Columbia, Canada, </institution> <month> Apr </month> <year> 1994. </year>
Reference-contexts: goal of the data model is to provide a rich but conceptually simple data model to encompass the wide variety of scientific observation and simulation data. 2.1 Related Work The formulation of the Conquest data model is similar to existing geoscientific data models (e.g., the Spatial Archive and Interchange Format <ref> [18] </ref>, and those defined in popular scientific data analysis and visualization systems such as IDL [17]) since our ultimate goal is for the model to be used as a canonical model in a heterogeneous geoscientific query processing environment.
Reference: [19] <author> A. Shoshani. </author> <title> Properties of statistical and scientific databases. </title> <editor> In Z. Michalewicz, editor, </editor> <title> Statistical and Scientific Databases, </title> <booktitle> chapter 1, </booktitle> <pages> pages 11-34. </pages> <publisher> Ellis Horwood, </publisher> <address> New York, NY, </address> <year> 1991. </year>
Reference-contexts: 1 Introduction Research interest in problems presented by geosci-entific data and the unique data management requirements of scientific applications <ref> [5, 19] </ref> has significantly increased over the last few years. The importance of scientific database technology is expected to increase as geoscience studies continue to produce data from various observations, experiments, and simulations at an enormous rate.
Reference: [20] <author> M. Stonebraker and G. Kemnitz. </author> <title> The Postgres next generation database management system. </title> <journal> Communications of the ACM, </journal> <volume> 34(1), </volume> <month> Jan </month> <year> 1991. </year>
Reference-contexts: Geo fl This research supported by NASA under HPCC grant NAG-2225. graphic information systems such as ARC/INFO, geo-scientific database systems like Paradise [2], and extensible database systems exemplified by Postgres <ref> [20] </ref> have made great strides towards effective management of a wide variety of spatial and scientific data objects.
Reference: [21] <author> R. H. Wolniewicz and G. Graefe. </author> <title> Algebraic optimization of computations over scientific databases. </title> <booktitle> In Proc. 19th Int'l Conf. on VLDB, </booktitle> <year> 1993. </year>
Reference-contexts: n dimensions is specified as a n-dimensional bounding box containing all coordinate attribute values. 2.3 Conquest Algebraic Operators An important feature of the model is the inclusion of an extensible algebra which allows algebraic transformation techniques similar to that used in many relational DBMSs to be applied to geoscientific queries <ref> [21] </ref>. The algebra contains a base set of general purpose logical data manipulation operators, while users are allowed to introduce operators corresponding to application-specific algorithms. It allows scientists to conveniently express their intentions by functionally combining complex scientific data manipulation operators within the Conquest algebra framework. <p> One notable exception can be found in <ref> [21] </ref> which describes a prototype scientific query optimizer constructed using the Volcano optimizer generator [9]. It focused on the optimization of computations over three bulk types: sets, time series, and spectra. Scientific operators considered include random sampling, digital filtering, interpolation, time series/spectra merging, spectra filtering, and FFT.
References-found: 21

