URL: http://www.cs.umd.edu/users/debanjan/psfiles/tpds96.ps
Refering-URL: http://www.cs.umd.edu/users/debanjan/pages/onepage.html
Root-URL: 
Title: An Analysis of the Average Message Overhead in Replica Control Protocols 1  
Author: Debanjan Saha Sampath Rangarajan Satish K. Tripathi 
Keyword: Replica Control, Quorum Consensus, Replicated Databases, Message Over head, Availability, Update Synchronization.  
Abstract: Management of replicated data has received considerable attention in the last few years. Several replica control schemes have been proposed which work in the presence of both node and communication link failures. However, this resiliency to failure inflicts a performance penalty in terms of the communication overhead incurred. Though the issue of performance of these schemes from the standpoint of availability of the system has been well addressed, the issue of message overhead has been limited to the analysis of worst case and best case message bounds. In this paper we derive expressions for computing the average message overhead of several well known replica control protocols and provide a comparative study of the different protocols with respect to both average message overhead and system availabilities. 1 A preliminary version of this paper appeared in the Proceedings of the International Conference on Dis 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Agarawal and A. El Abbadi, </author> <title> "An Efficient Fault-tolerant Solution to the Mutual Exclusion Problem," </title> <journal> ACM Transaction on Computer Systems, </journal> <volume> vol. 9, no. 1, </volume> <pages> pp. 1-20, </pages> <month> Feb. </month> <year> 1991. </year>
Reference-contexts: There are some quorum consensus protocols that are based on logical organization of the nodes. Agrawal and Abbadi <ref> [1] </ref> proposed a protocol in which the nodes are organized in a logical binary tree. Any set of nodes forming a path from the root to a leaf of this logical tree forms a quorum group. <p> We consider the following well known replica control protocols: * The majority voting protocol [12]. * The tree protocol <ref> [1] </ref>. * The grid protocol [2]. 4 * The hierarchical quorum consensus (HQC) protocol [8]. * The RST protocol [11]. For each of the above protocols we compute the average case message overhead and availability and consider the trade-off between the two. <p> This process is continued until permission messages are received from all the nodes to whom messages were sent in the previous round, or a situation is reached where it is determined by the initiating node that a quorum cannot be obtained. For a detailed description of this protocol, see <ref> [1] </ref>. The following recurrence holds for M T ree (p; d), which denotes the average number of request messages sent by the initiating node until the protocol terminates (either successfully or unsuccessfully), where the depth of the tree is d and p is the steady-state availability of a node. <p> Best case and worst case message overhead analysis for the respective protocols have been shown in <ref> [1, 2, 8] </ref> and can be compared with our average case message overhead results. The plots are provided for all the protocols that we have analyzed and for system sizes varying from N = 32 to N = 1024.
Reference: [2] <author> S. Y. Cheung, M. H. Ammar and M. Ahamad, </author> <title> "The Grid Protocol: A High Performance Scheme for Maintaining Replicated Data," </title> <booktitle> Proceedings of the Sixth International Conference on Data Engineering, </booktitle> <pages> pp. 438-445, </pages> <year> 1990. </year>
Reference-contexts: If a faulty node is encountered on this path, it can be substituted in the quorum group by nodes on two paths starting from the two children of the faulty node; and this is done recursively. Cheung, Ahamad and Ammar <ref> [2] </ref> suggest a logical two dimensional grid organization of the nodes. Each read quorum group contains at least one node from each column and a write quorum group consists of all nodes of one of the columns plus the nodes in a read quorum group. <p> We consider the following well known replica control protocols: * The majority voting protocol [12]. * The tree protocol [1]. * The grid protocol <ref> [2] </ref>. 4 * The hierarchical quorum consensus (HQC) protocol [8]. * The RST protocol [11]. For each of the above protocols we compute the average case message overhead and availability and consider the trade-off between the two. We further compare these performance parameters across the different protocols. <p> Best case and worst case message overhead analysis for the respective protocols have been shown in <ref> [1, 2, 8] </ref> and can be compared with our average case message overhead results. The plots are provided for all the protocols that we have analyzed and for system sizes varying from N = 32 to N = 1024.
Reference: [3] <author> M. Ahamad, M. H. Ammar and S. Y. Cheung, </author> <title> "Multi-Dimensional Voting," </title> <journal> ACM Trans. on Computer Systems, </journal> <pages> pp. 399-431, </pages> <month> Nov. </month> <year> 1991. </year>
Reference: [4] <author> P. A. Bernstein, V. Hadzilacos and N. Goodman, </author> <title> Concurrency Control and Recovery in Database Systems, </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: Replication, however, burdens the system with added responsibility of maintaining consistency among different copies of the same data. A replica control protocol is essentially a protocol for "synchronizing" concurrent read and write operations on a replicated data object by different concurrent transactions. To ensure one-copy serializability <ref> [4] </ref>, a read and a write operation to two different copies of the data (residing in two different "nodes" in the system) should not be allowed to execute concurrently. Also, two write requests to two different copies of the data should not be allowed to simultaneously update the copies.
Reference: [5] <author> A. El Abbadi, D. Skeen and F. Cristian, </author> <title> "An Efficient Fault Tolerant Protocol for Replicated Data Management," </title> <booktitle> Proceedings of the Symposium on Principles of Database Systems, </booktitle> <pages> pp. 215-228, </pages> <year> 1985. </year>
Reference: [6] <author> D. K. Gifford, </author> <title> "Weighted Voting for Replicated Data," </title> <booktitle> Proceedings of the Seventh Symposium on Operating System Principles, </booktitle> <pages> pp. 150-159, </pages> <year> 1979. </year>
Reference-contexts: The simplest replica control protocol is the Majority Voting protocol suggested by Thomas [12]. In this protocol a node can proceed with an operation only if it gets permission from a majority of other nodes in the system. This has been generalized by Gifford <ref> [6] </ref> to what is called the Weighted Voting protocol in which different weights may be assigned to each node. A node needs a majority of the sum of all weights before it can proceed with an operation.
Reference: [7] <author> S. Jajodia and D. Mutchler, </author> <title> "Dynamic Voting," </title> <booktitle> Proceedings of SIGMOD, </booktitle> <pages> pp. 227-238, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: Different quorum groups could be used for read and write operations, and these are referred to as read quorum and write quorum, respectively. 2 Several variants of the basic protocol have been suggested over the years, including protocols for dynamically changing vote assignment and quorum sizes <ref> [7] </ref> [9]. There are some quorum consensus protocols that are based on logical organization of the nodes. Agrawal and Abbadi [1] proposed a protocol in which the nodes are organized in a logical binary tree.
Reference: [8] <author> A. Kumar, </author> <title> "Hierarchical Quorum Consensus: A New Algorithm for Managing Replicated Data," </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. 40, no. 9, </volume> <pages> pp. 996-1004, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: Each read quorum group contains at least one node from each column and a write quorum group consists of all nodes of one of the columns plus the nodes in a read quorum group. In the hierarchical quorum consensus protocol <ref> [8] </ref>, the nodes are organized in a multilevel hierarchy with physical nodes at the lowest level of the hierarchy. Higher level "logical" nodes of the tree correspond to logical groups of the physical nodes. <p> We consider the following well known replica control protocols: * The majority voting protocol [12]. * The tree protocol [1]. * The grid protocol [2]. 4 * The hierarchical quorum consensus (HQC) protocol <ref> [8] </ref>. * The RST protocol [11]. For each of the above protocols we compute the average case message overhead and availability and consider the trade-off between the two. We further compare these performance parameters across the different protocols. <p> A GR (p; n r ; n c ) = (1 q n r )A GR (p; n r ; n c 1); n c &gt; 0 1; otherwise: 3.4 Hierarchical Quorum Consensus (HQC) The logical organization adopted in the HQC protocol <ref> [8] </ref> is a l level hierarchy with physical nodes at the lowest level. A node at the ith level of the hierarchy represents a logical subgroup consisting of n i of (i 1)st level nodes. <p> Best case and worst case message overhead analysis for the respective protocols have been shown in <ref> [1, 2, 8] </ref> and can be compared with our average case message overhead results. The plots are provided for all the protocols that we have analyzed and for system sizes varying from N = 32 to N = 1024.
Reference: [9] <author> J. F. Paris and D. </author> <title> Long, "Efficient Dynamic Voting," </title> <booktitle> Proceedings of the International Conference on Data Engineering, </booktitle> <month> January </month> <year> 1988. </year>
Reference-contexts: Different quorum groups could be used for read and write operations, and these are referred to as read quorum and write quorum, respectively. 2 Several variants of the basic protocol have been suggested over the years, including protocols for dynamically changing vote assignment and quorum sizes [7] <ref> [9] </ref>. There are some quorum consensus protocols that are based on logical organization of the nodes. Agrawal and Abbadi [1] proposed a protocol in which the nodes are organized in a logical binary tree.
Reference: [10] <author> D.A. Menasce, Y. Yesha and K. Kalpakis, </author> <title> "On a Unified Framework for the Evaluation of Distributed Quorum Attainment Protocols", </title> <journal> IEEE Transactions on Software Engineering, </journal> <pages> pp. 868-884, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Such a bounded fault-set model does not allow average case analysis. In this paper, in order to perform an average case analysis, we assume a probabilistic model <ref> [10] </ref> for failures. We assume that node failures are independent and use p to denote the steady-state probability that a node is non-faulty and is available to take part in the replica control procedure.
Reference: [11] <author> S. Rangarajan, S. Setia and S. K. Tripathi, </author> <title> "A Fault-Tolerant Algorithm for Replicated Data Management," </title> <booktitle> Proceedings of the Eighth International Conference on Data Engineering, </booktitle> <pages> pp. 230-237, </pages> <month> February </month> <year> 1992. </year> <note> Also, to appear in the IEEE Transactions on Parallel and Distributed Systems. </note>
Reference-contexts: We consider the following well known replica control protocols: * The majority voting protocol [12]. * The tree protocol [1]. * The grid protocol [2]. 4 * The hierarchical quorum consensus (HQC) protocol [8]. * The RST protocol <ref> [11] </ref>. For each of the above protocols we compute the average case message overhead and availability and consider the trade-off between the two. We further compare these performance parameters across the different protocols. <p> Substituting this for p in A Maj (p; n l1 =2+1; n l1 ), we get the first part of the above recurrence. It is easy to observe that when l is 1 A HQC (p; l) is p. 3.5 RST protocol In the RST protocol <ref> [11] </ref>, nodes are grouped into N G groups of G nodes each. Each such group is called a subgroup. Then, N G quorum groups are constructed such that each quorum group is made up of K = q G subgroups with each subgroup containing G nodes. <p> As our analysis suggests, the gap between the average message overhead of the majority protocol and the other four protocols widens when the system size is increased. Figure 5 shows that with increased system sizes, the system availability of the grid protocol gradually becomes worse. It can be shown <ref> [11] </ref> that when the system size is asymptotically increased, all the protocols that we have considered except the grid protocol see an asymptotic increase in their system availabilities. For node availabilities greater than 0:9 all the protocols except the grid protocol, have comparable system availabilities.
Reference: [12] <author> R. H. Thomas, </author> <title> "A Majority Consensus Approach to Concurrency Control for Multiple Copy Databases," </title> <journal> ACM Transactions on Database Systems, </journal> <volume> vol. 4, no. 2, </volume> <pages> pp. 180-209, </pages> <month> June </month> <year> 1979. </year> <note> 18 (bottom). 19 20 and in a 64-node system (bottom). 21 (bottom). 22 23 and in a 256-node system (bottom) 24 (bottom). 25 26 and in a 1024-node system (bottom) 27 </note>
Reference-contexts: Also, two write requests to two different copies of the data should not be allowed to simultaneously update the copies. The simplest replica control protocol is the Majority Voting protocol suggested by Thomas <ref> [12] </ref>. In this protocol a node can proceed with an operation only if it gets permission from a majority of other nodes in the system. This has been generalized by Gifford [6] to what is called the Weighted Voting protocol in which different weights may be assigned to each node. <p> We assume that node failures are independent and use p to denote the steady-state probability that a node is non-faulty and is available to take part in the replica control procedure. We consider the following well known replica control protocols: * The majority voting protocol <ref> [12] </ref>. * The tree protocol [1]. * The grid protocol [2]. 4 * The hierarchical quorum consensus (HQC) protocol [8]. * The RST protocol [11]. For each of the above protocols we compute the average case message overhead and availability and consider the trade-off between the two.
References-found: 12

