URL: http://www.cs.wisc.edu/~shoup/papers/quadfactor.ps.Z
Refering-URL: http://www.cs.wisc.edu/~shoup/papers/
Root-URL: 
Title: A Fast Deterministic Algorithm for Factoring Polynomials over Finite Fields of Small Characteristic  
Author: Victor Shoup 
Note: Appeared in Proc. 1991 International Symposium on Symbolic and Algebraic Computation (ISSAC), pp. 14-21, 1991.  
Address: Toronto, Ontario M5S 1A4  
Affiliation: Computer Sciences Department University of Toronto  
Abstract: We present a new algorithm for factoring polynomials over finite fields. Our algorithm is deterministic, and its running time is "almost" quadratic when the characteristic is a small fixed prime. As such, our algorithm is asymptotically faster than previously known deterministic algorithms for factoring polynomials over finite fields of small characteristic. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W. Baur and V. Strassen. </author> <title> The complexity of computing partial derivatives. </title> <journal> Theoretical Computer Science, </journal> <volume> 22 </volume> <pages> 317-330, </pages> <year> 1983. </year>
Reference-contexts: There are general methods by which one can transform an algorithm for computing the matrix-vector product Ax into an algorithm with the same asymptotic running time for computing A T x <ref> [1, 11] </ref>. Since computing V x is known to take O (M (t) log t) R-operations, the same bound applies to computing V T x. The algorithms that result from these general transformations are quite "unnatural," and moreover, require space proportional to their running times.
Reference: [2] <author> M. Ben-Or. </author> <title> Probabilistic algorithms in finite fields. </title> <booktitle> In 22nd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 394-398, </pages> <year> 1981. </year>
Reference-contexts: Finally, if probabilistic algorithms are allowed, then the running time bounds stated in Results 1 and 2 above have already been obtained with the algorithms of Ben-Or <ref> [2] </ref> and Cantor/Zassenhaus [9]. The significance of our results is that our algorithm is deterministic. 2. Overview In this section, we outline the main ingredients of our algorithm, along the way comparing our algorithm with other known algorithms.
Reference: [3] <author> E. R. Berlekamp. </author> <title> Factoring polynomials over large finite fields. </title> <journal> Math. Comp., </journal> <volume> 24(111) </volume> <pages> 713-735, </pages> <year> 1970. </year>
Reference-contexts: Currently, the best value for ! is ! 2:376 [10]. In order to achieve our running time bounds, our algorithm avoids linear algebra. Our algorithm is actually a generalization of Berlekamp's trace algorithm for root finding <ref> [3] </ref>. This algorithm involves the computation of many trace functions; if computed separately, the cost of computing these trace functions would be too much. <p> The computation of a separating set turns out to be the bottleneck in deterministic factoring algorithms, so we consider some of the known methods for this computation. The oldest method goes back to Berlekamp <ref> [3] </ref>. Any F p -basis for A is clearly a separating set. Furthermore, A is easily seen to be the kernel of the F p -linear map ff 7! ff p ff. <p> Thus, we can compute the elements of S 0 in time ~ O (m (dk) 2 ). Generalizing the idea of Berlekamp's trace algorithm for root finding <ref> [3] </ref>, we can use a relative 4 separating set S to construct a separating set S 0 as follows. Let T B=A be the map that sends ff 2 R to ff + ff p + + ff p k1 .
Reference: [4] <author> A. Borodin and I. Munro. </author> <title> The Computational Complexity of Algebraic and Numeric Problems. </title> <publisher> American Elsevier, </publisher> <year> 1975. </year>
Reference-contexts: We quote the following well-known results; the proofs can be found, e.g., in <ref> [4] </ref>. Theorem 2.1. Let R be a ring, and let F be a field. (1) Let f be a monic polynomial in R [X] of degree t.
Reference: [5] <author> D. A. Burgess. </author> <title> A note on the distribution of residues and non-residues. </title> <journal> Jour. London Math. Soc., </journal> <volume> 38 </volume> <pages> 253-256, </pages> <year> 1963. </year>
Reference-contexts: Remark. Several authors have fallaciously drawn the inference that the fact that the maximum number of consecutive quadratic residues or nonresidues mod p is O (p 1=4 log p) (see <ref> [5] </ref>) implies that polynomials over a finite field of characteristic p can be factored in time proportional to p 1=4 times a polynomial in the input size.
Reference: [6] <author> P. Camion. </author> <title> Improving an algorithm for factoring polynomials over a finite field and constructing large irreducible polynomials. </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> IT-29(3):378- 385, </volume> <year> 1983. </year>
Reference-contexts: Our approach to computing a separating set begins by computing a relative separating set. One method for computing a relative separating set, which is described by Camion <ref> [6] </ref>, runs as follows. Let T R=B be the map that sends ff 2 R to ff + ff q + + ff q d1 . <p> So T R=B acts on R (i) as the trace from F q d down to F q (and hence is a F q -linear map from R onto B). In <ref> [6] </ref>, it is shown that the set fT R=B ( ) : 0 &lt; 2dg is a relative separating set. One application of T R=B requires O (dk) R-operations.
Reference: [7] <author> J. F. Canny, E. Kaltofen, and L. Yagati. </author> <title> Solving systems of non-linear polynomial equations faster. </title> <booktitle> In Proc. ACM-SIGSAM Int. Symp. on Symbolic and Algebraic Computation, </booktitle> <pages> pages 121-128, </pages> <year> 1989. </year>
Reference-contexts: We mention two other methods for solving this problem. One is described in <ref> [7] </ref>, where it is assumed that R is a field and that the ff i 's are distinct. It has the same time and space complexity as ours. This algorithm works by first computing y = V 1 x, and then applying the Hankel matrix V T V to y.
Reference: [8] <author> D. G. Cantor and E. Kaltofen. </author> <title> Fast multiplication of polynomials over arbitrary rings. </title> <type> Technical Report 87-35, </type> <institution> Department of Computer Science, Rensselaer Polytechnic Institute, </institution> <year> 1987. </year> <note> To appear, Acta. </note> <institution> Inf. </institution>
Reference-contexts: For a field F , by an F -operation, we mean addition, subtraction, multiplication, or division of two elements of F . We let M (t) denote the number of R-operations required to compute the product of two degree t polynomials in R [X]. 2 It is shown in <ref> [8] </ref> that M (t) = O (t log t log log t). We quote the following well-known results; the proofs can be found, e.g., in [4]. Theorem 2.1.
Reference: [9] <author> D. G. Cantor and H. Zassenhaus. </author> <title> A new algorithm for factoring polynomials over finite fields. </title> <journal> Math. Comp., </journal> <volume> 36(154) </volume> <pages> 587-592, </pages> <year> 1981. </year>
Reference-contexts: Finally, if probabilistic algorithms are allowed, then the running time bounds stated in Results 1 and 2 above have already been obtained with the algorithms of Ben-Or [2] and Cantor/Zassenhaus <ref> [9] </ref>. The significance of our results is that our algorithm is deterministic. 2. Overview In this section, we outline the main ingredients of our algorithm, along the way comparing our algorithm with other known algorithms. We begin by summarizing some well-known facts about the complexity of various arithmetic operations.
Reference: [10] <author> D. Coppersmith and S. Winograd. </author> <title> Matrix multiplication via Behrend's method. </title> <booktitle> In 19th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 1-6, </pages> <year> 1987. </year>
Reference-contexts: Using linear algebra techniques, the general factoring problem can be solved in time O ((nk) ! ), where ! is the exponent of matrix multiplication (see [15]). Currently, the best value for ! is ! 2:376 <ref> [10] </ref>. In order to achieve our running time bounds, our algorithm avoids linear algebra. Our algorithm is actually a generalization of Berlekamp's trace algorithm for root finding [3].
Reference: [11] <author> M. Kaminski, D. G. Kirkpatrick, and N. H. Bshouty. </author> <title> Addition requirements for matrix and transposed matrix products. </title> <journal> Journal of Algorithms, </journal> <volume> 9 </volume> <pages> 354-364, </pages> <year> 1988. </year>
Reference-contexts: There are general methods by which one can transform an algorithm for computing the matrix-vector product Ax into an algorithm with the same asymptotic running time for computing A T x <ref> [1, 11] </ref>. Since computing V x is known to take O (M (t) log t) R-operations, the same bound applies to computing V T x. The algorithms that result from these general transformations are quite "unnatural," and moreover, require space proportional to their running times.
Reference: [12] <author> R. T. Moenck. </author> <title> On the efficiency of algorithms for polynomial factoring. </title> <journal> Math. Comp., </journal> <volume> 31(137) </volume> <pages> 235-250, </pages> <year> 1977. </year>
Reference-contexts: This is accomplished by using the fact that the polynomial X q i X is the product of all distinct monic irreducible polynomials whose degree divides i. We refer the reader to <ref> [12] </ref> for details, and note that using fast algorithms for polynomial arithmetic, we can perform the distinct degree factorization process in time ~ O ((nk) 2 ). <p> Our factoring algorithm proceeds as follows. First, we reduce the general factoring problem to the equal degree factoring problem by first performing distinct degree factorization. This can be done with log p ~ O ((nk) 2 ) F p -operations (see <ref> [12] </ref>). We therefore assume that f is the product of m distinct monic irreducible polynomials of degree d. All of the notation and terminology introduced in Section 2 is now in force. Second, we compute the separating set S 1 described in Section 2.
Reference: [13] <author> V. Shoup. </author> <title> On the deterministic complexity of factoring polynomials over finite fields. </title> <journal> Inform. Process. Lett., </journal> <volume> 33(5) </volume> <pages> 261-267, </pages> <year> 1990. </year>
Reference-contexts: In the next section, this compar ison is done in greater detail. In the case where k = 1, and we are factoring over the prime field F p , the running time ~ O (n 2 ) was previously obtained by the algorithm of the present author in <ref> [13] </ref>. The method described in that paper does not appear to generalize to large extensions of F p . Using linear algebra techniques, the general factoring problem can be solved in time O ((nk) ! ), where ! is the exponent of matrix multiplication (see [15]). <p> One application of T R=B requires O (dk) R-operations. The obvious method for computing the elements in this relative separating set requires 2d such applications, and hence takes time ~ O (md 3 k 2 ). Our method for constructing a relative separating set, described in <ref> [13] </ref>, is the following. Con sider the ring R [Y ] of univariate polynomials over R. Let h = (Y )(Y q ) (Y q d1 ) 2 R [Y ], and write h = h 0 + h 1 Y + h d1 Y d1 + Y d . <p> Con sider the ring R [Y ] of univariate polynomials over R. Let h = (Y )(Y q ) (Y q d1 ) 2 R [Y ], and write h = h 0 + h 1 Y + h d1 Y d1 + Y d . In <ref> [13] </ref> it is shown that the set S 0 = fh i : 0 i &lt; dg is a relative separating set; this fact follows directly from the observation that h (j) i is the coefficient of X i in f j . <p> using the separating set S 1 , which contains dk elements, the number of F p - operations used by our factorization procedure is easily seen to be bounded by log p ~ O (m (dk) 2 ) + B (p) log p ~ O (mdk min (m; dk)): In <ref> [13] </ref> it was shown that B (p) = O (p 1=2 log p). It was subsequently shown in [14] that B (p) = O (p 1=2 ). Putting all of this together, we can state our results as follows: Theorem 4.1. 1.
Reference: [14] <author> I. E. Shparlinsky. </author> <title> On some questions in the theory of finite fields. </title> <type> Preprint, </type> <year> 1990. </year>
Reference-contexts: It was subsequently shown in <ref> [14] </ref> that B (p) = O (p 1=2 ). Putting all of this together, we can state our results as follows: Theorem 4.1. 1.
Reference: [15] <author> J. von zur Gathen. </author> <title> Factoring polynomials and primitive elements for special primes. </title> <journal> Theoret. Comput. Sci., </journal> <volume> 52 </volume> <pages> 77-89, </pages> <year> 1987. </year> <month> 10 </month>
Reference-contexts: The method described in that paper does not appear to generalize to large extensions of F p . Using linear algebra techniques, the general factoring problem can be solved in time O ((nk) ! ), where ! is the exponent of matrix multiplication (see <ref> [15] </ref>). Currently, the best value for ! is ! 2:376 [10]. In order to achieve our running time bounds, our algorithm avoids linear algebra. Our algorithm is actually a generalization of Berlekamp's trace algorithm for root finding [3].
References-found: 15

