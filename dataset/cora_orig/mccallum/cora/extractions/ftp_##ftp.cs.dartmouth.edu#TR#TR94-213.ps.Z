URL: ftp://ftp.cs.dartmouth.edu/TR/TR94-213.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/reports/abstracts/TR94-213/
Root-URL: http://www.cs.dartmouth.edu
Email: email: karger@cs.stanford.edu  email: cliff@cs.dartmouth.edu  email: wein@mem.poly.edu  
Title: Job Scheduling in Rings  
Author: Perry Fizzano David Karger Clifford Stein Joel Wein 
Note: Research supported by a Hertz Foundation Graduate Fellowship and by NSF Young Investigator Award CCR-9357849, with matching funds from IBM, Schlumberger Foundation, Shell Foundation and Xe-rox Corporation.  Research partially supported by NSF grant CCR-9308701, a Wal-ter Burke Research Initiation Award and a Dartmouth College Research Initiation Award.  Research partially supported by NSF grant CCR-9211494 and a grant from the New York State Science and Technology Foundation, Center for Advanced Technology in Telecommunications. Part of this work was done while the author was visiting DIMACS.  
Address: Hanover, NH  Stanford, CA  Hanover, NH  Brooklyn, NY  
Affiliation: Department of Math and CS Dartmouth College  Department of Computer Science Stanford University  Department of Math and CS Dartmouth College  Department of Computer Science Polytechnic University  
Abstract: We give distributed approximation algorithms for job scheduling in a ring architecture. In contrast to almost all other parallel scheduling models, the model we consider captures the influence of the underlying communications network by specifying that task migration from one processor to another takes time proportional to the distance between those two processors in the network. As a result, our algorithms must balance both computational load and communication time. The algorithms are simple, require no global control, and work in a variety of settings. All come with small constant-factor approximation guarantees; the basic algorithm yields schedules of length at most 4:22 times optimal. We also give a lower bound on the performance of any distributed algorithm and the results of simulation experiments, which give better results than our worst-case analysis. fl Research partially supported by NSF grant CCR-9308701, a Wal-ter Burke Research Initiation Award and a Dartmouth College Research Initiation Award. email: perry@cs.dartmouth.edu
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W. Aiello, B. Awerbuch, B. Maggs, and S. Rao. </author> <title> Approximate load balancing on dynamic and asynchronous networks. </title> <booktitle> In Proceedings of the 25th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 632-641, </pages> <year> 1993. </year>
Reference-contexts: If algorithm A always yields a schedule of length no more than L (I) + O (1) we call A a -approximation algorithm. Note that this problem is related to, but different from, load balancing, which is another common problem in parallel and distributed systems (see <ref> [1, 8] </ref>). In the load balancing problem one is given a set of tasks or tokens and must distribute the tasks so that each processor in the system has approximately the same number.
Reference: [2] <author> F. Allen, M. Burke, P. Charles, R. Cytron, and J. Ferrante. </author> <title> An overview of the ptran analysis system for multiprocessing. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5 </volume> <pages> 617-640, </pages> <year> 1988. </year>
Reference-contexts: Simply put, the problem is to assign each of a set of independent tasks to processors in the system so as to finish the processing of the set of tasks as quickly as possible. Job scheduling arises frequently in parallel computing, for example in algorithms for automatic loop parallelization <ref> [2, 10, 11, 18] </ref> or in the use of a parallel system to process batches of transactions or independent sequential programs. We restrict our attention to the ring, which is an important network in both theory and practice.
Reference: [3] <author> H. Attiya, M. Snir, and M. Warmuth. </author> <title> Computing on an anonymous ring. </title> <journal> Journal of the ACM, </journal> <volume> 35(4) </volume> <pages> 845-875, </pages> <year> 1988. </year>
Reference-contexts: We restrict our attention to the ring, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [3, 5, 9, 15, 16, 20, 21] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [12, 13, 22, 23, 19].
Reference: [4] <author> B. Awerbuch, S. Kutten, and D.Peleg. </author> <title> Competetive distributed job scheduling. </title> <booktitle> In Proceedings of the 24th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 571-580, </pages> <year> 1992. </year>
Reference-contexts: In addition, much of the scheduling literature assumes global control of task allocation. Our algorithm has low control overhead, accounts for communication constraints and does not require global control. We know of only one paper which fully addresses the latter two issues: that of Awerbuch, Kutten and Peleg <ref> [4] </ref>, who study the problem of distributed dynamic job scheduling in general distributed networks. Due to the generality of the setting they give algorithms with performance guarantees that are polylogarithmic in the problem size. <p> Therefore it is an important question to develop and precisely analyze scheduling algorithms that exploit the structure of specific real networks. We know of no previous papers which give algorithms for this distributed ring scheduling problem. The general techniques of <ref> [4] </ref> can be applied to the ring to yield a constant-approximation algorithm. However, even when a number of refinements to their approach and analysis are incorporated in this algorithm, the performance guarantees of our algorithm are much better. <p> We require each job to be processed on exactly one processor without preemption. In one unit of time we assume that each processor can receive some jobs from each neighbor, send some jobs to each neighbor, and process one unit of work; this is the model of <ref> [4] </ref>, and their assumptions are supported by current technology [6]. If a processor sends a job to a neighbor at time t, the neighbor receives the job at time t + 1. <p> We assume that the job granularity is large enough so that the time for simple control operations, such as simple arithmetic, is negligible. For most of the paper we assume no bounds on the capacity of each network link in the ring, as in <ref> [4] </ref>; in Section 7 we consider a model in which each link has unit capacity. We will let I denote an instance of the scheduling problem, and L (I) the length of the shortest possible schedule for I. <p> An interesting open problem is whether simple, small-constant approximation algorithms which require no centralized control exist for the other networks, such as the mesh. As stated earlier, Awerbuch et al. <ref> [4] </ref> give a distributed algorithm for job scheduling in general networks. When applied to the mesh their algorithm is a constant-approximation algorithm.
Reference: [5] <author> L. Bhuyan, D. Ghosal, and Q. Yang. </author> <title> Approximate analysis of single and multiple ring networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38 </volume> <pages> 1027-1040, </pages> <year> 1989. </year>
Reference-contexts: We restrict our attention to the ring, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [3, 5, 9, 15, 16, 20, 21] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [12, 13, 22, 23, 19].
Reference: [6] <author> H. Choi and A. Esfahanian. </author> <title> A message routing strategy for multicomputer systems. </title> <journal> Networks, </journal> <volume> 22 </volume> <pages> 627-646, </pages> <year> 1992. </year>
Reference-contexts: In one unit of time we assume that each processor can receive some jobs from each neighbor, send some jobs to each neighbor, and process one unit of work; this is the model of [4], and their assumptions are supported by current technology <ref> [6] </ref>. If a processor sends a job to a neighbor at time t, the neighbor receives the job at time t + 1. We assume that the job granularity is large enough so that the time for simple control operations, such as simple arithmetic, is negligible.
Reference: [7] <author> X. Deng, H. Liu, J. Long, and B. Xiao. </author> <title> Deterministic load balancing in computer networks. </title> <booktitle> In Proceedings of 2nd IEEE Symposium on Parallel and Distributed Processing, </booktitle> <year> 1992. </year>
Reference-contexts: In addition, the control structures of our algorithm are much simpler than the application of their general approach to the ring. Other papers have included communication cost in basic scheduling models, and, while not applicable to our problem, are related to our work in spirit. Deng et. al. <ref> [7] </ref> seem to be the first to have studied the parallel machine scheduling problem in a network. They give a number of centralized off-line algorithms, in addition to several distributed algorithms for special cases and models. <p> For many of the test cases we actually computed the optimum schedule length. It was previously known how to compute the optimum length schedule for an instance <ref> [7] </ref> with unit-size jobs. This approach, however, requires roughly n 2 m space, which for some of our test cases is 10 15 . We developed another more space efficient approach which uses m 2 space which for the largest of our test cases is only 10 6 .
Reference: [8] <author> M. Herlihy, B. Lim, and N. Shavit. </author> <title> Low contention load-balancing on large-scale multiprocessors. </title> <booktitle> In Proceedings of the 1992 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 219-227, </pages> <year> 1992. </year>
Reference-contexts: If algorithm A always yields a schedule of length no more than L (I) + O (1) we call A a -approximation algorithm. Note that this problem is related to, but different from, load balancing, which is another common problem in parallel and distributed systems (see <ref> [1, 8] </ref>). In the load balancing problem one is given a set of tasks or tokens and must distribute the tasks so that each processor in the system has approximately the same number.
Reference: [9] <author> Y. Hong and T. Payne. </author> <title> Parallel sorting in a ring network of processors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38:458 - 464, </volume> <year> 1989. </year>
Reference-contexts: We restrict our attention to the ring, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [3, 5, 9, 15, 16, 20, 21] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [12, 13, 22, 23, 19].
Reference: [10] <author> S. Flynn Hummel and E. Schonberg. </author> <title> Low-overhead scheduling of nested parallelism. </title> <journal> IBM Journal of Research and Development, </journal> 35(5/6):743-765, 1991. 
Reference-contexts: Simply put, the problem is to assign each of a set of independent tasks to processors in the system so as to finish the processing of the set of tasks as quickly as possible. Job scheduling arises frequently in parallel computing, for example in algorithms for automatic loop parallelization <ref> [2, 10, 11, 18] </ref> or in the use of a parallel system to process batches of transactions or independent sequential programs. We restrict our attention to the ring, which is an important network in both theory and practice.
Reference: [11] <author> S. Flynn Hummel, E. Schonberg, and L. E. Flynn. </author> <title> Factoring: A practical and robust method for scheduling parallel loops. </title> <journal> Comm. of the ACM, </journal> <volume> 35(8) </volume> <pages> 90-101, </pages> <year> 1992. </year>
Reference-contexts: Simply put, the problem is to assign each of a set of independent tasks to processors in the system so as to finish the processing of the set of tasks as quickly as possible. Job scheduling arises frequently in parallel computing, for example in algorithms for automatic loop parallelization <ref> [2, 10, 11, 18] </ref> or in the use of a parallel system to process batches of transactions or independent sequential programs. We restrict our attention to the ring, which is an important network in both theory and practice.
Reference: [12] <author> D. Hutchinson. </author> <title> Local Area Network Architectures. </title> <publisher> Addison-Wesley, </publisher> <year> 1988. </year>
Reference-contexts: In practice the ring is either the basis of or an essential component of many parallel and distributed architectures <ref> [12, 13, 22, 23, 19] </ref>. The element of our model which most differentiates it from previous scheduling algorithms is that task migration from one processor to another takes time proportional to the distance between those two processors in the communications network.
Reference: [13] <author> H. Kanada. </author> <title> Construction of a distributed computer network containing ring connections. </title> <booktitle> In Systems and Computers in Japan, </booktitle> <pages> pages 25-34, </pages> <year> 1993. </year>
Reference-contexts: In practice the ring is either the basis of or an essential component of many parallel and distributed architectures <ref> [12, 13, 22, 23, 19] </ref>. The element of our model which most differentiates it from previous scheduling algorithms is that task migration from one processor to another takes time proportional to the distance between those two processors in the communications network.
Reference: [14] <author> E.L. Lawler, J.K. Lenstra, A.H.G. Rinooy Kan, </author> <title> and D.B. Shmoys. Sequencing and scheduling: Algorithms and complexity. In S.C. Graves, </title> <editor> A.H.G. Rinnooy Kan, and P.H. Zip-kin, editors, </editor> <booktitle> Handbooks in Operations Research and Management Science, </booktitle> <volume> Vol 4., </volume> <booktitle> Logistics of Production and Inventory, </booktitle> <pages> pages 445-522. </pages> <publisher> North-Holland, </publisher> <year> 1993. </year>
Reference-contexts: We also report on simulations of our algorithm, which yield significantly better results than the worst-case analysis. There is a wealth of literature on parallel machine scheduling (see <ref> [14] </ref> for some examples) but almost all of it fails to capture the full complexity of many real scheduling problems. Many of the proposed algorithms have significant control overhead. Almost all of the literature ignores the communication constraints imposed by an underlying network architecture.
Reference: [15] <author> F. T. Leighton. </author> <title> An Introduction to Parallel Algorithms and Architectures. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: We restrict our attention to the ring, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [3, 5, 9, 15, 16, 20, 21] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [12, 13, 22, 23, 19].
Reference: [16] <author> Y. Mansour and L. Schulman. </author> <title> Sorting on a ring of processors. </title> <journal> Journal of Algorithms, </journal> <volume> 11 </volume> <pages> 622-630, </pages> <year> 1990. </year>
Reference-contexts: We restrict our attention to the ring, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [3, 5, 9, 15, 16, 20, 21] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [12, 13, 22, 23, 19].
Reference: [17] <author> C. A. Phillips, C. Stein, and J. Wein. </author> <title> Task scheduling in networks. </title> <booktitle> In Proceedings of the 4th Scandinavian Workshop on Algorithm Theory, </booktitle> <month> July </month> <year> 1994. </year> <note> To appear. </note>
Reference-contexts: Deng et. al. [7] seem to be the first to have studied the parallel machine scheduling problem in a network. They give a number of centralized off-line algorithms, in addition to several distributed algorithms for special cases and models. Phillips, Stein and Wein <ref> [17] </ref> improved on their results by giving a centralized off-line 2-approximation algorithm for a very general form of the problem, as well as hardness-to-approximate results and approximation algorithms for different optimality criteria. The rest of this paper is organized as follows. In Section 2 we precisely define the problem.
Reference: [18] <author> C. Polychronopoulos and D. Kuck. </author> <title> Guided self-scheduling: A practical scheduling scheme for parallel computers. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 12 </volume> <pages> 1425-1439, </pages> <year> 1987. </year>
Reference-contexts: Simply put, the problem is to assign each of a set of independent tasks to processors in the system so as to finish the processing of the set of tasks as quickly as possible. Job scheduling arises frequently in parallel computing, for example in algorithms for automatic loop parallelization <ref> [2, 10, 11, 18] </ref> or in the use of a parallel system to process batches of transactions or independent sequential programs. We restrict our attention to the ring, which is an important network in both theory and practice.
Reference: [19] <author> J. Rothnie. </author> <title> Kendall square research introduction to the ksr1. </title> <booktitle> In Dartmouth Institute for Advanced Graduate Studies in Parallel Computation, </booktitle> <pages> pages 200-210, </pages> <year> 1992. </year>
Reference-contexts: In practice the ring is either the basis of or an essential component of many parallel and distributed architectures <ref> [12, 13, 22, 23, 19] </ref>. The element of our model which most differentiates it from previous scheduling algorithms is that task migration from one processor to another takes time proportional to the distance between those two processors in the communications network.
Reference: [20] <author> W. Sung and S. Mitra. </author> <title> Multiprocessor implementation of recursive least squares algorithms using a parallel block processing method. </title> <booktitle> In IEEE International Symposium on Circuits and Systems, </booktitle> <pages> pages 2939-2942, </pages> <year> 1991. </year>
Reference-contexts: We restrict our attention to the ring, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [3, 5, 9, 15, 16, 20, 21] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [12, 13, 22, 23, 19].
Reference: [21] <author> W. Sung, S. Mitra, and K. Kum. </author> <title> Mapping locally recursive sfgs upon a multiprocessor system in a ring network. </title> <booktitle> In Proceedings of the International Conference on Application Specific Array Processors, </booktitle> <pages> pages 560-573, </pages> <year> 1992. </year>
Reference-contexts: We restrict our attention to the ring, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [3, 5, 9, 15, 16, 20, 21] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [12, 13, 22, 23, 19].
Reference: [22] <author> J. Takahashi, S. Hattori, T. Kimura, and A. Iwata. </author> <title> A ring array processor for highly parallel dynamic time warping. </title> <journal> IEEE Transactions on Acoustics, Speech and Signal Processing, </journal> <volume> 34 </volume> <pages> 1310-1318, </pages> <year> 1986. </year>
Reference-contexts: In practice the ring is either the basis of or an essential component of many parallel and distributed architectures <ref> [12, 13, 22, 23, 19] </ref>. The element of our model which most differentiates it from previous scheduling algorithms is that task migration from one processor to another takes time proportional to the distance between those two processors in the communications network.
Reference: [23] <author> A.S. Tanenbaum. </author> <title> Computer Networks. </title> <publisher> Prentice Hall, </publisher> <year> 1989. </year>
Reference-contexts: In practice the ring is either the basis of or an essential component of many parallel and distributed architectures <ref> [12, 13, 22, 23, 19] </ref>. The element of our model which most differentiates it from previous scheduling algorithms is that task migration from one processor to another takes time proportional to the distance between those two processors in the communications network.
References-found: 23

