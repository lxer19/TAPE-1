URL: http://www-unix.mcs.anl.gov/prism/lib/techsrc/wn29.ps.Z
Refering-URL: http://www-unix.mcs.anl.gov/prism/lib/tech.html
Root-URL: http://www.mcs.anl.gov
Title: Aggregations of Elementary Transformations  
Author: Xiaobai Sun 
Date: March 10, 1996  
Abstract: The techniques of aggregating transformations have been used in the development of blocked algorithms, in particular, the compact representations of aggregated Householder transformation have been wellknown. We show in this paper that the aggregation techniques can be integrated in a framework for aggregating general elementary transformations. The framework consists of three basic compact forms, as extensions of the three compact forms for aggregated Householder transformations, and two componentwise representations of the compact forms. The componentwise representations, introduced in this paper, are a central link to various computational procedures (known and new) for the compact forms, and provide a stepping stone for numerical analysis of blocked algorithms. We show also the connection between the computation of the compact forms and the inverse of general nonsingular triangular matrices. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Anderson and et al. </author> <note> LAPACK User's Guide. SIAM, Philadephia, 2nd edition, </note> <year> 1995. </year>
Reference-contexts: In Section 2 we show that the three compact forms mentioned above, and their variants, can be extended in a straightforward way to general elementary matrices in aggregation. Blocking/aggregating techniques used in blocked al 2 gorithms, such as blocked LU factorizations and blocked QR factorizations in LAPACK <ref> [1] </ref> and blocked Hessenberg reductions [3], can thus be unified in a framework.
Reference: [2] <author> C. H. Bischof and C. Van Loan. </author> <title> The WY representation for products of Householder matrices. </title> <journal> SIAM J. Sci. Stat. Comp., </journal> <volume> 8 </volume> <pages> 12-13, </pages> <year> 1987. </year>
Reference-contexts: A block or blocked algorithm at BLAS Level 3 usually renders a better ratio between data process and data access [16]. The approach of WY form, as well as its variants for the product of Householder transformations by Bischof and Van Loan <ref> [2] </ref>, is to aggregate a sequence of Householder transformations, say, nb &gt; 1 of them, and then to apply the aggregated transformation to A at once, turning nb matrix-vector multiplications and k rank-1 updates into one matrix-matrix multiplication and one rank-nb update, both at BLAS Level 3.
Reference: [3] <author> Christian H. Bischof. </author> <title> A summary of block schemes for reducing a general matrix to Hessenberg form. </title> <type> Technical report ANL/MCS-TM-17, </type> <institution> Mathematics and Computer Science Division, Argonne national Laboratory, </institution> <year> 1993. </year>
Reference-contexts: Blocking/aggregating techniques used in blocked al 2 gorithms, such as blocked LU factorizations and blocked QR factorizations in LAPACK [1] and blocked Hessenberg reductions <ref> [3] </ref>, can thus be unified in a framework. <p> The computation of z j+1 = y j+1 Z j (X T y j+1 ) invokes two matrix-vector multiplications in about 4jn flops, the same as the WY approach, if no special structures of F i are assumed. For Householder matrices, the XZ form is the so-called YW variant <ref> [3] </ref>, since X is essentially Y . 4 If the aggregation order is reversed, starting with F k on the left instead, then the computational procedures for W k and Z k are changed accordingly.
Reference: [4] <author> Christian H. Bischof and Xiaobai Sun. </author> <title> On orthogonal block eliminations. </title> <type> Preprint MCS-P450-0794, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <year> 1994. </year>
Reference-contexts: For example, if kx j k 2 = 1, then je T i T 1 e j j; jT ij j 2. Thus, the computation of the aggregation kernel via an inverse operation is safe if nb is not too big. In <ref> [4] </ref> Bischof and Sun discussed the numerical issues pertinent to orthogonal transformations in the YTY form. Corollary 4 can be applied to the triangular factor found by Bjorck and Page [6] for aggregated reflectors that embed the projectors. <p> For blocked algorithms using Householder transformations, Bischof and Sun <ref> [4] </ref> have given normwise estimate on the condition number of the kernels, and we 13 have given a componentwise bound in Section 4.2 of this paper. In general, any orthogonal matrix can be represented in YTY form [18], which is called the basis-kernel representation of orthogonal matrices.
Reference: [5] <author> Ake Bjorck. </author> <title> Numerical Methods for Least Squares Problems. </title> <publisher> SIAM, </publisher> <address> Philadelphia, PA, </address> <year> 1996. </year>
Reference-contexts: Otherwise, jT ij j; j (T 1 ) ij j 1; i &gt; j: The YTY representation of elementary orthogonal projectors in aggregation and Corollary 5 explain the difference between the MGS method and the classical Gram-Schmidt (CGS) method <ref> [10, 5] </ref>. While elementary projectors are applied one at a time to the rest of the matrix, A, being factored, they are applied, as successive products of the projectors in block orthogonal projector form, to the consecutive columns of A.
Reference: [6] <author> Ake Bjorck and C. C. </author> <title> Page. Loss and recapture of orthogonality in the modified Gram-Schmidt algorithm. </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 13(1) </volume> <pages> 176-190, </pages> <year> 1992. </year>
Reference-contexts: For algorithms based on projection operations, it is convenient in algorithm analysis to use nonsingular transformations that embed the projections. Such a technique is used, for example, in the analysis of the Modified Gram-Schmidt (MGS) method <ref> [6] </ref>. <p> The factor form of aggregation kernels for embedding Householder transformations was first seen in the analysis work by Bjorck and Page <ref> [6] </ref> on the loss and recapture of orthogonality in the MGS method, although it is not 9 explicitly related to the YTY compact form. The factor form presented in Theorem 3 is for a much larger class of triangular matrices, especially, for aggregation kernels of general elementary matrices. <p> In [4] Bischof and Sun discussed the numerical issues pertinent to orthogonal transformations in the YTY form. Corollary 4 can be applied to the triangular factor found by Bjorck and Page <ref> [6] </ref> for aggregated reflectors that embed the projectors. The triangular factor is key to recapturing the lost orthogonality in MGS method. It is the aggregation kernel (see Section 3) for the orthogonal elementary projectors as well.
Reference: [7] <author> D. Dodson and J. Lewis. </author> <title> Issues relating to extention of the Basic Linear Algebra Subroutines. </title> <journal> ACM SIGNUM Newsletter, </journal> <volume> 20(1) </volume> <pages> 2-18, </pages> <year> 1985. </year>
Reference: [8] <author> J. J. Dongara, J. DuCros, I. Duff, and S. Hammarling. </author> <title> A set of level 3 Basic Linear Algebra Subprograms. </title> <journal> ACM Trans. Math. Softw., </journal> <volume> 16 </volume> <pages> 1-17, </pages> <year> 1990. </year>
Reference: [9] <author> J. J. Dongarra, I. S. Duff, D. C. Sorensen, and H. A. van der Vorst. </author> <title> Solving Linear Systems on Vector and Share Memory Computers. </title> <publisher> SIAM pub. </publisher> <address> Philadephia, </address> <year> 1991. </year>
Reference-contexts: Different update schemes lead to different block variants such as the right-looking version, left-looking 6 version, and Crout version <ref> [9] </ref>. The computations with these update vari-ants, nonetheless, are numerically equivalent provided that the same pivoting scheme is used in the pivot columns and a fixed block size is used. Strictly speaking, the numerical behavior is not invariant to the block size. <p> Together with the categories of update schemes <ref> [9] </ref>, the integration and classification of aggregating techniques suggests the possibility to have aggregations and block updates done at the system level. Such a system would remove the inconsistency in memory management between the user level and the system level, and circumvent the tradeoff between efficiency and portability.
Reference: [10] <author> G. H. Golub and C. F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> The Johns Hopkins University Press, </publisher> <address> 2nd edition, </address> <year> 1989. </year>
Reference-contexts: Otherwise, jT ij j; j (T 1 ) ij j 1; i &gt; j: The YTY representation of elementary orthogonal projectors in aggregation and Corollary 5 explain the difference between the MGS method and the classical Gram-Schmidt (CGS) method <ref> [10, 5] </ref>. While elementary projectors are applied one at a time to the rest of the matrix, A, being factored, they are applied, as successive products of the projectors in block orthogonal projector form, to the consecutive columns of A. <p> Some interesting results follow immediately. For example, if T is a Toeplitz matrix <ref> [10] </ref>, so is T 1 . For the inverse operation, Corollary 6 ( see Figure 1 ) suggests alternative algorithms to the two conventional column-oriented procedures [11]; the computation of L can start from either of the vertices on the diagonal or from the diagonal of the triangular.
Reference: [11] <author> Nicholas J. Higham. </author> <title> Accuracy and Stability of Numerical Algorithms. </title> <publisher> SIAM, </publisher> <address> Philadephia, </address> <year> 1996. </year>
Reference-contexts: Some interesting results follow immediately. For example, if T is a Toeplitz matrix [10], so is T 1 . For the inverse operation, Corollary 6 ( see Figure 1 ) suggests alternative algorithms to the two conventional column-oriented procedures <ref> [11] </ref>; the computation of L can start from either of the vertices on the diagonal or from the diagonal of the triangular. For instance, for a triangular matrix T with narrow band, L can also be easily computed diagonalwise beside the columnwise and row-wise versions. <p> For algorithm analysis of triangular inverse, one can use the recursive representation (5) to derive recursively general componentwise bounds on T 1 and hence bounds on the condition numbers of T (cf. <ref> [11] </ref>.) One can also derive special bounds on triangular matrices with special features such as those in Subsection 4.2. <p> We consider this another substantial difference between blocked algorithms and block algorithms. In Section 2.4, we have distinguished two kinds of reordered computation in blocked algorithms and suggested estimating the numerical effect of aggregations. In fact, for blocked LU algorithms, Demmel and Higham <ref> [11] </ref> have used the condition number of the pivoting blocks (i.e., the aggregation kernels for Gaussian elimination transformations) to describe and bound the numerical effect of the reordering and inverse operations introduced by aggregations.
Reference: [12] <author> A. S. </author> <title> Householder. The Theory of Matrices in Numerical Analysis. </title> <publisher> Dover Publications, </publisher> <address> New York, </address> <year> 1964. </year>
Reference-contexts: Householder transformations are also known as elementary reflectors. On the other hand, all singular elementary matrices are elementary projectors <ref> [12] </ref>, and the symmetric ones are orthogonal projectors. Orthogonal projections are the basic operations of classical and modified Gram-Schmidt orthogonalization procedures [17,10].
Reference: [13] <author> C. Lawson, R. Hanson, D. Kincaid, and F. Krogh. </author> <title> Basic Linear Algebra Subprograms for Fortran usage. </title> <journal> ACM Trans,. Math. Softw., </journal> <volume> 5 </volume> <pages> 308-329, </pages> <year> 1979. </year>
Reference: [14] <author> C. Puglisi. </author> <title> Modification of the Householder method based on the compact WY representation. </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 3(3) </volume> <pages> 723-726, </pages> <year> 1992. </year>
Reference-contexts: The YTY form free of inverse, proposed by Schreiber and Van Loan [15], has the advantage of efficient storage, and the YTY form with inverse, proposed by Walker [20] and Puglisi <ref> [14] </ref>, offers an alternative computation procedure introducing Level 3 BLAS operations in aggregation step as well. While the WY form remains preferred for mathematical software development, the YTY forms are found useful in algorithm analysis as well. We present in this paper a framework of aggregating techniques. <p> For Householder matrices, the XTY form is the YTY form by Walker [20] and Pulgilisi <ref> [14] </ref>, since X and Y are the same except in column scalings. For Gaussian elimination transformations, we have L = (I + X (1:k;1:k) ) 1 . The aggregated transformation I XLI (1:k;:) , combined with an update scheme, then leads to a blocked LU factorization ( cf.
Reference: [15] <author> R. Schreiber and C. Van Loan. </author> <title> A storage efficient WY representation for products of householder transformations. </title> <journal> SIAM J. Sci. Stat. Comp., </journal> <volume> 10(1) </volume> <pages> 53-57, </pages> <year> 1989. </year>
Reference-contexts: The YTY form free of inverse, proposed by Schreiber and Van Loan <ref> [15] </ref>, has the advantage of efficient storage, and the YTY form with inverse, proposed by Walker [20] and Puglisi [14], offers an alternative computation procedure introducing Level 3 BLAS operations in aggregation step as well.
Reference: [16] <author> Robert S. Schreiber. </author> <title> Block algorithms for parallel machines. </title> <editor> In M. H. Schults, editor, </editor> <title> Numerical Algorithms for Modern Computer Architectures. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1988. </year>
Reference-contexts: A block or blocked algorithm at BLAS Level 3 usually renders a better ratio between data process and data access <ref> [16] </ref>.
Reference: [17] <author> G. W. Stewart. </author> <title> Introduction to Matrix Computations. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1973. </year>
Reference: [18] <author> X. Sun and C. H. Bischof. </author> <title> A basis-kernel representation of orthogonal matrices. </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 16(4) </volume> <pages> 1184-1196, </pages> <month> Oct. </month> <year> 1995. </year> <month> 15 </month>
Reference-contexts: Similar to the basis-kernel representation for orthogonal transformations <ref> [18] </ref>, the XTY aggregation form can be viewed as a canonical representation form with triangular kernel for general transformations (up to a permutation matrix), and the XTY form is preserved by both (block) composition and (block) decomposition. <p> For blocked algorithms using Householder transformations, Bischof and Sun [4] have given normwise estimate on the condition number of the kernels, and we 13 have given a componentwise bound in Section 4.2 of this paper. In general, any orthogonal matrix can be represented in YTY form <ref> [18] </ref>, which is called the basis-kernel representation of orthogonal matrices. The basis-kernel representation underpins the approach of the so-called blockwise analysis [19] for blocked algorithms using orthogonal transformations or orthogonal projection transformations.
Reference: [19] <author> Xiaobai Sun. </author> <title> A blockwise analysis of numerical algorithms for QR fac-torizations. </title> <type> Manuscript. </type>
Reference-contexts: Although mathematically equivalent, the MGS and CGS methods are numerically different in that the triangular aggregation kernel, which would be the identity matrix in accurate computation, is missing in each block projector used by the CGS method (cf. <ref> [19] </ref>.) 4.3 The Recursive Form Applying the YTY form to the elementary factors in the componentwise representation (3) of the aggregation kernel L = T 1 , we have L ij = y T = y T i (:;j+1:i1) x j i x j + y T (:;j+1:i1) x j ; <p> In general, any orthogonal matrix can be represented in YTY form [18], which is called the basis-kernel representation of orthogonal matrices. The basis-kernel representation underpins the approach of the so-called blockwise analysis <ref> [19] </ref> for blocked algorithms using orthogonal transformations or orthogonal projection transformations. For blocked algorithms using Householder transformations, for example, the blockwise analysis approach is to find a nearby exactly orthogonal transformation in YTY form directly from the aggregated Householder transformation, instead of getting one inductively from the aggregation procedure.
Reference: [20] <author> Homer F. Walker. </author> <title> Implementation of the GMRES method using Householder transformations. </title> <journal> SIAM J. Sci. Stat. Comp., </journal> <volume> 9(1) </volume> <pages> 152-163, </pages> <year> 1988. </year> <month> 16 </month>
Reference-contexts: The YTY form free of inverse, proposed by Schreiber and Van Loan [15], has the advantage of efficient storage, and the YTY form with inverse, proposed by Walker <ref> [20] </ref> and Puglisi [14], offers an alternative computation procedure introducing Level 3 BLAS operations in aggregation step as well. While the WY form remains preferred for mathematical software development, the YTY forms are found useful in algorithm analysis as well. We present in this paper a framework of aggregating techniques. <p> For Householder matrices, the XTY form is the YTY form by Walker <ref> [20] </ref> and Pulgilisi [14], since X and Y are the same except in column scalings. For Gaussian elimination transformations, we have L = (I + X (1:k;1:k) ) 1 .
References-found: 20

