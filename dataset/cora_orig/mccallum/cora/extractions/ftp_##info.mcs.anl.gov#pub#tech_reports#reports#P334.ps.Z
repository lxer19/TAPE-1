URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P334.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts93.htm
Root-URL: http://www.mcs.anl.gov
Title: A Path-Following Infeasible-Interior-Point Algorithm for Linear Complementarity Problems  
Author: Stephen Wright 
Affiliation: MATHEMATICS AND COMPUTER SCIENCE DIVISION, ARGONNE NATIONAL LABORATORY  
Note: PREPRINT MCS-P334-1192,  
Date: November 18, 1992  
Abstract: We describe an infeasible-interior-point algorithm for monotone linear complementarity problems that has polynomial complexity, global linear convergence, and local superlinear convergence with a Q-order of 2. Only one matrix factorization is required per iteration, and the analysis assumes only that a strictly complementary solution exists. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Ji, F. Potra, and S. Huang, </author> <title> A predictor-corrector method for linear complementarity problems with polynomial complexity and superlinear convergence, </title> <type> Tech. Rep. 18, </type> <institution> Department of Mathematics, University of Iowa, Iowa City, Iowa, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: We denote the solution set for (1) by S and the set of strictly complementary solutions by S c . A number of interior point methods have been proposed for (1). Among recent papers are the predictor-corrector algorithm of Ji, Potra, and Huang <ref> [1] </ref> which has polynomial complexity and two-step superlinear convergence, the predictor-corrector algorithm of Ye and Anstreicher [5] which is polynomial and quadratically convergent, the path-following infeasible-interior-point algorithm of Zhang [6] which has polynomial complexity, and the algorithm described by the present author in an earlier report [4], which modifies Zhang's algorithm <p> Safe steps have the form (x k ('); y k (')) = (x k ; y k ) + '(u k ; v k ) + (u k ; v k ); (5) where, for any given ' 2 <ref> [0; 1] </ref>, is chosen so that x k (') T y k (') = (1 ')n k = (1 ')(x k ) T y k : (6) It is easy to verify by using (2) and (3) that y k (') M x k (') h = (1 ')(y k M <p> The procedure can be outlined formally as follows: Fast step calculation: Given ~oe 2 [0; 1=2], ~fl 2 (0; 1=2], and ~ fi 2 [0; 1=2], Solve (2) to find (u k ; v k ); Choose ~' as the largest value in <ref> [0; 1] </ref> such that (x k ; y k ) + '(u k ; v k ) 2 N (~fl); (11) (1 ~ fi)(1 ')(x k ) T y k (x k + 'u k ) T (y k + 'v k ) (1 + ~ fi)(1 ')(x k ) T <p> ) h k : Therefore condition (11) will be satisfied provided that fl k k (1 ') + ' 2 k h k ; or, equivalently, (fl k fl k+1 ) k (1 ') + ' 2 k (C 6 =2)(1 + fl k+1 ) 0: Since fl k+1 2 <ref> [fl; 1), ff 2 (0; 1] </ref>, and ' 2 (0; 1], this last inequality will hold if (fl k fl k+1 ) k (1 ') 'C 6 2 4 1 : We can use (26) to obtain ' I 1 C 6 fl k fl k+1 and so (11) is satisfied <p> We start by showing that k (') defined by k (') = n 1 ' 2 (u k ) T v k is monotonically decreasing for ' 2 <ref> [0; 1] </ref> when k &gt; 0.
Reference: [2] <author> F. A. Potra, </author> <title> An infeasible interior-point predictor-corrector algorithm for linear programming, </title> <type> Tech. Rep. 26, </type> <institution> Department of Mathematics, University of Iowa, Iowa City, Iowa, </institution> <month> June </month> <year> 1992. </year> <title> [3] , A quadratically convergent infeasible interior-point algorithm for linear programming, </title> <type> Tech. Rep. 28, </type> <institution> Department of Mathematics, University of Iowa, Iowa City, Iowa, </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: All these algorithms assume existence of a strictly feasible point for (1), that is, a vector pair (x; y) such that y = M x + h and (x; y) &gt; 0. Recently, Potra <ref> [2, 3] </ref> has proposed infeasible-interior-point fl This research was supported by the Applied Mathematical Sciences subprogram of the Office of Energy Research, U. S. <p> It is similar to Lemma 4.1 of Potra <ref> [2] </ref>.
Reference: [4] <author> S. J. Wright, </author> <title> An infeasible-interior-point algorithm for linear complementarity problems, </title> <type> Preprint MCS-P331-0991, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Illinois, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: Ji, Potra, and Huang [1] which has polynomial complexity and two-step superlinear convergence, the predictor-corrector algorithm of Ye and Anstreicher [5] which is polynomial and quadratically convergent, the path-following infeasible-interior-point algorithm of Zhang [6] which has polynomial complexity, and the algorithm described by the present author in an earlier report <ref> [4] </ref>, which modifies Zhang's algorithm so that superlinear convergence with Q-order 2 is attained. All these algorithms assume existence of a strictly feasible point for (1), that is, a vector pair (x; y) such that y = M x + h and (x; y) &gt; 0. <p> In this paper, we describe an algorithm that is similar to the algorithm in <ref> [4] </ref> in that it takes so-called safe steps in the early stages of the algorithm and fast steps in the later stages (with an intermediate stage in which both kinds of steps can occur). <p> The main point of difference between the two approaches is in the calculation of the safe steps. Essentially, the algorithm in <ref> [4] </ref> requires that, for safe steps, the infeasibility ky M x hk decreases at least as quickly as the complementarity gap x T y, while safe steps taken by the algorithm in this paper reduce these two quantities by exactly the same rate. <p> In the final "fast" phase of the algorithm, just one solve is required at each step. The convergence properties are identical to the algorithm of <ref> [4] </ref>, namely, global linear convergence, polynomial complexity when correctly initialized, and local superlinear convergence with Q-order 2. Throughout the remainder of the paper, we make just one assumption: Assumption 1 S c is nonempty. <p> the definition of B and N is independent of the particular choice of (x fl ; y fl ).) For our main result, we take note of the similarity between (u k ; v k ) and the step (x k ; y k ) computed by the algorithm of <ref> [4] </ref>. <p> ~oe 2 (0; 1=2]; (x k ; y k ) 2 N (fl k ); k k 0 fi L ; r k = k r 0 ; (x k ; y k ) is a bounded sequence: (Note that we use fi L in place of ^ fi in <ref> [4] </ref> and that, in the algorithm of this paper, we apply a restriction k fi U k 0 that does not exist in [4].) We also need several results like those in Section 3 of [4], which define upper and lower bounds for components of (x k ; y k ) <p> = k r 0 ; (x k ; y k ) is a bounded sequence: (Note that we use fi L in place of ^ fi in <ref> [4] </ref> and that, in the algorithm of this paper, we apply a restriction k fi U k 0 that does not exist in [4].) We also need several results like those in Section 3 of [4], which define upper and lower bounds for components of (x k ; y k ) in terms of k . These results are given in the first three lemmas of this section. <p> a bounded sequence: (Note that we use fi L in place of ^ fi in <ref> [4] </ref> and that, in the algorithm of this paper, we apply a restriction k fi U k 0 that does not exist in [4].) We also need several results like those in Section 3 of [4], which define upper and lower bounds for components of (x k ; y k ) in terms of k . These results are given in the first three lemmas of this section. <p> These results are given in the first three lemmas of this section. Our main result is Theorem 5.4, which uses the bounds on (x k ; y k ) to obtain bounds on (u k ; v k ) using a proof technique identical to one in <ref> [4, Section 5] </ref>. Finally, in Theorem 5.5, we restate these bounds in the form in which they will be used in Section 6. We start by defining an "auxiliary sequence" similar to the one defined by Zhang [6, Section 4] and Wright [4, Section 3]. <p> Finally, in Theorem 5.5, we restate these bounds in the form in which they will be used in Section 6. We start by defining an "auxiliary sequence" similar to the one defined by Zhang [6, Section 4] and Wright <ref> [4, Section 3] </ref>. The first element of this sequence is any vector pair (w 0 ; z 0 ) 2 IR n fi IR n such that z 0 = M w 0 + h; but not necessarily (w 0 ; z 0 ) 0. <p> The remaining inequality (49b) is proved similarly. Note that, in contrast to Zhang [6] and Wright <ref> [4] </ref>, we do not require (x 0 ; y 0 ) (w 0 ; z 0 ): (54) In [4], we needed (54) to prove (48) and (49) but, in this paper, our a priori knowledge of the boundedness of f (x k ; y k )g makes this assumption unnecessary. <p> The remaining inequality (49b) is proved similarly. Note that, in contrast to Zhang [6] and Wright <ref> [4] </ref>, we do not require (x 0 ; y 0 ) (w 0 ; z 0 ): (54) In [4], we needed (54) to prove (48) and (49) but, in this paper, our a priori knowledge of the boundedness of f (x k ; y k )g makes this assumption unnecessary. <p> The proof of (55b) is similar. We now have all the inequalities needed to prove the main results for boundedness of (u k ; v k ), using identical techniques to those in <ref> [4, Section 5] </ref>. <p> The proof of (56b) is similar. The remaining inequalities (57) can be proved as in Lemmas 5.2 and 5.3 of <ref> [4] </ref>. Lemma 5.2 is a technical result that is an extension of an earlier result of Ye and Anstreicher [5, Lemma 3.5]. <p> The proof of (56b) is similar. The remaining inequalities (57) can be proved as in Lemmas 5.2 and 5.3 of [4]. Lemma 5.2 is a technical result that is an extension of an earlier result of Ye and Anstreicher [5, Lemma 3.5]. In the proof of <ref> [4, Lemma 5.3] </ref>, we use the inequalities (18), (48), (49), (55), (56), and boundedness of the sequence f (x k ; y k )g, all of which have been proved above. We omit further details and refer the interested reader to [4]. <p> In the proof of [4, Lemma 5.3], we use the inequalities (18), (48), (49), (55), (56), and boundedness of the sequence f (x k ; y k )g, all of which have been proved above. We omit further details and refer the interested reader to <ref> [4] </ref>. <p> The result follows immediately from Theorem 5.4. 6 Superlinear Convergence In this final section, we show that the sequence f k g converges superlinearly to zero with Q-order 2. The development follows that in <ref> [4, Section 6] </ref> quite closely. We write out the proofs of our results where there is enough difference from the proofs of [4] to cause confusion, and omit them otherwise. <p> The development follows that in [4, Section 6] quite closely. We write out the proofs of our results where there is enough difference from the proofs of <ref> [4] </ref> to cause confusion, and omit them otherwise. We start by defining a threshold condition involving k and fl k , and finding bounds on the step length ~' given by the fast step procedure when this condition is satisfied. <p> The remainder of the proof is similar to the proof of Lemma 6.1 in <ref> [4] </ref>. First, we show that the centrality condition (11) is satisfied for all ' in the interval ' 2 0; 1 C 6 fl k fl k+1 : (61) Second, we show that the complementarity reduction condition (12) is also satisfied for all ' in the interval (61). <p> Proof. The second inequality in (64) guarantees that the fast step is accepted at iteration K, while (65) ensures that the threshold condition (58) still holds at iteration K + 1. By induction, it follows that (i) is true. For (ii), we apply an argument from <ref> [4] </ref> to the first inequality in (64). See [4, Theorem 6.3] for the details. Finally, we show that the algorithm will eventually reach an iterate K at which both (58) and K are satisfied, and so superlinear convergence is guaranteed to occur. <p> By induction, it follows that (i) is true. For (ii), we apply an argument from [4] to the first inequality in (64). See <ref> [4, Theorem 6.3] </ref> for the details. Finally, we show that the algorithm will eventually reach an iterate K at which both (58) and K are satisfied, and so superlinear convergence is guaranteed to occur. <p> Proof. The proof is almost identical to that of Theorem 6.4 in <ref> [4] </ref>, so we omit it. This section culminates in the following result, which is immediate from Theorems 6.3 and 6.4.
Reference: [5] <author> Y. Ye and K. Anstreicher, </author> <title> On quadratic and O( p nL) convergence of a predictor-corrector algorithm for LCP, </title> <type> Tech. Rep. 91-20, </type> <institution> Department of Management Sciences, University of Iowa, Iowa City, Iowa, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: A number of interior point methods have been proposed for (1). Among recent papers are the predictor-corrector algorithm of Ji, Potra, and Huang [1] which has polynomial complexity and two-step superlinear convergence, the predictor-corrector algorithm of Ye and Anstreicher <ref> [5] </ref> which is polynomial and quadratically convergent, the path-following infeasible-interior-point algorithm of Zhang [6] which has polynomial complexity, and the algorithm described by the present author in an earlier report [4], which modifies Zhang's algorithm so that superlinear convergence with Q-order 2 is attained. <p> Throughout the remainder of the paper, we make just one assumption: Assumption 1 S c is nonempty. When (1) is derived from a linear programming problem, all that is needed for Assumption 1 to be satisfied is that a solution exists! Moreover, Ye and Anstreicher <ref> [5, Proposition 5.1] </ref> give a simple example to show that Assumption 1 is, in a sense, necessary for superlinear convergence. <p> The proof of (56b) is similar. The remaining inequalities (57) can be proved as in Lemmas 5.2 and 5.3 of [4]. Lemma 5.2 is a technical result that is an extension of an earlier result of Ye and Anstreicher <ref> [5, Lemma 3.5] </ref>. In the proof of [4, Lemma 5.3], we use the inequalities (18), (48), (49), (55), (56), and boundedness of the sequence f (x k ; y k )g, all of which have been proved above. We omit further details and refer the interested reader to [4].
Reference: [6] <author> Y. Zhang, </author> <title> On the convergence of an infeasible interior-point algorithm for linear programming and other problems, </title> <type> Tech. Rep. 92-07, </type> <institution> Department of Mathematics and Statistics, University of Maryland, Baltimore County, Maryland, </institution> <month> April </month> <year> 1992. </year> <month> 25 </month>
Reference-contexts: Among recent papers are the predictor-corrector algorithm of Ji, Potra, and Huang [1] which has polynomial complexity and two-step superlinear convergence, the predictor-corrector algorithm of Ye and Anstreicher [5] which is polynomial and quadratically convergent, the path-following infeasible-interior-point algorithm of Zhang <ref> [6] </ref> which has polynomial complexity, and the algorithm described by the present author in an earlier report [4], which modifies Zhang's algorithm so that superlinear convergence with Q-order 2 is attained. <p> Finally, in Theorem 5.5, we restate these bounds in the form in which they will be used in Section 6. We start by defining an "auxiliary sequence" similar to the one defined by Zhang <ref> [6, Section 4] </ref> and Wright [4, Section 3]. The first element of this sequence is any vector pair (w 0 ; z 0 ) 2 IR n fi IR n such that z 0 = M w 0 + h; but not necessarily (w 0 ; z 0 ) 0. <p> The remaining inequality (49b) is proved similarly. Note that, in contrast to Zhang <ref> [6] </ref> and Wright [4], we do not require (x 0 ; y 0 ) (w 0 ; z 0 ): (54) In [4], we needed (54) to prove (48) and (49) but, in this paper, our a priori knowledge of the boundedness of f (x k ; y k )g makes
References-found: 5

