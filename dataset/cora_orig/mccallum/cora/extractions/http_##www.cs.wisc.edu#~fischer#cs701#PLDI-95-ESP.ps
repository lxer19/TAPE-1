URL: http://www.cs.wisc.edu/~fischer/cs701/PLDI-95-ESP.ps
Refering-URL: http://www.cs.wisc.edu/~fischer/cs701/readings.html
Root-URL: 
Title: Corpus-based Static Branch Prediction  
Author: Brad Calder, Dirk Grunwald, Donald Lindsay, James Martin, Michael Mozer, and Benjamin Zorn 
Address: Campus Box 430  Boulder, CO 80309-0430 USA  
Affiliation: Department of Computer Science  University of Colorado  
Date: June 18-21, 1995  
Note: To appear in the Proc. of the ACM SIGPLAN Conf. on Prog. Language Design and Implementation (PLDI '95), La Jolla, CA,  
Abstract: Correctly predicting the direction that branches will take is increasingly important in today's wide-issue computer architectures. The name program-based branch prediction is given to static branch prediction techniques that base their prediction on a program's structure. In this paper, we investigate a new approach to program-based branch prediction that uses a body of existing programs to predict the branch behavior in a new program. We call this approach to program-based branch prediction, evidence-based static prediction, or ESP. The main idea of ESP is that the behavior of a corpus of programs can be used to infer the behavior of new programs. In this paper, we use a neural network to map static features associated with each branch to the probabilty that the branch will be taken. ESP shows significant advantages over other prediction mechanisms. Specifically, it is a program-based technique, it is effective across a range of programming languages and programming styles, and it does not rely on the use of expert-defined heuristics. In this paper, we describe the application of ESP to the problem of branch prediction and compare our results to existing program-based branch predictors. We also investigate the applicability of ESP across computer architectures, programming languages, compilers, and run-time systems. Averaging over a body of 43 C and Fortran programs, ESP branch prediction results in a miss rate of 20%, as compared with the 25% miss rate obtained using the best existing program-based heuristics. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Alverson, D. Callahan, D. Cummings, B. Koblenz, A. Porter-field, and B. Smith. </author> <title> The tera computer system. </title> <booktitle> In International Conference on Supercomputing, </booktitle> <pages> pages 1-6, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Our results in Section 5 show it has an overall miss rate in our experiments of 34%. Any more sophisticated program-based prediction techniques must do better than BTFNT to be viable. To facilitate program-based methods for branch prediction, some modern architectures provide a branch-likely bit in each branch instruction <ref> [1] </ref>. In these architectures, compilers can employ either profile-based [11] or program-based techniques to determine what branches are likely to be taken. <p> The tanh function is normalized to achieve an activity range of <ref> [0; 1] </ref> for the output unit. The input-output behavior of the neural network is determined by its free parameters, the weights w and v and biases b and a. These parameters are set by an algorithm known as back propagation [16].
Reference: [2] <author> Vasanth Balasundaram, Geoffrey Fox, Ken Kennedy, and Ulrich Kremer. </author> <title> A static performanceestimator to guide data partitioning decisions. </title> <booktitle> In Third ACM SIGPLAN Symposium on Principles & Practice of Parallel Programming, </booktitle> <pages> pages 213-223, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: There is little other work in compiler optimization that has taken this approach. We summarize the work we are aware of here. In <ref> [2] </ref>, Balasundaram et al. address a somewhat different program-based estimation problem. The authors wanted to make compile-time decisions about data partitioning across a parallel computer. They report on the idea of using profile data to train an estimator.
Reference: [3] <author> Thomas Ball and James R. Larus. </author> <title> Branch prediction for free. </title> <booktitle> In Proceedings of the SIGPLAN'93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 300-313, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: As a result, such architectures are likely to execute branch instructions every two cycles or less and effective branch prediction on such architectures is extremely important. Many approaches have been taken to branch prediction, some of which involve hardware [5, 23] while others involve software <ref> [3, 6, 11] </ref>. Software methods usually work in tandem with hardware methods. For example, some architectures have a likely bit that can be set by a compiler if a branch is determined to be likely taken by a compiler. Compilers typically rely on two general approaches for branch prediction. <p> Some of these techniques use heuristics based on local knowledge that can be encoded in the architecture [14, 18]. Other techniques rely on applying heuristics based on less local program structure in an effort to predict branch behavior <ref> [3] </ref>. In this paper, we describe a new approach to program-based branch prediction that does not rely on such heuristics. Our branch prediction relies on a general program-based prediction framework that we call ESP. <p> To facilitate program-based methods for branch prediction, some modern architectures provide a branch-likely bit in each branch instruction [1]. In these architectures, compilers can employ either profile-based [11] or program-based techniques to determine what branches are likely to be taken. In recent work, Ball and Larus <ref> [3] </ref> showed that applying a number of simple program-based heuristics can significantly improve the branch prediction miss rate over BTFNT on tests based on the conditional branch operation. A complete summary of the Ball and Larus heuristics is given in Table 1 (as described in [22]). <p> Two questions arise when employing an approach like that taken by Ball and Larus. First, an important question is which heuristics should be used. In their paper, they describe seven heuristics that they considered successful, but also noted that We tried many heuristics that were unsuccessful. <ref> [3] </ref> A second issue that arises with heuristic methods is how to decide what to do when more than one heuristic applies to a given branch. This problem has existed in the artificial intelligence community for many years and is commonly known as the evidence combination problem. <p> The probabilities X% and Y% that Wu and Larus use are taken directly from the paper of Ball and Larus <ref> [3] </ref>. We refer to a DSHC algorithm based on this data as DSHC (B&L). Because the goal of Wu and Larus was to perform program-based profile estimation, they give no results about how the DSHC method works for program-based branch prediction. <p> Using the control flow graph, we computed the dominator and post-dominator trees. Following this, we determined the natural loop headers and applied the same definition of natural loops used by Ball and Larus to determine the loop bodies <ref> [3] </ref>. We used ATOM to reproduce the Ball and Larus APHC results, and to generate the static feature sets with the corresponding branch probabilities which are used to train the neural net for ESP. <p> We did the same for FORTRAN programs feeding into the neural net the feature sets for 19 of the 20 programs in order to predict branches for the 20th program. 5 Results We now compare the prediction accuracy of a priori heuristic combination (APHC) branch prediction <ref> [3] </ref>, the Dempster-Shafer heuristic combination (DSHC) proposed by Wu and Larus [22], and our ESP technique. <p> In implementing DSHC, we use both the original prediction rates specified in <ref> [3] </ref>, DSHC (B&L), and the prediction rates produced by our implementation, DSHC (Ours). Later, we compare the similarity between these two sets of prediction heuristics as seen in Table 6. <p> The fifth column is the miss rate for the ESP technique, while the last column is the miss rate for perfect static profile prediction. In each case, smaller values are better. 5.2 Cross-Architectural Study of A Priori Heuristics In the paper by Ball and Larus <ref> [3] </ref>, a number of prediction heuristics were described. These heuristics were the foundation for the prediction scheme in both the study by Ball and Larus and the study by Wu and Larus. In the study by Wu and Larus, the values given in [3] were used for the Dempster-Shafer combination method, <p> In the paper by Ball and Larus <ref> [3] </ref>, a number of prediction heuristics were described. These heuristics were the foundation for the prediction scheme in both the study by Ball and Larus and the study by Wu and Larus. In the study by Wu and Larus, the values given in [3] were used for the Dempster-Shafer combination method, even though the study by Wu and Larus used a different architecture, compiler and runtime system. We wondered how sensitive these metrics were to differences in architecture, compiler, runtime system and selection of programs. <p> We wondered how sensitive these metrics were to differences in architecture, compiler, runtime system and selection of programs. We use the CFG, dominator, post-dominator and loop information to implement the same heuristics in <ref> [3] </ref>, summarized in Table 1. Our implementation results for these heuristics are shown in Table 5. This table shows detailed information about how the branch heuristics performed for each program. Some of the programs in our suite were also used in the earlier study by Ball [3], and the values in <p> the same heuristics in <ref> [3] </ref>, summarized in Table 1. Our implementation results for these heuristics are shown in Table 5. This table shows detailed information about how the branch heuristics performed for each program. Some of the programs in our suite were also used in the earlier study by Ball [3], and the values in parenthesis show the equivalent metrics recorded in that study. In general, the values are quite similar, but there are some small differences that we believe arise from different runtime libraries. <p> For example, the Alpha has a conditional move operation that obliviates the need for many short conditional branches, reducing the number of conditional branches that are executed. Table 5 further demonstrates that our implementation of the heuristics listed in <ref> [3] </ref> appear to be correct. The loop miss rates are roughly the same, the heuristics cover approximately the same percentage of branches and the overall branch prediction miss rates are similar. <p> Clearly, determining this information at compile time would simplify the analysis, because we could use more information from the program. However, both Ball and Larus <ref> [3] </ref> and our study used binary instrumentation, so we felt that other factors must also contribute to the prediction differences.
Reference: [4] <author> M. Berry. </author> <title> The Perfect Club Benchmarks: Effective performance evaluation of supercomputers. </title> <journal> The International Journal of Supercomputer Applications, </journal> <volume> 3(3) </volume> <pages> 5-40, </pages> <month> Fall </month> <year> 1989. </year>
Reference-contexts: During our study, we instrumented the programs from the SPEC92 benchmark suite and other programs, including many from the Perfect Club <ref> [4] </ref> suite. We used ATOM [20] to instrument the programs. Due to the structure of ATOM, we did not need to record traces and could trace very long-running programs. The programs were compiled on a DEC 3000-400 using the Alpha AXP-21064 processor using either the DEC C or FORTRAN compilers.
Reference: [5] <author> Brad Calder and Dirk Grunwald. </author> <title> Fast & accurate instruction fetch and branch prediction. </title> <booktitle> In 21st Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 2-11. </pages> <publisher> ACM, </publisher> <month> April </month> <year> 1994. </year>
Reference-contexts: As a result, such architectures are likely to execute branch instructions every two cycles or less and effective branch prediction on such architectures is extremely important. Many approaches have been taken to branch prediction, some of which involve hardware <ref> [5, 23] </ref> while others involve software [3, 6, 11]. Software methods usually work in tandem with hardware methods. For example, some architectures have a likely bit that can be set by a compiler if a branch is determined to be likely taken by a compiler.
Reference: [6] <author> Brad Calder and Dirk Grunwald. </author> <title> Reducing branch costs via branch alignment. </title> <booktitle> In Six International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 242-251. </pages> <publisher> ACM, </publisher> <year> 1994. </year>
Reference-contexts: As a result, such architectures are likely to execute branch instructions every two cycles or less and effective branch prediction on such architectures is extremely important. Many approaches have been taken to branch prediction, some of which involve hardware [5, 23] while others involve software <ref> [3, 6, 11] </ref>. Software methods usually work in tandem with hardware methods. For example, some architectures have a likely bit that can be set by a compiler if a branch is determined to be likely taken by a compiler. Compilers typically rely on two general approaches for branch prediction.
Reference: [7] <author> Brad Calder, Dirk Grunwald, and Benjamin Zorn. </author> <title> Quantifying behavioral differences between C and C++ programs. </title> <journal> Journal of Programming Languages, </journal> <volume> 2(4), </volume> <year> 1994. </year> <note> Also available as University of Colorado Technical Report CU-CS-698-94. </note>
Reference-contexts: The penalty for a mispredicted branch may be several cycles long. For example, the mis-predict penalty is 4 to 5 cycles on the Digital Alpha AXP 21064 processor. In previous studies, we found that conditional branches in C programs were executed approximately every 8 instructions on the Alpha architecture <ref> [7] </ref>. Current wide-issue architectures can execute four or more instructions per cycle. As a result, such architectures are likely to execute branch instructions every two cycles or less and effective branch prediction on such architectures is extremely important.
Reference: [8] <author> P. P. Chang and W. W. Hwu. </author> <title> Profile-guided automatic inline expansion for C programs. </title> <journal> Software Practice and Experience, </journal> <volume> 22(5) </volume> <pages> 349-376, </pages> <year> 1992. </year>
Reference-contexts: Branch prediction is important, both for computer architectures and compilers. Compilers rely on branch prediction and execution estimation to implement optimizations such as trace-scheduling [12, 13] and other profile-directed optimizations <ref> [8, 9] </ref>. Wide-issue computer architectures rely on predictable control flow, and failure to correctly predict a branch results in delays for fetching and decoding the instructions along the incorrect path of execution. The penalty for a mispredicted branch may be several cycles long.
Reference: [9] <author> P. P. Chang, S. A. Mahlke, and W. W. Hwu. </author> <title> Using profile information to assist classic compiler code optimizations. </title> <journal> Software Practice and Experience, </journal> <volume> 21(12) </volume> <pages> 1301-1321, </pages> <year> 1991. </year>
Reference-contexts: Branch prediction is important, both for computer architectures and compilers. Compilers rely on branch prediction and execution estimation to implement optimizations such as trace-scheduling [12, 13] and other profile-directed optimizations <ref> [8, 9] </ref>. Wide-issue computer architectures rely on predictable control flow, and failure to correctly predict a branch results in delays for fetching and decoding the instructions along the incorrect path of execution. The penalty for a mispredicted branch may be several cycles long.
Reference: [10] <author> A. P. Dempster. </author> <title> A generalization of bayesian inference. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> 30 </volume> <pages> 205-247, </pages> <year> 1968. </year>
Reference-contexts: Wu and Larus abandoned the simplistic evidence combination function of APHC in favor of an evidence combination function borrowed from Dempster-Shafer theory <ref> [10, 17] </ref>. We call this form of evidence combination Dempster-Shafer Heuristic Combination (DSHC). By making some fairly strong independence assumptions, the Dempster-Shafer evidence combination function can produce an estimate of the branch probability from any number of sources of evidence.
Reference: [11] <author> J. A. Fisher and S. M. Freudenberger. </author> <title> Predicting conditional branch directions from previous runs of a program. </title> <booktitle> In Proceedings of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-V), </booktitle> <pages> pages 85-95, </pages> <address> Boston, Mass., </address> <month> October </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: As a result, such architectures are likely to execute branch instructions every two cycles or less and effective branch prediction on such architectures is extremely important. Many approaches have been taken to branch prediction, some of which involve hardware [5, 23] while others involve software <ref> [3, 6, 11] </ref>. Software methods usually work in tandem with hardware methods. For example, some architectures have a likely bit that can be set by a compiler if a branch is determined to be likely taken by a compiler. Compilers typically rely on two general approaches for branch prediction. <p> Compilers typically rely on two general approaches for branch prediction. Profile-based methods use program profiles to determine the frequency that branch paths are executed. Fisher and Freudenberger showed that profile-based branch prediction can be extremely successful in reducing the number of instructions executed between mis-predicted branches <ref> [11] </ref>. The main drawback of profile-based methods is that additional work is required on the part of the programmer to generate the program profiles. Program-based branch prediction methods attempt to predict branch behavior in the absence of profile information and are based only on a program's structure. <p> Any more sophisticated program-based prediction techniques must do better than BTFNT to be viable. To facilitate program-based methods for branch prediction, some modern architectures provide a branch-likely bit in each branch instruction [1]. In these architectures, compilers can employ either profile-based <ref> [11] </ref> or program-based techniques to determine what branches are likely to be taken. In recent work, Ball and Larus [3] showed that applying a number of simple program-based heuristics can significantly improve the branch prediction miss rate over BTFNT on tests based on the conditional branch operation.
Reference: [12] <author> Joseph A. Fisher. </author> <title> Trace scheduling: A technique for global microcode compaction. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-30(7):478-490, </volume> <month> July </month> <year> 1981. </year>
Reference-contexts: Branch prediction is the process of correctly predicting whether branches will be taken or not before they are actually executed. Branch prediction is important, both for computer architectures and compilers. Compilers rely on branch prediction and execution estimation to implement optimizations such as trace-scheduling <ref> [12, 13] </ref> and other profile-directed optimizations [8, 9]. Wide-issue computer architectures rely on predictable control flow, and failure to correctly predict a branch results in delays for fetching and decoding the instructions along the incorrect path of execution. The penalty for a mispredicted branch may be several cycles long.
Reference: [13] <author> Wen-mei W. Hwu and Pohua P. Chang. </author> <title> Achieving high instruction cache performance with an optimizing compiler. </title> <booktitle> In 16th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 242-251. </pages> <publisher> ACM, </publisher> <year> 1989. </year>
Reference-contexts: Branch prediction is the process of correctly predicting whether branches will be taken or not before they are actually executed. Branch prediction is important, both for computer architectures and compilers. Compilers rely on branch prediction and execution estimation to implement optimizations such as trace-scheduling <ref> [12, 13] </ref> and other profile-directed optimizations [8, 9]. Wide-issue computer architectures rely on predictable control flow, and failure to correctly predict a branch results in delays for fetching and decoding the instructions along the incorrect path of execution. The penalty for a mispredicted branch may be several cycles long.
Reference: [14] <author> Scott McFarling and John Hennessy. </author> <title> Reducing the cost of branches. </title> <booktitle> In 13th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 396-403. </pages> <institution> Association for Computing Machinery, </institution> <year> 1986. </year>
Reference-contexts: Program-based branch prediction methods attempt to predict branch behavior in the absence of profile information and are based only on a program's structure. Some of these techniques use heuristics based on local knowledge that can be encoded in the architecture <ref> [14, 18] </ref>. Other techniques rely on applying heuristics based on less local program structure in an effort to predict branch behavior [3]. In this paper, we describe a new approach to program-based branch prediction that does not rely on such heuristics.
Reference: [15] <author> Judea Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: This is likely a result of the strong independence assumptions embodied in the Dempster-Shafer evidence combination function <ref> [15] </ref>. Our ESP method addresses these two disadvantages directly. Instead of relying on experts to think of heuristics and to test them to determine if they are effective, our method extracts features associated with predictable behavior automatically. The ESP method also has disadvantages, as well.
Reference: [16] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Parallel distributed processing: Explorations in the microstructure of cognition. Volume I: Foundations, chapter Learning internal representations by error propagation,pages 318-362. </title> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year> <editor> D. E. Rumelhart and J. L. Mc-Clelland, </editor> <publisher> editors. </publisher>
Reference-contexts: The input-output behavior of the neural network is determined by its free parameters, the weights w and v and biases b and a. These parameters are set by an algorithm known as back propagation <ref> [16] </ref>. This is a gradient descent procedure for adjusting the parameters such that performance of the network on a training corpus is optimized.
Reference: [17] <author> G. Shafer. </author> <title> A Mathematical Theory of Evidence. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1976. </year>
Reference-contexts: Wu and Larus abandoned the simplistic evidence combination function of APHC in favor of an evidence combination function borrowed from Dempster-Shafer theory <ref> [10, 17] </ref>. We call this form of evidence combination Dempster-Shafer Heuristic Combination (DSHC). By making some fairly strong independence assumptions, the Dempster-Shafer evidence combination function can produce an estimate of the branch probability from any number of sources of evidence.
Reference: [18] <author> J. E. Smith. </author> <title> A study of branch prediction strategies. </title> <booktitle> In 8th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 135-148. </pages> <publisher> ACM, </publisher> <year> 1981. </year>
Reference-contexts: Program-based branch prediction methods attempt to predict branch behavior in the absence of profile information and are based only on a program's structure. Some of these techniques use heuristics based on local knowledge that can be encoded in the architecture <ref> [14, 18] </ref>. Other techniques rely on applying heuristics based on less local program structure in an effort to predict branch behavior [3]. In this paper, we describe a new approach to program-based branch prediction that does not rely on such heuristics.
Reference: [19] <author> P. Smolensky, M. C. Mozer, and D. E. Rumelhart, </author> <title> editors. Mathematical perspectives on neural networks. </title> <publisher> Erlbaum, </publisher> <year> 1994. </year> <note> In press. </note>
Reference-contexts: This system should accurately predict not just for the programs in the corpus, but also for previously unseen programs. One way of doing such prediction is via a feedforward neural network <ref> [19] </ref>. A feedforward neural network maps a numerical input vector to a numerical output.
Reference: [20] <author> Amitabh Srivastava and Alan Eustace. </author> <title> ATOM: A system for building customized program analysis tools. </title> <booktitle> In Proceedings of the SIGPLAN'94 Conference on Programming LanguageDesign and Implementation, </booktitle> <pages> pages 196-205. </pages> <publisher> ACM, </publisher> <year> 1994. </year>
Reference-contexts: During our study, we instrumented the programs from the SPEC92 benchmark suite and other programs, including many from the Perfect Club [4] suite. We used ATOM <ref> [20] </ref> to instrument the programs. Due to the structure of ATOM, we did not need to record traces and could trace very long-running programs. The programs were compiled on a DEC 3000-400 using the Alpha AXP-21064 processor using either the DEC C or FORTRAN compilers.
Reference: [21] <author> Tim A. Wagner, Vance Maverick, Susan Graham, and Michael Harrison. </author> <title> Accurate static estimators for program optimization. </title> <booktitle> In Proceedings of the SIGPLAN'94 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 85-96, </pages> <address> Orlando, Florida, </address> <month> June </month> <year> 1994. </year> <note> ACM. </note>
Reference-contexts: One of the contributions of our paper is that we quantify the effectiveness of the DSHC method for branch prediction. Wagner et al. <ref> [21] </ref> also used heuristics similar to those of Ball and Larus to perform program-based profile estimation. Heuristic Heuristic Name Description Loop Branch Predict that the edge back to the loop's head is taken and the edge exiting the loop is not taken.
Reference: [22] <author> Youfeng Wu and James R. Larus. </author> <title> Static branch frequency and program profile analysis. </title> <booktitle> In 27th International Symposium on Microarchitecture, </booktitle> <address> San Jose, Ca, </address> <month> November </month> <year> 1994. </year> <note> IEEE. </note>
Reference-contexts: A complete summary of the Ball and Larus heuristics is given in Table 1 (as described in <ref> [22] </ref>). Their heuristics use information about the branch opcode, operands, and characteristics of the branch successor blocks, and encode knowledge about common programming idioms. Two questions arise when employing an approach like that taken by Ball and Larus. First, an important question is which heuristics should be used. <p> We call using this pre-determined order for heuristic combination the A Priori Heuristic Combination (APHC) method. Using APHC, Ball and Larus report an average overall miss rate on the MIPS architecture of 20%. In a related paper, Wu and Larus refined the APHC method of Ball and Larus <ref> [22] </ref>. In that paper, their goal was to determine branch probabilities instead of simple branch prediction. <p> feeding into the neural net the feature sets for 19 of the 20 programs in order to predict branches for the 20th program. 5 Results We now compare the prediction accuracy of a priori heuristic combination (APHC) branch prediction [3], the Dempster-Shafer heuristic combination (DSHC) proposed by Wu and Larus <ref> [22] </ref>, and our ESP technique. Following this, we show that the APHC and DSHC techniques are sensitive to differences in system architecture and compilers. 5.1 Comparison: APHC, DSHC and ESP Table 4 shows the branch misprediction rate for the methods we implemented. <p> Table 4 reveals several interesting points. First, the overall average shows that the Dempster-Shafer method performs no better than the fixed order of heuristics. Wu and Larus <ref> [22] </ref> said When more than one heuristic applies to a branch, combining the probabilities estimated by the ap plicable heuristics should produce an overall branch probability that is more accurate than the individ ual probabilities. However, there was no comparison to the earlier results of Ball and Larus. <p> In 6 cases (flex, sort, mdljsp2, CSS, NAS, TFS), the Dempster-Shafer method is more than 5% worse than the simple APHC ordering, while the APHC ordering method is 5% worse in only three cases (wdiff, SDS, LWS). The intuition in <ref> [22] </ref> was correct; however, the Dempster-Shafer theory does not combine the evidence well enough to improve branch prediction.
Reference: [23] <author> Tse-Yu Yeh and Yale N. Patt. </author> <title> A comparison of dynamic branch predictors that use two levels of branch history. </title> <booktitle> In 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 257-266, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year> <note> ACM. </note>
Reference-contexts: As a result, such architectures are likely to execute branch instructions every two cycles or less and effective branch prediction on such architectures is extremely important. Many approaches have been taken to branch prediction, some of which involve hardware <ref> [5, 23] </ref> while others involve software [3, 6, 11]. Software methods usually work in tandem with hardware methods. For example, some architectures have a likely bit that can be set by a compiler if a branch is determined to be likely taken by a compiler.
References-found: 23

