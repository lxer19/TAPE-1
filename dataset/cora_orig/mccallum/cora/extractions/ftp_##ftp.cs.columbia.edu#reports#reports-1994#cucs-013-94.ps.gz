URL: ftp://ftp.cs.columbia.edu/reports/reports-1994/cucs-013-94.ps.gz
Refering-URL: http://www.cs.columbia.edu/~library/1994.html
Root-URL: http://www.cs.columbia.edu
Title: A Comparative Study of Divergence Control Algorithms  
Author: Akira Kawaguchi and Kui Mok Calton Pu Kun-Lung Wu and Philip S. Yu 
Keyword: Index Terms: divergence control algorithms, epsilon serializability, performance analysis, transaction and query processing.  
Address: New York, NY 10027 P.O. Box 91000, Portland, OR 97291-1000  P.O. Box 704 Yorktown Heights, NY 10598 CUCS-013-94  
Affiliation: Department of Computer Science Dept. of Computer Science Engineering Columbia University Oregon Graduate Institute  IBM T.J. Watson Research Center  
Abstract: This paper evaluates and compares the performance of two-phase locking divergence control (2PLDC) and optimistic divergence control (ODC) algorithms using a comprehensive centralized database simulation model. We examine a system with multiclass workloads in which on-line update transactions and long-duration queries progress based on epsilon serializability (ESR). Our results demonstrate that significant performance enhancements can be achieved with a non-zero tolerable inconsistency (*-spec). With sufficient *-spec and limited system resources, both algorithms achieve comparable performance. However, with low resource contention, ODC performs significantly better than 2PLDC. Moreover, given a small *-spec, ODC returns more accurate results on the committed queries then 2PLDC. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agrawal, M. J. Carey, and M. Livny. </author> <title> Concurrency control performance modeling: Alternatives and implications. </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 12(4) </volume> <pages> 609-654, </pages> <month> Dec. </month> <year> 1987. </year>
Reference-contexts: A QET contains a sequence of one or more read-only (Q) operations. An UET contains a mixture of read (R) and write (W ) operations in which R precedes W for any update operation as <ref> [1] </ref>. A QET (import *-spec &gt; 0) need not be serializable with other UETs whereas UETs (export *-spec &gt; 0 but import *-spec=0) must be serializable among themselves. Each W alters the database state. Database state spaces can be metric spaces. In particular, bank dollars (integers) form a cartesian space. <p> We thus built the TP performance model based on the framework introduced by <ref> [1, 4] </ref> which consists of database, user, and transaction models. <p> An aborted transaction is granted a higher priority from which a successive rescheduling is promptly done. Third, the Resource Manager conducts both computation and disk I/O activities in a tightly connected multiprocessor system. As in <ref> [1] </ref>, we define CPUs as multiple servers through a common queue, and each disk server has its own queue. In addition, we employ a data-buffering mechanism driven by LRU replacement policy. <p> Our simulation program is implemented using CSIM [16, 17]. The simulation is flexible with a large number of parameters, which enables us to characterize the workload more precisely. For validation, we ran a set of experiments with parameters identical to those used in <ref> [1] </ref>. Furthermore, most of the values are kept unchanged from [1] to maintain the validation and basis for comparison. 3.2.1 Workload Parameters Our workload consists of two classes of transactions: short updates (UETs) and lengthy queries (QETs). <p> The simulation is flexible with a large number of parameters, which enables us to characterize the workload more precisely. For validation, we ran a set of experiments with parameters identical to those used in <ref> [1] </ref>. Furthermore, most of the values are kept unchanged from [1] to maintain the validation and basis for comparison. 3.2.1 Workload Parameters Our workload consists of two classes of transactions: short updates (UETs) and lengthy queries (QETs). Unlike TPC benchmarks, where data contention is minimized, we introduce some interference between UETs and QETs. <p> Physical configuration of the system is determined in a straightforward way. They include sys num terminal for external terminals and sys num cpu and sys num disk for the amount of CPU and disk servers respectively. As in <ref> [1] </ref>, we use one CPU and two disks as a basic resource unit. We also inherit a constant service time spent on a single request to CPU and disk as sys mean cpu and sys mean disk as well as negligible sys dc cpu overhead in scheduling. <p> They are rather ad hoc but they range from several to a few dozens of update amounts, corresponding roughly from a small to a large tolerance in this context. 4 Results and Discussions All statistics in the next three sections are derived using a batch means method <ref> [1] </ref>. A maximum of 20 batches were run on each simulation where each batch lasts 1,000 simulation seconds. The transient period of the initial 100 seconds is not used in the computation of the final statistics. <p> However, in contrast to Figures 3 (a) and (b), ODC outperforms 2PLDC for almost all the *-spec, including *-spec=0. That ODC is better than 2PLDC with infinite resources and *-spec=0 conforms with previous studies of 2PLCC and OCC algorithms <ref> [1, 4] </ref>. This is different from the observation that 2PLDC is slightly better than ODC with the resource-limited environment in the previous section. extracted from MPL=50, 100 and 150. <p> Our simulation extends Agrawal et al's study <ref> [1] </ref> on the performance of concurrency control methods, whose results are used for validation of our simulation program. We investigated a wide range of workload and system parameter settings and found the following significant results. 4 The first bucket refers to zero accumulated inconsistency. The last bucket means maximum inconsistency.
Reference: [2] <author> R. Alonso, D. Barbara, and H. Garcia-Molina. </author> <title> Data Caching issues in an informational retrieval systems. </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 15(3) </volume> <pages> 359-384, </pages> <month> Sept. </month> <year> 1990. </year>
Reference: [3] <author> P. A. Bernstein and V. Hadzilacos, and N. Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year> <month> 13 </month>
Reference-contexts: 1 Introduction Serializability (SR) is maintained by concurrency control (CC) algorithms <ref> [3] </ref> in online transaction processing. Many applications have found SR too restrictive, and epsilon serializability (ESR) was proposed to alleviate SR constraints by allowing some bounded inconsistency. In particular, a limited amount of inconsistency (*-spec) can be seen by read-only transactions. <p> When such conflicts are detected, a DC algorithm ensures that inconsistency accumulation for each ET does not violate its *-spec. We call the CC and DC algorithms as strict serialization and ESR extension respectively. In the next two sections, we describe our implementation of strict two-phase locking divergence control <ref> [3] </ref> and broadcast-type optimistic divergence control [18, 20, 21] in the way they integrate strict serialization and ESR extension. 2.1 Two-phase Locking Divergence Control (2PLDC) 2PLDC is an extension of the classic 2PL concurrency control. We show a lock compatibility matrix in Figure 1 (a) 1 .
Reference: [4] <author> M. J. Carey, and M. R. Stonebraker. </author> <title> The performance of concurrency control algorithms for database management systems. </title> <booktitle> In Proc. of the 10th Int. Conf. on Very Large Data Bases, </booktitle> <pages> pages 107-118, </pages> <month> Aug. </month> <year> 1984. </year>
Reference-contexts: We thus built the TP performance model based on the framework introduced by <ref> [1, 4] </ref> which consists of database, user, and transaction models. <p> However, in contrast to Figures 3 (a) and (b), ODC outperforms 2PLDC for almost all the *-spec, including *-spec=0. That ODC is better than 2PLDC with infinite resources and *-spec=0 conforms with previous studies of 2PLCC and OCC algorithms <ref> [1, 4] </ref>. This is different from the observation that 2PLDC is slightly better than ODC with the resource-limited environment in the previous section. extracted from MPL=50, 100 and 150.
Reference: [5] <author> A. Dan, D. M. Dias, and P. S. Yu. </author> <title> The effect of skewed data access on buffer hits and data contention in a data sharing environment. </title> <booktitle> In Proc. of the 16th Int. Conf. on Very Large Data Bases, </booktitle> <pages> pages 419-431, </pages> <year> 1990. </year>
Reference-contexts: The rate of QETs issued by each terminal is determined by tran query prob. A pause of the submission of a new transaction from a terminal is set by the exponential distribution with tran mean thinktime. Since non-uniform data accesses always happen in real databases <ref> [5, 6, 7] </ref>, we characterize data contention caused by skewed access patterns using tran access f rac, where different frequencies of access relate to separate segments in the database. In our experiments, we choose an 80%-20% model, i.e., 80% of all accesses go to 20% of the database entities.
Reference: [6] <author> A. Dan, and D. Towsley. </author> <title> An approximate analysis of the LRU and FIFO buffer replacement schemes. </title> <booktitle> In Proc. of ACM SIGMETRICS, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: The rate of QETs issued by each terminal is determined by tran query prob. A pause of the submission of a new transaction from a terminal is set by the exponential distribution with tran mean thinktime. Since non-uniform data accesses always happen in real databases <ref> [5, 6, 7] </ref>, we characterize data contention caused by skewed access patterns using tran access f rac, where different frequencies of access relate to separate segments in the database. In our experiments, we choose an 80%-20% model, i.e., 80% of all accesses go to 20% of the database entities.
Reference: [7] <author> A. Dan, P. S. Yu, and J.-Y. Chung. </author> <title> Characterization of database access skew in a transaction processing environment. </title> <booktitle> In Proc. of Int. Conf. on Data Engineering, </booktitle> <pages> pages 134-143, </pages> <year> 1993. </year>
Reference-contexts: Unlike TPC benchmarks, where data contention is minimized, we introduce some interference between UETs and QETs. We assume that such combination is realistic in many transaction systems with decision support applications <ref> [7] </ref>. The size of an UET is decided by the mean of a uniform distribution between tran U min size and tran U max size. Each UET chooses a target entity randomly from a database of tran db size entities. <p> The rate of QETs issued by each terminal is determined by tran query prob. A pause of the submission of a new transaction from a terminal is set by the exponential distribution with tran mean thinktime. Since non-uniform data accesses always happen in real databases <ref> [5, 6, 7] </ref>, we characterize data contention caused by skewed access patterns using tran access f rac, where different frequencies of access relate to separate segments in the database. In our experiments, we choose an 80%-20% model, i.e., 80% of all accesses go to 20% of the database entities.
Reference: [8] <author> P. Franaszek and J. T. Robinson. </author> <title> Limitations of concurrency in transaction processing. </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 10(1) </volume> <pages> 1-28, </pages> <month> Mar. </month> <year> 1985. </year>
Reference: [9] <author> M. Kamath, and K. Ramamritham. </author> <title> Performance characteristics of epsilon serializability with hierarchical inconsistency bounds. </title> <booktitle> Proc. of Int. Conf. on Data Engineering, </booktitle> <year> 1993. </year>
Reference-contexts: These and other ESR papers have worked out the details of divergence control and shown the feasibility of quick production quality implementation. However, except for one paper studying the performance of hierarchical divergence control using timestamps <ref> [9] </ref>, the quantitative behavior of ESR systems remained unclear. The main contributions of this paper, compared to the previous ESR work, are threefold. First, we investigate the question of how much inconsistency must be tolerated before we see significant performance gains in terms of transaction throughput and response time. <p> Concretely, we explored the issue of ESR applicability to large-scale centralized TP environment. A comprehensive simulation model is built to determine transaction throughput and response time. The first quantitative performance evaluation <ref> [9] </ref> was based on a prototype using time stamp ordering on both transaction and object levels in a hierarchical manner. Despite the limitation of main memory database and small range of multiprogramming level (MPL), their paper clearly demonstrated the shift of thrashing points to a higher MPL as *-spec increases. <p> More specifically, they achieve better peak performance at higher MPL as *-spec is raised. Thrashing points also shift to higher MPL. This is true under both resource limited and unlimited environments. This result amplifies and complements previous work on timestamp-based divergence control <ref> [9] </ref>. Second, we compared the performance of 2PLDC and ODC beyond the confirmation of [9]'s results when *-spec=0. On the other end of spectrum, since sufficiently large *-spec values allow free access (without concurrency control) to a great majority of transactions, it matters little which divergence control method is used.
Reference: [10] <author> H. T. Kung and J. T. Robinson. </author> <title> On optimistic methods for concurrency control. </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 6(2) </volume> <pages> 213-226, </pages> <month> June </month> <year> 1981. </year>
Reference: [11] <author> C. Pu. </author> <title> Generalized transaction processing with epsilon-serializability. </title> <booktitle> In Proc. of 1991 Int. Workshop on High Performance Transaction Systems, </booktitle> <year> 1991. </year>
Reference-contexts: Divergence control (DC) algorithms have been designed [18, 14] to bound the amount of inconsistency for ESR the same way concurrency control maintains SR. In fact, DC algorithms extend classic CC algorithms such as two-phase locking, optimistic validation, and timestamps <ref> [11, 15] </ref>. Some important questions about ESR have been answered by previous papers. For example, a formal characterization of ESR [15] explains its meaning and relationship to SR. Also, several papers have described the divergence control algorithms used to guarantee ESR [11, 14, 18]. <p> Some important questions about ESR have been answered by previous papers. For example, a formal characterization of ESR [15] explains its meaning and relationship to SR. Also, several papers have described the divergence control algorithms used to guarantee ESR <ref> [11, 14, 18] </ref>. The question on practical feasibility was answered by a simple implementation of two-phase locking based divergence control built on top of Transarc Encina [12], a commercial transaction monitor.
Reference: [12] <author> C. Pu and S .W. Chen. </author> <title> ACID Properties need fast relief: Relaxing consistency using epsilon serializability. </title> <booktitle> In Proc. of 5th Int. Workshop on High Performance Transaction Systems, </booktitle> <year> 1993. </year>
Reference-contexts: Also, several papers have described the divergence control algorithms used to guarantee ESR [11, 14, 18]. The question on practical feasibility was answered by a simple implementation of two-phase locking based divergence control built on top of Transarc Encina <ref> [12] </ref>, a commercial transaction monitor. These and other ESR papers have worked out the details of divergence control and shown the feasibility of quick production quality implementation. However, except for one paper studying the performance of hierarchical divergence control using timestamps [9], the quantitative behavior of ESR systems remained unclear. <p> For experiments focused on data contention (using infinite hardware resources), ODC allows better throughput and response time for both UETs and QETs; this is particularly obvious at high MPL. Finally, the simulation program is useful in guiding our ongoing research. For example, we have implemented 2PLDC on Transarc Encina <ref> [12] </ref>, a commercial transaction monitor. The performance measurements of the implementation, using TPC benchmarks, have been limited by hardware resources (less than 20 MPL on a SUN IPX).
Reference: [13] <author> C. Pu, W. Hseush, G. E. Kaiser, K.-L. Wu and P. S. Yu. </author> <title> Distributed Divergence Control for Epsilon Serializability. </title> <booktitle> In 13th Int. Conf. on Distributed Computing Systems, </booktitle> <pages> pages 449-456, </pages> <month> May </month> <year> 1993. </year>
Reference: [14] <author> C. Pu and A. Leff. </author> <title> Execution autonomy in distributed transaction processing. </title> <booktitle> In Proc. of the 2nd Int. Workshop on Research Issues in Data Engineering: Transaction and Query Processing, </booktitle> <pages> pages 2-11, </pages> <year> 1992. </year>
Reference-contexts: Many applications have found SR too restrictive, and epsilon serializability (ESR) was proposed to alleviate SR constraints by allowing some bounded inconsistency. In particular, a limited amount of inconsistency (*-spec) can be seen by read-only transactions. Divergence control (DC) algorithms have been designed <ref> [18, 14] </ref> to bound the amount of inconsistency for ESR the same way concurrency control maintains SR. In fact, DC algorithms extend classic CC algorithms such as two-phase locking, optimistic validation, and timestamps [11, 15]. Some important questions about ESR have been answered by previous papers. <p> Some important questions about ESR have been answered by previous papers. For example, a formal characterization of ESR [15] explains its meaning and relationship to SR. Also, several papers have described the divergence control algorithms used to guarantee ESR <ref> [11, 14, 18] </ref>. The question on practical feasibility was answered by a simple implementation of two-phase locking based divergence control built on top of Transarc Encina [12], a commercial transaction monitor.
Reference: [15] <author> K. Ramamritham and C. Pu. </author> <title> A formal characterization of epsilon serializability. </title> <journal> IEEE Trans. on Knowledge and Data Engineering. </journal> <note> to appear. </note>
Reference-contexts: Divergence control (DC) algorithms have been designed [18, 14] to bound the amount of inconsistency for ESR the same way concurrency control maintains SR. In fact, DC algorithms extend classic CC algorithms such as two-phase locking, optimistic validation, and timestamps <ref> [11, 15] </ref>. Some important questions about ESR have been answered by previous papers. For example, a formal characterization of ESR [15] explains its meaning and relationship to SR. Also, several papers have described the divergence control algorithms used to guarantee ESR [11, 14, 18]. <p> In fact, DC algorithms extend classic CC algorithms such as two-phase locking, optimistic validation, and timestamps [11, 15]. Some important questions about ESR have been answered by previous papers. For example, a formal characterization of ESR <ref> [15] </ref> explains its meaning and relationship to SR. Also, several papers have described the divergence control algorithms used to guarantee ESR [11, 14, 18]. <p> In Section 3, we describe the performance model and outline the experiments. We present and discuss performance results in Section 4. Finally, we summarize the main conclusions of this study in Section 5. 2 Divergence Control Algorithms A formal characterization of ESR can be found in <ref> [15] </ref>. We only informally introduce the basic ESR concepts here. A classic transaction is extended to an epsilon-transaction (ET) by the addition of inconsistency limits, called an *-spec.
Reference: [16] <author> H. Schwetman. </author> <title> CSIM Reference Manual (Revision 16). </title> <institution> Microelectronic and Computer Technology Corporation, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: Thus, it can steal CPU being spent on the operation at Resource Manager whenever its scheduling is possible. 3.2 Experiments Table 1 summarizes our workload and resource parameter settings. Our simulation program is implemented using CSIM <ref> [16, 17] </ref>. The simulation is flexible with a large number of parameters, which enables us to characterize the workload more precisely. For validation, we ran a set of experiments with parameters identical to those used in [1].
Reference: [17] <author> H. Schwetman. </author> <title> CSIM Users' Guide (Revision 2). </title> <institution> Microelectronic and Computer Technology Corporation, </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: Thus, it can steal CPU being spent on the operation at Resource Manager whenever its scheduling is possible. 3.2 Experiments Table 1 summarizes our workload and resource parameter settings. Our simulation program is implemented using CSIM <ref> [16, 17] </ref>. The simulation is flexible with a large number of parameters, which enables us to characterize the workload more precisely. For validation, we ran a set of experiments with parameters identical to those used in [1].
Reference: [18] <author> K.-L. Wu, P. S. Yu, and C. Pu. </author> <title> Divergence control for epsilon-serializability. </title> <booktitle> In Proc. of 8th Int. Conf. on Data Engineering, </booktitle> <pages> pages 506-515, </pages> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: Many applications have found SR too restrictive, and epsilon serializability (ESR) was proposed to alleviate SR constraints by allowing some bounded inconsistency. In particular, a limited amount of inconsistency (*-spec) can be seen by read-only transactions. Divergence control (DC) algorithms have been designed <ref> [18, 14] </ref> to bound the amount of inconsistency for ESR the same way concurrency control maintains SR. In fact, DC algorithms extend classic CC algorithms such as two-phase locking, optimistic validation, and timestamps [11, 15]. Some important questions about ESR have been answered by previous papers. <p> Some important questions about ESR have been answered by previous papers. For example, a formal characterization of ESR [15] explains its meaning and relationship to SR. Also, several papers have described the divergence control algorithms used to guarantee ESR <ref> [11, 14, 18] </ref>. The question on practical feasibility was answered by a simple implementation of two-phase locking based divergence control built on top of Transarc Encina [12], a commercial transaction monitor. <p> We call the CC and DC algorithms as strict serialization and ESR extension respectively. In the next two sections, we describe our implementation of strict two-phase locking divergence control [3] and broadcast-type optimistic divergence control <ref> [18, 20, 21] </ref> in the way they integrate strict serialization and ESR extension. 2.1 Two-phase Locking Divergence Control (2PLDC) 2PLDC is an extension of the classic 2PL concurrency control. We show a lock compatibility matrix in Figure 1 (a) 1 .
Reference: [19] <author> K.-L. Wu, P. S. Yu, and J. Z. Teng. </author> <title> Performance Comparison of Thrashing Control Policies for Concurrent Mergesorts with Parallel Prefetching. </title> <booktitle> In Proc. of ACM SIGMETRICS, </booktitle> <pages> pages 171-182, </pages> <year> 1993. </year>
Reference: [20] <author> P. S. Yu and D. M. Dias. </author> <title> Performance analysis of concurrency control using locking with deferred blocking. </title> <journal> IEEE Trans. on Software Engineering, </journal> 19(10) 982-996, Oct. 1993. 
Reference-contexts: We call the CC and DC algorithms as strict serialization and ESR extension respectively. In the next two sections, we describe our implementation of strict two-phase locking divergence control [3] and broadcast-type optimistic divergence control <ref> [18, 20, 21] </ref> in the way they integrate strict serialization and ESR extension. 2.1 Two-phase Locking Divergence Control (2PLDC) 2PLDC is an extension of the classic 2PL concurrency control. We show a lock compatibility matrix in Figure 1 (a) 1 . <p> A conflict between strong and weak locks causes aborts. We show the lock compatibility matrix in Figure 1 (b). Every ET starts from the non-blocking phase and it escalates all locks associated with the past operations during the validation phase <ref> [20] </ref>. For strict serialization, when scheduling a new operation, a monitor investigates whether there exists escalated locks from other ETs. An escalation-flag indicates the midst of commit. If the monitor finds such one, for instance, when monitor U finds ^ W , it waits for the commit completion.
Reference: [21] <author> P. S. Yu and D. M. Dias. </author> <title> Analysis of hybrid concurrency control schemes for a high data contention environment. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> 18(2) </volume> <pages> 118-129, </pages> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: We call the CC and DC algorithms as strict serialization and ESR extension respectively. In the next two sections, we describe our implementation of strict two-phase locking divergence control [3] and broadcast-type optimistic divergence control <ref> [18, 20, 21] </ref> in the way they integrate strict serialization and ESR extension. 2.1 Two-phase Locking Divergence Control (2PLDC) 2PLDC is an extension of the classic 2PL concurrency control. We show a lock compatibility matrix in Figure 1 (a) 1 .
Reference: [22] <author> P. S. Yu, D. M. Dias, and S. S Lavenberg. </author> <title> On the analytical modeling of database concurrency control. </title> <journal> Journal of the ACM, </journal> <volume> 40(4) </volume> <pages> 831-872, </pages> <month> Sept. </month> <year> 1993. </year> <title> 15 (a) Throughput for UETs (b) Throughput for QETs (c) Response Time for UETs (d) Response Time for QETs 16 (a) 10 Resource Units (b) 1 Resources 17 (a) Throughput for UETs (b) Throughput for QETs (c) Response Time for UETs (d) Response Time for QETs 18 (a) *-spec=1,000; MPL=150 (b) *-spec=3,000; MPL=150 (c) *-spec=5,000; MPL=150 (d) *-spec=5,000; MPL=100 19 </title>
References-found: 22

