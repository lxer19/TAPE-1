URL: http://www.is.cs.cmu.edu/papers/speech/1996/ICSLP96-tilo.ps.gz
Refering-URL: http://www.is.cs.cmu.edu/ISL.speech.publications.html
Root-URL: 
Email: sloboda@ira.uka.de,waibel@ira.uka.de  
Title: DICTIONARY LEARNING FOR SPONTANEOUS SPEECH RECOGNITION  
Author: Tilo Sloboda, Alex Waibel 
Address: Pittsburgh, USA  
Affiliation: Interactive Systems Laboratories University of Karlsruhe Karlsruhe, Germany Carnegie Mellon University  
Abstract: Spontaneous speech adds a variety of phenomena to a speech recognition task: false starts, human and nonhuman noises, new words, and alternative pronunciations. All of these phenomena have to be tackled when adapting a speech recognition system for spontaneous speech. In this paper we will focus on how to automatically expand and adapt phonetic dictionaries for spontaneous speech recognition. Especially for spontaneous speech it is important to choose the pronunciations of a word according to the frequency in which they appear in the database rather than the "correct" pronunciation as might be found in a lexicon. Therefore, we proposed a data-driven approach to add new pronunciations to a given phonetic dictionary [1] in a way that they model the given occurrences of words in the database. We will show how this algorithm can be extended to produce alternative pronunciations for word tuples and frequently misrecognized words. We will also discuss how further knowledge can be incorporated into the phoneme recognizer in a way that it learns to generalize from pronunciations which were found previously. The experiments have been performed on the German Spontaneous Scheduling Task (GSST), using the speech recognition engine of JANUS 2, the spontaneous speech-to-speech translation system of the Interactive Systems Laboratories at Carnegie Mellon and Karlsruhe University [2, 3]. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Tilo Sloboda: </author> <title> Dictionary Learning: Performance through Consistency, </title> <booktitle> Proceedings of the ICASSP 1995, Detroit, </booktitle> <volume> volume 1, </volume> <pages> pp 453-456. </pages>
Reference: 2. <author> A.Waibel, M.Finke, D.Gates, M.Gavalda, T.Kemp, A.Lavie, L.Levin, M.Maier, L.Mayfield, A.McNair, I.Rogina, K.Shima, T.Sloboda, M.Woszczyna, T.Zeppenfeld, P.Zhan: </author> <title> JANUS II | Translation of Spontaneous Conversational Speech, </title> <booktitle> Proceedings of the ICASSP 1996, Atlanta, </booktitle> <volume> volume 1, </volume> <pages> pp 409-412. </pages>
Reference-contexts: The test vocabulary contained more than 3300 entries. Training Test #Dialogues 608 8 #Utterances 10735 110 #Words 281160 2346 Vocabulary Size 5442 543 Table 1: GSST Database For the experiments reported here we used the hybrid LVQ/HMM recognizer of JANUS 2, our spontaneous speech-to-speech translation system <ref> [2, 3] </ref>, using 69 context independent 1 phoneme models, including noise models. 4.2. Experiments In our first set of experiments we carried out all the steps described in the previous section, with exception of retraining.
Reference: 3. <author> M. Woszczyna, N. Aoki-Waibel, F.D. But, N. Coccaro, K. Horiguchi, T. Kemp, A. Lavie, A. McNair, T. Polzin, I. Rogina, C.P. Rose, T. Schultz, B. Suhm, M. Tomita, A. Waibel: </author> <title> JANUS 93: Towards Spontaneous Speech Translation, </title> <booktitle> Proceedings of the ICASSP 1994, Adelaide, </booktitle> <volume> volume 1, </volume> <pages> pp 345-348. </pages>
Reference-contexts: The test vocabulary contained more than 3300 entries. Training Test #Dialogues 608 8 #Utterances 10735 110 #Words 281160 2346 Vocabulary Size 5442 543 Table 1: GSST Database For the experiments reported here we used the hybrid LVQ/HMM recognizer of JANUS 2, our spontaneous speech-to-speech translation system <ref> [2, 3] </ref>, using 69 context independent 1 phoneme models, including noise models. 4.2. Experiments In our first set of experiments we carried out all the steps described in the previous section, with exception of retraining.
Reference: 4. <author> M.Woszczyna, N.Coccaro, A.Eisele, A.Lavie, A.McNair, T.Polzin, I.Rogina, C.P.Rose, T.Sloboda, M.Tomita, J.Tsutsumi, N.Aoki-Waibel, A.Waibel, W.Ward: </author> <title> Recent Advances in JANUS, a Speech to Speech Translation System, </title> <booktitle> Proceedings of the EUROSPEECH, </booktitle> <address> Berlin, </address> <year> 1993. </year>
Reference: 5. <author> J.L.Gauvain, L.F.Lamel, G.Adda, M.Adda-Decker: </author> <title> The LIMSI Continuous Speech Dictation System: Evaluation on the ARPA Wall Street Journal Task, </title> <booktitle> Proceedings of the ICASSP 1994, Adelaide, </booktitle> <volume> volume 1, </volume> <pages> pp 557-560. </pages>
Reference-contexts: We will show how our algorithm can learn pronunciations for word tuples and therefore learn interword effects such as coarticulation between words and dialectic variations of words and word sequences. 2. DICTIONARY LEARNING Modifying dictionaries is usually done either by hand or by applying phonological rules (e.g. <ref> [5, 6] </ref>) to a given dictionary. Hand tuning and modifying the dictionary requires an expert. It is time consuming and labor intensive, especially if a lot of new words need to be added, e.g. when the task is still growing, or the system is adapted to a new task.
Reference: 6. <author> Toru Imai, Akio Ando, Eiichi Miyasaka: </author> <title> A New Method for Automatic Generation of Speaker-Dependent Phonological Rules, </title> <booktitle> Proceedings of the ICASSP 1995, Detroit, </booktitle> <volume> volume 1, </volume> <pages> pp 864-867. </pages>
Reference-contexts: We will show how our algorithm can learn pronunciations for word tuples and therefore learn interword effects such as coarticulation between words and dialectic variations of words and word sequences. 2. DICTIONARY LEARNING Modifying dictionaries is usually done either by hand or by applying phonological rules (e.g. <ref> [5, 6] </ref>) to a given dictionary. Hand tuning and modifying the dictionary requires an expert. It is time consuming and labor intensive, especially if a lot of new words need to be added, e.g. when the task is still growing, or the system is adapted to a new task.
References-found: 6

