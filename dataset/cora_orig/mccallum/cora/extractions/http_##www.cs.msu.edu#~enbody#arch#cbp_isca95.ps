URL: http://www.cs.msu.edu/~enbody/arch/cbp_isca95.ps
Refering-URL: http://www.cs.msu.edu/~enbody/arch.html
Root-URL: http://www.cs.msu.edu
Email: smith-@das.harvard.edu  
Title: A Comparative Analysis of Schemes for Correlated Branch Prediction  
Author: Cliff Young, Nicolas Gloy, and Michael D. Smith -cyoung, ng, 
Keyword: branch prediction, branch correlation, branch stream characteristics.  
Address: Cambridge, MA 02138  
Affiliation: Division of Applied Sciences Harvard University,  
Abstract: Modern high-performance architectures require extremely accurate branch prediction to overcome the performance limitations of conditional branches. We present a framework that categorizes branch prediction schemes by the way in which they partition dynamic branches and by the kind of predictor that they use. The framework allows us to compare and contrast branch prediction schemes, and to analyze why they work. We use the framework to show how a static correlated branch prediction scheme increases branch bias and thus improves overall branch prediction accuracy. We also use the framework to identify the fundamental differences between static and dynamic correlated branch prediction schemes. This study shows that there is room to improve the prediction accuracy of existing branch prediction schemes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. Bala, </author> <type> personal communication, </type> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: Exploiting Cross-Procedure Correlation Statically We have not yet found a simple code transformation that can generally preserve correlation across calls. However, a number of techniques may be useful: selective inlining [6], template formation, and multiple entry points <ref> [1] </ref>. Fisher and Freudenberger point out that sophisticated ILP compilers already expect to perform aggressive inlining [5]. Inlining all procedures is impractical, since it is exponential in the depth and degree of the program call graph.
Reference: [2] <author> T. Ball and J. Larus, </author> <title> Branch Prediction for Free, </title> <booktitle> Proc. ACM SIGPLAN 1993 Conf. on Prog. Lang. Design and Implementation, </booktitle> <month> Jun. </month> <year> 1993. </year>
Reference-contexts: The backwards taken forwards not taken (BTFNT) scheme [12] bases the static prediction on the sign of a branchs target offset. Other schemes employ a predictor that com putes predictions as a function of the opcode of the branch [7]. Finally, methods like those described by Ball and Larus <ref> [2] </ref> use sophisticated heuristics about the program structure to generate a static prediction for each branch.
Reference: [3] <author> J. Bentley, </author> <title> Programming Pearls, </title> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: Inlining all procedures is impractical, since it is exponential in the depth and degree of the program call graph. But since a small number of procedures make up the majority of program execution cycles <ref> [3] </ref>, it is also likely that a small number of procedures are the best candidates for inlining to extract correlation.
Reference: [4] <author> P. Chang, E. Hao, T. Yeh, and Y. Patt, </author> <title> Branch Classification: a New Mechanism for Improving Branch Predictor Performance, </title> <booktitle> in Proc. 27th Annual ACM/IEEE Intl. Symp. and Workshop on Microarchitecture, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Recent work in branch prediction has led to the development of both hardware and software schemes that achieve good prediction accuracy by exploiting branch correlation <ref> [4, 9, 11, 14, 15, 16, 17] </ref>. However, little attention has been paid to why these schemes behave better than prior ones and to where further improvements can be made. <p> Why branch prediction schemes perform differently is just as important as how well they perform. Only after explaining why a scheme works can one understand appropriate ways to improve or alter it. Recent work by McFarling [9] and by Chang et al. <ref> [4] </ref> uses analysis, reasoning, and experimentation to devise better hardware schemes for correlated branch prediction. In particular, McFarling [9] noticed significant redundancy in the two-level index of the correlation-based branch prediction scheme proposed by Pan, So, and Rahmeh [11]. <p> By hashing the branch history with the branch address, McFarlings gshare scheme often improves prediction accuracy under the constraint of a fixed-size table of predictors. Similarly, Chang et al. <ref> [4] </ref> noticed that, for a fixed-size table of predictors, branches biased to one particular branch direction more than 95% of the time exhibited better prediction accuracies on a two-level adaptive scheme [14] when one decreased the branch history length, while the rest of the branches exhibited better prediction accuracies when one <p> Still, it is more difficult to understand the actual workings of todays branch prediction schemes than it needs to be. To make it easier to develop optimizations such as those proposed by McFar-ling [9] and Chang et al. <ref> [4] </ref>, we present a unifying framework that allows one to analyze and categorize branch prediction schemes. Because the framework is based on a theoretical model of the branch prediction problem, it is general enough to encompass all branch prediction schemes proposed to date. <p> This truncation merges streams that would be separated by a more sophisticated divider. We distinguish aliasing from merging: aliasing combines streams from different static branches, while merging combines streams from one static branch. 2.5 Hybrid Approaches Recent work in branch prediction by McFarling [9] and Chang <ref> [4] </ref> has proposed hybrid branch prediction schemes which group together multiple basic prediction schemes. The hybrid schemes, either statically or dynamically, select the basic prediction scheme that performs best on a stream. <p> As in a cache, increasing the size of the prediction table can help to reduce conicts (and increase prediction accuracy), as is shown in most of the dynamic branch prediction literature [10, 11, 14, 15, 16]. Chang et al. <ref> [4] </ref> show benefits to separating out strongly biased branches from weakly biased branches, noting that using static prediction on the strongly biased branches reduces contention (aliasing) in the table of 2-bit counters. Unlike cache conict misses though, aliasing can be constructive or harmless in addition to destructive. <p> The absolute number of Dynamic Better streams is less than 1,000 for all benchmarks except espresso. This suggests that there are ways to build better hybrid static/dynamic prediction schemes than that proposed by Chang et al <ref> [4] </ref>. Their scheme assigns all branches with low bias to dynamic predictors.
Reference: [5] <author> J. Fisher and S. Freudenberger, </author> <title> Predicting Conditional Branch Directions From Previous Runs of a Program, </title> <booktitle> Proc. 5th Annual Intl. Conf. on Architectural Support for Prog. Lang. and Operating Systems, </booktitle> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: In this section, we examine a simple application of this framework to a pair of similar prediction schemes: per-branch static profile prediction and our static correlated profile prediction [17]. Per-branch static profiling has been shown to work well in a number of studies <ref> [5, 10] </ref>. In this section, we show how our code transformation exploits branch corre lation to increase branch bias. As noted in Section 2, bias is key to static branch prediction. Figure 4 plots the distribution of taken branch frequency averaged over all benchmarks and data sets. <p> For static profile prediction to be practical, the static predictions chosen must be valid across invocations of the program. If the majority direction of a stream differs between the profiled (training) data set and the running (testing) data set, then a static predictor will suffer. Fisher and Freudenberger <ref> [5] </ref> examined a number of different benchmarks and data sets under static profile prediction, and determined that good prediction could be achieved even while training and testing on different data sets. <p> However, a number of techniques may be useful: selective inlining [6], template formation, and multiple entry points [1]. Fisher and Freudenberger point out that sophisticated ILP compilers already expect to perform aggressive inlining <ref> [5] </ref>. Inlining all procedures is impractical, since it is exponential in the depth and degree of the program call graph.
Reference: [6] <author> W. Hwu and P. Chang, </author> <title> Inlining Function Expansion for Compiling C Programs, </title> <booktitle> Proc. ACM SIGPLAN 1989 Conf. on Prog. Lang. Design and Implementation, </booktitle> <month> Jun. </month> <year> 1989. </year>
Reference-contexts: These results use a history depth of 12 and train and test on the same dataset. Exploiting Cross-Procedure Correlation Statically We have not yet found a simple code transformation that can generally preserve correlation across calls. However, a number of techniques may be useful: selective inlining <ref> [6] </ref>, template formation, and multiple entry points [1]. Fisher and Freudenberger point out that sophisticated ILP compilers already expect to perform aggressive inlining [5]. Inlining all procedures is impractical, since it is exponential in the depth and degree of the program call graph.
Reference: [7] <author> J. Lee and A. Smith, </author> <title> Branch Prediction Strategies and Branch Target Buffer Design, </title> <journal> Computer, </journal> <volume> 17(1), </volume> <month> Jan. </month> <year> 1984. </year>
Reference-contexts: In other words, we consider a branch prediction scheme to be a technique for improving performance by anticipating the outcome of conditional branches. Other work has shown how to couple a branch prediction scheme with a branch target buffer to eliminate the performance penalties of branches <ref> [7] </ref>. Why branch prediction schemes perform differently is just as important as how well they perform. Only after explaining why a scheme works can one understand appropriate ways to improve or alter it. <p> In the simplest case, the divider is the identity function; the program execution stream is fed to a single predictor. The prediction scheme that statically predicts all branches taken [12] and the prediction scheme that uses a single 2-bit saturating up/down counter for all branches <ref> [7] </ref> are both examples of the identity divider function. The most popular divider function in todays microprocessors partitions the program execution stream based on the static branch identifier. <p> The intuition behind this divider is that each branch should have its own predictor because the characteristics and past history of this branch are a good pre dictor of its future behavior. Both the per-branch 2-bit counter scheme 3 <ref> [7] </ref> and per-branch profile-based prediction scheme [10] partition the program execution stream in this manner. More recent branch prediction schemes further subdivide the per-branch streams. The intuition behind these schemes is that finer decomposition of a per-branch stream can increase the predictability of the individual substreams. <p> The backwards taken forwards not taken (BTFNT) scheme [12] bases the static prediction on the sign of a branchs target offset. Other schemes employ a predictor that com putes predictions as a function of the opcode of the branch <ref> [7] </ref>. Finally, methods like those described by Ball and Larus [2] use sophisticated heuristics about the program structure to generate a static prediction for each branch. <p> By far, the most popular dynamic predictor is the 2-bit saturating, up/down counter [12]. This predictor forms the basis of all of the correlated branch predictors described by McFarling [9], Pan et al. [11], and Yeh and Patt [14, 15, 16]. Lee and Smith <ref> [7] </ref> observed that the execution streams of most program branches tend to occur in long runs 4 and that an n-bit counter predictor can exploit this regularity. Smith [12] further observed that a 2-bit counter empirically provides an appropriate amount of damping (or hysteresis) to changes in stream direction.
Reference: [8] <author> S. Mahlke, et al., </author> <title> Characterizing the Impact of Predicated Execution on Branch Prediction, </title> <booktitle> Proc. 27th Annual Intl. Symp. on Microarchitecture, </booktitle> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: However, since the number of static streams requiring an adaptive predictor is very small, the possibility exists for a compiler to selectively apply techniques like predication <ref> [8] </ref> to these few streams. The vast majority of streams can be handled using simple static branch prediction techniques. Hybrid prediction schemes can mix static and dynamic predictors in one scheme.
Reference: [9] <author> S. McFarling, </author> <title> Combining Branch Predictors, </title> <note> WRL Technical Note TN-36, </note> <month> June </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Recent work in branch prediction has led to the development of both hardware and software schemes that achieve good prediction accuracy by exploiting branch correlation <ref> [4, 9, 11, 14, 15, 16, 17] </ref>. However, little attention has been paid to why these schemes behave better than prior ones and to where further improvements can be made. <p> Why branch prediction schemes perform differently is just as important as how well they perform. Only after explaining why a scheme works can one understand appropriate ways to improve or alter it. Recent work by McFarling <ref> [9] </ref> and by Chang et al. [4] uses analysis, reasoning, and experimentation to devise better hardware schemes for correlated branch prediction. In particular, McFarling [9] noticed significant redundancy in the two-level index of the correlation-based branch prediction scheme proposed by Pan, So, and Rahmeh [11]. <p> Only after explaining why a scheme works can one understand appropriate ways to improve or alter it. Recent work by McFarling <ref> [9] </ref> and by Chang et al. [4] uses analysis, reasoning, and experimentation to devise better hardware schemes for correlated branch prediction. In particular, McFarling [9] noticed significant redundancy in the two-level index of the correlation-based branch prediction scheme proposed by Pan, So, and Rahmeh [11]. By hashing the branch history with the branch address, McFarlings gshare scheme often improves prediction accuracy under the constraint of a fixed-size table of predictors. <p> Still, it is more difficult to understand the actual workings of todays branch prediction schemes than it needs to be. To make it easier to develop optimizations such as those proposed by McFar-ling <ref> [9] </ref> and Chang et al. [4], we present a unifying framework that allows one to analyze and categorize branch prediction schemes. Because the framework is based on a theoretical model of the branch prediction problem, it is general enough to encompass all branch prediction schemes proposed to date. <p> Surprisingly, there are very few designs for dynamic predictors. By far, the most popular dynamic predictor is the 2-bit saturating, up/down counter [12]. This predictor forms the basis of all of the correlated branch predictors described by McFarling <ref> [9] </ref>, Pan et al. [11], and Yeh and Patt [14, 15, 16]. Lee and Smith [7] observed that the execution streams of most program branches tend to occur in long runs 4 and that an n-bit counter predictor can exploit this regularity. <p> Issues in aliasing have led researchers to develop different branch prediction schemes that we would classify as based on the same ideal branch prediction model. For instance, the GAs scheme [14] and McFarlings gshare scheme <ref> [9] </ref> both ideally divide the program execution stream into per-branch global-history substreams, and both use a 2-bit counter as the base predictor. <p> This truncation merges streams that would be separated by a more sophisticated divider. We distinguish aliasing from merging: aliasing combines streams from different static branches, while merging combines streams from one static branch. 2.5 Hybrid Approaches Recent work in branch prediction by McFarling <ref> [9] </ref> and Chang [4] has proposed hybrid branch prediction schemes which group together multiple basic prediction schemes. The hybrid schemes, either statically or dynamically, select the basic prediction scheme that performs best on a stream. <p> Each of these implementation differences can be seen as a limitation that keeps the implemented divider from behaving as precisely as an ideal mathematical divider. Sections 4.1 through 4.3 show, by focusing on gshare <ref> [9] </ref>, GAs [14], and our static correlated branch prediction scheme (scbp) [17], that the removal of these implementation differences can improve the prediction accuracy of correlated branch prediction schemes.
Reference: [10] <author> S. McFarling and J. Hennessy, </author> <title> Reducing the Cost of Branches, </title> <booktitle> Proc. of 13th Annual Intl. Symp. on Computer Architecture, </booktitle> <month> Jun. </month> <year> 1986. </year>
Reference-contexts: The intuition behind this divider is that each branch should have its own predictor because the characteristics and past history of this branch are a good pre dictor of its future behavior. Both the per-branch 2-bit counter scheme 3 [7] and per-branch profile-based prediction scheme <ref> [10] </ref> partition the program execution stream in this manner. More recent branch prediction schemes further subdivide the per-branch streams. The intuition behind these schemes is that finer decomposition of a per-branch stream can increase the predictability of the individual substreams. <p> In this section, we examine a simple application of this framework to a pair of similar prediction schemes: per-branch static profile prediction and our static correlated profile prediction [17]. Per-branch static profiling has been shown to work well in a number of studies <ref> [5, 10] </ref>. In this section, we show how our code transformation exploits branch corre lation to increase branch bias. As noted in Section 2, bias is key to static branch prediction. Figure 4 plots the distribution of taken branch frequency averaged over all benchmarks and data sets. <p> Instead of suffering con-ict misses though, aliased predictors suffer from muddled predictions. As in a cache, increasing the size of the prediction table can help to reduce conicts (and increase prediction accuracy), as is shown in most of the dynamic branch prediction literature <ref> [10, 11, 14, 15, 16] </ref>. Chang et al. [4] show benefits to separating out strongly biased branches from weakly biased branches, noting that using static prediction on the strongly biased branches reduces contention (aliasing) in the table of 2-bit counters.
Reference: [11] <author> S. Pan, K. So, and J. Rahmeh, </author> <title> Improving the Accuracy of Dynamic Branch Prediction Using Branch Correlation, </title> <booktitle> Proc. 5th Annual Intl. Conf. on Architectural Support for Prog. Lang. and Operating Systems, </booktitle> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Recent work in branch prediction has led to the development of both hardware and software schemes that achieve good prediction accuracy by exploiting branch correlation <ref> [4, 9, 11, 14, 15, 16, 17] </ref>. However, little attention has been paid to why these schemes behave better than prior ones and to where further improvements can be made. <p> Recent work by McFarling [9] and by Chang et al. [4] uses analysis, reasoning, and experimentation to devise better hardware schemes for correlated branch prediction. In particular, McFarling [9] noticed significant redundancy in the two-level index of the correlation-based branch prediction scheme proposed by Pan, So, and Rahmeh <ref> [11] </ref>. By hashing the branch history with the branch address, McFarlings gshare scheme often improves prediction accuracy under the constraint of a fixed-size table of predictors. <p> More recent branch prediction schemes further subdivide the per-branch streams. The intuition behind these schemes is that finer decomposition of a per-branch stream can increase the predictability of the individual substreams. For instance, Pan, So, and Rah-meh <ref> [11] </ref> describe a scheme (which Yeh and Patt call GAs [14]) that partitions each per-branch stream based on the pattern of directions of the preceding branch executions in the program execution stream, as illustrated in Figure 3. <p> Surprisingly, there are very few designs for dynamic predictors. By far, the most popular dynamic predictor is the 2-bit saturating, up/down counter [12]. This predictor forms the basis of all of the correlated branch predictors described by McFarling [9], Pan et al. <ref> [11] </ref>, and Yeh and Patt [14, 15, 16]. Lee and Smith [7] observed that the execution streams of most program branches tend to occur in long runs 4 and that an n-bit counter predictor can exploit this regularity. <p> Instead of suffering con-ict misses though, aliased predictors suffer from muddled predictions. As in a cache, increasing the size of the prediction table can help to reduce conicts (and increase prediction accuracy), as is shown in most of the dynamic branch prediction literature <ref> [10, 11, 14, 15, 16] </ref>. Chang et al. [4] show benefits to separating out strongly biased branches from weakly biased branches, noting that using static prediction on the strongly biased branches reduces contention (aliasing) in the table of 2-bit counters.
Reference: [12] <author> J. Smith, </author> <title> A Study of Branch Prediction Strategies, </title> <booktitle> Proc. 8th Annual Intl. Symp. on Computer Architecture, </booktitle> <month> Jun. </month> <year> 1981. </year>
Reference-contexts: Existing schemes divide the program execution stream in a variety of interesting ways. In the simplest case, the divider is the identity function; the program execution stream is fed to a single predictor. The prediction scheme that statically predicts all branches taken <ref> [12] </ref> and the prediction scheme that uses a single 2-bit saturating up/down counter for all branches [7] are both examples of the identity divider function. The most popular divider function in todays microprocessors partitions the program execution stream based on the static branch identifier. <p> Researchers have investigated a variety of static program and branch characteristics to help determine the appropriate static prediction for an execution stream. For example, the simple static branch prediction scheme that always predicts branches to take <ref> [12] </ref> uses the statistical fact that branches tend to take more often than they fall through. The backwards taken forwards not taken (BTFNT) scheme [12] bases the static prediction on the sign of a branchs target offset. <p> For example, the simple static branch prediction scheme that always predicts branches to take <ref> [12] </ref> uses the statistical fact that branches tend to take more often than they fall through. The backwards taken forwards not taken (BTFNT) scheme [12] bases the static prediction on the sign of a branchs target offset. Other schemes employ a predictor that com putes predictions as a function of the opcode of the branch [7]. <p> This has the added benefit of not requiring any training or profiling before the program run. Surprisingly, there are very few designs for dynamic predictors. By far, the most popular dynamic predictor is the 2-bit saturating, up/down counter <ref> [12] </ref>. This predictor forms the basis of all of the correlated branch predictors described by McFarling [9], Pan et al. [11], and Yeh and Patt [14, 15, 16]. <p> Lee and Smith [7] observed that the execution streams of most program branches tend to occur in long runs 4 and that an n-bit counter predictor can exploit this regularity. Smith <ref> [12] </ref> further observed that a 2-bit counter empirically provides an appropriate amount of damping (or hysteresis) to changes in stream direction. <p> A 1-bit counter has no damping (it simply records the direction of the last branch), and 3-bit and higher counters do not appear to offer large cost/benefit advantages over 2-bit counters <ref> [12] </ref>. Damping trades off adaptability for vulnerability to short minority runs. A 2-bit counter is excellent at predicting streams with long minor ity runs, and it is damped enough to ignore minority runs of length 1.
Reference: [13] <author> A. Srivastava and A. Eustace, </author> <title> ATOM: A System for Building Customized Program Analysis Tools, </title> <booktitle> Proc. SIGPLAN 94 Conf. on Prog. Lang. Design and Implementation, </booktitle> <month> Jun. </month> <year> 1994. </year>
Reference-contexts: The results in this paper were derived from trace-driven simulations. We collected the traces using ATOM v1.1 <ref> [13] </ref>. We compiled the SPECint92 benchmarks using cc version 2.0.0 and the optimization level specified in the SPEC makefiles. The additional benchmarks were compiled using gcc v2.6.0 (-O3).
Reference: [14] <author> T. Yeh and Y. Patt, </author> <title> Two-Level Adaptive Branch Prediction, </title> <booktitle> Proc. 24th Annual ACM/IEEE Intl. Symp. and Workshop on Microarchitecture, </booktitle> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Recent work in branch prediction has led to the development of both hardware and software schemes that achieve good prediction accuracy by exploiting branch correlation <ref> [4, 9, 11, 14, 15, 16, 17] </ref>. However, little attention has been paid to why these schemes behave better than prior ones and to where further improvements can be made. <p> Similarly, Chang et al. [4] noticed that, for a fixed-size table of predictors, branches biased to one particular branch direction more than 95% of the time exhibited better prediction accuracies on a two-level adaptive scheme <ref> [14] </ref> when one decreased the branch history length, while the rest of the branches exhibited better prediction accuracies when one increased the branch history length. This observation led them to propose several new hybrid branch prediction schemes with better overall prediction accuracies. <p> More recent branch prediction schemes further subdivide the per-branch streams. The intuition behind these schemes is that finer decomposition of a per-branch stream can increase the predictability of the individual substreams. For instance, Pan, So, and Rah-meh [11] describe a scheme (which Yeh and Patt call GAs <ref> [14] </ref>) that partitions each per-branch stream based on the pattern of directions of the preceding branch executions in the program execution stream, as illustrated in Figure 3. <p> Surprisingly, there are very few designs for dynamic predictors. By far, the most popular dynamic predictor is the 2-bit saturating, up/down counter [12]. This predictor forms the basis of all of the correlated branch predictors described by McFarling [9], Pan et al. [11], and Yeh and Patt <ref> [14, 15, 16] </ref>. Lee and Smith [7] observed that the execution streams of most program branches tend to occur in long runs 4 and that an n-bit counter predictor can exploit this regularity. <p> Issues in aliasing have led researchers to develop different branch prediction schemes that we would classify as based on the same ideal branch prediction model. For instance, the GAs scheme <ref> [14] </ref> and McFarlings gshare scheme [9] both ideally divide the program execution stream into per-branch global-history substreams, and both use a 2-bit counter as the base predictor. <p> Each of these implementation differences can be seen as a limitation that keeps the implemented divider from behaving as precisely as an ideal mathematical divider. Sections 4.1 through 4.3 show, by focusing on gshare [9], GAs <ref> [14] </ref>, and our static correlated branch prediction scheme (scbp) [17], that the removal of these implementation differences can improve the prediction accuracy of correlated branch prediction schemes. <p> Instead of suffering con-ict misses though, aliased predictors suffer from muddled predictions. As in a cache, increasing the size of the prediction table can help to reduce conicts (and increase prediction accuracy), as is shown in most of the dynamic branch prediction literature <ref> [10, 11, 14, 15, 16] </ref>. Chang et al. [4] show benefits to separating out strongly biased branches from weakly biased branches, noting that using static prediction on the strongly biased branches reduces contention (aliasing) in the table of 2-bit counters.
Reference: [15] <author> T. Yeh and Y. Patt, </author> <title> A Comparison of Dynamic Branch Predictors that use Two Levels of Branch History, </title> <booktitle> Proc. 20th Annual Intl. Symp. on Computer Architecture, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Recent work in branch prediction has led to the development of both hardware and software schemes that achieve good prediction accuracy by exploiting branch correlation <ref> [4, 9, 11, 14, 15, 16, 17] </ref>. However, little attention has been paid to why these schemes behave better than prior ones and to where further improvements can be made. <p> We refer to these substreams as per-branch global-pattern streams. As another way to subdivide per-branch streams, Yeh and Patt describe a scheme called PAs <ref> [15] </ref> that uses the last branches in a per-branch stream to further partition that per-branch stream. This leads to a different set of substreams from the GAs scheme. Formally, consider the branch execution in the program execution stream, which is an execution of branch . <p> Surprisingly, there are very few designs for dynamic predictors. By far, the most popular dynamic predictor is the 2-bit saturating, up/down counter [12]. This predictor forms the basis of all of the correlated branch predictors described by McFarling [9], Pan et al. [11], and Yeh and Patt <ref> [14, 15, 16] </ref>. Lee and Smith [7] observed that the execution streams of most program branches tend to occur in long runs 4 and that an n-bit counter predictor can exploit this regularity. <p> A pattern is a non-empty string . A recurrent pattern is a substring that occurs multiple times in a stream. Unlike bias and distribution of runs, which are typically used to predict streams that have been divided, this property is exploited by some dividers (e.g. the PAs scheme <ref> [15] </ref>). 2.4 Implementation Details To this point, our explanations of existing branch prediction schemes focused on the ideal implementation of a scheme. For example, the explanation above describes a per-branch dynamic prediction scheme based on 2-bit counters as able to assign each per-branch stream to a unique 2-bit counter. <p> Instead of suffering con-ict misses though, aliased predictors suffer from muddled predictions. As in a cache, increasing the size of the prediction table can help to reduce conicts (and increase prediction accuracy), as is shown in most of the dynamic branch prediction literature <ref> [10, 11, 14, 15, 16] </ref>. Chang et al. [4] show benefits to separating out strongly biased branches from weakly biased branches, noting that using static prediction on the strongly biased branches reduces contention (aliasing) in the table of 2-bit counters.
Reference: [16] <author> T. Yeh, </author> <title> Two-Level Adaptive Branch Prediction and Instruction Fetch Mechanisms for High Performance Superscalar Processors, </title> <institution> Computer Science and Engineering Div. Tech. Report CSE-TR-182-93, Univ. of Michigan, </institution> <address> Ann Arbor, MI, </address> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Recent work in branch prediction has led to the development of both hardware and software schemes that achieve good prediction accuracy by exploiting branch correlation <ref> [4, 9, 11, 14, 15, 16, 17] </ref>. However, little attention has been paid to why these schemes behave better than prior ones and to where further improvements can be made. <p> Surprisingly, there are very few designs for dynamic predictors. By far, the most popular dynamic predictor is the 2-bit saturating, up/down counter [12]. This predictor forms the basis of all of the correlated branch predictors described by McFarling [9], Pan et al. [11], and Yeh and Patt <ref> [14, 15, 16] </ref>. Lee and Smith [7] observed that the execution streams of most program branches tend to occur in long runs 4 and that an n-bit counter predictor can exploit this regularity. <p> Instead of suffering con-ict misses though, aliased predictors suffer from muddled predictions. As in a cache, increasing the size of the prediction table can help to reduce conicts (and increase prediction accuracy), as is shown in most of the dynamic branch prediction literature <ref> [10, 11, 14, 15, 16] </ref>. Chang et al. [4] show benefits to separating out strongly biased branches from weakly biased branches, noting that using static prediction on the strongly biased branches reduces contention (aliasing) in the table of 2-bit counters.
Reference: [17] <author> C. Young and M. Smith, </author> <title> Improving the Accuracy of Static Branch Prediction Using Branch Correlation, </title> <booktitle> Proc. 6th Annual Intl. Conf. on Architectural Support for Prog. Lang. and Operating Systems, </booktitle> <month> October </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Recent work in branch prediction has led to the development of both hardware and software schemes that achieve good prediction accuracy by exploiting branch correlation <ref> [4, 9, 11, 14, 15, 16, 17] </ref>. However, little attention has been paid to why these schemes behave better than prior ones and to where further improvements can be made. <p> We refer to these substreams as per-branch branch-pattern streams. As a last example of how to subdivide per-branch substreams, we consider our scheme for static correlated branch prediction (scbp) <ref> [17] </ref>. This scheme divides both by branch and by the path of branches that led to the executed branch. A path differs from a pattern because it includes both the branch identifiers and the executed directions, not just the concatenation of direction bits. <p> If the majority direction remains the same from the profile (training) to the testing run, then a profiled static predictor will perform well. To date, researchers have used only the overall bias of the past branch exe cution to set the static prediction. In our earlier paper <ref> [17] </ref>, we used other characteristics of the past execution stream, but we used this information to reorganize the program so that its individual branch streams are more strongly biased. In contrast, dynamic predictors can adapt to track the bias of a stream during a single execution of a program. <p> Static branch prediction schemes that can fix a prediction to each static branch in the program obviously do not suffer from these effects of aliasing. However, static schemes have their own potential limitations due to implementation details. For example, the implementation of our algorithm for static correlated branch prediction <ref> [17] </ref> does not distinguish between paths that cross a procedure call or return boundary. In other words, they effectively truncate the vector that is used to divide the stream in the cases where a path crosses a procedure boundary. <p> In this section, we examine a simple application of this framework to a pair of similar prediction schemes: per-branch static profile prediction and our static correlated profile prediction <ref> [17] </ref>. Per-branch static profiling has been shown to work well in a number of studies [5, 10]. In this section, we show how our code transformation exploits branch corre lation to increase branch bias. As noted in Section 2, bias is key to static branch prediction. <p> The effect of exploiting branch correlation is to divide each per-branch stream into several separate streams, discriminating by correlation paths in addition to the static branch identifier. The Path History bars in Figure 4 show the distribution of taken branch frequency after our transformation to exploit branch correlation <ref> [17] </ref>. Compared to the Self History bars, the Path History bars This plot averages over all benchmarks, giving equal weight to each data set run. The Self-History bars indicate the branch bias in the original executables. <p> Superficially, one can compare the prediction accuracy reported by the designers of static and dynamic correlated schemes, but this numerical comparison is unenlightening. For example, in an earlier paper <ref> [17] </ref>, we found that our static correlated branch prediction scheme did not achieve as high a prediction accuracy as the published dynamic correlated schemes. <p> Each of these implementation differences can be seen as a limitation that keeps the implemented divider from behaving as precisely as an ideal mathematical divider. Sections 4.1 through 4.3 show, by focusing on gshare [9], GAs [14], and our static correlated branch prediction scheme (scbp) <ref> [17] </ref>, that the removal of these implementation differences can improve the prediction accuracy of correlated branch prediction schemes. Once we have equalized the divider function, an interesting question to ask is how much benefit one gets from the use of a dynamic predictor in a correlated scheme. <p> The vast majority of such cases turned out to be cross-procedure correlation: branches that occurred just after a procedure entry or just after a procedure return. Our scbp scheme <ref> [17] </ref> cannot preserve correlation information across procedure calls. The scheme encodes correlation history into the program counter by duplicating basic blocks. A particular copy of a basic block implies some set of previous execution paths. true per-branch, global-pattern divider.
Reference: [18] <author> C. Young, N. Gloy, and M. Smith, </author> <title> A Comparative Analysis of Schemes for Correlated Branch Prediction, </title> <type> Technical Report 06-95, </type> <institution> Center for Research in Computing Technology, Harvard University, </institution> <address> Cambridge, MA, </address> <month> Mar. </month> <year> 1995. </year>
Reference-contexts: Cliff Young is funded by a Graduate Fellowship from the Office of Naval Research. Michael D. Smith is supported by a National Science Foundation Young Investigator award, grant number CCR-9457779. An expanded set of the results for this paper can be found in <ref> [18] </ref>.
References-found: 18

