URL: http://www.cs.unc.edu/~anderson/papers/rtss98.ps.Z
Refering-URL: http://www.cs.unc.edu/~anderson/papers.html
Root-URL: http://www.cs.unc.edu
Email: fanderson,jain,jeffayg@cs.unc.edu  
Title: Efficient Object Sharing in Quantum-Based Real-Time Systems  
Author: James H. Anderson, Rohit Jain, and Kevin Jeffay 
Address: Chapel Hill, NC 27599-3175  
Affiliation: Department of Computer Science University of North Carolina  
Abstract: We consider the problem of implementing shared objects in uniprocessor and multiprocessor real-time systems in which tasks are executed using a scheduling quantum. In most quantum-based systems, the size of the quantum is quite large in comparison to the length of an object call. As a result, most object calls can be expected to execute without preemption. A good object-sharing scheme should optimize for this expected case, while achieving low overhead when preemptions do occur. In this paper, we present several new shared-object algorithms for uniprocessors and multiprocessors that were designed based upon this principle. We also present scheduling analysis results that can be used in conjunction with these algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Anderson, R. Jain, and K. </author> <note> Jeffay Efficient Object Sharing in Quantum-Based Real-Time Systems (expanded version of this paper). Available at http://www.cs.unc.edu/anderson/papers.html. </note>
Reference-contexts: If the code in Figure 2 is never preempted when executed by any task, then lines 6-8, 10-13, and 16-19 are never executed. Thus, in the expected case, this object implementation should perform well. In the full paper <ref> [1] </ref>, an implementation of a multi-word CAS (MWCAS) object is presented that is based on techniques that are similar to those described above; this implementation is not included here due to lack of space. The semantics of MWCAS generalizes that of CAS to allow multiple words to be accessed simultaneously. <p> Thus, such an access can be performed using a less-costly code fragment that is purely sequential. All of the scheduling conditions presented in this subsection can be improved by accounting for this fact. In the full paper <ref> [1] </ref>, we show how object-sharing overheads arising from algorithms as proposed here affect lag-bound calculations in proportional-share (PS) scheduled systems. In the PS scheduling literature, the term client is used to refer to a schedulable entity. <p> Each task's average estimated retry cost is shown. were generated in total, and for each task set, a retry cost was computed for each task using the two methods being compared. Due to space limitations, the exact methodology we used in generating task sets is not described here; see <ref> [1] </ref> for details. The results of these experiments are depicted in Figure 3. This figure shows the average retry cost of each task over all generated task sets as computed by each method. As before, tasks are indexed in order of increasing periods.
Reference: [2] <author> J. Anderson, R. Jain, and D. Ott. </author> <title> Wait-free synchronization in quantum-based multiprogrammed systems. </title> <booktitle> In Proceedings of the 12th International Symp. on Distributed Computing (to appear). </booktitle> <publisher> Springer Verlag, </publisher> <year> 1998. </year>
Reference-contexts: We have presented experimental evidence that such implementations should entail low overhead in practice. In a recent related paper, Anderson, Jain, and Ott presented a number of new results on the theoretical foundations of wait-free synchronization in quantum-based systems <ref> [2] </ref>. It was shown in that paper that the ability to achieve wait-free synchronization in quantum-based systems is a function of both the power of available synchronization primitives and the size of the scheduling quantum. We hope the results of [2] and this paper will spark further research on synchronization problems <p> on the theoretical foundations of wait-free synchronization in quantum-based systems <ref> [2] </ref>. It was shown in that paper that the ability to achieve wait-free synchronization in quantum-based systems is a function of both the power of available synchronization primitives and the size of the scheduling quantum. We hope the results of [2] and this paper will spark further research on synchronization problems arising in quantum-based systems. Acknowledgement: We are grateful to Alex Blate for his help in running simulation experiments. We also acknowledge David Koppelman for his help with the Proteus simulator.
Reference: [3] <author> J. Anderson, R. Jain, and S. Ramamurthy. </author> <title> Wait-free object-sharing schemes for real-time uniproces-sors and multiprocessors. </title> <booktitle> In Proceedings of the 18th IEEE Real-Time Systems Symp., </booktitle> <pages> pp. 111-122. </pages> <year> 1997. </year>
Reference-contexts: Our work builds upon recent research by us and others on using lock-free and wait-free shared-object algorithms in real-time systems <ref> [3, 4, 5, 6, 15, 19] </ref>. Operations on lock-free objects are optimistically performed using a user-level retry loop. Such an operation is atomically validated and committed by invoking a synchronization primitive such as compare-and-swap (CAS). The retry loop is executed repeatedly until this validation step succeeds. <p> As its definition shows, CCAS is a restriction of a two-word CAS primitive in which one word is a compare-only value. Lock-free and wait-free objects can be implemented by using a version number that is incremented by each object call <ref> [3, 12] </ref>. CCAS is useful because the version number can be used to ensure that a late CCAS operation performed by a task after having been preempted has no effect. a quantum-based uniprocessor. The implementation works by packing a task index into the words being accessed.
Reference: [4] <author> J. Anderson and S. Ramamurthy. </author> <title> A framework for implementing objects and scheduling tasks in lock-free real-time systems. </title> <booktitle> In Proceedings of the 17th IEEE Real-Time Systems Symp., </booktitle> <pages> pp. 92-105. </pages> <year> 1996. </year>
Reference-contexts: Our work builds upon recent research by us and others on using lock-free and wait-free shared-object algorithms in real-time systems <ref> [3, 4, 5, 6, 15, 19] </ref>. Operations on lock-free objects are optimistically performed using a user-level retry loop. Such an operation is atomically validated and committed by invoking a synchronization primitive such as compare-and-swap (CAS). The retry loop is executed repeatedly until this validation step succeeds. <p> Bounding interference costs using linear programming. Anderson and Ramamurthy showed that when lock-free objects are used in a uniprocessor system, object interference costs due to preemptions can be more accurately bounded using linear programming <ref> [4] </ref>. Given the Preemption Axiom, we show that it is possible to obtain bounds that are tighter than those of Anderson and Ramamurthy. Our linear programming conditions make use of a bit of additional notation. <p> Set 5: (8i :: P i1 P w j i (j; t) ( c 0 Q l p i ). 2 Constraint Set 6: (8i :: P i1 P w j i (j; t) x i t+1 m There first three constraint sets were given previously by Anderson and Ramamurthy <ref> [4] </ref>. The first set of constraints follows because the number of interferences in jobs of T i due to T j in an interval I of length t is bounded by the maximum number of jobs of T j that can be released in I. <p> We did not minimize the constraint sets in this way because we felt that this would make them more difficult to understand, especially when comparing them against those in <ref> [4] </ref>. This condition is obtained by modifying one proved in [4] by including a blocking factor for the scheduling quantum. For EDF scheduling, we have the following. <p> We did not minimize the constraint sets in this way because we felt that this would make them more difficult to understand, especially when comparing them against those in <ref> [4] </ref>. This condition is obtained by modifying one proved in [4] by including a blocking factor for the scheduling quantum. For EDF scheduling, we have the following. <p> For EDF scheduling, we have the following. Theorem 4: In an EDF-scheduled quantum-based uniprocessor system, a set of tasks with objects implemented using the proposed retry algorithms is schedulable if the following holds. (8t :: j=1 t k N (t 1) t) 2 This condition was also proved in <ref> [4] </ref>. Since t is checked beginning at time 0, a blocking factor is not required. As stated, the expression in Theorem 4 cannot be verified because the value of t is unbounded. However, there is an implicit bound on t. <p> Experimental Comparison. In order to compare the retry-cost estimates produced by the linear programming methods proposed in this paper and in <ref> [4] </ref>, we conducted a series of simulation experiments involving randomly-generated task sets scheduled under the RM scheme. <p> It can be seen in Figure 3 that the method of this paper yields retry-cost estimates for higher-priority tasks that are about 10% to 20% lower than those produced by the method of <ref> [4] </ref>. In addition to determining retry-cost estimates, we also kept track of how long each schedulabil-ity check took to complete. On average, the schedulability check proposed in this paper took 11.7 seconds per task set, while the one proposed in [4] took 235 seconds. <p> to 20% lower than those produced by the method of <ref> [4] </ref>. In addition to determining retry-cost estimates, we also kept track of how long each schedulabil-ity check took to complete. On average, the schedulability check proposed in this paper took 11.7 seconds per task set, while the one proposed in [4] took 235 seconds. This is because of the complicated procedure invoked to compute f v i values in the method of [4]. 3. Multiprocessor Systems In this section, we describe a new approach to implementing shared objects in quantum-based multiprocessor systems. <p> On average, the schedulability check proposed in this paper took 11.7 seconds per task set, while the one proposed in <ref> [4] </ref> took 235 seconds. This is because of the complicated procedure invoked to compute f v i values in the method of [4]. 3. Multiprocessor Systems In this section, we describe a new approach to implementing shared objects in quantum-based multiprocessor systems. Using this retry mechanism, scheduling analysis can be performed on each processor using the uniprocessor scheduling conditions considered in the previous section.
Reference: [5] <author> J. Anderson, S. Ramamurthy, and R. Jain. </author> <title> Implementing wait-free objects in priority-based systems. </title> <booktitle> In Proceedings of the 16th ACM Symp. on Principles of Distributed Computing, </booktitle> <pages> pp. 229-238. </pages> <year> 1997. </year>
Reference-contexts: Our work builds upon recent research by us and others on using lock-free and wait-free shared-object algorithms in real-time systems <ref> [3, 4, 5, 6, 15, 19] </ref>. Operations on lock-free objects are optimistically performed using a user-level retry loop. Such an operation is atomically validated and committed by invoking a synchronization primitive such as compare-and-swap (CAS). The retry loop is executed repeatedly until this validation step succeeds.
Reference: [6] <author> J. Anderson, S. Ramamurthy, and K. Jeffay. </author> <title> Real-time computing with lock-free objects. </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 15(6) </volume> <pages> 388-395, </pages> <year> 1997. </year>
Reference-contexts: Our work builds upon recent research by us and others on using lock-free and wait-free shared-object algorithms in real-time systems <ref> [3, 4, 5, 6, 15, 19] </ref>. Operations on lock-free objects are optimistically performed using a user-level retry loop. Such an operation is atomically validated and committed by invoking a synchronization primitive such as compare-and-swap (CAS). The retry loop is executed repeatedly until this validation step succeeds. <p> The second set of constraints follows from a result presented in <ref> [6] </ref>, which states that the total number of interferences in all jobs of tasks T 1 through T i in an interval I of length t is bounded by the maximum number of jobs of tasks T 1 through T i1 released in I.
Reference: [7] <author> T. Anderson. </author> <title> The performance of spin lock alternatives for shared-memory multiprocessors. </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> 1(1) </volume> <pages> 6-16, </pages> <year> 1990. </year>
Reference-contexts: Queue locks come in two flavors: array-based locks, which use an array of spin locations <ref> [7, 11] </ref>, and list-based locks, in which spinning tasks form a linked list [17]. List-based queue locks have the advantage of requiring only constant space overhead per task per lock.
Reference: [8] <author> N. C. Audsley, I. J. Bate, and A. Burns. </author> <title> Putting fixed priority scheduling into engineering practice for safety critical applications. </title> <booktitle> In Proceedings of the 1996 IEEE Real-Time Technology and Applications Symp., </booktitle> <pages> pp. 2-10, </pages> <year> 1996. </year>
Reference-contexts: Nonpreemptive systems have several advantages over preemptive systems, including lower scheduling overheads (if preemptions are frequent) and simpler object-sharing protocols <ref> [8, 13] </ref>. Also, timing analysis is simplified because cache behavior is easier to predict. However, these advantages come at the potential expense of longer response times for higher-priority tasks. Quantum-based systems can be seen as a compromise between these two extremes.
Reference: [9] <author> S. Baruah, R. Howell, and L. Rosier. </author> <title> Feasibility problems for recurring tasks on one processor. </title> <journal> Theoretical Computer Science, </journal> <volume> 118 </volume> <pages> 3-20, </pages> <year> 1993. </year>
Reference-contexts: In particular, we only need to consider values less than or equal to the least common multiple of the task periods. (If an upper bound on the utilization available for the tasks is known, then we can restrict t to a much smaller range <ref> [9] </ref>.) Note that, in a quantum-based system, no object access by a task that is guaranteed to complete within the first quantum allocated to a job of that task can be interfered with. Thus, such an access can be performed using a less-costly code fragment that is purely sequential.
Reference: [10] <author> E. Brewer, C. Dellarocas, A. Colbrook, and W. Weihl. Proteus: </author> <title> A high-performance parallel-architecture simulator. </title> <type> Technical Report MIT/LCS/TR-516, </type> <institution> MIT, Cambridge, Massachusetts, </institution> <year> 1992. </year>
Reference-contexts: The SPEPP/MCS algorithm was the fastest in the face of preemptions of several lock algorithms tested by Takada and Sakamura. Our experiments were conducted using the Pro-teus parallel architecture simulator <ref> [10] </ref>. Using a simulator made it easy to provide the kernel interface needed by each algorithm. The simulator was configured to simulate a bus-based shared-memory multiprocessor, with an equal number of processors and memory modules. The simulated system follows a bus-based snoopy protocol with write-invalidation for cache coherence.
Reference: [11] <author> G. Graunke and S. Thakkar. </author> <title> Synchronization algorithms for shared-memory multiprocessors. </title> <journal> IEEE Computer, </journal> <volume> 23 </volume> <pages> 60-69, </pages> <year> 1990. </year>
Reference-contexts: Queue locks come in two flavors: array-based locks, which use an array of spin locations <ref> [7, 11] </ref>, and list-based locks, in which spinning tasks form a linked list [17]. List-based queue locks have the advantage of requiring only constant space overhead per task per lock.
Reference: [12] <author> M. Greenwald and D. Cheriton. </author> <title> The synergy between non-blocking synchronization and operating system structure. </title> <booktitle> In Proceedings of the USENIX Association Second Symp. on Operating Systems Design and Implementation, </booktitle> <pages> pp. 123-136, </pages> <year> 1996. </year>
Reference-contexts: As its definition shows, CCAS is a restriction of a two-word CAS primitive in which one word is a compare-only value. Lock-free and wait-free objects can be implemented by using a version number that is incremented by each object call <ref> [3, 12] </ref>. CCAS is useful because the version number can be used to ensure that a late CCAS operation performed by a task after having been preempted has no effect. a quantum-based uniprocessor. The implementation works by packing a task index into the words being accessed.
Reference: [13] <author> K. Jeffay, D. Stanat, and C. Martel. </author> <title> On non-preemptive scheduling of periodic and sporadic tasks. </title> <booktitle> In Proceedings of the 12th IEEE Symp. on Real-Time Systems, </booktitle> <pages> pp. 129-139. </pages> <year> 1991. </year>
Reference-contexts: Nonpreemptive systems have several advantages over preemptive systems, including lower scheduling overheads (if preemptions are frequent) and simpler object-sharing protocols <ref> [8, 13] </ref>. Also, timing analysis is simplified because cache behavior is easier to predict. However, these advantages come at the potential expense of longer response times for higher-priority tasks. Quantum-based systems can be seen as a compromise between these two extremes. <p> P N c 0 p i (8i : 1 i N :: (8t : p 1 &lt; t &lt; p i :: min (Q; c 0 P i1 p j j t)) 2 The above condition is obtained by adapting the condition given by Jeffay et al. in <ref> [13] </ref> for nonpreemptive EDF scheduling. Note that this condition reduces to that of Jef-fay et al. when Q = 1 and to that for preemptive EDF scheduling [16] when Q = 0. Bounding interference costs using linear programming.
Reference: [14] <author> D. Katcher, H. Arakawa, and J.K. Strosnider. </author> <title> Engineering and analysis of fixed priority schedulers. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> 19(9) </volume> <pages> 920-934, </pages> <year> 1993. </year>
Reference-contexts: Round-robin scheduling is a simpler scheme in which each task has an identical share. Quantum-based execution also arises when conventional priority-based scheduling disciplines, such as rate-monotonic (RM) and earliest-deadline-first (EDF) scheduling, are implemented on top of a timer-driven real-time kernel <ref> [14] </ref>. In such an implementation, interrupts are scheduled to occur at regular intervals, and scheduling decisions are made when these interrupts occur. The length of time between interrupts defines the scheduling quantum. Timer-driven systems can be seen as a compromise between nonpreemptive and completely preemptive systems. <p> P i l p j c 0 In the above expression, B i is a blocking term that arises due to the use of quantum-based scheduling <ref> [14] </ref>. 4 The next theorem gives a scheduling condition for the EDF scheme. Theorem 2: In an EDF-scheduled quantum-based uniprocessor system, a set of tasks with objects implemented using the proposed retry algorithms is schedulable if the following holds. <p> Given the Preemption Axiom, we show that it is possible to obtain bounds that are tighter than those of Anderson and Ramamurthy. Our linear programming conditions make use of a bit of additional notation. If a job of T j interferes with the v th 4 In <ref> [14] </ref>, it is assumed that timer interrupts are spaced apart by a constant amount of time. If a task completes execution between these interrupts, then the processor is allocated to the next ready task, if such a task exists.
Reference: [15] <author> H. Kopetz and J. Reisinger. </author> <title> The non-blocking write protocol nbw: A solution to a real-time synchronization problem. </title> <booktitle> In Proceedings of the 14th IEEE Symp. on Real-Time Systems, </booktitle> <pages> pp. 131-137. </pages> <year> 1993. </year>
Reference-contexts: Our work builds upon recent research by us and others on using lock-free and wait-free shared-object algorithms in real-time systems <ref> [3, 4, 5, 6, 15, 19] </ref>. Operations on lock-free objects are optimistically performed using a user-level retry loop. Such an operation is atomically validated and committed by invoking a synchronization primitive such as compare-and-swap (CAS). The retry loop is executed repeatedly until this validation step succeeds.
Reference: [16] <author> C. Liu and J. Layland. </author> <title> Scheduling algorithms for multiprogramming in a hard real-time environment. </title> <journal> Journal of the ACM, </journal> <volume> 30 </volume> <pages> 46-61, </pages> <year> 1973. </year>
Reference-contexts: Note that this condition reduces to that of Jef-fay et al. when Q = 1 and to that for preemptive EDF scheduling <ref> [16] </ref> when Q = 0. Bounding interference costs using linear programming. Anderson and Ramamurthy showed that when lock-free objects are used in a uniprocessor system, object interference costs due to preemptions can be more accurately bounded using linear programming [4].
Reference: [17] <author> J. Mellor-Crummey and M. Scott. </author> <title> Algorithms for scalable synchronization on shared-memory multiprocessors. </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 9(1) </volume> <pages> 21-65, </pages> <year> 1991. </year>
Reference-contexts: In a multiprocessor, a retry mechanism by itself clearly is not sufficient, because a task on one processor may be repeatedly interfered with due to object invocations by tasks on other processors. Our approach is to use a retry mechanism in conjunction with a preemptable queue lock <ref> [17] </ref>. In our approach, a task performs an operation on an object by first acquiring a lock; if a task is preempted before its operation is completed, then its operation is retried. In comparison to previous preemptable queue-lock algorithms [21, 22], ours is quite simple. <p> Our approach is to use a retry mechanism in conjunction with a preemptable queue lock. A queue lock is a spin lock in which waiting tasks form a queue <ref> [17] </ref>. Queue locks are useful in real-time systems because waiting times can be bounded. With a preempt-able queue lock, a task waiting for or holding a lock can be preempted without impeding the progress of other tasks waiting for the lock. <p> Queue locks come in two flavors: array-based locks, which use an array of spin locations [7, 11], and list-based locks, in which spinning tasks form a linked list <ref> [17] </ref>. List-based queue locks have the advantage of requiring only constant space overhead per task per lock. In addition, list-based queue locks exist in which all spins are local if applied on multiprocessors either with coherent caches or distributed shared memory [17]. <p> locks, in which spinning tasks form a linked list <ref> [17] </ref>. List-based queue locks have the advantage of requiring only constant space overhead per task per lock. In addition, list-based queue locks exist in which all spins are local if applied on multiprocessors either with coherent caches or distributed shared memory [17]. In contrast, with existing array-based locks, spins are local only if applied in a system with coherent caches. All work known to us on preemptable queue locks involves list-based locks [21, 22]. <p> Their lock is designated as the SPEPP/MCS algorithm in their paper, so we will use that term here (SPEPP stands for spinning processor executes for preempted processors; MCS denotes that this lock is derived from one published previously by Mellor-Crummey and Scott <ref> [17] </ref>). The SPEPP/MCS algorithm was the fastest in the face of preemptions of several lock algorithms tested by Takada and Sakamura. Our experiments were conducted using the Pro-teus parallel architecture simulator [10]. Using a simulator made it easy to provide the kernel interface needed by each algorithm.
Reference: [18] <author> S. Ramamurthy. </author> <title> A Lock-Free Approach to Object Sharing in Real-Time Systems. </title> <type> PhD thesis, </type> <institution> University of North Carolina, Chapel Hill, North Carolina, </institution> <year> 1997. </year>
Reference-contexts: Even with the technology of several years ago, one could make the case that object calls are typically short compared to a quantum. As evidence of this, we cite results from experiments conducted by Ramamurthy to compute access times for several common objects <ref> [18] </ref>. These experiments were performed on a 25 MHz 68030 machine and involved objects ranging from queues to linked lists to medium-sized balanced trees. Both lock-based and lock-free (see below) object implementations were evaluated.
Reference: [19] <author> S. Ramamurthy, M. Moir, and J. Anderson. </author> <title> Real-time object sharing with minimal support. </title> <booktitle> In Proceedings of the 15th ACM Symp. on Principles of Distributed Computing, </booktitle> <pages> pp. 233-242. </pages> <year> 1996. </year>
Reference-contexts: Our work builds upon recent research by us and others on using lock-free and wait-free shared-object algorithms in real-time systems <ref> [3, 4, 5, 6, 15, 19] </ref>. Operations on lock-free objects are optimistically performed using a user-level retry loop. Such an operation is atomically validated and committed by invoking a synchronization primitive such as compare-and-swap (CAS). The retry loop is executed repeatedly until this validation step succeeds.
Reference: [20] <author> I. Stoica, H. Abdel-Wahab, K. Jeffay, S. Baruah, J. Gehrke, and C. Plaxton. </author> <title> A proportional share resource allocation algorithm for real-time, time-shared systems. </title> <booktitle> In Proceedings of the 17th IEEE Real-Time Systems Symp., </booktitle> <pages> pp. 288-299. </pages> <year> 1996. </year>
Reference-contexts: When a processor is allocated to some task, that task is guaranteed to execute without preemption for Q time units, where Q is the length of the quantum, or until it terminates, whichever comes first. Many real-time applications are designed based on scheduling disciplines such as proportional-share <ref> [20] </ref> and round-robin scheduling that are expressly quantum-based. Under proportional-share scheduling, each task is assigned a share of the processor, which represents the fraction of processing time that that task should receive. <p> Stoica et al. showed that optimal lag bounds can be achieved by using earliest-eligible-virtual-deadline-first (EEVDF) scheduling <ref> [20] </ref>. As we show in the full paper, the lag bounds of Stoica et al. can be applied in a system in which our shared-object algorithms are used by simply inflating the cost of a client's request by the cost of one retry loop for every quantum boundary it crosses.
Reference: [21] <author> H. Takada and K. Sakamura. </author> <title> A novel approach to multiprogrammed multiprocessor synchronization for real-time kernels. </title> <booktitle> In Proceedings of the 18th IEEE Real-Time Systems Symp., </booktitle> <pages> pp. 134-143. </pages> <year> 1997. </year>
Reference-contexts: In our approach, a task performs an operation on an object by first acquiring a lock; if a task is preempted before its operation is completed, then its operation is retried. In comparison to previous preemptable queue-lock algorithms <ref> [21, 22] </ref>, ours is quite simple. Its simplicity is mostly due to the fact that it was designed for systems satisfying the Preemption Axiom. 2. Uniprocessor Systems In this section, we consider the implementation of shared objects in quantum-based uniprocessor systems. <p> In contrast, with existing array-based locks, spins are local only if applied in a system with coherent caches. All work known to us on preemptable queue locks involves list-based locks <ref> [21, 22] </ref>. This is probably due to the advantages listed in the previous paragraph that (non-preemptable) list-based locks have over array-based ones. However, correctly maintaining a linked list of spinning tasks in the face of preemptions is very trick. <p> In the absence of such a kernel interface, list maintenance becomes quite hard, leading to complicated algorithms. For example, a list-based preemptable queue lock proposed recently by Takada and Sakamura requires a total of 63 executable statements <ref> [21] </ref>. Our preemptable queue lock is an array-based lock and is quite simple, consisting of only 17 lines of code. In addition, all that we require the kernel to do is to set a shared variable whenever a task is preempted indicating that that task is no longer running. <p> Experimental Comparison We have conducted performance experiments to compare our preemptable queue lock algorithm to a preemptable queue lock presented last year by Takada and Sakamura <ref> [21] </ref>. Their lock is designated as the SPEPP/MCS algorithm in their paper, so we will use that term here (SPEPP stands for spinning processor executes for preempted processors; MCS denotes that this lock is derived from one published previously by Mellor-Crummey and Scott [17]).
Reference: [22] <author> R. Wisniewski, L. Kontothanassis, and M. Scott. </author> <title> High performance synchronization algorithms for multipro-grammed multiprocessors. </title> <booktitle> In Proceedings of the Fifth ACM Symp. on Principles and Practices of Parallel Programming, </booktitle> <pages> pp. 199-206. </pages> <year> 1995. </year>
Reference-contexts: In our approach, a task performs an operation on an object by first acquiring a lock; if a task is preempted before its operation is completed, then its operation is retried. In comparison to previous preemptable queue-lock algorithms <ref> [21, 22] </ref>, ours is quite simple. Its simplicity is mostly due to the fact that it was designed for systems satisfying the Preemption Axiom. 2. Uniprocessor Systems In this section, we consider the implementation of shared objects in quantum-based uniprocessor systems. <p> In contrast, with existing array-based locks, spins are local only if applied in a system with coherent caches. All work known to us on preemptable queue locks involves list-based locks <ref> [21, 22] </ref>. This is probably due to the advantages listed in the previous paragraph that (non-preemptable) list-based locks have over array-based ones. However, correctly maintaining a linked list of spinning tasks in the face of preemptions is very trick. <p> Wisniewski et al. handle such problems by exploiting a rather non-standard kernel interface that has the ability to warn tasks before they are preempted so that they can take appropriate action in time <ref> [22] </ref>. In the absence of such a kernel interface, list maintenance becomes quite hard, leading to complicated algorithms. For example, a list-based preemptable queue lock proposed recently by Takada and Sakamura requires a total of 63 executable statements [21].
References-found: 22

