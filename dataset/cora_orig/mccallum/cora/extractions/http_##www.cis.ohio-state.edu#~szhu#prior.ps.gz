URL: http://www.cis.ohio-state.edu/~szhu/prior.ps.gz
Refering-URL: http://www.cis.ohio-state.edu/~szhu/publication.html
Root-URL: http://www.cis.ohio-state.edu
Title: Learning Generic Prior Models for Visual Computation  
Author: Song Chun Zhu and David Mumford 
Address: Box F, Brown University. Providence, RI 02912.  
Affiliation: Division of Applied Math  
Note: IEEE Trans. on Pattern Analysis and Machine Intelligence, short version CVPR97.  
Abstract: Many generic prior models have been widely used in computer vision ranging from image and surface reconstruction to motion analysis, and these models presume that surfaces of objects be smooth, and adjacent pixels in images have similar intensity values. However, there is little rigorous theory to guide the construction and selection of prior models for a given application. Furthermore, images are often observed at arbitrary scales, but none of the existing prior models are scale-invariant. Motivated by these problems, this article chooses general natural images as a domain of application, and proposes a theory for learning prior models from a set of observed natural images. Our theory is based on a maximum entropy principle, and the learned prior models are of Gibbs distributions. A novel information criterion is proposed for model selection by minimizing a Kullback-Leibler information distance. We also investigate scale invariance in the statistics of natural images and study a prior model which has scale invariant property. In this paper, in contrast with all existing prior models, negative potentials in Gibbs distribution are first reported. The learned prior models are verified in two ways. Firstly images are sampled from the prior distributions to demonstrate what typical images they stand for. Secondly they are compared with existing prior models in experiments of image restoration. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Akaike, </author> <title> "Canonical correlation analysis of time series and the use of an information criterion. Systems Identification: Advances and Case Studies, </title> <editor> eds. R. K. Mehra etc. </editor> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1976. </year>
Reference: [2] <author> P. N. Belhumeur, </author> <title> "A binocular stereo algorithm for reconstructing sloping, creased and broken surfaces, in the presence of half-occlusion", </title> <booktitle> Proc. </booktitle> <address> ICCV, Berlin, </address> <year> 1993. </year>
Reference: [3] <author> M. J. Black and A. Rangarajan, </author> <title> "The outlier process: unifying line processes and robust statistics." </title> <booktitle> Proc. </booktitle> <address> of CVPR Seattle, Washington, </address> <year> 1994. </year>
Reference: [4] <author> A. Blake and A. Zisserman. </author> <title> Visual Reconstruction. </title> <publisher> MIT press, </publisher> <year> 1987. </year>
Reference: [5] <author> R. R. Coifman and M. V. Wickerhauser, </author> <title> Entropy-based algorithms for best basis selection. </title> <journal> IEEE Trans. on Information Theory. </journal> <volume> vol. 38, pp.713-718, </volume> <year> 1992. </year>
Reference: [6] <author> T. M. Cover and J. A. Thomas, </author> <title> Elements of Information Theory, </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1985. </year>
Reference: [7] <author> J. Daugman, </author> <title> "Uncertainty relation for resolution in space, spatial frequency, and orientation optimized by two-dimensional visual cortical filters. </title> <journal> Journal of Optical Society of America. </journal> <volume> vol. 2, No. 7, pp1160-1169. </volume> <year> 1985. </year>
Reference: [8] <author> M. J. Donahue and D. Geiger, </author> " <title> Template matching and function decomposition using non-minimal spanning sets", </title> <type> Tech. Report. </type> <institution> Siemens, </institution> <year> 1993. </year> <month> 34 </month>
Reference: [9] <author> D. L. Donoho, </author> <title> De-Noising by soft thresholding, </title> <journal> IEEE Trans. on Information Theory. vol.41, </journal> <volume> pp.613-627, </volume> <year> 1995. </year>
Reference: [10] <author> D. J. </author> <title> Field, "Relations between the statistics of natural images and the response properties of cortical cells", </title> <journal> J. of Optical soc. America, A, vol.4, </journal> <volume> No. 12, </volume> <year> 1987. </year>
Reference: [11] <author> D. Gabor, </author> <title> "Theory of communication." </title> <booktitle> IEE Proc.vol 93, </booktitle> <address> no.26. </address> <year> 1946. </year>
Reference: [12] <author> S. Geman and D. Geman. </author> <title> "Stochastic relaxation, Gibbs distributions and the Bayesian restoration of images". </title> <journal> IEEE Trans. on PAMI 6(7), </journal> <pages> pp 721-741, </pages> <year> 1984. </year>
Reference: [13] <author> S. Geman and D. McClure, </author> <title> "Statistical methods for tomographic image reconstructions", </title> <journal> Bulletin of the International Statistical Institute, </journal> <volume> 52, </volume> <pages> 4-20. </pages> <year> 1987. </year>
Reference: [14] <author> B. Gidas, </author> <title> "A renormalization group approach to image processing problems". </title> <journal> IEEE Trans. on PAMI, </journal> <volume> vol. 11, </volume> <pages> No.2, </pages> <month> Feb. </month> <year> 1989. </year>
Reference: [15] <author> U. </author> <title> Grenander, </title> <journal> Lectures in Pattern Theory. </journal> <volume> vol. 1, </volume> <publisher> Springer-verlag, </publisher> <address> New York, </address> <year> 1976. </year>
Reference-contexts: that the potential functions () in a prior model should be different from quadratic, however the latter is widely adopted in computer vision. -15 -10 -5 0 5 10 15 0 0.1 0.2 0.3 0.4 -15 -10 -5 0 5 10 15 -20 -16 -12 -8 -4 0 in domain <ref> [15; 15] </ref>. b, The logarithm of the two curves in a. Third, the statistics of natural images are scale invariant with respect to some features. As an example, we study filters r x and r y again.
Reference: [16] <author> S. Mallat, </author> <title> "A theory for multi-resolution signal decomposition: the wavelet representation", </title> <journal> IEEE trans on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 11, No.7, </volume> <pages> 674-693, </pages> <year> 1989. </year>
Reference: [17] <author> D. Mumford and J. Shah. </author> <title> "Optimal approximations by piecewise smooth functions and associated variational problems." </title> <journal> Comm. Pure Appl. Math., </journal> <volume> 42, </volume> <pages> pp 577-684, </pages> <year> 1989. </year>
Reference: [18] <author> B. A. Olshausen and D. J. </author> <title> Field, "Natural image statistics and efficient coding", </title> <booktitle> Proc. of workshop on Information Theory and the Brain, </booktitle> <address> Setpember, </address> <year> 1995. </year>
Reference: [19] <author> T. Poggio, V. Torre and C. Koch, </author> <title> "Computational vision and regularization theory", </title> <journal> Nature, </journal> <volume> vol. 317, </volume> <pages> pp 314-319, </pages> <year> 1985. </year>
Reference: [20] <author> T. Poggio and F. Girosi, </author> <title> "Networks for approximation and learning", </title> <booktitle> Proc. of IEEE, vol.78, </booktitle> <pages> 1481-1497, </pages> <year> 1990. </year>
Reference: [21] <author> J. G. Propp and D. B. Wilson, </author> <title> "Exact sampling with coupled Markov chains and applications to statistical mechanics", </title> <type> Tech. report, </type> <institution> Math Dept. MIT. </institution> <year> 1995. </year>
Reference: [22] <author> D. L. Ruderman and Bialek, </author> <title> "Statistics of natural images: scaling in the woods", </title> <journal> Phys. Rev. Letter, </journal> <volume> 73 </volume> <pages> 814-817, </pages> <year> 1994. </year>
Reference-contexts: Since H obs (1) (z) = 0 if j z j 9:5, and H obs (ff) (z) = 0 if j z j 22 for ff = 2; 3, we only plot (1) (z) for z 2 [9:5; 9:5] and plot (2) (z); (3) (z) for z 2 <ref> [22; 22] </ref>. These three curves are fitted with the functions 1 (x) = 2:1 (11=(1+(j x j =4:8) 1:32 ), 2 (x) = 1:25 (11=(1+(j x j =2:8) 1:5 ), 3 (x) = 1:95 (1 1=(1 + (j x j =2:8) 1:5 ) respectively.
Reference: [23] <author> D. L. Ruderman, </author> <title> "Origins of scaling in natural images". </title> <booktitle> Proc. of IS&T/SPIE Symposium on Electronic Imaging. </booktitle> <year> 1996. </year>
Reference: [24] <author> J. Shah, </author> <title> "A common framework for curve evolution, segmentation, and anisotropic diffusion", </title> <booktitle> Proc. of CVPR, </booktitle> <address> San Fran. </address> <year> 1996. </year>
Reference: [25] <author> E. P. Simoncelli and E. H. Adelson, </author> <title> "Noise removal via Bayesian wavelet coring", </title> <booktitle> Int'l Conf. on Image Processing, </booktitle> <address> Switzerland, </address> <year> 1996. </year> <month> 35 </month>
Reference-contexts: 90 o ) 11x11 0.125 0.397 0.272 0.351 0.226 0.219 0.094 0.155 0.030 I obsi NxN M1 M 1 1 M 1 1 M Table 1 The information criterion for filter selection. 21 22 The potential function (1) (z) is discretized as a vector of 101 bins for z 2 <ref> [25; 25] </ref>, and it is plotted in figure (7) by linear interpolation. It has one degree of freedom, i.e., we can add an arbitrary constant c to (1) () without changing the probability, for c is absorbed by Z.
Reference: [26] <author> D. Terzopoulos, </author> <title> "Multilevel computational processes for visual surface reconstruction". </title> <journal> Com--puter Visiaon, Graphics, and Image Processing, </journal> <volume> 24, </volume> <pages> 52-96, </pages> <year> 1983. </year>
Reference: [27] <author> A. N. Tikhonov and V. Y. Arsenin, </author> <title> Solutions of Ill-posed Problems, 1906, (Translated version), </title> <publisher> V.H.Winston & Sons, </publisher> <year> 1977. </year>
Reference: [28] <author> A. B. Watson, </author> <title> "Efficiency of model human image code", </title> <journal> Journal of Optical Society of America A. Vol.4, </journal> <volume> No.12, </volume> <year> 1987. </year>
Reference: [29] <author> K. Wilson, </author> <title> "The renormalization group: critical phenonmena and the Knodo problem," </title> <journal> Rev. Mod. Phys., Vol.47, </journal> <volume> pp.773-840, </volume> <year> 1975. </year>
Reference: [30] <author> G, Winkler. </author> <title> Image Analysis, Random Fields and Dynamic Monte Carlo Methods, </title> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference: [31] <author> L. Younes, </author> <title> "Estimation and annealing for Gibbs fields", </title> <institution> Annales de l'Institut Henri Poincare, Section B, Calcul des Probabilities et Statistique Vol.24 pp269-294, </institution> <year> 1988. </year>
Reference-contexts: In figure (11), we notice that (s) x are negative 8 for s = 1; 2; 3, as we know, this is contrary to all existing prior models in computer vision. First of all, as the image intensity has finite range <ref> [0; 31] </ref>, r x I (s) is defined in [31; 31]. Therefore we may define (s) (z) = 0 for j z j&gt; 31, so p s (I) is legitimately defined. Second, such potentials have significant meanings in visual computation. <p> First of all, as the image intensity has finite range [0; 31], r x I (s) is defined in <ref> [31; 31] </ref>. Therefore we may define (s) (z) = 0 for j z j&gt; 31, so p s (I) is legitimately defined. Second, such potentials have significant meanings in visual computation. <p> Remark 3. All the prior models that we learned as well as the existing prior models discussed in section 1 have no preference about the image intensity domain. Therefore the image intensity has uniform distribution, but we limit it inside <ref> [0; 31] </ref>, thus the first row of table 1 has the same value for I C and AIG. 6 Comparison of prior models -20 -15 -10 -5 0 5 10 15 20 0 10 20 30 5 15 25 a b 5 15 25 -20 -15 -10 -5 0 5 10 <p> The potential function in the line process model is quadratic and flat around zero, thus it allows small fluctuation between adjacent locations. Figure (15) demonstrates a 2D experiment. The original image is the lobster boat displayed in figure (2). It is normalized to have intensity in <ref> [0; 31] </ref> and Gaussian noises from N (0; 25) are added. The distorted image is displayed in figure (15.a), where we keep the image boundary noise-free for the convenience of boundary condition.
Reference: [32] <author> S. C. Zhu and A. L. </author> <title> Yuille "Region Competition: unifying snakes, region growing, and Bayes/MDL for multi-band image segmentation". </title> <note> To appear in IEEE Trans.on PAMI. </note> <month> Sept. </month> <year> 1996. </year>
Reference: [33] <author> S. C. Zhu, Y. N. Wu and D. B. Mumford. </author> <title> "Filters, Random Fields, and Minimax Entropy (FRAME): Towards a unified theory for texture modeling". </title> <booktitle> Proc. Comp. Vision and Patt. </booktitle> <address> Recog., San Fran, </address> <year> 1996. </year> <month> 36 </month>
References-found: 33

