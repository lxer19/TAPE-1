URL: ftp://ftp.pmg.lcs.mit.edu/pub/castro/podc94.ps.gz
Refering-URL: http://www.pmg.lcs.mit.edu/~castro/pubs.html
Root-URL: 
Email: email: (nuno, miguel, pjg)@inesc.pt  
Title: A Checkpoint Protocol for an Entry Consistent Shared Memory System  
Author: Nuno Neves, Miguel Castro and Paulo Guedes R. Alves Redol , Lisboa PORTUGAL 
Affiliation: IST INESC  
Abstract: This paper presents a checkpoint protocol for a multi-threaded distributed shared memory system based on the entry consistency memory model. The protocol allows transparent recovery from single node failures and, in some cases, from multiple node failures. A simple mechanism is used to determine if the system can be brought to a consistent state in the event of multiple machine crashes. The protocol keeps a distributed log of shared data accesses in the volatile memory of the processes, taking advantage of the independent failure characteristics of workstation clusters. Periodically, or whenever the log reaches a high-water mark, each process checkpoints its state, independently from the others. The protocol needs no extra messages during the failure-free period, since all checkpoint control information is piggybacked on the memory coherence protocol messages. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. V. Adve and M. D. Hill. </author> <title> A unified formalization of four shared-memory models. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(6) </volume> <pages> 613-624, </pages> <month> June </month> <year> 1993. </year>
Reference: [2] <author> Mary Baker and Marl Sullivan. </author> <title> The Recovery Box: Using fast recovery to provide high availability in the UNIX environment. </title> <booktitle> In Proceedings of the Summer 1992 USENIX Conference, </booktitle> <pages> pages 31-44, </pages> <month> June </month> <year> 1992. </year>
Reference: [3] <author> B. N. Bershad, M. J. Zekauskas, and W. A. Sawdon. </author> <title> The midway distributed shared memory system. </title> <booktitle> In Proceedings of the 93 COMPCON Conference, </booktitle> <pages> pages 528-537, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: Hence, the probability of a failure during the execution of a long running application can become intolerably high. One solution to this problem is process checkpointing. This paper presents a checkpoint protocol for DiSOM [11], a multi-threaded DSM system based on the entry consistency memory model <ref> [3] </ref>. The protocol allows transparent recovery from single node failures and, in some cases, from multiple node failures. It uses a combination of a distributed log of shared data accesses and uncoordinated checkpointing. The logging mechanism is tightly integrated with the entry consistency memory coherence protocol. <p> If the program satisfies the contract's requirements the system guarantees that the program views a sequentially consistent memory [16], which is the model expected by most programmers. DiSOM uses the entry consistency memory coherence protocol introduced by Midway <ref> [3] </ref>. The contract imposed by entry consistency on the program is as follows. Firstly, the program has to identify the relationships between synchronization objects and data objects and explicitly associate them. Synchronization objects enforce concurrent read exclusive write synchronization and data objects are arbitrarily sized language-level data items.
Reference: [4] <author> Anita Borg, Jim Baumbach, and Sam Glazer. </author> <title> A message system supporting fault tolerance. </title> <booktitle> In Proceedings of the 9th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 90-99, </pages> <month> October </month> <year> 1983. </year>
Reference: [5] <author> J.B. Carter, J.K. Bennett, and W. Zwaenepoel. </author> <title> Implementation and performance of Munin. </title> <booktitle> In Proceedings of the 13th Symposium on Operating System P rinciples, </booktitle> <pages> pages 152-164, </pages> <month> October </month> <year> 1991. </year>
Reference: [6] <author> Miguel Castro, Nuno Neves, Pedro Trancoso, and Pedro Sousa. MIKE: </author> <title> A distributed object-oriented programming platform on top of the Mach micro-kernel. </title> <booktitle> In Proceedings of the USENIX Mach Conference, </booktitle> <pages> pages 253-273, </pages> <month> April </month> <year> 1993. </year>
Reference: [7] <author> K. Mani Chandy and Leslie Lamport. </author> <title> Distributed snapshots: Determining global states of distributed systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <pages> pages 3(1) 63-75, </pages> <month> February </month> <year> 1985. </year>
Reference: [8] <author> K. Gharachorloo, D. Lenoski, J. Laudon, P. Gibbons, A. Gupta, and J. Hennessy. </author> <title> Memory consistency and event ordering in scalable shared memory multiprocessors. </title> <booktitle> In Proceedings of the 16th Annual Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <month> May </month> <year> 1989. </year>
Reference: [9] <author> A. Goldberg, A. Gopal, K. Li, R. Strom, and D. Bacon. </author> <title> Transparent recovery of Mach applications. </title> <booktitle> In Proceedings of the Usenix Mach Workshop, </booktitle> <pages> pages 169-184, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Next, the recovering process threads re-execute, acquiring the same versions of the same objects as they did before the failure. This assumes that threads execute in a piece-wise deterministic manner <ref> [9] </ref>. After recovery, in the event of a single process failure, the system will be in a consistent state. On the other hand, if multiple process failures occurred it might be impossible to recover the system to a consistent state. The recovery mechanism detects this situation and aborts the application. <p> Messages are delivered reliably and in FIFO order. Each process is viewed as a collection of resources, which provides an execution environment for multiple threads. These resources include an address space, where a subset of the shared objects is mapped. Threads run in a piece-wise deterministic manner <ref> [9] </ref>, i.e. the execution of a thread is divided into deterministic intervals started by nondeterministic events. A new interval starts when a thread acquires an object for reading or writing and ends at the next acquire.
Reference: [10] <author> J. Goodman and P. Woest. </author> <title> The Wisconsin Multicube: A new large-scale cache coherent multiprocessor. </title> <booktitle> In Proceedings of the 15th Annual Symposium on Computer Architecture, </booktitle> <pages> pages 422-431, </pages> <month> June </month> <year> 1988. </year>
Reference: [11] <author> Paulo Guedes and Miguel Castro. </author> <title> Distributed shared object memory. </title> <booktitle> In Proceedings of the 4th Workshop on Workstation Operating Systems, </booktitle> <pages> pages 142-149, </pages> <month> Octo-ber </month> <year> 1993. </year>
Reference-contexts: In workstation clusters, mean time to failure decreases with increasing number of nodes. Hence, the probability of a failure during the execution of a long running application can become intolerably high. One solution to this problem is process checkpointing. This paper presents a checkpoint protocol for DiSOM <ref> [11] </ref>, a multi-threaded DSM system based on the entry consistency memory model [3]. The protocol allows transparent recovery from single node failures and, in some cases, from multiple node failures. It uses a combination of a distributed log of shared data accesses and uncoordinated checkpointing.
Reference: [12] <author> Golden G. Richard III and Mukesh Singhal. </author> <title> Using logging and asynchronous checkpointing to implement recoverable distributed shared memory. </title> <booktitle> In Proceedings of the 12th Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 86-95, </pages> <address> Princeton, New Jersey, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: The protocols proposed by Stumm and Zhou [24] only offer a partial solution to the process recovery problem, since only the state of shared pages is recovered. In their read-replication algorithm a process sends a copy of the dirty pages on every message send. Richard and Singhal <ref> [12] </ref> logged all the pages acquired in the volatile memory of the acquirer and saved the log in stable storage whenever a modified paged was transferred to another process. The only reference we found about checkpointing in relaxed consistent DSM was by Janssens and Fuchs [13].
Reference: [13] <author> Bob Janssens and W. Kent Fuchs. </author> <title> Relaxing consistency in recoverable distributed shared memory. </title> <booktitle> In The Twenty-Third Annual International Symposium on Fault-Tolerant Computing: Digest of Papers, </booktitle> <pages> pages 155-163, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Richard and Singhal [12] logged all the pages acquired in the volatile memory of the acquirer and saved the log in stable storage whenever a modified paged was transferred to another process. The only reference we found about checkpointing in relaxed consistent DSM was by Janssens and Fuchs <ref> [13] </ref>. In their protocol a process is checkpointed exactly before its updates become visible to the other processes. They used this characteristic to reduce the number of checkpoints needed for recovery.
Reference: [14] <author> David B. Johnson and Willy Zwaenepoel. </author> <title> Sender-based message logging. </title> <booktitle> In Proceedings of the Seventeenth International Symposium on Fault-Tolerant Computing: Digest of Papers, </booktitle> <pages> pages 14-19, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: After a failure a consistent state is reached by recovering the failed processes' checkpoints and possibly by rolling back some surviving processes. Logging can be used to prevent roll back propagation. In a message passing system, message logging can be made in the receiver [23] or in the sender <ref> [14] </ref>. Our shared memory abstraction is implemented using messages, therefore we could use a message logging protocol to achieve fault tolerance. This solution would perform worse than our protocol because our protocol takes advantage of the memory model constraints to avoid logging all the information in all the messages.
Reference: [15] <author> R. Koo and S. Toueg. </author> <title> Checkpointing and roolback-recovery for distributed systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-13(1):23-31, </volume> <month> January </month> <year> 1987. </year>
Reference: [16] <author> Leslie Lamport. </author> <title> How to make a multiprocessor computer that correctly executes multiprocess programs. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-28(9):241-248, </volume> <month> September </month> <year> 1979. </year> <month> 8 </month>
Reference-contexts: This assumption is usually verified in workstation clusters. The logging overhead is minimal because the log is stored in volatile memory and all checkpoint control infor-mation is piggybacked on the memory coherence protocol messages, avoiding extra messages during the failure-free period. Contrarily to the sequential consistency memory model <ref> [16] </ref>, where each update operation must potentially be logged, our protocol takes advantage of the entry consistency constraints to avoid logging individual updates. The checkpoint mechanism saves the state of each process on disk, periodically or when the process' log reaches a maximum size. <p> If the program satisfies the contract's requirements the system guarantees that the program views a sequentially consistent memory <ref> [16] </ref>, which is the model expected by most programmers. DiSOM uses the entry consistency memory coherence protocol introduced by Midway [3]. The contract imposed by entry consistency on the program is as follows.
Reference: [17] <author> Eliezer Levy and Avi Silberschatz. </author> <title> Incremental recov-ery in main memory database systems. </title> <type> Technical Report 01, </type> <institution> Dept. of Computer Science, University of Texas at Austin, </institution> <month> January </month> <year> 1992. </year>
Reference: [18] <author> Kai Li and Paul Hudak. </author> <title> Memory coherence in shared virtual memory systems. </title> <booktitle> In Proceedings of the 6th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 229-239, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: The garbage collection procedure applied to the protocol data structures is presented in section 4.4. The last section explains the detection of inconsistencies in the event of multiple failures. 4.1 DATA STRUCTURES DiSOM uses a modified version of Li's dynamic distributed manager protocol <ref> [18] </ref> to keep the shared memory coherent and implement synchronization 1 . The proto 1 DiSOM uses distributed copy sets.
Reference: [19] <author> Barbara Liskov, Sanjay Ghemawat, Robert Gruber, Paul Johnson, Liuba Shrira, and Michael Williams. </author> <title> Replication in the Harp file system. </title> <booktitle> In Proceedings of the 13th Symposium on Operating Systems Principles, </booktitle> <pages> pages 226-238, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Network partitions are not tolerated. We do not rely on special hardware support, e.g. non-volatile RAM [2,17] or uninterruptible power supply <ref> [19] </ref>. 3.1 MEMORY COHERENCE MODEL A memory coherence protocol is best described as a contract between the system and the application program. If the program satisfies the contract's requirements the system guarantees that the program views a sequentially consistent memory [16], which is the model expected by most programmers.
Reference: [20] <author> J. S. Plank. </author> <title> Efficient checkpointing on MIMD architectures. </title> <type> PhD thesis, </type> <institution> Princeton University, </institution> <month> June </month> <year> 1993. </year>
Reference: [21] <author> B. Randel. </author> <title> System structure for software fault tolerance. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-1(2):220-232, </volume> <month> June </month> <year> 1975. </year>
Reference-contexts: We use an uncoordinated protocol [4,14,23] where each process checkpoints itself, independently of the others. This way we avoid the overhead of checkpoint coordination and the loss of process autonomy characteristic of coordinated schemes [7,15,20]. In uncoordinated checkpoint protocols the domino effect <ref> [21] </ref> must be prevented to avoid a cascading of roll backs. Our checkpoint protocol prevents the domino effect by using the distributed log. Furthermore, the protocol is pessimistic [4,14], i.e. no thread in a surviving process has to be rolled back if a failure occurs.
Reference: [22] <author> R.D. Schlichting and F.B. Schneider. </author> <title> Fail-stop processors: An approach to designing fault-tolerant computing systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 1(3) </volume> <pages> 222-238, </pages> <month> August </month> <year> 1983. </year>
Reference-contexts: We also define the relations and as follows : ep i ep j iff tid i = tid j ^ lt i &lt; lt j and ep i ep j iff tid i = tid j We consider a fail-stop model <ref> [22] </ref>, where a processor fails by halting and all surviving processors detect the node failure within bounded time. Network partitions are not tolerated.
Reference: [23] <author> Robert E. Strom and Shaula A. Yemini. </author> <title> Optimistic recovery in distributed systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3(3) </volume> <pages> 204-226, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: Our checkpoint protocol prevents the domino effect by using the distributed log. Furthermore, the protocol is pessimistic [4,14], i.e. no thread in a surviving process has to be rolled back if a failure occurs. Nevertheless, it keeps the efficiency of optimistic schemes <ref> [23] </ref>, because logs are kept in the volatile memory of other processes. The recovery mechanism starts by loading the failed process' last checkpoint in a free processor. Then, the recovering process obtains, from the other processes, all the object versions acquired by its threads between the checkpoint and the failure. <p> After a failure a consistent state is reached by recovering the failed processes' checkpoints and possibly by rolling back some surviving processes. Logging can be used to prevent roll back propagation. In a message passing system, message logging can be made in the receiver <ref> [23] </ref> or in the sender [14]. Our shared memory abstraction is implemented using messages, therefore we could use a message logging protocol to achieve fault tolerance.
Reference: [24] <author> Michael Stumm and Songnian Zhou. </author> <title> Fault tolerant distributed shared memory algorithms. </title> <booktitle> In Proceedings of the Second IEEE Symposium on Parallel and Distributed Processing, </booktitle> <pages> pages 719-724, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: Most of the previous work in checkpoint protocols for DSM systems on workstation clusters was based on the sequential consistency memory model [12,24]. The protocols proposed by Stumm and Zhou <ref> [24] </ref> only offer a partial solution to the process recovery problem, since only the state of shared pages is recovered. In their read-replication algorithm a process sends a copy of the dirty pages on every message send.
Reference: [25] <author> V. Sunderam. </author> <title> Pvm: A framework for parallel distributed computing. </title> <journal> Concurrency: Practice & Experience, </journal> <volume> 2(4), </volume> <month> October </month> <year> 1991. </year>
References-found: 25

