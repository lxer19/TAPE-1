URL: http://www.aic.nrl.navy.mil/~spears/papers/onr92.ps.gz
Refering-URL: http://www.aic.nrl.navy.mil/~spears/pubs.html
Root-URL: 
Title: Competition-Based Learning  
Author: John J. Grefenstette, Kenneth A. De Jong, William M. Spears 
Address: Washington, DC 20375-5000  
Affiliation: Navy Center for Applied Research in Artificial Intelligence Information Technology Division Naval Research Laboratory  
Abstract: This paper summarizes recent research on competition-based learning procedures performed by the Navy Center for Applied Research in Artificial Intelligence at the Naval Research Laboratory. We have focused on a particularly interesting class of competition-based techniques called genetic algorithms. Genetic algorithms are adaptive search algorithms based on principles derived from the mechanisms of biological evolution. Recent results on the analysis of the implicit parallelism of alternative selection algorithms are summarized, along with an analysis of alternative crossover operators. Applications of these results in practical learning systems for sequential decision problems and for concept classification are also presented. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Baker, J. E. </author> <year> (1987). </year> <title> Reducing bias and inefficiency in the selection algorithm. </title> <booktitle> Proceedings of the Second International Conference Genetic Algorithms and Their Applications (pp. </booktitle> <pages> 14-21). </pages> <address> Cambridge, MA: Erl-baum. </address>
Reference: <author> Baker, J. E. </author> <year> (1989). </year> <title> Analysis of the effects of selection in genetic algorithms, </title> <type> Doctoral dissertation, </type> <institution> Department of Computer Science, Vander-bilt University, Nashville. </institution>
Reference-contexts: In practice, this selection algorithm may lead to premature convergence, based on the unlimited number of offspring that may be assigned to "super individuals" that may arise early in a search <ref> (Baker, 1989) </ref>. Other forms of selection are less brittle in this respect.
Reference: <author> Cobb, H. G. and J. J. </author> <title> Grefenstette (1991). Learning the persistence of actions in reactive control rules. </title> <booktitle> Proceedings of the Eighth International Machine Learning Workshop (pp. </booktitle> <pages> 293-297). </pages> <address> Evanston, IL: </address> <note> Mor-gan Kaufmann, </note> <author> De Jong, K. A. </author> <year> (1975). </year> <title> An analysis of the behavior of a class of genetic adaptive systems. </title> <type> Doctoral dissertation, </type> <institution> Department of Computer and Communication Sciences, University of Michigan, </institution> <address> Ann Arbor. </address>
Reference-contexts: Our research is currently focused on learning rules for a variety of tactical scenarios, using genetic algorithms as the method for exploring the space of possible rule sets. Our approach has been implemented in a system called SAMUEL <ref> (Gre-fenstette and Cobb, 1991) </ref>. The primary features of SAMUEL are: A restricted but high level rule language; Partial matching; Utility-driven con flict resolution; Numeric credit assignment at the level of individual rules; and Genetic learning at the level of rule sets.
Reference: <author> De Jong, K. A. </author> <year> (1990). </year> <title> Genetic-algorithm-based learning. </title> <booktitle> In Machine Learning: An artificial intelligence approach, </booktitle> <volume> Vol. 3, </volume> <editor> Y. Kodratoff and R. Michalski (eds.), </editor> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: GAs have in fact been applied successfully to routing and scheduling problems, machine vision, engineering design optimization, gas pipeline control systems, and others. In the area of machine learning, GAs have been used to learn rules for sequential decision problems as well as to learn classification rules from examples <ref> (De Jong, 1990) </ref>. GAs have also been widely used for learning both the topology and the weights of neural nets. Our research efforts for the past few years have fallen into two main categories: the analysis of genetic algorithms, and the application of genetic algorithms to machine learning problems.
Reference: <author> De Jong, K. A. and W. M. </author> <title> Spears (1992). A formal analysis of the role of multi-point crossover in genetic algorithms. </title> <journal> Annals of Mathematics and Artificial Intelligence. </journal>
Reference-contexts: The second important property is that the disruptive potential of uniform crossover is independent of the defining length of hyperplanes. This allows uniform crossover to perform equally well, regardless of the distribution of important genes. Finally, when disruption does occur, it can be shown <ref> (De Jong and Spears, 1992) </ref> that uniform crossover results in a minimally biased exploration of the search space. We are currently extending these results toward a more complete theory for recombination operators.
Reference: <author> Goldberg, D. E. </author> <year> (1989). </year> <title> Genetic algorithms in search, optimization, </title> <booktitle> and machine learning. </booktitle> <address> Reading: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: This method is sensitive, however, to "lethals", i.e., poor performing individuals that may occasionally arise through crossover or mutation. A more robust method has been called sigma scaling <ref> (Goldberg, 1989) </ref>: f (x ) = u (x) - (m - c * s) if u (x) &gt; (m - c * s) f (x) = 0 , otherwise. where m is the mean objective function value of the current population and s is the current population standard deviation. <p> Sigma scaling provides a level of selective pressure that is sensitive to the spread of performance values in the population. Besides these two forms of fitness functions, many other variations have been proposed and implemented <ref> (Goldberg, 1989) </ref>. We next consider variations in the selection phase. The selection algorithm assigns an expected number of children C (x) to each population member x, based on the fitness values.
Reference: <author> Gordon, D. F. </author> <year> (1991a). </year> <title> An enhancer for reactive plans. </title> <booktitle> Proceedings of the Eighth International Machine Learning Workshop (pp. </booktitle> <pages> 505-508). </pages> <address> Evanston, IL: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Gordon, D. F. </author> <year> (1991b). </year> <title> Improving the comprehensibility, accuracy, and generality of reactive plans. </title> <booktitle> Proceedings of the Sixth International Symposium on Methodologies for Intelligent Systems (pp. </booktitle> <pages> 358-367). </pages> <address> Charlotte, NC: </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Grefenstette, J. J. </author> <year> (1986). </year> <title> Optimization of control parameters for genetic algorithms. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> SMC-16(1), </volume> <pages> 122-128. </pages>
Reference-contexts: Scaling that accentuates small differences is especially desirable late in the search, when the variance in objective performance tends to diminish. One popular approach to scaling <ref> (Grefenstette, 1986) </ref> is to define the fitness function as a dynamic, linear transformation of the objective value: f (x) = a (u (x) - b (t )) where a is positive for maximization problems and negative for minimization problems, and b (t) represents the worst value seen in the last few
Reference: <author> Grefenstette, J. J. </author> <year> (1988). </year> <title> Credit assignment in rule discovery system based on genetic algorithms. </title> <booktitle> Machine Learning 3(2/3), </booktitle> <pages> 225-245. </pages>
Reference-contexts: In this section, we will briefly describe a number of recent studies on this approach. The reader is referred to the published articles for more complete details. The foundations for SAMUEL can be traced to the analysis of the credit assignment problem in <ref> (Grefenstette, 1988) </ref>. The credit assignment problem arises when long sequences of rules fire between successive external rewards. It can be shown that the two distinct approaches to rule learning with genetic algorithms each offer a useful solution to a different level of the credit assignment problem.
Reference: <author> Grefenstette, J. J. </author> <year> (1991a). </year> <title> Conditions for implicit parallelism. In Foundations of Genetic Algorithms, </title> <editor> G. J. E. Rawlins (ed.), Bloomington, IN: </editor> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The following two sections describe our progress on these two topics. ANALYSIS OF SELECTION ALGORITHMS One way to improve our understanding of genetic algorithms is to identify properties that are invariant across the many seemingly different versions of the algorithms. <ref> (Grefenstette, 1991a) </ref> focuses on invariances among genetic algorithms that differ along two dimensions: (1) the way the user-defined objective function is mapped to a fitness measure, and (2) the way the fitness measure is used to assign offspring to parents. The remainder of this section summarizes those results. <p> The trajectory of b (t ) generally rises over time, providing greater ________________ 2 This notation is at variance with that used in <ref> (Grefenstette, 1991a) </ref>. The mnemonic here is that f (x ) denotes the fitness, and u (x ) denotes the user-defined utility (e.g., cost to be minimized or profit to be maximized). The notation was reversed in (Grefenstette, 1991a). <p> time, providing greater ________________ 2 This notation is at variance with that used in <ref> (Grefenstette, 1991a) </ref>. The mnemonic here is that f (x ) denotes the fitness, and u (x ) denotes the user-defined utility (e.g., cost to be minimized or profit to be maximized). The notation was reversed in (Grefenstette, 1991a). We hope that standard notation may be adopted soon, but in the meantime, this paper will use the more intuitive notation. selection pressure later in the search. This method is sensitive, however, to "lethals", i.e., poor performing individuals that may occasionally arise through crossover or mutation. <p> Finally, we say that a GA is admissible if its fitness function and selection algorithm are both monotonic. A GA is strict iff its fitness function and selection algorithm are both strictly monotonic. The main results in <ref> (Grefenstette, 1991a) </ref> relate the dynamic behavior of monotonic and strict genetic algorithms to the notion of partial domination of one set by another. Consider two arbitrary subsets of the solution space, A and B. <p> set B, the number of offspring allocated to B by any strict GA ________________ 3 We assume without loss of generality that we are maximizing u. 4 These definitions can be extended in a natural way to cover the case where A (t) and B (t) have di ffering cardinalities <ref> (Grefenstette, 1991a) </ref>. If A (t) is smaller than B (t), we augment A (t ) by adding copies of the best representative of A.
Reference: <author> Grefenstette, J. J. </author> <year> (1991b). </year> <title> Lamarckian learning in multi-agent environments. </title> <booktitle> Proceedings of the Fourth International Conference of Genetic Algorithms (pp. </booktitle> <pages> 303-310). </pages> <address> San Diego, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Genetic algorithms gain much of their power from mechanisms derived from the field of population genetics. However, it is possible, and in some cases desirable, to augment the standard mechanisms with additional features not available in biological systems. In <ref> (Grefenstette, 1991b) </ref>, we examine the use of Lamarckian learning operators in the SAMUEL architecture. The operators are Lamarckian in the sense that strategies are modified through the addition or deletion of rules, based on the experience of the strategy in the test environment.
Reference: <author> Grefenstette, J. J. and H. G. </author> <note> Cobb (1991). User's guide for SAMUEL, Version 1.3. NRL Memorandum Report 6820. </note> <institution> Washington, </institution> <address> DC. </address>
Reference: <author> Grefenstette, J. J., C. L. Ramsey and A. C. </author> <title> Schultz (1990). Learning sequential decision rules using simulation models and competition. </title> <booktitle> Machine Learning 5(4), </booktitle> <pages> 355-381. </pages>
Reference-contexts: The primary features of SAMUEL are: A restricted but high level rule language; Partial matching; Utility-driven con flict resolution; Numeric credit assignment at the level of individual rules; and Genetic learning at the level of rule sets. The system is described in detail in <ref> (Grefenstette, Ramsey and Schultz, 1990) </ref>. We have experimented with SAMUEL on a variety of tasks involving multiple-agent environments, including evading a predator, stalking a prey, and dogfighting. SAMUEL has been able to learn high performance strategies for each of these tasks. <p> Robustness can be measured by testing the learned rules in new environments that have been systematically altered from the simulation environment in which the rules were learned. For example, either the learning environment or the target environment may contain noise. Experiments reported in <ref> (Ramsey, Schultz, and Grefenstette, 1990) </ref> examine the effect of learning tactical plans without noise and then testing the plans in a noisy environment, and the effect of learning plans in a noisy simulator and then testing the plans in a noise-free environment. <p> The use of a symbolic rule language in SAMUEL is intended to facilitate the incorporation of traditional machine learning methods into the system where appropriate. The rule language in SAMUEL also makes it easier to incorporate existing knowledge, whether acquired from experts or by symbolic learning programs. In <ref> (Schultz and Grefenstette, 1990) </ref>, the use of available heuristic domain knowledge to initialize the population to produce better plans is investigated, and two methods for initialization of the knowledge base are empirically compared.
Reference: <author> Holland, J. H. </author> <year> (1975). </year> <booktitle> Adaptation in natural and artificial systems. </booktitle> <address> Ann Arbor: </address> <publisher> University of Michigan Press. </publisher>
Reference-contexts: This method was originally proposed and analyzed by Holland, who showed that it results in a nearly-optimal allocation of trials, under certain circumstances <ref> (Holland, 1975) </ref>. In practice, this selection algorithm may lead to premature convergence, based on the unlimited number of offspring that may be assigned to "super individuals" that may arise early in a search (Baker, 1989). Other forms of selection are less brittle in this respect.
Reference: <author> Koza, J. R. </author> <year> (1989). </year> <title> Hierarchical genetic algorithms operating on populations of computer programs. </title> <booktitle> Proceedings of the 11th International Joint Conference on Artificial Intelligence. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kauf-mann. </publisher>
Reference: <author> Ramsey, C. L., A. C. Schultz and J. J. </author> <title> Grefenstette (1990). Simulation-assisted learning by competition: Effects of noise differences between training model and target environment. </title> <booktitle> Proceedings of Seventh International Conference on Machine Learning (pp. </booktitle> <pages> 211-215). </pages> <address> Austin, TX: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The primary features of SAMUEL are: A restricted but high level rule language; Partial matching; Utility-driven con flict resolution; Numeric credit assignment at the level of individual rules; and Genetic learning at the level of rule sets. The system is described in detail in <ref> (Grefenstette, Ramsey and Schultz, 1990) </ref>. We have experimented with SAMUEL on a variety of tasks involving multiple-agent environments, including evading a predator, stalking a prey, and dogfighting. SAMUEL has been able to learn high performance strategies for each of these tasks. <p> Robustness can be measured by testing the learned rules in new environments that have been systematically altered from the simulation environment in which the rules were learned. For example, either the learning environment or the target environment may contain noise. Experiments reported in <ref> (Ramsey, Schultz, and Grefenstette, 1990) </ref> examine the effect of learning tactical plans without noise and then testing the plans in a noisy environment, and the effect of learning plans in a noisy simulator and then testing the plans in a noise-free environment.
Reference: <author> Schultz. A. C. </author> <year> (1991). </year> <title> Using a genetic algorithm to learn strategies for collision avoidance and local navigation. </title> <booktitle> Proceedings of the Seventh International Symposium on Unmanned, Untethered Submersible Technology (pp. </booktitle> <pages> 213-225). </pages> <address> Durham, NH. </address>
Reference-contexts: By compressing time information, critical events in the decision sequence become apparent. We have begun to apply the SAMUEL approach to more complex learning environments. In <ref> (Schultz, 1991) </ref>, SAMUEL is used to learn high-performance reactive strategies for navigation and collision avoidance. The task domain requires an autonomous underwater vehicle to navigate through a randomly generated, dense mine field and then rendezvous with a stationary object.
Reference: <author> Schultz, A. C. and J. J. </author> <title> Grefenstette (1990). Improving tactical plans with genetic algorithms. </title> <booktitle> Proceedings of IEEE Conference on Tools for AI 90 (pp. </booktitle> <pages> 328-334). </pages> <address> Washington, DC: </address> <publisher> IEEE. </publisher>
Reference-contexts: The primary features of SAMUEL are: A restricted but high level rule language; Partial matching; Utility-driven con flict resolution; Numeric credit assignment at the level of individual rules; and Genetic learning at the level of rule sets. The system is described in detail in <ref> (Grefenstette, Ramsey and Schultz, 1990) </ref>. We have experimented with SAMUEL on a variety of tasks involving multiple-agent environments, including evading a predator, stalking a prey, and dogfighting. SAMUEL has been able to learn high performance strategies for each of these tasks. <p> Robustness can be measured by testing the learned rules in new environments that have been systematically altered from the simulation environment in which the rules were learned. For example, either the learning environment or the target environment may contain noise. Experiments reported in <ref> (Ramsey, Schultz, and Grefenstette, 1990) </ref> examine the effect of learning tactical plans without noise and then testing the plans in a noisy environment, and the effect of learning plans in a noisy simulator and then testing the plans in a noise-free environment. <p> The use of a symbolic rule language in SAMUEL is intended to facilitate the incorporation of traditional machine learning methods into the system where appropriate. The rule language in SAMUEL also makes it easier to incorporate existing knowledge, whether acquired from experts or by symbolic learning programs. In <ref> (Schultz and Grefenstette, 1990) </ref>, the use of available heuristic domain knowledge to initialize the population to produce better plans is investigated, and two methods for initialization of the knowledge base are empirically compared.
Reference: <author> Spears, W. M. and V. </author> <title> Anand (1991). A study of crossover operators in genetic programming. </title> <booktitle> Proceedings of the Sixth International Symposium on Methodologies for Intelligent Systems (pp. </booktitle> <pages> 409-418). </pages> <address> Charlotte, NC: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Preliminary results support that, despite minimal system bias, GABIL is an effective concept learner and is quite competitive with ID5R and C4.5 as the target concept increases in complexity. In <ref> (Spears and Gordon, 1991) </ref> we identify strategies responsible for the success of these concept learners. We then implement a subset of these strategies within GABIL to produce a multistrategy concept learner. Finally, this multistrategy concept learner is further enhanced by allowing the GAs to adaptively select the appropriate strategies.
Reference: <author> Spears, W. M. and K. A. </author> <title> De Jong (1990a). Using genetic algorithms for supervised concept learning. </title> <booktitle> Proceedings of IEEE Conference on Tools for AI 90 (pp. </booktitle> <pages> 335-341). </pages> <address> Washington, DC: </address> <publisher> IEEE. </publisher>
Reference-contexts: We will continue to advance these techniques, with the intention of exploring possible applications to laboratory robots and Navy research vehicles in the near future. Genetic Algorithms for Concept Learning Genetic algorithms (GAs) have traditionally been used for non-symbolic learning tasks. In <ref> (Spears and De Jong, 1990a) </ref> we consider the application of a GA to a symbolic learning task, supervised concept learning from examples. A GA concept learner (GABIL) is implemented that learns a concept from a set of positive and negative examples.
Reference: <author> Spears, W. M. and K. A. </author> <title> De Jong (1990b). Using neural networks and genetic algorithms as heuristics for NP-complete problems. </title> <booktitle> International Joint Conference on Neural Networks (pp. </booktitle> <pages> 118-121). </pages> <address> Washington D.C: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: <author> Spears, W. M. and K. A. </author> <title> De Jong (1991a). An analysis of multi-point crossover. In Foundations of Genetic Algorithms, </title> <editor> G. J. E. Rawlins (ed.), Bloomington, IN: </editor> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Spears, W. M. and K. A. </author> <title> De Jong (1991b). On the virtues of parameterized uniform crossover. </title> <booktitle> Proceedings of the Fourth International Conference of Genetic Algorithms (pp. </booktitle> <pages> 230-236). </pages> <address> San Diego, CA: </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: At the same time, note that the curves for the various number of crossover points have held their relative position with respect to one another. In <ref> (Spears and De Jong, 1991b) </ref>, a similar analysis is applied to uniform crossover. The results show that, as expected, uniform crossover eliminates all representational bias, yielding a horizontal line in graphs like Figure 4.
Reference: <author> Spears, W. M. and D. F. </author> <title> Gordon (1991). Adaptive strategy selection for concept learning. </title> <booktitle> Proceedings of the Workshop on Multistrategy Learning (pp. </booktitle> <pages> 231-246). </pages> <address> Harpers Ferry, WV: </address> <institution> George Mason University. </institution>
Reference-contexts: Preliminary results support that, despite minimal system bias, GABIL is an effective concept learner and is quite competitive with ID5R and C4.5 as the target concept increases in complexity. In <ref> (Spears and Gordon, 1991) </ref> we identify strategies responsible for the success of these concept learners. We then implement a subset of these strategies within GABIL to produce a multistrategy concept learner. Finally, this multistrategy concept learner is further enhanced by allowing the GAs to adaptively select the appropriate strategies.
Reference: <author> Syswerda, G. </author> <year> (1989). </year> <title> Uniform crossover in genetic algorithms. </title> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms (pp. </booktitle> <pages> 2-9). </pages> <address> Fairfax, VA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Whitley, D., T. Starkweather and D. </author> <title> Fuquay (1989). Scheduling problems and traveling salesmen: The genetic edge recombination. </title> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms (pp. </booktitle> <pages> 133-141). </pages> <address> Fairfax, VA: </address> <publisher> Morgan Kaufmann. </publisher>
References-found: 27

