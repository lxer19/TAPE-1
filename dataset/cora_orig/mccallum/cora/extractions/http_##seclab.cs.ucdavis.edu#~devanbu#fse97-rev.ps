URL: http://seclab.cs.ucdavis.edu/~devanbu/fse97-rev.ps
Refering-URL: http://seclab.cs.ucdavis.edu/~devanbu/prem_papers.html
Root-URL: http://www.cs.ucdavis.edu
Email: devanbu@cs.ucdavis.edu  stubblebine@research.att.com  
Phone: +1-530-752-7324  +1-973-360-8354  
Title: Cryptographic Verification of Test Coverage Claims  
Author: P. T. Devanbu S. G. Stubblebine 
Date: February 25, 1998  
Address: Davis, CA 95616 USA  180 Park Ave, Florham Park, NJ07932, USA  
Affiliation: Dept of Computer Science, University of California,  AT&T Laboratories  
Abstract: The market for software components is growing, driven on the "demand side" by the need for rapid deployment of highly functional products, and on the "supply side" by distributed object standards. As components and component vendors proliferate, there is naturally a growing concern about quality, and the effectiveness of testing processes. White box testing, particularly the use of coverage criteria, is a widely used method for measuring the "thoroughness" of testing efforts. High levels of test coverage are used as indicators of good quality control procedures. Software vendors who can demonstrate high levels of test coverage have a credible claim to high quality. However, verifying such claims involves knowledge of the source code, test cases, build procedures, etc. In applications where reliability and quality are critical, it would be desirable to verify test coverage claims without forcing vendors to give up valuable technical secrets. In this paper, we explore cryptographic techniques that can be used to verify such claims. Our techniques have certain limitations, which we discuss in this paper. However, vendors who have done the hard work of developing high levels of test coverage can use these techniques (at very low additional cost) to provide credible evidence of high coverage, while simultaneously reducing disclosure of intellectual property. Moreover, if such methods can be perfected and popularized, they can have an important "leveling" effect on the software market place: small, relatively unknown software vendors with limited resources can provide credible evidence of high-quality processes, and thus compete with much larger corporations. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Mondex inc. </author> <note> http:/www.mondex.com. </note>
Reference-contexts: One way to avoid 13 this problem is through the use of a physically secure co-processor. Various forms of these processors are available in tamper-proof enclosures, running secure operating systems; they are expected to become ubiquitous in the form of smart cards <ref> [1, 30] </ref>, which are expected to become quite powerful in a few years. The physical enclosure is a guarantee of integrity; if tampered with, the processor will erase its memory and cease to function. Thus, one can place customizable, trusted source code analyzers [8, 9] in secure co-processors.
Reference: [2] <institution> Source code for bin2chall. </institution> <address> http:/www.cs.ucdavis.edu/~devanbu/bin2chall.- cpio.gz. </address>
Reference-contexts: By using a publicly known, secure, pseudo-random number generator, and by sharing the seed, the vendor can guarantee that the sampling was done fairly. This tool can be downloaded in source form <ref> [2] </ref>; it can be modified for use in conjunction with any cryptographically strong pseudo-random generator. 7 Conclusion We have shown a set of protocols that can be used to verify test coverage, while protecting information valuable to the vendor and simultaneously reducing the vendor's ability to cheat.
Reference: [3] <institution> Delta Software Testing (accredited by Danish Accreditation Authority-DANAK). </institution> <note> http://www.delta.dk/se/ats.htm. </note>
Reference-contexts: As the number and types of components proliferate, and smaller, newer vendors enter the market, there is a natural concern about quality. Traditionally, systems with stringent quality requirements undergo a rigorous verification process, often under the auspices of third party verification agents <ref> [3, 19, 20] </ref>. One common testing technique used is white box testing; The goal is to ensure that a system has been adequately exercised during testing. <p> Several commercial laboratories <ref> [3, 19, 20] </ref> provide this service. We now describe how this works.
Reference: [4] <author> H. Agrawal. </author> <title> Dominators, super blocks and program coverage. </title> <booktitle> In Proceedings, POPL 94, </booktitle> <year> 1986. </year>
Reference-contexts: In cases where this trade-off is acceptable, this technique is applicable. There is a threat to the validity of the confidence level calculation described above: the sampling process is not really a series of independent events. Executions of coverage points (blocks, branches, or functions) are often strongly correlated. Agrawal <ref> [4] </ref> shows how to determine the set of statically independent coverage points from the control flow graph by computing the post-dominator and pre-dominator trees of basic blocks. The leaves of such trees could be used to form an independent set of coverage points.
Reference: [5] <author> T. Ball and J. Larus. </author> <title> Efficient path profiling. In Micro '96. </title> <publisher> IEEE Press, </publisher> <month> December </month> <year> 1996. </year>
Reference-contexts: Without a physically protected hardware platform, a determined adversary can reverse-engineer a good deal of information about software. Techniques and tools to support reverse engineering are an area of active research. In fact, previous research <ref> [5, 7, 21, 26] </ref> demonstrates how control-flow graphs, profile information, compiler-generated binary idioms, and even slices can be derived by analyzing and instrumenting binaries. Decompilation (converting binary to source code) and binary porting (converting binaries from one machine architecture to another) are typical goals of binary analysis. <p> Indeed, tools like EEL [21] can perform much of this analysis. In addition, by instrumentation, 18 and dynamic analysis. C A can detect which paths of the control flow graph are activated for different input conditions. Work by Ball & Larus <ref> [5] </ref> show how it is possible to trace and profile control flow path execution using just the binary. Additional information can be gained by tracing memory references and building dynamic slices.
Reference: [6] <author> C. Cifuentes. </author> <title> Partial automation of an integrated reverse engineering environment for binary code. </title> <booktitle> In Third Working Conference on Reverse Engineering, </booktitle> <year> 1996. </year>
Reference-contexts: As binary decompilation tools <ref> [6] </ref> mature and become more widely available, they can be used by customers to build confidence about areas of the binary that V claims to be non-testable for the reasons listed above.
Reference: [7] <author> C. Cifuentes and J. Gough. </author> <title> Decompilation of binary programs. </title> <journal> Software Practice and Experience, </journal> <month> July </month> <year> 1995. </year>
Reference-contexts: Without a physically protected hardware platform, a determined adversary can reverse-engineer a good deal of information about software. Techniques and tools to support reverse engineering are an area of active research. In fact, previous research <ref> [5, 7, 21, 26] </ref> demonstrates how control-flow graphs, profile information, compiler-generated binary idioms, and even slices can be derived by analyzing and instrumenting binaries. Decompilation (converting binary to source code) and binary porting (converting binaries from one machine architecture to another) are typical goals of binary analysis.
Reference: [8] <author> P. Devanbu. </author> <title> Genoa- a language and front-end independent source code analyzer generator. </title> <booktitle> In Proceedings of the Fourteenth International Conference on Software Engineering, </booktitle> <year> 1992. </year>
Reference-contexts: The physical enclosure is a guarantee of integrity; if tampered with, the processor will erase its memory and cease to function. Thus, one can place customizable, trusted source code analyzers <ref> [8, 9] </ref> in secure co-processors. Such a device can be installed as a co-processor at the site of the vendor; it can be sent an authenticated message which describes the type of analysis to be conducted. The smart-card resident tool can perform the analysis, and sign the results. <p> To support this, we have created a tool, src2binmod , which analyzes the source code and creates a set of commands to place instrumentations. This tool is built with the gen++ incarnation of GENOA <ref> [8] </ref> and is compatible with C++ and ANSI C source files. It creates output files that can be used to conduct instrumentation with ATOM [27] or with gdb. <p> Much of this can be automated, and we have constructed supporting source-based tools using GENOA <ref> [8] </ref>, and a tool for binary based sampling. Using such methods, any vendor, without the help of a trusted third party, and at relatively low overheads, can provide a credible claim that their software quality control is stringent, while disclosing only a minimal amount of information.
Reference: [9] <author> P. Devanbu, P. W. Fong, and S. Stubblebine. </author> <title> Techniques for trusted software engineering. </title> <booktitle> In Proceedings of the Twentieth International Conference on Software Engineering, </booktitle> <year> 1998. </year>
Reference-contexts: The physical enclosure is a guarantee of integrity; if tampered with, the processor will erase its memory and cease to function. Thus, one can place customizable, trusted source code analyzers <ref> [8, 9] </ref> in secure co-processors. Such a device can be installed as a co-processor at the site of the vendor; it can be sent an authenticated message which describes the type of analysis to be conducted. The smart-card resident tool can perform the analysis, and sign the results.
Reference: [10] <author> Joe W. Duran and Simeon C. Ntafos. </author> <title> An evaluation of random testing. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 10(4), </volume> <month> July </month> <year> 1984. </year>
Reference: [11] <author> P.G. Frankl and S. N. Weiss. </author> <title> An experimental comparison of the effectiveness of branch testing and data flow testing. </title> <journal> IEEE Transactions on Software Engineering, </journal> <month> August </month> <year> 1993. </year>
Reference-contexts: Most recent empirical work [16, 22] has found that test sets with coverage levels in the range of of 80-90% have a high chance of exposing failures. Earlier work <ref> [11] </ref> had yielded inconclusive results; however, the programs used in [11] were substantially smaller than [16, 22]. On the analytic front, rigorous probabilistic models of the relationship between increasing white-box coverage and the likelihood of fault detection have been developed [13]. <p> Most recent empirical work [16, 22] has found that test sets with coverage levels in the range of of 80-90% have a high chance of exposing failures. Earlier work <ref> [11] </ref> had yielded inconclusive results; however, the programs used in [11] were substantially smaller than [16, 22]. On the analytic front, rigorous probabilistic models of the relationship between increasing white-box coverage and the likelihood of fault detection have been developed [13].
Reference: [12] <author> P.G. Frankl and E. J. Weyuker. </author> <title> An applicable family of data flow testing criteria. </title> <journal> IEEE Transactions on Software Engineering, </journal> <month> August </month> <year> 1988. </year>
Reference-contexts: Several different criteria (fl in the discussion above) have been proposed; the relationships between these criteria have been well studied <ref> [12, 13] </ref>. Many are based purely on control flow, such as basic block coverage, branch coverage, and path coverage. Other criteria are based on data flow-i.e., the definition and use of values stored in memory.
Reference: [13] <author> P.G. Frankl and E. J. Weyuker. </author> <title> A formal analysis of the fault-detecting ability of testing methods. </title> <journal> IEEE Transactions on Software Engineering, </journal> <month> March </month> <year> 1993. </year>
Reference-contexts: Several different criteria (fl in the discussion above) have been proposed; the relationships between these criteria have been well studied <ref> [12, 13] </ref>. Many are based purely on control flow, such as basic block coverage, branch coverage, and path coverage. Other criteria are based on data flow-i.e., the definition and use of values stored in memory. <p> Earlier work [11] had yielded inconclusive results; however, the programs used in [11] were substantially smaller than [16, 22]. On the analytic front, rigorous probabilistic models of the relationship between increasing white-box coverage and the likelihood of fault detection have been developed <ref> [13] </ref>.
Reference: [14] <author> A. Freier, P. Karlton, and P. Kocher. </author> <title> The ssl protocol, </title> <note> version 3.0 (internet draft), </note> <month> March </month> <year> 1996. </year>
Reference-contexts: Thus we assume the testing protocols occur over secure channels 3 such as those provided by Secure Socket Layer ( SSL <ref> [14] </ref>). Several additional assumptions apply to the work described below: First, we assume that vendors are strongly motivated by market forces 4 to provide the highest quality software.
Reference: [15] <author> John Gannon. </author> <type> Personal conversation, </type> <month> April </month> <year> 1997. </year>
Reference-contexts: It is our hope that such approaches, as they are perfected and widely adopted, will engender a creative "churn" in the software market place, to the ultimate benefit of the consumer. J. Gannon <ref> [15] </ref> has pointed out a significant potential application of this work: customers with stringent quality requirements, such as the nuclear industry [25] need to obtain good evidence of good software quality control practices, prior to "dedicating" COTS software for use in safety-critical control systems.
Reference: [16] <author> M. Hutchins, H. Foster, T. Goradia, and T. </author> <title> Ostrand. Experiments on the effectiveness of dataflow- and controlflow-based test adequacy criteria. </title> <booktitle> In Proceedings of the 16th International Conference on Software Engineering. IEEE Computer Society, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: , and running the test suite T fl . 2 A vendor who undertakes the cost of developing an adequate set T fl for some stringent fl can reasonably expect that the system is less likely to fail 1 in the field due to undetected faults in in system X <ref> [16] </ref>. Often, in fields with exacting reliability requirements (such as transportation, telecommunications, energy or health) software users demand high quality standards, and expect vendors to use testing processes that achieve high levels of coverage with stringent coverage criteria. <p> Verification of random testing processes is beyond the scope of this paper. In practical software projects, the most common approaches are basic block coverage testing and branch coverage testing. These will form the primary focus of our discussion. These approaches have been justified by empirical work. Experimental work <ref> [16, 22] </ref> indicates that branch coverage levels in the range of 80-90% have a high likelihood of exposing remaining faults in the software. 2.2 Current Approaches to Coverage Verification Currently, test coverage verification is done by a third party testing which is trusted by both the vendor and customer to operate <p> Thus, at the 95% confidence level, T can reasonably conclude that an estimate of p = 0:95 is no more than 0:09 too high with about 25 samples. Experimental work <ref> [16, 22] </ref> indicates that branch coverage levels in the range of 80-90% have a high likelihood of exposing faults in the software. Estimated coverage levels in this range can give a customer high confidence that the V's testing has exposed a good number of faults. <p> Most recent empirical work <ref> [16, 22] </ref> has found that test sets with coverage levels in the range of of 80-90% have a high chance of exposing failures. Earlier work [11] had yielded inconclusive results; however, the programs used in [11] were substantially smaller than [16, 22]. <p> Most recent empirical work <ref> [16, 22] </ref> has found that test sets with coverage levels in the range of of 80-90% have a high chance of exposing failures. Earlier work [11] had yielded inconclusive results; however, the programs used in [11] were substantially smaller than [16, 22]. On the analytic front, rigorous probabilistic models of the relationship between increasing white-box coverage and the likelihood of fault detection have been developed [13]. <p> However, no known testing process is perfect; all known methods, white box or black box will let some faults 8 For simplicity, we assume trials can be repeated. 23 slip! The best current experimental work <ref> [16, 22] </ref> suggests that high levels of white box test coverage can guarantee high levels of fault detection. However, since white box testing is not perfect, there are several complications. Given a coverage point that has faults, there may be several test cases that exercise that point. <p> Again, another powerful disincentive to excessive padding is the vendor's inherent desire to produce high-quality software, and thus avoid costs of refunds, cancelled sales and extra update releases. To summarize, our work rests on the assumption (again, supported by <ref> [16, 22] </ref>) that comprehensive coverage testing tends to expose faults, and on the assumption that vendors will most often find it more profitable to fix faults exposed by a covering test (rather than searching for a test that covers but hides faults).
Reference: [17] <author> Plum Hall Inc. </author> <note> http:/www.plumhall.com. </note>
Reference-contexts: A comprehensive consideration of all these special cases is a valuable piece of intellectual property that demands protection. Indeed, there are vendors who make it their business to develop and sell comprehensive test suites <ref> [17, 28] </ref>.
Reference: [18] <author> M. J. Kearns and U. V. Vazirani. </author> <title> An Introduction to Computational Learning Theory. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: With a small number of random challenges, T can bound V's test coverage. If V's responses cover a proportion p s of T 's challenges, T can estimate V's actual coverage p (using Hoeffding's version of Chernoff bounds for the "positive tail" of a binomial distribution, see <ref> [18] </ref>, pp 190-191): P (p s p *) e 2p (1p) when p 0:5 (1) For a 95% confidence level, we can bound *: e 2p (1p) 0:05 6 Or a string indicating the lack of a test case for this coverage point. 16 * = 2ln ( 1 n Clearly,
Reference: [19] <institution> National Software Testing Labs. </institution> <note> http://www.nstl.com. </note>
Reference-contexts: As the number and types of components proliferate, and smaller, newer vendors enter the market, there is a natural concern about quality. Traditionally, systems with stringent quality requirements undergo a rigorous verification process, often under the auspices of third party verification agents <ref> [3, 19, 20] </ref>. One common testing technique used is white box testing; The goal is to ensure that a system has been adequately exercised during testing. <p> Several commercial laboratories <ref> [3, 19, 20] </ref> provide this service. We now describe how this works.
Reference: [20] <institution> Software Testing Labs. </institution> <note> http://www.stlabs.com. 28 </note>
Reference-contexts: As the number and types of components proliferate, and smaller, newer vendors enter the market, there is a natural concern about quality. Traditionally, systems with stringent quality requirements undergo a rigorous verification process, often under the auspices of third party verification agents <ref> [3, 19, 20] </ref>. One common testing technique used is white box testing; The goal is to ensure that a system has been adequately exercised during testing. <p> Several commercial laboratories <ref> [3, 19, 20] </ref> provide this service. We now describe how this works.
Reference: [21] <author> J. Larus and E. Schnarr. Eel: </author> <title> Machine-independent executable editing. </title> <booktitle> In ACM SIG--PLAN PLDI. </booktitle> <publisher> ACM Press, </publisher> <year> 1995. </year>
Reference-contexts: Without a physically protected hardware platform, a determined adversary can reverse-engineer a good deal of information about software. Techniques and tools to support reverse engineering are an area of active research. In fact, previous research <ref> [5, 7, 21, 26] </ref> demonstrates how control-flow graphs, profile information, compiler-generated binary idioms, and even slices can be derived by analyzing and instrumenting binaries. Decompilation (converting binary to source code) and binary porting (converting binaries from one machine architecture to another) are typical goals of binary analysis. <p> V sends T : B s , C fl and the test suite T fl , with the locations in the source files corre sponding the coverage points. 3. T uses a binary instrumentation tool, either interactive (e.g., a debugger, or batch-oriented (e.g., ATOM [27], EEL <ref> [21] </ref>) to instrument B s , using the line number/file information sent by T , and the symbol table information embedded in B s . For example, a debugger, can set break points at the appropriate locations (e.g., line numbers in files). 11 4. <p> It uses a pure binary patcher such as gdb, which can insert break points at specific binary offsets. A command such as break 0x89ABC to gdb will set a break point at the machine address 0x89ABC in the program. A batch-oriented tool like EEL <ref> [21] </ref> can also be used. Such a tool will be used by T to insert instrumentation at coverage points, and verify coverage. We also use a binary location finder (blf ), which uses the symbol table to find binary addresses for the coverage points. gdb can perform this function. <p> A limited amount of static control & data dependency analysis is even possible. Indeed, tools like EEL <ref> [21] </ref> can perform much of this analysis. In addition, by instrumentation, 18 and dynamic analysis. C A can detect which paths of the control flow graph are activated for different input conditions.
Reference: [22] <author> Y. Malaiya, N. Li, J. Bieman, R. Karcich, and B. Skibbe. </author> <title> Software test coverage and reliability. </title> <type> Technical report, </type> <institution> Colorado State University, </institution> <year> 1996. </year>
Reference-contexts: Verification of random testing processes is beyond the scope of this paper. In practical software projects, the most common approaches are basic block coverage testing and branch coverage testing. These will form the primary focus of our discussion. These approaches have been justified by empirical work. Experimental work <ref> [16, 22] </ref> indicates that branch coverage levels in the range of 80-90% have a high likelihood of exposing remaining faults in the software. 2.2 Current Approaches to Coverage Verification Currently, test coverage verification is done by a third party testing which is trusted by both the vendor and customer to operate <p> Thus, at the 95% confidence level, T can reasonably conclude that an estimate of p = 0:95 is no more than 0:09 too high with about 25 samples. Experimental work <ref> [16, 22] </ref> indicates that branch coverage levels in the range of 80-90% have a high likelihood of exposing faults in the software. Estimated coverage levels in this range can give a customer high confidence that the V's testing has exposed a good number of faults. <p> Most recent empirical work <ref> [16, 22] </ref> has found that test sets with coverage levels in the range of of 80-90% have a high chance of exposing failures. Earlier work [11] had yielded inconclusive results; however, the programs used in [11] were substantially smaller than [16, 22]. <p> Most recent empirical work <ref> [16, 22] </ref> has found that test sets with coverage levels in the range of of 80-90% have a high chance of exposing failures. Earlier work [11] had yielded inconclusive results; however, the programs used in [11] were substantially smaller than [16, 22]. On the analytic front, rigorous probabilistic models of the relationship between increasing white-box coverage and the likelihood of fault detection have been developed [13]. <p> However, no known testing process is perfect; all known methods, white box or black box will let some faults 8 For simplicity, we assume trials can be repeated. 23 slip! The best current experimental work <ref> [16, 22] </ref> suggests that high levels of white box test coverage can guarantee high levels of fault detection. However, since white box testing is not perfect, there are several complications. Given a coverage point that has faults, there may be several test cases that exercise that point. <p> Again, another powerful disincentive to excessive padding is the vendor's inherent desire to produce high-quality software, and thus avoid costs of refunds, cancelled sales and extra update releases. To summarize, our work rests on the assumption (again, supported by <ref> [16, 22] </ref>) that comprehensive coverage testing tends to expose faults, and on the assumption that vendors will most often find it more profitable to fix faults exposed by a covering test (rather than searching for a test that covers but hides faults).
Reference: [23] <author> Doug McIlroy. </author> <type> Personal e-mail communication, </type> <year> 1996. </year>
Reference-contexts: Sometimes generated code may contain additional control flow that represent different cases that can occur in the field, and V can legitimately be expected to supply covering test cases. When the generated code is genuinely unreachable <ref> [23] </ref>, V can claim it as such, and supply source code that C can compile to create similar binaries. Occurrences of dead code in the binary are really bugs in the compiler, and are likely to be rare.
Reference: [24] <author> Alfred J. Menezes, Paul C. van Oorschot, and Scott A. Vanstone. </author> <title> Handbook of Applied Cryptography. </title> <publisher> CRC Press, </publisher> <year> 1996. </year>
Reference-contexts: In this paper, we apply several cryptographic techniques to address some common scenarios that may arise in practice. We now briefly describe the techniques we have used in our work; more complete descriptions can be found in <ref> [24] </ref>. All of these techniques are used to build assurance in the customer (C) that the vendor (V) has high test coverage, while attempting to protect V's secrets. Our work is related to the notion of zero-knowledge protocols (ZKP).
Reference: [25] <institution> Committee on Application of Digital Instrumentation, </institution> <note> Control Systems to Nuclear Power Plant Operations, and Safety. Digital Instrumentation and Control Systems in Nuclear Power Plants|Safety and Reliability Issues-Final Report. </note> <institution> National Academy Press (Board on Energy and Environmental Systems, National Research Council), </institution> <year> 1997. </year>
Reference-contexts: The prospect of achieving lower costs and higher quality with off-the-self (COTS) components has wide attraction: recently a committee appointed by the National Research Council in the USA (See <ref> [25] </ref>, pp 71-76) has discussed the reuse of COTS software in nuclear power plants. A vibrant market for software components is growing. The cost of entry into this market is low, and small vendors can be players. <p> This problem is particularly acute when adopting COTS software for use in safety-critical systems (a process called "dedication") and is clarified in <ref> [25] </ref> (Page 76, first para): "Dedication of commercial components requires much more information than commercial vendors are accustomed to supplying . . . <p> J. Gannon [15] has pointed out a significant potential application of this work: customers with stringent quality requirements, such as the nuclear industry <ref> [25] </ref> need to obtain good evidence of good software quality control practices, prior to "dedicating" COTS software for use in safety-critical control systems. Our techniques can be used to obtain such evidence while protecting certain trade secrets.
Reference: [26] <author> N. Ramsey and M. Fernandez. </author> <title> Specifying representations of machine instructions. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <year> 1997. </year>
Reference-contexts: Without a physically protected hardware platform, a determined adversary can reverse-engineer a good deal of information about software. Techniques and tools to support reverse engineering are an area of active research. In fact, previous research <ref> [5, 7, 21, 26] </ref> demonstrates how control-flow graphs, profile information, compiler-generated binary idioms, and even slices can be derived by analyzing and instrumenting binaries. Decompilation (converting binary to source code) and binary porting (converting binaries from one machine architecture to another) are typical goals of binary analysis.
Reference: [27] <author> A. Srivastava and A. Eustace. </author> <title> Atom: A tool for building customized program analysis tools. </title> <type> Technical Report 1994/2, </type> <institution> DEC Western Research Labs, </institution> <year> 1994. </year>
Reference-contexts: V sends T : B s , C fl and the test suite T fl , with the locations in the source files corre sponding the coverage points. 3. T uses a binary instrumentation tool, either interactive (e.g., a debugger, or batch-oriented (e.g., ATOM <ref> [27] </ref>, EEL [21]) to instrument B s , using the line number/file information sent by T , and the symbol table information embedded in B s . For example, a debugger, can set break points at the appropriate locations (e.g., line numbers in files). 11 4. <p> This tool is built with the gen++ incarnation of GENOA [8] and is compatible with C++ and ANSI C source files. It creates output files that can be used to conduct instrumentation with ATOM <ref> [27] </ref> or with gdb. In addition, it also creates a command file for gdb that can be used to generate actual binary positions; this can be used to perform instrumentations on stripped binaries without symbol table information (Protocol 3).
Reference: [28] <institution> Applied Testing and Technology Inc. </institution> <note> http://www.aptest.com. </note>
Reference-contexts: A comprehensive consideration of all these special cases is a valuable piece of intellectual property that demands protection. Indeed, there are vendors who make it their business to develop and sell comprehensive test suites <ref> [17, 28] </ref>.
Reference: [29] <author> E. J. Weyuker. </author> <title> On testing non-testable programs. </title> <journal> The Computer Journal, </journal> <volume> 25(4) </volume> <pages> 465-470, </pages> <year> 1982. </year>
Reference-contexts: Third, we make the usual assumption that all parties involved in coverage verification protocols have access to a test oracle <ref> [29] </ref> that decides whether the output for any test case is right or not.
Reference: [30] <author> Bennet Yee and Doug Tygar. </author> <title> Secure coprocessors in electronic commerce applications. </title> <booktitle> In Proceedings of The First USENIX Workshop on Electronic Commerce, </booktitle> <address> New York, New York, </address> <month> July </month> <year> 1995. </year> <month> 29 </month>
Reference-contexts: One way to avoid 13 this problem is through the use of a physically secure co-processor. Various forms of these processors are available in tamper-proof enclosures, running secure operating systems; they are expected to become ubiquitous in the form of smart cards <ref> [1, 30] </ref>, which are expected to become quite powerful in a few years. The physical enclosure is a guarantee of integrity; if tampered with, the processor will erase its memory and cease to function. Thus, one can place customizable, trusted source code analyzers [8, 9] in secure co-processors.
References-found: 30

