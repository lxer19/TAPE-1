URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-292.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: gorkani@almaden.ibm.com  picard@media.mit.edu  
Author: Glance" Monika M. Gorkani Rosalind W. Picard 
Keyword: Texture Orientation for Sorting Photos  
Address: K54 650 Harry Rd; San Jose, CA 95120  20 Ames St; Cambridge, MA 02139  
Affiliation: Machine Vision Group IBM Almaden Research Center,  Vision and Modeling Group MIT Media Laboratory  
Note: "at a  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 292 Appears in the proceedings of: IEEE Conference on Pattern Recognition, Jerusalem, Oct. 1994 Abstract We investigate a measure of "dominant perceived orientation" that has recently been developed to match the output of a human study involving 40 subjects. The results of this measure are compared with humans analyzing seven "teaser" images to test its effectiveness for finding perceptually dominant orientations. The use of low-level orientation is then applied to a "quick search" problem important in image database applications. Since both pigeons and humans are able to perform coarse classification of certain kinds of scenes, e.g., city from country, without taking time or brain-power to solve the image understanding problem, we conjecture that the collective behavior of low-level textural features such as orientation may be doing most of the work. We demonstrate a simple test of global multiscale orientation for quickly searching a database of vacation photos for likely "city/suburb" shots. The orientation features achieve agreement with human classification in 91 out of 98 of the scenes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Tamura, S. Mori, and T. Yamawaki. </author> <title> Textural features corresponding to visual perception. </title> <journal> IEEE T. Sys., Man and Cyber., </journal> <volume> SMC-8(6):460-473, </volume> <year> 1978. </year>
Reference-contexts: 1 Introduction The fact that orientation is an important feature for texture recognition and discrimination <ref> [1] </ref> has been recognized for some time, especially after the physiological experiments performed by Hubel and Wiesel [2] suggested the existence of orientation selective mechanisms in the human visual system.
Reference: [2] <author> H. D. Hubel and T. N. Wiesel. </author> <title> Receptive fields and functional architecture of monkey striate cortex. </title> <journal> J. Physiology, </journal> <volume> 195 </volume> <pages> 215-243, </pages> <year> 1968. </year>
Reference-contexts: 1 Introduction The fact that orientation is an important feature for texture recognition and discrimination [1] has been recognized for some time, especially after the physiological experiments performed by Hubel and Wiesel <ref> [2] </ref> suggested the existence of orientation selective mechanisms in the human visual system. Oriented filters are now in use for a variety of texture problems such as multiscale texture analysis [3] [4] and analysis of flow textures [5] [6].
Reference: [3] <author> J. R. Bergen and M. S. Landy. </author> <title> Computational modeling of visual texture segregation. </title> <editor> In M. S. Landy and J. A. Movshon, editors, </editor> <booktitle> Computational Models of Visual Processing, </booktitle> <pages> pages 253-271, </pages> <address> Cambridge, MA, 1991. </address> <publisher> MIT Press. </publisher>
Reference-contexts: Oriented filters are now in use for a variety of texture problems such as multiscale texture analysis <ref> [3] </ref> [4] and analysis of flow textures [5] [6]. However, the use so far has been restricted to relatively "low-level" and pixel-level applications.
Reference: [4] <author> A. K. Jain and F. Farrokhnia. </author> <title> Unsupervised texture segmentation using Gabor filters. </title> <journal> Pattern Recognition Journal, </journal> <volume> 24 </volume> <pages> 1167-1186, </pages> <year> 1991. </year>
Reference-contexts: Oriented filters are now in use for a variety of texture problems such as multiscale texture analysis [3] <ref> [4] </ref> and analysis of flow textures [5] [6]. However, the use so far has been restricted to relatively "low-level" and pixel-level applications.
Reference: [5] <author> M. Kass and A. Witkin. </author> <title> Analyzing oriented patterns. </title> <editor> In M. A. Fischler and M. Kaufman, editors, </editor> <booktitle> Readings in Computer Vision, </booktitle> <pages> pages 268-276. </pages> <editor> M. </editor> <publisher> Kaufman, </publisher> <year> 1987. </year>
Reference-contexts: Oriented filters are now in use for a variety of texture problems such as multiscale texture analysis [3] [4] and analysis of flow textures <ref> [5] </ref> [6]. However, the use so far has been restricted to relatively "low-level" and pixel-level applications. <p> In this study, the textural features are dominant orientations, measured by an algorithm developed to approximate human perception of dominant orientation. A number of researchers have proposed computational schemes for measuring local orientation at each pixel position using directional filters in the spatial domain [6] <ref> [5] </ref> [8] This work was done while author Gorkani was at the MIT Media Lab and at INRIA Rocquencourt; it was supported in part by BT, PLC. orientation (from E. H. Adelson). [9] and in the Fourier domain [10] [11]. <p> The results of the algorithm were found to agree with human classifications in 91 of the 98 images. 1 Images available by ftp from the authors. 1 2 Background: finding "perceptual" orientations The orientation-finding algorithm we use is similar to those of Kass and Witkin <ref> [5] </ref>, Rao and Schunck [6] and Bigun and Granlund [8] in that it estimates the local orientation and its strength at each pixel of the image using a combination of the magnitudes of the outputs of a set of directional filters convolved with the image in the spatial domain.
Reference: [6] <author> R. Rao and B. G. Schunck. </author> <title> Computing oriented texture fields. CVGIP Graphical Models and Image Processing, </title> <booktitle> 53(2) </booktitle> <pages> 157-185, </pages> <year> 1991. </year>
Reference-contexts: Oriented filters are now in use for a variety of texture problems such as multiscale texture analysis [3] [4] and analysis of flow textures [5] <ref> [6] </ref>. However, the use so far has been restricted to relatively "low-level" and pixel-level applications. <p> In this study, the textural features are dominant orientations, measured by an algorithm developed to approximate human perception of dominant orientation. A number of researchers have proposed computational schemes for measuring local orientation at each pixel position using directional filters in the spatial domain <ref> [6] </ref> [5] [8] This work was done while author Gorkani was at the MIT Media Lab and at INRIA Rocquencourt; it was supported in part by BT, PLC. orientation (from E. H. Adelson). [9] and in the Fourier domain [10] [11]. <p> The results of the algorithm were found to agree with human classifications in 91 of the 98 images. 1 Images available by ftp from the authors. 1 2 Background: finding "perceptual" orientations The orientation-finding algorithm we use is similar to those of Kass and Witkin [5], Rao and Schunck <ref> [6] </ref> and Bigun and Granlund [8] in that it estimates the local orientation and its strength at each pixel of the image using a combination of the magnitudes of the outputs of a set of directional filters convolved with the image in the spatial domain.
Reference: [7] <author> R. J. Herrnstein, D. H. Loveland, and C. </author> <title> Cable. Natural concepts in pigeons. </title> <journal> J. of Exp. Psych: Anim. Beh. Procs., </journal> <volume> 2 </volume> <pages> 285-302, </pages> <year> 1976. </year>
Reference-contexts: In this paper we consider using "vision texture" or the global texture properties of the image as a quick way to make a first pass at higher-level problems, such as annotating or retrieving a particular set of your digitized vacation photos. Studies with pigeons <ref> [7] </ref> support the hypothesis for a mechanism that looks at collective low-level features for making comparatively high-level quick classifications. In this study, the textural features are dominant orientations, measured by an algorithm developed to approximate human perception of dominant orientation.
Reference: [8] <author> J. Bigun and G. H. Granlund. </author> <title> Optimal orientation detection of linear symmetry. </title> <booktitle> In Proc. 1st Int. Conf. Comp. Vis., </booktitle> <pages> pages 433-438, </pages> <address> London, England, </address> <year> 1987. </year>
Reference-contexts: In this study, the textural features are dominant orientations, measured by an algorithm developed to approximate human perception of dominant orientation. A number of researchers have proposed computational schemes for measuring local orientation at each pixel position using directional filters in the spatial domain [6] [5] <ref> [8] </ref> This work was done while author Gorkani was at the MIT Media Lab and at INRIA Rocquencourt; it was supported in part by BT, PLC. orientation (from E. H. Adelson). [9] and in the Fourier domain [10] [11]. <p> algorithm were found to agree with human classifications in 91 of the 98 images. 1 Images available by ftp from the authors. 1 2 Background: finding "perceptual" orientations The orientation-finding algorithm we use is similar to those of Kass and Witkin [5], Rao and Schunck [6] and Bigun and Granlund <ref> [8] </ref> in that it estimates the local orientation and its strength at each pixel of the image using a combination of the magnitudes of the outputs of a set of directional filters convolved with the image in the spatial domain.
Reference: [9] <author> W. T. Freeman and E. H. Adelson. </author> <title> The design and use of steerable filters. </title> <editor> IEEE T. Patt. Analy. </editor> <booktitle> and Mach. Intell., </booktitle> <address> PAMI-13(9):891-906, </address> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: H. Adelson). <ref> [9] </ref> and in the Fourier domain [10] [11]. However, to find global dominant orientation information in textures, further decision making is needed. For example, in Figure 1, an algorithm finding dominant global orientations would use the local estimated orientations of all the pixels to decide that and horizontal directions.
Reference: [10] <editor> R. Bajcsy. </editor> <booktitle> Computer description of textured surfaces. Int. Joint. Conf. Artificial Intelligence, </booktitle> <pages> pages 572-578, </pages> <year> 1973. </year>
Reference-contexts: H. Adelson). [9] and in the Fourier domain <ref> [10] </ref> [11]. However, to find global dominant orientation information in textures, further decision making is needed. For example, in Figure 1, an algorithm finding dominant global orientations would use the local estimated orientations of all the pixels to decide that and horizontal directions.
Reference: [11] <author> S. Chaudhuri, H. Nguyen, R. M. Rangayyan, S. Walsh, and C. B. Frank. </author> <title> A Fourier domain directional filtering method for analysis of collagen alignment in ligaments. </title> <journal> IEEE Transactions on Biomedical Engineering, </journal> <volume> 34(7) </volume> <pages> 509-517, </pages> <year> 1987. </year>
Reference-contexts: H. Adelson). [9] and in the Fourier domain [10] <ref> [11] </ref>. However, to find global dominant orientation information in textures, further decision making is needed. For example, in Figure 1, an algorithm finding dominant global orientations would use the local estimated orientations of all the pixels to decide that and horizontal directions.
Reference: [12] <author> R. W. Picard and M. Gorkani. </author> <title> Finding perceptually dominant orientations in natural textures. Spatial Vision, Spec. </title> <note> Julesz Issue. To Appear; also avail. as Per-cep. Comp. TR #229, </note> <institution> M.I.T. Media Lab, </institution> <year> 1993. </year>
Reference-contexts: However, to find global dominant orientation information in textures, further decision making is needed. For example, in Figure 1, an algorithm finding dominant global orientations would use the local estimated orientations of all the pixels to decide that and horizontal directions. In <ref> [12] </ref> Picard and Gorkani introduced an algorithm to extract dominant orientation information from a texture in a way that closely approximated results from a large human visual study. <p> Unlike the works mentioned above, the implementation used here and in <ref> [12] </ref> extracts orientation information over multiple scales using a steerable pyramid [14], then combines the orientations from different scales and decides which are dominant perceptually, as determined by a human study. <p> At each level, a set of directional filters are used to estimate orientations. In the two studies presented here, we used four and three levels of the pyramid respectively (four levels were used in <ref> [12] </ref>). The number of pyramid levels is set to be the largest it can given the size of the image or subregion for which the orientation is being computed. In [12], to find the dominant global orientations, we first accumulated the calculated orientation and its strength at each pixel position into <p> the two studies presented here, we used four and three levels of the pyramid respectively (four levels were used in <ref> [12] </ref>). The number of pyramid levels is set to be the largest it can given the size of the image or subregion for which the orientation is being computed. In [12], to find the dominant global orientations, we first accumulated the calculated orientation and its strength at each pixel position into a "strength histogram," H s : H s (k) = P b1 , k = 0; 1; 2; : : : ; b 1 (1) where N (k) is the <p> This is done using a measure of "salience" of a peak, dependent on the height of the peak, its steepness and its width <ref> [12] </ref>. These salience measures are then thresholded (different thresholds for the salience measure are used for each level of the pyramid) to obtain decisions about orientations at each scale, and combined over scale. The thresholds used in [12] were found by iterative adjustment until they gave results which closely matched those <p> peak, dependent on the height of the peak, its steepness and its width <ref> [12] </ref>. These salience measures are then thresholded (different thresholds for the salience measure are used for each level of the pyramid) to obtain decisions about orientations at each scale, and combined over scale. The thresholds used in [12] were found by iterative adjustment until they gave results which closely matched those found from the study of forty human subjects. <p> starting point for the second study, with only very slight changes needed to optimize their performance. 3 Study: Teaser images We designed a set of 256 fi 256 "teaser" images to investigate some of the limitations of filter size and "higher-level" human visual processing on the orientation-finding algorithm (same as <ref> [12] </ref> except that the H n histogram described above was used and the contrast normalization step was omitted due to the fact that it is very computationally expensive). A human study involving 39 subjects was carried out on this data using the same conditions as [12]. <p> the orientation-finding algorithm (same as <ref> [12] </ref> except that the H n histogram described above was used and the contrast normalization step was omitted due to the fact that it is very computationally expensive). A human study involving 39 subjects was carried out on this data using the same conditions as [12]. None of the subjects were researchers in computer vision or pattern recognition. 2 (a) (b) (c) (g) The images used in this study are shown in Figure 3 (a)- (g). Figure 3 (a) shows horizontal lines with a vertical break between them. <p> Similarly, eight of the 39 subjects picked the vertical orientation to be dominant. We count this inability of the algorithm to "group" the lines into their horizontal direction as the first case of where it fails. We discussed fixes to this failure mode in <ref> [12] </ref>; all of the fixes involve more processing which begins to slow down the "quick glance" approach. Both the computer and the human subjects chose the orientation of the diagonals at 43 ffi . The humans (by a narrow 24/39 subjects) also picked the vertical orientation to be dominant. <p> We count this lack of detecting the vertical orientation as the second case where the algorithm failed. data indicates that the subjects also perceived the diagonal lines to be parallel. One possible reason for the illusion not working could be due to the experimental design <ref> [12] </ref> which had the humans spin a bar on top of the test image. Also since the human data is quantized (same method as [12]), small differences between the orientations chosen are sometimes lost. At first glance, the "teaser" images may seem trivial. <p> One possible reason for the illusion not working could be due to the experimental design <ref> [12] </ref> which had the humans spin a bar on top of the test image. Also since the human data is quantized (same method as [12]), small differences between the orientations chosen are sometimes lost. At first glance, the "teaser" images may seem trivial. However, the fact that the subjects' responses were not always in agreement indicates that not all the orientations were perceptually obvious and may have required a "high-level" interpretation. <p> No other preprocessing was done on the images, nor were any images omitted from the original set we were given. 4.3 Finding orientation in image regions For natural scenes, we applied the orientation-finding algorithm of <ref> [12] </ref> except for the modifications described earlier, to regions in the images. There are a huge number of ways to divide the images into regions. <p> If a region has only a vertical orientation and an orientation from 45 ffi 45 ffi satisfying the salience measure thresholds shown in Table 1 (these thresholds are slightly different from <ref> [12] </ref> since only three levels of the pyramid were used), it is considered for the calculation of R. For regions having only a dominant vertical orientation, we use a higher salience measure threshold to ensure that only those with very strong vertical orientations are considered. <p> Except 5 for two cases, the computer detected the orientations found by the majority of the humans, thus offering more evidence that the multiscale orientation finding method of <ref> [12] </ref> can find "perceptually important" dominant orientations. Second, we showed an application where the dominant textural orientations were used to quickly index through 98 images of natural scenes to find likely "city/suburb" scenes which have strongly oriented man-made structures such as buildings, cars and sign posts.
Reference: [13] <author> P. Brodatz. </author> <title> Textures: A Photographic Album for Artists and Designers. </title> <publisher> Dover, </publisher> <address> New York, </address> <year> 1966. </year>
Reference-contexts: The orientation finding algorithm was able to find at least one dominant orientation chosen by the human subjects in 95 of the 111 test images from the Bro-datz Album <ref> [13] </ref>. Except for some small modifications, this is the algorithm used in this paper.
Reference: [14] <author> W. T. Freeman. </author> <title> Steerable Filters and Local Analysis of Image Structure. </title> <type> PhD thesis, </type> <institution> Media Arts and Sciences, MIT, </institution> <year> 1992. </year>
Reference-contexts: Unlike the works mentioned above, the implementation used here and in [12] extracts orientation information over multiple scales using a steerable pyramid <ref> [14] </ref>, then combines the orientations from different scales and decides which are dominant perceptually, as determined by a human study. The bottom level of the steerable pyramid (level0) is the original image, and each higher level is obtained by filtering and subsampling the previous level.
Reference: [15] <author> I. Rock. </author> <title> The Perceptual World. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, NY, </address> <year> 1990. </year>
Reference: [16] <author> D. H. Ballard and C. M. Brown. </author> <title> Computer Vision. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1982. </year>
Reference-contexts: For this study we only considered the 35 images judged by at least two out of three people to be "city/suburb" scenes. For determining the dominant orientations, we used the NTSC "Y" component of the images <ref> [16] </ref>. No other preprocessing was done on the images, nor were any images omitted from the original set we were given. 4.3 Finding orientation in image regions For natural scenes, we applied the orientation-finding algorithm of [12] except for the modifications described earlier, to regions in the images.
Reference: [17] <author> R. W. Picard and T. Kabir. </author> <title> Finding similar patterns in large image databases. </title> <booktitle> In Proc. ICASSP, pages V-161-V-164, </booktitle> <address> Minneapolis, MN, </address> <year> 1993. </year> <month> 6 </month>
Reference-contexts: These features can be pre-computed beforehand and used to further improve the "quick-glance" method in real-time image database retrieval environments like Photobook <ref> [17] </ref>. Another direct application for using dominant textural orientation is that it can be used to find areas in the image with certain types of directional structure for speeding up object and motion recognition.
References-found: 17

