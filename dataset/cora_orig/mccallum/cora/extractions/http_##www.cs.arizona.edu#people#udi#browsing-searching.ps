URL: http://www.cs.arizona.edu/people/udi/browsing-searching.ps
Refering-URL: http://www.cs.arizona.edu/people/udi/
Root-URL: http://www.cs.arizona.edu
Email: udi@cs.arizona.edu  
Phone: (520) 621-4317  
Title: COMBINING BROWSING AND SEARCHING (Preliminary Version)  
Author: Burra Gopal, Paul Klark, and Udi Manber 
Date: October 1995  
Address: Tucson, AZ 85721  
Affiliation: Department of Computer Science University of Arizona  
Abstract: We discuss how to combine on-line searching with browsing. Currently, these two paradigms are almost always separate, and users must choose between them. We have developed software that allows users to browse a hypertext-based information base and to search from any point while browsing such that the search will be limited to the area suggested by the current document. We describe the design and implementation of this software package, called glimpseHTTP, and discuss our plan to improve and extend the basic design to general hypertext-based systems. Our implementation was geared towards the World-Wide Web (WWW), but it is applicable to any large-scale information bases. GlimpseHTTP has been used for about two years now by numerous sites. We believe that the concept of browsing and searching is very powerful. We suggest in this paper methods to implement this concept in digital libraries and other large-scale information bases. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Yahoo Directory, </author> <note> http://www.yahoo.com/ </note>
Reference-contexts: However, browsing is slow, very time-consuming, and users tend to get disoriented and lose their train of thoughts and their original goals. These two paradigms are used separately by most systems. For example, the Yahoo WWW directory <ref> [1] </ref> (the most commonly used directory, since it is promoted by Netscape Corp) provides search facilities and a search icon appears on every page, but all searches are global. The same is true for the McKin-ley Internet Directory [2], Excite [3] (by Architext) and others.
Reference: [2] <institution> McKinley Group Directory of the Internet, </institution> <note> http://www.mckinley.com/ </note>
Reference-contexts: For example, the Yahoo WWW directory [1] (the most commonly used directory, since it is promoted by Netscape Corp) provides search facilities and a search icon appears on every page, but all searches are global. The same is true for the McKin-ley Internet Directory <ref> [2] </ref>, Excite [3] (by Architext) and others. We argue that by combining browsing and searching, users will be given a much more powerful tool to find their way. We envision a system where both paradigms will be offered all the time.
Reference: [3] <author> Excite by Architext, </author> <note> http://www.excite.com/Subject/ </note>
Reference-contexts: For example, the Yahoo WWW directory [1] (the most commonly used directory, since it is promoted by Netscape Corp) provides search facilities and a search icon appears on every page, but all searches are global. The same is true for the McKin-ley Internet Directory [2], Excite <ref> [3] </ref> (by Architext) and others. We argue that by combining browsing and searching, users will be given a much more powerful tool to find their way. We envision a system where both paradigms will be offered all the time.
Reference: [4] <author> InfoSeek search, </author> <note> http://www2.infoseek.com/ </note>
Reference-contexts: The question is how to implement such a scheme efficiently and as automatically as possible. The discussion above applies to the WWW just as well. Continuing the example above, we searched for ``military computer accident'' using InfoSeek <ref> [4] </ref>. One of the results pointed to a document entitled ``Robinson R-22 Accident Analysis 1979-1994.'' Having reached a relevant starting point, it would have been very beneficial if we could continue the search from there (maybe after following some links).
Reference: [5] <author> Manber U. and S. Wu, ``GLIMPSE: </author> <title> A Tool to Search Through Entire File Systems,'' </title> <booktitle> Usenix Winter 1994 Technical Conference, </booktitle> <address> San Francisco (January 1994), </address> <pages> pp. 23-32. </pages>
Reference-contexts: We describe the software and its implementation in detail in the next section, then go to describe our current plans for extending it, and our vision of how this might be used in large-scale digital libraries. 2. Glimpse and GlimpseHTTP 2.1. Glimpse The search engine for glimpseHTTP is glimpse <ref> [5] </ref> (which also serves as the default search engine in the Harvest system [6]). We'll just mention the features of glimpse that are relevant to the searching/browsing problem. More on glimpse can be found at its home pages [7]. <p> In the medium-size index the pointers point to exact locations, in the small one the pointers are just file names, and in the tiny one the pointers are to blocks of files. Glimpse has several other interesting features (see <ref> [5] </ref> or [7]). The pointers file has another feature. Its pointers are not explicit but indirect. There is another file, called the filenames file, which contains the list of all indexed files. The pointers in the pointers file are in fact indexes to the filenames file.
Reference: [6] <author> Bowman C. M., P. B. Danzig, D. R. Hardy, U. Manber, and M. F. Schwartz, </author> <title> ``The Harvest Information Discovery and Access System,'' </title> <note> to appear in a special issue of Computer Networks and ISDN Systems. An earlier version appeared in the Proceedings of the Second International World Wide Web Conference, </note> <institution> Chicago, </institution> <month> Illinois (October </month> <year> 1994), </year> <pages> pp. 763-771. </pages>
Reference-contexts: Glimpse and GlimpseHTTP 2.1. Glimpse The search engine for glimpseHTTP is glimpse [5] (which also serves as the default search engine in the Harvest system <ref> [6] </ref>). We'll just mention the features of glimpse that are relevant to the searching/browsing problem. More on glimpse can be found at its home pages [7]. Glimpse is an indexing and search software, designed slightly different than most other indexing systems. <p> to save time and network resources by asking neighborhood queries and following only relevant links. (We are also working on a scheme to link several remote indexes together, so queries can be asked on more than one index, but this is beyond the scope of this paper.) The Harvest system <ref> [6] </ref> is perfectly suited for this work. Harvest provides automatic ways to collect topical information. Its ``gatherers'' can perform the collection exactly as described above, and can further customize what documents to select (i.e., how to define the neighborhood). Its ``brokers'' (servers) provide the indexing and user interface.
Reference: [7] <institution> Glimpse Home Pages, </institution> <note> http://glimpse.cs.arizona.edu:1994/ </note>
Reference-contexts: Glimpse The search engine for glimpseHTTP is glimpse [5] (which also serves as the default search engine in the Harvest system [6]). We'll just mention the features of glimpse that are relevant to the searching/browsing problem. More on glimpse can be found at its home pages <ref> [7] </ref>. Glimpse is an indexing and search software, designed slightly different than most other indexing systems. Glimpse's index consists essentially of two parts, the word file and the pointers file. <p> In the medium-size index the pointers point to exact locations, in the small one the pointers are just file names, and in the tiny one the pointers are to blocks of files. Glimpse has several other interesting features (see [5] or <ref> [7] </ref>). The pointers file has another feature. Its pointers are not explicit but indirect. There is another file, called the filenames file, which contains the list of all indexed files. The pointers in the pointers file are in fact indexes to the filenames file.
Reference: [8] <author> Wu S., and U. Manber, </author> <title> ``Fast Text Searching Allowing Errors,'' </title> <booktitle> Communications of the ACM 35 (October 1992), </booktitle> <pages> pp. 83-91. </pages>
Reference-contexts: The relevant pointers (to the source text) in the pointers file are collected. The second stage is another search, using agrep <ref> [8] </ref>, in the corresponding places in the original text. This is similar in principle to the usual inverted indexes, except that the word file, being one relatively small file, can be searched sequentially.
Reference: [9] <author> Morton D., and S. Silcot, </author> <title> ``Systems for providing searchable access to collections of HTML documents,'' </title> <booktitle> First Australian WWW conference, </booktitle> <month> July </month> <year> 1995. </year> <note> (http://www.scu.edu.au/ausweb95/papers/indexing/morton/) </note>
Reference-contexts: Simple queries with words as patterns and Boolean operators is optimized by using hashing into the word file. Such queries generally take less than a second. More complex searches obviously take more time, but it is worth the extra flexibility. A recent article <ref> [9] </ref> compared glimpse with WAIS and found that ``system requirements, administration and maintenance and, most importantly, user functionality is dramatically better than WAIS for both searching and browsing.'' Glimpse is particularly suitable for our purposes because it supports very flexible ways to limit the search to only parts of the information
Reference: [10] <institution> A list of sites using GlimpseHTTP, </institution> <note> http://glimpse.cs.arizona.edu:1994/ghttp/sites.html </note>
Reference-contexts: It is used in over 150 servers (that we know of) around the WWW, including the governments of Canada, Australia, and New Zealand, the American Red Cross, NASA, LBL, the San Diego Supercomputer Center, and many universities. (See <ref> [10] </ref> for a current list.) We first describe it with one running example the Computer Science Bibliography server [11] which we have been running for over a year, serving about 600 queries a day and about the same at two other mirror sites.
Reference: [11] <institution> Computer Science Bibliography Glimpse Server, </institution> <note> http://glimpse.cs.arizona.edu:1994/bib/ </note>
Reference-contexts: servers (that we know of) around the WWW, including the governments of Canada, Australia, and New Zealand, the American Red Cross, NASA, LBL, the San Diego Supercomputer Center, and many universities. (See [10] for a current list.) We first describe it with one running example the Computer Science Bibliography server <ref> [11] </ref> which we have been running for over a year, serving about 600 queries a day and about the same at two other mirror sites. The information base for glimpseHTTP is assumed to be a regular UNIX hierarchical file structure.
Reference: [12] <author> Salton, G., </author> <title> Automatic Text Processing, The Transformation, Analysis, and Retrieval of Information by Computer, </title> <publisher> Addison Wesley, </publisher> <address> Reading, Mass., </address> <year> 1989. </year>
Reference-contexts: The typical Information Retrieval approach to the ``related-to'' type of queries is to analyze the current document and provide similarity searches in the global databases. There is a wide body of research about comparing documents and finding related ones <ref> [12] </ref>. If successful, this is the right approach, but it is still too hard, too slow for large scale, and requires too much human intervention. Computing similarities is expensive and it requires that the information base is organized and understood.
Reference: [13] <author> Domel, P., </author> <title> ``WebMap A Graphical Hypertext Navigation Tool,'' </title> <booktitle> Proceedings of the Second International World Wide Web Conference, </booktitle> <address> Chicago, Illinois (October 1994). </address> <month> 12 </month>
Reference-contexts: For example, having the neighborhoods can enhance visualizations of the structure of the hypertext (see <ref> [13, 14] </ref> for work on visualization of the WWW on the fly). One can also use this information to ``fly'' through it [15] (browse very quickly and on auto-pilot) to get a sense of it. 4.
Reference: [14] <author> Ayers, E. Z. and J. T. Stasko, </author> <title> ``Using Graphic History in Browsing the World Wide Web,'' </title> <type> Technical Report GIT-GVU-95-12, </type> <institution> Georgia Inst. </institution> <note> of Technology (May 1995). </note>
Reference-contexts: For example, having the neighborhoods can enhance visualizations of the structure of the hypertext (see <ref> [13, 14] </ref> for work on visualization of the WWW on the fly). One can also use this information to ``fly'' through it [15] (browse very quickly and on auto-pilot) to get a sense of it. 4.
Reference: [15] <author> Lai P, and U. Manber, </author> <title> ``Flying through Hypertext,'' </title> <booktitle> Proc. of the Third ACM Conference on Hypertext, </booktitle> <address> San Antonio, </address> <month> Texas (December </month> <year> 1991), </year> <pages> pp. 123-132. </pages>
Reference-contexts: For example, having the neighborhoods can enhance visualizations of the structure of the hypertext (see [13, 14] for work on visualization of the WWW on the fly). One can also use this information to ``fly'' through it <ref> [15] </ref> (browse very quickly and on auto-pilot) to get a sense of it. 4. Conclusions We believe that combining browsing with searching will significantly enhance future information discovery systems. This paper described our first step in implementing this concept and our plans for extending it.
Reference: [16] <author> Cutting D. R., D. R. Karger and J. O. Pedersen, </author> <title> ``Constant Interaction-Time Scatter/Gather Browsing of Very Large Document Collections,'' </title> <booktitle> Proceedings of the Sixteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (1993), </booktitle> <pages> pp. 126-134. </pages>
Reference-contexts: We concentrated on relatively simple and efficient schemes that can be implemented quickly. Our approach can complement classification and/or clustering systems very well. In particular, it would be very interesting to see how to combine our fixed neighborhood search with the ideas of scatter/gather <ref> [16] </ref>.
References-found: 16

