URL: http://pegasus.ece.utexas.edu:80/~ismail/paper_rev2.ps.Z
Refering-URL: 
Root-URL: 
Email: email: aggarwaljk@mail.utexas.edu  
Title: A Comparative Study of Three Paradigms for Object Recognition Bayesian Statistics, Neural Networks and Expert Systems.  
Author: J. K. Aggarwal, Joydeep Ghosh, Dinesh Nair and Ismail Taha 
Address: Austin, Austin, TX, USA  
Affiliation: Computer and Vision Research Center The University of Texas at  
Abstract: Object recognition, which involves the classification of objects into one of many a priori known object types, and determining object characteristics such as pose, is a difficult problem. A wide range of approaches have been proposed and applied to this problem with limited success. This paper presents a brief comparative study of methods from three different paradigms for object recognition: Bayesian, Neural Network and Expert Systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. W. McKee and J. K. Aggarwal, </author> <title> "Computer recognition of partial views of curved objects," </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. C-26, no. 8, </volume> <pages> pp. 790-800, </pages> <year> 1977. </year>
Reference-contexts: 1 Introduction Recognizing 3-dimensional (3D) objects from 2-dimensional (2D) images is an important part of computer vision <ref> [1] </ref>. The success of most computer vision applications (robotics, automatic target recognition, surveillance, etc.) is closely tied with the reliability of the recognition of 3D objects or surfaces. <p> Broadly speaking, there are two ways to approach this problem. The first is based on matching salient information, such as corner points, lines, contours etc., that has been extracted from the image to the information obtained from the image database <ref> [1] </ref>, [12]. Based on the best match, the object is recognized and its pose estimated.
Reference: [2] <author> W. E. L. </author> <title> Grimson, Object Recognition by Computer: The role of geometric constraints. </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1990. </year>
Reference-contexts: Recognition is the process of finding a correspondence between certain features in the image and similar features of the object model <ref> [2] </ref>. The most important issues involved in this process are: (a) identifying the type of features to use, and (b) determining the procedure to obtain the correspondence between image and model features. The reliability and efficiency of an object recognition system directly depends on how carefully these are addressed.
Reference: [3] <author> B. Vemuri, A. Mitiche, and J. K. Aggarwal, </author> <title> "Curvature-based representation of objects from range data," </title> <journal> Image and Vision Computing, </journal> <volume> vol. 4, no. 2, </volume> <pages> pp. 107-114, </pages> <year> 1986. </year>
Reference-contexts: The 3D model contains concise and complete information about the object in terms of shape descriptions <ref> [3] </ref>, object parts information, relationship between object parts, etc. The 3D structure of an object is frequently represented by CAD models [4], where volume-based representations of the object is built using primitives such as generalized cones, generalized cylinders and spheres.
Reference: [4] <author> F. Arman and J. K. Aggarwal, </author> <title> "CAD-based vision: Object recognition in cluttered range images using recognition strategies," Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> vol. 58, no. 1, </volume> <pages> pp. 33-47, </pages> <year> 1993. </year>
Reference-contexts: The 3D model contains concise and complete information about the object in terms of shape descriptions [3], object parts information, relationship between object parts, etc. The 3D structure of an object is frequently represented by CAD models <ref> [4] </ref>, where volume-based representations of the object is built using primitives such as generalized cones, generalized cylinders and spheres. Typically, recognition involves extracting 3D information from the image and comparing it with the model features [4], or deriving a 2D description from the image and then comparing it with 2D projections <p> The 3D structure of an object is frequently represented by CAD models <ref> [4] </ref>, where volume-based representations of the object is built using primitives such as generalized cones, generalized cylinders and spheres. Typically, recognition involves extracting 3D information from the image and comparing it with the model features [4], or deriving a 2D description from the image and then comparing it with 2D projections of the model.
Reference: [5] <author> Y. F. Wang, M. J. Magee, and J. K. Aggarwal, </author> <title> "Matching three-dimensional objects using silhouettes," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 6, no. 4, </volume> <pages> pp. 513-518, </pages> <year> 1984. </year>
Reference-contexts: In the latter case, the task is a more difficult because the effects of self-occlusions and perspective must be considered, and the projection direction needs to be determined. In <ref> [5] </ref> the 3D structure of an object is constructed using an observed sequence of silhouettes.
Reference: [6] <author> F. Arman and J. K. Aggarwal, </author> <title> "Model-based object recognition in dense depth images A review," </title> <journal> ACM Computing Surveys, </journal> <volume> vol. 25, no. 1, </volume> <pages> pp. 5-43, </pages> <year> 1993. </year>
Reference-contexts: During matching, the 3D structure of the unknown object is constructed from different image views and more views are added to the construction process until features extracted from the object matches one of the object models. A comprehensive survey of model-based vision systems using dense-range images is presented in <ref> [6] </ref> and a recent survey is found in [10]. 1.2 View-Based Object Recognition View-based object recognition is often referred to as viewed-centered or 2D object recognition, because direct information about the 3D structure (such as a 3D model) of the object is not available; the only a priori information is in
Reference: [7] <author> J. Koenderink and A. van Doorn, </author> <title> "The internal representation of solid shape with respect to vision," </title> <journal> Biological Cybernetics, </journal> <volume> vol. 32, </volume> <pages> pp. 211-216, </pages> <year> 1979. </year>
Reference-contexts: Each representation (or characteristic view) describes how the object appears from a single viewpoint, or from a range of viewpoints yielding similar views. There is evidence showing that object recognition by humans is viewer-centered rather than object-centered <ref> [7] </ref>. The characteristic views may be obtained by building a database of images of the object or may be rendered from a 3D model of the object [8], [9]. Matching in this case is simpler than in model-based recognition because it involves only a 2D/2D comparison. <p> Each object was represented by a vector of 23 features. For this application the multilayer perceptron with 2 hidden layers gave the best results. In view-centered recognition, approaches based on aspect graphs are quite common. Aspect graphs <ref> [7] </ref> are created by representing 2D views of a 3D object along the nodes of the graph, with legal view transitions indicated by the arcs among the nodes.
Reference: [8] <author> A. Pathak and O. I. </author> <title> Camps, "Bayesian view class determination," </title> <booktitle> Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 407-412, </pages> <year> 1993. </year>
Reference-contexts: There is evidence showing that object recognition by humans is viewer-centered rather than object-centered [7]. The characteristic views may be obtained by building a database of images of the object or may be rendered from a 3D model of the object <ref> [8] </ref>, [9]. Matching in this case is simpler than in model-based recognition because it involves only a 2D/2D comparison. However, the space requirements for representing all the characteristics views of an object tends to be considerable. <p> The pose identification process can also be used to verify the initial match (es), as the candidate view clusters should have a good pose match with the image region (features). Bayesian statistics provide a complete framework for representing these view clusters and for the view class determination problem <ref> [8] </ref>. In [28] a hierarchical recognition methodology that uses salient object parts as cues for classification and recognition and a hierarchical modular structure (HMS) for parts-based object recognition is proposed.
Reference: [9] <author> S. Zhang, G. Sullivan, and K. Baker, </author> <title> "The automatic construction of a view-independent relational model for 3D object recognition," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 15, no. 6, </volume> <pages> pp. 778-786, </pages> <year> 1993. </year>
Reference-contexts: There is evidence showing that object recognition by humans is viewer-centered rather than object-centered [7]. The characteristic views may be obtained by building a database of images of the object or may be rendered from a 3D model of the object [8], <ref> [9] </ref>. Matching in this case is simpler than in model-based recognition because it involves only a 2D/2D comparison. However, the space requirements for representing all the characteristics views of an object tends to be considerable.
Reference: [10] <author> A. Pope, </author> <title> "Model-based object recognition-a survey of recent research," </title> <type> Technical Report, vol. </type> <institution> TR-94-04, University of British Columbia, </institution> <year> 1994. </year>
Reference-contexts: A comprehensive survey of model-based vision systems using dense-range images is presented in [6] and a recent survey is found in <ref> [10] </ref>. 1.2 View-Based Object Recognition View-based object recognition is often referred to as viewed-centered or 2D object recognition, because direct information about the 3D structure (such as a 3D model) of the object is not available; the only a priori information is in the form of representations of the object viewed <p> Also, the number of model features to search among increases, because each characteristic view can be considered to be a model. Methods to reduce the search space have been addressed by grouping similar views <ref> [10] </ref> [11]. Broadly speaking, there are two ways to approach this problem. The first is based on matching salient information, such as corner points, lines, contours etc., that has been extracted from the image to the information obtained from the image database [1], [12].
Reference: [11] <author> J. B. Burns and E. M. Riseman, </author> <title> "Matching complex images to multiple 3D objects using view description networks," </title> <booktitle> Proceedings IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 328-334, </pages> <year> 1992. </year>
Reference-contexts: Also, the number of model features to search among increases, because each characteristic view can be considered to be a model. Methods to reduce the search space have been addressed by grouping similar views [10] <ref> [11] </ref>. Broadly speaking, there are two ways to approach this problem. The first is based on matching salient information, such as corner points, lines, contours etc., that has been extracted from the image to the information obtained from the image database [1], [12].
Reference: [12] <author> S. Chen and A. K. Jain, </author> <title> "Strategies of multi-view multi-matching for 3D object recognition," </title> <booktitle> Computer Vision and Image Processing, </booktitle> <volume> vol. 57, no. 1, </volume> <pages> pp. 121-130, </pages> <year> 1993. </year>
Reference-contexts: Broadly speaking, there are two ways to approach this problem. The first is based on matching salient information, such as corner points, lines, contours etc., that has been extracted from the image to the information obtained from the image database [1], <ref> [12] </ref>. Based on the best match, the object is recognized and its pose estimated.
Reference: [13] <author> J. Pearl, </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann Publishers, Inc. </publisher> <address> San Mateo, California, </address> <year> 1988. </year>
Reference-contexts: In this section we review three paradigms that are commonly used for handling uncertainties in realistic systems: Bayesian statistic, neural networks and expert systems. 1.3.1 Bayesian Statistics Bayesian methods provide a formal means to reason about partial beliefs under conditions of uncertainty <ref> [13] </ref> [14]. Within this formulation, propositions (A) are given numerical parameters (P (AjK)) whose values signify the degree of belief given some knowledge (K) about the current environment or problem, and the parameters can be combined and manipulated according to the rules of probability.
Reference: [14] <author> R. O. Duda and P. E. Hart, </author> <title> Pattern Classification and Scene Analysis. </title> <note> A Wiley-Interscience Publication, </note> <year> 1973. </year>
Reference-contexts: In this section we review three paradigms that are commonly used for handling uncertainties in realistic systems: Bayesian statistic, neural networks and expert systems. 1.3.1 Bayesian Statistics Bayesian methods provide a formal means to reason about partial beliefs under conditions of uncertainty [13] <ref> [14] </ref>. Within this formulation, propositions (A) are given numerical parameters (P (AjK)) whose values signify the degree of belief given some knowledge (K) about the current environment or problem, and the parameters can be combined and manipulated according to the rules of probability.
Reference: [15] <author> A. Jain, J. Mao, and K. M. Mohiuddin, </author> <title> "Artificial neural networks: A tutorial," </title> <booktitle> in Computer, </booktitle> <pages> pp. 31-44, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: Artificial neural networks (ANNs) are highly parallel networks of simple computational elements (nodes) <ref> [15] </ref>. Each node performs operations such as summing the weighted inputs coming into it and then amplifying / thresholding the sum.
Reference: [16] <author> D. J. MacKay, </author> <title> "Probable networks and plausible predictions a review of practical bayesian methods for supervised neural networks." </title> <note> to appear in Network. </note>
Reference-contexts: The biggest advantage of a Bayesian (or probabilistic) framework is in its ability to incorporate uncertainty elegantly into the recognition process. Bayesian approaches also provide an error estimate with its decision, which gives another perspective for analyzing systems. Other advantages of using a Bayesian framework are <ref> [16] </ref>: 1. Modeling assumptions such as priors, noise distributions, etc., need to be explicitly defined. However, once the assumptions are made, the rules of probability give us an unique answer for any question that is posed. 2. <p> We now touch upon some areas of research that the authors believe are important and will influence the design of object recognition systems in the future. 5.1 Bayesian Methods and Neural Networks Bayesian methods and neural networks share several similarities <ref> [16] </ref> [58] [59]. Both methods generate models that closely fit the data. Many popular artificial neural networks are essentially nonlinear parametric or semi-parametric estimators that are based on general and powerful functional forms such as a linear combination of sigmoidal or radial basis functions. <p> This process can be facilitated by interpreting neural networks as probabilistic models which is possible with several neural networks that are used as regression networks as well as classifiers <ref> [16] </ref>. For example, the objective function (plus some regularization parameter) that is minimized during the training (weight change) of a neural network can be regarded as the negative log of the probability assigned to the observed data by the model with the current weights.
Reference: [17] <author> Y. Lamdan, Y. Shwartz, and H. Wolfson, </author> <title> "Affine invariant model-based object recognition," </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> vol. 6, no. 5, </volume> <pages> pp. 578-589, </pages> <year> 1990. </year>
Reference-contexts: Thus a set of possible matches are found without actually comparing all possible image/model pairs. An important issue in indexing is to make the extracted features relatively invariant to affine transformation and orthographic/perspective projections <ref> [17] </ref>. For indexing using three points on the object, an elegant approach based on the probabilistic peaking effect can be implemented.
Reference: [18] <author> J. Ben-Arie, </author> <title> "The probabilistic peaking effect of viewed angles and distances with application to 3D object recognition," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 12, no. 8, </volume> <pages> pp. 760-774, </pages> <year> 1990. </year>
Reference-contexts: It has been observed that the probability density function of certain features in an image tend to peak at the values taken by the features in the model (probabilistic peaking effect) <ref> [18] </ref>. This means there is a large range of viewing directions over which these values change in the image by a small amount.
Reference: [19] <author> C. F. Olson, </author> <title> "Probabilistic indexing for object recognition," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 17, no. 5, </volume> <pages> pp. 518-522, </pages> <year> 1995. </year>
Reference-contexts: This information can be used to select only those matches whose feature values are fairly close to the image features and to disregard matches that have a small likelihood of being in actual correspondence. The probabilistic indexing approach can also be extended to more that three points <ref> [19] </ref>. As a final note, the probabilistic indexing works well for most object recognition problems except when the objects are considerably foreshortened in the image due to rotation. <p> Only these matches are considered and the rest are discarded. Other error measures can be used to further reduce the number of matches that need to be examined. Using this method the speedup obtained is equal to the fraction of the total matches indexed that are used for verification <ref> [19] </ref>. Geometric Hashing: for object recognition may be summarized as follows.
Reference: [20] <author> D. P. Huttenlocher and S. Ullman, </author> <title> "Recognizing solid objects by alignment with the image," </title> <journal> International Journal on Computer Vision, </journal> <volume> vol. 5, no. 2, </volume> <pages> pp. 195-212, </pages> <year> 1990. </year>
Reference-contexts: In such cases they produce angles and distance ratios far from the probability peaks and will be difficult to recognize using probabilistic indexing techniques. Alignment <ref> [20] </ref> and geometric hashing [21] [22] are related techniques that are used to recognize 3D object from 2D scenes. Both methods use a small number of points to find a transformation between the model space and the image space.
Reference: [21] <author> D. Gavrila and F. Greon, </author> <title> "3D object recognition from 2D image using geometric hashing," </title> <journal> Pattern Recognition Letters, </journal> <volume> vol. 13, no. 4, </volume> <pages> pp. 263-278, </pages> <year> 1992. </year>
Reference-contexts: In such cases they produce angles and distance ratios far from the probability peaks and will be difficult to recognize using probabilistic indexing techniques. Alignment [20] and geometric hashing <ref> [21] </ref> [22] are related techniques that are used to recognize 3D object from 2D scenes. Both methods use a small number of points to find a transformation between the model space and the image space.
Reference: [22] <author> I. Rigoutsos and R. Hummel, </author> <title> "Distributed Bayesian object recognition," </title> <booktitle> Proceedings IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 180-186, </pages> <year> 1993. </year>
Reference-contexts: In such cases they produce angles and distance ratios far from the probability peaks and will be difficult to recognize using probabilistic indexing techniques. Alignment [20] and geometric hashing [21] <ref> [22] </ref> are related techniques that are used to recognize 3D object from 2D scenes. Both methods use a small number of points to find a transformation between the model space and the image space. <p> Geometric hashing is recast in probabilistic terms in <ref> [22] </ref> and geometric hashing with weighted voting is interpreted as a Bayesian maximum likelihood object recognition system.
Reference: [23] <author> W. M. Wells, </author> <title> Statistical Object Recognition. </title> <type> PhD thesis, </type> <address> Cambridge, </address> <publisher> MIT, </publisher> <month> November </month> <year> 1993. </year>
Reference-contexts: Matching in the correspondence space is easily defined using Bayesian statistics. Also, the search in the correspondence space can by cast as an iterative estimation problem using the Bayesian theory. Both techniques are exemplified by the work done by Wells <ref> [23] </ref>, who uses a two stage statistical formulation for feature based object recognition. In the first stage (correspondence), the joint hypotheses of match and pose are evaluated in terms of their a posteriori probabilities for a given image.
Reference: [24] <author> P. R. Cooper, </author> <title> Parallel Object Recognition from Structure The Tinkertoy Project. </title> <type> PhD thesis, </type> <institution> University of Rochester, Rochester, </institution> <address> New York, </address> <year> 1989. </year>
Reference-contexts: This maximum is then obtained by iteratively using a variant of the Expectation-Minimization (EM) algorithm to get the correct pose. Markov random fields (MRFs): provide an efficient tool to incorporate neighborhood/ dependency constraints that can make the matching/recognition process more reliable and effective <ref> [24] </ref>. During the hypothesis generation stage, while trying to determine all possible matches between image features (such as regions or edges) and model features, it is important to include all possible correct matches and exclude as many incorrect ones as possible.
Reference: [25] <author> P. B. Chou and C. M. Brown, </author> <title> "The theory and practice of Bayesian image labeling," </title> <journal> International Journal on Computer Vision, </journal> <volume> vol. 4, </volume> <pages> pp. 185-210, </pages> <year> 1990. </year>
Reference-contexts: For a review of MRFs and their applications to computer vision, the reader is referred to <ref> [25] </ref>. The use of a Markovian framework to improve the efficiency of object recognition is used in [26] where a probabilistic hypothesis generation or matching between features in an image and the model features is done. <p> Given a set of regions extracted from the image, the most likely set of hypotheses is obtained by minimizing the energy function in equation (2). Different techniques such as Highest Confidence First (HCF) <ref> [25] </ref> and Simulated Annealing [27] procedures can be used to get fairly good results. After the minimization process is completed using either of the procedures mentioned above, all matches that are ON are considered for verification.
Reference: [26] <author> M. Wheeler and K. </author> <title> Ikeuchi, "Sensor modeling, probabilistic hypothesis generation, and robust localization for object recognition," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 17, no. 3, </volume> <pages> pp. 252-265, </pages> <year> 1995. </year>
Reference-contexts: For a review of MRFs and their applications to computer vision, the reader is referred to [25]. The use of a Markovian framework to improve the efficiency of object recognition is used in <ref> [26] </ref> where a probabilistic hypothesis generation or matching between features in an image and the model features is done. In this work, planar regions (R i ) extracted from range images are used as primitive features that are matched to faces on CAD models (M j ) of each object.
Reference: [27] <author> S. Geman and D. Geman, </author> <title> "Stochastic relaxation, gibbs distribution, and the bayesian restoration of images.," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 6, </volume> <pages> pp. 721-741, </pages> <year> 1984. </year>
Reference-contexts: Given a set of regions extracted from the image, the most likely set of hypotheses is obtained by minimizing the energy function in equation (2). Different techniques such as Highest Confidence First (HCF) [25] and Simulated Annealing <ref> [27] </ref> procedures can be used to get fairly good results. After the minimization process is completed using either of the procedures mentioned above, all matches that are ON are considered for verification. This verification is done by trying to estimate the pose of the object in the image.
Reference: [28] <author> D. Nair and J. K. Aggarwal, </author> <title> "Hierarchical, modular architectures for object recognition by parts." </title> <booktitle> submitted to 13th International Conference on Pattern Recognition. </booktitle> <month> November, </month> <year> 1996, </year> <institution> Vienna, Austria. </institution>
Reference-contexts: Bayesian statistics provide a complete framework for representing these view clusters and for the view class determination problem [8]. In <ref> [28] </ref> a hierarchical recognition methodology that uses salient object parts as cues for classification and recognition and a hierarchical modular structure (HMS) for parts-based object recognition is proposed.
Reference: [29] <author> A. P. Dempster, N. M. Laird, and D. B. Rubin, </author> <title> "Maximum likelihood from incomplete data via the EM algorithm.," </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> vol. 39-B, </volume> <pages> pp. 1-38, </pages> <year> 1977. </year>
Reference-contexts: The modular experts (i.e., object parts) are modeled as a mixture density of multivari-ate Gaussian distributions. For each module, features (Zernike moments in the current implementation) obtained from the object part from all possible viewpoints are used in an Expectation-Maximization (EM) approach <ref> [29] </ref> to determine the module parameters. When presented with an object part, each module computes the posterior probability of that part belonging to the object the module represents.
Reference: [30] <author> L. Xu and A. L. Yuille, </author> <title> "Robust principal component analysis by self-organizing rules based on statistical physics approach," </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 6, no. 1, </volume> <pages> pp. 131-195, </pages> <year> 1995. </year>
Reference-contexts: Some promising neural approaches to feature extraction and clustering have also been proposed [36], which are adaptive on-line and may exhibit additional desirable properties such as robustness against outliers <ref> [30] </ref>, as compared to more traditional feature extractors. Several types of neural networks can serve as adaptive classifiers that learn through examples. Thus, they do not require a good a priori mathematical model for the underlying physical characteristics.
Reference: [31] <author> K. Ng and R. Lippmann, </author> <title> "Practical characteristics of neural network and conventional pattern classifiers," </title> <booktitle> in Neural Information Processing Systems (J. </booktitle> <editor> M. R.P. Lippmann and D. Touretzky, </editor> <booktitle> eds.), </booktitle> <pages> pp. 970-976, </pages> <year> 1991. </year>
Reference-contexts: Techniques such as fuzzy logic can be incorporated into a neural network classifier for applications with little training data. A good review of probabilistic, hyperplane, kernel and exemplar-based classifiers that discusses the relative merit of various schemes within each category, is available in <ref> [31] </ref>.
Reference: [32] <author> J. Ghosh and K. Tumer, </author> <title> "Structural adaptation and generalization in supervised feed-forward networks," </title> <journal> Journal of Artificial Neural Networks, </journal> <volume> vol. 1, no. 4, </volume> <pages> pp. 431-458, </pages> <year> 1994. </year>
Reference-contexts: Although neural networks do not require geometric models, they do do require that the set of examples used for training should come from the same (possibly unknown) distribution as the set used for testing the networks, in order to provide valid generalization and good performance on classifying unknown signals <ref> [32] </ref>. To obtain valid results, the number of training examples must be adequate and comparable to the number of effective parameters in the neural network.
Reference: [33] <author> C. M. Bishop, </author> <title> Neural Networks for Pattern Recognition. </title> <address> New York: </address> <publisher> Oxford University Press, </publisher> <year> 1995. </year>
Reference-contexts: A deeper understanding of the properties of feed-forward neural networks has emerged recently that can relates their properties to Bayesian decision making and to information theoretic results <ref> [33] </ref>. A survey of neural network approaches to machine inspection can be found in [34]. 3.1 Function Approximation for Object Recognition In this section we describe neural network techniques that have been used for feature-based recognition and for indexing applications.
Reference: [34] <author> J. Ghosh, </author> <title> "Vision based inspection," in Artificial Neural Networks for Intelligent Manufacturing (C. </title> <editor> H. Dagli, </editor> <publisher> ed.), </publisher> <pages> pp. 265-297, </pages> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1994. </year>
Reference-contexts: A deeper understanding of the properties of feed-forward neural networks has emerged recently that can relates their properties to Bayesian decision making and to information theoretic results [33]. A survey of neural network approaches to machine inspection can be found in <ref> [34] </ref>. 3.1 Function Approximation for Object Recognition In this section we describe neural network techniques that have been used for feature-based recognition and for indexing applications.
Reference: [35] <author> A. K. Jain, </author> <title> "Advances in pattern recognition," in Pattern Recognition Theory and Applications (F. </title> <editor> A. Denijver and J. Kittler, </editor> <booktitle> eds.), </booktitle> <pages> pp. 1-19, </pages> <publisher> Springer-Verlag, </publisher> <year> 1986. </year>
Reference-contexts: A good review of the various issues in feature selection/extraction for pattern recognition is presented in <ref> [35] </ref>, [36]. Feature extraction and selection is used to identify the features which are most important in discriminating among different objects. Also, by retaining a small number of "useful" or "good" features, factors such as computational cost and classifier complexity are reduced.
Reference: [36] <author> J. Mao and A. K. Jain, </author> <title> "Artificial neural networks for feature extraction and multivari ate data projection," </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 6, no. 2, </volume> <pages> pp. </pages> <address> 296--317, </address> <year> 1995. </year>
Reference-contexts: Some promising neural approaches to feature extraction and clustering have also been proposed <ref> [36] </ref>, which are adaptive on-line and may exhibit additional desirable properties such as robustness against outliers [30], as compared to more traditional feature extractors. Several types of neural networks can serve as adaptive classifiers that learn through examples. <p> A good review of the various issues in feature selection/extraction for pattern recognition is presented in [35], <ref> [36] </ref>. Feature extraction and selection is used to identify the features which are most important in discriminating among different objects. Also, by retaining a small number of "useful" or "good" features, factors such as computational cost and classifier complexity are reduced.
Reference: [37] <author> G. Bradski and S. Grossberg, </author> <title> "Fast-learning VIEWNET architectures for recognizing three-dimensional from multiple two-dimensional views," </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 8, no. 7/8, </volume> <pages> pp. 1053-1080, </pages> <year> 1995. </year>
Reference-contexts: The biggest drawback of this system was in its space (cost) requirements. To reduce the system cost, which is directly related to the complexity of the evidence accumulation parts of the architecture, the VIEWNET architecture proposed in <ref> [37] </ref> explores the problem of enhancing the preprocessing and categorizing stages in order to generate less ambiguous 2D categories and hence, rely, less on view transitions. Indexing: as seen earlier, is an efficient method of recovering match hypotheses in model-based recognition.
Reference: [38] <author> J. Wang and F. Cohen, </author> <title> "3D object recognition and shape estimation from image contours using B-splines, shape invariant matching, and neural networks," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 16, no. 1, </volume> <pages> pp. 1-23, </pages> <year> 1994. </year>
Reference-contexts: A few of the commonly used features are invariant moments, log-polar transforms, shape descriptors such as Fourier descriptors and Zernike moments, and other local features such as curves and corner points, etc <ref> [38] </ref>. Saliency of a feature can be defined as the measure of the feature's ability to impact classification. One way to compare the saliency of features is by using the single probability of error criterion. This technique computes the probability of error separately for each individual feature.
Reference: [39] <author> D. P. Casasent and L. M. Neiberg, </author> <title> "Classifier and shift-invariant automatic target recognition neural networks," </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 8, no. 7/8, </volume> <pages> pp. 1117-1129, </pages> <year> 1995. </year>
Reference: [40] <author> D. Nair, A. Mitiche, and J. K. Aggarwal, </author> <title> "On comparing the performance of object recognition systems," </title> <booktitle> in Proceedings of the Second IEEE International Conference on Image Processing, </booktitle> <address> (Washington D. C.), </address> <pages> pp. 311-315, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: One way to compare the saliency of features is by using the single probability of error criterion. This technique computes the probability of error separately for each individual feature. These errors are then used to rank the features and select a subset of them. In <ref> [40] </ref>, object recognition was performed using Zernike moments to represent the shapes of the object. Five different neural network classifiers were tested for this application, with the aim of comparing and evaluating their classification performances.
Reference: [41] <author> S. Haykin, </author> <title> Neural Networks: A Comprehensive Foundation. </title> <publisher> MacMillan, </publisher> <year> 1994. </year>
Reference-contexts: Five different neural network classifiers were tested for this application, with the aim of comparing and evaluating their classification performances. These neural networks were a perceptron, a two-layer perceptron and the three-layer perceptron ART-2; an adaptive resonance theory based network; and a Kohonen associative memory <ref> [41] </ref>. The data set consisted of images of 6 tactical vehicles viewed from varying distances and angles and under conditions of noise and occlusions. Each object was represented by a vector of 23 features. For this application the multilayer perceptron with 2 hidden layers gave the best results.
Reference: [42] <author> T. Kohonen, </author> <title> Self-Organization and Associative Memory. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1988. </year>
Reference: [43] <author> S. V. Chakravarthy, J. Ghosh, and S. Jaikumar, </author> <title> "Aspect graph construction using a neural network of radial basis functions," </title> <booktitle> in Proc. ANNIE 91, </booktitle> <pages> pp. 465-472, </pages> <month> Nov </month> <year> 1991. </year>
Reference-contexts: Since each CV can be indicated by a binary vector with "1" for observable edges or faces and "0" for hidden ones, an object can be described as a mapping from (view angle, distance) to the CV vectors. In <ref> [43] </ref>, an Radial Basis Function (RBF) network was used to learn this mapping and then predict the CV from a given view angle or to propose a view angle for a given CV.
Reference: [44] <author> M. Seibert and A. Waxman, </author> <title> "Adaptive 3D object recognition from multiple views," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 11, no. 3, </volume> <pages> pp. 107-124, </pages> <year> 1987. </year>
Reference-contexts: In [43], an Radial Basis Function (RBF) network was used to learn this mapping and then predict the CV from a given view angle or to propose a view angle for a given CV. Clustering techniques: are used in <ref> [44] </ref> to self-organize aspect graph representations of 3D objects from 2D view sequences.
Reference: [45] <author> J. S. Beis and D. G. Lowe, </author> <title> "Learning indexing functions for 3D model-based object recognition," </title> <booktitle> Proceedings IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 275-280, </pages> <year> 1994. </year>
Reference-contexts: In a number of approaches, the indexing technique is viewed as obtaining indexing functions that associate each index vector from an image to some kind of probability measure with each of the indexed matches. One such method is presented in <ref> [45] </ref>, where indexing functions are introduced to estimate these probabilities. In [45], Radial Basis Functions (RBFs) are used to learn these functions. One advantage of using RBFs is that they smoothly interpolate between training examples (to fill in sections of the viewing sphere where no views exist). <p> One such method is presented in <ref> [45] </ref>, where indexing functions are introduced to estimate these probabilities. In [45], Radial Basis Functions (RBFs) are used to learn these functions. One advantage of using RBFs is that they smoothly interpolate between training examples (to fill in sections of the viewing sphere where no views exist).
Reference: [46] <author> B. Pravin and G. Medioni, </author> <title> "A constraint satisfaction network for matching 3D object," </title> <booktitle> in International Joint Conference on Artificial Intelligence, </booktitle> <volume> vol. II, </volume> <pages> pp. 18-22, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: This may be posed as a graph matching problem, which in turn, is often formulated as an optimization problem where an energy function is minimized. In <ref> [46] </ref>, a Hopfield network realizes a constraint satisfaction process to match visible surfaces to 3D objects. In [47], object recognition is posed an inexact graph matching problem and then formulated in terms of constrained optimization.
Reference: [47] <author> E. Mjolsness, E. Gindi, and P. Anandan, </author> <title> "Optimization in model matching and perceptual organization," </title> <journal> Neural Computation, </journal> <volume> vol. 1, </volume> <pages> pp. 218-219, </pages> <year> 1989. </year>
Reference-contexts: This may be posed as a graph matching problem, which in turn, is often formulated as an optimization problem where an energy function is minimized. In [46], a Hopfield network realizes a constraint satisfaction process to match visible surfaces to 3D objects. In <ref> [47] </ref>, object recognition is posed an inexact graph matching problem and then formulated in terms of constrained optimization. In [48] the problem of constraint satisfaction in computer vision is mapped to a network where the nodes are the hypotheses and the links are the constraints.
Reference: [48] <author> R. Mohan, </author> <title> "Application of neural constraint satisfaction network to vision," </title> <booktitle> in International Joint Conference on Artificial Intelligence, </booktitle> <volume> vol. II, </volume> <pages> pp. 619-620, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: In [46], a Hopfield network realizes a constraint satisfaction process to match visible surfaces to 3D objects. In [47], object recognition is posed an inexact graph matching problem and then formulated in terms of constrained optimization. In <ref> [48] </ref> the problem of constraint satisfaction in computer vision is mapped to a network where the nodes are the hypotheses and the links are the constraints. The network is then employed to select the optimal subset of hypotheses which satisfy the given constraints.
Reference: [49] <author> W. Lin, F. Liao, C. Tsao, and T. Lingutla, </author> <title> "A hierarchical multiple-view approach to three-dimensional object recognition," </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 2, no. 1, </volume> <pages> pp. 84-92, </pages> <year> 1991. </year>
Reference-contexts: The network is then employed to select the optimal subset of hypotheses which satisfy the given constraints. To convey the flavor of such optimization frameworks, we consider here the hierarchical approach of <ref> [49] </ref>, where Hopfield networks are used to recognize objects at two levels: (a) coarse recognition, which is based on the surfaces of the objects, and (b) fine recognition, which is done by determining the correspondences between vertexes in the image and the model.
Reference: [50] <author> A. Wong, </author> <title> "Knowledge representation for robot vision and path planning using attributed graphs and hypergraphs," </title> <booktitle> in Machine Intelligence and Knowledge Engineering for Robotics Applications, Proc. </booktitle> <editor> NATO/ASI Workshop (A. Wong and A. Pugh, </editor> <booktitle> eds.), </booktitle> <pages> pp. 113-143, </pages> <publisher> Springer Verlag, </publisher> <year> 1987. </year>
Reference-contexts: Several KBOR systems were developed during the 1980s and 1990s <ref> [50, 51, 52, 53] </ref>. In most of these systems, the knowledge-based paradigm has helped to perform complex and heuristic tasks in a logical and understandable manner. Figure 3 shows some popular approaches taken by KBOR systems, which provide some of the following advantages: 1.
Reference: [51] <author> J. T. Tou, </author> <title> "Knowledge-based systems for robotic application," </title> <booktitle> in Machine Intelligence and Knowledge Engineering for Robotics Applications, Proc. </booktitle> <editor> NATO/ASI Workshop (A. Wong and A. Pugh, </editor> <booktitle> eds.), </booktitle> <pages> pp. 145-189, </pages> <publisher> Springer Verlag, </publisher> <year> 1987. </year>
Reference-contexts: Several KBOR systems were developed during the 1980s and 1990s <ref> [50, 51, 52, 53] </ref>. In most of these systems, the knowledge-based paradigm has helped to perform complex and heuristic tasks in a logical and understandable manner. Figure 3 shows some popular approaches taken by KBOR systems, which provide some of the following advantages: 1.
Reference: [52] <author> M. De Mathelin, C. Perneel, and M. Acheroy, "IRES: </author> <title> an expert system for automatic target recognition from short-distance infrared images," in Proceedings of SPIE, Architecture, Hardware, and Forward-Looking Infrared Issues in Automatic Object Recognition (L. </title> <editor> Garn and L. Graceffo, eds.), </editor> <volume> vol. </volume> <year> 1957, </year> <pages> pp. 68-84, </pages> <year> 1993. </year>
Reference-contexts: Several KBOR systems were developed during the 1980s and 1990s <ref> [50, 51, 52, 53] </ref>. In most of these systems, the knowledge-based paradigm has helped to perform complex and heuristic tasks in a logical and understandable manner. Figure 3 shows some popular approaches taken by KBOR systems, which provide some of the following advantages: 1.
Reference: [53] <author> E. Riseman and A. Hanson, </author> <title> "A methodology for the development of general knowledge--based vision system," in Computer vision: theory and Industrial Applications (C. </title> <publisher> Tor-ras, ed.), </publisher> <pages> pp. 293-336, </pages> <publisher> Springer Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Several KBOR systems were developed during the 1980s and 1990s <ref> [50, 51, 52, 53] </ref>. In most of these systems, the knowledge-based paradigm has helped to perform complex and heuristic tasks in a logical and understandable manner. Figure 3 shows some popular approaches taken by KBOR systems, which provide some of the following advantages: 1.
Reference: [54] <author> W. Shomar, G. Seetharaman, and T. Young, </author> <title> "An expert system for recovering 3D shape and orientation from a single view," in Computer vision and image processing (L. </title> <editor> Shapiro and A. Rosenfeld, </editor> <booktitle> eds.), </booktitle> <pages> pp. 459-516, </pages> <publisher> Academic press, </publisher> <year> 1992. </year>
Reference-contexts: summarizes three object recognition systems that use a knowledge-based paradigm, specifically the expert system paradigm, as an integral part. 3D Shape and Orientation Recovery: Shomar et al. have implemented an object recognition system that depends on an expert system to perform 3D shape recovery and orientation from a single view <ref> [54] </ref>. This system has two main modules: an expert system module and a graphics display module. The system uses some geometric regularity assumptions about perceived objects and image formation to recognize the objects from 2D images.
Reference: [55] <author> C. Chu and J. K. Aggarwal, </author> <title> "The interpretation of a laser radar images by a knowledge-based system," </title> <booktitle> Machine Vision and application, </booktitle> <volume> vol. 4, </volume> <pages> pp. 145-163, </pages> <year> 1995. </year>
Reference-contexts: The key to the success of this system lies in constraining the domain to geometrical and unoccluded shapes. Regularities in this limited environment are then exploited to limit the search space. A KB system for Image Interpretation: Chu and Aggarwal <ref> [55] </ref> developed a knowledge-based multi-sensor image interpretation system using KEE, an expert system shell development package. The AIMS (Automatic Interpretation using Multiple Sensors) system has three main building blocks. 1.
Reference: [56] <author> C. Chu and J. K. Aggarwal, </author> <title> "The integration of image segmentation maps using region and edge information," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 15, no. 12, </volume> <pages> pp. 1241-1252, </pages> <year> 1993. </year>
Reference-contexts: The AIMS (Automatic Interpretation using Multiple Sensors) system has three main building blocks. 1. A segmentation module that integrates segmentation information from thermal, range, intensity, and velocity images and combines them into an integrated segmentation map <ref> [56] </ref>. 2. A representation module where the outcome of the segmentation module is represented in a structured knowledge-based format that can be utilized by the KEE package. 3. An interpretation module that uses KEE and supplementary LISP procedures in a bottom-up manner to recognize different objects in an image.
Reference: [57] <author> T. Matsuyama and V. Hwang, </author> <title> SIGMA: A knowledge-based aerial image understanding system. </title> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: However, the domain is again specialized, in this case to identify military objects from ground objects. SIGMA: Matsuyama and Hwang have developed an image understanding system called SIGMA, which is a knowledge-based aerial image understanding system <ref> [57] </ref>. SIGMA uses expert systems in three different modules. 1. A geometric reasoning expert which extracts geometric structures and spatial relations among objects and represents them in a symbolic hierarchical knowledge.
Reference: [58] <author> V. Cherkassky, J. Friedman, and H. W. (Eds.), </author> <title> From Statistics to Neural Networks, </title> <booktitle> Proc. NATO/ASI Workshop. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: We now touch upon some areas of research that the authors believe are important and will influence the design of object recognition systems in the future. 5.1 Bayesian Methods and Neural Networks Bayesian methods and neural networks share several similarities [16] <ref> [58] </ref> [59]. Both methods generate models that closely fit the data. Many popular artificial neural networks are essentially nonlinear parametric or semi-parametric estimators that are based on general and powerful functional forms such as a linear combination of sigmoidal or radial basis functions.
Reference: [59] <author> I. Sethi and A. Jain, eds., </author> <title> Artificial Neural Networks and Statistical Pattern Recognition. </title> <publisher> Elsevier Science, </publisher> <address> Amsterdam, </address> <year> 1991. </year>
Reference-contexts: We now touch upon some areas of research that the authors believe are important and will influence the design of object recognition systems in the future. 5.1 Bayesian Methods and Neural Networks Bayesian methods and neural networks share several similarities [16] [58] <ref> [59] </ref>. Both methods generate models that closely fit the data. Many popular artificial neural networks are essentially nonlinear parametric or semi-parametric estimators that are based on general and powerful functional forms such as a linear combination of sigmoidal or radial basis functions.
Reference: [60] <author> I. Taha and J. Ghosh, </author> <title> "A hybrid intelligent architecture for refining input characterization and domain knowledge," </title> <booktitle> in Proceedings of World Congress on Neural Networks, </booktitle> <volume> vol. II, </volume> <pages> pp. 284-287, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: Two popular methods of combining are presented in <ref> [60] </ref>. In one, an expert system is used to initialize a neural network. In this initialization, antecedents of rules are mapped into input and hidden nodes, certainty factors determine initial weights, while rule consequences are mapped into output nodes. <p> This information is provided from the Bayesian system at different levels. Recognition using relative spatial information of the parts as obtained using the Expert system is then used to inject all previously learned hypotheses into a neural network architecture, as described in <ref> [60] </ref>. 6 Conclusions In this paper, we present a comparative study of object recognition methods from three different paradigms: Bayesian, Neural Network and Expert Systems. Since object recognition is a difficult problem, a wide range of approaches, spanning across different theoretical paradigms, have been proposed and applied with limited success.
Reference: [61] <author> U. Grenander, </author> <title> General Pattern Theory. </title> <publisher> Oxford Univ. Press, </publisher> <year> 1994. </year>
Reference-contexts: Extracted rules can also be used to validate the connectionist networks' output decisions. 5.3 Pattern Theory: A Unifying Framework The statistical framework of pattern theory provides mathematical representations of subject-matter knowledge that can serve as a basis for the algorithmic understanding of images <ref> [61] </ref> [62]. This powerful theory uses a modified Bayesian approach for hypothesis formation that is capable of the creation or annihilation of hypotheses by jumps from one continuum to another in configuration (hypothesis) space.
Reference: [62] <author> U. Grenander and M. I. Miller, </author> <title> "Representations of knowledge in complex systems," </title> <journal> Jl. of the Royal Statistical Society Series B, </journal> <volume> vol. 56, no. 4, </volume> <pages> pp. 549-603, </pages> <year> 1994. </year>
Reference-contexts: Extracted rules can also be used to validate the connectionist networks' output decisions. 5.3 Pattern Theory: A Unifying Framework The statistical framework of pattern theory provides mathematical representations of subject-matter knowledge that can serve as a basis for the algorithmic understanding of images [61] <ref> [62] </ref>. This powerful theory uses a modified Bayesian approach for hypothesis formation that is capable of the creation or annihilation of hypotheses by jumps from one continuum to another in configuration (hypothesis) space. <p> Thus it provides a common language for both Bayesian and rule-based reasoning. Pattern theoretic approaches have met with success in a number of applications, from describing mitochondria ensembles to multi-target recognition and tracking <ref> [62] </ref> [63].
Reference: [63] <author> M. I. Miller, A. Srivastava, and U. Grenander, </author> <title> "Conditional-mean estimation via jump-diffusion processes in multiple target tracking/recognition," </title> <journal> IEEE Trans. Signal Processing, </journal> <volume> vol. 43, </volume> <pages> pp. 1-13, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: Thus it provides a common language for both Bayesian and rule-based reasoning. Pattern theoretic approaches have met with success in a number of applications, from describing mitochondria ensembles to multi-target recognition and tracking [62] <ref> [63] </ref>.
Reference: [64] <author> D. B. Mumford, </author> <title> "Pattern theory: a unifying perspective," </title> <booktitle> in Proc. 1st European Congress of Mathematics, </booktitle> <year> 1994. </year>
Reference-contexts: Pattern theoretic approaches have met with success in a number of applications, from describing mitochondria ensembles to multi-target recognition and tracking [62] [63]. Moreover, mixed Markov models inspired by this theory are being suggested as basic tools in object recognition <ref> [64] </ref>. 5.4 Combining all three paradigms: An illustration To illustrate how all three paradigms can be tightly integrated, we briefly describe an ongoing project in which supplementary information from each sub-system helps to guide the working of the other, as exemplified by figure 4.
Reference: [65] <author> I. Biederman, </author> <title> "Human image understanding: Recent research and a theory," Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> vol. 32, </volume> <pages> pp. 29-73, </pages> <year> 1985. </year>
Reference-contexts: In this paper we have briefly addressed issues on how this may be done. Even with the advance of technology and sophistication of object recognition algorithms, object recognition systems of today are still really limited when compared with human performance. Humans can recognize about 10,000 distinct objects <ref> [65] </ref> under varying conditions, while a state of the art object recognition system can recognize relatively a few objects and certainly are nowhere near the breadth and depth of the human performance.
References-found: 65

