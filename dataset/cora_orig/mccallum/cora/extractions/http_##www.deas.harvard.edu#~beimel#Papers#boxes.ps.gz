URL: http://www.deas.harvard.edu/~beimel/Papers/boxes.ps.gz
Refering-URL: http://www.deas.harvard.edu/~beimel/pub.html
Root-URL: 
Title: Learning Boxes in High Dimension  
Author: Amos Beimel Eyal Kushilevitz 
Keyword: Key words: Boxes, Discrete Geometric Objects, Decision Trees, Exact Learning, Multiplicity Automata, Hankel Matrices.  
Address: P.O. Box 1179, Piscataway, NJ 08855.  32000, Israel.  
Affiliation: Center, Rutgers University,  Technion. Dept. of Computer Science, Technion, Haifa  
Note: DIMACS  Part of this research was done while the author was a Ph.D. student at the  Phone: +972-4-8294303. Fax: +972-4-8221128. This research was supported by Technion V.P.R. Fund 120-872 and by Japan Technion Society Research Fund.  
Email: E-mail: beimel@dimacs.rutgers.edu. http://dimacs.rutgers.edu/~beimel.  E-mail: eyalk@cs.technion.ac.il.  
Phone: Phone: (908) 445-4575. Fax: (908) 445-5932.  
Web: http://www.cs.technion.ac.il/~eyalk.  
Date: April 21, 1998  
Abstract: We present exact learning algorithms that learn several classes of (discrete) boxes in f0; : : :; ` 1g n . In particular we learn: (1) The class of unions of O(log n) boxes in time poly(n; log `) (solving an open problem of [16, 12]; in [3] this class is shown to be learnable in time poly(n; `)). (2) The class of unions of disjoint boxes in time poly(n; t; log `), where t is the number of boxes. (Previously this was known only in the case where all boxes are disjoint in one of the dimensions; in [3] this class is shown to be learnable in time poly(n; t; `)). In particular our algorithm learns the class of decision trees over n variables, that take values in f0; : : :; ` 1g, with comparison nodes in time poly(n; t; log `), where t is the number of leaves (this was an open problem in [9] which was shown in [4] to be learnable in time poly(n; t; `)). (3) The class of unions of O(1)-degenerate boxes (that is, boxes that depend only on O(1) variables) in time poly(n; t; log `) (generalizing the learnability of O(1)-DNF and of boxes in O(1) dimensions). The algorithm for this class uses only equivalence queries and it can also be used to learn the class of unions of O(1) boxes (from equivalence queries only). fl A preliminary version of this paper appeared in the proceedings of the EuroCOLT '97 conference, published in volume 1208 of Lecture Notes in Artificial Intelligence, pages 3-15. Springer-Verlag, 1997. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Angluin. </author> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 319-342, </pages> <year> 1988. </year>
Reference-contexts: This conversion uses specific properties of the poly (n; t; `) algorithm. 2 Preliminaries 2.1 The Learning Model The learning model we use is the exact learning model <ref> [1] </ref>: Let C be a class of functions and f 2 C be a target function. A learning algorithm may propose, in each step, a hypothesis function h by making an equivalence query (EQ) to an oracle.
Reference: [2] <author> P. Auer. </author> <title> On-line learning of rectangles in noisy environments. </title> <booktitle> In Proc. of 6th Annu. ACM Conf. on Comput. Learning Theory, </booktitle> <pages> pages 253-261, </pages> <year> 1993. </year>
Reference-contexts: A particular attention was given to the case of discrete domains of points (i.e., f0; : : : ; ` 1g n ) and concept classes which are defined as unions of boxes in this domain (e.g., <ref> [22, 23, 15, 2, 16, 17, 24] </ref>). One of the reasons that unions of boxes seem to be interesting concepts is that they naturally extend DNF formulae (in other words, in the case ` = 2 any union of t boxes is equivalent to a DNF formula with t-terms).
Reference: [3] <author> A. Beimel, F. Bergadano, N. H. Bshouty, E. Kushilevitz, and S. Varricchio. </author> <title> Learning functions represented as multiplicity automata. </title> <note> Submitted for publication, </note> <year> 1997. </year> <title> Preliminary version: </title> <booktitle> On the applications of multiplicity automata in learning. In Proc. of 37th Annu. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 349-358, </pages> <year> 1996. </year>
Reference-contexts: In particular we show: 1. The class of all unions of O (log n) boxes can be learned in time poly (n; log `) (solving an open problem of [16, 12]; in <ref> [3] </ref> this class is shown to be learnable in time poly (n; `)). This generalizes a similar result for the class of O (log n)-term DNF [7, 9, 10, 19, 4]. 2. <p> The class of all unions of disjoint boxes (and, more generally, unions of boxes in which each point belongs to at most O (1) boxes) can be learned in time poly (n; t; log `), where t is the number of boxes (in <ref> [3] </ref> this class is shown to be learnable in time poly (n; t; `)). <p> The first two results are obtained in two steps: First, in Section 3, we show how to learn these classes but with complexity which is polynomial in ` (and the other parameters of the problem). This result appears in <ref> [3] </ref> and is a straightforward generalization of results in [4]. It is included in this paper for sake of completeness. <p> Our starting point is a recent algorithm of <ref> [4, 3] </ref> for learning multiplicity automata. In [3] it is shown that this algorithm can be used to learn disj-box t and box O (log n) in time polynomial in ` and the other parameters of the problem (this is a straightforward generalization of results in [4]). <p> Our starting point is a recent algorithm of [4, 3] for learning multiplicity automata. In <ref> [3] </ref> it is shown that this algorithm can be used to learn disj-box t and box O (log n) in time polynomial in ` and the other parameters of the problem (this is a straightforward generalization of results in [4]). <p> For sake of completeness we prove this result in this section. In addition, in the Appendix we briefly sketch the algorithm of <ref> [4, 3] </ref>. Then, in the next section, we show how to reduce the complexity to be polynomial in log `. We start with some notations. Let K be a field, be an alphabet, and f : n ! K be a function.
Reference: [4] <author> A. Beimel, F. Bergadano, N. H. Bshouty, E. Kushilevitz, and S. Varricchio. </author> <title> On the applications of multiplicity automata in learning. </title> <booktitle> In Proc. of the 37th Annu. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 349-358, </pages> <year> 1996. </year> <month> 16 </month>
Reference-contexts: Again, this sub-class is learnable in the PAC model [21] and in the on-line model [24]. In this work we generalize some of the state-of-the-art results in exact learning of DNF formulae <ref> [6, 4] </ref>, hence strengthening several results in direction (2) above. In particular we show: 1. <p> This generalizes a similar result for the class of O (log n)-term DNF <ref> [7, 9, 10, 19, 4] </ref>. 2. <p> This generalizes similar results for learning disjoint DNF and satisfy-O (1) DNF <ref> [6, 4] </ref>. (Previously such a result was known only in the case where all boxes are disjoint in one of the dimensions [11, 14]; in 2 this case in fact equivalence queries are sufficient.) In particular our algorithm learns the class of decision trees with comparison nodes in time poly (n; <p> 14]; in 2 this case in fact equivalence queries are sufficient.) In particular our algorithm learns the class of decision trees with comparison nodes in time poly (n; t; log `), where t is the number of leaves (the learnability of this class was an open problem in [9]; in <ref> [4] </ref> it was shown that this class is learnable in time poly (n; t; `)). 3. <p> The first two results are obtained in two steps: First, in Section 3, we show how to learn these classes but with complexity which is polynomial in ` (and the other parameters of the problem). This result appears in [3] and is a straightforward generalization of results in <ref> [4] </ref>. It is included in this paper for sake of completeness. Then, in Section 4, we prove the main result of this paper: we show how to (adaptively) select a "small" subset of the domain f0; 1; : : : ; ` 1g which is sufficient for the learning. <p> Our starting point is a recent algorithm of <ref> [4, 3] </ref> for learning multiplicity automata. In [3] it is shown that this algorithm can be used to learn disj-box t and box O (log n) in time polynomial in ` and the other parameters of the problem (this is a straightforward generalization of results in [4]). <p> In [3] it is shown that this algorithm can be used to learn disj-box t and box O (log n) in time polynomial in ` and the other parameters of the problem (this is a straightforward generalization of results in <ref> [4] </ref>). For sake of completeness we prove this result in this section. In addition, in the Appendix we briefly sketch the algorithm of [4, 3]. Then, in the next section, we show how to reduce the complexity to be polynomial in log `. We start with some notations. <p> For sake of completeness we prove this result in this section. In addition, in the Appendix we briefly sketch the algorithm of <ref> [4, 3] </ref>. Then, in the next section, we show how to reduce the complexity to be polynomial in log `. We start with some notations. Let K be a field, be an alphabet, and f : n ! K be a function. <p> The learnability of this class was an open problem in [9]. In <ref> [4] </ref> it was shown that this class is learnable in time poly (n; t; `) (where t here denotes the number of leaves in the tree corresponding to f ). Algorithm learn sensitive shows that this class can in fact be learned in time poly (n; t; log `). <p> Also, Theorem 4.3 can be extended to learning decision trees of depth O (log n), where each node contains a boolean query of the form "does x belong to a box B?" (for this result 10 we can use Corollary 4.11 from <ref> [4] </ref> to learn f L , and slightly generalize Lemma 4.2). In particular this shows the learnability of any function of O (log n) boxes, and not only unions of boxes.
Reference: [5] <author> S. Ben-David, N. H. Bshouty, and E. Kushilevitz. </author> <title> A composition theorem for learning algorithms with applications to geometric concept classes. </title> <booktitle> In Proc. of the 29th Annu. ACM Symp. on the Theory of Computing, </booktitle> <pages> pages 324-333, </pages> <year> 1997. </year>
Reference-contexts: 1 Introduction The learnability (under various learning models) of geometric concept classes was studied in many papers (e.g., <ref> [8, 11, 13, 5] </ref>). A particular attention was given to the case of discrete domains of points (i.e., f0; : : : ; ` 1g n ) and concept classes which are defined as unions of boxes in this domain (e.g., [22, 23, 15, 2, 16, 17, 24]). <p> There are two main directions: (1) Sub-classes in which the number of dimensions, n, is limited to O (1). In this case unions of boxes (and more general geometric concept classes) are known to be learnable in the PAC model [13] and even in the weaker online model <ref> [5] </ref>. (2) Sub-classes in which the number of boxes in the union is limited to O (1) (but the number of dimensions in not restricted). Again, this sub-class is learnable in the PAC model [21] and in the on-line model [24].
Reference: [6] <author> F. Bergadano, D. Catalano, and S. Varricchio. </author> <title> Learning sat-k-DNF formulas from membership queries. </title> <booktitle> In Proc. of the 28th Annu. ACM Symp. on the Theory of Computing, </booktitle> <pages> pages 126-130, </pages> <year> 1996. </year>
Reference-contexts: Again, this sub-class is learnable in the PAC model [21] and in the on-line model [24]. In this work we generalize some of the state-of-the-art results in exact learning of DNF formulae <ref> [6, 4] </ref>, hence strengthening several results in direction (2) above. In particular we show: 1. <p> This generalizes similar results for learning disjoint DNF and satisfy-O (1) DNF <ref> [6, 4] </ref>. (Previously such a result was known only in the case where all boxes are disjoint in one of the dimensions [11, 14]; in 2 this case in fact equivalence queries are sufficient.) In particular our algorithm learns the class of decision trees with comparison nodes in time poly (n;
Reference: [7] <author> A. Blum and S. Rudich. </author> <title> Fast learning of k-term DNF formulas with queries. </title> <journal> J. of Computer and System Sciences, </journal> <volume> 51(3) </volume> <pages> 367-373, </pages> <year> 1995. </year>
Reference-contexts: This generalizes a similar result for the class of O (log n)-term DNF <ref> [7, 9, 10, 19, 4] </ref>. 2.
Reference: [8] <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. </author> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> J. of the ACM, </journal> <volume> 36 </volume> <pages> 929-965, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction The learnability (under various learning models) of geometric concept classes was studied in many papers (e.g., <ref> [8, 11, 13, 5] </ref>). A particular attention was given to the case of discrete domains of points (i.e., f0; : : : ; ` 1g n ) and concept classes which are defined as unions of boxes in this domain (e.g., [22, 23, 15, 2, 16, 17, 24]).
Reference: [9] <author> N. H. Bshouty. </author> <title> Exact learning via the monotone theory. </title> <booktitle> In Proc. of the 34th Annu. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 302-311, </pages> <year> 1993. </year> <title> Journal version: </title> <journal> Information and Computation, </journal> <volume> 123(1) </volume> <pages> 146-153, </pages> <year> 1995. </year>
Reference-contexts: This generalizes a similar result for the class of O (log n)-term DNF <ref> [7, 9, 10, 19, 4] </ref>. 2. <p> dimensions [11, 14]; in 2 this case in fact equivalence queries are sufficient.) In particular our algorithm learns the class of decision trees with comparison nodes in time poly (n; t; log `), where t is the number of leaves (the learnability of this class was an open problem in <ref> [9] </ref>; in [4] it was shown that this class is learnable in time poly (n; t; `)). 3. <p> The learnability of this class was an open problem in <ref> [9] </ref>. In [4] it was shown that this class is learnable in time poly (n; t; `) (where t here denotes the number of leaves in the tree corresponding to f ).
Reference: [10] <author> N. H. Bshouty. </author> <title> Simple learning algorithms using divide and conquer. </title> <booktitle> In Proc. of 8th Annu. ACM Conf. on Comput. Learning Theory, </booktitle> <pages> pages 447-453, </pages> <year> 1995. </year>
Reference-contexts: This generalizes a similar result for the class of O (log n)-term DNF <ref> [7, 9, 10, 19, 4] </ref>. 2.
Reference: [11] <author> N. H. Bshouty, Z. Chen, and S. Homer. </author> <title> On learning discretized geometric concepts. </title> <booktitle> In Proc. of the 35th Annu. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 54-63, </pages> <year> 1994. </year>
Reference-contexts: 1 Introduction The learnability (under various learning models) of geometric concept classes was studied in many papers (e.g., <ref> [8, 11, 13, 5] </ref>). A particular attention was given to the case of discrete domains of points (i.e., f0; : : : ; ` 1g n ) and concept classes which are defined as unions of boxes in this domain (e.g., [22, 23, 15, 2, 16, 17, 24]). <p> This generalizes similar results for learning disjoint DNF and satisfy-O (1) DNF [6, 4]. (Previously such a result was known only in the case where all boxes are disjoint in one of the dimensions <ref> [11, 14] </ref>; in 2 this case in fact equivalence queries are sufficient.) In particular our algorithm learns the class of decision trees with comparison nodes in time poly (n; t; log `), where t is the number of leaves (the learnability of this class was an open problem in [9]; in <p> All together, algorithm learn sensitive learns the class box O (log n) in time poly (n; log `). The above theorem solves an open problem of [16, 12]. The following theorem shows the learnability of disjoint boxes in time poly (n; t; log `). This significantly improves over <ref> [11, 14] </ref> where a similar result was shown for the case where there exists a dimension in which all the boxes are disjoint. Theorem 4.4 The class disj-box can be learned in time poly (n; t; log `) (where t is the number of boxes in the target function). <p> The second problem that we face is how to search for a sensitive letter without using membership queries. We use an idea of <ref> [11, 12] </ref>: if there is a sensitive letter in a set fa; a + 1; : : : ; bg where a and b are in L then add (a + b)=2 to L (if (a + b)=2 is not an integer then add (a + b 1)=2).
Reference: [12] <author> N. H. Bshouty, P. W. Goldberg, S. A. Goldman, and H. D. Mathias. </author> <title> Exact learning of discretized geometric concepts. </title> <type> Technical Report WUCS-94-19, </type> <institution> Washing-ton University, </institution> <year> 1994. </year>
Reference-contexts: In particular we show: 1. The class of all unions of O (log n) boxes can be learned in time poly (n; log `) (solving an open problem of <ref> [16, 12] </ref>; in [3] this class is shown to be learnable in time poly (n; `)). This generalizes a similar result for the class of O (log n)-term DNF [7, 9, 10, 19, 4]. 2. <p> All together, algorithm learn sensitive learns the class box O (log n) in time poly (n; log `). The above theorem solves an open problem of <ref> [16, 12] </ref>. The following theorem shows the learnability of disjoint boxes in time poly (n; t; log `). This significantly improves over [11, 14] where a similar result was shown for the case where there exists a dimension in which all the boxes are disjoint. <p> The second problem that we face is how to search for a sensitive letter without using membership queries. We use an idea of <ref> [11, 12] </ref>: if there is a sensitive letter in a set fa; a + 1; : : : ; bg where a and b are in L then add (a + b)=2 to L (if (a + b)=2 is not an integer then add (a + b 1)=2).
Reference: [13] <author> N. H. Bshouty, S. A. Goldman, H. D. Mathias, S. Suri, and H. Tamaki. </author> <title> Noise-tolerant distribution-free learning of general geometric concepts. </title> <booktitle> In Proc. of the 28th Annu. ACM Symp. on the Theory of Computing, </booktitle> <pages> pages 151-160, </pages> <year> 1996. </year>
Reference-contexts: 1 Introduction The learnability (under various learning models) of geometric concept classes was studied in many papers (e.g., <ref> [8, 11, 13, 5] </ref>). A particular attention was given to the case of discrete domains of points (i.e., f0; : : : ; ` 1g n ) and concept classes which are defined as unions of boxes in this domain (e.g., [22, 23, 15, 2, 16, 17, 24]). <p> There are two main directions: (1) Sub-classes in which the number of dimensions, n, is limited to O (1). In this case unions of boxes (and more general geometric concept classes) are known to be learnable in the PAC model <ref> [13] </ref> and even in the weaker online model [5]. (2) Sub-classes in which the number of boxes in the union is limited to O (1) (but the number of dimensions in not restricted). Again, this sub-class is learnable in the PAC model [21] and in the on-line model [24].
Reference: [14] <author> Z. Chen and S. Homer. </author> <title> The bounded injury priority method and the learnability of unions of rectangles. </title> <journal> Annals of Pure and Applied Logic, </journal> <volume> 77(2) </volume> <pages> 143-168, </pages> <year> 1996. </year>
Reference-contexts: This generalizes similar results for learning disjoint DNF and satisfy-O (1) DNF [6, 4]. (Previously such a result was known only in the case where all boxes are disjoint in one of the dimensions <ref> [11, 14] </ref>; in 2 this case in fact equivalence queries are sufficient.) In particular our algorithm learns the class of decision trees with comparison nodes in time poly (n; t; log `), where t is the number of leaves (the learnability of this class was an open problem in [9]; in <p> All together, algorithm learn sensitive learns the class box O (log n) in time poly (n; log `). The above theorem solves an open problem of [16, 12]. The following theorem shows the learnability of disjoint boxes in time poly (n; t; log `). This significantly improves over <ref> [11, 14] </ref> where a similar result was shown for the case where there exists a dimension in which all the boxes are disjoint. Theorem 4.4 The class disj-box can be learned in time poly (n; t; log `) (where t is the number of boxes in the target function).
Reference: [15] <author> Z. Chen and W. Maass. </author> <title> On-line learning of rectangles and unions of rectangles. </title> <journal> Machine Learning, </journal> 17(2/3):23-50, 1994. <volume> 17 </volume>
Reference-contexts: A particular attention was given to the case of discrete domains of points (i.e., f0; : : : ; ` 1g n ) and concept classes which are defined as unions of boxes in this domain (e.g., <ref> [22, 23, 15, 2, 16, 17, 24] </ref>). One of the reasons that unions of boxes seem to be interesting concepts is that they naturally extend DNF formulae (in other words, in the case ` = 2 any union of t boxes is equivalent to a DNF formula with t-terms). <p> Remark 5.6 Algorithm fast elimination can be used to learn the class of all unions of O (1) boxes with only equivalence queries. (This was an open problem in <ref> [15] </ref> that was later solved in [24].) The idea is that if we have a function that can be represented as a union of O (1) boxes, then its negation can be represented as a union of O (1)-degenerate boxes.
Reference: [16] <author> P. W. Goldberg, S. A. Goldman, and H. D. Mathias. </author> <title> Learning unions of boxes with membership and equivalence queries. </title> <booktitle> In Proc. of 7th Annu. ACM Conf. on Comput. Learning Theory, </booktitle> <year> 1994. </year>
Reference-contexts: A particular attention was given to the case of discrete domains of points (i.e., f0; : : : ; ` 1g n ) and concept classes which are defined as unions of boxes in this domain (e.g., <ref> [22, 23, 15, 2, 16, 17, 24] </ref>). One of the reasons that unions of boxes seem to be interesting concepts is that they naturally extend DNF formulae (in other words, in the case ` = 2 any union of t boxes is equivalent to a DNF formula with t-terms). <p> In particular we show: 1. The class of all unions of O (log n) boxes can be learned in time poly (n; log `) (solving an open problem of <ref> [16, 12] </ref>; in [3] this class is shown to be learnable in time poly (n; `)). This generalizes a similar result for the class of O (log n)-term DNF [7, 9, 10, 19, 4]. 2. <p> All together, algorithm learn sensitive learns the class box O (log n) in time poly (n; log `). The above theorem solves an open problem of <ref> [16, 12] </ref>. The following theorem shows the learnability of disjoint boxes in time poly (n; t; log `). This significantly improves over [11, 14] where a similar result was shown for the case where there exists a dimension in which all the boxes are disjoint.
Reference: [17] <author> J. C. Jackson. </author> <title> An efficient membership-query algorithm for learning DNF with respect to the uniform distribution. </title> <booktitle> In Proc. of the 35th Annu. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 42-53, </pages> <year> 1994. </year>
Reference-contexts: A particular attention was given to the case of discrete domains of points (i.e., f0; : : : ; ` 1g n ) and concept classes which are defined as unions of boxes in this domain (e.g., <ref> [22, 23, 15, 2, 16, 17, 24] </ref>). One of the reasons that unions of boxes seem to be interesting concepts is that they naturally extend DNF formulae (in other words, in the case ` = 2 any union of t boxes is equivalent to a DNF formula with t-terms). <p> In this case only equivalence queries are used, i.e. we learn this class in the on-line model [20]. This result generalizes the learnability of O (1)-DNF and of boxes in O (1) dimensions. The class of k-degenerate boxes was previously considered in <ref> [17, 18, 24] </ref>. Our algorithm for this class also learns the class of unions of O (1) boxes from equivalence queries only.
Reference: [18] <author> J. C. Jackson. </author> <title> The Harmonic Sieve: A Novel Application of Fourier Analysis to Machine Learning Theory and Practice. </title> <type> PhD thesis, Technical Report CMU-CS-95-184, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <year> 1995. </year>
Reference-contexts: In this case only equivalence queries are used, i.e. we learn this class in the on-line model [20]. This result generalizes the learnability of O (1)-DNF and of boxes in O (1) dimensions. The class of k-degenerate boxes was previously considered in <ref> [17, 18, 24] </ref>. Our algorithm for this class also learns the class of unions of O (1) boxes from equivalence queries only.
Reference: [19] <author> E. Kushilevitz. </author> <title> A simple algorithm for learning O(log n)-term DNF. </title> <journal> Information Processing Letters, </journal> <volume> 61(6) </volume> <pages> 289-292, </pages> <year> 1997. </year>
Reference-contexts: This generalizes a similar result for the class of O (log n)-term DNF <ref> [7, 9, 10, 19, 4] </ref>. 2. <p> Corollary 3.4 The class disj-box can be learned in time poly (n; t; `) (where t is the number of boxes in the target functions). In <ref> [19] </ref> it is shown how to learn O (log n)-term DNF using deterministic automata. The algorithm of [19] can also be modified to learn the class box O (log n) in time poly (n; `), yielding a different proof for Corollary 3.3. 4 Reducing the Dependency on ` In this section <p> Corollary 3.4 The class disj-box can be learned in time poly (n; t; `) (where t is the number of boxes in the target functions). In <ref> [19] </ref> it is shown how to learn O (log n)-term DNF using deterministic automata. The algorithm of [19] can also be modified to learn the class box O (log n) in time poly (n; `), yielding a different proof for Corollary 3.3. 4 Reducing the Dependency on ` In this section we reduce the dependency of our algorithm on `.
Reference: [20] <author> N. Littlestone. </author> <title> Learning when irrelevant attributes abound: A new linear-threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: In this case only equivalence queries are used, i.e. we learn this class in the on-line model <ref> [20] </ref>. This result generalizes the learnability of O (1)-DNF and of boxes in O (1) dimensions. The class of k-degenerate boxes was previously considered in [17, 18, 24]. Our algorithm for this class also learns the class of unions of O (1) boxes from equivalence queries only. <p> We will sometimes restrict the learning algorithm to use equivalence queries only. This is equivalent to Littlestone's on-line model of learning <ref> [20] </ref>. 2.2 Classes of Boxes In this section we define the classes of boxes that we learn in this paper. We consider unions of n-dimensional boxes in [`] n (where [`] denotes the set f0; 1; : : : ; ` 1g).
Reference: [21] <author> P. M. Long and M. K. Warmuth. </author> <title> Composite geometric concepts and polynomial predictability. </title> <journal> Information and Computation, </journal> <volume> 113(2) </volume> <pages> 230-252, </pages> <year> 1994. </year>
Reference-contexts: Again, this sub-class is learnable in the PAC model <ref> [21] </ref> and in the on-line model [24]. In this work we generalize some of the state-of-the-art results in exact learning of DNF formulae [6, 4], hence strengthening several results in direction (2) above. In particular we show: 1.
Reference: [22] <author> W. Maass and G. Turan. </author> <title> On the complexity of learning from counterexamples. </title> <booktitle> In Proc. of the 30th Annu. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 262-273, </pages> <year> 1989. </year>
Reference-contexts: A particular attention was given to the case of discrete domains of points (i.e., f0; : : : ; ` 1g n ) and concept classes which are defined as unions of boxes in this domain (e.g., <ref> [22, 23, 15, 2, 16, 17, 24] </ref>). One of the reasons that unions of boxes seem to be interesting concepts is that they naturally extend DNF formulae (in other words, in the case ` = 2 any union of t boxes is equivalent to a DNF formula with t-terms).
Reference: [23] <author> W. Maass and G. Turan. </author> <title> Algorithms and lower bounds for on-line learning of geometrical concepts. </title> <journal> Machine Learning, </journal> <volume> 14:251 - 269, </volume> <year> 1994. </year>
Reference-contexts: A particular attention was given to the case of discrete domains of points (i.e., f0; : : : ; ` 1g n ) and concept classes which are defined as unions of boxes in this domain (e.g., <ref> [22, 23, 15, 2, 16, 17, 24] </ref>). One of the reasons that unions of boxes seem to be interesting concepts is that they naturally extend DNF formulae (in other words, in the case ` = 2 any union of t boxes is equivalent to a DNF formula with t-terms).
Reference: [24] <author> W. Maass and M. K. Warmuth. </author> <title> Efficient learning with virtual threshold gates. </title> <journal> Information and Computation, </journal> <volume> 141(1) </volume> <pages> 66-83, </pages> <year> 1998. </year>
Reference-contexts: A particular attention was given to the case of discrete domains of points (i.e., f0; : : : ; ` 1g n ) and concept classes which are defined as unions of boxes in this domain (e.g., <ref> [22, 23, 15, 2, 16, 17, 24] </ref>). One of the reasons that unions of boxes seem to be interesting concepts is that they naturally extend DNF formulae (in other words, in the case ` = 2 any union of t boxes is equivalent to a DNF formula with t-terms). <p> Again, this sub-class is learnable in the PAC model [21] and in the on-line model <ref> [24] </ref>. In this work we generalize some of the state-of-the-art results in exact learning of DNF formulae [6, 4], hence strengthening several results in direction (2) above. In particular we show: 1. <p> In this case only equivalence queries are used, i.e. we learn this class in the on-line model [20]. This result generalizes the learnability of O (1)-DNF and of boxes in O (1) dimensions. The class of k-degenerate boxes was previously considered in <ref> [17, 18, 24] </ref>. Our algorithm for this class also learns the class of unions of O (1) boxes from equivalence queries only. <p> Remark 5.6 Algorithm fast elimination can be used to learn the class of all unions of O (1) boxes with only equivalence queries. (This was an open problem in [15] that was later solved in <ref> [24] </ref>.) The idea is that if we have a function that can be represented as a union of O (1) boxes, then its negation can be represented as a union of O (1)-degenerate boxes.
Reference: [25] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <year> 1984. </year>
Reference-contexts: In Fig. 3 we describe a simple algorithm, eliminate boxes, which learns the class k dbox t 11 with complexity which is polynomial in `, for k = O (1). This algorithm is a variant of the standard elimination algorithm for learning k-DNF <ref> [25] </ref>. Algorithm eliminate boxes: 1. Make a list Q of all width one k-degenerate boxes. 2. Define a hypothesis h as the union of all boxes in the list Q. 3. Ask EQ (h). If the answer is "YES" halt with output h. 4.
References-found: 25

