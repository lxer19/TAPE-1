URL: http://www.cs.orst.edu:80/~tadepall/research/papers/speedup-learning.ps
Refering-URL: http://www.cs.orst.edu:80/~tadepall/research/publications.html
Root-URL: 
Email: tadepalli@cs.orst.edu  natarajan@hpl.hp.com  
Title: A Formal Framework for Speedup Learning from Problems and Solutions  
Author: Prasad Tadepalli Balas K. Natarajan 
Keyword: Explanation-Based Learning (EBL), and Probably Approximately Correct (PAC) Learning.  
Address: 303 Dearborn Hall,  Corvallis, OR 97331  1501 Page Mill Road, Bldg 3U Palo Alto, CA 94304  
Affiliation: Department of Computer Science  Oregon State University  Hewlett Packard Research Labs  
Note: Journal of Artificial Intelligence Research 4 (1996) 445-475 Submitted 11/95; published 6/96  
Abstract: Speedup learning seeks to improve the computational efficiency of problem solving with experience. In this paper, we develop a formal framework for learning efficient problem solving from random problems and their solutions. We apply this framework to two different representations of learned knowledge, namely control rules and macro-operators, and prove theorems that identify sufficient conditions for learning in each representation. Our proofs are constructive in that they are accompanied with learning algorithms. Our framework captures both empirical and explanation-based speedup learning in a unified fashion. We illustrate our framework with implementations in two domains: symbolic integration and Eight Puzzle. This work integrates many strands of experimental and theoretical work in machine learning, including empirical learning of control rules, macro-operator learning, 
Abstract-found: 1
Intro-found: 1
Reference: <author> Angluin, D. </author> <year> (1988). </year> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2 (4), </volume> <pages> 319-342. </pages>
Reference-contexts: Whenever a particular subproblem does not have a corresponding macro-operator in its table, it simply calls the "teacher" to solve it by search and stores the solution in its table. This is analogous to asking membership queries in one of Angluin's models of PAC learning <ref> (Angluin, 1988) </ref>. With this membership query model, it is no longer required that there is a problem solver in the learner's hypothesis space which is consistent with the teacher's solutions. There is also no guarantee that the learner and the teacher produce the same solutions on random problems. <p> This means that we have to extend our model to allow other kinds of information. For example, the learner might be allowed to pose its own problems to the teacher, a natural extension to the paradigm of membership queries <ref> (Angluin, 1988) </ref>. Reddy et al. (1996) report a speedup learning method that learns recursive decomposition rules for planning from examples and membership queries (Reddy, Tadepalli, & Roncagliolo, 1996). A decomposition rule recursively decomposes a goal into a number of subgoals and primitive actions.
Reference: <author> Anthony, M., & Biggs, N. </author> <year> (1992). </year> <title> Computational Learning Theory. </title> <publisher> Cambridge University Press, </publisher> <address> New York, NY. </address>
Reference: <author> Blumer, A., Ehrenfeucht, A., Haussler, D., & Warmuth, M. </author> <year> (1989). </year> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> Journal of the ACM, </journal> <volume> 36 (4), </volume> <pages> 929-965. </pages>
Reference-contexts: Before we prove theorems about particular hypotheses spaces, we first state a general theorem which is a direct consequence of the results in PAC-learning of finite hypothesis spaces <ref> (Blumer, Ehrenfeucht, Haussler, & Warmuth, 1989) </ref>. Theorem 1 Let M be a meta-domain, and F be a hypothesis space of polynomial-time problem solvers for domains in M. Let dim (F n ) be polynomially bounded in n.
Reference: <author> Bylander, T. </author> <year> (1992). </year> <title> Complexity results for serial decomposability. </title> <booktitle> In Proceedings of National Conference on Artificial Intelligence, </booktitle> <pages> pp. 729-734. </pages> <address> San Jose, CA. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Bylander (1992) shows that detecting serial decomposability without examples is NP-hard in general. The existence of macro-tables is only guaranteed if there is a unique goal state and the operator closure is satisfied. Checking these properties is, in general, PSPACE-hard <ref> (Bylander, 1992) </ref>. However, it may be easier 3. SOAR also makes the macro-table method applicable to any goal using another representational trick, i.e., by parameterizing the tiles rather than labeling them with fixed numbers. 4.
Reference: <author> Chalasani, P., Etzioni, O., & Mount, J. </author> <year> (1991). </year> <title> Detecting and exploiting decomposability in update graphs. </title> <booktitle> In 2nd International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pp. 89-98. </pages> <address> Cambridge, MA. </address>
Reference-contexts: We thank Prasad Chalasani for illustrating this. 468 A Formal Framework for Speedup Learning to check these properties under some conditions. For example, Chalasani et al. (1991) describe an algorithm that detects serial and total decomposability for permutation groups <ref> (Chalasani, Etzioni, & Mount, 1991) </ref>. If the operators are defined in STRIPS notation, it may sometimes be possible to check sufficient conditions for serial decomposability by constructing a graph of dependencies among the domain features and checking that it has no cycles.
Reference: <author> Cohen, W. </author> <year> (1992). </year> <title> Using distribution-free learning theory to analyze solution path caching mechanisms. </title> <journal> Computational Intelligence, </journal> <volume> 8 (2), </volume> <pages> 336-375. </pages>
Reference-contexts: Just as in PAC learning, we require the learner to be successful on any stationary problem distribution unknown to the learner. There have been some other attempts to formalize speedup learning <ref> (e.g., Cohen, 1992, Greiner & Likuski, 1989, Subramanian & Hunter, 1992) </ref>. <p> There have been some other attempts to formalize speedup learning (e.g., Cohen, 1992, Greiner & Likuski, 1989, Subramanian & Hunter, 1992). However, most of these formalizations of speedup learning use a measure of problem-solving performance such as the number of nodes expanded in solving a problem <ref> (Cohen, 1992) </ref> or the number of unifications done in answering a query (Greiner & Likuski, 1989). We believe that these measures are too fine grained to be useful as a foundation for a robust theory of speedup learning comparable to the analysis of concept learning in the PAC-learning framework.
Reference: <author> DeJong, G., & Mooney, R. </author> <year> (1986). </year> <title> Explanation based learning: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 145-176. </pages>
Reference: <author> Earley, J. </author> <year> (1970). </year> <title> An efficient context-free parsing algorithm.. </title> <journal> Communications of ACM, </journal> <volume> 13 (2), </volume> <pages> 94-102. </pages>
Reference-contexts: As described earlier, the MSC can be computed in time linear in the number of examples and the sizes of the parse trees. Since parsing for unambiguous context free grammars can be done in time O (n 2 ) <ref> (Earley, 1970) </ref>, the MSG of a set of problems can be found in polynomial time. Thus the second condition of Theorem 2 is satisfied as well. The third condition of Theorem 2 also holds since membership in select-sets corresponds to parsing which is an O (n 2 ) problem.
Reference: <author> Etzioni, O. </author> <year> (1993). </year> <title> A structural theory of explanation-based learning. </title> <journal> Artificial Intelligence, </journal> <volume> 60 (1), </volume> <pages> 93-139. </pages>
Reference-contexts: For example, Etzioni showed that in the PRODIGY system, EBL's success hinges on its ability to find constant-size nonrecursive proofs that show that choosing some operators in certain states is always bad (or always good) <ref> (Etzioni, 1993) </ref>. Such constant-size proofs result in constant-size control rules, which are inexpensive to match. <p> If there is a finite set of such control rules that can reduce the number of states expanded in problem solving from an exponential function of the state size to a polynomial function, the problem solving can be guaranteed to take only polynomial time <ref> (Etzioni, 1993, Proposition 2.1., pg. 102) </ref>. Etzioni's original system STATIC exploited this structural feature of the problem space to learn efficient problem solvers without using any examples (Etzioni, 1993). <p> Etzioni's original system STATIC exploited this structural feature of the problem space to learn efficient problem solvers without using any examples <ref> (Etzioni, 1993) </ref>. A subsequent system called 467 Tadepalli & Natarajan DYNAMIC used examples to identify the problems to be explained (Perez & Etzioni, 1992).
Reference: <author> Garey, M., & Johnson, D. </author> <year> (1979). </year> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. W.H. </title> <publisher> Freeman. </publisher>
Reference: <author> Gratch, J., & DeJong, G. </author> <year> (1992). </year> <title> Composer: A probabilistic solution to the utility problem in speedup-learning. </title> <booktitle> In Proceedings of National Conference on Artificial Intelligence, </booktitle> <pages> pp. 235-240. </pages> <address> San Jose, CA. </address> <publisher> AAAI Press. </publisher>
Reference: <author> Greiner, R. </author> <year> (1991). </year> <title> Finding the optimal derivation strategy in a redundant knowledge base. </title> <journal> Artificial Intelligence, </journal> <volume> 50 (1), </volume> <pages> 95-116. </pages>
Reference: <author> Greiner, R., & Jurisica, I. </author> <year> (1992). </year> <title> A statistical approach to solving the EBL utility problem. </title> <booktitle> In Proceedings of National Conference on Artificial Intelligence, </booktitle> <pages> pp. 241-248. </pages> <address> San Jose, CA. </address> <publisher> AAAI Press. 473 Tadepalli & Natarajan Greiner, </publisher> <editor> R., & Likuski, J. </editor> <year> (1989). </year> <title> Incorporating redundant learned rules: A preliminary formal analysis of EBL. </title> <booktitle> In Proceedings of International Joint conference on Artificial Intelligence, </booktitle> <pages> pp. 744-749. </pages> <address> Detroit,MI. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Just as in PAC learning, we require the learner to be successful on any stationary problem distribution unknown to the learner. There have been some other attempts to formalize speedup learning <ref> (e.g., Cohen, 1992, Greiner & Likuski, 1989, Subramanian & Hunter, 1992) </ref>.
Reference: <author> Guptha, N., & Nau, D. </author> <year> (1992). </year> <title> On the complexity of blocks world planning. </title> <journal> Artificial Intelligence, </journal> <volume> 56 (2-3), </volume> <pages> 223-254. </pages>
Reference: <author> Haussler, D. </author> <year> (1989). </year> <title> Learning conjunctive concepts in structural domains. </title> <journal> Machine Learning, </journal> <volume> 4, </volume> <pages> 7-40. </pages>
Reference-contexts: Before we prove theorems about particular hypotheses spaces, we first state a general theorem which is a direct consequence of the results in PAC-learning of finite hypothesis spaces <ref> (Blumer, Ehrenfeucht, Haussler, & Warmuth, 1989) </ref>. Theorem 1 Let M be a meta-domain, and F be a hypothesis space of polynomial-time problem solvers for domains in M. Let dim (F n ) be polynomially bounded in n. <p> There are many challenges in such domains. Concept learning from examples in such structural domains is known to be intractable <ref> (Haussler, 1989) </ref>. This means that we have to extend our model to allow other kinds of information. For example, the learner might be allowed to pose its own problems to the teacher, a natural extension to the paradigm of membership queries (Angluin, 1988). <p> As in the SIMPLEX program, the learning algorithm here needs to find a generalization of a set of positive examples. However, without the membership queries, finding a most specific generalization of a set of examples is known to be NP-hard <ref> (Haussler, 1989) </ref>. The queries make it possible to find a generalization incrementally, by verifying whether each literal in the condition is relevant to the rule. We plan to extend this work to real-time domains where actions are nondeterministic and planning and execution are interleaved.
Reference: <author> Hopcroft, J., & Ullman, J. </author> <year> (1979). </year> <title> Introduction to Automata Theory, Languages, and Computation. </title> <publisher> Addison-Wesley. </publisher>
Reference-contexts: The string of symbols obtained by reading the leaves of the parse tree from left to right is called the yield of the tree <ref> (Hopcroft & Ullman, 1979) </ref>. If the grammar is unambiguous, then for every sentence which can be generated by the grammar there is a unique parse tree which yields that sentence. This tree is called the parse of that sentence.
Reference: <author> Kaelbling, L. P., Littman, M. L., & Moore, A. W. </author> <year> (1996). </year> <title> Reinforcement learning: A survey. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 4, </volume> <pages> 237-285. </pages>
Reference-contexts: Unlike the typical reinforcement learning algorithms where action strategies are learned indirectly by learning value functions over states or state-action pairs <ref> (Kaelbling, Littman, & Moore, 1996) </ref>, here the approach is to learn them directly by empirical generalization of action sequences observed from a knowledgeable teacher.
Reference: <author> Kearns, M. J., & Vazirani, U. V. </author> <year> (1994). </year> <title> An Introduction to Computational Learning Theory. </title>
Reference: <institution> The M.I.T. Press, </institution> <address> Cambridge, MA. </address>
Reference: <author> Khardon, R. </author> <year> (1996). </year> <title> Learning to take actions. </title> <booktitle> In Proceedings of National Conference on Artificial Intelligence. </booktitle> <address> Portland, OR. </address>
Reference: <author> Korf, R. </author> <year> (1985). </year> <title> Macro-operators: a weak method for learning. </title> <journal> Artificial Intelligence, </journal> <volume> 26, </volume> <pages> 35-77. </pages>
Reference-contexts: A domain D is totally decomposable if the effect of any operator in D on a feature value is a function of the value of only that feature and is independent of all other feature values <ref> (Korf, 1985) </ref>. Rubik's Cube is an example of a totally decomposable domain, because the effect of any turn on the position of a cubie is completely predictable from the original position of that cubie. Total decomposability is not obeyed by domains like Eight Puzzle. <p> domains. 459 Tadepalli & Natarajan A domain is serially decomposable for a given total ordering on the set of features if the effect of any operator in the domain on a feature value is a function of the values of only that feature and all the features that precede it <ref> (Korf, 1985) </ref>. If we treat the blank as a special feature in Eight Puzzle, then Eight Puzzle is serially decomposable for any feature ordering that orders the blank first. Note that serial decomposability is a property of the domain as well as its representation. <p> A macro M j;i is nonredundant if it satisfies the macro-table property and no strict prefix of M j;i satisfies it. Korf showed that if a domain is serially decomposable and satisfies the operator closure, then it has a macro table <ref> (Korf, 1985) </ref>. To see why, let fl's stand for some arbitrary (don't-care) feature values. <p> := s i ; /* = the value of the i th feature of s */ solution := Append (solution; M j;i ) s := Apply (M j;i ; s); end; output (solution); end Macro-problem-solver Korf's program fills the macro table by a single backward search from the goal state <ref> (Korf, 1985) </ref>. In our implementation, macro-operators are learned incrementally by Iterative Deepening A* (IDA*) search. Given a random problem, the teacher constructs a solution as follows. It proceeds through the successive columns of the macro-table, starting with the first column.
Reference: <author> Laird, J., Rosenbloom, P., & Newell, A. </author> <year> (1986). </year> <title> Chunking in soar: The anatomy of a general learning mechanism. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 11-46. </pages>
Reference-contexts: There have been many successful speedup learning systems described in the experimental machine learning literature, PRODIGY (Minton, 1990) and SOAR <ref> (Laird, Rosenbloom, & Newell, 1986) </ref> being two of the most prominent ones. Consider the domain of symbolic integration. Given the definition of the domain and a standard table of integrals, anyone has complete information on how to solve any solvable problem. <p> This ensures that there is always a macro table in the learner's search space which is consistent with all the solutions generated thus far. This approach closely integrates the "learner" and the "teacher" and brings our system closer to the previous implementations of unsupervised speedup learning such as SOAR <ref> (Laird et al., 1986) </ref>. To see the importance of the above requirement, consider what happens if the teacher uses some form of admissible search algorithm to give an optimal solution to every Eight Puzzle problem it is asked to solve. <p> The application of our theory to learning macro-operators can be used to explain the success of SOAR in domains like Eight Puzzle <ref> (Laird et al., 1986) </ref>. (The version of EBL used in SOAR is called Chunking.) Recall that Serial Parsing is given the order in which the subgoals are achieved. <p> In systems like SOAR that successfully learn macros using EBL, the goal ordering is implicitly given by defining the subgoals such that they are successively inclusive <ref> (Laird et al., 1986) </ref>. For example, in Eight Puzzle, the goals are "getting the blank in correct position," "getting the blank and tile 1 in correct positions," "getting the blank and tiles 1 and 2 in correct positions," and so on. <p> To some extent, SOAR's operators are also opaque to its learning method in that the learning mechanism has only knowledge of which objects are "touched" by the operators, but does not have access to the operators themselves <ref> (Laird et al., 1986) </ref>. 3 This suggests that, unlike in EBL (Mitchell et al., 1986), it is not necessary to have access to declaratively represented operators to achieve speedup using macro-operators. <p> Our framework captures both empirical and explanation-based speedup learning methods in a uniform manner. Our SIMPLEX system is designed after LEX (1), which is described as an "empirical learning system" (Mitchell et al., 1983), and our macro-table learner is similar to SOAR, which is described as an "explanation-based learner" <ref> (Laird et al., 1986) </ref>. We view the speedup learning problem as one of finding a close approximation of the target problem solver from examples of that problem solver and the domain specification by efficiently searching the hypothesis space of problem solvers.
Reference: <author> Littlestone, N. </author> <year> (1988). </year> <title> Learning quickly when irrelevant attributes abound: A new linear threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2, </volume> <pages> 285-318. </pages>
Reference-contexts: M in F . 2 Note that the above theorem can also be stated using the on-line mistake-bound model, in which the learner incrementally updates a hypothesis whenever it cannot solve a new training problem in the same way as the teacher does, i.e., whenever the learner makes a "mistake" <ref> (Littlestone, 1988) </ref>. This yields a slightly more general result than Theorem 2, because, under the same conditions of this theorem, the number of mistakes of the learner in the worst-case is polynomially bounded for any arbitrary choice of training examples, i.e., not necessarily generated using a fixed probability distribution. <p> The mistake-bound algorithms can be converted to batch PAC-learning algorithms in a straightforward way <ref> (Littlestone, 1988) </ref>. 4.2 Application to symbolic integration We now consider an application of Theorem 2 to the domain of symbolic integration, as was done in the LEX program (Mitchell et al., 1983).
Reference: <author> Littman, M. L., Cassandra, A. R., & Kaelbling, L. P. </author> <year> (1995). </year> <title> Learning policies in partially observable environments: Scaling up. </title> <booktitle> In Proceedings of the International Machine Learning Conference, </booktitle> <pages> pp. 362-370. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Minton, S. </author> <year> (1990). </year> <title> Quantitative results concerning the utility of explanation-based learning. </title> <journal> Artificial Intelligence, </journal> <volume> 42 (2-3), </volume> <pages> 363-391. </pages>
Reference-contexts: Even though the speedup learning program has access to a brute-force problem solver, it is still a challenge to reformulate its knowledge in a way that makes problem solving efficient. There have been many successful speedup learning systems described in the experimental machine learning literature, PRODIGY <ref> (Minton, 1990) </ref> and SOAR (Laird, Rosenbloom, & Newell, 1986) being two of the most prominent ones. Consider the domain of symbolic integration. Given the definition of the domain and a standard table of integrals, anyone has complete information on how to solve any solvable problem. <p> If s is an arbitrary problem in S = n , then its size jsj is n. Notice that our domain specification is not as explicit as the domain theory used in typical speedup learning programs like PRODIGY <ref> (Minton, 1990) </ref>. The operators need not be described in the STRIPS formalism, and goals need not be logical formulas. In fact, they need not be declaratively represented at all, but may be described by procedures whose run time is reasonably bounded. <p> We identify sufficient conditions to guarantee speedup learning in each of these two hypothesis spaces. 4. Learning control rules One way to build efficient problem solvers is by learning control rules as in LEX (Mitchell, Utgoff, & Banerji, 1983) or in PRODIGY <ref> (Minton, 1990) </ref>. Control rules reduce search by selecting, rejecting or ordering operators appropriately. <p> If such a feature ordering is not known, neither EBL nor chunking might converge with a small number of macro-operators without some kind of utility analysis <ref> (Minton, 1990) </ref>. Tadepalli (1991b) describes a method called Batch Parsing, which learns the correct feature ordering along with the macro table. The basic idea here is to learn the macro table column by column, using multiple examples to disambiguate the feature that corresponds to a given column. <p> Speedup learning systems sometimes suffer from what has been called the "utility problem," which is the inefficiency of the learned problem solver caused by the proliferation of learned control knowledge which is too expensive to use <ref> (Minton, 1990) </ref>. Our approach suggests that the utility problem can be solved in some cases by constraining the target problem solver so that it only learns efficient forms of control knowledge (properly indexed macro-operators or control rules) and uses them in a controlled fashion. <p> Since the utility problem is unsolvable in general <ref> (Minton, 1990) </ref>, our approach suggests a way to identify the cases in which it can be solved and precisely characterize them.
Reference: <author> Mitchell, T., Keller, R., & Kedar-Cabelli, S. </author> <year> (1986). </year> <title> Explanation based generalization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 47-80. </pages>
Reference-contexts: To some extent, SOAR's operators are also opaque to its learning method in that the learning mechanism has only knowledge of which objects are "touched" by the operators, but does not have access to the operators themselves (Laird et al., 1986). 3 This suggests that, unlike in EBL <ref> (Mitchell et al., 1986) </ref>, it is not necessary to have access to declaratively represented operators to achieve speedup using macro-operators.
Reference: <author> Mitchell, T., Utgoff, P., & Banerji, R. </author> <year> (1983). </year> <title> Learning by experimentation: Acquiring and refining problem solving heuristics. </title> <editor> In Michalski, R., Carbonell, J., & Mitchell, T. (Eds.), </editor> <booktitle> Machine Learning, </booktitle> <pages> pp. 163-190. </pages> <publisher> Tioga, </publisher> <address> Palo Alto, CA. </address>
Reference-contexts: We identify sufficient conditions to guarantee speedup learning in each of these two hypothesis spaces. 4. Learning control rules One way to build efficient problem solvers is by learning control rules as in LEX <ref> (Mitchell, Utgoff, & Banerji, 1983) </ref> or in PRODIGY (Minton, 1990). Control rules reduce search by selecting, rejecting or ordering operators appropriately. <p> The mistake-bound algorithms can be converted to batch PAC-learning algorithms in a straightforward way (Littlestone, 1988). 4.2 Application to symbolic integration We now consider an application of Theorem 2 to the domain of symbolic integration, as was done in the LEX program <ref> (Mitchell et al., 1983) </ref>. We will show how this can be efficiently implemented using a straightforward application of Theorem 2 for a subset of LEX's domain. Consider the class of symbolic integrals that can be solved by the standard integration operators. <p> Our framework captures both empirical and explanation-based speedup learning methods in a uniform manner. Our SIMPLEX system is designed after LEX (1), which is described as an "empirical learning system" <ref> (Mitchell et al., 1983) </ref>, and our macro-table learner is similar to SOAR, which is described as an "explanation-based learner" (Laird et al., 1986).
Reference: <author> Natarajan, B. </author> <year> (1987). </year> <title> On learning Boolean functions. </title> <booktitle> In Proceedings of the 19 th ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 296-304. </pages> <publisher> ACM Press. </publisher>
Reference-contexts: Now, we are ready to state and prove the main theorem of this section. The statement and proof of this theorem can be derived from previous results on learning sets with one-sided error <ref> (Natarajan, 1987) </ref>. We prove it from the first principles for completeness. Let L denote a set of sentences, each of which represents a set of problems in the domain. There is a natural partial ordering over the elements of L defined by the "more specific than" relation.
Reference: <author> Natarajan, B. </author> <year> (1989). </year> <title> On learning from exercises. </title> <booktitle> In Proceedings of the 2 nd Annual Workshop on Computational Learning Theory, </booktitle> <pages> pp. 72-87. </pages> <address> Santa Cruz, CA. </address> <month> 474 </month>
Reference-contexts: For a given problem distribution, this can also be easily estimated from examples by the standard procedure of starting with size 1 and iteratively doubling it and verifying it with a sufficiently large set of randomly generated problems <ref> (Natarajan, 1989) </ref>.
References-found: 29

