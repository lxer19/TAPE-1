URL: http://www.almaden.ibm.com/cs/quest/papers/vldb95_tax.ps
Refering-URL: http://www.almaden.ibm.com/cs/quest/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fsrikant,ragrawalg@almaden.ibm.com  
Title: Mining Generalized Association Rules  
Author: Ramakrishnan Srikant Rakesh Agrawal 
Address: San Jose, CA 95120  
Affiliation: IBM Almaden Research Center  
Abstract: We introduce the problem of mining generalized association rules. Given a large database of transactions, where each transaction consists of a set of items, and a taxonomy (is-a hierarchy) on the items, we find associations between items at any level of the taxonomy. For example, given a taxonomy that says that jackets is-a outerwear is-a clothes, we may infer a rule that "people who buy outerwear tend to buy shoes". This rule may hold even if rules that "people who buy jackets tend to buy shoes", and "people who buy clothes tend to buy shoes" do not hold. An obvious solution to the problem is to add all ancestors of each item in a transaction to the transaction, and then run any of the algorithms for mining association rules on these "extended transactions". However, this "Basic" algorithm is not very fast; we present two algorithms, Cumulate and EstMerge, which run 2 to 5 times faster than Basic (and more than 100 times faster on one real-life dataset). We also present a new interest-measure for rules which uses the information in the taxonomy. Given a user-specified "minimum-interest-level", this measure prunes a large number of redundant rules; 40% to 60% of all the rules were pruned on two real-life datasets. fl Also, Department of Computer Science, University of Wis-consin, Madison. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the VLDB copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Very Large Data Base Endowment. To copy otherwise, or to republish, requires a fee and/or special permission from the Endowment. Proceedings of the 21st VLDB Conference Zurich, Swizerland, 1995 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agrawal, T. Imielinski, and A. Swami. </author> <title> Mining association rules between sets of items in large databases. </title> <booktitle> In Proc. of the ACM SIGMOD Conference on Management of Data, </booktitle> <pages> pages 207-216, </pages> <address> Washington, D.C., </address> <month> May </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Data mining, also known as knowledge discovery in databases, has been recognized as a new area for database research. The area can be defined as efficiently discovering interesting rules from large collections of data. The problem of mining association rules was introduced in <ref> [1] </ref>. Given a set of transactions, where each transaction is a set of items, an association rule is an expression X ) Y , where X and Y are sets of items. <p> Also, "Outerwear ) Hiking Boots" may be a valid rule, while "Jackets ) Hiking Boots" and "Clothes ) Hiking Boots" may not. The former may not have minimum support, and the latter may not have minimum confidence. Earlier work on association rules <ref> [1] </ref> [2] [5] [6] [7] did not consider the presence of taxonomies and restricted the items in association rules to the leaf-level items in the taxonomy. However, finding rules across different levels of the taxonomy is valuable since: * Rules at lower levels may not have minimum support. <p> For example, if the transaction contained Jackets, we would add Outerwear and Clothes to get the extended-transaction. We can then run any of the algorithms for mining association rules <ref> [1] </ref> [2] [5] [6] [7] on the extended transactions to get generalized association rules. However, this "Basic" algorithm is not very fast; two more sophisticated algorithms that we propose run 2 to 5 times faster than Basic (and more than 100 times faster on one real-life dataset). <p> We call these rules generalized association rules because both X and Y can contain items from any level of the taxonomy T , a possibility not entertained by the formalism introduced in <ref> [1] </ref>. Problem Statement (Tentative) Given a set of transactions D and a set of taxonomies T , the problem of mining generalized association rules is to discover all rules that have support and confidence greater than the user-specified minimum support (called min-sup) and minimum confidence (called minconf ) respectively. <p> Prune all uninteresting rules from this set. In the rest of this section, we look at algorithms for finding all frequent itemsets where the items can be from any level of the taxonomy. Given the frequent itemsets, the algorithm in <ref> [1] </ref> [2] can be used to generate rules. We first describe the obvious approach for finding frequent itemsets, and then present our two algorithms. 3.1 Algorithm Basic Consider the problem of deciding whether a transaction T supports an itemset X. <p> Now T supports X if and only if T 0 is a superset of X. Hence a straight-forward way to find generalized association rules would be to run any of the algorithms for finding association rules from <ref> [1] </ref> [2] [5] [6] [7] on the extended transactions. We discuss below the generalization of the Apriori algorithm given in [2]. Figure 5 gives an overview of the algorithm, using the notation in Figure 4. The first pass of the algorithm simply counts item occurrences to determine the frequent 1-itemsets. <p> The first pass of the algorithm simply counts item occurrences to determine the frequent 1-itemsets. Note that items in the itemsets can come from the leaves of the taxonomy or from interior nodes. A subsequent pass, say pass k, consists of two phases. First, 3 In earlier papers <ref> [1] </ref> [2], itemsets with minimum support were called large itemsets. However, some readers associated "large" with the number of items in the itemset, rather than its support. So we are switching the terminology to frequent itemsets. k-itemset An itemset having k items.
Reference: [2] <author> R. Agrawal and R. Srikant. </author> <title> Fast algorithms for mining association rules. </title> <booktitle> In Proc. of the VLDB Conference, </booktitle> <address> Santiago, Chile, </address> <month> September </month> <year> 1994. </year> <note> Expanded version available as IBM Research Report RJ9839, </note> <month> June </month> <year> 1994. </year>
Reference-contexts: Also, "Outerwear ) Hiking Boots" may be a valid rule, while "Jackets ) Hiking Boots" and "Clothes ) Hiking Boots" may not. The former may not have minimum support, and the latter may not have minimum confidence. Earlier work on association rules [1] <ref> [2] </ref> [5] [6] [7] did not consider the presence of taxonomies and restricted the items in association rules to the leaf-level items in the taxonomy. However, finding rules across different levels of the taxonomy is valuable since: * Rules at lower levels may not have minimum support. <p> For example, if the transaction contained Jackets, we would add Outerwear and Clothes to get the extended-transaction. We can then run any of the algorithms for mining association rules [1] <ref> [2] </ref> [5] [6] [7] on the extended transactions to get generalized association rules. However, this "Basic" algorithm is not very fast; two more sophisticated algorithms that we propose run 2 to 5 times faster than Basic (and more than 100 times faster on one real-life dataset). <p> Prune all uninteresting rules from this set. In the rest of this section, we look at algorithms for finding all frequent itemsets where the items can be from any level of the taxonomy. Given the frequent itemsets, the algorithm in [1] <ref> [2] </ref> can be used to generate rules. We first describe the obvious approach for finding frequent itemsets, and then present our two algorithms. 3.1 Algorithm Basic Consider the problem of deciding whether a transaction T supports an itemset X. <p> Now T supports X if and only if T 0 is a superset of X. Hence a straight-forward way to find generalized association rules would be to run any of the algorithms for finding association rules from [1] <ref> [2] </ref> [5] [6] [7] on the extended transactions. We discuss below the generalization of the Apriori algorithm given in [2]. Figure 5 gives an overview of the algorithm, using the notation in Figure 4. The first pass of the algorithm simply counts item occurrences to determine the frequent 1-itemsets. <p> Hence a straight-forward way to find generalized association rules would be to run any of the algorithms for finding association rules from [1] <ref> [2] </ref> [5] [6] [7] on the extended transactions. We discuss below the generalization of the Apriori algorithm given in [2]. Figure 5 gives an overview of the algorithm, using the notation in Figure 4. The first pass of the algorithm simply counts item occurrences to determine the frequent 1-itemsets. Note that items in the itemsets can come from the leaves of the taxonomy or from interior nodes. <p> The first pass of the algorithm simply counts item occurrences to determine the frequent 1-itemsets. Note that items in the itemsets can come from the leaves of the taxonomy or from interior nodes. A subsequent pass, say pass k, consists of two phases. First, 3 In earlier papers [1] <ref> [2] </ref>, itemsets with minimum support were called large itemsets. However, some readers associated "large" with the number of items in the itemset, rather than its support. So we are switching the terminology to frequent itemsets. k-itemset An itemset having k items. <p> Next, the database is scanned and the support of candidates in C k is counted. For fast counting, we need to efficiently determine the candidates in C k that are contained in a given transaction t. We reuse the hash-tree data structure described in <ref> [2] </ref> for this purpose. Candidate Generation Given L k1 , the set of all frequent (k1)-itemsets, we want to generate a super-set of the set of all frequent k-itemsets. Candidates may include leaf-level items as well as interior nodes in the taxonomy. <p> The data resided in the AIX file system and was stored on a local 2GB SCSI 3.5" drive, with measured sequential throughput of about 2 MB/second. 4.1 Synthetic Data Generation Our synthetic data generation program is a generalization of the algorithm in <ref> [2] </ref>; the addition being the incorporation of taxonomies. The various parameters and their default vales are shown in Table 2. We now describe the extensions to the data generation algorithm in more detail. The essential idea behind the synthetic data generation program in [2] was to first generate a table of <p> is a generalization of the algorithm in <ref> [2] </ref>; the addition being the incorporation of taxonomies. The various parameters and their default vales are shown in Table 2. We now describe the extensions to the data generation algorithm in more detail. The essential idea behind the synthetic data generation program in [2] was to first generate a table of potentially frequent itemsets I, and then generate p = 5% p = 1% p = 0:5% p = 0:1% n = 1000 0.32 0.76 0.80 0.95 0.89 0.97 0.98 0.99 n = 100; 000 0.00 0.00 0.00 0.01 0.00 0.07 0.12 0.60 Table <p> Details can be found in <ref> [2] </ref>. To extend this algorithm, we first build a taxonomy over the items. 4 For simplicity, we modeled the taxonomy as a forest rather than a DAG. For any internal node, the number of children is picked from a Poisson distribution with mean equal to fanout F .
Reference: [3] <author> N. Alon and J. H. Spencer. </author> <title> The Probabilistic Method. </title> <publisher> John Wiley Inc., </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: We use the abbreviation s - k ("s is at least as extreme as k") defined by s - k () x k if k pn Using Chernoff bounds [4] <ref> [3] </ref>, the probability that the fractional support in the sample is at least as extreme as a is bounded by P r [s an] p a 1p 1a (1) Table 1 presents probabilities that the support of an itemset in the sample is less than a when its real support is
Reference: [4] <author> T. Hagerup and C. Rub. </author> <title> A guided tour of Chernoff bounds. </title> <journal> Information Processing Letters, </journal> <volume> 33 </volume> <pages> 305-308, </pages> <year> 1989/90. </year>
Reference-contexts: We use the abbreviation s - k ("s is at least as extreme as k") defined by s - k () x k if k pn Using Chernoff bounds <ref> [4] </ref> [3], the probability that the fractional support in the sample is at least as extreme as a is bounded by P r [s an] p a 1p 1a (1) Table 1 presents probabilities that the support of an itemset in the sample is less than a when its real support
Reference: [5] <author> M. Houtsma and A. Swami. </author> <title> Set-oriented mining of association rules. </title> <booktitle> In Int'l Conference on Data Engineering, </booktitle> <address> Taipei, Taiwan, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: Also, "Outerwear ) Hiking Boots" may be a valid rule, while "Jackets ) Hiking Boots" and "Clothes ) Hiking Boots" may not. The former may not have minimum support, and the latter may not have minimum confidence. Earlier work on association rules [1] [2] <ref> [5] </ref> [6] [7] did not consider the presence of taxonomies and restricted the items in association rules to the leaf-level items in the taxonomy. However, finding rules across different levels of the taxonomy is valuable since: * Rules at lower levels may not have minimum support. <p> For example, if the transaction contained Jackets, we would add Outerwear and Clothes to get the extended-transaction. We can then run any of the algorithms for mining association rules [1] [2] <ref> [5] </ref> [6] [7] on the extended transactions to get generalized association rules. However, this "Basic" algorithm is not very fast; two more sophisticated algorithms that we propose run 2 to 5 times faster than Basic (and more than 100 times faster on one real-life dataset). <p> Now T supports X if and only if T 0 is a superset of X. Hence a straight-forward way to find generalized association rules would be to run any of the algorithms for finding association rules from [1] [2] <ref> [5] </ref> [6] [7] on the extended transactions. We discuss below the generalization of the Apriori algorithm given in [2]. Figure 5 gives an overview of the algorithm, using the notation in Figure 4. The first pass of the algorithm simply counts item occurrences to determine the frequent 1-itemsets.
Reference: [6] <author> H. Mannila, H. Toivonen, and A. I. Verkamo. </author> <title> Efficient algorithms for discovering association rules. </title> <booktitle> In KDD-94: AAAI Workshop on Knowledge Discovery in Databases, </booktitle> <pages> pages 181-192, </pages> <address> Seattle, Wash-ington, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: Also, "Outerwear ) Hiking Boots" may be a valid rule, while "Jackets ) Hiking Boots" and "Clothes ) Hiking Boots" may not. The former may not have minimum support, and the latter may not have minimum confidence. Earlier work on association rules [1] [2] [5] <ref> [6] </ref> [7] did not consider the presence of taxonomies and restricted the items in association rules to the leaf-level items in the taxonomy. However, finding rules across different levels of the taxonomy is valuable since: * Rules at lower levels may not have minimum support. <p> For example, if the transaction contained Jackets, we would add Outerwear and Clothes to get the extended-transaction. We can then run any of the algorithms for mining association rules [1] [2] [5] <ref> [6] </ref> [7] on the extended transactions to get generalized association rules. However, this "Basic" algorithm is not very fast; two more sophisticated algorithms that we propose run 2 to 5 times faster than Basic (and more than 100 times faster on one real-life dataset). <p> Now T supports X if and only if T 0 is a superset of X. Hence a straight-forward way to find generalized association rules would be to run any of the algorithms for finding association rules from [1] [2] [5] <ref> [6] </ref> [7] on the extended transactions. We discuss below the generalization of the Apriori algorithm given in [2]. Figure 5 gives an overview of the algorithm, using the notation in Figure 4. The first pass of the algorithm simply counts item occurrences to determine the frequent 1-itemsets.
Reference: [7] <author> J. S. Park, M.-S. Chen, and P. S. Yu. </author> <title> An effective hash based algorithm for mining association rules. </title> <booktitle> In Proc. of the ACM-SIGMOD Conference on Management of Data, </booktitle> <address> San Jose, California, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: Also, "Outerwear ) Hiking Boots" may be a valid rule, while "Jackets ) Hiking Boots" and "Clothes ) Hiking Boots" may not. The former may not have minimum support, and the latter may not have minimum confidence. Earlier work on association rules [1] [2] [5] [6] <ref> [7] </ref> did not consider the presence of taxonomies and restricted the items in association rules to the leaf-level items in the taxonomy. However, finding rules across different levels of the taxonomy is valuable since: * Rules at lower levels may not have minimum support. <p> For example, if the transaction contained Jackets, we would add Outerwear and Clothes to get the extended-transaction. We can then run any of the algorithms for mining association rules [1] [2] [5] [6] <ref> [7] </ref> on the extended transactions to get generalized association rules. However, this "Basic" algorithm is not very fast; two more sophisticated algorithms that we propose run 2 to 5 times faster than Basic (and more than 100 times faster on one real-life dataset). <p> Now T supports X if and only if T 0 is a superset of X. Hence a straight-forward way to find generalized association rules would be to run any of the algorithms for finding association rules from [1] [2] [5] [6] <ref> [7] </ref> on the extended transactions. We discuss below the generalization of the Apriori algorithm given in [2]. Figure 5 gives an overview of the algorithm, using the notation in Figure 4. The first pass of the algorithm simply counts item occurrences to determine the frequent 1-itemsets.
Reference: [8] <author> G. Piatetsky-Shapiro. </author> <title> Discovery, analysis, and presentation of strong rules. </title> <editor> In G. Piatetsky-Shapiro and W. Frawley, editors, </editor> <booktitle> Knowledge Discovery in Databases, </booktitle> <pages> pages 229-248. </pages> <publisher> AAAI/MIT Press, </publisher> <address> Menlo Park, CA, </address> <year> 1991. </year>
Reference-contexts: Outerwear ) Hiking Boots 33% 66.6% Outerwear ) Footwear 33% 66.6% Hiking Boots ) Outerwear 33% 100% Hiking Boots ) Clothes 33% 100% <ref> [8] </ref>, Piatetsky-Shapiro argues that a rule X ) Y is not interesting if support (X ) Y ) support (X) fi support (Y ). We implemented this idea, and used the chi-square value to check if the rule was statistically significant.
Reference: [9] <author> R. Srikant and R. Agrawal. </author> <title> Mining generalized association rules. </title> <type> Research Report RJ 9963, </type> <institution> IBM Al-maden Research Center, </institution> <address> San Jose, California, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: We describe the Basic algorithm and our two algorithms in Section 3, and evaluate their performance on both synthetic and real-life data in Section 4. Finally, we summarize our work and conclude in Section 5. For an expanded version of this paper, see <ref> [9] </ref>. 2 Problem Statement Let I = fi 1 ; i 2 ; . . . ; i m g be a set of literals, called items. Let T be a directed acyclic graph on the literals. <p> Proofs of these lemmas are given in <ref> [9] </ref>. Lemma 1 shows that we need not count any itemset which contains both an item and its ancestor. <p> At each node, we decide what branch to follow by tossing a k-sided weighted coin, where k is the number of children, and the weights correspond to the weights of the children. See <ref> [9] </ref> for further details of the candidate generation program. 4.2 Preliminary Experiments Stratification : Variants The results of comparing the three variants of the stratification algorithm on the default synthetic data are shown in Figure 9. <p> In contrast, the interest measure based on statistical significance did not prune any rules at 50% confidence and pruned less than 1% of the rules at 25% confidence (for both datasets). More details about these experiments can be found in <ref> [9] </ref>.
References-found: 9

