URL: http://www.medg.lcs.mit.edu/projects/ontology/publications/doyle-krsl-critique.ps
Refering-URL: http://www.medg.lcs.mit.edu/projects/ontology/publications/
Root-URL: 
Email: doyle@lcs.mit.edu  
Title: Critique of KRSL 2.0.2  
Author: Jon Doyle 
Keyword: rationales, namely argument fragments and descriptions of decisions.  
Affiliation: MIT Lab for Computer Science  
Date: October 12, 1994.  October 11, 1994  
Note: Notes prepared for ARPI Ontology Kickoff Meeting, held  c Copyright 1994 by Jon Doyle.  
Abstract: The current KRSL plan specification language treats information traditionally contained in plans reasonably well, but does not provide good means for representing economic information about how agents consume, produce, and choose among resources, and provides essentially no means for representing information about the rationales (reasons, decisions, and explanations) underlying plans. In consequence, planning agents cannot use KRSL to cooperatively make decisions and evaluate and repair plans, as they cannot use KRSL to communicate useful infor The KRSL plan-representation language is intended to provide a common language to ARPI groups for specifying information about plans and communicating such information among modules. The clear benefit of such a common language is that it simplifies the task of integrating modules by getting them all to speak the same language, rather than having to design a large numbers of point-to-point translators of idiosyncratic representations. Unfortunately, the current version KRSL facilitates communication of only a portion of the information needed by mixed-initiative planning systems. It focuses on describing the overt structures of objects and actions in a way completely appropriate to traditional AI planning systems. But it provides flawed means for specifying economic properties of agents and resources, and provides no standard means for communicating plan rationales. In the original ARPI vision of human-computer cooperative planning, human planners would work with automated systems to present commanders with a short list of primary, qualitatively different options, the idea being to give the commanders a good idea of the range of possibilities seen as reasonable by the planners. To allow the commander(s) to choose wisely, these options must be accompanied by at least a sketch of their underlying rationales if the options are not absolutely transparent (as is rarely the case). These rationales indicate the primary planning assumptions and decisions making the options plausible; the underlying assumptions about conditions and responses, the underlying assumptions about the relative importance of different strategic and tactical aims and principles, and the principal choices among equally good alternatives (equivalently, the dimensions of simple variability). One plan might presume that some position will hold without fail, or might chance greater risks than another, or might sacrifice one goal to accomplish another. Commanders need to know these things about the options to decide among them. For similar reasons, replanning systems designed to repair or revise large-scale plans in light of changed information also need the rationales of plans if they are to do anything other than replanning from scratch. The current KRSL specification provides no standard means for communicating useful plan rationales. One can state that a plan achieves a specific goal in KRSL; but one cannot say much about underlying assumptions about conditions, or the alternatives considered in selecting this plan over others that achieve the goal, or about the preferences that lead to this selection, or about the importance of this goal to others. Accordingly, KRSL should be improved to permit convenient specification of plan rationales and the information contained in them. Past work on reason maintenance [2, 5] and reasoned deliberation [3] provides suggestions for some elements of mation about their needs (in order to evaluate plans) and reasons (in order to modify plans).
Abstract-found: 1
Intro-found: 0
Reference: [1] <author> C. Boutilier. </author> <title> A modal characterization of defeasible deontic conditionals and conditional goals. </title> <booktitle> In AAAI Spring Symposium on Reasoning about Mental States, </booktitle> <pages> pages 30-39, </pages> <year> 1993. </year>
Reference: [2] <author> J. Doyle. </author> <title> A truth maintenance system. </title> <journal> Artificial Intelligence, </journal> <volume> 12(2) </volume> <pages> 231-272, </pages> <year> 1979. </year>
Reference: [3] <author> J. Doyle. </author> <title> A model for deliberation, action, and introspection. </title> <type> AI-TR 581, </type> <institution> Massachusetts Institute of Technology, Artificial Intelligence Laboratory, 545 Technology Square, </institution> <address> Cambridge, MA, 02139, </address> <year> 1980. </year>
Reference: [4] <author> J. Doyle, Y. Shoham, and M. P. Wellman. </author> <title> A logic of relative desire (preliminary report). </title> <editor> In Z. W. Ras and M. Zemankova, editors, </editor> <booktitle> Methodologies for Intelligent Systems, 6, volume 542 of Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 16-31, </pages> <address> Berlin, Oct. 1991. </address> <publisher> Springer-Verlag. </publisher>
Reference: [5] <author> J. Doyle and M. P. Wellman. </author> <title> Rational distributed reason maintenance for planning and replanning of large-scale activities. </title> <editor> In K. Sycara, editor, </editor> <booktitle> Proceedings of the DARPA Workshop on Planning and Scheduling, </booktitle> <pages> pages 28-36, </pages> <address> San Mateo, CA, Nov. 1990. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [6] <author> J. Doyle and M. P. Wellman. </author> <title> Representing preferences as ceteris paribus comparatives. </title> <editor> In S. Hanks, S. Russell, and M. P. Wellman, editors, </editor> <booktitle> Proceedings of the AAAI Spring Symposium on Decision-Theoretic Planning, </booktitle> <year> 1994. </year>
Reference: [7] <author> P. Haddawy and S. Hanks. </author> <title> Issues in decision-theoretic planning: Symbolic goals and numeric utilities. </title> <booktitle> In Proceedings of the DARPA Workshop on Innovative Approaches to Planning, Scheduling, and Control, </booktitle> <pages> pages 48-58, </pages> <year> 1990. </year>
Reference: [8] <author> P. Haddawy and S. Hanks. </author> <title> Representations for decision-theoretic planning: Utility functions for deadline goals. </title> <editor> In B. Nebel, C. Rich, and W. Swartout, editors, </editor> <booktitle> Proceedings of the Third International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 71-82, </pages> <address> San Mateo, CA, 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [9] <author> R. L. Keeney and H. Raiffa. </author> <title> Decisions with Multiple Objectives: Preferences and Value Tradeoffs. </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1976. </year>
Reference: [10] <author> S. Mantha. </author> <title> Towards a logical foundation for qualitative decision theory. </title> <editor> In S. Hanks, S. Russell, and M. P. Wellman, editors, </editor> <booktitle> Working Notes of the Symposium on Decision-Theoretic Planning, </booktitle> <pages> pages 169-174. </pages> <booktitle> American Association for Artificial Intelligence, </booktitle> <month> Mar. </month> <year> 1994. </year>
Reference: [11] <author> S.-W. Tan and J. Pearl. </author> <title> Specification and evaluation of preferences for planning under uncertainty. </title> <editor> In J. Doyle, E. Sandewall, and P. Torasso, editors, </editor> <booktitle> Principles of Knowledge Representation and Reasoning: Proceedings of the Fourth International Conference (KR'94), </booktitle> <address> San Francisco, CA, May 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [12] <author> M. P. Wellman and J. Doyle. </author> <title> Preferential semantics for goals. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 698-703, </pages> <year> 1991. </year>
Reference: [13] <author> M. P. Wellman and J. Doyle. </author> <title> Modular utility representation for decision-theoretic planning. </title> <booktitle> In Proceedings of the First International Conference on AI Planning Systems, </booktitle> <year> 1992. </year> <month> 4 </month>
References-found: 13

