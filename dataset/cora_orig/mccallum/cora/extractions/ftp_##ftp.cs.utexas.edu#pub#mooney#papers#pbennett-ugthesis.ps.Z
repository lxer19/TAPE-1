URL: ftp://ftp.cs.utexas.edu/pub/mooney/papers/pbennett-ugthesis.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/ml/abstracts.html
Root-URL: 
Title: Text Categorization Through Probabilistic Learning: Applications to Recommender Systems  
Author: Paul N. Bennett Raymond J. Mooney, Ph.D. Risto Miikkulainen, Ph.D. 
Note: Second Reader  
Address: Austin, TX 78712  
Affiliation: Department of Computer Sciences Plan II Honors Program University of Texas  Department Of Computer Sciences  Department Of Computer Sciences  
Pubnum: CS 379H  
Email: Email pbennett@cs.utexas.edu  
Degree: Supervising Professor  
Date: May 4, 1998  
Abstract-found: 0
Intro-found: 1
Reference: <author> Anderson, T., & Finn, J. D. </author> <year> (1996). </year> <title> The New Statistical Analysis of Data. </title> <publisher> Springer-Verlag, Inc., </publisher> <address> New York. </address>
Reference-contexts: In order to compute r s when there are ties in the data, the median of the rankings each example in the tie would have been given had they been sequential, is assigned as the rank of each <ref> (Anderson & Finn, 1996) </ref>. <p> percentage of performance change from using the system predictions as an estimate of user preference rather than guessing the mode; in more technical terms, the percentage reduction in the sum of squared deviations when using the system predictions instead of the mode of the data as the basis for prediction <ref> (Anderson & Finn, 1996) </ref>. Since this metric is simply the square of the correlation coefficient, we have not reported it separately.
Reference: <author> Balabanovic, M., & Shoham, Y. </author> <year> (1997). </year> <title> Fab: Content-based, collaborative recommendation. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 40 (3), </volume> <pages> 66-72. </pages>
Reference-contexts: In contrast, a content-based recommender builds a profile of a user based on the content of the items and the user's ratings <ref> (Balabanovic & Shoham, 1997) </ref>. This allows the system to make recommendations to a user based solely on that user's interests. Our prototype system applies text categorization learning methods to items with semi-structured text descriptions in order to make recommendations to the user. <p> These systems often judge similarity by overlap in ratings among other items. This approach is like the friend who will recommend an item to you because other friends, believed to be similar to you, liked the item. Some recommender systems use a hybridization of these two approaches <ref> (Balabanovic & Shoham, 1997) </ref>. 2.3 Text Categorization Text categorization in general involves assigning a category (or categories) to a sample of text. Sometimes the task is to determine the part-of-speech that a word has in some text; in other cases it may involve classifying a sample into relevant subject categories.
Reference: <author> Califf, M. E., & Mooney, R. J. </author> <year> (1998). </year> <title> Relational learning of pattern-match rules for information extraction. </title> <booktitle> In Working Notes of AAAI Spring Symposium on Applying Machine Learning to Discourse Processing Menlo Park, </booktitle> <address> CA. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Only the title, authors, synopsis, and subject slots are currently employed in learning; however, values for URL, type, length, price, ISBN, etc. are also extracted. The values for the slots are extracted with a pattern-based matcher that uses handwritten rules, including pre-filler, filler, and post-filler patterns <ref> (Califf & Mooney, 1998) </ref>, to extract information from the text. The Amazon pages are fairly structured making it easy to design information extraction rules. The values extracted for each slot are stored as an unordered set of words.
Reference: <author> Cardie, C. </author> <year> (1997). </year> <title> Empirical methods in information extraction. </title> <journal> AI Magazine, </journal> <volume> 18 (4), </volume> <pages> 65-79. </pages>
Reference: <author> Cohen, W. W. </author> <year> (1996a). </year> <title> Learning rules that classify e-mail. </title> <booktitle> In Papers from the AAAI Spring Symposium on Machine Learning in Information Access, </booktitle> <pages> pp. 18-25. </pages> <publisher> AAAI Press. </publisher>
Reference-contexts: LIBRA, however, uses a simple pattern-based extraction method to identify values for various slots, e.g. Author, ISBN, Price, etc. The book is represented as a group of set-valued features <ref> (Cohen, 1996a, 1996b) </ref> where each slot is a feature. The value of a slot is the set of words that occur in the value portion of the pattern for the slot. Currently not all of the slots extracted are used for learning.
Reference: <author> Cohen, W. W. </author> <year> (1996b). </year> <title> Learning trees and rules with set-valued features. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 709-716 Portland, OR. </address>
Reference: <author> Domingos, P., & Pazzani, M. </author> <year> (1996). </year> <title> Beyond independence: Conditions for the optimality of the simple Bayesian classifier. </title> <booktitle> In The Thirteenth International Conference on Machine Learning. </booktitle>
Reference-contexts: This results from the fact that under many less restrictive conditions, even though the probability estimates are strictly incorrect, the actual Cat MAP is still the category with the maximal probability estimate <ref> (Domingos & Pazzani, 1996) </ref>. 2.6 Feature Selection and Feature Construction It is important to note that we have used the term features to refer both to the slots (set-valued features) and when referring to the words that were extracted as the values of the slots.
Reference: <author> Joachims, T. </author> <year> (1997). </year> <title> A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization. </title> <booktitle> In Proceedings of the Fourteenth International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 143-151 San Francisco, CA. </address> <publisher> Morgan Kaufman. </publisher>
Reference: <author> Kohavi, R., Becker, B., & Sommerfield, D. </author> <year> (1997). </year> <title> Improving simple Bayes. </title> <booktitle> In Proceedings of the European Conference on Machine Learning. </booktitle>
Reference-contexts: In order to account for these issues, we use smoothing methods reported in <ref> (Kohavi et al., 1997) </ref>. Namely, we use a Laplace-m estimate where m is the number of training examples.
Reference: <author> Koller, D., & Sahami, M. </author> <year> (1996). </year> <title> Toward optimal feature selection. </title> <booktitle> In The Thirteenth International Conference on Machine Learning. </booktitle>
Reference-contexts: If one were to use multiple word phrases or other construction, the number of features becomes much higher. As learning algorithms tend to have a computational complexity proportional to the size of the feature set <ref> (Koller & Sahami, 1996) </ref>, large feature sets can be quite expensive. While Naive Bayes is one of the cheaper algorithms in this respect, in order to apply other more sophisticated algorithms to this task, it would most likely require feature selection in order to be computationally feasible. <p> In addition, the probability distribution function for the probability of a category given an example is often extremely complex in problems with a large feature set <ref> (Koller & Sahami, 1996) </ref>. <p> feature set <ref> (Koller & Sahami, 1996) </ref>. When data is limited, it is very difficult to accurately estimate the numerous probabilistic parameters needed for this high dimensional space; thus overfitting, estimating parameters that are overly specific to the training set and thus don't generalize well to the test set, is likely (Koller & Sahami, 1996). In addition, the large number of irrelevant and redundant features that tend to be present in large feature spaces often end up misleading the learning system (Koller & Sahami, 1996). Thus, the general goals of feature selection are more accurate results and reduced running time. <p> parameters that are overly specific to the training set and thus don't generalize well to the test set, is likely <ref> (Koller & Sahami, 1996) </ref>. In addition, the large number of irrelevant and redundant features that tend to be present in large feature spaces often end up misleading the learning system (Koller & Sahami, 1996). Thus, the general goals of feature selection are more accurate results and reduced running time.
Reference: <author> Lang, K. </author> <year> (1995). </year> <title> NewsWeeder: Learning to filter netnews. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 331-339 San Francisco, CA. </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Our prototype system applies text categorization learning methods to items with semi-structured text descriptions in order to make recommendations to the user. Other content-based recommenders that use text categorization have been used to recommend web pages (Pazzani, Muramatsu, & Billsus, 1996) and Usenet messages <ref> (Lang, 1995) </ref>. The system developed for this research is dubbed LIBRA (Learning Intelligent Book Recommending Agent) and was conceived as an interdisciplinary project between Ray Mooney of the UT-Austin Department of Computer Sciences and Loriene Roy of UT-Austin Library and Information Sciences.
Reference: <author> Lehnert, W., & Sundheim, B. </author> <year> (1991). </year> <title> A performance evaluation of text-analysis technologies. </title> <journal> AI Magazine, </journal> <volume> 12 (3), </volume> <pages> 81-94. </pages>
Reference: <author> Maes, P. </author> <year> (1994). </year> <title> Agents that reduce work and information overload. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 37 (7), </volume> <pages> 31-40. </pages>
Reference: <author> Mitchell, T. </author> <year> (1997). </year> <title> Machine Learning. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY. </address>
Reference-contexts: of the results; Section 5 discusses future work that could extend the research, and section 6 summarizes the paper. 2 Background 2.1 Machine Learning In general, learning is the use of experience in such a way that performance at a certain task is greater with that experience than without it <ref> (Mitchell, 1997) </ref>. Machine Learning seeks to construct systems that have the ability to automatically generalize from their experience in a manner that increases performance at a given task. <p> Thus each example is used as a test example once and a training example n 1 times. This process is termed n-fold cross-validation <ref> (Mitchell, 1997) </ref>|the standard choice of n in Machine Learning is 10. As mentioned above, the average of all the trial runs on some metric (s) is used as an indicator of the systems performance. <p> Given a certain text sample, we would like to be able to determine the most probable category for that sample given all of the information; this category is referred to as the maximum a posteriori category (Cat MAP ) <ref> (Mitchell, 1997) </ref>. A classifier system that, for each sample, can determine the Cat MAP and chooses the Cat MAP as the predicted class, cannot on average be outperformed by another system which uses the same information and hypothesis space. <p> A classifier system that, for each sample, can determine the Cat MAP and chooses the Cat MAP as the predicted class, cannot on average be outperformed by another system which uses the same information and hypothesis space. A classifier that performs this way is called a Bayes Optimal Classifier <ref> (Mitchell, 1997) </ref>. 2.4 Information Extraction Information Extraction attempts to apply patterns (or templates) to text in order to extract information relevant to certain areas (Lehnert & Sundheim, 1991; Cardie, 1997; Califf & Mooney, 1998). <p> For the interested reader, appendices A and B show a sample Amazon page and the information extracted from it by LIBRA, respectively. 2.5 Naive Bayes Algorithm The Naive Bayes algorithm is a simple algorithm but has performed quite well in most domains <ref> (Mitchell, 1997) </ref>. <p> The standard definitions for Entropy and Information Gain are <ref> (Mitchell, 1997) </ref>: Let E be the set of all training examples, fc i g j i=1 be the set of j categories in the target space, t be the set of all attributes, T be an attribute T 2 t , V alues (T ) be the set of values which
Reference: <author> Pazzani, M., & Billsus, D. </author> <year> (1997). </year> <title> Learning and revising user profiles: The identification of interesting web sites. </title> <journal> Machine Learning, </journal> <volume> 27 (3), </volume> <pages> 313-331. </pages> <note> 27 Pazzani, </note> <author> M., Muramatsu, J., & Billsus, D. </author> <year> (1996). </year> <title> Syskill & Webert: Identifying interesting web sites. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 54-61 Portland, OR. </address>
Reference-contexts: Extensions could be made for the system to combine information from other sources; in general or upon detecting that a certain example has low information content, an agent could be sent in search of information over the web. Furthermore, the use of initial user profiles <ref> (Pazzani & Billsus, 1997) </ref> could provide a boost in the early part of the learning curve. A comparison of the performance of the bag-of-words approach to the set-valued feature approach would be useful in evaluating the gain from using the information extraction methods.
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference (Revised Second Printing edition). </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Francisco, CA. </address>
Reference-contexts: These estimates can then be adjusted for the actual words that occur in a sample. In fact, revising the posterior probabilities estimates is quite easy with the Naive Bayes approach. Naive Bayes (and Bayesian methods in general) estimates can be incrementally updated| both adding and retracting information <ref> (Pearl, 1988) </ref>. Thus, Naive Bayes allows us to achieve several of the criteria for a useful recommender system enumerated in section 2.2. Namely, the user can retract ratings, extend the set of examples rated, and obtain recommendations, all fairly efficiently. <p> It treats items rated 1 - 5 as negative instances, and those rated 6 - 10 as positive instances. The scores are ranked based on the natural log of the posterior odds of positive, ln P (P ositivejExample) P (:P ositivejExample) <ref> (Pearl, 1988) </ref>. A second method treats the 10 ratings as 10 distinct categories. When predicting for a test sample, the system first computes the posterior probability of each category given the test sample.
Reference: <author> Resnik, P., & Varian, H. R. </author> <year> (1997). </year> <title> Introduction (to the special section on recommender systems). </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 40 (3), </volume> <pages> 56-59. </pages>
Reference: <author> Russell, S., & Norvig, P. </author> <year> (1995). </year> <title> Artificial Intelligence: A Modern Approach (First edition). </title> <publisher> Prentice Hall, </publisher> <address> Upper Saddle River, NJ. </address>
Reference-contexts: In other cases, the examples come without any additional information provided by an outside source. The former case is called supervised learning and the latter unsupervised <ref> (Russell & Norvig, 1995) </ref>. In order to judge the performance of the system, a learning curve is plotted with the number of training examples on the x-axis and some performance metric on the y-axis (where an increase in performance is shown by an increase in the y value).
Reference: <author> Salton, G., & Buckley, C. </author> <year> (1990). </year> <title> Improving retrieval performance by relevance feedback. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 41, </volume> <pages> 288-297. </pages>
Reference-contexts: Then allow the system to use these new ratings to revise its recommendations. As with the use of relevance feedback <ref> (Salton & Buckley, 1990) </ref>, this can be repeated in order to further improve recommendations. 3.5 System Details This section relates details of the algorithms used that would be necessary for reproducing the results reported here. 3.5.1 Estimating Probabilities This section relates the estimations and smoothing factors used for estimating the probability
Reference: <author> Spatz, C., & Johnston, J. O. </author> <year> (1984). </year> <title> Basic Statistics, Tales of Distributions (Third edition). </title> <publisher> Wadsworth, Inc., </publisher> <address> Belmont, CA. </address>
Reference-contexts: Since this metric is simply the square of the correlation coefficient, we have not reported it separately. When there are no ties, this reduces to the form given in most introductory statistics texts <ref> (Spatz & Johnston, 1984) </ref>. 4.1.3 Systems and Hypotheses Our current experiments compare a simple Binary Classifier and a 10-Ratings classifier which uses the expected value to predict ratings (hereafter referred to as Binary and 10-Ratings, respectively).

References-found: 20

