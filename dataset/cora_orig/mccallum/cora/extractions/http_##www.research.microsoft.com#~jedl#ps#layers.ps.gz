URL: http://www.research.microsoft.com/~jedl/ps/layers.ps.gz
Refering-URL: http://www.research.microsoft.com/~jedl/
Root-URL: http://www.research.microsoft.com
Title: Abstract Using Talisman, a hardware architecture with an efficient layer primitive,  
Keyword: complexity and shading quality of scenes rendered in real-time. CR Categories and Subject Descriptors: I.3.3 [Computer Graphics]: Picture/Image Generation; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism. Additional Keywords: sprite, affine transformation, image compositing, image-based rendering, Talisman  
Note: the work presented here dramatically improves the geometric  
Abstract: For decades, animated cartoons and movie special effects have factored the rendering of a scene into layers that are updated independently and composed in the final display. We apply layer factorization to real-time computer graphics. The layers allow targeting of resources, whether the ink and paint artists of cartoons or the graphics pipeline as described here, to those parts of the scene that are most important. To take advantage of frame-to-frame coherence, we generalize layer factorization to apply to both dynamic geometric objects and terms of the shading model, introduce new ways to trade off fidelity for resource use in individual layers, and show how to compute warps that reuse renderings for multiple frames. We describe quantities, called fiducials, that measure the fidelity of approximations to the original image. Layer update rates, spatial resolution, and other quality parameters are determined by geometric, photometric, visibility, and sampling fiducials weighted by the content authors preferences. We also compare the fidelity of various types of reuse warps and demonstrate the suitability of the affine warp. 
Abstract-found: 1
Intro-found: 1
Reference: [Blinn96] <editor> Consider the Lowly 2x2 Matrix, Jim Blinn, </editor> <booktitle> IEEE Computer Graphics and Applications, </booktitle> <month> March </month> <year> 1996, </year> <pages> pp. 82-88. </pages>
Reference-contexts: values of the Jacobian of the image mapping function measure the greatest magnification and minification and the ratio measures the maximum anisotropy 10 The affine warp has a spatially invariant Jaco-bian given by the left 22 part of the 23 matrix, for which the two singular values are easily calculated <ref> [Blinn96] </ref>. For transforms with spatially varying Jacobians, such as the perspective warp, the singular values vary over the image.
Reference: [Chen93] <editor> View Interpolation for Image Synthesis, Shenchang Eric Chen and Lance Williams, </editor> <booktitle> SIGGRAPH 93, </booktitle> <pages> pp. 279-288. </pages>
Reference-contexts: 320M pixels/second compared to 40Mps for the renderer. 2 Penetrating z-sprites will have a pointsampled and thus aliased boundary where visibility switches. 3 Postwarping of unfactored z-images also fails to address the case of independently moving objects. movement is allowed before changes in the projected geometry exceed a given tolerance. <ref> [Chen93, Chen95] </ref> show how to take advantage of coherence between viewpoints to produce nearly constant cost per frame walkthroughs of static environments. [McMillan95] reprojects images to produce an arbitrary view.
Reference: [Chen95] <editor> QuickTime VR An Image-Based Approach to Virtual Environment Navigation, Shenchang Eric Chen, </editor> <booktitle> SIGGRAPH 95, </booktitle> <pages> pp. 29-38. </pages>
Reference-contexts: 320M pixels/second compared to 40Mps for the renderer. 2 Penetrating z-sprites will have a pointsampled and thus aliased boundary where visibility switches. 3 Postwarping of unfactored z-images also fails to address the case of independently moving objects. movement is allowed before changes in the projected geometry exceed a given tolerance. <ref> [Chen93, Chen95] </ref> show how to take advantage of coherence between viewpoints to produce nearly constant cost per frame walkthroughs of static environments. [McMillan95] reprojects images to produce an arbitrary view.
Reference: [Cook84] <author> Shade Trees, Robert L. Cook, </author> <booktitle> SIGGRAPH 94, </booktitle> <pages> pp. 223-232. </pages>
Reference-contexts: This is conceptually similar to our work, but does not include the factoring across shading or the idea of real-time regulation of quality parameters. We harness simpler image transformations (affine rather than perspective) to achieve greater fidelity (Section 4.2). Our work also treats dynamic geometry. Shading expressions <ref> [Cook84, Hanrahan90] </ref> have been studied extensively. [Dorsey95] factors shading expressions by light source and linearly combines the resulting images in the final display. [Guenter95] caches intermediate results. [Meier96] uses image processing techniques to factor shadow and highlight regions into separate layers which are then re-rendered using painterly techniques and finally composited. <p> Shadows and reflections may instead be separated into layers as shown in Figure 6, so that the blend takes place in the compositor rather than the renderer. We call these shade sprites in reference to shade trees <ref> [Cook84] </ref>. To take advantage of temporal coherence, highlights from fast moving lights, reflections of fast moving reflected geometry, and animated texture maps should be in separate layers and rendered at higher frame rates than the receiving geometry.
Reference: [Dorsey95] <institution> Interactive Design of Complex Time Dependent Lighting, </institution> <note> Julie Dorsey, </note> <author> Jim Arvo, Donald P. Greenberg, </author> <title> IEEE Computer Graphics and Application, </title> <journal> March 1995, </journal> <volume> Volume 15, Number 2, </volume> <pages> pp. 26-36. </pages>
Reference-contexts: We harness simpler image transformations (affine rather than perspective) to achieve greater fidelity (Section 4.2). Our work also treats dynamic geometry. Shading expressions [Cook84, Hanrahan90] have been studied extensively. <ref> [Dorsey95] </ref> factors shading expressions by light source and linearly combines the resulting images in the final display. [Guenter95] caches intermediate results. [Meier96] uses image processing techniques to factor shadow and highlight regions into separate layers which are then re-rendered using painterly techniques and finally composited.
Reference: [Funkhouser93] <editor> Adaptive Display Algorithm for Interactive Frame Rates During Visualization of Complex Virtual Environments, Thomas A. Funkhouser and Carlo H. Squin, </editor> <booktitle> SIGGRAPH 93, </booktitle> <pages> pp. 247-254. </pages>
Reference-contexts: Of course, sprites could store multiple z layers per pixel, a prohibitively costly approach for hardware, but one near to ours in spirit. Such a scheme stores all the layers within each pixel, rather than all the pixels for each layer. 3 <ref> [Funkhouser93] </ref> adjusts rendering parameters to extract the best quality.
Reference: [Gill81] <author> Practical Optimization, Philip E. Gill, Walter Murray, and Margaret H. </author> <title> Wright, </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1981. </year>
Reference-contexts: As a compromise, we simulated both kinds of error minimization: sum-of-squares and maximum error using an optimization method for L norms that iteratively applies the sum-of-square minimization, as described in <ref> [Gill81, pp. 96-98] </ref>. Further complicating matters, minimizing the error for perspective transformations is easier when done in homogeneous space rather than 2D space, again since the latter yields an 88 linear system rather than a difficult nonlinear optimization problem. <p> We therefore included sum-of-square and maximum error methods for the first four (non-perspective) transformation types. For perspective, we included sum-of-square minimization in homogeneous space (yielding a linear system as described above), maximum error in homogeneous space (using the technique of <ref> [Gill81] </ref>), and sum-of-square minimization in nonhomogeneous space (post-perspective divide), using gradient descent. 5 The starting point Minimization of the maximum nonhomogeneous error seemed wholly impractical for real-time implementation. 3D Shape Frame 0 Frame 1 DA T 0 to the screen to find a transform A that best matches the original points
Reference: [Greene93] <author> Hierarchical Z-Buffer Visibility, Ned Greene, Michael Kass, Gavin Miller, </author> <booktitle> SIGGRAPH 93, </booktitle> <pages> pp. 231-238. </pages>
Reference: [Greene94] <author> Error-Bounded Antialiased Rendering of Complex Environments, Ned Greene and Michael Kass, </author> <booktitle> SIGGRAPH 94, </booktitle> <pages> pp. 59-66. </pages>
Reference: [Guenter95] <author> Specializing Shaders, Brian Guenter, Todd B. Knoblock, and Erik Ruf, </author> <booktitle> SIGGRAPH 95, </booktitle> <pages> pp. 343-350. </pages>
Reference-contexts: We harness simpler image transformations (affine rather than perspective) to achieve greater fidelity (Section 4.2). Our work also treats dynamic geometry. Shading expressions [Cook84, Hanrahan90] have been studied extensively. [Dorsey95] factors shading expressions by light source and linearly combines the resulting images in the final display. <ref> [Guenter95] </ref> caches intermediate results. [Meier96] uses image processing techniques to factor shadow and highlight regions into separate layers which are then re-rendered using painterly techniques and finally composited. <p> This shading model can be factored into three layers: S, ( )N L T 1 , and ( )N L T 2 , which are composited to produce the final image. The fact that this expression can be reordered and partial results cached is well known <ref> [Guenter95] </ref>. What we observe here is that each of these factors may be given different sampling resolutions in space and time, and interpolated to display resolutions. As an aside, we believe shade sprites will be useful in authoring.
Reference: [Hanrahan90] <editor> A Language for Shading and Lighting Calculations, Pat Hanrahan and Jim Lawson, </editor> <booktitle> SIGGRAPH 90, </booktitle> <pages> pp. 289-298. </pages>
Reference-contexts: This is conceptually similar to our work, but does not include the factoring across shading or the idea of real-time regulation of quality parameters. We harness simpler image transformations (affine rather than perspective) to achieve greater fidelity (Section 4.2). Our work also treats dynamic geometry. Shading expressions <ref> [Cook84, Hanrahan90] </ref> have been studied extensively. [Dorsey95] factors shading expressions by light source and linearly combines the resulting images in the final display. [Guenter95] caches intermediate results. [Meier96] uses image processing techniques to factor shadow and highlight regions into separate layers which are then re-rendered using painterly techniques and finally composited.
Reference: [Hofmann89] <institution> The Calculus of the NonExact Perspective Projection, </institution> <note> SceneShifting for Computer Animation. </note> <author> Georg Rainer Hofmann. </author> <title> Tutorial Notes for Computer Animation, </title> <type> Eurographics 89. </type>
Reference-contexts: Taking advantage of temporal coherence has been an ongoing theme in computer graphics [Hubschman81, Shelley82]. <ref> [Hofmann89] </ref> presents techniques for measuring how much camera In a prototype implementation of Talisman, the compositor is planned to run at 320M pixels/second compared to 40Mps for the renderer. 2 Penetrating z-sprites will have a pointsampled and thus aliased boundary where visibility switches. 3 Postwarping of unfactored z-images also fails to
Reference: [Horvitz96] <institution> Flexible Rendering of 3D Graphics Under Varying Resources: </institution> <note> Issues and Directions, </note> <editor> Eric Horvitz and Jed Lengyel, </editor> <booktitle> In Symposium on Flexible Computation, AAAI Notes FS-96-06, </booktitle> <pages> pp. 81-88. </pages> <note> Also available as Microsoft Technical Report MSR-TR-96-18. </note>
Reference-contexts: Visibility Fiducials Visibility fiducials measure potential visibility artifacts by tracking back-facing to front-facing transitions in the characteristic geometry (the simplified geometry makes these calculations tractable), and testing if the edges of clipped sprites become visible. 6 Regulation A more complete treatment of regulation issues and directions may be found in <ref> [Horvitz96] </ref>. Our prototype regulator uses a simple cost-benefit scheduler and fiducial thresholds. The fiducial threshold provides a cutoff below which no attempt to re-render the layer is made (i.e., the image warp approximation is used). The regulator considers each frame separately, and performs the following steps: 1.
Reference: [Horvitz97] <editor> Decision-Theoretic Regulation of Graphics Rendering, Eric Horvitz and Jed Lengyel, </editor> <booktitle> In Thirteenth Conference on Uncertainty in Artificial Intelligence, </booktitle> <editor> D. Geiger and P. Shenoy, eds., </editor> <month> August </month> <year> 1997. </year>
Reference-contexts: More work is needed on the seam artifact (handling the boundaries of contiguous geometry placed in separate sprites.) Better modeling of the perceptual effects of regulation parameters is another area of future work <ref> [Horvitz97] </ref>. Factoring of shading terms is currently done using a fixed shading model that targets only the addition and over operations provided by hardware. Compilation of programmable shaders into layerable terms is an important extension.
Reference: [Hubschman81] <editor> Frame to Frame Coherence and the Hidden Surface Computation: </editor> <title> Constraints for a Convex World, </title> <editor> Harold Hubschman, and Steven W. Zucker, </editor> <booktitle> SIGGRAPH 81, </booktitle> <pages> pp. 45-54. </pages>
Reference-contexts: Taking advantage of temporal coherence has been an ongoing theme in computer graphics <ref> [Hubschman81, Shelley82] </ref>. [Hofmann89] presents techniques for measuring how much camera In a prototype implementation of Talisman, the compositor is planned to run at 320M pixels/second compared to 40Mps for the renderer. 2 Penetrating z-sprites will have a pointsampled and thus aliased boundary where visibility switches. 3 Postwarping of unfactored z-images also
Reference: [Kay86] <author> Ray Tracing Complex Scenes, Timothy L. Kay and James T. Kajiya, </author> <booktitle> SIGGRAPH 86, </booktitle> <pages> pp. 269-278. </pages>
Reference-contexts: To choose the affine transform that gives the tightest fit, we first project the vertices of the characteristic bounding polyhedron to the screen, clipping to the expanded sprite extent. Then, using discrete directions (from 2-30, depending on the desired tightness), we calculate 2D bounding slabs <ref> [Kay86] </ref>. Alternately, the slab directions may be chosen by embedding preferred axes in the original model, and transforming the axes to screen space. Using the bounding slabs, we find the bounding rectangle with the smallest area (Figure 10). The origin and edges of the rectangle determine the affine matrix.
Reference: [Maciel95] <editor> Visual Navigation of Large Environments Using Textured Clusters, Paolo W. C. Maciel and Peter Shirley, </editor> <booktitle> Proceedings 1995 Symposium on Interactive 3D Graphics, </booktitle> <month> April </month> <year> 1995, </year> <pages> pp. 95-102. </pages>
Reference-contexts: The specific contributions of this paper include extending the generality of factoring. While some authors have considered factoring over static geometric objects <ref> [Regan94, Maciel95, Shade96, Schaufler96ab] </ref>, we consider dynamic situations and factoring over shading expressions (Section 2). We describe how to render using the layered pipeline (Section 3). We investigate different types of sprite transformations and show why an affine transformation is a good choice (Section 4). <p> We add sprite resolution and update rate to the set of regulated parameters and make photometric measurements rather than relying on a priori assignment of benefit to sampling rate. <ref> [Maciel95] </ref> takes a similar approach but use fiducials and impostor representations optimized for walkthroughs of static scenes.
Reference: [Mark97] <author> Post-Rendering 3D Warping, William R. Mark, Leonard McMillan, and Gary Bishop, </author> <booktitle> Proceedings 1997 Symposium on Interactive 3D Graphics, </booktitle> <month> April </month> <year> 1997, </year> <pages> pp. 7-16. </pages>
Reference-contexts: sprite composition is for free (i.e., sacrifices few rendering resources) and very high speed (because of sprite compression and the simplicity of sprite composition in relation to rendering). 1 1.2 Previous Work To avoid visibility sorting of layers, alternative architectures use what are essentially sprites with z information per pixel <ref> [Molnar92, Regan94, Mark97] </ref>. Such systems are more costly in computation, bandwidth, and storage requirements since z must be stored and transmitted to a more complicated compositor. Z information is also difficult to interpolate and compress.
Reference: [Meier96] <editor> Painterly Rendering for Animation, Barbara J. Meier, </editor> <booktitle> SIGGRAPH 96, </booktitle> <pages> pp. 477-484. </pages>
Reference-contexts: Our work also treats dynamic geometry. Shading expressions [Cook84, Hanrahan90] have been studied extensively. [Dorsey95] factors shading expressions by light source and linearly combines the resulting images in the final display. [Guenter95] caches intermediate results. <ref> [Meier96] </ref> uses image processing techniques to factor shadow and highlight regions into separate layers which are then re-rendered using painterly techniques and finally composited.
Reference: [Molnar92] <author> PixelFlow: </author> <title> HighSpeed Rendering Using Image Composition, </title> <editor> Steve Molnar, John Eyles, and John Poulton, </editor> <booktitle> SIGGRAPH 92, </booktitle> <pages> pp. 231-240. </pages>
Reference-contexts: sprite composition is for free (i.e., sacrifices few rendering resources) and very high speed (because of sprite compression and the simplicity of sprite composition in relation to rendering). 1 1.2 Previous Work To avoid visibility sorting of layers, alternative architectures use what are essentially sprites with z information per pixel <ref> [Molnar92, Regan94, Mark97] </ref>. Such systems are more costly in computation, bandwidth, and storage requirements since z must be stored and transmitted to a more complicated compositor. Z information is also difficult to interpolate and compress.
Reference: [McMillan95] <author> Plenoptic Modeling: </author> <title> An Image-Based Rendering System, </title> <editor> Leonard McMillan, Gary Bishop, </editor> <booktitle> SIGGRAPH 95, </booktitle> <pages> pp. 39-46. </pages>
Reference-contexts: 3 Postwarping of unfactored z-images also fails to address the case of independently moving objects. movement is allowed before changes in the projected geometry exceed a given tolerance. [Chen93, Chen95] show how to take advantage of coherence between viewpoints to produce nearly constant cost per frame walkthroughs of static environments. <ref> [McMillan95] </ref> reprojects images to produce an arbitrary view. Our use of temporal coherence is most similar to [Regan94], who observed that not all objects need updating at the display rate.
Reference: [Porter84] <editor> Compositing Digital Images, Thomas Porter and Tom Duff, </editor> <volume> SIG-GRAPH 84, </volume> <pages> pp. 253-259. </pages>
Reference-contexts: The layered pipeline decouples rendering of layers from their display. Specifically, the sprite transformation may be updated more frequently than the sprite image. Rendering (using 3D CG) updates the sprite image only when needed. Sprite transforming and compositing <ref> [Porter84] </ref> occur at display rates. The sprite transformation scales low-resolution sprites up to the display resolution, and transforms sprites rendered earlier to approximate their later appearance. In other words, the sprite transformation interpolates rendered image streams to display resolution in both space and time. <p> Sprite composition is limited to the over operator <ref> [Porter84] </ref>. Although our experiments assume the Talisman reference architecture, the ideas can be usefully applied to traditional architectures. Layer composition can be emulated with rendering hardware that supports texture mapping with transparency by dedicating some of the pixel-fill rate of the renderer for sprite composition.
Reference: [Regan94] <editor> Priority Rendering with a Virtual Reality Address Recalculation Pipeline, Matthew Regan and Ronald Pose, </editor> <booktitle> SIGGRAPH 94, </booktitle> <pages> pp. 155-162. </pages>
Reference-contexts: The specific contributions of this paper include extending the generality of factoring. While some authors have considered factoring over static geometric objects <ref> [Regan94, Maciel95, Shade96, Schaufler96ab] </ref>, we consider dynamic situations and factoring over shading expressions (Section 2). We describe how to render using the layered pipeline (Section 3). We investigate different types of sprite transformations and show why an affine transformation is a good choice (Section 4). <p> sprite composition is for free (i.e., sacrifices few rendering resources) and very high speed (because of sprite compression and the simplicity of sprite composition in relation to rendering). 1 1.2 Previous Work To avoid visibility sorting of layers, alternative architectures use what are essentially sprites with z information per pixel <ref> [Molnar92, Regan94, Mark97] </ref>. Such systems are more costly in computation, bandwidth, and storage requirements since z must be stored and transmitted to a more complicated compositor. Z information is also difficult to interpolate and compress. <p> Our use of temporal coherence is most similar to <ref> [Regan94] </ref>, who observed that not all objects need updating at the display rate.
Reference: [Segal92] <editor> Fast Shadows and Lighting Effects Using Texture Mapping, Mark Segal, Carl Korobkin, Rolf van Widenfelt, Jim Foran, Paul Haeberli, </editor> <volume> SIG-GRAPH 92, </volume> <pages> pp. 249-252. </pages>
Reference-contexts: The layers shown in the figure represent post-modulation images using the same camera. With traditional architectures, the three layers are combined in the frame buffer using pixel blend operations supported by the 3D hardware, as described in <ref> [Segal92] </ref>. Shadows and reflections may instead be separated into layers as shown in Figure 6, so that the blend takes place in the compositor rather than the renderer. We call these shade sprites in reference to shade trees [Cook84].
Reference: [Schaufler96a] <editor> Exploiting Frame to Frame Coherence in a Virtual Reality System, Gernot Schaufler, </editor> <booktitle> Proceedings of VRAIS 96, </booktitle> <month> April </month> <year> 1996, </year> <pages> pp. 95-102. </pages>
Reference: [Schaufler96b] <editor> A Three Dimensional Image Cache for Virtual Reality, Gernot Schaufler and Wolfgang Strzlinger, </editor> <booktitle> Proceedings of Eurographics 96, </booktitle> <month> August </month> <year> 1996, </year> <pages> pp. 227-235. </pages>
Reference: [Shade96] <institution> Hierarchical Image Caching for Accelerated Walkthroughs of Complex Environments, </institution> <note> Jonathan Shade, </note> <editor> Dani Lischinski, David Salesin, Tony DeRose, John Snyder, </editor> <booktitle> SIGGRAPH 96, </booktitle> <pages> pp. 75-82. </pages>
Reference-contexts: The specific contributions of this paper include extending the generality of factoring. While some authors have considered factoring over static geometric objects <ref> [Regan94, Maciel95, Shade96, Schaufler96ab] </ref>, we consider dynamic situations and factoring over shading expressions (Section 2). We describe how to render using the layered pipeline (Section 3). We investigate different types of sprite transformations and show why an affine transformation is a good choice (Section 4). <p> Rather than factoring globally across object sets requiring a common update rate, our scheme factors over geometric objects and shading model terms, and accounts for relative motion between dynamic objects. <ref> [Shade96] </ref> and [Schaufler96ab] use image caches and texture-mapped quadrilaterals to warp the image. This is conceptually similar to our work, but does not include the factoring across shading or the idea of real-time regulation of quality parameters. <p> We also included a perspective transformation derived using the method of <ref> [Shade96] </ref>, in which objects are replaced by a quadrilateral placed perpendicular to the view direction and through the center of the objects bounding box. Our derivation projects the characteristic points onto this quadrilateral, bounds the projected points with a rectangle, and projects the corners of the rectangle to the screen. <p> The contiguous landscape geometry was split into separate sprites. As an authoring preprocess, the geometry along the split boundaries was expanded to allow for small separation of the warped sprites (the seam artifact.) This is similar to the expansion of the geometry along the split used by <ref> [Shade96] </ref>. More work is needed for automatic determination of the geometric expansion and better blending along the split boundaries. The resource-use graph in Figure 22 shows three types of regulation.
Reference: [Shelley82] <editor> Path Specification and Path Coherence, Kim L. Shelley and Donald P. Greenberg, </editor> <booktitle> SIGGRAPH 82, </booktitle> <pages> pp. 157-166. </pages>
Reference-contexts: Taking advantage of temporal coherence has been an ongoing theme in computer graphics <ref> [Hubschman81, Shelley82] </ref>. [Hofmann89] presents techniques for measuring how much camera In a prototype implementation of Talisman, the compositor is planned to run at 320M pixels/second compared to 40Mps for the renderer. 2 Penetrating z-sprites will have a pointsampled and thus aliased boundary where visibility switches. 3 Postwarping of unfactored z-images also
Reference: [Snyder97] <institution> Visibility Sorting for Dynamic, </institution> <note> Aggregate Geometry, </note> <author> John Snyder, </author> <type> Microsoft Technical Report, </type> <institution> MSR-TR-97-11. </institution>
Reference-contexts: We have implemented a preliminary algorithm for which we provide a sketch here. A full discussion along with experimental results is in progress <ref> [Snyder97] </ref>. To determine visibility order for layers containing moving geometry, we construct an incrementally changing kd-tree based on a set of constant directions.
Reference: [Torborg96] <author> Talisman: </author> <title> Commodity Real-time 3D Graphics for the PC, </title> <editor> Jay Torborg, Jim Kajiya, </editor> <booktitle> SIGGRAPH 96, </booktitle> <pages> pp. 353-364. </pages>
Reference-contexts: Slowly changing or unimportant layers are updated at lower frame rates, at lower resolution, and with higher compression. Address: One Microsoft Way, Redmond, WA 98052-6399 Email: jedl@microsoft.com, johnsny@microsoft.com 1.1 The Layered Pipeline and Talisman The Talisman reference hardware architecture was designed to support the layered pipeline (see <ref> [Torborg96] </ref> for details.) Rendering occurs within one 3232 chunk at a time, so that z-buffer and fragment information for antialiasing can be stored on-chip. The resulting sprites with alpha channel are compressed and written to sprite memory.

References-found: 30

