URL: http://www.cs.umd.edu/users/kutluhan/Papers/thesis.ps.gz
Refering-URL: http://www.cs.umd.edu/users/kutluhan/
Root-URL: 
Title: Hierarchical Task Network Planning: Formalization, Analysis, and Implementation  
Author: Dana S. Nau 
Degree: Kutluhan Erol, Doctor of Philosophy, 1995  Associate Professor James Hendler  
Affiliation: Department of Computer Science  Department of Computer Science  
Note: Abstract Title of Dissertation:  Dissertation directed by: Professor  
Abstract: Planning is a central activity in many areas including robotics, manufacturing, space mission sequencing, and logistics. As the size and complexity of planning problems grow, there is great economic pressure to automate this process in order to reduce the cost of planning effort, and to improve the quality of produced plans. AI planning research has focused on general-purpose planning systems which can process the specifications of an application domain and generate solutions to planning problems in that domain. Unfortunately, there is a big gap between theoretical and application oriented work in AI planning. The theoretical work has been mostly based on state-based planning, which has limited practical applications. The application-oriented work has been based on hierarchical task network (HTN) planning, which lacks a theoretical foundation. As a result, in spite of many years of research, building planning applications remains a formidable task. The goal of this dissertation is to facilitate building reliable and effective planning applications. The methodology includes design of a mathematical framework for HTN planning, analysis of this framework, development of provably correct algorithms based on this analysis, and the implementation of these algorithms for further evaluation and exploration. The representation, analyses, and algorithms described in this thesis will make it easier to apply HTN planning techniques effectively and correctly to planning applications. The precise and mathematical nature of the descriptions will also help teaching about HTN planning, will clarify misconceptions in the literature, and will stimulate further research. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. V. Aho, J. E. Hopcroft, and J. D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1976. </year>
Reference: [2] <editor> J. Allen, J. Hendler, and A. Tate. </editor> <booktitle> Readings in Planning. </booktitle> <publisher> Morgan Kaufman, </publisher> <year> 1990. </year>
Reference-contexts: It is by no means intended as a comprehensive review of the literature, which can be found in the collection of papers edited by Allen, Hendler, and Tate <ref> [2] </ref>. The first section of this chapter describes the roots of classical AI planning. The second section contains a brief overview of some of the planning systems that evolved from these roots. Section 3 discusses the theoretical work on planning. <p> NOAH was applied to mechanical engineers apprentice supervision, NONLIN was applied to electricity turbine overhaul, DEVISER was applied to Voyager spacecraft mission sequencing, and SIPE was applied to aircraft carrier mission planning <ref> [2] </ref>. 2.2.6 Filter Conditions Filter conditions were introduced in NONLIN [64] as a mechanism to reduce the size of the search space by detecting and filtering out undesirable solutions in early stages of planning. For example, consider a medical domain.
Reference: [3] <author> James Allen, Henry Kautz, Richard Pelavin, and Josh Tenenberg. </author> <title> Reasoning about Plans. </title> <publisher> Morgan-Kaufmann, </publisher> <year> 1991. </year>
Reference: [4] <author> Scott Andrews, Brian Kettler, Kutluhan Erol, and Jaes Hendler. </author> <title> UM Translog: A planning domain for the development and benchmarkingof planning systems. </title> <type> Technical Report CS-TR-3487, </type> <institution> University of Maryland at College Park, Dept. of Computer Science, </institution> <year> 1995. </year>
Reference-contexts: UM Translog is a planning domain designed specifically for this purpose by Andrews, Kettler, and myself <ref> [4] </ref>. This section provides a brief description of the UM 95 Translog domain from that paper. The full domain specification is available online at: http://www.cs.umd.edu/projects/plus/UMT. UM Translog was inspired by the CMU Transport Logistics domain developed by Manuela Veloso [67]. <p> When the produced solutions are incorrect, it may take considerable effort to find out whether there is a mistake in the domain specifications, or a bug in the planner code. For example, developing specifications for the UM Translog Domain <ref> [4] </ref> involved several months of debugging both the NONLIN planning system, and the domain specification. Developing specifications for the same domain in the HTN language took little effort, even considering the experience from the same job on NONLIN.
Reference: [5] <author> F. Baader. </author> <title> A formal definition for expressive power of knowledge representation languages. </title> <booktitle> In 9th European Conference on Artificial Intelligence, </booktitle> <address> Stockholm, Sweden, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: A better understanding of the relationship between two planning paradigms can facilitate adaptation of the results and techniques developed in one paradigm to the other. Chapter 5 contains several definitions of expressivity for planning languages, extending the previous work on knowledge representation languages <ref> [5] </ref>. Based on these definitions, the HTN language can be evaluated in terms of expressive power in comparison to the STRIPS language, which is the de facto standard state-based planning language. This work proves that the HTN language is strictly more expressive than the STRIPS language. <p> Transformations can also be considered as translations between planning languages. Whenever there is a transformation from L 1 to L 2 , a planner for L 2 can solve problems represented in L 1 by first translating them into L 2 . 5.1.2 Model-Theoretic Expressivity Baader <ref> [5] </ref> has presented a model-theoretic definition of expressivity for knowledge representation languages. The following is a description of Baader's definition of expressivity and how it can be adapted for planning languages.
Reference: [6] <author> F. Bacchus and Q. Yang. </author> <title> Downward refinement, and the efficiency of hiearchical problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 71, </volume> <year> 1994. </year>
Reference-contexts: Yang and Bacchus have identified several properties of abstraction hierarchies as potential indicators of how well they would perform <ref> [6] </ref>. Particularly,they have identified the downward refinement property, which basically states that any solution at an abstraction level can be refined to a final solution, and thus no backtracking across abstraction levels is required.
Reference: [7] <author> C. Backstrom and P. Jonsson. </author> <title> Planning with abstraction hierarchies can be exponentially less efficient. </title> <booktitle> In Proc. IJCAI-95, </booktitle> <address> Montreal, </address> <year> 1995. </year>
Reference-contexts: Hence the abstraction hierarchies generated by ALPINE have the ordered monotonicity property. Knoblock's experiments on several planning domains, including "Towers of Hanoi," has indicated that planning using such a hierarchy usually reduces planning time. However, recently, Backstrom <ref> [7] </ref> has shown that there exist planning 26 problems for which abstraction hierarchies satisfying the ordered monotonicity property may work poorly. Yang has also worked extensively on abstraction hierarchies, collaborating with a number of researchers.
Reference: [8] <author> Christer Backstrom and Inger Klein. </author> <title> Planning in polynomial time: the sas-pubs class. </title> <booktitle> Computational Intelligence, </booktitle> <pages> pages pp. 181-197, </pages> <year> 1991. </year>
Reference-contexts: Bylander has also studied average-case complexity of propositional STRIPS-style planning under various assumptions as can be found in [14]. Backstrom has done a complexity analysis of a planning representation equivalent to STRIPS representation with similar results <ref> [8] </ref>. 2.3.4 Abstraction Hierarchies Abstraction hierarchies were originally introduced in the ABSTRIPS [60] system, as described in Section 2.2. ABSTRIPS used heuristic methods in assigning criticality levels to predicates, to determine which of those conditions the planner should try to accomplish first.
Reference: [9] <author> A. Barrett. </author> <title> Frugal task decomposition. </title> <type> Technical Report Unpublished manuscript, </type> <institution> Computer Science Dept., University of Washington, </institution> <address> Seattle, Washington, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Kambhampati and Yang [33, 74] provided the initial steps towards developing a formal model of HTN planning, which the work described in this dissertation has extensively benefited from. Barrett <ref> [9] </ref> and Young [78] have incorporated task decomposition techniques to their planning systems as a tool for increasing the speed of state-based planning. The general idea was to encapsulate heuristic fast ways of accomplishing conditions via task decompositions.
Reference: [10] <author> A. Barrett and D. Weld. </author> <title> Partial order planning. </title> <type> Technical Report TR 92-05-01, </type> <institution> Computer Science Dept., University of Washington, </institution> <address> Seattle, Washington, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: The state-based planning paradigm has been deeply investigated. The representation (i.e., the STRIPS language) has been precisely defined, and the flaws in its semantics have been corrected [47, 45]. Many algorithms for finding plans have been developed and investigated <ref> [60, 15, 46, 10, 41, 54] </ref>. The computational complexity of solving planning problems represented in the STRIPS language has been studied in detail [12, 15, 22]. <p> Minton, et. al. have shown that UA's search space is never bigger than that of TO, and in some cases it can be exponentially smaller than that of TO. Barrett and Weld have also studied partial order versus total order planning <ref> [10] </ref>. Their 27 intuition was that, in some planning problems, a partial order planner like SNLP [46] can easily find the correct order to achieve subgoals while doing conflict resolution, where as a total order planner may need to try many different orderings before finding the right one.
Reference: [11] <author> J. Blythe, O. Etzioni, Y. Gil, R. Joseph, A. Perez, S. Reilly, M. Veloso, and X. Wang. </author> <title> Prodigy 4.0: The manual and tutorial. </title> <type> Technical report, </type> <institution> School of Computer Science, Carnegie Melon University, Pittsburg, Pennsylvenia, </institution> <year> 1992. </year>
Reference-contexts: The degree of linkability in a problem refers to how much backtracking a causal link planner such as SNLP needs to do on the problem, because it has committed to the wrong step to establish a condition. They compare the performance of SNLP to PRODIGY <ref> [11] </ref>, which is a total-order planner, and show that SNLP performs much more slower than PRODIGY in several problems where goals are laboriously linkable. In recent years, several studies have been made on causal links, and the tradeoffs involved in it [36, 56, 61, 34].
Reference: [12] <author> T. Bylander. </author> <title> Complexity results for planning. </title> <booktitle> In IJCAI-91, </booktitle> <pages> pages 274-279, </pages> <year> 1991. </year> <month> 154 </month>
Reference-contexts: Many algorithms for finding plans have been developed and investigated [60, 15, 46, 10, 41, 54]. The computational complexity of solving planning problems represented in the STRIPS language has been studied in detail <ref> [12, 15, 22] </ref>. In spite of all this effort, state-based planning has been used mostly in the realm of simple "toy" domains, which were designed for research purposes only. <p> exists of length k given yes yes/no pspace-complete * pspace-complete in the yes np-complete * np-complete input no no p * np-complete no fi /no fl nlogspace-comp. np-complete fixed in yes/no yes/no constant constant advance time time fi No operator has more than one precondition. * Results due to Bylander <ref> [12] </ref>. 24 results. The complexity results are shown in Tables 2.2 and 2.3. <p> Delete lists are more powerful than negated preconditions. Thus, if the operators are allowed to have delete lists, then whether or not they have negated preconditions has no effect on the complexity. Several other researchers have studied the complexity of STRIPS-style planning. Some of Bylander's results <ref> [12] </ref> have been displayed in Table 2.3 and indicated as such. Bylander has also studied average-case complexity of propositional STRIPS-style planning under various assumptions as can be found in [14]. <p> Chapter 5 presents several polynomial transformations from STRIPS-style planning problems to totally ordered HTN planning problems. These transformations can be combined with the complexity results on STRIPS-style planning in <ref> [22, 12] </ref> to establish a lower bound on the complexity of totally-ordered HTN planning. Thus: Theorem 7 plan existence is expspace-hard and in double-exptime if P is restricted to be totally ordered. plan existence is pspace-hard and in exptime if P is further restricted to be propositional. <p> In the propositional case we have only a linear number of atoms, and as a result, the size of any state is polynomial. Thus the algorithm requires only polynomial space. Hardness: In <ref> [12, 22] </ref>, it is shown that plan existence problem in STRIPS representation is pspace-complete if it is restricted to be propositional. The reduction from STRIPS style planning that we presented in the hardness proof of Theorem 8 also works for the propositional case.
Reference: [13] <author> T. Bylander. </author> <title> Complexity results for extended planning. </title> <booktitle> In First Internat. Conf. AI Planning Systems, </booktitle> <year> 1992. </year>
Reference: [14] <author> T. Bylander. </author> <title> An avarage-case analysis of planning. </title> <booktitle> In AAAI-93, </booktitle> <pages> pages 480-485, </pages> <year> 1993. </year>
Reference-contexts: Several other researchers have studied the complexity of STRIPS-style planning. Some of Bylander's results [12] have been displayed in Table 2.3 and indicated as such. Bylander has also studied average-case complexity of propositional STRIPS-style planning under various assumptions as can be found in <ref> [14] </ref>. Backstrom has done a complexity analysis of a planning representation equivalent to STRIPS representation with similar results [8]. 2.3.4 Abstraction Hierarchies Abstraction hierarchies were originally introduced in the ABSTRIPS [60] system, as described in Section 2.2.
Reference: [15] <author> David Chapman. </author> <title> Planning for conjunctive goals. </title> <journal> Artificial Intelligence, </journal> <volume> 32 </volume> <pages> 333-378, </pages> <year> 1987. </year>
Reference-contexts: The state-based planning paradigm has been deeply investigated. The representation (i.e., the STRIPS language) has been precisely defined, and the flaws in its semantics have been corrected [47, 45]. Many algorithms for finding plans have been developed and investigated <ref> [60, 15, 46, 10, 41, 54] </ref>. The computational complexity of solving planning problems represented in the STRIPS language has been studied in detail [12, 15, 22]. <p> Many algorithms for finding plans have been developed and investigated [60, 15, 46, 10, 41, 54]. The computational complexity of solving planning problems represented in the STRIPS language has been studied in detail <ref> [12, 15, 22] </ref>. In spite of all this effort, state-based planning has been used mostly in the realm of simple "toy" domains, which were designed for research purposes only. <p> It does not matter which techniques are used (total-order, partial order, regression, etc.) for producing the plan. Thus according to this definition, STRIPS [24], SNLP [46], and TWEAK <ref> [15] </ref> are state-based planners. A planning system that represents planning problems as task networks, and uses task decomposition to construct the final plan is called a hierarchical task network (HTN) planner. Sometimes these terms are used with different meanings in the literature. <p> Typically, the precondition lists, add lists and delete lists contain only atoms, and the goal is a conjunct of ground or existentially quantified atoms. This representation has become the de facto standard STRIPS representation, used by most of the state-based planning systems <ref> [15, 46, 77] </ref>. The description of the STRIPS representation below, which I developed jointly with Dr. Nau and Dr. Subrahmanian [22], is in accordance with this formulation. Definition 1 Let L be any first-order language generated by finitely many constant symbols, predicate symbols, and function symbols. <p> The most influential algorithms among those have been TWEAK <ref> [15] </ref> by Chapman in 1987, SNLP [46] by McAllester in 1991, and UCPOP [54] by Penberthy and Weld in 1992. This section contains a brief overview of these planning algorithms. 18 2.3.2.1 TWEAK TWEAK [15] is the first provably correct partial-order planning algorithm. <p> The most influential algorithms among those have been TWEAK <ref> [15] </ref> by Chapman in 1987, SNLP [46] by McAllester in 1991, and UCPOP [54] by Penberthy and Weld in 1992. This section contains a brief overview of these planning algorithms. 18 2.3.2.1 TWEAK TWEAK [15] is the first provably correct partial-order planning algorithm. It works with incomplete plans, which are iteratively refined to a complete solution. An incomplete plan in TWEAK consists of a set of plan steps. Each step is associated with an operator. <p> At the heart of the TWEAK algorithm lies a definition called the modal truth criterion for evaluating a condition when the steps of the plan are only partially ordered. The modal truth criterion is defined as follows: <ref> [15] </ref> A proposition p is necessarily true in a situation s iff two conditions hold: there is a situation t equal or necessarily previous to s in which p is necessarily asserted; and for every step C possibly before s and every proposition q possibly codesignating with p which C denies, <p> Semidecidable, or recursively enumerable problems are those for which there is no algorithm that always terminates when the input problem has no solution. Semidecidable problems are sometimes, informally referred to as undecidable problems. 2.3.3.1 Chapman's Undecidability Results In 1987, Chapman <ref> [15] </ref> did the first analysis of the decidability of state-based planning. His results have been very influential in the planning community; however, there has been a certain amount of confusion about what Chapman's undecidability results actually say, because some of his assumptions are embedded in his proofs. <p> To prove this theorem, Chapman makes use of the following assumptions: 1. the planning language is function-free; 2. "an infinite [but recursive] set of constants t i are used to represent the tape squares" <ref> [15, p. 371] </ref>; 3. the initial state is infinite (but recursive). In particular, "there must be countably many successor propositions to encode the topology of the tape (and also countably many contents propositions to make all but finitely many squares blank)" [15, p. 371]. <p> t i are used to represent the tape squares" <ref> [15, p. 371] </ref>; 3. the initial state is infinite (but recursive). In particular, "there must be countably many successor propositions to encode the topology of the tape (and also countably many contents propositions to make all but finitely many squares blank)" [15, p. 371]. This theorem is not particularly strong, considering that planning problems seldomly, if ever, involve infinite initial states. <p> This theorem is not particularly strong, considering that planning problems seldomly, if ever, involve infinite initial states. In fact, in his discussion of the First Undecidability Theorem <ref> [15, p. 344] </ref>, Chapman says: 22 This result is weaker than it may appear : : : the proof uses an infinite (though recursive) initial state to model the connectivity of the tape. <p> The statement of Chapman's second undecidability theorem is that "planning is undecidable even with a finite initial state if the action representation is extended to represent actions whose effects are a function of their input situations" <ref> [15, p. 373] </ref>. The meaning of the phrase "effects are a function of their input situations" has caused some confusion. <p> The presence or absence of operators with context-dependent effects does not influence these results. This work solved an open problem formulated by Chapman in <ref> [15] </ref>: is planning decidable when the language contains infinitely many constants but the initial state is finite. This problem is decidable in the case where the planning operators have no negative preconditions and no delete lists. <p> Chapman's Second Undecidability Theorem states that "planning is undecidable even with a finite initial situation if the action representation is extended to represent actions whose effects are a function of their input situation" <ref> [15] </ref>, i.e., if the language contains function symbols and infinitely many constants. These results show that even with a number of additional restrictions, planning is still undecidable. This work has also provided equivalence theorems relating definite logic programs to planning with positive, deletion-free operators. <p> In fact, part of this work involves developing the necessary mathematical tools and definitions for comparing the expressivity of planning languages. The remaining chapters of the dissertation have focused on developing provably correct, efficient planning algorithms for HTN planning, which is in some ways analogous to what Chapman <ref> [15] </ref> and McAllester [46] accomplished for state-based planning. First, an abstract, but provably correct planning algorithm is developed. Then detailed algorithms are devised for computing the steps of the abstract algorithm. This part of the work also involves designing correct critics mechanisms for HTN planning, based on constraint satisfaction. <p> When the application involves infinite sets of objects such as numbers, these can be dealt 33 with more efficiently using procedural mechanisms instead of reasoning about them using axiomatic approaches. Most planning algorithms work with finitely many constants. TWEAK <ref> [15] </ref> is a particular exception, which relies on the domain to contain infinitely many constant symbols in order to operate correctly. <p> This condition does not need to be strictly enforced, as it does not affect the correctness of the planning algorithm. However, enforcing it may make the planning algorithm more efficient. In contrast to the abundance of well understood STRIPS-style planning algorithms (such as <ref> [24, 15, 46, 35] </ref>), HTN planning algorithms have typically not been proven to be sound or complete. However, using the formalism presented in Sections 3.2 and 3.3, the soundness and completeness of UMCP can be established. <p> This seems largely due to the fact that HTN planning emerged, without a formal description, in implemented planning systems [58, 64]. Many ideas introduced in HTN planning (such as nonlinearity, partial order planning, etc.) were formalized only as they were adapted to STRIPS-style planning, and only within that context <ref> [15, 46, 49, 16, 35] </ref>. The following subsections discuss the view of tasks in this dissertation, and possible alternative views. 3.6.1.1 A View of Tasks as Jobs The formalism described in this chapter views tasks as activities we need to plan, jobs that need to be accomplished. <p> All STRIPS-style planning systems that do precondition chaining (e.g. TWEAK <ref> [15] </ref>, SNLP [46]) exclude such solutions. Nonetheless, it is possible to define polynomial transformations such that any sequence of actions for which the final state satisfies the goal is a valid solution. Figure 5.3 shows one such transformation. This transformation introduces a compound task t. <p> Causal links are also employed by UMCP in the form of special state constraints stored in the Promissory List. SNLP's threat removal process is similar to how UMCP handles those special constraints in its constraint propagation phase. <ref> [15] </ref> introduced the MTC (modal truth criterion) to tell whether a literal is true at a given point in a partially-ordered plan. In order to evaluate state constraints, UMCP uses an extended version of the MTC that also accounts for compound tasks.
Reference: [16] <author> Gregg Collins and Louise Pryor. </author> <title> Achieving the functionality of filter conditions in a partial order planner. </title> <booktitle> In AAAI-92, </booktitle> <pages> pages 375|380, </pages> <year> 1992. </year>
Reference-contexts: This seems largely due to the fact that HTN planning emerged, without a formal description, in implemented planning systems [58, 64]. Many ideas introduced in HTN planning (such as nonlinearity, partial order planning, etc.) were formalized only as they were adapted to STRIPS-style planning, and only within that context <ref> [15, 46, 49, 16, 35] </ref>. The following subsections discuss the view of tasks in this dissertation, and possible alternative views. 3.6.1.1 A View of Tasks as Jobs The formalism described in this chapter views tasks as activities we need to plan, jobs that need to be accomplished. <p> In <ref> [16] </ref>, Collins and Pryor state that filter conditions are ineffective. They argue that filter conditions do not help pruning the search space for partial order planners, because it is not possible to check whether they hold or not in an incomplete plan. <p> seem to argue against the use of filter conditions: at one extreme, using filter conditions immediately to prune the search space sacrifices completeness, and at the other extreme, postponing their use until the plan is complete (so as to preserve completeness) is inefficient. 4 4 In fact, Collins and Pryor <ref> [16] </ref> have made a similar argument against filter conditions in the context of planning with STRIPS-style operators. 88 Although the above argument is partially correct, it ignores a third possibility that lies between the two extremes.
Reference: [17] <author> K. Currie and A. Tate. O-plan: </author> <title> the open planning architecture. </title> <journal> Artificial Intelligence, </journal> <month> November </month> <year> 1991. </year>
Reference-contexts: SIPE employs a taxonomy for storing the features of objects in the planning domain. The UMCP planning system, presented in Chapter 6, uses a similar technique for representing the initial state of a planning problem. The O-PLAN <ref> [17] </ref> system designed in 1991 by Currie and Tate further extended the NONLIN framework to a more general plan creation and execution platform. O-PLAN represents plans using several elaborate types of constraints.
Reference: [18] <author> Thomas Dean. </author> <title> Time map maintenance. </title> <type> Technical Report TR 289, </type> <institution> Yale University, </institution> <address> New Haven, Connecticut, </address> <month> October </month> <year> 1983. </year>
Reference-contexts: Such interactions arise when a side-effect of achieving one goal is to make it easier to achieve another goal. * To handle iteration in plans, Drummond [19] has proposed several extensions to the procedural net, and an extension to Sacerdoti's resolve-conflicts critic. 1 See also <ref> [18] </ref>. 14 * A number of special-purpose "domain-dependent" planning systems have identified interactions occurring only in the particular domain for which the system is being developed. Typically, special-purpose heuristics are introduced to exploit this knowledge.
Reference: [19] <author> M. E. Drummond. </author> <title> Refining and extending the procedural net. </title> <editor> In James Allen, James Hendler, and Austin Tate, editors, </editor> <booktitle> Readings in Planning, </booktitle> <pages> pages 667-674. </pages> <publisher> Morgan Kauf-man, </publisher> <year> 1990. </year>
Reference-contexts: Such interactions arise when a side-effect of achieving one goal is to make it easier to achieve another goal. * To handle iteration in plans, Drummond <ref> [19] </ref> has proposed several extensions to the procedural net, and an extension to Sacerdoti's resolve-conflicts critic. 1 See also [18]. 14 * A number of special-purpose "domain-dependent" planning systems have identified interactions occurring only in the particular domain for which the system is being developed.
Reference: [20] <author> Kutluhan Erol, James Hendler, and Dana Nau. </author> <title> Complexity results for hierarchical task-network planning. </title> <journal> Annals of Mathematics and Artificial Intelligence, (CS-TR-3240, </journal> <volume> UMIACS-TR-94-32), </volume> <year> 1994. </year>
Reference: [21] <author> Kutluhan Erol, James Hendler, and Dana Nau. </author> <title> Semantics for hierarchical task network planning. </title> <type> Technical Report CS-TR-3239, </type> <institution> UMIACS-TR-94-31, Computer Science Dept., University of Maryland, College Park, Maryland, </institution> <month> March </month> <year> 1994. </year>
Reference: [22] <author> Kutluhan Erol, Dana Nau, and V. S. Subrahmanian. </author> <title> Complexity, decidability and undecidability results for domain-independent planning. </title> <journal> Artificial Intelligence, </journal> <note> 1995. To appear. </note>
Reference-contexts: Many algorithms for finding plans have been developed and investigated [60, 15, 46, 10, 41, 54]. The computational complexity of solving planning problems represented in the STRIPS language has been studied in detail <ref> [12, 15, 22] </ref>. In spite of all this effort, state-based planning has been used mostly in the realm of simple "toy" domains, which were designed for research purposes only. <p> This representation has become the de facto standard STRIPS representation, used by most of the state-based planning systems [15, 46, 77]. The description of the STRIPS representation below, which I developed jointly with Dr. Nau and Dr. Subrahmanian <ref> [22] </ref>, is in accordance with this formulation. Definition 1 Let L be any first-order language generated by finitely many constant symbols, predicate symbols, and function symbols. Then a state is any finite set of ground atoms in L. <p> His results have been very influential in the planning community; however, there has been a certain amount of confusion about what Chapman's undecidability results actually say, because some of his assumptions are embedded in his proofs. This confusion has been clarified by Erol, et. al <ref> [22] </ref>, as explained in this section. Chapman's first undecidability theorem ([15, pp. 370-371]) says that all Turing machines with their inputs may be encoded as planning problems in the TWEAK system, and hence planning is undecidable. <p> Nau and Dr. Subrahmanian <ref> [22] </ref>. That work serves to clarify some of Chapman's results and provides a rather comprehensive study of how the complexity of STRIPS-style planning varies depending on a number of conditions. The results are summarized in the Tables 2.1, 2.2, and 2.3. <p> Chapter 5 presents several polynomial transformations from STRIPS-style planning problems to totally ordered HTN planning problems. These transformations can be combined with the complexity results on STRIPS-style planning in <ref> [22, 12] </ref> to establish a lower bound on the complexity of totally-ordered HTN planning. Thus: Theorem 7 plan existence is expspace-hard and in double-exptime if P is restricted to be totally ordered. plan existence is pspace-hard and in exptime if P is further restricted to be propositional. <p> Since the size of a state is at most exponential, the problem can be solved in exponential space. But even with regularity and several other restrictions, it is still possible to reduce the expspace-complete STRIPS-style planning problem (described in <ref> [22] </ref>) to the HTN planning. Thus: 54 Theorem 8 plan existence is expspace-complete if P is restricted to be regular. <p> It is proven in <ref> [22] </ref> that there exists STRIPS-style planning domains for which planning is pspace-complete. Those domains can be transformed into regular HTN planning domains for which planning is pspace-complete. Hence: Theorem 10 If P is restricted to be regular and D is fixed in advance, then plan existence is in pspace. <p> However, with no function symbols, STRIPS-style planning is decidable, regardless of whether or not the planning domain 2 is fixed in advance <ref> [22] </ref>. <p> The constraint formula contains only what needs to be true while we achieve t and what needs to be true immediately after we achieve t. 13. Nondeterministically, choose a method for t, expand it, and assign the resulting task network to d. 14. Go to step 2. Hardness: In <ref> [22] </ref>, we showed that plan existence problem in STRIPS representation is expspace-complete. Here we define a reduction from that problem. <p> In the propositional case we have only a linear number of atoms, and as a result, the size of any state is polynomial. Thus the algorithm requires only polynomial space. Hardness: In <ref> [12, 22] </ref>, it is shown that plan existence problem in STRIPS representation is pspace-complete if it is restricted to be propositional. The reduction from STRIPS style planning that we presented in the hardness proof of Theorem 8 also works for the propositional case. <p> Thus we can reduce it to propositional regular HTN-planning. As a direct consequence of Theorem 9, it is in pspace. In the proof of Theorem 5.17 in <ref> [22] </ref>, we had presented a set of STRIPS operators containing variables for which planning is pspace-complete.
Reference: [23] <author> R. E. Fikes, P. E. Hart, and N. J. Nilsson. </author> <title> Learning and executing generalized robot plans. </title> <editor> In James Allen, James Hendler, and Austin Tate, editors, </editor> <booktitle> Readings in Planning, </booktitle> <pages> pages 189-206. </pages> <publisher> Morgan Kaufman, </publisher> <year> 1990. </year>
Reference-contexts: The general idea was to encapsulate heuristic fast ways of accomplishing conditions via task decompositions. In that aspect, their approach is similar to that of MACROPS <ref> [23] </ref> developed by Fikes et. al. which used predefined sequences of operators (i.e. macros) to provide shortcuts in the search space. 2.4 Discussion As presented throughout Section 2.3, extensive research effort has gone into formalizing and analyzing the ideas embedded in planning systems.
Reference: [24] <author> R. E. Fikes and N. J. Nilsson. </author> <title> Strips: a new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> 2(3/4):189-208, 1971. 
Reference-contexts: Unfortunately, the interaction between the theoretical work and the more pragmatic, application oriented work on AI planning has been limited. The theoretical work on domain-independent planning has been mostly on state-based planning 1 that stemmed from STRIPS <ref> [24] </ref> planning system, with roots in situation calculus [47]. The state-based planning paradigm has been deeply investigated. The representation (i.e., the STRIPS language) has been precisely defined, and the flaws in its semantics have been corrected [47, 45]. <p> Another disadvantage of situation calculus is performance related: general purpose theorem provers cannot exploit the structure of planning problems and thus they are horrendously slow in solving planning problems. Both the representation and the performance issues were addressed in the STRIPS planning system <ref> [24] </ref>. The frame problem was dealt with by the STRIPS assumption: Executing an action does not change the truth value of a condition unless the condition is one of the effects of the action. <p> It does not matter which techniques are used (total-order, partial order, regression, etc.) for producing the plan. Thus according to this definition, STRIPS <ref> [24] </ref>, SNLP [46], and TWEAK [15] are state-based planners. A planning system that represents planning problems as task networks, and uses task decomposition to construct the final plan is called a hierarchical task network (HTN) planner. Sometimes these terms are used with different meanings in the literature. <p> HTN planning systems also use variations of the STRIPS representation for describing the world and change in the world. Thus a good understanding of the STRIPS representation is very important. The STRIPS representation has gone through several changes. In the original STRIPS planner <ref> [24] </ref>, the planning operators' precondition lists, add lists, and delete lists were allowed to contain arbitrary well-formed formulas in first-order logic. However, there were a number of problems with this formulation, such as the difficulty of providing a well-defined semantics for it [45]. <p> This condition does not need to be strictly enforced, as it does not affect the correctness of the planning algorithm. However, enforcing it may make the planning algorithm more efficient. In contrast to the abundance of well understood STRIPS-style planning algorithms (such as <ref> [24, 15, 46, 35] </ref>), HTN planning algorithms have typically not been proven to be sound or complete. However, using the formalism presented in Sections 3.2 and 3.3, the soundness and completeness of UMCP can be established.
Reference: [25] <author> E. C. Freuder and A. K. Mackworth. </author> <title> Special volume on constraint-based reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 58, </volume> <year> 1992. </year>
Reference-contexts: Abstraction hierarchies are given that name because of the abstraction resulting from ignoring some conditions, and the hierarchy consisting of the criticality levels. However, like the variable-ordering heuristics found in the constraint satisfaction literature <ref> [25, 50] </ref>, abstraction hierarchies can also be perceived as a means of deciding which part of the problem to work on next. 10 2.2.3 Relaxation of the Linearity Assumption Planning algorithms based on the linearity assumption could not solve problems containing nonserializable goals.
Reference: [26] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <year> 1979. </year> <month> 155 </month>
Reference-contexts: As computational complexity is measured in terms of the size of the input problem instance, it also means that L 1 is more concise than L 2 . The theory of computational complexity <ref> [26] </ref> is based on transformations (also called reductions) between sets of problem instances.
Reference: [27] <author> R. L. Graham, D. E. Knuth, and O. Patashnik. </author> <title> Concrete Mathematics: A Foundation for Computer Science. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference: [28] <author> Naresh Gupta and Dana S. Nau. </author> <title> On the complexity of blocks-world planning. </title> <journal> Artificial Intelligence, </journal> <volume> bf 5 :2-3:223-254, </volume> <year> 1992. </year>
Reference-contexts: [73] has added a number of different mechanisms for recognizing resource interactions and for allowing user preferences to be considered when making a choice between reductions. * Yang, Nau, and Hendler [76] have introduced a general "action-precedence" interaction that can be exploited in some planning situations. * Nau and Gupta <ref> [28] </ref> have identified "enabling-condition" interactions as the culprit that makes finding optimal plans in the blocks-world domain to be NP-hard.
Reference: [29] <author> Naresh Gupta and Dana S. Nau. </author> <title> On the complexity of blocks-world planning. </title> <journal> Artificial Intelligence, </journal> <volume> 2-3:223-254, </volume> <year> 1992. </year>
Reference-contexts: This is because what makes the problem hard is how to handle enabling-condition interactions, i.e., how to choose operators that achieve several subgoals in order to minimize the overall length of the plan <ref> [29] </ref>, and this task remains equally hard regardless of whether negated preconditions are allowed. 5. Delete lists are more powerful than negated preconditions. Thus, if the operators are allowed to have delete lists, then whether or not they have negated preconditions has no effect on the complexity.
Reference: [30] <author> Steven Hanks and Daniel S. Weld. </author> <title> Systematic adaptation for case-based planning. </title> <booktitle> In First Internat. Conf. AI Planning Systems, </booktitle> <pages> pages 96-105, </pages> <month> June </month> <year> 1992. </year>
Reference: [31] <author> James Hendler. </author> <title> AI Planning Systems. </title> <publisher> Morgan Kaufmann Publishing, </publisher> <address> Palo Alto, CA. </address> <note> To appear. </note>
Reference: [32] <author> Hopcroft and Ullman. </author> <title> Introduction to Automata Theory, Languages and Computation. </title> <publisher> Addison-Wesley Publishing Company Inc., </publisher> <year> 1979. </year>
Reference-contexts: Whether the intersection of the languages of two context-free grammars is non-empty is a semi-decidable problem <ref> [32] </ref>. <p> Membership: We can restate plan existence as 9k sol k (d; I; D) 6= ;. Thus the problem is in 1 . Hardness: Given two context-free grammars G 1 and G 2 , whether L (G 1 ) " L (G 2 ) is non-empty is an undecidable problem <ref> [32] </ref>. We define a reduction from this problem to plan existence as follows: Without loss of generality, assume both G 1 and G 2 have the same binary alphabet , and they are in Chomsky normal form (at most two symbols at the right hand side of production rules). <p> Refer to <ref> [32] </ref> to see how any context-free grammar can be converted into this form. Similarly, assume that the sets of non terminals 1 and 2 for each grammar are disjoint; i.e. 1 " 2 = ;. We also assume neither language contains the empty string.
Reference: [33] <author> Subbara Kambhampati and James. Hendler. </author> <title> A validation structure based theory of plan modification and reuse. </title> <journal> Artificial Intelligence, </journal> <month> May </month> <year> 1992. </year>
Reference-contexts: This issue is discussed in detail in Chapter 4. 2.3.6 Task Networks and Task Decomposition Very few researchers have tried to integrate task decomposition to their models of planning. Kambhampati and Yang <ref> [33, 74] </ref> provided the initial steps towards developing a formal model of HTN planning, which the work described in this dissertation has extensively benefited from. Barrett [9] and Young [78] have incorporated task decomposition techniques to their planning systems as a tool for increasing the speed of state-based planning. <p> Use critics to find the interactions among the tasks in P, and suggest ways to handle them. 7. Apply one of the ways suggested in step 6. 8. Go to step 2. See a show Rent-car ! drive (D.C., L.V.) % & Go (L.V., D.C.) Get rich these algorithms <ref> [74, 33] </ref>. Figure 3.3 presents the essence of these algorithms. As shown in this figure, HTN planning works by expanding tasks and resolving conflicts iteratively, until a conflict-free plan can be found that consists only of primitive tasks. <p> Although this is a perfectly coherent view, it is rather restrictive and there is more to HTN planning, as demonstrated in Chapter 5, where the expressivity results are presented. 3.6.1.3 A View of Tasks as Action Abstraction Yang and Kambhampati <ref> [74, 33] </ref> have viewed tasks as high-level actions. High-level actions have preconditions and effects, just as regular STRIPS operators; however, they can be expanded into lower level actions. Planning proceeds iteratively: goals in the planning problem are established using the highest-level actions first.
Reference: [34] <author> Subbarao Kambhampati. </author> <title> Characterizing multi-contributor causal structures for planning. </title> <booktitle> In First Internat. Conf. AI Planning Systems, </booktitle> <address> Tempe, Arizona, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Tradeoffs between systematicity versus commitment were investigated by Kambhampati in [36]. TWEAK and SNLP represent two opposite extremes in protecting none versus all of the established conditions. In the following years, intermediate techniques, which protect only some of the previously established conditions, were developed <ref> [56, 61, 34] </ref>. 2.3.2.3 UCPOP UCPOP [54] is another sound and complete planning algorithm. It was designed by Weld and Henks in 1992. Rather than the STRIPS language, UCPOP is based on the ADL language developed by Pednault [53] in his dissertation work. <p> They compare the performance of SNLP to PRODIGY [11], which is a total-order planner, and show that SNLP performs much more slower than PRODIGY in several problems where goals are laboriously linkable. In recent years, several studies have been made on causal links, and the tradeoffs involved in it <ref> [36, 56, 61, 34] </ref>. In general, preserving causal links reduces the redundancy in the search space, but increases the branching factor (i.e., the number of ways of establishing a condition). Using causal links may force the planner to commit to the wrong step as an establisher, and cause backtracking.
Reference: [35] <author> Subbarao Kambhampati. </author> <title> On the utility of systematicity: understanding trade-offs between redundancy and commitment in partial-ordering planning. </title> <type> Technical report, </type> <institution> Ari-zona State University, Tempe, Arizona, </institution> <month> December </month> <year> 1992. </year>
Reference-contexts: This condition does not need to be strictly enforced, as it does not affect the correctness of the planning algorithm. However, enforcing it may make the planning algorithm more efficient. In contrast to the abundance of well understood STRIPS-style planning algorithms (such as <ref> [24, 15, 46, 35] </ref>), HTN planning algorithms have typically not been proven to be sound or complete. However, using the formalism presented in Sections 3.2 and 3.3, the soundness and completeness of UMCP can be established. <p> This seems largely due to the fact that HTN planning emerged, without a formal description, in implemented planning systems [58, 64]. Many ideas introduced in HTN planning (such as nonlinearity, partial order planning, etc.) were formalized only as they were adapted to STRIPS-style planning, and only within that context <ref> [15, 46, 49, 16, 35] </ref>. The following subsections discuss the view of tasks in this dissertation, and possible alternative views. 3.6.1.1 A View of Tasks as Jobs The formalism described in this chapter views tasks as activities we need to plan, jobs that need to be accomplished. <p> The utility of systematicity is more debatable. Systematicity avoids redundancy in the search space, thus it was believed to improve the performance of planners; however, as discussed in <ref> [35] </ref>, enforcing systematicity may incur extra overhead in book keeping, which can offset the reduction in the size of the search space.
Reference: [36] <author> Subbarao Kambhampati. </author> <title> On the utility of systematicity: Understanding tradeoffs between redundancy and commitment in partial-order planning. </title> <booktitle> In IJCAI-93, </booktitle> <address> Chambery, France, </address> <year> 1993. </year>
Reference-contexts: This commitment is sometimes premature, and thus a wrong candidate may be selected which results in backtracking later on. SNLP also incurs significant overhead while protecting the causal links. Tradeoffs between systematicity versus commitment were investigated by Kambhampati in <ref> [36] </ref>. TWEAK and SNLP represent two opposite extremes in protecting none versus all of the established conditions. In the following years, intermediate techniques, which protect only some of the previously established conditions, were developed [56, 61, 34]. 2.3.2.3 UCPOP UCPOP [54] is another sound and complete planning algorithm. <p> They compare the performance of SNLP to PRODIGY [11], which is a total-order planner, and show that SNLP performs much more slower than PRODIGY in several problems where goals are laboriously linkable. In recent years, several studies have been made on causal links, and the tradeoffs involved in it <ref> [36, 56, 61, 34] </ref>. In general, preserving causal links reduces the redundancy in the search space, but increases the branching factor (i.e., the number of ways of establishing a condition). Using causal links may force the planner to commit to the wrong step as an establisher, and cause backtracking.
Reference: [37] <author> Subbarao Kambhampati, Craig A. Knoblock, and Qiang Yang. </author> <title> Planning as refinement search: A unified framework for evaluating design tradeoffs in partial order planning. </title> <journal> Artificial Intelligence, </journal> <note> To appear. To appear. </note>
Reference-contexts: Thus it becomes important to make a comparative analysis of these algorithms to see which algorithms are suitable for a given planning application. To facilitate this comparison, Kambhampati, et. al. <ref> [37] </ref>, have suggested a generic planning algorithm into which the numerous planning algorithms can be cast. This generic algorithm is based on planning as refinement search: Most planning algorithms work by refining incomplete plans to a final solution. <p> Apply R to tn and insert the resulting set of task networks into OPEN-LIST. 8. Go to step 3. Those task networks whose set of solutions are determined to be empty are filtered out. In this aspect, UMCP nicely fits into the general refinement search framework described in <ref> [37] </ref>. This algorithm is a deterministic version of the UMCP algorithm presented in Section 3.5. Search is implemented by keeping an OPEN-LIST of task networks that are to be explored.
Reference: [38] <author> Subbarao Kambhampati and Dana S. Nau. </author> <title> On the nature and role of modal truth criteria in planning. </title> <journal> Artificial Intelligence, </journal> <year> 1994. </year>
Reference-contexts: This does not cause a problem for TWEAK since it checks all the preconditions before it halts with a solution. Kambhampati and Nau have investigated this issue in depth and provided alternative definitions to the modal truth criterion <ref> [38] </ref>. 2 In order to ensure that there always exist a ground instantiation that satisfies the noncodesignation constraints on variables, TWEAK assumes the application domain contains infinitely many constant symbols.
Reference: [39] <editor> Laveen Kanal and V. Kumar. </editor> <booktitle> Search in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: To accomplish this UMCP uses a branch-and-bound approach <ref> [39] </ref>. A task network can be thought of as an implicit representation for the set of solutions for that task network. <p> matter of further investigation and experimentation to verify this opinion. 6.1.2 High-level Data Structures for UMCP This section provides a conceptual overview of the high-level data structures used by UMCP. 6.1.2.1 OPEN-LIST UMCP uses OPEN-LIST for its high-level search, which is a well known data structure in the search literature <ref> [39] </ref>. Each new generated node in the search space is inserted to OPEN-LIST, until it is removed for further exploration. Several search strategies can be used in deciding which node to pick and remove from OPEN-LIST at each iteration of the search.
Reference: [40] <author> Brian. P. Kettler. </author> <title> Case-based planning with a massively parallel memory. </title> <type> Technical report, </type> <institution> Dept. of Computer Science, University of Maryland,College Park, College Park, MD., </institution> <year> 1995. </year> <note> In Preparation. </note>
Reference-contexts: HACKER deals with interacting subgoals using the critics mechanism. This procedural mechanism identifies and patches conflicts based on heuristic methods. HACKER stores patches that worked well, to be used later in similar problems. Thus it can be considered as the ancestor of case-based planning systems <ref> [42, 40] </ref>. A case-based planner stores solutions to previous planning problems in a case-base, and solves each new planning problem by adapting the solution of a similar old problem from the case-base.
Reference: [41] <author> Craig A. Knoblock. </author> <title> An analysis of abstrips. </title> <booktitle> In Proceedings of the first International conference on AI Planning Systems, </booktitle> <pages> pages 126-135, </pages> <year> 1992. </year> <month> 156 </month>
Reference-contexts: The state-based planning paradigm has been deeply investigated. The representation (i.e., the STRIPS language) has been precisely defined, and the flaws in its semantics have been corrected [47, 45]. Many algorithms for finding plans have been developed and investigated <ref> [60, 15, 46, 10, 41, 54] </ref>. The computational complexity of solving planning problems represented in the STRIPS language has been studied in detail [12, 15, 22]. <p> ABSTRIPS used heuristic methods in assigning criticality levels to predicates, to determine which of those conditions the planner should try to accomplish first. Knoblock <ref> [41] </ref> has developed an algorithm called ALPINE for assigning criticality levels in such a way that during the planning process, establishing a condition (which possibly requires adding new steps to the plan) cannot clobber the previously established conditions with higher criticality levels. This property is called the ordered monotonicity property.
Reference: [42] <author> Janet Kolodner. </author> <title> Case-Based Reasoning. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1993. </year>
Reference-contexts: HACKER deals with interacting subgoals using the critics mechanism. This procedural mechanism identifies and patches conflicts based on heuristic methods. HACKER stores patches that worked well, to be used later in similar problems. Thus it can be considered as the ancestor of case-based planning systems <ref> [42, 40] </ref>. A case-based planner stores solutions to previous planning problems in a case-base, and solves each new planning problem by adapting the solution of a similar old problem from the case-base.
Reference: [43] <author> Amy L. Lansky. </author> <title> A representation of parallel activity based on events, structure, and causality. </title> <editor> In M. Georgeff and A. Lansky, editors, </editor> <booktitle> Reasoning About Actions and Plans, </booktitle> <pages> pages 123-160. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1987. </year>
Reference: [44] <author> Amy L. Lansky. </author> <title> Localized event-based reasoning for multiagent domains. </title> <journal> Computational Intelligence Journal, </journal> <year> 1988. </year>
Reference-contexts: Tasks and task networks provide a more natural and effective way of representing planning problems than STRIPS-style attainment goals. Lansky <ref> [44] </ref> has promoted this opinion for action-based planning in general. 3.6.1.2 A View of Tasks as Efficiency Hacks One view of HTN planning totally discards compound tasks, and views methods for goal tasks as heuristic information on how to go about achieving the goals (i.e., which operator to use, in which
Reference: [45] <author> Vladimir Lifschitz. </author> <title> On the semantics of strips. </title> <editor> In James Allen, James Hendler, and Austin Tate, editors, </editor> <booktitle> Readings in Planning, </booktitle> <pages> pages 523-531. </pages> <publisher> Morgan Kaufman, </publisher> <year> 1990. </year>
Reference-contexts: The state-based planning paradigm has been deeply investigated. The representation (i.e., the STRIPS language) has been precisely defined, and the flaws in its semantics have been corrected <ref> [47, 45] </ref>. Many algorithms for finding plans have been developed and investigated [60, 15, 46, 10, 41, 54]. The computational complexity of solving planning problems represented in the STRIPS language has been studied in detail [12, 15, 22]. <p> Chapter 6.3 presents a way of implementing domain-independent critics that preserves soundness, completeness, and systematicity, based on that framework. 2.3 Formalization and Analysis Efforts The 1980's brought formal approaches to planning. The semantics of the STRIPS language was freed of flaws <ref> [45] </ref> and brought to its current standard form as presented in Section 2.3.1. A significant amount of research effort went into attempts at formalizing and analyzing the ideas buried inside the implementation details of the systems summarized in Section 2.2. <p> In the original STRIPS planner [24], the planning operators' precondition lists, add lists, and delete lists were allowed to contain arbitrary well-formed formulas in first-order logic. However, there were a number of problems with this formulation, such as the difficulty of providing a well-defined semantics for it <ref> [45] </ref>. Thus, in subsequent work, researchers have placed several restrictions on the 15 nature of the planning operators [52]. Typically, the precondition lists, add lists and delete lists contain only atoms, and the goal is a conjunct of ground or existentially quantified atoms. <p> This part of the dissertation is analogous to the work on the STRIPS language to free it from semantic flaws <ref> [45] </ref>. The second part of the dissertation provides a complexity analysis of HTN planning to give insight into the algorithmic difficulties and bottlenecks, analogous to the complexity analyses on state-based planning, described in Section 2.3.3.
Reference: [46] <author> D. McAllester and D. Rosenblitt. </author> <title> Systematic nonlinear planning. </title> <booktitle> In AAAI-91, </booktitle> <year> 1991. </year>
Reference-contexts: The state-based planning paradigm has been deeply investigated. The representation (i.e., the STRIPS language) has been precisely defined, and the flaws in its semantics have been corrected [47, 45]. Many algorithms for finding plans have been developed and investigated <ref> [60, 15, 46, 10, 41, 54] </ref>. The computational complexity of solving planning problems represented in the STRIPS language has been studied in detail [12, 15, 22]. <p> It does not matter which techniques are used (total-order, partial order, regression, etc.) for producing the plan. Thus according to this definition, STRIPS [24], SNLP <ref> [46] </ref>, and TWEAK [15] are state-based planners. A planning system that represents planning problems as task networks, and uses task decomposition to construct the final plan is called a hierarchical task network (HTN) planner. Sometimes these terms are used with different meanings in the literature. <p> Typically, the precondition lists, add lists and delete lists contain only atoms, and the goal is a conjunct of ground or existentially quantified atoms. This representation has become the de facto standard STRIPS representation, used by most of the state-based planning systems <ref> [15, 46, 77] </ref>. The description of the STRIPS representation below, which I developed jointly with Dr. Nau and Dr. Subrahmanian [22], is in accordance with this formulation. Definition 1 Let L be any first-order language generated by finitely many constant symbols, predicate symbols, and function symbols. <p> The most influential algorithms among those have been TWEAK [15] by Chapman in 1987, SNLP <ref> [46] </ref> by McAllester in 1991, and UCPOP [54] by Penberthy and Weld in 1992. This section contains a brief overview of these planning algorithms. 18 2.3.2.1 TWEAK TWEAK [15] is the first provably correct partial-order planning algorithm. It works with incomplete plans, which are iteratively refined to a complete solution. <p> However, it left out several important ideas such as task networks and task decomposition, which are studied in this dissertation. 2.3.2.2 SNLP SNLP (Systematic Nonlinear Planner) was developed by McAllester in 1990 <ref> [46] </ref>, in an effort to design an efficient, provably correct planning algorithm. There was already a sound and complete planning algorithm TWEAK, described in the previous section; however, TWEAK performs rather slowly on many planning problems. <p> Barrett and Weld have also studied partial order versus total order planning [10]. Their 27 intuition was that, in some planning problems, a partial order planner like SNLP <ref> [46] </ref> can easily find the correct order to achieve subgoals while doing conflict resolution, where as a total order planner may need to try many different orderings before finding the right one. Thus, they introduced the concept of laboriously serializable goals. <p> The remaining chapters of the dissertation have focused on developing provably correct, efficient planning algorithms for HTN planning, which is in some ways analogous to what Chapman [15] and McAllester <ref> [46] </ref> accomplished for state-based planning. First, an abstract, but provably correct planning algorithm is developed. Then detailed algorithms are devised for computing the steps of the abstract algorithm. This part of the work also involves designing correct critics mechanisms for HTN planning, based on constraint satisfaction. <p> First, an abstract, but provably correct planning algorithm is developed. Then detailed algorithms are devised for computing the steps of the abstract algorithm. This part of the work also involves designing correct critics mechanisms for HTN planning, based on constraint satisfaction. Causal links introduced in SNLP <ref> [46] </ref> are modeled as a special type of constraint; they are employed for establishing conditions and preserving systematicity. 29 Chapter 3 HTN Formalism This chapter presents the HTN formalism I have developed. <p> This condition does not need to be strictly enforced, as it does not affect the correctness of the planning algorithm. However, enforcing it may make the planning algorithm more efficient. In contrast to the abundance of well understood STRIPS-style planning algorithms (such as <ref> [24, 15, 46, 35] </ref>), HTN planning algorithms have typically not been proven to be sound or complete. However, using the formalism presented in Sections 3.2 and 3.3, the soundness and completeness of UMCP can be established. <p> This seems largely due to the fact that HTN planning emerged, without a formal description, in implemented planning systems [58, 64]. Many ideas introduced in HTN planning (such as nonlinearity, partial order planning, etc.) were formalized only as they were adapted to STRIPS-style planning, and only within that context <ref> [15, 46, 49, 16, 35] </ref>. The following subsections discuss the view of tasks in this dissertation, and possible alternative views. 3.6.1.1 A View of Tasks as Jobs The formalism described in this chapter views tasks as activities we need to plan, jobs that need to be accomplished. <p> All STRIPS-style planning systems that do precondition chaining (e.g. TWEAK [15], SNLP <ref> [46] </ref>) exclude such solutions. Nonetheless, it is possible to define polynomial transformations such that any sequence of actions for which the final state satisfies the goal is a valid solution. Figure 5.3 shows one such transformation. This transformation introduces a compound task t. <p> The user may override UMCP's choice of refinement strategy and pick another one, and instruct UMCP to refine the current task network. Alternatively, the user can give the "go" command telling UMCP to run to completion. 6.7 Discussion Causal links are used by POCL planners such as SNLP <ref> [46] </ref> to establish preconditions and to detect threats. Causal links are also employed by UMCP in the form of special state constraints stored in the Promissory List.
Reference: [47] <author> J. McCarthy and P.J. Hayes. </author> <title> Some philosophical problems from the standpoint of artificial intelligence. </title> <journal> Machine Intelligence, </journal> <volume> bf 4 </volume> <pages> 463-502, </pages> <year> 1969. </year>
Reference-contexts: Unfortunately, the interaction between the theoretical work and the more pragmatic, application oriented work on AI planning has been limited. The theoretical work on domain-independent planning has been mostly on state-based planning 1 that stemmed from STRIPS [24] planning system, with roots in situation calculus <ref> [47] </ref>. The state-based planning paradigm has been deeply investigated. The representation (i.e., the STRIPS language) has been precisely defined, and the flaws in its semantics have been corrected [47, 45]. Many algorithms for finding plans have been developed and investigated [60, 15, 46, 10, 41, 54]. <p> The state-based planning paradigm has been deeply investigated. The representation (i.e., the STRIPS language) has been precisely defined, and the flaws in its semantics have been corrected <ref> [47, 45] </ref>. Many algorithms for finding plans have been developed and investigated [60, 15, 46, 10, 41, 54]. The computational complexity of solving planning problems represented in the STRIPS language has been studied in detail [12, 15, 22]. <p> This discovery led to the development of situation calculus <ref> [47] </ref>.
Reference: [48] <author> D. McDermott. </author> <title> Flexibility and efficiency in a computer program for designing circuits. </title> <type> Technical Report TR-40, </type> <institution> Massachusetts Institute of Technology, </institution> <year> 1977. </year>
Reference: [49] <author> S. Minton, J. Bresna, and M. Drummond. </author> <title> Commitment strategies in planning. </title> <booktitle> In IJCAI-91, </booktitle> <year> 1991. </year>
Reference-contexts: In recent years, several comparative studies of partial order versus total order planning have been done. One of the first studies on partial versus total order planning was done by Minton et. al. <ref> [49] </ref>. They designed two planners called TO and UA. TO is a total order planner, which orders each new step in a plan with respect to all the other steps. <p> This seems largely due to the fact that HTN planning emerged, without a formal description, in implemented planning systems [58, 64]. Many ideas introduced in HTN planning (such as nonlinearity, partial order planning, etc.) were formalized only as they were adapted to STRIPS-style planning, and only within that context <ref> [15, 46, 49, 16, 35] </ref>. The following subsections discuss the view of tasks in this dissertation, and possible alternative views. 3.6.1.1 A View of Tasks as Jobs The formalism described in this chapter views tasks as activities we need to plan, jobs that need to be accomplished.
Reference: [50] <author> S. Minton, M. D. Johnston, A. B. Philips, and P. Laird. </author> <title> Minimizing conflicts: a heuristic repair method for constraint satisfaction and scheduling problems. </title> <journal> Artificial Intelligence, </journal> <month> December </month> <year> 1992. </year>
Reference-contexts: Abstraction hierarchies are given that name because of the abstraction resulting from ignoring some conditions, and the hierarchy consisting of the criticality levels. However, like the variable-ordering heuristics found in the constraint satisfaction literature <ref> [25, 50] </ref>, abstraction hierarchies can also be perceived as a means of deciding which part of the problem to work on next. 10 2.2.3 Relaxation of the Linearity Assumption Planning algorithms based on the linearity assumption could not solve problems containing nonserializable goals.
Reference: [51] <author> A. Newell and J. A. Simon. </author> <title> Gps, a program that simulates human thought. </title> <editor> In E. A. Feigenbaum and J. Feldman, editors, </editor> <booktitle> Computers and Thought, </booktitle> <pages> pages 279-293. </pages> <editor> R. Old-enbourg KG, </editor> <year> 1963, 1963. </year>
Reference-contexts: Otherwise, the operator is added to the working plan, and its preconditions are pushed onto the goal stack as new subgoals. Whenever no operator has a matching effect with the goals on top of the goal stack, the algorithm backtracks. The STRIPS algorithm is heavily influenced by GPS <ref> [51] </ref> (General Problem Solver), whose operator choice is driven by minimizing the difference between the current state and the goal state.
Reference: [52] <author> N. Nilsson. </author> <booktitle> Principles of Artificial Intelligence. </booktitle> <publisher> Morgan-Kaufmann, </publisher> <year> 1980. </year>
Reference-contexts: This discovery led to the development of situation calculus [47]. The details of situation calculus can be found in most introductory AI textbooks such as <ref> [52] </ref>, but the general idea can be summarized as follows: atoms such as p (x) that are normally used to represent static facts about the world are augmented by an extra term as in p (x; s) to state that the predicate p is true of term x in situation s. <p> However, there were a number of problems with this formulation, such as the difficulty of providing a well-defined semantics for it [45]. Thus, in subsequent work, researchers have placed several restrictions on the 15 nature of the planning operators <ref> [52] </ref>. Typically, the precondition lists, add lists and delete lists contain only atoms, and the goal is a conjunct of ground or existentially quantified atoms. This representation has become the de facto standard STRIPS representation, used by most of the state-based planning systems [15, 46, 77]. <p> goal. 16 a c e (a) initial configuration b d (b) goal configuration Example 2.3.1 (Blocks World) Suppose we want to talk about a blocks-world planning domain in which there are five blocks a; b; c; d; e, along with the "stack", "unstack", "pickup", and "putdown" operators used by Nilsson <ref> [52] </ref>. Suppose the initial configuration is as shown in Fig. 2.1 (a), and the goal is to have b on c on d, as shown in Fig. 2.1 (b). Then the language, operators, planning domain, and planning problems are defined as follows: 1.
Reference: [53] <author> Edwin P. D. Pednault. </author> <title> Synthesizing plans that contain actions with context-dependent effects. </title> <journal> Computational Intelligence, </journal> <volume> bf 4 </volume> <pages> 356-372, </pages> <year> 1988. </year>
Reference-contexts: It was designed by Weld and Henks in 1992. Rather than the STRIPS language, UCPOP is based on the ADL language developed by Pednault <ref> [53] </ref> in his dissertation work.
Reference: [54] <author> J.S. Penberthy and D.S. Weld. Ucpop: </author> <title> A sound, complete, partial order planner for adl. </title> <booktitle> In Proceedings of the Third International Conference on Knowledge Representation and Reasoning, </booktitle> <month> October </month> <year> 1992. </year>
Reference-contexts: The state-based planning paradigm has been deeply investigated. The representation (i.e., the STRIPS language) has been precisely defined, and the flaws in its semantics have been corrected [47, 45]. Many algorithms for finding plans have been developed and investigated <ref> [60, 15, 46, 10, 41, 54] </ref>. The computational complexity of solving planning problems represented in the STRIPS language has been studied in detail [12, 15, 22]. <p> The most influential algorithms among those have been TWEAK [15] by Chapman in 1987, SNLP [46] by McAllester in 1991, and UCPOP <ref> [54] </ref> by Penberthy and Weld in 1992. This section contains a brief overview of these planning algorithms. 18 2.3.2.1 TWEAK TWEAK [15] is the first provably correct partial-order planning algorithm. It works with incomplete plans, which are iteratively refined to a complete solution. <p> TWEAK and SNLP represent two opposite extremes in protecting none versus all of the established conditions. In the following years, intermediate techniques, which protect only some of the previously established conditions, were developed [56, 61, 34]. 2.3.2.3 UCPOP UCPOP <ref> [54] </ref> is another sound and complete planning algorithm. It was designed by Weld and Henks in 1992. Rather than the STRIPS language, UCPOP is based on the ADL language developed by Pednault [53] in his dissertation work.
Reference: [55] <author> M. A. Peot. </author> <title> Conditional nonlinear planning. </title> <booktitle> In First Internat. Conf. AI Planning Systems, </booktitle> <pages> pages 189-197, </pages> <year> 1992. </year>
Reference: [56] <author> M. A. Peot and D. Smith. </author> <title> Threat removal strategies for partial-order planning. </title> <booktitle> In AAAI-93, </booktitle> <pages> pages 492-499, </pages> <address> Washington D.C., </address> <year> 1993. </year>
Reference-contexts: Tradeoffs between systematicity versus commitment were investigated by Kambhampati in [36]. TWEAK and SNLP represent two opposite extremes in protecting none versus all of the established conditions. In the following years, intermediate techniques, which protect only some of the previously established conditions, were developed <ref> [56, 61, 34] </ref>. 2.3.2.3 UCPOP UCPOP [54] is another sound and complete planning algorithm. It was designed by Weld and Henks in 1992. Rather than the STRIPS language, UCPOP is based on the ADL language developed by Pednault [53] in his dissertation work. <p> They compare the performance of SNLP to PRODIGY [11], which is a total-order planner, and show that SNLP performs much more slower than PRODIGY in several problems where goals are laboriously linkable. In recent years, several studies have been made on causal links, and the tradeoffs involved in it <ref> [36, 56, 61, 34] </ref>. In general, preserving causal links reduces the redundancy in the search space, but increases the branching factor (i.e., the number of ways of establishing a condition). Using causal links may force the planner to commit to the wrong step as an establisher, and cause backtracking.
Reference: [57] <author> Stuart Russell and Peter Norvig. </author> <title> Artificial Intelligence: A Modern Approach. </title> <publisher> Prentice-Hall, </publisher> <year> 1995. </year> <month> 157 </month>
Reference-contexts: It (optionally) shows what the planner does at every step, so that the HTN constructs can be better understood. The HTN framework has already made its way into an acclaimed AI text book, thanks to Russell and Norvig <ref> [57] </ref>. Writing correct domain specifications is a very challenging job, particularly for large applications. It can be even more difficult, if there are doubts about how the domain specifications are going to be interpreted by the planner.
Reference: [58] <author> E. D. Sacerdoti. </author> <title> A Structure for Plans and Behaviour. </title> <publisher> Elsevier-North Holland, </publisher> <year> 1977. </year>
Reference-contexts: For example, in Figure 3.4, if we use up all our money in order to rent the car, we may not be able to see a show. The job of finding and resolving such interactions is performed by critics. As explained in Section 2.2.7, critics were introduced into NOAH <ref> [58] </ref> to identify and deal with several kinds of interactions (not just deleted preconditions) among the different networks used to reduce each non-primitive operator. <p> This seems largely due to the fact that HTN planning emerged, without a formal description, in implemented planning systems <ref> [58, 64] </ref>. Many ideas introduced in HTN planning (such as nonlinearity, partial order planning, etc.) were formalized only as they were adapted to STRIPS-style planning, and only within that context [15, 46, 49, 16, 35]. <p> These can be eliminated by posting constraints (in methods) so that the planner does not waste time deriving this information. This ability to encode known shortcuts and/or pitfalls was offered as a major motivation for the move to procedural networks in NOAH <ref> [58] </ref>. 51 Chapter 4 Complexity of HTN Planning The HTN formalism presented in Chapter 3 makes it possible to analyze the complexity of HTN planning under a number of conditions: * whether the tasks in task networks are required to be totally ordered, * whether variables are allowed, * whether domain <p> In order to evaluate state constraints, UMCP uses an extended version of the MTC that also accounts for compound tasks. UMCP's extended MTC algorithm runs in quadratic time|and it is directly applicable for computing Chapman's MTC, for which the other known algorithms run in cubic time. NOAH <ref> [58] </ref> employs its resolve conflicts critic to deal with deleted-condition interactions, which are explicitly represented by state constraints in UMCP. The constraint refinement techniques of UMCP guarantees these interactions will be handled without sacrificing soundness or completeness.
Reference: [59] <author> E. D. Sacerdoti. </author> <title> The nonlinear nature of plans. </title> <editor> In James Allen, James Hendler, and Austin Tate, editors, </editor> <booktitle> Readings in Planning, </booktitle> <pages> pages 162-170. </pages> <publisher> Morgan Kaufman, </publisher> <year> 1990. </year>
Reference-contexts: The more pragmatic work on domain-independent planning has paid less attention to formal foundations, and instead focused directly on building planning systems. Out of this research avenue was born a number of planning systems such as HACKER [63], NOAH <ref> [59] </ref>, and NONLIN [64]. These systems established a new planning paradigm called hierarchical task network (HTN) planning. HTN planning introduced many powerful ideas such as tasks and task decomposition, partial order planning, and least commitment. HTN planning systems showed much promise in building planning applications. <p> Their planning systems would find a plan for the first subgoal, and then modify that plan by inserting new steps as necessary to achieve the next subgoal without undoing the previously achieved subgoals. HTN planning systems such as NOAH <ref> [59] </ref> and NONLIN [64] introduced partial-order planning, which facilitates handling nonserializable goals. In partial order planning, the decision regarding where a new step should be added in the working plan is deferred. Plan steps are pairwise ordered only to the extend necessary to resolve conflicts. <p> All possible orderings and variable instantiations would be explored in a depth-first manner. This results in a very large branching factor, and it is rather inefficient for many planning problems. In response to this situation, HTN planners such as NOAH <ref> [59] </ref> typically work by introducing ordering and variable binding restrictions only when necessary to resolve conflicts. This kind of strategy has been called least commitment. <p> Planning proceeded by decomposing each task into simpler tasks and resolving the conflicts among tasks iteratively, until a conflict-free plan consisting of primitive tasks could be found. Task decomposition techniques were initially introduced in the NOAH <ref> [59] </ref> system developed by Sacerdoti in the mid-1970's, and were enhanced in NONLIN [64] system designed by Tate in 1977. NOAH represented planning problems as partially ordered lists of tasks (hence the term "task network"). <p> Historically speaking, critics were introduced into NOAH <ref> [59] </ref> as a procedural, heuristic mechanism to identify and deal with several kinds of interactions (not just deleted preconditions) among tasks in a task network. After each task decomposition, a set of critics are consulted so as to recognize interactions and resolve conflicts. <p> After each task decomposition, a set of critics are consulted so as to recognize interactions and resolve conflicts. This approach provides a more general framework for detecting interactions than is available in most STRIPS-style planners. Based in part on Sussman's earlier work in HACKER [63], Sacerdoti <ref> [59] </ref> identified three critics of general use: * Resolve Conflicts. The conflicts handled by this critic, later referred to as "deleted condition" interactions, have received the bulk of the attention in the literature. * Use existing objects. <p> These mechanisms serve as domain independent critics, and they are designed to preserve soundness, completeness, and systematicity. As was explained in Section 2.2.7, HTN planning systems <ref> [59, 64, 69] </ref> have used a mechanism called critics to deal with interactions. Critics helped prune the search space by detecting dead ends in advance and by resolving many types of conflicts as soon as they appeared.
Reference: [60] <author> E. D. Sacerdoti. </author> <title> Planning in a hierarchy of abstraction spaces. </title> <editor> In James Allen, James Hendler, and Austin Tate, editors, </editor> <booktitle> Readings in Planning, </booktitle> <pages> pages 98-109. </pages> <publisher> Morgan Kauf-man, </publisher> <year> 1990. </year>
Reference-contexts: The state-based planning paradigm has been deeply investigated. The representation (i.e., the STRIPS language) has been precisely defined, and the flaws in its semantics have been corrected [47, 45]. Many algorithms for finding plans have been developed and investigated <ref> [60, 15, 46, 10, 41, 54] </ref>. The computational complexity of solving planning problems represented in the STRIPS language has been studied in detail [12, 15, 22]. <p> The term "nonlinear" is sometimes used to refer to partial-order or HTN planners. This type of usage is misleading and thus it is avoided in this dissertation. 2.2.2 Abstraction Hierarchies Abstraction hierarchies were introduced by Sacerdoti in 1974, in the ABSTRIPS system <ref> [60] </ref>. Their purpose is to cope with the huge size of the search space and to reduce planning time by focusing the planning effort on the most critical parts of the problem first. <p> Bylander has also studied average-case complexity of propositional STRIPS-style planning under various assumptions as can be found in [14]. Backstrom has done a complexity analysis of a planning representation equivalent to STRIPS representation with similar results [8]. 2.3.4 Abstraction Hierarchies Abstraction hierarchies were originally introduced in the ABSTRIPS <ref> [60] </ref> system, as described in Section 2.2. ABSTRIPS used heuristic methods in assigning criticality levels to predicates, to determine which of those conditions the planner should try to accomplish first. <p> The iteration is repeated until all the actions are primitive and all the conflicts are resolved. Each iteration of the procedure described above creates a layer of abstraction, in some ways similar to the abstraction layers produced by ABSTRIPS <ref> [60] </ref>. Unlike the abstraction hierarchies of ABSTRIPS, which are based on preconditions, this type of abstraction is based on actions. <p> UMCP requires all the task symbols to 85 be declared in advance, and those declarations can optionally specify a criticality level for each non-primitive task, analogous to the criticality assignments used by the ABSTRIPS system <ref> [60] </ref>. That system was described in Section 2.2.2. UMCP chooses the non-primitive task with the highest criticality level. Just as in ABSTRIPS, the criticality assignments in UMCP, provide valuable guidance in focusing the attention of the planner to the most critical part of the problem.
Reference: [61] <author> D. Smit and M. A. Peot. </author> <title> Postponing threads in partial-order planning. </title> <booktitle> In AAAI-93, </booktitle> <pages> pages 500-506, </pages> <address> Washington D.C., </address> <year> 1993. </year>
Reference-contexts: Tradeoffs between systematicity versus commitment were investigated by Kambhampati in [36]. TWEAK and SNLP represent two opposite extremes in protecting none versus all of the established conditions. In the following years, intermediate techniques, which protect only some of the previously established conditions, were developed <ref> [56, 61, 34] </ref>. 2.3.2.3 UCPOP UCPOP [54] is another sound and complete planning algorithm. It was designed by Weld and Henks in 1992. Rather than the STRIPS language, UCPOP is based on the ADL language developed by Pednault [53] in his dissertation work. <p> They compare the performance of SNLP to PRODIGY [11], which is a total-order planner, and show that SNLP performs much more slower than PRODIGY in several problems where goals are laboriously linkable. In recent years, several studies have been made on causal links, and the tradeoffs involved in it <ref> [36, 56, 61, 34] </ref>. In general, preserving causal links reduces the redundancy in the search space, but increases the branching factor (i.e., the number of ways of establishing a condition). Using causal links may force the planner to commit to the wrong step as an establisher, and cause backtracking.
Reference: [62] <author> Mark Stefik. </author> <title> lanning with constriants. </title> <editor> In James Allen, James Hendler, and Austin Tate, editors, </editor> <booktitle> Readings in Planning, </booktitle> <pages> pages 171-185. </pages> <publisher> Morgan Kaufman, </publisher> <year> 1990. </year>
Reference-contexts: This kind of strategy has been called least commitment. Least commitment strategy may reduce amount of backtracking in a number of planning situations where a total-order planner would try and backtrack from many possible orderings. The MOLGEN <ref> [62] </ref> system developed by Stefik in 1981 further enhanced least commitment for variable bindings. MOLGEN was designed to work in the area of experiment planning for molecular biology. The choice of objects in those experiments are rather important.
Reference: [63] <author> G.J. Sussman. </author> <title> A Computational Model of Skill Acquisition. </title> <publisher> American Elsevie, </publisher> <year> 1975. </year>
Reference-contexts: The more pragmatic work on domain-independent planning has paid less attention to formal foundations, and instead focused directly on building planning systems. Out of this research avenue was born a number of planning systems such as HACKER <ref> [63] </ref>, NOAH [59], and NONLIN [64]. These systems established a new planning paradigm called hierarchical task network (HTN) planning. HTN planning introduced many powerful ideas such as tasks and task decomposition, partial order planning, and least commitment. HTN planning systems showed much promise in building planning applications. <p> However, even very simple planning domains contain nonserializable goals. These are goals for which there is no solution unless the plans for each goal are interleaved. The STRIPS system ignores nonserializable goals by making the linearity assumption <ref> [63] </ref>: Subgoals are independent and thus can be sequentially achieved in an arbitrary order. The linearity assumption significantly simplifies devising algorithms for dealing with conjunctive goals. <p> As discussed earlier, subplans for nonserializable goals need to be interleaved. The planning systems of 1970's introduced several techniques for dealing with nonserializable goals. The HACKER <ref> [63] </ref> system was developed by Sussman in 1975 for manipulating a robot arm. HACKER deals with interacting subgoals using the critics mechanism. This procedural mechanism identifies and patches conflicts based on heuristic methods. HACKER stores patches that worked well, to be used later in similar problems. <p> NOAH represented planning problems as partially ordered lists of tasks (hence the term "task network"). The information on how to decompose tasks was encoded procedurally in the so called "soup code." NOAH used an improved version of critics, a heuristic procedural mechanism initially introduced by HACKER <ref> [63] </ref>, to detect and resolve interactions among tasks. Interactions were resolved mostly by placing ordering or variable binding restrictions. NONLIN replaced the procedural soup code of NOAH with opschemas, which declaratively represented how to decompose tasks. <p> After each task decomposition, a set of critics are consulted so as to recognize interactions and resolve conflicts. This approach provides a more general framework for detecting interactions than is available in most STRIPS-style planners. Based in part on Sussman's earlier work in HACKER <ref> [63] </ref>, Sacerdoti [59] identified three critics of general use: * Resolve Conflicts. The conflicts handled by this critic, later referred to as "deleted condition" interactions, have received the bulk of the attention in the literature. * Use existing objects.
Reference: [64] <author> A. Tate. </author> <title> Generating project networks. </title> <editor> In James Allen, James Hendler, and Austin Tate, editors, </editor> <booktitle> Readings in Planning, </booktitle> <pages> pages 291|296. </pages> <publisher> Morgan Kaufman, </publisher> <year> 1990. </year>
Reference-contexts: The more pragmatic work on domain-independent planning has paid less attention to formal foundations, and instead focused directly on building planning systems. Out of this research avenue was born a number of planning systems such as HACKER [63], NOAH [59], and NONLIN <ref> [64] </ref>. These systems established a new planning paradigm called hierarchical task network (HTN) planning. HTN planning introduced many powerful ideas such as tasks and task decomposition, partial order planning, and least commitment. HTN planning systems showed much promise in building planning applications. <p> Their planning systems would find a plan for the first subgoal, and then modify that plan by inserting new steps as necessary to achieve the next subgoal without undoing the previously achieved subgoals. HTN planning systems such as NOAH [59] and NONLIN <ref> [64] </ref> introduced partial-order planning, which facilitates handling nonserializable goals. In partial order planning, the decision regarding where a new step should be added in the working plan is deferred. Plan steps are pairwise ordered only to the extend necessary to resolve conflicts. Thus, subplans for goals can be freely interleaved. <p> Planning proceeded by decomposing each task into simpler tasks and resolving the conflicts among tasks iteratively, until a conflict-free plan consisting of primitive tasks could be found. Task decomposition techniques were initially introduced in the NOAH [59] system developed by Sacerdoti in the mid-1970's, and were enhanced in NONLIN <ref> [64] </ref> system designed by Tate in 1977. NOAH represented planning problems as partially ordered lists of tasks (hence the term "task network"). <p> NOAH was applied to mechanical engineers apprentice supervision, NONLIN was applied to electricity turbine overhaul, DEVISER was applied to Voyager spacecraft mission sequencing, and SIPE was applied to aircraft carrier mission planning [2]. 2.2.6 Filter Conditions Filter conditions were introduced in NONLIN <ref> [64] </ref> as a mechanism to reduce the size of the search space by detecting and filtering out undesirable solutions in early stages of planning. For example, consider a medical domain. Suppose a particular drug is administered only to patients with high fever. <p> Finally, Section 3.6 describes how various HTN concepts in previous HTN planning systems are modelled in this framework. 3.1 An Overview of HTN planning One of the motivations for HTN planning was to close the gap between STRIPS-style planning, and the operations-research techniques for project management and scheduling <ref> [64] </ref>. As a result, there are some similarities between HTN planning and STRIPS-style planning, but also some significant differences. HTN planning representations for actions and states of the world are similar to those used in STRIPS-style planning 1 , which was described in Section 2.3.1. <p> Figure 3.2 presents a (simplified) method for accomplishing Go (X,Y). A number of different systems that use heuristic algorithms have been devised for HTN planning <ref> [64, 69, 73] </ref>, and several recent papers have tried to provide general descriptions of are normally assumed to contain no function symbols. 31 1. Input a planning problem P. 2. If P contains only primitive tasks, then resolve the conflicts in P and return the result. <p> This seems largely due to the fact that HTN planning emerged, without a formal description, in implemented planning systems <ref> [58, 64] </ref>. Many ideas introduced in HTN planning (such as nonlinearity, partial order planning, etc.) were formalized only as they were adapted to STRIPS-style planning, and only within that context [15, 46, 49, 16, 35]. <p> These mechanisms serve as domain independent critics, and they are designed to preserve soundness, completeness, and systematicity. As was explained in Section 2.2.7, HTN planning systems <ref> [59, 64, 69] </ref> have used a mechanism called critics to deal with interactions. Critics helped prune the search space by detecting dead ends in advance and by resolving many types of conflicts as soon as they appeared. <p> HTN planners often allow several types of conditions in methods. How to deal with those conditions has been a topic of debate. NONLIN <ref> [64] </ref> evaluates filter conditions as soon as they are encountered, using the QA (Question Answering) mechanism. QA returns false unless it can verify those conditions to be necessarily true, even if the conditions are possibly true.
Reference: [65] <author> A. Tate, B. Drabble, and J. Dalton. </author> <title> The use of condition types to restrict search in an ai planner. </title> <booktitle> In AAAI-94, </booktitle> <pages> pages 1129-1134, </pages> <year> 1994. </year>
Reference-contexts: O-PLAN represents plans using several elaborate types of constraints. O-PLAN has introduced the triangle model of activity to integrate automatic manipulation of plans with human interaction and information acquisition. Recently this system was enhanced further resulting in a system called O-PLAN2 <ref> [65] </ref>. Unlike state-based planners which rarely were used for practical applications, HTN planners met with considerable success in building applications. <p> Furthermore, some filter conditions might not be affected by the actions (e.g. conditions on the type of objects), and thus it suffices to check the initial state to evaluate those. This kind of filter condition can also be very helpful in pruning the search space. Tate <ref> [65] </ref> also promotes the use of filter conditions, but suggests this must be done very carefully to work efficiently, without compromising correctness.
Reference: [66] <editor> A. Tate, J. Hendler, and D. </editor> <title> Drummond. Ai planning: Systems and techniques. </title> <journal> AI Magazine, UMIACS-TR-90-21, </journal> <volume> CS-TR-2408:61-77, </volume> <year> 1990. </year>
Reference: [67] <author> Manuela Veloso. </author> <title> Learning by analogical reasoning in general problem solving. </title> <type> Technical report, </type> <institution> Carnegie Mellon University, School of Computer Science, </institution> <year> 1992. </year>
Reference-contexts: This section provides a brief description of the UM 95 Translog domain from that paper. The full domain specification is available online at: http://www.cs.umd.edu/projects/plus/UMT. UM Translog was inspired by the CMU Transport Logistics domain developed by Manuela Veloso <ref> [67] </ref>. UM Translog is also an abstract, toy planning domain, but compared to the CMU Transport domain, it is an order of magnitude larger in size (41 actions versus 6), number of features and types of interactions.
Reference: [68] <author> Manuela Veloso and Jim Blythe. Linkability: </author> <title> Examining causal link commitments in partial-order planning. </title> <booktitle> In Second Internat. Conf. AI Planning Systems, </booktitle> <address> Chicago, </address> <year> 1994. </year>
Reference-contexts: Barrett and Weld designed several artificial planning problems with laboriously serializable goals, and their experiment results corroborate the intuition that partial-order planners perform better than total-order planners in solving problems with this type of goals. In response to this study, Veloso et. al. <ref> [68] </ref>, has introduced the concept of linkability. The degree of linkability in a problem refers to how much backtracking a causal link planner such as SNLP needs to do on the problem, because it has committed to the wrong step to establish a condition.
Reference: [69] <author> S. A. Vere. </author> <title> Planning in time: Windows and durations for activities and goals. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-5(3):246-247, </volume> <year> 1983. </year>
Reference-contexts: These systems established a new planning paradigm called hierarchical task network (HTN) planning. HTN planning introduced many powerful ideas such as tasks and task decomposition, partial order planning, and least commitment. HTN planning systems showed much promise in building planning applications. For example, DEVISER <ref> [69] </ref> was used to develop a prototype for Voyager spacecraft mission sequencing, and SIPE [72] was used to build a prototype system for factory automation. Unfortunately, HTN planning systems could not be developed to the level of successful software products for planning applications. <p> It employed backtracking to recover from incorrect planning decisions. NOAH had no such mechanism, and it would report failure in those cases. In the following years, the DEVISER <ref> [69] </ref> system developed by Vere in 1983 extended the NOAH and NONLIN systems to handle actions with durations and activities with temporal constraints. The work on HTN planning was further advanced by SIPE [73], developed by Wilkins in 1983. <p> When such opportunities were recognized, this critic would convert the already achieved goal task into a "phantom" condition. In addition to the interactions handled by these critics, a number of other situations that can arise in planning have been identified in the literature: * For his deviser system, Vere <ref> [69] </ref> has discussed temporal interactions between the times at which actions must occur. 1 He has discussed temporal windowing and an analysis thereof to eliminate possible reductions. * Wilkins' sipe system [73] has added a number of different mechanisms for recognizing resource interactions and for allowing user preferences to be considered <p> Figure 3.2 presents a (simplified) method for accomplishing Go (X,Y). A number of different systems that use heuristic algorithms have been devised for HTN planning <ref> [64, 69, 73] </ref>, and several recent papers have tried to provide general descriptions of are normally assumed to contain no function symbols. 31 1. Input a planning problem P. 2. If P contains only primitive tasks, then resolve the conflicts in P and return the result. <p> These mechanisms serve as domain independent critics, and they are designed to preserve soundness, completeness, and systematicity. As was explained in Section 2.2.7, HTN planning systems <ref> [59, 64, 69] </ref> have used a mechanism called critics to deal with interactions. Critics helped prune the search space by detecting dead ends in advance and by resolving many types of conflicts as soon as they appeared.
Reference: [70] <author> R. Waldinger. </author> <title> Achieving sevaral goals simultaneously. </title> <editor> In James Allen, James Hendler, and Austin Tate, editors, </editor> <booktitle> Readings in Planning, </booktitle> <pages> pages 118|139. </pages> <publisher> Morgan Kaufman, </publisher> <year> 1990. </year>
Reference-contexts: Another way of dealing with nonserializable goals is to keep the plan steps totally ordered, but to allow new steps to be inserted at any point in the plan. Warren [71] in 1974 and Waldinger <ref> [70] </ref> in 1977 took this approach and used goal regression and action regression techniques, respectively, for dealing with conjunctive goals.
Reference: [71] <author> D. H. D. Warren. </author> <title> Extract for apic studies in data processing. </title> <editor> In James Allen, James Hendler, and Austin Tate, editors, </editor> <booktitle> Readings in Planning, </booktitle> <pages> pages 140-153. </pages> <publisher> Morgan Kauf-man, </publisher> <year> 1990. </year>
Reference-contexts: Another way of dealing with nonserializable goals is to keep the plan steps totally ordered, but to allow new steps to be inserted at any point in the plan. Warren <ref> [71] </ref> in 1974 and Waldinger [70] in 1977 took this approach and used goal regression and action regression techniques, respectively, for dealing with conjunctive goals.
Reference: [72] <author> D. Wilkins. </author> <title> Practical Planning: Extending the classical AI planning paradigm. </title> <publisher> Morgan-Kaufmann, </publisher> <year> 1988. </year> <month> 158 </month>
Reference-contexts: HTN planning introduced many powerful ideas such as tasks and task decomposition, partial order planning, and least commitment. HTN planning systems showed much promise in building planning applications. For example, DEVISER [69] was used to develop a prototype for Voyager spacecraft mission sequencing, and SIPE <ref> [72] </ref> was used to build a prototype system for factory automation. Unfortunately, HTN planning systems could not be developed to the level of successful software products for planning applications. I contend this is due to the lack of an underlying theoretical foundation. <p> Currently, we are designing experiments to empirically evaluate these techniques. The constraint-handling mechanisms of the UMCP system provide the capabilities of many domain-independent critics discussed in the literature, and UMCP's user-specific critics module can be used to incorporate domain-specific critics as well. The modular and 5 SIPE <ref> [72] </ref> uses a "sort hierarchy" for this purpose, the only difference in UMCP is that UMCP allows arbitrary boolean formulae constructed from all types of constraints, instead of a conjunct of constraints as in SIPE. 89 formal nature of UMCP makes it readily extensible.
Reference: [73] <author> D. E. Wilkins. </author> <title> Domain-independent planning: Representation and plan generation. </title> <editor> In James Allen, James Hendler, and Austin Tate, editors, </editor> <booktitle> Readings in Planning, </booktitle> <pages> pages 319-335. </pages> <publisher> Morgan Kaufman, </publisher> <year> 1990. </year>
Reference-contexts: In the following years, the DEVISER [69] system developed by Vere in 1983 extended the NOAH and NONLIN systems to handle actions with durations and activities with temporal constraints. The work on HTN planning was further advanced by SIPE <ref> [73] </ref>, developed by Wilkins in 1983. SIPE emphasizes resource management and also the interactions with the user of the planning system. SIPE employs a taxonomy for storing the features of objects in the planning domain. <p> other situations that can arise in planning have been identified in the literature: * For his deviser system, Vere [69] has discussed temporal interactions between the times at which actions must occur. 1 He has discussed temporal windowing and an analysis thereof to eliminate possible reductions. * Wilkins' sipe system <ref> [73] </ref> has added a number of different mechanisms for recognizing resource interactions and for allowing user preferences to be considered when making a choice between reductions. * Yang, Nau, and Hendler [76] have introduced a general "action-precedence" interaction that can be exploited in some planning situations. * Nau and Gupta [28] <p> Figure 3.2 presents a (simplified) method for accomplishing Go (X,Y). A number of different systems that use heuristic algorithms have been devised for HTN planning <ref> [64, 69, 73] </ref>, and several recent papers have tried to provide general descriptions of are normally assumed to contain no function symbols. 31 1. Input a planning problem P. 2. If P contains only primitive tasks, then resolve the conflicts in P and return the result.
Reference: [74] <author> Q. Yang. </author> <title> Formalizing planning knowledge for hierarchical planning. </title> <journal> Computational Intelligence, </journal> <volume> 6 </volume> <pages> 12-2, </pages> <year> 1990. </year>
Reference-contexts: This issue is discussed in detail in Chapter 4. 2.3.6 Task Networks and Task Decomposition Very few researchers have tried to integrate task decomposition to their models of planning. Kambhampati and Yang <ref> [33, 74] </ref> provided the initial steps towards developing a formal model of HTN planning, which the work described in this dissertation has extensively benefited from. Barrett [9] and Young [78] have incorporated task decomposition techniques to their planning systems as a tool for increasing the speed of state-based planning. <p> Use critics to find the interactions among the tasks in P, and suggest ways to handle them. 7. Apply one of the ways suggested in step 6. 8. Go to step 2. See a show Rent-car ! drive (D.C., L.V.) % & Go (L.V., D.C.) Get rich these algorithms <ref> [74, 33] </ref>. Figure 3.3 presents the essence of these algorithms. As shown in this figure, HTN planning works by expanding tasks and resolving conflicts iteratively, until a conflict-free plan can be found that consists only of primitive tasks. <p> Although this is a perfectly coherent view, it is rather restrictive and there is more to HTN planning, as demonstrated in Chapter 5, where the expressivity results are presented. 3.6.1.3 A View of Tasks as Action Abstraction Yang and Kambhampati <ref> [74, 33] </ref> have viewed tasks as high-level actions. High-level actions have preconditions and effects, just as regular STRIPS operators; however, they can be expanded into lower level actions. Planning proceeds iteratively: goals in the planning problem are established using the highest-level actions first. <p> This is problematic: one can obtain the same sequence of primitive tasks with different tasks and methods, and given high-level effects, the final state might depend on what particular task (s) the sequence was intended for. Yang <ref> [74] </ref> addresses this problem by attaching high-level effects to tasks directly using operators.
Reference: [75] <author> Q. Yang. </author> <title> Understanding the essence of nonlinear planning. </title> <type> Technical report, </type> <institution> Computer Science Department, University of Waterloo, </institution> <year> 1991. </year>
Reference: [76] <author> Q. Yang, D. S. Nau, and J. Hendler. </author> <title> Merging separately generated plans with restricted interactions. </title> <booktitle> Computational Intelligence, </booktitle> <month> February </month> <year> 1993. </year>
Reference-contexts: occur. 1 He has discussed temporal windowing and an analysis thereof to eliminate possible reductions. * Wilkins' sipe system [73] has added a number of different mechanisms for recognizing resource interactions and for allowing user preferences to be considered when making a choice between reductions. * Yang, Nau, and Hendler <ref> [76] </ref> have introduced a general "action-precedence" interaction that can be exploited in some planning situations. * Nau and Gupta [28] have identified "enabling-condition" interactions as the culprit that makes finding optimal plans in the blocks-world domain to be NP-hard.
Reference: [77] <author> Q. Yang, J. Tenenberg, and S. Woods. </author> <title> Abstraction in nonlinear planning. </title> <type> Technical Report TR CS-91-65, </type> <institution> University of Waterloo, Dept. of Computer Science, </institution> <year> 1991. </year>
Reference-contexts: Typically, the precondition lists, add lists and delete lists contain only atoms, and the goal is a conjunct of ground or existentially quantified atoms. This representation has become the de facto standard STRIPS representation, used by most of the state-based planning systems <ref> [15, 46, 77] </ref>. The description of the STRIPS representation below, which I developed jointly with Dr. Nau and Dr. Subrahmanian [22], is in accordance with this formulation. Definition 1 Let L be any first-order language generated by finitely many constant symbols, predicate symbols, and function symbols. <p> However, recently, Backstrom [7] has shown that there exist planning 26 problems for which abstraction hierarchies satisfying the ordered monotonicity property may work poorly. Yang has also worked extensively on abstraction hierarchies, collaborating with a number of researchers. Together with Tenenberg and Woods, Yang has developed ABTWEAK <ref> [77] </ref>, a planning system that utilizes abstraction hierarchies like ABSTRIPS, but it uses TWEAK instead of STRIPS as the underlying plan generator at each level. Yang and Bacchus have identified several properties of abstraction hierarchies as potential indicators of how well they would perform [6].
Reference: [78] <author> R. M. Young, M. E. Pollack, and J. D. Moore. </author> <title> Decomposition and causality in partial-order planning. </title> <booktitle> In Second Internat. Conf. AI Planning Systems, </booktitle> <address> Chicago, </address> <year> 1994. </year> <month> 159 </month>
Reference-contexts: Kambhampati and Yang [33, 74] provided the initial steps towards developing a formal model of HTN planning, which the work described in this dissertation has extensively benefited from. Barrett [9] and Young <ref> [78] </ref> have incorporated task decomposition techniques to their planning systems as a tool for increasing the speed of state-based planning. The general idea was to encapsulate heuristic fast ways of accomplishing conditions via task decompositions.
References-found: 78

