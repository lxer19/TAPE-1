URL: http://www.cs.tamu.edu/people/kannank/broadcast/thesis.ps.gz
Refering-URL: http://www.cs.tamu.edu/people/kannank/broadcast/
Root-URL: http://www.cs.tamu.edu
Title: ON-DEMAND DATA BROADCASTING  
Degree: A Thesis by KANNAN KOTHANDARAMAN Submitted to the Office of Graduate Studies of Texas A&M University in partial fulfillment of the requirements for the degree of MASTER OF SCIENCE  
Note: Major Subject: Computer Science  
Date: August 1998  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> B. R. Badrinath and T. Imielinski, </author> <title> "Data management for mobile computing," </title> <journal> Communications of the ACM, </journal> <volume> vol. 37, no. 10, </volume> <pages> pp. 19-28, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: It has also given rise to a number of interesting and challenging network problems. In the future, tens of millions of people will carry a portable computer with a wireless connection to a worldwide information network <ref> [1] </ref>. Data management in this paradigm poses many challenging problems. As the number of users increases exponentially, new ways of delivering data to them have to be found. Many networked applications currently use the client-server model. This model is illustrated in Fig. 1. <p> This is because the clients in this case may be low-powered devices, and the more time spent listening to the broadcast, the higher the amount of energy spent. Viswanathan et. al. <ref> [1, 4, 25] </ref> have proposed solutions that address this issue. They call the time a client spends listening to the broadcast as the tuning time. They 11 propose indexing the broadcast so that the client knows exactly when to listen to the broadcast to get the required item.
Reference: [2] <author> S. Shekar, A. Fetterer, and D.-R. Liu, </author> <title> "Genesis: an approach to data dissemination in advanced traveller information systems," </title> <journal> Bulletin of the Technical Committee on Data Engineering, </journal> <volume> vol. 19, no. 3, </volume> <pages> pp. 40-47, </pages> <month> September </month> <year> 1996. </year>
Reference-contexts: In such environments, broadcasting data to all the clients is efficient. This model is illustrated in Fig. 2. Data broadcasting is ideally suited for several applications, such as traffic information dissemination <ref> [2] </ref>, video on-demand [3], airline information, weather information, stock quotes, and emergency services information [4]. Pointcast [5] and Airmedia [6] are two of the many commercial companies that are using data broadcasting as their data delivery model.
Reference: [3] <author> T. Imielinski and S. Viswanathan, </author> <title> "Pyramid broadcasting for video on demand," </title> <booktitle> in Proceedings of ACM/IEEE Multimedia Conference, </booktitle> <month> February </month> <year> 1995. </year> <note> http://www.cs.rutgers.edu/ imielins/index.html, accessed on September 25, </note> <year> 1997. </year>
Reference-contexts: In such environments, broadcasting data to all the clients is efficient. This model is illustrated in Fig. 2. Data broadcasting is ideally suited for several applications, such as traffic information dissemination [2], video on-demand <ref> [3] </ref>, airline information, weather information, stock quotes, and emergency services information [4]. Pointcast [5] and Airmedia [6] are two of the many commercial companies that are using data broadcasting as their data delivery model.
Reference: [4] <author> S. Viswanathan, </author> <title> "Publishing in wireless and wireline environments," </title> <type> Ph.D. dissertation, </type> <institution> Rutgers University, </institution> <address> New Brunswick, New Jersey, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: In such environments, broadcasting data to all the clients is efficient. This model is illustrated in Fig. 2. Data broadcasting is ideally suited for several applications, such as traffic information dissemination [2], video on-demand [3], airline information, weather information, stock quotes, and emergency services information <ref> [4] </ref>. Pointcast [5] and Airmedia [6] are two of the many commercial companies that are using data broadcasting as their data delivery model. Recently, data broadcasting is being used as the data delivery tool for The journal model is IEEE Transactions on Automatic Control. 2 Fig. 1. <p> This is because the clients in this case may be low-powered devices, and the more time spent listening to the broadcast, the higher the amount of energy spent. Viswanathan et. al. <ref> [1, 4, 25] </ref> have proposed solutions that address this issue. They call the time a client spends listening to the broadcast as the tuning time. They 11 propose indexing the broadcast so that the client knows exactly when to listen to the broadcast to get the required item.
Reference: [5] <author> Pointcast, Inc., </author> <note> http://www.pointcast.com, accessed on January 10, </note> <year> 1997. </year>
Reference-contexts: In such environments, broadcasting data to all the clients is efficient. This model is illustrated in Fig. 2. Data broadcasting is ideally suited for several applications, such as traffic information dissemination [2], video on-demand [3], airline information, weather information, stock quotes, and emergency services information [4]. Pointcast <ref> [5] </ref> and Airmedia [6] are two of the many commercial companies that are using data broadcasting as their data delivery model. Recently, data broadcasting is being used as the data delivery tool for The journal model is IEEE Transactions on Automatic Control. 2 Fig. 1. Client-Server Model message-oriented middleware [7].
Reference: [6] <author> Airmedia, Inc., </author> <note> http://www.airmedia.com, accessed on January 10, </note> <year> 1998. </year>
Reference-contexts: This model is illustrated in Fig. 2. Data broadcasting is ideally suited for several applications, such as traffic information dissemination [2], video on-demand [3], airline information, weather information, stock quotes, and emergency services information [4]. Pointcast [5] and Airmedia <ref> [6] </ref> are two of the many commercial companies that are using data broadcasting as their data delivery model. Recently, data broadcasting is being used as the data delivery tool for The journal model is IEEE Transactions on Automatic Control. 2 Fig. 1. Client-Server Model message-oriented middleware [7].
Reference: [7] <author> IBM, "MQSeries: </author> <title> message oriented middleware," </title> <note> http://www.software.ibm.com /ts/mqseries/library/whitepapers/mqover /, accessed on May 28, </note> <year> 1998. </year>
Reference-contexts: Recently, data broadcasting is being used as the data delivery tool for The journal model is IEEE Transactions on Automatic Control. 2 Fig. 1. Client-Server Model message-oriented middleware <ref> [7] </ref>. In this thesis, we assume that all information is in the form of data items. The first issue that this thesis deals with is scheduling data broadcasts. Scheduling algorithms for data broadcasting determine which item the server broadcasts at a particular instance of time.
Reference: [8] <author> S. Acharya, </author> <title> "Broadcast disks data management for asymmetric communications environments," </title> <type> Ph.D. dissertation, </type> <institution> Brown University, </institution> <address> Providence, Rhode Island, </address> <month> May </month> <year> 1998. </year>
Reference-contexts: We present algorithms that attempt to minimize the 3 Fig. 2. Broadcast Model access time. The second issue that this thesis deals with is caching at the client. Caching is a technique used to store items in the client's local memory to improve the responsiveness of an application <ref> [8] </ref>. Caching schemes have to work with the scheduling algorithms to further reduce the access time for the client. As the client cache becomes full, a policy is needed to decide which item (s) to delete, when subsequent items cannot fit in the cache. <p> Caching schemes have to work with the scheduling algorithms to further reduce the access time for the client. As the client cache becomes full, a policy is needed to decide which item (s) to delete, when subsequent items cannot fit in the cache. Several caching policies <ref> [8, 11, 21, 22] </ref> for data broadcasting have been proposed. This thesis proposes a caching policy for an on-demand broadcast model. The caching decisions made by the clients are completely based upon information received from the server. <p> This channel is different from the broadcast channel. Hence, the bandwidth available to the server is not affected by the client requests. This assumption is similar to that made in <ref> [8, 20] </ref>. * Every item, that is broadcast by the server, is received by all the clients. * Scheduling Algorithm [13]: It is an algorithm that is used by the server to determine which item to broadcast. * Caching Scheme: A caching scheme is used by the clients to determine how <p> Mean access time is simply the average over all the requests made by the clients. It is used as a performance measure throughout this thesis. Other researchers <ref> [8, 10, 11, 13, 14, 17, 20] </ref> have used this as their performance measure as well. * Weight: Weight of an item is the "cost" associated with not transmitting the item. <p> Since no consideration is given to the waiting times, this policy could lead to starvation for certain items. Acharya et. al. <ref> [8, 9, 21] </ref> proposed interesting ways of solving the broadcast scheduling problem. They use a combination of server scheduling and client caching, as does this thesis. Their schemes simply divide up the bandwidth based on the item demand probabilities, and determine the schedule a priori. <p> In case of a cache miss the item with the lowest last use time is replaced. As evident, LRU is not a broadcast specific scheme and hence does not make use of the knowledge the server has about client demands. * P <ref> [8] </ref>: P is a demand-driven caching policy which keeps items with the highest probability of access in the memory. So, in response to a cache-miss, P chooses as the victim, the cache-resident item with the lowest probability of access. <p> So, in response to a cache-miss, P chooses as the victim, the cache-resident item with the lowest probability of access. P requires perfect knowledge of the probability of access of the items. Therefore, it cannot be used in an on-demand environment. * PIX <ref> [8] </ref>: PIX is a cost based heuristic for demand driven caching. In PIX, the cost of replacement of an item already in memory with the newly fetched one is 10 considered to be the ratio of the access probability of item (P) and its broadcast frequency. <p> The replacement algorithm ejects any item in memory which has the lowest pix value or has value lower than the current item. * PT <ref> [8] </ref>: PT is a pre-fetching heuristic. It exploits the dissemination-based nature of the broadcast, which are particularly conducive to the user's prefetching. <p> A system where all items are equally popular, makes it difficult to improve performance using caching, since all items have the same cost associated with their deletion or addition. Therefore, our caching policy works very well in the presence of high access skew. Previous caching policies <ref> [8, 24] </ref> require the clients to store information about the items, such as demand probability, in order to make caching decisions. However, client request patterns can be completely unpredictable. <p> An event-driven simulator was used to measure the performance. A database of 1000 items (M) was used. Other parameters are described below. Demand Probability: We use the Zipf distribution to model item popularity. Other researchers <ref> [8, 11, 12, 13, 17, 18, 19, 20] </ref>, have also made this assumption. The Zipf distribution gives probability values for the items as follows: p i = P M where is the access skew coefficient. The higher the value of , the greater the disparity in popularity among the items. <p> All simulations were performed for 8 million client requests. We compared the performance of the Prefix caching policy to the Least Recently Used (LRU) caching policy and the PT <ref> [8] </ref> caching policy. Chapter III provides a description of these policies. All simulations for the caching policies used the Total Wait Time algorithm, since it performed the best.
Reference: [9] <author> S. Acharya, M. Franklin, and S. Zdonik, </author> <title> "Dissemination-based data delivery using broadcast disks," </title> <journal> IEEE Personal Communications, </journal> <volume> vol. 2, no. 6, </volume> <pages> pp. 50-60, </pages> <month> December </month> <year> 1995. </year> <month> 57 </month>
Reference-contexts: Since no consideration is given to the waiting times, this policy could lead to starvation for certain items. Acharya et. al. <ref> [8, 9, 21] </ref> proposed interesting ways of solving the broadcast scheduling problem. They use a combination of server scheduling and client caching, as does this thesis. Their schemes simply divide up the bandwidth based on the item demand probabilities, and determine the schedule a priori.
Reference: [10] <author> D. Aksoy and M. Franklin, </author> <title> "Scheduling for large-scale on-demand data broadcasting," </title> <booktitle> in Proceedings of IEEE Conference on Computer Communications (IN-FOCOM), </booktitle> <month> April </month> <year> 1998, </year> <pages> pp. 652-659. </pages>
Reference-contexts: There has been a lot of research [4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20] in broadcast scheduling. Most of these schemes assume that the client plays no part in the scheduling decisions made by the server. In some cases <ref> [10, 17, 20] </ref>, including this thesis, the schedule is based on explicit requests made by the clients. This is the on-demand or pull-based data broadcast model. Access time can be defined as the time between a client request and the time when it has finished receiving the requested item. <p> Mean access time is simply the average over all the requests made by the clients. It is used as a performance measure throughout this thesis. Other researchers <ref> [8, 10, 11, 13, 14, 17, 20] </ref> have used this as their performance measure as well. * Weight: Weight of an item is the "cost" associated with not transmitting the item. <p> The higher the value of , the greater the disparity in popularity among the items. Item Lengths: We use items of varying lengths for the simulations. The items have lengths uniformly distributed between 1 and 10. However, since <ref> [10] </ref> assumed equal lengths for their items, we also produce results with equal lengths (10) for all the items, so as to provide a fair comparison with [10]. Request Generation: The inter-request time for the clients was obtained according to a Poisson process. <p> The items have lengths uniformly distributed between 1 and 10. However, since <ref> [10] </ref> assumed equal lengths for their items, we also produce results with equal lengths (10) for all the items, so as to provide a fair comparison with [10]. Request Generation: The inter-request time for the clients was obtained according to a Poisson process. We set the mean inter-request time of the Poisson process to be 2 in all cases, except the simulation for the hierarchical model. <p> All simulations were performed for 8 million client requests. We compared the performance of both the algorithms, with the Most Request First (MRF) [23] algorithm, the S2P [18] algorithm, and the RxW <ref> [10] </ref> algorithm. Chapter III provides a brief description of these algorithms. Fig. 8 plots the performance evaluation results for these algorithms. Since the RxW algorithm was proposed for items of equal lengths only in [10], we plot simulation results for the algorithm, where the items are of equal length in Fig. <p> algorithms, with the Most Request First (MRF) [23] algorithm, the S2P [18] algorithm, and the RxW <ref> [10] </ref> algorithm. Chapter III provides a brief description of these algorithms. Fig. 8 plots the performance evaluation results for these algorithms. Since the RxW algorithm was proposed for items of equal lengths only in [10], we plot simulation results for the algorithm, where the items are of equal length in Fig. 9.
Reference: [11] <author> M. H. Ammar, </author> <title> "Response time in a teletext system: An individual user's perspective," </title> <journal> IEEE Transactions on Communications, </journal> <volume> vol. COM-35, no. 11, </volume> <pages> pp. 1159-1170, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: Caching schemes have to work with the scheduling algorithms to further reduce the access time for the client. As the client cache becomes full, a policy is needed to decide which item (s) to delete, when subsequent items cannot fit in the cache. Several caching policies <ref> [8, 11, 21, 22] </ref> for data broadcasting have been proposed. This thesis proposes a caching policy for an on-demand broadcast model. The caching decisions made by the clients are completely based upon information received from the server. <p> Mean access time is simply the average over all the requests made by the clients. It is used as a performance measure throughout this thesis. Other researchers <ref> [8, 10, 11, 13, 14, 17, 20] </ref> have used this as their performance measure as well. * Weight: Weight of an item is the "cost" associated with not transmitting the item. <p> As mentioned in Chapter I, minimizing the mean access time has been the primary performance objective in designing scheduling algorithms. Some of the early research in broadcast scheduling was performed by Ammar and Wong <ref> [11, 12, 20] </ref>. [20] studied the problem of on-demand broadcast scheduling and proposed the First-Come First-Serve algorithm. Here, the server broadcasts the item with the earliest request arrival time. <p> Since this scheme requires a priori knowledge of the popularity of the items and the broadcast schedule, it cannot be used in an on-demand environment. * Ammar's scheme <ref> [11] </ref>: In this scheme each item in the broadcast has a control information associated with it. The control information in item i is a list of items that are most likely to be requested next by the user. <p> An event-driven simulator was used to measure the performance. A database of 1000 items (M) was used. Other parameters are described below. Demand Probability: We use the Zipf distribution to model item popularity. Other researchers <ref> [8, 11, 12, 13, 17, 18, 19, 20] </ref>, have also made this assumption. The Zipf distribution gives probability values for the items as follows: p i = P M where is the access skew coefficient. The higher the value of , the greater the disparity in popularity among the items.
Reference: [12] <author> M. H. Ammar and J. W. Wong, </author> <title> "On the optimality of cyclic transmission in teletext systems," </title> <journal> IEEE Transactions on Communications, </journal> <volume> vol. COM-35, no. 1, </volume> <pages> pp. 68-73, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: As mentioned in Chapter I, minimizing the mean access time has been the primary performance objective in designing scheduling algorithms. Some of the early research in broadcast scheduling was performed by Ammar and Wong <ref> [11, 12, 20] </ref>. [20] studied the problem of on-demand broadcast scheduling and proposed the First-Come First-Serve algorithm. Here, the server broadcasts the item with the earliest request arrival time. <p> An event-driven simulator was used to measure the performance. A database of 1000 items (M) was used. Other parameters are described below. Demand Probability: We use the Zipf distribution to model item popularity. Other researchers <ref> [8, 11, 12, 13, 17, 18, 19, 20] </ref>, have also made this assumption. The Zipf distribution gives probability values for the items as follows: p i = P M where is the access skew coefficient. The higher the value of , the greater the disparity in popularity among the items.
Reference: [13] <author> S. Hameed, </author> <title> "Scheduling information broadcast in asymmetric environment," </title> <type> Master's thesis, </type> <institution> Texas A&M University, College Station, Texas, </institution> <month> May </month> <year> 1997. </year>
Reference-contexts: Hence, the bandwidth available to the server is not affected by the client requests. This assumption is similar to that made in [8, 20]. * Every item, that is broadcast by the server, is received by all the clients. * Scheduling Algorithm <ref> [13] </ref>: It is an algorithm that is used by the server to determine which item to broadcast. * Caching Scheme: A caching scheme is used by the clients to determine how best to make use of local cache. <p> Mean access time is simply the average over all the requests made by the clients. It is used as a performance measure throughout this thesis. Other researchers <ref> [8, 10, 11, 13, 14, 17, 20] </ref> have used this as their performance measure as well. * Weight: Weight of an item is the "cost" associated with not transmitting the item. <p> Whenever the server becomes idle, from amongst all items whose next broadcast time is less than or equal to the current time, the item with the lowest C i is chosen as the next item to be broadcast. This algorithm is also extended to a multi-channel broadcast model. <ref> [13] </ref> also considers scheduling broadcasts in the presence of transmission errors. 9 Recently, [16] proposed using the variance of the access times as a performance goal of the scheduling algorithm. They proposed scheduling algorithms that aim to minimize the variance. <p> An event-driven simulator was used to measure the performance. A database of 1000 items (M) was used. Other parameters are described below. Demand Probability: We use the Zipf distribution to model item popularity. Other researchers <ref> [8, 11, 12, 13, 17, 18, 19, 20] </ref>, have also made this assumption. The Zipf distribution gives probability values for the items as follows: p i = P M where is the access skew coefficient. The higher the value of , the greater the disparity in popularity among the items.
Reference: [14] <author> S. Hameed and N. H. </author> <title> Vaidya , "Efficient algorithms for scheduling data broadcast," </title> <journal> ACM/Baltzer Wireless Networks Journal, </journal> <note> to appear. http://www.cs.tamu.edu/faculty/vaidya/mobile.html, accessed on June 16, </note> <year> 1998. </year>
Reference-contexts: Mean access time is simply the average over all the requests made by the clients. It is used as a performance measure throughout this thesis. Other researchers <ref> [8, 10, 11, 13, 14, 17, 20] </ref> have used this as their performance measure as well. * Weight: Weight of an item is the "cost" associated with not transmitting the item.
Reference: [15] <author> S. Hameed and N. H. </author> <title> Vaidya , "Log-time Algorithms for Scheduling Single and Multiple Channel Data Broadcast," </title> <booktitle> ACM/IEEE International Conference on Mobile Computing and Networking (MOBICOM), </booktitle> <month> September </month> <year> 1997. </year> <note> http://www.cs.tamu.edu/faculty/vaidya/mobile.html, accessed on December 1, </note> <year> 1997. </year>
Reference-contexts: The best mean access time is obtained for fl = 0.5. Vaidya and Hameed [18] proposed an O (M)-time algorithm that uses s 2 i p i /l i , 1 i M, as the weight of each item, and transmits an item with the largest weight. <ref> [15] </ref> also presents two O (logM) algorithms, based on packet fair queueing, for single and multiple channel broadcast scheduling. For the O (logM) algorithm, two variables the earliest start time for the next broadcast and the broadcast after that (C i ) are maintained for every item.
Reference: [16] <author> S. Jiang and N. H. Vaidya, </author> <title> "Scheduling algorithms for a data broadcast system: minimizing variance of the response time," </title> <type> Tech. Rep. 98-005, </type> <institution> Computer Science Department, Texas A&M University, College Station, </institution> <month> February </month> <year> 1998. </year> <month> 58 </month>
Reference-contexts: Here clients make requests to a proxy server instead of the main server. Only requests that cannot 4 be satisfied by the proxy server are sent to the main server. We evaluate such a hierarchical broadcast model. Jiang and Vaidya <ref> [16] </ref> have proposed scheduling algorithms that aim to minimize the variance of the access times in a push-based broadcast environment. We look at how we can try to balance the performance of a pull-based system, so that the variance of the access times is reduced. <p> This algorithm is also extended to a multi-channel broadcast model. [13] also considers scheduling broadcasts in the presence of transmission errors. 9 Recently, <ref> [16] </ref> proposed using the variance of the access times as a performance goal of the scheduling algorithm. They proposed scheduling algorithms that aim to minimize the variance. <p> However, this can cause the waiting time for the unpopular items to be very high. As a result, we have to give more importance to s i , if we are to alleviate some of the high waiting times for the unpopular items. <ref> [16] </ref> proposed scheduling algorithms that aim to minimize the variance by giving more importance to the time since the last broadcast for every item. Based on the work done in [16], we conducted various experiments that used a different weight 31 measure for the SR scheduling algorithm. <p> importance to s i , if we are to alleviate some of the high waiting times for the unpopular items. <ref> [16] </ref> proposed scheduling algorithms that aim to minimize the variance by giving more importance to the time since the last broadcast for every item. Based on the work done in [16], we conducted various experiments that used a different weight 31 measure for the SR scheduling algorithm. We used s ff (1ff) l i as the weight to make the scheduling decision. The modified algorithm is referred to as ff-SR. <p> When fi = (1 ff), we get the ff-SR algorithm, and when ff = fi = 1, we get the original SR algorithm. An alternative is using s ff i R i =l i , similar to the push algorithm in <ref> [16] </ref>. 32 CHAPTER VIII PERFORMANCE EVALUATION In this chapter we present the performance measurements. An event-driven simulator was used to measure the performance. A database of 1000 items (M) was used. Other parameters are described below. Demand Probability: We use the Zipf distribution to model item popularity. <p> There are several issues that have to be tackled in this new paradigm. We list a few in this section. 1. Although we looked at the issue of reducing the variance of the access times, more work has to be done in this area. As mentioned in Chapter III, <ref> [16] </ref> proposed some solutions. But they do not take the on-demand model into consideration. If any quality of service guarantees are to made, then the variance is as important as the overall mean access time. 2.
Reference: [17] <author> C. J. Su and L. Tassiulas, </author> <title> "Broadcast scheduling for information distribution," </title> <booktitle> in Proceedings of IEEE Conference on Computer Communications (INFOCOM), </booktitle> <year> 1997. </year> <note> http://www.ee.umd.edu/ leandros/infocom97.ps, accessed on June 20, </note> <year> 1998. </year>
Reference-contexts: There has been a lot of research [4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20] in broadcast scheduling. Most of these schemes assume that the client plays no part in the scheduling decisions made by the server. In some cases <ref> [10, 17, 20] </ref>, including this thesis, the schedule is based on explicit requests made by the clients. This is the on-demand or pull-based data broadcast model. Access time can be defined as the time between a client request and the time when it has finished receiving the requested item. <p> Mean access time is simply the average over all the requests made by the clients. It is used as a performance measure throughout this thesis. Other researchers <ref> [8, 10, 11, 13, 14, 17, 20] </ref> have used this as their performance measure as well. * Weight: Weight of an item is the "cost" associated with not transmitting the item. <p> Also, their algorithm can leave holes (periods of time for which the channel is unused), since it strives to maintain constant spacing between broadcast instances of an item. They also studied the issue of dividing up the bandwidth between client-server and broadcast based data delivery. Su and Tassiulas <ref> [17] </ref> have also studied the problem of broadcasting in an on-demand environment. They propose using fl i R i , 1 i M, as the item weight, where i is the request arrival rate for item i. <p> An event-driven simulator was used to measure the performance. A database of 1000 items (M) was used. Other parameters are described below. Demand Probability: We use the Zipf distribution to model item popularity. Other researchers <ref> [8, 11, 12, 13, 17, 18, 19, 20] </ref>, have also made this assumption. The Zipf distribution gives probability values for the items as follows: p i = P M where is the access skew coefficient. The higher the value of , the greater the disparity in popularity among the items.
Reference: [18] <author> N. H. Vaidya and S. </author> <title> Hameed , "Data broadcast in asymmetric wireless environments," </title> <booktitle> Workshop on Satellite Based Information Services (WOSBIS), </booktitle> <pages> pp. 38-52, </pages> <month> November </month> <year> 1996. </year>
Reference-contexts: They calculate i as p i , where is the overall request arrival rate. The best mean access time is obtained for fl = 0.5. Vaidya and Hameed <ref> [18] </ref> proposed an O (M)-time algorithm that uses s 2 i p i /l i , 1 i M, as the weight of each item, and transmits an item with the largest weight. [15] also presents two O (logM) algorithms, based on packet fair queueing, for single and multiple channel broadcast <p> They proposed scheduling algorithms that aim to minimize the variance. Their ff-algorithm is a variation of the O (M)-time algorithm, from <ref> [18] </ref>, in that it varies ff, between 2 and 3, in s ff i p i /l i . <p> The performance goal of the algorithm is to minimize the mean access time for the clients. Every time the server becomes idle, which happens immediately after it has finished broadcasting an item, the server uses this algorithm to decide the next item to broadcast 1 . <ref> [18] </ref> proposed an algorithm which uses a decision rule to determine the next broadcast item. <p> Every time the server needs to make a decision, the value s 2 l i is calculated, where s i is the time since the last broadcast of item i, p i the demand probability, and l i the length of item i. However, <ref> [18] </ref> assumes that the server has a priori knowledge of the demand probabilities of all items, which is not valid for an on-demand model. <p> An event-driven simulator was used to measure the performance. A database of 1000 items (M) was used. Other parameters are described below. Demand Probability: We use the Zipf distribution to model item popularity. Other researchers <ref> [8, 11, 12, 13, 17, 18, 19, 20] </ref>, have also made this assumption. The Zipf distribution gives probability values for the items as follows: p i = P M where is the access skew coefficient. The higher the value of , the greater the disparity in popularity among the items. <p> All simulations were performed for 8 million client requests. We compared the performance of both the algorithms, with the Most Request First (MRF) [23] algorithm, the S2P <ref> [18] </ref> algorithm, and the RxW [10] algorithm. Chapter III provides a brief description of these algorithms. Fig. 8 plots the performance evaluation results for these algorithms.
Reference: [19] <author> N. H. Vaidya and S. Hameed, </author> <title> "Scheduling data broadcast in asymmetric communication environments," </title> <journal> ACM/Baltzer Wireless Networks Journal, </journal> <note> to appear. http://www.cs.tamu.edu/faculty/vaidya/mobile.html, accessed on June 16, </note> <year> 1998. </year>
Reference-contexts: An event-driven simulator was used to measure the performance. A database of 1000 items (M) was used. Other parameters are described below. Demand Probability: We use the Zipf distribution to model item popularity. Other researchers <ref> [8, 11, 12, 13, 17, 18, 19, 20] </ref>, have also made this assumption. The Zipf distribution gives probability values for the items as follows: p i = P M where is the access skew coefficient. The higher the value of , the greater the disparity in popularity among the items.
Reference: [20] <author> J. W. Wong, </author> <title> "Broadcast delivery," </title> <booktitle> in Proceedings of IEEE, </booktitle> <month> December </month> <year> 1998, </year> <pages> pp. 1566-1577. </pages>
Reference-contexts: There has been a lot of research [4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20] in broadcast scheduling. Most of these schemes assume that the client plays no part in the scheduling decisions made by the server. In some cases <ref> [10, 17, 20] </ref>, including this thesis, the schedule is based on explicit requests made by the clients. This is the on-demand or pull-based data broadcast model. Access time can be defined as the time between a client request and the time when it has finished receiving the requested item. <p> This channel is different from the broadcast channel. Hence, the bandwidth available to the server is not affected by the client requests. This assumption is similar to that made in <ref> [8, 20] </ref>. * Every item, that is broadcast by the server, is received by all the clients. * Scheduling Algorithm [13]: It is an algorithm that is used by the server to determine which item to broadcast. * Caching Scheme: A caching scheme is used by the clients to determine how <p> Mean access time is simply the average over all the requests made by the clients. It is used as a performance measure throughout this thesis. Other researchers <ref> [8, 10, 11, 13, 14, 17, 20] </ref> have used this as their performance measure as well. * Weight: Weight of an item is the "cost" associated with not transmitting the item. <p> As mentioned in Chapter I, minimizing the mean access time has been the primary performance objective in designing scheduling algorithms. Some of the early research in broadcast scheduling was performed by Ammar and Wong <ref> [11, 12, 20] </ref>. [20] studied the problem of on-demand broadcast scheduling and proposed the First-Come First-Serve algorithm. Here, the server broadcasts the item with the earliest request arrival time. <p> As mentioned in Chapter I, minimizing the mean access time has been the primary performance objective in designing scheduling algorithms. Some of the early research in broadcast scheduling was performed by Ammar and Wong [11, 12, 20]. <ref> [20] </ref> studied the problem of on-demand broadcast scheduling and proposed the First-Come First-Serve algorithm. Here, the server broadcasts the item with the earliest request arrival time. <p> An event-driven simulator was used to measure the performance. A database of 1000 items (M) was used. Other parameters are described below. Demand Probability: We use the Zipf distribution to model item popularity. Other researchers <ref> [8, 11, 12, 13, 17, 18, 19, 20] </ref>, have also made this assumption. The Zipf distribution gives probability values for the items as follows: p i = P M where is the access skew coefficient. The higher the value of , the greater the disparity in popularity among the items.
Reference: [21] <author> S. Acharya, M. Franklin, and S. Zdonik, </author> <title> "Prefetching from a broadcast disk," </title> <booktitle> 12th International Conference on Data Engineering, </booktitle> <month> February </month> <year> 1996. </year> <note> http://www.cs.umd.edu/users/franklin/papers/icde96.ps.gz, accessed on June 20, </note> <year> 1998. </year>
Reference-contexts: Caching schemes have to work with the scheduling algorithms to further reduce the access time for the client. As the client cache becomes full, a policy is needed to decide which item (s) to delete, when subsequent items cannot fit in the cache. Several caching policies <ref> [8, 11, 21, 22] </ref> for data broadcasting have been proposed. This thesis proposes a caching policy for an on-demand broadcast model. The caching decisions made by the clients are completely based upon information received from the server. <p> Since no consideration is given to the waiting times, this policy could lead to starvation for certain items. Acharya et. al. <ref> [8, 9, 21] </ref> proposed interesting ways of solving the broadcast scheduling problem. They use a combination of server scheduling and client caching, as does this thesis. Their schemes simply divide up the bandwidth based on the item demand probabilities, and determine the schedule a priori.
Reference: [22] <author> C. J. Su and L. Tassiulas, </author> <title> "Optimal memory management strategies for a mobile user in a broadcast delivery system," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <note> 1999, to appear. http://www.ee.umd.edu/ leandros/tass1.htm, accessed on June 1, </note> <year> 1998. </year>
Reference-contexts: Caching schemes have to work with the scheduling algorithms to further reduce the access time for the client. As the client cache becomes full, a policy is needed to decide which item (s) to delete, when subsequent items cannot fit in the cache. Several caching policies <ref> [8, 11, 21, 22] </ref> for data broadcasting have been proposed. This thesis proposes a caching policy for an on-demand broadcast model. The caching decisions made by the clients are completely based upon information received from the server.
Reference: [23] <author> H. D. Dykeman, M. H. Ammar, and J. W. Wong, </author> <title> "Scheduling algorithms for videotex systems under broadcast delivery," </title> <booktitle> in Proceedings of the International Conference on Communications, </booktitle> <year> 1986, </year> <pages> pp. 1847-1851. 59 </pages>
Reference-contexts: This is done by adding subsequent requests for an item, in the same position in the request queue as the first one. However, no consideration is given to the popularity of the items. <ref> [23] </ref> proposed the Most Request First (MRF) algorithm, which chooses the item with the highest number of pending requests as the next item 8 to be broadcast. Since no consideration is given to the waiting times, this policy could lead to starvation for certain items. <p> All simulations were performed for 8 million client requests. We compared the performance of both the algorithms, with the Most Request First (MRF) <ref> [23] </ref> algorithm, the S2P [18] algorithm, and the RxW [10] algorithm. Chapter III provides a brief description of these algorithms. Fig. 8 plots the performance evaluation results for these algorithms.
Reference: [24] <author> A. Tanenbaum, </author> <title> Modern Operating Systems. Upper Saddle River, </title> <address> New Jersey: </address> <publisher> Prentice Hall, </publisher> <year> 1992. </year>
Reference-contexts: They also proposed a Variance Optimal Algorithm that uses p i s i ( 3 1 M X p i s i ); 1 i M (3.1) as the weight to make the scheduling decision. B. Caching Schemes Some of the proposed schemes for caching are: * LRU <ref> [24] </ref>: LRU is the simplest of the schemes used as the cache replacement policy. In response to a cache miss, LRU chooses as the victim, the item which has the lowest last use time. <p> A system where all items are equally popular, makes it difficult to improve performance using caching, since all items have the same cost associated with their deletion or addition. Therefore, our caching policy works very well in the presence of high access skew. Previous caching policies <ref> [8, 24] </ref> require the clients to store information about the items, such as demand probability, in order to make caching decisions. However, client request patterns can be completely unpredictable. <p> It is optional, if that is not the case. There are several choices possible for costf () in Step 4 of the generalized algo rithm. For instance: 1. The time since the item was last used by the client, similar to LRU <ref> [24] </ref>. 2. The time since the last use of the item by the client or the last broadcast time, whichever is latest (as in our algorithm). 24 3.
Reference: [25] <author> B. R. Badrinath, T. Imielinski and S. Viswanathan, </author> <title> "Energy efficient indexing on air," </title> <booktitle> in Proceedings of ACM Special Interest Group on Management of Data (SIGMOD), </booktitle> <month> May </month> <year> 1994, </year> <pages> pp. 25-37. </pages>
Reference-contexts: This is because the clients in this case may be low-powered devices, and the more time spent listening to the broadcast, the higher the amount of energy spent. Viswanathan et. al. <ref> [1, 4, 25] </ref> have proposed solutions that address this issue. They call the time a client spends listening to the broadcast as the tuning time. They 11 propose indexing the broadcast so that the client knows exactly when to listen to the broadcast to get the required item.
Reference: [26] <author> M.-S. Chen, P. S. Yu, and K.-L. Wu, </author> <title> "Indexed sequential data broadcasting in wireless mobile computing," </title> <booktitle> in Proceedings of 17th IEEE International Conference on Distributed Computing Systems, </booktitle> <month> May </month> <year> 1997, </year> <pages> pp. 124-131. </pages>
Reference-contexts: They calculate the optimum value of m as q N=n, where N is the size of the broadcast cycle and n is the size of the index. They also present other distributed indexing schemes that break up the index and minimize replication of information. <ref> [26] </ref> also proposes indexing schemes for data broadcasting. They take into consideration the item demand probabilities. They propose constructing index trees such that items with high demand probabilities can be found faster, than those with lower probabilities, in the index.
Reference: [27] <author> A. L. N. Reddy, </author> <title> "Caching strategies for a multimedia server," </title> <booktitle> in Proceedings of IEEE Conference on Multimedia Computing and Systems, </booktitle> <month> June </month> <year> 1997. </year> <note> http://ee.tamu.edu/ reddy/papers/ieeemm97.ps, accessed on June 25, </note> <year> 1998. </year>
Reference-contexts: The product of the length of the item and the time since the last use of the item by the client or the last broadcast time, whichever is latest. This is based on a caching scheme that was proposed in <ref> [27] </ref>. The scheme in [27] was proposed for an Internet server, not a broadcast system. We did not evaluate the algorithm for all the choices of costf (). Only choice 2 was evaluated. 25 CHAPTER VI HIERARCHICAL BROADCAST MODEL In this chapter, we evaluate a hierarchical broadcast model. <p> The product of the length of the item and the time since the last use of the item by the client or the last broadcast time, whichever is latest. This is based on a caching scheme that was proposed in <ref> [27] </ref>. The scheme in [27] was proposed for an Internet server, not a broadcast system. We did not evaluate the algorithm for all the choices of costf (). Only choice 2 was evaluated. 25 CHAPTER VI HIERARCHICAL BROADCAST MODEL In this chapter, we evaluate a hierarchical broadcast model.
Reference: [28] <author> T. Brisco, </author> <title> "RFC 1794: DNS support for load balancing," </title> <month> April </month> <year> 1995. </year> <title> Status: Informational. </title> <journal> ftp://ftp.internic.net/rfc/rfc1794.txt, </journal> <note> accessed on June 10, </note> <year> 1998. </year>
Reference-contexts: Here, clients send their requests to a proxy server, instead of the main server. A proxy server could be located close to the main server, or we can can have proxy servers that are geographically closer to some portion of the client population. We assume that some re-routing mechanism <ref> [28, 29] </ref> exists, that diverts requests from the clients to the appropriate proxy server. An example of such an hierarchical system is shown in Fig. 6. In the model that we evaluate, the behavior of the main server is unchanged. Here, only the proxy servers form its client population.
Reference: [29] <author> H. Chawla and R. Bettati, </author> <title> "Replicating IP services," </title> <type> Tech. Rep. 97-008, </type> <institution> Department of Computer Science, Texas A&M University, </institution> <month> September </month> <year> 1997. </year>
Reference-contexts: Here, clients send their requests to a proxy server, instead of the main server. A proxy server could be located close to the main server, or we can can have proxy servers that are geographically closer to some portion of the client population. We assume that some re-routing mechanism <ref> [28, 29] </ref> exists, that diverts requests from the clients to the appropriate proxy server. An example of such an hierarchical system is shown in Fig. 6. In the model that we evaluate, the behavior of the main server is unchanged. Here, only the proxy servers form its client population.
Reference: [30] <author> S. Deering, </author> <title> "RFC 1112: Host extensions for IP multicasting," </title> <month> August </month> <year> 1989. </year> <title> Status: Standard. </title> <journal> ftp://ftp.internic.net/rfc/rfc1112.txt, </journal> <note> accessed on June 24, </note> <year> 1998. </year>
Reference-contexts: There are other models that could be used depending upon the application needs. These models are illustrated in Fig. 7. Note that the "broadcast" may be implemented using IP multicasting <ref> [30] </ref> or any other multicasting tool. 29 CHAPTER VII REDUCING THE VARIANCE In this chapter, we discuss using the standard deviation of the access times in addition to the mean access time as a performance goal of the scheduling algorithm. Standard deviation is the square root of the variance.

References-found: 30

