URL: http://www.robotics.stanford.edu/~hhg/upenn/paper.ps
Refering-URL: http://www.robotics.stanford.edu/~hhg/upenn/
Root-URL: http://www.robotics.stanford.edu
Email: @robotics.stanford.edu f gordillo, asarmien g @labrim.mty.itesm.mx  
Title: A Robotic Tool for Experimentation among Geographically Dispersed Groups  
Author: Hector Gonzalez-Ba~nos David Lin Jean-Claude Latombe Carlo Tomasi Jose-Luis Gordillo Alejandro Sarmiento f hhg, dlin, latombe, tomasi g 
Address: CA 94305 Monterrey, Mexico, 64849  
Affiliation: Robotics Laboratory, CS Dept. C. de Intel. Artificial, ITESM Stanford University,  
Abstract: This paper describes a robotic tool that permits geographically dispersed groups to collaborate and jointly supervise a common experiment.... MORE VERB HERE 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Becker, H. Gonzalez-Banos, J.-C. Latombe, and C. Tomasi. </author> <title> An intelligent observer. </title> <booktitle> In Proc. 4th International Symposium on Experimental Robotics, </booktitle> <pages> pages 153-160, </pages> <year> 1995. </year>
Reference-contexts: 1 Introduction CONSTRUCT INTRODUCTION WITH THIS MATERIAL..... My comments.... (the concept was introduced in <ref> [1] </ref>, three extensions identified. paper [HIDESEEK] and [9], address the theoretical intricacies behind the target seeking and target tracking. <p> In addition, the system has been succesfully tested as a virtual monitor for remote experiment supervision. The implementation of the autonomous tracking system has demonstrated the feasibility of the concept introduced in <ref> [1] </ref> and later extended in [4]. Furthermore, we have also shown its potential as a tool for joint experimentation between dispersed groups. Ongoing research now focuses on integrating into the system our target seeking and map building algorithms, some of which have already been individually tested with positive results.
Reference: [2] <author> C. Becker, J. Salas, K. Tokusei, and J.C. Latombe. </author> <title> Reliable navigation using landmarks. </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pages 401-406, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Our approach to this problem involves placing artificial landmarks throughout the environment. Many researchers have studied the use of landmarks in robot navigation (for examples see [5, 8, 10, 11]). The landmark detection module onboard the AO is the result of the experimental work developed in <ref> [2] </ref>. The underlying idea behind the approach is to provide the positions of the landmarks as an input map to the observer. Each landmark induces a landmark region, from which the landmark is visible to the robot. The robot localizes itself by detecting landmarks and computing its relative position.
Reference: [3] <author> J.F. Canny. </author> <title> A computational approach to edge detection. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 8(6) </volume> <pages> 679-698, </pages> <year> 1986. </year>
Reference-contexts: Each landmark consists of a black square with a 4fi4 matrix of smaller squares inside of it. The detection algorithm first identifies edges in the image (using a variant of the algo rithm presented in <ref> [3] </ref>), and then looks for edge chains that are consistent with the boundary of a square. When a chain is found, lines are fitted to the pixels which make up each edge. These lines and their intersections yield the orientation of the landmark its corners.
Reference: [4] <author> H. Gonzalez-Banos and et Al. </author> <title> Motion planning with visibility constraints: Building autonomous observers. </title> <booktitle> In Proc. 1997 International Symposium of Robotics Research, </booktitle> <year> 1997. </year>
Reference-contexts: 1 Introduction CONSTRUCT INTRODUCTION WITH THIS MATERIAL..... My comments.... (the concept was introduced in [1], three extensions identified. paper [HIDESEEK] and [9], address the theoretical intricacies behind the target seeking and target tracking. The paper <ref> [4] </ref> unifies the three problems as specific instances of a special planning problem: Motion Planning under Visibility Constraints.) (in this paper we are going to explain how to construct an observer that succesfully permits joint experimentation between geographically dispersed groups. this can be done without extremely sophisticated hardware, and the software <p> In addition, the system has been succesfully tested as a virtual monitor for remote experiment supervision. The implementation of the autonomous tracking system has demonstrated the feasibility of the concept introduced in [1] and later extended in <ref> [4] </ref>. Furthermore, we have also shown its potential as a tool for joint experimentation between dispersed groups. Ongoing research now focuses on integrating into the system our target seeking and map building algorithms, some of which have already been individually tested with positive results.
Reference: [5] <author> S. Hutchinson. </author> <title> Exploiting visual constraints in robot motion planning. </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pages 1722-1727, </pages> <year> 1991. </year>
Reference-contexts: Our approach to this problem involves placing artificial landmarks throughout the environment. Many researchers have studied the use of landmarks in robot navigation (for examples see <ref> [5, 8, 10, 11] </ref>). The landmark detection module onboard the AO is the result of the experimental work developed in [2]. The underlying idea behind the approach is to provide the positions of the landmarks as an input map to the observer.
Reference: [6] <author> D.P. Huttenlocher, J.J Noh, and W.J. Rucklidge. </author> <title> Tracking non-rigid objects in complex scenes. </title> <booktitle> In Proc. 4th Int. Conf. on Computer Vision, </booktitle> <pages> pages 93-101, </pages> <year> 1993. </year>
Reference-contexts: In general, for arbitrary targets, motions can be unconstrained and the target may be non-rigid. In order to handle arbitrary targets, we could apply real-time versions of tracking algorithms such as those described in <ref> [6] </ref> and [12]. For rigid targets with constrained motions (such as a mobile land vehicle, or a robot manipulator), we can use simpler and faster algorithms. Our current implementation tracks a cylindrical mobile robot with unobtrusive rectangular patterns placed on its surface (see Figure 3).
Reference: [7] <author> K. Kanatani. </author> <title> Geometric Computation for Machine Vision. </title> <address> Oxford Science Publicatons, </address> <year> 1993. </year>
Reference-contexts: At the same time, it also checks that the four detected corners are indeed perspective projections of a rectangle in space. This last check is based on a theorem by Kanatani stating that the vanishing points of a rectangle projection must be conjugate in the image plane (see <ref> [7] </ref>). The visual tracker additionaly executes adaptive thresholding to produce a suitable binary image based on the image intensity histogram at the previuosly detected pattern positions. The tracking system operates at approximately 25 FPS using 320fi240 grayscale images as input.
Reference: [8] <author> D.J. Kriegman, E. Triendl, </author> <title> and T.O. Binford. Stereo vision and navigation in buildings for mobile robots. </title> <journal> IEEE Trans. on Robotics and Automation, </journal> <volume> 5(6) </volume> <pages> 1722-1727, </pages> <year> 1991. </year>
Reference-contexts: Our approach to this problem involves placing artificial landmarks throughout the environment. Many researchers have studied the use of landmarks in robot navigation (for examples see <ref> [5, 8, 10, 11] </ref>). The landmark detection module onboard the AO is the result of the experimental work developed in [2]. The underlying idea behind the approach is to provide the positions of the landmarks as an input map to the observer.
Reference: [9] <author> S.M. LaValle, H. Gonzalez-Banos, C. Becker, and J.C. Latombe. </author> <title> Motion strategies for maintaining visibility of a moving target. </title> <booktitle> In Proc. 1997 IEEE Int'l Conf. Robotics & and Automation, </booktitle> <month> April </month> <year> 1997. </year>
Reference-contexts: 1 Introduction CONSTRUCT INTRODUCTION WITH THIS MATERIAL..... My comments.... (the concept was introduced in [1], three extensions identified. paper [HIDESEEK] and <ref> [9] </ref>, address the theoretical intricacies behind the target seeking and target tracking. <p> With the pose and barcode information of the detected patterns, the algorithm then infers the location and bearing of the target. (a) sample barcode pattern used for visual tracking. (c) A view of the barcode patterns on the target's surface. 2.3 Motion Planning As explained in <ref> [9] </ref>, target tracking without advance knowledge of the target's trajectory is a problem unduly complex to solve on-line. Under uncertainty, we are confined to solve for either the worst or expected case, both of which are untractable problems. <p> We must therefore resort to local solutions: our algorithm is an on-line scheme that maximizes the probability of future visibility over a limited time span. This approach is one of the schemes proposed in <ref> [9] </ref>, which is a local planner solving for the expected case. The planner assumes the observer is equipped with an omnidirectional camera, a false supposition. However, this assumption can be surmounted if an independent servo-loop keeps the camera oriented toward the target.
Reference: [10] <author> A. Lazanas and J.C. Latombe. </author> <title> Landmark-based robot navigation. </title> <journal> Algorithmica, </journal> <volume> 13 </volume> <pages> 472-501, </pages> <year> 1995. </year>
Reference-contexts: Our approach to this problem involves placing artificial landmarks throughout the environment. Many researchers have studied the use of landmarks in robot navigation (for examples see <ref> [5, 8, 10, 11] </ref>). The landmark detection module onboard the AO is the result of the experimental work developed in [2]. The underlying idea behind the approach is to provide the positions of the landmarks as an input map to the observer.
Reference: [11] <author> T.S. Levitt, D.T. Lawton, </author> <title> D.M. Chelberg, and P.C. Nelson. Qualitative navigation. </title> <booktitle> In Proc. DARPA Image Understanding Workshop, </booktitle> <pages> pages 447-465, </pages> <year> 1987. </year>
Reference-contexts: Our approach to this problem involves placing artificial landmarks throughout the environment. Many researchers have studied the use of landmarks in robot navigation (for examples see <ref> [5, 8, 10, 11] </ref>). The landmark detection module onboard the AO is the result of the experimental work developed in [2]. The underlying idea behind the approach is to provide the positions of the landmarks as an input map to the observer.
Reference: [12] <author> N. P. Papanikolopoulos, P. K. Khosla, and T. Kanade. </author> <title> Visual tracking of a moving target by a camera mounted on a robot: A combination of control and vision. </title> <journal> IEEE Trans. Robotics & Automation, </journal> <volume> 9(1) </volume> <pages> 14-35, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: In general, for arbitrary targets, motions can be unconstrained and the target may be non-rigid. In order to handle arbitrary targets, we could apply real-time versions of tracking algorithms such as those described in [6] and <ref> [12] </ref>. For rigid targets with constrained motions (such as a mobile land vehicle, or a robot manipulator), we can use simpler and faster algorithms. Our current implementation tracks a cylindrical mobile robot with unobtrusive rectangular patterns placed on its surface (see Figure 3). Each pattern has a binary barcode identifier.
References-found: 12

