URL: ftp://ftp.cc.gatech.edu/pub/coc/tech_reports/1996/GIT-CC-96-10.nofigs.ps.Z
Refering-URL: http://www.cs.gatech.edu/tech_reports/index.96.html
Root-URL: 
Title: Monitoring and Visualization in Cluster Environments  
Author: Brad Topol John T. Stasko Vaidy Sunderam 
Address: Atlanta, Georgia 30332-0280.  Atlanta, GA, 30322  
Affiliation: College of Computing, Georgia Institute of Technology,  Department of Math and Computer Science, Emory University,  
Note: Author's address:  Author's address:  
Date: March 1996  
Pubnum: GIT-CC-96-10  
Abstract: Cluster computing has evolved into a popular and effective mode of high performance computing. Cluster environments are intrinsically different from hardware multiprocessors, and hence require a different approach to measuring and characterizing performance, monitoring an application's progress, and understanding program behavior. In this article, we present the design and implementation of PVaniM, an experimental visualization environment we have developed for the PVM network computing system. PVaniM supports a two-phase approach whereby on-line visualization focuses on large-grained events that are influenced by and relate to the dynamic cluster environment, and postmortem visualization provides for detailed program analysis and tuning. PVaniM's capabilities are illustrated via its use on several applications and it is compared with other visualization environments developed for cluster computing. Our experiences indicate that for several classes of applications, the two-phase visualization scheme can provide more insight into the behavior, efficiency, and operation of distributed and parallel programs in cluster environments. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Beguelin, A., Dongarra, J., Geist, A., and Sunderam, V. </author> <title> Visualization and debugging in a heterogeneous environment. </title> <journal> Computer. </journal> <volume> 26, 6, </volume> <month> (June </month> <year> 1993), </year> <pages> 88-95. 31 </pages>
Reference-contexts: Typically, these tools do not provide views that illustrate external loads on the processing elements. Furthermore, they were originally meant for multicomputers which did not support multitasking <ref> [1] </ref>. In contrast, cluster environments are composed of multitasking workstations and multiple tasks may be assigned to each host. <p> For example, Hence <ref> [1] </ref>, Xab [1], and XPVM [5] all utilize event tracing which permits very detailed graphical views. While these types of views are very appropriate for off-line analysis, they require a large amount of network bandwidth when used on-line. <p> For example, Hence <ref> [1] </ref>, Xab [1], and XPVM [5] all utilize event tracing which permits very detailed graphical views. While these types of views are very appropriate for off-line analysis, they require a large amount of network bandwidth when used on-line. <p> If it is necessary to send statistics to the GUI, the routine performs a getrusage () system call to acquire other interesting resource information such as memory utilization and sends this data to the GUI. PVaniM uses techniques similar to Xab <ref> [1] </ref> to send satistics to the graphical user interface. Specifically, PVaniM utilizes PVM's multiple message buffer support so it may use PVM's message passing facilities without corrupting application message buffers. <p> Once the data is successfully read from the pipe, the monitoring routines send it to the graphical user interface which parses the data and generates PVaniM's Load Information view. 5 Related Work Several previous visualization systems have been developed for use in cluster computing environments. Xab <ref> [1] </ref> utilizes on-line event tracing to provide textual informational views available at run-time. Xab utilizes no buffering in its gathering of trace events and therefore not only requires a large amount of network bandwidth but also does not use it effectively. <p> While these delays may be perfectly acceptable and understandable in a postmortem profiling session, they are not acceptable during on-line analysis. The Hence environment <ref> [1] </ref> provides graphical development tools for composing parallel programs as well as providing on-line trace event based graphical views. Hence allows a user to draw a graph to describe the dependencies between user-defined function from which it automatically generates the parallel program.
Reference: [2] <author> Geist, G. et al. </author> <title> PICL:A Portable Instrumented Communication Library, C reference manual. </title> <type> Technical Report ORNL/TM-11130, </type> <institution> Oak Ridge National Lab., Oak Ridge, Tenn., </institution> <year> 1990. </year>
Reference-contexts: As discussed in [11], PVaniM's buffered tracing supports its own default library of visualizations and concurrent animations as well as allowing the user to develop application-specific visualizations. Furthermore, PVaniM provides a converter which translates PVaniM trace files to the PICL <ref> [2] </ref> trace format utilized by ParaGraph [4]. This allows PVaniM to also support ParaGraph views in addition to the visualization capabilities mentioned above.
Reference: [3] <author> Gu, W., Eisenhauer, G., Kraemer, E., Schwan, K., Stasko, J., and Vetter, J. </author> <title> Falcon: On-line monitoring and steering of large-scale parallel programs. </title> <type> Technical Report GIT-CC-94-21, </type> <institution> Georgia Institute of Technology, </institution> <address> Atlanta, GA, </address> <year> 1994. </year>
Reference-contexts: The on-line graphical views of PVaniM are resilient enough to support long running and communication-intensive PVM applications. * Support for interactive steering-Recent work on shared memory parallel processors has shown interactive steering to be extremely useful for large-scale molecular dynamics applications <ref> [3] </ref>. Steering essentially involves allowing a user to inspect and modify a program's attributes while it is executing. In order to integrate steering functionality into a cluster environment, an enhancement layer is necessary that allows external messages to be sent from an external task to application tasks. <p> PVaniM also differs because it incorporates external load information, a relatively complex procedure in typical cluster environments. PVaniM also provides support for transparently and safely sending steering messages into an application. Several systems also provide steering support in addition to monitoring. The Falcon environment <ref> [3] </ref> provides sampling, tracing, and interactive steering for high performance applications executing on shared memory parallel processors. The PVMAVS system [6] provides a library using PVM and AVS for the (scientific) visualization and steering of distributed simulations.
Reference: [4] <author> Heath, M. T. and Etheridge, J. A. </author> <title> Visualizing the performance of parallel programs. </title> <journal> IEEE Software. </journal> <volume> 8, 5, </volume> <month> (September </month> <year> 1991), </year> <note> 29 -39. </note>
Reference-contexts: The following are the primary novel features of the PVaniM system: * Graphical views tailored to cluster environments-Developing visualization support for clusters is more involved than simply porting traditional multicomputer tools such as ParaGraph <ref> [4] </ref> to the environment. Typically, these tools do not provide views that illustrate external loads on the processing elements. Furthermore, they were originally meant for multicomputers which did not support multitasking [1]. In contrast, cluster environments are composed of multitasking workstations and multiple tasks may be assigned to each host. <p> As discussed in [11], PVaniM's buffered tracing supports its own default library of visualizations and concurrent animations as well as allowing the user to develop application-specific visualizations. Furthermore, PVaniM provides a converter which translates PVaniM trace files to the PICL [2] trace format utilized by ParaGraph <ref> [4] </ref>. This allows PVaniM to also support ParaGraph views in addition to the visualization capabilities mentioned above.
Reference: [5] <author> Kohl, J. A. and Geist, G. A. </author> <title> The PVM 3.4 tracing facility and XPVM 1.1. </title> <booktitle> 29th Hawaii Int'l Conference on System Sciences (HICSS-29). </booktitle> <address> Maui, Hawaii, </address> <month> January </month> <year> 1996. </year>
Reference-contexts: For example, Hence [1], Xab [1], and XPVM <ref> [5] </ref> all utilize event tracing which permits very detailed graphical views. While these types of views are very appropriate for off-line analysis, they require a large amount of network bandwidth when used on-line. <p> Specifically, for each application, we provide snapshots of PVaniM's on-line graphical views as well as ParaGraph postmortem views that PVaniM provides via tracefile conversion. We then compare PVaniM's view support to XPVM <ref> [5] </ref>. XPVM also provides on-line and postmortem visualization support but uses the same views in on-line mode as it does it postmortem mode. <p> Xab [1] utilizes on-line event tracing to provide textual informational views available at run-time. Xab utilizes no buffering in its gathering of trace events and therefore not only requires a large amount of network bandwidth but also does not use it effectively. XPVM <ref> [5] </ref> provides graphical views of PVM applications, some similar to PVaniM. XPVM provides the same graphical views on-line as in postmortem mode. All of XPVM's graphical views are trace event based (and therefore utilize substantial network bandwidth).
Reference: [6] <author> Kohl, J. A. and Papadopoulos, P. M. </author> <title> A library for visualization and steering of distributed simulations using PVM and AVS. </title> <booktitle> High Performance Computing Symposium. </booktitle> <address> Montreal, CA, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: PVaniM also provides support for transparently and safely sending steering messages into an application. Several systems also provide steering support in addition to monitoring. The Falcon environment [3] provides sampling, tracing, and interactive steering for high performance applications executing on shared memory parallel processors. The PVMAVS system <ref> [6] </ref> provides a library using PVM and AVS for the (scientific) visualization and steering of distributed simulations.
Reference: [7] <author> Quinn, M. </author> <title> Designing Efficient Algorithms for Parallel Computers. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1987. </year>
Reference-contexts: The first of these is NAS Parallel Benchmark Kernel MG [13], the second application is a branch and bound application which solves the N-puzzle as described in <ref> [7] </ref>. The third application is another branch and bound application which solves the traveling salesperson (TSP) problem. Each application utilizes partitioning and load balancing strategies discussed in [8] tailored to network computing environments to varying degrees. <p> XPVM is able 14 to comfortably zoom and scroll with little interaction delay. 3.2 N-Puzzle N-puzzle problem <ref> [7] </ref> is a branch and bound application which is solved by searching a state space tree that corresponds to puzzle derivations. A "bag of tasks" approach is utilized in which a master node is responsible for the distribution of puzzle states to the worker tasks.
Reference: [8] <author> Schmidt, B. K. and Sunderam, V. S. </author> <title> Empirical analysis of overheads in cluster environments. </title> <journal> Concurrency: Practice & Experience. </journal> <volume> 6, 1, </volume> <month> (February </month> <year> 1994), </year> <pages> 1-33. </pages>
Reference-contexts: Furthermore, in open cluster environments, each computer as well as the network itself, is potentially subject to uncontrollable external loads. These factors often result in load imbalances and dynamic fluctuations in delivered resources, which can be a major cause of performance degradation <ref> [8] </ref>. Cluster environments are therefore intrinsically different from most hardware multiprocessors where typical operational methodology is for applications to have dedicated use of the machines or parts thereof. <p> The third application is another branch and bound application which solves the traveling salesperson (TSP) problem. Each application utilizes partitioning and load balancing strategies discussed in <ref> [8] </ref> tailored to network computing environments to varying degrees. In this section we present how PVaniM is utilized as an aid to understanding the complexities of implementing a high performance heterogeneous network computing application. <p> The "bag of tasks" approach provides for dynamic load balancing as worker processes acquire more tasks to perform when they complete their current task. The algorithm has 15 16 potential to perform well in a cluster environment <ref> [8] </ref>. The application executes on a combination of SGI R4400 workstations, Sun Sparc 10's, and Sun Sparc 2's. The master node executes on buster, an SGI R4400, and worker nodes execute on the remainder of the workstations. Examination of PVaniM's on-line graphical views yields several interesting observations.
Reference: [9] <author> Stellner, G. and Pruyne, J. </author> <title> CoCheck users' guide V1.0 PVM version. </title> <type> Technical report, </type> <institution> Technische Universitat Munchen, </institution> <month> November </month> <year> 1995. </year>
Reference-contexts: In addition to supporting primitive debugging, this support is partic 8 ularly apropos for PVM process migration systems such as CoCheck <ref> [9] </ref>. Under CoCheck, a migrated PVM task that is initially connected to a tty loses this connection after the task has migrated. This limits CoCheck's support for interactive applications. However, an application using PVaniM's transparent I/O support simply uses PVM messages to provide I/O.
Reference: [10] <author> Sunderam, V. </author> <title> PVM: A framework for parallel distributed computing. </title> <journal> Concurrency: Practice & Experience. </journal> <volume> 2, 4, </volume> <month> (December </month> <year> 1990), </year> <pages> 315-339. </pages>
Reference-contexts: In order to investigate this two-phase approach to visualization in networked environ ments, we have developed an experimental toolkit and methodology called the PVaniM vi sualization environment. PVaniM is a visualization environment for the PVM <ref> [10] </ref> network computing system which relies on its own monitoring techniques to support its graphical views. <p> Section 4 provides system implementation details of PVaniM's functionalities. Section 5 discusses related work. The final section presents conclusions and future work. 4 2 PVaniM The PVaniM system provides both on-line and postmortem visualizations of applications written with the PVM <ref> [10] </ref> heterogeneous network computing system. After making minor modifications to the application and recompiling to link to PVaniM's monitoring library, PVaniM is ready for use. Essentially, the user must add an extra header file which provides macros that replace standard PVM routines with calls to PVaniM's monitoring library.
Reference: [11] <author> Topol, B., Stasko, J. T., and Sunderam, V. </author> <title> The Dual Timestamping methodology for visualizing distributed applications. </title> <type> Technical Report GIT-CC-95-21, </type> <institution> Georgia Tech, </institution> <address> Atlanta, GA, </address> <month> May </month> <year> 1995. </year> <note> Submitted to IEEE Parallel & Distributed Technology, Systems & Applications. </note>
Reference-contexts: In contrast, PVaniM distinguishes between the types of monitoring and graphical views used for on-line analysis and those used for detailed postmortem analysis. For off-line analysis, PVaniM uses buffered postmortem tracing <ref> [11] </ref>, using a buffering hierarchy for collecting trace events. For on-line graphical views, PVaniM utilizes periodic sampling of tasks with adjustable granularity; this requires substantially less bandwidth than event trac 3 ing but the views are not as detailed. <p> As discussed later in this paper, 9 efforts are underway to support advanced steerable objects originally developed for shared memory parallel processors [12]. 2.4 PVaniM Postmortem Visualization Support For postmortem visualization, PVaniM supports event tracing with a technique we refer to as buffered postmortem tracing <ref> [11] </ref>. With this technique, each workstation writes its trace events to its local disk (if available). After the application has finished executing, the individual trace files are collected automatically by PVaniM. This allows PVaniM to perform event tracing without severely impacting the network bandwidth available to the application. <p> Furthermore, contrail lines are provided that allow the identity of the sender of the message to be easily determined. Lamport timestamps are utilized to provide a feasible concurrent ordering of events and this ordering is utilized to produce a concurrent animation of message traffic. As discussed in <ref> [11] </ref>, PVaniM's buffered tracing supports its own default library of visualizations and concurrent animations as well as allowing the user to develop application-specific visualizations. Furthermore, PVaniM provides a converter which translates PVaniM trace files to the PICL [2] trace format utilized by ParaGraph [4]. <p> In the remainder of this paper we focus on PVaniM's support for ParaGraph postmortem views to justify PVaniM's separation of on-line and postmortem visualization functionality. 10 PVaniM's own default postmortem graphical views and support for application-specific postmortem visualizations are thoroughly described in <ref> [11] </ref>. 2.4.1 Achieving Separated On-Line and Postmortem Functionality PVaniM's use of on-line sampling and buffered postmortem tracing allows it to achieve functionality at runtime and also used as a postmortem profiling tool.
Reference: [12] <author> Vetter, J. and Schwan, K. </author> <title> Progress: a toolkit for interactive program steering. </title> <booktitle> Proceedings of the International Conference on Parallel Processing. </booktitle> <address> Oconomowoc, Wisconsin, </address> <month> August </month> <year> 1995. </year> <month> 32 </month>
Reference-contexts: As discussed later in this paper, 9 efforts are underway to support advanced steerable objects originally developed for shared memory parallel processors <ref> [12] </ref>. 2.4 PVaniM Postmortem Visualization Support For postmortem visualization, PVaniM supports event tracing with a technique we refer to as buffered postmortem tracing [11]. With this technique, each workstation writes its trace events to its local disk (if available). <p> Several avenues for future work exist with PVaniM. PVaniM's transparent steering support has great potential and we are currently investigating supporting steerable objects such as those provided by the Progress toolkit <ref> [12] </ref>. Also being investigated is the addition of interactive load migration facilities. These are particularly apropos due to PVaniM's ability to gather external load information from the cluster environment.
Reference: [13] <author> White, S., Alund, A., and Sunderam, V. </author> <title> Performance of the NAS parallel benchmarks on PVM based networks. </title> <journal> Journal of Parallel and Distributed Computing. </journal> <volume> 26, 1, </volume> <month> (April </month> <year> 1995), </year> <pages> 61-71. </pages>
Reference-contexts: Furthermore, the postmortem tracefiles support graphical views that allow for detailed (perhaps even tedious) examination of an application's behavior. 11 3 Experiences with PVaniM In this section we present the use of PVaniM on three PVM applications. The first of these is NAS Parallel Benchmark Kernel MG <ref> [13] </ref>, the second application is a branch and bound application which solves the N-puzzle as described in [7]. The third application is another branch and bound application which solves the traveling salesperson (TSP) problem.
References-found: 13

