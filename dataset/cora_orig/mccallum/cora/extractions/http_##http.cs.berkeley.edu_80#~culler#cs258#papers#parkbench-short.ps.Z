URL: http://http.cs.berkeley.edu:80/~culler/cs258/papers/parkbench-short.ps.Z
Refering-URL: http://http.cs.berkeley.edu:80/~culler/cs258/
Root-URL: http://www.cs.berkeley.edu
Title: Public International Benchmarks for Parallel Computers  
Note: February 7, 1994  
Abstract: PARKBENCH Committee: Report-1 assembled by Roger Hockney (chairman) and Michael Berry (secretary) 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> PARKBENCH Committee. </author> <title> Public International Benchmarks for Parallel Computers. </title> <type> Technical Report CS-93-213, </type> <institution> Computer Science Department, University of Tennessee, Knoxville, Tennessee, </institution> <month> November </month> <year> 1993. </year> <note> (Scientific Programming, 1994, to appear). </note>
Reference: [2] <author> J. Dongarra, A. Geist, R. Manchek, and V. Sunderam. </author> <title> Integrated pvm framework supports heterogeneous network computing. </title> <journal> Computers in Physics, </journal> <volume> 7(2) </volume> <pages> 166-175, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Both PVM/MPI <ref> [2, 3] </ref> and subset HPF versions exist for most of the codes in addition to the standard Fortran-77 versions. A description of each benchmark and instructions on how to run it are given in individual ReadMe files.
Reference: [3] <author> Message Passing Interface Forum. </author> <title> Document for a Standard Message-Passing Interface. </title> <institution> Computer Science Dept. </institution> <type> Technical Report CS-93-214, </type> <institution> University of Tennessee, Knoxville, Tennessee, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: Both PVM/MPI <ref> [2, 3] </ref> and subset HPF versions exist for most of the codes in addition to the standard Fortran-77 versions. A description of each benchmark and instructions on how to run it are given in individual ReadMe files.
Reference: [4] <author> M. Metcalf and J. Reid. </author> <title> Fortran-90 Explained. </title> <address> Oxford Science Publications/OUP, Oxford and New York, </address> <year> 1990. </year>
Reference: [5] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran Language Specification. </title> <journal> Scientific Programming, </journal> <volume> 2 </volume> <pages> 1-170, </pages> <year> 1993. </year>
Reference-contexts: The parallel compiler technology as well as methods of evaluating it are not mature yet. Nevertheless, the advent of the HPF standard gives opportunity to develop systematic benchmarking techniques. The current definition of HPF <ref> [5] </ref> cannot be recognized as an ultimate solution for parallel computing. Its limitations are well known, and many researchers are working on extensions to HPF to address a broader class of real life, commercial and scientific applications.
Reference: [6] <author> R. W. Hockney. </author> <title> A Framework for Benchmark Analysis. Supercomputer, </title> <address> 48(IX-2):9-22, </address> <year> 1992. </year>
Reference: [7] <author> Quantities, </author> <title> Units and Symbols. </title> <journal> The Royal Society, London, </journal> <year> 1975. </year>
Reference: [8] <author> M. Berry, D. Chen, P. Koss, D. Kuck, S. Lo, Y. Pang, L. Pointer, R. Roloff, A. Sameh, E. Clementi, S. Chin, D. Schneider, G. Fox, P. Messina, D. Walker, C. Hsiung, J. Schwar-zmeier, K. Lue, S. Orszag, F. Seidl, O. Johnson, R. Goodrum, and J. Martin. </author> <title> The PERFECT Club Benchmarks: Effective Performance Evaluation of Computers. </title> <journal> Intl. J. Supercomputer Appls., </journal> <volume> 3(3) </volume> <pages> 5-40, </pages> <year> 1989. </year>
Reference: [9] <author> F. H. McMahon. </author> <title> The Livermore Fortran Kernels test of the Numerical Performance Range. </title> <editor> In J. L. Martin, editor, </editor> <booktitle> Performance Evaluation of Supercomputers, </booktitle> <pages> pages 143-186. </pages> <publisher> Elsevier Science B.V., North-Holland, </publisher> <address> Amsterdam, </address> <year> 1988. </year>
Reference-contexts: The next releases will contain more kernels that will address all features of HPF, and also they will be sensitive to advanced compiler transformations. The codes included in this suite are either adopted from existing benchmark suites, NAS suite [31], Livermore Loops <ref> [9] </ref>, and the Purdue Set [40], or are developed at Syracuse University. 6.2.2 FORALL statement kernel FL FORALL statement provides a convenient syntax for simultaneous assignments to large groups of array elements. Such assignments lie at the heart of the data parallel computations that HPF is designed to express.
Reference: [10] <author> J. Dongarra, T. Rowan, and R. Wade. </author> <title> Software Distribution Using XNETLIB Database Server. </title> <institution> Computer Science Dept. </institution> <type> Technical Report CS-93-191, </type> <institution> University of Tennessee, Knoxville, Tennessee, </institution> <month> March </month> <year> 1993. </year>
Reference: [11] <author> B. H. LaRose. </author> <title> The Development and Implementation of a Performance Database Server. </title> <institution> Computer Science Dept. </institution> <type> Technical Report CS-93-195, </type> <institution> University of Tennessee, Knoxville, Tennessee, </institution> <month> August </month> <year> 1993. </year>
Reference: [12] <author> J. J. Dongarra. </author> <title> Performance of various Computers using Standard Linear Equations Software in a Fortran Environment. </title> <institution> Computer Science Dept. </institution> <type> Technical Report CS-89-85, </type> <institution> University of Tennessee, Knoxville, Tennessee, </institution> <month> March </month> <year> 1990. </year> <month> 43 </month>
Reference: [13] <author> D. Bailey, J. Barton, T. Lasinski, and H. (editors) Simon. </author> <title> The NAS parallel benchmarks. </title> <type> Technical Report 103863, </type> <institution> NASA Ames Research Center, Moffett Field, </institution> <address> CA 94035, </address> <month> July </month> <year> 1993. </year>
Reference: [14] <author> Joseph Uniejewski. </author> <title> SPEC Benchmark Suite: Designed for Today's Advanced Systems. </title> <note> SPEC Newsletter, Fall 1989. Volume 1, Issue 1. </note>
Reference: [15] <author> C. Addison, J. Allwright, N. Binsted, N. Bishop, B. Carpenter, P. Dalloz, D. Gee, V. Getov, A. Hey, R. Hockney, M. Lemke, J. Merlin, M. Pinches, C. Scott, and I. Wolton. </author> <title> The Genesis Distributed-Memory Benchmarks. Part 1: methodology and general relativity benchmark with results for the SUPRENUM computer. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 5(1) </volume> <pages> 1-22, </pages> <year> 1993. </year>
Reference: [16] <author> D. Bailey, E. Barszcz, J. Barton, D. Browning, R. Carter, L. Dagum, R. Fatoohi, P. Fre-derickson, T. Lasinski, R. Schreiber, H. Simon, V. Venkatakrishnan, and S. Weeratunga. </author> <title> The NAS parallel benchmarks. </title> <journal> Int. J. of Supercomputer Applications, </journal> <volume> 5(3):63 - 73, </volume> <year> 1991. </year>
Reference: [17] <author> E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. Du Croz, A. Greenbaum, S. Hammarling, A. McKenney, S. Ostrouchov, and D. Sorensen. </author> <title> LAPACK Users' Guide. </title> <publisher> SIAM, </publisher> <address> Philadelphia, PA, </address> <year> 1992. </year>
Reference: [18] <author> R. W. Hockney. </author> <title> Performance Parameters and Benchmarking of Supercomputers. </title> <journal> Parallel Computing, </journal> <volume> 17 </volume> <pages> 1111-1130, </pages> <year> 1991. </year>
Reference: [19] <author> A. Friedli, W. Gentzsch, R. Hockney, and A. van der Steen. </author> <title> A European Supercomputer Benchmark Effort. Supercomputer 34, </title> <address> VI(6):14-17, </address> <year> 1989. </year>
Reference: [20] <author> A. J. G. Hey. </author> <title> The Genesis Distributed-Memory Benchmarks. </title> <journal> Parallel Computing, </journal> <volume> 17 </volume> <pages> 1275-1283, </pages> <year> 1991. </year>
Reference: [21] <author> V.S. Getov, A.J.G. Hey, R.W. Hockney, and I.C. Wolton. </author> <title> The Genesis Benchmark Suite: Current State and Results. </title> <booktitle> In Proceedings of Workshop on Performance Evaluation of Parallel Systems - PEPS'93. </booktitle> <institution> University of Warwick, Coventry, </institution> <month> November 29-30, </month> <year> 1993. </year>
Reference: [22] <author> R. W. Hockney. </author> <title> Super-Computer Architecture. </title> <editor> In F. Sumner, editor, </editor> <booktitle> Infotech State of the Art Conference: Future Systems, </booktitle> <pages> pages 277-305. </pages> <publisher> Infotech, </publisher> <address> Maidenhead, </address> <year> 1977. </year>
Reference: [23] <author> Roger W. Hockney and Christopher R. Jesshope. </author> <title> Parallel Computers: </title> <booktitle> Architecture, Programming and Algorithms. </booktitle> <address> Adam Hilger, Bristol, </address> <year> 1981. </year>
Reference: [24] <author> R. W. Hockney. </author> <title> Characterization of Parallel Computers and Algorithms. </title> <journal> Computer Physics Communications, </journal> <volume> 26 </volume> <pages> 285-29, </pages> <year> 1982. </year>
Reference: [25] <author> R. W. Hockney. </author> <title> Characterizing Computers and Optimizing the FACR(l) Poisson-Solver on Parallel Unicomputers. </title> <journal> IEEE Trans. Comput., </journal> <volume> C32:933-941, </volume> <year> 1983. </year>
Reference: [26] <author> R. W. Hockney. </author> <title> Parametrization of computer performance. </title> <journal> Parallel Computing, </journal> <volume> 5 </volume> <pages> 97-103, </pages> <year> 1987. </year>
Reference: [27] <author> Roger W. Hockney and Christopher R. Jesshope. </author> <title> Parallel Computers 2: Architecture, Programming and Algorithms. </title> <publisher> Adam Hilger/IOP Publishing, </publisher> <address> Bristol & Philadelphia, </address> <note> second edition, </note> <year> 1988. </year> <title> Distributed in the USA by IOP Publ. Inc., Public Ledger Bldg., Suite 1035, Independence Square, </title> <address> Philadelphia, PA 19106. </address> <month> 44 </month>
Reference: [28] <author> A. J. van der Steen and P. P. M. de Rijk. </author> <title> Guidelines for use of the EuroBen Bench--mark. </title> <type> Technical Report TR3, EuroBen, </type> <institution> The EuroBen Group, </institution> <address> Utrecht, The Netherlands, </address> <month> February </month> <year> 1993. </year>
Reference: [29] <author> R. W. Hockney. </author> <title> Synchronization and Communication Overheads on the LCAP Multiple FPS-164 Computer System. </title> <journal> Parallel Computing, </journal> <volume> 9 </volume> <pages> 279-290, </pages> <year> 1988. </year>
Reference: [30] <author> C.A. Addison, V.S. Getov, A.J.G. Hey, R.W. Hockney, and I.C. Wolton. </author> <title> The Genesis Distributed-Memory Benchmarks. </title> <editor> In J. Dongarra and W. Gentzsch, editors, </editor> <booktitle> Computer Benchmarks, </booktitle> <pages> pages 257-271. </pages> <publisher> Elsevier Science B.V., North-Holland, </publisher> <address> Amsterdam, </address> <year> 1993. </year>
Reference: [31] <author> D. Bailey and J. Barton. </author> <title> The NAS Kernel Benchmark Program. </title> <type> Technical Report 86711, </type> <institution> NASA Ames Technical Memorandum, </institution> <year> 1985. </year>
Reference-contexts: The next releases will contain more kernels that will address all features of HPF, and also they will be sensitive to advanced compiler transformations. The codes included in this suite are either adopted from existing benchmark suites, NAS suite <ref> [31] </ref>, Livermore Loops [9], and the Purdue Set [40], or are developed at Syracuse University. 6.2.2 FORALL statement kernel FL FORALL statement provides a convenient syntax for simultaneous assignments to large groups of array elements.
Reference: [32] <author> D. Bailey, J. Barton, T. Lasinski, and H. Simon (editors). </author> <title> The NAS parallel benchmarks. </title> <type> Technical Report RNR-91-02, </type> <institution> NASA Ames Research Center, Moffett Field, </institution> <address> CA 94035, </address> <month> January </month> <year> 1991. </year>
Reference-contexts: Note, however, that in this benchmark only nearest neighbour interactions are required and the number of floating point operations per grid point is very small when compared to more complex PDEs. 2. Multigrid kernel. The PARKBENCH multigrid kernel is the multigrid benchmark from the NAS Parallel Benchmarks <ref> [32] </ref>. It requires highly structured long distance communication and tests both short and long distance data exchange. <p> Embarrassingly Parallel. The PARKBENCH embarrassingly parallel kernel is taken from the NAS Parallel Benchmarks <ref> [32] </ref>. It provides an estimate of the upper achievable limits for floating point performance, i.e. the performance without significant interpro-cessor communication. <p> The benchmark counts the number of these Gaussian deviates that lie in various square annuli around the origin. 2. Conjugate gradient kernel. The PARKBENCH conjugate gradient benchmark is taken from the NAS Parallel Benchmarks <ref> [32] </ref>. In this kernel, the inverse power method is used to find an estimate of the largest eigenvalue of a symmetric positive definite sparse matrix with a random pattern of nonzeros. <p> Although sorting has traditionally been thought of as of importance primarily in non-scientific computing, this operation is increasingly important in advanced scientific applications. In particle method fluid simulations, for example, sorting is the dominant cost. The PARKBENCH integer sort benchmark is taken from the NAS Parallel Benchmarks <ref> [32] </ref>. The kernel tests both integer computation speed and communication performance. In this benchmark, a vector of integer data is generated using the same pseudorandom number generator that is used in the embarrassingly parallel kernel. This data is initially mapped according to a particular scheme.
Reference: [33] <author> J. Choi, J. J. Dongarra, and D. W. Walker. </author> <title> The design of scalable software libraries for distributed memory concurrent computers. </title> <booktitle> In Proceedings of Environment and Tools for Parallel Scientific Computing Workshop, </booktitle> <address> (Saint Hilaire du Touvet, France). </address> <publisher> Elsevier Science Publishers, </publisher> <month> September 7-8, </month> <year> 1992. </year>
Reference: [34] <author> J. Choi, J. J. Dongarra, R. Pozo, and D. W. Walker. </author> <title> ScaLAPACK: A scalable linear algebra library for distributed memory concurrent computers. </title> <booktitle> In Proceedings of Fourth Symposium on the Frontiers of Massively Parallel Computation (McLean, </booktitle> <address> Virginia). </address> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> California, </address> <month> October 19-21, </month> <year> 1992. </year>
Reference: [35] <author> J. J. Dongarra, R. van de Geijn, and D. Walker. </author> <title> A look at scalable linear algebra libraries. </title> <booktitle> In Proceedings of the 1992 Scalable High Performance Computing Conference, </booktitle> <pages> pages 372-379. </pages> <publisher> IEEE Press, </publisher> <year> 1992. </year>
Reference: [36] <author> J. Choi, J. Dongarra, R. Pozo, and D. Walker. </author> <title> ScaLAPACK: A Scalable Linear Algebra Library for Distributed Memory Concurrent Computers. </title> <booktitle> In IEEE, editor, Proceedings of the Fourth Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <address> McLean Virginia, </address> <pages> pages 120-127. </pages> <publisher> IEEE Publishers, </publisher> <month> October </month> <year> 1992. </year>
Reference: [37] <author> G. C. Fox, S. W. Otto, and A. J. G. Hey. </author> <title> Matrix algorithms on a hypercube I: Matrix multiplication. </title> <journal> Parallel Computing, </journal> <volume> 4 </volume> <pages> 17-31, </pages> <year> 1987. </year>
Reference: [38] <author> S. Huss-Lederman, E. M. Jacobson, A. Tsao, and G. Zhang. </author> <title> Matrix multiplication on the Intel Touchstone Delta. </title> <type> Technical report, </type> <institution> Supercomputing Research Center, </institution> <year> 1993. </year> <note> in preparation. </note>
Reference: [39] <author> C. Lin and L. Snyder. </author> <title> A matrix product algorithm and its comparative performance on hypercubes. </title> <booktitle> In Proceedings of the 1992 Scalable High Performance Computing Conference, </booktitle> <pages> pages 190-194. </pages> <publisher> IEEE Press, </publisher> <year> 1992. </year>
Reference: [40] <author> J. Rice. </author> <title> Problems to Test Parallel and Vector Languages. </title> <type> Technical Report CSDTR 516, </type> <institution> Purdue University, West Lafayette, Indiana, </institution> <month> October </month> <year> 1990. </year>
Reference-contexts: The next releases will contain more kernels that will address all features of HPF, and also they will be sensitive to advanced compiler transformations. The codes included in this suite are either adopted from existing benchmark suites, NAS suite [31], Livermore Loops [9], and the Purdue Set <ref> [40] </ref>, or are developed at Syracuse University. 6.2.2 FORALL statement kernel FL FORALL statement provides a convenient syntax for simultaneous assignments to large groups of array elements. Such assignments lie at the heart of the data parallel computations that HPF is designed to express.
Reference: [41] <author> R. W. Hockney and E. A. Carmona. </author> <title> Comparison of Communications on the Intel iPSC/860 and Touchstone Delta. </title> <journal> Parallel Computing, </journal> <volume> 18 </volume> <pages> 1067-1072, </pages> <year> 1992. </year> <month> 45 </month>
Reference: [42] <author> D. Bailey, R. Barszcz, L. Dagum, and H. Simon. </author> <title> NAS Parallel Benchmark Results. </title> <type> Technical Report RNR-93-016, </type> <institution> NASA Ames Research Center, Moffett Field, </institution> <address> CA 94035, </address> <month> October </month> <year> 1993. </year> <month> 46 </month>
References-found: 42

