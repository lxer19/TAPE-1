URL: http://www.umiacs.umd.edu/users/vishkin/PUBLICATIONS/ansv.ps
Refering-URL: http://www.umiacs.umd.edu/users/vishkin/PUBLICATIONS/papers.html
Root-URL: 
Phone: Tel  
Title: OPTIMAL DOUBLY LOGARITHMIC PARALLEL ALGORITHMS BASED ON FINDING ALL NEAREST SMALLER VALUES  
Author: Omer Berkman Baruch Schieber Uzi Vishkin 
Note: Part of this work was carried out while this author was  Israel 69978. Partially supported by NSF grant CCR-8906949.  
Address: King's College London, The Strand, London WC2R 2LS, England.  College Park, MD 20742; and  P.O. Box 218, Yorktown Heights, NY 10598.  
Affiliation: Dept. of Computing,  at University of Maryland Institute for Advanced Computer Studies (UMIACS),  Aviv University, Tel Aviv,  IBM Research Division, T.J. Watson Research Center,  
Abstract: The all nearest smaller values problem is defined as follows. Let A = (a 1 ; a 2 ; : : :; a n ) be n elements drawn from a totally ordered domain. For each a i , 1 i n, find the two nearest elements in A that are smaller than a i (if such exist): the left nearest smaller element a j (with j &lt; i) and the right nearest smaller element a k (with k &gt; i). We give an O(log log n) time optimal parallel algorithm for the problem on a CRCW PRAM. We apply this algorithm to achieve optimal O(log log n) time parallel algorithms for four problems: (i) Triangulating a monotone polygon, (ii) Preprocessing for answering range minimum queries in constant time, (iii) Reconstructing a binary tree from its inorder and either preorder or postorder numberings, (vi) Matching a legal sequence of parentheses. We also show that any optimal CRCW PRAM algorithm for the triangulation problem requires (log log n) time. z University of Maryland Institute for Advanced Computer Studies (UMIACS), and Dept. of Electrical Engineering, University of Maryland, College Park, MD 20742; and Tel Aviv University, Tel Aviv, Israel 69978. Partially supported by NSF grants CCR-8906949 and CCR-911348, ONR grant N00014-85-K-0046, the Applied Mathematical Sciences subprogram of the Office of Energy Research, U.S. Department of Energy under contract number DE-AC02-76ER03077 and the Foundation for Research in Electronics, Computers and Communication, administered by the Israeli Academy of Sciences and Humanities. 
Abstract-found: 1
Intro-found: 1
Reference: [ACG + 85] <author> A. Aggarwal, B. Chazelle, L. Guibas, C. O'Dunlaing, and C. Yap. </author> <title> Parallel computational geometry. </title> <booktitle> In Proc. of the 26th IEEE Annual Symp. on Foundation of Computer Science, </booktitle> <pages> pages 468-477, </pages> <year> 1985. </year>
Reference-contexts: Our parallel algorithm implies new serial algorithms for these two problems. Interestingly, for the OSMP problem our serial algorithm is simpler. Each of the parallel methods of Aggarwal et al. <ref> [ACG + 85] </ref>, Yap [Yap88] and Atallah and Goodrich [AG86] (given for a CREW PRAM) for triangulating a simple polygon uses, as its main subroutine, an algorithm for triangulating an OSMP. Their bounds for triangulating an OSMP is O (log n) time using n processors. <p> In the second stage we show how to triangulate an OSMP. 4.1.1. Decomposition into one-sided monotone polygons Assume for simplicity that no two vertices of P have the same x coordinate. The general idea for achieving decomposition into one-sided monotone polygons (OSMP's) is due to Aggarwal et al. <ref> [ACG + 85] </ref> and Goodrich [Goo89]. Step 1: Merge the vertices of the lower chain and the vertices of the upper chain, according to their x-values using the parallel merging algorithm of Kruskal [Kru83].
Reference: [AG86] <author> M.J. </author> <title> Atallah and M.T. Goodrich. Efficient plane sweeping in parallel. </title> <booktitle> In Proc 2nd ACM Symp. on Computational Geometry, </booktitle> <pages> pages 216-225, </pages> <year> 1986. </year>
Reference-contexts: Our parallel algorithm implies new serial algorithms for these two problems. Interestingly, for the OSMP problem our serial algorithm is simpler. Each of the parallel methods of Aggarwal et al. [ACG + 85], Yap [Yap88] and Atallah and Goodrich <ref> [AG86] </ref> (given for a CREW PRAM) for triangulating a simple polygon uses, as its main subroutine, an algorithm for triangulating an OSMP. Their bounds for triangulating an OSMP is O (log n) time using n processors.
Reference: [ALV90] <author> A. Amir, G.M. Landau, and U. Vishkin. </author> <title> Efficient pattern matching with scaling. </title> <booktitle> In Proc. of the 1st ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 344-357, </pages> <year> 1990. </year>
Reference-contexts: This lower bound result prohibits generalization of our results to any semi-group operations. We mention two recent papers that need range minimum (or maximum) search: <ref> [ALV90] </ref> on scaled string matching, and [RV88] on parallel triconnectivity. Other applications of the algorithm are given in [GBT84].
Reference: [AMW89] <editor> R.J. Anderson, E.W. Mayr, and M.K. </editor> <title> Warmuth. Parallel approximation algorithms for bin packing. </title> <journal> Information and Computation, </journal> <volume> 82 </volume> <pages> 262-277, </pages> <year> 1989. </year>
Reference-contexts: We mention two recent papers that need range minimum (or maximum) search: [ALV90] on scaled string matching, and [RV88] on parallel triconnectivity. Other applications of the algorithm are given in [GBT84]. Bar-On and Vishkin [BV85] gave a logarithmic optimal parallel algorithm for parentheses matching and Anderson, Mayr and Warmuth <ref> [AMW89] </ref> achieved logarithmic time using a linear number of processors (on weaker models of computation). The problem of reconstructing a binary tree from its inorder and either preorder or postorder numberings was introduced in [Knu73] (x2.3.1, Page 329, Ex. 7).
Reference: [AS87] <author> N. Alon and B. Schieber. </author> <title> Optimal preprocessing for answering on-line product queries. </title> <type> Technical Report TR 71/87, </type> <institution> The Moise and Frida Eskenasy Inst. of Computer Science, Tel Aviv University, </institution> <year> 1987. </year>
Reference-contexts: Using this observation they give a linear time sequential preprocessing algorithm for answering range minimum queries in constant time. Our preprocessing algorithm combines this serial approach with a preprocessing algorithm of <ref> [AS87] </ref>. Note that the binary minimum operation is not a general semi-group operation. Yao [Yao82] and Alon and Schieber [AS87] show that on-line retrieval of information on each sub-array relative to a general semi-group operation needs non-constant time if only linear amount of work is invested in the preprocessing stage. <p> Our preprocessing algorithm combines this serial approach with a preprocessing algorithm of <ref> [AS87] </ref>. Note that the binary minimum operation is not a general semi-group operation. Yao [Yao82] and Alon and Schieber [AS87] show that on-line retrieval of information on each sub-array relative to a general semi-group operation needs non-constant time if only linear amount of work is invested in the preprocessing stage. This lower bound result prohibits generalization of our results to any semi-group operations. <p> The doubly logarithmic time algorithm The doubly logarithmic time CRCW PRAM algorithm is based on the O (n log n) time preprocessing algorithm given in <ref> [AS87] </ref>. Let us recall this algorithm. Preprocessing: Without loss of generality assume that n is a power of two. Construct a complete binary tree T with n leaves, and associate the elements of A with the leaves of T , in order.
Reference: [BBG + 89] <author> O. Berkman, D. Breslauer, Z. Galil, B. Schieber, and U. Vishkin. </author> <title> Highly-parallelizable problems. </title> <booktitle> In Proc. of the 21st Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 309-319, </pages> <year> 1989. </year> <month> 23 </month>
Reference-contexts: The doubly logarithmic optimal algorithms for these problems make them highly parallelizable problems as classified in <ref> [BBG + 89] </ref>. The fact that the ANSV problem captures intrinsic difficulties in each of these problems which are from different domains, as well as the fact that merging and maximum finding can be reduced to ANSV support our claim that it is indeed a fundamental problem.
Reference: [BH85] <author> A. Borodin and J.E. Hopcroft. </author> <title> Routing, merging, and sorting on parallel models of computation. </title> <journal> J. Computer and System Sciences, </journal> <volume> 30 </volume> <pages> 130-145, </pages> <year> 1985. </year>
Reference-contexts: This is optimal since the ANSV problem has a simple linear time serial algorithm. We argue that the ANSV problem is fundamental. First, two elementary problems: merging two sorted lists <ref> [BH85, Kru83] </ref> and finding the maximum of n elements [Val75] can be reduced to this problem. However, it still has the same serial and parallel tight complexity bounds as each of them. <p> The first problem is finding the minimum (maximum) of n elements [Val75]. The ANSV problem is at least as hard as the problem of finding the minimum of n elements since the minimum is simply the unique element with no left or right matches. The second problem is merging <ref> [BH85, Kru83] </ref>. We show that the same holds for the merging problem. 5 Reduction from merging to ANSV.
Reference: [BLSZ87] <author> H.A. Burgdorff, S. Lajodia, F.N. Springsteel, and Y. Zalcstein. </author> <title> Alternative methods for the reconstruction of trees from their traversals. </title> <journal> Bit, </journal> <volume> 27 </volume> <pages> 134-140, </pages> <year> 1987. </year>
Reference-contexts: The problem of reconstructing a binary tree from its inorder and either preorder or postorder numberings was introduced in [Knu73] (x2.3.1, Page 329, Ex. 7). Burgdorff et al. <ref> [BLSZ87] </ref> gave an O (n 2 ) serial algorithm for this problem. The paper is organized as follows. In Section 2 we define and give an algorithm for the prefix minima problem which is an important subroutine in our ANSV algorithm.
Reference: [BV85] <author> I. Bar-On and U. Vishkin. </author> <title> Optimal parallel generation of a computation tree form. </title> <journal> ACM Trans. on Prog. Lang. and Systems, </journal> <volume> 7 </volume> <pages> 348-357, </pages> <year> 1985. </year>
Reference-contexts: This lower bound result prohibits generalization of our results to any semi-group operations. We mention two recent papers that need range minimum (or maximum) search: [ALV90] on scaled string matching, and [RV88] on parallel triconnectivity. Other applications of the algorithm are given in [GBT84]. Bar-On and Vishkin <ref> [BV85] </ref> gave a logarithmic optimal parallel algorithm for parentheses matching and Anderson, Mayr and Warmuth [AMW89] achieved logarithmic time using a linear number of processors (on weaker models of computation).
Reference: [BV89] <author> O. Berkman and U. Vishkin. </author> <title> Recursive *-tree parallel data-structure. </title> <booktitle> In Proc. of the 30th IEEE Annual Symp. on Foundation of Computer Science, </booktitle> <pages> pages 196-202, </pages> <year> 1989. </year> <note> To appear in SIAM J. Comput. </note>
Reference-contexts: Preprocessing: Construct the Cartesian tree for A. This can be done in linear time as shown in [GBT84]. Apply the linear time preprocessing algorithm for answering LCA queries in trees given in [HT84] (see also, <ref> [SV88, BV89] </ref>). Query processing: From the recursive definition of the Cartesian tree it readily follows that M IN (i; j) is the LCA of a i and a j in the Cartesian tree. <p> We construct the Cartesian tree using a proper algorithm for the ANVS problem, and then apply the optimal logarithmic time parallel preprocessing algorithms for answering LCA queries of [SV88] or <ref> [BV89] </ref>. This would give a logarithmic time preprocessing algorithm for the range minimum searching problem. Let a i be an element in A.
Reference: [CV89] <author> R. Cole and U. Vishkin. </author> <title> Faster optimal parallel prefix sums and list ranking. </title> <journal> Information and Computation, </journal> <volume> 81(3) </volume> <pages> 334-352, </pages> <year> 1989. </year>
Reference-contexts: In case the levels of nesting are not given, we can still match all parentheses in O (log n= log log n) time employing an optimal number of processors, by first finding the nesting levels using the parallel prefix-sums algorithm of Cole and Vishkin <ref> [CV89] </ref>. The doubly logarithmic optimal algorithms for these problems make them highly parallelizable problems as classified in [BBG + 89].
Reference: [EG88] <author> D. Eppstein and Z. Galil. </author> <title> Parallel algorithmic techniques for combinatorial computation. </title> <journal> Ann. Rev. Comput. Sci., </journal> <volume> 3 </volume> <pages> 233-283, </pages> <year> 1988. </year>
Reference-contexts: See <ref> [EG88] </ref>, [KR90] and [Vis91] for surveys of results concerning PRAMs. A parallel algorithm attains optimal speedup if its time-processor product is (asymptotically) the same as the time complexity of the best known sequential algorithm for the same problem.
Reference: [FM84] <author> A. Fournier and D.Y. Montuno. </author> <title> Triangulating simple polygons and equivalent problems. </title> <journal> ACM Trans. on Graphics, </journal> <volume> 3 </volume> <pages> 153-174, </pages> <year> 1984. </year>
Reference-contexts: Below, we discuss each of our four applications. The problem of triangulating a monotone polygon received considerable attention in the literature. For instance, Garey et al. [GJPT78] gave a linear time serial algorithm for the problem, and Fournier and Montuno <ref> [FM84] </ref> achieved similar performance for triangulating a one-sided monotone polygon (OSMP). Our parallel algorithm implies new serial algorithms for these two problems. Interestingly, for the OSMP problem our serial algorithm is simpler. <p> Consider, first, OSMP's whose entire vertices fall in the subarray of a single processor. The number of vertices of each such OSMP is at most log log n. In parallel, each processor applies a linear time serial algorithm (by the algorithms of [GJPT78] or <ref> [FM84] </ref>) to each such OSMP in its subarray. This takes O (log log n) time. Now, allocate the processors to OSMP's that extend into more than one subarray, so that a ratio of ( 1 log log n ) between processors and number of vertices is maintained for each OSMP.
Reference: [FRW88] <author> F.E. Fich, P.L. Ragde, and A. Wigderson. </author> <title> Relations between concurrent-write models of parallel computation. </title> <journal> SIAM J. Comput., </journal> <volume> 17 </volume> <pages> 606-627, </pages> <year> 1988. </year>
Reference-contexts: A similar algorithm was given in [Sch87]. Suppose we have n 2 processors. We show that in this case both the ANSV and the prefix minima problems can be solved in constant time. We begin by presenting the 1-color minimiza 3 tion problem of <ref> [FRW88] </ref> and the constant time n processors algorithm for it. This algorithm is used to get the constant time ANSV algorithm. <p> The 1-color minimization problem. The input to the problem is an array of n elements whose value is either zero or one. The output is the minimum index of the element whose value is one. Fich, Ragde and Wigderson <ref> [FRW88] </ref> proposed the following constant time algorithm for this problem: Partition the input array into p n successive subarrays each of length p For each such subarray, find, in constant time using p n processors, if it has a one.
Reference: [GBT84] <author> H.N. Gabow, J.L. Bentley, and R.E. Tarjan. </author> <title> Scaling and related techniques for geometry problems. </title> <booktitle> In Proc. of the 16th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 135-143, </pages> <year> 1984. </year>
Reference-contexts: Goodrich [Goo89] gave an algorithm for the problem of triangulating a monotone polygon on a CREW PRAM in O (log n) time using n= log n processors. This algorithm is quite involved. A variant of our algorithm matches this bound but is considerably simpler. 2 Gabow, Bentley and Tarjan <ref> [GBT84] </ref> observe that a range minimum search over any sub--array can be reduced to answering a lowest common ancestor (LCA) query in the Cartesian tree data structure introduced in [Vui80]. Using this observation they give a linear time sequential preprocessing algorithm for answering range minimum queries in constant time. <p> This lower bound result prohibits generalization of our results to any semi-group operations. We mention two recent papers that need range minimum (or maximum) search: [ALV90] on scaled string matching, and [RV88] on parallel triconnectivity. Other applications of the algorithm are given in <ref> [GBT84] </ref>. Bar-On and Vishkin [BV85] gave a logarithmic optimal parallel algorithm for parentheses matching and Anderson, Mayr and Warmuth [AMW89] achieved logarithmic time using a linear number of processors (on weaker models of computation). <p> The logarithmic time algorithm In this section we describe an optimal logarithmic time CREW PRAM preprocessing algorithm for the range minimum searching problem. Without loss of generality we assume that the elements in A are distinct. The preprocessing algorithm is based on the sequential algorithm of <ref> [GBT84] </ref>. First, we recollect this algorithm. The preprocessing algorithm of [GBT84] uses the Cartesian tree data structure introduced in [Vui80]. <p> Without loss of generality we assume that the elements in A are distinct. The preprocessing algorithm is based on the sequential algorithm of <ref> [GBT84] </ref>. First, we recollect this algorithm. The preprocessing algorithm of [GBT84] uses the Cartesian tree data structure introduced in [Vui80]. Definition 2 ([Vui80]): The Cartesian tree for an array A = (a 1 ; : : : ; a n ) of n distinct real numbers is a binary tree with vertices labeled by the numbers. <p> Preprocessing: Construct the Cartesian tree for A. This can be done in linear time as shown in <ref> [GBT84] </ref>. Apply the linear time preprocessing algorithm for answering LCA queries in trees given in [HT84] (see also, [SV88, BV89]). <p> Thus, each range minimum query can be answered in constant time by answering the corresponding LCA query in the Cartesian tree. To parallelize the above algorithm we show how to construct the Cartesian tree optimally in logarithmic time. The parallel algorithm is different from the sequential algorithm given by <ref> [GBT84] </ref> which does not seem to be amenable for efficient parallelism. We construct the Cartesian tree using a proper algorithm for the ANVS problem, and then apply the optimal logarithmic time parallel preprocessing algorithms for answering LCA queries of [SV88] or [BV89].
Reference: [GJPT78] <author> M.R. Garey, D.S. Johnson, F.P. Preparata, and R.E. Tarjan. </author> <title> Triangulating a simple polygon. </title> <journal> Information Processing Letters, </journal> <volume> 7 </volume> <pages> 175-179, </pages> <year> 1978. </year>
Reference-contexts: The computation in our doubly logarithmic algorithm is guided by a balanced doubly logarithmic height tree to be defined later. Below, we discuss each of our four applications. The problem of triangulating a monotone polygon received considerable attention in the literature. For instance, Garey et al. <ref> [GJPT78] </ref> gave a linear time serial algorithm for the problem, and Fournier and Montuno [FM84] achieved similar performance for triangulating a one-sided monotone polygon (OSMP). Our parallel algorithm implies new serial algorithms for these two problems. Interestingly, for the OSMP problem our serial algorithm is simpler. <p> Consider, first, OSMP's whose entire vertices fall in the subarray of a single processor. The number of vertices of each such OSMP is at most log log n. In parallel, each processor applies a linear time serial algorithm (by the algorithms of <ref> [GJPT78] </ref> or [FM84]) to each such OSMP in its subarray. This takes O (log log n) time.
Reference: [Goo89] <author> M.T. Goodrich. </author> <title> Triangulating a polygon in parallel. </title> <journal> J. Algorithms, </journal> <volume> 10 </volume> <pages> 327-351, </pages> <year> 1989. </year>
Reference-contexts: Their bounds for triangulating an OSMP is O (log n) time using n processors. Goodrich <ref> [Goo89] </ref> gave an algorithm for the problem of triangulating a monotone polygon on a CREW PRAM in O (log n) time using n= log n processors. This algorithm is quite involved. <p> Decomposition into one-sided monotone polygons Assume for simplicity that no two vertices of P have the same x coordinate. The general idea for achieving decomposition into one-sided monotone polygons (OSMP's) is due to Aggarwal et al. [ACG + 85] and Goodrich <ref> [Goo89] </ref>. Step 1: Merge the vertices of the lower chain and the vertices of the upper chain, according to their x-values using the parallel merging algorithm of Kruskal [Kru83].
Reference: [HT84] <author> D. Harel and R.E. Tarjan. </author> <title> Fast algorithms for finding nearest common ancestors. </title> <journal> SIAM J. Comput., </journal> <volume> 13(2) </volume> <pages> 338-355, </pages> <year> 1984. </year>
Reference-contexts: Preprocessing: Construct the Cartesian tree for A. This can be done in linear time as shown in [GBT84]. Apply the linear time preprocessing algorithm for answering LCA queries in trees given in <ref> [HT84] </ref> (see also, [SV88, BV89]). Query processing: From the recursive definition of the Cartesian tree it readily follows that M IN (i; j) is the LCA of a i and a j in the Cartesian tree. <p> Then, M IN (i; j) = minfS v (` i); P u (j ` + 1)g. The LCA of any two vertices in T can be found using the inorder numbering of T , as shown in <ref> [HT84] </ref>. The above sequential algorithm is easily parallelized to run in O (log log n) time using n log n processors. This is done by allocating to each vertex v of T having ` leaves ` processors, and then computing the prefix and suffix minima using these processors.
Reference: [KLP89] <author> Z.M. Kedem, G.M. Landau, and K.V. Palem. </author> <title> Optimal parallel prefix-suffix matching algorithm and applications. </title> <booktitle> In Proc. 1st ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 388-398, </pages> <year> 1989. </year>
Reference-contexts: The fact that the ANSV problem captures intrinsic difficulties in each of these problems which are from different domains, as well as the fact that merging and maximum finding can be reduced to ANSV support our claim that it is indeed a fundamental problem. Recently, <ref> [KLP89] </ref> applied our ANSV algorithm to obtain an optimal parallel algorithm for forest matching. In many logarithmic time algorithms on arrays, the computation is guided by a complete binary tree whose leaves correspond to the elements of the input array. See, e.g., the prefix sums algorithm of [Sto75] or [LF80].
Reference: [Knu73] <author> D.E. Knuth. </author> <booktitle> The art of computer programming, </booktitle> <volume> volume 1. </volume> <publisher> Addison-Wesley,, </publisher> <address> 2 edition, </address> <year> 1973. </year> <month> 24 </month>
Reference-contexts: The problem of reconstructing a binary tree from its inorder and either preorder or postorder numberings was introduced in <ref> [Knu73] </ref> (x2.3.1, Page 329, Ex. 7). Burgdorff et al. [BLSZ87] gave an O (n 2 ) serial algorithm for this problem. The paper is organized as follows. In Section 2 we define and give an algorithm for the prefix minima problem which is an important subroutine in our ANSV algorithm.
Reference: [KR90] <author> R.M. Karp and V. Ramachandran. </author> <title> A survey of parallel algorithms for shared--memory machines. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, </booktitle> <volume> volume 1. </volume> <publisher> MIT Press/Elsevier, </publisher> <year> 1990. </year>
Reference-contexts: See [EG88], <ref> [KR90] </ref> and [Vis91] for surveys of results concerning PRAMs. A parallel algorithm attains optimal speedup if its time-processor product is (asymptotically) the same as the time complexity of the best known sequential algorithm for the same problem.
Reference: [Kru83] <author> C.P. Kruskal. </author> <title> Searching, merging, and sorting in parallel computation. </title> <journal> IEEE Trans. on Comp, </journal> <volume> C-32:942-946, </volume> <year> 1983. </year>
Reference-contexts: This is optimal since the ANSV problem has a simple linear time serial algorithm. We argue that the ANSV problem is fundamental. First, two elementary problems: merging two sorted lists <ref> [BH85, Kru83] </ref> and finding the maximum of n elements [Val75] can be reduced to this problem. However, it still has the same serial and parallel tight complexity bounds as each of them. <p> The first problem is finding the minimum (maximum) of n elements [Val75]. The ANSV problem is at least as hard as the problem of finding the minimum of n elements since the minimum is simply the unique element with no left or right matches. The second problem is merging <ref> [BH85, Kru83] </ref>. We show that the same holds for the merging problem. 5 Reduction from merging to ANSV. <p> Each subarray contains no more than p r elements. We merge each pair of subarrays using the optimal doubly logarithmic merging algorithm of <ref> [Kru83] </ref>. This is done in O ( p r) operations and at most O (log log n) time for each pair of subarrays. <p> Step 1: Merge the vertices of the lower chain and the vertices of the upper chain, according to their x-values using the parallel merging algorithm of Kruskal <ref> [Kru83] </ref>.
Reference: [LF80] <author> R.E. Ladner and M.J. Fischer. </author> <title> Parallel prefix computation. </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 27 </volume> <pages> 831-838, </pages> <year> 1980. </year>
Reference-contexts: In many logarithmic time algorithms on arrays, the computation is guided by a complete binary tree whose leaves correspond to the elements of the input array. See, e.g., the prefix sums algorithm of [Sto75] or <ref> [LF80] </ref>. The computation in our doubly logarithmic algorithm is guided by a balanced doubly logarithmic height tree to be defined later. Below, we discuss each of our four applications. The problem of triangulating a monotone polygon received considerable attention in the literature.
Reference: [MW85] <editor> F. Meyer auf der Heide and A. </editor> <title> Wigderson. The complexity of parallel sorting. </title> <booktitle> In Proc. of the 26th IEEE Annual Symp. on Foundation of Computer Science, </booktitle> <pages> pages 532-540, </pages> <year> 1985. </year>
Reference-contexts: Proof: We reduce the following merging problem to the problem of triangulating a monotone polygon. The input to the merging problem are two sorted lists of size n, with all 2n elements distinct. The output is the merged list. Using a technique of <ref> [MW85] </ref>, [SV90] show that this merging problem requires (log log n) time, if O (n log c n) processors, for some constant c &gt; 0, are available.
Reference: [RV88] <author> V.L. Ramachandran and U. Vishkin. </author> <title> Efficient parallel triconnectivity in logarithmic parallel time. </title> <booktitle> In Proc. of AWOC 88, Lecture Notes in Computer Science No. </booktitle> <volume> 319, </volume> <pages> pages 33-42. </pages> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: This lower bound result prohibits generalization of our results to any semi-group operations. We mention two recent papers that need range minimum (or maximum) search: [ALV90] on scaled string matching, and <ref> [RV88] </ref> on parallel triconnectivity. Other applications of the algorithm are given in [GBT84]. Bar-On and Vishkin [BV85] gave a logarithmic optimal parallel algorithm for parentheses matching and Anderson, Mayr and Warmuth [AMW89] achieved logarithmic time using a linear number of processors (on weaker models of computation).
Reference: [Sch87] <author> B. Schieber. </author> <title> Design and analysis of some parallel algorithms. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Tel Aviv Univ., </institution> <year> 1987. </year>
Reference-contexts: We describe a recursive algorithm for finding the prefix minima of an array A. It runs in O (log log n) time using n= log log n processors on a CRCW PRAM. A similar algorithm was given in <ref> [Sch87] </ref>. Suppose we have n 2 processors. We show that in this case both the ANSV and the prefix minima problems can be solved in constant time. We begin by presenting the 1-color minimiza 3 tion problem of [FRW88] and the constant time n processors algorithm for it.
Reference: [Sto75] <author> H.S. Stone. </author> <title> Parallel tridiagonal equation solvers. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 1(2) </volume> <pages> 289-307, </pages> <year> 1975. </year>
Reference-contexts: Recently, [KLP89] applied our ANSV algorithm to obtain an optimal parallel algorithm for forest matching. In many logarithmic time algorithms on arrays, the computation is guided by a complete binary tree whose leaves correspond to the elements of the input array. See, e.g., the prefix sums algorithm of <ref> [Sto75] </ref> or [LF80]. The computation in our doubly logarithmic algorithm is guided by a balanced doubly logarithmic height tree to be defined later. Below, we discuss each of our four applications. The problem of triangulating a monotone polygon received considerable attention in the literature.
Reference: [SV81] <author> Y. Shiloach and U. Vishkin. </author> <title> Finding the maximum, merging, and sorting in a parallel computation model. </title> <journal> J. Algorithms, </journal> <volume> 2 </volume> <pages> 88-102, </pages> <year> 1981. </year>
Reference-contexts: Then, using n processors, apply the constant time algorithm of Shiloach and Vishkin <ref> [SV81] </ref> for finding the first of those subarrays that has a one. Finally, reapply this algorithm for finding the minimum index of a one in this subarray. The constant time n 2 processors ANSV algorithm. Allocate n processors to each a i .
Reference: [SV88] <author> B. Schieber and U. Vishkin. </author> <title> On finding lowest common ancestors: simplification and parallelization. </title> <journal> SIAM J. Comput., </journal> <volume> 17(6) </volume> <pages> 1253-1262, </pages> <year> 1988. </year>
Reference-contexts: Preprocessing: Construct the Cartesian tree for A. This can be done in linear time as shown in [GBT84]. Apply the linear time preprocessing algorithm for answering LCA queries in trees given in [HT84] (see also, <ref> [SV88, BV89] </ref>). Query processing: From the recursive definition of the Cartesian tree it readily follows that M IN (i; j) is the LCA of a i and a j in the Cartesian tree. <p> We construct the Cartesian tree using a proper algorithm for the ANVS problem, and then apply the optimal logarithmic time parallel preprocessing algorithms for answering LCA queries of <ref> [SV88] </ref> or [BV89]. This would give a logarithmic time preprocessing algorithm for the range minimum searching problem. Let a i be an element in A.
Reference: [SV90] <author> B. Schieber and U. Vishkin. </author> <title> Finding all nearest neighbors for convex polygons in parallel: a new lower bound technique and a matching algorithm. </title> <journal> Discrete Applied Math, </journal> <volume> 29 </volume> <pages> 97-111, </pages> <year> 1990. </year>
Reference-contexts: Proof: We reduce the following merging problem to the problem of triangulating a monotone polygon. The input to the merging problem are two sorted lists of size n, with all 2n elements distinct. The output is the merged list. Using a technique of [MW85], <ref> [SV90] </ref> show that this merging problem requires (log log n) time, if O (n log c n) processors, for some constant c &gt; 0, are available.
Reference: [Val75] <author> L.G. Valiant. </author> <title> Parallelism in comparison problems. </title> <journal> SIAM J. Comput., </journal> <volume> 4 </volume> <pages> 348-355, </pages> <year> 1975. </year>
Reference-contexts: This is optimal since the ANSV problem has a simple linear time serial algorithm. We argue that the ANSV problem is fundamental. First, two elementary problems: merging two sorted lists [BH85, Kru83] and finding the maximum of n elements <ref> [Val75] </ref> can be reduced to this problem. However, it still has the same serial and parallel tight complexity bounds as each of them. Second, the O (log log n) time optimal algorithm for ANSV implies doubly logarithmic optimal algorithms for four problems: 1. Triangulating a monotone polygon. <p> Preliminaries To gain some insight into the ANSV problem we note two known problems that can be solved (in parallel) using a (parallel) algorithm for the ANSV problem. The first problem is finding the minimum (maximum) of n elements <ref> [Val75] </ref>. The ANSV problem is at least as hard as the problem of finding the minimum of n elements since the minimum is simply the unique element with no left or right matches. The second problem is merging [BH85, Kru83].
Reference: [Vis91] <author> U. Vishkin. </author> <title> Structural parallel algorithmics. </title> <booktitle> In Proc. of 18th ICALP, Lecture Notes in Computer Science, </booktitle> <volume> No. 510. </volume> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: See [EG88], [KR90] and <ref> [Vis91] </ref> for surveys of results concerning PRAMs. A parallel algorithm attains optimal speedup if its time-processor product is (asymptotically) the same as the time complexity of the best known sequential algorithm for the same problem.
Reference: [Vui80] <author> J. Vuillemin. </author> <title> A unified look at data structures. </title> <journal> Communications of the ACM, </journal> <volume> 23 </volume> <pages> 229-239, </pages> <year> 1980. </year>
Reference-contexts: A variant of our algorithm matches this bound but is considerably simpler. 2 Gabow, Bentley and Tarjan [GBT84] observe that a range minimum search over any sub--array can be reduced to answering a lowest common ancestor (LCA) query in the Cartesian tree data structure introduced in <ref> [Vui80] </ref>. Using this observation they give a linear time sequential preprocessing algorithm for answering range minimum queries in constant time. Our preprocessing algorithm combines this serial approach with a preprocessing algorithm of [AS87]. Note that the binary minimum operation is not a general semi-group operation. <p> Without loss of generality we assume that the elements in A are distinct. The preprocessing algorithm is based on the sequential algorithm of [GBT84]. First, we recollect this algorithm. The preprocessing algorithm of [GBT84] uses the Cartesian tree data structure introduced in <ref> [Vui80] </ref>. Definition 2 ([Vui80]): The Cartesian tree for an array A = (a 1 ; : : : ; a n ) of n distinct real numbers is a binary tree with vertices labeled by the numbers.
Reference: [Yao82] <author> A.C. Yao. </author> <title> Space-time tradeoff for answering range queries. </title> <booktitle> In Proc. of the 14th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 128-136, </pages> <year> 1982. </year>
Reference-contexts: Using this observation they give a linear time sequential preprocessing algorithm for answering range minimum queries in constant time. Our preprocessing algorithm combines this serial approach with a preprocessing algorithm of [AS87]. Note that the binary minimum operation is not a general semi-group operation. Yao <ref> [Yao82] </ref> and Alon and Schieber [AS87] show that on-line retrieval of information on each sub-array relative to a general semi-group operation needs non-constant time if only linear amount of work is invested in the preprocessing stage. This lower bound result prohibits generalization of our results to any semi-group operations.
Reference: [Yap88] <author> C. Yap. </author> <title> Parallel triangulation of a polygon in two calls to the trapezoidal map. </title> <journal> Algorithmica, </journal> <volume> 3 </volume> <pages> 279-288, </pages> <year> 1988. </year> <month> 26 </month>
Reference-contexts: Our parallel algorithm implies new serial algorithms for these two problems. Interestingly, for the OSMP problem our serial algorithm is simpler. Each of the parallel methods of Aggarwal et al. [ACG + 85], Yap <ref> [Yap88] </ref> and Atallah and Goodrich [AG86] (given for a CREW PRAM) for triangulating a simple polygon uses, as its main subroutine, an algorithm for triangulating an OSMP. Their bounds for triangulating an OSMP is O (log n) time using n processors. <p> The comparisons during the algorithm are done lexicographically. This implements Step 2. Each of steps 1 and 2 above takes O (log log n) time using n= log log n processors. Using Yap <ref> [Yap88] </ref>, we conclude: 15 Theorem 4.1: The above algorithm triangulates a monotone polygon in O (log log n) time using n= log log n processors. 4.2.
References-found: 35

