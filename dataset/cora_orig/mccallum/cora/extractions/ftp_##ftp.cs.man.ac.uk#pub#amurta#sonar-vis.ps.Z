URL: ftp://ftp.cs.man.ac.uk/pub/amurta/sonar-vis.ps.Z
Refering-URL: http://aig.cs.man.ac.uk/publications/publications.html
Root-URL: http://www.cs.man.ac.uk
Email: E-mail: amurta@cs.man.ac.uk  
Phone: Tel: +44-161-275-6259 Fax: +44-161-275-6236  
Title: VISUALIZATION OF MOBILE ROBOT ENVIRONMENTS FROM ACOUSTIC SENSOR DATA  
Author: Alan Murta 
Address: Manchester, Manchester M13 9PL, United Kingdom  
Affiliation: Advanced Interfaces Group, Department of Computer Science, University of  
Abstract: This paper describes an approach to the visualization of data from mobile robot sensors which use acoustic echo-location to determine object distances. Acoustic distance measurement is problematic in that echoes may fail to be returned to the source, range assessments may be inaccurate, and ghost readings may also appear in the data. The method described maintains a geometric model of the perceived environment which supports the reduction of ambiguities in the sensor data. The approach is also tolerant to odometry inaccuracies. The aim is to develop a display method which will provide sufficient spatial consistency and comprehensibility to support telerobotic navigation tasks over a low-bandwidth link. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. Kirsch, U. Schnepf, I. Wachsmuth, </author> <title> "Robots and Simulated Environments First Steps Towards Virtual Robotics", </title> <booktitle> IEEE Symposium on Research Frontiers in Virtual Reality, </booktitle> <address> pp.122-123, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: The raw data obtained from such sensors tends to be of limited resolution and accuracy, and is often noisy. For this reason, robotics researchers sometimes choose to develop their control algorithms using simulated environments, thereby avoiding the need to deal with the idiosyncrasies of real-world sensing <ref> [1] </ref>.
Reference: [2] <author> H. Kuttruff, </author> <title> "Ultrasonics Fundamentals and Applications", </title> <publisher> Elsevier Science Publishers, </publisher> <year> 1991. </year>
Reference-contexts: must be considered if coherent information is to be supplied to the user. 2.1 Causes of low-quality sonar data The passage of an ultrasonic pulse around an environment is a complex process, with a be-haviour reminiscent of the transport of light rays a topic well-known to the computer graphics community <ref> [2] </ref>. However, in the context of acoustic sensing some general situations can be identified which may lead to measurement anomalies: Lost echoes. If an acoustic pulse strikes an object with a large angle of incidence the signal may not return to the source.
Reference: [3] <author> J.M. Loomis, </author> <title> "Understanding Synthetic Experience Must Begin with the Analysis of Ordinary Perceptual Experience", </title> <booktitle> IEEE Symposium on Research Frontiers in Virtual Reality, </booktitle> <address> pp.54-57, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: Clearly many solutions are possible. However, it is recognised that human spatial understanding is largely qualitative in nature. Perception of locality is always judged relative to some feature of the environment <ref> [3] </ref>. This suggests that the visualization of significant landmarks is of greater importance than the presentation of quantitative information, such as precise distance indicators.
Reference: [4] <author> U. Nehmzow, "Manchester Telerobotics", </author> <title> World Wide Web reference http:// www.cs.man.ac.uk/robotics/Telerobotics/telerobotics.html. </title>
Reference-contexts: No attempt is made to remove noisy data from the rendered image, which makes scene interpretation extremely difficult, particularly for remote navigation tasks. However, with effort a limited degree of teleoperation is possible using such an interface <ref> [4] </ref>. 2 Acoustic sensing Acoustic range finders determine obstacle distances using `sonar' echo-location ultrasonic pulses are fired into the environment, and the time taken for their return is measured. The raw data obtained from such sensors tends to be of limited resolution and accuracy, and is often noisy.
Reference: [5] <author> Nomadic Technologies Inc., </author> <title> "Nomadic Host Software Development Environment (Release 2.1)", </title> <month> November </month> <year> 1993. </year>
Reference-contexts: These are arranged to provide the robot with a full 360 degree sensing capability. The robot control software supplied by the manufacturer features a simple graphical utility for the visualization of sensor data <ref> [5] </ref>. The approach taken is to render a `scatter plot' of raw sensor readings, whose distribution forms an approximate plan view of the robot's perceived environment. No attempt is made to remove noisy data from the rendered image, which makes scene interpretation extremely difficult, particularly for remote navigation tasks. <p> The implementation of the refinement algorithm is close to completion. A number of experimental issues are still to be addressed. To begin with, a study of the effectiveness of the new visualization method for remote navigation tasks is to be performed. The existing raw data plotting method <ref> [5] </ref> will be used as a baseline. Secondly, an evaluation of 3D visualization methods is planned, in which obstacle regions are extruded vertically to form free-standing solids.
Reference: [6] <institution> Nomadic Technologies Inc., </institution> <note> "Nomad 200 User's guide", </note> <month> December </month> <year> 1993. </year>
Reference-contexts: A Nomad 200 mobile robot is being used in the research to allow the evaluation of visualization methods using real-world data <ref> [6] </ref>. Amongst its many sensing devices are sixteen acoustic range finders, each with an operating range of around ten metres (Figure 1). These are arranged to provide the robot with a full 360 degree sensing capability.
Reference: [7] <author> K. Weiler, </author> <title> "Polygon Comparison using a Graph Representation", </title> <journal> ACM Computer Graphics, </journal> <volume> 14(3), pp.10-18, </volume> <month> July </month> <year> 1980. </year>
Reference-contexts: The approach taken is to construct a geometric representation of the robot's perceived environment, which is then refined over time by incorporating more up-to-date sensor measurements. Polygon union ([) and difference () operations are used to edit the geometry <ref> [7] </ref>. The method is not intended as a means of precise map production, and does not require highly-accurate odometry in order to function.
References-found: 7

