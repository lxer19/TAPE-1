URL: ftp://ftp.cs.brown.edu/pub/techreports/95/cs95-29.ps.Z
Refering-URL: http://www.cs.brown.edu/publications/techreports/reports/CS-95-29.html
Root-URL: 
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Bod, A. Rens, </author> <title> Using an annotated language corpus as a virtual stochastic grammar. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <address> Menlo Park: </address> <note> AAAI Press/MIT Press (1993) 778-783 </note>
Reference-contexts: This latter figure represents a 41.1% reduction in the number of bracket-crossing errors when compared to the pure PCFG. This is consistent with other work using statistics on lexical information such as <ref> [1, 9] </ref>. 3 Verb Case Frames We now turn to the question of what the system described above actually learned. We took as our initial hypothesis that it had, in fact, learned at least some of the lexical information commonly of interest in linguistic discussions.
Reference: [2] <author> Brent, Michael R., </author> <title> Automatic acquisition of subcategorization frames from untagged text. </title> <booktitle> In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics (1991) 209-214 </booktitle>
Reference-contexts: Yesterday they abandoned the project. (Case frame: np) He abandoned himself to despair. (Case frame: np p) There have already been a few attempts at learning verb case frames from corpora. Brent <ref> [2, 3] </ref> has tried to extract this information from both untagged and tagged corpora. Similarly, Manning [10] generated case-frame lists for verbs from untagged corpora. To make our results compatible, we tried to follow Manning whenever possible. <p> So the raw results have to be filtered and the actual case frame assignments distinguished from the wrong ones. The filtering method used here is the one proposed by Brent <ref> [2] </ref>. This method assumes that B s is the estimated upper bound on the probability 9 that the program assigns a wrong case frame to a verb token.
Reference: [3] <author> Brent, Michael R. and Berwick, R. C., </author> <title> Automatic acquisition of subcategorization frames from tagged text. </title> <booktitle> In Proceedings of the 4th DARPA Speech and Natural Language Workshop (1991) 342-345 </booktitle>
Reference-contexts: Yesterday they abandoned the project. (Case frame: np) He abandoned himself to despair. (Case frame: np p) There have already been a few attempts at learning verb case frames from corpora. Brent <ref> [2, 3] </ref> has tried to extract this information from both untagged and tagged corpora. Similarly, Manning [10] generated case-frame lists for verbs from untagged corpora. To make our results compatible, we tried to follow Manning whenever possible.
Reference: [4] <author> Carroll, Glenn and Charniak, Eugene, </author> <title> Two experiments on learning probabilistic dependency grammars from corpora. </title> <booktitle> In Workshop Notes, Statistically-Based NLP Techniques, AAAI (1992) 1-13 </booktitle>
Reference-contexts: more on this data, see [11].) The grammar used throughout the experiment is a context-free grammar developed from 5 Head Rule/Subhead Count pulled s ! np vp 1 dogs 1 sleds 1 over 1 over pp ! prep np 1 rocks 1 rocks." work on context-free grammar induction described in <ref> [4, 5] </ref>. To test the model we used sentences from parsed ACL-LDCI WSJ text, none of which is used in training. We restricted consideration to sentences that use the 5400 most common words from this corpus, which were those that appeared in the corpus 500 or more times.
Reference: [5] <author> Charniak, Eugene and Carroll, Glenn, </author> <title> Context-sensitive statistics for improved grammatical language models. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <address> Menlo Park: </address> <note> AAAI Press/MIT Press (1994) 728-733 </note>
Reference-contexts: more on this data, see [11].) The grammar used throughout the experiment is a context-free grammar developed from 5 Head Rule/Subhead Count pulled s ! np vp 1 dogs 1 sleds 1 over 1 over pp ! prep np 1 rocks 1 rocks." work on context-free grammar induction described in <ref> [4, 5] </ref>. To test the model we used sentences from parsed ACL-LDCI WSJ text, none of which is used in training. We restricted consideration to sentences that use the 5400 most common words from this corpus, which were those that appeared in the corpus 500 or more times.
Reference: [6] <author> Charniak, Eugene, </author> <title> Parsing with context-free grammars and word statistics. </title> <type> Technical Report CS-95-28, </type> <institution> Department of Computer Science, Brown University (1995) </institution>
Reference-contexts: In this section we describe a system for syntactic disambiguation. We keep the description simple because our concern here is not the system per se, but rather what the system learned that made possible its improved performance. See <ref> [6] </ref> for a more complete description of the program and its underlying theory. From a statistical point of view syntactic disambiguation is formalized as finding the most probable parse of the sentence. One comparatively simple version of this ideas uses the notion of a probabilistic context-free grammar (PCFG).
Reference: [7] <author> Charniak, Eugene, </author> <title> Statistical Language Learning. </title> <publisher> Cambridge: MIT Press (1993) </publisher>
Reference-contexts: Also, we have assumed here that there is only one parse for this sentence, while in reality sentences have multiple parses. However, techniques for handling this obstacle are well known (see, e.g., <ref> [7] </ref>) and we do not go into them here. 2.2 The Experiment The system was run using data collected by parsing 36 million words of Wall Street Journal (WSJ) text provided by the ACL Linguistics Data Collection Initiative (ACL-LDCI). (For more on this data, see [11].) The grammar used throughout the
Reference: [8] <author> Hornby, A. S., </author> <title> Oxford Advanced Learner's Dictionary of Current English. </title> <publisher> Oxford: Oxford University Press. 3rd ed. </publisher> <year> (1985) </year>
Reference-contexts: For example, the tagger and parser we used are more likely to make mistakes that generate extra p frames than any other frame. All the B s values have been set empirically. 3.3 Evaluation The Oxford Advanced Learner's Dictionary (OALD) <ref> [8] </ref> is used for testing the results of the program. The case frames learned by the program and the case frames in OALD do not have a direct correspondence, so OALD's 51 case frames are mapped into our 16 case frames.
Reference: [9] <author> Magerman, David M., </author> <title> Statistical decision-tree models for parsing. </title> <booktitle> In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics (1995) 276-283 </booktitle>
Reference-contexts: This latter figure represents a 41.1% reduction in the number of bracket-crossing errors when compared to the pure PCFG. This is consistent with other work using statistics on lexical information such as <ref> [1, 9] </ref>. 3 Verb Case Frames We now turn to the question of what the system described above actually learned. We took as our initial hypothesis that it had, in fact, learned at least some of the lexical information commonly of interest in linguistic discussions.
Reference: [10] <author> Manning, Christopher D. </author> <title> Automatic acquisition of a large subcategorization dictionary from corpora. </title> <booktitle> In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics (1993) 235-242 </booktitle>
Reference-contexts: Yesterday they abandoned the project. (Case frame: np) He abandoned himself to despair. (Case frame: np p) There have already been a few attempts at learning verb case frames from corpora. Brent [2, 3] has tried to extract this information from both untagged and tagged corpora. Similarly, Manning <ref> [10] </ref> generated case-frame lists for verbs from untagged corpora. To make our results compatible, we tried to follow Manning whenever possible.
Reference: [11] <author> Marcus, Mitchell P., Santorini, Beatrice, and Marcinkiewicz, Mary Ann, </author> <title> Building a large annotated corpus of English: the Penn treebank. </title> <note> In Computational Linguistics 19 (1993) 313-330 18 </note>
Reference-contexts: are well known (see, e.g., [7]) and we do not go into them here. 2.2 The Experiment The system was run using data collected by parsing 36 million words of Wall Street Journal (WSJ) text provided by the ACL Linguistics Data Collection Initiative (ACL-LDCI). (For more on this data, see <ref> [11] </ref>.) The grammar used throughout the experiment is a context-free grammar developed from 5 Head Rule/Subhead Count pulled s ! np vp 1 dogs 1 sleds 1 over 1 over pp ! prep np 1 rocks 1 rocks." work on context-free grammar induction described in [4, 5].
References-found: 11

