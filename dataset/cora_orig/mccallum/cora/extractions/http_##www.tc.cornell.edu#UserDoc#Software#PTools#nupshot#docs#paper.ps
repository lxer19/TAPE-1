URL: http://www.tc.cornell.edu/UserDoc/Software/PTools/nupshot/docs/paper.ps
Refering-URL: http://www.tc.cornell.edu/UserDoc/Software/PTools/nupshot/
Root-URL: http://www.tc.cornell.edu
Email: E-mail: fcwu, frankeh, yhliug@watson.ibm.com  
Title: UTE: A Unified Trace Environment for IBM SP Systems  
Author: C. Eric Wu, Hubertus Franke, and Yew-Huey Liu P. O. Box 
Address: Heights, NY 10598  
Affiliation: IBM T. J. Watson Research Center  Yorktown  
Abstract: Distributed parallel systems such as IBM SP1/SP2 based on message passing are more difficult to program than sequential machines. This paper describes methods and tools in UTE, a unified trace environment for IBM SP systems. Two libraries, UTE/MPI and UTE/MPL, are developed for MPI and MPL applications, respectively, and no source code modification is necessary for trace generation. Message passing events in UTE are generated with minimum overhead (a few secs) along with system events such as process dispatch, page faults, and I/O. User markers are provided to mark various phases, loops, and routines if application source code is available. These events can be visualized, not only for users to understand the communication behavior of an application, but also to understand system responses and pinpoint the bottleneck of the application. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Aydt, </author> <title> The Pablo Self-Defining Data Format. </title> <type> Technical Report, </type> <institution> Dept. of Computer Science, University of Illinois, </institution> <month> July </month> <year> 1994. </year>
Reference-contexts: UTE provides multiple conversion utilities to convert a merged trace file to formats suitable for visualization, including the PV format for PV [13], SDDF format <ref> [1] </ref> for Pablo, and ALOG format for Upshot/Nupshot. In this subsection we will describe our visualization approach by modifying nupshot to suit our needs and unique experience of visualizing both message passing and system events.
Reference: [2] <author> V. Bala et al., </author> <title> The IBM external user interface for scalable parallel systems. </title> <journal> Parallel Computing, </journal> <volume> vol. 20 (1994), </volume> <pages> pp. 445 - 462. </pages>
Reference-contexts: There are two major message passing APIs supported in IBM SP systems: the Message Passing Interface (MPI) [15, 9] and the IBM Message Passing Library (MPL) <ref> [2, 10] </ref>. Figure 1 illustrates the UTE framework. In addition to these two UTE libraries, hooks have been inserted in MPLp (EUI-H) [18], MPX, PI-OFS [5], Vesta [4, 3], and HPF [13] using the same framework to generate events in various software layers. UTE supports on-line merging.
Reference: [3] <author> S. Baylor and C.E. Wu, </author> <title> Parallel I/O Workload Characteristics Using Vesta. </title> <booktitle> Proc. of IOPADS Workshop at IPPS'95, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: Figure 1 illustrates the UTE framework. In addition to these two UTE libraries, hooks have been inserted in MPLp (EUI-H) [18], MPX, PI-OFS [5], Vesta <ref> [4, 3] </ref>, and HPF [13] using the same framework to generate events in various software layers. UTE supports on-line merging.
Reference: [4] <author> P. Corbett and D. Feitelson, </author> <title> Design and Implementation of the Vesta Parallel File System. </title> <booktitle> Proc. of 1994 Scalable High Performance Computing Conference, </booktitle> <pages> pp. 63 - 70, </pages> <year> 1994. </year>
Reference-contexts: Figure 1 illustrates the UTE framework. In addition to these two UTE libraries, hooks have been inserted in MPLp (EUI-H) [18], MPX, PI-OFS [5], Vesta <ref> [4, 3] </ref>, and HPF [13] using the same framework to generate events in various software layers. UTE supports on-line merging.
Reference: [5] <author> P. Corbett et. al, </author> <title> Parallel File Systems for IBM SP Computers. </title> <journal> IBM System Journal, pp. </journal> <volume> 1 - 25, </volume> <year> 1995. </year>
Reference-contexts: Figure 1 illustrates the UTE framework. In addition to these two UTE libraries, hooks have been inserted in MPLp (EUI-H) [18], MPX, PI-OFS <ref> [5] </ref>, Vesta [4, 3], and HPF [13] using the same framework to generate events in various software layers. UTE supports on-line merging.
Reference: [6] <author> H. Davis, S. Goldschmidt, and J. Hennessy, </author> <title> Multiprocessor Simulation And Tracing Using Tango. </title> <booktitle> Proc. 1991 Int'l Conf. on Parallel Processing, </booktitle> <pages> pp. </pages> <address> II-99 II-107, </address> <month> Aug. </month> <year> 1991. </year>
Reference-contexts: That would not only make trace generation more intrusive, but also make performance analysis tedious and difficult. Many trace systems such as those in <ref> [6, 7, 17] </ref> require source code modification to generate trace events. The UTE trace libraries, on the other hand, requires only re-linking for trace generation. If the application source code is available, additional user markers can be inserted into the source code.
Reference: [7] <author> G. Geist, M. Heath, B. Peyton, and P. Wor-ley, </author> <title> A Users' Guide to PICL: A Portable Instrumented Communication Library. </title> <type> Technical Report ORNL/TM-11616, </type> <institution> Oak Ridge National Laboratory, </institution> <month> October </month> <year> 1990. </year>
Reference-contexts: As a result, many trace facilities in distributed systems are forced to do additional work to ensure consistent timestamps at the expense of increased trace overhead. For example, the tracenode () routine in PICL <ref> [7] </ref> synchronizes local clocks using a barrier synchronization. Lamport [11] developed a distributed algorithm for resource-sharing systems to extend the partial ordering to a consistent total ordering of all events by creating additional messages among processors: another form of barrier synchronization. <p> That would not only make trace generation more intrusive, but also make performance analysis tedious and difficult. Many trace systems such as those in <ref> [6, 7, 17] </ref> require source code modification to generate trace events. The UTE trace libraries, on the other hand, requires only re-linking for trace generation. If the application source code is available, additional user markers can be inserted into the source code.
Reference: [8] <author> M. Heath, </author> <title> Visualizing the Performance of Parallel Programs. </title> <journal> IEEE Software, </journal> <volume> vol 8, no. 5, </volume> <pages> pp. 29 - 39, </pages> <month> Sep. </month> <year> 1991. </year>
Reference-contexts: One common way of monitoring the behavior of a program is to generate trace events while executing the program. Events generated can then be used for trace-driven analysis [12], program visualization <ref> [8, 14] </ref>, and debugging [16]. In a distributed system, however, each processor (or node) has its own local memory and local clock, and processors communicate with one another by exchanging messages.
Reference: [9] <author> H. Franke, P. Hochschild, P. Pattnaik, and M. Snir, </author> <title> MPI-F: An Efficient Implementation of MPI on IBM SP2. </title> <booktitle> Proc. of 1994 International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: There are two major message passing APIs supported in IBM SP systems: the Message Passing Interface (MPI) <ref> [15, 9] </ref> and the IBM Message Passing Library (MPL) [2, 10]. Figure 1 illustrates the UTE framework.
Reference: [10] <author> International Business Machines, </author> <title> IBM AIX Parallel Environment: Parallel Programming Reference. </title> <institution> IBM Publication SH26-7228, </institution> <month> Sep. </month> <year> 1993. </year>
Reference-contexts: There are two major message passing APIs supported in IBM SP systems: the Message Passing Interface (MPI) [15, 9] and the IBM Message Passing Library (MPL) <ref> [2, 10] </ref>. Figure 1 illustrates the UTE framework. In addition to these two UTE libraries, hooks have been inserted in MPLp (EUI-H) [18], MPX, PI-OFS [5], Vesta [4, 3], and HPF [13] using the same framework to generate events in various software layers. UTE supports on-line merging.
Reference: [11] <author> L. Lamport, </author> <title> Time, Clocks, and the Ordering of Events in a Distributed System. </title> <journal> Communications of ACM, July 1978, </journal> <volume> vol. 21, no. 7, </volume> <pages> pp. 558 - 565. </pages>
Reference-contexts: In such a system, trace records are generated by multiple processors, and it is often the case that separate streams are produced independently in multiple nodes. There is a serious problem associated with trace analysis, i.e., the clock synchronization problem <ref> [11] </ref>. The logical order of events may not be guaranteed in the trace due to discrepancy among local clocks. As a result, many trace facilities in distributed systems are forced to do additional work to ensure consistent timestamps at the expense of increased trace overhead. <p> As a result, many trace facilities in distributed systems are forced to do additional work to ensure consistent timestamps at the expense of increased trace overhead. For example, the tracenode () routine in PICL [7] synchronizes local clocks using a barrier synchronization. Lamport <ref> [11] </ref> developed a distributed algorithm for resource-sharing systems to extend the partial ordering to a consistent total ordering of all events by creating additional messages among processors: another form of barrier synchronization.
Reference: [12] <author> T. Kerola and H. Schwetman, Monit: </author> <title> A Performance Monitoring Tool for Parallel and Pseudo-Parallel Programs. </title> <booktitle> Proc. of the ACM SIGMET-RICS, </booktitle> <month> May </month> <year> 1987. </year>
Reference-contexts: One common way of monitoring the behavior of a program is to generate trace events while executing the program. Events generated can then be used for trace-driven analysis <ref> [12] </ref>, program visualization [8, 14], and debugging [16]. In a distributed system, however, each processor (or node) has its own local memory and local clock, and processors communicate with one another by exchanging messages.
Reference: [13] <author> D. Kimelman et. al, </author> <title> Visualizing the Execution of High Performance Fortran (HPF) Programs. </title> <booktitle> Proc. of 1995 Int'l Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: Figure 1 illustrates the UTE framework. In addition to these two UTE libraries, hooks have been inserted in MPLp (EUI-H) [18], MPX, PI-OFS [5], Vesta [4, 3], and HPF <ref> [13] </ref> using the same framework to generate events in various software layers. UTE supports on-line merging. However, we collect 2 trace events in nodes where an application is executing and merge them afterwards in most cases due to the limited LAN bandwidth and volume of trace events. <p> This shows that trace overhead is indeed very small. 3.2 Visualization The purpose of program visualization systems is to gain insight into the dynamic behavior of programs. UTE provides multiple conversion utilities to convert a merged trace file to formats suitable for visualization, including the PV format for PV <ref> [13] </ref>, SDDF format [1] for Pablo, and ALOG format for Upshot/Nupshot. In this subsection we will describe our visualization approach by modifying nupshot to suit our needs and unique experience of visualizing both message passing and system events.
Reference: [14] <author> A. Malony, D. Hammerslag, and D. Jablonowski, </author> <title> Traceview: A Trace Visualization Tool. </title> <journal> IEEE Software, pp. </journal> <volume> 19 - 28, </volume> <month> September </month> <year> 1991. </year>
Reference-contexts: One common way of monitoring the behavior of a program is to generate trace events while executing the program. Events generated can then be used for trace-driven analysis [12], program visualization <ref> [8, 14] </ref>, and debugging [16]. In a distributed system, however, each processor (or node) has its own local memory and local clock, and processors communicate with one another by exchanging messages.
Reference: [15] <author> MPI Forum, </author> <title> Document for a standard message-passing interface. </title> <type> Tech. Rep. </type> <institution> CS-93-214, University of Tennessee, </institution> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: There are two major message passing APIs supported in IBM SP systems: the Message Passing Interface (MPI) <ref> [15, 9] </ref> and the IBM Message Passing Library (MPL) [2, 10]. Figure 1 illustrates the UTE framework.
Reference: [16] <author> M. Pongami, W. Hseush, and G. Kaiser, </author> <title> Debugging Multi-threaded Programs with MPD. </title> <journal> IEEE Software, </journal> <volume> vol. 8, no. 3, </volume> <pages> pp. 37 - 43, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: One common way of monitoring the behavior of a program is to generate trace events while executing the program. Events generated can then be used for trace-driven analysis [12], program visualization [8, 14], and debugging <ref> [16] </ref>. In a distributed system, however, each processor (or node) has its own local memory and local clock, and processors communicate with one another by exchanging messages.
Reference: [17] <author> K. So, A. Bolmarcich, F. Darema, and V. </author> <title> Norton, </title>
Reference-contexts: That would not only make trace generation more intrusive, but also make performance analysis tedious and difficult. Many trace systems such as those in <ref> [6, 7, 17] </ref> require source code modification to generate trace events. The UTE trace libraries, on the other hand, requires only re-linking for trace generation. If the application source code is available, additional user markers can be inserted into the source code.
References-found: 17

