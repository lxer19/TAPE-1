URL: http://www.cs.utexas.edu/users/dahlin/papers/masters.ps
Refering-URL: http://www.cs.utexas.edu/users/dahlin/papers/mastersAbstract.html
Root-URL: 
Title: CRAM: A TURBOChannel Board for Fast Lossless Compression  
Author: Michael D. Dahlin 
Date: May 11, 1993 1  
Note: CRAM  
Abstract: We have developed the Compression Reconfigurable Active Memory (CRAM) board, a prototype hardware compression engine designed to help examine the system implications of ubiquitous fast lossless data compression. This paper gives a description of this design, examines our choice of Wheeler hashing as a compression algorithm for high-speed hardware implementation, and surveys the cost/performance trade-offs made in selecting a version of the algorithm for our implementation. Most of the CRAMs logic is built using Xilinx Field Programmable Gate Arrays (FPGAs). The current implementation of the CRAM provides compression and decompression with a throughput of 6.25 MB/s accessed via a TURBOChannel DMA interface. The CRAM design allows simultaneous compression and decompression at a rate of 12.5 MB/s each. The algorithm used is expected to provide approximately 2:1 lossless compression for many applications. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> Advance Hardware Architectures. </editor> <title> AHA3210 data compression coprocessor IC. Preliminary Product Specification PS3210-0292, Advance Hardware Architectures, </title> <publisher> Inc., </publisher> <address> P.O. Box 9669, Moscow, Idaho 83843, </address> <month> February </month> <year> 1992. </year>
Reference-contexts: Bianchi, Kato, and Van Maren [5] have implemented a dedicated 2.4 MB/s LZ compression engine for the Hewlett-Packard 7980XC half-inch tape drive. They demonstrated significant throughput improvements when this compression was combined with aggressive super-blocking. The Advance Hardware Architectures AHA3210 chip <ref> [1] </ref> is a commercial product designed for integration into datapaths in this manner. It provides 10 MB/s compression or decompression using a variation of LZW coding. Compression has also been used to improve the throughput of low-speed networks.
Reference: [2] <author> Altera, </author> <title> Incorporated. Altera data book. Product specification, </title> <publisher> Altera, Incorporated, </publisher> <address> 2610 Orchard Parkway, San Jose, California 95134-2800, </address> <year> 1992. </year>
Reference-contexts: The microsequencer and two PALs are on the bottom right. Four trancievers and a ROM are on the right side. CRAM May 11, 1993 10 with a ash-clear feature to hold the Wheeler prediction tables, and two PALs and an Altera Microsequencer <ref> [2] </ref> to control single-word I/O and Xilinx programming. A top-level schematic of the CRAM is shown in Figure 10. A DMA transfer is activated by writing a pair of registers in the DMA Xilinx.
Reference: [3] <author> R. B. Arps, T. K. Truong, D. J. Lu, R. C. Pasco, and T. D. Friedman. </author> <title> A multi-purpose VLSI chip for adaptive compression of bilevel images. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 32(6):775795, </volume> <year> 1988. </year>
Reference-contexts: Bunton and Borriello [6] have designed a dictionary management scheme for LZ compression for CRAM May 11, 1993 4 which a custom 2m CMOS implementation could achieve compression rates from 14 to 20 MB/s depending on the level of integration achieved. The IBM Q-Coder <ref> [3, 18] </ref> implements bit-serial adaptive arithmetic coding in an ASIC design and achieves approximately 1.2 MB/s throughput. Printz and Stubley [19] have implemented a static arithmetic coder on the DECPeRLe-1 Xilinx prototyping board [4] using eight Xilinx 3090s and 2 12 x 23 bits of memory.
Reference: [4] <author> Patrice Bertin, Didier Roncin, and Jean Vuillemin. </author> <title> Programmable active memories: A performance assessment. </title> <address> Seattle, WA, 1993. </address> <publisher> MIT Press. </publisher>
Reference-contexts: The IBM Q-Coder [3, 18] implements bit-serial adaptive arithmetic coding in an ASIC design and achieves approximately 1.2 MB/s throughput. Printz and Stubley [19] have implemented a static arithmetic coder on the DECPeRLe-1 Xilinx prototyping board <ref> [4] </ref> using eight Xilinx 3090s and 2 12 x 23 bits of memory. This implementation has been successfully tested at 16 MB/s compression rate.
Reference: [5] <author> Mark J. Bianchi, Jeffery J. Kato, and David J. Van Maren. </author> <title> Data compression in a half-inch reel-to-reel tape drive. </title> <journal> Hewlett-Packard Journal, </journal> <volume> 40(3):2631, </volume> <year> 1989. </year>
Reference-contexts: He concluded that when compression allows all pages to fit into memory, program speedup will be linear with the speed of the compressor. Other storage systems have used dedicated compression hardware to increase both capacity and throughput. Bianchi, Kato, and Van Maren <ref> [5] </ref> have implemented a dedicated 2.4 MB/s LZ compression engine for the Hewlett-Packard 7980XC half-inch tape drive. They demonstrated significant throughput improvements when this compression was combined with aggressive super-blocking. The Advance Hardware Architectures AHA3210 chip [1] is a commercial product designed for integration into datapaths in this manner.
Reference: [6] <author> Susan Bunton and Gaetano Borriello. </author> <title> Practical dictionary management for hardware data compression. </title> <journal> Communications of the ACM, </journal> <volume> 32(1):95104, </volume> <month> January </month> <year> 1992. </year>
Reference-contexts: It uses a variation of LZW encoding and current commercial implementations attached to modems can give throughputs up to 0.005 MB/s over telephone lines. Other researchers are developing fast hardware compression implementations. Bunton and Borriello <ref> [6] </ref> have designed a dictionary management scheme for LZ compression for CRAM May 11, 1993 4 which a custom 2m CMOS implementation could achieve compression rates from 14 to 20 MB/s depending on the level of integration achieved.
Reference: [7] <author> Michael Burrows, Charles Jerian, Butler Lampson, and Timothy Mann. </author> <title> On-line data compression in a log-structured file system. </title> <booktitle> In ASPLOS-V, </booktitle> <pages> pages 29, </pages> <address> Boston, Massachusetts, </address> <month> October </month> <year> 1992. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: Unix compress is a familiar utility that provides users with a manual method to reduce the size of files stored to disk or tape. More sophisticated systems compress and decompress data on-line, without user intervention. Burrows, Jerian, Lampson, and Mann <ref> [7] </ref> devised a software compression scheme for log-structured file systems. They showed large increases in disk capacities in a Unix environment and speculated that the addition of hardware compression would increase disk throughputs relative to the uncompressed system. <p> We elected to implement Wheeler hashing as described by Burrows <ref> [7] </ref> as our lossless compression algorithm because it is a fast and reasonably effective compression algorithm that is simple enough to be implemented in two Xilinx FPGAs.
Reference: [8] <author> CCITT Study Group XVII. </author> <title> Data compression procedures for data circuit terminating equipment (DCE) using error correcting procedures (recommendation V42 bis). CCITT Report F ITU 1990, Internaltional Telegraph and Telephone Consensus Committee, </title> <month> January </month> <year> 1990. </year>
Reference-contexts: Compression has also been used to improve the throughput of low-speed networks. Jacobson [14] showed significant improvement for interactive response times for small packets transmitted over very slow links when the packets headers were compressed using a specialized software compression algorithm. The v42.bis standard <ref> [8] </ref> has been designed to improve bulk transfer rates across low-speed lines. It uses a variation of LZW encoding and current commercial implementations attached to modems can give throughputs up to 0.005 MB/s over telephone lines. Other researchers are developing fast hardware compression implementations.
Reference: [9] <author> Digital Equipment Corporation. </author> <title> TURBOChannel hardware specification. On-Line Hardware Specification EK-369AA-OD-007, </title> <institution> Digital Equipment Corporation, </institution> <year> 1991. </year>
Reference-contexts: We designed the board as a compression resource accessed by the system through DMA for a number of reasons. We implemented the board as a general system resource attached to the TURBOChannel <ref> [9] </ref> rather than hardwiring the compressor to a specific I/O subsystem because we desired the exibility to investigate the use of compression to enhance several different subsystems.
Reference: [10] <author> Fred Douglis. </author> <title> The compression cache: Using on-line compression to extend physical memory. </title> <booktitle> In USENIX Association Winter 1993 Conference Proceedings, </booktitle> <pages> pages 519 529, </pages> <address> San Diego, CA, </address> <month> January </month> <year> 1993. </year> <booktitle> The USENIX Association. </booktitle>
Reference-contexts: Grehan and Wszola [11] survey eight commercial systems that compress personal computer data before storing it to disks. They measured average compression ratios from 1.25:1 to 2:1 and average reductions in throughput from less than 3% to over 80%. Douglis <ref> [10] </ref> extended this idea to higher levels of the memory hierarchy by implementing a compression cache that attempted to reduce both the quantity and size of memory paging I/O by increasing the effective size of main memory using compression and by paging only compressed pages to and from disk.
Reference: [11] <author> Rick Grehan and Stan Wszola. </author> <title> Shrink to fit. </title> <journal> Byte, </journal> <volume> 18(4):150162, </volume> <year> 1993. </year>
Reference-contexts: Burrows, Jerian, Lampson, and Mann [7] devised a software compression scheme for log-structured file systems. They showed large increases in disk capacities in a Unix environment and speculated that the addition of hardware compression would increase disk throughputs relative to the uncompressed system. Grehan and Wszola <ref> [11] </ref> survey eight commercial systems that compress personal computer data before storing it to disks. They measured average compression ratios from 1.25:1 to 2:1 and average reductions in throughput from less than 3% to over 80%.
Reference: [12] <author> David A. Huffman. </author> <title> A method for the constructin of minimum-redundancy codes. </title> <booktitle> Proceedings of the Institute of Radio Engineers, </booktitle> <address> 40(9):10981101, </address> <year> 1952. </year>
Reference-contexts: Pseudo-code implementation of 1-Table Wheeler hashing compression algorithm. CRAM uses a slightly more complicated 2-Table version of the algorithm in which two predictions are stored at each table entry and the codes output can be one, three, nine, or ten bits in length. CRAM May 11, 1993 6 coding <ref> [12] </ref> would be constructed based on the target workloads expected hit frequencies for the different hash table predictions and miss frequencies for the different input characters.
Reference: [13] <author> IBM Compression Subsystems Development. </author> <title> ALDC1-5S design specification (version 2). Product specification, IBM Compression Subsystems Development, </title> <type> 1000 River Road, Essex Junction, Vermont 05452, </type> <month> March </month> <year> 1993. </year>
Reference-contexts: Storer [21] has implemented fast compression using a prototype systolic array using 30 custom CMOS chips. This algorithm runs at 20 MB/s and is accessed through a VME interface. IBMs ALDC compressor <ref> [13, 16] </ref> is available as a VHDL macro that may be inserted into 0.8m CMOS designs.
Reference: [14] <author> Van Jacobson. </author> <title> Compressing TCP/IP headers for low-speed serial links. Request for Comments 1144, Network Working Group, </title> <type> ISI, </type> <month> February </month> <year> 1990. </year>
Reference-contexts: The Advance Hardware Architectures AHA3210 chip [1] is a commercial product designed for integration into datapaths in this manner. It provides 10 MB/s compression or decompression using a variation of LZW coding. Compression has also been used to improve the throughput of low-speed networks. Jacobson <ref> [14] </ref> showed significant improvement for interactive response times for small packets transmitted over very slow links when the packets headers were compressed using a specialized software compression algorithm. The v42.bis standard [8] has been designed to improve bulk transfer rates across low-speed lines.
Reference: [15] <author> Randy H. Katz, Thomas E. Anderson, John K. Ousterhout, and David A. Patterson. </author> <title> Robo-line storage: Low latency high capacity storage systems over geographically distributed network. </title> <type> Sequoia 2000 Technical Report 91/3, </type> <institution> University of California, </institution> <month> September </month> <year> 1991. </year> <note> CRAM May 11, 1993 24 </note>
Reference: [16] <author> Ted Lattrell. ALDC: </author> <title> Adaptive lossless data compression. Unpublished report, IBM Compression Subsystems Development, </title> <type> 1000 River Road, Essex Junction, Vermont 05452, </type> <month> January </month> <year> 1993. </year>
Reference-contexts: Storer [21] has implemented fast compression using a prototype systolic array using 30 custom CMOS chips. This algorithm runs at 20 MB/s and is accessed through a VME interface. IBMs ALDC compressor <ref> [13, 16] </ref> is available as a VHDL macro that may be inserted into 0.8m CMOS designs.
Reference: [17] <author> Logic Devices, </author> <title> Incorporated. Fast CMOS data book. Product specification, Logic Devices, </title> <publisher> Incorporated, </publisher> <address> 628 East Evelyn Avenue, Sunnyvale, California, 94086, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: Total throughput was also enhanced by including a ash clear capability in the SRAMs so that we dont have to wait excessively between compression or decompression blocks. The largest SRAM we were able to locate with the desired speed and features contained 8K entries of eight bits each <ref> [17] </ref>. We use two of these chips for the compressor and two for the decompressor to implement 8K long by two prediction wide tables. This size is large enough to achieve good compression as indicated in Figure 3 on page 6. Two-table variation of Wheeler hashing.
Reference: [18] <author> W. B. Pennebaker, J. L. Mitchell, G. G. Langdon Jr., and R. B. </author> <title> Arps. An overview of the basic principles of the q-coder adaptive binary arithmetic coder. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 32(6):717726, </volume> <year> 1988. </year>
Reference-contexts: Bunton and Borriello [6] have designed a dictionary management scheme for LZ compression for CRAM May 11, 1993 4 which a custom 2m CMOS implementation could achieve compression rates from 14 to 20 MB/s depending on the level of integration achieved. The IBM Q-Coder <ref> [3, 18] </ref> implements bit-serial adaptive arithmetic coding in an ASIC design and achieves approximately 1.2 MB/s throughput. Printz and Stubley [19] have implemented a static arithmetic coder on the DECPeRLe-1 Xilinx prototyping board [4] using eight Xilinx 3090s and 2 12 x 23 bits of memory.
Reference: [19] <author> Harry Printz and Peter Stubley. </author> <title> Multialphabet arithmetic coding at 16 Mbytes/sec. </title> <booktitle> In DCC-93, </booktitle> <pages> pages 128137, </pages> <address> Snowbird, Utah, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: The IBM Q-Coder [3, 18] implements bit-serial adaptive arithmetic coding in an ASIC design and achieves approximately 1.2 MB/s throughput. Printz and Stubley <ref> [19] </ref> have implemented a static arithmetic coder on the DECPeRLe-1 Xilinx prototyping board [4] using eight Xilinx 3090s and 2 12 x 23 bits of memory. This implementation has been successfully tested at 16 MB/s compression rate.
Reference: [20] <author> Michael Stonebraker, James Frew, Kenn Gardels, and Jeff Meredith. </author> <title> The Sequoia 2000 storage benchmark. </title> <type> Sequoia 2000 Technical Report 92/12, </type> <institution> University of California, </institution> <year> 1992. </year>
Reference-contexts: Compression results for selected scientific data sets. CRAM May 11, 1993 9 are samples of the three data types used in the Sequoia 2000 system benchmark <ref> [20] </ref>. 2 The fourth is a data type known to be very difficult to compress from the Advanced Very High Resolution Radiometer (AVHRR) sensor.
Reference: [21] <author> James Storer. </author> <title> RSIC high speed massively parallel data compression hardware. </title> <type> Technical report, </type> <institution> RSIC Inc., 89 South Great Rd., Lincoln, </institution> <address> MA 01773, </address> <year> 1993. </year>
Reference-contexts: This implementation has been successfully tested at 16 MB/s compression rate. The authors note that while the decompression algorithm would fit on the DECPeRLe-1, it would require even more logic than the compressor and is likely to run more slowly (at about 4 MB/s). Storer <ref> [21] </ref> has implemented fast compression using a prototype systolic array using 30 custom CMOS chips. This algorithm runs at 20 MB/s and is accessed through a VME interface. IBMs ALDC compressor [13, 16] is available as a VHDL macro that may be inserted into 0.8m CMOS designs.
Reference: [22] <author> Xilinx, Inc. </author> <title> The programmable gate array data book. Product specification, </title> <publisher> Xilinx, Inc., </publisher> <address> 2100 Logic Drive, Santa Clara, California, 95124, </address> <year> 1992. </year>
Reference-contexts: Other types of scientific data may require application-specific compression algorithms. 4 Implementation We built the core of the CRAM using Xilinx Field Programmable Gate Arrays (FPGAs) <ref> [22] </ref> and used two additional FIFOs to buffer DMA bursts, four fast SRAMs 2. The raster data type used in the Sequoia benchmark is oversampled satellite data and is therefore significantly more compressible than may be realistic for most satellite data. FIGURE 9. The CRAM board.
Reference: [23] <author> Xilinx, Inc. </author> <title> Technical data: XC3100 logic cell array family. Product specification, </title> <publisher> Xilinx, Inc., </publisher> <address> 2100 Logic Drive, Santa Clara, California, 95124, </address> <year> 1992. </year>
Reference-contexts: The Wheeler hashing algorithm is extremely well suited for high-speed hardware implementation. Our Xilinx 3090-based implementation achieves good performance and new significantly faster FPGA implementations such as the Xilinx 3100 <ref> [23] </ref> series could enhance performance further. Throughputs of 50 MB/s or higher seem possible using an ASIC or VLSI implementation of this algorithm We are now preparing to use CRAM in systems studies to examine the use of on-line compression to increase I/O throughput.
References-found: 23

