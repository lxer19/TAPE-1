URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1994/tr-94-045.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1994.html
Root-URL: http://www.icsi.berkeley.edu
Title: Development of Parallel BLAS with ARCH Object-Oriented Parallel Library, Implementation on CM-5  
Phone: (510) 643-9153 FAX (510) 643-7684  
Author: J.M. Adamo 
Date: September 1994  
Address: I 1947 Center St. Suite 600 Berkeley, California 94704-1198  
Affiliation: INTERNATIONAL COMPUTER SCIENCE INSTITUTE  
Pubnum: TR-94-045  
Abstract: This paper reports on the developmemt of BLAS classes using the ARCH library. The BLAS library consists in two new SpreadMatrix and SpreadVector classes that are simply derived from the ARCH SpreadArray class. Their implementation essentially makes use of the ARCH remote read and write functions together with barrier-synchronization. They provide a good illustration of how ARCH can contribute to the development of loosely-synchronous systems. This paper describes the architecture of SpreadMatrix and SpreadVector classes and illustrates their use through the construction of a neural-network simulator. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.M. Adamo. </author> <title> Object-Oriented Parallel Programming: Library design and development for SPMD Programming. </title> <booktitle> Research-report, ICSI TR-94-011, </booktitle> <month> February </month> <year> 1994. </year>
Reference-contexts: 1 Introduction. The ARCH library is a general purpose object-oriented library that we have recently written to support the development of portable parallel applications. A description of ARCH can be found in <ref> [1] </ref>. ARCH is intended to offer the right set of specific programming facilities that are needed to develop parallel applications, no matter what the type of involved algorithms could be: synchronous, loosely synchronous, or asynchronous. The library has been written in C++. <p> A SpreadMatrices actually is a SpreadArray as defined in the ARCH library (see <ref> [1] </ref>). In the current version, I choose the simplest spreading policy that consists in block-decomposing the matrices over the processor grid so matrix-block i is held by processor i (logical numbering). <p> Giving global coordinates (v, h), the global function returns the global reference, over the nodes, to the corresponding SpreadArray element. A global reference consists of a processor number (logical numbering) and a pointer to a T-type data item in the processor local memory (see <ref> [1] </ref>, spread-arrays and pointers section). 3 template &lt; class T, int VSIZE, int HSIZE, int VPROCSIZE, int HPROCSIZE &gt; Lval &lt;S, T &gt; SpreadMatrix &lt; T, VSIZE, HSIZE, VPROCSIZE, HPROCSIZE &gt; ::operator ()(int v, int h) f return SpreadArray &lt; T &gt;::operator () (v%(VSIZE/VPROCSIZE), v/(VSIZE/VPROCSIZE), h/(HSIZE/HPROCSIZE), h%(HSIZE/HPROCSIZE)); g Giving local coordinates
Reference: [2] <author> J.M. Adamo, D. Anguita. </author> <title> Object-Oriented Design of a BP Neural Network Simulator and Implementation on the Connection Machine CM5. </title> <journal> Research-report, </journal> <note> to appear, </note> <year> 1994. </year>
Reference-contexts: Further details on the performances achieved by the neural-network simulator can be found in the companion paper <ref> [2] </ref>. Acknowledgments. I would like to thank Davide Anguita (University of Genova and ICSI) for his friendly collaboration. We shared the work of writing the neural-network simulator and he performed its assessement.
Reference: [3] <author> E. Anderson et al. </author> <note> LAPACK, Users' guide. </note> <institution> Society for Industrial and Applied Mathematics, </institution> <address> Philadelphia, </address> <year> 1992. </year>
Reference-contexts: in the neural-network simulator code (see Appendices 3-5). 2 DSpreadM atrix &lt; T; 512; 1024; 4; 8 &gt; SM 0; SpreadM atrix &lt; T; 128; 512; 4; 8 &gt; SM 1; SpreadM atrix &lt; T; 512; 256; 4; 8 &gt; SM 2; SpreadM atrices &lt; T; 4; 8 &gt; flSM <ref> [3] </ref>; 2.1.2 Spread matrices as spread arrays. A SpreadMatrices actually is a SpreadArray as defined in the ARCH library (see [1]).
Reference: [4] <author> W.W. Carlson, J.D. Schlesinger. </author> <title> AC: A C Language and compiler for the CM-5 Node Architecture. </title> <institution> SSuperComputing Researc Center, SRC-TR-93-094, </institution> <year> 1993. </year>
Reference-contexts: The current implementation has been written using the Nodal TMC's BLAS from the CMSSL library [12] and a few very low level functions that can be found in the CM5 CMRTS run-time library [13]. I could have instead used the AC compiler <ref> [4] </ref> which generates code that can be executed on the vector units. I preferred using CMSSL as I expected to get optimized code from there. 4 Writing a neural-network simulator. 4.1 Architecture. The BLAS classes described aboved have been used to develop a neural-net simulator (see Appendices 3-5).
Reference: [5] <author> J. Choi et al. </author> <title> ScaLAPACK: A Scalable Linear Algebra Library for Distributed Memory Concurrent Computers. </title> <institution> Oak Ridge National Laboratory, </institution> <year> 1992. </year>
Reference: [6] <author> J. Choi et al. PUMMA: </author> <title> Parallel Universal Matrix Multiplication Algorithms on Distributed Memory Concurrent Computers. </title> <institution> Oak Ridge National Laboratory, </institution> <month> May, </month> <year> 1993. </year> <month> 6 </month>
Reference-contexts: Depending on architectures, other spreading policies would, of course, be possible (and would lead to different implementations). For instance, the block-scattering policy as defined in <ref> [6] </ref> can be implemented as shown in [8].
Reference: [7] <author> J. Choi et al. </author> <title> PB-BLAS Reference Manual. </title> <institution> Oak Ridge National Laboratory, </institution> <month> March, </month> <year> 1994. </year>
Reference: [8] <author> D. Culler et al. </author> <title> Parallel Programming in Split-C. </title> <type> Technical Report U.C. </type> <institution> Berkeley, </institution> <year> 1993. </year>
Reference-contexts: Depending on architectures, other spreading policies would, of course, be possible (and would lead to different implementations). For instance, the block-scattering policy as defined in [6] can be implemented as shown in <ref> [8] </ref>. All this actually is hidden to the final user who is provided with suitable global/local access and input/output functions (see appendix 1-2). is encoded as a SpreadArray with three spread dimensions of size: 4, 2, 3 and one internal dimension of size: 3.
Reference: [9] <editor> J.J. Dongara et al. </editor> <title> LAPACK++: A Design and Overview of Object-Oriented Extensions for High Performance Linear Algebra. </title> <institution> Oak Ridge National Laboratory, </institution> <year> 1992. </year>
Reference-contexts: The presentation is completed by a set of appendices that give a clear idea of the whole design. Other works dealing with the development of Object-oriented BLAS libraries can be found in <ref> [9] </ref> and [10]. 2 Developing Object-oriented parallel BLAS with ARCH. 2.1 Spread matrices and vectors. 2.1.1 SpreadMatrix Definition. Spread matrices are defined by their type and the geometry of the set of processors which the matrices are spread over.
Reference: [10] <editor> J.J. Dongara et al. </editor> <title> An Object oriented Design for High Performance Linear Algebra on Distributed Memory Architectures. </title> <institution> Oak Ridge National Laboratory, </institution> <year> 1992. </year>
Reference-contexts: The presentation is completed by a set of appendices that give a clear idea of the whole design. Other works dealing with the development of Object-oriented BLAS libraries can be found in [9] and <ref> [10] </ref>. 2 Developing Object-oriented parallel BLAS with ARCH. 2.1 Spread matrices and vectors. 2.1.1 SpreadMatrix Definition. Spread matrices are defined by their type and the geometry of the set of processors which the matrices are spread over.
Reference: [11] <author> S.L. Johnsson, </author> <title> L.F. Ortiz. Local Basic Linear Algebra Subroutines (LBLAS) for distributed memory architectures and languages for array syntax. TMC, </title> <address> TR-226, </address> <year> 1992. </year>
Reference: [12] <author> Thinking Machine Corporation. </author> <title> CMSSL for CM Fortran: CM5 Edition. Volume I, </title> <booktitle> II, </booktitle> <month> January </month> <year> 1993. </year>
Reference-contexts: Indeed, reading and writing data to/from parallel memory would be too expensive as compared to the benefit we could expect by performing the functions there. The current implementation has been written using the Nodal TMC's BLAS from the CMSSL library <ref> [12] </ref> and a few very low level functions that can be found in the CM5 CMRTS run-time library [13]. I could have instead used the AC compiler [4] which generates code that can be executed on the vector units.
Reference: [13] <author> W.R. Swanson, K. Crouch. </author> <title> Connection Machine Run Time System (CMRTS), Architectural Specification, </title> <note> Version 7.2. TMC, </note> <month> March, </month> <year> 1993. </year>
Reference-contexts: The current implementation has been written using the Nodal TMC's BLAS from the CMSSL library [12] and a few very low level functions that can be found in the CM5 CMRTS run-time library <ref> [13] </ref>. I could have instead used the AC compiler [4] which generates code that can be executed on the vector units. I preferred using CMSSL as I expected to get optimized code from there. 4 Writing a neural-network simulator. 4.1 Architecture.
Reference: [14] <author> Thinking Machine Corporation. </author> <title> CM-5, VU Programmer's Handbook. Volume I, </title> <booktitle> II, </booktitle> <month> August </month> <year> 1993. </year>
References-found: 14

