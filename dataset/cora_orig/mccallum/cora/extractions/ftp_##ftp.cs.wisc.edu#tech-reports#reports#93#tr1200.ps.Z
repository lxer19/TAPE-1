URL: ftp://ftp.cs.wisc.edu/tech-reports/reports/93/tr1200.ps.Z
Refering-URL: http://www.cs.wisc.edu/~arch/uwarch/tech_reports/tech_reports.html
Root-URL: 
Title: Sufficient System Requirements for Supporting the PLpc Memory Model  
Author: Sarita V. Adve Kourosh Gharachorloo Anoop Gupta John L. Hennessy and Mark D. Hill 
Address: Madison, Wisconsin 53706  Stanford, CA 94305  
Affiliation: Computer Sciences Department University of Wisconsin  Computer System Laboratory Stanford University  
Abstract: University of Wisconsin-Madison Computer Sciences Technical Report #1200 Stanford University Technical Report CSL-TR-93-595 Abstract The paper, Programming for Different Memory Consistency Models [GAG + 92], defines the PLpc memory model. This companion note formalizes the system requirements for PLpc along with a proof that shows these requirements are sufficient for supporting this model. In addition, we prove the correctness of the conditions presented in the original paper [GAG + 92] for porting PLpc programs to the various hardware-centric models. The reader should be familiar with the material in the original paper on PLpc [GAG + 92] before reading this supplement.
Abstract-found: 1
Intro-found: 1
Reference: [Adv93] <author> Sarita V. Adve. </author> <title> Designing Memory Consistency Models for Shared-Memory Multiprocessors. </title> <type> PhD thesis, </type> <institution> Computer Sciences Technical Report #1198, University of Wisconsin - Madison, </institution> <month> December </month> <year> 1993. </year>
Reference: [AH90] <author> Sarita V. Adve and Mark D. Hill. </author> <title> Weak ordering Anew definition. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 2-14, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: However, to satisfy the PLpc model (which requires all executions of the program to be sequentially consistent), we need to disallow any execution in which either of the two write operations occurs. In most previous work, the conditions to disallow such executions are informal: "intraprocessor dependencies are preserved" <ref> [AH90] </ref> or "uniprocessor control and data dependences are respected" [GLL + 90]. Even though some proofs of correctness (e.g., proof of correctness for PL programs executing on the RCsc model [GLL + 90]) formalized certain aspects of this condition, the full condition was never presented in precise terms.
Reference: [AH92] <author> Sarita V. Adve and Mark D. Hill. </author> <title> Sufficient conditions for implementing the data-race-free-1 memory model. </title> <type> Technical Report #1107, </type> <institution> Computer Sciences, University of Wisconsin - Madison, </institution> <month> September </month> <year> 1992. </year>
Reference-contexts: Even though some proofs of correctness (e.g., proof of correctness for PL programs executing on the RCsc model [GLL + 90]) formalized certain aspects of this condition, the full condition was never presented in precise terms. The work by Adve and Hill in the context of the DRF1 model <ref> [AH92] </ref> specifies the condition more explicitly. In this paper, we have further formalized this condition and present a more aggressive form as part of specifying the sufficient conditions for PLpc. The full description of the reach relation ( rch !) is presented in Appendix B.
Reference: [AH93] <author> Sarita V. Adve and Mark D. Hill. </author> <title> A unified formalization of four shared-memory models. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(6) </volume> <pages> 613-624, </pages> <month> June </month> <year> 1993. </year>
Reference: [ASU86] <author> A. Aho, R. Sethi, and J. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference: [FOW87] <author> Jeanne Ferrante, Karl J. Ottenstein, and Joe D. Warren. </author> <title> The program dependence graph and its use in optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <month> July </month> <year> 1987. </year>
Reference: [GAG + 92] <author> Kourosh Gharachorloo, Sarita V. Adve, Anoop Gupta, John L. Hennessy, and Mark D. Hill. </author> <title> Programming for different memory consistency models. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 15(4) </volume> <pages> 399-407, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: 1 Introduction This is a supplementary note to the paper that defines the PLpc memory model <ref> [GAG + 92] </ref>. Section 2 provides a brief overview of the PLpc model along with the key definitions; a few definitions are changed slightly compared to the original versions to either address subtle correctness issues or to increase clarity. <p> Section 3 specifies the sufficient system requirements for supporting PLpc; this specification is based upon a general framework we have proposed for specifying system conditions for different memory models [GAG + 93]. Section 4 briefly describes the conditions presented in the PLpc paper <ref> [GAG + 92] </ref> for porting PLpc programs to hardware-centric models. Appendices A, B, and C provide extended forms for some of the conditions discussed in the paper. <p> Anoop Gupta is partly supported by a NSF Presidential Young Investigator Award. 1 2 The PLpc Model This section presents a brief overview of the relevant definitions for the PLpc model as they appear in the original paper on PLpc <ref> [GAG + 92] </ref>. We refer the reader to the original paper for the motivation, intuition, and full description of the PLpc model. Some of the definitions and conditions presented below are slightly different as compared to those in the original paper [GAG + 92]. (Some changes are made for clarity, while <p> as they appear in the original paper on PLpc <ref> [GAG + 92] </ref>. We refer the reader to the original paper for the motivation, intuition, and full description of the PLpc model. Some of the definitions and conditions presented below are slightly different as compared to those in the original paper [GAG + 92]. (Some changes are made for clarity, while others are for correctness or are restrictions on the original conditions because we were unable to do the proofs for the more aggressive conditions.) We begin by providing some terminology used in the PLpc framework [GAG + 92]. <p> those in the original paper <ref> [GAG + 92] </ref>. (Some changes are made for clarity, while others are for correctness or are restrictions on the original conditions because we were unable to do the proofs for the more aggressive conditions.) We begin by providing some terminology used in the PLpc framework [GAG + 92]. For every execution of a program, the program text defines a partial order, called program order ( po !), on the memory accesses of each process in the execution [SS88]. <p> As in the original definition, we assume that the unsuccessful reads of a synchronization loop construct do not contribute to the result of the program <ref> [GAG + 92] </ref>. Thus, we assume that if all accesses of a synchronization loop construct are replaced with only the last read or read-modify-write that exited the loop, we still get a SC execution with the same result as before. <p> (PLpc Programs) A program is properly labeled (PLpc) if (i) all accesses labeled non-competing L are non-competing and (ii) all accesses labeled loop L are either loop accesses or non-competing. 2 The third clause (iii) in the definition of loop read (Definition 2.4) is phrased differently in the original definition <ref> [GAG + 92] </ref>. It turns out that this makes a subtle semantic difference and we have changed the wording to correct this. <p> R that begins with co !, ends with po !, and consists of write-to-read co !'s only, then there should be an ordering chain from W to R that ends with a po 5 There is a minor omission in the second clause of Definition 2.6 in the original paper <ref> [GAG + 92] </ref>; the original definition did not say that non-competing accesses may be labeled loop L even though the description in the text mentioned this. 3 Definition 2.7: The PLpc Memory Model A system obeys the PLpc memory model if all executions of any PLpc program on the system are <p> implications of the above conditions on architecture and compiler optimizations, we refer the reader to the general discussion on implementations presented in the specification framework paper [GAG + 93]. 4 Porting PLpc Programs to Hardware-Centric Models This section briefly presents the conditions that were described in the original PLpc paper <ref> [GAG + 92] </ref> for correctly porting PLpc programs onto various hardware-centric models. Table 1 summarizes the mappings of accesses in a PLpc program to accesses recognized by the various hardware-centric models. <p> Table 1 summarizes the mappings of accesses in a PLpc program to accesses recognized by the various hardware-centric models. The proof of correctness for the porting conditions is provided in Appendix E. 7 As discussed in the original PLpc paper <ref> [GAG + 92] </ref>, the TSO, PSO, PC, and RCpc models do not provide a direct mechanism for imposing the program order between a non-loop write followed by a non-loop read (i.e., Wnl po ! Rnl). Thus, we impose the required order by employing read-modify-write (RMW) operations. <p> However, in some cases, the access has to actually be transformed into a RMW operation. The alternative is to augment the above models with direct mechanisms for obtaining the appropriate order <ref> [GAG + 92] </ref>. For TSO and PSO, we need a fence mechanism [GLL + 90] that delays future reads for previous writes. <p> Nevertheless, the sufficient conditions for PLpc in Figure 2 allow for a more aggressive implementation than any of the above hardware-centric systems. 5 Acknowledgements We would like to thank Allan Gottlieb for bringing to our attention an omission in Definition 6 in the original paper <ref> [GAG + 92] </ref> which is corrected in this note (Definition 2.6). We would also like to thank Michael Merritt whose comments led us to clarify the notion of competing in Definition 2 (Definition 2.2 in this note).
Reference: [GAG + 93] <author> Kourosh Gharachorloo, Sarita V. Adve, Anoop Gupta, John L. Hennessy, and Mark D. Hill. </author> <title> Specifying system requirements for memory consistency models. </title> <type> Technical Report CSL-TR-93-594, </type> <institution> Stanford University, </institution> <month> December </month> <year> 1993. </year> <note> Also available as Computer Sciences Technical Report #1199, </note> <institution> University of Wisconsin - Madison. </institution> <month> 8 </month>
Reference-contexts: Section 3 specifies the sufficient system requirements for supporting PLpc; this specification is based upon a general framework we have proposed for specifying system conditions for different memory models <ref> [GAG + 93] </ref>. Section 4 briefly describes the conditions presented in the PLpc paper [GAG + 92] for porting PLpc programs to hardware-centric models. Appendices A, B, and C provide extended forms for some of the conditions discussed in the paper. <p> These conditions are presented using a general formalism and framework that we have proposed for specifying system requirements for memory models <ref> [GAG + 93] </ref>. The first part of the section provides a brief background on the specification framework. We then proceed to present the specific conditions that satisfy PLpc. <p> Only the relevant terminology and definitions are provided below; we refer the reader to the paper that proposes this framework <ref> [GAG + 93] </ref> for a more detailed treatment (much of what follows is paraphrased from that paper). The specification methodology described below naturally exposes the architecture and compiler optimizations allowed by a memory model, thus leading to a relatively simple translation of the conditions into correct and efficient implementations. <p> Finally, a system correctly implements a memory model iff every execution allowed by the system is a valid execution. (The above correspond to Definitions 2, 3, and 4 in the specification framework paper <ref> [GAG + 93] </ref>.) 3.2 System Requirements for PLpc This section presents the system requirements for PLpc based on the specification framework [GAG + 93] discussed in the previous section. Figure 2 presents the sufficient system requirements for PLpc. We use the following notation. <p> implements a memory model iff every execution allowed by the system is a valid execution. (The above correspond to Definitions 2, 3, and 4 in the specification framework paper <ref> [GAG + 93] </ref>.) 3.2 System Requirements for PLpc This section presents the system requirements for PLpc based on the specification framework [GAG + 93] discussed in the previous section. Figure 2 presents the sufficient system requirements for PLpc. We use the following notation. Rc and Wc denote competing read and write memory operations, respectively, to shared writable locations. Rnl and Wnl are non-loop operations. <p> Rnl and Wnl are non-loop operations. R and W refer to any read or write operations (including, e.g., Rnl and Wnl) to shared writable locations. The relations used in the specification are as follows (the significance of these relations is discussed in <ref> [GAG + 93] </ref>). The spo sco ! relations capture the specific po co ! arcs that are used to define the sxo ! relation. In turn, the sxo ! relation captures certain po co ! orders that are used in the sxo ! condition to constrain the execution order. <p> Note that the sxo ! relation and condition impose orders among conflicting accesses only. This is in compliance with the philosophy of imposing as few constraints as possible in order to expose more optimizations <ref> [GAG + 93] </ref>. <p> To better understand the implications of the above conditions on architecture and compiler optimizations, we refer the reader to the general discussion on implementations presented in the specification framework paper <ref> [GAG + 93] </ref>. 4 Porting PLpc Programs to Hardware-Centric Models This section briefly presents the conditions that were described in the original PLpc paper [GAG + 92] for correctly porting PLpc programs onto various hardware-centric models.
Reference: [GLL + 90] <author> Kourosh Gharachorloo, Dan Lenoski, James Laudon, Phillip Gibbons, Anoop Gupta, and John Hen--nessy. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: In most previous work, the conditions to disallow such executions are informal: "intraprocessor dependencies are preserved" [AH90] or "uniprocessor control and data dependences are respected" <ref> [GLL + 90] </ref>. Even though some proofs of correctness (e.g., proof of correctness for PL programs executing on the RCsc model [GLL + 90]) formalized certain aspects of this condition, the full condition was never presented in precise terms. <p> In most previous work, the conditions to disallow such executions are informal: "intraprocessor dependencies are preserved" [AH90] or "uniprocessor control and data dependences are respected" <ref> [GLL + 90] </ref>. Even though some proofs of correctness (e.g., proof of correctness for PL programs executing on the RCsc model [GLL + 90]) formalized certain aspects of this condition, the full condition was never presented in precise terms. The work by Adve and Hill in the context of the DRF1 model [AH92] specifies the condition more explicitly. <p> However, in some cases, the access has to actually be transformed into a RMW operation. The alternative is to augment the above models with direct mechanisms for obtaining the appropriate order [GAG + 92]. For TSO and PSO, we need a fence mechanism <ref> [GLL + 90] </ref> that delays future reads for previous writes. Then, the alternative mapping for TSO and PSO is to place such a fence between any pair of Wnl po ! Rnl (for PSO, Wc still needs to be preceded by a STBAR as before).
Reference: [Lam79] <author> Leslie Lamport. </author> <title> How to make a multiprocessor computer that correctly executes multiprocess programs. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-28(9):690-691, </volume> <month> September </month> <year> 1979. </year>
Reference: [SS88] <author> Dennis Shasha and Marc Snir. </author> <title> Efficient and correct execution of parallel programs that share memory. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 10(2) </volume> <pages> 282-312, </pages> <month> April </month> <year> 1988. </year> <month> 9 </month>
Reference-contexts: For every execution of a program, the program text defines a partial order, called program order ( po !), on the memory accesses of each process in the execution <ref> [SS88] </ref>. <p> Two accesses are considered conflicting if they are to the same location and at least one of them is a write <ref> [SS88] </ref>. Definitions 2.1 and 2.2 below define an ordering chain and the notion of competing and non-competing accesses.
References-found: 11

