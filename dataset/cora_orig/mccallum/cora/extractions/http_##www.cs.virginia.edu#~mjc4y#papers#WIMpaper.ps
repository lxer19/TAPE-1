URL: http://www.cs.virginia.edu/~mjc4y/papers/WIMpaper.ps
Refering-URL: http://www.cs.virginia.edu/~mjc4y/publications.html
Root-URL: http://www.cs.virginia.edu
Email: pausch-@uvacs.cs.virginia.edu  
Title: Virtual Reality on a WIM: Interactive Worlds in Miniature user observation indicates that users adapt
Author: Richard Stoakley, Matthew J. Conway, Randy Pausch 
Keyword: virtual reality, three-dimensional interaction, two-handed interaction, information visualization  
Note: (804) 982-2200  Informal  
Address: Charlottesville, VA 22903 -rws2v conway  
Affiliation: The University of Virginia Department of Computer Science  
Abstract: This paper explores a user interface technique which augments an immersive head tracked display with a handheld miniature copy of the virtual environment. We call this interface technique the Worlds in Miniature (WIM) metaphor. By establishing a direct relationship between life-size objects in the virtual world and miniature objects in the WIM, we can use the WIM as a tool for manipulating objects in the virtual environment. In addition to describing object manipulation, this paper explores ways in which Worlds in Miniature can act as a single unifying metaphor for such application independent interaction techniques as object selection, navigation, path planning, and visualization. The WIM metaphor naturally offers multiple points of view and multiple scales at which the user can operate, all without requiring explicit modes or commands. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Eric A. Bier, Maureen C. Stone, Ken Pier , William Buxton, Tony D. DeRose. Toolglass and Magic Lenses: </author> <title> The See-Through Interface. </title> <booktitle> Proceedings of Computer Graphics, </booktitle> <pages> pages 73-80, </pages> <year> 1993. </year>
Reference-contexts: Here, the WIM acts more like a three dimensional version of Beir s magic lenses <ref> [1] </ref> or one of Fitzmaurices active maps [10]. Three Dimensional Design: the WIM, being a small three dimensional model, serves the same functions that architectural models have traditionally served.
Reference: [2] <author> Jeff Butterworth, Andrew Davidson, Stephen Hench, Marc Olano. 3DM: </author> <title> A Three Dimensional Modeler Using a Head-Mounted Display. </title> <booktitle> In Proceedings of Symposium on Interactive 3D Graphics, </booktitle> <pages> pages 135-138, </pages> <year> 1992. </year>
Reference-contexts: This work is also three dimensional but non-immersive and directly manipulates an object at 1:1 scale in a f ishtank paradigm. 3DM <ref> [2] </ref> was an immersive three dimensional drawing package, but provided only one point of view at a time and required the user to change scale or y explicitly to manipulate objects which were currently out of arm s reach. But-terworth states that users sometimes found the scaling disorienting.
Reference: [3] <author> Richard A. </author> <title> Bolt. </title> <booktitle> PutThat-There. ACM SIGGRAPH 80 Proceedings. pp262-270. </booktitle> <volume> Vol 14, No. 3. </volume> <month> July </month> <year> 1980. </year>
Reference-contexts: Common approaches include raycasting [10] [23] and selection cones [15]. Both of these techniques suffer from object occlusion and therefore need to be tied closely with some mechanism that can quickly establish different points of view. PutThat-There <ref> [3] </ref> used selection via a combination of pointing and naming (or description). Pointing in this two dimensional application is analogous to raycasting in virtual environments.
Reference: [4] <author> Frederick P. Brooks. </author> <title> Grasping Reality Through Illusion: Interactive Graphics Serving Science. </title> <booktitle> In Proceedings of the 1988 ACM SIGCHI Human Factors in Computer Systems Conference. </booktitle> <address> Washington, D.C. </address> <pages> pp 1-11. </pages>
Reference: [5] <author> Robert C. Zeleznik, Kenneth P. Herndon, Daniel C. Robbins, Nate Huang, Tom Meyer, Noah Parker, John F. Hughes. </author> <title> An Interactive 3D Toolkit for Constructing 3D Widgets. </title> <booktitle> Proceedings of Computer Graphics, </booktitle> <pages> pages 81-84, </pages> <year> 1993. </year>
Reference-contexts: Thus the user can manipulate the objects in the WIM and the objects in the world will follow (video f igure 1 - The WIM Interface). The environment itself (in miniature) becomes its own widget for manipulating objects in the environment <ref> [5] </ref>. Software and Equipment The Kit of Parts modeler was implemented using the Alice Rapid Prototyping System [6] running the simulation on a Sun Microsystems Sparc 10 and rendering on a Silicon Graphics Onyx Reality Engine 2.
Reference: [6] <author> Robert DeLine. </author> <type> Masters Thesis. </type> <month> Alice: </month> <title> A Rapid Pro-totyping System for Three-Dimensional Interactive Graphical Environments. </title> <institution> University of Virginia, </institution> <month> May, </month> <year> 1993. </year>
Reference-contexts: The environment itself (in miniature) becomes its own widget for manipulating objects in the environment [5]. Software and Equipment The Kit of Parts modeler was implemented using the Alice Rapid Prototyping System <ref> [6] </ref> running the simulation on a Sun Microsystems Sparc 10 and rendering on a Silicon Graphics Onyx Reality Engine 2. Typical rendering rates were about 25 frames per second ( FPS), while simulation rates were typically 6 FPS. <p> The buttonball and clipboard each carried a Polhemus tracker sensor for posi tion and orientation information. clipboard and buttonball props. INTERACTION TECHNIQUES USING THE WIM In this section, we discuss basic application independent WIM-based interaction techniques we have built using the Alice Rapid Prototyping System <ref> [6] </ref>. Quickly Changing the POV Being able to see objects from many different angles allows us to quickly remove or reduce occlusion and improves the sense of the three-dimensional space it occupies [22].
Reference: [7] <author> Rudy Darken, John Sibert. </author> <title> A Toolset for Navigation in Virtual Environments. </title> <booktitle> In proceedings of UIST93, </booktitle> <pages> pages 157-165, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: He found this surface invaluable in constraining the user s input to a plane. The scene was not immersive and the system only displayed one scale view at a time. Previous Work in Navigation Darkens <ref> [7] </ref> discussion of navigating virtual environments enumerates many important techniques and compares their relative strengths and weaknesses. Several of the navigation techniques presented were WIM-like maps, but were primarily two-dimensional in nature. Through the WIM interface, some of these techniques have been extended into the third dimension.
Reference: [8] <author> Steven Feiner, Clifford Beshers. </author> <title> Visualizing n-Dimensional Virtual Worlds with n-vision. </title> <booktitle> Symposium on Interactive 3D Graphics, </booktitle> <pages> pages 37-38, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: Multiple WIMs enable users to multiplex their attention much the same way Window Managers allow this in 2D. These multiple views into the virtual world, allow the user to visually compare different scales and/or different locations <ref> [8] </ref>. MANIPULATING THE WIM Through the exploration of the previous interfaces, several issues arose concerning the interface between the human and the WIM tool.
Reference: [9] <author> Scott Fisher. </author> <title> The AMES Virtual Environment Workstation (VIEW). </title> <booktitle> SIGGRAPH 89 Course #29 Notes. </booktitle> <month> August, </month> <year> 1989. </year>
Reference-contexts: He found this scene in hand metaphor particularly good for quickly viewing the bounding-cube edges of a scene. The scene in hand task was a unimanual operation which employed ratcheting to perform large rotations. The work most closely resembling the WIM interface was Fishers map cube in virtual reality <ref> [9] </ref>. The NASA VIEW system used a three dimensional miniature map of the immersive world to help navigate. In addition, it used multiple two dimensional viewports to jump from one place in the virtual environment to another. A user s manipulation of the map cube was unimanual. <p> A logical extension of this notion is that these snapshots can act as jump points to different spaces or times, much the same way hypertext systems sometimes have thumbnail pictures of previously visited documents [14]. Selecting a WIM would cause the immersive environment to change to that particular world <ref> [9] </ref>. Multiple WIMs enable users to multiplex their attention much the same way Window Managers allow this in 2D. These multiple views into the virtual world, allow the user to visually compare different scales and/or different locations [8].
Reference: [10] <author> George Fitzmaurice. </author> <title> Situated Information Spaces and Spatially Aware. </title> <journal> Communications of the ACM, </journal> <pages> pages 39-49, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: A user s manipulation of the map cube was unimanual. A similar map-cube concept was referred to as the God seye-view in the super cockpit project [11]. Previous Work in Object Selection Many researchers have explored methods for selecting objects in a virtual world. Common approaches include raycasting <ref> [10] </ref> [23] and selection cones [15]. Both of these techniques suffer from object occlusion and therefore need to be tied closely with some mechanism that can quickly establish different points of view. PutThat-There [3] used selection via a combination of pointing and naming (or description). <p> Here, the WIM acts more like a three dimensional version of Beir s magic lenses [1] or one of Fitzmaurices active maps <ref> [10] </ref>. Three Dimensional Design: the WIM, being a small three dimensional model, serves the same functions that architectural models have traditionally served.
Reference: [11] <author> Dr. Thomas A. Furness, III. </author> <title> The Super Cockpit and Human Factors Challenges. </title> <institution> Human Interface Technology (HIT) Laboratory of the Washington Technology Center, </institution> <month> September </month> <year> 1986 </year>
Reference-contexts: In addition, it used multiple two dimensional viewports to jump from one place in the virtual environment to another. A user s manipulation of the map cube was unimanual. A similar map-cube concept was referred to as the God seye-view in the super cockpit project <ref> [11] </ref>. Previous Work in Object Selection Many researchers have explored methods for selecting objects in a virtual world. Common approaches include raycasting [10] [23] and selection cones [15].
Reference: [12] <author> Yves Guiard. </author> <title> Asymmetric Division of Labor in Human Skilled Bimanual Action: The Kinematic Chain as a Model. The Journal of Motor Behavior , pages 486-517, </title> <year> 1987. </year>
Reference-contexts: The input props controlled the point of view by rotating the objects base plane. Hinkleys [13] work with props exploited the asymmetric use of hands, which follows from work by Guiard <ref> [12] </ref>. This work showed how a prop in the nondominant hand can be used to specify a coordinate system with gross orientation, while the user s preferred hand can be used for fine grain positioning relative to that coordinate system. <p> The most important of these results state that a human s dominant (preferred) hand makes its motions relative to the coordinate system specified by the nondominant hand, and the preferred hand s motion is generally at a f iner grain <ref> [12] </ref>. In our case, the nondominant hand establishes a coordinate system with the clipboard and the dominant hand performs f ine grained picking and manipulation operations.
Reference: [13] <author> Ken Hinckley, Randy Pausch, John C. Goble, Neal F. Kassell. </author> <title> Passive Real-World Interface Props for Neu-rosurgical Visualization. </title> <booktitle> In Proceedings of SIGCHI, </booktitle> <month> pages , October </month> <year> 1993. </year>
Reference-contexts: The input props controlled the point of view by rotating the objects base plane. Hinkleys <ref> [13] </ref> work with props exploited the asymmetric use of hands, which follows from work by Guiard [12].
Reference: [14] <institution> Apple Computer, </institution> <month> Inc.. </month> <title> Hyperscript Language Guide: The Hypertalk Language. </title> <publisher> Addison-Wesley 1988. </publisher>
Reference-contexts: A logical extension of this notion is that these snapshots can act as jump points to different spaces or times, much the same way hypertext systems sometimes have thumbnail pictures of previously visited documents <ref> [14] </ref>. Selecting a WIM would cause the immersive environment to change to that particular world [9]. Multiple WIMs enable users to multiplex their attention much the same way Window Managers allow this in 2D. <p> User Reactions We observed users in order to see how viable a solution the WIM interface was to several types of tasks. While it was not our intention for the study to produce concrete numbers, we were after what Brooks refers to as interesting Observations <ref> [14] </ref>.
Reference: [15] <author> Jiandong Liang, Mark Green. JDCAD: </author> <booktitle> A Highly Interactive 3D Modeling System . In 3rd International Conference on CAD, </booktitle> <pages> pages 217-222, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: A similar map-cube concept was referred to as the God seye-view in the super cockpit project [11]. Previous Work in Object Selection Many researchers have explored methods for selecting objects in a virtual world. Common approaches include raycasting [10] [23] and selection cones <ref> [15] </ref>. Both of these techniques suffer from object occlusion and therefore need to be tied closely with some mechanism that can quickly establish different points of view. PutThat-There [3] used selection via a combination of pointing and naming (or description). <p> For example: the user can reach into the WIM to select a distant object (taking advantage of the greater than 1:1 scale of the WIM), and then reach out to the immersive world to move the WIM-selected object at a distance in 1:1: scale [23] <ref> [15] </ref> all the while viewing the scene in the WIM. Rotation Our current implementation allows users to rotate objects, through ratcheting (repeated grabbing, rotating and releasing) [25] and is therefore more awkward than a rotation done with just the fingers [15]. <p> the WIM-selected object at a distance in 1:1: scale [23] <ref> [15] </ref> all the while viewing the scene in the WIM. Rotation Our current implementation allows users to rotate objects, through ratcheting (repeated grabbing, rotating and releasing) [25] and is therefore more awkward than a rotation done with just the fingers [15]. Interestingly, some users found it just as ef fective to grab the object and to counter - rotate the entire WIM. In our current implementation, rotation is gridded to 30 degree increments, primarily to assist in aligning rectilinear objects [15]. <p> more awkward than a rotation done with just the fingers <ref> [15] </ref>. Interestingly, some users found it just as ef fective to grab the object and to counter - rotate the entire WIM. In our current implementation, rotation is gridded to 30 degree increments, primarily to assist in aligning rectilinear objects [15]. We found that if the rotation grid is too course (greater than about 45 degrees), some people assume that they cannot rotate at all and if set to 15 degrees or less, users report that rotation behaves as if it had no gridded increments at all. <p> This animated movement helps maintain visual continuity <ref> [15] </ref>. Another useful form of update delay is batch update. Here, the user makes several changes to the WIM and then issues an explicit command (e.g. pressing the second button on the buttonball) to cause the immersive environment to commit to the current layout of the WIM.
Reference: [16] <author> John Lassiter. </author> <title> Principles of Traditional Animation Applied to 3D Computer Animation. </title> <booktitle> Computer Graphics 21, </booktitle> <pages> pages 35-44, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: We find that immediate update of the camera while the user is manipulating the camera proxy is highly disorienting, so instead we wait until the user has stopped moving the camera, and then use a smooth slow in / slow out animation <ref> [16] </ref> to move the camera to its new position. This animated movement helps maintain visual continuity [15]. Another useful form of update delay is batch update.
Reference: [17] <author> Donald Norman. </author> <title> The Design of Everyday Things . Doubleday. </title> <year> 1988. </year>
Reference-contexts: Shape of Props Like all real world artifacts, the shape of the props and the users experience suggest things about the usage of the props <ref> [17] </ref>. For example, the shape of the clipboard says something to users about its preferred orientation.
Reference: [18] <author> Randy Pausch, M. Anne Shackelford, </author> <note> Dennis Proffitt. </note>
Reference-contexts: INTRODUCTION Many benefits have been claimed formally and informally for using immersive three dimensional displays. While virtual reality technology has the potential to give the user a better understanding of the space he or she inhabits, and can improve performance in some tasks <ref> [18] </ref>, it can easily present a virtual world to the user that is just as confusing, limiting and ambiguous as the real world.
References-found: 18

