URL: ftp://ftp.cs.man.ac.uk/pub/robotics/iav.ps.Z
Refering-URL: http://www.cs.man.ac.uk/robotics/lopapers.html
Root-URL: 
Email: pmartin@cs.man.ac.uk u.nehmzow@cs.man.ac.uk  
Title: "PROGRAMMING" BY TEACHING: NEURAL NETWORK CONTROL IN THE MANCHESTER MOBILE ROBOT  
Author: Paul Martin and Ulrich Nehmzow 
Keyword: Mobile robots, neural networks, machine learning, vision, image process ing, sensor fusion.  
Address: Manchester M13 9PL United Kingdom  
Affiliation: Department of Computer Science Manchester University  
Abstract: The paper presents experiments conducted with the Manchester mobile robot FortyTwo on the application of reinforcement learning to robot control. An artificial neural network, forming the core component of the controller presented here, associates incoming sensor signals with corresponding motor actions. Teaching the network is achieved by initially operating the robot under human control (i.e. the robot's behaviour is the result of training, not programming). The observed actions are used to train the robot's associative memory, and after a very short training time FortyTwo becomes able to perform the required task autonomously. Experiments are presented in which data from sonar, infrared or vision sensors is associated with motor actions; and a suitable vision preprocessing system is discussed. 
Abstract-found: 1
Intro-found: 1
Reference: [ -Astrom 89] <author> Karl Johan -Astrom, </author> <title> Toward Intelligent Control, </title> <journal> IEEE Control Systems Magazine, </journal> <month> April </month> <year> 1989. </year>
Reference: [Barto 89] <author> A. Barto, </author> <title> Connectionist Learning for Control: An Overview, </title> <institution> Department of Computer and Information Science, University of Massachusetts at Amherst, </institution> <type> COINS technical report 89-89. </type>
Reference: [Campbell & Robson 68] <author> F.W.C. Campbell and J. Robson, </author> <title> Application of Fourier analysis to the visibility of gratings, </title> <editor> J. Physiol. </editor> <address> (London) 197, </address> <note> 551-566. </note> <author> [Dickmanns & Graefe 88] Ernst Dieter Dickmanns and Volker Graefe, </author> <title> Dynamic monocular machine vision, </title> <institution> Universitat der Bundeswehr Munchen, </institution> <note> Technical Report UniBwM/LRT/WE 13/FB/88-3. </note>
Reference: [Kosaka & Kak 92] <author> Akio Kosaka and Avinash Kak, </author> <title> Fast Vision-Guided Mobile Robot Navigation Using Model-Based Reasoning and Prediction of Uncertainties, CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> Vol 56 No. 3, </volume> <pages> pp. 271-329, </pages> <year> 1992. </year>
Reference: [Kaelbling 91] <author> Leslie Kaelbling, </author> <title> An Adaptable Mobile Robot, </title> <editor> in F. Varela and P. Bourgine, </editor> <title> Toward a practice of autonomous systems, </title> <publisher> MIT Press 1992. </publisher>
Reference-contexts: Contrary to reinforcement learning architectures enabling autonomous competence acquisition (for example <ref> [Mahadevan & Connell 91, Kaelbling 91, Nehmzow 92] </ref>) learning here is supervised by a human operator, an aspect that can be relevant re garding safety aspects of industrial applications. 1 FortyTwo 2 THE ROBOT FortyTwo (see figure 1), a Nomad 200 mobile robot, is fully autonomous and operates independently from any
Reference: [Mahadevan & Connell 91] <author> Sridhar Mahadevan and Jonathan Connell, </author> <title> Automatic Programming of Behavior-Based Robots using Reinforcement Learning, </title> <booktitle> AAAI 1991. </booktitle>
Reference-contexts: Contrary to reinforcement learning architectures enabling autonomous competence acquisition (for example <ref> [Mahadevan & Connell 91, Kaelbling 91, Nehmzow 92] </ref>) learning here is supervised by a human operator, an aspect that can be relevant re garding safety aspects of industrial applications. 1 FortyTwo 2 THE ROBOT FortyTwo (see figure 1), a Nomad 200 mobile robot, is fully autonomous and operates independently from any
Reference: [Marr & Hildreth 80] <author> D. Marr and E. Hildreth, </author> <title> Theory of edge detection, </title> <journal> Proc. R. Soc. Lond. </journal> <volume> B 207, </volume> <pages> 187-217 (after [Marr 82]). </pages>
Reference: [Marr 82] <author> David Marr, </author> <title> Vision, W.H. </title> <publisher> Freeman and Company, </publisher> <address> San Francisco 1982. </address>
Reference-contexts: The optical flow, i.e. the movement of pixels resulting from robot motion, can be used to compute distance to an object provided the correspondence problem (identifying the pixel belonging to the same object in subsequent frames) is solved (see, for instance, <ref> [Marr 82, p.212ff] </ref>). This, however, is difficult, particularly if the environment the robot is operating in is (partially) unknown. As a vision preprocessing system, generating sensor information for the artificial neural network used in the controller, however, optical flow can be used without having solved the correspondence problem.
Reference: [Nehmzow 92] <author> Ulrich Nehmzow, </author> <title> Experiments in Competence Acquisition for Autonomous Mobile Robots, </title> <type> PhD thesis, </type> <institution> University of Edin-burgh 1992. </institution>
Reference-contexts: Contrary to reinforcement learning architectures enabling autonomous competence acquisition (for example <ref> [Mahadevan & Connell 91, Kaelbling 91, Nehmzow 92] </ref>) learning here is supervised by a human operator, an aspect that can be relevant re garding safety aspects of industrial applications. 1 FortyTwo 2 THE ROBOT FortyTwo (see figure 1), a Nomad 200 mobile robot, is fully autonomous and operates independently from any
Reference: [Nehmzow 94] <author> U. Nehmzow, </author> <title> Acquisi--tion of Smooth, Continuous Obstacle Avoidance in Mobile Robots, </title> <editor> in H. Cruse, H. Ritter and J. Dean (eds.). </editor> <booktitle> Proc. Workshop "Prerational Intelligence in Robotics", </booktitle> <institution> ZIF, University of Biele-feld, </institution> <year> 1994. </year>
Reference-contexts: The resulting obstacle avoidance motion is smooth, and incorporates translational and rotational movements at varying speeds, according to the strength of association between sensory perception and corresponding motor action (see also <ref> [Nehmzow 94] </ref>). 4.3 Wall Following In the same manner as before, the robot was trained to stay within a distance of about 50 cm to the wall.
Reference: [Nehmzow 95] <author> U. Nehmzow, </author> <title> Flexible Control of Mobile Robots through Autonomous Competence Acquisition, </title> <journal> Trans. Institute for Measurement and Control (IMC), </journal> <volume> 3/1995. </volume>
Reference: [Sutton 91] <author> R. Sutton, </author> <title> Reinforcement Learning Architectures for Animats, </title> <editor> in J.A. Meyer and S. Wilson (eds), </editor> <booktitle> From Animals to Animats, </booktitle> <publisher> MIT Press 1991. </publisher>
References-found: 12

