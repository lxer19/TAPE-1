URL: http://www.isle.org/~langley/papers/invite97.ps
Refering-URL: http://www-csli.stanford.edu/cll/research.html
Root-URL: 
Email: (Langley@cs.stanford.edu)  
Title: Machine Learning for Intelligent Systems  
Author: Pat Langley 
Address: 1510 Page Mill Road, Palo Alto, CA 94304  
Affiliation: Intelligent Systems Laboratory Daimler-Benz Research Technology Center  
Note: From Proceedings of the Fourteenth National Conference on Artificial Intelligence (1997). Providence, RI: AAAI Press.  
Abstract: Recent research in machine learning has focused on supervised induction for simple classification and reinforcement learning for simple reactive behaviors. In the process, the field has become disconnected from AI's original goal of creating complete intelligent agents. In this paper, I review recent work on machine learning for planning, language, vision, and other topics that runs counter to this trend and thus holds interest for the broader AI research community. I also suggest some steps to encourage further research along these lines. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bowyer, K. W., Hall, L. O., Langley, P., Bhanu, B., & Draper, B. A. </author> <year> (1994). </year> <booktitle> Report of the AAAI Fall Symposium on Machine Learning and Computer Vision: What, Why and How. Proceedings of the Image Understanding Workshop (pp. </booktitle> <pages> 727-731). </pages> <address> Monterrey, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Day, D. </author> <year> (1992). </year> <title> Acquiring search heuristics automatically for constraint-based planning and scheduling. </title> <booktitle> Proceedings of the First International Conference on AI Planning Systems (pp. </booktitle> <pages> 45-51). </pages> <address> College Park, MD: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Draper, B. </author> <year> (1993). </year> <title> Learning from the schema learning system. </title> <booktitle> Working Notes of the AAAI Fall Symposium on Machine Learning in Computer Vision (pp. </booktitle> <pages> 75-79). </pages> <address> Raleigh, NC: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Draper, B. </author> <year> (1996). </year> <title> Learning grouping strategies for 2D and 3D object recognition. </title> <booktitle> Proceedings of the Image Understanding Workshop (pp. </booktitle> <pages> 1447-1454). </pages> <address> Palm Springs, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Eskey, M., & Zweben, M. </author> <year> (1990). </year> <title> Learning search control for constraint-based scheduling. </title> <booktitle> Proceedings of the Eighth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 908-915). </pages> <address> Boston: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Grefenstette, J. J. </author> <year> (1988). </year> <title> Credit assignment in rule discovery systems based on genetic algorithms. </title> <booktitle> Machine Learning, </booktitle> <pages> 3 , 225-245. </pages>
Reference: <author> Grefenstette, J. J., Ramsey, C. L., & Schultz, A. C. </author> <year> (1990). </year> <title> Learning sequential decision rules using simulation models and competition. </title> <booktitle> Machine Learning, </booktitle> <pages> 5 , 355-381. </pages>
Reference: <author> Grefenstette, J. J., & Schultz, A. </author> <year> (1994). </year> <title> An evolutionary approach to learning in robots. </title> <booktitle> Proceedings of the Machine Learning Workshop on Robot Learning. </booktitle> <address> New Brunswick, NJ. </address>
Reference: <author> Hermens, L. A., & Schlimmer, J. C. </author> <year> (1994). </year> <title> A machine-learning apprentice for the completion of repetitive forms. </title> <journal> IEEE Expert , 9 , 28-33. </journal>
Reference: <author> Hennessy, D., & Hinkle, D. </author> <year> (1992). </year> <title> Applying case-based reasoning to autoclave loading. </title> <journal> IEEE Expert, </journal> <volume> 7 , October, </volume> <pages> 21-26. </pages>
Reference: <author> Iba, G. A. </author> <year> (1989). </year> <title> A heuristic approach to the discovery of macro-operators. </title> <booktitle> Machine Learning, </booktitle> <pages> 3 , 285-317. </pages>
Reference: <author> Kambhampati, S., Ihrig, I., & Srivastava, B. </author> <year> (1996). </year> <title> A candidate set based analysis of subgoal interaction in conjunctive goal planning. </title> <booktitle> Proceedings of the Third International Conference on AI Planning Systems (pp. </booktitle> <pages> 125-133). </pages> <publisher> Edinburgh: Morgan Kaufmann. </publisher>
Reference: <author> Laird, J. E., Rosenbloom, P. S., & Newell, A. </author> <year> (1986). </year> <title> Chunking in Soar: The anatomy of a general learning mechanism. </title> <booktitle> Machine Learning, </booktitle> <pages> 1 , 11-46. </pages>
Reference-contexts: Yet some forms of 3 Laird, Pearson, and Huffman (1995) report a rare example of such work, in which they examine learning at the reactive, deliberate, and reflective levels in a simulated physical agent. 4 Research on chunk creation within the Soar framework <ref> (Laird, Rosenbloom, & Newell, 1986) </ref> is still active, but their use of `chunk' differs from the standard sense in psychology. human learning and discovery instead involve increased understanding of single observations or events.
Reference: <author> Laird, J. E., Pearson, D. J., & Huffman, S. B. </author> <year> (1996). </year> <title> Knowledge-directed adaptation in multi-level agents. </title> <booktitle> Proceedings of the AAAI Workshop on Intelligent Adaptive Agents. </booktitle> <address> Portland: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Langley, P. </author> <year> (1995). </year> <title> Elements of machine learning. </title> <address> San Francisco: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In fact, much of the 1980's excitement about `expert systems' has now been replaced by excitement about `advisory systems', which seem especially appropriate for many tasks that arise on the World Wide Web. As we have noted elsewhere <ref> (Langley & Simon, 1995) </ref>, such advisory systems provide ideal environments for learning, since each decision by the user to accept or override a system recommendation generates a training case that it can use to improve future behavior.
Reference: <author> Langley, P., & Simon, H. A. </author> <year> (1981). </year> <title> The central role of learning in cognition. </title> <editor> In J. R. Anderson (Ed.), </editor> <title> Cognitive skills and their acquisition. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum. </publisher>
Reference-contexts: Although there have been some exceptions to this tendency, most AI research now bears little resemblance to the original vision for the field. In this paper, we focus on one area machine learning that exemplifies this trend. Many have argued <ref> (e.g., Langley & Simon, 1981) </ref> that learning has a central role to play in intelligent behavior, and these are fl Also affiliated with Institute for the Study of Learning and Expertise, 2164 Staunton Court, Palo Alto, CA 94306. arguments are no less valid today than in AI's earlier days.
Reference: <author> Langley, P., & Simon, H. A. </author> <year> (1995). </year> <title> Applications of machine learning and rule induction. </title> <journal> Communications of the ACM , 38 , November, </journal> <pages> 55-64. </pages>
Reference-contexts: In fact, much of the 1980's excitement about `expert systems' has now been replaced by excitement about `advisory systems', which seem especially appropriate for many tasks that arise on the World Wide Web. As we have noted elsewhere <ref> (Langley & Simon, 1995) </ref>, such advisory systems provide ideal environments for learning, since each decision by the user to accept or override a system recommendation generates a training case that it can use to improve future behavior.
Reference: <author> Miller, G. A. </author> <year> (1956). </year> <title> The magical number seven, plus or minus two. </title> <type> Psychological Review , 63 , 81-97. </type>
Reference-contexts: The cognitive psychology literature suggests one key: expert performance almost always shadows expert memory, which is typically explained through the acquisition of chunks <ref> (Miller, 1956) </ref>. Theoretically, chunks are hierarchical structures made up from other chunks that, ultimately, are grounded in primitive percepts or actions.
Reference: <author> Minton, S. (Ed.). </author> <year> (1993). </year> <title> Machine learning methods for planning. </title> <address> San Francisco, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Minton, S. </author> <year> (1996). </year> <title> Automatically configuring constraint satisfaction programs: A case study. </title> <booktitle> Constraints, </booktitle> <pages> 1 , 7-43. </pages>
Reference: <author> Moore, A. W. </author> <year> (1990). </year> <title> Acquisition of dynamic control knowledge for a robot manipulator. </title> <booktitle> Proceedings of the Seventh International Conference on Machine Learning (pp. </booktitle> <pages> 244-252). </pages> <address> Austin: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Within machine learning, some researchers have made progress on ac quiring models for robot actions, but often by transforming this task into a one-step regression problem <ref> (e.g., Moore, 1990) </ref>. Reinforcement learning claims to address the acquisition of action strategies, but most work on that topic has dealt with learning discrete actions in `grid worlds', with little evidence that it generalizes to more realistic domains (e.g., Sutton, 1988).
Reference: <author> Pierce, D., & Kuipers, B. </author> <year> (1994). </year> <title> Learning to explore and build maps. </title> <booktitle> Proceedings of the Twelfth National Machine Learning for Intelligent Systems 769 Conference on Artificial Intelligence (pp. </booktitle> <pages> 1264-1271). </pages> <address> Seattle: </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Machine Learning for Physical Control An intelligent agent must do more than perceive its surroundings and plan its actions; it must also execute those actions in the world. Although there has been some learning work within the robotics community, this has focused mainly on constructing maps from sensor data <ref> (e.g., Pierce & Kuipers, 1994) </ref>. Within machine learning, some researchers have made progress on ac quiring models for robot actions, but often by transforming this task into a one-step regression problem (e.g., Moore, 1990).
Reference: <author> Reich, Y., & Fenves, S. J. </author> <year> (1991). </year> <title> The formation and use of abstract concepts in design. </title> <editor> In D. H. Fisher, M. J. Pazzani, & P. Langley (Eds.), </editor> <title> Concept formation: Knowledge and experience in unsupervised learning. </title> <address> San Francisco, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Schlimmer, J. C. </author> <year> (1991). </year> <title> Learning meta knowledge for database checking. </title> <booktitle> Proceedings of the Tenth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 335-340). </pages> <address> Anaheim, CA: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Schlimmer, J. C., & Hermens, L. A. </author> <year> (1993). </year> <title> Software agents: Completing patterns and constructing interfaces. </title> <journal> Journal of Artificial Intelligence Research, </journal> <pages> 1 , 61-89. </pages>
Reference: <author> Shrager, J. </author> <year> (1987). </year> <title> Theory change via view application in instructionless learning. </title> <booktitle> Machine Learning, </booktitle> <pages> 2 , 247-276. </pages>
Reference: <author> Sleeman, D., Langley, P., & Mitchell, T. </author> <year> (1982). </year> <title> Learning from solution paths: An approach to the credit assignment problem. </title> <journal> AI Magazine, </journal> <pages> 3 , 48-52. </pages>
Reference: <author> Stolcke, A., & Omohundro, S. </author> <year> (1994). </year> <title> Inducing probabilistic grammars by Bayesian model merging. </title> <booktitle> Proceedings of the Second International Conference on Grammatical Inference and Applications (pp. </booktitle> <pages> 106-118). </pages> <address> Alicante, Spain: </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Sutton, R. S. </author> <year> (1988). </year> <title> Learning to predict by the methods of temporal differences. </title> <booktitle> Machine Learning, </booktitle> <pages> 3 , 9-44. </pages>
Reference-contexts: The agent can receive reward from the environment on each step, but usually gets no information until it has taken many actions. Most (though not all) work on this topic uses some form of temporal-difference method <ref> (Sutton, 1988) </ref>, which propagates reward backward through time to better estimate the expected reward for taking a given action in a given state. <p> Reinforcement learning claims to address the acquisition of action strategies, but most work on that topic has dealt with learning discrete actions in `grid worlds', with little evidence that it generalizes to more realistic domains <ref> (e.g., Sutton, 1988) </ref>. However, work on reinforcement learning by Grefen-stette and his colleagues (Grefenstette, 1988; Grefen-stette, Ramsey, & Schultz, 1990; Grefenstette & Schultz, 1994) differs from this trend in some important respects.
Reference: <author> Thompson, C. A. </author> <year> (1995). </year> <title> Acquisition of a lexicon from semantic representations of sentences. </title> <booktitle> Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics (pp. </booktitle> <pages> 335-337). </pages>
Reference: <author> Valdes-Perez, R. E. </author> <year> (1992). </year> <title> Theory-driven discovery of reaction pathways in the Mechem system. </title> <booktitle> Proceedings of the Tenth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 63-69). </pages> <address> San Jose: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Veloso, M., & Blythe, J. </author> <year> (1994). </year> <title> Linkability: Examining causal link commitments in partial-order planning. </title> <booktitle> Proceedings of the Second International Conference on AI Planning Systems (pp. </booktitle> <pages> 170-175). </pages> <address> Chicago: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Veloso, M. M., & Carbonell, J. G. </author> <year> (1993). </year> <title> Derivational analogy in Prodigy: Automating case acquisition, storage, and utilization. </title> <booktitle> Machine Learning, </booktitle> <pages> 10 , 249-278. </pages>
Reference-contexts: Machine Learning for Planning Another core area of AI involves planning and problem solving. The 1980's saw considerable work on this topic within the machine learning community, some of it collected in Minton (1993), but interest in the area has declined in recent years. However, Veloso and her colleagues <ref> (e.g., Veloso & Carbonell, 1993) </ref> have continued an active research program on learning in planning, carried out within the Prodigy architecture.
Reference: <author> Wolff, J. G. </author> <year> (1980). </year> <title> Language acquisition and the discovery of phrase structure. </title> <booktitle> Language and Speech, </booktitle> <pages> 23 , 255-269. </pages>
Reference: <author> Zelle, J. M., & Mooney, R. J. </author> <year> (1993). </year> <title> Learning semantic grammars with constructive inductive logic programming. </title> <booktitle> Proceedings of the Eleventh National Conference on Artificial Intelligence (pp. </booktitle> <pages> 817-822). </pages> <address> Washington, DC: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Zelle, J. M., & Mooney, R. J. </author> <year> (1996). </year> <title> Learning to parse database queries using inductive logic programming. </title> <booktitle> Proceedings of the Thirteenth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 1050-1055). </pages> <address> Portland: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Zhang, W., & Dietterich, T. G. </author> <year> (1995). </year> <title> A reinforcement learning approach to job-shop scheduling. </title> <booktitle> Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 1114-1120). </pages> <address> Montreal: </address> <publisher> Morgan Kaufmann. </publisher>
References-found: 37

