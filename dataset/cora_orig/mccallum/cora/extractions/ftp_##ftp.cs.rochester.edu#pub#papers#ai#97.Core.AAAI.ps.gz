URL: ftp://ftp.cs.rochester.edu/pub/papers/ai/97.Core.AAAI.ps.gz
Refering-URL: http://www.cs.rochester.edu/research/trains/annotation/papers.html
Root-URL: 
Email: mcore@cs.rochester.edu  
Title: Analyzing and Predicting Patterns of DAMSL Utterance Tags tags. The fourth section covers interesting tag
Author: Mark G. Core Allen, Miller ). 
Note: DAMSL  
Address: Rochester, NY 14627  
Affiliation: Department of Computer Science University of Rochester  
Abstract: We have been annotating TRAINS dialogs with dialog acts in order to produce training data for a dialog act predictor, and to study how language is used in these dialogs. We are using DAMSL dialog acts which consist of 15 independent attributes. For the purposes of this paper, infrequent attributes such as Unintelligible and Self-Talk were set aside to concentrate on the eight major DAMSL tag sets. For five of these eight tag sets, hand constructed decision trees (based solely on the previous utterance's DAMSL tags) did better than always guessing the most frequent DAMSL tag values. This result suggests that it is possible to automatically build such decision trees especially if other sources of context are added. Our initial efforts to address our second goal (studying language use in the TRAINS dialogs) consist of measuring DAMSL tag co-occurrences and bigrams. Some interesting patterns have emerged from this simple analysis such as the fact that signaling non-understanding is often done through questions. These patterns suggest that we should also be considering an n-gram dialog act model for use in predicting DAMSL tags. Machine learning techniques have been successfully applied to speech recognition, part of speech tagging, word sense disambiguation, and parsing. One reason for this success is that researchers have been able to define "correct" answers even for word sense disambiguation (Miller et al. 1993) and parsing (Marcus, Santorini, & Marcinkiewicz 1992). DAMSL (Dialog Act Markup in Several Layers) is a system for labeling the "correct" dialog acts for an utterance. We are annotating dialogs with DAMSL tags in order to produce training data for a dialog act predictor, and to study how language is used in our dialog corpus. We start this paper with a brief description of DAMSL as well as a discussion of its suitability for encoding the "correct" dialog acts for an utterance. The second section of the paper discusses the motivation for using machine learning to automatically predict DAMSL tags, and the third section describes an initial attempt at constructing decision trees to predict Different types of dialogs, being analyzed for different purposes will lead to specialized dialog acts such as Digress and Acknowledge Apology. However, research groups can agree to a common set of higher-level dialog acts so they can share annotated dialogs, increasing the amount of training data available for dialog act rec-ognizers. For example, TRAINS and VERBMOBIL might agree to a general acknowledgment dialog act under which Acknowledge Apology would fit as well as VERBMOBIL's Feedback dialog act. The Multiparty Discourse Group was formed to develop such a set of dialog acts. It has meet twice at meetings of the Discourse Research Initiative (DRI). 1 The DAMSL utterance annotation scheme was developed from this effort and includes traditional illo-cutionary acts as well as a label of the utterance's general topic and how it responds to previous utterances. The annotation manual describing the la 
Abstract-found: 1
Intro-found: 1
Reference: <author> Allen, J. F., and Perrault, C. R. </author> <year> 1980. </year> <title> Analyzing intention in utterances. </title> <booktitle> Artificial Intelligence 15 </booktitle> <pages> 143-178. </pages>
Reference-contexts: The major problem with such an architecture is that the planner must sort through a large space of communicative plans and may also have to perform planning related to the domain (the dialog may involve constructing plans). <ref> (Allen & Perrault 1980) </ref> talk about heuristics to guide a planner through this space of plans so that the system does not waste its time considering implausible plans. Plans are given weights based on heuristics, but these heuristics are all general purpose and apply to any set of plan operators.
Reference: <author> Carletta, J. </author> <year> 1996. </year> <title> Assessing agreement on classification tasks: the kappa statistic. </title> <note> Computational Linguistics 22(2). </note>
Reference-contexts: Such uses require reliably labeled dialogs; otherwise there will not be consist patterns to identify. The kappa statistic (Siegel & Castellan 1988) for inter-annotator reliability is becoming the standard for annotations of this type. According to <ref> (Carletta 1996) </ref> even for tentative conclusions to be drawn, kappas must be above 0.67 with above 0.8 being considered reliable. (Core & Allen 1997) shows kappa scores from annotations of eight TRAINS dialogs by University of Rochester (undergraduate and graduate) students.
Reference: <author> Cohen, P. R., and Perrault, C. R. </author> <year> 1979. </year> <title> Elements of a plan-based theory of speech acts. </title> <booktitle> Cognitive Science 3 </booktitle> <pages> 177-212. </pages>
Reference-contexts: In the meantime, some tentative conclusions can be drawn about the TRAINS dialogs based on the current data. Automatically Predicting DAMSL Tags Can machine learning techniques predict DAMSL tags well enough to be useful in a dialog system? <ref> (Cohen & Perrault 1979) </ref> introduced the notation of formulating dialog acts as plan operators. Such an architecture allows the system to perform plan recognition to determine the appropriate dialog acts for an utterance.
Reference: <author> Core, M. G., and Allen, J. F. </author> <year> 1997. </year> <title> Annotating dialogs with the damsl annotation scheme. </title> <note> Presented at the AAAI Fall Symposium on Communicative Action in Humans and Machines. Available at http://www.cs.rochester.edu/u/mcore. </note>
Reference-contexts: The kappa statistic (Siegel & Castellan 1988) for inter-annotator reliability is becoming the standard for annotations of this type. According to (Carletta 1996) even for tentative conclusions to be drawn, kappas must be above 0.67 with above 0.8 being considered reliable. <ref> (Core & Allen 1997) </ref> shows kappa scores from annotations of eight TRAINS dialogs by University of Rochester (undergraduate and graduate) students. The TRAINS dialogs which are also used in the experiments of this paper are discussions between humans on solving transportation problems involving trains (Hee-man & Allen 1995). <p> The TRAINS dialogs which are also used in the experiments of this paper are discussions between humans on solving transportation problems involving trains (Hee-man & Allen 1995). Most of the kappa scores of these eight TRAINS dialogs are close to or above the 0.67 limit discussed above. <ref> (Core & Allen 1997) </ref> discusses reasons for annotator disagreement; most of these issues have been addressed in the newest version of the DAMSL annotation manual.
Reference: <author> Dehaspe, L., and Raedt, L. D. </author> <year> 1997. </year> <title> Mining a natural language corpus for multi-relational association rules. </title>
Reference-contexts: The addition of cue words and sentence forms to the context should bring new developments as well. Another area for exploration is the use of data mining techniques to extract interesting patterns from the corpus. <ref> (Dehaspe & Raedt 1997) </ref> tries such an approach on part of speech tags in a corpus of Wall Street Journal text. Conclusions Results on hand coded decision trees (given only the context of the last utterance's DAMSL tags) suggest that automatically derived decision trees should be effective DAMSL tag predictors.
Reference: <editor> In Daelemans, W.; van den Bosch, A.; and Weijters, A., eds., </editor> <booktitle> Workshop Notes of the ECML/MLnet Workshop on Empirical Learning of Natural Language Processing Tasks. </booktitle> <pages> 35-48. </pages>
Reference: <author> Ferguson, G.; Allen, J.; and Miller, B. </author> <year> 1996. </year> <title> TRAINS-95: Towards a mixed-initiative planning assistant. </title> <booktitle> In Proc. of the 3rd International Conference on AI Planning Systems (AIPS-96). </booktitle>
Reference: <author> Heeman, P., and Allen, J. </author> <year> 1995. </year> <title> the TRAINS 93 dialogues. </title> <type> TRAINS Technical Note 94-2, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY 14627-0226. </address>
Reference: <author> Heeman, P. A. </author> <year> 1997. </year> <title> Speech Repairs, Intonational Boundaries and Discourse Markers: Modeling Speakers' Utterances in Spoken Dialog. </title> <type> Ph.D. Dissertation, </type> <institution> Department of Computer Science, University of Rochester. </institution>
Reference-contexts: Connectionist models have been used in parsing (Wermter & Weber 1994), while inductive learning methods have been used in parsing (Magerman 1995), part of speech tagging, and speech repair correction <ref> (Heeman 1997) </ref>. To predict an utterance's DAMSL tags, one could simply use the highest frequency values for each label. Hopefully, one can do better by using machine learning techniques to identity contexts where alternative values are more likely.
Reference: <author> Jurafsky, D.; Bates, R.; Coccaro, N.; Martin, R.; Meteer, M.; Ries, K.; Shriberg, E.; Stolcke, A.; Tay-lor, P.; and Van Ess-Dykema, C. </author> <year> 1997. </year> <title> Automatic detection of discourse structure for speech recognition and understanding. </title> <booktitle> In Proceedings of the 1997 IEEE Workshop on Speech Recognition and Understanding. </booktitle>
Reference-contexts: The conditional probabilities taken from the labeled corpus not only provide interesting insights into these dialogs, but suggest that an n-gram model of dialog acts could also be an effective DAMSL tag predictor. <ref> (Jurafsky et al. 1997) </ref> uses such an n-gram dialog act model as a component of their 3 part system which also includes word models and a decision tree using prosodic features as context. <p> Different n-gram word models are created for each dialog act and one the best fitting the input is chosen for each utterance. (Mast et al. 1996) compares using decision trees (having the utterance's words as context) to using word models like <ref> (Jurafsky et al. 1997) </ref> and finds that the word models are better. Thus as work proceeds on predicting DAMSL tags in TRAINS dialogs, it may turn out that word models and n-gram dialog act models are used.
Reference: <author> Magerman, D. M. </author> <year> 1995. </year> <title> Statistical decision-tree models for parsing. </title> <booktitle> In Proc. of the 33rd annual meeting of the Association for Computational Linguistics (ACL-95). </booktitle>
Reference-contexts: Machine learning techniques have been used successfully in similar applications where there is a large amount of background information and it is unclear what the relevant pieces are. Connectionist models have been used in parsing (Wermter & Weber 1994), while inductive learning methods have been used in parsing <ref> (Magerman 1995) </ref>, part of speech tagging, and speech repair correction (Heeman 1997). To predict an utterance's DAMSL tags, one could simply use the highest frequency values for each label. Hopefully, one can do better by using machine learning techniques to identity contexts where alternative values are more likely.
Reference: <author> Marcus, M.; Santorini, B.; and Marcinkiewicz, M. </author> <year> 1992. </year> <title> Building a large annotated corpus of English: the Penn Treebank. Penn Treebank Project. </title>
Reference: <author> Mast, M.; Niemann, H.; Noth, E.; and Schukat-Talamazzini, E. G. </author> <year> 1996. </year> <title> Automatic classification of dialog acts with semantic classification trees and polygrams. </title> <editor> In Wermter, S.; Riloff, E.; and Scheler, G., eds., </editor> <title> Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing, </title> <booktitle> Lecture Notes in Artificial Intelligence. </booktitle> <address> New York: </address> <publisher> Springer. </publisher> <pages> 217-229. </pages>
Reference-contexts: Different n-gram word models are created for each dialog act and one the best fitting the input is chosen for each utterance. <ref> (Mast et al. 1996) </ref> compares using decision trees (having the utterance's words as context) to using word models like (Jurafsky et al. 1997) and finds that the word models are better.
Reference: <author> Miller, G.; Leacock, C.; Tengi, R.; and Bunker, R. </author> <year> 1993. </year> <title> A semantic concordance. </title> <editor> In Bates, M., ed., </editor> <booktitle> Proc. of the ARPA Human Language Technology Workshop, </booktitle> <pages> 303-308. </pages> <address> San Francisco: </address> <publisher> Morgan Kauf-mann Pub. Inc. </publisher>
Reference: <author> Reithinger, N., and Maier, E. </author> <year> 1995. </year> <title> Utilizing statistical dialogue act processing in verbmobil. </title> <booktitle> In Proc. of the 33rd annual meeting of the Association for Computational Linguistics (ACL-95). </booktitle>
Reference: <author> Searle, J. R. </author> <year> 1975. </year> <title> A taxonomy of illocutionary acts. </title> <editor> In Gunderson, K., ed., </editor> <booktitle> Language, Mind, and Knowledge. Minnesota Studies in the Philosophy of Science. </booktitle> <address> Minneapolis, Minnesota: </address> <publisher> University of Min-nesota Press. </publisher> <pages> 344-369. </pages>
Reference: <author> Siegel, S., and Castellan, N. J. </author> <year> 1988. </year> <title> Nonparametric Statistics for the Behavioral Sciences. </title> <type> McGraw-Hill, </type> <note> second edition. </note>
Reference-contexts: Such uses require reliably labeled dialogs; otherwise there will not be consist patterns to identify. The kappa statistic <ref> (Siegel & Castellan 1988) </ref> for inter-annotator reliability is becoming the standard for annotations of this type.
Reference: <author> Wermter, S., and Weber, V. </author> <year> 1994. </year> <title> Learning fault-tolerant speech parsing with screen. </title> <booktitle> In Proc. of the National Conference on Artificial Intelligence (AAAI94). </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: Machine learning techniques have been used successfully in similar applications where there is a large amount of background information and it is unclear what the relevant pieces are. Connectionist models have been used in parsing <ref> (Wermter & Weber 1994) </ref>, while inductive learning methods have been used in parsing (Magerman 1995), part of speech tagging, and speech repair correction (Heeman 1997). To predict an utterance's DAMSL tags, one could simply use the highest frequency values for each label.
References-found: 18

