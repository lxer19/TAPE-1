URL: http://www.isle.org/~langley/papers/app.cacm.ps
Refering-URL: http://www.isle.org/publications.html
Root-URL: 
Title: Applications of Machine Learning and Rule Induction  
Author: Pat Langley Herbert A. Simon 
Address: Stanford, CA 94305  Pittsburgh, PA 15213  
Affiliation: Robotics Laboratory, Computer Science Dept. Stanford University,  Department of Psychology Carnegie Mellon University  
Abstract: An important area of application for machine learning is in automating the acquisition of knowledge bases required for expert systems. In this paper, we review the major paradigms for machine learning, including neural networks, instance-based methods, genetic learning, rule induction, and analytic approaches. We consider rule induction in greater detail and review some of its recent applications, in each case stating the problem, how rule induction was used, and the status of the resulting expert system. In closing, we identify the main stages in fielding an applied learning system and draw some lessons from successful applications. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Biggs, D., de Ville, B., & Suen, E. </author> <year> (1991). </year> <title> A method of choosing multiway partitions for classification and decision trees. </title> <journal> Journal of Applied Statistics, </journal> <pages> 18 , 49-62. </pages>
Reference-contexts: Breiman, Friedman, Olshen, and Stone [2] describe a set of methods for inducing decision trees, which they tested on a variety of applied problems, such as predicting the survival of recent heart-attack patients. A related line of statistical work, known as automated interaction detection <ref> [1] </ref>, has been widely used in the analysis of survey data. Similar techniques are now included in SPSS, a widely available statistical package, making the technology of rule induction accessible to a wide audience.
Reference: [2] <author> Breiman, L., Friedman, J. H., Olshen, R. A., & Stone, C. J. </author> <year> (1984). </year> <title> Classification and regression trees. Belmont: </title> <publisher> Wadsworth. </publisher>
Reference-contexts: We have focused here on techniques that come from the machine learning community, but independent developments in statistics have produced similar methods. Breiman, Friedman, Olshen, and Stone <ref> [2] </ref> describe a set of methods for inducing decision trees, which they tested on a variety of applied problems, such as predicting the survival of recent heart-attack patients. A related line of statistical work, known as automated interaction detection [1], has been widely used in the analysis of survey data.
Reference: [3] <author> Cooper, G. F., & Herskovits, E. </author> <year> (1992). </year> <title> A Bayesian method for the induction of probabilistic networks from data. </title> <booktitle> Machine Learning, </booktitle> <pages> 9 , 309-347. </pages>
Reference-contexts: He repeated this process to find rules for predicting qualita 1. Unfortunately, we do not have space to review the growing literature on learning with probabilistic representations, including trees of probabilistic concepts (e.g., [7]) and Bayesian influence networks (e.g., <ref> [3] </ref>). But this learning paradigm is still young and, to our knowledge, has yet to produce any fielded applications. Applications of Machine Learning 5 tive powder attributes, which were then used in the top-level rules, giving a structured knowledge base.
Reference: [4] <author> El Attar, M., & Hamery, X. </author> <year> (1994). </year> <title> Industrial expert system acquired by machine learning. </title> <journal> Applied Artificial Intelligence, </journal> <pages> 8 , 497-542. </pages>
Reference-contexts: Additional Applications and Related Approaches Nor does above list exhaust the examples of machine learning applications. Researchers have explored a broad range of tasks, though diagnosis has been an especially popular problem area. For example, El Attar and Hamery <ref> [4] </ref>) have applied rule-induction methods to the diagnosis and repair of helicopter blades. The literature abounds with examples of machine induction for medical diagnosis of humans (e.g., [21]), and many of the online data sets fall into this area.
Reference: [5] <author> Evans, B., & Fisher, D. </author> <year> (1994). </year> <title> Overcoming process delays with decision-tree induction. </title> <journal> IEEE Expert, </journal> <pages> 9 , 60-66. </pages>
Reference-contexts: The print run must then be halted and in some cases the cylinder replaced, at a substantial cost. The reasons for banding are largely unknown, and experts cannot reliably predict when it will occur. Evans and Fisher <ref> [5] </ref> decided that decision-tree induction might be useful in reducing banding, which had become a significant problem at a plant of R. R. Donnelley, a large U.S. printing company. <p> Collecting the Training Data After settling on a task and a representation, one can collect the training data needed for the induction process. In some domains, this process is straightforward and can even be automated, but in others it can pose a significant challenge. In Evans and Fisher's <ref> [5] </ref> work on banding in rotogravure printing, the researchers asked the printing technicians to record periodically the values of the process variables and the outcome, but the technicians were reluctant to waste time collecting data on a machine that was working well. <p> Thus, an important part of the evaluation process is experts' examination of the learned knowledge. If significant problems emerge at this stage, they may suggest revisions to the problem formulation or representation. Evans and Fisher <ref> [5] </ref> encourage such an iterative process in developing a fielded application, and other work we have seen took similar approaches. Fielding the Knowledge Base The final stage in applications is fielding the learned knowledge base. We intend this term in the broadest possible sense. <p> Fielding the Knowledge Base The final stage in applications is fielding the learned knowledge base. We intend this term in the broadest possible sense. In some cases, the knowledge acquired can be used without even embedding it in a computer system. In Evans and Fisher's <ref> [5] </ref> work, a simple rule set written on Applications of Machine Learning 15 paper was enough for humans to use in making decisions that alleviated their banding problem.
Reference: [6] <author> Fayyad, U. M., Smyth, P., Weir, N., & Djorgovski, S. </author> <year> (1995). </year> <title> Automated analysis and exploration of image databases: Results, progress, and challenges. </title> <journal> Journal of Intelligent Information Systems, </journal> <volume> 4 , 1-19. </volume> <booktitle> Applications of Machine Learning 17 </booktitle>
Reference-contexts: However, here the aim was to handle stars and nebulae considerably fainter than either visual inspection or existing computer methods could support, and attempts to handcraft expert systems for the task had not produced reliable advances. In response, Fayyad, Smyth, Weir, and Djorgovski <ref> [6] </ref>) adapted a machine learning approach to the problem. First they used image-processing techniques to describe each object in a set of images in terms of standard numerical attributes, such as object magnitude, area, ellipticity, and statistical moments of object and core brightness. <p> In some cases, this involved little more than talking with domain experts and getting their advice on attributes that were likely to have predictive value. In other cases (e.g., Fayyad et al.'s work <ref> [6] </ref>), it involved a painstaking search of the feature space, looking for descriptors that could provide the discriminating power the more obvious features lacked. In some cases the "primitive" features may be computed by already established methods. <p> In Evans and Fisher's [5] work, a simple rule set written on Applications of Machine Learning 15 paper was enough for humans to use in making decisions that alleviated their banding problem. In other cases, as in Fayyad et al.'s <ref> [6] </ref> and Modesitt's [18] domains, users expected not only computer implementation of the learned knowledge, but also considerable software support that had nothing to do with machine learning. The important consideration is that the learned knowledge be used .
Reference: [7] <author> Gennari, J. H., Langley, P., & Fisher, D. H. </author> <year> (1989). </year> <title> Models of incremental concept formation. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 40 , 11-61. </pages>
Reference-contexts: He repeated this process to find rules for predicting qualita 1. Unfortunately, we do not have space to review the growing literature on learning with probabilistic representations, including trees of probabilistic concepts (e.g., <ref> [7] </ref>) and Bayesian influence networks (e.g., [3]). But this learning paradigm is still young and, to our knowledge, has yet to produce any fielded applications. Applications of Machine Learning 5 tive powder attributes, which were then used in the top-level rules, giving a structured knowledge base.
Reference: [8] <author> Giordana, A., Neri, F., & Saitta, L. </author> <title> (in press). Automated learning for industrial diagnosis. </title> <editor> In P. Langley & Y. Kodratoff (Eds.), </editor> <booktitle> Fielded applications of machine learning. </booktitle> <address> San Francisco: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Typical faults include an unbalanced pump, faulty bearings, and distortion of the base. Domain experts at Sogesta rely on Fourier analysis of the vibrations to aid them in their diagnostic decisions. Giordana, Neri, and Saitta <ref> [8] </ref> believed that this task would benefit from the use of machine learning. <p> Fayyad et al. relied heavily on established techniques for image processing to transform their digital images into attribute-value descriptions that could be handled by decision trees. Zubrick and Reese Applications of Machine Learning 14 [25] incorporated traditional statistical measures in their work on forecasting thunderstorms, and Giordana et al. <ref> [8] </ref> used the output of Fourier analysis as primitive attribute values. Collecting the Training Data After settling on a task and a representation, one can collect the training data needed for the induction process. <p> The important consideration is that the learned knowledge be used . Graphical interfaces may increase the chances of use in some domains but hurt them in others. Explanation capabilities may be welcomed by some users but not by others. In some cases (such as Giordana et al.'s work <ref> [8] </ref>), the existence of a fielded hand-crafted expert system has been useful in fielding the learned knowledge base.
Reference: [9] <author> Guilfoyle, C. </author> <year> (1986). </year> <title> Ten minutes to lay the foundations. </title> <booktitle> Expert Systems User , August, </booktitle> <pages> 16-19. </pages>
Reference-contexts: The complexity of the configuration task led the developers to use an approach called structured induction. This scheme incorporates the decisions made by some trees as tests on branches in higher-level trees, but decomposes the learning task by inducing each decision tree separately. Guilfoyle <ref> [9] </ref> reports that the British Petroleum developers collected 1600 training instances, providing a knowledge base of some 2500 rules organized into 25 sets which the company subsequently translated into 14000 lines of Fortran code.
Reference: [10] <author> Hermens, L. A., & Schlimmer, J. C. </author> <year> (1994). </year> <title> A machine-learning apprentice for the completion of repetitive forms. </title> <journal> IEEE Expert , 9 , 28-33. </journal>
Reference-contexts: Even partial automation of the process would produce substantial savings, but the cost of writing a separate expert system for each form often forestalls this approach. Hermens and Schlimmer <ref> [10] </ref> have developed a form-filling advisory system that learns to predict its users' preferences through observation. They used an incremental version of decision-tree induction to find rules for predicting the default entry for each field in terms of other fields already specified.
Reference: [11] <author> Karba, N., & Drole, R. </author> <year> (1989). </year> <title> Expert system for the cold rolling mill of the Steel Works Jesenice. </title> <booktitle> Proceedings of the Thirteenth Symposium on Information Technologies. </booktitle> <address> Sarajevo, Yugoslavia. </address>
Reference-contexts: When this approach did not succeed, the developers collaborated with local university researchers on an inductive approach, using examples of the expert's decisions as training data <ref> [11] </ref>. The induced decision tree was installed in the steel works, but later, after a change in the emulsion and its supplier, the knowledge ceased to perform satisfactorily.
Reference: [12] <author> Kibler, D., & Langley, P. </author> <year> (1988). </year> <title> Machine learning as an experimental science. </title> <booktitle> Proceedings of the Third European Working Session on Learning (pp. </booktitle> <pages> 81-92). </pages> <address> Glasgow: </address> <publisher> Pittman. </publisher>
Reference-contexts: One can repeat this process a number of times with different splits, then average the results to estimate the rules' performance on completely new problems. Kibler and Langley <ref> [12] </ref> experimental methods of this sort for a broad class of learning algorithms. However, human experts are available in many domains, and it would be foolhardy to ignore their opinions, even when they cannot articulate their knowledge fully.
Reference: [13] <author> Langley, P., Drastal, G., Rao, B., & Greiner, R. </author> <year> (1994). </year> <title> Theory revision in fault hierarchies. </title> <booktitle> Proceedings of the Fifth International Workshop on Principals of Diagnosis. </booktitle> <address> New Paltz, NY. </address>
Reference-contexts: Regular maintenance is needed Applications of Machine Learning 10 not only because of errors introduced at coding time, but also because the problem itself changes over time, as devices and users evolve. For instance, Langley, Drastal, Rao, and Greiner <ref> [13] </ref> describe a diagnostic system for computerized tomography scanners that is used on a regular basis by technicians at a Siemens operating company, but in which errors in the knowledge base have started to emerge.
Reference: [14] <author> Leech, W. J. </author> <year> (1986). </year> <title> A rule-based process control method with feedback. </title> <booktitle> Advances in Instrumentation, </booktitle> <pages> 41 , 169-175. </pages>
Reference-contexts: These pellets must be of high quality, but experts cannot predict when a batch of pellets will be good or bad. Researchers at Westinghouse used statistical methods to predict pellet quality with partial success, but interactions among the predictive attributes limited the effectiveness of this approach. Leech <ref> [14] </ref> followed a different path in which decision-tree induction played a central role. He collected samples of pellet batches of high and low quality, along with their manufacturing control settings (e.g., pelleting parameters and powder characteristics), some numeric and others symbolic. <p> A number of developers have relied on a technique known as structured induction, which involves dividing a complex task into subproblems, then providing training data for each one separately. Zubrick and Reese [25], Leech <ref> [14] </ref>, and Modesitt [18] all took this approach, producing performance systems that carry out multi-step inference, but, by factoring it, avoid this complexity during the induction process. <p> In process-control domains, it seems natural to search for rules or trees that directly predict the values of process variables, such as ink viscosity in printing, from environmental ones like humidity. However, on two of the control tasks we examined ([4], <ref> [14] </ref>), developers instead used induction to find rules to predict directly the effects of both process and environmental variables, apparently because users were more familiar with this formulation.
Reference: [15] <author> Michie, D. </author> <year> (1987). </year> <title> Current developments in expert systems. </title> <editor> In J. R. Quinlan (Ed.), </editor> <booktitle> Applications of expert systems. </booktitle> <address> Wokingham, UK: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: Additional Fielded Applications of Rule Induction The above examples constitute only a fraction of the fielded applications of decision-tree and rule induction, though few results are published in the scientific literature. For instance, Donald Michie <ref> [15] </ref> has reported four induced knowledge bases for diagnosing faults in circuit boards that are in routine use in a European electronics laboratory and that save millions of dollars a year.
Reference: [16] <author> Michie, D. </author> <year> (1989). </year> <title> Problems of computer-aided concept formation. </title> <editor> In J. R. Quinlan (Ed.), </editor> <booktitle> Applications of expert systems (Vol. 2). </booktitle> <address> Wokingham, UK: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: These observations motivated American Express UK to try methods from machine learning to improve the decision process. Starting with 1014 training cases and 18 descriptive attributes (such as age and years with an employer), Michie <ref> [16] </ref> and his colleagues used an induction method to produce a decision tree, containing around 20 nodes and ten of the original features, that made correct predictions on 70% of the borderline applicants.
Reference: [17] <author> Michie, D. </author> <year> (1992). </year> <title> Directions in machine intelligence. </title> <journal> Computer Bulletin, </journal> <volume> September/October, </volume> <pages> 9-11. </pages>
Reference-contexts: For example, depending on the size of ore lumps in a batch, one may crush them, blend them with other material, or send them directly to the blast furnace. Michie <ref> [17] </ref> describes an effort by Pohang Iron and Steel Company, in South Korea, to construct an expert system for this process using structured decision-tree induction. <p> On the other hand, similar work reported by Sammut et al. [24] and Michie <ref> [17] </ref> took the more `natural' approach, so no general conclusions can be drawn. Determining the Representation The second step in applying machine learning techniques is to settle on an effective representation for both training data and the knowledge to be learned.
Reference: [18] <author> Modesitt, K. L. </author> <year> (1990). </year> <title> Inductive knowledge acquisition: A case study of Scotty. </title> <editor> In K. L. Mc-Graw & C. R. Westphal (Eds.), </editor> <booktitle> Readings in knowledge acquisition: Current practices and trends. </booktitle> <address> Chichester, UK: </address> <publisher> Ellis Horwood. </publisher>
Reference-contexts: They must decide whether another test firing is needed, whether to replace engine components, and so forth. Because this evaluation process itself is expensive, Rocketdyne used structured-induction methods (similar to those used in the British Petroleum effort) to construct recursively structured decision trees for the task. Modesitt <ref> [18] </ref> describes one of the resulting systems, designed to handle data from static-fire tests, which contained over 1500 rules organized into 48 rule sets. Another knowledge base, constructed to analyze dynamic data such as frequencies and vibrations, was induced in a similar fashion. <p> A number of developers have relied on a technique known as structured induction, which involves dividing a complex task into subproblems, then providing training data for each one separately. Zubrick and Reese [25], Leech [14], and Modesitt <ref> [18] </ref> all took this approach, producing performance systems that carry out multi-step inference, but, by factoring it, avoid this complexity during the induction process. <p> In Evans and Fisher's [5] work, a simple rule set written on Applications of Machine Learning 15 paper was enough for humans to use in making decisions that alleviated their banding problem. In other cases, as in Fayyad et al.'s [6] and Modesitt's <ref> [18] </ref> domains, users expected not only computer implementation of the learned knowledge, but also considerable software support that had nothing to do with machine learning. The important consideration is that the learned knowledge be used .
Reference: [19] <author> Muggleton, S., King, R. D., & Sternberg, M. J. E. </author> <year> (1992). </year> <title> Protein secondary structure prediction using logic-based machine learning. </title> <journal> Protein Engineering, </journal> <pages> 5 , 647-657. </pages>
Reference-contexts: Predicting the Structure of Proteins One largely unsolved problem in molecular biology involves predicting the secondary structure (folding) of proteins from information about their primary amino acid sequences. Some hand-crafted theories exist, but their predictive abilities are disappointing. Muggleton, King, and Sternberg <ref> [19] </ref> attacked this problem using inductive logic programming, which they felt was appropriate for such a relational domain. Taking 16 proteins that contained only ff helices, they treated each position in these proteins as a training instance. <p> Zubrick and Reese [25], Leech [14], and Modesitt [18] all took this approach, producing performance systems that carry out multi-step inference, but, by factoring it, avoid this complexity during the induction process. Muggleton et al.'s <ref> [19] </ref> scheme, which added predictions produced by learned rules as background knowledge for later rounds of induction, provides an alternative way of decomposing the learning task. The best formulation of the problem may not always be the one most intuitive to a machine-learning researcher.
Reference: [20] <author> Quinlan, J. R. </author> <year> (1993). </year> <title> C4.5: Programs for machine learning. </title> <address> San Francisco: </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: Most methods partition the training data recursively into disjoint sets, attempting to summarize each set as a conjunction of logical conditions. Quinlan <ref> [20] </ref> describes one such rule-induction algorithm in some detail. A final approach, sometimes termed analytic learning, represents knowledge as rules in logical form, and typically employs a performance system that solves multi-step problems using some search process.
Reference: [21] <author> Quinlan, J. R., Compton, P. J., Horn, K. A., & Lazarus, L. </author> <year> (1987). </year> <title> Inductive knowledge acquisition: A case study. </title> <editor> In J. R. Quinlan (Ed.), </editor> <booktitle> Applications of expert systems. </booktitle> <address> Wokingham, UK: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: For example, El Attar and Hamery [4]) have applied rule-induction methods to the diagnosis and repair of helicopter blades. The literature abounds with examples of machine induction for medical diagnosis of humans (e.g., <ref> [21] </ref>), and many of the online data sets fall into this area. Despite repeated demonstrations that the induced knowledge bases can be more accurate than physicians, few of these efforts have led to fielded systems.
Reference: [22] <author> Riese, C. </author> <year> (1984). </year> <title> Transformer fault detection and diagnosis using RuleMaster by Radian (Technical Report). </title> <institution> Austin, TX: Radian Corporation. </institution> <note> Applications of Machine Learning 18 </note>
Reference-contexts: Experts can predict failures accurately from gas chromatographs that reveal chemical traces in the transformer oil. To reduce these experts' work loads, Hartford Steam Boiler, an insurer of industrial equipment, funded development of an expert system for this task using rule induction. The resulting system, described by Riese <ref> [22] </ref>, contains 27 sets of rules that check the validity of data, identify the presence of symptoms, infer faults from symptoms, and suggest corrective actions. Experimental evaluation on 859 test cases showed the induced rules agreed with the expert's diagnosis in all but four cases.
Reference: [23] <author> Samuelson, C., & Rayner, M. </author> <year> (1991). </year> <title> Quantitative evaluation of explanation-based learning as an optimization tool for a large-scale natural language system. </title> <booktitle> Proceedings of the Twelfth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 609-615). </pages> <address> Sydney: </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: Increasing the Speed of a Natural-Language Interface Natural-language interfaces have become increasingly common, but as their flexibility and coverage grows, the need for efficient parsing algorithms is growing as well. An interface that is slow to respond to improvements in parsers can lose users. Samuelson and Rayner <ref> [23] </ref> applied an analytic learning method to this problem. They noted that, because the linguistic knowledge in their natural-language system was given in a definite clause grammar, it could be easily transformed into the Horn-clause representation often used in analytic learning techniques.
Reference: [24] <author> Sammut, C., Hurst, S., Kedizer, D., & Michie, D. </author> <year> (1992). </year> <title> Learning to fly. </title> <booktitle> Proceedings of the Ninth International Conference on Machine Learning (pp. </booktitle> <pages> 385-393). </pages> <address> Aberdeen, Scotland: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Sammut, Hurst, Kedizer, and Michie <ref> [24] </ref> collected traces of expert behavior on a flight simulator, storing the pilot's actions and the associated sensor readings at each time step. <p> However, on two of the control tasks we examined ([4], [14]), developers instead used induction to find rules to predict directly the effects of both process and environmental variables, apparently because users were more familiar with this formulation. On the other hand, similar work reported by Sammut et al. <ref> [24] </ref> and Michie [17] took the more `natural' approach, so no general conclusions can be drawn. Determining the Representation The second step in applying machine learning techniques is to settle on an effective representation for both training data and the knowledge to be learned.
Reference: [25] <author> Zubrick, S. M., & Riese, C. E. </author> <title> (1985) An expert system to aid in severe thunderstorm forecasting. </title> <booktitle> Proceedings of the Fourteenth Conference on Severe Local Storms. </booktitle> <address> Indianapolis. </address>
Reference-contexts: For example, to determine the chance of severe thunderstorms they use factors like the amount of low-level moisture and the destabilization potential at low and high levels, which they in turn analyze using such data as the dew point, advection variables, and stability indices. Zubrick and Riese <ref> [25] </ref> describe an expert system for this task developed, using decision-tree induction, by a meteorologist at the National Severe Storms Forecast Center. <p> A number of developers have relied on a technique known as structured induction, which involves dividing a complex task into subproblems, then providing training data for each one separately. Zubrick and Reese <ref> [25] </ref>, Leech [14], and Modesitt [18] all took this approach, producing performance systems that carry out multi-step inference, but, by factoring it, avoid this complexity during the induction process. <p> In some cases the "primitive" features may be computed by already established methods. Fayyad et al. relied heavily on established techniques for image processing to transform their digital images into attribute-value descriptions that could be handled by decision trees. Zubrick and Reese Applications of Machine Learning 14 <ref> [25] </ref> incorporated traditional statistical measures in their work on forecasting thunderstorms, and Giordana et al. [8] used the output of Fourier analysis as primitive attribute values. Collecting the Training Data After settling on a task and a representation, one can collect the training data needed for the induction process.
References-found: 25

