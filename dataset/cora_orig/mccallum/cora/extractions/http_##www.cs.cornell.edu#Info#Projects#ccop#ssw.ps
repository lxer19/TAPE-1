URL: http://www.cs.cornell.edu/Info/Projects/ccop/ssw.ps
Refering-URL: http://www.cs.cornell.edu/Info/Projects/ccop/reports.html
Root-URL: 
Phone: 2  3  
Title: Approximation Algorithms  
Author: Andreas S. Schulz David B. Shmoys David P. Williamson 
Date: 2 10 6  
Note: made. Although one could, in principle, try all  
Address: 17. Juni 136, 10623 Berlin, Germany  232 Rhodes Hall, Ithaca, NY 14853  P. O. Box 218, Yorktown Heights, NY 10598  
Affiliation: 1 Fachbereich Mathematik, Technische Universitt Berlin, Strae des  School of Operations Research and Industrial Engineering and Department of Computer Science, Cornell University,  IBM T. J. Watson Research Labs,  
Abstract: possible solutions to find the optimal one, such a method would be impractically slow. Unfortunately, for most of these models, no algorithms are known that find optimal solutions with reasonable computation times. Typically, industry must rely on solutions of unguaranteed quality that are constructed in an ad hoc manner. Fortunately, for some of these models there are good approximation algorithms: algorithms that produce solutions quickly that are provably close to optimal. Over the past six years, there have been a sequence of major breakthroughs in our understanding of the design of approximation algorithms and of limits to obtaining such performance guarantees: this area has been one of the most flourishing areas of discrete mathematics and theoretical computer science.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Arora, S. & Lund, C. </author> <booktitle> (1997) in [11], </booktitle> <pages> pp. 399446. </pages>
Reference-contexts: There have been significant recent breakthroughs both in giving improved performance guarantees, and in proving limits on the extent to which near-optimal solutions can be efficiently computed. While we shall highlight only a few ideas in the former category and refer the reader to <ref> [1] </ref> for the latter, progress on both sides has made this one of the most flourishing areas of discrete mathematics and theoretical computer science. 2 Some Examples The central difficulty in designing approximation algorithms is proving that a solution close to the optimal can be computed quickly, when the optimal solution <p> If we can show that the optimal LP solution can be rounded to an integer solution of not much greater congestion, then the rounded solution is provably near-optimal. Raghavan & Thompson [7] introduced an elegant randomized rounding technique: interpret the value of x P 2 <ref> [0; 1] </ref> in the optimal LP solution as a probability, and for each i = 1; : : : ; k, choose a path P 2 P i with probability x P .
Reference: [2] <author> Barahona, F., Grtschel, M., Jnger, M., & Reinelt, G. </author> <title> (1988) Oper. </title> <journal> Res. </journal> <volume> 36, </volume> <pages> 493513. </pages>
Reference-contexts: These edges are said to be in the cut. This NP-complete problem arises in various contexts, from finding the ground state of the Ising spin glass model in statistical physics to minimizing the number of holes that must be drilled in circuit boards; see Barahona et al. <ref> [2] </ref> for further details. Randomization has proven to be a particularly effective tool in the design and analysis of approximation algorithms, and throughout discrete mathematics (see, 3 e.g., [3, 4]).
Reference: [3] <author> Motwani, R. & Raghavan, P. </author> <title> (1995) Randomized Algorithms (Cambridge University Press, </title> <publisher> Cambridge). </publisher>
Reference-contexts: Randomization has proven to be a particularly effective tool in the design and analysis of approximation algorithms, and throughout discrete mathematics (see, 3 e.g., <ref> [3, 4] </ref>). A naive use of randomization is to pick a solution uniformly at random; for example, in the maximum cut problem, we can flip a coin for each node, and thereby split the nodes into the heads set and the tails set.
Reference: [4] <author> Alon, N. & Spencer, J. H. </author> <title> (1992) The Probabilistic Method (John Wiley & Sons, </title> <address> New York). </address>
Reference-contexts: Randomization has proven to be a particularly effective tool in the design and analysis of approximation algorithms, and throughout discrete mathematics (see, 3 e.g., <ref> [3, 4] </ref>). A naive use of randomization is to pick a solution uniformly at random; for example, in the maximum cut problem, we can flip a coin for each node, and thereby split the nodes into the heads set and the tails set.
Reference: [5] <author> Goemans, M. X. & Williamson, D. P. </author> <note> (1995) J. ACM 42, 11151145. </note>
Reference-contexts: Thus using the vector problem to bias our random choice of a solution helps us to produce significantly better solutions to the maximum cut problem. This use of semidefinite programming was introduced by Goemans and Williamson <ref> [5] </ref>, and has subsequently been adapted to several other settings [6]. This result gave the first improvement in approximating the maximum cut problem after almost 20 years of essentially no progress. Linear programming is the technique most frequently used to obtain strong performance guarantees.
Reference: [6] <author> Goemans, M. X. </author> <title> (1997) Math. </title> <journal> Prog. </journal> <volume> 79, </volume> <pages> 143161. </pages>
Reference-contexts: Thus using the vector problem to bias our random choice of a solution helps us to produce significantly better solutions to the maximum cut problem. This use of semidefinite programming was introduced by Goemans and Williamson [5], and has subsequently been adapted to several other settings <ref> [6] </ref>. This result gave the first improvement in approximating the maximum cut problem after almost 20 years of essentially no progress. Linear programming is the technique most frequently used to obtain strong performance guarantees.
Reference: [7] <author> Raghavan, P. & Thompson, C. D. </author> <note> (1987) Combinatorica 7, 365374. </note>
Reference-contexts: The optimal value C fl of this LP is a lower bound on the optimal congestion. If we can show that the optimal LP solution can be rounded to an integer solution of not much greater congestion, then the rounded solution is provably near-optimal. Raghavan & Thompson <ref> [7] </ref> introduced an elegant randomized rounding technique: interpret the value of x P 2 [0; 1] in the optimal LP solution as a probability, and for each i = 1; : : : ; k, choose a path P 2 P i with probability x P .
Reference: [8] <author> Arora, S. </author> <booktitle> (1996) Proc. 37th IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> 213. </pages>
Reference-contexts: Finally, there has also been a dramatic recent advance for the drilling problem discussed in the introduction. If the time to move the drill is the Euclidean distance between the holes, Arora <ref> [8] </ref> and Mitchell [9] gave a (1 + e)-approximation algorithm, for any constant e &gt; 0. These examples highlight the importance of strong relaxations in the design of approximation algorithms, and show the power of randomization in constructing good solutions.
Reference: [9] <author> Mitchell, J. S. B. </author> <note> SIAM J. Comput., to appear. </note>
Reference-contexts: Finally, there has also been a dramatic recent advance for the drilling problem discussed in the introduction. If the time to move the drill is the Euclidean distance between the holes, Arora [8] and Mitchell <ref> [9] </ref> gave a (1 + e)-approximation algorithm, for any constant e &gt; 0. These examples highlight the importance of strong relaxations in the design of approximation algorithms, and show the power of randomization in constructing good solutions.
Reference: [10] <author> Shmoys, D. B. </author> <title> (1995) in Combinatorial Optimization, </title> <editor> eds. Cook, W., Lovsz, L., and Seymour, P. D. </editor> <publisher> (AMS, Providence), </publisher> <pages> pp. 355397. </pages>
Reference-contexts: These examples highlight the importance of strong relaxations in the design of approximation algorithms, and show the power of randomization in constructing good solutions. Other related important algorithmic techniques have also contributed to surprising advances in this area, and the reader is referred to <ref> [10, 11] </ref> for more comprehensive surveys of approximation algorithms. 5 Acknowledgments David Shmoys has been supported in part by NSF grant CCR-97-00029.
Reference: [11] <author> Hochbaum, D. S., ed. </author> <title> (1997) Approximation Algorithms for NP-hard Problems (PWS, </title> <address> Boston). </address> <month> 6 </month>
Reference-contexts: These examples highlight the importance of strong relaxations in the design of approximation algorithms, and show the power of randomization in constructing good solutions. Other related important algorithmic techniques have also contributed to surprising advances in this area, and the reader is referred to <ref> [10, 11] </ref> for more comprehensive surveys of approximation algorithms. 5 Acknowledgments David Shmoys has been supported in part by NSF grant CCR-97-00029.
References-found: 11

