URL: ftp://ftp.cs.columbia.edu/reports/reports-1993/cucs-031-93.ps.gz
Refering-URL: http://www.cs.columbia.edu/~library/1993.html
Root-URL: http://www.cs.columbia.edu
Title: Lower Bounds on the Cost of Binary Search Trees  
Author: Roberto De Prisco Alfredo De Santis 
Address: New York, N.Y. 10027  84081 Baronissi (SA) Italy  
Affiliation: Sistemi di Calcolo e Strutture Informative". Department of Computer Science, Columbia University,  Dipartimento di Informatica ed Applicazioni, Universita di Salerno,  
Note: New  This work was partially supported by the National Council of Research (C.N.R.) under grant 91.02326.CT12 and by M.U.R.S.T. in the framework of Project: "Algoritmi,  
Abstract: Technical Report CUCS-031-93 Abstract In this paper we provide new lower bounds on the cost of binary search trees. The bounds are expressed in terms of the entropy of the probability distribution, the number of elements and the probability that a search is successfully. Most of our lower bounds are derived by means of a new technique which exploits the relation between trees and codes. Our lower bounds compare favorably with known limitations. We also provide an achievable upper bound on the Kraft sum generalized to the internal nodes of a tree. This improves on a previous result. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Ahlswede and I. Wegener, </author> <title> Search problems, </title> <publisher> (J.Wiley & Sons, </publisher> <year> 1987). </year>
Reference-contexts: Finally, we recall the following results. kraft's equality. In any binary search tree we have that P n For the internal nodes of a binary search tree a result which corresponds to the Kraft's equality is the following <ref> [1] </ref>, [2], n X 2 l (q k ) 2 In Section 4 we improve on (5) and using the better bound on the Kraft sum generalized to the internal nodes of a tree, we improve the lower bound on C opt obtained in Section 3 by using the weaker (5).
Reference: [2] <author> M. Aigner, </author> <title> Combinatorial search, </title> <publisher> (J.Wiley & Sons, </publisher> <year> 1988). </year>
Reference-contexts: Finally, we recall the following results. kraft's equality. In any binary search tree we have that P n For the internal nodes of a binary search tree a result which corresponds to the Kraft's equality is the following [1], <ref> [2] </ref>, n X 2 l (q k ) 2 In Section 4 we improve on (5) and using the better bound on the Kraft sum generalized to the internal nodes of a tree, we improve the lower bound on C opt obtained in Section 3 by using the weaker (5). 3
Reference: [3] <author> P.J. Bayer, </author> <title> Improved bounds on the cost of optimal and balanced binary search trees, M.Sc. </title> <type> Thesis, </type> <institution> Mass.Inst.of Tech., </institution> <address> Cambridge, MA, </address> <year> 1975. </year>
Reference: [4] <author> R. De Prisco and A. De Santis, </author> <title> On binary search trees, </title> <journal> Information Processing Letters, </journal> <volume> 45, </volume> <month> (Apr </month> <year> 1993), </year> <pages> pp. 249-253. </pages>
Reference: [5] <author> E.N. Gilbert and E.F. Moore, </author> <title> Variable-length binary encodings, </title> <journal> Bell System Tech J. </journal> <volume> 38 (1959), </volume> <pages> pp. 933|968. </pages>
Reference: [6] <author> S.K. </author> <title> Leung-Yan-Cheong and T.M. Cover, Some equivalences between Shannon entropy and Kol-mogorv complexity, </title> <journal> IEEE Trans. Inf. Theory, </journal> <month> 24 (May </month> <year> 1978), </year> <pages> pp. 331-338. </pages>
Reference-contexts: The following bound is due to Rissanen [7] L 1:1 H S log log m: (3) We will use also the following bound due to Leung-Van-Cheong and Cover <ref> [6] </ref>, L 1:1 H S 2 log (H S + 2): (4) In Section 4 we utilize bounds better than (3) and (4) to improve our results. However, for the sake of simplicity in deriving the bounds we utilize (3) and (4). Finally, we recall the following results. kraft's equality.
Reference: [7] <author> J. Rissanen, </author> <title> Tight lower bounds for optimum code length, </title> <journal> IEEE Trans. Inf. Theory, </journal> <month> 18 (Mar </month> <year> 1982), </year> <pages> pp. 348-349. </pages>
Reference-contexts: The following bound is due to Rissanen <ref> [7] </ref> L 1:1 H S log log m: (3) We will use also the following bound due to Leung-Van-Cheong and Cover [6], L 1:1 H S 2 log (H S + 2): (4) In Section 4 we utilize bounds better than (3) and (4) to improve our results. <p> Utilizing this bound in Theorem 1, we can improve on (6). We can also get an improvement of bounds (11) and (13). In fact, in deriving these bounds we utilized (3). We can use the following bound, due to Rissanen <ref> [7] </ref>, that gives a sharper bound on the average codeword length L 1:1 of a one-to-one code for a source S of m letters whose entropy is H S where ff (m) = k (m) 1 + r (m)2 k (m) and k (m) is the maximum integer such that r
Reference: [8] <author> K. Mehlhorn, </author> <title> Nearly optimal binary search trees, </title> <journal> Acta Informatica 5, </journal> <year> (1975), </year> <pages> pp. 287-295. </pages>
Reference-contexts: Hence, throughout this paper we consider only optimal binary search trees. The entropy of the probability distribution D is 1 H = k=0 1 + k=1 1 : Mehlhorn <ref> [8] </ref> proved that C opt H= log 3 (1) and the smaller is H the tight is the bound. The above bound is expressed in terms of only the entropy of D. If other information on the probability distribution D are available, a better bound is known.
Reference: [9] <author> K. Mehlhorn, </author> <title> A best possible bound for the weighted path length of binary search trees, </title> <journal> SIAM J.Comput. </journal> <volume> 2, </volume> <year> (1977), </year> <pages> pp. 235-239. </pages>
Reference: [10] <author> E.I. Verriest, </author> <title> An achievable bound for optimal noiseless coding of a random variable, </title> <journal> IEEE Trans. Inf. Theory, </journal> <month> 32 (Jul </month> <year> 1986), </year> <pages> pp. 592-594. 11 </pages>
Reference-contexts: Moreover ff (m) &lt; log m. We can also improve on bounds (7) and (9) by using a bound better than (4). Actually, Verriest <ref> [10] </ref> proved that the average codeword length L 1:1 of a one-to-one code for a source S whose entropy is H S , is greater than or equal to the value L min given by the equation H S = L min 1 + H 1 and this limitation is the
References-found: 10

