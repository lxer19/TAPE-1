URL: ftp://db.stanford.edu/pub/papers/anomaly-full.ps
Refering-URL: http://www.cs.toronto.edu/~mendel/dwbib.html
Root-URL: 
Email: fzhuge,hector,joachim,widomg@cs.stanford.edu  
Title: View Maintenance in a Warehousing Environment  
Author: Yue Zhuge, Hector Garcia-Molina, Joachim Hammer, Jennifer Widom 
Keyword: I/O costs.  
Address: Stanford, CA 94305-2140, USA  
Affiliation: Computer Science Department Stanford University  
Abstract: A warehouse is a repository of integrated information drawn from remote data sources. Since a warehouse effectively implements materialized views, we must maintain the views as the data sources are updated. This view maintenance problem differs from the traditional one in that the view definition and the base data are now decoupled. We show that this decoupling can result in anomalies if traditional algorithms are applied. We introduce a new algorithm, ECA (for "Eager Compensating Algorithm"), that eliminates the anomalies. ECA is based on previous incremental view maintenance algorithms, but extra "compensating" queries are used to eliminate anomalies. We also introduce two streamlined versions of ECA for special cases of views and updates, and we present an initial performance study that compares ECA to a view recomputation algorithm in terms of messages transmitted, data transferred, and 
Abstract-found: 1
Intro-found: 1
Reference: [BLT86] <author> J.A. Blakeley, P.-A. Larson, and F.W. Tompa. </author> <title> Efficiently updating materialized views. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 61-71, </pages> <address> Washington, D.C., </address> <month> June </month> <year> 1986. </year>
Reference-contexts: Although we are using relational algebra, we assume that duplicates are retained in the materialized views. Duplicate retention (or at least a replication count) is essential if deletions are to be handled incrementally <ref> [BLT86, GMS93] </ref>. Note that the type of solution we propose here can be extended to other data models and view specification languages. Also, in the examples and in this paper we focus on a single source, and a single view over several base relations. <p> The answer it returns is A 1 = ; since both relations are now empty. 6. The warehouse receives A 1 and replaces the view by MV A 1 = ([1; 3]). (Difference is used here since the update to the base relation was a deletion <ref> [BLT86] </ref>.) 7. Similarly, the source evaluates Q 2 , returns A 2 = ;, and the warehouse replaces the view by MV A 2 = ([1; 3]). <p> Generalizing this idea, for a given view definition and a given update, it is possible to determine whether or not the update can be handled locally; see, e.g., <ref> [GB94, BLT86] </ref>. ECA L combines local handling of updates with the compensation approach for maintenance of arbitrary views. 1.3 Outline of Paper In the next section we briefly review related research. Then, in Section 3, we provide a formal definition of correctness for view maintenance in a warehousing environment. <p> These algorithms differ somewhat in the view definitions they handle. For example, <ref> [BLT86] </ref> considers select-project-join (SPJ) views only, while algorithms in [GMS93] handle views defined by any SQL or Datalog expression. Some algorithms depend on key information to deal with duplicate tuples [CW91], while others use a counting approach [GMS93]. <p> Note that although we describe our algorithms for SPJ views, our approach can be applied to adapt any existing centralized view maintenance algorithm to the warehousing environment. In both centralized and distributed systems, there are three general approaches to the timing of view maintenance: immediate update <ref> [BLT86] </ref>, which updates the view after each base relation is updated, deferred update [RK86], which updates the view only when a query is issued against the view, and periodic update [LHM + 86], which updates the view at periodic intervals. <p> once for each appearance of the relation). 4.1 Signs Our warehouse algorithms will handle two types of updates: insertions and deletions. (Modifi-cations must be treated as deletions followed by insertions, although extensions to our approach could permit modifications to be treated directly.) For convenience, we adopt an approach similar to <ref> [BLT86] </ref> and use signs on tuples: + to denote an inserted or an existing tuple, and to denote a deleted tuple. Tuple signs are propagated through relational operations, as we will illustrate. <p> ECA is an incremental view maintenance algorithm based on the centralized view maintenance algorithm described in <ref> [BLT86] </ref>. ECA anticipates the anomalies that arise due to the decoupling between base relation updates and view modification, and ECA compensates for the anomalies as needed to ensure correct view maintenance. <p> Before we present ECA and its extensions, we first review the original incremental view maintenance algorithm. 5.1 The Basic Algorithm The view maintenance algorithm described in <ref> [BLT86] </ref> applies incremental changes to a view each time changes are made to relevant base relations. <p> In ECA L , each update is handled either locally or non-locally. A number of papers, e.g., <ref> [BLT86, GB94, TB88] </ref>, describe conditions when, for a particular view definition and a particular base relation update, the view can be updated without further access to base relations (i.e., the view is autonomously computable, using the terminology of [BLT86]). <p> A number of papers, e.g., [BLT86, GB94, TB88], describe conditions when, for a particular view definition and a particular base relation update, the view can be updated without further access to base relations (i.e., the view is autonomously computable, using the terminology of <ref> [BLT86] </ref>). These results can be used to identify which updates ECA L will process locally. For updates that cannot be processed locally, ECA is used (assuming the key condition for ECA K does not hold), with compensating queries whenever necessary.
Reference: [CW91] <author> S. Ceri and J. Widom. </author> <title> Deriving production rules for incremental view maintenance. </title> <booktitle> In Proceedings of the Seventeenth International Conference on Very Large Data Bases, </booktitle> <pages> pages 577-589, </pages> <address> Barcelona, Spain, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: These algorithms differ somewhat in the view definitions they handle. For example, [BLT86] considers select-project-join (SPJ) views only, while algorithms in [GMS93] handle views defined by any SQL or Datalog expression. Some algorithms depend on key information to deal with duplicate tuples <ref> [CW91] </ref>, while others use a counting approach [GMS93]. A series of papers by Segev et al. studies materialized views in distributed systems [SF90, SF91, SP89a, SP89b]. All algorithms in these papers are based on timestamping the updated tuples, and the algorithms assume there is only one base table.
Reference: [GB94] <author> Ashish Gupta and J. A. Blakeley. </author> <title> Updating materialized views using the view contents and the update. In unpublished document, </title> <year> 1994. </year>
Reference-contexts: Generalizing this idea, for a given view definition and a given update, it is possible to determine whether or not the update can be handled locally; see, e.g., <ref> [GB94, BLT86] </ref>. ECA L combines local handling of updates with the compensation approach for maintenance of arbitrary views. 1.3 Outline of Paper In the next section we briefly review related research. Then, in Section 3, we provide a formal definition of correctness for view maintenance in a warehousing environment. <p> In ECA L , each update is handled either locally or non-locally. A number of papers, e.g., <ref> [BLT86, GB94, TB88] </ref>, describe conditions when, for a particular view definition and a particular base relation update, the view can be updated without further access to base relations (i.e., the view is autonomously computable, using the terminology of [BLT86]).
Reference: [GMS93] <author> A. Gupta, I. Mumick, and V. Subrahmanian. </author> <title> Maintaining views incrementally. </title> <booktitle> In Preceedings of the 1993 ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 157-166, </pages> <address> Washington, D.C., </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Although we are using relational algebra, we assume that duplicates are retained in the materialized views. Duplicate retention (or at least a replication count) is essential if deletions are to be handled incrementally <ref> [BLT86, GMS93] </ref>. Note that the type of solution we propose here can be extended to other data models and view specification languages. Also, in the examples and in this paper we focus on a single source, and a single view over several base relations. <p> These algorithms differ somewhat in the view definitions they handle. For example, [BLT86] considers select-project-join (SPJ) views only, while algorithms in <ref> [GMS93] </ref> handle views defined by any SQL or Datalog expression. Some algorithms depend on key information to deal with duplicate tuples [CW91], while others use a counting approach [GMS93]. A series of papers by Segev et al. studies materialized views in distributed systems [SF90, SF91, SP89a, SP89b]. <p> These algorithms differ somewhat in the view definitions they handle. For example, [BLT86] considers select-project-join (SPJ) views only, while algorithms in <ref> [GMS93] </ref> handle views defined by any SQL or Datalog expression. Some algorithms depend on key information to deal with duplicate tuples [CW91], while others use a counting approach [GMS93]. A series of papers by Segev et al. studies materialized views in distributed systems [SF90, SF91, SP89a, SP89b]. All algorithms in these papers are based on timestamping the updated tuples, and the algorithms assume there is only one base table.
Reference: [GW94] <author> P. Grefen and J. Widom. </author> <title> Integrity constraint checking in federated databases. </title> <note> Submitted for publication, </note> <year> 1994. </year>
Reference-contexts: While fragmenting itself does not pose a novel problem (at least in the straightforward relational case), coordinating the query results and the necessary compensations for anomaly-causing updates may require some intricate algorithms. We expect that the protocols reported in <ref> [GW94] </ref> for evaluating constraints in loosely-coupled databases may prove to be useful for extending ECA to the multi-site case. * We will consider how ECA can be extended to handle a set of updates at once, rather than one update at a time.
Reference: [Han87] <author> E.N. Hanson. </author> <title> A performance analysis of view materialization strategies. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 440-453, </pages> <year> 1987. </year>
Reference-contexts: Performance studies on these strategies have determined that the efficiency of an approach depends heavily on the structure of the base relations and on update patterns <ref> [Han87] </ref>.
Reference: [HD92] <author> J.V. Harrison and S.W. Dietrich. </author> <title> Maintenance of materialized views in a deductive database: An update propagation approach. </title> <booktitle> In Proceedings of the 1992 JICLSP Workshop on Deductive Databases, </booktitle> <pages> pages 56-65, </pages> <year> 1992. </year>
Reference-contexts: Most of them are designed for a traditional, centralized database environment, where it is assumed that view maintenance is performed by a system that has full control and knowledge of the view definition, the base relations, the updated tuples, and the view <ref> [HD92, QW91, SI84] </ref>. These algorithms differ somewhat in the view definitions they handle. For example, [BLT86] considers select-project-join (SPJ) views only, while algorithms in [GMS93] handle views defined by any SQL or Datalog expression.
Reference: [IK93] <author> W.H. Inmon and C. Kelley. Rdb/VMS: </author> <title> Developing the Data Warehouse. </title> <publisher> QED Publishing Group, </publisher> <address> Boston, London, Toronto, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction Warehousing is an emerging technique for retrieval and integration of data from distributed, autonomous, possibly heterogeneous, information sources. A data warehouse is a repository of integrated information, available for queries and analysis (e.g., decision support, or data mining) <ref> [IK93] </ref>. As relevant information becomes available from a source, or when relevant information is modified, the information is extracted from the source, translated into a common model (e.g., the relational model), and integrated with existing data at the warehouse.
Reference: [LHM + 86] <author> B. Lindsay, L.M. Haas, C. Mohan, H. Pirahesh, and P. Wilms. </author> <title> A snapshot differential refresh algorithm. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <address> Washington, D.C., </address> <month> May </month> <year> 1986. </year>
Reference-contexts: A series of papers by Segev et al. studies materialized views in distributed systems [SF90, SF91, SP89a, SP89b]. All algorithms in these papers are based on timestamping the updated tuples, and the algorithms assume there is only one base table. Other incremental algorithms, such as the "snapshot" procedure in <ref> [LHM + 86] </ref>, also assume timestamping and a single base table. In contrast, our algorithms have no restrictions on the number of base tables, and they require no additional information. <p> In both centralized and distributed systems, there are three general approaches to the timing of view maintenance: immediate update [BLT86], which updates the view after each base relation is updated, deferred update [RK86], which updates the view only when a query is issued against the view, and periodic update <ref> [LHM + 86] </ref>, which updates the view at periodic intervals. Performance studies on these strategies have determined that the efficiency of an approach depends heavily on the structure of the base relations and on update patterns [Han87].
Reference: [QW91] <author> X. Qian and G. Wiederhold. </author> <title> Incremental recomputation of active relational expressions. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 3(3) </volume> <pages> 337-341, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: Most of them are designed for a traditional, centralized database environment, where it is assumed that view maintenance is performed by a system that has full control and knowledge of the view definition, the base relations, the updated tuples, and the view <ref> [HD92, QW91, SI84] </ref>. These algorithms differ somewhat in the view definitions they handle. For example, [BLT86] considers select-project-join (SPJ) views only, while algorithms in [GMS93] handle views defined by any SQL or Datalog expression.
Reference: [RK86] <author> N. Roussopoulos and H. Kang. </author> <title> Preliminary design of ADMS+-: A workstation-mainframe integrated architecture for database management systems. </title> <booktitle> In Proceedings of the Twelfth International Conference on Very Large Data Bases, </booktitle> <pages> pages 355-364, </pages> <address> Kyoto, Japan, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: In both centralized and distributed systems, there are three general approaches to the timing of view maintenance: immediate update [BLT86], which updates the view after each base relation is updated, deferred update <ref> [RK86] </ref>, which updates the view only when a query is issued against the view, and periodic update [LHM + 86], which updates the view at periodic intervals.
Reference: [SF90] <author> A. Segev and W. Fang. </author> <title> Currency-based updates to distributed materialized views. </title> <booktitle> In Pro ceedings of the Sixth International Conference on Data Engineering, </booktitle> <pages> pages 512-520, </pages> <address> Los Alamitos, </address> <month> February </month> <year> 1990. </year>
Reference-contexts: Some algorithms depend on key information to deal with duplicate tuples [CW91], while others use a counting approach [GMS93]. A series of papers by Segev et al. studies materialized views in distributed systems <ref> [SF90, SF91, SP89a, SP89b] </ref>. All algorithms in these papers are based on timestamping the updated tuples, and the algorithms assume there is only one base table. Other incremental algorithms, such as the "snapshot" procedure in [LHM + 86], also assume timestamping and a single base table.
Reference: [SF91] <author> A. Segev and W. Fang. </author> <title> Optimal update policies for distributed materialized views. </title> <journal> Man agement Science, </journal> <volume> 37(7) </volume> <pages> 851-70, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Some algorithms depend on key information to deal with duplicate tuples [CW91], while others use a counting approach [GMS93]. A series of papers by Segev et al. studies materialized views in distributed systems <ref> [SF90, SF91, SP89a, SP89b] </ref>. All algorithms in these papers are based on timestamping the updated tuples, and the algorithms assume there is only one base table. Other incremental algorithms, such as the "snapshot" procedure in [LHM + 86], also assume timestamping and a single base table.
Reference: [SI84] <author> O. Shmueli and A. Itai. </author> <title> Maintenance of views. </title> <booktitle> In Proceedings of the ACM SIGMOD Inter national Conference on Management of Data, </booktitle> <pages> pages 240-255, </pages> <address> Boston, Massachusetts, </address> <month> May </month> <year> 1984. </year>
Reference-contexts: Most of them are designed for a traditional, centralized database environment, where it is assumed that view maintenance is performed by a system that has full control and knowledge of the view definition, the base relations, the updated tuples, and the view <ref> [HD92, QW91, SI84] </ref>. These algorithms differ somewhat in the view definitions they handle. For example, [BLT86] considers select-project-join (SPJ) views only, while algorithms in [GMS93] handle views defined by any SQL or Datalog expression.
Reference: [SP89a] <author> A. Segev and J. Park. </author> <title> Maintaining materialized views in distributed databases. </title> <booktitle> In Proceed ings of the Fifth International Conference on Data Engineering, </booktitle> <pages> pages 262-70, </pages> <address> Los Angeles, </address> <month> February </month> <year> 1989. </year> <month> 22 </month>
Reference-contexts: Some algorithms depend on key information to deal with duplicate tuples [CW91], while others use a counting approach [GMS93]. A series of papers by Segev et al. studies materialized views in distributed systems <ref> [SF90, SF91, SP89a, SP89b] </ref>. All algorithms in these papers are based on timestamping the updated tuples, and the algorithms assume there is only one base table. Other incremental algorithms, such as the "snapshot" procedure in [LHM + 86], also assume timestamping and a single base table.
Reference: [SP89b] <author> A. Segev and J. Park. </author> <title> Updating distributed materialized views. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 1(2) </volume> <pages> 173-184, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Some algorithms depend on key information to deal with duplicate tuples [CW91], while others use a counting approach [GMS93]. A series of papers by Segev et al. studies materialized views in distributed systems <ref> [SF90, SF91, SP89a, SP89b] </ref>. All algorithms in these papers are based on timestamping the updated tuples, and the algorithms assume there is only one base table. Other incremental algorithms, such as the "snapshot" procedure in [LHM + 86], also assume timestamping and a single base table.
Reference: [TB88] <author> F.WM. Tompa and J.A. Blakeley. </author> <title> Maintaining materialized views without accessing base data. </title> <journal> Information Systems, </journal> <volume> 13(4) </volume> <pages> 393-406, </pages> <year> 1988. </year>
Reference-contexts: In ECA L , each update is handled either locally or non-locally. A number of papers, e.g., <ref> [BLT86, GB94, TB88] </ref>, describe conditions when, for a particular view definition and a particular base relation update, the view can be updated without further access to base relations (i.e., the view is autonomously computable, using the terminology of [BLT86]).
Reference: [ZGMHW94] <author> Y. Zhuge, H. Garcia-Molina, J. Hammer, and J. Widom. </author> <title> View maintenance in a warehousing environment. </title> <type> Technical report, </type> <institution> Stanford University, </institution> <month> October </month> <year> 1994. </year> <note> Available via anonymous ftp from host db.stanford.edu as pub/zhuge/1994/anomaly-full.ps. 23 </note>
References-found: 18

