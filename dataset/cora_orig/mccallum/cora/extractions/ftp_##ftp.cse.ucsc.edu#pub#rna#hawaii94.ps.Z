URL: ftp://ftp.cse.ucsc.edu/pub/rna/hawaii94.ps.Z
Refering-URL: http://www.cse.ucsc.edu/research/compbio/scfg.html
Root-URL: http://www.cse.ucsc.edu
Email: email: haussler@cse.ucsc.edu  
Title: Stochastic Context-Free Grammars for Modeling RNA  
Author: Yasubumi Sakakibara yz Michael Brown Rebecca C. Underwood I. Saira Mian David Haussler 
Keyword: Stochastic Context-Free Grammar, RNA, Transfer RNA, Multiple Sequence Alignments, Database Searching.  
Note: present address: ISIS,  
Address: Santa Cruz, CA 95064, USA.  410-03, Japan.  
Affiliation: Computer and Information Sciences Sinsheimer Laboratories University of California,  Fujitsu Labs Ltd., 140, Miyamoto, Numazu, Shizuoka  
Abstract: Stochastic context-free grammars (SCFGs) are used to fold, align and model a family of homologous RNA sequences. SCFGs capture the sequences' common primary and secondary structure and generalize the hidden Markov models (HMMs) used in related work on protein and DNA. The novel aspect of this work is that SCFG parameters are learned automatically from unaligned, unfolded training sequences. A generalization of the HMM forward-backward algorithm is introduced. The new algorithm, based on tree grammars and faster than the previously proposed SCFG inside-outside algorithm, is tested on the transfer RNA (tRNA) family. Results show the model can discern tRNA from similar-length RNA sequences, can find secondary structure of new tRNA sequences, and can give multiple alignments of large sets of tRNA sequences. The model is extended to handle introns in tRNA. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. V. Aho and J. D. Ullman. </author> <title> The Theory of Parsing, Translation and Compiling,Vol. I: Parsing. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1972. </year>
Reference-contexts: However, a dynamic programming technique analogous to the Cocke-Kasami-Young or Early methods <ref> [1] </ref> for non-stochastic CFGs can accomplish this task efficiently (in time proportional to the cube of the length of s). We define the negative logarithm of the probability of a sequence given by the grammar, log (Prob (s j G)), as the negative log likelihood (NLL) score of the sequence.
Reference: [2] <author> J. K. Baker. </author> <title> Trainable grammars for speech recognition. </title> <booktitle> Speech Communication Papers for the 97th Meeting of the Acoustical Society of America, </booktitle> <pages> pages 547-550, </pages> <year> 1979. </year>
Reference-contexts: If we specify a probability for each production in a grammar, we obtain a stochastic grammar. A stochastic grammar assigns a probability to each string it derives. Stochastic regular grammars are equivalent to HMMs and suggest an interesting generalization from HMMs to stochastic context-free grammars <ref> [2] </ref>. In this paper, we pursue a stochastic model of the family of transfer RNAs (tRNAs) by using a SCFG that is similar to our protein HMMs [14] but that incorporates base-pairing information. <p> Our algorithm is based on tree grammars, and is more efficient than the inside-outside algorithm [17], a computationally expensive generalization of the forward-backward algorithm developed to train SCFGs <ref> [2] </ref>. We use our algorithm to derive a trained grammar from a training set of tRNA sequences. <p> This algorithm is more efficient than the inside-outside algorithm, which was previously proposed to train SCFGs. The inside-outside algorithm <ref> [17, 2] </ref> is an EM algorithm to reestimate a SCFG's parameters. However, it requires the grammar to be in Chomsky normal form, which is possible but inconvenient for modeling RNA (and requires more nontermi-nals).
Reference: [3] <author> P. Baldi, Y. Chauvin, T. Hunkapiller, and M. A. McClure. </author> <title> Hidden Markov models in molecular biology: new algorithms and applications. </title> <editor> In Hanson, Cowan, and Giles, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 5, </booktitle> <pages> pages 747-754, </pages> <address> San Mateo, CA, 1993. </address> <publisher> Morgan Kauffmann Publishers. </publisher>
Reference-contexts: Rapid generation of sequence data in recent years thus provides abundant opportunities for developing new approaches, such as hidden Markov models (HMMs), to problems in computational biology <ref> [15, 5, 20, 10, 14, 3, 4] </ref>.
Reference: [4] <author> L. R. Cardon and G. D. Stormo. </author> <title> Expectation maximization algorithm for identifying protein-binding sites with variable lengths from unaligned DNA fragments. </title> <journal> Journal of Molecular Biology, </journal> <volume> 223 </volume> <pages> 159-170, </pages> <year> 1992. </year>
Reference-contexts: Rapid generation of sequence data in recent years thus provides abundant opportunities for developing new approaches, such as hidden Markov models (HMMs), to problems in computational biology <ref> [15, 5, 20, 10, 14, 3, 4] </ref>.
Reference: [5] <author> G. A. Churchill. </author> <title> Stochastic models for heterogeneous DNA sequences. </title> <journal> Bull Math Biol, </journal> <volume> 51 </volume> <pages> 79-94, </pages> <year> 1989. </year>
Reference-contexts: Rapid generation of sequence data in recent years thus provides abundant opportunities for developing new approaches, such as hidden Markov models (HMMs), to problems in computational biology <ref> [15, 5, 20, 10, 14, 3, 4] </ref>.
Reference: [6] <author> S. R. Eddy and R. </author> <title> Durbin. Analysis of RNA sequence families using adaptive statistical models. </title> <type> Unpublished, </type> <year> 1993. </year>
Reference-contexts: Having done this, it would be straightforward to modify the grammar to account for this base pairing, and then iterate this process until no new structure is found. This process would essentially automate some of the hand methods originally used in phylogenetic analysis of tRNA. (See <ref> [6] </ref> for a related approach.) Finally, there is the question of what further generalizations of hidden Markov models, beyond SCFGs, might be useful. The key advantage of our method over the HMM method is that it allows us to explicitly deal with the secondary structure of the RNA sequence. <p> By extending stochastic models of strings to stochastic models of trees, we can model the base-pairing interactions of the molecule, 4 Independently of the work described here, Eddy and Durbin <ref> [6] </ref> have recently described a class of adaptive statistical models that simultaneously capture both primary sequence and secondary structure consensus features of a family of RNA sequences. &lt; D arm &gt; &lt; Anticodon arm &gt;&lt; Extra arm &gt;&lt; T arm &gt; ((((((( (((( )))) ((((( === ))))) ((((( )))))))))))) GCCCGGCUAGCUCAGUC-GGU--AGAGCAUGAGACUCUUAAUCUCAGG---------GUCGUGGGUUCGAGCCCCACGUUGGGCG GCGAAGGUGGCGGAAUU-GGUA-GACGCGCUAGCUUCAGGUGUUAGU-GUCCUUACGGACG-UGGGGGUUCAAGUCCCCCCCCUCGCA
Reference: [7] <author> J. Engelfriet and G. Rozenberg. </author> <title> Graph grammars based on node rewriting: An introduction to NLC graph grammars. </title> <editor> In E. Ehrig, H. Kreowski, and G. Rozenberg, editors, </editor> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> volume 532, </volume> <pages> pages 12-23. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: This progression is similar to the path taken by the late King Sun Fu and colleagues in their development of the field of syntactic pattern recognition [8]. Modeling higher-order structure would require still more general methods. One possibility would be to consider stochastic graph grammars (e.g., <ref> [7] </ref>) in hopes of obtaining a more general model of the interactions present in the molecule beyond the primary structure.
Reference: [8] <author> K. S. Fu. </author> <title> Syntactic pattern recognition and applications. </title> <publisher> Prentice-Hall, </publisher> <year> 1982. </year>
Reference-contexts: Abbreviations are "()" for base-paired columns; "===", anticodon domain; ".", fill characters; and "-", deletions by skip productions. which determine its secondary structure. This progression is similar to the path taken by the late King Sun Fu and colleagues in their development of the field of syntactic pattern recognition <ref> [8] </ref>. Modeling higher-order structure would require still more general methods. One possibility would be to consider stochastic graph grammars (e.g., [7]) in hopes of obtaining a more general model of the interactions present in the molecule beyond the primary structure.
Reference: [9] <author> R. R. Gutell, A. Power, G. Z. Hertz, E. J. Putz, and G. D. Stormo. </author> <title> Identifying constraints on the higher-order structure of RNA: continued development and application of comparative sequence analysis methods. </title> <journal> Nucleic Acids Research, </journal> <volume> 20 </volume> <pages> 5785-5795, </pages> <year> 1992. </year>
Reference-contexts: Then, by studying multiple alignments produced by this grammar, we might be able to apply methods for finding correlations between columns in this multiple alignment, such as those in <ref> [9, 16, 13, 28, 29, 23, 27] </ref>, to discover some of the base-pairing structure in tRNA. Having done this, it would be straightforward to modify the grammar to account for this base pairing, and then iterate this process until no new structure is found.
Reference: [10] <author> D. Haussler, A. Krogh, I. S. Mian, and K. Sjolander. </author> <title> Protein modeling using hidden Markov models: Analysis of globins. </title> <booktitle> In Proceedings of the Hawaii International Conference on System Sciences, </booktitle> <address> Los Alamitos, CA, 1993. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Rapid generation of sequence data in recent years thus provides abundant opportunities for developing new approaches, such as hidden Markov models (HMMs), to problems in computational biology <ref> [15, 5, 20, 10, 14, 3, 4] </ref>. <p> In this paper, in an approach highly related to our work on modeling protein families with HMMs <ref> [10, 14] </ref>, we apply stochastic context-free grammars (SCFGs) to the problems of statistical modeling, database searching, multiple align ment, and prediction of the secondary structure of RNA families. RNA is mostly involved in the biological machinery that expresses the genetic information from DNA to protein. <p> Our method of multiple alignment and folding differs markedly from the conventional techniques because it builds a statistical model during rather than after the process of alignment and folding. Such an approach has been applied successfully to modeling protein families with HMMs <ref> [10, 14] </ref>. Though in principle HMMs could be used for RNA, we strongly suspect that the more general statistical models described here will be required.
Reference: [11] <author> J. A. Jaeger, D. H. Turner, and M. Zuker. </author> <title> Predicting optimal and suboptimal secondary structure for RNA. </title> <booktitle> Methods in Enzymology, </booktitle> <volume> 183 </volume> <pages> 281-306, </pages> <year> 1990. </year>
Reference-contexts: Phyloge-netic analysis for homologous RNA molecules re lies on alignment and subsequent folding of many sequences into similar structures (reviewed in [12, 30]). Energy minimization depends on thermodynamic parameters and computer algorithms to evaluate the optimal and suboptimal free energy folding of an RNA species (reviewed in <ref> [11, 31] </ref>). Our method of multiple alignment and folding differs markedly from the conventional techniques because it builds a statistical model during rather than after the process of alignment and folding. Such an approach has been applied successfully to modeling protein families with HMMs [10, 14].
Reference: [12] <author> B. D. James, G. J. Olsen, and N. R. </author> <title> Pace. Phyloge-netic comparative analysis of RNA secondary structure. </title> <booktitle> Methods in Enzymology, </booktitle> <volume> 180 </volume> <pages> 227-239, </pages> <year> 1989. </year>
Reference-contexts: Currently, there are two principal methods for predicting secondary structure of RNA. Phyloge-netic analysis for homologous RNA molecules re lies on alignment and subsequent folding of many sequences into similar structures (reviewed in <ref> [12, 30] </ref>). Energy minimization depends on thermodynamic parameters and computer algorithms to evaluate the optimal and suboptimal free energy folding of an RNA species (reviewed in [11, 31]).
Reference: [13] <author> T. Klinger and D. Brutlag. </author> <title> Detection of correlations in tRNA sequences with structural implications. </title> <editor> In L. Hunter, D. Searls, and J. Shavlik, editors, </editor> <booktitle> First International Conference on Intelligent Systems for Molecular Biology, </booktitle> <address> Menlo Park, 1993. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Then, by studying multiple alignments produced by this grammar, we might be able to apply methods for finding correlations between columns in this multiple alignment, such as those in <ref> [9, 16, 13, 28, 29, 23, 27] </ref>, to discover some of the base-pairing structure in tRNA. Having done this, it would be straightforward to modify the grammar to account for this base pairing, and then iterate this process until no new structure is found.
Reference: [14] <author> A. Krogh, M. Brown, I. S. Mian, K. Sjolander, and D. Haussler. </author> <title> Hidden Markov models in computational biology: Applications to protein modeling. </title> <journal> Journal of Molecular Biology, </journal> <note> 1993. In press. </note>
Reference-contexts: Rapid generation of sequence data in recent years thus provides abundant opportunities for developing new approaches, such as hidden Markov models (HMMs), to problems in computational biology <ref> [15, 5, 20, 10, 14, 3, 4] </ref>. <p> In this paper, in an approach highly related to our work on modeling protein families with HMMs <ref> [10, 14] </ref>, we apply stochastic context-free grammars (SCFGs) to the problems of statistical modeling, database searching, multiple align ment, and prediction of the secondary structure of RNA families. RNA is mostly involved in the biological machinery that expresses the genetic information from DNA to protein. <p> Our method of multiple alignment and folding differs markedly from the conventional techniques because it builds a statistical model during rather than after the process of alignment and folding. Such an approach has been applied successfully to modeling protein families with HMMs <ref> [10, 14] </ref>. Though in principle HMMs could be used for RNA, we strongly suspect that the more general statistical models described here will be required. <p> Stochastic regular grammars are equivalent to HMMs and suggest an interesting generalization from HMMs to stochastic context-free grammars [2]. In this paper, we pursue a stochastic model of the family of transfer RNAs (tRNAs) by using a SCFG that is similar to our protein HMMs <ref> [14] </ref> but that incorporates base-pairing information. Here we build a SCFG forming a statistical model of tRNA sequences in much the same way that we constructed an HMM representing a statistical model of a protein family. <p> AAGAUCUCUUG, the grammar whose productions are given in Figure 1 yields this parse tree. This parse tree reflects a specific sec ondary structure. As in the protein HMM of <ref> [14] </ref>, we distinguish two different types of nonterminals: match and insert. The match nonterminals in a grammar correspond to important structural positions in an RNA or columns in a multiple alignment. These constitute the main line of the grammar. <p> One solution is to control the effective number of free parameters by regularization. We calculated a regularizer from the multiple alignment of tRNA sequences and added it to the counts used for reestimating the grammar's production probabilities in each iteration of training. Similar methods are described in <ref> [14] </ref>. 2.5 Using the new EM algorithm Since our EM training algorithm uses folded RNA as training examples, rather than unfolded ones, the base pairs in each training sequence need to be identified before the EM iteration begins. <p> The run time was around 10 CPU minutes on a Sun Sparcstation 10/30. During this process, only the probabilities of the productions were reestimated and no nonterminals or productions were added or deleted (unlike "model surgery" in <ref> [14] </ref>). Our future work will focus on developing a method that can automatically select a good structure and a good length of the grammar while training. 3.1 Data The experiments used data from three sources: 1. <p> This raw NLL score depends too much on the test sequence's length to be used directly to decide whether a sequence belongs to the family modeled by the grammar. We overcome this problem by normalizing the NLL score <ref> [14] </ref>. We calculate the difference between the NLL score of a sequence and the average NLL score of a typical non-tRNA sequence of same length, measured in standard deviations. This number is called the Z score for the sequence. <p> As described in Section 2.5, we could then try to gradually extend the grammar to account for the structure of the training sequences. 4 We might do this by starting with a regular grammar that represents an HMM like those we used to model protein families <ref> [14] </ref>. Then, by studying multiple alignments produced by this grammar, we might be able to apply methods for finding correlations between columns in this multiple alignment, such as those in [9, 16, 13, 28, 29, 23, 27], to discover some of the base-pairing structure in tRNA.
Reference: [15] <author> E. S. Lander and P. Green. </author> <title> Construction of multi-locus genetic linkage maps in humans. </title> <booktitle> Proceedings of the National Academy of Sciences of the United States of America, </booktitle> <volume> 84 </volume> <pages> 2363-2367, </pages> <year> 1987. </year>
Reference-contexts: Rapid generation of sequence data in recent years thus provides abundant opportunities for developing new approaches, such as hidden Markov models (HMMs), to problems in computational biology <ref> [15, 5, 20, 10, 14, 3, 4] </ref>.
Reference: [16] <author> A. </author> <title> Lapedes. </title> <type> Private communication, </type> <year> 1992. </year>
Reference-contexts: Then, by studying multiple alignments produced by this grammar, we might be able to apply methods for finding correlations between columns in this multiple alignment, such as those in <ref> [9, 16, 13, 28, 29, 23, 27] </ref>, to discover some of the base-pairing structure in tRNA. Having done this, it would be straightforward to modify the grammar to account for this base pairing, and then iterate this process until no new structure is found.
Reference: [17] <author> K. Lari and S. J. Young. </author> <title> The estimation of stochastic context-free grammars using the inside-outside algorithm. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 4 </volume> <pages> 35-56, </pages> <year> 1990. </year>
Reference-contexts: Here, we attempt to "learn" the parameters entirely automatically from a set of unaligned primary sequences with a novel generalization of the forward-backward algorithm commonly used to train HMMs. Our algorithm is based on tree grammars, and is more efficient than the inside-outside algorithm <ref> [17] </ref>, a computationally expensive generalization of the forward-backward algorithm developed to train SCFGs [2]. We use our algorithm to derive a trained grammar from a training set of tRNA sequences. <p> This algorithm is more efficient than the inside-outside algorithm, which was previously proposed to train SCFGs. The inside-outside algorithm <ref> [17, 2] </ref> is an EM algorithm to reestimate a SCFG's parameters. However, it requires the grammar to be in Chomsky normal form, which is possible but inconvenient for modeling RNA (and requires more nontermi-nals).
Reference: [18] <author> G. J. Olsen, R. Overbeek, N. Larsen, T. L. Mars-hand, M. J. McCaughey, M. A. Maciukenas, W. M. Kuan, T. J. Macke, Y. Xing, and C. R. Woese. </author> <title> The ribosomal database project. </title> <journal> Nucleic Acids Research, </journal> <volume> 20 </volume> <pages> 2199-2000, </pages> <year> 1992. </year>
Reference-contexts: Of these 1477 sequence descriptions, we selected 500 at random as training examples for deriving a grammar to model intron-free tRNA, and used the rest as test data. 2. The Ribosomal Database Project's (RDP) <ref> [18] </ref> aligned, folded large-subunit ribosomal RNA data file LSU.aln provided our primary source of non-tRNA sequences. We generated approximately 2400 non-tRNA sequences by cutting ribosomal RNA sequences into pieces of approximately the same lengths as tRNA sequences. 3.
Reference: [19] <author> E. M. Phizicky and C. L. </author> <title> Greer. Pre-tRNA splicing: variation on a theme or exception to the rule? Trends in Biochemical Sciences, </title> <booktitle> 18 </booktitle> <pages> 31-34, </pages> <year> 1993. </year>
Reference-contexts: Use the trained grammar to obtain more accurately folded training sequences and reestimate the SCFG using these. 4. Repeat Step 3 until the trained grammar gives no changes to the folding. 2.6 Dealing with introns Introns are normally present in the anticodon stem loop (reviewed in <ref> [19] </ref>).
Reference: [20] <author> L. R. Rabiner. </author> <title> A tutorial on hidden Markov models and selected applications in speech recognition. </title> <journal> Proc IEEE, </journal> <volume> 77(2) </volume> <pages> 257-286, </pages> <year> 1989. </year>
Reference-contexts: Rapid generation of sequence data in recent years thus provides abundant opportunities for developing new approaches, such as hidden Markov models (HMMs), to problems in computational biology <ref> [15, 5, 20, 10, 14, 3, 4] </ref>. <p> To obtain the most likely parse tree for the sequence s, we calculate max parse trees d Prob (S 0 d The dynamic-programming procedure to do this resembles the Viterbi algorithm for HMMs <ref> [20] </ref>.
Reference: [21] <author> Y. Sakakibara, M. Brown, R. Hughey, I. S. Mian, K. Sjolander, R. Underwood, and D. Haussler. </author> <title> The application of stochastic context-free grammars to folding, aligning and modeling homologous RNA sequences. </title> <note> In preparation, </note> <year> 1993. </year>
Reference-contexts: For each tRNA, there are five non-tRNA sequences of the same length. Figure 4 shows Z scores computed by the trained grammar. The lowest Z score 3 Certain tRNAs lack some arms (e.g., mitochondrial tRNA may have only three loops) and we model these irregular tRNAs in <ref> [21] </ref>. of tRNAs is 5.464 and the highest Z score of non-tRNAs is 4.517. <p> The grammar completely failed to identify introns for four sequences. Thus, this approach shows some promise in identifying in-trons and finding the correct secondary structure for tRNAs with introns. Further work is discussed in <ref> [21] </ref>. 4 Discussion The method we have proposed represents a significant new direction in computational biosequence analysis. We believe SCFGs may provide a flexible and highly effective statistical method in a number of problems for RNA sequences including database searching, multiple alignment, prediction of secondary structures, and locating introns.
Reference: [22] <author> Y. Sakakibara, M. Brown, R. Underwood, I. S. Mian, and D. Haussler. </author> <title> Stochastic context-free grammars for modeling RNA. </title> <type> Technical Report UCSC-CRL-93-16, </type> <institution> University of California at Santa Cruz, Computer Science, UC Santa Cruz, </institution> <address> CA 95064, </address> <year> 1993. </year>
Reference-contexts: We use this model to search a database for tRNA-like sequences and to obtain a multiple alignment in the same manner as for proteins. We also use the model to fold unfolded tRNA sequences, i.e., to determine the base pairing that defines their secondary structure. In preliminary work <ref> [22] </ref>, we derived a SCFG's parameters directly from an existing alignment of tRNA sequences to see how well the SCFG could model an RNA family. <p> each sequence by finding the most likely parse tree, after which the mutual alignment of the sequences among themselves is determined. 2.3 Estimating SCFGs from sequences To determine how well SCFGs could model a family of RNA sequences, we first developed a SCFG from an existing alignment of tRNA sequences <ref> [22] </ref>. Our next goal was to "learn" the grammar parameters (probabilities of productions) automatically. Estimation Maximization (EM) training algorithm To estimate the SCFG parameters from unaligned training tRNA sequences, we introduce a new method for training SCFGs that is a generalization of the forward-backward algorithm commonly used to train HMMs. <p> The new algorithm also tends to converge faster because each training example is much more informative. For a detailed discussion of the algorithm, see <ref> [22] </ref>. 2.4 Overfitting and regularization A grammar with too many free parameters cannot be estimated well from a relatively small set of training sequences.
Reference: [23] <author> D. Sankoff. </author> <title> Simultaneous solution of the RNA folding, alignment and protosequence problems. </title> <journal> SIAM J. Appl. Math., </journal> <volume> 45 </volume> <pages> 810-825, </pages> <year> 1985. </year>
Reference-contexts: Thus, the elucidation of common folding patterns among two or more sequences may indicate the pertinent regions to be aligned and vice versa <ref> [23] </ref>. Currently, there are two principal methods for predicting secondary structure of RNA. Phyloge-netic analysis for homologous RNA molecules re lies on alignment and subsequent folding of many sequences into similar structures (reviewed in [12, 30]). <p> Then, by studying multiple alignments produced by this grammar, we might be able to apply methods for finding correlations between columns in this multiple alignment, such as those in <ref> [9, 16, 13, 28, 29, 23, 27] </ref>, to discover some of the base-pairing structure in tRNA. Having done this, it would be straightforward to modify the grammar to account for this base pairing, and then iterate this process until no new structure is found.
Reference: [24] <author> D. B. </author> <title> Searls. The linguistics of DNA. </title> <journal> American Scientist, </journal> <volume> 80 </volume> <pages> 579-591, </pages> <address> Nov.-Dec. </address> <year> 1992. </year>
Reference-contexts: Here we describe a means to generalize HMMs to model most of the interactions seen in RNA using formal language theory. As in the elegant work of Searls <ref> [24] </ref>, we view the strings of characters representing pieces of DNA, RNA and protein as sentences derived from a formal grammar. <p> Using productions of this type, a CFG can specify the language of biological palindromes. Searls <ref> [24] </ref> argues the benefits of using context-free grammars as models for RNA folding, but does not discuss methods for estimating the grammar from training sequences. One purpose of this paper is to provide an effective method for estimating a stochastic context-free grammar to model a family of RNA sequences.
Reference: [25] <author> B. A. Shapiro and K. Zhang. </author> <title> Comparing multiple RNA secondary structures using tree comparisons. </title> <journal> CABIOS, </journal> <volume> 6(4) </volume> <pages> 309-318, </pages> <year> 1990. </year>
Reference-contexts: Our algorithm, a different EM method, is based on the theory of stochastic tree grammars. Tree grammars are used to derive labeled trees instead of strings. Labeled trees can be used to represent the secondary structure of RNA easily <ref> [25] </ref> (see Figure 2). When working with a tree grammar for RNA, one is explicitly working with both the primary sequence and the secondary structure of each molecule.
Reference: [26] <author> S. Steinberg, A. Misch, and M. Sprinzl. </author> <title> Compilation of tRNA sequences and sequences of tRNA genes. </title> <journal> Nucleic Acids Research, </journal> <volume> 21(13) </volume> <pages> 3011-3015, </pages> <year> 1993. </year>
Reference-contexts: For our training set, we choose 500 unfolded and unaligned sequences at random from 1477 tRNA sequences in the 1993 generated when a single-stranded loop region forms standard Watson-Crick base pairs with a complementary sequence outside the loop. compilation of aligned tRNA sequences <ref> [26] </ref> main-tained by EMBL Data Library. We withhold the remaining 977 sequences in order to test the trained grammar on data not used in training. <p> Our future work will focus on developing a method that can automatically select a good structure and a good length of the grammar while training. 3.1 Data The experiments used data from three sources: 1. From EMBL Data Library's database produced by Mathias Sprinzl and co-workers, Bayreuth, FRG <ref> [26] </ref>, we obtained 1477 aligned and folded complete tRNA sequences.
Reference: [27] <author> M. S. Waterman. </author> <title> Computer analysis of nucleic acid sequences. </title> <booktitle> Methods in Enzymology, </booktitle> <volume> 164 </volume> <pages> 765-792, </pages> <year> 1988. </year>
Reference-contexts: Then, by studying multiple alignments produced by this grammar, we might be able to apply methods for finding correlations between columns in this multiple alignment, such as those in <ref> [9, 16, 13, 28, 29, 23, 27] </ref>, to discover some of the base-pairing structure in tRNA. Having done this, it would be straightforward to modify the grammar to account for this base pairing, and then iterate this process until no new structure is found.
Reference: [28] <author> M. S. Waterman. </author> <title> Sequence alignments. </title> <editor> In M. S. Waterman, editor, </editor> <title> Mathematical Methods for DNA Sequences, chapter Consensus Methods for Folding Single-Stranded Nucleic Acids. </title> <publisher> CRC Press, </publisher> <year> 1989. </year>
Reference-contexts: Comparative analyses of two or more protein or nucleic-acid sequences have been used widely in detection and evaluation of biological similarities and evolutionary relationships. Several methods of producing these multiple sequence alignments have been developed, most based on dynamic programming techniques (e.g., <ref> [28] </ref>). However, when RNA sequences are to be aligned, both the primary and secondary structure need to be taken into consideration since the generation of a multiple sequence alignment and an analysis of folding are mutually dependent exercises. <p> Then, by studying multiple alignments produced by this grammar, we might be able to apply methods for finding correlations between columns in this multiple alignment, such as those in <ref> [9, 16, 13, 28, 29, 23, 27] </ref>, to discover some of the base-pairing structure in tRNA. Having done this, it would be straightforward to modify the grammar to account for this base pairing, and then iterate this process until no new structure is found.
Reference: [29] <author> S. Winker, R. Overbeek, C. Woese, G. Olsen, and N. Pfluger. </author> <title> Structure detection through automated covariance search. </title> <booktitle> Computer Applications in the Biosciences, </booktitle> <volume> 6 </volume> <pages> 365-371, </pages> <year> 1990. </year>
Reference-contexts: Then, by studying multiple alignments produced by this grammar, we might be able to apply methods for finding correlations between columns in this multiple alignment, such as those in <ref> [9, 16, 13, 28, 29, 23, 27] </ref>, to discover some of the base-pairing structure in tRNA. Having done this, it would be straightforward to modify the grammar to account for this base pairing, and then iterate this process until no new structure is found.
Reference: [30] <author> C. R. Woese, R. R. Gutell, R. Gupta, and H. F. Noller. </author> <title> Detailed analysis of the higher-order structure of 16s-like ribosomal ribonucleic acids. </title> <journal> Micro-biology Reviews, </journal> <volume> 47(4) </volume> <pages> 621-669, </pages> <year> 1983. </year>
Reference-contexts: Currently, there are two principal methods for predicting secondary structure of RNA. Phyloge-netic analysis for homologous RNA molecules re lies on alignment and subsequent folding of many sequences into similar structures (reviewed in <ref> [12, 30] </ref>). Energy minimization depends on thermodynamic parameters and computer algorithms to evaluate the optimal and suboptimal free energy folding of an RNA species (reviewed in [11, 31]).
Reference: [31] <author> M. Zuker and D. Sankoff. </author> <title> RNA secondary structures and their prediction. </title> <journal> Bull. Math. Biol., </journal> <volume> 46 </volume> <pages> 591-621, </pages> <year> 1984. </year>
Reference-contexts: Phyloge-netic analysis for homologous RNA molecules re lies on alignment and subsequent folding of many sequences into similar structures (reviewed in [12, 30]). Energy minimization depends on thermodynamic parameters and computer algorithms to evaluate the optimal and suboptimal free energy folding of an RNA species (reviewed in <ref> [11, 31] </ref>). Our method of multiple alignment and folding differs markedly from the conventional techniques because it builds a statistical model during rather than after the process of alignment and folding. Such an approach has been applied successfully to modeling protein families with HMMs [10, 14].
References-found: 31

