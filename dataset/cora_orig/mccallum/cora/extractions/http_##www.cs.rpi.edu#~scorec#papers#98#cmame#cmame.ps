URL: http://www.cs.rpi.edu/~scorec/papers/98/cmame/cmame.ps
Refering-URL: http://www.cs.rpi.edu/~scorec/papers/98/papers.html
Root-URL: http://www.cs.rpi.edu
Title: A Hierarchical Partition Model for Adaptive Finite Element Computation  
Author: J. D. Teresco, M. W. Beall, J. E. Flaherty and M. S. Shephard 
Date: 29 May 1998  
Note: Preprint submitted to Elsevier Preprint  
Address: Troy, NY 12180  
Affiliation: Scientific Computation Research Center (SCOREC) and Department of Computer Science Rensselaer Polytechnic Institute  
Abstract: Software tools for the solution of partial differential equations using parallel adaptive finite element methods have been developed. We describe the design and implementation of the parallel mesh structures within an adaptive framework. The most fundamental concept is that of a hierarchical partition model used to distribute finite element meshes and associated data on a parallel computer. The hierarchical model represents heterogeneous processor and network speeds, and may be used to represent processes in any parallel computing environment, including an SMP, a distributed-memory computer, a network of workstations, or some combination of these. Using this model to segment the computation into chunks which can fit into cache memory provides a potential efficiency gain from an increased cache hit rate, even in a single processor environment. The information about different processor speeds, memory sizes, and the corresponding interconnection network can be useful in a dynamic load balancing algorithm which seeks to achieve a good balance with minimal interprocessor communication penalties when a slow interconnection network is involved. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. W. Beall and M. S. Shephard. </author> <title> A general topology-based mesh data structure. </title> <journal> Int. J. Numer. Meth. Engng., </journal> <volume> 40(9) </volume> <pages> 1573-1596, </pages> <year> 1997. </year>
Reference-contexts: The method order may also be varied (p-refinement). Each adaptive process concentrates the computational effort in areas where the solution resolution would otherwise be inadequate [7]. Conventional array-based data representations, which work well for fixed-mesh solutions, are not well-suited to solutions involving mesh adaptivity <ref> [1] </ref>. Traversal of the data must be efficient in all cases, but when adaptivity is introduced, modification of the mesh structures and corresponding solution data must also be efficient. Parallel computation introduces complications such as the need to balance processor loading, coordinate interprocessor communication, and manage distributed data. <p> The model works with the mesh data structures described here; however, many of the ideas may be applied to other systems. 3.1 Basic Mesh Structures The SCOREC Mesh Database (MDB) <ref> [1] </ref> provides an object-oriented, hierarchical representation of a finite element mesh. It includes a set of operators 7 to query and update the mesh data structure. <p> Finally, a mesh vertex is classified on the domain region, face, edge, or vertex in which it lies. Mesh entities are always classified with respect to the lowest order model entity possible. More formal definitions of classification and adjacency can be found in <ref> [1] </ref>. Vertex Edge Face Region Geometric Model classification Fig. 2. MDB entity hierarchy with links to a geometric model.
Reference: [2] <author> M. W. Beall and M. S. Shephard. </author> <title> A geometry-based analysis framework. </title> <booktitle> In Advances in Computational Engineering Science, </booktitle> <pages> pages 557-562, </pages> <address> Forsyth, GA, </address> <year> 1997. </year> <note> Tech. Science Press. </note>
Reference-contexts: The mesh-based approach [1,4,14,21,24-27] uses mesh connectivity and distribution of mesh entities to achieve parallelism. Our recent efforts have focused on implementing a framework for the reliable automated solution of problems in science and engineering over arbitrary domains using scalable parallel adaptive techniques <ref> [2] </ref>. This framework provides common interfaces to various pieces of software typically needed for scientific computation, and in particular when writing finite element analysis procedures. Central to this framework is a distributed mesh structure, described in Section 3.
Reference: [3] <author> R. Biswas, K. D. Devine, and J. E. Flaherty. </author> <title> Parallel, adaptive finite element methods for conservation laws. </title> <journal> Appl. Numer. Math., </journal> <volume> 14 </volume> <pages> 255-283, </pages> <year> 1994. </year>
Reference: [4] <author> R. Biswas, L. Oliker, and A. Sohn. </author> <title> Global load balancing with parallel mesh adaption on distributed-memory systems. </title> <booktitle> In Proc. Supercomputing '96, </booktitle> <address> Pittsburgh, </address> <year> 1996. </year>
Reference: [5] <author> C. L. Bottasso, H. L. de Cougny, M. Dindar, J. E. Flaherty, C. Ozturan, Z. Rusak, and M. S. Shephard. </author> <title> Compressible aerodynamics using a parallel adaptive time-discontinuous Galerkin least-squares finite element method. </title> <booktitle> In Proc. 12th AIAA Appl. Aero. Conf., </booktitle> <address> number 94-1888, Colorado Springs, </address> <year> 1994. </year> <month> 28 </month>
Reference: [6] <author> C. L. Bottasso, J. E. Flaherty, C. Ozturan, M. S. Shephard, B. K. Szymanski, J. D. Teresco, and L. H. Ziantz. </author> <title> The quality of partitions produced by an iterative load balancer. </title> <editor> In B. K. Szymanski and B. Sinharoy, editors, </editor> <booktitle> Proc. Third Workshop on Languages, Compilers, and Runtime Systems, </booktitle> <pages> pages 265-277, </pages> <address> Troy, </address> <year> 1996. </year>
Reference-contexts: Like the computational costs of elements, the communication costs associated with boundary entities are not necessarily uniform. consider only two factors in partition quality for this example, although other factors <ref> [6] </ref> must be considered for a more thorough analysis. We consider computational balance, and two surface index measures.
Reference: [7] <author> K. Clark, J. E. Flaherty, and M. S. Shephard. </author> <title> Appl. Numer. Math., special ed. on Adaptive Methods for Partial Differential Equations, </title> <type> 14, </type> <year> 1994. </year>
Reference-contexts: During the adaptive solution process, portions of the mesh may be refined or coarsened (h-refinement) or moved to follow evolving phenomena (r-refinement). The method order may also be varied (p-refinement). Each adaptive process concentrates the computational effort in areas where the solution resolution would otherwise be inadequate <ref> [7] </ref>. Conventional array-based data representations, which work well for fixed-mesh solutions, are not well-suited to solutions involving mesh adaptivity [1]. Traversal of the data must be efficient in all cases, but when adaptivity is introduced, modification of the mesh structures and corresponding solution data must also be efficient.
Reference: [8] <author> K. D. Devine and J. E. Flaherty. </author> <title> Parallel adaptive hp-refinement techniques for conservation laws. </title> <journal> Appl. Numer. Math., </journal> <volume> 20 </volume> <pages> 367-386, </pages> <year> 1996. </year>
Reference: [9] <author> M. Dindar, A. Lemnios, and M. Shephard. </author> <title> Adaptive solution procedures for rotorcraft aerodynamics. </title> <note> Submitted for publication, </note> <year> 1997. </year>
Reference: [10] <author> P. Diniz, S. Plimpton, B. Hendrickson, and R. Leland. </author> <title> Parallel algorithms for dynamically partitioning unstructured grids. </title> <editor> In D. Bailey, editor, </editor> <booktitle> Proc. 7th SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <pages> pages 615-620. </pages> <publisher> SIAM, </publisher> <month> February </month> <year> 1995. </year>
Reference: [11] <author> H. C. Edwards. </author> <title> A Parallel Infrastructure for Scalable Adaptive Finite Element Methods and its Application to Least Squares C 1 Collocation. </title> <type> PhD thesis, </type> <institution> The University of Texas at Austin, </institution> <month> May </month> <year> 1997. </year>
Reference-contexts: The approaches can be categorized by a low-level view of the data structures. Two basic paradigms have been used as the underlying structure for these computations. An array-based approach, such as the Scalable Distributed Dynamic Array <ref> [11] </ref>, uses the distribution of arrays as the fundamental unit of parallelism. The mesh-based approach [1,4,14,21,24-27] uses mesh connectivity and distribution of mesh entities to achieve parallelism.
Reference: [12] <author> C. Farhat and M. Lesoinne. </author> <title> Automatic partitioning of unstructured meshes for the parallel solution of problems in computational mechanics. </title> <journal> Int. J. Numer. Meth. Engng., </journal> <volume> 36 </volume> <pages> 745-764, </pages> <year> 1993. </year>
Reference: [13] <author> J. E. Flaherty, M. Dindar, R. M. Loy, M. S. Shephard, B. K. Szymanski, J. D. Teresco, and L. H. Ziantz. </author> <title> An adaptive and parallel framework for partial differential equations. </title> <editor> In D. F. Griffiths, D. J. Higham, and G. A. Watson, editors, </editor> <booktitle> Numerical Analysis 1997 (Proc. 17th Dundee Biennial Conf.), number 380 in Pitman Research Notes in Mathematics Series, </booktitle> <pages> pages 74-90. </pages> <publisher> Addison Wesley Longman, </publisher> <year> 1998. </year>
Reference: [14] <author> J. E. Flaherty, R. M. Loy, C. Ozturan, M. S. Shephard, B. K. Szymanski, J. D. Teresco, and L. H. Ziantz. </author> <title> Parallel structures and dynamic load balancing for 29 adaptive finite element computation. </title> <journal> Appl. Numer. Math., </journal> <volume> 26 </volume> <pages> 241-263, </pages> <year> 1998. </year>
Reference-contexts: Each entity in the finite element mesh is uniquely assigned to a partition model entity or, more simply, to a partition. The direct assignment of one partition to each process has been a limitation of prior systems <ref> [14] </ref>. While this is straightfor 9 MeshFaces MeshEdges MeshVertices MeshEdges MeshVertices GRegions GFaces GEdges GVertices MeshRegions MeshFaces MeshEdges MeshVertices Geometric Model MeshVertices Mesh entity lists Mesh Fig. 3. Data organization with mesh data stored relative to a geometric model. <p> This is much more efficient than traversing all entities and checking the classification (geometric or partition) of each to determine whether it is one we wish to use. 3.9 Inter-Process Migration The approach to mesh migration is similar to the one described by Flaherty et al. <ref> [14] </ref>, but is implemented at a more abstract level. To migrate a subset of the mesh, the subset is first reclassified on a new partition model entity. This reclassification is very inexpensive: it involves two pointer updates and an entity count adjustment.
Reference: [15] <author> J. E. Flaherty, R. M. Loy, M. S. Shephard, B. K. Szymanski, J. D. Teresco, and L. H. Ziantz. </author> <title> Adaptive local refinement with octree load-balancing for the parallel solution of three-dimensional conservation laws. </title> <type> IMA Preprint Series 1483, </type> <institution> Institute for Mathematics and its Applications, University of Minnesota, </institution> <year> 1997. </year> <note> To appear, J. Parallel and Dist. Comput. </note>
Reference-contexts: The measurement of load imbalance in our existing algorithms is based on a weighted number of elements. Some sources of heterogeneity, such as the extra work on higher-order elements in adaptive p-refinement or the extra time steps taken on smaller elements in a local refinement method <ref> [15] </ref>, can be accounted for using the weighted element scheme. Others, like the run-time imbalance caused by other processes in a nondedicated parallel environment, are not known a priori with respect to a given step and do not fit well into this model.
Reference: [16] <author> W. Gropp. </author> <type> Personal communication. </type>
Reference-contexts: 41.35 22.58 32.34 162.70 10.02 SP2s-8 65.03 38.61 25.95 26.66 67.44 11.58 SP2s-16 65.19 38.56 27.70 24.60 35.86 12.04 SP2s-32 65.97 41.84 29.82 14.83 16.82 7.20 Table 5 Wall-clock times for network tests using medium meshes on the IBM SP2. safe libraries which are typically slower due to mutual-exclusion locks <ref> [16] </ref>. We would like to make use of multithreading in the future, so this somewhat disturbing result will be investigated further. On the SGI platform, no significant difference was observed between the two communication devices.
Reference: [17] <author> W. Gropp, E. Lusk, N. Doss, and A. Skjellum. </author> <title> A high-performance, portable implementation of the MPI message passing interface standard. </title> <journal> Parallel Comput., </journal> <volume> 22, </volume> <year> 1996. </year>
Reference-contexts: All cases used MPI for communication. IBM's implementation of MPI was used on their SP2, while others used the MPICH package <ref> [17] </ref>.
Reference: [18] <institution> Message Passing Interface Forum, University of Tennessee, Knoxville, Tennessee. </institution> <month> MPI: </month> <title> A Message Passing Interface Standard, </title> <booktitle> first edition, </booktitle> <year> 1994. </year>
Reference-contexts: Static data structures cannot be used with 2 adaptive computations, which makes automatic detection by a parallelizing compiler difficult. Parallelism is generally explicit, achieved through the use of a message passing library such as the Message Passing Interface (MPI) <ref> [18] </ref>, and requires a partitioning algorithm to distribute data among processing nodes. Parallel adaptive FEM computations can be distributed in a natural way by a domain decomposition of the mesh underlying the computation, but being adaptive, these meshes will change and the system must account for this. <p> Information that is useful in this respect includes available memory, available processing power, and availability and properties (bandwidth and latency) of communication resources. MPI <ref> [18] </ref> does not provide such information (nor does the MPI-2 specification [19]). Some of this information can be computed through environment queries, but other information will need to be provided manually. Consider five specific parallel computing environments, represented in Figure 1.
Reference: [19] <institution> Message Passing Interface Forum, University of Tennessee, Knoxville, Tennessee. </institution> <month> MPI-2: </month> <title> Extensions to the Message-Passing Interface, </title> <booktitle> first edition, </booktitle> <year> 1997. </year>
Reference-contexts: Information that is useful in this respect includes available memory, available processing power, and availability and properties (bandwidth and latency) of communication resources. MPI [18] does not provide such information (nor does the MPI-2 specification <ref> [19] </ref>). Some of this information can be computed through environment queries, but other information will need to be provided manually. Consider five specific parallel computing environments, represented in Figure 1. The first (Figure 1a) is an eight-node computer with all uniprocessor nodes connected by a fast, nonblocking switch.
Reference: [20] <author> T. Minyard and Y. Kallinderis. </author> <title> Octree partitioning of hybrid grids for parallel adaptive viscous flow simulations. </title> <journal> Int. J. Numer. Meth. Fluids, </journal> <volume> 26 </volume> <pages> 57-78, </pages> <year> 1998. </year>
Reference: [21] <author> T. Minyard, Y. Kallinderis, and K. Schulz. </author> <title> Parallel load balancing for dynamic execution environments. </title> <booktitle> In Proc. 34th Aerospace Sciences Meeting and Exhibit, </booktitle> <address> number 96-0295, Reno, </address> <year> 1996. </year>
Reference: [22] <author> K. Schloegel, G. Karypis, and V. Kumar. </author> <title> Parallel multilevel diffusion algorithms for repartitioning of adaptive meshes. </title> <type> Tech. Report 97-014, </type> <institution> University of Minnesota, Department of Computer Science and Army HPC Center, Minneapolis, MN, </institution> <year> 1997. </year>
Reference-contexts: A partition such as this would be useful when the primary concern is a good computational balance, such as in a shared-memory environment. The partition using ParMetis <ref> [22] </ref> (Figure 13b) achieves excellent surface index values, MLSI=2.72 and GSI=1.00, but at the expense of a larger computational imbalance. Here, the partitions contain 10,731, 11,369, 10,732, and 11,345 regions.
Reference: [23] <author> M. S. Shephard, S. Dey, and J. E. Flaherty. </author> <title> A straight forward structure to construct shape functions for variable p-order meshes. </title> <journal> Comp. Meth. in Appl. Mech. and Engng., </journal> <volume> 147 </volume> <pages> 209-233, </pages> <year> 1997. </year> <month> 30 </month>
Reference-contexts: MDB entity hierarchy with links to a geometric model. The full entity hierarchy allows the efficient deletion and creation of mesh entities during h-refinement [24] and simplifies attachment of degrees of freedom to the mesh entities and determination of necessary geometric information dur 8 ing p-refinement <ref> [23] </ref>. The database allows for the fast retrieval of adjacency information. Examples of available data include the list of faces bounding an element and the edges sharing a common vertex.
Reference: [24] <author> M. S. Shephard, J. E. Flaherty, C. L. Bottasso, H. L. de Cougny, C. Ozturan, and M. L. Simone. </author> <title> Parallel automated adaptive analysis. </title> <journal> Parallel Comput., </journal> <volume> 23 </volume> <pages> 1327-1347, </pages> <year> 1997. </year>
Reference-contexts: More formal definitions of classification and adjacency can be found in [1]. Vertex Edge Face Region Geometric Model classification Fig. 2. MDB entity hierarchy with links to a geometric model. The full entity hierarchy allows the efficient deletion and creation of mesh entities during h-refinement <ref> [24] </ref> and simplifies attachment of degrees of freedom to the mesh entities and determination of necessary geometric information dur 8 ing p-refinement [23]. The database allows for the fast retrieval of adjacency information. <p> Examples of partitioning using additional knowledge of parallel environment. Partitioning using (a) PSIRB, (b) ParMetis, (c) multilevel combination of PSIRB and ParMetis. Shading indicates processor assignments. Partitioning using parallel sort inertial recursive bisection (PSIRB) <ref> [24] </ref> (Figure 13a) achieves an excellent computational balance, with three processors assigned 11,044 regions, and the fourth 11,045 regions, and reasonable surface indices with MLSI=4.67 and GSI=1.53. A partition such as this would be useful when the primary concern is a good computational balance, such as in a shared-memory environment.
Reference: [25] <author> V. Vidwans, Y. Kallinderis, and V. Venkatakrishnan. </author> <title> Parallel dynamic load-balancing algorithm for three-dimensional adaptive unstructured grids. </title> <journal> AIAA J., </journal> <volume> 32(3) </volume> <pages> 497-505, </pages> <year> 1994. </year>
Reference: [26] <author> C. H. Walshaw and M. Berzins. </author> <title> Dynamic load balancing for PDE solvers on adaptive unstructured meshes. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 7(1) </volume> <pages> 17-28, </pages> <year> 1995. </year>
Reference: [27] <author> C. H. Walshaw, M. Cross, and M. Everett. </author> <title> Mesh partitioning and load-balancing for distributed memory parallel systems. </title> <booktitle> In Proc. Par. Dist. </booktitle> <institution> Comput. for Comput. Mech., </institution> <address> Lochinver, Scotland, </address> <year> 1997. </year> <month> 31 </month>
References-found: 27

