URL: ftp://ftp.cs.uu.nl/pub/RUU/CS/techreps/CS-1994/1994-27.ps.gz
Refering-URL: http://www.cs.ruu.nl/docs/research/publication/TechList1.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Phone: Tel. 31 30 531454  
Title: Probabilistic Network Construction Using the Minimum Description Length Principle  
Author: Remco R. Bouckaert 
Address: Padualaan 14, P.O. Box 80.089, 3508 TB Utrecht, The Netherlands,  
Affiliation: Utrecht University Department of Computer Science  
Date: July 1994  
Pubnum: RUU-CS-94-27  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> S. Andreassen, M. Wolbye, B. Falck, and S.K. Andersen. </author> <title> MUNIN a causal probabilistic network for interpretation of electromyographic findings. </title> <booktitle> In Proceedings of the IJCAI, </booktitle> <pages> pages 366-372, </pages> <year> 1987. </year>
Reference-contexts: Efficient algorithms have been designed for making inferences with information represented in a probabilistic network [9, 12, 15]. In various domains the framework has been applied successfully <ref> [1, 2, 7] </ref> indicating its practical use.
Reference: [2] <author> I. Beinlich, H. Seurmondt, R. Chavez, and G. Cooper. </author> <title> The alarm monitoring system: a case study with two probabilistic inference techniques for belief networks. </title> <booktitle> In Proceedings Artificial Intelligence in Medical Care, </booktitle> <pages> pages 247-256, </pages> <year> 1989. </year>
Reference-contexts: Efficient algorithms have been designed for making inferences with information represented in a probabilistic network [9, 12, 15]. In various domains the framework has been applied successfully <ref> [1, 2, 7] </ref> indicating its practical use.
Reference: [3] <author> R.R. Bouckaert. </author> <title> Optimizing causal orderings for generating DAGs from data. </title> <booktitle> In Proceedings Uncertainty in Artificial Intelligence 8, </booktitle> <pages> pages 9-16, </pages> <year> 1992. </year>
Reference-contexts: Such an ordering may be provided by an expert, but automated learning is often applied to avoid participation of expensive experts. An alternative is to start with a random ordering, apply K2 with this ordering, and to optimize this ordering. In <ref> [3] </ref> an 6 algorithm has been presented for optimizing an ordering for this purpose of removing arcs from a given network structure. 4 A Minimum Description Length Approach Another way to judge the quality of a network structure is by the minimum description length principle [18, 19] which stems from coding
Reference: [4] <author> C.K. Chow and C.N. Liu. </author> <title> Approximating discrete probability distributions with dependency trees. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-14:462-467, </volume> <year> 1986. </year>
Reference-contexts: Automated learning of probabilistic networks from a database of cases can help shorten this build and test cycle by suggesting an initial network. Learning algorithms for probabilistic networks developed so far can be divided into algorithms based on non-Bayesian approaches <ref> [4, 17, 22, 23, 24] </ref> and algorithms based on a Bayesian approach [5, 10, 14, 21]. The non-Bayesian approaches employ statistical tests on databases for deciding on the existence of arcs in the probabilistic network under construction.
Reference: [5] <author> G.F. Cooper and E. Herskovits. </author> <title> A Bayesian method for the induction of probabilistic networks from data. </title> <booktitle> Machine Learning, </booktitle> <pages> pages 309-347, </pages> <year> 1992. </year>
Reference-contexts: Learning algorithms for probabilistic networks developed so far can be divided into algorithms based on non-Bayesian approaches [4, 17, 22, 23, 24] and algorithms based on a Bayesian approach <ref> [5, 10, 14, 21] </ref>. The non-Bayesian approaches employ statistical tests on databases for deciding on the existence of arcs in the probabilistic network under construction. <p> In this paper, we focus on learning the network structure B S . Once B S is known, B P can be estimated directly from the database, <ref> [5] </ref>. 3.1 The Bayesian Measure The basic idea of the Bayesian approach is to maximize the probability of the network structure given the data, that is, to maximize P (B S jD) over all possible network structures B S given the cases of the database D. <p> To this end, Cooper and Herskovits provide the following formula, <ref> [5] </ref>. Theorem 3.1 Let U be the set of variables fx 1 ; : : : ; x n g, n 1, where each x i can take a value from fx i1 ; :::; x ir i g, r i 1, i = 1; : : : ; n.
Reference: [6] <author> R.L. Graham, D.E. Knuth, and O. Patashnik. </author> <title> Concrete mathematics. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference: [7] <author> D. Heckerman, E. Horvitz, and B. Nathwani. </author> <title> Towards normative expert systems: Part I, the pathfinder project. </title> <booktitle> Methods of Information in Medicine, </booktitle> <volume> 31 </volume> <pages> 90-105, </pages> <year> 1992. </year>
Reference-contexts: Efficient algorithms have been designed for making inferences with information represented in a probabilistic network [9, 12, 15]. In various domains the framework has been applied successfully <ref> [1, 2, 7] </ref> indicating its practical use.
Reference: [8] <author> M. Henrion. </author> <title> Propagating uncertainty in Bayesian networks by probabilistic logic sampling. </title> <booktitle> In Proceedings Uncertainty in Artificial Intelligence 4, </booktitle> <pages> pages 149-163, </pages> <year> 1988. </year>
Reference-contexts: With the resulting probabilistic network, a set of cases was generated using logic sampling <ref> [8] </ref> to constitute a database D. Both K2 and K3 were applied to this database, with the node ordering used for generating the network structure. This procedure was repeated for various database sizes.
Reference: [9] <author> M. Henrion. </author> <title> An introduction to algorithms for inference in belief nets. </title> <booktitle> In Proceedings Uncertainty in Artificial Intelligence 6, </booktitle> <pages> pages 129-138, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction The framework of probabilistic networks, also known as causal networks and Bayesian belief networks, offers a mathematically sound formalism for representing probabilistic information. Efficient algorithms have been designed for making inferences with information represented in a probabilistic network <ref> [9, 12, 15] </ref>. In various domains the framework has been applied successfully [1, 2, 7] indicating its practical use.
Reference: [10] <author> E. Herskovits. </author> <title> Computer-based probabilistic-network construction. </title> <type> PhD thesis, </type> <institution> Section of Medical Informatics, University of Pittsburgh, </institution> <year> 1991. </year> <month> 22 </month>
Reference-contexts: Learning algorithms for probabilistic networks developed so far can be divided into algorithms based on non-Bayesian approaches [4, 17, 22, 23, 24] and algorithms based on a Bayesian approach <ref> [5, 10, 14, 21] </ref>. The non-Bayesian approaches employ statistical tests on databases for deciding on the existence of arcs in the probabilistic network under construction. <p> In addition, a collection of most likely networks can be obtained and prior knowledge of the domain at hand can be easily incorporated. 4.4 Asymptotic Behavior of the MDL Measure For the Bayesian measure it is known that it prefers minimal I-maps over other network structures for large databases <ref> [10] </ref>. In this section, we investigate the behavior of the MDL measure for large databases. 16 Theorem 4.3 Let U be a set of variables and let be a total ordering on U . Let P D be a distribution over U with a unique minimal I-map obeys .
Reference: [11] <author> S. Htjsgaard and B. Thiesson. </author> <title> Bifrost- block recursive models induced from relevant knowledge, observationsm and statistical techniques. </title> <type> Technical Report R 92-2010, </type> <institution> Institute for Electronic Systems, University of Aalborg, Denmark, </institution> <year> 1992. </year>
Reference-contexts: The network structure with the highest quality will have a balanced contribution of both these terms. Note that due to this property, the MDL principle gives a natural stopping criterion for heuristics that search for network structures. Approaches based on information criteria as proposed in for example <ref> [11, 13] </ref>, apply a quality measure that is closely related to the MDL measure: the log N term is replaced by another function and the prior distribution on probabilistic network structures is assumed uniform. 8 4.2 Comparing the Bayesian and MDL measures In this section, we compare the MDL measure with
Reference: [12] <author> S.L. Lauritzen and D.J. Spiegelhalter. </author> <title> Local computations with probabilities on graphical structures and their applications to expert systems (with discussion). </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> 50 </volume> <pages> 157-224, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction The framework of probabilistic networks, also known as causal networks and Bayesian belief networks, offers a mathematically sound formalism for representing probabilistic information. Efficient algorithms have been designed for making inferences with information represented in a probabilistic network <ref> [9, 12, 15] </ref>. In various domains the framework has been applied successfully [1, 2, 7] indicating its practical use.
Reference: [13] <author> S.L. Lauritzen, B. Thiesson, </author> <title> and D.J. Spiegelhalter. Diagnostic systems created by model selection methods a case study. </title> <booktitle> In Proceedings 4th International Workshop on AI and Statistics, </booktitle> <year> 1993. </year>
Reference-contexts: The network structure with the highest quality will have a balanced contribution of both these terms. Note that due to this property, the MDL principle gives a natural stopping criterion for heuristics that search for network structures. Approaches based on information criteria as proposed in for example <ref> [11, 13] </ref>, apply a quality measure that is closely related to the MDL measure: the log N term is replaced by another function and the prior distribution on probabilistic network structures is assumed uniform. 8 4.2 Comparing the Bayesian and MDL measures In this section, we compare the MDL measure with
Reference: [14] <author> D. Madigan and J. York. </author> <title> Bayesian graphical models for discrete data. </title> <type> Technical Report 259, </type> <institution> Department of Statistics, University of Washington, </institution> <address> Seattle, </address> <year> 1993. </year>
Reference-contexts: Learning algorithms for probabilistic networks developed so far can be divided into algorithms based on non-Bayesian approaches [4, 17, 22, 23, 24] and algorithms based on a Bayesian approach <ref> [5, 10, 14, 21] </ref>. The non-Bayesian approaches employ statistical tests on databases for deciding on the existence of arcs in the probabilistic network under construction.
Reference: [15] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufman, inc., </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: 1 Introduction The framework of probabilistic networks, also known as causal networks and Bayesian belief networks, offers a mathematically sound formalism for representing probabilistic information. Efficient algorithms have been designed for making inferences with information represented in a probabilistic network <ref> [9, 12, 15] </ref>. In various domains the framework has been applied successfully [1, 2, 7] indicating its practical use.
Reference: [16] <author> J. Pearl, D. Geiger, and T. Verma. </author> <title> The logic of influence diagrams. In R.M. </title> <editor> Oliver and J.Q. Smith, editors, </editor> <title> Influence Diagrams, </title> <booktitle> Belief Nets and Decision Analysis, </booktitle> <pages> pages 67-87. </pages> <publisher> John Wiley & Sons Ltd., </publisher> <year> 1990. </year>
Reference-contexts: = M S 0 if and only if x a x b 2 B S , x a x b 2 B S 0 , and x, y, z vorms a v-node in B S if and only if x, y, z vorms a v-node in B S 0 , <ref> [16] </ref>. Note that the condition x a x b 2 B S , x a x b 2 B S 0 implies that both B S and B S 0 have the same underlying undirected graph, however, the direction of the arcs may not be the same in both graphs.
Reference: [17] <author> G. Rebane and J. Pearl. </author> <title> The recovery of causal polytrees from statistical data. </title> <booktitle> In Proceedings Uncertainty in Artificial Intelligence 3, </booktitle> <pages> pages 222-228, </pages> <year> 1987. </year>
Reference-contexts: Automated learning of probabilistic networks from a database of cases can help shorten this build and test cycle by suggesting an initial network. Learning algorithms for probabilistic networks developed so far can be divided into algorithms based on non-Bayesian approaches <ref> [4, 17, 22, 23, 24] </ref> and algorithms based on a Bayesian approach [5, 10, 14, 21]. The non-Bayesian approaches employ statistical tests on databases for deciding on the existence of arcs in the probabilistic network under construction.
Reference: [18] <author> J. Rissanen. </author> <title> Stochastic complexity and modeling. </title> <journal> Annals of Statistics, </journal> <volume> 14(3) </volume> <pages> 1080-1100, </pages> <year> 1986. </year>
Reference-contexts: In [3] an 6 algorithm has been presented for optimizing an ordering for this purpose of removing arcs from a given network structure. 4 A Minimum Description Length Approach Another way to judge the quality of a network structure is by the minimum description length principle <ref> [18, 19] </ref> which stems from coding theory where the aim is to create a network structure that describes the database as accurately as possible with as few symbols as possible. 4.1 The MDL Measure The MDL principle results in the following measure.
Reference: [19] <author> J. Rissanen. </author> <title> Stochastic complexity. </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> 49(3) </volume> <pages> 223-239, </pages> <year> 1987. </year>
Reference-contexts: In [3] an 6 algorithm has been presented for optimizing an ordering for this purpose of removing arcs from a given network structure. 4 A Minimum Description Length Approach Another way to judge the quality of a network structure is by the minimum description length principle <ref> [18, 19] </ref> which stems from coding theory where the aim is to create a network structure that describes the database as accurately as possible with as few symbols as possible. 4.1 The MDL Measure The MDL principle results in the following measure.
Reference: [20] <author> R.D. Robinson. </author> <title> Counting unlabeled acyclic digraphs. </title> <booktitle> In Proceedings of the fifth Australian Conference on Combinatorial Mathematics, </booktitle> <pages> pages 28-43, </pages> <year> 1976. </year>
Reference-contexts: We observe that the number of different network structures over n nodes is given by the recursive formula G (0) = 1, G (n) = P n i )2 i (n1) G (n i), <ref> [20] </ref>. For example, for n = 10 there are approximately 4:2 fi 10 18 different network structures. As this number is exponential in the number of nodes, it is not feasible from a computational point of view to regard all network structures.
Reference: [21] <author> D.J. Spiegelhalter, A.P. Dawid, S.L. Lauritzen, and R.G. Cowell. </author> <title> Bayesian analysis in expert systems. </title> <journal> Statistical Science, </journal> <volume> 8 </volume> <pages> 219-283, </pages> <year> 1993. </year>
Reference-contexts: Learning algorithms for probabilistic networks developed so far can be divided into algorithms based on non-Bayesian approaches [4, 17, 22, 23, 24] and algorithms based on a Bayesian approach <ref> [5, 10, 14, 21] </ref>. The non-Bayesian approaches employ statistical tests on databases for deciding on the existence of arcs in the probabilistic network under construction.
Reference: [22] <author> P. Spirtes, C. Glymour, and R. Scheines. </author> <title> Causation, Prediction, and Search. </title> ??, <year> 1993. </year>
Reference-contexts: Automated learning of probabilistic networks from a database of cases can help shorten this build and test cycle by suggesting an initial network. Learning algorithms for probabilistic networks developed so far can be divided into algorithms based on non-Bayesian approaches <ref> [4, 17, 22, 23, 24] </ref> and algorithms based on a Bayesian approach [5, 10, 14, 21]. The non-Bayesian approaches employ statistical tests on databases for deciding on the existence of arcs in the probabilistic network under construction.
Reference: [23] <author> T. Verma and J. Pearl. </author> <title> Causal networks: semantics and expressiveness. </title> <booktitle> In Proceedings Uncertainty in Artificial Intelligence 4, </booktitle> <pages> pages 352-359, </pages> <year> 1988. </year>
Reference-contexts: Automated learning of probabilistic networks from a database of cases can help shorten this build and test cycle by suggesting an initial network. Learning algorithms for probabilistic networks developed so far can be divided into algorithms based on non-Bayesian approaches <ref> [4, 17, 22, 23, 24] </ref> and algorithms based on a Bayesian approach [5, 10, 14, 21]. The non-Bayesian approaches employ statistical tests on databases for deciding on the existence of arcs in the probabilistic network under construction.
Reference: [24] <author> N. Wermuth and S.L. Lauritzen. </author> <title> Graphical and recursive models for contingency tables. </title> <journal> Biometrika, </journal> <volume> 72 </volume> <pages> 537-552, </pages> <year> 1983. </year> <month> 23 </month>
Reference-contexts: Automated learning of probabilistic networks from a database of cases can help shorten this build and test cycle by suggesting an initial network. Learning algorithms for probabilistic networks developed so far can be divided into algorithms based on non-Bayesian approaches <ref> [4, 17, 22, 23, 24] </ref> and algorithms based on a Bayesian approach [5, 10, 14, 21]. The non-Bayesian approaches employ statistical tests on databases for deciding on the existence of arcs in the probabilistic network under construction.
References-found: 24

