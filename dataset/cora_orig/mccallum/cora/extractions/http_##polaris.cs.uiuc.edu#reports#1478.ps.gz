URL: http://polaris.cs.uiuc.edu/reports/1478.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Email: lchoi@csrd.uiuc.edu achien@cs.uiuc.edu  
Phone: (217)333-0969 (217)333-6844  
Title: The Design and Performance Evaluation of the  
Author: DI-multicomputer Lynn Choi Andrew A. Chien 
Address: Urbana, IL 61801-1351 Urbana, IL 61801  
Affiliation: Center for Supercomputing R D Department of Computer Science University of Illinois University of Illinois  
Note: To appear in Journal of Parallel and Distributed Computing  
Abstract: In this paper, we propose a new multicomputer node architecture, the DI-multicomputer which uses packet routing on a uniform point-to-point interconnect for both local memory access and intern-ode communication. This is achieved by integrating a router onto each processor chip and eliminating the memory bus interface. Since communication resources such as pins and wires are allocated dynamically via packet routing, the DI-multicomputer is able to maximize the available communication resources, providing much higher performance for both intra-node and internode communication. Multi-packet handling mechanisms are used to implement a high performance memory interface based on packet routing. The DI-multicomputer network interface provides efficient communication for both short and long messages, decoupling the processor from the transmission overhead for long messages while achieving a minimum latency for short messages. Trace-driven simulations based on a suite of message passing applications show that the communication mechanisms of the DI-multicomputer can achieve up to four times speedup when compared to existing architectures.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Agarwal, A., Lim, B.-H., Kranz, D., and Kubiatowicz, J. </author> <month> April: </month> <title> a processor architecture for multiprocessing. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 104-114, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: interleaved memory organization (see Section 4), the low order bits are used to denote memory interleave module. 5 To maintain cache coherence locally on DMA access, an I/O processor should send messages to both memory and cache modules. 7 design we know is the processor architecture of the MIT Alewife <ref> [1] </ref>, which is based on the SPARC architecture. The DI-microprocessor architecture is based on the DEC Alpha processor core. The only modification to the Alpha architecture is its DI-based memory interface and the addition of the multiple hardware contexts.
Reference: [2] <author> Agarwal, A., and et al. </author> <title> The MIT Alewife Machine: A Large-Scale Distributed-Memory Multiprocessor. </title> <booktitle> In Proceedings of Workshop on Scalable Shared Memory Multiprocessors, </booktitle> <year> 1991. </year>
Reference-contexts: Maintaining global cache coherence is possible but an orthogonal issue for the DI-based systems, although each node has locally coherent caches. 5 Either hardware directory-based coherence protocols <ref> [2, 26] </ref> or software coherence schemes [7, 11] can be used to provide a cache coherent shared address space. Internode Synchronization A node can communicate with other nodes with message passing. In DI-multicomputer, short and long messages use different mechanisms for synchronization as they are differently handled for message passing. <p> This means that incoming short messages still need to be fetched from memory, increasing the latency. The issue of implementing global cache coherence is an orthogonal issue to the DI-based systems. Either hardware directory-based coherence protocols <ref> [2, 26] </ref> or software-based approaches [7, 11] can be implemented on top of the DI-based systems to support the cache coherence. 9 Summary The DI-multicomputer uses dynamic interconnection and novel message handling mechanisms to increase in memory bandwidth and reduce message passing overhead.
Reference: [3] <author> Alverson, G., Alverson, R., Callahan, D., Koblenz, B., Porterfield, A., and Smith, B. </author> <title> Exploiting heterogeneous parallelism on a multithreaded multiprocessor. </title> <booktitle> In Proceedings of the 6th ACM Interational Conference on Supercomputing, </booktitle> <year> 1992. </year>
Reference-contexts: However, he introduces the possibility of DI-based systems without discussing memory hierarchy and network interface issues. The Tera architecture <ref> [3] </ref> also implements its memory subsystem with interleaved memory units interconnected by a packet-switched interconnection network. However, the Tera architecture is quite different in that there is neither a cache nor local memory; all accesses are mapped to a global shared memory and no message passing is supported.
Reference: [4] <author> Aoyama, K. </author> <title> The cost of adaptivity and virtual lanes in a wormhole router. </title> <booktitle> In Journal of VLSI Design, </booktitle> <year> 1994. </year>
Reference-contexts: To evaluate memory interface performance, we compare cache refill times over a range of line sizes. The performance numbers assumed for the calculation are shown in Table III and they are derived from our hardware design studies <ref> [4] </ref> including SPICE simulations of multi-tap bus lines. We further assume 12 The only difference lies in that the destination addresses for reply packets become remote memory nodes instead of the local processor. 18 that the DI-microprocessor reloads its cache lines from its four nearest neighbors, minimizing the routing delay. <p> The higher network clock rate for the DI-microprocessor memory interface is due to the electrical advantages of point-to-point interconnects over multi-tap bus lines [31, 18]. Router delay is based on a number of published implementation studies [17, 32] and our own designs <ref> [4, 8] </ref>. The actions required to complete a cache line reload in each system are illustrated in Figure 15. Table III: Memory and interconnect performance numbers assumed for the evaluation. <p> Long message passing does not require any significant additional hardware since the mechanism is embedded in the memory subsystem. Packet Router Dynamic interconnection demands routers with three characteristics: First, they must exhibit extremely low latency. Our implementation studies and others <ref> [4, 8, 17, 33] </ref> show that router latencies in the 5-10 nanosecond range are feasible if chip crossing costs are reduced with advanced packaging. Second, it must have multiple input and output ports, supplying or absorbing several packets at a time. <p> For example, if the network used dimension-order routing, all packets would have to route in X first, making it impossible to inject in the Y dimension. Recent advances in the design of simple adaptive routers indicates that such networks overhead likely to be modest <ref> [4, 8] </ref>. A comparable router design we completed required only 18 M 2 , 1% of a modern microprocessor's die area. Also, our design study of three adaptive routing schemes [5, 9, 28] shows that 27 they all require less than 10,000 gates for 2-dimensional network [8].
Reference: [5] <author> Berman, P., Gravano, L., Pifarre, G., and Sanz, J. </author> <title> Adaptive deadlock and livelock free routing with all minimal paths in torus networks. </title> <booktitle> In Proceedings of the Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1992. </year>
Reference-contexts: Recent advances in the design of simple adaptive routers indicates that such networks overhead likely to be modest [4, 8]. A comparable router design we completed required only 18 M 2 , 1% of a modern microprocessor's die area. Also, our design study of three adaptive routing schemes <ref> [5, 9, 28] </ref> shows that 27 they all require less than 10,000 gates for 2-dimensional network [8]. Finally, they must use bidirectional channels. This allows all of the processor pins to be utilized for dynamic interconnections. A number of routers which use bidirectional signalling have already been constructed [5, 17]. <p> Finally, they must use bidirectional channels. This allows all of the processor pins to be utilized for dynamic interconnections. A number of routers which use bidirectional signalling have already been constructed <ref> [5, 17] </ref>. Memory Nodes Dynamic interconnection memory nodes require a router and packet processing hardware. This hardware can be added to individual dynamic RAM chips, or the cost can be amortized over a number of chips. A block diagram of a memory node design is shown in Figure 21.
Reference: [6] <author> Cerf, V., and Kahn, R. </author> <title> A protocol for packet network interconnection. </title> <journal> IEEE Transactions on Communications, </journal> <year> 1974. </year>
Reference-contexts: Several systems use dynamic allocation of communication resources when their efficient utilization is at a premium <ref> [6, 27] </ref>. Applying network-based dynamic interconnection to low-level interconnection has been discussed in the fine-grain multicomputer community for some time.
Reference: [7] <author> Cheong, H. </author> <title> Life Span Strategy A Compiler-Based Approach to Cache Coherence. </title> <booktitle> In Proceedings of the International Conference on Supercomputing, </booktitle> <year> 1992. </year>
Reference-contexts: Maintaining global cache coherence is possible but an orthogonal issue for the DI-based systems, although each node has locally coherent caches. 5 Either hardware directory-based coherence protocols [2, 26] or software coherence schemes <ref> [7, 11] </ref> can be used to provide a cache coherent shared address space. Internode Synchronization A node can communicate with other nodes with message passing. In DI-multicomputer, short and long messages use different mechanisms for synchronization as they are differently handled for message passing. <p> This means that incoming short messages still need to be fetched from memory, increasing the latency. The issue of implementing global cache coherence is an orthogonal issue to the DI-based systems. Either hardware directory-based coherence protocols [2, 26] or software-based approaches <ref> [7, 11] </ref> can be implemented on top of the DI-based systems to support the cache coherence. 9 Summary The DI-multicomputer uses dynamic interconnection and novel message handling mechanisms to increase in memory bandwidth and reduce message passing overhead.
Reference: [8] <author> Chien, A. A. </author> <title> A cost and speed model for k-ary n-cube wormhole routers. multiprocessors. </title> <booktitle> In Proceedings of the Hot Interconnects, </booktitle> <year> 1993. </year>
Reference-contexts: The higher network clock rate for the DI-microprocessor memory interface is due to the electrical advantages of point-to-point interconnects over multi-tap bus lines [31, 18]. Router delay is based on a number of published implementation studies [17, 32] and our own designs <ref> [4, 8] </ref>. The actions required to complete a cache line reload in each system are illustrated in Figure 15. Table III: Memory and interconnect performance numbers assumed for the evaluation. <p> Long message passing does not require any significant additional hardware since the mechanism is embedded in the memory subsystem. Packet Router Dynamic interconnection demands routers with three characteristics: First, they must exhibit extremely low latency. Our implementation studies and others <ref> [4, 8, 17, 33] </ref> show that router latencies in the 5-10 nanosecond range are feasible if chip crossing costs are reduced with advanced packaging. Second, it must have multiple input and output ports, supplying or absorbing several packets at a time. <p> For example, if the network used dimension-order routing, all packets would have to route in X first, making it impossible to inject in the Y dimension. Recent advances in the design of simple adaptive routers indicates that such networks overhead likely to be modest <ref> [4, 8] </ref>. A comparable router design we completed required only 18 M 2 , 1% of a modern microprocessor's die area. Also, our design study of three adaptive routing schemes [5, 9, 28] shows that 27 they all require less than 10,000 gates for 2-dimensional network [8]. <p> A comparable router design we completed required only 18 M 2 , 1% of a modern microprocessor's die area. Also, our design study of three adaptive routing schemes [5, 9, 28] shows that 27 they all require less than 10,000 gates for 2-dimensional network <ref> [8] </ref>. Finally, they must use bidirectional channels. This allows all of the processor pins to be utilized for dynamic interconnections. A number of routers which use bidirectional signalling have already been constructed [5, 17]. Memory Nodes Dynamic interconnection memory nodes require a router and packet processing hardware.
Reference: [9] <author> Chien, A. A., and Kim, J. H. </author> <title> Planar-adaptive routing: Low-cost adaptive networks for multiprocessors. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pp. 268-77, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Recent advances in the design of simple adaptive routers indicates that such networks overhead likely to be modest [4, 8]. A comparable router design we completed required only 18 M 2 , 1% of a modern microprocessor's die area. Also, our design study of three adaptive routing schemes <ref> [5, 9, 28] </ref> shows that 27 they all require less than 10,000 gates for 2-dimensional network [8]. Finally, they must use bidirectional channels. This allows all of the processor pins to be utilized for dynamic interconnections. A number of routers which use bidirectional signalling have already been constructed [5, 17].
Reference: [10] <author> Choi, L., and Chien, A. </author> <title> Integrating networks and memory hierarchies in a multicomputer node architecture. </title> <booktitle> In Proceedings of the International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: For example, in the Intel Paragon XP/S, the average hardware network latency is less than one s, yet the minimum process to fl A preliminary version of some of this work appears in <ref> [10] </ref>. 1 process communication delay is over 15 s. Such high communication delay confines the machine to the exploitation of medium-grained parallelism, limiting the application scope and scalability of these machines. In addition, medium-grained machines exhibit other critical problems.
Reference: [11] <author> Choi, L., and Yew, P. C. </author> <title> A Compiler-Directed Cache Coherence Scheme with Improved Intertask Locality. </title> <booktitle> In Proceedings of the ACM/IEEE Supercomputing, </booktitle> <pages> pp. 773-782, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Maintaining global cache coherence is possible but an orthogonal issue for the DI-based systems, although each node has locally coherent caches. 5 Either hardware directory-based coherence protocols [2, 26] or software coherence schemes <ref> [7, 11] </ref> can be used to provide a cache coherent shared address space. Internode Synchronization A node can communicate with other nodes with message passing. In DI-multicomputer, short and long messages use different mechanisms for synchronization as they are differently handled for message passing. <p> This means that incoming short messages still need to be fetched from memory, increasing the latency. The issue of implementing global cache coherence is an orthogonal issue to the DI-based systems. Either hardware directory-based coherence protocols [2, 26] or software-based approaches <ref> [7, 11] </ref> can be implemented on top of the DI-based systems to support the cache coherence. 9 Summary The DI-multicomputer uses dynamic interconnection and novel message handling mechanisms to increase in memory bandwidth and reduce message passing overhead.
Reference: [12] <institution> Cray Research Inc. </institution> <note> SHMEM User's Guide. </note> <year> 1994. </year>
Reference-contexts: The trap handler routine shown in Figure 11 loads a message from memory into an empty context and creates a new thread. 5.2 Long Messages The packet-based memory interface of the DI-multicomputer supports the PUT/GET primitives of shared-memory libraries <ref> [12] </ref> directly in hardware. This allows a high-bandwidth and low overhead 15 communication for long messages for both internode (PUT/GET) and intra-node (local memory-to-memory copy) communication. with those of other multicomputer node architectures.
Reference: [13] <author> Dally, W. J. </author> <title> Express cubes: Improving the performance of k-ary n-cube interconnection networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 40(9) </volume> <pages> 1016-1023, </pages> <year> 1991. </year>
Reference-contexts: Our studies confirm that the DI-multicomputer achieves more robust scalable performance for larger machine sizes than the target architectures. We have only begun to explore the possibilities of dynamic interconnection-based systems. There are a number of obvious optimizations: express cubes <ref> [13] </ref> can reduce the routing penalty in the dynamic interconnection and the network/memory hierarchy interference, and extremely large messages can be broken into several MOVE instructions to exploit greater communication parallelism, etc. The global physical address space can support a variety of additional functionality.
Reference: [14] <author> Dally, W. J. </author> <title> Virtual channel flow control. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(2) </volume> <pages> 194-205, </pages> <year> 1992. </year>
Reference-contexts: Regular point-to-point interconnects maximize signalling speeds by minimizing the capacitive and the inductive loads of each wire. Packet routing allows communication resources to be shared efficiently. 4 Advances in packet routers allow them to attain channel utilizations in excess of 90% <ref> [14] </ref> and extremely low latency [33]. These characteristics enable dynamic interconnection systems to achieve comparable communication latencies and much higher bandwidth. Dynamic interconnection systems have two major advantages. First, pooling communication resources among several tasks eliminates the resource idle time in the static interconnection system.
Reference: [15] <author> Dally, W. J., Chien, A., Fiske, S., Horwat, W., Keen, J., Larivee, M., Lethin, R., Nuth, P., Wills, S., Carrick, P., and Fyler, G. </author> <title> The J-Machine: A fine-grain concurrent computer. </title> <booktitle> In Information Processing 89, Proceedings of the IFIP Congress, </booktitle> <pages> pp. 1147-1153, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: By integrating the router onto the processor chip and deeply into the processing core, fine-grained architectures can dramatically reduce communication overhead. However a fine-grained approach requires changes to the microprocessor interface, and significant redesign of the processor. The fine-grained approach, is exemplified by the MIT J-machine <ref> [15, 16] </ref>, Intel iWARP [29], and Inmos Transputer [35]. Fine-grained architectures also have several critical performance problems. First, by integrating a router on the processor, they statically partition the processor pin bandwidth between local memory access and internode communication. <p> Long messages are routed directly from local memory to remote memory under software control. 1 As a variety of designs have shown [17], a router need not require a large amount of hardware. For example, the three dimensional router used in the J-machine <ref> [15] </ref> requires only 29,000 transistors. 2 The instruction set design and the memory and message packet formats of the DI-microprocessor are described in Appendix A and B. 5 Details of the memory and network interfaces are described in Sections 4 and 5. <p> Moreover, it allows the computation to overlap with message reception. This message driven reception mechanism is similar to that of J-machine <ref> [15] </ref>. However, it differs from J-machine in that the reception is based on the register file rather than memory, so it's not necessary to load the messages from memory except in the special cases. A dedicated hardware context moves the incoming messages into memory for message overflow cases. <p> Speedup versus Register Based Message Handling To study the performance impact of the memory hierarchy traffic overhead of the register based message handling, we simulate an another architecture, called Short architecture, which is similar to several fine-grained architectures <ref> [15, 29] </ref> and has user level message handling based on the register file. And we compare its result to that of the DI-multicomputer.
Reference: [16] <author> Dally, W. J., Fiske, J. A. S., Keen, J. S., Lethin, R. A., Noakes, M. D., Nuth, P. R., Davison, R. E., and Fyler, G A. </author> <title> The message-driven processor. </title> <booktitle> IEEE Micro, </booktitle> <month> April </month> <year> 1992. </year>
Reference-contexts: By integrating the router onto the processor chip and deeply into the processing core, fine-grained architectures can dramatically reduce communication overhead. However a fine-grained approach requires changes to the microprocessor interface, and significant redesign of the processor. The fine-grained approach, is exemplified by the MIT J-machine <ref> [15, 16] </ref>, Intel iWARP [29], and Inmos Transputer [35]. Fine-grained architectures also have several critical performance problems. First, by integrating a router on the processor, they statically partition the processor pin bandwidth between local memory access and internode communication. <p> An unavoidable consequence is that it impossible to support both high performance network and memory interfaces in multicomputer building blocks such as the iWARP [29] and MDP <ref> [16] </ref>. They all compromise, yielding mediocre network or memory system performance. The difference signalling rates of buses versus point to point interconnects is well documented and typically a factor of 3 or 4 in clock rate [18, 31]. Table I: Pin allocation and input/output performance. <p> And this number identifies which outstanding memory request it is in order to match replies to requests. 9 These define source node address, cache line size, etc. 11 Though several fine-grained machines <ref> [16, 29] </ref> incorporate on-chip network interfaces, they typically lack high performance memory interfaces. Without multi-packet mechanisms the communication bandwidth of a single router channel is far less than a typical bus-based memory interface, providing insufficient bandwidth to compete with a bus-based memory hierarchy. <p> Integration of the processor core with a network interface and router has been explored in the iWARP [29] and MDP <ref> [16] </ref>. We are currently exploring a variety of implementation approaches (gate-array, standard cell, and full custom VLSI). In this section, we briefly discuss the additional hardware requirements and likely speed of these implementations. <p> The Scalable Coherent Interface (IEEE P1596) also uses point-to-point links to achieve high speed signaling [20], but the ring topology used in SCI increases memory access latency. The J-machine <ref> [16] </ref> addresses message handling overhead with hardware support, by putting the network interface on chip and providing hardware to queue incoming messages. Processor-network interface studies for the fl T project [21] have addressed the issue of how to couple processors with the network.
Reference: [17] <author> Dally, W. J., and Song, P. </author> <title> Design of a self-timed vlsi multicomputer communication controller. </title> <booktitle> In Proceedings of the International Conference on Computer Design, </booktitle> <pages> pp. 230-4. </pages> <publisher> IEEE Computer Society, </publisher> <year> 1987. </year>
Reference-contexts: In particular, short messages are routed directly onto the processor chip, allowing them to be handled with low latency. Long messages are routed directly from local memory to remote memory under software control. 1 As a variety of designs have shown <ref> [17] </ref>, a router need not require a large amount of hardware. <p> The higher network clock rate for the DI-microprocessor memory interface is due to the electrical advantages of point-to-point interconnects over multi-tap bus lines [31, 18]. Router delay is based on a number of published implementation studies <ref> [17, 32] </ref> and our own designs [4, 8]. The actions required to complete a cache line reload in each system are illustrated in Figure 15. Table III: Memory and interconnect performance numbers assumed for the evaluation. <p> Long message passing does not require any significant additional hardware since the mechanism is embedded in the memory subsystem. Packet Router Dynamic interconnection demands routers with three characteristics: First, they must exhibit extremely low latency. Our implementation studies and others <ref> [4, 8, 17, 33] </ref> show that router latencies in the 5-10 nanosecond range are feasible if chip crossing costs are reduced with advanced packaging. Second, it must have multiple input and output ports, supplying or absorbing several packets at a time. <p> Finally, they must use bidirectional channels. This allows all of the processor pins to be utilized for dynamic interconnections. A number of routers which use bidirectional signalling have already been constructed <ref> [5, 17] </ref>. Memory Nodes Dynamic interconnection memory nodes require a router and packet processing hardware. This hardware can be added to individual dynamic RAM chips, or the cost can be amortized over a number of chips. A block diagram of a memory node design is shown in Figure 21.
Reference: [18] <author> Davidson, E. E. </author> <title> Electrical design of a high speed computer packaging system. </title> <journal> IEEE Transactions on Components, Hybrids and Manufacturing Technology, </journal> <volume> CHMT-6(3):272-282, </volume> <year> 1983. </year>
Reference-contexts: Partitioning communication resources between router and memory interface prevents efficient uti lization of available pin bandwidth. 2. Irregular or multi-tap interconnects (buses) increase capacitive loading and signal reflections, lim iting the maximum switching speed <ref> [18, 31, 20] </ref> and reducing available pin bandwidth. Table I demonstrates the problem of static pin allocation in existing microprocessors. First, in off-the-shelf microprocessors such as Intel i860XP and DEC Alpha, only about 40% of signal pins are allocated for data transfer due to address and control signals. <p> They all compromise, yielding mediocre network or memory system performance. The difference signalling rates of buses versus point to point interconnects is well documented and typically a factor of 3 or 4 in clock rate <ref> [18, 31] </ref>. Table I: Pin allocation and input/output performance. <p> The higher network clock rate for the DI-microprocessor memory interface is due to the electrical advantages of point-to-point interconnects over multi-tap bus lines <ref> [31, 18] </ref>. Router delay is based on a number of published implementation studies [17, 32] and our own designs [4, 8]. The actions required to complete a cache line reload in each system are illustrated in Figure 15. Table III: Memory and interconnect performance numbers assumed for the evaluation.
Reference: [19] <institution> Digital Equipment Corporation. Alpha Architecture Handbook, </institution> <year> 1992. </year> <month> 30 </month>
Reference-contexts: The DI-microprocessor uses a DEC Alpha microprocessor architecture <ref> [19] </ref> as its base RISC processor. The DI-microprocessor instruction set architecture uses a subset of the DEC Alpha microprocessor instruction set augmented with instruction support for message passing, address translation and synchronization. 2 The high-level organization of the DI-microprocessor is shown in Figure 3.
Reference: [20] <author> Gustavson, D. B. </author> <title> The scalable coherent interface and related standards projects. </title> <journal> IEEE Micro, </journal> <volume> 12(1), </volume> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: Partitioning communication resources between router and memory interface prevents efficient uti lization of available pin bandwidth. 2. Irregular or multi-tap interconnects (buses) increase capacitive loading and signal reflections, lim iting the maximum switching speed <ref> [18, 31, 20] </ref> and reducing available pin bandwidth. Table I demonstrates the problem of static pin allocation in existing microprocessors. First, in off-the-shelf microprocessors such as Intel i860XP and DEC Alpha, only about 40% of signal pins are allocated for data transfer due to address and control signals. <p> This hardware can be added to individual dynamic RAM chips, or the cost can be amortized over a number of chips. A block diagram of a memory node design is shown in Figure 21. Self-refresh capability is built in. Other designs <ref> [30, 20] </ref> have shown that the latency due to packet processing is small compared to memory access latency. 8 Discussion and Related Work Dynamic allocation of communication resources is not a new idea. <p> Dynamic interconnection is distinguished from Rambus primarily by the use of a general point-to-point interconnect and packet routing and the support for multiple masters and sharing 28 of memory modules. The Scalable Coherent Interface (IEEE P1596) also uses point-to-point links to achieve high speed signaling <ref> [20] </ref>, but the ring topology used in SCI increases memory access latency. The J-machine [16] addresses message handling overhead with hardware support, by putting the network interface on chip and providing hardware to queue incoming messages.
Reference: [21] <author> Henry, D. S., and Joerg, C. F. </author> <title> A tightly-coupled processor-network interface. </title> <booktitle> In Proceedings of the Fifth International Conference on Architectural Support for Programming Languages an Operating Systems, </booktitle> <pages> pp. 111-122, </pages> <year> 1992. </year>
Reference-contexts: The J-machine [16] addresses message handling overhead with hardware support, by putting the network interface on chip and providing hardware to queue incoming messages. Processor-network interface studies for the fl T project <ref> [21] </ref> have addressed the issue of how to couple processors with the network. However, like existing fine-grained architectures, their register-file based message handling suffers from the memory hierarchy traffic overhead. The Fujitsu AP1000 [22] includes hardware support for two different message classes.
Reference: [22] <author> Horie, T., et al. </author> <title> AP1000 architecture and performance of LU decomposition. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <year> 1991. </year>
Reference-contexts: The first interfaces the network to a local bus, allowing network-memory data transfers and preserving microprocessor interface compatibility. We term this approach the medium-grained approach, and it is exemplified by commercial machines such as the Intel Paragon XP/S [25], Thinking Machine CM-5 [34], and Fujitsu AP1000 <ref> [22] </ref>. Using a stock microprocessor as a building block typically produces poor coupling of processor and network, increasing the software overhead for communication. <p> Processor-network interface studies for the fl T project [21] have addressed the issue of how to couple processors with the network. However, like existing fine-grained architectures, their register-file based message handling suffers from the memory hierarchy traffic overhead. The Fujitsu AP1000 <ref> [22] </ref> includes hardware support for two different message classes. However, its line send mechanism for short messages is based on a hardware managed queue in memory, not an on-chip FIFO as in the DI-multicomputer. This means that incoming short messages still need to be fetched from memory, increasing the latency.
Reference: [23] <author> Hsu, J. M. </author> <title> Performance measurement and hardware support for message passing distributed memory multiprocessors. </title> <type> Technical Report UILC-ENG-91-2209, </type> <institution> University of Illinois, Center for Reliable and High-Performance Computing, </institution> <year> 1991. </year>
Reference-contexts: Trace-driven simulation using iPSC/2 traces <ref> [23] </ref> are used to address the following questions: (1) How much do the DI-multicomputer communication primitives speed up applications?, (2) How much performance improvement do the distinct mechanisms for short and long messages give?, and (3) How do machine size ( number of processors) and application granularity affect these tradeoffs? Our <p> Applications The communication traces are collected from the following seven parallel applications (2 VLSI CAD applications, 4 numerical applications and 1 event-driven simulator). The applications are described in Table VI. The traces are derived from <ref> [23] </ref>. 21 Table VI: The description of parallel applications that are used for simulation.
Reference: [24] <author> Intel Corporation. </author> <title> i860 XP Microprocessor Data Book, </title> <year> 1991. </year>
Reference-contexts: As a case study, we compare the bus-based memory interface of the Intel i860XP <ref> [24] </ref> to our DI-microprocessor memory interface. To make the comparison fair, we assume the processors have the same internals, with single level on-chip cache and approximately the same number of I/O pins (see Figure 14).
Reference: [25] <author> Intel Corporation. </author> <title> Paragon XP/S Product Overview, </title> <year> 1991. </year>
Reference-contexts: The first interfaces the network to a local bus, allowing network-memory data transfers and preserving microprocessor interface compatibility. We term this approach the medium-grained approach, and it is exemplified by commercial machines such as the Intel Paragon XP/S <ref> [25] </ref>, Thinking Machine CM-5 [34], and Fujitsu AP1000 [22]. Using a stock microprocessor as a building block typically produces poor coupling of processor and network, increasing the software overhead for communication.
Reference: [26] <author> D., Laudon, J., Gharachorloo, K., Gupta, A., and Hennessy, J. </author> <title> The Directory-Based Cache Coherence Protocol for the DASH Computer. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 148-159, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Maintaining global cache coherence is possible but an orthogonal issue for the DI-based systems, although each node has locally coherent caches. 5 Either hardware directory-based coherence protocols <ref> [2, 26] </ref> or software coherence schemes [7, 11] can be used to provide a cache coherent shared address space. Internode Synchronization A node can communicate with other nodes with message passing. In DI-multicomputer, short and long messages use different mechanisms for synchronization as they are differently handled for message passing. <p> This means that incoming short messages still need to be fetched from memory, increasing the latency. The issue of implementing global cache coherence is an orthogonal issue to the DI-based systems. Either hardware directory-based coherence protocols <ref> [2, 26] </ref> or software-based approaches [7, 11] can be implemented on top of the DI-based systems to support the cache coherence. 9 Summary The DI-multicomputer uses dynamic interconnection and novel message handling mechanisms to increase in memory bandwidth and reduce message passing overhead.
Reference: [27] <author> Metcalfe, R., and Boggs, D. </author> <title> Ethernet: Distributed packet-switching for local computer networks. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 19(7) </volume> <pages> 395-404, </pages> <year> 1976. </year>
Reference-contexts: Several systems use dynamic allocation of communication resources when their efficient utilization is at a premium <ref> [6, 27] </ref>. Applying network-based dynamic interconnection to low-level interconnection has been discussed in the fine-grain multicomputer community for some time.
Reference: [28] <author> Ni, L., and Glass, C. </author> <title> The turn model for adaptive routing. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <year> 1992. </year>
Reference-contexts: Recent advances in the design of simple adaptive routers indicates that such networks overhead likely to be modest [4, 8]. A comparable router design we completed required only 18 M 2 , 1% of a modern microprocessor's die area. Also, our design study of three adaptive routing schemes <ref> [5, 9, 28] </ref> shows that 27 they all require less than 10,000 gates for 2-dimensional network [8]. Finally, they must use bidirectional channels. This allows all of the processor pins to be utilized for dynamic interconnections. A number of routers which use bidirectional signalling have already been constructed [5, 17].
Reference: [29] <author> Peterson, C., Sutton, J., and Wiley, P. </author> <title> iWarp: a 100-MOPS LIW microprocessor for multicomputers. </title> <booktitle> IEEE Micro, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: However a fine-grained approach requires changes to the microprocessor interface, and significant redesign of the processor. The fine-grained approach, is exemplified by the MIT J-machine [15, 16], Intel iWARP <ref> [29] </ref>, and Inmos Transputer [35]. Fine-grained architectures also have several critical performance problems. First, by integrating a router on the processor, they statically partition the processor pin bandwidth between local memory access and internode communication. <p> An unavoidable consequence is that it impossible to support both high performance network and memory interfaces in multicomputer building blocks such as the iWARP <ref> [29] </ref> and MDP [16]. They all compromise, yielding mediocre network or memory system performance. The difference signalling rates of buses versus point to point interconnects is well documented and typically a factor of 3 or 4 in clock rate [18, 31]. Table I: Pin allocation and input/output performance. <p> And this number identifies which outstanding memory request it is in order to match replies to requests. 9 These define source node address, cache line size, etc. 11 Though several fine-grained machines <ref> [16, 29] </ref> incorporate on-chip network interfaces, they typically lack high performance memory interfaces. Without multi-packet mechanisms the communication bandwidth of a single router channel is far less than a typical bus-based memory interface, providing insufficient bandwidth to compete with a bus-based memory hierarchy. <p> Speedup versus Register Based Message Handling To study the performance impact of the memory hierarchy traffic overhead of the register based message handling, we simulate an another architecture, called Short architecture, which is similar to several fine-grained architectures <ref> [15, 29] </ref> and has user level message handling based on the register file. And we compare its result to that of the DI-multicomputer. <p> Integration of the processor core with a network interface and router has been explored in the iWARP <ref> [29] </ref> and MDP [16]. We are currently exploring a variety of implementation approaches (gate-array, standard cell, and full custom VLSI). In this section, we briefly discuss the additional hardware requirements and likely speed of these implementations.
Reference: [30] <author> Rambus Corporation. </author> <title> Rambus architectural overview. Product Literature, </title> <year> 1992. </year>
Reference-contexts: This hardware can be added to individual dynamic RAM chips, or the cost can be amortized over a number of chips. A block diagram of a memory node design is shown in Figure 21. Self-refresh capability is built in. Other designs <ref> [30, 20] </ref> have shown that the latency due to packet processing is small compared to memory access latency. 8 Discussion and Related Work Dynamic allocation of communication resources is not a new idea. <p> A number of new processor memory interfaces have been proposed which address memory bandwidth limitations. The Rambus uses a 9-bit data channel which runs at 250 Mhz and achieves rates of 500MByte/s <ref> [30] </ref>. Dynamic interconnection is distinguished from Rambus primarily by the use of a general point-to-point interconnect and packet routing and the support for multiple masters and sharing 28 of memory modules.
Reference: [31] <author> Matsui, N., Satoh, H., and Okada, K. </author> <title> Analysis of high-speed bus lines in printed circuit boards. </title> <booktitle> In IEEE/CHMT Japan IEMT Symposium, </booktitle> <pages> pp. 156-167. </pages> <publisher> IEEE, </publisher> <year> 1989. </year>
Reference-contexts: Partitioning communication resources between router and memory interface prevents efficient uti lization of available pin bandwidth. 2. Irregular or multi-tap interconnects (buses) increase capacitive loading and signal reflections, lim iting the maximum switching speed <ref> [18, 31, 20] </ref> and reducing available pin bandwidth. Table I demonstrates the problem of static pin allocation in existing microprocessors. First, in off-the-shelf microprocessors such as Intel i860XP and DEC Alpha, only about 40% of signal pins are allocated for data transfer due to address and control signals. <p> They all compromise, yielding mediocre network or memory system performance. The difference signalling rates of buses versus point to point interconnects is well documented and typically a factor of 3 or 4 in clock rate <ref> [18, 31] </ref>. Table I: Pin allocation and input/output performance. <p> The higher network clock rate for the DI-microprocessor memory interface is due to the electrical advantages of point-to-point interconnects over multi-tap bus lines <ref> [31, 18] </ref>. Router delay is based on a number of published implementation studies [17, 32] and our own designs [4, 8]. The actions required to complete a cache line reload in each system are illustrated in Figure 15. Table III: Memory and interconnect performance numbers assumed for the evaluation.
Reference: [32] <author> Seitz, C., and Su, W. </author> <title> A family of routing and communication chips based on the Mosaic. </title> <booktitle> In Proceedings of the University of Washington Symposium on Integrated Systems, </booktitle> <year> 1993. </year>
Reference-contexts: The higher network clock rate for the DI-microprocessor memory interface is due to the electrical advantages of point-to-point interconnects over multi-tap bus lines [31, 18]. Router delay is based on a number of published implementation studies <ref> [17, 32] </ref> and our own designs [4, 8]. The actions required to complete a cache line reload in each system are illustrated in Figure 15. Table III: Memory and interconnect performance numbers assumed for the evaluation.
Reference: [33] <author> Seitz, C. L. </author> <title> Let's route packets instead of wires. </title> <editor> In W. J. Dally, editor, </editor> <booktitle> Proceedings of the 6th MIT Conference on Advanced Research in VLSI, </booktitle> <pages> pp. 133-37. </pages> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Regular point-to-point interconnects maximize signalling speeds by minimizing the capacitive and the inductive loads of each wire. Packet routing allows communication resources to be shared efficiently. 4 Advances in packet routers allow them to attain channel utilizations in excess of 90% [14] and extremely low latency <ref> [33] </ref>. These characteristics enable dynamic interconnection systems to achieve comparable communication latencies and much higher bandwidth. Dynamic interconnection systems have two major advantages. First, pooling communication resources among several tasks eliminates the resource idle time in the static interconnection system. <p> Long message passing does not require any significant additional hardware since the mechanism is embedded in the memory subsystem. Packet Router Dynamic interconnection demands routers with three characteristics: First, they must exhibit extremely low latency. Our implementation studies and others <ref> [4, 8, 17, 33] </ref> show that router latencies in the 5-10 nanosecond range are feasible if chip crossing costs are reduced with advanced packaging. Second, it must have multiple input and output ports, supplying or absorbing several packets at a time. <p> Seitz was the first to describe the dynamic interconnection idea in print and observe some of its advantages such as the higher signaling speed and the capability of parallel transactions of point-to-point direct networks <ref> [33] </ref>. However, he introduces the possibility of DI-based systems without discussing memory hierarchy and network interface issues. The Tera architecture [3] also implements its memory subsystem with interleaved memory units interconnected by a packet-switched interconnection network.
Reference: [34] <institution> Thinking Machines Corporation, Cambridge, Massachusetts. </institution> <type> CM-5 Technical Summary, </type> <month> October </month> <year> 1991. </year>
Reference-contexts: The first interfaces the network to a local bus, allowing network-memory data transfers and preserving microprocessor interface compatibility. We term this approach the medium-grained approach, and it is exemplified by commercial machines such as the Intel Paragon XP/S [25], Thinking Machine CM-5 <ref> [34] </ref>, and Fujitsu AP1000 [22]. Using a stock microprocessor as a building block typically produces poor coupling of processor and network, increasing the software overhead for communication.
Reference: [35] <author> Whitby-Strevens, C. </author> <title> The transputer. </title> <booktitle> In Proceedings of 12th International Symposium on Computer Architecture, </booktitle> <year> 1985. </year>
Reference-contexts: However a fine-grained approach requires changes to the microprocessor interface, and significant redesign of the processor. The fine-grained approach, is exemplified by the MIT J-machine [15, 16], Intel iWARP [29], and Inmos Transputer <ref> [35] </ref>. Fine-grained architectures also have several critical performance problems. First, by integrating a router on the processor, they statically partition the processor pin bandwidth between local memory access and internode communication. For each of the fine-grained designs mentioned, this reduces local memory performance and therefore limits local computation speed.
References-found: 35

