URL: http://www.neci.nj.nec.com/homepages/lawrence/papers/finance-tr96/finance-tr96-letter.ps.gz
Refering-URL: http://www.neci.nj.nec.com/homepages/lawrence/papers/finance-tr96/finance-tr96-24.html
Root-URL: 
Email: flawrence,gilesg@research.nj.nec.com, Ah Chung Tsoi@uow.edu.au  
Phone: 1  2  
Title: Noisy Time Series Prediction using Symbolic Representation and Recurrent Neural Network Grammatical Inference  
Author: Steve Lawrence fl Ah Chung Tsoi C. Lee Giles yz 
Web: http://www.neci.nj.nec.com/homepages/giles.html  
Note: http://www.neci.nj.nec.com/homepages/lawrence Lee Giles is also with the  
Address: 4 Independence Way, Princeton, NJ 08540  NSW 2522 Australia  College Park, MD 20742  College Park, MD 20742.  
Affiliation: NEC Research Institute,  Faculty of Informatics, University of Wollongong,  Institute for Advanced Computer Studies University of Maryland  Institute for Advanced Computer Studies, University of Maryland,  
Pubnum: Technical Report UMIACS-TR-96-27 and CS-TR-3625  
Abstract: Financial forecasting is an example of a signal processing problem which is challenging due to small sample sizes, high noise, non-stationarity, and non-linearity. Neural networks have been very successful in a number of signal processing applications. We discuss fundamental limitations and inherent difficulties when using neural networks for the processing of high noise, small sample size signals. We introduce a new intelligent signal processing method which addresses the difficulties. The method uses conversion into a symbolic representation with a self-organizing map, and grammatical inference with recurrent neural networks. We apply the method to the prediction of daily foreign exchange rates, addressing difficulties with non-stationarity, overfitting, and unequal a priori class probabilities, and we find significant predictability in comprehensive experiments covering 5 different foreign exchange rates. The method correctly predicts the direction of change for the next day with an error rate of 47.1%. The error rate reduces to around 40% when rejecting examples where the system has low confidence in its prediction. The symbolic representation aids the extraction of symbolic knowledge from the recurrent neural networks in the form of deterministic finite state automata. These automata explain the operation of the system and are often relatively simple. Rules related to well known behavior such as trend following and mean reversal are extracted. 
Abstract-found: 1
Intro-found: 1
References-found: 0

