URL: file://cse.ogi.edu/pub/tech-reports/1990/016.ps.gz
Refering-URL: http://www.cse.ogi.edu/Sparse/sparse.papers.html
Root-URL: http://www.cse.ogi.edu
Email: mwolfe@cse.ogi.edu  
Phone: (503)-690-1153  
Title: Experiences with Data Dependence and Loop Restructuring in the Tiny Research Tool  
Author: Michael Wolfe 
Address: 19600 NW von Neumann Drive Beaverton, OR 97006  
Affiliation: Oregon Graduate Institute of Science and Technology Department of Computer Science and Engineering  
Abstract-found: 0
Intro-found: 1
Reference: [AKL81] <author> W. A. Abu-Sufah, D. J. Kuck and D. H. Lawrie, </author> <title> On the Performance Enhancement of Paging Systems Through Program Analysis and Transformations, </title> <journal> IEEE Trans. on Computers C-30, </journal> <month> 5 (May </month> <year> 1981), </year> <pages> 341-356. </pages>
Reference-contexts: representative citation (instead of an exhaustive list); a summary of many of these transformations is 1 available in the monograph [Wol89]. ____________________________________________ transformation enhances reference ____________________________________________ vectorization parallelism [Sch72] parallelization parallelism [ACK87] strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism [Wol86] tiling memory <ref> [AKL81] </ref> fusion overhead [AKL81] reversal interchanging [Wol89] alignment parallelism [ACK87] splitting parallelism [Ban79] rotation communication [Wol90a] ____________________________________________L L L L L L L L L L L L L L L L L L L L L L L L L L L An entry of "enhances memory" means the transformation <p> of an exhaustive list); a summary of many of these transformations is 1 available in the monograph [Wol89]. ____________________________________________ transformation enhances reference ____________________________________________ vectorization parallelism [Sch72] parallelization parallelism [ACK87] strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism [Wol86] tiling memory <ref> [AKL81] </ref> fusion overhead [AKL81] reversal interchanging [Wol89] alignment parallelism [ACK87] splitting parallelism [Ban79] rotation communication [Wol90a] ____________________________________________L L L L L L L L L L L L L L L L L L L L L L L L L L L An entry of "enhances memory" means the transformation enhances the performance
Reference: [AlK84] <author> J. R. Allen and K. Kennedy, </author> <title> Automatic Loop Interchange, </title> <booktitle> in Proc. of the SIGPLAN 84 Symposium on Compiler Construction, </booktitle> <address> New York, </address> <month> June </month> <year> 1984, </year> <pages> 233-246. </pages>
Reference-contexts: these transformations below; in each case we give a representative citation (instead of an exhaustive list); a summary of many of these transformations is 1 available in the monograph [Wol89]. ____________________________________________ transformation enhances reference ____________________________________________ vectorization parallelism [Sch72] parallelization parallelism [ACK87] strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism <ref> [AlK84] </ref> interchanging memory [GJG88] skewing parallelism [Wol86] tiling memory [AKL81] fusion overhead [AKL81] reversal interchanging [Wol89] alignment parallelism [ACK87] splitting parallelism [Ban79] rotation communication [Wol90a] ____________________________________________L L L L L L L L L L L L L L L L L L L L L L L L L L <p> In the late 1970's and early 1980's, research efforts at the University of Illinois, Rice University, and elsewhere developed compiler technology that could automatically detect when it was legal to interchange loops <ref> [AlK84] </ref>. This technology uses the concept of dependence distance, but with a separate dependence distance computed for each surrounding loop. In the original program fragment above, for instance, a compiler would find a distance vectorO comprising two elements, the first for the I loop and another for the J loop.
Reference: [ACK87] <author> R. Allen, D. Callahan and K. Kennedy, </author> <title> Automatic Decomposition of Scientific Programs for Parallel Execution, </title> <booktitle> in Conf. Record of the 14th Annual ACM Symp. on Principles of Programming Languages, </booktitle> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1987, </year> <pages> 63-76. </pages>
Reference-contexts: We present a table of some of these transformations below; in each case we give a representative citation (instead of an exhaustive list); a summary of many of these transformations is 1 available in the monograph [Wol89]. ____________________________________________ transformation enhances reference ____________________________________________ vectorization parallelism [Sch72] parallelization parallelism <ref> [ACK87] </ref> strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism [Wol86] tiling memory [AKL81] fusion overhead [AKL81] reversal interchanging [Wol89] alignment parallelism [ACK87] splitting parallelism [Ban79] rotation communication [Wol90a] ____________________________________________L L L L L L L L L L L L L L L L <p> of many of these transformations is 1 available in the monograph [Wol89]. ____________________________________________ transformation enhances reference ____________________________________________ vectorization parallelism [Sch72] parallelization parallelism <ref> [ACK87] </ref> strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism [Wol86] tiling memory [AKL81] fusion overhead [AKL81] reversal interchanging [Wol89] alignment parallelism [ACK87] splitting parallelism [Ban79] rotation communication [Wol90a] ____________________________________________L L L L L L L L L L L L L L L L L L L L L L L L L L L An entry of "enhances memory" means the transformation enhances the performance of memory hierarchies.
Reference: [AlK87] <author> J. R. Allen and K. Kennedy, </author> <title> Automatic Translation of Fortran Programs to Vector Form, </title> <journal> ACM Transactions on Programming Languages and Systems 9, </journal> <month> 4 (October </month> <year> 1987), </year> <pages> 491-542. </pages>
Reference-contexts: of some of these transformations below; in each case we give a representative citation (instead of an exhaustive list); a summary of many of these transformations is 1 available in the monograph [Wol89]. ____________________________________________ transformation enhances reference ____________________________________________ vectorization parallelism [Sch72] parallelization parallelism [ACK87] strip mining vectorization [Lov77] distribution vectorization <ref> [AlK87] </ref> interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism [Wol86] tiling memory [AKL81] fusion overhead [AKL81] reversal interchanging [Wol89] alignment parallelism [ACK87] splitting parallelism [Ban79] rotation communication [Wol90a] ____________________________________________L L L L L L L L L L L L L L L L L L L L L L L <p> One problem with this approach is the increase in the cost of the development of the compiler as a whole. As an example, Allen and Kennedy's paper <ref> [AlK87] </ref> describe a special form of Banerjee's inequalities to test whether two loops can be interchanged; this is an example of the second alternative above, a special dependence test for one transformation. <p> The point at which to split the index set is called the crossing threshold <ref> [AlK87] </ref>, and its computation is shown in Banerjee's thesis [Ban79]. Reduction Directions: The dependence test for vectorizing an innermost loop is that there must be no dependence cycle (after ignoring dependence relations carried by outer loops). <p> Determination of which loop "carries" a dependence can be done directly from the direction vector <ref> [AlK87] </ref>, and many of the transformations need only the information available in the direction and distance vectors. Tiny also uses the enhanced direction vectors, with reduction information. When a transformation is attempted that requires information outside of the direction or distance vector abstraction, Tiny calls special case dependence tests.
Reference: [Ban76] <author> U. Banerjee, </author> <title> Data Dependence in Ordinary Programs, </title> <institution> UIUCDCS-R-76-837, Univ. Illinois, Dept. Computer Science, Urbana, IL, </institution> <month> November </month> <year> 1976. </year>
Reference: [BCK79] <author> U. Banerjee, S. Chen, D. J. Kuck and R. A. Towle, </author> <title> Time and Parallel Processor Bounds for Fortran-Like Loops, </title> <journal> IEEE Trans. on Computers C-28, </journal> <month> 9 (September </month> <year> 1979), </year> <pages> 660-670. </pages>
Reference: [Ban79] <author> U. Banerjee, </author> <title> Speedup of Ordinary Programs, </title> <type> PhD Thesis, </type> <institution> Univ. of Illinois, </institution> <month> October </month> <year> 1979. </year> <pages> (UMI 80-08967). </pages>
Reference-contexts: these transformations is 1 available in the monograph [Wol89]. ____________________________________________ transformation enhances reference ____________________________________________ vectorization parallelism [Sch72] parallelization parallelism [ACK87] strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism [Wol86] tiling memory [AKL81] fusion overhead [AKL81] reversal interchanging [Wol89] alignment parallelism [ACK87] splitting parallelism <ref> [Ban79] </ref> rotation communication [Wol90a] ____________________________________________L L L L L L L L L L L L L L L L L L L L L L L L L L L An entry of "enhances memory" means the transformation enhances the performance of memory hierarchies. <p> The point at which to split the index set is called the crossing threshold [AlK87], and its computation is shown in Banerjee's thesis <ref> [Ban79] </ref>. Reduction Directions: The dependence test for vectorizing an innermost loop is that there must be no dependence cycle (after ignoring dependence relations carried by outer loops).
Reference: [Ban88] <author> U. Banerjee, </author> <title> Dependence Analysis for Supercomputing, </title> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1988. </year>
Reference-contexts: Other tests have even stronger overheads; the Power Test 6 [WoT90] uses Banerjee's Generalized GCD method as a starting point <ref> [Ban88] </ref>.
Reference: [Coh73] <author> W. L. Cohagan, </author> <title> Vector Optimization for the ASC, </title> <booktitle> in Proc. of the Seventh Annual Princeton Conf. on Information Sciences and Systems, </booktitle> <address> Princeton University, Princeton, NJ, </address> <year> 1973, </year> <pages> 169-174. </pages>
Reference: [Cyt90] <author> R. Cytron, </author> <title> private conversation, </title> <year> 1990. </year>
Reference-contexts: In the example above, if loop interchanging were never attempted, the direction vector information might never be computed; this is similar to the approach used in the PTRAN system <ref> [Cyt90] </ref>. Even this has some cost associated with it, however. Each decision algorithm has a certain amount of "overhead" associated with it, and the actual efficiency depends a great deal on the engineering of the implementation.
Reference: [GJG88] <author> D. Gannon, W. Jalby and K. Gallivan, </author> <title> Strategies for Cache and Local Memory Management by Global Program Transformation, </title> <editor> J. </editor> <booktitle> Parallel and Distributed Computing 5, </booktitle> <month> 5 (October </month> <year> 1988), </year> <pages> 587-616, </pages> <publisher> Academic Press. </publisher>
Reference-contexts: in each case we give a representative citation (instead of an exhaustive list); a summary of many of these transformations is 1 available in the monograph [Wol89]. ____________________________________________ transformation enhances reference ____________________________________________ vectorization parallelism [Sch72] parallelization parallelism [ACK87] strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory <ref> [GJG88] </ref> skewing parallelism [Wol86] tiling memory [AKL81] fusion overhead [AKL81] reversal interchanging [Wol89] alignment parallelism [ACK87] splitting parallelism [Ban79] rotation communication [Wol90a] ____________________________________________L L L L L L L L L L L L L L L L L L L L L L L L L L L An entry
Reference: [GoT88] <author> M. B. Gokhale and T. C. Torgerson, </author> <title> The Symbolic Hyperplane Transformation for Recursively Defined Arrays, </title> <booktitle> in Proc. of Supercomputing 88, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <address> Los Angeles, </address> <year> 1988, </year> <pages> 207-214. </pages> <address> Orlando, FL, </address> <month> November 14-18, </month> <year> 1988. </year>
Reference: [KKP90] <author> X. Kong, D. Klappholz and K. Psarris, </author> <title> The I Test: A New Test for Subscript Data Dependence, </title> <booktitle> in Proceedings of the 1990 International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1990. </year>
Reference: [Lam75] <author> L. Lamport, </author> <title> The Hyperplane Method for an Array Computer, </title> <booktitle> in Parallel Processing: Proc. of the Sagamore Computer Conference, </booktitle> <volume> vol. 24, </volume> <editor> T. Feng (ed.), </editor> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1975, </year> <pages> 113-131. 13 </pages>
Reference-contexts: For instance, the wavefront method or hyperplane method was proposed to allow parallel execution of a reindexed loop <ref> [Lam75] </ref> in cases where neither the inner nor outer loop could be executed in parallel. Previous work has shown that the wavefront method can be viewed as a combination of loop skewing and interchanging [Wol86].
Reference: [LeK90] <author> P. Lee and Z. M. Kedem, </author> <title> Mapping Nested Loop Algorithms into Multidimensional Systolic Arrays, </title> <journal> IEEE Trans. on Parallel and Distributed Systems 1, </journal> <month> 1 (January </month> <year> 1990), </year> <pages> 64-76. </pages>
Reference: [LY90] <author> Z. Li, P. C. Yew and C. Q. Zhu, </author> <title> An Efficient Data Dependence Analysis for Parallelizing Compilers, </title> <journal> IEEE Trans. on Parallel and Distributed Systems 1, </journal> <month> 1 (January </month> <year> 1990), </year> <pages> 26-34. </pages>
Reference: [Lov77] <author> D. Loveman, </author> <title> Program Improvement by Source-to-Source Transformation, </title> <editor> J. </editor> <booktitle> of the ACM 20, </booktitle> <month> 1 (January </month> <year> 1977), </year> <pages> 121-145. </pages>
Reference-contexts: present a table of some of these transformations below; in each case we give a representative citation (instead of an exhaustive list); a summary of many of these transformations is 1 available in the monograph [Wol89]. ____________________________________________ transformation enhances reference ____________________________________________ vectorization parallelism [Sch72] parallelization parallelism [ACK87] strip mining vectorization <ref> [Lov77] </ref> distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism [Wol86] tiling memory [AKL81] fusion overhead [AKL81] reversal interchanging [Wol89] alignment parallelism [ACK87] splitting parallelism [Ban79] rotation communication [Wol90a] ____________________________________________L L L L L L L L L L L L L L L L L L L L <p> It was quickly realized that from a compiler point of view, tiling could be viewed as a combination of strip mining (or sectioning) <ref> [Lov77] </ref> and interchanging, once again combining two elementary loop transformations to achieve a powerful result. 3. Direction and Distance Vector Abstractions In the early days of vectorizing compilers, users often manually interchanged loops to improve the vectoriza-tion.
Reference: [PaW86] <author> D. A. Padua and M. Wolfe, </author> <title> Advanced Compiler Optimizations for Supercomputers, </title> <journal> Comm. of the ACM 29, </journal> <month> 12 (December </month> <year> 1986), </year> <pages> 1184-1201. </pages>
Reference-contexts: The automation of a transformation comprises the development of the rules to test when the transformation is legal and the mechanics of implementation. In a compiler, the legality rules are usually tests of the data dependence relations in the program <ref> [PaW86] </ref>, and the mechanics of implementation include generating modified dependence relations [Wol90b]. Most dependence abstractions were originally developed with particular transformations in mind, and have proven to be useful for many common applications.
Reference: [Sch72] <author> P. B. Schneck, </author> <title> Automatic Recognition of Vector and Parallel Operations in a Higher Level Language, </title> <journal> SIGPLAN Notices 7, </journal> <month> 11 (November </month> <year> 1972), </year> <pages> 45-52. </pages>
Reference-contexts: We present a table of some of these transformations below; in each case we give a representative citation (instead of an exhaustive list); a summary of many of these transformations is 1 available in the monograph [Wol89]. ____________________________________________ transformation enhances reference ____________________________________________ vectorization parallelism <ref> [Sch72] </ref> parallelization parallelism [ACK87] strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism [Wol86] tiling memory [AKL81] fusion overhead [AKL81] reversal interchanging [Wol89] alignment parallelism [ACK87] splitting parallelism [Ban79] rotation communication [Wol90a] ____________________________________________L L L L L L L L L L L L L
Reference: [Wal88] <author> D. R. Wallace, </author> <title> Dependence of Multi-Dimensional Array References, </title> <booktitle> in Proc. of the 1988 International Conf. on Supercomputing, ACM, </booktitle> <year> 1988, </year> <pages> 418-428. </pages> <address> St. Malo, France, </address> <month> July 4-8, </month> <year> 1988. </year>
Reference: [Wed75] <author> D. Wedel, </author> <title> Fortran for the Texas Instruments ASC System, </title> <journal> SIGPLAN Notices 10, </journal> <month> 3 (March </month> <year> 1975), </year> <pages> 119-132. </pages>
Reference-contexts: Those listed above with an bullet are implemented in commercial language products (loop reversal, or running a loop backwards, was implemented in the TI ASC NX Fortran compiler, where it was called "loop inversion" <ref> [Wed75] </ref>).
Reference: [Wol86] <author> M. Wolfe, </author> <title> Loop Skewing: The Wavefront Method Revisited, </title> <booktitle> Intl J. Parallel Programming 15, </booktitle> <month> 4 (August </month> <year> 1986), </year> <pages> 279-294. </pages>
Reference-contexts: we give a representative citation (instead of an exhaustive list); a summary of many of these transformations is 1 available in the monograph [Wol89]. ____________________________________________ transformation enhances reference ____________________________________________ vectorization parallelism [Sch72] parallelization parallelism [ACK87] strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism <ref> [Wol86] </ref> tiling memory [AKL81] fusion overhead [AKL81] reversal interchanging [Wol89] alignment parallelism [ACK87] splitting parallelism [Ban79] rotation communication [Wol90a] ____________________________________________L L L L L L L L L L L L L L L L L L L L L L L L L L L An entry of "enhances memory" <p> Previous work has shown that the wavefront method can be viewed as a combination of loop skewing and interchanging <ref> [Wol86] </ref>. Another example is the independent work on loop blocking or tiling which found that proper partitioning of the iteration space (index set) of a nested loop into blocks or tiles would greatly enhance the locality of reference for data access in the inner loop levels [AKL81,OGJG88]. <p> In contrast, using the dependence distance information to test for interchanging would require more storage (one word for each loop) and a (slightly) more complicated test. Loop skewing is designed to be used with interchanging to implement the wavefront method <ref> [Wol86] </ref>. By itself, skewing is always legal; however since the purpose of skewing is to enable interchanging to find more parallelism, it must be done with the dependence relations in mind.
Reference: [WoB87] <author> M. Wolfe and U. Banerjee, </author> <title> Data Dependence and Its Application to Parallel Processing, </title> <booktitle> Intl Journal of Parallel Programming 16, </booktitle> <month> 2 (April </month> <year> 1987), </year> <pages> 137-178. </pages>
Reference-contexts: Compare this to the approach suggested in Wolfe and Banerjee's paper <ref> [WoB87] </ref>, which suggests computing a direction vector using Banerjee's inequalities (or some other test), and then testing the direction vector when loop interchanging is attempted. In comparing the two alternatives, we find several trade-offs.
Reference: [Wol89] <author> M. Wolfe, </author> <title> Optimizing Supercompilers for Supercomputers, </title> <publisher> Pitman Publishing, </publisher> <address> London, </address> <year> 1989. </year>
Reference-contexts: We present a table of some of these transformations below; in each case we give a representative citation (instead of an exhaustive list); a summary of many of these transformations is 1 available in the monograph <ref> [Wol89] </ref>. ____________________________________________ transformation enhances reference ____________________________________________ vectorization parallelism [Sch72] parallelization parallelism [ACK87] strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism [Wol86] tiling memory [AKL81] fusion overhead [AKL81] reversal interchanging [Wol89] alignment parallelism [ACK87] splitting parallelism [Ban79] rotation communication [Wol90a] ____________________________________________L L L L L <p> list); a summary of many of these transformations is 1 available in the monograph <ref> [Wol89] </ref>. ____________________________________________ transformation enhances reference ____________________________________________ vectorization parallelism [Sch72] parallelization parallelism [ACK87] strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism [Wol86] tiling memory [AKL81] fusion overhead [AKL81] reversal interchanging [Wol89] alignment parallelism [ACK87] splitting parallelism [Ban79] rotation communication [Wol90a] ____________________________________________L L L L L L L L L L L L L L L L L L L L L L L L L L L An entry of "enhances memory" means the transformation enhances the performance of memory hierarchies.
Reference: [WoT90] <author> M. Wolfe and C. Tseng, </author> <title> The Power Test for Data Dependence, </title> <journal> J. Supercomputing, </journal> <note> to appear, </note> <year> 1990. </year>
Reference-contexts: Other tests have even stronger overheads; the Power Test 6 <ref> [WoT90] </ref> uses Banerjee's Generalized GCD method as a starting point [Ban88].
Reference: [Wol90a] <author> M. Wolfe, </author> <title> Loop Rotation, in Languages and Compilers for Parallel Computing, </title> <editor> D. Gelernter, A. Nicolau and D. Padua (ed.), </editor> <publisher> Pitman, </publisher> <address> London, </address> <year> 1990, </year> <pages> 531-553. </pages>
Reference-contexts: 1 available in the monograph [Wol89]. ____________________________________________ transformation enhances reference ____________________________________________ vectorization parallelism [Sch72] parallelization parallelism [ACK87] strip mining vectorization [Lov77] distribution vectorization [AlK87] interchanging parallelism [AlK84] interchanging memory [GJG88] skewing parallelism [Wol86] tiling memory [AKL81] fusion overhead [AKL81] reversal interchanging [Wol89] alignment parallelism [ACK87] splitting parallelism [Ban79] rotation communication <ref> [Wol90a] </ref> ____________________________________________L L L L L L L L L L L L L L L L L L L L L L L L L L L An entry of "enhances memory" means the transformation enhances the performance of memory hierarchies.
Reference: [Wol90b] <author> M. Wolfe, </author> <title> Data Dependence and Program Restructuring, </title> <journal> Journal of Supercomputing, </journal> <year> 1990. </year>
Reference-contexts: In a compiler, the legality rules are usually tests of the data dependence relations in the program [PaW86], and the mechanics of implementation include generating modified dependence relations <ref> [Wol90b] </ref>. Most dependence abstractions were originally developed with particular transformations in mind, and have proven to be useful for many common applications.
Reference: [Wol90c] <author> M. Wolfe, </author> <title> A Loop Restructuring Research Tool, </title> <type> CS/E 90-014, </type> <institution> Oregon Graduate Institute, Beaverton OR, </institution> <year> 1990. </year>
Reference-contexts: Crossing Thresholds: Index set splitting is sometimes used to enable other transformations, such as interchanging non-tightly nested loops <ref> [Wol90c] </ref>, and so dependence information is not needed. Sometimes index set splitting is used to break a dependence cycle. In a loop such as: for i = 1 to 100 do endfor there is a dependence cycle, but every dependence relation "crosses" the 51st iteration.
References-found: 28

