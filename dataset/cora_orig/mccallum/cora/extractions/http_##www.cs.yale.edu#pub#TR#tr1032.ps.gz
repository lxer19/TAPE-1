URL: http://www.cs.yale.edu/pub/TR/tr1032.ps.gz
Refering-URL: http://www.cs.yale.edu/pub/TR/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Passive Map Learning and Visual Place Recognition  
Author: Sean Philip Engelson 
Date: May 1994  
Pubnum: YALEU/CSD/RR #1032  
Abstract-found: 0
Intro-found: 1
Reference: [Agre and Chapman, 1987] <author> P.E. Agre and D. Chapman. Pengi: </author> <title> An implementation of a theory of activity. </title> <booktitle> In Proceedings of AAAI-87, </booktitle> <address> Seattle, Wa., </address> <pages> pages 268-272. </pages> <publisher> AAAI, </publisher> <month> July </month> <year> 1987. </year>
Reference-contexts: A more complex example would be an instantiated geometric object model giving enough information for the robot to grasp something. Since such information quickly goes out-of-date if not tracked, designation is a sort of short-term memory of the robot's surroundings. As other researchers have noted (particularly see [Agre, 1988], <ref> [Agre and Chapman, 1987] </ref>, [Firby, 1989], and [Mc-Dermott, 1990]), designation (or indexical-functional representation) allows plans to refer to objects teleologically, by their function in the plan. This eases many aspects of plan construction, placing the burden of resolving reference on perception.
Reference: [Agre and Chapman, 1988] <author> Philip E. Agre and David Chapman. </author> <title> What are plans for? Technical Report A.I. </title> <type> Memo 1050, </type> <institution> MIT AI Lab, </institution> <month> September </month> <year> 1988. </year>
Reference: [Agre, 1988] <author> Philip E. Agre. </author> <title> The Dynamic Structure of Everyday Life. </title> <type> PhD thesis, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <year> 1988. </year>
Reference-contexts: A more complex example would be an instantiated geometric object model giving enough information for the robot to grasp something. Since such information quickly goes out-of-date if not tracked, designation is a sort of short-term memory of the robot's surroundings. As other researchers have noted (particularly see <ref> [Agre, 1988] </ref>, [Agre and Chapman, 1987], [Firby, 1989], and [Mc-Dermott, 1990]), designation (or indexical-functional representation) allows plans to refer to objects teleologically, by their function in the plan. This eases many aspects of plan construction, placing the burden of resolving reference on perception.
Reference: [Al-Badr and Hanks, 1991] <author> Badr Al-Badr and Steve Hanks. </author> <title> Critiquing the Tileworld: Agent architectures, planning benchmarks, and experimental methodology. </title> <journal> AI Magazine, </journal> <note> 1991. submitted. </note>
Reference-contexts: Even more recent abstract domains such as the Tileworld [Pollack and Ringuette, 1990], which attempt to address complex issues such as nondeterminism and extraneous events, have some difficulty with the irrelevance problem <ref> [Al-Badr and Hanks, 1991] </ref>. The solution to the irrelevance problem is an engineering design methodology involving three stages: justification, testing, and validation. 2.1.1 Justification, testing, and validation Every domain abstraction is derived from a theoretical position, whether explicitly or implicitly. <p> Several of these have been identified by Al-Badr and Hanks in their critique of the Tileworld domain <ref> [Al-Badr and Hanks, 1991] </ref>. The analysis below is abstracted, to some extent, from their discussion. They identify the following current research problems in planning: exogenous events, the time cost of planning, richness of world models, sensing and effecting, measuring plan quality, and multiple agents.
Reference: [Alefeld and Hertzberger, 1983] <author> G. Alefeld and J. Hertzberger. </author> <title> Introduction to Interval Computation. </title> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1983. </year>
Reference: [Angluin, 1978] <author> Dana Angluin. </author> <title> On the complexity of minimum inference of regular sets. </title> <journal> Information and Control, </journal> <volume> (39), </volume> <year> 1978. </year>
Reference: [Angluin, 1987] <author> Dana Angluin. </author> <title> Learning regular sets from queries and counterexamples. </title> <journal> Information and Computation, </journal> <volume> 75(2) </volume> <pages> 87-106, </pages> <month> November </month> <year> 1987. </year>
Reference: [Arkin, 1987] <author> Ronald C. Arkin. </author> <title> Towards Cosmopolitan Robots: Intelligent Navigation in Extended Man-Made Environments. </title> <type> PhD thesis, </type> <institution> University of Mas-sachusetts, Department of Computer and Information Sciences, </institution> <year> 1987. </year> <type> COINS Technical Report 87-80. </type>
Reference: [Arkin, 1989] <author> Ronald C. Arkin. </author> <title> Motor schema-based mobile robot navigation. </title> <journal> International Journal of Robotics Research, </journal> <year> 1989. </year>
Reference-contexts: This approach has been used to good effect, for example in Arkin's implementation of motor schemata <ref> [Arkin, 1989] </ref>. The main difficulty with the potential summing method is the occurrence of local minima, points where the potential is minimized (so the robot is motionless) but which do not correspond to the actual goal.
Reference: [Atiya and Hager, 1991] <author> Sami Atiya and Greg Hager. </author> <title> Real-time vision-based robot localization. </title> <booktitle> In Proc. Int'l Conf. on Robotics and Automation, 1991. </booktitle> <volume> 237 238 BIBLIOGRAPHY </volume>
Reference-contexts: In set-based representation, we consider sensor noise to be bounded, and hence to fall within some set of possible configurations U . This is a reasonable assumption in many cases (for example, see <ref> [Atiya and Hager, 1991] </ref>); even unbounded errors can be treated as bounded, if tails are sufficiently thin and robust techniques are used. In particular, our concern is with odometric error which can be modeled using set-based techniques, as discussed above in Section 2.4.3. <p> This can be ameliorated by representing non-axis-aligned intervals (that is, arbitrary rectangles). This, however, introduces overestimation into intersection; this tradeoff must be evaluated for particular applications. In some cases, exact or nearly-exact set representations can be used during preliminary processing before database incorporation, to reduce the effects of overestimation <ref> [Atiya and Hager, 1991] </ref>. 116 CHAPTER 4. NAVIGATIONAL REPRESENTATION In the mapping system developed here, a design decision was made to use regular intervals, as described in Chapter 5.
Reference: [Ballard and Brown, 1982] <author> Dana H. Ballard and Christopher M. Brown. </author> <title> Computer Vision. </title> <publisher> Prentice-Hall, </publisher> <year> 1982. </year>
Reference-contexts: SGD is given in multiples of 45 ffi (the scale that the matcher uses). 3.2. IMAGE SIGNATURES 59 change little with motion, but will be useful for recognition. DEO is calculated by convolving the image with the two first-order 3 fi 3 Prewitt operators (see <ref> [Ballard and Brown, 1982] </ref>) to estimate the image gradient at each pixel. Attention is then restricted to those pixels whose gradient magnitude is both a local maximum in the gradient direction, and which is above a threshold, # DEO grad .
Reference: [Ballard and Ozcandarli, 1988] <author> Dana H. Ballard and Altan Ozcandarli. </author> <title> Eye fixation and early vision: Kinetic depth. </title> <booktitle> In Proc. Int'l Conf. on Computer Vision, </booktitle> <year> 1988. </year>
Reference-contexts: THE RECOGNIZABILITY PROBLEM 69 active vision and sensor planning. Active vision techniques focus on temporal integration of visual information over a controlled trajectory to improve interpretation (see [Ballard, 1989]). Usually, low-level intensity/feature models are used to determine camera motion (for, eg, fixation as in <ref> [Ballard and Ozcandarli, 1988] </ref>). Visual servoing of some sort is often used for controlling camera motion, though arbitrary motion can also be helpful [Nelson and Aloimonos, 1988]. Sensor planning, on the other hand, addresses the problem of finding good viewpoints for object recognition and registration [Tarabanis et al., 1990].
Reference: [Ballard, 1989] <author> Dana H. Ballard. </author> <title> Reference frames for animate vision. </title> <booktitle> In Proc. Int'l Joint Conference on Artificial Intelligence, </booktitle> <year> 1989. </year>
Reference-contexts: Most work in vision that uses camera motion can be divided into two categories: 3.3. THE RECOGNIZABILITY PROBLEM 69 active vision and sensor planning. Active vision techniques focus on temporal integration of visual information over a controlled trajectory to improve interpretation (see <ref> [Ballard, 1989] </ref>). Usually, low-level intensity/feature models are used to determine camera motion (for, eg, fixation as in [Ballard and Ozcandarli, 1988]). Visual servoing of some sort is often used for controlling camera motion, though arbitrary motion can also be helpful [Nelson and Aloimonos, 1988].
Reference: [Barmish and Sankaran, 1979] <author> B. Ross Barmish and Jaishankar Sankaran. </author> <title> The propagation of parametric uncertainty via polytopes. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> AC-24(2), </volume> <year> 1979. </year>
Reference: [Basye et al., 1989] <author> Kenneth Basye, Tom Dean, and Jeffrey S. Vitter. </author> <title> Coping with uncertainty in map learning. </title> <booktitle> In Proc. Int'l Joint Conference on Artificial Intelligence, </booktitle> <year> 1989. </year>
Reference-contexts: Similar active learning techniques have been recently developed for cases with non-deterministic actions or outputs; see, for example, <ref> [Basye et al., 1989] </ref> and [Dean et al., 1992]. These methods use statistical techniques to learn maps to within given probabilistic error bounds. Passive learning of general FSMs, on the other hand, has proven to be intractable. <p> In particular, map-learning may be formalized in this framework as inferring minimal finite-state automata from observations [Rivest and Schapire, 1989]. Perceptual noise and effector error can be modeled by making state observations and transitions probabilistic (as in <ref> [Basye et al., 1989] </ref> and [Dean et al., 1992]). Navigational planning in a purely graph-based framework can be done easily by searching for a path of arcs through the path graph between the starting node and goal, possibly optimizing some measure of performance (shortest path). <p> RELATED WORK the time, maps can often be learned in polynomial time with exploration <ref> [Basye et al., 1989] </ref> (using Rivest and Sloan's [1988] probably almost always useful learning criterion). In particular, they present algorithms for learning maps if either: * The environment is a regular tessellation, or * The robot always knows the action associated with its last transition (reverse movement certainty ).
Reference: [Berger, 1985] <author> James O. Berger. </author> <title> Statistical Decision Theory and Bayesian Analysis. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: fi n image signatures, we have the pattern similarity metric: sim pat (s; t) = n 2 ij where id (v 1 ; v 2 ) = 1 if j v 1 v 2 j # id 0 otherwise This metric corresponds to using a 0-1 loss for measurement estimation <ref> [Berger, 1985] </ref>, and is reasonable if measurement deviations are usually less than # id , but occasionally are completely unpredictable. This will typically be the case if the measurements are based on tokens representing features in the world which may suddenly disappear from view when the viewpoint changes. <p> A second similarity metric is based on the root-mean-square-difference, or cross correlation, of the signature array elements. To wit: sim rms (s; t) = u t n 2 ij This similarity metric corresponds to using a squared-difference loss for measurement estimation <ref> [Berger, 1985] </ref>, or a Gaussian probability density on measurement deviation 2 . More generally, this metric is reasonable whenever the chance of a particular measurement deviation decreases smoothly with deviation's magnitude. In particular, dense measurement functions vary continuously with robot motion, so sim rms will be appropriate.
Reference: [Bertsekas and Rhodes, 1971] <author> Dimitri P. Bertsekas and Ian B. Rhodes. </author> <title> Recursive state estimation for a set-membership description of uncertainty. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> AC-16(2), </volume> <year> 1971. </year>
Reference: [Black, 1992] <author> Michael J. Black. </author> <title> Robust Incremental Optical Flow. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <month> September </month> <year> 1992. </year> <type> Technical Report 923. </type>
Reference-contexts: This kind of approach has been applied to good effect for pixel-level matching, see <ref> [Black, 1992] </ref> for example. We have not yet examined the effects of robustification on signature matching. 64 CHAPTER 3. IMAGE SIGNATURES Offset and cross-scale matching Recall that one of our goals for matching is stability|signatures from nearby views should be `close'.
Reference: [Blum and Chalasani, 1993] <author> Avrim Blum and Prasad Chalasani. </author> <title> An on-line algorithm for improving performance in navigation. </title> <booktitle> In Proc. Symp. Foundations of Computer Science, </booktitle> <year> 1993. </year>
Reference-contexts: Also, there has been some work on similar problems within the paradigm of competitive learning, for example, see <ref> [Blum and Chalasani, 1993] </ref>. Apparently, no one has yet addressed such incremental learning problems with changing tasks or considered expected (rather than worst-case) behavior. Robust set-based estimation Although there exist general, well-understood techniques for robust statistical estimation [Hampel et al., 1986], there are no comparable methods for set-based estimation.
Reference: [Brand et al., 1993] <author> Matthew Brand, Lawrence Birnbaum, and Paul Cooper. </author> <title> Sensible scenes: Visual understanding of complex structures through causal analysis. </title> <booktitle> In Proc. National Conference on Artificial Intelligence, </booktitle> <year> 1993. </year>
Reference-contexts: It shares some of the limitations of the approach as well, which Schank himself noted several years later [Schank, 1982]|chiefly brittleness in the face of true novelty. Recent work in causal vision <ref> [Brand et al., 1993] </ref>, however, maintains aspects of the generic models approach, while attaining flexibility by using true functional explanations for constructing a coherent percept of an object. 5 This is essentially the same idea as that developed by Erdman and Mason [1986] in their study of robust manipulation strategies.
Reference: [Braunegg, 1990] <author> David J. Braunegg. MARVEL: </author> <title> A System for Recognizing World Locations with Stereo Vision. </title> <type> PhD thesis, </type> <institution> MIT, </institution> <year> 1990. </year>
Reference: [Brogan, 1985] <author> William L. Brogan. </author> <title> Modern Control Theory. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> En-glewood Cliffs, New Jersey, </address> <year> 1985. </year>
Reference-contexts: Once a justified abstract domain has been developed, problems may be posed and solutions proposed for them. The testing phase is where proposed solutions are analyzed as to their effectiveness, relative to the domain model. This testing may be analytical, as in stability analysis in control theory <ref> [Brogan, 1985] </ref>, or it may take a more empirical form using simulation. The type of analysis depends on the nature of the model, the problem, and the proposed solution.
Reference: [Brooks, 1985] <author> Rodney A. Brooks. </author> <title> Visual map making for a mobile robot. </title> <booktitle> In Proc. Int'l Conf. on Robotics and Automation, </booktitle> <year> 1985. </year> <note> BIBLIOGRAPHY 239 </note>
Reference: [Brooks, 1986] <author> Rodney A. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-2(1), </volume> <month> March </month> <year> 1986. </year>
Reference-contexts: Thus we can develop a robot model (and mapping system) that abstracts away from most kinematic concerns. 9 These modules by themselves, can be thought of as comprising a subsumption architecture <ref> [Brooks, 1986, and see below] </ref>. We allow, however, for high-level reasoning to tinker with the operation of behavior control, as discussed later on. 2.4. <p> A sensor abstraction is a mapping from a low-level sensor space (eg, sonar readings) to a smaller, high-level sensor space (eg, corridor intersection type). An abstract sensor 12 We assume routine obstacle avoidance is taken care of by the effector control system. See, for example, <ref> [Brooks, 1986] </ref> or [Connell, 1989]. Tracking waypoints with occlusion is eased by the fact that they don't move. 36 CHAPTER 2. ROBOT MODELING AND SIMULATION oriented to. can be treated the same as any other sensor.
Reference: [Byun, 1990] <author> Yung-Tai Byun. </author> <title> Spatial Learning Mobile Robots With A Spatial Semantic Hierarchical Model. </title> <type> PhD thesis, </type> <institution> University of Texas, Austin, </institution> <year> 1990. </year> <note> Artificial Intelligence Lab Technical Report AI90-121. </note>
Reference: [Chapman, 1987] <author> David Chapman. </author> <title> Planning for conjunctive goals. </title> <journal> Artificial Intelligence, </journal> <year> 1987. </year>
Reference: [Chatila and Laumond, 1985] <author> Raja Chatila and J. Laumond. </author> <title> Position referencing and consistent world modeling for mobile robots. </title> <booktitle> In Proc. Int'l Conf. on Robotics and Automation, </booktitle> <pages> pages 138-170, </pages> <address> Washington, D.C., </address> <year> 1985. </year>
Reference-contexts: One useful property of their technique, however, is the ability to easily incorporate into the map general geometric constraints between sets of points by using linear approximations. Hilare The geometrical modeling system of the Hilare project <ref> [Chatila and Laumond, 1985] </ref> represents objects and spaces in the environment by convex polygons. Each polygon's shape is represented in a local frame of reference, in order to deal with the referential locality problem. These object-local frames are, however, related to each other in a global frame of reference.
Reference: [Chernoff, 1979] <author> John Miller Chernoff. </author> <title> African Rhythm and African Sensibility. </title> <publisher> The University of Chicago Press, </publisher> <address> Chicago, IL, </address> <year> 1979. </year>
Reference-contexts: dance; there is no explicit referent of this percept, it is rather associated with the action of replying to the rhythm. "In African music, excellence arises when the combination of rhythms is translated into meaningful action; people participate best when they can `hear' the rhythms, whether through understanding or dance." <ref> [Chernoff, 1979] </ref> 2.4. THE ROBOT MODEL 35 about which glass to use beforehand; I just go into the kitchen, look for a clean glass, and use it. A designator, by definition, instantiates the needed functional aspects, in a form that can be directly used by effector modules.
Reference: [Chrisman, 1992] <author> Lonnie Chrisman. </author> <title> Reinforcement learning with perceptual aliasing: The perceptual distinctions approach. </title> <booktitle> In Proc. National Conference on Artificial Intelligence, </booktitle> <pages> pages 183-188, </pages> <year> 1992. </year>
Reference-contexts: Predictive distinctions Another approach to learning, one with some close connections to this dissertation, is Chrisman's method of predictive distinctions <ref> [Chrisman, 1992] </ref>. His focus was not explicitly on the map learning problem, though; the problem he addressed was that of perceptual aliasing in reinforcement learning. Reinforcement learning is a class of techniques for learning action-selection policies which maximize overall performance (see, eg, [Sutton, 1984]).
Reference: [Cohen et al., 1989] <author> Paul R. Cohen, Michael L. Greenberg, David M. Hart, and Adele E. Howe. </author> <title> Trial by fire: Understanding the design requirements for agents in complex environments. </title> <journal> AI Magazine, </journal> <volume> 10(3), </volume> <year> 1989. </year>
Reference-contexts: of the object system makes it difficult to systematically vary perceptual error, since errors are hidden inside object-specific sensing methods. 2.6.4 The Phoenix environment One of the most elaborate simulation environments used today for AI research is the Phoenix environment (henceforth `Phoenix' 15 ) developed at the University of Mas-sachusetts <ref> [Cohen et al., 1989] </ref>. Phoenix simulates forest fires in Yellowstone park; the focus of the AI research is on developing agents to fight these simulated forest fires. The simulator was designed to support research into real-time adaptive planning, coordination of multiple agents, knowledge representation for plans, and distributed planning.
Reference: [Connell, 1989] <author> Jonathan Connell. </author> <title> A Colony Architecture for an Artificial Creature. </title> <type> PhD thesis, </type> <institution> MIT, </institution> <year> 1989. </year> <type> Technical Report 1151. </type>
Reference-contexts: Units in higher-level behavior modules can then override, or subsume, outputs (hence inputs) of units in lower-level modules. For example, a goal-tracking behavior's desired direction would subsume that of a wandering behavior. While the subsumption architecture has proven to be useful in the development of robotic systems (see, eg, <ref> [Connell, 1989] </ref> or [Mataric, 1990]), designing subsumption control systems is still something of a black art. This is because the subsumption architecture does not explicitly provide arbitration; rather, arbitration must be built into the behaviors themselves. <p> A sensor abstraction is a mapping from a low-level sensor space (eg, sonar readings) to a smaller, high-level sensor space (eg, corridor intersection type). An abstract sensor 12 We assume routine obstacle avoidance is taken care of by the effector control system. See, for example, [Brooks, 1986] or <ref> [Connell, 1989] </ref>. Tracking waypoints with occlusion is eased by the fact that they don't move. 36 CHAPTER 2. ROBOT MODELING AND SIMULATION oriented to. can be treated the same as any other sensor. <p> TRASH COLLECTION 197 trash, trash can icons denote trash cans. 6.5 Trash Collection We also evaluated the use of the mapping system during execution of a realistic robot task. We used a "trash collection" domain similar to other pickup-and-delivery domains that have been investigated, both in situated robotics <ref> [Connell, 1989] </ref> and in planning [McDermott, 1992]. In the trash collection domain, the environment contains objects of two types: trash and trash cans 1 . Trash and trash cans are easily distinguishable from one another. Pieces of trash are of various sizes, and trash cans have limited capacity.
Reference: [Cormen et al., 1992] <author> Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: Constraints 112 CHAPTER 4. NAVIGATIONAL REPRESENTATION of the sort that cause trouble for Yemini and Davis would only result in very high uncertainty in our framework. Another point to note is that we cannot use the standard O (n 3 ) Floyd-Warshall all-points shortest path algorithm <ref> [Cormen et al., 1992] </ref>, since distributivity does not hold when we consider intervals of 2-dimensional positions plus rotations (see Appendix A).
Reference: [Crowley, 1984] <author> James Crowley. </author> <title> Dynamic world modeling for an intelligent mobile robot. </title> <booktitle> In Proceedings of ICPR 7, </booktitle> <pages> pages 207-210, </pages> <year> 1984. </year>
Reference-contexts: This can be done by choosing to look at geometric landmark features as in [Leonard et al., 1992], or by dividing the environment into a set of disjoint convex spaces as in <ref> [Crowley, 1984] </ref>. It turns out, however, that for highly-structured environments (such as the modern office building), environmental structure provides natural ways of performing this discretization.
Reference: [Crowley, 1985] <author> James L. Crowley. </author> <title> Navigation for an intelligent mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-1(1), </volume> <year> 1985. </year>
Reference: [Davis, 1984] <author> Ernest Davis. </author> <title> Representing and Acquiring Geographic Knowledge. </title> <type> PhD thesis, </type> <institution> Yale University Department of Computer Science, </institution> <year> 1984. </year>
Reference-contexts: Thus, place representations must include a description of the place sufficient to support reliable recognition. Some of this burden can be laid on representations encoding the relative positions of places in the map (see, for example, <ref> [Davis, 1984] </ref> and [Smith et al., 1986]). Chapter 4 describes the diktiometric map representation scheme, which integrates both topological and high-level geometric knowledge in a uniform framework. In any case, due to odometric uncertainty, perceptual cues must be used as well. 3.2. <p> Due to the complexity of exact estimation of spatial relationships in this framework, SPAM uses two approximate techniques: a Monte Carlo method and conjugate-gradient hillclimbing. Our formulation in Section 4.4.4 avoids these difficulties by using path consistency as a weaker criterion for estimation correctness. MERCATOR MERCATOR <ref> [Davis, 1984] </ref> is a mapping system which represents objects as polygons. Spatial uncertainty is represented in two ways: grain-size and fuzz. Grain-size is used to parameterize uncertainty in the shape of objects approximated by polygons. Fuzz, as above, connotes intervals on spatial relationships.
Reference: [Dean et al., 1992] <author> Tom Dean, Dana Angluin, Kenneth Basye, Sean Engelson, Leslie Kaelbling, Evangelos Kokkevis, and Oded Maron. </author> <title> Inferring finite automata with stochastic output functions and an application to map learning. </title> <booktitle> In Proc. National Conference on Artificial Intelligence, </booktitle> <pages> pages 208-214, </pages> <year> 1992. </year> <note> 240 BIBLIOGRAPHY </note>
Reference-contexts: Similar active learning techniques have been recently developed for cases with non-deterministic actions or outputs; see, for example, [Basye et al., 1989] and <ref> [Dean et al., 1992] </ref>. These methods use statistical techniques to learn maps to within given probabilistic error bounds. Passive learning of general FSMs, on the other hand, has proven to be intractable. <p> In particular, map-learning may be formalized in this framework as inferring minimal finite-state automata from observations [Rivest and Schapire, 1989]. Perceptual noise and effector error can be modeled by making state observations and transitions probabilistic (as in [Basye et al., 1989] and <ref> [Dean et al., 1992] </ref>). Navigational planning in a purely graph-based framework can be done easily by searching for a path of arcs through the path graph between the starting node and goal, possibly optimizing some measure of performance (shortest path).
Reference: [Dudek et al., 1988] <author> Gregory Dudek, Michael Jenkins, Evangelos Milios, and David Wilkes. </author> <title> Robotic exploration as graph construction. </title> <type> Technical Report RBCV-TR-88-23, </type> <institution> University of Toronto, </institution> <year> 1988. </year>
Reference: [Elfes, 1987] <author> Alberto Elfes. </author> <title> Sonar-based real-world mapping and navigation. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-3(3):249-265, </volume> <year> 1987. </year>
Reference-contexts: They must both be represented, since visitation of two waypoints does not mean that the robot has ever moved between them. We represent this information approximately, using a variation of certainty grids <ref> [Elfes, 1987] </ref>. Space is tessellated by a confidence grid 9 , with each cell (x; y) associated with a visitation confidence v (x; y) and a traversal confidence t (x; y). <p> Odometric noise is accounted for by convolving the certainty grid with a Gaussian mask, to account for loss of precise registration. To compensate for this monotonic loss of information as the robot moves, a registration procedure is introduced in <ref> [Elfes, 1987] </ref>, however I am unaware of any analysis of the correlation that this process introduces into the certainty grid. In any case, old observations tend to get smoothed out beyond usefulness after a short while, so certainty grids are most useful for local maps.
Reference: [Engelson and Bertani, 1992] <author> Sean P. Engelson and Niklas Bertani. Ars Magna: </author> <title> The abstract robot simulator manual. </title> <type> Technical Report YALEU/DCS/TR-928, </type> <institution> Yale University Department of Computer Science, </institution> <year> 1992. </year>
Reference-contexts: All sensors and effectors have associated noise and error modes, all of which can be adjusted by the experimenter. One of our most important system design goals was that the agent-world interface be clean and conceptually simple. The interface is documented in detail in <ref> [Engelson and Bertani, 1992] </ref>. All sensor/effector operations are specified similarly, using a small set of predefined data types when complex information is 2.6. RELATED WORK 49 communicated.
Reference: [Engelson and McDermott, 1991] <author> Sean P. Engelson and Drew V. McDermott. </author> <title> Image signatures for place recognition and map construction. </title> <booktitle> In Proceedings of SPIE Symposium on Intelligent Robotic Systems, Sensor Fusion IV, </booktitle> <year> 1991. </year>
Reference: [Engelson, 1990] <author> Sean P. Engelson. </author> <title> Perceptual integration of piloting and navigation. </title> <booktitle> In Proceedings of IEEE Int'l Symp. on Intelligent Control, </booktitle> <year> 1990. </year>
Reference-contexts: This approach often allows the system to avoid the absurd results produced by potential field approaches, by having behaviors supply the arbitrator with more acceptable solutions, allowing a more satisfactory compromise. Another optimization approach is examined in <ref> [Engelson, 1990] </ref>, which explicitly incorporates directional information into the objective function. This allows deliberative processing a hand in arbitration, for example specifying that the robot should go left around an obstacle 10 . An enhancement to simple optimization is proposed by Yamauchi and Nelson [1991].
Reference: [Engelson, 1992] <author> Sean P. Engelson. </author> <title> Active place recognition using image signatures. </title> <booktitle> In Proceedings of SPIE Symposium on Intelligent Robotic Systems, Sensor Fusion V, </booktitle> <year> 1992. </year>
Reference: [Erdman and Mason, 1986] <author> Michael A. Erdman and Matthew T. Mason. </author> <title> An exploration of sensorless manipulation. </title> <booktitle> In Proc. Int'l Conf. on Robotics and Automation, </booktitle> <year> 1986. </year>
Reference: [Fikes and Nilsson, 1971] <author> R. E. Fikes and N. J. Nilsson. </author> <title> Strips: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 189-208, </pages> <year> 1971. </year>
Reference-contexts: Once the problem is stated in a simple and abstract fashion, the issues involved in its solution may become clearer. For example, much important work in planning was fueled by STRIPS and STRIPS-derived representations <ref> [Fikes and Nilsson, 1971] </ref>, culminating in simple and complete non-linear planning algorithms such as those of Chapman [1987] and McAllester and Rosenblitt [1991]. In the course of this devel opment, the shortcomings of such representation strategies for robotics also became apparent. <p> The `irrelevance problem' must be addressed, however; we must have some assurance that solutions to problems in our model will translate more-or-less directly to their real-world analogues. Until quite recently in AI, this question was hardly addressed. Take the example of the blocks world, as formalized in STRIPS <ref> [Fikes and Nilsson, 1971] </ref>. This provided what seemed like a reasonable formalization of the planning problem, for which good solutions were developed. However, when the planners were used to direct a real robot in a real environment, the experiment was a qualified success at best.
Reference: [Firby and Hanks, 1987] <author> R. James Firby and Steve Hanks. </author> <title> The simulator manual. </title> <type> Technical Report YALEU/DCS/TR-563, </type> <institution> Yale University Department of Computer Science, </institution> <year> 1987. </year>
Reference: [Firby, 1989] <author> R. James Firby. </author> <title> Adaptive Execution in Complex Dynamic Worlds. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <month> January </month> <year> 1989. </year> <type> Technical Report 672. </type>
Reference-contexts: We can remain agnostic as to the nature of the deliberator. All that is required for map learning is that it somehow generate actions for the robot to perform. It could take the form of a classical planning system [McAllester and Rosenblitt, 1991], a reactive plan <ref> [Firby, 1989] </ref>, or even a connectionist control scheme [Maes, 1989]. An action may be the activation of a perception routine or effector, or the formation of links between a sensor and an effector (a perceptual marker, as in "Follow that car!"). 1.1. <p> More important than the physical robot model is our model of low-level robot control, which is what allows us to abstract from the details of the physical world. We base our analysis on the emerging paradigm of hybrid control systems; see <ref> [Firby, 1989] </ref> and [Gat, 1991]. In this view, low-level control is handled by a set of primitives which produce behaviors such as wall-following or grasping 9 . Given a set of such primitives, a deliberator can reason using abstract models of the behavior of the robot. <p> Since such information quickly goes out-of-date if not tracked, designation is a sort of short-term memory of the robot's surroundings. As other researchers have noted (particularly see [Agre, 1988], [Agre and Chapman, 1987], <ref> [Firby, 1989] </ref>, and [Mc-Dermott, 1990]), designation (or indexical-functional representation) allows plans to refer to objects teleologically, by their function in the plan. This eases many aspects of plan construction, placing the burden of resolving reference on perception.
Reference: [Fryer, 1966] <author> H. C. Fryer. </author> <title> Concepts and Methods of Experimental Statistics. </title> <publisher> Allyn and Bacon, Inc., </publisher> <address> Boston, </address> <year> 1966. </year>
Reference-contexts: Since there is no good statistical model for the data, we used the Mann-Whitney median U non-parametric test (described in <ref> [Fryer, 1966] </ref>). It uses rank sums to test the hypothesis that two samples of different sizes come from distributions with the same median. The procedure provides a z score that can be checked for significance against tables of the normal distribution.
Reference: [Gallistel, 1990] <author> Charles R. Gallistel. </author> <title> The Organization of Learning. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year> <note> BIBLIOGRAPHY 241 </note>
Reference: [Gat, 1991] <author> Erann Gat. </author> <title> Reliable Goal-Directed Reactive Control of Autonomous Mobile Robots. </title> <type> PhD thesis, </type> <institution> Virginia Polytechnic Institute and State University, </institution> <year> 1991. </year>
Reference-contexts: More important than the physical robot model is our model of low-level robot control, which is what allows us to abstract from the details of the physical world. We base our analysis on the emerging paradigm of hybrid control systems; see [Firby, 1989] and <ref> [Gat, 1991] </ref>. In this view, low-level control is handled by a set of primitives which produce behaviors such as wall-following or grasping 9 . Given a set of such primitives, a deliberator can reason using abstract models of the behavior of the robot. <p> RAP methods invoke either other RAPs or primitive actions, which may be carried out in parallel. The RAP system is built around a complex interpreter which determines what RAPs should run when, depending of annotated preconditions, constraints, and priorities. The sequencing layer of Gat's ATLANTIS architecture <ref> [Gat, 1991] </ref> uses the RAP paradigm, extending the notion of primitive actions to apply to a behavior-based substrate. Each behavioral module has three primitive actions associated with it: initiation, termination, and monitoring. The former are clear; monitoring examines signals coming from the behavior to check on its state.
Reference: [Gat, 1993] <author> Erann Gat. </author> <title> On the role of stored internal state in the control of autonomous mobile robots. </title> <journal> AI Magazine, </journal> <volume> 14(1), </volume> <year> 1993. </year>
Reference: [Gelb, 1974] <author> Arthur Gelb, </author> <title> editor. Applied Optimal Estimation. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1974. </year>
Reference-contexts: Thus from an observation we can compute a set to which the true parameters must belong (according to the set-based model). 2.4. THE ROBOT MODEL 43 Noise is commonly assumed to be Gaussian, because this assumption leads to simple estimation procedures such as the Kalman filter <ref> [Gelb, 1974] </ref>. For many problems, this assumption is close enough to reality to produce reasonable results. Simple distributional assumptions like this are not valid for odometry, however, because of the causal complexity of odometric noise. <p> How this is done depends on the nature of the model used. For example, for classical linear systems with Gaussian noise models, an incremental least-squares fit `explains' observations <ref> [Gelb, 1974] </ref>. Robust estimators may allow `bad' observations to be thrown out or weighted less, implicitly explaining them as outliers [Hampel et al., 1986]. More generally, explanation of observation may also include hypothesized changes to the estimator's model. <p> There is a considerable literature on statistical methods for estimation and control which we will not review here, as it is peripheral to the topics of this chapter. The interested reader is referred to <ref> [Gelb, 1974] </ref>. 222 CHAPTER 8. RELATED WORK 8.2.1 Sets for estimation and control The use of bounded uncertainty representations like that we use has a long, though sparse, history in the estimation and control literature. Schweppe [1968] describes a set-based estimation method for continuous linear systems using bounding ellipses.
Reference: [Gold, 1978] <author> E. Mark Gold. </author> <title> Complexity of automaton identification from given sets. </title> <journal> Information and Control, </journal> <volume> (37), </volume> <year> 1978. </year>
Reference: [Hager et al., 1993] <author> Gregory Hager, Sean Engelson, and Sami Atiya. </author> <title> On comparing statistical and set-based methods in sensor data fusion. </title> <booktitle> In Proc. Int'l Conf. on Robotics and Automation, </booktitle> <address> Atlanta, GA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: He also relates this problem to that of minimax control [Witsenhausen, 1968a]. Barmish and Sankaran [1979] analyze the use of polytopic representations of sets for modeling uncertainty in discrete linear systems; this idea was also suggested by Witsenhausen [1968b]. In <ref> [Hager et al., 1993] </ref>, we compared set-based estimation methods with comparable statistical methods, with particular attention to robotic applications. We concluded that the two methods are generally appropriate for two different domains. <p> The maximal consistent correspondences can then be used to determine the robot's absolute location (within some interval). It turns out that for this problem, the set-based method performs significantly better than the equivalent statistical formulation <ref> [Hager et al., 1993] </ref>. 8.2.3 Statistical techniques Stochastic maps A general statistical method for metric representation is described by Smith, Self, and Cheeseman [1986]. <p> An Extended Kalman Filter (EKF) is used to incorporate new observations into the stochastic map. This amounts to a tacit assumption of Gaussian noise, which is a dubious assumption for odometric errors (and for visual errors; see <ref> [Hager et al., 1993] </ref>). In addition, the linearization required by the Extended Kalman Filter has problems with large angular uncertainty (they require noise be less than 5 degrees).
Reference: [Hager et al., 1994] <author> Gregory D. Hager, Wen-Chung Chang, and Steven Morse. </author> <title> Robot feedback control based on stereo vision: Towards calibration-free hand-eye coordination. </title> <booktitle> In Proc. Int'l Conf. on Robotics and Automation, </booktitle> <year> 1994. </year> <note> (submitted). </note>
Reference-contexts: The waypoint type's tracker enables the robot to track the designator once found. Complex model-based tracking is probably not often necessary, since feedback control using image-based feature tracking has proven to be quite effective <ref> [Hager et al., 1994] </ref>. If the robot then decides to go to the designated (and tracked) location, a simple servo routine will usually suffice 12 (see below). A recognizer detects when the robot is at a location of type T .
Reference: [Hager, 1990] <author> Gregory D. Hager. </author> <title> Task-Directed Sensor Fusion and Planning. </title> <publisher> Kluwer, </publisher> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: A high-level model is used to determine the best viewpoint subject to kinematic constraints, given some previous estimate (s) of the target's pose. The problem can also be formulated as a decision-theoretic problem of choosing the viewpoint with highest expected utility <ref> [Hager, 1990] </ref>. This can be iterated to obtain successively better estimates (of target identity or pose). The problem of finding recognizable viewpoints is similar to the classical sensor planning problem, in that we seek to optimize some measure of viewpoint `goodness'.
Reference: [Hampel et al., 1986] <author> F. R. Hampel, E. M. Ronchetti, P. J. Rousseeuw, and W. A. Stahel. </author> <title> Robust Statistics: The Approach Based on Influence Functions. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, NY, </address> <year> 1986. </year>
Reference-contexts: In particular, dense measurement functions vary continuously with robot motion, so sim rms will be appropriate. A match is permitted (as above) if sim rms (s; t) # M rms . 2 It is possible that matching could improved by reducing the influence of outliers, using robust estimation techniques <ref> [Hampel et al., 1986] </ref>. This kind of approach has been applied to good effect for pixel-level matching, see [Black, 1992] for example. We have not yet examined the effects of robustification on signature matching. 64 CHAPTER 3. <p> How this is done depends on the nature of the model used. For example, for classical linear systems with Gaussian noise models, an incremental least-squares fit `explains' observations [Gelb, 1974]. Robust estimators may allow `bad' observations to be thrown out or weighted less, implicitly explaining them as outliers <ref> [Hampel et al., 1986] </ref>. More generally, explanation of observation may also include hypothesized changes to the estimator's model. The best explanation for an observation, given a model, may be that the model itself needs changing. <p> Apparently, no one has yet addressed such incremental learning problems with changing tasks or considered expected (rather than worst-case) behavior. Robust set-based estimation Although there exist general, well-understood techniques for robust statistical estimation <ref> [Hampel et al., 1986] </ref>, there are no comparable methods for set-based estimation. Since set-based estimation has proven useful for robotics applications [Atiya and Hager, 1991,Hager et al., 1993], developing general robust set-based estimation techniques is of great importance to robotics.
Reference: [Haralick et al., 1973] <author> Robert M. Haralick, K. Shanmugam, and Its'hak Dinstein. </author> <title> Textural features for image classification. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 3(6), </volume> <year> 1973. </year>
Reference-contexts: Relative intensity is clearly a dense measurement. 1 This measurement function intentionally uses a simplistic notion of texturing, in order to demonstrate the power of the overall approach. More sophisticated texture measures could be used, perhaps based on the spatial-dependence matrices of <ref> [Haralick et al., 1973] </ref>. 3.2. IMAGE SIGNATURES 61 Other measurements In addition to the measurement functions described above, some others were tested and found wanting. They are briefly described here, along with why we think they failed.
Reference: [Hong et al., 1991] <author> Jiawei Hong, Xiaonan Tan, Brian Pinette, Richard Weiss, and Edward M. Riseman. </author> <title> Image-based homing. </title> <booktitle> In Proc. Int'l Conf. on Robotics and Automation, </booktitle> <year> 1991. </year>
Reference-contexts: Another similar approach is taken by Zetsche and Caelli [1989] for the problem of invariant pattern recognition. They use oriented gaussian filters to derive a 4D translation-, scale-, and rotation-invariant representation of 2D input patterns, using cross-correlation for matching. A different image-based technique is described in <ref> [Hong et al., 1991] </ref>. The authors use a spherical mirror to obtain a 360 ffi image of the robot's surroundings. They then segment the image's horizon circle, finding a discrete set of `landmarks'. Landmarks 3.5. RELATED WORK 95 are described by a window of image intensities, locally normalized for illumination.
Reference: [Horswill, 1993] <author> Ian Horswill. </author> <title> Specialization of Perceptual Processes. </title> <type> PhD thesis, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <year> 1993. </year>
Reference: [Khatib, 1985] <author> O. Khatib. </author> <title> Real-time obstacle avoidance for manipulators and mobile robots. </title> <booktitle> In Proc. Int'l Conf. on Robotics and Automation, </booktitle> <pages> pages 500-505, </pages> <year> 1985. </year> <note> 242 BIBLIOGRAPHY </note>
Reference: [Kirman et al., 1991] <author> Jak Kirman, Kenneth Basye, and Thomas Dean. </author> <title> Sensor abstraction for control of navigation. </title> <booktitle> In Proc. Int'l Conf. on Robotics and Automation, </booktitle> <address> Sacramento, CA, </address> <year> 1991. </year>
Reference: [Koditschek, 1989] <author> Daniel E. Koditschek. </author> <title> Autonomous mobile robots controlled by navigation functions. </title> <booktitle> In The Second IEEE International Workshop on Intelligent Robots and Systems, </booktitle> <month> September </month> <year> 1989. </year>
Reference: [Koenderink and van Doorn, 1989] <author> Jan J. Koenderink and Andrea J. van Doorn. </author> <title> Photometric invariants related to solid shape. </title> <editor> In Berthold K. P. Horn and Michael J. Brooks, editors, </editor> <booktitle> Shape From Shading, </booktitle> <pages> pages 301-322. </pages> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: There is also a great deal of previous work in vision that can be applied to measurement function development. For example, texture analysis (as done by Witkin [1981]), color histograms [Swain, 1990], or shading (as in <ref> [Koenderink and van Doorn, 1989] </ref> or [Pentland, 1989]) might provide good physically-based measurement functions. Evaluating measurement functions What makes some measurement functions useful and others not? We would like a succinct characterization of measurement `goodness' which could be used when designing measurement functions for a given environment.
Reference: [Kortenkamp et al., 1992] <author> David Kortenkamp, L. Douglas Baker, and Terry Wey-mouth. </author> <title> Using gateways to build a route map. </title> <booktitle> In Proc. IEEE/RSJ Int'l Workshop on Intelligent Robots and Systems, </booktitle> <year> 1992. </year>
Reference: [Kriegman, 1989] <author> David J. Kriegman. </author> <title> Object Classes and Image Contours in Model-Based Vision. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1989. </year>
Reference-contexts: It turns out, however, that for highly-structured environments (such as the modern office building), environmental structure provides natural ways of performing this discretization. Kriegman's generic models for visual perception <ref> [Kriegman, 1989] </ref> use the idea that much of the structure of the environment can be described in essentially stereotypical terms. For example, we may have a generic model of a stereotypical hallway, which can then be instantiated to create a percept of a particular hallway.
Reference: [Kuc and Viard, 1991] <author> Roman Kuc and Victor Brian Viard. </author> <title> A physically based navigation strategy for sonar-guided vehicles. </title> <journal> The International Journal of Robotics Research, </journal> <volume> 10(2), </volume> <year> 1991. </year>
Reference-contexts: First was their use of regions of constant depth (RCDs) for extracting reliable features from sonar. Building on the realistic sonar models developed in <ref> [Kuc and Viard, 1991] </ref>, they note that when nearby range estimates are similar, the estimates tend to be highly accurate. They further note that if two range readings from slightly different positions are used, the robot can distinguish between RCDs due to planar surfaces and those due to corners.
Reference: [Kuipers and Byun, 1988] <author> Benjamin Kuipers and Yung-Tai Byun. </author> <title> A robust qualitative method for robot spatial reasoning. </title> <booktitle> In Proc. National Conference on Artificial Intelligence, </booktitle> <pages> pages 774-779, </pages> <year> 1988. </year>
Reference-contexts: The model contains the constraints imposed by the generic structure of the `stereotypical hallway' 4 . In addition to the idea of using stereotypical building blocks for describing the world, we also note the use of local homing procedures in mapping <ref> [Kuipers and Byun, 1988] </ref>. Suppose we could provide our robot with the ability to reliably get to a particular position from somewhere in its vicinity. Then, once the procedure has been executed, the robot can localize itself quite precisely, regardless of its original positional uncertainty 5 . <p> This is reasonable since, if necessary, repeated sensing can be used to drive outlier probabilities down. In any case, this is an improvement over previous models used in mapping, where absolute orientation was assumed known (as in <ref> [Kuipers and Byun, 1988] </ref> and [Mataric, 1990]). Object perception As with waypoint types, non-local object perception includes finding and tracking, which are largely top-down. In addition, though, there is a third function, description, which gives more information about perceived objects than is supplied. <p> As long as we are `close enough', the effector modules will do the rest. In particular, waypoint approachers allow the robot to localize itself precisely by moving the robot repeatably to the same position (this also forms the basis for <ref> [Kuipers and Byun, 1988] </ref>). However, since absolute stability is rarely achievable in 104 CHAPTER 4. <p> The lower picture shows waypoint position estimates. Note that a straight line between waypoint nodes implies some known path between them, not necessarily straight. 6.4. LESION STUDY 195 (a) (b) similar to the learning component (excluding exploration and experimentation) of incremental active map-learners, such as <ref> [Kuipers and Byun, 1988] </ref>. The result of the normal run is shown in Figure 6.7 (b); there are no surprises|the map converges relatively quickly to an accurate map, despite some ambiguities. However, the naive system did not run quite so well, as is obvious in Figure 6.7 (c). <p> The error correction techniques can easily be combined with other (active) topological mapping techniques (such as those of <ref> [Kuipers and Byun, 1988] </ref> or [Mataric, 1990]) for increasing robustness.
Reference: [Kuipers, 1978] <author> Benjamin Kuipers. </author> <title> Modeling spatial knowledge. </title> <journal> Cognitive Science, </journal> <volume> 2 </volume> <pages> 129-153, </pages> <year> 1978. </year>
Reference-contexts: Within these constraints, a number of different representations have been developed, incorporating a variety of topological and geometric techniques for dealing with place recognition and navigation. TOUR Probably the earliest comprehensive path-based map representation scheme was that in Kuipers' TOUR model <ref> [Kuipers, 1978] </ref>. TOUR was developed primarily as a model of human cognitive mapping. It uses a relatively simple world model, based on human sensorimotor capabilities in path-structured environments (such as buildings or city streets).
Reference: [Leonard et al., 1992] <author> John J. Leonard, Hugh F. Durrant-Whyte, and Ingemar J. Cox. </author> <title> Dynamic map building for an autonomous mobile robot. </title> <journal> International Journal of Robotics Research, </journal> <volume> 11(4) </volume> <pages> 286-298, </pages> <year> 1992. </year>
Reference-contexts: In order to construct useful maps, it is generally necessary to discretize the world in some way, cutting it up into well-defined pieces that can be individually described and organized together into an overall map. This can be done by choosing to look at geometric landmark features as in <ref> [Leonard et al., 1992] </ref>, or by dividing the environment into a set of disjoint convex spaces as in [Crowley, 1984]. It turns out, however, that for highly-structured environments (such as the modern office building), environmental structure provides natural ways of performing this discretization. <p> Atiya and Hager [1991] developed a system for precise robot localization using stereo measurements of vertical edge segments. They solve correspondence by matching 3D geometric invariants. In a similar vein, Leonard and Durrant-Whyte developed a sonar-based mapping system <ref> [Leonard et al., 1992] </ref>, which effectively performs localization using sparsely distributed geometric features in a Kalman filtering framework. 96 CHAPTER 3. IMAGE SIGNATURES 3.6 Discussion Image-based place recognition has several benefits over reconstructionist approaches.
Reference: [Levitt et al., 1987] <author> T. S. Levitt, D. T. Lawton, D. M. Chelberg, and P. C. Nelson. </author> <title> Qualitative landmark-based path planning and following. </title> <booktitle> In Proc. National Conference on Artificial Intelligence, </booktitle> <address> Seattle, Washington, </address> <year> 1987. </year>
Reference: [Lumelsky and Stepanov, 1987] <author> V. J. Lumelsky and A. A. Stepanov. </author> <title> Path-planning strategies for a point mobile automaton moving amidst unknown obstacles of arbitrary shape. </title> <journal> Algorithmica, </journal> (2):403-430, 1987. BIBLIOGRAPHY <volume> 243 </volume>
Reference: [Lynch, 1960] <author> Kevin Lynch. </author> <title> The Image of the City. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1960. </year>
Reference: [Maes, 1989] <editor> Pattie Maes. </editor> <title> How to do the right thing. </title> <journal> Connection Science, </journal> <volume> 1, </volume> <year> 1989. </year>
Reference-contexts: All that is required for map learning is that it somehow generate actions for the robot to perform. It could take the form of a classical planning system [McAllester and Rosenblitt, 1991], a reactive plan [Firby, 1989], or even a connectionist control scheme <ref> [Maes, 1989] </ref>. An action may be the activation of a perception routine or effector, or the formation of links between a sensor and an effector (a perceptual marker, as in "Follow that car!"). 1.1. MAP LEARNING IN CONTEXT 9 arrows denote control flow, while dashed arrows denote flow of information.
Reference: [Malkin and Addanki, 1992] <author> Malkin and Addanki. Lognets. </author> <booktitle> In Proc. National Conference on Artificial Intelligence, </booktitle> <year> 1992. </year>
Reference: [Mataric, 1990] <editor> Maja J. Mataric. </editor> <title> A distributed model for mobile robot environment-learning and navigation. </title> <type> Technical Report 1228, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <year> 1990. </year>
Reference-contexts: For example, a goal-tracking behavior's desired direction would subsume that of a wandering behavior. While the subsumption architecture has proven to be useful in the development of robotic systems (see, eg, [Connell, 1989] or <ref> [Mataric, 1990] </ref>), designing subsumption control systems is still something of a black art. This is because the subsumption architecture does not explicitly provide arbitration; rather, arbitration must be built into the behaviors themselves. <p> This is reasonable since, if necessary, repeated sensing can be used to drive outlier probabilities down. In any case, this is an improvement over previous models used in mapping, where absolute orientation was assumed known (as in [Kuipers and Byun, 1988] and <ref> [Mataric, 1990] </ref>). Object perception As with waypoint types, non-local object perception includes finding and tracking, which are largely top-down. In addition, though, there is a third function, description, which gives more information about perceived objects than is supplied. <p> The error correction techniques can easily be combined with other (active) topological mapping techniques (such as those of [Kuipers and Byun, 1988] or <ref> [Mataric, 1990] </ref>) for increasing robustness. Similarly, the behavior abstraction method is likely to be useful for learning in a variety of robotic applications requiring flexible planned behavior. 9.2 Future Work Robotic validation The majority of the work described in this dissertation was developed and tested in simulation.
Reference: [McAllester and Rosenblitt, 1991] <author> D. McAllester and D. Rosenblitt. </author> <title> Systematic nonlinear planning. </title> <booktitle> In Proc. National Conference on Artificial Intelligence, </booktitle> <pages> pages 634-639, </pages> <year> 1991. </year>
Reference-contexts: We can remain agnostic as to the nature of the deliberator. All that is required for map learning is that it somehow generate actions for the robot to perform. It could take the form of a classical planning system <ref> [McAllester and Rosenblitt, 1991] </ref>, a reactive plan [Firby, 1989], or even a connectionist control scheme [Maes, 1989]. An action may be the activation of a perception routine or effector, or the formation of links between a sensor and an effector (a perceptual marker, as in "Follow that car!"). 1.1.
Reference: [McDermott and Davis, 1984] <author> Drew V. McDermott and Ernest Davis. </author> <title> Planning routes through uncertain territory. </title> <journal> Artificial Intelligence, </journal> <volume> 22 </volume> <pages> 107-156, </pages> <year> 1984. </year>
Reference-contexts: We develop such algorithms further below for set-based representations. Referential locality The problem of referential locality is an important one when representing geometrical information with uncertainty (see, e.g, <ref> [McDermott and Davis, 1984] </ref>). Consider two possible methods for representing the geometric information contained in the observations fz k ij g. The first is to choose some distinguished point as p 0 , and then represent estimates of positions of all other points with respect to that global reference frame.
Reference: [McDermott, 1978] <author> Drew V. McDermott. </author> <title> Planning and acting. </title> <journal> Cognitive Science, </journal> (2):71-109, 1978. 
Reference: [McDermott, 1981a] <author> Drew McDermott. </author> <booktitle> Artificial intelligence meets natural stupidity. In Mind Design, </booktitle> <pages> pages 143-160. </pages> <publisher> The MIT Press, </publisher> <year> 1981. </year>
Reference-contexts: No further meaning is intended, and the use of the word `doorway' is intended only as a mnemonic. As such, we must beware of the fallacy of `wishful terminology' <ref> [McDermott, 1981a] </ref> and remember that the true waypoint type denoted by an approacher/recognizer pair depends on a complex interaction between the procedures and the robot's environment.
Reference: [McDermott, 1981b] <author> Drew McDermott. </author> <title> Finding objects with given spatial properties. </title> <type> Technical Report 195, </type> <institution> Yale University Department of Computer Science, </institution> <year> 1981. </year>
Reference-contexts: Direct search can be efficiently performed on a k-d tree for points falling within intervals of IR k . A more flexible search strategy for our purposes, though, is a variety of spiral search <ref> [McDermott, 1981b] </ref>. Spiral search uses a heuristic strategy to find points in the tree progressively further and further from a given starting point. Note that k-d tree search can be efficiently implemented on massively parallel machines using marker-passing.
Reference: [McDermott, 1988] <author> Drew McDermott. </author> <title> Revised NISP manual. </title> <type> Technical Report 642, </type> <institution> Yale University Department of Computer Science, </institution> <year> 1988. </year>
Reference-contexts: The model is embodied in a simulator called Ars Magna 3 . The simulator was developed with attention to the problem of relevance discussed above. It is implemented in Nisp <ref> [McDermott, 1988] </ref>, a macro package on top of Common Lisp, and consists of about 15,000 lines of code. The primary purpose of the Ars Magna simulator was to support research in map-learning and navigation during task execution. <p> If a policy fails, the entire with-policy plan fails, since the constraint has been irreparably violated. If a policy succeeds, then the constraint is deemed moot, and goes away. 122 CHAPTER 4. NAVIGATIONAL REPRESENTATION Nisp notation RPL is written in Nisp <ref> [McDermott, 1988] </ref>, a portable Lisp macro package with compile-time typing. Nisp code looks mostly like Common Lisp code, with some exceptions. As far as we are concerned here, the relevant differences are 7 : * Variables may be declared when bound.
Reference: [McDermott, 1990] <author> Drew V. McDermott. </author> <title> Planning reactive behavior: A progress report. </title> <booktitle> In Proc. DARPA Workshop on Innovative Approaches to Planning, Scheduling, and Control, </booktitle> <year> 1990. </year>
Reference: [McDermott, 1991] <author> Drew McDermott. </author> <title> A reactive plan language. </title> <type> Technical Report 864, </type> <institution> Yale University Department of Computer Science, </institution> <year> 1991. </year>
Reference-contexts: The former are clear; monitoring examines signals coming from the behavior to check on its state. Such information may then be used by the monitoring RAP to adjust its behavior. Some recent work which builds on many of the ideas of the RAP system is Mc-Dermott's RPL language <ref> [McDermott, 1991] </ref>. Rather than encapsulating a plan in 2.4. THE ROBOT MODEL 31 separate, independent packages like RAPs, RPL conceives of a plan as a high-level robot control program. RPL is a programming language, much like Lisp, with added constructs for building parallel reactive plans. <p> This is the goal of behavioral repetition. To do this, we must translate from event traces to some kind of executable plan notation. The plan notation used here is McDermott's RPL, a reactive plan language developed for work in transformational planning <ref> [McDermott, 1991] </ref>. RPL is a parallel programming language with special constructs for reactive plan execution. This section will describe those RPL features used in this dissertation 6 . <p> Only a single process may own a valve at a given time (subplans inherit from their parent plans). If a process requests a valve (via valve-request) which is owned by another 6 This section does not purport to contain a complete description of the RPL language. Please refer to <ref> [McDermott, 1991] </ref> for a complete description and discussion of RPL features. 4.5. ABSTRACTING BEHAVIOR 121 process (not an ancestor), the process is blocked and cannot run until the valve is released (by valve-release). Valves are used to control contention over robot resources, such as the wheels. <p> Individual event specifications are translated by a set of translation rules, whose left-hand-sides are event specifications with variables to be instantiated. The right-hand-side of each rule is a plan fragment with variables to be substituted for. 7 This summary is adapted from that in <ref> [McDermott, 1991] </ref>. 4.5. ABSTRACTING BEHAVIOR 123 The plans we will construct are sequences consisting of three sorts of steps: effector activations, variable assignments, and condition tests.
Reference: [McDermott, 1992] <author> Drew V. McDermott. </author> <title> Transformational planning of reactive behavior. </title> <type> Technical Report YALEU/CSD/RR #941, </type> <institution> Yale University Department of Computer Science, </institution> <year> 1992. </year> <note> 244 BIBLIOGRAPHY </note>
Reference-contexts: We used a "trash collection" domain similar to other pickup-and-delivery domains that have been investigated, both in situated robotics [Connell, 1989] and in planning <ref> [McDermott, 1992] </ref>. In the trash collection domain, the environment contains objects of two types: trash and trash cans 1 . Trash and trash cans are easily distinguishable from one another. Pieces of trash are of various sizes, and trash cans have limited capacity.
Reference: [McLachlan and Basford, 1988] <author> Geoffrey J. McLachlan and Kaye E. Basford. </author> <title> Mixture Models: Inference And Applications To Clustering. </title> <editor> M. </editor> <publisher> Dekker, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: We restrict our attention to non-parametric methods, which do not assume particular types of distributions (as in, for example, work on mixture models <ref> [McLachlan and Basford, 1988] </ref>). One simple type of method for checking if a probability distribution is bimodal is examining a histogram of observations|multiple maxima in the histogram provide evidence of bimodality (provided enough samples are collected).
Reference: [Mitchell et al., 1986] <author> T.M. Mitchell, R.M. Keller, and S.T. Kedar-Cabelli. </author> <title> Explanation-based generalization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 47-80, </pages> <year> 1986. </year>
Reference-contexts: Here, desig-1 and desig-2 are variables representing designators acquired earlier. This suggests a strategy similar to that used in explanation-based generalization <ref> [Mitchell et al., 1986] </ref>, in which constants are `back-propagated' through a proof tree in order to find the weakest preconditions which allow the proof to remain valid. Those preconditions then describe a justified generalization of the example.
Reference: [Moravec and Elfes, 1985] <author> Hans P. Moravec and Alberto Elfes. </author> <title> High resolution maps from wide angle sonar. </title> <booktitle> In Proc. Int'l Conf. on Robotics and Automation, </booktitle> <pages> pages 138-145, </pages> <year> 1985. </year>
Reference: [Nelson and Aloimonos, 1988] <author> Randall Nelson and John Aloimonos. </author> <title> Obstacle avoidance: Towards qualitative vision. </title> <booktitle> In Proc. Int'l Conf. on Computer Vision, </booktitle> <year> 1988. </year>
Reference-contexts: Usually, low-level intensity/feature models are used to determine camera motion (for, eg, fixation as in [Ballard and Ozcandarli, 1988]). Visual servoing of some sort is often used for controlling camera motion, though arbitrary motion can also be helpful <ref> [Nelson and Aloimonos, 1988] </ref>. Sensor planning, on the other hand, addresses the problem of finding good viewpoints for object recognition and registration [Tarabanis et al., 1990].
Reference: [Nelson, 1989] <author> Randall Nelson. </author> <title> Visual Navigation. </title> <type> PhD thesis, </type> <institution> Computer Vision Laboratory, University of Maryland, </institution> <year> 1989. </year>
Reference-contexts: We also give the percentage of the image corpus (291 images) matched. as noted above. This reinforces the conclusion that these distinctiveness metrics are good predictors of ambiguity. 3.5 Related Work Image-based recognition Nelson's work on image-based homing <ref> [Nelson, 1989] </ref> used a coarse pattern-matching approach, which our framework generalizes. His `patterns' are essentially image signatures based on measurements of dominant edge orientation; he used them to construct a reactive plan for homing a robot to a predetermined location.
Reference: [Neumaier, 1990] <author> Arnold Neumaier. </author> <title> Interval Methods for Systems of Equations. </title> <publisher> Cambridge University Press, </publisher> <year> 1990. </year>
Reference: [Norman, 1980] <author> Donald A. Norman. </author> <title> The Psychology of Everyday Things. </title> <publisher> Basic Books, </publisher> <address> New York, NY, </address> <year> 1980. </year>
Reference-contexts: If waypoints are not easily distinguished, or if there is no recognizable large-scale structure to a space, it can take a very long time to learn to navigate in a space. Some of these issues are discussed in Norman's work on cognitive design <ref> [Norman, 1980] </ref>. 102 CHAPTER 4. NAVIGATIONAL REPRESENTATION can be recognized and approached from afar; and they are orientable. Typing means that we can distinguish waypoints based on different sorts of locally stereotyped environmental structure (we can tell a raven from a writing-desk).
Reference: [Payton, 1986] <author> David W. Payton. </author> <title> An architecture for reflexive autonomous vehicle control. </title> <booktitle> In Proc. Int'l Conf. on Robotics and Automation, </booktitle> <pages> pages 1838-1845, </pages> <year> 1986. </year>
Reference: [Pearl, 1988] <author> Judea Pearl. </author> <title> Probabilistic Reasoning In Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: Tracking waypoints with occlusion is eased by the fact that they don't move. 36 CHAPTER 2. ROBOT MODELING AND SIMULATION oriented to. can be treated the same as any other sensor. In particular, the authors use abstract sensors as inputs into a Bayesian network <ref> [Pearl, 1988] </ref> for robot control. This reduces the dimensionality of the input space, so that the conditional probability matrices in the Bayes nets are manageable.
Reference: [Pentland, 1989] <author> Alex P. Pentland. </author> <title> Local shading analysis. </title> <editor> In Berthold K. P. Horn and Michael J. Brooks, editors, </editor> <booktitle> Shape From Shading, </booktitle> <pages> pages 443-488. </pages> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: There is also a great deal of previous work in vision that can be applied to measurement function development. For example, texture analysis (as done by Witkin [1981]), color histograms [Swain, 1990], or shading (as in [Koenderink and van Doorn, 1989] or <ref> [Pentland, 1989] </ref>) might provide good physically-based measurement functions. Evaluating measurement functions What makes some measurement functions useful and others not? We would like a succinct characterization of measurement `goodness' which could be used when designing measurement functions for a given environment.
Reference: [Philips and Bresina, 1991] <author> A. Philips and J. Bresina. </author> <title> NASA Tileworld manual. </title> <type> Technical Report TR-FIA-91-11, </type> <institution> NASA Ames Research Center, Code FIA, </institution> <year> 1991. </year>
Reference-contexts: Thirdly, we wish events to be inhomogeneous and treat different parts of the world differently. An example of a homogeneous event is the periodic `wind' in 2.5. ANALYSIS 47 the NASA Tileworld <ref> [Philips and Bresina, 1991] </ref>. Homogeneous events are easier to deal with, since their effects on different objects are similar. Ars Magna supports exogenous events through kickers 14 , intermittently applicable procedures that may move or change objects in arbitrary ways.
Reference: [Pitt and Warmuth, 1989] <author> Leonard Pitt and Manfred K. Warmuth. </author> <title> The minimum consistent DFA problem cannot be approximated within any polynomial. </title> <booktitle> In Proc. Twenty First Annual ACM Symp. on Theoretical Computing, </booktitle> <year> 1989. </year> <note> BIBLIOGRAPHY 245 </note>
Reference-contexts: Passive learning of general FSMs, on the other hand, has proven to be intractable. Inferring the smallest deterministic FSM consistent with a set of input/output pairs (inputs not determined by the learner) is NP-complete [Angluin, 1978,Gold, 1978]. Even inferring a machine polynomially larger than the smallest is intractable <ref> [Pitt and Warmuth, 1989] </ref>. These constitute fairly strong negative results for passive map-learning of general finite automata, particularly since the results apply to the simplest (deterministic) case; adding movement uncertainty and sensor noise only makes matters worse.
Reference: [Pollack and Ringuette, 1990] <author> Martha E. Pollack and Marc Ringuette. </author> <title> Introducing the Tileworld: Experimentally evaluating agent architectures. </title> <booktitle> In Proc. National Conference on Artificial Intelligence, </booktitle> <year> 1990. </year>
Reference-contexts: This was because the planner relied on assumptions in the model (such as perfect knowledge) which did not obtain in the real world. Even more recent abstract domains such as the Tileworld <ref> [Pollack and Ringuette, 1990] </ref>, which attempt to address complex issues such as nondeterminism and extraneous events, have some difficulty with the irrelevance problem [Al-Badr and Hanks, 1991]. <p> In this section, we will discuss some of the more prominent of these systems, in terms of the requirements discussed in the last section. 2.6.1 Tileworld A recent effort whose goals are similar to ours is Pollack and Ringuette's Tileworld simulator <ref> [Pollack and Ringuette, 1990] </ref>. The Tileworld domain is a game played on a grid, where the robot's objective is to push square `tiles' into polyomino-shaped `holes'. Holes have limited capacity, requiring reasoning about limited resources.
Reference: [Preparata and Shamos, 1988] <author> Franco Preparata and Michael Ian Shamos. </author> <title> Computational Geometry: An Introduction. </title> <publisher> Springer-Verlag, </publisher> <address> New York, 2nd edition, </address> <year> 1988. </year>
Reference-contexts: The solution is to index signatures using k-d trees (a k-dimensional generalization of binary search trees <ref> [Preparata and Shamos, 1988] </ref>). Direct search can be efficiently performed on a k-d tree for points falling within intervals of IR k . A more flexible search strategy for our purposes, though, is a variety of spiral search [McDermott, 1981b]. <p> By geometric indexing we mean to find waypoints whose positions are close to the predicted current position of the robot; these waypoints are likely to be good matches. One way of doing this quickly is to index waypoints in a k-d tree <ref> [Preparata and Shamos, 1988] </ref> by their relative positions (choosing one as an origin). Alternatively, if local reference frames are used for groups of waypoints, a depth-limited search of reference frames near the current waypoint's could be used to find likely waypoint candidates.
Reference: [Ramey, 1982] <author> Daniel Bruce Ramey. </author> <title> A Non-Parametric Test Of Bimodality With Applications To Cluster Analysis. </title> <type> PhD thesis, </type> <institution> Yale University Department of Statistics, </institution> <year> 1982. </year>
Reference-contexts: However, as Figure 5.12 shows, use of histograms is sensitive to the quantization used to produce them. Another non-parametric bimodality test uses the minimum spanning tree of the observations to decide between unimodality and bimodality <ref> [Ramey, 1982] </ref>. The idea is that the links of the tree are shorter in the vicinity of a mode (since more observations will fall there); tests can be devised to determine if two `short-link regions' exist separated by longer links or not.
Reference: [Rivest and Schapire, 1989] <author> Ronald L. Rivest and Robert E. Schapire. </author> <title> Inference of finite automata using homing sequences. </title> <booktitle> In Proc. 21st Ann. ACM Symp. on Theoretical Computing, </booktitle> <year> 1989. </year>
Reference-contexts: Such graphs represent the connectivity of the environment well, so they have been used in many different sorts of map-learning research. In particular, map-learning may be formalized in this framework as inferring minimal finite-state automata from observations <ref> [Rivest and Schapire, 1989] </ref>. Perceptual noise and effector error can be modeled by making state observations and transitions probabilistic (as in [Basye et al., 1989] and [Dean et al., 1992]).
Reference: [Rivest and Sloan, 1988] <author> Ronald L. Rivest and Robert Sloan. </author> <title> Learning complicated concepts reliably and usefully. </title> <booktitle> In Proc. National Conference on Artificial Intelligence, </booktitle> <pages> pages 635-640, </pages> <year> 1988. </year>
Reference: [Rosenblatt and Payton, 1989] <author> J. Kenneth Rosenblatt and David Payton. </author> <title> A fine-grained alternative to the subsumption architecture for mobile robot control. </title> <booktitle> In Proc. Int'l Joint Conference on Neural Networks, </booktitle> <year> 1989. </year>
Reference: [Sarachik, 1989] <author> Karen B. Sarachik. </author> <title> Visual navigation: Constructing and utilizing simple maps of an indoor environment. </title> <type> Technical Report 1113, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <year> 1989. </year>
Reference-contexts: The assumption was reasonable at the time, but unjustified. On the other hand, assuming a vision system that can often (but not always) find doorways is justifiable, on the basis of recent research in robotic vision <ref> [Sarachik, 1989] </ref>. The reason for requiring justification is so that the abstract domain which is developed remains grounded in the real world. Strict justification is not always necessary, however. We can distinguish between three types of assumptions used to create abstractions: extrapolative, interpolative, and grounded. <p> Approachers may be implemented modularly, as finding and tracking routines combined with a general feedback controller, although specialized servo routines may also be developed (as in <ref> [Sarachik, 1989] </ref>). Naturally, our model allows for both recognizers and approachers to make errors; details of these error modes are discussed in Sections 2.4.2 and 2.4.4 below. A third procedure, not fundamental but nonetheless useful for each waypoint type, is an orienter. <p> It forms a reasonable first approximation, however, given a model of designation errors such as that described below in Section 2.4.2. 8 For example, Sarachik's door-finder occasionally mistakes the space between a water fountain and the wall as a doorway <ref> [Sarachik, 1989] </ref>. 24 CHAPTER 2. ROBOT MODELING AND SIMULATION 2.4 The Robot Model The class of robots we consider are point robots which can turn in place and move with limited velocity and angular speed. Collisions are detected by the cessation of motion. <p> Finding may rely on many different sorts of sensory inputs|doors may be detected as depth discontinuities by sonar, as rigid quadrilaterals in the image plane, and so on. One good example is Sarachik's doorway detector, which uses vision to find vertical edges surrounding depth discontinuities <ref> [Sarachik, 1989] </ref>. Finding a location of a given waypoint type provides a designator which gives the direction of the waypoint found from the current location of the robot. The waypoint type's tracker enables the robot to track the designator once found.
Reference: [Schank and Abelson, 1977] <author> Roger C. Schank and Robert Abelson. </author> <title> Scripts, Plans, Goals and Understanding. </title> <publisher> Erlbaum, </publisher> <address> Hillsdale, NJ, </address> <year> 1977. </year>
Reference-contexts: The idea of waypoints encompasses both these ideas, that of stereotyped environmental structure, and that of local homing. 4 This approach to vision bears a strong similarity to Schank and Abelson's use of scripts in planning and story understanding <ref> [Schank and Abelson, 1977] </ref>. It shares some of the limitations of the approach as well, which Schank himself noted several years later [Schank, 1982]|chiefly brittleness in the face of true novelty.
Reference: [Schank, 1982] <author> Roger C. Schank. </author> <title> Dynamic Memory. </title> <publisher> Cambridge University Press, </publisher> <year> 1982. </year>
Reference-contexts: It shares some of the limitations of the approach as well, which Schank himself noted several years later <ref> [Schank, 1982] </ref>|chiefly brittleness in the face of true novelty.
Reference: [Schweppe, 1968] <author> Fred C. Schweppe. </author> <title> Recursive state estimation: Unknown but bounded errors and system inputs. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> AC-13(5), </volume> <year> 1968. </year>
Reference-contexts: METRIC REPRESENTATION 115 as many as 2n sides, the space (and time) required grows exponentially in the worst case. This problem is only exacerbated for higher-dimensional polytopes. One intermediate approach that has been applied in set-based estimation is use of bounding ellipses <ref> [Schweppe, 1968] </ref>. Directionality is preserved as for polygons, but since ellipses require only constant space, all operation are also constant time. However, as in the case of circles, intersections of ellipses are not ellipses, hence overestimation cannot be avoided when combining two constraints.
Reference: [Slack, 1990] <author> Marc Slack. </author> <title> Situationally Driven Local Navigation for Mobile Robots. </title> <type> PhD thesis, </type> <institution> Virginia Polytechnic Institute, </institution> <year> 1990. </year> <note> NASA JPL Publication 90-17. 246 BIBLIOGRAPHY </note>
Reference: [Smith et al., 1986] <author> Randall Smith, Matthew Self, and Peter Cheeseman. </author> <title> Estimating uncertain spatial relationships in robotics. </title> <booktitle> In Proceedings of the Second Workshop on Uncertainty in Artificial Intelligence, </booktitle> <address> Philadelphia, PA, </address> <year> 1986. </year>
Reference-contexts: Thus, place representations must include a description of the place sufficient to support reliable recognition. Some of this burden can be laid on representations encoding the relative positions of places in the map (see, for example, [Davis, 1984] and <ref> [Smith et al., 1986] </ref>). Chapter 4 describes the diktiometric map representation scheme, which integrates both topological and high-level geometric knowledge in a uniform framework. In any case, due to odometric uncertainty, perceptual cues must be used as well. 3.2. <p> This overestimation can be compensated for somewhat by using more complex representations; their utility remains to be seen (we found regular intervals adequate for our task). Rotational uncertainty also causes problems for statistical techniques due to nonlinearities (as noted by <ref> [Smith et al., 1986] </ref>), so achieving accurate orientation information appears to be key for any robotic map-building using geometric information. In the following section, we will develop a basis for navigational representation based on the notion of the waypoint. <p> This dissertation uses a set-based approach to metric representation, as a system design decision. However, the place-recognition and map-making methods developed here should be adaptable to statistical representation methods (such as that of <ref> [Smith et al., 1986] </ref>) as well, should they be preferable in a given domain.
Reference: [Sutton, 1984] <author> R. Sutton. </author> <title> Temporal Credit Assignment in Reinforcement Learning. </title> <type> PhD thesis, </type> <institution> University of Massachusetts at Amherst, </institution> <year> 1984. </year>
Reference-contexts: His focus was not explicitly on the map learning problem, though; the problem he addressed was that of perceptual aliasing in reinforcement learning. Reinforcement learning is a class of techniques for learning action-selection policies which maximize overall performance (see, eg, <ref> [Sutton, 1984] </ref>). Explicit rewards from the environment are used to infer an `optimal' control policy, which usually takes the form of a function from percepts to actions. This approach can be problematic when important distinctions between world states are not captured by direct perception (perceptual aliasing). <p> FUTURE WORK 233 eventually be advantageous to simply explore the entire graph at the start; however, it is unclear where this tradeoff occurs. This problem is closely related to the problem of state-space exploration in reinforcement learning <ref> [Sutton, 1984] </ref>; in that literature random perturbations are used to ensure that the agent eventually explores its space well. Also, there has been some work on similar problems within the paradigm of competitive learning, for example, see [Blum and Chalasani, 1993].
Reference: [Swain, 1990] <author> Michael J. Swain. </author> <title> Color Indexing. </title> <type> PhD thesis, </type> <institution> University of Rochester, </institution> <year> 1990. </year>
Reference-contexts: Unfortunately, these measurements are very sensitive to camera motion for obvious reasons, which are diffi cult to correct for. There is also a great deal of previous work in vision that can be applied to measurement function development. For example, texture analysis (as done by Witkin [1981]), color histograms <ref> [Swain, 1990] </ref>, or shading (as in [Koenderink and van Doorn, 1989] or [Pentland, 1989]) might provide good physically-based measurement functions. <p> Matching is done using histogram intersection, which finds the fraction of model pixels for which an image pixel can be found with the same color. Localization of the recognized object can be done approximately, by histogram backprojection (see <ref> [Swain, 1990] </ref> for details). The method is simple, efficient, and reliable, and could easily be incorporated as a measurement function in an image signature library. Geometric techniques Another approach to place recognition for topological maps is to use local geometry.
Reference: [Tarabanis et al., 1990] <author> Konstantinos Tarabanis, Roger Y. Tsai, and Peter K. Allen. </author> <title> Automated sensor planning and modeling for robotic vision tasks. </title> <type> Technical Report CUCS 045-90, </type> <institution> Columbia University, </institution> <address> New York, NY, </address> <year> 1990. </year>
Reference-contexts: Visual servoing of some sort is often used for controlling camera motion, though arbitrary motion can also be helpful [Nelson and Aloimonos, 1988]. Sensor planning, on the other hand, addresses the problem of finding good viewpoints for object recognition and registration <ref> [Tarabanis et al., 1990] </ref>. This is done by optimizing some criterion of image goodness, using measures such as number of visible useful features or expected accuracy of image measurements.
Reference: [Taylor and Kriegman, 1993] <author> Camillo J. Taylor and David J. Kriegman. </author> <title> Exploration strategies for mobile robots. </title> <booktitle> In Proc. Int'l Conf. on Robotics and Automation, </booktitle> <address> Atlanta, GA, </address> <month> May </month> <year> 1993. </year>
Reference: [Torrance, 1994] <author> Mark C. Torrance. </author> <title> Natural communication with robots. </title> <type> Master's thesis, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <year> 1994. </year>
Reference: [Vere and Bickmore, 1990] <author> Steven Vere and Timothy Bickmore. </author> <title> A basic agent. </title> <journal> Computational Intelligence, </journal> <volume> 6(1), </volume> <month> Feb </month> <year> 1990. </year>
Reference-contexts: (the robot is omniscient), as Al-Badr and Hanks [1991] point out, hence it is hard to say whether it supports addressing fundamental issues of world complexity, incomplete knowledge and prediction, and real-time planning. 2.6.2 Seaworld Another simulator built as a testbed for AI system experimentation is Vere and Bick-more's Seaworld <ref> [Vere and Bickmore, 1990] </ref>. The simulator was developed for use in testing their integrated AI agent, whose goal is to explore issues of combining 50 CHAPTER 2. ROBOT MODELING AND SIMULATION techniques for planning, natural language comprehension/generation, knowledge representation, and episodic memory.
Reference: [Watkins, 1989] <author> C. J. C. H. Watkins. </author> <title> Learning from Delayed Rewards. </title> <type> PhD thesis, </type> <institution> University of Cambridge, </institution> <year> 1989. </year>
Reference-contexts: When the robot performs an action, its 8.1. QUALITATIVE REPRESENTATION 219 belief is updated based on the action performed and output received, using Bayes' rule. Given a state model, a variant of Q-learning <ref> [Watkins, 1989] </ref> is used to learn a policy relating model states to desired actions. Model learning is interleaved with policy learning. The system is initialized with a small random model. As the system operates and learns a policy for the model, it remembers all its actions and outputs.
Reference: [Witkin, 1981] <author> Andrew P. Witkin. </author> <title> Recovering surface shape and orientation from texture. </title> <journal> Artificial Intelligence, </journal> <volume> 17 </volume> <pages> 17-47, </pages> <year> 1981. </year>
Reference: [Witsenhausen, 1968a] <author> H. S. Witsenhausen. </author> <title> A minimax control problem for sampled linear systems. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> AC-13(1), </volume> <year> 1968. </year>
Reference-contexts: At the same time as Schweppe, Witsenhausen developed set-based methods for discrete-time linear systems using support functions for convex sets [Witsenhausen, 1968b]. He also relates this problem to that of minimax control <ref> [Witsenhausen, 1968a] </ref>. Barmish and Sankaran [1979] analyze the use of polytopic representations of sets for modeling uncertainty in discrete linear systems; this idea was also suggested by Witsenhausen [1968b]. In [Hager et al., 1993], we compared set-based estimation methods with comparable statistical methods, with particular attention to robotic applications.
Reference: [Witsenhausen, 1968b] <author> H. S. Witsenhausen. </author> <title> Sets of possible states of linear systems given perturbed observations. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> AC-13(5), </volume> <year> 1968. </year>
Reference-contexts: This method was extended and improved by Bertsekas and Rhodes [1971], who also noted the close relationship between ellipsoidal estimation and Kalman filtering for particular classes of noise models. At the same time as Schweppe, Witsenhausen developed set-based methods for discrete-time linear systems using support functions for convex sets <ref> [Witsenhausen, 1968b] </ref>. He also relates this problem to that of minimax control [Witsenhausen, 1968a]. Barmish and Sankaran [1979] analyze the use of polytopic representations of sets for modeling uncertainty in discrete linear systems; this idea was also suggested by Witsenhausen [1968b].
Reference: [Yamauchi and Nelson, 1991] <author> Brian Yamauchi and Randall Nelson. </author> <title> A behavior-based architecture for robots using real-time vision. </title> <booktitle> In Proc. Int'l Conf. on Robotics and Automation, </booktitle> <year> 1991. </year>
Reference: [Yeap, 1988] <author> Wai K. Yeap. </author> <title> Towards a computational theory of cognitive maps. </title> <journal> Artificial Intelligence, </journal> <volume> 34(3), </volume> <month> April </month> <year> 1988. </year> <note> BIBLIOGRAPHY 247 </note>
Reference: [Yemini, 1979] <author> Yechiam Yemini. </author> <title> Some theoretical aspects of position-location problems. </title> <booktitle> In Proc. 20th Symp. on Foundations of Computer Science, </booktitle> <pages> pages 1-8, </pages> <year> 1979. </year>
Reference: [Zetsche and Caelli, 1989] <author> Christoph Zetsche and Terry Caelli. </author> <title> Invariant pattern recognition using multiple filter image representations. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 45 </volume> <pages> 251-262, </pages> <year> 1989. </year> <note> 248 BIBLIOGRAPHY </note>
References-found: 122

