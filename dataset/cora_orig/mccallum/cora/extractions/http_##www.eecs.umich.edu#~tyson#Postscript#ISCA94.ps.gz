URL: http://www.eecs.umich.edu/~tyson/Postscript/ISCA94.ps.gz
Refering-URL: http://www.eecs.umich.edu/~tyson/publications.html
Root-URL: http://www.cs.umich.edu
Email: (tyson@cs.ucdavis.edu) (arp@tosca.colorado.edu)  
Title: d d A Study of Single-Chip Processor/Cache Organizations for Large Numbers of Transistors  
Author: Matthew Farrens Andrew R. Pleszkun Gary Tyson 
Address: Davis, CA 95616  (farrens@cs.ucdavis.edu) Boulder, CO 80309-0425  
Affiliation: Computer Science Department Department of Electrical and University of California, Davis Computer Engineering  University of Colorado-Boulder  
Abstract: This paper presents a trace-driven simulation-based study of a wide range of cache configurations and processor counts. This study was undertaken in an attempt to help answer the question of how best to allocate large numbers of transistors, a question that is rapidly increasing in importance as transistor densities continue to climb. At what point does continuing to increase the size of the on-chip first level cache cease to provide sufficient increases in hit rate and become prohibitively difficult to access in a single cycle? In order to compare different configurations, the concept of an Equivalent Cache Transistor is presented. Results indicate that the access time of the first-level data cache is more important than the size. In addition, it appears that once approximately 15 million transistors become available, a two processor configuration is preferable to a single processor with correspondingly larger caches. 
Abstract-found: 1
Intro-found: 1
Reference: [DWAA92] <author> D. W. Dobberpuhl, R. T. Witek, R. Allmon, R. Anglin, D. Bertucci, S. Britton, L. Chao, R. A. Conrad, D. E. Dever, B. Gieseke, S. M. N. Hassoun, G. W. Hoeppner, K. Kuchler, M. Ladd, B. M. Leary, L. Madden, E. J. McLellan, D. R. Meyer, J. Montanaro, D. A. Priore, V. Rajagopalan, S. Samudrala and S. Santhanam, </author> <title> ``A 200-MHz 64-b Dual-Issue CMOS Microprocessor'', </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> vol. 27, no. </volume> <month> 11 (November </month> <year> 1992). </year>
Reference-contexts: This processor has 16K bytes of on-chip cache and uses a 6 transistor standard cache cell design <ref> [DWAA92, Site93] </ref>. Then, using this transistor count in conjunction with an observation of the amount of on-chip space that is occupied by the caches, we can compute the number of transistors (in ECTs) needed to implement the processor.
Reference: [FaPT92] <author> M. Farrens, A. Pleszkun and G. Tyson, </author> <title> ``A Study of Single-Chip Processor/Cache Organizations for Large Numbers of Transistors'', </title> <institution> Computer Science Department Technical Report CSE-92-24, University of California at Davis, Davis, California (December 1992). </institution>
Reference-contexts: In order to get some feel for how representative the sampled traces were, we also calculated the number of unique addresses in each sampled and unsampled trace. This analysis can be found in <ref> [FaPT92] </ref>. 4. The Simulations Time and resource constraints prevented us from achieving the ideal goal of exhaustively simulating all possible configurations of processors and caches. <p> However, since some of our interpretations of these results may not be immediately evident from only looking at the figures, or because the reader may wish to analyze the results from a different perspective, we have included a table of all the simulations results in <ref> [FaPT92] </ref>. Before looking at multiprocessor results, we will first present the results for the single processor simulations. Figures 2a through 2d plot performance in terms of clocks per cycle (CPI) versus transistor count. The four plots group results by main memory access times and the percentage of delay slots filled. <p> Again, transistor counts that fall into d d these regions should have transistors available for alternate uses. Such detailed comparisons of other configurations can be made with the help of the data available in <ref> [FaPT92] </ref>. If we look at the groups of curves from left to right, as the second-level cache size becomes larger than 64K bytes, some overlap in the performance of the systems becomes apparent.
Reference: [Hill87] <author> M. D. Hill, </author> <title> Aspects of Cache Memory and Instruction Buffer Performance, </title> <type> Ph.D. Thesis, </type> <institution> Department of Computer Sciences,, Berkeley, California, </institution> <month> (November </month> <year> 1987). </year>
Reference-contexts: However, the afore-mentioned resource constraints forced us to chose a single associativity organization. While we realize that a large direct-mapped second-level cache should perform well <ref> [Hill87] </ref> we chose a 4-way set associative cache since in some of the system configurations, the second-level cache is not much larger than the first-level caches it supports. This is especially true when we look at multiple on-chip processor configurations where the second-level cache is supporting several first-level caches.
Reference: [John91] <author> M. Johnson, </author> <title> Superscalar Microprocessor Design, </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> (1991). </year>
Reference-contexts: The Traces Sixteen traces were selected as representative of a typical workload. Nine traces were chosen from the SPEC89 benchmark suite, and augmented by seven additional traces used by Johnson in his book <ref> [John91] </ref>. The benchmark programs were compiled with the native RISC C compiler (/usr/bin/cc) on a DECstation 5000/240 with optimization level 2. The traces were then gathered using the pixie trace generating facility.
Reference: [LaPI88] <author> S. Laha, J. Patel and R. K. Iyer, </author> <title> ``Accurate Low-Cost Methods for Performance Evaluation of Cache Memory Systems'', </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. 37, no. </volume> <month> 11 (November, </month> <year> 1988), </year> <pages> pp. 1325-1336. </pages>
Reference-contexts: So, for example, in our study we use sampled traces that consist of 100 contiguous blocks of instructions each 75,000 references long. This approach to using shorter traces to represent much longer reference streams is very similar to the approach used in <ref> [LaPI88] </ref>. In order to get some feel for how representative the sampled traces were, we also calculated the number of unique addresses in each sampled and unsampled trace. This analysis can be found in [FaPT92]. 4.
Reference: [Site93] <author> R. L. </author> <title> Sites, ``Alpha AXP Architecture'', </title> <journal> Communications of the ACM, </journal> <volume> vol. 36, no. </volume> <month> 2 (February, </month> <year> 1993), </year> <pages> pp. 33-44. </pages>
Reference-contexts: This processor has 16K bytes of on-chip cache and uses a 6 transistor standard cache cell design <ref> [DWAA92, Site93] </ref>. Then, using this transistor count in conjunction with an observation of the amount of on-chip space that is occupied by the caches, we can compute the number of transistors (in ECTs) needed to implement the processor.
Reference: [Smit82] <author> A. J. Smith, </author> <title> ``Cache Memories'', </title> <journal> ACM Computing Surveys, </journal> <volume> vol. 14, no. </volume> <month> 3 (September </month> <year> 1982), </year> <pages> pp. 473-530. </pages>
Reference-contexts: Numerous cache studies have also validated this as a reasonable size <ref> [Smit82, SmGo85] </ref>. All caches employ a write-back replacement policy. The processors are single-issue processors with a CPI of 1 (excluding memory references).
Reference: [SmGo85] <author> J. E. Smith and J. R. Goodman, </author> <title> ``Instruction Cache Replacement Policies and Organizations'', </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. C-34, no. </volume> <month> 3 (March </month> <year> 1985), </year> <pages> pp. 234-241. </pages>
Reference-contexts: Numerous cache studies have also validated this as a reasonable size <ref> [Smit82, SmGo85] </ref>. All caches employ a write-back replacement policy. The processors are single-issue processors with a CPI of 1 (excluding memory references).
Reference: [YeP91] <author> T. Yeh and Y. Patt, </author> <title> ``Two-Level Adaptive Training Branch Prediction'', </title> <booktitle> Proceedings of the 24th Annual International Symposium on Microarchitecture, </booktitle> <address> Albuquerque, New Mexico (November 18-20, </address> <year> 1991), </year> <pages> pp. 51-61. </pages> <address> d d </address>
Reference-contexts: For example, it may make sense to invest some transistors in branch prediction hardware, such as that proposed by Yeh and Patt <ref> [YeP91] </ref>. Another use of extra transistors could be for register renaming schemes, or more hardware support for multiple or out-of-order issue of instructions. Also, at some point, when most of the chip area is used as d d memory, it becomes reasonable to consider placing more processors on the chip.
References-found: 9

