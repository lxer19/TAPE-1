URL: http://www.eecs.umich.edu/~tyson/Postscript/IJPP.ps.gz
Refering-URL: http://www.eecs.umich.edu/~tyson/publications.html
Root-URL: http://www.cs.umich.edu
Email: email: tyson@cs.ucdavis.edu, farrens@cs.ucdavis.edu  
Phone: tel: (916) 752-9678, fax: (916) 752-4767  
Title: d d Code Scheduling for Multiple Instruction Stream Architectures  
Author: Gary Tyson and Matthew Farrens 
Address: Davis, CA 95616  
Affiliation: Computer Science Department University of California, Davis  
Abstract: Extensive research has been done on extracting parallelism from single instruction stream processors. This paper presents our investigation into ways to modify MIMD architectures to allow them to extract the instruction level parallelism achieved by current superscalar and VLIW machines. A new architecture is proposed which utilizes the advantages of a multiple instruction stream design while addressing some of the limitations that have prevented MIMD architectures from performing ILP operation. A new code scheduling mechanism is described to support this new architecture by partitioning instructions across multiple processing elements in order to exploit this level of parallelism. 
Abstract-found: 1
Intro-found: 1
Reference: [AhS] <author> A. V. Aho, R. Sethi and J. D. Ullman, </author> <booktitle> ``Compilers Principles, Techniques and Tools'', </booktitle> <publisher> Addison-Wesley Publishing, </publisher> <pages> pp. 644. </pages>
Reference-contexts: The detection of induction variables is a well understood problem. The algorithm used in this compiler is derived from <ref> [AhS] </ref> (Algorithm 10.9). - 16 - d d Once the control state of the machine has been modified to support loop operations, it is a simple modification to handle the calculation of induction variables used in the loop.
Reference: [AKPW83] <author> J. R. Allen, K. Kennedy, C. Porterfield and J. Warren, </author> <title> ``Conversion of control dependencies to data dependencies'', </title> <booktitle> Proceeding of the 10th ACM Symposium on Principles of Programming Languages(January 1983), </booktitle> <pages> pp. 177-189. </pages>
Reference-contexts: The store request (SAQ) instruction operates in a similar manner, except that the dest operand specifies a single PE from which the DCache should receive data to be written to memory. There are three types of MISC instructions: predicated operations <ref> [AKPW83] </ref>, vector operations, and sentinel operations (which use a sentinel value to terminate iterations of the instruction). Predicated ALU/FPU operations perform all scalar operations as well as allow conditional operations to be specified concisely.
Reference: [AuSo92] <author> T. Austin and G. Sohi, </author> <title> ``Dynamic Dependency Analysis of Ordinary Programs'', </title> <booktitle> Proceedings of the 19th Annual Symposium on Computer Architecture, </booktitle> <volume> vol. 20, no. </volume> <month> 2 (May 19-21, </month> <year> 1992), </year> <pages> pp. 342-351. </pages>
Reference-contexts: Several studies [JoWa89, TjFl70] indicate that compilers using simple scheduling techniques are capable of identifying 2-3 independent instructions per cycle. Other studies <ref> [AuSo92, BuYP91] </ref> suggest that even more parallelism can be found if the compiler's scheduler is capable of performing extensive code motion. In this paper, we will present a brief overview of single and multiple instruction stream approaches to multiple issue processor design.
Reference: [BeDa91] <author> M. E. Benitez and J. W. Davidson, </author> <title> ``Code Generation for Streaming: an Access/Execute Mechanism'', </title> <booktitle> Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Santa Clara, CA (April 8-11, </address> <year> 1991), </year> <pages> pp. 132-141. </pages>
Reference-contexts: This pattern of compare and issue is repeated until the comparison produces a match. 5. Related Work There have been several decoupled compilers that have been developed. These include the original PIPE compiler [Youn85], the WM streams compiler <ref> [BeDa91] </ref>, and the compiler for the Briarcliff Multiprocessor [Gupt90]. The PIPE compiler separates code into access and execute instruction streams. <p> The MISC Compiler The very portable C compiler (vpcc) <ref> [BeDa91] </ref> under development at the University of Virginia serves as the base compiler for MISC.
Reference: [BuYP91] <author> M. Butler, T. Yeh and Y. Patt, </author> <title> ``Single Instruction Stream Parallelism is Greater than Two'', </title> <booktitle> Proceedings of the Eighteenth Annual International Symposium on Computer Architecture, </booktitle> <address> Toronto, Canada (May 27-30, </address> <year> 1991), </year> <pages> pp. 276-286. </pages>
Reference-contexts: Several studies [JoWa89, TjFl70] indicate that compilers using simple scheduling techniques are capable of identifying 2-3 independent instructions per cycle. Other studies <ref> [AuSo92, BuYP91] </ref> suggest that even more parallelism can be found if the compiler's scheduler is capable of performing extensive code motion. In this paper, we will present a brief overview of single and multiple instruction stream approaches to multiple issue processor design.
Reference: [CGKP87] <author> G. L. Craig, J. R. Goodman, R. H. Katz, A. R. Pleszkun, K. Ramachandran, J. Sayah and J. E. Smith, </author> <title> ``PIPE: A High Performance VLSI Processor Implementation'', </title> <journal> Journal of VLSI and Computer Systems, </journal> <volume> vol. </volume> <month> 2 </month> <year> (1987). </year>
Reference-contexts: The ZS-1 [SDVK87, Smit89] and WM [Wulf92] systems operate in a decoupled manner while receiving instructions from a single instruction stream. Their architectural component descriptions are similar to those of Split Register superscalar designs [Site93, SCHP92]. The PIPE machine, in contrast, [GHLP85] consists of two PIPE processors <ref> [CGKP87] </ref> which run asynchronously, each with their own instruction stream, and cooperate on the execution of a single task. 3. Exploiting ILP on a MIMD architecture Parallelism in a single instruction stream architecture resides primarily at the instruction level, and is a well-studied problem [JoWa89, Wall91].
Reference: [DaVa90] <author> M. Danelutto and M. Vanneschi, ``VLIW-in-the-large: </author> <title> A Model for Fine Grain Parallelism Exploitation on Distributed Memory Multiprocessors'', </title> <booktitle> Proceedings of the 23rd Annual Symposium and Workshop on Microprogramming and Microarchitectures, </booktitle> <address> Orlando, Florida (November 27-29, </address> <year> 1990), </year> <pages> pp. 7-16. </pages>
Reference-contexts: The XIMD processor [WoSh91] adds control logic to each functional unit of a VLIW in order to transform it into a MIMD. However, since it is a VLIW at the core, it requires a high-performance, completely orthogonal, global register file in order to support inter-process communication. The coMP approach <ref> [DaVa90] </ref> is a communication oriented multi-processor that can be operated in VLIW mode. However, it does not allow dynamic slip between processing elements, and the communication ports between processors are only depth 1.
Reference: [FaPl91] <author> M. Farrens and A. Pleszkun, </author> <title> ``Overview of the PIPE Processor Implementation'', </title> <booktitle> Proceedings of the 24th Annual Hawaii International Conference on System Sciences, </booktitle> <address> Kapaa, Kauai (January 9-11, </address> <year> 1991), </year> <pages> pp. 433-443. </pages>
Reference-contexts: This allows the issue logic to proceed without interrupt through short segments of conditionally executed code by conditionally completing instead of branching around code. In the case of control flow operations, the dest field is used as a constant to determine the number of delayed branch slots <ref> [FaPl91] </ref> to be filled. The address of the branch is calculated as the sum of the src1 and src2 operands, and the src3 operand specifies the register to be tested. Vector instructions use the third source operand (src3) to specify a vector count.
Reference: [FaTP94] <author> M. Farrens, G. Tyson and A. Pleszkun, </author> <title> ``A Study of Single-Chip Processor/Cache Organizations for Large Numbers of Transistors'', </title> <booktitle> Proceedings of the 21st Annual Symposium on Computer Architecture, </booktitle> <address> Chicago, IL (April 18-21, </address> <year> 1994), </year> <pages> pp. 338-347. </pages>
Reference-contexts: In addition, using FIFO queues in a manner similar to that used by decoupled machines provides a clean way to handle synchronization. If transistor densities continue to increase as they have over the last decade, by the middle of this decade such a design will be realizable. One study <ref> [FaTP94] </ref> indicates that as tens of millions of transistors become available, something more than simply increasing on-chip cache sizes must be done. These facts led to the design of the MISC architecture, a decoupled MIMD machine that is designed to support and exploit instruction level parallelism. 4.
Reference: [FeOW87] <author> F. Ferrante, K. Ottenstein and J. Warren, </author> <title> ``The Program Dependence Graph and Its Use In Optimization'', </title> <journal> ACM Transactions on Programming Languages and Systems(July 1987), </journal> <pages> pp. 319-349. </pages>
Reference-contexts: The PIPE compiler separates code into access and execute instruction streams. This is accomplished by assigning each branch and memory access operation to the access processor, then examining a Program Dependence Graph (PDG) <ref> [FeOW87] </ref> to determine which additional branch control calculation operations and address calculation operations should also be assigned the access processor. All - 5 - d d remaining instructions, as well as duplicate branch operations, are then assigned to the execute processor.
Reference: [GHLP85] <author> J. R. Goodman, J. T. Hsieh, K. Liou, A. R. Pleszkun, P. B. Schechter and H. C. Young, </author> <title> ``PIPE: a VLSI Decoupled Architecture'', </title> <booktitle> Proceedings of the Twelveth Annual International Symposium on Computer Architecture(June 1985), </booktitle> <pages> pp. 20-27. </pages>
Reference-contexts: The ZS-1 [SDVK87, Smit89] and WM [Wulf92] systems operate in a decoupled manner while receiving instructions from a single instruction stream. Their architectural component descriptions are similar to those of Split Register superscalar designs [Site93, SCHP92]. The PIPE machine, in contrast, <ref> [GHLP85] </ref> consists of two PIPE processors [CGKP87] which run asynchronously, each with their own instruction stream, and cooperate on the execution of a single task. 3.
Reference: [Gupt89] <author> R. Gupta, </author> <title> ``The Fuzzy Barrier: A Mechanism for High-speed Synchronization of Processors'', </title> <booktitle> Proceedings of the Third International Conference on Architectural Support for Programming Languages and Operating Systems(1989), </booktitle> <pages> pp. 54-64. </pages>
Reference-contexts: While each PE may reach the actual branch instruction on different cycles, no PE can continue to process the next branch operation until each PE has completed its branch decision on the original branch. This fuzzy barrier <ref> [Gupt89] </ref> mechanism allows more flexibility than a VLIW implementation but fails to provide the flexibility found in true MIMD approaches like PIPE and MISC. There are several other designs that attempt to exploit ILP on a MIMD.
Reference: [Gupt90] <author> R. Gupta, </author> <title> ``A Fine-grained MIMD Architecture based upon Register Channels'', </title> <booktitle> Proceedings of the 23rd Annual Symposium and Workshop on Microprogramming and Microarchitectures, </booktitle> <address> Orlando, Florida (November 27-29, </address> <year> 1990), </year> <pages> pp. 54-64. </pages>
Reference-contexts: This pattern of compare and issue is repeated until the comparison produces a match. 5. Related Work There have been several decoupled compilers that have been developed. These include the original PIPE compiler [Youn85], the WM streams compiler [BeDa91], and the compiler for the Briarcliff Multiprocessor <ref> [Gupt90] </ref>. The PIPE compiler separates code into access and execute instruction streams. <p> This compiler is far more aggressive in separating code into multiple instruction streams. This machine shares many characteristics of a restricted dataflow architecture [Iann88]. Instructions are partitioned equally over the available processing elements with those data dependencies that exist between PEs being allocated a register channel. <ref> [Gupt90] </ref> Optimization is then performed to reduce the number of channels required without degrading code performance. Memory operations can also be performed on register channels.
Reference: [Iann88] <author> R. A. </author> <title> Iannucci, ``Toward a Dataflow / von Neumann Hybrid Architecture'', </title> <booktitle> Proceedings of the 15th Annual Symposium on Computer Architecture(1988), </booktitle> <pages> pp. 131-140. </pages>
Reference-contexts: The compiler used in the Briarcliff Multiprocessor performs in a much different manner from the previous two compilers. This compiler is far more aggressive in separating code into multiple instruction streams. This machine shares many characteristics of a restricted dataflow architecture <ref> [Iann88] </ref>. Instructions are partitioned equally over the available processing elements with those data dependencies that exist between PEs being allocated a register channel. [Gupt90] Optimization is then performed to reduce the number of channels required without degrading code performance. Memory operations can also be performed on register channels.
Reference: [JoWa89] <author> N. P. Jouppi and D. W. Wall, </author> <title> ``Available Instruction-Level Parallelism for Superscalar and Superpipelined Machines'', </title> <booktitle> Proceedings of the Third International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Boston, Mass (April 3-6, </address> <year> 1989), </year> <pages> pp. 272-282. </pages>
Reference-contexts: The task of the scheduler in a multi-issue system is further complicated by the fact that while the latency of operational units and memory remain fixed, the number of instructions that must be scheduled in a period is increased by the width of the issue stage. Several studies <ref> [JoWa89, TjFl70] </ref> indicate that compilers using simple scheduling techniques are capable of identifying 2-3 independent instructions per cycle. Other studies [AuSo92, BuYP91] suggest that even more parallelism can be found if the compiler's scheduler is capable of performing extensive code motion. <p> Exploiting ILP on a MIMD architecture Parallelism in a single instruction stream architecture resides primarily at the instruction level, and is a well-studied problem <ref> [JoWa89, Wall91] </ref>. Extracting parallelism on a MIMD architecture, on the other hand, has traditionally been accomplished by partitioning the program into data independent portions and assigning them to separate processing elements, ignoring any other parallelism that might exist.
Reference: [KeDa92] <author> S. W. Keckler and W. J. Dally, </author> <title> ``Processor Coupling: Integrating Compile Time and Runtime Scheduling for Parallelism'', </title> <institution> ISCA19, Queensland, </institution> <address> Australia (May 19-21, </address> <year> 1992), </year> <pages> pp. 202-213. </pages> - <address> 21 - d d </address>
Reference-contexts: The coMP approach [DaVa90] is a communication oriented multi-processor that can be operated in VLIW mode. However, it does not allow dynamic slip between processing elements, and the communication ports between processors are only depth 1. The work by Keckler and Dally <ref> [KeDa92] </ref> is similar to XIMD in that a 4-ALU machine is augmented to allow it to run in a MIMD fashion. PEs can write to each others register files, but no mention of queues is given, and multi-ported register files are still required.
Reference: [Lam88] <author> M. S. Lam, </author> <title> ``Software Pipelining: An Effective Scheduling Technique for VLIW Machines'', </title> <booktitle> Proceedings of the ACM SIGPLAN Notices 1988 Conference on Programming Languages and Implementations(June 1988), </booktitle> <pages> pp. 318-328. </pages>
Reference-contexts: Superscalar designs can remove some of the restrictions imposed by single stream scheduling by regenerating some the dataflow information at the issue stage of the pipeline, but not without considerable hardware issue logic. Furthermore, software pipelining <ref> [Lam88] </ref> and loop unrolling schemes [WeSm87] have difficulty in efficiently scheduling instructions with variable latency dependencies. MISC avoids these scheduling problems by allowing operations with indeterminate latencies to transfer data between PEs.
Reference: [MLCH92] <author> S. A. Mahlke, D. C. Lin, W. Y. Chen, R. E. Hank and R. A. Bringmann, </author> <title> ``Effective Compiler Support for Predicated Execution Using the Hyperblock'', </title> <booktitle> Proceedings of the 25th Annual International Symposium on Microarchitecture, </booktitle> <address> Portland, Oregon (December 1-4, </address> <year> 1992), </year> <pages> pp. 45-54. </pages>
Reference-contexts: It is best to do these transformations at this point, before the complexity of inter-PE dependencies must be considered. Similarly, if-conversion <ref> [MLCH92] </ref> can also be performed at this point in order to simplify the control flow. Global dataflow analysis can then be performed, and a PDG built. <p> The reduction figures for the benchmark programs is shown in Table 1. If-conversion <ref> [MLCH92] </ref> also reduces the effects of branching by eliminating branching operations in favor of predicated execution.
Reference: [RaS92] <author> B. R. Rau, M. S. Schlansker and P. P. Tirumalai, </author> <title> ``Code Generation Schema for Modulo Scheduled Loops'', </title> <booktitle> Proceedings of the 25th Annual International Symposium on Microarchitecture, </booktitle> <address> Portland, Oregon (December 1-4, </address> <year> 1992), </year> <pages> pp. 158-169. </pages>
Reference-contexts: To provide a comparison with a similarly configured single instruction stream/multiple issue architecture, the loops were also hand compiled for a four-issue VLIW architecture based upon the version found in <ref> [RaS92] </ref>. This VLIW machine allows four instructions to be issued per clock cycle, and places no limitations on the type of instructions that can be issued. Furthermore, it assumes sufficient resources (e.g. register transfer bandwidth) to sustain a four instructions per cycle execution rate.
Reference: [Site93] <author> R. L. </author> <title> Sites, ``Alpha AXP Architecture'', </title> <journal> Communications of the ACM, </journal> <volume> vol. 36, no. </volume> <month> 2 (February, </month> <year> 1993), </year> <pages> pp. 33-44. </pages>
Reference-contexts: The ZS-1 [SDVK87, Smit89] and WM [Wulf92] systems operate in a decoupled manner while receiving instructions from a single instruction stream. Their architectural component descriptions are similar to those of Split Register superscalar designs <ref> [Site93, SCHP92] </ref>. The PIPE machine, in contrast, [GHLP85] consists of two PIPE processors [CGKP87] which run asynchronously, each with their own instruction stream, and cooperate on the execution of a single task. 3.
Reference: [Smit82] <author> J. E. Smith, </author> <title> ``Decoupled Access/Execute Computer Architectures'', </title> <booktitle> Proceedings of the Ninth Annual International Symposium on Computer Architecture, </booktitle> <address> Austin, Texas (April 26-29, </address> <year> 1982), </year> <pages> pp. 112-119. </pages>
Reference-contexts: Conflict Buffers <ref> [Smit82] </ref> can then be used to reorder these memory operations during execution to maximize memory throughput.
Reference: [Smit84] <author> J. E. Smith, </author> <title> ``Decoupled Access/Execute Computer Architectures'', </title> <journal> TOCS, </journal> <volume> vol. 2, no. </volume> <month> 4 (November </month> <year> 1984), </year> <pages> pp. 289-308. </pages>
Reference-contexts: Furthermore, in order to transmit data among operational units by writing and then reading the contents of a register, the clocks on VLIW and superscalar processors must be synchronized. This requirement is relaxed with an explicit message passing approach. <ref> [Smit84] </ref> The greater flexibility found in a decoupled design allows both single and multiple instruction stream descriptions of a task. The ZS-1 [SDVK87, Smit89] and WM [Wulf92] systems operate in a decoupled manner while receiving instructions from a single instruction stream.
Reference: [SDVK87] <author> J. E. Smith, G. E. Dermer, B. D. Vanderwarn, S. D. Klinger, C. M. Rozewski, D. L. Fowler, K. R. Scidmore and J. P. Laudon, </author> <title> ``The ZS-1 Central Processor'', </title> <booktitle> Proceedings of the Second International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Palo Alto, California (October 1987), </address> <pages> pp. 199-204. </pages>
Reference-contexts: This requirement is relaxed with an explicit message passing approach. [Smit84] The greater flexibility found in a decoupled design allows both single and multiple instruction stream descriptions of a task. The ZS-1 <ref> [SDVK87, Smit89] </ref> and WM [Wulf92] systems operate in a decoupled manner while receiving instructions from a single instruction stream. Their architectural component descriptions are similar to those of Split Register superscalar designs [Site93, SCHP92].
Reference: [Smit89] <author> J. E. Smith, </author> <title> ``Dynamic Instruction Scheduling and the Astronautics ZS-1'', </title> <journal> Computer, </journal> <volume> vol. 22, no. </volume> <month> 7 (July </month> <year> 1989), </year> <pages> pp. 21-35. </pages>
Reference-contexts: This requirement is relaxed with an explicit message passing approach. [Smit84] The greater flexibility found in a decoupled design allows both single and multiple instruction stream descriptions of a task. The ZS-1 <ref> [SDVK87, Smit89] </ref> and WM [Wulf92] systems operate in a decoupled manner while receiving instructions from a single instruction stream. Their architectural component descriptions are similar to those of Split Register superscalar designs [Site93, SCHP92].
Reference: [SCHP92] <author> C. Stephens, B. Cogswell, J. Heinlein, G. Palmer and J. P. Shen, </author> <title> ``Instruction Level Profiling and Evaluation of the IBM RS/6000'', </title> <booktitle> Proceedings of the 19th Annual Symposium on Computer Architecture, </booktitle> <volume> vol. 20, no. </volume> <month> 2 (May 19-21, </month> <year> 1992), </year> <pages> pp. 180-189. </pages>
Reference-contexts: The ZS-1 [SDVK87, Smit89] and WM [Wulf92] systems operate in a decoupled manner while receiving instructions from a single instruction stream. Their architectural component descriptions are similar to those of Split Register superscalar designs <ref> [Site93, SCHP92] </ref>. The PIPE machine, in contrast, [GHLP85] consists of two PIPE processors [CGKP87] which run asynchronously, each with their own instruction stream, and cooperate on the execution of a single task. 3.
Reference: [TjFl70] <author> G. S. Tjaden and M. J. Flynn, </author> <title> ``Detection and Parallel Execution of Independent Instructions'', </title> <journal> IEEE Transactions on Computer(May 1970), </journal> <pages> pp. 889-895. </pages>
Reference-contexts: The task of the scheduler in a multi-issue system is further complicated by the fact that while the latency of operational units and memory remain fixed, the number of instructions that must be scheduled in a period is increased by the width of the issue stage. Several studies <ref> [JoWa89, TjFl70] </ref> indicate that compilers using simple scheduling techniques are capable of identifying 2-3 independent instructions per cycle. Other studies [AuSo92, BuYP91] suggest that even more parallelism can be found if the compiler's scheduler is capable of performing extensive code motion.
Reference: [TyFP92] <author> G. Tyson, M. Farrens and A. Pleszkun, ``MISC: </author> <title> A Multiple Instruction Stream Computer'', </title> <booktitle> Proceedings of the 25th Annual International Symposium on Microarchitecture, </booktitle> <address> Portland, Oregon (December 1-4, </address> <year> 1992), </year> <pages> pp. 193-196. </pages>
Reference-contexts: MISC avoids these scheduling problems by allowing operations with indeterminate latencies to transfer data between PEs. The inherent asynchronous relationship among the PEs can compensate for the variability of the latency without affecting the execution rate of non-dependent instructions. The MISC processor has been described in detail in <ref> [TyFP92] </ref>. A brief overview of MISC will be presented here, focusing on aspects of the architecture that will be featured in the code scheduling discussion later in the paper.
Reference: [TySF93] <author> G. S. Tyson, R. Shaw and M. Farrens, </author> <title> ``An Interactive Compiler Development System'', </title> <address> Tcl/Tk Workshop(June 10-11, </address> <year> 1993). </year>
Reference-contexts: The first 12 loops were compiled for both the MIPS and MISC architectures. The MIPS code was compiled using the cc compiler with optimization -O2, and the MISC code was generated using the IAGO <ref> [TySF93] </ref> compilation environment using the techniques discussed in section 5 of this paper. iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii [1] [PE4] t1 = 0 ; q=0 [3] [PE1-4] t3 = 1024 ; set register for test [4] [PE1] t4 = LOC [_z] ; t4 = base of array z [5] [PE2] t5 = LOC [_x] ;
Reference: [Wall91] <author> D. Wall, </author> <title> ``Limits of Instruction-Level Parallelism'', </title> <booktitle> Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Santa Clara, CA (April 8-11, </address> <year> 1991), </year> <pages> pp. 176-189. </pages>
Reference-contexts: Exploiting ILP on a MIMD architecture Parallelism in a single instruction stream architecture resides primarily at the instruction level, and is a well-studied problem <ref> [JoWa89, Wall91] </ref>. Extracting parallelism on a MIMD architecture, on the other hand, has traditionally been accomplished by partitioning the program into data independent portions and assigning them to separate processing elements, ignoring any other parallelism that might exist.
Reference: [WeSm87] <author> S. Weiss and J. E. Smith, </author> <title> ``A Study of Scalar Compilation Techniques for Pipelined Supercomputers'', </title> <booktitle> Proceedings of the Second International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Palo Alto, CA (October 5-8, </address> <year> 1987), </year> <pages> pp. 105-109. </pages>
Reference-contexts: Superscalar designs can remove some of the restrictions imposed by single stream scheduling by regenerating some the dataflow information at the issue stage of the pipeline, but not without considerable hardware issue logic. Furthermore, software pipelining [Lam88] and loop unrolling schemes <ref> [WeSm87] </ref> have difficulty in efficiently scheduling instructions with variable latency dependencies. MISC avoids these scheduling problems by allowing operations with indeterminate latencies to transfer data between PEs. The inherent asynchronous relationship among the PEs can compensate for the variability of the latency without affecting the execution rate of non-dependent instructions.
Reference: [WoSh91] <author> A. Wolfe and J. P. Shen, </author> <title> ``A Variable Instruction Stream Extension to the VLIW Architecture'', </title> <booktitle> Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Santa Clara, CA (April 8-11, </address> <year> 1991), </year> <pages> pp. 2-14. </pages>
Reference-contexts: This fuzzy barrier [Gupt89] mechanism allows more flexibility than a VLIW implementation but fails to provide the flexibility found in true MIMD approaches like PIPE and MISC. There are several other designs that attempt to exploit ILP on a MIMD. The XIMD processor <ref> [WoSh91] </ref> adds control logic to each functional unit of a VLIW in order to transform it into a MIMD. However, since it is a VLIW at the core, it requires a high-performance, completely orthogonal, global register file in order to support inter-process communication.
Reference: [Wulf92] <author> W. Wulf, </author> <title> ``Evaluation of the WM Architecture'', </title> <booktitle> Proceedings of the 19th Annual Symposium on Computer Architecture, </booktitle> <volume> vol. 20, no. </volume> <month> 2 (May 19-21, </month> <year> 1992), </year> <pages> pp. 382-390. </pages>
Reference-contexts: This requirement is relaxed with an explicit message passing approach. [Smit84] The greater flexibility found in a decoupled design allows both single and multiple instruction stream descriptions of a task. The ZS-1 [SDVK87, Smit89] and WM <ref> [Wulf92] </ref> systems operate in a decoupled manner while receiving instructions from a single instruction stream. Their architectural component descriptions are similar to those of Split Register superscalar designs [Site93, SCHP92].
Reference: [Youn85] <author> H. C. Young, </author> <title> Evaluation of a Decoupled Computer Architecture and the Design of a Vector Extension, </title> <type> Ph.D Thesis, </type> <institution> University of Wisconsin-Madison, </institution> <month> (July </month> <year> 1985). </year> <month> - 22 </month> - 
Reference-contexts: This pattern of compare and issue is repeated until the comparison produces a match. 5. Related Work There have been several decoupled compilers that have been developed. These include the original PIPE compiler <ref> [Youn85] </ref>, the WM streams compiler [BeDa91], and the compiler for the Briarcliff Multiprocessor [Gupt90]. The PIPE compiler separates code into access and execute instruction streams.
References-found: 33

