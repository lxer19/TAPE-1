URL: http://www.cs.caltech.edu/~arvo/papers/Novins92b.ps.Z
Refering-URL: http://www.cs.caltech.edu/~arvo/papers.html
Root-URL: http://www.cs.caltech.edu
Title: Adaptive Error Bracketing for Controlled-Precision Volume Rendering 1  
Author: Kevin Novins, James Arvo, David Salesin 
Date: November 1992  
Address: Ithaca, New York 14853  
Affiliation: Program of Computer Graphics Cornell University  
Abstract: We present a new ray tracing approach to volume rendering in which the low-albedo volume rendering integral for each ray is efficiently computed to any prescribed accuracy. By bracketing the emission and absorption functions along each ray with adaptively refined step functions, computation is directed toward large sources of error and continued until a desired accuracy is reached. As a result, coarse approximations can be used in regions that are nearly uniform, of low emission, or of low visibility due to absorption by material closer to the eye. Adaptive refinement for each ray is performed using a hierarchical organization of the volume data; at each step, a part of the ray estimated to contribute large error is refined, and the approximate integral is updated incrementally. Our current implementation operates on regularly-spaced data samples combined with trilinear interpolation; however, the concepts described apply to more general data topologies and reconstruction filters.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Larry Bergman, Henry Fuchs, and Eric Grant. </author> <title> Image rendering by adaptive refinement. </title> <journal> Computer Graphics, </journal> <volume> 20(4) </volume> <pages> 29-38, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: Ideally, the effort invested in making a fast but low-quality image could be put to good use when making a highly-accurate rendition of the same image. The idea of progressive refinement is to generate approximate images as intermediate results on the way to the final image <ref> [1] </ref>. The progressive technique of Levoy [8] refines solutions by continually adding rays and interpolating the regions between them. An approach based on adaptive error bracketing would instead refine all rays simultaneously.
Reference: [2] <author> James F. </author> <title> Blinn. Light reflection functions for simulation of clouds and dusty surfaces. </title> <journal> Computer Graphics, </journal> <volume> 16(3) </volume> <pages> 21-29, </pages> <month> July </month> <year> 1982. </year>
Reference-contexts: In volume rendering, the functions ff and * are typically reconstructed from point samples and depend upon the ray. Equations (1) and (2) provide a good approximation for a low-albedo medium <ref> [2] </ref>, and are exact in the absence of scattering [3, 13]. The goal in volume rendering is to solve for I (a; b) at each view ray.
Reference: [3] <author> S. Chandrasekar. </author> <title> Radiative Transfer. </title> <publisher> Dover Publications, </publisher> <address> New York, </address> <year> 1960. </year>
Reference-contexts: an algorithm for bracketing the continuous integrand by upper and lower step functions, and for adaptively refining these functions wherever the error is estimated to be large. 2 Formulation Our algorithm is based on a simple model of volume illumination that was originally developed as a model of radiative transfer <ref> [3, 13] </ref>. The model is physically-based and allows for independent absorption and emission functions throughout a volume. The volume illumination model can be expressed as a set of one-dimensional integrals, with each integral representing the intensity of light emanating 3 from the volume along a single ray. <p> In volume rendering, the functions ff and * are typically reconstructed from point samples and depend upon the ray. Equations (1) and (2) provide a good approximation for a low-albedo medium [2], and are exact in the absence of scattering <ref> [3, 13] </ref>. The goal in volume rendering is to solve for I (a; b) at each view ray. As this integral has no closed-form solution in general, we must resort to numerical approximation; that is, at best we can only compute the solution to within some tolerance ffi.
Reference: [4] <author> H. Fuchs, Z. M. Kedem, and B. F. Nayloy. </author> <title> On visible surface generation by a priori tree structures. </title> <journal> Computer Graphics, </journal> <volume> 14(3) </volume> <pages> 124-133, </pages> <month> July </month> <year> 1980. </year>
Reference-contexts: In our implementation, we use a BSP tree <ref> [4] </ref> instead of an octree. The hierarchical structure is view-independent, and can be built once for each dataset and stored as part of the data.
Reference: [5] <author> David Laur and Pat Hanrahan. </author> <title> Hierarchical splatting: A progressive refinement algorithm for volume rendering. </title> <journal> Computer Graphics, </journal> <volume> 25(4) </volume> <pages> 285-288, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Although empirical estimates of error are given by the authors, it is unclear whether an analytic metric for this projection technique also exists. As an algorithm for approximate volume rendering, the "hierarchical splat-ting" technique of Laur and Hanrahan <ref> [5] </ref> is interesting in that it provides a tunable accuracy control by allowing the coarseness of the data approximation to vary. This control effectively allows for a kind of time-accuracy tradeoff. However, the algorithm does not provide any control over quality in an absolute sense. <p> Estimates e ff and e * are also computed by averaging 11 the respective upper and lower bounds. This process of propagating error bounds through the hierarchical data structure is similar in spirit to the approach outlined by Laur and Hanrahan <ref> [5] </ref>. When a segment is split, the intervals T k and I k for a new segment k are computed from the ff and * values stored in the corresponding node of the BSP tree, according to equations (4) and (5).
Reference: [6] <author> Marc Levoy. </author> <title> Display of surfaces from volume data. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 8(3) </volume> <pages> 29-37, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: The role of projection is to create a two-dimensional image by integrating the reconstructed field in depth. Projection is accomplished in a variety of ways. One approach is to ray trace the image, integrating along each ray from front to back until the accumulated opacity exceeds a given threshold <ref> [6, 7] </ref>. <p> The idea is to start with a single segment representing the complete intersection of the ray with the volume, and then subdivide the segment until the tolerance ffi is reached. Iterative algorithms have been described previously, for example, by Levoy <ref> [6] </ref>, who refines the ray front-to-back until a certain opacity is reached. The advantage of this method is its simplicity, both in implementation and computation. However, the brute force front-to-back approach also has some drawbacks.
Reference: [7] <author> Marc Levoy. </author> <title> Efficient ray tracing of volume data. </title> <journal> Transactions on Graphics, </journal> <volume> 9(3) </volume> <pages> 245-261, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: The role of projection is to create a two-dimensional image by integrating the reconstructed field in depth. Projection is accomplished in a variety of ways. One approach is to ray trace the image, integrating along each ray from front to back until the accumulated opacity exceeds a given threshold <ref> [6, 7] </ref>. <p> Together, these drawbacks mean that the brute force algorithm may sometimes do more work than necessary to evaluate the integral to within a certain tolerance. The first drawback can be addressed by incorporating some notion of hierarchy. For example, in later work, Levoy uses an octree <ref> [7] </ref>, which allows the ray to pass quickly through empty regions of data. The algorithm described here generalizes this idea further by allowing the ray to pass quickly through any region that can be integrated approximately with good error bounds|not just empty regions. <p> In this way, the computation can always be directed toward a region of the ray that is contributing large error to the overall evaluation of the integral. 3.1 Overview As in the octree method described by Levoy <ref> [7] </ref>, we assume a hierarchical organization of the data. In our implementation, we use a BSP tree [4] instead of an octree. The hierarchical structure is view-independent, and can be built once for each dataset and stored as part of the data. <p> This computational cost is only worthwhile if it pays for itself in terms of a sufficient reduction in the overall number of refinement operations. To evaluate this tradeoff, we implemented Levoy's octree method <ref> [7] </ref>, modified to compute error bounds. In this method, the ray is refined front-to-back; thus, selection and update take constant time.
Reference: [8] <author> Marc Levoy. </author> <title> Volume rendering by adaptive refinement. </title> <journal> The Visual Computer, </journal> <volume> 6(1) </volume> <pages> 2-7, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: The idea of progressive refinement is to generate approximate images as intermediate results on the way to the final image [1]. The progressive technique of Levoy <ref> [8] </ref> refines solutions by continually adding rays and interpolating the regions between them. An approach based on adaptive error bracketing would instead refine all rays simultaneously.
Reference: [9] <author> Nelson Max, Pat Hanrahan, and Roger Crawfis. </author> <title> Area and volume coherence for efficient visualization of 3d scalar functions. </title> <journal> Computer Graphics, </journal> <volume> 24(5) </volume> <pages> 27-33, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: Reconstruction describes the process of extending point-sampled data to a continuous three-dimensional scalar field. As an approximation to the ideal but impractical sinc filter, reconstruction is commonly performed using trilinear or Gaussian interpolation. Other approximations include "nearest neighbor" [12] and combinations of bilinear and linear interpolation <ref> [9] </ref>. The role of projection is to create a two-dimensional image by integrating the reconstructed field in depth. Projection is accomplished in a variety of ways.
Reference: [10] <author> Ramon E. Moore. </author> <title> Interval Analysis. </title> <publisher> Prentice-Hall, </publisher> <year> 1966. </year>
Reference-contexts: Let ff k be a (nonnegative) interval [ff k ; ff + k ] such that ff k ff (s) ff + then solve for an interval T k = [T + k ] bracketing the exact transparency T k using standard interval arithmetic <ref> [10] </ref>: T k = e R d k ff k ds Similarly, if we bracket the emission function * within the segment [d k1 ; d k ] by an interval * k = [* k ; * + k ], then it is also possible to solve for I k <p> These intervals are actually three-tuples consisting of minimum, estimated, and maximum contributions. We denote the estimated value of an interval A by e A. When doing arithmetic, the minimum and maximum values are treated as ordinary intervals <ref> [10] </ref>, whereas the estimated values are treated as ordinary scalars.
Reference: [11] <author> Kevin L. Novins and James R. Arvo. </author> <title> A power series algorithm for highly accurate volume rendering. </title> <booktitle> Submitted to the 1992 Boston Workshop on Volume Visualization. </booktitle>
Reference-contexts: This control effectively allows for a kind of time-accuracy tradeoff. However, the algorithm does not provide any control over quality in an absolute sense. Indeed, even the "highest quality" renderings produced by the algorithm contain significant errors due to the inherent inaccuracies 2 of splatting. Novins and Arvo <ref> [11] </ref> explore an approximation to the volume rendering integral that provides absolute bounds on the error due to projection of a single voxel along a ray. <p> The algorithm as described in this paper makes use of an accurate integral evaluation routine, such as the one described by Novins and Arvo <ref> [11] </ref>, to speed convergence. However, any such technique giving accurate error bounds could be used. Moreover, the algorithm can be made to work without using any explicit evaluator; however, convergence is slower. Finally, the algorithm as described here does not address error due to reconstruction. <p> Refinement may be performed in different ways. For example, we may subdivide the segment and combine bounds on the two pieces to obtain a better approximation. Alternatively, we may compute the integral along the segment directly using some kind of quadrature rule, or power series expansion <ref> [11] </ref>. 10 If refinement is done by subdivision, a splitting point must be chosen. In our implementation this point is chosen according to the splitting planes of the BSP tree.
Reference: [12] <author> Paolo Sabella. </author> <title> A rendering algorithm for visualizing 3d scalar fields. </title> <journal> Computer Graphics, </journal> <volume> 22(4) </volume> <pages> 51-57, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Reconstruction describes the process of extending point-sampled data to a continuous three-dimensional scalar field. As an approximation to the ideal but impractical sinc filter, reconstruction is commonly performed using trilinear or Gaussian interpolation. Other approximations include "nearest neighbor" <ref> [12] </ref> and combinations of bilinear and linear interpolation [9]. The role of projection is to create a two-dimensional image by integrating the reconstructed field in depth. Projection is accomplished in a variety of ways. <p> statement that lends itself to efficient computation, and in Section 3 we describe an algorithm for computing its solution. 2.1 Partitioning the integral One way to make the volume rendering problem more tractable is to break up the integral in equation (1) into smaller pieces that are easier to solve <ref> [12, 14] </ref>. To make this transformation, observe first that transparency obeys 4 a simple multiplicative rule. In particular, for any point x in the ray segment [a; b], we have T (a; b) = T (a; x) T (x; b); as is easily verified from equation (2).
Reference: [13] <author> V. V. </author> <title> Sobolev. A Treatise on Radiative Transfer. </title> <address> D. </address> <publisher> Van Nostrand Company, </publisher> <address> Princeton, New Jersey, </address> <year> 1963. </year> <title> Translated by S.I. </title> <journal> Gaposchkin. </journal> <volume> 17 </volume>
Reference-contexts: an algorithm for bracketing the continuous integrand by upper and lower step functions, and for adaptively refining these functions wherever the error is estimated to be large. 2 Formulation Our algorithm is based on a simple model of volume illumination that was originally developed as a model of radiative transfer <ref> [3, 13] </ref>. The model is physically-based and allows for independent absorption and emission functions throughout a volume. The volume illumination model can be expressed as a set of one-dimensional integrals, with each integral representing the intensity of light emanating 3 from the volume along a single ray. <p> In volume rendering, the functions ff and * are typically reconstructed from point samples and depend upon the ray. Equations (1) and (2) provide a good approximation for a low-albedo medium [2], and are exact in the absence of scattering <ref> [3, 13] </ref>. The goal in volume rendering is to solve for I (a; b) at each view ray. As this integral has no closed-form solution in general, we must resort to numerical approximation; that is, at best we can only compute the solution to within some tolerance ffi.
Reference: [14] <author> Craig Upson and Michael Keeler. V-buffer: </author> <title> Visible volume rendering. </title> <journal> Computer Graphics, </journal> <volume> 22(4) </volume> <pages> 59-64, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: statement that lends itself to efficient computation, and in Section 3 we describe an algorithm for computing its solution. 2.1 Partitioning the integral One way to make the volume rendering problem more tractable is to break up the integral in equation (1) into smaller pieces that are easier to solve <ref> [12, 14] </ref>. To make this transformation, observe first that transparency obeys 4 a simple multiplicative rule. In particular, for any point x in the ray segment [a; b], we have T (a; b) = T (a; x) T (x; b); as is easily verified from equation (2).
Reference: [15] <author> Lee Westover. </author> <title> Interactive volume rendering. </title> <booktitle> In Proceedings of the Chapel Hill Workshop on Volume Visualization, </booktitle> <month> May </month> <year> 1989. </year>
Reference-contexts: In this paper, we describe an algorithm that makes use of reliable bounds to give substantial speed-ups for a certain class of volume data and level of approximation. Approximations in volume rendering fall into two categories <ref> [15] </ref>: approximations in reconstruction and approximations in projection. Reconstruction describes the process of extending point-sampled data to a continuous three-dimensional scalar field. As an approximation to the ideal but impractical sinc filter, reconstruction is commonly performed using trilinear or Gaussian interpolation. <p> Other projection methods have been devised to take advantage of special-purpose graphics hardware, thus substantially increasing rendering speed. For example, in "splatting" <ref> [15, 16] </ref>, individual samples are reconstructed and projected in screen space via compositing operations. These operations introduce a number of errors that are difficult to characterize|for example, the errors due to neglecting overlap in depth of the filter kernels.
Reference: [16] <author> Lee Westover. </author> <title> Footprint evaluation for volume rendering. </title> <journal> Computer Graphics, </journal> <volume> 24(4) </volume> <pages> 367-376, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: Other projection methods have been devised to take advantage of special-purpose graphics hardware, thus substantially increasing rendering speed. For example, in "splatting" <ref> [15, 16] </ref>, individual samples are reconstructed and projected in screen space via compositing operations. These operations introduce a number of errors that are difficult to characterize|for example, the errors due to neglecting overlap in depth of the filter kernels.

References-found: 16

