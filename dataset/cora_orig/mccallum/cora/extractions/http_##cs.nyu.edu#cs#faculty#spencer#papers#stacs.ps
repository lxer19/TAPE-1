URL: http://cs.nyu.edu/cs/faculty/spencer/papers/stacs.ps
Refering-URL: http://cs.nyu.edu/cs/faculty/spencer/papers/papers.html
Root-URL: http://www.cs.nyu.edu
Phone: 2  
Title: Random Sparse Bit Strings at the Threshold of Adjacency  
Author: Joel H. Spencer and Katherine St. John 
Address: New York University, New York, NY 10012  Santa Clara, CA 95053-0290  
Affiliation: 1 Courant Institute,  Department of Mathematics, Santa Clara University,  
Note: (Extended Abstract appeared in STACS `98)  
Abstract: 1 Abstract 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Noga Alon, Joel H. Spencer, and Paul Erd-os. </author> <title> The Probabilistic Method. </title> <publisher> John Wiley and Sons, Inc, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: If this set is finite, then it is the (unique) sequence of positive integers a such that U j= a;t . For example, if U j= (2;0);3 , then F t (U ) is the two element structure <ref> [0; 1] </ref> such that d (0) = 2 and d (1) = 0. Just as we wrote the unary structures as bit strings, we can write the models of L 0 t as ordered sequences of f0; : : : ; t 1g. <p> Then, E (X i ) = p (n), and by linearity of expectation, E (X) = i We have E (X) ! 1 as n ! 1. Since all the events are independent, Var [X] E [X]. By the Second Moment Method (see <ref> [1] </ref>, chapter 4 for details), Pr [X = 0] E [X] 2 E [X] 2 = 1 Thus, Pr [X &gt; 0] ! 1. So, almost surely, arbitrarily many 1's occur. <p> So, for any move of Spoiler in such a interval, Duplicator has a winning move. This gives U 1 t U 2 . a Using the Janson Inequalities The Janson Inequalities (see <ref> [1] </ref>, chapter 8 for more details) says that events that are "mostly" independent sometimes have probability "nearly equal" to the truly independent case. We will use these inequalities to give the limiting probability that a sequence of pairs a are the only occuring of length up to t.
Reference: 2. <author> Peter Dolan. </author> <title> A zero-one law for a random subset. Random Structures and Algorithms, </title> <booktitle> 2 </booktitle> <pages> 317-326, </pages> <year> 1991. </year>
Reference-contexts: That is, there exists a constant a such that lim Pr [U n;p j= ] = a (1) Dolan <ref> [2] </ref> showed that for p (n) t n 1 and n 1 t p (n) t n 1=2 for every , a = 0 or 1 in Equation 1. This stronger convergence is called a Zero-One Law for U n;p . <p> By <ref> [2] </ref>, we have that T 1 is a complete theory. We characterize the theories at the threshold of adjacency, namely the S c 's. These, in some sense, lie between T 1 and T 2 . <p> Just as we wrote the unary structures as bit strings, we can write the models of L 0 t as ordered sequences of f0; : : : ; t 1g. So, for our example, we would write <ref> [2; 0] </ref>. We show: Theorem 3 Fix a real, positive constant, c. Let U 1 ; U 2 be models of an almost sure theory S c . <p> For example, if U j= (2;0);3 , then F 3 (U ) can be written as <ref> [2; 0] </ref>. 4 The Results We use several facts and theorems from [12]. First, we can view U as a sequence of models of T 1 , separated by pairs of 1's occurring within t of one another.
Reference: 3. <author> Heinz-Dieter Ebbinghaus and Jorg Flum. </author> <title> Finite Model Theory. </title> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1995. </year>
Reference-contexts: If we let the alphabet of our automata be f0; 1g, then the words in the language are bit strings. First order logic captures exactly the plus free regular languages, while monadic second order logic expresses the regular languages (see [7] and chapter 5 of <ref> [3] </ref>). We discuss the behavior of first order logic over random sparse bit strings and raise some interesting open problems about monadic second order logic in Section 5.
Reference: 4. <author> Ronald Fagin. </author> <title> Generalized first-order spectra and polynomial-time recognizable sets. In Complexity of Computation, </title> <booktitle> SIAM-AMS Proceedings, </booktitle> <pages> pages 43-73, </pages> <year> 1974. </year>
Reference-contexts: Over classes of ordered finite structures, membership in a complexity classes is often equivalent to the ex-pressibility of the desired set in a given logic. For example, Immerman [6] showed that the expressibility in transitive closure logic is equivalent to NLOGSPACE, and Fagin <ref> [4] </ref> proved 1 1 captures NPTIME. The characterizations of logics and the limit probabilities of their sentences over ordered structures could shed light on issues in complexity theory. We focus on the class of ordered structures with a single unary predicate-that is, bit strings.
Reference: 5. <author> Erich Graedel. </author> <title> Subclasses of Presburger arithmetic and the polynomial-time hierarchy. </title> <journal> Theoretical Computer Science, </journal> <volume> 56 </volume> <pages> 289-301, </pages> <year> 1988. </year>
Reference-contexts: What happens to the limit probabilities of sentences over this extended language? Lynch [8] gave sufficient conditions on the unary predicates to be indistinguishable under sentences of quantifier rank less than k, for a fixed k over the natural numbers. Gradel <ref> [5] </ref> linked subclasses of Presburger arithmetic (the first order theory of the model &lt; N; +; &gt;) to the polynomial time hierarchy, and related the truth value of sentences of quantifier rank k to the truth on an initial segment of N whose length is dependent on k.
Reference: 6. <author> Neil Immerman. </author> <title> Expressibility as a complexity measure: results and directions. </title> <booktitle> In Second Structure in Complexity Conference, </booktitle> <pages> pages 194-202. </pages> <publisher> Springer, </publisher> <year> 1987. </year>
Reference-contexts: Over classes of ordered finite structures, membership in a complexity classes is often equivalent to the ex-pressibility of the desired set in a given logic. For example, Immerman <ref> [6] </ref> showed that the expressibility in transitive closure logic is equivalent to NLOGSPACE, and Fagin [4] proved 1 1 captures NPTIME. The characterizations of logics and the limit probabilities of their sentences over ordered structures could shed light on issues in complexity theory.
Reference: 7. <author> Harry R. Lewis and Christos H. Papadimitriou. </author> <title> Elements of the theory of computation. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1981. </year>
Reference-contexts: If we let the alphabet of our automata be f0; 1g, then the words in the language are bit strings. First order logic captures exactly the plus free regular languages, while monadic second order logic expresses the regular languages (see <ref> [7] </ref> and chapter 5 of [3]). We discuss the behavior of first order logic over random sparse bit strings and raise some interesting open problems about monadic second order logic in Section 5.
Reference: 8. <author> James F. Lynch. </author> <title> On sets of relations definable by addition. </title> <journal> Journal of Symbolic Logic, </journal> <volume> 47 </volume> <pages> 659-668, </pages> <year> 1982. </year>
Reference-contexts: What happens to the limit probabilities of sentences over this extended language? Lynch <ref> [8] </ref> gave sufficient conditions on the unary predicates to be indistinguishable under sentences of quantifier rank less than k, for a fixed k over the natural numbers.
Reference: 9. <author> James F. Lynch. </author> <title> Probabilities of sentences about very sparse random graphs. Random Structures and Algorithms, </title> <booktitle> 3 </booktitle> <pages> 33-54, </pages> <year> 1992. </year>
Reference-contexts: Other interesting structures that have also been examined in this fashion are random graphs (without order) with edge probability p (n) = c=n and p (n) = ln n=n + c=n (see the work of Lynch, Spencer, and Thoma: <ref> [9] </ref>, [10], and [13]). For each real constant c, let S c be the almost sure theory of the linear ordering with p (n) = c p n .
Reference: 10. <author> Saharon Shelah and Joel H. Spencer. </author> <title> Can you feel the double jump. Random Structures and Algorithms, </title> <booktitle> 5(1) </booktitle> <pages> 191-204, </pages> <year> 1994. </year>
Reference-contexts: Other interesting structures that have also been examined in this fashion are random graphs (without order) with edge probability p (n) = c=n and p (n) = ln n=n + c=n (see the work of Lynch, Spencer, and Thoma: [9], <ref> [10] </ref>, and [13]). For each real constant c, let S c be the almost sure theory of the linear ordering with p (n) = c p n .
Reference: 11. <author> Saharon Shelah and Joel H. Spencer. </author> <title> Random sparse unary predicates. Random Structures and Algorithms, </title> <booktitle> 5(3) </booktitle> <pages> 375-394, </pages> <year> 1994. </year>
Reference-contexts: For example, if n = 5 and the unary predicate holds only on the least element, we write: [10000]. In <ref> [11] </ref>, Shelah and Spencer showed that for every such sentence and for p (n) t n 1 or n 1=k t p (n) t n 1=(k+1) , there is convergence for the limit probability. <p> Thus, for every possible finite sequence a, S [ a;t j= . So, f (c) is constantly 1, and 2 S c for every c. Therefore, S = T 5 Future Work The work of <ref> [11] </ref> and [12] characterize the almost sure theories and their countable models for p (n) t n 1 and n 1=k t p (n) t n 1=(k+1) for k 1.
Reference: 12. <author> Joel H. Spencer and Katherine St. John. </author> <title> Random unary predicates: Almost sure theories and countable models. </title> <note> Submitted for publication, </note> <year> 1997. </year>
Reference-contexts: Theorem 2 Let S = T c S c be the intersection of all the almost sure theories. Then, for every real, positive c, S c = S. To prove these theorems, we look first at the countable models of the almost sure theories (for more on this, see <ref> [12] </ref>). Let U j= S c be such a model. Each of these models satisfy a set of basic axioms (defined in Section 3). <p> The set of sentences, [ f V r fi r g, axiomatizes T 1 . This follows from an Ehrenfeucht-Fraisse game argument (see <ref> [12] </ref> for more details). For countable models of T 1 , we cannot have a single infinite chain, since all the 1's must be isolated. <p> Since T 2 j= , any model of T 2 begins with an ascending chain of 0's. In fact, each model will begin with a model of T 1 , followed by a level 2 occurrence. Which level 2 occurrence occurs first is not fixed. <ref> [12] </ref> gives more details about the countable models of the almost sure theories T 1 and T 2 . <p> For example, if U j= (2;0);3 , then F 3 (U ) can be written as [2; 0]. 4 The Results We use several facts and theorems from <ref> [12] </ref>. First, we can view U as a sequence of models of T 1 , separated by pairs of 1's occurring within t of one another. That is: Theorem 4 ([12]) Fix a positive integer t and a real positive constant c. Let U j= S c . <p> Thus, for every possible finite sequence a, S [ a;t j= . So, f (c) is constantly 1, and 2 S c for every c. Therefore, S = T 5 Future Work The work of [11] and <ref> [12] </ref> characterize the almost sure theories and their countable models for p (n) t n 1 and n 1=k t p (n) t n 1=(k+1) for k 1.
Reference: 13. <author> Joel H. Spencer and Lubos Thoma. </author> <title> On the limit values of probabilities for the first order properties of graphs. </title> <type> Technical Report 97-35, </type> <institution> DIMACS, </institution> <year> 1997. </year>
Reference-contexts: Other interesting structures that have also been examined in this fashion are random graphs (without order) with edge probability p (n) = c=n and p (n) = ln n=n + c=n (see the work of Lynch, Spencer, and Thoma: [9], [10], and <ref> [13] </ref>). For each real constant c, let S c be the almost sure theory of the linear ordering with p (n) = c p n .
Reference: 14. <author> Katherine St. John. </author> <title> Limit probabilities for random sparse bit strings. </title> <journal> Electronic Journal of Combinatorics, </journal> <volume> 4(1):R23, </volume> <year> 1997. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: This stronger convergence is called a Zero-One Law for U n;p . Dolan also showed that the Zero-One Law does not hold for n 1=k t p (n) t n 1=(k+1) , k &gt; 1. In <ref> [14] </ref>, we examine the random sparse bit strings with probability p (n) = c=n and give a finer analysis than convergence. <p> Therefore, S = T 5 Future Work The work of [11] and [12] characterize the almost sure theories and their countable models for p (n) t n 1 and n 1=k t p (n) t n 1=(k+1) for k 1. In <ref> [14] </ref> and this paper, we fill the "gaps" between these theories by characterizing the almost sure theories of U n; c n and U n; c p n and giving the form of the function f (c) for each first order sentence .
References-found: 14

