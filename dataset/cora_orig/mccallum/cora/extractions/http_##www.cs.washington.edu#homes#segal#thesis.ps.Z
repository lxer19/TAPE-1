URL: http://www.cs.washington.edu/homes/segal/thesis.ps.Z
Refering-URL: http://www.cs.washington.edu/homes/segal/papers.html
Root-URL: http://www.cs.washington.edu
Title: Machine Learning as Massive Search  
Author: by Richard B. Segal 
Degree: A dissertation submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy  Approved by (Chairperson of Supervisory Committee)  
Note: Program Authorized to Offer Degree Date  
Date: 1997  
Affiliation: University of Washington  
Abstract-found: 0
Intro-found: 1
Reference: [Acharya&Tambe 92] <author> Acharya, A. and Tambe, M. </author> <title> Collection-oriented match: Scaling up the data in production systems. </title> <type> Technical Report CMU-CS-92-218, </type> <institution> Carnegie Mellon University, </institution> <year> 1992. </year>
Reference-contexts: The total number of tuples matching a rule can be easily computed using standard matching algorithms when all variables are bound during the matching process. Any variables not bound can be efficiently maintained using collection-oriented match <ref> [Acharya&Tambe 92] </ref>. However, the advantages of this approach have yet to be tested empirically.
Reference: [Agrawal et al. 93] <author> Agrawal, R., Imielinski, T., and Swami, A. </author> <title> Mining associations between sets of items in massive databases. </title> <booktitle> In ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 207-216, </pages> <address> Washington, DC, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: This approach requires the user to provide knowledge that may not be easily available and eliminates the possibility of learning previously unknown correlations. The ideal approach is to learn correlations directly from the training data. However, learning correlations is a difficult problem in its own right <ref> [Agrawal et al. 93] </ref> and beyond the scope of this thesis. Instead, Brute uses a heuristic approach that significantly reduces the number of correlated rules. 111 Brute's approach is to identify correlated rules and to return only the best rule from each correlated set. <p> The J-measure does not include a complexity term and is likely to have difficulties with oversearching. While ITRule predates Brute, the two algorithms were developed independently. Apriori <ref> [Agrawal et al. 93] </ref> also learns association rules but allows arbitrary conjunctions to appear in the consequent. Apriori returns all association rules meeting user-provided thresholds on accuracy and coverage. All associations are learned in 123 a two-step process.
Reference: [Agrawal et al. 96] <author> Agrawal, R., Mannila, H., Srikant, R., Toivonen, H., and Verkamo, A. I. </author> <title> Fast discovery of association rules. </title> <booktitle> In Advances in Knowledge Discovery and Data Mining, </booktitle> <pages> pages 307-328. </pages> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1996. </year>
Reference-contexts: Partitioning and sorting techniques were first used in ID3 [Quinlan 86] and have recently been extended in Apriori <ref> [Agrawal et al. 96] </ref>. We present them here to compare them with bit-vectors. Partitioning and sorting are also useful for analyzing Brute's complexity. Partitioning algorithms evaluate all tests for each discrete attribute using a single pass through the example set. <p> ITRule uses best-first search with branch-and-bound pruning to find the rule that maximizes an information-theoretic evaluation function. Brute improves on ITRule by making massive search more efficient. Apriori <ref> [Agrawal et al. 96] </ref> is another recent massive-search algorithm for learning association rules. Association rules are an extension of if-then rules that allow consequents to be arbitrary conjunctions. Apriori's algorithm first finds all rules with a minimum data coverage and then uses the search results to find association rules. <p> Brute reduces the cost of rule evaluation by representing examples using bitvectors. Bit-vectors improve the typical linear encoding by allowing thirty-two examples to be processed simultaneously using the low-level bitwise-and operation available on most machines. While partitioning and sorting techniques reduce the algorithmic complexity of rule evaluation <ref> [Quinlan 86, Agrawal et al. 96] </ref>, their large execution constants result in bit-vectors having a fifteen-fold advantage on many databases. As a result of Brute's pruning techniques and fast rule-evaluation algorithm, Brute can completely search all of our benchmark databases in less than two minutes. <p> However, Brute's assumption that all training data can fit in main memory implicitly limits the database sizes it can handle. Redesigning Brute to handle databases larger than main memory is difficult. Apriori <ref> [Agrawal et al. 96] </ref> handles large databases by leaving the database on disk and evaluating all rules at a given depth using a single scan of the database. The number of times Apriori reads the entire database from disk grows linearly with the maximum rule length.
Reference: [Blumer et al. 87] <author> Blumer, A., Ehrenfeucht, A., Haussler, D., and Warmuth, M. </author> <title> Oc-cam's razor. </title> <journal> Information Processing Letters, </journal> <volume> 24 </volume> <pages> 377-380, </pages> <year> 1987. </year>
Reference: [Breiman et al. 84] <author> Breiman, L., Friedman, J. H., Olshen, R. A., and Stone, C. J. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <year> 1984. </year>
Reference-contexts: Instead, we evaluate performance on the Boeing database using both accuracy and rule coverage. We will consider an algorithm better than another if it simultaneously learns both more accurate and higher-coverage rules. 5.3 Existing Solutions 5.3.1 Decision Trees Data mining is often performed using decision-tree algorithms such as CART <ref> [Breiman et al. 84] </ref> and C4.5 [Quinlan 93]. Decision-tree algorithms were not designed for data mining but for learning classifiers. Classifiers are functions that predict the goal attribute's value from the values of the remaining attributes. A decision tree is a tree-structured classifier. <p> The foremost problem is that the test-selection functions used for tree building can prevent finding the best rules. Classical test-selection functions, such as information gain [Quinlan 86] or the Gini Index <ref> [Breiman et al. 84] </ref>, have the following form: max i j 99 If material = X ^ batch = C then tag = reject ; (4x as likely ); If material 6= X ^ day = Friday ^ hour &gt; 12 then tag = reject ; (3x as likely ); If <p> This function evaluates each test by averaging the purity of each branch, weighted by the number of examples filtered to each branch. Although the exact measure of purity varies from one algorithm to another, standard measures exhibit similar behavior in practice <ref> [Breiman et al. 84, Mingers 89] </ref>. Test-selection functions that compute a weighted average across branches can cause decision-tree algorithms to overlook the best rules. These functions prefer splits that achieve good performance in each branch over splits that generate better performance on a single branch. <p> Gold-digger reduces overfitting in a different manner than Brute. Instead of learning with Laplace-depth, Gold-digger learns with Laplace accuracy and adds a postpruning phase that limits rule complexity. Gold-digger's postpruning phase is very similar to the tree-pruning technique used by CART <ref> [Breiman et al. 84] </ref>. The training data is randomly partitioned, 70% for learning and 30% for pruning. Rule learning proceeds as normal on the learning data. Postpruning re-evaluates the learned rule and searches for the subset of the rule's antecedent which is likely to have the best inductive performance.
Reference: [Clark&Boswell 91] <author> Clark, P. and Boswell, R. </author> <title> Rule induction with CN2: some recent improvements. </title> <booktitle> In Machine Learning - EWSL-91. Proceedings of the European Working Session on Learning., </booktitle> <pages> pages 151-163, </pages> <address> Porto, Portugal, </address> <month> March </month> <year> 1991. </year>
Reference-contexts: The goal predicate expresses the user's desire to extract information about when tennis is chosen. 2.3 Existing Solutions Since the machine-learning community has not focused on the rule-learning problem, there is no algorithm specifically designed for rule learning. However, many classification algorithms including AQ [Michalski 69], CN2 <ref> [Clark&Boswell 91] </ref>, FOIL [Quin-lan 90], Greedy3 [Pagallo&Haussler 90], RIPPER [Cohen 95] and RL [Provost et al. 93] make use of a rule-learning algorithm as a component. In this section we investigate the rule-learning components of these algorithms and discuss their limitations. The rule-learning components of these systems have several similarities. <p> Given these two assumptions, we can compute the posterior distribution on rule accuracies after seeing the data. The mean of this posterior distribution serves as a good estimate for rule accuracy. This estimate is known as Laplace accuracy and has been used in several learning algorithms <ref> [Niblett 87, Clark&Boswell 91, Smyth&Goodman 91, Webb 93] </ref>. Laplace accuracy can be calculated using the following formula: L (r) = jE (r)j + 2 See Niblett [1987] for a derivation. Laplace accuracy has the desirable property of taking into account both accuracy and coverage when estimating rule accuracy. <p> How well this improvement in estimated accuracy transfers to improvements in true accuracy is the topic of Chapter 4. 2.3.3 Real Systems Greedy3 [Pagallo&Haussler 90] and RIPPER [Cohen 95] use the greedy-search algorithm presented in the previous section. AQ [Michalski 69], CN2 <ref> [Clark&Boswell 91] </ref> and RL [Provost et al. 93] use an extension of the basic greedy-search algorithm called beam search. 1 A beam search maintains a list of the B best rules at each stage of its execution. <p> Table 3.1 lists common evaluation functions and displays their rationality and depth monotonicity. The table includes Laplace accuracy <ref> [Clark&Boswell 91] </ref>, mutual 38 information [Clark&Niblett 89], minimum description length [Quinlan&Rivest 89], and cost matrices [Pazzani et al. 94]. All of these functions are rational and depth monotone above some threshold. <p> This section proposes a greedy algorithm called Gold-digger [Riddle et al. 94], which was specifically designed for data mining. Although developed independently, Gold-digger shares structure with a variety of decision-list learning algorithms including AQ [Michalski 69], Greedy3 [Pa-gallo&Haussler 90], and CN2 <ref> [Clark&Boswell 91] </ref>. Gold-digger combines a greedy rule-learning algorithm with a covering algorithm for learning multiple rules. Gold-digger's rule-learning algorithm is the greedy rule-learning algorithm presented in Chapter 2 extended to reduce overfitting. Gold-digger reduces overfitting in a different manner than Brute. <p> CN2 uses an information-theoretic variant of Brute's trivial-specialization filter to avoid learning overly-complex rules, but not for reducing redundancy. Since CN2 prunes subtrees of rules failing its trivial-specialization filter, it cannot learn rules that require adding non-informative conjuncts. Later versions of CN2 <ref> [Clark&Boswell 91] </ref> replaced information gain with Laplace accuracy but continued using the specialization filter. 125 5.6 Summary The key difference between rule learning and data mining is data mining's requirement for learning multiple rules. <p> While most algorithms use the same covering algorithm, each uses a slightly different rule-learning component: AQ [Michalski 69] uses a beam search for 100%-accurate rules that cover a seed positive example and exclude a seed negative example, Greedy3 [Pagallo&Haussler 90] uses a greedy search for 100%-accurate rules, and CN2 <ref> [Clark&Boswell 91] </ref> uses a beam search for the rule that maximizes Laplace accuracy. Some of the algorithms add a postpruning step to reduce overfitting. inner loop. The final decision list is passed through a postpruning filter to improve inductive performance. <p> The performance of each algorithm was determined on fifty random splits of each database into 50% training data and 50% test data. 1 Brute-greedy does not include CN2's significance test which was shown empirically to reduce CN2's inductive performance <ref> [Clark&Boswell 91] </ref>. 128 FUNCTION LearnDecisionList (Tests, Database):RULESET TrainData = Database DecisionList = ; REPEAT Rule = LearnRule (Tests, TrainData) AppendRule (DecisionList, Rule) TrainData = TrainData - MatchedExamples (Rule, TrainData) UNTIL Positives (TrainData) = ; OR Rule = EmptyRule (Goal) AddDefaultRule (DecisionList, TrainData) PruneDecisionList (DecisionList) RETURN DecisionList END are instantiations of this <p> The basic ideas behind BruteDL apply equally well to heuristic search. 6.3 Related Work Brute-greedy descends from the AQ line of inductive algorithms that include AQ [Michalski 69], Greedy3 [Pagallo&Haussler 90], and CN2 <ref> [Clark&Niblett 89, Clark&Boswell 91] </ref>. These algorithms share Brute-greedy's iterative structure but use either a greedy or beam search to find the best rule. While Cover [Webb 93] extends CN2 to use massive search, it fails to improve performance because it lacks Brute-greedy's preference for short rules.
Reference: [Clark&Niblett 89] <author> Clark, P. and Niblett, T. </author> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3(4) </volume> <pages> 261-284, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: Rule learning is ideal for investigating massive search for two reasons. First, since the search space for rule learning grows singly exponentially, it is more amenable to massive search but is still challenging enough that most rule-learning algorithms use greedy or beam search to minimize costs <ref> [Michalski 69, Pagallo&Haussler 90, Clark&Niblett 89, Provost et al. 93] </ref>. Second, rule learning is an important subproblem of many other learning tasks. <p> Second, rule learning is an important subproblem of many other learning tasks. Many classification algorithms including AQ [Michalski 69], Greedy3 [Pagallo&Haussler 90], and 1 While direct search is prohibitively expensive, Chapter 6 shows that concept-learning algorithms can still benefit from massive search. 3 CN2 <ref> [Clark&Niblett 89] </ref> use a rule-learning component in its inner loop. Rule learning is also the primary task in many data-mining applications [Riddle et al. 94, Agrawal et al. 96, Provost et al. 93]. We evaluate massive search by designing and implementing a massive-search algorithm for rule learning. <p> By replacing the greedy rule-learning component in one of these algorithms with our massive-search algorithm, we can learn better classifiers. Chapter 6 demonstrates that replacing the rule-learning component of CN2 <ref> [Clark&Niblett 89] </ref> with massive search improves CN2's inductive performance. The availability of massive search makes it possible to consider alternative control structures for learning classifiers. <p> Many of the common evaluation functions for rule learning, including Laplace accuracy [Clark& Boswell 91], mutual information <ref> [Clark&Niblett 89] </ref> and minimum description length [Quinlan&Rivest 89], are all rational for accuracies above a threshold. These functions should not be used for learning rules below their rationality threshold. 1 Rationality, while capturing the notion of an appropriate evaluation function, is also useful in computing upper bounds. <p> Table 3.1 lists common evaluation functions and displays their rationality and depth monotonicity. The table includes Laplace accuracy [Clark&Boswell 91], mutual 38 information <ref> [Clark&Niblett 89] </ref>, minimum description length [Quinlan&Rivest 89], and cost matrices [Pazzani et al. 94]. All of these functions are rational and depth monotone above some threshold. <p> The basic ideas behind BruteDL apply equally well to heuristic search. 6.3 Related Work Brute-greedy descends from the AQ line of inductive algorithms that include AQ [Michalski 69], Greedy3 [Pagallo&Haussler 90], and CN2 <ref> [Clark&Niblett 89, Clark&Boswell 91] </ref>. These algorithms share Brute-greedy's iterative structure but use either a greedy or beam search to find the best rule. While Cover [Webb 93] extends CN2 to use massive search, it fails to improve performance because it lacks Brute-greedy's preference for short rules.
Reference: [Cohen 95] <author> Cohen, W. W. </author> <title> Fast effective rule induction. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <address> Lake Tahoe, CA, </address> <year> 1995. </year>
Reference-contexts: However, many classification algorithms including AQ [Michalski 69], CN2 [Clark&Boswell 91], FOIL [Quin-lan 90], Greedy3 [Pagallo&Haussler 90], RIPPER <ref> [Cohen 95] </ref> and RL [Provost et al. 93] make use of a rule-learning algorithm as a component. In this section we investigate the rule-learning components of these algorithms and discuss their limitations. The rule-learning components of these systems have several similarities. <p> The results above only show that exhaustive search finds rules with substantially higher estimated accuracies. How well this improvement in estimated accuracy transfers to improvements in true accuracy is the topic of Chapter 4. 2.3.3 Real Systems Greedy3 [Pagallo&Haussler 90] and RIPPER <ref> [Cohen 95] </ref> use the greedy-search algorithm presented in the previous section. <p> Brute-greedy's limitations appear to be the result of its covering algorithm and may benefit from newer covering methods <ref> [Cohen 95] </ref>. BruteDL, being a newer algorithm, has many avenues for possible improvement. The first step to improve BruteDL is gaining a better understanding of the relationship between its underlying theory and the approximations used in its implementation.
Reference: [Cormen et al. 90] <author> Cormen, T. H., Leiserson, C. E., and Rivest, R. L. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: This is substantially smaller than the 2 jT j rules required by simple enumeration and is what makes greedy search efficient. Greedy search, even though it does not explore the entire search space, produces optimal results for many search problems <ref> [Cormen et al. 90] </ref>. Whether greedy search will produce optimal solutions for rule learning depends on the structure of the optimization problem. Unfortunately, the structure of the rule-learning search space prevents greedy search from being optimal. <p> The complexity of evaluating all tests for a numerical attribute A i using a standard comparison sort is O (M log M ). We can improve the complexity to O (N ) by using a counting sort <ref> [Cormen et al. 90] </ref>. Counting sorts are almost always faster than a comparison sort for rule evaluation because M is usually a large fraction of N .
Reference: [Feelders&Verkooijen 95] <author> Feelders, A. and Verkooijen, W. </author> <booktitle> Which method learns the most from data? In Preliminary papers of the Fifth International Workshop on Artificial Intelligence and Statistics, </booktitle> <pages> pages 219-225, </pages> <month> January </month> <year> 1995. </year> <month> 161 </month>
Reference-contexts: The next step is to develop better methods for detecting homogeneity. The current method is computationally expensive and does not properly account for multiple 157 applications of its O 2 test. Simply correcting the threshold used for the O 2 test using Bonferroni adjustments <ref> [Feelders&Verkooijen 95] </ref> is likely to misjudge homogeneous rules because the accuracy of a rule's specializations is not independent. Sampling techniques are an interesting alternative because they may eliminate the independence problem while simultaneously reducing computational costs.
Reference: [Good 65] <author> Good, I. J. </author> <title> The Estimation of Probabilities: An Essay on Modern Bayesian Methods. Research monograph 30. </title> <publisher> MIT Press, </publisher> <year> 1965. </year>
Reference-contexts: While this function has not been used extensively in the machine-learning literature, we believe this modified form of Laplace accuracy is a better function because it correctly handles rules with less than 50% accuracy. This function is commonly used in the statistical literature <ref> [Good 65, Smyth&Goodman 91] </ref>. Most of the results presented in this thesis are not dependent on the choice of estimation function. Some sections do assume that the estimation function is rational over the range of interest.
Reference: [Korf 85] <author> Korf, R. E. </author> <title> Depth-first iterative-deepening: an optimal admissible tree search. </title> <journal> Artificial Intelligence, </journal> <volume> 27(1) </volume> <pages> 97-109, </pages> <year> 1985. </year>
Reference-contexts: The performance of Brute is not significantly degraded by using heuristically-guided search while significantly improving Brute's memory requirements. Another possibility for Brute's search algorithm is a linear-space best-first search algorithm. One such algorithm, iterative deepening <ref> [Korf 85] </ref>, implements best-first search by making multiple calls to a depth-first search engine. The number of calls grows linearly with the number of possible rule scores. Since the number of possible rule scores grows quadratically with the number of examples, iterative deepening is prohibitively expensive.
Reference: [Korf 92] <author> Korf, R. </author> <title> Linear-space best-first search: Summary of results. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 533-538, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: The number of calls grows linearly with the number of possible rule scores. Since the number of possible rule scores grows quadratically with the number of examples, iterative deepening is prohibitively expensive. RBFS <ref> [Korf 92] </ref> is an improved linear-space best-first search algorithm that requires fewer iterations over the search space. A unique aspect of RBFS is that it only backtracks and evaluates a rule multiple times if the depth-first path it has chosen is non-optimal.
Reference: [Lin 95] <author> Lin, J. </author> <title> A comparative study of default strategies for a decision list learner. </title> <type> Master's thesis, </type> <institution> Vanderbilt University, Nashville, Tennessee, </institution> <month> December </month> <year> 1995. </year>
Reference: [Michalski 69] <author> Michalski, R. S. </author> <title> On the quasi-minimal solution of the general covering problem. </title> <booktitle> In Proceedings of the Fifth International Symposium on Information Processing, </booktitle> <pages> pages 125-128, </pages> <address> Bled, Yugoslavia, </address> <year> 1969. </year>
Reference-contexts: Rule learning is ideal for investigating massive search for two reasons. First, since the search space for rule learning grows singly exponentially, it is more amenable to massive search but is still challenging enough that most rule-learning algorithms use greedy or beam search to minimize costs <ref> [Michalski 69, Pagallo&Haussler 90, Clark&Niblett 89, Provost et al. 93] </ref>. Second, rule learning is an important subproblem of many other learning tasks. <p> Second, rule learning is an important subproblem of many other learning tasks. Many classification algorithms including AQ <ref> [Michalski 69] </ref>, Greedy3 [Pagallo&Haussler 90], and 1 While direct search is prohibitively expensive, Chapter 6 shows that concept-learning algorithms can still benefit from massive search. 3 CN2 [Clark&Niblett 89] use a rule-learning component in its inner loop. <p> The goal predicate expresses the user's desire to extract information about when tennis is chosen. 2.3 Existing Solutions Since the machine-learning community has not focused on the rule-learning problem, there is no algorithm specifically designed for rule learning. However, many classification algorithms including AQ <ref> [Michalski 69] </ref>, CN2 [Clark&Boswell 91], FOIL [Quin-lan 90], Greedy3 [Pagallo&Haussler 90], RIPPER [Cohen 95] and RL [Provost et al. 93] make use of a rule-learning algorithm as a component. In this section we investigate the rule-learning components of these algorithms and discuss their limitations. <p> How well this improvement in estimated accuracy transfers to improvements in true accuracy is the topic of Chapter 4. 2.3.3 Real Systems Greedy3 [Pagallo&Haussler 90] and RIPPER [Cohen 95] use the greedy-search algorithm presented in the previous section. AQ <ref> [Michalski 69] </ref>, CN2 [Clark&Boswell 91] and RL [Provost et al. 93] use an extension of the basic greedy-search algorithm called beam search. 1 A beam search maintains a list of the B best rules at each stage of its execution. <p> This section proposes a greedy algorithm called Gold-digger [Riddle et al. 94], which was specifically designed for data mining. Although developed independently, Gold-digger shares structure with a variety of decision-list learning algorithms including AQ <ref> [Michalski 69] </ref>, Greedy3 [Pa-gallo&Haussler 90], and CN2 [Clark&Boswell 91]. Gold-digger combines a greedy rule-learning algorithm with a covering algorithm for learning multiple rules. Gold-digger's rule-learning algorithm is the greedy rule-learning algorithm presented in Chapter 2 extended to reduce overfitting. Gold-digger reduces overfitting in a different manner than Brute. <p> While the algorithm has been extended to learn multiple rules using a greedy covering algorithm [Webb 93], this extension has the same inability to learn overlapping rules that plagues Gold-digger. Gold-digger is similar to several algorithms for learning decision lists including AQ, Greedy3, and CN2. AQ <ref> [Michalski 69] </ref> was the first to employ Gold-digger's covering algorithm but used a different rule-learning strategy. AQ performs a beam search for 100% accurate rules but biases its search using a randomly chosen positive and negative example that must be correctly classified by every conjunct added. <p> Most algorithms combine a rule-learning component with a greedy covering algorithm. While most algorithms use the same covering algorithm, each uses a slightly different rule-learning component: AQ <ref> [Michalski 69] </ref> uses a beam search for 100%-accurate rules that cover a seed positive example and exclude a seed negative example, Greedy3 [Pagallo&Haussler 90] uses a greedy search for 100%-accurate rules, and CN2 [Clark&Boswell 91] uses a beam search for the rule that maximizes Laplace accuracy. <p> Heuristic search techniques (e.g., beam search) can be used when a pure depth-bounded search to the desired depth is too costly. The basic ideas behind BruteDL apply equally well to heuristic search. 6.3 Related Work Brute-greedy descends from the AQ line of inductive algorithms that include AQ <ref> [Michalski 69] </ref>, Greedy3 [Pagallo&Haussler 90], and CN2 [Clark&Niblett 89, Clark&Boswell 91]. These algorithms share Brute-greedy's iterative structure but use either a greedy or beam search to find the best rule.
Reference: [Mingers 89] <author> Mingers, J. </author> <title> An empirical comparison of selection measures for decision-tree induction. </title> <journal> Machine Learning, </journal> <volume> 3(4) </volume> <pages> 319-342, </pages> <year> 1989. </year>
Reference-contexts: This function evaluates each test by averaging the purity of each branch, weighted by the number of examples filtered to each branch. Although the exact measure of purity varies from one algorithm to another, standard measures exhibit similar behavior in practice <ref> [Breiman et al. 84, Mingers 89] </ref>. Test-selection functions that compute a weighted average across branches can cause decision-tree algorithms to overlook the best rules. These functions prefer splits that achieve good performance in each branch over splits that generate better performance on a single branch.
Reference: [Mitchell 82] <author> Mitchell, T. </author> <title> Generalization as search. </title> <journal> Artificial Intelligence, </journal> <volume> 18 </volume> <pages> 203-226, </pages> <month> March </month> <year> 1982. </year>
Reference: [Murphy 94] <author> Murphy, P. M. </author> <title> UCI repository of machine learning databases. [Machine-readable data repository]. </title> <address> Irvine, CA. </address> <institution> University of California, Department of Information and Computer Science., </institution> <year> 1994. </year>
Reference-contexts: We can answer these questions by analyzing the performance of greedy algorithms on benchmark databases and comparing the rules learned to the best possible rules. Table 2.2 presents several benchmark databases from the UCI Machine Learning Data Repository <ref> [Murphy 94] </ref> that will be used throughout this thesis for analyzing learning algorithms. Table 2.3 shows the results of running greedy search on the benchmark databases. The table shows the Laplace accuracy of the highest-scoring rule as well as the Laplace accuracy of the rules learned by greedy search.
Reference: [Murphy&Pazzani 94] <author> Murphy, P. M. and Pazzani, M. J. </author> <title> Exploring the decision forest: An empirical investigation of Occam's razor in decision tree induction. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1 </volume> <pages> 257-275, </pages> <year> 1994. </year>
Reference: [Niblett 87] <author> Niblett, T. </author> <title> Constructing decision trees in noisy domains. </title> <booktitle> In Progress in Machine Learning (Proceedings of the 2nd European Working Session on Learning), </booktitle> <pages> pages 67-78, </pages> <address> Wilmslow, UK, </address> <year> 1987. </year>
Reference-contexts: Given these two assumptions, we can compute the posterior distribution on rule accuracies after seeing the data. The mean of this posterior distribution serves as a good estimate for rule accuracy. This estimate is known as Laplace accuracy and has been used in several learning algorithms <ref> [Niblett 87, Clark&Boswell 91, Smyth&Goodman 91, Webb 93] </ref>. Laplace accuracy can be calculated using the following formula: L (r) = jE (r)j + 2 See Niblett [1987] for a derivation. Laplace accuracy has the desirable property of taking into account both accuracy and coverage when estimating rule accuracy.
Reference: [Pagallo&Haussler 90] <author> Pagallo, G. and Haussler, D. </author> <title> Boolean feature discovery in empirical learning. </title> <journal> Machine Learning, </journal> <volume> 5(1) </volume> <pages> 71-100, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: Rule learning is ideal for investigating massive search for two reasons. First, since the search space for rule learning grows singly exponentially, it is more amenable to massive search but is still challenging enough that most rule-learning algorithms use greedy or beam search to minimize costs <ref> [Michalski 69, Pagallo&Haussler 90, Clark&Niblett 89, Provost et al. 93] </ref>. Second, rule learning is an important subproblem of many other learning tasks. <p> Second, rule learning is an important subproblem of many other learning tasks. Many classification algorithms including AQ [Michalski 69], Greedy3 <ref> [Pagallo&Haussler 90] </ref>, and 1 While direct search is prohibitively expensive, Chapter 6 shows that concept-learning algorithms can still benefit from massive search. 3 CN2 [Clark&Niblett 89] use a rule-learning component in its inner loop. <p> However, many classification algorithms including AQ [Michalski 69], CN2 [Clark&Boswell 91], FOIL [Quin-lan 90], Greedy3 <ref> [Pagallo&Haussler 90] </ref>, RIPPER [Cohen 95] and RL [Provost et al. 93] make use of a rule-learning algorithm as a component. In this section we investigate the rule-learning components of these algorithms and discuss their limitations. The rule-learning components of these systems have several similarities. <p> For the rules to be better, they must have higher accuracy. The results above only show that exhaustive search finds rules with substantially higher estimated accuracies. How well this improvement in estimated accuracy transfers to improvements in true accuracy is the topic of Chapter 4. 2.3.3 Real Systems Greedy3 <ref> [Pagallo&Haussler 90] </ref> and RIPPER [Cohen 95] use the greedy-search algorithm presented in the previous section. <p> Most algorithms combine a rule-learning component with a greedy covering algorithm. While most algorithms use the same covering algorithm, each uses a slightly different rule-learning component: AQ [Michalski 69] uses a beam search for 100%-accurate rules that cover a seed positive example and exclude a seed negative example, Greedy3 <ref> [Pagallo&Haussler 90] </ref> uses a greedy search for 100%-accurate rules, and CN2 [Clark&Boswell 91] uses a beam search for the rule that maximizes Laplace accuracy. Some of the algorithms add a postpruning step to reduce overfitting. inner loop. <p> The basic ideas behind BruteDL apply equally well to heuristic search. 6.3 Related Work Brute-greedy descends from the AQ line of inductive algorithms that include AQ [Michalski 69], Greedy3 <ref> [Pagallo&Haussler 90] </ref>, and CN2 [Clark&Niblett 89, Clark&Boswell 91]. These algorithms share Brute-greedy's iterative structure but use either a greedy or beam search to find the best rule. While Cover [Webb 93] extends CN2 to use massive search, it fails to improve performance because it lacks Brute-greedy's preference for short rules.
Reference: [Pazzani et al. 94] <author> Pazzani, M. J., Merz, C., Murphy, P., Ali, K., Hume, T., and Brunk, C. </author> <title> Reducing misclassification costs. </title> <booktitle> In Proceedings of the 11th International Conference on Machine Learning, </booktitle> <pages> pages 217-225. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1994. </year> <month> 162 </month>
Reference-contexts: Table 3.1 lists common evaluation functions and displays their rationality and depth monotonicity. The table includes Laplace accuracy [Clark&Boswell 91], mutual 38 information [Clark&Niblett 89], minimum description length [Quinlan&Rivest 89], and cost matrices <ref> [Pazzani et al. 94] </ref>. All of these functions are rational and depth monotone above some threshold. Rather than try to compute an upper bound for each function separately, we compute an upper bound that applies to all evaluation functions that are both rational and depth monotone.
Reference: [Provost et al. 93] <author> Provost, F. J., Buchanan, B. G., Clearwater, S. H., and Lee, Y. </author> <title> Machine learning in the service of exploratory science and engineering: A case study of the RL induction program. </title> <type> Technical Report ISL-93-6, </type> <institution> Intelligent Systems Laboratory, Computer Science Department, University of Pittsburgh, </institution> <address> Pittsburgh, PA, </address> <year> 1993. </year>
Reference-contexts: Rule learning is ideal for investigating massive search for two reasons. First, since the search space for rule learning grows singly exponentially, it is more amenable to massive search but is still challenging enough that most rule-learning algorithms use greedy or beam search to minimize costs <ref> [Michalski 69, Pagallo&Haussler 90, Clark&Niblett 89, Provost et al. 93] </ref>. Second, rule learning is an important subproblem of many other learning tasks. <p> However, many classification algorithms including AQ [Michalski 69], CN2 [Clark&Boswell 91], FOIL [Quin-lan 90], Greedy3 [Pagallo&Haussler 90], RIPPER [Cohen 95] and RL <ref> [Provost et al. 93] </ref> make use of a rule-learning algorithm as a component. In this section we investigate the rule-learning components of these algorithms and discuss their limitations. The rule-learning components of these systems have several similarities. <p> How well this improvement in estimated accuracy transfers to improvements in true accuracy is the topic of Chapter 4. 2.3.3 Real Systems Greedy3 [Pagallo&Haussler 90] and RIPPER [Cohen 95] use the greedy-search algorithm presented in the previous section. AQ [Michalski 69], CN2 [Clark&Boswell 91] and RL <ref> [Provost et al. 93] </ref> use an extension of the basic greedy-search algorithm called beam search. 1 A beam search maintains a list of the B best rules at each stage of its execution. <p> Second, it decides what differences are interesting using a fixed constant rather than statistical significance. This causes Apriori to judge some similar rules as distinct and some differing rules as similar. Apriori does not avoid trivial specializations or correlations. 124 RL <ref> [Provost et al. 93] </ref> also applies extensive search to data mining but uses a beam search to ensure tractability. Similar to Apriori, RL returns all rules which meet user-set thresholds on positive and negative coverage. RL does not include any mechanisms to avoid redundant rules.
Reference: [Provost&Hennessy 96] <author> Provost, F. J. and Hennessy, D. N. </author> <title> Scaling up: Distributed machine learning with cooperation. </title> <booktitle> In Proceedings of the 1996 Workshop on Integrating Multiple Learned Models, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1996. </year>
Reference: [Quinlan 86] <author> Quinlan, J. R. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: Partitioning and sorting techniques were first used in ID3 <ref> [Quinlan 86] </ref> and have recently been extended in Apriori [Agrawal et al. 96]. We present them here to compare them with bit-vectors. Partitioning and sorting are also useful for analyzing Brute's complexity. Partitioning algorithms evaluate all tests for each discrete attribute using a single pass through the example set. <p> This occurs in only 1 of 279 discrete attributes in our database sample. The advantage of bit-vectors is greatest for binary attributes (V = 2) where it outperforms partitioning by a factor of seven. While partitioning cannot be applied to numerical attributes, similar results can be achieved by sorting <ref> [Quinlan 86] </ref>. With a sorted example set, we can estimate the accuracy for all tests by scanning the sorted array and counting the number of positive and negative examples that appear before each unique value v. <p> The decision-tree approach to data mining has several problems because decision-tree algorithms were not originally designed for data mining. The foremost problem is that the test-selection functions used for tree building can prevent finding the best rules. Classical test-selection functions, such as information gain <ref> [Quinlan 86] </ref> or the Gini Index [Breiman et al. 84], have the following form: max i j 99 If material = X ^ batch = C then tag = reject ; (4x as likely ); If material 6= X ^ day = Friday ^ hour &gt; 12 then tag = reject <p> Brute reduces the cost of rule evaluation by representing examples using bitvectors. Bit-vectors improve the typical linear encoding by allowing thirty-two examples to be processed simultaneously using the low-level bitwise-and operation available on most machines. While partitioning and sorting techniques reduce the algorithmic complexity of rule evaluation <ref> [Quinlan 86, Agrawal et al. 96] </ref>, their large execution constants result in bit-vectors having a fifteen-fold advantage on many databases. As a result of Brute's pruning techniques and fast rule-evaluation algorithm, Brute can completely search all of our benchmark databases in less than two minutes.
Reference: [Quinlan 87] <author> Quinlan, J. R. </author> <title> Generating production rules from decision trees. </title> <booktitle> In Proceedings of IJCAI-87, </booktitle> <pages> pages 304-307, </pages> <year> 1987. </year>
Reference: [Quinlan 90] <author> Quinlan, J. R. </author> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 239-266, </pages> <year> 1990. </year>
Reference-contexts: A beam search improves on greedy search by giving the learning system B more chances to find the highest-scoring rule. Beam search is practical because the added search complexity grows linearly with B. FOIL <ref> [Quinlan 90] </ref> uses a similar extension to greedy search called checkpointing. Checkpointing is designed to improve greedy search when learning exact descriptions. The greedy search algorithm described earlier can return rules with less than 100% data accuracy. <p> Since this grows exponentially with the number of free variables, the closed-world assumption often generates databases with millions or billions of examples. This is more examples than can be efficiently handled with current greedy algorithms let alone massive search. FOIL <ref> [Quinlan 90] </ref> addresses this problem by selecting a random sample of all negative examples and using the sample for rule evaluation. However, the sample can be a poor estimator since it represents a tiny fraction of all negative examples.
Reference: [Quinlan 93] <author> Quinlan, J. R. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kauf-mann, </publisher> <address> San Mateo, </address> <year> 1993. </year>
Reference-contexts: We will consider an algorithm better than another if it simultaneously learns both more accurate and higher-coverage rules. 5.3 Existing Solutions 5.3.1 Decision Trees Data mining is often performed using decision-tree algorithms such as CART [Breiman et al. 84] and C4.5 <ref> [Quinlan 93] </ref>. Decision-tree algorithms were not designed for data mining but for learning classifiers. Classifiers are functions that predict the goal attribute's value from the values of the remaining attributes. A decision tree is a tree-structured classifier. <p> Brute avoids both 153 these biases by considering each rule independently and is therefore better suited to data-mining problems. We compared Brute's data-mining performance to a decision-list algorithm we developed called Gold-digger [Riddle et al. 94] and a popular decision-tree algorithm called C4.5 <ref> [Quinlan 93] </ref>. We compared the three algorithms on two data-mining problems from a Boeing manufacturing domain. On the first database, the three algorithms performed similarly with Brute improving on Gold-digger by one percentage point and improving on C4.5 by 2.6 percentage points.
Reference: [Quinlan&Cameron-Jones 93] <author> Quinlan, J. R. and Cameron-Jones, R. M. </author> <title> FOIL: a midterm report. </title> <booktitle> In Proceedings of the European Conference on Machine Learning. </booktitle> <publisher> Springer Verlag, </publisher> <year> 1993. </year>
Reference: [Quinlan&Cameron-Jones 95] <author> Quinlan, J. R. and Cameron-Jones, R. M. </author> <title> Oversearch-ing and layered search in empirical learning. </title> <booktitle> In Proceedings of the 14th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1019-1024, </pages> <address> Montreal, Canada, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: Brute-greedy performs exceptionally well on the Monk2 database which requires learning an exclusive-or relationship for which greedy-search algorithms are known to perform poorly. Our results with Brute-greedy counter earlier results that suggest massive search reduces inductive performance of CN2-like algorithms <ref> [Webb 93, Quinlan&Cameron-Jones 95] </ref>. The key to Brute-greedy's success is its use of Laplace-depth to reduce overfitting. Early attempts using Laplace accuracy were prone to overfitting and therefore resulted in poor inductive performance.
Reference: [Quinlan&Rivest 89] <author> Quinlan, J. R. and Rivest, R. </author> <title> Inferring decision trees using the Minimum Description Length principle. </title> <journal> Information and Computation, </journal> <volume> 80 </volume> <pages> 227-248, </pages> <year> 1989. </year>
Reference-contexts: Many of the common evaluation functions for rule learning, including Laplace accuracy [Clark& Boswell 91], mutual information [Clark&Niblett 89] and minimum description length <ref> [Quinlan&Rivest 89] </ref>, are all rational for accuracies above a threshold. These functions should not be used for learning rules below their rationality threshold. 1 Rationality, while capturing the notion of an appropriate evaluation function, is also useful in computing upper bounds. <p> Table 3.1 lists common evaluation functions and displays their rationality and depth monotonicity. The table includes Laplace accuracy [Clark&Boswell 91], mutual 38 information [Clark&Niblett 89], minimum description length <ref> [Quinlan&Rivest 89] </ref>, and cost matrices [Pazzani et al. 94]. All of these functions are rational and depth monotone above some threshold. <p> High-coverage overfitting can be reduced using the same preference for short rules used to avoid low-coverage overfitting. Preferences for short rules are often encoded using the Minimum Description Length (MDL) principle <ref> [Rissanen 78, Rissanen 86, Quinlan&Rivest 89] </ref>. Since MDL uses a different tradeoff between accuracy and coverage than that used by Laplace accuracy, it is difficult to compare results using this function to those presented earlier. Instead, we modify Laplace accuracy to include a preference for short rules.
Reference: [Riddle et al. 92] <author> Riddle, P., Etzioni, O., Pearson, C., and Segal, R. </author> <title> Process improvement through automated feedback (preliminary report). </title> <booktitle> In Proceedings of the Machine Learning Workshop on Integrated Learning in Real-World Domains, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: This data contains information about various inefficiencies that may exist within the factory. The goal of data mining is to automatically extract this implicit information and make it available to factory engineers <ref> [Riddle et al. 92] </ref>. Each work cell consists of multiple automated workstations.
Reference: [Riddle et al. 94] <author> Riddle, P., Segal, R., and Etzioni, O. </author> <title> Representation design and brute-force induction in a Boeing manufacturing domain. </title> <journal> Applied Artificial Intelligence, </journal> <volume> 8 </volume> <pages> 125-147, </pages> <year> 1994. </year> <month> 163 </month>
Reference-contexts: The difficulties decision trees have with data mining therefore may not be related to using greedy search. This section proposes a greedy algorithm called Gold-digger <ref> [Riddle et al. 94] </ref>, which was specifically designed for data mining. Although developed independently, Gold-digger shares structure with a variety of decision-list learning algorithms including AQ [Michalski 69], Greedy3 [Pa-gallo&Haussler 90], and CN2 [Clark&Boswell 91]. Gold-digger combines a greedy rule-learning algorithm with a covering algorithm for learning multiple rules. <p> Second, classification algorithms are limited to learning a set of mutually-exclusive rules whereas many interesting rules overlap. Brute avoids both 153 these biases by considering each rule independently and is therefore better suited to data-mining problems. We compared Brute's data-mining performance to a decision-list algorithm we developed called Gold-digger <ref> [Riddle et al. 94] </ref> and a popular decision-tree algorithm called C4.5 [Quinlan 93]. We compared the three algorithms on two data-mining problems from a Boeing manufacturing domain.
Reference: [Riddle et al. 95] <author> Riddle, P., Fresnedo, R., and Newman, D. </author> <title> Framework for a generic knowledge discovery toolkit. </title> <booktitle> In Preliminary papers of the Fifth International Workshop on Artificial Intelligence and Statistics., </booktitle> <address> Ft. Lauderdale, Florida, </address> <month> January </month> <year> 1995. </year>
Reference-contexts: Brute was quite successful on the Boeing data-mining application, learning rules with substantially-higher accuracy and substantially-higher coverage than either Gold-digger or C4.5. Brute's success on the Boeing databases has made Brute the core component of Boeing's data-mining effort <ref> [Riddle et al. 95] </ref>. Chapter 6 CLASSIFICATION Classification is the central problem in many machine-learning applications. The goal of classification is to identify a function that can correctly predict, for any example, the value of the goal attribute.
Reference: [Rissanen 78] <author> Rissanen, J. </author> <title> Modeling by shortest data description. </title> <journal> Automatica, </journal> <volume> 14 </volume> <pages> 465-471, </pages> <year> 1978. </year>
Reference-contexts: High-coverage overfitting can be reduced using the same preference for short rules used to avoid low-coverage overfitting. Preferences for short rules are often encoded using the Minimum Description Length (MDL) principle <ref> [Rissanen 78, Rissanen 86, Quinlan&Rivest 89] </ref>. Since MDL uses a different tradeoff between accuracy and coverage than that used by Laplace accuracy, it is difficult to compare results using this function to those presented earlier. Instead, we modify Laplace accuracy to include a preference for short rules.
Reference: [Rissanen 86] <author> Rissanen, J. </author> <title> Stochastic complexity and modeling. </title> <journal> Annals of Statistics, </journal> <volume> 14(3) </volume> <pages> 1080-1100, </pages> <year> 1986. </year>
Reference-contexts: High-coverage overfitting can be reduced using the same preference for short rules used to avoid low-coverage overfitting. Preferences for short rules are often encoded using the Minimum Description Length (MDL) principle <ref> [Rissanen 78, Rissanen 86, Quinlan&Rivest 89] </ref>. Since MDL uses a different tradeoff between accuracy and coverage than that used by Laplace accuracy, it is difficult to compare results using this function to those presented earlier. Instead, we modify Laplace accuracy to include a preference for short rules.
Reference: [Rivest 87] <author> Rivest, R. </author> <title> Learning decision trees. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 229-246, </pages> <year> 1987. </year>
Reference-contexts: Finally, poor rule choices at the beginning of the list can significantly reduce the accuracy of the decision list learned. Nevertheless, Rivest showed that a greedy covering algorithm can provably PAC learn the concept class k-DL, decision lists composed of rules of length at most k <ref> [Rivest 87] </ref>. However, Rivest's PAC guarantee presupposes there exists 100%- accurate rules of length at most k that cover the training examples. This strong assumption neatly sidesteps the overlap problem because the accuracy of 100%-accurate rules remain unchanged regardless of the rules that precede them in the decision list.
Reference: [Salmon 84] <author> Salmon, W. C. </author> <title> Scientific Explanation and the Causal Structure of the World. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1984. </year>
Reference-contexts: BruteDL is an extension of Brute-greedy that uses a new algorithm for solving the overlap problem. BruteDL's solution is based on the concept of homogeneity from 132 the philosophical literature <ref> [Salmon 84] </ref>. Informally, a homogeneous rule is one whose accuracy does not change with its position in the decision list. Formally, let I denote the universe of examples. Let T denote the set of tests within a domain and G the set of goal classes.
Reference: [Schlimmer 93] <author> Schlimmer, J. C. </author> <title> Efficiently inducing determinations: A complete and systematic search algorithm that uses optimal pruning. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <address> Amherst, MA, </address> <month> June </month> <year> 1993. </year>
Reference: [Segal&Etzioni 94] <author> Segal, R. and Etzioni, O. </author> <title> Learning decision lists using homogeneous rules. </title> <booktitle> In Proceedings of the 12th National Conference on Artificial Intelligence, </booktitle> <month> July </month> <year> 1994. </year>
Reference-contexts: Brute-greedy is an extension of the standard decision-list algorithm that uses Brute rather than greedy search for its rule-learning component. BruteDL in an extension of Brute-greedy that replaces its greedy covering algorithm with a novel method for forming decision lists <ref> [Segal&Etzioni 94] </ref>. The next section describes Brute-greedy, 127 and the following section describes BruteDL. 6.1 Brute-greedy Though there are a variety of algorithms for learning decision lists, most have similar structure. Most algorithms combine a rule-learning component with a greedy covering algorithm.
Reference: [Smyth&Goodman 91] <author> Smyth, P. and Goodman, R. M. </author> <title> Rule induction using information theory. </title> <booktitle> In Knowledge Discovery in Databases, </booktitle> <pages> pages 159-176. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: Given these two assumptions, we can compute the posterior distribution on rule accuracies after seeing the data. The mean of this posterior distribution serves as a good estimate for rule accuracy. This estimate is known as Laplace accuracy and has been used in several learning algorithms <ref> [Niblett 87, Clark&Boswell 91, Smyth&Goodman 91, Webb 93] </ref>. Laplace accuracy can be calculated using the following formula: L (r) = jE (r)j + 2 See Niblett [1987] for a derivation. Laplace accuracy has the desirable property of taking into account both accuracy and coverage when estimating rule accuracy. <p> While this function has not been used extensively in the machine-learning literature, we believe this modified form of Laplace accuracy is a better function because it correctly handles rules with less than 50% accuracy. This function is commonly used in the statistical literature <ref> [Good 65, Smyth&Goodman 91] </ref>. Most of the results presented in this thesis are not dependent on the choice of estimation function. Some sections do assume that the estimation function is rational over the range of interest. <p> While Brute's running time for a few databases is several hours, in critical applications, the large error-rate reduction is worth the extra computational costs. 3.6 Related Work ITRule <ref> [Smyth&Goodman 91] </ref> was one of the first algorithms to apply massive search to rule learning. ITRule uses best-first search with branch-and-bound pruning to find the rule that maximizes an information-theoretic evaluation function. Brute improves on ITRule by making massive search more efficient.
Reference: [Srikant&Agrawal 96] <author> Srikant, R. and Agrawal, R. </author> <title> Mining quantitative association rules in large relational tables. </title> <booktitle> In Proceedings of the ACM SIGMOD Conference on Management of Data, </booktitle> <address> Montreal, Canada, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: All associations are learned in 123 a two-step process. The first step finds all conjunctions with the required coverage, and the second step finds partitions of these conjunctions that form associations. Apriori was recently extended to handle numerical attributes <ref> [Srikant&Agrawal 96] </ref>. The extended Apriori supports arbitrary numerical ranges and can automatically segment numerical attributes into subranges to improve efficiency. The extensions also include a mechanism for reducing the redundancy caused by numerical attributes.
Reference: [Valiant 84] <author> Valiant, L. G. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: Quinlan and Cameron-Jones' argument that oversearching is a natural conse quence of visiting more rules is motivated by Blumer et al.'s [1987] treatment of Valiant's PAC-learning model <ref> [Valiant 84] </ref>. PAC-learning theory shows that the qual ity of the rules learned on a database decreases with the size of the hypothesis space.
Reference: [Vapnik 95] <author> Vapnik, V. N. </author> <title> The Nature of Statistical Learning Theory. </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1995. </year>
Reference-contexts: Vapnik, a pioneer in PAC-learning theory, actually advocates a model very similar to Brute. Vapnik's structural risk-minimization (SRM) theory <ref> [Vapnik 95] </ref> asserts that the expected error of any classifier is the sum of its actual error and the error implied by the complexity of the smallest hypothesis space in which the rule fits. SRM suggests that classifier evaluation functions should take both classifier accuracy and classifier complexity into account.
Reference: [Weaver&Germond 94] <author> Weaver, D. L. and Germond, T., </author> <title> editors. The SPARC architecture manual : version 9. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1994. </year> <month> 164 </month>
Reference-contexts: Brute's bit-vector code uses 16-bit table lookups to count the number of bits set in a word because current architectures do not support a bit-count instruction. More than half the time spent in Brute's rule evaluation code is used for bit counting. Newer architectures such as the Ultra-SPARC <ref> [Weaver&Germond 94] </ref> which support a bit-count instruction should double performance. Bit-vectors introduce some additional memory overhead. Brute requires N T =8 bytes of memory to store the bit-vectors for a database with N examples and T tests.
Reference: [Webb 93] <author> Webb, G. I. </author> <title> Systematic search for categorical attribute-value data-driven machine learning. </title> <editor> In Foo, N. and Rowles, C., editors, </editor> <booktitle> AI `93. World Scientific, </booktitle> <address> Singapore, </address> <year> 1993. </year>
Reference-contexts: Given these two assumptions, we can compute the posterior distribution on rule accuracies after seeing the data. The mean of this posterior distribution serves as a good estimate for rule accuracy. This estimate is known as Laplace accuracy and has been used in several learning algorithms <ref> [Niblett 87, Clark&Boswell 91, Smyth&Goodman 91, Webb 93] </ref>. Laplace accuracy can be calculated using the following formula: L (r) = jE (r)j + 2 See Niblett [1987] for a derivation. Laplace accuracy has the desirable property of taking into account both accuracy and coverage when estimating rule accuracy. <p> RL does not include any mechanisms to avoid redundant rules. OPUS [Webb 95] also learns rules using massive search, but it was not designed for data mining. While the algorithm has been extended to learn multiple rules using a greedy covering algorithm <ref> [Webb 93] </ref>, this extension has the same inability to learn overlapping rules that plagues Gold-digger. Gold-digger is similar to several algorithms for learning decision lists including AQ, Greedy3, and CN2. AQ [Michalski 69] was the first to employ Gold-digger's covering algorithm but used a different rule-learning strategy. <p> Brute-greedy performs exceptionally well on the Monk2 database which requires learning an exclusive-or relationship for which greedy-search algorithms are known to perform poorly. Our results with Brute-greedy counter earlier results that suggest massive search reduces inductive performance of CN2-like algorithms <ref> [Webb 93, Quinlan&Cameron-Jones 95] </ref>. The key to Brute-greedy's success is its use of Laplace-depth to reduce overfitting. Early attempts using Laplace accuracy were prone to overfitting and therefore resulted in poor inductive performance. <p> These algorithms share Brute-greedy's iterative structure but use either a greedy or beam search to find the best rule. While Cover <ref> [Webb 93] </ref> extends CN2 to use massive search, it fails to improve performance because it lacks Brute-greedy's preference for short rules. The greedy covering algorithm shared by these systems limits their generalization ability because bad decisions made early in 144 the learning process adversely affect the learning of subsequent rules. <p> Brute-greedy is an extension of CN2-like algorithms to use massive rather than greedy search. Unlike previous systems that extend CN2-like algorithms for massive search <ref> [Webb 93] </ref>, Brute-greedy successfully improves inductive performance because its bias for short rules curbs overfitting. However, Brute-greedy's greedy covering algorithm limits performance. BruteDL is a novel algorithm for learning decision lists that eliminates the need for a greedy covering algorithm.
Reference: [Webb 95] <author> Webb, G. I. </author> <title> OPUS: An efficient admissible algorithm for unordered search. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 3 </volume> <pages> 431-465, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Brute employs four different pruning strategies: branch-and-bound pruning, sub-sumption pruning, dynamic reorganization, and depth-bound pruning. The following sections present each of these algorithms in turn. Two of these strategies, subsump-tion pruning and dynamic reorganization, were adapted from OPUS <ref> [Webb 95] </ref>. Sub-sumption pruning and dynamic reorganization are discussed below for completeness and because they are necessary for understanding Brute. <p> Brute's heuristically-guided search always explores the subtree with the greatest upper bound. This preference increases the likelihood that Brute will find a high-scoring rule before exploring branches with low upper bounds. 47 Webb has compared heuristically-guided search and best-first search on several UCI databases <ref> [Webb 95] </ref>. His results show that, when combined with dynamic reorganization, heuristically-guided search and best-first search have similar pruning performance. In 13 of 14 databases, heuristically-guided search expanded no more than twice the nodes of best-first search, expanding only four times the nodes in the worst case. <p> Since most search trees are fairly shallow, the number of passes through the database is minimal. The disadvantage of this approach is that it requires enough memory to store all rules visited. This is impractical for large search spaces. Brute's subsumption pruning and dynamic reorganization were adapted from OPUS <ref> [Webb 95] </ref>, a massive-search algorithm designed for rule learning. While both algorithms use similar branch-and-bound pruning techniques, they were developed independently. Brute extends OPUS to use depth-first search and to handle numerical attributes. <p> Similar to Apriori, RL returns all rules which meet user-set thresholds on positive and negative coverage. RL does not include any mechanisms to avoid redundant rules. OPUS <ref> [Webb 95] </ref> also learns rules using massive search, but it was not designed for data mining. While the algorithm has been extended to learn multiple rules using a greedy covering algorithm [Webb 93], this extension has the same inability to learn overlapping rules that plagues Gold-digger.
Reference: [Weiss et al. 90] <author> Weiss, S. M., Galen, R. S., and Tadepalli, P. V. </author> <title> Maximizing the predictive value of production rules. </title> <journal> Artificial Intelligence, </journal> <volume> 45 </volume> <pages> 47-71, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: The time complexity of the restricted BruteDL is asymptotically faster than k-DL by a factor of n. Furthermore, the unrestricted BruteDL is more general because it works for noisy domains, probabilistic concepts, and concepts not in k-DL. PVM <ref> [Weiss et al. 90] </ref> does a massive search of the space of classifiers. PVM's search is not exhaustive because it uses several heuristics to reduce the search space.

References-found: 48

