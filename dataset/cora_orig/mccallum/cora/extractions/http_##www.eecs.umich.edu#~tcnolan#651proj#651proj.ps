URL: http://www.eecs.umich.edu/~tcnolan/651proj/651proj.ps
Refering-URL: http://www.eecs.umich.edu/~tcnolan/651proj/index.html
Root-URL: http://www.cs.umich.edu
Title: A Single-Speaker CELP Speech Codec for Electronic Announcement Systems  
Author: Robert Nickel Troy Nolan Olga Milenkovic John McCanless 
Date: December 19, 1997  
Abstract: Final Report EECS 651 Term Project Fall 1997 by
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Mano, </author> <title> "Design of a Toll-Quality 4-Kbit/s Speech Coder Based on Phase-Adaptive PSI-CELP," </title> <booktitle> IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) Proceedings, v. </booktitle> <volume> 2, </volume> <year> 1997, </year> <pages> p 755-758. </pages>
Reference: [2] <author> C. H. Kwon and C. K. </author> <title> Un, "Low-Rate CELP Speech Coding Using an Improved Weighting Function," </title> <booktitle> IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) Proceedings, v. </booktitle> <volume> 2, </volume> <year> 1997, </year> <pages> p 743-746. </pages>
Reference: [3] <author> E. Erzin, A. Kumar, A. Gersho, </author> <title> "Natural Quality Variable-Rate Spectral Speech Coding Below 3.0 Kbps," </title> <booktitle> IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) Proceedings, v. </booktitle> <volume> 2, </volume> <year> 1997, </year> <pages> pp. 1579-1582. </pages>
Reference: [4] <author> A. Buzo, A. H. Gray, R. M. Gray, J. D. Markel, </author> <title> "Speech Coding Based Upon Vector Quantization," </title> <booktitle> Proc. ICASSP, v. </booktitle> <volume> 1, </volume> <year> 1980, </year> <pages> pp. 15-18. </pages>
Reference: [5] <author> M. R. Schroeder and B. S. Atal, </author> <title> "Code-Excited Linear Prediction (CELP): High-Quality Speech at Very Low Bit Rates," </title> <booktitle> Proc. ICASSP, </booktitle> <year> 1985, </year> <pages> pp. 937-940. </pages>
Reference: [6] <author> Bishnu S. Atal, </author> <title> "Predictive Coding of Speech at Low Bit Rates," </title> <journal> IEEE Trans. Commun. v. COM-30, </journal> <volume> no. 4, </volume> <month> Apr </month> <year> 1982, </year> <pages> pp. 600-614. </pages>
Reference: [7] <author> D. W. Griffin and J. S. Lim, </author> <title> "Multiband Excitation Vocoder," </title> <journal> IEEE Trans. Acoustics, Speech, Sig. Proc., v. </journal> <volume> ASSP-36, no. 8, </volume> <month> Aug </month> <year> 1988, </year> <pages> pp. 1223-1235. </pages>
Reference: [8] <author> A. J. Rubio Ayuso and J. M Lopez Soler, ed., </author> <title> Speech Recognition and Coding: New Advances and Trends, </title> <publisher> Springer, </publisher> <year> 1995. </year>
Reference: [9] <author> Khalid Sayood, </author> <title> Introduction to Data Compression, </title> <address> San Francisco: </address> <publisher> Morgan Kauf-man, </publisher> <year> 1996. </year>
Reference-contexts: using 8-bit PCM with -law scalar quantization produces a high-quality signal with rate 64 kbps that is certainly "coded," according to our discussion 10 Schemes such as differential pulse coded modulation (DPCM), adaptive DPCM (AD-PCM), sub-band coding, and transform coding, all of which use well-known scalar or vector quantization techniques <ref> [9] </ref>, are typically considered to fall into the class of waveform coders. <p> third pass is run with both the optimized LPC and optimized stochastic codebooks. 3.4.1 First Pass: The Modified LBG Algorithm for the IS Distortion Measure In the procedure of designing optimal LPC codebooks for the IS distortion measure there are just a few steps that differ from the standard steps <ref> [9] </ref>, based on the MSE 37 measure. All other issues, such as initial codebook assignment, empty-cell problem resolving and convergence, remain the same. Let us start with the initial codebook assignment. <p> All other issues, such as initial codebook assignment, empty-cell problem resolving and convergence, remain the same. Let us start with the initial codebook assignment. Several methods for this (such as Hilbert's method, NPP (nearest pair of points) method, and Gersho and Gray method) are explained in <ref> [9] </ref>. We implemented the first and the third, but the results are due to the first method (in our opinion, the most convenient and easiest to implement method).
Reference: [10] <author> Lawrence Rabiner and Bing-Hwang Juang, </author> <title> Fundamentals of Speech Recognition, </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall, </publisher> <year> 1993. </year>
Reference-contexts: In practice, the coefficients a i of this filter are estimated approximately every 20 ms (speech is thus considered to be quasi-stationary <ref> [10] </ref>); when this is done, fixing the order m of the filter to between 8 and 16 yields good results under a variety of conditions ([6],[10],[33]). We note that it is the estimation of the a i 's which is central to the performance of low-rate speech coders. <p> Finally, we note that G s and G a are scale factors which must also be determined for each frame. In some schemes, one or the other of these factors is set to zero in each frame, a process known as the voiced/unvoiced (V/UV) 8 from <ref> [10] </ref>.) 9 decision. Typically, coders which make a simple V/UV decision sacrifice a significant amount in the quality of reproduced speech ([10], [34],[33]). 1.2 Speech Coders Roughly speaking, speech coding techniques have evolved into three broad categories ([34],[33]): waveform coders, vocoders (or source coders), and hybrid coders. <p> The common approach in the literature <ref> [10] </ref> is to minimize the mean squared error (MSE) between the speech signal s (n) and the predicted speech signal s p (n) min Efd 2 (n)g = min E f (s (n) s p (n)) 2 g min Ef (^s (n) s p (n)) 2 g (3.3) which leads to <p> Windowing is usually desirable to alleviate boundary effects that get introduced into the spectrum due to the "sharp" cut-off at the beginning and the end of the frame. Commonly used window functions are a Hamming or a Hanning window for example (see <ref> [10] </ref>). The solution to the mentioned Yule-Walker equations can be found via the well-known Levinson-Durbin recursion. As a byproduct we do not only obtain the filter coefficients a i , but also the so called partial correlation (PARCOR) coefficients k i .
Reference: [11] <author> Lawrence Rabiner and Ronald Schafer, </author> <title> Digital Processing of Speech Signals , Englewood Cliffs, </title> <address> NJ: </address> <publisher> Prentice Hall, </publisher> <year> 1978. </year>
Reference: [12] <author> Sandaoki Furui and M. Mohan Sondhi, ed., </author> <booktitle> Advances in Speech Signal Processing, </booktitle> <address> New York: </address> <publisher> Marcel Dekker, </publisher> <year> 1992. </year> <pages> 55 56 </pages>
Reference: [13] <institution> Coding of Speech at 16 kbit/s Using Low-Delay Code Excited Linear Prediction (LD-CELP), CCITT Recommendation G.728, Geneva, </institution> <year> 1992. </year>
Reference-contexts: CELP techniques are discussed at length in Chapter 3, and we defer further discussion until then. We merely note here two CELP standards which have been adopted: the ITU produced a low-delay 16 kbps CELP codec standard, G.728 <ref> [13] </ref>, which produces speech nearly indistinguishable from 64 kbps -law PCM; and the U.S. Department of Defense has adopted standard FS1016 [14], a 4.8 kbps CELP codec producing good-quality speech for telecommunications. The latter in particular will figure prominently in the single-speaker CELP codec designed in this report.
Reference: [14] <author> Telecommunications: </author> <title> Analog to Digital Conversion of Radio Voice By 4,800 Bit/Second Code Excited Linear Prediction (CELP), Federal Standard 1016, </title> <institution> General Services Administration, Office of Information Resources Management, Febru-ary, </institution> <year> 1991. </year>
Reference-contexts: We merely note here two CELP standards which have been adopted: the ITU produced a low-delay 16 kbps CELP codec standard, G.728 [13], which produces speech nearly indistinguishable from 64 kbps -law PCM; and the U.S. Department of Defense has adopted standard FS1016 <ref> [14] </ref>, a 4.8 kbps CELP codec producing good-quality speech for telecommunications. The latter in particular will figure prominently in the single-speaker CELP codec designed in this report. <p> We will then broaden the general system in terms of "separating" between voiced and unvoiced excitations by employing a codec model proposed in the federal standard FS1016 <ref> [14] </ref>. Lastly, we will be concerned with techniques that exploit the specific structure of utterances from a specific single speaker. 3.1 Adaptive DPCM The adaptive DPCM system that is developed in this section should be considered an intermediate step towards our SS-CELP codec. <p> It has been shown, however, that a choice of fl = 0:994 (i.e. a bandwidth expansion of 15Hz see <ref> [14] </ref>) yields a good tradeoff. The next step after preprocessing the filter is to find a proper coefficient transform that enables us to code the coefficients with a simple set of uniform scalar quantizers. <p> In contrast to the adaptive DPCM system, the residual signal is not explicitly transmitted to the receiver. 28 3.3 The FS1016 CELP Coder The next step in our progression is to compare the general CELP system to the Federal Standard FS1016 CELP system <ref> [14] </ref>. With this FS1016 CELP coder, we hope to achieve lower distortion and a lower rate. The FS1016 standard introduces the concept of a stochastic codebook (SCB) and an adaptive codebook (ACB), these codebooks hope to accurately model the voiced and unvoiced parts human speech. <p> The FS1016 standard introduces the concept of a stochastic codebook (SCB) and an adaptive codebook (ACB), these codebooks hope to accurately model the voiced and unvoiced parts human speech. In the FS1016 specification, the implementation details for the pitch and spectral filters are given <ref> [14] </ref>. In addition, the excitation codebook is defined, so all standard coders have knowledge of it at the development stage. The FS1016 implementation 29 of the CELP coder is given in Figure 3.7.
Reference: [15] <author> L. M. Supplee, R. P. Cohn, J. S. Collura, and A. V. McCree, </author> <title> "MELP: The New Federal Standard at 2400 BPS," </title> <booktitle> Proc. ICASSP, </booktitle> <year> 1997, </year> <pages> pp. 1591-1594. </pages>
Reference: [16] <author> M. A. Kohler, </author> <title> "A Comparison of the New 2400 BPS MELP Federal Standard With Other Standard Coders," </title> <booktitle> Proc. ICASSP, </booktitle> <year> 1997, </year> <pages> pp. 1587-1590. </pages>
Reference: [17] <author> S.R. Quackenbusch, T. Barnwell, and M. Clements, </author> <title> Objective Measures of Speech Quality, </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall, </publisher> <year> 1988. </year>
Reference-contexts: On the other hand, there exists a large number of objective measures that are used with various amounts of success in determination of speech quality. 1 Many of these have been shown to be good in certain applications, but to fail in many other examples <ref> [17] </ref>. Two interesting classifications of objective distortion measures are made according to the correlation between the objective and subjective measure (2.1), and according to the error-variance (2.2), arising from the mismatch of the two different distortion measures [17]. <p> to be good in certain applications, but to fail in many other examples <ref> [17] </ref>. Two interesting classifications of objective distortion measures are made according to the correlation between the objective and subjective measure (2.1), and according to the error-variance (2.2), arising from the mismatch of the two different distortion measures [17]. <p> Subjective measures are obtained from experiments involving human factors (for example, the paired-comparison method is the basis for determining (2.1)). Also, ^ 2 e is the estimated standard deviation of the subjective measure. Table 2.1 is taken from <ref> [17] </ref>, and shows the correlation between objective 1 Examples are :signal-to-noise ratio, functional spectral distance measures, cepstral distance mea sures, and parametric distance measures such as log-area ratios [17]. 12 13 Objective distortion measure j ^j SNR 0.24 Segmental SNR 0.77 Frequency variant SNR 0.93 Linear area ratio 0.24 Log area <p> Also, ^ 2 e is the estimated standard deviation of the subjective measure. Table 2.1 is taken from <ref> [17] </ref>, and shows the correlation between objective 1 Examples are :signal-to-noise ratio, functional spectral distance measures, cepstral distance mea sures, and parametric distance measures such as log-area ratios [17]. 12 13 Objective distortion measure j ^j SNR 0.24 Segmental SNR 0.77 Frequency variant SNR 0.93 Linear area ratio 0.24 Log area ratio 0.62 Itakura distortion 0.59 Linear Spectral Distortion 0.38 Inverse Linear Spectral Distortion 0.63 Log-Spectral Distortion 0.60 Nonlinear Spectral Distortion 0.61 Table 2.1: Coefficient of correlation between objective <p> For Linear Predictive coding (LPC) [18], as well as for all similar techniques (CELP, RELP, DPCM, ADPCM [18]) the following distortion measures are more often used than MSE distortion: Linear area ratio, Log area ratio, Linear spectral distance, Log spectral distance, Maximum likelihood distance and Itakura-Saito's distance <ref> [17] </ref>, [22].
Reference: [18] <author> A. Gersho and R. Gray, </author> <title> Vector Quantization and Signal Compression, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1992. </year>
Reference-contexts: As an example, it is known that the ear is not very sensitive to phase offsets; however, if we calculate the MSE between a signal and its shifted version, we obtain a large error value, which does not reflect a listener's subjective perception. For Linear Predictive coding (LPC) <ref> [18] </ref>, as well as for all similar techniques (CELP, RELP, DPCM, ADPCM [18]) the following distortion measures are more often used than MSE distortion: Linear area ratio, Log area ratio, Linear spectral distance, Log spectral distance, Maximum likelihood distance and Itakura-Saito's distance [17], [22]. <p> For Linear Predictive coding (LPC) <ref> [18] </ref>, as well as for all similar techniques (CELP, RELP, DPCM, ADPCM [18]) the following distortion measures are more often used than MSE distortion: Linear area ratio, Log area ratio, Linear spectral distance, Log spectral distance, Maximum likelihood distance and Itakura-Saito's distance [17], [22]. <p> This is a suboptimal approach, but it has been shown that there is almost no degradation as compared to the case of joint vector quantization of the LPC parameters and the residual <ref> [18] </ref>. Chapter 3 Design of the Single-Speaker CELP Codec After defining our underlying speech model in Chapter 1 and our distortion measure in Chapter 2, we can now start to develop the proposed single speaker CELP (SS-CELP) codec. <p> 2 (d 1 ) = 2=k 2 (k + 2) x2 V jD 1 j 1=k f (x) k=k+2 tr (D 1 R 2=n (4.5) * k = V ol (Sphere; r = 1; dim = k) This reduces to the familiar expression for the distortion of the best VQ <ref> [18] </ref>, if both d 1 ; d 2 are MSE distortions, that is jD 1 j = jD 2 j = I.
Reference: [19] <author> S. Kay, </author> <title> Modern Spectral Estimation, </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall, </publisher> <year> 1988. </year>
Reference-contexts: Of the two steps, the more important one is the parameter quantization problem. It can be shown that the filter response is very sensitive to changes in the coefficient values (especially if the poles of the filter are clustered see Kaiser's result in <ref> [19] </ref>).
Reference: [20] <author> A. Gray, R. Gray, and J. Markel, </author> <title> "Comparison of Optimal Quantizations of Speech Reflection Coefficients," </title> <journal> IEEE Trans. on Acoustics, Speech and Signal Processing, </journal> <month> Feb. </month> <year> 1977. </year>
Reference: [21] <author> A. Buzo, A. Gray, R. Gray, and J. Markel, </author> <title> "Speech Coding Based Upon Vector Quantization," </title> <journal> IEEE Trans. on Acoustics, Speech and Signal Processing, </journal> <month> Oct. </month> <year> 1980. </year>
Reference-contexts: The Itakura-Saito (IS) distortion measure is particularly well-suited for LPC systems, and can be formulated in the following way ( <ref> [21] </ref>, [22], [24]): d IS (X; G) = 2 14 Here jX (!)j 2 is the power spectral density (PSD) of windowed speech data, and jG (!)j 2 is the PSD of the polynomial function used to describe the autoregressive model of order m of the input data. <p> A (z) is known as the inverse filter, and the energy of the output of this filter for a given input X (z) is the residual energy <ref> [21] </ref>. The filter A (z) is usually designed to minimize this residual energy. Although many variations of the IS distortion exist, we will refer to all of them as generalized IS distortion. <p> As a direct consequence, we can average the autocorrelation sequences for all speech frames, and then use the Levinson-Durbin algorithm for calculating the LPC filter parameters associated with the centroid. In <ref> [21] </ref> it has been shown that the average cell distortion can be expressed as: d IS;k = n d IS ( ^ X; G k ) + c (3.31) where c is a constant and ^ X is the arithmetic mean of the individual cell spectra. <p> needed for any of the calculations performed in designing 38 the codebook, it has a special interpretation as being the fixed distortion that does not change with filter order and is only due to the fact that we are assigning speech frames with different spectra to the same cell (see <ref> [21] </ref>). Although for the purpose of this project implementation complexity is not an issue, it is worth mentioning that the computational cost for evaluating the IS distortion is very high (compared to MSE). <p> Once we obtained the speech codebook, we have to face the problem of storage complexity and the time needed to find the best matching model in the codebook, given a training speech vector. More details can be found in <ref> [21] </ref>. Let us just mention that we implemented separated quantization of the LPC parameters and the residual, since this suboptimal vector quantization approach has shown to give a negligible performance loss [21]. <p> More details can be found in <ref> [21] </ref>. Let us just mention that we implemented separated quantization of the LPC parameters and the residual, since this suboptimal vector quantization approach has shown to give a negligible performance loss [21]. Although it is recommended to remove silence from spoken speech before applying it as a training sequence for the LBG algorithm (for example, with an adaptive algorithm [25]), we decided not to do it.
Reference: [22] <author> Y. Matsuyama, A. Buzo, and R. Gray, </author> <title> Spectral Distortion Measures for Speech Compression, </title> <type> Technical Report No. 6504-3, </type> <institution> Stanford Electronics Laboratories, Stanford University, Stanford, California, </institution> <month> April </month> <year> 1978. </year>
Reference-contexts: For Linear Predictive coding (LPC) [18], as well as for all similar techniques (CELP, RELP, DPCM, ADPCM [18]) the following distortion measures are more often used than MSE distortion: Linear area ratio, Log area ratio, Linear spectral distance, Log spectral distance, Maximum likelihood distance and Itakura-Saito's distance [17], <ref> [22] </ref>. The Itakura-Saito (IS) distortion measure is particularly well-suited for LPC systems, and can be formulated in the following way ( [21], [22], [24]): d IS (X; G) = 2 14 Here jX (!)j 2 is the power spectral density (PSD) of windowed speech data, and jG (!)j 2 is the <p> distortion measures are more often used than MSE distortion: Linear area ratio, Log area ratio, Linear spectral distance, Log spectral distance, Maximum likelihood distance and Itakura-Saito's distance [17], <ref> [22] </ref>. The Itakura-Saito (IS) distortion measure is particularly well-suited for LPC systems, and can be formulated in the following way ( [21], [22], [24]): d IS (X; G) = 2 14 Here jX (!)j 2 is the power spectral density (PSD) of windowed speech data, and jG (!)j 2 is the PSD of the polynomial function used to describe the autoregressive model of order m of the input data. <p> ): d I (A; A 0 ) = d IS ( ff=A; ff 0 =A 0 ) (2.6) with ff; ff 0 being defined as the residual energies: ff = 2 The generalized Itakura-Saito distortion measure has many interesting properties, some related to estimation theory, information theory and signal-processing ( <ref> [22] </ref>, [24]): * In the class of all AR filters, the filter that minimizes the prediction error also minimizes the IS distortion (that is, the filter obtained by the Levinson-Durbin algorithm also gives the minimum of the IS distortion for the model and input speech). 15 * For Gaussian random processes,
Reference: [23] <author> B-H. Juang, D. Wong, and A. Gray, </author> <title> "Distortion Performance of Vector Quantization for LPC Voice Coding," </title> <journal> IEEE Trans. on Acoustics, Speech and Signal Processing, </journal> <month> April </month> <year> 1982. </year>
Reference: [24] <author> B-H. Juang, </author> <title> "On Using the Itakura-Saito Measures for Speech Coder Performance Evaluation," </title> <institution> ATT Bell Lab., </institution> <month> October </month> <year> 1984. </year>
Reference-contexts: The Itakura-Saito (IS) distortion measure is particularly well-suited for LPC systems, and can be formulated in the following way ( [21], [22], <ref> [24] </ref>): d IS (X; G) = 2 14 Here jX (!)j 2 is the power spectral density (PSD) of windowed speech data, and jG (!)j 2 is the PSD of the polynomial function used to describe the autoregressive model of order m of the input data. <p> d I (A; A 0 ) = d IS ( ff=A; ff 0 =A 0 ) (2.6) with ff; ff 0 being defined as the residual energies: ff = 2 The generalized Itakura-Saito distortion measure has many interesting properties, some related to estimation theory, information theory and signal-processing ( [22], <ref> [24] </ref>): * In the class of all AR filters, the filter that minimizes the prediction error also minimizes the IS distortion (that is, the filter obtained by the Levinson-Durbin algorithm also gives the minimum of the IS distortion for the model and input speech). 15 * For Gaussian random processes, given <p> Before concluding our introduction to the IS distortion measure, we mention one weakness of the measure that should be the focus of further research. Experimental results show that special attention should be paid to rapid transitions in the speech spectra <ref> [24] </ref>. The IS distortion is a rather static measure that does not admit to incorporating the transition patterns in its description. We will see in Chapter 3 that the largest distortion occurs for frames of speech containing sudden transitions.
Reference: [25] <author> J. Proakis, </author> <title> Digital Communications, </title> <publisher> McGraw Hill, </publisher> <year> 1991. </year>
Reference-contexts: Although it is recommended to remove silence from spoken speech before applying it as a training sequence for the LBG algorithm (for example, with an adaptive algorithm <ref> [25] </ref>), we decided not to do it. Instead, we assured that certain initial codewords in the codebook correspond to silence periods (Hilbert's initialization procedure). The following two figures (Figure 3.4.1 and Figure 39 algorithm 3.4.1) show the initial and final distribution of the IS distortion per frame.
Reference: [26] <author> J.Li, N. Chaddha, and R. Gray, </author> <title> "Asymptotic Performance of Vector Quantiz-ers With a Perceptual Distortion Measure," </title> <journal> submitted to IEEE Trans. Inform. Theory, </journal> <month> April </month> <year> 1997. </year>
Reference-contexts: It has been shown ( <ref> [26] </ref>) that if the distortion measure d (X; Y ) between two vectors X; Y satisfies the following two conditions: * d (X; Y ) has continuous partial derivatives of order at least three almost every where * The so-called sensitivity matrix, defined as: D k;m (X; Y ) = 2
Reference: [27] <author> B. Atal, V. Cuperman, A. Gersho, </author> <title> Advances in Speech Coding, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year> <month> 57 </month>
Reference-contexts: The approach is very similar to the perceptually advantageous technique of "noise-shaping" in ADPCM systems. The parameter fl enables us adjust the amount of desired "shaping-level". In practice values around fl = 0:8 have proved to deliver good perceptual results <ref> [27] </ref>. Finally, the index of the selected excitation codeword is encoded and transmitted to the decoder, which selects the appropriate excitation vector used to excite the decoder's filters. The general mechanism for the above codeword selection is known as "Analysis-by-Synthesis", which is illustrated in Figure 3.5. <p> The presented algorithm is a modification of a method proposed by <ref> [27] </ref>. <p> find the optimal index and gain for the adaptive codebook alone 2. given the results from 1: find the best matching index and gain from the stochas tic codebook This method is clearly suboptimal, but it is significantly faster than an extensive search and it was shown in experiments (see <ref> [27] </ref>) that the improvements due to an extensive search are negligible. Lets start with the adaptive codebook search (part 1). <p> These approaches usually employ correlation functions, see <ref> [27] </ref>. 35 Given the results for the adaptive codebook search from above we can now try to find the best matching index and gain from the stochastic codebook (part 2).
Reference: [28] <author> W. Gardner, and B. Rao, </author> <title> "Theoretical Analysis of the High-Rate Vector Quna-tization of LPC Parameters," </title> <journal> IEEE Trans. on Speech and Audio Proc., </journal> <volume> Vol. 3, No. 5, </volume> <month> September </month> <year> 1995. </year>
Reference-contexts: R a (k m) (4.4) X g (i) g (n + i); g (i) = IF T ( A (!) This result is not very surprising, since it shows that the sensitivity matrix for the IS distortion measure is exactly one-half of the sensitivity matrix of the LSD distortion 48 <ref> [28] </ref>, and we already know that for the asymptotic case this two measures coincide. Having computed the sensitivity matrix, we can use the result from [28] that shows the distortion of the quantizer with target distortion d 2 and training distortion d 2 : D d 2 (d 1 ) = <p> surprising, since it shows that the sensitivity matrix for the IS distortion measure is exactly one-half of the sensitivity matrix of the LSD distortion 48 <ref> [28] </ref>, and we already know that for the asymptotic case this two measures coincide. Having computed the sensitivity matrix, we can use the result from [28] that shows the distortion of the quantizer with target distortion d 2 and training distortion d 2 : D d 2 (d 1 ) = 2=k 2 (k + 2) x2 V jD 1 j 1=k f (x) k=k+2 tr (D 1 R 2=n (4.5) * k = V ol
Reference: [29] <author> R. Viswanathan and J. Makhoul, </author> <title> "Quantization Properties of Transmission Parameters in Linear Predictive Systems," </title> <journal> IEEE Trans. Acoustics, Speech, Sig. Proc., v. </journal> <volume> ASSP-23, no. 3, </volume> <month> June </month> <year> 1975. </year>
Reference-contexts: The next step after preprocessing the filter is to find a proper coefficient transform that enables us to code the coefficients with a simple set of uniform scalar quantizers. The transform should satisfy the following three important properties (see <ref> [29] </ref>): 21 1. filter stability upon quantization 2. a natural ordering of the parameters 3. ability to account for differences in sensitivity It is obvious that we must be concerned with a filter that is stable after the quantization process. <p> Some regions in our transform domain might be much more sensitive with respect to coding errors than others. In the past, a lot of research has been geared towards finding good transformation domains. A comprehensive overview of the results can be found in <ref> [29] </ref> and [31]. In this report we would like to focus on three of the most commonly used: the log area ratios (LAR), the inverse sine of the reflection coefficients (ISC), and the line spectral pairs (LSP). <p> Moreover, despite the natural ordering it is reasonable to assume that no coefficient is (on average) "more important" than any other coefficient 1 (see <ref> [29] </ref>). Consequently, we can expect to achieve quantization with small errors by independently performing a nonuniform scalar quantization (NUSQ) on each individual reflection coefficient. <p> and take the limit for k ! 0 we obtain a measure of "sensitivity" to quantization errors as a function of k : S p (k) = lim 2 1 (3.8) A careful analysis of this sensitivity function for p = 1 and p = 2 can be found in <ref> [29] </ref> and [31]. Generally, we find that the sensitivity characteristic is similar for all components of the vector k and that the sensitivity value is high if individual components k i are close to +1 or 1. <p> Consequently we must quantize more finely for reflection coefficients close to +1 and 1 and we can quantize more coarsely for coefficients close to 0. The derivations of the optimal compander functions for p = 1 and p = 2 are omitted here and can be found in <ref> [29] </ref> and [31].
Reference: [30] <author> R. Viswanathan and J. Makhoul, </author> <title> "Current Issues in Linear Predictive Speech Compression," </title> <booktitle> Proc. 1974 EASCON Conf., </booktitle> <address> Washington, D.C., </address> <month> Oct. </month> <year> 1974, </year> <pages> pp. 577-585. </pages>
Reference-contexts: However, if we send pole locations p i instead, then the sequence of the poles doesn't matter and we thus wasted an important piece of information. A careful analysis of these effects can be found in <ref> [30] </ref>. Lastly, we need to be concerned about the required coding accuracy as a function of the transform values itself. Some regions in our transform domain might be much more sensitive with respect to coding errors than others.
Reference: [31] <author> A. H. Gray, Jr. and J. D. Markel, </author> <title> "Quantization and Bit Allocation in Speech Processing," </title> <journal> IEEE Trans. Acoustics, Speech, Sig. Proc., v. </journal> <volume> ASSP-24, no. 6, </volume> <month> Dec. </month> <year> 1976. </year>
Reference-contexts: Some regions in our transform domain might be much more sensitive with respect to coding errors than others. In the past, a lot of research has been geared towards finding good transformation domains. A comprehensive overview of the results can be found in [29] and <ref> [31] </ref>. In this report we would like to focus on three of the most commonly used: the log area ratios (LAR), the inverse sine of the reflection coefficients (ISC), and the line spectral pairs (LSP). <p> the limit for k ! 0 we obtain a measure of "sensitivity" to quantization errors as a function of k : S p (k) = lim 2 1 (3.8) A careful analysis of this sensitivity function for p = 1 and p = 2 can be found in [29] and <ref> [31] </ref>. Generally, we find that the sensitivity characteristic is similar for all components of the vector k and that the sensitivity value is high if individual components k i are close to +1 or 1. <p> The derivations of the optimal compander functions for p = 1 and p = 2 are omitted here and can be found in [29] and <ref> [31] </ref>.
Reference: [32] <author> B. S. Atal and P. Kroon, </author> <title> "Spectral Quantization and Interpolation for CELP Coders," </title> <booktitle> Proc. ICASSP 1989, </booktitle> <pages> pp. 69-72. </pages>
Reference: [33] <author> Ciaran McElroy, </author> <title> "Speech Coding," </title> <type> tutorial paper, </type> <year> 1995. </year> <note> Available in HTML format at http://wwwdsp.ucd.ie/speech/tutorial/speech coding/speech tut.html </note>
Reference-contexts: Vocoders are typically used at bit rates of 800 - 2400 bps, and have found application in military systems where speech quality is unimportant and/or large amounts of overhead are needed for encryption and error protection. Interestingly, vocoders date to 1939, when (see <ref> [33] </ref>) H.
Reference: [34] <author> Jason Woodard, </author> <title> "Speech Coding," </title> <note> tutorial paper. Available in HTML format at http://www-mobile.ecs.soton.ac.uk/speech codecs/index.html </note>
Reference-contexts: techniques have evolved into three broad categories (<ref> [34] </ref>,[33]): waveform coders, vocoders (or source coders), and hybrid coders. As we will see, each class of coders is designed to be efficient when used in applications with different rate-distortion and/or complexity requirements. Figure 1.6 illustrates some of these tradeoffs. ignored). (Taken from [34].) 1.2.1 Waveform Coders Waveform coders are so-called because they attempt to produce a replica of the input signal waveform, more or less directly, without regard to whether the input signal is speech or some other signal.
Reference: [35] <author> Tony Robinson, </author> <title> "Speech Analysis," </title> <note> tutorial paper. Available in HTML format at http://svr-www.eng.cam.ac.uk/~ ajr/SpeechAnalysis/index.html </note>
Reference-contexts: We note that it is the estimation of the a i 's which is central to the performance of low-rate speech coders. In summary, our model of human speech production is characterized by an excitation signal that is passed through an all-pole filter (a "source-filter model" <ref> [35] </ref>). Moreover, the excitation signal has two components: one is periodic, the other essentially noise. We can then immediately create the general speech synthesis model diagrammed in Figure 1.5: we sum both types of excitation and filter the result with the (all-pole) vocal tract filter.
Reference: [36] <author> N. Jayant and P. Noll, </author> <title> Digital Coding of Waveforms: Principles and Applications to Speech and Video, </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall, </publisher> <year> 1984. </year>
Reference-contexts: + d 0 (Y )(X Y ) + 2 with d 0 i (Y ) = @ x i and noting that d (Y ; Y ) = 0 and d 0 (Y ) = 0, since we have at least a local minimum for X ' Y (Max-LLoyd's result, <ref> [36] </ref>). <p> The idea of coding the first several LPC parameters of speech with a larger number of bits <ref> [36] </ref> seems to be justified only for the case of voiced speech. We assume that adaptive bit allocation for LPC parameters for different types of frames should lead to improved performance. <p> The final innovation of the SS-CELP system included the improved stochastic codebook. This added little to the subjective perceptual differences, but decreased the SNR and ISD quality, while doubling the complexity. 1 For law companding, the SNR function is given <ref> [36] </ref> as SNR (R) ' 6:02R 10:10 2 This value does not reflect the first pass LBG algorithm 3 This value does not reflect either of the LBG algorithms Chapter 5 Conclusions 5.1 I-SCB Conclusions Our analysis for the stochastic codebook has led to two conclusions 1.
Reference: [37] <author> F. Itakura, </author> <title> "Line Spectrum Representation of Linear Prediction Coefficients of Speech Signals," </title> <journal> J. Acoustical Society of America, v. </journal> <volume> 57, supplement 1, S35, </volume> <year> 1975. </year>
Reference-contexts: LSP parameters were first introduced by 23 Itakura in 1975 (see <ref> [37] </ref>).
Reference: [38] <author> J. R. B. de Marca, </author> <title> "An LSF Quantizer for the North American Half-Rate Speech Coder," </title> <journal> IEEE Trans. Vehicular Tech., v. </journal> <volume> 43, no. 3, </volume> <pages> pp. 413-419, </pages> <month> August, </month> <year> 1994. </year>
Reference: [39] <author> G. S. Kang and L. J. Fransen, </author> <title> "Application of Line-Spectrum Pairs to Low-Bit-Rate Speech Encoders," </title> <booktitle> Proc. ICASSP, </booktitle> <year> 1985, </year> <pages> pp. 244-247. </pages>
Reference: [40] <author> F. K. Soong and B.-H. Juang, </author> <title> "Optimal Quantization of LSP Parameters," </title> <booktitle> Proc. ICASSP, </booktitle> <year> 1988, </year> <pages> pp. 394-397. </pages>
Reference-contexts: that correspond to the phase angles of the conjugate complex root-pairs of the following two polynomials: Q + (z) = A (z) + z (m+1) A (z 1 ) (3.11) It can be shown that the roots of Q + (z) and Q (z) are on the unit circle (see <ref> [40] </ref>). <p> In addition, if this order does not get violated due to the quantization process, then the resulting filter is stable (see <ref> [40] </ref>). The quantized filter coefficients a i can be retrieved at the receiver by reconstructing Q + (z) and Q (z) from the roots e 2j f i F s . <p> Moreover, from experimental results it is known that every LSP parameter is distributed differently, so that we have to define a different NUSQ for each individual f i . A numerical method for the design of an optimal set of NUSQ quantizers can be found in <ref> [40] </ref>. Within the context of this report we have restricted ourselves to the LSP quantization that is proposed in the federal standard FS1016. 24 over 700 quantization operations. The underlying LPC models were computed from real speech signals.
Reference: [41] <author> N. Sugamura and N. Farvardin, </author> <title> "Quantizer Design in LSP Speech Analysis and Synthesis," </title> <booktitle> Proc. ICASSP, </booktitle> <year> 1988, </year> <pages> pp. 398-401. </pages>
Reference: [42] <author> M. Yong, G. Davidson, and A. Gersho, </author> <title> "Encoding of LPC Spectral Parameters Using Switched-Adaptive Interframe Vector Prediction," </title> <booktitle> Proc. ICASSP, </booktitle> <year> 1988, </year> <pages> pp. 402-405. 58 </pages>
Reference: [43] <author> F. K. Soong and B.-H. Juang, </author> <title> "Line Spectrum Pair (LSP) and Speech Data Compression," </title> <booktitle> Proc. ICASSP, </booktitle> <year> 1984, </year> <pages> pp. </pages> <month> 1.10.1-1.10.4. </month>
Reference: [44] <author> J. R. Crosmer and T. P. Barnwell, III, </author> <title> "A Low Bit Rate Segment Vocoder Based On Line Spectrum Pairs," </title> <booktitle> Proc. ICASSP, </booktitle> <year> 1985, </year> <pages> pp. 240-243. </pages>
Reference: [45] <author> J.-H. Chen and A. Gersho, </author> <title> "Covariance and Autocorrelation Methods for Vector Linear Prediction," </title> <booktitle> Proc. ICASSP, </booktitle> <year> 1987, </year> <pages> pp. 1545-1548. </pages>
Reference: [46] <author> G. Davidson, M. Yong, and A. Gersho, </author> <title> "Real-Time Vector Excitation Coding of Speech at 4800 BPS," </title> <booktitle> Proc. ICASSP, </booktitle> <year> 1987, </year> <pages> pp. 2189-2192. </pages>
Reference: [47] <author> Y. Shoham, </author> <title> "Vector Predictive Quantization of the Spectral Parameters for Low Rate Speech Coding," </title> <booktitle> Proc. ICASSP, </booktitle> <year> 1987, </year> <month> pp.2181-2184. </month>
Reference: [48] <author> N. S. Jayant and V. Ramamoorthy, </author> <title> "Adaptive Postfiltering of 16 kb/s-ADPCM Speech," </title> <booktitle> Proc. ICASSP, </booktitle> <year> 1986, </year> <pages> pp. 829-832. </pages>
References-found: 48

