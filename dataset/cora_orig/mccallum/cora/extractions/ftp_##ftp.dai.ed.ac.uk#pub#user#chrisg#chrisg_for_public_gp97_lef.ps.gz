URL: ftp://ftp.dai.ed.ac.uk/pub/user/chrisg/chrisg_for_public_gp97_lef.ps.gz
Refering-URL: http://www.dai.ed.ac.uk/students/chrisg/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fchrisg, peterg@dai.ed.ac.uk  
Phone: +44 (0)131 650-3090  
Title: Tackling the Boolean Even N Parity Problem with Genetic Programming and Limited-Error Fitness standard GP
Author: Chris Gathercole and Peter Ross 
Web: http://www.dai.ed.ac.uk/  
Address: CA, USA  80 South Bridge Edinburgh EH1 1HN U.K.  
Affiliation: Stanford University,  Department of Artificial Intelligence University of Edinburgh  
Date: 97, 13-16 July,  
Note: To be presented at Genetic Programming  LEF allows  
Abstract: This paper presents Limited Error Fitness (LEF), a modification to the standard supervised learning approach in Genetic Programming (GP), in which an individual's fitness score is based on how many cases remain uncovered in the ordered training set after the individual exceeds an error limit. The training set order and the error limit are both altered dynamically in response to the performance of the fittest individual in the previous generation. 
Abstract-found: 1
Intro-found: 1
Reference: [Angeline and Pollack, 1993] <author> Peter J. Angeline and Jordan B. Pollack. </author> <title> Competitive environments evolve better solutions for complex tasks. </title> <booktitle> In Proceedings of the 5th International Conference on Genetic Algorithms, ICGA-93, </booktitle> <pages> pages 264-270. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Reproduction takes place randomly within the remaining individuals. Good results and potential are reported. Angeline and Pollack look at competitive environments where the fitness is related only to the current ability of the population, <ref> [Angeline and Pollack, 1993] </ref>. <p> Simply evaluating each individual in each generation on the entire training set ignores the current abilities of the population which change with each generation, wasting a good resource, <ref> [Angeline and Pollack, 1993] </ref>, and ignores information gained about the difficulty of cases in the training set. Breaking up the problem into sub-problems, and presenting the sub-problems to be solved in turn, can `lead' the population to solve the entire problem.
Reference: [Blickle and Thiele, 1995] <author> Tobias Blickle and Lothar Thiele. </author> <title> A comparison of selection schemes used in genetic algorithms. </title> <type> TIK-Report 11, </type> <institution> TIK Insti-tut fur Technische Informatik und Kommunikation-snetze, Computer Engineering and Networks Laboratory, ETH, Swiss Federal Institute of Technology, </institution> <address> Glori-astrasse 35, 8092 Zurich, Switzerland, </address> <month> December </month> <year> 1995. </year>
Reference-contexts: The basic GP settings could certainly have been improved. In particular, the tournament size seems to have been too large. Some studies <ref> [Blickle and Thiele, 1995] </ref> and several discussions with GA practitioners seem to indicate that smaller tournament sizes work better. The choice of operators is also important.
Reference: [Gathercole and Ross, 1994] <author> Chris Gathercole and Peter Ross. </author> <title> Dynamic training subset selection for supervised learning in genetic programming. </title> <editor> In Yuval Davidor, Hans-Paul Schwefel, and Reinhard Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature III, </booktitle> <pages> pages 312-321, </pages> <address> Berlin, </address> <month> 9-14 October </month> <year> 1994. </year> <note> Springer-Verlag. </note>
Reference-contexts: space for a complex task. ... [U]sing the population as a reservoir for comparison is preferable to using an exemplar for the task when an objective measure of fitness is unavailable." The explicit selection of a subset of cases from the training set with which to evaluate each generation, in <ref> [Gathercole and Ross, 1994] </ref>, makes use of the difficulty of each training case, i.e. how often it is misclassified, and its age, i.e. how many generations since it was last selected. <p> With LEF however, the few cases not yet consistently classified cor rectly are continually being brought to the start of the set ordering, forcing the population to deal with the cases it finds `difficult' by penalising individuals which fail on the `difficult' cases, similar to the subset approach in <ref> [Gathercole and Ross, 1994] </ref>. Simply evaluating each individual in each generation on the entire training set ignores the current abilities of the population which change with each generation, wasting a good resource, [Angeline and Pollack, 1993], and ignores information gained about the difficulty of cases in the training set.
Reference: [Gathercole and Ross, 1997] <author> Chris Gathercole and Peter Ross. </author> <title> Small populations over many generations can beat large populations over few generations in genetic programming. </title> <booktitle> In Genetic Programming 1997: Proceedings of the Second Annual Conference, </booktitle> <address> Stanford University, CA, USA, </address> <month> 13-16 July </month> <year> 1997. </year> <note> Elsewhere in this volume. </note>
Reference-contexts: This has worked well on some large classification problems, using less computer resources to produce better results than standard GP, <ref> [Gathercole and Ross, 1997] </ref>. 4 GP and the Even N Parity Problem The GP setup was kept simple, and Automatically Defined Functions (ADF) were not used. Generational replacement with elitism was used, with panmitic tournament selection of size 4, using population sizes from 100 to 800. <p> In runs on other problems, where GP without LEF was able to find optimal solutions, GP with LEF requires roughly the same or fewer fitness evaluations, <ref> [Gathercole and Ross, 1997] </ref>. GP runs are frequently limited by computer memory capacity, with an upper limit on population size. Parsimony provides pressure to select smaller trees. LEF allows much smaller population sizes to be used effectively, so the CPU can run more efficiently, albeit requiring many more generations. <p> Many of them perform badly, impeding GP rather than helping it. Hopefully the values used here, and the reasoning behind them, will transfer satisfactorily to other problems. (A slightly different approach to finding reasonable LEF parameters can be found in <ref> [Gathercole and Ross, 1997] </ref>). However, it is not yet obvious how to use LEF sensibly with symbolic regression problems since the error term is not as straightforward as the number of misclassifications.
Reference: [Goldberg and Richardson, 1987] <author> David E. Goldberg and Jon Richardson. </author> <title> Genetic algorithms with sharing for multimodal function optimization. </title> <booktitle> In Genetic Algorithms and their Applications: Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> pages 41-49. </pages> <publisher> Lawrence Erlbaum, </publisher> <year> 1987. </year>
Reference-contexts: This links quite closely with the idea of fitness sharing and `niches' used by Goldberg and Richardson, where functionally similar individuals have their fitnesses reduced, favouring individuals which have unique abilities, <ref> [Goldberg and Richardson, 1987] </ref>. Greene and Smith make a much more explicit use of niches, [Greene and Smith, 1993]. Individuals are ranked according to their `discriminability', i.e. the ability to differentiate examples correctly.
Reference: [Greene and Smith, 1993] <author> David Perry Greene and Stephen F. Smith. </author> <title> Competition-based induction of decision models from examples. </title> <booktitle> Machine Learning, </booktitle> <address> 13:229, </address> <year> 1993. </year>
Reference-contexts: This links quite closely with the idea of fitness sharing and `niches' used by Goldberg and Richardson, where functionally similar individuals have their fitnesses reduced, favouring individuals which have unique abilities, [Goldberg and Richardson, 1987]. Greene and Smith make a much more explicit use of niches, <ref> [Greene and Smith, 1993] </ref>. Individuals are ranked according to their `discriminability', i.e. the ability to differentiate examples correctly. Moving sequentially through this ordering, each training example is allocated to the first individual which correctly differentiates it.
Reference: [Hillis, 1990] <author> W. D. Hillis. </author> <title> Co-evolving parasites improve simulated evolution as an optimization procedure. </title> <type> Technical Report TR-1 AE91-1, </type> <institution> Thinking Machines Corporation, </institution> <year> 1990. </year> <note> (Appeared in Physica D42 [1990]: pp. 228-234). </note>
Reference-contexts: Hillis in particular reports very similar dynamics to LEF, using two spatially distributed populations, where the fitness of an individual in one population is based on how well it confounds an individual at the same location in the other population, <ref> [Hillis, 1990] </ref>. One population, the `hosts', is evolving minimal sorting networks, whilst the other population, the `parasites', is evolving difficult subsets of training cases, where the success of a training subset represents a failure of a sorting network and vice versa. <p> With LEF, on the other hand, the population is continually being moved away from such a stasis and prevented from converging. A very similar effect occurs in co-evolving populations, <ref> [Hillis, 1990] </ref>. If the error limit is raised (because the BOGI exceeds the error limit), a wider variety of individuals in the next generation will have good fitness scores, which increases the possibility that a new tree will be produced which can `break out' of the current sub-optimal situation.
Reference: [Koza, 1992] <author> J.R. Koza. </author> <title> Genetic Programming: on the Programming of Computers by means of Natural Selection. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: However, the main aim of this paper is to show the possibly beneficial impact of LEF on a standard GP, and not to optimise all of the many GP parameters. The Even N Parity problem has been used by Koza as a problem which causes difficulties for GP in <ref> [Koza, 1992] </ref>: The parity family of functions is a very difficult family of functions to learn. <p> At this point, Koza then demonstrates the power and might of Automatically Defined Functions (ADF) which he uses to successfully solve the Even N Parity problem up to N=6, <ref> [Koza, 1992] </ref>, and up to N=11, [Koza, 1994], but using large population sizes of 4000, taking roughly 20 generations for N=6. ADF is a more powerful representation, particularly suited to the structure inherent in the Boolean Even N Parity problem, allowing GP to construct hierarchical function definitions. <p> LEF is a fitness function based on an error limit and an ordered set of training examples. The problem set for GP in this paper is the Even N Parity problem, taken from <ref> [Koza, 1992, Koza, 1994] </ref>, which increases rapidly in difficulty and solution size for GP with increasing N.
Reference: [Koza, 1994] <editor> J.R. Koza. </editor> <booktitle> Genetic Programming II:. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: At this point, Koza then demonstrates the power and might of Automatically Defined Functions (ADF) which he uses to successfully solve the Even N Parity problem up to N=6, [Koza, 1992], and up to N=11, <ref> [Koza, 1994] </ref>, but using large population sizes of 4000, taking roughly 20 generations for N=6. ADF is a more powerful representation, particularly suited to the structure inherent in the Boolean Even N Parity problem, allowing GP to construct hierarchical function definitions. <p> LEF is a fitness function based on an error limit and an ordered set of training examples. The problem set for GP in this paper is the Even N Parity problem, taken from <ref> [Koza, 1992, Koza, 1994] </ref>, which increases rapidly in difficulty and solution size for GP with increasing N.
Reference: [Rosin and Belew, 1995] <author> Christopher D. Rosin and Richard K. Belew. </author> <title> Finding opponents worth beating: Methods for competitive co-evolution. </title> <booktitle> In Proceedings of the 6th International Conference on Genetic Algorithms, </booktitle> <year> 1995. </year>
Reference-contexts: Rosin and Belew also co-evolve populations, using a globally calculated fitness and `fitness sharing' which depends on the difficulty of an individual's successes, i.e. the more individuals which share a success, the less important or difficult that success is, <ref> [Rosin and Belew, 1995] </ref>. This links quite closely with the idea of fitness sharing and `niches' used by Goldberg and Richardson, where functionally similar individuals have their fitnesses reduced, favouring individuals which have unique abilities, [Goldberg and Richardson, 1987].
Reference: [Ryan, 1994] <editor> Conor Ryan. Pygmies and civil servants. In Kenneth E. Kinnear, Jr., editor, </editor> <booktitle> Advances in Genetic Programming, chapter 11. </booktitle> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: However, once the BOGI stops improving, the fitness function is adjusted by altering the error limit and re-ordering the training set, subjecting the population to different selection criteria. GP runs (without LEF) very often converge prematurely <ref> [Ryan, 1994] </ref> and, once they reach such a stasis, are extremely unlikely ever to break out of it and produce fitter individuals. With LEF, on the other hand, the population is continually being moved away from such a stasis and prevented from converging.
References-found: 11

