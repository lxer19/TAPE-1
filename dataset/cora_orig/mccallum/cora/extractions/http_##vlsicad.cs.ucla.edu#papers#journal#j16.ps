URL: http://vlsicad.cs.ucla.edu/papers/journal/j16.ps
Refering-URL: http://vlsicad.cs.ucla.edu/pubs.html
Root-URL: http://www.cs.ucla.edu
Email: Email: hu@cs.ucsd.edu, abk@cs.ucla.edu, tsao@cs.ucla.edu  
Phone: Tel. 310-206-7073  Tel. 619-534-3854  
Title: Old Bachelor Acceptance: A New Class of Non-Monotone Threshold Accepting Methods  
Author: T. C. Hu Andrew B. Kahng and Chung-Wen Albert Tsao 
Address: Los Angeles, CA 90024-1596  La Jolla, CA 92093-0114  
Affiliation: UCLA Dept. of Computer Science,  UCSD CS&E Dept.,  
Abstract: Stochastic hill-climbing algorithms, particularly simulated annealing (SA) and threshold acceptance (TA), have become very popular for global optimization applications. Typical implementations of SA or TA use monotone temperature or threshold schedules, and are not formulated to accommodate practical time limits. We present a new threshold acceptance strategy called Old Bachelor Acceptance (OBA) which has three distinguishing features: (i) it is specifically motivated by the practical requirement of optimization within a prescribed time bound, (ii) the threshold schedule is self-tuning, and (iii) the threshold schedule is non-monotone, with threshold values even allowed to become negative. The standard implementation of the TA method of Dueck and Scheuer is a special case of OBA. Experiments using several classes of symmetric traveling salesman problem instances show that OBA can outperform previous hill-climbing methods for time-critical optimizations. A number of directions for future work are suggested. Given a set S of feasible solutions and a real-valued cost function f : S ! &lt;, global optimization may without loss of generality be formulated as the search for a global minimizer s 2 S such that f (s) f (s 0 ) 8s 0 2 S. Typically, jSj is very large compared to the number of solutions that can be examined in practice. For small instances of certain global optimizations, implicit enumeration (e.g., branch-and-bound) or polyhedral approaches can prune the solution space and afford solutions within practical time limits; other problem formulations may be tractable to problem-specific methods. However, many important global optimization formulations (both discrete and continuous) are not only NP-hard [8], but also have no known problem-specific solution methods. Therefore, general-purpose heuristics are of interest. In this paper, we present a new class of stochastic hill-climbing heuristics for global optimizations; we call this new strategy Old Bachelor Acceptance (OBA). Our discussion opens in Section 1 with a characterization of iterative, stochastic hill-climbing heuristics; these are usually superior to greedy methods in that they can probabilistically escape from locally optimal solutions. The leading examples of stochastic hill-climbing algorithms the simulated annealing (SA) approach of Kirkpatrick et al. [25] and Cerny [6], along with the threshold acceptance approach of Dueck and Scheuer [7] have gained wide popularity due to the quality of the 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. H. L. Aarts and J. Korst, </author> <year> 1989. </year> <title> Simulated Annealing and Boltzmann Machines: a Stochastic Approach to Combinatorial Optimization and Neural Computing, </title> <publisher> Wiley, </publisher> <address> New York. </address>
Reference-contexts: In other words, SA is optimal in the limit of infinite time <ref> [1] </ref>. Althofer and Koschnick [2] argue that each execution of SA lies in some sense within the convex hull of a set of TA executions, and that TA is therefore also provably good. However, this convergence result is slightly weaker than those established for SA. <p> However, this convergence result is slightly weaker than those established for SA. Finally, the practical utility of stochastic hill-climbing is well-documented, with the SA algorithm now being one of the most widely used heuristics for global optimization <ref> [1] </ref>. Thus, it is noteworthy that Dueck and Scheuer [7] claim that their TA method "yields better results than SA" with respect to both CPU time and the number of "new state choice steps" (i.e., applications of Rule 1), a standard measure of runtime complexity. <p> Two classes of TSP instances were considered: (i) Euclidean planar instances corresponding to random pointsets drawn from a uniform distribution in the Euclidean unit square; and (ii) random instances having symmetric distance matrices with each intercity distance drawn from a uniform distribution in <ref> [0; 1] </ref>. These are the two most commonly treated classes of TSP, and in some sense represent limiting cases with respect to "metricity" of the TSP instance. (We also studied a class of hierarchical TSP instances, which reflect a clustered, non-uniform distribution of points in the Euclidean plane.
Reference: [2] <author> I. Althofer and K. U. Koschnick, </author> <year> 1991. </year> <title> On the Convergence of Threshold Accepting, </title> <journal> Applied Mathematics and Optimization 24, </journal> <pages> 183-195. </pages>
Reference-contexts: In other words, SA is optimal in the limit of infinite time [1]. Althofer and Koschnick <ref> [2] </ref> argue that each execution of SA lies in some sense within the convex hull of a set of TA executions, and that TA is therefore also provably good. However, this convergence result is slightly weaker than those established for SA. <p> Recent work by Boese, Kahng and Tsao [4] has confirmed the dependence on CPU limit of general annealing schedules; the reader is also referred to the work of Strenski and Kirkpatrick [33] and Althofer and Koschnick <ref> [2] </ref>, which we discuss later in this section.] Second, current SA and TA implementations are "blind" to the specific features of the cost surface in any given optimization instance. <p> Hajek and Sasaki [13] show that a class of cost surfaces exists for which optimal schedules are non-monotone. Finally, Althofer and Koschnick <ref> [2] </ref> enumerate optimal TA schedules for a small cost surface and find clear evidence (Table 4.1 in [2]) of non-monotonicity; however, the authors surprisingly make no comment on this data. Our own investigations [4] support these previous studies. <p> Hajek and Sasaki [13] show that a class of cost surfaces exists for which optimal schedules are non-monotone. Finally, Althofer and Koschnick <ref> [2] </ref> enumerate optimal TA schedules for a small cost surface and find clear evidence (Table 4.1 in [2]) of non-monotonicity; however, the authors surprisingly make no comment on this data. Our own investigations [4] support these previous studies. <p> Thus, special cases of OBA will enjoy the same convergence properties shown for TA in <ref> [2] </ref>. 2.3 OBA Variants Via the threshold update functions incr (T i ) and decr (T i ), the template of Figure 5 captures many possible strategies. We have typically based decr and incr on the following factors: 8 1.
Reference: [3] <author> E. B. Baum, </author> <year> 1986. </year> <title> Iterated Descent: a Better Algorithm for Local Search in Combinatorial Optimization Problems, </title> <type> Technical Report 164-30, </type> <institution> Crellin Laboratory, California Institute of Technology, Pasadena, </institution> <address> CA 91125. </address> <month> 18 </month>
Reference-contexts: Note that a "history-dependent" Rule 1 0 might be, for example: Given the history of solutions evaluated thus far, generate a new trial solution s 0 . Such a Rule 1 0 accommodates such methods as iterated descent <ref> [3] </ref> and tabu search [10], which more systematically exploit information about the recent history of solutions, e.g., whether the current solution has been previously visited, whether the current solution is known to be a local optimum, etc. (see also the heuristic search techniques used in artificial intelligence [29]). <p> Moreover, central limit phenomena in the cost surface <ref> [3] </ref> imply that as problems grow large, random local minima are almost surely of "average" quality, so that simple "multi-start" heuristics [31] fail. For details on this subject, the reader is referred to discussions by Baum [3] and Kirkpatrick and Toulouse [26] on traveling salesman structures; by Kauffman and Levin [23] <p> Moreover, central limit phenomena in the cost surface <ref> [3] </ref> imply that as problems grow large, random local minima are almost surely of "average" quality, so that simple "multi-start" heuristics [31] fail. For details on this subject, the reader is referred to discussions by Baum [3] and Kirkpatrick and Toulouse [26] on traveling salesman structures; by Kauffman and Levin [23] on evolutionary optimization for "adaptive landscapes"; and by Bui et al. [5] and Hagen and Kahng [11]) for graph partitioning. <p> We note that our broader experiments have also confirmed the strength of Dueck and Scheuer's original TA method: for example, our implementations of OBA variants corresponding to the steepest ascent-descent [27] and iterated descent <ref> [3] </ref> approaches exhibited noticeably poorer performance than TA [22]. This is an indication of the sensitivity of multi-start and iterated greedy approaches with respect to input parameters. <p> A more careful investigation of the OBA2 N strategy seems warranted since OBA2 N is clearly the best variant that we report here; recall that OBA2 N is suggestive of the "steepest descent, mildest ascent" strategy proposed by Hansen and Jaumard [14] (see also the discussions in <ref> [3] </ref> [15]). (iii) Recall from above that OBAx N will always dominate the OBAx variant on "real" cost surfaces, the example of Figure 4 notwithstanding.
Reference: [4] <author> K. D. Boese, A. B. Kahng and C.-W. A. Tsao, </author> <year> 1993. </year> <title> Best-So-Far vs. Where-You-Are: New Perspectives on Simulated Annealing for CAD, </title> <booktitle> Proc. European Design Automation Conference, </booktitle> <pages> 78-83. </pages>
Reference-contexts: Recent work by Boese, Kahng and Tsao <ref> [4] </ref> has confirmed the dependence on CPU limit of general annealing schedules; the reader is also referred to the work of Strenski and Kirkpatrick [33] and Althofer and Koschnick [2], which we discuss later in this section.] Second, current SA and TA implementations are "blind" to the specific features of the <p> Finally, Althofer and Koschnick [2] enumerate optimal TA schedules for a small cost surface and find clear evidence (Table 4.1 in [2]) of non-monotonicity; however, the authors surprisingly make no comment on this data. Our own investigations <ref> [4] </ref> support these previous studies. Moreover, we have found that the non-monotonicity of the known optimal schedules does not seem to be an artifact of the small size of jSj relative to the available time M in these studies. <p> Our preliminary work <ref> [4] </ref> indicates that such studies may lead to additional justifications for the non-monotone approach to stochastic hill-climbing. 17 0.9 1.1 1.3 1.5 1.7 normalized tour cost i/4000 Average performance vs.
Reference: [5] <author> T. N. Bui, S. Chauduri, F. T. Leighton and M. Sipser, </author> <year> 1987. </year> <title> Graph Bisection Algorithms with Good Average Case Behavior, </title> <type> Combinatorica 7(2), </type> <pages> 171-191. </pages>
Reference-contexts: For details on this subject, the reader is referred to discussions by Baum [3] and Kirkpatrick and Toulouse [26] on traveling salesman structures; by Kauffman and Levin [23] on evolutionary optimization for "adaptive landscapes"; and by Bui et al. <ref> [5] </ref> and Hagen and Kahng [11]) for graph partitioning.
Reference: [6] <author> V. Cerny, </author> <year> 1985. </year> <title> Thermodynamical Approach to the Traveling Salesman Problem: an Efficient Simulation Algorithm, </title> <journal> Journal of Optimization Theory and Applications 45(1), </journal> <pages> 41-51. </pages>
Reference-contexts: The first such method, simulated annealing (SA), was proposed independently by Kirkpatrick et al. [25] and Cerny <ref> [6] </ref> and is motivated by analogies between the solution space of an optimization instance and microstates of a statistical thermodynamical ensemble. Figure 2 summarizes the SA algorithm, which uses the following criteria for Rule 2.
Reference: [7] <author> G. Dueck and T. Scheuer, </author> <year> 1990. </year> <title> Threshold Accepting: A General Purpose Optimization Algorithm Appearing Superior to Simulated Annealing, </title> <journal> Journal of Computational Physics 90, </journal> <pages> 161-175. </pages>
Reference-contexts: T i+1 = next (T i ); 8. Return s i , 0 i M , such that f (s i ) is minimum. Another stochastic hill-climbing heuristic called threshold acceptance (TA), which uses a different Rule 2 criterion (Figure 3), has recently been proposed by Dueck and Scheuer <ref> [7] </ref>. TA relies on a threshold, T i , which defines the maximum disimprovement f (s 0 ) f (s i ) that is acceptable at the current iteration. All disimprovements greater than T i are rejected, while all that are less than T i are accepted. <p> decrease in T i is accomplished by next (T i ), which is a heuristic function of the T i value and the number of iterations since the last cost function improvement. (Typically, next (T i ) tries to achieve "thermodynamic equilibrium" at each temperature value.) Similarly, implementations of TA <ref> [7] </ref> begin with a large initial threshold T 0 which decreases monotonically to T M = 0. <p> However, this convergence result is slightly weaker than those established for SA. Finally, the practical utility of stochastic hill-climbing is well-documented, with the SA algorithm now being one of the most widely used heuristics for global optimization [1]. Thus, it is noteworthy that Dueck and Scheuer <ref> [7] </ref> claim that their TA method "yields better results than SA" with respect to both CPU time and the number of "new state choice steps" (i.e., applications of Rule 1), a standard measure of runtime complexity. Experimental results are presented in [7] which support this claim. <p> Thus, it is noteworthy that Dueck and Scheuer <ref> [7] </ref> claim that their TA method "yields better results than SA" with respect to both CPU time and the number of "new state choice steps" (i.e., applications of Rule 1), a standard measure of runtime complexity. Experimental results are presented in [7] which support this claim. A further practical advantage of TA is its greater simplicity of Rule 2, with no exponentiation or random number generation being required. <p> For TA, the authors of <ref> [7] </ref> state that the "trivial" threshold schedule (linear in i, with T i = T 0 fl (1 i M )) is "essentially best", and suggest that the 5 performance of TA is basically insensitive to the threshold schedule. Indeed, the successful results reported in [7] were obtained using monotone threshold <p> For TA, the authors of <ref> [7] </ref> state that the "trivial" threshold schedule (linear in i, with T i = T 0 fl (1 i M )) is "essentially best", and suggest that the 5 performance of TA is basically insensitive to the threshold schedule. Indeed, the successful results reported in [7] were obtained using monotone threshold schedules. However, despite the tremendous success of both SA and TA, certain observations motivate the study of alternative hill-climbing strategies. First, standard implementations of SA and TA are not amenable to a priori specification of CPU limits. <p> update functions decr (T i ) = incr (T i ), then OBA can be made equivalent to the TA method of Dueck and Scheuer (e.g., using the constant functions decr (T i ) = incr (T i ) = T 0 M yields the "trivial" threshold schedule recommended in <ref> [7] </ref>). Thus, special cases of OBA will enjoy the same convergence properties shown for TA in [2]. 2.3 OBA Variants Via the threshold update functions incr (T i ) and decr (T i ), the template of Figure 5 captures many possible strategies. <p> We believe that the OBA paradigm provides a powerful and general template for exploration of such non-monotone heuristics. Indeed, a number of previous strategies, including multi-start [31], steepest ascent-descent [27], and even the TA algorithm <ref> [7] </ref>, may all be captured within the unifying OBA paradigm. 15 n = 50, M = 5i = 0:4 fi 10 6 Algorithm f (s i ) f (s 2i ) f (s 3i ) f (s 4i ) f (s 5i ) OBA1 0.966 0.928 0.908 0.893 0.889 OBA2 0.925
Reference: [8] <author> M. R. Garey and D. S. Johnson, </author> <year> 1979. </year> <title> Computers and Intractability: A Guide to the Theory of NP Completeness, </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> San Francisco. </address>
Reference: [9] <author> F. Glover, </author> <year> 1986. </year> <title> Future Paths for Integer Programming and Links to Artificial Intelligence, </title> <journal> Computers and Operations Research 13(5), </journal> <pages> 533-549, </pages>
Reference-contexts: A number of other authors have also touched on the issue of non-monotonicity in annealing. In particular, Glover <ref> [9] </ref> suggests in a very general way that some sort of nonmonotonicity would improve the performance of heuristic search procedures. Very recently, Osman [28] has reported very effective simulated annealing approaches with non-monotone cooling schedule; these significantly outperform other SA implementations that use cooling schedules.
Reference: [10] <author> F. Glover, </author> <year> 1989. </year> <title> Tabu Search Part I, </title> <journal> ORSA J. on Computing 1, </journal> <pages> 190-206. </pages>
Reference-contexts: Note that a "history-dependent" Rule 1 0 might be, for example: Given the history of solutions evaluated thus far, generate a new trial solution s 0 . Such a Rule 1 0 accommodates such methods as iterated descent [3] and tabu search <ref> [10] </ref>, which more systematically exploit information about the recent history of solutions, e.g., whether the current solution has been previously visited, whether the current solution is known to be a local optimum, etc. (see also the heuristic search techniques used in artificial intelligence [29]).
Reference: [11] <author> L. Hagen and A. B. Kahng, </author> <year> 1992. </year> <title> New Spectral Methods for Ratio Cut Partitioning and Clustering, </title> <journal> IEEE Trans. on CAD 11(9), </journal> <pages> 1074-1085. </pages>
Reference-contexts: For details on this subject, the reader is referred to discussions by Baum [3] and Kirkpatrick and Toulouse [26] on traveling salesman structures; by Kauffman and Levin [23] on evolutionary optimization for "adaptive landscapes"; and by Bui et al. [5] and Hagen and Kahng <ref> [11] </ref>) for graph partitioning. In view of these factors, global optimization heuristics must escape from local minima to adequately explore the solution space of large problems. 1.2 Stochastic Hill-Climbing: SA and TA Stochastic hill-climbing methods escape from local minima in the cost surface by probabilistically accepting disimprovements, or "uphill moves".
Reference: [12] <author> B. Hajek, </author> <year> 1988. </year> <title> Cooling Schedules for Optimal Annealing, </title> <journal> Mathematics of Operations Research 13, </journal> <pages> 311-329. </pages>
Reference-contexts: For SA, the thermodynamic analogy, as well as the convergence proof based on Gibbs-Boltzmann statistics, together motivate the following intuition <ref> [12] </ref>: monotone temperature schedules allow annealing to explore "large features" of the cost surface at high T , and then perform finer optimization at lower T .
Reference: [13] <author> B. Hajek and G. Sasaki, </author> <year> 1989. </year> <title> Simulated Annealing To Cool or Not, </title> <journal> Systems and Control Letters 12, </journal> <pages> 443-447. </pages>
Reference-contexts: Strenski and Kirkpatrick [33] have shown that "locally optimal" annealing schedules can be non-monotone for a small instance of the graph bisection problem that is highly structured to reduce the size of the solution space. Hajek and Sasaki <ref> [13] </ref> show that a class of cost surfaces exists for which optimal schedules are non-monotone. Finally, Althofer and Koschnick [2] enumerate optimal TA schedules for a small cost surface and find clear evidence (Table 4.1 in [2]) of non-monotonicity; however, the authors surprisingly make no comment on this data.
Reference: [14] <author> P. Hansen and B. Jaumard, </author> <year> 1990. </year> <title> Algorithms for the Maximum Satisfiability Problem, </title> <booktitle> Computing 44, </booktitle> <pages> 279-303. </pages>
Reference-contexts: The parameter c can be useful in determining the stage of the optimization at which a given granularity is applied.] In this way, OBA1 can capture the gamut of strategies from "steep descent, mild ascent" to "steep descent, steep ascent" (cf. the terminology of Hansen and Jaumard <ref> [14] </ref>). Two important points should be noted. First, OBA1 demonstrates that the new threshold value T i+1 does not have to be a function of the previous T i ; here, T i+1 is completely determined by age, the current timestep i, and the parameterization of the algorithm. <p> OBA2. The OBA2 variant (Figure 7) recalls the "steepest descent, mildest ascent" strategy proposed by Hansen and Jaumard described in <ref> [14] </ref>. In contrast to OBA1, the new threshold T i+1 in OBA2 depends on the previous value T i . <p> A more careful investigation of the OBA2 N strategy seems warranted since OBA2 N is clearly the best variant that we report here; recall that OBA2 N is suggestive of the "steepest descent, mildest ascent" strategy proposed by Hansen and Jaumard <ref> [14] </ref> (see also the discussions in [3] [15]). (iii) Recall from above that OBAx N will always dominate the OBAx variant on "real" cost surfaces, the example of Figure 4 notwithstanding.
Reference: [15] <author> D. S. Johnson, </author> <year> 1990. </year> <title> Local Optimization and the Traveling Salesman Problem, </title> <booktitle> Proc. of the 17th International Colloquium on Automata, Languages and Programming, </booktitle> <pages> 446-460. </pages>
Reference-contexts: A more careful investigation of the OBA2 N strategy seems warranted since OBA2 N is clearly the best variant that we report here; recall that OBA2 N is suggestive of the "steepest descent, mildest ascent" strategy proposed by Hansen and Jaumard [14] (see also the discussions in [3] <ref> [15] </ref>). (iii) Recall from above that OBAx N will always dominate the OBAx variant on "real" cost surfaces, the example of Figure 4 notwithstanding.
Reference: [16] <author> D. S. Johnson and C. R. Aragon, L. A. McGeoch and C. Schevon, </author> <year> 1989. </year> <title> Optimization by Simulated Annealing: An Experimental Evaluation; Part I, Graph Partitioning, </title> <journal> Operations Research 37(6), </journal> <pages> 865-892. 19 </pages>
Reference-contexts: Greed has been widely employed because of its simplicity and its acceptable success in a variety of implementations, e.g., Johnson et al. <ref> [16] </ref> [17] have documented the utility of greed for several hard combinatorial problems. However, the performance of greedy methods is erratic, and achieving "stable" - i.e., predictable performance requires multiple random initial starting solutions. Johnson et al. [16] have determined that several thousand initial random starting configurations are necessary for greed <p> and its acceptable success in a variety of implementations, e.g., Johnson et al. <ref> [16] </ref> [17] have documented the utility of greed for several hard combinatorial problems. However, the performance of greedy methods is erratic, and achieving "stable" - i.e., predictable performance requires multiple random initial starting solutions. Johnson et al. [16] have determined that several thousand initial random starting configurations are necessary for greed to afford stable solution quality for graph bisection instances of size n = 500; this number grows rapidly with n and becomes hopeless for instance sizes of, e.g., n = 100; 000 which arise in arenas such
Reference: [17] <author> D. S. Johnson, C. R. Aragon, L. A. McGeoch and C. Schevon, </author> <year> 1991. </year> <title> Optimization by Simulated Annealing: An Experimental Evaluation; Part II, Graph Coloring and Number Partitioning, </title> <journal> Operations Research 39(3), </journal> <pages> 378-406. </pages>
Reference-contexts: Typically, the set N (s) consists of slight perturbations of the current solution s, for example, via the 2-interchange operator for the traveling salesman problem [18] or the pair-swap operator for graph bisection <ref> [17] </ref>. When the size of N (s) is constant for all s 2 S, we denote the neighborhood size by jN j. <p> Greed has been widely employed because of its simplicity and its acceptable success in a variety of implementations, e.g., Johnson et al. [16] <ref> [17] </ref> have documented the utility of greed for several hard combinatorial problems. However, the performance of greedy methods is erratic, and achieving "stable" - i.e., predictable performance requires multiple random initial starting solutions.
Reference: [18] <author> D. S. Johnson, C. R. Aragon, L. A. McGeoch and C. Schevon, </author> <year> 1995. </year> <title> Optimization by Simulated Annealing: an Experimental Evaluation; Part III, the Traveling Salesman Problem, </title> <journal> Operations Research, forthcoming. </journal>
Reference-contexts: Typically, the set N (s) consists of slight perturbations of the current solution s, for example, via the 2-interchange operator for the traveling salesman problem <ref> [18] </ref> or the pair-swap operator for graph bisection [17]. When the size of N (s) is constant for all s 2 S, we denote the neighborhood size by jN j. <p> In practice, Rule 1 simply picks a random s 0 2 N (s i ) from within "obvious" neighborhood structures such as those noted for the TSP and graph bisection problems <ref> [18] </ref>. Therefore, it is Rule 2 which determines the nature of an optimization heuristic as it traverses the cost surface. A simple instance of Rule 2 is, "Replace s i by s 0 if f (s 0 ) &lt; f (s i )," which corresponds to greedy optimization.
Reference: [19] <author> A. B. Kahng, </author> <year> 1992. </year> <title> Exploiting Fractalness in Error Surfaces: New Methods for Neural Network Learning, </title> <booktitle> Proc. IEEE Intl. Symp. on Circuits and Systems, </booktitle> <pages> 41-44. </pages>
Reference-contexts: A finite time limit M will obviate the theoretical convergence results, and also reflect practical requirements for optimization. Experimental results [21] <ref> [19] </ref> for large discrete and continuous global optimizations show that optimal annealing schedules vary strongly with the time limit M , but it is not clear how next (T i ) should be defined to accommodate finite M . [The results in [21] and [19] are with respect to single-temperature annealing <p> Experimental results [21] <ref> [19] </ref> for large discrete and continuous global optimizations show that optimal annealing schedules vary strongly with the time limit M , but it is not clear how next (T i ) should be defined to accommodate finite M . [The results in [21] and [19] are with respect to single-temperature annealing schedules, which were used in order to reduce the number of degrees of freedom in the experiment. <p> Previous work [21] <ref> [19] </ref> [20] [32] has shown that large, real-world cost surfaces exhibit strong fits to models of self-similar random structure (e.g., VLSI placement problems have hierarchical scaling properties which resemble high-dimensional fractional Brownian motions [32]). <p> Intuitively, age reflects the OBA algorithm's current perception of local structure in the cost surface: increasing age implies greater likelihood that s i is a local minimum, and that the threshold should increase faster. 2. The amount of time remaining, M i. Since previous work <ref> [19] </ref> [20] has observed strong dependence of optimal hill-climbing strategies on the time bound M , we may allow decr and incr to depend on the proportion of time used, i=M . 3. The current threshold value T i .
Reference: [20] <author> A. B. Kahng, </author> <year> 1992. </year> <title> Random Structure of Error Surfaces: New Stochastic Learning Methods, </title> <booktitle> Proc. SPIE Conf. on Neural Networks and Optimization 1710(pt. </booktitle> <volume> 1, </volume> <pages> vol.2), 768-779. </pages>
Reference-contexts: Previous work [21] [19] <ref> [20] </ref> [32] has shown that large, real-world cost surfaces exhibit strong fits to models of self-similar random structure (e.g., VLSI placement problems have hierarchical scaling properties which resemble high-dimensional fractional Brownian motions [32]). <p> The parameters of such fitted models vary with the individual problem instances, and again, evidence suggests that optimal hill-climbing schedules should be tuned to these parameters <ref> [20] </ref>. These two observations prompt a variety of questions and simple experiments. Consider the BSF performance of TA from random starting solutions in the one-dimensional cost surface of Figure 4 (six solutions s i , each with two neighbors). <p> Intuitively, age reflects the OBA algorithm's current perception of local structure in the cost surface: increasing age implies greater likelihood that s i is a local minimum, and that the threshold should increase faster. 2. The amount of time remaining, M i. Since previous work [19] <ref> [20] </ref> has observed strong dependence of optimal hill-climbing strategies on the time bound M , we may allow decr and incr to depend on the proportion of time used, i=M . 3. The current threshold value T i .
Reference: [21] <author> A. B. Kahng and G. Robins, </author> <year> 1990. </year> <title> On Structure and Randomness in Practical Optimization, </title> <institution> UCLA Computer Science Department 1990-1991 Annual, </institution> <month> 23-38. </month>
Reference-contexts: A finite time limit M will obviate the theoretical convergence results, and also reflect practical requirements for optimization. Experimental results <ref> [21] </ref> [19] for large discrete and continuous global optimizations show that optimal annealing schedules vary strongly with the time limit M , but it is not clear how next (T i ) should be defined to accommodate finite M . [The results in [21] and [19] are with respect to single-temperature <p> Experimental results <ref> [21] </ref> [19] for large discrete and continuous global optimizations show that optimal annealing schedules vary strongly with the time limit M , but it is not clear how next (T i ) should be defined to accommodate finite M . [The results in [21] and [19] are with respect to single-temperature annealing schedules, which were used in order to reduce the number of degrees of freedom in the experiment. <p> Previous work <ref> [21] </ref> [19] [20] [32] has shown that large, real-world cost surfaces exhibit strong fits to models of self-similar random structure (e.g., VLSI placement problems have hierarchical scaling properties which resemble high-dimensional fractional Brownian motions [32]). <p> We hope to show that this dominance always holds within, e.g., the structural models of cost surfaces proposed in [32] <ref> [21] </ref>. (iv) We would like to extend the hill-climbing optimization template to include non-degenerate history (i.e., memory) in the Rule 1 generation of s 0 .
Reference: [22] <author> A. B. Kahng and C. W. Tsao, </author> <year> 1992. </year> <title> Old Bachelor Acceptance: A New Class of Non-Monotone Threshold Acceptance Methods, </title> <institution> UCLA CSD TR-920040, Computer Science Department, UCLA. </institution>
Reference-contexts: Finally, the OBAx N variants are noticeably better than the corresponding OBAx variants; indeed, negative threshold values resulted in worse performance for all of the OBA variants that we tested <ref> [22] </ref>. <p> We note that our broader experiments have also confirmed the strength of Dueck and Scheuer's original TA method: for example, our implementations of OBA variants corresponding to the steepest ascent-descent [27] and iterated descent [3] approaches exhibited noticeably poorer performance than TA <ref> [22] </ref>. This is an indication of the sensitivity of multi-start and iterated greedy approaches with respect to input parameters.
Reference: [23] <author> S. Kauffman and S. Levin, </author> <year> 1987. </year> <title> Toward a General Theory of Adaptive Walks on Rugged Landscapes, </title> <journal> Journal of Theoretical Biology 128, </journal> <pages> 11-45. </pages>
Reference-contexts: For details on this subject, the reader is referred to discussions by Baum [3] and Kirkpatrick and Toulouse [26] on traveling salesman structures; by Kauffman and Levin <ref> [23] </ref> on evolutionary optimization for "adaptive landscapes"; and by Bui et al. [5] and Hagen and Kahng [11]) for graph partitioning.
Reference: [24] <author> B. Kernighan and S. Lin, </author> <year> 1970. </year> <title> An Efficient Heuristic Procedure for Partitioning Graphs, </title> <journal> The Bell System Tech. Journal 49(2), </journal> <pages> 291-307. </pages>
Reference-contexts: Intuitively, this is an appropriate granularity for the TSP optimization. The same value was also used as the initial temperature of the TA. Here, we fix at a representative value.) 3. Our Rule 1 corresponds to the popular Lin 2-opt neighborhood structure <ref> [24] </ref>, wherein a neighbor solution s 0 is generated by deleting a random pair of edges in s i and then reconnecting the two paths to achieve the "other" possible tour.
Reference: [25] <author> S. Kirkpatrick, C. D. Gelatt, Jr. and M. Vecchi, </author> <year> 1983. </year> <title> Optimization by Simulated Annealing, </title> <booktitle> Science 220(4598), </booktitle> <pages> 671-680. </pages>
Reference-contexts: The first such method, simulated annealing (SA), was proposed independently by Kirkpatrick et al. <ref> [25] </ref> and Cerny [6] and is motivated by analogies between the solution space of an optimization instance and microstates of a statistical thermodynamical ensemble. Figure 2 summarizes the SA algorithm, which uses the following criteria for Rule 2.
Reference: [26] <author> S. Kirkpatrick and G. Toulouse, </author> <year> 1985. </year> <title> Configuration Space Analysis of Traveling Salesman Problems, </title> <journal> Journal de Physique 46, </journal> <pages> 1277-1292. </pages>
Reference-contexts: Moreover, central limit phenomena in the cost surface [3] imply that as problems grow large, random local minima are almost surely of "average" quality, so that simple "multi-start" heuristics [31] fail. For details on this subject, the reader is referred to discussions by Baum [3] and Kirkpatrick and Toulouse <ref> [26] </ref> on traveling salesman structures; by Kauffman and Levin [23] on evolutionary optimization for "adaptive landscapes"; and by Bui et al. [5] and Hagen and Kahng [11]) for graph partitioning.
Reference: [27] <author> J. B. Lasserre, P. P. Varaiya and J. Walrand, </author> <year> 1987. </year> <title> Simulated Annealing, Random Search, Multi-Start or SAD?, </title> <journal> Systems and Control Letters 8, </journal> <pages> 297-301. </pages>
Reference-contexts: We believe that the OBA paradigm provides a powerful and general template for exploration of such non-monotone heuristics. Indeed, a number of previous strategies, including multi-start [31], steepest ascent-descent <ref> [27] </ref>, and even the TA algorithm [7], may all be captured within the unifying OBA paradigm. 15 n = 50, M = 5i = 0:4 fi 10 6 Algorithm f (s i ) f (s 2i ) f (s 3i ) f (s 4i ) f (s 5i ) OBA1 0.966 <p> We note that our broader experiments have also confirmed the strength of Dueck and Scheuer's original TA method: for example, our implementations of OBA variants corresponding to the steepest ascent-descent <ref> [27] </ref> and iterated descent [3] approaches exhibited noticeably poorer performance than TA [22]. This is an indication of the sensitivity of multi-start and iterated greedy approaches with respect to input parameters.
Reference: [28] <author> I. H. Osman, </author> <year> 1983. </year> <title> Metastrategy simulated annealing and tabu search algorithms for the vehicle routing problem, </title> <journal> Annals of Operations Research 41, </journal> <pages> 421-451. </pages>
Reference-contexts: A number of other authors have also touched on the issue of non-monotonicity in annealing. In particular, Glover [9] suggests in a very general way that some sort of nonmonotonicity would improve the performance of heuristic search procedures. Very recently, Osman <ref> [28] </ref> has reported very effective simulated annealing approaches with non-monotone cooling schedule; these significantly outperform other SA implementations that use cooling schedules.
Reference: [29] <author> J. Pearl, </author> <year> 1984. </year> <title> Heuristics: Intelligent Search Strategies for Computer Problem Solving, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address> <month> 20 </month>
Reference-contexts: as iterated descent [3] and tabu search [10], which more systematically exploit information about the recent history of solutions, e.g., whether the current solution has been previously visited, whether the current solution is known to be a local optimum, etc. (see also the heuristic search techniques used in artificial intelligence <ref> [29] </ref>). These latter methods are beyond the scope of the present discussion.
Reference: [30] <author> Y. Rossier, M. Troyon and T. M. Liebling, </author> <year> 1986. </year> <title> Probabilistic Exchange Algorithms and Eu--clidean Traveling Salesman Problems, </title> <type> OR Spektrum 8(3), </type> <pages> 151-164. </pages>
Reference-contexts: Instance sizes ranged from n = 50 to n = 200; for these sizes, we considered CPU limits of between M = 0:4 fi 10 6 and M = 1:0 fi 10 6 applications of Rule 1, closely following the studies of Rossier et al. <ref> [30] </ref>. Since move generations and cost function evaluations dominate the runtimes of stochastic hill-climbing algorithms, the actual running time for OBA, SA, TA, etc. for any given value of M will be essentially identical.
Reference: [31] <author> F. Schoen, </author> <year> 1991. </year> <title> Stochastic Techniques for Global Optimization: A Survey of Recent Advances, </title> <editor> J. </editor> <booktitle> Global Optimization 1, </booktitle> <pages> 207-228. </pages>
Reference-contexts: Moreover, central limit phenomena in the cost surface [3] imply that as problems grow large, random local minima are almost surely of "average" quality, so that simple "multi-start" heuristics <ref> [31] </ref> fail. For details on this subject, the reader is referred to discussions by Baum [3] and Kirkpatrick and Toulouse [26] on traveling salesman structures; by Kauffman and Levin [23] on evolutionary optimization for "adaptive landscapes"; and by Bui et al. [5] and Hagen and Kahng [11]) for graph partitioning. <p> We believe that the OBA paradigm provides a powerful and general template for exploration of such non-monotone heuristics. Indeed, a number of previous strategies, including multi-start <ref> [31] </ref>, steepest ascent-descent [27], and even the TA algorithm [7], may all be captured within the unifying OBA paradigm. 15 n = 50, M = 5i = 0:4 fi 10 6 Algorithm f (s i ) f (s 2i ) f (s 3i ) f (s 4i ) f (s 5i
Reference: [32] <author> G. Sorkin, </author> <year> 1991. </year> <title> Efficient Simulated Annealing on Fractal Energy Landscapes, </title> <journal> Algorithmica 6(3), </journal> <pages> 367-418. </pages>
Reference-contexts: Previous work [21] [19] [20] <ref> [32] </ref> has shown that large, real-world cost surfaces exhibit strong fits to models of self-similar random structure (e.g., VLSI placement problems have hierarchical scaling properties which resemble high-dimensional fractional Brownian motions [32]). <p> Previous work [21] [19] [20] <ref> [32] </ref> has shown that large, real-world cost surfaces exhibit strong fits to models of self-similar random structure (e.g., VLSI placement problems have hierarchical scaling properties which resemble high-dimensional fractional Brownian motions [32]). The parameters of such fitted models vary with the individual problem instances, and again, evidence suggests that optimal hill-climbing schedules should be tuned to these parameters [20]. These two observations prompt a variety of questions and simple experiments. <p> We hope to show that this dominance always holds within, e.g., the structural models of cost surfaces proposed in <ref> [32] </ref> [21]. (iv) We would like to extend the hill-climbing optimization template to include non-degenerate history (i.e., memory) in the Rule 1 generation of s 0 .
Reference: [33] <author> P. Strenski and S. Kirkpatrick, </author> <year> 1991. </year> <title> Analysis of Finite Length Annealing Schedules, </title> <booktitle> Algorith-mica 6(3), </booktitle> <pages> 346-366. 21 </pages>
Reference-contexts: Recent work by Boese, Kahng and Tsao [4] has confirmed the dependence on CPU limit of general annealing schedules; the reader is also referred to the work of Strenski and Kirkpatrick <ref> [33] </ref> and Althofer and Koschnick [2], which we discuss later in this section.] Second, current SA and TA implementations are "blind" to the specific features of the cost surface in any given optimization instance. <p> Very recently, Osman [28] has reported very effective simulated annealing approaches with non-monotone cooling schedule; these significantly outperform other SA implementations that use cooling schedules. Strenski and Kirkpatrick <ref> [33] </ref> have shown that "locally optimal" annealing schedules can be non-monotone for a small instance of the graph bisection problem that is highly structured to reduce the size of the solution space. Hajek and Sasaki [13] show that a class of cost surfaces exists for which optimal schedules are non-monotone.
References-found: 33

