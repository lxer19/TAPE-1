URL: http://www.cs.princeton.edu/~min/report.ps.gz
Refering-URL: http://www.cs.princeton.edu/~min/tno.html
Root-URL: http://www.cs.princeton.edu
Note: Contents  
Abstract-found: 0
Intro-found: 1
Reference: [Atk92] <author> Phil Atkin. </author> <title> Paz object file specification. </title> <type> Technical report, </type> <institution> Division, </institution> <year> 1992. </year> <title> appendix K to the dVs v0.2 documentation. </title>
Reference-contexts: 3 5 vertex 0 1 3 5 Vertices 0, 1 and 2 are the same for both strips, but for n &gt; 2 triangle number n is built from vertices n 2, n 1 and n for a tristrip, and vertices n 2, n 1 and 0 for a polystrip <ref> [Atk92] </ref>. One object consists of one or more patches, and one patch of one or more strips. For the object and/or for specific patches several surface variables may be set. They are listed in Table 4.1 3 . <p> They are listed in Table 4.1 3 . In the SOS all variables are parsed and stored, but only variables COLOUR, COOKED and NORMALS are supported. An informal description of the PAZ file format is given in the dVS system documentation <ref> [Atk92] </ref>. In Appendix A a formal LL (1)-grammar of the PAZ file format in BNF is given, which was used to facilitate the implementation of a structured and easily extensible parser [Ter86]. 3 The table is copied from [Atk92] CHAPTER 4. <p> of the PAZ file format is given in the dVS system documentation <ref> [Atk92] </ref>. In Appendix A a formal LL (1)-grammar of the PAZ file format in BNF is given, which was used to facilitate the implementation of a structured and easily extensible parser [Ter86]. 3 The table is copied from [Atk92] CHAPTER 4.
Reference: [Fer87] <author> J.G. Ferwerda. </author> <title> A practical guide to stereo photography. 3-D Book Productions, </title> <booktitle> 2nd edition, </booktitle> <year> 1987. </year>
Reference-contexts: CHAPTER 2. VIRTUAL ENVIRONMENTS 10 display screens optics eyes computer HMD sensor optical axis Chapter 3 Stereoscopy 3.1 Background When human eyes look at an object in space, several factors contribute to the fact that they see a sharp, three-dimensional object [Hod92] <ref> [Fer87] </ref>. * The eyes turn towards the object: this is called convergence of view-lines, or convergence for short. The convergence angle is the angle between the viewlines. * By bulging or flattening the eye lenses their focal length is changed, in order to focus on the object. <p> Ferwerda uses the number of depth steps as a measure for the amount of depth in a stereo image: twice as many depth steps means twice as much depth <ref> [Fer87] </ref>. The number of depth steps s beyond a point at distance d can be calculated as follows: = arctan (IP D=d) s = =ff (with the convergence angle for distance d and ff the stereo acuity).
Reference: [HN92] <author> Mats Henricson and Erik Nyquist. </author> <title> Programming in c++, rules and recommendations. </title> <type> Technical Report M 90 0118 Uen, </type> <institution> Ellemtel, </institution> <year> 1992. </year>
Reference: [Hod92] <author> Larry F. Hodges. </author> <title> Time multiplexed stereoscopic computer graphics. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 12(2) </volume> <pages> 20-30, </pages> <month> march </month> <year> 1992. </year>
Reference-contexts: CHAPTER 2. VIRTUAL ENVIRONMENTS 10 display screens optics eyes computer HMD sensor optical axis Chapter 3 Stereoscopy 3.1 Background When human eyes look at an object in space, several factors contribute to the fact that they see a sharp, three-dimensional object <ref> [Hod92] </ref> [Fer87]. * The eyes turn towards the object: this is called convergence of view-lines, or convergence for short. The convergence angle is the angle between the viewlines. * By bulging or flattening the eye lenses their focal length is changed, in order to focus on the object. <p> CHAPTER 3. STEREOSCOPY 17 viewline object * on-axis projection The projection assuming parallel viewlines may be extended to account for the convergence error. Hodges describes an algorithm for this on-axis projection <ref> [Hod92] </ref>. He uses one center of projection and horizontal translations of the data. <p> STEREOSCOPY 18 for a 40 degrees horizontal FOV per eye, the binocular FOV is 35 % smaller than it would be if an off-axis projection had been used [WP90]. * off-axis projection The off-axis projection most closely corresponds with reality, because it assumes converging instead of parallel view lines <ref> [Hod92] </ref>. The only problem here is to find out on which object the viewer is focusing, because this determines the convergence angle. CHAPTER 3. <p> CHAPTER 3. STEREOSCOPY 19 * rotation A method sometimes used to generate the left- and right-eye view is to rotate the left image counter-clockwise and the right image clockwise by a few degrees. This usually introduces vertical parallax (displacements) in the image, which causes severe eyestrain <ref> [Hod92] </ref>. incorrect Inter-Pupillary Distance The IPD of a viewer determines how much he must converge his eyes to focus on an object at a specific distance. In Figure 3.7 this is illustrated by showing two viewers with a different IPD looking at an object at the same distance.
Reference: [How91] <author> Eric M. Howlett. </author> <title> Wide angle orthostereo. </title> <booktitle> In Proc. SPIE vol.1457, Stereoscopic Displays and Applications II, </booktitle> <pages> pages 210-223, </pages> <year> 1991. </year>
Reference-contexts: Robinett and Rolland define orthostereoscopy as constancy, as the head moves around, of the perceived size, shape and relative positions of the simulated objects [RR91]. Howlett formulates the same definition in terms of constancy of the azimuth and elevation of points <ref> [How91] </ref>. Sutherland recognized the impor tance of orthostereoscopy back in 1968: The image presented by the three-dimensional display must change in exactly the way that the image of a real object would change for similar motions of the user's head [Sut68]. <p> The results of the second method can be found in their article. The first method is reviewed in Section 3.4.2. optics errors * non-linear distortion When a wide Field Of View is warped onto a flat plane, distortion is necessary <ref> [How91] </ref>. The LEEP optics used in many HMDs use a fish-eye like transformation to be able to project a large FOV onto a plane (see Figure 3.9). <p> The effect of predistortion is shown in Figure 3.11. * chromatic aberration CHAPTER 3. STEREOSCOPY 22 Differently coloured light rays diffract differently in the lens system, causing lateral chromatism, or "chromatic difference of magnification" <ref> [How91] </ref>. In the LEEP optics, blue is magnified about 1 % more than red, with green in between.
Reference: [IT72] <author> IZF-TNO. </author> <title> TNO test for stereoscopic vision. </title> <booktitle> Lameris Ootech, ninth edition, </booktitle> <year> 1972. </year>
Reference-contexts: If they are not, they are not allowed to do any further tests. The test we use is the TNO test for stereoscopic vision <ref> [IT72] </ref>. The viewer wears a pair of glasses with the left glass coloured red, and the right one green. Next a series of random dot stereograms is presented, containing pictures requiring a certain stereo acuity in order to be seen. CHAPTER 5.
Reference: [Min93a] <author> P. Min. </author> <title> Stereoscopy optimization system, design and specification document. </title> <type> Technical report, </type> <institution> FEL-TNO, </institution> <month> May </month> <year> 1993. </year>
Reference: [Min93b] <author> P. Min. </author> <title> Stereoscopy optimization system, requirements definition document. </title> <type> Technical report, </type> <institution> FEL-TNO, </institution> <month> March </month> <year> 1993. </year> <note> 70 BIBLIOGRAPHY 71 </note>
Reference: [Ove92] <author> Mark H. Overmars. </author> <title> Forms Library, A Graphical User Interface Toolkit for Silicon Graphics Workstations. </title> <address> Utrecht University, the Netherlands, 2.1 edition, </address> <year> 1992. </year>
Reference-contexts: Two of these are sent to the HMD. 1 The development software used: * operating system: Irix version 4.0.5 * compiler: Gnu C++ version 2.3.3 * graphics library: GL * user interface library: Forms Library version 2.1 <ref> [Ove92] </ref> 1 The Videosplitter output is RGB with NTSC (RS170A) timing. Two outputs are connected to a converter that produces two NTSC composite signals which are sent to the HMD. CHAPTER 4. <p> Appendix A Implementation aspects This appendix is intended for readers who want to acquire insight into the program structure of the SOS. General information The system has been written in C++, using the Gnu gcc compiler version 2.3.3, the GL graphics library and the Forms user interface library <ref> [Ove92] </ref>. Not counting the system, GL and Forms Library header files, the total source length is about 5300 lines. Program decomposition Recall the class hierarchy of "has-a" relations resulting from the design phase (see Figure A.1).
Reference: [RR91] <author> Warren Robinett and Jannick P. Rolland. </author> <title> A computational model for the stereoscopic optics of a head-mounted display. </title> <booktitle> In Proc. SPIE vol.1457, Stereoscopic Displays and Applications II, </booktitle> <pages> pages 140-160, </pages> <year> 1991. </year>
Reference-contexts: The result must be that 11 CHAPTER 3. STEREOSCOPY 12 object convergence angle eye retina lens viewline a orthostereoscopy is achieved. Robinett and Rolland define orthostereoscopy as constancy, as the head moves around, of the perceived size, shape and relative positions of the simulated objects <ref> [RR91] </ref>. Howlett formulates the same definition in terms of constancy of the azimuth and elevation of points [How91]. <p> Robinett and Rolland suggest the user must learn to decouple accomodation and convergence <ref> [RR91] </ref>. incorrect projection * projection assuming parallel viewlines For effiency reasons, the perspective projection may be implemented assuming parallel view lines (see Figure 3.5). <p> Robinett and Rolland used both methods to determine the FOV for the HMD and found a small difference <ref> [RR91] </ref>. The results of the second method can be found in their article. The first method is reviewed in Section 3.4.2. optics errors * non-linear distortion When a wide Field Of View is warped onto a flat plane, distortion is necessary [How91]. <p> A computational model for the optics in an HMD given by Robinett and Rolland will aid in determining these parameters <ref> [RR91] </ref>. This model is extensively reviewed in this section. 3.4.1 Optics model for a single eye First, an optics model for a single eye is given in Figure 3.12. From this model an approximation for the non-linear distortion is derived. <p> Theoretically the images generated using parallel viewlines were the least pleasing to the eyes, because the object viewed was positioned at a distance of 0.4 meters. This caused distortion in the parallel viewlines images. * Predistortion test using regular grid The theoretically optimal predistortion coefficient is -0.18 <ref> [RR91] </ref>. The average of the coefficients chosen by our test persons to be optimal is -0.17125 -0.17.
Reference: [Sut68] <author> Ivan E. Sutherland. </author> <title> A head-mounted three dimensional display. </title> <booktitle> In Proc. Fall Joint Computer Conference, </booktitle> <pages> pages 757-764, </pages> <year> 1968. </year>
Reference-contexts: Sutherland recognized the impor tance of orthostereoscopy back in 1968: The image presented by the three-dimensional display must change in exactly the way that the image of a real object would change for similar motions of the user's head <ref> [Sut68] </ref>. In Section 3.3 a discussion is presented on the errors that can occur when attempting to achieve orthostereoscopy in an HMD. In Section 3.4 a computational model of an HMD is reviewed which has been used to implement orthostereoscopic image generation in our system. CHAPTER 3.
Reference: [Ter86] <author> Patrick D. Terry. </author> <title> Programming Language Translation. </title> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: An informal description of the PAZ file format is given in the dVS system documentation [Atk92]. In Appendix A a formal LL (1)-grammar of the PAZ file format in BNF is given, which was used to facilitate the implementation of a structured and easily extensible parser <ref> [Ter86] </ref>. 3 The table is copied from [Atk92] CHAPTER 4.
Reference: [Val66] <author> N.A. Valyus. </author> <title> Stereoscopy. </title> <publisher> Focal Press, </publisher> <address> London, </address> <year> 1966. </year>
Reference-contexts: The size of the FOV our both eyes observe when looking straight ahead is about 180 degrees horizontally and 135 degrees vertically. A single eye has a horizontal FOV of about 150 degrees <ref> [Val66] </ref>. <p> Valyus suggests a maximum allowable deviation from the proper convergence angle of 1.6 degrees. 1 Beyond that angle doubling may occur: although the intention is to make the viewer see for example one pixel, "the impression of two separate points is generated" <ref> [Val66] </ref>. Robinett and Rolland suggest the user must learn to decouple accomodation and convergence [RR91]. incorrect projection * projection assuming parallel viewlines For effiency reasons, the perspective projection may be implemented assuming parallel view lines (see Figure 3.5).
Reference: [vdB88] <author> J. van den Bos. </author> <title> Design and specifications based on a protocol-constrained object language. </title> <type> Technical report, </type> <institution> Leiden University, </institution> <month> January </month> <year> 1988. </year>
Reference: [VSLC90] <author> Harry Veron, David A. Southard, Jeffrey R. Leger, and John L. Conway. </author> <title> Stereoscopic displays for terrain database visualization. </title> <booktitle> In Proc. SPIE vol.1256, Stereoscopic Displays and Applications, </booktitle> <pages> pages 124-135, </pages> <year> 1990. </year>
Reference-contexts: In Figure 3.4 the eyes converge to the image of the object, but must remain accomodated at the image of the screen. CHAPTER 3. STEREOSCOPY 16 image of screen a image of object Veron calls this phenomenon an accomodation/convergence conflict <ref> [VSLC90] </ref>. Valyus suggests a maximum allowable deviation from the proper convergence angle of 1.6 degrees. 1 Beyond that angle doubling may occur: although the intention is to make the viewer see for example one pixel, "the impression of two separate points is generated" [Val66].
Reference: [Win92] <author> J.F.H. Winkler. Objectivism: </author> <title> "class" considered harmful. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 128-130, </pages> <month> August </month> <year> 1992. </year>
Reference: [WP90] <author> Steven P. Williams and Russell V. Parrish. </author> <title> New computational control techniques and increased understanding for stereo 3-d display. </title> <booktitle> In Proc. SPIE vol.1256, Stereoscopic Displays and Applications, </booktitle> <pages> pages 73-82, </pages> <year> 1990. </year>
Reference-contexts: Williams and Parrish show that for example CHAPTER 3. STEREOSCOPY 18 for a 40 degrees horizontal FOV per eye, the binocular FOV is 35 % smaller than it would be if an off-axis projection had been used <ref> [WP90] </ref>. * off-axis projection The off-axis projection most closely corresponds with reality, because it assumes converging instead of parallel view lines [Hod92]. The only problem here is to find out on which object the viewer is focusing, because this determines the convergence angle. CHAPTER 3.
Reference: [WS82] <author> Gunter Wyszecki and W.S. Stiles. </author> <title> Color Science, Concepts and Methods, Quantitative Data and Formulae. </title> <publisher> John Wiley & Sons, </publisher> <address> 2nd edition, </address> <year> 1982. </year> <note> BIBLIOGRAPHY 72 </note>
Reference-contexts: visual axis is the line that connects the center of the eye lens and the center of the fovea. optical axis visual axis retina fovea 1 The fovea is in fact a central area of 5.2 degrees, the next 3.4 degrees is the parafovea and the next 10.4 the perifovea <ref> [WS82] </ref>. CHAPTER 2. VIRTUAL ENVIRONMENTS 8 central area near and middle periphery far periphery inner (nasal) side outer side eye The near periphery subtends an angle of about 30 degrees, the middle periphery 50 degrees. <p> The remaining 100 degrees are part of the far periphery, consisting of about 35 degrees on the inner (nasal) side of the eye, and 65 on the outer side (see Figure 2.2) <ref> [WS82] </ref>. Here viewing resolution is smallest, however it does serve in detecting movement.
Reference: [You91] <author> Yourdon. </author> <title> Structured Analysis for Real Time Systems, </title> <booktitle> Course Lecture Notes, </booktitle> <address> 4.1 edition, </address> <year> 1991. </year>
References-found: 19

