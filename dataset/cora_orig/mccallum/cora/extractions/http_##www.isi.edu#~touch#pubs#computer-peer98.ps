URL: http://www.isi.edu/~touch/pubs/computer-peer98.ps
Refering-URL: http://www.isi.edu/~touch/pubs/
Root-URL: http://www.isi.edu
Title: Efficient High-Speed Data Paths for IP Forwarding using Host Based Routers  
Author: Simon Walton, Anne Hutton, JoeTouch 
Keyword: host routers, IP forwarding, data paths, peer DMA, router performance  
Note: 1.0 Introduction Production routers are special-purpose systems, which use custom backplanes and line interface cards, with closed, proprietary software. These systems are often limiting, because of  
Affiliation: USC Information Sciences Institute  
Abstract: Host-based forwarding uses general purpose computers with two or more network interfaces to act as a router. These routers offer certain advantages over the use of dedicated hardware, allowing open, public source code access to the forwarding, queuing, and routing algorithms, and the use of more exible, commodity host interfaces and host CPUs. The main drawback of host-based forwarding is its inefficiency in supporting high-bandwidth interfaces; although host I/O busses support gigabit throughputs, existing host routers achieve only 25% of this capacity. This paper examines a version of host-based forwarding that substantially increases the capacity of host-based routers, by transferring packets directly between host interfaces, rather than staging them through the host memory. On a 200 Mhz Pentium-Pro FreeBSD PC, the resulting system supports bandwidths in excess of 480 Mbps, a 45% increase compared to conventional techniques. Host workstations are increasingly being used as routers. Using commodity platforms and network interfaces, these host-based routers can be cheaper, and allow more exible configuration and programmability than production routers. This work optimizes the data path in a host-based router, to increase routing bandwidth, while reducing backplane bandwidth and CPU load. . This work is supported by the Defense Advanced Research Projects Agency through Ft. Huachuca contract #DABT63-93-C-0062 entitled Netstation Architecture and Advanced Atomic Network. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Department of the Army, the Defense Advanced Research Projects Agency, or the U.S. Government. 
Abstract-found: 1
Intro-found: 0
Reference: [1] <author> Boden, N., Cohen, D., et al, </author> <title> Myrinet A Gigabit-per-Second Local-Area Network, </title> <journal> IEEE Micro,Vol.15, </journal> <volume> No.1, </volume> <month> February </month> <year> 1995, </year> <note> pp.29-36. &lt;http://www.myri.com/research/publications/Hot.ps&gt;. </note>
Reference: [2] <author> Druchel, P., Abbot, M., Pagels, M., and Peterson, L., </author> <title> Network Subsystem Design: A Case for an Integrated Data Path, </title> <journal> IEEE Network, </journal> <volume> Vol 7, No 4, </volume> <pages> pp 36-43, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: As a result, we refer separately to the process of forwarding and queuing here. Several techniques have been introduced to minimize the number of times network data crosses the CPU/memory data path, notably hardware streaming <ref> [2] </ref> and kernel-level streaming [4]. In hardware streaming data is transferred from source to sink device without CPU involvement. This avoids the extra copy into kernel RAM, but is focused on inter-peripheral communication, such as video-to-disk.
Reference: [3] <author> McKusick, M., Bostic, K., Karels, M., and Quarterman, J., </author> <title> The Design and Implementation of the 4.4 BSD Operating System, </title> <publisher> Addison Wesley, </publisher> <year> 1996. </year> <month> 12 </month>
Reference-contexts: DMA is provided by the NIC across the host PCI bus, in either direction. For our testbed, we use 200 Mhz Pentium Pro PCs, running FreeBSD 2.2.5 <ref> [3] </ref>. These hosts also have a 33 Mhz, 32-bit wide PCI bus, used for high-bandwidth peripheral access. <p> NIC buffers are used only as long as required to transfer packets into main memory on the incoming path, or out to the link on the outgoing path. All other queuing, and queue management is performed in main memory <ref> [3] </ref>. These steps are somewhat different if the host is the destination of the incoming packet. In that case, the packet is copied from kernel memory into user memory, based on further demulti-plexing of the packet header by the kernel.
Reference: [4] <author> Murphy, B., Zeadally, S., and Adams, C., </author> <title> An Analysis of Process and Memory Models to Support High-Speed Networking in a UNIX Environment, </title> <booktitle> USENIX, Proceedings of the Technical Conference, </booktitle> <pages> pp 239-251, </pages> <month> Jan 22-26 </month> <year> 1996. </year>
Reference-contexts: As a result, we refer separately to the process of forwarding and queuing here. Several techniques have been introduced to minimize the number of times network data crosses the CPU/memory data path, notably hardware streaming [2] and kernel-level streaming <ref> [4] </ref>. In hardware streaming data is transferred from source to sink device without CPU involvement. This avoids the extra copy into kernel RAM, but is focused on inter-peripheral communication, such as video-to-disk.
Reference: [5] <editor> Partridge, C., et al., </editor> <title> A 50-Gb/s IP Router, </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> Vol 6, No 3, </volume> <month> June </month> <year> 1998. </year>
Reference-contexts: The interest is primarily in low latency message passing, 4 which may streamline the interrupt processing of current NICs, and allow outboard co-processors to be controlled and programmed using a standard interface. Finally, there are a number of techniques for optimizing custom router design, summarized in <ref> [5] </ref>. Peer-DMA transfers between router line cards has been utilized there, including variations on where whether the header forwarding processing occurred on-card or outboard, on a separate processor. One recent system at BBN shows how this can be accomplished using commodity CPUs in a custom backplane architecture [5]. 4.0 Conventional host-based <p> design, summarized in <ref> [5] </ref>. Peer-DMA transfers between router line cards has been utilized there, including variations on where whether the header forwarding processing occurred on-card or outboard, on a separate processor. One recent system at BBN shows how this can be accomplished using commodity CPUs in a custom backplane architecture [5]. 4.0 Conventional host-based forwarding This section describes the ow of IP packets in a conventional host-based router. A host router is composed of a host with at least two host interfaces (Figure 1).
Reference: [6] <author> Prylli, L. and Tourancheau, B., Bip: </author> <title> a new protocol designed for high performance networking on myrinet, </title> <booktitle> Proc. of the PC-NOW Workshop, </booktitle> <address> IPPS/SPDP98, Orlando, USA, </address> <year> 1998. </year>
Reference-contexts: In experiments performed elsewhere, the combination of these PCs and the Myrinet NICs have been shown to provide host-memory to host-memory data transfer rates in excess of 1 Gbps (gigabits per second), using very large transfer units (64 KB and larger), pipelined directly into the NIC DMA <ref> [6] </ref>. However, at the IP layer these hosts support UDP rates of 300 Mbps and TCP rates of 150 Mbps. 3 For our experiments, we relied on the packet multiplexing capability of the Myrinet switches to merge traffic from multiple sources, to find the limiting routing bandwidths.
Reference: [7] <author> Tennenhouse, D.L., Smith, J.M., Sincoskie, W.D., Wetherall, D.J., Minden, G.J., </author> <title> A survey of active network research, </title> <journal> IEEE Communications Magazine, </journal> <pages> pp. 80-86, </pages> <month> Jan. </month> <year> 1997. </year>
Reference-contexts: Government. 2 their closed software and proprietary backplane bus. Systems requiring software modification, such as experimental routing testbeds (e.g., DARTnet and CAIRN) and dynamically-reprogram-mable routers (Active Networks <ref> [7] </ref>), typically require host-based routers. Host interfaces for new gigabit technologies are typically available much earlier than their router line-card equivalents. In some cases, such as the Myrinet, no router line cards are available. In addition, the router line-cards are vendor, and sometimes product specific.
Reference: [8] <author> Dunning, D., Regnier, G., </author> <title> Virtual Interface Architecture, </title> <booktitle> IEEE Proceedings of the Hot Interconnects Symposium V, </booktitle> <year> 1997. </year>
Reference-contexts: An industry consortium is also extending the concept of virtualizing NIs to provide user-level access to the network interface <ref> [8] </ref>. The interest is primarily in low latency message passing, 4 which may streamline the interrupt processing of current NICs, and allow outboard co-processors to be controlled and programmed using a standard interface. Finally, there are a number of techniques for optimizing custom router design, summarized in [5].
Reference: [9] <author> Welsh, M., Basu, A, and von Eicken, T., </author> <title> ATM and Fast Ethernet Network Interfaces for User-level Communication, </title> <booktitle> IEEE Proceedings of the Third International Sympsosium on High Performance Computer Architecture, </booktitle> <pages> pp. 332-342 Feb 1-5, </pages> <year> 1997. </year>
Reference-contexts: Data does, however, pass through memory and the technique relies on the Sytem V STREAMS interface. There has also been substantial work in avoiding OS intervention by providing user access to network data <ref> [9] </ref>. Direct application access to the network interface is used to achieve both low-latency and high bandwidth using commodity workstation clusters. Protocol processing is moved to the application by virtualizing the interface using a combination of NIC capabilities (on board buffers, programmable co-processors, DMA) and OS mechanisms.
References-found: 9

