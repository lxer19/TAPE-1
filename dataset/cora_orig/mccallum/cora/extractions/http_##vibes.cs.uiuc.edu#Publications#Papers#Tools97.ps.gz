URL: http://vibes.cs.uiuc.edu/Publications/Papers/Tools97.ps.gz
Refering-URL: http://vibes.cs.uiuc.edu/Publications/publications.htm
Root-URL: http://www.cs.uiuc.edu
Email: fesmirni,reedg@cs.uiuc.edu  
Title: Workload Characterization of Input/Output Intensive Parallel Applications  
Author: Evgenia Smirni and Daniel A. Reed 
Address: Urbana, Illinois 61801, USA  
Affiliation: Department of Computer Science University of Illinois  
Abstract: The broadening disparity in the performance of input/output (I/O) devices and the performance of processors and communication links on parallel systems is a major obstacle to achieving high performance for a wide range of parallel applications. I/O hardware and file system parallelism are the keys to bridging this performance gap. A prerequisite to the development of efficient parallel file systems is detailed characterization of the I/O demands of parallel applications. In this paper, we present a comparative study of the I/O access patterns commonly found in I/O intensive parallel applications. Using the Pablo performance analysis environment and its I/O extensions we captured application I/O access patterns and analyzed their interactions with current parallel I/O systems. This analysis has proven instrumental in guiding the development of new application programming interfaces (APIs) for parallel file systems and in developing effective file system policies that can adap tively respond to complex application I/O requirements.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Bennett, R., Bryant, K., Sussman, A., Das, R., and Saltz, J. Jovian: </author> <title> A framework for optimizing parallel I/O. </title> <booktitle> In Proceedings of the Scalable Parallel Libraries Conference (October 1994), </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 10-20. </pages>
Reference-contexts: Early experience with these APIs has shown major I/O performance improvements | with high-level descriptions of I/O request patterns, file system policies can more intelligently prefetch and cache I/O data. The desire for intuitive APIs with high expressive power has led to a host of experimental I/O libraries <ref> [9, 2, 1] </ref> that support specific problem domains and access pattern classes. For example, such domain-specific libraries have emerged for computational chemistry [5] and out-of-core linear algebra computations [16].
Reference: 2. <author> Bordawekar, R., Thakur, R., and Choudhary, A. </author> <title> Efficient compilation of out-of-core data parallel programs. </title> <type> Tech. Rep. SCCS-622, </type> <institution> NPAC, </institution> <month> April </month> <year> 1994. </year>
Reference-contexts: Early experience with these APIs has shown major I/O performance improvements | with high-level descriptions of I/O request patterns, file system policies can more intelligently prefetch and cache I/O data. The desire for intuitive APIs with high expressive power has led to a host of experimental I/O libraries <ref> [9, 2, 1] </ref> that support specific problem domains and access pattern classes. For example, such domain-specific libraries have emerged for computational chemistry [5] and out-of-core linear algebra computations [16].
Reference: 3. <author> Corbett, P. F., Prost, J.-P., Demetriou, C., Gibson, G., Riedel, E., Ze-lenka, J., Chen, Y., Felten, E., Li, K., Hartman, J., Peterson, L., Ber-shad, B., Wolman, A., and Aydt, R. </author> <title> Proposal for a common parallel file system programming interface version 1.0, </title> <month> September </month> <year> 1996. </year>
Reference-contexts: Therefore, the design and implementation of a standard parallel I/O API that is expressive, compact, intuitively appealing, and at the same time offers high performance <ref> [3] </ref> is one of the goals of the SIO effort. 6.2 Emerging I/O APIs Even within our small application sample, the diversity of I/O request sizes and patterns suggests that achieving high performance is unlikely with a single file system policy.
Reference: 4. <author> Crandall, P., Aydt, R. A., Chien, A. A., and Reed, D. A. </author> <title> Input/Output characterization of scalable parallel applications. </title> <booktitle> In Supercomputing 1995 (1996). </booktitle>
Reference-contexts: In contrast to the results on vector systems, recent analyses on the Intel Paragon XP/S <ref> [4] </ref>, the Intel iPSC/860 [6], and the CM-5 [12], showed greater irregularity in I/O access patterns, with the majority of file requests being small but with the greatest data volume generated by a few large requests.
Reference: 5. <author> Foster, I., and Nieplocha, J. </author> <title> ChemIO: High-performance I/O for computational chemistry applications. </title> <note> http://www.mcs.anl.gov/chemio/, February 1996. </note>
Reference-contexts: The desire for intuitive APIs with high expressive power has led to a host of experimental I/O libraries [9, 2, 1] that support specific problem domains and access pattern classes. For example, such domain-specific libraries have emerged for computational chemistry <ref> [5] </ref> and out-of-core linear algebra computations [16]. Despite the demonstrated performance rewards from use of more expressive APIs, several studies have shown that users frequently opt to continue using UNIX I/O primitives on parallel systems.
Reference: 6. <author> Kotz, D., and Nieuwejaar, N. </author> <title> Dynamic file-access characteristics of a production parallel scientific workload. </title> <booktitle> In Supercomputing '94 (November 1994). </booktitle>
Reference-contexts: In contrast to the results on vector systems, recent analyses on the Intel Paragon XP/S [4], the Intel iPSC/860 <ref> [6] </ref>, and the CM-5 [12], showed greater irregularity in I/O access patterns, with the majority of file requests being small but with the greatest data volume generated by a few large requests.
Reference: 7. <author> Madhyastha, T., and Reed, D. A. </author> <title> Intelligent, adaptive file system policy selection. </title> <booktitle> In Proceedings of Frontiers'96 (1996). </booktitle>
Reference-contexts: Instead, one needs a file system API via which users can "inform" the file system of expected access patterns. Using such hints or an automatic access pattern classification scheme <ref> [7] </ref>, an adaptive file system could then choose those file policies and policy parameters best matched to the access pattern. For example, via user controls and hints one might advise the file system that the file access pattern is read only, write only, mixed read/write sequential, or strided.
Reference: 8. <author> Miller, E. L., and Katz, R. H. </author> <title> Input/Output behavior of supercomputer applications. </title> <booktitle> In Supercomputing '91 (November 1991), </booktitle> <pages> pp. 567-576. </pages>
Reference-contexts: Finally, x7 summarizes our observations. 2 Related Work The first I/O characterization efforts of scientific applications on vector supercomputers concluded that I/O behavior is regular, recurrent, and predictable <ref> [8, 10] </ref>, characteristics that were attributed to the iterative nature of such applications.
Reference: 9. <author> Nieuwejaar, N., and Kotz, D. </author> <title> The Galley parallel file system. </title> <booktitle> In Proceedings of the 10th ACM International Conference on Supercomputing (May 1996). </booktitle>
Reference-contexts: Early experience with these APIs has shown major I/O performance improvements | with high-level descriptions of I/O request patterns, file system policies can more intelligently prefetch and cache I/O data. The desire for intuitive APIs with high expressive power has led to a host of experimental I/O libraries <ref> [9, 2, 1] </ref> that support specific problem domains and access pattern classes. For example, such domain-specific libraries have emerged for computational chemistry [5] and out-of-core linear algebra computations [16].
Reference: 10. <author> Pasquale, B. K., and Polyzos, G. C. </author> <title> Dynamic I/O characterization of I/O intensive scientific applications. </title> <booktitle> In Proceedings of Supercomputing '94 (November 1994), </booktitle> <pages> pp. 660-669. </pages>
Reference-contexts: Finally, x7 summarizes our observations. 2 Related Work The first I/O characterization efforts of scientific applications on vector supercomputers concluded that I/O behavior is regular, recurrent, and predictable <ref> [8, 10] </ref>, characteristics that were attributed to the iterative nature of such applications.
Reference: 11. <author> Poole, J. T. </author> <title> Scalable I/O Initiative. </title> <institution> California Institute of Technology, </institution> <note> Available at http://www.ccsf.caltech.edu/SIO/, 1996. </note>
Reference-contexts: Understanding the interactions between application I/O request patterns and parallel I/O system hardware and software is necessary for the design of more effective I/O management policies. The primary objectives of the Scalable I/O initiative (SIO) <ref> [11] </ref> are (a) to assemble a suite of I/O intensive, national challenge applications, (b) to collect detailed performance data on application characteristics and access patterns, and (c) use this information to design and evaluate parallel file system ? This work was supported in part by the Defense Advanced Research Projects Agency
Reference: 12. <author> Purakayastha, A., Ellis, C. S., Kotz, D., Nieuwejaar, N., and Best, M. </author> <title> Characterizing parallel file-access patterns on a large-scale multiprocessor. </title> <booktitle> In Proceedings of the Ninth International Parallel Processing Symposium (April 1995), </booktitle> <pages> pp. 165-172. </pages>
Reference-contexts: In contrast to the results on vector systems, recent analyses on the Intel Paragon XP/S [4], the Intel iPSC/860 [6], and the CM-5 <ref> [12] </ref>, showed greater irregularity in I/O access patterns, with the majority of file requests being small but with the greatest data volume generated by a few large requests.
Reference: 13. <author> Reed, D. A., Aydt, R. A., Noe, R. J., Roth, P. C., Shields, K. A., Schwartz, B. W., and Tavera, L. F. </author> <title> Scalable performance analysis: The Pablo performance analysis environment. </title> <booktitle> In Proceedings of the Scalable Parallel Libraries Conference, </booktitle> <editor> A. Skjellum, Ed. </editor> <publisher> IEEE Computer Society, </publisher> <year> 1993, </year> <pages> pp. 104-113. </pages>
Reference-contexts: Below, we present the Pablo performance environment and its I/O analysis mechanisms, followed by a brief description of the selected applications. 3.1 Pablo Performance Environment Pablo <ref> [13] </ref> is a portable performance environment that supports performance data capture and analysis. The Pablo instrumentation software captures dynamic performance data via instrumented source code that is linked with a data capture library.
Reference: 14. <author> Reed, D. A., Elford, C. L., Madhyastha, T., Scullin, W. H., Aydt, R. A., and Smirni, E. </author> <title> I/O, performance analysis, and performance data immersion. </title> <booktitle> In Proceedings of MASCOTS '96 (Feb. </booktitle> <year> 1996), </year> <pages> pp. 1-12. </pages>
Reference-contexts: During program execution, the instrumented code generates dynamic performance data that can be directly recorded by the data capture library for off-line analysis, processed by one or more data analysis extensions prior to recording, or directly processed and displayed in real time <ref> [14] </ref>. Via the Pablo I/O extensions, one can capture detailed traces of I/O events during application program execution. These I/O event traces include the time, duration, size, file name, the processor identifier that initiated the I/O call, and other parameters particular to each I/O operation.
Reference: 15. <author> Smirni, E., Aydt, R. A., Chien, A. A., and Reed, D. A. </author> <title> I/O requirements of scientific applications: An evolutionary view. </title> <booktitle> In High Performance Distributed Computing (1996), </booktitle> <pages> pp. 49-59. </pages>
Reference-contexts: Despite the demonstrated performance rewards from use of more expressive APIs, several studies have shown that users frequently opt to continue using UNIX I/O primitives on parallel systems. The rationale for this lies in the desire to maximize code portability across diverse parallel platforms and to minimize software restructuring <ref> [15] </ref>. Simply put, many scientific application developers are unwilling to sacrifice portability for performance.
Reference: 16. <author> Toledo, S., and Gustavson, F. G. </author> <title> The design and implementation of SOLAR, a portable library for scalable out-of-core linear algebra computations. </title> <booktitle> In Fourth Workshop on Input/Output in Parallel and Distributed Systems (May 1996), </booktitle> <pages> pp. </pages> <month> 28-40. </month> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: The desire for intuitive APIs with high expressive power has led to a host of experimental I/O libraries [9, 2, 1] that support specific problem domains and access pattern classes. For example, such domain-specific libraries have emerged for computational chemistry [5] and out-of-core linear algebra computations <ref> [16] </ref>. Despite the demonstrated performance rewards from use of more expressive APIs, several studies have shown that users frequently opt to continue using UNIX I/O primitives on parallel systems.
References-found: 16

