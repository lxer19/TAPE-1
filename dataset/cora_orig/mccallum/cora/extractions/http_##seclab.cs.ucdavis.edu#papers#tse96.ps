URL: http://seclab.cs.ucdavis.edu/papers/tse96.ps
Refering-URL: http://seclab.cs.ucdavis.edu/papers.html
Root-URL: http://www.cs.ucdavis.edu
Email: E-mail: mukherje@cs.ucdavis.edu  
Phone: Tel: (916) 752-4826  
Title: A Methodology for Testing Intrusion Detection Systems 1  
Author: Nicholas J. Puketza, Kui Zhang, Mandy Chung, Biswanath Mukherjee*, Ronald A. Olsson 
Date: October, 1993  September 8, 1995  September 27, 1996  
Address: Davis, CA 95616  
Affiliation: Department of Computer Science University of California, Davis  
Note: *Correspondence Author  Original submission date:  First revision date:  Second revision date:  Copyright Note This work has not yet been published but it has been accepted by the IEEE for publication. The authors have already transferred the copyright to the IEEE. When the work is published, this version will be superseded by the published version.  
Abstract: Intrusion Detection Systems (IDSs) attempt to identify unauthorized use, misuse, and abuse of computer systems. In response to the growth in the use and development of IDSs, we have developed a methodology for testing IDSs. The methodology consists of techniques from the field of software testing which we have adapted for the specific purpose of testing IDSs. In this paper, we identify a set of general IDS performance objectives which is the basis for the methodology. We present the details of the methodology, including strategies for test-case selection and specific testing procedures. We include quantitative results from testing experiments on the Network Security Monitor (NSM), an IDS developed at UC Davis. We present an overview of the software platform that we have used to create user-simulation scripts for testing experiments. The platform consists of the UNIX tool expect and enhancements that we have developed, including mechanisms for concurrent scripts and a record-and-replay feature. We also provide background information on intrusions and IDSs to motivate our work. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Anderson et al., </author> <title> "Next Generation Intrusion Detection Expert System (NIDES)," Software Design, Product Specification, and Version Description Document, Project 3131, </title> <booktitle> SRI International, </booktitle> <month> July 11, </month> <year> 1994. </year>
Reference-contexts: IDSs have been developed and used at several institutions. Some example IDSs are National Security Agency's Multics Intrusion Detection and Alerting System (MIDAS) [31], AT&T's ComputerWatch [9], SRI International's Intrusion Detection Expert System (IDES) [24, 25] and Next-Generation Intrusion-Detection Expert System (NIDES) <ref> [1] </ref>, UC Santa Barbara's State Transition Analysis Tool for UNIX (USTAT) [15, 16], Los Alamos National Laboratory's (LANL's) Network Anomaly Detection and Intrusion Reporter (NADIR) [14], and UC Davis' Network Security Monitor (NSM) [13] and Distributed Intrusion Detection System (DIDS) [33].
Reference: [2] <author> R. G. </author> <month> Bace, </month> <institution> Division of Infosec Computer Science, Research and Technology, National Security Agency, </institution> <type> private communication, </type> <month> May </month> <year> 1995. </year>
Reference-contexts: PREVENTION INVESTIGATION POST-MORTEM DETECTION In response to these difficulties in developing secure systems (which are discussed further in [27]), a new model of system security management <ref> [2] </ref> has emerged. The model is pictured in identifies security breaches. The investigation component determines exactly what happened based on data from the detection component. This component may also include the gathering of further data in order to identify the security violator.
Reference: [3] <author> S. M. Bellovin, </author> <title> "There Be Dragons," </title> <booktitle> Proc., Third USENIX UNIX Security Symposium, </booktitle> <address> Baltimore, MD, </address> <pages> pp. 1-16, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Readers who are already familiar with these topics may skip this section. 2.1 Intrusions Intrusions in computer systems are occurring at an increasingly alarming rate. Some sites report that they are the targets of hundreds of intrusion attempts per month <ref> [3] </ref>. Moreover, there are numerous different intrusion techniques used by intruders [28].
Reference: [4] <author> S. M. Bellovin, </author> <title> "Security Problems in the TCP/IP Protocol Suite," </title> <journal> ACM Computer Communication Review, </journal> <volume> vol. 19, no. 2, </volume> <pages> pp. 32-48, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: Finally, a central component of computer systems, the computer network itself, may not be secure. For instance, there are a number of security flaws inherent in the widely-used Transmission Control Protocol/Internet Protocol (TCP/IP) suite, regardless of its particular implementation <ref> [4] </ref>. PREVENTION INVESTIGATION POST-MORTEM DETECTION In response to these difficulties in developing secure systems (which are discussed further in [27]), a new model of system security management [2] has emerged. The model is pictured in identifies security breaches.
Reference: [5] <author> M. Bishop, </author> <title> "A Taxonomy of UNIX System and Network Vulnerabilities," </title> <type> Technical Report CSE-95-10, </type> <institution> University of California at Davis, </institution> <month> September </month> <year> 1995. </year>
Reference-contexts: While some of the tests require simulated "normal" sessions, most of the test cases are simulated intrusions. A key problem is to select which intrusions to simulate. The testers should first collect as much intrusion data as possible. For UNIX systems, [20] and <ref> [5] </ref> report that intrusion data can be obtained from various sources, such as CERT advisories, periodicals such as PHRACK and 2600, and the USENET [10], and also by analyzing the vulnerabilities detected by security tools such as COPS [11] and TIGER [30]. <p> Intrusions can be classified according to the intrusion technique. A comprehensive example of this type of classification is presented in [28]. A second strategy is to classify intrusions based on a taxonomy of the system vulnerabilities that the intrusions exploit (e.g., see <ref> [5, 21] </ref>). A limitation of using either of these strategies for the purpose of selecting test cases is that, even though two intrusions share the same classification, the IDS might detect one intrusion but not the other.
Reference: [6] <author> P. Brinch Hansen, </author> <title> "Reproducible Testing of Monitors," </title> <journal> Software-Practice and Experience, </journal> <volume> vol. 8, </volume> <pages> pp. 721-729, </pages> <year> 1978. </year>
Reference-contexts: Thus, the IDS is likely to react differently to these two scenarios, even though all of the commands are the same in both scenarios. To accommodate "reproducible testing" or "replay" <ref> [6, 22] </ref>, deterministic execution of concurrent script sets is required. We have developed a synchronization mechanism to meet this requirement. The mechanism provides a means for the programmer to establish a fixed order of execution for key events, even if the events are associated with different scripts.
Reference: [7] <author> M. Chung, N. Puketza, R. A. Olsson, and B. Mukherjee, </author> <title> "Simulating Concurrent Intrusions for Testing Intrusion Detection Systems: Parallelizing Intrusions," </title> <booktitle> Proc., 18th National Information Systems Security Conference, </booktitle> <address> Baltimore, MD, </address> <pages> pp. 173-183, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: We have augmented expect with some additional commands that provide the capability to create concurrent scripts, complete with mechanisms for synchronization and communication among different scripts <ref> [35, 7] </ref>. These extensions to expect provide users with the ability to simulate concurrent intrusions, which were described in Section 2.2. Often, in the course of testing an IDS, it may be necessary to repeat a particular test.
Reference: [8] <author> D. E. Denning, </author> <title> "An Intrusion-Detection Model," </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. SE-13, no. 2, </volume> <pages> pp. 222-232, </pages> <month> February </month> <year> 1987. </year>
Reference-contexts: The anomaly-detection approach is based on the premise that an attack on a computer system (or network) will be noticeably different from normal system (or network) activity, and an intruder (possibly masquerading as a legitimate user) will exhibit a pattern of behavior different from the normal user <ref> [8] </ref>. So, the IDS attempts to characterize each user's normal behavior, often by maintaining statistical profiles of each user's activities [25, 17]. Each profile includes information about the user's computing behavior such as normal login time, duration of login session, CPU usage, disk usage, favorite editor, and so forth.
Reference: [9] <author> C. Dowell and P. Ramstedt, </author> <title> "The COMPUTERWATCH Data Reduction Tool," </title> <booktitle> Proc., 13th National Computer Security Conference, </booktitle> <address> Washington, D.C., </address> <pages> pp. 99-108, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: IDSs detect intrusions by analyzing information about user activity from sources such as audit records, system tables, and network traffic summaries. IDSs have been developed and used at several institutions. Some example IDSs are National Security Agency's Multics Intrusion Detection and Alerting System (MIDAS) [31], AT&T's ComputerWatch <ref> [9] </ref>, SRI International's Intrusion Detection Expert System (IDES) [24, 25] and Next-Generation Intrusion-Detection Expert System (NIDES) [1], UC Santa Barbara's State Transition Analysis Tool for UNIX (USTAT) [15, 16], Los Alamos National Laboratory's (LANL's) Network Anomaly Detection and Intrusion Reporter (NADIR) [14], and UC Davis' Network Security Monitor (NSM) [13] and
Reference: [10] <author> D. Farmer and W. Venema, </author> <title> "Improving the Security of Your Site by Breaking Into It," USENET posting, </title> <month> December </month> <year> 1993. </year>
Reference-contexts: The testers should first collect as much intrusion data as possible. For UNIX systems, [20] and [5] report that intrusion data can be obtained from various sources, such as CERT advisories, periodicals such as PHRACK and 2600, and the USENET <ref> [10] </ref>, and also by analyzing the vulnerabilities detected by security tools such as COPS [11] and TIGER [30].
Reference: [11] <author> D. Farmer and E. H. Spafford, </author> <title> "The COPS Security Checker System," </title> <booktitle> Proc., Summer USENIX Conference, </booktitle> <pages> pp. 165-170, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: For UNIX systems, [20] and [5] report that intrusion data can be obtained from various sources, such as CERT advisories, periodicals such as PHRACK and 2600, and the USENET [10], and also by analyzing the vulnerabilities detected by security tools such as COPS <ref> [11] </ref> and TIGER [30]. Next, assuming that the number of intrusions is too large to simulate all of them, the testers must partition the set of intrusions into classes, and then create a representative subset of intrusions by selecting one or more intrusions from each class.
Reference: [12] <author> L. D. Gary, </author> <title> talk presented in "Crime on the Internet" session, </title> <booktitle> 17th National Computer Security Conference, </booktitle> <address> Baltimore, MD, </address> <month> October 12, </month> <year> 1994. </year>
Reference-contexts: then to corrupt another user's file; * A user exploits a flaw in a system program to obtain super-user status; * An intruder uses a script to "crack" the passwords of other users on a computer; * An intruder installs a "snooping program" on a computer to inspect network traffic <ref> [12] </ref>, which often contains user passwords and other sensitive data; and * An intruder modifies router tables in a network to prevent the delivery of messages to a particular computer. 3 The reader can easily infer some of the consequences of intrusions from the preceding list. <p> Some additional consequences include loss or alteration of data, loss of money when financial records are altered by intruders, denial of service to legitimate users, loss of trust in the computer/network system, and loss of public confidence in the organization that is the victim of an intrusion <ref> [12] </ref>. 2.2 Concurrent Intrusions In addition to the variety of intrusion techniques, another complication in the task of detecting intrusions is the possibility of concurrent intrusions, in which one or more intruders use several terminals (or "windows" on a workstation) to carry out one or more intrusions simultaneously.
Reference: [13] <author> L. T. Heberlein, G. Dias, K. Levitt, B. Mukherjee, J. Wood, and D. Wolber, </author> <title> "A Network Security Monitor," </title> <booktitle> Proc., 1990 IEEE Symposium on Research in Security and Privacy, </booktitle> <address> Oakland, CA, </address> <pages> pp. 296-304, </pages> <month> May </month> <year> 1990. </year> <month> 23 </month>
Reference-contexts: ComputerWatch [9], SRI International's Intrusion Detection Expert System (IDES) [24, 25] and Next-Generation Intrusion-Detection Expert System (NIDES) [1], UC Santa Barbara's State Transition Analysis Tool for UNIX (USTAT) [15, 16], Los Alamos National Laboratory's (LANL's) Network Anomaly Detection and Intrusion Reporter (NADIR) [14], and UC Davis' Network Security Monitor (NSM) <ref> [13] </ref> and Distributed Intrusion Detection System (DIDS) [33]. As more and more organizations depend on IDSs as integral components of their computer security systems, techniques for evaluating IDSs are becoming more important.
Reference: [14] <author> J. Hochberg et al., "NADIR: </author> <title> An Automated System for Detecting Network Intrusion and Misuse," </title> <journal> Computers and Security, </journal> <volume> vol. 12, no. 3, </volume> <pages> pp. 235-248, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Intrusion Detection and Alerting System (MIDAS) [31], AT&T's ComputerWatch [9], SRI International's Intrusion Detection Expert System (IDES) [24, 25] and Next-Generation Intrusion-Detection Expert System (NIDES) [1], UC Santa Barbara's State Transition Analysis Tool for UNIX (USTAT) [15, 16], Los Alamos National Laboratory's (LANL's) Network Anomaly Detection and Intrusion Reporter (NADIR) <ref> [14] </ref>, and UC Davis' Network Security Monitor (NSM) [13] and Distributed Intrusion Detection System (DIDS) [33]. As more and more organizations depend on IDSs as integral components of their computer security systems, techniques for evaluating IDSs are becoming more important.
Reference: [15] <author> K. Ilgun, "USTAT: </author> <title> A Real-Time Intrusion Detection System for UNIX," </title> <booktitle> Proc., IEEE Symposium on Research in Security and Privacy, </booktitle> <address> Oakland, CA, </address> <pages> pp. 16-28, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Some example IDSs are National Security Agency's Multics Intrusion Detection and Alerting System (MIDAS) [31], AT&T's ComputerWatch [9], SRI International's Intrusion Detection Expert System (IDES) [24, 25] and Next-Generation Intrusion-Detection Expert System (NIDES) [1], UC Santa Barbara's State Transition Analysis Tool for UNIX (USTAT) <ref> [15, 16] </ref>, Los Alamos National Laboratory's (LANL's) Network Anomaly Detection and Intrusion Reporter (NADIR) [14], and UC Davis' Network Security Monitor (NSM) [13] and Distributed Intrusion Detection System (DIDS) [33].
Reference: [16] <author> K. Ilgun, R. A. Kemmerer, and P. A. Porras, </author> <title> "State Transition Analysis: A Rule-Based Intrusion Detection Approach," </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 21, no. 3, </volume> <pages> pp. 181-199, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: Some example IDSs are National Security Agency's Multics Intrusion Detection and Alerting System (MIDAS) [31], AT&T's ComputerWatch [9], SRI International's Intrusion Detection Expert System (IDES) [24, 25] and Next-Generation Intrusion-Detection Expert System (NIDES) [1], UC Santa Barbara's State Transition Analysis Tool for UNIX (USTAT) <ref> [15, 16] </ref>, Los Alamos National Laboratory's (LANL's) Network Anomaly Detection and Intrusion Reporter (NADIR) [14], and UC Davis' Network Security Monitor (NSM) [13] and Distributed Intrusion Detection System (DIDS) [33]. <p> We plan to develop additional performance objectives and tests for IDSs based on the related work of other groups. For example, tests that measure the processing speed of USTAT are described in <ref> [16] </ref>. Another task is to fine-tune the testing procedures and develop suitable metrics to create a "benchmark suite" for IDSs, similar in spirit to the well-established benchmarks such as SPECmarks, Livermore Loops, and Dhrystone, which are used to test the performance of various computer architectures.
Reference: [17] <author> H. S. Javitz and A. Valdes, </author> <title> "The SRI IDES Statistical Anomaly Detector," </title> <booktitle> Proc., IEEE Symposium on Research in Security and Privacy, </booktitle> <address> Oakland, CA, </address> <pages> pp. 316-376, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: So, the IDS attempts to characterize each user's normal behavior, often by maintaining statistical profiles of each user's activities <ref> [25, 17] </ref>. Each profile includes information about the user's computing behavior such as normal login time, duration of login session, CPU usage, disk usage, favorite editor, and so forth. The IDS can then use the profiles to monitor current user activity and compare it with past user activity. <p> Whenever the difference between a user's current activity and past activity falls outside some predefined "bounds" (threshold values for each item in the profile), the activity is considered to be anomalous, and hence suspicious. The interested reader is referred to <ref> [17] </ref> for a thorough discussion of both this topic and the implementation of the IDES anomaly detection component. In the misuse-detection approach, the IDS watches for indications of "specific, precisely-representable techniques of computer system abuse" [18].
Reference: [18] <author> S. Kumar and E. H. Spafford, </author> <title> "A Software Architecture to Support Misuse Intrusion Detection," </title> <type> Technical Report CSD-TR-95-009, </type> <institution> Purdue University, </institution> <month> March 17, </month> <year> 1995. </year>
Reference-contexts: The interested reader is referred to [17] for a thorough discussion of both this topic and the implementation of the IDES anomaly detection component. In the misuse-detection approach, the IDS watches for indications of "specific, precisely-representable techniques of computer system abuse" <ref> [18] </ref>. The IDS includes a collection of intrusion signatures, which are encapsulations of the identifying characteristics of specific intrusion techniques. The IDS detects intrusions by searching for these "tell-tale" intrusion signatures in the records of user activities.
Reference: [19] <author> S. Kumar and E. H. Spafford, </author> <title> "An Application of Pattern Matching in Intrusion Detection," </title> <type> Technical Report CSD-TR-94-013, </type> <institution> Purdue University, </institution> <month> June 17, </month> <year> 1994. </year>
Reference-contexts: We have identified the following objectives (which are similar to the key design goals for developing an IDS cited in <ref> [19] </ref>): * Broad Detection Range: for each intrusion in a broad range of known intrusions, the IDS should be able to distinguish the intrusion from normal behavior; * Economy in Resource Usage: the IDS should function without using too much system resources such as main memory, CPU time, and disk space;
Reference: [20] <author> S. Kumar and E. H. Spafford, </author> <title> "A Pattern Matching Model for Misuse Intrusion Detection," </title> <booktitle> Proc., 17th National Computer Security Conference, </booktitle> <address> Baltimore, MD, </address> <pages> pp. 11-21, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: While some of the tests require simulated "normal" sessions, most of the test cases are simulated intrusions. A key problem is to select which intrusions to simulate. The testers should first collect as much intrusion data as possible. For UNIX systems, <ref> [20] </ref> and [5] report that intrusion data can be obtained from various sources, such as CERT advisories, periodicals such as PHRACK and 2600, and the USENET [10], and also by analyzing the vulnerabilities detected by security tools such as COPS [11] and TIGER [30]. <p> A third strategy is to classify intrusions based on their signatures, which we defined in Section 2.4 as encapsulations of the identifying characteristics of specific intrusion techniques. A classification scheme based on signatures is presented in <ref> [20] </ref>. A limitation of using this classification strategy to select test cases is that the number of classes is small. However, this technique may possibly be extended to yield a finer-grained classification.
Reference: [21] <author> C. E. Landwehr et al., </author> <title> "A Taxonomy of Computer Program Security Flaws," </title> <journal> ACM Computing Surveys, </journal> <volume> vol. 26, no. 3, </volume> <pages> pp. 211-254, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: Intrusions can be classified according to the intrusion technique. A comprehensive example of this type of classification is presented in [28]. A second strategy is to classify intrusions based on a taxonomy of the system vulnerabilities that the intrusions exploit (e.g., see <ref> [5, 21] </ref>). A limitation of using either of these strategies for the purpose of selecting test cases is that, even though two intrusions share the same classification, the IDS might detect one intrusion but not the other.
Reference: [22] <author> T. J. LeBlanc and J. M. Mellor-Crummey, </author> <title> "Debugging Parallel Programs With Instant Replay," </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. C-36, no. 4. </volume> <pages> pp. 471-482, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: Thus, the IDS is likely to react differently to these two scenarios, even though all of the commands are the same in both scenarios. To accommodate "reproducible testing" or "replay" <ref> [6, 22] </ref>, deterministic execution of concurrent script sets is required. We have developed a synchronization mechanism to meet this requirement. The mechanism provides a means for the programmer to establish a fixed order of execution for key events, even if the events are associated with different scripts.
Reference: [23] <author> D. Libes, </author> <title> Exploring Expect: A Tcl-based Toolkit for Automating Interactive Programs, </title> <publisher> O'Reilly & Associates, Inc., </publisher> <year> 1994. </year>
Reference-contexts: It consists of strategies for selecting test cases, and a series of detailed testing procedures. To develop the methodology, we have borrowed techniques from the field of software testing and adapted them for the specific purpose of testing IDSs. We use the UNIX tool expect <ref> [23] </ref> as a software platform for creating user-simulation scripts for testing experiments. In addition, we have enhanced expect with features that allow us to simulate more-sophisticated intrusions, and a feature that greatly facilitates script creation. <p> We employ the UNIX package expect <ref> [23] </ref> to simulate users in our testing experiments. The expect package is based on another UNIX package called Tcl (Tool command language) [29]. Using the expect language, we can write scripts (similar 7 to UNIX shell scripts) that include intrusive commands. <p> Such a script could be constructed by combining several of the scripts from the Basic Detection Test. expect includes a mechanism that allows the user to specify how quickly consecutive script commands will be issued <ref> [23] </ref>. Such a mechanism should be used for this stress script so that the commands are issued at a high rate. The script should be run once. Then, a modified version of the script should be created, which generates the same commands, but at a much slower rate.
Reference: [24] <author> T. F. Lunt et al., "IDES: </author> <title> A Progress Report," </title> <booktitle> Proc., Sixth Annual Computer Security Applications Conference, </booktitle> <address> Tucson, AZ, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: IDSs have been developed and used at several institutions. Some example IDSs are National Security Agency's Multics Intrusion Detection and Alerting System (MIDAS) [31], AT&T's ComputerWatch [9], SRI International's Intrusion Detection Expert System (IDES) <ref> [24, 25] </ref> and Next-Generation Intrusion-Detection Expert System (NIDES) [1], UC Santa Barbara's State Transition Analysis Tool for UNIX (USTAT) [15, 16], Los Alamos National Laboratory's (LANL's) Network Anomaly Detection and Intrusion Reporter (NADIR) [14], and UC Davis' Network Security Monitor (NSM) [13] and Distributed Intrusion Detection System (DIDS) [33].
Reference: [25] <author> T. F. Lunt et al., </author> <title> "A Real-Time Intrusion Detection Expert System(IDES)," </title> <type> Interim Progress Report, Project 6784, </type> <institution> SRI International, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: IDSs have been developed and used at several institutions. Some example IDSs are National Security Agency's Multics Intrusion Detection and Alerting System (MIDAS) [31], AT&T's ComputerWatch [9], SRI International's Intrusion Detection Expert System (IDES) <ref> [24, 25] </ref> and Next-Generation Intrusion-Detection Expert System (NIDES) [1], UC Santa Barbara's State Transition Analysis Tool for UNIX (USTAT) [15, 16], Los Alamos National Laboratory's (LANL's) Network Anomaly Detection and Intrusion Reporter (NADIR) [14], and UC Davis' Network Security Monitor (NSM) [13] and Distributed Intrusion Detection System (DIDS) [33]. <p> So, the IDS attempts to characterize each user's normal behavior, often by maintaining statistical profiles of each user's activities <ref> [25, 17] </ref>. Each profile includes information about the user's computing behavior such as normal login time, duration of login session, CPU usage, disk usage, favorite editor, and so forth. The IDS can then use the profiles to monitor current user activity and compare it with past user activity.
Reference: [26] <author> G. J. Myers, </author> <title> The Art of Software Testing, </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1979. </year>
Reference-contexts: This technique is known in the software-testing field as equivalence partitioning <ref> [26] </ref>. Ideally, the classes should be selected such that, within each class, either the IDS detects each intrusion, or the IDS does not detect any intrusions [34]. Then, one test case from each class can be selected to represent the class in the final set of test cases. <p> We have divided the test procedures into three categories, which correspond directly to the three performance objectives described earlier in Section 4.1. Several of the test procedures are adaptations of the "higher-order" software-testing methods described by Myers <ref> [26] </ref>. 5.1 Intrusion Identification Tests The two Intrusion Identification Tests measure the ability of the IDS to distinguish known intrusions from normal behavior.
Reference: [27] <author> B. Mukherjee, L. T. Heberlein, and K. N. Levitt, </author> <title> "Network Intrusion Detection," </title> <journal> IEEE Network, </journal> <volume> vol. 8, no. 3, </volume> <pages> pp. 26-41, </pages> <month> May/June </month> <year> 1994. </year>
Reference-contexts: 1 INTRODUCTION An intrusion detection system (IDS) is a system that attempts to identify intrusions, which we define to be unauthorized uses, misuses, or abuses of computer systems by either authorized users or external perpetrators <ref> [27] </ref>. Some IDSs monitor a single computer, while others monitor several computers connected by a network. IDSs detect intrusions by analyzing information about user activity from sources such as audit records, system tables, and network traffic summaries. IDSs have been developed and used at several institutions. <p> For instance, there are a number of security flaws inherent in the widely-used Transmission Control Protocol/Internet Protocol (TCP/IP) suite, regardless of its particular implementation [4]. PREVENTION INVESTIGATION POST-MORTEM DETECTION In response to these difficulties in developing secure systems (which are discussed further in <ref> [27] </ref>), a new model of system security management [2] has emerged. The model is pictured in identifies security breaches. The investigation component determines exactly what happened based on data from the detection component. This component may also include the gathering of further data in order to identify the security violator. <p> Often, the main source of information about user activity for an IDS is the set of audit records from the computer system. However, relying on audit records alone can be problematic <ref> [27] </ref>. First, audit records may not arrive in a timely fashion. Some IDSs use a separate computer to perform the analysis of audit records (e.g., Haystack [32]).
Reference: [28] <author> P. G. Neumann and D. B. Parker, </author> <title> "A Summary of Computer Misuse Techniques," </title> <booktitle> Proc., 12th National Computer Security Conference, </booktitle> <address> Baltimore, MD, </address> <pages> pp. 396-407, </pages> <month> Oc-tober </month> <year> 1989. </year> <month> 24 </month>
Reference-contexts: However, evaluating an IDS is a difficult task. First, it can be difficult or impossible to identify the set of all possible intrusions that might occur at the site where a particular IDS is employed. To start with, the number of intrusion techniques is quite large (e.g., see <ref> [28] </ref>). Then, the site may not have access to information about all of the intrusions that have been detected in the past at other locations. Also, intruders can discover previously unknown vulnerabilities in a computer system, and then use new intrusion techniques to exploit the vulnerabilities. <p> Some sites report that they are the targets of hundreds of intrusion attempts per month [3]. Moreover, there are numerous different intrusion techniques used by intruders <ref> [28] </ref>. <p> However, in general, it is difficult to identify perfect equivalence classes [34]. Now, we consider some possible strategies for classifying intrusions. Intrusions can be classified according to the intrusion technique. A comprehensive example of this type of classification is presented in <ref> [28] </ref>. A second strategy is to classify intrusions based on a taxonomy of the system vulnerabilities that the intrusions exploit (e.g., see [5, 21]).
Reference: [29] <author> J. K. Ousterhout, </author> <title> Tcl and the Tk Toolkit, </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
Reference-contexts: As background, Section 2 of this paper presents some examples of intrusions, provides motivation for intrusion detection, and discusses specific approaches to intrusion detection. Section 3 describes a software platform for testing experiments, which consists of expect (which, in turn, is based on Tcl <ref> [29] </ref>) and our enhancements. Section 4 begins the discussion of our testing methodology by first identifying a set of important IDS performance objectives, and then discussing the selection of test cases, and some limitations to our approach. Section 5 describes our specific procedures for testing experiments in detail. <p> We employ the UNIX package expect [23] to simulate users in our testing experiments. The expect package is based on another UNIX package called Tcl (Tool command language) <ref> [29] </ref>. Using the expect language, we can write scripts (similar 7 to UNIX shell scripts) that include intrusive commands. For running the scripts, expect provides a script interpreter which issues the script commands to the computer system just as if a real user had typed in the commands.
Reference: [30] <author> D. R. Safford, D. L. Schales, and D. K. Hess, </author> <title> "The TAMU Security Package: An Ongoing Response to Internet Intruders in an Academic Environment," </title> <booktitle> Proc., Fourth USENIX UNIX Security Symposium, </booktitle> <address> Santa Clara, CA, </address> <pages> pp. 91-118, </pages> <month> October, </month> <year> 1993. </year>
Reference-contexts: For UNIX systems, [20] and [5] report that intrusion data can be obtained from various sources, such as CERT advisories, periodicals such as PHRACK and 2600, and the USENET [10], and also by analyzing the vulnerabilities detected by security tools such as COPS [11] and TIGER <ref> [30] </ref>. Next, assuming that the number of intrusions is too large to simulate all of them, the testers must partition the set of intrusions into classes, and then create a representative subset of intrusions by selecting one or more intrusions from each class.
Reference: [31] <author> M. M. Sebring, E. Shellhouse, M. E. Hanna, and R. A. Whitehurst, </author> <title> "Expert Systems in Intrusion Detection: A Case Study," </title> <booktitle> Proc., 11th National Computer Security Conference, </booktitle> <address> Baltimore, MD, </address> <pages> pp. 74-81, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: IDSs detect intrusions by analyzing information about user activity from sources such as audit records, system tables, and network traffic summaries. IDSs have been developed and used at several institutions. Some example IDSs are National Security Agency's Multics Intrusion Detection and Alerting System (MIDAS) <ref> [31] </ref>, AT&T's ComputerWatch [9], SRI International's Intrusion Detection Expert System (IDES) [24, 25] and Next-Generation Intrusion-Detection Expert System (NIDES) [1], UC Santa Barbara's State Transition Analysis Tool for UNIX (USTAT) [15, 16], Los Alamos National Laboratory's (LANL's) Network Anomaly Detection and Intrusion Reporter (NADIR) [14], and UC Davis' Network Security Monitor
Reference: [32] <author> S. E. Smaha, "Haystack: </author> <title> An Intrusion Detection System," </title> <booktitle> Proc., IEEE Fourth Aerospace Computer Security Applications Conference, </booktitle> <address> Orlando, FL, </address> <month> December </month> <year> 1988. </year>
Reference-contexts: However, relying on audit records alone can be problematic [27]. First, audit records may not arrive in a timely fashion. Some IDSs use a separate computer to perform the analysis of audit records (e.g., Haystack <ref> [32] </ref>). So, it may take a significant amount of time to transfer the audit information from the monitored computer to the computer which performs the analysis. Second, the audit system itself may be vulnerable.
Reference: [33] <author> S. Snapp, J. Brentano, G. Dias, T. Goan, L. Heberlein, C. Ho, K. Levitt, B. Mukherjee, S. Smaha, T. Grance, D. Teal, and D. Mansur, </author> <title> "DIDS (Distributed Intrusion Detection System) Motivation, Architecture, and An Early Prototype ," Proc., </title> <booktitle> 14th National Computer Security Conference, </booktitle> <address> Washington, D.C., </address> <pages> pp. 167-176, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: System (IDES) [24, 25] and Next-Generation Intrusion-Detection Expert System (NIDES) [1], UC Santa Barbara's State Transition Analysis Tool for UNIX (USTAT) [15, 16], Los Alamos National Laboratory's (LANL's) Network Anomaly Detection and Intrusion Reporter (NADIR) [14], and UC Davis' Network Security Monitor (NSM) [13] and Distributed Intrusion Detection System (DIDS) <ref> [33] </ref>. As more and more organizations depend on IDSs as integral components of their computer security systems, techniques for evaluating IDSs are becoming more important. <p> Intruders have been known to be able to turn off the audit system or to modify the audit records to hide their intrusions. Finally, the audit records may not contain enough information to detect certain intrusions. For example, in the so-called doorknob attack <ref> [33] </ref>, an intruder tries to guess passwords of accounts on several computers in a network. To avoid arousing suspicion, the intruder attempts only a few guesses on each individual computer. <p> Thus, DIDS is capable of recognizing network intrusions such as the aforementioned doorknob attack. A number of other scenarios in which the aggregation of information from a network of computers is necessary to detect intrusions is described in <ref> [33] </ref>. User Interface Expert System Communications Manager Host DIDS Director Monitored Host Monitored Host Local Area Network (Ethernet) LAN Monitor Communications Agent Host Monitor Communications Host Monitor Communications Agent Agent To conclude this section, we describe the components of an elaborate IDS by way of an example.
Reference: [34] <author> E. J. Weyuker and B. Jeng, </author> <title> "Analyzing Partition Testing Strategies," </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 17, no. 7, </volume> <pages> pp. 703-711, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: This technique is known in the software-testing field as equivalence partitioning [26]. Ideally, the classes should be selected such that, within each class, either the IDS detects each intrusion, or the IDS does not detect any intrusions <ref> [34] </ref>. Then, one test case from each class can be selected to represent the class in the final set of test cases. However, in general, it is difficult to identify perfect equivalence classes [34]. Now, we consider some possible strategies for classifying intrusions. <p> within each class, either the IDS detects each intrusion, or the IDS does not detect any intrusions <ref> [34] </ref>. Then, one test case from each class can be selected to represent the class in the final set of test cases. However, in general, it is difficult to identify perfect equivalence classes [34]. Now, we consider some possible strategies for classifying intrusions. Intrusions can be classified according to the intrusion technique. A comprehensive example of this type of classification is presented in [28].
Reference: [35] <author> K. Zhang, </author> <title> A Methodology for Testing Intrusion Detection Systems, M.S. </title> <type> Thesis, </type> <institution> University of California at Davis, </institution> <month> May </month> <year> 1993. </year> <month> 25 </month>
Reference-contexts: We have augmented expect with some additional commands that provide the capability to create concurrent scripts, complete with mechanisms for synchronization and communication among different scripts <ref> [35, 7] </ref>. These extensions to expect provide users with the ability to simulate concurrent intrusions, which were described in Section 2.2. Often, in the course of testing an IDS, it may be necessary to repeat a particular test.
References-found: 35

