URL: http://www.math.tau.ac.il/~reisfeld/papers/prl.ps.gz
Refering-URL: http://www.cnl.salk.edu/~wiskott/Bibliographies/FaceProcessing.html
Root-URL: http://www.cnl.salk.edu/~wiskott/Bibliographies/FaceProcessing.html
Title: Face Recognition using a Hybrid Supervised/Unsupervised Neural Network  
Author: Nathan Intrator Daniel Reisfeld Yehezkel Yeshurun 
Keyword: Key words: Face recognition, Neural Networks, Interest points, Symmetry operator.  
Date: Revised: June 22, 1995  
Address: Ramat Aviv 69978, Israel  
Affiliation: Department of Computer Science Tel-Aviv University  
Abstract: A system for automatic face recognition is presented. It consists of several steps; Automatic detection of the eyes and mouth is followed by a spatial normalization of the images. The classification of the normalized images is carried out by a hybrid (supervised and unsupervised) Neural Network. Two methods for reducing the overfitting a common problem in high dimensional classification schemes are presented, and the superiority of their combination is demonstrated. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. E. Bellman. </author> <title> Adaptive Control Processes. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1961. </year>
Reference-contexts: Another approach [21, 30], is based on direct processing of the grey level images. A review of face processing systems could be found in [6, 29]. The task of recognizing faces is inherently a classification problem in high dimensional feature space, and thus subject to the "curse of dimensionality" <ref> [1] </ref> which essentially says that the number of training patterns needed for robust classification, should be restrictively high. Regarding an image merely as a matrix and looking for algebraic invariants [13] reduces the dimensionality.
Reference: [2] <author> E. L. Bienenstock, L. N. Cooper, and P. W. Munro. </author> <title> Theory for the development of neuron selectivity: orientation specificity and binocular interaction in visual cortex. </title> <journal> Journal Neuroscience, </journal> <volume> 2 </volume> <pages> 32-48, </pages> <year> 1982. </year>
Reference-contexts: The application of the hybrid training in a feed-forward neural network is done by modifying the learning rule of the hidden units to reflect the additional constraints (Figure 3). 4 the warped image. The unsupervised feature extraction which we used, is based on the biologically motived BCM neuron <ref> [2] </ref>. <p> The Figure of Merit, s, is calculated as s = 100 Rejections 10 fi substitutions. Two points are worth mentioning in the results. First, as is often found, network ensemble reduces classification error. The results of networks trained with additional bias constraints in the form of BCM <ref> [17, 2] </ref> are intriguing; While the mean performance of networks trained with additional (bias) constraints, which are supposed to seek structure in the form of multi-modality, is slightly 9 a hybrid BCM/Back-Propagation Network (right) and by using a Hybrid BCM/Back-Propagation Network (right) worse compared to networks that were not trained with
Reference: [3] <author> M. Bischel and A. Pentland. </author> <title> Human face recognition and the face image set's topology. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 59(2) </volume> <pages> 254-261, </pages> <year> 1994. </year>
Reference-contexts: However, such algebraic constraints can be designed to be invariant to practically any transformation but they are too general. For instance they are not affected by upside down inversion, while biological systems are [24]. A recent approach to this problem <ref> [3] </ref> is based on the finding that facial images are projected to connected domains (an extension of clusters) and thus could be used to reduce dimensionality. An alternative approach for the reduction of the dimensionality is to use a limited set of biologically motivated receptive fields [23, 10].
Reference: [4] <author> W.W. Bledsoe. </author> <title> Man-machine facial recognition. </title> <type> Technical Report Rep. </type> <institution> PRI:22, Panoramic Research Inc., </institution> <address> Palo Alto, CA, </address> <month> August </month> <year> 1966. </year>
Reference-contexts: 1 Introduction Automatic face recognition has gained much attention in recent years, due to the variety of potential applications, and the increase in computational power which enables effective implementation of algorithms. Traditionally, face recognition was based on extracting certain features (e.g. spatial location of facial features and their geometrical relations) <ref> [4, 20] </ref>. These features are detected either manually, or by automatic algorithms [32, 8, 7, 27]. Another approach [21, 30], is based on direct processing of the grey level images. A review of face processing systems could be found in [6, 29].
Reference: [5] <author> L. Breiman. </author> <title> Stacked regression. </title> <type> Technical Report TR-367, </type> <institution> Department of Statistics, University of California, Berkeley, </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: This network ensemble average method can simply be considered as reducing the variance of the network outputs (considered as random variables) by summing over an ensemble of networks [22]. This technique has been shown to be a good stabilizer for neural network results <ref> [5] </ref>. Often the cost of making a mistake (substitution error) is larger than the cost of no decision (rejection). In digit recognition, a frequent classification measure suitable in such cases is the figure of merit, in which the cost of substitution is 10 times the cost of rejection.
Reference: [6] <author> V. Bruce and M. Burton. </author> <title> Computer recognition of faces. </title> <editor> In A.W. Young and H.D. Ellis, editors, </editor> <booktitle> Handbook of face processing, </booktitle> <pages> pages 487-506. </pages> <publisher> Elsevier Science publisher, B.V. (North-Holland), </publisher> <year> 1989. </year>
Reference-contexts: These features are detected either manually, or by automatic algorithms [32, 8, 7, 27]. Another approach [21, 30], is based on direct processing of the grey level images. A review of face processing systems could be found in <ref> [6, 29] </ref>. The task of recognizing faces is inherently a classification problem in high dimensional feature space, and thus subject to the "curse of dimensionality" [1] which essentially says that the number of training patterns needed for robust classification, should be restrictively high.
Reference: [7] <author> R. Brunelli and T. Poggio. </author> <title> Face recognition through geometrical features. </title> <booktitle> In Proceedings of the 2nd European Conference on Computer Vision, </booktitle> <pages> pages 972-800, </pages> <address> Santa Margherita Ligure, Italy, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: Traditionally, face recognition was based on extracting certain features (e.g. spatial location of facial features and their geometrical relations) [4, 20]. These features are detected either manually, or by automatic algorithms <ref> [32, 8, 7, 27] </ref>. Another approach [21, 30], is based on direct processing of the grey level images. A review of face processing systems could be found in [6, 29].
Reference: [8] <author> I. Craw, D. Tock, and A. Bennet. </author> <title> Finding face features. </title> <booktitle> In Proceedings of the 2nd European Conference on Computer Vision, </booktitle> <pages> pages 92-96, </pages> <address> Santa Margherita Ligure, Italy, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: Traditionally, face recognition was based on extracting certain features (e.g. spatial location of facial features and their geometrical relations) [4, 20]. These features are detected either manually, or by automatic algorithms <ref> [32, 8, 7, 27] </ref>. Another approach [21, 30], is based on direct processing of the grey level images. A review of face processing systems could be found in [6, 29].
Reference: [9] <author> G.M. Davis, H.D. Ellis, and J.W. Shepherd. </author> <title> Face recognition accuracy as a function of mode of representation. </title> <journal> Journal of Applied Psychology, </journal> <volume> 63 </volume> <pages> 180-187, </pages> <year> 1978. </year>
Reference-contexts: The extremum parts of the image (both negative dark, and positive bright) indicate the important features. Notice that the head outline, eyes and mouth are more salient on the Hybrid BCM/BP method (right) than on the BP method (left). This is more consistent with psychophysical experiments <ref> [9, 11] </ref> that show that more attention is devoted to prominent facial features such as eyes and mouth. Such interpretability method may be useful for human psychophysics studies, and for possible comparison between human and machine recognition, and for the study of object features.
Reference: [10] <author> S. Edelman, D. Reisfeld, and Y. Yeshurun. </author> <title> Learning to recognize faces from examples. </title> <booktitle> In Proceedings of the 2nd European Conference on Computer Vision, </booktitle> <pages> pages 787-791, </pages> <address> Santa Margherita Ligure, Italy, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: An alternative approach for the reduction of the dimensionality is to use a limited set of biologically motivated receptive fields <ref> [23, 10] </ref>. Yet another way to overcome the "curse" is to base the recognition on a small number of linear combinations (projections) of the high dimensional space. This approach is at the heart of projection pursuit methods [15] and neural network methods. <p> Previous results using the same preprocessing and dimensionality reduction using receptive fields and radial basis function networks have been described in <ref> [10] </ref>. The database we used contained 27 instances of each of 16 different persons. The images were taken under varying illumination and camera location. Of the 27 images, 17 were randomly chosen for each person to be used in training, while the remaining 10 were used for testing. <p> The implication of this finding is that another transformation was needed to reduce the dimensionality to a more invariant image representation. Earlier work with Radial Basis Function (RBF) classification <ref> [10] </ref> produced similar results to one nearest neighbor scheme on the warped images (Table 3,5). 5.2 Principal component extraction Due to the success of principal components for face recognition [21, 30], we have studied the classification performance based on projections onto a varying number of principal components extracted from the data
Reference: [11] <author> I. Fraser and D. Parker. </author> <title> Reaction time measures of feature saliency in perceptual integration task. </title> <editor> In H. Ellis, M. Jeeves, F. Newcombe, and A.W. Young, editors, </editor> <title> Aspects of Face Processing. </title> <publisher> Martinus Nijhoff, </publisher> <address> Dordrecht, </address> <year> 1986. </year>
Reference-contexts: The extremum parts of the image (both negative dark, and positive bright) indicate the important features. Notice that the head outline, eyes and mouth are more salient on the Hybrid BCM/BP method (right) than on the BP method (left). This is more consistent with psychophysical experiments <ref> [9, 11] </ref> that show that more attention is devoted to prominent facial features such as eyes and mouth. Such interpretability method may be useful for human psychophysics studies, and for possible comparison between human and machine recognition, and for the study of object features.
Reference: [12] <author> S. Geman, E. Bienenstock, and R. Doursat. </author> <title> Neural networks and the bias-variance dilemma. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 1-58, </pages> <year> 1992. </year>
Reference-contexts: Since this method can approximate any continuous function, great care should be taken so that the variance of the estimated weights is small, and the model does not "overfit" the training data <ref> [12, for discussion] </ref>. This is often done using some form of complexity regularization such as weight decay [31, for review]. The performance of a single back-propagation network can be easily enhanced by training several different networks and averaging their result [22]. <p> These results are best explained by the bias/variance tradeoff <ref> [12, for review] </ref>; the effort to control the bias via bias constraints, increases the variance in single networks, however, the ensemble network averaging does not affect the bias, but reduces the variance leading to an overall improvement in classification results.
Reference: [13] <author> Zi-Quan Hong. </author> <title> Algebraic feature extraction of image for recognition. </title> <journal> Pattern Recognition, </journal> <volume> 24(3) </volume> <pages> 211-219, </pages> <year> 1991. </year>
Reference-contexts: Regarding an image merely as a matrix and looking for algebraic invariants <ref> [13] </ref> reduces the dimensionality. However, such algebraic constraints can be designed to be invariant to practically any transformation but they are too general. For instance they are not affected by upside down inversion, while biological systems are [24].
Reference: [14] <author> K. Hornik, M. Stinchcombe, and H. White. </author> <title> Universal approximation of an unknown mapping and its derivatives using multilayer feedforward networks. </title> <booktitle> Neural Networks, </booktitle> <volume> 3 </volume> <pages> 551-560, </pages> <year> 1990. </year>
Reference-contexts: The class of functions that can be approximated by a back-propagation type network is very large; This architecture (with an unlimited number of projections) can uniformly approximate arbitrary continuous functions on compact sets, as well as their derivatives <ref> [14] </ref>. The ability to approximate a function and its derivatives will be used below for model interpretability. The error is propagated backwards to the previous (hidden) layer for modification of its synaptic weights (projections).
Reference: [15] <author> P. J. Huber. </author> <title> Projection pursuit. (with discussion). </title> <journal> The Annals of Statistics, </journal> <volume> 13 </volume> <pages> 435-475, </pages> <year> 1985. </year>
Reference-contexts: Yet another way to overcome the "curse" is to base the recognition on a small number of linear combinations (projections) of the high dimensional space. This approach is at the heart of projection pursuit methods <ref> [15] </ref> and neural network methods. Taking this approach, one is then confronted with the task of finding such an optimal projection.
Reference: [16] <author> N. Intrator. </author> <title> Combining exploratory projection pursuit and projection pursuit regression with application to neural networks. </title> <journal> Neural Computation, </journal> <volume> 5(3) </volume> <pages> 443-455, </pages> <year> 1993. </year>
Reference-contexts: In this paper we adopt a different approach to dimensionality reduction and classification, based on a combination of supervised and unsupervised learning <ref> [16] </ref>. We first automatically detect the eyes and the mouth in face image by using the Generalized Symmetry Transform, and use this information to normalize the images by affine transformation. We then proceed to classification. <p> This is often done using some form of complexity regularization such as weight decay [31, for review]. The performance of a single back-propagation network can be easily enhanced by training several different networks and averaging their result [22]. On this network ensemble, we have used a hybrid training method <ref> [16] </ref>. This method is based on a formulation that combines unsupervised (exploratory) methods for finding structure (extracting features) and supervised methods for reducing classification error. The unsupervised training portion is aimed at finding features such as clusters.
Reference: [17] <author> N. Intrator and L. N. Cooper. </author> <title> Objective function formulation of the BCM theory of visual cortical plasticity: Statistical connections, stability conditions. </title> <booktitle> Neural Networks, </booktitle> <volume> 5 </volume> <pages> 3-17, </pages> <year> 1992. </year>
Reference-contexts: It was found to be applicable for extracting features from very high dimensional vector spaces [18]. Below is a brief description of the unsupervised portion of the network (see <ref> [17] </ref> for details.) The activity of neuron k in the network is c k = P i x i w ik + w 0k . <p> Training was done using the back-propagation algorithm [28] for the supervised part and using the projection pursuit learning <ref> [17] </ref> for the unsupervised part. For comparison, we also report classification results based on other classification techniques. The calculation of significance of the object features for recognition was done via a newly introduced method for interpreting neural networks which is described elsewhere [19]. <p> The Figure of Merit, s, is calculated as s = 100 Rejections 10 fi substitutions. Two points are worth mentioning in the results. First, as is often found, network ensemble reduces classification error. The results of networks trained with additional bias constraints in the form of BCM <ref> [17, 2] </ref> are intriguing; While the mean performance of networks trained with additional (bias) constraints, which are supposed to seek structure in the form of multi-modality, is slightly 9 a hybrid BCM/Back-Propagation Network (right) and by using a Hybrid BCM/Back-Propagation Network (right) worse compared to networks that were not trained with
Reference: [18] <author> N. Intrator and J. I. Gold. </author> <title> Three-dimensional object recognition of gray level images: The usefulness of distinguishing features. </title> <journal> Neural Computation, </journal> <volume> 5 </volume> <pages> 61-74, </pages> <year> 1993. </year>
Reference-contexts: It was found to be applicable for extracting features from very high dimensional vector spaces <ref> [18] </ref>. Below is a brief description of the unsupervised portion of the network (see [17] for details.) The activity of neuron k in the network is c k = P i x i w ik + w 0k .
Reference: [19] <author> O. Intrator and N. Intrator. </author> <title> Using neural networks for interpretation of nonlinear models. </title> <journal> In American Statistical Society: 1993 Proceedings of the Statistical Computing Section, </journal> <pages> pages 244-249. </pages> <institution> American Statistical Association, </institution> <month> August </month> <year> 1993. </year> <month> 13 </month>
Reference-contexts: For comparison, we also report classification results based on other classification techniques. The calculation of significance of the object features for recognition was done via a newly introduced method for interpreting neural networks which is described elsewhere <ref> [19] </ref>. This method extends the interpretability associated with linear or logistic regression to feed-forward neural networks. 4 Experimental Methodology We have used a subset of the MIT Media Lab database of face images, courtesy of Turk and Pentland [30]. <p> There are various robustification issues related to the fact that the models which a network converges to are not unique. The full details of the method are described in <ref> [19] </ref>. The images presented in Figure 6 give the relative importance of parts of the images for the recognition of that specific prototype. The extremum parts of the image (both negative dark, and positive bright) indicate the important features.
Reference: [20] <author> T. Kanade. </author> <title> Picture processing system by computer complex and recognition of human faces. </title> <type> PhD thesis, </type> <institution> Dept. of Information Science, Kyoto University, </institution> <month> November </month> <year> 1973. </year>
Reference-contexts: 1 Introduction Automatic face recognition has gained much attention in recent years, due to the variety of potential applications, and the increase in computational power which enables effective implementation of algorithms. Traditionally, face recognition was based on extracting certain features (e.g. spatial location of facial features and their geometrical relations) <ref> [4, 20] </ref>. These features are detected either manually, or by automatic algorithms [32, 8, 7, 27]. Another approach [21, 30], is based on direct processing of the grey level images. A review of face processing systems could be found in [6, 29].
Reference: [21] <author> M. Kirby and L. Sirovich. </author> <title> Application of the Karhunen-Loeve procedure for characterization of human faces. </title> <journal> IEEE Transactions Pattern Analysis and Machine Intelligence, </journal> <volume> 12(1) </volume> <pages> 103-108, </pages> <year> 1990. </year>
Reference-contexts: Traditionally, face recognition was based on extracting certain features (e.g. spatial location of facial features and their geometrical relations) [4, 20]. These features are detected either manually, or by automatic algorithms [32, 8, 7, 27]. Another approach <ref> [21, 30] </ref>, is based on direct processing of the grey level images. A review of face processing systems could be found in [6, 29]. <p> Taking this approach, one is then confronted with the task of finding such an optimal projection. A commonly used approach is based on second order statistics of the data where one extracts the directions in which the variance is maximized also called the principal components of the data <ref> [21, 30] </ref>. In this paper we adopt a different approach to dimensionality reduction and classification, based on a combination of supervised and unsupervised learning [16]. <p> Earlier work with Radial Basis Function (RBF) classification [10] produced similar results to one nearest neighbor scheme on the warped images (Table 3,5). 5.2 Principal component extraction Due to the success of principal components for face recognition <ref> [21, 30] </ref>, we have studied the classification performance based on projections onto a varying number of principal components extracted from the data (PC fetures).
Reference: [22] <author> W. P. Lincoln and J. Skrzypek. </author> <title> Synergy of clustering multiple back-propagation networks. </title> <editor> In D. S. Touretzky and R. P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 2, </volume> <pages> pages 650-657. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: This is often done using some form of complexity regularization such as weight decay [31, for review]. The performance of a single back-propagation network can be easily enhanced by training several different networks and averaging their result <ref> [22] </ref>. On this network ensemble, we have used a hybrid training method [16]. This method is based on a formulation that combines unsupervised (exploratory) methods for finding structure (extracting features) and supervised methods for reducing classification error. The unsupervised training portion is aimed at finding features such as clusters. <p> This network ensemble average method can simply be considered as reducing the variance of the network outputs (considered as random variables) by summing over an ensemble of networks <ref> [22] </ref>. This technique has been shown to be a good stabilizer for neural network results [5]. Often the cost of making a mistake (substitution error) is larger than the cost of no decision (rejection).
Reference: [23] <author> B.S. Manjunath, R. Chellappa, and C. von der Malsburg. </author> <title> A feature based approach to face recognition. </title> <type> Technical Report CS-TR-2834, </type> <institution> Center for Automated Research. University of Maryland, </institution> <year> 1992. </year>
Reference-contexts: An alternative approach for the reduction of the dimensionality is to use a limited set of biologically motivated receptive fields <ref> [23, 10] </ref>. Yet another way to overcome the "curse" is to base the recognition on a small number of linear combinations (projections) of the high dimensional space. This approach is at the heart of projection pursuit methods [15] and neural network methods.
Reference: [24] <author> Y. Moses, S. Ullman, and S. Edelman. </author> <title> Selective attention gates visual processing in the extrastriate cortex. </title> <type> Technical report, </type> <institution> The Weizmann Institute of Science, </institution> <year> 1993. </year>
Reference-contexts: Regarding an image merely as a matrix and looking for algebraic invariants [13] reduces the dimensionality. However, such algebraic constraints can be designed to be invariant to practically any transformation but they are too general. For instance they are not affected by upside down inversion, while biological systems are <ref> [24] </ref>. A recent approach to this problem [3] is based on the finding that facial images are projected to connected domains (an extension of clusters) and thus could be used to reduce dimensionality.
Reference: [25] <author> D. Reisfeld, H. Wolfson, and Y. Yeshurun. </author> <title> Detection of interest points using symmetry. </title> <booktitle> In Proceedings of the 3rd International Conference on Computer Vision, </booktitle> <pages> pages 62-65, </pages> <address> Osaka, Japan, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: We detect the eyes and mouth in face images using the Generalized Symmetry Transform, and then we warp the face image to a "standard" location using these points. The Generalized Symmetry Transform is described in <ref> [26, 25] </ref>.
Reference: [26] <author> D. Reisfeld, H. Wolfson, and Y. Yeshurun. </author> <title> Context free attentional operators: the generalized symmetry transform. </title> <journal> Int. J. of Computer Vision, Special Issue on Qualitative Vision, </journal> <volume> 14 </volume> <pages> 119-130, </pages> <year> 1995. </year>
Reference-contexts: We detect the eyes and mouth in face images using the Generalized Symmetry Transform, and then we warp the face image to a "standard" location using these points. The Generalized Symmetry Transform is described in <ref> [26, 25] </ref>. <p> In this paper we have used the following operations on face images in order to detect the location of the eyes and mouth: * Computation of the symmetry magnitude and orientation. This is the standard Symmetry operation described before. * Computation of the Radial Symmetry (RS) <ref> [26] </ref>.
Reference: [27] <author> D. Reisfeld and Y. Yeshurun. </author> <title> Facial normalization using few anchor points. </title> <booktitle> In Proceedings of the 12th IAPR International Conference on Pattern Recognition, </booktitle> <address> Jerusalem, Israel, </address> <year> 1994. </year>
Reference-contexts: Traditionally, face recognition was based on extracting certain features (e.g. spatial location of facial features and their geometrical relations) [4, 20]. These features are detected either manually, or by automatic algorithms <ref> [32, 8, 7, 27] </ref>. Another approach [21, 30], is based on direct processing of the grey level images. A review of face processing systems could be found in [6, 29].
Reference: [28] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In D. E. Rumelhart and J. L. McClelland, editors, </editor> <booktitle> Parallel Distributed Processing, </booktitle> <volume> volume 1, </volume> <pages> pages 318-362. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: In the results Synaptic modification based on back-propagation rule and the EPP learning rule Internal Representation Unit to the hidden layer units only. reported here, a feed-forward architecture with a single hidden layer of 12 units was used in all the experiments. Training was done using the back-propagation algorithm <ref> [28] </ref> for the supervised part and using the projection pursuit learning [17] for the unsupervised part. For comparison, we also report classification results based on other classification techniques.
Reference: [29] <author> A. Samal and P.A. Iyengar. </author> <title> Automatic recognition and analysis of human faces and facial expressions: A survey. </title> <journal> Pattern Recognition, </journal> <volume> 25(1) </volume> <pages> 65-77, </pages> <year> 1992. </year>
Reference-contexts: These features are detected either manually, or by automatic algorithms [32, 8, 7, 27]. Another approach [21, 30], is based on direct processing of the grey level images. A review of face processing systems could be found in <ref> [6, 29] </ref>. The task of recognizing faces is inherently a classification problem in high dimensional feature space, and thus subject to the "curse of dimensionality" [1] which essentially says that the number of training patterns needed for robust classification, should be restrictively high.
Reference: [30] <author> M. Turk and A. Pentland. </author> <title> Eigenfaces for recognition. </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> 3(1) </volume> <pages> 71-86, </pages> <year> 1991. </year>
Reference-contexts: Traditionally, face recognition was based on extracting certain features (e.g. spatial location of facial features and their geometrical relations) [4, 20]. These features are detected either manually, or by automatic algorithms [32, 8, 7, 27]. Another approach <ref> [21, 30] </ref>, is based on direct processing of the grey level images. A review of face processing systems could be found in [6, 29]. <p> Taking this approach, one is then confronted with the task of finding such an optimal projection. A commonly used approach is based on second order statistics of the data where one extracts the directions in which the variance is maximized also called the principal components of the data <ref> [21, 30] </ref>. In this paper we adopt a different approach to dimensionality reduction and classification, based on a combination of supervised and unsupervised learning [16]. <p> This method extends the interpretability associated with linear or logistic regression to feed-forward neural networks. 4 Experimental Methodology We have used a subset of the MIT Media Lab database of face images, courtesy of Turk and Pentland <ref> [30] </ref>. Previous results using the same preprocessing and dimensionality reduction using receptive fields and radial basis function networks have been described in [10]. The database we used contained 27 instances of each of 16 different persons. The images were taken under varying illumination and camera location. <p> First, we describe the main building blocks of our recognition scheme, and then we proceed with the more refined and unique methods which further improved the results. We start with a discussion on the image background of the Turk and Pentland database <ref> [30] </ref>. 5.1 Preprocessing Contribution of the facial background The faces in the Turk & Pentland data-set are part of a larger picture that contains some background scenery usually a laboratory room of some sort. <p> Earlier work with Radial Basis Function (RBF) classification [10] produced similar results to one nearest neighbor scheme on the warped images (Table 3,5). 5.2 Principal component extraction Due to the success of principal components for face recognition <ref> [21, 30] </ref>, we have studied the classification performance based on projections onto a varying number of principal components extracted from the data (PC fetures).
Reference: [31] <author> A. S. Weigend, D. E. Rumelhart, and B. A. Huberman. </author> <title> Generalization by weight-elimination with application to forecasting. </title> <editor> In R. P. Lippmann, J. E. Moody, and D. S. Touretzky, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 3, </volume> <pages> pages 875-882. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: Since this method can approximate any continuous function, great care should be taken so that the variance of the estimated weights is small, and the model does not "overfit" the training data [12, for discussion]. This is often done using some form of complexity regularization such as weight decay <ref> [31, for review] </ref>. The performance of a single back-propagation network can be easily enhanced by training several different networks and averaging their result [22]. On this network ensemble, we have used a hybrid training method [16]. <p> These results complement a different set of experiments which tried to study the effect of variance constraints on feed-forward neural networks. In that work, variance constraints in the form of weight decay <ref> [31] </ref> were used in a real-world character recognition problem. While performance of single networks improved on average, the performance of the network ensemble was worse than the performance of an ensemble of networks that were not trained using variance constraints.
Reference: [32] <author> A.L. Yuille, P.W. Halilinman, and D.S. Cohen. </author> <title> Feature extraction from faces using deformable templates. </title> <journal> International Journal of Computer Vision, </journal> <volume> 8(2) </volume> <pages> 99-111, </pages> <year> 1992. </year> <month> 14 </month>
Reference-contexts: Traditionally, face recognition was based on extracting certain features (e.g. spatial location of facial features and their geometrical relations) [4, 20]. These features are detected either manually, or by automatic algorithms <ref> [32, 8, 7, 27] </ref>. Another approach [21, 30], is based on direct processing of the grey level images. A review of face processing systems could be found in [6, 29].
References-found: 32

