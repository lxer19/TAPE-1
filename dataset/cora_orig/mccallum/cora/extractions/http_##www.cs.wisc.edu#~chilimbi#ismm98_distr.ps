URL: http://www.cs.wisc.edu/~chilimbi/ismm98_distr.ps
Refering-URL: http://www.cs.wisc.edu/areas/pl/seminar/
Root-URL: http://www.cs.wisc.edu
Note: 1. ABSTRACT  
Abstract-found: 0
Intro-found: 0
Reference: [1] <author> Brad Calder, Chandra Krintz, Simmi John, and Todd Austin. </author> <title> Cache-conscious data placement. </title> <booktitle> To appear in Proceedings of the Eight International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS VIII), </booktitle> <month> Oct. </month> <year> 1998. </year>
Reference-contexts: Prior research has focused on improving cache locality in scientific programs that manipulate dense matrices through program (loop) transformations [31, 3, 12]. Recently, Calder et al. described a profiledriven, compiler-directed approach to cache-conscious data placement <ref> [1] </ref>. Other work has demonstrated that programs which manipulate pointer-based structures can benefit greatly from cache-conscious structure layouts [9, 22]. This paper describes how a copying garbage collector can produce a cache-conscious object layout using real-time data Copyright 199x by the Association for Computing Machinery, Inc. <p> The rest of this section describes the design and implementation of a low-overhead, real-time data access profiler. In the most general case, profile-guided data placement requires tracing every load and store to heap data. The overhead of such tracing (factor of 10 or more <ref> [1] </ref>) precludes its use in real-time profiling. However, two properties of objectoriented programs permit low overhead data profiling.: most objects are small, often less than 32 bytes, and most object accesses are not lightweight. Section 7 provides experimental results to support these assumptions. <p> As our results indicate, techniques that improve a programs page locality, are not necessarily effective at the cache level. In addition, we attempt to lay out objects in program access order with real-time data profiling, rather than hardware support. Recently, Calder et al. <ref> [1] </ref> applied placement techniques developed for instruction caches to data. They use a compiler-directed approach that creates an address placement for the stack (local variables), global variables, heap objects, and constants in order to reduce data cache misses.
Reference: [2] <author> David Callahan, Ken Kennedy, and Allan Porterfield. </author> <title> Software prefetching. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASP LOS IV), </booktitle> <pages> pages 4052, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: As a result, many programs performance is dominated by memory references. A variety of hardware and software techniquessuch as prefetching <ref> [19, 2] </ref>, multithreading [16, 24], non-blocking caches [14], dynamic instruction scheduling, and speculative executionhave been developed and implemented to reduce or tolerate memory latency. These techniques require complex hardware and compilers, but have proven ineffective for many programs [21].
Reference: [3] <author> Steve Carr, Kathryn S. McKinley, and Chau-Wen Tseng. </author> <title> Compiler optimizations for improving data locality. </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS VI), </booktitle> <pages> pages 252262, </pages> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: The fundamental problem with these techniques is that they attack the manifestation (memory latency), not the source (poor reference locality), of the bottleneck. Prior research has focused on improving cache locality in scientific programs that manipulate dense matrices through program (loop) transformations <ref> [31, 3, 12] </ref>. Recently, Calder et al. described a profiledriven, compiler-directed approach to cache-conscious data placement [1]. Other work has demonstrated that programs which manipulate pointer-based structures can benefit greatly from cache-conscious structure layouts [9, 22].
Reference: [4] <author> Craig Chambers. </author> <title> Objectoriented multi-methods in Cecil. </title> <booktitle> In Proceedings ECOOP92, </booktitle> <publisher> LNCS 615, Springer-Verlag, </publisher> <pages> pages 3356, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: The garbage collector uses the profile to construct an object affinity graph, in which weighted edges encode the temporal affinity between objects (nodes). A new copying algorithm uses the affinity graph to produce cache-conscious data layouts while copying objects during garbage collection. Experimental results for five Cecil programs <ref> [4, 5] </ref> show that our cache-conscious data placement technique reduces cache miss rates by 2142% and improves program performance by 1437%. Other researchers have attempted to improve a programs virtual memory (page) locality by changing the traversal algorithm used by a copying garbage collector [18, 30, 15, 10]. <p> Vortex is a language-independent optimizing compiler for object-oriented languages, with front ends for Cecil, C++, Java, and Modula-3. Unfortunately, generational garbage collection currently only works with Cecil, though efforts are underway to extend this functionality to Java [6]. Cecil <ref> [4, 5] </ref> is a dynamically-typed, purely objectoriented language. It combines multi-methods with a simple classless object model, a kind of dynamic inheritance, and modules. Instance variables in Cecil are accessed solely through messages, and can be replaced or overridden by methods.
Reference: [5] <author> Craig Chambers. </author> <title> The Cecil language: Specification and rationale. </title> <institution> University of Washington Seattle, Tech nical Report TR-93-03-05, </institution> <month> Mar. </month> <year> 1993. </year>
Reference-contexts: The garbage collector uses the profile to construct an object affinity graph, in which weighted edges encode the temporal affinity between objects (nodes). A new copying algorithm uses the affinity graph to produce cache-conscious data layouts while copying objects during garbage collection. Experimental results for five Cecil programs <ref> [4, 5] </ref> show that our cache-conscious data placement technique reduces cache miss rates by 2142% and improves program performance by 1437%. Other researchers have attempted to improve a programs virtual memory (page) locality by changing the traversal algorithm used by a copying garbage collector [18, 30, 15, 10]. <p> Vortex is a language-independent optimizing compiler for object-oriented languages, with front ends for Cecil, C++, Java, and Modula-3. Unfortunately, generational garbage collection currently only works with Cecil, though efforts are underway to extend this functionality to Java [6]. Cecil <ref> [4, 5] </ref> is a dynamically-typed, purely objectoriented language. It combines multi-methods with a simple classless object model, a kind of dynamic inheritance, and modules. Instance variables in Cecil are accessed solely through messages, and can be replaced or overridden by methods.
Reference: [6] <author> Craig Chambers. </author> <type> Personal communication. </type> <month> March </month> <year> 1998. </year>
Reference-contexts: Vortex is a language-independent optimizing compiler for object-oriented languages, with front ends for Cecil, C++, Java, and Modula-3. Unfortunately, generational garbage collection currently only works with Cecil, though efforts are underway to extend this functionality to Java <ref> [6] </ref>. Cecil [4, 5] is a dynamically-typed, purely objectoriented language. It combines multi-methods with a simple classless object model, a kind of dynamic inheritance, and modules. Instance variables in Cecil are accessed solely through messages, and can be replaced or overridden by methods.
Reference: [7] <author> Craig Chambers, Jeffrey Dean, and David Grove. </author> <note> Whole-program optimization of objectoriented languages. </note> <institution> University of Washington Seattle, </institution> <type> Technical Report 96-06-02, </type> <month> June </month> <year> 1996. </year>
Reference-contexts: that objectoriented programs manipulate small objects (&lt; 32 bytes), to demonstrate that our real-time data profiling technique incurs low overhead, and finally, to measure the impact of our cache-conscious object layouts on program performance. 7.1 Experimental Methodology Our system uses the Vortex compiler infrastructure developed at the University of Washington <ref> [7] </ref>. Vortex is a language-independent optimizing compiler for object-oriented languages, with front ends for Cecil, C++, Java, and Modula-3. Unfortunately, generational garbage collection currently only works with Cecil, though efforts are underway to extend this functionality to Java [6]. Cecil [4, 5] is a dynamically-typed, purely objectoriented language. <p> The Cecil benchmark programs used in the experiments are described in Table 1. The programs were compiled at the highest optimization level (o2), which applies techniques such as class analysis, splitting, class hierarchy analysis, class prediction, closure delaying, and inlining, in addition to traditional optimizations <ref> [7] </ref>. (We were unable to compile .
Reference: [8] <author> C. J. </author> <title> Cheney. A nonrecursive list compacting algo rithm. </title> <journal> Communications of the ACM, </journal> <volume> 13(11):677678, </volume> <year> 1970. </year>
Reference-contexts: The blocks that previously held the generation can be reused. The new space to which generation objects are copied is called TO space and the old space is called FROM space [11]. A common traversal algorithm for copying objects into TO space is Cheneys algorithm <ref> [8] </ref> (the toolkit uses this algorithm, see Figure 2). Starting with the root set, objects are traversed in breadth-first order and copied to TO space as they are visited. Breadth-first traversal requires a queue.
Reference: [9] <author> Trishul M. Chilimbi, James R. Larus, and Mark D. Hill. </author> <title> Improving pointer-based codes through cache-con scious data placement. </title> <institution> University of Wisconsin-Madi son, </institution> <type> Technical Report CS-TR-98-1365, </type> <month> Mar. </month> <year> 1998. </year>
Reference-contexts: Recently, Calder et al. described a profiledriven, compiler-directed approach to cache-conscious data placement [1]. Other work has demonstrated that programs which manipulate pointer-based structures can benefit greatly from cache-conscious structure layouts <ref> [9, 22] </ref>. This paper describes how a copying garbage collector can produce a cache-conscious object layout using real-time data Copyright 199x by the Association for Computing Machinery, Inc.
Reference: [10] <author> R. Courts. </author> <title> Improving locality of reference in a gar bage-collecting memory management system. </title> <booktitle> Com munications of the ACM, </booktitle> <address> 31(9):11281138, </address> <year> 1988. </year>
Reference-contexts: Other researchers have attempted to improve a programs virtual memory (page) locality by changing the traversal algorithm used by a copying garbage collector <ref> [18, 30, 15, 10] </ref>. We compare our cache-conscious copying scheme against one such algorithm (the Wilson-Lam-Moher algorithm [30]). <p> RELATED WORK White [28] first suggested using garbage collection to improve a programs locality of reference. Researchers investigated two approaches to using a garbage collector to improve paging behavior of Smalltalk and LISP systems <ref> [18, 30, 15, 10] </ref>. Static regrouping [18, 30] uses the topology of heap data structures to rearrange structurally-related objects, while dynamic regrouping [10] clusters objects according to a programs data access pattern. <p> Researchers investigated two approaches to using a garbage collector to improve paging behavior of Smalltalk and LISP systems [18, 30, 15, 10]. Static regrouping [18, 30] uses the topology of heap data structures to rearrange structurally-related objects, while dynamic regrouping <ref> [10] </ref> clusters objects according to a programs data access pattern. <p> However, in a later study [15], the authors found that the optimal grouping of data structure elements was very dependent on the shape and type of the structure being copied. While hierarchical decomposition performed well for trees, it was disappointing for other structures. Courts <ref> [10] </ref> dynamic regrouping technique takes advantage of specialized hardware to provide incremental garbage collection, which tends to move objects to TO space in program access order, and this can dramatically reduce the number of page faults. These studies focused on a programs paging behavior, not its cache behavior.
Reference: [11] <author> Robert Fenichel and Jerome Yochelson. </author> <title> A LISP gar bage-collector for virtual-memory computer systems. </title> <journal> Communications of the ACM, </journal> <volume> 12(11):611612, </volume> <year> 1969. </year>
Reference-contexts: The blocks that previously held the generation can be reused. The new space to which generation objects are copied is called TO space and the old space is called FROM space <ref> [11] </ref>. A common traversal algorithm for copying objects into TO space is Cheneys algorithm [8] (the toolkit uses this algorithm, see Figure 2). Starting with the root set, objects are traversed in breadth-first order and copied to TO space as they are visited. Breadth-first traversal requires a queue.
Reference: [12] <author> Dennis Gannon, William Jalby, and K. Gallivan. </author> <title> Strat egies for cache and local memory management by glo bal program transformation. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5:587616, </volume> <year> 1988. </year>
Reference-contexts: The fundamental problem with these techniques is that they attack the manifestation (memory latency), not the source (poor reference locality), of the bottleneck. Prior research has focused on improving cache locality in scientific programs that manipulate dense matrices through program (loop) transformations <ref> [31, 3, 12] </ref>. Recently, Calder et al. described a profiledriven, compiler-directed approach to cache-conscious data placement [1]. Other work has demonstrated that programs which manipulate pointer-based structures can benefit greatly from cache-conscious structure layouts [9, 22].
Reference: [13] <author> Richard Hudson, Eliot Moss, Amer Diwan, and Chris-topher Weight. </author> <title> A language-independent garbage col lector toolkit. </title> <institution> University of Massachusetts at Amherst technical report TR 91-47, </institution> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: Section 6 describes our copying algorithm. Section 7 presents experimental results that illustrate the benefits of our technique. Finally, Section 8 briefly discusses related work. 3. BACKGROUND: GENERATIONAL GAR BAGE COLLECTION Our system uses the University of Massachusetts language-independent garbage collector toolkit <ref> [13] </ref>. The toolkit implements a flexible generation scavenger [17, 26] with support for a time-varying number of generations of time-varying size. Figure 1 illustrates the heap organization from the garbage collectors viewpoint. The garbage collected heap is divided into a number of generations.
Reference: [14] <author> David Kroft. </author> <title> Lockup-free instruction fetch/prefetch cache organization. </title> <booktitle> In The 8th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 8187, </pages> <month> May </month> <year> 1981. </year>
Reference-contexts: As a result, many programs performance is dominated by memory references. A variety of hardware and software techniquessuch as prefetching [19, 2], multithreading [16, 24], non-blocking caches <ref> [14] </ref>, dynamic instruction scheduling, and speculative executionhave been developed and implemented to reduce or tolerate memory latency. These techniques require complex hardware and compilers, but have proven ineffective for many programs [21].
Reference: [15] <author> M. S. Lam, P. R. Wilson, and T. G. Moher. </author> <title> Object type directed garbage collection to improve locality. </title> <booktitle> In Proceedings of the International Workshop on Memory Management, </booktitle> <pages> pages 1618, </pages> <month> Sept. </month> <year> 1992. </year>
Reference-contexts: Other researchers have attempted to improve a programs virtual memory (page) locality by changing the traversal algorithm used by a copying garbage collector <ref> [18, 30, 15, 10] </ref>. We compare our cache-conscious copying scheme against one such algorithm (the Wilson-Lam-Moher algorithm [30]). <p> RELATED WORK White [28] first suggested using garbage collection to improve a programs locality of reference. Researchers investigated two approaches to using a garbage collector to improve paging behavior of Smalltalk and LISP systems <ref> [18, 30, 15, 10] </ref>. Static regrouping [18, 30] uses the topology of heap data structures to rearrange structurally-related objects, while dynamic regrouping [10] clusters objects according to a programs data access pattern. <p> Wilson et al. [30] treated hash tables, which group data in a pseudorandom order, specially, and normal data structures were copied in depth-first order. Their results showed a significant reduction in the incidence of page faults. However, in a later study <ref> [15] </ref>, the authors found that the optimal grouping of data structure elements was very dependent on the shape and type of the structure being copied. While hierarchical decomposition performed well for trees, it was disappointing for other structures.
Reference: [16] <author> James Laudon, Anoop Gupta, and Mark Horowitz. </author> <title> Interleaving: A multithreading technique targeting multiprocessors and workstations. </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 308318, </pages> <address> San Jose, California, </address> <year> 1994. </year>
Reference-contexts: As a result, many programs performance is dominated by memory references. A variety of hardware and software techniquessuch as prefetching [19, 2], multithreading <ref> [16, 24] </ref>, non-blocking caches [14], dynamic instruction scheduling, and speculative executionhave been developed and implemented to reduce or tolerate memory latency. These techniques require complex hardware and compilers, but have proven ineffective for many programs [21].
Reference: [17] <author> Henry Lieberman and Carl Hewitt. </author> <title> A real-time gar bage collector based on lifetimes of objects. </title> <booktitle> Commu nications of the ACM, </booktitle> <address> 26(6):419429, </address> <year> 1983. </year>
Reference-contexts: Section 7 presents experimental results that illustrate the benefits of our technique. Finally, Section 8 briefly discusses related work. 3. BACKGROUND: GENERATIONAL GAR BAGE COLLECTION Our system uses the University of Massachusetts language-independent garbage collector toolkit [13]. The toolkit implements a flexible generation scavenger <ref> [17, 26] </ref> with support for a time-varying number of generations of time-varying size. Figure 1 illustrates the heap organization from the garbage collectors viewpoint. The garbage collected heap is divided into a number of generations. The youngest (first) generation holds the most recently allocated objects.
Reference: [18] <author> D. A. Moon. </author> <title> Garbage collection in a large LISP sys tem. </title> <booktitle> In Conference Record of the 1984 Symposium on LISP and Functional Programming, </booktitle> <pages> pages 235246, </pages> <month> Aug. </month> <year> 1984. </year>
Reference-contexts: Other researchers have attempted to improve a programs virtual memory (page) locality by changing the traversal algorithm used by a copying garbage collector <ref> [18, 30, 15, 10] </ref>. We compare our cache-conscious copying scheme against one such algorithm (the Wilson-Lam-Moher algorithm [30]). <p> COMBINING CACHE-CONSCIOUS DATA PLACEMENT WITH GARBAGE COLLECTION Cheneys algorithm copies objects to TO space in breadth-first order. Moon describes a modification to this algorithm that results in approximate depth-first copying <ref> [18] </ref>. Wilson et al. further refine the traversal to obtain hierarchical grouping of objects in TO space [30]. <p> RELATED WORK White [28] first suggested using garbage collection to improve a programs locality of reference. Researchers investigated two approaches to using a garbage collector to improve paging behavior of Smalltalk and LISP systems <ref> [18, 30, 15, 10] </ref>. Static regrouping [18, 30] uses the topology of heap data structures to rearrange structurally-related objects, while dynamic regrouping [10] clusters objects according to a programs data access pattern. <p> RELATED WORK White [28] first suggested using garbage collection to improve a programs locality of reference. Researchers investigated two approaches to using a garbage collector to improve paging behavior of Smalltalk and LISP systems [18, 30, 15, 10]. Static regrouping <ref> [18, 30] </ref> uses the topology of heap data structures to rearrange structurally-related objects, while dynamic regrouping [10] clusters objects according to a programs data access pattern. <p> Static regrouping [18, 30] uses the topology of heap data structures to rearrange structurally-related objects, while dynamic regrouping [10] clusters objects according to a programs data access pattern. Moon <ref> [18] </ref> found that depth-first copying generally yields better virtual memory performance than breadth-first copying for LISP, because it is more likely to place parents and offspring on the same page, particularly if data structures tend to be shallow, but wide.
Reference: [19] <author> Todd C. Mowry, Monica S. Lam, and Anoop Gupta. </author> <title> Design and evaluation of a compiler algorithm for prefetching. </title> <booktitle> In Proceedings of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS V), </booktitle> <pages> pages 6273, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: As a result, many programs performance is dominated by memory references. A variety of hardware and software techniquessuch as prefetching <ref> [19, 2] </ref>, multithreading [16, 24], non-blocking caches [14], dynamic instruction scheduling, and speculative executionhave been developed and implemented to reduce or tolerate memory latency. These techniques require complex hardware and compilers, but have proven ineffective for many programs [21].
Reference: [20] <author> David Patterson, Thomas Anderson, Neal Cardwell, Richard Fromm, Kimberly Keaton, Christoforos Kazyrakis, Randi Thomas, and Katherine Yellick. </author> <title> A case for intelligent RAM. </title> <booktitle> In IEEE Micro, </booktitle> <pages> pages 34 44, </pages> <month> Apr </month> <year> 1997. </year>
Reference-contexts: INTRODUCTION Since 1980, microprocessor performance has improved 60% per year, while over the same period, memory access time decreased only 10% per year <ref> [20] </ref>. This discrepancy has produced a large processor-memory imbalance. Memory caches are the ubiquitous hardware solution to this problem [29, 23].
Reference: [21] <author> Sharon E. Perl and Richard L. </author> <title> Sites. Studies of Win dows NT performance using dynamic execution traces. </title> <booktitle> In Second Symposium on Operating Systems Design and Implementation, </booktitle> <month> Oct. </month> <year> 1996. </year>
Reference-contexts: A variety of hardware and software techniquessuch as prefetching [19, 2], multithreading [16, 24], non-blocking caches [14], dynamic instruction scheduling, and speculative executionhave been developed and implemented to reduce or tolerate memory latency. These techniques require complex hardware and compilers, but have proven ineffective for many programs <ref> [21] </ref>. The fundamental problem with these techniques is that they attack the manifestation (memory latency), not the source (poor reference locality), of the bottleneck. Prior research has focused on improving cache locality in scientific programs that manipulate dense matrices through program (loop) transformations [31, 3, 12].
Reference: [22] <author> Shai Rubin, David Bernstein, and Michael Rodeh. </author> <title> Vir tual cache line: A new technique to improve cache exploitation for recursive data structures. </title> <note> Submitted for publication, </note> <month> Apr. </month> <year> 1998. </year>
Reference-contexts: Recently, Calder et al. described a profiledriven, compiler-directed approach to cache-conscious data placement [1]. Other work has demonstrated that programs which manipulate pointer-based structures can benefit greatly from cache-conscious structure layouts <ref> [9, 22] </ref>. This paper describes how a copying garbage collector can produce a cache-conscious object layout using real-time data Copyright 199x by the Association for Computing Machinery, Inc.
Reference: [23] <author> Alan J. Smith. </author> <title> Cache memories. </title> <journal> ACM Computing Surveys, </journal> <volume> 14(3):473530, </volume> <year> 1982. </year>
Reference-contexts: INTRODUCTION Since 1980, microprocessor performance has improved 60% per year, while over the same period, memory access time decreased only 10% per year [20]. This discrepancy has produced a large processor-memory imbalance. Memory caches are the ubiquitous hardware solution to this problem <ref> [29, 23] </ref>. In the beginning, a single level of cache sufficed, but the increasing imbalance (now almost two orders of magnitude) demands a memory hierarchy, which produces a large range of memory-access costs. As a result, many programs performance is dominated by memory references.
Reference: [24] <author> Burton J. Smith. </author> <title> Architecture and applications of the HEP multiprocessor computer system. </title> <booktitle> In Real-Time Signal Processing IV, </booktitle> <pages> pages 241248, </pages> <year> 1981. </year>
Reference-contexts: As a result, many programs performance is dominated by memory references. A variety of hardware and software techniquessuch as prefetching [19, 2], multithreading <ref> [16, 24] </ref>, non-blocking caches [14], dynamic instruction scheduling, and speculative executionhave been developed and implemented to reduce or tolerate memory latency. These techniques require complex hardware and compilers, but have proven ineffective for many programs [21].
Reference: [25] <institution> Sun Microelectronics. </institution> <note> UltraSPARC Users Manual, </note> <year> 1996. </year>
Reference-contexts: Section 7 provides experimental results to support these assumptions. If most objects are small (&lt; 32 bytes), then it is not necessary for data profiling to distinguish different fields within the same object, since cache blocks are currently larger (e.g., 64 bytes in the UltraSparc <ref> [25] </ref>) and growing. Profiling can be implemented at object, not field, granularity. Moreover, if most object accesses are not lightweight (i.e., multiple fields are accessed together or an access involves a method invocation), then profiling instrumentation (several instructions per object access) will not incur a large overhead. <p> The next set of experiments measured the overhead of our real-time data profiling (Table 4). The results indicate that the overhead of our real-time data profiling technique is low (&lt; 6%). We used the UltraSPARCs <ref> [25] </ref> hardware counters to measure the effect of our cache-conscious object layouts on cache miss rates. Table 5 contains measurements of the overall execution time (including the instrumentation and processing overhead of our technique).
Reference: [26] <author> David Ungar. </author> <title> Generation scavenging: A non-disrup tive high performance storage reclamation algorithm. </title> <booktitle> In Proceedings of the ACM SIGSOFT/SIGPLAN Software Engineering Symposium on Practical Software Development Environments, </booktitle> <pages> pages 157167, </pages> <month> Apr. </month> <year> 1984. </year>
Reference-contexts: Section 7 presents experimental results that illustrate the benefits of our technique. Finally, Section 8 briefly discusses related work. 3. BACKGROUND: GENERATIONAL GAR BAGE COLLECTION Our system uses the University of Massachusetts language-independent garbage collector toolkit [13]. The toolkit implements a flexible generation scavenger <ref> [17, 26] </ref> with support for a time-varying number of generations of time-varying size. Figure 1 illustrates the heap organization from the garbage collectors viewpoint. The garbage collected heap is divided into a number of generations. The youngest (first) generation holds the most recently allocated objects.
Reference: [27] <author> David Ungar and Frank Jackson. </author> <title> An adaptive tenuring policy for generation scavengers. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 14(1):127, </volume> <month> January </month> <year> 1992. </year>
Reference-contexts: Objects in the oldest step of a generation are promoted to the youngest step of the next generation. Each step consists of a collection of fixed size blocks, which are not necessarily contiguous in memory. To simplify our implementation, our generations contained a single step. Ungar and Jackson <ref> [27] </ref> demonstrated performance advantages from not copying large objects. The UMass garbage collector toolkit also provides a separate large object space (LOS) as part of the collected area.
Reference: [28] <author> J. L. White. </author> <title> Address/memory management for a gigantic LISP environment, or, GC considered harmful. </title> <booktitle> In Conference Record of the 1980 LISP Confer ence, </booktitle> <pages> pages 119127, </pages> <year> 1980. </year>
Reference-contexts: Since the Wilson-Lam-Moher algorithm is ineffective at reducing a programs cache miss rate, and has a slightly higher overhead than Cheneys algorithm, it performs worse for richards, deltablue, and instr sched. 8. RELATED WORK White <ref> [28] </ref> first suggested using garbage collection to improve a programs locality of reference. Researchers investigated two approaches to using a garbage collector to improve paging behavior of Smalltalk and LISP systems [18, 30, 15, 10].
Reference: [29] <author> M. V. Wilkes. </author> <title> Slave memories and dynamic storage allocation. </title> <journal> In IEEE Trans. on Electronic Computers, </journal> <pages> pages 270271, </pages> <month> April </month> <year> 1965. </year>
Reference-contexts: INTRODUCTION Since 1980, microprocessor performance has improved 60% per year, while over the same period, memory access time decreased only 10% per year [20]. This discrepancy has produced a large processor-memory imbalance. Memory caches are the ubiquitous hardware solution to this problem <ref> [29, 23] </ref>. In the beginning, a single level of cache sufficed, but the increasing imbalance (now almost two orders of magnitude) demands a memory hierarchy, which produces a large range of memory-access costs. As a result, many programs performance is dominated by memory references.
Reference: [30] <author> Paul R. Wilson, Michael S. Lam, and Thomas G. Moher. </author> <title> Effective static-graph reorganization to improve locality in garbage-collected systems. </title> <journal> SIG PLAN Notices, </journal> <volume> 26(6):177191, </volume> <month> June </month> <year> 1991. </year> <booktitle> Proceedings of the ACM SIGPLAN91 Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: Other researchers have attempted to improve a programs virtual memory (page) locality by changing the traversal algorithm used by a copying garbage collector <ref> [18, 30, 15, 10] </ref>. We compare our cache-conscious copying scheme against one such algorithm (the Wilson-Lam-Moher algorithm [30]). <p> Other researchers have attempted to improve a programs virtual memory (page) locality by changing the traversal algorithm used by a copying garbage collector [18, 30, 15, 10]. We compare our cache-conscious copying scheme against one such algorithm (the Wilson-Lam-Moher algorithm <ref> [30] </ref>). The results show that our cache-conscious object layout reduces cache miss rates by 2041% and improves program performance by 1831% over their technique, indicating that page-level improvements are not necessarily effective at the cache level. The rest of the paper is organized as follows. <p> COMBINING CACHE-CONSCIOUS DATA PLACEMENT WITH GARBAGE COLLECTION Cheneys algorithm copies objects to TO space in breadth-first order. Moon describes a modification to this algorithm that results in approximate depth-first copying [18]. Wilson et al. further refine the traversal to obtain hierarchical grouping of objects in TO space <ref> [30] </ref>. The copying algorithm (Figure 9) described in this section uses the object affinity graph to produce a cache-conscious layout of objects in TO space. 6.1 Cache-Conscious Copying Algorithm Our cache-conscious copying algorithm can be divided into three steps. STEP 1: Flip the roles of FROM space and TO space. <p> In addition, the data indicates that the L2 cache miss rate is correlated with total execution time. Finally, we compared our approach against the Wilson-Lam-Moher algorithm <ref> [30] </ref>, which uses a hierarchical decomposition algorithm for copying data between semi-spaces (instead of Cheneys breadth-first traversal) to improve a programs virtual memory (page) locality. <p> RELATED WORK White [28] first suggested using garbage collection to improve a programs locality of reference. Researchers investigated two approaches to using a garbage collector to improve paging behavior of Smalltalk and LISP systems <ref> [18, 30, 15, 10] </ref>. Static regrouping [18, 30] uses the topology of heap data structures to rearrange structurally-related objects, while dynamic regrouping [10] clusters objects according to a programs data access pattern. <p> RELATED WORK White [28] first suggested using garbage collection to improve a programs locality of reference. Researchers investigated two approaches to using a garbage collector to improve paging behavior of Smalltalk and LISP systems [18, 30, 15, 10]. Static regrouping <ref> [18, 30] </ref> uses the topology of heap data structures to rearrange structurally-related objects, while dynamic regrouping [10] clusters objects according to a programs data access pattern. <p> Moon [18] found that depth-first copying generally yields better virtual memory performance than breadth-first copying for LISP, because it is more likely to place parents and offspring on the same page, particularly if data structures tend to be shallow, but wide. Wilson et al. <ref> [30] </ref> treated hash tables, which group data in a pseudorandom order, specially, and normal data structures were copied in depth-first order. Their results showed a significant reduction in the incidence of page faults.
Reference: [31] <author> Michael E. Wolf and Monica S. Lam. </author> <title> A data locality optimizing algorithm. </title> <journal> SIGPLAN Notices, </journal> <volume> 26(6):3044, </volume> <month> June </month> <year> 1991. </year> <booktitle> Proceedings of the ACM SIGPLAN91 Conference on Programming Language Design and Imple mentation. </booktitle>
Reference-contexts: The fundamental problem with these techniques is that they attack the manifestation (memory latency), not the source (poor reference locality), of the bottleneck. Prior research has focused on improving cache locality in scientific programs that manipulate dense matrices through program (loop) transformations <ref> [31, 3, 12] </ref>. Recently, Calder et al. described a profiledriven, compiler-directed approach to cache-conscious data placement [1]. Other work has demonstrated that programs which manipulate pointer-based structures can benefit greatly from cache-conscious structure layouts [9, 22].
References-found: 31

