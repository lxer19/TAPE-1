URL: ftp://ftp.cis.upenn.edu/pub/pelachaud/CA94/CA94.ps.Z
Refering-URL: http://www.cis.upenn.edu/~hms/publications.html
Root-URL: 
Title: Modeling and Animating the Human Tongue during Speech Production  
Author: Catherine Pelachaud C.W.A.M. van Overveld Chin Seah 
Address: Philadelphia, PA 19104 Eindhoven  Philadelphia, PA 19104  
Affiliation: Dept of Computer and Information Science Dept of Mathematics and Computing Science University of Pennsylvania University of Technology  Dept of Computer and Information Science University of Pennsylvania  
Abstract: A geometric and kinematic model for describing the global shape and the predominant motions of the human tongue, to be applied in computer animation, is discussed. The model consists of a spatial configuration of moving points that form the vertices of a mesh of 9 3-D triangles. These triangles are interpreted as charge centres (the so-called skeleton) for a potential field, and the surface of the tongue is modelled as an equi-potential surface of this field. In turn, this surface is approximated by a triangular mesh prior to rendering. As to the motion of the skeleton, precautions are taken in order to achieve (approximate) volume conservation; the computation of the triangular mesh describing the surface of the tongue implements penetration avoidance with respect to the palate. Further, the motions of the skeleton derive from a formal speech model which also controls the motion of the lips to arrive at a visually plausible speech synchronous mouth model. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R.A.W. Bladon and F.J. Nolan. </author> <title> A video-fluorographic investigation of tip and blade alve-olars in english. </title> <journal> Journal of Phonetics, </journal> <volume> 5 </volume> <pages> 185-193, </pages> <year> 1977. </year>
Reference-contexts: Therefore we retain only 3 segments in the sagittal plane and 3 segments in the coronal plane (see figure 1). Referring to figure 1, we denote vl [i] the points of the tongue skeleton. By moving points vl <ref> [1] </ref> and vl [2] along the median, they will represent respectively the anterior/middle and the dorsal/posterior degrees of freedom. <p> The median is divided into three parts. The two middle points vl <ref> [1] </ref> and vl [2] can move along the median. A tool has been developed to modify interactively and independently each shape parameter of the model; these shape parameters are: the lengths of the edges l i forming the median and the angles a i between these edges.
Reference: [2] <author> C.P. Browman and L. Goldstein. </author> <title> Gestural specification using dynamically-defined articulatory structures. </title> <journal> Journal of Phonetics, </journal> <volume> 18 </volume> <pages> 299-320, </pages> <year> 1990. </year>
Reference-contexts: Therefore we retain only 3 segments in the sagittal plane and 3 segments in the coronal plane (see figure 1). Referring to figure 1, we denote vl [i] the points of the tongue skeleton. By moving points vl [1] and vl <ref> [2] </ref> along the median, they will represent respectively the anterior/middle and the dorsal/posterior degrees of freedom. In normal speech, the anterior and middle segments are never independent characteristics of a tongue shape simultaneously (similarly for dorsal and posterior), so these don't have to occur as independent shape parameters. <p> The median is divided into three parts. The two middle points vl [1] and vl <ref> [2] </ref> can move along the median. A tool has been developed to modify interactively and independently each shape parameter of the model; these shape parameters are: the lengths of the edges l i forming the median and the angles a i between these edges.
Reference: [3] <author> Michael M. Cohen and Dominic W. Massaro. </author> <title> Modeling coarticulation in synthetic visual speech. </title> <editor> In D. Thalmann N. Magnenat-Thalmann, editor, </editor> <title> Computer Animation '93. </title> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: In most facial animation system, tongue movement is not considered, or if so it is over simplified. In most cases it is represented by a parallelepiped that can move inward, outward, upward, and downward [12], <ref> [3] </ref>, [17], [14]. We propose to model the tongue based on the soft object technique of [27]. This technique assumes a so called skeleton, comprising of few geometric primitives (in our case 9 triangles) that serves as a charge distribution causing a spatial potential field.
Reference: [4] <author> P. Ekman and W. Friesen. </author> <title> Facial Action Coding System. </title> <publisher> Consulting Psychologists Press, Inc., </publisher> <year> 1978. </year>
Reference-contexts: Ekman and W. Friesen. This system describes any visible facial action by the changes occurring beneath the muscular activity. An Action Unit (AU) corresponds to an action produced by one or more related muscles (we refer the reader to <ref> [4] </ref> for a detailed description of each AU.). Vowels and consonants are divided into clusters corresponding to their associated lip shapes. Such clustering depends on the speech rate. The faster a person talks, the more marginally visible segments will lose their characteristic lip shapes.
Reference: [5] <author> J.W. Folkins, R.N. Linville, J.D. Garrett, and C.K. Brown. </author> <title> Interactions in the labial musculature during speech. </title> <journal> Journal of speech and hearing research, </journal> <volume> 31 </volume> <pages> 253-264, </pages> <year> 1988. </year>
Reference: [6] <author> G. Heike, R. Greisbach, and B.J. Kroger. </author> <title> Coartic-ulation rules in an articulatory model. </title> <journal> Journal of Phonetics, </journal> <volume> 19 </volume> <pages> 465-471, </pages> <year> 1991. </year>
Reference: [7] <author> Eric Keller. </author> <title> Factors underlying tongue articulation in speech. </title> <journal> Journal of Speech and Hearing Research, </journal> <volume> 30 </volume> <pages> 223-229, </pages> <month> june </month> <year> 1987. </year>
Reference: [8] <author> R.D. Kent. </author> <title> Some considerations in the cineflu-orographic analysis of tongue movements during speech. </title> <journal> Phonetica, </journal> <volume> 26 </volume> <pages> 16-32, </pages> <year> 1972. </year>
Reference: [9] <author> R.D. Kent. </author> <title> The Production of Speech, chapter The Segmental Organization of Speech. </title> <address> Springler-Verlag, </address> <year> 1983. </year>
Reference: [10] <author> R.D. Kent and K.L. Moll. </author> <title> Tongue body articulation during vowel and diphthong gestures. </title> <journal> Folia Phoniatrica, </journal> <volume> 24, </volume> <year> 1972. </year>
Reference-contexts: Jaw actions occur during accented vowel production. During jaw opening the tongue has greater distances to cover to reach its maxima positions. Depending on the speech rate, the tongue might not have time to reach these positions. As it is noted in <ref> [10] </ref>, there is not a universal tongue shape for each articulation, but the constraints on the tongue are such that to each articulation corresponds a particular shape which can appear in various positions in the oral cavity. The relevant issue here is the relation between the different tongue positions. <p> As speech rate increases the tongue does not have time to reach its extreme positions; the tongue shows less displacement, but its curvature is not affected by higher speech rates. Curvature is accentuated with loudness. For slow speech-rate, steady-state tongue behavior occurs where the tongue remains still. <ref> [10] </ref> found coar-ticulation effects in tongue motion during speech production. To compute lip shapes, our model uses a look-ahead model with some temporal and geometric constraints [18].
Reference: [11] <author> P. Ladefoged. </author> <title> A course in Phonetics. </title> <publisher> Harcourt Brace Javanovich, </publisher> <year> 1982. </year>
Reference-contexts: To compute lip shapes, our model uses a look-ahead model with some temporal and geometric constraints [18]. Our tongue model uses also the look-ahead model to compute the tongue shape. 7 Coarticulation Many studies have characterized tongue shape during speech production <ref> [11] </ref>, [21]. Using the results of these studies and the tool we discussed in the previous sections, we specified a tongue shape for each vowel and consonant (see figure 4 (figure adapted from [11])). <p> model to compute the tongue shape. 7 Coarticulation Many studies have characterized tongue shape during speech production <ref> [11] </ref>, [21]. Using the results of these studies and the tool we discussed in the previous sections, we specified a tongue shape for each vowel and consonant (see figure 4 (figure adapted from [11])). Even though there is no universal shape for each phonemic item, we define one tongue shape to each phonemic item for the sake of simplicity [11]. Next, speech is decomposed into a sequence of discrete units such as syllables and phonemes. <p> the tool we discussed in the previous sections, we specified a tongue shape for each vowel and consonant (see figure 4 (figure adapted from <ref> [11] </ref>)). Even though there is no universal shape for each phonemic item, we define one tongue shape to each phonemic item for the sake of simplicity [11]. Next, speech is decomposed into a sequence of discrete units such as syllables and phonemes.
Reference: [12] <author> J.P. Lewis and F.I. Parke. </author> <title> Automated lip-synch and speech synthesis for character animation. </title> <booktitle> CHI + GI, </booktitle> <pages> pages 143-147, </pages> <year> 1987. </year>
Reference-contexts: In most facial animation system, tongue movement is not considered, or if so it is over simplified. In most cases it is represented by a parallelepiped that can move inward, outward, upward, and downward <ref> [12] </ref>, [3], [17], [14]. We propose to model the tongue based on the soft object technique of [27]. This technique assumes a so called skeleton, comprising of few geometric primitives (in our case 9 triangles) that serves as a charge distribution causing a spatial potential field.
Reference: [13] <author> B. Lindblom. </author> <title> The Production of Speech, chapter Economy of Speech Gestures. </title> <address> Springler-Verlag, </address> <year> 1983. </year>
Reference-contexts: To insure realism in the final animation, we compare the computed tongue shapes for given phonemes with pictures and diagrams found in the literature <ref> [13] </ref>, [21]. The program outputs the different values of the tongue skeleton for each key-frame (each phonemic item correspond with a key-frame). The final tongue shapes are computed using the soft object program. An implementation of this technique was already available to us.
Reference: [14] <author> N. Magnenat-Thalmann and D. Thalmann. </author> <title> The direction of synthetic actors in the film rendez-vous a montreal. </title> <journal> IEEE Computer Graphics and Applications, </journal> <pages> pages 9-19, </pages> <month> December </month> <year> 1987. </year>
Reference-contexts: In most facial animation system, tongue movement is not considered, or if so it is over simplified. In most cases it is represented by a parallelepiped that can move inward, outward, upward, and downward [12], [3], [17], <ref> [14] </ref>. We propose to model the tongue based on the soft object technique of [27]. This technique assumes a so called skeleton, comprising of few geometric primitives (in our case 9 triangles) that serves as a charge distribution causing a spatial potential field.
Reference: [15] <author> S.E.G. Ohman. </author> <title> Coarticulation in vcv utterances: Spectrographic measurements. </title> <journal> Journal of Acoustical Society of America, </journal> <volume> 39 </volume> <pages> 151-168, </pages> <year> 1966. </year>
Reference: [16] <author> S.E.G. Ohman. </author> <title> Numerical model of coarticula-tion. </title> <journal> Journal of Acoustical Society of America, </journal> <volume> 41(2) </volume> <pages> 311-321, </pages> <year> 1967. </year>
Reference: [17] <author> F.I. Parke. </author> <title> Control parametrization for facial animation. </title> <editor> In N. Magnenat-Thalmann and D. Thal-mann, editors, </editor> <booktitle> Computer Animation '91, </booktitle> <pages> pages 3-14. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: In most facial animation system, tongue movement is not considered, or if so it is over simplified. In most cases it is represented by a parallelepiped that can move inward, outward, upward, and downward [12], [3], <ref> [17] </ref>, [14]. We propose to model the tongue based on the soft object technique of [27]. This technique assumes a so called skeleton, comprising of few geometric primitives (in our case 9 triangles) that serves as a charge distribution causing a spatial potential field.
Reference: [18] <author> C. Pelachaud, N.I. Badler, and M. Steed-man. </author> <title> Linguistic issues in facial animation. </title> <editor> In N. Magnenat-Thalmann and D. Thalmann, editors, </editor> <booktitle> Computer Animation '91, </booktitle> <pages> pages 15-30. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: Curvature is accentuated with loudness. For slow speech-rate, steady-state tongue behavior occurs where the tongue remains still. [10] found coar-ticulation effects in tongue motion during speech production. To compute lip shapes, our model uses a look-ahead model with some temporal and geometric constraints <ref> [18] </ref>. Our tongue model uses also the look-ahead model to compute the tongue shape. 7 Coarticulation Many studies have characterized tongue shape during speech production [11], [21].
Reference: [19] <author> Elliot L. Salztman and Kevin G. Munhall. </author> <title> A dynamical approach to gestural patterning in speech production. </title> <journal> Ecological Psychology, </journal> <volume> 1(4) </volume> <pages> 333-382, </pages> <year> 1989. </year>
Reference: [20] <author> M. Stone. </author> <title> A three-dimensional model of tongue movement based on ultrasound and x-ray mi-crobean data. </title> <journal> Journal of Acoustical Society of America, </journal> <volume> 87(5) </volume> <pages> 2207-2217, </pages> <year> 1990. </year>
Reference-contexts: Their contraction patterns determine the direction of the tongue deformation. The contraction of longitudinal muscle will shorten and draw back the tongue while the contraction of the other group of muscles will flatten and extend it [21]. Moreover the tongue can be bent, twisted and tensed <ref> [20] </ref>. 3 Tongue Modeling Our goal is to find a compromise between a highly flexible structure with very complex movements and a simple representation made up from few primitives, each with few parameters. In this respect, the soft object technique seems to be a promising approach. <p> For vowels the degree of compressibility is mainly a function of tongue height. Some differences between segments occur also in the timing of tongue movement. Some points arrive earlier followed by the other points: each segment has its own characteristic velocity <ref> [20] </ref>. Regardless of context, the vowel expansion and compression patterns vary roughly as a function of tongue height. The higher vowels, /i/ and /o/, cause the anterior segment to become compressed and retracted whereas the dorsal segment moves upward. For /a/, the middle and dorsal segments are compressed.
Reference: [21] <author> M. Stone. </author> <title> Toward a model of three-dimensional tongue movement. </title> <journal> Journal of Phonetics, </journal> <volume> 19 </volume> <pages> 309-320, </pages> <year> 1991. </year>
Reference-contexts: Sounds are differentiated, among other factors, by the position of the tongue related to the palate, and by the curvature and contraction of the tongue. The tongue is a highly flexible organ. It comprises muscles, fat and connective tissue <ref> [21] </ref>. Longitudinal and transverse muscles interleave. Their contraction patterns determine the direction of the tongue deformation. The contraction of longitudinal muscle will shorten and draw back the tongue while the contraction of the other group of muscles will flatten and extend it [21]. <p> It comprises muscles, fat and connective tissue <ref> [21] </ref>. Longitudinal and transverse muscles interleave. Their contraction patterns determine the direction of the tongue deformation. The contraction of longitudinal muscle will shorten and draw back the tongue while the contraction of the other group of muscles will flatten and extend it [21]. Moreover the tongue can be bent, twisted and tensed [20]. 3 Tongue Modeling Our goal is to find a compromise between a highly flexible structure with very complex movements and a simple representation made up from few primitives, each with few parameters. <p> Each shape parameter implements a meaningful shape attribute of the tongue; each shape parameter can be modified interactively. Finally we explain how the final shape of the tongue is computed from the skeleton; to this end, the soft object technique will be explained briefly. 3.1 3-D Model In <ref> [21] </ref>, Maureen Stone proposed a 3-D model of the tongue. She defined 5 segments in the coronal plane - one medial and two laterals (on each side of the median) and 5 segments in the sagittal plane root, posterior, dorsal, middle and anterior. <p> To compute lip shapes, our model uses a look-ahead model with some temporal and geometric constraints [18]. Our tongue model uses also the look-ahead model to compute the tongue shape. 7 Coarticulation Many studies have characterized tongue shape during speech production [11], <ref> [21] </ref>. Using the results of these studies and the tool we discussed in the previous sections, we specified a tongue shape for each vowel and consonant (see figure 4 (figure adapted from [11])). <p> If no tongue shape is associated to a particular segment, the program uses the property of the tongue which states that when a gesture is not involved in a particular segment but is in the next one, this gesture starts earlier <ref> [21] </ref>. In this case, the program starts the tongue movement on the previous segment which shows no tongue movement (e.g for /be/, the tongue associated to phoneme /e/ in not engaged in the production of /b/ and therefore starts as the same time as /b/ is pronounced [21]). <p> gesture starts earlier <ref> [21] </ref>. In this case, the program starts the tongue movement on the previous segment which shows no tongue movement (e.g for /be/, the tongue associated to phoneme /e/ in not engaged in the production of /b/ and therefore starts as the same time as /b/ is pronounced [21]). To insure realism in the final animation, we compare the computed tongue shapes for given phonemes with pictures and diagrams found in the literature [13], [21]. The program outputs the different values of the tongue skeleton for each key-frame (each phonemic item correspond with a key-frame). <p> tongue associated to phoneme /e/ in not engaged in the production of /b/ and therefore starts as the same time as /b/ is pronounced <ref> [21] </ref>). To insure realism in the final animation, we compare the computed tongue shapes for given phonemes with pictures and diagrams found in the literature [13], [21]. The program outputs the different values of the tongue skeleton for each key-frame (each phonemic item correspond with a key-frame). The final tongue shapes are computed using the soft object program. An implementation of this technique was already available to us.
Reference: [22] <author> M. Stone, K.A. Morrish, B.C. Sonies, and T.H. Shawker. </author> <title> Tongue curvature: A model of shape during vowel production. </title> <journal> Folia Phoniatrica, </journal> <volume> 39 </volume> <pages> 302-315, </pages> <year> 1987. </year>
Reference: [23] <author> M. Unser and M. Stone. </author> <title> Automated detection of the tongue surface in sequences of ultrasound images. </title> <journal> Journal of Acoustical Society of America, </journal> <volume> 91(5) </volume> <pages> 3001-3007, </pages> <year> 1992. </year>
Reference: [24] <author> C.W.A.M. van Overveld and B. Wyvill. </author> <title> Potentials, polygons and penguins: An adaptive algorithm for triangulating and equi-potential surface. </title> <year> 1993. </year>
Reference-contexts: In the next section we explain our model and we discuss how the primitives for the model are built. We also summarize briefly our implementation of the soft object technique. The user is referred to <ref> [24] </ref> for more details on the construction of a triangle mesh to represent the equi-potential surface. In the subsequent section we describe our penetration avoidance algorithm. Finally we show how we compute tongue shapes during speech production. <p> Among other things, they can serve to model soft objects. Equi-potential surfaces are expensive to render directly (e.g. using ray tracing); rather, they should be converted into a triangle mesh prior to rendering. In <ref> [24] </ref>, a method is proposed to convert an equi-potential surface into a triangle mesh in such a way that the triangle shapes adapt to the local curvature of the equi-potential surface: relatively flat areas give rise to large triangles whereas small triangles occur in strongly curved regions; moreover, isotropically curved surface <p> Given fi, ff, and L max quantitative estimates for the maximal deviation of the surface and the triangular mesh approximation can be derived (see <ref> [24] </ref>). <p> For all triangles, lines and vertices, the combined equi-potential surface is S = fr 2 &lt; 3 j i j r R i j The algorithm discussed in detail in <ref> [24] </ref> guarantees that the vertices of the adaptive triangular mesh approximating S are on f (r) = V 0 ; that a closed surface results, and that the surface is tessalated by acceptable chords only.
Reference: [25] <author> D.H. Whalen. </author> <title> Coarticulation is largely planned. </title> <journal> Journal of Phonetics, </journal> <volume> 18 </volume> <pages> 3-35, </pages> <year> 1990. </year>
Reference: [26] <author> Sidney A.J. Wood. </author> <title> X-ray data on the temporal coordination of speech gestures. </title> <journal> Journal of Phonetics, </journal> <volume> 19 </volume> <pages> 281-292, </pages> <year> 1991. </year>
Reference: [27] <author> G. Wyvill, C. McPheeters, and B. Wyvill. </author> <title> Data structures for Soft Objects. </title> <journal> The Visual Computer, </journal> <volume> 2(4) </volume> <pages> 227-234, </pages> <month> April </month> <year> 1986. </year>
Reference-contexts: In most cases it is represented by a parallelepiped that can move inward, outward, upward, and downward [12], [3], [17], [14]. We propose to model the tongue based on the soft object technique of <ref> [27] </ref>. This technique assumes a so called skeleton, comprising of few geometric primitives (in our case 9 triangles) that serves as a charge distribution causing a spatial potential field. The modelled soft object is an equi-potential surface defined by this field.
References-found: 27

