URL: http://charm.cs.uiuc.edu/version2/papers/CharmSys2TPDS94.ps
Refering-URL: http://charm.cs.uiuc.edu/version2/papers/CharmSys2TPDS94.html
Root-URL: http://www.cs.uiuc.edu
Email: ramkumar@eng.uiowa.edu fsinha,kaleg@cs.uiuc.edu saletore@mist.ogst.edu  
Title: The Charm Parallel Programming Language and System: Part II The Runtime System  
Author: B. Ramkumar A. B. Sinha flfl V. A. Saletore flflfl L. V. Kale flfl 
Keyword: Index terms: Message-driven execution, MIMD machines, Parallel programming, Portable parallel software, Task granularity.  
Note: This research was supported in part by the National Science Foundation grants CCR-90-07195 and CCR-91-06608. Dr. Ramkumar's work is supported in part by the National Science Foundation grant NSF-CCR-9308108.  
Address: Iowa City, Iowa 52242 Urbana, Illinois 61801 Corvallis, Oregon 97331  
Affiliation: Dept. of Electrical and Computer Eng. flfl Dept. of Computer Science flflfl Dept. of Computer Science University of Iowa University of Illinois Oregon State University  
Abstract: Charm is a parallel programming system that permits users to write portable parallel programs on MIMD multiprocessors without losing efficiency. It supports an explicitly parallel language which helps control the complexity of parallel program design by imposing a separation of concerns between the user program and the system. It also provides target machine independent abstractions for information sharing which are implemented differently on different types of processors. In part I of this paper [16], we described the language support provided by Charm and the rationale behind its design. Charm has been implemented on a variety of parallel machines including shared memory machines like the Encore Multimax and the Sequent Symmetry, message passing architectures like the Intel iPSC/2, Intel i860 and the NCUBE 2, and a network of Unix workstations. The Chare kernel is the run-time system that supports the portable execution of Charm on several MIMD architectures. We discuss the implementation and performance of the Chare kernel on three architectures: shared memory, message passing, and a network of workstations. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Agha, </author> <title> G.A. Actors: A Model of Concurrent Computation in Distributed Systems. </title> <publisher> MIT press, </publisher> <year> 1986. </year>
Reference-contexts: Each chare instance has a unique address. Entry functions in a particular chare instance can be asynchronously invoked by addressing a message to the desired entry function of the chare using the SendMsg system call. A chare is a concurrent object [2] and is somewhat like an actor <ref> [1] </ref> although there are some significant differences [16]. The objects in Charm are message-driven. In practical terms, this means that there is no receive call in the language, nor is there any blocking call that depends on processing on a remote processor.
Reference: [2] <author> Agha, </author> <title> G.A. Concurrent object-oriented programming. </title> <journal> Communications of the ACM, </journal> <volume> vol. 33, </volume> <month> September </month> <year> 1990. </year>
Reference-contexts: Each chare instance has a unique address. Entry functions in a particular chare instance can be asynchronously invoked by addressing a message to the desired entry function of the chare using the SendMsg system call. A chare is a concurrent object <ref> [2] </ref> and is somewhat like an actor [1] although there are some significant differences [16]. The objects in Charm are message-driven. In practical terms, this means that there is no receive call in the language, nor is there any blocking call that depends on processing on a remote processor.
Reference: [3] <author> Ramkumar B. and Banerjee P. ProperCAD: </author> <title> A Portable Object-Oriented Parallel Environment for VLSI CAD. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 13, no 7, </volume> <month> July </month> <year> 1994. </year>
Reference-contexts: Note that the same is not true for the network version: we attribute this to 7 Similar curves were obtained for parallel Prolog [23], parallel circuit extraction <ref> [3] </ref>, test pattern generation [22], and several other applications they have been reported elsewhere. 31 costs incurred on the network version to poll the network for messages from other processors (even though there are no such messages). <p> They include several VLSI/CAD applications developed by P. Banerjee, B. Ramkumar, and others. A parallel Prolog compiler [23], a parallel circuit extractor <ref> [3] </ref>, a parallel test pattern generator for sequential circuits [22], parallel logic synthesis based on transduction [10], parallel cell placement based on simulated annealing [17], and a parallel molecular dynamics program called EGO have been implemented using Charm. <p> More importantly, Charm outperforms programs written using vendor primitives because of capabilities of adaptive scheduling provided by message driven execution [13] and the availability of prioritization queuing and load balancing strategies <ref> [23, 3, 22, 10, 17] </ref>. A parallel Prolog compiler which exploits both AND and OR parallelism has been written using Charm [23], and is one of the first such systems to run efficiently on both shared and non-shared memory system. <p> It was also one of the first implementations to demonstrate speedups on Prolog program on upto 256 processors (on an NCUBE/2) [23]. The parallel circuit extractor <ref> [3] </ref> was developed around the same sequential C code used by PACE2 [5] to permit a fair comparison of the two. On shared memory machines, the extractor outperforms 32 PACE2 [5], in spite of the fact that PACE2 is based on an algorithm designed specifically for shared memory machines.
Reference: [4] <author> Sargent J.S. Banerjee P., Jones M.H. </author> <title> Parallel Simulated Annealing Algorithms for Standard Cell Placement on Hypercube Multiprocessors. </title> <journal> IEEE Trans. Parallel and Distributed Systems, </journal> <volume> 1(1) </volume> <pages> 91-106, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: In several cases, these algorithms are not amenable to parallelization, in that parallel versions of these algorithms may result in in significant loss of quality and poor speedups. This is clearly evident in a wide range of VLSI CAD applications including test pattern generation [20, 21], cell placement <ref> [4, 24] </ref>, global routing [6, 25] and a molecular dynamics application EGO. We believe it is therefore necessary to build the parallel algorithm around the best available sequential algorithm.
Reference: [5] <author> Belkhale, K.P, Banerjee, P. PACE2: </author> <title> An Improved Parallel VLSI Extractor with Parameter Extraction. </title> <booktitle> In Proceedings of the International Conference on Computer Aided Design, </booktitle> <pages> pages 526-530, </pages> <month> November </month> <year> 1989. </year> <month> 34 </month>
Reference-contexts: It was also one of the first implementations to demonstrate speedups on Prolog program on upto 256 processors (on an NCUBE/2) [23]. The parallel circuit extractor [3] was developed around the same sequential C code used by PACE2 <ref> [5] </ref> to permit a fair comparison of the two. On shared memory machines, the extractor outperforms 32 PACE2 [5], in spite of the fact that PACE2 is based on an algorithm designed specifically for shared memory machines. <p> The parallel circuit extractor [3] was developed around the same sequential C code used by PACE2 <ref> [5] </ref> to permit a fair comparison of the two. On shared memory machines, the extractor outperforms 32 PACE2 [5], in spite of the fact that PACE2 is based on an algorithm designed specifically for shared memory machines.
Reference: [6] <author> R. J. Brouwer and P. Banerjee. PARAGRAPH: </author> <title> A Parallel Algorithm for Simultaneous Place--ment and Routing Using Hierarchy. </title> <booktitle> Proc. European Design Automation Conf. </booktitle> <address> (EDAC-92), </address> <month> Mar. </month> <year> 1992. </year>
Reference-contexts: This is clearly evident in a wide range of VLSI CAD applications including test pattern generation [20, 21], cell placement [4, 24], global routing <ref> [6, 25] </ref> and a molecular dynamics application EGO. We believe it is therefore necessary to build the parallel algorithm around the best available sequential algorithm.
Reference: [7] <author> Chien, A., Dally, W.J. </author> <title> Concurrent Aggregates (CA). </title> <booktitle> In ACM SIGPLAN Principles and Practice of Parallel Programming, </booktitle> <address> Seattle, Washington, </address> <month> March </month> <year> 1990. </year>
Reference-contexts: In addition to receiving messages at entry-points on individual branches like chares, BOCs also provide public functions. On any processor P , these functions can be called by any chare resident on P . A BOC has some similarities to the concurrent aggregate construct <ref> [7] </ref> independently proposed by Chien and Dally which was designed for fine-grained parallel machines like the J-machine [9] (discussed in part I of this paper). Branch office chares provide a convenient abstraction for the implementation 3 of various distributed strategies, such as load balancing and support for distributed data structures.
Reference: [8] <author> Christopher Walquist. </author> <title> Implementation of charm machine interface on networks of workstations. </title> <type> Master's thesis, </type> <institution> Dept. of Computer Science, University of Illinois, Urbana, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: Our experience has been that this interface is small and the functionality required is supported by most parallel vendors. The only special case was the interface for the network of workstations. A network of workstations can be regarded as a collection of processors <ref> [8] </ref> that do not share an address space. From this viewpoint, the nonshared memory implementation works unchanged on networks of workstations, and indeed the workstation version includes the same modules for the core kernel and strategies.
Reference: [9] <author> Dally, W.J. </author> <title> Fine-Grain Message-Passing Concurrent Computers. </title> <booktitle> In The Third Conference on Hypercube Concurrent Computers and Applications, </booktitle> <address> Pasadena, California, </address> <month> January </month> <year> 1988. </year>
Reference-contexts: On any processor P , these functions can be called by any chare resident on P . A BOC has some similarities to the concurrent aggregate construct [7] independently proposed by Chien and Dally which was designed for fine-grained parallel machines like the J-machine <ref> [9] </ref> (discussed in part I of this paper). Branch office chares provide a convenient abstraction for the implementation 3 of various distributed strategies, such as load balancing and support for distributed data structures. Charm does not permit general-purpose shared variables.
Reference: [10] <author> De, K., Ramkumar, B., Banerjee P. ProperSYN: </author> <title> A Portable Parallel Algorithm for Logic Synthesis. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 13 no. 5, </volume> <month> May </month> <year> 1994. </year>
Reference-contexts: They include several VLSI/CAD applications developed by P. Banerjee, B. Ramkumar, and others. A parallel Prolog compiler [23], a parallel circuit extractor [3], a parallel test pattern generator for sequential circuits [22], parallel logic synthesis based on transduction <ref> [10] </ref>, parallel cell placement based on simulated annealing [17], and a parallel molecular dynamics program called EGO have been implemented using Charm. Most of these applications are reported in detail elsewhere we do not repeat the algorithms here. <p> More importantly, Charm outperforms programs written using vendor primitives because of capabilities of adaptive scheduling provided by message driven execution [13] and the availability of prioritization queuing and load balancing strategies <ref> [23, 3, 22, 10, 17] </ref>. A parallel Prolog compiler which exploits both AND and OR parallelism has been written using Charm [23], and is one of the first such systems to run efficiently on both shared and non-shared memory system.
Reference: [11] <author> Doulas, N., Ramkumar B. </author> <title> Efficient Task Migration for Message-Driven Parallel Execution on Nonshared Memory Architectures. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1994. </year> <note> (to appear). </note>
Reference-contexts: We chose to implement a reliable communication layer using UDP socket connections. It was also necessary to implement fragmentation and reassembly of messages to accomodate large messages. A sliding 2 Chare migration is supported, but is outside the scope of this paper. For details see <ref> [11] </ref>. 11 window protocol was implemented to reduce the number of acknowledgement packets transmitted by the destination. This protocol uses a timeout mechanism to retransmit lost UDP datagrams to reduce network traffic further.
Reference: [12] <author> G. A. Geist and V. S. Sunderam. </author> <title> The PVM system: Supercomputing level concurrent computations on a heterogeneous network of workstations. </title> <booktitle> Sixth Distributed Memory Computing Conference Proceedings, </booktitle> <pages> pages 258-261, </pages> <year> 1991. </year>
Reference-contexts: We are currently improving the implementation to minimize the effect of these problems. Note that Charm, with message driven execution, is better equipped to deal with these problems than message passing libraries, such as PVM <ref> [30, 12] </ref>, because processors are not blocked waiting for just one message. 3 Some of these problems can be eliminated by creating a contrived environment with an isolated network and no other processes running on each workstation, but that, in our opinion, defeats one of the primary objectives of using a
Reference: [13] <author> Attila Gursoy. </author> <title> Simplified Expression of Message-Driven Programs and Quantification of their Impact on Performance. </title> <type> PhD thesis, </type> <institution> Departmant of Computer Science, University of Illinois at Urbana-Champaign, </institution> <month> March </month> <year> 1994. </year>
Reference-contexts: More importantly, Charm outperforms programs written using vendor primitives because of capabilities of adaptive scheduling provided by message driven execution <ref> [13] </ref> and the availability of prioritization queuing and load balancing strategies [23, 3, 22, 10, 17].
Reference: [14] <author> L. V. Kale and S. Krishnan. </author> <title> Charm++ : A portable concurrent object oriented system based on C++. </title> <booktitle> In Proceedings of OOPSLA-93., </booktitle> <month> March </month> <year> 1993. </year> <note> (Also: Technical Report UIUCDCS-R-93-1796, </note> <month> March </month> <year> 1993, </year> <institution> University of Illinois, Urbana, IL. </institution>
Reference-contexts: In Section 9, we describe the performance of the system and high-light some of the important characteristics of Charm programs. We then conclude the paper in Section 10 with a discussion of our experience. 1 An object-oriented version of Charm, based on C++ has also been developed <ref> [14] </ref>. Like Charm, it too uses the Chare kernel for its run-time support. 2 chare ChareName f /* Persistent Data (i.e.
Reference: [15] <author> Kale, L.V. </author> <title> Comparing the Performance of Two Dynamic Load Distribution Methods. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1988. </year> <month> 35 </month>
Reference-contexts: This obliviates the need for an explicit load balancing module for shared memory machines. Saletore [26] has developed many different strategies to balance load on large shared memory machines. On a nonshared memory machine, a suite of algorithms have been implemented, including random load balancing, adaptive contracting-within-neighborhood (ACWN) <ref> [15] </ref>, and a token-based local manager strategy for load balancing of prioritized tasks [29]. Any one of these strategies may be linked together with a Charm program to produce the final executable code.
Reference: [16] <author> Kale L.V. and Ramkumar B. and Sinha A.B. and Gursoy A. </author> <title> The CHARM Parallel Program--ming Language and System: Part I Description of Language Features. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <note> 1994. (submitted). </note>
Reference-contexts: The Chare kernel is a runtime system that supports portable, object based, and message driven parallel programming across MIMD architectures 1 . We discuss issues involved in realizing the features of Charm described in part I <ref> [16] </ref> of this paper on three classes of target architectures: shared memory machines, message passing machines and networks of workstations. <p> Entry functions in a particular chare instance can be asynchronously invoked by addressing a message to the desired entry function of the chare using the SendMsg system call. A chare is a concurrent object [2] and is somewhat like an actor [1] although there are some significant differences <ref> [16] </ref>. The objects in Charm are message-driven. In practical terms, this means that there is no receive call in the language, nor is there any blocking call that depends on processing on a remote processor. <p> Further, the completely general shared variable is difficult to implement efficiently on nonshared memory machines. Instead, Charm provides five different kinds of specifically shared variables: read only, write once, accumulator, monotonic, and distributed tables. A detailed description of the language features of Charm can be found in part I <ref> [16] </ref> of this paper. <p> This message is generated as a result of an explicit user terminate request (called CkExit () in Charm). Other system message types exist for various system strategies, such as load balancing. A translator translates the language described in part I of this paper <ref> [16] </ref> into C. Every entry point and the code associated with it is translated into a C-function, and a unique id is assigned to the entry point. <p> The information sharing abstractions were implemented, mostly for reasons of efficiency, using shared memory abstractions on shared memory machines. 14 7.1 Information Sharing Abstractions In addition to messages, chares can share data with the five information sharing variables (described in Part I <ref> [16] </ref>), namely, read-only variables, write-once variables, accumulator variables, monotonic variables and distributed tables. In this section, we discuss the implementation of these information sharing abstractions on shared and nonshared memory machines. On a nonshared memory machine, all the abstractions are implemented as branch office chares.
Reference: [17] <author> Kim S-H, Ramkumar B., Chandy J., Parkes S., Banerjee P. ProperPLACE: </author> <title> A Portable Parallel Algorithm for Standard Cell Placement. </title> <booktitle> In Proceedings of the International Parallel Processing Symposium, </booktitle> <address> Cancun, Mexico, </address> <month> March </month> <year> 1994. </year>
Reference-contexts: They include several VLSI/CAD applications developed by P. Banerjee, B. Ramkumar, and others. A parallel Prolog compiler [23], a parallel circuit extractor [3], a parallel test pattern generator for sequential circuits [22], parallel logic synthesis based on transduction [10], parallel cell placement based on simulated annealing <ref> [17] </ref>, and a parallel molecular dynamics program called EGO have been implemented using Charm. Most of these applications are reported in detail elsewhere we do not repeat the algorithms here. <p> More importantly, Charm outperforms programs written using vendor primitives because of capabilities of adaptive scheduling provided by message driven execution [13] and the availability of prioritization queuing and load balancing strategies <ref> [23, 3, 22, 10, 17] </ref>. A parallel Prolog compiler which exploits both AND and OR parallelism has been written using Charm [23], and is one of the first such systems to run efficiently on both shared and non-shared memory system. <p> The parallel test generator ProperTEST [21] was also one of the first parallel implementations of test pattern generation for sequential circuits to demonstrate the use of priorities to speedup up the parallel search consistently and improve fault coverage at the same time. The parallel cell placement algorithm ProperPLACE <ref> [17] </ref> demonstrated the feasibility of using one of the best available sequential implementations of cell placement based on simulated annealing - Timberwolf [28] as the sequential component of the Charm application.
Reference: [18] <author> Lin, F.C.H, Keller, R. </author> <title> Gradient Model: A Demand Driven Load Balancing Scheme. </title> <booktitle> In International Conference on Distributed Systems, </booktitle> <pages> pages 329-336, </pages> <year> 1986. </year>
Reference-contexts: An entry point, NeighborStatus, is provided for this purpose. For every message that is sent out, the kernel also calls the public function AddPiggybackInfo, which adds information about load on the processor onto the message. For a different load balancing scheme, e.g. the gradient model <ref> [18] </ref>, the load balancing process may be awakened periodically by the kernel to balance loads whenever the pressure gradient falls or rises above a certain threshold. Additional entry points may be added as desired for implementing different schemes.
Reference: [19] <author> Steven Parkes, John A. Chandy, and Prithviraj Banerjee. ProperCAD II: </author> <title> A run-time library for portable, parallel, object-oriented programming with applications to VLSI CAD. </title> <type> Technical Report CRHC-93-22/UILU-ENG-93-2250, </type> <institution> Center for Reliable and High-performance Computing, University of Illinois, </institution> <month> December </month> <year> 1993. </year>
Reference-contexts: Scalable techniques used in its design and implementation ensure that the system runs efficiently on machines with thousands of processors, 8 The latest version of ProperPLACE and other CAD applications now use a new object-oriented message-driven environment called ProperCAD II <ref> [19] </ref>, that has been fine-tuned for parallel CAD applications. 33 as confirmed by tests on a 1024 node NCUBE-II. Acknowledgements Our thanks to Weeg Supercomputing Center at the University of Iowa for access to the Encore Multimax, and the Sandia National Laboratories for access to their NCUBE/2 hypercube.
Reference: [20] <author> Patil S., Banerjee, B. </author> <title> A Parallel Branch and Bound Algorithm for Test Generation. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 9, no. 3 </volume> <pages> 313-322, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: In several cases, these algorithms are not amenable to parallelization, in that parallel versions of these algorithms may result in in significant loss of quality and poor speedups. This is clearly evident in a wide range of VLSI CAD applications including test pattern generation <ref> [20, 21] </ref>, cell placement [4, 24], global routing [6, 25] and a molecular dynamics application EGO. We believe it is therefore necessary to build the parallel algorithm around the best available sequential algorithm.
Reference: [21] <author> Ramkumar, B., Banerjee P. </author> <title> Portable Parallel Test Generation for Sequential Circuits. </title> <booktitle> In Proceedings of the International Conference on Computer-Aided Design, </booktitle> <pages> pages 220-223, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: In several cases, these algorithms are not amenable to parallelization, in that parallel versions of these algorithms may result in in significant loss of quality and poor speedups. This is clearly evident in a wide range of VLSI CAD applications including test pattern generation <ref> [20, 21] </ref>, cell placement [4, 24], global routing [6, 25] and a molecular dynamics application EGO. We believe it is therefore necessary to build the parallel algorithm around the best available sequential algorithm. <p> On shared memory machines, the extractor outperforms 32 PACE2 [5], in spite of the fact that PACE2 is based on an algorithm designed specifically for shared memory machines. The parallel test generator ProperTEST <ref> [21] </ref> was also one of the first parallel implementations of test pattern generation for sequential circuits to demonstrate the use of priorities to speedup up the parallel search consistently and improve fault coverage at the same time.
Reference: [22] <author> Ramkumar, B., Banerjee P. ProperTEST: </author> <title> A Portable Parallel Test Generator for Sequential Circuits. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <note> 1992. (submitted). </note>
Reference-contexts: Note that the same is not true for the network version: we attribute this to 7 Similar curves were obtained for parallel Prolog [23], parallel circuit extraction [3], test pattern generation <ref> [22] </ref>, and several other applications they have been reported elsewhere. 31 costs incurred on the network version to poll the network for messages from other processors (even though there are no such messages). <p> They include several VLSI/CAD applications developed by P. Banerjee, B. Ramkumar, and others. A parallel Prolog compiler [23], a parallel circuit extractor [3], a parallel test pattern generator for sequential circuits <ref> [22] </ref>, parallel logic synthesis based on transduction [10], parallel cell placement based on simulated annealing [17], and a parallel molecular dynamics program called EGO have been implemented using Charm. Most of these applications are reported in detail elsewhere we do not repeat the algorithms here. <p> More importantly, Charm outperforms programs written using vendor primitives because of capabilities of adaptive scheduling provided by message driven execution [13] and the availability of prioritization queuing and load balancing strategies <ref> [23, 3, 22, 10, 17] </ref>. A parallel Prolog compiler which exploits both AND and OR parallelism has been written using Charm [23], and is one of the first such systems to run efficiently on both shared and non-shared memory system.
Reference: [23] <author> Ramkumar B., Kale L.V. </author> <title> Machine Independent AND and OR Parallel Execution of Logic Programs Part II: Compiled Execution. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 5, no. 2, </volume> <month> February </month> <year> 1994. </year>
Reference-contexts: The summation of time-to-finish on all processors can be expressed as: T = T computation + T overhead + T idle , where the overhead T overhead = K fl T computation =g. 6 The exception to this was the parallel Prolog compiler <ref> [23] </ref>. The lack of availability of the source code of a fast sequential Prolog compiler caused us to use a slower garden-variety compiler. <p> Note that the same is not true for the network version: we attribute this to 7 Similar curves were obtained for parallel Prolog <ref> [23] </ref>, parallel circuit extraction [3], test pattern generation [22], and several other applications they have been reported elsewhere. 31 costs incurred on the network version to poll the network for messages from other processors (even though there are no such messages). <p> They include several VLSI/CAD applications developed by P. Banerjee, B. Ramkumar, and others. A parallel Prolog compiler <ref> [23] </ref>, a parallel circuit extractor [3], a parallel test pattern generator for sequential circuits [22], parallel logic synthesis based on transduction [10], parallel cell placement based on simulated annealing [17], and a parallel molecular dynamics program called EGO have been implemented using Charm. <p> More importantly, Charm outperforms programs written using vendor primitives because of capabilities of adaptive scheduling provided by message driven execution [13] and the availability of prioritization queuing and load balancing strategies <ref> [23, 3, 22, 10, 17] </ref>. A parallel Prolog compiler which exploits both AND and OR parallelism has been written using Charm [23], and is one of the first such systems to run efficiently on both shared and non-shared memory system. <p> A parallel Prolog compiler which exploits both AND and OR parallelism has been written using Charm <ref> [23] </ref>, and is one of the first such systems to run efficiently on both shared and non-shared memory system. It was also one of the first implementations to demonstrate speedups on Prolog program on upto 256 processors (on an NCUBE/2) [23]. <p> both AND and OR parallelism has been written using Charm <ref> [23] </ref>, and is one of the first such systems to run efficiently on both shared and non-shared memory system. It was also one of the first implementations to demonstrate speedups on Prolog program on upto 256 processors (on an NCUBE/2) [23]. The parallel circuit extractor [3] was developed around the same sequential C code used by PACE2 [5] to permit a fair comparison of the two.
Reference: [24] <author> Ravikumar, C.P., Sastry S. </author> <title> Parallel Placement on Hypercube Architectures. </title> <booktitle> In International Conference on Parallel Processing, pages III: </booktitle> <pages> 97-100, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: In several cases, these algorithms are not amenable to parallelization, in that parallel versions of these algorithms may result in in significant loss of quality and poor speedups. This is clearly evident in a wide range of VLSI CAD applications including test pattern generation [20, 21], cell placement <ref> [4, 24] </ref>, global routing [6, 25] and a molecular dynamics application EGO. We believe it is therefore necessary to build the parallel algorithm around the best available sequential algorithm.
Reference: [25] <author> Rose, J.S. </author> <title> Parallel Global Routing for Standard Cells. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 9, no. 10 </volume> <pages> 1085-1095, </pages> <month> October </month> <year> 1990. </year> <month> 36 </month>
Reference-contexts: This is clearly evident in a wide range of VLSI CAD applications including test pattern generation [20, 21], cell placement [4, 24], global routing <ref> [6, 25] </ref> and a molecular dynamics application EGO. We believe it is therefore necessary to build the parallel algorithm around the best available sequential algorithm.
Reference: [26] <author> Saletore, </author> <title> V.A. Machine Independent Parallel Execution of Speculative Computations. </title> <type> PhD the-sis, </type> <institution> Dept. of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, </institution> <year> 1991. </year>
Reference-contexts: This has been empirically found to provide negligible contention for a wide variety of programs <ref> [26] </ref>. This strategy also helps with memory utilization and load balancing. Processing new chare messages before for-chare messages would lead to an accumulation of for-chare messages proportional to the creation tree of chares, which would lead to exponential memory utilization in many application classes, such as divide and conquer. <p> The use for a shared queue for such messages improves the load distribution. This obliviates the need for an explicit load balancing module for shared memory machines. Saletore <ref> [26] </ref> has developed many different strategies to balance load on large shared memory machines. On a nonshared memory machine, a suite of algorithms have been implemented, including random load balancing, adaptive contracting-within-neighborhood (ACWN) [15], and a token-based local manager strategy for load balancing of prioritized tasks [29].
Reference: [27] <author> Saletore, V.A., Kale, L.V. </author> <title> Parallel State-Space Search for a First Solution with Consistent Linear Speedups. </title> <journal> International Journal of Parallel Programming, </journal> <year> 1990. </year>
Reference-contexts: A minor complication arises because Charm allows priorities to be specified for a message: a message can have no priority, an integer priority, or a variable length bit-vector priority <ref> [27] </ref>. The message must also include this priority field.
Reference: [28] <author> Sechen, C., Sangiovanni-Vincentelli A.L. </author> <title> The TimberWolf Placement and Routing Package. </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> vol. 20, no. 2 </volume> <pages> 510-522, </pages> <year> 1988. </year>
Reference-contexts: The parallel cell placement algorithm ProperPLACE [17] demonstrated the feasibility of using one of the best available sequential implementations of cell placement based on simulated annealing - Timberwolf <ref> [28] </ref> as the sequential component of the Charm application. A new parallel algorithm was built around Timberwolf and rendered portable through Charm. 8 EGO is a parallel molecular dynamics application, which was originally a synchronous program written in Occam for the Transputers.
Reference: [29] <author> Sinha A.B., Kale L.V. </author> <title> A Load Balancing Strategy for Prioritized Execution of Tasks. </title> <booktitle> In Proceedings of International Parallel Processing i Symposium, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: Saletore [26] has developed many different strategies to balance load on large shared memory machines. On a nonshared memory machine, a suite of algorithms have been implemented, including random load balancing, adaptive contracting-within-neighborhood (ACWN) [15], and a token-based local manager strategy for load balancing of prioritized tasks <ref> [29] </ref>. Any one of these strategies may be linked together with a Charm program to produce the final executable code. Additional strategies 17 may also be added by users as long as they conform to the prescribed interface shown in Figure 6.
Reference: [30] <author> V. S. Sunderam. </author> <title> PVM: A framework for parallel distributed computing. </title> <journal> Concurrency: Practice & Experience, </journal> <volume> 2, 4 </volume> <pages> 315-339, </pages> <month> December </month> <year> 1990. </year> <month> 37 </month>
Reference-contexts: We are currently improving the implementation to minimize the effect of these problems. Note that Charm, with message driven execution, is better equipped to deal with these problems than message passing libraries, such as PVM <ref> [30, 12] </ref>, because processors are not blocked waiting for just one message. 3 Some of these problems can be eliminated by creating a contrived environment with an isolated network and no other processes running on each workstation, but that, in our opinion, defeats one of the primary objectives of using a
References-found: 30

