URL: http://compgeom.cs.uiuc.edu/~jeffe/pubs/hopcroft.ps.gz
Refering-URL: http://compgeom.cs.uiuc.edu/~jeffe/pubs/hopcroft.html
Root-URL: http://www.cs.uiuc.edu
Email: jeffe@cs.berkeley.edu  
Title: New Lower Bounds for Hopcroft's Problem  
Author: Jeff Erickson 
Date: April 13, 1995  January 23, 1996  
Note: Submitted to Discrete Computational Geometry:  Revised and resubmitted:  
Address: Berkeley, CA 94720 USA  D-66123 Saarbrucken, Germany  
Affiliation: Computer Science Division University of California  Fachbereich 14 Informatik Universitat des Saarlandes  
Abstract: We establish new lower bounds on the complexity of the following basic geometric problem, attributed to John Hopcroft: Given a set of n points and m hyperplanes in IR d , is any point contained in any hyperplane? We define a general class of partitioning algorithms, and show that in the worst case, for all m and n, any such algorithm requires time (n log m + n 2=3 m 2=3 + m log n) in two dimensions, or (n log m + n 5=6 m 1=2 + n 1=2 m 5=6 + m log n) in three or more dimensions. We obtain slightly higher bounds for the counting version of Hopcroft's problem in four or more dimensions. Our planar lower bound is within a factor of 2 O(log fl (n+m)) of the best known upper bound, due to Matousek. Previously, the best known lower bound, in any dimension, was (n log m + m log n). We develop our lower bounds in two stages. First we define a combinatorial representation of the relative order type of a set of points and hyperplanes, called a monochromatic cover, and derive lower bounds on its size in the worst case. We then show that the running time of any partitioning algorithm is bounded below by the size of some monochromatic cover. As a related result, using a straightforward adversary argument, we derive a quadratic lower bound on the complexity of Hopcroft's problem in a surprisingly powerful decision tree model of computation. fl This research was partially supported by NSF grant CCR-9058440. An earlier version of this paper was published as Technical Report A/04/94, Fachbereich Informatik, Universitat des Saarlandes, Saarbrucken, Germany, November 1994. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. K. Agarwal. </author> <title> Partitioning arrangements of lines: II. </title> <journal> Applications. Discrete Comput. Geom., </journal> <volume> 5 </volume> <pages> 533-573, </pages> <year> 1990. </year>
Reference-contexts: Further research replaced the n " term in this upper bound with a succession of smaller and smaller poly-logarithmic factors. The running time was improved by Edelsbrunner et al. [18] to O (n 4=3 log 4 n) (expected), then by Agarwal <ref> [1] </ref> to O (n 4=3 log 1:78 n), then by Chazelle [9] to O (n 4=3 log 1=3 n), and most recently by Matousek [30] to n 4=3 2 O (log fl n) . 2 This is currently the fastest algorithm known. <p> Matousek's algorithm and Theorem 4.4 immediately give us the following theorem. Theorem 4.8. d (n; m) = O However, other algorithms do not use the point location data structure to locate hyperplanes, at least not at all levels of recursion. In these algorithms <ref> [18, 1] </ref>, the query regions form a decomposition of space into cells of constant complexity, typically simplices or trapezoids. The algorithms determine which cells a given hyperplane hits by iteratively "walking" through the cells.
Reference: [2] <author> P. K. Agarwal, N. Alon, B. Aronov, and S. Suri. </author> <title> Can visibility graphs be represented compactly? In Proc. </title> <booktitle> 9th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 338-347, </pages> <year> 1993. </year>
Reference-contexts: These results apply immediately to monochromatic covers of arbitrary sign matrices. See also <ref> [2] </ref> for a geometric application of bipartite clique covers. Relative orientation matrices are defined in terms of a fixed (projective) coordinate system, which determines what it means for a point to be "above" or "below" a hyperplane.
Reference: [3] <author> M. Ben-Or. </author> <title> Lower bounds for algebraic computation trees. </title> <booktitle> In Proc. 15th Annu. ACM Sympos. Theory Comput., </booktitle> <pages> pages 80-86, </pages> <year> 1983. </year>
Reference-contexts: The only previously known lower bound is (n log m+ m log n), in the algebraic decision tree and algebraic computation tree models, by reduction from the problem of detecting an intersection between two sets of real numbers <ref> [34, 3] </ref>. In this paper, we establish new lower bounds on the complexity of Hopcroft's problem.
Reference: [4] <author> M. de Berg, M. Overmars, and O. Schwarzkopf. </author> <title> Computing and verifying depth orders. </title> <booktitle> In Proc. 8th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 138-145, </pages> <year> 1992. </year>
Reference-contexts: We mention one specific example, the cyclic overlap problem. Given a set of non-intersecting line segments in IR 3 , does any subset form a cycle with respect to the "above" relation? The fastest known algorithm for this problem, due to de Berg et al. <ref> [4] </ref>, runs in time O (n 4=3+" ), using a divide-and-conquer strategy very similar to algorithms for Hopcroft's problem. In the algebraic decision tree model, the cyclic overlap problem is at least as hard as Hopcroft's problem [23].
Reference: [5] <author> M. de Berg and O. Schwarzkopf. </author> <title> Cuttings and applications. </title> <type> Report RUU-CS-92-26, </type> <institution> Dept. Comput. Sci., Utrecht Univ., </institution> <address> Utrecht, Netherlands, </address> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: Matousek's algorithm can be tuned to detect incidences among n points and m lines in the plane in time O (n log m + n 2=3 m 2=3 2 O (log fl (n+m)) + m log n) <ref> [5] </ref>, or more generally among n points and m hyperplanes in IR d in time O n log m + n d=(d+1) m d=(d+1) 2 O (log fl (n+m)) + m log n : The lower bound history is much shorter. <p> The fastest deterministic algorithm for counting line segment intersections, due to Chazelle [9], runs in time O (n 4=3 log 1=3 n). A randomized output sensitive algorithm of de Berg and Schwarzkopf <ref> [5] </ref> runs in expected time O (n log n + n 2=3 A 2=3 log 1=3 n), where A is the number of intersections, matching Chazelle's algorithm in the worst case.
Reference: [6] <author> H. Bronnimann, B. Chazelle, and J. Pach. </author> <title> How hard is halfspace range searching. </title> <journal> Discrete Comput. Geom., </journal> <volume> 10 </volume> <pages> 143-155, </pages> <year> 1993. </year>
Reference-contexts: In higher dimensions, Chazelle's results imply lower bounds of (n 2d=(d+1) = log d=(d+1) n) and (n 2d=(d+1) = log 5=2fl n) in the online and o*ine cases, respectively, where fl &gt; 0 is a small constant that depends on d. For related results, see also <ref> [6, 12] </ref>. These lower bounds hold in the Fredman/Yao semigroup arithmetic model [25]. In this model, points are given arbitrary weights from an additive semigroup, and the complexity of the algorithm is given by the number of additions required to calculate the total weight of the points in each range.
Reference: [7] <author> B. Chazelle. </author> <title> Reporting and counting segment intersections. </title> <journal> J. Comput. Syst. Sci., </journal> <volume> 32 </volume> <pages> 156-182, </pages> <year> 1986. </year>
Reference-contexts: Given a set of n points and n lines in the plane, does any point lie on a line? Hopcroft's problem arises as a special case of many other geometric problems, including collision detection, ray shooting, and range searching. The earliest sub-quadratic algorithm for Hopcroft's problem, due to Chazelle <ref> [7] </ref>, runs in time O (n 1:695 ). (Actually, this algorithm counts intersections among a set of n line segments in the plane, but it can easily be modified to count point-line incidences instead.) A very simple algorithm, attributed to Hopcroft and Seidel [16], described in [17, p. 350], runs in <p> Each algorithm divides space into a number of regions, determines which points and hy-perplanes intersect each region, and recursively solves the resulting subproblems. In some cases <ref> [7, 20, 13] </ref>, the number of regions used at each level of recursion is a constant, and these algorithms fit naturally into the partitioning algorithm framework.
Reference: [8] <author> B. Chazelle. </author> <title> Lower bounds on the complexity of polytope range searching. </title> <journal> J. Amer. Math. Soc., </journal> <volume> 2 </volume> <pages> 637-666, </pages> <year> 1989. </year>
Reference-contexts: Of course, we cannot apply this argument to either the decision version or the counting version of Hopcroft's problem, since the output size for these problems is constant. Our planar lower bounds are ultimately based on the Erd-os configuration. Chazelle <ref> [8, 10] </ref> has established lower bounds for the closely related simplex range counting problem: Given a set of points and a set of simplices, how many points are in each simplex? For example, any data structure of size s that supports triangular range queries among n points in the plane requires <p> the closely related simplex range counting problem: Given a set of points and a set of simplices, how many points are in each simplex? For example, any data structure of size s that supports triangular range queries among n points in the plane requires (n= p s) time per query <ref> [8] </ref>. It follows that answering n queries over n points requires (n 4=3 ) time in the worst case. <p> Replace each line ` in this configuration with a pair of lines, 5 Perhaps it is more interesting that Chazelle's static lower bounds <ref> [8, 10] </ref> do not use this construction. 8 Jeff Erickson parallel to ` and at distance " on either side, where " is chosen sufficiently small that all point-line distances in the new configuration are at least ". <p> The fastest known deterministic algorithm for detecting or counting line intersections in IR 3 , due to Chazelle et al. [11], runs in time O (n 8=5+" ). Pellegrini [31] describes a randomized algorithm with the same running time. 5.3 O*ine Range Searching Chazelle <ref> [8] </ref> has developed lower bounds for the query time required by a simplex or halfspace range query data structure, given an upper bound on its size. However, his results only apply to range searching problems in which the data structure must be built to handle arbitrary queries online.
Reference: [9] <author> B. Chazelle. </author> <title> Cutting hyperplanes for divide-and-conquer. </title> <journal> Discrete Comput. Geom., </journal> <volume> 9(2) </volume> <pages> 145-158, </pages> <year> 1993. </year>
Reference-contexts: The running time was improved by Edelsbrunner et al. [18] to O (n 4=3 log 4 n) (expected), then by Agarwal [1] to O (n 4=3 log 1:78 n), then by Chazelle <ref> [9] </ref> to O (n 4=3 log 1=3 n), and most recently by Matousek [30] to n 4=3 2 O (log fl n) . 2 This is currently the fastest algorithm known. <p> Composing all the point location data structures used by the algorithm in all recursive subproblems gives us the algorithm's partition graph. Many of these algorithms alternate between primal and dual spaces at various levels of recursion <ref> [9, 30] </ref>. The data structures used in primal space give us the primal nodes in the partition graph, and the data structures used in dual space give us the dual nodes. <p> What about the hyperplanes? Many algorithms also use the point location data structures to determine the regions hit by each hyperplane. Algorithms of this type fit into our model perfectly. In particular, Matousek's algorithm [30], which is based on Chazelle's hierarchical cuttings <ref> [9] </ref> and is the fastest algorithm known, can be modeled this way. Matousek's algorithm and Theorem 4.4 immediately give us the following theorem. <p> We could use, for example, the randomized incremental construction of Seidel [32] in the plane, or the hierarchical cuttings data structure of Chazelle <ref> [9] </ref> in higher dimensions. The modified algorithm can then be described as a partitioning algorithm. Other algorithms construct a point location data structure for the arrangement of the entire set of hyperplanes [16, 20, 9]. <p> The modified algorithm can then be described as a partitioning algorithm. Other algorithms construct a point location data structure for the arrangement of the entire set of hyperplanes <ref> [16, 20, 9] </ref>. Usually, this is done only when the number of hyperplanes is much smaller than the number of points. <p> Since the model is weaker than we expect, the lower bounds still hold. New Lower Bounds for Hopcroft's Problem 21 A simple sweep-line algorithm determines the presence of line segment intersections in time O (n log n). The fastest deterministic algorithm for counting line segment intersections, due to Chazelle <ref> [9] </ref>, runs in time O (n 4=3 log 1=3 n).
Reference: [10] <author> B. Chazelle. </author> <title> Lower bounds for off-line range searching. </title> <booktitle> In Proc. 27th Annu. ACM Sympos. Theory Comput., </booktitle> <pages> pages 733-740, </pages> <year> 1995. </year> <title> New Lower Bounds for Hopcroft's Problem 25 </title>
Reference-contexts: Of course, we cannot apply this argument to either the decision version or the counting version of Hopcroft's problem, since the output size for these problems is constant. Our planar lower bounds are ultimately based on the Erd-os configuration. Chazelle <ref> [8, 10] </ref> has established lower bounds for the closely related simplex range counting problem: Given a set of points and a set of simplices, how many points are in each simplex? For example, any data structure of size s that supports triangular range queries among n points in the plane requires <p> It follows that answering n queries over n points requires (n 4=3 ) time in the worst case. For the o*ine version of the same problem, where all the triangles are known in advance, Chazelle establishes a slightly weaker bound of (n 4=3 = log 4=3 n) <ref> [10] </ref>, although an (n 4=3 ) lower bound follows immediately from the Erd-os construction using Chazelle's methods. <p> Replace each line ` in this configuration with a pair of lines, 5 Perhaps it is more interesting that Chazelle's static lower bounds <ref> [8, 10] </ref> do not use this construction. 8 Jeff Erickson parallel to ` and at distance " on either side, where " is chosen sufficiently small that all point-line distances in the new configuration are at least ". <p> The lower bound follows from the following result of Chazelle <ref> [10, Lemma 3.3] </ref>. (Chazelle's lemma only deals with the case n = m, but his proof generalizes immediately to the more general case.) Lemma 3.13. <p> However, his results only apply to range searching problems in which the data structure must be built to handle arbitrary queries online. More recently, Chazelle <ref> [10] </ref> proves a lower bound of (n 2d=(d+1) = log 5=2fl n), where fl &gt; 0 is a small constant that depends on the dimension, on the complexity of the o*ine simplex range searching problem in IR d , in the Fredman/Yao semigroup arithmetic model.
Reference: [11] <author> B. Chazelle, H. Edelsbrunner, L. Guibas, and M. Sharir. </author> <title> Diameter, width, closest line pair and parametric searching. </title> <journal> Discrete Comput. Geom., </journal> <volume> 10 </volume> <pages> 183-196, </pages> <year> 1993. </year>
Reference-contexts: Theorem 5.3 also applies to such algorithms. The fastest known deterministic algorithm for detecting or counting line intersections in IR 3 , due to Chazelle et al. <ref> [11] </ref>, runs in time O (n 8=5+" ). Pellegrini [31] describes a randomized algorithm with the same running time. 5.3 O*ine Range Searching Chazelle [8] has developed lower bounds for the query time required by a simplex or halfspace range query data structure, given an upper bound on its size.
Reference: [12] <author> B. Chazelle and B. Rosenberg. </author> <title> Lower bounds on the complexity of simplex range reporting on a pointer machine. </title> <booktitle> In Proc. 19th International Colloquium on Automata, Languages, and Programming, volume 623 of Lecture Notes in Computer Science, </booktitle> <pages> pages 439-449. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year> <note> Also to appear in Comput. Geom. Theory Appl. </note>
Reference-contexts: In higher dimensions, Chazelle's results imply lower bounds of (n 2d=(d+1) = log d=(d+1) n) and (n 2d=(d+1) = log 5=2fl n) in the online and o*ine cases, respectively, where fl &gt; 0 is a small constant that depends on d. For related results, see also <ref> [6, 12] </ref>. These lower bounds hold in the Fredman/Yao semigroup arithmetic model [25]. In this model, points are given arbitrary weights from an additive semigroup, and the complexity of the algorithm is given by the number of additions required to calculate the total weight of the points in each range.
Reference: [13] <author> B. Chazelle, M. Sharir, and E. Welzl. </author> <title> Quasi-optimal upper bounds for simplex range searching and new zone theorems. </title> <journal> Algorithmica, </journal> <volume> 8 </volume> <pages> 407-429, </pages> <year> 1992. </year>
Reference-contexts: Edelsbrunner et al. [20] developed a randomized algorithm with expected running time O (n 4=3+" ) 1 ; see also [19]. A somewhat simpler algorithm with the same running time was developed by Chazelle et al. <ref> [13] </ref>. Further research replaced the n " term in this upper bound with a succession of smaller and smaller poly-logarithmic factors. <p> Each algorithm divides space into a number of regions, determines which points and hy-perplanes intersect each region, and recursively solves the resulting subproblems. In some cases <ref> [7, 20, 13] </ref>, the number of regions used at each level of recursion is a constant, and these algorithms fit naturally into the partitioning algorithm framework.
Reference: [14] <author> F. R. K. Chung, P. Erd-os, and J. Spencer. </author> <title> On the decomposition of graphs into complete bipartite subgraphs. </title> <editor> In P. Erd-os, editor, </editor> <booktitle> Studies in pure mathematics, </booktitle> <pages> pages 95-101. </pages> <publisher> Birkhauser, </publisher> <year> 1983. </year>
Reference-contexts: Tuza [38], and independently Chung et al. <ref> [14] </ref>, showed that every n fi m bipartite graph has such a cover of size O (nm= log (max (m; n))) and that this bound is tight in the worst case, up to constant factors. These results apply immediately to monochromatic covers of arbitrary sign matrices.
Reference: [15] <author> K. Clarkson, H. Edelsbrunner, L. Guibas, M. Sharir, and E. Welzl. </author> <title> Combinatorial complexity bounds for arrangements of curves and spheres. </title> <journal> Discrete Comput. Geom., </journal> <volume> 5 </volume> <pages> 99-160, </pages> <year> 1990. </year>
Reference-contexts: The corresponding upper bound was first proven by Szemeredi and Trotter [36]. A simpler proof, with better constants, was later given by Clarkson et al. <ref> [15] </ref> Theorem 3.3. 2 (n; m) = (n + n 2=3 m 2=3 + m) Proof: It is not possible for two distinct points to both be adjacent to two distinct lines; any mutually incident set of points and lines has either exactly one point or exactly one line. <p> Using the probabilistic counting techniques of Clarkson et al. <ref> [15] </ref>, we can improve this upper bound to O (n + n 4=5 m 3=5 + m). 10 Jeff Erickson Theorem 3.6. 3 (n; m) = (n + n 5=6 m 1=2 + n 1=2 m 5=6 + m) Proof: Consider the case n 1=3 &lt; m n. <p> Again, using probabilistic counting techniques <ref> [15] </ref>, we can prove an upper bound of I (P; H) = O (n + n (2d2)=(2d1) m d=(2d1) + m) if any d hyperplanes in H intersect in at most one point. The previous lemma immediately gives us the following lower bound for d (n; m). <p> We can easily verify that altering the definition to use point-unit circle duality does not change our lower bound. Our lower bound is somewhat surprising given known bounds on the maximum number of unit distances among n points in the plane. Spencer et al. [33] and Clarkson et al. <ref> [15] </ref> prove an upper New Lower Bounds for Hopcroft's Problem 23 bound of O (n 4=3 ).
Reference: [16] <author> R. Cole, M. Sharir, and C. K. Yap. </author> <title> On k-hulls and related problems. </title> <journal> SIAM J. Comput., </journal> <volume> 16 </volume> <pages> 61-77, </pages> <year> 1987. </year>
Reference-contexts: algorithm for Hopcroft's problem, due to Chazelle [7], runs in time O (n 1:695 ). (Actually, this algorithm counts intersections among a set of n line segments in the plane, but it can easily be modified to count point-line incidences instead.) A very simple algorithm, attributed to Hopcroft and Seidel <ref> [16] </ref>, described in [17, p. 350], runs in time O (n 3=2 log 1=2 n). Cole et al. [16] combined these two algorithms, achieving a running time of O (n 1:412 ). <p> counts intersections among a set of n line segments in the plane, but it can easily be modified to count point-line incidences instead.) A very simple algorithm, attributed to Hopcroft and Seidel <ref> [16] </ref>, described in [17, p. 350], runs in time O (n 3=2 log 1=2 n). Cole et al. [16] combined these two algorithms, achieving a running time of O (n 1:412 ). Edelsbrunner et al. [20] developed a randomized algorithm with expected running time O (n 4=3+" ) 1 ; see also [19]. <p> The modified algorithm can then be described as a partitioning algorithm. Other algorithms construct a point location data structure for the arrangement of the entire set of hyperplanes <ref> [16, 20, 9] </ref>. Usually, this is done only when the number of hyperplanes is much smaller than the number of points.
Reference: [17] <author> H. Edelsbrunner. </author> <title> Algorithms in Combinatorial Geometry, </title> <booktitle> volume 10 of EATCS Monographs on Theoretical Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1987. </year>
Reference-contexts: problem, due to Chazelle [7], runs in time O (n 1:695 ). (Actually, this algorithm counts intersections among a set of n line segments in the plane, but it can easily be modified to count point-line incidences instead.) A very simple algorithm, attributed to Hopcroft and Seidel [16], described in <ref> [17, p. 350] </ref>, runs in time O (n 3=2 log 1=2 n). Cole et al. [16] combined these two algorithms, achieving a running time of O (n 1:412 ). Edelsbrunner et al. [20] developed a randomized algorithm with expected running time O (n 4=3+" ) 1 ; see also [19]. <p> Otherwise, see <ref> [17] </ref> or [35]. 2 Jeff Erickson the regions or how they depend on the input. We give a more formal definition of partitioning algorithms in Section 4. <p> Some related results deserve to be mentioned here. Erd-os constructed a set of n points and n lines in the plane with (n 4=3 ) incident point-line pairs <ref> [17, p. 112] </ref>. It follows immediately that any algorithm that reports all incident pairs requires time (n 4=3 ) in the worst case. <p> In Section 4, we generalize this connection to higher dimensions. 3.2 Two Dimensions To derive lower bounds for fl 2 (n; m) and 2 (n; m), we use the following combinatorial result of Erd-os. (See [25] or <ref> [17, p.112] </ref> for proofs.) Lemma 3.2 (Erd-os). For all n and m, there is a set of n points and m lines in the plane with (n + n 2=3 m 2=3 + m) incident pairs. Thus, I 2 (n; m) = (n + n 2=3 m 2=3 + m). <p> Finally, a few algorithms partition the points or the hyperplanes arbitrarily into subsets, without using geometric information of any kind <ref> [17, p. 350] </ref>,[16]. In this case, every hyperplane becomes part of every subproblem.
Reference: [18] <author> H. Edelsbrunner, L. Guibas, J. Hershberger, R. Seidel, M. Sharir, J. Snoeyink, and E. Welzl. </author> <title> Implicitly representing arrangements of lines or segments. </title> <journal> Discrete Comput. Geom., </journal> <volume> 4 </volume> <pages> 433-466, </pages> <year> 1989. </year>
Reference-contexts: A somewhat simpler algorithm with the same running time was developed by Chazelle et al. [13]. Further research replaced the n " term in this upper bound with a succession of smaller and smaller poly-logarithmic factors. The running time was improved by Edelsbrunner et al. <ref> [18] </ref> to O (n 4=3 log 4 n) (expected), then by Agarwal [1] to O (n 4=3 log 1:78 n), then by Chazelle [9] to O (n 4=3 log 1=3 n), and most recently by Matousek [30] to n 4=3 2 O (log fl n) . 2 This is currently the <p> Matousek's algorithm and Theorem 4.4 immediately give us the following theorem. Theorem 4.8. d (n; m) = O However, other algorithms do not use the point location data structure to locate hyperplanes, at least not at all levels of recursion. In these algorithms <ref> [18, 1] </ref>, the query regions form a decomposition of space into cells of constant complexity, typically simplices or trapezoids. The algorithms determine which cells a given hyperplane hits by iteratively "walking" through the cells.
Reference: [19] <author> H. Edelsbrunner, L. Guibas, and M. Sharir. </author> <title> The complexity of many cells in arrangements of planes and related problems. </title> <journal> Discrete Comput. Geom., </journal> <volume> 5 </volume> <pages> 197-216, </pages> <year> 1990. </year>
Reference-contexts: Cole et al. [16] combined these two algorithms, achieving a running time of O (n 1:412 ). Edelsbrunner et al. [20] developed a randomized algorithm with expected running time O (n 4=3+" ) 1 ; see also <ref> [19] </ref>. A somewhat simpler algorithm with the same running time was developed by Chazelle et al. [13]. Further research replaced the n " term in this upper bound with a succession of smaller and smaller poly-logarithmic factors. <p> Since i ? j, each such plane determines a unique line. Furthermore, since all these lines are tangent to a parabola, no three of them are concurrent. It follows that the intersection of any three planes in H consists of at most one point. fl Edelsbrunner et al. <ref> [19] </ref> prove an upper bound of O (n log m + n 4=5+2" m 3=5" + m) on the maximum number of incidences between n points and m planes, where no three planes contain a common line.
Reference: [20] <author> H. Edelsbrunner, L. J. Guibas, and M. Sharir. </author> <title> The complexity and construction of many faces in arrangements of lines and of segments. </title> <journal> Discrete Comput. Geom., </journal> <volume> 5 </volume> <pages> 161-196, </pages> <year> 1990. </year>
Reference-contexts: Cole et al. [16] combined these two algorithms, achieving a running time of O (n 1:412 ). Edelsbrunner et al. <ref> [20] </ref> developed a randomized algorithm with expected running time O (n 4=3+" ) 1 ; see also [19]. A somewhat simpler algorithm with the same running time was developed by Chazelle et al. [13]. <p> Each algorithm divides space into a number of regions, determines which points and hy-perplanes intersect each region, and recursively solves the resulting subproblems. In some cases <ref> [7, 20, 13] </ref>, the number of regions used at each level of recursion is a constant, and these algorithms fit naturally into the partitioning algorithm framework. <p> The modified algorithm can then be described as a partitioning algorithm. Other algorithms construct a point location data structure for the arrangement of the entire set of hyperplanes <ref> [16, 20, 9] </ref>. Usually, this is done only when the number of hyperplanes is much smaller than the number of points.
Reference: [21] <author> H. Edelsbrunner and M. Sharir. </author> <title> A hyperplane incidence problem with applications to counting distances. </title> <editor> In P. Gritzman and B. Sturmfels, editors, </editor> <booktitle> Applied Geometry and Discrete Mathematics: The Victor Klee Festschrift, volume 4 of DIMACS Series in Discrete Mathematics and Theoretical Computer Science, </booktitle> <pages> pages 253-263. </pages> <publisher> AMS Press, </publisher> <year> 1991. </year>
Reference-contexts: 13 The best upper bound we can prove for the number of incidences between n points and m hyper-planes in IR 4 , where every point is above or on every hyperplane and no four hyperplanes contain a line, is O (n + n 2=3 m 2=3 + m). (See <ref> [21] </ref> for the derivation of a similar upper bound.) No superlinear lower bounds are known in any dimension, so there is some hope for a linear upper bound. However, we can achieve a superlinear number of incidences in five dimensions, under a weaker combinatorial general position requirement.
Reference: [22] <author> P. Erd-os. </author> <title> On a set of distances of n points. </title> <journal> Amer. Math. Monthly, </journal> <volume> 53 </volume> <pages> 248-250, </pages> <year> 1946. </year>
Reference-contexts: Our lower bound is somewhat surprising given known bounds on the maximum number of unit distances among n points in the plane. Spencer et al. [33] and Clarkson et al. [15] prove an upper New Lower Bounds for Hopcroft's Problem 23 bound of O (n 4=3 ). Erd-os <ref> [22] </ref> proves a lower bound of n 1+(1= log log n) , which is achieved by a regular p p n square lattice, and conjectures an upper bound of O (n 1+" ). 6 The fastest known algorithm for detecting incidences between n points and n unit circles runs in time
Reference: [23] <author> J. Erickson. </author> <title> On the relative complexities of some geometric problems. </title> <booktitle> In Proc. 7th Canad. Conf. Comput. Geom., </booktitle> <pages> pages 85-90, </pages> <year> 1995. </year>
Reference-contexts: Any (unbounded) partitioning algorithm that counts pairs of intersecting lines in IR 3 requires time (n 4=3 ) in the worst case. Detecting line intersections in IR 3 is at least as hard as detecting point-line incidences in the plane, at least in the algebraic decision tree model <ref> [23] </ref>. However, the following straightforward partitioning algorithm detects line intersections in only O (n log n) time. If there is an intersection, the trivial algorithm "detects" it. Otherwise, our algorithm arbitrarily splits the lines into two classes of n=2 lines each, say "red" lines and "blue" lines. <p> In the algebraic decision tree model, the cyclic overlap problem is at least as hard as Hopcroft's problem <ref> [23] </ref>. Apparently, however, this problem cannot even be solved by a partitioning algorithm, since the answer might depend on arbitrarily large tuples of segments, arbitrarily far apart. Extending our lower bounds into more traditional models of computation remains an important and very difficult open problem. Acknowledgments.
Reference: [24] <author> J. Erickson and R. Seidel. </author> <title> Better lower bounds on detecting affine and spherical degeneracies. </title> <booktitle> In Proc. 34th Annu. IEEE Sympos. Found. Comput. Sci. (FOCS 93), </booktitle> <pages> pages 528-536, </pages> <year> 1993. </year>
Reference-contexts: Finally, in Section 6, we offer our conclusions and suggest directions for further research. New Lower Bounds for Hopcroft's Problem 3 (a) (b) configuration. (b) The "collapsed" configuration. 2 Quadratic Lower Bounds Erickson and Seidel <ref> [24] </ref> have proven a number of lower bounds on other geometric degeneracy-detection problems, under a model of computation in which only a limited number of geometric primitives are allowed. It is natural to ask whether similar lower bounds can be proven for Hopcroft's problem. <p> We leave the details and further generalizations as exercises for the reader. Of course, none of the sub-quadratic algorithms listed in the introduction follow the models considered in this section. Unlike the degeneracy problems considered in <ref> [24] </ref>, there does not appear to be a small fixed set of primitives that are used by all known algorithms for Hopcroft's New Lower Bounds for Hopcroft's Problem 5 problem. <p> If we allow any primitives of this type, however, it seems unlikely that the techniques developed in <ref> [24] </ref> can be used to derive nontrivial lower bounds, either for Hopcroft's problem or for other range searching problems.
Reference: [25] <author> M. L. Fredman. </author> <title> Lower bounds on the complexity of some optimal data structures. </title> <journal> SIAM J. Comput., </journal> <volume> 10 </volume> <pages> 1-10, </pages> <year> 1981. </year>
Reference-contexts: For related results, see also [6, 12]. These lower bounds hold in the Fredman/Yao semigroup arithmetic model <ref> [25] </ref>. In this model, points are given arbitrary weights from an additive semigroup, and the complexity of the algorithm is given by the number of additions required to calculate the total weight of the points in each range. <p> In Section 4, we generalize this connection to higher dimensions. 3.2 Two Dimensions To derive lower bounds for fl 2 (n; m) and 2 (n; m), we use the following combinatorial result of Erd-os. (See <ref> [25] </ref> or [17, p.112] for proofs.) Lemma 3.2 (Erd-os). For all n and m, there is a set of n points and m lines in the plane with (n + n 2=3 m 2=3 + m) incident pairs. <p> For all n and m, there is a set of n points and m lines in the plane with (n + n 2=3 m 2=3 + m) incident pairs. Thus, I 2 (n; m) = (n + n 2=3 m 2=3 + m). Fredman <ref> [25] </ref> uses Erd-os' construction to prove lower bounds for dynamic range query data structures in the plane. 5 This lower bound is asymptotically tight. The corresponding upper bound was first proven by Szemeredi and Trotter [36].
Reference: [26] <author> G. Hardy and E. Wright. </author> <title> The Theory of Numbers. </title> <publisher> Oxford University Press, </publisher> <address> London, England, 4th edition, </address> <year> 1965. </year> <note> 26 Jeff Erickson </note>
Reference-contexts: We also use (without proof) a number of simple number-theoretic results concerning the Euler totient function (n), the number of positive integers less than or equal to n that are relatively prime to n. We refer the reader to <ref> [26] </ref> for relevant background. Lemma 3.5.
Reference: [27] <author> M. J. Katz and M. Sharir. </author> <title> An expander-based approach to geometric optimization. </title> <booktitle> In Proc. 9th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 198-207, </pages> <year> 1993. </year>
Reference-contexts: 1+(1= log log n) , which is achieved by a regular p p n square lattice, and conjectures an upper bound of O (n 1+" ). 6 The fastest known algorithm for detecting incidences between n points and n unit circles runs in time O (n 4=3 log 2+" n) <ref> [27] </ref>. 5.5 A "Convex" Version of Hopcroft's Problem The following lower bound follows directly from Lemma 3.12 and Theorem 4.6. Theorem 5.9.
Reference: [28] <author> L. Lovasz. </author> <title> Communication complexity: A survey. In Paths, Flows, and VLSI Layout, </title> <booktitle> volume 9 of Algorithms and Combinatorics, </booktitle> <pages> pages 235-265. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: A zero cover can also be interpreted as a partition of the incidence graph induced by P and H into (not necessarily disjoint) complete bipartite subgraphs. Monochromatic covers for 0-1 matrices have been previously used to prove lower bounds for communication complexity problems <ref> [28] </ref>. Typically, however, these results make use of the number of minors in the cover, not the size of the cover as we define it here. 4 Covers of bipartite graphs by complete subgraphs were introduced by Tarjan [37] in the context of switching theory.
Reference: [29] <author> J. Matousek and O. Schwarzkopf. </author> <title> On ray shooting in convex polytopes. </title> <journal> Discrete Comput. Geom., </journal> <volume> 10(2) </volume> <pages> 215-232, </pages> <year> 1993. </year>
Reference-contexts: For the special case n = m, the best upper bound known for this problem in both four and five dimensions is O (n 4=3 log O (1) n), using the half-space emptiness query structure of Matousek and Schwarzkopf <ref> [29] </ref>. In two and three dimensions, this problem can be solved in linear time in the partitioning model, or in O (n log n) time in the algebraic decision tree model, using any optimal convex hull algorithm.
Reference: [30] <author> J. Matousek. </author> <title> Range searching with efficient hierarchical cuttings. </title> <journal> Discrete Comput. Geom., </journal> <volume> 10(2) </volume> <pages> 157-182, </pages> <year> 1993. </year>
Reference-contexts: The running time was improved by Edelsbrunner et al. [18] to O (n 4=3 log 4 n) (expected), then by Agarwal [1] to O (n 4=3 log 1:78 n), then by Chazelle [9] to O (n 4=3 log 1=3 n), and most recently by Matousek <ref> [30] </ref> to n 4=3 2 O (log fl n) . 2 This is currently the fastest algorithm known. <p> For all other values of m between (n 1=d ) and O (n d ), however, the new bound is an improvement over any previously known lower bounds for this problem. The best known upper bound is given by Matousek's algorithm <ref> [30] </ref>. 14 Jeff Erickson 4 Partitioning Algorithms A partition graph is a directed acyclic graph, with one source, called the root, and several sinks, or leaves. Associated with each non-leaf node v is a set R v of query regions, satisfying three conditions. 1. <p> Composing all the point location data structures used by the algorithm in all recursive subproblems gives us the algorithm's partition graph. Many of these algorithms alternate between primal and dual spaces at various levels of recursion <ref> [9, 30] </ref>. The data structures used in primal space give us the primal nodes in the partition graph, and the data structures used in dual space give us the dual nodes. <p> What about the hyperplanes? Many algorithms also use the point location data structures to determine the regions hit by each hyperplane. Algorithms of this type fit into our model perfectly. In particular, Matousek's algorithm <ref> [30] </ref>, which is based on Chazelle's hierarchical cuttings [9] and is the fastest algorithm known, can be modeled this way. Matousek's algorithm and Theorem 4.4 immediately give us the following theorem.
Reference: [31] <author> M. Pellegrini. </author> <title> Incidence and nearest-neighbor problems for lines in 3-space. </title> <booktitle> In Proc. 8th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 130-137, </pages> <year> 1992. </year>
Reference-contexts: Theorem 5.3 also applies to such algorithms. The fastest known deterministic algorithm for detecting or counting line intersections in IR 3 , due to Chazelle et al. [11], runs in time O (n 8=5+" ). Pellegrini <ref> [31] </ref> describes a randomized algorithm with the same running time. 5.3 O*ine Range Searching Chazelle [8] has developed lower bounds for the query time required by a simplex or halfspace range query data structure, given an upper bound on its size.
Reference: [32] <author> R. Seidel. </author> <title> A simple and fast incremental randomized algorithm for computing trapezoidal decompositions and for triangulating polygons. </title> <journal> Comput. Geom. Theory Appl., </journal> <volume> 1 </volume> <pages> 51-64, </pages> <year> 1991. </year>
Reference-contexts: If the current point location data structure locates the hyperplanes too slowly, we may be able to replace it with a different data structure that supports fast hyperplane location, again without increasing the asymptotic running time. We could use, for example, the randomized incremental construction of Seidel <ref> [32] </ref> in the plane, or the hierarchical cuttings data structure of Chazelle [9] in higher dimensions. The modified algorithm can then be described as a partitioning algorithm. Other algorithms construct a point location data structure for the arrangement of the entire set of hyperplanes [16, 20, 9].
Reference: [33] <author> J. Spencer, E. Szemeredi, and W. T. Trotter, Jr. </author> <title> Unit distances in the Euclidean plane. </title> <editor> In B. Bollobas, editor, </editor> <booktitle> Graph Theory and Combinatorics: Proceedings of the Cambridge Combinatorial Conference in Honor of Paul Erd-os, </booktitle> <pages> pages 293-303. </pages> <publisher> Academic Press, </publisher> <year> 1984. </year>
Reference-contexts: We can easily verify that altering the definition to use point-unit circle duality does not change our lower bound. Our lower bound is somewhat surprising given known bounds on the maximum number of unit distances among n points in the plane. Spencer et al. <ref> [33] </ref> and Clarkson et al. [15] prove an upper New Lower Bounds for Hopcroft's Problem 23 bound of O (n 4=3 ).
Reference: [34] <author> J. M. Steele and A. C. Yao. </author> <title> Lower bounds for algebraic decision trees. </title> <journal> J. Algorithms, </journal> <volume> 3 </volume> <pages> 1-8, </pages> <year> 1982. </year>
Reference-contexts: The only previously known lower bound is (n log m+ m log n), in the algebraic decision tree and algebraic computation tree models, by reduction from the problem of detecting an intersection between two sets of real numbers <ref> [34, 3] </ref>. In this paper, we establish new lower bounds on the complexity of Hopcroft's problem.
Reference: [35] <author> J. Stolfi. </author> <title> Oriented Projective Geometry: A Framework for Geometric Computations. </title> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1991. </year>
Reference-contexts: Otherwise, see [17] or <ref> [35] </ref>. 2 Jeff Erickson the regions or how they depend on the input. We give a more formal definition of partitioning algorithms in Section 4. <p> In a more geometric setting, maps points and lines in the plane, represented in homogeneous coordinates, to points and hyperplanes in IR 5 , also represented in homogeneous coordinates <ref> [35] </ref>. For any point p and line ` in the plane, the point (p) is incident to the hyperplane (`) if and only if p is incident to `; otherwise, (p) lies above (`). <p> Thus, separating the red and blue lines requires only linear time. To separate every pair of lines in each class, the algorithm then proceeds recursively. Typically, algorithms for problems involving lines in IR 3 map the lines to points and hyperplanes in IR 5 using Plucker coordinates <ref> [35] </ref>. Thus, the line intersection problem is just a special case of Hopcroft's problem in IR 5 . Any partitioning algorithm that uses this approach can be forced to take time (n 4=3 ), even to solve the decision version of this problem.
Reference: [36] <author> E. Szemeredi and W. T. Trotter, Jr. </author> <title> Extremal problems in discrete geometry. </title> <journal> Combinatorica, </journal> <volume> 3 </volume> <pages> 381-392, </pages> <year> 1983. </year>
Reference-contexts: Fredman [25] uses Erd-os' construction to prove lower bounds for dynamic range query data structures in the plane. 5 This lower bound is asymptotically tight. The corresponding upper bound was first proven by Szemeredi and Trotter <ref> [36] </ref>.
Reference: [37] <author> T. G. Tarjan. </author> <title> Complexity of lattice-configurations. </title> <journal> Studia Sci. Math. Hungar., </journal> <volume> 10 </volume> <pages> 203-211, </pages> <year> 1975. </year>
Reference-contexts: Typically, however, these results make use of the number of minors in the cover, not the size of the cover as we define it here. 4 Covers of bipartite graphs by complete subgraphs were introduced by Tarjan <ref> [37] </ref> in the context of switching theory. Tuza [38], and independently Chung et al. [14], showed that every n fi m bipartite graph has such a cover of size O (nm= log (max (m; n))) and that this bound is tight in the worst case, up to constant factors.
Reference: [38] <author> Z. Tuza. </author> <title> Covering of graphs by complete bipartite subgraphs; complexity of 0-1 matrices. </title> <journal> Combinatorica, </journal> <volume> 4 </volume> <pages> 111-116, </pages> <year> 1984. </year>
Reference-contexts: Typically, however, these results make use of the number of minors in the cover, not the size of the cover as we define it here. 4 Covers of bipartite graphs by complete subgraphs were introduced by Tarjan [37] in the context of switching theory. Tuza <ref> [38] </ref>, and independently Chung et al. [14], showed that every n fi m bipartite graph has such a cover of size O (nm= log (max (m; n))) and that this bound is tight in the worst case, up to constant factors.
References-found: 38

