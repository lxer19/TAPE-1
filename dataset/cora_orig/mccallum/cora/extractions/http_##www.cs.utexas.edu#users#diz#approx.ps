URL: http://www.cs.utexas.edu/users/diz/approx.ps
Refering-URL: http://www.cs.utexas.edu/users/diz/pubs.html
Root-URL: 
Title: ON UNAPPROXIMABLE VERSIONS OF NP-COMPLETE PROBLEMS  
Author: DAVID ZUCKERMAN 
Keyword: Key words. NP-complete, unapproximable, randomized reduction, clique, counting problems,  
Note: permanent, 2SAT AMS subject classifications. 68Q15, 68Q25, 68Q99  
Abstract: We prove that all of Karp's 21 original NP -complete problems have a version that's hard to approximate. These versions are obtained from the original problems by adding essentially the same, simple constraint. We further show that these problems are absurdly hard to approximate. In fact, no polynomial-time algorithm can even approximate log (k) of the magnitude of these problems to within any constant factor, where log (k) denotes the logarithm iterated k times, unless N P is recognized by slightly superpolynomial randomized machines. We use the same technique to improve the constant * such that MAX CLIQUE is hard to approximate to within a factor of n * . Finally, we show that it is even harder to approximate two counting problems: counting the number of satisfying assignments to a monotone 2-SAT formula and computing the permanent of -1,0,1 matrices. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Ajtai, J. Komlos, and E. Szemeredi, </author> <title> Deterministic Simulation in Logspace, </title> <booktitle> 19th Annual ACM Symposium on Theory of Computing, </booktitle> <year> 1987, </year> <pages> pp. 132-140. </pages>
Reference-contexts: , a condition which as far as we know does not imply N ~ P = ~ P . 3 This difference also manifests itself in the derandomization: more work is needed to derandomize the randomized graph product construction [2] than the basic tool used to derandomize the proof-theoretic construction <ref> [1] </ref>. Implications for Counting Problems. We further show that under the same assumption that N P k 6= ZP P k , log (k+1) of the number of satisfying assignments to a monotone 2-SAT formula is hard to approximate to within any constant factor.
Reference: [2] <author> N. Alon, U. Feige, A. Wigderson, and D. Zuckerman, </author> <title> Derandomized graph products, Computational Complexity, </title> <note> to appear. </note>
Reference-contexts: log !(G) is hard to approximate unless NP = ZP P , a condition which as far as we know does not imply N ~ P = ~ P . 3 This difference also manifests itself in the derandomization: more work is needed to derandomize the randomized graph product construction <ref> [2] </ref> than the basic tool used to derandomize the proof-theoretic construction [1]. Implications for Counting Problems.
Reference: [3] <author> S. Arora, C. Lund, R. Motwani, M. Sudan, M. Szegedy, </author> <title> Proof Verification and Intractibility of Approximation Problems, </title> <booktitle> 33rd Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1992, </year> <pages> pp. 14-23. </pages>
Reference-contexts: This was based on the proof that MIP=NEXP [5]. Recently, there have been several improvements, culminating in the result that approximating !(G) to within a factor of n 1=4o (1) is N P -complete <ref> [4, 3, 7] </ref>. A New Role for Old Reductions. It is natural and important to identify other N P -complete problems that are hard to approximate. In the original theory of N P -completeness, polynomial-time reductions were used. <p> Here jxj denotes the length of x. Thus the algorithm can distinguish between x and y, jxj = jyj = n, if g (x) a (n)g (y) or g (y) a (n)g (x). 2 Our proofs closely follow the proofs of <ref> [11, 4, 3] </ref>, building on the work of [5]. First some definitions from [4]: A verifier is a probabilistic polynomial-time probabilistic Turing Machine M given access to the input x, random bits y, and a proof . <p> Definition 2.3. A language L is in the complexity class P CP (r (n); c (n)) iff there is an (r (n); c (n))-restricted verifier such that x 2 L ) (9)P r y [M (x; y)] = 1 Arora et.al. <ref> [3] </ref> give the following improvement of [5]: Theorem 2.4. [3] N P = P CP (O (log n); O (1)). Using this, they follow [11] and construct a graph G x which has a large clique iff x 2 L. <p> A language L is in the complexity class P CP (r (n); c (n)) iff there is an (r (n); c (n))-restricted verifier such that x 2 L ) (9)P r y [M (x; y)] = 1 Arora et.al. <ref> [3] </ref> give the following improvement of [5]: Theorem 2.4. [3] N P = P CP (O (log n); O (1)). Using this, they follow [11] and construct a graph G x which has a large clique iff x 2 L. <p> Otherwise, we will get b (n) 2 terms instead of a (n) terms. Our definition is also like the ones used in <ref> [11, 3] </ref>. 4 them. A transcript is basically a set of queries to locations of the proof and the bits that are found in these locations. Two transcripts are consistent if there is one proof that can correspond to both transcripts. <p> Thus it is natural to use pseudorandom strings that efficiently amplify the success probability of an RP (or coRP) algorithm. Indeed, this was the idea used in [22] to show that approximating log ! is hard. Arora, et.al. <ref> [3] </ref> later used this idea to achieve their result as well. But since we will cycle through all possibilities of the random seeds, the pseudorandom strings do not have to be constructible in the usual sense. <p> Lemma 2.12 shows that these conclusions are equivalent. Similarly, we improve the constant * in the n * of the MAX CLIQUE unapprox-imability results of <ref> [3] </ref>: Theorem 2.14. Let c be a constant such that some N P -complete language is in P CP (O (log n); c) (which exists by Theorem 2.4).
Reference: [4] <author> S. Arora and S. Safra, </author> <title> Approximating Clique is N P -Complete, </title> <booktitle> 33rd Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1992, </year> <pages> pp. 2-13. </pages>
Reference-contexts: This was based on the proof that MIP=NEXP [5]. Recently, there have been several improvements, culminating in the result that approximating !(G) to within a factor of n 1=4o (1) is N P -complete <ref> [4, 3, 7] </ref>. A New Role for Old Reductions. It is natural and important to identify other N P -complete problems that are hard to approximate. In the original theory of N P -completeness, polynomial-time reductions were used. <p> Here jxj denotes the length of x. Thus the algorithm can distinguish between x and y, jxj = jyj = n, if g (x) a (n)g (y) or g (y) a (n)g (x). 2 Our proofs closely follow the proofs of <ref> [11, 4, 3] </ref>, building on the work of [5]. First some definitions from [4]: A verifier is a probabilistic polynomial-time probabilistic Turing Machine M given access to the input x, random bits y, and a proof . <p> Thus the algorithm can distinguish between x and y, jxj = jyj = n, if g (x) a (n)g (y) or g (y) a (n)g (x). 2 Our proofs closely follow the proofs of [11, 4, 3], building on the work of [5]. First some definitions from <ref> [4] </ref>: A verifier is a probabilistic polynomial-time probabilistic Turing Machine M given access to the input x, random bits y, and a proof . The verifier's goal is to decide whether is a valid proof that x is in some language L.
Reference: [5] <author> L. Babai, L. Fortnow, and C. Lund, </author> <title> Non-Deterministic Exponential Time Has Two-Prover Interactive Protocols, Computational Complexity, </title> <booktitle> 1 (1991), </booktitle> <pages> pp. 16-25. </pages>
Reference-contexts: This was based on the proof that MIP=NEXP <ref> [5] </ref>. Recently, there have been several improvements, culminating in the result that approximating !(G) to within a factor of n 1=4o (1) is N P -complete [4, 3, 7]. A New Role for Old Reductions. <p> Here jxj denotes the length of x. Thus the algorithm can distinguish between x and y, jxj = jyj = n, if g (x) a (n)g (y) or g (y) a (n)g (x). 2 Our proofs closely follow the proofs of [11, 4, 3], building on the work of <ref> [5] </ref>. First some definitions from [4]: A verifier is a probabilistic polynomial-time probabilistic Turing Machine M given access to the input x, random bits y, and a proof . The verifier's goal is to decide whether is a valid proof that x is in some language L. <p> Definition 2.3. A language L is in the complexity class P CP (r (n); c (n)) iff there is an (r (n); c (n))-restricted verifier such that x 2 L ) (9)P r y [M (x; y)] = 1 Arora et.al. [3] give the following improvement of <ref> [5] </ref>: Theorem 2.4. [3] N P = P CP (O (log n); O (1)). Using this, they follow [11] and construct a graph G x which has a large clique iff x 2 L.
Reference: [6] <author> M. Bellare, S. Goldwasser, C. Lund, and A. Russell, </author> <title> Efficient probabilistically checkable proofs and applications to approximation, </title> <booktitle> 25th Annual ACM Symposium on Theory of Computing, </booktitle> <year> 1993, </year> <pages> pp. 294-304. </pages>
Reference-contexts: Recently much effort has been devoted towards improving the constant (see e.g. <ref> [6, 7] </ref>), and they all use this lemma or an extension of it. We point out that similar results may be obtained by using the randomized graph product method of Berman and Schnitger [8].
Reference: [7] <author> M. Bellare and M. Sudan, </author> <title> Improved Non-approximability Results, </title> <booktitle> 26th Annual ACM Symposium on Theory of Computing, </booktitle> <year> 1994, </year> <pages> pp. 184-193. 11 </pages>
Reference-contexts: This was based on the proof that MIP=NEXP [5]. Recently, there have been several improvements, culminating in the result that approximating !(G) to within a factor of n 1=4o (1) is N P -complete <ref> [4, 3, 7] </ref>. A New Role for Old Reductions. It is natural and important to identify other N P -complete problems that are hard to approximate. In the original theory of N P -completeness, polynomial-time reductions were used. <p> Recently much effort has been devoted towards improving the constant (see e.g. <ref> [6, 7] </ref>), and they all use this lemma or an extension of it. We point out that similar results may be obtained by using the randomized graph product method of Berman and Schnitger [8].
Reference: [8] <author> P. Berman and G. Schnitger, </author> <title> On the Complexity of Approximating the Independent Set Prob--lem, </title> <booktitle> Information and Computation 96 (1992), </booktitle> <pages> pp. 77-94. </pages>
Reference-contexts: Recently much effort has been devoted towards improving the constant (see e.g. [6, 7]), and they all use this lemma or an extension of it. We point out that similar results may be obtained by using the randomized graph product method of Berman and Schnitger <ref> [8] </ref>. However, such results would be under the stronger assumption that N P k 6= BP P k . The reason for this is that we look at the proof-theoretic construction of the graphs in question, while Berman and Schnitger use a straight reduction.
Reference: [9] <author> A. Cohen and A. Wigderson, Dispersers, </author> <title> Deterministic Amplification, and Weak Random Sources, </title> <booktitle> 30th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1989, </year> <pages> pp. 14-19. </pages>
Reference-contexts: An (R; r; d)-amplification scheme defines a pseudo-random generator that takes as input an R-bit string z and outputs the d r-bit neighbors of z. A good amplification scheme has been called a disperser <ref> [9] </ref>: Definition 2.9. An (m; n; d; a; b)-disperser is a bipartite graph with m nodes on the left side, each with degree d, and n nodes on the right side, such that every subset of a nodes on the left side has at least b neighbors on the right.
Reference: [10] <author> S.A. Cook, </author> <title> The Complexity of Theorem-Proving Procedures, </title> <booktitle> 3rd Annual ACM Symposium on Theory of Computing, </booktitle> <year> 1971, </year> <pages> pp. 151-158. </pages>
Reference-contexts: 1. Introduction. Previous Work. The theory of N P -completeness was developed in order to explain why certain computational problems appeared intractable <ref> [10, 14, 12] </ref>. Yet certain optimization problems, such as MAX KNAPSACK, while being N P -complete to compute exactly, can be approximated very accurately. It is therefore vital to ascertain how difficult various optimization problems are to approximate. One problem that eluded attempts at accurate approximation is MAX CLIQUE.
Reference: [11] <author> U. Feige, S. Goldwasser, L. Lovasz, S. Safra, M. Szegedy, </author> <title> Approximating Clique is Almost N P - Complete, </title> <booktitle> 32nd Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1991, </year> <pages> pp. 2-12. </pages>
Reference-contexts: One problem that eluded attempts at accurate approximation is MAX CLIQUE. This is the problem of finding !(G), the size of a largest clique in the graph G. There was no explanation for this until Feige, et.al. <ref> [11] </ref> showed that for all * &gt; 0 no polynomial-time algorithm can approximate !(G) to within a factor of 2 (log n) 1* , unless N ~ P = ~ P , where ~ P denotes quasi-polynomial time, or T IM E (2 polylog ). <p> Here jxj denotes the length of x. Thus the algorithm can distinguish between x and y, jxj = jyj = n, if g (x) a (n)g (y) or g (y) a (n)g (x). 2 Our proofs closely follow the proofs of <ref> [11, 4, 3] </ref>, building on the work of [5]. First some definitions from [4]: A verifier is a probabilistic polynomial-time probabilistic Turing Machine M given access to the input x, random bits y, and a proof . <p> Using this, they follow <ref> [11] </ref> and construct a graph G x which has a large clique iff x 2 L. <p> Otherwise, we will get b (n) 2 terms instead of a (n) terms. Our definition is also like the ones used in <ref> [11, 3] </ref>. 4 them. A transcript is basically a set of queries to locations of the proof and the bits that are found in these locations. Two transcripts are consistent if there is one proof that can correspond to both transcripts. <p> A transcript is basically a set of queries to locations of the proof and the bits that are found in these locations. Two transcripts are consistent if there is one proof that can correspond to both transcripts. Definition 2.5. <ref> [11] </ref> We say &lt; y; q 1 ; a 1 ; : : : ; q c ; a c &gt; is an (r; c)-transcript for verifier M on x if jyj = r, and on input x and random string y, for every i M queries bit location q i <p> The transcript is accepting if on input x, random string y, and history of communication (questions and answers) &lt; q 1 ; a 1 ; : : : ; q c ; a c &gt;, M accepts x. Definition 2.6. <ref> [11] </ref> We say that two transcripts &lt; y; q 1 ; a 1 ; : : : ; q c ; a c &gt; and &lt; ^y; ^q 1 ; ^a 1 ; : : : ; ^q c ; ^a c &gt; are consistent if for every i, q i <p> The vertices of G x are all accepting (r (n); c (n))-transcripts of M on x, and two nodes are connected iff the corresponding transcripts are consistent. Thus G x has at most 2 r (n)+c (n) vertices. It is also not hard to see: Lemma 2.7. <ref> [11] </ref> !(G x ) = max P r y [M (x; y)] 2 r (n) . In other words, !(G x ) is the maximum over all proofs of the number of random strings on which M accepts x.
Reference: [12] <author> M.R. Garey and D.S. Johnson, </author> <title> Computers and Intractability: A Guide to the Theory of N P - Completeness. W.H. </title> <publisher> Freeman, </publisher> <year> 1979. </year>
Reference-contexts: 1. Introduction. Previous Work. The theory of N P -completeness was developed in order to explain why certain computational problems appeared intractable <ref> [10, 14, 12] </ref>. Yet certain optimization problems, such as MAX KNAPSACK, while being N P -complete to compute exactly, can be approximated very accurately. It is therefore vital to ascertain how difficult various optimization problems are to approximate. One problem that eluded attempts at accurate approximation is MAX CLIQUE. <p> There are some reductions, however, for which the reductions in [14] will not work. For example, Karp reduces CLIQUE to VERTEX COVER by taking complements. This would yield a minimization problem. Instead, we use the reduction given in <ref> [12] </ref> which goes directly from 3SAT, and we can let S be the subset of vertices which Garey and Johnson call u i . To show the result for HAMILTONIAN CIRCUIT requires some care. We modify the reduction given in [12] reducing VERTEX COVER to HAMILTONIAN CIRCUIT. <p> Instead, we use the reduction given in <ref> [12] </ref> which goes directly from 3SAT, and we can let S be the subset of vertices which Garey and Johnson call u i . To show the result for HAMILTONIAN CIRCUIT requires some care. We modify the reduction given in [12] reducing VERTEX COVER to HAMILTONIAN CIRCUIT. We briefly outline their reduction. Say we have an instance of VERTEX COVER: a graph G = (V; E) and an integer k. They construct G 0 = (V 0 ; E 0 ) as follows. <p> Let S be the edges fa i ; a j g of this clique A. Since there is always a vertex cover of size n in G, there will always be a Hamiltonian circuit C in G 0 and hence in G 00 . The construction of <ref> [12] </ref> ensures that C can be found efficiently. The input to CONSTRAINED MAX HAMILTONIAN CIRCUIT is G 00 , S, and C. We show that the output of CONSTRAINED MAX HAMILTONIAN CIRCUIT is ff, the size of a maximum independent set in G. <p> We use the fact that the size of a minimum vertex cover is n ff. Since there is a vertex cover of size n ff in G, there is a Hamiltonian circuit in G 00 which passes through ff edges in S. Namely this is the Hamiltonian circuit in <ref> [12] </ref> with a nff replaced by the path a nff ; a nff+1 ; : : : ; a n . Note that we can make this replacement since each a i is connected to the same vertices outside A. <p> Since each a i has the same adjacency list outside A, by contracting these edges we see that there is a Hamiltonian circuit passing through n ff 1 selector vertices in the original construction of <ref> [12] </ref>, and hence there is a vertex cover of size n ff 1, a contradiction. 4. Two Unapproximable Counting Problems.
Reference: [13] <author> M. Jerrum and U. Vazirani, </author> <title> A Mildly Exponential Approximation Algorithm for the Permanent, </title> <booktitle> 33rd Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1992, </year> <pages> pp. 320-326. </pages>
Reference-contexts: We can assume the matrix has positive permanent, because conceivably the problem of deciding if the permanent is 0 is N P -hard, which would make the corollary uninteresting. This result should be contrasted with the subexponential algorithm to approximate the permanent of 0,1-matrices <ref> [13] </ref>. 2. The Iterated Log of Max Clique is Hard to Approximate. In this section we show that it is hard to approximate any iterated logarithm of the size of the maximum clique. We first define Definition 2.1.
Reference: [14] <author> R.M. Karp, </author> <title> Reducibility Among Combinatorial Problems, in Complexity of Computer Computations, R.E. </title> <editor> Miller and J.W. Thatcher, eds., </editor> <year> 1972, </year> <pages> pp. 85-103. </pages>
Reference-contexts: 1. Introduction. Previous Work. The theory of N P -completeness was developed in order to explain why certain computational problems appeared intractable <ref> [10, 14, 12] </ref>. Yet certain optimization problems, such as MAX KNAPSACK, while being N P -complete to compute exactly, can be approximated very accurately. It is therefore vital to ascertain how difficult various optimization problems are to approximate. One problem that eluded attempts at accurate approximation is MAX CLIQUE. <p> We show that Karp's original reductions can be modified to have this general form, and hence the original 21 N P -complete problems presented in <ref> [14] </ref> all have a version that's hard to approximate. This gives evidence that all N P -complete problems have a version that's hard to approximate. The Small Jump to Unapproximability. <p> Proof. The proof is contained in the proof of Theorem 4.1. Proof of Theorem 3.1. We basically use the sequence of reductions given by Karp <ref> [14] </ref> that the unconstrained versions of the above problems are N P -complete. Lemma 3.3 tells us that the constrained version of 2SAT is hard to approximate. Moreover, for 2SAT, we can easily compute a satisfying assignment if one exists. <p> Lemma 3.3 tells us that the constrained version of 2SAT is hard to approximate. Moreover, for 2SAT, we can easily compute a satisfying assignment if one exists. Next, for most of the problems above, we can look at the reductions in <ref> [14] </ref> and verify that they satisfy the conditions of Lemma 3.2. There are some reductions, however, for which the reductions in [14] will not work. For example, Karp reduces CLIQUE to VERTEX COVER by taking complements. This would yield a minimization problem. <p> Moreover, for 2SAT, we can easily compute a satisfying assignment if one exists. Next, for most of the problems above, we can look at the reductions in <ref> [14] </ref> and verify that they satisfy the conditions of Lemma 3.2. There are some reductions, however, for which the reductions in [14] will not work. For example, Karp reduces CLIQUE to VERTEX COVER by taking complements. This would yield a minimization problem.
Reference: [15] <author> R.M. Karp, M. Luby, and N. </author> <title> Madras, Monte-Carlo Approximation Algorithms for Enumeration Problems, </title> <editor> J. </editor> <booktitle> of Algorithms, 10(3) (1989), </booktitle> <pages> pp. 429-448. </pages>
Reference-contexts: That this is hard to approximate may seem surprising, because finding a satisfying assignment is trivial. In the case of a DNF-formula, where finding a satisfying assignment is also easy, approximating the number of satisfying assignments is in randomized polynomial-time <ref> [15] </ref>. As a corollary, we use Valiant's reduction [21] to observe that approximating log (k+1) of the permanent of a matrix with entries in f1; 0; 1g is hard under the same assumption as above.
Reference: [16] <author> C. Lund and M. Yannakakis, </author> <title> On the Hardness of Approximating Minimization Problems, </title> <booktitle> 25th Annual ACM Symposium on Theory of Computing, </booktitle> <year> 1993, </year> <pages> pp. 286-293. </pages>
Reference-contexts: Most of this research was done while the author was supported by an NSF Postdoctoral Fellowship at MIT. At UT Austin, the author was partially supported by NSF NYI Grant No. CCR-9457799. 1 <ref> [16] </ref> used an approximation-preserving reduction to show the intractability of approx-imating CHROMATIC NUMBER. Here we show that the reductions can have a much more general form and still yield unapproximability results.
Reference: [17] <author> A. Panconesi and D. Ranjan, </author> <title> Quantifiers and Approximation, </title> <booktitle> 22nd Annual ACM Symposium on Theory of Computing, </booktitle> <year> 1990, </year> <pages> pp. 446-456. </pages>
Reference-contexts: In the original theory of N P -completeness, polynomial-time reductions were used. Yet these reductions might not preserve the quality of an approximation well, so researchers focused on reductions that preserved the quality of approximation very closely <ref> [18, 17] </ref>. Using such reductions, Panconesi and Ranjan [17] defined a class RMAX (2) of optimization problems, of which MAX CLIQUE is one natural complete problem. The intractability of approximating MAX CLIQUE implies that the other RMAX (2)- complete problems are intractable to approximate. <p> In the original theory of N P -completeness, polynomial-time reductions were used. Yet these reductions might not preserve the quality of an approximation well, so researchers focused on reductions that preserved the quality of approximation very closely [18, 17]. Using such reductions, Panconesi and Ranjan <ref> [17] </ref> defined a class RMAX (2) of optimization problems, of which MAX CLIQUE is one natural complete problem. The intractability of approximating MAX CLIQUE implies that the other RMAX (2)- complete problems are intractable to approximate. <p> Unapproximable Versions of N P -Complete Problems. We now modify Karp's list of 21 N P -complete problems to obtain versions that are hard to approximate. Problems 4 and 11 had previously been shown to be as difficult to approximate as MAX SAT <ref> [17] </ref>. Theorem 3.1. For each of the following maximization problems A, there exists a constant * &gt; 0 such that A cannot be approximated to within a factor n * in polynomial time unless P = N P . <p> Proof. The lemma follows because fi 0 = fi and jx 0 j = poly (jxj). We can now prove the theorem. We first observe as in <ref> [17] </ref> that approximating MAX 2-ANLSAT is as hard as approximating MAX CLIQUE. 9 Lemma 3.3. [17] For any functions f; g, approximating f (M AXCLIQU E) to within a factor g (n) is polynomial time reducible to approximating f (MAX 2-ANLSAT) to within a factor g (n). Proof. <p> Proof. The lemma follows because fi 0 = fi and jx 0 j = poly (jxj). We can now prove the theorem. We first observe as in <ref> [17] </ref> that approximating MAX 2-ANLSAT is as hard as approximating MAX CLIQUE. 9 Lemma 3.3. [17] For any functions f; g, approximating f (M AXCLIQU E) to within a factor g (n) is polynomial time reducible to approximating f (MAX 2-ANLSAT) to within a factor g (n). Proof. The proof is contained in the proof of Theorem 4.1. Proof of Theorem 3.1. <p> If for some constant a approximating log (k+1) of the number of satisfying assignments to a monotone 2CNF to within a factor a is in F ZP P k , then N P k = ZP P k . Proof. The proof extends the reduction in <ref> [17] </ref>.
Reference: [18] <author> C.H. Papadimitriou and M. Yannakakis, </author> <title> Optimization, Approximation, and Complexity Classes, </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 43 (1991), </volume> <pages> pp. 425-440. </pages>
Reference-contexts: In the original theory of N P -completeness, polynomial-time reductions were used. Yet these reductions might not preserve the quality of an approximation well, so researchers focused on reductions that preserved the quality of approximation very closely <ref> [18, 17] </ref>. Using such reductions, Panconesi and Ranjan [17] defined a class RMAX (2) of optimization problems, of which MAX CLIQUE is one natural complete problem. The intractability of approximating MAX CLIQUE implies that the other RMAX (2)- complete problems are intractable to approximate.
Reference: [19] <author> M. Santha, </author> <title> On Using Deterministic Functions to Reduce Randomness in Probabilistic Algorithms, </title> <journal> Information and Computation, </journal> <volume> 74 (1987), </volume> <pages> pp. 241-249. </pages>
Reference-contexts: We pick an (R; r; d)-amplification scheme uniformly at random by choosing independently, for each u 2 f0; 1g R , d uniformly random elements from f0; 1g r as the neighbors of u. Santha <ref> [19] </ref> and Sipser [20] have shown that a random amplification scheme is a disperser. In order to get the optimal * in the n * results we use an extremely minor modification of their arguments: Lemma 2.10.
Reference: [20] <author> M. Sipser, Expanders, </author> <title> Randomness, or Time versus Space, </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 36 (1988), </volume> <pages> pp. 379-383. </pages>
Reference-contexts: We pick an (R; r; d)-amplification scheme uniformly at random by choosing independently, for each u 2 f0; 1g R , d uniformly random elements from f0; 1g r as the neighbors of u. Santha [19] and Sipser <ref> [20] </ref> have shown that a random amplification scheme is a disperser. In order to get the optimal * in the n * results we use an extremely minor modification of their arguments: Lemma 2.10. <p> The probability that a uniformly random (R; r; R + 2)-amplification scheme is a (2 R ; 2 r ; R + 2; 2 r ; 2 r1 )-disperser is greater than 1 2 2 r . Proof. We basically follow <ref> [20] </ref>. For S f0; 1g R , T f0; 1g r , let A S;T be the event that all neighbors of S are in T .
Reference: [21] <author> L.G. Valiant, </author> <title> The Complexity of Computing the Permanent, </title> <booktitle> Theoretical Computer Science, 8 (1979), </booktitle> <pages> pp. 189-201. </pages>
Reference-contexts: That this is hard to approximate may seem surprising, because finding a satisfying assignment is trivial. In the case of a DNF-formula, where finding a satisfying assignment is also easy, approximating the number of satisfying assignments is in randomized polynomial-time [15]. As a corollary, we use Valiant's reduction <ref> [21] </ref> to observe that approximating log (k+1) of the permanent of a matrix with entries in f1; 0; 1g is hard under the same assumption as above. <p> Thus if lg N can be approximated to within a factor a, then ! can be approximated to within a factor a lg n. Observing that the additional lg n factor is negligible in the proof of Theorem 2.13 completes the proof. As a corollary, using Valiant's reduction <ref> [21] </ref> we can show that computing the permanent of matrices with entries in f1; 0; 1g is hard. Corollary 4.2. <p> If for some constant a approximating log (k+1) of the permanent of a matrix having positive permanent and entries in f1; 0; 1g to within a factor a is in F ZP P k , then N P k = ZP P k . Proof. Valiant <ref> [21] </ref> showed that the number of satisfying assignments to a 3CNF formula, and hence 2CNF formula, can be expressed as the permanent of a -1,0,1 matrix. Acknowledgements.
Reference: [22] <author> D. Zuckerman, </author> <title> Simulating BPP Using a General Weak Random Source, </title> <journal> Algorithmica, </journal> <note> to appear. Preliminary version in the 32nd Annual IEEE Symposium on Foundations of Computer Science, </note> <year> 1991, </year> <pages> pp. 79-89. 12 </pages>
Reference-contexts: The proof also does not rely on the fact that the iterated logarithm may become 0 (or negative); we can assume the iterated logarithm is at least 1. This result extends the result in <ref> [22] </ref> that the logarithm of !(G) is hard to approximate to within any constant factor, unless N ~ P = ~ P . 1 In order to state our results precisely, define log (k) n = log log : : : log k p e;k (n) = 2 2 : : <p> We therefore need only deal with the error in the "easy" direction, while Berman and Schnitger need to worry about the error in both directions. 1 This does not entirely improve upon <ref> [22] </ref>; here we show that log !(G) is hard to approximate unless NP = ZP P , a condition which as far as we know does not imply N ~ P = ~ P . 3 This difference also manifests itself in the derandomization: more work is needed to derandomize the <p> Thus it is natural to use pseudorandom strings that efficiently amplify the success probability of an RP (or coRP) algorithm. Indeed, this was the idea used in <ref> [22] </ref> to show that approximating log ! is hard. Arora, et.al. [3] later used this idea to achieve their result as well. But since we will cycle through all possibilities of the random seeds, the pseudorandom strings do not have to be constructible in the usual sense.
References-found: 22

