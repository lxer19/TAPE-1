URL: http://www.cs.toronto.edu/~greiner/PAPERS/comp-tr-AIJ.ps
Refering-URL: http://www.cs.toronto.edu/~greiner/PAPERS/
Root-URL: 
Email: greiner@scr.siemens.com  
Title: The Complexity of Theory Revision  
Author: Russell Greiner 
Keyword: theory revision, computational learning theory, inductive logic programming, agnostic learning  
Date: July 30, 1996  
Address: Princeton, NJ 08540-6632  
Affiliation: Siemens Corporate Research  
Abstract: A knowledge-based system uses its database (a.k.a. its "theory") to produce answers to the queries it receives. Unfortunately, these answers may be incorrect if the underlying theory is faulty. Standard "theory revision" systems use a given set of "labeled queries" (each a query paired with its correct answer) to transform the given theory, by adding and/or deleting either rules and/or antecedents, into a related theory that is as accurate as possible. After formally defining the theory revision task, this paper provides both sample and computational complexity bounds for this process. It first specifies the number of labeled queries necessary to identify a revised theory whose error is close to minimal with high probability. It then considers the computational complexity of finding this best theory, and proves that, unless P = N P , no polynomial time algorithm can identify this near-optimal revision, even given the exact distribution of queries, except in the most trivial of situations. It also shows that, except in such trivial situations, no polynomial-time algorithm can produce a theory whose error is even close to (i.e., within a particular polynomial factor of) optimal. These results suggest reasons why theory revision can be more effective than learning from scratch, and also justify many aspects of the standard theory revision systems, including the practice of hill-climbing to a locally-optimal theory, based on a given set of labeled queries. fl This paper extends the short article that appeared in the Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence (IJCAI95), Montreal, August 1995. y I gratefully acknowledge receiving helpful comments from Edoardo Amaldi, Mukesh Dalal, George Drastal, Adam Grove, Tom Hancock, Sheila McIlraith, Roni Khardon, Dan Roth and especially the very thorough comments from the anonymous referees. 
Abstract-found: 1
Intro-found: 1
Reference: [AGM85] <author> Carlos E. Alchourron, Peter Gardenfors, and David Makinson. </author> <title> On the logic of theory change: Partial meet contraction and revision functions. </title> <journal> Journal of Symbolic Logic, </journal> <volume> 50 </volume> <pages> 510-30, </pages> <year> 1985. </year>
Reference-contexts: For example, many Bayesian systems use such observations to update their representations, often by adjusting the (continuous) parameters in a Dirichlet distribution within a given belief net structure [Hec95]. We, however, are making discrete changes to the structure of the Horn theory. Similarly, belief revision systems <ref> [AGM85, Dal88, Gar88, KM91] </ref> take as input an initial theory T 0 and a new assertion hq; +i (resp., new retraction hr; i) and return a new consistent theory T 0 that entails q (resp., does not entail r) but otherwise is "close" to T 0 [Dal88].
Reference: [BCH90] <author> E. Boros, Y. Crama, and P.L. Hammer. </author> <title> Polynomial-time inference of all valid implications for horn and related formulae. </title> <journal> Annals of Mathematics and Artificial Intelligence, </journal> <volume> 1 </volume> <pages> 21-32, </pages> <year> 1990. </year>
Reference-contexts: Another delete-rule, t DR d removes the atomic "d." clause. The t DA h:f;g; g delete-antecedent transformation removes propositional case <ref> [BCH90] </ref>. The Complexity of Theory Revision 9 the "g" antecedent from the "h :- f, g." rule; an alternative delete-antecedent transformation, t DA h:f;g; f , removes the "f" from that rule. Of course, yet other delete-antecedent transformations modify other rules.
Reference: [BE89] <author> Alex Borgida and David Etherington. </author> <title> Hierarchical knowledge bases and efficient disjunctive reasoning. </title> <booktitle> In Proceedings of KR-89, </booktitle> <pages> pages 33-43, </pages> <address> Toronto, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: More significantly, we present situations where the computational task is not just intractable, but is not even approximatable. Second, many works on "approximations" <ref> [BE89, SK91, DE92, GS92] </ref> and "structural identification" [DP92] seek a theory, of a specified syntactic form, that is semantically close to an explicitly given theory T target (i.e., which entails essentially the same set of propositions that T target entails).
Reference: [BEHW89] <author> Anselm Blumer, Andrzei Ehrenfeucht, David Haussler, and Manfred Warmuth. </author> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 36(4) </volume> <pages> 929-965, </pages> <month> October </month> <year> 1989. </year> <title> The Complexity of Theory Revision 38 </title>
Reference-contexts: Lower Bounds: To obtain a lower bound on the number of samples required to be at least 1 ffi confident of finding a theory within * of optimal, we can use Theorem 2 (Sample Complexity <ref> [BEHW89, EH89] </ref>) Given a class of theories T and values *; ffi &gt; 0, let T fl 2 T be any theory with empirical error of Err S ( T fl ) = 0 based on m samples drawn independently from a stationary distribution over the query class Q.
Reference: [BFOS84] <author> L. Breiman, J. Friedman, J. Olshen, and C. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth and Brooks, </publisher> <address> Monterey, CA, </address> <year> 1984. </year>
Reference-contexts: The appendix supplies the relevant proofs. We close this section by describing related research. Related Results: Our underlying task, of producing a theory that is as correct as possible, is the main objective of most research in inductive learning, including as notable instances cart <ref> [BFOS84] </ref>, c4.5 [Qui92] and connectionist learning algorithms [Hin89]. While many of these systems learn descriptions based on bit vectors or simple hierarchies, our work deals with logical descriptions.
Reference: [BM93] <author> Paul T. Baffes and Raymond J. Mooney. </author> <title> Symbolic revision of theories with M-of-N rules. </title> <booktitle> In Proceedings of IJCAI-93, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: Our analysis, and results, can easily be applied to many other types of modifications | e.g., specializing or generalizing antecedents [OM94], using "n-of-m rules" <ref> [BM93] </ref>, or merging rules 1 Throughout, we will assume that P 6= N P [GJ79], which implies that any NP-hard problem is intractable. This also implies certain approximation claims, presented below.
Reference: [Bol85] <author> B. Bollobas. </author> <title> Random Graphs. </title> <publisher> Academic Press, </publisher> <year> 1985. </year>
Reference-contexts: Let Err S ( T ) be the sample mean after taking M = M upper (T ; *; ffi) samples, S. Hoeffding-Chernoff bounds <ref> [Che52, Bol85] </ref> bound the confidence that Err S ( T ) will be close to Err ( T ): P r [ jErr S ( T ) Err ( T )j &gt; ] &lt; e 2M 2 Using the above value for M , this means P r [ jErr S
Reference: [Bou93] <author> C. Boutilier. </author> <title> Revision sequences and nested conditionals. </title> <booktitle> In Proceedings of IJCAI-93, </booktitle> <pages> pages 519-525, </pages> <year> 1993. </year>
Reference-contexts: extension T target , agnostically produces a Horn theory W which is usually a strong weakening of T target (i.e., with high probability, W 's models include all models of the original T target , and at most a small number of others). 3 While the work on "iterated revision" <ref> [Bou93, GPS94, FL94, DP94] </ref> also considers more than a single assertion, it usually deals with a sequence of assertions, where each new assertion must be incorporated, as it arrives. Afterwards, it is no longer distinguished from any other information in the current theory (but see [FH96]).
Reference: [Che52] <author> Herman Chernoff. </author> <title> A measure of asymptotic efficiency for tests of a hypothesis based on the sums of observations. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 23 </volume> <pages> 493-507, </pages> <year> 1952. </year>
Reference-contexts: Let Err S ( T ) be the sample mean after taking M = M upper (T ; *; ffi) samples, S. Hoeffding-Chernoff bounds <ref> [Che52, Bol85] </ref> bound the confidence that Err S ( T ) will be close to Err ( T ): P r [ jErr S ( T ) Err ( T )j &gt; ] &lt; e 2M 2 Using the above value for M , this means P r [ jErr S
Reference: [Cla78] <author> K. Clark. </author> <title> Negation as failure. </title> <editor> In H. Gallaire and J. Minker, editors, </editor> <booktitle> Logic and Data Bases, </booktitle> <pages> pages 293-322. </pages> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1978. </year>
Reference-contexts: MaxPerf [MaxThRev [ y ]]( B y ; x ) 2 The companion paper [Gre95] considers other related cases, including the above special cases in the context where our underlying theories can use the not () operator to return Yes if the specified goal cannot be proven; i.e., using Negation-as-Failure <ref> [Cla78] </ref>. It also considers the effect of re-ordering the rules and the antecedents, in the context where such shu*ings can affect the answers returned.
Reference: [Coh90] <author> William W. Cohen. </author> <title> Learning from textbook knowledge: A case study. </title> <booktitle> In Proceeding of AAAI-90, </booktitle> <year> 1990. </year>
Reference-contexts: Most theory revision algorithms use a set of transformations to hill-climb through successive theories, until reaching a theory whose empirical error is (locally) optimal, based on a set of correctly-answered queries; cf., <ref> [Pol85, MB88, Coh90, OM94, WP93, CS90, LDRG94] </ref>. <p> This also implies certain approximation claims, presented below. The Complexity of Theory Revision 4 and removing chains of rules that produced incorrect results <ref> [Coh90, Coh92] </ref>. 2 While these projects provide empirical evidence for the effectiveness of their specific algorithms, and deal with classification (i.e., determining whether a given element or tuple is a member of some target class) rather than general derivation, our work formally addresses the complexities inherent in finding the best theory, <p> There are several related complexity results: First, Cohen <ref> [Coh90] </ref> observed that the challenge of computing the smallest modification was intractable in a particular context; this relates to our Corollary 4.1.
Reference: [Coh92] <author> William W. Cohen. </author> <title> Abductive explanation-based learning: A solution to the multiple inconsistent explanation problems. </title> <journal> Machine Learning, </journal> <volume> 8(2) </volume> <pages> 167-219, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: This also implies certain approximation claims, presented below. The Complexity of Theory Revision 4 and removing chains of rules that produced incorrect results <ref> [Coh90, Coh92] </ref>. 2 While these projects provide empirical evidence for the effectiveness of their specific algorithms, and deal with classification (i.e., determining whether a given element or tuple is a member of some target class) rather than general derivation, our work formally addresses the complexities inherent in finding the best theory,
Reference: [Coh95a] <author> William W. Cohen. </author> <title> PAC-learning recursive logic programs: Efficient algorithms. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 2 </volume> <pages> 500-539, </pages> <year> 1995. </year>
Reference-contexts: Finally, there are a number of results on the complexity of "pac-learning" logic programs from scratch (i.e., of inductive logic programming, ILP); cf., <ref> [Coh95b, Coh95a, Coh96, DMR92] </ref>. As mentioned above, this framework is different, as ILP systems can return any Horn theory (rather than just the theories that are syntactically close to an initial theory), and ILP assumes there is a Horn theory which is perfect.
Reference: [Coh95b] <author> William W. Cohen. </author> <title> PAC-learning recursive logic programs: Negative results. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 2 </volume> <pages> 541-573, </pages> <year> 1995. </year>
Reference-contexts: Finally, there are a number of results on the complexity of "pac-learning" logic programs from scratch (i.e., of inductive logic programming, ILP); cf., <ref> [Coh95b, Coh95a, Coh96, DMR92] </ref>. As mentioned above, this framework is different, as ILP systems can return any Horn theory (rather than just the theories that are syntactically close to an initial theory), and ILP assumes there is a Horn theory which is perfect.
Reference: [Coh96] <author> William W. Cohen. </author> <title> PAC-learning non-recursive prolog clauses. </title> <journal> Artificial Intelligence, </journal> <volume> 79(1) </volume> <pages> 1-38, </pages> <year> 1996. </year>
Reference-contexts: Finally, there are a number of results on the complexity of "pac-learning" logic programs from scratch (i.e., of inductive logic programming, ILP); cf., <ref> [Coh95b, Coh95a, Coh96, DMR92] </ref>. As mentioned above, this framework is different, as ILP systems can return any Horn theory (rather than just the theories that are syntactically close to an initial theory), and ILP assumes there is a Horn theory which is perfect.
Reference: [CP91] <author> P. Crescenzi and A. Panconesi. </author> <title> Completeness in approximation classes. </title> <journal> Information and Computation, </journal> <volume> 93(2) </volume> <pages> 241-62, </pages> <year> 1991. </year>
Reference-contexts: Or if this bound was some constant c (x) = c 2 &lt;, then we could efficiently obtain a solution within a factor of c of optimal, which may be good enough for some applications. 13 However, not all problems can be so approximated. Following <ref> [CP91, Kan92] </ref>, we define 12 While Theorem 3 only proves ThRev Prop [ 1 ] to be NP-hard, this problem is clearly in NP. 13 There are such constants for some other NP-hard minimization problems.
Reference: [CS90] <author> Susan Craw and Derek Sleeman. </author> <title> Automating the refinement of knowledge-based systems. In L.C. </title> <editor> Aiello, editor, </editor> <booktitle> Proceedings of ECAI 90. </booktitle> <publisher> Pitman, </publisher> <year> 1990. </year>
Reference-contexts: Most theory revision algorithms use a set of transformations to hill-climb through successive theories, until reaching a theory whose empirical error is (locally) optimal, based on a set of correctly-answered queries; cf., <ref> [Pol85, MB88, Coh90, OM94, WP93, CS90, LDRG94] </ref>. <p> These comments provide a theoretical justification for the intuition that it takes more evidence to justify adding a new part to a theory, than is required to delete an existing part. Note that several theory revision systems, including Krust <ref> [CS90] </ref>, incorporate this bias. Alternative Spaces: The set +A=K; +R=K; A; R strictly extends K by including trans formation-sequences that can delete an unrestricted number of symbols, as well as add up to K + K symbols. <p> The Complexity of Theory Revision 22 Moreover, the further observation that fewer samples are required to justify deleting parts of a theory, rather than adding new parts, motivates theory revision algorithms that focus on the first task <ref> [CS90] </ref>. We next examined the computational challenge of producing such T fl theories, and saw this is intractable if T fl is syntactically far from the initial theory T 0 .
Reference: [Dal88] <author> Mukesh Dalal. </author> <title> Investigations into a theory of knowledge base revision: Preliminary report. </title> <booktitle> In Proceedings of AAAI-88, </booktitle> <pages> pages 475-479, </pages> <year> 1988. </year>
Reference-contexts: For example, many Bayesian systems use such observations to update their representations, often by adjusting the (continuous) parameters in a Dirichlet distribution within a given belief net structure [Hec95]. We, however, are making discrete changes to the structure of the Horn theory. Similarly, belief revision systems <ref> [AGM85, Dal88, Gar88, KM91] </ref> take as input an initial theory T 0 and a new assertion hq; +i (resp., new retraction hr; i) and return a new consistent theory T 0 that entails q (resp., does not entail r) but otherwise is "close" to T 0 [Dal88]. <p> Similarly, belief revision systems [AGM85, Dal88, Gar88, KM91] take as input an initial theory T 0 and a new assertion hq; +i (resp., new retraction hr; i) and return a new consistent theory T 0 that entails q (resp., does not entail r) but otherwise is "close" to T 0 <ref> [Dal88] </ref>.
Reference: [DE92] <author> Mukesh Dalal and David Etherington. </author> <title> Tractable approximate deduction using limited vocabulary. </title> <booktitle> In Proceedings of the Ninth Canadian Conference on Artificial Intelligence, </booktitle> <address> Vancouver, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: More significantly, we present situations where the computational task is not just intractable, but is not even approximatable. Second, many works on "approximations" <ref> [BE89, SK91, DE92, GS92] </ref> and "structural identification" [DP92] seek a theory, of a specified syntactic form, that is semantically close to an explicitly given theory T target (i.e., which entails essentially the same set of propositions that T target entails).
Reference: [DMR92] <author> S. Dzeroski, S. Muggleton, and S. Russell. </author> <title> PAC-learnability of determiniate logic programs. </title> <booktitle> In Proceedings of the Fifth Workshop on Computational Learning Theory, </booktitle> <address> Pittsburgh, </address> <year> 1992. </year> <title> The Complexity of Theory Revision 39 </title>
Reference-contexts: Finally, there are a number of results on the complexity of "pac-learning" logic programs from scratch (i.e., of inductive logic programming, ILP); cf., <ref> [Coh95b, Coh95a, Coh96, DMR92] </ref>. As mentioned above, this framework is different, as ILP systems can return any Horn theory (rather than just the theories that are syntactically close to an initial theory), and ILP assumes there is a Horn theory which is perfect.
Reference: [DP91] <author> Jon Doyle and Ramesh Patil. </author> <title> Two theses of knowledge representation: Language restrictions, taxonomic classification, and the utility of representation services. </title> <journal> Artificial Intelligence, </journal> <volume> 48(3), </volume> <year> 1991. </year>
Reference-contexts: Borrowing from <ref> [Lev84, DP91] </ref>, we also view a theory T as a function that maps each query to its proposed answer; hence, T: Q 7! A, where Q is a (possibly infinite) set of Horn queries, and A = f Yes; No g is the set of possible answers. 5 Hence, given T
Reference: [DP92] <author> Rina Dechter and Judea Pearl. </author> <title> Structure identification in relational data. </title> <journal> Artificial Intelligence, </journal> <volume> 58(1-3):237-270, </volume> <year> 1992. </year>
Reference-contexts: More significantly, we present situations where the computational task is not just intractable, but is not even approximatable. Second, many works on "approximations" [BE89, SK91, DE92, GS92] and "structural identification" <ref> [DP92] </ref> seek a theory, of a specified syntactic form, that is semantically close to an explicitly given theory T target (i.e., which entails essentially the same set of propositions that T target entails). As two representative results: Dechter and Pearl [DP92] agnostically seek a theory W opt , of a specified <p> works on "approximations" [BE89, SK91, DE92, GS92] and "structural identification" <ref> [DP92] </ref> seek a theory, of a specified syntactic form, that is semantically close to an explicitly given theory T target (i.e., which entails essentially the same set of propositions that T target entails). As two representative results: Dechter and Pearl [DP92] agnostically seek a theory W opt , of a specified syntactic form (e.g., Horn or k-Horn) that is a "strongest weakening" of a given extension T target ; 4 and Kautz, Kearns and Selman [KKS95] provide an efficient randomized algorithm that, given an extension T target , agnostically produces a
Reference: [DP94] <author> A. Darwiche and J. Pearl. </author> <title> On the logic of iterated belief revision. </title> <booktitle> In TARK-94, </booktitle> <pages> pages 5-23, </pages> <year> 1994. </year>
Reference-contexts: extension T target , agnostically produces a Horn theory W which is usually a strong weakening of T target (i.e., with high probability, W 's models include all models of the original T target , and at most a small number of others). 3 While the work on "iterated revision" <ref> [Bou93, GPS94, FL94, DP94] </ref> also considers more than a single assertion, it usually deals with a sequence of assertions, where each new assertion must be incorporated, as it arrives. Afterwards, it is no longer distinguished from any other information in the current theory (but see [FH96]).
Reference: [EG92] <author> T. Eiter and G. Gottlob. </author> <title> On the complexity of propositional knowledge base revison, updates and counterfactuals. </title> <journal> Artificial Intelligence, </journal> <volume> 57 </volume> <pages> 227-270, </pages> <year> 1992. </year>
Reference-contexts: task is difficult even if both the initial and final theories, as well as the queries, are Horn; by contrast, many belief revision frameworks deal with arbitrary CNF formulae. (Of course, the standard belief revision tasks | e.g., the "counterfactual problem" | are complete for higher levels in polynomial-time hierarchy <ref> [EG92] </ref>.) Notice theory revision seeks a theory, from within the syntactically defined class of "all theories produced by applying certain syntactical modifications to an initial theory", whose performance is optimal on the semantically-defined task of "either entailing, or not entailing, certain queries".
Reference: [EH89] <author> Andrzei Ehrenfeucht and David Haussler. </author> <title> A general lower bound on the number of examples needed for learning. </title> <journal> Inform. Comput., </journal> <volume> 82(3) </volume> <pages> 247-251, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: Lower Bounds: To obtain a lower bound on the number of samples required to be at least 1 ffi confident of finding a theory within * of optimal, we can use Theorem 2 (Sample Complexity <ref> [BEHW89, EH89] </ref>) Given a class of theories T and values *; ffi &gt; 0, let T fl 2 T be any theory with empirical error of Err S ( T fl ) = 0 based on m samples drawn independently from a stationary distribution over the query class Q.
Reference: [FH96] <author> N. Friedman and J. Halpern. </author> <title> Belief revision: A critique. </title> <booktitle> In KR-96 (submit), </booktitle> <year> 1996. </year>
Reference-contexts: Afterwards, it is no longer distinguished from any other information in the current theory (but see <ref> [FH96] </ref>).
Reference: [FL94] <author> M. Freund and D. Lehmann. </author> <title> Belief revision and rational inference. </title> <type> Technical Report TR-94-16, </type> <institution> Hebrew University, </institution> <year> 1994. </year>
Reference-contexts: extension T target , agnostically produces a Horn theory W which is usually a strong weakening of T target (i.e., with high probability, W 's models include all models of the original T target , and at most a small number of others). 3 While the work on "iterated revision" <ref> [Bou93, GPS94, FL94, DP94] </ref> also considers more than a single assertion, it usually deals with a sequence of assertions, where each new assertion must be incorporated, as it arrives. Afterwards, it is no longer distinguished from any other information in the current theory (but see [FH96]).
Reference: [FP93] <author> Michael Frazier and Leonard Pitt. </author> <title> Learning from entailment: An application to propositional horn sentences. </title> <booktitle> In Proceedings of IML-93, </booktitle> <pages> pages 120-27. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: See also "entailment queries" <ref> [FP93, KR94] </ref>. ) For now, we will assume there is a single correct answer to each question, and represent it using the "target function" (or "real-world oracle") O : Q 7! A. Here, perhaps, O ( h ) = No, meaning that "h" should not hold. <p> In fact, many of these tasks become trivial if we consider only target functions that correspond to a Horn theory. Frazier and Pitt <ref> [FP93] </ref>, however, prove that learning a perfect Horn theory from Horn queries (which corresponds to ThRev P rop;Horn;P erf [ 1 ] when the target oracle is in O Horn ) is as hard as learning arbitrary CNFs from examples in this "PAC" framework; n.b., the latter is an open problem
Reference: [Gar88] <author> Peter Gardenfors. </author> <title> Knowledge in Flux: Modeling the Dynamics of the Epistemic States. </title> <publisher> Bradford Book, MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: For example, many Bayesian systems use such observations to update their representations, often by adjusting the (continuous) parameters in a Dirichlet distribution within a given belief net structure [Hec95]. We, however, are making discrete changes to the structure of the Horn theory. Similarly, belief revision systems <ref> [AGM85, Dal88, Gar88, KM91] </ref> take as input an initial theory T 0 and a new assertion hq; +i (resp., new retraction hr; i) and return a new consistent theory T 0 that entails q (resp., does not entail r) but otherwise is "close" to T 0 [Dal88].
Reference: [GJ79] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: Our analysis, and results, can easily be applied to many other types of modifications | e.g., specializing or generalizing antecedents [OM94], using "n-of-m rules" [BM93], or merging rules 1 Throughout, we will assume that P 6= N P <ref> [GJ79] </ref>, which implies that any NP-hard problem is intractable. This also implies certain approximation claims, presented below. <p> problems; for example, the MinGraphColor decision problem The Complexity of Theory Revision 18 Given a graph G = hN; Ei and a positive integer K, can each node be labeled by one of K colors in such a way that no edge connects two nodes of the same color; see <ref> [GJ79, p191 (Chromatic Number)] </ref> corresponds to the obvious minimization problem: Find the minimal coloring of the given graph G. <p> For example, there is a polynomial-time algorithm that computes a solution whose cost is within a factor of 1:5 for any TravelingSalesman-with-Triangle-Inequality problem; see <ref> [GJ79, Theorem 6.5] </ref>. The Complexity of Theory Revision 19 Definition 2 A minimization problem MinP is PolyApprox if 8fl 2 &lt; + ; 9B fl 2 Poly ( MinP ); 8x 2 MinP; MinPerf [MinP]( B; x ) jxj fl . <p> As Err ( T 0 ) = p, this set must contain k elements, as desired. (c): We show that ThRev P redCal;Atom;P erf [ 1 ] is NP-hard by reducing to it the (canonical) NP-complete problem: Definition 4 (3sat Decision Problem, from <ref> [GJ79, p259] </ref>:) Given a set U = fu 1 ; : : : ; u n g of variables and formula ' = fc 1 ; : : : ; c m g (a conjunction of clauses over U ) such that each clause c 2 C is a disjunction of <p> Proof: All three proofs use the following result: Definition 5 (MinColor Minimization Problem, from <ref> [GJ79, p191] </ref>:) Find the minimal k such that G is k-colorable, where a graph G = hN; Ei is k-colorable if there is a function c : N 7! f1; : : : ; kg such that 8hn 1 ; n 2 i 2 E; c (n 1 ) 6= c <p> We can use a similar approach to handle ThRev P rop;Horn;P erf [ A ]. (2a*): We reduce the following NP-complete problem to ThRev P rop;Atom;Opt [ R ]: Definition: MinHitSet Decision Problem, from <ref> [GJ79, p222] </ref>: Given set of elements X = fx 1 ; : : : ; x k g, collection C = fc i g of subsets of X where each c i X, and integer k 2 Z + , is there a subset of X of size k that intersects
Reference: [GPS94] <author> G. Gogic, C. H. Papadimitriou, and M. Sideri. </author> <title> Incremental recompilation of knowledge. </title> <booktitle> In Proceedings of AAAI-94, </booktitle> <pages> pages 922-927, </pages> <year> 1994. </year>
Reference-contexts: extension T target , agnostically produces a Horn theory W which is usually a strong weakening of T target (i.e., with high probability, W 's models include all models of the original T target , and at most a small number of others). 3 While the work on "iterated revision" <ref> [Bou93, GPS94, FL94, DP94] </ref> also considers more than a single assertion, it usually deals with a sequence of assertions, where each new assertion must be incorporated, as it arrives. Afterwards, it is no longer distinguished from any other information in the current theory (but see [FH96]).
Reference: [Gre95] <author> Russell Greiner. </author> <title> The challenge of revising impure theories. </title> <booktitle> In Proceedings of the Twelfth International Machine Learning Conference, </booktitle> <year> 1995. </year>
Reference-contexts: with the assertion hq; +i is equivalent to the theory obtained by revising T 2 with hq; +i. 2 (1) However, we make no claims concerning the applicability of our techniques to systems like KBANN [Tow91], which use a completely different means of modifying a theory. (2) The companion paper <ref> [Gre95] </ref> considers yet other ways of modifying a theory, viz., by rearranging its component rules or antecedents. <p> Similarly, the order of rules is also irrelevant in this model. The companion paper <ref> [Gre95] </ref> considers alternative models in which these orders can matter. <p> ) = 1Err ( opt (x) ) Theorem 8 For each y 2 f R;+A ; R ; +A ; +R;A ; +R ; A g, 9B y 2 Poly ( MaxThRev [ y ] ); MaxPerf [MaxThRev [ y ]]( B y ; x ) 2 The companion paper <ref> [Gre95] </ref> considers other related cases, including the above special cases in the context where our underlying theories can use the not () operator to return Yes if the specified goal cannot be proven; i.e., using Negation-as-Failure [Cla78].
Reference: [GS92] <author> Russell Greiner and Dale Schuurmans. </author> <title> Learning useful horn approximations. </title> <editor> In B. Nebel, C. Rich, and W. Swartout, editors, </editor> <booktitle> Proceedings of KR-92, </booktitle> <address> San Mateo, CA, October 1992. </address> <publisher> Morgan Kaufmann. ftp://scr.siemens.com/pub/learning/Papers/greiner/horn.ps. </publisher>
Reference-contexts: More significantly, we present situations where the computational task is not just intractable, but is not even approximatable. Second, many works on "approximations" <ref> [BE89, SK91, DE92, GS92] </ref> and "structural identification" [DP92] seek a theory, of a specified syntactic form, that is semantically close to an explicitly given theory T target (i.e., which entails essentially the same set of propositions that T target entails).
Reference: [Hau88] <author> David Haussler. </author> <title> Quantifying inductive bias: AI learning algorithms and Valiant's learning framework. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> pages 177-221, </pages> <year> 1988. </year> <title> The Complexity of Theory Revision 40 </title>
Reference-contexts: The earlier worst-case results for +R and +A cases each require predicate calculus, as they rely on using function symbols. In the context of a propositional logic system with 10 Readers wishing to learn yet more about "Vapnik-Chervonenkis Dimension" are referred to <ref> [Hau88] </ref>.
Reference: [Hec95] <author> David E. Heckerman. </author> <title> A tutorial on learning with bayesian networks. </title> <type> Technical Report Technical Report MSR-TR-95-06, </type> <institution> Microsoft Research, </institution> <year> 1995. </year>
Reference-contexts: There are many other frameworks that use new observations to improve a given description of the world. For example, many Bayesian systems use such observations to update their representations, often by adjusting the (continuous) parameters in a Dirichlet distribution within a given belief net structure <ref> [Hec95] </ref>. We, however, are making discrete changes to the structure of the Horn theory.
Reference: [Hin89] <author> Geoff Hinton. </author> <title> Connectionist learning procedures. </title> <journal> Artificial Intelligence, </journal> <volume> 40(1-3):185-234, </volume> <month> September </month> <year> 1989. </year>
Reference-contexts: We close this section by describing related research. Related Results: Our underlying task, of producing a theory that is as correct as possible, is the main objective of most research in inductive learning, including as notable instances cart [BFOS84], c4.5 [Qui92] and connectionist learning algorithms <ref> [Hin89] </ref>. While many of these systems learn descriptions based on bit vectors or simple hierarchies, our work deals with logical descriptions.
Reference: [Kan92] <author> Viggo Kann. </author> <title> On the Approximability of NP-Complete Optimization Problems. </title> <type> PhD thesis, </type> <institution> Royal Institute of Technology, Stockholm, </institution> <year> 1992. </year>
Reference-contexts: Or if this bound was some constant c (x) = c 2 &lt;, then we could efficiently obtain a solution within a factor of c of optimal, which may be good enough for some applications. 13 However, not all problems can be so approximated. Following <ref> [CP91, Kan92] </ref>, we define 12 While Theorem 3 only proves ThRev Prop [ 1 ] to be NP-hard, this problem is clearly in NP. 13 There are such constants for some other NP-hard minimization problems.
Reference: [KKS95] <author> Henry Kautz, Michael Kearns, and Bart Selman. </author> <title> Horn approximations of empirical data. </title> <journal> Artificial Intelligence, </journal> <volume> 74 </volume> <pages> 129-145, </pages> <year> 1995. </year>
Reference-contexts: As two representative results: Dechter and Pearl [DP92] agnostically seek a theory W opt , of a specified syntactic form (e.g., Horn or k-Horn) that is a "strongest weakening" of a given extension T target ; 4 and Kautz, Kearns and Selman <ref> [KKS95] </ref> provide an efficient randomized algorithm that, given an extension T target , agnostically produces a Horn theory W which is usually a strong weakening of T target (i.e., with high probability, W 's models include all models of the original T target , and at most a small number of
Reference: [KM91] <author> Hirofumi Katsuno and Alberto Mendelzon. </author> <title> On the difference between updating a knowledge base and revising it. </title> <booktitle> In Proceedings of KR-91, </booktitle> <pages> pages 387-94, </pages> <address> Boston, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: For example, many Bayesian systems use such observations to update their representations, often by adjusting the (continuous) parameters in a Dirichlet distribution within a given belief net structure [Hec95]. We, however, are making discrete changes to the structure of the Horn theory. Similarly, belief revision systems <ref> [AGM85, Dal88, Gar88, KM91] </ref> take as input an initial theory T 0 and a new assertion hq; +i (resp., new retraction hr; i) and return a new consistent theory T 0 that entails q (resp., does not entail r) but otherwise is "close" to T 0 [Dal88].
Reference: [KR94] <author> Roni Khardon and Dan Roth. </author> <title> Learning to reason. </title> <booktitle> In AAAI-94, </booktitle> <pages> pages 682-687, </pages> <year> 1994. </year>
Reference-contexts: See also "entailment queries" <ref> [FP93, KR94] </ref>. ) For now, we will assume there is a single correct answer to each question, and represent it using the "target function" (or "real-world oracle") O : Q 7! A. Here, perhaps, O ( h ) = No, meaning that "h" should not hold.
Reference: [KS90] <author> Michael Kearns and Robert E. Shapire. </author> <title> Efficient distribution-free learning of probabilistic concepts. </title> <booktitle> In Proceedings of the 31st Symposium on Foundation of Computer Science, </booktitle> <month> October </month> <year> 1990. </year>
Reference-contexts: This allows us to model the situation where, for a particular set of observations, different repairs are appropriate at different times; this could happen, for example, if the correct repair depends on some unobserved variables, as well as the observations; see <ref> [KS90] </ref>.
Reference: [KSS92] <author> M. J. Kearns, R. E. Schapire, and L. M. Sellie. </author> <title> Toward efficient agnostic leaning. </title> <booktitle> In Proceedings COLT-92, </booktitle> <pages> pages 341-352. </pages> <publisher> ACM Press, </publisher> <year> 1992. </year>
Reference-contexts: theories, or when considering with only atomic queries, or when considering only a bounded number of transformations, etc. 1 These results hold both in situations where there is a perfect Horn theory (i.e., there is a theory that correctly labels all of the instances), as well as the "agnostic" setting <ref> [KSS92] </ref>, where there is no such theory. <p> We still want to find the optimal member of the class. This corresponds exactly to the "agnostic learning" model; Kearns, Schapire and Sellie <ref> [KSS92] </ref> have shown that this task is often intractable. Our framework differs by dealing with a different class of "samples" (arbitrary queries, not bit vectors), and by having a different class of hypotheses (predicate calculus Horn theories, rather than propositional conjunctions). <p> This is the same motivation that gave rise to the study of "agnostic learning" <ref> [KSS92] </ref>. In general, our goal is to find a theory that is as close to the target function O ( ) as possible.
Reference: [LDRG94] <author> Pat Langley, George Drastal, R. Bharat Rao, and Russell Greiner. </author> <title> Theory revision in fault hierarchies. </title> <booktitle> In Proceedings of The Fifth International Workshop on Principles of Diagnosis (DX-94), </booktitle> <address> New Paltz, NY, </address> <year> 1994. </year>
Reference-contexts: Most theory revision algorithms use a set of transformations to hill-climb through successive theories, until reaching a theory whose empirical error is (locally) optimal, based on a set of correctly-answered queries; cf., <ref> [Pol85, MB88, Coh90, OM94, WP93, CS90, LDRG94] </ref>. <p> Most use essentially the same set of transformations described here | e.g., Audrey [WP93], Fonte [MB88], Either [OM94] and <ref> [LDRG94] </ref> each consider adding or deleting antecedents or rules. <p> First, the standard justification for theory revision, in general, is the intuition that a relatively small number of samples will be sufficient to transform a nearly-perfect theory into an even better theory; note this intuition has been borne out empirically <ref> [LDRG94] </ref>. Our sample complexity results prove this in general: showing that it takes fewer samples to produce a very good theory T fl by revising an already good theory, than are required to learn this T fl from scratch.
Reference: [Lev84] <author> Hector J. Levesque. </author> <title> Foundations of a functional approach to knowledge representation. </title> <journal> Artificial Intelligence, </journal> <volume> 23 </volume> <pages> 155-212, </pages> <year> 1984. </year>
Reference-contexts: 1 Introduction There are many fielded knowledge-based systems, ranging from expert systems and logic programs to production systems and database management systems <ref> [Lev84] </ref>. Each such system uses its database of general information (a.k.a. its "theory") to produce an answer to each given query; this can correspond to retrieving information from a database or to providing a diagnosis or repair, based on a given set of symptoms. <p> Borrowing from <ref> [Lev84, DP91] </ref>, we also view a theory T as a function that maps each query to its proposed answer; hence, T: Q 7! A, where Q is a (possibly infinite) set of Horn queries, and A = f Yes; No g is the set of possible answers. 5 Hence, given T
Reference: [LMR88] <author> Nathan Linial, Yishay Mansour, and Ronald Rivest. </author> <title> Results on learnability and the Vapnik-Chervonenkis dimension. </title> <booktitle> In Proceedings of COLT-88, </booktitle> <year> 1988. </year>
Reference-contexts: ]; and if not, consider all theories in 2 [T 0 ] (formed by applying sequences of transformations with cost at most two), and return any perfect T 2 2 2 [T 0 ]; and so forth. (Notice this may involve using successively more samples on each iteration, a la <ref> [LMR88] </ref>.) 4.2 Approximatability Many decision problems correspond immediately to optimization problems; for example, the MinGraphColor decision problem The Complexity of Theory Revision 18 Given a graph G = hN; Ei and a positive integer K, can each node be labeled by one of K colors in such a way that no
Reference: [LV91] <author> Charles X.F. Ling and Marco Valtorta. </author> <title> Some results on the computational complexity of refining certainty factors. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 5 </volume> <pages> 121-148, </pages> <year> 1991. </year>
Reference-contexts: Our results show that this problem remains intractable (and is in fact, not even approximatable) even in the propositional case, when all rules have unit weight and a single rule is sufficient to establish a conclusion. Third, Valtorta and Ling <ref> [LV91, LV95] </ref> also considered the computational complexity of modifying a theory. Their analysis, however, dealt with a different type of modifications: viz., adjusting various numeric weights within a given network (e.g., altering the certainty factors associated with the rules), but not changing the structure by adding or deleting rules.
Reference: [LV95] <author> Charles X.F. Ling and Marco Valtorta. </author> <title> Refinement of uncertain rule bases via reduction. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 13 </volume> <pages> 95-126, </pages> <year> 1995. </year>
Reference-contexts: Our results show that this problem remains intractable (and is in fact, not even approximatable) even in the propositional case, when all rules have unit weight and a single rule is sufficient to establish a conclusion. Third, Valtorta and Ling <ref> [LV91, LV95] </ref> also considered the computational complexity of modifying a theory. Their analysis, however, dealt with a different type of modifications: viz., adjusting various numeric weights within a given network (e.g., altering the certainty factors associated with the rules), but not changing the structure by adding or deleting rules.
Reference: [LY93] <author> Carsten Lund and Mihalis Yannakakis. </author> <title> On the hardness of approximating minimization problems. </title> <booktitle> In Proceeding of Twenty-fifth Annual ACM Symposium on Theory of Computation (STOC-93), </booktitle> <pages> pages 286-93, </pages> <year> 1993. </year> <title> The Complexity of Theory Revision 41 </title>
Reference-contexts: The Complexity of Theory Revision 19 Definition 2 A minimization problem MinP is PolyApprox if 8fl 2 &lt; + ; 9B fl 2 Poly ( MinP ); 8x 2 MinP; MinPerf [MinP]( B; x ) jxj fl . Lund and Yannakakis <ref> [LY93] </ref> prove that (unless P = N P ) the "MinGraphColor minimization problem" is not PolyApprox | i.e., there is some fl 2 &lt; + such that no polynomial-time algorithm can always find a solution within jxj fl of optimal.
Reference: [MB88] <author> S. Muggleton and W. Buntine. </author> <title> Machine invention of first order predicates by inverting resolution. </title> <booktitle> In Proceedings of IML-88, </booktitle> <pages> pages 339-51. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: Most theory revision algorithms use a set of transformations to hill-climb through successive theories, until reaching a theory whose empirical error is (locally) optimal, based on a set of correctly-answered queries; cf., <ref> [Pol85, MB88, Coh90, OM94, WP93, CS90, LDRG94] </ref>. <p> Most use essentially the same set of transformations described here | e.g., Audrey [WP93], Fonte <ref> [MB88] </ref>, Either [OM94] and [LDRG94] each consider adding or deleting antecedents or rules.
Reference: [Moo94] <author> Raymond Mooney. </author> <title> A preliminary PAC analysis of theory revision. </title> <editor> In T. Petsche and S. Hanson, editors, </editor> <booktitle> Third Annual Workshop on Computational Learning Theory and Natural Learning Systems (CLNL-92). </booktitle> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: Their analysis, however, dealt with a different type of modifications: viz., adjusting various numeric weights within a given network (e.g., altering the certainty factors associated with the rules), but not changing the structure by adding or deleting rules. Third, Mooney <ref> [Moo94] </ref> addressed the sample complexity of certain types of theory revision systems.
Reference: [Mug92] <author> S.H. Muggleton. </author> <title> Inductive Logic Programming. </title> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: Here too there is a history, dating back (at least) to Plotkin [Plo71] and Shapiro [Sha83], and including the more contemporary foil [Qui90] and the body of work on inductive logic programming (ILP) <ref> [Mug92] </ref>.
Reference: [OM94] <author> Dirk Ourston and Raymond J. Mooney. </author> <title> Theory refinement combining analytical and empirical methods. </title> <journal> Artificial Intelligence, </journal> <volume> 66(2) </volume> <pages> 273-310, </pages> <year> 1994. </year>
Reference-contexts: Most theory revision algorithms use a set of transformations to hill-climb through successive theories, until reaching a theory whose empirical error is (locally) optimal, based on a set of correctly-answered queries; cf., <ref> [Pol85, MB88, Coh90, OM94, WP93, CS90, LDRG94] </ref>. <p> Most use essentially the same set of transformations described here | e.g., Audrey [WP93], Fonte [MB88], Either <ref> [OM94] </ref> and [LDRG94] each consider adding or deleting antecedents or rules. Our analysis, and results, can easily be applied to many other types of modifications | e.g., specializing or generalizing antecedents [OM94], using "n-of-m rules" [BM93], or merging rules 1 Throughout, we will assume that P 6= N P [GJ79], which <p> Most use essentially the same set of transformations described here | e.g., Audrey [WP93], Fonte [MB88], Either <ref> [OM94] </ref> and [LDRG94] each consider adding or deleting antecedents or rules. Our analysis, and results, can easily be applied to many other types of modifications | e.g., specializing or generalizing antecedents [OM94], using "n-of-m rules" [BM93], or merging rules 1 Throughout, we will assume that P 6= N P [GJ79], which implies that any NP-hard problem is intractable. This also implies certain approximation claims, presented below.
Reference: [Plo71] <author> G. D. Plotkin. </author> <title> Automatic Methods of Inductive Inference. </title> <type> PhD thesis, </type> <institution> University of Edinburgh, </institution> <year> 1971. </year>
Reference-contexts: While many of these systems learn descriptions based on bit vectors or simple hierarchies, our work deals with logical descriptions. Here too there is a history, dating back (at least) to Plotkin <ref> [Plo71] </ref> and Shapiro [Sha83], and including the more contemporary foil [Qui90] and the body of work on inductive logic programming (ILP) [Mug92].
Reference: [Pol85] <author> P.G. Politakis. </author> <title> Empirical Analysis for Expert Systems. </title> <booktitle> Pitman Research Notes in Artificial Intelligence, </booktitle> <year> 1985. </year>
Reference-contexts: Most theory revision algorithms use a set of transformations to hill-climb through successive theories, until reaching a theory whose empirical error is (locally) optimal, based on a set of correctly-answered queries; cf., <ref> [Pol85, MB88, Coh90, OM94, WP93, CS90, LDRG94] </ref>.
Reference: [Qui90] <author> J. Ross Quinlan. </author> <title> Learning logical definitions from relations. </title> <journal> Machine Learning Journal, </journal> <volume> 5(3) </volume> <pages> 239-66, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: While many of these systems learn descriptions based on bit vectors or simple hierarchies, our work deals with logical descriptions. Here too there is a history, dating back (at least) to Plotkin [Plo71] and Shapiro [Sha83], and including the more contemporary foil <ref> [Qui90] </ref> and the body of work on inductive logic programming (ILP) [Mug92].
Reference: [Qui92] <author> J. Ross Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, </address> <year> 1992. </year>
Reference-contexts: The appendix supplies the relevant proofs. We close this section by describing related research. Related Results: Our underlying task, of producing a theory that is as correct as possible, is the main objective of most research in inductive learning, including as notable instances cart [BFOS84], c4.5 <ref> [Qui92] </ref> and connectionist learning algorithms [Hin89]. While many of these systems learn descriptions based on bit vectors or simple hierarchies, our work deals with logical descriptions.
Reference: [RBK88] <author> R. Ramakrishman, C. Beeri, and R. Krishnamurthy. </author> <title> Optimizing existential datalog queries. </title> <booktitle> In Proc. of 7th Symposium on Principles of Database Systems, </booktitle> <pages> pages 89-102, </pages> <address> Austin, TX, </address> <month> March </month> <year> 1988. </year>
Reference-contexts: from both O ( ff ) and T (ff): err (T; ff) = 1 jO ( ff )"T (ff)j will use Yes [X= ?] to indicate that there is an instantiation that is satisfied, but the particular value of that instantiation is not important. (This corresponds to an "existential question" <ref> [RBK88] </ref>.) All of the results in this paper hold even when considering only non-recursive theories; and all computational results hold even for Datalog (i.e., "function-free") theories.
Reference: [Sha83] <author> Ehud Shapiro. </author> <title> Algorithmic Program Debugging. </title> <publisher> MIT Press, </publisher> <year> 1983. </year>
Reference-contexts: While many of these systems learn descriptions based on bit vectors or simple hierarchies, our work deals with logical descriptions. Here too there is a history, dating back (at least) to Plotkin [Plo71] and Shapiro <ref> [Sha83] </ref>, and including the more contemporary foil [Qui90] and the body of work on inductive logic programming (ILP) [Mug92].
Reference: [SK91] <author> Bart Selman and Henry Kautz. </author> <title> Knowledge compilation using horn approximations. </title> <booktitle> In Proceedings of AAAI-91, </booktitle> <pages> pages 904-09, </pages> <address> Anaheim, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: More significantly, we present situations where the computational task is not just intractable, but is not even approximatable. Second, many works on "approximations" <ref> [BE89, SK91, DE92, GS92] </ref> and "structural identification" [DP92] seek a theory, of a specified syntactic form, that is semantically close to an explicitly given theory T target (i.e., which entails essentially the same set of propositions that T target entails).
Reference: [Tow91] <author> Geoff Towell. </author> <title> Symbolic Knowledge and Neural Networks: Insertion, Refinement and Extraction. </title> <type> PhD thesis, </type> <institution> University of Wisconsin, Madison, </institution> <year> 1991. </year>
Reference-contexts: i.e., if T 1 T 2 , then the theory obtained by revising T 1 with the assertion hq; +i is equivalent to the theory obtained by revising T 2 with hq; +i. 2 (1) However, we make no claims concerning the applicability of our techniques to systems like KBANN <ref> [Tow91] </ref>, which use a completely different means of modifying a theory. (2) The companion paper [Gre95] considers yet other ways of modifying a theory, viz., by rearranging its component rules or antecedents.
Reference: [Vap82] <author> V.N. Vapnik. </author> <title> Estimation of Dependencies Based on Empirical Data. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: The following theorem provides an upper bound on the number of samples required to be at least 1 ffi confident that the true error of empirically-optimal theory T fl will be within * of the truly best theory of T , T opt : Theorem 1 (from <ref> [Vap82, Theorem 6.2] </ref>) Given a class of theories T , and *; ffi &gt; 0, let T fl 2 T be the theory with the smallest empirical error after M upper (T ; *; ffi) = & * 2 ln jT j !' labeled queries, drawn independently from a stationary distribution. <p> In particular, when K t M = jT opt j, 9 Note that even fewer samples are required to reliably determine whether there is a theory in the given space of theories T whose error is within * of a given quantity, say 0%; see <ref> [Vap82, Theorem 6.1] </ref>. <p> It therefore makes sense to instead accept a locally optimal revised theory; this in turn justifies that standard theory-revision practice of hill-climbing. The Complexity of Theory Revision 23 A Proofs Theorem 1 (from <ref> [Vap82, Theorem 6.2] </ref>) Given a class of theories T , and *; ffi &gt; 0, let T fl 2 T be the theory with the smallest empirical error after M upper (T ; *; ffi) = ~ * 2 ln jT j labeled queries, drawn independently from a stationary distribution.
Reference: [WM94] <author> David C. Wilkins and Yong Ma. </author> <title> The refinement of probabilistic rule sets: sociopathic interactions. </title> <journal> Artificial Intelligence, </journal> <volume> 70 </volume> <pages> 1-32, </pages> <year> 1994. </year>
Reference-contexts: There are several related complexity results: First, Cohen [Coh90] observed that the challenge of computing the smallest modification was intractable in a particular context; this relates to our Corollary 4.1. Second, Wilkins and Ma <ref> [WM94] </ref> show the intractability of determining the best set of rules to delete in the context of "weighted" rules, where a conclusion is believed if a particular function of the weights of the supporting rules exceeds a threshold.
Reference: [WP93] <author> James Wogulis and Michael J. Pazzani. </author> <title> A methodology for evaluating theory revision systems: Results with Audrey II. </title> <booktitle> In Proceedings of IJCAI-93, </booktitle> <pages> pages 1128-1134, </pages> <year> 1993. </year>
Reference-contexts: Most theory revision algorithms use a set of transformations to hill-climb through successive theories, until reaching a theory whose empirical error is (locally) optimal, based on a set of correctly-answered queries; cf., <ref> [Pol85, MB88, Coh90, OM94, WP93, CS90, LDRG94] </ref>. <p> Most use essentially the same set of transformations described here | e.g., Audrey <ref> [WP93] </ref>, Fonte [MB88], Either [OM94] and [LDRG94] each consider adding or deleting antecedents or rules.
References-found: 63

