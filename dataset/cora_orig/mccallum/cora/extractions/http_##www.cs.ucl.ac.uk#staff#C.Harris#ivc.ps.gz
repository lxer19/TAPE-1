URL: http://www.cs.ucl.ac.uk/staff/C.Harris/ivc.ps.gz
Refering-URL: http://www.cs.ucl.ac.uk/staff/C.Harris/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: C.Harris@cs.ucl.ac.uk, B.Buxton@cs.ucl.ac.uk  
Title: 1 Low-level Edge Detection Using Genetic Programming: performance, specificity and application to real-world signals  
Author: Christopher Harris and Bernard Buxton 
Address: Gower Street London WC1E 6BT  
Affiliation: Department of Computer Science University College London  
Abstract: Genetic Programming (GP) is a powerful machine learning technique derived from Genetic Algorithms. We use GP to produce high-performance edge detectors in 1-dimensional signals. Using the theory of edge detection to assess candidate detectors produced by GP, we show that this technique can produce detectors that often outperform the established optimal detectors. Further, we show that detectors can be evolved to be specific to the training data, offering the capability to produce tailor-made edge detectors. Such detectors are shown to perform better on the data set than other evolved detectors.
Abstract-found: 1
Intro-found: 1
Reference: [Bhandarkar] <author> Bhandarkar, S.M., Yiqing Zhang, Potter, W.D. </author> <title> An edge detection technique using Genetic Algorithm based optimisation. </title> <journal> Pattern Recognition. </journal> <volume> 27(9). </volume> <pages> pp 1159-1180. </pages> <year> 1994. </year>
Reference-contexts: Detecting edges well is therefore an - 2 - important problem. In addition to a considerable body of work on applying different practical techniques to the detection of edges in images <ref> [Chao, Bhandarkar, Srinivasan] </ref>, theoretical work on the properties of an ideal edge detector has produced a number of high quality operators [Canny, Spacek, Petrou], each satisfying slightly different theoretical requirements aimed at optimising the accuracy and reliability of the edge detection process. <p> It also has facilities for producing reusable code in the form of evolved subroutines called ADFs [Koza2]. Although it is quite possible to apply techniques such as GAs and neural networks to the problem of edge detection <ref> [Bhandarkar, Chao, Srinivasan] </ref>, the nature of these techniques, in particular the centrality of the underlying representations used (i.e. sigmoid or radial basis - 7 - functions in neural nets, bitstrings in GAs) restricts the ways in which the problem can be approached.
Reference: [Canny] <author> Canny, J. </author> <title> A Computational Approach to Edge Detection. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence. </journal> <volume> 8(6). </volume> <year> 1986. </year>
Reference-contexts: In addition to a considerable body of work on applying different practical techniques to the detection of edges in images [Chao, Bhandarkar, Srinivasan], theoretical work on the properties of an ideal edge detector has produced a number of high quality operators <ref> [Canny, Spacek, Petrou] </ref>, each satisfying slightly different theoretical requirements aimed at optimising the accuracy and reliability of the edge detection process. In this paper we present several applications of the theory of edge detection to the automatic production of high-quality detectors. <p> This consists of a transition of infinite gradient in the signal from one - 3 - steady value to another, as shown in Figure 1. Theoretical treatments assume that the signal is corrupted with Gaussian noise. <ref> [Canny] </ref> was the first to present a set of criteria that an ideal filter would fulfil. Three criteria were presented that contributed to the performance of a filter on noisy edges of various kinds. <p> Evolving a filter with Genetic Programming Our experiments concentrated on the evolution of the functional form used to produce the digital filter in the first stage of the detection process. This filter was used to perform edge First derivative of Gaussian <ref> [Canny] </ref> Cubic spline [Spacek] Spaceks optimal operator Petrous optimal operator [Petrou] - 6 - detection on a series of training data, and the output signals produced were analysed to produce a performance measure, as detailed in section 4. 3.1 Genetic Programming Genetic Programming is an extension of the Genetic Algorithm [Holland], <p> This function analyses each output signal, the result of convolving the training signal with the candidate filter. Three criteria are applied to the signal to produce an overall score. These criteria are ensemble ensemble ensemble training set - 11 - designed to correspond closely to those specified in <ref> [Canny] </ref>, with some modifications to render the three criteria independent of each other as explained below. Around the locations marked as edge positions, criteria measuring response strength and localisation error are applied. <p> The third criterion is not localised to marked edge positions. It is desired that the operator respond as little as possible to any noise present in the signal, i.e. we require operators with noise suppression properties. To measure the degree to which the operator responds to noise, following <ref> [Canny] </ref>, we look at the separation of peaks in the output signal. <p> These results are then further averaged over all sampling rates to give an overall performance figure. In addition, the number First derivative of Gaussian as used in <ref> [Canny] </ref>. - e s 2 Cubic spline approximation, used in [Spacek]. Positive x values are mirrors of the negative values, to gain anti-symmetry (a necessary precondition in the theory). x x x 3 2 2 + + Optimal operator derived by Spacek.
Reference: [Chao] <author> Chih-Ho Chao, Atam P. Dhawan. </author> <title> Edge detection using a Hopfield neural network. </title> <booktitle> Optical Engineering 33(11). </booktitle> <year> 1994. </year>
Reference-contexts: Detecting edges well is therefore an - 2 - important problem. In addition to a considerable body of work on applying different practical techniques to the detection of edges in images <ref> [Chao, Bhandarkar, Srinivasan] </ref>, theoretical work on the properties of an ideal edge detector has produced a number of high quality operators [Canny, Spacek, Petrou], each satisfying slightly different theoretical requirements aimed at optimising the accuracy and reliability of the edge detection process. <p> It also has facilities for producing reusable code in the form of evolved subroutines called ADFs [Koza2]. Although it is quite possible to apply techniques such as GAs and neural networks to the problem of edge detection <ref> [Bhandarkar, Chao, Srinivasan] </ref>, the nature of these techniques, in particular the centrality of the underlying representations used (i.e. sigmoid or radial basis - 7 - functions in neural nets, bitstrings in GAs) restricts the ways in which the problem can be approached.
Reference: [Harris] <author> Harris, </author> <title> C.P., Buxton, B.F. 1996. Evolving Edge Detectors with Genetic Programming. </title> <booktitle> In Genetic Programming 1996: Proceedings of the First Conference. </booktitle> <publisher> MIT Press. </publisher>
Reference: [Holland] <author> Holland J. </author> <title> Adaptation in Natural and Artificial Systems . Elsevier. </title> <note> 1975 (revised 1992). </note>
Reference-contexts: [Canny] Cubic spline [Spacek] Spaceks optimal operator Petrous optimal operator [Petrou] - 6 - detection on a series of training data, and the output signals produced were analysed to produce a performance measure, as detailed in section 4. 3.1 Genetic Programming Genetic Programming is an extension of the Genetic Algorithm <ref> [Holland] </ref>, pioneered by John Koza [Koza]. Instead of representing possible solutions to problems with a fixed-length bit string, Genetic Programming (GP) uses a tree-based structure. This structure allows the manipulation of solution forms that are based on grammars, such as computer program code.
Reference: [Koza] <author> Koza, J.R. </author> <title> Genetic Programming: On the Programming of Computers by Natural Selection. </title> <publisher> MIT Press. </publisher> <year> 1992. </year>
Reference-contexts: optimal operator Petrous optimal operator [Petrou] - 6 - detection on a series of training data, and the output signals produced were analysed to produce a performance measure, as detailed in section 4. 3.1 Genetic Programming Genetic Programming is an extension of the Genetic Algorithm [Holland], pioneered by John Koza <ref> [Koza] </ref>. Instead of representing possible solutions to problems with a fixed-length bit string, Genetic Programming (GP) uses a tree-based structure. This structure allows the manipulation of solution forms that are based on grammars, such as computer program code.
Reference: [Koza2] <author> Koza, J.R. </author> <title> Genetic Programming II: Automatic Discovery of Reusable Programs. </title> <publisher> MIT Press. </publisher> <year> 1994. </year>
Reference-contexts: Genetic Programming evolves solutions in symbolic form directly, permitting many different kinds of representation in the solutions formed. It also has facilities for producing reusable code in the form of evolved subroutines called ADFs <ref> [Koza2] </ref>.
Reference: [Petrou] <author> Petrou, M., Kittler, J. </author> <title> On the optimal edge detector. </title> <booktitle> In Proceedings of the Alvey Vision Conference. </booktitle> <address> Manchester, UK. </address> <pages> pp 191-196. </pages> <year> 1986 </year> <month> - 20 </month> - 
Reference-contexts: In addition to a considerable body of work on applying different practical techniques to the detection of edges in images [Chao, Bhandarkar, Srinivasan], theoretical work on the properties of an ideal edge detector has produced a number of high quality operators <ref> [Canny, Spacek, Petrou] </ref>, each satisfying slightly different theoretical requirements aimed at optimising the accuracy and reliability of the edge detection process. In this paper we present several applications of the theory of edge detection to the automatic production of high-quality detectors. <p> A convenient approximation to Spaceks optimal detector, which also outperformed both of Cannys operators using Cannys own criteria, was a cubic spline function, x x x 3 2 2 + + . This approximation had over 99.9% of the performance of Spaceks optimum according to his performance measure. <ref> [Petrou] </ref> extended Spaceks work to optimise all six parameters in the expression for the optimal operator. The resulting form improved on Spaceks optimal operator and on the cubic spline operator using identical criteria as in [Spacek]. <p> This filter was used to perform edge First derivative of Gaussian [Canny] Cubic spline [Spacek] Spaceks optimal operator Petrous optimal operator <ref> [Petrou] </ref> - 6 - detection on a series of training data, and the output signals produced were analysed to produce a performance measure, as detailed in section 4. 3.1 Genetic Programming Genetic Programming is an extension of the Genetic Algorithm [Holland], pioneered by John Koza [Koza]. <p> C = -13.3816 C = 2.7953 3 4 ( ) C x C x e x 1 2 1 sin cos + + - Optimal operator derived in <ref> [Petrou] </ref>.
Reference: [Spacek] <author> Spacek, L.A. </author> <title> Edge detection and motion detection. </title> <booktitle> Image Vision Computing 4. </booktitle> <pages> pp 43-55. </pages> <year> 1986. </year>
Reference-contexts: In addition to a considerable body of work on applying different practical techniques to the detection of edges in images [Chao, Bhandarkar, Srinivasan], theoretical work on the properties of an ideal edge detector has produced a number of high quality operators <ref> [Canny, Spacek, Petrou] </ref>, each satisfying slightly different theoretical requirements aimed at optimising the accuracy and reliability of the edge detection process. In this paper we present several applications of the theory of edge detection to the automatic production of high-quality detectors. <p> Canny derived expressions for these three quantities and combined the first two to produce an expression for an optimal filter for step edges. Maximising this expression gave a complicated expression that Canny approximated with the first derivative of a Gaussian function. <ref> [Spacek] </ref> took Cannys work and derived an expression for the optimal operator using all three criteria, with slightly different boundary conditions. Spaceks work assumed an interval for the detector function of [-1,0] and reflected this function in the y-axis to guarantee anti-symmetry. <p> The resulting form improved on Spaceks optimal operator and on the cubic spline operator using identical criteria as in <ref> [Spacek] </ref>. When applied in practice to real images however, the difference in performance was not found to be significant. The functional forms of the operators derived can be found in Table 3. <p> Evolving a filter with Genetic Programming Our experiments concentrated on the evolution of the functional form used to produce the digital filter in the first stage of the detection process. This filter was used to perform edge First derivative of Gaussian [Canny] Cubic spline <ref> [Spacek] </ref> Spaceks optimal operator Petrous optimal operator [Petrou] - 6 - detection on a series of training data, and the output signals produced were analysed to produce a performance measure, as detailed in section 4. 3.1 Genetic Programming Genetic Programming is an extension of the Genetic Algorithm [Holland], pioneered by John <p> Better noise suppressors will produce more widely spaced peaks. This value is averaged over all the output signals and taken as the partial fitness value, C (f). Once the partial fitness values for the operator have been calculated, the final fitness of each genetic program, following <ref> [Spacek] </ref>, is calculated as S (f)C (f)/L (f). This means we are looking for operators with high response strength, small localisation error, and good noise suppression. The objective of the genetic search is thus to maximise this product. <p> These results are then further averaged over all sampling rates to give an overall performance figure. In addition, the number First derivative of Gaussian as used in [Canny]. - e s 2 Cubic spline approximation, used in <ref> [Spacek] </ref>. Positive x values are mirrors of the negative values, to gain anti-symmetry (a necessary precondition in the theory). x x x 3 2 2 + + Optimal operator derived by Spacek.
Reference: [Srinivasan] <author> Srinivasan, V., Byatia, P., Ong, S.H. </author> <title> Edge detection using a neural network. </title> <booktitle> Pattern Recognition 27(12). </booktitle> <pages> pp 1653-1662. </pages> <year> 1994. </year> <month> - 21 </month> - 
Reference-contexts: Detecting edges well is therefore an - 2 - important problem. In addition to a considerable body of work on applying different practical techniques to the detection of edges in images <ref> [Chao, Bhandarkar, Srinivasan] </ref>, theoretical work on the properties of an ideal edge detector has produced a number of high quality operators [Canny, Spacek, Petrou], each satisfying slightly different theoretical requirements aimed at optimising the accuracy and reliability of the edge detection process. <p> It also has facilities for producing reusable code in the form of evolved subroutines called ADFs [Koza2]. Although it is quite possible to apply techniques such as GAs and neural networks to the problem of edge detection <ref> [Bhandarkar, Chao, Srinivasan] </ref>, the nature of these techniques, in particular the centrality of the underlying representations used (i.e. sigmoid or radial basis - 7 - functions in neural nets, bitstrings in GAs) restricts the ways in which the problem can be approached.
References-found: 10

