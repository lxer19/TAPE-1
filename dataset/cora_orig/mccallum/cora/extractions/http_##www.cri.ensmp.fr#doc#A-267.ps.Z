URL: http://www.cri.ensmp.fr/doc/A-267.ps.Z
Refering-URL: http://www.cri.ensmp.fr/rapports.html
Root-URL: 
Title: A Linear Algebra Framework for Static HPF Code Distribution  
Author: Corinne Ancourt, Fabien Coelho, Fran~cois Irigoin, Ronan Keryell Fabien Coelho. 
Address: 35, rue Saint-Honore, 77305 Fontainebleau cedex, France.  
Affiliation: Centre de Recherche en Informatique, Ecole Nationale Superieure des Mines de Paris,  
Note: Corresponding author:  ftp:  
Email: anonymous@ftp.cri.ensmp.fr  
Phone: Phone: +33 1 64 69 47 08. Fax: 33 1 64 69 47 09.  
Date: May 27, 1995  
Web: URL: http://www.cri.ensmp.fr,  
Abstract: fl An early version of this paper was presented at the Fourth International Workshop on Compilers for Parallel Computers held in Delft, the Netherlands, December 1993. y fancourt,coelho,irigoin,keryellg@cri.ensmp.fr, http://www.cri.ensmp.fr/~f...g 1 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1986. </year>
Reference-contexts: Many partial optimization techniques are integrated in our direct synthesis approach: message vectorization, and aggregation [37], overlap analysis [31]. A new storage management scheme is also proposed. Moreover other optimizations techniques may be applied to the generated code such as vectorization [69], loop invariant code motion <ref> [1] </ref> and software pipelining [30, 66]. A polyhedron-based approach is already implemented in our prototype Hpf compiler [22] to deal I/O communications in a host and nodes model [23].
Reference: [2] <author> Saman P. Amarasinghe and Monica S. Lam. </author> <title> Communication Optimization and Code Generation for Distributed Memory Machines. </title> <booktitle> In ACM SIGPLAN International Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: Algorithms presented in [4] or others <ref> [28, 24, 40, 2, 20, 19, 48, 46, 41, 68] </ref> can be used to generate the loop nest enumerating the local iterations. When S is of rank jaj, optimal code is generated because no projections are required. <p> Stichnoth uses the dual method for array allocation as in [22], that is blocks are first compressed, and the cycle number is used as a second argument. In [3, 5] polyhedron based techniques are presented to generate transfer code for machines with a memory hierarchy. In <ref> [2, 64] </ref> advanced analyses are used as an input to a code generation phase for distributed memory machines. Polyhedron scanning techniques are used for generating the code. Two familly of techniques have been suggested for that purpose. <p> In [2, 64] advanced analyses are used as an input to a code generation phase for distributed memory machines. Polyhedron scanning techniques are used for generating the code. Two familly of techniques have been suggested for that purpose. First, Fourier elimination based techniques <ref> [4, 40, 2, 48, 46, 41, 68] </ref>, and second, parametric integer programming based methods [28, 24, 20, 19]. In [12], a two-fold Hermite transformation is also used to remove modulo indexing from Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 49 a loop nest.
Reference: [3] <author> Corinne Ancourt. </author> <title> Generation automatique de codes de transfert pour multiprocesseurs a memoires locales. </title> <type> PhD thesis, </type> <institution> Universite Paris VI, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: Arrays are densely allocated as in [21] and the initial order is preserved but no formulae are given. Stichnoth uses the dual method for array allocation as in [22], that is blocks are first compressed, and the cycle number is used as a second argument. In <ref> [3, 5] </ref> polyhedron based techniques are presented to generate transfer code for machines with a memory hierarchy. In [2, 64] advanced analyses are used as an input to a code generation phase for distributed memory machines. Polyhedron scanning techniques are used for generating the code.
Reference: [4] <author> Corinne Ancourt and Fran~cois Irigoin. </author> <title> Scanning polyhedra with DO loops. </title> <booktitle> In Symposium on Principles and Practice of Parallel Programming, </booktitle> <month> April </month> <year> 1991. </year>
Reference-contexts: If regions are not precise enough because convex hulls are used to summarize multiple references, it is possible to use additional parameters to exactly express a set of references <ref> [4] </ref>. This might be useful for red-black sor. <p> When no replication occurs, elementary data communications implied by Send Y and Receive Y can be parametrically enumerated in basis (p; u), where u is a basis for Y 0 , the local part of Y. Send and Receive are polyhedral sets and algorithms in <ref> [4] </ref> can be used. <p> Algorithms presented in <ref> [4] </ref> or others [28, 24, 40, 2, 20, 19, 48, 46, 41, 68] can be used to generate the loop nest enumerating the local iterations. When S is of rank jaj, optimal code is generated because no projections are required. <p> Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 46 Note that an extra-loop is generated. Y diagonal can be enumerated with only two loops and three are generated. This is due to the use of an imprecise projection algorithm but does not endanger correctness <ref> [4] </ref>. Further work is needed in this area. 5.5 Integer divide One implementation of the integer divide is finally shown. The divider is assumed strictly positive, as is the case in all call sites. It necessary because Fortran remainder is not positive for negative numbers. <p> In [2, 64] advanced analyses are used as an input to a code generation phase for distributed memory machines. Polyhedron scanning techniques are used for generating the code. Two familly of techniques have been suggested for that purpose. First, Fourier elimination based techniques <ref> [4, 40, 2, 48, 46, 41, 68] </ref>, and second, parametric integer programming based methods [28, 24, 20, 19]. In [12], a two-fold Hermite transformation is also used to remove modulo indexing from Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 49 a loop nest.
Reference: [5] <author> Corinne Ancourt and Fran~cois Irigoin. </author> <title> Automatic code distribution. </title> <booktitle> In Third Workshop on Compilers for Parallel Computers, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: When Y (or X, or Z,...) is referenced many times in the input loop or in the input program, these references must be clustered according to their connexity in the dependence graph <ref> [5] </ref>. Input dependencies are taken into account as well as usual ones (flow-, anti- and output-dependencies). <p> Arrays are densely allocated as in [21] and the initial order is preserved but no formulae are given. Stichnoth uses the dual method for array allocation as in [22], that is blocks are first compressed, and the cycle number is used as a second argument. In <ref> [3, 5] </ref> polyhedron based techniques are presented to generate transfer code for machines with a memory hierarchy. In [2, 64] advanced analyses are used as an input to a code generation phase for distributed memory machines. Polyhedron scanning techniques are used for generating the code.
Reference: [6] <author> Fran~coise Andre, Olivier Cheron, and Jean-Louis Pazat. </author> <title> Compiling sequential programs for distributed memory parallel computers with Pandore II. </title> <type> Technical report, </type> <institution> IRISA, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: Techniques and prototypes have been developed based on Fortran [31, 32, 37, 15, 53, 70, 16, 17], C <ref> [8, 49, 6, 47, 7] </ref> or others languages [57, 58, 45, 51, 44]. The most obvious, most general and safest technique is called run-time resolution [18, 54, 57]. Each instruction is guarded by a condition that is true for processors that must execute it.
Reference: [7] <author> Fran~coise Andre, Marc Le Fur, Yves Maheo, and Jean-Louis Pazat. </author> <title> Parallelization of a Wave Propagation Application using a Data Parallel Compiler. </title> <note> Publication interne 868, IRISA, </note> <month> October </month> <year> 1994. </year>
Reference-contexts: Techniques and prototypes have been developed based on Fortran [31, 32, 37, 15, 53, 70, 16, 17], C <ref> [8, 49, 6, 47, 7] </ref> or others languages [57, 58, 45, 51, 44]. The most obvious, most general and safest technique is called run-time resolution [18, 54, 57]. Each instruction is guarded by a condition that is true for processors that must execute it.
Reference: [8] <author> Fran~coise Andre, Jean-Louis Pazat, and Henry Thomas. </author> <title> Pandore: A system to manage data distribution. </title> <note> Publication Interne 519, IRISA, February 1990. Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 52 </note>
Reference-contexts: Techniques and prototypes have been developed based on Fortran [31, 32, 37, 15, 53, 70, 16, 17], C <ref> [8, 49, 6, 47, 7] </ref> or others languages [57, 58, 45, 51, 44]. The most obvious, most general and safest technique is called run-time resolution [18, 54, 57]. Each instruction is guarded by a condition that is true for processors that must execute it.
Reference: [9] <author> Beatrice Apvrille. </author> <title> Calcul de regions de tableaux exactes. </title> <booktitle> In Rencontres Francophones du Parallelisme, </booktitle> <pages> pages 65-68, </pages> <month> June </month> <year> 1994. </year>
Reference: [10] <author> Beatrice Apvrille-Creusillet. </author> <title> Regions exactes et privatisation de tableaux (exact array region analysis and array privatization). </title> <type> Master's thesis, </type> <institution> Universite Paris VI, France, </institution> <month> September </month> <year> 1994. </year> <note> Available via http://www.cri.ensmp.fr/~creusil. </note>
Reference: [11] <author> Beatrice Apvrille-Creusillet. </author> <title> Calcul de regions de tableaux exactes. </title> <journal> TSI, Numero special RenPar'6, </journal> <month> mai </month> <year> 1995. </year>
Reference: [12] <author> Florin Balasa, Frank H. M. Fransen, Francky V. M. Catthoor, and Hugo J. De Man. </author> <title> Transformation on nested loops with modulo indexing to affine recur-rences. </title> <journal> Parallel Processing Letters, </journal> <volume> 4(3) </volume> <pages> 271-280, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: Polyhedron scanning techniques are used for generating the code. Two familly of techniques have been suggested for that purpose. First, Fourier elimination based techniques [4, 40, 2, 48, 46, 41, 68], and second, parametric integer programming based methods [28, 24, 20, 19]. In <ref> [12] </ref>, a two-fold Hermite transformation is also used to remove modulo indexing from Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 49 a loop nest.
Reference: [13] <author> Siegfried Benkner. </author> <title> Handling block-cyclic distributed arrays in vienna fortran. </title> <type> TR 94 9, </type> <institution> Institute for Software Technology and Parallel Systems, University of Vienna, </institution> <month> November </month> <year> 1994. </year>
Reference-contexts: Each dimension is independent of the others as was assumed in Sec- tion 4.3. Paalvast et al. [55, 65] are dealing with distribution without template. The subscript function can be an affine alignment function. The same kind of techniques is used by Benkner et al. <ref> [14, 13] </ref>. Chatterjee et al. [21] developed a finite state machine approach to enumerate local elements. No memory space is wasted and local array elements are ordered by Fortran lexico-graphic order exactly like user array elements.
Reference: [14] <author> Siegfried Benkner, Peter Brezany, and Hans Zima. </author> <title> Processing array statements and procedure interfaces in the prepare high performance fortran compiler. </title> <booktitle> In 5th International Conference on Compiler Construction, </booktitle> <address> April 1994. </address> <publisher> Springer-Verlag LNCS vol. </publisher> <pages> 786, pages 324-338. </pages>
Reference-contexts: Each dimension is independent of the others as was assumed in Sec- tion 4.3. Paalvast et al. [55, 65] are dealing with distribution without template. The subscript function can be an affine alignment function. The same kind of techniques is used by Benkner et al. <ref> [14, 13] </ref>. Chatterjee et al. [21] developed a finite state machine approach to enumerate local elements. No memory space is wasted and local array elements are ordered by Fortran lexico-graphic order exactly like user array elements.
Reference: [15] <author> Thomas Brandes. </author> <title> Efficient data parallel programming without explicit message passing for distributed memory multiprocessors. </title> <type> Internal Report AHR-92 4, </type> <institution> High Performance Computing Center, German National Research Institute for Computer Science, </institution> <month> September </month> <year> 1992. </year>
Reference-contexts: The definition of the new language, Hpf, was frozen in May 1993 [29] and the first compilers are already available <ref> [15, 16, 22, 63, 50] </ref>. This quick delivery was made possible by defining a subset of the language which only allows static distribution of data and prohibits dynamic redistribution. <p> Techniques and prototypes have been developed based on Fortran <ref> [31, 32, 37, 15, 53, 70, 16, 17] </ref>, C [8, 49, 6, 47, 7] or others languages [57, 58, 45, 51, 44]. The most obvious, most general and safest technique is called run-time resolution [18, 54, 57].
Reference: [16] <author> Thomas Brandes. </author> <title> Adaptor: A compilation system for data parallel fortran pro-grams. </title> <type> Technical report, </type> <institution> High Performance Computing Center, German National Research Institute for Computer Science, </institution> <month> August </month> <year> 1993. </year> <note> Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 53 </note>
Reference-contexts: The definition of the new language, Hpf, was frozen in May 1993 [29] and the first compilers are already available <ref> [15, 16, 22, 63, 50] </ref>. This quick delivery was made possible by defining a subset of the language which only allows static distribution of data and prohibits dynamic redistribution. <p> Techniques and prototypes have been developed based on Fortran <ref> [31, 32, 37, 15, 53, 70, 16, 17] </ref>, C [8, 49, 6, 47, 7] or others languages [57, 58, 45, 51, 44]. The most obvious, most general and safest technique is called run-time resolution [18, 54, 57].
Reference: [17] <author> Thomas Brandes. </author> <title> Evaluation of high performance fortran on some real applica-tions. In High-Performance Computing and Networking, </title> <publisher> Springer-Verlag LNCS 797, </publisher> <pages> pages 417-422, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Techniques and prototypes have been developed based on Fortran <ref> [31, 32, 37, 15, 53, 70, 16, 17] </ref>, C [8, 49, 6, 47, 7] or others languages [57, 58, 45, 51, 44]. The most obvious, most general and safest technique is called run-time resolution [18, 54, 57].
Reference: [18] <author> David Callahan and Ken Kennedy. </author> <title> Compiling programs for distributed-memory multiprocessors. </title> <journal> The Journal of Supercomputing, </journal> <volume> 2 </volume> <pages> 151-169, </pages> <year> 1988. </year>
Reference-contexts: It was added to insure the semantics of the output code. Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 47 6 Related work Techniques to generate distributed code from sequential or parallel code using a uniform memory space have been extensively studied since 1988 <ref> [18, 54, 71] </ref>. Techniques and prototypes have been developed based on Fortran [31, 32, 37, 15, 53, 70, 16, 17], C [8, 49, 6, 47, 7] or others languages [57, 58, 45, 51, 44]. The most obvious, most general and safest technique is called run-time resolution [18, 54, 57]. <p> Techniques and prototypes have been developed based on Fortran [31, 32, 37, 15, 53, 70, 16, 17], C [8, 49, 6, 47, 7] or others languages [57, 58, 45, 51, 44]. The most obvious, most general and safest technique is called run-time resolution <ref> [18, 54, 57] </ref>. Each instruction is guarded by a condition that is true for processors that must execute it. <p> This rewriting scheme is easy to implement [22] but very inefficient at run-time because guards, tests, sends and receives are pure overhead. Moreover every processor has to execute the whole control flow of the program, and even for parallel loop, communications may sequentialize the program at run-time <ref> [18] </ref>. Many optimization techniques have been introduced to handle specific cases. Gerndt introduced overlap analysis in [31] for block distributions.
Reference: [19] <author> Zbigniew Chamski. </author> <title> Fast and efficient generation of loop bounds. </title> <note> Research Report 2095, INRIA, </note> <month> October </month> <year> 1993. </year>
Reference-contexts: Algorithms presented in [4] or others <ref> [28, 24, 40, 2, 20, 19, 48, 46, 41, 68] </ref> can be used to generate the loop nest enumerating the local iterations. When S is of rank jaj, optimal code is generated because no projections are required. <p> Polyhedron scanning techniques are used for generating the code. Two familly of techniques have been suggested for that purpose. First, Fourier elimination based techniques [4, 40, 2, 48, 46, 41, 68], and second, parametric integer programming based methods <ref> [28, 24, 20, 19] </ref>. In [12], a two-fold Hermite transformation is also used to remove modulo indexing from Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 49 a loop nest.
Reference: [20] <author> Zbigniew Chamski. </author> <title> Nested loop sequences: Towards efficient loop structures in automatic parallelization. </title> <note> Research Report 2094, INRIA, </note> <month> October </month> <year> 1993. </year> <booktitle> In Proceedings of the 27th Annual Hawaii Int. Conf. on System Sciences, 1994, p. </booktitle> <pages> 14-22. </pages>
Reference-contexts: Algorithms presented in [4] or others <ref> [28, 24, 40, 2, 20, 19, 48, 46, 41, 68] </ref> can be used to generate the loop nest enumerating the local iterations. When S is of rank jaj, optimal code is generated because no projections are required. <p> Polyhedron scanning techniques are used for generating the code. Two familly of techniques have been suggested for that purpose. First, Fourier elimination based techniques [4, 40, 2, 48, 46, 41, 68], and second, parametric integer programming based methods <ref> [28, 24, 20, 19] </ref>. In [12], a two-fold Hermite transformation is also used to remove modulo indexing from Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 49 a loop nest.
Reference: [21] <author> Siddhartha Chatterjee, John R. Gilbert, Fred J. E. Long, Robert Schreiber, and Shang-Hua Teng. </author> <title> Generating local addresses and communication sets for dataparallel programs. </title> <booktitle> In Symposium on Principles and Practice of Parallel Programming, </booktitle> <year> 1993. </year>
Reference-contexts: This is the case when array sections are used as in <ref> [21, 34, 61] </ref>. <p> The geometric intuition of the packing scheme for one dimension, still in the example in <ref> [21] </ref> displayed on Figure 5, is shown in Figure 10 for the first processor of the dimension. The "ffi" and "*" are just used to support the geometrical intuition of the change of frame. <p> Constraints may also be simplified, for instance if the concerned elements just match a cycle. Moreover, it is possible to generate the loop nest directly on u 0 , when u is not used in the loop body. For the main example in <ref> [21] </ref>, such transformations produce the code shown in Figure 13. In the general resolution (Section 4.1) the cycle variables c were put after the local Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 35 offsets `. The induced inner loop nest is then on c. <p> Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 41 5 Examples The different algorithms presented in the previous section were used to distribute the contrived piece of code of Figure 16. This is an extension of an example given in <ref> [21] </ref> showing that allocation of Hpf arrays may be non-trivial. The reference to X in the first loop requires an allocation of X 0 and the computation of new loop bounds. <p> Paalvast et al. [55, 65] are dealing with distribution without template. The subscript function can be an affine alignment function. The same kind of techniques is used by Benkner et al. [14, 13]. Chatterjee et al. <ref> [21] </ref> developed a finite state machine approach to enumerate local elements. No memory space is wasted and local array elements are ordered by Fortran lexico-graphic order exactly like user array elements. <p> They use array sections but compute some of the coefficients at run-time. Gupta et al. solve the block distribution case and use processor virtualization to handle cyclic distributions. Arrays are densely allocated as in <ref> [21] </ref> and the initial order is preserved but no formulae are given. Stichnoth uses the dual method for array allocation as in [22], that is blocks are first compressed, and the cycle number is used as a second argument.
Reference: [22] <author> Fabien Coelho. </author> <title> Etude de la Compilation du high performance fortran. </title> <type> Master's thesis, </type> <institution> Universite Paris VI, </institution> <month> September </month> <year> 1993. </year> <institution> Rapport de DEA Systemes Informatiques. TR EMP E/178/CRI. </institution>
Reference-contexts: The definition of the new language, Hpf, was frozen in May 1993 [29] and the first compilers are already available <ref> [15, 16, 22, 63, 50] </ref>. This quick delivery was made possible by defining a subset of the language which only allows static distribution of data and prohibits dynamic redistribution. <p> Each memory address is checked before it is referenced to decide whether the address is local and the reference is executed, whether it is remote, and a receive is executed, or whether it is remotely accessed and a send is executed. This rewriting scheme is easy to implement <ref> [22] </ref> but very inefficient at run-time because guards, tests, sends and receives are pure overhead. Moreover every processor has to execute the whole control flow of the program, and even for parallel loop, communications may sequentialize the program at run-time [18]. <p> Gupta et al. solve the block distribution case and use processor virtualization to handle cyclic distributions. Arrays are densely allocated as in [21] and the initial order is preserved but no formulae are given. Stichnoth uses the dual method for array allocation as in <ref> [22] </ref>, that is blocks are first compressed, and the cycle number is used as a second argument. In [3, 5] polyhedron based techniques are presented to generate transfer code for machines with a memory hierarchy. <p> A new storage management scheme is also proposed. Moreover other optimizations techniques may be applied to the generated code such as vectorization [69], loop invariant code motion [1] and software pipelining [30, 66]. A polyhedron-based approach is already implemented in our prototype Hpf compiler <ref> [22] </ref> to deal I/O communications in a host and nodes model [23]. Future work includes the implementation of the presented scheme in our compiler, extensions to optimize sequential loops, to overlap communication and computation, and to handle indirections.
Reference: [23] <author> Fabien Coelho. </author> <title> Compilation of I/O communications for HPF. </title> <booktitle> In 5th Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 102-109, </pages> <month> February </month> <year> 1995. </year> <note> Also available as TR-CRI A/264. </note>
Reference-contexts: Moreover other optimizations techniques may be applied to the generated code such as vectorization [69], loop invariant code motion [1] and software pipelining [30, 66]. A polyhedron-based approach is already implemented in our prototype Hpf compiler [22] to deal I/O communications in a host and nodes model <ref> [23] </ref>. Future work includes the implementation of the presented scheme in our compiler, extensions to optimize sequential loops, to overlap communication and computation, and to handle indirections.
Reference: [24] <author> Jean-Fran~cois Collard, Paul Feautrier, and Tanguy Risset. </author> <title> Construction of DO loops from Systems of Affine Constraints. LIP RR93 15, </title> <address> ENS-Lyon, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Algorithms presented in [4] or others <ref> [28, 24, 40, 2, 20, 19, 48, 46, 41, 68] </ref> can be used to generate the loop nest enumerating the local iterations. When S is of rank jaj, optimal code is generated because no projections are required. <p> Polyhedron scanning techniques are used for generating the code. Two familly of techniques have been suggested for that purpose. First, Fourier elimination based techniques [4, 40, 2, 48, 46, 41, 68], and second, parametric integer programming based methods <ref> [28, 24, 20, 19] </ref>. In [12], a two-fold Hermite transformation is also used to remove modulo indexing from Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 49 a loop nest.
Reference: [25] <editor> Beatrice Creusillet. Analyse de flot de donnees : Regions de tableaux IN et OUT. In Rencontres Francophones du Parallelisme, </editor> <month> mai-juin </month> <year> 1995. </year> <note> Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 54 </note>
Reference: [26] <author> Beatrice Creusillet. </author> <title> IN and OUT array region analyses. </title> <booktitle> In Workshop on Compilers for Parallel Computers, </booktitle> <month> June </month> <year> 1995. </year>
Reference: [27] <author> Beatrice Creusillet and Fran~cois Irigoin. </author> <title> Interprocedural array regions analyses. </title> <type> Technical report A-270, </type> <institution> CRI, cole des mines de Paris, </institution> <month> March </month> <year> 1995. </year> <note> Submitted to LCPC'95. </note>
Reference: [28] <author> Paul Feautrier. </author> <title> Parametric integer programming. </title> <journal> RAIRO Recherche Operationnelle, </journal> <volume> 22 </volume> <pages> 243-268, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: A combined cost function might even be better by taking advantage of the Manhattan distance to minimize the number of hops and of the lexicographical minimum to insure uniqueness. These problems can be cast as linear parametric problems and solved <ref> [28] </ref>. When no replication occurs, elementary data communications implied by Send Y and Receive Y can be parametrically enumerated in basis (p; u), where u is a basis for Y 0 , the local part of Y. Send and Receive are polyhedral sets and algorithms in [4] can be used. <p> Algorithms presented in [4] or others <ref> [28, 24, 40, 2, 20, 19, 48, 46, 41, 68] </ref> can be used to generate the loop nest enumerating the local iterations. When S is of rank jaj, optimal code is generated because no projections are required. <p> Polyhedron scanning techniques are used for generating the code. Two familly of techniques have been suggested for that purpose. First, Fourier elimination based techniques [4, 40, 2, 48, 46, 41, 68], and second, parametric integer programming based methods <ref> [28, 24, 20, 19] </ref>. In [12], a two-fold Hermite transformation is also used to remove modulo indexing from Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 49 a loop nest.
Reference: [29] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran Language Specification. </title> <institution> Rice University, Houston, Texas, </institution> <month> May </month> <year> 1993. </year> <note> Version 1.0. </note>
Reference-contexts: The definition of the new language, Hpf, was frozen in May 1993 <ref> [29] </ref> and the first compilers are already available [15, 16, 22, 63, 50]. This quick delivery was made possible by defining a subset of the language which only allows static distribution of data and prohibits dynamic redistribution. <p> The relations between the global programmer space and the local processor spaces can also be used to translate sequential loops with a run-time resolution mechanism or with some optimizations. The reader is assumed knowledgeable in Hpf directives <ref> [29] </ref> and optimization techniques for Hpf [31, 63]. The paper is organized as follows. Section 2 shows how Hpf directives can be expressed as affine constraints and normalized to simplify the compilation process and its description. <p> Alignments are specified dimension-wise with integer affine expressions as template subscript expressions. Each array index can be used at most once in a template subscript expression in any given alignment, and each subscript expression cannot contain more than one index <ref> [29] </ref>. <p> The extents (n in BLOCK (n) or CYCLIC (n)) are stored in a diagonal matrix, C. P is a square matrix with the size of the processor dimensions on the diagonal. Such a distribution is not linear according to its definition <ref> [29, page 27] </ref> but may be written as a linear relation between the processor coordinate p, the template coordinate t and two additional variables, ` and c: t = CP c + Cp + ` (3) Vector ` represents the offset within one block in one processor and vector c represents
Reference: [30] <author> Franco Gasperoni and Uwe Scheiegelshohn. </author> <title> Scheduling loop on parallel processors: A simple algorithm with close to optimum performance. </title> <note> Lecture Note, INRIA, </note> <year> 1992. </year>
Reference-contexts: A new storage management scheme is also proposed. Moreover other optimizations techniques may be applied to the generated code such as vectorization [69], loop invariant code motion [1] and software pipelining <ref> [30, 66] </ref>. A polyhedron-based approach is already implemented in our prototype Hpf compiler [22] to deal I/O communications in a host and nodes model [23].
Reference: [31] <author> Hans Michael Gerndt. </author> <title> Automatic Parallelization for Distributed-Memory Multiprocessing Systems. </title> <type> PhD thesis, </type> <institution> University of Vienna, </institution> <year> 1989. </year>
Reference-contexts: Manufacturers and research laboratories, led by Digital and Rice University, decided in 1991 to shift part of the burden onto compilers by providing the programmer a uniform address space to allocate objects and a (mainly) implicit way to express parallelism. Numerous research projects <ref> [31, 37, 63] </ref> and a few commercial products had shown that this goal could be achieved and the High Performance Fortran Forum was set up to select the most useful functionalities and to standardize the syntax. <p> The resulting code is a pair of loops that can be compiled by our scheme, following the owner-computes rule, if the ON clause is put into the affine framework. This compilation scheme directly generates optimized code which includes techniques such as guard elimination <ref> [31] </ref>, message vectorization and aggregation [37, 63], and is compatible overlap analysis [31]. There are no restrictions neither on the kind of distribution, block or cyclic, nor on the rank of array references. The memory allocation part is independent of parallel loops and can always be used. <p> This compilation scheme directly generates optimized code which includes techniques such as guard elimination <ref> [31] </ref>, message vectorization and aggregation [37, 63], and is compatible overlap analysis [31]. There are no restrictions neither on the kind of distribution, block or cyclic, nor on the rank of array references. The memory allocation part is independent of parallel loops and can always be used. <p> The relations between the global programmer space and the local processor spaces can also be used to translate sequential loops with a run-time resolution mechanism or with some optimizations. The reader is assumed knowledgeable in Hpf directives [29] and optimization techniques for Hpf <ref> [31, 63] </ref>. The paper is organized as follows. Section 2 shows how Hpf directives can be expressed as affine constraints and normalized to simplify the compilation process and its description. <p> This optimization is known as overlap analysis <ref> [31] </ref>. Once remote values are copied into the overlapping Y 0 , all elements of View Y (p) can be accessed uniformly in Y 0 with no overhead. <p> Thus the local cache and/or prefetch mechanisms, if any, are efficiently used. The packing scheme is also compatible with overlap analysis techniques <ref> [31] </ref>. Local array declarations are extended to provide space for border elements that are owned by neighbor processors, and to simplify accesses to non-local elements. The overlap is induced by relaxing constraints on `, which is transformed through the scheme as relaxed constraints on u 0 2 . <p> Techniques and prototypes have been developed based on Fortran <ref> [31, 32, 37, 15, 53, 70, 16, 17] </ref>, C [8, 49, 6, 47, 7] or others languages [57, 58, 45, 51, 44]. The most obvious, most general and safest technique is called run-time resolution [18, 54, 57]. <p> Moreover every processor has to execute the whole control flow of the program, and even for parallel loop, communications may sequentialize the program at run-time [18]. Many optimization techniques have been introduced to handle specific cases. Gerndt introduced overlap analysis in <ref> [31] </ref> for block distributions. <p> Such a scheme could reuse HPF distribution to map HPF processors on physical processors. Many partial optimization techniques are integrated in our direct synthesis approach: message vectorization, and aggregation [37], overlap analysis <ref> [31] </ref>. A new storage management scheme is also proposed. Moreover other optimizations techniques may be applied to the generated code such as vectorization [69], loop invariant code motion [1] and software pipelining [30, 66].
Reference: [32] <author> Hans Michael Gerndt and Hans Peter Zima. </author> <title> Optimizing communication in superb. </title> <booktitle> In CONPAR90, </booktitle> <pages> pages 300-311, </pages> <year> 1990. </year>
Reference-contexts: Techniques and prototypes have been developed based on Fortran <ref> [31, 32, 37, 15, 53, 70, 16, 17] </ref>, C [8, 49, 6, 47, 7] or others languages [57, 58, 45, 51, 44]. The most obvious, most general and safest technique is called run-time resolution [18, 54, 57].
Reference: [33] <author> Philippe Granger. </author> <title> Analyses Semantiques de Congruence. </title> <type> PhD thesis, </type> <institution> Ecole Polytechnique, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: Linearity of access to temporary elements is preserved. The correctness of the scheme is shown by proving that a unique location y 0 is associated to each y. Further insight on this problem, the minimal covering of a set by interval congruences, can be found in Granger <ref> [33] </ref> and Masdupuy [52]. 4.7 Data movements The relationships between the bases and frames defined in the previous sections are shown in Figure 15. Three areas are distinguished. The top one contains user level bases for iterations, i, and array elements, a X , a Y ,...
Reference: [34] <author> S. K. S. Gupta, S. D. Kaushik, S. Mufti, S. Sharma, C.-H. Huang, and P. Sadayappan. </author> <title> On compiling array expressions for efficient execution on distributed-memory machines. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <pages> pages II-301-II305, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: This is the case when array sections are used as in <ref> [21, 34, 61] </ref>. <p> Kennedy et al. [43, 42, 38, 36] have suggested improvements to this technique, essentially to compute faster the automaton transition map. Papers by Stichnoth et al. [61, 60] on the one hand and Gupta et al. <ref> [34, 35] </ref> on the other present two similar methods to solve the same problem. They use array sections but compute some of the coefficients at run-time. Gupta et al. solve the block distribution case and use processor virtualization to handle cyclic distributions.
Reference: [35] <author> S.K.S. Gupta, S. D. Kaushik, C.-H. Huang, and P. Sadayappan. </author> <title> On compiling array expressions for efficient execution on distributed-memory machines. </title> <type> TR 19, </type> <institution> Ancourt et al., </institution> <note> A Linear Algebra: : : , Submitted to Scientific Programming 55 Department of Computer and Information Science, </note> <institution> The Ohio State University, </institution> <year> 1994. </year>
Reference-contexts: Kennedy et al. [43, 42, 38, 36] have suggested improvements to this technique, essentially to compute faster the automaton transition map. Papers by Stichnoth et al. [61, 60] on the one hand and Gupta et al. <ref> [34, 35] </ref> on the other present two similar methods to solve the same problem. They use array sections but compute some of the coefficients at run-time. Gupta et al. solve the block distribution case and use processor virtualization to handle cyclic distributions.
Reference: [36] <author> Seema Hiranandani, Ken Kennedy, John Mellor-Crummey, and Ajay Sethi. </author> <title> Compilation techniques for block-cyclic distributions. </title> <booktitle> In ACM International Conference on Supercomputing, </booktitle> <month> pages ??-??, July </month> <year> 1994. </year>
Reference-contexts: Note that the code generated in Figure 9 may be used to compute the fsm. In fact the lower iteration of the innermost loop is computed by the algorithm that constructs the fsm. Kennedy et al. <ref> [43, 42, 38, 36] </ref> have suggested improvements to this technique, essentially to compute faster the automaton transition map. Papers by Stichnoth et al. [61, 60] on the one hand and Gupta et al. [34, 35] on the other present two similar methods to solve the same problem.
Reference: [37] <author> Seema Hiranandani, Ken Kennedy, and Chau-Wen Tseng. </author> <title> Compiling Fortran D for MIMD Distributed-Memory machines. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 66-80, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Manufacturers and research laboratories, led by Digital and Rice University, decided in 1991 to shift part of the burden onto compilers by providing the programmer a uniform address space to allocate objects and a (mainly) implicit way to express parallelism. Numerous research projects <ref> [31, 37, 63] </ref> and a few commercial products had shown that this goal could be achieved and the High Performance Fortran Forum was set up to select the most useful functionalities and to standardize the syntax. <p> The resulting code is a pair of loops that can be compiled by our scheme, following the owner-computes rule, if the ON clause is put into the affine framework. This compilation scheme directly generates optimized code which includes techniques such as guard elimination [31], message vectorization and aggregation <ref> [37, 63] </ref>, and is compatible overlap analysis [31]. There are no restrictions neither on the kind of distribution, block or cyclic, nor on the rank of array references. The memory allocation part is independent of parallel loops and can always be used. <p> Techniques and prototypes have been developed based on Fortran <ref> [31, 32, 37, 15, 53, 70, 16, 17] </ref>, C [8, 49, 6, 47, 7] or others languages [57, 58, 45, 51, 44]. The most obvious, most general and safest technique is called run-time resolution [18, 54, 57]. <p> Such a scheme could reuse HPF distribution to map HPF processors on physical processors. Many partial optimization techniques are integrated in our direct synthesis approach: message vectorization, and aggregation <ref> [37] </ref>, overlap analysis [31]. A new storage management scheme is also proposed. Moreover other optimizations techniques may be applied to the generated code such as vectorization [69], loop invariant code motion [1] and software pipelining [30, 66].
Reference: [38] <author> Semma Hirannandani, Ken Kennedy, John Mellor-Crummey, and Ajay Sethi. </author> <title> Advanced compilation techniques for fortran d. </title> <type> CRPC-TR 93338, </type> <institution> Center for Research on Parallel Computation, Rice University, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: Note that the code generated in Figure 9 may be used to compute the fsm. In fact the lower iteration of the innermost loop is computed by the algorithm that constructs the fsm. Kennedy et al. <ref> [43, 42, 38, 36] </ref> have suggested improvements to this technique, essentially to compute faster the automaton transition map. Papers by Stichnoth et al. [61, 60] on the one hand and Gupta et al. [34, 35] on the other present two similar methods to solve the same problem.
Reference: [39] <author> Fran~cois Irigoin. </author> <title> Interprocedural analyses for programming environment. </title> <editor> In Jack J. Dongara and Bernard Tourancheau, editors, </editor> <booktitle> Environments and Tools for Parallel Scientific Computing, </booktitle> <pages> pages 333-350, </pages> <address> Saint-Hilaire-du-Touvet, September 1992. </address> <publisher> North-Holland, </publisher> <address> Amsterdam, NSF-CNRS. </address>
Reference: [40] <author> Wayne Kelly and William Pugh. </author> <title> A framework for unifying reordering transforma-tions. </title> <type> UMIACS-TR-93 134, </type> <institution> Institute for Advanced Computer Studies, University of Maryland, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: Algorithms presented in [4] or others <ref> [28, 24, 40, 2, 20, 19, 48, 46, 41, 68] </ref> can be used to generate the loop nest enumerating the local iterations. When S is of rank jaj, optimal code is generated because no projections are required. <p> In [2, 64] advanced analyses are used as an input to a code generation phase for distributed memory machines. Polyhedron scanning techniques are used for generating the code. Two familly of techniques have been suggested for that purpose. First, Fourier elimination based techniques <ref> [4, 40, 2, 48, 46, 41, 68] </ref>, and second, parametric integer programming based methods [28, 24, 20, 19]. In [12], a two-fold Hermite transformation is also used to remove modulo indexing from Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 49 a loop nest.
Reference: [41] <author> Wayne Kelly, William Pugh, and Evan Rosser. </author> <title> Code generation for multiple map-pings. </title> <booktitle> In 5th Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 332-341, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: Algorithms presented in [4] or others <ref> [28, 24, 40, 2, 20, 19, 48, 46, 41, 68] </ref> can be used to generate the loop nest enumerating the local iterations. When S is of rank jaj, optimal code is generated because no projections are required. <p> In [2, 64] advanced analyses are used as an input to a code generation phase for distributed memory machines. Polyhedron scanning techniques are used for generating the code. Two familly of techniques have been suggested for that purpose. First, Fourier elimination based techniques <ref> [4, 40, 2, 48, 46, 41, 68] </ref>, and second, parametric integer programming based methods [28, 24, 20, 19]. In [12], a two-fold Hermite transformation is also used to remove modulo indexing from Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 49 a loop nest.
Reference: [42] <author> Ken Kennedy, Nenad Nedeljkovic, and Ajay Sethi. </author> <title> Efficient address generation for block-cyclic distributions. CRPC-TR 94497-S, Center for Research on Parallel Computation, </title> <institution> Rice University, </institution> <month> December </month> <year> 1994. </year> <note> Submitted to ICS'95. Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 56 </note>
Reference-contexts: Note that the code generated in Figure 9 may be used to compute the fsm. In fact the lower iteration of the innermost loop is computed by the algorithm that constructs the fsm. Kennedy et al. <ref> [43, 42, 38, 36] </ref> have suggested improvements to this technique, essentially to compute faster the automaton transition map. Papers by Stichnoth et al. [61, 60] on the one hand and Gupta et al. [34, 35] on the other present two similar methods to solve the same problem.
Reference: [43] <author> Ken Kennedy, Nenad Nedeljkovic, and Ajay Sethi. </author> <title> A linear time algorithm for computing the memory access sequence in data-parallel programs. CRPC-TR 94485-S, Center for Research on Parallel Computation, </title> <institution> Rice University, </institution> <month> October </month> <year> 1994. </year> <note> Submitted to PPoPP'95. </note>
Reference-contexts: Note that the code generated in Figure 9 may be used to compute the fsm. In fact the lower iteration of the innermost loop is computed by the algorithm that constructs the fsm. Kennedy et al. <ref> [43, 42, 38, 36] </ref> have suggested improvements to this technique, essentially to compute faster the automaton transition map. Papers by Stichnoth et al. [61, 60] on the one hand and Gupta et al. [34, 35] on the other present two similar methods to solve the same problem.
Reference: [44] <author> Charles Koelbel and Piyush Mehrotra. </author> <title> Compiling global name-space parallel loops for distributed execution. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4) </volume> <pages> 440-451, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Techniques and prototypes have been developed based on Fortran [31, 32, 37, 15, 53, 70, 16, 17], C [8, 49, 6, 47, 7] or others languages <ref> [57, 58, 45, 51, 44] </ref>. The most obvious, most general and safest technique is called run-time resolution [18, 54, 57]. Each instruction is guarded by a condition that is true for processors that must execute it.
Reference: [45] <author> Charles Koelbel, Piyush Mehrotra, and John Van Rosendale. </author> <title> Supporting shared data structures on distributed memory architectures. </title> <type> Technical Report ASD 915, </type> <institution> Purdue University, </institution> <month> January </month> <year> 1990. </year>
Reference-contexts: Techniques and prototypes have been developed based on Fortran [31, 32, 37, 15, 53, 70, 16, 17], C [8, 49, 6, 47, 7] or others languages <ref> [57, 58, 45, 51, 44] </ref>. The most obvious, most general and safest technique is called run-time resolution [18, 54, 57]. Each instruction is guarded by a condition that is true for processors that must execute it.
Reference: [46] <author> Marc Le Fur. </author> <title> Scanning Parametrized Polyhedron using Fourier-Motzkin Elimination. </title> <note> Publication interne 858, IRISA, </note> <month> September </month> <year> 1994. </year>
Reference-contexts: Algorithms presented in [4] or others <ref> [28, 24, 40, 2, 20, 19, 48, 46, 41, 68] </ref> can be used to generate the loop nest enumerating the local iterations. When S is of rank jaj, optimal code is generated because no projections are required. <p> In [2, 64] advanced analyses are used as an input to a code generation phase for distributed memory machines. Polyhedron scanning techniques are used for generating the code. Two familly of techniques have been suggested for that purpose. First, Fourier elimination based techniques <ref> [4, 40, 2, 48, 46, 41, 68] </ref>, and second, parametric integer programming based methods [28, 24, 20, 19]. In [12], a two-fold Hermite transformation is also used to remove modulo indexing from Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 49 a loop nest.
Reference: [47] <author> Marc Le Fur, Jean-Louis Pazat, and Fran~coise Andre. </author> <title> Commutative loop nests distribution. </title> <booktitle> In Workshop on Compilers for Parallel Computers, Delft, </booktitle> <pages> pages 345350, </pages> <month> December </month> <year> 1993. </year> <note> extended version in IRISA TR 757, Sept. 93. </note>
Reference-contexts: Techniques and prototypes have been developed based on Fortran [31, 32, 37, 15, 53, 70, 16, 17], C <ref> [8, 49, 6, 47, 7] </ref> or others languages [57, 58, 45, 51, 44]. The most obvious, most general and safest technique is called run-time resolution [18, 54, 57]. Each instruction is guarded by a condition that is true for processors that must execute it.
Reference: [48] <author> Herve Le Verge, Vincent Van Dongen, and Doran K. Wilde. </author> <title> Loop nest synthesis unsing the polyhedral library. </title> <note> Publication interne 830, IRISA, </note> <month> May </month> <year> 1994. </year>
Reference-contexts: Algorithms presented in [4] or others <ref> [28, 24, 40, 2, 20, 19, 48, 46, 41, 68] </ref> can be used to generate the loop nest enumerating the local iterations. When S is of rank jaj, optimal code is generated because no projections are required. <p> In [2, 64] advanced analyses are used as an input to a code generation phase for distributed memory machines. Polyhedron scanning techniques are used for generating the code. Two familly of techniques have been suggested for that purpose. First, Fourier elimination based techniques <ref> [4, 40, 2, 48, 46, 41, 68] </ref>, and second, parametric integer programming based methods [28, 24, 20, 19]. In [12], a two-fold Hermite transformation is also used to remove modulo indexing from Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 49 a loop nest.
Reference: [49] <author> Oded Lempel, Shlomit S. Pinter, and Eli Turiel. </author> <title> Parallelizing a C dialect for Distributed Memory MIMD machines. </title> <booktitle> In Language and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1992. </year>
Reference-contexts: Techniques and prototypes have been developed based on Fortran [31, 32, 37, 15, 53, 70, 16, 17], C <ref> [8, 49, 6, 47, 7] </ref> or others languages [57, 58, 45, 51, 44]. The most obvious, most general and safest technique is called run-time resolution [18, 54, 57]. Each instruction is guarded by a condition that is true for processors that must execute it.
Reference: [50] <author> John Levesque. </author> <title> FORGE 90 and High Performance Fortran. Applied Parallel Research, </title> <publisher> Inc., </publisher> <year> 1992. </year> <note> xHPF77 presentation. </note>
Reference-contexts: The definition of the new language, Hpf, was frozen in May 1993 [29] and the first compilers are already available <ref> [15, 16, 22, 63, 50] </ref>. This quick delivery was made possible by defining a subset of the language which only allows static distribution of data and prohibits dynamic redistribution.
Reference: [51] <author> J. Li and Marina Chen. </author> <title> Compiling communication-efficient programs for mas-sively parallel machines. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(3) </volume> <pages> 361-376, </pages> <month> July </month> <year> 1991. </year> <note> Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 57 </note>
Reference-contexts: Techniques and prototypes have been developed based on Fortran [31, 32, 37, 15, 53, 70, 16, 17], C [8, 49, 6, 47, 7] or others languages <ref> [57, 58, 45, 51, 44] </ref>. The most obvious, most general and safest technique is called run-time resolution [18, 54, 57]. Each instruction is guarded by a condition that is true for processors that must execute it.
Reference: [52] <author> Fran~cois Masdupuy. </author> <title> Array Indices Relational Semantic Analysis using Rational Cosets and Trapezoids. </title> <type> PhD thesis, </type> <institution> Ecole Polytechnique, </institution> <month> November </month> <year> 1993. </year> <note> Technical Report EMP-CRI A/247. </note>
Reference-contexts: The correctness of the scheme is shown by proving that a unique location y 0 is associated to each y. Further insight on this problem, the minimal covering of a set by interval congruences, can be found in Granger [33] and Masdupuy <ref> [52] </ref>. 4.7 Data movements The relationships between the bases and frames defined in the previous sections are shown in Figure 15. Three areas are distinguished. The top one contains user level bases for iterations, i, and array elements, a X , a Y ,...
Reference: [53] <author> John Merlin. </author> <title> Techniques for the automatic parallelisation of `Distributed Fortran 90'. </title> <type> SNARC 92 02, </type> <institution> University of Southampton, </institution> <year> 1992. </year>
Reference-contexts: Techniques and prototypes have been developed based on Fortran <ref> [31, 32, 37, 15, 53, 70, 16, 17] </ref>, C [8, 49, 6, 47, 7] or others languages [57, 58, 45, 51, 44]. The most obvious, most general and safest technique is called run-time resolution [18, 54, 57].
Reference: [54] <author> Ravi Mirchandaney, Joel S. Saltz, Roger M. Smith, David M. Nicol, and Kay Crowley. </author> <title> Principles of runtime support for parallel processors. </title> <booktitle> In ACM International Conference on Supercomputing, </booktitle> <pages> pages 140-152, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: It was added to insure the semantics of the output code. Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 47 6 Related work Techniques to generate distributed code from sequential or parallel code using a uniform memory space have been extensively studied since 1988 <ref> [18, 54, 71] </ref>. Techniques and prototypes have been developed based on Fortran [31, 32, 37, 15, 53, 70, 16, 17], C [8, 49, 6, 47, 7] or others languages [57, 58, 45, 51, 44]. The most obvious, most general and safest technique is called run-time resolution [18, 54, 57]. <p> Techniques and prototypes have been developed based on Fortran [31, 32, 37, 15, 53, 70, 16, 17], C [8, 49, 6, 47, 7] or others languages [57, 58, 45, 51, 44]. The most obvious, most general and safest technique is called run-time resolution <ref> [18, 54, 57] </ref>. Each instruction is guarded by a condition that is true for processors that must execute it.
Reference: [55] <author> Edwin M. Paalvast, Henk J. Sips, and A.J. van Gemund. </author> <title> Automatic parallel program generation and optimization from data decompositions. </title> <booktitle> In 1991 International Conference on Parallel Processing | Volume II : Software, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: Ancourt et al., A Linear Algebra: : : , Submitted to Scientific Programming 48 Recent publications tackle any alignment and distribution but restrict references to array sections. Each dimension is independent of the others as was assumed in Sec- tion 4.3. Paalvast et al. <ref> [55, 65] </ref> are dealing with distribution without template. The subscript function can be an affine alignment function. The same kind of techniques is used by Benkner et al. [14, 13]. Chatterjee et al. [21] developed a finite state machine approach to enumerate local elements.
Reference: [56] <author> William Pugh. </author> <title> A pratical algorithm for exact array dependence analysis. </title> <journal> CACM, </journal> <volume> 35(8) </volume> <pages> 102-114, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: When S is of rank jaj, optimal code is generated because no projections are required. Otherwise, the quality of the control overhead depends on the accuracy of integer projections <ref> [56] </ref> but the correctness does not.
Reference: [57] <author> Anne Rogers and Keshav Pingali. </author> <title> Process decomposition through locality of ref-erence. </title> <booktitle> In ACM SIGPLAN International Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: Techniques and prototypes have been developed based on Fortran [31, 32, 37, 15, 53, 70, 16, 17], C [8, 49, 6, 47, 7] or others languages <ref> [57, 58, 45, 51, 44] </ref>. The most obvious, most general and safest technique is called run-time resolution [18, 54, 57]. Each instruction is guarded by a condition that is true for processors that must execute it. <p> Techniques and prototypes have been developed based on Fortran [31, 32, 37, 15, 53, 70, 16, 17], C [8, 49, 6, 47, 7] or others languages [57, 58, 45, 51, 44]. The most obvious, most general and safest technique is called run-time resolution <ref> [18, 54, 57] </ref>. Each instruction is guarded by a condition that is true for processors that must execute it.
Reference: [58] <author> Anne Rogers and Keshav Pingali. </author> <title> Compiling for distributed memory architectures, </title> <month> June </month> <year> 1992. </year> <title> communication personnelle, sans doute un rapport technique. </title>
Reference-contexts: Techniques and prototypes have been developed based on Fortran [31, 32, 37, 15, 53, 70, 16, 17], C [8, 49, 6, 47, 7] or others languages <ref> [57, 58, 45, 51, 44] </ref>. The most obvious, most general and safest technique is called run-time resolution [18, 54, 57]. Each instruction is guarded by a condition that is true for processors that must execute it.
Reference: [59] <author> Alexander Schrijver. </author> <title> Theory of linear and integer programming. </title> <publisher> Wiley, </publisher> <address> New-York, </address> <year> 1986. </year>
Reference-contexts: First the constant unknown parameters, n the value of which are known at runtime. Second, the parameters we are interested in, that have to be enumerated or instantiated on each processor to scan the integer solutions to the Hpf equations, namely the variables in vector x. An Hermite form <ref> [59] </ref> of integer matrix F is used to find the parameters. This form associates to F three matrices H, P and Q, such that H = P F Q. P is a permutation, H a lower triangular integer matrix and Q a unimodular change of basis.
Reference: [60] <author> J. Stichnoth, D. O'Hallaron, and T. Gross. </author> <title> Generating communication for array statements: Design, implementation and evaluation. </title> <booktitle> In Language and Compilers for Parallel Computing, </booktitle> <month> pages ??-??, August </month> <year> 1993. </year>
Reference-contexts: In fact the lower iteration of the innermost loop is computed by the algorithm that constructs the fsm. Kennedy et al. [43, 42, 38, 36] have suggested improvements to this technique, essentially to compute faster the automaton transition map. Papers by Stichnoth et al. <ref> [61, 60] </ref> on the one hand and Gupta et al. [34, 35] on the other present two similar methods to solve the same problem. They use array sections but compute some of the coefficients at run-time.
References-found: 60

