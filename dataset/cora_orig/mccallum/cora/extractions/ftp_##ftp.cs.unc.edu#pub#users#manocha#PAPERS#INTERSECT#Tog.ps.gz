URL: ftp://ftp.cs.unc.edu/pub/users/manocha/PAPERS/INTERSECT/Tog.ps.gz
Refering-URL: http://www.cs.unc.edu/~geom/CSG/intersect.html
Root-URL: http://www.cs.unc.edu
Title: Algorithms for Intersecting Parametric and Algebraic Curves I: Simple Intersections  
Author: Dinesh Manocha James Demmel 
Address: Chapel Hill, NC 27599  Berkeley, CA 94720  
Affiliation: Department of Computer Science Computer Science Division and University of North Carolina at Chapel Hill Mathematics Department  University of California at Berkeley  
Note: To Appear in ACM Transactions on Graphics  
Abstract: The problem of computing the intersection of parametric and algebraic curves arises in many applications of computer graphics and geometric and solid modeling. Previous algorithms are based on techniques from elimination theory or subdivision and iteration. The former is however, restricted to low degree curves. This is mainly due to issues of efficiency and numerical stability. In this paper we use elimination theory and express the resultant of the equations of intersection as a matrix determinant. The matrix itself rather than its symbolic determinant, a polynomial, is used as the representation. The problem of intersection is reduced to computing the eigenvalues and eigenvectors of a numeric matrix. The main advantage of this approach lies in its efficiency and robustness. Moreover, the numerical accuracy of these operations is well understood. For almost all cases we are able to compute accurate answers in 64 bit IEEE floating point arithmetic. Keywords: Intersection, curves, algebraic, parametric, eigenvalues, robustness, resultants 
Abstract-found: 1
Intro-found: 1
Reference: [ABB + 92] <author> E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. Du Croz, A. Greenbaum, S. Hammarling, and D. Sorensen. </author> <title> LAPACK User's Guide, Release 1.0. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1992. </year>
Reference-contexts: The algorithms for computing eigenvalues and eigenvectors of a matrix are backward stable 3 and fast implementations are available as part of packages like EISPACK and 3 An eigendecomposition algorithm is backward stable if it computes the exact eigendecomposition 2 LAPACK <ref> [GL89, ABB + 92] </ref>. The algorithm for intersecting algebraic curves is similar to that for parametric curves. The rest of the paper is organized in the following manner. In Section 2 we present our notation and review techniques from elimination theory for implicitizing parametric curves. <p> As a result, the eigenvalues of a diagonal matrix, upper triangular matrix or a lower triangular matrix are the elements on its diagonal. Efficient algorithms for computing eigenvalues and eigenvectors are well known [GL89], and their implementations are available as part of packages EISPACK, [GBDM77], and LAPACK <ref> [Dem89, ABB + 92] </ref>. Most algorithms make use of the similarity transformations of the form A 0 12 where Q is any non-singular n fi n matrix. This transformation has the characteristic that the eigenvalues of A and A 0 are identical. <p> Higher multiplicity eigenvalues are being considered in [MD92]. 3.7 Accuracy of Right Eigenvectors Detailed error bounds for eigenvectors are given in <ref> [Wil65, ABB + 92] </ref>. We will not use these detailed bounds beyond the following implication: Since we will later need to take ratios of certain eigenvector components, we want to choose those components with the highest relative accuracy. <p> Furthermore, we also compute the condition number of each eigenvalue in the domain of interest. The condition number computation requires the left as well right eigenvectors of the matrix. We used the LAPACK implementation of the QR algorithm for eigendecomposi-tion <ref> [ABB + 92] </ref>. The QR algorithm computes all the eigenvalues of the given matrix. However, we are interested in the positive real eigenvalues only.
Reference: [BBB87] <author> R.H. Bartels, J.C. Beatty, and B.A. Barsky. </author> <title> An Introduction to Splines for use in Computer Graphics & Geometric Modeling. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1987. </year> <month> 27 </month>
Reference-contexts: Given the eigenvalues and eigenvectors, we compute the intersection points of parametric curves in the domain of interest. We also discuss the performance and robustness of the resulting algorithm. 2 Parametric and Algebraic Curves A rational Bezier curve is of the form <ref> [BBB87] </ref>: P (t) = (X (t); Y (t)) = i=0 w i P i B i;n (t) i=0 w i B i;n (t) where P i = (X i ; Y i ) are the coordinates of a control point, w i is the weight of the control point and B <p> Other rational formulations like B-splines can be converted into a series of rational Bezier curves by knot insertion algorithms <ref> [BBB87] </ref>. Thus, the problem of intersecting rational curves can be reduced to intersecting rational Bezier curves. Each of these curves is described by its corresponding control polygon and the curve is always contained in the convex hull of the control points.
Reference: [BD93] <author> Z. Bai and J. Demmel. </author> <title> Design of a parallel nonsymmetric eigenroutine toolbox, Part I. </title> <booktitle> In Proceedings of the Sixth SIAM Conference on Parallel Proceesing for Scientific Computing. </booktitle> <publisher> SIAM, </publisher> <year> 1993. </year> <note> Long version available as UC Berkeley Computer Science report UCB/CSD/92-718. </note>
Reference-contexts: The QR algorithm computes all the eigenvalues of the given matrix. It is difficult to restrict them to computing eigenvalues in the domain of interest without any heuristics, although some progress on large matrices on parallel machines has recently been made <ref> [BD93] </ref>. The order of the matrix, say p, corresponds to the product of the degree of the two curves and the number of eigenvalues is equal to the order of the matrix. The running time of the algorithm is a cubic function of p. However, eigenvalue algorithms have good convergence.
Reference: [BDM93] <author> Z. Bai, J. Demmel, and A. McKenney. </author> <title> On computing condition numbers for the nonsymmetric eigenproblem. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 19(3) </volume> <pages> 202-223, </pages> <year> 1993. </year>
Reference-contexts: These condition numbers are used to bound errors in computed solutions of numerical problems. More details on condition numbers are given in [GL89, Wil65]. The implementations of these condition number computations are available as part of LAPACK <ref> [BDM93] </ref>. In our intersection algorithm, we will be performing computations like matrix inversion and computing eigenvalues and eigenvectors of a matrix.
Reference: [CK92] <author> G.E. Collins and W. Krandick. </author> <title> An efficient algorithm for infallible polynomial complex root isolation. </title> <booktitle> In Proceedings of International Symposium on Symbolic and Algebraic Computation, </booktitle> <pages> pages 189-194, </pages> <address> Berkeley, California, </address> <year> 1992. </year>
Reference-contexts: Intersection is a primitive operation in the computation of a boundary representation from a CSG (constructive solid geometry) model in a CAD system. Other applications of intersection include hidden curve removal for free form surfaces, finding complex roots of polynomials etc. <ref> [EC90, CK92] </ref>. Algorithms for computing the intersection of these curves have been extensively studied in the literature. As far as computing the intersection of rational parametric curves is concerned, algorithms based on implicitization [Sed83], Bezier subdivision [LR80] and interval arithmetic [KM83] are well known.
Reference: [Dem89] <author> J. Demmel. </author> <title> LAPACK: A portable linear algebra library for supercomputers. </title> <booktitle> In Proceedings of the 1989 IEEE Control Systems Society Workshop on Computer-Aided Control System Design, </booktitle> <address> Tampa, FL, </address> <month> Dec </month> <year> 1989. </year> <note> IEEE. </note>
Reference-contexts: As a result, the eigenvalues of a diagonal matrix, upper triangular matrix or a lower triangular matrix are the elements on its diagonal. Efficient algorithms for computing eigenvalues and eigenvectors are well known [GL89], and their implementations are available as part of packages EISPACK, [GBDM77], and LAPACK <ref> [Dem89, ABB + 92] </ref>. Most algorithms make use of the similarity transformations of the form A 0 12 where Q is any non-singular n fi n matrix. This transformation has the characteristic that the eigenvalues of A and A 0 are identical.
Reference: [EC90] <author> G. Elber and E. Cohen. </author> <title> Hidden curve removal for free form surfaces. </title> <journal> Computer Graphics, </journal> <volume> 24(4) </volume> <pages> 95-104, </pages> <year> 1990. </year>
Reference-contexts: Intersection is a primitive operation in the computation of a boundary representation from a CSG (constructive solid geometry) model in a CAD system. Other applications of intersection include hidden curve removal for free form surfaces, finding complex roots of polynomials etc. <ref> [EC90, CK92] </ref>. Algorithms for computing the intersection of these curves have been extensively studied in the literature. As far as computing the intersection of rational parametric curves is concerned, algorithms based on implicitization [Sed83], Bezier subdivision [LR80] and interval arithmetic [KM83] are well known.
Reference: [FR87] <author> R.T. Farouki and V.T. Rajan. </author> <title> On the numerical condition of polynomials in bernstein form. </title> <booktitle> Computer Aided Geometric Design, </booktitle> <volume> 4 </volume> <pages> 191-216, </pages> <year> 1987. </year>
Reference-contexts: The algorithm for computing the entries of the matrix assumes that the polynomi als x (t); y (t); w (t) are expressed in the power basis. However, converting from Bezier to power basis can introduce numerical errors <ref> [FR87] </ref>. To circumvent this problem we perform a reparametrization.
Reference: [GBDM77] <author> B.S. Garbow, J.M. Boyle, J. Dongarra, and C.B. Moler. </author> <title> Matrix Eigensys-tem Routines - EISPACK Guide Extension, </title> <booktitle> volume 51 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1977. </year>
Reference-contexts: As a result, the eigenvalues of a diagonal matrix, upper triangular matrix or a lower triangular matrix are the elements on its diagonal. Efficient algorithms for computing eigenvalues and eigenvectors are well known [GL89], and their implementations are available as part of packages EISPACK, <ref> [GBDM77] </ref>, and LAPACK [Dem89, ABB + 92]. Most algorithms make use of the similarity transformations of the form A 0 12 where Q is any non-singular n fi n matrix. This transformation has the characteristic that the eigenvalues of A and A 0 are identical. <p> A better algorithm, called the QZ algorithm [GL89], applies orthogonal transformations to A and B to reduce A to Hessenberg form, to reduce B to upper triangular form, and then implicitly perform the QR algorithm on B 1 A without ever forming it. This algorithm is in EISPACK <ref> [GBDM77] </ref> and in the most recent release of LAPACK. It's running time is O (n 3 ). However, the constant can be as high as 75.
Reference: [GL89] <author> G.H. Golub and C.F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> John Hopkins Press, </publisher> <address> Baltimore, </address> <year> 1989. </year>
Reference-contexts: The algorithms for computing eigenvalues and eigenvectors of a matrix are backward stable 3 and fast implementations are available as part of packages like EISPACK and 3 An eigendecomposition algorithm is backward stable if it computes the exact eigendecomposition 2 LAPACK <ref> [GL89, ABB + 92] </ref>. The algorithm for intersecting algebraic curves is similar to that for parametric curves. The rest of the paper is organized in the following manner. In Section 2 we present our notation and review techniques from elimination theory for implicitizing parametric curves. <p> As a result, the eigenvalues of a diagonal matrix, upper triangular matrix or a lower triangular matrix are the elements on its diagonal. Efficient algorithms for computing eigenvalues and eigenvectors are well known <ref> [GL89] </ref>, and their implementations are available as part of packages EISPACK, [GBDM77], and LAPACK [Dem89, ABB + 92]. Most algorithms make use of the similarity transformations of the form A 0 12 where Q is any non-singular n fi n matrix. <p> Furthermore, if y is an eigenvector of A , Q 1 y is an eigenvector of A. Standard algorithms for eigenvalue computations, like the QR algorithm, choose Q to be an orthogonal matrix, since similarity transformation by an orthogonal matrix is a numerically stable operation <ref> [GL89] </ref>. Q is an orthogonal matrix if QQ T = I. Given A, the eigendecomposition algorithm converts it into a Hessenberg matrix, H, using a sequence of similarity transformations by orthogonal matrices. <p> Given U and R, the next step of the iteration computes a modified Hessenberg matrix given by H = RU + qI: The shifts are chosen appropriately such that the matrix converges to its to its real Schur decomposition of the form <ref> [GL89, Wil65] </ref>: QAQ 1 = B B B R 11 R 12 . . . R 1m . . . . . . 0 0 . . . <p> Given the real Schur decomposition, computing the eigenvalues is a trivial 13 operation. Often a matrix has complex eigenvalues and the above algorithm is mod-ified to double shift consisting of a complex number and its conjugate. More details are given in <ref> [GL89] </ref>. We will use the QR algorithm with double implicit shift strategy to compute the real Schur decomposition. Given the matrix eigenvalues, real Schur decomposition and matrix Q, computing eigenvectors corresponds to solving quasi triangular systems [GL89, Wil65]. The running time of these algorithms is O (n 3 ). <p> More details are given in [GL89]. We will use the QR algorithm with double implicit shift strategy to compute the real Schur decomposition. Given the matrix eigenvalues, real Schur decomposition and matrix Q, computing eigenvectors corresponds to solving quasi triangular systems <ref> [GL89, Wil65] </ref>. The running time of these algorithms is O (n 3 ). However, the constant in front of n 3 can be as high as 25 for computing all the eigen-values and eigenvectors. In many cases we may a priori know some of the eigenvalues of the given matrix. <p> A better algorithm, called the QZ algorithm <ref> [GL89] </ref>, applies orthogonal transformations to A and B to reduce A to Hessenberg form, to reduce B to upper triangular form, and then implicitly perform the QR algorithm on B 1 A without ever forming it. This algorithm is in EISPACK [GBDM77] and in the most recent release of LAPACK. <p> The i 's are called the singular values and columns of U and V, denoted as u i 's and v j 's, are known as the left and right singular vectors, respectively <ref> [GL89] </ref>. The relationship between the elements of A, singular values and singular vectors can be expressed as: A ij = n where A ij ; U ij ; V ij represent the element in the ith row and jth column of A; U and V, respectively. <p> The matrix A has rank k &lt; n, if k+1 = 0; k+2 = 0; . . . ; n = 0. Furthermore, the smallest positive singular value gives us information about the closeness to a rank deficient matrix <ref> [GL89] </ref>. 3.4 Condition Numbers The condition number of a problem measures the sensitivity of a solution to small changes in the input. A problem is ill-conditioned if its condition number is large, and ill-posed if its condition number is infinite. <p> A problem is ill-conditioned if its condition number is large, and ill-posed if its condition number is infinite. These condition numbers are used to bound errors in computed solutions of numerical problems. More details on condition numbers are given in <ref> [GL89, Wil65] </ref>. The implementations of these condition number computations are available as part of LAPACK [BDM93]. In our intersection algorithm, we will be performing computations like matrix inversion and computing eigenvalues and eigenvectors of a matrix.
Reference: [GLR82] <author> I. Gohberg, P. Lancaster, and L. Rodman. </author> <title> Matrix Polynomials. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: More details on matrix polynomials and their properties are given in <ref> [GLR82] </ref>. <p> Q.E.D. The matrix polynomials have been used to solve general systems of non-linear polynomial equations. More details are highlighted in [Man92]. The relationship between the eigenvalues of C and the roots of P (s) has been proved using similarity transformations in <ref> [GLR82] </ref>. At times the leading matrix M n is singular or close to being singular (due to high condition number). Therefore, reducing it to an eigenvalue problem using Theorem 4.1 may not be numerically stable. In such cases, we reduce the intersection problem to a generalized eigenvalue problem. <p> I m 3 7 7 7 7 ; where 0 and I m are m fi m null and identity matrices, respectively. The proof of this theorem is similar to that of Theorem 4.1 and can also be proved using similarity transformations, as highlighted in <ref> [GLR82] </ref>. It follows from Theorem 4.1 that the eigenvalues of C correspond exactly to the preimages of intersection points on Q (u).
Reference: [GSA84] <author> R. Goldman, T.W. Sederberg, and D. C. Anderson. </author> <title> Vector elimination: A technique for the implicitization, inversion and intersection of planar parametric rational polynomial curves. </title> <booktitle> Computer Aided Geometric Design, </booktitle> <volume> 1(4) </volume> <pages> 327-356, </pages> <year> 1984. </year>
Reference-contexts: Cayley's formulation highlighted above is used for implicitizing parametric curves and eliminating a variable from a pair of bivariate algebraic equations, representing algebraic plane curves. It has also been used to implicitize Bezier curves in <ref> [GSA84] </ref>. 2.2 Implicitizing Parametric Curves Given a rational Bezier curve, P (t), we express it in homogeneous form as p (t) = (x (t); y (t); w (t)) = ( m i=0 w i Y i B i;m (t); m 5 We assume that the curve, P (t) has a proper
Reference: [Hob91] <author> J.D. </author> <title> Hobby. Numerically stable implicitization of cubic curves. </title> <journal> ACM Transactions on Graphics, </journal> <volume> 10(3) </volume> <pages> 255-296, </pages> <year> 1991. </year> <month> 28 </month>
Reference-contexts: This is mainly due to issues of numerical stability and their effect on the choice of representation and algorithms for root finding. As far as computation of implicit representation is concerned, stable algorithms are available for curves of degree up to three <ref> [Hob91] </ref>. Furthermore, for curves of degree up to three, the entries of the matrix are represented as polynomials in power basis and the roots of its determinant are computed using a standard polynomial solver, such as Jenkins-Traub [SP86].
Reference: [Hof89] <author> C.M. Hoffmann. </author> <title> Geometric and Solid Modeling. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1989. </year>
Reference-contexts: 1 Introduction The problems of computing the intersection of parametric and algebraic curves are fundamental to geometric and solid modeling. Parametric curves, like B-splines and Bezier curves, are extensively used in the modeling systems and algebraic plane curves are becoming popular as well <ref> [Hof89, MM89, SP86, Sed89] </ref>. Intersection is a primitive operation in the computation of a boundary representation from a CSG (constructive solid geometry) model in a CAD system. Other applications of intersection include hidden curve removal for free form surfaces, finding complex roots of polynomials etc. [EC90, CK92]. <p> The other possibility is to use Sylvester's formulation of the resultant of two polynomial equations. After eliminating y from the two equations, Sylvester's resultant produces a matrix of order m + n, M (x). The construction of Sylvester's resultant is explained in <ref> [Hof89] </ref>. 3 Matrix Computations In this section we review some techniques from linear algebra and numerical analysis. We also discuss the numerical accuracy of the problems in terms of their condition number and the algorithms used to solve those problems.
Reference: [KM83] <author> P.A. Koparkar and S. P. Mudur. </author> <title> A new class of algorithms for the processing of parametric curves. </title> <booktitle> Computer-Aided Design, </booktitle> <volume> 15(1) </volume> <pages> 41-45, </pages> <year> 1983. </year>
Reference-contexts: Algorithms for computing the intersection of these curves have been extensively studied in the literature. As far as computing the intersection of rational parametric curves is concerned, algorithms based on implicitization [Sed83], Bezier subdivision [LR80] and interval arithmetic <ref> [KM83] </ref> are well known. The implicitization approach is based on the fact that every rational parametric curve can be implicitized into an algebraic plane curve of the form F (x; y) = 0, where F (x; y) is a bivariate polynomial.
Reference: [LR80] <author> J.M. Lane and R.F. Riesenfeld. </author> <title> A theoretical development for the computer generation and display of piecewise polynomial surfaces. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 2(1) </volume> <pages> 150-159, </pages> <year> 1980. </year>
Reference-contexts: Algorithms for computing the intersection of these curves have been extensively studied in the literature. As far as computing the intersection of rational parametric curves is concerned, algorithms based on implicitization [Sed83], Bezier subdivision <ref> [LR80] </ref> and interval arithmetic [KM83] are well known. The implicitization approach is based on the fact that every rational parametric curve can be implicitized into an algebraic plane curve of the form F (x; y) = 0, where F (x; y) is a bivariate polynomial.
Reference: [Mac02] <author> F.S. </author> <title> Macaulay. On some formula in elimination. </title> <booktitle> Proceedings of London Mathematical Society, </booktitle> <pages> pages 3-27, </pages> <month> May </month> <year> 1902. </year>
Reference-contexts: Its results have been known a century ago <ref> [Mac02, Sal85] </ref>. The main result is the construction of a single resultant polynomial such that the vanishing of the resultant is the necessary and sufficient condition for the given system of equations to have a non-trivial solution.
Reference: [Man90] <author> D. Manocha. </author> <title> Regular curves and proper parametrizations. </title> <booktitle> In Proceedings of International Symposium on Symbolic and Algebraic Computations, </booktitle> <pages> pages 271-276, </pages> <year> 1990. </year>
Reference-contexts: In other words, there is more than one value of the parameter t, which gives rise to the point S. At such points, the curve has more than one place [Wal50]. Algorithms to compute the proper parametrizations of curves have been described in <ref> [Man90, MC92, Sed86] </ref>. A simple version of Bezout's theorem is used for determining the number of intersections between a curve of degree m and that of degree n [Wal50]. It is assumed that the curves have no component in common.
Reference: [Man92] <author> D. Manocha. </author> <title> Algebraic and Numeric Techniques for Modeling and Robotics. </title> <type> PhD thesis, </type> <institution> Computer Science Division, Department of Electrical Engineering and Computer Science, University of California, Berkeley, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: In this paper we will be dealing with resultants of two polynomials in one unknown. Surveys on various formulations of resultants are given in [Sed83, Stu91] and effective techniques for computing and applying them are presented in <ref> [Man92] </ref>. Given two polynomials in one unknown, their resultant is a polynomial in their coefficients. Moreover, the vanishing of the resultant is a necessary and sufficient condition for the two polynomials to have a common root. <p> Furthermore, C is a matrix of order mn and therefore, has mn eigenvalues. Thus, all the roots of P (s) correspond to the eigenvalues of C. Q.E.D. The matrix polynomials have been used to solve general systems of non-linear polynomial equations. More details are highlighted in <ref> [Man92] </ref>. The relationship between the eigenvalues of C and the roots of P (s) has been proved using similarity transformations in [GLR82]. At times the leading matrix M n is singular or close to being singular (due to high condition number).
Reference: [MC92] <author> D. Manocha and J.F. Canny. </author> <title> Detecting cusps and inflection points in curves. </title> <booktitle> Computer Aided Geometric Design, </booktitle> <volume> 9 </volume> <pages> 1-24, </pages> <year> 1992. </year>
Reference-contexts: In other words, there is more than one value of the parameter t, which gives rise to the point S. At such points, the curve has more than one place [Wal50]. Algorithms to compute the proper parametrizations of curves have been described in <ref> [Man90, MC92, Sed86] </ref>. A simple version of Bezout's theorem is used for determining the number of intersections between a curve of degree m and that of degree n [Wal50]. It is assumed that the curves have no component in common.
Reference: [MD92] <author> D. Manocha and J. Demmel. </author> <title> Algorithms for intersecting parametric and algebraic curves. </title> <type> Technical Report UCB/CSD 92/698, </type> <institution> Computer Science Division, University of California at Berkeley, </institution> <year> 1992. </year>
Reference-contexts: Singular or higher multiplicity points on the parametric curves are analyzed in <ref> [MD92] </ref> and many properties of the matrix corresponding to the implicit representation are being highlighted as well. <p> Then j s s j * 2 k P k 2 +O (* 2 Thus, for sufficiently small perturbations in the matrix, the perturbation in the eigen values is a function of k P k 2 . Higher multiplicity eigenvalues are being considered in <ref> [MD92] </ref>. 3.7 Accuracy of Right Eigenvectors Detailed error bounds for eigenvectors are given in [Wil65, ABB + 92]. <p> We use the property of the linear system of equations (5) and Theorem 4.1. Let us assume that (x 0 ; y 0 ; w 0 ) is a simple point on P (t). Algorithms to deal with higher multiplicity points are described in <ref> [MD92] </ref>. Substitute for (X; Y; W ) = (x 0 ; y 0 ; w 0 ) in the matrix, M as shown in (5), corresponding to the implicit representation of P (t). The resulting matrix is singular, and let us assume that its kernel has dimension one.
Reference: [MM89] <author> R.P. Markot and R. L. Magedson. </author> <title> Solutions of tangential surface and curve intersections. </title> <booktitle> Computer-Aided Design, </booktitle> <volume> 21(7) </volume> <pages> 421-427, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction The problems of computing the intersection of parametric and algebraic curves are fundamental to geometric and solid modeling. Parametric curves, like B-splines and Bezier curves, are extensively used in the modeling systems and algebraic plane curves are becoming popular as well <ref> [Hof89, MM89, SP86, Sed89] </ref>. Intersection is a primitive operation in the computation of a boundary representation from a CSG (constructive solid geometry) model in a CAD system. Other applications of intersection include hidden curve removal for free form surfaces, finding complex roots of polynomials etc. [EC90, CK92].
Reference: [Sal85] <author> G. Salmon. </author> <title> Lessons Introductory to the Modern Higher Algebra. G.E. </title> <publisher> Stechert & Co., </publisher> <address> New York, </address> <month> 1885. </month>
Reference-contexts: Its results have been known a century ago <ref> [Mac02, Sal85] </ref>. The main result is the construction of a single resultant polynomial such that the vanishing of the resultant is the necessary and sufficient condition for the given system of equations to have a non-trivial solution. <p> Moreover, the vanishing of the resultant is a necessary and sufficient condition for the two polynomials to have a common root. Three methods are known in the literature for computing the resultant, owing to Bezout or Cayley and Sylvester <ref> [Sal85] </ref>. Each of them expresses the resultant as determinant of a matrix. The order of the matrix is different for different methods. We use Cayley's formulation of Bezout resultant as it results in a matrix of lower order as compared to Sylvester's formulation. <p> P m1;m1 C C C 0 B B B B 1 x 2 x m1 C C C C A Let us denote the m fi m matrix by M. The determinant of M is the resultant of F (x) and G (x) <ref> [Sal85] </ref>. Let us assume that x = x 0 is a common root of the two polynomials. Therefore, P (x 0 ; ff) = 0 for all ff. As a result P i (x 0 ) = 0 for 0 i &lt; m.
Reference: [Sed83] <author> T.W. </author> <title> Sederberg. Implicit and Parametric Curves and Surfaces. </title> <type> PhD thesis, </type> <institution> Purdue University, </institution> <year> 1983. </year>
Reference-contexts: Algorithms for computing the intersection of these curves have been extensively studied in the literature. As far as computing the intersection of rational parametric curves is concerned, algorithms based on implicitization <ref> [Sed83] </ref>, Bezier subdivision [LR80] and interval arithmetic [KM83] are well known. The implicitization approach is based on the fact that every rational parametric curve can be implicitized into an algebraic plane curve of the form F (x; y) = 0, where F (x; y) is a bivariate polynomial. <p> Algorithms for implicitization make use of resultants and the computation involves expanding a symbolic determinant <ref> [Sed83] </ref>. Given the implicit representation of one curve, substitute the second parametrization and obtain a univariate polynomial in its parameter. The problem of intersection corresponds to computing the roots of the resulting polynomial. <p> As far as geometric and solid modeling are concerned, the use of resultants was resurrected by Sederberg for implicitizing parametric curves and surfaces <ref> [Sed83] </ref>. In this paper we will be dealing with resultants of two polynomials in one unknown. Surveys on various formulations of resultants are given in [Sed83, Stu91] and effective techniques for computing and applying them are presented in [Man92]. <p> As far as geometric and solid modeling are concerned, the use of resultants was resurrected by Sederberg for implicitizing parametric curves and surfaces [Sed83]. In this paper we will be dealing with resultants of two polynomials in one unknown. Surveys on various formulations of resultants are given in <ref> [Sed83, Stu91] </ref> and effective techniques for computing and applying them are presented in [Man92]. Given two polynomials in one unknown, their resultant is a polynomial in their coefficients. Moreover, the vanishing of the resultant is a necessary and sufficient condition for the two polynomials to have a common root. <p> The resulting vectors are multiplied by an orthogonal matrix to obtain the eigenvectors of C. The running time of these operations is O (qp 2 ). Example 4.3 We illustrate the algorithm by considering the intersection of two rational cubic Bezier curves. The example is taken from <ref> [Sed83] </ref>. The control points of 22 two Bezier curves along with the weights (as shown in Fig. 3) are (4; 1; 1), (5; 6; 2), (5; 0; 2), (6; 4; 1) and (7; 4; 1), (1; 2; 2),(9; 2; 2),(3; 4; 1).
Reference: [Sed86] <author> T.W. </author> <title> Sederberg. Improperly parametrized rational curves. </title> <booktitle> Computer Aided Geometric Design, </booktitle> <volume> 3 </volume> <pages> 67-75, </pages> <year> 1986. </year> <month> 29 </month>
Reference-contexts: In other words, there is more than one value of the parameter t, which gives rise to the point S. At such points, the curve has more than one place [Wal50]. Algorithms to compute the proper parametrizations of curves have been described in <ref> [Man90, MC92, Sed86] </ref>. A simple version of Bezout's theorem is used for determining the number of intersections between a curve of degree m and that of degree n [Wal50]. It is assumed that the curves have no component in common.
Reference: [Sed89] <author> T.W. </author> <title> Sederberg. Algorithms for algebraic curve intersection. </title> <journal> Computer--Aided Design, </journal> <volume> 21(9) </volume> <pages> 547-555, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction The problems of computing the intersection of parametric and algebraic curves are fundamental to geometric and solid modeling. Parametric curves, like B-splines and Bezier curves, are extensively used in the modeling systems and algebraic plane curves are becoming popular as well <ref> [Hof89, MM89, SP86, Sed89] </ref>. Intersection is a primitive operation in the computation of a boundary representation from a CSG (constructive solid geometry) model in a CAD system. Other applications of intersection include hidden curve removal for free form surfaces, finding complex roots of polynomials etc. [EC90, CK92]. <p> The problem of intersection corresponds to computing roots of the resulting univariate polynomial. This approach causes numerical problems for higher degree curves (greater than four). A robust algorithm based on subdivision has been presented in <ref> [Sed89] </ref>. However, resultant based algorithms are considered to be the fastest for lower degree curves. In this paper we present efficient and robust algorithms for intersecting parametric and algebraic curves. For parametric curves we implicitize one of the curves and represent the implicit form as a matrix determinant.
Reference: [SP86] <author> T.W. Sederberg and S.R. Parry. </author> <title> Comparison of three curve intersection algorithms. </title> <booktitle> Computer-Aided Design, </booktitle> <volume> 18(1) </volume> <pages> 58-63, </pages> <year> 1986. </year>
Reference-contexts: 1 Introduction The problems of computing the intersection of parametric and algebraic curves are fundamental to geometric and solid modeling. Parametric curves, like B-splines and Bezier curves, are extensively used in the modeling systems and algebraic plane curves are becoming popular as well <ref> [Hof89, MM89, SP86, Sed89] </ref>. Intersection is a primitive operation in the computation of a boundary representation from a CSG (constructive solid geometry) model in a CAD system. Other applications of intersection include hidden curve removal for free form surfaces, finding complex roots of polynomials etc. [EC90, CK92]. <p> Thus, we obtain a rectangular bounding box and the subdivision amounts to evaluating the coordinate of the midpoint of the interval and defining the resulting rectangles. The 1 rest is similar to subdivision. The relative performance and accuracy of these algorithms is highlighted in <ref> [SP86] </ref>. In particular, implicitization based approaches are considered faster than other intersection algorithms for curves of degree up to four. This includes faster subdivision based algorithms [SWZ89]. However, their relative performance degrades for higher degree curves. <p> Furthermore, for curves of degree up to three, the entries of the matrix are represented as polynomials in power basis and the roots of its determinant are computed using a standard polynomial solver, such as Jenkins-Traub <ref> [SP86] </ref>. For curves of degree greater than three, the resulting univariate polynomial has degree 16 or higher. The problem of computing real roots of such high degree polynomials is frequently ill-conditioned [Wil59].
Reference: [Stu91] <author> B. Sturmfels. </author> <title> Sparse elimination theory. </title> <editor> In D. Eisenbud and L. Rob-biano, editors, </editor> <title> Computational Algebraic Geometry and Commutative Algebra. </title> <publisher> Cambridge University Press, </publisher> <year> 1991. </year>
Reference-contexts: As far as geometric and solid modeling are concerned, the use of resultants was resurrected by Sederberg for implicitizing parametric curves and surfaces [Sed83]. In this paper we will be dealing with resultants of two polynomials in one unknown. Surveys on various formulations of resultants are given in <ref> [Sed83, Stu91] </ref> and effective techniques for computing and applying them are presented in [Man92]. Given two polynomials in one unknown, their resultant is a polynomial in their coefficients. Moreover, the vanishing of the resultant is a necessary and sufficient condition for the two polynomials to have a common root.
Reference: [SWZ89] <author> T.W. Sederberg, S. White, and A. Zundel. </author> <title> Fat arcs: A bounding region with cubic convergence. </title> <booktitle> Computer Aided Geometric Design, </booktitle> <volume> 6 </volume> <pages> 205-218, </pages> <year> 1989. </year>
Reference-contexts: With each subdivision, the new curve segments become increasingly better approximated by a straight line. After the two curves segments are approximated by straight lines up to certain tolerance, their intersection point is accepted as the intersection of two curves. It has been improved by <ref> [SWZ89] </ref> by more effective use of the convex hull property. The resulting algorithm has the flavor of a geometrically based interval Newton method and has better convergence behavior. The interval arithmetic approach uses an idea similar to subdivision. <p> The 1 rest is similar to subdivision. The relative performance and accuracy of these algorithms is highlighted in [SP86]. In particular, implicitization based approaches are considered faster than other intersection algorithms for curves of degree up to four. This includes faster subdivision based algorithms <ref> [SWZ89] </ref>. However, their relative performance degrades for higher degree curves. This is mainly due to issues of numerical stability and their effect on the choice of representation and algorithms for root finding.
Reference: [Wal50] <author> R.J. Walker. </author> <title> Algebraic Curves. </title> <publisher> Princeton University Press, </publisher> <address> New Jersey, </address> <year> 1950. </year>
Reference-contexts: Let S be one of these exceptional points. In other words, there is more than one value of the parameter t, which gives rise to the point S. At such points, the curve has more than one place <ref> [Wal50] </ref>. Algorithms to compute the proper parametrizations of curves have been described in [Man90, MC92, Sed86]. A simple version of Bezout's theorem is used for determining the number of intersections between a curve of degree m and that of degree n [Wal50]. <p> such points, the curve has more than one place <ref> [Wal50] </ref>. Algorithms to compute the proper parametrizations of curves have been described in [Man90, MC92, Sed86]. A simple version of Bezout's theorem is used for determining the number of intersections between a curve of degree m and that of degree n [Wal50]. It is assumed that the curves have no component in common.
Reference: [Wil59] <author> J.H. Wilkinson. </author> <title> The evaluation of the zeros of ill-conditioned polynomials. parts i and ii. </title> <journal> Numer. Math., </journal> <volume> 1 </volume> <pages> 150-166 and 167-180, </pages> <year> 1959. </year>
Reference-contexts: For curves of degree greater than three, the resulting univariate polynomial has degree 16 or higher. The problem of computing real roots of such high degree polynomials is frequently ill-conditioned <ref> [Wil59] </ref>. As a result the intersection algorithm involves representing matrix entries as linear combinations of Bernstein polynomials, multiplying Bernstein polynomials for expanding the determinant and using subdivision for computing the roots of the resulting polynomial.
Reference: [Wil65] <author> J.H. Wilkinson. </author> <title> The algebraic eigenvalue problem. </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1965. </year> <month> 30 </month>
Reference-contexts: Given U and R, the next step of the iteration computes a modified Hessenberg matrix given by H = RU + qI: The shifts are chosen appropriately such that the matrix converges to its to its real Schur decomposition of the form <ref> [GL89, Wil65] </ref>: QAQ 1 = B B B R 11 R 12 . . . R 1m . . . . . . 0 0 . . . <p> More details are given in [GL89]. We will use the QR algorithm with double implicit shift strategy to compute the real Schur decomposition. Given the matrix eigenvalues, real Schur decomposition and matrix Q, computing eigenvectors corresponds to solving quasi triangular systems <ref> [GL89, Wil65] </ref>. The running time of these algorithms is O (n 3 ). However, the constant in front of n 3 can be as high as 25 for computing all the eigen-values and eigenvectors. In many cases we may a priori know some of the eigenvalues of the given matrix. <p> A problem is ill-conditioned if its condition number is large, and ill-posed if its condition number is infinite. These condition numbers are used to bound errors in computed solutions of numerical problems. More details on condition numbers are given in <ref> [GL89, Wil65] </ref>. The implementations of these condition number computations are available as part of LAPACK [BDM93]. In our intersection algorithm, we will be performing computations like matrix inversion and computing eigenvalues and eigenvectors of a matrix. <p> Higher multiplicity eigenvalues are being considered in [MD92]. 3.7 Accuracy of Right Eigenvectors Detailed error bounds for eigenvectors are given in <ref> [Wil65, ABB + 92] </ref>. We will not use these detailed bounds beyond the following implication: Since we will later need to take ratios of certain eigenvector components, we want to choose those components with the highest relative accuracy.
References-found: 32

