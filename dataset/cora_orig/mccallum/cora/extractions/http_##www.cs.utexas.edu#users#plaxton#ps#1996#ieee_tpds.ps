URL: http://www.cs.utexas.edu/users/plaxton/ps/1996/ieee_tpds.ps
Refering-URL: http://www.cs.utexas.edu/users/plaxton/html/journal.html
Root-URL: http://www.cs.utexas.edu
Title: All Nearest Smaller Values on the Hypercube  
Author: Dina Kravets and C. Greg Plaxton 
Keyword: All nearest smaller values, normal hypercube algorithm, monotone polygon triangulation, Cartesian tree.  
Date: Abstract  
Abstract: Given a sequence of n elements, the All Nearest Smaller Values (ANSV) problem is to find, for each element in the sequence, the nearest element to the left (right) that is smaller, or to report that no such element exists. Time and work optimal algorithms for this problem are known on all the PRAM models [3], [5], but the running time of the best previous hypercube algorithm [6] is optimal only when the number of processors p satisfies 1 p n=((lg 3 n)(lg lg n) 2 ). In this paper, we prove that any normal hypercube algorithm requires (n) processors to solve the ANSV problem in O(lg n) time, and we present the first normal hypercube ANSV algorithm that is optimal for all values of n and p. We use our ANSV algorithm to give the first O(lg n)-time n-processor normal hypercube algorithms for triangulating a monotone polygon and for constructing a Cartesian tree. Keywords 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aggarwal, D. Kravets, J. K. Park, and S. Sen. </author> <title> Parallel searching in generalized Monge arrays with applications. </title> <booktitle> In Proceedings of the 2nd Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 259-268, </pages> <year> 1990. </year>
Reference: [2] <author> M. J. Atallah and D. Z. Chen. </author> <title> Optimal parallel hypercube algorithms for polygon problems. </title> <booktitle> In Proceedings of the 5th IEEE Symposium on Parallel and Distributed Processing, </booktitle> <pages> pages 208-215, </pages> <year> 1993. </year>
Reference-contexts: A recent result of Atallah and Chen <ref> [2] </ref> gives an optimal hypercube algorithm for determining the line with respect to which a given polygon is monotone, if such a line exists.
Reference: [3] <author> O. Berkman, B. Schieber, and U. Vishkin. </author> <title> Optimal doubly logarithmic parallel algorithms based on finding nearest smaller values. </title> <journal> Journal of Algorithms, </journal> <volume> 14(3) </volume> <pages> 344-370, </pages> <year> 1993. </year>
Reference-contexts: Perform the following operations within each subcube C ff;fi . First, merge the sorted sequences S ff;fi and T ff;fi . Then, use prefix operations to determine the right match of each element in S ff;fi . (As proven in <ref> [3] </ref>, the right match of every element of S ff;fi is an element of T ff;fi .) Use additional prefix operations to count, for each element y of T ff;fi , the number of elements x in S ff;fi such that y is the right match of x. (a) At each <p> The proof of correctness of algorithm SparseANSV is essentially the same as the proof of correctness of the CREW PRAM algorithm of Berkman et al. <ref> [3] </ref> and hinges on showing [3] that the right matches for the elements of S ff;fi are among the elements of T ff;fi . An n-input n-processor algorithm We will now show how to solve a larger ANSV problem using the same number of processors. <p> The proof of correctness of algorithm SparseANSV is essentially the same as the proof of correctness of the CREW PRAM algorithm of Berkman et al. <ref> [3] </ref> and hinges on showing [3] that the right matches for the elements of S ff;fi are among the elements of T ff;fi . An n-input n-processor algorithm We will now show how to solve a larger ANSV problem using the same number of processors. <p> An n-input n-processor algorithm We will now show how to solve a larger ANSV problem using the same number of processors. The algorithm presented in this section offers two main advantages over the algorithm of Berkman et al. <ref> [3] </ref>: (i) the present algorithm runs efficiently on any hypercubic machine, and (ii) the high-level structure of the present algorithm is somewhat simpler. <p> A monotone polygon is one-sided if either its upper or lower chain consists of a single edge, called the distinguished edge. Our algorithm for triangulating a monotone polygon follows the approach of Berkman et al. <ref> [3] </ref>. The algorithm consists of two stages. In the first stage, we decompose the monotone polygon into one-sided monotone polygons. In the second stage, we triangulate the one-sided monotone polygons. We give only the high level description below; the implementation on the hypercube is straightforward. Algorithm Triangulate 1. <p> Algorithm Triangulate runs in O (lg n) time on an n-processor hypercube. The correctness of the algorithm follows from the work of Berkman et al. <ref> [3] </ref>. Furthermore, Berkman et al. [3] show how to reduce the problem of merging two sorted lists of length n to the problem of triangulating a monotone polygon of size n. <p> Algorithm Triangulate runs in O (lg n) time on an n-processor hypercube. The correctness of the algorithm follows from the work of Berkman et al. <ref> [3] </ref>. Furthermore, Berkman et al. [3] show how to reduce the problem of merging two sorted lists of length n to the problem of triangulating a monotone polygon of size n. <p> The Cartesian tree is used in preprocessing algorithms for answering range minimum queries. Berkman et al. <ref> [3] </ref> show how to find the Cartesian tree in O (lg n) time using an (n= lg n)-processor CREW PRAM. They prove that the parent of any element w i in the Cartesian tree is the larger of w i 's left and right matches.
Reference: [4] <author> A. Borodin and J. E. Hopcroft. </author> <title> Routing, merging, and sorting on parallel models of computation. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 30 </volume> <pages> 130-145, </pages> <year> 1985. </year>
Reference: [5] <author> D. Z. Chen. </author> <title> Efficient geometric algorithms in the EREW-PRAM. </title> <booktitle> In Proceedings of the 28th Annual Allerton Conference on Communication, Control, and Computing, </booktitle> <pages> pages 818-827, </pages> <year> 1990. </year>
Reference: [6] <author> J. F. JaJa and K. W. Ryu. </author> <title> Optimal algorithms on the pipelined hypercube and related networks. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4 </volume> <pages> 582-591, </pages> <year> 1993. </year>
Reference-contexts: III. A Lower Bound This section establishes a lower bound for the ANSV problem on a wide class of fixed-connection networks, including the hypercube and all of its bounded-degree variants. JaJa and Ryu <ref> [6] </ref> use a separator-based argument to establish the same asymptotic lower bound for the shu*e-exchange and cube-connected cycles. However, the bound they obtain for the hypercube is weaker than ours by a p lg p factor. <p> Our (non-separator-based) argument establishes the same lower bound not only for the hypercube, shu*e-exchange, and cube-connected cycles, but also for any bounded-degree expander network. (The separator-based approach of JaJa and Ryu <ref> [6] </ref> does not give a non-trivial lower bound for bounded-degree expander networks.) The lower bound is proven under the following set of assumptions: (L1) each input key is provided at exactly one processor; (L2) in a single time step, a processor can send and receive O (1) messages, and perform O
Reference: [7] <author> C. P. Kruskal. </author> <title> Searching, merging, and sorting. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-32(10):942-946, </volume> <year> 1983. </year>
Reference: [8] <author> F. T. Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays, Trees, </title> <booktitle> Hypercubes, </booktitle> <volume> volume 1. </volume> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference: [9] <author> E. W. Mayr and R. Werchner. </author> <title> Optimal routing of parentheses on the hypercube. </title> <booktitle> In Proceedings of the 4th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 109-117, </pages> <year> 1992. </year>
Reference-contexts: We can efficiently exchange information between all pairs of matching subcubes in parallel by making use of the parenthesis routing operation of Mayr and Werchner <ref> [9] </ref>.
Reference: [10] <author> L. G. Valiant. </author> <title> Parallelism in comparison problems. </title> <journal> SIAM Journal on Computing, </journal> <volume> 4 </volume> <pages> 348-355, </pages> <year> 1975. </year>
Reference: [11] <author> J. Vuillemin. </author> <title> A unified look at data structures. </title> <journal> Communications of the ACM, </journal> <volume> 23 </volume> <pages> 229-239, </pages> <year> 1980. </year>
Reference-contexts: a binary tree where the root corresponds to the element w k = min 0i&lt;n w i , the left child is the Cartesian tree of hw i : 0 i &lt; ki, and the right child is the Cartesian tree of hw i : k &lt; i &lt; ni <ref> [11] </ref>. The Cartesian tree is used in preprocessing algorithms for answering range minimum queries. Berkman et al. [3] show how to find the Cartesian tree in O (lg n) time using an (n= lg n)-processor CREW PRAM.
References-found: 11

