URL: http://www.cs.iastate.edu/tech-reports/TR92-10.ps
Refering-URL: http://www.cs.iastate.edu/tech-reports/catalog.html
Root-URL: 
Title: On Languages with Very High Information Content  
Author: TR - Ronald V. Book and Jack Lutz 
Address: 226 Atanasoff Ames, IA 50011  
Affiliation: Iowa State University of Science and Technology Department of Computer Science  
Date: May 1992  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> J. Balcazar, J. Daz, and J. Gabarro, </author> <title> In Structural Complexity I, </title> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference: [2] <author> J. Balcazar, J. Daz, and J. Gabarro, </author> <title> In Structural Complexity II, </title> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: machine U that is optimal in the sense that for each machine M there is a constant c such that for all t; L, and n, we have KS ct+c M (L n ) + c: Hence, we fix an optimal machine U and omit it from the notation. (See <ref> [2] </ref> or [4] for additional discussion of Kolmogorov complexity.) The main result involves languages with essentially maximal information content, that is, languages B such that for every polynomial q; KS q (B n ) &gt; 2 n+1 2n a.e. (Notice that for every language A; KS n (A n ) &lt;
Reference: [3] <author> R. Karp and R. Lipton, </author> <title> "Turing machines that take advice," </title> <booktitle> L'Enseignement Mathematique Vol. 28 2nd series, </booktitle> <pages> 191-209, </pages> <year> 1982. </year>
Reference: [4] <author> M. Li and P. Vitanyi, </author> <title> "Kolmogorov complexity and its applications," </title> <editor> In J. van Leeuwen (ed.), </editor> <booktitle> Handbook of Theoretical Computer Science, </booktitle> <publisher> Else-vier Science Publishers A, </publisher> <pages> 187-254, </pages> <year> 1990. </year>
Reference-contexts: that is optimal in the sense that for each machine M there is a constant c such that for all t; L, and n, we have KS ct+c M (L n ) + c: Hence, we fix an optimal machine U and omit it from the notation. (See [2] or <ref> [4] </ref> for additional discussion of Kolmogorov complexity.) The main result involves languages with essentially maximal information content, that is, languages B such that for every polynomial q; KS q (B n ) &gt; 2 n+1 2n a.e. (Notice that for every language A; KS n (A n ) &lt; 2 n+1
Reference: [5] <author> J. Lutz, </author> <title> "Almost everywhere high nonuniform complexity," </title> <journal> J. Comput. Sys. Sci. </journal> <volume> Vol. </volume> <pages> 44, </pages> <note> to appear, </note> <year> 1992. </year>
Reference-contexts: This follows from the fact [8] that RAND HIGH, where RAND is the set of algorithmically random languages defined by Martin-Lof [7]. Martin-Lof showed that almost every language is in RAND. In fact, the inclusion of RAND in HIGH is proper since almost every recursive language is in HIGH <ref> [5] </ref> while no recursively enumerable (hence, no recursive) language is in RAND. On the other hand, HIGH ESPACE = ;, that is, no language recognized by a machine that uses workspace O (2 cn ) for any c &gt; 0 is in HIGH [5]. <p> almost every recursive language is in HIGH <ref> [5] </ref> while no recursively enumerable (hence, no recursive) language is in RAND. On the other hand, HIGH ESPACE = ;, that is, no language recognized by a machine that uses workspace O (2 cn ) for any c &gt; 0 is in HIGH [5]. The Main Theorem shows that for every integer k &gt; 0; P ktt (HIGH) " ESPACE P ktt (SPARSE). The following result shows that it is highly unlikely that any language in HIGH is P btt -hard for many of the classes studied in structural complexity theory.
Reference: [6] <author> S. Mahaney, </author> <title> "Sparse complete set for NP: solution to a conjecture by Berman and Hartmanis" J. </title> <journal> Comput. Sys. Sci. </journal> <volume> Vol. 25, </volume> <pages> 130-143, </pages> <year> 1982. </year>
Reference: [7] <author> P. Martin-Lof, </author> <title> "On the definition of random sequences," </title> <journal> Info. and Control Vol. </journal> <volume> 9, </volume> <pages> 602-619, </pages> <year> 1966. </year>
Reference-contexts: As noted above, if a language is in HIGH, then it has essentially maximal information content. Almost every language is in HIGH. This follows from the fact [8] that RAND HIGH, where RAND is the set of algorithmically random languages defined by Martin-Lof <ref> [7] </ref>. Martin-Lof showed that almost every language is in RAND. In fact, the inclusion of RAND in HIGH is proper since almost every recursive language is in HIGH [5] while no recursively enumerable (hence, no recursive) language is in RAND.
Reference: [8] <author> P. Martin-Lof, </author> <title> "Complexity oscillations in infinite binary sequences," </title> <journal> Zeitschrift fur Wahrschein-lichkeitstheorie und Verwandte Gebiete Vol. </journal> <volume> 19, </volume> <pages> 225-230, </pages> <year> 1971. </year>
Reference-contexts: As noted above, if a language is in HIGH, then it has essentially maximal information content. Almost every language is in HIGH. This follows from the fact <ref> [8] </ref> that RAND HIGH, where RAND is the set of algorithmically random languages defined by Martin-Lof [7]. Martin-Lof showed that almost every language is in RAND.
Reference: [9] <author> M. Ogiwara and A. Lozano, </author> <title> "On one query self-reducible sets," </title> <booktitle> In Proc. 6th IEEE Conference on Structure in Complexity Theory 139-151, </booktitle> <year> 1991. </year>
Reference-contexts: If there is a language in HIGH that is P btt - hard for K, then K=P. Theorem 1 follows from the Main Theorem by results of Ogiwara and Watanabe [10] and Ogiwara and Lozano <ref> [9] </ref>. Theorem 1 shows that for any class K chosen from PSPACE, NP, PP, C = P, MOD 2 P, MOD 3 P,. . .g, if P 6= K, then no language in HIGH can be P btt - hard for K.
Reference: [10] <author> M. Ogiwara and O. Watanabe, </author> <title> "On polynomial bounded truth-table reduciblity of NP sets to sparse sets," </title> <journal> SIAM J. Comput. </journal> <volume> Vol. 20, </volume> <pages> 471-483, </pages> <year> 1991. </year>
Reference-contexts: If there is a language in HIGH that is P btt - hard for K, then K=P. Theorem 1 follows from the Main Theorem by results of Ogiwara and Watanabe <ref> [10] </ref> and Ogiwara and Lozano [9]. Theorem 1 shows that for any class K chosen from PSPACE, NP, PP, C = P, MOD 2 P, MOD 3 P,. . .g, if P 6= K, then no language in HIGH can be P btt - hard for K.
Reference: [11] <author> O. Watanabe, </author> <title> "Polynomial time reducibility to a set of small density," </title> <booktitle> In Proc. 2nd IEEE Conference on Structure in Complexity Theory 138-146, </booktitle> <year> 1987. </year>
Reference-contexts: A similar consequence holds for E = DTIME (2 linear ) with no unproven hypothesis since Watanabe <ref> [11] </ref> has shown that no sparse set is P btt - hard for E. Theorem 2 No language in HIGH is P btt -hard for E. The Main Theorem was stated in terms of a fixed integer k that bounds the number of queries.
References-found: 11

