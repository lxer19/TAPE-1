URL: ftp://ftp.eecs.umich.edu/groups/os_arch/isca94.ps.Z
Refering-URL: http://www.eecs.umich.edu/UMichMP/NT/papers.html
Root-URL: http://www.cs.umich.edu
Title: Abstract The allocation of die area to different processor components is a central issue in
Keyword: On-chip Memory, Cache, TLB, Multiple-API Oper ating System, Mach  
Note: Small  such as Ultrix.  
Abstract: Results: 
Abstract-found: 1
Intro-found: 1
Reference: [Accetta86] <editor> M. Accetta, et al. </editor> <booktitle> Mach: A new kernel foundation for UNIX development , In Summer 1986 USENIX Conference, USENIX, </booktitle> <year> 1986. </year>
Reference-contexts: Inputs were tuned so that each benchmark takes approximately the same amount of time to run (100-200 seconds under Mach). relies significantly on operating system services and emphasizes digital media applications. 4 The Effect of Multiple-APIs on Memory Allocation Decisions Many recent operating systems (e.g., Mach <ref> [Accetta86] </ref>, V [Cheriton84], Chorus [Rozier92], KeyKOS [Bomberger92], Windows NT [Custer93]) have been designed to support multiple APIs. For example, there currently exist servers for 4.3 BSD UNIX, MS-DOS, Macintosh OS and VMS that run on the Mach 3.0 microkernel [Black92, Malan91, Wiecek92].
Reference: [Agarwal88] <author> A. Agarwal, et al. </author> <title> Cache performance of operating system and multiprogramming workloads ACM Transac tions on Computer Systems 6 (Number 4): </title> <type> 393-431, </type> <year> 1988. </year>
Reference-contexts: We use the MQF model in this paper. Many of the studies cited above fail to consider operating system references. Other work has shown that this can lead to overoptimistic predictions of miss and traffic ratios <ref> [Clark85a, Clark85b, Agarwal88, Torrellas92] </ref>. At the same time, operating systems are changing. OS researchers have argued that trends, 1. Earlier models were shown to be inaccurate by a factor of 2 or more.
Reference: [Alpert88] <author> D. Alpert, et al. </author> <title> Performance trade-offs for micropro cessor cache memories IEEE Micro (Aug): </title> <type> 44-54, </type> <year> 1988. </year>
Reference-contexts: This work has been followed by numerous studies of on-chip memory structures, sometimes in conjunction with off-chip, second-level caches <ref> [Goodman86, Eickemeyer88, Alpert88, Short88, Przybylski89, Olukotun91, Farrens89] </ref>. The common conclusion of these papers is that on-chip memory structures are essential to minimizing off-chip memory accesses which, in turn, enables the low cycle times of modern processors. <p> 2.6 CPI I-cache D-cache Write buffer Other 5 Cost and Benefit Analysis 5.1 Cost Analysis To explore architectural trade-offs within the constraints of an area budget, several cost models have been developed to estimate the die area required for a given memory structure (e.g. register file, cache, TLB, write buffer) <ref> [Mulder91, Hill84, Alpert88] </ref>. This study uses the MQF model mentioned earlier [Mulder91]. The MQF model considers the memory cell type (dynamic or static), tag and data bits, organization (fully-associative, set-associative or direct-mapped), drivers and comparators to estimate die area using a technology-independent unit, the register-bit equivalent (rbe).
Reference: [Anderson91] <editor> T. E. Anderson, et al. </editor> <booktitle> The interaction of architecture and operating system design , In Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Santa Clara, Califor nia, </address> <publisher> ACM, </publisher> <pages> 108-119, </pages> <year> 1991. </year>
Reference-contexts: These systems, which typically implement API servers in separate address spaces and have a long execution path from the service invocation point to the actual service routines, are likely to depend more on TLBs and I-caches <ref> [Anderson91] </ref>. This paper explores the problem of on-chip memory allocation through a cost/benefit analysis. We use an area model for on-chip memories developed by Mulder, Quach and Flynn (MQF) to estimate the cost (area) of memory structures with various sizes and associativities [Mulder91]. <p> These data were collected from a variety of processor data books and issues of Microprocessor Report during the past two years [MReport 92, MReport93]. Throughout this paper we report line sizes in 4-byte words. such as support for multiple APIs, places additional pressure on existing hardware structures <ref> [Anderson91, Ousterhout89] </ref>. These claims are supported by recent work reporting that cache and TLB misses are substantially higher for new-generation operating systems like Mach 3.0 [Huck93, Chen93, Nagle93]. This paper extends previous work in several ways. <p> Machs aggressive use of virtual memory sharing is also responsible for increased pressure on the TLB. These and other explanations for increased TLB miss ratios under Mach are documented more completely in [Nagle93] and <ref> [Anderson91] </ref>. 4.3 Common Trends Table 4 and Figure 3 show that higher CPIs and the increased reliance on the I-cache and TLB under Mach is common to all of the workloads that we considered.
Reference: [Bershad92] <author> B. N. Bershad. </author> <title> The increasing irrelevance of IPC performance for microkernel-based operating systems Micro-kernels and Other Kernel Architectures, </title> <address> Seattle, Washington, </address> <publisher> USENIX, </publisher> <pages> 205-211, </pages> <year> 1992. </year>
Reference-contexts: has suggested other ways to avoid the costs of RPC, such as pre-allocating buffers between client and server address spaces for small messages using virtual memory primitives, or migrating more OS services into the clients address space as is currently done to a limited degree with the Mach emulation library <ref> [Bershad92] </ref>. Avoiding RPCs through more aggressive virtual memory sharing, however, is likely to shift misses from the I-cache to the TLB. Though they have their performance penalties, these OS structuring approaches offer important advantages. Dynamically-loaded emulation libraries enable binary compatibility.

Reference: [Bomberger92] <editor> A. Bomberger, et al. </editor> <booktitle> The KeyKOS nanokernel architecture , In USENIX Micro-Kernels and Other Kernel Architectures, </booktitle> <address> Seattle, Washington, </address> <publisher> USENIX, </publisher> <pages> 95-112, </pages> <year> 1992. </year>
Reference-contexts: tuned so that each benchmark takes approximately the same amount of time to run (100-200 seconds under Mach). relies significantly on operating system services and emphasizes digital media applications. 4 The Effect of Multiple-APIs on Memory Allocation Decisions Many recent operating systems (e.g., Mach [Accetta86], V [Cheriton84], Chorus [Rozier92], KeyKOS <ref> [Bomberger92] </ref>, Windows NT [Custer93]) have been designed to support multiple APIs. For example, there currently exist servers for 4.3 BSD UNIX, MS-DOS, Macintosh OS and VMS that run on the Mach 3.0 microkernel [Black92, Malan91, Wiecek92].
Reference: [Chen93] <editor> B. Chen, et al. </editor> <booktitle> The impact of operating system structure on memory system performance , In Proc. 14th Sympo sium on Operating System Principles, </booktitle> <year> 1993. </year>
Reference-contexts: Throughout this paper we report line sizes in 4-byte words. such as support for multiple APIs, places additional pressure on existing hardware structures [Anderson91, Ousterhout89]. These claims are supported by recent work reporting that cache and TLB misses are substantially higher for new-generation operating systems like Mach 3.0 <ref> [Huck93, Chen93, Nagle93] </ref>. This paper extends previous work in several ways. We revise previous studies of on-chip memories in the context of present-day VLSI technology and through the use of the improved MQF chip-area model. <p> Note that these are just service invocation paths. The actual OS code that provides the service must still execute in both Ultrix and Mach, but differences with respect to this service code are minor because both systems are derived from the same 4.2 BSD code <ref> [Chen93] </ref>. Using the instruction path lengths above, and assuming 4 bytes per instruction, we see that Mach increases the code path to OS services by approximately 4 K-bytes of instruction memory and the return path by about 3 K-bytes. <p> Recent work by Chen and Ber-shad corroborates this observation, although their data show a less pronounced shift to TLB stalls <ref> [Chen93] </ref>. This discrepancy may be due to differences between their workload suite and the benchmarks considered in this study. It should be noted that the long path to system services under Mach is a case of poor coding.
Reference: [Cheriton84] <author> D. R. Cheriton. </author> <title> The V kernel: A software base for distributed systems IEEE Software </title>
Reference-contexts: Inputs were tuned so that each benchmark takes approximately the same amount of time to run (100-200 seconds under Mach). relies significantly on operating system services and emphasizes digital media applications. 4 The Effect of Multiple-APIs on Memory Allocation Decisions Many recent operating systems (e.g., Mach [Accetta86], V <ref> [Cheriton84] </ref>, Chorus [Rozier92], KeyKOS [Bomberger92], Windows NT [Custer93]) have been designed to support multiple APIs. For example, there currently exist servers for 4.3 BSD UNIX, MS-DOS, Macintosh OS and VMS that run on the Mach 3.0 microkernel [Black92, Malan91, Wiecek92].
Reference: [Clark85a] <author> D. W. Clark, et al. </author> <title> Measuring VAX 8800 performance with a histogram hardware monitor , In The 15th Annual International Symposium on Computer Architecture, Honolulu, </title> <booktitle> Hawaii, IEEE, </booktitle> <pages> 176-185, </pages> <year> 1985. </year>
Reference-contexts: We use the MQF model in this paper. Many of the studies cited above fail to consider operating system references. Other work has shown that this can lead to overoptimistic predictions of miss and traffic ratios <ref> [Clark85a, Clark85b, Agarwal88, Torrellas92] </ref>. At the same time, operating systems are changing. OS researchers have argued that trends, 1. Earlier models were shown to be inaccurate by a factor of 2 or more.
Reference: [Clark85b] <author> D. W. Clark, et al. </author> <title> Performance of the VAX-11/780 translation buffer: </title> <booktitle> Simulation and measurement ACM Transactions on Computer Systems </booktitle>
Reference-contexts: We use the MQF model in this paper. Many of the studies cited above fail to consider operating system references. Other work has shown that this can lead to overoptimistic predictions of miss and traffic ratios <ref> [Clark85a, Clark85b, Agarwal88, Torrellas92] </ref>. At the same time, operating systems are changing. OS researchers have argued that trends, 1. Earlier models were shown to be inaccurate by a factor of 2 or more.
Reference: [Custer93] <author> H. Custer. </author> <title> Inside Windows NT . Redmond, </title> <address> Washington, </address> <publisher> Microsoft Press, </publisher> <year> 1993. </year>
Reference-contexts: each benchmark takes approximately the same amount of time to run (100-200 seconds under Mach). relies significantly on operating system services and emphasizes digital media applications. 4 The Effect of Multiple-APIs on Memory Allocation Decisions Many recent operating systems (e.g., Mach [Accetta86], V [Cheriton84], Chorus [Rozier92], KeyKOS [Bomberger92], Windows NT <ref> [Custer93] </ref>) have been designed to support multiple APIs. For example, there currently exist servers for 4.3 BSD UNIX, MS-DOS, Macintosh OS and VMS that run on the Mach 3.0 microkernel [Black92, Malan91, Wiecek92].
Reference: [Dean91] <author> R. W. Dean, et al. </author> <title> Data movement in kernelized systems In Micro-kernels and Other Kernel Architectures, </title> <address> Seattle, Washington, </address> <publisher> USENIX, </publisher> <pages> 243-261, </pages> <year> 1991. </year>
Reference-contexts: In fact, the Mach implementation of RPC has been highly optimized through the use of techniques such as stack-handoff scheduling and continuations [Draves91] for the common case of small messages and out-of-line (virtual memory) transfers for the expensive case of large messages <ref> [Dean91] </ref>.
Reference: [Draves91] <editor> R. P. Draves, et al. </editor> <booktitle> Using continuations to implement thread management and communication in operating systems . In Proceedings of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> 122-136, </pages> <year> 1991. </year>
Reference-contexts: Other structural differences are responsible for increased I-cache misses under Mach. For example, in Ultrix, paging is implemented in the kernel, but Mach supports an external pager, running in user mode, that is responsible for locating pages in a backing store after a page fault <ref> [Draves91] </ref>. Similarly, recent ver In Ultrix, BSD UNIX services reside in the kernel and are accessed through a single system call trap. In Mach, services reside in a user-level BSD server accessed via a remote procedure call (RPC) mechanism that passes through the Mach kernel. <p> In fact, the Mach implementation of RPC has been highly optimized through the use of techniques such as stack-handoff scheduling and continuations <ref> [Draves91] </ref> for the common case of small messages and out-of-line (virtual memory) transfers for the expensive case of large messages [Dean91].
Reference: [Eickemeyer88] <author> R. Eickemeyer, et al. </author> <title> Performance evaluation of on-chip register and cache organizations , In Proc. </title> <booktitle> 15th Annual Symposium on Computer Architecture, Hono-lulu, Hawaii, </booktitle> <pages> 64-72, </pages> <year> 1988. </year>
Reference-contexts: This work has been followed by numerous studies of on-chip memory structures, sometimes in conjunction with off-chip, second-level caches <ref> [Goodman86, Eickemeyer88, Alpert88, Short88, Przybylski89, Olukotun91, Farrens89] </ref>. The common conclusion of these papers is that on-chip memory structures are essential to minimizing off-chip memory accesses which, in turn, enables the low cycle times of modern processors.
Reference: [Farrens89] <editor> M. Farrens, et al. </editor> <booktitle> Improving performance of small on-chip instruction caches , In The 16th Annual International Symposium on Computer Architecture, ACM, </booktitle> <pages> 234-241, </pages> <year> 1989. </year>
Reference-contexts: This work has been followed by numerous studies of on-chip memory structures, sometimes in conjunction with off-chip, second-level caches <ref> [Goodman86, Eickemeyer88, Alpert88, Short88, Przybylski89, Olukotun91, Farrens89] </ref>. The common conclusion of these papers is that on-chip memory structures are essential to minimizing off-chip memory accesses which, in turn, enables the low cycle times of modern processors.
Reference: [Forin91] <editor> A. Forin, et al. </editor> <booktitle> An I/O system for Mach 3.0 , In USENIX Mach Symposium, </booktitle> <address> Monterey, CA, </address> <publisher> USENIX, </publisher> <pages> 163-176, </pages> <year> 1991. </year>
Reference-contexts: Emulation 4.3 BSD Server Mach Kernel mpeg_play 2 6 4 RPC Stubs RPC Stubs Emulation Trap Stack Handoff Ultrix Kernel BSD Services a b mpeg_play Ultrix Mach System Call System Call Library sions of Mach have migrated I/O device drivers from the kernel to the user level <ref> [Forin91] </ref>. As a third example, Black et al. have described efforts to further decompose monolithic API servers (like the BSD server shown in Figure 2) into multiple, small-granularity servers (e.g., for naming, authentication, and file access) [Black92].
Reference: [Ginsberg93] <author> M. Ginsberg, et al. </author> <title> Using the Mach communication primitives in X11 . Carnegie-Mellon Technical Report, </title> <year> 1993. </year>
Reference-contexts: The X11 windowing system has been rewritten to use Mach IPC and VM sharing facilities instead of the BSD socket interface <ref> [Ginsberg93] </ref>. server (4) which unpacks the arguments using its own RPC stub code. These steps (1-4) are equivalent to the single kernel trap (a) in Ultrix.
Reference: [Golub91] <author> D. Golub, et al. </author> <title> Moving the default memory manager out of the Mach kernel , In USENIX Mach Symposium, </title> <address> Monterey, CA, </address> <publisher> USENIX, </publisher> <pages> 177-188, </pages> <year> 1991. </year>
Reference: [Goodman83] <author> J. Goodman. </author> <title> Using cache memory to reduce processor memory traffic , In 10th International Symposium on Computer Architecture, </title> <address> Stockholm, Sweden, 124-131, </address> <year> 1983. </year>
Reference-contexts: Subsequently, in two separate studies, Goodman and Hill & Smith demonstrated the effectiveness of small on-chip cache memories and argued that future processor designs should allocate some portion of die area to these structures in favor of developing more complex CPU datapaths <ref> [Goodman83, Hill84] </ref>. This work has been followed by numerous studies of on-chip memory structures, sometimes in conjunction with off-chip, second-level caches [Goodman86, Eickemeyer88, Alpert88, Short88, Przybylski89, Olukotun91, Farrens89].
Reference: [Goodman86] <author> J. Goodman, et al. </author> <title> On the use of registers vs. cache to minimize memory traffic , In Proc. </title> <booktitle> 13th International Symposium on Computer Architecture, </booktitle> <pages> 375-383, </pages> <year> 1986. </year>
Reference-contexts: This work has been followed by numerous studies of on-chip memory structures, sometimes in conjunction with off-chip, second-level caches <ref> [Goodman86, Eickemeyer88, Alpert88, Short88, Przybylski89, Olukotun91, Farrens89] </ref>. The common conclusion of these papers is that on-chip memory structures are essential to minimizing off-chip memory accesses which, in turn, enables the low cycle times of modern processors.
Reference: [Hill84] <author> M. Hill, et al. </author> <title> Experimental evaluation of on-chip microprocessor cache memories , In 11th Annual International Symposium on Computer Architecture, </title> <address> Ann Arbor, Mich-igan, 158-166, </address> <year> 1984. </year>
Reference-contexts: Subsequently, in two separate studies, Goodman and Hill & Smith demonstrated the effectiveness of small on-chip cache memories and argued that future processor designs should allocate some portion of die area to these structures in favor of developing more complex CPU datapaths <ref> [Goodman83, Hill84] </ref>. This work has been followed by numerous studies of on-chip memory structures, sometimes in conjunction with off-chip, second-level caches [Goodman86, Eickemeyer88, Alpert88, Short88, Przybylski89, Olukotun91, Farrens89]. <p> 2.6 CPI I-cache D-cache Write buffer Other 5 Cost and Benefit Analysis 5.1 Cost Analysis To explore architectural trade-offs within the constraints of an area budget, several cost models have been developed to estimate the die area required for a given memory structure (e.g. register file, cache, TLB, write buffer) <ref> [Mulder91, Hill84, Alpert88] </ref>. This study uses the MQF model mentioned earlier [Mulder91]. The MQF model considers the memory cell type (dynamic or static), tag and data bits, organization (fully-associative, set-associative or direct-mapped), drivers and comparators to estimate die area using a technology-independent unit, the register-bit equivalent (rbe).
Reference: [Huck93] <editor> J. Huck, et al. </editor> <booktitle> Architectural support for translation table management in large address space machines The 20th Annual International Symposium on Computer Architecture, </booktitle> <address> San Diego, California, </address> <publisher> IEEE, </publisher> <pages> 39-50, </pages> <year> 1993. </year>
Reference-contexts: Throughout this paper we report line sizes in 4-byte words. such as support for multiple APIs, places additional pressure on existing hardware structures [Anderson91, Ousterhout89]. These claims are supported by recent work reporting that cache and TLB misses are substantially higher for new-generation operating systems like Mach 3.0 <ref> [Huck93, Chen93, Nagle93] </ref>. This paper extends previous work in several ways. We revise previous studies of on-chip memories in the context of present-day VLSI technology and through the use of the improved MQF chip-area model.
Reference: [Khalidi92] <author> Y. A. Khalidi, et al. </author> <title> An implementation of UNIX on an object-oriented operating system . Sun Microsystems Laboratories. </title> <year> 1992. </year>
Reference-contexts: It should be noted that the long path to system services under Mach is a case of poor coding. This service invocation mechanism is common to other modular, object-oriented software systems (e.g. <ref> [Khalidi92] </ref>) and simply represents a cost for the advantages that they offer over traditional, single-service systems.
Reference: [Kessler91] <author> R. Kessler. </author> <title> Analysis of multi-megabyte secondary CPU cache memories . University of Wisconsin-Madison. </title> <year> 1991. </year>
Reference-contexts: Samples must be long enough to prime the cache so that references will be known to hit or miss. This problem, which is most severe with simulations of large caches, is commonly referred to as cold-start bias and can intro duce error in miss ratio estimators <ref> [Kessler91] </ref>. Our method satisfies both requirements. Monster was used to collect trace samples over random intervals of workload execu tion. Fifty samples of 120- to 200-thousand references apiece were collected for each workload under both operating systems.
Reference: [Laha88] <author> S. Laha, et al. </author> <title> Accurate low-cost methods for performance evaluation of cache memory systems IEEE Trans actions on Computers </title>
Reference-contexts: Each sample is used to obtain an estimator of the miss ratio during a given segment of the workload. Laha et al. report that 35 samples are usually sufficient to characterize a workload <ref> [Laha88] </ref>, although other researchers report that some workloads (especially those with low miss ratios) may require as many as 100 samples to bring relative error to under 10% [Martonosi93]. Samples must be long enough to prime the cache so that references will be known to hit or miss.
Reference: [Malan91] <author> G. Malan, et al. </author> <title> DOS as a Mach 3.0 application USENIX Mach Symposium, </title> <booktitle> USENIX, </booktitle> <pages> 27-40, </pages> <year> 1991. </year>
Reference-contexts: For example, there currently exist servers for 4.3 BSD UNIX, MS-DOS, Macintosh OS and VMS that run on the Mach 3.0 microkernel <ref> [Black92, Malan91, Wiecek92] </ref>. These API services are typically implemented in one or more user-level programs and invoked through a remote procedure call (RPC) interface. <p> In Mach, much of the system code runs at the user level and interacts via Mach messages or RPCs. Each of the API servers depicted above (BSD, MS-DOS, MacOS and VMS) exist in actual implementations <ref> [Black92, Malan91, Wiecek92] </ref>, though not currently all on the same processor architecture.
Reference: [Martonosi93] <author> M. Martonosi, et al. </author> <title> Effectiveness of trace sam pling for performance debugging tools , In SIGMET-RICS, </title> <address> Santa Clara, California, </address> <publisher> ACM, </publisher> <pages> 248-259, </pages> <year> 1993. </year>
Reference-contexts: Laha et al. report that 35 samples are usually sufficient to characterize a workload [Laha88], although other researchers report that some workloads (especially those with low miss ratios) may require as many as 100 samples to bring relative error to under 10% <ref> [Martonosi93] </ref>. Samples must be long enough to prime the cache so that references will be known to hit or miss. This problem, which is most severe with simulations of large caches, is commonly referred to as cold-start bias and can intro duce error in miss ratio estimators [Kessler91].
Reference: [MReport92] <institution> Microprocessor Report. Sebastopol, CA, MicroDe-sign Resources, </institution> <year> 1992. </year>
Reference-contexts: 1 Introduction Improvements in integrated-circuit processing technology over the past decade have enabled the inclusion of on-chip memory structures in microprocessor designs. Current microprocessors typically dedicate about half of their chip area to memory structures such as TLBs, write buffers, and caches <ref> [MReport92, MReport93] </ref>. While numerous studies have demonstrated the effectiveness of caches and TLBs in improving performance, these structures are costly because they quickly consume the scarce resource of chip area. As a result, on-chip caches tend to be rather small (4- to 16-Kbytes).
Reference: [MReport93] <institution> Microprocessor Report. Sebastopol, CA, MicroDe-sign Resources, </institution> <year> 1993. </year>
Reference-contexts: 1 Introduction Improvements in integrated-circuit processing technology over the past decade have enabled the inclusion of on-chip memory structures in microprocessor designs. Current microprocessors typically dedicate about half of their chip area to memory structures such as TLBs, write buffers, and caches <ref> [MReport92, MReport93] </ref>. While numerous studies have demonstrated the effectiveness of caches and TLBs in improving performance, these structures are costly because they quickly consume the scarce resource of chip area. As a result, on-chip caches tend to be rather small (4- to 16-Kbytes). <p> These data were collected from a variety of processor data books and issues of Microprocessor Report during the past two years <ref> [MReport 92, MReport93] </ref>. Throughout this paper we report line sizes in 4-byte words. such as support for multiple APIs, places additional pressure on existing hardware structures [Anderson91, Ousterhout89]. <p> The MQF model predicts that the total of these memory structures should cost less than 250,000 rbes. This relatively small amount of on-chip memory reects technology constraints that will continue for the next several years <ref> [MReport93] </ref>. High-end systems will provide more on-chip memory, but access times will probably require that this be in a second-level cache. Moreover, trends towards inexpensive, scaled-back processors such as the MIPS R4200 and the DEC 21064 will keep many processors on-chip primary caches small.
Reference: [MIPS88] <author> MIPS. </author> <title> RISCompiler Languages Programmer's Guide MIPS, </title> <year> 1988. </year>
Reference-contexts: This workload suite was chosen because it 1. Monster connects to the system at the CPU package pins. Because caches are implemented off-chip in the R2000, this method captures all memory references, not just those that miss the cache. 2. We use the cache2000 Cheetah cache simulators <ref> [MIPS88, Sugumar93] </ref>. 3. Our kernel-based TLB simulator can process memory references at a rate of over 6 million references / sec. A comparable trace-driven simulator processes at a rate of 20 to 150 thousand references / sec. <p> Numbers in parenthesis give the relative contribution of each stall type. Other stands for non-memory related stalls, such as integer and oating-point interlock cycles. In the first row, CPI was determined by a cache2000 simulation driven by pixie -generated traces <ref> [MIPS88] </ref>. cache2000 was configured to simulate a mem ory system with the same parameters as the DECstation 3100. Because pixie generates user-only references, this measurement does not consider operating system references.
Reference: [Mulder91] <editor> J. Mulder, et al. </editor> <title> An area model for on-chip memories and its application IEEE Journal of Solid-State Circuits </title>
Reference-contexts: This paper explores the problem of on-chip memory allocation through a cost/benefit analysis. We use an area model for on-chip memories developed by Mulder, Quach and Flynn (MQF) to estimate the cost (area) of memory structures with various sizes and associativities <ref> [Mulder91] </ref>. To determine the performance benefit of different memory structures, we employ a collection of analysis tools including hardware-based monitors, trace-driven simulators and kernel-based simulators. We consider two different operating systems, Mach 3.0 and Ultrix, and a collection of applications that rely heavily on operating system services. <p> 2.6 CPI I-cache D-cache Write buffer Other 5 Cost and Benefit Analysis 5.1 Cost Analysis To explore architectural trade-offs within the constraints of an area budget, several cost models have been developed to estimate the die area required for a given memory structure (e.g. register file, cache, TLB, write buffer) <ref> [Mulder91, Hill84, Alpert88] </ref>. This study uses the MQF model mentioned earlier [Mulder91]. The MQF model considers the memory cell type (dynamic or static), tag and data bits, organization (fully-associative, set-associative or direct-mapped), drivers and comparators to estimate die area using a technology-independent unit, the register-bit equivalent (rbe). <p> This study uses the MQF model mentioned earlier <ref> [Mulder91] </ref>. The MQF model considers the memory cell type (dynamic or static), tag and data bits, organization (fully-associative, set-associative or direct-mapped), drivers and comparators to estimate die area using a technology-independent unit, the register-bit equivalent (rbe).
Reference: [Nagle92] <author> D. Nagle, et al. </author> <title> Monster: a tool for analyzing the interaction between operating systems and architectures CSE-TR147-92. </title> <institution> University of Michigan, </institution> <year> 1992. </year>
Reference-contexts: The advantage of this method is that it non-inva-sively measures actual system activity without the error that usually accompanies simulation or analytical modeling due to incomplete assumptions about system operation. This system, which we call Monster , is described more completely in <ref> [Nagle92] </ref>. Because hardware monitoring is unable to explore alternative design parameters, we also use trace-driven architectural simulation.
Reference: [Nagle93] <editor> D. Nagle, et al. </editor> <booktitle> Design tradeoffs for software-managed TLBs . In the 20th Annual International Symposium on Computer Architecture, </booktitle> <address> San Diego, California, 27-38, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Throughout this paper we report line sizes in 4-byte words. such as support for multiple APIs, places additional pressure on existing hardware structures [Anderson91, Ousterhout89]. These claims are supported by recent work reporting that cache and TLB misses are substantially higher for new-generation operating systems like Mach 3.0 <ref> [Huck93, Chen93, Nagle93] </ref>. This paper extends previous work in several ways. We revise previous studies of on-chip memories in the context of present-day VLSI technology and through the use of the improved MQF chip-area model. <p> Machs aggressive use of virtual memory sharing is also responsible for increased pressure on the TLB. These and other explanations for increased TLB miss ratios under Mach are documented more completely in <ref> [Nagle93] </ref> and [Anderson91]. 4.3 Common Trends Table 4 and Figure 3 show that higher CPIs and the increased reliance on the I-cache and TLB under Mach is common to all of the workloads that we considered.
Reference: [Olukotun91] <author> O. A. Olukotun, et al. </author> <title> Implementing a cache for a high-performance GaAs microprocessor , In Proc. </title> <booktitle> 18th Annual International Symposium on Computer Architecture, </booktitle> <address> Toronto, Canada, 138-147, </address> <year> 1991. </year>
Reference-contexts: This work has been followed by numerous studies of on-chip memory structures, sometimes in conjunction with off-chip, second-level caches <ref> [Goodman86, Eickemeyer88, Alpert88, Short88, Przybylski89, Olukotun91, Farrens89] </ref>. The common conclusion of these papers is that on-chip memory structures are essential to minimizing off-chip memory accesses which, in turn, enables the low cycle times of modern processors.
Reference: [Ousterhout89] <author> J. Ousterhout. </author> <title> Why aren't operating systems getting faster as fast as hardware WRL Technical Note 11): </title> <year> 1989. </year>
Reference-contexts: These data were collected from a variety of processor data books and issues of Microprocessor Report during the past two years [MReport 92, MReport93]. Throughout this paper we report line sizes in 4-byte words. such as support for multiple APIs, places additional pressure on existing hardware structures <ref> [Anderson91, Ousterhout89] </ref>. These claims are supported by recent work reporting that cache and TLB misses are substantially higher for new-generation operating systems like Mach 3.0 [Huck93, Chen93, Nagle93]. This paper extends previous work in several ways. <p> Benchmark Description IOzone A sequential file I/O benchmark that writes and then reads a 10 Megabyte file. Written by Bill Norcott. jpeg_play xloadimage program written by Jim Frost. Dis plays four JPEG images. John Ousterhouts Modified Andrew Benchmark <ref> [Ousterhout89] </ref>. mpeg_play mpeg_play V2.0 from the Berkeley Plateau Research Group. Displays 610 frames from a compressed video file [Patel92]. ousterhout John Ousterhouts benchmark suite from [Ousterhout89]. video_play A modified version of mpeg_play that displays 610 frames from an uncompressed video file. <p> Written by Bill Norcott. jpeg_play xloadimage program written by Jim Frost. Dis plays four JPEG images. John Ousterhouts Modified Andrew Benchmark <ref> [Ousterhout89] </ref>. mpeg_play mpeg_play V2.0 from the Berkeley Plateau Research Group. Displays 610 frames from a compressed video file [Patel92]. ousterhout John Ousterhouts benchmark suite from [Ousterhout89]. video_play A modified version of mpeg_play that displays 610 frames from an uncompressed video file. Operating System Description Ultrix Version 3.1 from Digital Equipment Corporation. Mach Carnegie Mellon Universitys version mk77 of the ker nel and version uk38 of the 4.3 BSD UNIX server.
Reference: [Patterson80] <author> D. A. Patterson, et al. </author> <title> Design considerations for single-chip computers of the future IEEE Transactions on Computers </title>
Reference-contexts: Section 6 presents conclusions and suggests future work. 2 Related Work The idea of building microprocessors with on-chip cache memories dates back to at least a decade ago, when VLSI advances began to enable such designs <ref> [Patterson80] </ref>. Subsequently, in two separate studies, Goodman and Hill & Smith demonstrated the effectiveness of small on-chip cache memories and argued that future processor designs should allocate some portion of die area to these structures in favor of developing more complex CPU datapaths [Goodman83, Hill84].
Reference: [Patel92] <author> K. Patel, et al. </author> <title> Performance of a Software MPEG Video Decoder . University of California, </title> <address> Berkeley. </address> <year> 1992. </year>
Reference-contexts: Written by Bill Norcott. jpeg_play xloadimage program written by Jim Frost. Dis plays four JPEG images. John Ousterhouts Modified Andrew Benchmark [Ousterhout89]. mpeg_play mpeg_play V2.0 from the Berkeley Plateau Research Group. Displays 610 frames from a compressed video file <ref> [Patel92] </ref>. ousterhout John Ousterhouts benchmark suite from [Ousterhout89]. video_play A modified version of mpeg_play that displays 610 frames from an uncompressed video file. Operating System Description Ultrix Version 3.1 from Digital Equipment Corporation.
Reference: [Przybylski89] <author> S. Przybylski, et al. </author> <title> Characteristics of performance-optimal multi-level cache hierarchies , In Proc. </title> <booktitle> 16th Annual International Symposium on Computer Architecture, Jerusalem, Israel, </booktitle> <pages> 114-121, </pages> <year> 1989. </year>
Reference-contexts: This work has been followed by numerous studies of on-chip memory structures, sometimes in conjunction with off-chip, second-level caches <ref> [Goodman86, Eickemeyer88, Alpert88, Short88, Przybylski89, Olukotun91, Farrens89] </ref>. The common conclusion of these papers is that on-chip memory structures are essential to minimizing off-chip memory accesses which, in turn, enables the low cycle times of modern processors.
Reference: [Rozier92] <author> M. Rozier, et al. </author> <title> Overview of the Chorus distributed operating system , In Micro-kernels and Other Kernel Architectures, </title> <address> Seattle, Washington, </address> <publisher> USENIX, </publisher> <pages> 39-69, </pages> <year> 1992. </year>
Reference-contexts: Inputs were tuned so that each benchmark takes approximately the same amount of time to run (100-200 seconds under Mach). relies significantly on operating system services and emphasizes digital media applications. 4 The Effect of Multiple-APIs on Memory Allocation Decisions Many recent operating systems (e.g., Mach [Accetta86], V [Cheriton84], Chorus <ref> [Rozier92] </ref>, KeyKOS [Bomberger92], Windows NT [Custer93]) have been designed to support multiple APIs. For example, there currently exist servers for 4.3 BSD UNIX, MS-DOS, Macintosh OS and VMS that run on the Mach 3.0 microkernel [Black92, Malan91, Wiecek92].
Reference: [Short88] <author> R. Short, et al. </author> <title> A simulation study of two-level caches In Proc. </title> <booktitle> 15th Annual International Symposium on Computer Architecture, Honolulu, Hawaii, </booktitle> <pages> 81-88, </pages> <year> 1988. </year>
Reference-contexts: This work has been followed by numerous studies of on-chip memory structures, sometimes in conjunction with off-chip, second-level caches <ref> [Goodman86, Eickemeyer88, Alpert88, Short88, Przybylski89, Olukotun91, Farrens89] </ref>. The common conclusion of these papers is that on-chip memory structures are essential to minimizing off-chip memory accesses which, in turn, enables the low cycle times of modern processors.
Reference: [Sugumar93] <author> R. Sugumar. </author> <title> Multi-configuration simulation algorithms for the evaluation of computer designs . University of Michigan. </title> <year> 1993. </year>
Reference-contexts: This workload suite was chosen because it 1. Monster connects to the system at the CPU package pins. Because caches are implemented off-chip in the R2000, this method captures all memory references, not just those that miss the cache. 2. We use the cache2000 Cheetah cache simulators <ref> [MIPS88, Sugumar93] </ref>. 3. Our kernel-based TLB simulator can process memory references at a rate of over 6 million references / sec. A comparable trace-driven simulator processes at a rate of 20 to 150 thousand references / sec.
Reference: [Torrellas92] <editor> J. Torrellas, et al. </editor> <booktitle> Characterizing the caching and synchronization performance of multiprocessor operating system , In Fifth International Conference on Architectural Support for Programming Languages and Operating Sys tems, </booktitle> <address> Boston, Massachusetts, </address> <publisher> ADM, </publisher> <pages> 162-174, </pages> <year> 1992. </year>
Reference-contexts: We use the MQF model in this paper. Many of the studies cited above fail to consider operating system references. Other work has shown that this can lead to overoptimistic predictions of miss and traffic ratios <ref> [Clark85a, Clark85b, Agarwal88, Torrellas92] </ref>. At the same time, operating systems are changing. OS researchers have argued that trends, 1. Earlier models were shown to be inaccurate by a factor of 2 or more.
Reference: [Uhlig93] <author> R. Uhlig, et al. </author> <title> Kernel-based memory simulation . Technical Report CSE-TR-185-93. </title> <institution> University of Michigan, </institution> <year> 1993. </year>
Reference-contexts: By modifying the kernel to pass these TLB miss events to a TLB simulator, it is possible to simulate alternative TLB configurations. Our kernel-based simulator, called Tapeworm , is described more completely in <ref> [Uhlig93] </ref>. Extensions to this basic technique are used to simulate instruction and data caches [Uhlig94]. Kernel-based simulation is an attractive compliment to trace-driven simulation because it is significantly faster, though less exible. Tapeworms speed makes it possible to obtain performance figures without resorting to sampling.
Reference: [Uhlig94] <editor> R. Uhlig, et al. </editor> <booktitle> Kernel-based memory simulation (Extended Abstract) . To appear in 1994 ACM SIGMET RICS Conference on Measurement and Modeling of Computer Systems (Poster Session), </booktitle> <address> Nashville, Tennes-see, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: By modifying the kernel to pass these TLB miss events to a TLB simulator, it is possible to simulate alternative TLB configurations. Our kernel-based simulator, called Tapeworm , is described more completely in [Uhlig93]. Extensions to this basic technique are used to simulate instruction and data caches <ref> [Uhlig94] </ref>. Kernel-based simulation is an attractive compliment to trace-driven simulation because it is significantly faster, though less exible. Tapeworms speed makes it possible to obtain performance figures without resorting to sampling.
Reference: [Wada92] <author> T. Wada, et al. </author> <title> An analytical access time model for on chip cache memories IEEE Journal of Solid-State Circuits </title>
Reference-contexts: First, we did not consider the impact of size and associativity on memory access times in a rigorous fashion. An accurate access-time model, such as that developed by Wada et al., could be used to add another dimension to this style of cost/benefit analysis <ref> [Wada92] </ref>. Second, we only considered the I-cache, D-cache and TLB in die area allocations.
Reference: [Wiecek92] <author> C. A. Wiecek, et al. </author> <title> A model and prototype of VMS using the Mach 3.0 kernel , In USENIX Micro-kernels and Other Kernel Architectures Workshop, </title> <booktitle> Seattle, Wash-ington, USENIX, </booktitle> <pages> 187-203, </pages> <year> 1992. </year>
Reference-contexts: For example, there currently exist servers for 4.3 BSD UNIX, MS-DOS, Macintosh OS and VMS that run on the Mach 3.0 microkernel <ref> [Black92, Malan91, Wiecek92] </ref>. These API services are typically implemented in one or more user-level programs and invoked through a remote procedure call (RPC) interface. <p> In Mach, much of the system code runs at the user level and interacts via Mach messages or RPCs. Each of the API servers depicted above (BSD, MS-DOS, MacOS and VMS) exist in actual implementations <ref> [Black92, Malan91, Wiecek92] </ref>, though not currently all on the same processor architecture.
References-found: 46

