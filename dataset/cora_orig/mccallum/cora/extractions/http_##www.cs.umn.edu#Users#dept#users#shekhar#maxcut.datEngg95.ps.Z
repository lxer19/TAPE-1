URL: http://www.cs.umn.edu/Users/dept/users/shekhar/maxcut.datEngg95.ps.Z
Refering-URL: http://www.cs.umn.edu/Users/dept/users/shekhar/
Root-URL: http://www.cs.umn.edu
Email: dliu@cs.umn.edu shekhar@cs.umn.edu  
Title: A Similarity Graph-Based Approach to Declustering Problems and Its Application towards Parallelizing Grid Files  
Author: Duen-Ren Liu Shashi Shekhar 
Address: Minneapolis, MN 55455  
Affiliation: Department of Computer Science, University of Minnesota,  
Abstract: We propose a new similarity-based technique for declustering data. The proposed method can adapt to available information about query distributions, data distributions, data sizes and partition-size constraints. The method is based on max-cut partitioning of a similarity graph defined over the given set of data, under constraints on the partition sizes. It maximizes the chances that a pair of data-items that are to be accessed together by queries are allocated to distinct disks. We show that the proposed method can achieve optimal speed-up for a query-set, if there exists any other declustering method which will achieve the optimal speed-up. Experiments in parallelizing Grid Files show that the proposed method outperforms mapping-function-based methods for interesting query distributions as well for non-uniform data distributions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E.R. Barnes. </author> <title> "An Algorithm for Partitioning the Nodes of a Graph". </title> <journal> SIAM Journal Alg. Disc. Meth., </journal> <volume> 3(4) </volume> <pages> 541-550, </pages> <month> December </month> <year> 1982. </year>
Reference-contexts: Many good heuristic algorithms which have been developed for the min-cut graph partitioning problem can also be applied to efficiently solve the max-cut graph-partitioning problem. These heuristics Proc. of the IEEE Eleventh Intl. Conference on Data Engineering, March 1995 4 are based on spectral partitioning <ref> [1] </ref>, and iterative approaches [14, 3]. 3 Implementation and Analysis of Max-Cut Declustering In this section, we present the implementation and analysis of the max-cut declustering approach. The analysis will demonstrate in forthcoming theorem 1 that the max-cut declustering approach is capable of achieving perfect declustering, if perfect declustering exists.
Reference: [2] <author> C.C. Chang and C.Y. Cheng. </author> <title> "Performance of Two-Disk Partition Data Allocations". </title> <journal> BIT, </journal> <volume> 27(3) </volume> <pages> 306-314, </pages> <year> 1987. </year>
Reference-contexts: Several single-attribute functions including round robin, hash-partitioning, key-range partitioning [4, 10], and hybrid of these [11], as well as multi-attribute functions including disk modulo [5, 19], generalized disk modulo (linear) [5, 25], field-wise-XOR [16], Hilbert [6], error correcting code [7], latin-square [25, 15], random <ref> [2] </ref> and lattice [25] have been proposed and evaluated. A survey of multi-attribute functions can be found in [7, 6]. These methods are limited for managing updates, non-uniform data-distributions and nonuniform data-sizes. Furthermore, they are limited in their ability to adapt to available information about query distribution and size constraints.
Reference: [3] <author> C.K. Cheng and Y.C. Wei. </author> <title> "An Improved Two-Way Partitioning Algorithm with Stable Performance". </title> <journal> IEEE Trans. on Computer-Aided Design, </journal> <volume> 10(12) </volume> <pages> 1502-1511, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: Many good heuristic algorithms which have been developed for the min-cut graph partitioning problem can also be applied to efficiently solve the max-cut graph-partitioning problem. These heuristics Proc. of the IEEE Eleventh Intl. Conference on Data Engineering, March 1995 4 are based on spectral partitioning [1], and iterative approaches <ref> [14, 3] </ref>. 3 Implementation and Analysis of Max-Cut Declustering In this section, we present the implementation and analysis of the max-cut declustering approach. The analysis will demonstrate in forthcoming theorem 1 that the max-cut declustering approach is capable of achieving perfect declustering, if perfect declustering exists. <p> Those data items which belong to the same group are allocated to the same disk. We implement the N-way max-cut graph partitioning by repeated applications of two-way graph partitioning, using the modified ratio-cut heuristic <ref> [3] </ref>. The cost metric in the two-way ratio-cut algorithm is modified to be E c fl jAjfl jBj, and the sign of the weight on the edge is changed to negative, to maximize the weight on the edges in the cut-set.
Reference: [4] <author> D.J. DeWitt and et. al. </author> <title> "The Gamma Database Machine Project". </title> <journal> IEEE Trans. on Knowledge and Data Engineering, </journal> <volume> 2(1), </volume> <year> 1990. </year>
Reference-contexts: These methods provide a mapping function from the domain of data-items to the set of disk-ids, assuming that all data-items and queries are equiprobable. Several single-attribute functions including round robin, hash-partitioning, key-range partitioning <ref> [4, 10] </ref>, and hybrid of these [11], as well as multi-attribute functions including disk modulo [5, 19], generalized disk modulo (linear) [5, 25], field-wise-XOR [16], Hilbert [6], error correcting code [7], latin-square [25, 15], random [2] and lattice [25] have been proposed and evaluated.
Reference: [5] <author> H. C. Du and J. S. Sobolewski. </author> <title> "Disk Allocation for Product Files on Multiple Disk Systems". </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 7, </volume> <month> March </month> <year> 1982. </year>
Reference-contexts: These methods provide a mapping function from the domain of data-items to the set of disk-ids, assuming that all data-items and queries are equiprobable. Several single-attribute functions including round robin, hash-partitioning, key-range partitioning [4, 10], and hybrid of these [11], as well as multi-attribute functions including disk modulo <ref> [5, 19] </ref>, generalized disk modulo (linear) [5, 25], field-wise-XOR [16], Hilbert [6], error correcting code [7], latin-square [25, 15], random [2] and lattice [25] have been proposed and evaluated. A survey of multi-attribute functions can be found in [7, 6]. <p> Several single-attribute functions including round robin, hash-partitioning, key-range partitioning [4, 10], and hybrid of these [11], as well as multi-attribute functions including disk modulo [5, 19], generalized disk modulo (linear) <ref> [5, 25] </ref>, field-wise-XOR [16], Hilbert [6], error correcting code [7], latin-square [25, 15], random [2] and lattice [25] have been proposed and evaluated. A survey of multi-attribute functions can be found in [7, 6]. These methods are limited for managing updates, non-uniform data-distributions and nonuniform data-sizes. <p> Corollary 2 The max-cut declustering method is a perfect allocation method with respect to the Row queries over one dimension of a k-dimensional grid. Proof: The Disk Modulo method is strictly optimal (i.e., perfect) for all partial match queries, with only one unspecified attribute <ref> [5] </ref>. Therefore, the corollary is derived from theorem 1. 2 Theorem 1 demonstrates that the max-cut declus-tering (partition) is capable of achieving perfect declustering, if a perfect declustering exists. However, perfect declustering does not exist for all query-sets, e.g. range queries [25]. <p> We note that the hot-spot data-set is not factorizable and has been used in literature [18] to simulate skewed distributions. We compare max-cut declustering with two well-known mapping-function-based methods, the Hilbert allocation method [6] and the Linear method <ref> [25, 19, 5] </ref>. The Hilbert method is chosen for comparison, since it achieves good performance for square-shape range queries [6]. Two types of linear methods are also used in our experiments. The first one, denoted as Linear1, uses the modulo function (x + y) mod N. <p> The first one, denoted as Linear1, uses the modulo function (x + y) mod N. The second one, represented as Linear2, uses the modulo function (x + 5y) mod N. The Linear1 method is also known as the CMD method [19] or the Disk Modulo method (DM) <ref> [5] </ref> in a two-dimensional space. The Linear2 method belongs to the class of Generalized Disk Modulo method (GMD) [5], which can achieve perfect load-balance for many query-sets including Row/Col queries [25]. We also report the performance of a fictitious method, called optimal, in all tables and graph. <p> The Linear1 method is also known as the CMD method [19] or the Disk Modulo method (DM) <ref> [5] </ref> in a two-dimensional space. The Linear2 method belongs to the class of Generalized Disk Modulo method (GMD) [5], which can achieve perfect load-balance for many query-sets including Row/Col queries [25]. We also report the performance of a fictitious method, called optimal, in all tables and graph.
Reference: [6] <author> C. Faloutsos and P. Bhagwat. </author> <title> "Declustering Using Fractals". </title> <booktitle> In Proc. of Intl Symposium on Databases in Parallel and Distributed Systems, </booktitle> <pages> pages 18-25, </pages> <year> 1993. </year>
Reference-contexts: Several single-attribute functions including round robin, hash-partitioning, key-range partitioning [4, 10], and hybrid of these [11], as well as multi-attribute functions including disk modulo [5, 19], generalized disk modulo (linear) [5, 25], field-wise-XOR [16], Hilbert <ref> [6] </ref>, error correcting code [7], latin-square [25, 15], random [2] and lattice [25] have been proposed and evaluated. A survey of multi-attribute functions can be found in [7, 6]. These methods are limited for managing updates, non-uniform data-distributions and nonuniform data-sizes. <p> A survey of multi-attribute functions can be found in <ref> [7, 6] </ref>. These methods are limited for managing updates, non-uniform data-distributions and nonuniform data-sizes. Furthermore, they are limited in their ability to adapt to available information about query distribution and size constraints. Lastly, these techniques are not designed for schema partitioning. <p> We note that the hot-spot data-set is not factorizable and has been used in literature [18] to simulate skewed distributions. We compare max-cut declustering with two well-known mapping-function-based methods, the Hilbert allocation method <ref> [6] </ref> and the Linear method [25, 19, 5]. The Hilbert method is chosen for comparison, since it achieves good performance for square-shape range queries [6]. Two types of linear methods are also used in our experiments. <p> We compare max-cut declustering with two well-known mapping-function-based methods, the Hilbert allocation method <ref> [6] </ref> and the Linear method [25, 19, 5]. The Hilbert method is chosen for comparison, since it achieves good performance for square-shape range queries [6]. Two types of linear methods are also used in our experiments. The first one, denoted as Linear1, uses the modulo function (x + y) mod N. The second one, represented as Linear2, uses the modulo function (x + 5y) mod N. <p> We consider several types of queries, including square-shape, rectangle-shape range queries, and diagonal/row/column queries. The square-shape queries represent range queries with equal lengths on both side and are used to evaluate declustering methods in recent studies <ref> [6, 12] </ref>. In our experiments, we examine all possible square-range queries. Suppose that the grid file is a MxM grid. The row-query (Row) set is a set of 1xM rectangle-shape queries and the column-query (Col) set is a set of Mx1 rectangle-shape queries.
Reference: [7] <author> C. Faloutsos and D. Metaxas. </author> <title> "Disk Allocation Methods Using Error Correcting Codes". </title> <journal> IEEE Trans. on Computers, </journal> <volume> 40(8), </volume> <month> August </month> <year> 1991. </year>
Reference-contexts: 1 Introduction With an increasing performance gap between processors and I/O systems, parallelizing I/O operations by declustering data <ref> [8, 7, 21] </ref> is becoming essential for high performance applications. The database machines, multi-processors and parallel computers can all benefit from effective declustering. <p> Unfortunately, this problem is NP-complete in several contexts, which include partial match queries on cartesian product files <ref> [7] </ref> and join queries on a set of relations [21]. Thus any method to solve this problem in polynomial time will be heuristic. Several heuristic methods have been proposed that are based on the ideas of mapping functions and similarity. <p> Several single-attribute functions including round robin, hash-partitioning, key-range partitioning [4, 10], and hybrid of these [11], as well as multi-attribute functions including disk modulo [5, 19], generalized disk modulo (linear) [5, 25], field-wise-XOR [16], Hilbert [6], error correcting code <ref> [7] </ref>, latin-square [25, 15], random [2] and lattice [25] have been proposed and evaluated. A survey of multi-attribute functions can be found in [7, 6]. These methods are limited for managing updates, non-uniform data-distributions and nonuniform data-sizes. <p> A survey of multi-attribute functions can be found in <ref> [7, 6] </ref>. These methods are limited for managing updates, non-uniform data-distributions and nonuniform data-sizes. Furthermore, they are limited in their ability to adapt to available information about query distribution and size constraints. Lastly, these techniques are not designed for schema partitioning. <p> To find the initial partition, we use the approaches suggested in [14] 1 . 3.2 Analysis of Max-Cut Declustering Approach We first define two properties of declustering methods, namely, balance and perfectness, using concepts from <ref> [25, 7, 12] </ref>. We then characterize when the proposed declustering method has these properties in theorem 1, and illustrate two interesting cases in corollary 1 and 2.
Reference: [8] <author> M.T. Fang, R.C.T. Lee, and C.C. Chang. </author> <title> "The Idea of Declustering and its Applications". </title> <booktitle> In Proc. of Intl Conference on Very Large Databases. VLDB, 1986. Proc. of the IEEE Eleventh Intl. Conference on Data Engineering, </booktitle> <month> March </month> <year> 1995 </year> <month> 9 </month>
Reference-contexts: 1 Introduction With an increasing performance gap between processors and I/O systems, parallelizing I/O operations by declustering data <ref> [8, 7, 21] </ref> is becoming essential for high performance applications. The database machines, multi-processors and parallel computers can all benefit from effective declustering. <p> These methods are limited for managing updates, non-uniform data-distributions and nonuniform data-sizes. Furthermore, they are limited in their ability to adapt to available information about query distribution and size constraints. Lastly, these techniques are not designed for schema partitioning. Fang et. al. <ref> [8] </ref> introduced the similarity idea (e.g. nearest neighbor) for declustering. Minimal spanning trees and shortest spanning paths were proposed in [8] to divide a set of given data-items into two "similar" groups. Index-specific load-balancing based declustering methods have been proposed for B-tree [22], R-tree [13] and temporal index [17] etc. <p> Lastly, these techniques are not designed for schema partitioning. Fang et. al. <ref> [8] </ref> introduced the similarity idea (e.g. nearest neighbor) for declustering. Minimal spanning trees and shortest spanning paths were proposed in [8] to divide a set of given data-items into two "similar" groups. Index-specific load-balancing based declustering methods have been proposed for B-tree [22], R-tree [13] and temporal index [17] etc. Dynamic file allocation methods are proposed in FIVE system [24]. <p> Section 4 presents the application of the proposed method to parallelizing Grid Files. Experiments in this context are also presented. Finally, section 5 presents the conclusions and suggests future work. 2 Similarity-Based Approach to Declustering The idea of declustering was originally introduced by Fang et. al. in <ref> [8] </ref> as follows: Given a set of data, divide them into two groups such that these two groups are similar to each other.
Reference: [9] <author> M.R. Garey and D.S. Johnson. </author> <title> "Computers and Intractability: A Guide to the Theory of NP-Completeness". W.H. </title> <publisher> Freeman and Company, </publisher> <address> San Francisco, </address> <year> 1979. </year>
Reference-contexts: Thus, it takes the same amount of I/O time to retrieve each data item (e.g. a bucket or a page). A generalized formulation to model different sizes of data-items is discussed in [23]. 2.3 Max-cut Graph Partitioning Tech niques Unfortunately, the max-cut graph-partitioning problem, as stated, remains NP-complete <ref> [9] </ref>, which can be shown by reducing it to the complementary min-cut graph partitioning problem [14].
Reference: [10] <author> S. Ghandeharizadeh and D.J. DeWitt. </author> <title> "A Mutltiuser Performance Analysis of Alternative Declustering Strategies". </title> <booktitle> In Proc. of the 6th Intl Conference on Data Engineering. IEEE, </booktitle> <year> 1990. </year>
Reference-contexts: These methods provide a mapping function from the domain of data-items to the set of disk-ids, assuming that all data-items and queries are equiprobable. Several single-attribute functions including round robin, hash-partitioning, key-range partitioning <ref> [4, 10] </ref>, and hybrid of these [11], as well as multi-attribute functions including disk modulo [5, 19], generalized disk modulo (linear) [5, 25], field-wise-XOR [16], Hilbert [6], error correcting code [7], latin-square [25, 15], random [2] and lattice [25] have been proposed and evaluated.
Reference: [11] <author> S. Ghandeharizadeh and D.J. DeWitt. </author> <title> "Hybrid-range Partitioning Strategy: A New Declustering Strategy for Multiprocessor Database Machine". </title> <booktitle> In Proc. of Intl Conference on Very Large Databases. VLDB, </booktitle> <year> 1990. </year>
Reference-contexts: These methods provide a mapping function from the domain of data-items to the set of disk-ids, assuming that all data-items and queries are equiprobable. Several single-attribute functions including round robin, hash-partitioning, key-range partitioning [4, 10], and hybrid of these <ref> [11] </ref>, as well as multi-attribute functions including disk modulo [5, 19], generalized disk modulo (linear) [5, 25], field-wise-XOR [16], Hilbert [6], error correcting code [7], latin-square [25, 15], random [2] and lattice [25] have been proposed and evaluated. A survey of multi-attribute functions can be found in [7, 6]. <p> The size-constraint predicate L i for each disk may be determined based on the disk load-balance criterion, available disk capacity, N and sizeof (V). It could represent either disk-capacity constraints, P v2G i size (v) Capacity (disk i ), or storage-load balance constraints. It could balance the "heat" <ref> [11] </ref> or frequency of access to data-items in each group. We note that the problem definition explicitly accounts for available information about query distribution via weights on edges. It also accounts for data sizes, data distribution, and disk-load size constraints.
Reference: [12] <author> Bhaskar Himmatsingka and Jaideep Srivastava. </author> <title> "Performance Evaluation of Grid Based Multi-Attribute Record Declustering Methods". </title> <booktitle> In Proc. of the Tenth Intl Conference on Data Engineering. IEEE, </booktitle> <year> 1994. </year>
Reference-contexts: To find the initial partition, we use the approaches suggested in [14] 1 . 3.2 Analysis of Max-Cut Declustering Approach We first define two properties of declustering methods, namely, balance and perfectness, using concepts from <ref> [25, 7, 12] </ref>. We then characterize when the proposed declustering method has these properties in theorem 1, and illustrate two interesting cases in corollary 1 and 2. <p> The Grid file partitions the coordinate space into rectangular grids, called cells. We will work with a two-dimensional coordinate space for simplicity. The result can be generalized to higher dimensions. Most existing declustering methods for grid files <ref> [25, 12] </ref> are based on coordinate mapping of the data pages in the grid-directory to the disk-id, assuming that data are uniformly distributed. However, for many nonuniform distributions, multiple grid cells may need to share a disk block [20], and the mapping-function based methods will then need to resolve conflicts. <p> We consider several types of queries, including square-shape, rectangle-shape range queries, and diagonal/row/column queries. The square-shape queries represent range queries with equal lengths on both side and are used to evaluate declustering methods in recent studies <ref> [6, 12] </ref>. In our experiments, we examine all possible square-range queries. Suppose that the grid file is a MxM grid. The row-query (Row) set is a set of 1xM rectangle-shape queries and the column-query (Col) set is a set of Mx1 rectangle-shape queries.
Reference: [13] <author> I. Kamel and C. Faloutsos. </author> <title> "Parallel R-Trees". </title> <booktitle> In Proc. of Intl Conference on Management of Data. ACM SIGMOD, </booktitle> <year> 1992. </year>
Reference-contexts: Fang et. al. [8] introduced the similarity idea (e.g. nearest neighbor) for declustering. Minimal spanning trees and shortest spanning paths were proposed in [8] to divide a set of given data-items into two "similar" groups. Index-specific load-balancing based declustering methods have been proposed for B-tree [22], R-tree <ref> [13] </ref> and temporal index [17] etc. Dynamic file allocation methods are proposed in FIVE system [24]. These methods are incremental in nature to balance the load (e.g. storage, I/O time) in various partitions for a window (i.e. a subset of existing data-items in partitions) around the new data-item.
Reference: [14] <author> B.W. Kernighan and S. Lin. </author> <title> "An Efficient Heuristic Procedure for Partitioning Graphs". </title> <journal> Bell Syst. Tech. J., </journal> <volume> 49(2) </volume> <pages> 291-307, </pages> <month> February </month> <year> 1970. </year>
Reference-contexts: A generalized formulation to model different sizes of data-items is discussed in [23]. 2.3 Max-cut Graph Partitioning Tech niques Unfortunately, the max-cut graph-partitioning problem, as stated, remains NP-complete [9], which can be shown by reducing it to the complementary min-cut graph partitioning problem <ref> [14] </ref>. The min-cut graph partitioning problem is to partition the nodes of a graph with weight on its edges into subsets of given sizes so as to minimize the sum of the weight on all edges in the Cut-Set. Kernighan and Lin [14] have shown that by changing the signs of <p> it to the complementary min-cut graph partitioning problem <ref> [14] </ref>. The min-cut graph partitioning problem is to partition the nodes of a graph with weight on its edges into subsets of given sizes so as to minimize the sum of the weight on all edges in the Cut-Set. Kernighan and Lin [14] have shown that by changing the signs of all edge weights, the max-cut graph partitioning problem can be transformed to the min-cut graph partitioning problem. <p> Many good heuristic algorithms which have been developed for the min-cut graph partitioning problem can also be applied to efficiently solve the max-cut graph-partitioning problem. These heuristics Proc. of the IEEE Eleventh Intl. Conference on Data Engineering, March 1995 4 are based on spectral partitioning [1], and iterative approaches <ref> [14, 3] </ref>. 3 Implementation and Analysis of Max-Cut Declustering In this section, we present the implementation and analysis of the max-cut declustering approach. The analysis will demonstrate in forthcoming theorem 1 that the max-cut declustering approach is capable of achieving perfect declustering, if perfect declustering exists. <p> The pairwise optimization process may converge quickly, if the number of disks (groups) is not very large. CPU cost for partitioning can also be controlled by T , which limits the number of passes for pairwise optimization. To find the initial partition, we use the approaches suggested in <ref> [14] </ref> 1 . 3.2 Analysis of Max-Cut Declustering Approach We first define two properties of declustering methods, namely, balance and perfectness, using concepts from [25, 7, 12].
Reference: [15] <author> K. Kim and V.K. Prasanna. </author> <title> "Latin Squares for Parallel Array Access". </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> 4(4) </volume> <pages> 361-370, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Several single-attribute functions including round robin, hash-partitioning, key-range partitioning [4, 10], and hybrid of these [11], as well as multi-attribute functions including disk modulo [5, 19], generalized disk modulo (linear) [5, 25], field-wise-XOR [16], Hilbert [6], error correcting code [7], latin-square <ref> [25, 15] </ref>, random [2] and lattice [25] have been proposed and evaluated. A survey of multi-attribute functions can be found in [7, 6]. These methods are limited for managing updates, non-uniform data-distributions and nonuniform data-sizes.
Reference: [16] <author> M.H. Kim and S. Pramanik. </author> <title> "Optimal File Distribution for Partial Match Queries". </title> <booktitle> In Proc. of SIGMOD Conference on Management of Data, </booktitle> <pages> pages 173-182. </pages> <publisher> ACM, </publisher> <year> 1988. </year>
Reference-contexts: Several single-attribute functions including round robin, hash-partitioning, key-range partitioning [4, 10], and hybrid of these [11], as well as multi-attribute functions including disk modulo [5, 19], generalized disk modulo (linear) [5, 25], field-wise-XOR <ref> [16] </ref>, Hilbert [6], error correcting code [7], latin-square [25, 15], random [2] and lattice [25] have been proposed and evaluated. A survey of multi-attribute functions can be found in [7, 6]. These methods are limited for managing updates, non-uniform data-distributions and nonuniform data-sizes.
Reference: [17] <author> V. Kouramajian, R. Elmasri, and A. Chaudhry. </author> <title> "Declustering Techniques for Parallelizing Temporal Access Structures". </title> <booktitle> In Proc. of the Tenth Intl Conference on Data Engineering. IEEE, </booktitle> <year> 1994. </year>
Reference-contexts: Minimal spanning trees and shortest spanning paths were proposed in [8] to divide a set of given data-items into two "similar" groups. Index-specific load-balancing based declustering methods have been proposed for B-tree [22], R-tree [13] and temporal index <ref> [17] </ref> etc. Dynamic file allocation methods are proposed in FIVE system [24]. These methods are incremental in nature to balance the load (e.g. storage, I/O time) in various partitions for a window (i.e. a subset of existing data-items in partitions) around the new data-item.
Reference: [18] <author> R. Krishnamurthy and K.-Y. Whang. </author> <title> "Multilevel Grid Files". </title> <institution> IBM Research Report, </institution> <year> 1985. </year>
Reference-contexts: We then generate and insert 3K/4 other points from the normal distribution, with a small standard deviation. We note that the hot-spot data-set is not factorizable and has been used in literature <ref> [18] </ref> to simulate skewed distributions. We compare max-cut declustering with two well-known mapping-function-based methods, the Hilbert allocation method [6] and the Linear method [25, 19, 5]. The Hilbert method is chosen for comparison, since it achieves good performance for square-shape range queries [6].
Reference: [19] <author> J. Li, J. Srivastava, and D. Rotem. "CMD: </author> <title> A Multidimensional Declustering Method for Parallel Database Systems". </title> <booktitle> In Proc. of Intl Conference on Very Large Data Bases, </booktitle> <year> 1992. </year>
Reference-contexts: These methods provide a mapping function from the domain of data-items to the set of disk-ids, assuming that all data-items and queries are equiprobable. Several single-attribute functions including round robin, hash-partitioning, key-range partitioning [4, 10], and hybrid of these [11], as well as multi-attribute functions including disk modulo <ref> [5, 19] </ref>, generalized disk modulo (linear) [5, 25], field-wise-XOR [16], Hilbert [6], error correcting code [7], latin-square [25, 15], random [2] and lattice [25] have been proposed and evaluated. A survey of multi-attribute functions can be found in [7, 6]. <p> We note that the hot-spot data-set is not factorizable and has been used in literature [18] to simulate skewed distributions. We compare max-cut declustering with two well-known mapping-function-based methods, the Hilbert allocation method [6] and the Linear method <ref> [25, 19, 5] </ref>. The Hilbert method is chosen for comparison, since it achieves good performance for square-shape range queries [6]. Two types of linear methods are also used in our experiments. The first one, denoted as Linear1, uses the modulo function (x + y) mod N. <p> The first one, denoted as Linear1, uses the modulo function (x + y) mod N. The second one, represented as Linear2, uses the modulo function (x + 5y) mod N. The Linear1 method is also known as the CMD method <ref> [19] </ref> or the Disk Modulo method (DM) [5] in a two-dimensional space. The Linear2 method belongs to the class of Generalized Disk Modulo method (GMD) [5], which can achieve perfect load-balance for many query-sets including Row/Col queries [25].
Reference: [20] <author> J. Nievergelt, H. Hinteberger, and K.D. Sevcik. </author> <title> "The Grid File: An Adaptable, Symmetric Multi-Key File Structure". </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 9(1) </volume> <pages> 38-71, </pages> <year> 1984. </year>
Reference-contexts: addition, heuristic implementation of max-cut declustering may not always provide optimal declustering. 4 Experiments with Grid Files In this section, we focus on detailed experimental evaluation in context of a real-world indexing method, namely Grid Files. 4.1 Parallelizing Grid Files We apply the max-cut declustering scheme to par-allelizing Grid files <ref> [20] </ref>, a well known access method for multi-dimensional and spatial data. The Grid file partitions the coordinate space into rectangular grids, called cells. We will work with a two-dimensional coordinate space for simplicity. The result can be generalized to higher dimensions. <p> Most existing declustering methods for grid files [25, 12] are based on coordinate mapping of the data pages in the grid-directory to the disk-id, assuming that data are uniformly distributed. However, for many nonuniform distributions, multiple grid cells may need to share a disk block <ref> [20] </ref>, and the mapping-function based methods will then need to resolve conflicts. In addition, the mapping-based methods need extension to deal with the splitting and merging that result from updates, since these events may change the grid-coordinates of existing data-pages.
Reference: [21] <author> D. Rotem, G.A. Schloss, and A. Segev. </author> <title> "Data Allocation for Multidisk Databases". </title> <journal> IEEE Trans. on Knowledge and Data Engineering, </journal> <volume> 5(5), </volume> <month> October </month> <year> 1993. </year>
Reference-contexts: 1 Introduction With an increasing performance gap between processors and I/O systems, parallelizing I/O operations by declustering data <ref> [8, 7, 21] </ref> is becoming essential for high performance applications. The database machines, multi-processors and parallel computers can all benefit from effective declustering. <p> Unfortunately, this problem is NP-complete in several contexts, which include partial match queries on cartesian product files [7] and join queries on a set of relations <ref> [21] </ref>. Thus any method to solve this problem in polynomial time will be heuristic. Several heuristic methods have been proposed that are based on the ideas of mapping functions and similarity. The mapping-function-based techniques have been proposed for k-dimensional and spatial data with partial match queries and range queries.
Reference: [22] <author> B. Seeger and P.A. Larson. </author> <title> "Multi-Disk B-trees". </title> <booktitle> In Proc. of Intl Conference on Management of Data. ACM SIGMOD, </booktitle> <year> 1991. </year>
Reference-contexts: Fang et. al. [8] introduced the similarity idea (e.g. nearest neighbor) for declustering. Minimal spanning trees and shortest spanning paths were proposed in [8] to divide a set of given data-items into two "similar" groups. Index-specific load-balancing based declustering methods have been proposed for B-tree <ref> [22] </ref>, R-tree [13] and temporal index [17] etc. Dynamic file allocation methods are proposed in FIVE system [24]. These methods are incremental in nature to balance the load (e.g. storage, I/O time) in various partitions for a window (i.e. a subset of existing data-items in partitions) around the new data-item.
Reference: [23] <author> S. Shekhar and D. R. Liu. </author> <title> "A Similarity-Graph Based Approach to Declustering and Its Application Toward Parallelizing Grid Files". </title> <type> Technical report, </type> <institution> Computer Science Dept. University of Minnesota, </institution> <year> 1994. </year>
Reference-contexts: The above formulation assumes that the size of each data-item is the same. Thus, it takes the same amount of I/O time to retrieve each data item (e.g. a bucket or a page). A generalized formulation to model different sizes of data-items is discussed in <ref> [23] </ref>. 2.3 Max-cut Graph Partitioning Tech niques Unfortunately, the max-cut graph-partitioning problem, as stated, remains NP-complete [9], which can be shown by reducing it to the complementary min-cut graph partitioning problem [14]. <p> Lemma 1 A partition of W SG (q), for query q into N groups, has the maximum weight on the cut-set, if and only if the partition is balanced with respect to q. Proof: The proof can be found in a detailed version of this paper <ref> [23] </ref>. 2 Lemma 2 If an allocation/partition method is perfect with respect to a query set Q s , then it has the maximum weight on the cut-set of W SG (Q s ). <p> The partitioning of data-pages among disks may need revision to adapt to changes in the data distribution. Incremental declustering strategies are low-cost heuristics used to reorganize the partitioning after changes in data distribution. We describe the incremental declustering strategies for grid files in <ref> [23] </ref>. 4.2 Experiment Design We examine range queries over a two-dimensional data set that is partitioned by the grid file. Query execution is simulated to measure the response time, i.e., the number of parallel I/O required to fetch the data pages, qualifying in the queries.
Reference: [24] <author> G. Weikum, P. Zabback, and P. Scheuermann. </author> <title> "Dynamic File Allocation in Disk Arrays". </title> <booktitle> In Proc. of Intl Conference on Management of Data. ACM SIGMOD, </booktitle> <year> 1991. </year>
Reference-contexts: Minimal spanning trees and shortest spanning paths were proposed in [8] to divide a set of given data-items into two "similar" groups. Index-specific load-balancing based declustering methods have been proposed for B-tree [22], R-tree [13] and temporal index [17] etc. Dynamic file allocation methods are proposed in FIVE system <ref> [24] </ref>. These methods are incremental in nature to balance the load (e.g. storage, I/O time) in various partitions for a window (i.e. a subset of existing data-items in partitions) around the new data-item. The incremental nature of the load balance method allows them to work well with indexing methods (e.g.
Reference: [25] <author> Y. Zhou, S. Shekhar, and M. Coyle. </author> <title> "Disk Allocation Methods for Parallelizing Grid Files". </title> <booktitle> In Proc. of the Tenth Intl Conference on Data Engineering. IEEE, </booktitle> <year> 1994. </year>
Reference-contexts: Several single-attribute functions including round robin, hash-partitioning, key-range partitioning [4, 10], and hybrid of these [11], as well as multi-attribute functions including disk modulo [5, 19], generalized disk modulo (linear) <ref> [5, 25] </ref>, field-wise-XOR [16], Hilbert [6], error correcting code [7], latin-square [25, 15], random [2] and lattice [25] have been proposed and evaluated. A survey of multi-attribute functions can be found in [7, 6]. These methods are limited for managing updates, non-uniform data-distributions and nonuniform data-sizes. <p> Several single-attribute functions including round robin, hash-partitioning, key-range partitioning [4, 10], and hybrid of these [11], as well as multi-attribute functions including disk modulo [5, 19], generalized disk modulo (linear) [5, 25], field-wise-XOR [16], Hilbert [6], error correcting code [7], latin-square <ref> [25, 15] </ref>, random [2] and lattice [25] have been proposed and evaluated. A survey of multi-attribute functions can be found in [7, 6]. These methods are limited for managing updates, non-uniform data-distributions and nonuniform data-sizes. <p> Several single-attribute functions including round robin, hash-partitioning, key-range partitioning [4, 10], and hybrid of these [11], as well as multi-attribute functions including disk modulo [5, 19], generalized disk modulo (linear) [5, 25], field-wise-XOR [16], Hilbert [6], error correcting code [7], latin-square [25, 15], random [2] and lattice <ref> [25] </ref> have been proposed and evaluated. A survey of multi-attribute functions can be found in [7, 6]. These methods are limited for managing updates, non-uniform data-distributions and nonuniform data-sizes. Furthermore, they are limited in their ability to adapt to available information about query distribution and size constraints. <p> To find the initial partition, we use the approaches suggested in [14] 1 . 3.2 Analysis of Max-Cut Declustering Approach We first define two properties of declustering methods, namely, balance and perfectness, using concepts from <ref> [25, 7, 12] </ref>. We then characterize when the proposed declustering method has these properties in theorem 1, and illustrate two interesting cases in corollary 1 and 2. <p> Therefore, the corollary is derived from theorem 1. 2 Theorem 1 demonstrates that the max-cut declus-tering (partition) is capable of achieving perfect declustering, if a perfect declustering exists. However, perfect declustering does not exist for all query-sets, e.g. range queries <ref> [25] </ref>. In this situation, no declus-tering method can achieve theoretically optimal response time. <p> The Grid file partitions the coordinate space into rectangular grids, called cells. We will work with a two-dimensional coordinate space for simplicity. The result can be generalized to higher dimensions. Most existing declustering methods for grid files <ref> [25, 12] </ref> are based on coordinate mapping of the data pages in the grid-directory to the disk-id, assuming that data are uniformly distributed. However, for many nonuniform distributions, multiple grid cells may need to share a disk block [20], and the mapping-function based methods will then need to resolve conflicts. <p> We note that the hot-spot data-set is not factorizable and has been used in literature [18] to simulate skewed distributions. We compare max-cut declustering with two well-known mapping-function-based methods, the Hilbert allocation method [6] and the Linear method <ref> [25, 19, 5] </ref>. The Hilbert method is chosen for comparison, since it achieves good performance for square-shape range queries [6]. Two types of linear methods are also used in our experiments. The first one, denoted as Linear1, uses the modulo function (x + y) mod N. <p> The Linear1 method is also known as the CMD method [19] or the Disk Modulo method (DM) [5] in a two-dimensional space. The Linear2 method belongs to the class of Generalized Disk Modulo method (GMD) [5], which can achieve perfect load-balance for many query-sets including Row/Col queries <ref> [25] </ref>. We also report the performance of a fictitious method, called optimal, in all tables and graph. It represents the perfect method, i.e., it is assumed to speed up the I/O time of a query by a factor of N given N disks. <p> Suppose that the grid file is a MxM grid. The row-query (Row) set is a set of 1xM rectangle-shape queries and the column-query (Col) set is a set of Mx1 rectangle-shape queries. The diagonal queries include Principle Diagonal (PD) queries and the Anti-Diagonal (PA) queries <ref> [25] </ref>. <p> Diagonal, Row and Column Queries Now, we examine a query set, including PD, PA, Row and Col queries for which the mapping-function-based methods are not perfect, since the number of disk is a power of two <ref> [25] </ref>. Table 1 (B) lists the average response time over all the PA/PD/Row/Col queries for each method, under different grid sizes and number of disks. <p> We broke the tie in a fair manner by choosing a disk at random. This is consistent with the tie-breaking approaches used previously in mapping-function based methods to decluster grid files <ref> [25] </ref>. The experiments are conducted on square-shape range queries. Table 2 lists the average response time over square-shape queries for each method, under different data distributions and number of disks. Both SMaxCut and GMaxCut achieve better performance than the others in both non-uniformly distributed data sets.
References-found: 25

