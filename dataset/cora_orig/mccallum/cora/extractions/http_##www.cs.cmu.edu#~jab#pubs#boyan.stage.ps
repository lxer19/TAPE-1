URL: http://www.cs.cmu.edu/~jab/pubs/boyan.stage.ps
Refering-URL: http://www.cs.cmu.edu/afs/cs/user/jab/web/cv/cv100.html
Root-URL: 
Email: fjab,awmg@cs.cmu.edu  
Title: Using Prediction to Improve Combinatorial Optimization Search  
Author: Justin A. Boyan and Andrew W. Moore 
Address: Pittsburgh, PA 15213  
Affiliation: Computer Science Department Carnegie Mellon University  
Abstract: To appear in AISTATS-97 This paper describes a statistical approach to improving the performance of stochastic search algorithms for optimization. Given a search algorithm A, we learn to predict the outcome of A as a function of state features along a search trajectory. Predictions are made by a function approximator such as global or locally-weighted polynomial regression; training data is collected by Monte-Carlo simulation. Extrapolating from this data produces a new evaluation function which can bias future search trajectories toward better optima. Our implementation of this idea, STAGE, has produced very promising results on two large-scale domains.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Bellman. </author> <title> Dynamic Programming. </title> <publisher> Princeton University Press, </publisher> <year> 1957. </year>
Reference-contexts: Since value functions satisfy the Bellman equations <ref> [1] </ref>, algorithms more sophisticated than Monte-Carlo simulation with supervised learning are applicable: in particular, the TD () family of temporal-difference algorithms may make better use of training data and converge faster [6].
Reference: [2] <author> K. D. Boese, A. B. Kahng, and S. Muddu. </author> <title> A new adaptive multi-start technique for combinatorial global optimizations. </title> <journal> Operations Research Letters, </journal> <volume> 16 </volume> <pages> 101-113, </pages> <year> 1994. </year>
Reference: [3] <author> H-Y. Chao and M. P. Harper. </author> <title> An efficient lower bound algorithm for channel routing. Integration: </title> <journal> The VLSI Journal, </journal> <year> 1996. </year>
Reference-contexts: We call this effect transfer and the extent to which it occurs is largely an empirical question. To investigate the potential for transfer, we re-ran experiment (C) on a suite of eight problems from the channel routing literature <ref> [3] </ref>. Table 2 summarizes the results and gives the coefficients of the linear evaluation function learned (independently) for each problem. <p> 12 &lt; 0:71; 0:05; 0:70 &gt; HYC2 9 9 9 &lt; 0:71; 0:21; 0:67 &gt; HYC4 20 42 23 &lt; 0:71; 0:03; 0:71 &gt; HYC6 50 69 51 &lt; 0:70; 0:05; 0:71 &gt; HYC8 21 44 25 &lt; 0:71; 0:03; 0:70 &gt; Table 2: STAGE results on eight problems from <ref> [3] </ref>. The coefficients have been normalized so that their squares sum to one. The similarities among the learned evaluation functions are striking.
Reference: [4] <author> S. E. Frantzich and S. L. Percy. </author> <title> American Government. Brown & Benchmark, </title> <address> Madison, WI, </address> <year> 1994. </year>
Reference-contexts: the end of Section 3.3. 3.2 Area-Reweighted Map Layout The second problem we considered was that of redrawing a map of the United States such that each state's area is proportional to its population. (Such maps provide a useful means of visualizing geographic data and appear in some textbooks, e.g. <ref> [4] </ref>.) The goal of optimization is to best meet the new area targets for each state while minimally distorting the states' shapes and borders. We set up the problem as follows.
Reference: [5] <author> E. Ochotta. </author> <title> Synthesis of High-Performance Analog Cells in AS-TRX/OBLX. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University Department of Electrical and Computer Engineering, </institution> <month> April </month> <year> 1994. </year>
Reference-contexts: All algorithms were run 21 times and allowed a total of 100; 000 function evaluations; the results of the best and median of the 21 runs is reported. The simulated annealing experiments made use of the successful "modified Lam" adaptive annealing schedule <ref> [5, x4.5] </ref>. Experiment (B) shows that hillclimbing gets stuck in very poor local optima, even when allowed to consider 100; 000 random moves. Experiment (E) shows that simulated annealing, as used with the objective function of [8], does considerably better. Surprisingly, the annealer of experiment (F) does better still.
Reference: [6] <author> R. S. Sutton. </author> <title> Learning to predict by the methods of temporal differences. </title> <journal> Machine Learning, </journal> <volume> 3, </volume> <year> 1988. </year>
Reference-contexts: Since value functions satisfy the Bellman equations [1], algorithms more sophisticated than Monte-Carlo simulation with supervised learning are applicable: in particular, the TD () family of temporal-difference algorithms may make better use of training data and converge faster <ref> [6] </ref>. However, our experiments reported in this paper use only supervised learning. 3 2.2 Using the Predictions The learned function V A is designed to predict which states make good starting places for search policy A.
Reference: [7] <author> P. van Laarhoven. </author> <title> Simulated Annealing: Theory and Applications. </title> <publisher> Kluwer Academic, </publisher> <year> 1987. </year>
Reference-contexts: Simulated annealing is Markovian in the expanded state space X fi ftemperatureg <ref> [7] </ref>. Thus, from a search trajectory of length 100, we would obtain not one but 100 training samples for V A . 2 The state space X is huge, so we cannot expect our simulations to explore any significant fraction of it.
Reference: [8] <author> D. F. Wong, H.W. Leong, and C.L. Liu. </author> <title> Simulated Annealing for VLSI Design. </title> <publisher> Kluwer Academic, </publisher> <year> 1988. </year>
Reference-contexts: We have obtained encouraging preliminary results in the domains of channel routing and map layout. 4 3 Results 3.1 Channel Routing The problem of "Manhattan channel routing" is an important subtask of VLSI circuit design <ref> [8] </ref>. Given two rows of labelled pins across a rectangular channel, we must connect like-labelled pins to one another by placing wire segments into vertical and horizontal tracks (see Figure 2). Segments may cross but not otherwise overlap. <p> U = P w i , where u i is the fraction of track i that is unoccupied. <ref> [8] </ref> They hand-tuned the coefficients and set p = 0:5; U = 10. To apply STAGE to this problem, we began with not the contrived function C but the natural objective function f (x) = w. <p> Experiment (B) shows that hillclimbing gets stuck in very poor local optima, even when allowed to consider 100; 000 random moves. Experiment (E) shows that simulated annealing, as used with the objective function of <ref> [8] </ref>, does considerably better. Surprisingly, the annealer of experiment (F) does better still. <p> The coefficients have been normalized so that their squares sum to one. The similarities among the learned evaluation functions are striking. Like the hand-tuned cost function C of <ref> [8] </ref> (Equation 2), all but one of the STAGE-learned cost functions (HYC1) assigned a relatively large positive weight to feature w and a small positive weight to feature p. Unlike the hand-tuned C, all the STAGE runs assigned a negative weight to feature U .
Reference: [9] <author> W. Zhang. </author> <title> Reinforcement Learning for Job-Shop Scheduling. </title> <type> PhD thesis, </type> <institution> Oregon State University, </institution> <year> 1996. </year> <month> 12 </month>
Reference-contexts: Zhang and Dietterich have explored another way to use learning to improve combinatorial optimization: they learn a search strategy from scratch using online value iteration <ref> [9] </ref>. By contrast, STAGE begins with an already-given search strategy and uses prediction to learn to improve on it. Zhang and Dietterich reported success in transferring learned search control knowledge from simple job-shop scheduling instances to more complex ones.
References-found: 9

