URL: ftp://ftp.cs.uchicago.edu/pub/publications/tech-reports/TR-93-18.ps
Refering-URL: http://cs-www.uchicago.edu/publications/tech-reports/
Root-URL: 
Email: friedl@cs.uchicago.edu tsai@cs.uchicago.edu  
Title: t-Particle Random Walks and Recycling Random Bits in Parallel  
Author: Katalin Friedl Shi-Chun Tsai 
Address: 1100 E. 58th St., Chicago, IL 60637  
Affiliation: University of Chicago Department of Computer Science  
Abstract: We show that r pseudo-random bits can be obtained by concatenating t blocks of r=t pseudo-random bits, where the blocks are generated in parallel. This can be considered as a parallel version of [8] recycling random bits by doing a random walk on an expander. The proof is based on the fact that t simultaneous independent random walks on an expander graph is equivalent to a random walk on a much larger expander. In [8] generating the random walk requires arithmetical operations with long integers. In the parallel version the integers involved are much shorter, and different segments of the pseudo-random bits are generated independently in parallel. Optimal speedup is also achieved.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Ajtai, J. Komlos, and E. Szemeredi. </author> <title> Deterministic simulation of logspace. </title> <booktitle> In 19th STOC, </booktitle> <pages> pages 132-140, </pages> <year> 1987. </year>
Reference-contexts: The method to obtain the pseudo-random bits is based on random walks on explicitly given expanders. The idea of using expanders to reduce the error was proposed in <ref> [15, 1] </ref>. The first explicit construction of expanders is from [12]. A simplified and improved version is in [7]. There are other construction of better expanders [13, 10]. <p> More generally, j (N B)(N B)(M B)p 0 j indicates the probability of generating bad pseudo-random bits, good pseudo-random bits and again good pseudo-random bits in order. In the sequel, we follow the proof technique used in <ref> [1] </ref>. 7 Lemma 6 [8] Let p = (p 1 ; ; p 2 r ), where p i 0 and P 2 r i=1 p i = 1. Then (1) k M Bp kk p k. (2) k N Bp kk p k =5. Proof.
Reference: [2] <author> N. Alon. </author> <title> Eigenvalues and expanders. </title> <journal> Combinatorica, </journal> <volume> 6 </volume> <pages> 83-96, </pages> <year> 1986. </year>
Reference-contexts: The constant c is called the expansion coefficient or expansion rate of the graph. If G is d-regular then its largest eigenvalue is d. The expansion coefficient is connected to the second largest eigenvalue, namely Theorem 1 <ref> [2] </ref> If is the second largest eigenvalue of the d-regular graph G with n vertices, then G is an (n; d; c)-expander for c = 2 (d) 3d2 . <p> For example in [7], an (n; d; c)-expander is defined as a bipartite graph with n inputs, n outputs and at most dn edges, such that for every subset X of inputs, jN (X)j (1 + c (1 jXj=n))jXj. These graphs are called strong (n; d; c)-expanders in <ref> [2] </ref>. There is a relation between expanders and strong expanders, which was proved in [2]. If G = (I; O; E) is a strong (n; d; c)-expander, then G is a (2n; d; c=16)-expander. <p> These graphs are called strong (n; d; c)-expanders in <ref> [2] </ref>. There is a relation between expanders and strong expanders, which was proved in [2]. If G = (I; O; E) is a strong (n; d; c)-expander, then G is a (2n; d; c=16)-expander. The expansion rate can be improved from c=16 to c=6 by a more careful estimate in the proof.
Reference: [3] <author> N. Alon, J. Spencer, and P. Erd-os. </author> <title> The Probabilistic Method. </title> <publisher> John Wiley and Sons Inc., </publisher> <year> 1991. </year>
Reference-contexts: By the eigenvalue of a graph we mean the eigenvalue of its adjacency matrix. 2 2.1 Expanders Definition. <ref> [3] </ref> A graph G is called an (n; d; c)-expander if it has n vertices, the maximum degree of a vertex is d, and for every set of vertices W V (G) of cardinality jW j n 2 , the inequality jN (W )j cjW j holds.
Reference: [4] <author> S. Arora, C. Lund, R. Motwani, M. Sudan, and M. Szegedy. </author> <title> Proof verification and hardness of approximation problems. </title> <booktitle> In 33rd FOCS, </booktitle> <pages> pages 14-23, </pages> <year> 1992. </year>
Reference-contexts: Random bits are an expensive resource. Lately much work has been done on "de-randomization" of algorithms. The tricks to save random bits are not just useful in designing efficient algorithms but in other areas, for example they also play an important role in the theory of transparent proofs <ref> [5, 4] </ref>. In some simulations computers can consume thousands of random bits per second. Since the parallel machines are getting more pervasive, the topic of generating pseudo-random numbers in parallel has drawn more and more attention.
Reference: [5] <author> L. Babai, L. Fortnow, and C. Lund. </author> <title> Nondeterministic exponential time has two-prover interactive protocols. </title> <journal> Computational Complexity, </journal> <volume> 1 </volume> <pages> 3-40, </pages> <year> 1991. </year>
Reference-contexts: Random bits are an expensive resource. Lately much work has been done on "de-randomization" of algorithms. The tricks to save random bits are not just useful in designing efficient algorithms but in other areas, for example they also play an important role in the theory of transparent proofs <ref> [5, 4] </ref>. In some simulations computers can consume thousands of random bits per second. Since the parallel machines are getting more pervasive, the topic of generating pseudo-random numbers in parallel has drawn more and more attention.
Reference: [6] <author> A. Cohen and A. Wigderson. Dispersers, </author> <title> deterministic amplification, and weak random sources. </title> <booktitle> In 30th FOCS, </booktitle> <pages> pages 14-19, </pages> <year> 1989. </year>
Reference-contexts: A randomized algorithm which uses r random bits and has error probability less than 1/2 can be repeated t times using independent random bits to reduce the error to less than 1=2 k . This uses rt random bits. Impagliazzo and Zuckerman [8] and independently Cohen 1 and Wigderson <ref> [6] </ref> showed that the error can be reduced by using fewer random bits, namely O (r+k) random bits are sufficient to achieve error less then 1=2 k . <p> The relation is bridged by the fact that the eigenvalues of the tensor product of two matrices can be obtained from the product of the eigenvalues of the two matrices. Therefore the quality of the pseudo-random bits generated by our approach is guaranteed by the results in <ref> [8, 6] </ref>. Meanwhile we can speed up the algorithm in [8] by t times. Thus we get an optimal speedup. The rest of the paper is organized as follows. In section 2 we present some definitions and facts. In section 3 we prove some technical results about graph products.
Reference: [7] <author> O. Gabber and Z. Galil. </author> <title> Explicit construction of linear sized superconcentrators. </title> <journal> J. Comp. and Sys. Sci., </journal> <volume> 22 </volume> <pages> 407-420, </pages> <year> 1981. </year>
Reference-contexts: The method to obtain the pseudo-random bits is based on random walks on explicitly given expanders. The idea of using expanders to reduce the error was proposed in [15, 1]. The first explicit construction of expanders is from [12]. A simplified and improved version is in <ref> [7] </ref>. There are other construction of better expanders [13, 10]. To generate the pseudo-random sequence the algorithm of [8] performs a random walk on a 7-regular expander of size 2 r described in [7]. <p> The first explicit construction of expanders is from [12]. A simplified and improved version is in <ref> [7] </ref>. There are other construction of better expanders [13, 10]. To generate the pseudo-random sequence the algorithm of [8] performs a random walk on a 7-regular expander of size 2 r described in [7]. In the construction, computing the next transition in the random walk involves arithmetic operations on integers of length r (r can be a polynomial of the input size n). The parallel version we propose has the advantage that the length of the numbers involved is reduced. <p> Note that if we consider the matrix 1 d A then its largest eigenvalue is 1 and if 2 is its second largest eigenvalue then c = 2 (1 2 )=(3 2 2 ). Sometimes a slightly different definition of expander is used. For example in <ref> [7] </ref>, an (n; d; c)-expander is defined as a bipartite graph with n inputs, n outputs and at most dn edges, such that for every subset X of inputs, jN (X)j (1 + c (1 jXj=n))jXj. These graphs are called strong (n; d; c)-expanders in [2]. <p> If G = (I; O; E) is a strong (n; d; c)-expander, then G is a (2n; d; c=16)-expander. The expansion rate can be improved from c=16 to c=6 by a more careful estimate in the proof. Gabber and Galil <ref> [7] </ref> explicitly constructed strong (n; 7; (2 p 3)=2)-expanders, where n = m 2 and m is any positive integer, which with our notation are (2n; 7; (2 p 3)=12)-expanders. Let V n be f0; 1; ; m 1g fi f0; 1; ; m 1g. <p> We use the 7-regular expander G with 2 r t vertices. Let A be the adjacency matrix of G, t &gt; 1 be an integer and i be the i-th largest eigenvalue of 1 8 (I + A). With the construction of the 7-regular expander in <ref> [7] </ref>, there is a positive constant * such that 2 &lt; 1 *. We perform t independent random walks on G with the transition matrix 1 8 (I + A). <p> x; y 2 f0; 1g r 2 , can be decomposed by computing i1 (x 1 ; y 1 ) ffi i2 (x 2 ; y 2 ) ffi ffi it (x t ; y t ), where each ij and can be any one of the 7 permutations in <ref> [7] </ref>, and x i 's, y i 's are in f0; 1g r 2t . Note that each ij (x i ; y i ) is computed in parallel.
Reference: [8] <author> R. Impagliazzo and D. Zuckerman. </author> <title> How to recycle random bits. </title> <booktitle> In 30th FOCS, </booktitle> <pages> pages 248-253, </pages> <year> 1989. </year>
Reference-contexts: A randomized algorithm which uses r random bits and has error probability less than 1/2 can be repeated t times using independent random bits to reduce the error to less than 1=2 k . This uses rt random bits. Impagliazzo and Zuckerman <ref> [8] </ref> and independently Cohen 1 and Wigderson [6] showed that the error can be reduced by using fewer random bits, namely O (r+k) random bits are sufficient to achieve error less then 1=2 k . <p> The idea of using expanders to reduce the error was proposed in [15, 1]. The first explicit construction of expanders is from [12]. A simplified and improved version is in [7]. There are other construction of better expanders [13, 10]. To generate the pseudo-random sequence the algorithm of <ref> [8] </ref> performs a random walk on a 7-regular expander of size 2 r described in [7]. In the construction, computing the next transition in the random walk involves arithmetic operations on integers of length r (r can be a polynomial of the input size n). <p> Each generated segment can be stored in a pre-assigned block of memory. To do so, we make t independent random walks on an expander with 2 r=t vertices. Thus the r-bit arithmetics in <ref> [8] </ref> are reduced to t independent r=t-bit arithmetics. Our method uses O (r + tk) random bits to reduce the error probability to 2 k . <p> The relation is bridged by the fact that the eigenvalues of the tensor product of two matrices can be obtained from the product of the eigenvalues of the two matrices. Therefore the quality of the pseudo-random bits generated by our approach is guaranteed by the results in <ref> [8, 6] </ref>. Meanwhile we can speed up the algorithm in [8] by t times. Thus we get an optimal speedup. The rest of the paper is organized as follows. In section 2 we present some definitions and facts. In section 3 we prove some technical results about graph products. <p> Therefore the quality of the pseudo-random bits generated by our approach is guaranteed by the results in [8, 6]. Meanwhile we can speed up the algorithm in <ref> [8] </ref> by t times. Thus we get an optimal speedup. The rest of the paper is organized as follows. In section 2 we present some definitions and facts. In section 3 we prove some technical results about graph products. <p> This so called lazy random walk is used in <ref> [8] </ref>. Instead of P we use another random walk on the s-regular graph G given by the following transition matrix P 0 = 1 s+1 (I + A) = 1 s+1 A 0 . <p> Thus the theorem follows. 2 Now it is clear that t independent random walks with proper transition matrices on an s-regular expander is nothing but a random walk with a random walk on a bigger expander. This allows us to parallelize the computation proposed in <ref> [8] </ref>. 4 How to recycle random bits in parallel The work in [8] is to reduce the error probability with less random bits for the membership problems in BBP . <p> This allows us to parallelize the computation proposed in <ref> [8] </ref>. 4 How to recycle random bits in parallel The work in [8] is to reduce the error probability with less random bits for the membership problems in BBP . <p> The success probability can be amplified with O (r+k) random bits by using an expander with 2 r vertices to generate the pseudo-random sequence <ref> [8] </ref>. The idea is to perform a random walk on the expander and from time to time take the label of the vertex being visited as the next segment of pseudo-random string, meanwhile make enough moves between generating two segments to ensure that the resulting string is pseudo-random. <p> By Corollary 4, we know 1 8 t (I + A (t)) have all, except the largest one, its eigenvalues bounded away from 1, i.e. the second largest eigenvalue is at most 1 fl, where fl = Minf 7* 8 ; 1 8 g. Based on the work in <ref> [8] </ref>, we can state our algorithm as follows. Algorithm: Let ` be the smallest integer such that (1 fl) ` &lt; 1=10. Use r bits to find t starting vertices uniformly. Perform t independent random walks on G with the transition matrix 1 8 (I + A) for 7`k steps. <p> Each r-bit pseudo-random string is generated in parallel. It is not hard to see that we use O (r + tk) random bits in the above algorithm. The correctness of the algorithm can be shown by following the proof in <ref> [8] </ref> with the (8 t 1)-regular expander and the transition matrix 1 8 t (I + A (t)). Note that the expander has 2 r vertices and we will use the label of each vertex as pseudo-random bits. <p> For completeness, we include the proof in this paper, i.e. we will show that by using the pseudo-random bits generated by our algorithm the error probability is at most 2 k . Before we apply our algorithm, as in <ref> [8] </ref> we boost the success probability from 2/3 to .99 by using the usual technique (i.e. we repeat the algorithm a few times and take the majority answers as the output). This step will use at most O (r) random bits. <p> More generally, j (N B)(N B)(M B)p 0 j indicates the probability of generating bad pseudo-random bits, good pseudo-random bits and again good pseudo-random bits in order. In the sequel, we follow the proof technique used in [1]. 7 Lemma 6 <ref> [8] </ref> Let p = (p 1 ; ; p 2 r ), where p i 0 and P 2 r i=1 p i = 1. Then (1) k M Bp kk p k. (2) k N Bp kk p k =5. Proof. <p> Then jSp 0 j represents the probability that the majority of the pseudo-random bits give wrong answers, i.e. it visits the vertices in U more than 7k=2 times in the walk. We can prove that this probability is small. Theorem 7 <ref> [8] </ref> In a random walk giving by the transition matrix B, the probability that it visits the vertices in U more than 7k=2 times is less than 2 k . <p> In total, there are at most 2 7k such sequences S. Thus the probability is bounded by 2 7k 5 7k=2 &lt; 2 k . 2 We now show how to deal with the overhead of long integer arithmetics involved in <ref> [8] </ref>. The smaller expander makes it easier and more feasible to calculate the neighbors in the random walk, since each vertex has a shorter label. <p> It is clear that we can get an optimal speed-up by t times. Note that ` can be very small, if we can find an expander which has a very small second largest eigenvalue and can be efficiently generated. The naive way to parallelize <ref> [8] </ref> would be doing the arithmetic in parallel. Our method is faster than that: assume that r=t-bit operations take one unit time then we do one step in unit time; the naive parallel version of [8] with t processors will take more time, because of the carries between the blocks (see <p> The naive way to parallelize <ref> [8] </ref> would be doing the arithmetic in parallel. Our method is faster than that: assume that r=t-bit operations take one unit time then we do one step in unit time; the naive parallel version of [8] with t processors will take more time, because of the carries between the blocks (see N C addition). Another advantage is that in our method the processors are independent, thus there is no need to communicate among processors.
Reference: [9] <author> L. Lovasz. </author> <title> Combinatorial Problems and Exercises. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <note> second edition, </note> <year> 1993. </year>
Reference-contexts: of two matrices A and B in coordinate form is defined as 3 A nfip B mfiq = 0 B B B B B a 11 B a 12 B ::: a 1p B : : : : : : : : 1 C C C C C : Definition. <ref> [9] </ref> Let G 1 and G 2 be two graphs.
Reference: [10] <author> A. Lubotzky, R. Phillips, and N. Sarnak. </author> <title> Explicit expanders and the ramanujan conjec ture. </title> <booktitle> In 18th STOC, </booktitle> <pages> pages 261-277, </pages> <year> 1986. </year>
Reference-contexts: The idea of using expanders to reduce the error was proposed in [15, 1]. The first explicit construction of expanders is from [12]. A simplified and improved version is in [7]. There are other construction of better expanders <ref> [13, 10] </ref>. To generate the pseudo-random sequence the algorithm of [8] performs a random walk on a 7-regular expander of size 2 r described in [7].
Reference: [11] <author> M. Marcus and H. </author> <title> Minc. A Survey of Matrix Theory and Matrix Inequalities. </title> <publisher> Allyn and Bacon Inc., </publisher> <year> 1964. </year>
Reference-contexts: Note that this expander can be constructed. efficiently by an algorithm. 2.2 Graph product To show that t independent random walks on a smaller expander can be simulated with a random walk on a larger expander we need the following definitions. Definition. <ref> [11] </ref> The tensor (or Kronecker) product of two matrices A and B in coordinate form is defined as 3 A nfip B mfiq = 0 B B B B B a 11 B a 12 B ::: a 1p B : : : : : : : : 1 C C <p> Since we are interested in expanders and the expansion rate is connected to the second largest eigenvalue the following well known fact will be useful. Lemma 2 <ref> [11] </ref> Given two matrices A and B, the eigenvalues of AB are given by all possible products , where and are eigenvalues of A and B, respectively. 2.3 Random walks In a random walk on the graph G a particle starting from an initial vertex u, and in each step it
Reference: [12] <author> G. A. Margulis. </author> <title> Explicit construction of expanders. Probl. </title> <journal> Peredachi Informatsii, 9/4:71 80(in Russian), </journal> <year> 1973. </year> <month> 9 </month>
Reference-contexts: The method to obtain the pseudo-random bits is based on random walks on explicitly given expanders. The idea of using expanders to reduce the error was proposed in [15, 1]. The first explicit construction of expanders is from <ref> [12] </ref>. A simplified and improved version is in [7]. There are other construction of better expanders [13, 10]. To generate the pseudo-random sequence the algorithm of [8] performs a random walk on a 7-regular expander of size 2 r described in [7].
Reference: [13] <author> G. A. Margulis. </author> <title> Explicit group-theoretical constructions of combinatorial schemes and their application to the design of expanders and concentrators. Probl. </title> <journal> Peredachi Infor-matsii(Problems of Information Transmission), 24/1:51-60(in Russian), 39-46(English translation), </journal> <year> 1988. </year>
Reference-contexts: The idea of using expanders to reduce the error was proposed in [15, 1]. The first explicit construction of expanders is from [12]. A simplified and improved version is in [7]. There are other construction of better expanders <ref> [13, 10] </ref>. To generate the pseudo-random sequence the algorithm of [8] performs a random walk on a 7-regular expander of size 2 r described in [7].
Reference: [14] <author> M. O. Rabin. </author> <title> Probabilistic algorithm for testing primality. </title> <journal> Journal of Number Theory, </journal> <volume> 12 </volume> <pages> 128-138, </pages> <year> 1980. </year>
Reference-contexts: 1 Introduction It is well known that randomness plays an important role in computations. Randomized algorithms are often simpler and faster than their deterministic versions. The best known example is the primality test <ref> [14] </ref>. Random bits are an expensive resource. Lately much work has been done on "de-randomization" of algorithms.
Reference: [15] <author> M. Sipser. Expanders, </author> <title> randomness or time vs space. </title> <booktitle> In Structure in Complexity Theory, </booktitle> <pages> pages 325-329, </pages> <year> 1986. </year> <month> 10 </month>
Reference-contexts: The method to obtain the pseudo-random bits is based on random walks on explicitly given expanders. The idea of using expanders to reduce the error was proposed in <ref> [15, 1] </ref>. The first explicit construction of expanders is from [12]. A simplified and improved version is in [7]. There are other construction of better expanders [13, 10].
References-found: 15

