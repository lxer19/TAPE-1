URL: http://www.cs.pitt.edu/~gupta/research/Comp/pact98a.ps
Refering-URL: http://www.cs.pitt.edu/~gupta/research/arch.html
Root-URL: http://www.cs.pitt.edu
Email: fsoner,guptag@cs.pitt.edu  
Title: Superscalar Execution With Dynamic Data Forwarding  
Author: Soner Onder Rajiv Gupta 
Address: Pittsburgh Pittsburgh PA 15260  
Affiliation: Department of Computer Science University of  
Abstract: We empirically demonstrate that in order to take advantage of increasing issue widths, superscalar processors require quadratically growing instruction window sizes. Since conventional central window design aims to provide full data fan-out to all the instructions which are in the window, designing large instruction windows using conventional techniques is not feasible. We show that full data fan-out is not necessary for achieving high performance when a novel approach is used to distribute the values. We use direct matching using a small on chip memory called the wait memory to implement the instruction window and bring in a small subset of instructions which are likely to become ready into a match unit where instruction selection and operand matching tasks are performed. We show that the match unit needs to grow only linearly with the issue width. We use SPEC95 benchmarks to demonstrate that at a given instruction window size our algorithm provides over 90 percent of the IPC that can be obtained by a central window implementation that provides full data fan-out. Keywords: Wide-issue superscalar, instruction window, data fan-out, direct matching, dynamic forwarding. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Arvind, V. Kathail, and K. Pingali. </author> <title> A dataflow architecture with tagged tokens. </title> <type> Technical Report 174, </type> <institution> MIT, </institution> <year> 1980. </year>
Reference-contexts: The Fan-out problem The fan-out problem is the representation and the implementation of the flow of values from their pro ducers to their consumers. There are mainly three approaches to the problem. These are providing varying size destination lists (TTDA <ref> [1] </ref>), assuming a fixed fan-out per instruction and implementing the required fan-out by inserting identity instructions (ETS [6]) and finally assuming a fixed fan-out and blocking the instruction issue if issuing the new instruction will cause the fan-out limit to be exceeded (DTS [11]).
Reference: [2] <author> E. Hao, P.-Y. Chang, M. Evers, and Y. N. Patt. </author> <title> Increasing the instruction fetch rate via block-structured instruction set architectures. </title> <booktitle> In Proceedings of the 29th Annual International Symposium on Microarchi-tecture, </booktitle> <pages> pages 191-200, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: on the problems of the processor front-end such as equipping the fetch unit with accurate branch predictors which can perform multiple branch predic fl This work is supported by NSF grants CCR-9704350, CCR-9808590 and a grant from Intel Corporation. tions and increasing the fetch bandwidth without increasing the fetch latency <ref> [2, 8] </ref>. Research in this area of the processor design has been yielding increasingly promising results. (a) (b) Unfortunately, even with a perfect instruction fetcher, the processor core still needs improvement. Providing large issue widths alone is not sufficient for exploiting greater degrees of instruction level parallelism.
Reference: [3] <author> M. H. Lipasti and J. P. Shen. </author> <title> Superspeculative mi-croarchitecture for beyond ad 2000. </title> <journal> IEEE Computer, </journal> <volume> 30(9) </volume> <pages> 59-66, </pages> <year> 1997. </year>
Reference-contexts: 1. Introduction Recent research indicates that issuing a large number of instructions per cycle may yield high performance, and processors that can issue large numbers of instructions will become feasible with the advances in manufacturing techniques <ref> [3, 7] </ref>.
Reference: [4] <author> S. Onder and R. Gupta. </author> <title> Automatic generation of microarchitecture simulators. </title> <booktitle> In IEEE International Conference on Computer Languages, </booktitle> <pages> pages 80-89, </pages> <address> Chicago, </address> <month> May </month> <year> 1998. </year>
Reference-contexts: Simulators have been described for the MIPS ISA using the ADL <ref> [4] </ref> language and generated from ADL descriptions automatically. Functional Unit Latency (cycles) Load 2 Integer division 8 Integer multiply 4 Other integer 1 Float multiply 4 Float addition 3 Float division 8 Other float 2 Table 1.
Reference: [5] <author> S. Palacharla, N. P. Jouppi, and J. Smith. </author> <title> Complexity-effective superscalar processors. </title> <booktitle> In Proceedings of the 24th International Conference on Computer Architecture, </booktitle> <pages> pages 206-218, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: with the conventional approaches, which provide full data fan-out by using a broadcast and select mechanism [9] due to the delays involved in the wake-up logic, long wires used to broadcast the tags (and data) to the waiting instructions, and large number of comparators needed to implement the instruction window <ref> [5] </ref>. To address these problems, various techniques have been proposed. These techniques attempt to partition the central window either in the form of a clustered architecture where the machine has multiple instruction windows [5], or in the form of trace lines [10] as well as using dependency information to reduce the <p> (and data) to the waiting instructions, and large number of comparators needed to implement the instruction window <ref> [5] </ref>. To address these problems, various techniques have been proposed. These techniques attempt to partition the central window either in the form of a clustered architecture where the machine has multiple instruction windows [5], or in the form of trace lines [10] as well as using dependency information to reduce the number of instructions being considered for selection. In this work, we take these approaches one step further by handling the problem as a data-flow graph problem.
Reference: [6] <author> G. M. Papadopoulos. </author> <title> Implementation of a general purpose dataflow multiprocessor. </title> <type> Technical Report TR-432, </type> <institution> MIT, </institution> <year> 1988. </year>
Reference-contexts: Our approach relies on a graph which is computed from a conventional instruction set dynamically and is called the Dynamic Data Forwarding Graph (DDFG). The semantics of DDFG can easily be implemented using direct matching and unlike the prior direct matching techniques <ref> [11, 6] </ref>, the graph does not limit parallelism or introduce additional instructions to carry out data propagation. The graph is based on the novel idea of using instructions which are being woken-up as stepping stones to waking-up further instructions. <p> Finally, in section 4, we discuss the results of a comparative study of dynamic data forwarding architecture with a conventional superscalar processor. 2. Dynamic Data Forwarding Although direct matching has been studied extensively in the context of data-flow architectures by Pa-padopoulos and Culler <ref> [6] </ref>, the technique has never been applied in superscalar processors because of two reasons. First, data-flow architectures execute a data-flow graph where the association between the producer and the consumers of a value is explicit. To apply direct matching, we need to construct such a graph dynamically. <p> There are mainly three approaches to the problem. These are providing varying size destination lists (TTDA [1]), assuming a fixed fan-out per instruction and implementing the required fan-out by inserting identity instructions (ETS <ref> [6] </ref>) and finally assuming a fixed fan-out and blocking the instruction issue if issuing the new instruction will cause the fan-out limit to be exceeded (DTS [11]). Using a varying length list is not suitable for superscalar processors since varying length lists are difficult to manage efficiently in the hardware. <p> This is because, the average number of destinations across all instructions executed in a given program cannot exceed two, even when arbitrary fan-out is permitted <ref> [6] </ref>. 4 Evaluation We have evaluated the effectiveness of the dynamic data forwarding approach using detailed cycle level simulators. Simulators have been described for the MIPS ISA using the ADL [4] language and generated from ADL descriptions automatically.
Reference: [7] <author> Y. N. Patt, S. J. Patel, M. Evers, D. H. Friendly, and J. Stark. </author> <title> One billion transistors, one uniprocessor, one chip. </title> <journal> IEEE Computer, </journal> <volume> 30(9) </volume> <pages> 51-57, </pages> <year> 1997. </year>
Reference-contexts: 1. Introduction Recent research indicates that issuing a large number of instructions per cycle may yield high performance, and processors that can issue large numbers of instructions will become feasible with the advances in manufacturing techniques <ref> [3, 7] </ref>.
Reference: [8] <author> E. Rotenberg, S. Bennett, and J. E. Smith. </author> <title> Trace cache: a low latency approach to high bandwidth instruction fetching. </title> <booktitle> In Proceedings of the 29th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 24-34, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: on the problems of the processor front-end such as equipping the fetch unit with accurate branch predictors which can perform multiple branch predic fl This work is supported by NSF grants CCR-9704350, CCR-9808590 and a grant from Intel Corporation. tions and increasing the fetch bandwidth without increasing the fetch latency <ref> [2, 8] </ref>. Research in this area of the processor design has been yielding increasingly promising results. (a) (b) Unfortunately, even with a perfect instruction fetcher, the processor core still needs improvement. Providing large issue widths alone is not sufficient for exploiting greater degrees of instruction level parallelism.
Reference: [9] <author> R. M. Tomasulo. </author> <title> An efficient algorithm for exploiting multiple arithmetic units. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 11 </volume> <pages> 25-33, </pages> <year> 1967. </year>
Reference-contexts: When the window size is enlarged quadratically with increasing issue width almost a linear speed-up is obtained (Fig. 1 (b)). Designing such large windows is not feasible with the conventional approaches, which provide full data fan-out by using a broadcast and select mechanism <ref> [9] </ref> due to the delays involved in the wake-up logic, long wires used to broadcast the tags (and data) to the waiting instructions, and large number of comparators needed to implement the instruction window [5]. To address these problems, various techniques have been proposed. <p> All programs were run to completion using the SPEC95 test inputs. However, in a few cases the input sets were modified to have a smaller data set. As a baseline processor, we used a superscalar processor based on Tomasulo's algorithm <ref> [9] </ref> which implements the full data fan-out using broadcasting and a central instruction window (CW). The experiments consist of two sets. The first set studies the performance of the DDFA which assumes a match unit size set at the theoretical maximum.
Reference: [10] <author> S. Vajapeyam and T. Mitra. </author> <title> Improving superscalar instruction dispatch and issue by exploiting dynamic code sequences. </title> <booktitle> In Proceedings of the 24th International Conference on Computer Architecture, </booktitle> <pages> pages 1-12, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: To address these problems, various techniques have been proposed. These techniques attempt to partition the central window either in the form of a clustered architecture where the machine has multiple instruction windows [5], or in the form of trace lines <ref> [10] </ref> as well as using dependency information to reduce the number of instructions being considered for selection. In this work, we take these approaches one step further by handling the problem as a data-flow graph problem.
Reference: [11] <author> S. Weiss and J. E. Smith. </author> <title> Instruction issue logic in pipelined supercomputers. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-33:1013-1022, </volume> <month> November </month> <year> 1984. </year>
Reference-contexts: Our approach relies on a graph which is computed from a conventional instruction set dynamically and is called the Dynamic Data Forwarding Graph (DDFG). The semantics of DDFG can easily be implemented using direct matching and unlike the prior direct matching techniques <ref> [11, 6] </ref>, the graph does not limit parallelism or introduce additional instructions to carry out data propagation. The graph is based on the novel idea of using instructions which are being woken-up as stepping stones to waking-up further instructions. <p> are providing varying size destination lists (TTDA [1]), assuming a fixed fan-out per instruction and implementing the required fan-out by inserting identity instructions (ETS [6]) and finally assuming a fixed fan-out and blocking the instruction issue if issuing the new instruction will cause the fan-out limit to be exceeded (DTS <ref> [11] </ref>). Using a varying length list is not suitable for superscalar processors since varying length lists are difficult to manage efficiently in the hardware. Similarly, the early algorithm DTS [11] is not suitable since it severely limits the parallelism that can be exploited. <p> fixed fan-out and blocking the instruction issue if issuing the new instruction will cause the fan-out limit to be exceeded (DTS <ref> [11] </ref>). Using a varying length list is not suitable for superscalar processors since varying length lists are difficult to manage efficiently in the hardware. Similarly, the early algorithm DTS [11] is not suitable since it severely limits the parallelism that can be exploited. Finally, insertion of identity instructions is not desirable for superscalar processors since the need for a large data fan-out occurs when the instruction window becomes full.
References-found: 11

