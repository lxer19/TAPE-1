URL: http://www.lsi.upc.es/dept/techreps/ps/R93-12.ps.gz
Refering-URL: http://www.lsi.upc.es/dept/techreps/1993.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: On the Power of Equivalence Queries  
Author: Ricard Gavalda 
Date: June 20th, 1994  
Address: Pau Gargallo, 5 08028 Barcelona, Spain  
Affiliation: Department of Software (LSI) Universitat Politecnica de Catalunya  
Abstract: In 1990, Angluin showed that no class exhibiting a combinatorial property called "approximate fingerprints" can be identified exactly using polynomially many Equivalence queries (of polynomial size). Here we show that this is a necessary condition: every class without approximate fingerprints has an identification strategy that makes a polynomial number of Equivalence queries. Furthermore, if the class is "honest" in a technical sense, the computational power required by the strategy is within the polynomial-time hierarchy, so proving non learnability is at least as hard as showing P 6= NP.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> D. Angluin: </author> <title> "Learning regular sets from queries and counterexamples". </title> <booktitle> Information and Computation 75 (1987), </booktitle> <pages> 87-106. </pages>
Reference: 2. <author> D. Angluin: </author> <title> "Queries and concept learning". </title> <booktitle> Machine Learning 2 (1988), </booktitle> <pages> 319-342. </pages>
Reference-contexts: E-mail: gavalda@lsi.upc.es 1 There are a few classes of concepts known to be learnable from Equiv--alence queries alone: CNF and DNF formulas with a bounded number of literals per clause <ref> [2] </ref>, discrete geometric concepts [10], and some types of simple grammars [14]. (By "learnable" we always mean "learnable in polynomial time"; see Section 2 for definitions.) Equivalence queries, however, are provably insufficient for learning many other classes.
Reference: 3. <author> D. Angluin: </author> <title> "Negative results for equivalence queries". </title> <booktitle> Machine Learning 5 (1990), </booktitle> <pages> 121-150. </pages>
Reference-contexts: Angluin <ref> [3] </ref> showed that they do not suffice for learning deterministic or nondeterministic finite automata, context-free grammars, or general CNF or DNF formulas. She proved these facts by showing that these classes exhibit a certain combinatorial property, "having approximate fingerprints", together with the following theorem. Theorem 1 [3] If a representation class <p> Angluin <ref> [3] </ref> showed that they do not suffice for learning deterministic or nondeterministic finite automata, context-free grammars, or general CNF or DNF formulas. She proved these facts by showing that these classes exhibit a certain combinatorial property, "having approximate fingerprints", together with the following theorem. Theorem 1 [3] If a representation class C has approximate fingerprints, then it is not learnable from Equivalence queries. <p> We take first a slight variation of Angluin's "approximate fingerprints", mainly to ensure that it is decidable whether a given object is an approximate fingerprint. It is easy to verify that this variation still allows to prove Theorem 1, and that the classes shown to have approximate fingerprints in <ref> [3] </ref> still have them with the new definition. Then we show that, in any class not having approximate fingerprints, it is possible to implement a very weak version of majority vote, which leads to a polynomial learning strategy. <p> Finally, we apply the techniques in the proof of Theorem 2 to the class of boolean circuits. Theorem 4 If P = NP then boolean circuits are learnable from Equivalence queries. Thus, boolean circuits are different in a sense from the classes discussed in <ref> [3] </ref>. For those classes, negative results are absolute; for circuits, any negative result needs to assume or prove that P 6= NP. In other words, the hardness of learning circuits relies on the intractability of computational problems, not on the amount of information needed for identification. <p> The learner learns C if, for any target concept c taken from C and any sequence of answers consistent with c, it outputs a representation in R for c, and it does so in polynomial time. 3 Approximate Fingerprints Revisited We recall the following definitions from Angluin's work <ref> [3] </ref>. All of them assume that C = (R; ) is a honest representation class. <p> This definition is different from that in <ref> [3] </ref> in two respects. First, line (2) reads "for all sufficiently large n" in [3]. It is easy to verify that the weaker condition "for infinitely many n" is enough for the proof of Theorem 1. <p> This definition is different from that in <ref> [3] </ref> in two respects. First, line (2) reads "for all sufficiently large n" in [3]. It is easy to verify that the weaker condition "for infinitely many n" is enough for the proof of Theorem 1. Intuitively, to prove non-learnability it is enough to force superpolynomial running time in each algorithm at infinitely many lengths.
Reference: 4. <author> J.L. Balcazar, J. Daz, and J. Gabarro: </author> <title> Structural Complexity I. </title> <journal> EATCS Monographs on Theoretical Computer Science, </journal> <volume> vol. 11. </volume> <publisher> Springer-Verlag 1988. </publisher>
Reference-contexts: For two complexity classes C and D, C (D) denotes the complexity class C relativized to class D, i.e., the set of languages accepted by machines of type C relative to oracles in D. See <ref> [4] </ref> for explanations. Representation classes. We specify learning problems by means of representation classes, in the style of [11, 13].
Reference: 5. <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M.K. Warmuth: </author> <title> "Occam's razor". </title> <booktitle> Information Processing Letters 24 (1987), </booktitle> <pages> 377-380. </pages>
Reference-contexts: It would be interesting to delimit more precisely the frontier between "information" and "computation" hardness, especially when other types of queries are present. Let us remind that this problem is completely solved for the PAC-learning paradigm. It is known <ref> [5] </ref> that every honest class is PAC-learnable from a polynomial number of examples, given access to an oracle in NP. Hence, for PAC, all the difficulty comes from the computation side.
Reference: 6. <author> N.H. Bshouty, R. Cleve, S. Kannan, and C. Tamon: </author> <title> "Oracles and queries that are sufficient for exact learning". </title> <booktitle> To be presented at the 7th COLT Conference, </booktitle> <address> New Jersey, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: Very recently, Bshouty, Cleve, and Tamon have independently shown that CIR is learnable both by randomized algorithms with an NP oracle and by deterministic algorithms with a p 3 oracle <ref> [6] </ref>, thus obtaining Theorem 4 as a corollary. Many similar results concerning other representation classes are also shown in [6]. Acknowledgements. I am grateful to David Guijarro and Vijay Ragha-van for helpful comments. <p> Very recently, Bshouty, Cleve, and Tamon have independently shown that CIR is learnable both by randomized algorithms with an NP oracle and by deterministic algorithms with a p 3 oracle <ref> [6] </ref>, thus obtaining Theorem 4 as a corollary. Many similar results concerning other representation classes are also shown in [6]. Acknowledgements. I am grateful to David Guijarro and Vijay Ragha-van for helpful comments. I also thank Nader Bshouty, Richard Cleve, and 12 Christino Tamon for promptly sending a copy of their work [6], and Vijay again for first telling me about it. <p> Many similar results concerning other representation classes are also shown in <ref> [6] </ref>. Acknowledgements. I am grateful to David Guijarro and Vijay Ragha-van for helpful comments. I also thank Nader Bshouty, Richard Cleve, and 12 Christino Tamon for promptly sending a copy of their work [6], and Vijay again for first telling me about it.
Reference: 7. <author> R. Gavalda: </author> <title> Kolmogorov Randomness and its Applications to Structural Complexity Theory. </title> <type> Doctoral Dissertation, </type> <institution> Universitat Politecnica de Catalunya, </institution> <month> april </month> <year> 1992. </year>
Reference-contexts: Using this fact, it is possible to give an ad-hoc version of algorithm A in Section 4 that works for the class CIR. We omit its presentation in this version; a complete proof can be found in <ref> [7] </ref>. Late addition. Note that our proof of Theorem 4 does not show that CIR is learnable with the help of an oracle in PH; it uses the full force of the assumption that P = NP.
Reference: 8. <author> R. Gavalda: </author> <title> "Bounding the complexity of advice functions". </title> <booktitle> Proceedings of the 7th Annual Conference on Structure in Complexity Theory, </booktitle> <pages> 249-254. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1992. </year>
Reference-contexts: By a similar argument, any r 2 R satisfying this condition also satisfies kf c 2 Cons (n; s) n kCons (n; s) n 16q (n) as required by the definition of algorithm A. Let us note that a more careful use of Stockmeyer's techniques, along the lines of <ref> [8, 9] </ref>, brings the required oracle down to p If these lines are solved as explained, clearly each iteration of the loop takes time polynomial in n and the maximum length of a counterexample received so far.
Reference: 9. <author> J. Kobler: </author> <title> "Locating P/poly optimally in the extended low hierarchy". </title> <booktitle> Proceedings of the 10th Symposium on Theoretical Aspects of Computer Science, </booktitle> <pages> 28-37. </pages> <booktitle> Lecture Notes in Computer Science 665. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993. </year> <month> 13 </month>
Reference-contexts: By a similar argument, any r 2 R satisfying this condition also satisfies kf c 2 Cons (n; s) n kCons (n; s) n 16q (n) as required by the definition of algorithm A. Let us note that a more careful use of Stockmeyer's techniques, along the lines of <ref> [8, 9] </ref>, brings the required oracle down to p If these lines are solved as explained, clearly each iteration of the loop takes time polynomial in n and the maximum length of a counterexample received so far.
Reference: 10. <author> W. Maass and G. Turan: </author> <title> "On the complexity of learning from counterex-amples". </title> <booktitle> Proceedings of the 30th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> 262-267. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1989. </year>
Reference-contexts: E-mail: gavalda@lsi.upc.es 1 There are a few classes of concepts known to be learnable from Equiv--alence queries alone: CNF and DNF formulas with a bounded number of literals per clause [2], discrete geometric concepts <ref> [10] </ref>, and some types of simple grammars [14]. (By "learnable" we always mean "learnable in polynomial time"; see Section 2 for definitions.) Equivalence queries, however, are provably insufficient for learning many other classes.
Reference: 11. <author> M.K. Warmuth: </author> <title> "Towards representation independence in PAC learning". </title> <booktitle> Proceedings of the International Workshop on Analogical and Inductive Inference AII-89, </booktitle> <pages> 78-103. </pages> <booktitle> Lecture Notes in Artificial Intelligence 397. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: See [4] for explanations. Representation classes. We specify learning problems by means of representation classes, in the style of <ref> [11, 13] </ref>. A representation class C is a tuple (R; ), where * language R ? is the set of representations, and * function maps each representation r 2 R to a language, or concept, (r) ? .
Reference: 12. <author> L. Stockmeyer: </author> <title> "On approximation algorithms for #P". </title> <journal> SIAM Journal on Computing 14 (1985), </journal> <pages> 849-861. </pages>
Reference: 13. <author> O. Watanabe: </author> <title> "A formal study of learning via queries". </title> <booktitle> Proceedings of the 17th International Colloquium on Automata, Languages, and Programming, </booktitle> <pages> 139-152. </pages> <booktitle> Lecture Notes in Computer Science 443. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: See [4] for explanations. Representation classes. We specify learning problems by means of representation classes, in the style of <ref> [11, 13] </ref>. A representation class C is a tuple (R; ), where * language R ? is the set of representations, and * function maps each representation r 2 R to a language, or concept, (r) ? .
Reference: 14. <author> T. Yokomori: </author> <title> "Polynomial-time learning of very simple grammars from positive data". </title> <booktitle> Proceedings of the 4th ACM Workshop on Computational Learning Theory, </booktitle> <pages> 213-227. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year> <month> 14 </month>
Reference-contexts: E-mail: gavalda@lsi.upc.es 1 There are a few classes of concepts known to be learnable from Equiv--alence queries alone: CNF and DNF formulas with a bounded number of literals per clause [2], discrete geometric concepts [10], and some types of simple grammars <ref> [14] </ref>. (By "learnable" we always mean "learnable in polynomial time"; see Section 2 for definitions.) Equivalence queries, however, are provably insufficient for learning many other classes. Angluin [3] showed that they do not suffice for learning deterministic or nondeterministic finite automata, context-free grammars, or general CNF or DNF formulas.
References-found: 14

