URL: http://www.ius.cs.cmu.edu/IUS/sourdough_usr0/har/papers/cvpr98/tr.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/har/faces.html
Root-URL: 
Phone: 2  
Title: Rotation Invariant Neural Network-Based Face Detection  
Author: Henry A. Rowley Shumeet Baluja ; Takeo Kanade 
Address: Pittsburgh, PA 15213  4616 Henry Street Pittsburgh, PA 15213  
Affiliation: 1 School of Computer Science Carnegie Mellon University  Justsystem Pittsburgh Research Center  
Date: December 1997  
Pubnum: CMU-CS-97-201  
Abstract: In this paper, we present a neural network-based face detection system. Unlike similar systems which are limited to detecting upright, frontal faces, this system detects faces at any degree of rotation in the image plane. The system employs multiple networks; the first is a router network which processes each input window to determine its orientation and then uses this information to prepare the window for one or more detector networks. We present the training methods for both types of networks. We also perform sensitivity analysis on the networks, and present empirical results on a large test set. Finally, we present preliminary results for detecting faces which are rotated out of the image plane, such as profiles and semi-profiles. This work was partially supported by grants from Hewlett-Packard Corporation, Siemens Corporate Research, Inc., the Department of the Army, Army Research Office under grant number DAAH04-94-G-0006, and by the Office of Naval Research under grant number N00014-95-1-0591. The views and conclusions contained in this document are those of the authors, and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the sponsors. 
Abstract-found: 1
Intro-found: 1
Reference: [ Baluja, 1994 ] <author> Shumeet Baluja. </author> <title> Population-based incremental learning: A method for integrating genetic search based function optimization and competitive learning. </title> <institution> CMU-CS-94-163, Carnegie Mellon University, </institution> <year> 1994. </year> <note> Also available at ftp://reports.adm.cs.cmu.edu/usr/anon/1994/CMU-CS-94-163.ps. </note>
Reference-contexts: These images were laid out automatically by the PBIL optimization algorithm <ref> [ Baluja, 1994 ] </ref> .
Reference: [ Baluja, 1997 ] <author> Shumeet Baluja. </author> <title> Face detection with in-plane rotation: Early concepts and prelim inary results. </title> <institution> JPRC-1997-001-1, Justsystem Pittsburgh Research Center, </institution> <year> 1997. </year> <note> Also available at http://www.cs.cmu.edu/baluja/papers/baluja.face.in.plane.ps.gz. </note>
Reference-contexts: Therefore, the entire detection procedure would need to be applied at least 18 times to each image, with the image rotated in increments of 20 ffi . An alternate, significantly faster procedure is described in this paper, extending some early results in <ref> [ Baluja, 1997 ] </ref> . This procedure uses a separate neural network, termed a router, to analyze the input window before it is processed by the face detector. The router's input is the same region that the detector network will receive as input.
Reference: [ Beymer et al., 1993 ] <author> David Beymer, Amnon Shashua, and Tomaso Poggio. </author> <title> Example based image analysis and synthesis. </title> <journal> A.I. </journal> <volume> Memo 1431, </volume> <publisher> MIT, </publisher> <month> November </month> <year> 1993. </year>
Reference-contexts: The first is directly analogous to handling in-plane rotations: using knowledge of the shape and symmetry of the face, it may be possible to convert a profile or semi-profile view of a face to a frontal view (for related work, see <ref> [ Vetter et al., 1997, Beymer et al., 1993 ] </ref> ). A second approach, and the one we have explored, is to partition the views of the face, and to train separate detector networks for each view.
Reference: [ Burel and Carel, 1994 ] <author> Gilles Burel and Dominique Carel. </author> <title> Detection and localization of faces on digital images. </title> <journal> Pattern Recognition Letters, </journal> <volume> 15:963967, </volume> <month> October </month> <year> 1994. </year>
Reference: [ Colmenarez and Huang, 1997 ] <author> Antonio J. Colmenarez and Thomas S. Huang. </author> <title> Face detection with information-based maximum discrimination. </title> <booktitle> In Computer Vision and Pattern Recognition, </booktitle> <pages> pages 782787, </pages> <year> 1997. </year>
Reference: [ Leung et al., 1995 ] <author> T. K. Leung, M. C. Burl, and P. Perona. </author> <title> Finding faces in cluttered scenes using random labeled graph matching. </title> <booktitle> In Fifth International Conference on Computer Vision, </booktitle> <pages> pages 637644, </pages> <address> Cambridge, Massachusetts, June 1995. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Other researchers have taken the approach of extracting features and applying either manually or automatically generated rules for evaluating these features. By using a graph-matching algorithm on detected features, <ref> [ Leung et al., 1995 ] </ref> can also achieve rotation invariance. Our paper presents a general method to make template-based face detectors rotation invariant. Our system directly analyzes image intensities using neural networks, whose parameters are learned automatically from training examples.
Reference: [ Lin et al., 1997 ] <author> S. H. Lin, S. Y. Kung, and L. J. Lin. </author> <title> Face recognition/detection by probabilis tic decision-based neural network. </title> <journal> IEEE Transactions on Neural Networks, Special Issue on Artificial Neural Networks and Pattern Recognition, </journal> <volume> 8(1), </volume> <month> January </month> <year> 1997. </year>
Reference: [ Moghaddam and Pentland, 1995 ] <author> Baback Moghaddam and Alex Pentland. </author> <title> Probabilistic visual learning for object detection. </title> <booktitle> In Fifth International Conference on Computer Vision, </booktitle> <pages> pages 786793, </pages> <address> Cambridge, Massachusetts, June 1995. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference: [ Osuna et al., 1997 ] <author> Edgar Osuna, Robert Freund, and Federico Girosi. </author> <title> Training support vector machines: an application to face detection. </title> <booktitle> In Computer Vision and Pattern Recognition, </booktitle> <pages> pages 130136, </pages> <year> 1997. </year>
Reference: [ Pentland et al., 1994 ] <author> Alex Pentland, Baback Moghaddam, and Thad Starner. </author> <title> View-based and modular eigenspaces for face recognition. </title> <booktitle> In Computer Vision and Pattern Recognition, </booktitle> <pages> pages 8491, </pages> <year> 1994. </year>
Reference: [ Phillips et al., 1996 ] <author> P. Jonathon Phillips, Patrick J. Rauss, and Sandor Z. Der. </author> <title> FERET (face recognition technology) recognition algorithm development and test results. </title> <institution> ARL-TR-995, Army Research Laboratory, </institution> <month> October </month> <year> 1996. </year>
Reference-contexts: We suspect that one reason for this is that our training data is not representative of the variations present in real images. Most of our profile training images are taken from the FERET database <ref> [ Phillips et al., 1996 ] </ref> , which has very uniform lighting conditions. 11 There are two immediate directions for future work. First, it would be interesting to merge the systems for in-plane and out-of-plane rotations.
Reference: [ Pomerleau, 1992 ] <author> Dean Pomerleau. </author> <title> Neural Network Perception for Mobile Robot Guidance. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <month> February </month> <year> 1992. </year> <note> Available as CS Technical Report CMU-CS-92-115. </note>
Reference-contexts: To signal that a face is at an angle of , each output is trained to have a value of cos ( i fl 10 ffi ). This approach is closely related to the Gaussian weighted outputs used in the autonomous driving domain <ref> [ Pomerleau, 1992 ] </ref> . Examples of the training data are given in Figure 3. Previous algorithms using Gaussian weighted outputs inferred a single value from them by computing an average of the positions of the outputs, weighted by their activations.
Reference: [ Rowley et al., 1998 ] <author> Henry A. Rowley, Shumeet Baluja, and Takeo Kanade. </author> <title> Neural network based face detection. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 20(1), </volume> <month> January </month> <year> 1998. </year> <note> Also available at http://www.cs.cmu.edu/har/faces.html. </note>
Reference-contexts: Our system directly analyzes image intensities using neural networks, whose parameters are learned automatically from training examples. There are many ways to use neural networks for rotated-face detection. The simplest would be to employ one of the existing frontal, upright, face detection systems. Systems such as <ref> [ Rowley et al., 1998 ] </ref> use a neural-network based filter that receives as input a small, constant-sized window of the image, and generates an output signifying the presence or absence of a face. <p> To extend this framework to capture faces which are rotated, the entire image can be repeatedly rotated by small increments and the detection system can be applied to each rotated image. However, this would be an extremely computationally expensive procedure. For example, the system reported in <ref> [ Rowley et al., 1998 ] </ref> was invariant to approximately 10 ffi of rotation from upright (both clockwise and of our new system. 1 counterclockwise). <p> The rotation angle returned by the router is then used to rotate the window with the potential face to an upright position. Finally, the derotated window is preprocessed and passed to one or more detector networks <ref> [ Rowley et al., 1998 ] </ref> , which decide whether or not the window contains a face. The system as presented so far could easily signal that there are two faces of very different orientations located at adjacent pixel locations in the image. <p> In each face, the eyes, tip of the nose, and the corners and center of the mouth are labelled. The set of labelled faces are then aligned to one another using an iterative procedure <ref> [ Rowley et al., 1998 ] </ref> . We first compute the average location for each of the labelled features over the entire training set. Then, each face is aligned with the average feature locations, by computing the rotation, translation, and scaling that minimizes the distances between the corresponding features. <p> The remaining task is to decide whether or not the window contains an upright face. The algorithm used for detection is identical to the one presented in <ref> [ Rowley et al., 1998 ] </ref> . The resampled image, which is also 20x20 pixels, is preprocessed in two steps [ Sung, 1996 ] . First, we fit a function which varies linearly across the window to the intensity values in an oval region inside the window. <p> The detectors have two sets of training examples: images which are faces, and images which are not. The positive examples are generated in a manner similar to that of the router; however, as suggested in <ref> [ Rowley et al., 1998 ] </ref> , the amount of rotation of the training images is limited to the range 10 ffi to 10 ffi . Training a neural network for the face detection task is challenging because of the difficulty in characterizing prototypical non-face images. <p> To further reduce the number of false detections, and reinforce correct detections, we arbitrate between two independently trained detector networks, as in <ref> [ Rowley et al., 1998 ] </ref> . Each network is given the same set of positive examples, but starts with different randomly set initial weights. Therefore, each network learns different features, and make different mistakes. <p> The specific preprocessing thresholds used in the experiments will be given in Sections 4. These arbitration heuristics are very similar to, but computationally less expensive than, those presented in <ref> [ Rowley et al., 1998 ] </ref> . 3 Analysis of the Networks In order for the system described above to be accurate, the router and detector must perform robustly and compatibly. <p> The first set, which we will call the upright test set, is Test Set 1 from <ref> [ Rowley et al., 1998 ] </ref> . It contains many images with faces against complex backgrounds and many images without any faces. There are a total of 130 images, with 511 faces (of which 469 are within 10 ffi of upright), and 83,099,211 windows to be processed. <p> set, referred to as the rotated test set, consists of 50 images (with 34,064,635 windows) containing 223 faces, of which 210 are at angles of more than 10 ffi from upright. 1 The upright test set is used as a baseline for comparison with an existing upright face detection system <ref> [ Rowley et al., 1998 ] </ref> . This will ensure that the modifications for rotated faces do not hamper the ability to detect upright faces. <p> The rotated test set will demonstrate the new capabilities of our system. 4.1 Router Network with Standard Upright Face Detectors The first system we test employs the router network to determine the orientation of any potential face, and then applies two standard upright face detection networks from <ref> [ Rowley et al., 1998 ] </ref> . Table 1 shows the number of faces detected and the number of false alarms generated on the two test sets. <p> Note that the detection rate for the rotated test set is higher than that for the upright test set, due to differences in the overall difficulty of the two test sets. Table 1: Results of first applying the router network, then applying the standard detector networks <ref> [ Rowley et al., 1998 ] </ref> at the appropriate orientation. <p> The detectors were instead applied at 18 different orientations (in increments of 20 ffi ) for each image location. Table 3 shows the results using the standard upright face detection networks of <ref> [ Rowley et al., 1998 ] </ref> , and Table 4 shows the results using the detection networks trained with derotated negative examples. Table 3: Results of applying the standard detector networks [ Rowley et al., 1998 ] at 18 different image orientations. <p> Table 3 shows the results using the standard upright face detection networks of <ref> [ Rowley et al., 1998 ] </ref> , and Table 4 shows the results using the detection networks trained with derotated negative examples. Table 3: Results of applying the standard detector networks [ Rowley et al., 1998 ] at 18 different image orientations. <p> the expense of much more computation. 4.4 Upright Detection Accuracy Finally, to check that adding the capability of detecting rotated faces has not come at the expense of accuracy in detecting upright faces, in Table 5 we present the result of applying the original detector networks and arbitration method from <ref> [ Rowley et al., 1998 ] </ref> to the two test sets used in this paper. 3 As expected, this system does well on the upright test set, but has a poor detection rate on the rotated test set. <p> <ref> [ Rowley et al., 1998 ] </ref> to the two test sets used in this paper. 3 As expected, this system does well on the upright test set, but has a poor detection rate on the rotated test set. Table 5: Results of applying the original algorithm and arbitration method from [ Rowley et al., 1998 ] to the two test sets. <p> Our new system has a slightly lower detection rate on upright faces for two 3 The results for the upright test set are slightly different from those presented in <ref> [ Rowley et al., 1998 ] </ref> because we now check for the detection of 4 upside-down faces, which were present, but ignored, in the original test set. Also, there are slight differences in the way the image pyramid is generated. 10 reasons. <p> Table 6: Breakdown of detection rates for upright and rotated faces from both test sets. All Upright Faces Rotated Faces System Faces ( 10 ffi ) (&gt; 10 ffi ) New system (Table 2) 79.6% 77.2% 84.1% Upright detector <ref> [ Rowley et al., 1998 ] </ref> 63.4% 88.0% 16.3% 5 Summary and Extensions This paper has demonstrated the effectiveness of detecting faces rotated in the image plane by using a router network in combination with an upright face detector. <p> The second area for future work is improvement to the speed of the system. Based on the work of [ Umezaki, 1995 ] , <ref> [ Rowley et al., 1998 ] </ref> presented a quick algorithm based on the use of a fast (but somewhat inaccurate) candidate detector network, whose results could then be checked by the detector networks. A similar technique may be applicable to the present work.
Reference: [ Sung, 1996 ] <author> Kah-Kay Sung. </author> <title> Learning and Example Selection for Object and Pattern Detection. </title> <type> PhD thesis, </type> <institution> MIT AI Lab, </institution> <month> January </month> <year> 1996. </year> <note> Available as AI Technical Report 1572. </note>
Reference-contexts: The remaining task is to decide whether or not the window contains an upright face. The algorithm used for detection is identical to the one presented in [ Rowley et al., 1998 ] . The resampled image, which is also 20x20 pixels, is preprocessed in two steps <ref> [ Sung, 1996 ] </ref> . First, we fit a function which varies linearly across the window to the intensity values in an oval region inside the window. <p> It is easy to get a representative sample of images which contain faces, but much harder to get a representative sample of those which do not. Instead of collecting the images before training is started, the images are collected during training in the following bootstrap manner, adapted from <ref> [ Sung, 1996 ] </ref> : 1. Create an initial set of non-face images by generating 1000 random images. 2. Train the neural network to produce an output of +1:0 for the face examples, and 1:0 for the non face examples. In the first iteration, the network's weights are initialized random.
Reference: [ Umezaki, 1995 ] <author> Tazio Umezaki. </author> <type> Personal communication, </type> <year> 1995. </year>
Reference-contexts: The second area for future work is improvement to the speed of the system. Based on the work of <ref> [ Umezaki, 1995 ] </ref> , [ Rowley et al., 1998 ] presented a quick algorithm based on the use of a fast (but somewhat inaccurate) candidate detector network, whose results could then be checked by the detector networks. A similar technique may be applicable to the present work.
Reference: [ Vaillant et al., 1994 ] <author> R. Vaillant, C. Monrocq, and Y. Le Cun. </author> <title> Original approach for the locali sation of objects in images. </title> <booktitle> IEE Proceedings on Vision, Image, and Signal Processing, </booktitle> <volume> 141(4), </volume> <month> August </month> <year> 1994. </year>
Reference: [ Vetter et al., 1997 ] <author> Thomas Vetter, Michael J. Jones, and Tomaso Poggio. </author> <title> A bootstrapping algo rithm for learning linear models of object classes. </title> <booktitle> In Computer Vision and Pattern Recognition, </booktitle> <pages> pages 4046, </pages> <address> San Juan, Puerto Rico, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: The first is directly analogous to handling in-plane rotations: using knowledge of the shape and symmetry of the face, it may be possible to convert a profile or semi-profile view of a face to a frontal view (for related work, see <ref> [ Vetter et al., 1997, Beymer et al., 1993 ] </ref> ). A second approach, and the one we have explored, is to partition the views of the face, and to train separate detector networks for each view.
Reference: [ Yang and Huang, 1994 ] <author> Gaungzheng Yang and Thomas S. Huang. </author> <title> Human face detection in a complex background. </title> <journal> Pattern Recognition, </journal> <volume> 27(1):5363, </volume> <year> 1994. </year>
Reference: [ Yow and Cipolla, 1996 ] <author> Kin Choong Yow and Roberto Cipolla. </author> <title> Feature-based human face detec tion. </title> <type> CUED/F-INFENG/TR 249, </type> <institution> Department of Engineering, University of Cambridge, Eng-land, </institution> <year> 1996. </year>
Reference: [ Zhang and Fulcher, 1996 ] <author> Ming Zhang and John Fulcher. </author> <title> Face recognition using artificial neural network group-based adaptive tolerance (GAT) trees. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 7(3):555567, </volume> <year> 1996. </year>
Reference-contexts: We used five views: left profile, left semi-profile, frontal, right semi-profile, and right profile. The router is responsible for directing the input window to one of these view detectors <ref> [ Zhang and Fulcher, 1996 ] </ref> . of false detections and missed faces. We suspect that one reason for this is that our training data is not representative of the variations present in real images.
References-found: 20

