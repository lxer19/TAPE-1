URL: http://www.cs.wustl.edu/cs/techreports/1992/wucs-92-25.ps.Z
Refering-URL: http://www.cs.wustl.edu/cs/cs/publications.html
Root-URL: 
Title: Can PAC Learning Algorithms Tolerate Random Attribute Noise?  
Author: Sally A. Goldman Robert H. Sloan 
Note: Supported in part by NSF grant CCR-9108753. Part of this research was conducted while the author was at Harvard and supported by ARO grant DAAL 03-86-K-0171.  An earlier version of this report appeared as technical report WUCS-91-29.  
Address: St. Louis, Missouri 63130  Chicago, IL 60680  
Affiliation: Department of Computer Science Washington University  Dept. of Electrical Engineering and Computer Science University of Illinois at Chicago  
Pubnum: WUCS-92-25  
Email: Net address: sloan@uicbert.eecs.uic.edu.  
Date: July 10, 1992  
Abstract: This paper studies the robustness of pac learning algorithms when the instance space is f0; 1g n , and the examples are corrupted by purely random noise affecting only the instances (and not the labels). In the past, conflicting results on this subject have been obtained|the "best agreement" rule can only tolerate small amounts of noise, yet in some cases large amounts of noise can be tolerated. We show that the truth lies somewhere between these two alternatives. For uniform attribute noise, in which each attribute is flipped independently at random with the same probability, we present an algorithm that pac learns monomials for any (unknown) noise rate less than 1=2. Contrasting this positive result, we show that product random attribute noise, where each attribute i is flipped randomly and independently with its own probability p i , is nearly as harmful as malicious noise|no algorithm can tolerate more than a very small amount of such noise. fl Supported in part by a GE Foundation Junior Faculty Grant and NSF grant CCR-9110108. Part of this research was conducted while the author was at the M.I.T. Laboratory for Computer Science and supported by NSF grant DCR-8607494 and a grant from the Siemens Corporation. Net address: sg@cs.wustl.edu. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Dana Angluin and Philip Laird. </author> <title> Learning from noisy examples. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 343-370, </pages> <year> 1988. </year> <month> 10 </month>
Reference-contexts: On the whole, these results are surprising. Intuitively, one would think that random labeling noise destroys much more information than random attribute noise, but, in fact, pac learning is possible with large amounts of random labeling noise <ref> [1] </ref>. 2 Review of pac learning from noisy data The method most commonly used for pac learning in the presence of noise is to pick a concept that has the best (or at least very good) agreement with a sample of data 1 corrupted by noise. <p> It has been shown that for both discrete <ref> [1] </ref> and continuous [8] instance spaces, the hypothesis that minimizes disagreements meets the pac criterion when the examples are modified by random labeling noise. Sloan [12] has extended those results to the case of malicious labeling noise. <p> Thus we will estimate the noise rate to be the minimum, over all literals, of the ratio specified in (1) for the literal x 1 . Since we are able to obtain good estimates for the noise rate, we can apply Angluin and Laird's <ref> [1] </ref> technique of successive approximation to obtain an upper bound for the noise rate that is sufficiently close to the actual noise rate. Finally, using this estimate of the noise rate, we apply Shackelford and Volper's [11] algorithm when specialized to the case of monomials. <p> The sample complexity is O (12-) 2 * 3 ln n (12-) 2 ln n time complexity is O (12-) 2 * 3 ln n (12-) 2 ln n Proof: It follows from Theorem 3 of Angluin and Laird <ref> [1] </ref> that after step 2 of the algorithm with probability at least 1 ffi=2, the algorithm halts with r 1 + l 12 , 12-b 12- .
Reference: [2] <author> Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K. War--muth. </author> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> Journal of the ACM, </journal> <volume> 36(4) </volume> <pages> 929-965, </pages> <year> 1989. </year>
Reference-contexts: So these results specify the amount of noise that can be tolerated ignoring the issue of computation time. (Of course, if a hypothesis minimizing disagreements can be found in polynomial time then the above techniques produce efficient learning algorithms.) Finally, as Blumer et al. mention <ref> [2] </ref>, their VC dimension methods can be used to prove that this minimal disagreement method also works for handling small amounts of malicious noise in continuous instance spaces.
Reference: [3] <author> David Haussler, Michael Kearns, Nick Littlestone, and Manfred K. Warmuth. </author> <title> Equivalence of models for polynomial learnability. </title> <journal> Information and Computation. </journal> <note> To appear. </note>
Reference-contexts: Good discussions of the details of the model are given by Kearns et al. and by Haussler et al. <ref> [7, 3] </ref>. Briefly, a concept is a subset of some instance space X, and a concept class is some subset of 2 X . An example of a concept c is a pair (x; s), where x 2 X, and s is 1 if x 2 c and 0 otherwise.
Reference: [4] <author> Wassily Hoeffding. </author> <title> Probability inequalities for sums of bounded random variables. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 58(301) </volume> <pages> 13-30, </pages> <month> March </month> <year> 1963. </year>
Reference-contexts: r=1 ffi = O 1 2 n ! Let p + denote the probability of drawing a positive example from URA -. (Note that since the noise process does not affect the labels, p + is also the probability of drawing a positive example directly from EX.) Applying Hoeffding's Inequality <ref> [4] </ref> it is easily shown that if p + * then using a sample of size max n * ; 2 ffi ensures with probability at least 1 ffi=4 that the algorithm will obtain at least m positive examples in step 4. <p> Again, by applying Hoeffding's Inequality <ref> [4] </ref>, it is easily shown that by using a sample of size m = (1 2-b ) 2 * 2 ln ffi (1 2-) 2 * 2 ln ffi ; the probability that all of the estimates ^p i are within *(1 2-b )=8n of their true value p i is
Reference: [5] <author> Michael Kearns. </author> <title> Thoughts on hypothesis boosting. </title> <type> (Unpublished), </type> <month> December </month> <year> 1988. </year>
Reference-contexts: We note that for arbitrary adversarial malicious noise, that is the maximum noise rate that any algorithm can tolerate <ref> [5] </ref>. Although the method of minimizing disagreements is not effective against random attribute noise, there are techniques for coping with uniform random attribute noise. In particular, Shackelford and Volper [11] have an algorithm that tolerates large amounts of random attribute noise for learning k-DNF formulas.
Reference: [6] <author> Michael Kearns and Ming Li. </author> <title> Learning in the presence of malicious errors. </title> <booktitle> In Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, </booktitle> <address> Chicago, Illinois, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: It has been shown that for both discrete [1] and continuous [8] instance spaces, the hypothesis that minimizes disagreements meets the pac criterion when the examples are modified by random labeling noise. Sloan [12] has extended those results to the case of malicious labeling noise. Similarly, Kearns and Li <ref> [6] </ref> have shown that this method of minimizing disagreements can tolerate a small amount of malicious noise in discrete instance spaces. <p> Kearns and Li <ref> [6] </ref> showed that for any nontrivial concept class, it is impossible to pac learn to accuracy * with examples from MAL - unless - &lt; *=(1 + *): Our result for product random attribute noise is similar, with a slightly weaker bound. <p> It is possible to pac learn C to accuracy * with examples from PRA only if - &lt; 2*. Proof: We use the method of induced distributions <ref> [6] </ref>. Say C contains the concepts x 1 and x 2 . In what follows, we will put zero probability weight on instances containing 1's in positions 3 through n, and thus may assume without loss of generality that -k = 0 for 3 k n.
Reference: [7] <author> Michael Kearns, Ming Li, Leonard Pitt, and Leslie Valiant. </author> <title> On the learnability of boolean formulae. </title> <booktitle> In Proceedings of the Nineteenth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 285-295, </pages> <address> New York, New York, </address> <month> May </month> <year> 1987. </year>
Reference-contexts: Good discussions of the details of the model are given by Kearns et al. and by Haussler et al. <ref> [7, 3] </ref>. Briefly, a concept is a subset of some instance space X, and a concept class is some subset of 2 X . An example of a concept c is a pair (x; s), where x 2 X, and s is 1 if x 2 c and 0 otherwise.
Reference: [8] <author> Philip D. Laird. </author> <title> Learning from Good and Bad Data. </title> <booktitle> Kluwer international series in engineering and computer science. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1988. </year>
Reference-contexts: It has been shown that for both discrete [1] and continuous <ref> [8] </ref> instance spaces, the hypothesis that minimizes disagreements meets the pac criterion when the examples are modified by random labeling noise. Sloan [12] has extended those results to the case of malicious labeling noise.
Reference: [9] <author> Nicholas Littlestone. </author> <title> Redundant noisy attributes, attribute errors, and lineary-threshold learning using winnow. </title> <booktitle> In Fourth Workshop on Computational Learning Theory, </booktitle> <pages> pages 147-156, </pages> <year> 1991. </year>
Reference-contexts: That algorithm, however, has one very unpleasant requirement: it must be given the exact noise rate (or at least a very good estimate of the noise rate) as an input. Recently, Littlestone <ref> [9] </ref> has looked at how Winnow can tolerate several different models of attribute noise. He first considers an adversarial model of attribute noise.
Reference: [10] <author> J. Ross Quinlan. </author> <title> The effect of noise on concept learning. </title> <booktitle> In Machine Learning, An Artificial Intelligence Approach (Volume II), chapter 6, </booktitle> <pages> pages 149-166. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1986. </year>
Reference-contexts: Yet, one would expect that labeling noise would be worse than random attribute noise. Indeed, in one empirical test (of the ID-3 system), that is exactly what was found <ref> [10] </ref>. Yet, in spite of both these empirical results and our intuition, we have shown that in the pac model random attribute noise (when it is product) is significantly more harmful than random labeling noise.
Reference: [11] <author> George Shackelford and Dennis Volper. </author> <title> Learning k-DNF with noise in the attributes. </title> <booktitle> In First Workshop on Computatinal Learning Theory, </booktitle> <pages> pages 97-103, </pages> <address> Cambridge, Mass. August 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: On the one hand, Sloan [12] has show that the "best-agreement" rule can only tolerate very small amounts of random attribute noise|suggesting that random attribute noise may be difficult to overcome. However, by using a different strategy, Shackelford and Volper <ref> [11] </ref> have obtained an algorithm that tolerates a large amount of random attribute noise (at a known noise rate) for learning k-DNF formulas. Thus their result suggests that random attribute noise may be like random classification noise, where large amounts of noise can sometimes be tolerated. <p> We note that for arbitrary adversarial malicious noise, that is the maximum noise rate that any algorithm can tolerate [5]. Although the method of minimizing disagreements is not effective against random attribute noise, there are techniques for coping with uniform random attribute noise. In particular, Shackelford and Volper <ref> [11] </ref> have an algorithm that tolerates large amounts of random attribute noise for learning k-DNF formulas. That algorithm, however, has one very unpleasant requirement: it must be given the exact noise rate (or at least a very good estimate of the noise rate) as an input. <p> Finally, using this estimate of the noise rate, we apply Shackelford and Volper's <ref> [11] </ref> algorithm when specialized to the case of monomials. However, the correctness proof provided by Shackelford and Volper assumes the exact noise rate is provided.
Reference: [12] <author> Robert H. Sloan. </author> <title> Types of noise in data for concept learning. </title> <booktitle> In First Workshop on Computational Learning Theory, </booktitle> <pages> pages 91-96. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: We assume throughout that the classification of each instance is always correctly reported. In the past, conflicting results on handling random attribute noise have been obtained. On the one hand, Sloan <ref> [12] </ref> has show that the "best-agreement" rule can only tolerate very small amounts of random attribute noise|suggesting that random attribute noise may be difficult to overcome. <p> It has been shown that for both discrete [1] and continuous [8] instance spaces, the hypothesis that minimizes disagreements meets the pac criterion when the examples are modified by random labeling noise. Sloan <ref> [12] </ref> has extended those results to the case of malicious labeling noise. Similarly, Kearns and Li [6] have shown that this method of minimizing disagreements can tolerate a small amount of malicious noise in discrete instance spaces. <p> In the case of uniform random attribute noise, if one uses the minimal disagreement method, then the minimum error rate obtainable (i.e. the minimum "epsilon") is bounded below by the noise rate <ref> [12] </ref>. We note that for arbitrary adversarial malicious noise, that is the maximum noise rate that any algorithm can tolerate [5]. Although the method of minimizing disagreements is not effective against random attribute noise, there are techniques for coping with uniform random attribute noise. <p> The "desired," noiseless output of each oracle would thus be a correctly labeled example (x; s), where x is drawn according to D. We now describe the actual outputs from the following noise oracles: MAL - [14], URA - <ref> [12] </ref>, and PRA -. * When MAL is called, with probability 1 -, it does indeed return a correctly labeled (x; s) where x is drawn according to D. With probability it returns an example (x; s) about which no assumptions whatsoever may be made. <p> In fact, product random attribute noise is significantly more harmful than malicious labeling noise generated by a powerful adversary <ref> [12] </ref>, and nearly as harmful as truly malicious noise. Acknowledgments We would like to thank Les Valiant for suggesting this line of research. We thank Dana Angluin for pointing out an error (and providing a correction to this error) in our original statement of Theorem 2.
Reference: [13] <author> Leslie G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: that with product random attribute noise, the minimum error rate obtainable is bounded below by one-half of the noise rate, regardless of the technique (or computation time) of the learning algorithm. 2 3 Notation We assume that the reader is familiar with the model of pac learning introduced by Valiant <ref> [13] </ref>. Good discussions of the details of the model are given by Kearns et al. and by Haussler et al. [7, 3]. Briefly, a concept is a subset of some instance space X, and a concept class is some subset of 2 X .
Reference: [14] <author> Leslie G. Valiant. </author> <title> Learning disjunctions of conjunctions. </title> <booktitle> In Proceedings IJCAI-85, </booktitle> <pages> pages 560-566. </pages> <booktitle> International Joint Committee for Artificial Intelligence, </booktitle> <publisher> Mor-gan Kaufmann, </publisher> <month> August </month> <year> 1985. </year> <month> 11 </month>
Reference-contexts: The output from the noise process is all the learner can observe. The "desired," noiseless output of each oracle would thus be a correctly labeled example (x; s), where x is drawn according to D. We now describe the actual outputs from the following noise oracles: MAL - <ref> [14] </ref>, URA - [12], and PRA -. * When MAL is called, with probability 1 -, it does indeed return a correctly labeled (x; s) where x is drawn according to D. With probability it returns an example (x; s) about which no assumptions whatsoever may be made.
References-found: 14

