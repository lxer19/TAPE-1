URL: http://www.cis.ohio-state.edu/~paolo/research/publications/cascon98.ps
Refering-URL: http://www.cis.ohio-state.edu/~paolo/research/
Root-URL: http://www.cis.ohio-state.edu
Title: A Class of Synchronization Systems that Permit the Use of Large Atomic Blocks  
Author: Paolo A.G. Sivilotti 
Address: 2015 Neil Ave., Columbus, OH 43210-1277, USA  
Affiliation: Department of Computer and Information Science The Ohio State University  
Abstract: This paper revisits the formal justification of a common practice used in formal and informal reasoning about distributed systems: considering certain sections of code to be implicitly atomic. This practice is extremely useful as it allows distributed and concurrent programs to be developed, tested, and verified with large atomic blocks, yet executed with a much finer granularity of parallelism for efficiency. We expose the elements on which this practice is based and characterize the synchronization systems for which this practice is valid. Unlike previous justifications for this practice, our approach is based on a weakest precondition semantics. Owing to the generality of our model of computation, the result is applicable to both distributed-memory and shared-memory systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. J. R. </author> <title> Back. On correct refinements of programs. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 23 </volume> <pages> 49-68, </pages> <year> 1981. </year>
Reference-contexts: Although this restricts our results to programs with a precondition and postcondition specification (as opposed to reactive programs [11] such as operating systems), it allows us to use the traditional refinement calculus <ref> [1, 14, 13] </ref> as the foundation for our proof. Our work is perhaps closest in spirit to Back's extension of the refinement calculus to include concurrent action systems [2]. He presents sufficient conditions for permitting the refinement of a concurrent algorithm.
Reference: [2] <author> R. J. R. </author> <title> Back. A method for refining atom-icity in parallel algorithms. </title> <editor> In G. Goos and J. Hartmanis, editors, </editor> <booktitle> PARLE '89, </booktitle> <volume> volume II, </volume> <pages> pages 199-216, </pages> <address> Berlin, </address> <month> June 12-16 </month> <year> 1989. </year> <note> Available as LNCS 366, Springer-Verlag. </note>
Reference-contexts: Our work is perhaps closest in spirit to Back's extension of the refinement calculus to include concurrent action systems <ref> [2] </ref>. He presents sufficient conditions for permitting the refinement of a concurrent algorithm. Our work is similar to this extension of the refinement calculus in that both use weakest precondition semantics, both consider nondeterministic actions that may or may not terminate, and both preserve total correctness.
Reference: [3] <author> Edsger W. Dijkstra. </author> <title> A Discipline of Programming. Prentice-Hass Series in Automatic Computation. </title> <publisher> Prentice-Hall, </publisher> <address> Engle-wood Cliffs, New Jersey, </address> <year> 1976. </year>
Reference-contexts: This predicate characterizes when an invariant is required to hold. Lamport [7] further generalizes the result to include progress properties by introducing fairness requirements. Our approach differs from these results in several ways. First, we use a weakest precondition <ref> [3, 5] </ref> semantics, while the work cited above uses a next-state transition system semantics. <p> Such an action has an associated enabling predicate that the shared state must satisfy in order for the action to complete. The enabling predicate of a synchronization action S can be defined using weakest precondition semantics <ref> [3, 5] </ref> as wp:S :true . In the trace of the computation, the state immediately before the execution of a synchronization action must meet that action's enabling condition. For example, for a blocking receive on a channel, the enabling condition is that there be a delivered message in the channel. <p> A trace maps the initial system state to a set of possible final system states (the effect of an action, hence a trace, can be nondeterministic). We use weakest preconditions <ref> [3, 5] </ref> to define trace semantics.
Reference: [4] <author> Edsger W. Dijkstra and C. S. Scholten. </author> <title> Termination detection for diffusing computations. </title> <journal> Information Processing Letters, </journal> <volume> 11(1) </volume> <pages> 1-4, </pages> <month> August </month> <year> 1980. </year>
Reference-contexts: a Java wait operation inside a synchronized block releases the associated lock, terminating the atomic block. tion 8 illustrates the application of the the-orem to several real synchronization systems; and Section 9 concludes. 2 Motivating Example: The Gossip Algorithm The gossip algorithm is a simple implementation of a diffusing computation <ref> [4, 12] </ref>. It can be used to synchronize a collection of processes. Informally, the gossip algorithm uses an expanding wave to include all processes, followed by a contracting wave to signal that all processes were included. The algorithm for a single process in this computation is given in Figure 1.
Reference: [5] <author> Edsger W. Dijkstra and Carel S. Scholten. </author> <title> Predicate Calculus and Program Semantics. Texts and Monographs in Computer Science. </title> <publisher> Springer-Verlag, </publisher> <address> 175 Fifth Avenue, New York, New York 10010, </address> <year> 1990. </year>
Reference-contexts: This predicate characterizes when an invariant is required to hold. Lamport [7] further generalizes the result to include progress properties by introducing fairness requirements. Our approach differs from these results in several ways. First, we use a weakest precondition <ref> [3, 5] </ref> semantics, while the work cited above uses a next-state transition system semantics. <p> Such an action has an associated enabling predicate that the shared state must satisfy in order for the action to complete. The enabling predicate of a synchronization action S can be defined using weakest precondition semantics <ref> [3, 5] </ref> as wp:S :true . In the trace of the computation, the state immediately before the execution of a synchronization action must meet that action's enabling condition. For example, for a blocking receive on a channel, the enabling condition is that there be a delivered message in the channel. <p> A trace maps the initial system state to a set of possible final system states (the effect of an action, hence a trace, can be nondeterministic). We use weakest preconditions <ref> [3, 5] </ref> to define trace semantics. <p> A trace maps the initial system state to a set of possible final system states (the effect of an action, hence a trace, can be nondeterministic). We use weakest preconditions [3, 5] to define trace semantics. Following the notation of <ref> [5] </ref>, wp:t:Q denotes the weakest precondition (i.e., the set of states from which trace t is guaranteed to terminate in a state satisfying Q ), while wlp:t:Q denotes the weakest liberal precondition (i.e., the set of states from which trace t is guaranteed to either not terminate or terminate in a <p> Denoting trace refinement by v (read "refined by"), this can be expressed more formally as: t v t 0 j ( 8 Q :: [wp:t:Q ) wp:t 0 :Q] ) We make use of [ ] as "everywhere brackets" <ref> [5] </ref>, denoting universal quantification over the state space.
Reference: [6] <author> Thomas W. Doeppner, Jr. </author> <title> Parallel program correctness through refinement. </title> <booktitle> In Fourth ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 155-169, </pages> <address> 1133 Avenue of the Americas, New York, New York 10036, </address> <month> January 17-19 </month> <year> 1977. </year> <note> ACM. </note>
Reference-contexts: Also, Lipton's main result is for "PV parallel programs" (i.e., semaphore-based programs), whereas our result applies more generally to any synchronization system with a pair of synchronization primitives. We use our result to analyze a collection of synchronization paradigms, including semaphores. Lipton's results were extended by Doeppner <ref> [6] </ref> to a larger class of safety properties, then further generalized by Lamport and Schneider [8] to the general class of safety properties, namely invariants. They generalize the notion of atomicity by introducing a predicate "(A) (for "external") that holds when control is outside of an atomic action A .
Reference: [7] <author> Leslie Lamport. </author> <title> A theorem on atomicity in distributed algorithms. </title> <journal> Distributed Computing, </journal> <volume> 4(2) </volume> <pages> 59-68, </pages> <year> 1990. </year>
Reference-contexts: They generalize the notion of atomicity by introducing a predicate "(A) (for "external") that holds when control is outside of an atomic action A . This predicate characterizes when an invariant is required to hold. Lamport <ref> [7] </ref> further generalizes the result to include progress properties by introducing fairness requirements. Our approach differs from these results in several ways. First, we use a weakest precondition [3, 5] semantics, while the work cited above uses a next-state transition system semantics.
Reference: [8] <author> Leslie Lamport and Fred B. Schneider. </author> <title> Pretending atomicity. </title> <type> Technical Report 44, </type> <institution> Digital Systems Research Center, Palo Alto, California, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: We use our result to analyze a collection of synchronization paradigms, including semaphores. Lipton's results were extended by Doeppner [6] to a larger class of safety properties, then further generalized by Lamport and Schneider <ref> [8] </ref> to the general class of safety properties, namely invariants. They generalize the notion of atomicity by introducing a predicate "(A) (for "external") that holds when control is outside of an atomic action A . This predicate characterizes when an invariant is required to hold.
Reference: [9] <author> Harry R. Lewis and Christos H. Papadim-itriou. </author> <title> Elements of the Theory of Computation. </title> <booktitle> Prentice-Hall Software Series. </booktitle> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, New Jersey 07632, </address> <year> 1981. </year>
Reference-contexts: For a collection of processes S , the trace of a computation is projected to a string in the language: L = ( [ p : p 2 S : p? [ p! [ p# ) fl As in <ref> [9] </ref>, we use [ to separate alternative items and fl to mean a (possibly empty) sequence of items. A trace maps the initial system state to a set of possible final system states (the effect of an action, hence a trace, can be nondeterministic).
Reference: [10] <author> Richard J. Lipton. </author> <title> Reduction: A method of proving properties of parallel programs. </title> <journal> CACM, </journal> <volume> 18(12) </volume> <pages> 717-721, </pages> <month> December </month> <year> 1975. </year>
Reference-contexts: This paper addresses the following question: Under what conditions is such a modification valid? 3 Related Work The problem of reasoning about a concurrent program by considering a program with larger atomic blocks was first formally addressed by Lipton <ref> [10] </ref>. His approach was to classify actions as "right movers" and "left movers", which is the core of the proof of our theorem as well. Lipton's reduction method considers partial correctness only, however, while we use total correctness.
Reference: [11] <author> Zohar Manna and Amir Pnueli. </author> <title> The Temporal Logic of Reactive and Concurrent Systems, volume 1. Specification. </title> <publisher> Springer-Verlag, </publisher> <address> 175 Fifth Avenue, New York, New York 10010, </address> <year> 1992. </year>
Reference-contexts: Second, we base our approach on total correctness as a semantic definition of a program, rather than safety properties. Although this restricts our results to programs with a precondition and postcondition specification (as opposed to reactive programs <ref> [11] </ref> such as operating systems), it allows us to use the traditional refinement calculus [1, 14, 13] as the foundation for our proof. Our work is perhaps closest in spirit to Back's extension of the refinement calculus to include concurrent action systems [2].
Reference: [12] <author> Jayadev Misra and K. M. Chandy. </author> <title> Termination detection of diffusing computations in communicating sequential processes. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 4(1) </volume> <pages> 37-43, </pages> <month> January </month> <year> 1982. </year>
Reference-contexts: a Java wait operation inside a synchronized block releases the associated lock, terminating the atomic block. tion 8 illustrates the application of the the-orem to several real synchronization systems; and Section 9 concludes. 2 Motivating Example: The Gossip Algorithm The gossip algorithm is a simple implementation of a diffusing computation <ref> [4, 12] </ref>. It can be used to synchronize a collection of processes. Informally, the gossip algorithm uses an expanding wave to include all processes, followed by a contracting wave to signal that all processes were included. The algorithm for a single process in this computation is given in Figure 1.
Reference: [13] <author> Carroll Morgan. </author> <title> The specification statement. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 10(3) </volume> <pages> 7-30, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: Although this restricts our results to programs with a precondition and postcondition specification (as opposed to reactive programs [11] such as operating systems), it allows us to use the traditional refinement calculus <ref> [1, 14, 13] </ref> as the foundation for our proof. Our work is perhaps closest in spirit to Back's extension of the refinement calculus to include concurrent action systems [2]. He presents sufficient conditions for permitting the refinement of a concurrent algorithm. <p> A trace t is said to be refined by a trace t 0 if and only if any specification satisfied by t is satisfied by t 0 as well <ref> [13] </ref>. (Conversely, t 0 is said to refine t .) Refinement is therefore a "correctness preserving" process [14].
Reference: [14] <author> Joseph M. Morris. </author> <title> A theoretical basis for stepwise refinement and the progamming calculus. </title> <booktitle> Science of Computer Programming, </booktitle> <volume> 9(3) </volume> <pages> 287-306, </pages> <year> 1987. </year>
Reference-contexts: Although this restricts our results to programs with a precondition and postcondition specification (as opposed to reactive programs [11] such as operating systems), it allows us to use the traditional refinement calculus <ref> [1, 14, 13] </ref> as the foundation for our proof. Our work is perhaps closest in spirit to Back's extension of the refinement calculus to include concurrent action systems [2]. He presents sufficient conditions for permitting the refinement of a concurrent algorithm. <p> A trace t is said to be refined by a trace t 0 if and only if any specification satisfied by t is satisfied by t 0 as well [13]. (Conversely, t 0 is said to refine t .) Refinement is therefore a "correctness preserving" process <ref> [14] </ref>. Denoting trace refinement by v (read "refined by"), this can be expressed more formally as: t v t 0 j ( 8 Q :: [wp:t:Q ) wp:t 0 :Q] ) We make use of [ ] as "everywhere brackets" [5], denoting universal quantification over the state space.
References-found: 14

