URL: ftp://ftp.ee.lbl.gov/papers/vp-tcpanaly-sigcomm97.ps.Z
Refering-URL: http://www.cs.washington.edu/education/courses/590s/w98/index.html
Root-URL: 
Email: vern@ee.lbl.gov  
Title: Automated Packet Trace Analysis of TCP Implementations  
Author: Vern Paxson 
Date: June 23, 1997  
Address: Berkeley  
Affiliation: Network Research Group Lawrence Berkeley National Laboratory University of California,  
Pubnum: LBNL-40489  
Abstract: We describe tcpanaly, a tool for automatically analyzing a TCP implementation's behavior by inspecting packet traces of the TCP's activity. Doing so requires surmounting a number of hurdles, including detecting packet filter measurement errors, coping with ambiguities due to the distance between the measurement point and the TCP, and accommodating a surprisingly large range of behavior among different TCP implementations. We discuss why our efforts to develop a fully general tool failed, and detail a number of significant differences among 8 major TCP implementations, some of which, if ubiquitous, would devastate Internet performance. The most problematic TCPs were all independently written, suggesting that correct TCP implementation is fraught with difficulty. Consequently, it behooves the Internet community to develop testing programs and reference implementations. 
Abstract-found: 1
Intro-found: 1
Reference: [Ba95] <author> F. Baker, Ed., </author> <title> Requirements for IP Version 4 Routers, </title> <type> RFC 1812, </type> <institution> DDN Network Information Center, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: consistent with slow start having begun sometime between the ack and the data packet, then the trace is consistent with an unseen source quench. (This analysis does not work for Linux 1.0, since it does not enter slow start.) Source quenches are quite rarethey have been deprecated (x 4.3.3.3 of <ref> [Ba95] </ref>), since generating extra network traffic during a time of heavy load violates fundamental stability principlesbut they do happen, and tcpanaly detected 91 instances among the 20,000 traces. 7 Receiver analysis In this section we discuss how tcpanaly analyzes a TCP implementation's receiver behavior, namely when and how the implementation chooses
Reference: [Br89] <author> R. Braden, ed., </author> <title> Requirements for Internet HostsCommunication Layers, </title> <type> RFC 1122, </type> <institution> Network Information Center, SRI International, </institution> <address> Menlo Park, CA, </address> <month> October </month> <year> 1989. </year>
Reference-contexts: This occurs when new data arrives that is in sequence. The TCP standard states that a TCP may refrain from acknowledging such data in the hopes that additional data may arrive and the acknowledgements combined, but for no longer than 500 msec (x 4.2.3.2 of <ref> [Br89] </ref>). Furthermore, a correct TCP implementation should always generate at least one acknowledgement for every two packet's worth of new data received. Acknowledgement strategy is further discussed in [Cl82]. <p> The TCP standard <ref> [Br89] </ref> requires that acknowledgements be delayed no more than 500 msec, and that a TCP acknowledge at least every two full-sized segments it receives. tcpanaly classifies acks into three categories, those for less than two full-sized packets (delayed acks), those for two full-sized packets (normal acks), and those for more than <p> TCP receives a packet with out-of-sequence data, it either must generate an ack, if the data corresponds to data already acknowledged, which we term below sequence; or should generate an ack, if the data is for a sequence number beyond what has been previously acknowledged, which we term above sequence <ref> [Br89] </ref>. In both cases, the ack generated is for the highest in-sequence data received. Of the TCPs in our study, only SunOS 4.1 exhibited unusual behavior when receiving out-of-sequence data. <p> Skipping slow start initially and after loss means that Trumpet/Winsock data transfers can present heavy bursts of traffic to the network when it lacks the resources to accept them. It violates the standard <ref> [Br89] </ref>. Ack-ing only when a timer expires can lead to excessive, unnecessary retransmissions when a single ack for many packets is dropped by the network. It also violates the standard. Finally, discarding successfully-received above-sequence data wastes network resources as the other TCP must resend all of the data again. <p> It also violates the standard. Finally, discarding successfully-received above-sequence data wastes network resources as the other TCP must resend all of the data again. This behavior, while strongly discouraged by <ref> [Br89, x 4.2.2.20] </ref>, is not strictly forbidden, presumably to avoid indefinitely tying up resources in the receiving TCP in cases where connectivity is lost with the sender. Linux version 2.
Reference: [BOP94] <author> L. Brakmo, S. O'Malley, and L. Peterson, </author> <title> TCP Vegas: New Techniques for Congestion Detection and Avoidance, </title> <booktitle> Proceedings of SIGCOMM '94, </booktitle> <pages> pp. 24-35, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: An example of such measurements is the congestion control scheme used by TCP Vegas <ref> [BOP94] </ref>, which infers how 12 the sender's window changes are affecting the queueing de-lays in the network by inspecting the associated RTT timings. As developed in [BOP94], the RTT timings are made solely by the sender. 6 Not needing to rely on cooperation by the receiver in making these measurements is <p> An example of such measurements is the congestion control scheme used by TCP Vegas <ref> [BOP94] </ref>, which infers how 12 the sender's window changes are affecting the queueing de-lays in the network by inspecting the associated RTT timings. As developed in [BOP94], the RTT timings are made solely by the sender. 6 Not needing to rely on cooperation by the receiver in making these measurements is a great boon because it immensely diminishes the problem of deploying the scheme in the face of the Internet's huge installed base of TCP implementations; but
Reference: [BP95] <author> L. Brakmo and L. Peterson, </author> <title> Performance Problems in BSD4.4 TCP, </title> <journal> Computer Communication Review, </journal> <volume> 25(5), </volume> <pages> pp. 69-84, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: The authors' emphasis was on correctness in terms of the TCP standards, and they found several implementation flaws. Brakmo and Peterson analyzed performance problems they found in TCP Lite, a widely-used successor to TCP Reno <ref> [BP95] </ref>. TCP Lite is also known as Net/3, the name we will subsequently use. Their approach was to simulate Net/3's behavior using a simulator that directly executed the Net/3 code. <p> A fuller description of each implementation can be found in [Pa97b]. Among the implementations in our study, the minor variations we observed among the Reno-derived implementations concern: presence or absence of the header prediction bug and MSS confusion problems discussed in <ref> [BP95] </ref>; use of Eqn 1 versus Eqn 2; how ssthresh is rounded when it is cut in response to a retransmission; failure to clear the duplicate ack counter upon timeout (rarely manifested); duplicate acks resulting in updates to cwnd (rarely manifested); and use of the initially offered MSS to initialize cwnd
Reference: [Cl82] <author> D. Clark, </author> <title> Window and Acknowledgement Strategy in TCP, </title> <type> RFC 813, </type> <institution> Network Information Center, SRI International, </institution> <address> Menlo Park, CA, </address> <month> July </month> <year> 1982. </year>
Reference-contexts: Furthermore, a correct TCP implementation should always generate at least one acknowledgement for every two packet's worth of new data received. Acknowledgement strategy is further discussed in <ref> [Cl82] </ref>. A mandatory ack obligation occurs when a packet arrives that requires the receiving TCP to respond with an acknowledgement. tcpanaly considers the arrival of any out-of-sequence data as creating a mandatory ack obligation.
Reference: [CL94] <author> D. Comer and J. Lin, </author> <title> Probing TCP Implementations, </title> <booktitle> Proceedings of the 1994 Summer USENIX Conference, </booktitle> <address> Boston, MA. </address>
Reference-contexts: In this section, we give a brief overview of the techniques and results, and at the end compare the studies with ours. Comer and Lin studied TCP behavior using a technique termed active probing <ref> [CL94] </ref>. Active probing consists of treating a TCP implementation as a black box and observing how it reacts to external stimuli, such as a loss of connectivity to the other endpoint. <p> They also found that Solaris 2.3 uses a much lower initial RTO, around 300 msec, than the other implementations (Comer and Lin found the same for Solaris 2.1 <ref> [CL94] </ref>), and takes much longer to adapt the RTO to higher, measured round-trip times (RTTs). We discuss both of these latter problems further in x 8.6. <p> Dawson et al. identified that Solaris uses an atypically low initial value of about 300 msec for its retransmission timeout (RTO) [DJM97], which agrees with Comer and Lin's finding concerning the Solaris 2.1 initial RTO <ref> [CL94] </ref>. This value, coupled with difficulties in adapting the timer to higher RTTs, leads to the broken retransmission behavior. For a connection with a longer RTT, the TCP is guaranteed to retransmit its first packet, whether needed or not.
Reference: [DJM97] <author> S. Dawson, F. Jahanian, and T. Mitton, </author> <title> Experiments on Six Commercial TCP Implementations Using a Software Fault Injection Tool, </title> <note> to appear in Software: Practice & Experience. </note>
Reference-contexts: He also identified three Net/3 implementation bugs and discussed fixes. In recent work, Dawson, Jahanian and Mitton studied six TCP implementationsSunOS 4.1.3, AIX 3.2.3, NeXT (Mach 2.5), OS/2, Windows 95, and Solaris 2.3using a software fault injection tool they developed <ref> [DJM97] </ref>. Their basic approach is a refinement of Comer and Lin's active probing, in which they interpose a general purpose packet manipulation program between the TCP implementation and the actual network, so they can arbitrarily control the packets the TCP sends and receives. <p> Like Linux, the most striking feature of Solaris 2.3/2.4 TCP is its broken retransmission behavior. Dawson et al. identified that Solaris uses an atypically low initial value of about 300 msec for its retransmission timeout (RTO) <ref> [DJM97] </ref>, which agrees with Comer and Lin's finding concerning the Solaris 2.1 initial RTO [CL94]. This value, coupled with difficulties in adapting the timer to higher RTTs, leads to the broken retransmission behavior.
Reference: [Ja88] <author> V. Jacobson, </author> <title> Congestion Avoidance and Control, </title> <booktitle> Proceedings of SIGCOMM '88, </booktitle> <pages> pp. 314-329, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: For example, the original TCP specification did not detail how many packets a TCP endpoint should retransmit when it believes it has detected packet loss. This led to an unforeseen interaction in which congestion collapse rendered the network useless during periods of heavy load <ref> [Ja88] </ref>. The situation was remedied by Jacobson's work on congestion avoidance, now part of the TCP specification. However, the Internet can still be subject to congestion collapse if TCPs do not correctly implement these refinements. <p> The sender behavior includes the TCP's congestion behavior: how it responds to signals of network stress. Proper congestion behavior is crucial to assure the network's stability <ref> [Ja88] </ref>. <p> Second, it decides to retransmit much too early, leading it to retransmit packets for which acks are already heading back. Jacobson terms this sort of behavior the network equivalent of pouring gasoline on a fire <ref> [Ja88] </ref>, because it unnecessarily consumes network resources precisely when they are scarce. Consequently, it can lead to congestion collapse, in which the network load stays extremely high but throughput is reduced to close to zero [Na84]. ack arrives advancing the window by three packets, which the TCP immediately sends.
Reference: [JLM89] <author> V. Jacobson, C. Leres, and S. McCanne, tcpdump, </author> <note> available via anonymous ftp to ftp.ee.lbl.gov, </note> <month> June </month> <year> 1989. </year>
Reference-contexts: In this paper we discuss tcpanaly, a tool we developed that analyzes packet filter traces produced by tcpdump <ref> [JLM89] </ref>. 1 tcpanaly has coded within it knowledge of a large number of TCP implementations. Using this, it can determine whether a given trace appears consistent with a given implementation, and, if so, exactly why the TCP chose to transmit each packet at the time it did.
Reference: [KP87] <author> P. Karn and C. Partridge. </author> <title> Estimating round-trip times in reliable transport protocols, </title> <booktitle> Proceedings of SIGCOMM '87, </booktitle> <month> August </month> <year> 1987. </year>
Reference-contexts: new packets, yet each retransmission is completely unnecessary! (The initial SYN sent at T = 0 is not retransmitted, since it uses a different retransmission timer.) Furthermore, so many retransmissions are generated that it is difficult to find unambiguous RTT timings, which are required in order to adapt the timer <ref> [KP87] </ref>. While the RTO does indeed double on multiple timeouts, it is restored to its erroneously small value immediately upon an acknowledgement for a retransmitted packet, so it never has much opportunity to adapt. As the path's RTT increases, the problem only gets worse.
Reference: [Na84] <author> J. Nagle, </author> <title> Congestion Control in IP/TCP Internet-works, </title> <type> RFC 896, </type> <institution> Network Information Center, SRI International, </institution> <address> Menlo Park, CA, </address> <month> January </month> <year> 1984. </year>
Reference-contexts: Consequently, it can lead to congestion collapse, in which the network load stays extremely high but throughput is reduced to close to zero <ref> [Na84] </ref>. ack arrives advancing the window by three packets, which the TCP immediately sends. At T = 86, however, two duplicate acks arrive, the first of which apparently spurs the TCP to retransmit every packet it has in flight.
Reference: [Pa97a] <author> V. Paxson, </author> <title> End-to-End Internet Packet Dynamics, </title> <booktitle> Proceedings of SIGCOMM '97, </booktitle> <month> Septem-ber </month> <year> 1997. </year>
Reference-contexts: We became interested in the problem of automatically analyzing a TCP's behavior when faced with a wealth of TCP trace data for which we wished to distinguish the effects of the TCP endpoints from those due to the network path itself <ref> [Pa97a] </ref>. In this paper we discuss tcpanaly, a tool we developed that analyzes packet filter traces produced by tcpdump [JLM89]. 1 tcpanaly has coded within it knowledge of a large number of TCP implementations. <p> If the TCP's behavior is instead consistent with it having not received one or more of the recent packets, then tcpanaly infers that the packets were discarded upon arrival as corrupted. In <ref> [Pa97a] </ref>, we analyze the prevalence of Internet packet corruption based on this analysis. 8 Observed sender behavior In this section we look at the variations in how the different TCP implementations listed in Table 1 act when sending data. <p> Normal acks. We term an ack normal if it is for two full-sized packets. Since our study concerns unidirectional 5 Well, almost impossible. It sometimes happens due to timing compression by the network after the bottleneck link, as discussed in <ref> [Pa97a] </ref>. bulk transfer, we expect that most of the time the receiving TCP will have plenty of opportunity to generate normal acks. BSD-derived TCPs do not simply generate acknowledge-ments every time they receive two in-sequence, full-sized packets. <p> Consequently, we are very interested in the degree to which single-endpoint measurement can yield accurate results. In <ref> [Pa97a] </ref>, we explore in detail some of the difficulties of single-endpoint measurement, namely that many Internet path properties, such as delay and loss rate, are often asymmetric in the path's two directions. <p> Finally, we observed two implementation problems (both communicated to the implementors). The first is that the TCP executes fast retransmission upon receiving two duplicate acks rather than threea consequence of misinterpreting a description of the algorithm. In <ref> [Pa97a] </ref> we analyze the effects of this change and find that it results in up to 70% more fast retransmission opportunities, but also leads to three times as many unnecessary retransmissions, because of the prevalence of out-of-order data packet delivery in the Internet.
Reference: [Pa97b] <author> V. Paxson, </author> <title> Measurements and Analysis of End-to-End Internet Dynamics, </title> <type> Ph.D. dissertation, </type> <institution> University of California, Berkeley, </institution> <month> April </month> <year> 1997. </year>
Reference-contexts: The 2.5 MB/sec corresponds to how fast the operating system is sourcing the traffic, while the 1 MB/sec reflects the local rate limit of the Ethernet link speed. tcpanaly copes with measurement duplicates by discarding the later copy, for reasons detailed in <ref> [Pa97b] </ref>. 3.1.3 Resequencing Another form of packet filter error is what we term rese-quencing, in which the packet filter alters the ordering of the packets so that it no longer reflects events as they actually occurred in the network. <p> These tests prove quite effective at detecting two key timing problems, clock adjustments (a clock jumps forward or backward) and relative clock skew (the clock at one endpoint runs faster than that at the other). The tests, however, require extensive analysis, which we discuss in <ref> [Pa97b] </ref> and not here due to space limitations. In this section we confine ourselves to a simple test tcpanaly performs to check the validity of a single trace's timestamps, namely ensuring that they never decrease. We refer to a decrease in the timestamp values as time travel. <p> Another form of time travel is a forward adjustment. These are much more difficult to detect since they appear virtually identical to a period of elevated network delays. They can, however, be detected if one has available trace pairs of packet departures and arrivals, as discussed in <ref> [Pa97b] </ref>. 3.2 Packet filter vantage point While not a measurement error per se, another difficulty in calibrating packet filter measurements arises from complications due to the packet filter's location in the network. We term this its vantage point. <p> Since none of the TCPs discussed in this paper do so (an experimental TCP that tcpanaly also knows about does), we defer discussion of this issue to <ref> [Pa97b] </ref>. The final situation tcpanaly must infer is whether the TCP it analyzes received an Internet Control Message Protocol (ICMP) source quench message instructing it to slow down [Po81]. <p> A fuller description of each implementation can be found in <ref> [Pa97b] </ref>.
Reference: [Po81] <author> J. Postel, </author> <title> Internet Control Message Protocol, </title> <type> RFC 792, </type> <institution> Network Information Center, SRI International, </institution> <address> Menlo Park, CA, </address> <month> September </month> <year> 1981. </year>
Reference-contexts: The final situation tcpanaly must infer is whether the TCP it analyzes received an Internet Control Message Protocol (ICMP) source quench message instructing it to slow down <ref> [Po81] </ref>. Since ICMP messages do not match a packet filter pattern limited to TCP packets (which is what we used in our study), such messages will not appear in a TCP-only packet trace. TCP implementations vary in how they respond to source quench messages.
Reference: [St94] <author> W.R. Stevens, </author> <title> TCP/IP Illustrated, Volume 1: The Protocols, </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
Reference-contexts: We assume that the reader is familiar with the principles of TCP congestion behavior in terms of the congestion window, cwnd, and the congestion avoidance threshold, ssthresh, as outlined in Ja-cobson's paper; and with the notions of fast retransmission and fast recovery, detailed in <ref> [St94] </ref>. 6.1 Data liberations To accurately deduce the sender behavior of a TCP from a record of its traffic requires a packet trace captured from a vantage point at or near the TCP, in order to reliably distinguish between TCP behavior and network-induced behavior.
Reference: [St96] <author> W.R. Stevens, </author> <title> TCP/IP Illustrated, Volume 3: TCP for Transactions, HTTP, NNTP, and the UNIX Domain Protocols, </title> <publisher> Addison-Wesley, </publisher> <year> 1996. </year>
Reference-contexts: They also discussed fixes for the problems. Stevens devotes a chapter in <ref> [St96] </ref> to an analysis of the behavior of a large number of TCP connections made to a World Wide Web server running Net/3 TCP. <p> We discuss both of these latter problems further in x 8.6. Except for <ref> [St96] </ref>, these previous studies used active techniques, in which an implementation's behavior is examined by controlling the packets it receives and determining its response. All of the studies involve manual analysis. <p> We next summarize the minor variations among the different implementations, and then study in detail the significant sender problems exhibited by Net/3, Linux 1.0, and Solaris 2.3/2.4 TCPs. 8.1 Generic Tahoe behavior Our Tahoe implementation reflects the behavior of the Tahoe version of BSD TCP, released in 1988 <ref> [St96, p.27] </ref>. We discuss it separately from the later Reno release because one of the implementations prevalent in our study, SunOS 4.1, was clearly derived from Tahoe and not Reno.
Reference: [WS95] <author> G. Wright and W. Stevens, </author> <title> TCP/IP Illustrated, </title> <booktitle> Volume 2: The Implementation, </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1995. </year> <month> 15 </month>
Reference-contexts: It updates the congestion window cwnd according to congestion avoidance if cwnd is strictly larger than ssthresh, using: W = MSS 2 cwnd - without any additional constant term (Eqn 2 below). 2 Linux 1.0, a later Solaris release, and the invaluable analysis of Net/3 in <ref> [WS95] </ref>. 8.2 Generic Reno behavior The Reno version of BSD TCP was released in 1990. Our generic Reno implementation does not attempt to precisely describe that release, but instead to provide a common base from which we can express as variants the numerous Reno-derived implementations in our study. <p> Consequently, it is not surprising that it differs in many ways from the others in our study. The most significant difference is its broken retransmission behavior. First, often when it decides to retransmit, it re-sends every unac 3 Specifically: 2 30 - 2 14 . See <ref> [WS95, p.835] </ref>. The bug does not occur if the initialization instead comes from the route cache. knowledged packet in a single burst. Second, it decides to retransmit much too early, leading it to retransmit packets for which acks are already heading back.
References-found: 17

