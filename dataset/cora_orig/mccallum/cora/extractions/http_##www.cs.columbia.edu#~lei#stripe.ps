URL: http://www.cs.columbia.edu/~lei/stripe.ps
Refering-URL: http://www.cs.columbia.edu/~lei/publications.html
Root-URL: http://www.cs.columbia.edu
Email: lei,kar@cs.columbia.edu  
Title: Faster Joins, Self-Joins and Multi-Way Joins Using Join Indices  
Author: Hui Lei Kenneth A. Ross 
Keyword: Categories and Subject Descriptors: H.2.4 [Database Management]: Systems query processing Keywords: Relational databases, join, query optimization, decision support systems.  
Address: New York, NY 10027  
Affiliation: Department of Computer Science, Columbia University,  
Abstract: We propose a new algorithm, called Stripe-join, for performing a join given a join index. Stripe-join is inspired by an algorithm called "Jive-join" developed by Li and Ross. Stripe-join makes a single sequential pass through each input relation, in addition to one pass through the join index and two passes through a set of temporary files that contain tuple identifiers but no input tuples. Stripe-join performs this efficiently even when the input relations are much larger than main memory, as long as the number of blocks in main memory is of the order of the square root of the number of blocks in the participating relations. Stripe-join is particularly efficient for self-joins. To our knowledge, Stripe-join is the first algorithm that, given a join index and a relation significantly larger than main memory, can perform a self-join with just a single pass over the input relation and without storing input tuples in intermediate files. Almost all the I/O is sequential, thus minimizing the impact of seek and rotational latency. The algorithm is resistant to data skew. It can also join multiple relations while still making only a single pass over each input relation. Using a detailed cost model, Stripe-join is analyzed and compared with competing algorithms. For large input relations, Stripe-join performs significantly better than Valduriez's algorithm and hash join algorithms. We demonstrate circumstances under which Stripe-join performs significantly better than Jive-join. Unlike Jive-join, Stripe-join makes no assumptions about the order of the join index. fl This research was supported by a grant from the AT&T Foundation, by a David and Lucile Packard Foundation Fellowship in Science and Engineering, by a Sloan Foundation Fellowship, by NSF CISE award CDA-96-25374, and by an NSF Young Investigator award IRI-94-57613. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. S. Batory. </author> <title> On searching transposed files. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 4(4) </volume> <pages> 531-544, </pages> <year> 1979. </year>
Reference-contexts: Like Jive-join, Stripe-join uses a vertically partitioned data structure for the join result. (We do not assume that the inputs are vertically partitioned.) Attributes from the first input relation are stored in a separate file from those of the second input relation, using transposed files <ref> [1] </ref>. Attributes that are common are placed arbitrarily in one of the two vertical fragments. There is a one-to-one correspondence between records in each vertical partition: The nth record in the first vertical fragment matches the nth record in the second. <p> on the same disk as each other. 2 Similarly, we can store all temporary files on one disk. (This kind of configuration is recommended by most commercial vendors.) 2.1 A Vertically Partitioned Data Structure for the Join Result We use a vertically partitioned data structure known as a transposed file <ref> [1] </ref> to store the join result. Attributes from each R i that are present in the join result are stored in a separate file (denoted JR i ). Join attributes that are common to more than one relation are placed arbitrarily in one of the vertical fragments.
Reference: [2] <author> J. Blakeley and Nancy Martin. </author> <title> Join index, materialized view, and hybrid-hash join: a performance analysis. </title> <booktitle> In Proc. IEEE Int'l Conf. on Data Eng., </booktitle> <pages> pages 256-263, </pages> <year> 1990. </year>
Reference-contexts: We assume that in-memory sorting is done in-place. In this paper we do not address the cost of maintaining the join index. Blakeley and Martin have comprehensively analyzed the tradeoff between join index maintenance cost and the join speedup <ref> [2] </ref>. 4 One can show analytically that for linear seek times the time taken to traverse the whole disk is, on average, three times the time taken to move from a random cylinder to another random cylinder on the disk. 4.2 Memory Requirements We need Step 1 and Step 2 to
Reference: [3] <author> M. Blasgen and K. Eswaran. </author> <title> Storage and access in relational data bases. </title> <journal> IBM Systems Journal, </journal> <volume> 16(4), </volume> <year> 1977. </year>
Reference-contexts: Therefore, it is critical to implement joins in the most efficient way possible. A number of techniques have been developed to perform "ad-hoc" joins, i.e., joins performed without the benefit of additional data structures such as indices <ref> [3, 4, 6, 9, 13, 16] </ref>. In this paper, we consider joins of relations for which there exists a pre-computed access structure, namely a join index [17]. A join index between two relations maintains pairs of identifiers of tuples that would match in case of a join.
Reference: [4] <author> B. Bratbergsengen. </author> <title> Hashing methods and relational algebra operations. </title> <booktitle> In Proceedings of the VLDB Conference, </booktitle> <pages> pages 323-333, </pages> <month> August </month> <year> 1984. </year>
Reference-contexts: Therefore, it is critical to implement joins in the most efficient way possible. A number of techniques have been developed to perform "ad-hoc" joins, i.e., joins performed without the benefit of additional data structures such as indices <ref> [3, 4, 6, 9, 13, 16] </ref>. In this paper, we consider joins of relations for which there exists a pre-computed access structure, namely a join index [17]. A join index between two relations maintains pairs of identifiers of tuples that would match in case of a join.
Reference: [5] <author> K. Brown et al. </author> <title> Resource allocation and scheduling for mixed database workloads. </title> <type> Technical Report 1095, </type> <institution> University of Wisconsin, Madison, </institution> <year> 1992. </year>
Reference-contexts: A table of system constants, with their value (used in the analytic comparisons) is given in Table 2. The constants used follow <ref> [8, 5, 12] </ref>, and correspond to the Fujitsu M2266 disk drive.
Reference: [6] <author> D. J. DeWitt et al. </author> <title> Implementation techniques for main memory database systems. </title> <booktitle> In Proceedings of the ACM SIGMOD Conference, </booktitle> <pages> pages 1-8, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: Therefore, it is critical to implement joins in the most efficient way possible. A number of techniques have been developed to perform "ad-hoc" joins, i.e., joins performed without the benefit of additional data structures such as indices <ref> [3, 4, 6, 9, 13, 16] </ref>. In this paper, we consider joins of relations for which there exists a pre-computed access structure, namely a join index [17]. A join index between two relations maintains pairs of identifiers of tuples that would match in case of a join. <p> In [17], Valduriez proposed and analyzed a join algorithm that uses the join index. The most important conclusion of that study was that, under many circumstances, having the join index allows one to compute the join significantly faster than the "best" ad-hoc methods such as Hybrid hash-join <ref> [6] </ref>. However, it was shown in [12] that Valduriez's algorithm utilizes a significant amount of repetitious I/O. Blocks are accessed often for only a small fraction of their tuples. The same block may be read multiple times on different passes within the algorithm. <p> We present performance graphs for several example scenarios that illustrate the analytically derived cost for each algorithm. 5.1 Hash Joins There are several variants of hash joins in the literature. Two important variants are Grace-hash join [10] and Hybrid-hash join <ref> [6] </ref>. In Grace-hash join the input relations are hashed on the join attribute in such a way that the disk-resident hash buckets of one relation fit in memory. In a second phase the algorithm performs an in-memory join of the records in the corresponding hash-buckets. <p> Hybrid-hash join additionally keeps one hash bucket of the first relation in memory. When the first relation is not much larger than main memory the in-memory hash bucket significantly reduces the amount of I/O. The I/O performance of Hybrid-hash join has been studied in <ref> [6, 8, 12] </ref>; the graphs in this paper use the formulas from [12]. One can formulate a version of Grace-hash join that applies specifically to self-joins. During an initial pass of the relation to be joined, one can simultaneously hash on both attributes that are matched for the join.
Reference: [7] <author> G. Graefe. </author> <title> Performance enhancements for hybrid hash join. </title> <type> Technical Report 606, </type> <institution> University of Colorado, Boulder, </institution> <year> 1992. </year>
Reference-contexts: To be fair, the two-phase nature of Jive-join does allow a selection condition on a nonindexed attribute of the first relation to be combined within the join itself; such a combination is not straightforward with Stripe-join. 6 Extensions Stripe-join can use multi-level recursion <ref> [7] </ref> when the inputs are larger than the memory bound (Equation 3). We need to perform additional levels of partitioning, and to make an intermediate partitioning pass over (some of) the input tuples. Thus, the cost of the algorithm will be higher.
Reference: [8] <author> L. M. Haas, M. J. Carey, and M. Livny. </author> <title> Seeking the truth about ad hoc join costs. </title> <type> Technical Report RJ9368, </type> <institution> IBM Almaden Research Center, </institution> <year> 1993. </year>
Reference-contexts: The extension of our analysis to cases where fewer attributes are required is straightforward. We do not assume that any indexes are available on the input relations. We also do not assume that either input relation is physically ordered by any attribute. Following <ref> [8] </ref>, we assume that separate disks are used to store (a) join indices, (b) temporary files, (c) input relations, and (d) the output result. By using separate disks we avoid unnecessary disk seeks between accesses. <p> A table of system constants, with their value (used in the analytic comparisons) is given in Table 2. The constants used follow <ref> [8, 5, 12] </ref>, and correspond to the Fujitsu M2266 disk drive. <p> T L 8.3 Average rotational latency (milliseconds). T X 2.6 Block transfer time (milliseconds). Table 2: Table of system constants Haas, Carey and Livny have proposed a detailed I/O cost model in which seek time and rotational latency are explicit <ref> [8] </ref>. These authors reexamine a number of ad-hoc join methods using their cost model, and demonstrate that the ranking of join methods obtained by using a block-transfer-only cost model for I/O may change when the same algorithms are analyzed using their more detailed cost model. <p> In this paper, we shall use the detailed cost model from <ref> [8] </ref> to measure the cost of various join algorithms. The total I/O cost of a join algorithm is measured as N S T S + N I=O T L + N X T X : In this paper we ignore CPU cost, and focus on the I/O cost. <p> Hybrid-hash join additionally keeps one hash bucket of the first relation in memory. When the first relation is not much larger than main memory the in-memory hash bucket significantly reduces the amount of I/O. The I/O performance of Hybrid-hash join has been studied in <ref> [6, 8, 12] </ref>; the graphs in this paper use the formulas from [12]. One can formulate a version of Grace-hash join that applies specifically to self-joins. During an initial pass of the relation to be joined, one can simultaneously hash on both attributes that are matched for the join. <p> Thus one can save an entire pass through the input relation, although one still has to write and read the two disk-resident hash tables. We refer to this algorithm as a "Self-hash" join. Its performance characteristics can easily be derived from those of Grace-hash join <ref> [10, 8] </ref>. 5.2 Jive-join Jive-join improved on previous join techniques by allowing one to perform the join using a single sequential scan of the input relations. Stripe-join was inspired by Jive-join.
Reference: [9] <author> W. Kim. </author> <title> A new way to compute the product and join of relations. </title> <booktitle> In Proceedings of the ACM SIGMOD Conference, </booktitle> <pages> pages 179-187, </pages> <month> May </month> <year> 1980. </year>
Reference-contexts: Therefore, it is critical to implement joins in the most efficient way possible. A number of techniques have been developed to perform "ad-hoc" joins, i.e., joins performed without the benefit of additional data structures such as indices <ref> [3, 4, 6, 9, 13, 16] </ref>. In this paper, we consider joins of relations for which there exists a pre-computed access structure, namely a join index [17]. A join index between two relations maintains pairs of identifiers of tuples that would match in case of a join.
Reference: [10] <author> M. Kitsuregawa et al. </author> <title> Application of hash to data base machine and its architecture. </title> <journal> New Generation Computing, </journal> <volume> 1 </volume> <pages> 62-74, </pages> <year> 1983. </year>
Reference-contexts: We present performance graphs for several example scenarios that illustrate the analytically derived cost for each algorithm. 5.1 Hash Joins There are several variants of hash joins in the literature. Two important variants are Grace-hash join <ref> [10] </ref> and Hybrid-hash join [6]. In Grace-hash join the input relations are hashed on the join attribute in such a way that the disk-resident hash buckets of one relation fit in memory. In a second phase the algorithm performs an in-memory join of the records in the corresponding hash-buckets. <p> Thus one can save an entire pass through the input relation, although one still has to write and read the two disk-resident hash tables. We refer to this algorithm as a "Self-hash" join. Its performance characteristics can easily be derived from those of Grace-hash join <ref> [10, 8] </ref>. 5.2 Jive-join Jive-join improved on previous join techniques by allowing one to perform the join using a single sequential scan of the input relations. Stripe-join was inspired by Jive-join.
Reference: [11] <author> Donald Ervin Knuth. </author> <title> Sorting and Searching, </title> <booktitle> volume 3 of The Art of Computer Programming. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, USA, </address> <year> 1973. </year>
Reference: [12] <author> Z. Li and K. Ross. </author> <title> Fast joins using join indices. </title> <type> Technical Report CUCS-032-96, </type> <institution> Columbia University, </institution> <year> 1996. </year>
Reference-contexts: The most important conclusion of that study was that, under many circumstances, having the join index allows one to compute the join significantly faster than the "best" ad-hoc methods such as Hybrid hash-join [6]. However, it was shown in <ref> [12] </ref> that Valduriez's algorithm utilizes a significant amount of repetitious I/O. Blocks are accessed often for only a small fraction of their tuples. The same block may be read multiple times on different passes within the algorithm. In [12], Li and Ross proposed two algorithms that significantly improve upon Valduriez's algorithm. <p> However, it was shown in <ref> [12] </ref> that Valduriez's algorithm utilizes a significant amount of repetitious I/O. Blocks are accessed often for only a small fraction of their tuples. The same block may be read multiple times on different passes within the algorithm. In [12], Li and Ross proposed two algorithms that significantly improve upon Valduriez's algorithm. The algorithms are called "Jive-join" and "Slam-join." The two algorithms are duals of one another, and have very similar performance. Jive-join range-partitions the tuple-ids of the second input relation, then processes each partition separately. <p> In this paper, we propose a new algorithm that is similar to the Jive-join algorithm of <ref> [12] </ref>. Our new algorithm, which we term "Stripe-join," 1 has several important advantages over Jive-join: * Jive-join requires a fixed ordering of the join index. If the join index is not stored in such an order, one would have to first sort it before applying Jive-join. <p> There is a one-to-one correspondence between records in each vertical partition: The nth record in the first vertical fragment matches the nth record in the second. Such a representation has a negligible performance impact on processes that read the join result <ref> [12] </ref>. It is our understanding that vertical partitioning is being deployed in some current proprietary commercial database systems, including Sybase IQ and Red Brick. Our main contributions include: * The proposal of a novel algorithm for joining relations using a join index. <p> The partitions of JR i can be linked together 3 into a single file. Once we have performed Step 3 for all values of i we have the required join result. 2 We illustrate the use of Stripe-join using an example based on <ref> [12] </ref>, but without an ordered join index. Example 3.1: Consider the two relations Student and Course, and their join result, given below. This particular join is a natural join in which we match the course numbers in the two input tables. <p> A table of system constants, with their value (used in the analytic comparisons) is given in Table 2. The constants used follow <ref> [8, 5, 12] </ref>, and correspond to the Fujitsu M2266 disk drive. <p> Due to space constraints, we defer the presentation of our CPU cost model to the full version of this paper. The dominance of I/O cost over CPU cost for Jive-join has been demonstrated experimentally in <ref> [12] </ref>. We perform input buffering on the input relations in order to reduce seek and rotational latency. <p> In fact, we can perfectly partition the tasks of Step 3 to just fit into memory if we are prepared to perform a preprocessing step on the join index. The join index provides us with all the information we need about skew. A preprocessing step like that of <ref> [12] </ref> can examine the join index and calculate the partitioning elements that divide the tasks of Step 3 into equal-sized chunks. Another alternative is for the system to maintain a set of partitioning values at the same time that it maintains the join index. <p> Hybrid-hash join additionally keeps one hash bucket of the first relation in memory. When the first relation is not much larger than main memory the in-memory hash bucket significantly reduces the amount of I/O. The I/O performance of Hybrid-hash join has been studied in <ref> [6, 8, 12] </ref>; the graphs in this paper use the formulas from [12]. One can formulate a version of Grace-hash join that applies specifically to self-joins. During an initial pass of the relation to be joined, one can simultaneously hash on both attributes that are matched for the join. <p> When the first relation is not much larger than main memory the in-memory hash bucket significantly reduces the amount of I/O. The I/O performance of Hybrid-hash join has been studied in [6, 8, 12]; the graphs in this paper use the formulas from <ref> [12] </ref>. One can formulate a version of Grace-hash join that applies specifically to self-joins. During an initial pass of the relation to be joined, one can simultaneously hash on both attributes that are matched for the join. <p> Stripe-join was inspired by Jive-join. Example 5.1: Figure 3 shows a graph (based on one from <ref> [12] </ref>) that compares Jive-join (and Slam-join), Valduriez's algorithm, Hybrid-hash join and Stripe-join. The join is a two-way one-to-one join between two relations of size 2 25 ( 34 million) tuples of width 256 bytes. All tuples participate in the join. The performance of Stripe-join and Jive-join is very similar. <p> As can be seen from the graph, Jive-join and Stripe-join perform close to the lower bound, and significantly better than both Hybrid-hash join and Valduriez's algorithm. 2 For a complete description of Jive-join, and a thorough performance comparison of Jive-join with other algorithms see <ref> [12] </ref>. In no scenarios that we have studied have we found examples where Jive-join significantly outperforms Stripe-join. In cases like Example 5.1, Stripe-join and Jive-join have comparable performance characteristics. <p> In cases like Example 5.1, Stripe-join and Jive-join have comparable performance characteristics. In those cases the comparisons of Jive-join with other techniques apply equally well to Stripe-join, but we do not repeat all of the comparisons from <ref> [12] </ref> here. Instead, we focus on the cases where Stripe-join can significantly improve upon Jive-join. Jive-join and Slam-join are dual algorithms with very similar characteristics. <p> In Jive-join there are two distinct phases: one relation must be completely processed before the other relations can be processed. 7 Conclusions We have proposed a new algorithm, Stripe-join, for performing a join using a join index. Like its predecessor Jive-join from <ref> [12] </ref>, Stripe-join has the following properties: Almost all of the I/O performed is sequential. A block of an input relation is read if and only if it contains a record that participates in the join. Skew does not adversely affect the performance.
Reference: [13] <author> P. Mishra and M. Eich. </author> <title> Join processing in relational databases. </title> <journal> ACM Computing Surveys, </journal> <volume> 24(1), </volume> <month> March </month> <year> 1992. </year>
Reference-contexts: Therefore, it is critical to implement joins in the most efficient way possible. A number of techniques have been developed to perform "ad-hoc" joins, i.e., joins performed without the benefit of additional data structures such as indices <ref> [3, 4, 6, 9, 13, 16] </ref>. In this paper, we consider joins of relations for which there exists a pre-computed access structure, namely a join index [17]. A join index between two relations maintains pairs of identifiers of tuples that would match in case of a join.
Reference: [14] <author> C. Mohan, D. Haderie, Y. Wang, and J. Cheng. </author> <title> Single table access using multiple indexes: optimization, execution and concurrency control techniques. </title> <booktitle> In Proc. International Conference on Extending Data Base Technology, </booktitle> <year> 1990. </year>
Reference-contexts: Thus one could apply selection conditions to the input relations' indexes (which are much smaller than the input relations themselves), combine the lists of resulting tuple-ids (using union for an "or" condition and intersection for an "and" condition <ref> [14] </ref>), and use the result to semijoin the join index [17]. Stripe-join can then be applied to the input relations and the reduced join index.
Reference: [15] <author> P. O'Neill and G. Graefe. </author> <title> Multi-table joins through bitmapped join indices. </title> <booktitle> SIGMOD Record, </booktitle> <volume> 24(3), </volume> <year> 1995. </year>
Reference-contexts: In situations where joins are taken often, the cost of doing this maintenance can be more than offset by the savings achieved in performing the join. A number of commercial decision support systems are rumored to be using join indexes <ref> [15] </ref>. In [17], Valduriez proposed and analyzed a join algorithm that uses the join index. The most important conclusion of that study was that, under many circumstances, having the join index allows one to compute the join significantly faster than the "best" ad-hoc methods such as Hybrid hash-join [6].
Reference: [16] <author> L. Shapiro. </author> <title> Join processing in database systems with large main memories. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 11(3), </volume> <year> 1986. </year>
Reference-contexts: Therefore, it is critical to implement joins in the most efficient way possible. A number of techniques have been developed to perform "ad-hoc" joins, i.e., joins performed without the benefit of additional data structures such as indices <ref> [3, 4, 6, 9, 13, 16] </ref>. In this paper, we consider joins of relations for which there exists a pre-computed access structure, namely a join index [17]. A join index between two relations maintains pairs of identifiers of tuples that would match in case of a join.
Reference: [17] <author> P. Valduriez. </author> <title> Join indices. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 12(2) </volume> <pages> 218-246, </pages> <year> 1987. </year>
Reference-contexts: In this paper, we consider joins of relations for which there exists a pre-computed access structure, namely a join index <ref> [17] </ref>. A join index between two relations maintains pairs of identifiers of tuples that would match in case of a join. The join index may be maintained by the database system, and updated when tuples are inserted and deleted in the underlying relations. <p> In situations where joins are taken often, the cost of doing this maintenance can be more than offset by the savings achieved in performing the join. A number of commercial decision support systems are rumored to be using join indexes [15]. In <ref> [17] </ref>, Valduriez proposed and analyzed a join algorithm that uses the join index. The most important conclusion of that study was that, under many circumstances, having the join index allows one to compute the join significantly faster than the "best" ad-hoc methods such as Hybrid hash-join [6]. <p> Thus one could apply selection conditions to the input relations' indexes (which are much smaller than the input relations themselves), combine the lists of resulting tuple-ids (using union for an "or" condition and intersection for an "and" condition [14]), and use the result to semijoin the join index <ref> [17] </ref>. Stripe-join can then be applied to the input relations and the reduced join index.
Reference: [18] <author> S. B. Yao. </author> <title> Approximating block accesses in database organizations. </title> <journal> Communications of the ACM, </journal> <volume> 20(4) </volume> <pages> 260-261, </pages> <year> 1977. </year>
Reference-contexts: Y (k; d; n) Function to estimate the number of block accesses needed to retrieve k tuples out of n tuples stored in d blocks <ref> [18] </ref>. m Size of main memory, in disk blocks. fi Blocks in an input relation buffer. N S Seeks in an algorithm. N I=O I/O requests in an algorithm. N X Block transfers in an algorithm.
References-found: 18

