URL: http://www.cs.toronto.edu/~greiner/PAPERS/accuracy-ecai.ps
Refering-URL: http://www.cs.toronto.edu/~greiner/PAPERS/
Root-URL: 
Phone: 2  
Title: Learning an Optimally Accurate Representation System  
Author: Russell Greiner and Dale Schuurmans 
Note: 1 ffi, within of a local optimum.  
Address: 755 College Road East, Princeton, NJ 08540-6632  Toronto, Toronto, ON M5S 1A4, Canada  
Affiliation: 1 Siemens Corporate Research,  Dept. of Computer Science, University of  
Abstract: A default theory can sanction different, mutually incompatible, answers to certain queries. We can identify each such theory with a set of related credulous theories, each of which produces but a single response to each query, by imposing a total ordering on the defaults. Our goal is to identify the credulous theory with optimal "expected accuracy" averaged over the natural distribution of queries in the domain. There are two obvious complications: First, the expected accuracy of a theory depends on the query distribution, which is usually not known. Second, the task of identifying the optimal theory, even given that distribution information, is intractable. This paper presents a method, OptAcc, that side-steps these problems by using a set of samples to estimate the unknown distribution, and by hill-climbing to a local optimum. In particular, given any error and confidence parameters *; ffi &gt; 0, OptAcc produces a theory whose expected accuracy is, with probability at least 
Abstract-found: 1
Intro-found: 1
Reference: [AGM85] <author> Carlos E. Alchourron, Peter Gardenfors, and David Makinson. </author> <title> On the logic of theory change: Partial meet contraction and revision functions. </title> <journal> Journal of Symbolic Logic, </journal> <volume> 50 </volume> <pages> 510-30, </pages> <year> 1985. </year>
Reference-contexts: From this perspective, our work is also related to one form of "theory revision", a la <ref> [Gar88, AGM85] </ref> and many others.
Reference: [BD88] <author> Mark Boddy and Thomas Dean. </author> <title> Solving time dependent planning problems. </title> <type> Technical report, </type> <institution> Brown University, </institution> <year> 1988. </year>
Reference-contexts: in 1=*, 1=ffi and jHj. 2 4 Issues and Extensions This section discusses: other algorithms related to OptAcc, ways for OptAcc to accommodate more general Theorist-style representations, efficiency issues, and alternative performance measures and types of transformations. 4.1 Related Algorithms We can view OptAcc as a variant on anytime algorithms <ref> [BD88, DB88] </ref> as, at any time, OptAcc provides a usable result (here, the theory produced at the k th iteration, k ), with the property that later systems are (probably) better than earlier ones; i.e., i &gt; j means C [ i ] &gt; C [ j ] with high probability.
Reference: [BE89] <author> Alex Borgida and David Etherington. </author> <title> Hierarchical knowledge bases and efficient disjunctive reasoning. </title> <booktitle> In Proceedings of KR-89, </booktitle> <pages> pages 33-43, </pages> <address> Toronto, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: Two major distinctions are (i) our work explicitly constrains the set of propositions that can be affected (viz., only hypotheses can be deleted); and (ii) we use an explicit notion of expected accuracy to dictate which of the possible revisions (read "weakenings") to use. (3) The work on "approximation" <ref> [BE89, SK91, DE92, GS92] </ref> also seeks good weakenings. Its goal however is an efficient encoding; by contrast, we are seeking an accurate representation. Finally, the motivation underlying our work is similar to the research in [Sha89] and elsewhere, which also uses probabilistic information to identify the best default theory.
Reference: [BMSJ78] <author> Bruce G. Buchanan, Thomas M. Mitchell, Reid G. Smith, and C. R. John-son, Jr. </author> <title> Models of learning systems. </title> <booktitle> In Encyclopedia of Computer Science and Technology, </booktitle> <volume> volume 11. </volume> <publisher> Dekker, </publisher> <year> 1978. </year>
Reference-contexts: other bodies of research also seek weakened theories (i.e., theories which admit fewer conclusions), albeit in the framework of standard monotonic theories. (1) One branch of explanation-based learning (EBL) research seeks the appropriate "specialization" (read "weakenings") of a given theory [FD89, OM90, Paz88, Coh92]; however, (i) the underlying performance task <ref> [BMSJ78] </ref> for the EBL systems is classification (i.e., determining whether a given element is, or is not, a member of some target class) rather than general derivation; and (ii) each uses negation-as-failure [Cla78] (a hardwired form of non-monotonicity) to classify negatively any sample that cannot be proved to be in the
Reference: [Bol85] <author> B. Bollobas. </author> <title> Random Graphs. </title> <publisher> Academic Press, </publisher> <year> 1985. </year>
Reference-contexts: or 0 2 T [ 0 ]) is h fi fi ^ C [ 0 ] C [ 0 ] fi 4 2e 2L 0 ( * 2 * 2 ln 2 K (1+jT [ 0 ])j * 2 = 2 ffi K (1+jT [ 0 ]j) : 9 See <ref> [Bol85, p. 12] </ref>. N.b., these inequalities hold for arbitrary bounded random vari ables, and thus for ^ C [ 0 ] as 0 c ( 0 ; q i ) 1 8q i 2 Q.
Reference: [Bre89] <author> Gerhard Brewka. </author> <title> Preferred subtheories: An extended logical framework for default reasoning. </title> <booktitle> In Proceedings of IJCAI-89, </booktitle> <pages> pages 1043-48, </pages> <address> Detroit, </address> <month> August </month> <year> 1989. </year>
Reference-contexts: We therefore focus on a credulous theories, here formed by embellishing a standard default theory with an ordering on its defaults <ref> [vA90, Bre89] </ref>, with the understanding that only the most preferred default (s) will be used to reach a unique answer to each query; see Section 2. 3 As a theory that produces the correct response for one query may be incorrect for other queries, it is not obvious which of the <p> optimal; i.e., find R opt 2 R such that 8R 2 R ; C [ R opt ] C [ R ] : 2.2 Prioritized Theorist-Style Representation Systems While much of our analysis applies to representation systems in general, this paper focuses one particular form: stratified Theorist-style representation system [PGA86] <ref> [Bre89, vA90] </ref>. Here, each R i can be expressed as a set of factual information, a set of allowed hypotheses (each a simple type of default) and an 5 We assume Q is at most countably infinite to simplify the presentation, and to avoid measure-theoretic technicalities. ordering of the hypotheses.
Reference: [Cla78] <author> K. Clark. </author> <title> Negation as failure. </title> <editor> In H. Gallaire and J. Minker, editors, </editor> <booktitle> Logic and Data Bases, </booktitle> <pages> pages 293-322. </pages> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1978. </year>
Reference-contexts: appropriate "specialization" (read "weakenings") of a given theory [FD89, OM90, Paz88, Coh92]; however, (i) the underlying performance task [BMSJ78] for the EBL systems is classification (i.e., determining whether a given element is, or is not, a member of some target class) rather than general derivation; and (ii) each uses negation-as-failure <ref> [Cla78] </ref> (a hardwired form of non-monotonicity) to classify negatively any sample that cannot be proved to be in the class.
Reference: [Coh90] <author> William W. Cohen. </author> <title> Learning from textbook knowledge: A case study. </title> <booktitle> In Proceeding of AAAI-90, </booktitle> <year> 1990. </year>
Reference-contexts: A representation system that accepts this N AE (Z 15 ) hypothesis will produce the answer IDK to the query S (Z 15 ; ?y). There are yet other types of transformations, for converting one representation system into another | for instance eliminating some inappropriate sets of hypotheses <ref> [Coh90, Won91] </ref>, or modifying the antecedents of individual rules (cf., [OM90]), etc. Each of these approaches can be viewed as using a set of transformations to navigate around a space of interrelated representation systems.
Reference: [Coh92] <author> William W. Cohen. </author> <title> Abductive explanation-based learning: A solution to the multiple inconsistent explanation problems. </title> <journal> Machine Learning, </journal> <volume> 8(2) </volume> <pages> 167-219, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Many other bodies of research also seek weakened theories (i.e., theories which admit fewer conclusions), albeit in the framework of standard monotonic theories. (1) One branch of explanation-based learning (EBL) research seeks the appropriate "specialization" (read "weakenings") of a given theory <ref> [FD89, OM90, Paz88, Coh92] </ref>; however, (i) the underlying performance task [BMSJ78] for the EBL systems is classification (i.e., determining whether a given element is, or is not, a member of some target class) rather than general derivation; and (ii) each uses negation-as-failure [Cla78] (a hardwired form of non-monotonicity) to classify negatively
Reference: [DB88] <author> Thomas Dean and Mark Boddy. </author> <title> An analysis of time-dependent planning. </title> <booktitle> In Proceedings of AAAI-88, </booktitle> <pages> pages 49-54, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: in 1=*, 1=ffi and jHj. 2 4 Issues and Extensions This section discusses: other algorithms related to OptAcc, ways for OptAcc to accommodate more general Theorist-style representations, efficiency issues, and alternative performance measures and types of transformations. 4.1 Related Algorithms We can view OptAcc as a variant on anytime algorithms <ref> [BD88, DB88] </ref> as, at any time, OptAcc provides a usable result (here, the theory produced at the k th iteration, k ), with the property that later systems are (probably) better than earlier ones; i.e., i &gt; j means C [ i ] &gt; C [ j ] with high probability.
Reference: [DE92] <author> Mukesh Dalal and David Etherington. </author> <title> Tractable approximate deduction using limited vocabulary. </title> <booktitle> In Proceedings of CSCSI-92, </booktitle> <address> Vancouver, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: Two major distinctions are (i) our work explicitly constrains the set of propositions that can be affected (viz., only hypotheses can be deleted); and (ii) we use an explicit notion of expected accuracy to dictate which of the possible revisions (read "weakenings") to use. (3) The work on "approximation" <ref> [BE89, SK91, DE92, GS92] </ref> also seeks good weakenings. Its goal however is an efficient encoding; by contrast, we are seeking an accurate representation. Finally, the motivation underlying our work is similar to the research in [Sha89] and elsewhere, which also uses probabilistic information to identify the best default theory.
Reference: [DP91] <author> Jon Doyle and Ramesh Patil. </author> <title> Two theses of knowledge representation: Language restrictions, taxonomic classification, and the utility of representation services. </title> <journal> Artificial Intelligence, </journal> <volume> 48(3), </volume> <year> 1991. </year>
Reference-contexts: sampling techniques to obtain estimates of the required distribution, and by coping with the computational complexity inherent in this identification process. 2 Framework This section first provides the general framework for our analysis, then describes the class of representation systems we will use. 2.1 General Analytic Framework Following [Lev84] and <ref> [DP91] </ref>, we view a representation system R as a function that maps each query to its proposed answer; hence, R : Q 7! A, where Q is a (possibly infinite) set of queries, and A is the set of possible answers.
Reference: [FD89] <author> N. Flann and T. G. Dietterich. </author> <title> A study of explanation-based methods for inductive learning. </title> <journal> Machine Learning, </journal> <volume> 4, </volume> <year> 1989. </year>
Reference-contexts: Many other bodies of research also seek weakened theories (i.e., theories which admit fewer conclusions), albeit in the framework of standard monotonic theories. (1) One branch of explanation-based learning (EBL) research seeks the appropriate "specialization" (read "weakenings") of a given theory <ref> [FD89, OM90, Paz88, Coh92] </ref>; however, (i) the underlying performance task [BMSJ78] for the EBL systems is classification (i.e., determining whether a given element is, or is not, a member of some target class) rather than general derivation; and (ii) each uses negation-as-failure [Cla78] (a hardwired form of non-monotonicity) to classify negatively
Reference: [Gar88] <author> Peter Gardenfors. </author> <title> Knowledge in Flux: Modeling the Dynamics of the Epis-temic States. </title> <publisher> Bradford Book, MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: From this perspective, our work is also related to one form of "theory revision", a la <ref> [Gar88, AGM85] </ref> and many others.
Reference: [GE91] <author> Russell Greiner and Charles Elkan. </author> <title> Measuring and improving the effectiveness of representations. </title> <booktitle> In Proceedings of IJCAI-91, </booktitle> <pages> pages 518-24, </pages> <address> Sydney, Australia, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: This would allow the user to prefer, for example, a performance system that returns IDK in complex situations, rather than spend a long time returning the correct answer; or even allow it to be wrong in some instances <ref> [GE91] </ref>. Of course, the OptAcc-variant may have to consider other transformations, besides the simple "reordering the hypotheses" one discussed above.
Reference: [GJ92] <author> Russell Greiner and Igor Jurisica. </author> <title> A statistical approach to solving the EBL utility problem. </title> <booktitle> In Proceedings of AAAI-92, </booktitle> <address> San Jose, </address> <year> 1992. </year>
Reference-contexts: There can, in some situations, be more efficient ways of estimating these values, for example, by using some Horn approximation to F [ fh i g; see [Gre92a] and <ref> [GJ92] </ref>.
Reference: [GO91] <author> Russell Greiner and Pekka Orponen. </author> <title> Probably approximately optimal derivation strategies. </title> <editor> In J.A. Allen, R. Fikes, and E. Sandewall, editors, </editor> <booktitle> Proceedings of KR-91, </booktitle> <address> San Mateo, CA, April 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In some simple cases, we may be able to identify (an approximation to) the globally optimal element with high probability (a la the pao algorithm discussed in <ref> [OG90, GO91] </ref>). In most cases, however, this identification task is intractable.
Reference: [Gre92a] <author> Russell Greiner. </author> <title> Learning near optimal horn approximations. </title> <booktitle> In Proceedings of Knowledge Assimilation Symposium, </booktitle> <address> Stanford, </address> <month> March </month> <year> 1992. </year>
Reference-contexts: There can, in some situations, be more efficient ways of estimating these values, for example, by using some Horn approximation to F [ fh i g; see <ref> [Gre92a] </ref> and [GJ92].
Reference: [Gre92b] <author> Russell Greiner. </author> <title> Probabilistic hill-climbing: Theory and applications. </title> <booktitle> In Proceedings of CSCSI-92, </booktitle> <address> Vancouver, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: OptAcc works in a "batched incremental" mode, as it iteratively uses a set of samples to decide whether to climb to a new theory, or to terminate. There is also a strictly-incremental variant of this algorithm <ref> [Gre92b] </ref>, which observes samples one-by-one, and decides after each individual sample, whether to climb, terminate, or simply draw an additional sample; hence this variant can, in some situations, climb to better theories after fewer samples. 8 Here, as in Figure 1, "C [ ff ]" refers to "C [ hF ;
Reference: [Gre93] <author> Russell Greiner. </author> <title> The complexity of computing optimally-accurate default theories. </title> <type> Technical report, </type> <institution> Siemens Corporate Research, </institution> <year> 1993. </year>
Reference-contexts: Even if we knew this distribution, the task of identifying the optimal hypothesis ordering is NP-complete. This holds even for the simplistic situation we have been considering, where every derivation requires exactly one hypoth esis, every ordering of hypotheses is allowed, and so forth; see <ref> [Gre93] </ref>. 3 The OptAcc Algorithm This section presents a learning system, OptAcc, that side-steps the two problems mentioned above.
Reference: [Gro91] <author> Benjamin Grosof. </author> <title> Generalizing prioritization. </title> <booktitle> In Proceedings of KR-91, </booktitle> <pages> pages 289-300, </pages> <address> Boston, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: In some contexts, there may already be a meaningful partial ordering of the hypotheses, perhaps based on specificity or some other criteria <ref> [Gro91] </ref>. Here, we can still use OptAcc to complete the partial ordering, by determining the relative priorities of the initially incomparable elements. In some situations, we may be unable to answer certain queries without adding in several new assertions.
Reference: [GS92] <author> Russell Greiner and Dale Schuurmans. </author> <title> Learning useful horn approximations. </title> <editor> In B. Nebel, C. Rich, and W. Swartout, editors, </editor> <booktitle> Proceedings of KR-92, </booktitle> <address> San Mateo, CA, October 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Two major distinctions are (i) our work explicitly constrains the set of propositions that can be affected (viz., only hypotheses can be deleted); and (ii) we use an explicit notion of expected accuracy to dictate which of the possible revisions (read "weakenings") to use. (3) The work on "approximation" <ref> [BE89, SK91, DE92, GS92] </ref> also seeks good weakenings. Its goal however is an efficient encoding; by contrast, we are seeking an accurate representation. Finally, the motivation underlying our work is similar to the research in [Sha89] and elsewhere, which also uses probabilistic information to identify the best default theory.
Reference: [Hau88] <author> David Haussler. </author> <title> Quantifying inductive bias: AI learning algorithms and Valiant's learning framework. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> pages 177-221, </pages> <year> 1988. </year>
Reference-contexts: In each, it has produced a great deal of attention and debate; cf., [Rei87, Mor87] <ref> [Mit80, RG87, Hau88] </ref>, [Kyb82, Lou88]. In general, an effective representation system will return a single (and we hope, correct) answer to each query, rather than remain silent or propose a set of incompatible answers.
Reference: [Hin89] <author> Geoff Hinton. </author> <title> Connectionist learning procedures. </title> <journal> Artificial Intelligence, </journal> <volume> 40(1-3):185-234, </volume> <month> September </month> <year> 1989. </year>
Reference-contexts: We close this section by describing other research that is related to our work. Related Research: Our underlying task, of producing a theory that is as correct as possible, is the sine qua non of essentially all research on inductive learning; cf., <ref> [MCM83, HV88, Hin89] </ref>.
Reference: [HV88] <author> David Haussler and Leslie Valiant, </author> <title> editors. </title> <booktitle> Proceedings of the First Workshop on Computational Learning Theory. </booktitle> <publisher> Morgan Kaufmann, MIT, </publisher> <year> 1988. </year>
Reference-contexts: We close this section by describing other research that is related to our work. Related Research: Our underlying task, of producing a theory that is as correct as possible, is the sine qua non of essentially all research on inductive learning; cf., <ref> [MCM83, HV88, Hin89] </ref>.
Reference: [Kyb82] <author> H. Kyburg. </author> <title> The reference class. </title> <journal> Philosophy of Science, </journal> <volume> 50, </volume> <year> 1982. </year>
Reference-contexts: In each, it has produced a great deal of attention and debate; cf., [Rei87, Mor87] [Mit80, RG87, Hau88], <ref> [Kyb82, Lou88] </ref>. In general, an effective representation system will return a single (and we hope, correct) answer to each query, rather than remain silent or propose a set of incompatible answers.
Reference: [Lev84] <author> Hector J. Levesque. </author> <title> Foundations of a functional approach to knowledge representation. </title> <journal> Artificial Intelligence, </journal> <volume> 23 </volume> <pages> 155-212, </pages> <year> 1984. </year>
Reference-contexts: using statistical sampling techniques to obtain estimates of the required distribution, and by coping with the computational complexity inherent in this identification process. 2 Framework This section first provides the general framework for our analysis, then describes the class of representation systems we will use. 2.1 General Analytic Framework Following <ref> [Lev84] </ref> and [DP91], we view a representation system R as a function that maps each query to its proposed answer; hence, R : Q 7! A, where Q is a (possibly infinite) set of queries, and A is the set of possible answers.
Reference: [Lou88] <author> R. Loui. </author> <title> Computing reference classes. </title> <booktitle> In AAAI Workshop on Uncertainty. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> St Paul, </address> <year> 1988. </year>
Reference-contexts: In each, it has produced a great deal of attention and debate; cf., [Rei87, Mor87] [Mit80, RG87, Hau88], <ref> [Kyb82, Lou88] </ref>. In general, an effective representation system will return a single (and we hope, correct) answer to each query, rather than remain silent or propose a set of incompatible answers.
Reference: [MB88] <author> S. Muggleton and W. Buntine. </author> <title> Machine invention of first order predicates by inverting resolution. </title> <booktitle> In Proceedings of IML-88, </booktitle> <pages> pages 339-51. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: While many of these systems learn descriptions based on bit vectors or simple hierarchies, our work deals in the context of propositions; here too there is a history of results, dating back (at least) to Shapiro [Sha83], and including foil [Qui90] and the body of work on inductive logic programming <ref> [MB88] </ref>.
Reference: [MCM83] <author> Ryszard S. Michalski, Jaime G. Carbonell, and Thomas M. Mitchell, </author> <title> editors. Machine Learning: An Artificial Intelligence Approach. </title> <publisher> Tioga Publishing Company, </publisher> <address> Palo Alto, CA, </address> <year> 1983. </year>
Reference-contexts: We close this section by describing other research that is related to our work. Related Research: Our underlying task, of producing a theory that is as correct as possible, is the sine qua non of essentially all research on inductive learning; cf., <ref> [MCM83, HV88, Hin89] </ref>.
Reference: [Mit80] <author> Thomas M. Mitchell. </author> <title> The need for bias in learning generalizations. </title> <type> Technical Report CBM-TR-117, </type> <institution> Laboratory for Computer Science Research, </institution> <month> May </month> <year> 1980. </year>
Reference-contexts: In each, it has produced a great deal of attention and debate; cf., [Rei87, Mor87] <ref> [Mit80, RG87, Hau88] </ref>, [Kyb82, Lou88]. In general, an effective representation system will return a single (and we hope, correct) answer to each query, rather than remain silent or propose a set of incompatible answers.
Reference: [Mor87] <author> Paul Morris. </author> <title> Curing anomalous extensions. </title> <booktitle> In Proceedings of AAAI-87, </booktitle> <pages> pages 437-42, </pages> <address> Seattle, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: In each, it has produced a great deal of attention and debate; cf., <ref> [Rei87, Mor87] </ref> [Mit80, RG87, Hau88], [Kyb82, Lou88]. In general, an effective representation system will return a single (and we hope, correct) answer to each query, rather than remain silent or propose a set of incompatible answers.
Reference: [OG90] <author> Pekka Orponen and Russell Greiner. </author> <title> On the sample complexity of finding good search strategies. </title> <booktitle> In Proceedings of COLT-90, </booktitle> <pages> pages 352-58, </pages> <address> Rochester, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: In some simple cases, we may be able to identify (an approximation to) the globally optimal element with high probability (a la the pao algorithm discussed in <ref> [OG90, GO91] </ref>). In most cases, however, this identification task is intractable.
Reference: [OM90] <author> Dirk Ourston and Raymond J. Mooney. </author> <title> Changing the rules: A comprehensive approach to theory refinement. </title> <booktitle> In Proceedings of AAAI-90, </booktitle> <pages> pages 815-20, </pages> <year> 1990. </year>
Reference-contexts: Many other bodies of research also seek weakened theories (i.e., theories which admit fewer conclusions), albeit in the framework of standard monotonic theories. (1) One branch of explanation-based learning (EBL) research seeks the appropriate "specialization" (read "weakenings") of a given theory <ref> [FD89, OM90, Paz88, Coh92] </ref>; however, (i) the underlying performance task [BMSJ78] for the EBL systems is classification (i.e., determining whether a given element is, or is not, a member of some target class) rather than general derivation; and (ii) each uses negation-as-failure [Cla78] (a hardwired form of non-monotonicity) to classify negatively <p> There are yet other types of transformations, for converting one representation system into another | for instance eliminating some inappropriate sets of hypotheses [Coh90, Won91], or modifying the antecedents of individual rules (cf., <ref> [OM90] </ref>), etc. Each of these approaches can be viewed as using a set of transformations to navigate around a space of interrelated representation systems. We can then consider the same objective described above: to identify which element has the highest expected accuracy (or in general, "highest expected utility").
Reference: [Paz88] <author> M. Pazzani. </author> <title> Selecting the best explanation in explanation-based learning. </title> <booktitle> In Proceedings of Symposium on Explanation-Based Learning, </booktitle> <address> Stanford, </address> <month> March </month> <year> 1988. </year>
Reference-contexts: Many other bodies of research also seek weakened theories (i.e., theories which admit fewer conclusions), albeit in the framework of standard monotonic theories. (1) One branch of explanation-based learning (EBL) research seeks the appropriate "specialization" (read "weakenings") of a given theory <ref> [FD89, OM90, Paz88, Coh92] </ref>; however, (i) the underlying performance task [BMSJ78] for the EBL systems is classification (i.e., determining whether a given element is, or is not, a member of some target class) rather than general derivation; and (ii) each uses negation-as-failure [Cla78] (a hardwired form of non-monotonicity) to classify negatively
Reference: [PGA86] <author> David Poole, Randy Goebel, and Romas Aleliunas. </author> <title> Theorist: A logical reasoning system for default and diagnosis. Technical Report CS-86-06, </title> <booktitle> Logic Programming and Artificial Intelligence Group, </booktitle> <institution> Faculty of Mathematics, University of Waterloo, </institution> <month> February </month> <year> 1986. </year>
Reference-contexts: is optimal; i.e., find R opt 2 R such that 8R 2 R ; C [ R opt ] C [ R ] : 2.2 Prioritized Theorist-Style Representation Systems While much of our analysis applies to representation systems in general, this paper focuses one particular form: stratified Theorist-style representation system <ref> [PGA86] </ref> [Bre89, vA90].
Reference: [Qui90] <author> J. Ross Quinlan. </author> <title> Learning logical definitions from relations. </title> <journal> Machine Learning Journal, </journal> <volume> 5(3) </volume> <pages> 239-66, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: While many of these systems learn descriptions based on bit vectors or simple hierarchies, our work deals in the context of propositions; here too there is a history of results, dating back (at least) to Shapiro [Sha83], and including foil <ref> [Qui90] </ref> and the body of work on inductive logic programming [MB88].
Reference: [Rei87] <author> Raymond Reiter. </author> <title> Nonmonotonic reasoning. </title> <booktitle> In Annual Review of Computing Sciences, </booktitle> <volume> volume 2, </volume> <pages> pages 147-87. </pages> <publisher> Annual Reviews Incorporated, </publisher> <address> Palo Alto, </address> <year> 1987. </year>
Reference-contexts: this body of accepted information is insufficient to entail an answer to some queries, many of these systems will consider augmenting this initial information with some new hypothesis (or conjecture or default) that is plausible but not necessarily true; each particular collection of facts and hypotheses is a "default theory" <ref> [Rei87] </ref>. Unfortunately, there can often be more than one such hypothesis, and these hypotheses (and hence the conclusions they respectively entail) may not be compatible; consider for example the Nixon diamond [Rei87, p155]: By default, Quakers tend to be pacifists, while Republicans tend to be non-pacifists. <p> Unfortunately, there can often be more than one such hypothesis, and these hypotheses (and hence the conclusions they respectively entail) may not be compatible; consider for example the Nixon diamond <ref> [Rei87, p155] </ref>: By default, Quakers tend to be pacifists, while Republicans tend to be non-pacifists. <p> In each, it has produced a great deal of attention and debate; cf., <ref> [Rei87, Mor87] </ref> [Mit80, RG87, Hau88], [Kyb82, Lou88]. In general, an effective representation system will return a single (and we hope, correct) answer to each query, rather than remain silent or propose a set of incompatible answers.
Reference: [RG87] <author> Stuart J. Russell and Benjamin N. Grosof. </author> <title> A declarative approach to bias in concept learning. </title> <booktitle> In Proceedings of AAAI-87, </booktitle> <pages> pages 505-10, </pages> <address> Seattle, WA, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: In each, it has produced a great deal of attention and debate; cf., [Rei87, Mor87] <ref> [Mit80, RG87, Hau88] </ref>, [Kyb82, Lou88]. In general, an effective representation system will return a single (and we hope, correct) answer to each query, rather than remain silent or propose a set of incompatible answers.
Reference: [Sha83] <author> Ehud Shapiro. </author> <title> Algorithmic Program Debugging. </title> <publisher> MIT Press, </publisher> <year> 1983. </year>
Reference-contexts: While many of these systems learn descriptions based on bit vectors or simple hierarchies, our work deals in the context of propositions; here too there is a history of results, dating back (at least) to Shapiro <ref> [Sha83] </ref>, and including foil [Qui90] and the body of work on inductive logic programming [MB88].
Reference: [Sha89] <author> Lokendra Shastri. </author> <title> Default reasoning in semantic networks: A formalization of recognition and inheritance. </title> <journal> Artificial Intelligence, </journal> <volume> 39 </volume> <pages> 283-355, </pages> <year> 1989. </year>
Reference-contexts: Its goal however is an efficient encoding; by contrast, we are seeking an accurate representation. Finally, the motivation underlying our work is similar to the research in <ref> [Sha89] </ref> and elsewhere, which also uses probabilistic information to identify the best default theory.
Reference: [SK91] <author> Bart Selman and Henry Kautz. </author> <title> Knowledge compilation using horn approximations. </title> <booktitle> In Proceedings of AAAI-91, </booktitle> <pages> pages 904-09, </pages> <address> Anaheim, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: Two major distinctions are (i) our work explicitly constrains the set of propositions that can be affected (viz., only hypotheses can be deleted); and (ii) we use an explicit notion of expected accuracy to dictate which of the possible revisions (read "weakenings") to use. (3) The work on "approximation" <ref> [BE89, SK91, DE92, GS92] </ref> also seeks good weakenings. Its goal however is an efficient encoding; by contrast, we are seeking an accurate representation. Finally, the motivation underlying our work is similar to the research in [Sha89] and elsewhere, which also uses probabilistic information to identify the best default theory.
Reference: [vA90] <author> Paul van Arragon. </author> <title> Nested default reasoning with priority levels. </title> <booktitle> In Proceedings of CSCSI-90, </booktitle> <pages> pages 77-83, </pages> <address> Ottawa, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: We therefore focus on a credulous theories, here formed by embellishing a standard default theory with an ordering on its defaults <ref> [vA90, Bre89] </ref>, with the understanding that only the most preferred default (s) will be used to reach a unique answer to each query; see Section 2. 3 As a theory that produces the correct response for one query may be incorrect for other queries, it is not obvious which of the <p> optimal; i.e., find R opt 2 R such that 8R 2 R ; C [ R opt ] C [ R ] : 2.2 Prioritized Theorist-Style Representation Systems While much of our analysis applies to representation systems in general, this paper focuses one particular form: stratified Theorist-style representation system [PGA86] <ref> [Bre89, vA90] </ref>. Here, each R i can be expressed as a set of factual information, a set of allowed hypotheses (each a simple type of default) and an 5 We assume Q is at most countably infinite to simplify the presentation, and to avoid measure-theoretic technicalities. ordering of the hypotheses.
Reference: [Vor91] <author> David Vormittag. </author> <title> Evaluating answers to questions, </title> <month> May </month> <year> 1991. </year> <type> Bachelors Thesis, </type> <institution> University of Toronto. </institution>
Reference-contexts: As another situation, we may be able to rank responses in terms of their precision: e.g., knowing that the cost of watch 7 is $3;000 is more precise than knowing only that watch 7 is expensive <ref> [Vor91] </ref>.) We have also assumed that all queries are equally important; i.e., a wrong answer to any query "costs" us the same 0, whether we are asking for the location of a salt-shaker, or of the tiger currently stalking us.
Reference: [Won91] <author> Jonathan Wong. </author> <title> Improving the accuracy of a representational system, </title> <month> May </month> <year> 1991. </year> <title> Bachelors Thesis, University of Toronto. This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: A representation system that accepts this N AE (Z 15 ) hypothesis will produce the answer IDK to the query S (Z 15 ; ?y). There are yet other types of transformations, for converting one representation system into another | for instance eliminating some inappropriate sets of hypotheses <ref> [Coh90, Won91] </ref>, or modifying the antecedents of individual rules (cf., [OM90]), etc. Each of these approaches can be viewed as using a set of transformations to navigate around a space of interrelated representation systems.
References-found: 45

