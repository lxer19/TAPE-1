URL: ftp://ftp.cs.yale.edu/pub/mcdermott/papers/unpop-aij.ps.gz
Refering-URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/mcdermott.html
Root-URL: http://www.cs.yale.edu
Email: mcdermott-drew@yale.edu  
Title: Using Regression-Match Graphs to Control Search in Planning  
Author: Drew McDermott 
Date: May 16, 1997  
Affiliation: Department of Computer Science Yale University  
Abstract: Classical planning is the problem of finding a sequence of actions to achieve a goal given an exact characterization of a domain. An algorithm to solve this problem is presented, which searches a space of plan prefixes, trying to extend one of them to a complete sequence of actions. It is guided by a heuristic estimator based on regression-match graphs, which attempt to characterize the entire subgoal structure of the remaining part of the problem. These graphs simplify the structure by neglecting goal interactions and by assuming that variables in goal conjunctions should be bound in such a way as to make as many conjuncts as possible true without further work. In some domains, these approximations work very well, and experiments show many classical-planning problems can be solved with very little search.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Anthony Barrett and Daniel S. Weld. </author> <title> Partial-order planning: evaluating possible efficiency gains. </title> <booktitle> Artificial Intelligence , 67(1) </booktitle> <pages> 71-112, </pages> <year> 1994. </year>
Reference-contexts: Section 3.3 are eliminated. 6 Results Unpop has been run on a wide variety of planning problems, including the Blocks World, the Grid World described in Section 1, a corpus of problems from the University of Washington, the "Rocket" problem of [3], the "Sokoban" domain, and the artificial domains of <ref> [1] </ref>. On some of these it exhibits exponential behavior, but on many of them its behavior is polynomial, especially when you measure the number of plans (search states) tried. In this section I will summarize these results. <p> This phenomenon is, after all, what makes this such a popular PC puzzle. I believe any planner would find this kind of problem difficult. 6.5 Artificial Domains I tested Unpop on most of the problem domains described in <ref> [1] </ref>. The performance is shown in Figures 9 through 14. These data were produced by averaging the results for five random problems of each size. None of these domains used 42 variables in any nontrivial way, so there was always exactly one maximal match for every goal conjunction. In [1], the <p> in <ref> [1] </ref>. The performance is shown in Figures 9 through 14. These data were produced by averaging the results for five random problems of each size. None of these domains used 42 variables in any nontrivial way, so there was always exactly one maximal match for every goal conjunction. In [1], the total-order planners usually do very poorly on these problems, becoming exponential for all but the simplest classes. Unpop does fairly well. It exhibits exponential behavior only on the most difficult ones, D m S 2 fl and fi 2 D 0 S 1 . <p> Unpop does fairly well. It exhibits exponential behavior only on the most difficult ones, D m S 2 fl and fi 2 D 0 S 1 . The reason for the difference is that none of the planners in <ref> [1] </ref> had very interesting heuristic estimators. Given such an estimator, performance improves dramatically. In the simplest domain, D 0 S 1 (Figure 9), Unpop does no search at all.
Reference: [2] <author> Avrim L. Blum and Merrick L. Furst. </author> <title> Fast planning through planning graph analysis. </title> <booktitle> In Proc. Ijcai, </booktitle> <year> 1995. </year>
Reference-contexts: Some recent algorithms succeed by searching nontraditional spaces <ref> [2, 18] </ref>. In this paper, the focus is on improving the performance of classical-planning algorithms by finding improved heuristic estimators for controlling search in a traditional space. <p> What these papers have in common is that they model plans as collections of goals and subgoals. Alternative goals and subgoals are reached only by switching to another part of the search space (i.e., backtracking). More recent algorithms have begun to represent explicit alternatives the way Unpop does. See <ref> [14, 16, 2, 3] </ref>. However, all of these previous works omit the idea of matching as a way of zeroing in on relevant actions. On the plus side, they do a better job than Unpop in reasoning about destructive interactions among subplans. <p> On the plus side, they do a better job than Unpop in reasoning about destructive interactions among subplans. Bernhard Nebel reports (in a personal communication) that the Graphplan algorithm of <ref> [2, 3] </ref> solves grid-world problems faster than Unpop does. 43 Times are in tenths of a second 44 Times are in tenths of a second 45 Times are in tenths of a second 46 Times are in tenths of a second 47 Times are in tenths of a second 48 Times
Reference: [3] <author> Avrim L. Blum and Merrick L. Furst. </author> <title> Fast planning through planning graph analysis. </title> <journal> Artificial Intelligence 1-2, </journal> <volume> 90 </volume> <pages> 279-298, </pages> <year> 1997. </year>
Reference-contexts: The problem is that classical techniques have not been concerned with the OR branches represented by alternative reductions and matches. But many recent algorithms have already begun to address that issue <ref> [3, 14] </ref>. 28 Another source of inaccuracy in effort estimates is the failure to count mul-tiple occurrences of subgraphs properly. Consider a domain in which a robot is able to carry two objects, and it has to go a long distance to reach them. <p> how the absurd matches described at the end of Section 3.3 are eliminated. 6 Results Unpop has been run on a wide variety of planning problems, including the Blocks World, the Grid World described in Section 1, a corpus of problems from the University of Washington, the "Rocket" problem of <ref> [3] </ref>, the "Sokoban" domain, and the artificial domains of [1]. On some of these it exhibits exponential behavior, but on many of them its behavior is polynomial, especially when you measure the number of plans (search states) tried. In this section I will summarize these results. <p> In limited-discrepancy mode, it can't recover from a deletion except by trying all possible extensions of the bad plan before giving up. In this case, the estimated effort is actually a better global estimate than a local one. 6.3 The Rocket Problem This problem, drawn from <ref> [3] </ref>, is very hard for Unpop. You are given two rockets and N cargo objects, all in London. Any amount of cargo can be loaded onto a rocket, but the rocket can be flown only once. <p> What these papers have in common is that they model plans as collections of goals and subgoals. Alternative goals and subgoals are reached only by switching to another part of the search space (i.e., backtracking). More recent algorithms have begun to represent explicit alternatives the way Unpop does. See <ref> [14, 16, 2, 3] </ref>. However, all of these previous works omit the idea of matching as a way of zeroing in on relevant actions. On the plus side, they do a better job than Unpop in reasoning about destructive interactions among subplans. <p> On the plus side, they do a better job than Unpop in reasoning about destructive interactions among subplans. Bernhard Nebel reports (in a personal communication) that the Graphplan algorithm of <ref> [2, 3] </ref> solves grid-world problems faster than Unpop does. 43 Times are in tenths of a second 44 Times are in tenths of a second 45 Times are in tenths of a second 46 Times are in tenths of a second 47 Times are in tenths of a second 48 Times
Reference: [4] <author> Eugene Charniak and Drew McDermott. </author> <title> Introduction to Artificial Intelligence. </title> <publisher> Addison-Wesley, </publisher> <year> 1985. </year>
Reference-contexts: The idea of cashing out all matching operations to generate a graph structure linking top-level goals to feasible actions first appeared in <ref> [4] </ref>, Section 5.7, where the phrase "operator-difference tree" was used for what I now call the "regression-match graph." However, I did not at the time appreciate the need for clear definition of the match layers of the graph.
Reference: [5] <author> Eugene Charniak, Christopher Riesbeck, Drew McDermott, and James Meehan. </author> <booktitle> Artificial Intelligence Programming. </booktitle> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1987. </year> <note> second edition. </note>
Reference-contexts: This table does not depend on the particular problem being solved, so it is saved from run to run. The "indexes" in the list, and the action-difference table, are implemented as discrimination trees on symbolic expressions <ref> [5, 23] </ref>. Each node discriminates 30 on a particular position in the expression (CAR, CADR, etc.) and partitions the expressions it is storing into buckets depending on whatever content it finds at that position. When a bucket gets to be too large, it is further discriminated.
Reference: [6] <author> Ken Currie and Austin Tate. O-plan: </author> <title> the open planning architecture. </title> <booktitle> Artificial Intelligence , 52(1) </booktitle> <pages> 49-86, </pages> <year> 1991. </year>
Reference-contexts: However, there is hope that for some kinds of problems there are algorithms that 1 Most applications of "practical planning" algorithms such as Sipe [31] and O-plan <ref> [6] </ref> have made good use of the plan-management capacities of these systems, but not much use of their plan-search capacities. 1 do well enough in spite of the intractability. Some recent algorithms succeed by searching nontraditional spaces [2, 18].
Reference: [7] <author> George W. Ernst and Allen Newell. </author> <title> GPS: A Case Study in Generality and Problem Solving. </title> <publisher> Academic Press, </publisher> <year> 1969. </year>
Reference-contexts: The alternative search space I describe is much closer to the space searched by the Prodigy planner [29, 28], in that it is based on means-ends analysis, a classic search technique first embodied in the GPS system <ref> [21, 7] </ref>. The principal difference is that Prodigy, like GPS and Strips [10], uses as a search state an ordered pair containing a plan prefix and a goal structure. <p> Hence the last data point in the two upper curves of that graph should be taken with a grain of salt. 7 Relation to Previous Work The present work derives from an attempt to simplify the GPS control structure, which, as described by <ref> [7] </ref>, is rather arcane and complex.
Reference: [8] <author> Kutluhan Erol, Dana Nau, </author> <title> and V.S. Subrahmanian. Complexity, decidabil-ity and undecidability results for domain-independent planning. </title> <editor> In Drew McDermott and James Hendler, </editor> <title> editors, </title> <journal> Artificial Intelligence 76, Special Issue on Planning and Scheduling, </journal> <pages> pages 75-88. NIL, </pages> <year> 1995. </year>
Reference-contexts: However, none of them have been applied in practical domains. 1 The main reason is that all interesting classes of classical-planning problems are intractable <ref> [8] </ref>, and therefore all planning algorithms must resort to search.
Reference: [9] <author> Richard Fikes, Peter E. Hart, and Nils J. Nilsson. </author> <title> Learning and executing generalized robot plans. </title> <booktitle> Artificial Intelligence , 3(4) </booktitle> <pages> 349-371, </pages> <year> 1972. </year> <month> 54 </month>
Reference-contexts: In best-first mode it considers even more possibilities. The "Strips" problem involves a robot pushing boxes from room to room, as the Shakey robot <ref> [9] </ref> did.
Reference: [10] <author> Richard Fikes and Nils J. Nilsson. </author> <title> Strips: A new approach to the applica-tion of theorem proving to problem solving. </title> <booktitle> Artificial Intelligence 2, </booktitle> <pages> pages 189-208, </pages> <year> 1971. </year>
Reference-contexts: I will assume that world states (henceforth called situations) are described as collections of propositions, and that actions are described using a variant of the University of Washington notation [30], which is based on Pednault's Action Description Language [25]. These notations have a flavor like the Strips notation <ref> [10] </ref>, and share its essential weakness, which is that it is good with propositions and bad with numbers and geometry. Tables 1 and 2 show the definitions for a typical domain. Actions are described as predicate-calculus functional terms whose arguments are variables, prefixed by question marks. <p> The alternative search space I describe is much closer to the space searched by the Prodigy planner [29, 28], in that it is based on means-ends analysis, a classic search technique first embodied in the GPS system [21, 7]. The principal difference is that Prodigy, like GPS and Strips <ref> [10] </ref>, uses as a search state an ordered pair containing a plan prefix and a goal structure. There are two sorts of operators: those that add steps to the prefix, and those that commit to a particular operator for achieving an outstanding goal. <p> The planner knows exactly which actions achieve which goals, because every action has a well defined list of literals that it adds. This is the basic idea of means-ends analysis, and in this form was first developed by the Strips group <ref> [10] </ref>. The problem, of course, is that an action that achieves G m+1 may not be feasible in the current situation. In Figure 1, action A achieves the goal conjunct, but has preconditions that are not all true.
Reference: [11] <author> Eugene Fink and Manuela Veloso. </author> <title> Prodigy planning algorithm. </title> <type> Technical Report 94-123, </type> <institution> CMU School of Computer Science, </institution> <year> 1994. </year>
Reference-contexts: The most recent planning work that is related to the Unpop algorithm is the Prodigy planner of Carbonell and Veloso <ref> [29, 11] </ref>, and especially its incarnation as the "FLECS" commitment strategy.[28]. Kambhampati [15] introduced a similar framework in the context of partial-order planning. What these papers have in common is that they model plans as collections of goals and subgoals.
Reference: [12] <author> Alfonso Gerevini and Lenhart K. Schubert. </author> <title> Accelerating partial-order planners: some techniques for effective search control and pruning. </title> <editor> J. </editor> <booktitle> of Art. Intell. </booktitle> <volume> Res , 5 </volume> <pages> 95-137, </pages> <year> 1996. </year>
Reference-contexts: Most of the recent work in this area has been in a quite different paradigm, using search states that consist of networks of partially ordered steps. Search control in this paradigm consists mainly of deciding using local criteria which "flaw" in the current partial plan to fix <ref> [12] </ref>. There has been practically no work on heuristic estimators for comparing potential plans. As a consequence, these planners often search through thousands of plans to solve seemingly simple problems.
Reference: [13] <author> William D. Harvey and Matthew L. Ginsberg. </author> <title> Limited discrepancy search. </title> <booktitle> In Proc. Ijcai95, </booktitle> <pages> pages 607-613, </pages> <year> 1995. </year>
Reference-contexts: The problem is especially severe if short prefixes look too good. Then a best-first search tends to degenerate into a breadth-first search. We can sometimes avoid some of these problems by the use of limited-discrepancy search <ref> [13] </ref> We define the discrepancy of a branch in a search space with respect to a heuristic to be the number of times the branch departs from what the heuristic recommends.
Reference: [14] <author> David Joslin and Martha Pollack. </author> <title> Passive and active decision postponement in plan generation. </title> <booktitle> In Proc. 3rd European Workshop on Planning, </booktitle> <year> 1995. </year>
Reference-contexts: The problem is that classical techniques have not been concerned with the OR branches represented by alternative reductions and matches. But many recent algorithms have already begun to address that issue <ref> [3, 14] </ref>. 28 Another source of inaccuracy in effort estimates is the failure to count mul-tiple occurrences of subgraphs properly. Consider a domain in which a robot is able to carry two objects, and it has to go a long distance to reach them. <p> What these papers have in common is that they model plans as collections of goals and subgoals. Alternative goals and subgoals are reached only by switching to another part of the search space (i.e., backtracking). More recent algorithms have begun to represent explicit alternatives the way Unpop does. See <ref> [14, 16, 2, 3] </ref>. However, all of these previous works omit the idea of matching as a way of zeroing in on relevant actions. On the plus side, they do a better job than Unpop in reasoning about destructive interactions among subplans.
Reference: [15] <author> Subbarao Kambhampati. </author> <title> Universal classical planner: an algorithm for unifying state-space and plan-space planning. </title> <booktitle> In Proc. </booktitle> <address> AAAI-95, </address> <year> 1995. </year>
Reference-contexts: The most recent planning work that is related to the Unpop algorithm is the Prodigy planner of Carbonell and Veloso [29, 11], and especially its incarnation as the "FLECS" commitment strategy.[28]. Kambhampati <ref> [15] </ref> introduced a similar framework in the context of partial-order planning. What these papers have in common is that they model plans as collections of goals and subgoals. Alternative goals and subgoals are reached only by switching to another part of the search space (i.e., backtracking).
Reference: [16] <author> Subbarao Kambhampati. </author> <title> On the role of disjunctive representations and constraint propagation in refinement planning. </title> <booktitle> In Proc. Conf. on Knowledge Representation and Reasoning, </booktitle> <year> 1996. </year>
Reference-contexts: What these papers have in common is that they model plans as collections of goals and subgoals. Alternative goals and subgoals are reached only by switching to another part of the search space (i.e., backtracking). More recent algorithms have begun to represent explicit alternatives the way Unpop does. See <ref> [14, 16, 2, 3] </ref>. However, all of these previous works omit the idea of matching as a way of zeroing in on relevant actions. On the plus side, they do a better job than Unpop in reasoning about destructive interactions among subplans.
Reference: [17] <author> Subbarao Kambhampati, Craig A. Knoblock, and Qiang Yang. </author> <title> Planning as refinement search: a unified framework for evaluating design tradeoffs in partial-order planning. </title> <editor> In Drew McDermott and James Hendler, </editor> <title> editors, </title> <journal> Artificial Intelligence 76, Special Issue on Planning and Scheduling, </journal> <pages> pages 167-238. NIL, </pages> <year> 1995. </year>
Reference-contexts: Gi is a sequence hA 1 ; : : : ; A n i of variable-free action terms, such that in the situation resulting from executing the sequence starting in I, some instance of G is true. 2 Means-Ends Analysis The dominant framework for solving planning problems is refinement search <ref> [17] </ref>. A refinement search goes on in a space of potential plans. A potential plan is a partial sketch of a plan, which can be filled out by applying various planning operators. Different planners use different notions of potential plan, and different operators for transforming one potential plan into another. <p> The search stops when a potential plan is found all of whose completions are solutions to the problem <ref> [17] </ref>. In this paper, I will be discussing a very simple search space for classical planning. Potential plans are just plan prefixes, that is, sequences of actions that the planner is trying to extend to a solution plan.
Reference: [18] <author> Henry A. Kautz, David McAllester, and Bart Selman. </author> <title> Encoding Plans in Propositional Logic. </title> <booktitle> In Proc. </booktitle> <address> KR-96, </address> <year> 1996. </year>
Reference-contexts: Some recent algorithms succeed by searching nontraditional spaces <ref> [2, 18] </ref>. In this paper, the focus is on improving the performance of classical-planning algorithms by finding improved heuristic estimators for controlling search in a traditional space. <p> in tenths of a second 48 Times are in tenths of a second 49 Times are in tenths of a second 50 Times are in tenths of a second 51 One of the most interesting lines of research in classical planning is the application of propositional-satisfiability techniques to the problem <ref> [18] </ref>. <p> first-order constraint by all its instances, after imposing a bound on the length of the plan being sought. (Unpop uses a similar bound.) A truth assignment that satisfies all the constraints will make one action true at each time instant (roughly speaking), and that action sequence corresponds to a plan <ref> [18] </ref>. The resulting algorithm works amazingly well. 8 Conclusions and Future Work Total-order planning is more promising than its critics have implied.
Reference: [19] <author> John McCarthy and Patrick Hayes. </author> <title> Some philosophical problems from the standpoint of artificial intelligence. </title> <editor> In Bernard Meltzer and Donald Michie, editors, </editor> <booktitle> Machine Intelligence 4, </booktitle> <pages> pages 463-502. </pages> <publisher> Edinburgh University Press, </publisher> <year> 1969. </year>
Reference-contexts: The idea is to express a classical planning problem as a set of first-order constraints on sequences of time instants (by using, in essence, the situation calculus <ref> [19] </ref>), and then replace every first-order constraint by all its instances, after imposing a bound on the length of the plan being sought. (Unpop uses a similar bound.) A truth assignment that satisfies all the constraints will make one action true at each time instant (roughly speaking), and that action sequence
Reference: [20] <author> Drew McDermott. </author> <title> Revised Nisp Manual. </title> <type> Technical Report 642, </type> <institution> Yale Computer Science Department, </institution> <year> 1988. </year>
Reference-contexts: The idea is to get the focus of limited-discrepancy search plus the deletion-sensitivity of best-first. I have tried variations of these ideas, but so far none has had interesting results. 29 5 Implementation Unpop is implemented using the Nisp macro package <ref> [20] </ref> on top of Harlequin Common Lisp. Problems are presented to Unpop in the context of domain theories. For each domain theory there is stored: 1. Lists of all the object types and constant symbols associated with the theory. 2.
Reference: [21] <author> Allen Newell and Herbert Simon. </author> <title> Gps: a program that simulates human thought. </title> <booktitle> In Lernende Automaten, </booktitle> <pages> pages 279-293. </pages> <note> R. Oldenbourg KG. Reprinted in Feigenbaum and Feldman 1963, </note> <year> 1961. </year>
Reference-contexts: The alternative search space I describe is much closer to the space searched by the Prodigy planner [29, 28], in that it is based on means-ends analysis, a classic search technique first embodied in the GPS system <ref> [21, 7] </ref>. The principal difference is that Prodigy, like GPS and Strips [10], uses as a search state an ordered pair containing a plan prefix and a goal structure. <p> : ; G n g is the set of differences between the current situation and the goal description. (For now, I 5 will ignore any variables that might occur in the goals; pretend there aren't any.) This notion of matching to find differences goes all the way back to GPS <ref> [21] </ref>. If there are no differences, then the current plan prefix is a solution to the problem. <p> In addition, there is a simple inheritance mechanism for domain theories, so that one theory can be defined to be equal to another theory, with the addition of further predicates, rules, actions, or whatever. The action-difference table corresponds to the operator-difference table of GPS <ref> [21] </ref>. It is built up incrementally. Every time Unpop computes the regression of an action, it caches it in the table, so the next lookup will be much faster. This table does not depend on the particular problem being solved, so it is saved from run to run.
Reference: [22] <author> Nils J. Nilsson. </author> <booktitle> Principles of Artificial Intelligence. </booktitle> <publisher> Tioga Publishing Company, </publisher> <year> 1980. </year> <month> 55 </month>
Reference-contexts: The "Prodigy" problem is another version of the blocks world, closer to Nilsson's <ref> [22] </ref> specification, in which there are separate actions of the form unstack (block, off-block), stack (block, on-block), pick up (block) etc. The "Monkey" problem involves a monkey, some boxes, some bananas, and so forth. The goal is to get some bananas and a glass of water.
Reference: [23] <author> Peter Norvig. </author> <booktitle> Paradigms of Artificial Intelligence Programming. NIL, </booktitle> <year> 1995. </year>
Reference-contexts: This table does not depend on the particular problem being solved, so it is saved from run to run. The "indexes" in the list, and the action-difference table, are implemented as discrimination trees on symbolic expressions <ref> [5, 23] </ref>. Each node discriminates 30 on a particular position in the expression (CAR, CADR, etc.) and partitions the expressions it is storing into buckets depending on whatever content it finds at that position. When a bucket gets to be too large, it is further discriminated.
Reference: [24] <author> Edwin Peter Dawson Pednault. </author> <title> Toward a Mathematical Theory of Plan Synthesis. </title> <type> PhD thesis, </type> <year> 1986. </year>
Reference-contexts: We call [A] R (P ) the causation precondition for P before A, and [A] R (P ) the preservation precondition for P before A <ref> [24, 25] </ref>. Until Section 3.7, I will focus only on causation preconditions. To compute [A] R A (P ), it suffices to take the definition of A in A, and examine all the Add: effects.
Reference: [25] <author> Edwin Peter Dawson Pednault. </author> <title> Adl: Exploring the middle ground between Strips and the situation calculus. </title> <booktitle> In Proc. Conf. on Knowledge Representation and Reasoning 1, </booktitle> <pages> pages 324-332, </pages> <year> 1989. </year>
Reference-contexts: I will assume that world states (henceforth called situations) are described as collections of propositions, and that actions are described using a variant of the University of Washington notation [30], which is based on Pednault's Action Description Language <ref> [25] </ref>. These notations have a flavor like the Strips notation [10], and share its essential weakness, which is that it is good with propositions and bad with numbers and geometry. Tables 1 and 2 show the definitions for a typical domain. <p> This condition is easy to compute given our Strips-style action formalism <ref> [25] </ref>. It depends on the action definitions of a particular theory, and when that is important I will write [A] R theory P to relativize it. <p> We call [A] R (P ) the causation precondition for P before A, and [A] R (P ) the preservation precondition for P before A <ref> [24, 25] </ref>. Until Section 3.7, I will focus only on causation preconditions. To compute [A] R A (P ), it suffices to take the definition of A in A, and examine all the Add: effects.
Reference: [26] <author> Mark Stefik. </author> <title> Planning with constraints. </title> <booktitle> Artificial Intelligence , 16(2) </booktitle> <pages> 111-139, </pages> <year> 1980. </year>
Reference-contexts: Some planning algorithms can get hung up on closing the boot and reopening it repeatedly. Unpop uses its heuristic estimator, plus the incoherence mechanism of Section 3.6 to curtail the search sharply. The "Molgen" domain is inspired by <ref> [26] </ref>. But the problem in the corpus is probably not representative of problems solved by the real Molgen planner. 5 Well, almost nothing.
Reference: [27] <author> Gerald J. Sussman. </author> <title> A Computer Model of Skill Acquisition. </title> <publisher> American Elsevier Publishing Company, </publisher> <year> 1975. </year>
Reference-contexts: The former issue is one that is often dealt with ambivalently in the literature. Officially plan optimality is not part of the classical-planning problem, but unofficially some of the research (e.g., <ref> [27] </ref>) has been driven by attempts to avoid redundant plan steps. Unpop shares this ambivalence. On one hand, its heuristic estimator explicitly takes plan length into account | the value of a plan prefix is its length plus the estimated effort of its last step.
Reference: [28] <author> Manueal Veloso and P. Stone. "Flecs: </author> <title> Planning with a Flexible Commitment Strategy. </title> <editor> J. </editor> <booktitle> of Art. Intel. </booktitle> <volume> Res , 3 </volume> <pages> 25-52, </pages> <year> 1995. </year> ". 
Reference-contexts: There has been practically no work on heuristic estimators for comparing potential plans. As a consequence, these planners often search through thousands of plans to solve seemingly simple problems. The alternative search space I describe is much closer to the space searched by the Prodigy planner <ref> [29, 28] </ref>, in that it is based on means-ends analysis, a classic search technique first embodied in the GPS system [21, 7]. The principal difference is that Prodigy, like GPS and Strips [10], uses as a search state an ordered pair containing a plan prefix and a goal structure.
Reference: [29] <author> Manuela Veloso and Jaime Carbonell. </author> <title> Derivational analogy in prodigy: automating case acquisition, storage, and utilization. </title> <booktitle> Machine Learning , 10 </booktitle> <pages> 249-278, </pages> <year> 1993. </year>
Reference-contexts: There has been practically no work on heuristic estimators for comparing potential plans. As a consequence, these planners often search through thousands of plans to solve seemingly simple problems. The alternative search space I describe is much closer to the space searched by the Prodigy planner <ref> [29, 28] </ref>, in that it is based on means-ends analysis, a classic search technique first embodied in the GPS system [21, 7]. The principal difference is that Prodigy, like GPS and Strips [10], uses as a search state an ordered pair containing a plan prefix and a goal structure. <p> In limited-discrepancy mode, the system just plods ahead looking at the locally best successor plan, and solves the problem with almost no search. Problems like those in the grid world are difficult for traditional planners. A system like Ucpop [30] or Prodigy <ref> [29] </ref> has trouble because it represents only a single goal structure in its partial-plan representation. <p> The most recent planning work that is related to the Unpop algorithm is the Prodigy planner of Carbonell and Veloso <ref> [29, 11] </ref>, and especially its incarnation as the "FLECS" commitment strategy.[28]. Kambhampati [15] introduced a similar framework in the context of partial-order planning. What these papers have in common is that they model plans as collections of goals and subgoals.
Reference: [30] <author> Daniel Weld. </author> <title> An introduction to least-commitment planning. </title> <journal> AI Magazine, </journal> <year> 1994. </year>
Reference-contexts: I will assume that world states (henceforth called situations) are described as collections of propositions, and that actions are described using a variant of the University of Washington notation <ref> [30] </ref>, which is based on Pednault's Action Description Language [25]. These notations have a flavor like the Strips notation [10], and share its essential weakness, which is that it is good with propositions and bad with numbers and geometry. Tables 1 and 2 show the definitions for a typical domain. <p> The planner can handle the subgoal at (?k2,2,3) in one of several ways. The standard way <ref> [30] </ref> is to treat ?k2 as an unknown, a global variable that is "solved for" during the course of the remaining planning process. Typically, it gets bound when the planner decides what effect of what step to identify with this goal. <p> In limited-discrepancy mode, the system just plods ahead looking at the locally best successor plan, and solves the problem with almost no search. Problems like those in the grid world are difficult for traditional planners. A system like Ucpop <ref> [30] </ref> or Prodigy [29] has trouble because it represents only a single goal structure in its partial-plan representation.
Reference: [31] <author> David Wilkins. </author> <title> Practical Planning: Extending the Classical AI Planning Paradigm. </title> <publisher> Morgan Kaufmann Publishers, Inc, </publisher> <year> 1988. </year> <month> 56 </month>
Reference-contexts: However, there is hope that for some kinds of problems there are algorithms that 1 Most applications of "practical planning" algorithms such as Sipe <ref> [31] </ref> and O-plan [6] have made good use of the plan-management capacities of these systems, but not much use of their plan-search capacities. 1 do well enough in spite of the intractability. Some recent algorithms succeed by searching nontraditional spaces [2, 18].
References-found: 31

