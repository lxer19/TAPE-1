URL: http://www.cs.brown.edu/people/tld/postscript/DeanandKambhampatiCRC-96.ps
Refering-URL: http://www.cs.brown.edu/research/ai/publications/
Root-URL: http://www.cs.brown.edu
Title: Planning and Scheduling  
Author: Thomas Dean, Brown 
Affiliation: University Subbarao Kambhampati, Arizona State University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> J. F. Allen, H. A. Kautz, R. N. Pelavin, and J. D. Tenenberg. </author> <title> Reasoning about Plans. </title> <publisher> Morgan-Kaufmann, </publisher> <address> San Francisco, California, </address> <year> 1991. </year>
Reference-contexts: The above descriptions of dynamical systems provide the semantics for a planning system embedded in a dynamic environment. There remains the question of syntax: specifically, how do you represent the dynamical system? In artificial intelligence, the answer varies widely. Researchers have used first-order logic <ref> [1] </ref>, dynamic logic [35], state-space operators [14], and factored probabilistic state-transition functions [10]. In the later sections, we examine some of these representations in more detail. In some variants of job-shop scheduling the dynamics are relatively simple.
Reference: [2] <editor> James F. Allen, James Hendler, and Austin Tate, editors. </editor> <booktitle> Readings in Planning. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, California, </address> <year> 1990. </year>
Reference: [3] <author> C. Backstrom and I. Klein. </author> <title> Parallel non-binary planning in polynomial time. </title> <booktitle> In Proceedings IJCAI 12, </booktitle> <pages> pages 268-273. </pages> <address> IJCAII, </address> <year> 1991. </year>
Reference-contexts: Dean and Boddy [9] show that the problem of evaluating plans represented as sets of partially ordered actions is NP-hard in all but the simplest cases. Backstrom and Klein <ref> [3] </ref> provide some examples of easy (polynomial time) planning problems, but these problems are of marginal practical interest. Regarding closed-loop, deterministic planning, Papadimitriou and Tsitsiklis [30] discuss polynomial-time algorithms for finding an optimal conditional plan for a variety of performance functions.
Reference: [4] <author> Thomas Bylander. </author> <title> Complexity results for planning. </title> <booktitle> In Proceedings IJCAI 12, </booktitle> <pages> pages 274-279. </pages> <address> IJCAII, </address> <year> 1991. </year>
Reference-contexts: Lawler et al. [27] survey results for the traveling salesperson problem, a special case of our travel planning problem. Here again the prospects for optimal, exact algorithms are not good, but there is some hope for approximate algorithms. With regard to open-loop, deterministic planning, Chapman [5], Bylander <ref> [4] </ref>, and Gupta and Nau [19] have shown that most problems in this general class are hard. Dean and Boddy [9] show that the problem of evaluating plans represented as sets of partially ordered actions is NP-hard in all but the simplest cases.
Reference: [5] <author> David Chapman. </author> <title> Planning for conjunctive goals. </title> <journal> Artificial Intelligence, </journal> <volume> 32 </volume> <pages> 333-377, </pages> <year> 1987. </year>
Reference-contexts: Lawler et al. [27] survey results for the traveling salesperson problem, a special case of our travel planning problem. Here again the prospects for optimal, exact algorithms are not good, but there is some hope for approximate algorithms. With regard to open-loop, deterministic planning, Chapman <ref> [5] </ref>, Bylander [4], and Gupta and Nau [19] have shown that most problems in this general class are hard. Dean and Boddy [9] show that the problem of evaluating plans represented as sets of partially ordered actions is NP-hard in all but the simplest cases.
Reference: [6] <author> K. Currie and A. Tate. O-Plan: </author> <title> The open planning architecture. </title> <journal> Artificial Intelligence, </journal> <volume> 51(1) </volume> <pages> 49-86, </pages> <year> 1991. </year>
Reference-contexts: Of course, there do exist general-purpose planning systems. The SIPE [38] and O-PLAN <ref> [6] </ref> systems are examples that have been around for some time and have been applied to a range of problems from spacecraft scheduling to fermentation planning for commercial breweries.
Reference: [7] <author> P. Dagum, R. Karp, M. Luby, and Sheldon M. Ross. </author> <title> An optimal stopping rule for monte carlo estimation. </title> <booktitle> In Proceedings of the 1995 Symposium on the Foundations of Computer Science, </booktitle> <year> 1995. </year>
Reference-contexts: Return J K () = S=T The above algorithm terminates after generating E [T ] samples, where E [T ] 4 log (2=ffi)(1 + *) J K ()* 2 so that the entire algorithm for approximating J 1 () runs in expected time polynomial in 1=ffi, 1=*, 1=(1 fl) (see <ref> [7] </ref> for a detailed analysis). 32 Approximating J 1 () is only one possible step in an algorithm for computing an optimal or near-optimal plan. In most iterative repair-based algorithms, the algorithm evaluates the current policy and then tries to improve it on each iteration.
Reference: [8] <author> Thomas Dean, James Allen, and Yiannis Aloimonos. </author> <booktitle> Artificial Intelligence: Theory and Practice. </booktitle> <publisher> Benjamin/Cummings Publishing Company, </publisher> <address> Redwood City, California, </address> <year> 1995. </year>
Reference: [9] <author> Thomas Dean and Mark Boddy. </author> <title> Reasoning about partially ordered events. </title> <journal> Artificial Intelligence, </journal> <volume> 36(3) </volume> <pages> 375-399, </pages> <year> 1988. </year>
Reference-contexts: Here again the prospects for optimal, exact algorithms are not good, but there is some hope for approximate algorithms. With regard to open-loop, deterministic planning, Chapman [5], Bylander [4], and Gupta and Nau [19] have shown that most problems in this general class are hard. Dean and Boddy <ref> [9] </ref> show that the problem of evaluating plans represented as sets of partially ordered actions is NP-hard in all but the simplest cases. Backstrom and Klein [3] provide some examples of easy (polynomial time) planning problems, but these problems are of marginal practical interest.
Reference: [10] <author> Thomas Dean and Keiji Kanazawa. </author> <title> A model for reasoning about persistence and causation. </title> <journal> Computational Intelligence, </journal> <volume> 5(3) </volume> <pages> 142-150, </pages> <year> 1989. </year>
Reference-contexts: There remains the question of syntax: specifically, how do you represent the dynamical system? In artificial intelligence, the answer varies widely. Researchers have used first-order logic [1], dynamic logic [35], state-space operators [14], and factored probabilistic state-transition functions <ref> [10] </ref>. In the later sections, we examine some of these representations in more detail. In some variants of job-shop scheduling the dynamics are relatively simple.
Reference: [11] <author> Thomas Dean and Michael Wellman. </author> <title> Planning and Control. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, California, </address> <year> 1991. </year>
Reference: [12] <author> Oren Etzioni, Steve Hanks, Daniel Weld, Denise Draper, Neal Lesh, and Mike Williamson. </author> <title> An approach to planning with incomplete information. </title> <booktitle> In Proceedings of the 1992 International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <year> 1992. </year> <month> 37 </month>
Reference-contexts: These operators have preconditions and postconditions similar to other operators, but some of the postconditions, those corresponding to the consequences of information gathering, are nondeterministic; we will not know the actual value of these postconditions until after we have executed the action <ref> [12] </ref>. The approach to conditional planning sketched above theoretically extends to arbitrary sources of uncertainty, but in practice search has to be limited to consider only outcomes that are likely to have a significant impact on performance.
Reference: [13] <author> Claude-Nicolas Fiechter. </author> <title> Efficient reinforcement learning. </title> <booktitle> In Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, </booktitle> <pages> pages 88-97, </pages> <year> 1994. </year>
Reference-contexts: Let be any plan, J 1 () = J (j0) be the performance of accounting for an infinite sequence of state transitions, and J K () the performance of accounting for only K state transitions. We can bound the difference between these two measures of performance as follows (see <ref> [13] </ref> for a proof ). jJ 1 () J K ()j fl K C max =(1 fl) The above result implies that if we are willing to sacrifice a (maximum) error of fl K C max =(1 fl) in measuring the performance of plans, we need only concern ourselves with histories
Reference: [14] <author> Richard Fikes and Nils J. Nilsson. </author> <title> Strips: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 189-208, </pages> <year> 1971. </year>
Reference-contexts: There remains the question of syntax: specifically, how do you represent the dynamical system? In artificial intelligence, the answer varies widely. Researchers have used first-order logic [1], dynamic logic [35], state-space operators <ref> [14] </ref>, and factored probabilistic state-transition functions [10]. In the later sections, we examine some of these representations in more detail. In some variants of job-shop scheduling the dynamics are relatively simple.
Reference: [15] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractibility: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: Our discussion begins with a quick survey of what is known about the complexity of planning and scheduling problems. 3.1 Complexity Results Garey and Johnson <ref> [15] </ref> provide an extensive listing of NP-hard problems, including a great many scheduling problems. They also provide numerous examples of how a hard problem can be rendered easy by relaxing certain assumptions. For example, most variants of job-shop scheduling are NP-hard.
Reference: [16] <author> Michael P. Georgeff. </author> <title> Planning. </title> <editor> In J. F. Traub, editor, </editor> <booktitle> Annual Review of Computer Science, Volume 2. Annual Review Incorporated, </booktitle> <year> 1987. </year>
Reference: [17] <author> Matthew L. Ginsberg and David McAllester. </author> <title> GSAT and dynamic backtracking. </title> <booktitle> In Proceedings of the 1994 International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <year> 1994. </year>
Reference-contexts: This guidance can sometimes be at odds with the commitments that have already been made in the current search branch. Iterative methods do not have this problem since they do not do any bookkeeping about the current state of the search. Recent work on partial order dynamic backtracking algorithms <ref> [17] </ref> provides an elegant way of keeping both systematicity and freedom of movement. 3.4 Improving Efficiency While the previous sections surveyed the methods used to organize the search for plans and discussed their relative advantages, as observed in Section 3.1, most planning problems are 29 computationally hard.
Reference: [18] <author> R. L. Graham, E. L. Lawler, J. K. Lenstra, and A. H. G. Rinnooy Kan. </author> <title> Optimization and approximation in deterministic sequencing and scheduling: A survey. </title> <booktitle> In Proceedings Discrete Optimization, </booktitle> <year> 1977. </year>
Reference-contexts: With this assumption, some hard problems become easy. Unfortunately, most real scheduling problems are NP-hard. Graham et al. <ref> [18] </ref> provide a somewhat more comprehensive survey of scheduling problems with a similarly dismal conclusion. Lawler et al. [27] survey results for the traveling salesperson problem, a special case of our travel planning problem.
Reference: [19] <author> Naresh Gupta and Dana S. Nau. </author> <title> Complexity results for blocks-world planning. </title> <booktitle> In Proceedings AAAI-91, </booktitle> <pages> pages 629-633. </pages> <publisher> AAAI, </publisher> <year> 1991. </year>
Reference-contexts: Here again the prospects for optimal, exact algorithms are not good, but there is some hope for approximate algorithms. With regard to open-loop, deterministic planning, Chapman [5], Bylander [4], and Gupta and Nau <ref> [19] </ref> have shown that most problems in this general class are hard. Dean and Boddy [9] show that the problem of evaluating plans represented as sets of partially ordered actions is NP-hard in all but the simplest cases.
Reference: [20] <author> Kristian J. Hammond. </author> <title> Case-Based Planning. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: This explanation can then be used to focus the repair activity <ref> [36, 20] </ref>. <p> We briefly survey some of these methods below. One of the simplest ways of improving performance over time involves "caching" plans for frequently occurring problems and subproblems, and reusing them in subsequent planning scenarios. This approach is called case-based planning (scheduling) <ref> [20, 23] </ref> and is motivated by similar considerations to those motivating task-reduction refinements. In storing a previous planning experience, we have two choices: store the final plan, or store the plan along with the search decisions that lead to the plan.
Reference: [21] <author> James Hendler, Austin Tate, and Mark Drummond. </author> <title> AI planning: Systems and techniques. </title> <journal> AI Magazine, </journal> <volume> 11(2) </volume> <pages> 61-77, </pages> <year> 1990. </year>
Reference: [22] <author> Subbarao Kambhampati. </author> <title> A comparative analysis of partial-order planning and task-reduction planning. </title> <journal> ACM SIGART Bulletin, </journal> <volume> 6(1), </volume> <year> 1995. </year>
Reference-contexts: Finally, if the operator ff 4 is a non-primitive operator, we can also use task reduction refinement to replace ff 4 with its reduction schema. There is some evidence that planners using multiple refinement strategies intelligently can outperform those using single refinement strategies <ref> [22] </ref>. However, the question as to which refinement strategy should be preferred when is still largely open.
Reference: [23] <author> Subbarao Kambhampati and James Hendler. </author> <title> A validation structure based theory of plan modification and reuse. </title> <journal> Artificial Intelligence, </journal> <volume> 55(2-3):193-258, </volume> <year> 1992. </year>
Reference-contexts: We briefly survey some of these methods below. One of the simplest ways of improving performance over time involves "caching" plans for frequently occurring problems and subproblems, and reusing them in subsequent planning scenarios. This approach is called case-based planning (scheduling) <ref> [20, 23] </ref> and is motivated by similar considerations to those motivating task-reduction refinements. In storing a previous planning experience, we have two choices: store the final plan, or store the plan along with the search decisions that lead to the plan.
Reference: [24] <author> Subbarao Kambhampati, Craig Knoblock, and Qiang Yang. </author> <title> Refinement search as a unifying framework for evaluating design tradeoffs in partial order planning. </title> <journal> Artificial Intelligence, </journal> <volume> 76(1-2):167-238, </volume> <year> 1995. </year> <month> 38 </month>
Reference-contexts: We define a generic refinement procedure, Refine (), as follows <ref> [24] </ref>. 1.
Reference: [25] <author> S. Kirkpatrick, C. D. Gelatt, and M. P. Vecchi. </author> <title> Optimization by simulated annealing. </title> <journal> Science, </journal> <volume> 220 </volume> <pages> 671-680, </pages> <year> 1983. </year>
Reference-contexts: In many cases, these local extrema correspond to very poor solutions. To improve performance and reduce the risk of becoming stuck in local extrema corresponding to badly suboptimal solutions, some schedulers employ stochastic techniques that occasionally choose to make repairs other than those suggested by their heuristics. Simulated annealing <ref> [25] </ref> is one example of a stochastic search method used to escape local extrema in scheduling. In simulated annealing, there is a certain probability that the scheduler will choose a repair other than the one suggested by the scheduler's heuristics.
Reference: [26] <author> Nicholas Kushmerick, Steve Hanks, and Daniel Weld. </author> <title> An algorithm for probabilistic planning. </title> <booktitle> In Proceedings AAAI-94. AAAI, </booktitle> <year> 1994. </year>
Reference-contexts: For more on planning in stochastic domains using probabilistic state space operators, see <ref> [26] </ref>. There are well known methods for computing an optimal plan for the problem described above [34]. Most of these methods proceed using iterative repair-based methods that work by improving an existing plan using the computed function J (ji).
Reference: [27] <author> E.L. Lawler, J.K. Lenstra, A.H.G. Rinnooy Kan, </author> <title> and D.B. Shmoys. The Travelling Salesman Problem. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: With this assumption, some hard problems become easy. Unfortunately, most real scheduling problems are NP-hard. Graham et al. [18] provide a somewhat more comprehensive survey of scheduling problems with a similarly dismal conclusion. Lawler et al. <ref> [27] </ref> survey results for the traveling salesperson problem, a special case of our travel planning problem. Here again the prospects for optimal, exact algorithms are not good, but there is some hope for approximate algorithms.
Reference: [28] <author> S. Lin and B. W. Kernighan. </author> <title> An effective heuristic for the travelling salesman problem. </title> <journal> Operations Research, </journal> <volume> 21 </volume> <pages> 498-516, </pages> <year> 1973. </year>
Reference-contexts: Continue to make repairs in this manner until no improvement (reduction in the length of the resulting tour) is possible. Lin and Kernighan's algorithm <ref> [28] </ref> which is based on this local repair method generates solutions that are within 10% of the length of the optimal tour on a large class of practical problems.
Reference: [29] <author> Steve Minton, </author> <title> editor. Machine Learning Methods for Planning and Scheduling. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, California, </address> <year> 1992. </year>
Reference-contexts: By analyzing the search failures and using explanation-based learning techniques, it is possible to learn search control rules that, for example, can be used to advise a planner as to which refinement or repair to pursue under what circumstances. For more about the connections between planning and learning see <ref> [29] </ref>. 3.5 Approximation in Stochastic Domains In this section, we consider a planning problem involving stochastic dynamics.
Reference: [30] <author> Christos H. Papadimitriou and John N. Tsitsiklis. </author> <title> The complexity of Markov chain decision processes. </title> <journal> Mathematics of Operations Research, </journal> <volume> 12(3) </volume> <pages> 441-450, </pages> <year> 1987. </year>
Reference-contexts: Backstrom and Klein [3] provide some examples of easy (polynomial time) planning problems, but these problems are of marginal practical interest. Regarding closed-loop, deterministic planning, Papadimitriou and Tsitsiklis <ref> [30] </ref> discuss polynomial-time algorithms for finding an optimal conditional plan for a variety of performance functions. Unfortunately, the polynomial is in the size of the state space. As mentioned earlier, we assume that the size of the state space is exponential in the number of state variables.
Reference: [31] <author> Edwin P. D. Pednault. </author> <title> Synthesizing plans that contain actions with context-dependent effects. </title> <journal> Computational Intelligence, </journal> <volume> 4(4) </volume> <pages> 356-372, </pages> <year> 1988. </year>
Reference-contexts: This can be done by posting R as a precondition of Step 3. Since R is not a normal precondition of ff 3 , and is being posted only to guarantee one of its conditional effects, it is called a secondary precondition <ref> [31] </ref>. Now that we have introduced Step 3 and ensured that it produces Q as a postcondition, we need to make sure that Q is not violated by any steps possibly intervening between Steps 3 and 2. This phase of plan-space refinement is called arbitration.
Reference: [32] <author> J. S. Penberthy and Daniel S. Weld. UCPOP: </author> <title> A sound, complete, partial order planner for ADL. </title> <booktitle> In Proceedings of the 1992 International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 103-114, </pages> <year> 1992. </year>
Reference: [33] <author> Mark Peot and Ross Shachter. </author> <title> Fusion and propagation with multiple observations in belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 48(3) </volume> <pages> 299-318, </pages> <year> 1991. </year>
Reference-contexts: There exist methods for extending refinement strategies so that instead of working on K unconditional plans with significant overlap, a single, multi-threaded conditional plan is generated <ref> [33] </ref>. Conditional planning can be very expensive in situations in which the unspecified variable has a large set of possible values or there are several unspecified variables.
Reference: [34] <author> Martin L. Puterman. </author> <title> Markov Decision Processes. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: For more on planning in stochastic domains using probabilistic state space operators, see [26]. There are well known methods for computing an optimal plan for the problem described above <ref> [34] </ref>. Most of these methods proceed using iterative repair-based methods that work by improving an existing plan using the computed function J (ji). On each iteration, we end up with a new plan 0 and must calculate J ( 0 ji) for all i.
Reference: [35] <author> Stan Rosenschein. </author> <title> Plan synthesis: A logical perspective. </title> <booktitle> In Proceedings IJCAI 7, </booktitle> <pages> pages 331-337. </pages> <address> IJCAII, </address> <year> 1981. </year>
Reference-contexts: The above descriptions of dynamical systems provide the semantics for a planning system embedded in a dynamic environment. There remains the question of syntax: specifically, how do you represent the dynamical system? In artificial intelligence, the answer varies widely. Researchers have used first-order logic [1], dynamic logic <ref> [35] </ref>, state-space operators [14], and factored probabilistic state-transition functions [10]. In the later sections, we examine some of these representations in more detail. In some variants of job-shop scheduling the dynamics are relatively simple.
Reference: [36] <author> Reid Simmons and Randall Davis. </author> <title> Generate, test and debug: Combining associational rules and causal models. </title> <booktitle> In Proceedings IJCAI 10, </booktitle> <pages> pages 1071-1078. </pages> <address> IJCAII, </address> <year> 1987. </year> <month> 39 </month>
Reference-contexts: This explanation can then be used to focus the repair activity <ref> [36, 20] </ref>.
Reference: [37] <author> Edward Tsang. </author> <title> Foundations of Constraint Satisfaction. </title> <publisher> Academic Press, </publisher> <address> San Diego, California, </address> <year> 1993. </year>
Reference-contexts: A schedule is then represented as an assignment of values to all of the variables that satisfies all the constraints. The resulting formulation of scheduling problems is called a constraint satisfaction problem <ref> [37] </ref>. <p> Other ways of improving search efficiency include using look ahead techniques to prune inconsistent partial assignments ahead of time, to process the domains of the remaining variables so that any infeasible values are removed, or using dependency directed backtracking techniques to recover from inconsistent partial assignments intelligently. See <ref> [37] </ref> for a description of these techniques and their tradeoffs.
Reference: [38] <author> David E. Wilkins. </author> <title> Practical Planning: Extending the Classical AI Planning Paradigm. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, California, </address> <year> 1988. </year>
Reference-contexts: Of course, there do exist general-purpose planning systems. The SIPE <ref> [38] </ref> and O-PLAN [6] systems are examples that have been around for some time and have been applied to a range of problems from spacecraft scheduling to fermentation planning for commercial breweries.

References-found: 38

