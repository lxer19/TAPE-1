URL: http://www.eecis.udel.edu:80/~samuel/work/papers/aiotblid/samuel-1998c.ps
Refering-URL: http://www.eecis.udel.edu:80/~samuel/work/papers/aiotblid/index.html
Root-URL: http://www.cis.udel.edu
Email: samuel@cis.udel.edu  carberry@cis.udel.edu  vijay@cis.udel.edu  
Title: An Investigation of Transformation-Based Learning in Discourse  
Author: Ken Samuel Sandra Carberry K. Vijay-Shanker 
Address: Newark, Delaware 19716 USA  Newark, Delaware 19716 USA  Newark, Delaware 19716 USA  
Affiliation: CIS Department University of Delaware  CIS Department University of Delaware  CIS Department University of Delaware  
Abstract: This paper presents results from the first attempt to apply Transformation-Based Learning to a discourse-level Natural Language Processing task. To address two limitations of the standard algorithm, we developed a Monte Carlo version of Transformation-Based Learning to make the method tractable for a wider range of problems without degradation in accuracy, and we devised a committee method for assigning confidence measures to tags produced by Transformation-Based Learning. The paper describes these advances, presents experimental evidence that Transformation-Based Learning is as effective as alternative approaches (such as Decision Trees and N-Grams) for a discourse task called Dialogue Act Tagging, and argues that Transformation-Based Learning has desirable features that make it particularly appealing for the Dialogue Act Tagging task.
Abstract-found: 1
Intro-found: 1
Reference: <author> Brill, </author> <title> Eric (1995a). Transformation-Based Error-Driven Learning and Natural Language Processing: A Case Study in Part-of-Speech Tagging. </title> <booktitle> Computational Linguistics 21(4) </booktitle> <pages> 543-566. </pages>
Reference-contexts: 1 INTRODUCTION Transformation-Based Learning is a relatively new machine learning method, which has been as effective as any other approach on the Part-of-Speech Tagging problem 1 <ref> (Brill, 1995a) </ref>. We are utilizing Transformation-Based Learning for another important language task called Dialogue Act Tagging, in which the goal is to label each utterance in a conversational dialogue with the proper dialogue act. A dialogue act is a concise abstraction of a speaker's intention, such as SUGGEST or ACCEPT. <p> This parallel suggests that Transformation-Based Learning has potential for success on the Dialogue Act Tagging problem. Since we currently lack a systematic theory of dialogue acts, another reason that Transformation-Based Learning is an attractive choice is that its learned model consists of relatively intuitive rules <ref> (Brill, 1995a) </ref>, which a human can analyze to determine what the system has learned and develop a working theory. Also, Transformation-Based Learning is good at ignoring any potential rules that are irrelevant. <p> Our experiments confirm these intuitions, as shown in Figures 4 and 5. For these runs, eight condi 6 For the Part-of-Speech Tagging task, Brill used only about 30 simple rule templates <ref> (Brill, 1995a) </ref>. tions were preselected, and for different values of n, 0 n 8, the first n conditions were combined in all possible ways to generate 2 n templates. Using these templates, we trained, tested, and compared the standard Transformation-Based Learning method and our Monte Carlo version of Transformation-Based Learning. <p> In addition, Transformation-Based Learning has a number of features that make it particularly appealing for the Dialogue Act Tagging task: 1. Transformation-Based Learning's learned model consists of a relatively short sequence of intuitive rules, stressing relevant features and highlighting important relationships between features and tags <ref> (Brill, 1995a) </ref>. Thus, Transformation-Based Learning's learned model offers insights into a theory to explain the training data. This is especially useful in Dialogue Act Tagging, which currently lacks a systematic theory. 2.
Reference: <author> Brill, </author> <title> Eric (1995b). Unsupervised Learning of Disambiguation Rules for Part of Speech Tagging. </title> <booktitle> In Proceedings of the Very Large Corpora Workshop. </booktitle>
Reference-contexts: We would also like to extend our system so that it may learn from untagged data, as there is still very little tagged data available in discourse. Brill developed an unsupervised version of Transformation-Based Learning for Part-of-Speech Tagging <ref> (Brill, 1995b) </ref>, but this algorithm must be initialized with instances that can be tagged unambiguously (such as "the", which is always a determiner), and in Dialogue Act Tagging there are very few unambiguous examples.
Reference: <author> Brill, Eric and Mooney, Raymond J. </author> <year> (1997). </year> <title> An Overview of Empirical Natural Language Processing. </title> <journal> AI Magazine 18(4) </journal> <pages> 13-24. </pages>
Reference-contexts: So "probabilistic methods ... provide a continuous ranking of alternative analyses rather than just a single output, and such rankings can productively increase the bandwidth between components of a modular system." <ref> (Brill and Mooney, 1997) </ref> The second limitation of Transformation-Based Learning is that it is highly dependent on the rule templates, which are manually developed in advance. Since the omission of any relevant templates would handicap the system, it is essential that these choices be made carefully.
Reference: <author> Dagan, Ido and Engelson, Sean P. </author> <year> (1995). </year> <title> Committee-Based Sampling for Training Probabilistic Classifiers. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning. </booktitle>
Reference-contexts: strategy to minimize the required pass through the training data, sometimes the standard Transformation-Based Learning method selects a rule that locks it into a local maximum, while the Monte Carlo version might fail to consider this attractive rule and end up producing a better model. size of a training corpus <ref> (Dagan and Engelson, 1995) </ref>. We applied these methods to compute confidence measures, by training the system a number of times to produce a few different but reasonable learned models, which are called committee members.
Reference: <author> Freund, Yoav and Schapire, Robert E. </author> <year> (1996). </year> <title> Experiments with a New Boosting Algorithm. </title> <booktitle> In Proceedings of the Thirteenth International Conference on Machine Learning. </booktitle>
Reference-contexts: So, for the purpose of computing confidence measures, we adapted two techniques that were developed for very different tasks. The Boosting approach has been used to improve accuracy in tagging data <ref> (Freund and Schapire, 1996) </ref>, and Committee-Based Sampling utilized a very similar strategy to minimize the required pass through the training data, sometimes the standard Transformation-Based Learning method selects a rule that locks it into a local maximum, while the Monte Carlo version might fail to consider this attractive rule and end
Reference: <author> Hirschberg, Julia and Litman, </author> <title> Diane (1993). Empirical Studies on the Disambiguation of Cue Phrases. </title> <booktitle> Computational Linguistics 19(3) </booktitle> <pages> 501-530. </pages>
Reference: <author> Knott, </author> <title> Alistair (1996). A Data-Driven Methodology for Motivating a Set of Coherence Relations. </title> <type> Ph.D. Thesis. </type> <institution> The University of Edinburgh. </institution>
Reference: <author> Ramshaw, Lance A. and Marcus, Mitchell P. </author> <year> (1994). </year> <title> Exploring the Statistical Derivation of Transformation Rule Sequences for Part-of-Speech Tagging. </title> <booktitle> In Proceedings of the 32nd Annual Meeting of the ACL. </booktitle>
Reference-contexts: This is especially useful in Dialogue Act Tagging, which currently lacks a systematic theory. 2. With its iterative training algorithm, when developing a new rule, Transformation-Based Learning can consider tags that have been produced by previous rules <ref> (Ramshaw and Marcus, 1994) </ref>. Since the dialogue act of an utterance is affected by the surrounding dialogue acts, this leveraged learning approach can directly integrate the relevant contextual information into the rules.
Reference: <author> Reithinger, Norbert and Klesen, </author> <title> Martin (1997). Dialogue Act Classification Using Language Models. </title> <booktitle> In Proceedings of EuroSpeech-97. Rulequest Research. (1998). Data Mining Tools see5 and c5.0. </booktitle> <address> [http://www.rulequest.com/see5-info.html]. </address>
Reference-contexts: We experimentally compared our modified version of Transformation-Based Learning with C5.0, an implementation of Decision Trees, and N-Grams, which was previously the best reported method for Dialogue Act Tagging <ref> (Reithinger and Klesen, 1997) </ref>. Our system performs as well as these benchmarks, and we note that Transformation-Based Learning has several characteristics that make it particularly appealing for the Dialogue Act Tagging task.
Reference: <author> Samuel, Ken, Carberry, Sandra, and Vijay-Shanker, K. </author> <year> (1998a). </year> <title> Computing Dialogue Acts from Features with Transformation-Based Learning. In Applying Machine Learning to Discourse Processing: </title> <booktitle> Papers from the 1998 AAAI Spring Symposium. </booktitle>
Reference: <author> Samuel, Ken, Carberry, Sandra, and Vijay-Shanker, K. </author> <year> (1998b). </year> <title> Dialogue Act Tagging with Transformation-Based Learning. </title> <booktitle> In Proceedings of COLING-ACL. </booktitle>
References-found: 11

