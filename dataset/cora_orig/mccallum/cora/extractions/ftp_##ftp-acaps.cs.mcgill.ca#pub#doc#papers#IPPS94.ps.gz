URL: ftp://ftp-acaps.cs.mcgill.ca/pub/doc/papers/IPPS94.ps.gz
Refering-URL: http://www.cs.mcgill.ca/resrchpages/pub94.html
Root-URL: http://www.cs.mcgill.ca
Email: herbert@ece.concordia.ca theobald@cs.mcgill.ca, gao@cs.mcgill.ca  
Title: Building Multithreaded Architectures with Off-the-Shelf Microprocessors  
Author: Herbert H. J. Hum Kevin B. Theobald and Guang R. Gao 
Address: Montreal, Canada  
Affiliation: Dept. of Electrical and Computer Engineering School of Computer Science Concordia University, Montreal, Canada McGill University,  
Abstract: In the Proceedings of the 8th IEEE International Parallel Processing Symposium (IPPS '94), pp. 288-294, Cancun, Mex--ico, April 23-26, 1994. c fl1994 IEEE. Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works must be obtained from the IEEE. Abstract Present-day parallel computers often face the problems of large software overheads for process switching and inter-processor communication. These problems are addressed by the Multi-Threaded Architecture (MTA), a multiprocessor model designed for efficient parallel execution of both numerical and non-numerical programs. We begin with a conventional processor, and add what we believe to be the minimal external hardware necessary for efficient support of multithreaded programs. The presentation begins with the top-level architecture and the program execution model. The latter includes a description of activation frames and thread synchronization. This is followed by a detailed presentation of the processor. Major features of the MTA include the Register-Use Cache for exploiting temporal locality in multiple register set microprocessors, support for programs requiring non-determinism and speculation, and local function invocations which can utilize registers for parameter passing. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Alverson, D. Callahan, D. Cummings, B. Koblenz, A. Porterfield, and B. Smith, </author> <title> "The Tera computer system," </title> <booktitle> in Conf. Proc., 1990 ICS, </booktitle> <address> Amsterdam, The Netherlands, </address> <pages> pp. 1-6, </pages> <month> Jun. </month> <year> 1990. </year>
Reference-contexts: The MTA approach to scalable parallel processing is based on multithreading. In broad terms, a multithreaded architecture <ref> [1, 5, 7, 8, 11, 12, 14] </ref> is best characterized as an architecture designed to support the efficient concurrent execution of multiple threads of control. A thread is a sequence of instructions whose relative order is determined at compile time. <p> Multithreading can be supported by external hardware which can be implemented with simple ASIC chips. In comparing the MTA to other multithreaded machines, we note that the Empire [11], RWC-1 [14], and Tera <ref> [1] </ref>, among others, are different from the MTA in that there is no clear separation between the execution unit and synchronization unit. Some other machines, such as *T [12], have separate synchronization and execution units.
Reference: [2] <author> U. Bruening, W. Giloi, and W. Schroeder-Preikschat, </author> <title> "Genesis and MANNA|goals, concepts, and realization," </title> <journal> JPDC, </journal> <note> Accepted for publication. </note>
Reference-contexts: single activation frame from the ready queue, and associated events from the event queue. 5 Development of the MTA To experiment with the MTA model, we will program a multiprocessor whose hardware configuration closely matches the MTA (e.g., a machine with two RISC processors per node, such as the MANNA <ref> [2] </ref>) to emulate the behavior of the MTA. The emulation overhead should be much smaller than the cost of software simulation, so that programs can run at an acceptable speed. The MTA instruction set will contain a standard complement of RISC instructions augmented by special instructions to support multithreading.
Reference: [3] <author> D. E. Culler, A. Sah, K. E. Schauser, T. von Eicken, and J. Wawrzynek, </author> <title> "Fine-grain parallelism with minimal hardware support: A compiler-controlled threaded abstract machine," </title> <booktitle> in Proc. of ASPLOS-IV, </booktitle> <address> Santa Clara, Calif., </address> <pages> pp. 164-175, </pages> <month> Apr. </month> <year> 1991. </year>
Reference-contexts: Therefore, our runtime model supports a tree of activation frames in which each activation frame is dynamically linked to its caller. This was first proposed for dataflow [13] and later used in multithreaded systems <ref> [3, 12] </ref>. When a function is invoked in the MTA, an activation frame is allocated to represent that function instance. A frame pointer fp points to the base of the frame and is used to identify the frame uniquely. A function will usually contain many threads. <p> means that the SU will favor (prioritize) 290 0 x set 1 . . 0 x fp 1 SU queue event register register file use cache queue ready cache memory local threads in the ready queue which are immediately related to the currently executing thread, i.e., in the same quantum <ref> [3] </ref>. Identifying threads belonging to the same function activation as the currently active thread can be easily performed by comparing the fp value of the ready id with the %fp register. The SU can put such recently created ready ids on top of the ready queue. <p> A software routine would then spill that register set. 2.4.2 Data Outside a Frame Access to remote memory requires explicit messages to be sent to the remote SU. These are clearly long-latency operations that would cause huge stalls if they were in the middle of threads. Split-phase transactions <ref> [3] </ref> can be used to avoid this situation. A remote load operation is performed in one thread, and the values produced are used in other threads. The other thread (s) are activated by the messages returning from the remote SU.
Reference: [4] <author> J. B. Dennis and G. R. Gao, </author> <title> "An efficient pipelined dataflow processor architecture," </title> <booktitle> in Proc. Supercomputing '88, </booktitle> <address> Orlando, </address> <publisher> Flor., </publisher> <pages> pp. 368-373, </pages> <month> Nov. </month> <year> 1988. </year>
Reference-contexts: The last section summarizes our paper. 2 The Base MTA Model An MTA node contains an Execution Unit (EU) and a Synchronization Unit (SU) linked together by buffers (see Figure 1). This organization is derived from the Argument-Fetch Dataflow Processor <ref> [4] </ref>, in which the analogous units are called the Dataflow Instruction Scheduling Unit (DISU) and the Pipelined Instruction Processing Unit (PIPU). The SU and EU share the processor's local memory, which is cached. <p> event queue include local synchronization signals emitted by the EU of the local processor, as well as remote synchronization signals and communication messages delivered from the network. 2.2 Thread Synchronization The method of determining the order of execution of threads on the MTA is derived from the static dataflow model <ref> [4] </ref>. In the dataflow model, an actor (instruction) is enabled (becomes eligible for execution) as soon as all inputs required by the actor are available. For each actor, there is an associated "enable" count which counts how many inputs remain to be filled.
Reference: [5] <author> J. B. Dennis and G. R. Gao, </author> <title> "The evolution of multi-threaded computers," in Multithreaded Computer Architecture: A Summary of the State of the Art (R. </title> <editor> Ian-nucci et al., eds.), </editor> <publisher> Kluwer Academic Pub., </publisher> <year> 1994. </year>
Reference-contexts: The MTA approach to scalable parallel processing is based on multithreading. In broad terms, a multithreaded architecture <ref> [1, 5, 7, 8, 11, 12, 14] </ref> is best characterized as an architecture designed to support the efficient concurrent execution of multiple threads of control. A thread is a sequence of instructions whose relative order is determined at compile time.
Reference: [6] <author> L. J. Hendren, G. R. Gao, C. Mukerji, and B. Srid-haran, </author> <title> "Introducing McCAT|The McGill Compiler-Architecture Testbed," </title> <type> ACAPS Tech. Memo 27, </type> <institution> Sch. of Comp. Sci., McGill U., Montreal, Que., </institution> <month> Sep. </month> <year> 1991. </year>
Reference-contexts: Lastly, support hardware will also need to be emulated in the processor. Initial experiments with MTA will probably use hand-compiled code. A multithreading compiler, based on McGill's McCAT compiler <ref> [6] </ref>, is currently being constructed to complete the system. There are still some important architectural issues to be settled.
Reference: [7] <author> H. H.-J. Hum, </author> <title> The Super-Actor Machine: a Hybrid Dataflow/von Neumann Architecture. </title> <type> PhD thesis, </type> <institution> McGill U., Montreal, Que., </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: The MTA approach to scalable parallel processing is based on multithreading. In broad terms, a multithreaded architecture <ref> [1, 5, 7, 8, 11, 12, 14] </ref> is best characterized as an architecture designed to support the efficient concurrent execution of multiple threads of control. A thread is a sequence of instructions whose relative order is determined at compile time. <p> Moreover, the register set to which it is assigned should be included in the ready id such that when the ready id does enter the EU, the proper register set will be used. This is a simpler form of the registering process in the register-cache of the Super-Actor Machine <ref> [7, 8] </ref>. Complexity arises when a ready id which is not prioritized enters the EU. In that case, a software routine is executed which tries to find an unallocated register set with the help of the RU-cache. <p> Ordinarily, when a sync count reaches 0, the SU will set it back to the reset count, and it is up to the compiler, following proper construction rules <ref> [7] </ref>, to ensure that no more data will come in until the thread has finished reading its inputs.
Reference: [8] <author> H. H. J. Hum and G. R. Gao, </author> <title> "A high-speed memory organization for hybrid dataflow/von Neumann computing," </title> <journal> Future Generation Computer Systems, </journal> <volume> 8(4) </volume> <pages> 287-301, </pages> <month> Sep. </month> <year> 1992. </year>
Reference-contexts: The MTA approach to scalable parallel processing is based on multithreading. In broad terms, a multithreaded architecture <ref> [1, 5, 7, 8, 11, 12, 14] </ref> is best characterized as an architecture designed to support the efficient concurrent execution of multiple threads of control. A thread is a sequence of instructions whose relative order is determined at compile time. <p> Moreover, the register set to which it is assigned should be included in the ready id such that when the ready id does enter the EU, the proper register set will be used. This is a simpler form of the registering process in the register-cache of the Super-Actor Machine <ref> [7, 8] </ref>. Complexity arises when a ready id which is not prioritized enters the EU. In that case, a software routine is executed which tries to find an unallocated register set with the help of the RU-cache.
Reference: [9] <author> H. H. J. Hum and G. R. Gao, </author> <title> "Supporting a dynamic SPMD model in a multi-threaded architecture," </title> <booktitle> in Digest of Papers, COMPCON Spring '93, </booktitle> <address> San Fran-cisco, Calif., </address> <pages> pp. 165-175, </pages> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: In our previous work, some initial thoughts on the MTA model were presented <ref> [9, 10] </ref>. The intent of this paper is to define formally the basic MTA model and present various features which we believe are beneficial to the efficient and effective support of both numerical and non-numerical applications. <p> However, this does not preclude the use of software and/or limited hardware mechanisms for projecting a global address space to the compiler, thereby making the MTA a distributed shared memory machine. (A version of the MTA in <ref> [9] </ref> specifies one such mechanism.) The EU consists of a register file and a RISC execution pipeline. The register file contains registers for storing temporary values, and special registers such as a frame pointer register (%fp).
Reference: [10] <author> H. H. J. Hum, K. B. Theobald, and G. R. Gao, </author> <title> "Building multithreaded architectures with off-the-shelf microprocessors," </title> <type> ACAPS Tech. Memo 68, </type> <institution> Sch. of Comp. Sci., McGill U., Montreal, Que., </institution> <month> Oct. </month> <year> 1993. </year> <note> In pub/doc/memos on ftp site wally.cs.mcgill.ca. </note>
Reference-contexts: In our previous work, some initial thoughts on the MTA model were presented <ref> [9, 10] </ref>. The intent of this paper is to define formally the basic MTA model and present various features which we believe are beneficial to the efficient and effective support of both numerical and non-numerical applications. <p> We have also provided details of the operation of the EU and the SU, and mentioned extensions for compiler- or programmer-controlled prioritizing of threads, and for the killing of threads to support efficient speculative execution and parallel search. More details on the MTA can be found in <ref> [10] </ref>. Our next ongoing phase is to implement the MTA emulator on our chosen multiprocessor.
Reference: [11] <author> R. A. </author> <title> Iannucci, "Toward a dataflow/von Neumann hybrid architecture," </title> <booktitle> in Proc. of ISCA-15, Honolulu, Hawaii, </booktitle> <pages> pp. 131-140, </pages> <month> May-Jun. </month> <year> 1988. </year>
Reference-contexts: 1 Introduction Current strategies for supporting high-performance parallel computing often face the problem of large software overheads for process switching and interprocessor communication <ref> [11] </ref>. These overheads limit the range of applications which can be effectively mapped to these architectures. While some architectures have been proposed to deal with the problems of overheads, most of them require unusual hardware designs that are far removed from the mainstream of processor technology. <p> The MTA approach to scalable parallel processing is based on multithreading. In broad terms, a multithreaded architecture <ref> [1, 5, 7, 8, 11, 12, 14] </ref> is best characterized as an architecture designed to support the efficient concurrent execution of multiple threads of control. A thread is a sequence of instructions whose relative order is determined at compile time. <p> Multithreading can be supported by external hardware which can be implemented with simple ASIC chips. In comparing the MTA to other multithreaded machines, we note that the Empire <ref> [11] </ref>, RWC-1 [14], and Tera [1], among others, are different from the MTA in that there is no clear separation between the execution unit and synchronization unit. Some other machines, such as *T [12], have separate synchronization and execution units.
Reference: [12] <author> R. S. Nikhil, G. M. Papadopoulos, and Arvind, </author> <title> "*T: A multithreaded massively parallel architecture," </title> <booktitle> in Proc. of ISCA-19, </booktitle> <address> Gold Coast, Australia, </address> <pages> pp. 156-167, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: The MTA approach to scalable parallel processing is based on multithreading. In broad terms, a multithreaded architecture <ref> [1, 5, 7, 8, 11, 12, 14] </ref> is best characterized as an architecture designed to support the efficient concurrent execution of multiple threads of control. A thread is a sequence of instructions whose relative order is determined at compile time. <p> In comparing the MTA to other multithreaded machines, we note that the Empire [11], RWC-1 [14], and Tera [1], among others, are different from the MTA in that there is no clear separation between the execution unit and synchronization unit. Some other machines, such as *T <ref> [12] </ref>, have separate synchronization and execution units. A key difference between the MTA and *T is that the synchronization unit is user-programmable in the *T, 288 EU event queue queue ready PE . PE Interconnection Network cache memory local but not in the MTA. <p> Therefore, our runtime model supports a tree of activation frames in which each activation frame is dynamically linked to its caller. This was first proposed for dataflow [13] and later used in multithreaded systems <ref> [3, 12] </ref>. When a function is invoked in the MTA, an activation frame is allocated to represent that function instance. A frame pointer fp points to the base of the frame and is used to identify the frame uniquely. A function will usually contain many threads.
Reference: [13] <author> J. E. Rumbaugh, </author> <title> A Parallel Asynchronous Computer Architecture for Data Flow Programs. </title> <type> PhD thesis, </type> <institution> Mass. Inst. of Tech., </institution> <month> May </month> <year> 1975. </year>
Reference-contexts: Therefore, our runtime model supports a tree of activation frames in which each activation frame is dynamically linked to its caller. This was first proposed for dataflow <ref> [13] </ref> and later used in multithreaded systems [3, 12]. When a function is invoked in the MTA, an activation frame is allocated to represent that function instance. A frame pointer fp points to the base of the frame and is used to identify the frame uniquely.
Reference: [14] <author> S. Sakai, K. Okamoto, H. Matsuoka, H. Hirono, Y. Kodama, and M. Sato, "Super-threading: </author> <title> Architectural and software mechanisms for optimizing parallel computation," </title> <booktitle> in Conf. Proc., 1993 ICS, </booktitle> <address> Tokyo, Japan, </address> <pages> pp. 251-260, </pages> <month> Jul. </month> <year> 1993. </year>
Reference-contexts: The MTA approach to scalable parallel processing is based on multithreading. In broad terms, a multithreaded architecture <ref> [1, 5, 7, 8, 11, 12, 14] </ref> is best characterized as an architecture designed to support the efficient concurrent execution of multiple threads of control. A thread is a sequence of instructions whose relative order is determined at compile time. <p> Multithreading can be supported by external hardware which can be implemented with simple ASIC chips. In comparing the MTA to other multithreaded machines, we note that the Empire [11], RWC-1 <ref> [14] </ref>, and Tera [1], among others, are different from the MTA in that there is no clear separation between the execution unit and synchronization unit. Some other machines, such as *T [12], have separate synchronization and execution units.
Reference: [15] <author> K. B. Theobald, G. R. Gao, and L. J. Hendren, </author> <title> "Speculative execution and branch prediction on parallel machines," </title> <booktitle> in Conf. Proc., 1993 ICS, </booktitle> <address> Tokyo, Japan, </address> <pages> pp. 77-86, </pages> <month> Jul. </month> <year> 1993. </year> <month> 294 </month>
Reference-contexts: Many non-numerical programs, and even some numerical programs, have the potential for big improvements in speed if some computation is performed speculatively, i.e., before its need has been determined <ref> [15] </ref>. There are also many applications in which the program can search down many paths in the search space simultaneously, but a success in any subsearch satisfies the search conditions, i.e., an OR condition. The subsearches can often be done in parallel.
References-found: 15

