URL: http://www.cs.berkeley.edu/~pm/Papers/beymer_etal_cvpr97.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~pm/Abstracts/abstracts.html
Root-URL: 
Email: E-mail: fbeymer, pm, zephyr, malikg@cs.berkeley.edu  
Title: A Real-time Computer Vision System for Measuring Traffic Parameters  
Author: David Beymer, Philip McLauchlan, Benn Coifman, and Jitendra Malik 
Address: Berkeley, California, 94720-1776  
Affiliation: Dept. of Electrical Engineering and Computer Sciences University of California  
Abstract: For the problem of tracking vehicles on freeways using machine vision, existing systems work well in free-flowing traffic. Traffic engineers, however, are more interested in monitoring freeways when there is congestion, and current systems break down for congested traffic due to the problem of partial occlusion. We are developing a feature- based tracking approach for the task of tracking vehicles under congestion. Instead of tracking entire vehicles, vehicle sub-features are tracked to make the system robust to partial occlusion. In order to group together sub-features that come from the same vehicle, the constraint of common motion is used. In this paper we describe the system, a real-time implementation using a network of DSP chips, and experiments of the system on approximately 44 lane hours of video data. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K.D. Baker and G.D. Sullivan. </author> <title> Performance assessment of modelbased tracking. </title> <booktitle> In Proc. of the IEEE Workshop on Applications of Computer Vision, </booktitle> <pages> pp. 28-35, </pages> <address> Palm Springs, CA, </address> <year> 1992. </year>
Reference-contexts: the computer vision literature, the different tracking approaches for video data can be classified as follows. 2.1 3D Model based tracking Three-dimensional model-based vehicle tracking systems have previously been investigated by several research groups, the most prominent being the groups at Karl- sruhe [10] and at the University of Reading <ref> [1, 15] </ref>. The emphasis is on recovering trajectories and models with high accuracy for a small number of vehicles. The most serious weakness of this approach is the reliance on detailed geometric object models.
Reference: [2] <author> Yaakov Bar-Shalom and Thomas E. Fortmann. </author> <title> Tracking and Data Association. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1988. </year>
Reference: [3] <author> David Beymer and Jitendra Malik. </author> <title> Tracking vehicles in congested traffic. </title> <booktitle> In SPIE Vol. </booktitle> <month> 2902, </month> <title> Transportation Sensors and Controls: Collision Avoidance, Traffic Management, </title> <booktitle> and ITS, </booktitle> <pages> pages 8-18, </pages> <address> Boston, MA, </address> <month> November </month> <year> 1996. </year>
Reference-contexts: We have also considered the more general case where P a and P b are not at the same distance from the camera. Space considerations in these proceedings prevent a discussion of this case; please see <ref> [3] </ref> for the details. 4 Algorithm 4.1 Off-line camera definition Before running the tracking and grouping system, the user specifies some camera-specific parameters off-line.
Reference: [4] <author> A. Chatziioanou, S. Hockaday, L. Ponce, S. Kaighn and C. Staley. </author> <title> Video Image Processing Systems Applications in Transportation, Phase II. </title> <type> Final Report, </type> <institution> Calif. Poly. State Univ., </institution> <address> San Luis Obispo, Calif., </address> <month> Dec. 30, </month> <year> 1994. </year>
Reference-contexts: Real-time operation of the system. Even though a number of commercial systems for traffic monitoring have been introduced recently, many of these criteria still cannot be met. In a recent evaluation of a group of these commercial systems <ref> [4] </ref>, problems were reported with congestion, long shadows linking together vehicles, and the transition between night and day.
Reference: [5] <author> L.C. Edie. </author> <title> Discussion of traffic stream measurements and defini-tions. </title> <booktitle> In Proc. Second International Symposium on the Theory of Traffic Flow, OECD, </booktitle> <pages> pages 139-154, </pages> <address> Paris, France, </address> <year> 1963. </year>
Reference-contexts: Headway. Average spacing between vehicles. These parameters are computed separately for each lane of traffic and are averaged over a period of time (taken to be 5 minutes in our experiments). Also, it should be apparent that these are not independent variables; we use the methodology from Edie <ref> [5] </ref> to compute these parameters from the vehicle track data. Ground truth is provided from inductive loop data that was collected concurrently with the video data. Each lane of traffic has two loops separated by 20 feet, giving us an effective speed trap for measuring velocity.
Reference: [6] <author> W. Forstner and E. Gulch. </author> <title> A fast operator for detection and precise location of distinct points, corners, and centers of circular features. </title> <booktitle> In Proc. of the Intercommission Conf. on Fast Processing of Photogrammetric Data, </booktitle> <pages> pages 281-305, </pages> <year> 1987. </year>
Reference-contexts: Corner features are the chosen sub-features since they can be reliably tracked. Our corner detector computes the windowed second moment matrix by averaging in a spatial window the 2x2 matrix, rIrI T , where rI is the image gradient <ref> [6] </ref>. Corners are declared where the numerical rank of this matrix is 2 (smaller eigenvalue above threshold). Fig. 3 shows some example corner features detected by the system.
Reference: [7] <author> Arthur Gelb, </author> <title> editor. Applied Optimal Estimation. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA., </address> <year> 1974. </year>
Reference-contexts: The tracking module tracks corner sub-features from the detection region at the bottom of the image to the exit region near the top. To address the problem of noisy measurements, we employ Kalman filtering <ref> [7] </ref> to provide most likely estimates of the state of a vehicle sub-feature based on accumulated observations. In our system, the state vector contains sub-feature positions and velocities (X; Y; _ X; _ Y ) in the world coordinate system; vehicle acceleration is captured in the system dynamics noise process.
Reference: [8] <author> Klaus-Peter Karmann and Achim von Brandt. </author> <title> Moving object recog-nition using an adaptive background memory. In V Cappellini, ed-itor, Time-Varying Image Processing and Moving Object Recognition, 2. </title> <publisher> Elsevier, </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1990. </year>
Reference-contexts: Initializa- tion of the process is most easily done by the background subtraction technique. A Kalman filter-based adaptive background model <ref> [8, 9] </ref> allows the background estimate to evolve as the weather and time of day affect lighting conditions. Foreground objects (vehicles) are detected by subtracting the incoming image from the current background estimate, looking for pixels where this difference image is above some threshold and then finding connected components.
Reference: [9] <author> Michael Kilger. </author> <title> A shadow handler in a video-based real-time traffic monitoring system. </title> <booktitle> In IEEE Workshop on Applications of Computer Vision, </booktitle> <pages> pages 1060-1066, </pages> <address> Palm Springs, CA, </address> <year> 1992. </year>
Reference-contexts: Initializa- tion of the process is most easily done by the background subtraction technique. A Kalman filter-based adaptive background model <ref> [8, 9] </ref> allows the background estimate to evolve as the weather and time of day affect lighting conditions. Foreground objects (vehicles) are detected by subtracting the incoming image from the current background estimate, looking for pixels where this difference image is above some threshold and then finding connected components.
Reference: [10] <author> D. Koller, K. Daniilidis, and H.-H. Nagel. </author> <title> Model-based Object Tracking in Monocular Image Sequences of Road Traffic Scenes. </title> <journal> International Journal of Computer Vision, </journal> <volume> 10: </volume> <year> 257-281,1993. </year>
Reference-contexts: In the computer vision literature, the different tracking approaches for video data can be classified as follows. 2.1 3D Model based tracking Three-dimensional model-based vehicle tracking systems have previously been investigated by several research groups, the most prominent being the groups at Karl- sruhe <ref> [10] </ref> and at the University of Reading [1, 15]. The emphasis is on recovering trajectories and models with high accuracy for a small number of vehicles. The most serious weakness of this approach is the reliance on detailed geometric object models.
Reference: [11] <author> D. Koller, J. Weber, and J. Malik. </author> <title> Robust multiple car tracking with occlusion reasoning. </title> <booktitle> In ECCV, </booktitle> <pages> pp. 189-196, </pages> <address> Stockholm, Sweden, </address> <month> May 2-6, </month> <year> 1994. </year>
Reference-contexts: Second, cameras are less disruptive and less costly to install than loop detectors, which require digging up the road surface. For some years, our group has been developing a prototype vision-based traffic surveillance system <ref> [11, 12] </ref>. The core idea is to have video cameras mounted on poles or other tall structures looking down at the traffic scene. <p> The idea is to have a representation of the bounding contour of the object and keep dynamically updating it. The previous system for vehicle tracking developed in our group <ref> [11, 12] </ref> was based on this approach. The advantage of having a contour based representation instead of a region based representation is reduced computational complexity. However, the inability to segment vehicles that are partially occluded remains. <p> However, the inability to segment vehicles that are partially occluded remains. If one could initialize a separate contour for each vehicle, then one could track even in the presence of partial occlusion <ref> [11] </ref>. However, initialization is the difficult part of the problem! 2.4 Feature based tracking Finally, yet another approach to tracking abandons the idea of tracking objects as a whole but instead tracks sub-features such as distinguishable points or lines on the object.
Reference: [12] <author> D. Koller, J. Weber, T. Huang, J. Malik, G. Ogasawara, B. Rao, and S. Russell. </author> <title> Towards robust automatic traffic scene analysis in real-time. </title> <booktitle> In ICPR, </booktitle> <address> Israel, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: Second, cameras are less disruptive and less costly to install than loop detectors, which require digging up the road surface. For some years, our group has been developing a prototype vision-based traffic surveillance system <ref> [11, 12] </ref>. The core idea is to have video cameras mounted on poles or other tall structures looking down at the traffic scene. <p> The idea is to have a representation of the bounding contour of the object and keep dynamically updating it. The previous system for vehicle tracking developed in our group <ref> [11, 12] </ref> was based on this approach. The advantage of having a contour based representation instead of a region based representation is reduced computational complexity. However, the inability to segment vehicles that are partially occluded remains.
Reference: [13] <author> H.A. Mallot, H.H. Bulthoff, J.J. Little, and S. Bohrer. </author> <title> Inverse per-spective mapping simplifies optical flow computation and obstacle detection. </title> <journal> Biological Cybernetics, </journal> <volume> 64(3) </volume> <pages> 177-185, </pages> <year> 1991. </year>
Reference: [14] <author> P. Michalopoulos. </author> <title> Vehicle detection video through image process-ing: the Autoscope system. </title> <journal> IEEE Trans. on Vehicular Technology, </journal> <volume> 40 </volume> <pages> 21-29, </pages> <year> 1991. </year>
Reference: [15] <author> G.D.Sullivan. </author> <title> Visual interpretation of known objects in constrained scenes. </title> <journal> In Phil. Trans. Roy. Soc (B), </journal> <volume> 337: </volume> <pages> 361-370, </pages> <year> 1992. </year>
Reference-contexts: the computer vision literature, the different tracking approaches for video data can be classified as follows. 2.1 3D Model based tracking Three-dimensional model-based vehicle tracking systems have previously been investigated by several research groups, the most prominent being the groups at Karl- sruhe [10] and at the University of Reading <ref> [1, 15] </ref>. The emphasis is on recovering trajectories and models with high accuracy for a small number of vehicles. The most serious weakness of this approach is the reliance on detailed geometric object models.
References-found: 15

