URL: http://www.cs.ubc.ca/spider/pope/AAAI93-Paper.ps.gz
Refering-URL: http://www.cs.ubc.ca/spider/pope/AAAI93-Paper.html
Root-URL: 
Email: Email:-pope,lowe-@cs.ubc.ca  
Title: Learning 3D Object Recognition Models from 2D Images  
Author: Arthur R. PopeDavid G. Lowe 
Address: Vancouver, B.C., CanadaV6T 1Z2  
Affiliation: Department of Computer Science, University of British Columbia  
Abstract: To recognize an object in an image one must have some internal model of how that object may appear. We show how to learn such a model from a series of training images depicting a class of objects. The model represents a 3D object by a set of characteristic views, each defining a probability distribution over variation in object appearance. Features identified in an image through perceptual organization are represented by a graph whose nodes include feature labels and numeric measurements. Image graphs are partitioned into characteristic views by an incremental conceptual clustering algorithm. A learning procedure generalizes multiple image graphs to form a characteristic view graph in which the numeric measure - ments are described by probability distributions. A match - ing procedure, using a similarity metric based on a non parametric probability density estimator, compares image and characteristic view graphs to identify an instance of a modeled object in an image. We present experimental results from a system constructed to test this approach. The system is demonstrated learning to recognize partially occluded objects in images using shape cues. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Bergevin and M.D. Levine, </author> <title> Extraction of Line Drawing Features for Object Recognition, </title> <booktitle> Pattern Recognition 25 (1992) 319334. </booktitle>
Reference-contexts: All are found by a bottomup, datadriven process of grouping and abstraction controlled by several thresholds and other parameters (like, for example, <ref> [1] </ref>). Once detected in an image, a feature is represented by a token that records the type of feature plus its image location, orientation, and scale.
Reference: [2] <author> J.H. Connell and M. Brady, </author> <title> Generating and Generalizing Models of Visual Objects, </title> <booktitle> Artificial Intelligence 31 (1987) 159183. </booktitle>
Reference-contexts: Moreover, objects can be recognized as similar in general appearance, yet still be distinguished according to their detailed features. 2. Related research Among published model learning approaches, one due to Connell and Brady <ref> [2] </ref> most closely resembles our own. They use graphs to represent the part/whole and adjacency relations among object regions described by smoothed local symmetries. An attribute of a region, such as its elongation or curvature, is encoded symbolically by the presence or absence of additional graph nodes.
Reference: [3] <author> D.H. Fisher, </author> <title> Knowledge Acquisition Via Incremental Conceptual Clustering, </title> <note> Machine Learning 2 (1987) 139-172. </note>
Reference-contexts: Here well describe first the method of partitioning into clusters, and then the method of merging each clusters contents into a single CV graph. An incremental conceptual clustering algorithm is used to create clusters among the training images as they are obtained. Like, for example, COBWEB <ref> [3] </ref>, the algorithm makes a series of local changes in cluster partitions according to a global measure of cluster quality while training examples are added incrementally.
Reference: [4] <author> D.W. Jacobs, </author> <title> Grouping for Recognition , MIT AI Lab Technical Report 1177 (1989). </title>
Reference-contexts: Two important refinements of this procedure remain for further work. First, an indexing scheme should be used to rank CV graphs for matching. Indexing could, for example, employ groups of features, as in <ref> [4] </ref>. Secondly, a decision procedure is needed that will validate an optimal match, and either accept or reject it. The procedure will likely need more information than that provided by the graph similarity measure, g, which confounds the effects of both occlusion and shape variation.
Reference: [5] <author> D.G. Lowe, </author> <title> Perceptual Organization and Visual Recognition (Kluwer 1985). </title>
Reference-contexts: For our experiments, these features include line and circular arc segments, their junctions, parallel pairs of lines and arcs, closed regions, and ribbons. Features are intended to satisfy the viewpoint invariance and detection conditions described in <ref> [5] </ref>, to represent explicitly all important appearance dis - tinctions among objects of interest, and to be easily detect - ed. All are found by a bottomup, datadriven process of grouping and abstraction controlled by several thresholds and other parameters (like, for example, [1]).
Reference: [6] <author> B.A. McArthur and A.K.C. Wong, </author> <title> Random graph representation for 3-D object models, </title> <booktitle> in Proc. Model-Based Vision Development and Tools (SPIE Vol. </booktitle> <volume> 1609, </volume> <year> 1991) </year> <month> 229238. </month>
Reference-contexts: In representing a model we use an attributed graph in which attribute values are characterized by probability dis - tributions. This structure is similar to what Wong and others have called a random graph. He and McArthur <ref> [6] </ref> use the random graph to represent and to learn an object model from images in which the pose or feature correspondences have been provided. Attributes record feature positions in 3D space, and their distributions are modeled as Gaussian.
Reference: [7] <author> A.R. Pope and D.G. Lowe, </author> <title> Learning Object Recognition Models from Images, </title> <booktitle> in: Proc. </booktitle> <month> ICCV </month> <year> (1993) </year> <month> 296301. </month>
Reference-contexts: The learning procedure must generalize enough to overcome insignificant variation, but not so much as to confuse dissimilar objects. And the procedure used to identify modeled objects in images must tolerate the likely range of mismatch between model and image. In a previous paper <ref> [7] </ref>, we considered the problem of learning a single characteristic view from a series of 2D training images. We are now extending that work by considering the problem of learning a set of characteristic views, automatically chosen to be sufficient for represent - ing all aspects of a 3D object. <p> The measure combines empirical statis tics using the rules of Bayesian probability theory to judge the likelihood that a given pairing of CV tokens with image tokens corresponds to an actual instance of the object in the image. Since the graph similarity measure is described in detail in <ref> [7] </ref> we will only briefly summarize it here. <p> The learning procedure discovers the relative importance of each feature, and the extent to which its attributes may be expected to vary. An illustration of the systems generalization and discrimination perfor - mance may be found in <ref> [7] </ref>.
Reference: [8] <author> J. Rissanen, </author> <title> A universal prior for integers and estimation by minimum description length, </title> <booktitle> Annals of Statistics 11 (1983) 416431. </booktitle>
Reference-contexts: Like, for example, COBWEB [3], the algorithm makes a series of local changes in cluster partitions according to a global measure of cluster quality while training examples are added incrementally. We use a measure of 4 cluster quality, based on Rissanens minimum description length principle <ref> [8] </ref>, that seeks to optimize both the com - plexity of the model and the degree to which the model accounts for the training images.

References-found: 8

