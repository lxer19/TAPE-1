URL: file://ftp.cs.utexas.edu/pub/mooney/papers/contex-acl-97.ps.Z
Refering-URL: http://www.isi.edu/~ulf/diss_abstract.html
Root-URL: 
Email: ulf@cs.utexas.edu mooney@cs.utexas.edu  
Title: Learning Parse and Translation Decisions From Examples With Rich Context  
Author: Ulf Hermjakob and Raymond J. Mooney 
Address: Austin, TX 78712, USA  
Affiliation: Dept. of Computer Sciences University of Texas at Austin  
Date: 1997 482  
Note: Appeared in Proceedings of the Association for Computational Linguistics (ACL)  
Abstract: We present a knowledge and context-based system for parsing and translating natural language and evaluate it on sentences from the Wall Street Journal. Applying machine learning techniques, the system uses parse action examples acquired under supervision to generate a deterministic shift-reduce parser in the form of a decision structure. It relies heavily on context, as encoded in features which describe the morphological, syntactic, semantic and other aspects of a given parse state.
Abstract-found: 1
Intro-found: 1
Reference: <author> E. Black, J. Lafferty, and S. Roukos. </author> <year> 1992. </year> <title> Development and evaluation of a broad-coverage probabilistic grammar of English-language computer manuals. </title> <booktitle> In 30th Proceedings of the ACL, </booktitle> <pages> pages 185-192. </pages>
Reference: <author> M. J. Collins. </author> <year> 1996. </year> <title> A New Statistical Parser Based on Bigram Lexical Dependencies. </title> <booktitle> In 34th Proceedings of the ACL, </booktitle> <pages> pages 184-191. </pages>
Reference-contexts: While this necessitates the involvement of a parsing supervisor for training, we are able to perform deterministic parsing and get already very good test results for only 256 training sentences. <ref> (Collins, 1996) </ref> focuses on bigram lexical dependencies (Bld).
Reference: <author> U. Hermjakob. </author> <year> 1997. </year> <title> Learning Parse and Translation Decisions From Examples With Rich Context. </title> <type> Ph.D. thesis, </type> <institution> University of Texas at Austin, Dept. </institution> <note> of Computer Sciences TR 97-12. </note> <editor> file://ftp.cs.utexas.edu/pub/mooney/papers/herm jakob-dissertation-97.ps.Z D. M. Magerman. </editor> <booktitle> 1995. Statistical Decision-Tree Models for Parsing In 33rd Proceedings of the ACL, </booktitle> <pages> pages 276-283. </pages>
Reference: <author> M. P. Marcus. </author> <year> 1980. </year> <title> A Theory of Syntactic Recognition for Natural Language. </title> <publisher> MIT Press. </publisher>
Reference-contexts: Compared with standard statistical methods, our system relies on deeper analysis and more supervision, but radically fewer examples. 2 Basic Parsing Paradigm As the basic mechanism for parsing text into a shallow semantic representation, we choose a shift-reduce type parser <ref> (Marcus, 1980) </ref>. It breaks parsing into an ordered sequence of small and manageable parse actions such as shift and reduce.
Reference: <author> M. P. Marcus, B. Santorini, and M. A. Marcinkie-wicz. </author> <year> 1993. </year> <title> Building a Large Annotated Corpus of English: The Penn Treebank. </title> <booktitle> In Computational Linguistics 19 (2), </booktitle> <pages> pages 184-191. </pages>
Reference-contexts: simple features that were limited to syntax only, by adding more background knowledge and by introducing a sophisticated machine learning component. (Magerman, 1995) uses a decision tree model similar to ours, training his system Spatter with parse action sequences for 40,000 Wall Street Journal sentences derived from the Penn Treebank <ref> (Marcus et al., 1993) </ref>. Questioning the traditional n-grams, Magerman already advocates a heavier reliance on contextual information. Going beyond Magerman's still relatively rigid set of 36 features, we propose a yet richer, basically unlimited feature language set.
Reference: <author> S. Nirenburg, J. Carbonell, M. Tomita, </author> <title> and K. </title>
Reference: <author> Goodman. </author> <year> 1992. </year> <title> Machine Translation: A Knowledge-Based Approach. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> J. R. Quinlan. </author> <year> 1986. </year> <title> Induction of decision trees. </title> <booktitle> In Machine Learning 1 (1), </booktitle> <pages> pages 81-106. </pages>
Reference-contexts: A set of parse examples, as already described in the previous section, is then fed into an ID3-based learning routine that generates a decision structure, which can then `classify' any given parse state by proposing what parse action to perform next. We extended the standard ID3 model <ref> (Quinlan, 1986) </ref> to more general hybrid decision structures. In our tests, the best performing structure was a decision list (Rivest, 1987) of hierarchical decision trees, whose simplified basic structure is illustrated in figure 3.
Reference: <author> R. L. Rivest. </author> <year> 1987. </year> <title> Learning Decision Lists. </title> <booktitle> In Machine Learning 2, </booktitle> <pages> pages 229-246. </pages>
Reference-contexts: We extended the standard ID3 model (Quinlan, 1986) to more general hybrid decision structures. In our tests, the best performing structure was a decision list <ref> (Rivest, 1987) </ref> of hierarchical decision trees, whose simplified basic structure is illustrated in figure 3. Note that in the `reduce operation tree', the system first decides whether or not to perform a reduction before deciding on a specific reduction.
Reference: <author> R. F. Simmons and Yeong-Ho Yu. </author> <year> 1992. </year> <title> The Acquisition and Use of Context-Dependent Grammars for English. </title> <booktitle> In Computational Linguistics 18 (4), </booktitle> <pages> pages 391-418. </pages>
Reference-contexts: Most correlation values, incl. for labeled precision are negative, because a higher (better) labeled precision correlates with a numerically lower (better) translation score on the 1.0 (best) to 6.0 (worst) translation evaluation scale. 7 Related Work Our basic parsing and interactive training paradigm is based on <ref> (Simmons and Yu, 1992) </ref>.
Reference: <author> F. Smadja, K. R. KcKeown and V. Hatzivassiloglou. </author> <year> 1996. </year> <title> Translating Collocations for Bilingual Lexicons: A Statistical Approach. </title> <booktitle> In Computational Linguistics 22 (1), </booktitle> <pages> pages 1-38. </pages> <address> Globalink. http://www.globalink.com/home.html Oct. 1996. Logos. http://www.logos-ca.com/ Oct. 1996. Systran. http://systranmt.com/ Oct. </address> <year> 1996. </year>
Reference-contexts: We believe that an extensive collection of complex translation pairs in the bilingual dictionary is critical for translation quality and we are confident that its acquisition can be at least partially automated by using techniques like those described in <ref> (Smadja et al., 1996) </ref>. Complex translation entries are preprocessed using the same parser as for normal text. During the transfer process, the resulting parse tree pairs are then accessed using pattern matching.
References-found: 11

