URL: ftp://ftp.engr.orst.edu/pub/dambrosi/uai-93.ps.Z
Refering-URL: http://www.cs.orst.edu/~dambrosi/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Incremental Efficient Incremental Abstract  
Note: Bruce D'Ambrosio  
Abstract-found: 0
Intro-found: 1
Reference: [2] <author> G. Cooper. </author> <title> The computational complexity of probabilistic inference using bayesian belief networks. </title> , <address> 42(2-3):393-406, </address> <year> 1990. </year>
Reference-contexts: A belief net is a compact representation for the joint probability distribution over a set of variables. The representation consists of a directed acyclic graph over the variables and a set of marginal and conditional probability distributions, one for each variable [23]. While probabilistic inference in general is NP-hard <ref> [2] </ref>, current state-of-the-art belief-net algorithms exploit the independence information in the graph to construct efficient computations for probability distributions not explicitly stored in the belief net [23], [17], [25].
Reference: [3] <author> B. D'Ambrosio. </author> <title> Process, structure, and modularity in reasoning under uncertainty. In , pages 64-72. </title> <publisher> AAAI, </publisher> <month> August </month> <year> 1988. </year>
Reference-contexts: Also, the services offered by current belief-net based systems are not well matched to the needs of higher level problem solvers. As we discussed in <ref> [3] </ref> and [4], problem solvers typically interleave model construction, revision, and evaluation.
Reference: [4] <author> B. D'Ambrosio. </author> <title> Incremental evaluation and construction of defeasible probabilistic models. </title> , <month> July </month> <year> 1990. </year>
Reference-contexts: Also, the services offered by current belief-net based systems are not well matched to the needs of higher level problem solvers. As we discussed in [3] and <ref> [4] </ref>, problem solvers typically interleave model construction, revision, and evaluation.
Reference: [5] <author> B. D'Ambrosio. </author> <title> Local expression languages for probabilistic dependence. </title> <booktitle> In , pages 95-102, </booktitle> <address> Palo Alto, July 1991. </address> <publisher> Morgan Kaufmann, Publishers. </publisher>
Reference-contexts: All modern belief net algorithms exploit the conditional independence information contained in the topology of a belief net to reduce computational complexity. However, there is often considerable structure within the conditional distributions in a belief net <ref> [5] </ref>, [13], [26], [12]. This structure can and should be exploited to improve efficiency. For a discussion of how this structural information is captured and exploited in SPI see [5]. <p> However, there is often considerable structure within the conditional distributions in a belief net <ref> [5] </ref>, [13], [26], [12]. This structure can and should be exploited to improve efficiency. For a discussion of how this structural information is captured and exploited in SPI see [5]. Finally, there is often considerable numeric structure within a belief net, in the form of skewness of distributions (a distribution is when one of the probability masses in the distribution is larger than the others, we will formalize this later).
Reference: [6] <author> B. D'Ambrosio. </author> <title> Value-driven real-time diagnosis. </title> <note> In , October 1992. </note>
Reference-contexts: This later is work in progress, and not fully implemented at this time. We have been applying term computation to a variety of problems, but our core application is real-time decision-making <ref> [6] </ref> (although not discussed in this paper, the approach easily extends to arbitrary influence diagrams). Figure 4 shows how term computation using Z* search scales with problem size (number of components), as compared with exact, exhaustive evaluation using a traditional belief net inference algorithm (SPI, [25]).
Reference: [7] <author> B. D'Ambrosio and J. Edwards. </author> <title> A partitioned atms. </title> <booktitle> In , pages 330-336. IEEE, </booktitle> <month> February </month> <year> 1991. </year>
Reference-contexts: Also, the services offered by current belief-net based systems are not well matched to the needs of higher level problem solvers. As we discussed in [3] and [4], problem solvers typically interleave model construction, revision, and evaluation. One class of propositional representation service, truth maintenance systems [11], [8], [20], <ref> [7] </ref>, is optimized for this kind of use: truth maintenance systems typically provide incremental (but monotonic) model construction facilities, and incrementally update inference when the propositional model is expanded.
Reference: [8] <author> J. de Kleer. </author> <title> An assumption-based tms. </title> , <address> 28(2):127 - 162, </address> <month> March </month> <year> 1986. </year>
Reference-contexts: Also, the services offered by current belief-net based systems are not well matched to the needs of higher level problem solvers. As we discussed in [3] and [4], problem solvers typically interleave model construction, revision, and evaluation. One class of propositional representation service, truth maintenance systems [11], <ref> [8] </ref>, [20], [7], is optimized for this kind of use: truth maintenance systems typically provide incremental (but monotonic) model construction facilities, and incrementally update inference when the propositional model is expanded.
Reference: [9] <author> J. de Kleer. </author> <title> Focusing on probable diagnoses. In , pages 842-848. </title> <publisher> AAAI, </publisher> <month> July </month> <year> 1991. </year>
Reference-contexts: Also, while resource incrementality was not a feature of early TMS's, deK-leer has found it desirable to extend the ATMS to include resource incrementality through various "focusing" mechanisms [10], <ref> [9] </ref>. We believe a low-level representation service should have two key properties: it should be and .
Reference: [10] <author> J. de Kleer and B. Williams. </author> <title> Diagnosis with behavioral modes. </title> <booktitle> In , pages 1324-1330. IJCAI, </booktitle> <month> August </month> <year> 1984. </year>
Reference-contexts: Also, while resource incrementality was not a feature of early TMS's, deK-leer has found it desirable to extend the ATMS to include resource incrementality through various "focusing" mechanisms <ref> [10] </ref>, [9]. We believe a low-level representation service should have two key properties: it should be and . <p> This selection criterion is similar to the techniques used by deKleer <ref> [10] </ref> and Henrion [15]. Both use search on restricted classes of networks for the diagnostic task of finding most likely composite hypotheses, with good results.
Reference: [11] <author> J. Doyle. </author> <title> A truth maintenance system. </title> , <booktitle> 12(3) </booktitle> <pages> 231-272, </pages> <year> 1979. </year>
Reference-contexts: Also, the services offered by current belief-net based systems are not well matched to the needs of higher level problem solvers. As we discussed in [3] and [4], problem solvers typically interleave model construction, revision, and evaluation. One class of propositional representation service, truth maintenance systems <ref> [11] </ref>, [8], [20], [7], is optimized for this kind of use: truth maintenance systems typically provide incremental (but monotonic) model construction facilities, and incrementally update inference when the propositional model is expanded.
Reference: [12] <author> D. Geiger and D. Heckerman. </author> <booktitle> Advances in probabilistic reasoning. </booktitle> <pages> In , pages 118-126. </pages> <publisher> Morgan Kaufmann, Publishers, </publisher> <month> July </month> <year> 1991. </year>
Reference-contexts: All modern belief net algorithms exploit the conditional independence information contained in the topology of a belief net to reduce computational complexity. However, there is often considerable structure within the conditional distributions in a belief net [5], [13], [26], <ref> [12] </ref>. This structure can and should be exploited to improve efficiency. For a discussion of how this structural information is captured and exploited in SPI see [5].
Reference: [13] <author> D. Heckerman. </author> <title> A tractable inference algorithm for diagnosing multiple diseases. </title> <booktitle> In , pages 174-181, </booktitle> <month> August </month> <year> 1989. </year>
Reference-contexts: All modern belief net algorithms exploit the conditional independence information contained in the topology of a belief net to reduce computational complexity. However, there is often considerable structure within the conditional distributions in a belief net [5], <ref> [13] </ref>, [26], [12]. This structure can and should be exploited to improve efficiency. For a discussion of how this structural information is captured and exploited in SPI see [5].
Reference: [14] <author> David Heckerman and Eric. Horvitz. </author> <title> On the expressiveness of rule-based systems for reasoning with uncertainty. </title> <booktitle> In , pages 121 - 126. AAAI, </booktitle> <month> August </month> <year> 1987. </year>
Reference: [15] <author> M. Henrion. </author> <title> Search-based methods to bound diagnostic probabilities in very large belief nets. In , pages 142-150. </title> <publisher> Morgan Kaufmann, Publishers, </publisher> <month> July </month> <year> 1991. </year>
Reference-contexts: Several systems have explored exploitation of this structure [22], [16], <ref> [15] </ref>. 2. Efficiency with respect to resource incremental-ity: We expect an incremental system to be only minimally more expensive than a non-incremental system on comparable tasks. <p> It would be easy to construct a term computation system which merely enumerated elements of the full joint distribution across all variables in a network, as in our example. Indeed, some existing proposals for anytime probabilistic inference essentially do this <ref> [15] </ref>. However, such an approach can be inefficient. There are several sources for this inefficiency: First, there would be a time inefficiency due to unnecessary repetition of sub-computations (eg, the computation of ( ) ( ) in our example). <p> This selection criterion is similar to the techniques used by deKleer [10] and Henrion <ref> [15] </ref>. Both use search on restricted classes of networks for the diagnostic task of finding most likely composite hypotheses, with good results.
Reference: [16] <author> E. Horvitz, H. J. Suermondt, and G. Cooper. </author> <title> Bounded conditioning: Flexible inference for decisions under scarce resources. </title> <note> In , August 1989. </note>
Reference-contexts: Finally, there is often considerable numeric structure within a belief net, in the form of skewness of distributions (a distribution is when one of the probability masses in the distribution is larger than the others, we will formalize this later). Several systems have explored exploitation of this structure [22], <ref> [16] </ref>, [15]. 2. Efficiency with respect to resource incremental-ity: We expect an incremental system to be only minimally more expensive than a non-incremental system on comparable tasks.
Reference: [17] <author> S. Lauritzen and D. Spiegelhalter. </author> <title> Local computations with probabilities on graphical structures and their application to expert systems. , B 50, </title> <year> 1988. </year>
Reference-contexts: While probabilistic inference in general is NP-hard [2], current state-of-the-art belief-net algorithms exploit the independence information in the graph to construct efficient computations for probability distributions not explicitly stored in the belief net [23], <ref> [17] </ref>, [25]. However, in practice computational cost still grows rapidly [18] (except in the case of a few special-case net topologies), limiting application of these techniques to belief nets with a few hundred variables at most.
Reference: [18] <author> Z. Li. </author> <title> Experimental characterization of several algorithms for inference in belief nets. </title> <type> Technical report, Master's thesis, </type> <institution> CS Dept., Oregon State University, </institution> <year> 1990. </year>
Reference-contexts: While probabilistic inference in general is NP-hard [2], current state-of-the-art belief-net algorithms exploit the independence information in the graph to construct efficient computations for probability distributions not explicitly stored in the belief net [23], [17], [25]. However, in practice computational cost still grows rapidly <ref> [18] </ref> (except in the case of a few special-case net topologies), limiting application of these techniques to belief nets with a few hundred variables at most. Also, the services offered by current belief-net based systems are not well matched to the needs of higher level problem solvers.
Reference: [19] <author> Z. Li and B. D'Ambrosio. </author> <title> An efficient approach to probabilistic inference in belief nets. </title> <booktitle> In . Canadian Association for Artificial Intelligence, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: Construction of an optimal evaluation poly-tree for an arbitrary query set is a hard problem <ref> [19] </ref>. However, simple, polynomial-time greedy heuristics perform quite well, and are described in [19]. <p> Construction of an optimal evaluation poly-tree for an arbitrary query set is a hard problem <ref> [19] </ref>. However, simple, polynomial-time greedy heuristics perform quite well, and are described in [19].
Reference: [20] <author> D. McDermott. </author> <title> A general framework for reason maintenance. </title> , <booktitle> 50(3) </booktitle> <pages> 289-330, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: Also, the services offered by current belief-net based systems are not well matched to the needs of higher level problem solvers. As we discussed in [3] and [4], problem solvers typically interleave model construction, revision, and evaluation. One class of propositional representation service, truth maintenance systems [11], [8], <ref> [20] </ref>, [7], is optimized for this kind of use: truth maintenance systems typically provide incremental (but monotonic) model construction facilities, and incrementally update inference when the propositional model is expanded.
Reference: [21] <author> J. Pearl. </author> <title> Distributed revision of composite beliefs. </title> , <booktitle> 33(2) </booktitle> <pages> 173-216, </pages> <year> 1987. </year>
Reference: [22] <author> J. Pearl. </author> <title> Evidential reasoning using stochastic simulation of causal models. </title> , <booktitle> 32(2) </booktitle> <pages> 245-258, </pages> <year> 1987. </year>
Reference-contexts: Finally, there is often considerable numeric structure within a belief net, in the form of skewness of distributions (a distribution is when one of the probability masses in the distribution is larger than the others, we will formalize this later). Several systems have explored exploitation of this structure <ref> [22] </ref>, [16], [15]. 2. Efficiency with respect to resource incremental-ity: We expect an incremental system to be only minimally more expensive than a non-incremental system on comparable tasks.
Reference: [23] <author> J. </author> <title> Pearl. </title> . <publisher> Morgan Kaufmann, </publisher> <address> Palo Alto, </address> <year> 1988. </year>
Reference-contexts: A belief net is a compact representation for the joint probability distribution over a set of variables. The representation consists of a directed acyclic graph over the variables and a set of marginal and conditional probability distributions, one for each variable <ref> [23] </ref>. While probabilistic inference in general is NP-hard [2], current state-of-the-art belief-net algorithms exploit the independence information in the graph to construct efficient computations for probability distributions not explicitly stored in the belief net [23], [17], [25]. <p> over the variables and a set of marginal and conditional probability distributions, one for each variable <ref> [23] </ref>. While probabilistic inference in general is NP-hard [2], current state-of-the-art belief-net algorithms exploit the independence information in the graph to construct efficient computations for probability distributions not explicitly stored in the belief net [23], [17], [25]. However, in practice computational cost still grows rapidly [18] (except in the case of a few special-case net topologies), limiting application of these techniques to belief nets with a few hundred variables at most. <p> of the evidence variable, requiring pruning of the mass dependency structure of the affected terms and propagation of the resulting mass changes upward through the evaluation poly-tree. (3) Certain query evaluation subtrees will require additional child subtrees (effectively, conditioning on the new evidence seethe discussion of d-separation in, for example, <ref> [23] </ref> for further details). We handle this by invalidating and recomputing all streams on a line from the poly-tree node at which a new subtree is added to the roots of the evaluation poly-tree.
Reference: [24] <author> D. Poole. </author> <title> Search in bayesian horn clause networks. </title> <note> In , October 1992. </note>
Reference: [25] <author> R. Shachter, B. D'Ambrosio, and B. DelFavero. </author> <title> Symbolic probabilistic inference in belief networks. In , pages 126-131. </title> <publisher> AAAI, </publisher> <month> August </month> <year> 1990. </year>
Reference-contexts: While probabilistic inference in general is NP-hard [2], current state-of-the-art belief-net algorithms exploit the independence information in the graph to construct efficient computations for probability distributions not explicitly stored in the belief net [23], [17], <ref> [25] </ref>. However, in practice computational cost still grows rapidly [18] (except in the case of a few special-case net topologies), limiting application of these techniques to belief nets with a few hundred variables at most. <p> However, note that on completion of these updates streams may not contain the same number of completed terms. The underlying theory has already been developed in <ref> [25] </ref>. The contribution here is simply to point out its applicability to incremental term computation. We consider monotonic network growth only. Network extensions include both arc and node addition (we do not currently permit modifications to variable value spaces). <p> Figure 4 shows how term computation using Z* search scales with problem size (number of components), as compared with exact, exhaustive evaluation using a traditional belief net inference algorithm (SPI, <ref> [25] </ref>). The two tasks are computation of the most likely composite hypothesis (MLCH), and computation of the optimal action over a range of alternatives including sensing and repair actions. The exact MLCH computation is performed using the algorithm by Li presented elsewhere in this conference.
Reference: [26] <author> R. Shachter and R. Fung. </author> <title> Contingent influence diagrams. </title> <type> Tech report, </type> <institution> Advanced Decision Systems, </institution> <month> September </month> <year> 1990. </year>
Reference-contexts: All modern belief net algorithms exploit the conditional independence information contained in the topology of a belief net to reduce computational complexity. However, there is often considerable structure within the conditional distributions in a belief net [5], [13], <ref> [26] </ref>, [12]. This structure can and should be exploited to improve efficiency. For a discussion of how this structural information is captured and exploited in SPI see [5].
Reference: [27] <author> S. Srinivas. </author> <title> A probabilistic extension of the atms. </title> <note> In , July 1993. </note>
References-found: 26

