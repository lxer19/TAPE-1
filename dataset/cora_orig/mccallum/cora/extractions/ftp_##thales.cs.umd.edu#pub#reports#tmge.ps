URL: ftp://thales.cs.umd.edu/pub/reports/tmge.ps
Refering-URL: ftp://thales.cs.umd.edu/pub/biographical/xlaa.html
Root-URL: 
Title: The Triangular Matrices of Gaussian Elimination and Related Decompositions  
Author: G. W. Stewart 
Note: This report is available by anonymous ftp from thales.cs.umd.edu in the directory pub/reports.  
Date: October, 1995  
Affiliation: University of Maryland College Park Institute for Advanced Computer Studies TR-95-91 Department of Computer Science  
Pubnum: TR-3533  
Abstract: It has become a commonplace that triangular systems are solved to higher accuracy than their condition would warrant. This observation is not true in general, and counterexamples are easy to construct. However, it is often true of the triangular matrices from pivoted LU or QR decompositions. It is shown that this fact is closely connected with the rank-revealing character of these decompositions. y Department of Computer Science and Institute for Advanced Computer Studies, University of Maryland, College Park, MD 20742. This work was supported in part by the National Science Foundation under grant CCR 95503126. The paper will appear in the IMA Journal on Numerical Analysis. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. H. Golub. </author> <title> Numerical methods for solving least squares problems. </title> <journal> Nu-merische Mathematik, </journal> <volume> 7 </volume> <pages> 206-216, </pages> <year> 1965. </year>
Reference-contexts: Thus the R factor from a pivoted QR factorization is another source of triangular systems that tend to be solved accurately. These results possibly explain an observation of Golub on the use of Householder transformations to solve least squares problems <ref> [1] </ref>. He noted that column pivoting slightly improved the accuracy of the computed solutions.
Reference: [2] <author> G. H. Golub and C. F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> Johns Hopkins University Press, </publisher> <address> Baltimore, Maryland, 2nd edition, </address> <year> 1989. </year> <title> The Triangular Matrices of Gaussian Elimination 11 </title>
Reference-contexts: The paper concludes with a brief recapitulation. In the following, k k denotes the 2-norm. Since the basic results are stated in terms of singular values, we will assume the reader is familiar with their elementary properties. For details see <ref> [2, 4, 8] </ref>. 2. Lower bounds for singular values The purpose of this section is to show that a triangular matrix whose principal minors reveal their rank becomes well conditioned when its rows are equilibrated.
Reference: [3] <author> N. J. Higham. </author> <title> Accuracy and Stability of Numerical Algorithms. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1995. </year> <note> To appear. </note>
Reference-contexts: The matrix L is well conditioned. The first of these consequences implies that systems involving U will be solved accurately, since the best bounds on the accuracy of the solution do not depend on row scaling <ref> [3] </ref>. The second implies ipso facto that systems involving L will be solved accurately. It might be objected that we have traded one mystery for another | the other being that Gaussian elimination tends to be rank revealing. The proper response is that it is not very mysterious.
Reference: [4] <author> R. A. Horn and C. R. Johnson. </author> <title> Topics in Matrix Analysis. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1991. </year>
Reference-contexts: The paper concludes with a brief recapitulation. In the following, k k denotes the 2-norm. Since the basic results are stated in terms of singular values, we will assume the reader is familiar with their elementary properties. For details see <ref> [2, 4, 8] </ref>. 2. Lower bounds for singular values The purpose of this section is to show that a triangular matrix whose principal minors reveal their rank becomes well conditioned when its rows are equilibrated. <p> The diagonals of U must not just approximate the corresponding singular values of U but instead must approximate the smallest singular value of the corresponding leading principal submatrix. By the interlacing theorem for singular values <ref> [4, p. 149] </ref>, the latter can be smaller than the former. To illustrate the bounds, let us consider an upper-triangular matrix whose elements are standard normal deviates and also some triangular matrices that can be obtained from them by computing factorizations.
Reference: [5] <author> G. W. Stewart. </author> <title> The efficient generation of random orthogonal matrices with an application to condition estimators. </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 17 </volume> <pages> 403-404, </pages> <year> 1980. </year>
Reference-contexts: Since the bound is nearly attained, we observe a small singular value in D 1 U . The numbers in the second column come from the R factor in a pivoted QR decomposition of the U in column one. Such a decomposition is generally an excellent rank revealer <ref> [5] </ref>, and indeed we observe that the bounds and the smallest singular value are near one. The Triangular Matrices of Gaussian Elimination 7 1 2 3 4 1:0e10 1:4e01 2:1e02 6:7e11 3:0e07 1:3e01 1:1e02 2:8e07 1:6e08 1:4e01 2:6e02 1:5e08 1:3e11 1:3e01 3:2e02 8:1e12 5:4e07 1:3e01 1:5e02 2:7e07 1. <p> The pivoting insures that r 2 j X r 2 The pivoted QR decomposition is known empirically to reveal the rank of A in the following sense <ref> [5] </ref>. If A k denotes the matrix consisting of the first k columns of A, then r kk is an approximation to the smallest singular value of A k .
Reference: [6] <author> G. W. Stewart. </author> <title> On sublinear convergence. </title> <type> Technical Report CS-TR-3534 UMIACS-TR-95-92, </type> <institution> University of Maryland, Department of Computer Science, </institution> <year> 1995. </year>
Reference-contexts: of Gaussian Elimination The following table exhibits values of the lower bounds for k when fi k is held constant. fi 5 2:4e1 5:0e2 5:0e3 100 5:0e2 1:0e2 1:0e3 In fact it can be shown that in the limit the iterates approach fi= p general theory of sublinear convergence see <ref> [6] </ref>.) The price we pay for these slowly decreasing bounds is the requirement that U satisfy a strong rank-revealing condition. The diagonals of U must not just approximate the corresponding singular values of U but instead must approximate the smallest singular value of the corresponding leading principal submatrix.
Reference: [7] <author> G. W. Stewart. </author> <title> On the perturbation of LU and Cholesky factors. </title> <type> Technical Report CS-TR-3535 UMIACS-TR-95-93, </type> <institution> University of Maryland, Department of Computer Science, </institution> <year> 1995. </year>
Reference-contexts: These results have implications for the perturbation theory of the LU decomposition. Let A + E have the LU decomposition (L + F L )(U + F U ) and let S be The Triangular Matrices of Gaussian Elimination 9 an arbitrary nonsingular diagonal matrix. The author has shown <ref> [7] </ref> that for any absolute norm k k kF U k (L)(SU ) kAk where as usual (X) = kXkkX 1 k.
Reference: [8] <author> G. W. Stewart and J.-G. Sun. </author> <title> Matrix Perturbation Theory. </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1990. </year>
Reference-contexts: The paper concludes with a brief recapitulation. In the following, k k denotes the 2-norm. Since the basic results are stated in terms of singular values, we will assume the reader is familiar with their elementary properties. For details see <ref> [2, 4, 8] </ref>. 2. Lower bounds for singular values The purpose of this section is to show that a triangular matrix whose principal minors reveal their rank becomes well conditioned when its rows are equilibrated.
Reference: [9] <author> L. N. Trefethen and R. S. Schreiber. </author> <title> Average-case stability of Gaussian elimination. </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 11 </volume> <pages> 335-360, </pages> <year> 1990. </year>
Reference-contexts: Gaussian elimination In applying our results to Gaussian elimination, we will have to make use of some empirical facts about the growth of elements in course of the algorithm. For experiments and analyses concerning this important topic, see the paper by Trefethen and Schreiber <ref> [9] </ref>. Let the matrix A of order n be decomposed by Gaussian elimination with pivoting, so that P T AQ = LDU; where P and Q are permutation matrices, L is a unit lower triangular matrix, and U is unit upper triangular. <p> The fact | critical to our analysis | that L and U are of modest size is guaranteed for complete pivoting, but for partial pivoting what inhibits growth of the elements of U is imperfectly understood <ref> [9] </ref>. For the pivoted QR and Cholesky factorizations we need no auxiliary hypothesis about the sizes of the triangular factor. All we need to believe is that the factorizations reveal rank. Perhaps the most unusual feature of the analysis is the nature of the recursion (2.5).
Reference: [10] <author> J. H. Wilkinson. </author> <title> Error analysis of direct methods of matrix inversion. </title> <journal> Journal of the ACM, </journal> <volume> 8 </volume> <pages> 281-330, </pages> <year> 1961. </year>
Reference-contexts: 1. Introduction In 1961 J. H. Wilkinson <ref> [10] </ref> published a ground-breaking error analysis of Gaussian elimination. In the course of the paper he observed that triangular systems are frequently solved more accurately than their condition would warrant. In support of this observation he offered some examples and suggestive analyses, but no general theorems.
Reference: [11] <author> J. H. Wilkinson. </author> <title> The Algebraic Eigenvalue Problem. </title> <publisher> Clarendon Press, Oxford, </publisher> <address> England, </address> <year> 1965. </year>
Reference-contexts: It is the purpose of this paper to show that these matrices have special properties that derive from the rank revealing character of Gaussian elimination. Specifically, Wilkinson <ref> [11, pp. 213-214] </ref> has noted that partial or complete pivoting tends to reveal ill-conditioning in the matrix the sense that the diagonal elements of U show a steady decrease in size.
References-found: 11

