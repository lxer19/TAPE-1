URL: ftp://ftp.cs.wisc.edu/tech-reports/reports/91/tr1050a.ps
Refering-URL: http://www.cs.wisc.edu/math-prog/tech-reports/
Root-URL: 
Title: WEAK SHARP MINIMA IN MATHEMATICAL PROGRAMMING  
Author: J.V. BURKE AND M.C. FERRIS 
Abstract: The notion of a sharp, or strongly unique, minimum is extended to include the possibility of a nonunique solution set. These minima will be called weak sharp minima. Conditions necessary for the solution set of a minimization problem to be a set of weak sharp minima are developed in both the unconstrained and constrained cases. These conditions are also shown to be sufficient under the appropriate convexity hypotheses. The existence of weak sharp minima is characterized in the cases of linear and quadratic convex programming and for the linear complementarity problem. In particular, we reproduce a result of Mangasarian and Meyer that shows that the solution set of a linear program is always a set of weak sharp minima whenever it is nonempty. Consequences for the convergence theory of algorithms is also examined, especially conditions yielding finite termination. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F.A. Al-Khayyal and J. Kyparisis. </author> <title> Finite convergence of algorithms for nonlinear programs and variational inequalities. </title> <journal> Journal of Optimization Theory and Applications, </journal> <volume> 70(2): </volume> <pages> 319-332, </pages> <year> 1991. </year>
Reference-contexts: The notion of a sharp minimum, or equivalently, a strongly unique local minimum, has far reaching consequences for the convergence analysis of many iterative procedures <ref> [1, 8, 11, 12, 17, 18] </ref>. In this article, we extend the notion of a sharp minimum in order to include the possibility of a non-unique solution set. <p> However, in this later case rather strong regularity conditions are required to yield significant extentions of the convex case. Nonetheless, we do obtain some very interesting and significant results for differentiable problems with convex constraints. These results extend and refine earlier work of Al-Khayyal and Kyparisis <ref> [1] </ref> on the finite termination of algorithms at sharp minima. In a later study, we also show how these results can be applied to convex composite optimization problems to establish the quadratic rate of convergence of a variety of algorithms. This study builds on the work initiated in [9]. <p> Let z = y + (1 )p for 2 <ref> [0; 1] </ref>. <p> Example 2.4. Consider the problem (3) where f : IR 7! IR is given by f (x) := 1 + x 2 , for x 2 <ref> [1; 1] </ref> +1 , otherwise, and S := fx : x 1g. This is a convex program with a closed proper convex objective function having unique global solution x = 1. However, the condition (4) does not hold since @f (x) = ;. <p> nonempty closed and convex, then S is a set of weak sharp minima for f over S with modulus ff &gt; 0 if and only if rf (x) 2 int x2 S T (x j S) N (x j S) : Remark The corollary given above is a strengthening of <ref> [1, Proposition 2.2] </ref>. In particular, the equivalence in Part (a) is proven without assumptions on convexity of S. In fact, under the convexity assumptions in Part (c), the condition given in [1] is equiva lent to strong uniqueness. <p> In particular, the equivalence in Part (a) is proven without assumptions on convexity of S. In fact, under the convexity assumptions in Part (c), the condition given in <ref> [1] </ref> is equiva lent to strong uniqueness. By relaxing strong uniqueness to the assumption of a weak sharp minimum, all the results of [1, Proposition 2.2] still follow, with the exception of uniqueness. 3. Some Special Cases. <p> In fact, under the convexity assumptions in Part (c), the condition given in [1] is equiva lent to strong uniqueness. By relaxing strong uniqueness to the assumption of a weak sharp minimum, all the results of <ref> [1, Proposition 2.2] </ref> still follow, with the exception of uniqueness. 3. Some Special Cases. We now examine three important classes of convex pro gramming problems and characterize when these problems posses weak sharp minima. The problem classes considered are linear and quadratic programming and the linear complementarity problem. 3.1. <p> to (M + M T )d = 0 as required. 15 Note that in this result, we asume that the related optimization problem (17) has a weak sharp minimum, as opposed to an assumption of the form M ^x q 2 int N (^x j IR n as made in <ref> [1] </ref>. Using Theorem 3.7 it is easy to construct examples which are sharp in the sense given above, but do not satisfy (18). 4. Finite Termination of Algorithms. <p> The required equality E (c j S) = E (c j S) now follows easily. As another immediate consequence of Theorem 4.1, we obtain the following generalization of a result due to Al-Khayyal and Kyparisis <ref> [1] </ref>. Corollary 4.5. Suppose S is a set of weak sharp minima for the problem (19) and let fx k g IR n . <p> The proof of this result only requires the assumption (22) to hold. Part b) of the above corollary can then be proven under the hypothesis that (22) holds only at ^x. This is a weakening of the hypotheses that rf (^x) 2 int N (^x j S) in <ref> [1, Theorem 2.1] </ref>. Assuming that one can solve (21), Corollary 4.5 can be employed to construct hybrid iterative algorithms for solving the problem (19) that will terminate finitely at weak sharp minima.
Reference: [2] <author> L.N.H. Bunt. Bijdrage tot de Theorie der Convexe Puntverzamelingen. </author> <type> Thesis, </type> <institution> University of Groningen, </institution> <year> 1934. </year>
Reference-contexts: That is, the set A is closed and convex if and only if the projection operator for A, P ( j A), is single valued on all of IR n <ref> [2, 16] </ref>.
Reference: [3] <author> J.V. Burke and M.C. Ferris. </author> <title> Characterization of solution sets of convex programs. </title> <journal> Operations Research Letters, </journal> <volume> 10(1) </volume> <pages> 57-60, </pages> <year> 1991. </year>
Reference-contexts: In order to apply this result we must first obtain a tractable description of the tangent cone to the solution set of (11). This is accomplished by using the description of the solution set of a convex program given in <ref> [3, 14] </ref>. Theorem 3.1. Let S be the set of solutions to the problem minff (x) : x 2 Sg where both f : IR n 7! IR and S IR n are taken to be convex and choose x 2 S.
Reference: [4] <author> J.V. Burke, M.C. Ferris, and M. Qian. </author> <title> On the Clarke subdifferential of the distance function to a closed set. </title> <journal> Journal of Mathematical Analysis and its Applications, </journal> <volume> 166 </volume> <pages> 199-213, </pages> <year> 1992. </year>
Reference-contexts: (x) ffdist (x + td 0 j S) which implies that f (x + td 0 ) f (x) ff dist (x + td 0 j S) dist (x j S) t By taking lim infs of both sides as d 0 ! d and t # 0 and applying <ref> [4, Theorem 4] </ref>, we obtain the result. [(2 plus regularity ) =) 3]: Simply observe that regularity at x 2 S implies the equivalence T (x j S) = K (x j S) and by definition f ffi (x; ) f (x; ). [3 () 4]: We recall from [5, Theorem <p> implies both 3 and 4 for all x 2 S. [(4 holds for all x 2 S) =) 5]: Trivial. [(5 plus convexity) =) 4]: Convexity and Lemma 2.1 combine to establish that 5 implies 4. [(5 plus convexity) =) 1]: Given y 2 IR n , Theorem 1 in <ref> [4] </ref> implies the existence of a x fl 2 ffIB ffi T N (P (y j S) j S) such that ffdist (y j S) = hx fl ; yi fl (x fl j S). Thus, by hypothesis, there exists a x 2 S with x fl 2 @f (x).
Reference: [5] <author> J.V. Burke and S.P. Han. </author> <title> A Gauss-Newton approach to solving generalized inequalities. </title> <journal> Math. of Oper. Res., </journal> <volume> 11(1986), </volume> <month> pp.632-643. </month>
Reference-contexts: applying [4, Theorem 4], we obtain the result. [(2 plus regularity ) =) 3]: Simply observe that regularity at x 2 S implies the equivalence T (x j S) = K (x j S) and by definition f ffi (x; ) f (x; ). [3 () 4]: We recall from <ref> [5, Theorem 3.1] </ref> that if K IR n is a nonempty closed convex cone, then dist (x j K) = fl (x j K ffi " IB ffi ): The result now follows from the fact that f ffi (x; ) = fl ( j @f (x)).
Reference: [6] <author> J.V. Burke and J.J. </author> <title> More. On the identification of active constraints. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 25(1988), </volume> <month> pp.1197-1211. </month>
Reference-contexts: Under the assumption that the solution set for (19), S, is a set of weak sharp minima, we will examine certain tools for identifying an element of S in a finite number of iterations. Our approach is based on the techniques developed in <ref> [6] </ref>. Consequently, we need to introduce some elementary facts concerning the face structure of convex sets. <p> Consequently, the set F in the above lemma may be taken to be the set S. In this case one may write K = x2 S Lemma 4.6 is now employed to show that the characterization given in <ref> [6] </ref> of those algorithms that identify the optimal face of S in a finite number of steps also characterizes those algorithms that identify weak sharp minima finitely. Theorem 4.7. Suppose f is convex and let S S be a set of weak sharp minima for (19). <p> Therefore, x k = P x k + P (rf (x k ) j N (x k j S)) fi 0 [ [x + N (x j S)] fi fi fi 1 x2 S = S for all k sufficiently large. In <ref> [6] </ref>, it was shown that the condition (24) is simple to check in certain cases. In particular, it was established that the standard sequential quadratic programming method and the gradient projection method both satisfy (24) and so will automatically generate sequences that terminate finitely at weak sharp minima.
Reference: [7] <author> F.H. Clarke. </author> <title> Optimization and Nonsmooth Analysis. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1983. </year>
Reference: [8] <author> L. Cromme. </author> <title> Strong Uniqueness. </title> <journal> Numerische Mathematik, </journal> <volume> 29(1978), </volume> <pages> 179-193. </pages>
Reference-contexts: The notion of a sharp minimum, or equivalently, a strongly unique local minimum, has far reaching consequences for the convergence analysis of many iterative procedures <ref> [1, 8, 11, 12, 17, 18] </ref>. In this article, we extend the notion of a sharp minimum in order to include the possibility of a non-unique solution set.
Reference: [9] <author> M.C. Ferris. </author> <title> Weak sharp minima and penalty functions in mathematical programming. </title> <type> Technical Report 779, </type> <institution> Computer Sciences Department, University of Wisconsin, Madison, Wisconsin 53706, </institution> <month> June </month> <year> 1988. </year>
Reference-contexts: In a later study, we also show how these results can be applied to convex composite optimization problems to establish the quadratic rate of convergence of a variety of algorithms. This study builds on the work initiated in <ref> [9] </ref>. Our study begins in Section 2 with the derivation of first order necessary conditions for the solution set of a problem to be a set of weak sharp minima. The unconstrained (S = IR n ) and constrained cases are treated separately.
Reference: [10] <author> M.C. Ferris and O.L. Mangasarian. </author> <title> Minimum principle sufficiency. </title> <journal> Mathematical Programming, </journal> <volume> 57(1) </volume> <pages> 1-14, </pages> <year> 1992. </year>
Reference-contexts: In the absence of such a differentiability hypothesis, the result would, in general, be false. Indeed, one need only consider the case f (x) := dist (x j S) where S is any nonempty closed set and S is any set that properly contains S in its interior. In <ref> [10] </ref>, the notion of minimum principle sufficiency was introduced. Assuming x 2 S, we define ^ S: = arg min frf (x)x j x 2 S g : Minimum principle sufficiency (MPS) is the equality of the sets ^ S and S.
Reference: [11] <author> R. Hettich. </author> <title> A review of numerical methods for semi-infinite optimization. In A.V. Fiacco and K.O. Kortanek, editors, Semi-Infinite Programming and Applciations, </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1983. </year>
Reference-contexts: The notion of a sharp minimum, or equivalently, a strongly unique local minimum, has far reaching consequences for the convergence analysis of many iterative procedures <ref> [1, 8, 11, 12, 17, 18] </ref>. In this article, we extend the notion of a sharp minimum in order to include the possibility of a non-unique solution set.
Reference: [12] <author> K.Madsen. </author> <title> Minimization of Non-Linear Approximation Functions. Dr. </title> <type> Techn. Thesis, </type> <institution> Instititute for Numerical Analysis, The Technical University of Denmark, DK2800 Lyngby, Denmark. </institution>
Reference-contexts: The notion of a sharp minimum, or equivalently, a strongly unique local minimum, has far reaching consequences for the convergence analysis of many iterative procedures <ref> [1, 8, 11, 12, 17, 18] </ref>. In this article, we extend the notion of a sharp minimum in order to include the possibility of a non-unique solution set.
Reference: [13] <author> O.L. Mangasarian. </author> <title> Error bounds for nondegenerate monotone linear complementarity problems. </title> <journal> Mathematical Programming, </journal> <volume> 48: </volume> <pages> 437-446, </pages> <year> 1990. </year>
Reference-contexts: Thus (15) has a weak sharp minimum as required. 14 3.3. Sharpness for linear complementarity problems. We will use the anal-ysis given previously to show that nondegenerate monotone linear complementarity problems have weak sharp minima. This was proved in <ref> [13] </ref>. The linear complementarity problem is to find an x 0 with M x + q 0 satisfying hx; Mx + qi = 0. <p> M is positive semidefinite and a nondegeneracy assumption that there is a solution of (17), ^x, which satisfies I (^x) J (^x) = ;: Under these assumptions, it can be shown that any other solution of (17) satisfies I (^x) I (x) and J (^x) J (x), (see for instance <ref> [13, Lemma 2.2] </ref>). Theorem 3.7. The solution set of a nondegenerate monotone linear complemen tarity problem (17) is a set of weak sharp minima for the problem (17). Proof Let x be any solution of (17) and let ^x be the nondegenerate solution.
Reference: [14] <author> O.L. Mangasarian. </author> <title> A simple characterization of solution sets of convex programs. </title> <journal> Operations Research Letters, </journal> <volume> 7(1): </volume> <pages> 21-26, </pages> <year> 1988. </year> <month> 21 </month>
Reference-contexts: In order to apply this result we must first obtain a tractable description of the tangent cone to the solution set of (11). This is accomplished by using the description of the solution set of a convex program given in <ref> [3, 14] </ref>. Theorem 3.1. Let S be the set of solutions to the problem minff (x) : x 2 Sg where both f : IR n 7! IR and S IR n are taken to be convex and choose x 2 S.
Reference: [15] <author> O.L. Mangasarian and R.R. Meyer. </author> <title> Nonlinear perturbation of linear programs. </title> <journal> SIAM Journal on Control and Optimization, </journal> <volume> 17(6): </volume> <pages> 745-752, </pages> <month> November </month> <year> 1979. </year>
Reference-contexts: Linear Programming. It was shown in <ref> [15] </ref> that the solution set of a linear program is a set of weak sharp minima. We show below how it can be obtained as a corollary to Theorem 3.2. The linear programming problem is minimize hc; xi x 2 S where S is polyhedral. Theorem 3.5.
Reference: [16] <editor> T.S. Motzkin. Sur quelque proprietes caracteristiques des ensembles convexes. Rend. Accad. Naz. Lincei, </editor> <volume> 21(1935), </volume> <pages> 562-567. </pages>
Reference-contexts: That is, the set A is closed and convex if and only if the projection operator for A, P ( j A), is single valued on all of IR n <ref> [2, 16] </ref>.
Reference: [17] <author> B.T. Polyak. </author> <booktitle> Sharp Minima Institute of Control Sciences Lecture Notes, Moscow, USSR (1979), Presented at the IIASA Workshop on Generalized Lagrangians and Their Applications, </booktitle> <address> IIASA, Laxenburg, Austria (1979). </address>
Reference-contexts: The notion of a sharp minimum, or equivalently, a strongly unique local minimum, has far reaching consequences for the convergence analysis of many iterative procedures <ref> [1, 8, 11, 12, 17, 18] </ref>. In this article, we extend the notion of a sharp minimum in order to include the possibility of a non-unique solution set.
Reference: [18] <author> B. T. </author> <title> Polyak Introduction to Optimization. Optimization Software, </title> <publisher> Inc., Publications Division, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: The notion of a sharp minimum, or equivalently, a strongly unique local minimum, has far reaching consequences for the convergence analysis of many iterative procedures <ref> [1, 8, 11, 12, 17, 18] </ref>. In this article, we extend the notion of a sharp minimum in order to include the possibility of a non-unique solution set. <p> It is possible to illustrate the Theorem by means of adapting a simple example given in <ref> [18, page 206] </ref> Example 3.3. The problem is minimize x2IR 3 1 2 x 2 2 x 2 subject to x i 2 [a i ; b i ]; i = 1; 2; 3 for given a, b 2 IR 3 with a b. <p> In particular, it was established that the standard sequential quadratic programming method and the gradient projection method both satisfy (24) and so will automatically generate sequences that terminate finitely at weak sharp minima. We should also note that Polyak <ref> [18, Exercise 2, page 209] </ref> indicates that the gradient projection method terminates finitely at weak sharp minima.
Reference: [19] <author> S.M. Robinson. </author> <title> Local structure of feasible sets in nonlinear programming, part II: nondegeneracy. </title> <journal> Mathematical Programming Study, </journal> <volume> 22(1984), </volume> <pages> 217-230. </pages>
Reference-contexts: If we consider points x on the boundary of the circle, then it follows that x 2 which is not true for x 1 sufficiently small. Another simple application of Theorem 4.1 results in the following strong upper semi-continuity result for linear programs that was first proven in <ref> [19, Lemma 3.5] </ref>. Corollary 4.4. Let S be a polyhedral convex set in IR n . Let c 2 IR n and S: = arg max x2S hc; xi.
Reference: [20] <author> R.T. Rockafellar. </author> <title> Extensions of subgradient calculus with applications to optimization. </title> <journal> Nonlinear Anal., </journal> <volume> 9(1985), </volume> <pages> 665-698. </pages>
Reference-contexts: This is a convex program with a closed proper convex objective function having unique global solution x = 1. However, the condition (4) does not hold since @f (x) = ;. For this reason we introduce the following constraint qualification due to Rockafellar <ref> [20] </ref>. Definition 2.5. <p> The BCQ is said to be satisfied on a set S S if it is satisfied at every point of S. From Rockafellar <ref> [20, Corollary 5.2.1] </ref>, we know that the optimality condition (4) is satisfied at every local solution to (3) at which the BCQ holds. <p> Since S is a set of weak sharp minima for h over IR n with modulus ff &gt; 0, Theorem 2.2 implies that h 0 (x; d) ffdist (d j T (x j S)) for all d : Now, by the BCQ, <ref> [20, Corollary 8.1.2] </ref>, and the regularity of S, we know that h 0 (x; d) f 0 (x; d) + ( j S) 0 (x; d) = f 0 (x; d) + (d j T (x j S)):(9) Therefore, f 0 (x; d) ffdist (d j T (x j S)) for
Reference: [21] <author> R.T. Rockafellar. </author> <title> Convex Analysis. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1970. </year>
Reference-contexts: (x j S) = N (x j S) + span (rf (x)) + ? = N (x j S) + span (rf (x)) Therefore ffdist (d j T (x j S)) = ff fl (d j IB " ffi = ff sup hz; di fi " o It follows from <ref> [21, page 65] </ref> that K = span (rf (x)) + (K T ? ), hence, z 2 IB K implies z = rf (x) + y with jj where := 1= krf (x)k ; if krf (x)k 6= 0 0 otherwise and y 2 K (rf (x)) . <p> Observe that the argument given above only employs the polyhedrality of S to establish that (12) holds. However, (12) also holds under the assumption ri (S x) (rf (x)) ker (r 2 f (x)) 6= ; (see <ref> [21, Corollaries 23.8.1 and 16.4.2] </ref>) and so the following result is immediate. Theorem 3.4. Let S be the solution set for (11) where it is no longer assumed that S is polyhedral. <p> Recall that a nonempty convex subset b C of a closed convex set C in IR n is said to be a face of C if every convex subset of C whose relative interior meets b C is contained in b C (e.g. see <ref> [21, Section 18] </ref>). In fact, the relative interiors of the faces of C form a partition of C [21, Theorem 18.2]. Thus every point x 2 C can be associated with a unique face of C denoted by F (xjC) such that x 2 ri (F (xjC)). <p> In fact, the relative interiors of the faces of C form a partition of C <ref> [21, Theorem 18.2] </ref>. Thus every point x 2 C can be associated with a unique face of C denoted by F (xjC) such that x 2 ri (F (xjC)).
Reference: [22] <author> M.V. Solodov. </author> <title> Private communication. </title> <type> 22 </type>
Reference-contexts: Assuming x 2 S, we define ^ S: = arg min frf (x)x j x 2 S g : Minimum principle sufficiency (MPS) is the equality of the sets ^ S and S. Note that in the notation above ^ S E (rf (x) j S). M.V. Solodov <ref> [22] </ref> pointed out the following interesting corollary to Theorem 4.1. Theorem 4.2. Suppose f is convex and differentiable and S IR n is a closed convex set. If S is a set of weak sharp minima for (19) then MPS is satisfied.
References-found: 22

