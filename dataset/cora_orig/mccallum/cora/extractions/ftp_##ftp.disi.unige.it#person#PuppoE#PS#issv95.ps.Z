URL: ftp://ftp.disi.unige.it/person/PuppoE/PS/issv95.ps.Z
Refering-URL: 
Root-URL: 
Email: Email: cignoni@di.unipi.it  Email: puppo@ima.ge.cnr.it  Email: R.Scopigno@cnuce.cnr.it  
Title: Representation and Visualization of Terrain Surfaces at Variable Resolution  
Author: P. Cignoni E. Puppo R. Scopigno 
Address: C.so Italia, 40 56100 Pisa ITALY  Via  Francia) 16149 Genova, ITALY  Via S. Maria 36, 56126 Pisa, ITALY  
Affiliation: Dipartimento di Informatica Universita di Pisa,  Istituto per la Matematica Applicata Consiglio Nazionale delle Ricerche  dei Marini, 6 (Torre di  CNUCE Consiglio Nazionale delle Ricerche,  
Abstract: We present a new approach for managing the multiresolution representation of discrete topographic surfaces. A Triangulated Irregular Network (TIN) representing the surface is built from sampled data by iteratively refining an initial triangulation that covers the whole domain. The refinement process generates triangulations of the domain corresponding to increasingly finer approximations of the surface. Such triangulations are embedded into a structure in a three dimensional space. The resulting representation scheme encodes all intermediate representations that were generated during refinement. We propose a data structure and traversal algorithms that are oriented to the efficient extraction of approximated terrain models with an arbitrary precision, either constant or variable over the domain.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P.K. Agarwal and S. Suri. </author> <title> Surface approximation and geometric partitions. </title> <booktitle> In Proceedings 5th ACM-SIAM Symposium On Discrete Algorithms, </booktitle> <pages> pages 24-33, </pages> <year> 1994. </year>
Reference-contexts: Finding the best method to select from a set of sites the vertices or edges on which the triangulation has to be built is still an open issue. However, a recent theoretical result <ref> [1] </ref> suggests that the search for an optimal solution is hopeless in many cases; moreover, approximated algorithms that can guarantee a certain bound with respect to the optimal solution are far too slow to be of practical interest.
Reference: [2] <author> M. Bertolotto, L. De Floriani, and P. Marzano. </author> <title> Pyramidal simplicial complexes. </title> <booktitle> In Proceedings ACM Solid Modeling '95, page (in print), </booktitle> <address> Salt Lake City, Utah, U.S.A., </address> <month> May 17-19 </month> <year> 1995. </year>
Reference-contexts: More recent advances in the formalization of multiresolution models for scalar fields in any dimension also outline the possibility of overcoming the above classification into multi-layer and tree, in order to obtain more compact models that incorporate different levels of resolution within a unified representation <ref> [2] </ref>. An interesting yet not much explored application of multiresolution models is rendering at variable resolutions over various zones of the surface/object/volume. <p> The sequence of error tolerances monotonically decreases: " 0 &gt; " 1 &gt; : : : &gt; " n = 0. The sequence of triangulations could be piled up into a layered model, such as the Delaunay Pyramid proposed in [10] 2 . As pointed out in <ref> [2] </ref>, the Delaunay pyramid has the disadvantage of replicating at each new layer all the portions of the triangulation that remain unchanged from the previous layer as well.
Reference: [3] <author> J.D. Boissonnat and M. Teillaud. </author> <title> A hierarchical representation of objects: the delaunay tree. </title> <booktitle> In Proceedings 2nd ACM Symposium on Computational Geometry, </booktitle> <pages> pages 260-268, </pages> <year> 1986. </year>
Reference-contexts: Our alternative approach is to store a sort of history of the incremental refinement process. Structures that store the full history of the incremental construction of Delaunay triangulations were proposed in <ref> [3, 14] </ref>, which depend on the construction algorithm, and whose main purpose is to improve point location either during construction or spatial query.
Reference: [4] <author> E. Brisson. </author> <title> Representing geometric structures in d dimensions: topology and order. </title> <booktitle> In Proceedings 5th ACM Symposium on Computational Geometry, </booktitle> <pages> pages 218-227. </pages> <publisher> ACM Press, </publisher> <year> 1989. </year>
Reference-contexts: The same structure can generally be defined for multidimensional data through a d-simplicial complex embedded in IR d+1 . The generalization of the fact-edge data structure proposed in <ref> [4] </ref> extends the same efficient data structure for HyperTriangulations in any dimension. We plan to develop the details of this multidimensional model in the near future, and to develop and test a system based on a three-dimensional version for applications to volume visualization.
Reference: [5] <author> P. Cignoni, L. De Floriani, C. Montani, E. Puppo, and R. Scopigno. </author> <title> Multiresolution Modeling and Rendering of Volume Data based on Simplicial Complexes. </title> <booktitle> In Proceedings of 1994 Symposium on Volume Visualization, </booktitle> <pages> pages 19-26. </pages> <publisher> ACM Press, </publisher> <month> October 17-18 </month> <year> 1994. </year>
Reference-contexts: 1 Introduction The search for multiresolution representation schemes has recently become very popular. Major applications involve generic surfaces embedded in 3D space [16, 8, 27], terrains in the context of Geographical Information Systems [10, 23, 12], 3D objects for classical CAD and recognition [9, 20, 21], and volume data <ref> [5, 31, 30] </ref>. All such models are based on the idea that a detailed 1 digital model taken as input can be simplified into an approximate representation: appropriate measures of fidelity to the original model are taken as a quantitative mean to define multiple resolution levels. <p> main approaches to the construction of approximate models are iterative, and can be classified into simplification methods [25, 28, 21, 17, 27] - i.e., methods that start from the full resolution and progressively reduce the dataset on which the model is based, in order to coarsen resolution; and refinement methods <ref> [13, 16, 8, 23, 12, 5] </ref> - i.e., methods that start from a very coarse approximation based on a very small dataset, and progressively refine it by inserting new data, in order to improve resolution. <p> The models proposed in the literature to pursue the second goal can be broadly classified 2 into multi-layer models <ref> [10, 5] </ref> - i.e., frameworks that relate a sequence of independent models of the whole object represented at different levels of resolution and tree models [9, 20, 16, 8, 23, 12, 21, 27] - i.e., models in which a hierarchy of descriptions is represented by a tree, where each node corresponds <p> Multiresolution allows a larger number of polygons to be rendered only in the areas where the visual impact is at its most significant. A similar approach has also been outlined in scientific visualization to sharpen resolution only in user-selected focus areas <ref> [5, 6] </ref>. The main problem in providing a representation with variable resolutions is to maintain the continuity of the surface where pieces of surface with different precisions meet. Most methods resolve this problem through rendering artifacts [6], or merely choose to ignore it. <p> This approach is called the Delaunay Selector, and it derived from an early method proposed in [13]. A 3D generalization of this method has also been used for multiresolution volume modeling and visualization <ref> [5] </ref>. Here, we give a brief description of the algorithm, based on an efficient implementation proposed in [11]. Let " 0 be a tolerance value, let P be a finite set of points in IR 2 , and let be the elevation function known at the points of P .
Reference: [6] <author> P. Cignoni, C. Montani, and R. Scopigno. MagicSphere: </author> <title> an insight tool for 3D data visualization. </title> <journal> Computer Graphics Forum, </journal> <volume> 13(3) </volume> <pages> 317-328, </pages> <year> 1994. </year> <note> (Eurographics '94 Conf. Proc.). </note>
Reference-contexts: Multiresolution allows a larger number of polygons to be rendered only in the areas where the visual impact is at its most significant. A similar approach has also been outlined in scientific visualization to sharpen resolution only in user-selected focus areas <ref> [5, 6] </ref>. The main problem in providing a representation with variable resolutions is to maintain the continuity of the surface where pieces of surface with different precisions meet. Most methods resolve this problem through rendering artifacts [6], or merely choose to ignore it. <p> The main problem in providing a representation with variable resolutions is to maintain the continuity of the surface where pieces of surface with different precisions meet. Most methods resolve this problem through rendering artifacts <ref> [6] </ref>, or merely choose to ignore it. In this paper, we present a multiresolution model for triangulated topographic surfaces, called a HyperTriangulation (HT), which is more compact and flexible than previous models.
Reference: [7] <author> D.P. Dobkin and M.J. Laszlo. </author> <title> Primitives for the manipulation of three-dimensional subdivisions. </title> <journal> Algorithmica, </journal> <volume> 4 </volume> <pages> 3-32, </pages> <year> 1989. </year> <month> 18 </month>
Reference-contexts: triangle in HT will be used to efficiently extract terrain representations from HT (see Section 5), they will be encoded explicitly in the model. 4 A data structure for HyperTriangulation In this section we describe a data structure for managing HyperTriangulations, which is based on the facet-edge structure described in <ref> [7] </ref> for representing cell complexes in three dimensions 4 . In the facet-edge data structure, an atomic entity is associated with each pair that is identified by a face and one of its edges: the so-called facet-edge.
Reference: [8] <author> N. Dyn, D. Levin, and J.A. Gregory. </author> <title> A butterfly subdivision scheme for surface interpola-tion with tension control. </title> <journal> ACM Transactions on Graphics, </journal> <volume> 9(2) </volume> <pages> 160-169, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: 1 Introduction The search for multiresolution representation schemes has recently become very popular. Major applications involve generic surfaces embedded in 3D space <ref> [16, 8, 27] </ref>, terrains in the context of Geographical Information Systems [10, 23, 12], 3D objects for classical CAD and recognition [9, 20, 21], and volume data [5, 31, 30]. <p> main approaches to the construction of approximate models are iterative, and can be classified into simplification methods [25, 28, 21, 17, 27] - i.e., methods that start from the full resolution and progressively reduce the dataset on which the model is based, in order to coarsen resolution; and refinement methods <ref> [13, 16, 8, 23, 12, 5] </ref> - i.e., methods that start from a very coarse approximation based on a very small dataset, and progressively refine it by inserting new data, in order to improve resolution. <p> The models proposed in the literature to pursue the second goal can be broadly classified 2 into multi-layer models [10, 5] - i.e., frameworks that relate a sequence of independent models of the whole object represented at different levels of resolution and tree models <ref> [9, 20, 16, 8, 23, 12, 21, 27] </ref> - i.e., models in which a hierarchy of descriptions is represented by a tree, where each node corresponds to the description of (a portion of) an object at a given level of resolution, while each of its children represents a more detailed description
Reference: [9] <author> G. Fekete and L.S. Davis. </author> <title> Property spheres: a new representation for 3-d object recognition. </title> <booktitle> In Proceedings Workshop on Computer Vision: Representation and Control, </booktitle> <pages> pages 192-201, </pages> <address> Los Alamitos, CA, 1984. </address> <publisher> CS Press. </publisher>
Reference-contexts: 1 Introduction The search for multiresolution representation schemes has recently become very popular. Major applications involve generic surfaces embedded in 3D space [16, 8, 27], terrains in the context of Geographical Information Systems [10, 23, 12], 3D objects for classical CAD and recognition <ref> [9, 20, 21] </ref>, and volume data [5, 31, 30]. <p> The models proposed in the literature to pursue the second goal can be broadly classified 2 into multi-layer models [10, 5] - i.e., frameworks that relate a sequence of independent models of the whole object represented at different levels of resolution and tree models <ref> [9, 20, 16, 8, 23, 12, 21, 27] </ref> - i.e., models in which a hierarchy of descriptions is represented by a tree, where each node corresponds to the description of (a portion of) an object at a given level of resolution, while each of its children represents a more detailed description
Reference: [10] <author> L. De Floriani. </author> <title> A pyramidal data structure for triangle-based surface description. </title> <journal> IEEE Comp. Graph. & Appl., </journal> <volume> 9(2) </volume> <pages> 67-78, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: 1 Introduction The search for multiresolution representation schemes has recently become very popular. Major applications involve generic surfaces embedded in 3D space [16, 8, 27], terrains in the context of Geographical Information Systems <ref> [10, 23, 12] </ref>, 3D objects for classical CAD and recognition [9, 20, 21], and volume data [5, 31, 30]. <p> The models proposed in the literature to pursue the second goal can be broadly classified 2 into multi-layer models <ref> [10, 5] </ref> - i.e., frameworks that relate a sequence of independent models of the whole object represented at different levels of resolution and tree models [9, 20, 16, 8, 23, 12, 21, 27] - i.e., models in which a hierarchy of descriptions is represented by a tree, where each node corresponds <p> The sequence of error tolerances monotonically decreases: " 0 &gt; " 1 &gt; : : : &gt; " n = 0. The sequence of triangulations could be piled up into a layered model, such as the Delaunay Pyramid proposed in <ref> [10] </ref> 2 . As pointed out in [2], the Delaunay pyramid has the disadvantage of replicating at each new layer all the portions of the triangulation that remain unchanged from the previous layer as well.
Reference: [11] <author> L. De Floriani, P. Marzano, and E. Puppo. </author> <title> Multiresolution models for topographic surface description. </title> <type> Technical Report 1-94, </type> <institution> Department of Information and Computer Sciences, University of Genova, ITALY, </institution> <year> 1994. </year>
Reference-contexts: A comprehensive discussion of multiresolution models for terrain representation is presented in <ref> [11] </ref>. More recent advances in the formalization of multiresolution models for scalar fields in any dimension also outline the possibility of overcoming the above classification into multi-layer and tree, in order to obtain more compact models that incorporate different levels of resolution within a unified representation [2]. <p> A 3D generalization of this method has also been used for multiresolution volume modeling and visualization [5]. Here, we give a brief description of the algorithm, based on an efficient implementation proposed in <ref> [11] </ref>. Let " 0 be a tolerance value, let P be a finite set of points in IR 2 , and let be the elevation function known at the points of P .
Reference: [12] <author> L. De Floriani and E. Puppo. </author> <title> A hierarchical triangle-based model for terrain description. In Theories and Methods of Spatio-Temporal Reasoning in Geographical Space, </title> <editor> LNCS n. </editor> <volume> 639, </volume> <pages> pages 236-251. </pages> <publisher> Springer-Verlag, </publisher> <address> Pisa, </address> <month> (Sept. </month> <year> 1992). </year>
Reference-contexts: 1 Introduction The search for multiresolution representation schemes has recently become very popular. Major applications involve generic surfaces embedded in 3D space [16, 8, 27], terrains in the context of Geographical Information Systems <ref> [10, 23, 12] </ref>, 3D objects for classical CAD and recognition [9, 20, 21], and volume data [5, 31, 30]. <p> main approaches to the construction of approximate models are iterative, and can be classified into simplification methods [25, 28, 21, 17, 27] - i.e., methods that start from the full resolution and progressively reduce the dataset on which the model is based, in order to coarsen resolution; and refinement methods <ref> [13, 16, 8, 23, 12, 5] </ref> - i.e., methods that start from a very coarse approximation based on a very small dataset, and progressively refine it by inserting new data, in order to improve resolution. <p> The models proposed in the literature to pursue the second goal can be broadly classified 2 into multi-layer models [10, 5] - i.e., frameworks that relate a sequence of independent models of the whole object represented at different levels of resolution and tree models <ref> [9, 20, 16, 8, 23, 12, 21, 27] </ref> - i.e., models in which a hierarchy of descriptions is represented by a tree, where each node corresponds to the description of (a portion of) an object at a given level of resolution, while each of its children represents a more detailed description
Reference: [13] <author> R.J. Fowler and J.J. Little. </author> <title> Automatic extraction of irregular network digital terrain models. </title> <journal> ACM Computer Graphics, </journal> <volume> 13(3) </volume> <pages> 199-207, </pages> <month> Aug. </month> <year> 1979. </year>
Reference-contexts: main approaches to the construction of approximate models are iterative, and can be classified into simplification methods [25, 28, 21, 17, 27] - i.e., methods that start from the full resolution and progressively reduce the dataset on which the model is based, in order to coarsen resolution; and refinement methods <ref> [13, 16, 8, 23, 12, 5] </ref> - i.e., methods that start from a very coarse approximation based on a very small dataset, and progressively refine it by inserting new data, in order to improve resolution. <p> This approach is called the Delaunay Selector, and it derived from an early method proposed in <ref> [13] </ref>. A 3D generalization of this method has also been used for multiresolution volume modeling and visualization [5]. Here, we give a brief description of the algorithm, based on an efficient implementation proposed in [11].
Reference: [14] <author> L.J. Guibas, D. E. Knuth, and M. Sharir. </author> <title> Randomized incremental construction of De-launay and Voronoy diagrams. </title> <booktitle> In Automata, Languages and Programming, LNCS N.443, </booktitle> <pages> pages 414-431. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: Our alternative approach is to store a sort of history of the incremental refinement process. Structures that store the full history of the incremental construction of Delaunay triangulations were proposed in <ref> [3, 14] </ref>, which depend on the construction algorithm, and whose main purpose is to improve point location either during construction or spatial query.
Reference: [15] <author> P. Heckbert and M. </author> <title> Garland. Multiresolution Modeling for Fast Rendering. </title> <booktitle> In Graphics Interface '94 Proceedings, </booktitle> <pages> pages 43-50, </pages> <year> 1994. </year>
Reference-contexts: There are two major challenges underlying the construction of multiresolution models <ref> [15] </ref>: 1. to find effective and efficient algorithms for automatically building an approximate model at a predefined level of resolution; 2. to structure models at different resolutions into a comprehensive framework that allows data to be manipulated at different resolutions according to the needs of a given applica tion or task.
Reference: [16] <author> B. Von Herzen and A.H. Barr. </author> <title> Accurate triangulations of deformed, intersecting surfaces. </title> <journal> Computer Graphics, </journal> <volume> 21(4) </volume> <pages> 103-110, </pages> <year> 1987. </year>
Reference-contexts: 1 Introduction The search for multiresolution representation schemes has recently become very popular. Major applications involve generic surfaces embedded in 3D space <ref> [16, 8, 27] </ref>, terrains in the context of Geographical Information Systems [10, 23, 12], 3D objects for classical CAD and recognition [9, 20, 21], and volume data [5, 31, 30]. <p> main approaches to the construction of approximate models are iterative, and can be classified into simplification methods [25, 28, 21, 17, 27] - i.e., methods that start from the full resolution and progressively reduce the dataset on which the model is based, in order to coarsen resolution; and refinement methods <ref> [13, 16, 8, 23, 12, 5] </ref> - i.e., methods that start from a very coarse approximation based on a very small dataset, and progressively refine it by inserting new data, in order to improve resolution. <p> The models proposed in the literature to pursue the second goal can be broadly classified 2 into multi-layer models [10, 5] - i.e., frameworks that relate a sequence of independent models of the whole object represented at different levels of resolution and tree models <ref> [9, 20, 16, 8, 23, 12, 21, 27] </ref> - i.e., models in which a hierarchy of descriptions is represented by a tree, where each node corresponds to the description of (a portion of) an object at a given level of resolution, while each of its children represents a more detailed description
Reference: [17] <author> H. Hoppe, T. DeRose, T. Duchamp, J. McDonald, and W. Stuetzle. </author> <title> Mesh optimization. </title> <booktitle> In Proceedings of SIGGRAPH '93( Anaheim, </booktitle> <address> CA, </address> <month> August 1-6). </month> <booktitle> In Computer Graphics Proceedings, Annual Conference series, ACM SIGGRAPH, </booktitle> <pages> pages 19-26, </pages> <year> 1993. </year>
Reference-contexts: The main idea underlying all the works proposed in the literature to pursue the first goal is that a simplified model can be built based on a reduced set of data. The main approaches to the construction of approximate models are iterative, and can be classified into simplification methods <ref> [25, 28, 21, 17, 27] </ref> - i.e., methods that start from the full resolution and progressively reduce the dataset on which the model is based, in order to coarsen resolution; and refinement methods [13, 16, 8, 23, 12, 5] - i.e., methods that start from a very coarse approximation based on
Reference: [18] <author> K. Kaneda, F. Kato, E. Nakamae, T. Nishita, H. Tanaka, and T. Noguchi. </author> <title> Three dimensional terrain modeling and display for environment assessment. </title> <journal> ACM Computer Graphics, </journal> <volume> 23(3) </volume> <pages> 207-214, </pages> <month> July </month> <year> 1989. </year> <month> 19 </month>
Reference-contexts: An interesting yet not much explored application of multiresolution models is rendering at variable resolutions over various zones of the surface/object/volume. A typical example is in landscape visualization for either flight simulators, or environmental assessment <ref> [18] </ref>: the detail of the terrain model presented to the user may be variable, depending on the distance from the point of view. Multiresolution allows a larger number of polygons to be rendered only in the areas where the visual impact is at its most significant.
Reference: [19] <author> T.K. Peucker and D.H. Douglas. </author> <title> Detection of surface-specific points by local parallel processing of discrete terrain elevation data. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 4 </volume> <pages> 375-387, </pages> <year> 1975. </year>
Reference-contexts: The most common approach is to base point selection on the impact, in terms of error reduction/increase, which is caused by the insertion/deletion of a point into/from the dataset. Many authors have also tried to preprocess data to extract meaningful features, in the form of points and lines <ref> [19, 29, 22, 26] </ref>. Other authors have attempted to improve results by shifting the vertices so that curvature within the triangles is nearly equal, or by removing unnecessary triangles [24].
Reference: [20] <author> J. Ponce and O. Faugeras. </author> <title> An object centered hierarchical representation for 3d objects: the prism tree. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 38(1) </volume> <pages> 1-28, </pages> <month> Apr. </month> <year> 1987. </year>
Reference-contexts: 1 Introduction The search for multiresolution representation schemes has recently become very popular. Major applications involve generic surfaces embedded in 3D space [16, 8, 27], terrains in the context of Geographical Information Systems [10, 23, 12], 3D objects for classical CAD and recognition <ref> [9, 20, 21] </ref>, and volume data [5, 31, 30]. <p> The models proposed in the literature to pursue the second goal can be broadly classified 2 into multi-layer models [10, 5] - i.e., frameworks that relate a sequence of independent models of the whole object represented at different levels of resolution and tree models <ref> [9, 20, 16, 8, 23, 12, 21, 27] </ref> - i.e., models in which a hierarchy of descriptions is represented by a tree, where each node corresponds to the description of (a portion of) an object at a given level of resolution, while each of its children represents a more detailed description
Reference: [21] <author> J. Rossignac and P. Borrel. </author> <title> Multi-resolution 3d approximations for rendering complex scenes. </title> <editor> In T. Kunii B. Falcidieno, editor, </editor> <booktitle> Modeling in Computer Graphics, </booktitle> <pages> pages 455-465. </pages> <publisher> Springer-Verlag, </publisher> <month> October 17-18 </month> <year> 1993. </year>
Reference-contexts: 1 Introduction The search for multiresolution representation schemes has recently become very popular. Major applications involve generic surfaces embedded in 3D space [16, 8, 27], terrains in the context of Geographical Information Systems [10, 23, 12], 3D objects for classical CAD and recognition <ref> [9, 20, 21] </ref>, and volume data [5, 31, 30]. <p> The main idea underlying all the works proposed in the literature to pursue the first goal is that a simplified model can be built based on a reduced set of data. The main approaches to the construction of approximate models are iterative, and can be classified into simplification methods <ref> [25, 28, 21, 17, 27] </ref> - i.e., methods that start from the full resolution and progressively reduce the dataset on which the model is based, in order to coarsen resolution; and refinement methods [13, 16, 8, 23, 12, 5] - i.e., methods that start from a very coarse approximation based on <p> The models proposed in the literature to pursue the second goal can be broadly classified 2 into multi-layer models [10, 5] - i.e., frameworks that relate a sequence of independent models of the whole object represented at different levels of resolution and tree models <ref> [9, 20, 16, 8, 23, 12, 21, 27] </ref> - i.e., models in which a hierarchy of descriptions is represented by a tree, where each node corresponds to the description of (a portion of) an object at a given level of resolution, while each of its children represents a more detailed description
Reference: [22] <author> L. Scarlatos. </author> <title> An automatic critical line detector for digital elevation matrices. </title> <booktitle> In Proceedings 1990 ACSM-ASPRS Annual Convention, Denver, CO, </booktitle> <volume> volume 2, </volume> <pages> pages 43-52, </pages> <month> March 18-23 </month> <year> 1990. </year>
Reference-contexts: The most common approach is to base point selection on the impact, in terms of error reduction/increase, which is caused by the insertion/deletion of a point into/from the dataset. Many authors have also tried to preprocess data to extract meaningful features, in the form of points and lines <ref> [19, 29, 22, 26] </ref>. Other authors have attempted to improve results by shifting the vertices so that curvature within the triangles is nearly equal, or by removing unnecessary triangles [24].
Reference: [23] <author> L. Scarlatos and T. Pavlidis. </author> <title> Hierarchical Triangulation Using Cartographic Coherence. CVGIP: Graphical Models and Image Processing, </title> <booktitle> 34(2) </booktitle> <pages> 147-161, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: 1 Introduction The search for multiresolution representation schemes has recently become very popular. Major applications involve generic surfaces embedded in 3D space [16, 8, 27], terrains in the context of Geographical Information Systems <ref> [10, 23, 12] </ref>, 3D objects for classical CAD and recognition [9, 20, 21], and volume data [5, 31, 30]. <p> main approaches to the construction of approximate models are iterative, and can be classified into simplification methods [25, 28, 21, 17, 27] - i.e., methods that start from the full resolution and progressively reduce the dataset on which the model is based, in order to coarsen resolution; and refinement methods <ref> [13, 16, 8, 23, 12, 5] </ref> - i.e., methods that start from a very coarse approximation based on a very small dataset, and progressively refine it by inserting new data, in order to improve resolution. <p> The models proposed in the literature to pursue the second goal can be broadly classified 2 into multi-layer models [10, 5] - i.e., frameworks that relate a sequence of independent models of the whole object represented at different levels of resolution and tree models <ref> [9, 20, 16, 8, 23, 12, 21, 27] </ref> - i.e., models in which a hierarchy of descriptions is represented by a tree, where each node corresponds to the description of (a portion of) an object at a given level of resolution, while each of its children represents a more detailed description
Reference: [24] <author> L. Scarlatos and T. Pavlidis. </author> <title> Optimizing Triangulations by Curvature Equalization. </title> <editor> In A. Kaufman G. Nielson, editor, </editor> <booktitle> Visualization '92 Proceedings, </booktitle> <pages> pages 333-339. </pages> <publisher> IEEE Press, </publisher> <year> 1992. </year>
Reference-contexts: Many authors have also tried to preprocess data to extract meaningful features, in the form of points and lines [19, 29, 22, 26]. Other authors have attempted to improve results by shifting the vertices so that curvature within the triangles is nearly equal, or by removing unnecessary triangles <ref> [24] </ref>. Finding the best method to select from a set of sites the vertices or edges on which the triangulation has to be built is still an open issue.
Reference: [25] <author> W.J. Schroeder, J.A. Zarge, and W. Lorensen. </author> <title> Decimation of triangle mesh. </title> <journal> ACM Computer Graphics, </journal> <volume> 26(2) </volume> <pages> 65-70, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: The main idea underlying all the works proposed in the literature to pursue the first goal is that a simplified model can be built based on a reduced set of data. The main approaches to the construction of approximate models are iterative, and can be classified into simplification methods <ref> [25, 28, 21, 17, 27] </ref> - i.e., methods that start from the full resolution and progressively reduce the dataset on which the model is based, in order to coarsen resolution; and refinement methods [13, 16, 8, 23, 12, 5] - i.e., methods that start from a very coarse approximation based on
Reference: [26] <author> D.A. Southard. </author> <title> Piecewise linear surface models from sampled data. </title> <booktitle> In Proceedings of Computer Graphics International '91, </booktitle> <pages> pages 667-680, </pages> <month> June 22-28 </month> <year> 1991. </year>
Reference-contexts: The most common approach is to base point selection on the impact, in terms of error reduction/increase, which is caused by the insertion/deletion of a point into/from the dataset. Many authors have also tried to preprocess data to extract meaningful features, in the form of points and lines <ref> [19, 29, 22, 26] </ref>. Other authors have attempted to improve results by shifting the vertices so that curvature within the triangles is nearly equal, or by removing unnecessary triangles [24].
Reference: [27] <author> D.C. Taylor and W.A. Barrett. </author> <title> An Algorithm for Continuous Resolution Polygonalization of a Discrete Surface. </title> <booktitle> In Graphics Interface '94 Proceedings, </booktitle> <pages> pages 33-42, </pages> <year> 1994. </year>
Reference-contexts: 1 Introduction The search for multiresolution representation schemes has recently become very popular. Major applications involve generic surfaces embedded in 3D space <ref> [16, 8, 27] </ref>, terrains in the context of Geographical Information Systems [10, 23, 12], 3D objects for classical CAD and recognition [9, 20, 21], and volume data [5, 31, 30]. <p> The main idea underlying all the works proposed in the literature to pursue the first goal is that a simplified model can be built based on a reduced set of data. The main approaches to the construction of approximate models are iterative, and can be classified into simplification methods <ref> [25, 28, 21, 17, 27] </ref> - i.e., methods that start from the full resolution and progressively reduce the dataset on which the model is based, in order to coarsen resolution; and refinement methods [13, 16, 8, 23, 12, 5] - i.e., methods that start from a very coarse approximation based on <p> The models proposed in the literature to pursue the second goal can be broadly classified 2 into multi-layer models [10, 5] - i.e., frameworks that relate a sequence of independent models of the whole object represented at different levels of resolution and tree models <ref> [9, 20, 16, 8, 23, 12, 21, 27] </ref> - i.e., models in which a hierarchy of descriptions is represented by a tree, where each node corresponds to the description of (a portion of) an object at a given level of resolution, while each of its children represents a more detailed description
Reference: [28] <author> G. Turk. </author> <title> Re-Tiling Polygonal Surfaces. </title> <journal> ACM Computer Graphics, </journal> <volume> 26(2) </volume> <pages> 55-64, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: The main idea underlying all the works proposed in the literature to pursue the first goal is that a simplified model can be built based on a reduced set of data. The main approaches to the construction of approximate models are iterative, and can be classified into simplification methods <ref> [25, 28, 21, 17, 27] </ref> - i.e., methods that start from the full resolution and progressively reduce the dataset on which the model is based, in order to coarsen resolution; and refinement methods [13, 16, 8, 23, 12, 5] - i.e., methods that start from a very coarse approximation based on
Reference: [29] <author> L.T. Watson, T.J. Laffey, and R.M. Haralick. </author> <title> Topographic classification of digital image intensity surfaces using generalized splines and the discrete cosine transformation. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 29 </volume> <pages> 143-167, </pages> <month> Apr. </month> <year> 1985. </year>
Reference-contexts: The most common approach is to base point selection on the impact, in terms of error reduction/increase, which is caused by the insertion/deletion of a point into/from the dataset. Many authors have also tried to preprocess data to extract meaningful features, in the form of points and lines <ref> [19, 29, 22, 26] </ref>. Other authors have attempted to improve results by shifting the vertices so that curvature within the triangles is nearly equal, or by removing unnecessary triangles [24].
Reference: [30] <author> R. Westermann. </author> <title> A Multiresolution Framework for Volume Rendering. </title> <booktitle> In Proceedings of 1994 Symposium on Volume Visualization, </booktitle> <pages> pages 51-58. </pages> <publisher> ACM Press, </publisher> <month> October 17-18 </month> <year> 1994. </year> <month> 20 </month>
Reference-contexts: 1 Introduction The search for multiresolution representation schemes has recently become very popular. Major applications involve generic surfaces embedded in 3D space [16, 8, 27], terrains in the context of Geographical Information Systems [10, 23, 12], 3D objects for classical CAD and recognition [9, 20, 21], and volume data <ref> [5, 31, 30] </ref>. All such models are based on the idea that a detailed 1 digital model taken as input can be simplified into an approximate representation: appropriate measures of fidelity to the original model are taken as a quantitative mean to define multiple resolution levels.
Reference: [31] <author> J. Wilhelms and A. Van Gelder. </author> <title> Multi-dimensional Trees for Controlled Volume Rendering and Compression. </title> <booktitle> In Proceedings of 1994 Symposium on Volume Visualization, </booktitle> <pages> pages 27-34. </pages> <publisher> ACM Press, </publisher> <month> October 17-18 </month> <year> 1994. </year> <month> 21 </month>
Reference-contexts: 1 Introduction The search for multiresolution representation schemes has recently become very popular. Major applications involve generic surfaces embedded in 3D space [16, 8, 27], terrains in the context of Geographical Information Systems [10, 23, 12], 3D objects for classical CAD and recognition [9, 20, 21], and volume data <ref> [5, 31, 30] </ref>. All such models are based on the idea that a detailed 1 digital model taken as input can be simplified into an approximate representation: appropriate measures of fidelity to the original model are taken as a quantitative mean to define multiple resolution levels.
References-found: 31

