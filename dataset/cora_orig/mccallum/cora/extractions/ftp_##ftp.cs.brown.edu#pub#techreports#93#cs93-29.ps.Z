URL: ftp://ftp.cs.brown.edu/pub/techreports/93/cs93-29.ps.Z
Refering-URL: http://www.cs.brown.edu/publications/techreports/reports/CS-93-29.html
Root-URL: http://www.cs.brown.edu/
Abstract-found: 0
Intro-found: 1
Reference: [1] , <institution> Scheduling with Application to Register Allocation and Deadlock Problems," University of Waterloo, </institution> <type> PhD Thesis, </type> <year> 1976. </year>
Reference: [2] <author> Abdel-Wahab, H. M. & Kameda, T., </author> <title> Scheduling to Minimize Maximum Cumulative Cost Subject to Series-parallel Precedence Constraints," Operations Research 26 (1978), 141158. [3] , On Strictly Optimal Schedules for the Cumulative Cost-Optimal Scheduling Problem," </title> <booktitle> Computing 24 (1980), </booktitle> <pages> 6186. </pages>
Reference-contexts: The SMMCC problem is NP-complete in general [1,5], but Abdel-Wahab and Kameda present an O (n 2 )-time algorithm for the special case where G is a series-parallel graph <ref> [2] </ref> (the time bound was later improved to O (n log n) [3]). As part of this solution, they give an O (n log p)-time algorithm applicable when G is a chain graph, a graph consisting of a union of p disjoint directed paths. <p> Thus we shall be interested in computing (G [ fabg) for pairs a; b of nodes of G. Now we introduce some terminology having to do with schedules. Much of this terminology is adapted from that in <ref> [2] </ref>. A segment of a schedule is a consecutive subsequence. Let H = v j v j+1 v k be a sequence consisting of some of the nodes of G. The cost of H, denoted s (H), is the sum of the costs of its nodes. <p> Three lemmas are useful to our results. They are all generalizations of lemmas in <ref> [2] </ref>. The first lemma concerns an operation on a schedule called clustering the nodes of a hump. Suppose H is a hump in G, and let v be a useful peak of H. Let S be a schedule of G. <p> This one is obtained from the previous schedule by clustering every hump. (e) A clustered schedule of G of minimum height. The proof is a modification of the proof in <ref> [2] </ref> of a similar lemma that requires G 0 to be a chain graph. An example is shown in Figure 4. The height of the schedule in (c) is smaller than that of the schedule in (b). <p> If the series of BA is in standard form then either h (S) h (T 1 ) or h (S) h (T 2 ). The proof of Lemma 4 is a modification of a similar lemma in <ref> [2] </ref> that requires A and B to be humps and requires S, T 1 , and T 2 to be schedules of G 0 . The following lemma is immediate from Lemma 4; we simply let S 2 be empty. Lemma 5.
Reference: [4] <author> Emrath, P. A., Ghosh, S. & Padua, D. A., </author> <title> Event Synchronization Analysis for Debugging Parallel Programs," </title> <booktitle> Supercomputing '89 (November 1989), </booktitle> <pages> 580588. </pages>
Reference: [5] <author> Garey, M. R. & Johnson, D. S., </author> <title> Computers and IntractabilityA Guide to the Theory of NP-Completeness, </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <year> 1979. </year>
Reference: [6] <author> Helmbold, D. P. & McDowell, C. E., </author> <title> A Class of Synchronization Operations that Permit Efficient Race Detection," </title> <institution> University of California at Santa Cruz Technical Report (January 1993). </institution>
Reference: [7] <author> Helmbold, D. P., McDowell, C. E. & Wang, J-Z., </author> <title> Analyzing Traces with Anonymous Synchronization," </title> <booktitle> International Conference on Parallel Processing (August 1990), II70II77. </booktitle> <pages> 12 </pages>
Reference: [8] <author> Netzer, R. H. B. & Ghosh, S., </author> <title> Efficient Race Condition Detection for Shared-Memory Programs with Post/Wait Synchronization," </title> <booktitle> International Conference on Parallel Processing (August 1992), </booktitle> <address> II242II246. </address>
Reference: [9] <author> Netzer, R. H. B. & Miller, B. P., </author> <title> On the Complexity of Event Ordering for Shared-Memory Parallel Program Executions," </title> <booktitle> International Conference on Parallel Processing (August 1990), II93II97. </booktitle> <pages> 13 </pages>
Reference-contexts: Our algorithms can be used to exactly detect race conditions in executions of such programs. Past work has shown that exactly detecting races in programs that use multiple semaphores is NP-complete <ref> [9] </ref>, and has developed exact algorithms for other cases where the problem is efficiently solvable (programs that use types of synchronization weaker than semaphores) [6,8], and heuristics for the multiple semaphore case [4,7]. The complexity for the case of a single semaphore has been an open question.
References-found: 8

