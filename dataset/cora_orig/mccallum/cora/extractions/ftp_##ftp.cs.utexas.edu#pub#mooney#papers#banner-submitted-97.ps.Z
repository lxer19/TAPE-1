URL: ftp://ftp.cs.utexas.edu/pub/mooney/papers/banner-submitted-97.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/ml/abstracts.html
Root-URL: 
Email: Email sowmya@cs.utexas.edu  
Title: Parameter Revision Techniques for Bayesian Networks with Hidden Variables: An Experimental Comparison  
Author: Sowmya Ramachandran, Raymond J. Mooney 
Date: February 22, 1997  
Address: Austin, TX 78712-1188  
Affiliation: Department of Computer Sciences, University of Texas,  
Abstract: Multiple Submission Statement: We intend to submit a version of this paper to The Third International Conference on Knowledge Discovery and Data Mining, 1997 (KDD-97). If this paper is accepted for publication at UAI-97 we will withdraw it from KDD-97. Abstract Learning Bayesian networks inductively in the presence of hidden variables is still an open problem. Even the simpler task of learning just the conditional probabilities on a Bayesian network with hidden variables is not completely solved. In this paper, we present an approach that learns the parameters of a Bayesian network composed of noisy-or and noisy-and nodes by using a gradient descent back-propagation approach similar to that used to train neural networks. For the task of causal inference, it has the advantage of being able to learn in the presence of hidden variables. We compare the performance of this approach with the adaptive probabilistic networks technique on a real-world classification problem in molecular biology, and show that our approach trains faster and learns networks with higher classification accuracy.
Abstract-found: 1
Intro-found: 1
Reference: <author> Baffes, P., & Mooney, R. </author> <year> (1993). </year> <title> Symbolic revision of theories with M-of-N rules. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 1135-1140 Chambery, France. </address>
Reference: <author> Buntine, W. </author> <year> (1991). </year> <title> Theory refinement on Bayesian networks. </title> <booktitle> In Proceedings of the Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pp. 52-60. </pages>
Reference: <author> Connolly, D. </author> <year> (1993). </year> <title> Constructing hidden variables in Bayesian networks via conceptual clustering. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 65-72 Amherst, MA. </address>
Reference: <author> Cooper, G. G., & Herskovits, E. </author> <year> (1992). </year> <title> A Bayesian method for the induction of probabilistic networks from data. </title> <journal> Machine Learning, </journal> <volume> 9, </volume> <pages> 309-347. </pages>
Reference: <author> Dempster, A., Laird, N., & Rubin, D. </author> <year> (1977). </year> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> 39, </volume> <pages> 1-38. </pages>
Reference: <author> Fisher, D. H. </author> <year> (1987). </year> <title> Knowledge acquisition via incremental conceptual clustering. </title> <journal> Machine Learning, </journal> <volume> 2, </volume> <pages> 139-172. </pages>
Reference-contexts: Most of the above techniques could be adapted to discover hidden variables, but at a great cost involving brute force search. Connolly (1993) has proposed using clustering techniques <ref> (Fisher, 1987) </ref> to discover hidden variables. However, this technique can only learn tree structured networks. Figure 1 summarizes these learning scenarios and the techniques that handle them. (Heckerman, 1995) provides a good tutorial on the state-of-the-art with respect to learning Bayesian networks.
Reference: <author> Friedman, N., & Goldszmidt, M. </author> <year> (1996). </year> <title> Building classifiers using Bayesian networks. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 1277-1284. </pages>
Reference: <author> Geman, S., & Geman, D. </author> <year> (1984). </year> <title> Stochastic relaxation, Gibbs distributions and the Bayesian restoration of images. </title> <journal> IEEE transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6, </volume> <pages> 721-742. </pages>
Reference-contexts: The problem of learning the parameters for a network with a given structure, in the presence of hidden variables, has also received some attention. Many statistical techniques like Gibbs sampling <ref> (Geman & Geman, 1984) </ref> and EM (Dempster, Laird, & Rubin, 1977; Lauritzen, 1995) can be used in the context of Bayesian networks. APEM (Thiesson, 1995) is a statistical technique that combines EM and gradient descent approaches to learn the parameters of a network. <p> In the case of data that is missing some values, approximation methods like Gibbs Sampling <ref> (Ge-man & Geman, 1984) </ref> and EM (Dempster et al., 1977; Lauritzen, 1995) have been proposed. Both these methods require some initialization of the parameters and data for the missing variables. The complete data is then sampled to compute new values for the parameters.
Reference: <author> Heckerman, D. </author> <year> (1995). </year> <title> A tutorial on learning Bayesian networks. </title> <type> Tech. rep. </type> <institution> MSR-TR-95-06, Microsoft Research, Advanced Technology Division, Microsoft Corporation, One Microsoft Way, </institution> <address> Redmond, WA 98052. </address>
Reference-contexts: Connolly (1993) has proposed using clustering techniques (Fisher, 1987) to discover hidden variables. However, this technique can only learn tree structured networks. Figure 1 summarizes these learning scenarios and the techniques that handle them. <ref> (Heckerman, 1995) </ref> provides a good tutorial on the state-of-the-art with respect to learning Bayesian networks. Thus, while researchers have a grasp on some aspects of learning Bayesian networks, the problem of inducing Bayesian networks with unknown structures and hidden variables still poses a tough challenge.
Reference: <author> Heckerman, D., Geiger, D., & Chikering, D. M. </author> <year> (1994). </year> <title> Learning Bayesian networks: The combination of knowledge and statistical data. </title> <booktitle> In Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 293-301 Seattle, WA. </address>
Reference: <author> Kwoh, C.-K., & Gillies, D. </author> <year> (1996). </year> <title> Using hidden nodes in Bayesian networks. </title> <journal> Artificial Intelligence, </journal> <volume> 88 (1-2), </volume> <pages> 1-38. </pages>
Reference: <author> Lam, W., & Bacchus, F. </author> <year> (1994). </year> <title> Using new data to refine a Bayesian network. </title> <booktitle> In Proceedings of the Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pp. 383-390. </pages>
Reference: <author> Langley, P., Iba, W., & Thompson, K. </author> <year> (1992). </year> <title> An analysis of Bayesian classifiers. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 223-228. </pages>
Reference: <author> Lauritzen, S. L. </author> <year> (1995). </year> <title> The EM algorithm for graphical association models with missing data. </title> <journal> Computational Statistics and Data Analysis, </journal> <volume> 19, </volume> <pages> 191-201. </pages>
Reference: <author> Mahoney, J. J. </author> <year> (1996). </year> <title> Combining Symbolic and Connectionist Learning to Revise Certainty-Factor Rule Bases. </title> <type> Ph.D. thesis, </type> <institution> University of Texas, Austin, TX. </institution>
Reference-contexts: Since it is based on APN, it is just as general. The approach is also compared to a "naive" Bayesian classifier and a previous rule-based revision system that has the currently best known performance on this task <ref> (Mahoney, 1996) </ref>. We begin with a description of the details of Banner, APN and C-APN. This is followed by a discussion of the experimental evaluation of these techniques.
Reference: <author> Mahoney, J. J., & Mooney, R. J. </author> <year> (1993). </year> <title> Combining connectionist and symbolic learning to refine certainty-factor rule-bases. </title> <journal> Connection Science, </journal> <volume> 5, </volume> <pages> 339-364. </pages>
Reference-contexts: The learning curves clearly demonstrate that our technique is successful at learning a network with a high classification accuracy. They also show that Banner outperforms APN and C-APN significantly. It also performs better than naive Bayes. Rapture <ref> (Mahoney & Mooney, 1993, 1994) </ref> is a system that uses a connectionist approach to revise certainty-factor rule bases. Among a number of theory-revision systems that have been evaluated on this problem, Rapture currently 10 has the best performance. <p> As such, their computations are only valid for tree-structured networks and do not handle noisy-or/and nodes. Our research was initially motivated by previous research on Rapture <ref> (Mahoney & Mooney, 1993, 1994) </ref>. While Rapture is concerned with applying symbolic and connectionist techniques to revise certainty factor rule bases, we address the same problem for Bayesian networks.
Reference: <author> Mahoney, J. J., & Mooney, R. J. </author> <year> (1994). </year> <title> Comparing methods for refining certainty-factor rule bases. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 173-180 New Brunswick, NJ. </address>
Reference: <author> McClelland, J. L., & Rumelhart, D. E. </author> <year> (1988). </year> <title> Explorations in Parallel Distributed Processing: A Handbook of Models, Programs, and Exercises. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: We conclude with a discussion of where we hope to take our research in the future. 2 Overview of Banner The learning algorithm used by Banner is analogous to the standard backpropagation algorithm used to train a multi-layered feedforward network <ref> (McClelland & Rumelhart, 1988) </ref>. It uses gradient descent to minimize the mean-squared error between the measured and computed values of certain output variables. The algorithm is as follows: 1. Initialize the parameters of the network either randomly or based on some prior knowledge. 2. <p> Schwalb (1993) addresses the problem of learning the parameters of a given Bayesian network by mapping it onto a neural network with SIGMA-PI nodes and learning the conditional probabilities associated with the network (represented by link weights in the corresponding neural network) using standard backpropagation techniques <ref> (McClelland & Rumelhart, 1988) </ref>. This has the advantage that it is able to learn the conditional probabilities even in the presence of hidden variables.
Reference: <author> Musick, R. C. </author> <year> (1994). </year> <title> Belief Network Induction. </title> <type> Ph.D. thesis, </type> <institution> University of California at Berkeley. </institution>
Reference: <author> Neal, R. M. </author> <year> (1992). </year> <title> Connectionist learning of belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 56, </volume> <pages> 71-113. </pages>
Reference: <author> Ourston, D., & Mooney, R. </author> <year> (1990). </year> <title> Changing the rules: A comprehensive approach to theory refinement. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 815-820 Detroit, MI. </address>
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, Inc., </publisher> <address> San Mateo,CA. </address>
Reference: <author> Pradhan, M., Provan, G., Middleton, B., & Henrion, M. </author> <year> (1994). </year> <title> Knowledge engineering for large belief networks. </title> <booktitle> In Proceedings of the Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 484-490 Seattle, WA. </address>
Reference: <author> Provan, G. M., & Singh, M. </author> <year> (1994). </year> <title> Learning Bayesian networks using feature selection. </title> <booktitle> In Proceedings of the Workshop on Artificial Intelligence and Statistics. </booktitle>
Reference: <author> Quinlan, J. R. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 (1), </volume> <pages> 81-106. </pages> <note> 15 Ramachandran, </note> <author> S., & Mooney, R. J. </author> <year> (1996). </year> <title> Revising Bayesian network parameters using back-propagation. </title> <note> Unpublished. </note>
Reference-contexts: This procedure would also help identify and localize the types of revisions (e.g. by adding a parent, removing a parent etc.) that would help remove these inconsistencies. It would then use information gain <ref> (Quinlan, 1986) </ref> to determine the nodes to be added or deleted from the parent set of a node.
Reference: <author> Rissanen, J. </author> <year> (1978). </year> <title> Modeling by shortest data description. </title> <journal> Automatica, </journal> <volume> 14, </volume> <pages> 465-471. </pages>
Reference-contexts: The more complex the domain, the more the advantage of such 2 a bias. There has been some research on revising Bayesian networks. Lam and Bacchus (1994) have a technique for incrementally refining a Bayesian network using the Minimum Description Length principle <ref> (Rissanen, 1978) </ref>. Buntine (1991) has proposed a technique for revising a Bayesian network efficiently, using scoring metrics similar to that proposed by Cooper and Herskovits (1992). However, neither of these techniques can revise networks with hidden variables.
Reference: <author> Russell, S., Binder, J., Koller, D., & Kanazawa, K. </author> <year> (1995). </year> <title> Local learning in probabilistic networks with hidden variables. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 1146-1152 Montreal, Canada. </address>
Reference-contexts: APEM (Thiesson, 1995) is a statistical technique that combines EM and gradient descent approaches to learn the parameters of a network. APN <ref> (Russell, Binder, Koller, & Kanazawa, 1995) </ref> is an approach that optimizes the probability of the data given the network using a gradient descent algorithm. The learning problem addressed by Cooper and Herskovits (1992) falls in the third category. <p> We then compare the performance of Banner with two other techniques for parameter revision on a real-world learning problem of DNA promoter recognition (Towell et al., 1990). These are: 1. Adaptive Probabilistic Networks (APN) <ref> (Russell et al., 1995) </ref>: This technique uses gradient descent to learn a network that optimizes the likelihood of the given data being generated by the network. This is a general algorithm that does not place many restrictions on the kinds of distributions it can learn.
Reference: <author> Schwalb, E. </author> <year> (1993). </year> <title> Compiling Bayesian networks into neural networks. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 291-297 Amherst, MA. </address>
Reference: <author> Spiegelhalter, D. J., & Lauritzen, S. L. </author> <year> (1990). </year> <title> Sequential updating of conditional probabilities on directed graphical structures. </title> <journal> Networks, </journal> <volume> 20, </volume> <pages> 579-605. </pages>
Reference-contexts: The first of these is fairly straightforward. A common approach is to use the maximum likelihood estimates for the parameters, which in the case of no hidden variables, reduces to a function of the relative frequencies of occurrences of the values of the variable <ref> (Spiegelhalter & Lauritzen, 1990) </ref>. The problem of learning the parameters for a network with a given structure, in the presence of hidden variables, has also received some attention.
Reference: <author> Srinivas, S., & Breese, J. </author> <year> (1993). </year> <title> Ideal: Influence diagram evaluation and analysis in Lisp: Documentation and users' guide. </title> <type> Tech. rep. No. 23, </type> <institution> Rockwell International Science Center, Palo Alto: Rockwell. </institution>
Reference-contexts: Although, the authors do not report any results on noisy-or models, they point out how their technique can be extended to compute gradients for noisy-or parameters. Our implementation of APN, built on top of IDEAL <ref> (Srinivas & Breese, 1993) </ref>, can handle noisy-or and noisy-and nodes in addition to general discrete-valued, probabilistic nodes. 1 @ ln P w (D) = l=1 w ijk where m is the number of training instances, x ij is the jth possible assignment to variable X i , u ik is the
Reference: <author> Thiesson, B. </author> <year> (1995). </year> <title> Accelerated quantification of Bayesian networks with incomplete data. </title> <editor> In Fayyad, U. M., & Uthurusamy, R. (Eds.), </editor> <booktitle> Proceedings of the First International Conference on Knowledge Discovery and Data Mining, </booktitle> <pages> pp. 306-11. </pages> <publisher> AAAI Press. </publisher>
Reference-contexts: Many statistical techniques like Gibbs sampling (Geman & Geman, 1984) and EM (Dempster, Laird, & Rubin, 1977; Lauritzen, 1995) can be used in the context of Bayesian networks. APEM <ref> (Thiesson, 1995) </ref> is a statistical technique that combines EM and gradient descent approaches to learn the parameters of a network. APN (Russell, Binder, Koller, & Kanazawa, 1995) is an approach that optimizes the probability of the data given the network using a gradient descent algorithm. <p> The complete data is then sampled to compute new values for the parameters. These steps are repeated until some convergence criteria is met. The goal of these methods is to optimize the likelihood of the data given the network. APEM <ref> (Thiesson, 1995) </ref> is a technique that combines traditional EM with gradient descent methods for faster convergence. Preliminary experiments with using APEM 3 on the DNA promoter recognition problem did not yield encouraging results (Ramachandran & Mooney, 1996).
Reference: <author> Towell, G. G., Shavlik, J. W., & Noordewier, M. O. </author> <year> (1990). </year> <title> Refinement of approximate domain theories by knowledge-based artificial neural networks. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 861-866 Boston, MA. </address> <month> 16 </month>
Reference-contexts: The reason for these restrictions will become clear when we present the details of the algorithm. We then compare the performance of Banner with two other techniques for parameter revision on a real-world learning problem of DNA promoter recognition <ref> (Towell et al., 1990) </ref>. These are: 1. Adaptive Probabilistic Networks (APN) (Russell et al., 1995): This technique uses gradient descent to learn a network that optimizes the likelihood of the given data being generated by the network. <p> In our experiment, we follow the standard methodology used to evaluate machine learning methods, i.e. that of studying the effect of training by determining the classification accuracy of the trained network on a separate test set. We use a real-world classification problem of DNA promoter recognition <ref> (Towell et al., 1990) </ref> to evaluate the learning algorithms. This problem comes with an initial domain theory (rule base) provided by a domain expert and independent data for use in training and testing.
References-found: 32

