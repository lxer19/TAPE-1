URL: http://cobar.cs.umass.edu/pubfiles/cb-16.ps
Refering-URL: http://cobar.cs.umass.edu/pubfiles/
Root-URL: 
Email: Email: fDaniels, Risslandg@cs.umass.edu  
Phone: Phone: (413) 545-3639  
Title: A Case-Based Approach to Intelligent Information Retrieval  
Author: Jody J. Daniels and Edwina L. Rissland 
Address: Amherst, MA 01003 USA  
Affiliation: Department of Computer Science University of Massachusetts  
Abstract: We have built a hybrid Case-Based Reasoning (CBR) and Information Retrieval (IR) system that generates a query to the IR system by using information derived from CBR analysis of a problem situation. The query is automatically formed by submitting in text form a set of highly relevant cases, based on a CBR analysis, to a modified version of INQUERY's relevance feedback module. This approach extends the reach of CBR, for retrieval purposes, to much larger corpora and injects knowledge-based techniques into traditional IR. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Kevin D. Ashley. </author> <title> Modeling Legal Argument: Reasoning with Cases and Hypotheticals. </title> <publisher> M.I.T. Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: Among current case-based reasoning systems few have large case bases (say, larger than 1000 cases). Those systems that have supported large case bases-containing thousands or even tens of thousands of cases-have employed simple case representations (e.g., MBRtalk [17], PACE [4], Anapron [7] ). Our own CBR systems-HYPO <ref> [1] </ref> [11], CABARET [15], BankXX [12] [13]-perform in-depth reasoning to produce sophisticated precedent-based legal arguments, challenging hypothetical cases, interpretations of ill-defined legal concepts, etc. They use detailed case representations and they have typically had case bases in the range of three to five dozen cases. <p> Background on HYPO-style CBR In the CBR portion of the system, we use a CBR engine of the HYPO-style, with which we have had extensive experience <ref> [1] </ref>, [10], [11], [12], [13], [15]. In brief, HYPO-style CBR systems work as follows. First, a problem case is input and analyzed to see what dimensions, sometimes also called factors, are applicable in the problem case.
Reference: [2] <author> David C. Blair and M. E. Maron. </author> <title> An Evaluation of Retrieval Effectiveness for a Full-Text Document-Retrieval System. </title> <journal> Communications of the ACM, </journal> <volume> 28(3) </volume> <pages> 289-299, </pages> <month> March </month> <year> 1985. </year>
Reference-contexts: For instance, one study found that although the users felt that they had retrieved most of the right texts (i.e., that recall was high), in fact, they had only retrieved a mere 25% of the relevant texts <ref> [2] </ref>. A recurring problem is retrieving too much information, only some of which is really relevant. Bringing in specifics of the case at hand is one way to deal with this sort of problem. This is what an experienced user does and what the vendors of such systems recommend.
Reference: [3] <author> James P. Callan, W. Bruce Croft, and Stephen M. Harding. </author> <title> The INQUERY Retrieval System. </title> <editor> In A. M. Tjoa and I. Ramos, editors, </editor> <booktitle> Database and Expert Systems Applications: Proceedings of the International Conference in Valencia, Spain, </booktitle> <pages> pages 78-83, </pages> <address> Valencia, Spain, 1992. </address> <publisher> Springer Verlag, </publisher> <address> NY. </address>
Reference-contexts: Then texts associated with these selected cases are passed to a modified version of the relevance feedback (RF) mechanism of the INQUERY IR system <ref> [3] </ref>, which then generates a standard query consisting of the top n terms or top n pairs of terms generated from these texts. In the work reported here, for the texts we use the full texts of the court opinions.
Reference: [4] <author> Robert H. Creecy, Brij M. Masand, Stephen J. Smith, and David L. Waltz. </author> <title> Trading MIPs and Memory for Knowledge Engineering. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 48-64, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Among current case-based reasoning systems few have large case bases (say, larger than 1000 cases). Those systems that have supported large case bases-containing thousands or even tens of thousands of cases-have employed simple case representations (e.g., MBRtalk [17], PACE <ref> [4] </ref>, Anapron [7] ). Our own CBR systems-HYPO [1] [11], CABARET [15], BankXX [12] [13]-perform in-depth reasoning to produce sophisticated precedent-based legal arguments, challenging hypothetical cases, interpretations of ill-defined legal concepts, etc.
Reference: [5] <author> W. Bruce Croft and Raj Das. </author> <title> Experiments with Query Acquisition and Use in Document Retrieval Systems. </title> <booktitle> In 13th International Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 349-365, </pages> <year> 1990. </year>
Reference-contexts: Thus, not only is there limited cost associated with using this many terms, there is no detrimental effect. 4 In re Rasmussen, 888 F.2d 703 244 These results stand in contrast to those of Croft and Das, <ref> [5] </ref>, who found that relevance feedback may not be beneficial when using a small set of relevant documents. We found this not to be the case. Their belief is due to the potential lack of concept coverage by a small set of documents.
Reference: [6] <author> W. Bruce Croft, Howard R. Turtle, and David D. Lewis. </author> <title> The Use of Phrases and Structured Queries in Information Retrieval. </title> <booktitle> In Proceedings of the 14th Annual ACM/SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 32-45, </pages> <address> Chicago, IL, </address> <month> October </month> <year> 1991. </year> <note> ACM. </note>
Reference-contexts: For this paper we restrict these to be either terms or pairs of terms that must be found within a specified window or proximity. We use the same model for our pairs as was used for proximity pairs in <ref> [6] </ref>. We do not vary the selection metric nor the weighting metric, but use those developed by Haines and Croft [8]. They conducted a series of experiments using differing term selection and weighting schemes on two collections.
Reference: [7] <author> Andrew R. Golding and Paul S. Rosenbloom. </author> <title> Improving Rule-Based Systems Through Case-Based Reasoning. </title> <booktitle> In Proceedings, Ninth International Conference on Artificial Intelligence, </booktitle> <volume> volume 1, </volume> <pages> pages 22-27, </pages> <address> Anaheim, CA, </address> <month> July </month> <year> 1991. </year> <note> AAAI. </note>
Reference-contexts: Among current case-based reasoning systems few have large case bases (say, larger than 1000 cases). Those systems that have supported large case bases-containing thousands or even tens of thousands of cases-have employed simple case representations (e.g., MBRtalk [17], PACE [4], Anapron <ref> [7] </ref> ). Our own CBR systems-HYPO [1] [11], CABARET [15], BankXX [12] [13]-perform in-depth reasoning to produce sophisticated precedent-based legal arguments, challenging hypothetical cases, interpretations of ill-defined legal concepts, etc.
Reference: [8] <author> David Haines and Bruce Croft. </author> <title> Relevance Feedback and Inference Networks. </title> <type> Technical report, </type> <institution> University of Massachusetts at Amherst, </institution> <address> Amherst, MA, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: We use the same model for our pairs as was used for proximity pairs in [6]. We do not vary the selection metric nor the weighting metric, but use those developed by Haines and Croft <ref> [8] </ref>. They conducted a series of experiments using differing term selection and weighting schemes on two collections. One of their collections is very similar to the one used here: full-text legal cases. Therefore, we used their recommended term selection and weighting formulas. The selection and weighting criterion are described below. <p> The HOD-corpus contains cases addressing a great many legal questions. It was built by adding approximately 200 cases to another already existing, nearly 12,000 document collection, called the West or FSupp collection, <ref> [8] </ref>, [18]. The additional texts came from the cases found in the CABARET CKB and those found when the query home office was posed to the on-line WestLaw Rfl Federal Taxation Case Law database. <p> For comparison purposes, Figure 3 gives the total number of unique terms in each RF-CKB for the Weissman case as well as the average number of unique terms for a text and the average document size for each RF-CKB. Figures for the original FSupp collection are given as well <ref> [8] </ref>. 5.4 Answer Keys For each problem case, we constructed an answer key that specified the documents to be considered as relevant.
Reference: [9] <author> Janet L. Kolodner. </author> <title> Case-Based Reasoning. </title> <publisher> Morgan Kauf-mann, </publisher> <year> 1993. </year>
Reference-contexts: 1 Introduction One strength of Case-Based Reasoning (CBR) systems is the ability to reason about a problem case and perform highly intelligent problem-solving, such as the generation of legal arguments or detailed operational plans <ref> [9] </ref>. In particular, CBR systems have at their core the ability to retrieve highly relevant cases. However, CBR systems are limited by the availability of cases actually represented in their case bases. Among current case-based reasoning systems few have large case bases (say, larger than 1000 cases).
Reference: [10] <author> E. L. Rissland, J. J. Daniels, Z. B. Rubinstein, and D. B. Skalak. </author> <title> Case-Based Diagnostic Analysis in A Blackboard Architecture. </title> <booktitle> In Proceedings, The 11th National Conference on Artificial Intelligence, </booktitle> <pages> pages 66-72, </pages> <address> Washington D.C., </address> <month> July </month> <year> 1993. </year> <note> AAAI. </note>
Reference-contexts: Background on HYPO-style CBR In the CBR portion of the system, we use a CBR engine of the HYPO-style, with which we have had extensive experience [1], <ref> [10] </ref>, [11], [12], [13], [15]. In brief, HYPO-style CBR systems work as follows. First, a problem case is input and analyzed to see what dimensions, sometimes also called factors, are applicable in the problem case.
Reference: [11] <author> Edwina L. Rissland and Kevin D. Ashley. </author> <title> A Case-Based System for Trade Secrets Law. </title> <booktitle> In Proceedings, First International Conference on Artificial Intelligence and Law. ACM, </booktitle> <publisher> ACM Press, </publisher> <month> May </month> <year> 1987. </year>
Reference-contexts: Among current case-based reasoning systems few have large case bases (say, larger than 1000 cases). Those systems that have supported large case bases-containing thousands or even tens of thousands of cases-have employed simple case representations (e.g., MBRtalk [17], PACE [4], Anapron [7] ). Our own CBR systems-HYPO [1] <ref> [11] </ref>, CABARET [15], BankXX [12] [13]-perform in-depth reasoning to produce sophisticated precedent-based legal arguments, challenging hypothetical cases, interpretations of ill-defined legal concepts, etc. They use detailed case representations and they have typically had case bases in the range of three to five dozen cases. <p> In particular, our system first uses its HYPO-style CBR module ([1] <ref> [11] </ref>) to analyze the problem case with respect to the cases that are represented in its case-knowledge-base (CKB). This produces a sorting-actually a partial ordering-of cases relevant to the problem case according to how on-point they are (based on the model of relevance and on-pointness used in HYPO-style systems). <p> Background on HYPO-style CBR In the CBR portion of the system, we use a CBR engine of the HYPO-style, with which we have had extensive experience [1], [10], <ref> [11] </ref>, [12], [13], [15]. In brief, HYPO-style CBR systems work as follows. First, a problem case is input and analyzed to see what dimensions, sometimes also called factors, are applicable in the problem case. Dimensions address important legal aspects of cases and are used both to index and compare cases.
Reference: [12] <author> Edwina L. Rissland, D. B. Skalak, and M. Timur Friedman. BankXX: </author> <title> Supporting Legal Arguments through Heuristic Retrieval. </title> <type> Technical Report 94-76, </type> <institution> University of Massachusetts at Amherst, </institution> <address> Amherst, MA, </address> <year> 1994. </year>
Reference-contexts: Those systems that have supported large case bases-containing thousands or even tens of thousands of cases-have employed simple case representations (e.g., MBRtalk [17], PACE [4], Anapron [7] ). Our own CBR systems-HYPO [1] [11], CABARET [15], BankXX <ref> [12] </ref> [13]-perform in-depth reasoning to produce sophisticated precedent-based legal arguments, challenging hypothetical cases, interpretations of ill-defined legal concepts, etc. They use detailed case representations and they have typically had case bases in the range of three to five dozen cases. <p> Background on HYPO-style CBR In the CBR portion of the system, we use a CBR engine of the HYPO-style, with which we have had extensive experience [1], [10], [11], <ref> [12] </ref>, [13], [15]. In brief, HYPO-style CBR systems work as follows. First, a problem case is input and analyzed to see what dimensions, sometimes also called factors, are applicable in the problem case. Dimensions address important legal aspects of cases and are used both to index and compare cases. <p> We did not design new case representations for this project (i.e., for representing problem cases and cases in the CKB). Rather, we used pretty much as is the representations developed in two past CBR projects from our lab: CABARET [15] and BankXX [13] <ref> [12] </ref>. Both of these projects use a standard frame-based representation for cases, in which specific facts fill designated slots.
Reference: [13] <author> Edwina L. Rissland, D. B. Skalak, and M. Timur Friedman. </author> <title> Heuristic Harvesting of Information for Case-Based Argument. </title> <booktitle> In Proceedings, The 12th National Conference on Artificial Intelligence, </booktitle> <pages> pages 36-43, </pages> <address> Seattle, WA, </address> <month> August </month> <year> 1994. </year> <note> AAAI. </note>
Reference-contexts: Background on HYPO-style CBR In the CBR portion of the system, we use a CBR engine of the HYPO-style, with which we have had extensive experience [1], [10], [11], [12], <ref> [13] </ref>, [15]. In brief, HYPO-style CBR systems work as follows. First, a problem case is input and analyzed to see what dimensions, sometimes also called factors, are applicable in the problem case. Dimensions address important legal aspects of cases and are used both to index and compare cases. <p> We did not design new case representations for this project (i.e., for representing problem cases and cases in the CKB). Rather, we used pretty much as is the representations developed in two past CBR projects from our lab: CABARET [15] and BankXX <ref> [13] </ref> [12]. Both of these projects use a standard frame-based representation for cases, in which specific facts fill designated slots. <p> collections, and the creation of the relevance files or answer keys. 5.1 Problem Domains We have experimented with our approach in two domains thus far: 1. the home office deduction (HOD) domain, which was the domain used by CABARET [15]; and 2. the good faith bankruptcy domain, used by BankXX <ref> [13] </ref>. CABARET's original case base consisted of 36 real and hypothetical cases concerning the home office deduction, whose requirements are given in Section 280A (c)(1) of the Internal Revenue Code. For this project, we used 25 cases from the CABARET case base.
Reference: [14] <author> Edwina L. Rissland, D. B. Skalak, and M. Timur Friedman. </author> <title> Evaluating a Legal Argument Program. </title> <type> (95-30), </type> <year> 1995. </year>
Reference-contexts: We restricted ourselves to these meaty cases, since so many of the cases in the BankXX case base have very sparse hand-coded answers, which creates evaluation problems, for instance, instabilities in precision-recall statistics <ref> [14] </ref>. 5.2 RF-CKB's Cases for Seeding Relevance Feedback For the home office deduction domain, we have experimented with several problem cases. The Weissman 2 case was the first with which we experimented. (The Weissman case is discussed in [15].) For each problem case, we experimented with different RF-CKB's. <p> We were able to use the second stricter definition of relevance because we already had hand-coded answers for individual problems available from our empirical evaluation of the BankXX system <ref> [14] </ref> in which we compared the sets of items (e.g., cases, legal theories) retrieved by BankXX against those actually mentioned in a case.
Reference: [15] <author> Edwina L. Rissland and David B. Skalak. CABARET: </author> <title> Rule Interpretation in a Hybrid Architecture. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 34 </volume> <pages> 839-887, </pages> <year> 1991. </year>
Reference-contexts: Those systems that have supported large case bases-containing thousands or even tens of thousands of cases-have employed simple case representations (e.g., MBRtalk [17], PACE [4], Anapron [7] ). Our own CBR systems-HYPO [1] [11], CABARET <ref> [15] </ref>, BankXX [12] [13]-perform in-depth reasoning to produce sophisticated precedent-based legal arguments, challenging hypothetical cases, interpretations of ill-defined legal concepts, etc. They use detailed case representations and they have typically had case bases in the range of three to five dozen cases. <p> Background on HYPO-style CBR In the CBR portion of the system, we use a CBR engine of the HYPO-style, with which we have had extensive experience [1], [10], [11], [12], [13], <ref> [15] </ref>. In brief, HYPO-style CBR systems work as follows. First, a problem case is input and analyzed to see what dimensions, sometimes also called factors, are applicable in the problem case. Dimensions address important legal aspects of cases and are used both to index and compare cases. <p> We did not design new case representations for this project (i.e., for representing problem cases and cases in the CKB). Rather, we used pretty much as is the representations developed in two past CBR projects from our lab: CABARET <ref> [15] </ref> and BankXX [13] [12]. Both of these projects use a standard frame-based representation for cases, in which specific facts fill designated slots. <p> on the experiment domains, selection of the RF-CKB's, building of the collections, and the creation of the relevance files or answer keys. 5.1 Problem Domains We have experimented with our approach in two domains thus far: 1. the home office deduction (HOD) domain, which was the domain used by CABARET <ref> [15] </ref>; and 2. the good faith bankruptcy domain, used by BankXX [13]. CABARET's original case base consisted of 36 real and hypothetical cases concerning the home office deduction, whose requirements are given in Section 280A (c)(1) of the Internal Revenue Code. <p> The Weissman 2 case was the first with which we experimented. (The Weissman case is discussed in <ref> [15] </ref>.) For each problem case, we experimented with different RF-CKB's. For Weissman, we examined the queries and resulting precision-recall results (see Figures 4 and 5) derived from six different types of RF-CKB's: 1. RF-CKB1. This RF-CKB consists solely of the set of mopc's.
Reference: [16] <author> Gerard Salton. </author> <title> Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: Rather, text-based systems rely on broadly applicable methods, such as statistical measures, to define relevance <ref> [16] </ref>. Nonetheless, we would still like to be able to access these collections in a more intelligent, problem-based manner. Such massive on-line corpora represent a tremendous resource and investment of capital. <p> Relevance feedback has been found to improve precision by up to 40-60% <ref> [16] </ref>. Using information derived from the user-denoted relevant texts, a relevance feedback algorithm alters the weights of the terms in the original query and/or adds additional query terms. In all cases, the modified query is submitted back to the IR engine.
Reference: [17] <author> Craig Stanfill and David Waltz. </author> <title> Toward Memory-Based Reasoning. </title> <journal> Communications of the ACM, </journal> <volume> 29(12) </volume> <pages> 1213-1228, </pages> <month> De-cember </month> <year> 1986. </year>
Reference-contexts: Among current case-based reasoning systems few have large case bases (say, larger than 1000 cases). Those systems that have supported large case bases-containing thousands or even tens of thousands of cases-have employed simple case representations (e.g., MBRtalk <ref> [17] </ref>, PACE [4], Anapron [7] ). Our own CBR systems-HYPO [1] [11], CABARET [15], BankXX [12] [13]-perform in-depth reasoning to produce sophisticated precedent-based legal arguments, challenging hypothetical cases, interpretations of ill-defined legal concepts, etc.
Reference: [18] <author> Howard Turtle. </author> <title> Natural Language vs. Boolean Query Evaluation: A Comparison of Retrieval Performance. </title> <booktitle> In Proceedings of the 17th Annual International ACM/SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 212-220, </pages> <address> Dublin, Ireland, </address> <month> July </month> <year> 1994. </year> <journal> ACM. </journal> <volume> 245 </volume>
Reference-contexts: The HOD-corpus contains cases addressing a great many legal questions. It was built by adding approximately 200 cases to another already existing, nearly 12,000 document collection, called the West or FSupp collection, [8], <ref> [18] </ref>. The additional texts came from the cases found in the CABARET CKB and those found when the query home office was posed to the on-line WestLaw Rfl Federal Taxation Case Law database.
References-found: 18

