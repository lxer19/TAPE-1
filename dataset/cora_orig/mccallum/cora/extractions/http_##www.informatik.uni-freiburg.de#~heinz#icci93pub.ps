URL: http://www.informatik.uni-freiburg.de/~heinz/icci93pub.ps
Refering-URL: http://www.informatik.uni-freiburg.de/~heinz/
Root-URL: 
Email: heinz@informatik.uni-freiburg.de  
Title: Bootstrap Learning of ff-fi-Evaluation Functions  
Author: Alois P. Heinz Christoph Hense 
Address: Freiburg, 79104 Freiburg, Germany  
Affiliation: Institut fur Informatik, Universitat  
Abstract: We propose ff-fi-evaluation functions that can be used in game-playing programs as a substitute for the traditional static evaluation functions without loss of functionality. The main advantage of an ff-fi-evaluation function is that it can be implemented with a much lower time complexity than the traditional counterpart and so provides a significant speedup for the evaluation of any game position which eventually results in better play. We describe an implementation of the ff-fi-evaluation function using a modification of the classical classification and regression trees and show that a typical call to this function involves the computation of only a small subset of all features that may be used to describe a game position. We show that an iterative bootstrap process can be used to learn ff-fi-evaluation functions efficiently and describe some of the experience we made with this new approach applied to a game called malawi. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. G. Akl. </author> <title> Checkers-playing programs. </title> <editor> In S. C. Shapiro and D. Eckroth, editors, </editor> <booktitle> Encyclopedia of Artificial Intelligence, </booktitle> <pages> pages 88-93, </pages> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: 1 Introduction Game playing programs especially those for two-person games with complete information and with alternating moves like chess and checkers make up a very important part of AI research <ref> [2, 11, 1, 4] </ref>. <p> But in practice the recursion depth of the procedure has to be restricted somehow and the static evaluation function has to be augmented to give heuristic values in the interval <ref> [1; 1] </ref> for interior nodes, where the game tree expansion has to be stopped for timing reasons. The alpha-beta procedure evaluates a given game position by applying a kind of lazy evaluation scheme and so tries to minimize computation time by subtree pruning. <p> It returns immediately with the value of the static evaluation function if the limiting recursion depth has been reached. Initially the alpha-beta procedure is called with the window <ref> [1; 1] </ref>. It should be noticed that the static evaluation function in the traditional form of the alpha-beta procedure is not called with ff and fi parameters and may return values outside of the alpha-beta window. <p> Beyond that we can show that a static evaluator that obeys the alpha-beta window can be implemented more efficiently than a classical evaluator. An ff-fi-evaluation function is called with three arguments, a game position p and the boundaries ff and fi of an interval [ff; fi] <ref> [1; 1] </ref> and it returns a value from the interval [ff; fi]. If the function returns the value v when called with the parameters p, 1 and 1, then it returns v as well, when called with p, ff and fi if v 2 [ff; fi].
Reference: [2] <author> R. Banerji. </author> <title> Game playing. </title> <editor> In S. C. Shapiro and D. Eckroth, editors, </editor> <booktitle> Encyclopedia of Artificial Intelligence, </booktitle> <pages> pages 312-319, </pages> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: 1 Introduction Game playing programs especially those for two-person games with complete information and with alternating moves like chess and checkers make up a very important part of AI research <ref> [2, 11, 1, 4] </ref>.
Reference: [3] <author> L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <address> Belmont, California, </address> <year> 1984. </year>
Reference-contexts: We secondly demonstrate how ff-fi-evaluation functions can be implemented as a modification of the classical classification and regression trees <ref> [3] </ref> which can be built from a set of n training examples in time O (n log 2 n). <p> Therefore a two-phase procedure is applied, that uses a learning set L for growing a tree and a test set Q for subsequent pruning <ref> [3] </ref>. At the beginning of the tree building process the tree consists of only one node, the root, which is a leaf at the same time.
Reference: [4] <author> S. E. Fahlman. </author> <note> Final Report on Information Processing Research | Juli 1987 to July 1990. Technical Report CMU-CS-92-156, </note> <institution> School of Computer Science, Carnegie Mellon University, Pittsburgh, </institution> <year> 1992. </year>
Reference-contexts: 1 Introduction Game playing programs especially those for two-person games with complete information and with alternating moves like chess and checkers make up a very important part of AI research <ref> [2, 11, 1, 4] </ref>.
Reference: [5] <author> R. Gasser. </author> <title> Applying retrograde analysis to nine mens morris. </title> <editor> In D. Levy and D. Beal, editors, </editor> <booktitle> Heuristic Programming in Artificial Intelligence 2, </booktitle> <pages> pages 161-173, </pages> <publisher> Ellis Horwood, </publisher> <year> 1991. </year>
Reference-contexts: In practice, iterative application of the upgrade step eventually yields a good evaluation function that is bootstraped from the trivial one in a kind of heuristic retrograde analysis <ref> [5] </ref>. Each step of the bootstrap procedure may construct a completely new classification tree from the classified feature vectors and throw the old tree away. Another possibility is the reuse of the old tree.
Reference: [6] <author> G. M. Gupton. </author> <title> Genetic learning algorithm applied to the game of othello. </title> <editor> In D. Levy and D. Beal, editors, </editor> <booktitle> Heuristic Programming in Artificial Intelligence, </booktitle> <pages> pages 241-254, </pages> <publisher> Ellis Horwood, </publisher> <year> 1989. </year>
Reference-contexts: The alpha-beta procedure [8, 13] is one of the best known algorithms that prunes off subtrees of the search tree through knowledge that they cannot have any further influence on the solution. There is a large record of investigations in machine learning procedures for evaluation functions, e.g. see <ref> [15, 16, 14, 10, 6] </ref>. Our new approach to evaluation function learning is three-fold: First, we define ff-fi-evaluation functions that allow us to extend the alpha-beta pruning scheme from the alpha-beta procedure to the static evaluation function, providing a more seamless integration of search-based dynamic and knowledge-based static evaluation.
Reference: [7] <author> C. Hense. </author> <title> Lernen von Klassifikationsbaumen fur Spielsituationen. </title> <type> Diploma thesis, </type> <institution> Albert-Ludwigs-Universitat Freiburg, </institution> <month> June </month> <year> 1992. </year>
Reference-contexts: And after that the expanded tree is pruned again with a test set. We have implemented the bootstrap learning procedure on a Sun workstation in C. We applied it in a number of different experiments with varying conditions to the not widely known game named malawi <ref> [7] </ref>. Malawi [9] is played on a 6 fi 6 board. Each player owns six movable tiles that are initially positioned at the own baseline and twelve balls, two of them are initially on each of the own tiles.
Reference: [8] <author> D. Knuth and R. Moore. </author> <title> An analysis of alpha-beta pruning. </title> <journal> Artificial Intelligence, </journal> <volume> 6 </volume> <pages> 293-326, </pages> <year> 1975. </year>
Reference-contexts: Much research in developing general methods for search reduction [12] on the one hand and in finding game-specific evaluation functions on the other hand has been accomplished. The alpha-beta procedure <ref> [8, 13] </ref> is one of the best known algorithms that prunes off subtrees of the search tree through knowledge that they cannot have any further influence on the solution. There is a large record of investigations in machine learning procedures for evaluation functions, e.g. see [15, 16, 14, 10, 6].
Reference: [9] <author> G. Kody. Malawi. Piatnik-Verlag, </author> <type> Wien. </type>
Reference-contexts: And after that the expanded tree is pruned again with a test set. We have implemented the bootstrap learning procedure on a Sun workstation in C. We applied it in a number of different experiments with varying conditions to the not widely known game named malawi [7]. Malawi <ref> [9] </ref> is played on a 6 fi 6 board. Each player owns six movable tiles that are initially positioned at the own baseline and twelve balls, two of them are initially on each of the own tiles.
Reference: [10] <author> K. Lee and S. Mahajan. </author> <title> A pattern classification approach to evaluation function learning. </title> <journal> Artificial Intelligence, </journal> <volume> 36 </volume> <pages> 1-25, </pages> <year> 1988. </year>
Reference-contexts: The alpha-beta procedure [8, 13] is one of the best known algorithms that prunes off subtrees of the search tree through knowledge that they cannot have any further influence on the solution. There is a large record of investigations in machine learning procedures for evaluation functions, e.g. see <ref> [15, 16, 14, 10, 6] </ref>. Our new approach to evaluation function learning is three-fold: First, we define ff-fi-evaluation functions that allow us to extend the alpha-beta pruning scheme from the alpha-beta procedure to the static evaluation function, providing a more seamless integration of search-based dynamic and knowledge-based static evaluation.
Reference: [11] <author> T. Marsland. </author> <title> Computer chess methods. </title> <editor> In S. C. Shapiro and D. Eckroth, editors, </editor> <booktitle> Encyclopedia of Artificial Intelligence, </booktitle> <pages> pages 159-171, </pages> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: 1 Introduction Game playing programs especially those for two-person games with complete information and with alternating moves like chess and checkers make up a very important part of AI research <ref> [2, 11, 1, 4] </ref>.
Reference: [12] <author> J. Pearl. </author> <title> Heuristics: Intelligent Search Strategies for Computer Problem Solving. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1984. </year>
Reference-contexts: Much research in developing general methods for search reduction <ref> [12] </ref> on the one hand and in finding game-specific evaluation functions on the other hand has been accomplished. The alpha-beta procedure [8, 13] is one of the best known algorithms that prunes off subtrees of the search tree through knowledge that they cannot have any further influence on the solution.
Reference: [13] <author> J. Pearl. </author> <title> The solution for the branching factor of the alpha-beta pruning algorithm and its optimality. </title> <journal> Commun. ACM, </journal> <volume> 25(8) </volume> <pages> 559-564, </pages> <month> August </month> <year> 1982. </year>
Reference-contexts: Much research in developing general methods for search reduction [12] on the one hand and in finding game-specific evaluation functions on the other hand has been accomplished. The alpha-beta procedure <ref> [8, 13] </ref> is one of the best known algorithms that prunes off subtrees of the search tree through knowledge that they cannot have any further influence on the solution. There is a large record of investigations in machine learning procedures for evaluation functions, e.g. see [15, 16, 14, 10, 6].
Reference: [14] <author> J. R. Quinlain. </author> <title> Learning efficient classification procedures and their application to chess end games. </title> <editor> In R. S. Michalski, J. G. Carbonell, and T. M. Mitchell, editors, </editor> <booktitle> Machine Learning, An Artificial Intelligence Approach, chapter 15, </booktitle> <pages> pages 463-482, </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1984. </year>
Reference-contexts: The alpha-beta procedure [8, 13] is one of the best known algorithms that prunes off subtrees of the search tree through knowledge that they cannot have any further influence on the solution. There is a large record of investigations in machine learning procedures for evaluation functions, e.g. see <ref> [15, 16, 14, 10, 6] </ref>. Our new approach to evaluation function learning is three-fold: First, we define ff-fi-evaluation functions that allow us to extend the alpha-beta pruning scheme from the alpha-beta procedure to the static evaluation function, providing a more seamless integration of search-based dynamic and knowledge-based static evaluation.
Reference: [15] <author> A. Samuel. </author> <title> Some studies in machine learning using the game of checkers. </title> <editor> In E. Feigenbaum and J. Feld-man, editors, </editor> <booktitle> Computers and Thought, </booktitle> <pages> pages 71-105, </pages> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1963. </year>
Reference-contexts: The alpha-beta procedure [8, 13] is one of the best known algorithms that prunes off subtrees of the search tree through knowledge that they cannot have any further influence on the solution. There is a large record of investigations in machine learning procedures for evaluation functions, e.g. see <ref> [15, 16, 14, 10, 6] </ref>. Our new approach to evaluation function learning is three-fold: First, we define ff-fi-evaluation functions that allow us to extend the alpha-beta pruning scheme from the alpha-beta procedure to the static evaluation function, providing a more seamless integration of search-based dynamic and knowledge-based static evaluation.
Reference: [16] <author> A. Samuel. </author> <title> Some studies in machine learning using the game of checkers. ii | recent progress. </title> <journal> IBM J. Res. Develop., </journal> <volume> 11(6) </volume> <pages> 601-617, </pages> <month> Nov. </month> <year> 1967. </year>
Reference-contexts: The alpha-beta procedure [8, 13] is one of the best known algorithms that prunes off subtrees of the search tree through knowledge that they cannot have any further influence on the solution. There is a large record of investigations in machine learning procedures for evaluation functions, e.g. see <ref> [15, 16, 14, 10, 6] </ref>. Our new approach to evaluation function learning is three-fold: First, we define ff-fi-evaluation functions that allow us to extend the alpha-beta pruning scheme from the alpha-beta procedure to the static evaluation function, providing a more seamless integration of search-based dynamic and knowledge-based static evaluation.
References-found: 16

