URL: http://www.cs.wisc.edu/~solodov/mvs97perturb.ps.Z
Refering-URL: http://www.cs.wisc.edu/~solodov/solodov.html
Root-URL: 
Title: CONVERGENCE ANALYSIS OF PERTURBED FEASIBLE DESCENT METHODS  
Author: M. V. Solodov 
Keyword: Key words. Feasible descent methods, perturbation analysis, approximate solutions.  
Date: 337-353, May 1997  June 15, 1995 (revised February 23, 1996)  
Note: JOURNAL OF OPTIMIZATION THEORY AND APPLICATIONS Vol. 93, No. 2, pp.  c fl1997 Plenum Publishing Corporation  
Abstract: We develop a general approach to convergence analysis of feasible descent methods in the presence of perturbations. The important novel feature of our analysis is that perturbations need not tend to zero in the limit. In that case, standard convergence analysis techniques are not applicable. Therefore a new approach is needed. We show that, in the presence of perturbations, a certain "-approximate solution can be obtained, where " depends on the level of perturbations linearly. Applications to the gradient projection, proximal minimization, extragradient and incremental gradient algorithms are described. fl The author is supported in part by CNPq grant 300734/95-6. This work was started when the author was with the Computer Sciences Department, University of Wisconsin, Madison, Wisconsin, where he was supported by Air Force Office of Scientific Research Grant F49620-94-1-0036 and National Science Foundation Grant CCR-9322479. y Instituto de Matematica Pura e Aplicada, Estrada Dona Castorina 110, Jardim Bot^anico, Rio de Janeiro, RJ 22460-320, Brazil. Email : solodov@impa.br . 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D.P. Bertsekas. </author> <title> A new class of incremental gradient methods for least squares problems. </title> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <address> Cambridge, Massachusetts 02139, U.S.A., </address> <month> May </month> <year> 1995. </year> <month> 16 </month>
Reference-contexts: In particular, it is typically more effective than the standard gradient descent method given by K X rf j (x) = x rf (x): Incremental methods is an area of active research (see <ref> [2, 1, 11, 15, 20, 19, 30, 33] </ref>).
Reference: [2] <author> D.P. Bertsekas. </author> <title> Incremental least squares methods and the extended Kalman filter. </title> <journal> SIAM Journal on Optimization, </journal> <volume> 6 </volume> <pages> 807-822, </pages> <year> 1996. </year>
Reference-contexts: In particular, it is typically more effective than the standard gradient descent method given by K X rf j (x) = x rf (x): Incremental methods is an area of active research (see <ref> [2, 1, 11, 15, 20, 19, 30, 33] </ref>).
Reference: [3] <author> P.T. Boggs and J.E. Dennis. </author> <title> A stability analysis for perturbed nonlinear iterative methods. </title> <journal> Mathematics of Computation, </journal> <volume> 30 </volume> <pages> 199-215, </pages> <year> 1976. </year>
Reference-contexts: This makes traditional convergence analysis techniques [25, 24] inapplicable. In this paper, we develop a new approach to the analysis of feasible descent algorithms with nonvanishing perturbations. Our analysis extends some of the ideas presented in <ref> [3, 20, 19, 36] </ref> for methods of unconstrained optimization and is close in spirit to the study of unconstrained gradient method in [36]. Essential perturbations were considered in [30] in a different context of incremental gradient-type methods with decaying stepsize.
Reference: [4] <author> R.S. Dembo, S.C Eisenstat, and T. Steihaug. </author> <title> Inexact Newton methods. </title> <journal> SIAM Journal of Numerical Analysis, </journal> <volume> 19 </volume> <pages> 400-408, </pages> <year> 1982. </year>
Reference-contexts: Note that either assumption ensures that ffi (x i ; i ) ! 0 as i ! 1. Similar "tolerance" requirements are common in other methods that involve solving subproblems, e.g. <ref> [32, 4] </ref>. In the above mentioned cases, convergence properties of the algorithm stay intact, except possibly for the rate of convergence. We emphasize that the setting considered in this work is fundamentally different. Condition (1.5) no longer guarantees convergence of iterates generated by (1.4) to an exact solution of (1.1).
Reference: [5] <author> E.M. Gafni and D.P. Bertsekas. </author> <title> Two-metric projection methods for constrained optimization. </title> <journal> SIAM Journal on Control and Optimization, </journal> <volume> 22 </volume> <pages> 936-964, </pages> <year> 1984. </year>
Reference: [6] <author> A.A. Goldstein. </author> <title> Convex programming in Hilbert space. </title> <journal> Bull. Am. Math. Soc., </journal> <volume> 70 </volume> <pages> 709-710, </pages> <year> 1964. </year>
Reference-contexts: This is a rather general framework that includes a gradient projection algorithm <ref> [6, 8] </ref>; proximal minimization algorithm [22, 28]; the extragradient algorithm [7, 21]; and the incremental gradient algorithms [31] among others. <p> kx ^xk d 1 *; where is as specified in (1.7) and d 1 is given in Theorem 2.1. 3 Applications In this Section, we briefly discuss applications of our analysis to a number of well known algorithms. 11 3.1 Gradient Projection Algorithm We first consider the gradient projection algorithm <ref> [6, 8] </ref>.
Reference: [7] <author> G.M. Korpelevich. </author> <title> The extragradient method for finding saddle points and other problems. </title> <journal> Matecon, </journal> <volume> 12 </volume> <pages> 747-756, </pages> <year> 1976. </year>
Reference-contexts: This is a rather general framework that includes a gradient projection algorithm [6, 8]; proximal minimization algorithm [22, 28]; the extragradient algorithm <ref> [7, 21] </ref>; and the incremental gradient algorithms [31] among others. <p> It can be checked that d 1 = O (L 2 ); where d 1 is the constant involved in Theorem 2.1. 3.3 Extragradient Method Consider now the extragradient method <ref> [7, 21] </ref> which updates a current iterate according to the double-projection formula x i+1 = [x i i rf [x i i rf (x i )] + ] + : This iteration can be re-written as x i+1 = [x i i rf (x i ) + e (x i ;
Reference: [8] <author> E.S. Levitin and B. T. Polyak. </author> <title> Constrained minimization methods. </title> <journal> USSR Computational Mathematics and Mathematical Physics, </journal> <volume> 6 </volume> <pages> 1-50, </pages> <year> 1965. </year>
Reference-contexts: This is a rather general framework that includes a gradient projection algorithm <ref> [6, 8] </ref>; proximal minimization algorithm [22, 28]; the extragradient algorithm [7, 21]; and the incremental gradient algorithms [31] among others. <p> kx ^xk d 1 *; where is as specified in (1.7) and d 1 is given in Theorem 2.1. 3 Applications In this Section, we briefly discuss applications of our analysis to a number of well known algorithms. 11 3.1 Gradient Projection Algorithm We first consider the gradient projection algorithm <ref> [6, 8] </ref>.
Reference: [9] <author> W. Li. </author> <title> Remarks on matrix splitting algorithms for symmetric linear complementarity problems. </title> <journal> SIAM Journal on Optimization, </journal> <volume> 3 </volume> <pages> 155-163, </pages> <year> 1993. </year>
Reference-contexts: in the analysis of matrix splitting methods : kffi (x i ; i )k ckx i+1 x i k; c &gt; 0; c sufficiently small or i=0 kffi (x i ; i )k &lt; 1: In particular, the first condition has been used in [17, 13] and the second in <ref> [9] </ref>. Note that either assumption ensures that ffi (x i ; i ) ! 0 as i ! 1. Similar "tolerance" requirements are common in other methods that involve solving subproblems, e.g. [32, 4].
Reference: [10] <author> X.-D. Luo and P. Tseng. </author> <title> On global projection-type error bound for the linear complementarity problem. Linear Algebra and Its Applications. </title> <note> To appear. </note>
Reference-contexts: Moreover, under additional assumptions, this condition holds with - = 1 (global error bound) <ref> [12, 23, 10] </ref>. Therefore, if x 2 S (*) and the bound (1.7) holds with - *, it follows immediately that d (x; S) kr (x)k *: The rest of the paper is organized as follows. In Section 2 we develop our general technique for convergence analysis of perturbed algorithms.
Reference: [11] <author> Z.-Q. Luo. </author> <title> On the convergence of the LMS algorithm with adaptive learning rate for linear feedforward networks. </title> <journal> Neural Computation, </journal> <volume> 3 </volume> <pages> 226-245, </pages> <year> 1991. </year>
Reference-contexts: In particular, it is typically more effective than the standard gradient descent method given by K X rf j (x) = x rf (x): Incremental methods is an area of active research (see <ref> [2, 1, 11, 15, 20, 19, 30, 33] </ref>).
Reference: [12] <author> Z.-Q. Luo, O.L. Mangasarian, J. Ren, </author> <title> and M.V. Solodov. New error bounds for the linear complementarity problem. </title> <journal> Mathematics of Operations Research, </journal> <volume> 19 </volume> <pages> 880-892, </pages> <year> 1994. </year>
Reference-contexts: Moreover, under additional assumptions, this condition holds with - = 1 (global error bound) <ref> [12, 23, 10] </ref>. Therefore, if x 2 S (*) and the bound (1.7) holds with - *, it follows immediately that d (x; S) kr (x)k *: The rest of the paper is organized as follows. In Section 2 we develop our general technique for convergence analysis of perturbed algorithms.
Reference: [13] <author> Z.-Q. Luo and P. Tseng. </author> <title> Error bound and convergence analysis of matrix splitting algorithms for the affine variational inequality problem. </title> <journal> SIAM Journal on Optimization, </journal> <volume> 2 </volume> <pages> 43-54, </pages> <year> 1992. </year>
Reference-contexts: of this type have been used in the analysis of matrix splitting methods : kffi (x i ; i )k ckx i+1 x i k; c &gt; 0; c sufficiently small or i=0 kffi (x i ; i )k &lt; 1: In particular, the first condition has been used in <ref> [17, 13] </ref> and the second in [9]. Note that either assumption ensures that ffi (x i ; i ) ! 0 as i ! 1. Similar "tolerance" requirements are common in other methods that involve solving subproblems, e.g. [32, 4].
Reference: [14] <author> Z.-Q. Luo and P. Tseng. </author> <title> Error bounds and convergence analysis of feasible descent methods : A general approach. </title> <journal> Annals of Operations Research, </journal> <volume> 46 </volume> <pages> 157-178, </pages> <year> 1993. </year>
Reference-contexts: Let [] + denote the orthogonal projection onto X. Following <ref> [14] </ref>, we consider a broad class of feasible descent methods that can be represented by the formula x new := [x rf (x) + e (x; )] + ; (1.3) where is a positive scalar, and mapping e : &lt; n+1 ! &lt; n is the defining feature of each particular <p> We note, in the passing, that (in the noise-free case) the characteristic mappings e (; ) of classical feasible descent methods satisfy the condition that e (x i ; i ) ! 0 as i ! 1 by algorithm construction (see <ref> [14] </ref> for details). Only incremental methods are an exception to this rule (see [31] for details). <p> We note that very little is known about convergence properties of essentially perturbed algorithms. The primary contribution of this paper is laying down theoretical framework for analysis of such algorithms. Convergence (and rate of convergence) of feasible descent methods have been studied extensively (see <ref> [14] </ref> and references therein). <p> We note that another important property of the residual function r () is that, under certain conditions, its norm provides a (local) upper bound on the distance to the set S <ref> [14, 26] </ref>. Namely, there exist positive constants and - (depending on f () and X only) such that d (x; S) kr (x)k 8x with kr (x)k -; (1.7) where d (; S) denotes the Euclidean distance to S. <p> Condition (2.1) is standard for feasible descent methods and is a consequence of algorithm construction <ref> [14] </ref>. Bounds (2.3) imposed on the stepsize are also fairly standard. With respect to (2.2), we note the following. If the left-hand-side of (2.2) is nonnegative for all x then we set c 2 := 0, otherwise c 2 := c 1 (it follows that 0 c 2 &lt; 1).
Reference: [15] <author> Z.-Q. Luo and P. Tseng. </author> <title> Analysis of an approximate gradient projection method with applications to the backpropagation algorithm. </title> <journal> Optimization Methods and Software, </journal> <volume> 4 </volume> <pages> 85-101, </pages> <year> 1994. </year>
Reference-contexts: Essential perturbations were considered in [30] in a different context of incremental gradient-type methods with decaying stepsize. A special case of an approximate gradient projection method with decaying stepsize is also studied in <ref> [15] </ref>. We note that in the present paper, the stepsize is bounded away from zero. Therefore, the situation and the analysis required are completely different from [30, 15]. We now define the following residual function r (x) := x [x rf (x)] + which is central for the subsequent analysis. <p> A special case of an approximate gradient projection method with decaying stepsize is also studied in [15]. We note that in the present paper, the stepsize is bounded away from zero. Therefore, the situation and the analysis required are completely different from <ref> [30, 15] </ref>. We now define the following residual function r (x) := x [x rf (x)] + which is central for the subsequent analysis. <p> In particular, it is typically more effective than the standard gradient descent method given by K X rf j (x) = x rf (x): Incremental methods is an area of active research (see <ref> [2, 1, 11, 15, 20, 19, 30, 33] </ref>).
Reference: [16] <author> O.L. Mangasarian. </author> <title> Nonlinear Programming. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1969. </year>
Reference-contexts: We now define the following residual function r (x) := x [x rf (x)] + which is central for the subsequent analysis. It is well known that some x 2 &lt; n satisfies the Minimum Principle optimality condition <ref> [16] </ref> for problem (1.1) if and only if r (x) = 0. We shall call such x a stationary point of (1.1).
Reference: [17] <author> O.L. Mangasarian. </author> <title> Convergence of iterates of an inexact matrix splitting algorithm for the symmetric monotone linear complementarity problem. </title> <journal> SIAM Journal on Optimization, </journal> <volume> 1 </volume> <pages> 114-122, </pages> <year> 1991. </year>
Reference-contexts: of this type have been used in the analysis of matrix splitting methods : kffi (x i ; i )k ckx i+1 x i k; c &gt; 0; c sufficiently small or i=0 kffi (x i ; i )k &lt; 1: In particular, the first condition has been used in <ref> [17, 13] </ref> and the second in [9]. Note that either assumption ensures that ffi (x i ; i ) ! 0 as i ! 1. Similar "tolerance" requirements are common in other methods that involve solving subproblems, e.g. [32, 4].
Reference: [18] <author> O.L. Mangasarian. </author> <title> Mathematical programming in neural networks. </title> <journal> ORSA Journal on Computing, </journal> <volume> 5(4) </volume> <pages> 349-360, </pages> <year> 1993. </year>
Reference-contexts: learning (in particular, neural network) applications, where weights and thresholds of the network comprise the problem variable x 2 &lt; n , K is the number of training samples, and f j () represents the error associated with the j-th sample, j = 1; : : : ; K (see <ref> [18] </ref> for a detailed description).
Reference: [19] <editor> O.L. Mangasarian and M.V. Solodov. </editor> <title> Backpropagation convergence via deterministic nonmonotone perturbed minimization. </title> <editor> In G. Tesauro J.D. Cowan and J. Alspector, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 6, </booktitle> <pages> pages 383-390, </pages> <address> San Francisco, CA, 1994. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: This makes traditional convergence analysis techniques [25, 24] inapplicable. In this paper, we develop a new approach to the analysis of feasible descent algorithms with nonvanishing perturbations. Our analysis extends some of the ideas presented in <ref> [3, 20, 19, 36] </ref> for methods of unconstrained optimization and is close in spirit to the study of unconstrained gradient method in [36]. Essential perturbations were considered in [30] in a different context of incremental gradient-type methods with decaying stepsize. <p> In particular, it is typically more effective than the standard gradient descent method given by K X rf j (x) = x rf (x): Incremental methods is an area of active research (see <ref> [2, 1, 11, 15, 20, 19, 30, 33] </ref>).
Reference: [20] <editor> O.L. Mangasarian and M.V. Solodov. </editor> <title> Serial and parallel backpropagation convergence via nonmonotone perturbed minimization. </title> <journal> Optimization Methods and Software, </journal> <volume> 4 </volume> <pages> 103-116, </pages> <year> 1994. </year>
Reference-contexts: This makes traditional convergence analysis techniques [25, 24] inapplicable. In this paper, we develop a new approach to the analysis of feasible descent algorithms with nonvanishing perturbations. Our analysis extends some of the ideas presented in <ref> [3, 20, 19, 36] </ref> for methods of unconstrained optimization and is close in spirit to the study of unconstrained gradient method in [36]. Essential perturbations were considered in [30] in a different context of incremental gradient-type methods with decaying stepsize. <p> In particular, it is typically more effective than the standard gradient descent method given by K X rf j (x) = x rf (x): Incremental methods is an area of active research (see <ref> [2, 1, 11, 15, 20, 19, 30, 33] </ref>).
Reference: [21] <author> P. Marcotte. </author> <title> Application of Khobotov's algorithm to variational inequalities and network equilibrium problems. </title> <journal> Information Systems and Operational Research, </journal> <volume> 29 </volume> <pages> 258-270, </pages> <year> 1991. </year>
Reference-contexts: This is a rather general framework that includes a gradient projection algorithm [6, 8]; proximal minimization algorithm [22, 28]; the extragradient algorithm <ref> [7, 21] </ref>; and the incremental gradient algorithms [31] among others. <p> It can be checked that d 1 = O (L 2 ); where d 1 is the constant involved in Theorem 2.1. 3.3 Extragradient Method Consider now the extragradient method <ref> [7, 21] </ref> which updates a current iterate according to the double-projection formula x i+1 = [x i i rf [x i i rf (x i )] + ] + : This iteration can be re-written as x i+1 = [x i i rf (x i ) + e (x i ;
Reference: [22] <author> B. Martinet. </author> <title> Regularisation d'inequations variationelles per approximations successive. </title> <journal> Revue Fran~caise d'Informatique et de Recherche Operationelle, </journal> <volume> 4 </volume> <pages> 154-159, </pages> <year> 1970. </year>
Reference-contexts: This is a rather general framework that includes a gradient projection algorithm [6, 8]; proximal minimization algorithm <ref> [22, 28] </ref>; the extragradient algorithm [7, 21]; and the incremental gradient algorithms [31] among others. <p> Provided the stepsize satisfies the standard conditions 0 &lt; c 3 i L it can be verified that d 1 = O (L 2 ); where d 1 is the constant involved in Theorem 2.1. 3.2 Proximal Minimization Algorithm Given a current iterate x i , the proximal minimization algorithm <ref> [22, 28] </ref> generates the next iterate x i+1 according to x i+1 = arg min i (x) := f (x) + 2 i This method also falls within the presented framework as can be seen from the following.
Reference: [23] <author> J.-S. Pang. </author> <title> A posteriori error bounds for the linearly-constrained variational inequality problem. </title> <journal> Mathematics of Operations Research, </journal> <volume> 12 </volume> <pages> 474-484, </pages> <year> 1987. </year>
Reference-contexts: Moreover, under additional assumptions, this condition holds with - = 1 (global error bound) <ref> [12, 23, 10] </ref>. Therefore, if x 2 S (*) and the bound (1.7) holds with - *, it follows immediately that d (x; S) kr (x)k *: The rest of the paper is organized as follows. In Section 2 we develop our general technique for convergence analysis of perturbed algorithms.
Reference: [24] <author> E. Polak. </author> <title> Computational methods in optimization: A unified approach. </title> <publisher> Academic Press, </publisher> <address> New York, New York, </address> <year> 1971. </year> <month> 18 </month>
Reference-contexts: Moreover, standard relations such as f (x i ) f (x i+1 ) 0; kx i+1 x i k ! 0 as i ! 1 need not hold (see Section 2). This makes traditional convergence analysis techniques <ref> [25, 24] </ref> inapplicable. In this paper, we develop a new approach to the analysis of feasible descent algorithms with nonvanishing perturbations. <p> Our argument is based on monitoring the behaviour of f () on the iterates of the algorithm. We emphasize that this behaviour is nonmonotone, and Lyapunov-type convergence analysis <ref> [24, 35] </ref> cannot be applied. We first state three well known results that will be used later.
Reference: [25] <author> B.T. Polyak. </author> <title> Introduction to Optimization. Optimization Software, </title> <publisher> Inc., Publications Division, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: Moreover, standard relations such as f (x i ) f (x i+1 ) 0; kx i+1 x i k ! 0 as i ! 1 need not hold (see Section 2). This makes traditional convergence analysis techniques <ref> [25, 24] </ref> inapplicable. In this paper, we develop a new approach to the analysis of feasible descent algorithms with nonvanishing perturbations.
Reference: [26] <author> S.M. Robinson. </author> <title> Some continuity properties of polyhedral multifunctions. </title> <journal> Mathematical Programming Study, </journal> <volume> 14 </volume> <pages> 206-214, </pages> <year> 1981. </year>
Reference-contexts: We note that another important property of the residual function r () is that, under certain conditions, its norm provides a (local) upper bound on the distance to the set S <ref> [14, 26] </ref>. Namely, there exist positive constants and - (depending on f () and X only) such that d (x; S) kr (x)k 8x with kr (x)k -; (1.7) where d (; S) denotes the Euclidean distance to S.
Reference: [27] <author> R.T. Rockafellar. </author> <title> Convex Analysis. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1970. </year>
Reference: [28] <author> R.T. Rockafellar. </author> <title> Monotone operators and the proximal point algorithm. </title> <journal> SIAM Journal on Control and Optimization, </journal> <volume> 14(5) </volume> <pages> 877-898, </pages> <year> 1976. </year>
Reference-contexts: This is a rather general framework that includes a gradient projection algorithm [6, 8]; proximal minimization algorithm <ref> [22, 28] </ref>; the extragradient algorithm [7, 21]; and the incremental gradient algorithms [31] among others. <p> Provided the stepsize satisfies the standard conditions 0 &lt; c 3 i L it can be verified that d 1 = O (L 2 ); where d 1 is the constant involved in Theorem 2.1. 3.2 Proximal Minimization Algorithm Given a current iterate x i , the proximal minimization algorithm <ref> [22, 28] </ref> generates the next iterate x i+1 according to x i+1 = arg min i (x) := f (x) + 2 i This method also falls within the presented framework as can be seen from the following.
Reference: [29] <author> M. V. Solodov and P. Tseng. </author> <title> Modified projection-type methods for monotone variational inequalities. </title> <journal> SIAM Journal on Control and Optimization, </journal> <volume> 34 </volume> <pages> 1814-1830, </pages> <year> 1996. </year>
Reference-contexts: It is shown that the perturbed gradient projection, proximal minimization, extragradient and incremental gradient methods fall within the presented framework. Applications of the ideas presented here to other classes of optimization algorithms (for example, projection methods which are not descent methods, e.g. <ref> [29, 34] </ref>) is an interesting subject of future research.
Reference: [30] <author> M. V. Solodov and S. K. Zavriev. </author> <title> Error-stabilty properties of generalized gradient-type algorithms. </title> <type> Mathematical Programming Technical Report 94-05, </type> <institution> Computer Science Department, University of Wisconsin, </institution> <address> 1210 West Dayton Street, Madison, Wisconsin 53706, U.S.A., </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Our analysis extends some of the ideas presented in [3, 20, 19, 36] for methods of unconstrained optimization and is close in spirit to the study of unconstrained gradient method in [36]. Essential perturbations were considered in <ref> [30] </ref> in a different context of incremental gradient-type methods with decaying stepsize. A special case of an approximate gradient projection method with decaying stepsize is also studied in [15]. We note that in the present paper, the stepsize is bounded away from zero. <p> A special case of an approximate gradient projection method with decaying stepsize is also studied in [15]. We note that in the present paper, the stepsize is bounded away from zero. Therefore, the situation and the analysis required are completely different from <ref> [30, 15] </ref>. We now define the following residual function r (x) := x [x rf (x)] + which is central for the subsequent analysis. <p> To study the convergence properties of Algorithm 2.1, we need to estimate the level of perturbations in the limit. We say that "(x) is the exact asymptotic level of perturbations <ref> [30] </ref> at a point x 2 X, if "(x) = lim sup k!1 kffi (y k ; k )k: It is easy to see that "() : &lt; n ! &lt; + is upper semicontinuous. For the clarity of presentation, we briefly outline our argument. <p> In particular, it is typically more effective than the standard gradient descent method given by K X rf j (x) = x rf (x): Incremental methods is an area of active research (see <ref> [2, 1, 11, 15, 20, 19, 30, 33] </ref>).
Reference: [31] <author> M.V. Solodov. </author> <title> Incremental gradient algorithms with stepsizes bounded away from zero. </title> <type> Technical Report B-096, </type> <institution> Instituto de Matematica Pura e Aplicada, Estrada Dona Cas-torina 110, Jardim Bot^anico, Rio de Janeiro, </institution> <address> RJ 22460, Brazil, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: This is a rather general framework that includes a gradient projection algorithm [6, 8]; proximal minimization algorithm [22, 28]; the extragradient algorithm [7, 21]; and the incremental gradient algorithms <ref> [31] </ref> among others. We note, in the passing, that (in the noise-free case) the characteristic mappings e (; ) of classical feasible descent methods satisfy the condition that e (x i ; i ) ! 0 as i ! 1 by algorithm construction (see [14] for details). <p> Only incremental methods are an exception to this rule (see <ref> [31] </ref> for details). <p> We refer the reader to <ref> [31] </ref> for a detailed analysis. 4 Concluding Remarks A unified approach to the analysis of perturbed feasible descent methods has been presented. It was established that a certain "-approximate solution can be obtained where " depends on the level of perturbations linearly.
Reference: [32] <author> M.V. Solodov. </author> <title> New inexact parallel variable distribution algorithms. </title> <journal> Computational Optimization and Applications, </journal> <volume> 7(2), </volume> <month> March </month> <year> 1997. </year>
Reference-contexts: Note that either assumption ensures that ffi (x i ; i ) ! 0 as i ! 1. Similar "tolerance" requirements are common in other methods that involve solving subproblems, e.g. <ref> [32, 4] </ref>. In the above mentioned cases, convergence properties of the algorithm stay intact, except possibly for the rate of convergence. We emphasize that the setting considered in this work is fundamentally different. Condition (1.5) no longer guarantees convergence of iterates generated by (1.4) to an exact solution of (1.1).
Reference: [33] <author> P. Tseng. </author> <title> Incremental gradient(-projection) method with momentum term and adaptive stepsize rule. </title> <institution> Department of Mathematics, University of Washington, </institution> <address> Seattle, Wash-ington 98195, U.S.A., </address> <month> October </month> <year> 1995. </year> <note> SIAM Journal on Optimization, submitted. </note>
Reference-contexts: In particular, it is typically more effective than the standard gradient descent method given by K X rf j (x) = x rf (x): Incremental methods is an area of active research (see <ref> [2, 1, 11, 15, 20, 19, 30, 33] </ref>).
Reference: [34] <author> P. Tseng. </author> <title> On linear convergence of iterative methods for the variational inequality problem. </title> <journal> Journal of Computational and Applied Mathematics, </journal> <volume> 60 </volume> <pages> 237-252, </pages> <year> 1995. </year>
Reference-contexts: It is shown that the perturbed gradient projection, proximal minimization, extragradient and incremental gradient methods fall within the presented framework. Applications of the ideas presented here to other classes of optimization algorithms (for example, projection methods which are not descent methods, e.g. <ref> [29, 34] </ref>) is an interesting subject of future research.
Reference: [35] <author> W.I. Zangwill. </author> <title> Nonlinear Programming: A Unified Approach. </title> <publisher> Prentice-Hall, Inc, </publisher> <address> En-glewood Cliffs, New Jersey, </address> <year> 1969. </year> <month> 19 </month>
Reference-contexts: Our argument is based on monitoring the behaviour of f () on the iterates of the algorithm. We emphasize that this behaviour is nonmonotone, and Lyapunov-type convergence analysis <ref> [24, 35] </ref> cannot be applied. We first state three well known results that will be used later.
Reference: [36] <author> S. K. Zavriev. </author> <title> Convergence properties of the gradient method under variable level interference. </title> <journal> USSR Computational Mathematics and Mathematical Physics, </journal> <volume> 30 </volume> <pages> 997-1007, </pages> <year> 1990. </year>
Reference-contexts: This makes traditional convergence analysis techniques [25, 24] inapplicable. In this paper, we develop a new approach to the analysis of feasible descent algorithms with nonvanishing perturbations. Our analysis extends some of the ideas presented in <ref> [3, 20, 19, 36] </ref> for methods of unconstrained optimization and is close in spirit to the study of unconstrained gradient method in [36]. Essential perturbations were considered in [30] in a different context of incremental gradient-type methods with decaying stepsize. <p> In this paper, we develop a new approach to the analysis of feasible descent algorithms with nonvanishing perturbations. Our analysis extends some of the ideas presented in [3, 20, 19, 36] for methods of unconstrained optimization and is close in spirit to the study of unconstrained gradient method in <ref> [36] </ref>. Essential perturbations were considered in [30] in a different context of incremental gradient-type methods with decaying stepsize. A special case of an approximate gradient projection method with decaying stepsize is also studied in [15]. We note that in the present paper, the stepsize is bounded away from zero.
References-found: 36

