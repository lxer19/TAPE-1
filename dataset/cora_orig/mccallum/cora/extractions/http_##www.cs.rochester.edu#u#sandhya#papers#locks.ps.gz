URL: http://www.cs.rochester.edu/u/sandhya/papers/locks.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/sandhya/papers/
Root-URL: 
Title: Replacing Locks by Higher-Level Primitives  
Author: Sarita V. Adve, Alan L. Cox, Sandhya Dwarkadas, and Willy Zwaenepoel 
Note: This work is supported in part by NSF Grants No. CCR-91163343, CCR-9211004, CDA-9222911, and CDA-9310073, and by Texas ATP Grant No. 0036404013.  
Address: Houston, TX 77251-1892  
Affiliation: Department of Electrical and Computer Engineering Department of Computer Science Rice University  
Abstract: Locks are used in shared memory parallel programs to achieve a variety of synchronization objectives. They may provide mutual exclusion for a critical section, or they may provide synchronized access to a task queue. In the former case, no ordering is implied between data operations outside of the critical sections, while in the latter case the operations preceding the enqueue of a task are ordered before the operations following a dequeue of that task. In this paper we argue that many uses of locks can be replaced by higher-level primitives that directly express the intended behavior, such as, for example, enqueue and dequeue operations on a task queue. This approach not only simplifies the programming model, but also allows a more efficient implementation. By making the intended use explicit, we can tailor the implementation of each primitive accordingly, thereby achieving reductions in latency and communication overhead. Synchronization latency has been shown to be one of the major impediments for achieving high performance, especially on software distributed shared memory systems. We demonstrate the benefits of our approach by comparing the performance on the TreadMarks distributed shared memory system of lock-based implementations of four applications (TSP, Quicksort, Water, and ILINK) to new implementations using the higher-level primitives. For each of the four applications, the high-level primitives lead to simpler programs with better performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Adve and M. Hill. </author> <title> Weak ordering: A new definition. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 2-14, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: The improvement is due to the elimination of the local to global copy in addition to the removal of the lock operations required to perform these copies. 15 7 Related Work There has been a lot of previous work on using programmer-provided information to lead to memory system optimizations (e.g., <ref> [1, 3, 4, 6, 8, 11, 16] </ref>). This paper builds on previous work to get more information from the programmer. We replace the use of locks with high-level aggregate operations that make the intended use of the lock more explicit. <p> This paper builds on previous work to get more information from the programmer. We replace the use of locks with high-level aggregate operations that make the intended use of the lock more explicit. In contrast, the work in <ref> [1, 6, 8, 11, 16] </ref> is at a lower-level, focusing on distinguishing individual memory operations based on their behavior in the execution. Two previous studies that look at higher-level semantics are the following.
Reference: [2] <author> S. V. Adve and M. D. Hill. </author> <title> A unified formalization of four shared-memory models. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(6) </volume> <pages> 613-624, </pages> <month> June </month> <year> 1993. </year> <month> 16 </month>
Reference-contexts: At this time, the acquiring processor determines which modifications it needs to see to preserve the semantics of RC for the programs described above. To do so, LRC uses the happens-before-1 partial order <ref> [2] </ref>.
Reference: [3] <author> S.V. Adve. </author> <title> Designing Memory Consistency Models for Shared-Memory Multiprocessors. </title> <type> PhD thesis, </type> <institution> University of Wisconsin, Madison, </institution> <month> December </month> <year> 1993. </year>
Reference-contexts: Executions of programs that obey the above constraint will appear sequentially consistent, and the atomic operators will appear to be atomic with respect to each other. 2 2 The proof that this restriction ensures sequential consistency can be done along the same lines as in <ref> [3] </ref>. 9 4 Experimental Environment Our experimental environment consists of 8 DECstation-5000/240's running Ultrix V4.3. Each machine has a Fore ATM interface that is connected to a Fore ATM switch. The connection between the interface boards and the switch operates at 100-Mbps; the switch has an aggregate throughput of 1.2-Gbps. <p> The improvement is due to the elimination of the local to global copy in addition to the removal of the lock operations required to perform these copies. 15 7 Related Work There has been a lot of previous work on using programmer-provided information to lead to memory system optimizations (e.g., <ref> [1, 3, 4, 6, 8, 11, 16] </ref>). This paper builds on previous work to get more information from the programmer. We replace the use of locks with high-level aggregate operations that make the intended use of the lock more explicit. <p> Thus, Midway might sometimes require more synchronization than necessary (as in the task queue example where locks are intended to actually order operations not in the critical section). We do not require any more synchronization than would be needed in a sequentially consistent system. Adve <ref> [3] </ref> discusses how system performance can be improved by making explicit many well-defined high-level programming constructs that have not been fully exploited by previous memory models. Some of those constructs are lock-based.
Reference: [4] <author> B.N. Bershad and M.J. Zekauskas. Midway: </author> <title> Shared memory parallel programming with entry consistency for distributed memory multiprocessors. </title> <type> Technical Report CMU-CS-91-170, </type> <institution> Carnegie-Mellon University, </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: The improvement is due to the elimination of the local to global copy in addition to the removal of the lock operations required to perform these copies. 15 7 Related Work There has been a lot of previous work on using programmer-provided information to lead to memory system optimizations (e.g., <ref> [1, 3, 4, 6, 8, 11, 16] </ref>). This paper builds on previous work to get more information from the programmer. We replace the use of locks with high-level aggregate operations that make the intended use of the lock more explicit. <p> In contrast, the work in [1, 6, 8, 11, 16] is at a lower-level, focusing on distinguishing individual memory operations based on their behavior in the execution. Two previous studies that look at higher-level semantics are the following. The Midway system [5] and the entry consistency model <ref> [4] </ref> associate locks with data, thereby reducing the information that needs to be transferred on synchronization. Our synchronizing atomic operators can be interpreted as a similar construct.
Reference: [5] <author> B.N. Bershad, M.J. Zekauskas, </author> <title> and W.A. </title> <booktitle> Sawdon. The Midway distributed shared memory system. In Proceedings of the '93 CompCon Conference, </booktitle> <pages> pages 528-537, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: In contrast, the work in [1, 6, 8, 11, 16] is at a lower-level, focusing on distinguishing individual memory operations based on their behavior in the execution. Two previous studies that look at higher-level semantics are the following. The Midway system <ref> [5] </ref> and the entry consistency model [4] associate locks with data, thereby reducing the information that needs to be transferred on synchronization. Our synchronizing atomic operators can be interpreted as a similar construct.
Reference: [6] <author> J.B. Carter, J.K. Bennett, and W. Zwaenepoel. </author> <title> Implementation and performance of Munin. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 152-164, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: The improvement is due to the elimination of the local to global copy in addition to the removal of the lock operations required to perform these copies. 15 7 Related Work There has been a lot of previous work on using programmer-provided information to lead to memory system optimizations (e.g., <ref> [1, 3, 4, 6, 8, 11, 16] </ref>). This paper builds on previous work to get more information from the programmer. We replace the use of locks with high-level aggregate operations that make the intended use of the lock more explicit. <p> This paper builds on previous work to get more information from the programmer. We replace the use of locks with high-level aggregate operations that make the intended use of the lock more explicit. In contrast, the work in <ref> [1, 6, 8, 11, 16] </ref> is at a lower-level, focusing on distinguishing individual memory operations based on their behavior in the execution. Two previous studies that look at higher-level semantics are the following.
Reference: [7] <author> R. W. Cottingham Jr., R. M. Idury, and A. A. Schaffer. </author> <title> Faster sequential genetic linkage computations. </title> <journal> American Journal of Human Genetics, </journal> <volume> 53 </volume> <pages> 252-263, </pages> <year> 1993. </year>
Reference-contexts: We started with a version from the FASTLINK package <ref> [7] </ref>, in which the sequential algorithms have been sped up by roughly one order of magnitude. Genetic linkage analysis is a statistical technique that uses family pedigree information to map human genes and locate disease genes in the human genome.
Reference: [8] <author> M. Dubois and C. Scheurich. </author> <title> Memory access dependencies in shared-memory multiprocessors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 16(6) </volume> <pages> 660-673, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: The improvement is due to the elimination of the local to global copy in addition to the removal of the lock operations required to perform these copies. 15 7 Related Work There has been a lot of previous work on using programmer-provided information to lead to memory system optimizations (e.g., <ref> [1, 3, 4, 6, 8, 11, 16] </ref>). This paper builds on previous work to get more information from the programmer. We replace the use of locks with high-level aggregate operations that make the intended use of the lock more explicit. <p> This paper builds on previous work to get more information from the programmer. We replace the use of locks with high-level aggregate operations that make the intended use of the lock more explicit. In contrast, the work in <ref> [1, 6, 8, 11, 16] </ref> is at a lower-level, focusing on distinguishing individual memory operations based on their behavior in the execution. Two previous studies that look at higher-level semantics are the following.
Reference: [9] <author> S. Dwarkadas, P. Keleher, A.L. Cox, and W. Zwaenepoel. </author> <title> Evaluation of release consistent software distributed shared memory on emerging network technology. </title> <booktitle> In Proceedings of the 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 244-255, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: A write notice is an indication that a page has been modified in a particular interval, but it does not contain the actual modifications. The timing of the actual data movement depends on whether an invalidate, an update, or a hybrid protocol is used (see <ref> [9] </ref>). Our current implementation uses an invalidate protocol: the arrival of a write notice for a page causes the processor to invalidate its copy of that page. A subsequent access to that page causes an access miss, at which time the modifications are obtained for the local copy.
Reference: [10] <author> S. Dwarkadas, A.A. Schaffer, R.W. Cottingham Jr., A.L. Cox, P. Keleher, and W. Zwaenepoel. </author> <title> Parallelization of general linkage analysis problems. </title> <booktitle> Human Heredity, </booktitle> <volume> 44 </volume> <pages> 127-141, </pages> <year> 1994. </year>
Reference-contexts: fault, to obtain a 4096 byte page from another processor takes 2792 seconds. 5 Applications In this section, we describe the applications used in our study and motivate the efficiency and ease of use of the proposed synchronization primitives. 5.1 ILINK Our first application is a parallel version of ILINK <ref> [10] </ref>, which is part of the standard LINKAGE package [15] for genetic linkage analysis that is widely used by geneticists (and therefore a "real" application). We started with a version from the FASTLINK package [7], in which the sequential algorithms have been sped up by roughly one order of magnitude.
Reference: [11] <author> K. Gharachorloo, D. Lenoski, J. Laudon, P. Gibbons, A. Gupta, and J. Hennessy. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: This section provides the necessary background to understand the performance advantages of the proposed approach in such a system. To that end, we focus on the implementation of general-purpose locks in a software DSM. 2.1 Release Consistency Release consistency (RC) <ref> [11] </ref> is a relaxed memory consistency model that permits a processor to delay making its changes to shared data visible to other processors until certain synchronization accesses occur. <p> Programs written for conventional sequentially consistent (SC) memory [14] produce the same results on an RC memory, provided that (i) all synchronization operations use system-supplied primitives, and (ii) there is a release-acquire pair between conflicting ordinary accesses to the same memory location on different processors <ref> [11] </ref>. In practice, most shared memory programs require little or no modifications to meet these requirements. RC can, however, be implemented more efficiently than SC. <p> The improvement is due to the elimination of the local to global copy in addition to the removal of the lock operations required to perform these copies. 15 7 Related Work There has been a lot of previous work on using programmer-provided information to lead to memory system optimizations (e.g., <ref> [1, 3, 4, 6, 8, 11, 16] </ref>). This paper builds on previous work to get more information from the programmer. We replace the use of locks with high-level aggregate operations that make the intended use of the lock more explicit. <p> This paper builds on previous work to get more information from the programmer. We replace the use of locks with high-level aggregate operations that make the intended use of the lock more explicit. In contrast, the work in <ref> [1, 6, 8, 11, 16] </ref> is at a lower-level, focusing on distinguishing individual memory operations based on their behavior in the execution. Two previous studies that look at higher-level semantics are the following.
Reference: [12] <author> J. T. Hecht, Y. Wang, B. Connor, S. H. Blanton, and S. P. Daiger. Non-syndromic cleft lip and palate: </author> <title> No evidence of linkage to hla or factor 13a. </title> <journal> American Journal of Human Genetics, </journal> <volume> 52 </volume> <pages> 1230-1233, </pages> <year> 1993. </year>
Reference-contexts: Table 1 details the number of messages and the amount of data movement per second on TreadMarks for each of the applications on up to 7 processors. 3 Sections 6.1.1 to 6.1.4 discuss the results for each application in detail. 6.1.1 ILINK input data set <ref> [12] </ref>. As can be seen, the use of ns atomic adds greatly improves performance. This is mainly because of the reduction in the number of off-node messages, as borne out by the message counts at 7 processors.
Reference: [13] <author> P. Keleher, A. L. Cox, and W. Zwaenepoel. </author> <title> Lazy release consistency for software distributed shared memory. </title> <booktitle> In Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 13-21, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: No such requirement exists under RC. The propagation of the modifications can be postponed until the next synchronization operation takes effect. 2 2.2 Lazy Release Consistency In lazy release consistency (LRC) <ref> [13] </ref>, the propagation of modifications is postponed until the time of the acquire. At this time, the acquiring processor determines which modifications it needs to see to preserve the semantics of RC for the programs described above. To do so, LRC uses the happens-before-1 partial order [2].
Reference: [14] <author> L. Lamport. </author> <title> How to make a multiprocessor computer that correctly executes multiprocess programs. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-28(9):690-691, </volume> <month> September </month> <year> 1979. </year>
Reference-contexts: Essentially, RC requires ordinary shared memory updates by a processor p to become visible at another processor q, only when a subsequent release by p becomes visible at q. Programs written for conventional sequentially consistent (SC) memory <ref> [14] </ref> produce the same results on an RC memory, provided that (i) all synchronization operations use system-supplied primitives, and (ii) there is a release-acquire pair between conflicting ordinary accesses to the same memory location on different processors [11].
Reference: [15] <author> G. M. Lathrop, J. M. Lalouel, C. Julier, and J. Ott. </author> <title> Strategies for multilocus linkage analysis in humans. </title> <booktitle> Proc. </booktitle> <institution> Natl. Acad. Sci. USA, </institution> <month> 81 </month> <pages> 3443-3446, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: processor takes 2792 seconds. 5 Applications In this section, we describe the applications used in our study and motivate the efficiency and ease of use of the proposed synchronization primitives. 5.1 ILINK Our first application is a parallel version of ILINK [10], which is part of the standard LINKAGE package <ref> [15] </ref> for genetic linkage analysis that is widely used by geneticists (and therefore a "real" application). We started with a version from the FASTLINK package [7], in which the sequential algorithms have been sped up by roughly one order of magnitude. <p> The sequential algorithm is summarized in Figure 4. The program involves a nested loop that, for a given value of the recombination vector, iterates over each pedigree and each nuclear family (consisting of parents and child) within each pedigree to update the probabilities of each genotype <ref> [15] </ref> for each individual. The probabilities are stored in an array genarray. The update involves an addition of a value, which is computed in the inner loop.
Reference: [16] <author> David Probst. </author> <title> Programming, compiling and executing partially-ordered instruction streams on scalable shared-memory multiprocessors. </title> <booktitle> In Hawaii International Conference on System Sciences, </booktitle> <pages> pages 504-513, </pages> <year> 1994. </year>
Reference-contexts: The improvement is due to the elimination of the local to global copy in addition to the removal of the lock operations required to perform these copies. 15 7 Related Work There has been a lot of previous work on using programmer-provided information to lead to memory system optimizations (e.g., <ref> [1, 3, 4, 6, 8, 11, 16] </ref>). This paper builds on previous work to get more information from the programmer. We replace the use of locks with high-level aggregate operations that make the intended use of the lock more explicit. <p> This paper builds on previous work to get more information from the programmer. We replace the use of locks with high-level aggregate operations that make the intended use of the lock more explicit. In contrast, the work in <ref> [1, 6, 8, 11, 16] </ref> is at a lower-level, focusing on distinguishing individual memory operations based on their behavior in the execution. Two previous studies that look at higher-level semantics are the following.
Reference: [17] <author> J.P. Singh, W.-D. Weber, and A. Gupta. </author> <title> SPLASH: Stanford parallel applications for shared-memory. </title> <type> Technical Report CSL-TR-91-469, </type> <institution> Stanford University, </institution> <month> April </month> <year> 1991. </year> <month> 17 </month>
Reference-contexts: This eliminates any consistency information transfer at that critical section. The two versions of TSP are referred to as TSP-Lock and TSP-Min. 5.4 Water Water is a molecular dynamics simulation from the SPLASH suite <ref> [17] </ref>. The program evaluates forces and potentials in a system of water molecules for a user-specified number of time steps. Each time step consists of several phases, where consecutive phases are separated by a barrier.
References-found: 17

