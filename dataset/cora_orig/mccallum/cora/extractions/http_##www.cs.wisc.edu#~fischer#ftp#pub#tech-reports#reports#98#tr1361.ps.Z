URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/reports/98/tr1361.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/reports/98/
Root-URL: http://www.cs.wisc.edu
Email: flfan,cao,jussarag@cs.wisc.edu broder@pa.dec.com  
Title: Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol  
Author: Li Fan, Pei Cao and Jussara Almeida Andrei Z. Broder 
Affiliation: Department of Computer Science Systems Research Center University of Wisconsin-Madison Digital Equipment Corporation  
Abstract: The sharing of caches among Web proxies is an important technique to reduce Web traffic and alleviate network bottlenecks. Nevertheless it is not widely deployed due to the overhead of existing protocols. In this paper we demonstrate the benefits of cache sharing, measure the overhead of the existing protocols, and propose a new protocol called "Summary Cache". In this new protocol, each proxy keeps a summary of the cache directory of each participating proxy, and checks these summaries for potential hits before sending any queries. Two factors contribute to our protocol's low overhead: the summaries are updated only periodically, and the directory representations are very economical, as low as 8 bits per entry. Using trace-driven simulations and a prototype implementation, we show that, compared to existing protocols such as the Internet Cache Protocol (ICP), Summary Cache reduces the number of inter-cache protocol messages by a factor of 25 to 60, reduces the bandwidth consumption by over 50%, eliminates 75% and 95% of the protocol CPU overhead, all while maintaining almost the same cache hit ratio as ICP. Hence Summary Cache scales to a large number of proxies. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Jussara Almeida and Pei Cao. </author> <title> Wisconsin proxy benchmark 1.0. </title> <address> http://www.cs.wisc.edu/ cao/wpb1.0.html, </address> <year> 1997. </year>
Reference-contexts: As the number of collaborating proxies increases, the overhead quickly becomes prohibitive. To measure the overhead of ICP and its impact on proxy performance, we run experiments using a proxy benchmark designed by us <ref> [1] </ref>. (The benchmark has been submitted to SPEC as a candidate for the industry standard benchmark and is currently in-use at a number of proxy system vendors.) The benchmark consists of a collection of client processes that issue requests following patterns observed in real traces, including request size distribution and temporal
Reference: [2] <author> Thomas E. Anderson, Michael D. Dahlin, Jeanna M. Neefe, David A. Patterson, Drew S. Roselli, and Ran-dolph Y. Wang. </author> <title> Serverless network file systems. </title> <booktitle> In Page 18 Proceedings of 15th ACM Symposium on Operating Systems Principles, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: Our inspection of the Questnet traces shows that the child-to-parent ICP queries can be a significant portion (over 2=3) of the messages that the parent has to process. In the operating system context, there have been a lot of studies on cooperative file caching <ref> [11, 2] </ref> and the global memory system (GMS) [17]. The underlying assumption in these systems is that the high-speed local area networks are faster than disks, and workstations should use each other's idle memory to cache file pages or virtual memory pages to avoid traffic to disks.
Reference: [3] <author> M. Arlitt and C. Williamson. </author> <title> Web server workload characterization. </title> <booktitle> In Proceedings of the 1996 ACM SIGMETRICS International Conference on Measurement and Modelling of Computer Systems, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Our results indicate that the summary-cache enhanced ICP solves the overhead problem of ICP, requires minimal changes, and enables scalable Web cache sharing over a wide-area network. 8 Related Work Web caching is an active research area. There are many studies on Web client access characteristics <ref> [10, 3, 14, 33, 23] </ref>, web caching algorithms [49, 35, 8] as well as Web cache consistency [28, 31, 34, 13]. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing.
Reference: [4] <author> Aline Baggio and Guillaume Pierre. Oleron: </author> <title> Supporting information sharing in large-scale mobile environments. </title> <booktitle> In Proceedings of the ERSADS Workshop, </booktitle> <month> March </month> <year> 1997. </year> <note> Available from http://www-sor.inria.fr/projects/relais/. </note>
Reference-contexts: The idea is similar to summary cache. However, the project does not seem to address the issue of memory demands. From the publications on Relais that we can find and read <ref> [4] </ref>, it is also not clear to us whether the project addresses the issue of directory update frequencies.
Reference: [5] <author> Kirby Beck. </author> <title> Tennessee cache box project. In the 2nd Web Caching Workshop, </title> <address> Boulder, Colorado, </address> <month> June </month> <year> 1997. </year> <note> http://ircache.nlanr.net/Cache/Workshop97/. </note>
Reference-contexts: The Harvest group designed the Internet Cache Protocol (ICP) [18] that supports discovery and retrieval of documents from neighboring caches. Today, many institutions and many countries have established hierarchies of proxy caches that cooperate via ICP to reduce traffic to the Internet <ref> [25, 30, 41, 5, 14] </ref>. Nevertheless, the wide deployment of web cache sharing is currently hindered by the overhead of the ICP protocol. ICP discovers cache hits in other proxies by having the proxy multicast a query message to all other proxies whenever a cache miss occurs.
Reference: [6] <author> Burton Bloom. </author> <title> Space/time trade-offs in hash coding with allowable errors. </title> <journal> Communications of ACM, </journal> <pages> pages 13(7) 422-426, </pages> <month> July </month> <year> 1970. </year>
Reference-contexts: To reduce the memory requirements, we store each summary as a "Bloom filter" <ref> [6] </ref>. This is a computa-tionally very efficient hash-based probabilistic scheme that can represent a set of keys (in our case, a cache directory) with minimal memory requirements while answering membership queries with 0 probability for false negatives and low probability for false positives. <p> It was invented by Burton Bloom in 1970 <ref> [6] </ref> and was proposed for use in the web context by Marais and Bharat [37] as a mechani sm for identifying which pages have associated comments stored within a CommonKnowledge server.
Reference: [7] <author> Andrei Z. Broder. </author> <title> Some applications of Rabin's fingerprinting method. </title> <editor> In Renato Capocelli, Alfredo De Santis, and Ugo Vaccaro, editors, </editor> <title> Sequences II: Methods in Communications, Security, </title> <booktitle> and Computer Science, </booktitle> <pages> pages 143-152. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: This approach is simple and easy to implement. In addition to MD5, other faster hashing methods are available, for instance hash functions can be based on polynomial arithmetic as in Rabin's fingerprinting method (See <ref> [42, 7] </ref>), or a simple hash function (e.g. [22, p. 48]) can be used to generate, say 32 bits, and further bits can be obtained by taking random linear transformations of these 32 bits viewed as an integer.
Reference: [8] <author> Pei Cao and Sandy Irani. </author> <title> Cost-aware WWW proxy caching algorithms. </title> <booktitle> In Proceedings of the 1997 USENIX Symposium on Internet Technology and Systems, </booktitle> <month> December </month> <year> 1997. </year>
Reference-contexts: Most of our simulations assume a cache size that is 10% of the "infinite" cache size. Studies have shown that 10% of the "infinite" cache size typically achieves about 90% of the maximum cache hit ratio <ref> [49, 8, 35] </ref>. <p> We also performed simulations with cache sizes being 5% of the infinite cache size and the results are very similar. 3 Benefits of Cache Sharing Recent studies <ref> [8, 23, 14] </ref> have shown that under infinite cache capacity, Web cache hit ratio appears to grow logarithmically with the size of the user population served by the cache. <p> However, if the resource planning for each proxy is done properly, there is no need to perform load-balancing and to incur the overhead of more tightly coordinating schemes. Finally, note that the results are obtained under the LRU replacement algorithm as explained in Section 2. Different replacement algorithms <ref> [8] </ref> may give different results. <p> We experiment with two different cache hit ratios, 25% and 45%, as the overhead of ICP varies with the cache miss ratio in each proxy. In the benchmark, the client issues requests following the temporal locality patterns observed in <ref> [35, 8] </ref>, and the inherent cache hit ratio in the request stream can be adjusted. In an experiment, each client process issues 200 requests, for a total of 24000 requests. Using the benchmark, we compare two configurations: no-ICP, where proxies do not collaborate, and ICP, where proxies collaborate via ICP. <p> There are many studies on Web client access characteristics [10, 3, 14, 33, 23], web caching algorithms <ref> [49, 35, 8] </ref> as well as Web cache consistency [28, 31, 34, 13]. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing.
Reference: [9] <author> M. Crovella and A. Bestavros. </author> <title> Self-similiarity in world wide web traffic: Evidence and possible causes. </title> <booktitle> In Proc of the 1996 Sigmetrics Conference on Measurment and Modeling of Computer systems Philadelphia, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: The client processes on each workstation connect to one of the proxies. Client processes issue requests with no thinking time in between, and the requested document size follow the Pareto distribution with ff = 1:1 and k = 3:0 <ref> [9] </ref>. Finally, two workstations act as servers, each with 15 servers listing on different ports. The Web server forks off a process when handling an HTTP request, and the process waits for 1 second before sending the reply to simulate the network latency.
Reference: [10] <author> Carlos R. Cunha, Azer Bestavros, and Mark E. Crov-ella. </author> <title> Characteristics of WWW client-based traces. </title> <type> Technical report, </type> <institution> BU-CS-96-010, Boston University, </institution> <month> October </month> <year> 1995. </year>
Reference-contexts: Our results indicate that the summary-cache enhanced ICP solves the overhead problem of ICP, requires minimal changes, and enables scalable Web cache sharing over a wide-area network. 8 Related Work Web caching is an active research area. There are many studies on Web client access characteristics <ref> [10, 3, 14, 33, 23] </ref>, web caching algorithms [49, 35, 8] as well as Web cache consistency [28, 31, 34, 13]. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing.
Reference: [11] <author> Michael D. Dahlin, Randolph Y. Wang, Thomas E. Anderson, and David A. Patterson. </author> <title> Cooperative caching: Using remote client memory to improve file system performance. </title> <booktitle> In Proceedings of the First USENIX Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 267-280, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Our inspection of the Questnet traces shows that the child-to-parent ICP queries can be a significant portion (over 2=3) of the messages that the parent has to process. In the operating system context, there have been a lot of studies on cooperative file caching <ref> [11, 2] </ref> and the global memory system (GMS) [17]. The underlying assumption in these systems is that the high-speed local area networks are faster than disks, and workstations should use each other's idle memory to cache file pages or virtual memory pages to avoid traffic to disks.
Reference: [12] <author> P. B. Danzig, R. S. Hall, and M. F. Schwartz. </author> <title> A case for caching file objects inside internetworks. </title> <booktitle> In Proceedings of SIGCOMM '93, </booktitle> <pages> pages 239-248, </pages> <year> 1993. </year>
Reference-contexts: To gain the full benefits of caching, proxy caches behind a common bottleneck link should cooperate and serve each other's misses, thus further reducing the traffic through the bottleneck. We call the process "Web cache sharing." Web cache sharing was first proposed in the context of the Harvest project <ref> [26, 12] </ref>. The Harvest group designed the Internet Cache Protocol (ICP) [18] that supports discovery and retrieval of documents from neighboring caches. Today, many institutions and many countries have established hierarchies of proxy caches that cooperate via ICP to reduce traffic to the Internet [25, 30, 41, 5, 14]. <p> In other words, we assume that cache consistency mechanism is perfect. In practice, there are a variety of protocols <ref> [12, 34, 28] </ref> for Web cache consistency. Most of our simulations assume a cache size that is 10% of the "infinite" cache size. Studies have shown that 10% of the "infinite" cache size typically achieves about 90% of the maximum cache hit ratio [49, 8, 35]. <p> The advantage is that little communication is needed between sibling proxies except for remote hits. Page 17 There have also been many studies on Web cache hierarchies and cache sharing. Hierarchical Web caching is first proposed in the Harvest project <ref> [26, 12] </ref>, which also introduces the ICP protocol. Currently, the Squid proxy server implements version 2 of the ICP protocol [48], upon which our Summary-Cached enhanced ICP is based. Adaptive Web caching [50] proposes a multicast-based adaptive caching infrastructure for document dissemination in the Web.
Reference: [13] <author> Fred Douglis, Anja Feldmann, Balachander Krish-namurthy, and Jeffrey Mogul. </author> <title> Rate of change and other metrics: A live study of the world wide web. </title> <booktitle> In Proceedings of USENIX Symposium on Internet Technology and Systems, </booktitle> <month> December </month> <year> 1997. </year>
Reference-contexts: There are many studies on Web client access characteristics [10, 3, 14, 33, 23], web caching algorithms [49, 35, 8] as well as Web cache consistency <ref> [28, 31, 34, 13] </ref>. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing. Recently, there have been a number of new cache sharing approaches proposed in the literature.
Reference: [14] <author> Bradley M. Duska, David Marwood, and Michael J. Feeley. </author> <title> The measured access characteristics of worldwide-web client proxy caches. </title> <booktitle> In Proceedings of USENIX Symposium on Internet Technology and Systems, </booktitle> <month> December </month> <year> 1997. </year>
Reference-contexts: 1 Introduction As the tremendous growth of the World-Wide Web continues to strain the Internet, caching has been recognized as one of the most important techniques to reduce bandwidth consumption [29]. In particular, caching within Web proxies has been shown to be very effective <ref> [14, 33] </ref>. To gain the full benefits of caching, proxy caches behind a common bottleneck link should cooperate and serve each other's misses, thus further reducing the traffic through the bottleneck. <p> The Harvest group designed the Internet Cache Protocol (ICP) [18] that supports discovery and retrieval of documents from neighboring caches. Today, many institutions and many countries have established hierarchies of proxy caches that cooperate via ICP to reduce traffic to the Internet <ref> [25, 30, 41, 5, 14] </ref>. Nevertheless, the wide deployment of web cache sharing is currently hindered by the overhead of the ICP protocol. ICP discovers cache hits in other proxies by having the proxy multicast a query message to all other proxies whenever a cache miss occurs. <p> We also performed simulations with cache sizes being 5% of the infinite cache size and the results are very similar. 3 Benefits of Cache Sharing Recent studies <ref> [8, 23, 14] </ref> have shown that under infinite cache capacity, Web cache hit ratio appears to grow logarithmically with the size of the user population served by the cache. <p> Our results indicate that the summary-cache enhanced ICP solves the overhead problem of ICP, requires minimal changes, and enables scalable Web cache sharing over a wide-area network. 8 Related Work Web caching is an active research area. There are many studies on Web client access characteristics <ref> [10, 3, 14, 33, 23] </ref>, web caching algorithms [49, 35, 8] as well as Web cache consistency [28, 31, 34, 13]. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing.
Reference: [15] <author> Li Fan, Pei Cao, and Jussara Almeida. </author> <title> A prototype implementation of summary-cache enhanced icp in squid 1.1.14. </title> <address> http://www.cs.wisc.edu/ cao/sc-icp.html, </address> <month> February </month> <year> 1998. </year>
Reference-contexts: Thus, it has the potential to significantly increase the deployment of Web cache sharing and re duce Web traffic on the Internet. Toward this end, we are making our implementation publicly available <ref> [15] </ref> and are in the process of transferring it to the ICP user community. 2 Traces and Simulations For our study we have collected five sets of traces of HTTP requests. The number of requests in each trace, the number of clients, and other statistics are listed in Table 1. <p> Page 15 6 Implementation of Summary- Cache Enhanced ICP Based on the simulation results, we propose the following Summary-Cache Enhanced Internet Cache Protocol as an optimization of ICP. The protocol has been implemented in a prototype built on top of Squid 1.1.14 and the prototype is publicly available <ref> [15] </ref>. A variant of our approach called Cache Digest is also implemented in Squid 1.2b20 [44]. 6.1 The Protocol The design of our protocol is geared toward small delay thresholds. Thus, it assumes that summaries are updated via sending the differences. <p> We have built a prototype implementation in Squid 1.1.14. Synthetic and trace-replay experiments show that, in addition to the network traffic reduction, the new protocol reduces the CPU overhead between 75% to 95% and improves the client latency. The prototype implementation is publicly available <ref> [15] </ref>. Much future work remains. We plan to investigate the impact of the protocol on parent-child proxy cooperations, and the optimal hierarchy configuration for a given workload. We also plan to study the application of summary cache to various Web cache consistency protocols.
Reference: [16] <author> Li Fan, Pei Cao, Jussara Almeida, and Andrei Z. Broder. </author> <title> Summary cache: A scalable wide-area web cache sharing protocol. </title> <type> Technical report, Technical Report 1361, </type> <institution> Computer Science Department, University of Wisconsin-Madison, </institution> <month> February </month> <year> 1998. </year> <note> URL http://www.cs.wisc.edu/ cao/papers/summarycache.html. </note>
Reference-contexts: A load factor between 8 and 16 works well, though proxies can lower or raise it depending on their memory and network traffic concerns. Based on the load factor, four or more hash functions should be used. The data provided here and in <ref> [16] </ref> can be used as references in making the decisions. For hash functions, we recommend taking disjoint groups of bits from the 128-bit MD5 signature of the URL. If more bits are needed, one can calculate the MD5 signature of the URL concatenated with itself.
Reference: [17] <author> Michael J. Feeley, William E. Morgan, Frederic H. Pighin, Anna R. Karlin, Henry M. Levy, and Chan-dramohan A. Thekkath. </author> <title> Implementing global memory management in a workstation cluster. </title> <booktitle> In To appear in Proceedings of 15th ACM Symposium on Operating Systems Principles, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: In the operating system context, there have been a lot of studies on cooperative file caching [11, 2] and the global memory system (GMS) <ref> [17] </ref>. The underlying assumption in these systems is that the high-speed local area networks are faster than disks, and workstations should use each other's idle memory to cache file pages or virtual memory pages to avoid traffic to disks. <p> Most cooperative file caching and GMS systems try to emulate the global LRU replacement algorithm, sometimes also using hints in doing so [45]. It is interesting to note that we arrive at quite different conclusions on whether global replacement algorithm is necessary <ref> [17] </ref>. The reason is that in the OS context, the global replacement algorithm is used for stealing memory from idle workstations (i.e. load-balancing the caches), while in Web cache sharing, every proxy is busy all the time.
Reference: [18] <institution> National Lab for Applied Network Research. Icp working group. </institution> <note> http://ircache.nlanr.net/Cache/ICP/, 1998. </note>
Reference-contexts: We call the process "Web cache sharing." Web cache sharing was first proposed in the context of the Harvest project [26, 12]. The Harvest group designed the Internet Cache Protocol (ICP) <ref> [18] </ref> that supports discovery and retrieval of documents from neighboring caches. Today, many institutions and many countries have established hierarchies of proxy caches that cooperate via ICP to reduce traffic to the Internet [25, 30, 41, 5, 14]. <p> confirmed that in case of severe load imbalance, the global cache will have a better cache hit ratio, and therefore it is important to allocate cache size of each proxy to be proportional to its user population size and anticipated use. 4 Overhead of ICP The Internet Cache Protocol (ICP) <ref> [18] </ref> has been very successful at encouraging the practice of Web cache sharing around the world. It requires loose coordinations among the proxies, and is built on top of UDP for efficiency.
Reference: [19] <institution> National Lab for Applied Network Research. Squid internet object cache. </institution> <note> http://squid.nlanr.net/Squid/, 1998. </note>
Reference-contexts: It requires loose coordinations among the proxies, and is built on top of UDP for efficiency. It was designed by the Harvest research group [26] and supported by both the public-domain Squid <ref> [19] </ref> proxy software and some commercial products today. With the deployment of Squid proxies around the globe, ICP is widely used by international countries to reduce traffic over trans-Atlantic and trans-Pacific links. Despite its success, ICP is not a scalable protocol.
Reference: [20] <author> Armando Fox, Steven D. Gribble, Yatin Chawathe, Eric A. Brewer, and Paul Gauthier. </author> <title> Cluster-based scalable network service. </title> <booktitle> In Proceedings of SOSP'16, </booktitle> <month> October </month> <year> 1997. </year>
Reference-contexts: Proxies built out of tightly-coupled clustered workstations also use various hashing and partitioning approaches to utilize the memory and disks in the cluster <ref> [20] </ref>, but the approaches are not appropriate in wide-area networks. Our study is partially motivated by an existing proposal called directory server [21].
Reference: [21] <author> S. Gadde, M. Rabinovich, and J. Chase. </author> <title> Reduce, reuse, recycle: An approach to building large internet caches. </title> <booktitle> In Proceedings of the Sixth Workshop on Hot Topics in Operating Systems (HotOS VI), </booktitle> <month> May </month> <year> 1997. </year> <note> Available from http://www.research.att.com/ misha/. </note>
Reference-contexts: Proxies built out of tightly-coupled clustered workstations also use various hashing and partitioning approaches to utilize the memory and disks in the cluster [20], but the approaches are not appropriate in wide-area networks. Our study is partially motivated by an existing proposal called directory server <ref> [21] </ref>. The approach uses a central server to keep track of the cache directories of all proxies, and all proxies query the server for cache hits in other proxies. The drawback of the approach is that the central server can easily become a bottleneck.
Reference: [22] <author> G. Gonnet and R. Baeza-Yates. </author> <title> Handbook of Algorithms and Data Structures. </title> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: We first investigate two naive summary representations: exact-directory and server-name. In the exact-directory approach, the summary is essentially the cache directory, with each URL represented by its 16-byte MD5 signature <ref> [38, 22] </ref>. In the server-name approach, the summary is the list of the server name component of the URLs in cache. <p> Since we also need to allocate memory for the counts, it is important to know how large they can become. The asymptotic expected maximum count after inserting n keys with k hash functions into a bit array of size m is (see <ref> [22, p. 72] </ref>) 1 (m) 1 + ln 1 (m) ln 2 1 (m) ; and the probability that any count is greater or equal i is i 1 im : As already mentioned the optimum value for k (over reals) is ln 2m=n so assuming that the number of hash <p> This approach is simple and easy to implement. In addition to MD5, other faster hashing methods are available, for instance hash functions can be based on polynomial arithmetic as in Rabin's fingerprinting method (See [42, 7]), or a simple hash function (e.g. <ref> [22, p. 48] </ref>) can be used to generate, say 32 bits, and further bits can be obtained by taking random linear transformations of these 32 bits viewed as an integer. <p> The header completely specifies the hashing functions used to probe the filter. There are Function Num of hashing functions. The functions are calculated by first taking bits 0 to M-1, M to 2M-1, 2M to 3M-1, etc. out of the MD5 signature <ref> [38, 22] </ref> of the URL, where M is Function Bits, and then modular the bits by BitArray Size InBits. If 128 bits are not enough, more bits are generated by computing the MD5 signature of the URL concatenated with itself. The header is followed by a list of 32-bit integers.
Reference: [23] <author> Steve Gribble and Eric Brewer. </author> <title> System design issues for internet middleware service: Deduction from a large client trace. </title> <booktitle> In Proceedings of USENIX Symposium on Internet Technology and Systems, </booktitle> <month> December </month> <year> 1997. </year>
Reference-contexts: do not include query strings, since most proxies do not cache query requests. * Questnet traces [47]: 7-days worth of logs of HTTP requests seen by the parent proxies at 1 The change may have contributed to the difference between our hit ratio results on UCB and those reported in <ref> [23] </ref>. <p> We also performed simulations with cache sizes being 5% of the infinite cache size and the results are very similar. 3 Benefits of Cache Sharing Recent studies <ref> [8, 23, 14] </ref> have shown that under infinite cache capacity, Web cache hit ratio appears to grow logarithmically with the size of the user population served by the cache. <p> Our results indicate that the summary-cache enhanced ICP solves the overhead problem of ICP, requires minimal changes, and enables scalable Web cache sharing over a wide-area network. 8 Related Work Web caching is an active research area. There are many studies on Web client access characteristics <ref> [10, 3, 14, 33, 23] </ref>, web caching algorithms [49, 35, 8] as well as Web cache consistency [28, 31, 34, 13]. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing.
Reference: [24] <author> Steven Gribble and Eric Brewer. </author> <note> UCB home IP HTTP traces. Available at http://www.cs.berkeley.edu/ grib-ble/traces/index.html, </note> <month> June </month> <year> 1997. </year>
Reference-contexts: Our simulator can only simulate the subtraces due to swap-space limitations. In this paper, we present the results on the trace of the week of Aug. 29 to Sep. 4, 1996. Results on other traces are very similar. * UCB traces <ref> [24] </ref>: traces of HTTP requests gath ered from the Home IP service offered by UC Berkeley to its students, faculty, and staff.
Reference: [25] <author> Christian Grimm. </author> <title> The dfn cache service in B-WiN. In the 2nd Web Caching Workshop, </title> <address> Boulder, Colorado, </address> <month> June </month> <year> 1997. </year> <note> http://www-cache.dfn.de/CacheEN/. </note>
Reference-contexts: The Harvest group designed the Internet Cache Protocol (ICP) [18] that supports discovery and retrieval of documents from neighboring caches. Today, many institutions and many countries have established hierarchies of proxy caches that cooperate via ICP to reduce traffic to the Internet <ref> [25, 30, 41, 5, 14] </ref>. Nevertheless, the wide deployment of web cache sharing is currently hindered by the overhead of the ICP protocol. ICP discovers cache hits in other proxies by having the proxy multicast a query message to all other proxies whenever a cache miss occurs.
Reference: [26] <institution> The Harvest Group. </institution> <note> Harvest information discovery and access system. http://excalibur.usc.edu/, 1994. </note>
Reference-contexts: To gain the full benefits of caching, proxy caches behind a common bottleneck link should cooperate and serve each other's misses, thus further reducing the traffic through the bottleneck. We call the process "Web cache sharing." Web cache sharing was first proposed in the context of the Harvest project <ref> [26, 12] </ref>. The Harvest group designed the Internet Cache Protocol (ICP) [18] that supports discovery and retrieval of documents from neighboring caches. Today, many institutions and many countries have established hierarchies of proxy caches that cooperate via ICP to reduce traffic to the Internet [25, 30, 41, 5, 14]. <p> It requires loose coordinations among the proxies, and is built on top of UDP for efficiency. It was designed by the Harvest research group <ref> [26] </ref> and supported by both the public-domain Squid [19] proxy software and some commercial products today. With the deployment of Squid proxies around the globe, ICP is widely used by international countries to reduce traffic over trans-Atlantic and trans-Pacific links. Despite its success, ICP is not a scalable protocol. <p> The advantage is that little communication is needed between sibling proxies except for remote hits. Page 17 There have also been many studies on Web cache hierarchies and cache sharing. Hierarchical Web caching is first proposed in the Harvest project <ref> [26, 12] </ref>, which also introduces the ICP protocol. Currently, the Squid proxy server implements version 2 of the ICP protocol [48], upon which our Summary-Cached enhanced ICP is based. Adaptive Web caching [50] proposes a multicast-based adaptive caching infrastructure for document dissemination in the Web.
Reference: [27] <author> The Relais Group. Relais: </author> <title> cooperative caches for the worldwide web. </title> <note> http://www-sor.inria.fr/projects/relais/, 1998. </note>
Reference-contexts: An advantage of the approach is that it eliminates duplicate copies of documents. However, it is not clear how well the approach performs for wide-area cache sharing, where proxies are distributed over a regional network. The Relais project <ref> [27] </ref> also proposes using local directories to find documents in other caches, and updating the directories asynchronously. The idea is similar to summary cache. However, the project does not seem to address the issue of memory demands.
Reference: [28] <author> James Gwertzman and Margo Seltzer. </author> <title> World-wide web cache consistency. </title> <booktitle> In Proceedings of the 1996 USENIX Technical Conference, </booktitle> <address> San Diego, CA, </address> <month> Jan-uary </month> <year> 1996. </year> <pages> Page 19 </pages>
Reference-contexts: In other words, we assume that cache consistency mechanism is perfect. In practice, there are a variety of protocols <ref> [12, 34, 28] </ref> for Web cache consistency. Most of our simulations assume a cache size that is 10% of the "infinite" cache size. Studies have shown that 10% of the "infinite" cache size typically achieves about 90% of the maximum cache hit ratio [49, 8, 35]. <p> There are many studies on Web client access characteristics [10, 3, 14, 33, 23], web caching algorithms [49, 35, 8] as well as Web cache consistency <ref> [28, 31, 34, 13] </ref>. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing. Recently, there have been a number of new cache sharing approaches proposed in the literature.
Reference: [29] <author> Van Jacobson. </author> <title> How to kill the internet. </title> <booktitle> In SIGCOMM'95 Middleware Workshop, </booktitle> <month> August </month> <year> 1995. </year> <note> URL ftp://ftp.ee.lhl.gov/talks/vj-webflame.ps.Z. </note>
Reference-contexts: 1 Introduction As the tremendous growth of the World-Wide Web continues to strain the Internet, caching has been recognized as one of the most important techniques to reduce bandwidth consumption <ref> [29] </ref>. In particular, caching within Web proxies has been shown to be very effective [14, 33]. To gain the full benefits of caching, proxy caches behind a common bottleneck link should cooperate and serve each other's misses, thus further reducing the traffic through the bottleneck.
Reference: [30] <author> Jaeyeon. </author> <title> Nation-wide caching project in korea. In the 2nd Web Caching Workshop, </title> <address> Boulder, Colorado, </address> <month> June </month> <year> 1997. </year> <note> http://ircache.nlanr.net/Cache/Workshop97/. </note>
Reference-contexts: The Harvest group designed the Internet Cache Protocol (ICP) [18] that supports discovery and retrieval of documents from neighboring caches. Today, many institutions and many countries have established hierarchies of proxy caches that cooperate via ICP to reduce traffic to the Internet <ref> [25, 30, 41, 5, 14] </ref>. Nevertheless, the wide deployment of web cache sharing is currently hindered by the overhead of the ICP protocol. ICP discovers cache hits in other proxies by having the proxy multicast a query message to all other proxies whenever a cache miss occurs.
Reference: [31] <author> Balachander Krishnamurthy and Craig E. Ellis. </author> <title> Study of piggyback cache validation for proxy caches in the world wide web. </title> <booktitle> In Proceedings of USENIX Symposium on Internet Technology and Systems, </booktitle> <month> De-cember </month> <year> 1997. </year>
Reference-contexts: There are many studies on Web client access characteristics [10, 3, 14, 33, 23], web caching algorithms [49, 35, 8] as well as Web cache consistency <ref> [28, 31, 34, 13] </ref>. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing. Recently, there have been a number of new cache sharing approaches proposed in the literature.
Reference: [32] <author> T. M. Kroeger, J. Mogul, and C. Maltzahn. </author> <title> Digital's web proxy traces. </title> <note> Available at URL: ftp://ftp.digital.com/pub/DEC/traces/proxy/webtraces.html, </note> <month> August </month> <year> 1996. </year>
Reference-contexts: In particular, Table 1 lists the "infinite" cache size for each trace, which is the total size in bytes of unique documents in the trace (i.e. the size of the "infinite" cache which incurs no cache replacement). * DEC traces <ref> [32] </ref>: Digital Equipment Corporation Web Proxy server traces, servicing about 17,000 workstations. The trace is for a period of 25 days (Aug. 29 to Sep. 21, 1996). We partitioned the trace into three one-week traces and one half-week traces. Our simulator can only simulate the subtraces due to swap-space limitations.
Reference: [33] <author> Thomas M. Kroeger, Darrell D. E. Long, and Jef-frey C. Mogul. </author> <title> Exploring the bounds of web latency reduction from caching and prefetching. </title> <booktitle> In Proceedings of USENIX Symposium on Internet Technology and Systems, </booktitle> <month> December </month> <year> 1997. </year>
Reference-contexts: 1 Introduction As the tremendous growth of the World-Wide Web continues to strain the Internet, caching has been recognized as one of the most important techniques to reduce bandwidth consumption [29]. In particular, caching within Web proxies has been shown to be very effective <ref> [14, 33] </ref>. To gain the full benefits of caching, proxy caches behind a common bottleneck link should cooperate and serve each other's misses, thus further reducing the traffic through the bottleneck. <p> Our results indicate that the summary-cache enhanced ICP solves the overhead problem of ICP, requires minimal changes, and enables scalable Web cache sharing over a wide-area network. 8 Related Work Web caching is an active research area. There are many studies on Web client access characteristics <ref> [10, 3, 14, 33, 23] </ref>, web caching algorithms [49, 35, 8] as well as Web cache consistency [28, 31, 34, 13]. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing.
Reference: [34] <author> Chengjie Liu and Pei Cao. </author> <title> Maintaining strong cache consistency for the world-wide web. </title> <booktitle> In The 17th International Conference on Distributed Computing Systems, </booktitle> <month> May </month> <year> 1997. </year>
Reference-contexts: In other words, we assume that cache consistency mechanism is perfect. In practice, there are a variety of protocols <ref> [12, 34, 28] </ref> for Web cache consistency. Most of our simulations assume a cache size that is 10% of the "infinite" cache size. Studies have shown that 10% of the "infinite" cache size typically achieves about 90% of the maximum cache hit ratio [49, 8, 35]. <p> There are many studies on Web client access characteristics [10, 3, 14, 33, 23], web caching algorithms [49, 35, 8] as well as Web cache consistency <ref> [28, 31, 34, 13] </ref>. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing. Recently, there have been a number of new cache sharing approaches proposed in the literature.
Reference: [35] <author> P. Lorenzetti, L. Rizzo, and L. Vicisano. </author> <title> Replacement policies for a proxy cache. </title> <type> Technical report, </type> <institution> Universita di Pisa, Italy, </institution> <month> October </month> <year> 1996. </year> <note> URL http://www.iet.unipi.it/ luigi/caching.ps.gz. </note>
Reference-contexts: Most of our simulations assume a cache size that is 10% of the "infinite" cache size. Studies have shown that 10% of the "infinite" cache size typically achieves about 90% of the maximum cache hit ratio <ref> [49, 8, 35] </ref>. <p> We experiment with two different cache hit ratios, 25% and 45%, as the overhead of ICP varies with the cache miss ratio in each proxy. In the benchmark, the client issues requests following the temporal locality patterns observed in <ref> [35, 8] </ref>, and the inherent cache hit ratio in the request stream can be adjusted. In an experiment, each client process issues 200 requests, for a total of 24000 requests. Using the benchmark, we compare two configurations: no-ICP, where proxies do not collaborate, and ICP, where proxies collaborate via ICP. <p> There are many studies on Web client access characteristics [10, 3, 14, 33, 23], web caching algorithms <ref> [49, 35, 8] </ref> as well as Web cache consistency [28, 31, 34, 13]. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing.
Reference: [36] <author> Carlos Maltzahn, Kathy Richardson, and Dirk Grun-wald. </author> <title> Performance issues of enterprise level web proxies. </title> <booktitle> In Proceedings of the 1997 ACM SIGMET-RICS International Conference on Measurement and Modelling of Computer Systems, </booktitle> <pages> pages 13-23, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: Summaries need to be stored in the main Page 7 memory not only because memory lookups are much faster, but also because disk arms are typically the bottlenecks in proxy caches <ref> [36] </ref>. Although DRAM prices continue to drop, we still need a careful design, since the memory requirement grows linearly with the number of proxies. Summaries also take DRAM away from the in-memory cache of hot documents, affecting the proxy performance. Thus, it is important to keep the summaries small.
Reference: [37] <author> J. Marais and K. Bharat. </author> <title> Supporting cooperative and personal surfing with a desktop assistant. </title> <booktitle> In Proceedings of ACM UIST'97, </booktitle> <month> October </month> <year> 1997. </year> <note> Available on-line at ftp://ftp.digital.com/pub/DEC/SRC /publications/marais/uist97paper.pdf. </note>
Reference-contexts: It was invented by Burton Bloom in 1970 [6] and was proposed for use in the web context by Marais and Bharat <ref> [37] </ref> as a mechani sm for identifying which pages have associated comments stored within a CommonKnowledge server.
Reference: [38] <author> Alfred J. Menezes, Paul C. van Oorschot, and Scott A. Vanstone. </author> <title> Handbook of Applied Cryptography. </title> <publisher> CRC Press, </publisher> <year> 1997. </year>
Reference-contexts: We first investigate two naive summary representations: exact-directory and server-name. In the exact-directory approach, the summary is essentially the cache directory, with each URL represented by its 16-byte MD5 signature <ref> [38, 22] </ref>. In the server-name approach, the summary is the list of the server name component of the URLs in cache. <p> All three configurations use four hash functions. The number of hash functions is not the optimal choice for each configuration, but suffices to demonstrate the performance of Bloom filters. The hash functions are built by first calculating the MD5 signature <ref> [38] </ref> of the URL, which yields 128 bits, then dividing the 128 bits into four 32-bit word, and finally taking the modular of each 32-bit word by the table size m. MD5 is a cryptographic message digest algorithm that hashes arbitrary length strings to 128 bits [38]. <p> calculating the MD5 signature <ref> [38] </ref> of the URL, which yields 128 bits, then dividing the 128 bits into four 32-bit word, and finally taking the modular of each 32-bit word by the table size m. MD5 is a cryptographic message digest algorithm that hashes arbitrary length strings to 128 bits [38]. We select it because of its well-known properties and relatively fast implementation. The performance of these summary representations, the exact-directory approach, and the server-name approach are shown in Figures 5 through 9. <p> The header completely specifies the hashing functions used to probe the filter. There are Function Num of hashing functions. The functions are calculated by first taking bits 0 to M-1, M to 2M-1, 2M to 3M-1, etc. out of the MD5 signature <ref> [38, 22] </ref> of the URL, where M is Function Bits, and then modular the bits by BitArray Size InBits. If 128 bits are not enough, more bits are generated by computing the MD5 signature of the URL concatenated with itself. The header is followed by a list of 32-bit integers.
Reference: [39] <author> Jeffrey C. Mogul, Fred Douglis, Anja Feld-mann, and Balachander Krishnamurthy. </author> <title> Potential benefits of delta encoding and data compression for http. In Proceedings of ACM SIGCOMM'97, </title> <month> August </month> <year> 1997. </year> <note> Available from http://www.research.att.com/ douglis/. </note>
Reference-contexts: A remote stale hit is when a document is cached at another proxy, but the cached copy is stale. Remote stale hits are not necessarily wasted efforts, because delta compressions can be used to transfer the new document <ref> [39] </ref>. However, it does contribute to the inter-proxy communication. Two factors limit the scalability of summary cache: the network overhead (the inter-proxy traffic), and the memory required to store the summaries (for performance reasons, the summaries should be stored in DRAM, not on disk).
Reference: [40] <institution> National Lab of Applied Network Research. </institution> <note> Sanitized access log. Available at ftp://ircache.nlanr.net/Traces/, </note> <month> July </month> <year> 1997. </year> <title> Configuration files for the proxies are at http://ircache.nlanr.net/Cache/Configuration/. </title>
Reference-contexts: We extract successful GET requests seen by the parent proxies. Thus, the trace is only a subset of user requests going to the ten proxies. Unfortunately, the full set of user requests to the proxies are not avail able. * NLANR traces <ref> [40] </ref>: one-day log (Dec. 22, 1997) of HTTP requests to four major parent proxy caches in the National Caching hierarchy by NLANR (National Lab of Applied Network Research). <p> Thus, we believe that the sharp drop in hit ratio is due to the anomaly in the NLANR trace. Unfortunately, we cannot determine the offending clients because client IDs are not consistent across NLANR traces <ref> [40] </ref>. The results demonstrate that in practice, a summary update delay threshold of 1% to 10% results in a tolerable degradation of the cache hit ratios.
Reference: [41] <author> Pietsch. </author> <title> Caching in the washington state k-20 network. In the 2nd Web Caching Workshop, </title> <address> Boulder, Colorado, </address> <month> June </month> <year> 1997. </year> <note> http://ircache.nlanr.net/Cache/Workshop97/. </note>
Reference-contexts: The Harvest group designed the Internet Cache Protocol (ICP) [18] that supports discovery and retrieval of documents from neighboring caches. Today, many institutions and many countries have established hierarchies of proxy caches that cooperate via ICP to reduce traffic to the Internet <ref> [25, 30, 41, 5, 14] </ref>. Nevertheless, the wide deployment of web cache sharing is currently hindered by the overhead of the ICP protocol. ICP discovers cache hits in other proxies by having the proxy multicast a query message to all other proxies whenever a cache miss occurs.
Reference: [42] <author> Michael O. Rabin. </author> <title> Fingerprinting by random polynomials. </title> <type> Technical Report TR-15-81, </type> <institution> Center for Research in Computing Technology, Harvard University, </institution> <year> 1981. </year>
Reference-contexts: This approach is simple and easy to implement. In addition to MD5, other faster hashing methods are available, for instance hash functions can be based on polynomial arithmetic as in Rabin's fingerprinting method (See <ref> [42, 7] </ref>), or a simple hash function (e.g. [22, p. 48]) can be used to generate, say 32 bits, and further bits can be obtained by taking random linear transformations of these 32 bits viewed as an integer.
Reference: [43] <author> Luigi Rizzo. </author> <title> Web proxy traces. </title> <note> Available at URL: http://info.iet.unipi.it/ luigi/proxy-traces/, </note> <month> May </month> <year> 1997. </year>
Reference-contexts: Again, we have run the simulations on other traces in the UCB collections, and the results are similar to what are presented here. * UPisa traces <ref> [43] </ref>: traces of HTTP requests made by the users in Computer Science Department in Universita di Pisa, Italy, for a period of three months from January to March, 1997.
Reference: [44] <author> Alex Rousskov. </author> <title> Cache digest. </title> <address> http://squid.nlanr.net/Squid/CacheDigest/, April 1998. </address>
Reference-contexts: The protocol has been implemented in a prototype built on top of Squid 1.1.14 and the prototype is publicly available [15]. A variant of our approach called Cache Digest is also implemented in Squid 1.2b20 <ref> [44] </ref>. 6.1 The Protocol The design of our protocol is geared toward small delay thresholds. Thus, it assumes that summaries are updated via sending the differences. <p> Thus, it assumes that summaries are updated via sending the differences. If the delay threshold is large, then it is more economical to send the entire bit array; this approach is adopted in the Cache Digest prototype in Squid 1.2b20 <ref> [44] </ref>. We added a new opcode in ICP version 2 [48], ICP OP DIRUPDATE (= 20), which stands for directory update messages.
Reference: [45] <author> P. Sarkar and J. Hartman. </author> <title> Efficient cooperative caching using hints. </title> <booktitle> In Proceedings of the USENIX Conference on Operating System Design and Implementations, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: On the other hand, in both context there is the issue of how tightly coordinated the caches should be. Most cooperative file caching and GMS systems try to emulate the global LRU replacement algorithm, sometimes also using hints in doing so <ref> [45] </ref>. It is interesting to note that we arrive at quite different conclusions on whether global replacement algorithm is necessary [17].
Reference: [46] <author> Vinod Valloppillil and Keith W. Ross. </author> <title> Cache array routing protocol v1.0. </title> <note> http://ircache.nlanr.net/Cache/ICP/draft-vinod-carp-v1-02.txt, 1997. </note>
Reference-contexts: Thus, as the number of proxies increases, both the communication and the CPU processing overhead increase quadratically. A number of alternative protocols have been proposed to address the problem, for example, a cache array routing protocol that partitions the URL space among proxies <ref> [46] </ref>. However, such solutions are often not appropriate for wide-area cache sharing, which is characterized by limited network bandwidth among proxies and non-uniform network distances between proxies and their users (for example, each proxy might be much closer to one user group than to others). <p> Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing. Recently, there have been a number of new cache sharing approaches proposed in the literature. The Cache Array Routing Protocol <ref> [46] </ref> divides URL-space among an array of loosely coupled proxy servers, and lets each proxy cache only the documents whose URLs are hashed to it. An advantage of the approach is that it eliminates duplicate copies of documents.
Reference: [47] <author> Julianne Weekers. </author> <type> Personal communication. </type> <month> January </month> <year> 1998. </year>
Reference-contexts: Of the traces, we only simulate GET requests, and only those whose URLs do not include query strings, since most proxies do not cache query requests. * Questnet traces <ref> [47] </ref>: 7-days worth of logs of HTTP requests seen by the parent proxies at 1 The change may have contributed to the difference between our hit ratio results on UCB and those reported in [23].
Reference: [48] <author> Duane Wessels and Kim Claffy. </author> <title> Internet cache protocol (ICP), </title> <note> version 2. http://ds.internic.net/rfc/rfc2186.txt, 1998. </note>
Reference-contexts: If the delay threshold is large, then it is more economical to send the entire bit array; this approach is adopted in the Cache Digest prototype in Squid 1.2b20 [44]. We added a new opcode in ICP version 2 <ref> [48] </ref>, ICP OP DIRUPDATE (= 20), which stands for directory update messages. In an update message, an additional header follows the regular ICP header and consists of: 16 bits of Function Num, 16 bits of Function Bits, 32 bits of BitArray Size InBits, and 32 bits of Number of Updates. <p> Page 17 There have also been many studies on Web cache hierarchies and cache sharing. Hierarchical Web caching is first proposed in the Harvest project [26, 12], which also introduces the ICP protocol. Currently, the Squid proxy server implements version 2 of the ICP protocol <ref> [48] </ref>, upon which our Summary-Cached enhanced ICP is based. Adaptive Web caching [50] proposes a multicast-based adaptive caching infrastructure for document dissemination in the Web. In particular, the scheme seeks to position the documents at the right caches along the routes to the servers.
Reference: [49] <author> S. Williams, M. Abrams, C.R. Stanbridge, G. Ab-dulla, and E.A. Fox. </author> <title> Removal policies in network caches for world-wide web documents. </title> <booktitle> In Proceedings of the ACM SIGCOMM'96, </booktitle> <month> August </month> <year> 1996. </year> <note> URL http://ei.cs.vt.edu/ succeed/96sigcomm/. </note>
Reference-contexts: Most of our simulations assume a cache size that is 10% of the "infinite" cache size. Studies have shown that 10% of the "infinite" cache size typically achieves about 90% of the maximum cache hit ratio <ref> [49, 8, 35] </ref>. <p> There are many studies on Web client access characteristics [10, 3, 14, 33, 23], web caching algorithms <ref> [49, 35, 8] </ref> as well as Web cache consistency [28, 31, 34, 13]. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing.
Reference: [50] <author> Lixia Zhang, Sally Floyd, and Van Jacobson. </author> <title> Adaptive web caching. In the 2nd Web Caching Workshop, </title> <address> Boulder, Col-orado, </address> <month> June </month> <year> 1997. </year> <note> http://ircache.nlanr.net/Cache/ Workshop97/Papers/Floyd/floyd.ps. Page 20 </note>
Reference-contexts: Hierarchical Web caching is first proposed in the Harvest project [26, 12], which also introduces the ICP protocol. Currently, the Squid proxy server implements version 2 of the ICP protocol [48], upon which our Summary-Cached enhanced ICP is based. Adaptive Web caching <ref> [50] </ref> proposes a multicast-based adaptive caching infrastructure for document dissemination in the Web. In particular, the scheme seeks to position the documents at the right caches along the routes to the servers. Our study does not address the positioning issues.
References-found: 50

