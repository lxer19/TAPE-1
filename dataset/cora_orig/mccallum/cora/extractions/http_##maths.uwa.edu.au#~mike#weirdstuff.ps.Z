URL: http://maths.uwa.edu.au/~mike/weirdstuff.ps.Z
Refering-URL: http://ciips.ee.uwa.edu.au/~mike/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: An Investigation into Formal Animals  
Author: Michael D. Alder 
Date: November 24, 1996  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Edwin T. Jaynes. </author> <title> Probability Theory: </title> <booktitle> The Logic of Science. </booktitle> <address> Wash-ington University in St. Louis, http://bayes.wustl.edu, 1996. </address>
Reference-contexts: Indeed, one way of modelling uncertainty or noise is to regard it as ignorance of factors not perceived. See Jaynes, <ref> [1] </ref> for, inter alia, an intelligent discourse on foundational aspects of probability theory which takes this view. <p> We next consider a missile which extrapolates the position of the target, heads for a mixture of where it is and where it is predicted to be. Let 54 CHAPTER 2. ANIMALS : R + ! <ref> [0; 1] </ref> be a function which has (0) = 0 and is monotone increasing. <p> One of the squares will have only the ^ E T terms, the other the rest. There are two parameters which specify the map b 0 , namely the values of , the prognostication time, and the value of , the map into <ref> [0; 1] </ref> which determines the mix between the lookahead and the actual value of where the target is. As observed, we wish to switch from aiming where the target is going to be to where it is, with a speed of `switch' given by .
Reference: [2] <author> Gene Franklin; J. David Powell; Abbas Emami-Naeini. </author> <title> Feedback Control of Dynamic Systems. </title> <publisher> Addison-Wesley, </publisher> <address> Reading Mass., </address> <year> 1987. </year>
Reference-contexts: The situation is described as a simple proportional feedback closed loop control system, in the language of Control Theory . See <ref> [2] </ref> for the source of the terminology `stick on a cart'. The effector rule given is not a particularly good example of a control system, but by analysing the effects of changing the rule, we can easily find a better one. <p> INTRODUCTION: ABSTRACT ORGANISMS a PID controller (Proportional, Integral, Derivative). They have been studied extensively and are well known to engineers, <ref> [2, 3, 4] </ref> This may give an optimal controller of the system; it is, of course, optimal with respect to the model of the reality employed.
Reference: [3] <author> Richard C. Dorf. </author> <title> Modern Control Systems. </title> <publisher> Addison Wesley, </publisher> <address> NY, fifth edition, </address> <year> 1989. </year>
Reference-contexts: INTRODUCTION: ABSTRACT ORGANISMS a PID controller (Proportional, Integral, Derivative). They have been studied extensively and are well known to engineers, <ref> [2, 3, 4] </ref> This may give an optimal controller of the system; it is, of course, optimal with respect to the model of the reality employed.
Reference: [4] <author> Thomas Kailath. </author> <title> Linear Systems. </title> <publisher> Prentice-Hall, </publisher> <address> NY, </address> <year> 1980. </year>
Reference-contexts: INTRODUCTION: ABSTRACT ORGANISMS a PID controller (Proportional, Integral, Derivative). They have been studied extensively and are well known to engineers, <ref> [2, 3, 4] </ref> This may give an optimal controller of the system; it is, of course, optimal with respect to the model of the reality employed.
Reference: [5] <author> Yoan D. Landau. </author> <title> Adaptive Control: The Model Reference Approach, volume 8 of Control Systems Theory. </title> <publisher> Marcel Dekker, </publisher> <address> NY, </address> <year> 1979. </year>
Reference-contexts: More complicated forms of adaption are easy to envisage. Such an 1.2. MAKING THIS PRECISE 31 organism is clearly learning from experience of what works and what does not. Such a control system is known as an adaptive controller, and they are studied extensively, see <ref> [5, 6, 7] </ref>. It is not too far fetched to suppose that a child learns to walk in much this way, although there are many more sensory data, and many complex sequences to be learnt, rather than a single parameter. <p> It is clear that the equation arises naturally in the setting of organisms in a universe. It is also well known that it is a considerable restriction on the class of control systems which are necessary in practice, <ref> [5] </ref>. The stick on a cart in the first example of that organism gives a non-linear map, which may be linearised when the angle is small, but constructing a computer simulation is much more profitable than trying to solve in closed form the non-linearised equations. <p> Such self-organising automata are used in control theory in those (many) cases where the engineer does not have a satisfactory knowledge of the world map. See <ref> [5, 6, 7] </ref> for accessible expositions of some of the ideas of Adaptive Control Theory. 38 CHAPTER 1.
Reference: [6] <author> K.S. Narendra; A.M. Annaswamy. </author> <title> Stable Adaptive Systems, </title> <booktitle> volume 14 of Information and Systems Sciences. </booktitle> <publisher> Prentice-Hall, </publisher> <address> En-glewood Cliffs NJ, </address> <year> 1989. </year>
Reference-contexts: More complicated forms of adaption are easy to envisage. Such an 1.2. MAKING THIS PRECISE 31 organism is clearly learning from experience of what works and what does not. Such a control system is known as an adaptive controller, and they are studied extensively, see <ref> [5, 6, 7] </ref>. It is not too far fetched to suppose that a child learns to walk in much this way, although there are many more sensory data, and many complex sequences to be learnt, rather than a single parameter. <p> Such self-organising automata are used in control theory in those (many) cases where the engineer does not have a satisfactory knowledge of the world map. See <ref> [5, 6, 7] </ref> for accessible expositions of some of the ideas of Adaptive Control Theory. 38 CHAPTER 1.
Reference: [7] <author> Carlos A Canudas de Wit. </author> <title> Adaptive Control for Partially Known Systems:Theory and Application, </title> <booktitle> volume 7 of Studies in Automation and Control. </booktitle> <publisher> Elsevier, </publisher> <address> Amsterdam, </address> <year> 1988? </year>
Reference-contexts: More complicated forms of adaption are easy to envisage. Such an 1.2. MAKING THIS PRECISE 31 organism is clearly learning from experience of what works and what does not. Such a control system is known as an adaptive controller, and they are studied extensively, see <ref> [5, 6, 7] </ref>. It is not too far fetched to suppose that a child learns to walk in much this way, although there are many more sensory data, and many complex sequences to be learnt, rather than a single parameter. <p> Such self-organising automata are used in control theory in those (many) cases where the engineer does not have a satisfactory knowledge of the world map. See <ref> [5, 6, 7] </ref> for accessible expositions of some of the ideas of Adaptive Control Theory. 38 CHAPTER 1.
Reference: [8] <author> R.G. Brown; P.Y.C. Hwang. </author> <title> Introduction to Random Signals and Applied Kalman Filtering. </title> <publisher> John Wiley, </publisher> <address> N.Y., </address> <note> second edition, </note> <year> 1992. </year>
Reference-contexts: t+1 C T (CP Since R is, by hypothesis, positive definite and CP t+1 C T is non-negative definite ( P t is always a covariance matrix), the term in parentheses is positive definite (and symmetric) and hence invertible. 2 The treatment here is a simplified version of that in <ref> [8] </ref>. Other versions may be found in [9] and [10]. The derivation of the update procedures given in [8] is elementary, convincing and warmly recommended. The result generalises in several ways, notably to the case where the matrices A,C, Q, R are allowed to be arbitrary functions of time. <p> definite ( P t is always a covariance matrix), the term in parentheses is positive definite (and symmetric) and hence invertible. 2 The treatment here is a simplified version of that in <ref> [8] </ref>. Other versions may be found in [9] and [10]. The derivation of the update procedures given in [8] is elementary, convincing and warmly recommended. The result generalises in several ways, notably to the case where the matrices A,C, Q, R are allowed to be arbitrary functions of time. The matrix K t is called the Kalman Gain matrix at time t. <p> The matrix K t is called the Kalman Gain matrix at time t. The al gorithm was presented by Kalman in 1960, and the real time case was presented by Kalman and Bucy the following year. There are a number of applications of Kalman filters in <ref> [8] </ref> It may be seen that the animal which is a simple Kalman Filter, like the missile which predicts ahead, merely updates the prediction at each time step. The Kalman filter has a very explicit model embodied in it. 52 CHAPTER 2.
Reference: [9] <author> A.V. Balakrishnan. </author> <title> Kalman Filtering Theory. University Series in Modern Engineering. Optimization Software Inc, </title> <address> NY, </address> <year> 1984. </year> <note> 61 62 BIBLIOGRAPHY </note>
Reference-contexts: Other versions may be found in <ref> [9] </ref> and [10]. The derivation of the update procedures given in [8] is elementary, convincing and warmly recommended. The result generalises in several ways, notably to the case where the matrices A,C, Q, R are allowed to be arbitrary functions of time.
Reference: [10] <author> C. K. Chui; G Chen. </author> <title> Kalman Filtering, </title> <booktitle> volume 17 of Springer Series in Information Sciences. </booktitle> <publisher> Springer, </publisher> <address> Berlin, New York, </address> <year> 1987. </year>
Reference-contexts: Other versions may be found in [9] and <ref> [10] </ref>. The derivation of the update procedures given in [8] is elementary, convincing and warmly recommended. The result generalises in several ways, notably to the case where the matrices A,C, Q, R are allowed to be arbitrary functions of time.
References-found: 10

