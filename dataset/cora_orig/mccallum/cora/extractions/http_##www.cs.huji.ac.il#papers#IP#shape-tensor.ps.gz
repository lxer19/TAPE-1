URL: http://www.cs.huji.ac.il/papers/IP/shape-tensor.ps.gz
Refering-URL: http://www.cs.huji.ac.il/papers/IP/index.html
Root-URL: 
Email: email: daphna@cs.huji.ac.il  
Title: Shape Tensors for Efficient and Learnable Indexing  
Author: Daphna Weinshall, Michael Werman and Amnon Shashua 
Address: 91904, Jerusalem, Israel tl: 972-2-658-6298  
Affiliation: Institute of Computer Science, The Hebrew University of Jerusalem  
Abstract: Multi-point geometry: The geometry of 1 point in N images under perspective projection has been thoroughly investigated, identifying bilinear, trilinear, and quadrilinear relations between the projections of 1 point in 2, 3 and 4 frames respectively. The dual problem the geometry of N points in 1 image has been studied mostly in the context of object recognition, often assuming weak perspective or affine projection. We provide here a complete description of this problem. We employ a formalism in which multi-frame and multi-point geometries appear in symmetry: points and projections are interchangeable. We then derive bilinear equations for 6 points (dual to 4-frame geometry), trilinear equations for 7 points (dual to 3-frame geometry), and quadrilinear equations for 8 points (dual to the epipolar geometry). We show that the quadrilinear equations are dependent on the the bilinear and trilinear equations, and we show that adding more points will not generate any new equation. Applications to reconstruction and recognition: The new equations are used to design new algorithms for the reconstruction of shape from many frames, and for learning invariant relations for indexing into a data-base. We describe algorithms which require matching 6 (or more) corresponding points from at least 4 images, 7 (or more) points from at least 3 images, or 8 (or more) points from at least 2 images. Unlike previous approaches, the equations developed here lead to direct and linear solutions without going through the cameras' geometry. Our final linear shape computation uses all the available data all points and all frames simultaneously: it uses a factorization of the matrix of invariant relations into 2 components of rank 4, a shape matrix and a coordinate-system matrix. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Carlsson. </author> <title> Duality of reconstruction and positioning from projective views. </title> <booktitle> In IEEE Workshop on Representations of Visual Scenes, </booktitle> <address> Cambridge, Mass, </address> <year> 1995. </year>
Reference-contexts: A geometrical interpretation and derivation leading to the same observation can be also found in <ref> [1] </ref>. 2.3 Multi-point geometry From now on we fix the frame and ignore the subscript j. <p> Ignoring for now this technical difficulty, the homogeneous 3D coordinates of each point can be recovered from the shape vectors V6; V7 as follows: 6 model points: X 1 = V6 [2] V6 [3] W 1 V6 [4] Z 1 = V6 <ref> [1] </ref> V6 [2] 7 model points: X 1 = V7 [11] W 1 V7 [4] V7 [5] Z 1 = V7 [10] V7 [11] W 2 V7 [4] V7 [7] Y 2 = V7 [3] V7 [9] W 2 V7 [2] V7 [5] Similar derivation can be obtained from V8. 2.8
Reference: [2] <author> O. Faugeras. </author> <booktitle> What can be seen in three dimensions with an uncalibrated stereo rig? In Proceedings of the 2nd European Conference on Computer Vision, </booktitle> <pages> pages 563-578, </pages> <address> Santa Margherita Ligure, Italy, 1992. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: in P 2 : P M = m (2) Given our particular selection of projective bases, and using the fact that the first 4 points are transformed from a basis in P 3 to a basis in P 2 , the pro jection matrix P must be of the form <ref> [2] </ref>: P = 6 ff 0 0 ffi 0 0 fl ffi 7 We define a corresponding projection vector in P 3 p = ( ff fi fl ffi ) 2.2 Multi-frame and multi-point geome try We start by writing down (2) for the 5 + i model point M i <p> Note that only "projective shape", namely, the shape up to a linear transformation in the projective space P 3 , is computed; with uncalibrated cameras, this is the most we can compute <ref> [2] </ref>. Clearly there are less degrees of freedom in the explicit representation as compared to any of the shape vectors. This is because there are additional non-linear constraints on the elements of the shape vectors, constraints which we have until now ignored. <p> Ignoring for now this technical difficulty, the homogeneous 3D coordinates of each point can be recovered from the shape vectors V6; V7 as follows: 6 model points: X 1 = V6 <ref> [2] </ref> V6 [3] W 1 V6 [4] Z 1 = V6 [1] V6 [2] 7 model points: X 1 = V7 [11] W 1 V7 [4] V7 [5] Z 1 = V7 [10] V7 [11] W 2 V7 [4] V7 [7] Y 2 = V7 [3] V7 [9] W 2 V7 <p> Ignoring for now this technical difficulty, the homogeneous 3D coordinates of each point can be recovered from the shape vectors V6; V7 as follows: 6 model points: X 1 = V6 <ref> [2] </ref> V6 [3] W 1 V6 [4] Z 1 = V6 [1] V6 [2] 7 model points: X 1 = V7 [11] W 1 V7 [4] V7 [5] Z 1 = V7 [10] V7 [11] W 2 V7 [4] V7 [7] Y 2 = V7 [3] V7 [9] W 2 V7 [2] V7 [5] Similar derivation can be obtained from V8. 2.8 Geometrical interpretation: <p> V6 [3] W 1 V6 [4] Z 1 = V6 [1] V6 <ref> [2] </ref> 7 model points: X 1 = V7 [11] W 1 V7 [4] V7 [5] Z 1 = V7 [10] V7 [11] W 2 V7 [4] V7 [7] Y 2 = V7 [3] V7 [9] W 2 V7 [2] V7 [5] Similar derivation can be obtained from V8. 2.8 Geometrical interpretation: A geometrical interpretation of what's going on here is the following: A projection transformation from a 3D world to a 2D image is mapped to a point in P 3 .
Reference: [3] <author> O. Faugeras and B. Mourrain. </author> <title> On the geometry and algebra of the point and line correspondences between N images. In Proceeding of the Europe-China Workshop on geometrical modeling and invariant for computer vision. </title> <publisher> Xidian University Press, </publisher> <year> 1995. </year>
Reference-contexts: A few 3fi3fi3 tensors represent the camera geometry, and the image measurements appear in the equations in trilinear forms [8, 9, 11, 4]. 4 images: A few 3 fi 3 fi 3 fi 3 tensors represent the camera geometry, and the image measurements appear in the equations in quadrilinear forms <ref> [13, 17, 3] </ref>. [3] provides a simple derivation of the same results, using crisp geometrical intuition and no more than linear algebra. Much less is known about multi-point geometry under perspective projection with uncalibrated cameras, and this gap is filled by our paper. <p> tensors represent the camera geometry, and the image measurements appear in the equations in trilinear forms [8, 9, 11, 4]. 4 images: A few 3 fi 3 fi 3 fi 3 tensors represent the camera geometry, and the image measurements appear in the equations in quadrilinear forms [13, 17, 3]. <ref> [3] </ref> provides a simple derivation of the same results, using crisp geometrical intuition and no more than linear algebra. Much less is known about multi-point geometry under perspective projection with uncalibrated cameras, and this gap is filled by our paper. <p> We prove these results by modifying the analysis described in <ref> [3] </ref> to apply to the dual multi-point case. This analysis gives the geometrical insight into what is going on. We first observe that a projection matrix from a 3D projective world to a 2D projective image is really a point in P 3 . <p> Hopefully, the 2 approaches can be combined to obtain better results in both computations. 2 Algebraic and Geometrical deriva tion of Results In this section we derive the bilinear, trilinear, and quadrilinear results described in the introduction, using a formalism analogous to <ref> [3] </ref>. We show duality between multi-frame and multi-point geometries: every relation between the vector coordinates of one point in many images has an almost identical equivalent here, a relation between the vector coordinates of many points in 1 image. <p> Therefore it is necessary to consider the columns of a measurement matrix where the 3D and 2D coordinate systems are general, using a general 3 fi 4 projection matrix and not a point in P 3 . This is the derivation described in <ref> [3] </ref>. In order for these points to be instances of the model M, the 4 fi 4 matrix must be of rank 3, namely, its determinant must be 0. <p> Ignoring for now this technical difficulty, the homogeneous 3D coordinates of each point can be recovered from the shape vectors V6; V7 as follows: 6 model points: X 1 = V6 [2] V6 <ref> [3] </ref> W 1 V6 [4] Z 1 = V6 [1] V6 [2] 7 model points: X 1 = V7 [11] W 1 V7 [4] V7 [5] Z 1 = V7 [10] V7 [11] W 2 V7 [4] V7 [7] Y 2 = V7 [3] V7 [9] W 2 V7 [2] V7 <p> points: X 1 = V6 [2] V6 <ref> [3] </ref> W 1 V6 [4] Z 1 = V6 [1] V6 [2] 7 model points: X 1 = V7 [11] W 1 V7 [4] V7 [5] Z 1 = V7 [10] V7 [11] W 2 V7 [4] V7 [7] Y 2 = V7 [3] V7 [9] W 2 V7 [2] V7 [5] Similar derivation can be obtained from V8. 2.8 Geometrical interpretation: A geometrical interpretation of what's going on here is the following: A projection transformation from a 3D world to a 2D image is mapped to a point in P 3 .
Reference: [4] <author> R. </author> <title> Hartley. Lines and points in three views - an integrated approach. </title> <booktitle> In Proceedings Image Understanding Workshop, </booktitle> <pages> pages 1009-10016, </pages> <address> San Mateo, CA, 1994. </address> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: This case is described by the epipolar geometry: the fundamental matrix represents the camera geometry, and the image measurements appear in the equation in a bilinear form [5, 6]. 3 images: A few 3fi3fi3 tensors represent the camera geometry, and the image measurements appear in the equations in trilinear forms <ref> [8, 9, 11, 4] </ref>. 4 images: A few 3 fi 3 fi 3 fi 3 tensors represent the camera geometry, and the image measurements appear in the equations in quadrilinear forms [13, 17, 3]. [3] provides a simple derivation of the same results, using crisp geometrical intuition and no more than <p> Ignoring for now this technical difficulty, the homogeneous 3D coordinates of each point can be recovered from the shape vectors V6; V7 as follows: 6 model points: X 1 = V6 [2] V6 [3] W 1 V6 <ref> [4] </ref> Z 1 = V6 [1] V6 [2] 7 model points: X 1 = V7 [11] W 1 V7 [4] V7 [5] Z 1 = V7 [10] V7 [11] W 2 V7 [4] V7 [7] Y 2 = V7 [3] V7 [9] W 2 V7 [2] V7 [5] Similar derivation can <p> the homogeneous 3D coordinates of each point can be recovered from the shape vectors V6; V7 as follows: 6 model points: X 1 = V6 [2] V6 [3] W 1 V6 <ref> [4] </ref> Z 1 = V6 [1] V6 [2] 7 model points: X 1 = V7 [11] W 1 V7 [4] V7 [5] Z 1 = V7 [10] V7 [11] W 2 V7 [4] V7 [7] Y 2 = V7 [3] V7 [9] W 2 V7 [2] V7 [5] Similar derivation can be obtained from V8. 2.8 Geometrical interpretation: A geometrical interpretation of what's going on here is the following: A <p> vectors V6; V7 as follows: 6 model points: X 1 = V6 [2] V6 [3] W 1 V6 <ref> [4] </ref> Z 1 = V6 [1] V6 [2] 7 model points: X 1 = V7 [11] W 1 V7 [4] V7 [5] Z 1 = V7 [10] V7 [11] W 2 V7 [4] V7 [7] Y 2 = V7 [3] V7 [9] W 2 V7 [2] V7 [5] Similar derivation can be obtained from V8. 2.8 Geometrical interpretation: A geometrical interpretation of what's going on here is the following: A projection transformation from a 3D world to a 2D image is mapped to
Reference: [5] <author> H. C. Longuet-Higgins. </author> <title> A computer algorithm for reconstructing a scene from two projections. </title> <journal> Nature, </journal> <volume> 293 </volume> <pages> 133-135, </pages> <year> 1981. </year>
Reference-contexts: For the case of uncalibrated perspective cameras, the following has been shown: 2 images: This case is described by the epipolar geometry: the fundamental matrix represents the camera geometry, and the image measurements appear in the equation in a bilinear form <ref> [5, 6] </ref>. 3 images: A few 3fi3fi3 tensors represent the camera geometry, and the image measurements appear in the equations in trilinear forms [8, 9, 11, 4]. 4 images: A few 3 fi 3 fi 3 fi 3 tensors represent the camera geometry, and the image measurements appear in the equations <p> 3D coordinates of each point can be recovered from the shape vectors V6; V7 as follows: 6 model points: X 1 = V6 [2] V6 [3] W 1 V6 [4] Z 1 = V6 [1] V6 [2] 7 model points: X 1 = V7 [11] W 1 V7 [4] V7 <ref> [5] </ref> Z 1 = V7 [10] V7 [11] W 2 V7 [4] V7 [7] Y 2 = V7 [3] V7 [9] W 2 V7 [2] V7 [5] Similar derivation can be obtained from V8. 2.8 Geometrical interpretation: A geometrical interpretation of what's going on here is the following: A projection transformation <p> W 1 V6 [4] Z 1 = V6 [1] V6 [2] 7 model points: X 1 = V7 [11] W 1 V7 [4] V7 <ref> [5] </ref> Z 1 = V7 [10] V7 [11] W 2 V7 [4] V7 [7] Y 2 = V7 [3] V7 [9] W 2 V7 [2] V7 [5] Similar derivation can be obtained from V8. 2.8 Geometrical interpretation: A geometrical interpretation of what's going on here is the following: A projection transformation from a 3D world to a 2D image is mapped to a point in P 3 .
Reference: [6] <author> Q.-T. Luong and O. Faugeras. </author> <title> The fundamental matrix: theory, algorithms, and stability analysis. </title> <journal> International Journal of Computer Vision, </journal> <note> 1995. in press. </note>
Reference-contexts: For the case of uncalibrated perspective cameras, the following has been shown: 2 images: This case is described by the epipolar geometry: the fundamental matrix represents the camera geometry, and the image measurements appear in the equation in a bilinear form <ref> [5, 6] </ref>. 3 images: A few 3fi3fi3 tensors represent the camera geometry, and the image measurements appear in the equations in trilinear forms [8, 9, 11, 4]. 4 images: A few 3 fi 3 fi 3 fi 3 tensors represent the camera geometry, and the image measurements appear in the equations
Reference: [7] <author> L. Quan. </author> <title> Invariants of 6 points from 3 uncalibrated images. </title> <booktitle> In Proceedings of the 3rd European Conference on Computer Vision, </booktitle> <pages> pages 459-470, </pages> <address> Stockholdm, Sweden, 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: We can rewrite (4) in a matrix form, in a dual way to the use of the fundamental matrix to describe the epipolar geometry (cf. <ref> [7] </ref>): m T " b 1 # where G 01 = W 1 Y 1 Y 1 Z 1 0 X 1 Y 1 W 1 Y 1 # Whereas the fundamental matrix depends on the camera calibration, the matrix G 01 here depends on the 3D shape of the object. <p> V7 as follows: 6 model points: X 1 = V6 [2] V6 [3] W 1 V6 [4] Z 1 = V6 [1] V6 [2] 7 model points: X 1 = V7 [11] W 1 V7 [4] V7 [5] Z 1 = V7 [10] V7 [11] W 2 V7 [4] V7 <ref> [7] </ref> Y 2 = V7 [3] V7 [9] W 2 V7 [2] V7 [5] Similar derivation can be obtained from V8. 2.8 Geometrical interpretation: A geometrical interpretation of what's going on here is the following: A projection transformation from a 3D world to a 2D image is mapped to a point
Reference: [8] <author> A. Shashua. </author> <title> Trilinearity in visual recognition by alignment. </title> <booktitle> In Proceedings of the 1st Eu-ropean Conference on Computer Vision, </booktitle> <address> Stock-holm, Sweden, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: This case is described by the epipolar geometry: the fundamental matrix represents the camera geometry, and the image measurements appear in the equation in a bilinear form [5, 6]. 3 images: A few 3fi3fi3 tensors represent the camera geometry, and the image measurements appear in the equations in trilinear forms <ref> [8, 9, 11, 4] </ref>. 4 images: A few 3 fi 3 fi 3 fi 3 tensors represent the camera geometry, and the image measurements appear in the equations in quadrilinear forms [13, 17, 3]. [3] provides a simple derivation of the same results, using crisp geometrical intuition and no more than
Reference: [9] <author> A. Shashua. </author> <title> Algebraic functions for recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <note> 1995. in press. </note>
Reference-contexts: This case is described by the epipolar geometry: the fundamental matrix represents the camera geometry, and the image measurements appear in the equation in a bilinear form [5, 6]. 3 images: A few 3fi3fi3 tensors represent the camera geometry, and the image measurements appear in the equations in trilinear forms <ref> [8, 9, 11, 4] </ref>. 4 images: A few 3 fi 3 fi 3 fi 3 tensors represent the camera geometry, and the image measurements appear in the equations in quadrilinear forms [13, 17, 3]. [3] provides a simple derivation of the same results, using crisp geometrical intuition and no more than <p> 1 = V6 [2] V6 [3] W 1 V6 [4] Z 1 = V6 [1] V6 [2] 7 model points: X 1 = V7 [11] W 1 V7 [4] V7 [5] Z 1 = V7 [10] V7 [11] W 2 V7 [4] V7 [7] Y 2 = V7 [3] V7 <ref> [9] </ref> W 2 V7 [2] V7 [5] Similar derivation can be obtained from V8. 2.8 Geometrical interpretation: A geometrical interpretation of what's going on here is the following: A projection transformation from a 3D world to a 2D image is mapped to a point in P 3 .
Reference: [10] <author> A. Shashua and S. Avidan. </author> <title> N&gt;4 camera geometry part I: rank consistency across trilinear tensors, </title> <note> 1995. in preparation. </note>
Reference-contexts: can be recovered from the shape vectors V6; V7 as follows: 6 model points: X 1 = V6 [2] V6 [3] W 1 V6 [4] Z 1 = V6 [1] V6 [2] 7 model points: X 1 = V7 [11] W 1 V7 [4] V7 [5] Z 1 = V7 <ref> [10] </ref> V7 [11] W 2 V7 [4] V7 [7] Y 2 = V7 [3] V7 [9] W 2 V7 [2] V7 [5] Similar derivation can be obtained from V8. 2.8 Geometrical interpretation: A geometrical interpretation of what's going on here is the following: A projection transformation from a 3D world to <p> 4 which is the closest (in least squares) to W; ~ W is computed 4 On the duality between the trilinear camera and shape ten-sors, we note that this result is dual to the recent result stating that all trilinear camera tensors having two fixed views satisfy a rank constraint <ref> [10] </ref>.
Reference: [11] <author> A. Shashua and M. Werman. </author> <title> Trilinearity of three perspective views and its associated tensor. </title> <booktitle> In Proceedings of the 5th International Conference on Computer Vision, </booktitle> <address> Cambridge, MA, 1995. </address> <publisher> IEEE, </publisher> <address> Washington, DC. </address>
Reference-contexts: This case is described by the epipolar geometry: the fundamental matrix represents the camera geometry, and the image measurements appear in the equation in a bilinear form [5, 6]. 3 images: A few 3fi3fi3 tensors represent the camera geometry, and the image measurements appear in the equations in trilinear forms <ref> [8, 9, 11, 4] </ref>. 4 images: A few 3 fi 3 fi 3 fi 3 tensors represent the camera geometry, and the image measurements appear in the equations in quadrilinear forms [13, 17, 3]. [3] provides a simple derivation of the same results, using crisp geometrical intuition and no more than <p> now this technical difficulty, the homogeneous 3D coordinates of each point can be recovered from the shape vectors V6; V7 as follows: 6 model points: X 1 = V6 [2] V6 [3] W 1 V6 [4] Z 1 = V6 [1] V6 [2] 7 model points: X 1 = V7 <ref> [11] </ref> W 1 V7 [4] V7 [5] Z 1 = V7 [10] V7 [11] W 2 V7 [4] V7 [7] Y 2 = V7 [3] V7 [9] W 2 V7 [2] V7 [5] Similar derivation can be obtained from V8. 2.8 Geometrical interpretation: A geometrical interpretation of what's going on here <p> recovered from the shape vectors V6; V7 as follows: 6 model points: X 1 = V6 [2] V6 [3] W 1 V6 [4] Z 1 = V6 [1] V6 [2] 7 model points: X 1 = V7 <ref> [11] </ref> W 1 V7 [4] V7 [5] Z 1 = V7 [10] V7 [11] W 2 V7 [4] V7 [7] Y 2 = V7 [3] V7 [9] W 2 V7 [2] V7 [5] Similar derivation can be obtained from V8. 2.8 Geometrical interpretation: A geometrical interpretation of what's going on here is the following: A projection transformation from a 3D world to a 2D
Reference: [12] <author> C. Tomasi and T. Kanade. </author> <title> Shape and motion from image streams under orthography: a factorization method. </title> <journal> International Journal of Computer Vision, </journal> <volume> 9(2) </volume> <pages> 137-154, </pages> <year> 1992. </year>
Reference-contexts: We made the distinction above between algorithms that compute camera geometry first and shape next, and algorithms that compute shape first and camera geometry next. Under the weak perspective projection, the distinction does not have to be that sharp. In <ref> [12] </ref> (see also [14, 15]), Tomasi & Kanade described a factorization method for the weak perspective projection model, where the data is linearly divided into shape components and camera geometry components. <p> To proceed, we cannot use a global method such as SVD decomposition as proposed in <ref> [12] </ref>; instead, we can isolate and compute each component separately, as proposed in [15, 16]. The algorithms described in this paper, together with the algorithms developed for the multi-camera geometry, allow us to accomplish this goal. <p> With k frames and n + 4 points, we get the 2k fi n measurements matrix W whose ji element is x ji for j k, and y (jk)i for k &lt; j 2k (cf. <ref> [12, 16] </ref>). Now if we read W by columns, the i-th column gives us multi-camera geometry 1 ; if we read it by rows, the j-th and (j + k) th rows give us multi-point geometry in a single image. <p> Taken together, both the multiplicity of views (three or more) and the multiplicity of points (7 or more) contribute to a linear least-squares solution of projective shape, in the final algorithm described in Section 4. To date, this idea is the closest in spirit to the factorization method of <ref> [12] </ref> for scaled orthographic projection.
Reference: [13] <author> B. Triggs. </author> <title> The geometry of projective reconstruction I: matching constraints and the joint image. </title> <type> Technical report, </type> <institution> LIFIA, INRIA Rhone Alpes, </institution> <year> 1994. </year>
Reference-contexts: A few 3fi3fi3 tensors represent the camera geometry, and the image measurements appear in the equations in trilinear forms [8, 9, 11, 4]. 4 images: A few 3 fi 3 fi 3 fi 3 tensors represent the camera geometry, and the image measurements appear in the equations in quadrilinear forms <ref> [13, 17, 3] </ref>. [3] provides a simple derivation of the same results, using crisp geometrical intuition and no more than linear algebra. Much less is known about multi-point geometry under perspective projection with uncalibrated cameras, and this gap is filled by our paper.
Reference: [14] <author> S. Ullman and R. Basri. </author> <title> Recognition by linear combinations of models. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13 </volume> <pages> 992-1006, </pages> <year> 1991. </year>
Reference-contexts: We made the distinction above between algorithms that compute camera geometry first and shape next, and algorithms that compute shape first and camera geometry next. Under the weak perspective projection, the distinction does not have to be that sharp. In [12] (see also <ref> [14, 15] </ref>), Tomasi & Kanade described a factorization method for the weak perspective projection model, where the data is linearly divided into shape components and camera geometry components.
Reference: [15] <author> D. Weinshall. </author> <title> Model-based invariants for 3D vision. </title> <journal> International Journal of Computer Vision, </journal> <volume> 10(1) </volume> <pages> 27-42, </pages> <year> 1993. </year>
Reference-contexts: The computed shape descriptions are sufficient for the identification of novel images of the same object. Moreover, the description provides a natural index from an image to the database. Thus object recognition applications can directly benefit from these representations. A previous paper <ref> [15] </ref> described the use of such model-based invariant relations between models and images in object recognition, for indexing and database building, assuming the scaled orthographic (weak perspective) projection model. A general description of an algorithm to optmize such indexing schemes can be found in [18]. <p> We made the distinction above between algorithms that compute camera geometry first and shape next, and algorithms that compute shape first and camera geometry next. Under the weak perspective projection, the distinction does not have to be that sharp. In [12] (see also <ref> [14, 15] </ref>), Tomasi & Kanade described a factorization method for the weak perspective projection model, where the data is linearly divided into shape components and camera geometry components. <p> To proceed, we cannot use a global method such as SVD decomposition as proposed in [12]; instead, we can isolate and compute each component separately, as proposed in <ref> [15, 16] </ref>. The algorithms described in this paper, together with the algorithms developed for the multi-camera geometry, allow us to accomplish this goal.
Reference: [16] <author> D. Weinshall and C. Tomasi. </author> <title> Linear and incremental acquisition of invariant shape models from image sequences. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 17(5) </volume> <pages> 512-517, </pages> <year> 1995. </year>
Reference-contexts: To proceed, we cannot use a global method such as SVD decomposition as proposed in [12]; instead, we can isolate and compute each component separately, as proposed in <ref> [15, 16] </ref>. The algorithms described in this paper, together with the algorithms developed for the multi-camera geometry, allow us to accomplish this goal. <p> With k frames and n + 4 points, we get the 2k fi n measurements matrix W whose ji element is x ji for j k, and y (jk)i for k &lt; j 2k (cf. <ref> [12, 16] </ref>). Now if we read W by columns, the i-th column gives us multi-camera geometry 1 ; if we read it by rows, the j-th and (j + k) th rows give us multi-point geometry in a single image. <p> Consider an object with n + 6 points: 1. Choose a subset of 6 "good" points (an algorithm on how to choose good basis points in described in <ref> [16] </ref>). 2. For every additional point M i , i 7: (a) Using Eq. (6), compute the shape vector V7 i of the set of 7 points &lt; 1; 2; 3; 4; 5; 6; 6 + i &gt; using all available frames (but at least 3). 3.
Reference: [17] <author> M. Werman and A. Shashua. </author> <title> Elimination: An approach to the study of 3D-from-2D. </title> <booktitle> In Proceedings of the 1st International Conference on Computer Vision, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: A few 3fi3fi3 tensors represent the camera geometry, and the image measurements appear in the equations in trilinear forms [8, 9, 11, 4]. 4 images: A few 3 fi 3 fi 3 fi 3 tensors represent the camera geometry, and the image measurements appear in the equations in quadrilinear forms <ref> [13, 17, 3] </ref>. [3] provides a simple derivation of the same results, using crisp geometrical intuition and no more than linear algebra. Much less is known about multi-point geometry under perspective projection with uncalibrated cameras, and this gap is filled by our paper.
Reference: [18] <author> M. Werman and D. Weinshall. </author> <title> Complexity of indexing: Efficient and learnable large database indexing. </title> <type> TR 95-7, </type> <institution> Hebrew University, </institution> <year> 1995. </year>
Reference-contexts: A previous paper [15] described the use of such model-based invariant relations between models and images in object recognition, for indexing and database building, assuming the scaled orthographic (weak perspective) projection model. A general description of an algorithm to optmize such indexing schemes can be found in <ref> [18] </ref>. So far we have discussed shape descriptors of a minimal number of points. In Section 3 we show how to enhance the shape computation to include many points simultaneously.
References-found: 18

