URL: ftp://ftp.cs.columbia.edu/reports/reports-1989/cucs-511-89c.ps.gz
Refering-URL: http://www.cs.columbia.edu/~library/1989.html
Root-URL: http://www.cs.columbia.edu
Note: 171 Chapter 5  
Abstract: Empirical Learning Results in POLLYANNA The value of empirical learning is demonstrated by results of testing the theory space search (TSS) component of POLLYANNA. Empirical data shows approximations generated from generic simplifying assumptions to have widely varying levels of accuracy and efficiency. The candidate theory space includes some theories with Pareto optimal combinations of accuracy and efficiency, as well as others that are non-optimal. Empirical learning is thus needed to separate the optimal theories from the non-optimal ones. It works as a filter on the process of generating approximations from generic simplifying assumptions. Empirical tests serve an additional purpose as well. Theory space search collects data that precisely characterizes the tradeoff between accuracy and efficiency among the candidate approximate theories. The tradeoff data can be used to select a theory that best balances the competing objectives of accuracy and efficiency in a manner appropriate to the intended performance context. The feasibility of empirical learning is also addressed by results of testing the theory space search component of POLLYANNA. In order for empirical testing to be feasible, candidate approximate theories must be operationally usable. Candidate hearts theories generated by POLLYANNA are shown to be operationally usable by experimental results from the theory space search (TSS) phase of learning. They run on a real machine producing results that can be compared with training examples. Feasibility also depends on the information and computation costs of empirical testing. Information costs result from the need to supply the system with training examples. Computation costs result from the need to execute candidate theories. Both types of costs grow with the numbers of candidate theories to be tested. Experimental results show that empirical testing in POLLYANNA is limited more by the computation costs of executing candidate theories than by the information costs of obtaining many training examples. POLLYANNA contrasts in this respect with traditional inductive learning systems. The feasibility of empirical learning depends also on the intended performance context, and on the resources available in the context of learning. Measurements from the theory space search phase indicate that TSS algorithms performing exhaustive search would not be feasible for the hearts domain, although they may be feasible for other applications. TSS algorithms that avoid exhaustive search hold considerably more promise. 
Abstract-found: 1
Intro-found: 1
Reference: [Andrews 83] <author> Andrews, J., D. </author> <title> Win at Hearts. </title> <publisher> Dover Publications, </publisher> <address> New York, New York, </address> <year> 1983. </year>
Reference: [Angluin and Smith 83] <author> Angluin, D. and Smith, C. H. </author> <title> ``Inductive Inference: Theory and Methods.'' </title> <journal> Computing Surveys 15, </journal> <volume> 3, </volume> <year> 1983, </year> <pages> pp. 237 - 269. </pages>
Reference: [Balzer et al. 76] <author> Balzer, R. N., Goldman, and Wile, D. </author> <title> On the Transformational Implementation Approach to Programming. </title> <booktitle> Proceedings of the 2nd International Conference on Software Engineering, IEEE, </booktitle> <year> 1976, </year> <pages> pp. 337-343". </pages>
Reference: [Barstow 85] <author> Barstow, D., R. </author> <title> ``Domain Specific Automatic Programming.'' </title> <journal> IEEE Transactions on Software Engineering 11, </journal> <volume> 11, </volume> <year> 1985, </year> <pages> pp. 1321 - 1336. </pages>
Reference: [Bennett 87] <author> Bennett, S. W. </author> <title> Approximation in Mathematical Domains. </title> <booktitle> Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1987. </year>
Reference: [Bennett 89] <author> Bennett, S. W. </author> <title> Learning Uncertainty Tolerant Plans Through Approximation in Complex Domains. </title> <type> Technical Report UILU-ENG-89-2204, </type> <institution> University of Illinois, Beckman Institute for Advanced Science and Technology, Urbana-Champaign, IL, </institution> <year> 1989. </year> <type> Masters Thesis. </type>
Reference: [Berliner and Ebeling 89] <author> Berliner, H. and Ebeling, C. </author> <title> ``Pattern Knowledge and Search: The SUPREM Architecture.'' </title> <journal> Artificial Intelligence 38, </journal> <volume> 2, </volume> <year> 1989, </year> <pages> pp. 161 - 198. </pages>
Reference: [Bird 80] <author> Bird, R. </author> <title> ``Tabulation Techniques for Recursive Programs.'' </title> <journal> Computing Surveys 12, </journal> <volume> 4, </volume> <year> 1980, </year> <pages> pp. 403 - 413. </pages>
Reference: [Bobrow 85] <author> Bobrow, D. G., Ed. </author> <title> Qualitative Reasoning about Physical Systems. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1985. </year> <note> Also found in Artificial Intelligence, Volume 24. </note>
Reference-contexts: Abstraction is a truth-preserving process. The abstract theory says less, but speaks just as correctly as the original theory. Abstraction sacrifices scope or precision to gain efficiency, just as approximation sacrifices accuracy to gain efficiency in return. Abstraction techniques are widely used in qualitative reasoning about physical systems <ref> [Bobrow 85] </ref>. For example, one qualitative reasoning technique involves replacing quantitative differential equations with qualitative ones [de Kleer and Brown 85]. The behavior of a system is then simulated using the qualitative model.
Reference: [Burstall and Darlington 77] <author> R. M. Burstall and J. Darlington. </author> <title> ``A transformational system for developing recursive programs.'' </title> <journal> Journal of the ACM 24, </journal> <volume> 1, </volume> <month> January </month> <year> 1977, </year> <pages> pp. 44-67. </pages>
Reference: [Carbonell 86] <author> Carbonell, J. G. </author> <title> Derivational Analogy: A Theory of Reconstructive Problem Solving and Expertise Acquisition. </title> <editor> In R. S. Michalski, J. G. Carbonell and T. M. Mitchell, Ed., </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, Volume II, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1986, </year> <pages> pp. 371 - 392. </pages>
Reference: [Cardelli 85] <author> Luca Cardelli and Peter Wegner. </author> <title> ``On Understanding Types, Data Abstraction, and Polymorphism.'' </title> <journal> ACM Computing Surveys 17, </journal> <volume> 4, </volume> <month> December </month> <year> 1985, </year> <pages> pp. 471-522. </pages>
Reference: [Chase et al. 89] <author> Chase, M., Zweben, M., Piazza, R., Burger, J., Maglio, P., Hirsh, H. </author> <title> Approximating Learned Search Control Knowledge. </title> <booktitle> Proceedings of the Sixth International Conference on Machine Learning, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference: [Chien 87] <author> Chien, S. A. </author> <title> Extending Explanation-Based Learning: Failure-Driven Schema Refinement. </title> <type> Technical Report UILU-ENG-87-2203, </type> <institution> University of Illinois, Coordinated Science Laboratory, Urbana-Champaign, IL, </institution> <year> 1987. </year>
Reference: [Chien 89] <author> Chien, S. A. </author> <title> Using and Refining Simplifications: Explanation-Based Learning of Plans in Intractable Domains. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference: [Cohen and Feigenbaum 82] <editor> Cohen, P. R. and Feigenbaum, E. A. (Eds.). </editor> <booktitle> The Handbook of Artificial Intelligence, </booktitle> <volume> Volume 3. </volume> <publisher> William Kaufmann, Inc., </publisher> <address> Los Altos, CA, </address> <year> 1982. </year>
Reference: [Danyluk 89] <author> Danyluk, A. P. </author> <title> A Survey of Machine Learning Systems Integrating Explanation-Based and Similarity-Based Methods. </title> <type> Technical Report CUCS-467-89, </type> <institution> Columbia University Department of Computer Science, </institution> <year> 1989. </year>
Reference: [Davis and Patterson 75] <author> Davis, E. and Patterson, J. </author> <title> ``A Comparison of Heuristic and Optimal Solutions in Resource Constrained Project Scheduling.'' </title> <journal> AI Magazine 21, </journal> <volume> 8, </volume> <year> 1975, </year> <pages> pp. </pages> <note> 944 - 955. </note> <author> 240 [de Kleer and Brown 85] de Kleer, J. and Brown J. </author> <title> A Qualitative Physics Based on Confluences. </title> <editor> In Bobrow, D. G., Ed., </editor> <title> Qualitative Reasoning about Physical Systems, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1985, </year> <pages> pp. </pages> <note> 7 - 83. Also found in Artificial Intelligence, Volume 24. </note>
Reference: [DeJong and Mooney 86] <author> DeJong, G. and Mooney, R. </author> <title> ``Explanation-Based Learning: An Alternative View.'' </title> <journal> Machine Learning 1, </journal> <volume> 2, </volume> <year> 1986, </year> <pages> pp. 145 - 176. </pages>
Reference: [Dietterich 86] <author> Dietterich, T. G. </author> <title> ``Learning at the Knowledge Level.'' </title> <journal> Machine Learning 1, </journal> <volume> 3, </volume> <year> 1986, </year> <pages> pp. 287 - 315. </pages>
Reference-contexts: Two definitions of knowledge level learning are considered. The standard one (KLL) says simply that knowledge level learning occurs whenever there is a change in the deductive closure of a system's knowledge base <ref> [Dietterich 86] </ref>. Standard knowledge level learning occurs across all three state transitions. An alternative definition (TKLL) accounts for the difference between changes that improve accuracy and those that degrade accuracy [Subramanian and Smith 88].
Reference: [Dietterich and Bennett 88] <author> Dietterich, T. G. and Bennett, J. S. </author> <title> Varieties of Operationality. </title> <type> Technical Report 88-30-6, </type> <institution> Department of Computer Science, Oregon State University, Corvallis, Oregon, </institution> <year> 1988. </year>
Reference: [Doyle 79] <author> Doyle, J. </author> <title> ``A Truth Maintenance System.'' </title> <booktitle> Artificial Intelligence 12, </booktitle> <year> 1979, </year> <pages> pp. 231 - 272. </pages>
Reference-contexts: Truth Maintenance Techniques A truth-maintenance mechanism could be used to reduce the computational expense of empirical testing. Truth maintenance systems are generally useful for determining which inferences remain valid when one assumption is replaced by another <ref> [Doyle 79] </ref>. In the context of POLLYANNA, truth-maintenance methods would determine whether the results of some computations are unchanged when one candidate theory is refined into another. For example, suppose the system has already tested theory t against a set E of training examples.
Reference: [Doyle 88] <author> Doyle, R. </author> <title> Hypothesizing Device Mechanisms: Opening Up the Black Box. </title> <type> Technical Report 1047, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <address> Cambridge, MA, </address> <year> 1988. </year> <type> PhD Thesis. </type>
Reference: [Ellman 87] <author> Ellman, T. P. </author> <title> Explanation-Based Methods for Simplifying Intractable Theories: A Thesis Proposal. </title> <type> Technical Report CUCS-265-87, </type> <institution> Columbia University, </institution> <address> New York, NY, </address> <year> 1987. </year>
Reference: [Ellman 88] <author> Ellman, T. </author> <title> Approximate Theory Formation: An Explanation-Based Approach. </title> <booktitle> Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference: [Ellman 89a] <author> Ellman, T. </author> <title> ``Explanation-Based Learning: A Survey of Programs and Perspectives.'' </title> <journal> Computing Surveys 21, </journal> <volume> 2, </volume> <month> June </month> <year> 1989, </year> <pages> pp. 163 - 221. </pages>
Reference: [Ellman 89b] <author> Ellman, T. P. </author> <title> Mechanical Generation of Heuristics for Intractable Theories. </title> <type> Technical Report CUCS-400-88, </type> <institution> Columbia University, </institution> <address> New York, NY, </address> <year> 1989. </year>
Reference: [Ellman 89c] <author> Ellman, T. </author> <title> Mechanical Generation of Heuristic Theories: Trading Accuracy for Efficiency. </title> <booktitle> Proceedings of the AAAI Spring Symposium on AI and Limited Rationality, </booktitle> <year> 1989. </year>
Reference: [Fikes et al. 72] <author> Fikes, R. E., Hart, P. E., and Nilsson, N. J. </author> <title> ``Learning and Executing Generalized Robot Plans.'' </title> <booktitle> Artificial Intelligence 3, </booktitle> <year> 1972, </year> <pages> pp. 251 - 288. </pages>
Reference-contexts: Interactions of these sorts appear to be quite widespread. Examples such interactions will be presented below. They provide evidence supporting the generality of the heuristic generation framework H=IT+GSA+R, and the associated paradigm for attacking intractable theory problems. Problem spaces defined by STRIPS operators fit well into the paradigm <ref> [Fikes et al. 72] </ref>. A STRIPS operator is defined by a list boolean expressions defining preconditions of the operator, as well as a list of boolean expressions defining the effects of the operator. Generic simplifying assumptions could be defined to simplify STRIPS problem spaces by ignoring selected preconditions of operators.
Reference: [Flann and Dietterich 86] <author> Flann, N. S. and Dietterich, T. G. </author> <title> Selecting Appropriate Representations for Learning from Examples. </title> <booktitle> Proceedings of the Fifth National Conference on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1986. </year>
Reference-contexts: For example, methods using a declarative knowledge base to generate candidate hypotheses are discussed in [Russell and Grosof 87]. Methods of using tractable fragments of an intractable theory to enrich the representation of instances prior to an empirical learning phase are discussed in <ref> [Flann and Dietterich 86] </ref>. Such systems might be usefully evaluated in terms of cost effectiveness, i.e., the rate and quality of learning versus the difficulty of engineering an appropriate initial domain theory. Additional research is needed to determine the cost effectiveness of each approach. 6.7.
Reference: [Fox et al. 89] <author> Fox, M., Sadeh, N. and Baykan, C. </author> <title> Constrained Heuristic Search. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference: [Garey and Johnson 79] <author> Garey, M. R. and Johnson, D. S. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, New York, </address> <year> 1979. </year>
Reference: [Gaschnig 79] <author> Gaschnig, J. </author> <title> A Problem Similarity Approach to Devising Heuristics: First Results. </title> <booktitle> Proceedings of the Sixth International Joint Conference on Artificial Intelligence, </booktitle> <year> 1979. </year>
Reference: [Gibson 74] <author> Gibson, W. B. </author> <title> Hoyle's Modern Encyclopedia of Card Games. </title> <publisher> Doubleday and Company., </publisher> <address> Garden City, NY, </address> <year> 1974. </year>
Reference: [Guida and Somalvico 79] <author> Guida, G. and Somalvico, M. </author> <title> ``A Method for Computing Heuristics in Problem Solving.'' </title> <journal> Information Sciences 19, </journal> <volume> 1, </volume> <year> 1979, </year> <pages> pp. 251 - 259. </pages>
Reference: [Gupta 87] <author> Gupta, A. </author> <title> Explanation-Based Failure Recovery. </title> <booktitle> Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1987. </year>
Reference: [Hammond et al. 88] <author> Hammond, K., Converse, T. and Marks, M. </author> <title> Learning from Opportunities: Storing and Re-using Execution-Time Optimizations. </title> <booktitle> Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year> <month> 241 </month>
Reference: [Jaynes 83a] <author> Jaynes, E. T. </author> <title> Where do We Stand on Maximum Entropy? In R. </title> <editor> D. Rosenkrantz, Ed., E. T. Jaynes: </editor> <booktitle> Papers on Probability, Statistics and Statistical Physics, </booktitle> <address> D. </address> <publisher> Reidel Publishing Company, </publisher> <address> Boston, Massachusetts, </address> <year> 1983, </year> <pages> pp. 210 - 314. </pages>
Reference-contexts: The generic simplifying assumption Equiprobable Random Variables (EP) is the workhorse of the approximation generator. Assumptions of this type correspond to Bernoulli's Principle of Insufficient Reason. (See Section 2.5.2.) Bernoulli's principle has received attention in a variety of contexts, most notably in Bayesian decision theory <ref> [Jaynes 83a] </ref>. The informal principle is easy to state. Implementation of the principle is unfortunately not so straightforward.
Reference: [Jaynes 83b] <author> Jaynes, E. T. </author> <title> Information Theory and Statistical Mechanics. </title> <editor> In R. D. Rosenkrantz, Ed., E. T. Jaynes: </editor> <booktitle> Papers on Probability, Statistics and Statistical Physics, </booktitle> <address> D. </address> <publisher> Reidel Publishing Company, </publisher> <address> Boston, Massachusetts, </address> <year> 1983, </year> <pages> pp. 8 - 18. </pages>
Reference: [Jaynes 83c] <author> Jaynes, E. T. </author> <title> Prior Probabilities. </title> <editor> In R. D. Rosenkrantz, Ed., E. T. Jaynes: </editor> <booktitle> Papers on Probability, Statistics and Statistical Physics, </booktitle> <address> D. </address> <publisher> Reidel Publishing Company, </publisher> <address> Boston, Massachusetts, </address> <year> 1983, </year> <pages> pp. 114 - 130. </pages>
Reference: [Keller 83] <author> Keller, R. M. </author> <title> Learning by Re-expressing Concepts for Efficient Recognition. </title> <booktitle> Proceedings of the National Conference on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1983, </year> <pages> pp. 182-186. </pages>
Reference-contexts: An approximate concept description space could be partially ordered according to relations of concept inclusion. Initial efforts in this direction are presented in <ref> [Keller 83] </ref>, which described several operations for transforming one concept description into another. The operations are classified according to the type of error they introduce. Operations can be concept generalizing, concept specializing or concept preserving.
Reference: [Keller 87] <author> Keller, R. M. </author> <title> The Role of Explicit Contextual Knowledge in Learning Concepts to Improve Performance. </title> <type> Technical Report ML-TR-7, </type> <institution> Department of Computer Science, Rutgers University, </institution> <address> New Brunswick, NJ, </address> <year> 1987. </year> <type> PhD Thesis. </type>
Reference-contexts: In the absence of such analytic techniques, a search control mechanism might assume decomposability to estimate the impact of refinements prior to actual empirical testing. A similar control technique was used in Keller's MetaLEX system <ref> [Keller 87] </ref>. 189 5.3.7. Univariate Analysis of Accuracy and Efficiency 5.3.7.1. Comparison of Accuracy Measures Empirical data was collected to test the relationship between the two types of training examples described in choices, and the measure E is used when the examples specify only one optimal choice. <p> Use of Enriched Training Examples A sufficiently cooperative teacher might be able to supply training examples that are more informative than those defined in Figure 4-21. In order to illustrate the value of such enriched examples, it helps to make a distinction between "global" and "local" training information <ref> [Keller 87] </ref>. Global training information includes only the final answer of a computation. The information is considered "global" it gives only the final answer, without providing any information about the rationale behind the final answer.
Reference: [Keller 88] <author> Keller, R. M. </author> <title> ``Defining Operationality for Explanation-Based Learning.'' </title> <booktitle> Artificial Intelligence 35, </booktitle> <year> 1988, </year> <pages> pp. 227 - 241. </pages>
Reference: [Kibler 85] <author> Kibler, D. </author> <title> Natural Generation of Heuristics by Transforming the the Problem Representation. </title> <type> Technical Report TR-85-20, </type> <institution> University of California, </institution> <address> Irvine, CA, </address> <year> 1985. </year>
Reference: [Knoblock 89] <author> Knoblock, C. </author> <title> Learning Hierarchies of Abstraction Spaces. </title> <booktitle> Proceedings of the Sixth International Conference on Machine Learning, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference: [Korf 87] <author> Korf, R. E. </author> <title> ``Planning as Search: A Quantitative Approach.'' </title> <journal> Artificial Intelligence 33, </journal> <volume> 1, </volume> <year> 1987, </year> <pages> pp. 65 - 88. </pages>
Reference: [Kronsjo 79] <author> Kronsjo, </author> <title> Lydia Algorithms: Their Complexity and Efficiency. </title> <publisher> John, Wiley and Sons, </publisher> <address> New York, New York, </address> <year> 1979. </year>
Reference: [Kuhn 70] <author> Kuhn, T. </author> <title> The Structure of Scientific Revolutions. </title> <publisher> The University of Chicago Press, </publisher> <address> Chicago, IL, </address> <year> 1970. </year>
Reference: [Laird et al. 86] <author> Laird, J. E., Rosenbloom, P. S. and Newell, A. </author> <title> ``Chunking in SOAR: The Anatomy of a General Learning Mechanism.'' </title> <journal> Machine Learning 1, </journal> <volume> 1, </volume> <year> 1986, </year> <pages> pp. 11 - 46. </pages>
Reference: [Laird, et al. 87] <author> Laird, J. E., Newell, A. and Rosenbloom, P. S. </author> <title> ``SOAR: Architecture for General Intelligence.'' </title> <booktitle> Artificial Intelligence 33, </booktitle> <year> 1987, </year> <pages> pp. 1 - 64. </pages>
Reference: [Langley 88] <author> Langley, P. </author> <title> ``Machine Learning as an Experimental Science.'' </title> <journal> Machine Learning 3, </journal> <volume> 1, </volume> <year> 1988, </year> <pages> pp. 5-8. </pages>
Reference-contexts: Learning Curves for POLLYANNA A more quantitative measure of learning results from an incremental view of the empirical phase. If POLLYANNA really learns something by processing training examples, the results ought to improve with the size of the training set. Such improvement can be demonstrated with learning curves <ref> [Langley 88] </ref>. Given some arbitrary measure of performance, a learning curve shows how the measured performance depends on the number of examples. In most empirical learning systems, performance is measured in terms of accuracy. In most analytic learning systems, performance is measured in terms of efficiency.
Reference: [Lebowitz 83] <author> Lebowitz, M. </author> <title> ``Generalization from Natural Language Text.'' </title> <journal> Cognitive Science 7, </journal> <volume> 1, </volume> <year> 1983, </year> <pages> pp. 1 - 40. </pages>
Reference: [Lewis and Papadimitriou 81] <author> Lewis, H. R. and Papadimitriou, C. H. </author> <title> Elements of the Theory of Computation. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1981. </year>
Reference: [Luce and Raiffa 57] <author> Luce, R. D. and Raiffa, H. </author> <title> Games and Decisions. </title> <publisher> John Wiley and Sons, </publisher> <address> New York, NY, </address> <year> 1957. </year>
Reference: [Michalski 80] <author> Michalski, R. S. </author> <title> ``Pattern Recognition as Rule-Guided Inductive Inference.'' </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence 2, </journal> <volume> 4, </volume> <year> 1980, </year> <pages> pp. 349 - 361. </pages>
Reference: [Michalski 83] <author> Michalski, R. S. </author> <title> ``A Theory and Methodology of Inductive Learning.'' </title> <booktitle> Artificial Intelligence 20, </booktitle> <year> 1983, </year> <pages> pp. 111 - 161. </pages>
Reference: [Michalski et al. 83] <author> Michalski, R. S., Carbonell, J. G. and Mitchell, T. M., eds. </author> <title> Machine Learning, An Artificial Intelligence Approach. </title> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1983. </year> <month> 242 </month>
Reference: [Minton 88] <author> Minton, S. </author> <title> Learning Effective Search Control Knowledge: An Explanation-Based Approach. </title> <type> Technical Report CMU-CS-88-133, </type> <institution> Department of Computer Science, Carnegie-Mellon University , Pittsburgh, </institution> <address> PA, </address> <year> 1988. </year> <type> PhD Thesis. </type>
Reference: [Mitchell 80] <author> Mitchell, T. M. </author> <title> The Need for Biases in Learning Generalizations. </title> <type> Technical Report CBM-TR-117, </type> <institution> Department of Computer Science, Rutgers University, </institution> <address> New Brunswick, NJ, </address> <year> 1980. </year>
Reference-contexts: The curves could then be compared to those that result from using the large hearts theory space. Such a test is not actually necessary. The results can be predicted in advance. Unbiased learning algorithms can do no better than learning by rote <ref> [Mitchell 80] </ref>. When faced with a test example, an unbiased learner can answer correctly if the same example appears in the test set. Otherwise it must make a random guess on the test example. <p> Such systems learn effectively to the extent that the hypothesis space is biased to suit the domain under study <ref> [Mitchell 80] </ref>. Such programs are unfortunately rather rigid. They may work well in one domain, only to fall apart upon encountering a domain for which the hypothesis space is not well suited. POLLYANNA potentially avoids rigidity by generating a candidate hypothesis space that depends on the domain under study.
Reference: [Mitchell 82] <author> Mitchell, T. M. </author> <title> ``Generalization as Search.'' </title> <booktitle> Artificial Intelligence 18, </booktitle> <year> 1982, </year> <pages> pp. 203 - 226. </pages>
Reference-contexts: For example, the candidate elimination algorithms described in <ref> [Mitchell 82] </ref> search through a version space of concept descriptions organized according to the generalization-of and specialization-of relations. When an algorithm replaces one candidate concept c with a more specialized concept c , it need not examine all previously considered 1 2 examples. <p> The results of reprocessing all other examples can be predicted from the 1 2 fact that c is a specialization of c . The incremental methods described in <ref> [Mitchell 82] </ref> thus depend on organizing 2 1 the hypothesis space to reflect semantic relationships among theories. Theory spaces monotonic in efficiency are particularly ill-suited to exploiting incremental processing of examples. <p> The operations are classified according to the type of error they introduce. Operations can be concept generalizing, concept specializing or concept preserving. If an approximate theory space is generated by these operations, incremental methods described in <ref> [Mitchell 82] </ref> could be used to avoid reprocessing examples when moving from one theory to another. 5.6.8. Starting at the Initial Intractable Theory The search algorithms described above all commence search at the most efficient theory, i.e., the theory space root. <p> Traditional Inductive Learning Traditional inductive learning programs can also be compared to POLLYANNA. (See Conjecture #1 in Section 1.6.7.) Consider the case of a program that learns by selecting a member of a fixed space of candidate hypotheses <ref> [Mitchell 82] </ref>. Such systems learn effectively to the extent that the hypothesis space is biased to suit the domain under study [Mitchell 80]. Such programs are unfortunately rather rigid.
Reference: [Mitchell 83] <author> Mitchell, T. M. </author> <title> Learning and Problem Solving. </title> <booktitle> Proceedings of the Eighth International Joint Conference on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1983. </year>
Reference: [Mitchell et al. 86] <author> Mitchell, T. M., Keller, R. M. and Kedar-Cabelli, S. T. </author> <title> ``Explanation-Based Learning: A Unifying View.'' </title> <journal> Machine Learning 1, </journal> <volume> 1, </volume> <year> 1986, </year> <pages> pp. 47 - 80. </pages>
Reference: [Mohan and Tong 89] <author> Mohan, S. and Tong. C. </author> <title> Automatic Construction of a Hierarchical Generate and Test Algorithm. </title> <booktitle> Proceedings of the Sixth International Conference on Machine Learning, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference: [Mostow 81] <author> Mostow, D. J. </author> <title> Mechanical Transformation of Task Heuristics into Operational Procedures. </title> <type> Technical Report CMU-CS-81-113, </type> <institution> Carnegie-Mellon University, Department of Computer Science, </institution> <address> Pittsburgh, PA, </address> <year> 1981. </year> <type> PhD Thesis. </type>
Reference: [Mostow 83] <author> Mostow, J. </author> <title> A Problem Solver for Making Advice Operational. </title> <booktitle> Proceedings of the National Conference on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1983, </year> <pages> pp. 279-283. </pages>
Reference: [Mostow 89] <author> Mostow, J. </author> <title> ``Design by Derivational Analogy: Issues in the Automated Replay of Design Plans.'' </title> <booktitle> Artificial Intelligence 40, </booktitle> <year> 1989, </year> <pages> pp. 119 - 184. </pages>
Reference: [Mostow and Cohen 85] <author> Mostow, J. and Cohen, D. </author> <title> Automating Program Speedup by Deciding What to Cache. </title> <booktitle> Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1985. </year>
Reference: [Mostow and Fawcett 87] <author> Mostow, J. and Fawcett, T. </author> <title> Approximating Intractable Theories: A Problem Space Model. </title> <type> Technical Report ML-TR-16, </type> <institution> Rutgers University, Department of Computer Science, </institution> <address> New Brunswick, NJ, </address> <year> 1987. </year>
Reference: [Mostow and Prieditis 89] <author> Mostow, J. and Prieditis, A. E. </author> <title> Discovering Admissible Heuristics by Abstracting and Optimizing. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1989, </year> <pages> pp. 701 - 707. </pages>
Reference-contexts: Such operations would be quite similar to previously studied methods for generating abstraction spaces [Sacerdoti 74; Pearl 84]. Efficiency improving reformulations can be defined for STRIPS problem spaces as well. One such reformulation operates by factorization of subproblems that can be shown not to interact with each other <ref> [Mostow and Prieditis 89] </ref>. Interactions between approximations and reformulations can be observed in the context of STRIPS problem spaces. Subproblem factorization is sometimes possible only after making approximations. Some useful approximations are possible only after applying reformulations that enrich the representation of problem states. <p> Subproblem factorization is sometimes possible only after making approximations. Some useful approximations are possible only after applying reformulations that enrich the representation of problem states. Interactions of both types are present in the work of <ref> [Mostow and Prieditis 89] </ref>. Goal regression is also a standard type of reformulation often applied to STRIPS operator sequences [Nilsson 80]. Possible interactions between goal regression and approximation would be interesting to study. Algebraic and differential equations are also examples of representation formalisms that might fit into the paradigm.
Reference: [Natarajan and Tadepalli 88] <author> Natarajan, B. K. and Tadepalli, P. </author> <title> Two New Frameworks for Learning. </title> <booktitle> Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference: [Newell 82] <author> Newell, A. </author> <title> ``The Knowledge Level.'' </title> <booktitle> Artificial Intelligence 18, </booktitle> <year> 1982, </year> <pages> pp. 87 - 127. </pages>
Reference: [Newell and Simon 72] <author> Newell, A. and Simon, H. </author> <title> Human Problem Solving. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1972. </year>
Reference: [Nilsson 80] <author> Nilsson, N. J. </author> <booktitle> Principles of Artificial Intelligence. </booktitle> <publisher> Tioga Publishing Company, </publisher> <address> Palo Alto, CA, </address> <year> 1980. </year>
Reference-contexts: Some useful approximations are possible only after applying reformulations that enrich the representation of problem states. Interactions of both types are present in the work of [Mostow and Prieditis 89]. Goal regression is also a standard type of reformulation often applied to STRIPS operator sequences <ref> [Nilsson 80] </ref>. Possible interactions between goal regression and approximation would be interesting to study. Algebraic and differential equations are also examples of representation formalisms that might fit into the paradigm. Taylor series expansions are a type of reformulation that often applies usefully to algebraic and differential equations.
Reference: [Papadimitriou and Steiglitz 82] <author> Papadimitriou, C. H. and Steiglitz, K. </author> <title> Combinatorial Optimization: Algorithms and Complexity. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1982. </year>
Reference-contexts: Reformulations useful for solving differential equations include coordinate transformations and separation of variables. Techniques for approximating combinatorial optimization problems might also fit into the paradigm. One 234 approximation technique involves solving a relaxed version of the original optimization problem <ref> [Papadimitriou and Steiglitz 82; Pearl 84] </ref>. Consider the problem of finding the minimal value M of function F (x ,...,x ) over the set s 1 n n SI . A relaxation technique begins by approximating set S with some superset R.
Reference: [Pearl 84] <author> Pearl, J. </author> <title> Heuristics: Intelligent Search Strategies for Computer Problem Solving. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1984. </year>
Reference-contexts: For example, operations similar to Truify and Falsify could assert that certain preconditions will always or never be met. Such operations would be quite similar to previously studied methods for generating abstraction spaces <ref> [Sacerdoti 74; Pearl 84] </ref>. Efficiency improving reformulations can be defined for STRIPS problem spaces as well. One such reformulation operates by factorization of subproblems that can be shown not to interact with each other [Mostow and Prieditis 89]. <p> Reformulations useful for solving differential equations include coordinate transformations and separation of variables. Techniques for approximating combinatorial optimization problems might also fit into the paradigm. One 234 approximation technique involves solving a relaxed version of the original optimization problem <ref> [Papadimitriou and Steiglitz 82; Pearl 84] </ref>. Consider the problem of finding the minimal value M of function F (x ,...,x ) over the set s 1 n n SI . A relaxation technique begins by approximating set S with some superset R.
Reference: [Polya 57] <author> Polya, G. </author> <title> How to Solve it. </title> <publisher> Doubleday Anchor Books, </publisher> <address> New York, NY, </address> <year> 1957. </year>
Reference: [Rajamoney and DeJong 87] <author> Rajamoney, S. and DeJong, G. </author> <title> The Classification, Detection and Handling of Imperfect Theory Problems. </title> <booktitle> Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1987. </year> <month> 243 </month>
Reference: [Ralston and Rabinowitz 78] <author> Ralston, A. and Rabinowitz, P. </author> <title> A First Course in Numerical Analysis. </title> <publisher> McGraw-Hill Book Company, </publisher> <address> New York, New York, </address> <year> 1978. </year>
Reference: [Russell and Grosof 87] <author> Russell, S. J. and Grosof, B. N. </author> <title> A Declarative Approach to Bias in Concept Learning. </title> <booktitle> Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1987. </year>
Reference-contexts: Some alternative approaches to the same task are described in [Russell and Grosof 87; Flann and Dietterich 86; Ellman 89a; Danyluk 89]. For example, methods using a declarative knowledge base to generate candidate hypotheses are discussed in <ref> [Russell and Grosof 87] </ref>. Methods of using tractable fragments of an intractable theory to enrich the representation of instances prior to an empirical learning phase are discussed in [Flann and Dietterich 86].
Reference: [Sacerdoti 74] <author> Sacerdoti, E. D. </author> <title> ``Planning in a Hierarchy of Abstraction Spaces.'' </title> <booktitle> Artificial Intelligence 5, </booktitle> <year> 1974, </year> <pages> pp. 115 - 135. </pages>
Reference-contexts: For example, operations similar to Truify and Falsify could assert that certain preconditions will always or never be met. Such operations would be quite similar to previously studied methods for generating abstraction spaces <ref> [Sacerdoti 74; Pearl 84] </ref>. Efficiency improving reformulations can be defined for STRIPS problem spaces as well. One such reformulation operates by factorization of subproblems that can be shown not to interact with each other [Mostow and Prieditis 89].
Reference: [Savitch, et al. 87] <editor> Savitch, W. J., et al, (Eds.) </editor> <booktitle> The Formal Complexity of Natural Language. </booktitle> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1987. </year>
Reference: [Segre 88] <author> Segre, A. M. </author> <title> Operationality and Real World Plans. </title> <booktitle> Proceedings of the AAAI Spring Symposium on Explanation-Based Learning, AAAI, </booktitle> <year> 1988. </year>
Reference: [Shannon 48] <author> Shannon, C. E. </author> <title> ``A Mathematical Theory of Communication.'' </title> <journal> The Bell System Technical Journal 27, </journal> <volume> 3, </volume> <year> 1948, </year> <pages> pp. 379 - 423. </pages>
Reference: [Smith 88] <author> D. R. Smith. KIDS: </author> <title> A Knowledge-Based Software Development System. </title> <booktitle> Proceedings of the AAAI88 Workshop on Automated Software Design, American Association for Artificial Intelligence, </booktitle> <month> August, </month> <year> 1988. </year>
Reference: [Smith et al. 86] <author> Smith, S., Fox, M. and Ow, P. </author> <title> ``Construction and Maintaining Detailed Production Plans: Investigations into the Development of Knowledge-Based Factory Scheduling Systems.'' </title> <journal> AI Magazine 7, </journal> <volume> 4, </volume> <year> 1986, </year> <pages> pp. 45 - 61. </pages>
Reference: [Stefik and Bobrow 86] <author> Stefik, M. and Bobrow, D. </author> <title> ``Object-Oriented Programming: Themes and Variations.'' </title> <journal> AI Magazine 6, </journal> <volume> 4, </volume> <year> 1986, </year> <pages> pp. 40 - 62. </pages>
Reference: [Stokey 89] <author> Stokey, R. </author> <title> ``AI Factory Scheduling: Multiple Problem Formulations.'' </title> <journal> SIGART Newsletter 1, </journal> <volume> 110, </volume> <month> October </month> <year> 1989, </year> <pages> pp. 27 - 30. </pages>
Reference: [Subramanian and Smith 88] <author> Subramanian, D. and Smith, D. </author> <title> Knowledge Level Learning: An Alternative View. </title> <booktitle> Proceedings of the AAAI Spring Symposium on Explanation-Based Learning, AAAI, </booktitle> <year> 1988. </year>
Reference-contexts: Standard knowledge level learning occurs across all three state transitions. An alternative definition (TKLL) accounts for the difference between changes that improve accuracy and those that degrade accuracy <ref> [Subramanian and Smith 88] </ref>. Truth-theoretic knowledge level learning occurs only if the deductive closure changes, and the knowledge base 51 moves closer to a true model of the world. The knowledge base moves away from a true model across transitions S fiS and S fiS . <p> Both Cost (t) and Error-Rate (t) may be considered properties of candidate theories. Prior to empirical testing, the costs and error rates of candidate theories are unknown. After empirical testing, the system has obtained an estimate of average cost and 51 The definition of TKLL in <ref> [Subramanian and Smith 88] </ref> requires that (a) no true facts be lost and (b) no false facts be added to the knowledge base. In the present analysis this definition is relaxed to use an average measure of accuracy. 195 error rates.
Reference: [Swartout 83] <author> Swartout, W. ``XPLAIN: </author> <title> A System for Creating and Explaining Expert Consulting Systems.'' </title> <booktitle> Artificial Intelligence 21, </booktitle> <year> 1983, </year> <pages> pp. 285 - 325. </pages>
Reference: [Tadepalli 89] <author> Tadepalli, P. </author> <title> Lazy Explanation-Based Learning: A Solution to the Intractable Theory Problem. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference: [Tsotsos 87] <author> Tsotsos, J. K. </author> <title> A 'Complexity Level' Analysis of Vision. </title> <booktitle> Proceedings of the First International Conference on Computer Vision, IEEE Computer Society, </booktitle> <year> 1987. </year>
Reference: [Ullman 82] <author> Ullman, J. D. </author> <title> Principles of Database Systems. </title> <publisher> Computer Science Press, </publisher> <address> Rockville, Maryland, </address> <year> 1982. </year>
Reference: [Unruh and Rosenbloom 89] <author> Unruh, A. and Rosenbloom, P. </author> <title> Abstraction in Problem Solving and Planning. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference: [Utgoff 86] <author> Utgoff, P. E. </author> <title> Shift of Bias for Inductive Concept Learning. </title> <editor> In R. S. Michalski, J. G. Carbonell and T. M. Mitchell, Ed., </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, Volume II, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1986, </year> <pages> pp. 107-148. </pages>
Reference: [Valiant 84] <author> Valiant, L. G. </author> <title> ``A Theory of the Learnable.'' </title> <journal> Communications of the ACM 27, </journal> <year> 1984, </year> <pages> pp. 1134 - 1142. </pages>
Reference: [Winston 72] <author> Winston, P. H. </author> <title> Learning Structural Descriptions From Examples. </title> <editor> In P. H. Winston, Ed., </editor> <booktitle> The Psychology of Computer Vision, </booktitle> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1972. </year> <pages> 244 245 </pages>
References-found: 96

