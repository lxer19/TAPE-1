URL: http://ftp.eecs.umich.edu/people/rundenst/papers/r-96-9.ps.Z
Refering-URL: http://ftp.eecs.umich.edu/people/rundenst/papers/
Root-URL: http://www.eecs.umich.edu
Email: Email: hibino@eecs.umich.edu, rundenst@eecs.umich.edu  
Title: Companion as a formal demonstration summary.] MMVIS: A MultiMedia Visual Information Seeking Environment for Video Analysis  
Author: Stacie Hibino and Elke A. Rundensteiner 
Keyword: Video analysis, dynamic queries, temporal query filters, interactive visualizations, trend discovery.  
Address: 1301 Beal Avenue, Ann Arbor, MI 48109-2122 USA  
Affiliation: EECS Department, Software Systems Research Laboratory The University of Michigan,  
Note: [To appear in CHI96 Conference  
Abstract: Our MultiMedia Visual Information Seeking (MMVIS) environment is designed to support an exploratory approach to video analysis. Specialized subset, temporal, spatial, and motion dynamic query filters are tightly coupled with dynamic, user-customizable relationship visualizations to aid users in the discovery of data trends. Users can select two subsets (e.g., a subset of person P1 talking events) and then browse various relationships between them (e.g., browsing for temporal relationships such as whether events of type A frequently start at the same time as events of type B). The visualization highlights the frequencies of both the subsets and the relationships between them. This allows users to discover various relationships and trends without having to explicitly pre-code them. In this demonstration, we will focus on temporal analysis aspects of the system, presenting our temporal visual query language, temporal visualization, and an application to real CSCW data. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Ahlberg, C., Williamson, C., & Shneiderman, B. </author> <year> (1992). </year> <title> Dynamic Queries for Information Exploration: An Implementation and Evaluation. </title> <booktitle> CHI'92 Conference Proceedings. </booktitle> <publisher> NY:ACM Press, </publisher> <pages> pp. 619-626). </pages>
Reference-contexts: This approach has been shown to aid users in locating information, as well as for searching for trends and exceptions to trendsand to accomplish such tasks more efficiently than through traditional forms-based methods <ref> [1] </ref>. We thus extend the VIS framework to handle multimedia data sets, more specifically to perform video analysis [5].
Reference: 2. <author> Ahlberg, C., & Shneiderman, B. </author> <year> (1994). </year> <title> Visual Information Seeking: Tight Coupling of Dynamic Query Filters with Starfield Displays. C H I ' 9 4 Conference Proceedings. </title> <publisher> NY:ACM Press, </publisher> <pages> pp. 619-626. </pages>
Reference-contexts: INTRODUCTION Visual Information Seeking (VIS) is a framework for information exploration where users filter data through direct manipulation of dynamic query filters <ref> [2] </ref>. A visualization of the results is dynamically updated as users adjust a query filter, thus allowing them to incrementally specify and refine their queries. In this way, users also see the direct correlation between adjusting parameter values and the corresponding changes in the visualization of results.
Reference: 3. <author> Fishkin, K. and Stone, M.C. </author> <year> (1995). </year> <title> Enhanced Dynamic Queries via Movable Filters. </title> <booktitle> C H I ' 9 5 Conference Proceedings, </booktitle> <pages> 415-420. </pages> <publisher> ACM Press. </publisher>
Reference-contexts: The novel approach to video analysis presented in MMVIS empowers users to explore the data in search of trends and exceptions to trends. Other extensions to VIS have been done <ref> [3] </ref>, but they do not address the spatio-temporal and relative exploratory needs of video analysis. MMVIS introduces some new extensions to VISthe use of specialized temporal query filters and spatio-temporal visualizations, tailored to highlight the strengths of relationships between different types of subsets.
Reference: 4. <author> Harrison, B.L., Owen, R., & Baecker, R.M. </author> <year> (1994). </year> <title> Timelines: An Interactive System for the Collection of Visualization of Temporal Data. </title> <booktitle> Proc. of Graphics Interface '94. Canadian Information Processing Society. </booktitle>
Reference-contexts: This could be done simply by moving the right thumb to zero. COMPARISON TO SIMILAR SYSTEMS Although several video annotation and analysis systems have been developed, they have focused on novel approaches to video annotation, timeline-based formats for video analysis, or pre-coding relationships rather than searching for them <ref> [7, 4] </ref>. The novel approach to video analysis presented in MMVIS empowers users to explore the data in search of trends and exceptions to trends. Other extensions to VIS have been done [3], but they do not address the spatio-temporal and relative exploratory needs of video analysis.
Reference: 5. <author> Hibino, S. & Rundensteiner, E. </author> <title> (in press). A Visual Query Language for Temporal Analysis of Video Data. The Design and Implementation of Multimedia Database Systems (K. </title> <editor> Nwosu, Ed.), </editor> <address> NY: </address> <publisher> Kluwer Books. </publisher>
Reference-contexts: We thus extend the VIS framework to handle multimedia data sets, more specifically to perform video analysis <ref> [5] </ref>. Our extensions give users the power to explore various relationships between different types of video events, in a way that was not previously possible through other traditional means (e.g., timelines for temporal analysis, statistically based approaches, etc.) [6]. <p> Exploring Relationships Between Event Subsets Once users have selected subsets, they can then explore various relationships between members of these subsets using the specialized relationship query filters. Our temporal query filters, forming a temporal visual query language (TVQL) <ref> [5] </ref>, are presented to the user on a single palette (see Figure 1, Temporal Query palette). TVQL can be used to specify any one of thirteen temporal primitives (e.g., before, meets, equals) as well as combinations of such primitives.
Reference: 6. <author> Hibino, S. & Rundensteiner, E. </author> <year> (1995). </year> <title> Interactive Visualizations for Temporal Analysis: Application to CSCW Multimedia Data. </title> <type> UM Tech. </type> <institution> Rep.#CSE-272-95. </institution>
Reference-contexts: Our extensions give users the power to explore various relationships between different types of video events, in a way that was not previously possible through other traditional means (e.g., timelines for temporal analysis, statistically based approaches, etc.) <ref> [6] </ref>. <p> Vertical bars along the side of the lists indicate the last action taken and its impact on the values of other parameters. In Figure 1, the Subset A query palette selects all Activity (Talking & NonVerbal) types of events while Subset B selects all design rationales <ref> [6] </ref>. Yellow transparent circles are displayed in the visualization to highlight the corresponding A events, as the user de/selects values from each parameter list. Similarly, blue transparent squares indicate B events.
Reference: 7. <author> Roschelle, J., Pea, R., & Trigg, R. </author> <year> (1990). </year> <title> VIDEONOTER: A tool for exploratory analysis (Research Rep. No. </title> <address> IRL90-0021). Palo Alto, CA: </address> <booktitle> Institute for Research on Learning. </booktitle>
Reference-contexts: This could be done simply by moving the right thumb to zero. COMPARISON TO SIMILAR SYSTEMS Although several video annotation and analysis systems have been developed, they have focused on novel approaches to video annotation, timeline-based formats for video analysis, or pre-coding relationships rather than searching for them <ref> [7, 4] </ref>. The novel approach to video analysis presented in MMVIS empowers users to explore the data in search of trends and exceptions to trends. Other extensions to VIS have been done [3], but they do not address the spatio-temporal and relative exploratory needs of video analysis.
References-found: 7

