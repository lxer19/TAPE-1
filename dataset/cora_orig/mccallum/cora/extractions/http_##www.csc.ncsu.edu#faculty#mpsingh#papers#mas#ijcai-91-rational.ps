URL: http://www.csc.ncsu.edu/faculty/mpsingh/papers/mas/ijcai-91-rational.ps
Refering-URL: http://www.csc.ncsu.edu/faculty/mpsingh/papers/mas/
Root-URL: http://www.csc.ncsu.edu
Email: msingh@cs.utexas.edu  
Title: Workshop on Theoretical and Practical Design of Rational Agents, 1991 On the Commitments and Precommitments
Author: Munindar P. Singh 
Address: Austin, TX 78712 USA  Postfach 2080 D-6750 Kaiserslautern Germany  
Affiliation: Center for Cognitive Science and Dept of Computer Sciences University of Texas  and DFKI (German Research Center for AI)  Center for Cognitive Science, University of Texas at Austin)  
Note: In Proceedings of the International Joint Conference on Artificial Intelligence  This research was supported by the National Science Foundation (through grant IRI-8945845 to the  and by the DFKI.  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [ Bratman, 1987 ] <author> Bratman, Michael E.; </author> <year> 1987. </year> <title> Intention, Plans, and Practical Reason. </title> <publisher> Har-vard University Press, </publisher> <address> Cambridge, MA. </address> <month> 10 </month>
Reference-contexts: Perhaps the salient property of future-directed intentions is that they involve commitment on the part of agents. This view has been gaining ground in the philosophical and AI literatures recently <ref> [ Bratman, 1987, ch. 2 ] </ref> [ Harman, 1986, p. 94 ] [ Cohen & Levesque, 1990, p. 217 ] . <p> This is important from a philosophical point of view because it allows an agent's intentional state now to influence his actions later, in a way that the behavioristically minded philosophers of yore would have found unacceptable <ref> [ Bratman, 1987, p. 6 ] </ref> . When conceived of as involving commitments, future-directed intentions allow an agent to coordinate his activities, both with his other activities, and with those of other agents.
Reference: [ Cohen & Levesque, 1990 ] <author> Cohen, Philip R. and Levesque, Hector J.; </author> <year> 1990. </year> <title> Intention is choice with commitment. </title> <booktitle> Artificial Intelligence 42 </booktitle> <pages> 213-261. </pages>
Reference-contexts: Perhaps the salient property of future-directed intentions is that they involve commitment on the part of agents. This view has been gaining ground in the philosophical and AI literatures recently [ Bratman, 1987, ch. 2 ] [ Harman, 1986, p. 94 ] <ref> [ Cohen & Levesque, 1990, p. 217 ] </ref> .
Reference: [ Dennett, 1987 ] <author> Dennett, Daniel C.; </author> <year> 1987. </year> <title> The Intentional Stance. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: It provides a powerful abstraction with which to view intelligent agents, independent of their internal architecture and with minimal knowledge about them. Dennett sees the attribution of rationality as the central step in adopting the intentional stance <ref> [ Dennett, 1987 ] </ref> . While agents who are sufficiently autonomous may act in any way they please, with rational agents you have a pretty good idea of how they will proceed, if you know what situation they are in.
Reference: [ Georgeff, 1987 ] <author> Georgeff, Michael P.; </author> <year> 1987. </year> <title> Planning. </title> <editor> In Traub, J. F., editor, </editor> <booktitle> Annual Review of Computer Science, </booktitle> <volume> Vol 2. </volume> <publisher> Annual Reviews Inc., </publisher> <address> Palo Alto, CA. </address>
Reference-contexts: Intentions, along with beliefs and desires, are an important component of the folk psychological concepts of intelligence and agency, especially as these concepts are used in AI. Specifically, intentions and reasoning about intentions are a crucial part of many important subareas of AI|e.g., planning <ref> [ Georgeff, 1987; McDermott, 1982 ] </ref> , plan recognition [ Pollack, 1986 ] , natural language understanding [ Grosz & Sidner, 1990 ] and multiagent systems [ S-ingh, 1991c ] . Perhaps the salient property of future-directed intentions is that they involve commitment on the part of agents.
Reference: [ Grosz & Sidner, 1990 ] <author> Grosz, Barbara and Sidner, </author> <title> Candace; 1990. Plans for discourse. </title> <editor> In Cohen, P.; Morgan, J.; and Pollack, M., editors, </editor> <title> SDF Benchmark Series: Intentions in Communication. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: Specifically, intentions and reasoning about intentions are a crucial part of many important subareas of AI|e.g., planning [ Georgeff, 1987; McDermott, 1982 ] , plan recognition [ Pollack, 1986 ] , natural language understanding <ref> [ Grosz & Sidner, 1990 ] </ref> and multiagent systems [ S-ingh, 1991c ] . Perhaps the salient property of future-directed intentions is that they involve commitment on the part of agents.
Reference: [ Harman, 1986 ] <author> Harman, </author> <title> Gilbert; 1986. Change in View. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: Perhaps the salient property of future-directed intentions is that they involve commitment on the part of agents. This view has been gaining ground in the philosophical and AI literatures recently [ Bratman, 1987, ch. 2 ] <ref> [ Harman, 1986, p. 94 ] </ref> [ Cohen & Levesque, 1990, p. 217 ] .
Reference: [ McDermott, 1982 ] <author> McDermott, </author> <title> Drew; 1982. A temporal logic for reasoning about processes and plans. </title> <booktitle> Cognitive Science 6(2) </booktitle> <pages> 101-155. </pages>
Reference-contexts: Intentions, along with beliefs and desires, are an important component of the folk psychological concepts of intelligence and agency, especially as these concepts are used in AI. Specifically, intentions and reasoning about intentions are a crucial part of many important subareas of AI|e.g., planning <ref> [ Georgeff, 1987; McDermott, 1982 ] </ref> , plan recognition [ Pollack, 1986 ] , natural language understanding [ Grosz & Sidner, 1990 ] and multiagent systems [ S-ingh, 1991c ] . Perhaps the salient property of future-directed intentions is that they involve commitment on the part of agents.
Reference: [ Pollack, 1986 ] <author> Pollack, Martha E.; </author> <year> 1986. </year> <title> Inferring Domain Plans in Question Answering. </title> <type> Ph.D. Dissertation, </type> <institution> University of Pennsylvania. </institution>
Reference-contexts: Specifically, intentions and reasoning about intentions are a crucial part of many important subareas of AI|e.g., planning [ Georgeff, 1987; McDermott, 1982 ] , plan recognition <ref> [ Pollack, 1986 ] </ref> , natural language understanding [ Grosz & Sidner, 1990 ] and multiagent systems [ S-ingh, 1991c ] . Perhaps the salient property of future-directed intentions is that they involve commitment on the part of agents.
Reference: [ Singh & Asher, 1990 ] <author> Singh, Munindar P. and Asher, Nicholas M.; </author> <year> 1990. </year> <title> Towards a formal theory of intentions. </title> <booktitle> In European Workshop on Logics in Artificial Intelligence. </booktitle>
Reference-contexts: This model is quite abstract, is derived from models for dynamic and branching time temporal logics, has previously been developed, and has been applied to the formalization of intentions and know-how <ref> [ Singh, 1991b; Singh & Asher, 1990 ] </ref> .
Reference: [ Singh, 1991a ] <author> Singh, Munindar P.; </author> <year> 1991a. </year> <title> Intentions, commitments and rationality. </title> <booktitle> In 13th Annual Conference of the Cognitive Science Society. </booktitle>
Reference-contexts: But then, if the agent has to decide whether a given intention is beneficial or not repeatedly, the concept of commitment is both descriptively and prescriptively redundant|the agent can just do the optimal action at each moment (see <ref> [ Singh, 1991a ] </ref> for a detailed discussion). <p> This model is quite abstract, is derived from models for dynamic and branching time temporal logics, has previously been developed, and has been applied to the formalization of intentions and know-how [ Singh, 1991b; Singh & Asher, 1990 ] . I follow the presentation of <ref> [ Singh, 1991a ] </ref> , where it was used to formalize some postulates concerning commitments. 5 Intuitive Description of Model and Primitive Concepts We need a formal model that involves time, action, possibility and choice and allows some notion of probability so that expected utility may be formalized (see [ Singh, <p> of <ref> [ Singh, 1991a ] </ref> , where it was used to formalize some postulates concerning commitments. 5 Intuitive Description of Model and Primitive Concepts We need a formal model that involves time, action, possibility and choice and allows some notion of probability so that expected utility may be formalized (see [ Singh, 1991a ] for details). The model used here is based on possible worlds. Each possible world has a branching 6 history of times. Histories are sets of times, partially ordered by temporal precedence, &lt;. They branch into the future, and are assumed to never end. <p> Many of these are given in <ref> [ Singh, 1991a ] </ref> and are not repeated here. One of those that we need here is that acting for an intention "uses up" a part of the resources allocated to it. Here the metaphor of commitment as a measure of the resources committed to an intention is invoked.
Reference: [ Singh, 1991b ] <author> Singh, Munindar P.; </author> <year> 1991b. </year> <title> A logic of situated know-how. </title> <booktitle> In National Conference on Artificial Intelligence (AAAI). </booktitle>
Reference-contexts: This model is quite abstract, is derived from models for dynamic and branching time temporal logics, has previously been developed, and has been applied to the formalization of intentions and know-how <ref> [ Singh, 1991b; Singh & Asher, 1990 ] </ref> .
Reference: [ Singh, 1991c ] <author> Singh, Munindar P.; </author> <year> 1991c. </year> <title> Towards a formal theory of communication for multiagent systems. </title> <booktitle> In International Joint Conference on Artificial Intelligence (IJCAI). </booktitle> <pages> 11 </pages>
References-found: 12

