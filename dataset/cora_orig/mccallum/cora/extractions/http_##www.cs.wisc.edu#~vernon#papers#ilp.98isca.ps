URL: http://www.cs.wisc.edu/~vernon/papers/ilp.98isca.ps
Refering-URL: http://www.cs.wisc.edu/~vernon/papers.html
Root-URL: 
Email: davidg@cs.wisc.edu fvijaypai, saritag@rice.edu  
Title: Analytic Evaluation of Shared-Memory Systems with ILP Processors model input parameters characterize the ability of
Author: Daniel J. Sorin Vijay S. Pai Sarita V. Adve Mary K. Vernon and David A. Wood fsorin, vernon, 
Affiliation: Computer Sciences Dept Dept of Electrical Computer Engineering University of Wisconsin Madison Rice University  
Note: To appear in 25th Annual International Symposium on Computer Architecture  The  
Abstract: This paper develops and validates an analytical model for evaluating various types of architectural alternatives for shared-memory systems with processors that aggressively exploit instruction-level parallelism. Compared to simulation, the analytical model is many orders of magnitude faster to solve, yielding highly accurate system performance estimates in seconds. Finally, this paper shows that the analytical model can be used to gain insights into application performance and to evaluate architectural design trade-offs. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Adve, V. Adve, M. Hill, and M. Vernon. </author> <title> Comparison of Hardware and Software Cache Coherence Schemes. </title> <booktitle> In Proc. 18th Int'l Symp. on Computer Architecture, </booktitle> <pages> pages 298308, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: These parameters, referred to as ILP parameters, are discussed in more detail below. The other parameters in the table are standard parameters for models of architectures based on directory coherence protocols <ref> [1] </ref>. Further description of those parameters is omitted due to space constraints.
Reference: [2] <author> V. Adve et al. </author> <title> An Integrated Compilation and Performance Analysis Environment for Data Parallel Programs . In Proceedings of Supercomputing '95, </title> <address> San Diego, CA, </address> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: obtained by RSIM, and Section 5.3 presents the results of the analytic model validations. 5.1 Applications Used in Model Validations The validation experiments include the following applications: FFT, LU, and Radix from the SPLASH-2 suites [29], Water from the SPLASH suite [24], and Er-lebacher from the Rice parallel compiler group <ref> [2] </ref>. 2 We also use versions of LU and of FFT (denoted by opt) that are optimized for ILP systems by applying loop interchange to schedule read misses closer together, thus better overlapping their latencies [21].
Reference: [3] <author> V. Adve and M. Vernon. </author> <title> The Influence of Random Delays on Parallel Task Execution Times. </title> <booktitle> In Proc. ACM SIGMET-RICS, </booktitle> <pages> pages 6173, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Finally, the throughput slowdown due to barriers <ref> [3] </ref> is computed from the average number of instructions and lock delays between each barrier (for load-balanced barriers) or the number of such instructions and lock delays for each processor participating in the barrier (unbalanced barriers), in addition to the estimated time to execute a perfectly load-balanced barrier on the given
Reference: [4] <author> D. Albonesi and I. Koren. </author> <title> A Mean Value Analysis Multiprocessor Model Incorporating Superscalar Processors and Latency Tolerating Techniques. </title> <journal> Int'l Journal of Parallel Programming, </journal> <year> 1996. </year>
Reference-contexts: A key question addressed in this research is whether a highly accurate yet tractable system of equations with fairly simple input parameters can be created for complex parallel ILP-processor architectures. We are aware of two previous analytical models of multiprocessors that have non-blocking caches <ref> [4, 27] </ref>. <p> We are aware of two previous analytical models of multiprocessors that have non-blocking caches [4, 27]. The model by Albonesi and Koren <ref> [4] </ref> was not validated and has at least two significant drawbacks: (1) the number of memory reads that are issued before the next read blocks is assumed to be fixed, whereas that number changes dynamically for ILP processors, and (2) some of the fixed model input parameters, such as the probability
Reference: [5] <author> M. Chiang and G. Sohi. </author> <title> Evaluating Design Choices for Shared Bus Multiprocessors. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 41(3):297317, </volume> <month> Mar. </month> <year> 1992. </year>
Reference-contexts: We create a set of intuitive customized mean value analysis (CMVA) equations [26] to obtain the estimates of processor stall time in each submodel. The CMVA technique has proven to be accurate in validation experiments for a number of simpler architectural models <ref> [26, 5] </ref>. * We show that reasonable approximations of key input parameters that characterize the application behavior can be obtained from a high-level simulator, FastILP, that runs two orders of magnitude faster than the detailed simulation.
Reference: [6] <author> M. Durbhakula, V. Pai, and S. Adve. </author> <title> Improving the Speed vs. Accuracy Tradeoff for Simulating Shared-Memory Multiprocessors with ILP Processors. </title> <type> Technical Report 9802, </type> <institution> Dept. of Elec. and Comp. Engineering, Rice Univ., </institution> <month> Apr. </month> <year> 1998. </year>
Reference-contexts: Computer architects have generally relied on simulation for designing shared-memory systems. However, an architectural simulator for shared-memory systems with processors that aggressively exploit instruction-level parallelism (ILP) requires several hours to simulate a few seconds of real execution time with reasonable accuracy <ref> [6] </ref>. This severely restricts the application and architectural design space that can be explored. fl This research is supported in part by DARPA/ITO under Contract N66001-97-C-8533 and by the National Science Foundation under Grants HRD-9896132, MIP-9625558, CDA-9623632, CCR-9410457, CCR-9502500, CDA-9502791, and CDA-9617383. Sarita V. <p> FastILP differs from conventional cycle by cycle ILP-based multiprocessor simulators in three key ways. First, FastILP speeds up processor simulation using techniques from DirectRSIM, a simulator designed for speeding up accurate timing simulation of ILP-based multiprocessors <ref> [6] </ref>. Each instruction in FastILP sets the timestamp of its destination register based on the completion time for that instruction. For non-memory instructions, the comple tion time is determined by the timestamps of the source registers of the instruction and the availability of the appropriate functional unit.
Reference: [7] <author> D. </author> <title> Eager. </title> <type> Private communication, </type> <month> Nov. </month> <year> 1997. </year>
Reference-contexts: To produce a more accurate estimate of processor residence time, we approximate the residual life using an interpolation <ref> [7] </ref> between t , which is the residual life when the memory transaction takes zero time, and the MVA residual life formula for a random arrival. 6 * Water (and MP3D) has a non-negligible value for f synchwrite , the fraction of write requests that are generated by read-modify-write instructions or
Reference: [8] <author> K. Farkas, P. Chow, N. Jouppi, and Z. Vranesic. </author> <title> Memory-System Design Considerations for Dynamically-Scheduled Processors. </title> <booktitle> In Proc. 24th Int'l Symp. on Computer Architecture, </booktitle> <pages> pages 133143, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: If this is the case for most applications of interest, then system designers could consider smaller sets of MSHRs to reduce both cost and MSHR lookup latency. Similar results have been obtained by Farkas, et al. <ref> [8] </ref> and Pai, et al. [21] using extensive simulation. Our analytic model (together with FastILP) is capable of obtaining the same results quickly over a wide range of applications. 6.3 Alternative Directory Configurations The memories and directories at each node in the shared memory architecture may be coupled or decoupled.
Reference: [9] <author> P. Heidelberger and K. Trivedi. </author> <title> Analytic Queueing Models for Programs with Internal Concurrency. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-32(1):7382, </volume> <month> Jan. </month> <year> 1982. </year>
Reference-contexts: Once the measures are computed from the MB model, the SB model is solved again using t SB = t U MB The alternating solution of the submodels is repeated until the estimated throughputs converge. This approach is similar to the method of complementary delays <ref> [9, 13] </ref>.
Reference: [10] <author> P. Heidelberger and K. Trivedi. </author> <title> Queueing Network Models for Parallel Processing with Asynchronous Tasks. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-31(11):10991109, </volume> <month> Nov. </month> <year> 1982. </year>
Reference-contexts: If the request is a write miss, the customer is routed immediately back to the processor while simultaneously forking an asynchronous memory write or upgrade transaction, using the technique proposed by Heidelberger and Trivedi <ref> [10] </ref>. In the MB submodel, the number of customers per processor is equal to the number of MSHRs, M hw . <p> When read misses occur, these customers are immediately routed back to the processor (since the processor cannot stall on read misses in this submodel) while simultaneously forking a read transaction to the memory system, again using the technique in <ref> [10] </ref>. 5 The mean time that each customer occupies the proces-sor in the MB model is equal to t adjusted to reflect the fraction of time that the processor is stalled due to load or read-modify-write instructions that cannot be retired (computed from the SB model).
Reference: [11] <author> M. Heinrich et al. </author> <title> The Performance Impact of Flexibility in the Stanford FLASH Multiprocessor. </title> <booktitle> In ASPLOS-VI, </booktitle> <pages> pages 274285, </pages> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: However, the flexibility and generality of a programmable controller leads to slower coherence protocol execution, which in turn increases controller occupancy and memory latency <ref> [11] </ref>. The extent to which this degrades application performance has been the subject of several detailed simulation studies [12, 23, 19]. The analytic model can quickly assess the impact of higher controller occupancy.
Reference: [12] <author> C. Holt, J. Singh, and J. Hennessy. </author> <title> Application and Architectural Bottlenecks in Large Scale Distributed Shared Memory Machines. </title> <booktitle> In Proc. 23rd Int'l Symp. on Computer Architecture, </booktitle> <pages> pages 134145, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: However, the flexibility and generality of a programmable controller leads to slower coherence protocol execution, which in turn increases controller occupancy and memory latency [11]. The extent to which this degrades application performance has been the subject of several detailed simulation studies <ref> [12, 23, 19] </ref>. The analytic model can quickly assess the impact of higher controller occupancy. We evaluate the impact of programmable controllers by modeling a decoupled node architecture with increased di rectory occupancy (i.e., 80 cycles).
Reference: [13] <author> P. Jacobson and E. Lazowska. </author> <title> Analyzing Queueing Networks with Simultaneous Resource Possession. </title> <journal> Communications of the ACM, </journal> <volume> 25(2):142151, </volume> <month> Feb. </month> <year> 1982. </year>
Reference-contexts: Once the measures are computed from the MB model, the SB model is solved again using t SB = t U MB The alternating solution of the submodels is repeated until the estimated throughputs converge. This approach is similar to the method of complementary delays <ref> [9, 13] </ref>.
Reference: [14] <author> D. Kroft. </author> <title> Lockup-Free Instruction Fetch/Prefetch Cache Organization. </title> <booktitle> In Proc. 8th Int'l Symp. on Computer Architecture, </booktitle> <pages> pages 8187, </pages> <month> May </month> <year> 1981. </year>
Reference-contexts: System Architecture Parameters standing misses <ref> [14] </ref>. Misses to the same cache line are coalesced in the MSHRs; only one memory request is generated for such coalesced misses. The memory and directory are interleaved. Directory accesses are overlapped with memory accesses. The bus is split transaction.
Reference: [15] <author> J. Kuskin et al. </author> <title> The Stanford FLASH Multiprocessor. </title> <booktitle> In Proc. 21st Int'l Symp. on Computer Architecture, </booktitle> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: The estimated performance advantage, for LU or other applications, can be traded off against cost considerations. 6.4 Programmable Coherence Controllers Several recent commercial and research multiprocessor systems <ref> [18, 15, 22] </ref> have employed programmable coherence controllers to reduce design time and/or support multiple protocols. However, the flexibility and generality of a programmable controller leads to slower coherence protocol execution, which in turn increases controller occupancy and memory latency [11].
Reference: [16] <author> J. Laudon and D. Lenoski. </author> <title> The SGI Origin: A ccNUMA Highly Scalable Server. </title> <booktitle> In Proc. 24th Int'l Symp. on Computer Architecture, </booktitle> <month> June </month> <year> 1997. </year>
Reference-contexts: The latter optimization allows remote transactions to bypass the memory bus. (The SGI Origin 2000 effectively provides such a fast path <ref> [16] </ref>.) We easily adapted the model to represent these different architectures. The results are shown for LU, an application whose read misses are primarily remote; results for FFT (not shown) are qualitatively similar although requests in FFT are more often local.
Reference: [17] <author> E. Lazowska, J. Zahorjan, G. Graham, and K. Sevcik. </author> <title> Quantitative System Performance, Computer System Analysis Using Queueing Network Models. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <month> May </month> <year> 1984. </year>
Reference-contexts: transaction in the MB submodel rather than con tributing directly to processor stall time. 4 FastILP underpredicts t for Water because rollbacks of misspeculated loads, triggered by disambiguating stores, are not yet accurately modeled. 5 The estimated mean residual life equals the second moment of service time divided by 2t <ref> [17] </ref>. 6 Note that the standard formula for mean residual life is assumed at all other queues in the model.
Reference: [18] <author> T. Lovett and R. Clapp. STiNG: </author> <title> A CC-NUMA Computer System for the Commercial Marketplace. </title> <booktitle> In Proc. 23rd Int'l Symp. on Computer Architecture, </booktitle> <pages> pages 308317, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: The estimated performance advantage, for LU or other applications, can be traded off against cost considerations. 6.4 Programmable Coherence Controllers Several recent commercial and research multiprocessor systems <ref> [18, 15, 22] </ref> have employed programmable coherence controllers to reduce design time and/or support multiple protocols. However, the flexibility and generality of a programmable controller leads to slower coherence protocol execution, which in turn increases controller occupancy and memory latency [11].
Reference: [19] <author> M. Michael, A. Nanda, B. Lim, and M. Scott. </author> <title> Coherence Controller Architectures for SMP-Based CC-NUMA Multiprocessors. </title> <booktitle> In Proc. 24th Int'l Symp. on Computer Architecture, </booktitle> <pages> pages 219229, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: However, the flexibility and generality of a programmable controller leads to slower coherence protocol execution, which in turn increases controller occupancy and memory latency [11]. The extent to which this degrades application performance has been the subject of several detailed simulation studies <ref> [12, 23, 19] </ref>. The analytic model can quickly assess the impact of higher controller occupancy. We evaluate the impact of programmable controllers by modeling a decoupled node architecture with increased di rectory occupancy (i.e., 80 cycles).
Reference: [20] <author> V. Pai, P. Ranganathan, and S. Adve. </author> <title> RSIM Reference Manual. </title> <type> Technical Report 9705, </type> <institution> Department of Electrical and Computer Engineering, Rice University, </institution> <month> Aug. </month> <year> 1997. </year>
Reference-contexts: The architecture is modeled in RSIM <ref> [20] </ref>, a detailed execution-driven simulator for shared-memory multiprocessors with ILP processors against which we validate our model. <p> The validations were performed against the RSIM execution-driven simulator <ref> [20] </ref>. Section 5.1 presents the applications used in the validations and the model input parameters for those applications measured by RSIM.
Reference: [21] <author> V. Pai, P. Ranganathan, and S. Adve. </author> <title> The Impact of Instruction-Level Parallelism on Multiprocessor Performance and Simulation Methodology. </title> <booktitle> In Proc. Third Int'l Symp. on High Performance Computer Architecture, </booktitle> <pages> pages 7283, </pages> <month> Feb. </month> <year> 1997. </year>
Reference-contexts: Second, FastILP speeds up memory system simulation by taking advantage of two observations: the ILP parameters are not very sensitive to the exact latencies or configuration of the memory system, and L2 cache misses have high latencies that can be overlapped effectively only with other memory misses <ref> [21] </ref>. Using these observations, FastILP does not explicitly simulate any part of the memory system beyond the cache hierarchy. FastILP divides simulated time into distinct eras, which start when one or more memory replies unblock the processor and end when the processor blocks again waiting for a memory reply. <p> [29], Water from the SPLASH suite [24], and Er-lebacher from the Rice parallel compiler group [2]. 2 We also use versions of LU and of FFT (denoted by opt) that are optimized for ILP systems by applying loop interchange to schedule read misses closer together, thus better overlapping their latencies <ref> [21] </ref>. The optimization in FFTopt has the side effect that all read requests overlapped at any given time from a single processor go to the same memory bank. This causes the effective number of memory modules per node to be equal to one. <p> In contrast, the f M values for Radix and Water reveal considerably less ability to exploit ILP hardware to overlap read memory requests. Erlebacher shows moderate ability for overlap. These observations were also noted in <ref> [21] </ref>. <p> If this is the case for most applications of interest, then system designers could consider smaller sets of MSHRs to reduce both cost and MSHR lookup latency. Similar results have been obtained by Farkas, et al. [8] and Pai, et al. <ref> [21] </ref> using extensive simulation. Our analytic model (together with FastILP) is capable of obtaining the same results quickly over a wide range of applications. 6.3 Alternative Directory Configurations The memories and directories at each node in the shared memory architecture may be coupled or decoupled.
Reference: [22] <author> S. Reinhardt, J. Larus, and D. Wood. Tempest and Typhoon: </author> <title> User-Level Shared Memory. </title> <booktitle> In Proc. 21st Int'l Symp. on Computer Architecture, </booktitle> <pages> pages 325337, </pages> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: The estimated performance advantage, for LU or other applications, can be traded off against cost considerations. 6.4 Programmable Coherence Controllers Several recent commercial and research multiprocessor systems <ref> [18, 15, 22] </ref> have employed programmable coherence controllers to reduce design time and/or support multiple protocols. However, the flexibility and generality of a programmable controller leads to slower coherence protocol execution, which in turn increases controller occupancy and memory latency [11].
Reference: [23] <author> S. Reinhardt, R. Pfile, and D. Wood. </author> <title> Decoupled Hardware Support for Distributed Shared Memory. </title> <booktitle> In Proc. 23rd Int'l Symp. on Computer Architecture, </booktitle> <pages> pages 3443, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: However, the flexibility and generality of a programmable controller leads to slower coherence protocol execution, which in turn increases controller occupancy and memory latency [11]. The extent to which this degrades application performance has been the subject of several detailed simulation studies <ref> [12, 23, 19] </ref>. The analytic model can quickly assess the impact of higher controller occupancy. We evaluate the impact of programmable controllers by modeling a decoupled node architecture with increased di rectory occupancy (i.e., 80 cycles).
Reference: [24] <author> J. Singh, W. Weber, and A. Gupta. </author> <title> SPLASH: Stanford Parallel Applications for Shared-Memory. Computer Architecture News, </title> <year> 1992. </year>
Reference-contexts: 5.2 compares the inputs generated by FastILP to those obtained by RSIM, and Section 5.3 presents the results of the analytic model validations. 5.1 Applications Used in Model Validations The validation experiments include the following applications: FFT, LU, and Radix from the SPLASH-2 suites [29], Water from the SPLASH suite <ref> [24] </ref>, and Er-lebacher from the Rice parallel compiler group [2]. 2 We also use versions of LU and of FFT (denoted by opt) that are optimized for ILP systems by applying loop interchange to schedule read misses closer together, thus better overlapping their latencies [21].
Reference: [25] <author> D. Sorin et al. </author> <title> A Customized MVA Model for ILP Multiprocessors. </title> <type> Technical Report 1369, </type> <institution> Computer Sciences Dept., Univ. of Wisconsin - Madison, </institution> <month> Mar. </month> <year> 1998. </year>
Reference-contexts: The remainder of this section gives the most pertinent details of the two submodels as well as how slowdown due to synchronization delays is computed; the full set of equations for the submodels is given in <ref> [25] </ref>. Each of the two submodels (SB and MB) contains the same set of customized MVA equations [26] to compute the delay for a transaction in the memory subsystem (see Section 4.2). <p> Fixed delays are assumed for resources that have negligible contention (e.g., cache tag checks) and for the approximate average delay at each network switch (observed during measurement or simulation of several applications). 1 The CMVA equations, explained in detail in <ref> [25] </ref>, are briefly outlined below. The total average round-trip time in either submodel is the sum of the customer's mean residence time at each of the resources that it visits.
Reference: [26] <author> M. Vernon, E. Lazowska, and J. Zahorjan. </author> <title> An Accurate and Efficient Performance Analysis Technique for Multiprocessor Snooping Cache-Consistency Protocols. </title> <booktitle> In Proc. 15th Int'l Symp. on Computer Architecture, </booktitle> <pages> pages 192202, </pages> <year> 1988. </year>
Reference-contexts: We create a set of intuitive customized mean value analysis (CMVA) equations <ref> [26] </ref> to obtain the estimates of processor stall time in each submodel. <p> We create a set of intuitive customized mean value analysis (CMVA) equations [26] to obtain the estimates of processor stall time in each submodel. The CMVA technique has proven to be accurate in validation experiments for a number of simpler architectural models <ref> [26, 5] </ref>. * We show that reasonable approximations of key input parameters that characterize the application behavior can be obtained from a high-level simulator, FastILP, that runs two orders of magnitude faster than the detailed simulation. <p> Each of the two submodels (SB and MB) contains the same set of customized MVA equations <ref> [26] </ref> to compute the delay for a transaction in the memory subsystem (see Section 4.2).
Reference: [27] <author> D. Willick and D. Eager. </author> <title> An Analytical Model of Multistage Interconnection Networks. </title> <booktitle> In Proc. ACM SIGMET-RICS, </booktitle> <pages> pages 192202, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: A key question addressed in this research is whether a highly accurate yet tractable system of equations with fairly simple input parameters can be created for complex parallel ILP-processor architectures. We are aware of two previous analytical models of multiprocessors that have non-blocking caches <ref> [4, 27] </ref>. <p> The model by Willick and Eager <ref> [27] </ref> also assumes a fixed limit on the number of outstanding memory requests (e.g., a hardware upper bound), and was validated against a simulation that had statistical workload assumptions similar to the analytical model. <p> This approach is similar to the method of complementary delays [9, 13]. The SB and MB submodels are each similar to Willick and Eager's model <ref> [27] </ref> except that: (1) transaction routing is according to the cache coherence protocol, (2) the switching network is configured as a two-dimensional mesh and the delay per switch is modeled as an average quantity measured directly in the system or by simulating over a number of applications, (3) contention for the
Reference: [28] <author> E. Witchel and M. Rosenblum. Embra: </author> <title> Fast and Flexible Machine Simulation. </title> <booktitle> In Proc. ACM SIGMETRICS, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: other than t , CV t , f M , and the part of f synchwrite that is due to writes coalescing with later memory read requests, do not depend directly on ILP features and can thus be measured using current fast simulators for multiprocessors with simple single-issue processors (e.g., <ref> [28] </ref>). The remainder of this section provides an overview of FastILP, a fast high-level simulator for quickly estimating the ILP parameters t , CV t , f M , and f synchwrite .
Reference: [29] <author> S. Woo et al. </author> <title> The SPLASH-2 Programs: Characterization and Methodological Considerations. </title> <booktitle> In Proc. 22nd Int'l Symp. on Computer Architecture, </booktitle> <pages> pages 2436, </pages> <month> June </month> <year> 1995. </year> <month> 12 </month>
Reference-contexts: Section 5.2 compares the inputs generated by FastILP to those obtained by RSIM, and Section 5.3 presents the results of the analytic model validations. 5.1 Applications Used in Model Validations The validation experiments include the following applications: FFT, LU, and Radix from the SPLASH-2 suites <ref> [29] </ref>, Water from the SPLASH suite [24], and Er-lebacher from the Rice parallel compiler group [2]. 2 We also use versions of LU and of FFT (denoted by opt) that are optimized for ILP systems by applying loop interchange to schedule read misses closer together, thus better overlapping their latencies [21]. <p> We therefore omit those results in the remainder of this section. 3 The baseline measures for the model input parameters used the following processor/cache subsystem configuration: maximum fetch/decode/retire rate = 4, instruction window size = 64, L1/L2 cache size = 16KB/64KB (scaled based on application input sizes <ref> [29] </ref>), cache line size = 64 bytes, L1/L2 associativity = 1/4, L1/L2 hit time = 1/13 cycles, L1/L2 ports = 2/1.
References-found: 29

