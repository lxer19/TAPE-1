URL: http://www.cs.huji.ac.il/~rousso/TRs/iccv98.ps.gz
Refering-URL: http://www.cs.huji.ac.il/~rousso/
Root-URL: http://www.cs.huji.ac.il
Email: E-Mail: frousso,pelegg@cs.huji.ac.il  
Title: Universal Mosaicing using Pipe Projection mosaicing methodology to allow image mosaicing in the most general
Author: B. Rousso S. Peleg I. Finci A. Rav-Acha 
Note: A  
Address: 91904 Jerusalem, ISRAEL  
Affiliation: Institute of Computer Science The Hebrew University of Jerusalem  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> ARPA Image Understanding Workshop, Mon-terey, California, </institution> <month> November </month> <year> 1994. </year> <title> Morgan Kauf-mann. a c (a) Two original images. A map is seen on a wall parallel to the optical axis. Left image is with smallest zoom, and right image is with largest zoom. (b) Reconstructed panoramic mosaic, which is somewhat similar to a frontal view of the map (c). a (a) First and last original images. The camera was performing composite translation and rotation, inducing substantial parallax. (b) Pipe mo-saicing using view interpolation eliminates the parallax distortions: distant objects are not duplicated, and close objects are not truncated. </title>
Reference: [2] <institution> Fifth International Conference on Computer Vision, </institution> <address> Cambridge, MA, </address> <month> June </month> <year> 1995. </year> <pages> IEEE-CS. </pages>
Reference: [3] <editor> Proc. </editor> <booktitle> IEEE Workshop on Representation of Visual Scenes, </booktitle> <address> Cambridge, MA, </address> <month> June </month> <year> 1995. </year> <pages> IEEE-CS. </pages>
Reference: [4] <institution> IEEE Conference on Computer Vision and Pattern Recognition, </institution> <address> San Fransisco, California, </address> <month> June </month> <year> 1996. </year>
Reference: [5] <author> P.J. Burt and E.H. Adelson. </author> <title> A multiresolution spline with application to image mosaics. </title> <journal> ACM Trans. on Graphics, </journal> <volume> 2(4) </volume> <pages> 217-236, </pages> <month> October </month> <year> 1983. </year>
Reference-contexts: A more common solution is photo-mosaicing: aligning, and pasting, frames in a video sequence, which enables a more complete view. Digital photography enabled new implementations for mosaicing <ref> [5, 18] </ref>, which were fl This research was partially funded by DARPA through ARL Contract DAAL01-97-0101 and by the European ACTS project AC074 "Vanguard". Contact E-Mail: peleg@cs.huji.ac.il first applied to aerial and satellite images, and later used for scene and object representation.
Reference: [6] <author> P.J. Burt and P. Anandan. </author> <title> Image stabilization by registration to a reference mosaic. </title> <booktitle> In ARPA Image Understanding Workshop [1], </booktitle> <pages> pages 457-465. </pages>
Reference-contexts: However, the limitations to motion which is a pure rotation about the optical center limits the applicability of this approach. In more general camera motions, that may include both camera translations and small camera rotations, more general transformation for image alignment are used <ref> [6, 8, 12, 16, 10] </ref>. In all cases images are aligned pairwise, using a parametric transformation like an affine transformation or planar-projective transformation. A reference frame is selected, and all images are aligned with this reference frame and combined to create the panoramic mosaic.
Reference: [7] <author> S.E. Chen and L. Williams. </author> <title> View interpolation for image synthesis. </title> <booktitle> In SIGGRAPH, </booktitle> <pages> pages 279-288, </pages> <address> Anahiem, California, </address> <month> August </month> <year> 1993. </year> <note> ACM. </note>
Reference-contexts: For example, we can take a collection of N strips, each with a width of one pixel, from interpolated camera views in between the original camera positions. In order to synthesize new views we can use various methods, such as optical flow interpolation <ref> [7, 17] </ref>, trilinear tensor methods [15], and others. In most cases approximate methods will give good results. The creation of the intermediate views can involve only view interpolation, as in this application view extrapolation is not needed.
Reference: [8] <author> M. Hansen, P. Anandan, K. Dana, G. van der Wal, and P.J. Burt. </author> <title> Real-time scene stabilization and mosaic construction. </title> <booktitle> In ARPA Image Understanding Workshop [1], </booktitle> <pages> pages 457-465. </pages>
Reference-contexts: However, the limitations to motion which is a pure rotation about the optical center limits the applicability of this approach. In more general camera motions, that may include both camera translations and small camera rotations, more general transformation for image alignment are used <ref> [6, 8, 12, 16, 10] </ref>. In all cases images are aligned pairwise, using a parametric transformation like an affine transformation or planar-projective transformation. A reference frame is selected, and all images are aligned with this reference frame and combined to create the panoramic mosaic.
Reference: [9] <author> R. Hartley and R. Gupta. </author> <title> Linear pushbroom cameras. </title> <editor> In J.O. Eklundh, editor, </editor> <booktitle> Third European Conference on Computer Vision, </booktitle> <pages> pages 555-566, </pages> <address> Stockholm, Sweden, May 1994. </address> <publisher> Springer. </publisher>
Reference-contexts: The strip collection process allows the introduction of a mechanism to overcome the effects of parallax by generating dense intermediate views. In some cases mosaics generated in this manner can be considered as linear push-broom cameras <ref> [9] </ref>. <p> In the simple case of a camera which is moving horizontally, vertical strips are usually taken from each image and pasted side by side (see Fig. 1.a). This process can also be viewed as scanning the scene with a vertical broom <ref> [9, 19] </ref>. This vertical broom scans the entire sequence, extracts vertical strips along the sequence, and pastes them one next to the other to create the panoramic mosaic.
Reference: [10] <author> M. Irani, P. Anandan, and S. Hsu. </author> <title> Mosaic based representations of video sequences and their applications. </title> <booktitle> In Fifth International Conference on Computer Vision [2], </booktitle> <pages> pages 605-611. </pages>
Reference-contexts: However, the limitations to motion which is a pure rotation about the optical center limits the applicability of this approach. In more general camera motions, that may include both camera translations and small camera rotations, more general transformation for image alignment are used <ref> [6, 8, 12, 16, 10] </ref>. In all cases images are aligned pairwise, using a parametric transformation like an affine transformation or planar-projective transformation. A reference frame is selected, and all images are aligned with this reference frame and combined to create the panoramic mosaic.
Reference: [11] <author> M. Irani, B. Rousso, and S. Peleg. </author> <title> Detecting and tracking multiple moving objects using temporal integration. </title> <editor> In G. Sandini, editor, </editor> <booktitle> Second Euro-pean Conference on Computer Vision, </booktitle> <pages> pages 282-287, </pages> <address> Santa Margherita, Italy, May 1992. </address> <publisher> Springer. </publisher>
Reference-contexts: Numerous methods exist to recover the parameters of an affine transformation <ref> [11, 16] </ref>.
Reference: [12] <author> P. Jaillon and A. Montanvert. </author> <title> Image mosaick-ing applied to three-dimensional surfaces. </title> <booktitle> In 12th International Conference on Pattern Recognition, </booktitle> <pages> pages 253-257, </pages> <address> Jerusalem, Israel, </address> <month> October </month> <year> 1994. </year> <pages> IEEE-CS. </pages>
Reference-contexts: However, the limitations to motion which is a pure rotation about the optical center limits the applicability of this approach. In more general camera motions, that may include both camera translations and small camera rotations, more general transformation for image alignment are used <ref> [6, 8, 12, 16, 10] </ref>. In all cases images are aligned pairwise, using a parametric transformation like an affine transformation or planar-projective transformation. A reference frame is selected, and all images are aligned with this reference frame and combined to create the panoramic mosaic.
Reference: [13] <author> S. Mann and R. </author> <title> Picard. Virtual bellows: Constructing high quality stills from video. </title> <booktitle> In First IEEE International Conference on Image Processing, </booktitle> <address> Austin, Texas, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: Such translations can either be computed by manually pointing to corresponding points, or by image correlation methods. Other simple mosaics are created by rotating the camera around its optical center using a special device, and creating a panoramic image which represents the projection of the scene onto a cylinder <ref> [14, 13] </ref>. However, the limitations to motion which is a pure rotation about the optical center limits the applicability of this approach. In more general camera motions, that may include both camera translations and small camera rotations, more general transformation for image alignment are used [6, 8, 12, 16, 10].
Reference: [14] <author> L. McMillan and G. Bishop. </author> <title> Plenoptic modeling: An image-based rendering system. </title> <booktitle> In SIG-GRAPH, </booktitle> <address> Los Angeles, California, </address> <month> August </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: Such translations can either be computed by manually pointing to corresponding points, or by image correlation methods. Other simple mosaics are created by rotating the camera around its optical center using a special device, and creating a panoramic image which represents the projection of the scene onto a cylinder <ref> [14, 13] </ref>. However, the limitations to motion which is a pure rotation about the optical center limits the applicability of this approach. In more general camera motions, that may include both camera translations and small camera rotations, more general transformation for image alignment are used [6, 8, 12, 16, 10].
Reference: [15] <author> B. Rousso, S. Avidan, A. Shashua, and S. Peleg. </author> <title> Robust recovery of camera rotation from three frames. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition [4], </booktitle> <pages> pages 796-802. </pages>
Reference-contexts: In general camera motion, the optical flow is induced by camera translation and by camera rotation. The rotational part can be recovered and compensated for if needed, as it does not depend on the structure of the scene (see, for example, <ref> [15] </ref>). The translation (and zoom) induce radial optical flow which emerges from the FOE (Focus Of Expansion), except for the singular case of sideways translation in which the optical flow is parallel. <p> For example, we can take a collection of N strips, each with a width of one pixel, from interpolated camera views in between the original camera positions. In order to synthesize new views we can use various methods, such as optical flow interpolation [7, 17], trilinear tensor methods <ref> [15] </ref>, and others. In most cases approximate methods will give good results. The creation of the intermediate views can involve only view interpolation, as in this application view extrapolation is not needed. The use of intermediate views for strips collection gives the effect of orthographic projection, which avoids parallax discontinuities.
Reference: [16] <author> H.S. Sawhney, S. Ayer, and M. Gorkani. </author> <title> Model-based 2D & 3D dominant motion estimation for mosaicing and video representation. </title> <booktitle> In Fifth International Conference on Computer Vision [2], </booktitle> <pages> pages 583-590. </pages>
Reference-contexts: However, the limitations to motion which is a pure rotation about the optical center limits the applicability of this approach. In more general camera motions, that may include both camera translations and small camera rotations, more general transformation for image alignment are used <ref> [6, 8, 12, 16, 10] </ref>. In all cases images are aligned pairwise, using a parametric transformation like an affine transformation or planar-projective transformation. A reference frame is selected, and all images are aligned with this reference frame and combined to create the panoramic mosaic. <p> Numerous methods exist to recover the parameters of an affine transformation <ref> [11, 16] </ref>.
Reference: [17] <author> S. Seitz and C. Dyer. </author> <title> Physically valid view synthesis by image interpolation. </title> <booktitle> In Proc. IEEE Workshop on Representation of Visual Scenes [3]. </booktitle>
Reference-contexts: For example, we can take a collection of N strips, each with a width of one pixel, from interpolated camera views in between the original camera positions. In order to synthesize new views we can use various methods, such as optical flow interpolation <ref> [7, 17] </ref>, trilinear tensor methods [15], and others. In most cases approximate methods will give good results. The creation of the intermediate views can involve only view interpolation, as in this application view extrapolation is not needed.
Reference: [18] <author> R. Szeliski. </author> <title> Video mosaics for virtual environments. </title> <journal> IEEE Computer Graphics and Applications, </journal> <pages> pages 22-30, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: A more common solution is photo-mosaicing: aligning, and pasting, frames in a video sequence, which enables a more complete view. Digital photography enabled new implementations for mosaicing <ref> [5, 18] </ref>, which were fl This research was partially funded by DARPA through ARL Contract DAAL01-97-0101 and by the European ACTS project AC074 "Vanguard". Contact E-Mail: peleg@cs.huji.ac.il first applied to aerial and satellite images, and later used for scene and object representation.
Reference: [19] <author> J.Y. Zheng and S. Tsuji. </author> <title> Panoramic representation for route recognition by a mobile robot. </title> <journal> International Journal of Computer Vision, </journal> <volume> 9 </volume> <pages> 55-76, </pages> <year> 1992. </year>
Reference-contexts: In the simple case of a camera which is moving horizontally, vertical strips are usually taken from each image and pasted side by side (see Fig. 1.a). This process can also be viewed as scanning the scene with a vertical broom <ref> [9, 19] </ref>. This vertical broom scans the entire sequence, extracts vertical strips along the sequence, and pastes them one next to the other to create the panoramic mosaic.
References-found: 19

