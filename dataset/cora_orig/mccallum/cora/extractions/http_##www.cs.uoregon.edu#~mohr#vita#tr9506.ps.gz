URL: http://www.cs.uoregon.edu/~mohr/vita/tr9506.ps.gz
Refering-URL: http://www.cs.uoregon.edu/~mohr/vita/vita-e.html
Root-URL: http://www.cs.uoregon.edu
Email: -mohr, kesavans, malony-@cs.uoregon.edu  
Title: 1 Speedy: An Integrated Performance Extrapolation Tool for pC++ Programs  
Author: Bernd W. Mohr, Kesavan Shanmugam, Allen D. Malony 
Keyword: performance prediction, extrapolation, object-parallel programming, trace driven simulation, performance debugging tools, and modeling.  
Address: OR 97403, USA  
Affiliation: Department of Computer and Information Science, University of Oregon, Eugene  
Abstract: Performance Extrapolation is the process of evaluating the performance of a parallel program in a target execution environment using performance information obtained for the same program in a different execution environment. Performance extrapolation techniques are suited for rapid performance tuning of parallel programs, particularly when the target environment is unavailable. This paper describes one such technique that was developed for data-parallel C++ programs written in the pC++ language. In pC++, the programmer can distribute a collection of objects to various processors and can have methods invoked on those objects execute in parallel. Using performance extrapolation in the development of pC++ applications allows tuning decisions to be made in advance of detailed execution performance measurements. The current pC++ language system includes t, an integrated environment for analyzing and tuning the performance of pC++ programs. This paper presents speedy, a new addition to t, that predicts the performance of pC++ programs on parallel machines using extrapolation techniques. Speedy applies the existing instrumentation support of t to capture high-level event traces of a n-thread pC++ program run on a uniprocessor machine (made possible by pC++s multithreaded runtime system) together with trace-driven simulation to predict the performance of the program run on a target n-processor machine. We describe how speedy works and how it is integrated into t. We also show how speedy can be used to evaluate and tune a pC++ program for a given target environment. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F. Bodin, P. Beckman, D. Gannon, S. Yang, S. Kesavan, A. Malony, B. Mohr, </author> <title> Implementing a Parallel C++ Runtime System for Scalable Parallel Systems, </title> <booktitle> Proceedings Supercomputing 93, IEEE Computer Society and ACM SIGARCH, </booktitle> <pages> pages 588-597, </pages> <month> November </month> <year> 1993. </year>
Reference: [2] <author> F. Bodin, P. Beckman, D. Gannon, J. Gotwals, S. Narayana, S. Srinivas, B. Winnicka, Sage++: </author> <title> An Object Oriented Toolkit and Class Library for Building Fortran and C++ Restructuring Tools, </title> <booktitle> Proceedings Oonski 94, </booktitle> <address> Oregon, </address> <year> 1994. </year>
Reference-contexts: These language-level objects appear in all t tools. By plan, t was designed and developed in concert with the pC++ language system. It leverages pC++ language technology, especially in its use of the Sage++ toolkit <ref> [2] </ref> as an interface to the pC++ compiler for instrumentation and for accessing properties of program objects. t is also integrated with the pC++ runtime system for profiling and tracing support. Because pC++ is intended to be portable, the tools are built to be portable as well.
Reference: [3] <author> E. A. Brewer, C. N. Dellarocas, A. Colbrook, W. E. Weihl, Proteus: </author> <title> A High Performance Parallel Architecture Simulator, </title> <type> Technical Report MIT/LCS/TR-516, </type> <institution> MIT Laboratory of Computer Science, </institution> <month> September </month> <year> 1991. </year>
Reference: [4] <author> E. A. Brewer, W. E. Weihl, </author> <title> Developing Parallel Applications Using High-Performance Simulation, </title> <booktitle> Proc. ACM/ONR Workshop on Parallel and Distributed Debugging, </booktitle> <pages> pages 158-168, </pages> <month> May </month> <year> 1993. </year>
Reference: [5] <author> D. Brown, S. Hackstadt, A. Malony, B. Mohr, </author> <title> Program Analysis Environments for Parallel Language Systems: The TAU Environment, </title> <booktitle> Proc. of the Workshop on Environments and Tools For Parallel Scientific Computing, Townsend, Tennessee, </booktitle> <pages> pages. 162-171, </pages> <month> May </month> <year> 1994. </year>
Reference: [6] <author> M. E. Crovella and T. J. LeBlanc, </author> <title> Parallel Performance Prediction Using Lost Cycles Analysis, </title> <booktitle> Proc. Supercomputing 94, IEEE Computer Society and ACM, </booktitle> <pages> pages 600-609, </pages> <month> November </month> <year> 1994.. </year> <month> 17 </month>
Reference: [7] <author> T. Fahringer, </author> <title> Automatic Performance Prediction for Parallel Programs on Massively Parallel Computers, </title> <type> Ph.D. Thesis, </type> <institution> University of Vienna, </institution> <month> September </month> <year> 1993. </year>
Reference: [8] <author> D. Gannon and J. K. Lee, </author> <title> Object Oriented Parallelism: pC++ Ideas and Experiments, </title> <booktitle> Proc. Japan Society of Parallel Processing, </booktitle> <pages> pages 13-23, </pages> <year> 1991. </year>
Reference: [9] <author> D. C. Grunwald, </author> <title> A Users Guide to AWESIME: An Object Oriented Parallel Programming and Simulation System, </title> <type> Technical Report 552-91, </type> <institution> Department of Computer Science, University of Colorado at Boulder, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: Onyx, and PowerChallenge, BBN TC2000, Cray T3D, Meiko CS-2, and homogeneous clusters of UNIX workstations using PVM and MPI; work on porting pC++ to the Convex SPP is in progress. pC++ also has multi-threading support for running applications in a quasi-parallel mode on UNIX workstations; supported thread systems are Awesime <ref> [9] </ref>, Pthreads, LWP, and the AT&T task library. This enables the testing and pre-evaluation of parallel pC++ applications in a familiar desktop environment.
Reference: [10] <author> S. Hackstadt, A. Malony, </author> <title> Next-Generation Parallel Performance Visualization: A Prototyping Environment for Visualization Development, </title> <booktitle> Proc. Parallel Architectures and Languages Europe, (PARLE), </booktitle> <address> Athens, Greece, </address> <year> 1994. </year>
Reference: [11] <author> R. Helm, A. D. Malony and S. F. Fickas, </author> <title> Capturing and Automating Performance Diagnosis: The Poirot Approach, </title> <booktitle> Proc. International Parallel Processing Symposium </booktitle>
Reference-contexts: 1 Introduction One of the foremost challenges for a parallel programmer is to achieve the best possible performance for an application on a parallel machine. For this purpose, the process of performance debugging (the iterative application of performance diagnosis <ref> [11] </ref> and tuning) is applied as an integral constituent part of a parallel program development methodology. Application of performance debugging in practice has invariably required the development of performance tools based on the measurement and analysis of actual parallel program execution.
Reference: [12] <author> V. Herrarte, E. Lusk, </author> <title> Studying Parallel Program Behavior with Upshot, </title> <type> Technical Report ANL-91/15, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <year> 1991. </year>
Reference-contexts: Event tracing is fully operational on all parallel computer systems supported by pC++. This has several advantages for an ExtraP user. The traces used for simulation can be analyzed with all the event trace browsers supported by t (currently easy, Pablo [21], SIMPLE [17], and upshot <ref> [12] </ref>). As the ExtraP model is based on the operational characteristics of pC++ event classes, the user can also generate semantically equivalent traces on real parallel computer systems for comparing to or validating the extrapolation results.
Reference: [13] <author> High Performance Fortran Forum, </author> <title> High Performance Fortran Language Specification version 1.0, TR92225, Center for Research on Parallel Computation, </title> <institution> Rice University, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: More specifically, a collection is a structured set of objects which are distributed across the processing elements of the computer in a manner designed to be consistent with HPF <ref> [13] </ref>. To accomplish this, pC++ provides a simple mechanism to build collections of objects from a base element class. Member functions from this element class can be applied to the entire collection (or a subset) in parallel.
Reference: [14] <author> S. Hiranandani, K. Kennedy, C.-W. Tseng, S. </author> <title> Warren,The D Editor: A New Interactive Parallel Programming Tool, </title> <booktitle> Proc. Supercomputing 94, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pages 733-742, </pages> <month> November </month> <year> 1994. </year>
Reference: [15] <author> J. Kohn and W. Williams, </author> <title> ATExpert, </title> <journal> Jounral of Parallel and Distributed Computing, </journal> <volume> Vol. 18, </volume> <year> 1993, </year> <pages> pages 205-222. </pages>
Reference: [16] <author> A. Malony, B. Mohr, P. Beckman, D. Gannon, S. Yang, F. Bodin, </author> <title> Performance Analysis of pC++: A Portable Data-Parallel Programming System for Scalable Parallel Computers, </title> <booktitle> Proc. 8th Int. Parallel Processing Symb. (IPPS), </booktitle> <address> Mexico, </address> <publisher> IEEE Computer Society Press, </publisher> <pages> pages 75-85, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: This experiment tells us that to improve the performance of Poisson, we must tune Cyclic reduction first because it is the bottleneck. Speedy can be used in this way to locate the bottlenecks in a program. The performance behavior observed using speedy is consistent with actual results <ref> [16] </ref>. FIGURE 10.
Reference: [17] <author> B. Mohr, </author> <title> Standardization of Event Traces Considered Harmful or Is an Implementation of Object-Independent Event Trace Monitoring and Analysis Systems Possible?, </title> <booktitle> Proc. CNRS-NSF Workshop on Environments and Tools For Parallel Scientific Computing, </booktitle> <address> St. Hilaire du Touvet, France, Elsevier, </address> <booktitle> Advances in Parallel Computing, </booktitle> <volume> Vol. 6, </volume> <pages> pages 103-124, </pages> <year> 1993. </year>
Reference-contexts: Event tracing is fully operational on all parallel computer systems supported by pC++. This has several advantages for an ExtraP user. The traces used for simulation can be analyzed with all the event trace browsers supported by t (currently easy, Pablo [21], SIMPLE <ref> [17] </ref>, and upshot [12]). As the ExtraP model is based on the operational characteristics of pC++ event classes, the user can also generate semantically equivalent traces on real parallel computer systems for comparing to or validating the extrapolation results.
Reference: [18] <author> B. Mohr, D. Brown, A. Malony, </author> <title> TAU: A Portable Parallel Program Analysis Environment for pC++, </title> <booktitle> Proc. of CONPAR 94 - VAPP VI, </booktitle> <address> Linz, Austria, </address> <publisher> Springer Verlag, LNCS 854, </publisher> <pages> pages 29-40, </pages> <month> September </month> <year> 1994. </year>
Reference: [19] <institution> On-line information on CM-5, </institution> <type> CM-5 Technical Summary, </type> <address> http://www.think.com/Prod-Serv/Products/ cmmd.html, </address> <month> November </month> <year> 1992. </year>
Reference: [20] <author> J. Ousterhout, </author> <title> Tcl and the Tk Toolkit, </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
Reference-contexts: Because pC++ is intended to be portable, the tools are built to be portable as well. C++ and C are used to ensure portable and efficient implementation, and similar reasons led us to choose Tcl/Tk <ref> [20] </ref> for the graphical interface. The t tools are implemented as graphical hypertools. While the tools are distinct, providing unique capabilities, they can act in combination to provide enhanced functionality.
Reference: [21] <author> D. A. Reed, R. D. Olson, R. A. Aydt, T. M. Madhyasta, T. Birkett, D. W. Jensen, B. A.A. Nazief, B. K. Totty, </author> <title> Scalable Performance Environments for Parallel Systems. </title> <booktitle> Proc. 6th Distributed Memory Computing Conference, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pages 562-569, </pages> <year> 1991. </year>
Reference-contexts: Parallel performance This research is supported by ARPA under Rome Labs contract AF 30602-92-C-0135 and Fort Huachuca contract ARMY DABT63-94-C-0029. The research is also supported by a NSF National Young Investigator (NYI) award. 2 environments <ref> [21] </ref> support performance debugging through program instrumentation, performance data analysis, and results presentation tools, but have often lacked in the level of their integration with parallel programming systems. <p> Event tracing is fully operational on all parallel computer systems supported by pC++. This has several advantages for an ExtraP user. The traces used for simulation can be analyzed with all the event trace browsers supported by t (currently easy, Pablo <ref> [21] </ref>, SIMPLE [17], and upshot [12]). As the ExtraP model is based on the operational characteristics of pC++ event classes, the user can also generate semantically equivalent traces on real parallel computer systems for comparing to or validating the extrapolation results.
Reference: [22] <author> S. K. Reinhardt, M. D. Hill, J. R. Larus, A. R. Lebeck, J. C. Lewis and D. A. Wood, </author> <title> The Wisconsin Wind Tunnel: Virtual Prototyping of Parallel Computers, </title> <booktitle> Proc. ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 48-60, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: For example, the Proteus system [3,4] and the Wisconsin Wind Tunnel <ref> [22] </ref> have considerably advanced the efficiency and effectiveness of dynamic prediction techniques for architectural studies, but the overhead is prohibitively high to warrant their use for rapid and interactive performance debugging.
Reference: [23] <author> K. Shanmugam, </author> <title> Performance Extrapolation of Parallel Programs, </title> <type> Masters Thesis, </type> <institution> Department of Computer and Information Science, University of Oregon, </institution> <month> June </month> <year> 1994. </year> <month> 18 </month>
Reference: [24] <author> K.Shanmugam, A. D. Malony, </author> <title> Performance Extrapolation of Parallel Programs, </title> <note> Submitted to ICPP 95. </note>
Reference-contexts: The technique is one example of a general prediction methodology called Performance Extrapolation that estimates the performance of a parallel program in a target execution environment by using the performance data obtained from running the program in a different execution environment. In <ref> [24] </ref>, we demonstrated that performance extrapolation is a viable process for parallel program performance debugging that can be applied effectively in situations where standard measurement techniques are restrictive or costly. <p> A new addition to t called speedy interacts with ExtraP to perform the necessary extrapolation experiments. This integration of ExtraP with t is of paramount importance because ExtraP is intended to be used as part of a program analysis environment to provide a performance debugging methodology. In <ref> [24] </ref> we showed how ExtraP can give good feedback about the performance of a pC++ program as the user attempts to tune the code to different target environments. 4 Integrating TAU and ExtraP ExtraP is integrated with in two ways: First, for generating the traces needed for the simulation, ExtraP uses <p> The results also show that even with the stepwise behavior (BLOCK, BLOCK) starts winning after 16 processors. Such crossover point information is very useful for the programmer during the development process. Validation against the actual CM-5 performance was accurate <ref> [24] </ref>. The goal of our next experiment is to show how speedy can be used to selectively study various portions of the program. Such profile information is useful when the programmer wants to tune parts of the program for a particular machine. We used Poisson as the test case.
Reference: [25] <author> H. Wabnig and G. Haring, </author> <title> PAPS - The Parallel Program Performance Prediction Toolset, Computer Performance Evaluation - Modelling Techniques and Tools, </title> <booktitle> Lecture Notes in Computer Science 794, </booktitle> <publisher> Springer-Verlag, </publisher> <pages> pages 284-304, </pages> <year> 1994. </year>
Reference-contexts: In this manner, the environment would enable performance-driven parallel program design where algorithm choices could be considered early in the development process <ref> [25] </ref>. However, the user would demand a level of detail from predicted performance analysis comparable to that provided by measurements, which static prediction tools often cannot provide.
References-found: 25

