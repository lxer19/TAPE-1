URL: ftp://synapse.cs.byu.edu/pub/papers/martinez_89b.ps
Refering-URL: ftp://synapse.cs.byu.edu/pub/papers/details.html
Root-URL: 
Title: Neural Network Applicability: Classifying the Problem Space  
Author: Tony Martinez 
Degree: Professor,  
Address: Provo, Utah 84602  
Affiliation: Computer Science Dept. 230 TMCB, Brigham Young University  
Note: In Proceedings of the IASTED International Symposium on Expert Systems and Neural Networks, pp. 41-44, 1989.  
Abstract: The tremendous current effort to propose neurally inspired methods of computation forces closer scrutiny of real world application potential of these models. This paper categorizes applications into classes and particularly discusses features of applications which make them efficiently amenable to neural network methods. Computational machines do deterministic mappings of inputs to outputs and many computational mechanisms have been proposed for problem solutions. Neural network features include parallel execution, adaptive learning, generalization, and fault tolerance. Often, much effort is given to a model and applications which can already be implemented in a much more efficient way with an alternate technology. Neural networks are potentially powerful devices for many classes of applications, but not all. However, it is proposed that the class of applications for which neural networks are efficient is both large and commonly occurring in nature. Comparison of supervised, unsupervised, and generalizing systems is also included. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Carpenter, G.A., and Grossberg, S., </author> <title> A massively parallel architecture for a self-organizing neural pattern recognition machine, Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 37, </volume> <pages> pp. 54-115, </pages> <year> (1987). </year>
Reference-contexts: Although a simplistic and incomplete dichotomy, I classify current artificial neural systems into categorization (unsupervised) and decision (supervised) systems. Examples of categorization systems include adaptive resonance theory <ref> [1] </ref> and self-organizing feature maps [4]. These systems do unsupervised learning of categories and classifications of arbitrary inputs. They seek solutions in the important domain of building up reasonable categories from an unknown input environment.
Reference: 2. <author> Hinton, G., Sejnowski, T, and D. Ackley, </author> <title> Boltzmann Machines: Constraint Satisfaction Networks that Learn,"Tech. </title> <type> Rep CMU-CS-84-119, </type> <address> CMU, Pittsburgh, PA, </address> <year> (1984). </year>
Reference-contexts: This is the realm of decision systems. These systems are required to do more arbitrary mappings and require some type of supervised learning (teacher, environment, reward, etc.) Attempts at this type of system include backpropagation techniques [9] and Boltzmann machines <ref> [2] </ref>. There is certainly overlap between categorization and decision systems, and classifying a model as one or the other is a matter of degree. Many times direct comparison of categorization and decision systems are made. Since their functionality and target applications are quite different, these comparisons seem empty.
Reference: 3. <author> Hopfield, J.J., </author> <title> Neurons with graded response have collective computational properties like those of twostate neurons, </title> <journal> Proc. Natl. Acad. Sci., </journal> <volume> Vol. 81, pp.3088-3092 (1084). </volume>
Reference-contexts: Note that the most intuitive forms of generalization follow from the incompleteness of applications. Many current neural models do generalization by similarity of inputs (hamming distance, etc.) <ref> [3] </ref>. This is but one type of generalization, and the type most beneficial will depend on the application. One of the apparent powers of natural nervous systems is the ability to discriminate the current critical inputs from a massive barrage of total inputs.
Reference: 4. <author> Kohonen, T., </author> <title> Self-organization and associative memory, </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> (1984). </year>
Reference-contexts: Although a simplistic and incomplete dichotomy, I classify current artificial neural systems into categorization (unsupervised) and decision (supervised) systems. Examples of categorization systems include adaptive resonance theory [1] and self-organizing feature maps <ref> [4] </ref>. These systems do unsupervised learning of categories and classifications of arbitrary inputs. They seek solutions in the important domain of building up reasonable categories from an unknown input environment. However, they are limited to a restricted type of classifying, mapping similar things into similar classes.
Reference: 5. <author> Martinez, T. R., </author> <title> Adaptive Self-Organizing Logic Networks, </title> <type> Ph.D. Dissertation, Technical Report - CSD 860093, </type> <institution> University of California, </institution> <address> Los Angeles, CA (May 1986). </address>
Reference: 6. <author> Martinez T. R., </author> <title> Models of Parallel Adaptive Logic, </title> <booktitle> Proceedings of the 1987 IEEE Systems Man and Cybernetics Conference, </booktitle> <pages> pp. 290-296, </pages> <month> (October, </month> <year> 1987). </year>
Reference: 7. <author> Martinez, T. R. and J. J. Vidal, </author> <title> Adaptive Parallel Logic Networks, </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> Vol. 5, </volume> <pages> pp. 26-58, </pages> <year> (1988). </year>
Reference: 8. <author> Martinez, T. R., </author> <title> Adaptive Self-Organizing Concurrent Systems, </title> <booktitle> in Progress in Neural Networks, </booktitle> <publisher> Ablex Publishing, </publisher> <year> 1989. </year>
Reference: 9. <editor> Rumelhart, D. and McClelland, J., </editor> <booktitle> Parallel Distributed Processing:, </booktitle> <volume> Vol. I, </volume> <pages> pp. 318-362, </pages> <publisher> MIT Press, </publisher> <year> (1986). </year>
Reference-contexts: This is the realm of decision systems. These systems are required to do more arbitrary mappings and require some type of supervised learning (teacher, environment, reward, etc.) Attempts at this type of system include backpropagation techniques <ref> [9] </ref> and Boltzmann machines [2]. There is certainly overlap between categorization and decision systems, and classifying a model as one or the other is a matter of degree. Many times direct comparison of categorization and decision systems are made.
Reference: 10. <author> Waltz, D., </author> <title> Applications of the Connection Machine, </title> <booktitle> Computer, </booktitle> <month> (Jan. </month> <year> 1987). </year>
Reference-contexts: Rather, an iterative technique is used which requires more time but is far more efficient overall. As research continues, more basic applications which initially appear sequential, are being solved with creative parallel techniques <ref> [10] </ref>. Complete (fragmented) vs. Incomplete (generalizable): This is considered to be a crucial, yet not often considered feature of applications. A given application (function) is called complete if a specific output mapping is required for all (or a majority) of the permutations of the input variables.
References-found: 10

