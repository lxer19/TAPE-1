URL: ftp://ftp.dcs.ex.ac.uk/pub/connect/328.ps.gz
Refering-URL: http://www.dcs.ex.ac.uk/pub/index.htm
Root-URL: http://www.dcs.ex.ac.uk
Title: ENGINEERING RELIABLE NEURAL NETWORKS  
Author: D Partridge and W B Yates 
Address: Exeter, UK  
Affiliation: University of  
Abstract: The notion of multiversion system design is imported from software engineering where it has sometimes been used as part of a strategy for producing highly reliable software. We have further developed and refined this notion such that we can confidently undertake to improve the performance of any single neural network. For a number of reasons neural computing is better suited for use with a multiversion strategy than the conventional computing from whence the basic idea came. We have developed a methodology to underpin a mul-tiversion approach to highly reliable neural net implementations. We present this methodology and several different applications of it (e.g., single level and two-level multiversion systems) that demonstrate the gen-eralisation improvements obtainable within the general framework of a diverse, multiversion approach. A variety of results are compared and contrasted. They indicate that significant generalisation improvements can be obtained by a variety of different means. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Littlewood, B and Miller, D R, </author> <year> 1989, </year> <title> Conceptual modeling of coincident failures in multiversion software, </title> <journal> IEEE Transactions on Software Engineering, 15,1596-1614. </journal>
Reference-contexts: Many of these selection strategies use a new statistical model. This model, which is derived from the conceptual model of Littlewood and Miller <ref> [1] </ref>, is based on the assumption that the observed data (i.e. test results) provide complete information on finite populations of versions and inputs, and the aim of the analysis is simply to make statements about these particular populations.
Reference: [2] <author> Partridge, D and Griffith, N, </author> <year> 1994, </year> <title> Techniques for Improving Neural Net Generalisation, </title> <booktitle> Neural Computing & Applications, </booktitle> <pages> 4. </pages>
Reference-contexts: These are our selection strategies. They are mostly statistical techniques (such as, majority of three randomly selected versions), although we have also explored a `selector net' approach | an MLP trained to operate as a switch between the versions in a set (Partridge and Griffith, <ref> [2] </ref>) | to exploit a new type of diversity, minority-specialisation (MS) diversity which is not indifferent with respect to version choice, unlike MCF diversity.
Reference: [3] <author> Pearlmutter, B A and Rosenfeld, R, </author> <year> 1991, </year> <title> Chaitin-Kolmogorov Complexity and generalisation in neural Networks, Neural Information Processing Systems 3, </title> <editor> D Touretzky (Ed), </editor> <month> 925-931. </month>
Reference-contexts: In addition, it has been claimed (Pearl-mutter and Rosenfeld, <ref> [3] </ref>) that the initial randomi-sation of link weights introduces noise that is likely to adversely affect the generalisation performance of the trained net.
Reference: [4] <author> Partridge, </author> <title> D, (in press), On the difficulty of really considering a radical novelty, Minds and Machines. </title>
Reference-contexts: The main conclusion, however, is that the novel nature of NC (see Partridge <ref> [4] </ref> for a full justification of this claim) opens up the possibility of a radically new way to engineer certain classes of software | i.e. as diverse multiver-sion systems.
Reference: [5] <author> Partridge, D and Collins T, </author> <title> 1995 Neural net training: random versus systematic, 85-92, In Neural Networks J. </title> <editor> G. Taylor (Ed.), </editor> <publisher> Alfred Waller Ltd, Henley-on-Thames. </publisher>
Reference-contexts: Previous studies have shown that decision boundary patterns (i.e. ones that are `just' true and `just' false) are superior to random patterns for training purposes (Partridge and Collins <ref> [5] </ref>). Thus sets of decision boundary patterns (called `rational' sets) were constructed. One such training set is illustrated below; it is projected so that the decision boundary is a bottom-left to top-right diagonal line.
Reference: [6] <author> Partridge, D and Yates, W B, </author> <year> 1995, </year> <institution> Engineering Mul-tiversion Neural-Net Systems, Res. </institution> <type> rep. 320, </type> <institution> Dept. Computer Science, University of Exeter. </institution>
Reference-contexts: Should conventional versions be available, they can be included within the scope of the selection process which operates only on the behaviour of the versions. Currently, we are exploring, and have first results (Partridge and Yates <ref> [6] </ref>) using a heuristic for choosing subsets of versions with high diversity (the `pick' heuristic) and a genetic algorithm approach for doing likewise.
References-found: 6

