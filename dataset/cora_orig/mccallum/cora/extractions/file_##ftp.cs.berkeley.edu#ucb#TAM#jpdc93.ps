URL: file://ftp.cs.berkeley.edu/ucb/TAM/jpdc93.ps
Refering-URL: http://http.cs.berkeley.edu/~sethg/papers.html
Root-URL: 
Email: ftam@boing.CS.Berkeley.EDUg  
Title: TAM A Compiler Controlled Threaded Abstract Machine  
Author: David E. Culler Seth Copen Goldstein Klaus Erik Schauser Thorsten von Eicken 
Address: Berkeley  
Affiliation: Computer Science Division University of California,  
Abstract: The Threaded Abstract Machine (TAM) refines dataflow execution models to address the critical constraints that modern parallel architectures place on the compilation of general-purpose parallel programming languages. TAM defines a self-scheduled machine language of parallel threads, which provides a path from dataflow-graph program representations to conventional control flow. The most important feature of TAM is the way it exposes the interaction between the handling of asynchronous message events, the scheduling of computation, and the utilization of the storage hierarchy. This paper provides a complete description of TAM and codifies the model in terms of a pseudo machine language TL0. Issues in compilation from a high level parallel language to TL0 are discussed in general and specifically in regard to the Id90 language. The implementation of TL0 on the CM-5 multiprocessor is explained in detail. Using this implementation, a cost model is developed for the various TAM primitives. The TAM approach is evaluated on sizable Id90 programs on a 64 processor system. The scheduling hierarchy of quanta and threads is shown to provide substantial locality while tolerating long latencies. This allows the average thread scheduling cost to be extremely low. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Arvind, D. E. Culler, R. A. Iannucci, V. Kathail, K. Pingali, and R. E. Thomas. </author> <title> The tagged token dataflow architecture. </title> <type> Technical report, </type> <institution> MIT Laboratory for Computer Science, 545 Technology Square, </institution> <address> Cambridge, MA 02139, </address> <month> August </month> <year> 1983. </year> <note> Revised October, </note> <year> 1984. </year>
Reference-contexts: 1 Introduction Dataflow execution models have evolved considerably since their original formulation <ref> [1, 15] </ref>, reflecting an improved understanding of hardware implementation techniques [1, 18, 16, 20, 31, 36], parallel programming languages [27, 30], compilation methods [38, 43], and resource management strategies [9, 34]. <p> 1 Introduction Dataflow execution models have evolved considerably since their original formulation [1, 15], reflecting an improved understanding of hardware implementation techniques <ref> [1, 18, 16, 20, 31, 36] </ref>, parallel programming languages [27, 30], compilation methods [38, 43], and resource management strategies [9, 34]. Several hybrid models [5, 12, 23, 28] have been formulated which eliminate operand matching, avoid redundant synchronization, or use more conventional processor organizations. <p> The work per message event cannot be enlarged by referring to the context of the operation. In refinements of the MIT Tagged-Token Data Machine <ref> [1] </ref> the local processor state took on an ever more significant role. Pure dataflow graphs circulate loop constants through the body of the loop for every iteration. To eliminate this overhead, a loop constant area was provided.
Reference: [2] <author> Arvind and K. Ekanadham. </author> <title> Future Scientific Programming on Parallel Machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5(5) </volume> <pages> 460-493, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: Splitting is handled by recursive calls to the trace particle routine. Particles are independent, but statistics from all particle traces are combined into a set of histograms represented as M-structures. The input consists of 8192 initial particles. Paraffins [3] enumerates the distinct isomers of paraffins. Simple <ref> [2, 8] </ref> is a hydrodynamics and heat conduction code widely used as an application benchmark, rewritten in Id90. It integrates the solution to several PDEs forward in time over a collection of roughly 25 large rectangular grids.
Reference: [3] <author> Arvind, S. K. Heller, and R. S. Nikhil. </author> <title> Programming Generality and Parallel Computers. </title> <booktitle> In Proc. of the Fourth Int. Symp. on Biological and Artificial Intelligence Systems, </booktitle> <pages> pages 255-286, </pages> <address> Trento, Italy, </address> <month> September </month> <year> 1988. </year> <note> ESCOM (Leider). </note>
Reference-contexts: Splitting is handled by recursive calls to the trace particle routine. Particles are independent, but statistics from all particle traces are combined into a set of histograms represented as M-structures. The input consists of 8192 initial particles. Paraffins <ref> [3] </ref> enumerates the distinct isomers of paraffins. Simple [2, 8] is a hydrodynamics and heat conduction code widely used as an application benchmark, rewritten in Id90. It integrates the solution to several PDEs forward in time over a collection of roughly 25 large rectangular grids.
Reference: [4] <author> Arvind, R. S. Nikhil, and K. K. Pingali. I-Structures: </author> <title> Data Structures for Parallel Computing. </title> <type> Technical Report CSG Memo 269, </type> <institution> MIT Lab for Comp. Science, </institution> <address> Cambridge, MA, </address> <month> February </month> <year> 1987. </year> <title> (Also in Proc. of the Graph Reduction Workshop, </title> <address> Santa Fe, NM. </address> <month> October </month> <year> 1986.). </year>
Reference-contexts: The global heap supports synchronization on an element-by-element basis, as with I-structures <ref> [4] </ref>. Thus, there are two sources of latency in global accesses. A hardware communication latency occurs if the accessed element is remote to the issuing processor and, regardless of placement, a synchronization latency occurs if the accessed element is not present, causing the request to be deferred. <p> Heap storage is assumed to be distributed over processors and is accessed through split-phase fetch and store operations, described below. In addition to data, each heap location holds a small number of tag bits, providing element-by-element synchronization as required for I-structures, M-structures, and thunks <ref> [4, 19] </ref>. In summary, the TAM data storage hierarchy is composed of three levels: registers, local frames, and heap-allocated structures. Registers are the least expensive to access, however their content is short-lived.
Reference: [5] <author> R. Buehrer and K. Ekanadham. </author> <title> Incorporating Dataflow Ideas into von Neumann Processors for Parallel Execution. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(12):1515-1522, </volume> <month> December </month> <year> 1987. </year>
Reference-contexts: 1 Introduction Dataflow execution models have evolved considerably since their original formulation [1, 15], reflecting an improved understanding of hardware implementation techniques [1, 18, 16, 20, 31, 36], parallel programming languages [27, 30], compilation methods [38, 43], and resource management strategies [9, 34]. Several hybrid models <ref> [5, 12, 23, 28] </ref> have been formulated which eliminate operand matching, avoid redundant synchronization, or use more conventional processor organizations. In addition, message driven models [14] demonstrate that the architecture need not dictate the format and handling of tokens, or rather, messages.
Reference: [6] <author> P. J. Burns, M. Christon, R. Schweitzer, O. M. Lubeck, H. J. Wasserman, M. L. Simmons, and D. V. Pryor. </author> <title> Vectorization of Monte-Carlo Particle Transport: An Architectural Study using the LANL Benchmark Gamteb. </title> <booktitle> In Proc. Supercomputing '89. IEEE Computer Society and ACM SIGARCH, </booktitle> <address> New York, NY, </address> <month> November </month> <year> 1989. </year>
Reference-contexts: These were developed by other researchers in the context of other platforms, especially the GITA dataflow graph interpreter and the Monsoon dataflow machine. QS is a simple quick-sort using accumulation lists. The input is a list of random numbers. Gamteb is a Monte Carlo neutron transport code <ref> [6] </ref>. It is highly recursive with many conditionals. The work associated with a particle is unpredictable, since particles may be absorbed or scattered due to collisions with various materials, or may split into multiple particles. Splitting is handled by recursive calls to the trace particle routine.
Reference: [7] <author> A. A. Chien. </author> <title> Concurrent Aggregates (CA): An Object-Oriented Language for Fine-Grained Message-Passing Machines. </title> <type> Technical Report AI-TR 1248, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: For example, most extensions of Fortran and C with send/receive message passing provide exactly one thread of control per physical processor and a crude abstraction of communication channels. An emerging class of languages <ref> [7, 21, 24, 27] </ref> lets the programmer define arbitrary parallel data structures spread across the machine and dynamically spawn computations to perform coordinated actions on these data structures. Dataflow machines attempt to realize these concepts directly in hardware.
Reference: [8] <author> W. P. Crowley, C. P. Hendrickson, and T. E. Rudy. </author> <title> The SIMPLE code. </title> <type> Technical Report UCID 17715, </type> <institution> Lawrence Livermore Laboratory, </institution> <month> February </month> <year> 1978. </year>
Reference-contexts: Splitting is handled by recursive calls to the trace particle routine. Particles are independent, but statistics from all particle traces are combined into a set of histograms represented as M-structures. The input consists of 8192 initial particles. Paraffins [3] enumerates the distinct isomers of paraffins. Simple <ref> [2, 8] </ref> is a hydrodynamics and heat conduction code widely used as an application benchmark, rewritten in Id90. It integrates the solution to several PDEs forward in time over a collection of roughly 25 large rectangular grids.
Reference: [9] <author> D. E. Culler. </author> <title> Managing Parallelism and Resources in Scientific Dataflow Programs. </title> <type> Technical Report 446, </type> <institution> MIT Lab for Comp. Science, </institution> <month> March </month> <year> 1990. </year> <type> (PhD Thesis, </type> <institution> Dept. of EECS, MIT). </institution> <month> 32 </month>
Reference-contexts: 1 Introduction Dataflow execution models have evolved considerably since their original formulation [1, 15], reflecting an improved understanding of hardware implementation techniques [1, 18, 16, 20, 31, 36], parallel programming languages [27, 30], compilation methods [38, 43], and resource management strategies <ref> [9, 34] </ref>. Several hybrid models [5, 12, 23, 28] have been formulated which eliminate operand matching, avoid redundant synchronization, or use more conventional processor organizations. In addition, message driven models [14] demonstrate that the architecture need not dictate the format and handling of tokens, or rather, messages. <p> By limiting the problem size and explicitly constraining the scheduling of computation, a 27 instruction (CPT); bars show the contribution to the CPT resulting from each TL0 instruction class. program can be made to operate within the machine resource limits <ref> [9] </ref>. Second, the token queue serves to represent the excess parallelism in the program. To avoid overcommitting this resource, it is necessary to constrain the scheduling of computation to limit the maximum exposed parallelism.
Reference: [10] <author> D. E. Culler. </author> <title> Multithreading: Fundamental Limits, Potential Gains, and Alternatives. </title> <booktitle> In Proc. of the Supercom--puting '91, Workshop on Multithreading, </booktitle> <year> 1992. </year> <note> (to appear). </note>
Reference-contexts: The execution model places no limit on the number of outstanding messages, although architectural factors such as latency, overhead, or available bandwidth may introduce a practical limit <ref> [10] </ref>. The communication model is efficient because no buffering is required in the communication layer. Storage to receive the message is pre-allocated in the frame so that the inlet can move the data directly from the network interface to the frame [45].
Reference: [11] <author> D. E. Culler and Arvind. </author> <title> Resource Requirements of Dataflow Programs. </title> <booktitle> In Proc. of the 15th Annual Int. Symp. on Comp. Arch., </booktitle> <pages> pages 141-150, </pages> <address> Hawaii, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: The assignment of iterations to frames can be addressed by a variety of policies. A very general form of parallel loop structure, called k-bounded loops <ref> [11] </ref>, is used in compiling Id90. In this scheme, the amount of parallelism, i.e., the number of frames, is determined at the time the loop is invoked, possibly depending on values within the program. The loop builds a ring of k frames and cycles through them.
Reference: [12] <author> D. E. Culler and G. M. Papadopoulos. </author> <title> The Explicit Token Store. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 10 </volume> <pages> 289-308, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Dataflow execution models have evolved considerably since their original formulation [1, 15], reflecting an improved understanding of hardware implementation techniques [1, 18, 16, 20, 31, 36], parallel programming languages [27, 30], compilation methods [38, 43], and resource management strategies [9, 34]. Several hybrid models <ref> [5, 12, 23, 28] </ref> have been formulated which eliminate operand matching, avoid redundant synchronization, or use more conventional processor organizations. In addition, message driven models [14] demonstrate that the architecture need not dictate the format and handling of tokens, or rather, messages. <p> Since it was necessary to allocate and initialize the loop constant area, work could no longer be assigned to processors by simply hashing the tag. The Manchester machine [18] and 28 Sigma-1 [20] adopted an alternative approach of sticky match operations with similar drawbacks. 6.2 ETS The ETS model <ref> [12] </ref> embodied in Monsoon [31] is a partial remedy to these problems. Implicit allocation of the matching store is eliminated by explicitly allocating an activation frame to hold the local storage for each function invocation. Synchronization bits are associated with each frame location to support a dyadic match.
Reference: [13] <author> D. E. Culler, K. E. Schauser, and T. von Eicken. </author> <title> Two Fundamental Limits on Dataflow Multiprocessing. </title> <booktitle> In Proceedings of the IFIP WG 10.3 Working Conference on Architectures and Compilation Techniques for Fine and Medium Grain Parallelism, </booktitle> <address> Orlando, FL. </address> <publisher> North-Holland, </publisher> <month> January </month> <year> 1993. </year> <note> (Also available as Technical Report UCB/CSD 92/716, </note> <institution> CS Div., University of California at Berkeley). </institution>
Reference-contexts: If the program does not not have enough parallelism, techniques such as loop unrolling may be applied to introduce it. In general, the more parallelism a program exploits, the more storage resources it needs. Thus a tradeoff has to be struck between good latency tolerance and storage requirements <ref> [13] </ref>. 3.5 Storage hierarchy Compilers for sequential languages manage the placement of data between registers and call frame locations based on the analysis of a single flow of control. The basic technique is to construct an interference graph describing which variables may have overlapping lifetimes. <p> We have seen examples where a processor becomes so successfully focused on its local work that it starves other processors by failing to spawn off additional work <ref> [13] </ref>. Nonetheless, it is clear that latency tolerance and dynamic scheduling must be addressed in concert with the characteristics of the local storage hierarchy. Acknowledgments We are grateful to the anonymous referees for their valuable comments. Computational support at Berkeley was provided by the NSF Infrastructure Grant number CDA-8722788.
Reference: [14] <author> W. J. Dally. </author> <title> The J-Machine system. </title> <editor> In P. Winston and S. A. Shellard, editors, </editor> <booktitle> Artificial Intelligence at MIT: Expanding Frontiers, chapter 21, </booktitle> <pages> pages 536-569. </pages> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Several hybrid models [5, 12, 23, 28] have been formulated which eliminate operand matching, avoid redundant synchronization, or use more conventional processor organizations. In addition, message driven models <ref> [14] </ref> demonstrate that the architecture need not dictate the format and handling of tokens, or rather, messages. The Threaded Abstract Machine (TAM) draws together these diverse investigations into a coherent execution model that can be implemented efficiently on a variety of machine architectures. <p> Furthermore, the amount of work performed per scheduling event must be small, unless stronger assumptions are made about the state of the computation assigned to the particular processor. Thus, the fundamental shortcomings of the dataflow approach remain, the tokens are simply larger. The J-Machine <ref> [14] </ref> approximates the message-driven model, rather than implementing it directly. A portion of the on-chip memory provides a message buffer and scheduling queue managed in hardware as a fixed-size ring buffer. Arriving messages are transferred into the queue and serviced in FIFO order.
Reference: [15] <author> J. B. Dennis. </author> <title> First Version of a Data Flow Procedure Language. </title> <editor> In G. Goos and J. Hartmanis, editors, </editor> <booktitle> Proc. Programming Symposium, Paris (Lecture Notes in Computer Science 19, </booktitle> <publisher> Springer Verlag). Spinger-Verlag, </publisher> <address> New York, </address> <year> 1974. </year>
Reference-contexts: 1 Introduction Dataflow execution models have evolved considerably since their original formulation <ref> [1, 15] </ref>, reflecting an improved understanding of hardware implementation techniques [1, 18, 16, 20, 31, 36], parallel programming languages [27, 30], compilation methods [38, 43], and resource management strategies [9, 34].
Reference: [16] <author> V. G. Grafe and J. E. Hoch. </author> <title> The Epsilon-2 Hybrid Dataflow Architecture. </title> <booktitle> In Proc. of Compcon90, </booktitle> <pages> pages 88-93, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Dataflow execution models have evolved considerably since their original formulation [1, 15], reflecting an improved understanding of hardware implementation techniques <ref> [1, 18, 16, 20, 31, 36] </ref>, parallel programming languages [27, 30], compilation methods [38, 43], and resource management strategies [9, 34]. Several hybrid models [5, 12, 23, 28] have been formulated which eliminate operand matching, avoid redundant synchronization, or use more conventional processor organizations.
Reference: [17] <author> A. Gupta et al. </author> <title> Comparative Evaluation of Latency Reducing and Tolerating Techniques. </title> <booktitle> In Proceedings of the 19th Annual Symposium on Computer Architecture, </booktitle> <pages> pages 254-263, </pages> <address> Gold Coast, Australia, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: To keep the utilization of each processor at an acceptable level, it is important to treat remote accesses as split-phase operations, that is, to continue executing instructions while the access completes <ref> [17, 35] </ref>. In some cases this can be accomplished using prefetching techniques, but in general multiplexing several logical threads of control onto each processor, called multithreading, is required. Coordinating threads of control on separate processors presents similar concerns, but the latencies involved are usually longer and potentially unbounded.
Reference: [18] <author> J. Gurd, C. C. Kirkham, and I. Watson. </author> <title> The Manchester Prototype Dataflow Computer. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 28(1) </volume> <pages> 34-52, </pages> <month> January </month> <year> 1985. </year>
Reference-contexts: 1 Introduction Dataflow execution models have evolved considerably since their original formulation [1, 15], reflecting an improved understanding of hardware implementation techniques <ref> [1, 18, 16, 20, 31, 36] </ref>, parallel programming languages [27, 30], compilation methods [38, 43], and resource management strategies [9, 34]. Several hybrid models [5, 12, 23, 28] have been formulated which eliminate operand matching, avoid redundant synchronization, or use more conventional processor organizations. <p> To eliminate this overhead, a loop constant area was provided. Since it was necessary to allocate and initialize the loop constant area, work could no longer be assigned to processors by simply hashing the tag. The Manchester machine <ref> [18] </ref> and 28 Sigma-1 [20] adopted an alternative approach of sticky match operations with similar drawbacks. 6.2 ETS The ETS model [12] embodied in Monsoon [31] is a partial remedy to these problems.
Reference: [19] <author> S. K. Heller. </author> <title> Efficient Lazy Data-Structures on a Dataflow Machine. </title> <type> Technical report, </type> <institution> MIT Lab for Comp. Science, </institution> <month> February </month> <year> 1989. </year>
Reference-contexts: Heap storage is assumed to be distributed over processors and is accessed through split-phase fetch and store operations, described below. In addition to data, each heap location holds a small number of tag bits, providing element-by-element synchronization as required for I-structures, M-structures, and thunks <ref> [4, 19] </ref>. In summary, the TAM data storage hierarchy is composed of three levels: registers, local frames, and heap-allocated structures. Registers are the least expensive to access, however their content is short-lived.
Reference: [20] <author> K. Hiraki, S. Sekiguchi, and T. Shimada. </author> <title> System Architecture of a Dataflow Supercomputer. </title> <type> Technical report, </type> <institution> Computer Systems Division, Electrotechnical Laboratory, </institution> <address> Japan, </address> <year> 1987. </year>
Reference-contexts: 1 Introduction Dataflow execution models have evolved considerably since their original formulation [1, 15], reflecting an improved understanding of hardware implementation techniques <ref> [1, 18, 16, 20, 31, 36] </ref>, parallel programming languages [27, 30], compilation methods [38, 43], and resource management strategies [9, 34]. Several hybrid models [5, 12, 23, 28] have been formulated which eliminate operand matching, avoid redundant synchronization, or use more conventional processor organizations. <p> To eliminate this overhead, a loop constant area was provided. Since it was necessary to allocate and initialize the loop constant area, work could no longer be assigned to processors by simply hashing the tag. The Manchester machine [18] and 28 Sigma-1 <ref> [20] </ref> adopted an alternative approach of sticky match operations with similar drawbacks. 6.2 ETS The ETS model [12] embodied in Monsoon [31] is a partial remedy to these problems.
Reference: [21] <author> W. Horwat. </author> <title> Concurrent Smalltalk on the Message-Driven Processor. </title> <type> Master's thesis, </type> <institution> Massachusetts Institure of Technology, </institution> <address> Cambridge, MA, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: For example, most extensions of Fortran and C with send/receive message passing provide exactly one thread of control per physical processor and a crude abstraction of communication channels. An emerging class of languages <ref> [7, 21, 24, 27] </ref> lets the programmer define arbitrary parallel data structures spread across the machine and dynamically spawn computations to perform coordinated actions on these data structures. Dataflow machines attempt to realize these concepts directly in hardware.
Reference: [22] <author> R. A. </author> <title> Iannucci. A Dataflow/von Neumann Hybrid Architecture. </title> <type> Technical Report TR-418, </type> <institution> MIT Lab for Comp. Science, </institution> <address> Cambridge, MA, </address> <month> May </month> <year> 1988. </year> <type> (PhD Thesis, </type> <institution> Dept. of EECS, MIT). </institution>
Reference-contexts: Dependence analysis uses sets of inputs to establish independence. Given two apparently independent nodes in the dataflow graph, if they both depend unconditionally on the same set of inputs, neither can depend on the other, since the dependence would need to be conveyed through one of the inputs <ref> [22] </ref>. Demand analysis uses sets of outputs to establish independence. If two apparently independent nodes unconditionally affect the same set of outputs then neither can depend on the other, since the dependence would have to be conveyed through one of the outputs [38].
Reference: [23] <author> R. A. </author> <title> Iannucci. Toward a Dataflow/von Neumann Hybrid Architecture. </title> <booktitle> In Proc. 15th Int. Symp. on Comp. Arch., </booktitle> <pages> pages 131-140, </pages> <address> Hawaii, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: 1 Introduction Dataflow execution models have evolved considerably since their original formulation [1, 15], reflecting an improved understanding of hardware implementation techniques [1, 18, 16, 20, 31, 36], parallel programming languages [27, 30], compilation methods [38, 43], and resource management strategies [9, 34]. Several hybrid models <ref> [5, 12, 23, 28] </ref> have been formulated which eliminate operand matching, avoid redundant synchronization, or use more conventional processor organizations. In addition, message driven models [14] demonstrate that the architecture need not dictate the format and handling of tokens, or rather, messages. <p> Furthermore, the machine cycle time is limited by the read-modify-write on the frame synchronization bits and the frame access per instruction. These times could potentially be reduced via caching, but the arbitrary interleaving of tokens in the queue is unlikely to provide any useful locality. 6.3 Hybrids The Hybrid <ref> [23] </ref> proposal was the first to observe the interplay between register allocation and thread scheduling. This model provides a machine language of multiple threads operating against an activation frame and registers. However, each frame slot includes presence bits, like the ETS.
Reference: [24] <author> R. H. Halstead Jr. </author> <title> Multilisp: A Language for Concurrent Symbolic Computation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(4) </volume> <pages> 501-538, </pages> <month> October </month> <year> 1985. </year>
Reference-contexts: For example, most extensions of Fortran and C with send/receive message passing provide exactly one thread of control per physical processor and a crude abstraction of communication channels. An emerging class of languages <ref> [7, 21, 24, 27] </ref> lets the programmer define arbitrary parallel data structures spread across the machine and dynamically spawn computations to perform coordinated actions on these data structures. Dataflow machines attempt to realize these concepts directly in hardware. <p> This must be mapped onto a fixed set of physical processors. The chunk of work associated with a frame need not correspond exactly to a user-defined function in the program: it may be desirable to execute individual expressions in parallel, as with futures <ref> [24] </ref>, or to inline several calls to use a single frame. Frames could also represent the state of individual tasks, communicating through messages. The dynamic allocation of frames implies that the task structure need not be static.
Reference: [25] <author> P. J. Landin. </author> <title> The Mechanical Evaluation of Languages. </title> <journal> Computer Journal, </journal> <volume> 6(4) </volume> <pages> 308-320, </pages> <month> January </month> <year> 1964. </year>
Reference-contexts: Fortran, for example, did not support dynamic data structures or recursive control structures. The insistence on supporting these concepts in the Algol family of languages led to the development of abstract machines which demonstrated how to map the concepts to conventional hardware structures <ref> [25, 33] </ref>. This route proved more effective than supporting the language concepts directly in hardware [26]. By analogy, many current parallel languages remain close to the underlying machine, constraining the programmer to local data structures and static parallelism.
Reference: [26] <author> W. Lonergan and P. King. </author> <title> Design of the B5000 System. </title> <journal> Datamation, </journal> <month> May </month> <year> 1961. </year> <month> 33 </month>
Reference-contexts: The insistence on supporting these concepts in the Algol family of languages led to the development of abstract machines which demonstrated how to map the concepts to conventional hardware structures [25, 33]. This route proved more effective than supporting the language concepts directly in hardware <ref> [26] </ref>. By analogy, many current parallel languages remain close to the underlying machine, constraining the programmer to local data structures and static parallelism.
Reference: [27] <author> R. S. Nikhil. </author> <title> ID Language Reference Manual Version 90.1. </title> <type> Technical Report CSG Memo 284-2, </type> <institution> MIT Lab for Comp. Science, </institution> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: 1 Introduction Dataflow execution models have evolved considerably since their original formulation [1, 15], reflecting an improved understanding of hardware implementation techniques [1, 18, 16, 20, 31, 36], parallel programming languages <ref> [27, 30] </ref>, compilation methods [38, 43], and resource management strategies [9, 34]. Several hybrid models [5, 12, 23, 28] have been formulated which eliminate operand matching, avoid redundant synchronization, or use more conventional processor organizations. <p> For example, most extensions of Fortran and C with send/receive message passing provide exactly one thread of control per physical processor and a crude abstraction of communication channels. An emerging class of languages <ref> [7, 21, 24, 27] </ref> lets the programmer define arbitrary parallel data structures spread across the machine and dynamically spawn computations to perform coordinated actions on these data structures. Dataflow machines attempt to realize these concepts directly in hardware.
Reference: [28] <author> R. S. Nikhil and Arvind. </author> <title> Can Dataflow Subsume von Neumann Computing? In Proc. </title> <booktitle> of the 16th Annual Int. Symp. on Comp. Arch., </booktitle> <address> Jerusalem, Israel, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Dataflow execution models have evolved considerably since their original formulation [1, 15], reflecting an improved understanding of hardware implementation techniques [1, 18, 16, 20, 31, 36], parallel programming languages [27, 30], compilation methods [38, 43], and resource management strategies [9, 34]. Several hybrid models <ref> [5, 12, 23, 28] </ref> have been formulated which eliminate operand matching, avoid redundant synchronization, or use more conventional processor organizations. In addition, message driven models [14] demonstrate that the architecture need not dictate the format and handling of tokens, or rather, messages. <p> Scheduling (and the scheduling structure) is outside the programming model, so there is no means by which the compiler can organize the program to make efficient use of processor resources. P-Risc <ref> [28] </ref> observed that presence-bits can be kept in the frame like local data, rather than as special tags, and that matching could be simulated by toggling the tag bit atomically and suspending on the result. This is easily extended to a general counter, as in TAM.
Reference: [29] <author> R. S. Nikhil, G. M. Papadopoulos, and Arvind. </author> <title> *T: A Killer Micro for A Brave New World. </title> <type> Technical Report CSG Memo 325, </type> <institution> MIT Lab for Comp. Science, </institution> <address> Cambridge, MA, </address> <month> January </month> <year> 1991. </year>
Reference-contexts: The main cause for this high cost on the CM-5 is the slow access to the network interface across the node memory bus. Placing the NI on the cache bus or integrating it into a co-processor, for example as proposed in the MIT/Motorola *T project <ref> [29] </ref>, would reduce the overhead of messages considerably. 21 5 Dynamic Measurements In this section we present empirical data based on the implementation of TAM described above to validate the TAM approach and its effectiveness on current parallel machines.
Reference: [30] <author> R. R. Oldehoeft, D. C. Cann, A. P. W. Bohm, J. T. Feo, and D. H. Grit. </author> <title> SISAL Reference Manual Language Version 2.0. </title> <type> Technical Report UCRL-JC-104008, </type> <institution> Lawrence Livermore National Laboratory, Livermore, </institution> <address> CA, </address> <month> December </month> <year> 1988. </year>
Reference-contexts: 1 Introduction Dataflow execution models have evolved considerably since their original formulation [1, 15], reflecting an improved understanding of hardware implementation techniques [1, 18, 16, 20, 31, 36], parallel programming languages <ref> [27, 30] </ref>, compilation methods [38, 43], and resource management strategies [9, 34]. Several hybrid models [5, 12, 23, 28] have been formulated which eliminate operand matching, avoid redundant synchronization, or use more conventional processor organizations.
Reference: [31] <author> G. M. Papadopoulos and D. E. Culler. Monsoon: </author> <title> an Explicit Token-Store Architecture. </title> <booktitle> In Proc. of the 17th Annual Int. Symp. on Comp. Arch., </booktitle> <address> Seattle, Washington, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Dataflow execution models have evolved considerably since their original formulation [1, 15], reflecting an improved understanding of hardware implementation techniques <ref> [1, 18, 16, 20, 31, 36] </ref>, parallel programming languages [27, 30], compilation methods [38, 43], and resource management strategies [9, 34]. Several hybrid models [5, 12, 23, 28] have been formulated which eliminate operand matching, avoid redundant synchronization, or use more conventional processor organizations. <p> The Manchester machine [18] and 28 Sigma-1 [20] adopted an alternative approach of sticky match operations with similar drawbacks. 6.2 ETS The ETS model [12] embodied in Monsoon <ref> [31] </ref> is a partial remedy to these problems. Implicit allocation of the matching store is eliminated by explicitly allocating an activation frame to hold the local storage for each function invocation. Synchronization bits are associated with each frame location to support a dyadic match.
Reference: [32] <author> C. D. Polychronopoulos. </author> <title> Toward Auto-scheduling Compilers. </title> <journal> J. of Supercomputing, </journal> <volume> 2 </volume> <pages> 297-330, </pages> <year> 1988. </year>
Reference-contexts: Under TAM, this can be easily extended to handle nested loop parallelism, where each loop frame maintains several frames for iterations of the inner loop <ref> [32] </ref>. The assignment of iterations to frames can be addressed by a variety of policies. A very general form of parallel loop structure, called k-bounded loops [11], is used in compiling Id90.
Reference: [33] <author> B. Randell and L. J. Russell. </author> <title> Algol 60 Implementation. </title> <publisher> Academic Press, </publisher> <year> 1964. </year>
Reference-contexts: Fortran, for example, did not support dynamic data structures or recursive control structures. The insistence on supporting these concepts in the Algol family of languages led to the development of abstract machines which demonstrated how to map the concepts to conventional hardware structures <ref> [25, 33] </ref>. This route proved more effective than supporting the language concepts directly in hardware [26]. By analogy, many current parallel languages remain close to the underlying machine, constraining the programmer to local data structures and static parallelism.
Reference: [34] <author> C. A. Ruggiero. </author> <title> Throttle Mechanisms for the Manchester Dataflow Machine. </title> <type> PhD thesis, </type> <institution> University of Manch-ester, </institution> <address> Manchester M13 9PL, England, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: 1 Introduction Dataflow execution models have evolved considerably since their original formulation [1, 15], reflecting an improved understanding of hardware implementation techniques [1, 18, 16, 20, 31, 36], parallel programming languages [27, 30], compilation methods [38, 43], and resource management strategies <ref> [9, 34] </ref>. Several hybrid models [5, 12, 23, 28] have been formulated which eliminate operand matching, avoid redundant synchronization, or use more conventional processor organizations. In addition, message driven models [14] demonstrate that the architecture need not dictate the format and handling of tokens, or rather, messages.
Reference: [35] <author> R. Saavedra-Barrerra, D. E. Culler, and T. von Eicken. </author> <title> Analysis of Multithreaded Architectures for Parallel Computing. </title> <booktitle> In Proceedings of the 2nd Annual Symp. on Par. Algorithms and Arch., </booktitle> <month> July </month> <year> 1990. </year>
Reference-contexts: To keep the utilization of each processor at an acceptable level, it is important to treat remote accesses as split-phase operations, that is, to continue executing instructions while the access completes <ref> [17, 35] </ref>. In some cases this can be accomplished using prefetching techniques, but in general multiplexing several logical threads of control onto each processor, called multithreading, is required. Coordinating threads of control on separate processors presents similar concerns, but the latencies involved are usually longer and potentially unbounded.
Reference: [36] <author> S. Sakai, Y. Yamaguchi, K. Hiraki, Y. Kodama, and T. Yuba. </author> <title> An Architecture of a Dataflow Single Chip Processor. </title> <booktitle> In Proc. of the 16th Annual Int. Symp. on Comp. Arch., </booktitle> <pages> pages 46-53, </pages> <address> Jerusalem, Israel, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Dataflow execution models have evolved considerably since their original formulation [1, 15], reflecting an improved understanding of hardware implementation techniques <ref> [1, 18, 16, 20, 31, 36] </ref>, parallel programming languages [27, 30], compilation methods [38, 43], and resource management strategies [9, 34]. Several hybrid models [5, 12, 23, 28] have been formulated which eliminate operand matching, avoid redundant synchronization, or use more conventional processor organizations.
Reference: [37] <author> V. Sarkar and J. Hennessy. </author> <title> Partitioning Parallel Programs for Macro-Dataflow. </title> <booktitle> In Proceedings of the 1986 ACM Conference on Lisp and Functional Programming, </booktitle> <address> Cambridge, MA, </address> <pages> pages 202-211, </pages> <month> August 4-6 </month> <year> 1986. </year>
Reference-contexts: The compiler orders the instructions within a thread, and initializes the synchronization counters, such that all data and control dependencies are enforced. This is straight-forward for static dataflow graphs, where all dependencies are visible at compile time and no cycles exist <ref> [37] </ref>. 3.7 From dataflow graphs to threads Non-strict languages, such as Id90, introduce an additional compilation issue.
Reference: [38] <author> K. E. Schauser, D. Culler, and T. von Eicken. </author> <title> Compiler-controlled Multithreading for Lenient Parallel Languages. </title> <booktitle> In Proceedings of the 1991 Conference on Functional Programming Languages and Computer Architecture, </booktitle> <address> Cambridge, MA, </address> <month> August </month> <year> 1991. </year> <note> (Also available as Technical Report UCB/CSD 91/640, </note> <institution> CS Div., University of California at Berkeley). </institution>
Reference-contexts: 1 Introduction Dataflow execution models have evolved considerably since their original formulation [1, 15], reflecting an improved understanding of hardware implementation techniques [1, 18, 16, 20, 31, 36], parallel programming languages [27, 30], compilation methods <ref> [38, 43] </ref>, and resource management strategies [9, 34]. Several hybrid models [5, 12, 23, 28] have been formulated which eliminate operand matching, avoid redundant synchronization, or use more conventional processor organizations. <p> Demand analysis uses sets of outputs to establish independence. If two apparently independent nodes unconditionally affect the same set of outputs then neither can depend on the other, since the dependence would have to be conveyed through one of the outputs <ref> [38] </ref>. The compiler repeatedly reduces the dataflow graph into macro nodes representing threads using analysis of dependence sets (input nodes on which a node depends) and demand sets (output nodes that depend on the node) to drive the reduction process.
Reference: [39] <author> E. Spertus, S. C. Goldstein, K. E. Schauser, T. von Eicken, D. E. Culler, and W. J. Dally. </author> <title> Evaluation of Mechanisms for Fine-Grained Parallel Programs in the J-Machine and the CM-5. </title> <booktitle> In Proc. of the 20th Int'l Symposium on Computer Architecture, </booktitle> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: The division of work between inlets and threads suggests that separate processors should be considered, but to handle the frequent case of remote responses arriving during the issuing quantum there needs to be a very tight coupling between the two processors <ref> [39] </ref>. Looking at the anticipated evolution of microprocessor architectures, the reliance on branch prediction will be undermined by the TAM style of indirect transfer to threads. This is an interesting trade-off because the fork-based model allows ample opportunity for thread prefetching, which is lost when mapped to jumps and branches.
Reference: [40] <institution> Thinking Machines Corporation, Cambridge, Massachusetts. </institution> <note> The Connection Machine CM-5 Technical Summary, </note> <month> January </month> <year> 1992. </year>
Reference-contexts: Improvements in partitioning increase the thread length, decrease the number of dynamic scheduling events, and reduce the total number of synchronizations 14 by eliminating redundant ones. 4 Implementation of TAM This section describes an implementation of TAM on the CM-5 multiprocessor <ref> [40] </ref>. The discussion is centered around the thread language TL0 which takes a position on many of the alternatives left open in TAM by defining an instruction set with precise semantics.
Reference: [41] <author> K. R. Traub. </author> <title> A Compiler for the MIT Tagged-Token Dataflow Architecture. </title> <type> Technical Report TR-370, </type> <institution> MIT Lab for Comp. Science, </institution> <address> Cambridge, MA, </address> <month> August </month> <year> 1986. </year> <type> (MS Thesis, </type> <institution> Dept. of EECS, MIT). </institution>
Reference-contexts: To demonstrate the effectiveness of the TAM execution model, we have designed a threaded machine language, called TL0, and implemented a compilation path from Id90 to TL0. This uses the front-end of the MIT dataflow compiler, which produces program graphs <ref> [41] </ref> for the TTDA and Monsoon, with additional passes to partition the graph into threads and synthesize the control flow. The TL0 code is used as a machine independent intermediate form and can be input into a variety of code generators.
Reference: [42] <author> K. R. Traub. </author> <title> Compilation as Partitioning: A New Approach to Compiling Non-strict Functional Languages. </title> <booktitle> In Proc. of the Apenas Workshop on the Implmentation of Lazy Functional Languages, </booktitle> <institution> Chalmers Univ., Goteborg Sweden, </institution> <month> September </month> <year> 1988. </year> <month> 34 </month>
Reference-contexts: Frames could also represent the state of individual tasks, communicating through messages. The dynamic allocation of frames implies that the task structure need not be static. In fact, non-strict functional languages <ref> [42] </ref> behave at the TAM level like co-operating processes, since the child may need to return certain results in order for the parent to make further progress and deliver additional arguments. 11 At the other extreme, parallelism may be limited to a single loop.
Reference: [43] <author> K. R. Traub. </author> <title> Sequential Implementation of Lenient Programming Languages. </title> <type> Technical Report TR-417, </type> <institution> MIT Lab for Comp. Science, </institution> <address> Cambridge, MA, </address> <month> September </month> <year> 1988. </year> <type> (PhD Thesis, </type> <institution> Dept. of EECS, MIT). </institution>
Reference-contexts: 1 Introduction Dataflow execution models have evolved considerably since their original formulation [1, 15], reflecting an improved understanding of hardware implementation techniques [1, 18, 16, 20, 31, 36], parallel programming languages [27, 30], compilation methods <ref> [38, 43] </ref>, and resource management strategies [9, 34]. Several hybrid models [5, 12, 23, 28] have been formulated which eliminate operand matching, avoid redundant synchronization, or use more conventional processor organizations.
Reference: [44] <author> K. R. Traub, D. E. Culler, and K. E. Schauser. </author> <title> Global Analysis for Partitioning Non-Strict Programs into Sequential Threads. </title> <booktitle> In Proc. of the ACM Conf. on LISP and Functional Programming, </booktitle> <address> San Francisco, CA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Recent work shows how this analysis can be carried out globally <ref> [44] </ref>. Improvements in partitioning increase the thread length, decrease the number of dynamic scheduling events, and reduce the total number of synchronizations 14 by eliminating redundant ones. 4 Implementation of TAM This section describes an implementation of TAM on the CM-5 multiprocessor [40].
Reference: [45] <author> T. von Eicken, D. E. Culler, S. C. Goldstein, and K. E. Schauser. </author> <title> Active Messages: a Mechanism for Integrated Communication and Computation. </title> <booktitle> In Proc. of the 19th Int'l Symposium on Computer Architecture, </booktitle> <address> Gold Coast, Australia, </address> <month> May </month> <year> 1992. </year> <note> (Also available as Technical Report UCB/CSD 92/675, </note> <institution> CS Div., University of California at Berkeley). </institution> <month> 35 </month>
Reference-contexts: The TL0 code is used as a machine independent intermediate form and can be input into a variety of code generators. To date, we have implemented code generators to translate into either C or machine code augmented with Active Messages <ref> [45] </ref> or conventional message passing as the network interface. The code generator described in this paper targets the CM-5 multiprocessor, consisting of Sparc processors with a memory mapped network interface. The paper is organized as follows. <p> The communication model is efficient because no buffering is required in the communication layer. Storage to receive the message is pre-allocated in the frame so that the inlet can move the data directly from the network interface to the frame <ref> [45] </ref>. The Id90 compiler generates a specialized message handler for each heap reference, function argument, and result in the program text. This specialization reduces the message size, since the message format is encoded in the inlet, and reduces the cost of message handling, since no parsing is required.
References-found: 45

