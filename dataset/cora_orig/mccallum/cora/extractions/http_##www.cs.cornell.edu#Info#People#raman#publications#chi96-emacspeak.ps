URL: http://www.cs.cornell.edu/Info/People/raman/publications/chi96-emacspeak.ps
Refering-URL: http://www.cs.cornell.edu/Info/People/raman/publications/
Root-URL: 
Email: E-mail: hraman@crl.dec.comi  
Phone: Voice-mail: 1 (617) 692-7637 Fax: 1 (617) 692-6650  
Author: T. V. Raman 
Keyword: Speech Interface, Direct Access, Spoken Feedback, Audio Formatting, Speech as a first-class I/O medium.  
Address: Bldg 650, One Kendall Square Cambridge MA 02139  
Affiliation: Cambridge Research Lab Digital Equipment Corp.  
Abstract: Screen-readers |computer software that enables a visually impaired user to read the contents of a visual display| have been available for more than a decade. Screen-readers are separate from the user application. Consequently, they have little or no contextual information about the contents of the display. The author has used traditional screen-reading applications for the last five years. The design of the speech-enabling approach described here has been implemented in Emacspeak to overcome many of the shortcomings he has encountered with traditional screen-readers. The approach used by Emacspeak is very different from that of traditional screen-readers. Screen-readers allow the user to listen to the contents appearing in different parts of the display; but the user is entirely responsible for building a mental model of the visual display in order to interpret what an application is trying to convey. Emacspeak, on the other hand, does not speak the screen. Instead, applications provide both visual and speech feedback, and the speech feedback is designed to be sufficient by itself. This approach reduces cognitive load on the user and is relevant to providing general spoken access to information. Producing spoken output from within the application, rather than speaking the visually displayed information, vastly improves the quality of the spoken feedback. Thus, an application can display its results in a visually pleasing manner; the speech-enabling component renders the same in an aurally pleasing way. 
Abstract-found: 1
Intro-found: 1
Reference: [BGB88] <author> W. Buxton, W. Gaver, and S. Bly. </author> <title> The use of nonspeech audio at the interface. </title> <booktitle> Tutorial Notes, CHI '88., </booktitle> <year> 1988. </year>
Reference-contexts: This is a powerful method of conveying structure succinctly and was first described in [Ram94]. Audio Formatting is used to aurally set apart different syntactic units, for example, high light regions of text. * Emacspeak uses auditory icons <ref> [SMG90, BGB88, Gav93, BGP93, JSBG86] </ref> |short snippets of sounds (under 0:25-0:5 seconds) to cue common events such as selecting, opening and closing an object.
Reference: [BGP93] <author> Meera M. Blattner, Ephraim P. Glinert, and Albert L. Papp. </author> <title> Sonic Enhancements for 2-D Graphic Displays, and Auditory Displays. To be published by Addison-Wesley in the Santa Fe Institute Series. </title> <publisher> IEEE, </publisher> <year> 1993. </year>
Reference-contexts: This is a powerful method of conveying structure succinctly and was first described in [Ram94]. Audio Formatting is used to aurally set apart different syntactic units, for example, high light regions of text. * Emacspeak uses auditory icons <ref> [SMG90, BGB88, Gav93, BGP93, JSBG86] </ref> |short snippets of sounds (under 0:25-0:5 seconds) to cue common events such as selecting, opening and closing an object.
Reference: [Gav93] <author> William Gaver. </author> <title> Synthesizing auditory icons. </title> <booktitle> Proceedings of INTERCHI 1993, </booktitle> <pages> pages 228-235, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: This is a powerful method of conveying structure succinctly and was first described in [Ram94]. Audio Formatting is used to aurally set apart different syntactic units, for example, high light regions of text. * Emacspeak uses auditory icons <ref> [SMG90, BGB88, Gav93, BGP93, JSBG86] </ref> |short snippets of sounds (under 0:25-0:5 seconds) to cue common events such as selecting, opening and closing an object.
Reference: [JSBG86] <author> K. I. Joy, D. A. Sumikawa, M. M. Blattner, and R. M. Greenberg. </author> <title> Guidelines for the syntactic design of audio cues in computer interfaces. Nineteenth Annual Hawaii 7 He got tired of listening to my complaints about how inadequate screen-readers were. </title> <booktitle> International Conference on System Sciences, </booktitle> <year> 1986. </year>
Reference-contexts: This is a powerful method of conveying structure succinctly and was first described in [Ram94]. Audio Formatting is used to aurally set apart different syntactic units, for example, high light regions of text. * Emacspeak uses auditory icons <ref> [SMG90, BGB88, Gav93, BGP93, JSBG86] </ref> |short snippets of sounds (under 0:25-0:5 seconds) to cue common events such as selecting, opening and closing an object.
Reference: [ME92] <author> Elizabeth D. Mynatt and W. Keith Edwards. </author> <title> Mapping GUIs to auditory interfaces. </title> <booktitle> Proceedings ACM UIST92, </booktitle> <pages> pages 61-70, </pages> <year> 1992. </year>
Reference-contexts: Jim Thatcher at the IBM Wat-son Research Center [Tha94]. This package provides robust spoken access to applications under the OS2 Presentation Manager and Windows 3.1. Commercial packages for Microsoft Windows 3.1 provide varying levels of spoken access to the GUI. The Mercator project <ref> [ME92, WKES94, MW94, Myn94] </ref> has focused on providing spoken access to the X-Windows system. A common feature of traditional DOS-based screen-readers and speech access packages to the GUI is their attempt to convey the contents of the visual display via speech.
Reference: [MW94] <author> E.D. Mynatt and G. Weber. </author> <title> Nonvisual presentation of graphical user interfaces: Contrasting two approaches. </title> <booktitle> Proceedings of the 1994 ACM Conference on Human Factors in Computing Systems (CHI'94), </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: Jim Thatcher at the IBM Wat-son Research Center [Tha94]. This package provides robust spoken access to applications under the OS2 Presentation Manager and Windows 3.1. Commercial packages for Microsoft Windows 3.1 provide varying levels of spoken access to the GUI. The Mercator project <ref> [ME92, WKES94, MW94, Myn94] </ref> has focused on providing spoken access to the X-Windows system. A common feature of traditional DOS-based screen-readers and speech access packages to the GUI is their attempt to convey the contents of the visual display via speech.
Reference: [Myn94] <author> E.D. Mynatt. </author> <title> Auditory Presentation of Graphical User Interfaces. </title> <address> Santa Fe. </address> <publisher> Addison-Wesley: </publisher> <address> Reading MA.., </address> <year> 1994. </year>
Reference-contexts: Jim Thatcher at the IBM Wat-son Research Center [Tha94]. This package provides robust spoken access to applications under the OS2 Presentation Manager and Windows 3.1. Commercial packages for Microsoft Windows 3.1 provide varying levels of spoken access to the GUI. The Mercator project <ref> [ME92, WKES94, MW94, Myn94] </ref> has focused on providing spoken access to the X-Windows system. A common feature of traditional DOS-based screen-readers and speech access packages to the GUI is their attempt to convey the contents of the visual display via speech.
Reference: [Ram94] <author> T. V. Raman. </author> <title> Audio System for Technical Readings. </title> <type> PhD thesis, </type> <institution> Cornell University, </institution> <month> May </month> <year> 1994. </year> <note> URL http://www.research.digital.com/CRL /personal/raman/raman.html. </note>
Reference-contexts: Actions causing new information to be spoken first inter rupt any ongoing output. * Emacspeak provides a voice-lock facility that permits association of syntactic units of text with different voices. This is a powerful method of conveying structure succinctly and was first described in <ref> [Ram94] </ref>. Audio Formatting is used to aurally set apart different syntactic units, for example, high light regions of text. * Emacspeak uses auditory icons [SMG90, BGB88, Gav93, BGP93, JSBG86] |short snippets of sounds (under 0:25-0:5 seconds) to cue common events such as selecting, opening and closing an object.
Reference: [SMG90] <author> D. A. Sumikawa, Blattner M. M., and R. M. Greenberg. Earcons and icons: </author> <title> Their structure and common design principles. Visual Programming Environments, </title> <year> 1990. </year>
Reference-contexts: This is a powerful method of conveying structure succinctly and was first described in [Ram94]. Audio Formatting is used to aurally set apart different syntactic units, for example, high light regions of text. * Emacspeak uses auditory icons <ref> [SMG90, BGB88, Gav93, BGP93, JSBG86] </ref> |short snippets of sounds (under 0:25-0:5 seconds) to cue common events such as selecting, opening and closing an object.
Reference: [Tha94] <author> James Thatcher. </author> <title> Screen reader/2: Access to os/2 and the graphical user interface. </title> <booktitle> Proc. of The First Annual ACM Conference on Assistive Technologies (ASSETS '94), </booktitle> <pages> pages 39-47, </pages> <month> Nov </month> <year> 1994. </year>
Reference-contexts: The best and perhaps the most complete speech access system to the GUI is Screenreader/2 (ScreenReader For OS/2) developed by Dr. Jim Thatcher at the IBM Wat-son Research Center <ref> [Tha94] </ref>. This package provides robust spoken access to applications under the OS2 Presentation Manager and Windows 3.1. Commercial packages for Microsoft Windows 3.1 provide varying levels of spoken access to the GUI. The Mercator project [ME92, WKES94, MW94, Myn94] has focused on providing spoken access to the X-Windows system.
Reference: [WKES94] <author> E. D. Mynatt W. K. Edwards and K. Stockton. </author> <title> Providing access to graphical user interfaces not graphical screens. </title> <booktitle> Proc. Of The First Annual ACM Conference on Assistive Technologies (ASSETS '94), </booktitle> <pages> pages 47-54, </pages> <month> Nov </month> <year> 1994. </year>
Reference-contexts: Jim Thatcher at the IBM Wat-son Research Center [Tha94]. This package provides robust spoken access to applications under the OS2 Presentation Manager and Windows 3.1. Commercial packages for Microsoft Windows 3.1 provide varying levels of spoken access to the GUI. The Mercator project <ref> [ME92, WKES94, MW94, Myn94] </ref> has focused on providing spoken access to the X-Windows system. A common feature of traditional DOS-based screen-readers and speech access packages to the GUI is their attempt to convey the contents of the visual display via speech.
Reference: [YLM95] <author> Nicole Yankelovich, Gina Anne Levow, and Matt Marx. </author> <title> Designing speechacts: Issues in speech user interfaces. </title> <booktitle> In Proceedings of CHI95, Human Factors In Computing Systems, </booktitle> <pages> pages 369-376. </pages> <institution> Sun Micro Systems, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: As a case in point, when using the calendar application, the user hears the current date as Sunday, January 1, 1995. For related work in integrating speech as a first-class I/O medium into general user applications, see <ref> [YLM95] </ref>. We conclude this introduction by pointing out that visual layout plays an important role in cuing the reader to information structure.
References-found: 12

