URL: http://www.cs.dartmouth.edu/~nicol/papers/pucs.ps
Refering-URL: http://www.cs.dartmouth.edu/~nicol/papers/papers.html
Root-URL: http://www.cs.dartmouth.edu
Title: A Comparative Study of Parallel Algorithms for Simulating Continuous Time Markov Chains  
Author: David M. Nicol Philip Heidelberger 
Note: This research was partially supported by NASA Contract No. NAS1-19480 while the author was on sabbatical at the Institute for Computer Applications in  
Address: Williamsburg, Virginia 23185  P.O. Box 704 Yorktown Heights, New York 10598  Hampton Virginia 23681.  
Affiliation: Department of Computer Science The College of William and Mary  IBM Thomas J. Watson Research Center, Hawthorne  Science and Engineering (ICASE), NASA Langley Research Center,  
Abstract: This paper describes methods for simulating continuous time Markov chain models, using parallel architectures. The basis of our method is the technique of uniformization; within this framework there are a number of options concerning optimism and aggregation. We describe four different variations, paying particular attention to an adaptive method that optimistically assumes upper bounds on the rate at which one processor affects another in simulation time, and which recovers from violations of this assumption using global checkpoints. We describe our experiences with these methods on a variety of Intel multiprocessor architectures, including the Touchstone Delta, where excellent speedups of up to 220 using 256 processors are observed. fl Portions of this paper are reprinted with permission from "Parallel Algorithms for Simulating Continuous Time Markov Chains" in Proceedings of the 1993 Workshop on Parallel and Distributed Simulation, and from "Parallel Simulation of Markovian Queueing Networks Using Uniformization", in Proceedings of the 1993 ACM SIGMETRICS Conference. Copyright is owned by ACM. Appeared in ACM Trans. on Modeling and Simulation of Computer Systems, vol. 5, no. 4, October 1995, pp. 326-354. y This work was initiated while David Nicol was a visiting scientist at the IBM T.J. Watson Research Center. This work was also supported in part by NSF Grants ASC 8819373 and CCR-9201195, and NASA Grants NAG-1-1060 and NAG-1-995. This research was also partially supported by NASA Contract No. NAS1-19480 while the author was on sabbatical at the Institute for Computer Applications in Science and Engineering (ICASE), NASA Langley Research Center, Hampton Virginia 23681. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.P. Buzen, </author> <title> "Computational Algorithms for Closed Queueing Networks with Exponential Servers," </title> <journal> Commun. ACM, </journal> <volume> vol. 16, no. 9, </volume> <pages> pp. 527-531, </pages> <month> September </month> <year> 1973. </year>
Reference-contexts: Finally we identify model characteristics that may lead to excessive pseudo events. 4 2.1 Example The model consists of a number, P , of computing clusters. The model is a closed queueing network with J fi P jobs. Each cluster is a central server model (see <ref> [1] </ref>) with a single CPU and K I/O devices. All queueing disciplines are FCFS (an assumption that is not necessary for uniformization to work). The service times at the CPU are assumed to be exponentially distributed with rate c .
Reference: [2] <author> R.M. Fujimoto, </author> <title> "Parallel Discrete Event Simulation," </title> <journal> Commun. ACM, </journal> <volume> vol. 33, no. 10, </volume> <pages> pp. 31-53, </pages> <year> 1990. </year>
Reference-contexts: One of the key issues is synchronization between processors, as the synchronization demands are highly variable, depending dynamically on the simulation model's state. Comprehensive surveys on the topic are found in <ref> [2] </ref>, [21], and [15]. Parallel simulation is hard because synchronization between processors is very dynamic and often unpredictable.
Reference: [3] <author> R.M. Fujimoto, J.-J. Tsai and G.C. Gopalakrishnan, </author> <title> "Design and Evaluation of the Rollback Chip: Special Purpose Hardware for Time Warp," </title> <journal> IEEE Trans. Comput., </journal> <volume> vol. 41, no. 1, </volume> <pages> pp. 68-82, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: This recovery is made possible if the LP frequently saves its state. State-saving is usually cited as the leading source of overhead; the potential problem is severe enough that efforts to provide hardware support have been proposed <ref> [3] </ref>. Optimism can also be employed by periodically checkpointing the entire simulation state, simulating optimistically between checkpoints, and noting any errors that occur along the way due to optimism.
Reference: [4] <author> A. Greenberg, B. Lubachevsky, D. Nicol, and P. Wright. </author> <title> "Efficient Massively Parallel Simulation of Dynamic Channel Assignment Schemes for Wireless Cellular Communications", </title> <booktitle> Proceedings of the 1994 Workshop on Parallel and Distributed Simulation, to appear. </booktitle>
Reference-contexts: Such situations induce uniformized communication costs that are orders of magnitude larger than the ones induced by actual job transfer. Overly high uniformized rates have also been observed in a parallel simulation of a wireless network <ref> [4] </ref> when extended to include hand-offs.
Reference: [5] <editor> K.J. Gordon, R.F. Gordon, J.F. Kurose and E.A. MacNair. </editor> <title> "An Extensible Visual Environment for Construction and Analysis of Hierarchically-Structured Models of Resource Contention Systems," </title> <journal> Management Science, </journal> <volume> vol. 37, no. 6, </volume> <pages> pp. 714-732, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: In either case, it is clear that a very substantial improvement over serial execution is being achieved. As an additional point of comparison, we measured the execution rate of the commercial queueing network simulator RESQ <ref> [5] </ref>, executing on an IBM 3090 mainframe. The model simulated by RESQ is actually substantially smaller than this one, having only 16 clusters (due to memory constraints). The RESQ execution rate is only 1,781 events/sec, compared to PUCS execution rates in excess of 1,500,000 events/second.
Reference: [6] <author> D. Gross and D.R. Miller, </author> <title> "The Randomization Technique as a Modeling Tool and Solution Procedure for Transient Markov Processes," </title> <journal> Operations Research, </journal> <volume> vol. 32, no. 2, </volume> <pages> pp. 343-361, </pages> <month> March-April </month> <year> 1984. </year>
Reference-contexts: It suffices to construct the transition distribution by computing the rates Q NN 0 , and then sampling from the distribution fP NN 0 = Q NN 0 =(N)g. Uniformization of a CTMC is a mathematical device (originally used to simplify numerical solution <ref> [6] </ref>) designed so that every holding time is drawn from the same distribution. The basic idea is to find a uniformization rate max such that for every state N, (N) max . All holding times are sampled from the exponential distribution with rate max .
Reference: [7] <author> P. Heidelberger and D.M. Nicol, </author> <title> "Conservative Parallel Simulation of Continuous Time Markov Chains Using Uniformization", </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> vol. 4, no. 8, </volume> <pages> pp. 906-921. </pages>
Reference-contexts: This sort of approach is promising when state-saving costs are high, and errors are very rare; it has proven to be successful in simulating "colliding pucks" [13] and is the approach we will take with one of our methods. In a series of previous papers <ref> [7, 16, 17, 18] </ref> we have investigated the idea of using uniformization as the basis for synchronization in parallel discrete-event simulation of continuous-time Markov chains (CTMCs). CTMC models are important, appearing frequently in the study of computer and communication systems. <p> Section 4 presents and analyzes our experimental results, and Section 5 gives our conclusions. 2 Uniformization-Based Synchronization In this section we describe the basic notions of direct Markovian simulation, and uniformization. More rigorous and complete mathematical details can be found in <ref> [7] </ref>. Following the descriptions we illustrate them concretely with an example. Let us first review some basic elements of the theory of CTMCs. Readers unfamiliar with CTMCs are encouraged to consult Ross [23] for a more complete and exact introduction to the topic. <p> We have explored a number of logical and implementation issues for uniformization based synchronization. As we will report on the performance of each, we now briefly cover their salient points. 2.3 Conservative Aggregated PUCS CA-PUCS (identified simply as PUCS in <ref> [7, 16, 17] </ref>) was one of the first methods we developed. In implementation it is almost identical to the description given in the last section. <p> Models of this structure were also used for experimentation in <ref> [7] </ref> and [16]. The model has a few simple parameters that can be varied to study the effect on speedup. <p> In all experiments, the model parameters were set so that good parallel performance is achievable if enough external pseudo event communications can be eliminated. Speedups were calculated 14 relative to an efficient serial simulator similar to the one described in <ref> [7] </ref> and [16]. The models were run for a sufficiently long time so that stable estimates of the event processing rate (the number of real events executed per unit of real time) were obtained.
Reference: [8] <author> Intel Corporation, </author> <title> Paragon User's Guide, Order Number 312489-002, </title> <month> October, </month> <year> 1993. </year>
Reference-contexts: To give an overview of uniformization-based synchronization. 2. To describe an adaptive algorithm that dynamically adjusts the rate at which LPs synchronize. 3. To empirically examine these different methods on a variety of Intel multiprocessors, including the iPSC/2 [20], the Intel Touchstone Delta [11], and the Intel Paragon <ref> [8] </ref>. These studies show that the adaptive algorithm is the most robust of our implementations. It is capable of providing good performance over a wider range of problems than any of our other algorithms.
Reference: [9] <author> D. R. Jefferson, </author> <title> "Virtual Time," </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> vol. 7, no. 3, </volume> <pages> pp. 404 - 425, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: Thus execution of the event e is guaranteed to be correct. In an optimistic method (e.g., Time Warp <ref> [9] </ref>) an LP may execute e before it is certain that e is correct. <p> When the message does finally arrive, if the receiving LP's guess was correct, then there is no need to roll back. This is an application of the idea of "lazy reevaluation" explored first in [25]. Otherwise, as with standard optimistic algorithms such as Time Warp <ref> [9] </ref>, the receiving LP is rolled back to the time of the late message.
Reference: [10] <author> P.A.W. Lewis and G.S. Shedler, </author> <title> "Simulation of Nonhomogeneous Poisson Processes by Thinning," </title> <journal> Naval Research Logistics Quarterly, </journal> <volume> vol. 26, no. 3, </volume> <pages> pp. 403-413, </pages> <month> September </month> <year> 1979. </year>
Reference-contexts: During the simulation run P i randomly decides at each such pre-chosen synchronization point whether to actually make a transition that affects P j , in effect "thinning" (see <ref> [10] </ref>) the Poisson process. The probability of making such a transition depends on the state of P i 's submodel at that instant. P i must send a message to P j indicating either that the threatened transition occurred, or that the communication event is a pseudo. <p> Before describing the algorithm, we note that the uniformization approach is valid even if one "thins" a non-homogeneous Poisson process (NHPP) with non-constant rate (see <ref> [10, 24] </ref>). 11 More specifically, samples from a NHPP fN (t)g with rate (t) can be generated by thinning a NHPP fN fi (t)g with rate fi (t) ((t) fi (t) for all t), i.e., an event at time T in N fi (t) is accepted as an event in fN
Reference: [11] <author> S.L. Lillevik, </author> <title> "The Touchstone 30 Gigaflop DELTA Prototype", </title> <booktitle> Proceedings of the 1991 Distributed Memory Computer Conference, </booktitle> <publisher> IEEE Press, </publisher> <pages> pp. 671-677, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: To give an overview of uniformization-based synchronization. 2. To describe an adaptive algorithm that dynamically adjusts the rate at which LPs synchronize. 3. To empirically examine these different methods on a variety of Intel multiprocessors, including the iPSC/2 [20], the Intel Touchstone Delta <ref> [11] </ref>, and the Intel Paragon [8]. These studies show that the adaptive algorithm is the most robust of our implementations. It is capable of providing good performance over a wider range of problems than any of our other algorithms. <p> In the remainder we will speak only of the "aggregated" APUCS algorithm as presented, with the understanding that an alternative partitioned form is feasible. 4 Experiments Comparing Alternative Algorithms In this section we present the results of experiments performed on the Intel Touchstone Delta multiprocessor <ref> [11] </ref>, using 16, 64 and 256 processors, as well as results using 16, 32, and 64 nodes of the Intel Paragon.
Reference: [12] <author> B.D. Lubachevsky, </author> <title> "Efficient Parallel Simulations of Asynchronous Cellular Arrays", </title> <journal> Complex Systems, </journal> <volume> vol. 1, </volume> <pages> pp. 1099-1123, </pages> <year> 1987. </year>
Reference-contexts: In the second phase one randomly generates synchronization points; in the third phase one simulates a mathematically correct sample path through those points. We call the general method PUCS, for Parallel Uniformized Continuous-time Simulation. This approach generalizes Lubachevsky's algorithm <ref> [12] </ref> for simulating cellular arrays. We have developed four different variations of PUCS that differ in their treatment of LP aggregation, communication management, use of optimism, and generation of communication schedules. Each of these methods has strengths and weaknesses that are alternatively revealed by problem characteristics.
Reference: [13] <author> B.D. Lubachevsky, </author> <title> "Simulating Colliding Rigid Disks in Parallel Using Bounded Lag Without Time Warp", Distributed Simulation, </title> <booktitle> 1990, Simulation Series vol. </booktitle> <volume> 22, no. 2., </volume> <pages> pp. 194-204, </pages> <month> January </month> <year> 1990. </year> <month> 27 </month>
Reference-contexts: This sort of approach is promising when state-saving costs are high, and errors are very rare; it has proven to be successful in simulating "colliding pucks" <ref> [13] </ref> and is the approach we will take with one of our methods. In a series of previous papers [7, 16, 17, 18] we have investigated the idea of using uniformization as the basis for synchronization in parallel discrete-event simulation of continuous-time Markov chains (CTMCs).
Reference: [14] <author> D.M. Nicol, </author> <title> "Parallel Discrete-Event Simulation of FCFS Stochastic Queueing Networks," </title> <booktitle> Proceedings of the ACM/SIGPLAN PPEALS 1988. Parallel Programming: Experiences with Applications, Languages and Systems. </booktitle> <publisher> ACM Press, </publisher> <pages> pp. 124-137, </pages> <year> 1988. </year>
Reference: [15] <author> D.M. Nicol and R. Fujimoto, </author> <title> "Parallel Simulation Today", </title> <journal> Annals of Operations Research, </journal> <pages> pp. 249-286, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: One of the key issues is synchronization between processors, as the synchronization demands are highly variable, depending dynamically on the simulation model's state. Comprehensive surveys on the topic are found in [2], [21], and <ref> [15] </ref>. Parallel simulation is hard because synchronization between processors is very dynamic and often unpredictable. Each processor maintains its own simulation clock, and we require that the end result of the simulation be consistent with a scenario in which every processor executes its time-stamped events in monotone increasing order.
Reference: [16] <author> D.M. Nicol and P. Heidelberger, </author> <title> "Optimistic Parallel Simulation of Continuous Time Markov Chains Using Uniformization", </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol. 18, no. 4, </volume> <pages> pp. 395-410, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: This sort of approach is promising when state-saving costs are high, and errors are very rare; it has proven to be successful in simulating "colliding pucks" [13] and is the approach we will take with one of our methods. In a series of previous papers <ref> [7, 16, 17, 18] </ref> we have investigated the idea of using uniformization as the basis for synchronization in parallel discrete-event simulation of continuous-time Markov chains (CTMCs). CTMC models are important, appearing frequently in the study of computer and communication systems. <p> We have explored a number of logical and implementation issues for uniformization based synchronization. As we will report on the performance of each, we now briefly cover their salient points. 2.3 Conservative Aggregated PUCS CA-PUCS (identified simply as PUCS in <ref> [7, 16, 17] </ref>) was one of the first methods we developed. In implementation it is almost identical to the description given in the last section. <p> However, it may be that another piece of the submodel is free to continue past time t. To block at time t is to cheat oneself of some potential parallelism. CP-PUCS (identified as PUCSThreads in <ref> [16] </ref>) allows multiple LPs per processor, and also strives to reduce the communication overhead of list generation. The principle features of the method are * LP independence: A processor may manage any number of distinct LPs. <p> However, as we will see, data in the present paper shows that this is not always the case and there are situations in which CP-PUCS outperforms CA-PUCS. We will comment more on this in Section 4. 2.4 Optimistic PUCS Opt-PUCS (identified in <ref> [16] </ref> as OptAll) endows CP-PUCS with optimism. This comes into play when an LP reaches an incoming communication instant, and the message it is to receive is not yet present. <p> However, if either LP j was unsure at time t, or if the LP i decides to optimistically bypass that communication, then LP i becomes unsure. In <ref> [16] </ref> we show how every LP can maintain a Least Sure Time (LST) that describes the last instant in simulation time when the LP was sure. By simply appending sure/unsure tags to messages and analyzing these, every LP's LST advances without extra calculation. <p> In fact, our studies in <ref> [16] </ref> found that a very effective scheduling strategy is one that is averse to state-saving, as follows. <p> Models of this structure were also used for experimentation in [7] and <ref> [16] </ref>. The model has a few simple parameters that can be varied to study the effect on speedup. <p> In all experiments, the model parameters were set so that good parallel performance is achievable if enough external pseudo event communications can be eliminated. Speedups were calculated 14 relative to an efficient serial simulator similar to the one described in [7] and <ref> [16] </ref>. The models were run for a sufficiently long time so that stable estimates of the event processing rate (the number of real events executed per unit of real time) were obtained.
Reference: [17] <author> D.M. Nicol and P. Heidelberger, </author> <title> "Parallel Simulation of Markovian Queueing Networks Using Adaptive Uniformization", </title> <booktitle> Proceedings of the 1993 ACM SIGMETRICS Conference, </booktitle> <publisher> ACM Press, </publisher> <pages> pp. 135-145. </pages>
Reference-contexts: This sort of approach is promising when state-saving costs are high, and errors are very rare; it has proven to be successful in simulating "colliding pucks" [13] and is the approach we will take with one of our methods. In a series of previous papers <ref> [7, 16, 17, 18] </ref> we have investigated the idea of using uniformization as the basis for synchronization in parallel discrete-event simulation of continuous-time Markov chains (CTMCs). CTMC models are important, appearing frequently in the study of computer and communication systems. <p> It is capable of providing good performance over a wider range of problems than any of our other algorithms. A description of the adaptive method and a preliminary empirical comparison previously appeared only in conference proceedings papers <ref> [17, 18] </ref>. Not all CTMCs are suitable for parallel simulation using our methods. A key requirement is that one be able to partition the CTMC into loosely synchronous interacting subchains. <p> We have explored a number of logical and implementation issues for uniformization based synchronization. As we will report on the performance of each, we now briefly cover their salient points. 2.3 Conservative Aggregated PUCS CA-PUCS (identified simply as PUCS in <ref> [7, 16, 17] </ref>) was one of the first methods we developed. In implementation it is almost identical to the description given in the last section. <p> large rates are rare and that the model is not initialized in such a way as to artificially introduce a large rate at the beginning of the simulation.) The selection of the parameter fi is an important issue, which we will address experimentally (we have also addressed it theoretically in <ref> [17] </ref>). Our intuition is that in many models max ij (t) will grow slowly after an initial warm-up period, and therefore picking a modest value of fi will both protect against rate faults and keep the level of interprocessor communications reasonable. <p> For example, with a window size of 1000 and fi = 1:25, the Set I execution rate is about 45,000 events/second; with fi = 2:00 no rate faults occur and the execution rate is about 80,000 events/second. These observations (and the analysis in <ref> [17] </ref>) suggest that fi should be set rather conservatively. Setting fi = 2 permits up to double the number of occurrences of whatever phenomenon defined the base rate without incurring a rate fault.
Reference: [18] <author> D.M. Nicol and P. Heidelberger, </author> <title> "Parallel Algorithms for Simulating Continuous Time Markov Chains", </title> <booktitle> Proceedings of the 7th Workshop on Parallel and Distributed Simulation (PADS93), </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 11-18 </pages>
Reference-contexts: This sort of approach is promising when state-saving costs are high, and errors are very rare; it has proven to be successful in simulating "colliding pucks" [13] and is the approach we will take with one of our methods. In a series of previous papers <ref> [7, 16, 17, 18] </ref> we have investigated the idea of using uniformization as the basis for synchronization in parallel discrete-event simulation of continuous-time Markov chains (CTMCs). CTMC models are important, appearing frequently in the study of computer and communication systems. <p> It is capable of providing good performance over a wider range of problems than any of our other algorithms. A description of the adaptive method and a preliminary empirical comparison previously appeared only in conference proceedings papers <ref> [17, 18] </ref>. Not all CTMCs are suitable for parallel simulation using our methods. A key requirement is that one be able to partition the CTMC into loosely synchronous interacting subchains.
Reference: [19] <author> D.M. Nicol and P. Heidelberger, </author> <title> "On Extending Parallelism to Serial Simulators", </title> <booktitle> Proceedings of the 9th Workshop on Parallel and Distributed Simulation (PADS95)), </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 60-67. </pages>
Reference-contexts: We are dealing with both of these issues in the context of a tool we call the Utilitarian Parallel Simulator (U.P.S.). U.P.S. extends parallel processing to an existing serial simulator, CSIM [22], through libraries used in conjunction with CSIM models. A preliminary report on which appears in <ref> [19] </ref>. We hope to address partitioning and load-balancing problems in U.P.S. as well. 25 Acknowledgments This research was performed in part using the Intel Touchstone Delta System operated by Cal. Tech. on behalf of the Concurrent Supercomputing Consortium.
Reference: [20] <author> J. Rattner, </author> <title> "Concurrent Processing: a new direction in scientific computing", </title> <booktitle> In AFIPS Conference Proceedings, National Computer Conference, </booktitle> <volume> vol. 54, pp.157-166, </volume> <year> 1985. </year>
Reference-contexts: The objectives and contributions of this paper are: 1. To give an overview of uniformization-based synchronization. 2. To describe an adaptive algorithm that dynamically adjusts the rate at which LPs synchronize. 3. To empirically examine these different methods on a variety of Intel multiprocessors, including the iPSC/2 <ref> [20] </ref>, the Intel Touchstone Delta [11], and the Intel Paragon [8]. These studies show that the adaptive algorithm is the most robust of our implementations. It is capable of providing good performance over a wider range of problems than any of our other algorithms.
Reference: [21] <author> R. Righter and J.V. Walrand, </author> <title> "Distributed Simulation of Discrete Event Systems," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 77, no. 1, </volume> <pages> pp. 99-113, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: One of the key issues is synchronization between processors, as the synchronization demands are highly variable, depending dynamically on the simulation model's state. Comprehensive surveys on the topic are found in [2], <ref> [21] </ref>, and [15]. Parallel simulation is hard because synchronization between processors is very dynamic and often unpredictable.
Reference: [22] <author> H. Schwetman. CSIM : A C-based, </author> <title> process oriented simulation language. </title> <booktitle> In Proceedings of the 1986 Winter Simulation Conference, </booktitle> <pages> pages 387-396, </pages> <year> 1986. </year>
Reference-contexts: We are dealing with both of these issues in the context of a tool we call the Utilitarian Parallel Simulator (U.P.S.). U.P.S. extends parallel processing to an existing serial simulator, CSIM <ref> [22] </ref>, through libraries used in conjunction with CSIM models. A preliminary report on which appears in [19]. We hope to address partitioning and load-balancing problems in U.P.S. as well. 25 Acknowledgments This research was performed in part using the Intel Touchstone Delta System operated by Cal.
Reference: [23] <author> S. Ross, </author> <title> "Stochastic Processes", </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: More rigorous and complete mathematical details can be found in [7]. Following the descriptions we illustrate them concretely with an example. Let us first review some basic elements of the theory of CTMCs. Readers unfamiliar with CTMCs are encouraged to consult Ross <ref> [23] </ref> for a more complete and exact introduction to the topic. A CTMC is a stochastic process fX (t)g, where X (t) is the state of the CTMC at time t.
Reference: [24] <author> J.G. Shanthikumar, </author> <title> "Uniformization and Hybrid Simulation/Analytic Models of Renewal Processes," </title> <journal> Operations Research, </journal> <volume> vol. 34, no. 4, </volume> <pages> pp. 573-580, </pages> <month> July-August </month> <year> 1986. </year>
Reference-contexts: Before describing the algorithm, we note that the uniformization approach is valid even if one "thins" a non-homogeneous Poisson process (NHPP) with non-constant rate (see <ref> [10, 24] </ref>). 11 More specifically, samples from a NHPP fN (t)g with rate (t) can be generated by thinning a NHPP fN fi (t)g with rate fi (t) ((t) fi (t) for all t), i.e., an event at time T in N fi (t) is accepted as an event in fN
Reference: [25] <author> D. West, </author> <title> Lazy Rollback and Lazy Reevaluation, M.S. </title> <type> Thesis, </type> <institution> University of Calgary, </institution> <month> January </month> <year> 1988. </year>
Reference-contexts: When the message does finally arrive, if the receiving LP's guess was correct, then there is no need to roll back. This is an application of the idea of "lazy reevaluation" explored first in <ref> [25] </ref>. Otherwise, as with standard optimistic algorithms such as Time Warp [9], the receiving LP is rolled back to the time of the late message.
References-found: 25

