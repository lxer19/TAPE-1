URL: http://www.eecs.umich.edu/~qstout/pap/Seattle98.ps.Z
Refering-URL: http://www.eecs.umich.edu/~qstout/papers.html
Root-URL: http://www.eecs.umich.edu
Title: In New Developments and Applications in Experimental Design, FLEXIBLE ALGORITHMS FOR CREATING AND ANALYZING ADAPTIVE
Author: N. Flournoy, W.F. Rosenberger, and W.K. Wong, By Janis P. Hardwick and Quentin F. Stout 
Address: Ann Arbor, MI 48109  
Affiliation: University of Michigan,  
Note: eds., Institute of Math. Stat. Lecture Notes Monograph Series Vol. 34, 1998, pp. 91-105.  
Abstract: We describe a collection of algorithms and techniques that have been developed to aid in the design and analysis of adaptive allocation procedures. The emphasis is on providing flexibility to the investigator, so that appropriate statistical and practical concerns can be addressed directly. The techniques described allow for optimizations previously not attainable. They also permit exact evaluations for a wide range of criteria and are intended to encourage investigators to explore more alternatives. Optimizations investigated include 2- and 3-population fully sequential models, few-stage models, and models with constrained switching between options. One of our algorithmic approaches, path induction, speeds up the process of evaluating a procedure multiple times so that thorough robustness studies can be undertaken. Our approaches can be utilized with both Bayesian and frequentist analyses. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Agrawal, R., Hegde, M.V., and Teneketzis, D. </author> <year> (1988), </year> <title> "Asymptotically efficient adaptive allocation rules for the multiarmed bandit problem with switching costs", </title> <journal> IEEE Trans. Auto. </journal> <volume> Cont. </volume> <pages> 33 899-906. </pages>
Reference-contexts: There is an upper bound, S, on the number of times you can switch during the experiment. While cost structures of the sort listed can be important to investigators, they are seldom incorporated into experimental procedures. One exception comes up in certain control theory problems <ref> [1, 22] </ref> in which cost structures such as (1) are utilized. However, the results in [1, 22] are applicable only to the special case in which there is geometric discounting of an infinite horizon and no terminal objective. <p> While cost structures of the sort listed can be important to investigators, they are seldom incorporated into experimental procedures. One exception comes up in certain control theory problems <ref> [1, 22] </ref> in which cost structures such as (1) are utilized. However, the results in [1, 22] are applicable only to the special case in which there is geometric discounting of an infinite horizon and no terminal objective.
Reference: [2] <author> Armitage, P. </author> <year> (1985), </year> <title> "The search for optimality in clinical trials", </title> <journal> Int. Statist. Rev. </journal> <pages> 53 15-24. </pages>
Reference: [3] <author> Bellman, R. </author> <year> (1956), </year> <title> "A problem in the sequential design of experiments", </title> <note> Sankhya A 16 221-229. </note>
Reference: [4] <author> Berry, D.A. and Eick, S.G. </author> <year> (1995), </year> <title> "Adaptive assignment versus balanced randomization in clinical trials | a decision-analysis", </title> <journal> Statist. in Med. </journal> <pages> 14 231-246. </pages>
Reference: [5] <author> Berry, D.A. and Fristedt, B. </author> <year> (1985), </year> <title> Bandit Problems: Sequential Allocation of Experiments, </title> <publisher> Chapman and Hall. </publisher>
Reference-contexts: A number of different types of goals can be treated using the techniques discussed here, and we have selected two problems to serve as examples. The first is the classic multi-armed bandit problem with finite horizon n, <ref> [5] </ref>, where the objective is to sample from among a Bernoulli populations (the "arms") in such a way that the sum of the n observations is maximized.
Reference: [6] <author> Betensky, R. A. </author> <year> (1996), </year> <title> "An O'Brien-Fleming sequential trial for comparing three treatments", </title> <journal> Annals of Statistics 24 1765-1791. </journal>
Reference-contexts: Such problems are of great interest, particularly in the design of clinical trials to sequentially select or test among several populations (e.g., see <ref> [6, 8, 9, 10, 26, 30] </ref>). We know of no prior work in which exact, optimal solutions for fully sequential problems with 3 or more populations are determined. In [12], we describe initial work on the Bernoulli 3-population fully sequential problem with samples up to n = 100.
Reference: [7] <author> Bradt, R. and Karlin, S. </author> <year> (1956), </year> <title> "On the design and comparison of certain dichotomous experiments", </title> <journal> Ann. Math. Statist. </journal> <pages> 27 390-409. </pages>
Reference: [8] <author> Buringer, H., Martin, H. and Schriever, K.H. </author> <year> (1980), </year> <title> Nonparametric Sequential Selection Procedures, </title> <publisher> Birkhauser. </publisher>
Reference-contexts: Such problems are of great interest, particularly in the design of clinical trials to sequentially select or test among several populations (e.g., see <ref> [6, 8, 9, 10, 26, 30] </ref>). We know of no prior work in which exact, optimal solutions for fully sequential problems with 3 or more populations are determined. In [12], we describe initial work on the Bernoulli 3-population fully sequential problem with samples up to n = 100.
Reference: [9] <author> Coad, D. S. </author> <year> (1993), </year> <title> "Sequential allocation involving several treatments", Adaptive Designs (N. </title> <editor> Flournoy & W. F. Rosenberger, ed.'s), </editor> <booktitle> Institute Math. Stat. Lec. Notes 25, </booktitle> <pages> pp. 95-109. </pages>
Reference-contexts: Such problems are of great interest, particularly in the design of clinical trials to sequentially select or test among several populations (e.g., see <ref> [6, 8, 9, 10, 26, 30] </ref>). We know of no prior work in which exact, optimal solutions for fully sequential problems with 3 or more populations are determined. In [12], we describe initial work on the Bernoulli 3-population fully sequential problem with samples up to n = 100.
Reference: [10] <author> Cheng, Y. </author> <title> (1994) "Multistage decision procedures", </title> <journal> Seq. Anal. </journal> <pages> 13 329-349. </pages>
Reference-contexts: Such problems are of great interest, particularly in the design of clinical trials to sequentially select or test among several populations (e.g., see <ref> [6, 8, 9, 10, 26, 30] </ref>). We know of no prior work in which exact, optimal solutions for fully sequential problems with 3 or more populations are determined. In [12], we describe initial work on the Bernoulli 3-population fully sequential problem with samples up to n = 100.
Reference: [11] <author> Hall, P. </author> <year> (1981), </year> <title> "Asymptotic theory of triple sampling for sequential estimation of a mean", </title> <journal> Ann. Statist. </journal> <pages> 9 1229-1238. </pages>
Reference-contexts: Uniform Priors Slope = 0.82 Slope = 0.5 There has been a tendency to use asymptotic analyses to address the first of these questions, but the answers came in weak forms indicating, for example, that a given 2-stage procedure is first-order optimal or a given 3-stage procedure is second-order optimal, <ref> [11] </ref>. For any specific sample size, however, these results do not indicate whether the given procedure is 95% of optimal or merely 50% of optimal. The type of asymptotic results available for the last two questions are even weaker.
Reference: [12] <author> Hardwick, J., Oehmke, R. and Stout, Q.F. </author> <year> (1997), </year> <title> "A parallel program for 3-arm bandits", </title> <journal> Comp. Sci. and Statist. </journal> <pages> 29 390-395. </pages>
Reference-contexts: Our goal is to help researchers utilize adaptive allocation by creating a collection of algorithms to optimize and analyze a variety of sequential procedures. The techniques are detailed in <ref> [12, 15, 16, 18, 20, 21, 13] </ref>. The intent here is to illustrate how this growing suite of algorithms allows researchers the flexibility to incorporate a variety of statistical objectives and operational considerations into Research supported in part by National Science Foundation under grants DMS-9157715 and DMS-9504980. <p> We know of no prior work in which exact, optimal solutions for fully sequential problems with 3 or more populations are determined. In <ref> [12] </ref>, we describe initial work on the Bernoulli 3-population fully sequential problem with samples up to n = 100.
Reference: [13] <author> Hardwick, J., Oehmke, R. and Stout, Q.F. </author> <year> (1998), </year> <title> "Adaptive allocation in the presence of censoring" Computing Science and Statistics 30, </title> <note> to appear. </note>
Reference-contexts: Our goal is to help researchers utilize adaptive allocation by creating a collection of algorithms to optimize and analyze a variety of sequential procedures. The techniques are detailed in <ref> [12, 15, 16, 18, 20, 21, 13] </ref>. The intent here is to illustrate how this growing suite of algorithms allows researchers the flexibility to incorporate a variety of statistical objectives and operational considerations into Research supported in part by National Science Foundation under grants DMS-9157715 and DMS-9504980. <p> adaptive procedures for situations in which * the responses are delayed and hence not available before allocations must be decided, * covariate information needs to be incorporated (e.g., dose response settings), * equal allocation approaches are optimized for criteria such as stopping time [15], and * censoring of observations occurs <ref> [13] </ref>. Progress has been made on all of these, although much work (and more variations) remains to be done. Finally, we remind the reader that the different algorithms correspond to different classes of procedures or analyses, and not to different objective functions.
Reference: [14] <author> Hardwick, J. and Stout, Q.F. </author> <year> (1991), </year> <title> "Bandit strategies for ethical sequential allocation", </title> <journal> Comp. Sci. and Statist. </journal> <pages> 23 421-424. </pages>
Reference-contexts: Concurrently, in 1991 we addressed virtually the same variation with samples of size n = 150 using a modest desktop workstation <ref> [14] </ref>, and by 1993 were solving problems of size n = 400. Further, we needed to evaluate the procedures 100 times to determine the probability of correct selection.
Reference: [15] <author> Hardwick, J. and Stout, Q.F. </author> <year> (1993), </year> <title> "Optimal adaptive equal allocation rules", </title> <journal> Comp. Sci. and Statist. </journal> <pages> 24 597-601. </pages>
Reference-contexts: Our goal is to help researchers utilize adaptive allocation by creating a collection of algorithms to optimize and analyze a variety of sequential procedures. The techniques are detailed in <ref> [12, 15, 16, 18, 20, 21, 13] </ref>. The intent here is to illustrate how this growing suite of algorithms allows researchers the flexibility to incorporate a variety of statistical objectives and operational considerations into Research supported in part by National Science Foundation under grants DMS-9157715 and DMS-9504980. <p> To simplify the discussion, the total number of observations, n, is fixed. It is important to note that this is merely for convenience in describing the complexity of the algorithms, and is not a requirement of the procedures. For example, in <ref> [15] </ref>, n represents the maximum possible number of observations, where optional stopping is available and the goal is to minimize the expected number of observations needed. <p> investigation include the development of algorithms for adaptive procedures for situations in which * the responses are delayed and hence not available before allocations must be decided, * covariate information needs to be incorporated (e.g., dose response settings), * equal allocation approaches are optimized for criteria such as stopping time <ref> [15] </ref>, and * censoring of observations occurs [13]. Progress has been made on all of these, although much work (and more variations) remains to be done. Finally, we remind the reader that the different algorithms correspond to different classes of procedures or analyses, and not to different objective functions.
Reference: [16] <author> Hardwick, J. and Stout, Q.F. </author> <year> (1993), </year> <title> "Exact computational analyses for adaptive designs", Adaptive Designs (N. </title> <editor> Flournoy & W. F. Rosenberger, ed.'s), </editor> <title> Inst. </title> <journal> Math. Stat. </journal> <note> Lec. Notes 25 223-237. </note>
Reference-contexts: Our goal is to help researchers utilize adaptive allocation by creating a collection of algorithms to optimize and analyze a variety of sequential procedures. The techniques are detailed in <ref> [12, 15, 16, 18, 20, 21, 13] </ref>. The intent here is to illustrate how this growing suite of algorithms allows researchers the flexibility to incorporate a variety of statistical objectives and operational considerations into Research supported in part by National Science Foundation under grants DMS-9157715 and DMS-9504980. <p> More recently, however, refined algorithms, careful implementations, and ongoing advances in computer speed and memory, have greatly extended the range of sample sizes that can be exactly evaluated. Some of the techniques for careful implementation are detailed in <ref> [16] </ref>. To be specific as to the benefits claimed, it is our understanding that, prior to our work, the largest 2-population fully sequential problem that had been solved appeared in Berry and Eick (1995).
Reference: [17] <author> Hardwick, J. and Stout, Q.F. </author> <year> (1995), </year> <title> "Determining optimal few stage allocation rules", </title> <journal> Comp. Sci. and Statist. </journal> <volume> 27 342-346. </volume> <pages> 12 </pages>
Reference-contexts: Part of the reason for this may be the counter-intuitive fact that they are more complex to optimize than are fully sequential procedures. While dynamic programming can be used, the most straightforward approaches are impractical. In <ref> [17, 21] </ref>, we provide efficient, although more complicated, dynamic programming algorithms for optimizing s-stage procedures with 2 Bernoulli populations and arbitrary objective function. <p> For any specific sample size, however, these results do not indicate whether the given procedure is 95% of optimal or merely 50% of optimal. The type of asymptotic results available for the last two questions are even weaker. In <ref> [17, 21] </ref>, we apply our general algorithms to various problems to determine the efficiency of optimal 1-, 2-, and 3-stage procedures, as compared to the optimal fully sequential procedure. In this section, we use the product of means example to illustrate the results we have observed. <p> Similar results were observed over a wide variety of parameter configurations and for the bandit problem. These results are consistent with the asymptotic analyses that suggest that little efficiency is lost when well-chosen 2- and 3-stage procedures are used. The work in <ref> [17, 21] </ref> also revealed unexpected results, namely that the initial stages of optimal few-stage procedures are much larger than those suggested in the literature. In general, for example, being told that a stage size grows like the square root of n is not useful when n = 100. <p> The author suggests that L 1:2 should grow like fi (n 0:5 ), and he provides some direction for choosing 8 appropriate constants. Noble's guidelines, while frequentist, suggest that for uniform priors and n = 100, L 1:2 should be about 14. In <ref> [17] </ref>, however, we found that the optimal value is 42; and that, in the range n = 10 to 1,000, the optimal L 1:2 grows at a rate which is closer to linear than to the square root.
Reference: [18] <author> Hardwick, J. and Stout, Q.F. </author> <year> (1996), </year> <title> "Sequential allocation with minimal switching", </title> <journal> Comp. Sci. and Statist. </journal> <pages> 28 567-572. </pages>
Reference-contexts: Our goal is to help researchers utilize adaptive allocation by creating a collection of algorithms to optimize and analyze a variety of sequential procedures. The techniques are detailed in <ref> [12, 15, 16, 18, 20, 21, 13] </ref>. The intent here is to illustrate how this growing suite of algorithms allows researchers the flexibility to incorporate a variety of statistical objectives and operational considerations into Research supported in part by National Science Foundation under grants DMS-9157715 and DMS-9504980. <p> For the 2-population Bernoulli response fully sequential setting, we developed dynamic programming algorithms that produce procedures which optimize objective functions under constraints on either the maximum or expected number of switches <ref> [18] </ref>. <p> If at most one switch were allowed, then the efficiency would drop to about 90%. Similar results hold for the product of means estimation problem which has a completely different form of objective function (see <ref> [18] </ref>). A critical point to note, however, is that to obtain efficiencies of the level presented here, the timing of the switches must be as dictated by the optimal rule for this constraint.
Reference: [19] <author> Hardwick, J. and Stout, Q.F. </author> <year> (1996), </year> <title> "Optimal allocation for estimating the mean of a bivariate polynomial", </title> <journal> Seq. Anal. </journal> <pages> 15 71-90. </pages>
Reference-contexts: The second, the product of means problem, is to minimize the mean squared error of the estimate of the product of the success probabilities for the different populations. It arises in reliability and other settings and has been studied by several authors in a variety of forms (see <ref> [19, 25, 32] </ref> and the references therein). <p> Here we apply path induction (Section 3.3) to the study of robustness in the product of means example. This example is from <ref> [19] </ref>, in which sequentially estimating polynomial functions of means is considered. In particular, we examine the impact of departing from the prior parameter configurations used in the design of a procedure.
Reference: [20] <author> Hardwick, J. and Stout, Q.F. </author> <year> (1998), </year> <title> "Path induction for evaluating sequential allocation procedures", </title> <note> SIAM J. Sci. Comp., to appear. </note>
Reference-contexts: Our goal is to help researchers utilize adaptive allocation by creating a collection of algorithms to optimize and analyze a variety of sequential procedures. The techniques are detailed in <ref> [12, 15, 16, 18, 20, 21, 13] </ref>. The intent here is to illustrate how this growing suite of algorithms allows researchers the flexibility to incorporate a variety of statistical objectives and operational considerations into Research supported in part by National Science Foundation under grants DMS-9157715 and DMS-9504980. <p> Table 1: Computational Solutions for Multi-Armed Bandits 3.3 Path Induction The progress in addressing fully sequential allocation was not limited to mere size increases. A new technique we refer to as path induction has allowed for multiple evaluations of arbitrary procedures <ref> [20] </ref>. The multiple evaluations are useful because they provide insight into the behavior of the procedures. <p> This method is exact and quite general, and is applicable to a wide range of procedures, analyses and criteria. For more details and algorithms, see <ref> [20] </ref>. In Section 4, path induction is applied to the problem of assessing the robustness of prior specifications in a Bayesian setting. Path induction can be also be used to assess frequentist characteristics of arbitrary procedures | due to space limitations we refer the reader to [20] for examples. <p> details and algorithms, see <ref> [20] </ref>. In Section 4, path induction is applied to the problem of assessing the robustness of prior specifications in a Bayesian setting. Path induction can be also be used to assess frequentist characteristics of arbitrary procedures | due to space limitations we refer the reader to [20] for examples. Multiple evaluation is often called for in frequentist analyses because some criteria, such as the probability of correctly selecting the best populations, are defined in terms of extremal values over a parameter range.
Reference: [21] <author> Hardwick, J. and Stout, Q.F. </author> <year> (1998), </year> <title> "Optimal few-stage allocation procedures", </title> <note> submitted. </note>
Reference-contexts: Our goal is to help researchers utilize adaptive allocation by creating a collection of algorithms to optimize and analyze a variety of sequential procedures. The techniques are detailed in <ref> [12, 15, 16, 18, 20, 21, 13] </ref>. The intent here is to illustrate how this growing suite of algorithms allows researchers the flexibility to incorporate a variety of statistical objectives and operational considerations into Research supported in part by National Science Foundation under grants DMS-9157715 and DMS-9504980. <p> Part of the reason for this may be the counter-intuitive fact that they are more complex to optimize than are fully sequential procedures. While dynamic programming can be used, the most straightforward approaches are impractical. In <ref> [17, 21] </ref>, we provide efficient, although more complicated, dynamic programming algorithms for optimizing s-stage procedures with 2 Bernoulli populations and arbitrary objective function. <p> Note that the calculations for the first and last stages are significantly easier than for intermediate stages, in that either their start or end is predetermined. Situations in which the total sample size, itself, is random are also addressed in <ref> [21] </ref>, as are situations where the stage sizes are fixed. There are a number of questions one might ask about few-stage procedures. For any given problem, and for any given number of stages, s, naturally arising questions include: 1. <p> For any specific sample size, however, these results do not indicate whether the given procedure is 95% of optimal or merely 50% of optimal. The type of asymptotic results available for the last two questions are even weaker. In <ref> [17, 21] </ref>, we apply our general algorithms to various problems to determine the efficiency of optimal 1-, 2-, and 3-stage procedures, as compared to the optimal fully sequential procedure. In this section, we use the product of means example to illustrate the results we have observed. <p> Similar results were observed over a wide variety of parameter configurations and for the bandit problem. These results are consistent with the asymptotic analyses that suggest that little efficiency is lost when well-chosen 2- and 3-stage procedures are used. The work in <ref> [17, 21] </ref> also revealed unexpected results, namely that the initial stages of optimal few-stage procedures are much larger than those suggested in the literature. In general, for example, being told that a stage size grows like the square root of n is not useful when n = 100. <p> However, once the algorithm for a class of procedure has been developed, adapting to different objective functions, such as bandits versus product of means, is a minor change. Occasionally one can exploit special properties of the objective function to simplify calculations (this is discussed in <ref> [21] </ref>), but all of our descriptions herein are for general objectives. Acknowledgments. We greatly appreciate the comments and recommendations by our referees. The parallel program for the 3-population fully sequential model was developed by Robert Oehmke, using facilities provided by the University of Michigan's Center for Parallel Computing. 11
Reference: [22] <author> Hofri, M. and Ross, K.W. </author> <year> (1987), </year> <title> "On the optimal control of two queues with server setup times and its analysis", </title> <note> SIAM J. Computing 16 399-420. </note>
Reference-contexts: There is an upper bound, S, on the number of times you can switch during the experiment. While cost structures of the sort listed can be important to investigators, they are seldom incorporated into experimental procedures. One exception comes up in certain control theory problems <ref> [1, 22] </ref> in which cost structures such as (1) are utilized. However, the results in [1, 22] are applicable only to the special case in which there is geometric discounting of an infinite horizon and no terminal objective. <p> While cost structures of the sort listed can be important to investigators, they are seldom incorporated into experimental procedures. One exception comes up in certain control theory problems <ref> [1, 22] </ref> in which cost structures such as (1) are utilized. However, the results in [1, 22] are applicable only to the special case in which there is geometric discounting of an infinite horizon and no terminal objective.
Reference: [23] <author> Jones, P. </author> <year> (1992), </year> <title> "Multiobjective Bayesian Bandits", Bayesian Statistics 4: </title> <booktitle> Proc. 4 th Va-lencia Int'l Meeting, </booktitle> <pages> 689-695. </pages>
Reference: [24] <author> Noble, W. </author> <year> (1990), </year> <title> First Order Allocation, </title> <type> Ph.D. Thesis, </type> <institution> Michigan State Univ. </institution>
Reference: [25] <author> Page Shapiro, C. </author> <year> (1985), </year> <title> "Allocation schemes for estimating the product of positive parameters", </title> <journal> J. Amer. Statist. Assoc. </journal> <pages> 80 449-454. </pages>
Reference-contexts: The second, the product of means problem, is to minimize the mean squared error of the estimate of the product of the success probabilities for the different populations. It arises in reliability and other settings and has been studied by several authors in a variety of forms (see <ref> [19, 25, 32] </ref> and the references therein).
Reference: [26] <author> Palmer, C. </author> <year> (1993), </year> <title> "Selecting the best of k treatments", Adaptive Designs (N. </title> <editor> Flournoy & W. F. Rosenberger, ed.'s), </editor> <title> Inst. </title> <journal> Math. Stat. </journal> <note> Lec. Notes 25 110-123. </note>
Reference-contexts: Such problems are of great interest, particularly in the design of clinical trials to sequentially select or test among several populations (e.g., see <ref> [6, 8, 9, 10, 26, 30] </ref>). We know of no prior work in which exact, optimal solutions for fully sequential problems with 3 or more populations are determined. In [12], we describe initial work on the Bernoulli 3-population fully sequential problem with samples up to n = 100.
Reference: [27] <author> Rekab, K. </author> <year> (1992), </year> <title> "A nearly optimal 2-stage procedure", </title> <journal> Comm. Stat. Theory Meth. </journal> <pages> 21 197-201. </pages>
Reference: [28] <author> Schmitz, N. </author> <year> (1993), </year> <title> Optimal Sequentially Planned Decision Procedures, </title> <publisher> Springer-Verlag Lecture Notes. </publisher>
Reference-contexts: know the asymptotic growth rate of the optimal L 1:2 , and finding it is a challenging problem, though it may well be irrelevant for practical sample sizes. 6 Constrained Switching Investigators are occasionally concerned that fully sequential procedures may switch sampling among the different populations with an unguarded frequency, <ref> [28] </ref>. Unconstrained, sequential procedures optimize the objective function but ignore practical considerations such as cost, timing and convenience.
Reference: [29] <author> Simon, R. </author> <year> (1977), </year> <title> "Adaptive treatment assignment methods and clinical trials", </title> <type> Biometrics 33 743-744. </type>
Reference: [30] <author> Thall, P.F., Simon, R., and Ellenberg, S.S. </author> <year> (1989), </year> <title> "A two-stage design for choosing among several experimental treatments and a control in clinical trials", </title> <type> Biometrics 45 537-547. </type>
Reference-contexts: Such problems are of great interest, particularly in the design of clinical trials to sequentially select or test among several populations (e.g., see <ref> [6, 8, 9, 10, 26, 30] </ref>). We know of no prior work in which exact, optimal solutions for fully sequential problems with 3 or more populations are determined. In [12], we describe initial work on the Bernoulli 3-population fully sequential problem with samples up to n = 100.
Reference: [31] <author> Wang, Y.-G. </author> <year> (1991), </year> <title> "Sequential allocation in clinical trials", </title> <journal> Comm. Stat. Theo. Meth. </journal> <pages> 20 791-805. </pages>
Reference: [32] <author> Zheng, S., Seila, </author> <title> A.F., and Sriram, </title> <address> T.N. </address> <year> (1998), </year> <title> "Asymptotically risk eficient two stage procedure for estimating the product of k( 2) means", </title> <journal> Statistics and Decisions, </journal> <note> to appear. 13 </note>
Reference-contexts: The second, the product of means problem, is to minimize the mean squared error of the estimate of the product of the success probabilities for the different populations. It arises in reliability and other settings and has been studied by several authors in a variety of forms (see <ref> [19, 25, 32] </ref> and the references therein).
References-found: 32

