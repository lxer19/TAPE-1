URL: ftp://psyche.mit.edu/pub/jordan/variational-intro.ps.gz
Refering-URL: http://www.ph.tn.tudelft.nl/PRInfo/reports/msg00410.html
Root-URL: 
Title: AN INTRODUCTION TO VARIATIONAL METHODS FOR GRAPHICAL MODELS  
Author: MICHAEL I. JORDAN ZOUBIN GHAHRAMANI TOMMI S. JAAKKOLA AND LAWRENCE K. SAUL 
Address: Cambridge, MA  Toronto, Ontario  Santa Cruz, CA  Florham Park, NJ  
Affiliation: Massachusetts Institute of Technology  University of Toronto  University of California  AT&T Labs Research  
Note: To appear: M. I. Jordan, (Ed.), Learning in Graphical Models, Kluwer Academic Publishers.  
Abstract: This paper presents a tutorial introduction to the use of variational methods for inference and learning in graphical models. We present a number of examples of graphical models, including the QMR-DT database, the sigmoid belief network, the Boltzmann machine, and several variants of hidden Markov models, in which it is infeasible to run exact inference algorithms. We then introduce variational methods, showing how upper and lower bounds can be found for local probabilities, and discussing methods for extending these bounds to bounds on global probabilities of interest. Finally we return to the examples and demonstrate how variational algorithms can be formulated in each case. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bathe, K. J. </author> <year> (1996). </year> <title> Finite Element Procedures. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall. </publisher>
Reference-contexts: This problem is intractable for general HMDTs|as can be seen by noting that the HMDT includes the FHMM as a special case. 4. Basics of variational methodology Variational methods are used as approximation methods in a wide variety of settings, include finite element analysis <ref> (Bathe, 1996) </ref>, quantum mechanics (Sakurai, 1985), statistical mechanics (Parisi, 1988), and statistics (Rustagi, 1976).
Reference: <author> Baum, L.E., Petrie, T., Soules, G., & Weiss, N. </author> <year> (1970). </year> <title> A maximization technique occurring in the statistical analysis of probabilistic functions of Markov chains. </title> <journal> The Annals of Mathematical Statistics, </journal> <volume> 41, </volume> <pages> 164-171. </pages>
Reference: <author> Cover, T., & Thomas, J. </author> <year> (1991). </year> <title> Elements of Information Theory. </title> <address> New York: </address> <publisher> John Wiley. </publisher>
Reference-contexts: Thus, by the positivity of the KL divergence <ref> (Cover & Thomas, 1991) </ref>, the right-hand side of Eq. (43) is a lower bound on P (E). Moreover, by choosing according to Eq. (41), we obtain the tightest lower bound. 6.1. <p> Suppose now that we allow Q (HjE) to range over all possible probability distributions on H and minimize the KL divergence. It is a standard result <ref> (cf. Cover & Thomas, 1991) </ref> that the KL divergence is minimized by choosing Q (HjE) = P (HjE; ), and that the minimal value is zero. This is verified by substituting P (HjE; ) into the right-hand side of Eq. (47) and recovering ln P (Ej).
Reference: <author> Cowell, R. </author> <title> (in press). Introduction to inference for Bayesian networks. </title> <editor> In M. I. Jordan (Ed.), </editor> <title> Learning in Graphical Models. </title> <publisher> Norwell, </publisher> <address> MA: </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference: <author> Dagum, P., & Luby, M. </author> <year> (1993). </year> <title> Approximating probabilistic inference in Bayesian belief networks is NP-hard. </title> <journal> Artificial Intelligence, </journal> <volume> 60, </volume> <pages> 141-153. </pages>
Reference: <author> Dayan, P., Hinton, G. E., Neal, R., & Zemel, R. S. </author> <year> (1995). </year> <title> The Helmholtz Machine. </title> <journal> Neural Computation, </journal> <volume> 7, </volume> <pages> 889-904. </pages>
Reference: <author> Dean, T., & Kanazawa, K. </author> <year> (1989). </year> <title> A model for reasoning about causality and persistence. </title> <journal> Computational Intelligence, </journal> <volume> 5, </volume> <pages> 142-150. </pages>
Reference: <author> Dechter, R. </author> <title> (in press). Bucket elimination: A unifying framework for probabilistic inference. </title> <editor> In M. I. Jordan (Ed.), </editor> <title> Learning in Graphical Models. </title> <publisher> Norwell, </publisher> <address> MA: </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference: <author> Dempster, A.P., Laird, N.M., & Rubin, D.B. </author> <year> (1977). </year> <title> Maximum-likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society, B39, </journal> <pages> 1-38. </pages>
Reference-contexts: More formally, we have: (E step) : Q (k+1) = argmax Q L (Q; (k) ) (48) (M step) : (k+1) = argmax L (Q (k+1) ; ) (49) which is coordinate ascent in L (Q; ). This can be related to the traditional presentation of the EM algorithm <ref> (Dempster, Laird, & Rubin, 1977) </ref> by noting that for fixed Q, the right-hand side of Eq. (47) is a function of only through the ln P (H; Ej) term.
Reference: <author> Draper, D. L., & Hanks, S. </author> <year> (1994). </year> <title> Localized partial evaluation of belief networks. </title> <booktitle> Uncertainty and Artificial Intelligence: Proceedings of the Tenth Conference. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Frey, B. Hinton, G. E., Dayan, P. </author> <year> (1996). </year> <title> Does the wake-sleep algorithm learn good density estimators? In D. </title> <editor> S. Touretzky, M. C. Mozer, & M. E. Hasselmo (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 8. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Fung, R. & Favero, B. D. </author> <year> (1994). </year> <title> Backward simulation in Bayesian networks. </title> <booktitle> Uncertainty and Artificial Intelligence: Proceedings of the Tenth Conference. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Galland, C. </author> <year> (1993). </year> <title> The limitations of deterministic Boltzmann machine learning. </title> <journal> Network, </journal> <volume> 4, </volume> <pages> 355-379. </pages>
Reference-contexts: These cases include sparse Boltzmann machines and Boltzmann machines with "frustrated" interactions; these are networks whose potential functions embody constraints between neighboring nodes that cannot be simultaneously satisfied <ref> (see also Galland, 1993) </ref>. In the case of sparse networks, exact algorithms can provide help; indeed, this observation led to the use of exact algorithms as subroutines within the "structured mean field" approach pursued by Saul and Jordan (1996). Let us now consider the parameter estimation problem for Boltzmann machines.
Reference: <author> Ghahramani, Z., & Hinton, G. E. </author> <year> (1996). </year> <title> Switching state-space models. </title> <institution> University of Toronto Technical Report CRG-TR-96-3, Department of Computer Science. </institution>
Reference: <author> Ghahramani, Z., & Jordan, M. I. </author> <year> (1997). </year> <title> Factorial Hidden Markov models. </title> <journal> Machine Learning, </journal> <volume> 29, </volume> <pages> 245-273. </pages>
Reference: <author> Gilks, W., Thomas, A., & Spiegelhalter, D. </author> <year> (1994). </year> <title> A language and a program for complex Bayesian modelling. </title> <journal> The Statistician, </journal> <volume> 43, </volume> <month> 169-178. </month> <title> AN INTRODUCTION TO VARIATIONAL METHODS 55 Heckerman, </title> <editor> D. (in press). </editor> <title> A tutorial on learning with Bayesian networks. </title> <editor> In M. I. Jordan (Ed.), </editor> <title> Learning in Graphical Models. </title> <publisher> Norwell, </publisher> <address> MA: </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference: <author> Henrion, M. </author> <year> (1991). </year> <title> Search-based methods to bound diagnostic probabilities in very large belief nets. </title> <booktitle> Uncertainty and Artificial Intelligence: Proceedings of the Seventh Conference. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: A variety of approximation procedures have been developed that attempt to identify and exploit such situations. Examples include the pruning algorithms of Kjrulff (1994), the "bounded conditioning" method of Horvitz, Suer-mondt, and Cooper (1989), search-based methods <ref> (e.g., Henrion, 1991) </ref>, and the "localized partial evaluation" method of Draper and Hanks (1994). A virtue of all of these methods is that they are closely tied to the exact methods and thus are able to take full advantage of conditional independencies.
Reference: <author> Hinton, G. E., & Sejnowski, T. </author> <year> (1986). </year> <title> Learning and relearning in Boltzmann machines. </title> <editor> In D. E. Rumelhart & J. L. McClelland, (Eds.), </editor> <booktitle> Parallel distributed processing: Volume 1, </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: In particular, when we triangulate generic Boltzmann machines, including the layered Boltzmann machines and grid-like Boltzmann machines, we obtain intractably large cliques. Sampling algorithms have traditionally been used to attempt to cope with the intractability of the Boltzmann machine <ref> (Hinton & Sejnowski, 1986) </ref>. The sampling algorithms are overly slow, however, and more recent work has considered the faster "mean field" approximation (Peterson & Anderson, 1987).
Reference: <author> Hinton, G.E. & van Camp, D. </author> <year> (1993). </year> <title> Keeping neural networks simple by minimizing the description length of the weights. </title> <booktitle> In Proceedings of the 6th Annual Workshop on Computational Learning Theory, </booktitle> <pages> pp 5-13. </pages> <address> New York, NY: </address> <publisher> ACM Press. </publisher>
Reference-contexts: A variational method known as "ensemble learning" was originally introduced as a way of fitting an "ensemble" of neural networks to data, where each setting of the parameters can be thought of as a different member of the ensemble <ref> (Hinton & van Camp, 1993) </ref>. Let Q (jE) represent a variational approximation to the posterior distribution P (jE).
Reference: <author> Hinton, G. E., Dayan, P., Frey, B., and Neal, R. M. </author> <year> (1995). </year> <title> The wake-sleep algorithm for unsupervised neural networks. </title> <journal> Science, </journal> <volume> 268 </volume> <pages> 1158-1161. </pages>
Reference: <author> Hinton, G. E., Sallans, B., & Ghahramani, Z. </author> <title> (in press). A hierarchical community of experts. </title> <editor> In M. I. Jordan (Ed.), </editor> <title> Learning in Graphical Models. </title> <publisher> Norwell, </publisher> <address> MA: </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference: <author> Horvitz, E. J., Suermondt, H. J., & Cooper, </author> <title> G.F. (1989). Bounded conditioning: Flexible inference for decisions under scarce resources. </title> <booktitle> Conference on Uncertainty in Artificial Intelligence: Proceedings of the Fifth Conference. </booktitle> <address> Mountain View, CA: </address> <publisher> Association for UAI. </publisher>
Reference: <author> Jaakkola, T. S., & Jordan, M. I. </author> <year> (1996). </year> <title> Computing upper and lower bounds on likelihoods in intractable networks. </title> <booktitle> Uncertainty and Artificial Intelligence: Proceedings of the Twelth Conference. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Jaakkola, T. S. </author> <year> (1997). </year> <title> Variational methods for inference and estimation in graphical models. </title> <type> Unpublished doctoral dissertation, </type> <institution> Massachusetts Institute of Technology. </institution>
Reference-contexts: Moreover, by choosing according to Eq. (41), we obtain the tightest lower bound. 6.1. CONVEX DUALITY AND THE KL DIVERGENCE We can also justify the choice of KL divergence by making an appeal to convex duality theory, thereby linking the block approach with the sequential approach <ref> (Jaakkola, 1997) </ref>. Consider, for simplicity, the case of discrete-valued nodes H. The distribution Q (HjE; ) can be viewed as a vector of real numbers, one for each configuration of the variables H. Treat this vector as the vector-valued variational parameter "" in Eq. (23). <p> In fact, if we run the latter algorithm until all nodes are eliminated from the graph, we obtain a bound that is identical to the mean field bound <ref> (Jaakkola, 1997) </ref>. To see this, note that for a Boltzmann machine in which all of the nodes have been eliminated there are no quadratic and linear terms; only the constant terms remain.
Reference: <author> Jaakkola, T. S., & Jordan, M. I. </author> <year> (1997a). </year> <title> Recursive algorithms for approximating probabilities in graphical models. </title> <editor> In M. C. Mozer, M. I. Jordan, & T. Petsche (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 9. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: We will also discuss a more general variational algorithm that provides upper and lower bounds on probabilities (marginals and conditionals) for Boltzmann machines <ref> (Jaakkola & Jordan, 1997a) </ref>. (although the latter can represent zero probabilities while the former cannot). 14 MICHAEL I. JORDAN ET AL. represents time. The output nodes Y i are evidence nodes during the training process and the state nodes X i are hidden. 3.4. <p> We have focused on linear bounds in this section, but convex duality is not restricted to linear bounds. More general bounds can be obtained by transforming the argument of the function of interest rather than the value of the function <ref> (Jaakkola & Jordan, 1997a) </ref>. For example, if f (x) is concave in x 2 we can write: f (x) = min fx 2 f fl ()g; (25) where f fl () is the conjugate function of f (x) f (x 2 ). <p> The upper bound transformation, on the other hand, by introducing links between the neighbors of a delinked node, does not reveal tractable structure as readily. This seeming disad vantage is mitigated by the fact that the upper bound is a tighter bound <ref> (Jaakkola & Jordan, 1997a) </ref>. 6. The block approach An alternative approach to variational inference is to designate in advance a set of nodes that are to be transformed. We can in principle view this "block approach" as an off-line application of the sequential approach.
Reference: <author> Jaakkola, T. S., & Jordan, M. I. </author> <year> (1997b). </year> <title> Bayesian logistic regression: a variational approach. </title> <editor> In D. Madigan & P. Smyth (Eds.), </editor> <booktitle> Proceedings of the 1997 Conference on Artificial Intelligence and Statistics, </booktitle> <address> Ft. Lauderdale, FL. </address>
Reference-contexts: Thus the transformation yields a quadratic bound on f (x). It is also worth noting that such transformations can be combined with the logarithmic transformation utilized earlier to obtain Gaussian representations for the upper bounds. This can be useful in obtaining variational approximations for posterior distributions <ref> (Jaakkola & Jordan, 1997b) </ref>. To summarize, the general methodology suggested by convex duality is the following. We wish to obtain upper or lower bounds on a function of interest. If the function is already convex or concave then we simply 24 MICHAEL I. JORDAN ET AL. calculate the conjugate function.
Reference: <author> Jaakkola, T. S., & Jordan. M. I. </author> <year> (1997c). </year> <title> Variational methods and the QMR-DT database. </title> <note> Submitted to: Journal of Artificial Intelligence Research. </note>
Reference-contexts: Finally, (3) we must also choose the parameters i so as to make the approximation as tight as possible. It is not difficult to verify that products of the expression in Eq. (32) yield an overall bound that is a convex function of the i parameters <ref> (Jaakkola & Jordan, 1997c) </ref>. Thus standard optimization algorithms can be used to find good choices for the i . Jaakkola and Jordan (1997c) presented results for approximate inference on the "CPC cases" that were mentioned earlier. These are difficult cases which have up to 100 positive findings.
Reference: <author> Jaakkola, T. S., & Jordan. M. I. </author> <title> (in press). Improving the mean field approximation via the use of mixture distributions. </title> <editor> In M. I. Jordan (Ed.), </editor> <title> Learning in Graphical Models. </title> <publisher> Norwell, </publisher> <address> MA: </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference: <author> Jensen, C. S., Kong, A., & Kjrulff, U. </author> <year> (1995). </year> <title> Blocking-Gibbs sampling in very large probabilistic expert systems. </title> <journal> International Journal of Human-Computer Studies, </journal> <volume> 42, </volume> <pages> 647-666. </pages>
Reference: <author> Jensen, F. V., & Jensen, F. </author> <year> (1994). </year> <title> Optimal junction trees. </title> <booktitle> Uncertainty and Artificial Intelligence: Proceedings of the Tenth Conference. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Jensen, F. V. </author> <year> (1996). </year> <title> An Introduction to Bayesian Networks. </title> <publisher> London: UCL Press. </publisher>
Reference: <author> Jordan, M. I. </author> <year> (1994). </year> <title> A statistical approach to decision tree modeling. </title> <editor> In M. Warmuth (Ed.), </editor> <booktitle> Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory. </booktitle> <address> New York: </address> <publisher> ACM Press. </publisher>
Reference: <author> Jordan, M. I., Ghahramani, Z., & Saul, L. K. </author> <year> (1997). </year> <title> Hidden Markov decision trees. </title> <editor> In M. C. Mozer, M. I. Jordan, & T. Petsche (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 9. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: We will not discuss the higher-order HMM further in this chapter; for a variational algorithm for the higher-order HMM see Saul and Jordan (1996). 3.7. HIDDEN MARKOV DECISION TREES Finally, we consider a model in which a decision tree is endowed with Marko-vian dynamics <ref> (Jordan, et al., 1997) </ref>. A decision tree can be viewed as a graphical model by modeling the decisions in the tree as multinomial random variables, one for each level of the decision tree. <p> As in the FHMM, we write a variational approximation for the forest of chains approximation by respecting the conditional independencies in the approximating graph and incorporating variational parameters to obtain extra degrees of freedom <ref> (see Jordan, et al., 1997, for the details) </ref>. AN INTRODUCTION TO VARIATIONAL METHODS 49 graph leads to an approximating family of Q distributions. We can also consider a "forest of trees approximation" in which the horizontal links are eliminated (see Fig. 24).
Reference: <author> Kanazawa, K., Koller, D., & Russell, S. </author> <year> (1995). </year> <title> Stochastic simulation algorithms for dynamic probabilistic networks. </title> <booktitle> Uncertainty and Artificial Intelligence: Proceedings of the Eleventh Conference. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Kjrulff, U. </author> <year> (1990). </year> <title> Triangulation of graphs|algorithms giving small total state space. </title> <institution> Research Report R-90-09, Department of Mathematics and Computer Science, Aal-borg University, Denmark. </institution>
Reference-contexts: Thus we will not need to consider specific algorithms for triangulation <ref> (for discussion of triangulation algorithms, see, e.g., Kjrulff, 1990) </ref>. 3. Examples In this section we present examples of graphical models in which exact inference is generally infeasible. Our first example involves a diagnostic system in which a fixed graphical model is used to answer queries.
Reference: <author> Kjrulff, U. </author> <year> (1994). </year> <title> Reduction of computational complexity in Bayesian networks 56 MICHAEL I. </title> <editor> JORDAN ET AL. </editor> <title> through removal of weak dependences. </title> <booktitle> Uncertainty and Artificial Intelligence: Proceedings of the Tenth Conference. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> MacKay, D.J.C. </author> <year> (1997a). </year> <title> Ensemble learning for hidden Markov models. </title> <type> Unpublished manuscript. </type> <institution> Department of Physics, University of Cambridge. </institution>
Reference-contexts: More recently, the ensemble learning approach has been applied to mixture of experts architectures (Waterhouse, et al, 1996) and hidden Markov models <ref> (MacKay, 1997a) </ref>. One interesting aspect of these applications is that they do not assume any particular parametric family for Q, just that Q factorizes in a specific way. The variational minimization itself determines the best family given this factorization and the prior on .
Reference: <author> MacKay, D.J.C. </author> <year> (1997b). </year> <title> Comparison of approximate methods for handling hyperparam-eters. </title> <note> Submitted to Neural Computation. </note>
Reference: <author> MacKay, D.J.C. </author> <year> (1997b). </year> <title> Introduction to Monte Carlo methods. </title> <editor> In M. I. Jordan (Ed.), </editor> <title> Learning in Graphical Models. </title> <publisher> Norwell, </publisher> <address> MA: </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference: <author> McEliece, R.J., MacKay, D.J.C., & Cheng, J.-F. </author> <title> (1996) Turbo decoding as an instance of Pearl's "belief propagation algorithm." Submitted to: </title> <journal> IEEE Journal on Selected Areas in Communication. </journal>
Reference-contexts: This virtue can also be a vice, however, given the exponential growth in complexity of the exact algorithms. A related approach to approximate inference has arisen in in applications of graphical model inference to error-control decoding <ref> (McEliece, MacKay, & Cheng, 1996) </ref>. In particular, Kim and Pearl's algorithm for singly-connected graphical models (Pearl, 1988) has been used successfully as an iterative approximate method for inference in non-singly-connected graphs. Another approach to the design of approximation algorithms involves making use of Monte Carlo methods.
Reference: <author> Merz, C. J., & Murphy, P. M. </author> <year> (1996). </year> <title> UCI repository of machine learning databases. </title> <address> [http:/www.ics.uci/~mlearn/MLRepository.html]. Irvine, CA: </address> <institution> University of Cali-fornia, Department of Information and Computer Science. </institution>
Reference-contexts: The procedure then returns to the first phase and iterates. 48 MICHAEL I. JORDAN ET AL. graph leads to an approximating family of Q distributions. Ghahramani and Jordan (1997) reported results on fitting an FHMM to the Bach chorale data set <ref> (Merz & Murphy, 1996) </ref>. They showed that significantly larger effective state spaces could be fit with the FHMM than with an unstructured HMM, and that performance in terms of probability of the test set was an order of magnitude larger for the FHMM.
Reference: <author> Neal, R. </author> <year> (1992). </year> <title> Connectionist learning of belief networks, </title> <journal> Artificial Intelligence, </journal> <volume> 56, </volume> <pages> 71-113. </pages>
Reference-contexts: (this volume) takes the following form: ij / ( i ~ i ) j ij ~ i (1 ~ i ) i (1 i ): (68) Note that there is no need to calculate variational parameters under the unconditional distribution, P (Sj), as in the case of the Boltzmann machine <ref> (a fact first noted by Neal, 1992) </ref>. Note also the interesting appearance of a regularization term|the second term in the equation is a "weight decay" term that is maximal for non-extreme values of the variational parameters (both of these parameters are bounded between zero and one).
Reference: <author> Neal, R. </author> <year> (1993). </year> <title> Probabilistic inference using Markov chain Monte Carlo methods. </title> <institution> University of Toronto Technical Report CRG-TR-93-1, Department of Computer Science. </institution>
Reference-contexts: Another approach to the design of approximation algorithms involves making use of Monte Carlo methods. A variety of Monte Carlo algorithms have been developed <ref> (see MacKay, this volume, and Neal, 1993) </ref> and applied to the inference problem in graphical models (Dagum & Luby, 1993; Fung & Favero, 1994; Gilks, Thomas, & Spiegelhalter, 1994; Jensen, Kong, & Kjrulff, 1995; Pearl, 1988). Advantages of these algorithms include their simplicity of implementation and theoretical guarantees of convergence.
Reference: <author> Neal, R., & Hinton, G. E. </author> <title> (in press). A view of the EM algorithm that justifies incremental, sparse, and other variants. </title> <editor> In M. I. Jordan (Ed.), </editor> <title> Learning in Graphical Models. </title> <publisher> Norwell, </publisher> <address> MA: </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference: <author> Parisi, G. </author> <year> (1988). </year> <title> Statistical Field Theory. </title> <address> Redwood City, CA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: Basics of variational methodology Variational methods are used as approximation methods in a wide variety of settings, include finite element analysis (Bathe, 1996), quantum mechanics (Sakurai, 1985), statistical mechanics <ref> (Parisi, 1988) </ref>, and statistics (Rustagi, 1976). In each of these cases the application of variational methods converts a complex problem into a simpler problem, where the simpler problem is generally characterized by a decoupling of the degrees of freedom in the original problem. <p> For mean field methods, a good starting point is to understand the examples in the statistical mechanics literature where this approximation gives not only good, but indeed exact, results. These are densely connected graphs with uniformly weak (but non-negative) couplings between neighboring nodes <ref> (Parisi, 1988) </ref>. The mean field equations for these networks have a unique solution that determines the statistics of individual nodes in the limit of very large graphs. In more general graphical models, of course, the conditions for a mean field approximation may not be so favorable.
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmannn. </publisher>
Reference-contexts: A related approach to approximate inference has arisen in in applications of graphical model inference to error-control decoding (McEliece, MacKay, & Cheng, 1996). In particular, Kim and Pearl's algorithm for singly-connected graphical models <ref> (Pearl, 1988) </ref> has been used successfully as an iterative approximate method for inference in non-singly-connected graphs. Another approach to the design of approximation algorithms involves making use of Monte Carlo methods.
Reference: <author> Peterson, C., & Anderson, J. R. </author> <year> (1987). </year> <title> A mean field theory learning algorithm for neural networks. </title> <journal> Complex Systems, </journal> <volume> 1, </volume> <pages> 995-1019. </pages>
Reference-contexts: Sampling algorithms have traditionally been used to attempt to cope with the intractability of the Boltzmann machine (Hinton & Sejnowski, 1986). The sampling algorithms are overly slow, however, and more recent work has considered the faster "mean field" approximation <ref> (Peterson & Anderson, 1987) </ref>. We will describe the mean field approximation for Boltzmann machines later in the paper|it is a special form of the variational approximation approach that provides lower bounds on marginal probabilities. <p> The "mean field" approximation <ref> (Peterson & Anderson, 1987) </ref> for Boltzmann machines is a particular form of variational approximation in which a 40 MICHAEL I. JORDAN ET AL. approximating mean field distribution Q is based on a graph with no edges.
Reference: <author> Rockafellar, R. </author> <year> (1972). </year> <title> Convex Analysis. </title> <publisher> Princeton University Press. </publisher>
Reference-contexts: CONVEX DUALITY Can we find variational transformations more systematically? Indeed, many of the variational transformations that have been utilized in the literature 22 MICHAEL I. JORDAN ET AL. on graphical models are examples of the general principle of convex duality. It is a general fact of convex analysis <ref> (Rockafellar, 1972) </ref> that a concave function f (x) can be represented via a conjugate or dual function as follows: f (x) = min f T x f fl ()g; (21) where we now allow x and to be vectors.
Reference: <author> Rustagi, J. </author> <year> (1976). </year> <title> Variational Methods in Statistics. </title> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference-contexts: Basics of variational methodology Variational methods are used as approximation methods in a wide variety of settings, include finite element analysis (Bathe, 1996), quantum mechanics (Sakurai, 1985), statistical mechanics (Parisi, 1988), and statistics <ref> (Rustagi, 1976) </ref>. In each of these cases the application of variational methods converts a complex problem into a simpler problem, where the simpler problem is generally characterized by a decoupling of the degrees of freedom in the original problem.
Reference: <author> Sakurai, J. </author> <year> (1985). </year> <title> Modern Quantum Mechanics. </title> <address> Redwood City, CA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: This problem is intractable for general HMDTs|as can be seen by noting that the HMDT includes the FHMM as a special case. 4. Basics of variational methodology Variational methods are used as approximation methods in a wide variety of settings, include finite element analysis (Bathe, 1996), quantum mechanics <ref> (Sakurai, 1985) </ref>, statistical mechanics (Parisi, 1988), and statistics (Rustagi, 1976). In each of these cases the application of variational methods converts a complex problem into a simpler problem, where the simpler problem is generally characterized by a decoupling of the degrees of freedom in the original problem.
Reference: <author> Saul, L. K., & Jordan, M. I. </author> <year> (1994). </year> <title> Learning in Boltzmann trees. </title> <journal> Neural Computation, </journal> <volume> 6, </volume> <pages> 1173-1183. </pages>
Reference: <author> Saul, L. K., Jaakkola, T. S., & Jordan, M. I. </author> <year> (1996). </year> <title> Mean field theory for sigmoid belief networks. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 4, </volume> <pages> 61-76. </pages>
Reference: <author> Saul, L. K., & Jordan, M. I. </author> <year> (1996). </year> <title> Exploiting tractable substructures in intractable networks. </title> <editor> In D. S. Touretzky, M. C. Mozer, & M. E. Hasselmo (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 8. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Saul, L. K., & Jordan, M. I. </author> <title> (in press). A mean field learning algorithm for unsupervised neural networks. </title> <editor> In M. I. Jordan (Ed.), </editor> <title> Learning in Graphical Models. </title> <publisher> Norwell, </publisher> <address> MA: </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference: <author> Seung, S. </author> <year> (1995). </year> <title> Annealed theories of learning. </title> <editor> In J.-H Oh, C. Kwon, and S. Cho, (Eds.), </editor> <booktitle> Neural Networks: The Statistical Mechanics Perspectives. </booktitle> <address> Singapore: </address> <publisher> World Scientific. </publisher>
Reference: <author> Shachter, R. D., Andersen, S. K., & Szolovits, P. </author> <year> (1994). </year> <title> Global conditioning for probabilistic inference in belief networks. </title> <booktitle> Uncertainty and Artificial Intelligence: Proceedings of the Tenth Conference. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Shenoy, P. P. </author> <year> (1992). </year> <title> Valuation-based systems for Bayesian decision analysis. </title> <journal> Operations Research, </journal> <volume> 40, </volume> <pages> 463-484. </pages>
Reference: <author> Shwe, M. A., Middleton, B., Heckerman, D. E., Henrion, M., Horvitz, E. J., Lehmann, H. P., & Cooper, G. F. </author> <year> (1991). </year> <title> Probabilistic diagnosis using a reformulation of the INTERNIST-1/QMR knowledge base. </title> <journal> Meth. Inform. Med., </journal> <volume> 30, </volume> <pages> 241-255. </pages>
Reference: <author> Smyth, P., Heckerman, D., & Jordan, M. I. </author> <year> (1997). </year> <title> Probabilistic independence networks for hidden Markov probability models. </title> <journal> Neural Computation, </journal> <volume> 9, </volume> <pages> 227-270. </pages>
Reference-contexts: FACTORIAL HIDDEN MARKOV MODELS In many problem domains it is natural to make additional structural assumptions about the state space and the transition probabilities that are not available within the simple HMM framework. A number of structured variations on HMMs have been considered in recent years <ref> (see Smyth, et al., 1997) </ref>; generically these variations can be viewed as "dynamic belief networks" (Dean & Kanazawa, 1989; Kanazawa, Koller, & Russell, 1995). Here we consider a particular simple variation on the HMM theme known as the "factorial hidden Markov model" (Ghahramani & Jordan, 1997; Williams & Hinton, 1991).
Reference: <author> Waterhouse, S., MacKay, D.J.C. & Robinson, T. </author> <year> (1996). </year> <title> Bayesian methods for mixtures of experts. </title> <editor> In D. S. Touretzky, M. C. Mozer, & M. E. Hasselmo (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 8. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: More recently, the ensemble learning approach has been applied to mixture of experts architectures <ref> (Waterhouse, et al, 1996) </ref> and hidden Markov models (MacKay, 1997a). One interesting aspect of these applications is that they do not assume any particular parametric family for Q, just that Q factorizes in a specific way.
Reference: <author> Williams, C. K. I., & Hinton, G. E. </author> <year> (1991). </year> <title> Mean field networks that learn to discriminate AN INTRODUCTION TO VARIATIONAL METHODS 57 temporally distorted strings. </title> <editor> In Touretzky, D. S., Elman, J., Sejnowski, T., & Hinton, G. E., (Eds.), </editor> <booktitle> Proceedings of the 1990 Connectionist Models Summer School. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
References-found: 61

