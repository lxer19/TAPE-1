URL: http://www.cs.utah.edu/projects/robot/papers/Navigation_Papers/sutherland.ps.gz
Refering-URL: http://www.cs.utah.edu/projects/robot/navigation.html
Root-URL: 
Title: The Stability of Geometric Inference in Location Determination  
Author: Karen T. Sutherland 
Degree: the thesis submitted to the faculty of the Graduate School of the University of Minnesota in partial fulfillment of the requirements for the degree of Doctor of Philosophy  
Date: July 8, 1994  
Address: Salt Lake City, UT 84112 USA  
Affiliation: of  UUCS-94-021 Department of Computer Science University of Utah  
Note: A revised version  This work was supported by National Science Foundation grant IRI-9196146, with partial funding from the Advanced Research Projects Agency.  
Abstract: Geometric inference is widely used in computer vision, but very little attention has been given to the question of how geometric properties affect the resulting errors in the inferences made. This thesis addresses the problem of the stability of geometric inference in determining locations with a goal of being able to predict type and magnitude of the errors which occur and to determine on what basis to make geometric inferences which will minimize error. It is shown that the amount of the error occurring in a localization process using angular measurements to features depends heavily on which features are used, that the amount of the error occurring in such a localization process is not a function of the number of features used, that it is possible to develop simple heuristic functions for choosing features for localization which will significantly decrease error in that localization, that it is possible to decrease localization error in a particular direction, and that, if features have been identified but knowledge of left to right order in the view is unknown, simple steps can be taken to aid in determining that ordering. This knowledge is applied in the domain of robot navigation in outdoor, unstructured environments. 
Abstract-found: 1
Intro-found: 1
Reference: [ Atiya and Hager, 1993 ] <author> Sami Atiya and Greg Hager. </author> <title> Real-time vision-based robot localization. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 9(6) </volume> <pages> 785-800, </pages> <month> December </month> <year> 1993. </year>
Reference: [ Ayache and Faugeras, 1989 ] <author> Nicholas Ayache and Oliver D. Faugeras. </author> <title> Maintaining representations of the environment of a mobile robot. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 5(6) </volume> <pages> 804-819, </pages> <month> December </month> <year> 1989. </year>
Reference: [ Babb, 1990 ] <author> Richard J. Babb. </author> <title> Navigation of unmanned underwater vehicles for scientific surveys. </title> <booktitle> In Proceedings of the IEEE Symposium on Autonomous Underwater Vehicle Technology, </booktitle> <pages> pages 194-198. </pages> <publisher> IEEE, </publisher> <year> 1990. </year>
Reference-contexts: Autonomous underwater vehicles (AUV's) often navigate in their completely unstructured environments by either adding structures for reference or navigating only over short local distances. Methods proposed include the use of a network of bottom-laid acoustic transponders combined with a high accuracy dead reckoning system <ref> [ Babb, 1990 ] </ref> , electronic still cameras with high performance, large format CCD imagers [ Harris et al., 1987 ] , and the exploitation of surface texture properties [ Negahdaripour et al., 1990, Negahdaripour and Yu, 1990 ] .
Reference: [ Bajcsy, 1988 ] <editor> Ruzena Bajcsy. </editor> <title> Active perception. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 76(8) </volume> <pages> 996-1005, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: These simulations show that small movements can aid in reducing the ambiguity resulting from only partial knowledge of order, especially when the three feature points are non-linear. Does this process fall into the category of active perception or active vision as in <ref> [ Bajcsy, 1988 ] </ref> ? Bajcsy states: perceptual activity is exploratory, probing, searching; In that general sense, this process could be considered a type of active perception. Something is being actively done to aid in the perceptual process.
Reference: [ Ballard, 1989 ] <author> Dana H. Ballard. </author> <title> Reference frames for animate vision. </title> <booktitle> In Proceedings of the 11th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1635-1641. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Something is being actively done to aid in the perceptual process. However, most research in active machine perception has dealt with ideas such as the use of retina-like lenses [ Sandini and Tagliasco, 1980 ] or gaze control <ref> [ Ballard, 1989 ] </ref> in which small, often continuous movement of the imaging device implements low level visual goals.
Reference: [ Blostein and Huang, 1987 ] <author> Steven D. Blostein and Thomas S. Huang. </author> <title> Error analysis in stereo determination of 3-d point positions. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 9(6) </volume> <pages> 752-765, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: An error in estimate of an extrinsic camera parameter such as pan or tilt will give a result similar to that of a visual angle error in navigation. <ref> [ Blostein and Huang, 1987 ] </ref> have derived the probability that position estimate due to quantization error in triangulation is within a specified error tolerance. They assume uniform distribution of the possible locations of the 3D point and analyze the effect on the pixel area.
Reference: [ Bowditch, 1802 ] <author> Nathaniel Bowditch. </author> <title> The American Practical Navigator (an epitome of navigation). </title> <journal> Blunt, </journal> <volume> 1802. </volume>
Reference-contexts: A common fix is called the three-point fix and is the intersection of arcs of position using three points. The fact that errors which occur in localization are not directly proportional to errors in sensing has been known to navigators for many years. Nathaniel Bowditch (1773-1838) <ref> [ Bowditch, 1802 ] </ref> said: A person who understands the nature of errors avoids many pitfalls. Thus, the magnitude of the errors of individual lines of position is not a reliable indication of the size of the error of the fix obtained from them.
Reference: [ Brooks, 1986 ] <author> Rodney A. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-2(1):14-23, </volume> <month> March </month> <year> 1986. </year>
Reference: [ Cartwright and Collett, 1982 ] <author> B. A. Cartwright and T. S. Collett. </author> <title> How honey bees use landmarks to guide their return to a food source. </title> <journal> Nature, </journal> <volume> 295 </volume> <pages> 560-564, </pages> <month> February </month> <year> 1982. </year>
Reference: [ Cohen et al., 1993 ] <author> S. C. Cohen, D. S. Chinn, M. H. Torrence, and P. J. Dunn. </author> <title> Spaceborne laser ranging: sensitivity to ephemeris and range measurement errors. </title> <journal> Manuscripta Geodaetica, </journal> <volume> 18 </volume> <pages> 72-81, </pages> <year> 1993. </year>
Reference-contexts: This is necessary because GPS is not accurate enough for such maritime applications as navigating a harbor entrance or offshore surveying. Atmospheric conditions also affect GPS. The signal strength is a function of the thickness of the air mass which the signal passes through <ref> [ Cohen et al., 1993 ] </ref> . Experiments have been conducted [ Tranquilla and Al-Rizzo, 1993 ] during periods of snowfall and when ice clouds were present in the atmosphere. The phase delays caused by the ice clouds and snow were calculated.
Reference: [ Collett et al., 1992 ] <author> T. S. Collett, E. Dillmann, A. Giger, and R. Wehner. </author> <title> Visual landmarks and route following in desert ants. </title> <journal> Journal of Comparative Physiology A, </journal> <volume> 170 </volume> <pages> 435-442, </pages> <year> 1992. </year>
Reference-contexts: As the desert ant nears the nest site, it switches into its piloting stage, using a small number of prominent landmarks. This helps eliminate the uncertainty present in a cluttered environment as well as the directional errors which accumulated during path integration <ref> [ Collett et al., 1992, Wehner and Harkness, 1983 ] </ref> . Rather than recalling route details as it approaches the nest site, it simply passes either to the left or right of specific landmarks. <p> Turning again to the example of the desert ant, Cataglyphis economizes on what it learns about its surroundings. It learns only significant landmarks and no more than are necessary to stay on course. It does not learn the complete topography of a large area <ref> [ Collett et al., 1992 ] </ref> . The results of the analysis in Chapter 3 can be used to choose areas on the terrain map in which to look for landmarks. Consider two navigators following the path shown in Figure 4.13. 7 Their landmarks are mountain peaks.
Reference: [ Crowley, 1985 ] <author> James L. Crowley. </author> <title> Navigation for an intelligent mobile robot. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> RA-1(1):31-41, </volume> <month> March </month> <year> 1985. </year>
Reference: [ Cui et al., 1990 ] <author> Ning Cui, Juyang Weng, and Paul Cohen. </author> <title> Extended structure and motion analysis from monocular image sequences. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 222-229. </pages> <publisher> IEEE, </publisher> <year> 1990. </year>
Reference-contexts: Due to the problems mentioned above, initial solution estimates in an unstructured environment can be very poor. Even when convergence is possible, the number of measurements a filter requires to converge is often large due to the amount of error in those measurements <ref> [ Cui et al., 1990 ] </ref> . This factor is important when images must be taken and processed in real time. A combination of all of these problems leads to error being a significant discriminant between navigating in structured and unstructured environments.
Reference: [ Dai and Lawton, 1993 ] <author> David Dai and Daryl Lawton. </author> <title> Range-free qualitative navigation. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <volume> volume 1, </volume> <pages> pages 783-790. </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1993. </year>
Reference-contexts: They built up a representation of such space based upon observations of visual events. Due to the fact that their environment was rich in landmarks and that their qualitative navigation approach was intended to function with only approximate knowledge, types and magnitudes of errors were not an issue. <ref> [ Dai and Lawton, 1993 ] </ref> expanded on this approach, developing algorithms which deal with landmarks for which there are no range estimates.
Reference: [ Davis et al., 1987 ] <author> L. S. Davis, D. Dementhon, R. Gajulapalli, T. R. Kushner, J. LeMoigne, and P. Veatch. </author> <title> Vision-based navigation: A status report. </title> <booktitle> In Proc. DARPA Image Understanding Workshop, </booktitle> <pages> pages 153-169, </pages> <address> San Mateo, CA, February 1987. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Work in both the DARPA ALV program and the Carnegie Mellon Navlab also was carried out in a structured outdoor environment with roads, their intersections and lanemarkings the predominant terrain features <ref> [ Davis et al., 1987, Thorpe et al., 1987 ] </ref> . Talluri and Aggarwal, [ Talluri and Aggarwal, 1992 ] , used a constrained search paradigm, deriving a significantly pruned search space in which to determine robot location by making terrain elevation assumptions based on altimeter and compass readings.
Reference: [ Dhond and Aggarwal, 1991 ] <author> Umesh R. Dhond and J. K. Aggarwal. </author> <title> A cost-benefit analysis of a third camera for stereo correspondence. </title> <journal> International Journal of Computer Vision, </journal> <volume> 6(1) </volume> <pages> 39-58, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Given that the world point is in one of the 4 areas shown in Figure 5.3, whether A and/or B are under or overestimates of the actual projected image point is shown. 83 An analysis of the geometric constraints involved in the use of a third camera should be done. <ref> [ Dhond and Aggarwal, 1991 ] </ref> in their cost-benefit analysis of adding a third camera to the stereo process, mention that the pan and tilt angles of the second and third cameras. respectively, are usually set equal in magnitude and equal to arctan b Z max where b is the baseline
Reference: [ Diaconis and Freedman, 1984 ] <author> Persi Diaconis and David Freedman. </author> <title> Asymptotics of graphical projection pursuit. </title> <journal> The Annals of Statistics, </journal> <volume> 12(3) </volume> <pages> 793-815, </pages> <month> September </month> <year> 1984. </year>
Reference-contexts: In this case, the interesting information in a pattern recognition problem is obtained by projecting the data onto an axis so that a single Gaussian distribution is not produced. However, the opposite can also be true. Diaconis and Freedman <ref> [ Diaconis and Freedman, 1984 ] </ref> showed that there are classes of data sets where the interesting projections are the ones which are close to Gaussian. It is this type of projection which will be pursued herein.
Reference: [ Dickmanns and Graefe, 1988a ] <author> Ernst Dickmanns and Volker Graefe. </author> <title> Applications of dynamic monocular machine vision. </title> <journal> Machine Vision and Applications, </journal> <volume> 1 </volume> <pages> 241-261, </pages> <year> 1988. </year>
Reference: [ Dickmanns and Graefe, 1988b ] <author> Ernst Dickmanns and Volker Graefe. </author> <title> Dynamic monocular machine vision. </title> <journal> Machine Vision and Applications, </journal> <volume> 1 </volume> <pages> 223-240, </pages> <year> 1988. </year>
Reference: [ Dickmanns, 1992 ] <author> Ernst D. Dickmanns. </author> <title> Expectation based dynamic scene understanding. </title> <editor> In A. Blake and A. L. Yuille, editors, </editor> <booktitle> Active Vision, </booktitle> <pages> pages 285-318. </pages> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference: [ D'Orazio et al., 1992 ] <author> T. D'Orazio, M. Ianigro, E. Stella, and A. Distante. </author> <title> Self localization of a mobile robot using visual landmarks. </title> <booktitle> In Proceedings of the 1992 IEEE/RSJ International Conference on Intelligent Robots and Systems, </booktitle> <pages> pages 1869-1874. </pages> <publisher> IEEE, </publisher> <month> July </month> <year> 1992. </year>
Reference: [ Duerr, 1992 ] <author> T. E. Duerr. </author> <title> Effect of terrain masking on GPS position dilution of precision. </title> <booktitle> Navigation, </booktitle> <volume> 39(3) </volume> <pages> 317-323, </pages> <year> 1992. </year>
Reference-contexts: The visible horizon when GPS is used for navigation on land is approximately 25 ffi rather than the 5 ffi assumed when a vehicle is at sea. This can be even worse in an urban or mountainous setting [ Mattos, 1992 ] . Duerr, <ref> [ Duerr, 1992 ] </ref> , has studied the effect of terrain masking on the precision of GPS readings. Most published results on GPS accuracy have assumed an unobstructed view of the sky.
Reference: [ Dyer, 1991 ] <author> Fred C. Dyer. </author> <title> Bees acquire route-based memories but not cognitive maps in a familiar landscape. Animal Behavior, </title> <booktitle> 41(2) </booktitle> <pages> 239-246, </pages> <year> 1991. </year>
Reference-contexts: They do not seem to possess more general information such as that the nest site is located halfway between two landmarks. Similar recent observations have been made in the case of foraging honey bees <ref> [ Dyer, 1991 ] </ref> . Rather than a cognitive map in the sense of an internal topographic map, the bees use landmarks associated with routes which they have traveled previously. They will also head toward a panorama of landmarks associated with a food site.
Reference: [ Enge, 1993 ] <author> Per K. Enge. </author> <title> Forward error correction for radiobeacon broadcast of differential GPS data. </title> <journal> IEEE Transactions on Aerospace and Electronic Systems, </journal> <volume> 29(1) </volume> <pages> 223-232, </pages> <month> January </month> <year> 1993. </year> <month> 89 </month>
Reference-contexts: DGPS (Differential Global Positioning System)/radiobeacon broadcast networks have been developed to provide position fixing for maritime applications which require more than an accuracy within 100 meters <ref> [ Enge, 1993 ] </ref> . A local reference station with a high quality GPS receiver and an antenna at a known location estimates the error in the GPS signal and transmits it as a correction to users within the range of the station.
Reference: [ Fennema et al., 1990 ] <author> C. Fennema, A. Hansen, E. Riseman, J. R. Beveridge, and R. Kumar. </author> <title> Model-directed mobile robot navigation. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> 20(6) </volume> <pages> 1352-1369, </pages> <month> November/December </month> <year> 1990. </year>
Reference: [ Ferrari et al., 1990 ] <author> F. Ferrari, E. Grosso, G. Sandini, and M. Magrassi. </author> <title> A stereo vision system for real time obstacle avoidance in unknown environment. </title> <booktitle> In Proceedings of the 1990 IEEE/RSJ International Conference on Intelligent Robots and Systems, </booktitle> <pages> pages 703-708. </pages> <publisher> IEEE, </publisher> <month> July </month> <year> 1990. </year>
Reference: [ Fischler and Bolles, 1981 ] <author> Martin A. Fischler and Robert C. Bolles. </author> <title> Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography. </title> <journal> Communications of the ACM, </journal> <volume> 24(6) </volume> <pages> 381-395, </pages> <month> June </month> <year> 1981. </year>
Reference-contexts: This pose is then used to find the location of additional model points in the image <ref> [ Fischler and Bolles, 1981, Huttenlocher and Ullman, 1990 ] </ref> .
Reference: [ Friedman, 1987 ] <author> Jerome H. Friedman. </author> <title> Exploratory projection pursuit. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 82(397) </volume> <pages> 249-266, </pages> <month> March </month> <year> 1987. </year>
Reference: [ Gallistel, 1990 ] <author> Charles R. Gallistel. </author> <title> The Organization of Learning. </title> <publisher> MIT Press, </publisher> <address> 1st edition, </address> <year> 1990. </year>
Reference-contexts: It is possible for an animal to have such a record of geometric relationships among points in its environment, but not have a complete map of the surrounding terrain. Gallistel <ref> [ Gallistel, 1990 ] </ref> claims that the popular belief that the cognitive maps of lower animals are weaker than those of humans is not well-founded. <p> Regardless of the rotation of individual stars around Polaris itself, flying away from the cluster results in a path heading south [ Slater, 1985 ] . Any constellations used for navigation are learned by these birds as nestlings <ref> [ Gallistel, 1990 ] </ref> . Birds in different areas of the world learn different constellations. It is also not unlike the cognitive map as defined by Kuipers [ Kuipers, 1978 ] . <p> It is more closely tied to the concept of purposive vision as described in [ Maver and Bajcsy, 1993 ] . Animals will use motion parallax to judge distance <ref> [ Gallistel, 1990 ] </ref> but this again usually consists of either small movements of the head from side to side or a series of vertical head bobs.
Reference: [ Grimson et al., 1991 ] <author> W. Eric Grimson, Daniel P. Huttenlocher, and David W. Jacobs. </author> <title> Affine matching with bounded sensor error: A study of geometric hashing and alignment. </title> <type> Technical Report AI-Memo-1250, </type> <institution> Massachusetts Institute of Technology, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: Consider the numbered areas in the plane of Figure 5.2. The radius of the circle for each of the areas is: 1. 2* 3. 2* 5. 2*~ 7. 2*(1 ~ ) which the transformed point lies. These values can be easily computed from the previously stated general formula <ref> [ Grimson et al., 1991 ] </ref> . What is interesting about these values is that areas 4 and 7 are the only ones in which the size of the circle depends on both affine coordinates of the point.
Reference: [ Hager and Mintz, 1991 ] <author> Greg Hager and Max Mintz. </author> <title> Computational methods for task-directed sensor data fusion and sensor planning. </title> <journal> The International Journal of Robotics Research, </journal> <volume> 10(4) </volume> <pages> 285-313, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: An assumption of a uniform distribution of error does not necessarily mean that error is uniformly distributed. A case could be made for running experiments in these environments and developing an error model such as those described by Mintz et al. <ref> [ Hager and Mintz, 1991, McKendall and Mintz, 1990 ] </ref> for indoor use. However, many of the errors a navigator must handle are due to environmental conditions. Weather, humidity levels, undersea thermal vents, fog, etc. will all affect the error.
Reference: [ Haralick et al., 1989 ] <author> Robert M. Haralick, Hyonam Joo, Chung-Nam Lee, Xinhua Zhuang, Vinay G. Vaidya, and Man Bae Kim. </author> <title> Pose estimation from corresponding point data. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> 19(6) </volume> <pages> 1426-1446, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: The navigation problem of self-localization in the world is an absolute orientation problem. Absolute orientation <ref> [ Haralick et al., 1989 ] </ref> is defined as the recovery of the relationship between two 3D coordinate systems. To find this relationship, one must determine scaling, translation and rotation. The early algorithms for determining absolute orientation were developed by researchers in the field of photogrammetry. In 1958, E. H.
Reference: [ Harris et al., 1987 ] <author> Stewart E. Harris, Robert H. Squires, and Emile M. Bergeron. </author> <title> Underwater imagery using an electronic still camera. </title> <booktitle> In Oceans '87, </booktitle> <pages> pages 1242-1245. </pages> <publisher> IEEE, </publisher> <year> 1987. </year>
Reference-contexts: Methods proposed include the use of a network of bottom-laid acoustic transponders combined with a high accuracy dead reckoning system [ Babb, 1990 ] , electronic still cameras with high performance, large format CCD imagers <ref> [ Harris et al., 1987 ] </ref> , and the exploitation of surface texture properties [ Negahdaripour et al., 1990, Negahdaripour and Yu, 1990 ] . However, even when several methods are combined, the error involved is significant.
Reference: [ Hoffman and Krotkov, 1993 ] <author> Regis Hoffman and Eric Krotkov. </author> <title> Terrain mapping for outdoor robots: Robust perception for walking in the grass. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <volume> volume 1, </volume> <pages> pages 529-533. </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1993. </year>
Reference-contexts: Whether the robot is wheeled [ Talluri and Aggarwal, 1992 ] or legged <ref> [ Hoffman and Krotkov, 1993 ] </ref> , terrain surface conditions exacerbate these errors for land vehicles. Existing tools for determining position and translational motion in underwater vehicles (e.g., linear accelerometers or Doppler techniques) are insensitive to slow positional drift [ Negahdaripour et al., 1990 ] .
Reference: [ Huntingford, 1984 ] <author> Felicity Huntingford. </author> <title> The Study of Animal Behavior. </title> <publisher> Chapman and Hall, </publisher> <year> 1984. </year>
Reference-contexts: fairly new field of ethology 1 , which involves observations of animals in their natural environments rather than in a laboratory setting has contributed much to the understanding of how insects as well as other animals can successfully find their way home after foraging large distances from a nest site <ref> [ Huntingford, 1984, Slater, 1985 ] </ref> . Several well known computational navigation systems have been modeled after insect-type navigation [ Brooks, 1986, Maes and Brooks, 1990, Lucarini et al., 1993 ] . However, these systems are based on low level reactive behaviors or self-organization of multiple agents.
Reference: [ Hutchins, 1983 ] <author> Edwin Hutchins. </author> <title> Understanding micronesian navigation. </title> <editor> In Dedre Gentner and Albert L. Stevens, editors, </editor> <booktitle> Mental Models, </booktitle> <pages> pages 191-225. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1983. </year>
Reference-contexts: The Micronesians, although sharing the same computational theory as western navigators, hold an egocentric point of view. They do not have the bird's eye world view idea of western cultures. They do not use a map of the navigational area <ref> [ Hutchins, 1983 ] </ref> , nor do they use instruments. The navigational methods they do use are much like those of the desert ant, a combination of dead reckoning and piloting. 7 In the area surrounding the Caroline Islands, approximately :2% of the earth's surface is land.
Reference: [ Hutchins, 1993 ] <author> Edwin Hutchins. </author> <title> Cognition in the Wild. </title> <publisher> MIT Press - Bradford Books, </publisher> <year> 1993. </year>
Reference-contexts: They will also head toward a panorama of landmarks associated with a food site. In neither case do they need or seem to use the complex geometric relationships available in a topographic map. 2.2 Geometric inferences made by human navigators According to Hutchins <ref> [ Hutchins, 1993 ] </ref> , human navigators have three basic questions: * Where Am I? (Localization) * If I am here, how do I get there? (Path Planning) * If I am here and move in a certain way for a certain time, where will I be? (Dead Reckoning) Errors in <p> The computational level gives the goal of the computation and the logic by which it can be carried out, while the representational level deals with the actual algorithm needed for accomplishing the task. Hutchins claims <ref> [ Hutchins, 1993 ] </ref> that early studies of Micronesian navigation assumed that representations used in western navigation were also used by the Micronesian navigators. Due to this blindness to other feasible navigational algorithms, they attributed the navigators' success to luck rather than to skill.
Reference: [ Huttenlocher and Ullman, 1990 ] <author> Daniel P. Huttenlocher and Shimon Ullman. </author> <title> Recognizing solid objects by alignment with an image. </title> <journal> International Journal of Computer Vision, </journal> <volume> 4 </volume> <pages> 195-212, </pages> <year> 1990. </year>
Reference-contexts: This pose is then used to find the location of additional model points in the image <ref> [ Fischler and Bolles, 1981, Huttenlocher and Ullman, 1990 ] </ref> .
Reference: [ Huttenlocher, 1988 ] <author> Daniel P. Huttenlocher. </author> <title> Three-Dimensional Recognition of Solid Objects from a Two-Dimensional Image. </title> <type> Tech Report 1045, </type> <institution> MIT, </institution> <year> 1988. </year>
Reference-contexts: The features to match are points and a bounded amount of sensing error is assumed. Three non-collinear model points are transformed, usually by orthographic projection plus scale (equivalently, by an affine transform <ref> [ Huttenlocher, 1988 ] </ref> ) then matched against triples of non-collinear image points to determine a model pose. This pose is then used to find the location of additional model points in the image [ Fischler and Bolles, 1981, Huttenlocher and Ullman, 1990 ] .
Reference: [ Intrator, 1992 ] <author> Nathan Intrator. </author> <title> Feature extraction using an unsupervised neural network. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 98-107, </pages> <year> 1992. </year>
Reference: [ Intrator, 1993 ] <author> Nathan Intrator. </author> <title> On the use of projection pursuit constraints for training neural networks. </title> <editor> In C. L. Giles, S. J. Hanson, and J. D. Cowan, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 5, </volume> <pages> pages 3-10. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference: [ Jacobs, 1991 ] <author> David W. Jacobs. </author> <title> Optimal matching of planar models in 3D. </title> <booktitle> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 269-274. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1991. </year>
Reference-contexts: The affine coordinates are invariant under affine transforms but they are dependent on the three points which were chosen for the basis [ Lamdan et al., 1988 ] . As in visual navigation, there is sensing error in the presumed location of image points. Jacobs <ref> [ Jacobs, 1991 ] </ref> assumed a sensing error in image point locations up to * in any direction, such that the correct model pose would align each basis point within a circle of radius * around the corresponding image point.
Reference: [ Kalman, 1960 ] <author> R. E. </author> <title> Kalman. A new approach to linear filtering and prediction problems. </title> <journal> Journal of Basic Engineering, </journal> <pages> pages 35-45, </pages> <year> 1960. </year>
Reference: [ Kosaka and Kak, 1992 ] <author> Akio Kosaka and Avinash C. Kak. </author> <title> Fast vision-guided mobile robot navigation using model- based reasoning and prediction of uncertainties. CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> 56(3) </volume> <pages> 271-329, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Existing tools for determining position and translational motion in underwater vehicles (e.g., linear accelerometers or Doppler techniques) are insensitive to slow positional drift [ Negahdaripour et al., 1990 ] . Kosaka and Kak, in their very thorough treatment of indoor navigation techniques <ref> [ Kosaka and Kak, 1992 ] </ref> , state that occasional wheel slippage inconsistent with the mathematical model was the believed cause of failure in their hallway experiments.
Reference: [ Kriegman et al., 1989 ] <author> D. J. Kriegman, E. Triendl, and T. O. Binford. </author> <title> Stereo vision and navigation in buildings for mobile robots. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 5(6) </volume> <pages> 792-803, </pages> <month> October </month> <year> 1989. </year>
Reference: [ Krotkov, 1989 ] <author> Eric Krotkov. </author> <title> Mobile robot localization using a single image. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 978-983. </pages> <publisher> IEEE, </publisher> <year> 1989. </year>
Reference-contexts: In the two-dimensional case, as shown in Figure 3.4, visual angles between three points will constrain the viewpoint to the intersection of three circles, unless all three points and the navigator lie on the same circle <ref> [ Krotkov, 1989, Sugihara, 1988 ] </ref> . This single circle configuration restricts the viewpoint to the arc of the circle boundary from A to C, providing the same localization as would knowledge of the visual angle between only two points. 10 viewpoint V to a) a surface of revolution. <p> When a two-dimensional approximation of the environment is assumed, an error in the visual angle estimate to two features, as shown in Figure 3.5a, will constrain the viewpoint to a thickened ring, the thickness of the ring determined by the amount of error <ref> [ Krotkov, 1989, Levitt and Lawton, 1990 ] </ref> .
Reference: [ Kuipers and Levitt, 1988 ] <author> Benjamin J. Kuipers and Tod S. Levitt. </author> <title> Navigation and mapping in large-scale space. </title> <journal> AI Magazine, </journal> <pages> pages 25-43, </pages> <month> Summer </month> <year> 1988. </year>
Reference-contexts: When three features are used, any given error in estimate constrains the viewpoint to the intersection of two such rings <ref> [ Kuipers and Levitt, 1988, Sutherland, 1992 ] </ref> . 1 See Appendix A for 1 A third ring passing through the two features lying at greatest distance from each other can be computed, but it does not affect area size. 12 details of the computation. <p> As an example, Figure 3.7 shows two areas of uncertainty. The outer area, with an error bound of 30% of visual angle measure, is the same as shown in Figure 3.5. The inner area is for an error bound of 10% of visual angle measure. It has been shown <ref> [ Kuipers and Levitt, 1988, Levitt and Lawton, 1990 ] </ref> that the lines joining pairs of features divide space into distinguishable areas (orientation regions). [ Levitt and Lawton, 2 Although all graphs in this example show a straight line configuration of features, the described conditions also hold for nonlinear configurations. 14
Reference: [ Kuipers, 1978 ] <author> Benjamin Kuipers. </author> <title> Modeling spatial knowledge. </title> <journal> Cognitive Science, </journal> <volume> 2 </volume> <pages> 129-153, </pages> <year> 1978. </year>
Reference-contexts: Any constellations used for navigation are learned by these birds as nestlings [ Gallistel, 1990 ] . Birds in different areas of the world learn different constellations. It is also not unlike the cognitive map as defined by Kuipers <ref> [ Kuipers, 1978 ] </ref> .
Reference: [ Lamdan et al., 1988 ] <author> Yehezkel Lamdan, Jacob T. Schwartz, and Haim J. Wolfson. </author> <title> Object recognition by affine invariant matching. </title> <booktitle> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 335-344. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1988. </year>
Reference-contexts: The affine coordinates are invariant under affine transforms but they are dependent on the three points which were chosen for the basis <ref> [ Lamdan et al., 1988 ] </ref> . As in visual navigation, there is sensing error in the presumed location of image points.
Reference: [ Levitt and Lawton, 1990 ] <author> Tod S. Levitt and Daryl T. Lawton. </author> <title> Qualitative navigation for mobile robots. </title> <journal> Artificial Intelligence, </journal> <volume> 44(3) </volume> <pages> 305-360, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: The visual angle from a viewpoint to two point features will be defined as the angle formed by the rays from the viewpoint location to each point feature. It has been shown <ref> [ Levitt and Lawton, 1990 ] </ref> that a perfect estimate of the visual angle between two points constrains the viewpoint to a surface of revolution somewhat resembling the torus shown in Figure 3.3a. <p> When a two-dimensional approximation of the environment is assumed, an error in the visual angle estimate to two features, as shown in Figure 3.5a, will constrain the viewpoint to a thickened ring, the thickness of the ring determined by the amount of error <ref> [ Krotkov, 1989, Levitt and Lawton, 1990 ] </ref> . <p> As an example, Figure 3.7 shows two areas of uncertainty. The outer area, with an error bound of 30% of visual angle measure, is the same as shown in Figure 3.5. The inner area is for an error bound of 10% of visual angle measure. It has been shown <ref> [ Kuipers and Levitt, 1988, Levitt and Lawton, 1990 ] </ref> that the lines joining pairs of features divide space into distinguishable areas (orientation regions). [ Levitt and Lawton, 2 Although all graphs in this example show a straight line configuration of features, the described conditions also hold for nonlinear configurations. 14 <p> Levitt and Lawton <ref> [ Levitt and Lawton, 1990 ] </ref> showed experimentally that, in general, localization is sensitive to the number of landmarks used. However, they assumed that a large number of landmarks were available. Their results compare localization using up to 20 landmarks. Twenty landmarks provide 1140 different ordered triples.
Reference: [ Levitt et al., 1987 ] <author> T. S. Levitt, D. T. Lawton, D. M Chelberg, and P. C. Nelson. </author> <title> Qualitative navigation. </title> <booktitle> In Proc. DARPA Image Understanding Workshop, </booktitle> <pages> pages 447-465, </pages> <address> Los Altos, CA, </address> <month> February </month> <year> 1987. </year> <note> Morgan Kaufmann. 91 </note>
Reference: [ Levitt et al., 1988 ] <author> T. S. Levitt, D. T. Lawton, D. M Chelberg, K. V. Koitzsch, and John W. Dye. </author> <title> Qualitative navigation II. </title> <booktitle> In Proc. DARPA Image Understanding Workshop, </booktitle> <pages> pages 319-326, </pages> <address> Los Altos, CA, April 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [ Lu and Lachapelle, 1992 ] <author> G. Lu and G. Lachapelle. </author> <title> Statistical quality control for kinematic GPS positioning. </title> <journal> Manuscripta Geodaetica, </journal> <volume> 17(5) </volume> <pages> 270-281, </pages> <year> 1992. </year>
Reference-contexts: When using the Kalman filter in this type of application, the dynamic and observation models which are assumed are often incorrect due to causes such as cycle slips, leading to significant errors or possible nonconvergence in the filter results <ref> [ Lu and Lachapelle, 1992 ] </ref> . DGPS (Differential Global Positioning System)/radiobeacon broadcast networks have been developed to provide position fixing for maritime applications which require more than an accuracy within 100 meters [ Enge, 1993 ] .
Reference: [ Lucarini et al., 1993 ] <author> G. Lucarini, M. Varoli, R. Cerutti, and G. </author> <title> Sandini. </title> <booktitle> Cellular robotics: Simulation and HW implementation. In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <volume> volume 3, </volume> <pages> pages 846-852. </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1993. </year>
Reference: [ Maes and Brooks, 1990 ] <author> Pattie Maes and Rodney A. Brooks. </author> <title> Learning to coordinate behaviors. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 796-802. </pages> <publisher> AAAI Press, </publisher> <month> July </month> <year> 1990. </year>
Reference: [ Marr, 1982 ] <author> David Marr. Vision. W. H. Freeman and Company, </author> <year> 1982. </year>
Reference-contexts: One possible explanation for the inability to comprehend the reasoning behind these techniques is that an assumption was made that both Micronesian and western navigators were processing information in the same way. According to David Marr <ref> [ Marr, 1982 ] </ref> , any information processing task is carried out at three levels: computational theory, representational and implementational.
Reference: [ Matthies and Shafer, 1987 ] <author> Larry Matthies and Steven A. Shafer. </author> <title> Error modeling in stereo navigation. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-3(3):239-248, </volume> <month> June </month> <year> 1987. </year>
Reference: [ Mattos, 1992 ] <author> Philip Mattos. </author> <title> GPS. </title> <journal> Electronics and Wireless World, </journal> <volume> 98 </volume> <pages> 982-987, </pages> <year> 1992. </year>
Reference-contexts: The visible horizon when GPS is used for navigation on land is approximately 25 ffi rather than the 5 ffi assumed when a vehicle is at sea. This can be even worse in an urban or mountainous setting <ref> [ Mattos, 1992 ] </ref> . Duerr, [ Duerr, 1992 ] , has studied the effect of terrain masking on the precision of GPS readings. Most published results on GPS accuracy have assumed an unobstructed view of the sky.
Reference: [ Maver and Bajcsy, 1993 ] <editor> Jasna Maver and Ruzena Bajcsy. </editor> <title> Occlusions as a guide for planning the next view. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15(5) </volume> <pages> 417-433, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: It is more closely tied to the concept of purposive vision as described in <ref> [ Maver and Bajcsy, 1993 ] </ref> . Animals will use motion parallax to judge distance [ Gallistel, 1990 ] but this again usually consists of either small movements of the head from side to side or a series of vertical head bobs.
Reference: [ McFarland and Houston, 1981 ] <author> David McFarland and Alasdair Houston. </author> <title> Quantitative Ethology: The State Space Approach. </title> <publisher> Pitman Advanced Publishing Program, </publisher> <year> 1981. </year>
Reference: [ McKendall and Mintz, 1990 ] <author> Raymond McKendall and Max Mintz. </author> <title> Sensor-fusion with statistical decision theory: A prospectus of research in the GRASP lab. </title> <type> Technical Report MS-CIS-90-68, </type> <institution> University of Pennsylvania, </institution> <month> September </month> <year> 1990. </year>
Reference-contexts: An assumption of a uniform distribution of error does not necessarily mean that error is uniformly distributed. A case could be made for running experiments in these environments and developing an error model such as those described by Mintz et al. <ref> [ Hager and Mintz, 1991, McKendall and Mintz, 1990 ] </ref> for indoor use. However, many of the errors a navigator must handle are due to environmental conditions. Weather, humidity levels, undersea thermal vents, fog, etc. will all affect the error.
Reference: [ Muller and Wehner, 1988 ] <author> Martin Muller and Rudiger Wehner. </author> <title> Path integration in desert ants, </title> <booktitle> cataglyphis fortis. Proceedings of the National Academy of Science, </booktitle> <volume> 85 </volume> <pages> 5287-5290, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: At this point, the dead reckoning stops and piloting takes over. This dead reckoning or path integration is not done by performing a vector summation such as a modern human navigator would do, but by using computationally simple approximations <ref> [ Muller and Wehner, 1988 ] </ref> . A path integration system produces large errors only when the ant makes sharp backward turns, and it very seldom makes this type of turn. The errors in distance and angular measure that it does make tend to cancel each other out.
Reference: [ Negahdaripour and Yu, 1990 ] <author> Shariar Negahdaripour and C. H. Yu. </author> <title> Passive optical sensing for near-bottom stationkeeping. </title> <booktitle> In Oceans '90, </booktitle> <year> 1990. </year>
Reference-contexts: Methods proposed include the use of a network of bottom-laid acoustic transponders combined with a high accuracy dead reckoning system [ Babb, 1990 ] , electronic still cameras with high performance, large format CCD imagers [ Harris et al., 1987 ] , and the exploitation of surface texture properties <ref> [ Negahdaripour et al., 1990, Negahdaripour and Yu, 1990 ] </ref> . However, even when several methods are combined, the error involved is significant. The Navstar Global Positioning System (GPS) has often been promoted as an error free solution to the problem of self-localization.
Reference: [ Negahdaripour et al., 1990 ] <author> Shahriar Negahdaripour, Chih Ho Yu, and Amir Shokrollahi. </author> <title> Recovering shape and motion from undersea images. </title> <journal> IEEE Journal of Oceanic Engineering, </journal> <volume> 15(3) </volume> <pages> 189-198, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Methods proposed include the use of a network of bottom-laid acoustic transponders combined with a high accuracy dead reckoning system [ Babb, 1990 ] , electronic still cameras with high performance, large format CCD imagers [ Harris et al., 1987 ] , and the exploitation of surface texture properties <ref> [ Negahdaripour et al., 1990, Negahdaripour and Yu, 1990 ] </ref> . However, even when several methods are combined, the error involved is significant. The Navstar Global Positioning System (GPS) has often been promoted as an error free solution to the problem of self-localization. <p> Existing tools for determining position and translational motion in underwater vehicles (e.g., linear accelerometers or Doppler techniques) are insensitive to slow positional drift <ref> [ Negahdaripour et al., 1990 ] </ref> . Kosaka and Kak, in their very thorough treatment of indoor navigation techniques [ Kosaka and Kak, 1992 ] , state that occasional wheel slippage inconsistent with the mathematical model was the believed cause of failure in their hallway experiments.
Reference: [ Negast and Paschall, 1992 ] <author> William J. Negast and Randall N. Paschall. </author> <title> Compensation of selected availability using a GPS/INS extended Kalman filter. </title> <booktitle> In Proc. IEEE 1992 National Aerospace and Electronics Conference, </booktitle> <pages> pages 356-362, </pages> <month> May </month> <year> 1992. </year> <month> 92 </month>
Reference-contexts: These users make up a large group: the entire civilian community. Averaging techniques such as the Extended Kalman filter are used to add differential corrections to the GPS measurements and improve accuracy <ref> [ Negast and Paschall, 1992 ] </ref> .
Reference: [ Pedoe, 1970 ] <author> Daniel Pedoe. </author> <title> A Course of Geometry. </title> <publisher> Cambridge University Press, </publisher> <address> 1st edition, </address> <year> 1970. </year>
Reference-contexts: In most cases, an estimate of this ratio can be obtained in the following way: for any landmark triple A, B and C, the circle through A, B and the viewpoint V intersects the circle through B, C and V at points B and V. It is well known <ref> [ Pedoe, 1970 ] </ref> that when two circles intersect, there is only one angle of intersection, the same at both intersection points. Thus, the angle at V equals the angle at B.
Reference: [ Pick et al., 1993 ] <author> Herbert L. Pick, Jr., Albert Yonas, Douglas Gentile, Patricia Melendez, Douglas Wagner, and Dominick Wegesin. </author> <title> Perceptual aspects of navigation. </title> <booktitle> In Proc. DARPA Image Understanding Workshop, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: The extraordinary navigation skills of the Micronesians were described in Chapter 2. Several land-based ancient cultures are also known for their ability to navigate without sophisticated instruments. It might be just as interesting to investigate these navigational techniques as was the work of <ref> [ Pick et al., 1993 ] </ref> with modern, experienced land navigators. 79 5.2.2 Object recognition Several extensions to what has been done here exist in the area of pose estimation in model-based object recognition.
Reference: [ Sandini and Tagliasco, 1980 ] <author> Giulio Sandini and Vincenzo Tagliasco. </author> <title> An anthropomorphic retina-like structure for scene analysis. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 14 </volume> <pages> 365-372, </pages> <year> 1980. </year>
Reference-contexts: Something is being actively done to aid in the perceptual process. However, most research in active machine perception has dealt with ideas such as the use of retina-like lenses <ref> [ Sandini and Tagliasco, 1980 ] </ref> or gaze control [ Ballard, 1989 ] in which small, often continuous movement of the imaging device implements low level visual goals.
Reference: [ Sanso, 1973 ] <author> Fernando Sanso. </author> <title> An exact solution of the roto-translation problem. </title> <journal> Photogramme-tria, </journal> <volume> 29 </volume> <pages> 203-216, </pages> <year> 1973. </year>
Reference-contexts: In 1958, E. H. Thompson [ Thompson, 1958 ] matched model coordinates with geodetic coordinates. He projected the sphere onto the complex plane and used a system of linear equations to solve the 3D ! 3D absolute orientation problem for rotation only. In 1973, Sanso <ref> [ Sanso, 1973 ] </ref> extended this solution to include scaling and translation. Sanso's solution used the quaternion algebra, a method which has recently regained popularity, particularly in the area of computer vision. Most recent work in autonomous robot navigation has been done in structured indoor environments.
Reference: [ Shepard and Hurwitz, 1985 ] <author> Roger N. </author> <title> Shepard and Shelley Hurwitz. Upward direction, mental rotation and discrimination of left and right. </title> <editor> In Steven Pinker, editor, </editor> <booktitle> Visual Cognition, </booktitle> <pages> pages 161-194. </pages> <publisher> MIT Press, </publisher> <year> 1985. </year>
Reference-contexts: In fact, this lack of cluttered detail most likely contributed to their ability to compute their own location without the use of instruments. Shepard and Hurwitz <ref> [ Shepard and Hurwitz, 1985 ] </ref> discuss the mental rotations required to follow left and right turns on a map and the confusion resulting when up on the map does not coincide with straight ahead in the surrounding environment.
Reference: [ Slater, 1985 ] <author> P. J. B. Slater. </author> <title> An Introduction to Ethology. </title> <publisher> Cambridge University Press, </publisher> <year> 1985. </year>
Reference-contexts: fairly new field of ethology 1 , which involves observations of animals in their natural environments rather than in a laboratory setting has contributed much to the understanding of how insects as well as other animals can successfully find their way home after foraging large distances from a nest site <ref> [ Huntingford, 1984, Slater, 1985 ] </ref> . Several well known computational navigation systems have been modeled after insect-type navigation [ Brooks, 1986, Maes and Brooks, 1990, Lucarini et al., 1993 ] . However, these systems are based on low level reactive behaviors or self-organization of multiple agents. <p> This is not unlike the methods used by those birds in the northern hemisphere which migrate at night, flying away from the small cluster of stars around Polaris. Regardless of the rotation of individual stars around Polaris itself, flying away from the cluster results in a path heading south <ref> [ Slater, 1985 ] </ref> . Any constellations used for navigation are learned by these birds as nestlings [ Gallistel, 1990 ] . Birds in different areas of the world learn different constellations. It is also not unlike the cognitive map as defined by Kuipers [ Kuipers, 1978 ] .
Reference: [ Smith and Cheeseman, 1986 ] <author> Randall C. Smith and Peter Cheeseman. </author> <title> On the representation and estimation of spatial uncertainty. </title> <journal> The International Journal of Robotics Research, </journal> <volume> 5(4) </volume> <pages> 56-68, </pages> <month> Winter </month> <year> 1986. </year>
Reference: [ Sorenson, 1970 ] <author> Harold W. Sorenson. </author> <title> Least-squares estimation: from Gauss to Kalman. </title> <journal> IEEE Spectrum, </journal> <pages> pages 63-68, </pages> <month> July </month> <year> 1970. </year>
Reference-contexts: Although the Kalman filter is guaranteed to converge, the EKF is not. It can easily fall into a local minimum if a good estimate of the solution is not available in advance <ref> [ Sorenson, 1970 ] </ref> . Due to the problems mentioned above, initial solution estimates in an unstructured environment can be very poor.
Reference: [ Stewart, 1991 ] <author> W. Kenneth Stewart. </author> <title> Remote-sensing issues for intelligent underwater systems. </title> <booktitle> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 230-235. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1991. </year>
Reference-contexts: In 42 addition, conditions such as fog surrounding a land navigator or particles suspended in the water around an undersea system can cause image blurring and back-scattered noise, both of which affect sensor accuracy <ref> [ Stewart, 1991 ] </ref> . * Maps contain errors. As an example, the location of the highest point of a significant peak is 200 meters off on one of the United States Geological Survey (USGS) Digital Elevation Maps (DEMs) [ Thompson et al., 1993 ] .
Reference: [ Sugihara, 1988 ] <author> Kokichi Sugihara. </author> <title> Some localization problems for robot navigation using a single camera. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 42 </volume> <pages> 112-129, </pages> <year> 1988. </year>
Reference-contexts: In the two-dimensional case, as shown in Figure 3.4, visual angles between three points will constrain the viewpoint to the intersection of three circles, unless all three points and the navigator lie on the same circle <ref> [ Krotkov, 1989, Sugihara, 1988 ] </ref> . This single circle configuration restricts the viewpoint to the arc of the circle boundary from A to C, providing the same localization as would knowledge of the visual angle between only two points. 10 viewpoint V to a) a surface of revolution.
Reference: [ Sutherland and Thompson, 1993 ] <author> Karen T. Sutherland and William B. Thompson. </author> <title> Inexact navigation. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <volume> volume 1, </volume> <pages> pages 1-7. </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1993. </year>
Reference-contexts: For a viewpoint facing the configuration, change in area is lateral only. To summarize, the area of uncertainty corresponding to a given visual angle and error in that visual angle varies greatly for different configurations of features <ref> [ Sutherland, 1992, Sutherland and Thompson, 1993 ] </ref> . Figure 3.13 shows a comparison of different areas with visual angle error range of 13:5 ffi or 30% in both ff and fi. <p> An estimate of the viewpoint using this set will locate the navigator at point V 0 . Step II: Choose the best configuration based on V 0 , and estimate a new viewpoint, V 1 . In preliminary work <ref> [ Sutherland and Thompson, 1993 ] </ref> , the best configurations in two dissimilar directions were used to estimate viewpoint. The weighted average of these two values was taken as the estimated viewpoint. As explained in Section 4.2.2, results were not as good as when only one configuration was used.
Reference: [ Sutherland and Thompson, 1994 ] <author> Karen T. Sutherland and William B. Thompson. </author> <title> Pursuing projections: Keeping a robot on path. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <volume> volume 4, </volume> <pages> pages 3355-3361. </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1994. </year>
Reference: [ Sutherland, 1992 ] <author> Karen T. Sutherland. </author> <title> Sensitivity of feature configuration in viewpoint determination. </title> <booktitle> In Proc. DARPA Image Understanding Workshop, </booktitle> <pages> pages 315-319, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: When three features are used, any given error in estimate constrains the viewpoint to the intersection of two such rings <ref> [ Kuipers and Levitt, 1988, Sutherland, 1992 ] </ref> . 1 See Appendix A for 1 A third ring passing through the two features lying at greatest distance from each other can be computed, but it does not affect area size. 12 details of the computation. <p> For a viewpoint facing the configuration, change in area is lateral only. To summarize, the area of uncertainty corresponding to a given visual angle and error in that visual angle varies greatly for different configurations of features <ref> [ Sutherland, 1992, Sutherland and Thompson, 1993 ] </ref> . Figure 3.13 shows a comparison of different areas with visual angle error range of 13:5 ffi or 30% in both ff and fi.
Reference: [ Sutherland, 1993 ] <author> Karen T. Sutherland. </author> <title> Landmark selection for accurate navigation. </title> <booktitle> In Proc. DARPA Image Understanding Workshop, </booktitle> <pages> pages 485-490, </pages> <month> April </month> <year> 1993. </year> <month> 93 </month>
Reference: [ Talluri and Aggarwal, 1992 ] <author> Raj Talluri and J. K. Aggarwal. </author> <title> Position estimation for an au-tonomous mobile robot in an outdoor environment. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 8(5) </volume> <pages> 573-584, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Work in both the DARPA ALV program and the Carnegie Mellon Navlab also was carried out in a structured outdoor environment with roads, their intersections and lanemarkings the predominant terrain features [ Davis et al., 1987, Thorpe et al., 1987 ] . Talluri and Aggarwal, <ref> [ Talluri and Aggarwal, 1992 ] </ref> , used a constrained search paradigm, deriving a significantly pruned search space in which to determine robot location by making terrain elevation assumptions based on altimeter and compass readings. <p> Without making these assumptions, an outdoor, unstructured environment with its rugged terrain and few distinguishable landmarks presents unique challenges to a robot navigator: * Errors in distance traveled can be significant and unpredictable, compounding as the robot moves. Whether the robot is wheeled <ref> [ Talluri and Aggarwal, 1992 ] </ref> or legged [ Hoffman and Krotkov, 1993 ] , terrain surface conditions exacerbate these errors for land vehicles. <p> In an unstructured environment, this type of error occurs frequently. * The sensors commonly used in indoor navigation do not have a large enough range to be very useful outdoors. The accuracy of a compass or barometric altimeter <ref> [ Talluri and Aggarwal, 1992 ] </ref> is often affected by conditions such as magnetic fields or atmospheric pressures in the environment to the extent that these devices are not reliable. Thus, absolute bearings, registered to a map, may not be available.
Reference: [ Thompson and Kearney, 1986 ] <author> W. B. Thompson and J. K. Kearney. </author> <title> Inexact vision. </title> <booktitle> In Proc. Workshop on Motion: Representation and Analysis, </booktitle> <pages> pages 15-21. </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1986. </year>
Reference-contexts: A mobile robot, navigating in real time and limited in the number of measurements it can take, must make the best use of the sensory data it has. In short, a successful navigator must use inexact navigation (i.e., produce good localization with only approximate information) <ref> [ Thompson and Kearney, 1986 ] </ref> .
Reference: [ Thompson and Pick, 1992 ] <author> William B. Thompson and H. L. Pick, Jr. </author> <title> Vision-based navigation. </title> <booktitle> In Proc. DARPA Image Understanding Workshop, </booktitle> <pages> pages 149-152, </pages> <address> San Mateo, CA, January 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This information, together with knowing that the viewpoint is located somewhere on the map, can be used to choose configurations of landmarks which will lead to good localization. Identifying landmarks in large-scale space is difficult and time consuming <ref> [ Thompson and Pick, 1992 ] </ref> . Rather than depend on a large pool of identified landmarks, one can start with a small basis set. Additional landmarks can be identified relative to those in the basis set only if they are needed.
Reference: [ Thompson et al., 1993 ] <author> William B. Thompson, Thomas C. Henderson, Thomas L. Colvin, Lisa B. Dick, and Carolyn M. Valiquette. </author> <title> Vision-based localization. </title> <booktitle> In Proc. DARPA Image Understanding Workshop, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: The problems of setting up view to map correspondences and dealing with any major correspondence errors were not addressed. <ref> [ Thompson et al., 1993 ] </ref> addresses those problems. A small set of correspondences are established, used to infer a viewpoint, which is then used to establish more correspondences. A constraint satisfaction approach is taken such that ambiguous correspondences generate multiple hypotheses. <p> As an example, the location of the highest point of a significant peak is 200 meters off on one of the United States Geological Survey (USGS) Digital Elevation Maps (DEMs) <ref> [ Thompson et al., 1993 ] </ref> . Navigation researchers working in small structured environments have a great deal of control over the maps they use. That is not the case for those working in large unstructured environments. Traditionally, errors in localization have been dealt with after the fact.
Reference: [ Thompson, 1958 ] <author> E. H. Thompson. </author> <title> An exact linear solution of the problem of absolute orientation. </title> <journal> Photogrammetria, </journal> <volume> 13(4) </volume> <pages> 163-178, </pages> <year> 1958. </year>
Reference-contexts: To find this relationship, one must determine scaling, translation and rotation. The early algorithms for determining absolute orientation were developed by researchers in the field of photogrammetry. In 1958, E. H. Thompson <ref> [ Thompson, 1958 ] </ref> matched model coordinates with geodetic coordinates. He projected the sphere onto the complex plane and used a system of linear equations to solve the 3D ! 3D absolute orientation problem for rotation only.
Reference: [ Thorpe et al., 1987 ] <author> Charles Thorpe, Steven Shafer, and Takeo Kanade. </author> <title> Vision and navigation for the Carnegie Mellon Navlab. </title> <booktitle> In Proc. DARPA Image Understanding Workshop, </booktitle> <pages> pages 143-152, </pages> <address> San Mateo, CA, February 1987. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Work in both the DARPA ALV program and the Carnegie Mellon Navlab also was carried out in a structured outdoor environment with roads, their intersections and lanemarkings the predominant terrain features <ref> [ Davis et al., 1987, Thorpe et al., 1987 ] </ref> . Talluri and Aggarwal, [ Talluri and Aggarwal, 1992 ] , used a constrained search paradigm, deriving a significantly pruned search space in which to determine robot location by making terrain elevation assumptions based on altimeter and compass readings.
Reference: [ Tranquilla and Al-Rizzo, 1993 ] <author> J. M. Tranquilla and H. M. Al-Rizzo. </author> <title> Investigation of GPS precise relative static positioning during periods of ice clouds and snowfall precipitation. </title> <journal> IEEE Transactions on Geoscience and Remote Sensing, </journal> <volume> 31(1) </volume> <pages> 295-299, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Atmospheric conditions also affect GPS. The signal strength is a function of the thickness of the air mass which the signal passes through [ Cohen et al., 1993 ] . Experiments have been conducted <ref> [ Tranquilla and Al-Rizzo, 1993 ] </ref> during periods of snowfall and when ice clouds were present in the atmosphere. The phase delays caused by the ice clouds and snow were calculated.
Reference: [ Tsubouchi and Yuta, 1987 ] <author> T. Tsubouchi and S. Yuta. </author> <title> Map assisted vision system of mobile robots for reckoning in a building environment. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 1978-1984. </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1987. </year>
Reference: [ Walter, 1953 ] <author> W. Grey Walter. </author> <title> The Living Brain. </title> <editor> W. W. </editor> <publisher> Norton, </publisher> <address> New York, </address> <year> 1953. </year>
Reference-contexts: Even when maps were assumed available, an attempt was made to use only simple geometric information from those maps. This need for simplicity was emphasized by W. Grey Walter <ref> [ Walter, 1953 ] </ref> in his description of the behavior of Machina speculatrix. The electromechanical M. speculatrix was built to exemplify the behaviors of a living creature. Three of those behaviors were parsimony, discernment and optima.
Reference: [ Wehner and Harkness, 1983 ] <author> Rudiger Wehner and Robert Harkness. </author> <title> Foraging Strategies in Individually Searching Ants: </title> <institution> Cataglyphis Bicolor. Akademie der Wissenschaften und der Literatur, </institution> <year> 1983. </year>
Reference-contexts: As the desert ant nears the nest site, it switches into its piloting stage, using a small number of prominent landmarks. This helps eliminate the uncertainty present in a cluttered environment as well as the directional errors which accumulated during path integration <ref> [ Collett et al., 1992, Wehner and Harkness, 1983 ] </ref> . Rather than recalling route details as it approaches the nest site, it simply passes either to the left or right of specific landmarks.
Reference: [ Wehner and Raber, 1979 ] <author> Rudiger Wehner and F. Raber. </author> <title> Visual spatial memory in desert ants, </title> <journal> cartaglyphis bicolor. Experientia, </journal> <volume> 35 </volume> <pages> 1569-1571, </pages> <year> 1979. </year>
Reference: [ Wehner and Srinivasan, 1981 ] <author> Rudiger Wehner and Mandyam Srinivasan. </author> <title> Searching behavior of desert ants, </title> <journal> genus cataglyphis. Journal of Comparative Physiology, </journal> <volume> 142 </volume> <pages> 315-338, </pages> <year> 1981. </year>
Reference-contexts: The search process that the ant goes through if it does get lost is also governed by this concept <ref> [ Wehner and Srinivasan, 1981 ] </ref> . As the desert ant nears the nest site, it switches into its piloting stage, using a small number of prominent landmarks.
Reference: [ Wehner, 1981 ] <author> Rudiger Wehner. </author> <title> Spatial vision in anthropods. </title> <editor> In H. Autrum, editor, </editor> <booktitle> Physiology and Evolution of Vision in Invertebrates, </booktitle> <pages> pages 287-617. </pages> <publisher> Springer, </publisher> <year> 1981. </year>
Reference-contexts: The zigzag flight motions employed by bees and wasps to measure distance as they back away from a nest or feeding site <ref> [ Wehner, 1981 ] </ref> contain large movements.
Reference: [ Wehner, 1990 ] <author> Rudiger Wehner. </author> <title> Do insects have cognitive maps? Annual Review of Neuro-science, </title> <booktitle> 13 </booktitle> <pages> 403-414, </pages> <year> 1990. </year> <month> 94 </month>
Reference-contexts: Distance and angle measures, fundamental to a metric map, are used to differentiate configurations. At the other extreme, a cognitive map can also be defined as the mental analogue of a topographical map <ref> [ Wehner, 1990 ] </ref> where an animal can determine its position relative to any other point within its environment, even if it has been displaced. In this wider sense, it is questionable whether or not insects possess cognitive maps at all. If they do, they are most likely weak.
Reference: [ Wichmann and Hill, 1982 ] <author> B. A. Wichmann and I. D. Hill. </author> <title> An efficient and portable pseudo-random number generator. </title> <journal> Applied Statistics, </journal> <volume> 31 </volume> <pages> 188-190, </pages> <year> 1982. </year>
Reference-contexts: The areas in the diagram corresponding to Sections 1 and 4 are each equal in size to one quarter of the total area of the square. 6 Error amounts here and in subsequent sections were generated using an implementation of the Wichmann-Hill algorithm <ref> [ Wichmann and Hill, 1982 ] </ref> . 26 Area Overestimate Underestimate 1 ff, fi, fl 3 fi ff, fl 5 ff fi, fl Table 3.1: The visual angles are either under or overestimated in each of the 6 areas of Figure 3.20.
Reference: [ Wu and Melbourne, 1993 ] <author> Sien-Chong Wu and William G. </author> <title> Melbourne. An optimal GPS data processing technique for precise positioning. </title> <journal> IEEE Transactions on Geoscience and Remote Sensing, </journal> <volume> 31 </volume> <pages> 146-152, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: The Navstar Global Positioning System (GPS) has often been promoted as an error free solution to the problem of self-localization. However, problems also exist with the use of GPS. The signals of the GPS satellites are corrupted by data noise, multipath errors, clock errors, atmospheric delays and instrumental delays <ref> [ Wu and Melbourne, 1993 ] </ref> . Selective availability encryption degrades the positioning accuracy for any user without access to the encryption [ Wu et al., 1992 ] . These users make up a large group: the entire civilian community.
Reference: [ Wu et al., 1992 ] <author> Sien-Chong Wu, W. I. Bertiger, and J. T. Wu. </author> <title> Minimizing selective availability error on satellite and positioning. </title> <journal> Journal of Guidance, Control and Dynamics, </journal> <volume> 15 </volume> <pages> 1306-1309, </pages> <month> September/October </month> <year> 1992. </year>
Reference-contexts: The signals of the GPS satellites are corrupted by data noise, multipath errors, clock errors, atmospheric delays and instrumental delays [ Wu and Melbourne, 1993 ] . Selective availability encryption degrades the positioning accuracy for any user without access to the encryption <ref> [ Wu et al., 1992 ] </ref> . These users make up a large group: the entire civilian community. Averaging techniques such as the Extended Kalman filter are used to add differential corrections to the GPS measurements and improve accuracy [ Negast and Paschall, 1992 ] .
Reference: [ Yacoob and Davis, 1992 ] <author> Yaser Yacoob and Larry Davis. </author> <title> Computational ground and airborne localization over rough terrain. </title> <booktitle> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 781-783. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1992. </year> <month> 95 </month>
Reference-contexts: Yacoob and Davis, <ref> [ Yacoob and Davis, 1992 ] </ref> , used a single point range finder, an altimeter, a compass and an inclinometer along with Digital Elevation Map (DEM) data to prune the search space.
References-found: 97

