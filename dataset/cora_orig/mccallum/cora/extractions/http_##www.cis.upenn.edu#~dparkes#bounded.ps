URL: http://www.cis.upenn.edu/~dparkes/bounded.ps
Refering-URL: http://www.cis.upenn.edu/~dparkes/home.html
Root-URL: 
Email: dparkes@unagi.cis.upenn.edu  
Title: Bounded Rationality  
Author: David C. Parkes 
Address: 200 South 33rd Street, Philadelphia, PA 19104  
Affiliation: Computer and Information Science Department University of Pennsylvania  
Abstract: Russell and Wefald (Russell & Wefald 1991) propose that the study of resource-bounded intelligent systems should be central to artificial intelligence. A resource-bounded agent acting in a time-critical domain must decide what to reason about, when, and for how long. Too little reasoning can lead to mistakes, while too much can lead to lost opportunities. We use the term bounded rationality to mean reasoning that is optimal in a utility-maximizing sense, given the bounded-resources of the agent, and the dynamic environment within which the agent is situated. Bounded rationality necessarily requires optimal meta-reasoning, that is reasoning about reasoning. This paper surveys recent research into resource-bounded rationality for artificial intelligent agents. The central thesis of this work is that it is not appropriate to design agents using a normative theory of rationality, such as decision-theoretic inference, and then add heuristics to allow the agents to operate in time-dependent environments. Russell and Wefald present a general framework for decision-theoretic metareasoning, that is reasoning about reasoning. Russell and Wefald use probability and decision theory to develop a general formula for the utility of computation. The utility of a computational action is derived from its effect on the agent's choice of action in the world. Their work is related to some early work in the decision sciences by Good (Good 1971) and Simon (Simon 1976). The problem is cast as search, with the marginal value of computation determining the optimal sequence of computations. Russell and Wefald present an application to competitive game-playing, and are able to demonstrate a substantial improvement in search efficiency when compared to alpha-beta search. Boddy and Dean (Boddy & Dean 1989), and Horvitz (Horvitz 1987), independently developed an approach to meta-reasoning for a special class of decision procedures, known as flexible computations, or anytime algorithms. Anytime algorithms guarantee that the quality of a solution increases monotonically with time, and can be interrupted at any time. The flexibility simplifies the problem of balancing computation time and quality in an uncertain environment. Boddy and Dean present a class of efficient algorithms for optimal deliberation-scheduling on a set of anytime algorithms that compute the best response of an agent to a series of events in the world. Horvitz presents an application to time-critical medical decision making, and Boddy and Dean present an application to a robot courier domain. The decision-theoretic meta-level of Russell and Wefald can be seen as a means to construct a near-optimal anytime algorithm. Zilberstein addresses the composition problem, that is how to schedule deliberation to a system of 
Abstract-found: 1
Intro-found: 1
Reference: <author> Agre, P. E., and Chapman, D. </author> <year> 1991. </year> <title> Pengi: An implementation of a theory of activity. </title> <booktitle> In Proc. 9th National Conference on Artificial Intelligence (AAAI-91), </booktitle> <pages> 268-272. </pages> <note> 45 Boddy, </note> <author> M., and Dean, T. </author> <year> 1989. </year> <title> Solving time-dependent planning problems. </title> <booktitle> In Proc. 11th International Joint Conference on Artificial Intelligence (IJCAI-89) (1989), </booktitle> <pages> 979-984. </pages>
Reference: <author> Boddy, M., and Dean, T. L. </author> <year> 1994. </year> <title> Deliberation scheduling for problem solving in time-constrained environments. </title> <booktitle> Artificial Intelligence 67 </booktitle> <pages> 245-285. </pages>
Reference-contexts: The metareasoning problem is then cast as one of deliberation scheduling: a resource-bounded rational agent should allocate computational resources to the anytime algorithm that has the highest utility. Boddy and Dean <ref> (Boddy & Dean 1994) </ref> study deliberation scheduling for time-dependent planning problems, when there are events in the real world that the agent must react to, and these events are known ahead of time. As time passes the agent must make a sequence of time-critical decisions. <p> The robot must complete all deliberation about a path between two locations before it starts to travel between the two locations, the robot can deliberate about future paths as it moves, and the robot may stop and deliberate at any time. Boddy and Dean <ref> (Boddy & Dean 1994) </ref> consider a few special instances of this problem. First consider a model where all the deliberations are performed before carrying out any 21 task. <p> of the first segment is the same for all profiles and the slope of the second is 0. 3.4 Deliberation Scheduling in response to events in the world Dean and Boddy are able to present an optimal solution to the simpler problem of re sponding to events in the world <ref> (Boddy & Dean 1994) </ref>. The agent knows about some set 26 of pending events that it has to formulate a response to. This problem is simpler because the decision processes are independent. <p> Assuming a diminishing returns performance profile Boddy and Dean are able construct optimal deliberation-schedules using a polynomial-time algorithm <ref> (Boddy & Dean 1994) </ref>. Boddy and Dean extend the algorithms to the case where 27 the exact time of the occurrence of conditions is not known. <p> The agent constructs a schedule that allocates some amount of time to some of the decision procedures, not allocating any time after the even occurs. Dean and Boddy describe a pair of algorithms for finding optimal schedules <ref> (Boddy & Dean 1994) </ref>. The first algorithm (DS-1) assumes that the gain for a performance profile at any particular time is available. The algorithm schedules backwards from the latest deadline to the current time, in fixed increments of size .
Reference: <author> Boddy, M. </author> <year> 1991. </year> <title> Solving time-dependent problems: A decision theoretic approach to planning in dynamic environments. </title> <type> Technical Report CS-91-06, </type> <institution> Department of Computer Science, Brown University. </institution>
Reference-contexts: The average travel time of a path with no planning is T i;j (0) = 3:17d i;j =v, where v is the velocity of the robot. The expected travel time for a path after maximum useful 1 The values presented here are from <ref> (Boddy 1991) </ref>, and differ slightly from those in (Boddy & Dean 1989) 20 deliberation is T i;j (ffi fl j ) = 1:17d i;j =v, and the expected travel time saved, (ffi j ), for ffi j ffi fl j , (ffi) = T i;j T i;j (ffi) 3:17d i;j ffi <p> The procedure allocates deliberation times ffi i , 0 &lt; i k, and returns the total length of the optimal tour, including deliberation time and journey time. The correctness of the algorithm is proved by Boddy <ref> (Boddy 1991) </ref>. The correctness is based on three properties: 1. Any optimal deliberation schedule can be transformed without cost into a deliberation schedule in which the robot deliberates about each path in turn, in the order in which they occur. 2. <p> Note that if fl &lt; 1 we never do any deliberation for T 0;1 , because deliberation time is larger than the expected decrease in travel time. Even when fl &lt; 1 however, we should deliberate during the execution of tasks, since this deliberation 2 This algorithm is from <ref> (Boddy 1991) </ref> and differs from (Boddy & Dean 1989) 22 is essentially "free". The optimal solution is ffi 1 = 112, and ffi 2 = ffi 3 = 133, which gives T 0;1 = 149, and T 1;2 = T 2;3 = 117. <p> The third condition is derived by setting the execution time saved by deliberation so that the total time spent in execution is equal to that needed for deliberation. The problem can also be cast as a linear optimization problem <ref> (Boddy 1991) </ref>. 3.3.2 Pr-II: Tour-improvement followed by Path-planning We now allow the tour S to be reordered, but only before any path-planning. Given a tour S we can generate a schedule for path-planning using Pr-I. <p> The algorithm then updates this schedule to include deliberation for path-planning, where it has a greater expected value than tour-improvement, and seeks an optimal value for the partition f0; : : : ; igfi; : : : ; kg. 3.3.4 A comparison: Pr-I, Pr-II and Pr-III Boddy <ref> (Boddy 1991) </ref> performed a series of experiments involving randomly-generated environments and sets of locations for the robot to visit. <p> From the quality map of the performance of an algorithm A we can generate the expected performance profile (EPP), a function E A : &lt; + ! &lt; that maps computation time to the expected quality of results (this is the performance profile used by Boddy and Dean <ref> (Boddy 1991) </ref>). Zilberstein and Russell introduce three new types of performance profiles, that allow a trade-off between accuracy, compactness of representation, and efficiency for reasoning. The first is the performance distribution profile (PDP).
Reference: <author> Brooks, R. A. </author> <year> 1986. </year> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation 2 </journal> <pages> 14-23. </pages>
Reference: <author> Chase, W. G., and Simon, H. A. </author> <year> 1973. </year> <title> Skill in chess. </title> <journal> American Scientist 394-403. </journal>
Reference-contexts: There is good evidence that grandmasters compare up to 50,000 board positions that they have studied to the current situation, and that they are able to choose the right move "intuitively", because they are unaware of the reasoning process that is occurring in the brain <ref> (Chase & Simon 1973) </ref>. If the computer did the same thing the trick would be revealed - but would it not still be "intelligent"? The metareasoning that happens unconsciously in the brain must be explicitly considered in an artificial agent.
Reference: <author> Cooper, G. F. </author> <year> 1984. </year> <title> Nestor: A computer-based medical diagnostic aid that integrates causal and probabilistic knowledge. </title> <type> Technical Report STAN-CS-84-48, </type> <institution> Computer Science Department, Stanford University. </institution>
Reference-contexts: Horvitz uses a probabilistic bounding strategy for the computation, that determines upper and lower bounds on point probabilities of interest through a logical analysis of constraints acquired from partial analysis. Bounds become tighter as additional constraints are brought into consideration <ref> (Cooper 1984) </ref>. The precision of this decision procedure, S 1 , increases with time as illustrated in Figure 10 (a). The physician then provides the expert knowledge to enable values to be assigned to partial results.
Reference: <author> Cooper, G. F. </author> <year> 1990. </year> <title> Probabilistic inference using belief networks is NP-hard. </title> <booktitle> Artificial Intelligence 42 </booktitle> <pages> 393-405. </pages>
Reference-contexts: Instead of competing as normative theories, logical and economic notions of rationality fill complementary needs. Logic describes the possibilities for reasoning and action, and economics allows an agent to make choices among these. However, decision-theoretic reasoning is in general N P-hard <ref> (Cooper 1990) </ref>. The normative use of decision theory provides a standard for rationality, but one which is often unattainable due to limitations on the available information or resources. <p> The goal is to extend the principles of normative rationality to situations of uncertain, varying and scarce resources. Traditional decision theory has the desirable property that it finds provably optimal solutions to problems. Unfortunately the updating of beliefs using probabilistic inference is N P-hard <ref> (Cooper 1990) </ref>, making traditional decision-theory unsuitable for most real-time situations. Horvitz seeks to apply normative methods to provide bounded-rational solutions to otherwise intractable problems. Rational reasoning at the meta-level necessarily requires knowledge about the inference costs, and real-world costs and benefits.
Reference: <author> Doyle, J. </author> <year> 1989. </year> <title> Rationality and its roles in reasoning. </title> <booktitle> In Proc. 7th National Conference on Artificial Intelligence (AAAI-89), </booktitle> <pages> 1093-1100. </pages>
Reference-contexts: The approach is summarized by Newell: If one of the available actions leads to one of the goals, take it! (Newell 1981). Another view of rationality is termed economic rationality <ref> (Doyle 1989) </ref>. Economic rationality provides formal tools for understanding heuristics and reasoning, and a rigorous normative framework for analyzing utility and probability. We use utility theory to represent degrees of goodness: an agent is rational if it chooses the action with the maximum expected utility.
Reference: <author> Good, I. J. </author> <year> 1971. </year> <title> Twenty-seven principles of rationality. </title> <editor> In Godambe, V. P., and Sprott, D. A., eds., </editor> <booktitle> Foundations of Statistical Inference. </booktitle>
Reference-contexts: Good <ref> (Good 1971) </ref> provided the earliest discussion of the explicit integration of the costs of inference within the framework of normative rationality.
Reference: <author> Grass, J., and Zilberstein, S. </author> <year> 1996. </year> <title> Anytime algorithm development tools. </title> <journal> SIGART Bulleting 7(2) </journal> <pages> 20-27. </pages>
Reference-contexts: The future goal of Zilberstein's work is to develop a complete theory of anytime 43 rationality for an agent situated in the world. Current research efforts are aimed at studying additional programming structures, producing a large library of anytime algorithms <ref> (Grass & Zilberstein 1996) </ref>, and extending the model to include anytime sensing and anytime actions (Zilberstein 1993). 6 Conclusions We have argued that the concept of intelligence for resource-bounded agents must necessarily be defined in terms of the reasoning that the agent does, given its resources, and a model of the
Reference: <author> Hansen, E. A., and Zilberstein, S. </author> <year> 1996. </year> <title> Monitoring the progress of anytime problem-solving. </title> <booktitle> In Proc. 14th National Conference on Artificial Intelligence (AAAI-96), </booktitle> <pages> 1229-1234. </pages>
Reference-contexts: An interesting property is that they recommend monitoring more frequently near the expected stopping time of the algorithm (intuitive). When solution quality cannot be determined at run-time, a similar policy can be developed based on estimated solution quality <ref> (Hansen & Zilberstein 1996) </ref>. 42 5.7 Zilberstein and Russell: Summary Zilberstein and Russell are able to show that a system of modular anytime algorithms can be compiled efficiently into a global anytime system, given certain constraints on the form of the compositions.
Reference: <author> Horvitz, E. J., and Breese, J. S. </author> <year> 1990. </year> <title> Ideal partition of resources for metareasoning. </title> <type> Technical Report KSL-90-26, </type> <institution> Knowledge Systems Laboratory, Stanford University. </institution>
Reference-contexts: This tradeoff is illustrated in Figure 13. 4.3 A general framework for metareasoning Horvitz has also looked at the general problem of partitioning resources between metareason-ing and base-level problem solving <ref> (Horvitz & Breese 1990) </ref>. In particular, he examines how much time to devote to deliberation-scheduling when both scheduling and base-level reasoning are carried out using anytime algorithms. For particular classes of anytime algorithms, Horvitz and Breese are able to find optimal solutions to the problem of metareasoning.
Reference: <author> Horvitz, E. J. </author> <year> 1987. </year> <title> Reasoning about beliefs and actions under computational resource constraints. </title> <booktitle> In Proc. 3rd AAAI Workshop on Uncertainty in Artificial Intelligence, </booktitle> <pages> 429-444. </pages>
Reference-contexts: A meta-level rational agent selects computations according to the expected utility. The fourth is bounded optimality, which is a term originated by Horvitz <ref> (Horvitz 1987) </ref>. Bounded optimality is really the ultimate goal for a real artificial intelligent agent. <p> Boddy and Dean motivate the composition problem for anytime algorithms, that is how to schedule deliberation to a system of dependent anytime algorithms , which is the main thesis of Zilberstein's (Zilberstein & Russell 1996) later work. 4 Horvitz: Flexible Computations Horvitz <ref> (Horvitz 1987) </ref> takes a similar approach to that of Boddy and Dean. He also proposes anytime algorithms, he terms them flexible computations, for decision processes. The main focus of his work is on the control of probabilistic inference in medical decision-making. <p> The approach scales to reasoning about the best use of resources when an agent must respond to a known sequence of deterministic events in the world. Horvitz <ref> (Horvitz 1987) </ref> complements the work by providing an explicit consideration of the costs of computation. He decomposes the utility of a computation into the object-level, that is time-independent, and the inference-level, that reflects the time-value of a decision. Horvitz presents an example to a time-critical decision problem in the medical-domain.
Reference: <author> Howard, R. A. </author> <year> 1966. </year> <title> Information value theory. </title> <journal> IEEE Transactions on Systems Science and Cybernetics SSC-2:22-26. </journal>
Reference-contexts: Procedural rationality of a grandmaster in chess comes from heuristics for selective search, and knowledge of significant patterns. Search is terminated when a satisfactory solution is found, not when the optimal solution is found (Newell & Simon 1972). The theory of information value <ref> (Howard 1966) </ref> has many parallels with the work on metareasoning that we survey here. <p> Russell and Wefald (Russell & Wefald 1991) present a powerful framework for metalevel rationality, using information value theory <ref> (Howard 1966) </ref>, to derive conditions that define how the agent should deliberate at the base-level. The "external model" that they promote underlies the theory of normative metareasoning.
Reference: <author> Korf, R. E. </author> <year> 1988. </year> <title> Real-time heuristic search: New results. </title> <booktitle> In Proc. 6th National Conference on Artificial Intelligence (AAAI-88), </booktitle> <pages> 139-144. </pages>
Reference-contexts: The second algorithm that the robot may use is a path-planning algorithm. The path-planning algorithm plans the exact path that the robot will take between consecutive locations on its tour. The algorithm is a heuristic A* search <ref> (Korf 1988) </ref>, that does not guarantee to generate an optimal path between any two locations, but does better than the dead-reckoning, bouncing off obstacles and finding its way around them, that the robot must otherwise use.
Reference: <author> Lin, S., and Kernighan, B. W. </author> <year> 1973. </year> <title> An effective heuristic for the Traveling Salesman Problem. </title> <journal> Operations Research 21 </journal> <pages> 498-516. </pages>
Reference-contexts: The algorithm for tour improvement is based on an iterative-improvement algorithm for the Traveling Salesperson Problem <ref> (Lin & Kernighan 1973) </ref>. The algorithm guesses an initial tour, and then produces tours that are progressively closer to an optimal tour by exchanging small sets of edges such that the tour is still complete, but the length of the overall tour decreases (Figure 3).
Reference: <author> McCarthy, J. </author> <year> 1958. </year> <title> Programs with common sense. </title> <booktitle> In Proc. of the Symp. Mechanization of Thought Processes. </booktitle> <address> HMSO. </address>
Reference-contexts: Russell and Wefald (Russell & Wefald 1991) propose that the study of resource-bounded intelligent systems should be central to artificial intelligence. 1.1 A brief history of rationality within AI In artificial intelligence the logical approach provided the first formal definition of rationality <ref> (McCarthy 1958) </ref>. Logical rationality assumes that an agent can be described in terms of its beliefs and goals, and that an agent is rational if it satisfies one of the goals entailed by its beliefs.
Reference: <author> Newell, A., and Simon, H. A. </author> <year> 1972. </year> <title> Human Problem Solving. </title>
Reference-contexts: Procedural rationality of a grandmaster in chess comes from heuristics for selective search, and knowledge of significant patterns. Search is terminated when a satisfactory solution is found, not when the optimal solution is found <ref> (Newell & Simon 1972) </ref>. The theory of information value (Howard 1966) has many parallels with the work on metareasoning that we survey here.
Reference: <author> Newell, A. </author> <year> 1981. </year> <title> The knowledge level. </title> <journal> AI Magazine 2 </journal> <pages> 1-20. </pages>
Reference-contexts: The emphasis was on finding a satisficing solution, that is any solution to a problem that solved the goal, and there was no notion of quality. The approach is summarized by Newell: If one of the available actions leads to one of the goals, take it! <ref> (Newell 1981) </ref>. Another view of rationality is termed economic rationality (Doyle 1989). Economic rationality provides formal tools for understanding heuristics and reasoning, and a rigorous normative framework for analyzing utility and probability.
Reference: <author> Russell, S., and Wefald, E. </author> <year> 1989. </year> <title> On optimal game-tree search using rational meta-reasoning. </title> <booktitle> In Proc. 11th International Joint Conference on Artificial Intelligence (IJCAI-89) (1989), </booktitle> <pages> 334-340. </pages>
Reference: <author> Russell, S., and Wefald, E. </author> <year> 1991. </year> <booktitle> Principles of metareasoning. Artificial Intelligence 49 </booktitle> <pages> 361-395. </pages>
Reference-contexts: Kasparov was able to use pattern matching and intuition to recognize the move, while Deep Blue would have needed to do a very deep search to recognize its value. The combinatorial explosion of the search domain for chess makes the control of search critical. Russell and Wefald <ref> (Russell & Wefald 1991) </ref> apply decision-theoretic principles to the control of search, and are able to show significant gains over a heuristic control technique such as alpha-beta pruning for competitive-game playing. A resource-bounded agent acting in a time-critical domain must decide what to reason about, when, and for how long. <p> The central thesis is that it is not appropriate to design agents using a normative theory of rationality, such as decision-theoretic inference, and then add heuristics to allow the agents to operate in time-dependent environments. Russell and Wefald <ref> (Russell & Wefald 1991) </ref> propose that the study of resource-bounded intelligent systems should be central to artificial intelligence. 1.1 A brief history of rationality within AI In artificial intelligence the logical approach provided the first formal definition of rationality (McCarthy 1958). <p> An efficient search algorithm, MGSS*, is developed for Othello that soundly beats heuristic alpha-beta search in a tournament of games, while expanding significantly fewer nodes and taking less time <ref> (Russell & Wefald 1991) </ref>. A search program proceeds by expanding leaf nodes and propagating the value information back to the parents. The value that will be assigned to a new leaf node depends on the type of leaf node and the nature of the computation. <p> We reassert the thesis of the work surveyed here: the study of resource-bounded agents should be central to AI, since perfect rationality and epistemological correctness provide neither an adequate theoretical or practical framework. Russell and Wefald <ref> (Russell & Wefald 1991) </ref> present a powerful framework for metalevel rationality, using information value theory (Howard 1966), to derive conditions that define how the agent should deliberate at the base-level. The "external model" that they promote underlies the theory of normative metareasoning.
Reference: <author> Russell, S. J.; Subramanian, D.; and Parr, R. </author> <year> 1993. </year> <title> Provably bounded optimal agents. </title> <booktitle> In Proc. 13th International Joint Conference on Artificial Intelligence (IJCAI-93), </booktitle> <pages> 338-344. </pages>
Reference: <author> Russell, S. </author> <year> 1995. </year> <booktitle> Ratonality and intelligence. In Proc. 14th International Joint Conference on Artificial Intelligence (IJCAI-95). </booktitle>
Reference: <author> Schoppers, M. J. </author> <year> 1987. </year> <title> Universal plans for reactive robots in unpredictable environments. </title> <booktitle> In Proc. 10th International Joint Conference on Artificial Intelligence (IJCAI-87), </booktitle> <pages> 1039-1046. </pages>
Reference-contexts: Instead agents have reactive mechanisms that generate actions in response to interactions with the physical world. Brooks argues that we can achieve intelligence in this way without reason, that agents can be right by design. A similar approach is that of Universal Planning <ref> (Schoppers 1987) </ref>. Agents determine what to do next by finding a result in a large look-up table. This solution to the problem of bounded-resource agents in time-critical environments seems unsatisfying, and is also infeasible in complex domains where the look-up table quickly becomes too large.
Reference: <author> Simon, H. A. </author> <year> 1976. </year> <title> From substantive to procedural rationality. </title> <editor> In Latsis, S. J., ed., </editor> <title> Method and Appraisal in Economics. </title> <publisher> Cambridge University Press. </publisher> <pages> 129-148. </pages>
Reference-contexts: Simon <ref> (Simon 1976) </ref> also considers two types of rationality: procedural rationality where the agent must compute the rational thing to do, and substantive rationality where the agent must simply do the right thing, and rationality is judged by actions in the world.
Reference: <author> Simon, H. A. </author> <year> 1978. </year> <title> On how to decide what to do. </title> <journal> The Bell Journal of Economics 9(2) </journal> <pages> 494-507. </pages>
Reference-contexts: 1 Introduction Artificial Intelligence is the discipline that is concerned with programming computers to do clever, humanoid things but not necessarily to do them in a humanoid way. <ref> (Simon 1978) </ref> It seems pertinent to begin our discussion of resource-bounded rationality, and what it means to be intelligent, with the man-machine contest on the 35th floor of the Equitable Center, mid-town Manhattan, that has been dominating the media all week.
Reference: <author> Zilberstein, S., and Russell, S. </author> <year> 1996. </year> <title> Optimal composition of real-time systems. </title> <booktitle> Artificial Intelligence 82 </booktitle> <pages> 181-213. </pages> <note> 47 Zilberstein, </note> <author> S. </author> <year> 1993. </year> <title> Operational Rationality through compilation of anytime algorithms. </title> <type> Ph.D. Dissertation, </type> <institution> Computer Science Division, University of California, Berkeley, </institution> <address> CA. </address> <month> 48 </month>
Reference-contexts: Boddy and Dean motivate the composition problem for anytime algorithms, that is how to schedule deliberation to a system of dependent anytime algorithms , which is the main thesis of Zilberstein's <ref> (Zilberstein & Russell 1996) </ref> later work. 4 Horvitz: Flexible Computations Horvitz (Horvitz 1987) takes a similar approach to that of Boddy and Dean. He also proposes anytime algorithms, he terms them flexible computations, for decision processes. <p> This assumption is consistent with one of the tenets of good code design modularity. With a compact tabular representation of PPs, local compilation can be performed in constant time, and the overall complexity of compilation becomes linear in the size of the program <ref> (Zilberstein & Russell 1996) </ref>. 5.5 Heuristics for the general problem Zilberstein present three heuristic time allocation methods that deal with general functional expressions: HILL-CLIMBING-ALLOCATION, CONDITIONING-ALLOCATION, and TRADING-ALLOCATION. The choice of algorithm to use represents a tradeoff between guaranteeing optimality, and achieving an efficient algorithm. <p> More generally, monitoring allows a trade-off between off-line compilation and run-time deliberation. An active approach to monitoring is useful when the utility function is not predictable. Zilberstein <ref> (Zilberstein & Russell 1996) </ref> suggests using the expected marginal value of computation to continually make resource scheduling decisions. The monitor estimates the difference between the expected utility after one more time increment and the current expected utility. <p> An interesting property is that they recommend monitoring more frequently near the expected stopping time of the algorithm (intuitive). When solution quality cannot be determined at run-time, a similar policy can be developed based on estimated solution quality <ref> (Hansen & Zilberstein 1996) </ref>. 42 5.7 Zilberstein and Russell: Summary Zilberstein and Russell are able to show that a system of modular anytime algorithms can be compiled efficiently into a global anytime system, given certain constraints on the form of the compositions. <p> The future goal of Zilberstein's work is to develop a complete theory of anytime 43 rationality for an agent situated in the world. Current research efforts are aimed at studying additional programming structures, producing a large library of anytime algorithms <ref> (Grass & Zilberstein 1996) </ref>, and extending the model to include anytime sensing and anytime actions (Zilberstein 1993). 6 Conclusions We have argued that the concept of intelligence for resource-bounded agents must necessarily be defined in terms of the reasoning that the agent does, given its resources, and a model of the
References-found: 27

