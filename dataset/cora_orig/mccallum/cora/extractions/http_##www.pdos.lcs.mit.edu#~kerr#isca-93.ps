URL: http://www.pdos.lcs.mit.edu/~kerr/isca-93.ps
Refering-URL: http://www.pdos.lcs.mit.edu/~kerr/papers.html
Root-URL: 
Email: noakes@ai.mit.edu, kerr@ai.mit.edu, billd@ai.mit.edu  
Title: The J-Machine Multicomputer: An Architectural Evaluation  
Author: Michael D. Noakes, Deborah A. Wallach, and William J. Dally 
Address: Cambridge, Massachusetts 02139  
Affiliation: Artificial Intelligence Laboratory and Laboratory for Computer Science Massachusetts Institute of Technology  
Date: May 1993.  
Note: Appears in Proceedings of the 20th International Symposium on Computer Architecture,  
Abstract: The MIT J-Machine multicomputer has been constructed to study the role of a set of primitive mechanisms in providing efficient support for parallel computing. Each J-Machine node consists of an integrated multicomputer component, the Message-Driven Processor (MDP), and 1 MByte of DRAM. The MDP provides mechanisms to support efficient communication, synchronization, and naming. A 512 node J-Machine is operational and is due to be expanded to 1024 nodes in March 1993. In this paper we discuss the design of the J-Machine and evaluate the effectiveness of the mechanisms incorporated into the MDP. We measure the performance of the communication and synchronization mechanisms directly and investigate the behavior of four complete applications. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> AGARWAL, A. </author> <title> Limits on interconnection network performance. </title> <journal> IEEE Transactions on Parallel and Distributed Systems 2, </journal> <month> 4 (Oct. </month> <year> 1991), </year> <pages> 398-412. </pages>
Reference-contexts: The figure shows that random traffic causes the network of a 512-node J-Machine to saturate with a bisection traffic of 6Gbits/sec, nearly half of the bisection capacity (14.4Gbits/sec). This measurement is consistent with analytical predictions and simulation studies <ref> [1] </ref> [4]. The figure also shows that the component of latency due to contention increases in the expected manner [1]. The right-hand side of Figure 3 uses the same data to illustrate how network contention affects the achievable ratio of communication to computation. <p> This measurement is consistent with analytical predictions and simulation studies <ref> [1] </ref> [4]. The figure also shows that the component of latency due to contention increases in the expected manner [1]. The right-hand side of Figure 3 uses the same data to illustrate how network contention affects the achievable ratio of communication to computation.
Reference: [2] <author> BAKER, H. C., AND HEWITT, C. </author> <title> The incremental garbage collection of processes. </title> <booktitle> In Conference Record of the Conference on AI and Programming Languages (Rochester, </booktitle> <address> New York, </address> <month> Aug. </month> <year> 1977), </year> <booktitle> ACM, </booktitle> <pages> pp. 55-59. </pages>
Reference-contexts: In this event, the arrival of the value is used to restart the thread. The cfut type provides inexpensive synchronization on a single slot, much like a full-empty bit. The fut type may be copied without faulting and thus supports the more flexible, but more expensive, future datatype <ref> [2] </ref>. Futures are first-class data objects and references to them may be returned from functions and stored in arrays, for example. The MDP supports a global namespace with segmented memory management and with name translation instructions.
Reference: [3] <author> BLELLOCH, G. </author> <title> Scans as primitive parallel operations. </title> <booktitle> In International Conference on Parallel Processing (1987), </booktitle> <pages> pp. </pages> <month> S355-362. </month>
Reference-contexts: Our numbers represent the time taken from the point at which the current thread calls the barrier routine until the time this single thread is resumed. The barrier synchronization library routine is implemented in a scan <ref> [3] </ref> style. For an n processor machine, O (n log 2 n) messages are sent, n per wave. The pattern formed by the messages is that of a butterfly network mapped onto a 3-d grid, with the messages sent each wave representing one stage of the butterfly.
Reference: [4] <author> DALLY, W. J. </author> <title> Performance analysis of k-ary n-cube interconnection networks. </title> <journal> IEEE Trans. Comput. </journal> <volume> 39, </volume> <month> 6 (June </month> <year> 1990). </year>
Reference-contexts: The format of a message is arbitrary except that the first word must contain the address of the code to run at the destination and the length of the message. Messages are routed through the 3D-mesh network using deterministic, e-cube, wormhole routing <ref> [4] </ref>. The channel bandwidth is 0.5 words/cycle and the minimum latency is 1 cycle/hop. Upon arrival, messages are buffered in a hardware queue. When a message arrives at the head of the queue, a task is dispatched to handle it in four processor cycles. <p> The figure shows that random traffic causes the network of a 512-node J-Machine to saturate with a bisection traffic of 6Gbits/sec, nearly half of the bisection capacity (14.4Gbits/sec). This measurement is consistent with analytical predictions and simulation studies [1] <ref> [4] </ref>. The figure also shows that the component of latency due to contention increases in the expected manner [1]. The right-hand side of Figure 3 uses the same data to illustrate how network contention affects the achievable ratio of communication to computation.
Reference: [5] <author> DALLY, W. J., FISKE, J. S., KEEN, J. S., LETHIN, R. A., NOAKES, M. D., NUTH, P. R., DAVISON, R. E., AND FYLER, G. A. </author> <title> The Message-Driven Processor: A multicomputer processing node with efficient mechanisms. </title> <booktitle> IEEE Micro 12, </booktitle> <month> 2 (Apr. </month> <year> 1992), </year> <pages> 23-39. </pages>
Reference-contexts: These mechanisms do not efficiently support synchronization of threads, communication of data, or global naming of objects. As a result, these functions, inherent to any parallel model of computation, must be implemented largely in software with prohibitive overhead. The J-Machine project <ref> [5] </ref> was developed to study how to best apply modern VLSI technology to construct a multi-computer. Each processing node of the J-Machine consists of a Message-Driven Processor (MDP) and 1 MByte of DRAM.
Reference: [6] <author> DUNIGAN, T. </author> <title> Communication performance of the Intel Touchstone Delta mesh. </title> <type> Tech. Rep. </type> <institution> ORNL/TM-11983, Oak Ridge National Laboratory, </institution> <month> Jan. </month> <year> 1992. </year>
Reference-contexts: T s is the sum of the fixed overheads of send and receive. T b is the injection overhead per byte <ref> [6] </ref>, [17]. pinging itself. This latency consists of two trips through the network at a total cost of 24 cycles, and the execution of two threads at a total cost of 19 cycles. <p> Software barrier synchronization (sec) Nodes EM4 J KSR IPSC/860 Delta 2 2.7 4.4 60 111 109 8 4.7 8.7 180 381 473 32 14.4 525 692 1816 128 20.7 512 27.4 Table 3: Barrier synchronization <ref> [6] </ref>, [7], [14]. performance of our algorithm to similar routines on other machines as presented in the literature since sufficient detail to determine what is being included is rarely provided.
Reference: [7] <author> DUNIGAN, T. </author> <title> Kendall Square multiprocessor: early experiences and performance. </title> <type> Tech. Rep. </type> <institution> ORNL/TM-12065, Oak Ridge National Laboratory, </institution> <month> Mar. </month> <year> 1992. </year>
Reference-contexts: Software barrier synchronization (sec) Nodes EM4 J KSR IPSC/860 Delta 2 2.7 4.4 60 111 109 8 4.7 8.7 180 381 473 32 14.4 525 692 1816 128 20.7 512 27.4 Table 3: Barrier synchronization [6], <ref> [7] </ref>, [14]. performance of our algorithm to similar routines on other machines as presented in the literature since sufficient detail to determine what is being included is rarely provided.
Reference: [8] <author> HORWAT, W. </author> <title> A Concurrent Smalltalk compiler for the Message-Driven Processor. AI Memo, </title> <publisher> MIT, </publisher> <address> 545 Technology Sq., Cambridge, MA 02139, </address> <month> May </month> <year> 1988. </year> <type> SB Thesis. </type>
Reference-contexts: The run times on a single node of the J-machine running at 12.5 MHz varied from 8% faster to 20% slower than the C versions compiled with a C compiler and run on a Intel 386SX processor at 33 MHz. CST The Concurrent Smalltalk programming system <ref> [8] </ref> supports object-based abstraction mechanisms and encourages fine-grained program composition. It extends sequential Smalltalk by supporting asynchronous method invocation, distributed objects, and a small repertoire of control constructs for explicit specification of parallel control flow. The compiler and runtime system provide the programmer with a global object namespace.
Reference: [9] <author> HSU, J.-M., AND BANERJEE, P. </author> <title> Performance measurement and trace driven simulation of parallel and numeric applications on a hypercube multicomputer. </title> <booktitle> In 17th Annual International Symposium on Computer Architecture (1990), </booktitle> <publisher> IEEE Press, </publisher> <pages> pp. 260-269. </pages>
Reference-contexts: A remote operation incurs overhead due to message setup, channel acquisition, and message invocation. This overhead is traditionally amortized by ensuring that remote accesses transfer relatively large amounts of data <ref> [9] </ref>. Requiring coarse-grain communication complicates programming in general and makes fine-grained synchronization and effective load-balancing particularly difficult. The efficient communication mechanisms of the J-Machine enable us to approach the effective terminal bandwidth of the network using small messages. be sustained between two nodes for a given message size.
Reference: [10] <author> KECKLER, S. W., AND DALLY, W. J. </author> <title> Processor coupling: Integrating compile time and runtime scheduling for parallelism. </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture (Queensland, </booktitle> <address> Australia, </address> <month> May </month> <year> 1992), </year> <booktitle> ACM, </booktitle> <pages> pp. 202-213. </pages>
Reference-contexts: We are currently researching methods of increasing the number of architectural registers without increasing context switch time for short-lived tasks [13]. To extract more parallelism out of an application of a given size, we are exploring ways to combine compile-time and run-time scheduling to exploit inter-thread and instruction-level parallelism <ref> [10] </ref>. The data presented here demonstrates that the J-Machine's communication, synchronization, and naming mechanisms are effective in supporting programs with small task sizes (150 instructions).
Reference: [11] <author> KNOBE, K., LUKAS, J. D., AND DALLY, W. J. </author> <title> Dynamic alignment on distributed memory systems. </title> <booktitle> In The Third Workshop on Compilers for Parallel Computers (Vienna, </booktitle> <address> Austria, </address> <month> July </month> <year> 1992), </year> <note> Austrian Center for Parallel Computation. </note>
Reference-contexts: Future directions Our experience with the J-Machine has shown that global bandwidth is a critical resource that limits the computation to communication ratio for highly parallel programs. To reduce the demand for bandwidth, we are exploring methods for building parallel software systems that minimize communication by exploiting locality <ref> [11] </ref>. The MDP's paucity of registers, while reducing context switch time, resulted in more memory references than were necessary. We are currently researching methods of increasing the number of architectural registers without increasing context switch time for short-lived tasks [13].
Reference: [12] <author> NIKHIL, R. S., AND ARVIND. </author> <title> Id language reference manual version 90.1. </title> <type> Tech. Rep. </type> <month> 284-2, </month> <title> Computation Structures Group, </title> <publisher> MIT, </publisher> <address> Cambridge, MA 02139, </address> <year> 1991. </year>
Reference-contexts: Two other programming systems are also running on the machine: Id <ref> [12] </ref> [15] and PCN [16]. Tuned J The J language serves as a system-level programming language for the J-Machine. It extends a per-node ANSI C environment with a small number of additional constructs for remote function invocation and synchronization.
Reference: [13] <author> NUTH, P. R., AND DALLY, W. J. </author> <title> A mechanism for efficient context switching. </title> <booktitle> In Proceedings of the International Conference on Computer Design: VLSI in Computers & Processors (Oct. 1991), IEEE, </booktitle> <pages> pp. 301-304. </pages>
Reference-contexts: The MDP's paucity of registers, while reducing context switch time, resulted in more memory references than were necessary. We are currently researching methods of increasing the number of architectural registers without increasing context switch time for short-lived tasks <ref> [13] </ref>. To extract more parallelism out of an application of a given size, we are exploring ways to combine compile-time and run-time scheduling to exploit inter-thread and instruction-level parallelism [10].
Reference: [14] <author> SHAW, A. </author> <title> Implementing data-parallel software on dataflow hardware. </title> <type> Master's thesis, </type> <institution> MIT, Laboratory for Computer Science, 545 Technology Square, </institution> <address> Cambridge, MA 02139, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: Software barrier synchronization (sec) Nodes EM4 J KSR IPSC/860 Delta 2 2.7 4.4 60 111 109 8 4.7 8.7 180 381 473 32 14.4 525 692 1816 128 20.7 512 27.4 Table 3: Barrier synchronization [6], [7], <ref> [14] </ref>. performance of our algorithm to similar routines on other machines as presented in the literature since sufficient detail to determine what is being included is rarely provided.
Reference: [15] <author> SPERTUS, E. </author> <title> Execution of dataflow programs on general-purpose hardware. </title> <type> MS Thesis, </type> <institution> Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science, </institution> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: Two other programming systems are also running on the machine: Id [12] <ref> [15] </ref> and PCN [16]. Tuned J The J language serves as a system-level programming language for the J-Machine. It extends a per-node ANSI C environment with a small number of additional constructs for remote function invocation and synchronization.
Reference: [16] <author> TAYLOR, S., ET AL. </author> <title> Scalable concurrent programming project. </title> <type> Semiannual technical report, </type> <institution> Dept. of Computer Science, California Institute of Technology, </institution> <month> Apr. </month> <year> 1992. </year>
Reference-contexts: Two other programming systems are also running on the machine: Id [12] [15] and PCN <ref> [16] </ref>. Tuned J The J language serves as a system-level programming language for the J-Machine. It extends a per-node ANSI C environment with a small number of additional constructs for remote function invocation and synchronization.
Reference: [17] <author> VON EICKEN, T., CULLER, D., GOLDSTEIN, S., AND SCHAUSER, K. </author> <title> Active messages: A mechanism for integrated communication and computation. </title> <booktitle> In Proceedings of 19th Annual International Symposium on Computer Architecture (1992), IEEE, </booktitle> <pages> pp. 256-266. </pages>
Reference-contexts: T s is the sum of the fixed overheads of send and receive. T b is the injection overhead per byte [6], <ref> [17] </ref>. pinging itself. This latency consists of two trips through the network at a total cost of 24 cycles, and the execution of two threads at a total cost of 19 cycles. <p> Note that network latency is not included in this table. The first three rows in the table are the times reported by the vendor based on their message libraries. The second set of rows are for tuned implementations of the Active Message system <ref> [17] </ref> on the same hardware and give a sense of the reduction in overhead that can be achieved when the programming model matches the available hardware more closely.
References-found: 17

