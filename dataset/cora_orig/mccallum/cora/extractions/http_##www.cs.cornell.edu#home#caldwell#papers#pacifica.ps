URL: http://www.cs.cornell.edu/home/caldwell/papers/pacifica.ps
Refering-URL: http://www.cs.cornell.edu/home/caldwell/papers.html
Root-URL: 
Title: Hierarchical Approach to Specification and Verification of Fault-tolerant Operating Systems  
Author: James L. Caldwell II Ricky W. Butler Benedetto L. DiVito 
Date: 9 June 1990  
Address: Hampton, VA. 23665-5225  Hampton VA. 23666  
Affiliation: NASA Langley Research Center  Vigyan, Inc.  
Abstract: The goal of formal methods research in the Systems Validation Methods Branch (SVMB) at NASA Langley Research Center (LaRC) is the development of design and verification methodologies to support the development of provably correct system designs for life-critical control applications. Specifically, our efforts are directed at formal specification and verification of the most critical hardware and software components of fault-tolerant fly-by-wire control systems. These systems typically have reliability requirements mandating probability of failure &lt; 10 9 for 10-hour mission times. To achieve these ultra-reliability requirements implies provably correct fault-tolerant designs based on replicated hardware and software resources.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Dolev, J. Y. Halpern, and H. R. </author> <title> Strong. On the possibility and impossibility of achieving clock synchronization. </title> <booktitle> In Proceedings of 16th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 504-511, </pages> <address> Washington, D.C., </address> <month> April </month> <year> 1984. </year>
Reference-contexts: The fault models used are worst case models in which faulty processors can maliciously cooperate in attempts to defeat the fault tolerance of the system. Under this worst case model, 3m + 1 processors must be working in order to tolerate m faults <ref> [1] </ref>. If we assume the existence of a fault-tolerant basis providing clock synchronization and interactive consistency, then a simple majority of working processors suffices to out vote any minority of faulty processors. Empirical evidence indicates that transient faults are significantly more common than permanent faults.
Reference: [2] <author> J. C. Knight and N. G. Levenson. </author> <title> An experimental evaluation of the assumptions of independence in multiversion programming. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-12(1):96-109, </volume> <month> Jan </month> <year> 1986. </year>
Reference-contexts: A current approach to solving the problem of latent design errors is based on notions of design diversity. This approach is typically implemented by independent design groups working from common specifications. However, in an often cited paper <ref> [2] </ref>, Knight and Leveson have shown, at least in the software domain, that design diversity does not necessarily ensure independence of design errors. Moreover, quantification of software reliability in the ultra-reliability range is not feasible in the presence of design errors [5].
Reference: [3] <author> Leslie Lamport. </author> <title> Using time instead of timeout for fault-tolerant distributed systems. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 6(2) </volume> <pages> 254-280, </pages> <month> April </month> <year> 1984. </year>
Reference-contexts: If the global state is voted periodically and internal state is recoverable from sensors, it is clear that after some finite time errors can be flushed from the system. The approach adopted here for the design of the distributed aspect of the system is motivated by Lamport's paper <ref> [3] </ref>. At the base of the system is a distributed clock synchronization algorithm, allowing the system to be viewed as a synchronous system. Under contract to NASA, Rushby and von Henke [6] formally verified Lamport and Melliar-Smith's [4] clock synchronization algorithm 1 providing a key system building block.
Reference: [4] <author> Leslie Lamport and P. M. Melliar-Smith. </author> <title> Synchronizing clocks in the presence of faults. </title> <journal> Journal of the ACM, </journal> <volume> 32(1) </volume> <pages> 52-78, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: A second difficulty arises from the fact that voted results mask errors only if each replicate receives the same inputs; thus sensor values must also be distributed to each processor in a fault-tolerant manner. Ingenious algorithms have been developed to perform these tasks <ref> [4] </ref>. Verifying that these algorithms have been 2 correctly incorporated into the fabric of a distributed operating system is at the heart of reliable fault-tolerant system design. 2 A Science of Reliable Design Mathematical reliability models provide the foundation for a scientific approach to fault-tolerant system design. <p> At the base of the system is a distributed clock synchronization algorithm, allowing the system to be viewed as a synchronous system. Under contract to NASA, Rushby and von Henke [6] formally verified Lamport and Melliar-Smith's <ref> [4] </ref> clock synchronization algorithm 1 providing a key system building block. In a system relying on exact match voting it must also be ensured that each processor receives the same inputs from the sensors.
Reference: [5] <author> Doug Miller. </author> <title> Making statistical inferences about software reliability. </title> <type> Technical Report CR-4197, </type> <institution> NASA, </institution> <month> December </month> <year> 1988. </year> <month> 8 </month>
Reference-contexts: However, in an often cited paper [2], Knight and Leveson have shown, at least in the software domain, that design diversity does not necessarily ensure independence of design errors. Moreover, quantification of software reliability in the ultra-reliability range is not feasible in the presence of design errors <ref> [5] </ref>. Historically, quantification of hardware unreliability due to physical failure has not been viewed as a problem and, reliability analysts assume hardware components are immune from design errors. <p> The justification for building ultra-reliable systems from replicated resources rests on an assumption of the failure independence between redundant units. The alternative approach of modeling and experimentally measuring the degree of dependence is infeasible, see <ref> [5] </ref>. The unreliability of a system of replicated components with independent probabilities of failure can easily be calculated by multiplying the individual probabilities. Thus, the assumption of independence allows fault-tolerant system designers to obtain ultra-reliable designs using moderately reliable parts. Often complex systems are constructed from several ultra-reliable subsystems.
Reference: [6] <author> John Rushby and Frieder von Henke. </author> <title> Formal verification of a fault tol-erant clock synchronization algorithm. </title> <type> Technical Report 4239, </type> <institution> NASA, </institution> <month> June </month> <year> 1989. </year> <type> Contractor Report. </type>
Reference-contexts: At the base of the system is a distributed clock synchronization algorithm, allowing the system to be viewed as a synchronous system. Under contract to NASA, Rushby and von Henke <ref> [6] </ref> formally verified Lamport and Melliar-Smith's [4] clock synchronization algorithm 1 providing a key system building block. In a system relying on exact match voting it must also be ensured that each processor receives the same inputs from the sensors.
Reference: [7] <institution> U.S. Department of Defense. Reliability Prediction of Electronic Equipment, </institution> <month> January </month> <year> 1982. </year> <note> MIL-HDBK-217D. 9 </note>
Reference-contexts: Using these models, the impact of architectural design decisions on system reliability can be analytically evaluated. Reliability analysis is based on stochastic models of fault arrival rates and system fault recovery behavior. Fault arrival rates for physical hardware devices are available from field data or empirical models <ref> [7] </ref>. The fault recovery behavior of a system is a characteristic of the fault-tolerant system architecture. The justification for building ultra-reliable systems from replicated resources rests on an assumption of the failure independence between redundant units.
References-found: 7

