URL: http://www.cs.tamu.edu/faculty/bhuyan/papers/ICCD98.ps
Refering-URL: http://www.cs.tamu.edu/faculty/bhuyan/
Root-URL: http://www.cs.tamu.edu
Email: E-mail: ninan, pirvum, bhuyan@cs.tamu.edu  
Title: Circular Buffered Switch Design with Wormhole Routing and Virtual Channels  
Author: Nan Ni, Marius Pirvu and Laxmi Bhuyan 
Address: College Station, TX 77843  
Affiliation: Department of Computer Science Texas A&M University  
Abstract: Switch design for interconnection networks plays an important role in the overall performance of multiprocessors and computer networks. In this paper, a new switch design, namely FC-CB, is proposed that offers low average message latency and high throughput over a wide range of input workloads. The FC-CB switch incorporates wormhole routing and virtual channels with a full crossbar connection. Its structure is based on a novel circular buffer design with dynamic allocation. We have performed extensive simulations to compare its performance with other alternatives. Our results show that the proposed design is superior in terms of latency and throughput, especially for heavy input traffic rate and low buffer space. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. N. Bhuyan, H. Wang, R. Iyer, and A. Kumar. </author> <title> Impact of switch design on the application performance of cache-coherent multiprocessors. </title> <booktitle> In Proceedings of the IPPS/SPDP '98, </booktitle> <pages> pages 466475, </pages> <address> Orlando, FL, </address> <month> March </month> <year> 1998. </year>
Reference-contexts: This problem can be solved by multiplexing several virtual channels [3] on a physical link. By using virtual channels (VCs), buffer allocation is decoupled from the link resources. Therefore, active messages can bypass blocked messages dramatically improving the network throughput. Switches with buffered virtual channels <ref> [1, 5] </ref> exhibit low average message latency. Regarding the buffering technique, we can distinguish between input queueing and output queueing. Although switches with output queueing have been shown to outperform those with input queueing [6], their higher hardware complexity has restricted their popularity.
Reference: [2] <author> J. Carbonaro and F. Verhoom. Cavallino: </author> <title> The teraflops router and NIC. </title> <booktitle> In Proceedings of Symposium on High Performance Interconnects, </booktitle> <pages> pages 157160, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: The use of dynamic buffer allocation results in better utilization of the buffer space, compared to the existing virtual channel switches with fixed size channels <ref> [2, 5] </ref>. We have com pared our switch design with both dynamically allocated fully connected switches based on virtual cut-through and traditional wormhole routing techniques. Our simulation results show the superiority of our design in terms of both network latency and throughput. <p> Packets are then absorbed one by one by the network and routed towards their destinations. For each generated packet its destination is randomly determined. Other pertinent architectural parameters are presented in Table 1. These parameters have been selected to reflect the current state-of-the-art interconnect <ref> [5, 2] </ref>. Each simulation run is for a duration of sending and receiving 32000 packets. In our simulations we employ two performance metrics: throughput and message latency. The throughput is defined as the utilization of the local links between the switch and the associated processing unit (see Figure 7).
Reference: [3] <author> W. Dally. </author> <title> Virtual-channel flow control. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(2):194205, </volume> <year> 1992. </year>
Reference-contexts: The architecture is based on a novel circular buffer design with reduced hardware complexity. A plethora of switch architectures have been described in the literature <ref> [7, 3, 8, 4, 11] </ref>. Two main factors differentiate their design: the switching technique, and the buffer management. The switching technique determines the way a message is transmitted over the network. In this paper we consider two well known switching techniques: virtual cut-through and wormhole-routing. <p> In contrast to virtual cut-through, it is not necessary to allocate a packet sized buffer before accepting each packet. However, should the packet be blocked, it obstructs the entire path. This problem can be solved by multiplexing several virtual channels <ref> [3] </ref> on a physical link. By using virtual channels (VCs), buffer allocation is decoupled from the link resources. Therefore, active messages can bypass blocked messages dramatically improving the network throughput. Switches with buffered virtual channels [1, 5] exhibit low average message latency. <p> As before, VCT can keep up with the rest of designs only for large buffers. For small input buffers (16-48 flits), the advantage of our scheme employing virtual channels is obvious. 4.3.2. Comparison with traditional virtual channels The classic virtual channel architecture as defined by Dally <ref> [3] </ref> has statically allocated buffers for each channel as currently employed in Spider and Cavallino. In contrast, our switch has a global set of buffers dynamically allocated to virtual channels as needed. However, we do reserve one flit buffer for each virtual channel.
Reference: [4] <author> J. Ding and L. N. Bhuyan. </author> <title> Evaluation of multi-queue buffered multistage interconnection networks under uniform and non-uniform traffic patterns. </title> <journal> International Journal of Systems Science, </journal> <volume> 28(11):11151128, </volume> <year> 1997. </year>
Reference-contexts: The architecture is based on a novel circular buffer design with reduced hardware complexity. A plethora of switch architectures have been described in the literature <ref> [7, 3, 8, 4, 11] </ref>. Two main factors differentiate their design: the switching technique, and the buffer management. The switching technique determines the way a message is transmitted over the network. In this paper we consider two well known switching techniques: virtual cut-through and wormhole-routing. <p> The simplest way to build an input buffer is with a single FIFO queue. However, the head of line (HOL) problem is inherent in such a design. Newer switch designs, have significantly improved performance compared to the FIFO queue by introducing dynamically allocated buffer management <ref> [12, 4, 11] </ref>. On the other hand, the performance benefits come at the expense of increased hardware complexity, as in the linked list buffer management [12]. Most of the research in this area has been confined to using packet switching or virtual cut-through switching. <p> A combination of the ideas of SAFC and DAMQ results in a switch which is both fully connected and has combined input queueing space as shown in Figure 1 (d). Such a dynamically allocated fully connected (DAFC) switch was analyzed in <ref> [4] </ref> and its performance was shown to be better than other categories. HIPIQS [11] is an example of such a DAFC switch with wormhole routing.
Reference: [5] <author> M. Galles. Spider: </author> <title> A high-speed network interconnect. </title> <booktitle> IEEE Micro, </booktitle> <pages> pages 3439, </pages> <month> January/Febrary </month> <year> 1997. </year>
Reference-contexts: This problem can be solved by multiplexing several virtual channels [3] on a physical link. By using virtual channels (VCs), buffer allocation is decoupled from the link resources. Therefore, active messages can bypass blocked messages dramatically improving the network throughput. Switches with buffered virtual channels <ref> [1, 5] </ref> exhibit low average message latency. Regarding the buffering technique, we can distinguish between input queueing and output queueing. Although switches with output queueing have been shown to outperform those with input queueing [6], their higher hardware complexity has restricted their popularity. <p> The use of dynamic buffer allocation results in better utilization of the buffer space, compared to the existing virtual channel switches with fixed size channels <ref> [2, 5] </ref>. We have com pared our switch design with both dynamically allocated fully connected switches based on virtual cut-through and traditional wormhole routing techniques. Our simulation results show the superiority of our design in terms of both network latency and throughput. <p> Packets are then absorbed one by one by the network and routed towards their destinations. For each generated packet its destination is randomly determined. Other pertinent architectural parameters are presented in Table 1. These parameters have been selected to reflect the current state-of-the-art interconnect <ref> [5, 2] </ref>. Each simulation run is for a duration of sending and receiving 32000 packets. In our simulations we employ two performance metrics: throughput and message latency. The throughput is defined as the utilization of the local links between the switch and the associated processing unit (see Figure 7).
Reference: [6] <author> M. J. Karol, M. G. Hluchyj, and S. P. Morgan. </author> <title> Input versus output queueing on a space-division packet switch. </title> <journal> IEEE Transactions on Communications, </journal> <volume> COM-35(12):13471356, </volume> <month> December </month> <year> 1987. </year>
Reference-contexts: Switches with buffered virtual channels [1, 5] exhibit low average message latency. Regarding the buffering technique, we can distinguish between input queueing and output queueing. Although switches with output queueing have been shown to outperform those with input queueing <ref> [6] </ref>, their higher hardware complexity has restricted their popularity. For this reason, in this paper we concentrate on input queueing. The simplest way to build an input buffer is with a single FIFO queue. However, the head of line (HOL) problem is inherent in such a design.
Reference: [7] <author> P. Kermani and L. Kleinrock. </author> <title> Virtual cut-through: a new computer communication switching technique. </title> <booktitle> Computer Networks, </booktitle> <address> 3(4):267286, </address> <year> 1979. </year>
Reference-contexts: The architecture is based on a novel circular buffer design with reduced hardware complexity. A plethora of switch architectures have been described in the literature <ref> [7, 3, 8, 4, 11] </ref>. Two main factors differentiate their design: the switching technique, and the buffer management. The switching technique determines the way a message is transmitted over the network. In this paper we consider two well known switching techniques: virtual cut-through and wormhole-routing. <p> Two main factors differentiate their design: the switching technique, and the buffer management. The switching technique determines the way a message is transmitted over the network. In this paper we consider two well known switching techniques: virtual cut-through and wormhole-routing. The optimization introduced by virtual cut-through <ref> [7] </ref> compared to store-and-forward packet fl This research has been supported by NSF Grant CCR 9622740 switching is that the head of the message is not required to wait for the tail before it can start moving to the next switch.
Reference: [8] <author> M. Kumar and J. </author> <title> Jump. Performance enhancement in buffered Delta networks using crossbar switches and multiple links. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 1(1):81103, </volume> <year> 1984. </year>
Reference-contexts: The architecture is based on a novel circular buffer design with reduced hardware complexity. A plethora of switch architectures have been described in the literature <ref> [7, 3, 8, 4, 11] </ref>. Two main factors differentiate their design: the switching technique, and the buffer management. The switching technique determines the way a message is transmitted over the network. In this paper we consider two well known switching techniques: virtual cut-through and wormhole-routing. <p> Such a FIFO buffer will result in low performance due to the head of line (HOL) problem. Kumar and Jump <ref> [8] </ref> improved the above design by dividing the buffer at each input port into separate small queues dedicated to the outputs. As illustrated in Figure 1 (b), if a packet from a queue is blocked, packets in other queues at the same input can still pass through.
Reference: [9] <author> L. Ni and P. McKinley. </author> <title> A survey of wormhole routing techniques in direct networks. </title> <journal> IEEE Computer, </journal> <volume> 26(2):6276, </volume> <month> February </month> <year> 1993. </year>
Reference-contexts: However, the entire message/packet has to be buffered at an intermediate node in case of blocking. In wormhole routing <ref> [9] </ref>, a packet is divided into a number of flits. They can be transmitted over the network in a pipelined fashion. In contrast to virtual cut-through, it is not necessary to allocate a packet sized buffer before accepting each packet.
Reference: [10] <author> J. Park, B. O'Krafka, S. Vassiliadis, and J. Kelgado-Frias. </author> <title> Design and evaluation of a DAMQ multiprocessor network with self-compacting buffers. </title> <booktitle> In IEEE Supercomputing '94, The Conference on High Performance Computing and Communications, </booktitle> <pages> pages 713722, </pages> <month> Nov.14-18 </month> <year> 1994. </year>
Reference-contexts: FC-CB can achieve lower average message latency and higher throughput, especially in the presence of heavy workload. The other major change we suggest is the avoidance of the linked list scheme. The work reported in <ref> [10] </ref> improved the hardware complexity by using a self-compacting buffer. We further reduce the complexity by proposing a circular buffer scheme for dynamic allocation of space. <p> The head register of a list points to the first slot in the queue while the tail register points to the last slot. For each slot, a pointer is needed to indicate the position of the next slot belonging to the queue. Self-compacting buffer management. According to <ref> [10] </ref>, a self-compacting buffer has less overhead compared to the linked list approach. The basic idea is to keep the slots belonging to the same queue together and in the order of the flit sequence. The regions occupied by different queues follow one another. <p> We think that the equations above are simple and therefore the complexity of implementation is low. 3.2.3. Advantages of the circular buffer over previous schemes Park et al. <ref> [10] </ref> showed that a self-compacting buffer has less hardware overhead when compared to a linked list approach. Our circular buffer further reduces the hardware complexity of the self-compacting buffer. The ring structure permits us to shift the slots in just one direction instead of two in [10]. <p> schemes Park et al. <ref> [10] </ref> showed that a self-compacting buffer has less hardware overhead when compared to a linked list approach. Our circular buffer further reduces the hardware complexity of the self-compacting buffer. The ring structure permits us to shift the slots in just one direction instead of two in [10]. Moreover, we do not need any comparators to decide which flits must shift. The main disadvantage of the self-compacting buffer is that only one flit is read-out at a time. Conceptually, the design can be modified to allow more flits to be read-out.
Reference: [11] <author> R. Sivaram, C. B. Stunkel, and D. K. Panda. HIPIQS: </author> <title> a High-performance switch architecture using input queueing. </title> <booktitle> In Proceedings of the IPPS/SPDP '98, </booktitle> <pages> pages 134143, </pages> <address> Or-lando, FL, </address> <month> March </month> <year> 1998. </year>
Reference-contexts: The architecture is based on a novel circular buffer design with reduced hardware complexity. A plethora of switch architectures have been described in the literature <ref> [7, 3, 8, 4, 11] </ref>. Two main factors differentiate their design: the switching technique, and the buffer management. The switching technique determines the way a message is transmitted over the network. In this paper we consider two well known switching techniques: virtual cut-through and wormhole-routing. <p> The simplest way to build an input buffer is with a single FIFO queue. However, the head of line (HOL) problem is inherent in such a design. Newer switch designs, have significantly improved performance compared to the FIFO queue by introducing dynamically allocated buffer management <ref> [12, 4, 11] </ref>. On the other hand, the performance benefits come at the expense of increased hardware complexity, as in the linked list buffer management [12]. Most of the research in this area has been confined to using packet switching or virtual cut-through switching. <p> Such a dynamically allocated fully connected (DAFC) switch was analyzed in [4] and its performance was shown to be better than other categories. HIPIQS <ref> [11] </ref> is an example of such a DAFC switch with wormhole routing. It should always perform better than the DAMQ switch because it allows multiple packets to be read-out from one input port and almost always outperforms SAFC due to the better utilization of the buffer space. <p> It should always perform better than the DAMQ switch because it allows multiple packets to be read-out from one input port and almost always outperforms SAFC due to the better utilization of the buffer space. We find that improvement over HIPIQS <ref> [11] </ref> is feasible in two respects. First, a network with wormhole routing does not allow the flow of a packet to be interrupted by another packet. In a network with messages of different priorities, the ability to give way to urgent messages is crucial for high performance. <p> Given that k virtual channels will share the entire input buffer, the question is how to allocate this buffer dynamically to different incoming messages. 3.2.1. Existing buffer allocation schemes Linked list buffer management. In <ref> [11] </ref> and [12] the combined buffers are implemented using linked lists. This approach usually keeps (k + 1) lists: one for each small queue and one for the free space. <p> Meanwhile, some trailing flits will follow into the buffer (provided there is enough free space). The number of these trailing flits is equal to the number of cycles for switch delay. In HIPIQS <ref> [11] </ref>, during routing, the trailing flits are blocked outside the switch. number of VCs per physical link: 4 flit size: 2 bytes packet size: 8 or 32 flits switch delay: 4 cycles wire delay: 1 cycle buffer size in the local interface: infinite routing algorithm: X-Y routing link arbitration policy: FCFS <p> SWR is an improvement over VCT because a worm can move as soon as there is at least one slot available in the input buffer. However, once a worm becomes blocked due to insufficient buffer space, the link cannot be used by anybody else. HIP-IQS <ref> [11] </ref> is an example of SWR. FC-CB employs 4 virtual channels that can be used to bypass a blocked message. The only drawback of FC-CB is that it cannot hold more than four different messages in its input buffer. FC-CB+ overcomes this limitation by allowing more worms per channel.
Reference: [12] <author> Y. Tamir and G. L. Frazier. </author> <title> Dynamically-allocated multi-queue buffers for VLSI communication switches. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 41(2):725737, </volume> <month> June </month> <year> 1992. </year>
Reference-contexts: The simplest way to build an input buffer is with a single FIFO queue. However, the head of line (HOL) problem is inherent in such a design. Newer switch designs, have significantly improved performance compared to the FIFO queue by introducing dynamically allocated buffer management <ref> [12, 4, 11] </ref>. On the other hand, the performance benefits come at the expense of increased hardware complexity, as in the linked list buffer management [12]. Most of the research in this area has been confined to using packet switching or virtual cut-through switching. <p> Newer switch designs, have significantly improved performance compared to the FIFO queue by introducing dynamically allocated buffer management [12, 4, 11]. On the other hand, the performance benefits come at the expense of increased hardware complexity, as in the linked list buffer management <ref> [12] </ref>. Most of the research in this area has been confined to using packet switching or virtual cut-through switching. <p> As illustrated in Figure 1 (b), if a packet from a queue is blocked, packets in other queues at the same input can still pass through. A switch with such a feature is called fully connected. This type of design is referred to as SAFC (Statically Allocated Fully Connected) <ref> [12] </ref>, with static meaning that the size of each small queue is fixed. Nevertheless, there is still one important disadvantage. The buffer for one small queue can be full while all the other small queues of the same input port can be empty. Tamir and Frazier [12] presented a detailed design <p> (Statically Allocated Fully Connected) <ref> [12] </ref>, with static meaning that the size of each small queue is fixed. Nevertheless, there is still one important disadvantage. The buffer for one small queue can be full while all the other small queues of the same input port can be empty. Tamir and Frazier [12] presented a detailed design for a DAMQ (Dynamically Allocated Multi-Queue) switch and demonstrated its performance improvement over SAFC. In their switch (Figure 1 (c)), the small queues share the entire buffer space of an input as needed. An incoming flit can occupy any available slot in the buffer. <p> This problem can be solved by the use of virtual channels, which multiplex the transmission of several packets along one physical link. Second, the dynamic buffer allocation in HIPIQS is based on a linked list scheme, originally proposed in <ref> [12] </ref>. We propose an innovative circular buffer design which has less hardware complexity. The new switch architecture is introduced in Section 3 and we demonstrate its superiority in Section 4. 3. <p> Given that k virtual channels will share the entire input buffer, the question is how to allocate this buffer dynamically to different incoming messages. 3.2.1. Existing buffer allocation schemes Linked list buffer management. In [11] and <ref> [12] </ref> the combined buffers are implemented using linked lists. This approach usually keeps (k + 1) lists: one for each small queue and one for the free space.
References-found: 12

