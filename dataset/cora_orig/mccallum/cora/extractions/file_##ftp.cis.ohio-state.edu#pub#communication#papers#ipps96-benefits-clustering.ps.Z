URL: file://ftp.cis.ohio-state.edu/pub/communication/papers/ipps96-benefits-clustering.ps.Z
Refering-URL: http://www.cis.ohio-state.edu/~panda/paper.html
Root-URL: 
Email: Email: fbasak,pandag@cis.ohio-state.edu  
Title: Benefits of Processor Clustering in Designing Large Parallel Systems: When and How?  
Author: Debashis Basak and Dhabaleswar K. Panda M. Banikazemi 
Address: Columbus, OH 43210-1277  
Affiliation: Dept. of Computer and Information Science Dept. of Electrical Engineering The Ohio State University,  
Date: April, 1996  
Note: To be presented at the International Parallel Processing Symposium, Hawaii,  
Abstract: Advances in multiprocessor interconnect technology are leading to high performance networks. However, software overheads associated with message passing are limiting the processors to get maximum performance from these networks, leading to under-utilization of network resources. Though processor-clusters are being used in some systems in an ad hoc manner to alleviate this problem, there is no formal analysis in the literature to show when and how processor clusters benefit in designing high performance and scalable systems. In this paper we analyze and solve this problem by considering processor-clustering, messaging overheads, and network performance in an integrated manner. Our analysis establishes the following three design guidelines. Compared to a base system, under high messaging overheads, processor clustering can be used to build a) an equal-sized system with a smaller network or b) a larger system with an equal-sized network. Under low messaging overheads, a combination of processor clustering and wider channels can be used to build a range of larger-sized systems. All these guidelines lead to designing cost-effective and scalable parallel systems while delivering high performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Basak and D. K. Panda. </author> <title> Designing Large Hierarchical Multiprocessor Systems under Processor, Interconnection, </title> <booktitle> and Packaging Advancements. In Proc. of the ICPP, </booktitle> <pages> pages I:63-66, </pages> <year> 1994. </year>
Reference-contexts: This is leading to the development of parallel systems using such processor-clusters as building blocks instead of single processors [3]. Previous research on clustered systems have focused mostly on proposing and proving different interconnection topologies [4] and studying the design problem under very realistic packaging constraints <ref> [1, 7] </ref>. Such processor clustering also demonstrates potential to alleviate the network under-utilization problem by allowing more number of processors to use a given set of network resources. However, no formal study is available in the literature which shows the benefits of processor clustering towards better utilization of network resources. <p> This leads us to an interesting question: given that any of these systems can be built, which one would be more cost-effective? To compare costs here we use the metric of interconnect wiring costs <ref> [1] </ref> for the inter-cluster network. It has been demonstrated in [7] that such costs constitute a significant fraction of the total system cost. <p> Additional results for other configurations can be found in [2] 1 . base system is scaled to larger sizes by using larger clusters and proportionately larger channel widths. 1 Please refer http://www.cis.ohio-state.edu/~panda/pac.html It has been shown in <ref> [1] </ref> that the design of a real system is constrained by packaging constraints which can bound the maximum available channel width (W max ) and cluster size (c max ).
Reference: [2] <author> D. Basak, D. K. Panda, and M. Banikazemi. </author> <title> Benefits of Processor Clustering in Designing Large Parallel Systems: When and How? OSU-CISRC-10/95-TR41, </title> <institution> The Ohio State University. </institution>
Reference-contexts: For uniform representation, we consider a single processor based computing node to be a processor-cluster having one processor only. The network connecting the processors inside a cluster can be a bus, crossbar, star, etc. as discussed in <ref> [2] </ref>. Although the choice of the cluster topology is an important design issue, in this study we emphasize more on how and when processor-clusters can be used in designing balanced and larger cost-effective systems. <p> Let the limit on , imposed only by the bisection size (assuming messaging overhead t sw = 0:0), be denoted as nw messages/sec. For a (k 1 fi k 2 -c; W ) system, this limit has been derived by us <ref> [2] </ref> as: nw / max (k 1 ; k 2 )cLt c messages/sec, (1) where t c (in sec) denotes the channel cycle time in the network and L (in bytes) denotes the message length in the system. <p> These costs can be determined by first computing the total number of channels in the inter-cluster network and multiplying this number by the channel width to yield the total number of connecting wires. This has been derived by us in <ref> [2] </ref> as (32 (k g 2 )(k g 2 1)W g 1 g 2 ), which can be simpli fied to (32k (k p g 2 1)W g). <p> Uniform traffic and t sw = 0:25sec were considered. It is observed that the performance is maintained in larger systems re sulting in ideal scaling. Additional results for other configurations can be found in <ref> [2] </ref> 1 . base system is scaled to larger sizes by using larger clusters and proportionately larger channel widths. 1 Please refer http://www.cis.ohio-state.edu/~panda/pac.html It has been shown in [1] that the design of a real system is constrained by packaging constraints which can bound the maximum available channel width (W max <p> Among the various solution configurations to scale a given system, only those hav ing (W W max ) and (c c max ) are feasible. Under such constraints, it has been demonstrated by us in <ref> [2] </ref> that among the feasible solutions the one with the largest cluster size is still the most cost-effective. 6 Conclusion In this paper we demonstrated a new approach to scale parallel systems by taking into account recent advancements in interconnection and processor-cluster technologies.
Reference: [3] <author> Cray Reasearch Inc. </author> <title> Cray T3D System Architecture Overview, </title> <year> 1993. </year>
Reference-contexts: 1 Introduction The performance of a multiprocessor system is often limited by the bisection bandwidth of its interconnection network. In the recent past, systems <ref> [3] </ref> have been built using advanced interconnection networks with 16 and 32 bit channels and channel cycle times of 6.6-10.0 ns. The offered bandwidth for inter-processor communication in such systems is very high. <p> With advancements in VLSI and packaging technologies it has become cost-effective to integrate multiple processing elements into a chip or a board [6, 7]. This is leading to the development of parallel systems using such processor-clusters as building blocks instead of single processors <ref> [3] </ref>. Previous research on clustered systems have focused mostly on proposing and proving different interconnection topologies [4] and studying the design problem under very realistic packaging constraints [1, 7]. <p> With advancements in VLSI and packaging technologies, computing nodes having more than one processor on a single multi-chip module or processor-board are becoming increasingly viable. Many current parallel architectures like the CRAY T3D <ref> [3] </ref>, Intel Paragon, and the Stanford DASH [5] are using processor-cluster based nodes to build larger systems. The number of processors available inside a cluster, denoted as c, depends on the level of integration.
Reference: [4] <author> S. Dandamudi and D. Eager. </author> <title> On Hierarchical Hypercube Multicomputer Interconnection Network Design. </title> <journal> JPDC, </journal> <volume> 12(3) </volume> <pages> 283-289, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: This is leading to the development of parallel systems using such processor-clusters as building blocks instead of single processors [3]. Previous research on clustered systems have focused mostly on proposing and proving different interconnection topologies <ref> [4] </ref> and studying the design problem under very realistic packaging constraints [1, 7]. Such processor clustering also demonstrates potential to alleviate the network under-utilization problem by allowing more number of processors to use a given set of network resources.
Reference: [5] <author> D. Lenoski et al. </author> <title> The Stanford DASH Multiprocessor. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 63-79, </pages> <year> 1990. </year>
Reference-contexts: With advancements in VLSI and packaging technologies, computing nodes having more than one processor on a single multi-chip module or processor-board are becoming increasingly viable. Many current parallel architectures like the CRAY T3D [3], Intel Paragon, and the Stanford DASH <ref> [5] </ref> are using processor-cluster based nodes to build larger systems. The number of processors available inside a cluster, denoted as c, depends on the level of integration. Figure 1 (b) shows an example system with 16 processor-clusters, each having c = 4 processors, interconnected by a 4x4 mesh.
Reference: [6] <author> W. Hsu and P. C. Yew. </author> <title> The Impact of Wiring Constraints on Hierarchical Network Performance. </title> <booktitle> In Proc. of the IPPS, </booktitle> <month> Mar </month> <year> 1992. </year>
Reference-contexts: This can lead to much of the communication bandwidth offered by the expensive fast interconnect to remain unutilized. With advancements in VLSI and packaging technologies it has become cost-effective to integrate multiple processing elements into a chip or a board <ref> [6, 7] </ref>. This is leading to the development of parallel systems using such processor-clusters as building blocks instead of single processors [3]. Previous research on clustered systems have focused mostly on proposing and proving different interconnection topologies [4] and studying the design problem under very realistic packaging constraints [1, 7].
Reference: [7] <author> M. T. Raghunath and A. Ranade. </author> <title> Designing interconnection networks for multi-level packaging. </title> <booktitle> In Proc. of the Supercomputing, </booktitle> <pages> pages 772-781, </pages> <year> 1993. </year> <month> 5 </month>
Reference-contexts: This can lead to much of the communication bandwidth offered by the expensive fast interconnect to remain unutilized. With advancements in VLSI and packaging technologies it has become cost-effective to integrate multiple processing elements into a chip or a board <ref> [6, 7] </ref>. This is leading to the development of parallel systems using such processor-clusters as building blocks instead of single processors [3]. Previous research on clustered systems have focused mostly on proposing and proving different interconnection topologies [4] and studying the design problem under very realistic packaging constraints [1, 7]. <p> This is leading to the development of parallel systems using such processor-clusters as building blocks instead of single processors [3]. Previous research on clustered systems have focused mostly on proposing and proving different interconnection topologies [4] and studying the design problem under very realistic packaging constraints <ref> [1, 7] </ref>. Such processor clustering also demonstrates potential to alleviate the network under-utilization problem by allowing more number of processors to use a given set of network resources. However, no formal study is available in the literature which shows the benefits of processor clustering towards better utilization of network resources. <p> This leads us to an interesting question: given that any of these systems can be built, which one would be more cost-effective? To compare costs here we use the metric of interconnect wiring costs [1] for the inter-cluster network. It has been demonstrated in <ref> [7] </ref> that such costs constitute a significant fraction of the total system cost. These costs can be determined by first computing the total number of channels in the inter-cluster network and multiplying this number by the channel width to yield the total number of connecting wires.
References-found: 7

