URL: http://www.cs.purdue.edu/homes/ayg/publications/ps/sc96.ps
Refering-URL: http://www.cs.purdue.edu/homes/ayg/publications/work.html
Root-URL: http://www.cs.purdue.edu
Email: sameh-@cs.umn.edu  
Phone: Ph: (612) 625 4002, FAX (612) 625 0572  
Title: Parallel Hierarchical Solvers and Preconditioners for Boundary Element Methods  
Author: Ananth Grama, Vipin Kumar, Ahmed Sameh E., -ananth, kumar, 
Note: S.  
Address: 4-192, EE/CSci Building, 200 Union St.  Minneapolis, MN 55455  
Affiliation: Department of Computer Science,  University of Minnesota  
Abstract: The method of moments is an important tool for solving boundary integral equations arising in a variety of applications. It transforms the physical problem into a dense linear system. Due to the large number of variables and the associated computational requirements, these systems are solved iteratively using methods such as GMRES, CG and its variants. The core operation of these iterative solvers is the application of the system matrix to a vector. This requires (n 2 ) operations and memory using accurate dense methods. The computational complexity can be reduced to O(n log n) and the memory requirement to fi(n) using hierarchical approximation techniques. The algorithmic speedup from approximation can be combined with parallelism to yield very fast dense solvers. In this paper, we present efficient parallel formulations of dense iterative solvers based on hierarchical approximations for solving the integral form of Laplace equation. We study the impact of various parameters on the accuracy and performance of the parallel solver. We present two preconditioning techniques for accelerating the convergence of the iterative solver. These techniques are based on an inner-outer scheme and a block diagonal scheme based on a truncated Green's function. We present detailed experimental results on up to 256 processors of a Cray T3D. fl This work is sponsored by the by Army Research Office contract DA/DAAH04-95-1-0538 and by Army High Performance Computing Research Center under the auspices of the Department of the Army, Army Research Laboratory cooperative agreement number DAAH04-95-2-0003/contract number DAAH04-95-C-0008, the content of which does not necessarily reflect the position or the policy of the government, and no official endorsement should be inferred. This work is also sponsored in part by MSI. Access to computing facilities was provided by Cray Research Inc. and by the Pittsburgh Supercomputing Center. Related papers are available via WWW at URL: http://www.cs.umn.edu/users/kumar/papers.html. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. W. Appel. </author> <title> An efficient program for many-body simulation. </title> <journal> SIAM Journal of Computing, </journal> <volume> 6, </volume> <year> 1985. </year>
Reference-contexts: This forms the basis of hierarchical methods. These methods provide systematic ways of aggregating entities and computing interactions while controlling the overall error in modeling. Algorithms based on hierarchical techniques include Barnes-Hut [2], Fast Multipole [10], and Appel's <ref> [1] </ref> algorithms. Approximating long range interactions in this manner reduces the sequential complexity of typical simulations involving n particles from O (n 2 ) to O (n log n) or O (n).
Reference: [2] <author> J. Barnes and P. Hut. </author> <title> A hierarchical o(n log n) force calculation algorithm. </title> <journal> Nature, </journal> <volume> 324, </volume> <year> 1986. </year>
Reference-contexts: Using this approach, the total number of interactions in the system can be reduced significantly. This forms the basis of hierarchical methods. These methods provide systematic ways of aggregating entities and computing interactions while controlling the overall error in modeling. Algorithms based on hierarchical techniques include Barnes-Hut <ref> [2] </ref>, Fast Multipole [10], and Appel's [1] algorithms. Approximating long range interactions in this manner reduces the sequential complexity of typical simulations involving n particles from O (n 2 ) to O (n log n) or O (n).
Reference: [3] <author> S. Bindiganavale and J.L. Volakis. </author> <title> Guidelines for using the fast multipole method to calculate the rcs of large objects. </title> <journal> Microwave and Optical Tech. letters, </journal> <volume> 11(4), </volume> <month> March </month> <year> 1996. </year>
Reference-contexts: 1 Introduction The method of moments [12] is a popular method for solving integral equations. It has extensive applications in computational electromagnetics, wave propagation, and heat transfer <ref> [22, 21, 3, 11] </ref>. It transforms a physical problem defined as an integral equation into a dense linear system. The integral equation is termed a volume or a boundary integral equation depending on whether the variables are defined on the volume or the surface of the modeled object. <p> Since the system matrix is never explicitly constructed, preconditioners must be derived from the hierarchical domain representation. Furthermore, the preconditioning strategies must be highly parallelizable. Since the early work of Rokhlin [16], relatively little work has been done on dense hierarchical solvers even in the serial context <ref> [14, 17, 22, 3] </ref>. In this paper, we investigate the accuracy and convergence of a GMRES solver built around a parallel hierarchical matrix-vector product. We investigate the impact of various parameters on accuracy and performance. We propose two preconditioning strategies for accelerating the convergence of the solver. <p> Even in the serial context, relatively little work has been done since the initial work of Rokhlin [16]. Other prominent pieces of work were in this area include <ref> [14, 17, 22, 3] </ref>. To the best of our knowledge, the treecode presented in this paper is among the first parallel multilevel solver-preconditioner toolkit. We are currently extending the hierarchical solver to scattering problems in electromag-netics [17, 16, 22, 21, 3]. <p> Other prominent pieces of work were in this area include [14, 17, 22, 3]. To the best of our knowledge, the treecode presented in this paper is among the first parallel multilevel solver-preconditioner toolkit. We are currently extending the hierarchical solver to scattering problems in electromag-netics <ref> [17, 16, 22, 21, 3] </ref>. The free-space Green's function for the Field Integral Equation depends on the wave number of incident radiation. At high wave numbers, the boundary discretizations must be very fine. This corresponds to a large number of unknowns.
Reference: [4] <author> J. A. Board, J. W. Causey, J. F. Leathrum, A. Windemuth, and K. Schulten. </author> <title> Accelerated molecular dynamics with the fast multipole algorithm. </title> <institution> Chem. Phys. Let., 198:89, </institution> <year> 1992. </year>
Reference-contexts: Parallel formulations of hierarchical methods involve partitioning the domain among various processors with the combined objectives of optimizing commu 2 nication and balancing load. If particle densities are uniform across the domain, these objectives are easily met <ref> [4, 25, 13, 19, 9] </ref>. For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. [20] and Warren and Salmon [24, 23] presented schemes for irregular distributions that try to meet these objectives.
Reference: [5] <author> Ananth Grama. </author> <title> Efficient Parallel Formulations of Hierarchical Methods and their Applications. </title> <type> PhD thesis, </type> <institution> Computer Science Department, University of Minnesota, </institution> <address> Minneapolis, MN 55455, </address> <year> 1996. </year>
Reference-contexts: For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. [20] and Warren and Salmon [24, 23] presented schemes for irregular distributions that try to meet these objectives. In <ref> [6, 8, 5] </ref> we presented alternate schemes for irregular distributions that improve on the performance of the earlier schemes. In [7, 5], we used parallel hierarchical techniques for computing dense matrix-vector products and studied the impact of various parameters on accuracy and performance. <p> Singh et al. [20] and Warren and Salmon [24, 23] presented schemes for irregular distributions that try to meet these objectives. In [6, 8, 5] we presented alternate schemes for irregular distributions that improve on the performance of the earlier schemes. In <ref> [7, 5] </ref>, we used parallel hierarchical techniques for computing dense matrix-vector products and studied the impact of various parameters on accuracy and performance. An important aspect of using iterative solvers for solving large systems is the use of effective preconditioning techniques for accelerating the convergence. <p> Both of these functions are decreasing functions of distance r. This allows us to aggregate the impact of several boundary elements into a single expression and apply them in constant time. This is similar in principle to a single iteration of the n-body algorithm <ref> [5] </ref>. The integrals over boundary elements are performed using Gaussian quadrature. For nearby elements, a higher number of Gauss points have to be used for desired accuracy. For computing coupling coefficients between distant basis functions, fewer Gauss points may be used. <p> We refer to the former as function shipping and the latter as data shipping. Our parallel formulations are based on the function shipping paradigm. We discuss the advantages of function shipping in <ref> [5, 7] </ref>. The load-balancing technique is an efficient implementation of the costzones scheme on message-passing computers. Each node in the tree contains a variable that stores the number of boundary elements it interacted with in computing a previous mat-vec. <p> This results in varying raw computation speeds across problem instances. Detailed studies of impact of various parameters on the accuracy of the matrix-vector product are presented by the authors in <ref> [5, 7] </ref>. 5.2 Parallel Performance of the Unpreconditioned GMRES Solver One of the important metrics for the performance of a code is the time to solution. We now investigate the solution time on different number of processors with different accuracy parameters.
Reference: [6] <author> Ananth Grama, Vipin Kumar, and Ahmad Sameh. </author> <title> Scalable parallel formulations of the barnes-hut method for n-body simulations. </title> <booktitle> In Supercomputing '94 Proceedings, </booktitle> <year> 1994. </year>
Reference-contexts: For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. [20] and Warren and Salmon [24, 23] presented schemes for irregular distributions that try to meet these objectives. In <ref> [6, 8, 5] </ref> we presented alternate schemes for irregular distributions that improve on the performance of the earlier schemes. In [7, 5], we used parallel hierarchical techniques for computing dense matrix-vector products and studied the impact of various parameters on accuracy and performance.
Reference: [7] <author> Ananth Grama, Vipin Kumar, and Ahmad Sameh. </author> <title> Parallel matrix-vector product using hierarchical methods. </title> <booktitle> In Proceedings of Supercomputing '95, </booktitle> <address> San Diego, CA, </address> <year> 1995. </year>
Reference-contexts: Singh et al. [20] and Warren and Salmon [24, 23] presented schemes for irregular distributions that try to meet these objectives. In [6, 8, 5] we presented alternate schemes for irregular distributions that improve on the performance of the earlier schemes. In <ref> [7, 5] </ref>, we used parallel hierarchical techniques for computing dense matrix-vector products and studied the impact of various parameters on accuracy and performance. An important aspect of using iterative solvers for solving large systems is the use of effective preconditioning techniques for accelerating the convergence. <p> We refer to the former as function shipping and the latter as data shipping. Our parallel formulations are based on the function shipping paradigm. We discuss the advantages of function shipping in <ref> [5, 7] </ref>. The load-balancing technique is an efficient implementation of the costzones scheme on message-passing computers. Each node in the tree contains a variable that stores the number of boundary elements it interacted with in computing a previous mat-vec. <p> This results in varying raw computation speeds across problem instances. Detailed studies of impact of various parameters on the accuracy of the matrix-vector product are presented by the authors in <ref> [5, 7] </ref>. 5.2 Parallel Performance of the Unpreconditioned GMRES Solver One of the important metrics for the performance of a code is the time to solution. We now investigate the solution time on different number of processors with different accuracy parameters.
Reference: [8] <author> Ananth Grama, Vipin Kumar, and Ahmed Sameh. </author> <title> On n-body simulations using message passing parallel computers. </title> <booktitle> In Proceedings of the SIAM Conference on Parallel Processing, </booktitle> <address> San Francisco, </address> <year> 1995. </year> <month> 16 </month>
Reference-contexts: For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. [20] and Warren and Salmon [24, 23] presented schemes for irregular distributions that try to meet these objectives. In <ref> [6, 8, 5] </ref> we presented alternate schemes for irregular distributions that improve on the performance of the earlier schemes. In [7, 5], we used parallel hierarchical techniques for computing dense matrix-vector products and studied the impact of various parameters on accuracy and performance.
Reference: [9] <author> L. Greengard and W. Gropp. </author> <title> A parallel version of the fast multipole method. </title> <booktitle> Parallel Processing for Scientific Computing, </booktitle> <pages> pages 213-222, </pages> <year> 1987. </year>
Reference-contexts: Parallel formulations of hierarchical methods involve partitioning the domain among various processors with the combined objectives of optimizing commu 2 nication and balancing load. If particle densities are uniform across the domain, these objectives are easily met <ref> [4, 25, 13, 19, 9] </ref>. For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. [20] and Warren and Salmon [24, 23] presented schemes for irregular distributions that try to meet these objectives.
Reference: [10] <author> L. Greengard and V. Rokhlin. </author> <title> A fast algorithm for particle simulations. </title> <journal> J. Comp. Physics, </journal> <volume> 73 </volume> <pages> 325-348, </pages> <year> 1987. </year>
Reference-contexts: This forms the basis of hierarchical methods. These methods provide systematic ways of aggregating entities and computing interactions while controlling the overall error in modeling. Algorithms based on hierarchical techniques include Barnes-Hut [2], Fast Multipole <ref> [10] </ref>, and Appel's [1] algorithms. Approximating long range interactions in this manner reduces the sequential complexity of typical simulations involving n particles from O (n 2 ) to O (n log n) or O (n).
Reference: [11] <author> R. F. Harrington. </author> <title> Field Computation by Method of Moments. </title> <publisher> Macmillan, </publisher> <year> 1993. </year>
Reference-contexts: 1 Introduction The method of moments [12] is a popular method for solving integral equations. It has extensive applications in computational electromagnetics, wave propagation, and heat transfer <ref> [22, 21, 3, 11] </ref>. It transforms a physical problem defined as an integral equation into a dense linear system. The integral equation is termed a volume or a boundary integral equation depending on whether the variables are defined on the volume or the surface of the modeled object.
Reference: [12] <author> R. F. Harrington. </author> <title> Matrix methods for field problems. </title> <booktitle> In Proc. IEEE, </booktitle> <volume> Vol. 55, No. 2, </volume> <pages> pages 136 - 149, </pages> <month> Feb, </month> <year> 1967. </year>
Reference-contexts: 1 Introduction The method of moments <ref> [12] </ref> is a popular method for solving integral equations. It has extensive applications in computational electromagnetics, wave propagation, and heat transfer [22, 21, 3, 11]. It transforms a physical problem defined as an integral equation into a dense linear system.
Reference: [13] <author> J. F. Leathrum and J. A. </author> <title> Board. Mapping the adaptive fast multipole algorithm into mimd systems. </title> <editor> In P. Mehrotra and J. Saltz, editors, </editor> <title> Unstructured Scientific Computation on Scalable Multiprocessors. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: Parallel formulations of hierarchical methods involve partitioning the domain among various processors with the combined objectives of optimizing commu 2 nication and balancing load. If particle densities are uniform across the domain, these objectives are easily met <ref> [4, 25, 13, 19, 9] </ref>. For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. [20] and Warren and Salmon [24, 23] presented schemes for irregular distributions that try to meet these objectives.
Reference: [14] <author> K. Nabors, F. T. Korsmeyer, F. T. Leighton, and J. White. </author> <title> Multipole accelerated preconditioned iterative methods for three-dimensional potential integral equations of the first kind. </title> <journal> J. on Sci. and Stat. Comp., </journal> <volume> 15(3) </volume> <pages> 713-735, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Since the system matrix is never explicitly constructed, preconditioners must be derived from the hierarchical domain representation. Furthermore, the preconditioning strategies must be highly parallelizable. Since the early work of Rokhlin [16], relatively little work has been done on dense hierarchical solvers even in the serial context <ref> [14, 17, 22, 3] </ref>. In this paper, we investigate the accuracy and convergence of a GMRES solver built around a parallel hierarchical matrix-vector product. We investigate the impact of various parameters on accuracy and performance. We propose two preconditioning strategies for accelerating the convergence of the solver. <p> Even in the serial context, relatively little work has been done since the initial work of Rokhlin [16]. Other prominent pieces of work were in this area include <ref> [14, 17, 22, 3] </ref>. To the best of our knowledge, the treecode presented in this paper is among the first parallel multilevel solver-preconditioner toolkit. We are currently extending the hierarchical solver to scattering problems in electromag-netics [17, 16, 22, 21, 3].
Reference: [15] <author> S. Ranka, R. V. Shankar, and K. A. Alsabti. </author> <title> Many-to-many personalized communication with bounded traffic. </title> <booktitle> In Proceedings. Frontiers '95. The Fifth Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <month> 6-9 Feb. </month> <year> 1995. </year>
Reference-contexts: Both of these problems are solved by hashing the vector elements to the processor designated by the GMRES partitioning. The destination processor has the job of accruing all the vector elements (adding them when necessary). The communication is performed using a single all-to-all personalized communication with variable message sizes <ref> [15] </ref>. 5 6 4 Preconditioning Techniques for Iterative Solver In this section we present preconditioning techniques for the iterative solver. Since the coefficient matrix is never explicitly computed, preconditioners must be constructed from the hierarchical representation of the domain or the limited explicit representation of the coefficient matrix.
Reference: [16] <author> V. Rokhlin. </author> <title> Rapid solution of integral equations of classical potential theory. </title> <journal> Journal of Computational Physics, </journal> <volume> 60 </volume> <pages> 187-207, </pages> <year> 1985. </year>
Reference-contexts: Since the system matrix is never explicitly constructed, preconditioners must be derived from the hierarchical domain representation. Furthermore, the preconditioning strategies must be highly parallelizable. Since the early work of Rokhlin <ref> [16] </ref>, relatively little work has been done on dense hierarchical solvers even in the serial context [14, 17, 22, 3]. In this paper, we investigate the accuracy and convergence of a GMRES solver built around a parallel hierarchical matrix-vector product. <p> The treecode developed here is highly modular in nature and provides a general framework for solving a variety of dense linear systems. Even in the serial context, relatively little work has been done since the initial work of Rokhlin <ref> [16] </ref>. Other prominent pieces of work were in this area include [14, 17, 22, 3]. To the best of our knowledge, the treecode presented in this paper is among the first parallel multilevel solver-preconditioner toolkit. <p> Other prominent pieces of work were in this area include [14, 17, 22, 3]. To the best of our knowledge, the treecode presented in this paper is among the first parallel multilevel solver-preconditioner toolkit. We are currently extending the hierarchical solver to scattering problems in electromag-netics <ref> [17, 16, 22, 21, 3] </ref>. The free-space Green's function for the Field Integral Equation depends on the wave number of incident radiation. At high wave numbers, the boundary discretizations must be very fine. This corresponds to a large number of unknowns.
Reference: [17] <author> V. Rokhlin. </author> <title> Rapid solutions of integral equations of scattering theory in two dimensions. </title> <journal> Journal of Computational Physics, </journal> <volume> 86 </volume> <pages> 414-439, </pages> <year> 1990. </year>
Reference-contexts: Since the system matrix is never explicitly constructed, preconditioners must be derived from the hierarchical domain representation. Furthermore, the preconditioning strategies must be highly parallelizable. Since the early work of Rokhlin [16], relatively little work has been done on dense hierarchical solvers even in the serial context <ref> [14, 17, 22, 3] </ref>. In this paper, we investigate the accuracy and convergence of a GMRES solver built around a parallel hierarchical matrix-vector product. We investigate the impact of various parameters on accuracy and performance. We propose two preconditioning strategies for accelerating the convergence of the solver. <p> Even in the serial context, relatively little work has been done since the initial work of Rokhlin [16]. Other prominent pieces of work were in this area include <ref> [14, 17, 22, 3] </ref>. To the best of our knowledge, the treecode presented in this paper is among the first parallel multilevel solver-preconditioner toolkit. We are currently extending the hierarchical solver to scattering problems in electromag-netics [17, 16, 22, 21, 3]. <p> Other prominent pieces of work were in this area include [14, 17, 22, 3]. To the best of our knowledge, the treecode presented in this paper is among the first parallel multilevel solver-preconditioner toolkit. We are currently extending the hierarchical solver to scattering problems in electromag-netics <ref> [17, 16, 22, 21, 3] </ref>. The free-space Green's function for the Field Integral Equation depends on the wave number of incident radiation. At high wave numbers, the boundary discretizations must be very fine. This corresponds to a large number of unknowns.
Reference: [18] <author> Y. Saad and M. Schultz. </author> <title> GMRES: A generalized minimal residual algorithm for solving non-symmetrical linear systems. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 3 </volume> <pages> 856-869, </pages> <year> 1986. </year>
Reference-contexts: For such objects, the boundary element method results in dense linear systems with hundreds of thousands of unknowns. The memory and computational requirements of solving these systems are formidable. Iterative solution techniques such as Generalized Minimal Residual (GMRES) <ref> [18] </ref> are the method of choice. The memory and computational requirements of these solvers grow as fi (n 2 ) per iteration. Solving systems with 10K variables in this manner can challenge most current supercomputers. <p> This is unlike the original Barnes-Hut method which uses the size of the oct for computing the ff criterion. 4 3 Parallel GMRES Using Hierarchical Matrix-Vector Products We implement a parallel formulation of a restart GMRES <ref> [18] </ref> algorithm. The critical components of the algorithm are: product of the system matrix A with vector x n , and dot products.
Reference: [19] <author> K. E. Schmidt and M. A. Lee. </author> <title> Implementing the fast multipole method in three dimensions. </title> <journal> J. Stat. Phys., </journal> <volume> 63:1120, </volume> <year> 1991. </year>
Reference-contexts: Parallel formulations of hierarchical methods involve partitioning the domain among various processors with the combined objectives of optimizing commu 2 nication and balancing load. If particle densities are uniform across the domain, these objectives are easily met <ref> [4, 25, 13, 19, 9] </ref>. For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. [20] and Warren and Salmon [24, 23] presented schemes for irregular distributions that try to meet these objectives.
Reference: [20] <author> J. Singh, C. Holt, T. Totsuka, A. Gupta, and J. Hennessy. </author> <title> Load balancing and data locality in hierarchical n-body methods. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <note> 1994 (to appear). </note>
Reference-contexts: If particle densities are uniform across the domain, these objectives are easily met [4, 25, 13, 19, 9]. For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. <ref> [20] </ref> and Warren and Salmon [24, 23] presented schemes for irregular distributions that try to meet these objectives. In [6, 8, 5] we presented alternate schemes for irregular distributions that improve on the performance of the earlier schemes.
Reference: [21] <author> J.M. Song and W.C. Chew. </author> <title> Fast multipole method solution using parametric geometry. </title> <journal> Microwave and Optical Tech. letters, </journal> <volume> 7(16) </volume> <pages> 760-765, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: 1 Introduction The method of moments [12] is a popular method for solving integral equations. It has extensive applications in computational electromagnetics, wave propagation, and heat transfer <ref> [22, 21, 3, 11] </ref>. It transforms a physical problem defined as an integral equation into a dense linear system. The integral equation is termed a volume or a boundary integral equation depending on whether the variables are defined on the volume or the surface of the modeled object. <p> Other prominent pieces of work were in this area include [14, 17, 22, 3]. To the best of our knowledge, the treecode presented in this paper is among the first parallel multilevel solver-preconditioner toolkit. We are currently extending the hierarchical solver to scattering problems in electromag-netics <ref> [17, 16, 22, 21, 3] </ref>. The free-space Green's function for the Field Integral Equation depends on the wave number of incident radiation. At high wave numbers, the boundary discretizations must be very fine. This corresponds to a large number of unknowns.
Reference: [22] <author> J.M. Song and W.C. Chew. </author> <title> Multilevel fast multipole algorithm for solving combined field integral equation of electromagnetic scattering. </title> <journal> Microwave and Optical Tech. letters, </journal> <volume> 10(1) </volume> <pages> 14-19, </pages> <month> September </month> <year> 1995. </year> <month> 17 </month>
Reference-contexts: 1 Introduction The method of moments [12] is a popular method for solving integral equations. It has extensive applications in computational electromagnetics, wave propagation, and heat transfer <ref> [22, 21, 3, 11] </ref>. It transforms a physical problem defined as an integral equation into a dense linear system. The integral equation is termed a volume or a boundary integral equation depending on whether the variables are defined on the volume or the surface of the modeled object. <p> Since the system matrix is never explicitly constructed, preconditioners must be derived from the hierarchical domain representation. Furthermore, the preconditioning strategies must be highly parallelizable. Since the early work of Rokhlin [16], relatively little work has been done on dense hierarchical solvers even in the serial context <ref> [14, 17, 22, 3] </ref>. In this paper, we investigate the accuracy and convergence of a GMRES solver built around a parallel hierarchical matrix-vector product. We investigate the impact of various parameters on accuracy and performance. We propose two preconditioning strategies for accelerating the convergence of the solver. <p> Even in the serial context, relatively little work has been done since the initial work of Rokhlin [16]. Other prominent pieces of work were in this area include <ref> [14, 17, 22, 3] </ref>. To the best of our knowledge, the treecode presented in this paper is among the first parallel multilevel solver-preconditioner toolkit. We are currently extending the hierarchical solver to scattering problems in electromag-netics [17, 16, 22, 21, 3]. <p> Other prominent pieces of work were in this area include [14, 17, 22, 3]. To the best of our knowledge, the treecode presented in this paper is among the first parallel multilevel solver-preconditioner toolkit. We are currently extending the hierarchical solver to scattering problems in electromag-netics <ref> [17, 16, 22, 21, 3] </ref>. The free-space Green's function for the Field Integral Equation depends on the wave number of incident radiation. At high wave numbers, the boundary discretizations must be very fine. This corresponds to a large number of unknowns.
Reference: [23] <author> M. Warren and J. Salmon. </author> <title> Astrophysical n-body simulations using hierarchical tree data structures. </title> <booktitle> In Proceedings of Supercomputing Conference, </booktitle> <year> 1992. </year>
Reference-contexts: If particle densities are uniform across the domain, these objectives are easily met [4, 25, 13, 19, 9]. For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. [20] and Warren and Salmon <ref> [24, 23] </ref> presented schemes for irregular distributions that try to meet these objectives. In [6, 8, 5] we presented alternate schemes for irregular distributions that improve on the performance of the earlier schemes.
Reference: [24] <author> M. Warren and J. Salmon. </author> <title> A parallel hashed oct tree n-body algorithm. </title> <booktitle> In Proceedings of Supercomputing Conference, </booktitle> <year> 1993. </year>
Reference-contexts: If particle densities are uniform across the domain, these objectives are easily met [4, 25, 13, 19, 9]. For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. [20] and Warren and Salmon <ref> [24, 23] </ref> presented schemes for irregular distributions that try to meet these objectives. In [6, 8, 5] we presented alternate schemes for irregular distributions that improve on the performance of the earlier schemes.
Reference: [25] <author> F. Zhao and S. L. Johnsson. </author> <title> The parallel multipole method on the connection machine. </title> <journal> SIAM J. of Sci. Stat. Comp., </journal> <volume> 12 </volume> <pages> 1420-1437, </pages> <year> 1991. </year> <month> 18 </month>
Reference-contexts: Parallel formulations of hierarchical methods involve partitioning the domain among various processors with the combined objectives of optimizing commu 2 nication and balancing load. If particle densities are uniform across the domain, these objectives are easily met <ref> [4, 25, 13, 19, 9] </ref>. For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. [20] and Warren and Salmon [24, 23] presented schemes for irregular distributions that try to meet these objectives.
References-found: 25

