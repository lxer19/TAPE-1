URL: http://www.cs.umn.edu/Users/dept/users/kumar/mlevel_parallel_ipps.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kumar/
Root-URL: http://www.cs.umn.edu
Title: Parallel Multilevel Graph Partitioning  
Author: George Karypis and Vipin Kumar 
Address: Minneapolis, MN 55455  
Affiliation: University of Minnesota, Department of Computer Science,  
Date: 1996  
Note: Appears in the Proceedings of the International Parallel Processing Symposium  
Abstract: In this paper we present a parallel formulation of a graph partitioning and sparse matrix ordering algorithm that is based on a multilevel algorithm we developed recently. Our parallel algorithm achieves a speedup of up to 56 on a 128-processor Cray T3D for moderate size problems, further reducing its already moderate serial run time. Graphs with over 200,000 vertices can be partitioned in 128 parts, on a 128-processor Cray T3D in less than 3 seconds. This is at least an order of magnitude better than any previously reported run times on 128-processors for obtaining an 128-partition. This also makes it possible to use our parallel graph partitioning algorithm to partition meshes dynamically in adaptive computations. Furthermore, the quality of the produced partitions and orderings are comparable to those produced by the serial multilevel algorithm that has been shown to substantially outperform both spectral partitioning and multiple minimum degree. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Stephen T. Barnard. Pmrsb: </author> <title> Parallel multilevel recursive spectral bisection. </title> <booktitle> In Supercomputing 1995, </booktitle> <year> 1995. </year>
Reference-contexts: Only moderately good speedups have been obtained for parallel formulation of graph partitioning algorithms that use geometric methods [9, 5] despite the fact that geometric partitioning algorithms are inherently easier to parallelize. All parallel formulations presented so far for spectral partitioning have reported fairly small speedups <ref> [2, 1, 12] </ref> unless the graph has been distributed to the processors so that certain degree of data locality is achieved [1]. In this paper we present a parallel formulation of a graph partitioning and sparse matrix ordering algorithm that is based on a multilevel algorithm we developed recently [14]. <p> All parallel formulations presented so far for spectral partitioning have reported fairly small speedups [2, 1, 12] unless the graph has been distributed to the processors so that certain degree of data locality is achieved <ref> [1] </ref>. In this paper we present a parallel formulation of a graph partitioning and sparse matrix ordering algorithm that is based on a multilevel algorithm we developed recently [14]. <p> In this paper we present a parallel formulation of a graph partitioning and sparse matrix ordering algorithm that is based on a multilevel algorithm we developed recently [14]. A key feature of our parallel formulation (that distinguishes it from other proposed parallel formulations of multilevel algorithms <ref> [2, 1, 22] </ref>) is that it partitions the vertices of the graph into p p parts while distributing the overall adjacency matrix of the graph among all p processors.
Reference: [2] <author> Stephen T. Barnard and Horst Simon. </author> <title> A parallel implementation of multilevel recursive spectral bisection for application to adaptive unstructured meshes. </title> <booktitle> In Proceedingsof the seventh SIAM conferenceon Parallel Processing for Scientific Computing, </booktitle> <pages> pages 627-632, </pages> <year> 1995. </year>
Reference-contexts: Significant amount of work has been done in developing parallel algorithms for partitioning unstructured graphs and for producing fill reducing orderings for sparse matrices <ref> [2, 5, 8, 7, 12] </ref>. Only moderately good speedups have been obtained for parallel formulation of graph partitioning algorithms that use geometric methods [9, 5] despite the fact that geometric partitioning algorithms are inherently easier to parallelize. <p> Only moderately good speedups have been obtained for parallel formulation of graph partitioning algorithms that use geometric methods [9, 5] despite the fact that geometric partitioning algorithms are inherently easier to parallelize. All parallel formulations presented so far for spectral partitioning have reported fairly small speedups <ref> [2, 1, 12] </ref> unless the graph has been distributed to the processors so that certain degree of data locality is achieved [1]. In this paper we present a parallel formulation of a graph partitioning and sparse matrix ordering algorithm that is based on a multilevel algorithm we developed recently [14]. <p> In this paper we present a parallel formulation of a graph partitioning and sparse matrix ordering algorithm that is based on a multilevel algorithm we developed recently [14]. A key feature of our parallel formulation (that distinguishes it from other proposed parallel formulations of multilevel algorithms <ref> [2, 1, 22] </ref>) is that it partitions the vertices of the graph into p p parts while distributing the overall adjacency matrix of the graph among all p processors.
Reference: [3] <author> Stephen T. Barnard and Horst D. Simon. </author> <title> A fast multilevel implementationof recursive spectral bisection for partitioningunstructuredproblems. </title> <booktitle> In Proceedings of the sixth SIAM conference on Parallel Processing for Scientific Computing, </booktitle> <pages> pages 711-718, </pages> <year> 1993. </year>
Reference-contexts: T p is the run time for a p-way partition, and E C p is the edge-cut of the p-way partition. relative to the serial multilevel algorithm. gorithm (MSB) <ref> [3] </ref>. The MSB algorithm is a widely used algorithm that has been found to generate high quality partitions with small edge-cuts. We used the Chaco [10] graph partitioning package to produce the MSB partitions.
Reference: [4] <author> T. Bui and C. Jones. </author> <title> A heuristic for reducing fill in sparse matrix factorization. </title> <booktitle> In 6th SIAM Conf. Parallel Processing for Scientific Computing, </booktitle> <pages> pages 445-452, </pages> <year> 1993. </year>
Reference-contexts: Furthermore, geometric methods are applicable only if coordinate information for the graph is available. Recently, a number of researches have investigated a class of algorithms that are based on multilevel graph partitioning that have moderate computational complexity <ref> [4, 11, 14, 15, 13] </ref>. Some of these multilevel schemes [4, 11, 14, 15, 13] provide excellent (even better than spectral) graph partitions. <p> Furthermore, geometric methods are applicable only if coordinate information for the graph is available. Recently, a number of researches have investigated a class of algorithms that are based on multilevel graph partitioning that have moderate computational complexity <ref> [4, 11, 14, 15, 13] </ref>. Some of these multilevel schemes [4, 11, 14, 15, 13] provide excellent (even better than spectral) graph partitions. <p> The parallel formulation in this paper is described in the context of the serial multilevel graph partitioning algorithm presented in [14]. However, nearly all of the discussion in this paper is applicable to other multilevel graph partitioning algorithms <ref> [4, 11, 15] </ref>. 2 Multilevel Graph Partitioning The p-way graph partitioning problem is defined as follows: Given a graph G D .V ; E / with jV j D n, partition V into p subsets, V 1 ; V 2 ; : : : ; V p such that V i
Reference: [5] <author> Pedro Diniz, Steve Plimpton, Bruce Hendrickson, and Robert Leland. </author> <title> Parallel algorithms for dynamically partitioning unstructured grids. </title> <booktitle> In Proceedings of the seventh SIAM conference on Parallel Processing for Scientific Computing, </booktitle> <pages> pages 615-620, </pages> <year> 1995. </year>
Reference-contexts: Significant amount of work has been done in developing parallel algorithms for partitioning unstructured graphs and for producing fill reducing orderings for sparse matrices <ref> [2, 5, 8, 7, 12] </ref>. Only moderately good speedups have been obtained for parallel formulation of graph partitioning algorithms that use geometric methods [9, 5] despite the fact that geometric partitioning algorithms are inherently easier to parallelize. <p> Significant amount of work has been done in developing parallel algorithms for partitioning unstructured graphs and for producing fill reducing orderings for sparse matrices [2, 5, 8, 7, 12]. Only moderately good speedups have been obtained for parallel formulation of graph partitioning algorithms that use geometric methods <ref> [9, 5] </ref> despite the fact that geometric partitioning algorithms are inherently easier to parallelize. All parallel formulations presented so far for spectral partitioning have reported fairly small speedups [2, 1, 12] unless the graph has been distributed to the processors so that certain degree of data locality is achieved [1]. <p> The key idea behind our parallel refinement algorithm is to select a group of vertices to swap from one part to the other instead of selecting a single vertex. Refinement schemes that use similar ideas are described in <ref> [5] </ref>;. However, our algorithm differs in two important ways from the other schemes: (i) it uses a different method for selecting vertices; (ii) it uses a two-dimensional partition to minimize communication. The parallel refinement algorithm consists of a number of phases.
Reference: [6] <author> A. George and J. W.-H. Liu. </author> <title> Computer Solutionof Large Sparse Positive Definite Systems. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1981. </year>
Reference-contexts: If parallel direct methods are used to solve a sparse system of equations, then a graph partitioning algorithm can be used to compute a fill reducing ordering that lead to high degree of concurrency in the factorization phase <ref> [18, 6] </ref>. The graph partitioning problem is NP-complete. However, many algorithms have been developed that find a reasonably good partition. Spectral partitioning methods [21, 11] provide good quality graph partitions, but have very high computational complexity. <p> Thus, the problem of performing a p-way partition is reduced to that of performing a sequence of 2-way partitions or bisections. Even though this scheme does not necessarily lead to optimal partition [15], it is used extensively due to its simplicity <ref> [6] </ref>. The basic idea behind the multilevel graph bisection algorithm is very simple.
Reference: [7] <author> Madhurima Ghose and Edward Rothberg. </author> <title> A parallel implementtaion of the multiple minimum degree ordering heuristic. </title> <type> Technical report, </type> <institution> Old Dominion University, </institution> <address> Norfolk, VA, </address> <year> 1994. </year>
Reference-contexts: Significant amount of work has been done in developing parallel algorithms for partitioning unstructured graphs and for producing fill reducing orderings for sparse matrices <ref> [2, 5, 8, 7, 12] </ref>. Only moderately good speedups have been obtained for parallel formulation of graph partitioning algorithms that use geometric methods [9, 5] despite the fact that geometric partitioning algorithms are inherently easier to parallelize.
Reference: [8] <author> J. R. Gilbert and E. Zmijewski. </author> <title> A parallel graph partitioning algorithm for a message-passing multiprocessor. </title> <journal> Internation Journal of Parallel Programming, </journal> (16):498-513, 1987. 
Reference-contexts: Significant amount of work has been done in developing parallel algorithms for partitioning unstructured graphs and for producing fill reducing orderings for sparse matrices <ref> [2, 5, 8, 7, 12] </ref>. Only moderately good speedups have been obtained for parallel formulation of graph partitioning algorithms that use geometric methods [9, 5] despite the fact that geometric partitioning algorithms are inherently easier to parallelize. <p> However, the BKLR algorithm is sequential in nature and it cannot be used in its current form to efficiently refine a partition when the graph is distributed among a grid of processors <ref> [8] </ref>. In this case we use a different algorithm that tries to approximate the BKLR algorithm but is more amenable to parallel computations.
Reference: [9] <author> M. T. Heath and Padma Raghavan. </author> <title> A Cartesian parallel nested dissection algorithm. </title> <type> Technical Report 92-1772, </type> <institution> Department of Computer Science, University of Illinois, Urbana, IL, </institution> <year> 1992. </year> <note> To appear in SIAM Journal on Matrix Analysis and Applications, </note> <year> 1994. </year>
Reference-contexts: The graph partitioning problem is NP-complete. However, many algorithms have been developed that find a reasonably good partition. Spectral partitioning methods [21, 11] provide good quality graph partitions, but have very high computational complexity. Geometric partition methods <ref> [9, 20] </ref> are quite fast but they often provide worse partitions than those of more expensive methods such as spectral. Furthermore, geometric methods are applicable only if coordinate information for the graph is available. <p> Significant amount of work has been done in developing parallel algorithms for partitioning unstructured graphs and for producing fill reducing orderings for sparse matrices [2, 5, 8, 7, 12]. Only moderately good speedups have been obtained for parallel formulation of graph partitioning algorithms that use geometric methods <ref> [9, 5] </ref> despite the fact that geometric partitioning algorithms are inherently easier to parallelize. All parallel formulations presented so far for spectral partitioning have reported fairly small speedups [2, 1, 12] unless the graph has been distributed to the processors so that certain degree of data locality is achieved [1].
Reference: [10] <author> Bruce Hendrickson and Rober Leland. </author> <title> The chaco user's guide, version 1.0. </title> <type> Technical Report SAND93-2339, </type> <institution> Sandia National Laboratories, </institution> <year> 1993. </year>
Reference-contexts: The MSB algorithm is a widely used algorithm that has been found to generate high quality partitions with small edge-cuts. We used the Chaco <ref> [10] </ref> graph partitioning package to produce the MSB partitions. As before, any bars above the baseline indicate that the parallel algorithm generates partitions with higher edge-cuts. From this figure we see that the quality of the parallel algorithm is almost never worse than that of the MSB algorithm.
Reference: [11] <author> Bruce Hendrickson and Rober Leland. </author> <title> A multilevel algorithm for partitioning graphs. </title> <type> Technical Report SAND93-1301, </type> <institution> Sandia National Laboratories, </institution> <year> 1993. </year>
Reference-contexts: The graph partitioning problem is NP-complete. However, many algorithms have been developed that find a reasonably good partition. Spectral partitioning methods <ref> [21, 11] </ref> provide good quality graph partitions, but have very high computational complexity. Geometric partition methods [9, 20] are quite fast but they often provide worse partitions than those of more expensive methods such as spectral. Furthermore, geometric methods are applicable only if coordinate information for the graph is available. <p> Furthermore, geometric methods are applicable only if coordinate information for the graph is available. Recently, a number of researches have investigated a class of algorithms that are based on multilevel graph partitioning that have moderate computational complexity <ref> [4, 11, 14, 15, 13] </ref>. Some of these multilevel schemes [4, 11, 14, 15, 13] provide excellent (even better than spectral) graph partitions. <p> Furthermore, geometric methods are applicable only if coordinate information for the graph is available. Recently, a number of researches have investigated a class of algorithms that are based on multilevel graph partitioning that have moderate computational complexity <ref> [4, 11, 14, 15, 13] </ref>. Some of these multilevel schemes [4, 11, 14, 15, 13] provide excellent (even better than spectral) graph partitions. <p> The parallel formulation in this paper is described in the context of the serial multilevel graph partitioning algorithm presented in [14]. However, nearly all of the discussion in this paper is applicable to other multilevel graph partitioning algorithms <ref> [4, 11, 15] </ref>. 2 Multilevel Graph Partitioning The p-way graph partitioning problem is defined as follows: Given a graph G D .V ; E / with jV j D n, partition V into p subsets, V 1 ; V 2 ; : : : ; V p such that V i
Reference: [12] <author> Zdenek Johan, Kapil K. Mathur, S. Lennart Johnsson, and Thomas J. R. Hughes. </author> <title> Finite element methods on the connection machine cm-5 system. </title> <type> Technical report, </type> <institution> Thinking Machines Corporation, </institution> <year> 1993. </year>
Reference-contexts: Significant amount of work has been done in developing parallel algorithms for partitioning unstructured graphs and for producing fill reducing orderings for sparse matrices <ref> [2, 5, 8, 7, 12] </ref>. Only moderately good speedups have been obtained for parallel formulation of graph partitioning algorithms that use geometric methods [9, 5] despite the fact that geometric partitioning algorithms are inherently easier to parallelize. <p> Only moderately good speedups have been obtained for parallel formulation of graph partitioning algorithms that use geometric methods [9, 5] despite the fact that geometric partitioning algorithms are inherently easier to parallelize. All parallel formulations presented so far for spectral partitioning have reported fairly small speedups <ref> [2, 1, 12] </ref> unless the graph has been distributed to the processors so that certain degree of data locality is achieved [1]. In this paper we present a parallel formulation of a graph partitioning and sparse matrix ordering algorithm that is based on a multilevel algorithm we developed recently [14].
Reference: [13] <author> G. Karypis and V. Kumar. </author> <title> Analysis of multilevel graph partitioning. </title> <type> Technical Report TR 95-037, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1995. </year> <note> Also available on WWW at URL http://www.cs.umn.edu/karypis/papers/mlevel analysis.ps. </note>
Reference-contexts: Furthermore, geometric methods are applicable only if coordinate information for the graph is available. Recently, a number of researches have investigated a class of algorithms that are based on multilevel graph partitioning that have moderate computational complexity <ref> [4, 11, 14, 15, 13] </ref>. Some of these multilevel schemes [4, 11, 14, 15, 13] provide excellent (even better than spectral) graph partitions. <p> Furthermore, geometric methods are applicable only if coordinate information for the graph is available. Recently, a number of researches have investigated a class of algorithms that are based on multilevel graph partitioning that have moderate computational complexity <ref> [4, 11, 14, 15, 13] </ref>. Some of these multilevel schemes [4, 11, 14, 15, 13] provide excellent (even better than spectral) graph partitions.
Reference: [14] <author> G. Karypis and V. Kumar. </author> <title> A fast and high quality multilevel scheme for partitioning irregular graphs. </title> <type> Technical Report TR 95-035, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1995. </year> <note> Also available on WWW at URL http://www.cs.umn.edu/karypis/papers/mlevel serial.ps. A short version appears in Intl. Conf. on Parallel Processing 1995. </note>
Reference-contexts: Furthermore, geometric methods are applicable only if coordinate information for the graph is available. Recently, a number of researches have investigated a class of algorithms that are based on multilevel graph partitioning that have moderate computational complexity <ref> [4, 11, 14, 15, 13] </ref>. Some of these multilevel schemes [4, 11, 14, 15, 13] provide excellent (even better than spectral) graph partitions. <p> Furthermore, geometric methods are applicable only if coordinate information for the graph is available. Recently, a number of researches have investigated a class of algorithms that are based on multilevel graph partitioning that have moderate computational complexity <ref> [4, 11, 14, 15, 13] </ref>. Some of these multilevel schemes [4, 11, 14, 15, 13] provide excellent (even better than spectral) graph partitions. <p> In this paper we present a parallel formulation of a graph partitioning and sparse matrix ordering algorithm that is based on a multilevel algorithm we developed recently <ref> [14] </ref>. A key feature of our parallel formulation (that distinguishes it from other proposed parallel formulations of multilevel algorithms [2, 1, 22]) is that it partitions the vertices of the graph into p p parts while distributing the overall adjacency matrix of the graph among all p processors. <p> Furthermore, the quality of the produced partitions and orderings are comparable to those produced by the serial multilevel algorithm that has been shown to outperform both spectral partitioning and multiple minimum degree <ref> [14] </ref>. The parallel formulation in this paper is described in the context of the serial multilevel graph partitioning algorithm presented in [14]. <p> of the produced partitions and orderings are comparable to those produced by the serial multilevel algorithm that has been shown to outperform both spectral partitioning and multiple minimum degree <ref> [14] </ref>. The parallel formulation in this paper is described in the context of the serial multilevel graph partitioning algorithm presented in [14]. <p> Since the finer graph has more degrees of freedom, such refinements usually decrease the edge-cut. This process, is graphically illustrated in Figure 1. The reader should refer to <ref> [14] </ref> for further details. 3 Parallel Multilevel Graph Partitioning Algo rithm There are two types of parallelism that can be exploited in the p-way graph partitioning algorithm based on the multilevel bisection algorithms. The first type of parallelism is due to the recursive nature of the algorithm. <p> We use the Greedy Graph Growing (GGGP) algorithm described <ref> [14] </ref> to partition the coarsest graph. We perform a small number of GGGP runs starting from different random vertices and the one with the smaller edge-cut is selected as the partition. <p> After each step of projection, the resulting partition is further refined by using vertex swap heuristics (based on Kernighan-Lin [17]) that decrease the edge-cut <ref> [14] </ref>. For refining the coarser graphs that reside on a single processor, we use the boundary Kernighan-Lin refinement algorithm (BKLR) described in [14]. <p> After each step of projection, the resulting partition is further refined by using vertex swap heuristics (based on Kernighan-Lin [17]) that decrease the edge-cut <ref> [14] </ref>. For refining the coarser graphs that reside on a single processor, we use the boundary Kernighan-Lin refinement algorithm (BKLR) described in [14]. However, the BKLR algorithm is sequential in nature and it cannot be used in its current form to efficiently refine a partition when the graph is distributed among a grid of processors [8]. <p> This figure (along with Figure 2) also indicates that our serial multilevel algorithm outperforms the MSB algorithm. An extensive comparison between our serial multilevel algorithm and MSB, can be found in <ref> [14] </ref>. Tables 2 and 3 also show the run time of the parallel algorithm and the serial algorithm, respectively. A number of conclusions can be drawn from these results. First, as relative to the multilevel spectral bisection algorithm. p increases, the time required for the p-way partition on p-processors decreases.
Reference: [15] <author> G. Karypis and V. Kumar. </author> <title> Multilevel k-way partitioning scheme for irregular graphs. </title> <type> Technical Report TR 95-064, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1995. </year> <note> Also available on WWW at URL http://www.cs.umn.edu/karypis/papers/mlevel kway.ps. </note>
Reference-contexts: Furthermore, geometric methods are applicable only if coordinate information for the graph is available. Recently, a number of researches have investigated a class of algorithms that are based on multilevel graph partitioning that have moderate computational complexity <ref> [4, 11, 14, 15, 13] </ref>. Some of these multilevel schemes [4, 11, 14, 15, 13] provide excellent (even better than spectral) graph partitions. <p> Furthermore, geometric methods are applicable only if coordinate information for the graph is available. Recently, a number of researches have investigated a class of algorithms that are based on multilevel graph partitioning that have moderate computational complexity <ref> [4, 11, 14, 15, 13] </ref>. Some of these multilevel schemes [4, 11, 14, 15, 13] provide excellent (even better than spectral) graph partitions. <p> The parallel formulation in this paper is described in the context of the serial multilevel graph partitioning algorithm presented in [14]. However, nearly all of the discussion in this paper is applicable to other multilevel graph partitioning algorithms <ref> [4, 11, 15] </ref>. 2 Multilevel Graph Partitioning The p-way graph partitioning problem is defined as follows: Given a graph G D .V ; E / with jV j D n, partition V into p subsets, V 1 ; V 2 ; : : : ; V p such that V i <p> After log p phases, graph G is partitioned into p parts. Thus, the problem of performing a p-way partition is reduced to that of performing a sequence of 2-way partitions or bisections. Even though this scheme does not necessarily lead to optimal partition <ref> [15] </ref>, it is used extensively due to its simplicity [6]. The basic idea behind the multilevel graph bisection algorithm is very simple.
Reference: [16] <author> G. Karypis and V. Kumar. </author> <title> Parallel multilevel graph partitioning. </title> <type> Technical Report TR 95-036, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1995. </year> <note> Also available on WWW at URL http://www.cs.umn.edu/karypis/papers/mlevel parallel.ps. </note>
Reference-contexts: As 1 shown in <ref> [16] </ref>, this mapping is usually much better than one--dimensional distribution, when no partitioning information about the graph is known. Our parallel algorithm achieves a speedup of up to 56 on 128 processors for moderate size problems, further reducing the already moderate serial run time of multilevel schemes. <p> In our parallel coarsening algorithm, we retain the advantages of the previous scheme, but minimize its drawbacks by computing the matchings between groups of n= p tices. This increases the size of the computed matchings, and also, as discussed in <ref> [16] </ref>, the communication overhead for constructing the coarse graph is decreased. Specifically, our parallel coarsening algorithm treats the p processors as a two-dimensional array of p p p processors (assume that p D 2 2r ). <p> Since, between successive coarsening levels, the size of the graph decreases, the coarsening scheme just described utilizes more processors during the coarsening levels in which the graphs are large and fewer processors for the smaller graphs. As our analysis in <ref> [16] </ref> shows, decreasing the size of the processor grid does not affect the overall performance of the algorithm as long as the graph size shrinks by a certain factor between successive graph foldings. 3.2 Initial Partitioning Phase At the end of the coarsening phase, the coarsest graph resides on a single <p> increases, the time required to perform the p-way partition also increases; (there are more partitions to perform). (b) The parallel multilevel algorithm incurs communication and idling overhead that limits the asymptotic speedup to O. p unless a good partition of the graph is available even before the partitioning process starts <ref> [16] </ref>. 4.2 Sparse Matrix Ordering We used the parallel multilevel graph partitioning algorithm to find a fill reducing ordering via nested dissection. The performance of the parallel multilevel nested dissection algorithm (MLND) for various matrices is shown in Table 4.
Reference: [17] <author> B. W. Kernighan and S. Lin. </author> <title> An efficient heuristic procedure for partitioning graphs. </title> <journal> The Bell System Technical Journal, </journal> <year> 1970. </year>
Reference-contexts: After each step of projection, the resulting partition is further refined by using vertex swap heuristics (based on Kernighan-Lin <ref> [17] </ref>) that decrease the edge-cut [14]. For refining the coarser graphs that reside on a single processor, we use the boundary Kernighan-Lin refinement algorithm (BKLR) described in [14].
Reference: [18] <author> Vipin Kumar, Ananth Grama, Anshul Gupta, and George Karypis. </author> <title> Introduction to Parallel Computing: Design and Analysis of Algorithms. </title> <publisher> Ben-jamin/Cummings Publishing Company, </publisher> <address> Redwood City, CA, </address> <year> 1994. </year>
Reference-contexts: Access to computing facilities was provided by Minnesota Supercomputer Institute, Cray Research Inc, and by the Pittsburgh Supercomputing Center. Related papers are available via WWW at URL: http://www.cs.umn.edu/users/kumar/papers.html to matrix A, is used to significantly reduce the amount of communication <ref> [18] </ref>. If parallel direct methods are used to solve a sparse system of equations, then a graph partitioning algorithm can be used to compute a fill reducing ordering that lead to high degree of concurrency in the factorization phase [18, 6]. The graph partitioning problem is NP-complete. <p> If parallel direct methods are used to solve a sparse system of equations, then a graph partitioning algorithm can be used to compute a fill reducing ordering that lead to high degree of concurrency in the factorization phase <ref> [18, 6] </ref>. The graph partitioning problem is NP-complete. However, many algorithms have been developed that find a reasonably good partition. Spectral partitioning methods [21, 11] provide good quality graph partitions, but have very high computational complexity. <p> The vertices of the graph G 0 D .V 0 ; E 0 / are distributed among this processor grid using a cyclic map ping <ref> [18] </ref>. The vertices V 0 are partitioned into p p subsets, V 0 0 ; : : : ; V p1 0 . Processor P i; j stores the edges of E 0 between the subsets of vertices V i 0 and V 0 .
Reference: [19] <author> J. W.-H. Liu. </author> <title> Modification of the minimum degree algorithm by multiple elimination. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 11 </volume> <pages> 141-153, </pages> <year> 1985. </year>
Reference-contexts: On p processors, the ordering is computed by using nested dissection for the first log p levels, and then multiple minimum degree <ref> [19] </ref> (MMD) is used to order the submatrices stored locally on each processor.
Reference: [20] <author> Gary L. Miller, Shang-Hua Teng, and Stephen A. Vavasis. </author> <title> A unified geometric approach to graph separators. </title> <booktitle> In Proceedings of 31st Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 538-547, </pages> <year> 1991. </year>
Reference-contexts: The graph partitioning problem is NP-complete. However, many algorithms have been developed that find a reasonably good partition. Spectral partitioning methods [21, 11] provide good quality graph partitions, but have very high computational complexity. Geometric partition methods <ref> [9, 20] </ref> are quite fast but they often provide worse partitions than those of more expensive methods such as spectral. Furthermore, geometric methods are applicable only if coordinate information for the graph is available.
Reference: [21] <author> Alex Pothen, Horst D. Simon, and Kang-Pu Liou. </author> <title> Partitioning sparse matrices with eigenvectors of graphs. </title> <journal> SIAM Journal of Matrix Analysis and Applications, </journal> <volume> 11(3) </volume> <pages> 430-452, </pages> <year> 1990. </year>
Reference-contexts: The graph partitioning problem is NP-complete. However, many algorithms have been developed that find a reasonably good partition. Spectral partitioning methods <ref> [21, 11] </ref> provide good quality graph partitions, but have very high computational complexity. Geometric partition methods [9, 20] are quite fast but they often provide worse partitions than those of more expensive methods such as spectral. Furthermore, geometric methods are applicable only if coordinate information for the graph is available.
Reference: [22] <author> Padma Raghavan. </author> <title> Parallel ordering using edge contraction. </title> <type> Technical Report CS-95-293, </type> <institution> Department of Computer Science, University of Tennessee, </institution> <year> 1995. </year>
Reference-contexts: In this paper we present a parallel formulation of a graph partitioning and sparse matrix ordering algorithm that is based on a multilevel algorithm we developed recently [14]. A key feature of our parallel formulation (that distinguishes it from other proposed parallel formulations of multilevel algorithms <ref> [2, 1, 22] </ref>) is that it partitions the vertices of the graph into p p parts while distributing the overall adjacency matrix of the graph among all p processors.
References-found: 22

