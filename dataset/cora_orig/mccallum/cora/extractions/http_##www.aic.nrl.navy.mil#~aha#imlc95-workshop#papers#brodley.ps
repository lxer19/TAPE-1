URL: http://www.aic.nrl.navy.mil/~aha/imlc95-workshop/papers/brodley.ps
Refering-URL: http://www.aic.nrl.navy.mil/~aha/imlc95-workshop/notes.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: brodley@ecn.purdue.edu  pjs@galway.jpl.nasa.gov  
Title: The Process of Applying Machine Learning Algorithms  
Author: Carla E. Brodley Padhraic Smyth 
Address: West Lafayette, IN 47906  MS 525-3660  4800 Oak Grove Drive Pasadena, CA 91109  
Affiliation: School of Electrical and Computer Engineering Purdue University  Jet Propulsion Laboratory  California Institute of Technology  
Abstract: In this paper we present a view of the overall process of application development for real-world classification and regression problems. Specifically, we identify, categorize and discuss the various problem-specific factors that influence this process.
Abstract-found: 1
Intro-found: 1
Reference: <author> Box, D. R. </author> <year> (1990). </year> <title> Role of models in statistical analysis. </title> <journal> Statistical Science, </journal> <volume> 5, </volume> <pages> 169-174. </pages>
Reference: <author> Brodley, C. E. </author> <title> (to appear). Recursive automatic bias selection for classifier construction. </title> <booktitle> Machine Learning. </booktitle>
Reference: <author> Buntine, W., & Smyth, P. </author> <year> (1994). </year> <title> Learning from data: A probabilistic framework. </title> <booktitle> Tutorial notes for AAAI-94 conference. </booktitle> <address> Menlo Park, CA: </address> <publisher> AAAI. </publisher>
Reference: <author> Burl, M. C., Fayyad, U. M., Perona, P., Smyth, P. , & Burl, M. P. </author> <year> (1994). </year> <title> Automating the hunt for volcanoes on Venus. </title> <booktitle> Proceedings of the 1994 Computer Vision and Pattern Recognition Conference (CVPR-94) (pp. </booktitle> <pages> 302-309). </pages> <address> Los Alamitos, CA: </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: A variety of factors can be examined: relevant variables for the problem are not being measured, important prior knowledge is being ignored, a larger training set is needed, the dimensionality of the problem is too high, the selected models and algorithms are inap propriate. For example, in <ref> (Burl, Fayyad, Perona, Smyth & Burl, 1994) </ref> analysis of the errors being made by a classifier trained to detect small volcanos in images of Venus revealed that the class labels provided by the domain experts were quite subjective in nature and that there was considerable disagreement among experts.
Reference: <author> Cheeseman, P. </author> <year> (1990). </year> <title> On finding the most probable model. In Shrager & Langley (Eds.), Computational Models of Scientific Discovery and Theory Formation. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: It is important to note that representation and estimation are separate characteristics of a learning method and can be treated relatively indepen dently <ref> (Cheeseman, 1990) </ref>. 3. Search Method: Finally, given both a representational form (or a set of such forms) and an estimation criterion, the search method is the algorithmic specification of how the parameters and functional forms are fit to the data.
Reference: <author> Draper, B. A., Brodley, C. E., & Utgoff, P. E. </author> <year> (1994). </year> <title> Goal-directed classification using linear machine decision trees. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 16, </volume> <pages> 888-893. </pages>
Reference-contexts: In a particular application, road-following, a misclassification cost matrix was initially specified and a cost-sensitive algorithm was applied to the problem <ref> (Draper, Brodley & Utgoff, 1994) </ref>. The results were unsatisfactory, causing a revision of the misclassification cost matrix. This process was iterated several times before an optimal cost matrix was selected. These are a sample of many possible examples illustrating the iterative nature of the application development process.
Reference: <author> Evans, B., & Fisher, D. </author> <year> (1994). </year> <title> Overcoming process delays with decision tree induction. </title> <journal> IEEE Expert, </journal> <volume> 9, </volume> <pages> 60-66. </pages>
Reference-contexts: For example, human factors played a large role in solving the problem of banding in rotogravure printing. In this application process delays (due to banding) were mitigated using the control rules discovered by decision tree induction <ref> (Evans & Fisher, 1994) </ref>. For this problem, the primary objective was that the end result of a machine learning algorithm provide an operational set of rules; the rules were used to guide the operation of the printing press.
Reference: <author> Fayyad, U. M., Smyth, P., Weir, N., & Djorgovski, S. </author> <year> (1995). </year> <title> Automated analysis and exploration of large image databases. </title> <journal> Journal of Intelligent Information Systems, </journal> <volume> 4, </volume> <pages> 7-25. </pages>
Reference-contexts: identify two common types of applications: (1) generic applications such as speech and optical character recognition (OCR) where different instances of the problem share many of the same characteristics, and (2) specific applications such as the classification of sky objects in astronomical images into the classes of star or galaxy <ref> (Fayyad, Smyth, Weir & Djorgovski, 1995) </ref>. For generic applications, there is a continuous iterative process of application development which may last decades (as in speech) and techniques and results are shared by many groups working on the same problem. <p> Domain (Prior) Knowledge: Are the features for the problem well-defined or is feature extraction part of the problem? (Frequently in image analysis it is a major part of the overall classification problem <ref> (Fayyad, Smyth, Weir & Djorgovski, 1995) </ref>).
Reference: <author> Fayyad, U. M., Piatetsky-Shapiro, G., & Smyth, P. </author> <title> (in press). From data-mining to knowledge discovery: An overview. </title> <editor> In Fayyad, Piatetsky-Shapiro, Smyth & Uthurasamy (Eds.), </editor> <booktitle> Advances in Knowledge Discovery and Data Mining. </booktitle> <publisher> AAAI/MIT Press. </publisher>
Reference: <author> Hand, D. J. </author> <year> (1993). </year> <booktitle> Artificial Intelligence Frontiers in Statistics: AI and Statistics III. </booktitle> <address> London, UK: </address> <publisher> Chapman and Hall. </publisher>
Reference: <author> Hand, D. J. </author> <year> (1994). </year> <title> Statistical strategy: Step 1. </title> <editor> In Cheeseman & Oldford (Eds.), </editor> <title> Selecting Models from Data: </title> <booktitle> Artificial Intelligence and Statistics IV. </booktitle> <address> New York: </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Landgrebe, D., & Biehl, L. </author> <year> (1994). </year> <title> An Introduction to Multispec. </title> <institution> Purdue Research Foundation. </institution>
Reference-contexts: One such example is the MultiSpec system <ref> (Landgrebe & Biehl, 1994) </ref>, which is a data analysis system intended for multispectral image data, such as that from the Landsat series of Earth Observational Satellites. MultiSpec's classification method is well-known and simple it uses maximum likelihood discriminant analysis.
Reference: <author> Lehmann, E. L. </author> <year> (1990). </year> <title> Model specification: The views of Fisher and Neyman, and later developments. </title> <journal> Statistical Science, </journal> <volume> 5, </volume> <pages> 160-168. </pages>
Reference: <author> Linhart, H., & Zucchini, W. </author> <year> (1986). </year> <title> Model Selection. </title> <publisher> NY: Wiley. </publisher>
Reference: <author> Smyth, P. </author> <year> (1994a). </year> <title> Hidden Markov monitoring for fault detection in dynamic systems. </title> <journal> Pattern Recognition, </journal> <volume> 27, </volume> <pages> 149-164. </pages>
Reference-contexts: an initial attempt at online fault classification from time series of large antenna pointing systems ignored the temporal aspect of the problem: the initial results suggested that an improved model could be obtained by embedding the initial classification model within a time dependent model such as a hidden Markov model <ref> (Smyth, 1994a) </ref>. The im proved model was subsequently adapted for use. * For some applications, the initial results are successful enough in terms of predictive accuracy that closer attention is paid to the possible operational deployment of the model, which in turn can uncover new constraints.
Reference: <author> Smyth, P. </author> <year> (1994b). </year> <title> Markov monitoring with unknown states. </title> <journal> IEEE Journal on Selected Areas in Communications, special issue on intelligent signal processing for communications, </journal> <volume> 12, </volume> <pages> 1600-1612. </pages>
Reference-contexts: or some mixture of these forms? What is the dimensionality (the number of features) of the problem? Is the number of features fixed or variable? What is the form of the class variable? Are the classes mutually exclusive, mutually exhaustive? In fault detection, classes may be neither exhaustive nor exclusive <ref> (Smyth, 1994b) </ref>. How many classes are there? For example, in speech and OCR applications there can be thousands of classes. 2. <p> In particular, the necessity of being able to detect classes which were not present in the training data was identified <ref> (Smyth, 1994b) </ref>. This lead to further iteration through the model selection step of the process. * The application development process itself may be designed to be iterative. In the Mul-tiSpec system described earlier, the user and the system interact to achieve the best classification of an image.
References-found: 16

