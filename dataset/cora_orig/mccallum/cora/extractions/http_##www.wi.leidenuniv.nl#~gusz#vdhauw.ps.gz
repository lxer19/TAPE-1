URL: http://www.wi.leidenuniv.nl/~gusz/vdhauw.ps.gz
Refering-URL: http://www.wi.leidenuniv.nl/~jvhemert/csp-ea/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Evaluating and Improving Steady State Evolutionary Algorithms on Constraint Satisfaction Problems  
Author: Koen van der Hauw 
Date: 9 August 1996  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> S. Arora, C. Lund, R. Motwani, M. Sudan, and M. Szegedy. </author> <title> Proof verification and hardness of approximation problems. </title> <booktitle> In Proceedings 33rd IEEE Symposium on the Foundations of Computer Science, </booktitle> <pages> pages 14-23, </pages> <address> Los Angeles, CA, </address> <year> 1992. </year> <note> IEEE Computer Sociecty. </note>
Reference-contexts: Then E is a normalized value in the interval <ref> [0; 1] </ref>. The minimum will be when all individuals are identical. The maximum will be when all gene values are uniformly distributed, as will be the expected case in the initial situation 7 . Therefore the entropy is the most precise measure of the diversity. <p> And if we assume P 6= N P for the optimization variants, there is an * &gt; 0 such that no polynomial time approximation algorithm for these problems can find a solution that is guaranteed to be within a ratio of jV j * of optimal <ref> [1] </ref>. Still there are many applications like register allocation [10], timetabling [76], scheduling and printed circuit testing [34] and although no good polynomial algorithm exists for general graphs, an algorithm can still exist which has good expected performance for a specific class of graphs.
Reference: [2] <author> T. </author> <title> Back. The interaction of mutation rate, selection, and self-adaption within a genetic algorithm. </title> <editor> In R. Manner and B. Manderick, editors, </editor> <booktitle> Parellel Problem Solving from Nature - 2, </booktitle> <pages> pages 85-94, </pages> <address> Amsterdam, 1992. </address> <publisher> Elsevier. </publisher>
Reference: [3] <author> T. </author> <title> Back. Self-adaptation in genetic algorithms. </title> <booktitle> In Proceedings of the first European Conference on Artificial Life, </booktitle> <pages> pages 263-271, </pages> <address> Paris, December 1992. </address> <publisher> MIT Press. </publisher>
Reference-contexts: mutation rate by Back [2]<ref> [3] </ref>. Here the mutation rates are incorporated into the genetic representation of the individuals and the mutation rates are also subject to mutation and selection. So no external, deterministic control is needed for changing the mutation rate. Though in personal communication he said the mechanism in [3] did not work so well and he introduced another scheme where the mutation rate is dependent on the fitness value.
Reference: [4] <author> T. Back and S. Khuri. </author> <title> An evolutionary heuristic for the maximum independent set problem. </title> <booktitle> In Proceedings of the first IEEE Conference on Evolutionary Computation, </booktitle> <pages> pages 531-535. </pages> <publisher> IEEE Press, </publisher> <year> 1994. </year>
Reference: [5] <author> Thomas Back. </author> <title> Optimal mutation rates in genetic search. </title> <editor> In S. Forrest, editor, </editor> <booktitle> Proceedings of the fifth International Conference on Genetic Algorithms, </booktitle> <pages> pages 2-9. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Back uses some theory in isolation of a recombination operator to observe that dynamic mutation rates can be useful for multimodal fitness functions <ref> [5] </ref>.
Reference: [6] <author> Thomas Back. </author> <title> Selective pressure in evolutionary algorithms: A characterization of selection mechanisms. </title> <booktitle> In Proceedings of the first IEEE Conference on Evolutionary Computation, </booktitle> <pages> pages 57-62. </pages> <publisher> IEEE Press, </publisher> <year> 1994. </year>
Reference-contexts: In worst fitness deletion, the individuals with worst fitness are deleted from the (+) individuals (ties are broken randomly 2 ). Together with an SSEA, this ensures that the best individual is always kept in the population which is called elitist selection. 3.3 Tournament Selection In [41] and <ref> [6] </ref> some mechanisms are investigated for selecting the parents that are used to produce offspring. In [6], Back uses the takeover time as a quantitative measure for the selective pressure: the force that gives fit individuals higher probability to be selected. <p> Together with an SSEA, this ensures that the best individual is always kept in the population which is called elitist selection. 3.3 Tournament Selection In [41] and <ref> [6] </ref> some mechanisms are investigated for selecting the parents that are used to produce offspring. In [6], Back uses the takeover time as a quantitative measure for the selective pressure: the force that gives fit individuals higher probability to be selected. He reports that selective pressure increases in the order proportional selection, linear ranking, tournament selection, (; )-selection.
Reference: [7] <author> Thomas Back and Martin Schutz. </author> <title> Intelligent mutation rate control in canonical genetic algorithms. </title> <type> Technical report, </type> <institution> Center for Applied Systems Analysis, </institution> <address> Joseph-von-Fraunhofer-Str. 20, D-44227 Dortmund, </address> <year> 1996. </year>
Reference-contexts: We get p m (t) = &gt; &lt; t c t ; if 0 t t c (6.1) Another function to control the decrease of p m is by Back and Schutz <ref> [7] </ref>, which is of the form p m (t) = (b + c t) 1 . They constrain p m (t) so that p m (0) = 0:5 and p m (T max ) = 1 L , so they do not use a parameter like t c . <p> So no external, deterministic control is needed for changing the mutation rate. Though in personal communication he said the mechanism in [3] did not work so well and he introduced another scheme where the mutation rate is dependent on the fitness value. In <ref> [7] </ref> he compared the self-adapting mechanism with the deterministic mechanism for changing p m which is described above and concluded that the deterministic mechanism gave better results when the fitness function is not changing over time. Therefore the self-adapting mechanism is not tested here. <p> As dynamically changing the mutation rate proved effective for the asexual EA, it could be interesting to try a combination with the SAW mechanism, perhaps by increasing the mutation rate directly after each weight update and then slowly decrease it again. Interesting now becomes the self-adaptation by Back <ref> [7] </ref> as this works better for dynamically changing fitness functions which is the case for an EA that uses the SAW mechanism. Also for Graph 3-Coloring, initializing the EA with recombination and a population with permutations found by DSatur (without backtracking), proved to be very successful.
Reference: [8] <author> A. Blum. </author> <title> An O(n 0:4 )-approximation algorithm for 3-coloring (and improved approximation algorithms for k-coloring). </title> <booktitle> In Proceedings of the 21st ACM Symposium on Theory of Computing, </booktitle> <pages> pages 535-542, </pages> <address> New York, 1989. </address> <publisher> ACM. </publisher>
Reference-contexts: Existing algorithms for Graph k-coloring are: an O (n 0:4 )-approximation algorithm by Blum <ref> [8] </ref>, the simple Greedy algorithm [54], DSatur from Brelaz [9], Iterated Greedy (IG) 30 from Culberson [14], XRLF from Johnson et al. [47]. Both XRLF and DSatur (and some variants) are often considered the best existing algorithms.
Reference: [9] <author> D. Brelaz. </author> <title> New methods to color vertices of a graph. </title> <journal> Communications of the ACM, </journal> <volume> 22 </volume> <pages> 251-256, </pages> <year> 1979. </year>
Reference-contexts: Existing algorithms for Graph k-coloring are: an O (n 0:4 )-approximation algorithm by Blum [8], the simple Greedy algorithm [54], DSatur from Brelaz <ref> [9] </ref>, Iterated Greedy (IG) 30 from Culberson [14], XRLF from Johnson et al. [47]. Both XRLF and DSatur (and some variants) are often considered the best existing algorithms. <p> However, the Greedy Algorithm is as a basis for DSatur, IG and the EA with order-based representation. 5.4.2 DSatur DSatur from Brelaz <ref> [9] </ref> uses some heuristics to dynamically create an ordering of the nodes and then greedily colors the nodes as follows: 33 * node with highest saturation degree (number of differently colored neighbors) is se- lected and given the smallest possible color. * in case of a tie, the node with highest
Reference: [10] <author> G.J. Chaitin. </author> <title> Register allocation and spilling via graph coloring. </title> <booktitle> In Proceedings of the ACM SIGPLAN 82 Symposium on Compiler Construction, </booktitle> <pages> pages 98-105. </pages> <publisher> ACM Press, </publisher> <year> 1982. </year>
Reference-contexts: Still there are many applications like register allocation <ref> [10] </ref>, timetabling [76], scheduling and printed circuit testing [34] and although no good polynomial algorithm exists for general graphs, an algorithm can still exist which has good expected performance for a specific class of graphs.
Reference: [11] <author> Scott H. Clearwater and Tad Hogg. </author> <title> Problem structure heuristics and scaling behavior for genetic algorithms. </title> <journal> Artificial Intelligence, </journal> <volume> 81 </volume> <pages> 327-347, </pages> <year> 1996. </year>
Reference-contexts: Hogg did a lot of research about the phase transition and developed some theory around it <ref> [11] </ref>. They used Walsh polynomials to model an arbitrary CSP and to predict the cost function for simple backtrack search.
Reference: [12] <author> S.A. Cook. </author> <title> The complexity of theorem-proving procedures. </title> <booktitle> In Proceedings of the 3rd Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 151-158, </pages> <year> 1971. </year>
Reference-contexts: In 3-SAT we also constrain the clauses to have exactly three literals. In the common notation, a formula has l clauses and n variables. SAT was the first computational task shown to be NP-hard by Cook <ref> [12] </ref>, but is also of practical interest as it has applications in for example reasoning, diagnosis, planning [49] and image interpretation [64]. Originally SAT was formulated as a decision problem, but here the variant is used where we ask for an actual solution.
Reference: [13] <author> Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: To illustrate the effect of transforming problems, we use the following transformation from Cormen et al. <ref> [13] </ref> for a 3-SAT problem to a Graph 3-Coloring problem. Given a formula of l clauses on n variables, x 1 ; x 2 ; : : : ; x n , we construct a graph G = (V; E).
Reference: [14] <author> Joseph C. Culberson and Feng Luo. </author> <title> Exploring the k-colorable landscape with iterated greedy. In Second DIMACS Challenge, </title> <journal> Discrete Mathematics and Theoretical Computer Science. AMS, </journal> <note> 1995. Available http://web.cs.ualberta.ca/~joe/. </note>
Reference-contexts: Existing algorithms for Graph k-coloring are: an O (n 0:4 )-approximation algorithm by Blum [8], the simple Greedy algorithm [54], DSatur from Brelaz [9], Iterated Greedy (IG) 30 from Culberson <ref> [14] </ref>, XRLF from Johnson et al. [47]. Both XRLF and DSatur (and some variants) are often considered the best existing algorithms. <p> IG was also implemented as it will be used in a combination with the EA. 5.2 Problem Instances In the literature do not exist so many benchmark 3-colorable graphs and therefore new graphs are created with the graph generator 1 written by Joe Culberson <ref> [14] </ref>. This generator creates various classes of k-colorable quasi-random graphs. The classes that will be examined are the following: * arbitrary 3-colorable graphs, where vertices are randomly assigned one of the 3 colors uniformly and independently. <p> The generator creates a graph G n;p;s for a specific graph class with parameters n (number of nodes), p (edge connectivity) and s (the seed for the random generator). More information on these classes can be found in <ref> [14] </ref>. <p> So it is for these instances that EAs and other time consuming methods get a chance. 5.4.3 Iterated Greedy Joe Culberson's Iterated Greedy (IG) <ref> [14] </ref>, makes use of the greedy algorithm described earlier and tries to find the minimum number of colors to color a graph, so a valid solution always exists.
Reference: [15] <author> Charles Darwin. </author> <title> The Origin of Species. </title> <type> 1859. </type>
Reference-contexts: In appendix A, a summary of the abbreviations and some notation is given. 2 Chapter 2 What are Evolutionary Algorithms? Evolutionary algorithms (EAs) are search algorithms based on biological evolution. Darwin was the first to clearly state the idea of natural selection as a principle behind biological evolution <ref> [15] </ref>. Natural selection or "survival of the fittest" 1 is simply the process by which the best or most fit members of some species have more probability of surviving or by which the weakest members have more probability of dying out so that the weakest individuals will be selected out.
Reference: [16] <author> David Bull David Beasley and Ralph Martin. </author> <title> An overview of genetic algorithms: Part 2, research topics. </title> <journal> University Computing, </journal> <volume> 15(4) </volume> <pages> 170-181, </pages> <year> 1993. </year>
Reference-contexts: Biologists even see mutation as the main source for evolutionary change. In <ref> [16] </ref> several good results of "nave evolution" (as it is called in [66]) are reported. Eiben et al. [24] compared several asexual operators for the Graph 3-Coloring problem with a version that used uniform crossover, a standard mutation and fixed to 200 for n = 50.
Reference: [17] <author> L. Davis. </author> <title> Handbook of Genetic Algorithms. </title> <publisher> Van Nostrand Reinhold, </publisher> <year> 1991. </year>
Reference-contexts: j 8 9 2 4 Child 1: 0 1 3 7 j 4 5 6 j 8 9 2 10 Child 2: 2 4 5 6 j 1 3 7 j 8 9 10 0 Order Crossover Order crossover (OX), an operator that works on permutations, was developed by Davis <ref> [17] </ref> and creates two children which preserve the order and position of symbols in a subsequence of one parent while preserving the relative order of the remaining symbols from the other parent. <p> # Parent 2: 2 5 0 9 7 3 8 6 1 4 10 Child 1: 0 9 2 3 4 5 6 7 8 1 10 Child 2: 2 5 0 9 7 3 6 8 1 4 10 Order #2 Crossover Order crossover #2 (OX2), developed by Syswerda <ref> [17] </ref>, differs from OX in that several key positions are chosen randomly and the order in which these elements appear in one parent is imposed on the other parent to create the two children. <p> 0 1 2 # Parent 2: 2 5 0 9 7 3 8 6 1 4 10 Child 1: 2 1 0 3 4 5 6 7 8 9 10 Child 2: 0 5 2 9 7 3 8 6 1 4 10 5 Position based crossover, proposed by Syswerda <ref> [17] </ref>, is almost the same as OX2, only now the genes that are not selected are used to impose the ordering.
Reference: [18] <author> M. Davis and H. Putnam. </author> <title> A computing procedure for quantification theory. </title> <journal> Jnl. Association for Computing Machinery, </journal> <volume> 7 </volume> <pages> 201-215, </pages> <year> 1960. </year>
Reference-contexts: Originally SAT was formulated as a decision problem, but here the variant is used where we ask for an actual solution. The most well known complete algorithm for SAT, DP (Davis-Putnam, which is a backtracking algorithm based on resolution and combined with unit propagation) <ref> [18] </ref> , can take a time exponential in the length of the formula to run. To overcome this, an incomplete algorithm, GSAT, was proposed by Selman et al. [69].
Reference: [19] <author> Richard Dawkins. </author> <title> The Blind Watchmaker. </title> <publisher> Penguin Books, </publisher> <year> 1986. </year>
Reference-contexts: The advantage of half an eye is simply that it's better than seeing nothing and even one lightcell could be an advantage. In <ref> [19] </ref>, Dawkins very clearly and gradually explains how evolution can build up complex organisms with mutation, natural selection and enough time. An example, drawn from [57], should clarify the basic ideas from evolution theory. Let's suppose that somewhere and sometime we have a population of cute, furry, little rabbits.
Reference: [20] <author> A.E. Eiben, E.H.L. Aarts, and K.M. van Hee. </author> <title> Global convergence of genetic algorithms: A markov chain analysis. </title> <editor> In R. Manner and B. Manderick, editors, </editor> <booktitle> Proceedings of the 2nd Parallel Problem Solving from Nature, </booktitle> <pages> pages 4-12. </pages> <publisher> North-Holland, </publisher> <year> 1992. </year>
Reference-contexts: As we work with CSPs and a solution is always forced to exist, we can compare the algorithms on the time that they need to find a solution. Theorems exist saying that some probabilistic algorithms are guaranteed to find a solution if one exists <ref> [20] </ref>, but infinite time is needed to guarantee this and in practice we will need to define a maximum on the computational effort that an algorithm is allowed to take, so that not in all runs a solution will be found.
Reference: [21] <author> A.E. Eiben, C.H.M. van Kemenade, and J.N. Kok. </author> <title> Orgy in the computer: Multi-parent reproduction in genetic algorithms,. </title> <editor> In F. Moran, A. Moreno, J.J. Merelo, and P. Chacon, editors, </editor> <booktitle> Proceedings of the 3rd European Conference on Artificial Life, number 929 in LNAI, </booktitle> <pages> pages 934-945. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference: [22] <author> A.E. Eiben, P.-E. Raue, and Zs. Ruttkay. </author> <title> Genetic algorithms with multi-parent recombination. </title> <editor> In Y. Davidor, editor, </editor> <booktitle> Parallel Problem Solving from Nature - 3, </booktitle> <volume> LNCS 866, </volume> <pages> pages 78-87, </pages> <year> 1994. </year>
Reference: [23] <author> A.E. Eiben, P.-E. Raue, and Zs. Ruttkay. </author> <title> Repairing, adding constraints and learning as a means of improving GA performance on CSPs. </title> <editor> In M. Meyer, editor, </editor> <booktitle> Benelearn '94 Proceedings of the 4th Belgian-Dutch Conference on Machine Learning, </booktitle> <pages> pages 112-123, </pages> <year> 1994. </year>
Reference: [24] <author> A.E. Eiben, P.-E. Raue, and Zs. Ruttkay. </author> <title> Solving constraint satisfaction problems using genetic algorithms. </title> <booktitle> In First IEEE conference on Evolutionary Computation, </booktitle> <pages> pages 542-547, </pages> <year> 1994. </year>
Reference-contexts: But increasing the population size often has positive effect on the performance <ref> [24] </ref> and because we cannot be sure that the change in population size has the same effect on the performance for each operator, the effect of changing the will be examined for uniform, SCAN5, DIAG35 and 34-point crossover. 47 300:000 with IP (SE). <p> Biologists even see mutation as the main source for evolutionary change. In [16] several good results of "nave evolution" (as it is called in [66]) are reported. Eiben et al. <ref> [24] </ref> compared several asexual operators for the Graph 3-Coloring problem with a version that used uniform crossover, a standard mutation and fixed to 200 for n = 50. <p> Uniform crossover also uses IP. 6.2 EA with Order-based Representation Because Eiben et al. had very good results for the order-based representation in <ref> [24] </ref>, although only tested for small problems, this will be experimented with in this section. In order-based EAs the individuals are permutations and special operators are used to recombine and mutate permutations (see section 3.6) and so the fitness function now has to evaluate permutations.
Reference: [25] <author> A.E. Eiben and Zs. Ruttkay. </author> <title> Self-adaptivity for constraint satisfaction: Learning penalty functions,. </title> <booktitle> In Proceedings of the 3rd IEEE World Conference on Evolutionary Computation, </booktitle> <pages> pages 258-261. </pages> <publisher> IEEE Service Center, </publisher> <year> 1996. </year>
Reference: [26] <editor> Larry J. Eshelman. </editor> <title> The CHC adaptive search algorithm: How to have safe search when engaging in nontraditional genetic recombination. </title> <booktitle> In Foundations of Genetic Algorithms - 1, </booktitle> <pages> pages 265-283, </pages> <year> 1991. </year>
Reference-contexts: HUX Operator The HUX (heuristic uniform crossover) operator, designed by Eshelman <ref> [26] </ref>, is based on uniform crossover. The idea is to have a maximally disruptive crossover operator, to exploit the search space as much as possible. <p> As we know from nature, it is important for a species to keep enough diversity in the population. Now mating similar individuals (like in incest or in-breeding) reduces the diversity and Eshelman designed a mechanism, called Incest Prevention (IP) to prevent similar individuals from recombining <ref> [26] </ref>. The idea is to only recombine parents that are maximally different to ensure that the children will not resemble other individuals already present in the population. <p> a problem when is very small! A solution would be to stop using a population as soon as it is converged and then only use mutation (or start using mutation only then) or to reinitialize the population after convergence or after a weight update as was done by Eshelman in <ref> [26] </ref> 17 Still for = 2 such a long period as before is probably not necessary and as we decrease T p , more weight updates can be done.
Reference: [27] <author> Charles Fleurent and Jacques A. Ferland. </author> <title> Genetic and hybrid algorithms for graph coloring. </title> <editor> In I. H. Osman G. Laporte and P. L. Hammer, editors, </editor> <booktitle> Annals of Operations Research, Metaheuristics in Combinatorial Optimization, </booktitle> <institution> Universite de Montreal, Departement d'Informatique et de Recherche Operationalle, Canada, </institution> <year> 1994. </year> <note> Available via ftp://ftp.iro.umontreal.ca/pub/optim/fleurent/papers/coloring/coloring.ps.Z. </note>
Reference-contexts: An advantage is that it can also be used for problems with real valued genes. * Sum over all genes of the entropy per gene over all individuals <ref> [27] </ref>: E i = P jDj n ij n ij log jDj P L L where n ij is the number of individuals in the population for which gene i has value j, with 1 j jDj, jDj the number of domain values for each gene.
Reference: [28] <author> T.C. Fogarty. </author> <title> Varying the probability of mutation in the genetic algorithm. </title> <booktitle> In Proceedings of the third International Conference on Genetic Algorithms, </booktitle> <pages> pages 104-109, </pages> <year> 1989. </year>
Reference-contexts: This can especially be interesting as we saw that the mutation operator turned out to be so important and so mechanisms that can enhance the performance of the mutation operator are important as well. It has been argued that p m should decrease over time ([45] 69 and <ref> [28] </ref>) 14 . Hesser and Manner [45] used a function of the form p m (t) = e ct with b and c constants and t the evaluation number, to control the decrease of p m .
Reference: [29] <editor> D.B. Fogel. </editor> <booktitle> Evolutionary Programming. </booktitle> <publisher> IEEE Press, </publisher> <year> 1995. </year>
Reference-contexts: For the asexual EA with population size 1, more research will have to show if it's superior to EAs with recombination. More and more often, researchers report that an asexual EA can perform better <ref> [29] </ref>. If this happens to be more general, it could be interesting to experiment with many other types of mutation, possibly making use of the fact that the positions in the beginning of a permutation are more important in order-based EAs.
Reference: [30] <author> B.R. Fox and M.B. McMahon. </author> <title> Genetic operators for sequencing problems. </title> <booktitle> In Foundations of Genetic Algorithms - 1, </booktitle> <pages> pages 284-300, </pages> <year> 1991. </year>
Reference-contexts: Both types of problems need different kind of operators and several studies have been done to compare operators on both types of problems ([70], <ref> [30] </ref> and [56]).
Reference: [31] <author> Jeremy Frank. </author> <title> Learning short-term weights for GSAT. </title> <booktitle> In Proceedings of the AAAI, </booktitle> <year> 1996. </year> <note> To appear, available by http://rainier.cs.ucdavis.edu/~frank/decay.ml96.ps. </note>
Reference-contexts: Also instead of only increasing the weights of variables, weights could also be decreased after a while when the variable is correctly instantiated. Among other things, Frank experimented with this in <ref> [31] </ref>, though the results on this were not very significant. Also questions remain about the weights that the SAW mechanism learned. Preliminary tests showed that using the learned weights again in a next run for the same instance, give spectacular degraded performances.
Reference: [32] <author> Jeremy Frank. </author> <title> Weighting for godot: Learning heuristics for GSAT. </title> <booktitle> In Proceedings of the AAAI, </booktitle> <year> 1996. </year> <note> To appear, available by http://rainier.cs.ucdavis.edu/~frank/weighting.aaai96.ps. </note>
Reference-contexts: Some tests however, showed that this gave a spectacular decrease in performance which was also found by Frank <ref> [32] </ref>. This shows that the adaptivity is crucial in two ways in the SAW mechanism. The individual adapts itself to the weights (by mutation and selection) and the weights adapt to the best individual (by SAW) and one cannot be used without the other. <p> To overcome this, an incomplete algorithm, GSAT, was proposed by Selman et al. [69]. Frank presented a modification of a weighted GSAT version <ref> [32] </ref>, and showed that this modification, WGSAT, has better performance than one of the best known variants of GSAT, HSAT [36], and so the EA will be compared to the WGSAT algorithm. 93 7.2 Problem Instances As for the Graph 3-Coloring problem, we need instances that are known to have a <p> This generator creates 3-CNF instances by generating each clause by selecting 3 of n literals without replacement and negating each literal with probability 1 2 . From Frank, we obtained the same 1000 seeds for n = 100 as were used in his comparison with HSAT and GSAT <ref> [32] </ref>. The instances that were generated with these seeds, were proven to have solutions with a variant of the DP procedure. <p> T p = 12 and fl = 12 and for the DO operator T p = 100. 7.6 The Final Tests In this section, a big comparison between WGSAT and the EA will be done using the same 1000 satisfiable instances (SeedSet1) as Frank used in his comparison with HSAT <ref> [32] </ref> (see section 7.2 for a description). SeedSet2 consists of 1000 random instances for the same generator, so not necessarily all instances are satisfiable. The results are given in table 7.9. Clearly, both EA versions (preservative and extinctive) greatly improve on the performance of WGSAT.
Reference: [33] <author> M.R. Garey and D.S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. W.H. </title> <publisher> Freedman and Co., </publisher> <year> 1979. </year>
Reference-contexts: Several variations exist, like finding the least number of colors that is needed to color the graph, or to find the largest subgraph in G that can be colored with the given number of colors. All of these problems are known to be NP-complete <ref> [33] </ref>, so it is unlikely that a polynomial time algorithm exists that solves any of these problems.
Reference: [34] <author> M.R. Garey, D.S. Johnson, and H.C. </author> <title> So. An application of graph coloring to printed circuit testing. </title> <journal> IEEE Trans. on Circuits and Systems, </journal> <volume> CAS-23:591-599, </volume> <year> 1976. </year>
Reference-contexts: Still there are many applications like register allocation [10], timetabling [76], scheduling and printed circuit testing <ref> [34] </ref> and although no good polynomial algorithm exists for general graphs, an algorithm can still exist which has good expected performance for a specific class of graphs.
Reference: [35] <author> I. Gent and T. Walsh. </author> <title> The enigma of SAT hill-climbing procedures. </title> <type> Technical Report 605, </type> <institution> Department of AI, University of Edinburgh, </institution> <address> 80 South Bridge, Edinburgh EH1 1HN, Scotland, </address> <year> 1992. </year>
Reference-contexts: Formulas obtained in this way tend to be somewhat harder than formulas that are forced to be satisfiable. 7.3 The Traditional Algorithms 7.3.1 GSAT To present GSAT, a more general framework, presented by Gent and Walsh, "GenSAT" <ref> [35] </ref>, that captures all versions of GSAT (and an EA version as we will see in section 7.5), will be used.
Reference: [36] <author> I. Gent and T. Walsh. </author> <title> Unsatisfied variables in local search. </title> <editor> In J. Hallam, editor, </editor> <title> Hybrid Problems, Hybrid Solutions. </title> <publisher> IOS Press, </publisher> <year> 1995. </year> <month> 121 </month>
Reference-contexts: To overcome this, an incomplete algorithm, GSAT, was proposed by Selman et al. [69]. Frank presented a modification of a weighted GSAT version [32], and showed that this modification, WGSAT, has better performance than one of the best known variants of GSAT, HSAT <ref> [36] </ref>, and so the EA will be compared to the WGSAT algorithm. 93 7.2 Problem Instances As for the Graph 3-Coloring problem, we need instances that are known to have a solution, because the EA is an incomplete algorithm.
Reference: [37] <author> Ian P. Gent and Toby Walsh. </author> <title> Towards an understanding of hill-climbing prodedures for SAT. </title> <publisher> AAAI, </publisher> <pages> pages 28-33, </pages> <year> 1993. </year>
Reference-contexts: As table 7.6 14 shows, it is better not to use steepest ascent hill-climbing. This was also found by Gent and Walsh <ref> [37] </ref>, who discovered that greediness is unimportant and could even degrade the performance. Without steepest ascent hill-climbing, the search will be slower but will not be trapped as easily by local minima.
Reference: [38] <author> F. Glover. </author> <title> Tabu search part I. </title> <journal> ORSA Journal on Computing, </journal> <volume> 1(3) </volume> <pages> 190-206, </pages> <year> 1989. </year>
Reference: [39] <author> F. Glover. </author> <title> Tabu search part II. </title> <journal> ORSA Journal on Computing, </journal> <volume> 2(1) </volume> <pages> 4-32, </pages> <year> 1990. </year>
Reference: [40] <author> David E. Goldberg. </author> <title> Sizing populations for serial and parallel genetic algorithms. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the third International Conference on Genetic Algorithms, </booktitle> <pages> pages 70-79. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: is 1 which is the smallest population size that still has some form of selection! Still Goldberg already gives some theory that predicts a really small population size of 3 (which still makes sense in connection with reproduction and crossover according to him) to be optimal for a serial EA <ref> [40] </ref>. And although figures 6.10 and 6.11 show the advantage of a big population size, for the order-based representation later in this thesis, this really small population size will be tested as well. Figures 6.14 and 6.15 show the performance of uniform crossover (with mutation) against that of mutation alone. <p> It should be noted that in a first test only &gt; 100 was tested and if one extrapolates the curve in figure 6.16 this seems reasonable. But because of the results for the asexual EA and because of Goldberg's theory predicting = 3 to be optimal <ref> [40] </ref>, also some really small values for were tested and this gave some unexpected results. If is decreased below = 50, the performance starts increasing again with optimal performance for = 2, which is the smallest possible population size for an EA with recombination.
Reference: [41] <editor> David E. Goldberg and Kalyanmoy Deb. </editor> <title> A comparative analysis of selection schemes used in genetic algorithms. </title> <booktitle> In Foundations of Genetic Algorithms - 1, </booktitle> <pages> pages 69-93, </pages> <year> 1991. </year>
Reference-contexts: The mechanisms for selecting among the ( + ) individuals and for producing the offspring will be described in the next sections. 1 It should be noted however that Goldberg and Deb <ref> [41] </ref> claim that SSEAs are not fundamentally better than generational EAs which should be able to obtain the same results with higher selective pressure. 9 3.2 Worst Fitness Deletion Several mechanisms exist to select a population of size again from the ( + ) individuals (or from the &gt; individuals in <p> In worst fitness deletion, the individuals with worst fitness are deleted from the (+) individuals (ties are broken randomly 2 ). Together with an SSEA, this ensures that the best individual is always kept in the population which is called elitist selection. 3.3 Tournament Selection In <ref> [41] </ref> and [6] some mechanisms are investigated for selecting the parents that are used to produce offspring. In [6], Back uses the takeover time as a quantitative measure for the selective pressure: the force that gives fit individuals higher probability to be selected.
Reference: [42] <author> D.E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: 9 7 3 j 8 6 1 4 10 Child 1: 2 1 j 0 9 7 3 j 6 4 8 5 10 Child 2: 0 9 j 2 3 4 5 j 8 6 1 7 10 Partially Mapped Crossover Partially mapped crossover (PMX), by Goldberg and Lingle <ref> [42] </ref> preserves the order and position of genes in a subsequence of one parent while preserving the order and position of many of the remaining genes from the second parent. It is implemented by selecting two random cut points which define the boundaries for a series of swapping operations.
Reference: [43] <author> G.R. Grimmet and C.J.H. McDiarmid. </author> <title> On colouring random graphs. </title> <booktitle> Mathematical Proceedings of the Cambridge Philosophical Society, </booktitle> <volume> 77 </volume> <pages> 313-324, </pages> <year> 1975. </year>
Reference-contexts: This ordering of the nodes often is random, but some heuristics can be used to determine the ordering, which is the case for DSatur. Grimmet and McDiarmid <ref> [43] </ref> have shown that for almost all random graphs (in the usual model), the greedy algorithm uses no more than about twice the optimal number of colors.
Reference: [44] <author> Jin-Kao Hao. </author> <title> A clausal genetic representation and its evolutionary procedures for-satisfiability problems. </title> <booktitle> In Proceedings of the International Conference on Artificial Neural Networks and Genetic Algorithms, </booktitle> <address> France, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: De Jong and Spears [48] also used a bit representation for GAs on SAT, but they used a different evaluation function than the above one, because they experimented with more general CNF (not necessarily 3-CNF) formulas. Hao <ref> [44] </ref> used a clausal representation, where each clause in the SAT problem is represented by a group of three genes and some adapted operators are used. <p> As this would give individuals with length L = 1290 instead of L = 100 for an instance with n = 100 and because he did not report any results in <ref> [44] </ref>, that representation will not be used. Next will be shown that the order-based representation is not suited to SAT and therefore the bit representation will be used in the following sections. For each instance 50 runs with T max = 300:000 are done.
Reference: [45] <author> J. Hesser and R. </author> <title> Manner. Towards an optimal mutation probability in genetic algorithms. </title> <editor> In Hans-Paul Schwefel, editor, </editor> <booktitle> Parallel Problem Solving from Nature - 1, </booktitle> <volume> LNCS 496, </volume> <pages> pages 23-32, </pages> <year> 1991. </year>
Reference-contexts: It has been argued that p m should decrease over time (<ref> [45] </ref> 69 and [28]) 14 . Hesser and Manner [45] used a function of the form p m (t) = e ct with b and c constants and t the evaluation number, to control the decrease of p m .
Reference: [46] <author> J.H. Holland. </author> <booktitle> Adaption in natural and artificial systems. </booktitle> <publisher> MIT Press, </publisher> <year> 1975. </year>
Reference-contexts: The basic principles of EAs were first described by Holland <ref> [46] </ref> and further develop 6 ments and descriptions can be found in many other texts (e.g. [17][42][53][57][67]). EAs are a more general class of algorithms that include genetic algorithms (GAs). <p> recombination, the OneSWAP operator will not be used unless stated otherwise. 6.5.2 Changing the Mutation Rate Externally Up to now, the mutation rate has been kept fixed, but probably changing p m during a run can have a positive effect on the performance, which has already been suggested by Holland <ref> [46] </ref>. This can especially be interesting as we saw that the mutation operator turned out to be so important and so mechanisms that can enhance the performance of the mutation operator are important as well.
Reference: [47] <author> D.S. Johnson, C.R. Aragon, L.A. McGeoch, and C. Schevon. </author> <title> Optimization by simulated annealing: An experimental evaluation; part II, graph coloring and number partitioning. </title> <journal> Operations Research, </journal> <volume> 39(3) </volume> <pages> 378-406, </pages> <year> 1991. </year>
Reference-contexts: Existing algorithms for Graph k-coloring are: an O (n 0:4 )-approximation algorithm by Blum [8], the simple Greedy algorithm [54], DSatur from Brelaz [9], Iterated Greedy (IG) 30 from Culberson [14], XRLF from Johnson et al. <ref> [47] </ref>. Both XRLF and DSatur (and some variants) are often considered the best existing algorithms. In [47] it was reported that XRLF finds sometimes better solutions than DSatur, but takes far more time and that a clear winner between the two was not found, though this analysis was for finding the <p> for Graph k-coloring are: an O (n 0:4 )-approximation algorithm by Blum [8], the simple Greedy algorithm [54], DSatur from Brelaz [9], Iterated Greedy (IG) 30 from Culberson [14], XRLF from Johnson et al. <ref> [47] </ref>. Both XRLF and DSatur (and some variants) are often considered the best existing algorithms. In [47] it was reported that XRLF finds sometimes better solutions than DSatur, but takes far more time and that a clear winner between the two was not found, though this analysis was for finding the minimal k in random graphs.
Reference: [48] <author> K.A. De Jong and W.M. Spears. </author> <title> Using genetic algorithms to solve NP-complete problems. </title> <booktitle> In Proceedings of the third International Conference on Genetic Algorithms, </booktitle> <pages> pages 124-132, </pages> <year> 1989. </year>
Reference-contexts: Then an individual can directly (without a decoder) be interpreted as a truth assignment. The fitness function just counts the unsatisfied clauses, so again we obtain a minimization problem. De Jong and Spears <ref> [48] </ref> also used a bit representation for GAs on SAT, but they used a different evaluation function than the above one, because they experimented with more general CNF (not necessarily 3-CNF) formulas.
Reference: [49] <author> H.A. Kautz and B. Selman. </author> <title> Planning as satisfiability. </title> <booktitle> In Proceedings of the 10th ECAI, </booktitle> <pages> pages 359-363, </pages> <year> 1992. </year>
Reference-contexts: In the common notation, a formula has l clauses and n variables. SAT was the first computational task shown to be NP-hard by Cook [12], but is also of practical interest as it has applications in for example reasoning, diagnosis, planning <ref> [49] </ref> and image interpretation [64]. Originally SAT was formulated as a decision problem, but here the variant is used where we ask for an actual solution.
Reference: [50] <author> C.H.M. van Kemenade, J.N. Kok, and A.E. Eiben. </author> <title> Raising GA performance by simultaneous tuning of selective pressure and recombination disruptiveness. </title> <type> Technical Report CS-R9558, </type> <institution> Centrum voor Wiskunde en Informatica, </institution> <address> Kruislaan 413, 1098 SJ Amsterdam, The Netherlands, </address> <month> August </month> <year> 1995. </year> <month> 122 </month>
Reference-contexts: When k = 1, random selection is used and to keep some selective pressure, often the lowest value for k is 2. In <ref> [50] </ref> it is noticed that "the worst fitness deletion mechanism is best combined with a low tournament 2 In a first nave implementation, ties were broken by taking the first individual from the (unsorted) population.
Reference: [51] <author> S. Khuri and T. </author> <title> Back. An evolutionary heuristic for the minimum vertex cover prob-lem. </title> <editor> In J. Kunze and H. Stoyan, editors, </editor> <booktitle> KI-94 Workshops (Extended Abstracts), </booktitle> <pages> pages 83-84, </pages> <address> Bonn, </address> <year> 1994. </year>
Reference: [52] <author> S. Khuri, T. Back, and J. Heitkotter. </author> <title> The zero/one multiple knapsack problem and genetic algorithms. </title> <editor> In J. Urban E. Deaton, D. Oppenheim and H. Berghel, editors, </editor> <booktitle> Proceedings of the 1994 ACM Symposium on Applied Computing, </booktitle> <pages> pages 188-193, </pages> <address> New York, 1994. </address> <publisher> ACM Press. </publisher>
Reference: [53] <editor> J.R. Koza. </editor> <booktitle> Genetic Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: An attempt to solve this problem is presented in the next section. 4.3 Expected Number of Functions Evaluations In this section a kind of combination of SR and AES <ref> [53] </ref> is presented. In a practical situation we're really only interested in the time necessary to find a solution or to say that a solution will not be found. Because EAs are incomplete algorithms we cannot say whether a solution will never be found.
Reference: [54] <author> L. Kucera. </author> <title> The greedy coloring is a bad probabilistic algorithm. </title> <journal> Journal of Algorithms, </journal> <volume> 12 </volume> <pages> 674-684, </pages> <year> 1991. </year>
Reference-contexts: Existing algorithms for Graph k-coloring are: an O (n 0:4 )-approximation algorithm by Blum [8], the simple Greedy algorithm <ref> [54] </ref>, DSatur from Brelaz [9], Iterated Greedy (IG) 30 from Culberson [14], XRLF from Johnson et al. [47]. Both XRLF and DSatur (and some variants) are often considered the best existing algorithms.
Reference: [55] <author> A. Lokketangen and F. Glover. </author> <title> Surrogate constraint methods with simple learning for satisfiability problems. </title> <editor> In D.-Z. Du, J. Gu, and P. Pardolos, editors, </editor> <booktitle> Proceedings of the DIMACS workshop on Satisfiability Problems: Theory and Applications, </booktitle> <year> 1996. </year>
Reference-contexts: TABU search maintains a history of moves to prevent it from making the same moves again and is claimed to give very good results. Also Glover's Scatter Search with surrogate constraints <ref> [55] </ref>, which keeps a population of potential solutions and generates trial points (offspring) by weighted linear combinations of them, could be interesting. 117 Appendix A Summary of Abbreviations and Notation Symbol Meaning Pagenumber 4w Weight increment constant for SAW 74 Offspring population size 9 Population size 9 l Number of clauses
Reference: [56] <author> Bernard Manderick and Piet Spiessens. </author> <title> How to select genetic operators for combinatorial optimization problems by analyzing their fitness landscape. </title> <editor> In J.C. Bioche and X.-H. Tan, editors, </editor> <booktitle> Proceedings of the 7th Dutch Conference on Artificial Intelligence, </booktitle> <pages> pages 127-136, </pages> <year> 1995. </year>
Reference-contexts: Both types of problems need different kind of operators and several studies have been done to compare operators on both types of problems ([70], [30] and <ref> [56] </ref>). <p> In [70] the most important order-based operators are described and compared and it shows that for scheduling-like problems order crossover #2 (OX2) by Syswerda [72] is the best operator. This can also be seen in the study of Manderick and Spiessens <ref> [56] </ref> that 4 Another possibility is to give nodes just any color if no other colors are left so that they constrain future nodes in their colors. Important is that this decoder will color deterministically and uses some fixed criterium to decide on the color.
Reference: [57] <author> Z. Michalewicz. </author> <title> Genetic Algorithms + Data structures = Evolution programs. </title> <publisher> Springer-Verlag, </publisher> <address> second edition, </address> <year> 1994. </year>
Reference-contexts: The advantage of half an eye is simply that it's better than seeing nothing and even one lightcell could be an advantage. In [19], Dawkins very clearly and gradually explains how evolution can build up complex organisms with mutation, natural selection and enough time. An example, drawn from <ref> [57] </ref>, should clarify the basic ideas from evolution theory. Let's suppose that somewhere and sometime we have a population of cute, furry, little rabbits. Now some of them will be faster and smarter than other rabbits.
Reference: [58] <author> D. Mitchell, B. Selman, and H.J. Levesque. </author> <title> Hard and easy distributions of SAT problems. </title> <booktitle> In Proceedings of the AAAI, </booktitle> <pages> pages 459-465, </pages> <address> San Jose, CA, </address> <year> 1992. </year>
Reference-contexts: This generator can force formulas to be satisfiable which should be harder to solve than those generated by mwff.c. With it, 3-CNF instances are created that have n variables, l clauses and seed s 2 , notated as S n;l;s . Mitchell et al. <ref> [58] </ref> report that the phase transition is found when l = 4:3 n.
Reference: [59] <author> H. Muhlenbein. </author> <title> How genetic algorithms really work: </title> <editor> I. mutation and hillclimbing. In R. Manner and B. Manderick, editors, </editor> <booktitle> Parellel Problem Solving from Nature - 2, </booktitle> <pages> pages 15-25, </pages> <address> Amsterdam, 1992. </address> <publisher> Elsevier. </publisher>
Reference-contexts: For this EA, a slightly more disruptive mutation operator could be better. At the moment p m = 1 L (with L the number of genes in an individual). In the literature it is suggested that this is a reasonable value in general <ref> [59] </ref>. Later the effect of the mutation rate will be examined further (see section 6.5). A fast implementation is obtained (see section 3.11) by using the probability distribution of the number of genes that will be mutated with p m = 1 L . <p> This is based on some theory by Muhlenbein for the counting one problem <ref> [59] </ref> which showed p m = 1 L (which gives an expectation of one mutated gene for each mutated child), was optimal for that problem. This value also gave good results for a variety of NP-hard combinatorial problems [4][51][52].
Reference: [60] <author> B. Nudel. </author> <title> Consistent-labeling problems and their algorithms: Expected complexities and theory based heuristics. </title> <journal> Journal of Artificial Intelligence, </journal> <volume> 21 </volume> <pages> 135-178, </pages> <year> 1983. </year>
Reference: [61] <author> I.M. Oliver, D.J. Smith, and J.C.R. Holland. </author> <title> A study of permutation crossover operators on the travelling salesman problem. </title> <booktitle> In Proceedings of the second International Conference on Genetic Algorithms, </booktitle> <pages> pages 224-230, </pages> <year> 1987. </year>
Reference-contexts: As we use probability 1 2 to select genes, these two operators are exactly the same. 17 Cycle Crossover Cycle Crossover (CX), developed by Oliver et al. <ref> [61] </ref>, preserves the absolute position of elements in the parent sequence. A randomly chosen cycle starting point is selected. The element at the cycle starting point in the first parent is inherited by the first child.
Reference: [62] <author> Anne L. Olsen. </author> <title> Penalty functions and the knapsack problem. </title> <booktitle> In Proceedings of the first IEEE Conference on Evolutionary Computation, </booktitle> <pages> pages 554-558, </pages> <year> 1994. </year>
Reference: [63] <author> B. Kenefsky P. Cheeseman and W. M. Taylor. </author> <title> Where the really hard problems are. </title> <booktitle> In Proceedings of the International Joint Conference on Artifical Intelligence, </booktitle> <pages> pages 331-337, </pages> <year> 1991. </year>
Reference-contexts: Turner found that many k-colorable graphs are easy to color [75]. Because any algorithm can color them easily, comparisons between algorithms based on these graphs are not very meaningful and we should look for harder problem instances that pose some challenges for candidate algorithms to overcome. Cheeseman et al. <ref> [63] </ref> 2 found that NP-complete problems have an "order" parameter and that the hard problems occur at a critical value of this parameter, called the phase transition. This phase transition will be at the point where the problem changes from underconstrained to overconstrained.
Reference: [64] <author> R. Reiter and A. Mackworth. </author> <title> A logical framework for depiction and image interpre-tation. </title> <journal> Artificial Intelligence, </journal> <volume> 41(3) </volume> <pages> 123-155, </pages> <year> 1989. </year>
Reference-contexts: In the common notation, a formula has l clauses and n variables. SAT was the first computational task shown to be NP-hard by Cook [12], but is also of practical interest as it has applications in for example reasoning, diagnosis, planning [49] and image interpretation <ref> [64] </ref>. Originally SAT was formulated as a decision problem, but here the variant is used where we ask for an actual solution.
Reference: [65] <author> Jon T. Richardson, Mark R. Palmer, Gunar Liepins, and Mike Hilliard. </author> <title> Some guidelines for genetic algorithms with penalty functions. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the third International Conference on Genetic Algorithms, </booktitle> <pages> pages 191-197. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference: [66] <editor> J.D. Schaffer, R.A. Caruna, L.J. Eshelman, and R. </editor> <title> Das. A study of control parameters affecting online performance of genetic algorithms for function optimization. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the third International Conference on Genetic Algorithms, </booktitle> <pages> pages 51-60. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Biologists even see mutation as the main source for evolutionary change. In [16] several good results of "nave evolution" (as it is called in <ref> [66] </ref>) are reported. Eiben et al. [24] compared several asexual operators for the Graph 3-Coloring problem with a version that used uniform crossover, a standard mutation and fixed to 200 for n = 50.
Reference: [67] <author> H.-P. Schwefel. </author> <title> Evolution and Optimum Seeking. </title> <booktitle> Sixth-Generation Computer Technology Series. </booktitle> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: This is called extinctive selection, because the current population will be extinct in the next generation. This also models lower organisms which reproduce once and only live for one generation. We will use the notation from Evolution Strategies (ES) <ref> [67] </ref> where denotes the size of the population and the size of the offspring population (i.e. the number of children created in the current generation). Preservative selection is notated as ( + )-strategy where the + symbolizes that the new population is obtained from both current and offspring population. <p> Table 6.10 shows that without doubt we can conclude that again = 1 is optimal both for n = 200 and n = 1000, so that for an asexual (serial) EA a minimal population is most efficient. Just like for the asexual EA, in Evolution Strategies (ES) <ref> [67] </ref> mutation is the main operator, the representation is real-valued and deterministic selection is used, where in a (pure) GA, crossover is the main operator, the representation is binary-valued and probabilistic selection is used.
Reference: [68] <author> Bart Selman and Henry Kautz. </author> <title> Domain-independent extensions to GSAT: Solving large structured satisfiability problems. </title> <booktitle> In Proceedings of IJCAI, </booktitle> <year> 1993. </year>
Reference-contexts: But both are better than a version that broke ties (unfairly) by always selecting the first individual in the population. 95 than GSAT. 7.3.2 WGSAT In <ref> [68] </ref>, Selman and Kautz describe a modification in which GSAT associates a weight with each clause. The weights of all clauses that remain unsatisfied at the end of a try are incremented.
Reference: [69] <author> Bart Selman, Hector Levesque, and David Mitchell. </author> <title> A new method for solving hard satisfiability problems. </title> <booktitle> In Proceedings of the 10th National Conference on Artificial Intelligence, </booktitle> <pages> pages 440-446, </pages> <year> 1992. </year>
Reference-contexts: To overcome this, an incomplete algorithm, GSAT, was proposed by Selman et al. <ref> [69] </ref>.
Reference: [70] <author> T. Starkweather, S. McDaniel, K. Mathias, D. Whitley, and C. Whiley. </author> <title> A comparison of genetic sequencing operators. </title> <editor> In R.K. Belew and L.B. Booker, editors, </editor> <booktitle> Proceedings of the fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 69-76. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: In <ref> [70] </ref> the most important order-based operators are described and compared and it shows that for scheduling-like problems order crossover #2 (OX2) by Syswerda [72] is the best operator.
Reference: [71] <author> G. Syswerda. </author> <title> Uniform crossover in genetic algorithms. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the third Internation Conference on Genetic Algorithms, </booktitle> <pages> pages 2-9. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Uniform Crossover A further generalization of m-point crossover, is uniform crossover <ref> [71] </ref>, that uses the extreme number of crossover points so that all genes separately can be crossed over. Further each gene has a probability of being crossed over, which will be fixed to 0.5 in this research. <p> For problems where the distance between the 13 position of two genes does not say anything about the relationship between them, this can be an advantage. For other problems uniform crossover was inferior to 2-point crossover <ref> [71] </ref>. So for each gene position we have to draw a random number to decide if it will be crossed over. Because drawing random numbers is quite costly, an optimization will be done which is possible because the probability was fixed to 0.5.
Reference: [72] <author> G. Syswerda. </author> <title> Schedule optimization using genetic algorithms. </title> <editor> In L. Davis, editor, </editor> <booktitle> Handbook of Genetic Algorithms, chapter 21, </booktitle> <pages> pages 332-349. </pages> <publisher> Van Nostrand Reinhold, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: In [70] the most important order-based operators are described and compared and it shows that for scheduling-like problems order crossover #2 (OX2) by Syswerda <ref> [72] </ref> is the best operator. This can also be seen in the study of Manderick and Spiessens [56] that 4 Another possibility is to give nodes just any color if no other colors are left so that they constrain future nodes in their colors.
Reference: [73] <author> Gilbert Syswerda. </author> <title> A study of reproduction in generational and steady-state genetic algorithms. </title> <booktitle> In Foundations of Genetic Algorithms - 1, </booktitle> <pages> pages 94-101, </pages> <year> 1992. </year>
Reference-contexts: Syswerda <ref> [73] </ref> suggests random deletion, exponential ranking, reverse fitness and worst fitness deletion. Random deletion could be implemented to run in O (1) time but gives worse results than the others. Syswerda found worst fitness deletion and exponentional ranking the best, with exponential ranking just somewhat better than worst fitness deletion.
Reference: [74] <author> E. Tsang and T. Warwick. </author> <title> Applying genetic algorithms to constraint satisfaction optimization problems. In L.C. </title> <editor> Aiello, editor, </editor> <booktitle> Proceedings of ECAI-90, </booktitle> <pages> pages 649-654. </pages> <publisher> Pitman Publishing, </publisher> <year> 1990. </year>
Reference-contexts: be NP-complete and because it is a direct instance of a more general class of problems: random Constraint Satisfaction Problems (CSPs), that have n variables, a number of possible values per variable and a set of binary constraints on pairs of variables, meaning variables are supposed to have different values <ref> [74] </ref>. Graph Coloring restricts each of the variables to have the same domain values and the results that are found in this research might be applicable to other CSPs as well. To reduce the space of possible problem instances we restrict ourselves to Graph 3-Coloring.
Reference: [75] <author> Jonathan S. Turner. </author> <title> Almost all k-colorable graphs are easy to color. </title> <journal> Journal of Algorithms, </journal> <volume> 9 </volume> <pages> 63-82, </pages> <year> 1988. </year> <month> 124 </month>
Reference-contexts: Turner found that many k-colorable graphs are easy to color <ref> [75] </ref>. Because any algorithm can color them easily, comparisons between algorithms based on these graphs are not very meaningful and we should look for harder problem instances that pose some challenges for candidate algorithms to overcome. <p> Because of the random tie breaking, DSatur becomes a stochastic algorithm and just like the EA, we need to do several runs to obtain useful statistics. The datastructure of Turner <ref> [75] </ref> who proposed heaps to dynamically keep the nodes ordered by saturation degree has been implemented 3 . Because we want to do fair comparison between the EA and DSatur, we have to allow DSatur to continue for a number of search steps.
Reference: [76] <author> D. De Werra. </author> <title> An introduction to timetabling. </title> <journal> European Journal of Operations Re--search, </journal> <volume> 19 </volume> <pages> 151-162, </pages> <year> 1985. </year>
Reference-contexts: Still there are many applications like register allocation [10], timetabling <ref> [76] </ref>, scheduling and printed circuit testing [34] and although no good polynomial algorithm exists for general graphs, an algorithm can still exist which has good expected performance for a specific class of graphs.
Reference: [77] <author> Darrell Whitley. </author> <title> The GENITOR algorithm and selective pressure: Why rank-based allocation of reproductive trials is best. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the third International Conference on Genetic Algorithms, </booktitle> <pages> pages 116-121. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: In a traditional GA the fitness of an individual is used as an absolute value to create a probability distribution for selecting individuals. As Whitley noticed in <ref> [77] </ref>, ranking avoids some problems of fitness proportionate selection. The value returned by an evaluation function is often only an approximation to the distance to the global optimum.
References-found: 77

