URL: http://www.ai.mit.edu/~edelman/mirror/pnas-91.ps.Z
Refering-URL: http://www.ai.mit.edu/~edelman/archive.html
Root-URL: 
Title: Psychophysical support for a 2D view interpolation theory of object recognition  
Author: Heinrich H. Bulthoff and Shimon Edelman and 
Keyword: object representation, regularization networks, computer graphics psychophysics  
Note: To whom reprint requests should be addressed.  
Address: Providence, Rhode Island 02912, USA  Rehovot 76100, Israel  
Affiliation: Dept. of Cognitive and Linguistic Sciences Brown University  Dept. of Applied Mathematics and Computer Science The Weizmann Institute of Science  
Abstract-found: 0
Intro-found: 0
Reference: [1] <author> S. Ullman. </author> <title> Aligning pictorial descriptions: an approach to object recognition. </title> <journal> Cognition, </journal> <volume> 32 </volume> <pages> 193-254, </pages> <year> 1989. </year>
Reference: [2] <author> S. Ullman and R. Basri. </author> <title> Recognition by linear combinations of models. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1152, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1990. </year>
Reference-contexts: A polyhedral object that can undergo a general linear transformation requires three views if separate linear bases are used to represent the x and the y coordinates of a new view; two views suffice if a mixed x; y basis is used <ref> [2, 9] </ref>.
Reference: [3] <author> T. Poggio and S. Edelman. </author> <title> A network that learns to recognize threedimensional objects. </title> <journal> Nature, </journal> <volume> 343 </volume> <pages> 263-266, </pages> <year> 1990. </year>
Reference-contexts: Another approach that represents objects by sets of 2D views is view approximation by regularization networks <ref> [3, 11] </ref>, which includes as a special case approximation by radial basis functions (RBFs) [12, 13]. <p> We remark that the bias in favor of the horizontal plane is ecologically justified, since it is probably more useful to generalize recognition to a side view than to the top or the bottom views. Similar results were generated by a recognition model based on view approximation <ref> [3, 17] </ref> in a simulated experiment which used the same views of the same wire stimuli shown to the human subjects (Figure 4b). <p> The relative per <p>- 8 formance under the inter, extra and ortho conditions, as well as the hor-izontal/vertical asymmetry, were replicated by making the weights w x of the horizontal components of the input to prototype distance <ref> [11, 3] </ref> smaller by a factor of about 3 than the weights w y of the vertical components (Figure 5b; in equations 1 through 3 this would correspond to the use of a weighted norm kX X k k 2 W = (X X k ) T W T W (X
Reference: [4] <author> D. G. Lowe. </author> <title> Perceptual organization and visual recognition. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1986. </year>
Reference-contexts: Such a claim, however, ignores the likelihood of implementation-dictated deviations from linearity, the numerical instability of extrapolation as opposed to interpolation [10], and the possible availability of other routes to recognition, based, e.g., on certain distinctive and relatively viewpoint-invariant features such as parallel or co-terminating segments <ref> [4] </ref>. It should be noted that allowing for these factors would render the linear combination scheme rather similar to view approximation, and would make the distinction between the two, based on the present data, difficult.
Reference: [5] <author> D. W. Thompson and J. L. Mundy. </author> <title> Three-dimensional model matching from an unconstrained viewpoint. </title> <booktitle> In Proceedings of IEEE Conference on Robotics and Automation, </booktitle> <pages> pages 208-220, </pages> <address> Raleigh, NC, </address> <year> 1987. </year>
Reference: [6] <author> D. Marr and H. K. Nishihara. </author> <title> Representation and recognition of the spatial organization of three dimensional structure. </title> <journal> Proceedings of the Royal Society of London B, </journal> <volume> 200 </volume> <pages> 269-294, </pages> <year> 1978. </year>
Reference: [7] <author> I. Biederman. </author> <title> Human image understanding: Recent research and a theory. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 32 </volume> <pages> 29-73, </pages> <year> 1985. </year>
Reference: [8] <author> E. Rosch, C. B. Mervis, W. D. Gray, D. M. Johnson, and P. Boyes-Braem. </author> <title> Basic objects in natural categories. </title> <journal> Cognitive Psychology, </journal> <volume> 8 </volume> <pages> 382-439, </pages> <year> 1976. </year>
Reference-contexts: 1 Numerous studies in cognitive science (see <ref> [8] </ref> for a review) reveal that in the hierarchical structure of object categories there exists a certain level, called basic level, which is the most salient according to a variety of criteria (such as the ease and preference of access).
Reference: [9] <author> S. Edelman and T. Poggio. </author> <title> Bringing the Grandmother back into the picture: a memory-based view of object recognition. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1181, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1990. </year> <month> 12 </month>
Reference-contexts: A polyhedral object that can undergo a general linear transformation requires three views if separate linear bases are used to represent the x and the y coordinates of a new view; two views suffice if a mixed x; y basis is used <ref> [2, 9] </ref>. <p> The approximation can be performed by a two-stage network (see <ref> [9] </ref> for details). In the first stage intermediate responses are formed by a collection of nonlinear "receptive fields" (shaped, e.g., as multidimensional Gaussians), centered at the 5 familiar views. The output of the second stage is a linear combination of the intermediate receptive field responses.
Reference: [10] <author> S. Ullman and R. Basri. </author> <title> Recognition by linear combinations of models. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <note> 1991. in press. </note>
Reference-contexts: The recognition criterion under one possible version of the linear combination approach <ref> [10] </ref> can be formulated schematically as k i (2D) where the stored views X (2D) i comprise the linear vector basis that represents an object model (i.e., spans the space of the object's views), X (2D) is the input image, and ff i are the coefficients estimated for the given model/image <p> Specifically, recognition by linear combination should be near perfect both for the inter and the extra conditions, and poor for all the views in the ortho plane. Such a claim, however, ignores the likelihood of implementation-dictated deviations from linearity, the numerical instability of extrapolation as opposed to interpolation <ref> [10] </ref>, and the possible availability of other routes to recognition, based, e.g., on certain distinctive and relatively viewpoint-invariant features such as parallel or co-terminating segments [4].
Reference: [11] <author> T. Poggio and F. Girosi. </author> <title> Regularization algorithms for learning that are equivalent to multilayer networks. </title> <journal> Science, </journal> <volume> 247 </volume> <pages> 978-982, </pages> <year> 1990. </year>
Reference-contexts: Another approach that represents objects by sets of 2D views is view approximation by regularization networks <ref> [3, 11] </ref>, which includes as a special case approximation by radial basis functions (RBFs) [12, 13]. <p> The relative per <p>- 8 formance under the inter, extra and ortho conditions, as well as the hor-izontal/vertical asymmetry, were replicated by making the weights w x of the horizontal components of the input to prototype distance <ref> [11, 3] </ref> smaller by a factor of about 3 than the weights w y of the vertical components (Figure 5b; in equations 1 through 3 this would correspond to the use of a weighted norm kX X k k 2 W = (X X k ) T W T W (X <p> This difference in weights is equivalent to having a larger tolerance to viewpoint shifts in the horizontal than in the vertical direction and can be learned automatically <ref> [11] </ref>. The predictions of the linear combination approach outlined in the introduction appear at the first glance to be incompatible with the experimental results.
Reference: [12] <author> D. S. Broomhead and D. Lowe. </author> <title> Multivariable functional interpolation and adaptive networks. </title> <journal> Complex Systems, </journal> <volume> 2 </volume> <pages> 321-355, </pages> <year> 1988. </year>
Reference-contexts: Another approach that represents objects by sets of 2D views is view approximation by regularization networks [3, 11], which includes as a special case approximation by radial basis functions (RBFs) <ref> [12, 13] </ref>. In this approach, generalization from familiar to novel views is regarded as a problem of approximating a smooth hypersurface in the space of all possible views, with the "height" of the surface known only at a sparse set of points corresponding to the familiar views.
Reference: [13] <author> J. Moody and C. Darken. </author> <title> Fast learning in networks of locally tuned process-ing units. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 281-289, </pages> <year> 1989. </year>
Reference-contexts: Another approach that represents objects by sets of 2D views is view approximation by regularization networks [3, 11], which includes as a special case approximation by radial basis functions (RBFs) <ref> [12, 13] </ref>. In this approach, generalization from familiar to novel views is regarded as a problem of approximating a smooth hypersurface in the space of all possible views, with the "height" of the surface known only at a sparse set of points corresponding to the familiar views.
Reference: [14] <author> S. Edelman and D. Weinshall. </author> <title> A self-organizing multiple-view representation of 3D objects. </title> <journal> Biological Cybernetics, </journal> <volume> 64 </volume> <pages> 209-219, </pages> <year> 1991. </year>
Reference-contexts: A recognition system based on this method is expected to perform well when the novel view is close to the stored ones (that is, when most of the features of the input image fall close to their counterparts at least in some of the stored views; cf. <ref> [14] </ref>). The performance should become progressively worse on views that are far from the familiar ones. Methods To distinguish between the theories outlined above, we have developed an experimental paradigm based on a two-alternative forced-choice (2AFC) task. Our experiments consist of two phases: training and testing.
Reference: [15] <author> I. Rock and J. DiVita. </author> <title> A case of viewer-centered object perception. </title> <journal> Cognitive Psychology, </journal> <volume> 19 </volume> <pages> 280-293, </pages> <year> 1987. </year>
Reference-contexts: Both pairwise and pooled comparisons of the mean error rates in the three conditions revealed significant differences, with the inter error rate being the lowest and the ortho the highest (see Figure 3; cf. <ref> [15, 16] </ref>). A subsequent experiment established this finding for a different set of wire objects, for each of which the three principal second moments of inertia agreed to within 10% (balanced objects; see Figure 4a).
Reference: [16] <author> I. Rock, D. Wheeler, and L. Tudor. </author> <title> Can we imagine how objects look from other viewpoints? Cognitive Psychology, </title> <booktitle> 21 </booktitle> <pages> 185-210, </pages> <year> 1989. </year>
Reference-contexts: Both pairwise and pooled comparisons of the mean error rates in the three conditions revealed significant differences, with the inter error rate being the lowest and the ortho the highest (see Figure 3; cf. <ref> [15, 16] </ref>). A subsequent experiment established this finding for a different set of wire objects, for each of which the three principal second moments of inertia agreed to within 10% (balanced objects; see Figure 4a).
Reference: [17] <author> S. Edelman, D. Weinshall, H. Bulthoff, and T. Poggio. </author> <title> A model of the acquisition of object representations in human 3D visual recognition. </title> <editor> In P. Dario, G. Sandini, and P. Aebischer, editors, </editor> <booktitle> Proc. NATO Advanced Research Workshop on Robots and Biological Systems. </booktitle> <publisher> Springer Verlag, </publisher> <year> 1990. </year>
Reference-contexts: We remark that the bias in favor of the horizontal plane is ecologically justified, since it is probably more useful to generalize recognition to a side view than to the top or the bottom views. Similar results were generated by a recognition model based on view approximation <ref> [3, 17] </ref> in a simulated experiment which used the same views of the same wire stimuli shown to the human subjects (Figure 4b).
Reference: [18] <author> S. Edelman and H. H. Bulthoff. </author> <title> Generalization of object recognition in human vision across stimulus transformations and deformations. </title> <editor> In Y. Feldman and A. Bruckstein, editors, </editor> <booktitle> Proc. 7th Israeli AICV Conference, </booktitle> <pages> pages 479-487. </pages> <publisher> Elsevier, </publisher> <year> 1990. </year> <month> 13 </month>
Reference-contexts: The two approaches can be distinguished experimentally, by comparing generalization to novel views obtained, on one hand, by rigid rotation of the object, and, on the other hand, by nonrigid deformation <ref> [18] </ref>. Discussion The performance pattern of our subjects in recognizing novel views seems incompatible with predictions of alignment and other theories that employ 3D 9 representations.
Reference: [19] <author> S. Edelman and H. H. Bulthoff. </author> <title> Viewpoint-specific representations in 3D object recognition. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1239, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1990. </year>
Reference-contexts: It is possible that the subjects could not form the 3D repre-sentations required by the alignment theory given the motion information in the training stage. However, a different study <ref> [19] </ref> in which the training views were shown in motion and stereo yielded similar poor recognition of radically novel views. Thus, even when given every opportunity to form 3D representations, the subjects performed as if they had not done so.
Reference: [20] <author> J. J. Koenderink and A. J. van Doorn. </author> <title> The internal representation of solid shape with respect to vision. </title> <journal> Biological Cybernetics, </journal> <volume> 32 </volume> <pages> 211-217, </pages> <year> 1979. </year>
Reference-contexts: This type of object is well-suited for studying the basics of recognition, because it allows one to isolate "pure" 3D shape processing from other factors such as self-occlusion (and the associated aspect structure <ref> [20] </ref>) and large- area surface phenomena. Although this restriction necessarily limits the scope of our conclusions, an ongoing series of experiments that involve spheroidal amoeba- like objects has confirmed our earlier main finding | anisotropic generalization to novel views | that counters the predictions of theories based on 3D representations.

References-found: 20

