URL: ftp://ftp.cs.columbia.edu/reports/reports-1992/cucs-052-92.ps.gz
Refering-URL: http://www.cs.columbia.edu/~library/1992.html
Root-URL: http://www.cs.columbia.edu
Title: Saving Comparisons in the Crochemore-Perrin String Matching Algorithm (preliminary version) modified algorithm takes linear time,
Author: Dany Breslauer 
Note: Given any fixed &gt; 0, the  and makes at most n b 1+* 2 (n m)c comparisons. If O(log m) space is available, then the algorithm makes at most n b 1  
Address: CUCS-052-92  
Affiliation: CWI  
Abstract: Crochemore and Perrin discovered an elegant linear-time constant-space string matching algorithm that makes at most 2n m symbol comparison. This paper shows how to modify their algorithm to use fewer comparisons. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. V. Aho. </author> <title> Algorithms for finding pattern in strings. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, </booktitle> <pages> pages 257-300. </pages> <publisher> Elsevier Science Publishers B. V., </publisher> <address> Amsterdam, the Netherlands, </address> <year> 1990. </year> <month> 13 </month>
Reference-contexts: We assume that the only access an algorithm has to the input strings is by pairwise symbol comparisons that result in equal or unequal answers. Several algorithms solve the string matching problem in linear time. For a survey on string matching algorithm see Aho's paper <ref> [1] </ref>. Most known perhaps is the algorithm of Knuth, Morris and Pratt [20] that makes 2n m comparisons in the worst case.
Reference: [2] <author> A. Apostolico and R. Giancarlo. </author> <title> The Boyer-Moore-Galil string searching strategies revisited. </title> <journal> SIAM J. Comput., </journal> <volume> 15(1) </volume> <pages> 98-105, </pages> <year> 1986. </year>
Reference-contexts: For a survey on string matching algorithm see Aho's paper [1]. Most known perhaps is the algorithm of Knuth, Morris and Pratt [20] that makes 2n m comparisons in the worst case. A variant of the Boyer-Moore [4] algorithm that was designed by Apostolico and Giancarlo <ref> [2] </ref> also makes 2n fl Partially supported by the IBM Graduate Fellowship while studying at Columbia University and by the European Research Consorium for Informatics and Mathematics postdoctoral fellowship.
Reference: [3] <author> A. B. Borodin, M. J. Fischer, D. G. Kirkpatrick, N. A. Lynch, and M. Tompa. </author> <title> A time-space tradeoff for sorting on non-oblivious machines. </title> <booktitle> In Proc. 20th IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 294-301, </pages> <year> 1979. </year>
Reference-contexts: All the algorithm mentioned above use O (m) auxiliary space. At a certain time the string matching problem was conjectured to have a time-space tradeoff <ref> [3, 16] </ref>. This conjecture was later disproved when a linear-time constant-space algorithm was discovered by Galil and Seiferas [17]. Their algorithm can even be implemented on a six-head two-way finite automaton in linear time. <p> The term space in this model refers to the number of auxiliary data registers used. Namely, a constant-space algorithm can use only a constant number of auxiliary registers. This notion of space is different from the one used in <ref> [3] </ref> since a constant-space algorithm in our model has a logarithmic capacity. Crochemore and Perrin [11] discovered a simple linear-time constant-space string matching algorithm that makes at most 2n m comparisons. The Galil-Seiferas algorithm uses more comparisons.
Reference: [4] <author> R. S. Boyer and J. S. Moore. </author> <title> A fast string searching algorithm. </title> <journal> Comm. of the ACM, </journal> <volume> 20 </volume> <pages> 762-772, </pages> <year> 1977. </year>
Reference-contexts: Several algorithms solve the string matching problem in linear time. For a survey on string matching algorithm see Aho's paper [1]. Most known perhaps is the algorithm of Knuth, Morris and Pratt [20] that makes 2n m comparisons in the worst case. A variant of the Boyer-Moore <ref> [4] </ref> algorithm that was designed by Apostolico and Giancarlo [2] also makes 2n fl Partially supported by the IBM Graduate Fellowship while studying at Columbia University and by the European Research Consorium for Informatics and Mathematics postdoctoral fellowship.
Reference: [5] <author> D. Breslauer and Z. Galil. </author> <title> Efficient Comparison Based String Matching. </title> <type> Technical Report CUCS-054-92, </type> <institution> Computer Science Dept., Columbia University, </institution> <year> 1992. </year>
Reference-contexts: Research on the exact number of comparisons required to solve the string matching problem has been stimulated by Colussi's [9] discovery of an algorithm that makes at most n + 1 2 (n m) comparisons. This bound was improved by Galil and Giancarlo [14], Breslauer and Galil <ref> [5] </ref> and most recently by Cole and Hariharan [8] who show that the string matching problem can be solved using at most n + 8 3 (n m) comparisons 1 . <p> The number of comparisons made is obviously linear (the constant is not very large). 2 8 Open Problems There are several open problems about the exact comparison complexity of string matching and of related string problems. Many of the problems listed in Breslauer and Galil's paper <ref> [5] </ref> can also be asked in this context. Two problems which are related to this work are: 1. What is the exact number of comparisons required by a constant-space string matching algorithm? Is there a space vs. comparisons tradeoff for this problem? 2.
Reference: [6] <author> Y. Cesari and M. Vincent. </author> <title> Une caracterisation des mots periodiques. </title> <type> C.R. </type> <institution> Acad. Sci. Paris, 286(A):1175-1177, </institution> <year> 1978. </year>
Reference-contexts: The following theorem states that critical factorizations always exist. It is the basis for the Crochemore-Perrin string matching algorithm. Theorem 2.7 (The Critical Factorization Theorem, Cesari and Vincent <ref> [6, 23] </ref>) Let S 1 be the period length of a string S [1::k].
Reference: [7] <author> R. Cole. </author> <title> Tight bounds on the complexity of the Boyer-Moore pattern matching algorithm. </title> <booktitle> In Proc. 2nd ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 224-233, </pages> <year> 1991. </year>
Reference-contexts: Part of the work was done while this author was visiting at Universita de L'Aquila, L'Aquila, Italy in summer 1991. 1 m comparisons. The original Boyer-Moore algorithm makes about 3n comparisons as shown recently by Cole <ref> [7] </ref>. All these algorithms work in two steps: in the first step the pattern is preprocessed and some information is stored and used later in a text processing step.
Reference: [8] <author> R. Cole and R. Hariharan. </author> <title> Tighter Bounds on The Exact Complexity of String Matching. </title> <booktitle> In Proc. 33rd IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 600-609, </pages> <year> 1992. </year>
Reference-contexts: This bound was improved by Galil and Giancarlo [14], Breslauer and Galil [5] and most recently by Cole and Hariharan <ref> [8] </ref> who show that the string matching problem can be solved using at most n + 8 3 (n m) comparisons 1 . Lower bounds given by Galil and Giancarlo [13], Zwick and Paterson [24], and Cole and Hariharan [8] still leave a small gap between the lower and upper bounds. <p> Breslauer and Galil [5] and most recently by Cole and Hariharan <ref> [8] </ref> who show that the string matching problem can be solved using at most n + 8 3 (n m) comparisons 1 . Lower bounds given by Galil and Giancarlo [13], Zwick and Paterson [24], and Cole and Hariharan [8] still leave a small gap between the lower and upper bounds. All the algorithm mentioned above use O (m) auxiliary space. At a certain time the string matching problem was conjectured to have a time-space tradeoff [3, 16].
Reference: [9] <author> L. Colussi. </author> <title> Correctness and efficiency of string matching algorithms. </title> <journal> Inform. and Control, </journal> <volume> 95 </volume> <pages> 225-251, </pages> <year> 1991. </year>
Reference-contexts: Our bounds do not account for comparisons that are performed in the pattern preprocessing step that can compare even all pairs of pattern symbols for free. Research on the exact number of comparisons required to solve the string matching problem has been stimulated by Colussi's <ref> [9] </ref> discovery of an algorithm that makes at most n + 1 2 (n m) comparisons. <p> This bound is the same as the bound given by Galil and Giancarlo [14] for Colussi's <ref> [9] </ref> algorithm. Our analysis is much simpler. 2. The periodicity structure of the pattern that is used in the modified algorithm can be stored in log m memory registers. Thus, the algorithm can be implemented using O (log m) auxiliary memory registers. 3.
Reference: [10] <author> M. Crochemore. </author> <title> String-matching on ordered alphabets. </title> <journal> Theoret. Comput. Sci., </journal> <volume> 92 </volume> <pages> 33-47, </pages> <year> 1992. </year>
Reference-contexts: Crochemore and Perrin [11] discovered a simple linear-time constant-space string matching algorithm that makes at most 2n m comparisons. The Galil-Seiferas algorithm uses more comparisons. Crochemore and Rytter [12] show how to reduce the number of comparisons made by the Galil-Seiferas algorithm by a better choice of parameters. Crochemore <ref> [10] </ref> gives another constant-space string matching algorithm. The comparison bounds achieved by Crochemore and Rytter [12] and by Crochemore [10] are larger than 2n m. This paper focuses on the number of comparisons required by constant-space string matching algorithms. <p> The Galil-Seiferas algorithm uses more comparisons. Crochemore and Rytter [12] show how to reduce the number of comparisons made by the Galil-Seiferas algorithm by a better choice of parameters. Crochemore <ref> [10] </ref> gives another constant-space string matching algorithm. The comparison bounds achieved by Crochemore and Rytter [12] and by Crochemore [10] are larger than 2n m. This paper focuses on the number of comparisons required by constant-space string matching algorithms.
Reference: [11] <author> M. Crochemore and D. Perrin. </author> <title> Two-way string-matching. </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 38(3) </volume> <pages> 651-675, </pages> <year> 1991. </year>
Reference-contexts: Namely, a constant-space algorithm can use only a constant number of auxiliary registers. This notion of space is different from the one used in [3] since a constant-space algorithm in our model has a logarithmic capacity. Crochemore and Perrin <ref> [11] </ref> discovered a simple linear-time constant-space string matching algorithm that makes at most 2n m comparisons. The Galil-Seiferas algorithm uses more comparisons. Crochemore and Rytter [12] show how to reduce the number of comparisons made by the Galil-Seiferas algorithm by a better choice of parameters. <p> Note that in some cases the local period can overflow to either side; this happens when the local period is longer than either of the two fac tors. The factorization (b) is a critical factorization. 3 The Crochemore-Perrin Algorithm Crochemore and Perrin <ref> [11] </ref> used the Critical Factorization Theorem to obtain a simple and elegant linear-time constant-space string matching algorithm. The pattern preprocessing step of their algorithm also takes linear time and uses constant space. It is discussed is Section 7. <p> Only then, after this suffix was discovered in the text, the algorithm tries to match the pattern prefix P [1::] that was skipped. Lemma 3.1 (Crochemore and Perrin <ref> [11] </ref>) Let (P [1::]; P [ + 1::m]) be a critical factorization of the pattern and let min (; m ) be the length of a local period of this factorization. Then is a multiple of P 1 . Theorem 3.2 (Crochemore and Perrin [11]) There exist a constant-space linear-time string <p> Lemma 3.1 (Crochemore and Perrin <ref> [11] </ref>) Let (P [1::]; P [ + 1::m]) be a critical factorization of the pattern and let min (; m ) be the length of a local period of this factorization. Then is a multiple of P 1 . Theorem 3.2 (Crochemore and Perrin [11]) There exist a constant-space linear-time string matching algorithm that makes at most 2n m comparisons. Proof: The Crochemore-Perrin algorithm is given is Figure 2. We prove it correctness and show that is makes at most 2n m symbol comparisons.
Reference: [12] <author> M. Crochemore and W. Rytter. </author> <title> Periodic prefixes in texts. </title> <booktitle> In Proc. of Sequences '91. </booktitle> <year> 1991. </year> <note> To appear. </note>
Reference-contexts: Crochemore and Perrin [11] discovered a simple linear-time constant-space string matching algorithm that makes at most 2n m comparisons. The Galil-Seiferas algorithm uses more comparisons. Crochemore and Rytter <ref> [12] </ref> show how to reduce the number of comparisons made by the Galil-Seiferas algorithm by a better choice of parameters. Crochemore [10] gives another constant-space string matching algorithm. The comparison bounds achieved by Crochemore and Rytter [12] and by Crochemore [10] are larger than 2n m. <p> The Galil-Seiferas algorithm uses more comparisons. Crochemore and Rytter <ref> [12] </ref> show how to reduce the number of comparisons made by the Galil-Seiferas algorithm by a better choice of parameters. Crochemore [10] gives another constant-space string matching algorithm. The comparison bounds achieved by Crochemore and Rytter [12] and by Crochemore [10] are larger than 2n m. This paper focuses on the number of comparisons required by constant-space string matching algorithms. <p> Proof: The preprocessing consists of two parts: 1. A critical factorization of the pattern is computed by Crochemore and Perrin's pattern preprocessing algorithm. This computation requires the use of order comparisons. 2. Galil and Seiferas [17] and Crochemore and Rytter <ref> [12] </ref> show that their linear-time constant-space algorithms can find all overhanging occurrences of the pattern in the text and therefore find all period lengths of the pattern. These algorithms find the period lengths in an increasing order as required in Theorem 5.1.
Reference: [13] <author> Z. Galil and R. Giancarlo. </author> <title> On the exact complexity of string matching: lower bounds. </title> <journal> SIAM J. Comput., </journal> <volume> 20(6) </volume> <pages> 1008-1020, </pages> <year> 1991. </year>
Reference-contexts: Lower bounds given by Galil and Giancarlo <ref> [13] </ref>, Zwick and Paterson [24], and Cole and Hariharan [8] still leave a small gap between the lower and upper bounds. All the algorithm mentioned above use O (m) auxiliary space. At a certain time the string matching problem was conjectured to have a time-space tradeoff [3, 16].
Reference: [14] <author> Z. Galil and R. Giancarlo. </author> <title> The exact complexity of string matching: upper bounds. </title> <journal> SIAM J. Comput., </journal> <volume> 21(3) </volume> <pages> 407-437, </pages> <year> 1992. </year>
Reference-contexts: Research on the exact number of comparisons required to solve the string matching problem has been stimulated by Colussi's [9] discovery of an algorithm that makes at most n + 1 2 (n m) comparisons. This bound was improved by Galil and Giancarlo <ref> [14] </ref>, Breslauer and Galil [5] and most recently by Cole and Hariharan [8] who show that the string matching problem can be solved using at most n + 8 3 (n m) comparisons 1 . <p> This bound is the same as the bound given by Galil and Giancarlo <ref> [14] </ref> for Colussi's [9] algorithm. Our analysis is much simpler. 2. The periodicity structure of the pattern that is used in the modified algorithm can be stored in log m memory registers. Thus, the algorithm can be implemented using O (log m) auxiliary memory registers. 3.
Reference: [15] <author> Z. Galil and J. Seiferas. </author> <title> Saving space in fast string-matching. </title> <journal> SIAM J. Comput., </journal> <volume> 2 </volume> <pages> 417-438, </pages> <year> 1980. </year>
Reference-contexts: Corollary 5.2 All periods of a string S [1::k] can be represented by b2 log kc periods. Remark. The compact representation of periods of a string is not new. Galil and Seiferas <ref> [15] </ref> used similar arguments in a variant of the Knuth-Morris-Pratt string matching algorithm that uses only O (log m) space.
Reference: [16] <author> Z. Galil and J. Seiferas. </author> <title> Linear-time string-matching using only a fixed number of local storage locations. </title> <journal> Theoret. Comput. Sci., </journal> <volume> 13 </volume> <pages> 331-336, </pages> <year> 1981. </year> <month> 14 </month>
Reference-contexts: All the algorithm mentioned above use O (m) auxiliary space. At a certain time the string matching problem was conjectured to have a time-space tradeoff <ref> [3, 16] </ref>. This conjecture was later disproved when a linear-time constant-space algorithm was discovered by Galil and Seiferas [17]. Their algorithm can even be implemented on a six-head two-way finite automaton in linear time.
Reference: [17] <author> Z. Galil and J. Seiferas. </author> <title> Time-space-optimal string matching. </title> <journal> J. Comput. System Sci., </journal> <volume> 26 </volume> <pages> 280-294, </pages> <year> 1983. </year>
Reference-contexts: All the algorithm mentioned above use O (m) auxiliary space. At a certain time the string matching problem was conjectured to have a time-space tradeoff [3, 16]. This conjecture was later disproved when a linear-time constant-space algorithm was discovered by Galil and Seiferas <ref> [17] </ref>. Their algorithm can even be implemented on a six-head two-way finite automaton in linear time. It is still an open problem whether a k-head one-way finite automaton can do string matching (for k 3 the answer is negative [18, 21, 22]). <p> It uses order comparisons to find a critical factorization of the pattern. Proof: The preprocessing consists of two parts: 1. A critical factorization of the pattern is computed by Crochemore and Perrin's pattern preprocessing algorithm. This computation requires the use of order comparisons. 2. Galil and Seiferas <ref> [17] </ref> and Crochemore and Rytter [12] show that their linear-time constant-space algorithms can find all overhanging occurrences of the pattern in the text and therefore find all period lengths of the pattern. These algorithms find the period lengths in an increasing order as required in Theorem 5.1.
Reference: [18] <author> M. Gereb-Graus and M. Li. </author> <title> Three one-way heads cannot do string matching. </title> <type> Manuscript, </type> <year> 1990. </year>
Reference-contexts: Their algorithm can even be implemented on a six-head two-way finite automaton in linear time. It is still an open problem whether a k-head one-way finite automaton can do string matching (for k 3 the answer is negative <ref> [18, 21, 22] </ref>). The computation model used in this paper consists of random-access read-only input registers, random-access write-only output registers and a limited number of auxiliary random-access read-write data registers. The number of bits per data register is bounded by some constant times the logarithm of n + m.
Reference: [19] <author> L. Guibas and A. M. Odlyzko. </author> <title> Periods in strings. </title> <journal> Journal of Combinatorial Theory, Series A, </journal> <volume> 30 </volume> <pages> 19-42, </pages> <year> 1981. </year>
Reference-contexts: Remark. The compact representation of periods of a string is not new. Galil and Seiferas [15] used similar arguments in a variant of the Knuth-Morris-Pratt string matching algorithm that uses only O (log m) space. Guibas and Odlyzko <ref> [19] </ref> characterized all possible periodicity structures of a string of length k and showed that there are fi (k log k ) such structures, independent of the alphabet size.
Reference: [20] <author> D. E. Knuth, J. H. Morris, and V. R. Pratt. </author> <title> Fast pattern matching in strings. </title> <journal> SIAM J. Comput., </journal> <volume> 6 </volume> <pages> 322-350, </pages> <year> 1977. </year>
Reference-contexts: Several algorithms solve the string matching problem in linear time. For a survey on string matching algorithm see Aho's paper [1]. Most known perhaps is the algorithm of Knuth, Morris and Pratt <ref> [20] </ref> that makes 2n m comparisons in the worst case.
Reference: [21] <author> M. Li. </author> <title> Lower bounds on string-matching. </title> <type> Technical Report TR 84-63, </type> <institution> Cornell University, Department of Computer Science, </institution> <year> 1984. </year>
Reference-contexts: Their algorithm can even be implemented on a six-head two-way finite automaton in linear time. It is still an open problem whether a k-head one-way finite automaton can do string matching (for k 3 the answer is negative <ref> [18, 21, 22] </ref>). The computation model used in this paper consists of random-access read-only input registers, random-access write-only output registers and a limited number of auxiliary random-access read-write data registers. The number of bits per data register is bounded by some constant times the logarithm of n + m.
Reference: [22] <author> M. Li and Y. Yesha. </author> <title> String-matching cannot be done by a two-head one-way deterministic finite automaton. </title> <journal> Inform. Process. Lett., </journal> <volume> 22 </volume> <pages> 231-235, </pages> <year> 1986. </year>
Reference-contexts: Their algorithm can even be implemented on a six-head two-way finite automaton in linear time. It is still an open problem whether a k-head one-way finite automaton can do string matching (for k 3 the answer is negative <ref> [18, 21, 22] </ref>). The computation model used in this paper consists of random-access read-only input registers, random-access write-only output registers and a limited number of auxiliary random-access read-write data registers. The number of bits per data register is bounded by some constant times the logarithm of n + m.
Reference: [23] <author> M. </author> <title> Lothaire. Combinatorics on Words. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA., U.S.A., </address> <year> 1983. </year>
Reference-contexts: The following theorem states that critical factorizations always exist. It is the basis for the Crochemore-Perrin string matching algorithm. Theorem 2.7 (The Critical Factorization Theorem, Cesari and Vincent <ref> [6, 23] </ref>) Let S 1 be the period length of a string S [1::k].
Reference: [24] <author> U. Zwick and M. S. Paterson. </author> <title> Lower bounds for string matching in the sequential comparison model. </title> <type> Manuscript, </type> <year> 1991. </year> <month> 15 </month>
Reference-contexts: Lower bounds given by Galil and Giancarlo [13], Zwick and Paterson <ref> [24] </ref>, and Cole and Hariharan [8] still leave a small gap between the lower and upper bounds. All the algorithm mentioned above use O (m) auxiliary space. At a certain time the string matching problem was conjectured to have a time-space tradeoff [3, 16].
References-found: 24

