URL: ftp://ftp.cs.umass.edu/pub/osl/papers/sigir95.ps.Z
Refering-URL: http://www.cs.umass.edu/~brown/
Root-URL: 
Email: brown@cs.umass.edu  
Title: Fast Evaluation of Structured Queries for Information Retrieval  
Author: Eric W. Brown 
Address: Amherst, MA 01003-4610, USA  
Affiliation: Computer Science Department, University of Massachusetts  
Abstract: Information retrieval systems are being challenged to manage larger and larger document collections. In an effort to provide better retrieval performance on large collections, more sophisticated retrieval techniques have been developed that support rich, structured queries. Structured queries are not amenable to previously proposed optimization techniques. Optimizing execution, however, is even more important in the context of large document collections. We present a new structured query optimization technique which we have implemented in an inference network-based information retrieval system. Experimental results show that query evaluation time can be reduced by more than half with little impact on retrieval effectiveness. 
Abstract-found: 1
Intro-found: 1
Reference: [2] <author> E. W. Brown, J. P. Callan, W. B. Croft, and J. E. B. Moss. </author> <title> Supporting full-text information retrieval with a persistent object store. </title> <booktitle> In Proc. of the 4th Inter. Conf. on Extending Database Technology (EDBT), </booktitle> <pages> pages 365-378, </pages> <address> Cambridge, UK, </address> <month> Mar. </month> <year> 1994. </year>
Reference-contexts: Finally, we must be able to distinguish between the different types of lists and handle them accordingly at indexing time, query processing time, and collection modification time. Fortunately, these functionality requirements are easily met in INQUERY. INQUERY's inverted file is managed by the Mneme persistent object store <ref> [14, 2] </ref>. Mneme provides storage and retrieval of objects, where an object is a chunk of contiguous bytes that has been assigned a unique identifier. Mneme does not interpret the contents of objects, but does support inter-object references, allowing the fabrication of complex data structures.
Reference: [3] <author> C. Buckley and A. F. Lewit. </author> <title> Optimization of inverted vector searches. </title> <booktitle> In Proc. of the 8th Inter. ACM SIGIR Conf. on Research and Development in Information Retrieval, </booktitle> <pages> pages 97-110, </pages> <month> June </month> <year> 1985. </year>
Reference-contexts: Perry and Willett [15] show how the upper bound technique can be applied to the same model extended to support incremental document score accumulation. Using a system that returns a full ranking of the document collection, Buckley and Lewit <ref> [3] </ref>, and later Lucarella [11], describe a technique to eliminate processing of entire inverted lists, assuming we are interested in only the top n documents. After processing a given term, the documents can be ranked by their currently accumulated scores, establishing the current set of top n documents.
Reference: [4] <author> J. P. Callan, W. B. Croft, and S. M. Harding. </author> <title> The INQUERY retrieval system. </title> <booktitle> In Proc. of the 3rd Inter. Conf. on Database and Expert Systems Applications, </booktitle> <month> Sept. </month> <year> 1992. </year>
Reference-contexts: In particular, we are interested in statistical models that support structured queries. An example of such a model is the inference network-based information retrieval model [19], as implemented in the INQUERY full-text information retrieval system <ref> [4] </ref>. INQUERY has established itself as a solid performer in terms of retrieval effectiveness [6], or the ability to satisfy a user's information need by identifying the documents fl This work is supported by the National Science Foundation Center for Intelligent Information Retrieval at the University of Massachusetts.
Reference: [5] <author> C. Faloutsos. </author> <title> Access methods for text. </title> <journal> ACM Comput. Surv., </journal> <volume> 17 </volume> <pages> 50-74, </pages> <year> 1985. </year>
Reference-contexts: The details of belief value calculation can be found in the Appendix. The document counts, within document frequencies, and proximity lists for indexed concepts are extracted and stored in an inverted file <ref> [5, 8] </ref> when the document collection is indexed. An inverted file consists of a record, or inverted list, for every indexed concept that appears in the document collection.
Reference: [6] <editor> D. Harman, editor. </editor> <booktitle> The Second Text REtrieval Conference (TREC2), </booktitle> <address> Gaithersburg, MD, </address> <year> 1994. </year> <institution> National Institute of Standards and Technology Special Publication 500-215. </institution>
Reference-contexts: In particular, we are interested in statistical models that support structured queries. An example of such a model is the inference network-based information retrieval model [19], as implemented in the INQUERY full-text information retrieval system [4]. INQUERY has established itself as a solid performer in terms of retrieval effectiveness <ref> [6] </ref>, or the ability to satisfy a user's information need by identifying the documents fl This work is supported by the National Science Foundation Center for Intelligent Information Retrieval at the University of Massachusetts. <p> In all cases we allocated 15 Mbytes of Mneme buffer space to cache memory resident inverted list objects. 5.2 Test Collections For our experiments we used three test collections drawn from the three volume TIPSTER document collection used in the TREC <ref> [6] </ref> evaluations. The TIPSTER document collection consists of articles and abstracts from various periodicals, Department of Energy abstracts, Associated Press articles, Federal Register articles, and U.S. Patent Office reports.
Reference: [7] <author> D. Harman and G. Candela. </author> <title> Retrieving records from a gigabyte of text on a minicomputer using statistical ranking. </title> <journal> J. Amer. Soc. Inf. Sci., </journal> <volume> 41(8) </volume> <pages> 581-589, </pages> <month> Dec. </month> <year> 1990. </year>
Reference-contexts: This work and the work on nearest neighbor models forms the basis of our first rule for candidate set population. There are two variations on the previous scheme, both of which share our goal of constraining the candidate document set. The first variation, proposed by Harman and Candela <ref> [7] </ref>, is called pruning. Rather than place a limit on the number of documents returned to the user, they establish an insertion threshold for placing new documents in the candidate set.
Reference: [8] <author> D. Harman, E. Fox, R. Baeza-Yates, and W. Lee. </author> <title> Inverted files. </title> <editor> In W. B. Frakes and R. Baeza-Yates, editors, </editor> <booktitle> Information Retrieval: Data Structures & Algorithms, chapter 3, </booktitle> <pages> pages 28-43. </pages> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1992. </year>
Reference-contexts: The details of belief value calculation can be found in the Appendix. The document counts, within document frequencies, and proximity lists for indexed concepts are extracted and stored in an inverted file <ref> [5, 8] </ref> when the document collection is indexed. An inverted file consists of a record, or inverted list, for every indexed concept that appears in the document collection.
Reference: [9] <author> Y. Jing and W. B. Croft. </author> <title> An association thesaurus for information retrieval. </title> <booktitle> In Proc. of RIAO 94 Conf., </booktitle> <pages> pages 146-160, </pages> <address> New York, </address> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: The second query set, Query Set 2, was generated from TIPSTER topics 151-200 in a series of steps. First, a base query set was created using automatic methods. Next, each base query was run against a PhraseFinder <ref> [9] </ref> database built from TIPSTER volumes 1 and 2. PhraseFinder returns a set of phrases extracted from the supporting database based on the given query. Thirty new phrases were automatically added to each query, forming an augmented query.
Reference: [10] <author> D. Knaus and P. Schauble. </author> <title> Effective and efficient retrieval from large and dynamic document collections. </title> <booktitle> In Harman [6], </booktitle> <pages> pages 163-170. </pages>
Reference-contexts: By pre-computing our candidate document set, we ensure that this is the case. The process of identifying a candidate document set followed by evaluating the query for just those documents is similar in spirit to the two stage query evaluation strategy of the SPIDER information retrieval system <ref> [17, 10] </ref>. In SPIDER, a signature file is used to identify documents that potentially match the query, and an upper bound is calculated for each document's similarity to the query.
Reference: [11] <author> D. Lucarella. </author> <title> A document retrieval system based on nearest neighbour searching. </title> <journal> J. Inf. Sci., </journal> <volume> 14(1) </volume> <pages> 25-33, </pages> <year> 1988. </year>
Reference-contexts: Perry and Willett [15] show how the upper bound technique can be applied to the same model extended to support incremental document score accumulation. Using a system that returns a full ranking of the document collection, Buckley and Lewit [3], and later Lucarella <ref> [11] </ref>, describe a technique to eliminate processing of entire inverted lists, assuming we are interested in only the top n documents. After processing a given term, the documents can be ranked by their currently accumulated scores, establishing the current set of top n documents.
Reference: [12] <author> A. Moffat and J. Zobel. </author> <title> Fast ranking in limited space. </title> <booktitle> In Proc. 10th IEEE Inter. Conf. on Data Engineering, </booktitle> <pages> pages 428-437, </pages> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: The second 2 factor is the size of the set of documents that must be evaluated, or the candidate document set. This set may be quite large. Moffat and Zobel <ref> [12] </ref> found that for queries containing around 40 terms, using the terms' inverted lists to populate the candidate document set caused nearly 75% of the documents in the collection to be placed in the candidate document set. <p> First, at low recall, precision actually improves somewhat and then falls off. This indicates that the technique is doing a good job of identifying the very best candidate documents, and is consistent with other results using similar techniques <ref> [16, 12] </ref>. Second, at high recall, precision becomes significantly worse as the optimization becomes more aggressive. <p> Then, after the insertion threshold is reached, a conjunctive phase occurs where terms are not allowed to add new documents, only update the scores of existing documents. The second variation was proposed by Moffat and Zobel <ref> [12] </ref>. Rather than use an insertion threshold related to a term's potential score contribution, a hard limit is placed on the size of the candidate document set. The disjunctive phase proceeds until the candidate set is full.
Reference: [13] <author> A. Moffat and J. Zobel. </author> <title> Self-indexing inverted files for fast text retrieval. </title> <type> Technical Report 94/2, </type> <institution> Collaborative Information Technology Research Institute, Department of Computer Science, Royal Melbourne Institute of Technology, Australia, </institution> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: Moreover, if we are no longer processing every document that appears in the inverted lists, we may be able to skip portions of inverted lists <ref> [13] </ref>. If the skipped portions are large enough and our inverted list implementation provides the necessary functionality, the overall number of disk I/Os might be reduced.
Reference: [14] <author> J. E. B. Moss. </author> <title> Design of the Mneme persistent object store. </title> <journal> ACM Trans. Inf. Syst., </journal> <volume> 8(2) </volume> <pages> 103-139, </pages> <month> Apr. </month> <year> 1990. </year>
Reference-contexts: Finally, we must be able to distinguish between the different types of lists and handle them accordingly at indexing time, query processing time, and collection modification time. Fortunately, these functionality requirements are easily met in INQUERY. INQUERY's inverted file is managed by the Mneme persistent object store <ref> [14, 2] </ref>. Mneme provides storage and retrieval of objects, where an object is a chunk of contiguous bytes that has been assigned a unique identifier. Mneme does not interpret the contents of objects, but does support inter-object references, allowing the fabrication of complex data structures.
Reference: [15] <author> S. A. Perry and P. Willett. </author> <title> A review of the use of inverted files for best match searching in information retrieval systems. </title> <institution> J. Inf. Sci., 6(2-3):59-66, </institution> <year> 1983. </year>
Reference-contexts: They describe how an upper bound on the similarity of any unseen document can be calculated based on the unprocessed query terms. If this upper bound is less than the similarity of the current best document, processing may stop. Perry and Willett <ref> [15] </ref> show how the upper bound technique can be applied to the same model extended to support incremental document score accumulation.
Reference: [16] <author> M. Persin. </author> <title> Document filtering for fast ranking. </title> <booktitle> In Proc. of the 17th Inter. ACM SIGIR Conf. on Research and Development in Information Retrieval, </booktitle> <pages> pages 339-348, </pages> <address> Dublin, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: First, at low recall, precision actually improves somewhat and then falls off. This indicates that the technique is doing a good job of identifying the very best candidate documents, and is consistent with other results using similar techniques <ref> [16, 12] </ref>. Second, at high recall, precision becomes significantly worse as the optimization becomes more aggressive. <p> Persin <ref> [16] </ref> uses thresholds to determine how a tf idf weight is processed. If the document for the current weight is not in the candidate document set, an insertion threshold is used to determine if the weight justifies adding the document to the candidate set.
Reference: [17] <author> P. Schauble. SPIDER: </author> <title> A multiuser information retrieval system for semistructured and dynamic data. </title> <booktitle> In Proc. of the 16th Inter. ACM SIGIR Conf. on Research and Development in Information Retrieval, </booktitle> <pages> pages 318-327, </pages> <address> Pittsburgh, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: By pre-computing our candidate document set, we ensure that this is the case. The process of identifying a candidate document set followed by evaluating the query for just those documents is similar in spirit to the two stage query evaluation strategy of the SPIDER information retrieval system <ref> [17, 10] </ref>. In SPIDER, a signature file is used to identify documents that potentially match the query, and an upper bound is calculated for each document's similarity to the query.
Reference: [18] <author> A. F. Smeaton and C. J. van Rijsbergen. </author> <title> The nearest neighbour problem in information retrieval. An algorithm using upperbounds. </title> <booktitle> In Proc. of the 4th Inter. ACM SIGIR Conf. on Research and Development in Information Retrieval, </booktitle> <pages> pages 83-87, </pages> <address> Oakland, CA, </address> <year> 1981. </year>
Reference-contexts: This suggests that our retrieval performance could even be improved. 6 Related Work Some of the earliest optimization work in information retrieval was carried out by Smeaton and van Rijsbergen <ref> [18] </ref> in the context of a nearest neighbor retrieval model. They describe how an upper bound on the similarity of any unseen document can be calculated based on the unprocessed query terms. If this upper bound is less than the similarity of the current best document, processing may stop.
Reference: [19] <author> H. R. Turtle and W. B. Croft. </author> <title> Evaluation of an inference network-based retrieval model. </title> <journal> ACM Trans. Inf. Syst., </journal> <volume> 9(3) </volume> <pages> 187-222, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: The goal of our work here is to reduce the cost of evaluating queries in sophisticated retrieval systems. In particular, we are interested in statistical models that support structured queries. An example of such a model is the inference network-based information retrieval model <ref> [19] </ref>, as implemented in the INQUERY full-text information retrieval system [4]. <p> Belief operators describe how to combine these belief values to produce the final belief score. 1 This definition of concept is a slight departure from the formal definition in the inference network <ref> [19] </ref>. The distinction between indexed and constructed concepts is introduced here to facilitate discussion from an implementation perspective. 1 Belief operators operate on belief values and return belief values. The belief operators include and, or, not, sum, weighted sum, and maximum.
Reference: [20] <author> W. Y. P. Wong and D. L. Lee. </author> <title> Implementations of partial document ranking using inverted files. </title> <journal> Inf. Process. & Mgmnt., </journal> <volume> 29(5) </volume> <pages> 647-669, </pages> <year> 1993. </year>
Reference-contexts: They do not, however, incorporate a clear version of our second rule based on tf weight. The previous techniques use inverted lists sorted by document id. Other techniques sort inverted lists by tf weight. Wong and Lee <ref> [20] </ref> partition their inverted lists into pages and process the pages in order of upper bound contribution to document score. They describe a number of estimation techniques for determining 6 Table 5: Precision at standard recall points for Tip1, Query Set 1.
Reference: [21] <author> G. K. Zipf. </author> <title> Human Behavior and the Principle of Least Effort. </title> <publisher> Addison-Wesley Press, </publisher> <year> 1949. </year> <month> 9 </month>
Reference-contexts: However, query evaluation is document driven and requires that the inverted lists be sorted by document identifier. Instead, if n is defined to be relatively small, we can maintain a separate list of the documents associated with the top n tf weights for each long inverted list. Zipf's Law <ref> [21] </ref> suggests that there will be relatively few long inverted lists, but they will consume the majority of the space in the inverted file.
References-found: 20

