URL: http://www.isr.umd.edu/Labs/CACSE/FSQP/oms.ps
Refering-URL: http://www.isr.umd.edu/Labs/CACSE/FSQP/fsqp.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Nonlinear Equality Constraints in Feasible Sequential Quadratic Programming  
Author: Craig T. Lawrence and Andre L. Tits 
Keyword: KEY WORDS: Constrained optimization, nonlinear equality constraints, sequential quadratic programming, feasibility  
Date: Received January, 1995 Revised manuscript received August, 1995  
Address: College Park College Park, MD 20742  
Affiliation: Institute for Systems Research and Electrical Engineering Department University of Maryland,  
Note: Optimization Methods and Software 6 (1996), pp. 265-282. c fl1996 OPA (Overseas Publishers Association) Amsterdam B.V.  
Abstract: A simple scheme is proposed for handling nonlinear equality constraints in the context of a previously introduced sequential quadratic programming (SQP) algorithm for inequality constrained problems, generating iterates satisfying the constraints. The key is an idea due to Mayne and Polak (Math. Progr., vol. 11, pp. 67-80, 1976) by which nonlinear equality constraints are treated as ""-type constraints to be satisfied by all iterates, thus precluding any positive value, and an exact penalty term is added to the objective function, thus penalizing negative values. Mayne and Polak obtain a suitable value of the penalty parameter by iterative adjustments based on a test involving estimates of the KKT multipliers. We argue that the SQP framework allows for a more effective estimation of these multipliers, and we provide convergence analysis of the resulting algorithm. Numerical results, obtained with the cfsqp code, are reported. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J. F. Bonnans, E. R. Panier, A. L. Tits, and J. L. Zhou. </author> <title> Avoiding the Maratos effect by means of a nonmonotone line search II. Inequality constrained problems feasible iterates. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 29(4) </volume> <pages> 1187-1202, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: In the case when m e = 0, a recently proposed "feasible" sequential quadratic programming (FSQP) algorithm [9] efficiently solves such problems while forcing all iterates to remain feasible (i.e., to satisfy all constraints). Advantages of feasible iterates are discussed in <ref> [1, 9] </ref>. <p> The corrected direction d is formed as a convex combination of d 0 and d 1 , i.e. d = (1 )d 0 + d 1 where = (d 0 ) 2 <ref> [0; 1] </ref>. To preserve the quasi-Newton character of the iteration, d must be chosen close to d 0 . Accordingly, following [9], () : IR n ! [0; 1] is defined in such a way that (d 0 ) = O (kd 0 k 2 ): (4) Finally, even close to <p> combination of d 0 and d 1 , i.e. d = (1 )d 0 + d 1 where = (d 0 ) 2 <ref> [0; 1] </ref>. To preserve the quasi-Newton character of the iteration, d must be chosen close to d 0 . Accordingly, following [9], () : IR n ! [0; 1] is defined in such a way that (d 0 ) = O (kd 0 k 2 ): (4) Finally, even close to a solution, x + d may violate the feasibility and descent requirements.
Reference: 2. <author> J. W. Daniel. </author> <title> Stability of the solution of definite quadratic programs. </title> <journal> Math. Programming, </journal> <volume> 5 </volume> <pages> 41-53, </pages> <year> 1973. </year>
Reference-contexts: Then d 0 k ! d 0 Proof. In view of Assumptions 1 and 2, the feasible set for QP (x; c; H) has a nonempty interior for all x 2 ~ and all H. We may directly apply a result of J. W. Daniel <ref> [2] </ref> to conclude that the mapping (x; H) 7! d 0 (x; c; H) is continuous at (x fl ; H fl ). Thus, we have d 0 k ! d 0 fl .
Reference: 3. <author> J. Herskovits. </author> <title> A two-stage feasible directions algorithm for nonlinear constrained optimization. </title> <journal> Math. Programming, </journal> <volume> 36 </volume> <pages> 19-38, </pages> <year> 1986. </year>
Reference-contexts: While equality constraints can easily be handled by means of a standard quadratic penalty function, the feasible iterate framework makes it possible to use a more satisfactory scheme proposed by Mayne and Polak in the context of first order methods of feasible directions [8] (and later used by Herskovits in <ref> [3] </ref> and by Schonefeld in [11]). Their scheme considers the related family of inequality constrained problems min m e X f j (x) g j (x) 0; j = 1; : : : ; m i ; where c &gt; 0.
Reference: 4. <author> W. Hock and K. Schittkowski. </author> <title> Test Examples For Nonlinear Programming Codes, </title> <booktitle> Lecture Notes in Economics and Mathematical Systems No. </booktitle> <volume> 187. </volume> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1981. </year>
Reference-contexts: Table 1 lists the results obtained on test problems taken from <ref> [4] </ref> and [10]. For purposes of comparison, also listed are the results obtained when the test problems were run using VF02AD from the Harwell subroutine library [6], modified so that the stopping criterion was the same as that in cfsqp (see below). <p> All computations were performed on a Sun 4/SPARCstation IPC in double precision and the gradients were computed analytically. In Table 1, # indicates the problem number as listed in <ref> [4, 10] </ref> and the second column (A) indicates the algorithm used to solve the problem (C for Algorithm 1 as implemented in cfsqp and V for VF02AD). n and m i are as defined in Section 1, while m e is the number of nonlinear equality constraints.
Reference: 5. <author> C. T. Lawrence, J. L. Zhou, and A. L. </author> <title> Tits. User's Guide for CFSQP Version 2.4: A C Code for Solving (Large Scale) Constrained Nonlinear (Minimax) Optimization Problems, Generating Iterates Satisfying All Inequality Constraints, 1996. </title> <institution> ISR TR-94-16r1, Institute for Systems Research, University of Maryland (College Park, MD). </institution>
Reference-contexts: Then fx k g k2IN converges to x fl two-step superlinearly. 14 C. T. Lawrence and A. L. Tits 4 IMPLEMENTATION AND NUMERICAL RESULTS Algorithm 1 has been implemented in fsqp (fsqp includes two packages: ffsqp is a Fortran implementation, while cfsqp is a C implementation, see <ref> [12, 5] </ref>). Version 2.3 of cfsqp was used for our tests.
Reference: 6. <author> Harwell Subroutine Library. </author> <title> Library Reference Manual. </title> <address> Harwell, England, </address> <year> 1985. </year>
Reference-contexts: Table 1 lists the results obtained on test problems taken from [4] and [10]. For purposes of comparison, also listed are the results obtained when the test problems were run using VF02AD from the Harwell subroutine library <ref> [6] </ref>, modified so that the stopping criterion was the same as that in cfsqp (see below). All computations were performed on a Sun 4/SPARCstation IPC in double precision and the gradients were computed analytically.
Reference: 7. <author> N. Maratos. </author> <title> Exact Penalty Functions for Finite Dimensional and Control Optimization Problems. </title> <type> PhD thesis, </type> <institution> Imperial College of Science and Technology, </institution> <year> 1978. </year>
Reference-contexts: Thus, in order to avoid such Maratos effect <ref> [7] </ref> (and guarantee local superlinear convergence), a correction ~ d = ~ d (x; c; d; H) is computed.
Reference: 8. <author> D. Q. Mayne and E. Polak. </author> <title> Feasible direction algorithms for optimization problems with equality and inequality constraints. </title> <journal> Math. Programming, </journal> <volume> 11 </volume> <pages> 67-80, </pages> <year> 1976. </year>
Reference-contexts: While equality constraints can easily be handled by means of a standard quadratic penalty function, the feasible iterate framework makes it possible to use a more satisfactory scheme proposed by Mayne and Polak in the context of first order methods of feasible directions <ref> [8] </ref> (and later used by Herskovits in [3] and by Schonefeld in [11]). Their scheme considers the related family of inequality constrained problems min m e X f j (x) g j (x) 0; j = 1; : : : ; m i ; where c &gt; 0. <p> In <ref> [8] </ref>, Mayne and Polak show that convergence to Karush-Kuhn-Tucker (KKT) points for the original problem is guaranteed when the penalty parameter is updated in such a way that it is eventually larger than the largest magnitude of an equality constraint KKT multiplier at the solution. <p> satisfying r c (x fl ) + j=1 m i X ~ fl;j rg j (x fl ) = 0; g j (x fl ) 0; ~ fl;j g j (x fl ) = 0; j = 1; : : : ; m i : The following proposition, found in <ref> [8] </ref>, is crucial to our development. We include a proof here for ease of reference. Proposition 2.1. If x fl 2 is a KKT point for ( ~ P c ), then x fl is a KKT point for (P ). Proof. <p> Namely, in order to guarantee that c k remains bounded, it is necessary to add to the test in Step 3 (iii) for increasing the penalty parameter a condition that was not needed in <ref> [8] </ref>. Without the additional condition, it may happen that the updated c k leads to large multipliers k in QP (x k ; c k ; H k ), in turn forcing another increase of c k .
Reference: 9. <author> E. R. Panier and A. L. </author> <title> Tits. On combining feasibility, descent and superlinear convergence in inequality constrained optimization. </title> <journal> Math. Programming, </journal> <volume> 59 </volume> <pages> 261-276, </pages> <year> 1993. </year>
Reference-contexts: Tits Consider the problem min s.t. f j (x) = 0; j = 1; : : : ; m e ; (P ) where f j : IR n n continuously differentiable. In the case when m e = 0, a recently proposed "feasible" sequential quadratic programming (FSQP) algorithm <ref> [9] </ref> efficiently solves such problems while forcing all iterates to remain feasible (i.e., to satisfy all constraints). Advantages of feasible iterates are discussed in [1, 9]. <p> In the case when m e = 0, a recently proposed "feasible" sequential quadratic programming (FSQP) algorithm [9] efficiently solves such problems while forcing all iterates to remain feasible (i.e., to satisfy all constraints). Advantages of feasible iterates are discussed in <ref> [1, 9] </ref>. <p> Of course, if * 0 is small enough, the correct active set will eventually be identified, but progress may be slow in early iterations. Fortunately, as discussed below, more satisfactory alternatives are available in the context of second-order feasible direction methods, such as the algorithm proposed in <ref> [9] </ref>. In SQP-type methods, a candidate search direction d 0 is obtained as the solution of a quadratic program approximating (to second order) the original nonlinear program around the current iterate. <p> This also eliminates the need for * 0 , and further, the size of the least squares problem is reduced. In this paper we investigate incorporating the Mayne and Polak scheme, modified along the lines of this second alternative, into the algorithm of <ref> [9] </ref>. The balance of this paper is organized as follows. In Section 2 we present the algorithm (a few of the details are deferred to Section 4 in order to avoid any loss of continuity). Section 3 is devoted to establishing convergence. <p> Algorithm 1 below is an extension of the algorithm given in <ref> [9] </ref>. As suggested in Section 1, consider solving the problem ( ~ P c ) for a fixed c &gt; 0. <p> In order to construct a new iterate in such a way that local superlinear convergence is guaranteed, and feasibility for the modified problem is maintained, the algorithm proposed in <ref> [9] </ref> performs a search along an arc defined by three direction vectors. The first direction is the standard SQP direction, which we call d 0 = d 0 (x; c; H), and is defined as the solution of QP (x; c; H). <p> T. Lawrence and A. L. Tits direction d 1 = d 1 (x; c; d 0 ). In <ref> [9] </ref>, d 1 (; ; ) is selected to be a continuous map such that d 1 (x; c; 0) is zero if x is a KKT point for ( ~ P c ) and is a strictly feasible descent direction if x is not a KKT point (see [9]). <p> In <ref> [9] </ref>, d 1 (; ; ) is selected to be a continuous map such that d 1 (x; c; 0) is zero if x is a KKT point for ( ~ P c ) and is a strictly feasible descent direction if x is not a KKT point (see [9]). The corrected direction d is formed as a convex combination of d 0 and d 1 , i.e. d = (1 )d 0 + d 1 where = (d 0 ) 2 [0; 1]. <p> To preserve the quasi-Newton character of the iteration, d must be chosen close to d 0 . Accordingly, following <ref> [9] </ref>, () : IR n ! [0; 1] is defined in such a way that (d 0 ) = O (kd 0 k 2 ): (4) Finally, even close to a solution, x + d may violate the feasibility and descent requirements. <p> It is chosen so that close to a solution x + d + ~ d is feasible, c (x + d + ~ d ) &lt; c (x), and d + ~ d converges to d (again, see <ref> [9] </ref>). An Armijo-type search is then performed along the arc x + td + t 2 ~ d for t 2 (0; 1]. <p> conditions for QP (x k ; c k ; H k ) that Assumption 2 would be violated (see Lemma 3.4 below). 3 CONVERGENCE ANALYSIS If c k is not updated, i.e. if it is kept fixed at a constant value c, then Algorithm 1 reduces to the algorithm in <ref> [9] </ref> applied to the problem ( ~ P c ). So that we may invoke convergence results from [9], we make an additional assumption. Assumption 3. <p> (see Lemma 3.4 below). 3 CONVERGENCE ANALYSIS If c k is not updated, i.e. if it is kept fixed at a constant value c, then Algorithm 1 reduces to the algorithm in <ref> [9] </ref> applied to the problem ( ~ P c ). So that we may invoke convergence results from [9], we make an additional assumption. Assumption 3. <p> k2IN generated by Algorithm 1 is bounded, then there exists constants 2 1 &gt; 0 such that, for all k 2 IN, 1 kxk 2 hx; H k xi 2 kxk 2 8x 2 IR n : The following result now follows directly from Propositions 3.1, 3.2, and 3.3 of <ref> [9] </ref>. Proposition 3.1. Algorithm 1 is well-defined (i.e. Step 2 is well-defined). <p> The following proposition is essentially a restatement of Proposition 3.4 in <ref> [9] </ref>. Proposition 3.7. If some accumulation point x fl of the sequence fx k g k2IN generated by Algorithm 1 satisfies the second order sufficiency conditions with strict complementary slackness, and the sequence is bounded, then the entire sequence converges to x fl . <p> Finally, define the projection matrices P k = I R k (R T k : Assumption 4. kP k (H k r 2 kd k k where d k is the direction vector computed in Step 1 (iii). The following result is a direct consequence of Theorem 3.7 in <ref> [9] </ref>. Theorem 3.8. Suppose that the sequence fx k g k2IN generated by Algorithm 1 converges to a point x fl where the second order sufficiency conditions of optimality, with strict complementary slackness, hold. Then fx k g k2IN converges to x fl two-step superlinearly. 14 C. T. <p> Version 2.3 of cfsqp was used for our tests. In fsqp, the strictly feasible descent direction d 1 = d 1 (x; c; d 0 ) is computed as the solution of the QP (inspired by the suggestions in <ref> [9] </ref>): min s.t. hr c (x); d 1 i fl; g j (x) + hrg j (x); d 1 i fl; j = 1; : : : ; m i ; where = 0:1. <p> Finally, the correction ~ d = ~ d (x; c; d; H) is computed as the solution of the QP (again, inspired by <ref> [9] </ref>): min 1 s.t. f j (x + d) + hrf j (x); ~ di minf0:01kdk; kdk t g; j = 1; : : : ; m e ; g j (x + d) + hrg j (x); ~ di minf0:01kdk; kdk t g; j = 1; : : : ;
Reference: 10. <author> K. Schittkowski. </author> <title> More Test Examples For Nonlinear Programming Codes, </title> <booktitle> Lecture Notes in Economics and Mathematical Systems No. </booktitle> <volume> 282. </volume> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1987. </year>
Reference-contexts: Table 1 lists the results obtained on test problems taken from [4] and <ref> [10] </ref>. For purposes of comparison, also listed are the results obtained when the test problems were run using VF02AD from the Harwell subroutine library [6], modified so that the stopping criterion was the same as that in cfsqp (see below). <p> All computations were performed on a Sun 4/SPARCstation IPC in double precision and the gradients were computed analytically. In Table 1, # indicates the problem number as listed in <ref> [4, 10] </ref> and the second column (A) indicates the algorithm used to solve the problem (C for Algorithm 1 as implemented in cfsqp and V for VF02AD). n and m i are as defined in Section 1, while m e is the number of nonlinear equality constraints.
Reference: 11. <author> K. Schonefeld. </author> <title> A note on a globalization of Wilson-type optimization methods. </title> <journal> Computing, </journal> <volume> 37 </volume> <pages> 171-178, </pages> <year> 1986. </year>
Reference-contexts: be handled by means of a standard quadratic penalty function, the feasible iterate framework makes it possible to use a more satisfactory scheme proposed by Mayne and Polak in the context of first order methods of feasible directions [8] (and later used by Herskovits in [3] and by Schonefeld in <ref> [11] </ref>). Their scheme considers the related family of inequality constrained problems min m e X f j (x) g j (x) 0; j = 1; : : : ; m i ; where c &gt; 0.

References-found: 11

