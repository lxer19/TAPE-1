URL: http://www.cs.umass.edu/~papka/sig97.ps.gz
Refering-URL: http://www.cs.umass.edu/~papka/
Root-URL: 
Email: papka@cs.umass.edu, allan@cs.umass.edu  
Title: Why Bigger Windows Are Better Than Smaller Ones  
Author: Ron Papka and James Allan 
Address: Amherst, MA 01003  
Affiliation: Department of Computer Science University of Massachusetts  
Abstract: We investigate the use of multi-term query concepts to improve the performance of text-retrieval systems that accept "natural-language" queries. A relevance feedback process is explained that massively expands an initial query with single and multi-term concepts. The multi-term concepts are modelled as a set of words appearing within windows of varying sizes. Experimental results suggest that windows of larger size yield improvements in average precision. The reason for this improvement is explored. A window size relaxation process that yields a significant reduction in expanded query size with no performance loss is also described.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Buckley, G. Salton, J. Allan, </author> " <title> The Effect of Adding Relevance Information in a Relevance Feedback Environment," </title> <booktitle> Proceedings of SIGIR 1993, </booktitle> <pages> pp. 49-58. </pages>
Reference-contexts: Otherwise, the belief of the #BAND assumes the default belief of 0:4 number of concepts . 4 Query Expansion Process The query expansion processes used for this work is similar to those described in <ref> [1, 11, 2, 3] </ref> which exhibit good performance in routing environments [1, 13] using a two step methodology of concept 3 selection and weight assignment. 4.1 Concept selection Our methodology for selecting expansion concepts begins with collecting the union of the terms appearing in documents judged to be relevant. <p> Otherwise, the belief of the #BAND assumes the default belief of 0:4 number of concepts . 4 Query Expansion Process The query expansion processes used for this work is similar to those described in [1, 11, 2, 3] which exhibit good performance in routing environments <ref> [1, 13] </ref> using a two step methodology of concept 3 selection and weight assignment. 4.1 Concept selection Our methodology for selecting expansion concepts begins with collecting the union of the terms appearing in documents judged to be relevant. <p> Recent research [7, 11, 2] indicates that iterative techniques can be used to improve these weights. 5 Experiments Experiments were conducted on 50 natural-language information requests used for the routing track for TREC-4 <ref> [1] </ref>. The information requests were stopped and stemmed to produce an initial query, and subsequently expanded in several ways using the retrieval and expansion processes described above. 5.1 Data The 50 queries used were the topics developed for the routing track at Text Retrieval Conferences (TREC)[13]. <p> To our surprise, the reason bigger windows are better is related to the reason the query expansion process works well in the relevance feedback environment described above. 6.1 Expansion Process An experiment studying the effects of the expansion process confirms the findings by Buckley et al <ref> [1] </ref>: adding query concepts that appear in the set of judged relevant documents gives rise to performance improvements in the test set. Furthermore, their results generalize to multi-term proximity concepts. Table 2 shows the performance improvements in the test set realized by the successive iterations of query expansion.
Reference: [2] <author> D. Lewis, R. Schapire, J. Callan, and R. Papka, </author> <title> "Training Algorithms for Linear Text Classifiers", </title> <booktitle> Proceedings of SIGIR 1996, </booktitle> <pages> pp. 298-306. </pages>
Reference-contexts: such that for class R, eval (q; d; c) ! d 2 R, and eval (q; d; c) &lt; ! d 2 R, so that R is the set of documents from the collection that are classified as relevant to the query, and R is the set classified as non-relevant <ref> [2, 3] </ref>. The document representation for the expansion process described below is a set of belief values corresponding to each concept specified in a query. <p> Otherwise, the belief of the #BAND assumes the default belief of 0:4 number of concepts . 4 Query Expansion Process The query expansion processes used for this work is similar to those described in <ref> [1, 11, 2, 3] </ref> which exhibit good performance in routing environments [1, 13] using a two step methodology of concept 3 selection and weight assignment. 4.1 Concept selection Our methodology for selecting expansion concepts begins with collecting the union of the terms appearing in documents judged to be relevant. <p> The 4 weight assigned to a concept added to an expanded query is 8 fl tf rel 2 fl tf nonrel , where tf rel is the average tf component of the concept in relevant documents, and tf nonrel is the average tf component in non-relevant documents. Recent research <ref> [7, 11, 2] </ref> indicates that iterative techniques can be used to improve these weights. 5 Experiments Experiments were conducted on 50 natural-language information requests used for the routing track for TREC-4 [1].
Reference: [3] <author> R. Papka, J. Callan, and A. Barto, </author> <title> "Text-Based Information Retrieval using EG", </title> <booktitle> Proceedings of Neural Information Processing Systems Conference, </booktitle> <year> 1996. </year> <month> Forthcoming. </month>
Reference-contexts: such that for class R, eval (q; d; c) ! d 2 R, and eval (q; d; c) &lt; ! d 2 R, so that R is the set of documents from the collection that are classified as relevant to the query, and R is the set classified as non-relevant <ref> [2, 3] </ref>. The document representation for the expansion process described below is a set of belief values corresponding to each concept specified in a query. <p> Otherwise, the belief of the #BAND assumes the default belief of 0:4 number of concepts . 4 Query Expansion Process The query expansion processes used for this work is similar to those described in <ref> [1, 11, 2, 3] </ref> which exhibit good performance in routing environments [1, 13] using a two step methodology of concept 3 selection and weight assignment. 4.1 Concept selection Our methodology for selecting expansion concepts begins with collecting the union of the terms appearing in documents judged to be relevant.
Reference: [4] <author> D. Hawking, and P. Thistlewaite, </author> <title> "Proximity Operators So Near And Yet So Far", </title> <booktitle> Proceedings of TREC-4 (1995), </booktitle> <pages> pp. 131-144. </pages>
Reference-contexts: 1 Introduction The general intuition about multi-term concepts is that "the closer a set of intersecting terms, the more likely they are to indicate relevance" <ref> [4, 5] </ref>. Our experiments indicate that, contrary to intuition, in the context of relevance feedback, performance gains are obtained by using query concepts that are modelled as pairs of terms that appear further separated within natural language text.
Reference: [5] <author> C. Clarke and G. Cormak, </author> <title> "Interactive Substring Retrieval: MultiText Experiments for TREC-5", </title> <booktitle> Proceedings of TREC-5 (1996). </booktitle> <publisher> Forthcoming. </publisher>
Reference-contexts: 1 Introduction The general intuition about multi-term concepts is that "the closer a set of intersecting terms, the more likely they are to indicate relevance" <ref> [4, 5] </ref>. Our experiments indicate that, contrary to intuition, in the context of relevance feedback, performance gains are obtained by using query concepts that are modelled as pairs of terms that appear further separated within natural language text.
Reference: [6] <author> J. Allan, </author> <title> "Relevance Feedback With Too Much Data," </title> <booktitle> Proceedings of SIGIR 1995, </booktitle> <pages> pp. 337-343. 9 </pages>
Reference-contexts: A window of size 20 would represent a concept appearing within adjacent sentences, a window of size 50 can be thought of as a paragraph, and one of size 250 can be thought of as a "passage" <ref> [6] </ref>. The #BAND (boolean AND) operator is the generalization of the unordered window operator to the entire document.
Reference: [7] <author> C. Buckley and G. Salton, </author> <title> "Optimization of Relevance Feedback Weights", </title> <booktitle> Proceedings of SIGIR 1995, </booktitle> <pages> pp. 351-357. </pages>
Reference-contexts: Unfortunately, early results suggest that query-specific tailoring of these numbers may not be effective.[16, 17] 4.2 Weight Assignment A step popular in relevance feedback methodology is to assign query term weights based on a closed-form function originally developed by Rocchio [9], and has been improved upon in <ref> [10, 7, 11] </ref>. The 4 weight assigned to a concept added to an expanded query is 8 fl tf rel 2 fl tf nonrel , where tf rel is the average tf component of the concept in relevant documents, and tf nonrel is the average tf component in non-relevant documents. <p> The 4 weight assigned to a concept added to an expanded query is 8 fl tf rel 2 fl tf nonrel , where tf rel is the average tf component of the concept in relevant documents, and tf nonrel is the average tf component in non-relevant documents. Recent research <ref> [7, 11, 2] </ref> indicates that iterative techniques can be used to improve these weights. 5 Experiments Experiments were conducted on 50 natural-language information requests used for the routing track for TREC-4 [1]. <p> In general, 30% of unique pairs of terms appeared as duplicates in the top 50 concepts selected for more than one window size. Table 4 shows the breakdown of the overlap between window sizes. Learning new weights using the Dynamic Feedback Optimization technique <ref> [7, 11] </ref> showed a slight tendency to increase the weights of smaller windows, but even after the weights were adjusted, the bigger window received the higher weight 70% of the time.
Reference: [8] <author> J. P. Callan, W.B. Croft, </author> <title> and S.M. Harding, "The INQUERY Retrieval System", Database and Expert Systems Applications: </title> <booktitle> Proceedings of the International Conference in Valencia Spain. A.M. </booktitle> <editor> Tjoa and I. Ramos eds., </editor> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: INQUERY <ref> [8, 11] </ref>, for example, accepts queries containing ordered and unordered window operators. This functionality allows the user to specify an information request more precisely by imposing a locality constraint on groups of words. Proximity can assist in discriminating between relevant and non-relevant documents.
Reference: [9] <author> J.J. Rocchio, </author> <title> "Relevance Feedback in Information Retrieval in The Smart System - Experiments in Automatic document processing", </title> <journal> pp. </journal> <pages> 313-323. </pages> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall Inc., </publisher> <year> 1971. </year>
Reference-contexts: Unfortunately, early results suggest that query-specific tailoring of these numbers may not be effective.[16, 17] 4.2 Weight Assignment A step popular in relevance feedback methodology is to assign query term weights based on a closed-form function originally developed by Rocchio <ref> [9] </ref>, and has been improved upon in [10, 7, 11].
Reference: [10] <author> G. Salton, and C. Buckley, </author> <title> "Improving Retrieval Performance by Relevance Feedback", </title> <journal> Journal of The American Society For Information Science 41(4), </journal> <year> 1990. </year>
Reference-contexts: Unfortunately, early results suggest that query-specific tailoring of these numbers may not be effective.[16, 17] 4.2 Weight Assignment A step popular in relevance feedback methodology is to assign query term weights based on a closed-form function originally developed by Rocchio [9], and has been improved upon in <ref> [10, 7, 11] </ref>. The 4 weight assigned to a concept added to an expanded query is 8 fl tf rel 2 fl tf nonrel , where tf rel is the average tf component of the concept in relevant documents, and tf nonrel is the average tf component in non-relevant documents.
Reference: [11] <author> J. Allan, L. Ballesteros, J. Callan, W.B. Croft, and Z. Lu, </author> <title> "Recent Experiments with Inquery", </title> <booktitle> Proceedings of TREC-4 (1995), </booktitle> <pages> pp. 49-64. </pages>
Reference-contexts: INQUERY <ref> [8, 11] </ref>, for example, accepts queries containing ordered and unordered window operators. This functionality allows the user to specify an information request more precisely by imposing a locality constraint on groups of words. Proximity can assist in discriminating between relevant and non-relevant documents. <p> Belief values are produced by INQUERY's belief function which is composed of a term frequency component, tf , and an inverse document frequency component, idf , described in <ref> [11, 14] </ref>. The tf component causes the belief in a document to increase as a query concept's occurrence in the document increases, and the idf component causes the belief in a document to decrease as the number of documents in the collection in which the concept occurs increases. <p> Otherwise, the belief of the #BAND assumes the default belief of 0:4 number of concepts . 4 Query Expansion Process The query expansion processes used for this work is similar to those described in <ref> [1, 11, 2, 3] </ref> which exhibit good performance in routing environments [1, 13] using a two step methodology of concept 3 selection and weight assignment. 4.1 Concept selection Our methodology for selecting expansion concepts begins with collecting the union of the terms appearing in documents judged to be relevant. <p> Finally, the pairs of concepts from the expanded query are passed through the #BAND operator, and the top 50 #BANDS are added to the query. Phrases are added at the beginning of the expansion processes using a lexographical technique described in <ref> [11] </ref>. The focus of our experiments is on multi-term concept selection. <p> Unfortunately, early results suggest that query-specific tailoring of these numbers may not be effective.[16, 17] 4.2 Weight Assignment A step popular in relevance feedback methodology is to assign query term weights based on a closed-form function originally developed by Rocchio [9], and has been improved upon in <ref> [10, 7, 11] </ref>. The 4 weight assigned to a concept added to an expanded query is 8 fl tf rel 2 fl tf nonrel , where tf rel is the average tf component of the concept in relevant documents, and tf nonrel is the average tf component in non-relevant documents. <p> The 4 weight assigned to a concept added to an expanded query is 8 fl tf rel 2 fl tf nonrel , where tf rel is the average tf component of the concept in relevant documents, and tf nonrel is the average tf component in non-relevant documents. Recent research <ref> [7, 11, 2] </ref> indicates that iterative techniques can be used to improve these weights. 5 Experiments Experiments were conducted on 50 natural-language information requests used for the routing track for TREC-4 [1]. <p> In general, 30% of unique pairs of terms appeared as duplicates in the top 50 concepts selected for more than one window size. Table 4 shows the breakdown of the overlap between window sizes. Learning new weights using the Dynamic Feedback Optimization technique <ref> [7, 11] </ref> showed a slight tendency to increase the weights of smaller windows, but even after the weights were adjusted, the bigger window received the higher weight 70% of the time.
Reference: [12] <author> J. Zobel and A. Mofit, </author> <title> "Similarity Measures Explored," </title> <institution> Department of Computer Science, RMIT Technical Report CITRI/TR-95-3, </institution> <year> 1995. </year>
Reference: [13] <author> D. </author> <title> Harman, </title> <booktitle> Proceedings of Text REtrieval Conferences (TREC), </booktitle> <pages> 1993-1996. </pages>
Reference-contexts: Otherwise, the belief of the #BAND assumes the default belief of 0:4 number of concepts . 4 Query Expansion Process The query expansion processes used for this work is similar to those described in [1, 11, 2, 3] which exhibit good performance in routing environments <ref> [1, 13] </ref> using a two step methodology of concept 3 selection and weight assignment. 4.1 Concept selection Our methodology for selecting expansion concepts begins with collecting the union of the terms appearing in documents judged to be relevant.
Reference: [14] <editor> S.E. Robertson, W. Walker, S. Jones, M.M. Hancock-Beaulieu, and M.Gatford, </editor> <booktitle> "Okapi at TREC-3", Proceedings of TREC-3 (1994), </booktitle> <pages> pp. 109-126. </pages>
Reference-contexts: Belief values are produced by INQUERY's belief function which is composed of a term frequency component, tf , and an inverse document frequency component, idf , described in <ref> [11, 14] </ref>. The tf component causes the belief in a document to increase as a query concept's occurrence in the document increases, and the idf component causes the belief in a document to decrease as the number of documents in the collection in which the concept occurs increases.
Reference: [15] <author> W.B. Croft, R Cook, and D. Wilder, </author> <title> "Providing Government Information on the Internet: Experiences with THOMAS," </title> <booktitle> Proceedings of Digital Libraries Conference, </booktitle> <year> 1995. </year>
Reference-contexts: Researchers tracking several thousand queries against the Thomas Congressional database found that most queries were between 2 and 8 words <ref> [15] </ref>. In addition, they showed that internally translating the user's request into a query containing proximity operators provided better results than using the single terms.
Reference: [16] <author> C. Buckley, J. Allan, and G. Salton, </author> <title> "Automatic Routing and Ad-hoc Retrieval Using SMART: </title> <booktitle> TREC-2", Proceedings of TREC-2 (1993), </booktitle> <pages> pp. 45-56. </pages>
Reference: [17] <author> C. Buckley, G. Salton, J. Allan, and A. Singhal, </author> <title> "Automatic Query Expansion Using SMART: </title> <booktitle> TREC-3", Proceedings of TREC-3 (1994), </booktitle> <pages> pp. 69-80. 10 </pages>
References-found: 17

