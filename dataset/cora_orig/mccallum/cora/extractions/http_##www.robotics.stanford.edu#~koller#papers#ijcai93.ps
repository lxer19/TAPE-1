URL: http://www.robotics.stanford.edu/~koller/papers/ijcai93.ps
Refering-URL: http://www.robotics.stanford.edu/~koller/papers/ijcai93.html
Root-URL: http://www.robotics.stanford.edu
Email: fbacchus@logos.uwaterloo.ca  grove@research.nj.nec.com  halpern@almaden.ibm.com  daphne@cs.stanford.edu  
Title: Statistical Foundations for Default Reasoning  
Author: Fahiem Bacchus Adam J. Grove Joseph Y. Halpern Daphne Koller 
Address: Waterloo, Ontario Canada, N2L 3G1  4 Independence Way Princeton, NJ 08540  650 Harry Road San Jose, CA 95120-6099  Stanford, CA 94305  
Affiliation: Computer Science Dept. University of Waterloo  NEC Research Inst.  IBM Almaden Research Center  Computer Science Dept. Stanford University  
Abstract: We describe a new approach to default reasoning, based on a principle of indifference among possible worlds. We interpret default rules as extreme statistical statements, thus obtaining a knowledge base KB comprised of statistical and first-order statements. We then assign equal probability to all worlds consistent with KB in order to assign a degree of belief to a statement '. The degree of belief can be used to decide whether to defeasibly conclude '. Various natural patterns of reasoning, such as a preference for more specific defaults, indifference to irrelevant information, and the ability to combine independent pieces of evidence, turn out to follow naturally from this technique. Furthermore, our approach is not restricted to default reasoning; it supports a spectrum of reasoning, from quantitative to qualitative. It is also related to other systems for default reasoning. In particular, we show that the work of [ Goldszmidt et al., 1990 ] , which applies maximum entropy ideas to *-semantics, can be embedded in our framework.
Abstract-found: 1
Intro-found: 1
Reference: [ Adams, 1975 ] <author> E. Adams. </author> <title> The Logic of Conditionals. </title> <address> D. </address> <publisher> Reidel, </publisher> <address> Dordrecht, Netherlands, </address> <year> 1975. </year>
Reference-contexts: However, while all the other probabilistic approaches we are aware of use the statistical interpretation as a motivation for using probabilities, none make explicit use of statistical assertions. Nevertheless, there are close technical connections between our approach and *-semantics <ref> [ Adams, 1975; Geffner and Pearl, 1990 ] </ref> . In particular, we show in Section 5 that the approach of Goldszmidt, Morris, and Pearl [1990], which extends *-semantics by applying ideas of maximum entropy, can be embedded in our framework.
Reference: [ Bacchus et al., 1992 ] <author> F. Bacchus, A. J. Grove, J. Y. Halpern, and D. Koller. </author> <title> From statistics to belief. </title> <booktitle> In Proc. National Conference on Artificial Intelligence (AAAI-92), </booktitle> <pages> pages 602-608, </pages> <year> 1992. </year>
Reference-contexts: Our theme in this paper is that this plausible connection between direct inference and default reasoning can be made precise. In particular, we show in Section 3 that a new method for direct inference, first introduced in <ref> [ Bacchus et al., 1992; Grove et al., 1992b ] </ref> , can provide many of the features considered desirable in default reasoning. Among other things, it provides a preference for more specific defaults as well as the ability to ignore irrelevant information. <p> triple (M; ~t ; V ), where M is a finite first-order structure, ~t = ht 1 ; t 2 ; : : :i, t i &gt; 0, is a tolerance 1 We discuss the issue of conditioning on an event with probability zero in the full paper. 2 In <ref> [ Bacchus et al., 1992 ] </ref> the use of approximate equality was suppressed in order to highlight other issues. vector , used to give semantics to the connectives i and i , and V is a valuation, which interprets the free variables as elements of the domain in structure M .
Reference: [ Bacchus et al., 1993 ] <author> F. Bacchus, A. J. Grove, J. Y. Halpern, and D. Koller. </author> <title> Forming beliefs about a changing world. </title> <note> In preparation, </note> <year> 1993. </year>
Reference-contexts: In <ref> [ Bacchus et al., 1993 ] </ref> , we present a more general approach within the random-worlds framework, and show that it deals with many of the problematic aspects of causal reasoning. The language problem is more subtle.
Reference: [ Bacchus, 1990 ] <author> F. Bacchus. </author> <title> Representing and Reasoning with Probabilistic Knowledge. </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1990. </year>
Reference-contexts: We use the probability logic presented in [ Grove et al., 1992b ] , which is a variant of logics developed in <ref> [ Bacchus, 1990; Halpern, 1990 ] </ref> . This logic augments first-order logic by allowing proportion expressions of the form k (x)k x . This term denotes the proportion of domain elements satisfying . We actually allow an arbitrary set of variables in the subscript. <p> One important difference between our syntax and that of <ref> [ Bacchus, 1990 ] </ref> is the use of approximate equality to compare proportion expressions. It is not hard to see that exact comparisons are sometimes inappropriate. Consider a statement such as "90% of birds fly".
Reference: [ Carnap, 1950 ] <author> R. Carnap. </author> <title> Logical Foundations of Probability. </title> <publisher> University of Chicago Press, </publisher> <address> Chicago, </address> <year> 1950. </year>
Reference: [ Carnap, 1952 ] <author> R. Carnap. </author> <title> The Continuum of Inductive Methods. </title> <publisher> University of Chicago Press, </publisher> <address> Chicago, </address> <year> 1952. </year>
Reference: [ Geffner and Pearl, 1990 ] <author> H. Geffner and J. Pearl. </author> <title> A framework for reasoning with defaults. </title> <editor> In H. E. Ky-burg, Jr., R. Loui, and G. Carlson, editors, </editor> <title> Knowledge Representation and Defeasible Reasoning. </title> <publisher> Kluwer Academic Press, </publisher> <address> Dordrecht, Netherlands, </address> <year> 1990. </year>
Reference-contexts: However, while all the other probabilistic approaches we are aware of use the statistical interpretation as a motivation for using probabilities, none make explicit use of statistical assertions. Nevertheless, there are close technical connections between our approach and *-semantics <ref> [ Adams, 1975; Geffner and Pearl, 1990 ] </ref> . In particular, we show in Section 5 that the approach of Goldszmidt, Morris, and Pearl [1990], which extends *-semantics by applying ideas of maximum entropy, can be embedded in our framework. <p> We begin by outlining *-semantics <ref> [ Geffner and Pearl, 1990 ] </ref> , on which the framework of [ Goldszmidt et al., 1990 ] is based. <p> A set R of default rules *-entails B ! C if for every PPD that *-satisfies R, lim *!0 * (CjB) = 1. As shown in <ref> [ Geffner and Pearl, 1990 ] </ref> , *-entailment possesses a number of reasonable properties typically associated with default reasoning, including a preference for more specific information. However, there are a number of desirable properties that it does not have. Among other things, irrelevant information is not ignored.
Reference: [ Goldszmidt et al., 1990 ] <author> M. Goldszmidt, P. Morris, and J. Pearl. </author> <title> A maximum entropy approach to nonmono-tonic reasoning. </title> <booktitle> In Proc. National Conference on Artificial Intelligence (AAAI-90), </booktitle> <pages> pages 646-652, </pages> <year> 1990. </year>
Reference-contexts: In particular, we show in Section 5 that the approach of Goldszmidt, Morris, and Pearl [1990], which extends *-semantics by applying ideas of maximum entropy, can be embedded in our framework. Besides providing further justification for the use of maximum entropy in <ref> [ Goldszmidt et al., 1990 ] </ref> , this embedding allows us to use the algorithms they have developed to calculate degrees of belief for formulas in a fragment of our full language. 2 The Formalism We assume that the knowledge base consists of sentences written in a formal language that allows <p> This has a reasonable explanation: if we have two independent bodies of evidence, both supporting ' quite strongly, when we combine them we should get even more support for '. 5 Maximum entropy In this section, we show how the approach of <ref> [ Goldszmidt et al., 1990 ] </ref> can be embedded in our framework. We begin by outlining *-semantics [ Geffner and Pearl, 1990 ] , on which the framework of [ Goldszmidt et al., 1990 ] is based. <p> them we should get even more support for '. 5 Maximum entropy In this section, we show how the approach of <ref> [ Goldszmidt et al., 1990 ] </ref> can be embedded in our framework. We begin by outlining *-semantics [ Geffner and Pearl, 1990 ] , on which the framework of [ Goldszmidt et al., 1990 ] is based. <p> We showed above that our approach does not suffer from this problem. In order to obtain additional desirable properties, *- semantics is extended in <ref> [ Goldszmidt et al., 1990 ] </ref> by an application of the maximum entropy principle [ Jaynes, 1957 ] . Instead of considering all possible PPD's, as above, only the PPD f fl *;R g *&gt;0 of maximum entropy is considered (see [ Goldszmidt et al., 1990 ] for precise definitions and <p> obtain additional desirable properties, *- semantics is extended in <ref> [ Goldszmidt et al., 1990 ] </ref> by an application of the maximum entropy principle [ Jaynes, 1957 ] . Instead of considering all possible PPD's, as above, only the PPD f fl *;R g *&gt;0 of maximum entropy is considered (see [ Goldszmidt et al., 1990 ] for precise definitions and technical details). A rule B ! C is an ME-plausible consequence of R if lim *!0 fl *;R (CjB) = 1. The notion of ME-plausible consequence is analyzed in detail in [ Goldszmidt et al., 1990 ] , where it is <p> *;R g *&gt;0 of maximum entropy is considered (see <ref> [ Goldszmidt et al., 1990 ] </ref> for precise definitions and technical details). A rule B ! C is an ME-plausible consequence of R if lim *!0 fl *;R (CjB) = 1. The notion of ME-plausible consequence is analyzed in detail in [ Goldszmidt et al., 1990 ] , where it is shown to inherit all the nice properties of *-entailment (such as the preference for more specific information), while successfully ignoring irrelevant information. Equally importantly, algorithms are provided for computing the ME-plausible consequences of a set of rules in certain cases. <p> These results can be extended to show that the approach of <ref> [ Goldszmidt et al., 1990 ] </ref> can be embedded in our framework in a straightforward manner. <p> Note that the formulas that arise under this conversion all use the same approximately equals relation 1 , since the approach of <ref> [ Goldszmidt et al., 1990 ] </ref> uses the same * for all default rules. Moreover, they all involve only unary predicates. Under this translation, we can prove the following theorem, using techniques similar to [ Grove et al., 1992b ] . Theorem 5.1: Let c be a constant symbol. <p> Theorem 5.1: Let c be a constant symbol. Using the translation described above, for any set R of defeasible rules, B ! C is an ME-plausible consequence of R iff Pr w V Thus, all the computational techniques and results described in <ref> [ Goldszmidt et al., 1990 ] </ref> carry over to this special case of our approach. It is very encouraging that the results of [ Goldszmidt et al., 1990 ] can be arrived at in two quite different ways. <p> set R of defeasible rules, B ! C is an ME-plausible consequence of R iff Pr w V Thus, all the computational techniques and results described in <ref> [ Goldszmidt et al., 1990 ] </ref> carry over to this special case of our approach. It is very encouraging that the results of [ Goldszmidt et al., 1990 ] can be arrived at in two quite different ways. Our result formalizes a connection between entropy and indifference, well known in other contexts like statistical thermodynamics, in the context of an agent reasoning by default. <p> While the random-worlds method is not entropy-based, the relationship we observed in Section 5 suggests that similar problems may arise. With regard to causality, <ref> [ Goldszmidt et al., 1990; Pearl, 1988 ] </ref> and [ Hunter, 1989 ] have observed that knowledge about causal relationships greatly affects our intuitions concerning the "right" answers to various problems, and that the naive maximum entropy approaches do not take this causal information into consid eration.
Reference: [ Grove et al., 1992a ] <author> A. J. Grove, J. Y. Halpern, and D. Koller. </author> <title> Asymptotic conditional probabilities for first-order logic. </title> <booktitle> In Proc. 24th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 294-305, </pages> <year> 1992. </year>
Reference-contexts: Once we have even a single binary predicate in the language, all connection between our approach and maximum entropy disappears. As discussed in [ Grove et al., 1992b ] , we cannot even find a suitable probability space to take entropy over. Results of <ref> [ Grove et al., 1992a ] </ref> showing that, with a binary predicate in the language, degrees of belief are in general uncomputable support the conjecture that there is none to be found. 6 Discussion and conclusions We have shown that a logic that allows statistical and first-order assertions, together with a
Reference: [ Grove et al., 1992b ] <author> A. J. Grove, J. Y. Halpern, and D. Koller. </author> <title> Random worlds and maximum entropy. </title> <booktitle> In Proc. 7th IEEE Symp. on Logic in Computer Science, </booktitle> <pages> pages 22-33, </pages> <year> 1992. </year>
Reference-contexts: Our theme in this paper is that this plausible connection between direct inference and default reasoning can be made precise. In particular, we show in Section 3 that a new method for direct inference, first introduced in <ref> [ Bacchus et al., 1992; Grove et al., 1992b ] </ref> , can provide many of the features considered desirable in default reasoning. Among other things, it provides a preference for more specific defaults as well as the ability to ignore irrelevant information. <p> We use the probability logic presented in <ref> [ Grove et al., 1992b ] </ref> , which is a variant of logics developed in [ Bacchus, 1990; Halpern, 1990 ] . This logic augments first-order logic by allowing proportion expressions of the form k (x)k x . This term denotes the proportion of domain elements satisfying . <p> It is clear that we do not mean that exactly 90% of all birds fly. Among other things, this would imply that the number of birds is a multiple of ten, an implication that is surely not intended. We therefore use the approach described in <ref> [ Grove et al., 1992b; Koller and Halpern, 1992 ] </ref> , and compare proportion expressions using (instead of = and ) one of an infinite family of con-nectives i and i , for i = 1; 2; 3 : : : ("i-approximately equal" or "i-approximately less than or equal"). 2 For <p> Even if KB is eventually consistent, the limit may not exist. In many cases, the nonexistence of a limit can be intuitively justified, and is sometimes related to the issue of multiple extensions. (See Section 4 and <ref> [ Grove et al., 1992b ] </ref> .) However, there are cases where the limit does not exist for what seem to be the "wrong" reasons. <p> Although no explicit use is made of maximum entropy in our framework, there is a close connection between the random-worlds approach and maximum entropy provided that the language consists only of unary predicates and constants, as shown in <ref> [ Grove et al., 1992b ] </ref> . These results can be extended to show that the approach of [ Goldszmidt et al., 1990 ] can be embedded in our framework in a straightforward manner. <p> Moreover, they all involve only unary predicates. Under this translation, we can prove the following theorem, using techniques similar to <ref> [ Grove et al., 1992b ] </ref> . Theorem 5.1: Let c be a constant symbol. <p> It is unlikely that an approach that uses entropy directly could be extended to deal such languages. Once we have even a single binary predicate in the language, all connection between our approach and maximum entropy disappears. As discussed in <ref> [ Grove et al., 1992b ] </ref> , we cannot even find a suitable probability space to take entropy over.
Reference: [ Halpern, 1990 ] <author> J. Y. Halpern. </author> <title> An analysis of first-order logics of probability. </title> <journal> Artificial Intelligence, </journal> <volume> 46 </volume> <pages> 311-350, </pages> <year> 1990. </year>
Reference-contexts: We use the probability logic presented in [ Grove et al., 1992b ] , which is a variant of logics developed in <ref> [ Bacchus, 1990; Halpern, 1990 ] </ref> . This logic augments first-order logic by allowing proportion expressions of the form k (x)k x . This term denotes the proportion of domain elements satisfying . We actually allow an arbitrary set of variables in the subscript. <p> We write j= ' if (M; ~t ; V ) j= ' for all (M; ~t ; V ). We want the agent to use the information in the knowledge base to assign degrees of belief to various assertions. Following <ref> [ Halpern, 1990 ] </ref> , we give semantics to degrees of belief in terms of a set of finite first-order models or possible worlds, together with a probability distribution over this set.
Reference: [ Hunter, 1989 ] <author> D. Hunter. </author> <title> Causality and maximum entropy updating. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 3(1) </volume> <pages> 379-406, </pages> <year> 1989. </year>
Reference-contexts: While the random-worlds method is not entropy-based, the relationship we observed in Section 5 suggests that similar problems may arise. With regard to causality, [ Goldszmidt et al., 1990; Pearl, 1988 ] and <ref> [ Hunter, 1989 ] </ref> have observed that knowledge about causal relationships greatly affects our intuitions concerning the "right" answers to various problems, and that the naive maximum entropy approaches do not take this causal information into consid eration. <p> We would argue that this only shows that this information is not properly captured by the straightforward encoding of defaults, and that we may therefore have to include information about causality when expressing defaults in the knowledge base. <ref> [ Hunter, 1989 ] </ref> presents one possibility for encoding causal information within the maximum entropy approach. In [ Bacchus et al., 1993 ] , we present a more general approach within the random-worlds framework, and show that it deals with many of the problematic aspects of causal reasoning.
Reference: [ Jaynes, 1957 ] <author> E. T. </author> <title> Jaynes. </title> <journal> Information theory and statistical mechanics. Physical Review, </journal> <volume> 106(4) </volume> <pages> 620-630, </pages> <year> 1957. </year>
Reference-contexts: We showed above that our approach does not suffer from this problem. In order to obtain additional desirable properties, *- semantics is extended in [ Goldszmidt et al., 1990 ] by an application of the maximum entropy principle <ref> [ Jaynes, 1957 ] </ref> . Instead of considering all possible PPD's, as above, only the PPD f fl *;R g *&gt;0 of maximum entropy is considered (see [ Goldszmidt et al., 1990 ] for precise definitions and technical details).
Reference: [ Johnson, 1932 ] <author> W. E. Johnson. </author> <title> Probability: The deductive and inductive problems. </title> <journal> Mind, </journal> <volume> 41(164) </volume> <pages> 409-423, </pages> <year> 1932. </year>
Reference: [ Koller and Halpern, 1992 ] <author> D. Koller and J. Y. Halpern. </author> <title> A logic for approximate reasoning. </title> <booktitle> In Proc. Third International Conference on Principles of Knowledge Representation and Reasoning (KR '92), </booktitle> <pages> pages 153-164, </pages> <year> 1992. </year>
Reference-contexts: It is clear that we do not mean that exactly 90% of all birds fly. Among other things, this would imply that the number of birds is a multiple of ten, an implication that is surely not intended. We therefore use the approach described in <ref> [ Grove et al., 1992b; Koller and Halpern, 1992 ] </ref> , and compare proportion expressions using (instead of = and ) one of an infinite family of con-nectives i and i , for i = 1; 2; 3 : : : ("i-approximately equal" or "i-approximately less than or equal"). 2 For
Reference: [ Kyburg, 1961 ] <author> H. E Kyburg, Jr. </author> <title> Probability and the Logic of Rational Belief. </title> <publisher> Wesleyan University Press, </publisher> <address> Middletown, Connecticut, </address> <year> 1961. </year>
Reference-contexts: Furthermore, in those cases where qualitative defaults are insufficient, our approach can often pinpoint the extra information required to reach a definite conclusion. To demonstrate, we examine two examples that are well-known to be problematic for pure default reasoning: the Lottery Paradox <ref> [ Kyburg, 1961 ] </ref> and the Nixon Diamond [ Reiter and Criscuolo, 1981 ] . In the Lottery Paradox, the assumption is that a large number of people buy tickets to a lottery in which there is only one winner.
Reference: [ Kyburg, 1974 ] <author> H. E. Kyburg, Jr. </author> <title> The Logical Foundations of Statistical Inference. </title> <publisher> Reidel, </publisher> <address> Dordrecht, Netherlands, </address> <year> 1974. </year>
Reference: [ Laplace, 1820 ] <author> P. S. </author> <title> de Laplace. Essai Philosophique sur les Probabilites. 1820. English translation is Philosophical Essay on Probabilities, </title> <publisher> Dover Publications, </publisher> <address> New York, </address> <note> 1951. </note> [ <author> Lehmann and Magidor, 1992 ] D. Lehmann and M. Magidor. </author> <title> What does a conditional knowledge base entail? Artificial Intelligence, </title> <booktitle> 55(1) </booktitle> <pages> 1-60, </pages> <year> 1992. </year>
Reference: [ Levi, 1980 ] <author> I. Levi. </author> <title> The Enterprise of Knowledge. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1980. </year>
Reference: [ McCarthy, 1986 ] <author> J. McCarthy. </author> <title> Applications of circumscription to formalizing common-sense knowledge. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 86-116, </pages> <year> 1986. </year>
Reference: [ Neufeld, 1989 ] <author> E. Neufeld. </author> <title> Defaults and probabilities; extensions and coherence. </title> <booktitle> In Proc. First International Conference on Principles of Knowledge Representation and Reasoning (KR '89), </booktitle> <pages> pages 312-323, </pages> <year> 1989. </year>
Reference-contexts: This interpretation of defaults has a number of benefits. The first is simply that we understand what our knowledge base means. Many default theories will tell us how to reason with "Birds typically fly". But, as pointed out by <ref> [ Neufeld, 1989 ] </ref> , there is far less work telling us when we should adopt this default in the first place.
Reference: [ Pearl, 1988 ] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: Our results demonstrate the close connection between default reasoning and direct inference. We close by briefly discussing two criticisms that have been made of entropy-based reasoning systems: language and syntax dependence, and the treatment of causality <ref> [ Pearl, 1988 ] </ref> . While the random-worlds method is not entropy-based, the relationship we observed in Section 5 suggests that similar problems may arise. <p> While the random-worlds method is not entropy-based, the relationship we observed in Section 5 suggests that similar problems may arise. With regard to causality, <ref> [ Goldszmidt et al., 1990; Pearl, 1988 ] </ref> and [ Hunter, 1989 ] have observed that knowledge about causal relationships greatly affects our intuitions concerning the "right" answers to various problems, and that the naive maximum entropy approaches do not take this causal information into consid eration.
Reference: [ Pearl, 1989 ] <author> J. Pearl. </author> <title> Probabilistic semantics for non-monotonic reasoning: A survey. </title> <editor> In R. J. Brachman, H. J. Levesque, and R. Reiter, editors, </editor> <booktitle> Proc. First International Conference on Principles of Knowledge Representation and Reasoning (KR '89), </booktitle> <pages> pages 505-516, </pages> <year> 1989. </year> <note> Reprinted in Readings in Uncertain Reasoning, </note> <editor> G. Shafer and J. Pearl (eds.), </editor> <publisher> Morgan Kauf-mann, </publisher> <address> San Mateo, CA, </address> <year> 1990, </year> <pages> pp. 699-710. </pages>
Reference-contexts: In Section 4, we demonstrate the advantages of being able to perform both types of reasoning in a unified framework, by considering both the Lottery Paradox and the Nixon Diamond example. We are certainly not the first to apply a probabilistic semantics to nonmonotonic logic (see <ref> [ Pearl, 1989 ] </ref> for an overview). However, while all the other probabilistic approaches we are aware of use the statistical interpretation as a motivation for using probabilities, none make explicit use of statistical assertions.
Reference: [ Pearl, 1990 ] <author> J. Pearl. </author> <title> System Z: A natural ordering of defaults with tractable applications to nonmonotonic reasoning. </title> <editor> In M. Vardi, editor, </editor> <booktitle> Theoretical Aspects of Reasoning about Knowledge: Proc. Third Conference, </booktitle> <pages> pages 121-135. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: However, there are a number of desirable properties that it does not have. Among other things, irrelevant information is not ignored. Pearl's notion of 1-entailment <ref> [ Pearl, 1990 ] </ref> strengthens *-entailment by allowing it to ignore irrelevant information in certain cases. However, it suffers from the problem that subclasses that are exceptional in one aspect are deemed exceptional in all aspects. In particular, using 1-entailment, we cannot conclude that Opus the penguin has a beak.
Reference: [ Pollock, 1990 ] <author> J. L. Pollock. </author> <title> Nomic Probabilities and the Foundations of Induction. </title> <publisher> Oxford University Press, Oxford, </publisher> <address> U.K., </address> <year> 1990. </year>
Reference: [ Reichenbach, 1949 ] <author> H. Reichenbach. </author> <title> Theory of Probability. </title> <institution> University of California Press, Berkeley, </institution> <year> 1949. </year>
Reference: [ Reiter and Criscuolo, 1981 ] <author> R. Reiter and G. Criscuolo. </author> <title> On interacting defaults. </title> <booktitle> In Proc. Seventh International Joint Conference on Artificial Intelligence (IJCAI-81), </booktitle> <pages> pages 270-276, </pages> <year> 1981. </year>
Reference-contexts: To demonstrate, we examine two examples that are well-known to be problematic for pure default reasoning: the Lottery Paradox [ Kyburg, 1961 ] and the Nixon Diamond <ref> [ Reiter and Criscuolo, 1981 ] </ref> . In the Lottery Paradox, the assumption is that a large number of people buy tickets to a lottery in which there is only one winner.
Reference: [ Reiter, 1980 ] <author> R. Reiter. </author> <title> A logic for default reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 13 </volume> <pages> 81-132, </pages> <year> 1980. </year>
Reference: [ Salmon, 1971 ] <author> W. Salmon. </author> <title> Statistical Explanation and Statistical Relevance. </title> <institution> University of Pittsburgh Press, Pittsburgh, </institution> <year> 1971. </year>
Reference: [ Shafer, 1976 ] <author> G. Shafer. </author> <title> A Mathematical Theory of Evidence. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1976. </year>
Reference-contexts: In this case the limit does exist; we get Pr w 1 ('jKB 2 ) = fffi fffi+ff fi , where ff = 1 ff and fi = 1 fi. Readers familiar with Dempster's rule of combination <ref> [ Shafer, 1976 ] </ref> will note that this formula is precisely the result of combining the two probability functions that give probability ff and fi, respectively, to Nixon being a Pacifist.
References-found: 30

