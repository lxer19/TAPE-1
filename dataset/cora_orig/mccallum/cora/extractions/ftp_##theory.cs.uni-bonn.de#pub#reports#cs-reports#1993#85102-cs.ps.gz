URL: ftp://theory.cs.uni-bonn.de/pub/reports/cs-reports/1993/85102-cs.ps.gz
Refering-URL: http://cs.uni-bonn.de/info5/publications/CS-1993-en.html
Root-URL: http://cs.uni-bonn.de
Title: On a Sublinear Time Parallel Construction of Optimal Binary Search Trees (Note) time for the
Author: Marek Karpinski Wojciech Rytter E 
Note: to n 2  Mail: marek@cs.uni-bonn.de. Research supported in part by the DFG grant KA 67314-1, ESPRIT BR Grant 7079 and the Volkswagen-Stiftung. Supported by the grant KBN 2-1190-91-01.  
Address: 53117 Bonn  02-097 Warsaw  
Affiliation: Dept. of Computer Science University of Bonn  Institute of Informatics Warsaw University  
Abstract: We design an efficient sublinear time parallel construction of optimal binary search trees. The efficiency of the parallel algorithm corresponds to its total work (the product time fi processors). Our algorithm works in O(n 1* ) log(n) time with the total work O(n 2+2* ), for an arbitrarily small constant 0 &lt; * 1 2 . This is optimal within a factor n 2* with respect to the best known sequential algorithm given by Knuth, which needs only O(n 2 ) time due to a monotonicity property of optimal binary search trees, see [6]). It is unknown how to explore this property in an efficient N C construction of binary search trees. Here we show that it can be effectively used in sublinear time parallel computation. Our improvement also relies on the use (in independently processed small subcomputations) of the parallelism present in Knuth's algorithm. The best known sublinear time algorithms for the construction of binary search trees (as an instance of a more general problem) have O(n 3 ) work for time larger than n 3=4 , see [3] and [7]. For time n these algorithms need n 4 work, while our algorithm needs for this time only n 3 work, thus improving the known algorithms by a linear factor. Also if time is O(n 1* ) and * is very small our improvement is close to O(n). Such improvement is similar to the one implied by the monotonicity property in sequential computations (from n 3 sequential time for a more general dynamic programming problem p
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.Aho, J.Hopcroft, J.Ullman, </author> <title> Introduction to the design and analysis of computer algorithms, </title> <publisher> Addison-Wesley (1974) </publisher>
Reference-contexts: We use the same name cost for this array and call it the dynamic programming table. It can be computed in O (n 3 ) time, by procesing diagonal after diagonal, starting with the central diagonal, see <ref> [1] </ref>. In case of optimal binary search trees this can be reduced to O (n 2 ) using additional tabulated values of the cuts in table CU T (see [10]).
Reference: [2] <author> M. J. Atallah, S. ~ R. Kosaraju, L. L. Larmore, G. L. Miller, and S-H. Teng, </author> <title> Constructing trees in parallel, </title> <booktitle> Proceedings of the 1st ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <year> (1989), </year> <pages> pp. 499-533. </pages>
Reference-contexts: Once the table cost (i; j) is computed then the construction of an optimal tree can be done very efficiently in parallel. The following (easy to see) result was also observed in <ref> [2] </ref>: Lemma 1.2 If the table of costs is computed then an optimal tree can be constructed in O (log n) time with n 2 = log (n) processors. <p> Another important problem is the design of an efficient NC algorithm for the general OBST problem. Even an improvement O (n 6* ) in the number of processors would be of considerable interest (cf., also, <ref> [2] </ref>).
Reference: [3] <author> Z. Galil, K. Park, </author> <title> Parallel algorithms for dynamic programming recurrences with more than O(1) dependency, </title> <type> Manuscript. </type>
Reference-contexts: This generality is probably a cause of the inefficiency. Optimal binary search trees have special properties. The way to an improvement is a suitable use of these properties. The binary search tree problem is a special case of the more general dynamic programming problem. In <ref> [3] </ref> and [7] (independently) it was shown that the dynamic programming 2 recurrences can be solved in n 1* time with cubic total work for * 1=4. (A slightly worse algorithm was presented in [4]). So these algorithms worked in n 3=4 time with O (n 3 ) work.
Reference: [4] <author> S. Huan, H. Liu, V. Viswanathan, </author> <title> A sublinear time parallel algorithms for some dynamic programming problems, </title> <booktitle> Proceedings of the 1990 International Conference on Parallel Processing, 3 (1990), </booktitle> <pages> pp. 261-264. </pages>
Reference-contexts: In [3] and [7] (independently) it was shown that the dynamic programming 2 recurrences can be solved in n 1* time with cubic total work for * 1=4. (A slightly worse algorithm was presented in <ref> [4] </ref>). So these algorithms worked in n 3=4 time with O (n 3 ) work. However for smaller time the work increases, for example if time is O ( p n then the total work in these algorithms was of order n 4 .
Reference: [5] <author> D. E. Knuth, </author> <title> The Art of computer programming, Volume 3: Sorting and searching, </title> <publisher> Addison-Wesley (1973). </publisher>
Reference-contexts: In the latter case we have linear factor improvement. A similar improvement by a linear factor occurs in sequential computation of the considered problem (compared to the general dynamic programming problem). Statement of the OBST problem. We use terminology from <ref> [5] </ref>, pages 434-435. Let fi = (K 1 ; : : : K n ) be a sequence of n weighted items (keys), which are to be placed in a binary search tree.
Reference: [6] <author> D. E. Knuth, </author> <title> Optimum binary search trees, </title> <journal> Acta Informatica 1 (1971), </journal> <pages> pp. 14-25. </pages>
Reference-contexts: The construction of optimal binary search trees (the OBST problem) is an important algorithmic problem which has so far resisted any really efficient N C implementation, though Knuth gives a quadratic time sequential algorithm <ref> [6] </ref>. Only a special case (alphabetic trees) can be solved by a really efficient (in the sense of total work) N C algorithm, see [8]. The Knuth's algorithm uses a monotonicity property of optimal binary search trees (defined later). <p> This is the first point giving an optimal decomposition of obst (i; j) into two smaller (son) subtrees. Optimal binary search trees have the following crucial property (proved in <ref> [6] </ref>): monotonicity property: i i 0 j j 0 =) CU T (i; j) CU T (i 0 ; j 0 ). Sequentially the values of cost (i; j) are computed by tabulating them in an array. <p> This guarantees that the total work for a fixed diagonal is linear (by the same argument as in <ref> [6] </ref>). All values on a fixed diagonal are computed simultaneously. Additionally the table of cuts is computed. We refer the reader to [6] for details. This implies the following fact. <p> This guarantees that the total work for a fixed diagonal is linear (by the same argument as in <ref> [6] </ref>). All values on a fixed diagonal are computed simultaneously. Additionally the table of cuts is computed. We refer the reader to [6] for details. This implies the following fact. Lemma 2.1 The dynamic programming table for the OBST problem can be computed in n log n time with n= log (n) processors. Let fi = (K 1 ; : : : K n ) be an initial sequence of n keys.
Reference: [7] <author> L. Larmore, W. Rytter, </author> <title> Efficient sublinear time parallel algorithms for the recognition for dynamic programming problems and context-free recognition, </title> <booktitle> in: STACS'92, Lecture Notes of Computer Science 577, </booktitle> <publisher> Springer Verlag (1992), pp.121-132 </publisher>
Reference-contexts: This generality is probably a cause of the inefficiency. Optimal binary search trees have special properties. The way to an improvement is a suitable use of these properties. The binary search tree problem is a special case of the more general dynamic programming problem. In [3] and <ref> [7] </ref> (independently) it was shown that the dynamic programming 2 recurrences can be solved in n 1* time with cubic total work for * 1=4. (A slightly worse algorithm was presented in [4]). So these algorithms worked in n 3=4 time with O (n 3 ) work.
Reference: [8] <author> L. Larmore, T. Przytycka, W. Rytter, </author> <title> Parallel construction of optimal alphabetic trees, in: </title> <publisher> SPAA'93. </publisher>
Reference-contexts: Only a special case (alphabetic trees) can be solved by a really efficient (in the sense of total work) N C algorithm, see <ref> [8] </ref>. The Knuth's algorithm uses a monotonicity property of optimal binary search trees (defined later). It is unknown how to use a similar property to reduce number of processors in polylogarithmic time computations.
Reference: [9] <author> W. Rytter, </author> <title> Efficient parallel computations for some dynamic programming problems, </title> <booktitle> Theoretical Computer Science 59 (1988), </booktitle> <pages> pp. 297-307. 9 </pages>
Reference-contexts: The Knuth's algorithm uses a monotonicity property of optimal binary search trees (defined later). It is unknown how to use a similar property to reduce number of processors in polylogarithmic time computations. The best upper bound in polylogarithmic time computations is close to n 6 , see <ref> [9] </ref>, and is certainly too large. It applies to much larger class of problems which are instances of the dynamic recurrences problem. This generality is probably a cause of the inefficiency. Optimal binary search trees have special properties. The way to an improvement is a suitable use of these properties.
Reference: [10] <author> F. F. Yao. </author> <title> Efficient dynamic programming using quadrangle inequalities, </title> <booktitle> Proceedings of the 12th ACM Symposium on Theory of Computing (1980), </booktitle> <pages> pp. 429-435. 10 </pages>
Reference-contexts: In case of optimal binary search trees this can be reduced to O (n 2 ) using additional tabulated values of the cuts in table CU T (see <ref> [10] </ref>). Once the table cost (i; j) is computed then the construction of an optimal tree can be done very efficiently in parallel.
References-found: 10

