URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3666/3666.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Email: fswade,bonnieg@cs.umd.edu  
Title: Bilingual Lexicon Construction Using Large Corpora  
Author: CS TR , UMIACS TR - Wade Shen Bonnie J. Dorr 
Date: June 26, 1997  
Address: College Park  
Affiliation: Department of Computer Science University of Maryland  
Abstract: This paper introduces a method for learning bilingual term and sentence level alignments for the purpose of building bilingual lexicons. Combining statistical techniques with linguistic knowledge, a general algorithm is developed for learning term and sentence alignments from large bilingual corpora with high accuracy. This is achieved through the use of filtered linguistic feedback between term and sentence alignment processes. An implementation of this algorithm, TAG-ALIGN, is evaluated against approaches similar to [Brown et al.1993] that apply Bayesian techniques for term alignment, and [Gale and Church 1991] a dynamic programming method for aligning sentences. The ultimate goal is to produce large bilingual lexicons with a high degree of accuracy from potentially noisy corpora.
Abstract-found: 1
Intro-found: 1
Reference: [Fung and Church1994] <author> P. Fung and K. W. Church, </author> <booktitle> 1994 K-Vec: A New Approach for Aligning Parallel Texts Proceedings of the 15th International Conference on Computational Linguistics, </booktitle> <address> Kyoto, Japan. </address>
Reference: [Gale and Church1991] <author> W. Gale and K. W. </author> <title> Church 1991 A Program for Aligning Sentences in Bilingual Corpora Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, </title> <address> Berkeley, CA. </address>
Reference: [Brown et al.1993] <author> P. Brown, S. Della Pietra, V. Della Pietra, and R. </author> <title> Mercer 1993 The Mathematics of Machine Translation: Parameter Estimation Computational Linguistics, </title> <booktitle> 19 </booktitle> <pages> 263-312 </pages>
Reference-contexts: The algorithm, in its alignment process, generates a highly accurate bilingual lexicon that can be used to generate better word and sentence level alignments from new corpora. TAG-ALIGN's word alignment algorithm draws on a Bayesian model similar to that discussed in <ref> [Brown et al.1993] </ref>. The algorithm simply counts the co-occurrence frequencies between source language words and target language words. <p> This process yields the measure P (W source ^ W target ) which is then used, in conjunction with P (W source ) and P (W target ) to estimate the conditional probability P (W target jW source ) (what <ref> [Brown et al.1993] </ref> call the language model probability. <p> Algorithms of the former category attempt to estimate conditional probabilities for a target word's occurrence given the presence of a source word within a section of a document (see <ref> [Brown et al.1993] </ref>). These systems can be considered adaptive, as they attempt to learn these conditional probabilities from training data. Approaches of the latter category rely on similarities in the orthography of words (cognates) to build anchor points in a document.
Reference: [Church1993] <author> K. W. Church 1993 Char align: </author> <title> A Program for Aligning Parallel Texts at the Character Level Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, </title> <address> Columbus, OH. </address>
Reference: [Brown et al.1991] <author> Peter F. Brown, Jenifer C.Lai, and Robert Mercer. </author> <year> 1990. </year> <title> Aligning Sentences in Parallel Corpora Computational Linguistics, </title> <booktitle> 16 </booktitle> <pages> 79-80 </pages>
Reference-contexts: The Alignment Problem Sentence Alignment The problem of aligning sentences within a document has been the focus of two different classes of algorithms. In [Gale and Church 1991] and <ref> [Brown et al.1991] </ref> a dynamic programming method for probabilistic alignment is introduced. In these systems a document-wide sentence mapping is created, correlating source and target language sentences by their sentence lengths. <p> These entries are subsequently used by the Anchors module to evaluate the similarity of new sentences that are to be aligned by the sentence aligner. Tag-based Word Alignment The TAG-ALIGN approach presented here borrows from the translation models of <ref> [Brown et al.1991] </ref> by using conditional probabilities to find likely translations of a source word in target sentences. However, it improves upon these approaches through its use of linguistic filters (discussed below). Initially, TAG-ALIGN acts much like a Bayesian classifier. Source/target sentence pairs are used to tabulate word correspondences. <p> The anchor function is used along with sentence length are used as similarity functions for a sentence alignment protocol similar to [Gale and Church 1991] and <ref> [Brown et al.1991] </ref> with certain enhancements. TAG-ALIGN performs a dynamic programming search for the best alignment allowing source/target sentence pairs to be matched, inserted, deleted, joined, and split. For further 7 discussion of these processes, see [Gale and Church 1991].
Reference: [Melamed1996] <author> I. </author> <title> Dan Melamed 1996 A Geometric Approach to Mapping Bitext Correspondence Proceedings of the Conference on Empirical Methods in Natural Language Processing, Philadel-phia. 3 Their algorithm considers insertion, </title> <booktitle> deletion, </booktitle> <pages> 1-1, 2-2, (1-2), </pages> <month> (2-1), </month> <title> and crossover mappings, but does not consider N to 1 or 1 to N mappings for arbitrary N, although TAG-ALIGN does. We believe this performance degradation is primarily due to the lack of paragraph boundaries and the high number of N to 1 mappings in the UN data. This data irregularity does not seem to manifest as frequently in other UN data sets. </title> <type> 10 </type>
Reference: [Simard et al.1992] <author> Michel Simard, G. F. Foster and P. </author> <title> Isabelle, 1992 Using Cognates to Align Sentences in Bilingual Texts Proceedings of TMI-92, </title> <address> Montreal, PQ. </address>
Reference-contexts: Newer methods do not rely on the existence of hard boundaries to perform accurately. Systems such as [Melamed 1996] and <ref> [Simard et al.1992] </ref> rely on generating bitext maps, character level mappings between source and target language documents. These methods use similarity measures at the level of words [Melamed 1996] and character ([Simard et al.1992] and [Church 1993]) to generate points of correspondence in a bitext space. [Melamed 1996] and [Simard et <p> and <ref> [Simard et al.1992] </ref> rely on generating bitext maps, character level mappings between source and target language documents. These methods use similarity measures at the level of words [Melamed 1996] and character ([Simard et al.1992] and [Church 1993]) to generate points of correspondence in a bitext space. [Melamed 1996] and [Simard et al.1992] then calculate best-fit linear approximations to find a bitext map. These approaches have proven to be highly robust as they are able to process imperfect documents without sacrificing accuracy. <p> These approaches have proven to be highly robust as they are able to process imperfect documents without sacrificing accuracy. TAG-ALIGN uses an extended sentence alignment method similar to [Gale and Church 1991], while incorporating features of the word/character similarity found in [Melamed 1996], <ref> [Simard et al.1992] </ref> and [Church 1993]. Instead of relying on raw sentence length alone, TAG-ALIGN incorporates word alignments generated by its term alignment module in its measure of sentence similarity. <p> Approaches of the latter category rely on similarities in the orthography of words (cognates) to build anchor points in a document. These anchors are then used to compute a best-fit linear approximation for an overall document alignment at the character level (see [Melamed 1996] and <ref> [Simard et al.1992] </ref>) which can then be used to create a word level alignment. Because these methods generally do not require documents to be sectioned, they are quite robust in their ability to handle poorly sectioned data. <p> A promising avenue of inquiry may be to apply these concepts to other existing alignment schemes similar to [Melamed 1996] and <ref> [Simard et al.1992] </ref>. [Melamed 1996] reports that his SIMR/GSA system already benefit from having a lexicon. If a feedback mechanism could be implemented with such a system, even more robust and accurate sentence/word alignments might result.
Reference: [Dagan et al.1993] <author> I. Dagan, K. Church, and W. </author> <title> Gale 1993 Robust Word Alignment for Machine Aided Translation Proceedings of VLC-93, </title> <institution> Columbus, Ohio. </institution>
References-found: 8

