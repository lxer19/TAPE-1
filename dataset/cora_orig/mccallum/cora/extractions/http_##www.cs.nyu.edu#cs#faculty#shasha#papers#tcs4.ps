URL: http://www.cs.nyu.edu/cs/faculty/shasha/papers/tcs4.ps
Refering-URL: http://www.cs.nyu.edu/cs/faculty/shasha/papers/papers.html
Root-URL: http://www.cs.nyu.edu
Title: MOCA A Multiprocessor On-Line Competitive Algorithm for Real-Time System Scheduling  
Author: Gilad Koren Dennis Shasha 
Date: November 14, 1993  
Address: 251 Mercer Street New York, NY 10012-1185  
Affiliation: Department of Computer Science Courant Institute, New York University  
Abstract: We study competitive on-line scheduling in multi-processor real-time environments. In our model, every task has a deadline and a value that it obtains only if it completes by its deadline. A task can be assigned to any processor, all of which are equally powerful. The problem is to design an on-line scheduling algorithm (i.e., one in which the scheduler has no knowledge of a task until it is released) with worst case guarantees as to the total value obtained by the system. We study systems with two or more processors. We present an inherent limit on the best competitive guarantee that any on-line parallel real-time scheduler can give. Then we present a competitive algorithm that achieves a worst case guarantee which is within a small constant factor from the best possible guarantee in many cases. We consider two memory models: a distributed system having a centralized scheduler and a shared memory multiprocessor. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Audsley and A. Burns. </author> <title> Real time system scheduling. </title> <institution> Computer Science Department Technical Report No. YCS134, York University, UK, </institution> <month> Jan. </month> <year> 1990. </year>
Reference-contexts: Static binding of tasks to processors (i.e., no migration) is assumed in [16, 17, 18] while dynamic binding is assumed in [6, 14]. For a survey of scheduling issues for uniprocessor and multiprocessor systems see <ref> [1, 4] </ref>. Mok and Dertouzos [6] showed that in a multiprocessor environment an optimal algorithm must have an a priori knowledge of release times. Hence, no on-line optimal algorithm exists even when the system is underloaded. Locke [15, pp. 124-134] presented heuristics for the multiprocessor environment.
Reference: [2] <author> S. Baruah, G. Koren, D. Mao, B. Mishra, A. Raghunathan, L. Rosier, D. Shasha, and F. Wang. </author> <title> On the competitiveness of on-line task real-time task scheduling. </title> <journal> The Journal of Real-Time Systems, </journal> <volume> 4(2) </volume> <pages> 124-144, </pages> <year> 1992. </year> <booktitle> Conference version appeared in Proceedings of the 12th Real-Time Systems Symposium ,pages 106-115, </booktitle> <address> San Antonio, Texas, </address> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: The goal of the scheduler is to obtain as much value as possible. As in <ref> [2, 3] </ref>, the value density of a task is its value divided by its computation time. The importance ratio of a collection of tasks is the ratio of the largest value density to the smallest value density. For convenience, we normalize the smallest value density to be 1. <p> The smaller the competitive multiplier is, the better the guarantee is. Our goal is to devise on-line algorithms with the best possible worst case performance guarantees; that is, the lowest competitive multiplier possible. For uniprocessor environments with an importance ratio k, Baruah et. al. <ref> [2, 3] </ref> showed a lower bound of (1 + p k) 2 on the best competitive multiplier that any on-line scheduler can have. Wang and Mao [2, 21] first reported an algorithm that achieves this bound when k is 1. <p> For uniprocessor environments with an importance ratio k, Baruah et. al. [2, 3] showed a lower bound of (1 + p k) 2 on the best competitive multiplier that any on-line scheduler can have. Wang and Mao <ref> [2, 21] </ref> first reported an algorithm that achieves this bound when k is 1. <p> Having independently developed an algorithm for the k = 1 case [12], we were forced to use a different algorithmic strategy to achieve an algorithm called D over [11, 13] that meets the Baruah et al. bound for all k. For multiprocessor environments, Wang and Mao <ref> [2, 21] </ref> showed a lower bound of 2 (on the competitive multiplier) and presented an algorithm that achieved this bound for an arbitrary even number of processors, assuming uniform value density and that tasks are released with no slack time 4 . <p> For the "No-Migration" model, a variant of this algorithm, called the Safe-Risky-(fixed), achieves a competitive multiplier of 3. 5 This was already known when tasks have no slack-time <ref> [2, 21] </ref>. 4 3 The Lower Bound We would first like to show that every on-line algorithm has a competitive multiplier of at least k 1 n 1) for a system with n processors and importance ratio of k. <p> Remark 3.2 For n = 1 the lower bound is k which is not as good as the already known tight lower bound of (1 + p k) 2 <ref> [2, 13] </ref>. For k = 1 a different treatment is needed. 4 Algorithmic Guarantees Having proved the lower bound on the best possible competitive multiplier, we would like to devise an on-line scheduler that achieves this bound. <p> The algorithmic guarantee is within a small multiplicative factor 23 Since all the tasks go through the central scheduler this is not difficult to do. 22 number of importance bounds processors ratio lower bound algorithmic comments 1 : any k 1 (1 + k) 2 <ref> [3, 2] </ref> tight [13] tight bound achieved by D over . 2 : 1 2 tight tasks have no slack time and may not : (uniform) migrate between processors [2, 21]. 2 : 1 2 3 [10] tasks may have slack time but may not : (uniform) migrate between processors. 2 <p> do. 22 number of importance bounds processors ratio lower bound algorithmic comments 1 : any k 1 (1 + k) 2 [3, 2] tight [13] tight bound achieved by D over . 2 : 1 2 tight tasks have no slack time and may not : (uniform) migrate between processors <ref> [2, 21] </ref>. 2 : 1 2 3 [10] tasks may have slack time but may not : (uniform) migrate between processors. 2 : 1 2 tight [10] tasks may have slack time and may migrate : (uniform) between processors. n 2 : k &gt; 1 k 1 1 1) z bounds
Reference: [3] <author> S. Baruah, G. Koren, B. Mishra, A. Raghunathan, L. Rosier, and D. Shasha. </author> <title> On-line scheduling in the presence of overload. </title> <booktitle> In Proceedings of the 32nd Annual Symposium on the Foundations of Computer Science, </booktitle> <pages> pages 101-110, </pages> <address> San Juan, Puerto Rico, </address> <month> Oct. </month> <year> 1991. </year> <note> IEEE. </note>
Reference-contexts: The goal of the scheduler is to obtain as much value as possible. As in <ref> [2, 3] </ref>, the value density of a task is its value divided by its computation time. The importance ratio of a collection of tasks is the ratio of the largest value density to the smallest value density. For convenience, we normalize the smallest value density to be 1. <p> A clairvoyant scheduler has complete a priori knowledge of all the parameters of all the tasks. A clairvoyant scheduler can choose a "scheduling sequence" that will obtain the maximum possible value achievable by any scheduler 3 . As in <ref> [3, 9, 13, 19] </ref> we say that an on-line algorithm has a competitive factor r; 0 r 1, if and only if it is guaranteed to achieve a cumulative value of at least r times the cumulative value achievable by a clairvoyant algorithm on any set of tasks. <p> The smaller the competitive multiplier is, the better the guarantee is. Our goal is to devise on-line algorithms with the best possible worst case performance guarantees; that is, the lowest competitive multiplier possible. For uniprocessor environments with an importance ratio k, Baruah et. al. <ref> [2, 3] </ref> showed a lower bound of (1 + p k) 2 on the best competitive multiplier that any on-line scheduler can have. Wang and Mao [2, 21] first reported an algorithm that achieves this bound when k is 1. <p> The algorithmic guarantee is within a small multiplicative factor 23 Since all the tasks go through the central scheduler this is not difficult to do. 22 number of importance bounds processors ratio lower bound algorithmic comments 1 : any k 1 (1 + k) 2 <ref> [3, 2] </ref> tight [13] tight bound achieved by D over . 2 : 1 2 tight tasks have no slack time and may not : (uniform) migrate between processors [2, 21]. 2 : 1 2 3 [10] tasks may have slack time but may not : (uniform) migrate between processors. 2
Reference: [4] <author> S.-C. Cheng, J. A. Stankovic, and K. Ramamritham. </author> <title> Scheduling algorithms for hard real-time systems: A brief survey. </title> <editor> In J. A. Stankovic and K. Ramamritham, editors, </editor> <title> Hard Real-Time Systems: </title> <booktitle> Tutorial, </booktitle> <pages> pages 150-173. </pages> <publisher> IEEE, </publisher> <year> 1988. </year> <month> 25 </month>
Reference-contexts: Static binding of tasks to processors (i.e., no migration) is assumed in [16, 17, 18] while dynamic binding is assumed in [6, 14]. For a survey of scheduling issues for uniprocessor and multiprocessor systems see <ref> [1, 4] </ref>. Mok and Dertouzos [6] showed that in a multiprocessor environment an optimal algorithm must have an a priori knowledge of release times. Hence, no on-line optimal algorithm exists even when the system is underloaded. Locke [15, pp. 124-134] presented heuristics for the multiprocessor environment. <p> When a task is released, its value, computation time and deadline are known precisely. If a task completes before its deadline, then the system acquires its value. Otherwise, the system acquires no value for that task. Following [8, 13], we denote such deadlines as firm. (Other papers <ref> [4] </ref> denote such deadlines as hard. 1 A reasonable assumption since real time kernels are designed to keep all tasks' code and data in memory thereby avoiding paging-induced faults during context switches; also, such kernels are built with short code path lengths. 2 And additional references within. 2 The reader should
Reference: [5] <author> M. L. Dertouzos. </author> <title> Control robotics: the procedural control of physical processes. </title> <booktitle> In Proceedings IFIF Congress, </booktitle> <pages> pages 807-813, </pages> <year> 1974. </year>
Reference-contexts: Tasks that are assigned to a band are guaranteed to complete and can all complete on a single processor. This means that they constitute a uniprocessor underloaded system and can be scheduled according to the earliest-deadline-first algorithm <ref> [5] </ref>. Suppose the new task cannot be added to the band that corresponds to its value density (because it will cause overload at that band). Then the scheduler will determine whether the new task can be scheduled on the next band below (i.e, a band corresponding to lower value density).
Reference: [6] <author> M. L. Dertouzos and A. K.-L. Mok. </author> <title> Multiprocessor on-line scheduling of hard-real-time tasks. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 15(12) </volume> <pages> 1497-1506, </pages> <month> Dec. </month> <year> 1989. </year>
Reference-contexts: In both cases, we assume a centralized scheduler. By "migration" we mean the ability to move a thread that has already begun execution from one processor to another. For both models, we assume that preemption within a processor takes no time 1 (as in <ref> [6, 14] </ref>). Multiprocessor real-time scheduling is an active field of research. Both shared memory [14, 17] and distributed memory [16, 20, 22, 18] architectures have been studied. Static binding of tasks to processors (i.e., no migration) is assumed in [16, 17, 18] while dynamic binding is assumed in [6, 14]. <p> (as in <ref> [6, 14] </ref>). Multiprocessor real-time scheduling is an active field of research. Both shared memory [14, 17] and distributed memory [16, 20, 22, 18] architectures have been studied. Static binding of tasks to processors (i.e., no migration) is assumed in [16, 17, 18] while dynamic binding is assumed in [6, 14]. For a survey of scheduling issues for uniprocessor and multiprocessor systems see [1, 4]. Mok and Dertouzos [6] showed that in a multiprocessor environment an optimal algorithm must have an a priori knowledge of release times. Hence, no on-line optimal algorithm exists even when the system is underloaded. <p> Static binding of tasks to processors (i.e., no migration) is assumed in [16, 17, 18] while dynamic binding is assumed in [6, 14]. For a survey of scheduling issues for uniprocessor and multiprocessor systems see [1, 4]. Mok and Dertouzos <ref> [6] </ref> showed that in a multiprocessor environment an optimal algorithm must have an a priori knowledge of release times. Hence, no on-line optimal algorithm exists even when the system is underloaded. Locke [15, pp. 124-134] presented heuristics for the multiprocessor environment.
Reference: [7] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability: a guide to the theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: In section 5, we analyze the MOCA Algorithm. The paper ends with a brief conclusion and a discussion of some salient open problems. 3 Finding the maximum achievable value for such a scheduler, even in the uniprocessor case, is reducible from the knapsack problem <ref> [7] </ref>; hence is NP-hard. 4 We say that a task has no slack time if the computation time needed to execute the task to completion equals its deadline minus the current time (i.e., such a task must be scheduled immediately in order to complete). 3 2 Summary of Results We present
Reference: [8] <author> J. R. Haritsa, M. J. Carey, and M. Livny. </author> <title> On being optimistic about real-time constraints. </title> <booktitle> In Proceedings of the PODS Conference, </booktitle> <pages> pages 331-343, </pages> <address> Nashville, TN, </address> <month> Apr. </month> <year> 1990. </year> <note> ACM. </note>
Reference-contexts: When a task is released, its value, computation time and deadline are known precisely. If a task completes before its deadline, then the system acquires its value. Otherwise, the system acquires no value for that task. Following <ref> [8, 13] </ref>, we denote such deadlines as firm. (Other papers [4] denote such deadlines as hard. 1 A reasonable assumption since real time kernels are designed to keep all tasks' code and data in memory thereby avoiding paging-induced faults during context switches; also, such kernels are built with short code path
Reference: [9] <author> A. Karlin, M. Manasse, L. Rudolph, and D. Sleator. </author> <title> Competitive snoopy caching. </title> <journal> Algorith-mica, </journal> <volume> 3(1) </volume> <pages> 79-119, </pages> <year> 1988. </year>
Reference-contexts: A clairvoyant scheduler has complete a priori knowledge of all the parameters of all the tasks. A clairvoyant scheduler can choose a "scheduling sequence" that will obtain the maximum possible value achievable by any scheduler 3 . As in <ref> [3, 9, 13, 19] </ref> we say that an on-line algorithm has a competitive factor r; 0 r 1, if and only if it is guaranteed to achieve a cumulative value of at least r times the cumulative value achievable by a clairvoyant algorithm on any set of tasks.
Reference: [10] <author> G. Koren. </author> <title> Competitive On-Line Scheduling for Overloaded Real-Time Systems. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Courant Institute, NYU, </institution> <address> New York, NY, </address> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: i ! + i (k 1) &gt; &gt; &gt; &gt; &gt; &gt; = When n tends to infinity this bound is at most 2 ln k +3, which is within a small multiplicative constant factor from the lower bound for the same system. * Scheduling Algorithms for Two-Processor Systems In <ref> [10] </ref>, we present an algorithm called the Safe-Risky algorithm, for two-processor systems with uniform value density (i.e., n = 2 and k = 1) that achieves the best possible competitive multiplier of 2 even when tasks may have slack time but migration is allowed 5 . <p> This leads to a competitive multiplier of 2 + 1 (when some tasks may have slack time). For n = 2 this corresponds to our results for two processor systems <ref> [10] </ref>. * When the number of processor is odd, a similar result can be obtained. For a system with 2n + 1 processors, create bands and pool from the first 2n processors. The left over processor can be used, for example, as a second SP for one of the bands. <p> ratio lower bound algorithmic comments 1 : any k 1 (1 + k) 2 [3, 2] tight [13] tight bound achieved by D over . 2 : 1 2 tight tasks have no slack time and may not : (uniform) migrate between processors [2, 21]. 2 : 1 2 3 <ref> [10] </ref> tasks may have slack time but may not : (uniform) migrate between processors. 2 : 1 2 tight [10] tasks may have slack time and may migrate : (uniform) between processors. n 2 : k &gt; 1 k 1 1 1) z bounds are tight within constant coefficient for many <p> bound achieved by D over . 2 : 1 2 tight tasks have no slack time and may not : (uniform) migrate between processors [2, 21]. 2 : 1 2 3 <ref> [10] </ref> tasks may have slack time but may not : (uniform) migrate between processors. 2 : 1 2 tight [10] tasks may have slack time and may migrate : (uniform) between processors. n 2 : k &gt; 1 k 1 1 1) z bounds are tight within constant coefficient for many cases.
Reference: [11] <author> G. Koren and D. Shasha. D-over: </author> <title> An optimal on-line scheduling algorithm for overloaded real-time systems. </title> <journal> SIAM Journal on Computing. </journal> <note> to appear. </note>
Reference-contexts: Wang and Mao [2, 21] first reported an algorithm that achieves this bound when k is 1. Having independently developed an algorithm for the k = 1 case [12], we were forced to use a different algorithmic strategy to achieve an algorithm called D over <ref> [11, 13] </ref> that meets the Baruah et al. bound for all k. <p> Our adversary arguments and algorithms offer two useful insights: 1. A parallel on-line scheduling algorithm achieves a competitive guarantee by allocating some processing resources according to tasks' value density. This is a qualitative difference from our uniprocessor scheduling algorithm D over <ref> [11, 13] </ref> which made its decisions based on total value only. Moreover, high value density tasks in the MOCA Algorithm have priority over lower value density tasks in the sense that they have more processors on which they can be scheduled due to the cascading. 2.
Reference: [12] <author> G. Koren and D. Shasha. </author> <title> An optimal scheduling algorithm with a competitive factor for real-time systems. </title> <institution> Computer Science Department Technical Report No. 572, Courant Institute, NYU, </institution> <address> New York, NY, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: Wang and Mao [2, 21] first reported an algorithm that achieves this bound when k is 1. Having independently developed an algorithm for the k = 1 case <ref> [12] </ref>, we were forced to use a different algorithmic strategy to achieve an algorithm called D over [11, 13] that meets the Baruah et al. bound for all k.
Reference: [13] <author> G. Koren and D. Shasha. D-over: </author> <title> An optimal on-line scheduling algorithm for overloaded real-time systems. </title> <booktitle> In Proceedings of the 13th Real-Time Systems Symposium, </booktitle> <pages> pages 290-299, </pages> <address> Phoenix, Arizona, </address> <month> Dec. </month> <year> 1992. </year> <note> IEEE. </note>
Reference-contexts: When a task is released, its value, computation time and deadline are known precisely. If a task completes before its deadline, then the system acquires its value. Otherwise, the system acquires no value for that task. Following <ref> [8, 13] </ref>, we denote such deadlines as firm. (Other papers [4] denote such deadlines as hard. 1 A reasonable assumption since real time kernels are designed to keep all tasks' code and data in memory thereby avoiding paging-induced faults during context switches; also, such kernels are built with short code path <p> A clairvoyant scheduler has complete a priori knowledge of all the parameters of all the tasks. A clairvoyant scheduler can choose a "scheduling sequence" that will obtain the maximum possible value achievable by any scheduler 3 . As in <ref> [3, 9, 13, 19] </ref> we say that an on-line algorithm has a competitive factor r; 0 r 1, if and only if it is guaranteed to achieve a cumulative value of at least r times the cumulative value achievable by a clairvoyant algorithm on any set of tasks. <p> Wang and Mao [2, 21] first reported an algorithm that achieves this bound when k is 1. Having independently developed an algorithm for the k = 1 case [12], we were forced to use a different algorithmic strategy to achieve an algorithm called D over <ref> [11, 13] </ref> that meets the Baruah et al. bound for all k. <p> Remark 3.2 For n = 1 the lower bound is k which is not as good as the already known tight lower bound of (1 + p k) 2 <ref> [2, 13] </ref>. For k = 1 a different treatment is needed. 4 Algorithmic Guarantees Having proved the lower bound on the best possible competitive multiplier, we would like to devise an on-line scheduler that achieves this bound. <p> The algorithmic guarantee is within a small multiplicative factor 23 Since all the tasks go through the central scheduler this is not difficult to do. 22 number of importance bounds processors ratio lower bound algorithmic comments 1 : any k 1 (1 + k) 2 [3, 2] tight <ref> [13] </ref> tight bound achieved by D over . 2 : 1 2 tight tasks have no slack time and may not : (uniform) migrate between processors [2, 21]. 2 : 1 2 3 [10] tasks may have slack time but may not : (uniform) migrate between processors. 2 : 1 2 <p> Our adversary arguments and algorithms offer two useful insights: 1. A parallel on-line scheduling algorithm achieves a competitive guarantee by allocating some processing resources according to tasks' value density. This is a qualitative difference from our uniprocessor scheduling algorithm D over <ref> [11, 13] </ref> which made its decisions based on total value only. Moreover, high value density tasks in the MOCA Algorithm have priority over lower value density tasks in the sense that they have more processors on which they can be scheduled due to the cascading. 2.
Reference: [14] <author> E. L. Lawler and C. U. Martel. </author> <title> Scheduling periodically occurring tasks on multiple processors. </title> <journal> Information Processing Letters, </journal> <volume> 12(1) </volume> <pages> 9-12, </pages> <month> Feb. </month> <year> 1981. </year>
Reference-contexts: In both cases, we assume a centralized scheduler. By "migration" we mean the ability to move a thread that has already begun execution from one processor to another. For both models, we assume that preemption within a processor takes no time 1 (as in <ref> [6, 14] </ref>). Multiprocessor real-time scheduling is an active field of research. Both shared memory [14, 17] and distributed memory [16, 20, 22, 18] architectures have been studied. Static binding of tasks to processors (i.e., no migration) is assumed in [16, 17, 18] while dynamic binding is assumed in [6, 14]. <p> For both models, we assume that preemption within a processor takes no time 1 (as in [6, 14]). Multiprocessor real-time scheduling is an active field of research. Both shared memory <ref> [14, 17] </ref> and distributed memory [16, 20, 22, 18] architectures have been studied. Static binding of tasks to processors (i.e., no migration) is assumed in [16, 17, 18] while dynamic binding is assumed in [6, 14]. For a survey of scheduling issues for uniprocessor and multiprocessor systems see [1, 4]. <p> (as in <ref> [6, 14] </ref>). Multiprocessor real-time scheduling is an active field of research. Both shared memory [14, 17] and distributed memory [16, 20, 22, 18] architectures have been studied. Static binding of tasks to processors (i.e., no migration) is assumed in [16, 17, 18] while dynamic binding is assumed in [6, 14]. For a survey of scheduling issues for uniprocessor and multiprocessor systems see [1, 4]. Mok and Dertouzos [6] showed that in a multiprocessor environment an optimal algorithm must have an a priori knowledge of release times. Hence, no on-line optimal algorithm exists even when the system is underloaded.
Reference: [15] <author> C. D. Locke. </author> <title> Best-Effort Decision Making for Real-Time Scheduling. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Carnegie-Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1986. </year>
Reference-contexts: For a survey of scheduling issues for uniprocessor and multiprocessor systems see [1, 4]. Mok and Dertouzos [6] showed that in a multiprocessor environment an optimal algorithm must have an a priori knowledge of release times. Hence, no on-line optimal algorithm exists even when the system is underloaded. Locke <ref> [15, pp. 124-134] </ref> presented heuristics for the multiprocessor environment. Ramamritham and Stankovic [20] studied the question of scheduling firm deadline tasks in a distributed environment. They proposed a scheduler that assumes, at the design phase, that the system is underloaded for critical tasks.
Reference: [16] <author> A. K.-L. Mok. </author> <title> Fundamental Design Problems of Distributed Systems for the Hard Real-Time Environment. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Science, M.I.T, </institution> <address> Boston, MA, </address> <month> May </month> <year> 1983. </year>
Reference-contexts: For both models, we assume that preemption within a processor takes no time 1 (as in [6, 14]). Multiprocessor real-time scheduling is an active field of research. Both shared memory [14, 17] and distributed memory <ref> [16, 20, 22, 18] </ref> architectures have been studied. Static binding of tasks to processors (i.e., no migration) is assumed in [16, 17, 18] while dynamic binding is assumed in [6, 14]. For a survey of scheduling issues for uniprocessor and multiprocessor systems see [1, 4]. <p> Multiprocessor real-time scheduling is an active field of research. Both shared memory [14, 17] and distributed memory [16, 20, 22, 18] architectures have been studied. Static binding of tasks to processors (i.e., no migration) is assumed in <ref> [16, 17, 18] </ref> while dynamic binding is assumed in [6, 14]. For a survey of scheduling issues for uniprocessor and multiprocessor systems see [1, 4]. Mok and Dertouzos [6] showed that in a multiprocessor environment an optimal algorithm must have an a priori knowledge of release times. <p> We will denote the importance ratio of a collection of tasks by k and will assume throughout the paper that this value is known before a given execution begins. We quantify the performance guarantee of an on-line scheduler by comparing it with a clairvoyant <ref> [16, p. 39] </ref> scheduling algorithm (also called an off-line scheduler). A clairvoyant scheduler has complete a priori knowledge of all the parameters of all the tasks. A clairvoyant scheduler can choose a "scheduling sequence" that will obtain the maximum possible value achievable by any scheduler 3 .
Reference: [17] <author> R. Rajkumar, L. Sha, and J. P. Lehoczky. </author> <title> Real-time synchronization protocols for multiprocessors. </title> <booktitle> In Proceedings of the 9th Real-Time Systems Symposium, </booktitle> <pages> pages 159-269. </pages> <publisher> IEEE, </publisher> <month> Dec. </month> <year> 1988. </year>
Reference-contexts: For both models, we assume that preemption within a processor takes no time 1 (as in [6, 14]). Multiprocessor real-time scheduling is an active field of research. Both shared memory <ref> [14, 17] </ref> and distributed memory [16, 20, 22, 18] architectures have been studied. Static binding of tasks to processors (i.e., no migration) is assumed in [16, 17, 18] while dynamic binding is assumed in [6, 14]. For a survey of scheduling issues for uniprocessor and multiprocessor systems see [1, 4]. <p> Multiprocessor real-time scheduling is an active field of research. Both shared memory [14, 17] and distributed memory [16, 20, 22, 18] architectures have been studied. Static binding of tasks to processors (i.e., no migration) is assumed in <ref> [16, 17, 18] </ref> while dynamic binding is assumed in [6, 14]. For a survey of scheduling issues for uniprocessor and multiprocessor systems see [1, 4]. Mok and Dertouzos [6] showed that in a multiprocessor environment an optimal algorithm must have an a priori knowledge of release times.
Reference: [18] <author> L. Sha and S. S. Sathaye. </author> <title> A systematic approach to designing distributed real-time systems. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 68-78, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: For both models, we assume that preemption within a processor takes no time 1 (as in [6, 14]). Multiprocessor real-time scheduling is an active field of research. Both shared memory [14, 17] and distributed memory <ref> [16, 20, 22, 18] </ref> architectures have been studied. Static binding of tasks to processors (i.e., no migration) is assumed in [16, 17, 18] while dynamic binding is assumed in [6, 14]. For a survey of scheduling issues for uniprocessor and multiprocessor systems see [1, 4]. <p> Multiprocessor real-time scheduling is an active field of research. Both shared memory [14, 17] and distributed memory [16, 20, 22, 18] architectures have been studied. Static binding of tasks to processors (i.e., no migration) is assumed in <ref> [16, 17, 18] </ref> while dynamic binding is assumed in [6, 14]. For a survey of scheduling issues for uniprocessor and multiprocessor systems see [1, 4]. Mok and Dertouzos [6] showed that in a multiprocessor environment an optimal algorithm must have an a priori knowledge of release times.
Reference: [19] <author> D. Sleator and R. Tarjan. </author> <title> Amortized efficiency of list update and paging rules. </title> <journal> Communications of the ACM, </journal> <volume> 28 </volume> <pages> 202-208, </pages> <month> Feb. </month> <year> 1985. </year> <month> 26 </month>
Reference-contexts: A clairvoyant scheduler has complete a priori knowledge of all the parameters of all the tasks. A clairvoyant scheduler can choose a "scheduling sequence" that will obtain the maximum possible value achievable by any scheduler 3 . As in <ref> [3, 9, 13, 19] </ref> we say that an on-line algorithm has a competitive factor r; 0 r 1, if and only if it is guaranteed to achieve a cumulative value of at least r times the cumulative value achievable by a clairvoyant algorithm on any set of tasks.
Reference: [20] <author> J. A. Stankovic and K. Ramamritham. </author> <title> The spring kernel: A new paradigm for real-time systems. </title> <journal> IEEE software, </journal> <pages> pages 62-72, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: For both models, we assume that preemption within a processor takes no time 1 (as in [6, 14]). Multiprocessor real-time scheduling is an active field of research. Both shared memory [14, 17] and distributed memory <ref> [16, 20, 22, 18] </ref> architectures have been studied. Static binding of tasks to processors (i.e., no migration) is assumed in [16, 17, 18] while dynamic binding is assumed in [6, 14]. For a survey of scheduling issues for uniprocessor and multiprocessor systems see [1, 4]. <p> Mok and Dertouzos [6] showed that in a multiprocessor environment an optimal algorithm must have an a priori knowledge of release times. Hence, no on-line optimal algorithm exists even when the system is underloaded. Locke [15, pp. 124-134] presented heuristics for the multiprocessor environment. Ramamritham and Stankovic <ref> [20] </ref> studied the question of scheduling firm deadline tasks in a distributed environment. They proposed a scheduler that assumes, at the design phase, that the system is underloaded for critical tasks. The non-critical tasks are scheduled dynamically and heuristically using any surplus processing power.
Reference: [21] <author> F. Wang and D. Mao. </author> <title> Worst case analysis for on-line scheduling in real-time systems. </title> <institution> Department of Computer and Information Science Technical Report No. 91-54, University of Massachusetts, </institution> <address> Amherst, MA, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: For uniprocessor environments with an importance ratio k, Baruah et. al. [2, 3] showed a lower bound of (1 + p k) 2 on the best competitive multiplier that any on-line scheduler can have. Wang and Mao <ref> [2, 21] </ref> first reported an algorithm that achieves this bound when k is 1. <p> Having independently developed an algorithm for the k = 1 case [12], we were forced to use a different algorithmic strategy to achieve an algorithm called D over [11, 13] that meets the Baruah et al. bound for all k. For multiprocessor environments, Wang and Mao <ref> [2, 21] </ref> showed a lower bound of 2 (on the competitive multiplier) and presented an algorithm that achieved this bound for an arbitrary even number of processors, assuming uniform value density and that tasks are released with no slack time 4 . <p> For the "No-Migration" model, a variant of this algorithm, called the Safe-Risky-(fixed), achieves a competitive multiplier of 3. 5 This was already known when tasks have no slack-time <ref> [2, 21] </ref>. 4 3 The Lower Bound We would first like to show that every on-line algorithm has a competitive multiplier of at least k 1 n 1) for a system with n processors and importance ratio of k. <p> do. 22 number of importance bounds processors ratio lower bound algorithmic comments 1 : any k 1 (1 + k) 2 [3, 2] tight [13] tight bound achieved by D over . 2 : 1 2 tight tasks have no slack time and may not : (uniform) migrate between processors <ref> [2, 21] </ref>. 2 : 1 2 3 [10] tasks may have slack time but may not : (uniform) migrate between processors. 2 : 1 2 tight [10] tasks may have slack time and may migrate : (uniform) between processors. n 2 : k &gt; 1 k 1 1 1) z bounds
Reference: [22] <author> H. Zhou, K. Schwan, and I. F. Akyildiz. </author> <title> Performance effects of information sharing in a distributed multiprocessor real-time scheduler. </title> <booktitle> In Proceedings of the 13th Real-Time Systems Symposium, </booktitle> <pages> pages 46-55, </pages> <address> Phoenix, Arizona, </address> <month> Dec. </month> <year> 1992. </year> <journal> IEEE. </journal> <volume> 27 </volume>
Reference-contexts: For both models, we assume that preemption within a processor takes no time 1 (as in [6, 14]). Multiprocessor real-time scheduling is an active field of research. Both shared memory [14, 17] and distributed memory <ref> [16, 20, 22, 18] </ref> architectures have been studied. Static binding of tasks to processors (i.e., no migration) is assumed in [16, 17, 18] while dynamic binding is assumed in [6, 14]. For a survey of scheduling issues for uniprocessor and multiprocessor systems see [1, 4]. <p> The non-critical tasks are scheduled dynamically and heuristically using any surplus processing power. Our algorithm could be used for the non-critical tasks in their environment. Zhou et. al. presented an on-line algorithm <ref> [22] </ref> 2 for distributed real-time systems. Our model resembles theirs but our goal is to give worst case guarantees for value obtained (even for overloaded systems) while their goal is to generate a schedule efficiently when the system is underloaded (i.e, all tasks can be scheduled). <p> Once a task is assigned to a band it is left in the hands of the local scheduler (which basically employs earliest-deadline-first). It is desirable for reasons of fault-tolerant and efficiency <ref> [22] </ref> to distribute the functionality of the centralized scheduler among the processors even further. This is an interesting and important extension to the work presented here. 5.3 The Scheduling Overhead In the previous sections we analyzed the performance of our algorithm in the sense of their competitive multipliers.
References-found: 22

