URL: http://www.cs.pitt.edu/~moir/Papers/anderson-moir-tpds97.ps
Refering-URL: http://www.cs.pitt.edu/~moir/papers.html
Root-URL: 
Title: Universal Constructions for Large Objects  
Author: James H. Anderson Mark Moir 
Keyword: concurrency, lock-free, non-blocking synchronization, shared objects, wait-free.  
Date: June 1997  
Address: Chapel Hill, NC 27599  Pittsburgh Pittsburgh, PA 15260  
Affiliation: Department of Computer Science The University of North Carolina  Department of Computer Science The University of  
Abstract: We present lock-free and wait-free universal constructions for implementing large shared objects. Most previous universal constructions require processes to copy the entire object state, which is impractical for large objects. Previous attempts to address this problem require programmers to explicitly fragment large objects into smaller, more manageable pieces, paying particular attention to how such pieces are copied. In contrast, our constructions are designed to largely shield programmers from this fragmentation. Furthermore, for many objects, our constructions result in lower copying overhead than previous ones. Fragmentation is achieved in our constructions through the use of load-linked, store-conditional, and validate operations on a "large" multi-word shared variable. Before presenting our constructions, we show that these operations can be efficiently implemented from similar one-word primitives. fl Work supported by NSF grants CCR 9216421 and CCR 9510156, and by a Young Investigator Award from the U.S. Army Research Office, grant number DAAH04-95-1-0323. The first author was also supported by an Alfred P. Sloan research fellowship. The second author was also supported by a UNC Alumni Fellowship, by an NSF CAREER Award, CCR 9702767, and by an ORAU Junior Faculty Enhancement Award. A preliminary version of this work appeared in the Proceedings of the Ninth International Workshop on Distributed Algorithms, September 1995. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Anderson and M. Moir, </author> <title> "Universal Constructions for Multi-Object Operations", </title> <booktitle> to appear in the Proceedings of the 14th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1995. </year>
Reference-contexts: This large variable is stored across several memory words. 1 In the first part of the paper, we show how to efficiently implement 1 The multi-word operations considered here access a single variable that spans multiple words. Thus, they are not the same as the multi-word operations considered in <ref> [1, 3, 7, 11] </ref>, which access multiple variables, each stored in a separate word. The 2 these operations using the usual single-word LL, SC, and VL primitives. <p> We assume that the SC operation does not fail spuriously. As shown in <ref> [1, 9] </ref>, algorithms based on these assumptions are applicable in machines that provide either compare-and-swap, or a limited form of LL and SC that is commonly available in hardware. The semantics of LL, VL, and SC are shown by equivalent code fragments below. <p> N is the total number of processes. The semantics of VL and SC are undefined if process p has not executed a LL instruction since p's most recent SC. multi-word operations we consider admit simpler and more efficient implementations than those considered in <ref> [1, 3, 7, 11] </ref>. 3 The correctness condition used in the proof presented in [8] is that of linearizability [4]. <p> To ensure that a SC operation does not overwrite the contents of the current buffer, the SC operations of each process p alternate between two buffers, BUF [p; 0] and BUF <ref> [p; 1] </ref>. To see why this ensures that the current buffer is not overwritten, observe that, if BUF [p; 0] is the current buffer, then process p will attempt a SC operation using BUF [p; 1] before it modifies BUF [p; 0] again. <p> the SC operations of each process p alternate between two buffers, BUF [p; 0] and BUF <ref> [p; 1] </ref>. To see why this ensures that the current buffer is not overwritten, observe that, if BUF [p; 0] is the current buffer, then process p will attempt a SC operation using BUF [p; 1] before it modifies BUF [p; 0] again. If p's SC succeeds, then BUF [p; 0] is no longer the current buffer. If p's SC fails, then some other process has performed a successful SC, which also implies that BUF [p; 0] is no longer the current buffer. <p> Because sequential object code must call these procedures, our constructions are not completely transparent to the sequential object designer. For example, instead of writing "MEM <ref> [1] </ref> := MEM [10]", the designer would write "Write (1; Read (10))". As a more concrete example, consider Figure 3, which contains the actual code we used to implement a FIFO queue using our constructions. <p> The bit field of ANC is 0 for both processes, and the applied and copied fields of the current return block are also 0. This indicates that neither process has an outstanding operation. Also, process 0's return block is RET [0], and process 1's is RET <ref> [1] </ref>. written its operation and parameters to ANC [0] and has incremented ANC [0].bit (line 19). Process 0 has also copied the current return block into its own return block, performed its own operation, and made its own return block current. <p> We would like to extend our constructions to allow such parallel execution where possible. For example, in our shared queue implementations, an enqueue operation might unnecessarily interfere with a dequeue operation. In <ref> [1] </ref>, we addressed similar concerns when implementing wait-free operations on multiple objects. More recently, Moir has developed new lock-free and wait-free constructions that support general transactions and allow parallel execution of transactions that do not conflict with each other [10].
Reference: [2] <author> J. Anderson and M. Moir, </author> <title> "Universal Constructions for Large Objects", </title> <booktitle> Proceedings of the Ninth Inter national Workshop on Distributed Algorithms, </booktitle> <year> 1995, </year> <pages> pp. 168-182. </pages>
Reference-contexts: For these reasons, we use weak-LL in our universal constructions. (Elsewhere, we have presented a similar implementation that provides the "normal" semantics for the LL operation <ref> [2] </ref>. That implementation is less efficient and requires more space than the one presented here.) To avoid the excessive space requirements of previous wait-free universal constructions, our wait-free construction imposes an upper bound on the number of private blocks each process may have. <p> Figure 8 (a) shows ANC and the RET blocks in the initial state. (In the example there are two processes, so there are three RET blocks.) In this state, the current return block is RET <ref> [2] </ref>, as indicated by BANK.ret. The bit field of ANC is 0 for both processes, and the applied and copied fields of the current return block are also 0. This indicates that neither process has an outstanding operation. <p> its own operation, it writes the value from the bit field of its ANC entry to its copied field in the current return block (line 45). (This is not really necessary; it was included only to simplify the correctness proof.) Process 0 has also reclaimed the previous return block (RET <ref> [2] </ref>) as its own return block for use in subsequent operations. and performed its own operation, and replaced the current return block with an appropriately modified copy. <p> In this case, however, process 0 has also detected that process 1 has an outstanding enqueue (h) operation (by seeing that ANC [1]:bit 6= RET [0][1]:applied), and has performed this operation on behalf of process 1. As a result, process 1's entry in the new current return block (RET <ref> [2] </ref>) contains a return value for the enqueue operation, and also contains 1 in the applied field. Finally, Figure 8 (d) shows the result of process 0 executing another enqueue operation, this time with a parameter of j. <p> To see why two bits are needed to detect whether q's operation is complete, consider the two scenarios shown in Figure 9. In this figure, process 0 performs three operations. In the first operation, process 0's SC is successful, and process 0 replaces RET <ref> [2] </ref> with RET [0] as the current return block at line 51. In Scenario 1, process 1 starts an operation during process 0's first operation. However, process 1 starts this operation too late to be helped by process 0. <p> In Scenario 1, process 1 starts an operation during process 0's first operation. However, process 1 starts this operation too late to be helped by process 0. Before process 0's execution of line 51, process 1 determines that RET <ref> [2] </ref> is the current return block (line 23). Now, process 0 starts a second operation. Because process 0 previously replaced RET [2] as the current return block, RET [2] is now process 0's private return block, so its second operation uses RET [2] to record the operations it helps. <p> However, process 1 starts this operation too late to be helped by process 0. Before process 0's execution of line 51, process 1 determines that RET <ref> [2] </ref> is the current return block (line 23). Now, process 0 starts a second operation. Because process 0 previously replaced RET [2] as the current return block, RET [2] is now process 0's private return block, so its second operation uses RET [2] to record the operations it helps. Process 0 changes process 1's applied bit to indicate that it has applied process 1's operation (line 18). <p> Before process 0's execution of line 51, process 1 determines that RET <ref> [2] </ref> is the current return block (line 23). Now, process 0 starts a second operation. Because process 0 previously replaced RET [2] as the current return block, RET [2] is now process 0's private return block, so its second operation uses RET [2] to record the operations it helps. Process 0 changes process 1's applied bit to indicate that it has applied process 1's operation (line 18). <p> of line 51, process 1 determines that RET <ref> [2] </ref> is the current return block (line 23). Now, process 0 starts a second operation. Because process 0 previously replaced RET [2] as the current return block, RET [2] is now process 0's private return block, so its second operation uses RET [2] to record the operations it helps. Process 0 changes process 1's applied bit to indicate that it has applied process 1's operation (line 18). <p> Note that, at this stage, process 1's operation has only been applied to process 0's 13 private object copy, and process 0 has not yet performed its SC. However, if process 1 reads the applied field of RET <ref> [2] </ref> at line 22 instead of the copied field, then it incorrectly concludes that its operation has been applied to the object, and terminates prematurely. (Note that process 1 previously determined RET [2] to be the current return block.) In the linearizability proof presented in [8], each operation is linearized to <p> However, if process 1 reads the applied field of RET <ref> [2] </ref> at line 22 instead of the copied field, then it incorrectly concludes that its operation has been applied to the object, and terminates prematurely. (Note that process 1 previously determined RET [2] to be the current return block.) In the linearizability proof presented in [8], each operation is linearized to the successful SC that completes the operation. Therefore, the premature termination of process 1 would violate linearizability.
Reference: [3] <author> G. Barnes, </author> <title> "A Method for Implementing Lock-Free Shared Data Structures", </title> <booktitle> Proceedings of the Fifth Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1993, </year> <pages> pp. 261-270. </pages>
Reference-contexts: This large variable is stored across several memory words. 1 In the first part of the paper, we show how to efficiently implement 1 The multi-word operations considered here access a single variable that spans multiple words. Thus, they are not the same as the multi-word operations considered in <ref> [1, 3, 7, 11] </ref>, which access multiple variables, each stored in a separate word. The 2 these operations using the usual single-word LL, SC, and VL primitives. <p> N is the total number of processes. The semantics of VL and SC are undefined if process p has not executed a LL instruction since p's most recent SC. multi-word operations we consider admit simpler and more efficient implementations than those considered in <ref> [1, 3, 7, 11] </ref>. 3 The correctness condition used in the proof presented in [8] is that of linearizability [4].
Reference: [4] <author> M. Herlihy and J. Wing, </author> <title> "Linearizability: A Correctness Condition for Concurrent Objects", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(3), </volume> <year> 1990, </year> <pages> pp. 463-492. </pages>
Reference-contexts: SC are undefined if process p has not executed a LL instruction since p's most recent SC. multi-word operations we consider admit simpler and more efficient implementations than those considered in [1, 3, 7, 11]. 3 The correctness condition used in the proof presented in [8] is that of linearizability <ref> [4] </ref>. A linearizable implementation ensures that, in every run, the partial order over operations 2 can be extended to a total order that is consistent with the sequential semantics of the implemented object.
Reference: [5] <author> M. Herlihy, </author> <title> "Wait-Free Synchronization", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 13, No. 1, </volume> <year> 1991, </year> <pages> pp. 124-149. </pages>
Reference-contexts: 1 Introduction This paper extends recent research on universal lock-free and wait-free constructions of shared objects <ref> [5, 6] </ref>. An object implementation is wait-free if every operation by each process is guaranteed to complete after a finite number of steps of that process. An object implementation is lock-free if some operation is guaranteed to complete after a finite number of steps of any operation.
Reference: [6] <author> M. Herlihy, </author> <title> "A Methodology for Implementing Highly Concurrent Data Objects", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 15, No. 5, </volume> <year> 1993, </year> <pages> pp. 745-770. </pages>
Reference-contexts: 1 Introduction This paper extends recent research on universal lock-free and wait-free constructions of shared objects <ref> [5, 6] </ref>. An object implementation is wait-free if every operation by each process is guaranteed to complete after a finite number of steps of that process. An object implementation is lock-free if some operation is guaranteed to complete after a finite number of steps of any operation. <p> In this paper, we address this shortcoming by presenting universal constructions that can be used to implement large objects with low space overhead. We take as our starting point the lock-free and wait-free universal constructions presented by Herlihy in <ref> [6] </ref>. In these constructions, operations are implemented using retry loops. <p> The overall structure of our helping mechanism is the same as Herlihy's helping mechanism <ref> [6] </ref>. Specifically, helping is achieved by having each process p announce its operation in ANC [p] before entering a loop that attempts to perform its own operation, possibly together with the operations of other processes. <p> It is interesting to note that our wait-free construction outperforms our lock-free one. We believe that this is because the cost of recopying blocks in the event that a SC fails dominates the cost of helping. In Herlihy's performance experiments on small objects <ref> [6] </ref>, exponential backoff played an important role in improving performance. Exponential backoff is implemented by introducing a random delay after each failed SC operation. The length of this delay is chosen from a uniform, random distribution between zero and a maximum delay. <p> The queue represents an extreme case, for which Herlihy's construction necessarily copies the entire object, while ours do not. To consider an object more favorable to Herlihy's constructions, we also implemented a skew heap | the object considered by Herlihy in <ref> [6] </ref>. Skew heap operations usually modify only a few nodes near the root of a tree, and therefore avoid the long copying chains exhibited by Herlihy's construction when used to implement a queue.
Reference: [7] <author> A. Israeli and L. Rappoport, </author> <title> "Disjoint-Access-Parallel Implementations of Strong Shared Memory Prim itives", </title> <booktitle> Proceedings of the 13th Annual ACM Symposium on Principles of Distributed Computing , ACM, </booktitle> <address> New York, </address> <month> August </month> <year> 1994, </year> <pages> pp. 151-160. </pages>
Reference-contexts: This large variable is stored across several memory words. 1 In the first part of the paper, we show how to efficiently implement 1 The multi-word operations considered here access a single variable that spans multiple words. Thus, they are not the same as the multi-word operations considered in <ref> [1, 3, 7, 11] </ref>, which access multiple variables, each stored in a separate word. The 2 these operations using the usual single-word LL, SC, and VL primitives. <p> N is the total number of processes. The semantics of VL and SC are undefined if process p has not executed a LL instruction since p's most recent SC. multi-word operations we consider admit simpler and more efficient implementations than those considered in <ref> [1, 3, 7, 11] </ref>. 3 The correctness condition used in the proof presented in [8] is that of linearizability [4].
Reference: [8] <author> M. Moir, </author> <title> Efficient Object Sharing in Shared-Memory Multiprocessors, </title> <type> Ph.D. thesis, </type> <institution> University of North Carolina at Chapel Hill, </institution> <year> 1996. </year>
Reference-contexts: Finally, we discuss performance results in Section 6, and end the paper with concluding remarks in Section 7. Most of the algorithms we present are rather intuitive, so formal proofs have been omitted. For full proofs, the interested reader is refered to <ref> [8] </ref>. Although we do not give formal proofs here, our algorithm descriptions do walk through most of the important cases that arise in the proofs. 2 Preliminaries Our algorithms are designed for use in shared-memory multiprocessors that provide load-linked (LL), validate (VL), and store-conditional (SC) instructions. <p> The semantics of VL and SC are undefined if process p has not executed a LL instruction since p's most recent SC. multi-word operations we consider admit simpler and more efficient implementations than those considered in [1, 3, 7, 11]. 3 The correctness condition used in the proof presented in <ref> [8] </ref> is that of linearizability [4]. A linearizable implementation ensures that, in every run, the partial order over operations 2 can be extended to a total order that is consistent with the sequential semantics of the implemented object. <p> As mentioned above, this copy is made by process q in line 27. In the correctness proof in <ref> [8] </ref>, it is shown that, if pr's applied field in this copy is different to that in the current return block, then q's subsequent SC will fail, so q will not incorrectly apply an operation.) If these two fields are different, then q performs pr's operation (line 16), records the return <p> the applied field of RET [2] at line 22 instead of the copied field, then it incorrectly concludes that its operation has been applied to the object, and terminates prematurely. (Note that process 1 previously determined RET [2] to be the current return block.) In the linearizability proof presented in <ref> [8] </ref>, each operation is linearized to the successful SC that completes the operation. Therefore, the premature termination of process 1 would violate linearizability. As explained below, the use of the second field (copied ) prevents this from happening.
Reference: [9] <author> M. Moir, </author> <title> "Practical Implementations of Synchronization Primitives", </title> <booktitle> to appear in the 16th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <month> August </month> <year> 1997. </year>
Reference-contexts: We assume that the SC operation does not fail spuriously. As shown in <ref> [1, 9] </ref>, algorithms based on these assumptions are applicable in machines that provide either compare-and-swap, or a limited form of LL and SC that is commonly available in hardware. The semantics of LL, VL, and SC are shown by equivalent code fragments below.
Reference: [10] <author> M. Moir, </author> <title> "Transparent Support for Wait-Free Transactions", </title> <booktitle> to appear in the 11th Annual International Workshop on Distributed Algorithms, </booktitle> <month> September </month> <year> 1997. </year>
Reference-contexts: Because sequential object code must call these procedures, our constructions are not completely transparent to the sequential object designer. For example, instead of writing "MEM [1] := MEM <ref> [10] </ref>", the designer would write "Write (1; Read (10))". As a more concrete example, consider Figure 3, which contains the actual code we used to implement a FIFO queue using our constructions. As seen in the figure, this code is very similar to the "normal" sequential code for a queue. <p> In [1], we addressed similar concerns when implementing wait-free operations on multiple objects. More recently, Moir has developed new lock-free and wait-free constructions that support general transactions and allow parallel execution of transactions that do not conflict with each other <ref> [10] </ref>. While these constructions do allow parallelism, they are somewhat more complicated than the 17 constructions presented here. <p> No performance studies have yet been conducted using the constructions presented in <ref> [10] </ref>. Acknowledgement: We would like to thank Lars Nyland for his help with the performance studies in Section 6.
Reference: [11] <author> N. Shavit and D. Touitou, </author> <title> "Software Transactional Memory", </title> <booktitle> Proceedings of the 14th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1995, </year> <pages> pp. 204-213. 18 </pages>
Reference-contexts: This large variable is stored across several memory words. 1 In the first part of the paper, we show how to efficiently implement 1 The multi-word operations considered here access a single variable that spans multiple words. Thus, they are not the same as the multi-word operations considered in <ref> [1, 3, 7, 11] </ref>, which access multiple variables, each stored in a separate word. The 2 these operations using the usual single-word LL, SC, and VL primitives. <p> N is the total number of processes. The semantics of VL and SC are undefined if process p has not executed a LL instruction since p's most recent SC. multi-word operations we consider admit simpler and more efficient implementations than those considered in <ref> [1, 3, 7, 11] </ref>. 3 The correctness condition used in the proof presented in [8] is that of linearizability [4].
References-found: 11

