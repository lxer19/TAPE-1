URL: http://www.cs.tamu.edu/research/robotics/Skubic/Papers/forum.ps.gz
Refering-URL: http://www.cs.tamu.edu/research/robotics/Skubic/Papers/marge_bib.html
Root-URL: http://www.cs.tamu.edu
Title: Fuzzy Classification of Contact Formations from Sensor Patterns  
Author: Marjorie Skubic and Richard A. Volz 
Address: College Station, TX 77843-3112  
Affiliation: Department of Computer Science Texas A&M University  
Abstract: This paper presents a pattern recognition approach to identifying contact formations from force sensor signals. The approach is sensor-based and does not use geometric models of the workpieces. The design of a fuzzy classifier is described, where membership functions are generated automatically from training data. The technique is demonstrated using supervised learning. Test results are included for experiments using both rigid and non-rigid workpieces. The technique is discussed in the context of robot programming by human demonstration. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Asada and H. Izumi. </author> <title> Automatic program generation from teaching data for the hybrid control of robots. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 5(2) </volume> <pages> 166-173, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: Capabilities could be expanded with the use of force-based skills. While not yet coupled with vision, force signals have been incorporated into programming by demonstration (PbD) systems, to learn compliant task strategies for assembly operations (e.g., <ref> [2, 1] </ref>). Although progress has been made, the methodology has thus far been restricted to using simple workpieces and limited motions, such as no rotational movement.
Reference: [2] <author> Nathan Delson and Harry West. </author> <title> Robot programming by human demonstration: Subtask compliance controller identification. In Proceedings of the 1993 IEEE/RSJ International Conference on International Conference on Intelligent Robots 2 During the demonstration, visual feedback of force and moment data was provided to the operator in the form of a graphics display. </title> <booktitle> and Systems, </booktitle> <pages> pages 33-41, </pages> <address> Yokohama, Japan, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: Capabilities could be expanded with the use of force-based skills. While not yet coupled with vision, force signals have been incorporated into programming by demonstration (PbD) systems, to learn compliant task strategies for assembly operations (e.g., <ref> [2, 1] </ref>). Although progress has been made, the methodology has thus far been restricted to using simple workpieces and limited motions, such as no rotational movement.
Reference: [3] <author> K. Hara and R. Yokogawa. </author> <title> Recognition of state in peg-in-hole by fuzzy schema. </title> <journal> Journal of Advanced Automation Technology, </journal> <volume> 4(3) </volume> <pages> 134-139, </pages> <year> 1992. </year>
Reference-contexts: In this paper, we present a sensor-based scheme for identifying contact formations which does not use geometric models of the workpieces. In contrast to the method used in [8], our method is based on a quasi-static contact condition. Similar to the approach used in <ref> [3] </ref>, our method uses fuzzy logic to model and recognize the sensory patterns and also resolve the inherent ambiguities. In addition to its pattern recognition strengths, fuzzy logic provides a linguistic interface to the human demonstrator, which makes it particularly well-suited to the PbD method.
Reference: [4] <author> Shinichi Hirai and Kazuaki Iwata. </author> <title> Recognition of contact state based on geometric model. </title> <booktitle> In Proceedings of the 1992 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 1507-1512, </pages> <address> Nice, France, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: However, the current methods used to identify the discrete contact states require a geometric model fl This work has been supported by NSF under grants CDA-9115123, CDA-9422123, and EID-9017249 and by the State of Texas under TATP grants 999903-267 and 999903-095. of the workpieces (e.g., <ref> [4, 6] </ref> and often ignore uncertainty and friction. In this paper, we present a sensor-based scheme for identifying contact formations which does not use geometric models of the workpieces. In contrast to the method used in [8], our method is based on a quasi-static contact condition. <p> learned from the training data and encapsulated in a form that can be used later for automatic program generation as well as for control during program execution. 2.1 Contact Formation Patterns The set of force and moment vectors that comprise all possible vectors for a given CF form a cone <ref> [4] </ref>, which reflects the motion constraints existing between Contact Formations the objects in a given CF. Figures 1 and 2 shows example force and moment patterns for several measurements on 2 vertex-to-surface contact formations. This data was collected using a small plastic block in contact with a flat plate. <p> Each class represents a unique CF. An example is the classifier developed by Hirai et al, which uses a geometric model to build polyhedral convex cones that approximate the sensory patterns <ref> [4] </ref>. We propose, as a sensor-based pattern classifier, the use of fuzzy logic. Empirical training data, instead of geometric models, is used to learn the sensory patterns. Fuzzy membership functions are used to represent the patterns.
Reference: [5] <author> S.B. Kang and K. </author> <title> Ikeuchi. Toward automatic robot instruction from perception- temporal segmentation of tasks from human hand motion. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 11(5) </volume> <pages> 670-681, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: The method provides a natural approach to human-robot interaction and at the same time, avoids much of the computational complexity found in model-based program generation. Vision-based systems have been proposed and developed, which strive to extract an assembly plan from human demonstrators <ref> [10, 5] </ref>. While useful for observing high-level task information, vision has so far not proven adequate for observing intricate assembly operations. Capabilities could be expanded with the use of force-based skills.
Reference: [6] <author> Kosei Kitagaki, Tsukasa Ogasawara, and Takashi Suehiro. </author> <title> Methods to detect contact state by force sensing in an edge mating task. </title> <booktitle> In Proceedings of the 1993 IEEE International Conference on Robotics and Automation, </booktitle> <volume> volume 2, </volume> <pages> pages 701-706, </pages> <address> Atlanta, GA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: However, the current methods used to identify the discrete contact states require a geometric model fl This work has been supported by NSF under grants CDA-9115123, CDA-9422123, and EID-9017249 and by the State of Texas under TATP grants 999903-267 and 999903-095. of the workpieces (e.g., <ref> [4, 6] </ref> and often ignore uncertainty and friction. In this paper, we present a sensor-based scheme for identifying contact formations which does not use geometric models of the workpieces. In contrast to the method used in [8], our method is based on a quasi-static contact condition.
Reference: [7] <author> Kazuhiro Kosuge, Toshio Fukuda, and Haruhiko Asada. </author> <title> Acquisition of human skills for robotic systems. </title> <booktitle> In Proceedings of the 1991 IEEE International Symposium on Intelligent Control, </booktitle> <pages> pages 469-474, </pages> <address> Arlington, VA, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: In this way, the learning process can be simplified and the learned program should be more robust to discrepancies in position and orientation. The utility of this approach was demonstrated in <ref> [7] </ref>.
Reference: [8] <author> Brenan J. McCarragher. </author> <title> Force sensing from human demonstration using a hybrid dynamical model and qualitative reasoning. </title> <booktitle> In Proceedings of the 1994 IEEE International Conference on Robotics and Automation, </booktitle> <volume> volume 1, </volume> <pages> pages 557-563, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: In this paper, we present a sensor-based scheme for identifying contact formations which does not use geometric models of the workpieces. In contrast to the method used in <ref> [8] </ref>, our method is based on a quasi-static contact condition. Similar to the approach used in [3], our method uses fuzzy logic to model and recognize the sensory patterns and also resolve the inherent ambiguities. <p> In the future, we intend to use the commercially available PHANToM to provide haptic feedback during the demonstration process. To increase the success of CF classification, we intend to combine our fuzzy classifier with other methods, such as that proposed by McCarragher <ref> [8] </ref>. Another idea is to add task context information, to help in resolving ambiguities. Task context could be provided in the form of a graph or petri net which holds the feasible sequences of CF's.
Reference: [9] <author> Marjorie Skubic and Richard A. Volz. </author> <title> Identifying contact formations from sensory patterns and its applicability to robot programming by demonstration. </title> <booktitle> In Proceedings of the 1996 IEEE/RSJ International Conference on International Conference on Intelligent Robots and Systems, </booktitle> <address> Os-aka, Japan, </address> <month> November </month> <year> 1996. </year>
Reference-contexts: Training Data Is Shown with the Generated Membership Function (right) where n is the number of membership functions to be combined. See <ref> [9] </ref> for more details. The combination of the 6 feature membership functions is interpreted as the possibility (i.e., a fuzzy number in [0,1]) of this sensor data set being in the specified class. Possibility values are calculated for each class; the highest possibility number represents the identified CF class. <p> The training data and test data was acquired Functions for Edge 1 (left) and Edge 3 (right) with the robot stationary and an operator moving the environment. 3.1 Classifier Results Three tests are described here; the results are summarized in Table 1. More test results are given in <ref> [9] </ref>. The first test used a square plastic block with 12 CF classes. Each CF consisted of a specified portion of the block making contact with a planar surface (the environment). The success ratio was 94%. Test 2 used a pentagon-shaped plastic block.
Reference: [10] <author> Y.Kuniyoshi, M. Inaba, and H. Inoue. </author> <title> Learning by watching: Extracting reusable task knowledge from visual observation of human performance. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 10(6) </volume> <pages> 799-822, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: The method provides a natural approach to human-robot interaction and at the same time, avoids much of the computational complexity found in model-based program generation. Vision-based systems have been proposed and developed, which strive to extract an assembly plan from human demonstrators <ref> [10, 5] </ref>. While useful for observing high-level task information, vision has so far not proven adequate for observing intricate assembly operations. Capabilities could be expanded with the use of force-based skills.
References-found: 10

