URL: http://www.cs.purdue.edu/homes/spa/papers/random98-kmp.ps
Refering-URL: http://www.cs.purdue.edu/homes/spa/publications.html
Root-URL: http://www.cs.purdue.edu
Phone: 2  
Title: Complexity of Sequential Pattern Matching Algorithms  
Author: Mireille Regnier and Wojciech Szpankowski 
Note: Moore algorithm does not possess this property).  
Address: Rocquencourt, 78153 Le Chesnay Cedex, FRANCE  W. Lafayette, IN 47907, USA  
Affiliation: 1 INRIA,  Dept. Computer Science, Purdue University,  
Abstract: We formally define a class of sequential pattern matching algorithms that includes all variations of Morris-Pratt algorithm. For the last twenty years it was known that the complexity of such algorithms is bounded by a linear function of the text length. Recently, substantial progress has been made in identifying lower bounds. We now prove there exists asymptotically a linearity constant for the worst and the average cases. We use Subadditive Ergodic Theorem and prove an almost sure convergence. Our results hold for any given pattern and text and for stationary ergodic pattern and text. In the course of the proof, we establish some structural property, namely, the existence of "unavoidable positions" where the algorithm must stop to compare. This property seems to be uniquely reserved for Morris-Pratt type algorithms (e.g., Boyer and 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> A. Apostolico and R. Giancarlo, </author> <title> The Boyer-Moore-Galil String Searching Strategies Revisited, </title> <journal> SIAM J. Compt., </journal> <volume> 15, </volume> <pages> 98-105, </pages> <year> 1986. </year>
Reference-contexts: 1 Introduction The complexity of string searching algorithms has been discussed in various papers (cf. <ref> [1, 6, 7, 8, 9, 12, 18] </ref>). It is well known that most pattern matching algorithms perform linearly in the worst case as well as "on average". Several attempts have been made to provide tight bounds on the so-called "linearity constant".
Reference: 2. <author> R. Baeza-Yates and M. Regnier, </author> <title> Average Running Time of Boyer-Moore-Horspool Algorithm, </title> <journal> Theoretical Computer Science, </journal> <volume> 92, </volume> <pages> 19-31, </pages> <year> 1992. </year>
Reference-contexts: Sequential algorithms include the naive one and several variants of Morris-Pratt algorithm [16]. These algorithms never go backward, work by comparisons, and are easy to implement. They perform better than Boyer-Moore like algorithms in numerous cases, e.g., for binary alphabet <ref> [2] </ref>, when character distributions are strongly biased, and when the pattern and text distributions are correlated.
Reference: 3. <author> P. Billingsley, </author> <title> Convergence of Probability Measures, </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1968. </year>
Reference-contexts: p and t are non random (deterministic) and p is given. (B) Semi-Random model The text string t is a realization of a stationary and ergodic sequence while the pattern string p is given. (C) Stationary Model Strings t and p are realizations of a stationary and ergodic sequence (cf. <ref> [3] </ref>). (Roughly speaking, a sequence, say t n 1 , is stationary if the probability distribution is the same for all substrings of equal sizes, say t i+k i and t j Formulation of our results depends on the model we work with. <p> More formally, we write C n =a n ! ff (a.s.) where a n is a deterministic sequence and ff is a constant if lim n!1 Prfsup kn jC k =a k ffj &gt; "g = 0 for any " &gt; 0 (cf. <ref> [3] </ref>). Finally, in the stationary model (C) we use standard average case complexity, that is, EC n . Now we are ready to formulate our main results. Theorem 6. Consider an ` m convergent sequential string matching algo- rithm. <p> Let X m;n (m &lt; n) be a sequence of nonnegative random variables satisfying the following three properties (a) X 0;n X 0;m + X m;n (subadditivity); (b) X m;n is stationary (i.e., the joint distributions of X m;n are the same as X m+1;n+1 ) and ergodic (cf. <ref> [3] </ref>); (c) EX 0;1 &lt; 1. Then, lim EX 0;n = fl and lim X 0;n = fl (a:s:) (10) for some constant fl. (iii) (Almost Subadditive Ergodic Theorem [10]).
Reference: 4. <author> A. Blumer, A. Ehrenfeucht and D. Haussler, </author> <title> Average Size of Suffix Trees and DAWGS, </title> <journal> Discrete Applied Mathematics, </journal> <volume> 24, </volume> <pages> 37-45, </pages> <year> 1989. </year>
Reference-contexts: We should point out that in the analysis of algorithms on words such a fluctuation can occur in some problems involving suffix trees (cf. <ref> [4, 14, 20] </ref>). But, in this paper we prove that such a fluctuation cannot take place for the complexity function of the strongly sequential pattern matching algorithms.
Reference: 5. <author> R. Boyer and J. Moore, </author> <title> A fast String Searching Algorithm, </title> <journal> Comm. of the ACM, </journal> <volume> 20, </volume> <pages> 762-772, </pages> <year> 1977. </year>
Reference-contexts: Hence, the result extends to any algorithm that satisfies such a property [6, 13]. Nevertheless, in order to speed up the search, Boyer and Moore introduced in <ref> [5] </ref> a quite different algorithm. Given an alignment position AP, matching against p are checked from right to left; i.e. k is decreasing. Several variants have been proposed that differ by the amount of information saved to compute the next alignment position.
Reference: 6. <author> D. Breslauer, L. Colussi, and L. Toniolo, </author> <title> Tight Comparison Bounds for the String Prefix-Matching Problem, </title> <booktitle> Proc. 4-th Symposium on Combinatorial Pattern Matching, </booktitle> <address> Padova, Italy, 11-19. </address> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: 1 Introduction The complexity of string searching algorithms has been discussed in various papers (cf. <ref> [1, 6, 7, 8, 9, 12, 18] </ref>). It is well known that most pattern matching algorithms perform linearly in the worst case as well as "on average". Several attempts have been made to provide tight bounds on the so-called "linearity constant". <p> We will see that they share a common property of "unavoidability" explored below. Our definition of semi-sequentiality is very close to the definition of sequen-tiality given in [13]. We do not use the "on-line" concept of <ref> [6] </ref>. The on-line algorithms are very close to our strongly sequential ones. Also, while condition (2) is a natural optimization for semi-sequential algorithms, it seems not to be true for other efficient algorithms discussed in [8]. <p> We provided a formal definition, but the main property we use is the existence of the so called unavoidable positions in any window of fixed size (here the length of the searched pattern p). Hence, the result extends to any algorithm that satisfies such a property <ref> [6, 13] </ref>. Nevertheless, in order to speed up the search, Boyer and Moore introduced in [5] a quite different algorithm. Given an alignment position AP, matching against p are checked from right to left; i.e. k is decreasing.
Reference: 7. <author> R. Cole, R. Hariharan, M. Paterson, and U. Zwick, </author> <title> Tighter Lower Bounds on the Exact Complexity of String Matching, </title> <journal> SIAM J. Comp., </journal> <volume> 24, </volume> <pages> 30-45, </pages> <year> 1995. </year>
Reference-contexts: 1 Introduction The complexity of string searching algorithms has been discussed in various papers (cf. <ref> [1, 6, 7, 8, 9, 12, 18] </ref>). It is well known that most pattern matching algorithms perform linearly in the worst case as well as "on average". Several attempts have been made to provide tight bounds on the so-called "linearity constant". <p> For almost twenty years the upper bound was known [16], and no progress has been reported on a lower bound or a tight bound. This was partially rectified by Colussi et al. [8] and Cole et al. <ref> [7] </ref> who established several lower bounds for the so called "on-line" sequential algorithms. However, the existence of the linearity constant was not established yet, at least for the "average complexity" under general probabilistic model assumed in this paper.
Reference: 8. <author> L. Colussi, Z. Galil, and R. Giancarlo, </author> <title> On the Exact Complexity of String Matching, </title> <booktitle> Proc. 31-st Annual IEEE Symposium on the Foundations of Computer Science, </booktitle> <pages> 135-143. </pages> <publisher> IEEE, </publisher> <year> 1990. </year>
Reference-contexts: 1 Introduction The complexity of string searching algorithms has been discussed in various papers (cf. <ref> [1, 6, 7, 8, 9, 12, 18] </ref>). It is well known that most pattern matching algorithms perform linearly in the worst case as well as "on average". Several attempts have been made to provide tight bounds on the so-called "linearity constant". <p> The literature on worst case as well average case on Knuth-Morris-Pratt type algorithms is rather scanty. For almost twenty years the upper bound was known [16], and no progress has been reported on a lower bound or a tight bound. This was partially rectified by Colussi et al. <ref> [8] </ref> and Cole et al. [7] who established several lower bounds for the so called "on-line" sequential algorithms. However, the existence of the linearity constant was not established yet, at least for the "average complexity" under general probabilistic model assumed in this paper. <p> We do not use the "on-line" concept of [6]. The on-line algorithms are very close to our strongly sequential ones. Also, while condition (2) is a natural optimization for semi-sequential algorithms, it seems not to be true for other efficient algorithms discussed in <ref> [8] </ref>. Finally, in the course of proving our main result we discover an interesting structural property of sequential algorithms that we already observed in Ex. 3.
Reference: 9. <author> M. Crochemore and W. Rytter, </author> <title> Text Algorithms, </title> <publisher> Oxford University Press, </publisher> <address> New York 1995. </address>
Reference-contexts: 1 Introduction The complexity of string searching algorithms has been discussed in various papers (cf. <ref> [1, 6, 7, 8, 9, 12, 18] </ref>). It is well known that most pattern matching algorithms perform linearly in the worst case as well as "on average". Several attempts have been made to provide tight bounds on the so-called "linearity constant".
Reference: 10. <editor> Y. Derriennic, Une Theoreme Ergodique Presque Sous Additif, Ann. Probab., </editor> <volume> 11, </volume> <pages> 669-677, </pages> <year> 1983. </year>
Reference-contexts: In the "average case analysis" we indicate that under assumption (C) the average complexity C n is a stationary and ergodic sequence. Then, direct application of an extension of Kingman's Subadditive Ergodic Theorem due to Derriennic <ref> [10] </ref> will do the job of proving our results. In passing, we point out that the most challenging is establishing the subadditivity property to which most of this section is devoted. <p> Then, lim EX 0;n = fl and lim X 0;n = fl (a:s:) (10) for some constant fl. (iii) (Almost Subadditive Ergodic Theorem <ref> [10] </ref>). If the subadditivity inequality is replaced by X 0;n X 0;m + X m;n + A n (11) such that lim n!1 EA n =n = 0, then (10) holds, too. <p> Assume now that t = y 10 az 4 (bazbz 2 ) n with y 6= x and natural n. If the Boyer-Moore-Horspool algorithm starts with AP = 1, a mismatch occurs on the second comparison between t <ref> [10] </ref> and p [10] with AP shifted by 6. The same event occurs then and we eventually get the sequence AP i = 1 + 6i. Assume now that we split the text at r = 6. <p> Assume now that t = y 10 az 4 (bazbz 2 ) n with y 6= x and natural n. If the Boyer-Moore-Horspool algorithm starts with AP = 1, a mismatch occurs on the second comparison between t <ref> [10] </ref> and p [10] with AP shifted by 6. The same event occurs then and we eventually get the sequence AP i = 1 + 6i. Assume now that we split the text at r = 6. As t [16] is b, one shifts by 3 and b is found again.
Reference: 11. <author> R. Durrett, </author> <title> Probability: Theory and Examples, </title> <publisher> Wadsworth & Brooks/Cole Books, </publisher> <address> Pacific Grove, California, </address> <year> 1991. </year>
Reference-contexts: We show that asymptotic complexity grows linearly with the text length for all but finitely many strings (i.e., in almost sure sense). The proof relies on the Subadditive Ergodic Theorem <ref> [11] </ref>. The literature on worst case as well average case on Knuth-Morris-Pratt type algorithms is rather scanty. For almost twenty years the upper bound was known [16], and no progress has been reported on a lower bound or a tight bound. <p> In passing, we point out that the most challenging is establishing the subadditivity property to which most of this section is devoted. For the reader's convenience we start this section with a brief review of the subadditive ergodic theorem (cf. <ref> [11, 15] </ref>.
Reference: 12. <author> L. Guibas and A. Odlyzko, </author> <title> A New Proof of the Linearity of the Boyer-Moore String Matching Algorithm, </title> <journal> SIAM J. Compt., </journal> <volume> 9, </volume> <pages> 672-682, </pages> <year> 1980. </year>
Reference-contexts: 1 Introduction The complexity of string searching algorithms has been discussed in various papers (cf. <ref> [1, 6, 7, 8, 9, 12, 18] </ref>). It is well known that most pattern matching algorithms perform linearly in the worst case as well as "on average". Several attempts have been made to provide tight bounds on the so-called "linearity constant".
Reference: 13. <author> C. </author> <month> Hancart, </month> <institution> Analyse Exacte et en Moyenne d'Algorithmes de Recherche d'un Motif dans un Texte, </institution> <address> These, l'Universite Paris 7, </address> <year> 1993. </year>
Reference-contexts: It is interesting to observe that the subset f1; 5; 12g of alignments positions appears in all variants. We will see that they share a common property of "unavoidability" explored below. Our definition of semi-sequentiality is very close to the definition of sequen-tiality given in <ref> [13] </ref>. We do not use the "on-line" concept of [6]. The on-line algorithms are very close to our strongly sequential ones. Also, while condition (2) is a natural optimization for semi-sequential algorithms, it seems not to be true for other efficient algorithms discussed in [8]. <p> We provided a formal definition, but the main property we use is the existence of the so called unavoidable positions in any window of fixed size (here the length of the searched pattern p). Hence, the result extends to any algorithm that satisfies such a property <ref> [6, 13] </ref>. Nevertheless, in order to speed up the search, Boyer and Moore introduced in [5] a quite different algorithm. Given an alignment position AP, matching against p are checked from right to left; i.e. k is decreasing. <p> It is worth noticing that the Subadditive Ergodic Theorem proves the existence of the linearity constant under quite general probabilistic assumptions. The computation of the constant is difficult and only limited success was achieved so far (cf. <ref> [13, 18, 17] </ref>). However even if we cannot compute the constant, we can prove that C n is well concentrated around its most probably value ff 2 n. Using Azuma's inequality (cf. [21]) we conclude the following. Theorem 12.
Reference: 14. <author> P. Jacquet and W. Szpankowski, </author> <title> Autocorrelation on Words and Its Applications. Analysis of Suffix Tree by String-Ruler Approach, </title> <journal> J. Combinatorial Theory. Ser. A, </journal> <volume> 66, </volume> <pages> 237-269, </pages> <year> 1994. </year>
Reference-contexts: We should point out that in the analysis of algorithms on words such a fluctuation can occur in some problems involving suffix trees (cf. <ref> [4, 14, 20] </ref>). But, in this paper we prove that such a fluctuation cannot take place for the complexity function of the strongly sequential pattern matching algorithms.
Reference: 15. <editor> J.F.C. Kingman, Subadditive Processes, in Ecole d'Ete de Probabilites de Saint-Flour V-1975, </editor> <booktitle> Lecture Notes in Mathematics, </booktitle> <volume> 539, </volume> <publisher> Springer-Verlag, </publisher> <address> Berlin 1976. </address>
Reference-contexts: In passing, we point out that the most challenging is establishing the subadditivity property to which most of this section is devoted. For the reader's convenience we start this section with a brief review of the subadditive ergodic theorem (cf. <ref> [11, 15] </ref>. <p> Theorem 10. (Subadditive Sequence). (i) Let for a (deterministic) nonnegative sequence fx n g 1 n=0 the following property, called subadditivity, holds x m+n x n + x m : (8) Then lim x n = inf x m = ff (9) for some constant ff. (ii) (Subadditive Ergodic Theorem <ref> [15] </ref>).
Reference: 16. <author> D.E. Knuth, J. Morris and V. Pratt, </author> <title> Fast Pattern Matching in Strings, </title> <journal> SIAM J. Compt., </journal> <volume> 6, </volume> <pages> 189-195, </pages> <year> 1977. </year>
Reference-contexts: In this paper we investigate a fairly general class of algorithms, called sequential algorithms, for which the existence of the linearity constant (in an asymptotic sense) is proved for the worst and the average case. Sequential algorithms include the naive one and several variants of Morris-Pratt algorithm <ref> [16] </ref>. These algorithms never go backward, work by comparisons, and are easy to implement. They perform better than Boyer-Moore like algorithms in numerous cases, e.g., for binary alphabet [2], when character distributions are strongly biased, and when the pattern and text distributions are correlated. <p> The proof relies on the Subadditive Ergodic Theorem [11]. The literature on worst case as well average case on Knuth-Morris-Pratt type algorithms is rather scanty. For almost twenty years the upper bound was known <ref> [16] </ref>, and no progress has been reported on a lower bound or a tight bound. This was partially rectified by Colussi et al. [8] and Cole et al. [7] who established several lower bounds for the so called "on-line" sequential algorithms. <p> This algorithm is sequential (hence semi-sequential) but not strongly sequential. Condition in (ii) is violated after any mismatch on an alignment position l with parameter k 3 , as comparison (l + 1; 1) occurs after (l + 1; 2) and (l + 2; 3). Example 2: Morris-Pratt-like algorithms <ref> [16, 19] </ref>. It was already noted in [16] that after a mismatch occurs when comparing t [l] with p [k], some alignment positions in [l + 1; : : : ; l + k 1] can be disregarded without further text-pattern comparisons. <p> Condition in (ii) is violated after any mismatch on an alignment position l with parameter k 3 , as comparison (l + 1; 1) occurs after (l + 1; 2) and (l + 2; 3). Example 2: Morris-Pratt-like algorithms [16, 19]. It was already noted in <ref> [16] </ref> that after a mismatch occurs when comparing t [l] with p [k], some alignment positions in [l + 1; : : : ; l + k 1] can be disregarded without further text-pattern comparisons. Namely, the ones that satisfy t l+k1 l+i 6= 1 . <p> Other i define the "surviving candidates", and chosing the next alignment position among the surviving candidates is enough to ensure that condition (ii) in Definition 3 holds. Different choices lead to different variants of the classic Morris-Pratt algorithm <ref> [16] </ref>. They differ by the use of the information obtained from the mismatching position. We formally define three main variants, and provide an example. <p> Then, as the text distribution is stationary, the subadditivity holds in case (B). Also, the cost C r;n is stationary when the text distribution is. Applying Subadditive Ergodic Theorem yields (4) and (5). We turn now to the average complexity. The uniform bound <ref> [16] </ref> on the linearity constant, allows to define E p (E t (c r;n )), when p ranges over a random (possibly infinite) set of patterns. The subadditivity property transfers to E t;p (C n ) and (6) follows. <p> The same event occurs then and we eventually get the sequence AP i = 1 + 6i. Assume now that we split the text at r = 6. As t <ref> [16] </ref> is b, one shifts by 3 and b is found again. Finally, one gets sequence AP 0 i = 6 + 3i. As gcd (6; 3) does not divide 5, these two sequences are disjoint and there is no unavoidable position.
Reference: 17. <author> H. Mahmoud, M. Regnier and R. Smythe, </author> <title> Analysis of Boyer-Moore-Horspool String Matching Heuristic, in Random Structures and Algorithms, </title> <booktitle> 10, </booktitle> <pages> 169-186, </pages> <year> 1996. </year>
Reference-contexts: Several attempts have been made to provide tight bounds on the so-called "linearity constant". Nevertheless, the existence of such a constant has never been proved. The only exception known to us is the average case of Morris-Pratt-like algorithms [18] (cf. <ref> [17] </ref>) for the symmetric Bernoulli model (independent generation of symbols with each symbol occurring with the same probability) where the constant was also explicitly computed. <p> It follows that unavoidability cannot be used to prove linearity of Boyer-Moore algorithms. Nevertheless, it is clear that we assumed a very strong (and unlikely) structure on both text and patterns. In a recent paper <ref> [17] </ref>, the existence of renewal points almost surely allowed to prove the existence of a linearity constant. It is worth noticing that the Subadditive Ergodic Theorem proves the existence of the linearity constant under quite general probabilistic assumptions. <p> It is worth noticing that the Subadditive Ergodic Theorem proves the existence of the linearity constant under quite general probabilistic assumptions. The computation of the constant is difficult and only limited success was achieved so far (cf. <ref> [13, 18, 17] </ref>). However even if we cannot compute the constant, we can prove that C n is well concentrated around its most probably value ff 2 n. Using Azuma's inequality (cf. [21]) we conclude the following. Theorem 12.
Reference: 18. <author> M. Regnier, </author> <title> Knuth-Morris-Pratt Algorithm: An Analysis, </title> <booktitle> Proc. Mathematical Foundations for Computer Science 89, Porubka, Poland, Lecture Notes in Computer Science, </booktitle> <volume> 379, </volume> <pages> 431-444. </pages> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: 1 Introduction The complexity of string searching algorithms has been discussed in various papers (cf. <ref> [1, 6, 7, 8, 9, 12, 18] </ref>). It is well known that most pattern matching algorithms perform linearly in the worst case as well as "on average". Several attempts have been made to provide tight bounds on the so-called "linearity constant". <p> Several attempts have been made to provide tight bounds on the so-called "linearity constant". Nevertheless, the existence of such a constant has never been proved. The only exception known to us is the average case of Morris-Pratt-like algorithms <ref> [18] </ref> (cf. [17]) for the symmetric Bernoulli model (independent generation of symbols with each symbol occurring with the same probability) where the constant was also explicitly computed. <p> It is worth noticing that the Subadditive Ergodic Theorem proves the existence of the linearity constant under quite general probabilistic assumptions. The computation of the constant is difficult and only limited success was achieved so far (cf. <ref> [13, 18, 17] </ref>). However even if we cannot compute the constant, we can prove that C n is well concentrated around its most probably value ff 2 n. Using Azuma's inequality (cf. [21]) we conclude the following. Theorem 12.
Reference: 19. <author> I. Simon, </author> <title> String Matching Algorithms and Automata, </title> <booktitle> First South-American Workshop on String Processing 93, </booktitle> <editor> Belo Horizonte, Brazil, R. Baeza-Yates and N. </editor> <booktitle> Zi-viani,ed, </booktitle> <pages> 151-157, </pages> <year> 1993. </year>
Reference-contexts: This algorithm is sequential (hence semi-sequential) but not strongly sequential. Condition in (ii) is violated after any mismatch on an alignment position l with parameter k 3 , as comparison (l + 1; 1) occurs after (l + 1; 2) and (l + 2; 3). Example 2: Morris-Pratt-like algorithms <ref> [16, 19] </ref>. It was already noted in [16] that after a mismatch occurs when comparing t [l] with p [k], some alignment positions in [l + 1; : : : ; l + k 1] can be disregarded without further text-pattern comparisons.
Reference: 20. <author> W. Szpankowski, </author> <title> Asymptotic Properties of Data Compression and Suffix Trees, </title> <journal> IEEE Trans. Information Theory, </journal> <volume> 39, </volume> <pages> 1647-1659, </pages> <year> 1993. </year>
Reference-contexts: We should point out that in the analysis of algorithms on words such a fluctuation can occur in some problems involving suffix trees (cf. <ref> [4, 14, 20] </ref>). But, in this paper we prove that such a fluctuation cannot take place for the complexity function of the strongly sequential pattern matching algorithms.
Reference: 21. <author> M. Waterman, </author> <title> Introduction to Computational Biology, Chapman & Hall, London 1995. This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: The computation of the constant is difficult and only limited success was achieved so far (cf. [13, 18, 17]). However even if we cannot compute the constant, we can prove that C n is well concentrated around its most probably value ff 2 n. Using Azuma's inequality (cf. <ref> [21] </ref>) we conclude the following. Theorem 12. Let the text t be generated by a memoryless source (i.e., t is an i.i.d sequence).
References-found: 21

