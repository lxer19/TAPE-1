URL: http://www.cs.jhu.edu/~jhndrsn/papers/proposal.ps
Refering-URL: http://www.cs.jhu.edu/~jhndrsn/thesis.html
Root-URL: http://www.cs.jhu.edu
Title: Rational Creation and Combination of Diverse Natural Language Processing Systems  
Author: John Henderson 
Degree: Thesis Proposal  
Date: March 6, 1997  
Abstract-found: 0
Intro-found: 1
Reference: [BHW] <author> Eric Brill, John Henderson, and Jun Wu. </author> <title> Combining classifiers for lexical disambiguation. under submission. </title> <type> 10 </type>
Reference-contexts: Yet when the outputs from the two systems were combined using a straightforward technique similar to backoff the accuracy was boosted by .36%, yielding a system which outperforms any previously reported result for this task <ref> [BHW] </ref>. 1 The task this thesis is concerned with is developing reasonable methods for combining the outputs of a diverse set of systems which all address the same task.
Reference: [BR94] <author> Eric Brill and Philip Resnik. </author> <title> A rule-based approach to prepositional phrase attachment disambiguation. </title> <booktitle> In Proceedings of the Fifteenth International Conference on Computational Linguistics (COLING-1994), </booktitle> <year> 1994. </year>
Reference-contexts: The prepositional phrase attachment problem has been studied in depth by a number of authors 2 <ref> [BR94, CB95, RRR94] </ref>. We have chosen it as another development test-bed for some new methods because of this and because the corpora that are used to evaluate this task are small and simple enough to make experiments computationally cheap to perform. <p> To determine if the gains we got from these methods were particular to tagging, we repeated all three experiments on the prepositional phrase attachment task. The corpus we used for training our attachment system was 12,266 tuples from 7 the Wall Street Journal corpus collected for <ref> [BR94] </ref>. The test set was 500 tuples from the same source. The same techniques that were so successfully applied to the stochastic rule lists were also applied to the prepositional phrase attachment task. We created nine greedy rule lists and nine stochastic rule lists. <p> We believe the source of the difference lies in the size of the datasets for this task. The best previously reported results on this dataset was 80.8% accuracy by <ref> [BR94] </ref>, and this performance was replicated by [CB95].
Reference: [Bre94] <author> L. Breiman. </author> <title> Bagging predictors. </title> <type> Technical Report 421, </type> <institution> Department of Statistics, University of California, Berkeley, </institution> <year> 1994. </year>
Reference-contexts: A decision tree is made for each of the pseudo-training sets, and results are combined using simple interpolation or majority voting depending on the type of predictor that is required. Bagging can be used in combination with decision trees and voting to boost the accuracy of certain systems <ref> [Bre94] </ref>. His technique reduces the variance among classifiers by combining them, and he submits that it can reduce the accuracy of systems that are already performing well. <p> Probabilistic systems on the other hand give classification hints or soft decisions, realized as probability distributions over the predicted classes. We felt that the latter style of classification would be much more useful when combining rule lists based on the results from <ref> [Bre94, OS96] </ref>. Since we were convinced that we had managed to increase the variance among rule lists generated from the same set of data by making them stochastic, we attempted to get them to produce soft decisions to be used during the combining phase.
Reference: [Bri95] <author> Eric Brill. </author> <title> Transformation-based error-driven learning and natural language processing: A case study in part of speech tagging. </title> <booktitle> Computational Linguistics, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: We will also show the results of applying those principles to the prepositional phrase attachment problem. Annotating text with part of speech tags has been the focus of a great deal of study. The two systems that have most recently pushed accuracy up are <ref> [Bri95, Rat96] </ref>. While it is still unclear whether we have reached a ceiling on the accuracy that can be obtained for this problem, this task has collected a large number of automated systems that attack it. The task is easy to describe.
Reference: [CB95] <author> Michael Collins and James Brooks. </author> <title> Prepositional phrase attachment through a backed-off model. </title> <booktitle> In Proceedings of the Third Workshop on Very Large Corpora, </booktitle> <year> 1995. </year>
Reference-contexts: The prepositional phrase attachment problem has been studied in depth by a number of authors 2 <ref> [BR94, CB95, RRR94] </ref>. We have chosen it as another development test-bed for some new methods because of this and because the corpora that are used to evaluate this task are small and simple enough to make experiments computationally cheap to perform. <p> We believe the source of the difference lies in the size of the datasets for this task. The best previously reported results on this dataset was 80.8% accuracy by [BR94], and this performance was replicated by <ref> [CB95] </ref>.
Reference: [HKS96] <author> David Heath, Simon Kasif, and Steven Salzberg. </author> <title> Committees of decision trees. </title> <editor> In B. Gorayska and J. Mey, editors, </editor> <booktitle> Cognitive Technology: In Search of a Humane Interface, </booktitle> <pages> pages 305-317. </pages> <publisher> Elsevier Science B.V., </publisher> <address> Amsterdam, </address> <year> 1996. </year>
Reference-contexts: The interesting part of his technique is that it can be applied to any classification method which is sensitive to changes in the distribution of its input samples. Heath et al. give a result on using committees of randomly generated decision trees to improve accuracy <ref> [HKS96] </ref>. Opitz and Shavlik have used bagging in conjunction with a genetic algorithm that trains a collection of neural networks to boost accuracy [OS96]. The highlight of their paper is that they actively enforce that their ensemble be diverse. <p> Our hypothesis was that if we could introduce more variance between rule lists while sacrificing no or little accuracy, the voting technique would use that variance to its advantage. A similar method has been used before in experiments involving combining decision trees <ref> [HKS96] </ref>. The method we used to introduce variance was softening the greedy search during rule list induction. During learning, a stochastic rule list selects the next rule to add to the rule list by picking a random rule that scores above the threshold according to the distribution of scores.
Reference: [Jel97] <author> Frederick Jelinek. </author> <title> Information Extraction From Speech And Text, chapter 13. </title> <publisher> MIT Press, </publisher> <year> 1997. </year> <title> forthcoming, </title> <type> preprint. </type>
Reference-contexts: Recent work by Rosenfeld combines an n-gram language model output with a trigger language model output using a provably optimal form of linear interpolation [Ros94]. Maximum entropy models can also be used to combine outputs of multiple independent classifiers <ref> [Jel97] </ref>. 2 Preliminary Experiments We will provide a number of preliminary results on applying combining methods to lexical disambiguation (part of speech tagging), illustrating the principles we learned in the process. We will also show the results of applying those principles to the prepositional phrase attachment problem.
Reference: [KS63] <author> S. Klein and R. Simmons. </author> <title> A computational approach to grammatical coding of english words. </title> <journal> Journal of the Association for Computing Machinery, JACM, </journal> <volume> 10, </volume> <year> 1963. </year>
Reference-contexts: For example, the features used in part of speech tagging have not changed significantly since the mid 1960's <ref> [KS63] </ref>. This is not to say that the hunt for better features is not a worthwhile endeavor. On the contrary, many of the largest advances in natural language processing have come from the clever use of larger or more independent feature spaces.
Reference: [OS96] <author> D. W. Opitz and J. W. Shavlik. </author> <title> Generating accurate and diverse members of a neural-network ensemble. </title> <booktitle> In Proceedings of the Conference on Neural Information Processing Systems (NIPS8), </booktitle> <year> 1996. </year>
Reference-contexts: Heath et al. give a result on using committees of randomly generated decision trees to improve accuracy [HKS96]. Opitz and Shavlik have used bagging in conjunction with a genetic algorithm that trains a collection of neural networks to boost accuracy <ref> [OS96] </ref>. The highlight of their paper is that they actively enforce that their ensemble be diverse. In the speech recognition community, it is widely recognized that combining diverse knowledge sources is important, and much work is being done to utilize this fact to produce better language models. <p> Probabilistic systems on the other hand give classification hints or soft decisions, realized as probability distributions over the predicted classes. We felt that the latter style of classification would be much more useful when combining rule lists based on the results from <ref> [Bre94, OS96] </ref>. Since we were convinced that we had managed to increase the variance among rule lists generated from the same set of data by making them stochastic, we attempted to get them to produce soft decisions to be used during the combining phase.
Reference: [Rat96] <author> Adwait Ratnaparkhi. </author> <title> A maximum entropy model for part of speech tagging. </title> <booktitle> In Proceedings of the First Conference on Empirical Methods in Natural Language Processing, </booktitle> <address> Philadelphia, </address> <year> 1996. </year>
Reference-contexts: We will also show the results of applying those principles to the prepositional phrase attachment problem. Annotating text with part of speech tags has been the focus of a great deal of study. The two systems that have most recently pushed accuracy up are <ref> [Bri95, Rat96] </ref>. While it is still unclear whether we have reached a ceiling on the accuracy that can be obtained for this problem, this task has collected a large number of automated systems that attack it. The task is easy to describe.
Reference: [Ros94] <author> Ronald Rosenfeld. </author> <title> Adaptive Statistical Language Modeling: A Maximum Entropy Approach. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, Pittsburgh, </institution> <month> April </month> <year> 1994. </year>
Reference-contexts: Recent work by Rosenfeld combines an n-gram language model output with a trigger language model output using a provably optimal form of linear interpolation <ref> [Ros94] </ref>. Maximum entropy models can also be used to combine outputs of multiple independent classifiers [Jel97]. 2 Preliminary Experiments We will provide a number of preliminary results on applying combining methods to lexical disambiguation (part of speech tagging), illustrating the principles we learned in the process.
Reference: [RRR94] <author> Adwait Ratnaparkhi, Jeff Reynar, and Salim Roukos. </author> <title> A maximum entropy model for prepositional phrase attachment. </title> <booktitle> In Proceedings of the ARPA Workshop on Human Language Technology, </booktitle> <address> Plainsboro, </address> <month> March </month> <year> 1994. </year>
Reference-contexts: The prepositional phrase attachment problem has been studied in depth by a number of authors 2 <ref> [BR94, CB95, RRR94] </ref>. We have chosen it as another development test-bed for some new methods because of this and because the corpora that are used to evaluate this task are small and simple enough to make experiments computationally cheap to perform.
Reference: [TLV93] <author> G. Towell, C. Leacock, and E. Voorhees. </author> <title> Corpus-based statistical sense resolution. </title> <booktitle> In Proceedings of the ARPA Workshop on Human Language Technology. </booktitle> <publisher> Morgan Kaufman, </publisher> <year> 1993. </year>
Reference-contexts: Until sufficient features are found, picking features will continue to be a research area for natural language processing. For some natural language problems, controlled experiments have shown that the differences in accuracies achieved by varying only the learning method are not great <ref> [TLV93] </ref>. This suggests that feature sets and training data are the most important characteristics to examine or enhance when one is attempting to push up the accuracy of a system.
References-found: 13

