URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/Web/People/vsam/Papers/wacv98_geolocation.ps.gz
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/Web/People/vsam/iubapage.html
Root-URL: 
Email: Email:  
Title: Using a DEM to Determine Geospatial Object Trajectories  
Author: Robert T. Collins, Yanghai Tsin, J. Ryan Miller and Alan J. Lipton 
Web: frcollins,ytsin,jmce,ajlgcs.cmu.edu  
Address: Pittsburgh, PA. 15213  
Affiliation: The Robotics Institute, Carnegie Mellon University,  
Abstract: This paper addresses the estimation of moving object trajectories within a geospatial coordinate system, using a network of video sensors. A high-resolution (0.5m grid spacing) digital elevation map (DEM) has been constructed using a helicopter-based laser range-finder. Object locations are estimated by intersecting viewing rays from a calibrated sensor platform with the DEM. Continuous object trajectories can then be assembled from sequences of single-frame location estimates using spatio-temporal filtering and domain knowledge. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> American Society of Photogrammetry, </institution> <note> Manual of Photogrammetry, Fourth Edition, </note> <institution> American Society of Photogrammetry, Falls Church, VA, </institution> <year> 1980. </year>
Reference-contexts: Unfor tunately, even simple computations such as the dis-tance between two points become complicated as a function of latitude, longitude and elevation. For this reason, geometric processing is performed within a site-specific Local Vertical Coordinate System (LVCS) <ref> [1] </ref>. An LVCS is a Cartesian system oriented so that the positive X axis points east, positive Y points true north, and positive Z points up (anti-parallel to gravity). All that is needed to completely specify an LVCS is the 3D geodetic coordinate of its origin point.
Reference: [2] <institution> O.Amidi, T.Kanade and R.Miller, "Vision-based Autonomous Helicopter Research at Carnegie Mellon Robotics Institute," Proceedings of Heli Japan '98, </institution> <address> Gifu, Japan, </address> <month> April </month> <year> 1998. </year>
Reference-contexts: Since this high-resolution DEM is crucial to the target geolocation algorithm, the construction process is described in detail below. 2.3 High-Resolution DEM The CMU autonomous helicopter project is developing an aerial laser mapping system <ref> [2, 9] </ref>. The CMU helicopter is a mid-sized, unmanned helicopter that is capable of fully autonomous takeoff, flight path tracking, accurate (&lt; 20 cm) stationary hover, and landing. The laser scanning system is one of the sensor packages that can be flown aboard the helicopter.
Reference: [3] <author> K.Bradshaw, I.Reid and D.Murray, </author> <title> "The Active Recovery of 3D Motion Trajectories and Their Use in Prediction," </title> <journal> IEEE PAMI, </journal> <volume> Vol.19(3), </volume> <month> March </month> <year> 1997, </year> <pages> pp. 219-234. </pages>
Reference-contexts: Sequences of location estimates over time are then assembled into consistent object trajectories. Previous uses of the ray intersection technique for object localization have been restricted to small areas of planar terrain, where the relation between image pixels and terrain locations is a simple 2D homography <ref> [3, 4, 6] </ref>. This has the benefit that no camera calibration is required to determine the back-projection of an image point onto the scene plane, provided the mappings of at least 4 coplanar scene points are known beforehand. <p> A more general mechanism for assembling location estimates into smooth, continuous object trajectories is spatio-temporal filtering. For example, Kalman filtering could be used to build a dynamic model of the target, based on the assumption that the target will not make sharp turns and abrupt accelerations <ref> [3, 6] </ref>. However, as mentioned above, a viewing ray may intersect the terrain multiple times, resulting in several alternative hypotheses for target location. The shows a car "jumping" into a tree. Right: Filtered trajectory removes the treetop detour.
Reference: [4] <author> B.Flinchbaugh and T.Bannon, </author> <title> "Autonomous Scene Monitoring System", </title> <booktitle> Proc. 10th Annual Joint Government-Industry Security Technology Symposium, </booktitle> <publisher> American Defense Preparedness Association, </publisher> <month> June </month> <year> 1994. </year>
Reference-contexts: Sequences of location estimates over time are then assembled into consistent object trajectories. Previous uses of the ray intersection technique for object localization have been restricted to small areas of planar terrain, where the relation between image pixels and terrain locations is a simple 2D homography <ref> [3, 4, 6] </ref>. This has the benefit that no camera calibration is required to determine the back-projection of an image point onto the scene plane, provided the mappings of at least 4 coplanar scene points are known beforehand.
Reference: [5] <author> M.Isard and A.Blake, </author> <title> "Contour Tracking by Stochastic Propagation of Conditional Density," </title> <booktitle> Proc. </booktitle> <address> ECCV, </address> <year> 1996, </year> <pages> pp. 343-356. </pages>
Reference-contexts: Kalman filter, based on unimodal Gaussian densities, cannot simultaneously represent these multiple possible paths, and an incorrect choice of initial value will doom the entire trajectory. What is required is a more advanced filtering method that can handle multiple data associations, such as the CONDENSATION algorithm <ref> [5] </ref>. This is a topic of current work. 4.2 Domain Knowledge Notwithstanding the need for a powerful, general mechanism to generate smooth target trajectories, in certain cases domain knowledge can be used to generate simpler, approximate solutions.
Reference: [6] <author> D.Koller, K.Daniilidis, and H.Nagel, </author> <title> "Model-Based Object Tracking in Monocular Image Sequences of Road Traffic Scenes, </title> <address> IJCV, Vol.10(3), </address> <month> June </month> <year> 1993, </year> <pages> pp. 257-281. </pages>
Reference-contexts: Sequences of location estimates over time are then assembled into consistent object trajectories. Previous uses of the ray intersection technique for object localization have been restricted to small areas of planar terrain, where the relation between image pixels and terrain locations is a simple 2D homography <ref> [3, 4, 6] </ref>. This has the benefit that no camera calibration is required to determine the back-projection of an image point onto the scene plane, provided the mappings of at least 4 coplanar scene points are known beforehand. <p> A more general mechanism for assembling location estimates into smooth, continuous object trajectories is spatio-temporal filtering. For example, Kalman filtering could be used to build a dynamic model of the target, based on the assumption that the target will not make sharp turns and abrupt accelerations <ref> [3, 6] </ref>. However, as mentioned above, a viewing ray may intersect the terrain multiple times, resulting in several alternative hypotheses for target location. The shows a car "jumping" into a tree. Right: Filtered trajectory removes the treetop detour.
Reference: [7] <author> A.Lipton, H.Fujiyoshi, and R.Patil, </author> <title> "Moving Target Identification and Tracking from Real-time Video," </title> <note> submitted to WACV 1998. </note>
Reference-contexts: This fusion of information was possible since both DEMS are precisely geolocated. area as orthophoto in Figure 1. Intensity has been enhanced to emphasize terrain variation. 3 Estimating Target Location The VSAM testbed contains highly effective algorithms for detecting, classifying and tracking moving targets through a 2D video sequence <ref> [7] </ref>. Target locations in the scene are estimated from the bounding box of stable motion regions in each frame of the sequence. <p> In particular, the VSAM testbed classifies moving objects as being either human or vehicle <ref> [7] </ref>. Vehicular target motion is typically constrained to lie along roadways in the scene, and this heuristic suggests the use of a road network graph together with the viewing ray DEM intersection algorithm to produce unambiguous, accurate target trajectories.
Reference: [8] <author> K.V.Mardia, </author> <title> Statistics of Directional Data, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: angle yields an independent estimate i of camera yaw as i = atan2 (y i y 0 ; x i x 0 ) pan i : A final yaw estimate ^ is computed as the average of these angles, taking care to use the appropriate formula for averaging angular data <ref> [8] </ref>, namely ^ = atan2 ( n X sin i ; 1 3.2 Ray Intersection with the DEM Given a calibrated sensor, and an image pixel corresponding to the assumed contact point between an object and the terrain, a viewing ray (x 0 +ku; y 0 +kv; z 0 + kw)
Reference: [9] <author> R.Miller and O.Amidi, </author> <title> "3-D Site Mapping with the CMU Autonomous Helicopter," </title> <booktitle> To appear in Proc. 5th Intl. Conf. on Intelligent Autonomous Systems, </booktitle> <address> Sapporo, Japan, </address> <month> June </month> <year> 1998. </year>
Reference-contexts: Since this high-resolution DEM is crucial to the target geolocation algorithm, the construction process is described in detail below. 2.3 High-Resolution DEM The CMU autonomous helicopter project is developing an aerial laser mapping system <ref> [2, 9] </ref>. The CMU helicopter is a mid-sized, unmanned helicopter that is capable of fully autonomous takeoff, flight path tracking, accurate (&lt; 20 cm) stationary hover, and landing. The laser scanning system is one of the sensor packages that can be flown aboard the helicopter.
References-found: 9

