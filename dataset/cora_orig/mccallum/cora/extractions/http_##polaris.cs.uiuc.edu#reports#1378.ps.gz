URL: http://polaris.cs.uiuc.edu/reports/1378.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: A hybrid block GMRES method for nonsymmetric systems with multiple right-hand sides  
Author: V. Simoncini and E. Gallopoulos IMGA-CNR 
Address: 1308 West Main Street Urbana, Illinois 61801  
Affiliation: Modena, Italy Center for Supercomputing Research and Development University of Illinois at Urbana-Champaign  
Date: September 1994 September 1995 revision  
Note: To appear in J. Comput. Appl. Math., 66, 1996.  
Pubnum: CSRD Report No. 1378  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> D. CALVETTI AND L. REICHEL, </author> <title> Application of a block modified Chebyshev algorithm to the iterative solution of symmetric linear systems with multiple right-hand side vectors, </title> <journal> Numer. Math., </journal> <volume> 68 (1994), </volume> <pages> pp. 3-16. </pages>
Reference-contexts: One method close to ours, but restricted to positive definite Hermitian systems was proposed by Calvetti and Reichel <ref> [1] </ref>. That method uses the block Lanczos algorithm to generate approximations to the eigenvalues followed by a modified block Chebyshev algorithm. fl IMGA-CNR, Modena, Italy. <p> Our test suite consists of matrices originating from the discretization of an elliptic operator, and from the Harwell-Boeing collection [3]. We next report the common features of the experimental setup. We used the same set of s 20 random right-hand sides, all consisting of elements selected uniformly from <ref> [0; 1] </ref>. Matrix A was stored in compressed row format. We considered that convergence was reached when all true relative residuals satisfied kr (j) (j) 0 k 10 7 ; 1 j s, for consistency, however, no early stopping was used.
Reference: [2] <author> B. N. DATTA AND Y. SAAD, </author> <title> Arnoldi methods for large Sylvester-like observer matrix equations, and an associated algorithm for partial spectrum assignment, </title> <journal> Lin. Alg. Appl., </journal> <month> 154-156 </month> <year> (1991), </year> <pages> pp. 225-244. </pages>
Reference-contexts: Methods for solving shifted systems when s = 1 can be found in <ref> [5, 2] </ref>. One approach consists of approximating the unshifted system Ax = b with a Krylov subspace method while updating certain quantities in order to solve the shifted systems [5]. In this manner the p multiplications with A ! i I are replaced by one multiplication with A per step. <p> The reason is that upon restarting, one would need to solve for p distinct systems (A ! i I )x = ^ b; in particular, all right-hand sides would be different, and the advantage offered by the invariance properties cannot be used. Therefore, the method described in <ref> [2] </ref> continues with GMRES until a good approximation has been obtained. It is easy to show that the invariance properties of Krylov subspaces carry over to block Krylov subspaces. <p> Equality (5.1) also holds in the block setting, though the block version of the algorithm of <ref> [2] </ref> becomes very demanding in terms of memory as m and s increase. Therefore, continuing BGMRES till convergence might be impractical.
Reference: [3] <author> I.S. DUFF, R.G. GRIMES, AND J.G. LEWIS, </author> <title> Sparsematrix test problems, </title> <journal> ACM Trans. Math. Softw., </journal> <volume> 15 </volume> <pages> 1-14, </pages> <year> 1989. </year>
Reference-contexts: Our test suite consists of matrices originating from the discretization of an elliptic operator, and from the Harwell-Boeing collection <ref> [3] </ref>. We next report the common features of the experimental setup. We used the same set of s 20 random right-hand sides, all consisting of elements selected uniformly from [0; 1]. Matrix A was stored in compressed row format.
Reference: [4] <author> R. W. FREUND, </author> <title> Quasi-kernel polynomials and their use in non-Hermitian matrix iterations, </title> <journal> J. Comput. Appl. Math., </journal> <volume> 43 (1992), </volume> <pages> pp. </pages> <month> 135-158. </month> <title> [5] , Solution of shifted linear systems by quasi-minimal residual iterations, in Numerical Linear Algebra, </title> <editor> L. Reichel, A. Ruttan, and R. Varga, eds., </editor> <address> Berlin, 1993, </address> <publisher> W. de Gruyter, </publisher> <pages> pp. </pages> <month> 101-121. </month> <title> [6] , A transpose-free quasi-minimal residual algorithm for non-Hermitian linear systems, </title> <note> SIAM J. </note> <institution> Sci. Comput., </institution> <month> 14 (Mar. </month> <year> 1993), </year> <pages> pp. 470-482. </pages>
Reference-contexts: Letting m () = (q i;j ()) i;j=1;s with q i;j 2 P m , we have r (k) P s (k) 3.2. Implementation issues. Method BG-RICH requires the latent roots of m . One procedure for generating these roots was introduced by Freund <ref> [4] </ref>. It is based on solving the generalized eigenvalue problem H T m z (3.6) with ~ H m := [I ms ; 0]H m , using the available factors Q m and R m of the QR decomposition of H m . <p> The total cost of this computation is O (m 3 s 3 ). It is worth noting that reference <ref> [4] </ref> was only dealing with the case s = 1, and performance considerations were not a major concern. For s &gt; 1, however, this calculation can impose a significant performance penalty.
Reference: [7] <author> E. GALLOPOULOS AND V. SIMONCINI, </author> <title> Iterative solution of multiple linear systems: Theory, practice, parallelism, </title> <booktitle> and applications, in Advances in Parallel and Vector Processing for Structural Mechanics: Proc. Second Int'l. Conf. Computational Structures Technology, </booktitle> <editor> B.H.V. Topping and M. Papadrakakis, eds., </editor> <address> Edinburgh, 1994, </address> <publisher> Civil-Comp Press, </publisher> <pages> pp. 47-51. </pages>
Reference-contexts: Results are presented in Tables 4.3 and 4.4. 1 Strictly speaking, the algorithm applies the same operation across the systems. This is a data parallel approach that we could exploit, were we interested in a parallel implementation <ref> [7] </ref>. 8 TABLE 4.2 CPU seconds to convergence for operator L (u) = u + 50 (e xy u x + e xy u y ) + 100u, n = 3600; B = RAND (n; s). In parentheses is m.
Reference: [8] <author> I. GOHBERG, L. RODMAN, AND P. LANCASTER, </author> <title> Matrix Polynomials, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: The parameters of the Richardson process are inverses of the latent roots of m ; these are the roots of the polynomial p ms () := det ( m ()), p ms 2 P ms <ref> [8] </ref>.
Reference: [9] <author> G. H. HARDY, J. E. LITTLEWOOD, AND G. P OLYA, </author> <title> Inequalities, </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <note> second ed., </note> <year> 1952. </year>
Reference: [10] <author> W. D. JOUBERT, </author> <title> A robust GMRES-based adaptive polynomial preconditioning algorithm for nonsymmetric linear systems 11 </title>
Reference-contexts: We refer to the method that we propose as hybrid BGMRES, because it extracts and applies the matrix polynomial obtained in the course of a BGMRES step; as such, the method attempts to combine the advantages of the block approach with those of recent hybrid methods by Joubert <ref> [10] </ref>, Saylor and Smolarski [16], and especially Nachtigal, Reichel and Trefethen [12]. One method close to ours, but restricted to positive definite Hermitian systems was proposed by Calvetti and Reichel [1]. <p> It was shown in [12] that by computing the GMRES polynomial and applying it on the residual vector after a certain number of GMRES steps it is 2 possible to obtain a scheme that is frequently faster than GMRES. A restarted hybrid algorithm was also presented in <ref> [10] </ref>. We devote most of the remainder of this paper to show that a hybrid block approach is mathematically feasible, practical, and computationally superior to BGMRES. <p> Similar strategies have been used in hybrid solvers designed for single right-hand sides, see <ref> [10, 12] </ref>. In the next two sections we discuss algorithm HYBRID in greater detail. In our implementation the 3 phases are repeated till convergence, with only one computation of the acceleration parameters.
Reference: [11] <author> M. D. KENT, </author> <title> Chebyshev, Krylov, Lanczos: Matrix relationship and computations, </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1989. </year>
Reference-contexts: R 0 t j ; t j 2 R sfis ; t 0 = I s :(3.1) In particular, m () := P m i=0 i t i is a matrix polynomial (of full degree) in P m;s , therefore, we use the symbol ffi to define the product (cf. <ref> [11] </ref>): ^ R m = m (A) ffi R 0 j=0 Moreover, m solves the minimization problem: min kfi m (A) ffi R 0 k:(3.2) Hence, after m iterations of BGMRES, one can use: * The basis V m 2 R nfims and the block upper Hessenberg matrix H m 2
Reference: [12] <author> N. M. NACHTIGAL, L. REICHEL, AND L. N. TREFETHEN, </author> <title> A hybrid GMRES algorithm for nonsymmetric matrix iterations, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <month> 13 (July </month> <year> 1992), </year> <pages> pp. 796-825. </pages>
Reference-contexts: hybrid BGMRES, because it extracts and applies the matrix polynomial obtained in the course of a BGMRES step; as such, the method attempts to combine the advantages of the block approach with those of recent hybrid methods by Joubert [10], Saylor and Smolarski [16], and especially Nachtigal, Reichel and Trefethen <ref> [12] </ref>. One method close to ours, but restricted to positive definite Hermitian systems was proposed by Calvetti and Reichel [1]. That method uses the block Lanczos algorithm to generate approximations to the eigenvalues followed by a modified block Chebyshev algorithm. fl IMGA-CNR, Modena, Italy. <p> The high costs of BGMRES can be handled, in part, by restarting the procedure after m (block) iterations. Using such a restarted algorithm, however, entails lack of minimization over the entire block Krylov subspace and leads to performance losses [17]. It was shown in <ref> [12] </ref> that by computing the GMRES polynomial and applying it on the residual vector after a certain number of GMRES steps it is 2 possible to obtain a scheme that is frequently faster than GMRES. A restarted hybrid algorithm was also presented in [10]. <p> Similar strategies have been used in hybrid solvers designed for single right-hand sides, see <ref> [10, 12] </ref>. In the next two sections we discuss algorithm HYBRID in greater detail. In our implementation the 3 phases are repeated till convergence, with only one computation of the acceleration parameters. <p> We call this approach BG-POL, and show its basic steps in Table 3.1. BG-POL is an extension of a method used in the single right-hand side case <ref> [12] </ref>. Despite its simplicity, however, BG-POL becomes susceptible to numerical difficulties as m and s increase, which are caused by the underlying power form representation and by the conditioning of the matrix C m . Richardson acceleration. In the interest of stability, another approach that was used in [12] for the <p> side case <ref> [12] </ref>. Despite its simplicity, however, BG-POL becomes susceptible to numerical difficulties as m and s increase, which are caused by the underlying power form representation and by the conditioning of the matrix C m . Richardson acceleration. In the interest of stability, another approach that was used in [12] for the single right-hand side case consists of explicitly obtaining the GMRES polynomial but applying it using Richardson's method. <p> Thus, for each k = 1; : : : ; s, the Richardson procedure accomplishes the multiplication ([14]) r (k) m :(3.4) To reduce the risk of instability in the Richardson procedure, we use Leja ordering for the parameters of <ref> [12] </ref>; moreover, we coupled complex pairs of roots as in [16], in order to avoid complex arithmetic. We call this algorithm BG-RICH and present it in Table 3.1. <p> We also note that the method described in <ref> [12] </ref> for the single right-hand side case does not use restarting, but applies the GMRES polynomial repeatedly, enlarging m whenever its effect on the residual is not satisfactory. Unfortunately, because of its numerical sensitivity and added cost this option becomes less practical as s increases. 4. Experiments.
Reference: [13] <author> D. P. O'LEARY, </author> <title> The block conjugate gradient algorithm and related methods, </title> <journal> Lin. Alg. Appl., </journal> <volume> 29 (1980), </volume> <pages> pp. 293-322. </pages>
Reference-contexts: Two methods that have been discussed in the literature are block GMRES (BGMRES) [17, 18, 19] and the block biconjugate gradient algorithm (BBCG) <ref> [13] </ref>. Given R; ^ R 2 R nfis , the methods use the block Krylov subspace K m (A; R) := fR; AR; : : : ; A m1 Rg (and K m (A T ; ^ R) for BBCG), to approximate X .
Reference: [14] <author> G. OPFER AND G. SCHOBER, </author> <title> Richardson's iteration for nonsymmetric matrices, </title> <journal> Lin. Alg. Appl., </journal> <volume> 58 (1984), </volume> <pages> pp. 343-361. </pages>
Reference: [15] <author> Y. SAAD AND M.H. SCHULTZ, </author> <title> GMRES: A generalizedminimal residual algorithm for solving nonsymmetric linear systems, </title> <journal> SIAM J. Sci. Comput., </journal> <volume> 7(3) </volume> <pages> 856-869, </pages> <month> July </month> <year> 1986. </year>
Reference: [16] <author> P. E. SAYLOR AND D. C. SMOLARSKI, </author> <title> Implementation of an adaptive algorithm for Richardson's method, </title> <journal> Lin. Alg. Appl., </journal> <month> 154-156 </month> <year> (1991), </year> <pages> pp. 615-646. </pages>
Reference-contexts: to the method that we propose as hybrid BGMRES, because it extracts and applies the matrix polynomial obtained in the course of a BGMRES step; as such, the method attempts to combine the advantages of the block approach with those of recent hybrid methods by Joubert [10], Saylor and Smolarski <ref> [16] </ref>, and especially Nachtigal, Reichel and Trefethen [12]. One method close to ours, but restricted to positive definite Hermitian systems was proposed by Calvetti and Reichel [1]. <p> Thus, for each k = 1; : : : ; s, the Richardson procedure accomplishes the multiplication ([14]) r (k) m :(3.4) To reduce the risk of instability in the Richardson procedure, we use Leja ordering for the parameters of [12]; moreover, we coupled complex pairs of roots as in <ref> [16] </ref>, in order to avoid complex arithmetic. We call this algorithm BG-RICH and present it in Table 3.1.
Reference: [17] <author> V. SIMONCINI AND E. </author> <title> GALLOPOULOS,An iterative method for nonsymmetric systems with multiple right-hand sides, </title> <journal> SIAM J. Sci. Comput., </journal> <volume> 16(4) </volume> <pages> 917-933, </pages> <month> July </month> <year> 1995. </year> <title> [18] , Convergence properties of block GMRES and matrix polynomials, </title> <journal> Lin. Alg. Appl., </journal> <note> to appear. Also Tech. Report 1316 (1994 revision), </note> <institution> Center for Supercomputing Research and Development. </institution>
Reference-contexts: Two methods that have been discussed in the literature are block GMRES (BGMRES) <ref> [17, 18, 19] </ref> and the block biconjugate gradient algorithm (BBCG) [13]. <p> The former problem seems to affect BBCG, while the latter was found to have consequences that are adverse to the performance of BGMRES. It is sufficient to observe that the BGMRES iterates are computed using block recurrences of increasing work and storage requirements per iteration. Experiments in <ref> [17] </ref> indicated that because of these costs, BGMRES has great difficulty competing with other solvers. Therefore, the question that arises is how to modify the BGMRES method in order to make it viable and competitive. In this paper we propose one approach for addressing this question. <p> of the final residual matrix with maximum norm, obtained from BGMRES, is at most as large as the maximum residual norm among the s residuals obtained from the Krylov subspaces K m (A; r (j) 0 ), (1 j s) after the independent application of GMRES to each system; see <ref> [17, 19] </ref>. <p> The high costs of BGMRES can be handled, in part, by restarting the procedure after m (block) iterations. Using such a restarted algorithm, however, entails lack of minimization over the entire block Krylov subspace and leads to performance losses <ref> [17] </ref>. It was shown in [12] that by computing the GMRES polynomial and applying it on the residual vector after a certain number of GMRES steps it is 2 possible to obtain a scheme that is frequently faster than GMRES. A restarted hybrid algorithm was also presented in [10]. <p> We describe such a strategy and show its effectiveness in Section 4. The numerical experiments therein suggest that its application increases the performance of the BGMRES method whenever ms is large. Table 3.2 lists the computational costs of BGMRES (cf. <ref> [17] </ref>) and the additional costs corresponding to each implementation of the block hybrid approach. The cost associated with the computation of the parameters for the polynomial acceleration led us to reuse the same BGMRES polynomial ( m or m ) during all instances of phase 3 of the algorithm. <p> We expect that an effective multiple right-hand side solver should achieve a sublinear increase of T (s) with s (cf. <ref> [17] </ref>). For large values of ms the hybrid BGMRES implementations followed the strategy we described in Section 3.2 and applied polynomial acceleration with the residual matrix polynomial corresponding to K m , where 1 m min (m; b100=sc). <p> Our numerical experiments show that i) the hybrid block approach improves the performance of BGMRES, and ii) the method is competitive and frequently faster than standard single right-hand side solvers such as GMRES and TFQMR. Another successful hybrid scheme for multiple right-hand sides was discussed in <ref> [17] </ref>. That scheme was based on approximating the solution of (1.1) by generating parameters from a single seed subspace at a time. Instead, here, we advanced by building polynomials based on the entire subspace.
Reference: [19] <author> B. </author> <title> VITAL, Etude de quelques methodes de resolution de problemes lineaires de grande taille sur multipro-cesseur, </title> <type> PhD thesis, </type> <institution> Universite de Rennes I, Rennes, </institution> <month> Nov. </month> <year> 1990. </year> <month> 12 </month>
Reference-contexts: Two methods that have been discussed in the literature are block GMRES (BGMRES) <ref> [17, 18, 19] </ref> and the block biconjugate gradient algorithm (BBCG) [13]. <p> procedure to produce an orthogonal basis for K m (A; R 0 ) and then solves a block least squares problem with the (block) Hessenberg matrix H m , which is the representation of the section of A in K m (A; R 0 ) relative to the selected basis <ref> [19] </ref>. <p> of the final residual matrix with maximum norm, obtained from BGMRES, is at most as large as the maximum residual norm among the s residuals obtained from the Krylov subspaces K m (A; r (j) 0 ), (1 j s) after the independent application of GMRES to each system; see <ref> [17, 19] </ref>.
References-found: 16

