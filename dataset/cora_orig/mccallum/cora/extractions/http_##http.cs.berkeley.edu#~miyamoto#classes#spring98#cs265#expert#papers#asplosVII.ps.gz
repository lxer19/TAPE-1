URL: http://http.cs.berkeley.edu/~miyamoto/classes/spring98/cs265/expert/papers/asplosVII.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~miyamoto/classes/spring98/cs265/expert/index.html
Root-URL: http://www.cs.berkeley.edu
Title: A Quantitative Analysis of Loop Nest Locality  
Author: Kathryn S. M c Kinley Olivier Temam 
Address: Versailles University  
Affiliation: University of Massachusetts  
Abstract: This paper analyzes and quantifies the locality characteristics of numerical loop nests in order to suggest future directions for architecture and software cache optimizations. Since most programs spend the majority of their time in nests, the vast majority of cache optimization techniques target loop nests. In contrast, the locality characteristics that drive these optimizations are usually collected across the entire application rather than the nest level. Indeed, researchers have studied numerical codes for so long that a number of commonly held assertions have emerged on their locality characteristics. In light of these assertions, we use the Perfect Benchmarks to take a new look at measuring locality on numerical codes based on references, loop nests, and program locality properties. Our results show that several popular assertions are at best overstatements. For example, we find that temporal and spatial reuse have balanced roles within a loop nest and most reuse across nests and the entire program is temporal. These results are consistent with high hit rates, but go against the commonly held assumption that spatial reuse dominates. Another result contrary to popular assumption is that misses within a nest are overwhelmingly conflict misses rather than capacity misses. Capacity misses are a significant source of misses for the entire program, but mostly correspond to potential reuse between different loop nests. Our locality measurements reveal important differences between loop nests and programs; refute some popular assertions; and provide new insights for the compiler writer and the architect. 
Abstract-found: 1
Intro-found: 1
Reference: [AP93] <author> A. Agarwal and S. D. Pudar. </author> <title> Column-associative caches: A technique for reducing the miss rate of direct-mapped caches. </title> <booktitle> In Proceedings of the 20th International Symposium on Computer Architecture,pages 169-178, </booktitle> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: These assertions, listed in Table 1, arise from extensive measurements of complete programs [Bel66, GHPS93, Hil88, HS89, HP95, PHH88, Smi82, SA93], slightly more narrow measurements that evaluate proposed hardware or software techniques <ref> [AP93, CB95, Dra95, Jou90, KL91, MLG92] </ref>, and software models [CMT94, GJG88, MLG92, WL91]. Our results dispute Assertions 1 and 2, and confirm Assertions 3 and 4 for our benchmark suite. <p> Capacity misses occur more frequently than conflict misses, and both are significant sources of misses [HP95, HS89, SA93]. a. Do ping-pong conflicts occur frequently? b. 2-way set-associative caches remove the majority of conflict misses <ref> [AP93, HS89] </ref>. 3. Most reuse occurs within a nest rather than across nests [CMT94, TGJ93, WL91]. a. Targeting individual loop nests is sufficient. b. Is inter-nest reuse difficult to exploit? 4. Many memory references within numerical codes correspond to reg ular references [BC91]. a.
Reference: [ASW + 93] <author> S. G. Abraham, R. A. Sugumar, D. Windheiser, B. R. Rau, and R. Gupta. </author> <title> Predictability of load/store instruction latencies. </title> <booktitle> In Proceedings of the 28th International Symposium on Microarchitecture, </booktitle> <address> Austin, TX, </address> <month> De-cember </month> <year> 1993. </year>
Reference-contexts: Misses are accumulated over all nest instructions which are sorted by decreasing number of total misses. These results confirm Abraham et al.'s <ref> [ASW + 93] </ref> findings that misses are concentrated in particular load/store instructions. In addition, Figure 18 illustrates that the concentration is even higher for stream misses, misses occurring within streams. For instance, 27% of DYFESM's stream misses occur within a single instruction.
Reference: [BBG + 94] <author> F. Bodin, P. Beckman, D. Gannon, J. Gotwals, S. Narayana, S. Srinivas, and B. Winnicka. Sage++: </author> <title> An object-orientedtoolkit and class library for building Fortran and C++ restructuring tools. </title> <booktitle> In Second Object-Oriented Numerics Conference, </booktitle> <year> 1994. </year>
Reference-contexts: We compiled the benchmarks with Sun's F77 compiler using -O2 which includes all optimizations except optimizations on global variables and loop unrolling. We disabled loop unrolling because it obscures self and group locality. We instrumented the programs with Sage++, a source-to-source Fortran compiler <ref> [BBG + 94] </ref>. Our Sage++ routine detects loop nests as described in Section 2.1 and inserts variables and subroutine calls to uniquely identify nests. Spy catches the instrumented subroutine calls. Since the subroutine calls are outside of the nests and contain very few assembly instructions, the trace perturbation is negligible.
Reference: [BC91] <author> J-L. Baer and T-F. Chen. </author> <title> An effective on-chip preloading scheme to reduce data access penalty. </title> <booktitle> In Proceedings of Supercomputing '91, </booktitle> <address> Al-buquerque, NM, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: Most reuse occurs within a nest rather than across nests [CMT94, TGJ93, WL91]. a. Targeting individual loop nests is sufficient. b. Is inter-nest reuse difficult to exploit? 4. Many memory references within numerical codes correspond to reg ular references <ref> [BC91] </ref>. a. What is the fraction of misses due to scalar references? b. The most commonly used stride value is 1. c. Loop nest structures are mostly rectangular and triangular. tions, we examine the relevant assertions and mention related work.
Reference: [Bel66] <author> L. A. Belady. </author> <title> A study of replacement algorithms for a virtual-storage computer. </title> <journal> IBM Systems Journal, </journal> <volume> 5(2) </volume> <pages> 79-101, </pages> <year> 1966. </year>
Reference-contexts: To provide a framework for our study, we examined the literature on memory optimizations and extracted some of the most prevalent assertions. These assertions, listed in Table 1, arise from extensive measurements of complete programs <ref> [Bel66, GHPS93, Hil88, HS89, HP95, PHH88, Smi82, SA93] </ref>, slightly more narrow measurements that evaluate proposed hardware or software techniques [AP93, CB95, Dra95, Jou90, KL91, MLG92], and software models [CMT94, GJG88, MLG92, WL91]. Our results dispute Assertions 1 and 2, and confirm Assertions 3 and 4 for our benchmark suite.
Reference: [BGK95] <author> D. Burger, J. R. Goodman, and A. Kagi. </author> <title> The declining effectiveness of dynamic caching for general-puropose microprocessors. </title> <type> Technical Report 1216, </type> <institution> Dept. of Computer Science, University of Wisconsin at Madison, </institution> <month> January </month> <year> 1995. </year>
Reference-contexts: Long cache block agonies have also been observed by Wood et al. [WHK91] and Burger et al. <ref> [BGK95] </ref>. 4.2.5 Summary of Results The major findings of this section refute Assertions 1 and 2. Instead of a preponderance of spatial reuse, we find a more balanced role between spatial and temporal reuse (Assertion 1.a), particularly group-temporal reuse.
Reference: [BKG96] <author> D. Burger, A. Kagi, and J. R. Goodman. </author> <title> Memory bandwidth limitations of future microprocessors. </title> <booktitle> In Proceedings of the 23rd International Symposium on Computer Architecture, </booktitle> <address> Philadelphia, PA, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: These statistics contradict Assertion 1.b. An important corollary to this observation is that cache blocks are not efficiently exploited and many loaded words are not used, wasting cache bandwidth. Other works support these results <ref> [BKG96, TFMP95, WHK91] </ref>.
Reference: [CB95] <author> T. Chen and J. Baer. </author> <title> Effective hardware based data prefetching. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 44(5) </volume> <pages> 609-623, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Most of this work depends on loop nests to provide predictable and regular data accesses. Techniques to improve data cache performance typically target and model locality characteristics found in loop nests. For example, software and hardware prefetching exploit the spatial locality of regular accesses in loop nests <ref> [CB95, CKP91, Dra95, KL91, MLG92] </ref>. <p> These assertions, listed in Table 1, arise from extensive measurements of complete programs [Bel66, GHPS93, Hil88, HS89, HP95, PHH88, Smi82, SA93], slightly more narrow measurements that evaluate proposed hardware or software techniques <ref> [AP93, CB95, Dra95, Jou90, KL91, MLG92] </ref>, and software models [CMT94, GJG88, MLG92, WL91]. Our results dispute Assertions 1 and 2, and confirm Assertions 3 and 4 for our benchmark suite. <p> Probably the most widespread assertion we address is Assertion 1: Spatial reuse is the dominant form of reuse [CMT94, Jou90, KW73, PHH88, Smi82, Smi87]. For example, all modern caches use block sizes greater than one. Spatial locality enables hardware and software prefetching to achieve most of its improvements <ref> [CB95, Dra95, Jou90, KL91, MLG92] </ref>. Software techniques have also attributed their improvements to improved spatial locality [CMT94]. 4.1 Intra-Nest Reuse spatial. <p> We show that the locality patterns between intra-nest, inter-nest, and program locality are usually very different. 8 6 Load/Store Locality Hardware and software optimizations target not only nests, but the load/store instructions within nests. For instance, prefetching tables <ref> [CB95] </ref> analyze the stride of each load/store instruction within nests. Compilers of course translate array references into load/store instructions. Optimizing compilers may expand array references into several load/store instructions. Other advanced optimizations, like scalar replacement combined with unroll-and-jam [CCK90, CK94], collapse several array references into a single load/store. <p> For this reason, numerical codes are often called regular codes. A load/store instruction induces a regular reference if the distance between 3 consecutive references (2 strides) is identical (the hardware characterization proposed by Chen and Baer <ref> [CB95] </ref>). A set of regular references using a constant stride is called a stream. The stream ends with the nest execution or when the stride changes. Figure 17 quantifies the fraction of references that belong to streams. <p> Therefore, the stride changes, the stream ends, and hence the short stream lengths. Short stream lengths can disrupt hardware prefetching. For instance in prefetch tables <ref> [CB95] </ref>, prefetching stops if the stride changes and the instruction must make 3 new stream references to stabilize. <p> This result suggests prefetching should handle stride changes [MLG92] as well as stream references <ref> [CB95] </ref>. To determine the influence of short length streams and the potential of data tagged prefetching, we implemented a form of virtual tagged prefetching.
Reference: [CCK90] <author> D. Callahan, S. Carr, and K. Kennedy. </author> <title> Improving register allocation for subscripted variables. </title> <booktitle> In Proceedings of the SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <address> White Plains, NY, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: For instance, prefetching tables [CB95] analyze the stride of each load/store instruction within nests. Compilers of course translate array references into load/store instructions. Optimizing compilers may expand array references into several load/store instructions. Other advanced optimizations, like scalar replacement combined with unroll-and-jam <ref> [CCK90, CK94] </ref>, collapse several array references into a single load/store.
Reference: [CK94] <author> S. Carr and K. Kennedy. </author> <title> Improving the ratio of memory operations to floating-point operations in loops. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 15(3) </volume> <pages> 400-462, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: For instance, prefetching tables [CB95] analyze the stride of each load/store instruction within nests. Compilers of course translate array references into load/store instructions. Optimizing compilers may expand array references into several load/store instructions. Other advanced optimizations, like scalar replacement combined with unroll-and-jam <ref> [CCK90, CK94] </ref>, collapse several array references into a single load/store.
Reference: [CKM95] <author> K. Cooper, K. Kennedy, and N. McIntosh. </author> <title> An empirical study of cross-loop reuse in the NAS benchmarks. </title> <type> Technical Report CRPC-TR95519-S, </type> <institution> Center for Research on Parallel Computation, Rice University, </institution> <month> October </month> <year> 1995. </year>
Reference-contexts: ARC2D, OCEAN, BDNA, and FLO52 all achieve 100% intra-nest reuse. McIntosh et al. confirm this result for small caches, and show when caches are much larger and hit rates drop, inter-nest reuse is more prevalent <ref> [CKM95] </ref>. Although most reuse is intra-nest (Figure 13), more than 70% of misses are inter-nest (Figure 14). To decrease these misses, optimizations cannot simply focus on nest optimizations but need to consider more than one nest, in contrast to Assertion 3.a.
Reference: [CKM96] <author> K. Cooper, K. Kennedy, and N. McIntosh. </author> <title> Cross-loop reuse analysis and its application to cache optimizations. </title> <booktitle> In Proceedings of the Ninth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Santa Clara, CA, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: McIn-tosh et al. <ref> [CKM96] </ref> propose an inter-nest reuse analysis to exploit locality, but have not yet implemented it. Figures 4, 5, 7, and 8 continue the trend away from spatial locality that we saw in Section 4.1 for intra-nest reuse. Spatial locality accounts for only 14% of inter-nest reuse.
Reference: [CKP91] <author> D. Callahan, K. Kennedy, and A. Porterfield. </author> <title> Software prefetching. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 40-52, </pages> <address> Santa Clara, CA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: Most of this work depends on loop nests to provide predictable and regular data accesses. Techniques to improve data cache performance typically target and model locality characteristics found in loop nests. For example, software and hardware prefetching exploit the spatial locality of regular accesses in loop nests <ref> [CB95, CKP91, Dra95, KL91, MLG92] </ref>.
Reference: [CKPK90] <author> G. Cybenko, L. Kipp, L. Pointer, and D. Kuck. </author> <title> Supercomputer performance evaluation and the Perfect benchmarks. </title> <booktitle> In Proceedings of the 1990 ACM International Conference on Supercomputing, </booktitle> <address> Amsterdam, The Netherlands, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Matrix-Matrix Multiply in reference to X has group-spatial locality with the second reference to X. (See Section 4.1 for additional examples.) 2.3 Test Suite For our test suite, we used 8 of the Perfect Benchmark programs which range in number of non-comment lines from 485 to 6105, averaging 3509 lines <ref> [CKPK90] </ref>. Although the Perfect Benchmarks suffer from the same flaw as SPEC92 [Uni89], namely small data set sizes, they are real applications, and thus are more likely to exhibit classic programming patterns.
Reference: [CM95] <author> S. Coleman and K. S. M c Kinley. </author> <title> Tile size selection using cache organization and data layout. </title> <booktitle> In Proceedings of the SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <address> La Jolla, CA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Because processor speed is increasingly outpacing memory speed, an enormous amount of research focuses on improving the cache behavior of numerical programs (see for example, Smith's bibliographies on hardware aspects of cache memories [Smi86, Smi91] and compiler techniques that exploit cache memories <ref> [CM95, CMT94, LRW91, MLG92, WL91] </ref>). Most of this work depends on loop nests to provide predictable and regular data accesses. Techniques to improve data cache performance typically target and model locality characteristics found in loop nests. <p> In QCD2 and TRFD, several nests had large working set sizes, about 256 Kbytes, but these misses barely contribute to the total number of intra-nest misses. Several software techniques focus on selecting tile sizes that eliminate capacity misses and do not introduce self-interference misses <ref> [CM95, LRW91] </ref>. These tiling studies focus on kernels, and have yet to demonstrate effectiveness on complete applications. The lack of capacity misses in Figure 10 indicates that the data set sizes for these programs are too small to make tiling effective.
Reference: [CMT94] <author> S. Carr, K. S. M c Kinley, and C. Tseng. </author> <title> Compiler optimizations for improving data locality. </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> San Jose, CA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Because processor speed is increasingly outpacing memory speed, an enormous amount of research focuses on improving the cache behavior of numerical programs (see for example, Smith's bibliographies on hardware aspects of cache memories [Smi86, Smi91] and compiler techniques that exploit cache memories <ref> [CM95, CMT94, LRW91, MLG92, WL91] </ref>). Most of this work depends on loop nests to provide predictable and regular data accesses. Techniques to improve data cache performance typically target and model locality characteristics found in loop nests. <p> These assertions, listed in Table 1, arise from extensive measurements of complete programs [Bel66, GHPS93, Hil88, HS89, HP95, PHH88, Smi82, SA93], slightly more narrow measurements that evaluate proposed hardware or software techniques [AP93, CB95, Dra95, Jou90, KL91, MLG92], and software models <ref> [CMT94, GJG88, MLG92, WL91] </ref>. Our results dispute Assertions 1 and 2, and confirm Assertions 3 and 4 for our benchmark suite. <p> Within each of the sec 1 Table 1: Assertions about reuse characteristics and cache behavior of numerical programs Assertions Related Issues, Assertions, & Questions 1. Spatial reuse is the dominant form of reuse <ref> [CMT94, Jou90, KW73, PHH88, Smi82, Smi87] </ref>. a. Temporal reuse avoids fewer misses than spatial. b. Cache blocks effectively exploit spatial reuse [KW73, PHH88, Smi82, Smi87]. c. Most cache pollution is due to spatial-only blocks, i.e., blocks which are only reused spatially [Pou94]. 2. <p> Capacity misses occur more frequently than conflict misses, and both are significant sources of misses [HP95, HS89, SA93]. a. Do ping-pong conflicts occur frequently? b. 2-way set-associative caches remove the majority of conflict misses [AP93, HS89]. 3. Most reuse occurs within a nest rather than across nests <ref> [CMT94, TGJ93, WL91] </ref>. a. Targeting individual loop nests is sufficient. b. Is inter-nest reuse difficult to exploit? 4. Many memory references within numerical codes correspond to reg ular references [BC91]. a. What is the fraction of misses due to scalar references? b. <p> All of our figures use this basic configuration. We also discuss a few results for a 2-way set-associative version of the same cache (the Intel P6 [Res95] first-level data cache implements these parameters). Our nest selection, on average, considers more nests than Carr et al. <ref> [CMT94] </ref> consider for optimization. The numbers are not directly comparable because Carr et al. do not include single loops and consider more complex nesting structures than we do. In 7 of the 8 programs, 88% or more of the references occur within the nests we instrumented. <p> Probably the most widespread assertion we address is Assertion 1: Spatial reuse is the dominant form of reuse <ref> [CMT94, Jou90, KW73, PHH88, Smi82, Smi87] </ref>. For example, all modern caches use block sizes greater than one. Spatial locality enables hardware and software prefetching to achieve most of its improvements [CB95, Dra95, Jou90, KL91, MLG92]. <p> For example, all modern caches use block sizes greater than one. Spatial locality enables hardware and software prefetching to achieve most of its improvements [CB95, Dra95, Jou90, KL91, MLG92]. Software techniques have also attributed their improvements to improved spatial locality <ref> [CMT94] </ref>. 4.1 Intra-Nest Reuse spatial. QCD2, TRFD, and DYFESM achieve a majority of spatial reuse (51%, 56%, and 61%, respectively), but FLO52, ARC2D, ADM, OCEAN, and BDNA achieve a majority of temporal reuse (61%, 61%, 66%, 68%, and 87%, respectively). <p> These results also hold for 2-way set-associativity and are in contrast to Assertion 1 and 1.a since spatial reuse is never the single overwhelming factor. Compiler algorithms to improve locality target group and self, spatial and temporal locality <ref> [CMT94, TGJ93, WL91] </ref>. All of which have a role in these results. Two classic examples in Figure 1 that demonstrate a mixture of self-temporal, group-temporal, self-spatial, and group-spatial reuse are Matrix-Vector Multiply and Matrix-Matrix Multiply. <p> All of which have a role in these results. Two classic examples in Figure 1 that demonstrate a mixture of self-temporal, group-temporal, self-spatial, and group-spatial reuse are Matrix-Vector Multiply and Matrix-Matrix Multiply. Both are written in the best order for exploiting short-term data locality, assuming Fortran's column-major order <ref> [CMT94, WL91] </ref>. In Matrix-Vector Multiply on the inner J loop, the cache should exploit group-temporal locality for C, self-spatial for A, and self-spatial for D. For the entire nest, C is group-spatial and temporal, A is self-spatial, and D is self-spatial and temporal. <p> Most misses in the original program are at a distance of 2 10 or greater. Loop interchange and fusion improve ARC2D's performance by a factor of 2.15 on an IBM/RS6000 <ref> [CMT94] </ref>. However, a significant portion of intra-nest self-spatial misses occur for very short reuse distances. <p> The spatial locality occurs after a complete execution of the inner loop. Since the spatial locality is far apart, it is difficult to exploit. As we discussed in Section 4.2, loop interchange can solve this problem for some nests <ref> [CMT94] </ref>. We found such references to be responsible for a high share of global pollution, in line with Assertion 1.c: Most cache pollution is due to spatial-only blocks.
Reference: [Dig94] <institution> Digital Equipment Corporation, Maynard, </institution> <month> Massachussets. </month> <title> Alpha 21164 Microprocessor, Hardware Reference Manual, </title> <year> 1994. </year>
Reference-contexts: in nests and out of nests; the total number of references; the working set size of the program; the number of instrumented loop nests partitioned into nests of depth 1, 2, and 3; and the program miss rate for an 8-Kbyte, 32-Byte block size, direct-mapped data cache (the DEC 21164 <ref> [Dig94] </ref> first-level data cache implements these parameters). These miss rates vary from 1.1 to 9.9%. We selected the smallest cache parameters available in current processors to keep the ratio of data set size to cache size as close as possible to that of real programs run on future-generation processors.
Reference: [Dra95] <author> N. Drach. </author> <title> Hardware implementation issues of data prefetching. </title> <booktitle> In Proceedings of the 1995 ACM International Conference on Supercomputing, </booktitle> <pages> pages 323-334, </pages> <address> Barcelona, Spain, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: Most of this work depends on loop nests to provide predictable and regular data accesses. Techniques to improve data cache performance typically target and model locality characteristics found in loop nests. For example, software and hardware prefetching exploit the spatial locality of regular accesses in loop nests <ref> [CB95, CKP91, Dra95, KL91, MLG92] </ref>. <p> These assertions, listed in Table 1, arise from extensive measurements of complete programs [Bel66, GHPS93, Hil88, HS89, HP95, PHH88, Smi82, SA93], slightly more narrow measurements that evaluate proposed hardware or software techniques <ref> [AP93, CB95, Dra95, Jou90, KL91, MLG92] </ref>, and software models [CMT94, GJG88, MLG92, WL91]. Our results dispute Assertions 1 and 2, and confirm Assertions 3 and 4 for our benchmark suite. <p> Probably the most widespread assertion we address is Assertion 1: Spatial reuse is the dominant form of reuse [CMT94, Jou90, KW73, PHH88, Smi82, Smi87]. For example, all modern caches use block sizes greater than one. Spatial locality enables hardware and software prefetching to achieve most of its improvements <ref> [CB95, Dra95, Jou90, KL91, MLG92] </ref>. Software techniques have also attributed their improvements to improved spatial locality [CMT94]. 4.1 Intra-Nest Reuse spatial. <p> a scalar if the address referenced changes from one execution of the nest to another. the potential of prefetching can be measured since virtual prefetch-ing ignores cache side-effects such as flushing prefetched blocks too early, the pollution of useful data, coherence issues, and limitations due to the prefetch buffer size <ref> [Dra95] </ref>. In Figure 19, the fraction of intra-nest misses that can be potentially removed with prefetch-ing is plotted as a function of the prefetch distance in number of references between the prefetch and the use.
Reference: [GHPS93] <author> J. D. Gee, M. D. Hill, D. N. Pnevmatikatos, and A. J. Smith. </author> <title> Cache performanceof the SPEC92 benchmarksuite. </title> <journal> IEEE Micro, </journal> <volume> 13(4) </volume> <pages> 17-27, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: To provide a framework for our study, we examined the literature on memory optimizations and extracted some of the most prevalent assertions. These assertions, listed in Table 1, arise from extensive measurements of complete programs <ref> [Bel66, GHPS93, Hil88, HS89, HP95, PHH88, Smi82, SA93] </ref>, slightly more narrow measurements that evaluate proposed hardware or software techniques [AP93, CB95, Dra95, Jou90, KL91, MLG92], and software models [CMT94, GJG88, MLG92, WL91]. Our results dispute Assertions 1 and 2, and confirm Assertions 3 and 4 for our benchmark suite.
Reference: [GJG88] <author> D. Gannon, W. Jalby, and K. Gallivan. </author> <title> Strategies for cache and local memory management by global program transformation. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5(5) </volume> <pages> 587-616, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: These assertions, listed in Table 1, arise from extensive measurements of complete programs [Bel66, GHPS93, Hil88, HS89, HP95, PHH88, Smi82, SA93], slightly more narrow measurements that evaluate proposed hardware or software techniques [AP93, CB95, Dra95, Jou90, KL91, MLG92], and software models <ref> [CMT94, GJG88, MLG92, WL91] </ref>. Our results dispute Assertions 1 and 2, and confirm Assertions 3 and 4 for our benchmark suite.
Reference: [Hil87] <author> M. D. Hill. </author> <title> Aspects of Cache Memory and Instruction Buffer Performance. </title> <type> PhD thesis, </type> <institution> Computer Science Dept., University of California, Berkeley, </institution> <year> 1987. </year> <note> Available as Technical Report UCB/CSD 87/381. </note>
Reference-contexts: in the cache, we use Hill's miss classification which is orthogonal to the above: compulsory misses misses that occur on the first reference to a block; capacity misses additional misses resulting from the limited capacity of a cache; and conflict misses additional misses due to mapping constraints in set-associative caches <ref> [Hil87, HS89] </ref>. Like Hill, we measure conflict and capacity misses with respect to a fully-associative cache using an LRU replacement policy. We measure the locality distance in terms of the number of memory references (load/store references in the trace) between two references to the same word or cache block.
Reference: [Hil88] <author> M. D. Hill. </author> <title> A case for direct-mappedcaches. </title> <journal> IEEE Computer, </journal> <volume> 21(12) </volume> <pages> 25-40, </pages> <month> December </month> <year> 1988. </year>
Reference-contexts: To provide a framework for our study, we examined the literature on memory optimizations and extracted some of the most prevalent assertions. These assertions, listed in Table 1, arise from extensive measurements of complete programs <ref> [Bel66, GHPS93, Hil88, HS89, HP95, PHH88, Smi82, SA93] </ref>, slightly more narrow measurements that evaluate proposed hardware or software techniques [AP93, CB95, Dra95, Jou90, KL91, MLG92], and software models [CMT94, GJG88, MLG92, WL91]. Our results dispute Assertions 1 and 2, and confirm Assertions 3 and 4 for our benchmark suite.
Reference: [HP95] <author> J. Hennessy and D. Patterson. </author> <title> Computer Architecture A Quantitative Approach. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1995. </year>
Reference-contexts: Even though many of these approaches yield significant improvements, there exists no broad quantitative study of loop nest locality, of which we are aware, driving this exploration. New memory architectures can exploit locality more selectively than previous caches <ref> [HP95, MW96] </ref>. For example, the HP-7200 [HP95] uses a form of cache bypass for a reference stream with only spatial locality. These architectures require detailed knowledge about the locality properties of loop nests and programs. Of course, much of the research on memory optimizations analyzes relevant locality characteristics. <p> Even though many of these approaches yield significant improvements, there exists no broad quantitative study of loop nest locality, of which we are aware, driving this exploration. New memory architectures can exploit locality more selectively than previous caches [HP95, MW96]. For example, the HP-7200 <ref> [HP95] </ref> uses a form of cache bypass for a reference stream with only spatial locality. These architectures require detailed knowledge about the locality properties of loop nests and programs. Of course, much of the research on memory optimizations analyzes relevant locality characteristics. <p> Of course, much of the research on memory optimizations analyzes relevant locality characteristics. These studies are typically conducted across the entire application, while many optimizations just target loop nests. For instance, several studies find numerous capacity misses in applications <ref> [HP95, HS89, SA93] </ref>. If these misses actually correspond to locality across distinct nests, loop nest optimizations are unlikely to eliminate them. In this paper, we investigate the locality behavior of loop nests in order to suggest targets for future software and hardware research. <p> To provide a framework for our study, we examined the literature on memory optimizations and extracted some of the most prevalent assertions. These assertions, listed in Table 1, arise from extensive measurements of complete programs <ref> [Bel66, GHPS93, Hil88, HS89, HP95, PHH88, Smi82, SA93] </ref>, slightly more narrow measurements that evaluate proposed hardware or software techniques [AP93, CB95, Dra95, Jou90, KL91, MLG92], and software models [CMT94, GJG88, MLG92, WL91]. Our results dispute Assertions 1 and 2, and confirm Assertions 3 and 4 for our benchmark suite. <p> Cache blocks effectively exploit spatial reuse [KW73, PHH88, Smi82, Smi87]. c. Most cache pollution is due to spatial-only blocks, i.e., blocks which are only reused spatially [Pou94]. 2. Capacity misses occur more frequently than conflict misses, and both are significant sources of misses <ref> [HP95, HS89, SA93] </ref>. a. Do ping-pong conflicts occur frequently? b. 2-way set-associative caches remove the majority of conflict misses [AP93, HS89]. 3. Most reuse occurs within a nest rather than across nests [CMT94, TGJ93, WL91]. a. Targeting individual loop nests is sufficient. b. Is inter-nest reuse difficult to exploit? 4. <p> may differ significantly. 2.2 Classifying Locality and Reuse The classical definitions of locality properties found in programs are: temporal locality if an item is referenced, it will tend to be referenced again soon; and spatial locality if an item is referenced, an adjacent item will tend to be referenced soon <ref> [HP95] </ref>. Given a reference, cache designers exploit temporal locality by placing the referenced word into the cache, and spatial locality by using a cache block size greater than one word that places adjacent words in the cache at the same time. <p> Future architectural and software improvements to cache performance may therefore need to selectively load the cache and/or use adjustable cache block sizes. 4.2.3 Capacity and Conflict Misses Previous research demonstrates Assertion 2: Capacity misses occur more frequently than conflict misses, and both are significant sources of misses for whole programs <ref> [HP95, HS89, SA93] </ref>. Conflict misses play the lesser role in these results, typically making up about 30-40% of misses. Figure 12 divides program misses into self and group, 1 capacity and conflict misses, again plotting the fraction of misses against their distance. <p> On average, conflict misses reduce to 68% of intra-nest misses with 2-way set-associativity, but are still a significantly larger fraction than the average of 30 to 40% conflict misses on whole programs for direct-mapped caches in Figure 12 and other studies <ref> [SA93, HP95] </ref>. Considering that these programs have relatively high hit rates (see Table 2), this result should not have been surprising. The working set of most executions of a loop nest should fit and already be in the cache, implying inter-nest misses should be conflict misses.
Reference: [HS89] <author> M. D. Hill and A. J. Smith. </author> <title> Evaluating associativity in cpu caches. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(12) </volume> <pages> 1612-1630, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: Of course, much of the research on memory optimizations analyzes relevant locality characteristics. These studies are typically conducted across the entire application, while many optimizations just target loop nests. For instance, several studies find numerous capacity misses in applications <ref> [HP95, HS89, SA93] </ref>. If these misses actually correspond to locality across distinct nests, loop nest optimizations are unlikely to eliminate them. In this paper, we investigate the locality behavior of loop nests in order to suggest targets for future software and hardware research. <p> To provide a framework for our study, we examined the literature on memory optimizations and extracted some of the most prevalent assertions. These assertions, listed in Table 1, arise from extensive measurements of complete programs <ref> [Bel66, GHPS93, Hil88, HS89, HP95, PHH88, Smi82, SA93] </ref>, slightly more narrow measurements that evaluate proposed hardware or software techniques [AP93, CB95, Dra95, Jou90, KL91, MLG92], and software models [CMT94, GJG88, MLG92, WL91]. Our results dispute Assertions 1 and 2, and confirm Assertions 3 and 4 for our benchmark suite. <p> Cache blocks effectively exploit spatial reuse [KW73, PHH88, Smi82, Smi87]. c. Most cache pollution is due to spatial-only blocks, i.e., blocks which are only reused spatially [Pou94]. 2. Capacity misses occur more frequently than conflict misses, and both are significant sources of misses <ref> [HP95, HS89, SA93] </ref>. a. Do ping-pong conflicts occur frequently? b. 2-way set-associative caches remove the majority of conflict misses [AP93, HS89]. 3. Most reuse occurs within a nest rather than across nests [CMT94, TGJ93, WL91]. a. Targeting individual loop nests is sufficient. b. Is inter-nest reuse difficult to exploit? 4. <p> Capacity misses occur more frequently than conflict misses, and both are significant sources of misses [HP95, HS89, SA93]. a. Do ping-pong conflicts occur frequently? b. 2-way set-associative caches remove the majority of conflict misses <ref> [AP93, HS89] </ref>. 3. Most reuse occurs within a nest rather than across nests [CMT94, TGJ93, WL91]. a. Targeting individual loop nests is sufficient. b. Is inter-nest reuse difficult to exploit? 4. Many memory references within numerical codes correspond to reg ular references [BC91]. a. <p> in the cache, we use Hill's miss classification which is orthogonal to the above: compulsory misses misses that occur on the first reference to a block; capacity misses additional misses resulting from the limited capacity of a cache; and conflict misses additional misses due to mapping constraints in set-associative caches <ref> [Hil87, HS89] </ref>. Like Hill, we measure conflict and capacity misses with respect to a fully-associative cache using an LRU replacement policy. We measure the locality distance in terms of the number of memory references (load/store references in the trace) between two references to the same word or cache block. <p> Future architectural and software improvements to cache performance may therefore need to selectively load the cache and/or use adjustable cache block sizes. 4.2.3 Capacity and Conflict Misses Previous research demonstrates Assertion 2: Capacity misses occur more frequently than conflict misses, and both are significant sources of misses for whole programs <ref> [HP95, HS89, SA93] </ref>. Conflict misses play the lesser role in these results, typically making up about 30-40% of misses. Figure 12 divides program misses into self and group, 1 capacity and conflict misses, again plotting the fraction of misses against their distance.
Reference: [Irl91] <author> G. Irlam. </author> <title> SPA package, </title> <year> 1991. </year>
Reference-contexts: Although we collected statistics for MDG, we exclude them from our statistics because less than 50% of references and misses are in nests. 3 2.4 Instrumentation and Analysis We modified the Spy tracing tool from the Spa package by G. Ir-lam <ref> [Irl91] </ref> to trace each benchmark on a Sparc-20 workstation. Spy uses object codes as inputs so no special compilation flag is required. Spy traces all calls to system libraries but doesn't handle a number of traps. Six of the eight benchmarks were run till completion.
Reference: [Jou90] <author> N. P. Jouppi. </author> <title> Improving direct-mapped cache performance by the addition of a samll fully-associative cache and prefetch buffers. </title> <booktitle> In Proceedings of the 17th International Symposium on Computer Architecture, </booktitle> <pages> pages 364-373, </pages> <address> Seattle, WA, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: These assertions, listed in Table 1, arise from extensive measurements of complete programs [Bel66, GHPS93, Hil88, HS89, HP95, PHH88, Smi82, SA93], slightly more narrow measurements that evaluate proposed hardware or software techniques <ref> [AP93, CB95, Dra95, Jou90, KL91, MLG92] </ref>, and software models [CMT94, GJG88, MLG92, WL91]. Our results dispute Assertions 1 and 2, and confirm Assertions 3 and 4 for our benchmark suite. <p> Within each of the sec 1 Table 1: Assertions about reuse characteristics and cache behavior of numerical programs Assertions Related Issues, Assertions, & Questions 1. Spatial reuse is the dominant form of reuse <ref> [CMT94, Jou90, KW73, PHH88, Smi82, Smi87] </ref>. a. Temporal reuse avoids fewer misses than spatial. b. Cache blocks effectively exploit spatial reuse [KW73, PHH88, Smi82, Smi87]. c. Most cache pollution is due to spatial-only blocks, i.e., blocks which are only reused spatially [Pou94]. 2. <p> Probably the most widespread assertion we address is Assertion 1: Spatial reuse is the dominant form of reuse <ref> [CMT94, Jou90, KW73, PHH88, Smi82, Smi87] </ref>. For example, all modern caches use block sizes greater than one. Spatial locality enables hardware and software prefetching to achieve most of its improvements [CB95, Dra95, Jou90, KL91, MLG92]. <p> Probably the most widespread assertion we address is Assertion 1: Spatial reuse is the dominant form of reuse [CMT94, Jou90, KW73, PHH88, Smi82, Smi87]. For example, all modern caches use block sizes greater than one. Spatial locality enables hardware and software prefetching to achieve most of its improvements <ref> [CB95, Dra95, Jou90, KL91, MLG92] </ref>. Software techniques have also attributed their improvements to improved spatial locality [CMT94]. 4.1 Intra-Nest Reuse spatial. <p> Larger data set sizes would probably result in increased capacity misses that may be eliminated by tiling. Even if tiling increases self-conflict misses, it is also clear from Group-conflicts are however much more difficult to analyze and reduce [TFJ94]. Hardware mechanisms like victim caches <ref> [Jou90] </ref> or higher set associativity may be more likely to eliminate these misses (see Section 5.1.1). 4.2.4 Miss Characteristics of Individual Nests We also measured how the individual nests contribute to the overall misses. <p> Tagged prefetching fails to improve performance when a stride is larger than a cache block. (Strides that occur at the end of a stream are usually larger than a cache block.) Since 16 to 32 references to adjacent words correspond to 2 to 4, 32-byte cache blocks, tagged prefetching <ref> [Jou90] </ref> may fail every 2 to 4 prefetch requests. This result suggests prefetching should handle stride changes [MLG92] as well as stream references [CB95]. To determine the influence of short length streams and the potential of data tagged prefetching, we implemented a form of virtual tagged prefetching.
Reference: [KL91] <author> A. C. Klaiber and H. M. Levy. </author> <title> An architecture for software-controlled data prefetching. </title> <booktitle> In Proceedings of the 18th InternationalSymposium on Computer Architecture, </booktitle> <pages> pages 43-53, </pages> <address> Toronto, Canada, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: Most of this work depends on loop nests to provide predictable and regular data accesses. Techniques to improve data cache performance typically target and model locality characteristics found in loop nests. For example, software and hardware prefetching exploit the spatial locality of regular accesses in loop nests <ref> [CB95, CKP91, Dra95, KL91, MLG92] </ref>. <p> These assertions, listed in Table 1, arise from extensive measurements of complete programs [Bel66, GHPS93, Hil88, HS89, HP95, PHH88, Smi82, SA93], slightly more narrow measurements that evaluate proposed hardware or software techniques <ref> [AP93, CB95, Dra95, Jou90, KL91, MLG92] </ref>, and software models [CMT94, GJG88, MLG92, WL91]. Our results dispute Assertions 1 and 2, and confirm Assertions 3 and 4 for our benchmark suite. <p> Probably the most widespread assertion we address is Assertion 1: Spatial reuse is the dominant form of reuse [CMT94, Jou90, KW73, PHH88, Smi82, Smi87]. For example, all modern caches use block sizes greater than one. Spatial locality enables hardware and software prefetching to achieve most of its improvements <ref> [CB95, Dra95, Jou90, KL91, MLG92] </ref>. Software techniques have also attributed their improvements to improved spatial locality [CMT94]. 4.1 Intra-Nest Reuse spatial.
Reference: [KW73] <author> K. R. Kaplan and R. O. Winder. </author> <title> Cache based computer systems. </title> <journal> IEEE Computer, </journal> <volume> 6(3) </volume> <pages> 30-36, </pages> <month> March </month> <year> 1973. </year>
Reference-contexts: Within each of the sec 1 Table 1: Assertions about reuse characteristics and cache behavior of numerical programs Assertions Related Issues, Assertions, & Questions 1. Spatial reuse is the dominant form of reuse <ref> [CMT94, Jou90, KW73, PHH88, Smi82, Smi87] </ref>. a. Temporal reuse avoids fewer misses than spatial. b. Cache blocks effectively exploit spatial reuse [KW73, PHH88, Smi82, Smi87]. c. Most cache pollution is due to spatial-only blocks, i.e., blocks which are only reused spatially [Pou94]. 2. <p> Spatial reuse is the dominant form of reuse [CMT94, Jou90, KW73, PHH88, Smi82, Smi87]. a. Temporal reuse avoids fewer misses than spatial. b. Cache blocks effectively exploit spatial reuse <ref> [KW73, PHH88, Smi82, Smi87] </ref>. c. Most cache pollution is due to spatial-only blocks, i.e., blocks which are only reused spatially [Pou94]. 2. Capacity misses occur more frequently than conflict misses, and both are significant sources of misses [HP95, HS89, SA93]. a. <p> Probably the most widespread assertion we address is Assertion 1: Spatial reuse is the dominant form of reuse <ref> [CMT94, Jou90, KW73, PHH88, Smi82, Smi87] </ref>. For example, all modern caches use block sizes greater than one. Spatial locality enables hardware and software prefetching to achieve most of its improvements [CB95, Dra95, Jou90, KL91, MLG92].
Reference: [LRW91] <author> M. Lam, E. Rothberg, and M. E. Wolf. </author> <title> The cache performance and optimizations of blocked algorithms. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Santa Clara, CA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Because processor speed is increasingly outpacing memory speed, an enormous amount of research focuses on improving the cache behavior of numerical programs (see for example, Smith's bibliographies on hardware aspects of cache memories [Smi86, Smi91] and compiler techniques that exploit cache memories <ref> [CM95, CMT94, LRW91, MLG92, WL91] </ref>). Most of this work depends on loop nests to provide predictable and regular data accesses. Techniques to improve data cache performance typically target and model locality characteristics found in loop nests. <p> In QCD2 and TRFD, several nests had large working set sizes, about 256 Kbytes, but these misses barely contribute to the total number of intra-nest misses. Several software techniques focus on selecting tile sizes that eliminate capacity misses and do not introduce self-interference misses <ref> [CM95, LRW91] </ref>. These tiling studies focus on kernels, and have yet to demonstrate effectiveness on complete applications. The lack of capacity misses in Figure 10 indicates that the data set sizes for these programs are too small to make tiling effective.
Reference: [MLG92] <author> T. Mowry, M. Lam, and A. Gupta. </author> <title> Design and evaluation of a compiler algorithm for prefetching. </title> <booktitle> In Proceedings of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 62-73, </pages> <address> Boston, MA, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Because processor speed is increasingly outpacing memory speed, an enormous amount of research focuses on improving the cache behavior of numerical programs (see for example, Smith's bibliographies on hardware aspects of cache memories [Smi86, Smi91] and compiler techniques that exploit cache memories <ref> [CM95, CMT94, LRW91, MLG92, WL91] </ref>). Most of this work depends on loop nests to provide predictable and regular data accesses. Techniques to improve data cache performance typically target and model locality characteristics found in loop nests. <p> Most of this work depends on loop nests to provide predictable and regular data accesses. Techniques to improve data cache performance typically target and model locality characteristics found in loop nests. For example, software and hardware prefetching exploit the spatial locality of regular accesses in loop nests <ref> [CB95, CKP91, Dra95, KL91, MLG92] </ref>. <p> These assertions, listed in Table 1, arise from extensive measurements of complete programs [Bel66, GHPS93, Hil88, HS89, HP95, PHH88, Smi82, SA93], slightly more narrow measurements that evaluate proposed hardware or software techniques <ref> [AP93, CB95, Dra95, Jou90, KL91, MLG92] </ref>, and software models [CMT94, GJG88, MLG92, WL91]. Our results dispute Assertions 1 and 2, and confirm Assertions 3 and 4 for our benchmark suite. <p> These assertions, listed in Table 1, arise from extensive measurements of complete programs [Bel66, GHPS93, Hil88, HS89, HP95, PHH88, Smi82, SA93], slightly more narrow measurements that evaluate proposed hardware or software techniques [AP93, CB95, Dra95, Jou90, KL91, MLG92], and software models <ref> [CMT94, GJG88, MLG92, WL91] </ref>. Our results dispute Assertions 1 and 2, and confirm Assertions 3 and 4 for our benchmark suite. <p> Probably the most widespread assertion we address is Assertion 1: Spatial reuse is the dominant form of reuse [CMT94, Jou90, KW73, PHH88, Smi82, Smi87]. For example, all modern caches use block sizes greater than one. Spatial locality enables hardware and software prefetching to achieve most of its improvements <ref> [CB95, Dra95, Jou90, KL91, MLG92] </ref>. Software techniques have also attributed their improvements to improved spatial locality [CMT94]. 4.1 Intra-Nest Reuse spatial. <p> This result suggests prefetching should handle stride changes <ref> [MLG92] </ref> as well as stream references [CB95]. To determine the influence of short length streams and the potential of data tagged prefetching, we implemented a form of virtual tagged prefetching.
Reference: [MW96] <author> S. A. McKee and W. A. Wulf. </author> <title> A memory controller for improved performance of streamed computations on symmetric multiprocessors. </title> <booktitle> In Proceedings of the 1996 International Conference on Parallel Processing, </booktitle> <address> Honolulu, HI, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: Even though many of these approaches yield significant improvements, there exists no broad quantitative study of loop nest locality, of which we are aware, driving this exploration. New memory architectures can exploit locality more selectively than previous caches <ref> [HP95, MW96] </ref>. For example, the HP-7200 [HP95] uses a form of cache bypass for a reference stream with only spatial locality. These architectures require detailed knowledge about the locality properties of loop nests and programs. Of course, much of the research on memory optimizations analyzes relevant locality characteristics. <p> This assertion arises from the assumption that references that only exhibit spatial locality like A (J,I) in Matrix-Vector Multiply are the culprits in pollution. The Assist-Cache of the HP-7200 [Pou94] and stream buffers <ref> [MW96] </ref> use cache bypass to avoid pollution from blocks with only spatial locality. In Figure 9, we measure polluting blocks within nests by evaluating the ratio of temporal to spatial reuses for each block upon its eviction from cache. This ratio defines the 7 classes indicated in Figure 9.
Reference: [PHH88] <author> S. Przybylski, M. Horowitz, and J. Hennessy. </author> <title> Performance tradeoffs in cache design. </title> <booktitle> In Proceedings of the 15th International Symposium on Computer Architecture, </booktitle> <pages> pages 290-298, </pages> <address> Honolulu, HI, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: To provide a framework for our study, we examined the literature on memory optimizations and extracted some of the most prevalent assertions. These assertions, listed in Table 1, arise from extensive measurements of complete programs <ref> [Bel66, GHPS93, Hil88, HS89, HP95, PHH88, Smi82, SA93] </ref>, slightly more narrow measurements that evaluate proposed hardware or software techniques [AP93, CB95, Dra95, Jou90, KL91, MLG92], and software models [CMT94, GJG88, MLG92, WL91]. Our results dispute Assertions 1 and 2, and confirm Assertions 3 and 4 for our benchmark suite. <p> Within each of the sec 1 Table 1: Assertions about reuse characteristics and cache behavior of numerical programs Assertions Related Issues, Assertions, & Questions 1. Spatial reuse is the dominant form of reuse <ref> [CMT94, Jou90, KW73, PHH88, Smi82, Smi87] </ref>. a. Temporal reuse avoids fewer misses than spatial. b. Cache blocks effectively exploit spatial reuse [KW73, PHH88, Smi82, Smi87]. c. Most cache pollution is due to spatial-only blocks, i.e., blocks which are only reused spatially [Pou94]. 2. <p> Spatial reuse is the dominant form of reuse [CMT94, Jou90, KW73, PHH88, Smi82, Smi87]. a. Temporal reuse avoids fewer misses than spatial. b. Cache blocks effectively exploit spatial reuse <ref> [KW73, PHH88, Smi82, Smi87] </ref>. c. Most cache pollution is due to spatial-only blocks, i.e., blocks which are only reused spatially [Pou94]. 2. Capacity misses occur more frequently than conflict misses, and both are significant sources of misses [HP95, HS89, SA93]. a. <p> Probably the most widespread assertion we address is Assertion 1: Spatial reuse is the dominant form of reuse <ref> [CMT94, Jou90, KW73, PHH88, Smi82, Smi87] </ref>. For example, all modern caches use block sizes greater than one. Spatial locality enables hardware and software prefetching to achieve most of its improvements [CB95, Dra95, Jou90, KL91, MLG92].
Reference: [Pou94] <author> D. Pountain. </author> <title> A different kind of RISC. </title> <journal> BYTE, </journal> <month> August </month> <year> 1994. </year>
Reference-contexts: Spatial reuse is the dominant form of reuse [CMT94, Jou90, KW73, PHH88, Smi82, Smi87]. a. Temporal reuse avoids fewer misses than spatial. b. Cache blocks effectively exploit spatial reuse [KW73, PHH88, Smi82, Smi87]. c. Most cache pollution is due to spatial-only blocks, i.e., blocks which are only reused spatially <ref> [Pou94] </ref>. 2. Capacity misses occur more frequently than conflict misses, and both are significant sources of misses [HP95, HS89, SA93]. a. Do ping-pong conflicts occur frequently? b. 2-way set-associative caches remove the majority of conflict misses [AP93, HS89]. 3. <p> This assertion arises from the assumption that references that only exhibit spatial locality like A (J,I) in Matrix-Vector Multiply are the culprits in pollution. The Assist-Cache of the HP-7200 <ref> [Pou94] </ref> and stream buffers [MW96] use cache bypass to avoid pollution from blocks with only spatial locality. In Figure 9, we measure polluting blocks within nests by evaluating the ratio of temporal to spatial reuses for each block upon its eviction from cache.
Reference: [Res95] <author> MicroDesign Resources. </author> <title> Intel boosts Pentium Pro to 200 Mhz. </title> <type> Microprocessor Report, 9(17), </type> <month> November </month> <year> 1995. </year>
Reference-contexts: All of our figures use this basic configuration. We also discuss a few results for a 2-way set-associative version of the same cache (the Intel P6 <ref> [Res95] </ref> first-level data cache implements these parameters). Our nest selection, on average, considers more nests than Carr et al. [CMT94] consider for optimization. The numbers are not directly comparable because Carr et al. do not include single loops and consider more complex nesting structures than we do.
Reference: [SA93] <author> R. A. Sugumar and S. G. Abraham. </author> <title> Efficient simulation of caches under optimal replacement with applications to miss characterization. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on Measurement & Modeling Computer Systems, </booktitle> <pages> pages 24-35, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Of course, much of the research on memory optimizations analyzes relevant locality characteristics. These studies are typically conducted across the entire application, while many optimizations just target loop nests. For instance, several studies find numerous capacity misses in applications <ref> [HP95, HS89, SA93] </ref>. If these misses actually correspond to locality across distinct nests, loop nest optimizations are unlikely to eliminate them. In this paper, we investigate the locality behavior of loop nests in order to suggest targets for future software and hardware research. <p> To provide a framework for our study, we examined the literature on memory optimizations and extracted some of the most prevalent assertions. These assertions, listed in Table 1, arise from extensive measurements of complete programs <ref> [Bel66, GHPS93, Hil88, HS89, HP95, PHH88, Smi82, SA93] </ref>, slightly more narrow measurements that evaluate proposed hardware or software techniques [AP93, CB95, Dra95, Jou90, KL91, MLG92], and software models [CMT94, GJG88, MLG92, WL91]. Our results dispute Assertions 1 and 2, and confirm Assertions 3 and 4 for our benchmark suite. <p> Cache blocks effectively exploit spatial reuse [KW73, PHH88, Smi82, Smi87]. c. Most cache pollution is due to spatial-only blocks, i.e., blocks which are only reused spatially [Pou94]. 2. Capacity misses occur more frequently than conflict misses, and both are significant sources of misses <ref> [HP95, HS89, SA93] </ref>. a. Do ping-pong conflicts occur frequently? b. 2-way set-associative caches remove the majority of conflict misses [AP93, HS89]. 3. Most reuse occurs within a nest rather than across nests [CMT94, TGJ93, WL91]. a. Targeting individual loop nests is sufficient. b. Is inter-nest reuse difficult to exploit? 4. <p> Future architectural and software improvements to cache performance may therefore need to selectively load the cache and/or use adjustable cache block sizes. 4.2.3 Capacity and Conflict Misses Previous research demonstrates Assertion 2: Capacity misses occur more frequently than conflict misses, and both are significant sources of misses for whole programs <ref> [HP95, HS89, SA93] </ref>. Conflict misses play the lesser role in these results, typically making up about 30-40% of misses. Figure 12 divides program misses into self and group, 1 capacity and conflict misses, again plotting the fraction of misses against their distance. <p> On average, conflict misses reduce to 68% of intra-nest misses with 2-way set-associativity, but are still a significantly larger fraction than the average of 30 to 40% conflict misses on whole programs for direct-mapped caches in Figure 12 and other studies <ref> [SA93, HP95] </ref>. Considering that these programs have relatively high hit rates (see Table 2), this result should not have been surprising. The working set of most executions of a loop nest should fit and already be in the cache, implying inter-nest misses should be conflict misses.
Reference: [Smi82] <author> A. J. Smith. </author> <title> Cache memories. </title> <journal> Computing Surveys, </journal> <volume> 14(3) </volume> <pages> 473-530, </pages> <month> September </month> <year> 1982. </year>
Reference-contexts: To provide a framework for our study, we examined the literature on memory optimizations and extracted some of the most prevalent assertions. These assertions, listed in Table 1, arise from extensive measurements of complete programs <ref> [Bel66, GHPS93, Hil88, HS89, HP95, PHH88, Smi82, SA93] </ref>, slightly more narrow measurements that evaluate proposed hardware or software techniques [AP93, CB95, Dra95, Jou90, KL91, MLG92], and software models [CMT94, GJG88, MLG92, WL91]. Our results dispute Assertions 1 and 2, and confirm Assertions 3 and 4 for our benchmark suite. <p> Within each of the sec 1 Table 1: Assertions about reuse characteristics and cache behavior of numerical programs Assertions Related Issues, Assertions, & Questions 1. Spatial reuse is the dominant form of reuse <ref> [CMT94, Jou90, KW73, PHH88, Smi82, Smi87] </ref>. a. Temporal reuse avoids fewer misses than spatial. b. Cache blocks effectively exploit spatial reuse [KW73, PHH88, Smi82, Smi87]. c. Most cache pollution is due to spatial-only blocks, i.e., blocks which are only reused spatially [Pou94]. 2. <p> Spatial reuse is the dominant form of reuse [CMT94, Jou90, KW73, PHH88, Smi82, Smi87]. a. Temporal reuse avoids fewer misses than spatial. b. Cache blocks effectively exploit spatial reuse <ref> [KW73, PHH88, Smi82, Smi87] </ref>. c. Most cache pollution is due to spatial-only blocks, i.e., blocks which are only reused spatially [Pou94]. 2. Capacity misses occur more frequently than conflict misses, and both are significant sources of misses [HP95, HS89, SA93]. a. <p> Probably the most widespread assertion we address is Assertion 1: Spatial reuse is the dominant form of reuse <ref> [CMT94, Jou90, KW73, PHH88, Smi82, Smi87] </ref>. For example, all modern caches use block sizes greater than one. Spatial locality enables hardware and software prefetching to achieve most of its improvements [CB95, Dra95, Jou90, KL91, MLG92].
Reference: [Smi86] <author> A. J. Smith. </author> <title> Bibliography and readings on cpu cache memories and related topics. </title> <journal> Computer Architecture News, </journal> <volume> 14(1) </volume> <pages> 22-42, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: 1 Introduction Because processor speed is increasingly outpacing memory speed, an enormous amount of research focuses on improving the cache behavior of numerical programs (see for example, Smith's bibliographies on hardware aspects of cache memories <ref> [Smi86, Smi91] </ref> and compiler techniques that exploit cache memories [CM95, CMT94, LRW91, MLG92, WL91]). Most of this work depends on loop nests to provide predictable and regular data accesses. Techniques to improve data cache performance typically target and model locality characteristics found in loop nests.
Reference: [Smi87] <author> A. J. Smith. </author> <title> Line (block) size choice for cpu caches. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(9):1063-1075, </volume> <month> September </month> <year> 1987. </year>
Reference-contexts: Within each of the sec 1 Table 1: Assertions about reuse characteristics and cache behavior of numerical programs Assertions Related Issues, Assertions, & Questions 1. Spatial reuse is the dominant form of reuse <ref> [CMT94, Jou90, KW73, PHH88, Smi82, Smi87] </ref>. a. Temporal reuse avoids fewer misses than spatial. b. Cache blocks effectively exploit spatial reuse [KW73, PHH88, Smi82, Smi87]. c. Most cache pollution is due to spatial-only blocks, i.e., blocks which are only reused spatially [Pou94]. 2. <p> Spatial reuse is the dominant form of reuse [CMT94, Jou90, KW73, PHH88, Smi82, Smi87]. a. Temporal reuse avoids fewer misses than spatial. b. Cache blocks effectively exploit spatial reuse <ref> [KW73, PHH88, Smi82, Smi87] </ref>. c. Most cache pollution is due to spatial-only blocks, i.e., blocks which are only reused spatially [Pou94]. 2. Capacity misses occur more frequently than conflict misses, and both are significant sources of misses [HP95, HS89, SA93]. a. <p> Probably the most widespread assertion we address is Assertion 1: Spatial reuse is the dominant form of reuse <ref> [CMT94, Jou90, KW73, PHH88, Smi82, Smi87] </ref>. For example, all modern caches use block sizes greater than one. Spatial locality enables hardware and software prefetching to achieve most of its improvements [CB95, Dra95, Jou90, KL91, MLG92].
Reference: [Smi91] <author> A. J. Smith. </author> <title> Second bibliography on cache memories. </title> <journal> Computer Architecture News, </journal> <volume> 19(4) </volume> <pages> 154-182, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Because processor speed is increasingly outpacing memory speed, an enormous amount of research focuses on improving the cache behavior of numerical programs (see for example, Smith's bibliographies on hardware aspects of cache memories <ref> [Smi86, Smi91] </ref> and compiler techniques that exploit cache memories [CM95, CMT94, LRW91, MLG92, WL91]). Most of this work depends on loop nests to provide predictable and regular data accesses. Techniques to improve data cache performance typically target and model locality characteristics found in loop nests.
Reference: [TFJ94] <author> O. Temam, C. Fricker, and W. Jalby. </author> <title> Cache interference phenomena. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on Measurement & Modeling Computer Systems, </booktitle> <year> 1994. </year>
Reference-contexts: Larger data set sizes would probably result in increased capacity misses that may be eliminated by tiling. Even if tiling increases self-conflict misses, it is also clear from Group-conflicts are however much more difficult to analyze and reduce <ref> [TFJ94] </ref>. Hardware mechanisms like victim caches [Jou90] or higher set associativity may be more likely to eliminate these misses (see Section 5.1.1). 4.2.4 Miss Characteristics of Individual Nests We also measured how the individual nests contribute to the overall misses.
Reference: [TFMP95] <author> G. Tyson, M. Farrens, J. Matthews, and A. Pleszkun. </author> <title> A new approach to cache management. </title> <booktitle> In Proceedings of the 28th International Symposium on Microarchitecture, </booktitle> <address> Ann Arbor, MI, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: These statistics contradict Assertion 1.b. An important corollary to this observation is that cache blocks are not efficiently exploited and many loaded words are not used, wasting cache bandwidth. Other works support these results <ref> [BKG96, TFMP95, WHK91] </ref>.
Reference: [TGJ93] <author> O. Temam, E. Granston, and W. Jalby. </author> <title> To copy or not to copy: A compile-time technique for assessing when data copying should be used to eliminate cache conflicts. </title> <booktitle> In Proceedings of Supercomputing '93, </booktitle> <address> Portland, OR, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: Capacity misses occur more frequently than conflict misses, and both are significant sources of misses [HP95, HS89, SA93]. a. Do ping-pong conflicts occur frequently? b. 2-way set-associative caches remove the majority of conflict misses [AP93, HS89]. 3. Most reuse occurs within a nest rather than across nests <ref> [CMT94, TGJ93, WL91] </ref>. a. Targeting individual loop nests is sufficient. b. Is inter-nest reuse difficult to exploit? 4. Many memory references within numerical codes correspond to reg ular references [BC91]. a. What is the fraction of misses due to scalar references? b. <p> These results also hold for 2-way set-associativity and are in contrast to Assertion 1 and 1.a since spatial reuse is never the single overwhelming factor. Compiler algorithms to improve locality target group and self, spatial and temporal locality <ref> [CMT94, TGJ93, WL91] </ref>. All of which have a role in these results. Two classic examples in Figure 1 that demonstrate a mixture of self-temporal, group-temporal, self-spatial, and group-spatial reuse are Matrix-Vector Multiply and Matrix-Matrix Multiply.
Reference: [Uni89] <author> J. Uniejewski. </author> <title> SPEC Benchmark Suite: Designed for today's advanced systems. </title> <journal> SPEC Newsletter Volume 1, </journal> <note> Issue 1, SPEC, Fall 1989. </note>
Reference-contexts: Although the Perfect Benchmarks suffer from the same flaw as SPEC92 <ref> [Uni89] </ref>, namely small data set sizes, they are real applications, and thus are more likely to exhibit classic programming patterns.
Reference: [WHK91] <author> D. A. Wood, M. D. Hill, and R. E. Kessler. </author> <title> A model for estimating trace-sample miss ratios. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on Measurement & Modeling Computer Systems, </booktitle> <pages> pages 79-89, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: These statistics contradict Assertion 1.b. An important corollary to this observation is that cache blocks are not efficiently exploited and many loaded words are not used, wasting cache bandwidth. Other works support these results <ref> [BKG96, TFMP95, WHK91] </ref>. <p> These blocks often have long agonies, i.e., they stay in the cache a long time after they die, and on average 60% of dead blocks are replaced by blocks from a different nest. Long cache block agonies have also been observed by Wood et al. <ref> [WHK91] </ref> and Burger et al. [BGK95]. 4.2.5 Summary of Results The major findings of this section refute Assertions 1 and 2. Instead of a preponderance of spatial reuse, we find a more balanced role between spatial and temporal reuse (Assertion 1.a), particularly group-temporal reuse.
Reference: [WL91] <author> M. E. Wolf and M. Lam. </author> <title> A data locality optimizing algorithm. </title> <booktitle> In Proceedings of the SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <address> Toronto, Canada, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Because processor speed is increasingly outpacing memory speed, an enormous amount of research focuses on improving the cache behavior of numerical programs (see for example, Smith's bibliographies on hardware aspects of cache memories [Smi86, Smi91] and compiler techniques that exploit cache memories <ref> [CM95, CMT94, LRW91, MLG92, WL91] </ref>). Most of this work depends on loop nests to provide predictable and regular data accesses. Techniques to improve data cache performance typically target and model locality characteristics found in loop nests. <p> Techniques to improve data cache performance typically target and model locality characteristics found in loop nests. For example, software and hardware prefetching exploit the spatial locality of regular accesses in loop nests [CB95, CKP91, Dra95, KL91, MLG92]. Wolf and Lam <ref> [WL91] </ref> model data locality by distinguishing four categories of locality which they use to drive loop optimizations: spatial - reuse of adjacent locations in a cache block; temporal reuse of the same location; self reuse from the same data reference; and group reuse from distinct references. <p> These assertions, listed in Table 1, arise from extensive measurements of complete programs [Bel66, GHPS93, Hil88, HS89, HP95, PHH88, Smi82, SA93], slightly more narrow measurements that evaluate proposed hardware or software techniques [AP93, CB95, Dra95, Jou90, KL91, MLG92], and software models <ref> [CMT94, GJG88, MLG92, WL91] </ref>. Our results dispute Assertions 1 and 2, and confirm Assertions 3 and 4 for our benchmark suite. <p> Capacity misses occur more frequently than conflict misses, and both are significant sources of misses [HP95, HS89, SA93]. a. Do ping-pong conflicts occur frequently? b. 2-way set-associative caches remove the majority of conflict misses [AP93, HS89]. 3. Most reuse occurs within a nest rather than across nests <ref> [CMT94, TGJ93, WL91] </ref>. a. Targeting individual loop nests is sufficient. b. Is inter-nest reuse difficult to exploit? 4. Many memory references within numerical codes correspond to reg ular references [BC91]. a. What is the fraction of misses due to scalar references? b. <p> These results also hold for 2-way set-associativity and are in contrast to Assertion 1 and 1.a since spatial reuse is never the single overwhelming factor. Compiler algorithms to improve locality target group and self, spatial and temporal locality <ref> [CMT94, TGJ93, WL91] </ref>. All of which have a role in these results. Two classic examples in Figure 1 that demonstrate a mixture of self-temporal, group-temporal, self-spatial, and group-spatial reuse are Matrix-Vector Multiply and Matrix-Matrix Multiply. <p> All of which have a role in these results. Two classic examples in Figure 1 that demonstrate a mixture of self-temporal, group-temporal, self-spatial, and group-spatial reuse are Matrix-Vector Multiply and Matrix-Matrix Multiply. Both are written in the best order for exploiting short-term data locality, assuming Fortran's column-major order <ref> [CMT94, WL91] </ref>. In Matrix-Vector Multiply on the inner J loop, the cache should exploit group-temporal locality for C, self-spatial for A, and self-spatial for D. For the entire nest, C is group-spatial and temporal, A is self-spatial, and D is self-spatial and temporal.
Reference: [Wol92] <author> M. E. Wolf. </author> <title> Improving Locality and Parallelism in Nested Loops. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Stanford University, </institution> <month> August </month> <year> 1992. </year> <month> 11 </month>
Reference-contexts: The lack of capacity misses in Figure 10 indicates that the data set sizes for these programs are too small to make tiling effective. Wolf supports this conclusion as he was unable to achieve improvements from tiling SPEC92 <ref> [Wol92] </ref>. Larger data set sizes would probably result in increased capacity misses that may be eliminated by tiling. Even if tiling increases self-conflict misses, it is also clear from Group-conflicts are however much more difficult to analyze and reduce [TFJ94].
References-found: 46

