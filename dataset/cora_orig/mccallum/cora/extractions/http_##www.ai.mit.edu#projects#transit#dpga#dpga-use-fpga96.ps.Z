URL: http://www.ai.mit.edu/projects/transit/dpga/dpga-use-fpga96.ps.Z
Refering-URL: http://www.ai.mit.edu/projects/transit/dpga_prototype_documents.html
Root-URL: 
Email: andre@mit.edu  
Phone: Phone: (617) 253-5868 FAX: (617) 253-5060  
Title: DPGA Utilization and Application  
Author: Andr e DeHon 
Address: NE43-791, 545 Technology Sq., Cambridge, MA 02139  
Affiliation: MIT Artificial Intelligence Laboratory  
Date: February 11-13, 1996, Monterey, CA  
Note: Copyright (c) 1996 by the Association for Computing Machinery, Inc. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that new copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request Permissions from Publications Dept, ACM Inc., Fax +1 (212) 869-0481, or &lt;permissions@acm.org&gt;. FPGA '96 ACM/SIGDA Fourth International Symposium on FPGAs  
Abstract: Dynamically Programmable Gate Arrays (DPGAs) are programmable arrays which allow the strategic reuse of limited resources. In so doing, DPGAs promise greater capacity, and in some cases higher performance, than conventional programmable device architectures where all array resources are dedicated to a single function for an entire operational epoch. This paper examines several usage patterns for DPGAs including temporal pipelining, utility functions, multiple function accommodation, and state-dependent logic. In the process, it offers insight into the application and technology space where DPGA-style reuse techniques are most beneficial. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Peter Athanas and Harvey F. Silverman. </author> <title> Processor Reconfiguration Through Instruction-Set Metamorphosis. </title> <journal> IEEE Computer, </journal> <volume> 26(3) </volume> <pages> 11-18, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: A DPGA can thus act as a multifunc-tion peripheral, performing distinct tasks without idling for long reconfiguration intervals. In a system such as the one shown in a reconfigurable accelerator for a processor (e.g. <ref> [1] </ref> [3] [8]) or to implement a dynamic processor (e.g. [12]), the DPGA can support multiple loaded acceleration functions simultaneously. Within a CAD application, such as espresso [9], one needs to perform several distinct operations at different times, each of which could be accelerated with reconfigurable logic. <p> Within a CAD application, such as espresso [9], one needs to perform several distinct operations at different times, each of which could be accelerated with reconfigurable logic. We could load the DPGA with assist functions, such as an ASCII decoder (e.g. [8]), bitvector manipulator, first one locator (e.g. <ref> [1] </ref>), or hamming distance calculator (e.g. [1]). Since these tasks are needed at distinct times, they can easily be stacked in separate contexts and selected as needed. <p> We could load the DPGA with assist functions, such as an ASCII decoder (e.g. [8]), bitvector manipulator, first one locator (e.g. <ref> [1] </ref>), or hamming distance calculator (e.g. [1]). Since these tasks are needed at distinct times, they can easily be stacked in separate contexts and selected as needed.
Reference: [2] <author> Narasimha B. Bhat. </author> <title> Novel Techniques for High Performance Field Programmable Logic Devices. </title> <institution> UCB/ERL M93/80, University of California, Berkeley, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: Operations with fixed bandwidth requirements can increasingly be compressed into more temporal and less spatial evaluation. 7.2 Levelized Logic Levelized logic is a CAD technique for automatic temporal pipelin-ing of existing circuit netlists. Bhat refers to this as temporal partitioning in the context of the Dharma architecture <ref> [2] </ref>. The basic idea is to assign an evaluation context to each gate so the gate's predecessors are evaluated in a context prior to the gate's context. With latency constraints, we may further require that the levelized network not take any more t min clk steps than necessary.

Reference: [4] <author> Srinivas Devadas, Hi-Keung Ma, , A.R. Newton, and Alberto Sangiovanni-Vincentelli. MUSTANG: </author> <title> State Assignment of Finite State Machines Targeting Multilevel Logic Implementations. </title> <journal> IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, </journal> <volume> 7(12) </volume> <pages> 1290-1300, </pages> <month> December </month> <year> 1988. </year>
Reference-contexts: The next state computation simply selects the appropriate next context in which to operate. Table 2 shows the reduction in logic depth and increase in utilization efficiency which results from multiple context implementation. FSMs were mapped using mustang <ref> [4] </ref>. Logic minimization and LUT mapping were done with espresso, sis, and Chortle. All single context FSM implementations use one-hot state encodings since those uniformly offered the lowest latency and had the lowest capacity requirements.
Reference: [5] <author> Robert Francis. </author> <title> Technology Mapping for Lookup-Table Based Field-Programmable Gate Arrays. </title> <type> PhD thesis, </type> <institution> University of Toronto, </institution> <year> 1992. </year>
Reference-contexts: Table 1 summarizes full levelization results for several MCNC benchmarks. sis [10] was used for technology independent optimization. Chortle <ref> [5] </ref> was used to map the circuits to 4-LUTs. For the purpose of comparison, circuits were mapped to minimize delay since this generally gave the highest, single context utilization efficiency. No modifications to the mapping and netlist generation were made for levelized computation.
Reference: [6] <author> David Hawley. </author> <title> Advanced PLD Architectures. </title> <editor> In Will Moore and Wayne Luk, editors, </editor> <booktitle> FPGAs, </booktitle> <pages> pages 11-23. </pages> <publisher> Abingdon EE&CS Books, </publisher> <address> 15 Harcourt Way, Abingdon, OX14 1NV, UK, </address> <year> 1991. </year>
Reference-contexts: When the state transitions to a state whose logic resides in another context, we can switch contexts making a different portion of the FSM active. National Semiconductor, for example, exploits this feature in their multicon-text programmable logic array (PLA), MAPL <ref> [6] </ref>. In the most extreme case, each FSM state is assigned its own context. The next state computation simply selects the appropriate next context in which to operate. Table 2 shows the reduction in logic depth and increase in utilization efficiency which results from multiple context implementation.
Reference: [7] <author> Chris Jones, John Oswald, Brian Schoner, and John Vil-lasenor. </author> <title> Issues in Wireless Video Coding using Run-time-reconfigurable FPGAs. </title> <booktitle> In Proceedings of the IEEE Workshop on FPGAs for Custom Computing Machines, </booktitle> <month> April </month> <year> 1995. </year>
Reference: [8] <author> Rahul Razdan. PRISC: </author> <title> Programmable Reduced Instruction Set Computers. </title> <type> PhD thesis, </type> <institution> Harvard Univeristy, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: A DPGA can thus act as a multifunc-tion peripheral, performing distinct tasks without idling for long reconfiguration intervals. In a system such as the one shown in a reconfigurable accelerator for a processor (e.g. [1] [3] <ref> [8] </ref>) or to implement a dynamic processor (e.g. [12]), the DPGA can support multiple loaded acceleration functions simultaneously. Within a CAD application, such as espresso [9], one needs to perform several distinct operations at different times, each of which could be accelerated with reconfigurable logic. <p> Within a CAD application, such as espresso [9], one needs to perform several distinct operations at different times, each of which could be accelerated with reconfigurable logic. We could load the DPGA with assist functions, such as an ASCII decoder (e.g. <ref> [8] </ref>), bitvector manipulator, first one locator (e.g. [1]), or hamming distance calculator (e.g. [1]). Since these tasks are needed at distinct times, they can easily be stacked in separate contexts and selected as needed.
Reference: [9] <author> R. Rudell and A. Sangiovanni-Vincentelli. </author> <title> Multiple-Valued Minimization for PLA Optimization. </title> <journal> IEEE Transactions on Computer-Aided Design of Integrated Circuits, </journal> <volume> 6(5) </volume> <pages> 727-751, </pages> <month> September </month> <year> 1987. </year>
Reference-contexts: In a system such as the one shown in a reconfigurable accelerator for a processor (e.g. [1] [3] [8]) or to implement a dynamic processor (e.g. [12]), the DPGA can support multiple loaded acceleration functions simultaneously. Within a CAD application, such as espresso <ref> [9] </ref>, one needs to perform several distinct operations at different times, each of which could be accelerated with reconfigurable logic. We could load the DPGA with assist functions, such as an ASCII decoder (e.g. [8]), bitvector manipulator, first one locator (e.g. [1]), or hamming distance calculator (e.g. [1]).
Reference: [10] <author> Ellen M. Sentovich, Kanwar Jit Singh, Luciano Lavagno, Cho Moon, Rajeev Murgai, Alexander Saldanha, Hamid Savoj, Paul R. Stephan, Robert K. Brayton, and Alberto Sangiovanni-Vincentelli. </author> <title> SIS: A System for Sequential Circuit Synthesis. </title> <institution> UCB/ERL M92/41, University of California, Berkeley, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: In general, this slack should be used to equalize context size, mini mizing capacity usage. * Up to a point, more contexts allow increased utilization. * Achieving the highest utilization often requires increasing the evaluation delay. Table 1 summarizes full levelization results for several MCNC benchmarks. sis <ref> [10] </ref> was used for technology independent optimization. Chortle [5] was used to map the circuits to 4-LUTs. For the purpose of comparison, circuits were mapped to minimize delay since this generally gave the highest, single context utilization efficiency.
Reference: [11] <author> Edward Tau, Ian Eslick, Derrick Chen, Jeremy Brown, and Andre DeHon. </author> <title> A First Generation DPGA Implementation. </title> <booktitle> In Proceedings of the Third Canadian Workshop on Field-Programmable Devices, </booktitle> <pages> pages 138-143, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: of the device, we can approximate A mem as proportional to A active : A mem = C mem fi A active (8) This gives us: A active + (c 1) fi C mem fi A active = 1 (9) A active = 1 (10) Our first generation DPGA prototype <ref> [11] </ref> was implemented in a 3-layer metal, 1.0m CMOS process. The prototype used 4-LUTs for the basic logic blocks and supported 4 on-chip context memories. Each context fully specified both the interconnect and LUT functions. Roughly 40% of the die area consumed on the prototype went into memory.
Reference: [12] <author> Michael J. Wirthlin and Brad L. Hutchings. </author> <title> A Dynamic Instruction Set Computer. </title> <booktitle> In Proceedings of the IEEE Workshop on FPGAs for Custom Computing Machines, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: A DPGA can thus act as a multifunc-tion peripheral, performing distinct tasks without idling for long reconfiguration intervals. In a system such as the one shown in a reconfigurable accelerator for a processor (e.g. [1] [3] [8]) or to implement a dynamic processor (e.g. <ref> [12] </ref>), the DPGA can support multiple loaded acceleration functions simultaneously. Within a CAD application, such as espresso [9], one needs to perform several distinct operations at different times, each of which could be accelerated with reconfigurable logic.
Reference: [13] <author> Xilinx, Inc., </author> <title> 2100 Logic Drive, </title> <address> San Jose, CA 95124. </address> <booktitle> The Programmable Logic Data Book, </booktitle> <year> 1989, 1994. </year>
Reference-contexts: We will assume t min cycle captures both the bandwidth and the propagation delay limitations. The flip-flop toggle rate which was often quoted by vendors as a measure of device performance <ref> [13] </ref>, provides a rough approximation of t min cycle for commercial devices (i.e. t min cycle 1 ). Throughout, we assume t ff setup ; t clk!q &lt;< t min cycle to allow simple time discretization and comparison.
References-found: 12

