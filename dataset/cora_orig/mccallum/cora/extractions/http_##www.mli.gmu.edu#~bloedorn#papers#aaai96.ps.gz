URL: http://www.mli.gmu.edu/~bloedorn/papers/aaai96.ps.gz
Refering-URL: http://www.mli.gmu.edu/~bloedorn/pubs.html
Root-URL: 
Email: -bloedorn, imani, macmilla-@mitre.org  
Title: Machine Learning of User Profiles: Representational Issues  
Author: Eric Bloedorn, Inderjeet Mani, and T. Richard MacMillan 
Keyword: Machine Learning and Inference Laboratory  
Address: Z40,11820 Dolley Madison Boulevard, McLean, VA 22102  Fairfax, VA 22030  
Affiliation: Artificial Intelligence Technical Center, The MITRE Corporation  George Mason University,  
Abstract: As more information becomes available electronically, tools for finding information of interest to users becomes increasingly important. The goal of the research described here is to build a system for generating comprehensible user profiles that accurately capture user interest with minimum user interaction. The research described here focuses on the importance of a suitable generalization hierarchy and representation for learning profiles which are predictively accurate and comprehensible. In our experiments we evaluated both traditional features based on weighted term vectors as well as subject features corresponding to categories which could be drawn from a thesaurus. Our experiments, conducted in the context of a content-based profiling system for online newspapers on the World Wide Web (the IDD News Browser), demonstrate the importance of a generalization hierarchy and the promise of combining natural language processing techniques with machine learning (ML) to address an information retrieval (IR) problem. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Armstrong, R.; Freitag, T.; Joachims, T. and Mitchell, T. </author> <year> 1995. </year> <title> WebWatcher: A learning apprentice for the World Wide Web, </title> <booktitle> In Proceedings 1995 AAAI Spring Symposium on Information Gathering from Heterogeneous, Distributed Environments, </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: Work on the application of machine learning techniques for constructing personalized information filters has gained momentum in recent years. Filters have been constructed for many applications including web pages and USENET news, such as NewT (Maes 1994), Webhound (Lashkari, Metral, & Maes 1994), WebWatcher <ref> (Armstrong et al. 1995) </ref>, WebLearner (Pazzani et al. 1995) and NewsWeeder (Lang 1995). However, in the above approaches, the agent is unable to learn generalizations about the users interests.
Reference: <author> Belew, R. </author> <year> 1989. </year> <title> Adaptive Information Retrieval: Using a Connectionist Representation to Retrieve and Learn about Documents, </title> <booktitle> ACM SIGIR, </booktitle> <pages> 1120. </pages>
Reference-contexts: We will now introduce these briefly, to better motivate and distinguish our work. Relevance feedback approaches are a form of supervised learning where a user indicates which retrieved documents are relevant or irrelevant. These approaches, e.g., (Rocchio 1971), (Robertson & Sparck-Jones 1976), <ref> (Belew 1989) </ref>, (Salton & Buckley 1990), (Harman 1992), (Haines & Croft 1993), (Buckley, Salton, & Allan 1994), have investigated techniques for automatic query reformulation based on user feedback, such as term reweighting and query expansion.
Reference: <author> Belkin N. and Croft, B. </author> <year> 1992. </year> <title> Information Filtering and Information Retrieval: Two Sides of the Same Coin?, </title> <journal> CACM, December, </journal> <volume> 35, (12): </volume> <pages> 29-38. </pages>
Reference-contexts: Introduction As more information becomes available on the Internet, the need for effective personalized information filters becomes critical. In particular, there is a need for tools to capture profiles of users information needs, and to find articles relevant to these needs, as these needs change over time. Information filtering, as <ref> (Belkin & Croft 1992) </ref>, (Foltz & Dumais 1992) point out, is an information access activity similar to information retrieval, but where the profiles represent evolving interests of users over a long-term period, and where the filters are applied to dynamic streams of incoming data.
Reference: <author> Bloedorn, E.; Michalski, R. and Wnek, J. </author> <year> 1993. </year> <title> Multistrategy Constructive Induction: </title> <booktitle> AQ17-MCI, In Proceedings of the Second International Workshop on Multistrategy Learning, </booktitle> <pages> 188-203. </pages>
Reference-contexts: We also hope to investigate the use of constructive induction to automate the search for an improved representation <ref> (Bloedorn & Michalski 1993) </ref>.
Reference: <author> Broglio, J. and Croft, B. </author> <year> 1993. </year> <title> Query Processing for Retrieval from Large Text Bases. </title> <booktitle> In Proceedings of Human Language Technology Workshop. </booktitle>
Reference-contexts: To remedy this, we extended the set of terminal categories under one of the categories, medicine, by hand to include another 16 lowest level categories. Based on recent findings by <ref> (Broglio & Croft 1993) </ref>, on improved retrieval performance on TIPSTER queries, and to further strengthen profile intelligibility, we included features in our document representation involving terms relating to People, Organizations, and Locations (POLs) (along with their respective attributes).
Reference: <author> Buckley, C.; Salton, G. and Allan, J. </author> <year> 1994. </year> <title> The Effect of Adding Relevance Information in a Relevance Feedback Environment. </title> <booktitle> ACM SIGIR. </booktitle>
Reference-contexts: Relevance feedback approaches are a form of supervised learning where a user indicates which retrieved documents are relevant or irrelevant. These approaches, e.g., (Rocchio 1971), (Robertson & Sparck-Jones 1976), (Belew 1989), (Salton & Buckley 1990), (Harman 1992), (Haines & Croft 1993), <ref> (Buckley, Salton, & Allan 1994) </ref>, have investigated techniques for automatic query reformulation based on user feedback, such as term reweighting and query expansion. While this body of work is not necessarily focused exclusively on the information filtering problem, it demonstrates effectively how learning can be used to improve queries. <p> In these experiments individual articles are represented as vectors of 30,000 tf-idf features. Our Rocchio method is based on the procedure described in <ref> (Buckley, Salton, & Allan 1994) </ref>. As before, the training involved induction of a new profile based on feedback from the pre-classified training examples, as follows. <p> This average was converted from a tf.idf measure to a tf measure by dividing each tf.idf value by the idf. The profile was then reweighted using the modified Rocchio formula below. This formula transforms the weight of a profile term k from pold to p-new as follows <ref> (Buckley, Salton, & Allan 1994) </ref>: Learning Learning Predictive Accuracy Average Precision/ Average Recall Method Problem TFIDF POL S F C ALL TFIDF POL S F C ALL AQ15c USMED 0.58 0.48 0 . 7 8 0.55 0.51/1.00 0.45/0.45 0 . 7 8 / 0 . 7 3 0.52/0.34 T122 0.39 0.59
Reference: <author> Foltz, P. and Dumais, S. </author> <year> 1992. </year> <title> Personalized Information Delivery: An Analysis of Information-Filtering Methods. </title> <journal> CACM , 35, </journal> <volume> (12): </volume> <pages> 51-60. </pages>
Reference-contexts: In particular, there is a need for tools to capture profiles of users information needs, and to find articles relevant to these needs, as these needs change over time. Information filtering, as (Belkin & Croft 1992), <ref> (Foltz & Dumais 1992) </ref> point out, is an information access activity similar to information retrieval, but where the profiles represent evolving interests of users over a long-term period, and where the filters are applied to dynamic streams of incoming data.
Reference: <author> Evans, D.; Hersh, W.; Monarch, I.; Lefferts, R. and Henderson, S. </author> <year> 1991. </year> <title> Automatic Indexing of Abstracts via Natural-Language Processing Using a Simple Thesaurus, Medical Decision Making 11 (supp), S108-S115. Learning Predictive Accuracy Average Precision/ Average Recall Method U S M E D T 1 2 2 U S M E D T 1 2 2 R o c c h i o 0.49 0.51 0.52/0.53 0.39/0.27 Best AQ15c (SFC) 0.78 0.76 0.78/0.73 0.79//0.48 Best C4.5 (ALL) 0.76 0.76 0.97/0.60 0.70/0.67 Table 2. Comparing Predictive Accuracy, Average Precision / Average Recall for tf.idf terms. </title>
Reference-contexts: Other features and combinations thereof showed different learning performance for different topics, further emphasizing the usefulness of the hybrid representation. These results also confirm the suspicion that tuning a thesaurus to a particular domain will generally yield better learning performance. In this connection, the work of <ref> (Evans et al. 1991) </ref> on thesaurus discovery and (Hearst & Schutze 1993) on thesaurus tuning is highly relevant. In the latter work, thesaural categories extracted automatically from Wordnet (Miller et al 1990) were extended with terms from a corpus.
Reference: <author> Haines, D. and Croft, B. </author> <year> 1993. </year> <title> Relevance Feedback and Inference Networks. </title> <booktitle> ACM SIGIR. </booktitle>
Reference-contexts: Relevance feedback approaches are a form of supervised learning where a user indicates which retrieved documents are relevant or irrelevant. These approaches, e.g., (Rocchio 1971), (Robertson & Sparck-Jones 1976), (Belew 1989), (Salton & Buckley 1990), (Harman 1992), <ref> (Haines & Croft 1993) </ref>, (Buckley, Salton, & Allan 1994), have investigated techniques for automatic query reformulation based on user feedback, such as term reweighting and query expansion.
Reference: <author> Harman, D. </author> <year> 1992. </year> <title> Relevance Feedback Revisited. </title> <booktitle> ACM SIGIR. </booktitle>
Reference-contexts: We will now introduce these briefly, to better motivate and distinguish our work. Relevance feedback approaches are a form of supervised learning where a user indicates which retrieved documents are relevant or irrelevant. These approaches, e.g., (Rocchio 1971), (Robertson & Sparck-Jones 1976), (Belew 1989), (Salton & Buckley 1990), <ref> (Harman 1992) </ref>, (Haines & Croft 1993), (Buckley, Salton, & Allan 1994), have investigated techniques for automatic query reformulation based on user feedback, such as term reweighting and query expansion.
Reference: <author> Harman, D. </author> <year> 1994. </year> <title> Overview of the Third Text Retrieval Conference (TREC-3). </title> <institution> Computer Systems Laboratory, National Institute of Standards and Technology. </institution>
Reference: <author> Hearst, M. and Schutze, H. </author> <year> 1992. </year> <title> Customizing a Lexicon to Better Suit a Computational Task. </title> <booktitle> In Proceedings of the ACL SIGLEX Workshop on Acquisition of Lexical Knowledge from Text, </booktitle> <address> Columbus, Ohio. </address>
Reference: <author> Jones, S.; Gatford, M.; Robertson, S.; Hancock-Beaulieu, M. Secker, J. and Walker, S. </author> <title> Interactive Thesaurus Navigation: </title> <journal> Intelligence Rules OK? Journal of the American Society for Information Science, </journal> <volume> 46 </volume> (1):52-59. 
Reference: <author> Lang, K. </author> <year> 1995. </year> <title> NewsWeeder: Learning to Filter Netnews. </title> <booktitle> In Proceedings of the Twelth International Workshop on Machine Learning. </booktitle> <pages> 331-339. </pages>
Reference-contexts: Filters have been constructed for many applications including web pages and USENET news, such as NewT (Maes 1994), Webhound (Lashkari, Metral, & Maes 1994), WebWatcher (Armstrong et al. 1995), WebLearner (Pazzani et al. 1995) and NewsWeeder <ref> (Lang 1995) </ref>. However, in the above approaches, the agent is unable to learn generalizations about the users interests.
Reference: <author> Lashkari, Y.; Metral, M. and Maes, P. </author> <year> 1994. </year> <title> Collaborative interface agents. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence. </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: Work on the application of machine learning techniques for constructing personalized information filters has gained momentum in recent years. Filters have been constructed for many applications including web pages and USENET news, such as NewT (Maes 1994), Webhound <ref> (Lashkari, Metral, & Maes 1994) </ref>, WebWatcher (Armstrong et al. 1995), WebLearner (Pazzani et al. 1995) and NewsWeeder (Lang 1995). However, in the above approaches, the agent is unable to learn generalizations about the users interests.
Reference: <author> Liddy, E. and Myaeng, S. </author> <year> 1992. </year> <title> DR-LINK's Linguistic-Conceptual Approach to Document Detection. </title> <booktitle> In Proceedings of the First Text Retrieval Conference. </booktitle> <institution> Natl. Institute of Standards and Technology. </institution>
Reference-contexts: Our first set of summary level features assigns thesaural categories (or subjects) to segments of text based on the Subject Field Coder (SFC) <ref> (Liddy and Paik 1992) </ref> (Liddy and Myaeng 1992) (from TextWise, Inc.). In attempting to associate thesaural categories with texts, one well-known problem is that of wordsense disambiguation, in this case deciding which of several thesaurus categories are the most likely ones for a term in the text. <p> Our first set of summary level features assigns thesaural categories (or subjects) to segments of text based on the Subject Field Coder (SFC) (Liddy and Paik 1992) <ref> (Liddy and Myaeng 1992) </ref> (from TextWise, Inc.). In attempting to associate thesaural categories with texts, one well-known problem is that of wordsense disambiguation, in this case deciding which of several thesaurus categories are the most likely ones for a term in the text. <p> Although this hierarchy covers a fairly wide set of subjects 1 An earlier version of the SFC was tested on 166 sentences from the Wall Street Journal (1638 words) giving the right category on 87% of the words <ref> (Liddy and Myaeng 1992) </ref>. as required for our newspaper application, it does not have a great deal of depth to allow more specific profiles to be differentiated.
Reference: <author> Liddy, E. and Paik, W. </author> <year> 1992. </year> <title> Statistically Guided Word-Sense Disambiguation. </title> <booktitle> In Proceedings of the AAAI Fall Symposium Series: Probabilistic Approaches to Natural Language. </booktitle> <address> Menlo Park, Calif.; </address> <booktitle> American Association for Artificial Intelligence. </booktitle>
Reference-contexts: Our first set of summary level features assigns thesaural categories (or subjects) to segments of text based on the Subject Field Coder (SFC) <ref> (Liddy and Paik 1992) </ref> (Liddy and Myaeng 1992) (from TextWise, Inc.). In attempting to associate thesaural categories with texts, one well-known problem is that of wordsense disambiguation, in this case deciding which of several thesaurus categories are the most likely ones for a term in the text. <p> Our first set of summary level features assigns thesaural categories (or subjects) to segments of text based on the Subject Field Coder (SFC) (Liddy and Paik 1992) <ref> (Liddy and Myaeng 1992) </ref> (from TextWise, Inc.). In attempting to associate thesaural categories with texts, one well-known problem is that of wordsense disambiguation, in this case deciding which of several thesaurus categories are the most likely ones for a term in the text. <p> Although this hierarchy covers a fairly wide set of subjects 1 An earlier version of the SFC was tested on 166 sentences from the Wall Street Journal (1638 words) giving the right category on 87% of the words <ref> (Liddy and Myaeng 1992) </ref>. as required for our newspaper application, it does not have a great deal of depth to allow more specific profiles to be differentiated.
Reference: <author> Maes, P. </author> <year> 1994. </year> <title> Agents That Reduce Work and Information Overload. </title> <journal> CACM, </journal> <volume> 37 </volume> (7):31-40, 146-147. 
Reference-contexts: Work on the application of machine learning techniques for constructing personalized information filters has gained momentum in recent years. Filters have been constructed for many applications including web pages and USENET news, such as NewT <ref> (Maes 1994) </ref>, Webhound (Lashkari, Metral, & Maes 1994), WebWatcher (Armstrong et al. 1995), WebLearner (Pazzani et al. 1995) and NewsWeeder (Lang 1995). However, in the above approaches, the agent is unable to learn generalizations about the users interests. <p> Work on the application of machine learning techniques for constructing personalized information filters has gained momentum in recent years. Filters have been constructed for many applications including web pages and USENET news, such as NewT (Maes 1994), Webhound <ref> (Lashkari, Metral, & Maes 1994) </ref>, WebWatcher (Armstrong et al. 1995), WebLearner (Pazzani et al. 1995) and NewsWeeder (Lang 1995). However, in the above approaches, the agent is unable to learn generalizations about the users interests.
Reference: <author> Mani, I. and MacMillan, T. </author> <year> 1995. </year> <title> Identifying Unknown Proper Names in Newswire Text. </title> <editor> in J. Pustejovsky, ed., </editor> <title> Corpus Processing for Lexical Acquisition, </title> <publisher> MIT Press. </publisher>
Reference-contexts: These features were provided by a name tagger <ref> (Mani & MacMillan 1995) </ref> which classifies names in unrestricted news articles in terms of a hierarchy of different types of POLs along with their attributes (e.g., a persons title, an organizations business, a citys country, etc.) The name tagger combines evidence from multiple knowledge sources, each of which uses patterns based
Reference: <author> Menczer, F.; Willuhn, W. and Belew, R. </author> <year> 1994. </year> <title> An Endogenous Fitness Paradigm for Adaptive Information Agents. </title> <booktitle> In Proceedings of the CIKM94 Workshop on Intelligent Information Agents. </booktitle>
Reference: <author> Millet, G.; Beckwith, R.; Fellbaum, C.; Gross, D. and Miller, K. </author> <year> 1990. </year> <title> Introduction to WordNet: An online lexical database. </title> <journal> Journal of Lexicography, </journal> <volume> 3 </volume> (4):235-244. 
Reference: <author> Pazzani, M.; Nguyen, L. and Mantik, S. </author> <year> 1995. </year> <title> Learning from Hotlists and Coldlists: Towards a WWW Information Filtering and Seeking Agent. </title> <booktitle> In Proceedings of the Tools for AI Conference. </booktitle>
Reference-contexts: Work on the application of machine learning techniques for constructing personalized information filters has gained momentum in recent years. Filters have been constructed for many applications including web pages and USENET news, such as NewT (Maes 1994), Webhound (Lashkari, Metral, & Maes 1994), WebWatcher (Armstrong et al. 1995), WebLearner <ref> (Pazzani et al. 1995) </ref> and NewsWeeder (Lang 1995). However, in the above approaches, the agent is unable to learn generalizations about the users interests.
Reference: <author> Quinlan, J. </author> <year> 1992. </year> <title> C4.5: Programs for Machine Learning. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: We wanted to use learning methods which performed inductive generalization where the SFC generalization hierarchy could be exploited. Also, we required a learning algorithm whose learnt rules could be made easily intelligible to users. We decided to try both AQ15c (Wnek et al. 1994) and C4.5-Rules <ref> (Quinlan 1992) </ref> because they meet these requirements (the generalization hierarchy is made available to C4.5 by extending the attribute set), are well-known in the field and are readily available.
Reference: <author> Quinlan, J. </author> <year> 1995. </year> <type> personal communication. </type>
Reference-contexts: Here AQ15c has the hierarchy available to it in the form of hierarchical domain definitions for attributes x1 through x5. C4.5 has a hierarchy available to it through an extended attribute set. In this extension, based on a pointer from Quinlan <ref> (Quinlan, 1995) </ref>, we extended the attribute set to include attributes which describe nodes higher up on the generalization hierarchy. A total of eighteen additional 3 Feedback on only a small number of examples is quite typical of real-world applications.
Reference: <author> Robertson, S. and Sparck-Jones, K. </author> <year> 1976. </year> <title> Relevance Weighting of Search Terms. </title> <journal> Journal of the American Society for Information Science 27 </journal> (3):129-146. 
Reference-contexts: We will now introduce these briefly, to better motivate and distinguish our work. Relevance feedback approaches are a form of supervised learning where a user indicates which retrieved documents are relevant or irrelevant. These approaches, e.g., (Rocchio 1971), <ref> (Robertson & Sparck-Jones 1976) </ref>, (Belew 1989), (Salton & Buckley 1990), (Harman 1992), (Haines & Croft 1993), (Buckley, Salton, & Allan 1994), have investigated techniques for automatic query reformulation based on user feedback, such as term reweighting and query expansion.
Reference: <author> Rocchio, J. </author> <year> 1971. </year> <title> Relevance Feedback in Information Retrieval. in The SMART Retrieval System: Experiments in Automatic Document Processing. </title> <address> 313-323, </address> <publisher> Prentice-Hall. </publisher>
Reference-contexts: We will now introduce these briefly, to better motivate and distinguish our work. Relevance feedback approaches are a form of supervised learning where a user indicates which retrieved documents are relevant or irrelevant. These approaches, e.g., <ref> (Rocchio 1971) </ref>, (Robertson & Sparck-Jones 1976), (Belew 1989), (Salton & Buckley 1990), (Harman 1992), (Haines & Croft 1993), (Buckley, Salton, & Allan 1994), have investigated techniques for automatic query reformulation based on user feedback, such as term reweighting and query expansion.
Reference: <author> Salton, G. and Buckley, C. </author> <year> 1990. </year> <title> Improving Retrieval Performance by Relevance Feedback. </title> <journal> Journal of the American Society for Information Science, </journal> <pages> 88-297. </pages>
Reference-contexts: We will now introduce these briefly, to better motivate and distinguish our work. Relevance feedback approaches are a form of supervised learning where a user indicates which retrieved documents are relevant or irrelevant. These approaches, e.g., (Rocchio 1971), (Robertson & Sparck-Jones 1976), (Belew 1989), <ref> (Salton & Buckley 1990) </ref>, (Harman 1992), (Haines & Croft 1993), (Buckley, Salton, & Allan 1994), have investigated techniques for automatic query reformulation based on user feedback, such as term reweighting and query expansion.
Reference: <author> Salton, G. and McGill, M. </author> <year> 1983. </year> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill. </publisher>
Reference-contexts: title, an organizations business, a citys country, etc.) The name tagger combines evidence from multiple knowledge sources, each of which uses patterns based on lexical items, parts of speech, etc., to contribute evidence towards a particular classification. 2 Document keywords were also extracted by using a term-frequency inverse-document-frequency (tf.idf) calculation <ref> (Salton & McGill 1983) </ref>, which is a well-established technique in information retrieval. <p> During testing, the test documents were compared against the new profile using the following cosine similarity metric for calculating the degree of match between a profile j (with the tf weights converted back to tf.idf weights) and a test document i (with tf.idf weights) <ref> (Salton & McGill 1983) </ref>: c ij = k=1 (dw ik *qw jk ) k=1 dw ik 2 * t 2 Where t = total number of terms in collection, dw ik = tf.idf weight of term k in document I, qw jk = tf.idf weight of term k in profile j.
Reference: <author> Schutze, H.; Hull, D. and Pedersen, J. </author> <year> 1995. </year> <title> A Comparison of Classifiers and Document Representations for the Routing Problem. </title> <booktitle> ACM SIGIR. </booktitle>
Reference: <author> Wnek, J.; Kaufman, K.; Bloedorn, E. and Michalski, R. </author> <year> 1995. </year> <title> Selective Inductive Learning Method AQ15c: The Method and User's Guide. Reports of the Machine Learning and Inference Laboratory, </title> <institution> ML95-4, George Mason Univ. </institution>
References-found: 30

