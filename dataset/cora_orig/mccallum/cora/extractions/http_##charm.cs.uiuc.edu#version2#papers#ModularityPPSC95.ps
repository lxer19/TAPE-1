URL: http://charm.cs.uiuc.edu/version2/papers/ModularityPPSC95.ps
Refering-URL: http://charm.cs.uiuc.edu/version2/papers/ModularityPPSC95.html
Root-URL: http://www.cs.uiuc.edu
Title: Chapter 1 Modularity, Reuse and Efficiency with Message-Driven Libraries  
Author: L.V. Kale and A. Gursoy 
Address: Urbana Champaign 1304 W. Springfield Ave., Urbana, IL-61801  
Affiliation: Department of Computer Science University of Illinois at  
Web: CCR-91-06608.  
Note: This research was supported in part by the National Science Foundation grants CCR-90-07195 and  
Abstract: Software re-use via libraries is a strategy that allows the cost of software to be amortized. A parallel programming system must support the ability to develop modules that can be "fitted together" in a variety of contexts. Although it is important to be able to reuse parallel libraries, it is also more difficult to use parallel modules in comparison to sequential module. We present a methodology for developing libraries that addresses these issues effectively. The methodology, which is embodied in the Charm system, employs message-driven execution (in contrast to traditional, receive based message passing), information sharing abstractions, the notion of branched objects, and explicit support for modules.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L.V. Kale, </author> <title> The Chare Kernel Parallel Programming Language and System, </title> <journal> Proc. ICCP90, </journal> <volume> Vol II, </volume> <month> Aug </month> <year> 1990, </year> <pages> pp. 17-25. </pages>
Reference-contexts: Caller modules must invoke the library on all processors even when only a subset of the processors provide input, and receive output. 3. Library computations must be called in the same sequence on each processor. A message-driven system, such as Charm <ref> [1] </ref>, supports multiple objects per processor, and uses a pool of messages on every processors. An object is scheduled for execution when there is a message for it. In such a system, one can invoke multiple library modules concurrently, allowing them to naturally overlap their idle times with useful computations.
Reference: [2] <institution> Charm 4.3 Programming Language Manual, Department of Computer Science, University of Illinois at Urbana-Champaign, </institution> <month> Sep </month> <year> 1994. </year>
Reference-contexts: Entry functions are invoked asynchronously by an object on any processor. Invoking an entry function in a remote object can also be thought of 2 as sending a message to it. A full description of the Charm language and its C++ based version, Charm++, can be found in <ref> [2, 3] </ref>. The Charm runtime system is message driven.
Reference: [3] <author> L.V. Kale and S. Krishnan, </author> <title> Charm++ : A portable concurrent object oriented system based on C++, </title> <booktitle> Proc. of OOPSLA 93, </booktitle> <address> Washington D.C. </address>
Reference-contexts: Entry functions are invoked asynchronously by an object on any processor. Invoking an entry function in a remote object can also be thought of 2 as sending a message to it. A full description of the Charm language and its C++ based version, Charm++, can be found in <ref> [2, 3] </ref>. The Charm runtime system is message driven.
Reference: [4] <author> A. Gursoy, </author> <title> Simplified expression of message-driven programs and quantification of their impact on performance, </title> <type> Ph.D Thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> Apr </month> <year> 1994. </year>
Reference-contexts: In such a system, one can invoke multiple library modules concurrently, allowing them to naturally overlap their idle times with useful computations. This is a substantial boost for encouraging use of libraries. As an example, taken from <ref> [4] </ref>, consider an application A that invokes two independent library modules B and C as shown in Figure 1. The B and C themselves are parallel computations which may have their own idle times on all processors due to message latency and dependencies among sub-computations. <p> If the return is by a function call, the reference number can be passed as an additional parameter to the return function. 5 Example and Performance This example <ref> [4] </ref> is abstracted and modified from a real application | a core routine in parallelized version of a molecular mechanics code, CHARMM. Each processor has an array A of size n.
Reference: [5] <author> L.V. Kale and A. Sinha, </author> <title> Information Sharing Mechanisms in Parallel Programs, </title> <booktitle> Proc. of IPPS-94, </booktitle> <address> Cancun April 1994. </address>
Reference-contexts: On the other hand, a shared variable is too amorphous a mechanism | its generality is not needed in most situations and costs too much to implement. Recognizing this, Charm provides six specific information sharing abstractions in addition to messages. Further information about these abstractions can be found elsewhere <ref> [5] </ref>. Many of these mechanisms provide flexible ways of data exchange across modules. For example, a distributed table holds a collection of data items, each indexed by a distinct key. On distributed memory machines, this collection may be distributed across the processors.
Reference: [6] <author> N. Carriero and D. Gelernter, </author> <title> Linda in Context, </title> <journal> Comm. ACM, </journal> <month> 32-4 </month> <year> (1989), </year> <pages> pp. 444-458. </pages>
Reference-contexts: Information is shared in a few but multiple, distinct ways in a parallel program. A "message" is not an adequate mechanism for expressing information sharing, nor is any single generic mechanism such as Linda's tuples <ref> [6] </ref>. On the other hand, a shared variable is too amorphous a mechanism | its generality is not needed in most situations and costs too much to implement. Recognizing this, Charm provides six specific information sharing abstractions in addition to messages.
Reference: [7] <author> Message Passing Interface Forum, </author> <title> Document for a standard message passing interface, </title> <institution> CS-93-214, University of Tennessee, </institution> <month> Nov, </month> <year> 1993. </year> <month> 7 </month>
Reference-contexts: For example, an entry function f of a chare c in module m is invoked as: m::c@f (msg). Thus, a library developer can freely use names | even including the names that they wish to export | without worrying about possible conflicts. The recent concept of "contexts" in MPI <ref> [7] </ref> eliminates conflicts on tags across modules, but other name conflicts remain. Complex libraries often require the use of callbacks: a library module invoked by its client might, during the course of its parallel computation, require further information from the client.
References-found: 7

