URL: http://www.cogs.susx.ac.uk/users/ibrahim/icml96.ps
Refering-URL: http://www.cs.bham.ac.uk/~wbl/biblio/gp-bibliography.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Genetic Programming and Incremental Approaches to Solve Supervised Learning Problems  
Author: Ibrahim KUSCU 
Keyword: Supervised Learning, Genetic Programming, Three Monk's Problems, Par ity Problems.  
Note: This research is funded by  
Address: Brighton BN1 9QH  
Affiliation: Cognitive and Computing Sciences University of Sussex  Middle East Technical Uni versity, Ankara, Turkiye  
Abstract: This paper presents an evolutionary approach and an incremental approach to find learning rules of several supervised learning tasks. In evolutionary approach potential solutions are represented as variable length mathematical (LISP S-) expressions. Thus, it is similar to Genetic Programming (GP) but it employs only a fixed set of non-problem specific functions to solve a variety of problems. The model is tested on three Monks' and parity problems. The results indicate the usefulness of the encoding schema in discovering learning rules for simple supervised learning problems. However, hard learning problems require special attention in terms of their need for larger size codings of the potential solutions and their ability of generalisa-tion over the testing set. In order to find better solutions to these issues, a hill climbing strategy with an incremental coding of potential solutions is used in discovering learning rules for the same problems. It is found that with this strategy larger solutions can easily be coded for with less computational effort. Although a better performance is achieved in training for the hard learning problems, the ability of the generalisation over the testing cases is observed to be poor. 
Abstract-found: 1
Intro-found: 1
Reference: [ 1 ] <author> A. Clark and C. Thornton. </author> <title> Trading spaces: Computation, representation and the limits of uninformed learning. Behavioral and Brain Sciences, </title> <publisher> Forthcoming. </publisher>
Reference-contexts: This means that there is a direct correlation between particular input values and particular output values. However, sometimes the rule may not refer to particular values of variables. Rather it may refer to possible relationships between input values. It has been shown <ref> [ 1 ] </ref> that learning behaviors based on training sets that involve a relationship among values of the input variables can be extremely difficult (named as type-2 learning problems). <p> solving hard learning problems (i.e. in the context of this research hard learning problems are considered to be those supervised learning problems where the learning rule refers to the relationship among the input values rather than representing a direct correlation between value (s) of input (s) and output variable (s) <ref> [ 1 ] </ref> [ 10 ] ) such as Monk 2 and parity problems. However, when the problems were larger and more complex (i.e. hard learning problems), the ability of the model in coding for good solutions and effectively generalising over the testing set was not found to be satisfactory.
Reference: [ 2 ] <author> J. Koza. </author> <title> Genetic Programming:On the programming of computers by means of natural selection. </title> <publisher> MIT press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: 1 INTRODUCTION This research presents how a Genetic Programmming (GP) <ref> [ 2 ] </ref> [ 3 ] based learning model can be developed to solve supervised learning problems. The main characteristic of supervised learning is that the problem is defined in terms of an input/output mapping. <p> In a previous paper [ 6 ] a pure GP based learning model has been presented and tested on several simple supervised and hard supervised tasks. The representation schema is very similar to the one used in genetic programming (GP) <ref> [ 2 ] </ref> . However, introducing prior knowledge into the representation of initial solutions using problem-specific functions is minimal, if any at all. In this strategy potential learning rules are encoded as random mathematical expressions at variable lengths. The expressions are made up of random numbers and random variables. <p> The number of input variables increases from 6 to 17 since each possible value of the attributes is represented as 3 digit binary numbers where each digit represents the presence of a specific value of the attributes. 3 GENETIC PROGRAMMING In genetic programming paradigm <ref> [ 2 ] </ref> [ 3 ] problems of artificial intelligence (AI) are viewed as the discovery of computer programs which produce desired outputs for particular inputs. A computer program could be an expression, formula, plan, control strategy, decision tree or a model depending on the sort of AI problem. <p> <ref> [ 2 ] </ref> [ 3 ] problems of artificial intelligence (AI) are viewed as the discovery of computer programs which produce desired outputs for particular inputs. A computer program could be an expression, formula, plan, control strategy, decision tree or a model depending on the sort of AI problem. Koza [ 2 ] claims that solving AI problems requires searching the space of possible computer programs for the better fitting individual computer program. GP is a method of searching for this better fitting individual computer program based on Darwinian selection and genetic operations. <p> The selection of the functions and terminals are guided by the sufficiency property which states that "the set of terminals and the set of primitive functions be capable of expressing a solution to the problem" <ref> [ 2 ] </ref> p.86. Since there is not a universal set of functions which is capable of solving every problem, the need for reducing the set of primitives to a minimally sufficient set seems justified. However, how to choose a minimally sufficient set remains an open question. <p> In GP practice, however, user defined functions introduces excessively high prior domain knowledge (human intervention) into the model such that the degree of learning to be achieved is excessively low. Although the step of selecting user defined functions has been claimed to be common to several other learning paradigms <ref> [ 2 ] </ref> p.88, the amount of domain knowledge introduced in this step by GP and other paradigms is not compared. <p> In this case, a larger population size and an increased number of generations as well as longer and more complex representations of the solutions may be required. For example Koza, in experiments with even-5-parity problems, increased the number of population from 4000 to 8000 to find a solution <ref> [ 2 ] </ref> p.533. This is a huge number compared to our 300 population size and 250 generations. 6.2 RESULTS OF INCREMENTAL MODEL In general, for the same problems the incremental model found slightly more satisfactory solutions to hard learning problems compared to the evolutionary method.
Reference: [ 3 ] <editor> J. Koza. </editor> <booktitle> Genetic Programming II. </booktitle> <publisher> MIT press, </publisher> <year> 1994. </year>
Reference-contexts: 1 INTRODUCTION This research presents how a Genetic Programmming (GP) [ 2 ] <ref> [ 3 ] </ref> based learning model can be developed to solve supervised learning problems. The main characteristic of supervised learning is that the problem is defined in terms of an input/output mapping. <p> The number of input variables increases from 6 to 17 since each possible value of the attributes is represented as 3 digit binary numbers where each digit represents the presence of a specific value of the attributes. 3 GENETIC PROGRAMMING In genetic programming paradigm [ 2 ] <ref> [ 3 ] </ref> problems of artificial intelligence (AI) are viewed as the discovery of computer programs which produce desired outputs for particular inputs. A computer program could be an expression, formula, plan, control strategy, decision tree or a model depending on the sort of AI problem.
Reference: [ 4 ] <author> I. Kuscu. </author> <title> Evolution of learning rules for supervised tasks i: Simple learning problems. </title> <type> Technical Report CSRP-394, Uni. </type> <institution> of Sussex, COGS, </institution> <year> 1995. </year>
Reference-contexts: The results of the experiments in <ref> [ 4 ] </ref> and being able to discover or re-represent solutions to monk-1 and monk-3 problems in this paper provided evidence in support of the first hypothesis. Failing to find a successful solution for monk-2 seems a poor support for the sec ond hypothesis.
Reference: [ 5 ] <author> I. Kuscu. </author> <title> Incrementally learning the rules for supervised tasks: Monk's problems. </title> <type> Technical Report CSRP-396, Uni. </type> <institution> of Sussex, COGS, </institution> <year> 1995. </year>
Reference-contexts: However, when the problems were larger and more complex (i.e. hard learning problems), the ability of the model in coding for good solutions and effectively generalising over the testing set was not found to be satisfactory. In recent experiments <ref> [ 5 ] </ref> these issues are investigated further. The experiments involve an incremental encoding of an expression as a potential solution. Although the basic encoding strategy (forming potential solutions as random mathematical expressions) is the same as the one used in previous experiments, the searching strategy is different. <p> The performance on monk-1 and monk-3 is at the level of competing with most of the algorithms. Although the performance on monk-2 is very low, this is not surprising and similar to the results obtained by Thrun. Moreover, in a recent extension of the experiments <ref> [ 5 ] </ref> where the representation is improved and the performance in learning, especially on the monk-2 problem, is increased. The results emphasise how the encoding can enable us to evolve learning rules for these problems with fixed, general and non-problem-specific set of functions.
Reference: [ 6 ] <author> I. Kuscu. </author> <title> Evolution of learning rules for hard learning problems. </title> <booktitle> In the Proceedings of The Fifth Annual Conference on Evolutionary Programming, </booktitle> <publisher> forthcoming. </publisher>
Reference-contexts: In one of the studies [ 9 ] well-known learning algorithms such as ID3, backpropagation, and classifier systems were tested on a type-2 problem and all showed poor results. In a previous paper <ref> [ 6 ] </ref> a pure GP based learning model has been presented and tested on several simple supervised and hard supervised tasks. The representation schema is very similar to the one used in genetic programming (GP) [ 2 ] .
Reference: [ 7 ] <author> I. Kuscu and C. Thornton. </author> <title> Design of artificial neural networks using genetic algorithms:review and prospect. </title> <editor> In C. et al Bozsahin, editor, </editor> <booktitle> Proceedings of Third Turkish Syposium on artificial Intelligence and Neural Networks, </booktitle> <pages> pages 411-420, </pages> <year> 1994. </year>
Reference-contexts: Moreover, in the light of substantial research on automatising the topological structure and parameter selection of artificial neural networks <ref> [ 7 ] </ref> , any claim that neural networks and GP require a similar level of human intervention would be even less convincing.
Reference: [ 8 ] <author> D. Rumelhart, G. Hinton, and R. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In D. Rumelhart, J. McClelland, </editor> <title> and the PDP Research Group, editors, Parallel Distributed Processing: Explorations in the Micro-structures of Cognition. Vols I and II. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1986. </year>
Reference-contexts: Several functions have been tested in this mapping including the logistic activation function used by <ref> [ 8 ] </ref> . <p> In the first one the value of the each sub-expression is mapped to a value in a specific range (between 2 and +2) by using another squashing function called LF2. LF2 behaves like logistic activation function used in <ref> [ 8 ] </ref> but the boundary values are 2 and +2. In the second way, each sub-expression is multiplied by a random number usually in the range of 0 and 1.
Reference: [ 9 ] <author> C. Thornton. </author> <title> Supervised learning of conditional approach: a case study. </title> <type> Technical Report 291, </type> <institution> COGS, University of Sussex, </institution> <year> 1993. </year>
Reference-contexts: Rather it may refer to possible relationships between input values. It has been shown [ 1 ] that learning behaviors based on training sets that involve a relationship among values of the input variables can be extremely difficult (named as type-2 learning problems). In one of the studies <ref> [ 9 ] </ref> well-known learning algorithms such as ID3, backpropagation, and classifier systems were tested on a type-2 problem and all showed poor results. In a previous paper [ 6 ] a pure GP based learning model has been presented and tested on several simple supervised and hard supervised tasks.
Reference: [ 10 ] <author> C. Thornton. </author> <title> Measuring the difficulty of specific learning problems. </title> <journal> Connection Science, </journal> <volume> 7(1), </volume> <year> 1995. </year>
Reference-contexts: problems (i.e. in the context of this research hard learning problems are considered to be those supervised learning problems where the learning rule refers to the relationship among the input values rather than representing a direct correlation between value (s) of input (s) and output variable (s) [ 1 ] <ref> [ 10 ] </ref> ) such as Monk 2 and parity problems. However, when the problems were larger and more complex (i.e. hard learning problems), the ability of the model in coding for good solutions and effectively generalising over the testing set was not found to be satisfactory.
Reference: [ 11 ] <author> S. B. Thrun, J. Bala, E. Bloendorn, I. Bratko, B. Cestnik, J. Cheng, K. De Jong, S. D^zeroski, S. E. Fahlman, D. Fisher, R. Hamann, K. Kauf-man, S. Keller, I. Kononenko, J. Kreuziger, R. S. Michalski, T. Mitchell, P. Pachovicz, Y. Re-ich, H. Vafaie, W. Van de Welde, W. Wentzel, J. Wnek, and J. Zhang. </author> <title> The monk's problems a performance comparison of different learning algorithms. </title> <type> Technical Report CMU-CS-91-197, </type> <institution> School of Computer Science, Carnegie-Mellon University., USA, </institution> <year> 1991. </year>
Reference-contexts: Then, the experiments and the results will be presented. Finally, I will conclude with a discussion and a comparison of the models. 2 THREE MONK'S PROBLEMS The three Monk's problems are used to compare the performance of different symbolic and non-symbolic learning techniques <ref> [ 11 ] </ref> including AQ17-DCI, AQ17-FCLS, AQ14-NT, AQ15-GA, Assistant Professional, mFOIL, ID5R-hat, TDIDT, ID3, AQR, CN2, CLASS-WEB, ECOBVEB, PRISM, Backpropagation and Cascade Correlation. Monk's problems involve classification of robots which are described by six different attributes. <p> RESULTS Original Coding Binary Coding Problems Training Testing Training Testing MONK 1 91 88 MONK 2 74 68 79 69 MONK 3 93 98 93.5 97 Table 1: Best performances in percentages The results obtained are better than some of the learning algorithms used in the comparison experiment of Thrun <ref> [ 11 ] </ref> . The performance on monk-1 and monk-3 is at the level of competing with most of the algorithms. Although the performance on monk-2 is very low, this is not surprising and similar to the results obtained by Thrun. <p> Although, the performance in learning the rule for Monk 2 increased compared to performance of the solutions found in genetic based experiments and was better than the performance of the most learning algorithms reported in <ref> [ 11 ] </ref> . In all cases, during the training a solution with a performance higher than 90 percent found for Monk 2 but they all showed a poor gener-alisation over testing set. When tested with the parity problems, similar results are observed.
Reference: [ 12 ] <author> D. Whitley. </author> <title> The genitor algorithm and why rank based-based allocation of reproductive trials is best. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 116-123. </pages> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference-contexts: The expressions are ranked after each generation according to their success. Those who are higher in the rank (higher scoring ones) are said to be most fitting expressions. 5.2.2 Selection In the model, parent selection technique for reproduction is normalizing by using an exponential function taken from Whitley's <ref> [ 12 ] </ref> rank-based selection technique. The function generates integer numbers from 1 to population size. The generation of numbers exhibits characteristics of a non-linear function where there is more tendency to produce smaller numbers (since higher scoring expressions are on top of the rank).
References-found: 12

