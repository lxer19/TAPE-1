URL: http://www.ultimode.com/wray/lwgmJAIR.ps.Z
Refering-URL: http://www.ultimode.com/wray/lwgmja/
Root-URL: 
Email: wray@kronos.arc.nasa.gov  
Title: Operations for Learning with Graphical Models decomposition techniques and the demonstration that graphical models provide
Author: Wray L. Buntine 
Address: Moffett Field, CA 94035-1000, USA  
Affiliation: RIACS NASA Ames Research Center, Mail Stop 269-2  
Note: Journal of Artificial Intelligence Research 2 (1994) 159-225 Submitted 4/94; published 12/94  The main original contributions here are the  
Abstract: This paper is a multidisciplinary review of empirical, statistical learning from a graphical model perspective. Well-known examples of graphical models include Bayesian networks, directed graphs representing a Markov chain, and undirected networks representing a Markov field. These graphical models are extended to model data analysis and empirical learning using the notation of plates. Graphical operations for simplifying and manipulating a problem are provided including decomposition, differentiation, and the manipulation of probability models from the exponential family. Two standard algorithm schemas for learning are reviewed in a graphical framework: Gibbs sampling and the expectation maximization algorithm. Using these operations and schemas, some popular algorithms can be synthesized from their graphical specification. This includes versions of linear regression, techniques for feed-forward networks, and learning Gaussian and discrete Bayesian networks from data. The paper concludes by sketching some implications for data analysis and summarizing how some popular algorithms fall within the framework presented. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Andersen, S., Olesen, K., Jensen, F., & Jensen, F. </author> <year> (1989). </year> <title> HUGIN|a shell for building Bayesian belief universes for expert systems. </title> <booktitle> In International Joint Conference on Artificial Intelligence, </booktitle> <address> Detroit. </address> <publisher> Morgan Kaufmann, </publisher> <pages> pp. 1080-1085. </pages>
Reference: <author> Azevedo-Filho, A., & Shachter, R. </author> <year> (1994). </year> <title> Laplace's method approximations for probabilistic inference in belief networks with continuous variables.. </title> <editor> In de Mantaras, R. L., & Poole, D. (Eds.)(1994). </editor> <booktitle> Uncertainty in Artificial Intelligence: Proceedings of the Tenth Conference, </booktitle> <address> Seattle, Washington, </address> <pages> pp. 28-36. </pages>
Reference: <author> Becker, R., Chambers, J., & Wilks, A. </author> <year> (1988). </year> <title> The New S Language. </title> <address> Pacific Grove, California: </address> <publisher> Wadsworth & Brooks/Cole. </publisher>
Reference: <author> Berger, J. </author> <year> (1985). </year> <title> Statistical Decision Theory and Bayesian Analysis. </title> <address> New York: </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Bernardo, J., & Smith, A. </author> <year> (1994). </year> <title> Bayesian Theory. </title> <address> Chichester: </address> <publisher> John Wiley. </publisher>
Reference: <author> Besag, J., York, J., & Mollie, A. </author> <year> (1991). </year> <title> Bayesian image restoration with two applications in spatial statistics. </title> <journal> Ann. Inst. Statist. Math., </journal> <volume> 43 (1), </volume> <pages> 1-59. </pages>
Reference: <author> Box, G., & Tiao, G. </author> <year> (1973). </year> <title> Bayesian Inference in Statistical Analysis. </title> <address> Reading, Mas-sachusetts: </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> Breiman, L., Friedman, J., Olshen, R., & Stone, C. </author> <year> (1984). </year> <title> Classification and Regression Trees. </title> <address> Belmont, California: </address> <publisher> Wadsworth. </publisher>
Reference: <author> Bretthorst, G. </author> <year> (1994). </year> <title> An introduction to model selection using probability theory as logic. </title>
Reference: <editor> In Heidbreder, G. (Ed.). </editor> <year> (1994), </year> <title> Maximum Entropy and Bayesian Methods, </title> <publisher> Kluwer Academic. (Proceedings, </publisher> <address> at Santa Barbara, </address> <year> 1993.) </year> <note> Buntine, </note> <author> W. </author> <year> (1991a). </year> <title> Classifiers: A theoretical and empirical study. </title> <booktitle> In International Joint Conference on Artificial Intelligence, </booktitle> <address> Sydney, </address> <publisher> Morgan Kaufmann, </publisher> <pages> pp. 638-644. </pages>
Reference: <author> Buntine, W. </author> <year> (1991b). </year> <title> Learning classification trees. </title> <editor> In Hand, D. (Ed.), </editor> <booktitle> Artificial Intelligence Frontiers in Statistics, </booktitle> <address> London: </address> <publisher> Chapman & Hall, </publisher> <pages> pp. 182-201. </pages>
Reference-contexts: Local search is then quite fast, and Gibbs sampling over the space of Bayesian networks is possible. A similar situation exists with trees <ref> (Buntine, 1991b) </ref>. The same results apply to any Bayesian network with exponential family distributions at each node, such as Gaussian or Poisson. Results for Gaussians are presented, for instance, in (Geiger & Heckerman, 1994).
Reference: <author> Buntine, W. </author> <year> (1991c). </year> <title> Theory refinement of Bayesian networks. </title> <editor> In D'Ambrosio, B., Smets, P., & Bonissone, P. (Eds.), </editor> <booktitle> Uncertainty in Artificial Intelligence: Proceedings of the Seventh Conference Los Angeles, </booktitle> <address> California. </address>
Reference-contexts: To instantiate a hatched arc they can either be removed or replaced with a full arc. This graphical model then represents many different models, for all 2 4 possible instantiations of the arcs. Prior probabilities for these models could be generated using a scheme such as in <ref> (Buntine, 1991c, p54) </ref> or (Heckerman et al., 1994), where a prior probability is assigned by 197 Buntine a domain expert for different parts of the model, arcs and parameters, and the prior for a full model found by multiplication.
Reference: <author> Buntine, W. </author> <year> (1994). </year> <title> Representing learning with graphical models. </title> <type> Technical Report FIA-94-14, </type> <institution> Artificial Intelligence Research Branch, NASA Ames Research Center. </institution> <note> Submitted. </note>
Reference: <author> Buntine, W., & Weigend, A. </author> <year> (1991). </year> <title> Bayesian back-propagation. </title> <journal> Complex Systems, </journal> <volume> 5 (1), </volume> <pages> 603-643. </pages>
Reference: <author> Buntine, W., & Weigend, A. </author> <year> (1994). </year> <title> Computing second derivatives in feed-forward networks: a review. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 5 (3). 219 Buntine Casella, </volume> <editor> G., & Berger, R. </editor> <year> (1990). </year> <title> Statistical Inference. </title> <address> Belmont, California: </address> <publisher> Wadsworth & Brooks/Cole. </publisher>
Reference: <author> C~ inlar, E. </author> <year> (1975). </year> <title> Introduction to Stochastic Processes. </title> <publisher> Prentice Hall. </publisher>
Reference: <author> Chambers, J., </author> & <title> Hastie, </title> <editor> T. (Eds.). </editor> <year> (1992). </year> <title> Statistical Models in S. </title> <address> Pacific Grove, California: </address> <publisher> Wadsworth & Brooks/Cole. </publisher>
Reference-contexts: In some ways the S system plays the role of a toolkit <ref> (Chambers & Hastie, 1992) </ref>. It provides a system for prototyping learning algorithms, includes the ability to handle generalized linear models, does automatic differentiation of expressions, and includes many statistical and mathematical functions useful as primitives.
Reference: <author> Chan, B., & Shachter, R. </author> <year> (1992). </year> <title> Structural controllability and observability in influence diagrams.. </title> <editor> In Dubois, D., Wellman, M., D'Ambrosio, B., & Smets, P. (Eds.), </editor> <booktitle> (1992). Uncertainty in Artificial Intelligence: Proceedings of the Eight Conference, </booktitle> <address> Stanford, California, </address> <pages> pp. 25-32. </pages>
Reference: <author> Charniak, E. </author> <year> (1991). </year> <title> Bayesian networks without tears. </title> <journal> AI Magazine, </journal> <volume> 12 (4), </volume> <pages> 50-63. </pages>
Reference: <author> Cheeseman, P., Self, M., Kelly, J., Taylor, W., Freeman, D., & Stutz, J. </author> <year> (1988). </year> <title> Bayesian classification. </title> <booktitle> In Seventh National Conference on Artificial Intelligence, </booktitle> <address> Saint Paul, </address> <publisher> Minnesota, </publisher> <pages> pp. 607-611. </pages>
Reference: <author> Cheeseman, P. </author> <year> (1990). </year> <title> On finding the most probable model. </title> <editor> In Shrager, J., & Langley, P. (Eds.), </editor> <title> Computational Models of Discovery and Theory Formation. </title> <publisher> Morgan Kauf-mann. </publisher>
Reference: <author> Cohen, W. </author> <year> (1992). </year> <title> Compiling prior knowledge into an explicit bias. </title> <booktitle> In Ninth International Conference on Machine Learning, </booktitle> <publisher> Morgan Kaufmann, </publisher> <pages> pp. 102-110. </pages>
Reference: <author> Cooper, G., & Herskovits, E. </author> <year> (1992). </year> <title> A Bayesian method for the induction of probabilistic networks from data. </title> <journal> Machine Learning, </journal> <volume> 9 (4), </volume> <pages> 309-348. </pages>
Reference: <author> Cowell, R. </author> <year> (1992). </year> <title> BAIES|a probabilistic expert system shell with qualitative and quantitative learning. </title> <editor> Bernardo, In Bernardo, J., Berger, J., Dawid, A., & Smith, A. (Eds.). </editor> <year> (1992). </year> <title> Bayesian Statistics 4. </title> <publisher> Oxford University Press, </publisher> <pages> pp. 595-600. </pages>
Reference: <author> Dagum, P., Galper, A., Horvitz, E., & Seiver, A. </author> <year> (1994). </year> <title> Uncertain reasoning and forecasting. </title> <journal> International Journal of Forecasting. </journal> <note> Submitted. </note>
Reference: <author> Dagum, P., & Horvitz, E. </author> <year> (1992). </year> <title> Reformulating inference problems through selective conditioning.. </title> <editor> In Dubois, D., Wellman, M., D'Ambrosio, B., & Smets, P. (Eds.), </editor> <booktitle> (1992). Uncertainty in Artificial Intelligence: Proceedings of the Eight Conference, </booktitle> <address> Stanford, California, </address> <pages> pp. 49-54. </pages>
Reference: <author> Dawid, A. </author> <year> (1979). </year> <title> Conditional independence in statistical theory. </title> <journal> SIAM Journal on Computing, </journal> <volume> 41, </volume> <pages> 1-31. </pages>
Reference: <author> Dawid, A. P. </author> <year> (1976). </year> <title> Properties of diagnostic data distributions. </title> <journal> Biometrics, </journal> <volume> 32, </volume> <pages> 647-658. </pages>
Reference: <author> Dawid, A., & Lauritzen, S. </author> <year> (1993). </year> <title> Hyper Markov laws in the statistical analysis of decomposable graphical models. </title> <journal> Annals of Statistics, </journal> <volume> 21 (3), </volume> <pages> 1272-1317. </pages>
Reference-contexts: This incremental modification of evidence, Bayes factors, and finest decompositions is also general, and follows directly from the independence test. A similar property for undirected graphs is given in <ref> (Dawid & Lauritzen, 1993) </ref>. This is developed below for the case of directed arcs and non-deterministic variables. Handling deterministic variables will require repeated application of these results, because several non-deterministic variables may be effected when adding a single arc between deterministic variables. Lemma 6.3 (Incremental decomposition).
Reference: <author> Dean, T., & Wellman, M. </author> <year> (1991). </year> <title> Planning and Control. </title> <address> San Mateo, California: </address> <note> Morgan Kaufmann. 220 Learning with Graphical Models DeGroot, </note> <author> M. </author> <year> (1970). </year> <title> Optimal Statistical Decisions. </title> <publisher> McGraw-Hill. </publisher>
Reference: <author> Dempster, A., Laird, N., & Rubin, D. </author> <year> (1977). </year> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> 39, </volume> <pages> 1-38. </pages>
Reference-contexts: Various other methods for inference on plates can be 200 Learning with Graphical Models applied either at the model level or the parameter level: Gibbs sampling, first described in Section 7.1, other more general Markov chain Monte Carlo algorithms, EM style algorithms <ref> (Dempster, Laird, & Rubin, 1977) </ref>, and various closed form approximations such as the mean field approximation, and the Laplace approximation (Berger, 1985; Azevedo-Filho & Shachter, 1994). <p> kind of approach leads naturally to the EM algorithm, which will be discussed in Section 7.4. 7.4 The expectation maximization (EM) algorithm The expectation maximization algorithm, widely known as the EM algorithm, corresponds to a deterministic version of Gibbs sampling used to search for the MAP estimate for model parameters <ref> (Dempster et al., 1977) </ref>. It is generally considered to be faster than gradient descent. Convergence is slow near a local maxima so some implementations switch to conjugate gradient or other methods (Meilijson, 1989) when near a solution. <p> When the mode is used in Step 2 (b), ignoring numerical problems, the EM algorithm converges on a local maxima of the posterior distribution for the parameters <ref> (Dempster et al., 1977) </ref>. The general method is summarized in the following comment (Dempster et al., 1977). Comment 7.2 The conditions of Lemma 5.1 apply with data variables X inside the plate and model parameters outside. <p> When the mode is used in Step 2 (b), ignoring numerical problems, the EM algorithm converges on a local maxima of the posterior distribution for the parameters <ref> (Dempster et al., 1977) </ref>. The general method is summarized in the following comment (Dempster et al., 1977). Comment 7.2 The conditions of Lemma 5.1 apply with data variables X inside the plate and model parameters outside. In addition, some of the variables U X are latent, so they are unknown and unshaded.
Reference: <author> Duda, R., & Hart, P. </author> <year> (1973). </year> <title> Pattern Classification and Scene Analysis. </title> <address> New York: </address> <publisher> John Wiley. </publisher>
Reference: <author> Frydenberg, M. </author> <year> (1990). </year> <title> The chain graph Markov property. </title> <journal> Scandinavian Journal of Statistics, </journal> <volume> 17, </volume> <pages> 333-353. </pages>
Reference: <author> Geiger, D., & Heckerman, D. </author> <year> (1994). </year> <title> Learning Gaussian networks.. </title> <editor> In de Mantaras, R. L., & Poole, D. (Eds.)(1994). </editor> <booktitle> Uncertainty in Artificial Intelligence: Proceedings of the Tenth Conference, </booktitle> <address> Seattle, Washington, </address> <pages> pp. 235-243. </pages>
Reference-contexts: A similar situation exists with trees (Buntine, 1991b). The same results apply to any Bayesian network with exponential family distributions at each node, such as Gaussian or Poisson. Results for Gaussians are presented, for instance, in <ref> (Geiger & Heckerman, 1994) </ref>. This local search approach is a MAP approach because it searches for the network structure maximizing posterior probability. More accurate approximation can be done by generating a Markov chain of Bayesian networks from the search space of Bayesian networks.
Reference: <author> Geman, D. </author> <year> (1990). </year> <title> Random fields and inverse problems in imaging. </title> <editor> In Hennequin, P. (Ed.), Ecole d' Ete de Probabilites de Saint-Flour XVIII - 1988. </editor> <publisher> Springer-Verlag, </publisher> <address> Berlin. </address> <booktitle> In Lecture Notes in Mathematics, </booktitle> <volume> Volume 1427. </volume>
Reference: <author> Geman, S., & Geman, D. </author> <year> (1984). </year> <title> Stochastic relaxation, Gibbs distributions, and the Bayesian relation of images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6, </volume> <pages> 721-741. </pages>
Reference: <author> Gilks, W., Clayton, D., Spiegelhalter, D., Best, N., McNeil, A., Sharples, L., & Kirby, A. </author> <year> (1993a). </year> <title> Modelling complexity: applications of Gibbs sampling in medicine. </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> 55, </volume> <pages> 39-102. </pages>
Reference-contexts: For instance, the simple unsupervised learning problem represented in Figure 10 is a Bayesian network once the plate is expanded out. It follows that Gibbs sampling is readily applied to learning as a general inference algorithm <ref> (Gilks et al., 1993a, 1993b) </ref>. Consider a simplified example of this unsupervised learning problem. In this model, assume that each variable var 1 and var 2 belongs to a mixture of Gaussians of known variance equal to 1.0. This simple model is given in Figure 29.
Reference: <author> Gilks, W., Thomas, A., & Spiegelhalter, D. </author> <year> (1993b). </year> <title> A language and program for complex Bayesian modelling. </title> <journal> The Statistician, </journal> <volume> 43, </volume> <pages> 169-178. </pages>
Reference: <author> Gill, P. E., Murray, W., & Wright, M. H. </author> <year> (1981). </year> <title> Practical Optimization. </title> <address> San Diego: </address> <publisher> Academic Press. </publisher>
Reference-contexts: The literature is extensive. Gibbs sampling corresponds to a probabilistic version of gradient ascent, although their goals of averaging as opposed to maximizing are fundamentally different. Gradient ascent in real valued problems corresponds to simple methods from function optimization <ref> (Gill et al., 1981) </ref> and in discrete problems corresponds to local repair or local search (Johnson et al., 1985; Minton, Johnson, Philips, & Laird, 1990; Selman, Levesque, & Mitchell, 1992). Gibbs sampling varies gradient ascent by introducing a random component.
Reference: <editor> Griewank, A., & Corliss, G. F. (Eds.). </editor> <year> (1991). </year> <title> Automatic Differentiation of Algorithms: Theory, Implementation, and Application, </title> <address> Breckenridge, Colorado. </address> <publisher> SIAM. </publisher>
Reference: <author> Heckerman, D., Geiger, D., & Chickering, D. </author> <year> (1994). </year> <title> Learning Bayesian networks: The combination of knowledge and statistical data. </title> <type> Technical Report MSR-TR-94-09 (Revised), </type> <institution> Microsoft Research, Advanced Technology Division. </institution> <note> Submitted Machine Learning Journal. </note>
Reference-contexts: This graphical model then represents many different models, for all 2 4 possible instantiations of the arcs. Prior probabilities for these models could be generated using a scheme such as in (Buntine, 1991c, p54) or <ref> (Heckerman et al., 1994) </ref>, where a prior probability is assigned by 197 Buntine a domain expert for different parts of the model, arcs and parameters, and the prior for a full model found by multiplication. The family of models given by Figure 26 includes those of Figure 11 as instances. <p> A similar situation exists with trees (Buntine, 1991b). The same results apply to any Bayesian network with exponential family distributions at each node, such as Gaussian or Poisson. Results for Gaussians are presented, for instance, in <ref> (Geiger & Heckerman, 1994) </ref>. This local search approach is a MAP approach because it searches for the network structure maximizing posterior probability. More accurate approximation can be done by generating a Markov chain of Bayesian networks from the search space of Bayesian networks.
Reference: <author> Heckerman, D. </author> <year> (1991). </year> <title> Probabilistic Similarity Networks. </title> <publisher> MIT Press. </publisher>
Reference: <author> Henrion, M. </author> <year> (1990). </year> <title> Towards efficient inference in multiply connected belief networks. </title> <editor> In Oliver, R., & Smith, J. (Eds.), </editor> <title> Influence Diagrams, Belief Nets and Decision Analysis, </title> <journal> pp. </journal> <pages> 385-407. </pages> <publisher> Wiley. </publisher>
Reference: <author> Hertz, J., Krogh, A., & Palmer, R. </author> <year> (1991). </year> <title> Introduction to the Theory of Neural Computation. Addison-Wesley. </title> <type> 221 Buntine Howard, </type> <institution> R. </institution> <year> (1970). </year> <title> Decision analysis: perspectives on inference, decision, and experimentation. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 58 (5). </volume>
Reference-contexts: Indeed, this computation forms the core of the early Boltzmann machine algorithm <ref> (Hertz et al., 1991) </ref>. In general, this must be done using something like Gibbs sampling and the techniques of Section 7.1 can be applied directly. 6.2 Decomposing learning problems Learning problems can be decomposed into sub-problems in some cases. <p> posterior variance of the i + 1-th sample given the i-th sample would be small so that: i+1 E i ; 1;i ; 2;i ( i+1 ) : This approximation is used with Markov chain Monte Carlo methods by the mean field method from statistical physics, popular in neural networks <ref> (Hertz et al., 1991) </ref>.
Reference: <author> Hrycej, T. </author> <year> (1990). </year> <title> Gibbs sampling in Bayesian networks. </title> <journal> Artificial Intelligence, </journal> <volume> 46, </volume> <pages> 351-363. </pages>
Reference: <author> Jeffreys, H. </author> <year> (1961). </year> <title> Theory of Probability (third edition). </title> <publisher> Oxford: Clarendon Press. </publisher>
Reference: <author> Johnson, D., Papdimitriou, C., & Yannakakis, M. </author> <year> (1985). </year> <title> How easy is local search? In FOCS'85, </title> <journal> pp. </journal> <pages> 39-42. </pages>
Reference-contexts: Corollary 6.1.2 Equation (24) holds if the parent graph G is a Bayesian network with plates. In general, we might consider searching through a family of graphical models. To do this local search <ref> (Johnson, Papdimitriou, & Yannakakis, 1985) </ref> or numerical optimization can be used to find high posterior models, or Markov chain Monte Carlo methods to select a sample of representative models, as discussed in Section 7.2. To do this, how to represent a family of models must be shown.
Reference: <author> Kass, R., & Raftery, A. </author> <year> (1993). </year> <title> Bayes factors and model uncertainty. </title> <type> Technical Report #571, </type> <institution> Department of Statistics, Carnegie Mellon University, PA. </institution> <note> Submitted to Jnl. </note> <institution> of American Statistical Association. </institution>
Reference-contexts: For models in the exponential family, whose normalization constant is known in closed form, this turns out to be easy. If these exact computations are not available, various approximation methods can be used to compute the evidence or Bayes factors <ref> (Kass & Raftery, 1993) </ref>; some are discussed in Section 7.3. If the conjugate distribution for an exponential family model and its derivatives can be readily computed, then the Bayes factor for the model can be found in closed form.
Reference: <author> Kjruff, U. </author> <year> (1992). </year> <title> A computational scheme for reasoning in dynamic probabilistic networks.. </title> <editor> In Dubois, D., Wellman, M., D'Ambrosio, B., & Smets, P. (Eds.), </editor> <booktitle> (1992). Uncertainty in Artificial Intelligence: Proceedings of the Eight Conference, </booktitle> <address> Stanford, California, </address> <pages> pp. 121-129. </pages>
Reference: <author> Kohavi, R. </author> <year> (1994). </year> <title> Bottom-up induction of oblivious, read-once decision graphs : Strengths and limitations.. </title> <booktitle> In Twelfth National Conference on Artificial Intelligence. </booktitle>
Reference: <author> Lange, K., & Sinsheimer, J. </author> <year> (1993). </year> <title> Normal/independent distributions and their applications in robust regression. </title> <journal> Journal of Computational and Graphical Statistics, </journal> <volume> 2 (2). </volume>
Reference-contexts: By introducing a convolution, these robust regression models can be handled by combining the EM algorithm with standard least squares <ref> (Lange & Sinsheimer, 1993) </ref>. 8.2 Feed-forward networks with a linear output layer A similar example is the standard feed-forward network where the final output layer is linear.
Reference: <author> Langley, P., Iba, W., & Thompson, K. </author> <year> (1992). </year> <title> An analysis of Bayesian classifiers.. </title> <booktitle> In Tenth National Conference on Artificial Intelligence, </booktitle> <address> San Jose, California, </address> <pages> pp. 223-228. </pages>
Reference: <author> Lauritzen, S., Dawid, A., Larsen, B., & Leimer, H.-G. </author> <year> (1990). </year> <title> Independence properties of directed Markov fields. </title> <journal> Networks, </journal> <volume> 20, </volume> <pages> 491-505. </pages>
Reference: <author> Little, R., & Rubin, D. </author> <year> (1987). </year> <title> Statistical Analysis with Missing Data. </title> <address> New York: </address> <publisher> John Wiley and Sons. </publisher>
Reference: <author> Loredo, T. </author> <year> (1992). </year> <title> The promise of Bayesian inference for astrophysics. </title> <editor> In Feigelson, E., & Babu, G. (Eds.), </editor> <title> Statistical Challenges in Modern Astronomy. </title> <publisher> Springer-Verlag. </publisher>
Reference: <author> MacKay, D. </author> <year> (1992). </year> <title> A practical Bayesian framework for backprop networks. </title> <journal> Neural Computation, </journal> <volume> 4, </volume> <pages> 448-472. </pages>
Reference: <author> MacKay, D. </author> <year> (1993). </year> <title> Bayesian non-linear modeling for the energy prediction competition. </title> <type> Report Draft 1.2, </type> <institution> Cavendish Laboratory, University of Cambridge. </institution>
Reference: <author> Madigan, D., & Raftery, A. </author> <year> (1994). </year> <title> Model selection and accounting for model uncertainty in graphical models using Occam's window. </title> <journal> Journal of the American Statistical Association. </journal> <note> To appear. </note>
Reference: <author> McCullagh, P., & Nelder, J. </author> <year> (1989). </year> <title> Generalized Linear Models (second edition). Chapman and Hall, London. 222 Learning with Graphical Models McLachlan, </title> <editor> G. J., & Basford, K. E. </editor> <year> (1988). </year> <title> Mixture Models: Inference and Applications to Clustering. </title> <address> New York: </address> <publisher> Marcel Dekker. </publisher>
Reference-contexts: with respect to is invertible, det d 6= 0), then various moments of the distribution can be easily found: E xjy; (t (x; y)) = dw () 1 dZ () : (28) The vector function w () now has an inverse and it is referred to as the link function <ref> (McCullagh & Nelder, 1989) </ref>.
Reference: <author> Meilijson, I. </author> <year> (1989). </year> <title> A fast improvement to the EM algorithm on its own terms. </title> <journal> J. Roy. Statist. Soc. B, </journal> <volume> 51 (1), </volume> <pages> 127-138. </pages>
Reference-contexts: It is generally considered to be faster than gradient descent. Convergence is slow near a local maxima so some implementations switch to conjugate gradient or other methods <ref> (Meilijson, 1989) </ref> when near a solution. The computation used to find the derivative is similar to the computation used for the EM algorithm, so this does not require a great deal of additional code. Also, the determinism means the EM algorithm no longer generates unbiased posterior estimates of model parameters.
Reference: <author> Minton, S., Johnson, M., Philips, A., & Laird, P. </author> <year> (1990). </year> <title> Solving large-scale constraint-satisfaction and scheduling problems using a heuristic repair method. </title> <booktitle> In Eighth National Conference on Artificial Intelligence, </booktitle> <address> Boston, Massachusetts, </address> <pages> pp. 17-24. </pages>
Reference: <author> Neal, R. </author> <year> (1993). </year> <title> Probabilistic inference using Markov chain Monte Carlo methods. </title> <type> Technical Report CRG-TR-93-1, </type> <institution> Dept. of Computer Science, University of Toronto. </institution>
Reference: <author> Nowlan, S., & Hinton, G. </author> <year> (1992). </year> <title> Simplifying neural networks by soft weight sharing. </title> <editor> In Touretzky, D. (Ed.), </editor> <booktitle> Advances in Neural Information Processing Systems 4 (NIPS*91). </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Oliver, J. </author> <year> (1993). </year> <title> Decision graphs an extension of decision trees. </title> <booktitle> In Proceedings of the Fourth International Workshop on Artificial Intelligence and Statistics, </booktitle> <pages> pp. 343-350. </pages> <note> Extended version available as TR 173, </note> <institution> Department of Computer Science, Monash University, Australia. </institution>
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Only include conditional distributions for variables that have x as a parent. Thus, the formula only involves examining the parents, children and children's parents of x, the so-called Markov blanket <ref> (Pearl, 1988) </ref>. Also, notice normalization is only required over the single dimension changed in the current cycle, done in the denominator. For x discrete, these conditional probabilities can be enumerated and direct sampling done for x.
Reference: <author> Poland, W. </author> <year> (1994). </year> <title> Decision Analysis with Continuous and Discrete Variables: A Mixture Distribution Approach. </title> <type> Ph.D. thesis, </type> <institution> Department of Engineering Economic Systems, Stanford University, Stanford, California. </institution>
Reference: <author> Press, S. </author> <year> (1989). </year> <title> Bayesian Statistics. </title> <address> New York: </address> <publisher> Wiley. </publisher>
Reference: <author> Quinlan, J. </author> <year> (1989). </year> <title> Unknown attribute values in induction. </title> <editor> In Segre, A. (Ed.), </editor> <booktitle> Proceedings of the Sixth International Machine Learning Workshop Cornell, </booktitle> <address> New York. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This problem is handled by symmetry breaking: force 1;c &lt; 2;c . Gibbs sampling applies whenever there are variables associated with the data that are not given. Hidden or latent variables are an example. Incomplete data (or missing values) <ref> (Quinlan, 1989) </ref>, robust methods and modeling of outliers, and various density estimation and non-parametric methods all fall in this family of models (Titterington et al., 1985).
Reference: <author> Quinlan, J. </author> <year> (1992). </year> <title> C4.5: Programs for Machine Learning. </title> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Ripley, B. </author> <year> (1981). </year> <title> Spatial Statistics. </title> <address> New York: </address> <publisher> Wiley. </publisher>
Reference: <author> Ripley, B. </author> <year> (1987). </year> <title> Stochastic Simulation. </title> <publisher> John Wiley & Sons. </publisher>
Reference-contexts: In Gibbs sampling, all the conditional sampling is done in accordance with the original distribution, and since this is a stationary process, in the long run the samples converge to the stationary distribution or fixed-point of the process. Methods for making subsequent samples independent are known as regenerative simulation <ref> (Ripley, 1987) </ref> and correspond to sending the temperature back to zero occasionally. With this sample different quantities such as the probability a patient will have Age &gt; 20 and Clim = tropical given Symp can be estimated. <p> Because the Bayes factors are readily computed in this case, Gibbs sampling or Markov chain Monte Carlo schemes can be used. The scheme given below is the Metropolis algorithm <ref> (Ripley, 1987) </ref>. This only looks at single neighbors until a successor is found. This is done be repeating the following steps: 1. For the initial Bayesian network G, randomly select a neighboring Bayesian network G 0 differing only by an arc. 211 Buntine 2.
Reference: <author> Rivest, R. </author> <year> (1987). </year> <title> Learning decision lists. </title> <journal> Machine Learning, </journal> <volume> 2 (3), </volume> <pages> 229-246. </pages>
Reference: <author> Russell, S., Binder, J., & Koller, D. </author> <year> (1994). </year> <title> Adaptive probabilistic networks. </title> <type> Technical Report CSD-94-824, </type> <month> July </month> <year> 1994, </year> <institution> University of California, Berkeley. </institution>
Reference: <author> Selman, B., Levesque, H., & Mitchell, D. </author> <year> (1992). </year> <title> A new method for solving hard satisfi-ability problems.. </title> <booktitle> In Tenth National Conference on Artificial Intelligence, </booktitle> <address> San Jose, California, </address> <pages> pp. 440-446. </pages>
Reference: <author> Shachter, R. </author> <year> (1986). </year> <title> Evaluating influence diagrams. </title> <journal> Operations Research, </journal> <volume> 34 (6), </volume> <pages> 871-882. </pages> <note> 223 Buntine Shachter, </note> <author> R. </author> <year> (1990). </year> <title> An ordered examination of influence diagrams. </title> <journal> Networks, </journal> <volume> 20, </volume> <pages> 535-563. </pages>
Reference: <author> Shachter, R., Andersen, S., & Szolovits, P. </author> <year> (1994). </year> <title> Global conditioning for probabilistic inference in belief networks.. </title> <editor> In de Mantaras, R. L., & Poole, D. (Eds.)(1994). </editor> <booktitle> Uncertainty in Artificial Intelligence: Proceedings of the Tenth Conference, </booktitle> <address> Seattle, Washington, </address> <pages> pp. 514-522. </pages>
Reference: <author> Shachter, R., & Heckerman, D. </author> <year> (1987). </year> <title> Thinking backwards for knowledge acquisition. </title> <journal> AI Magazine, </journal> <volume> 8 (Fall), </volume> <pages> 55-61. </pages>
Reference: <author> Shachter, R., & Kenley, C. </author> <year> (1989). </year> <title> Gaussian influence diagrams. </title> <journal> Management Science, </journal> <volume> 35 (5), </volume> <pages> 527-550. </pages>
Reference: <author> Smith, A., & Spiegelhalter, D. </author> <year> (1980). </year> <title> Bayes factors and choice criteria for linear models. </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> 42 (2), </volume> <pages> 213-220. </pages>
Reference: <author> Spiegelhalter, D. </author> <year> (1993). </year> <type> Personal communication. </type>
Reference: <author> Spiegelhalter, D., Dawid, A., Lauritzen, S., & Cowell, R. </author> <year> (1993). </year> <title> Bayesian analysis in expert systems. </title> <journal> Statistical Science, </journal> <volume> 8 (3), </volume> <pages> 219-283. </pages>
Reference: <author> Spiegelhalter, D., & Lauritzen, S. </author> <year> (1990). </year> <title> Sequential updating of conditional probabilities on directed graphical structures. </title> <journal> Networks, </journal> <volume> 20, </volume> <pages> 579-605. </pages>
Reference: <author> Srinivas, S., & Breese, J. </author> <year> (1990). </year> <title> IDEAL: A software package for analysis of influence diagrams. </title> <editor> In Bonissone, P. (Ed.), </editor> <booktitle> Proceedings of the Sixth Conference on Uncertainty in Artificial Intelligence Cambridge, </booktitle> <address> Massachusetts. </address>
Reference: <author> Stewart, L. </author> <year> (1987). </year> <title> Hierarchical Bayesian analysis using Monte Carlo integration: computing posterior distributions when there are many possible models. </title> <journal> The Statistician, </journal> <volume> 36, </volume> <pages> 211-219. </pages>
Reference: <author> Tanner, M. </author> <year> (1993). </year> <title> Tools for Statistical Inference (Second edition). </title> <publisher> Springer-Verlag. </publisher>
Reference: <author> Thomas, A., Spiegelhalter, D., & Gilks, W. </author> <year> (1992). </year> <title> BUGS: A program to perform Bayesian inference using Gibbs sampling. </title> <editor> Bernardo, In Bernardo, J., Berger, J., Dawid, A., & Smith, A. (Eds.). </editor> <year> (1992). </year> <title> Bayesian Statistics 4. </title> <publisher> Oxford University Press, </publisher> <pages> pp. 837-42. </pages>
Reference: <author> Tierney, L., & Kadane, J. </author> <year> (1986). </year> <title> Accurate approximations for posterior moments and marginal densities. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 81 (393), </volume> <pages> 82-86. </pages>
Reference: <author> Titterington, D., Smith, A., & Makov, U. </author> <year> (1985). </year> <title> Statistical Analysis of Finite Mixture Distributions. </title> <address> Chichester: </address> <publisher> John Wiley & Sons. </publisher> <editor> van Laarhoven, P., & Aarts, E. </editor> <year> (1987). </year> <title> Simulated Annealing: </title> <journal> Theory and Applications. </journal>
Reference-contexts: Gibbs sampling applies whenever there are variables associated with the data that are not given. Hidden or latent variables are an example. Incomplete data (or missing values) (Quinlan, 1989), robust methods and modeling of outliers, and various density estimation and non-parametric methods all fall in this family of models <ref> (Titterington et al., 1985) </ref>.
Reference: <editor> Dordrecht: D. </editor> <publisher> Reidel. </publisher>
Reference: <author> Vuong, T. </author> <year> (1989). </year> <title> Likelihood ratio tests for model selection and non-nested hypotheses. </title> <journal> Econometrica, </journal> <volume> 36, </volume> <month> 307-333. </month> <title> 224 Learning with Graphical Models Werbos, </title> <editor> P. J., McAvoy, T., & Su, T. </editor> <year> (1992). </year> <title> Neural networks, system identification, and control in the chemical process industry. In White, </title> <editor> D. A., & Sofge, D. A. (Eds.), </editor> <booktitle> Handbook of Intelligent Control, </booktitle> <pages> pp. 283-356. </pages> <publisher> Van Nostrand Reinhold. </publisher>
Reference: <author> Wermuth, N., & Lauritzen, S. </author> <year> (1989). </year> <title> On substantive research hypotheses, conditional independence graphs and graphical chain models. </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> 51 (3). </volume>
Reference: <author> Whittaker, J. </author> <year> (1990). </year> <title> Graphical Models in Applied Multivariate Statistics. </title> <publisher> Wiley. </publisher>
Reference: <author> Wolpert, D. </author> <year> (1994). </year> <title> Bayesian backpropagation over functions rather than weights. </title> <editor> In Tesauro, G. (Ed.), </editor> <booktitle> Advances in Neural Information Processing Systems 6 (NIPS*93). </booktitle> <publisher> Morgan Kaufmann. </publisher> <pages> 225 </pages>
References-found: 93

