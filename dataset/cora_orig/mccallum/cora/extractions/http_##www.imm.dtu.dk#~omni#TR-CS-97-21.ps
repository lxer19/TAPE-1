URL: http://www.imm.dtu.dk/~omni/TR-CS-97-21.ps
Refering-URL: http://www.mathsoft.com/wavelets.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: TR-CS-97-21 A Scalable Parallel 2D Wavelet Transform Algorithm  
Author: Ole Mller Nielsen and Markus Hegland 
Date: December 1997  
Abstract: Joint Computer Science Technical Report Series Department of Computer Science Faculty of Engineering and Information Technology Computer Sciences Laboratory Research School of Information Sciences and Engineering 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Beylkin, R. Coifman, and V. Rohklin. </author> <title> Wavelets in numerical analysis. </title> <editor> In Mary Beth Ruskai et al., editors, </editor> <booktitle> Wavelets and their applications, </booktitle> <pages> pages 181-210. </pages> <publisher> Jones and Bartlett, </publisher> <year> 1992. </year>
Reference-contexts: 1 Introduction Wavelets have generated a tremendous interest in both theoretical and applied mathematics over the past few years, and the wavelet transform in particular has proven to be an effective tool for e.g. numerical analysis <ref> [1] </ref> and image processing [2]. Problems from these areas are typically large and the wavelet transforms can be very time-consuming although the algorithmic complexity is proportional to the problem size. The use of parallel computers is one way of speeding up the wavelet transforms.
Reference: [2] <author> Charles K. Chui. </author> <title> Wavelets: A Mathematical Tool for Signal Analysis. </title> <booktitle> SIAM Monographs on Mathematical Modeling and Computation. </booktitle> <publisher> SIAM, </publisher> <year> 1997. </year>
Reference-contexts: 1 Introduction Wavelets have generated a tremendous interest in both theoretical and applied mathematics over the past few years, and the wavelet transform in particular has proven to be an effective tool for e.g. numerical analysis [1] and image processing <ref> [2] </ref>. Problems from these areas are typically large and the wavelet transforms can be very time-consuming although the algorithmic complexity is proportional to the problem size. The use of parallel computers is one way of speeding up the wavelet transforms.
Reference: [3] <author> Ingrid Daubechies. </author> <title> Ten Lectures on Wavelets. </title> <publisher> SIAM, </publisher> <year> 1992. </year>
Reference-contexts: The FWT is used to obtain the coefficients used in the wavelet expansions mentioned above. Because many of these are often small enough to be disregarded without introducing a large error, the FWT forms the basis of efficient data compression algorithms. See <ref> [13, 3, 10] </ref> for good expositions of wavelet analysis. Let N = 2 J and c J be a given vector with elements fc J n g n=0;1;:::;N1 .
Reference: [4] <author> B. K. Das, R. N. Mahapatra, and B. N. Chatterli. </author> <title> Modelling of wavelet transform on multistage interconnection network. </title> <booktitle> In Proceedings of the Australasian Conference on Parallel and Real-Time Systems, </booktitle> <pages> pages 134-142, </pages> <address> Freemantle, Western Australia, </address> <month> 28-29 September </month> <year> 1995. </year>
Reference-contexts: In <ref> [4] </ref> the communication pattern of a MIMD parallel wavelet transform algorithm is analyzed and it is shown that the asymmetry in the standard formulation of the wavelet transform leads to poor speedup. 1 We base our approach on the MIMD philosophy and the architectures we have in mind are distributed memory <p> In subsequent steps 3 this communication will take place among the active processors only. This kind of layout was used in <ref> [4] </ref> where it was observed that optimal load balancing could not be achieved and also in [9] where the global communication was treated by organizing the processors of a connection machine (CM-2) in a pyramid structure.
Reference: [5] <author> Markus Hegland. </author> <title> Real and Complex Fast Fourier Transforms on the Fujitsu VPP500. </title> <journal> Parallel Computing, </journal> <volume> 22, </volume> <pages> pp. 539-553, </pages> <year> 1996. </year> <month> 13 </month>
Reference-contexts: We therefore rewrite the matrix product (19) as Y T = XW T T M yielding efficient memory access on each processor at the cost of one transpose step. This algorithm can be implemented on a parallel computer similar to parallel 2D FFTs <ref> [5] </ref>.
Reference: [6] <author> Mats Holmstrom. </author> <title> Parallelizing the fast wavelet transform. </title> <journal> Parallel Computing, </journal> <volume> 11(21) </volume> <pages> 1837-1848, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: It is normally not feasible to adapt SIMD algorithms to MIMD architectures because they are typically dependent on the data parallel architecture for which they were written: In <ref> [6] </ref>, for example, the proposed algorithm is dependent on the ability to shift arrays fast in power-of-two steps, and in [9] the algorithm relies on a particular processor topology to be efficient.
Reference: [7] <author> Robert Lang and Andrew Spray. </author> <title> The 2d wavelet transform on a massively parallel machine. </title> <booktitle> In Proceedings of the Australasian Conference on Parallel and Real-Time Systems, </booktitle> <pages> pages 325-332, </pages> <address> Freemantle, Western Australia, </address> <month> 28-29 September </month> <year> 1995. </year>
Reference-contexts: This is a problem for vector architectures such as the Fujitsu VPP300 as mentioned in section 2.3. A similar approach was adopted in <ref> [7] </ref> where a 2D FWT was implemented on the MasPar a data parallel computer with 2048 processors. It was noted that "the transpose operations dominate the computation time" and a speedup of no more than 6 times relative to the best sequential program was achieved.
Reference: [8] <author> A. Lega, H. Scholl, J.-M. Alimi, A. Bijaoui, and P. Bury. </author> <title> A parallel algorithm for structure detection based on wavelet and segmentation analysis. </title> <journal> Parallel Computing, </journal> <volume> 21 </volume> <pages> 265-285, </pages> <month> April </month> <year> 1995. </year>
Reference: [9] <author> Jian Lu. </author> <title> Parallelizing mallat algorithm for 2-d wavelet transforms. </title> <journal> Information Processing Letters, </journal> <volume> 45 </volume> <pages> 255-259, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: It is normally not feasible to adapt SIMD algorithms to MIMD architectures because they are typically dependent on the data parallel architecture for which they were written: In [6], for example, the proposed algorithm is dependent on the ability to shift arrays fast in power-of-two steps, and in <ref> [9] </ref> the algorithm relies on a particular processor topology to be efficient. <p> In subsequent steps 3 this communication will take place among the active processors only. This kind of layout was used in [4] where it was observed that optimal load balancing could not be achieved and also in <ref> [9] </ref> where the global communication was treated by organizing the processors of a connection machine (CM-2) in a pyramid structure. However, we can obtain perfect load balancing and avoid global communication by introducing another ordering of the resulting and intermediate vectors.
Reference: [10] <author> Yves Meyer. </author> <title> Wavelets: Algorithms and Applications. </title> <publisher> SIAM, </publisher> <year> 1993. </year>
Reference-contexts: The FWT is used to obtain the coefficients used in the wavelet expansions mentioned above. Because many of these are often small enough to be disregarded without introducing a large error, the FWT forms the basis of efficient data compression algorithms. See <ref> [13, 3, 10] </ref> for good expositions of wavelet analysis. Let N = 2 J and c J be a given vector with elements fc J n g n=0;1;:::;N1 .
Reference: [11] <author> Ole Mtller Nielsen and Markus Hegland. </author> <title> A Two-Dimensional Fast Wavelet Transform for the Fu-jitsu VP2200. </title> <note> In preparation </note>
Reference-contexts: This is not the case for the expression W M X, because it consists of a collection of columnwise 1D transforms which do not access the memory as efficiently <ref> [11] </ref>. We therefore rewrite the matrix product (19) as Y T = XW T T M yielding efficient memory access on each processor at the cost of one transpose step. This algorithm can be implemented on a parallel computer similar to parallel 2D FFTs [5].
Reference: [12] <author> Ole Mtller Nielsen, Gavin Mercer, and Markus Hegland. </author> <title> Vector-parallel fast wavelet transforms. </title> <booktitle> In PCW97 Parallel Computing Workshop 1997, </booktitle> <institution> Australian National University, Canberra, ACT, </institution> <month> 25-26 September </month> <year> 1997. </year>
Reference: [13] <author> Gilbert Strang and Truong Nguyen. </author> <title> Wavelets and Filter Banks. </title> <publisher> Wellesley-Cambridge Press, </publisher> <year> 1996. </year> <month> 14 </month>
Reference-contexts: The FWT is used to obtain the coefficients used in the wavelet expansions mentioned above. Because many of these are often small enough to be disregarded without introducing a large error, the FWT forms the basis of efficient data compression algorithms. See <ref> [13, 3, 10] </ref> for good expositions of wavelet analysis. Let N = 2 J and c J be a given vector with elements fc J n g n=0;1;:::;N1 .
References-found: 13

