URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/douglas-craig/Preprints/cache4.ps.gz
Refering-URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/douglas-craig/ccd-preprints.html
Root-URL: http://www.cs.yale.edu
Title: MINIMIZING MEMORY CACHE USAGE FOR MULTIGRID ALGORITHMS IN TWO DIMENSIONS new algorithm is up to
Author: CRAIG C. DOUGLAS 
Keyword: Key words. multigrid, cache, threads, sparse matrix, iterative methods, domain decomposition, compiler optimization.  
Note: Numerical experiments are provided that show that the  choices.  AMS subject classifications. 65N15, 65N10  
Abstract: Computers today rely heavily on good utilization of their cache memory subsystems. Compilers are optimized for business applications, not scientific computing ones, however. Automatic tiling of basic numerical algorithms is simply not provided by any compiler. Thus, absolutely terrible cache performance is normal for scientific computing applications. Multigrid algorithms combine several numerical algorithms into a more complicated algorithm. In this paper, an algorithm is derived that allows for data to pass through cache exactly once per multigrid level during a V cycle before the level changes. This is optimal cache usage for large problems that do not fit entirely in cache. The new algorithm would appear to be quite complicated to implement, leading to spaghetti coding. Actually, an efficient implementation of the algorithm requires a rigid, highly structured coding style. A coding example is given that is suitable for almost all common discretization methods. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. E. Bank and C. C. Douglas, </author> <title> Sharp estimates for multigrid rates of convergence with general smoothing and acceleration, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 22 (1985), </volume> <pages> pp. 617-633. </pages>
Reference-contexts: Hence, level 1 is the real problem; all other levels are approximations to this. The linear systems result from discretizing a partial differential equation over a given grid i . The discretization can be any standard finite element, difference, volume, or wavelet approach (see <ref> [1] </ref> and [2] for examples of this approach). In this paper, A i is assumed to be a sparse matrix. Further, the discrete grids i will be assumed to be structured and regular.
Reference: [2] <author> C. C. Douglas, </author> <title> Multi-grid algorithms with applications to elliptic boundary-value problems, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 21 (1984), </volume> <pages> pp. </pages> <month> 236-254. </month> <title> [3] , Caching in with multigrid algorithms: problems in two dimensions, </title> <journal> Paral. Alg. Appl., </journal> <volume> 9 (1996), </volume> <pages> pp. 195-204. </pages>
Reference-contexts: Hence, level 1 is the real problem; all other levels are approximations to this. The linear systems result from discretizing a partial differential equation over a given grid i . The discretization can be any standard finite element, difference, volume, or wavelet approach (see [1] and <ref> [2] </ref> for examples of this approach). In this paper, A i is assumed to be a sparse matrix. Further, the discrete grids i will be assumed to be structured and regular.
Reference: [4] <author> C. C. Douglas and J. Douglas, </author> <title> A unified convergence theory for abstract multigrid or multilevel algorithms, serial and parallel, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 30 (1993), </volume> <pages> pp. 136-158. </pages>
Reference-contexts: At first glance, the methodology in this paper seems unable to deal effectively with Krylov space roughers (see <ref> [4] </ref> and [5]). A standard set of preconditioners for Krylov space methods is based on doing a relaxation sweep inside the Krylov space algorithm. An alternate is a block Krylov space preconditioner for a relaxation method. The computational subdomains (`) ij can certainly be chosen to utilize a block solver.
Reference: [5] <author> C. C. Douglas, J. Douglas, and D. E. Fyfe, </author> <title> A multigrid unified theory for non-nested grids and/or quadrature, </title> <editor> E. W. J. </editor> <publisher> Numer. Math., </publisher> <month> 2 </month> <year> (1994), </year> <pages> pp. 285-294. </pages>
Reference-contexts: At first glance, the methodology in this paper seems unable to deal effectively with Krylov space roughers (see [4] and <ref> [5] </ref>). A standard set of preconditioners for Krylov space methods is based on doing a relaxation sweep inside the Krylov space algorithm. An alternate is a block Krylov space preconditioner for a relaxation method. The computational subdomains (`) ij can certainly be chosen to utilize a block solver.
Reference: [6] <author> S. F. McCormick, </author> <title> Multigrid methods for variational problems: general theory for the V-cycle, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 22 (1985), </volume> <pages> pp. 634-643. </pages>
Reference-contexts: Approximately solve A i u i = f i . 2b. If i &gt; 1, then set u i1 u i1 + P i u i . 2c. End Do Fig. 5. V cycle definition These are referred to by McCormick <ref> [6] </ref> as slash cycles. While both steps may have an approximate solve step included, the change of level step at the end of each has quite different cache effects. There are 3 major operations in the V cycle: 1. Approximate solves: steps 1a and 2a.
Reference: [7] <author> J. Philbin, J. Edler, O. J. Anshus, C. C. Douglas, and K. Li, </author> <title> Thread scheduling for cache locality, </title> <booktitle> in Proceedings of the Seventh ACM Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Cambridge, MA, 1996, </address> <publisher> ACM, </publisher> <pages> pp. 60-73. 18 </pages>
Reference-contexts: Five point discretization, point relaxation large of subdomains as possible each iteration of the relaxation algorithm. The last iteration of the relaxation algorithm must be treated differently due to the projection or interpolation steps that must be done. As is noted in <ref> [7] </ref>, only 50-60% of the cache is actually available for use by a given program. This is a side effect of multitasking operating systems. Determining the sizes of the (`) ij 's per iteration ` can be done as a preprocessing step and is inexpensive. <p> The computational subdomains (`) ij can certainly be chosen to utilize a block solver. Unstructured grids would appear at first to be nearly unworkable with the algorithms developed in xx2-3. Using the light weight threads package developed in <ref> [7] </ref> with some modifications, this class of problems might be conquered. The light weight threads package requires only data address hints. It automatically chooses a cache aware tiling for a decomposed set of computations. An inexpensive method (hashing) determines the cache blocks.
References-found: 6

