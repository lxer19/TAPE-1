URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/fgcozman/www/Research/TruncatedGaussians/bounded.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/fgcozman/www/Publications/publications.html
Root-URL: 
Title: Truncated Gaussians as Tolerance Sets  
Author: Fabio Cozman Eric Krotkov CMU-RI-TR - 
Note: c fl1994 Carnegie Mellon University This research is supported in part by NASA under Grant NAGW-1175. Fabio Cozman is supported under a scholarship from CNPq, Brazil.  
Date: June 23, 1997  
Address: Pittsburgh, PA 15213  
Affiliation: The Robotics Institute Carnegie Mellon University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Y. Bar-Shalom and T. E. Fortmann, </author> <title> Tracking and Data Association, </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1988. </year>
Reference-contexts: To date, few statistical models for bounded variables are available, none of them satisfactory. The most common approach is to use the Gaussian distribution and model bounds through an ad hoc selection mechanism <ref> [2, 1] </ref>. Another possibility is the uniform distribution [8], but this approach has computational problems: summation of uniform variables does not yield a uniform variable and application of Bayes rule is hard [11]. In short: even though bounds contain a lot of information, they have not received proper attention yet. <p> Consider an n-dimensional source of (unbounded) Gaussian noise and an ellipsoid in this n-dimensional space. If any measurement outside the ellipsoid is discarded, then the resulting data obeys a truncated Gaussian. Examples of these procedures are the algorithms of Cox [2] and Bar-Shalom/Fortmann <ref> [1] </ref>. These algorithms use the Gaussian distribution associated with ad hoc selection mechanisms; none of these algorithms uses appropriate models for bounded data. This approach to bounded data is employed in Statistics in order to model selection mechanisms [9]. <p> If we multiply these distributions together, the result is positive only on the set A " B; on this set the result is proportional to: 1 (x x ) T P 1 z (z Hx) : By using the Matrix Inversion Lemma <ref> [1] </ref>, we get the following standard result of linear systems theory: W / exp 2 where Q = P x P x H T (HP x H T + P z ) 1 HP x and 0 = Q (P 1 x x + P 1 z H T z). <p> ) T P 1 o 1 Using the following standard result: (x a) T A (x a) + (x b) T B (x b) = (x c) T C (x c) where C = A + B and c = C 1 (Aa + Bb), and the Matrix Inversion Lemma <ref> [1] </ref>. 10 where: P 1 i + aq i+1 B T P i B T 1 + aq i+1 B i P i B T (8) i i + aq i+1 B T (y i+1 B i i ) 2 i * We must determine q i+1 by some convention. <p> As a comparison, we analyze what would have happened if we had used an approximation strategy in the spirit of <ref> [1] </ref> or [2]. We would pretend x and ! to be distributed as unbounded Gaussians (with same mean and variance).
Reference: [2] <author> I. J. Cox, </author> <title> A Review of Statistical Data Association Techniques for Motion Correspondence, </title> <journal> International Journal of Computer Vision, </journal> <volume> 10(1): </volume> <pages> 53-66, </pages> <year> 1993. </year>
Reference-contexts: To date, few statistical models for bounded variables are available, none of them satisfactory. The most common approach is to use the Gaussian distribution and model bounds through an ad hoc selection mechanism <ref> [2, 1] </ref>. Another possibility is the uniform distribution [8], but this approach has computational problems: summation of uniform variables does not yield a uniform variable and application of Bayes rule is hard [11]. In short: even though bounds contain a lot of information, they have not received proper attention yet. <p> Consider an n-dimensional source of (unbounded) Gaussian noise and an ellipsoid in this n-dimensional space. If any measurement outside the ellipsoid is discarded, then the resulting data obeys a truncated Gaussian. Examples of these procedures are the algorithms of Cox <ref> [2] </ref> and Bar-Shalom/Fortmann [1]. These algorithms use the Gaussian distribution associated with ad hoc selection mechanisms; none of these algorithms uses appropriate models for bounded data. This approach to bounded data is employed in Statistics in order to model selection mechanisms [9]. <p> As a comparison, we analyze what would have happened if we had used an approximation strategy in the spirit of [1] or <ref> [2] </ref>. We would pretend x and ! to be distributed as unbounded Gaussians (with same mean and variance).
Reference: [3] <author> H. Cramer, </author> <title> Mathematical Methods of Statistics, </title> <publisher> Princeton University Press, </publisher> <year> 1946. </year>
Reference-contexts: All ellipsis fail to cover the region where x is known to lie. Radius 1/4 is extreme: almost all values of x inferred from this posterior are inconsistent with prior expectations! 12 13 Example 3 Consider the situation: z = 1 0 # z = <ref> [3; 7] </ref> T and x is unknown. the measurement is inconsistent, indicating either the presence of outliers or mismodeling. Incorporation of z 1 yields the hatched ellipse in the figure; y 1 is consistent.
Reference: [4] <author> M. </author> <title> DeGroot, Optimal Statistical Decisions, </title> <publisher> McGraw-Hill Inc., </publisher> <year> 1970. </year>
Reference-contexts: The optimal estimate is the conditional mean ^x = E [xjz] <ref> [4] </ref>. Since we have the posterior, we can evaluate the mean by the methods previously presented. 4 Filtering with the Truncated Gaussian Using all results so far presented, we can derive a filtering scheme akin to the Kalman filter but using truncated Gaussians.
Reference: [5] <author> M. Erdmann, </author> <title> Randomization in Robot Tasks, </title> <journal> International Journal of Robotics Research, </journal> <volume> 11(5) </volume> <pages> 399-436, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: The truncated Gaussian model has been proposed in a variety of contexts in Statistics [9] as models of selection mechanisms. In Robotics, the first explicit mention of the possibility of using the truncated Gaussian appears to be by Erdmann <ref> [5] </ref>.
Reference: [6] <author> O. Faugeras, </author> <title> Three-Dimensional Computer Vision: a Geometric Viewpoint, </title> <publisher> The MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: The question is: how much of the epipolar line should we explore in order to find the correspondence x 1 ? From the basic optics of the problem we can derive the following equation <ref> [6] </ref>: x 1 = x 2 + z where x 2 is the known coordinate of the correspondence (in pixels), B is the baseline distance (in meters), f is the focal length (in pixels) and z is the depth of the feature (in meters).
Reference: [7] <author> E. Fogel and Y. F. Huang, </author> <title> On the Value of Information in System Identification Bounded Noise Case, </title> <journal> Automatica, </journal> <volume> 18(2) </volume> <pages> 229-238, </pages> <year> 1982. </year>
Reference-contexts: This is presented in the next section. 3.1 Intersecting Ellipsoids In order to approximate the posterior, an ellipsoidal approximation can be built so that the approximate posterior is always a truncated Gaussian. This method was originally proposed by Fogel and Huang <ref> [7] </ref> in the context of tolerance sets for ARMA processes. Since the algorithm approximates only the geometric intersection of ellipsoids, the values of and P do not matter. <p> All ellipsis fail to cover the region where x is known to lie. Radius 1/4 is extreme: almost all values of x inferred from this posterior are inconsistent with prior expectations! 12 13 Example 3 Consider the situation: z = 1 0 # z = <ref> [3; 7] </ref> T and x is unknown. the measurement is inconsistent, indicating either the presence of outliers or mismodeling. Incorporation of z 1 yields the hatched ellipse in the figure; y 1 is consistent.
Reference: [8] <author> W. E. L. </author> <title> Grimson, Object Recognition by Computer: the Role of Geometric Constraints, </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: To date, few statistical models for bounded variables are available, none of them satisfactory. The most common approach is to use the Gaussian distribution and model bounds through an ad hoc selection mechanism [2, 1]. Another possibility is the uniform distribution <ref> [8] </ref>, but this approach has computational problems: summation of uniform variables does not yield a uniform variable and application of Bayes rule is hard [11]. In short: even though bounds contain a lot of information, they have not received proper attention yet.
Reference: [9] <author> N. L. Johnson and S. Kotz, </author> <title> Distributions in Statistics: Continuous Multivariate Distributions, </title> <publisher> John Wiley and Sons, Inc., </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: A distribution in this family is proportional to a Gaussian inside an ellipsoid and is zero outside the ellipsoid. The truncated Gaussian model has been proposed in a variety of contexts in Statistics <ref> [9] </ref> as models of selection mechanisms. In Robotics, the first explicit mention of the possibility of using the truncated Gaussian appears to be by Erdmann [5]. <p> These algorithms use the Gaussian distribution associated with ad hoc selection mechanisms; none of these algorithms uses appropriate models for bounded data. This approach to bounded data is employed in Statistics in order to model selection mechanisms <ref> [9] </ref>. Results derived in this work can be understood as new tools for this type of analysis. There is a different way of looking at bounded data. We can use bounded models in order to model data that is fundamentally bounded, not bounded as the result of a selection. <p> Then (d i the inverse of the ith element in the diagonal of D): q (!; D; k) = P r i=1 ! Z P n exp 2 Kotz, Johnson and Boyd <ref> [9] </ref> give a numerical method for the evaluation of this integral based 3 on its Laguerre expansion.
Reference: [10] <author> A. Papoulis, </author> <title> Probability, Random Variables and Stochastic Processes, 3rd edition, </title> <publisher> McGraw Hill, </publisher> <year> 1991. </year>
Reference-contexts: recursions for q (! t; D; k) and then plugging the result in (q (!; D; k)) 1 q (! t; D; k) exp (t T t=2). 4 2.4 Mean Vector and Covariance Matrix of a Truncated Gaussian The mean and covariance can be obtained by successive differentiations of (t) <ref> [10] </ref>. Since Kotz, Johnson and Boyd recursions for (t) are uniformly convergent we can differentiate these expressions term by term. We use for the mean and P for the covariance of a truncated Gaussian. <p> As an example, we take = 5, 2 = 4 and k = 3. Note that the variance is large, reflecting a possible situation of ignorance with respect to z. The distribution of z is shown in figure 6.a. The distribution of x 1 is <ref> [10] </ref>: p X 1 (x 1 ) = Bfx 2 p X 1 ! This distribution is graphed in figure 6.b. A simple calculation will show that x 1 2 [35:4438; 195:325]. <p> Without any statistical knowledge, we only obtain that b 2 (1; 1)! If instead we take a ~ N 0;1;1 (0; 1), then we can obtain b ~ (1 + b 2 )N 0;1;1 (0; 1) <ref> [10] </ref>, from where the analysis can proceed. Situations like this can appear, for example, when using triangulation in order to recover position. The adaptation of tolerance sets to the language of Probability theory is an area in which our models can be applied.
Reference: [11] <author> L. D. Servi and Y. C. Ho, </author> <title> Recursive Estimation in the Presence of Uniformly Distributed Measurement Noise, </title> <journal> IEEE Trans. on Automatic Control, </journal> <volume> AC-26(2):563-564, </volume> <year> 1981. </year> <month> 20 </month>
Reference-contexts: Another possibility is the uniform distribution [8], but this approach has computational problems: summation of uniform variables does not yield a uniform variable and application of Bayes rule is hard <ref> [11] </ref>. In short: even though bounds contain a lot of information, they have not received proper attention yet. Our work uses a class of distributions in the truncated Gaussian family in order to model bounded data.
References-found: 11

