URL: ftp://rtcl.eecs.umich.edu/outgoing/atri/thesisdbl.ps.Z
Refering-URL: http://www.eecs.umich.edu/~atri/
Root-URL: http://www.cs.umich.edu
Title: ABSTRACT EXPLORING QUALITY-OF-SERVICE ISSUES IN NETWORK INTERFACE DESIGN  
Author: by Atri Indiresan Chair: Kang G. Shin 
Abstract: This dissertation examines issues related to the design and implementation of communication subsystems for quality-of-service (QoS). End-to-end communication performance is determined by factors such as the underlying network technology, the end-host operating system, and the host-network interface. Increasing network speeds shifts the performance bottleneck to the end hosts, especially to the hardware and software components of the communication subsystem. The tradeoffs involved in providing QoS in communication are explored by implementing real-time communication services using the Ancor VME CIM 250 (CIM), a commercial network adapter that does not provide QoS support. Though QoS guarantees are achieved, architectural deficiencies in the design of the CIM result in throughput which is much less than the capacity of its network link or the host's memory bandwidth. An Emulated Network Device (END) tool is proposed and implemented to address the above deficiencies. END couples a representative executable model of an adapter to a host, allowing the host's communication software to interact with this model in real time. END may be used to design and analyze network adapters before they are built, thus helping avoid costly design errors. A representative model of the CIM was built using END. This 
Abstract-found: 1
Intro-found: 1
Reference: <institution> 141 BIBLIOGRAPHY </institution>
Reference: [1] <author> J. S. Ahn, P. B. Danzig, Z. Liu, and L. Yan, </author> <title> "Evaluation of TCP vegas: Emulation and experiment," </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 185-195, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: Emulation has been used before for network evaluation. For example, a transputer-based network was used to emulate four hosts interconnected on a FDDI ring, and to evaluate a 19 multimedia network interface design [18]. A more general-purpose emulator, Hitbox <ref> [1] </ref> is a layer just above the device driver in a network connected by Ethernets in a point-to-point configuration. Hitbox can be programmed to insert delays and/or errors to emulate the latency and noise characteristics of a WAN link. <p> Also, faster CPUs may be modeled by slowing down other activities, so that the CPU is now relatively faster. Scalability and contention limitations may also be addressed by using WAN emulation in the style suggested by hitbox <ref> [1] </ref>. 5.4 Conclusions In this chapter, we used END to accurately model the behavior of a real network adapter, the Ancor VME CIM 250, and modify both the hardware and software in its original design to remove some performance bottlenecks.
Reference: [2] <institution> Fibre Channel Physical and Signalling Interface (FC-PH), American National Standards Institute, </institution> <note> rev. 3.0 edition, </note> <month> June </month> <year> 1992. </year>
Reference-contexts: In the current configuration, the HARTS interconnection network is constructed using an Ancor CXT 250 crossbar switch [4] and Ancor VME CIM 250 network adaptors [3], which implement the ANSI Fiber Channel 3.0 standard <ref> [2] </ref>. The CXT 250 crossbar switch is fully connected, but may be used to embed various partially-connected point-to-point topologies for studying multi-hop communication. <p> We now describe the CIM, its data transmit and receive paths, and how we emulate its behavior using END. 5.1.1 Ancor CIM 250 The Ancor VME CIM 250 [3] Communications Interface Module is a network adapter for ANSI Fiber Channel 3.0 <ref> [2] </ref> networks. Besides communication interface hardware (an IBM OLC266 Fiber Optic link card), the CIM has an NEC 32 MHz 70236 I/O processor, 8 MB DRAM, independent DMA controllers for data movement, and VMEbus interface logic. The CIM communicates with the host using command/response FIFOs.
Reference: [3] <institution> VME CIM 250 Reference/User's Manual, ANCOR Communications, Inc., </institution> <year> 1992. </year>
Reference-contexts: For this, we use a VMEbus-based multiprocessor as the end host, with hosts connected by a network constructed using an Ancor CXT 250 crossbar switch [4] and Ancor CIM 250 network adapters <ref> [3] </ref>. We highlight the performance implications of the design features and interface characteristics of the network adapter, especially for real-time communication. These observations are used to motivate desirable features in network adapters to support real-time communication, and hence, the implementation of real-time channels. <p> In the current configuration, the HARTS interconnection network is constructed using an Ancor CXT 250 crossbar switch [4] and Ancor VME CIM 250 network adaptors <ref> [3] </ref>, which implement the ANSI Fiber Channel 3.0 standard [2]. The CXT 250 crossbar switch is fully connected, but may be used to embed various partially-connected point-to-point topologies for studying multi-hop communication. <p> In this chapter, we use END to study adapter design by conducting a case study for an existing device, the Ancor VME CIM 250 <ref> [3] </ref> (CIM) adapter, described in Chapter 3. This is achieved by first building a representative model of the device, called the base model, and implementing it using END. The base model is then modified to incorporate design changes that improve communication performance for this device. <p> We now describe the CIM, its data transmit and receive paths, and how we emulate its behavior using END. 5.1.1 Ancor CIM 250 The Ancor VME CIM 250 <ref> [3] </ref> Communications Interface Module is a network adapter for ANSI Fiber Channel 3.0 [2] networks. Besides communication interface hardware (an IBM OLC266 Fiber Optic link card), the CIM has an NEC 32 MHz 70236 I/O processor, 8 MB DRAM, independent DMA controllers for data movement, and VMEbus interface logic.
Reference: [4] <institution> CXT 250 16 Port Switch Installer's/User's Manual, ANCOR Communications, Inc., </institution> <year> 1993. </year>
Reference-contexts: Three aspects pertaining to the performance of real-time and best-effort traffic on our hardware and software architecture are explored. For this, we use a VMEbus-based multiprocessor as the end host, with hosts connected by a network constructed using an Ancor CXT 250 crossbar switch <ref> [4] </ref> and Ancor CIM 250 network adapters [3]. We highlight the performance implications of the design features and interface characteristics of the network adapter, especially for real-time communication. These observations are used to motivate desirable features in network adapters to support real-time communication, and hence, the implementation of real-time channels. <p> In the current configuration, the HARTS interconnection network is constructed using an Ancor CXT 250 crossbar switch <ref> [4] </ref> and Ancor VME CIM 250 network adaptors [3], which implement the ANSI Fiber Channel 3.0 standard [2]. The CXT 250 crossbar switch is fully connected, but may be used to embed various partially-connected point-to-point topologies for studying multi-hop communication.
Reference: [5] <author> D. P. Anderson, S. Y. Tzou, R. Wahbe, R. Govindan, and M. Andrews, </author> <title> "Support for continuous media in the DASH system," </title> <booktitle> in Proc. Int'l Conf. on Distributed Computing Systems, </booktitle> <pages> pp. 54-61, </pages> <year> 1990. </year>
Reference-contexts: The Session Reservation Protocol (SRP) [8] was proposed as a (compound) session establishment protocol for IP networks as part of the DASH project <ref> [5, 6] </ref>. The Tenet real-time protocol suite [11] is a successor to DASH, and is an advanced implementation of real-time communication on wide-area networks (WAN). This protocol suite comprises the RCAP channel administration protocol and the RTMP/RTIP transport and network layer protocols, which implement unicast real-time channels [43] in Unix. <p> The sending task establishes a real-time channel by invoking rtc create, specifying the traffic parameters for the message generation process and the end-to-end delay bound desired on this channel. The traffic generation model is based on a linear bounded arrival process <ref> [5, 32] </ref>, in which the arrival process has the following parameters: maximum message size (S max bytes), maximum message rate (R max messages/second), and maximum burst size (B max messages).
Reference: [6] <author> D. P. Anderson, </author> <title> "Metascheduling for continuous media," </title> <journal> ACM Trans. Computer Systems, </journal> <volume> vol. 11, no. 3, </volume> <pages> pp. 226-252, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: The Session Reservation Protocol (SRP) [8] was proposed as a (compound) session establishment protocol for IP networks as part of the DASH project <ref> [5, 6] </ref>. The Tenet real-time protocol suite [11] is a successor to DASH, and is an advanced implementation of real-time communication on wide-area networks (WAN). This protocol suite comprises the RCAP channel administration protocol and the RTMP/RTIP transport and network layer protocols, which implement unicast real-time channels [43] in Unix.
Reference: [7] <author> D. P. Anderson, L. Delgrossi, and R. G. Herrtwich, </author> <title> "Structure and scheduling in real-time protocol implementations," </title> <type> Technical Report TR-90-021, </type> <institution> International Computer Science Institute, Berkeley, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: An orthogonal requirement is making protocol processing predictable within hosts. The need for scheduling protocol processing at priority levels consistent with those of the communicating application is highlighted in <ref> [7] </ref> and some implementation strategies demonstrated in [51]. More recently, processor capacity reserves in Real-Time Mach [78] have been combined with user-level protocol processing [72] to make protocol processing inside hosts predictable [79].
Reference: [8] <author> D. P. Anderson, R. G. Herrtwich, and C. Schaefer, "SRP: </author> <title> A resource reservation protocol for guaranteed performance communication in the internet," </title> <type> Technical Report TR-90-006, </type> <institution> International Computer Science Institute, Berkeley, </institution> <month> February </month> <year> 1990. </year>
Reference-contexts: Though it is interesting to study how the system is designed by considering the issues related to the targeted application requirements and platform architecture, and their impact on fault-tolerance and scheduling, TTP is not sufficiently flexible to be directly applicable to more general systems. The Session Reservation Protocol (SRP) <ref> [8] </ref> was proposed as a (compound) session establishment protocol for IP networks as part of the DASH project [5, 6]. The Tenet real-time protocol suite [11] is a successor to DASH, and is an advanced implementation of real-time communication on wide-area networks (WAN).
Reference: [9] <author> C. M. Aras, J. F. Kurose, D. S. Reeves, and H. Schulzrinne, </author> <title> "Real-time communication in packet-switched networks," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 82, no. 1, </volume> <pages> pp. 122-139, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: These applications have quality-of-service (QoS) requirements on end-to-end communication that are typically defined in terms of a desired minimum bandwidth and a maximum delay from the network; additional requirements on delay jitter and packet loss may also be specified <ref> [9] </ref>. In general, these applications require high data-transfer throughput and low, bounded, end-to-end delay. A high-speed network by itself cannot guarantee high application-level throughput and/or bounded data-transfer delays. In addition, precise characterization and control over system overhead in the end-host communication subsystem is required for guaranteed QoS. <p> These networks typically use packet- or cell-switching technologies. In contrast to circuit-switched networks, due to statistical multiplexing of traffic, unused portions of capacity reserved by real-time applications can be reallocated to other applications. Various service disciplines have been proposed that provide real-time guarantees in these networks <ref> [9] </ref>. Desirable characteristics of such service disciplines include the ability to provide real-time guarantees, low latency and jitter, ability to mix real-time and non-real-time traffic, scalability, low buffer utilization and high bandwidth utilization. <p> Once a connection has been established, the network's admission control policies preserves the QoS of already accepted applications. Thus, real-time applications place stringent demands on the communication subsystem. A detailed survey of various proposed techniques for real-time communication can be found in <ref> [9] </ref>. Some of these techniques are presented here to provide an insight into the variety of paradigms used, and the issues involved in selecting a scheme appropriate to the system requirements. In rate-based methods, the requested QoS is translated into a transmission rate or bandwidth.
Reference: [10] <author> E. A. Arnould, F. J. Bitz, E. C. Cooper, H. T. Kung, R. D. Sansom, and P. A. Steenkiste, </author> <title> "The design of nectar: A network backplane for heterogeneous multi-computers," </title> <booktitle> in Proc. Third Intl. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pp. 205-216, </pages> <address> Boston, </address> <month> April </month> <year> 1989, </year> <note> ACM. </note>
Reference-contexts: Application Device Channels (ADC) were proposed as a means to give applications direct access to the network interface bypassing the overhead of the operating system. The Nectar project <ref> [10, 29, 94, 95] </ref> was another significant effort in the design of high 14 performance network interfaces for heterogeneous multicomputers. This has now evolved into the Gigabit Nectar project which focuses on network interfaces for supercomputers [54].
Reference: [11] <author> A. Banerjea, D. Ferrari, B. Mah, M. Moran, D. C. Verma, and H. Zhang, </author> <title> "The Tenet real-time protocol suite: Design, implementation, and experiences," </title> <type> Technical Report TR-94-059, </type> <institution> International Computer Science Institute, Berkeley, </institution> <address> CA, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: While there have been some implementations of real-time communications services, they have been constrained in many ways by their hardware and/or software characteristics. Some have been designed for particular classes of networks and are applicable in an extremely limited domain [66]. Others have been more general <ref> [11, 12] </ref>, but did not consider how best to exploit the underlying communication hardware. As a result, these implementations sacrifice either generality or performance. These problems may be further exacerbated due to ad hoc design of system components. <p> The Session Reservation Protocol (SRP) [8] was proposed as a (compound) session establishment protocol for IP networks as part of the DASH project [5, 6]. The Tenet real-time protocol suite <ref> [11] </ref> is a successor to DASH, and is an advanced implementation of real-time communication on wide-area networks (WAN). This protocol suite comprises the RCAP channel administration protocol and the RTMP/RTIP transport and network layer protocols, which implement unicast real-time channels [43] in Unix. <p> The real-time protocols could have been implemented in pSOS +m using sockets as the real-time channel API, similar to the approach adopted by the Tenet group <ref> [11] </ref>. However, this would have limited us to uniprocessor configurations, with the accompanying process scheduling interference effects, and the semantics and associated overhead of the socket API. More importantly, an expensive coordination amongst the APs may be necessitated to determine the (node-wide) global transmission order.
Reference: [12] <author> A. Banerjea, E. W. Knightly, F. L. Templin, and H. Zhang, </author> <title> "Experiments with the Tenet real-time protocol suite on the Sequoia 2000 wide area network," </title> <booktitle> in Proc. ACM Multimedia '94, </booktitle> <pages> pp. 183-192, </pages> <address> San Francisco, CA, </address> <month> October </month> <year> 1994. </year> <note> Also Tech. </note> <institution> Rept. TR-94-020, International Computer Science Institute, Berkeley, </institution> <address> CA, </address> <month> April </month> <year> 1994. </year> <month> 142 </month>
Reference-contexts: While there have been some implementations of real-time communications services, they have been constrained in many ways by their hardware and/or software characteristics. Some have been designed for particular classes of networks and are applicable in an extremely limited domain [66]. Others have been more general <ref> [11, 12] </ref>, but did not consider how best to exploit the underlying communication hardware. As a result, these implementations sacrifice either generality or performance. These problems may be further exacerbated due to ad hoc design of system components. <p> While the Tenet implementation uses standard network adapters, it does not consider the impact of adapter characteristics on the ability to support real-time communication effectively. Though the effectiveness of these protocols in providing and maintaining bandwidth and delay guarantees has been demonstrated <ref> [12] </ref>, delay jitter is quite large, probably due to the variance in the CPU processing delays. The resource ReSerVation Protocol (RSVP) has been proposed for use in the Internet [108].
Reference: [13] <author> T. Barzilai, D. Kandlur, A. Mehra, D. Saha, and S. Wise, </author> <title> "Design and implementation of an RSVP-based quality of service architecture for integrated services Internet," </title> <booktitle> in Proc. Int'l Conf. on Distributed Computing Systems, </booktitle> <pages> pp. 543-551, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: (b) Controlled load service which provides looser guarantees, but tries to ensure that most packets meet their deadlines. 1 Tenet Protocol Suite 2 [16, 52] considers extensions for multi-point, multi-party communication. 12 An implementation of RSVP for Unix-based servers supporting Integrated Services [19] has been described by Barzilai et al. <ref> [13] </ref>. It is an enhancement of traditional sockets-based communications that preserves the API and binary compatibility of existing applications. It supports a wide variety of network interfaces ranging from legacy LANs, like Ethernets and Token Rings, to high-speed ATM interfaces.
Reference: [14] <author> A. Bas, V. Buch, W. Vogels, and T. von Eicken, "U-net: </author> <title> A user-level network interface for parallel and distributed computing," </title> <booktitle> in Proc. ACM Symp. on Operating Systems Principles, </booktitle> <pages> pp. 40-53, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: For a given network and end host, the network adapter should be designed such that its hardware and software components do not limit communication performance. 3 Several researchers have studied many of the issues above <ref> [14, 33, 41, 83, 95] </ref>, and com-munication subsystems in general [38, 39, 89]. While many of these studies have influenced this work, they are often constrained by their host and network adapter architectures, thus preventing them from exploring novel architectural features.
Reference: [15] <author> R. C. Bedichek, "Talisman: </author> <title> Fast and accurate multicomputer simulation," </title> <booktitle> in Proceedings of Sigmetrics 95/Performance 95, </booktitle> <pages> pp. 14-24, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: More detailed models capturing concur-rency, contention, and dynamic component interaction have been constructed for some systems [23, 65], but these rapidly become intractable. Another technique is simulation, which has several advantages <ref> [15] </ref>. Since a simulator is built in software, it can be readily modified and augmented to test new features and interfaces. Simulators are usually easier and cheaper to build than real systems. They can 16 model "ideal" systems that are impossible to build, e.g., an infinitely fast network. <p> Simulation-based evaluation: Performance evaluation via simulation can be conducted at various levels of detail, and hence, accuracy. Recently, significant attention has been given to accurate, low-level simulation to study machine architectures while capturing operating system overhead <ref> [15, 102] </ref>. Other efforts have focused on protocol-level simulation with the ability to run the actual protocol stack during simulation [20], and network-level simulation with a focus on routing and end-to-end protocol performance [64, 73]. Most relevant to our work is architecture-level and protocol-level simulation.
Reference: [16] <author> R. Bettati and A. Gupta, </author> <title> "Dynamic resource migration for multiparty real-time communication," </title> <booktitle> in Proc. Int'l Conf. on Distributed Computing Systems, </booktitle> <pages> pp. 646-656, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: for two classes of traffic: (a) Guaranteed service which provides end-to-end bandwidth and delay guarantees, provided the connection does not violate the traffic parameters it provided, and (b) Controlled load service which provides looser guarantees, but tries to ensure that most packets meet their deadlines. 1 Tenet Protocol Suite 2 <ref> [16, 52] </ref> considers extensions for multi-point, multi-party communication. 12 An implementation of RSVP for Unix-based servers supporting Integrated Services [19] has been described by Barzilai et al. [13]. It is an enhancement of traditional sockets-based communications that preserves the API and binary compatibility of existing applications.
Reference: [17] <author> M. Bjorkman and P. Gunningberg, </author> <title> "Locking effects in multiprocessor implementations of protocols," </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 74-83, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: Capturing events at this low granularity in simulation models would require highly accurate resource models and could render the simulation extremely slow. Network adapter as source/sink of data: Network adapters have been modeled as simple data sources and sinks for parallel protocol implementations <ref> [17] </ref>. Interestingly, these models are executed on a separate processor within the host. Besides modeling the source/sink behavior of the network, our approach captures significantly more details of the adapter design and its interactions with the protocol stack.
Reference: [18] <author> G. Blair, A. Campbell, G. Coulson, F. Garcia, D. Hutchison, A. Scott, and D. Shepherd, </author> <title> "A network interface unit to support continuous media," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 11, no. 2, </volume> <pages> pp. 264-275, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: We study receive livelock and its solutions in detail in Chapter 7. Issues similar to those described above have been studied in the other network adapter implementations including the Afterburner [33], Jetstream [42] and APIC [37]. QoS support in network interfaces has been studied in <ref> [18, 30] </ref>. While most designs are qualitative in nature with measurements to verify performance, quantitative studies predict network performance based on the analysis of the system configuration and costs of individual communication subsystem components [74, 76]. <p> Emulation has been used before for network evaluation. For example, a transputer-based network was used to emulate four hosts interconnected on a FDDI ring, and to evaluate a 19 multimedia network interface design <ref> [18] </ref>. A more general-purpose emulator, Hitbox [1] is a layer just above the device driver in a network connected by Ethernets in a point-to-point configuration. Hitbox can be programmed to insert delays and/or errors to emulate the latency and noise characteristics of a WAN link.
Reference: [19] <author> R. Braden, D. Clark, and S. Shenker. </author> <title> Integrated Services in the Internet Architecture: An Overview. Request for Comments RFC 1633, </title> <month> July </month> <year> 1994. </year>
Reference-contexts: However, this can be very inefficient since real-time traffic is often bursty, and bandwidth utilization will be low unless idle time can be utilized by non-real-time traffic. Integrated services networks <ref> [19] </ref> are expected to carry a mix of traffic with different requirements on QoS. These networks typically use packet- or cell-switching technologies. In contrast to circuit-switched networks, due to statistical multiplexing of traffic, unused portions of capacity reserved by real-time applications can be reallocated to other applications. <p> These include FIFO+ [28] and Hop-Laxity [90]. The Internet Engineering Task Force (IETF) is examining these issues in the context of providing integrated services on the Internet <ref> [19] </ref>. Generalized Processor Sharing (GPS) was first proposed as Weighted Fair Queuing (WFQ) [36]. This is a work conserving scheme that guarantees bandwidth to applications based on their average traffic rate. <p> not violate the traffic parameters it provided, and (b) Controlled load service which provides looser guarantees, but tries to ensure that most packets meet their deadlines. 1 Tenet Protocol Suite 2 [16, 52] considers extensions for multi-point, multi-party communication. 12 An implementation of RSVP for Unix-based servers supporting Integrated Services <ref> [19] </ref> has been described by Barzilai et al. [13]. It is an enhancement of traditional sockets-based communications that preserves the API and binary compatibility of existing applications. It supports a wide variety of network interfaces ranging from legacy LANs, like Ethernets and Token Rings, to high-speed ATM interfaces.
Reference: [20] <author> L. S. Brakmo and L. L. Peterson, </author> <title> "Experiences with network simulation," </title> <booktitle> in Proceedings of ACM Sigmetrics 96, </booktitle> <pages> pp. 80-90, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: However, a simulator is typically an artificial device, i.e., no real system components are involved, which has been accurately parameterized via performance measurements. Exceptions to this do exist in approaches that execute actual software under control of the simulator <ref> [20] </ref>. However, while sufficient to study the network performance of communication protocols, such approaches are not applicable when hardware components (such as the system I/O bus, caches, device interrupts) must also be considered and hardware/software concurrency and dynamic interaction captured in the evaluation. <p> Recently, significant attention has been given to accurate, low-level simulation to study machine architectures while capturing operating system overhead [15, 102]. Other efforts have focused on protocol-level simulation with the ability to run the actual protocol stack during simulation <ref> [20] </ref>, and network-level simulation with a focus on routing and end-to-end protocol performance [64, 73]. Most relevant to our work is architecture-level and protocol-level simulation.
Reference: [21] <author> K. Buchenrieder, </author> <title> "Hot topics: </title> <booktitle> Hardware-software codesign: Codesign and concurrent engineering," Computer, </booktitle> <volume> vol. 26, no. 1, </volume> <pages> pp. 85-86, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Such a process is 4 called hardware/software codesign <ref> [21, 44, 96] </ref>. Various techniques may be used in the design process. <p> comparison of END, the emulator used in this research, with other emulators used for network evaluation. 2.3.2 The Case for Device Emulation Hardware/software codesign involves identifying the various functions that need to be implemented, and how to partition these functions between the hardware and software for optimal cost and performance <ref> [21, 44, 59, 96] </ref>. Typically, hardware models are built using a hardware description language like VHDL, and simulating the software in conjunction with these hardware models [25, 67, 101].
Reference: [22] <author> R. K. Budhia, P. M. Melliar-Smith, L. E. Moser, and R. Miller, </author> <title> "Higher performance and implementation independence: Downloading a protocol onto a communication card," </title> <booktitle> in Proc. of the Intl. Conf. on Comm., </booktitle> <pages> pp. 385-389, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Prototyping a device and interfacing to higher software layers in the operating system is time-consuming and expensive. While prototypes can be highly accurate (see Figure 2.1), they are not easily modifiable. The on-board firmware may be modified to study different design options [41], or one may employ programmable adapters <ref> [22] </ref>, but the internal hardware architecture is typically impossible to modify without developing a new prototype.
Reference: [23] <author> A. Burns, K. Tindell, and A. Wellings, </author> <title> "Effective analysis for engineering real-time fixed priority schedulers," </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> vol. 21, no. 5, </volume> <pages> pp. 475-480, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Though mathematical models are relatively inexpensive to develop for overly-simplified systems, they rarely account for system overhead encountered in practice (such as interrupt handling and context switches). More detailed models capturing concur-rency, contention, and dynamic component interaction have been constructed for some systems <ref> [23, 65] </ref>, but these rapidly become intractable. Another technique is simulation, which has several advantages [15]. Since a simulator is built in software, it can be readily modified and augmented to test new features and interfaces. Simulators are usually easier and cheaper to build than real systems.
Reference: [24] <author> C.-H. Chang, R. Flower, J. Forecast, H. Gray, W. R. Hawe, A. P. Nadkarni, K. K. Ramakrishnan, U. N. Shikarpur, and K. M. Wilde, </author> <title> "High-performance TCP/IP and UDP/IP networking in DEC OSF/1 for Alpha AXP," </title> <journal> Digital Technical Journal of Digital Equipment Corporation, </journal> <volume> vol. 5, no. 1, </volume> <pages> pp. 44-61, </pages> <month> Winter </month> <year> 1993. </year>
Reference-contexts: In LRP [39], the adapter could determine the destination of a packet, and since it had access to socket queues on the host, it could drop packets without interrupting the host. Similarly, in DEFTA <ref> [24] </ref>, the device driver ensures that the packets are dropped in the adapter when the host is starved of resources to receive subsequent packets.
Reference: [25] <author> M. Chiodo, P. Giusto, A. Jurecska, H. C. Hsieh, A. Sangiovanni-Vincentelli, and L. Lavagno, </author> <title> "Hardware-software codesign of embedded systems," </title> <journal> IEEE Micro, </journal> <volume> vol. 14, no. 4, </volume> <pages> pp. 26-36, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: Typically, hardware models are built using a hardware description language like VHDL, and simulating the software in conjunction with these hardware models <ref> [25, 67, 101] </ref>. Emulation is another hardware/software codesign technique, but, in contrast to the methods used in [25, 67, 101], instead of simulating the hardware model with the software, the software runs on the target host, and interacts with an executable model of the hardware in real time while capturing the <p> Typically, hardware models are built using a hardware description language like VHDL, and simulating the software in conjunction with these hardware models <ref> [25, 67, 101] </ref>. Emulation is another hardware/software codesign technique, but, in contrast to the methods used in [25, 67, 101], instead of simulating the hardware model with the software, the software runs on the target host, and interacts with an executable model of the hardware in real time while capturing the details of the actual hardware/software interface.
Reference: [26] <author> C.-C. Chou and K. G. Shin, </author> <title> "Statistical real-time video channels over a multiac-cess network," </title> <booktitle> in Proc. High-Speed Networking and Multimedia Computing Symposium,IS&T/SPIE Symposium on Electronic Imaging Science and Technology, </booktitle> <pages> pp. 86-96, </pages> <month> February </month> <year> 1994. </year> <month> 143 </month>
Reference-contexts: In the next section, we consider an adapter for such a network, and determine the nature and efficacy of its QoS support. 6.4 Shared Network Model Various schemes have been proposed to support real-time traffic over shared networks such as FDDI <ref> [26] </ref> and Ethernet [100]. Typically, such schemes involve passing a token between the nodes on the network, and permitting the host holding the token to transmit data.
Reference: [27] <author> C.-C. Chou and K. G. Shin, </author> <title> "A distributed table-driven route selection scheme for establishing real-time video channels," </title> <booktitle> in Proceedings of the 15th International Conference on Distributed Computing Systems (ICDCS'95), </booktitle> <pages> pp. 52-59, </pages> <address> Los Alamitos, CA, USA, May 30-June 2 1995, </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: A distributed network manager that addresses these issues has been described in <ref> [27] </ref>. Our implementation uses a distributed network manager comprising network manager protocols (NMP) running on each node in the network. The NMP provides channel management services to establish and tear down real-time channels. Each NMP maintains only information about the real-time channels passing through its node.
Reference: [28] <author> D. D. Clark, S. Shenker, and L. Zhang, </author> <title> "Supporting real-time applications in an integrated services packet network: Architecture and mechanism," </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 14-26, </pages> <year> 1992. </year>
Reference-contexts: While the schemes mentioned so far are for hard real-time communication, with strong guarantees, proposals have been made for predicted (or best-effort) real-time communication, which provide some kind of statistical guarantees. These include FIFO+ <ref> [28] </ref> and Hop-Laxity [90]. The Internet Engineering Task Force (IETF) is examining these issues in the context of providing integrated services on the Internet [19]. Generalized Processor Sharing (GPS) was first proposed as Weighted Fair Queuing (WFQ) [36].
Reference: [29] <author> E. C. Cooper, P. A. Steenkiste, R. D. Sansom, and B. D. Zill, </author> <title> "Protocol Implementation on the Nectar Communication Processor," </title> <booktitle> in SIGCOMM Symposium on Communications Architectures and Protocols, </booktitle> <pages> pp. 135-144, </pages> <address> Philadelphia, PA, </address> <month> September </month> <year> 1990, </year> <note> ACM. </note>
Reference-contexts: Application Device Channels (ADC) were proposed as a means to give applications direct access to the network interface bypassing the overhead of the operating system. The Nectar project <ref> [10, 29, 94, 95] </ref> was another significant effort in the design of high 14 performance network interfaces for heterogeneous multicomputers. This has now evolved into the Gigabit Nectar project which focuses on network interfaces for supercomputers [54]. <p> The application programming interface (API) for accessing communication services is split between this protocol processor and the other (application) processors. Dedicating a processor for protocol processing has also been proposed by other researchers <ref> [29] </ref> in order to o*oad all protocol processing from the application processors, freeing them from adapter handshake overhead and permitting greater overlap between useful computation and communication processing. <p> If the network adapter were on the NP's memory bus, it could potentially perform these functions efficiently. This has been done in the Nectar project <ref> [29] </ref> by moving protocol processing operations to the network adapter.
Reference: [30] <author> G. Coulson, A. Campbell, P. Robin, G. Blair, M. Papathomas, and D. Shepherd, </author> <title> "Design of a QoS controlled ATM based communications system in chorus," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 13, no. 4, </volume> <pages> pp. 686-700, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: We study receive livelock and its solutions in detail in Chapter 7. Issues similar to those described above have been studied in the other network adapter implementations including the Afterburner [33], Jetstream [42] and APIC [37]. QoS support in network interfaces has been studied in <ref> [18, 30] </ref>. While most designs are qualitative in nature with measurements to verify performance, quantitative studies predict network performance based on the analysis of the system configuration and costs of individual communication subsystem components [74, 76].
Reference: [31] <author> F. Cristian, </author> <title> "Probabilistic clock synchronization," </title> <journal> Distributed Computing, </journal> <volume> vol. 4, no. 3, </volume> <pages> pp. 146-158, </pages> <year> 1989. </year>
Reference-contexts: VME PIO (4 KB bcopy) 2040 ns per word VME DMA (4 KB transfer peak) 100 ns per word CIM DMA (2 KB transfer) 1250 ns per word CIM DMA (4 KB transfer) 2250 ns per word Table 3.1: Baseline system performance derivative 3 of Cristian's probabilistic clock synchronization algorithm <ref> [31] </ref>, while the Network Manager protocol is the resource reservation protocol for real-time channels. These two protocols together support real-time communication services. The HNET protocol is an unreliable datagram service with addressing support for the underlying network. <p> Since real-time communication necessitates low, predictable medium access latency, the pipeline depth and packet size on the CIM must be limited for real-time traffic as well as best-effort traffic. For example, an upper bound on pipeline depth is essential for jitter-sensitive applications like clock synchronization <ref> [31] </ref> and real-time audio/video. Since the CIM does not distinguish between best-effort and real-time traffic, the same pipeline depth and packet size must be used for both.
Reference: [32] <author> R. L. Cruz, </author> <title> A Calculus for Network Delay and a Note on Topologies of Interconnection Networks, </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> July </month> <year> 1987. </year> <note> available as technical report UILU-ENG-87-2246. </note>
Reference-contexts: The sending task establishes a real-time channel by invoking rtc create, specifying the traffic parameters for the message generation process and the end-to-end delay bound desired on this channel. The traffic generation model is based on a linear bounded arrival process <ref> [5, 32] </ref>, in which the arrival process has the following parameters: maximum message size (S max bytes), maximum message rate (R max messages/second), and maximum burst size (B max messages).
Reference: [33] <author> C. Dalton, G. Watson, D. Banks, C. Calamvokis, A. Edwards, and J. Lumley, </author> <title> "Afterburner," </title> <journal> IEEE Network Magazine, </journal> <pages> pp. 36-43, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: For a given network and end host, the network adapter should be designed such that its hardware and software components do not limit communication performance. 3 Several researchers have studied many of the issues above <ref> [14, 33, 41, 83, 95] </ref>, and com-munication subsystems in general [38, 39, 89]. While many of these studies have influenced this work, they are often constrained by their host and network adapter architectures, thus preventing them from exploring novel architectural features. <p> Other (partial) solutions based on modifications to the network adapter and/or operating system have also been proposed [39]. We study receive livelock and its solutions in detail in Chapter 7. Issues similar to those described above have been studied in the other network adapter implementations including the Afterburner <ref> [33] </ref>, Jetstream [42] and APIC [37]. QoS support in network interfaces has been studied in [18, 30]. <p> Our work relates to, and builds upon the following areas of research. Communication subsystem design and performance: Several researchers have studied the issues affecting the design and performance of network adapters <ref> [33, 41, 83, 95] </ref>, and communication subsystems in general [38, 89]. While many of these studies have influenced our work, we have focussed as much on the design process, as the design itself. Simulation-based evaluation: Performance evaluation via simulation can be conducted at various levels of detail, and hence, accuracy.
Reference: [34] <author> B. Davie, </author> <title> "The architecture and implementation of a high-speed host interface," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 11, no. 2, </volume> <pages> pp. 228-239, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: Polling for per-cell operations is also necessary since process contexts that need to be saved during interrupts are often larger than the cell size. Some operations were further optimized by using Programmable Logic Devices (PLD) for per-cell operations <ref> [34] </ref>. Later work on Aurora shifted the focus to software issues [38, 93, 99]. Per-cell operations were now moved completely to hardware, and the software abstraction of the hardware was that of a device that transferred arbitrary sized data between the host memory and the network.
Reference: [35] <author> B. S. Davie, </author> <title> "A host-network interface architecture for atm," </title> <booktitle> in Proc. of ACM SIG-COMM, </booktitle> <pages> pp. 307-315, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: While early work was mainly targeted towards improving throughput and reducing latency, more recently, adapters have been designed with explicit support for QoS. The Aurora project has studied the design and implementation of high-performance ATM adapters. Early work <ref> [35, 98] </ref> focused on the hardware aspects of the design, and optimized performance by implementing fixed services like Segmentation and Reassembly (SAR) in hardware, and allowing parallel operations for each communication channel.
Reference: [36] <author> A. Demers, S. Keshav, and S. Shenker, </author> <title> "Analysis and simulation of a fair queueing algorithm," </title> <booktitle> Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 3-12, </pages> <year> 1989. </year>
Reference-contexts: While rate-based schemes are usually simpler to implement, the rate and data priority cannot be assigned independently. Scheduler-based schemes are more complex to implement, but allow greater flexibility in independently selecting bandwidth, deadlines and delay jitter. Some of the notable rate-based schemes include Weighted Fair Queuing <ref> [36] </ref>, Packet-by-Packet Generalized Processor Sharing (PGPS) [82], Stop-and-Go [48], Hierarchical Round 9 Robin (HRR) [60], and Rate-Controlled Static-Priority Queuing (RCSP) [105]. Scheduler--based schemes include the Real-time Channel (RTC) [43] and its variants and enhancements [63, 109, 111]. <p> These include FIFO+ [28] and Hop-Laxity [90]. The Internet Engineering Task Force (IETF) is examining these issues in the context of providing integrated services on the Internet [19]. Generalized Processor Sharing (GPS) was first proposed as Weighted Fair Queuing (WFQ) <ref> [36] </ref>. This is a work conserving scheme that guarantees bandwidth to applications based on their average traffic rate. When combined with a leaky bucket admission scheme, a generalized form of the packet-based GPS (PGPS) [82] provides performance guarantees in a flexible environment.
Reference: [37] <author> Z. D. Dittia, J. R. Cox, Jr., and G. M. Parulkar, </author> <title> "Design of the APIC: A high performance ATM host-network interface chip," </title> <booktitle> in IEEE INFOCOM, </booktitle> <pages> pp. 179-187, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: We study receive livelock and its solutions in detail in Chapter 7. Issues similar to those described above have been studied in the other network adapter implementations including the Afterburner [33], Jetstream [42] and APIC <ref> [37] </ref>. QoS support in network interfaces has been studied in [18, 30]. While most designs are qualitative in nature with measurements to verify performance, quantitative studies predict network performance based on the analysis of the system configuration and costs of individual communication subsystem components [74, 76].
Reference: [38] <author> P. Druschel, M. Abbott, M. Pagels, and L. Peterson, </author> <title> "Network subsystem design," </title> <journal> IEEE Network Magazine, </journal> <pages> pp. 8-17, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: For a given network and end host, the network adapter should be designed such that its hardware and software components do not limit communication performance. 3 Several researchers have studied many of the issues above [14, 33, 41, 83, 95], and com-munication subsystems in general <ref> [38, 39, 89] </ref>. While many of these studies have influenced this work, they are often constrained by their host and network adapter architectures, thus preventing them from exploring novel architectural features. <p> Polling for per-cell operations is also necessary since process contexts that need to be saved during interrupts are often larger than the cell size. Some operations were further optimized by using Programmable Logic Devices (PLD) for per-cell operations [34]. Later work on Aurora shifted the focus to software issues <ref> [38, 93, 99] </ref>. Per-cell operations were now moved completely to hardware, and the software abstraction of the hardware was that of a device that transferred arbitrary sized data between the host memory and the network. <p> Our work relates to, and builds upon the following areas of research. Communication subsystem design and performance: Several researchers have studied the issues affecting the design and performance of network adapters [33, 41, 83, 95], and communication subsystems in general <ref> [38, 89] </ref>. While many of these studies have influenced our work, we have focussed as much on the design process, as the design itself. Simulation-based evaluation: Performance evaluation via simulation can be conducted at various levels of detail, and hence, accuracy.
Reference: [39] <author> P. Druschel and G. Banga, </author> <title> "Lazy receiver processing (LRP): A network subsystem architecture for server systems," </title> <booktitle> in Proc. Second USENIX Symp. on Operating Systems Design and Implementation, </booktitle> <pages> pp. 261-276, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: For a given network and end host, the network adapter should be designed such that its hardware and software components do not limit communication performance. 3 Several researchers have studied many of the issues above [14, 33, 41, 83, 95], and com-munication subsystems in general <ref> [38, 39, 89] </ref>. While many of these studies have influenced this work, they are often constrained by their host and network adapter architectures, thus preventing them from exploring novel architectural features. <p> More recently, processor capacity reserves in Real-Time Mach [78] have been combined with user-level protocol processing [72] to make protocol processing inside hosts predictable [79]. Some other implementations have used CPU scheduling to address some problems related to network interfaces <ref> [39, 80] </ref>, but not in the context of QoS. Our implementation of real-time channels [56, 74, 75] is described in detail in Chapter 3. It discusses the efficacy of link scheduling for our hardware and software architecture, and explicitly considers issues related to the network adapter interface to the host. <p> It also demonstrated that straight-forward design of the operating system and network interface makes the system susceptible to receive livelock . Operating system modifications to avoid receive livelock are proposed in [80]. Other (partial) solutions based on modifications to the network adapter and/or operating system have also been proposed <ref> [39] </ref>. We study receive livelock and its solutions in detail in Chapter 7. Issues similar to those described above have been studied in the other network adapter implementations including the Afterburner [33], Jetstream [42] and APIC [37]. QoS support in network interfaces has been studied in [18, 30]. <p> Another solution to receive livelock is lazy receiver processing (LRP) <ref> [39] </ref>, which has been implemented on Unix platforms with UDP/IP and TCP/IP based protocol stacks. As seen in the discussion above, receive livelock occurs since reception protocol processing is performed by the OS kernel at a very high priority. <p> With a more heavily-loaded system, the delay is likely to complete before the host can re-enable interrupts, resulting in behavior similar to clocked interrupts. 7.2.3 Adapter-based Policies Intelligent (programmable) adapters may also be used help avoid receive livelock. In LRP <ref> [39] </ref>, the adapter could determine the destination of a packet, and since it had access to socket queues on the host, it could drop packets without interrupting the host. <p> While this helps delay the onset of livelock, it does not prevent it, and neither does 122 it raise the value of MLF RR. This is similar to what was observed using the early discard policy in <ref> [39] </ref>. 7.3.3 Continuous Polling By polling the network interfaces (instead of using interrupts), the OS can explicitly schedule all activities (reception processing, packet processing and other applications), and thereby control their CPU utilization.
Reference: [40] <author> P. Druschel and L. L. Peterson, "Fbufs: </author> <title> A high-bandwidth cross-domain transfer facility," </title> <booktitle> in Proc. ACM Symp. on Operating Systems Principles, </booktitle> <pages> pp. 189-202, </pages> <month> December </month> <year> 1993. </year>
Reference: [41] <author> P. Druschel, L. L. Peterson, and B. S. Davie, </author> <title> "Experiences with a high-speed network adaptor: A software perspective," </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 2-13, </pages> <address> London, UK, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: For a given network and end host, the network adapter should be designed such that its hardware and software components do not limit communication performance. 3 Several researchers have studied many of the issues above <ref> [14, 33, 41, 83, 95] </ref>, and com-munication subsystems in general [38, 39, 89]. While many of these studies have influenced this work, they are often constrained by their host and network adapter architectures, thus preventing them from exploring novel architectural features. <p> Other issues that were addressed were the interaction of cache behavior with Programmed I/O (PIO) or Direct Memory Access (DMA) transfers, and issues related to polling vs. interrupts, and hybrid solutions like clocked interrupts. This line of research was further developed in the Osiris project <ref> [41] </ref>, which considered software issues from the perspectives of the adapter firmware, the operating system interface and the applications. Application Device Channels (ADC) were proposed as a means to give applications direct access to the network interface bypassing the overhead of the operating system. <p> Prototyping a device and interfacing to higher software layers in the operating system is time-consuming and expensive. While prototypes can be highly accurate (see Figure 2.1), they are not easily modifiable. The on-board firmware may be modified to study different design options <ref> [41] </ref>, or one may employ programmable adapters [22], but the internal hardware architecture is typically impossible to modify without developing a new prototype. <p> Our work relates to, and builds upon the following areas of research. Communication subsystem design and performance: Several researchers have studied the issues affecting the design and performance of network adapters <ref> [33, 41, 83, 95] </ref>, and communication subsystems in general [38, 89]. While many of these studies have influenced our work, we have focussed as much on the design process, as the design itself. Simulation-based evaluation: Performance evaluation via simulation can be conducted at various levels of detail, and hence, accuracy.
Reference: [42] <author> A. Edwards, G. Watson, J. Lumley, D. Banks, C. Calamvokis, and C. Dalton, </author> <title> "User-space protocols deliver high performance to applications on a low-cost Gb/s LAN," </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 14-23, </pages> <address> London, UK, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: We study receive livelock and its solutions in detail in Chapter 7. Issues similar to those described above have been studied in the other network adapter implementations including the Afterburner [33], Jetstream <ref> [42] </ref> and APIC [37]. QoS support in network interfaces has been studied in [18, 30]. While most designs are qualitative in nature with measurements to verify performance, quantitative studies predict network performance based on the analysis of the system configuration and costs of individual communication subsystem components [74, 76].
Reference: [43] <author> D. Ferrari and D. C. Verma, </author> <title> "A scheme for real-time channel establishment in wide-area networks," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. SAC-8, no. 3, </volume> <pages> pp. 368-379, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Desirable characteristics of such service disciplines include the ability to provide real-time guarantees, low latency and jitter, ability to mix real-time and non-real-time traffic, scalability, low buffer utilization and high bandwidth utilization. In this dissertation, we study real-time communication using real-time channels (RTC) <ref> [43, 63] </ref>, a service discipline for packet-switched networks that provides end-to-end deadline guarantees to real-time traffic, while minimizing degradation of total bandwidth utilization or service to best-effort traffic. RTCs include admission control, traffic policing and scheduling, and buffer management techniques that ensure that real-time guarantees are met. <p> Some of the notable rate-based schemes include Weighted Fair Queuing [36], Packet-by-Packet Generalized Processor Sharing (PGPS) [82], Stop-and-Go [48], Hierarchical Round 9 Robin (HRR) [60], and Rate-Controlled Static-Priority Queuing (RCSP) [105]. Scheduler--based schemes include the Real-time Channel (RTC) <ref> [43] </ref> and its variants and enhancements [63, 109, 111]. While the schemes mentioned so far are for hard real-time communication, with strong guarantees, proposals have been made for predicted (or best-effort) real-time communication, which provide some kind of statistical guarantees. These include FIFO+ [28] and Hop-Laxity [90]. <p> VirtualClock [106, 107] is a scheduler-based flow control mechanism that supports diverse performance requirements by enforcing resource usage based on prior reservations. Though the formulation of the algorithm is different, it is equivalent to the logical arrival time method used for policing traffic in RTCs <ref> [43, 63] </ref>. Unlike RTCs, this scheme only provides guaranteed bandwidth for connections, but does not guarantee specific deadlines. However, extensions of the VirtualClock scheme have been used to compute end-to-end delay bounds as well [104]. Our approach to real-time communication is based on the real-time channel , a scheduler-based scheme. <p> Since we consider platforms that can support a mix of real-time and best-effort traffic with a wide variety of QoS requirements, the advantages provided by the flexibility of this scheme outweigh the complexity of its implementation. The RTC was first 10 proposed by Ferrari and Verma <ref> [43] </ref> as part of the Tenet project. RTCs provide end-to-end guarantees by computing link deadlines for each link along the path for the message. This method is valid under the assumption that the sum of all packet times is less than the shortest period of any connection using that link. <p> Though static priorities are used to test for admission of new connections, a multi-class Earliest Due Date algorithm <ref> [43] </ref> is used for run-time scheduling. This scheduling scheme uses logical arrival time to set deadlines, and this provides flow control and also protects connections from one another. The details of our implementation of this scheme are described in Chapter 3. RTCs have also been adapted for other communication architectures. <p> The Tenet real-time protocol suite [11] is a successor to DASH, and is an advanced implementation of real-time communication on wide-area networks (WAN). This protocol suite comprises the RCAP channel administration protocol and the RTMP/RTIP transport and network layer protocols, which implement unicast real-time channels <ref> [43] </ref> in Unix. Since Unix-based uniprocessor workstations are the implementation platform, the Tenet approach uses the socket application programming interface (API) and implements the real-time channel scheduling discipline for ordering packet transmissions. <p> The architecture of END is described in detail in Chapter 4. Examples of its use as a design and evaluation tool are presented in Chapter 5. 20 CHAPTER 3 DESIGN TRADEOFFS IN IMPLEMENTING REAL-TIME CHANNELS The real-time channel (RTC) model <ref> [43, 63] </ref> provides a paradigm for real-time communication services in packet-switched networks. In this model, an application requesting service must specify its traffic characteristics, including the rate at which data is generated and QoS requirements, to the network.
Reference: [44] <author> D. W. Franke and M. K. Purvis, "Hardware/software codesign: </author> <title> A perspective," </title> <booktitle> in Proceedings of the 13th International Conference on Software Engineering, </booktitle> <pages> pp. 344-352, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Such a process is 4 called hardware/software codesign <ref> [21, 44, 96] </ref>. Various techniques may be used in the design process. <p> comparison of END, the emulator used in this research, with other emulators used for network evaluation. 2.3.2 The Case for Device Emulation Hardware/software codesign involves identifying the various functions that need to be implemented, and how to partition these functions between the hardware and software for optimal cost and performance <ref> [21, 44, 59, 96] </ref>. Typically, hardware models are built using a hardware description language like VHDL, and simulating the software in conjunction with these hardware models [25, 67, 101].
Reference: [45] <author> A. Gokhale and D. C. Schmidt, </author> <title> "Measuring the performance of communication mid-dleware on high-speed networks," </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 306-317, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: This permits evaluation of adapter performance for a wide range of network speeds. There is at least one other study that has evaluated protocol performance using the I/O bus of a multiprocessor host as a high-speed network <ref> [45] </ref>. In order to support such two-way communication, the END model of the network adapter was extended to support the commands for data reception, as well as for data transmission. Further, the time device provides time services for more than one END node, and synchronizes their activities when necessary.
Reference: [46] <author> S. J. Golestani, </author> <title> "A self-clocked fair queueing scheme for broadband applications," </title> <booktitle> in IEEE INFOCOM, </booktitle> <pages> pp. 636-646, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: For leaky-bucket constrained sources, PGPS may be used to tightly bound the end-to-end delay [81]. While GPS has been proven to be optimal, and PGPS is a good approximation of it, these schemes are very complicated and hard to implement. Self-Clocked Fair Queuing (SCFQ) <ref> [46] </ref> is somewhat simpler, with comparable performance, but, in the worst case, does not guarantee fairness. These schemes often serve as a benchmark to compare against the performance of simpler schemes [88].
Reference: [47] <author> S. J. Golestani, </author> <title> "Congestion-free transmission of real-time traffic in packet networks," </title> <booktitle> in IEEE INFOCOM, </booktitle> <pages> pp. 527-536. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1990. </year>
Reference: [48] <author> S. J. Golestani, </author> <title> "A stop-and-go queueing framework for congestion management," </title> <booktitle> in Proc. SIGCOMM Symposium, </booktitle> <pages> pp. 8-18. </pages> <publisher> ACM, </publisher> <month> September </month> <year> 1990. </year>
Reference-contexts: Scheduler-based schemes are more complex to implement, but allow greater flexibility in independently selecting bandwidth, deadlines and delay jitter. Some of the notable rate-based schemes include Weighted Fair Queuing [36], Packet-by-Packet Generalized Processor Sharing (PGPS) [82], Stop-and-Go <ref> [48] </ref>, Hierarchical Round 9 Robin (HRR) [60], and Rate-Controlled Static-Priority Queuing (RCSP) [105]. Scheduler--based schemes include the Real-time Channel (RTC) [43] and its variants and enhancements [63, 109, 111].
Reference: [49] <author> S. J. Golestani, </author> <title> "Congestion-free communication in high-speed packet networks," </title> <journal> IEEE Trans. Communications, </journal> <volume> vol. 39, no. 12, </volume> <pages> pp. 1802-1812, </pages> <month> December </month> <year> 1991. </year>
Reference: [50] <author> R. Gopalakrishnan and G. M. Parulkar, </author> <title> "Bringing real-time scheduling theory and practice closer for multimedia computing," </title> <booktitle> in Proceedings of ACM Sigmetrics 96, </booktitle> <pages> pp. 1-12, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Recently, there have been a few papers in the literature that address the issues related to the constraints imposed by real systems, and how the admission control and run-time scheduling of existing service disciplines need to be modified to provide QoS guarantees under these circumstances <ref> [50, 74, 75] </ref>. Given below are a few examples of implementations of real-time communication services, and how they address these issues. The Time-Triggered Protocol (TTP) [66] is an integrated communication protocol for 11 time-triggered architectures.
Reference: [51] <author> R. Govindan and D. P. Anderson, </author> <title> "Scheduling and IPC mechanisms for continuous media," </title> <booktitle> in Proc. ACM Symp. on Operating Systems Principles, </booktitle> <pages> pp. 68-80, </pages> <year> 1991. </year>
Reference-contexts: An orthogonal requirement is making protocol processing predictable within hosts. The need for scheduling protocol processing at priority levels consistent with those of the communicating application is highlighted in [7] and some implementation strategies demonstrated in <ref> [51] </ref>. More recently, processor capacity reserves in Real-Time Mach [78] have been combined with user-level protocol processing [72] to make protocol processing inside hosts predictable [79]. Some other implementations have used CPU scheduling to address some problems related to network interfaces [39, 80], but not in the context of QoS.
Reference: [52] <author> A. Gupta, W. Howe, M. Moran, and Q. Nguyen, </author> <title> "Resource sharing for multi-party real-time communication," </title> <booktitle> in IEEE INFOCOM, </booktitle> <pages> pp. 1230-1237, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: for two classes of traffic: (a) Guaranteed service which provides end-to-end bandwidth and delay guarantees, provided the connection does not violate the traffic parameters it provided, and (b) Controlled load service which provides looser guarantees, but tries to ensure that most packets meet their deadlines. 1 Tenet Protocol Suite 2 <ref> [16, 52] </ref> considers extensions for multi-point, multi-party communication. 12 An implementation of RSVP for Unix-based servers supporting Integrated Services [19] has been described by Barzilai et al. [13]. It is an enhancement of traditional sockets-based communications that preserves the API and binary compatibility of existing applications.
Reference: [53] <author> S. Han and K. G. Shin, </author> <title> "A non-intrusive distributed monitoring support in fault injection experiments," </title> <booktitle> in IEEE International Workshop on Evaluation Techniques for Dependable Systems, </booktitle> <month> October </month> <year> 1995. </year>
Reference-contexts: A completion function associated with each request is executed when the emulator is notified of the expiry of the time interval. Time measurements are provided by the VME StopWatch <ref> [53] </ref> 1 . It has a high resolution (25ns), 24-bit timer, that wraps around about every 0.4s. Since the time device continuously polls the timer to determine when an interval has elapsed, it also detects timer wraparound, and ensures that elapsed time is measured correctly.
Reference: [54] <author> M. Hemy and P. Steenkiste, </author> <title> "Gigabit I/O for distributed-memory systems: </title> <booktitle> Architecture and applications," in Proc. of Conf. on Supercomputing, </booktitle> <address> San Diego, CA, </address> <month> Decem-ber </month> <year> 1995. </year>
Reference-contexts: The Nectar project [10, 29, 94, 95] was another significant effort in the design of high 14 performance network interfaces for heterogeneous multicomputers. This has now evolved into the Gigabit Nectar project which focuses on network interfaces for supercomputers <ref> [54] </ref>. The Nectar CAB (Communications Accelerator Block) ensures high throughput and leaves sufficient resources for applications by moving some of the protocol processing to the network adapter.
Reference: [55] <author> N. C. Hutchinson and L. L. Peterson, </author> <title> "The x-Kernel: An architecture for implementing network protocols," </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> vol. 17, no. 1, </volume> <pages> pp. 1-13, </pages> <month> January </month> <year> 1991. </year> <month> 145 </month>
Reference-contexts: Figure 3.1 highlights the main HARTOS components. The APs run the pSOS +m kernel [58] while the NP runs a protocol stack based on the x-kernel <ref> [55] </ref>. Communication between the APs and the NP is provided via the HARTOS API, a command/response interface that permits pSOS +m and x-kernel to provide network services to applications. AP Kernel: pSOS +m is a real-time multiprocessor OS kernel and serves as the executive for each AP. <p> The HARTOS API is split between the APs and the NP, with API stubs marshaling call parameters implemented on the AP and the interface mailboxes implemented on the NP. NP Kernel: The NP employs a derivative of the x-kernel <ref> [55] </ref> as the communication executive. It employs a process-per-message 2 model for protocol processing, in which a process or thread shepherds a message through the protocol stack. This eliminates extraneous context switches encountered in the process-per-protocol model [89].
Reference: [56] <author> A. Indiresan, A. Mehra, and K. Shin, </author> <title> "Design tradeoffs in implementing real-time channels on bus-based multiprocessor hosts," </title> <type> Technical Report CSE-TR-238-95, </type> <institution> University of Michigan, </institution> <month> April </month> <year> 1995. </year>
Reference-contexts: Some other implementations have used CPU scheduling to address some problems related to network interfaces [39, 80], but not in the context of QoS. Our implementation of real-time channels <ref> [56, 74, 75] </ref> is described in detail in Chapter 3. It discusses the efficacy of link scheduling for our hardware and software architecture, and explicitly considers issues related to the network adapter interface to the host. <p> We gathered information for these functions from three sources: existing literature [70], our own measurements <ref> [56] </ref>, and conversations with staff at Ancor Communications, Inc. Lin et al. [70] performed extensive experiments on the CIM (using VMEbus probes) and characterized the delays of various components. As a first approximation for our model, these delays deliver a performance significantly different from our observations.
Reference: [57] <author> D. B. Ingham and G. D. Parrington, "Delayline: </author> <title> A wide-area network emulation tool," </title> <journal> Computing Systems, </journal> <volume> vol. 7, no. 3, </volume> <pages> pp. 313-332, </pages> <month> Summer </month> <year> 1994. </year> <title> The USENIX Association. </title> <note> [58] pSOS + /68K User's Manual, </note> <institution> Integrated Systems Inc., </institution> <note> version 1.2 edition, September 1992. Document No. KX68K-MAN. </note>
Reference-contexts: Hitbox can be programmed to insert delays and/or errors to emulate the latency and noise characteristics of a WAN link. Of course, it can not be used to emulate links with a bandwidth greater than that of the Ethernet, i.e., 10 Mb/s. Delayline <ref> [57] </ref> is another WAN emulation tool. Here, an arbitrary WAN topology is superposed on a LAN configuration, and the application code is intercepted to insert the appropriate queuing delays.
Reference: [59] <author> T. B. Ismail and A. Amine Jerraya, </author> <title> "Synthesis steps and design models for codesign," </title> <journal> Computer, </journal> <volume> vol. 28, no. 2, </volume> <pages> pp. 44-52, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: comparison of END, the emulator used in this research, with other emulators used for network evaluation. 2.3.2 The Case for Device Emulation Hardware/software codesign involves identifying the various functions that need to be implemented, and how to partition these functions between the hardware and software for optimal cost and performance <ref> [21, 44, 59, 96] </ref>. Typically, hardware models are built using a hardware description language like VHDL, and simulating the software in conjunction with these hardware models [25, 67, 101].
Reference: [60] <author> C. R. Kalmanek, H. Kanakia, and S. Keshav, </author> <title> "Rate controlled servers for very high-speed networks," </title> <booktitle> in Proc. GLOBECOM, </booktitle> <pages> pp. 12-20, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: Scheduler-based schemes are more complex to implement, but allow greater flexibility in independently selecting bandwidth, deadlines and delay jitter. Some of the notable rate-based schemes include Weighted Fair Queuing [36], Packet-by-Packet Generalized Processor Sharing (PGPS) [82], Stop-and-Go [48], Hierarchical Round 9 Robin (HRR) <ref> [60] </ref>, and Rate-Controlled Static-Priority Queuing (RCSP) [105]. Scheduler--based schemes include the Real-time Channel (RTC) [43] and its variants and enhancements [63, 109, 111].
Reference: [61] <author> D. D. Kandlur, D. L. Kiskis, and K. G. Shin, "HARTOS: </author> <title> A distributed real-time operating system," </title> <journal> ACM SIGOPS Operating Systems Review, </journal> <volume> vol. 23, no. 3, </volume> <pages> pp. 72-89, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: Though the CIM has a general-purpose I/O processor, the on-board firmware is controlled by the manufacturer and cannot be modified by the user. The NP exercises control over the CIM only through command/response FIFOs. 3.1.2 Software HARTOS <ref> [61, 91] </ref>, the operating system running on each HARTS node, provides a uniform interface for application programs to access kernel and network services, and supports real-time applications in a distributed environment. Figure 3.1 highlights the main HARTOS components.
Reference: [62] <author> D. D. Kandlur and K. G. Shin, </author> <title> "Design of a communication subsystem for HARTS," </title> <type> Technical Report CSE-TR-109-91, </type> <institution> CSE Division, Department of EECS, The University of Michigan, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: A scheme for channel establishment in point-to-point networks may be found in <ref> [62, 63] </ref>. In this scheme, there is a global network manager that maintains information about the network topology and resources and all established real-time channels. Applications send requests for channel establishment to this network manager which decides the route and reserves resources along the path of the real-time channel.
Reference: [63] <author> D. D. Kandlur, K. G. Shin, and D. Ferrari, </author> <title> "Real-time communication in multi-hop networks," </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> vol. 5, no. 10, </volume> <pages> pp. 1044-1056, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Desirable characteristics of such service disciplines include the ability to provide real-time guarantees, low latency and jitter, ability to mix real-time and non-real-time traffic, scalability, low buffer utilization and high bandwidth utilization. In this dissertation, we study real-time communication using real-time channels (RTC) <ref> [43, 63] </ref>, a service discipline for packet-switched networks that provides end-to-end deadline guarantees to real-time traffic, while minimizing degradation of total bandwidth utilization or service to best-effort traffic. RTCs include admission control, traffic policing and scheduling, and buffer management techniques that ensure that real-time guarantees are met. <p> Some of the notable rate-based schemes include Weighted Fair Queuing [36], Packet-by-Packet Generalized Processor Sharing (PGPS) [82], Stop-and-Go [48], Hierarchical Round 9 Robin (HRR) [60], and Rate-Controlled Static-Priority Queuing (RCSP) [105]. Scheduler--based schemes include the Real-time Channel (RTC) [43] and its variants and enhancements <ref> [63, 109, 111] </ref>. While the schemes mentioned so far are for hard real-time communication, with strong guarantees, proposals have been made for predicted (or best-effort) real-time communication, which provide some kind of statistical guarantees. These include FIFO+ [28] and Hop-Laxity [90]. <p> VirtualClock [106, 107] is a scheduler-based flow control mechanism that supports diverse performance requirements by enforcing resource usage based on prior reservations. Though the formulation of the algorithm is different, it is equivalent to the logical arrival time method used for policing traffic in RTCs <ref> [43, 63] </ref>. Unlike RTCs, this scheme only provides guaranteed bandwidth for connections, but does not guarantee specific deadlines. However, extensions of the VirtualClock scheme have been used to compute end-to-end delay bounds as well [104]. Our approach to real-time communication is based on the real-time channel , a scheduler-based scheme. <p> This method is valid under the assumption that the sum of all packet times is less than the shortest period of any connection using that link. This restriction was removed by Kandlur et al. <ref> [63] </ref>. They used a variant of the critical zone analysis used in the Rate Monotonic algorithm [71] to assign static priorities to existing connections, and to check if introducing a new connection would affect the guarantees of existing channels. <p> The architecture of END is described in detail in Chapter 4. Examples of its use as a design and evaluation tool are presented in Chapter 5. 20 CHAPTER 3 DESIGN TRADEOFFS IN IMPLEMENTING REAL-TIME CHANNELS The real-time channel (RTC) model <ref> [43, 63] </ref> provides a paradigm for real-time communication services in packet-switched networks. In this model, an application requesting service must specify its traffic characteristics, including the rate at which data is generated and QoS requirements, to the network. <p> A scheme for channel establishment in point-to-point networks may be found in <ref> [62, 63] </ref>. In this scheme, there is a global network manager that maintains information about the network topology and resources and all established real-time channels. Applications send requests for channel establishment to this network manager which decides the route and reserves resources along the path of the real-time channel. <p> Select the next link along the source-destination route. 2. Use algorithm D Order <ref> [63] </ref> to compute the worst-case delay at this link. Assign the channel the highest possible priority that does not violate guarantees of existing channels. Also compute and reserve adequate buffer and processing resources. 3. Check if the link delay is less than the end-to-end delay. <p> Figure 3.3 outlines the forward phase of the channel establishment procedure. Given a particular source-destination route, channel establishment is performed using a fixed-priority scheme (algorithm D Order <ref> [63] </ref>). We consider only static routes for real-time channels since it is very difficult to provide any message-delivery delay guarantees for a channel based on dynamic routing. Channel teardown is triggered by an rtc close call. <p> Situation (ii) is handled by registering an event with the x-kernel to wake up the scheduler at the correct time. The link scheduler maintains three queues (Queue 1, Queue 2, and Queue 3) in which outbound packets are inserted by protocol threads <ref> [63] </ref>. Queue 1 contains current real-time packets (whose logical arrival time is less than the current clock time). Best-effort packets are inserted in Queue 2. Queue 3 contains real-time packets which have arrived early, either because of bursty message generation or because they encountered smaller delays at upstream nodes. <p> Using the CIM as an example, we discuss the effect of network adapter design features and interface characteristics on data transfer performance, medium access latency, and packet handling on reception. Based on these insights, we 7 The link horizon <ref> [63] </ref> is a parameter that controls the extent to which the scheduler is work conserving. 34 highlight some desirable design features for adapters to support real-time communication. 3.3.1 CIM Performance Characteristics and Implications Several experiments were performed to determine the performance characteristics of the CIM, namely, the factors that affect data <p> For all these configurations, END implements suitably QoS-enhanced host-adapter and adapter-network interfaces with shared packet buffers. The host QoS support we consider is for real-time channels <ref> [63] </ref>, in the form of QoS-sensitive protocol processing via deadline-based CPU scheduling of channel handlers, as described in the previous section. In some of the experiments, some of the CPU support may be relaxed.
Reference: [64] <author> S. Keshav, </author> <title> "REAL : A network simulator," </title> <type> UCB CS Tech Report 88/472, </type> <institution> University of California, Berkeley, </institution> <month> December </month> <year> 1988. </year>
Reference-contexts: Other efforts have focused on protocol-level simulation with the ability to run the actual protocol stack during simulation [20], and network-level simulation with a focus on routing and end-to-end protocol performance <ref> [64, 73] </ref>. Most relevant to our work is architecture-level and protocol-level simulation. Since END executes on its own processor concurrently with the host, it avoids any intrusion on the host operating system 70 (including the protocol stack) executing on the host CPU.
Reference: [65] <author> K. A. Kettler, D. I. Katcher, and J. K. Strosnider, </author> <title> "A modeling methodology for real-time/multimedia operating systems," </title> <booktitle> in Proc. of the Real-Time Technology and Applications Symposium, </booktitle> <pages> pp. 15-26, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Though mathematical models are relatively inexpensive to develop for overly-simplified systems, they rarely account for system overhead encountered in practice (such as interrupt handling and context switches). More detailed models capturing concur-rency, contention, and dynamic component interaction have been constructed for some systems <ref> [23, 65] </ref>, but these rapidly become intractable. Another technique is simulation, which has several advantages [15]. Since a simulator is built in software, it can be readily modified and augmented to test new features and interfaces. Simulators are usually easier and cheaper to build than real systems.
Reference: [66] <author> H. Kopetz and G. Grunsteidl, </author> <title> "Ttp a protocol for fault-tolerant real-time systems," </title> <journal> IEEE Computer, </journal> <volume> vol. 27, no. 1, </volume> <pages> pp. 14-23, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: While there have been some implementations of real-time communications services, they have been constrained in many ways by their hardware and/or software characteristics. Some have been designed for particular classes of networks and are applicable in an extremely limited domain <ref> [66] </ref>. Others have been more general [11, 12], but did not consider how best to exploit the underlying communication hardware. As a result, these implementations sacrifice either generality or performance. These problems may be further exacerbated due to ad hoc design of system components. <p> Given below are a few examples of implementations of real-time communication services, and how they address these issues. The Time-Triggered Protocol (TTP) <ref> [66] </ref> is an integrated communication protocol for 11 time-triggered architectures. It provides predictable delays, clock synchronization and fault--tolerant communication on replicated broadcast channels using time-division multiplexing. While this has been implemented successfully, it is narrowly targeted towards embedded systems which have workloads that can be precisely defined in advance.
Reference: [67] <author> S. Kumar, J. H. Aylor, B. W. Johnson, and W. A. Wulf, </author> <title> "A framework for hardware/ software codesign," </title> <journal> Computer, </journal> <volume> vol. 26, no. 12, </volume> <pages> pp. 39-45, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Typically, hardware models are built using a hardware description language like VHDL, and simulating the software in conjunction with these hardware models <ref> [25, 67, 101] </ref>. Emulation is another hardware/software codesign technique, but, in contrast to the methods used in [25, 67, 101], instead of simulating the hardware model with the software, the software runs on the target host, and interacts with an executable model of the hardware in real time while capturing the <p> Typically, hardware models are built using a hardware description language like VHDL, and simulating the software in conjunction with these hardware models <ref> [25, 67, 101] </ref>. Emulation is another hardware/software codesign technique, but, in contrast to the methods used in [25, 67, 101], instead of simulating the hardware model with the software, the software runs on the target host, and interacts with an executable model of the hardware in real time while capturing the details of the actual hardware/software interface.
Reference: [68] <author> C. Lee, K. Yoshida, C. Mercer, and R. Rajkumar, </author> <title> "Predictable communication protocol processing in real-time mach," </title> <booktitle> in Proc. 2nd Real-Time Technology and Applications Symposium, </booktitle> <pages> pp. 220-229, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: On a uniprocessor system there is no need to coordinate between the activities of multiple processors. However, having a dedicated processor for network activities trivially guarantees a minimum processing bandwidth for these activities. On a uniprocessor system, other approaches, such as Processor Capacity Reserves <ref> [68, 77] </ref>, could be used to ensure that sufficient CPU capacity is available for protocol processing. We optimize the data transfer path such that there is no unnecessary data copying and bus bandwidth on transmission is consumed in the link-access order determined by the link scheduler.
Reference: [69] <author> S. J. Le*er, M. K. McKusick, M. J. Karels, and J. S. Quarterman, </author> <title> The Design and Implementation of the 4.3BSD Unix Operating System, </title> <publisher> Addison Wesley, </publisher> <month> May </month> <year> 1989. </year>
Reference-contexts: This eliminates extraneous context switches encountered in the process-per-protocol model [89]. A process-per-message model also allows protocol processing for each message to be independently scheduled on the processor based on a variety of scheduling policies, as opposed to the software-interrupt level processing in BSD Unix <ref> [69] </ref>. This improves the traffic insulation between different real-time channels. The HARTOS protocol interfaces with the HARTOS device driver on the APs to implement the HARTOS API. The Name Service protocol provides facilities to register a name locally, and to look up a name globally.
Reference: [70] <author> M. Lin, J. Hsieh, D. H. C. Du, and J. A. MacDonald, </author> <title> "Performance of high-speed network I/O subsystems: Case study of a fibre channel network," </title> <booktitle> in Proc. of Conf. on Supercomputing, </booktitle> <pages> pp. 174-183, </pages> <month> November </month> <year> 1994. </year> <month> 146 </month>
Reference-contexts: The memory bandwidth was measured using the bcopy 4 operation, both within the NP and across the VMEbus. The CIM has been reported to deliver a maximum throughput of 6 MB/second only for very large ( 3 MB) transfers <ref> [70] </ref>. While the throughput we obtained for smaller packet sizes ( 16 KB) was similar to that obtained in [70], we could only obtain a data transfer bandwidth of about 3 MB/second with 3 MB transfers. 3 This implementation of clock synchronization is completely in software, but it uses some ideas <p> The CIM has been reported to deliver a maximum throughput of 6 MB/second only for very large ( 3 MB) transfers <ref> [70] </ref>. While the throughput we obtained for smaller packet sizes ( 16 KB) was similar to that obtained in [70], we could only obtain a data transfer bandwidth of about 3 MB/second with 3 MB transfers. 3 This implementation of clock synchronization is completely in software, but it uses some ideas from the Hardware Assisted Software Clock Synchronization proposed by Ramanathan et al. [84] that help both to reduce the <p> Our experiments with the CIM in Chapter 3 revealed several performance bottlenecks and potential for improvement, making the CIM a suitable candidate for this study. The performance 72 characteristics of the CIM have also been studied in detail in <ref> [70] </ref>; some of those results have been used in this study. Our emulation methodology is to first construct a base model that is representative of the device (in this case, the CIM). <p> We gathered information for these functions from three sources: existing literature <ref> [70] </ref>, our own measurements [56], and conversations with staff at Ancor Communications, Inc. Lin et al. [70] performed extensive experiments on the CIM (using VMEbus probes) and characterized the delays of various components. As a first approximation for our model, these delays deliver a performance significantly different from our observations. <p> We gathered information for these functions from three sources: existing literature <ref> [70] </ref>, our own measurements [56], and conversations with staff at Ancor Communications, Inc. Lin et al. [70] performed extensive experiments on the CIM (using VMEbus probes) and characterized the delays of various components. As a first approximation for our model, these delays deliver a performance significantly different from our observations. This is attributed to the fact that the measurements in [70] were made on a completely different <p> Lin et al. <ref> [70] </ref> performed extensive experiments on the CIM (using VMEbus probes) and characterized the delays of various components. As a first approximation for our model, these delays deliver a performance significantly different from our observations. This is attributed to the fact that the measurements in [70] were made on a completely different platform with a different CPU, memory, protocol stack and operating system. Accordingly, we used only the measurements corresponding to operations that are strictly internal to the CIM, and hence, not affected by the change in platform. <p> While T F C is inferred from the results reported in <ref> [70] </ref>, T DMA must be computed via measurements since it is 77 platform-dependent.
Reference: [71] <author> C. L. Liu and J. W. Layland, </author> <title> "Scheduling algorithms for multiprogramming in a hard real-time environment," </title> <journal> Journal of the ACM, </journal> <volume> vol. 20, no. 1, </volume> <pages> pp. 46-61, </pages> <month> January </month> <year> 1973. </year>
Reference-contexts: This restriction was removed by Kandlur et al. [63]. They used a variant of the critical zone analysis used in the Rate Monotonic algorithm <ref> [71] </ref> to assign static priorities to existing connections, and to check if introducing a new connection would affect the guarantees of existing channels. Though static priorities are used to test for admission of new connections, a multi-class Earliest Due Date algorithm [43] is used for run-time scheduling.
Reference: [72] <author> C. Maeda and B. N. Bershad, </author> <title> "Protocol service decomposition for high-performance networking," </title> <booktitle> in Proc. ACM Symp. on Operating Systems Principles, </booktitle> <pages> pp. 244-255, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: The need for scheduling protocol processing at priority levels consistent with those of the communicating application is highlighted in [7] and some implementation strategies demonstrated in [51]. More recently, processor capacity reserves in Real-Time Mach [78] have been combined with user-level protocol processing <ref> [72] </ref> to make protocol processing inside hosts predictable [79]. Some other implementations have used CPU scheduling to address some problems related to network interfaces [39, 80], but not in the context of QoS. Our implementation of real-time channels [56, 74, 75] is described in detail in Chapter 3. <p> These optimizations have received significant attention in recent years <ref> [39-42, 72, 95] </ref>. The primary focus of these efforts has been to eliminate unnecessary copies of data as it moves between the application's address space and the network through the OS kernel.
Reference: [73] <author> S. McCanne and S. Floyd. </author> <title> NS (Network Simulator), </title> <note> 1995. Available via http://www-nrg.ee.lbl.gov/ns. </note>
Reference-contexts: Other efforts have focused on protocol-level simulation with the ability to run the actual protocol stack during simulation [20], and network-level simulation with a focus on routing and end-to-end protocol performance <ref> [64, 73] </ref>. Most relevant to our work is architecture-level and protocol-level simulation. Since END executes on its own processor concurrently with the host, it avoids any intrusion on the host operating system 70 (including the protocol stack) executing on the host CPU.
Reference: [74] <author> A. Mehra, A. Indiresan, and K. Shin, </author> <title> "Resource management for real-time communication: Making theory meet practice," </title> <booktitle> in Proc. of 2nd Real-Time Technology and Applications Symposium, </booktitle> <pages> pp. 130-138, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: Recently, there have been a few papers in the literature that address the issues related to the constraints imposed by real systems, and how the admission control and run-time scheduling of existing service disciplines need to be modified to provide QoS guarantees under these circumstances <ref> [50, 74, 75] </ref>. Given below are a few examples of implementations of real-time communication services, and how they address these issues. The Time-Triggered Protocol (TTP) [66] is an integrated communication protocol for 11 time-triggered architectures. <p> Some other implementations have used CPU scheduling to address some problems related to network interfaces [39, 80], but not in the context of QoS. Our implementation of real-time channels <ref> [56, 74, 75] </ref> is described in detail in Chapter 3. It discusses the efficacy of link scheduling for our hardware and software architecture, and explicitly considers issues related to the network adapter interface to the host. <p> It discusses the efficacy of link scheduling for our hardware and software architecture, and explicitly considers issues related to the network adapter interface to the host. Chapter 6 presents a brief description of our QoS-sensitive communication architecture, and discusses how CPU and network scheduling were integrated on this platform <ref> [74, 75] </ref>. <p> QoS support in network interfaces has been studied in [18, 30]. While most designs are qualitative in nature with measurements to verify performance, quantitative studies predict network performance based on the analysis of the system configuration and costs of individual communication subsystem components <ref> [74, 76] </ref>. The examples discussed in this section present an overview of the design of specific network adapters and the design goals and issues addressed in each case. They illustrate the increasing importance of integration of hardware and software for optimal performance. <p> A detailed performance analysis of this platform has been presented in <ref> [74] </ref>. To summarize, using the protocol stack in Figure 3.2, this CPU can process about 2000-2750 best-effort packets per second, with the lower number corresponding to single-packet messages, and the higher number corresponding to 15-packet messages (Figure 1 (a) in [74]). <p> detailed performance analysis of this platform has been presented in <ref> [74] </ref>. To summarize, using the protocol stack in Figure 3.2, this CPU can process about 2000-2750 best-effort packets per second, with the lower number corresponding to single-packet messages, and the higher number corresponding to 15-packet messages (Figure 1 (a) in [74]). Since the maximum packet size is 4 KB, this corresponds to throughputs of 8000-11000 KB/second. <p> While the admission control and scheduling policies described so far mainly consider link scheduling as a critical requirement to guarantee deadlines, further analysis <ref> [74] </ref> revealed that other system overhead could also critically affect system throughput and admissibility of real-time traffic. However, in Chapter 3, even though we did not explicitly consider this overhead, the relatively simple CPU scheduling was quite effective. <p> In such a case, it is necessary that not only the link, but the CPU resources as well, are consumed in an order determined by the QoS requirements of individual applications. In this chapter, we briefly describe a QoS-sensitive communication subsystem that integrates CPU and link scheduling <ref> [74, 75] </ref>. We consider various configurations of the host operating system, networks and network adapters with differing levels of QoS support. Using END, we examine how delivered QoS is affected by the level of QoS support provided by the different components of the end-host communication subsystem. <p> That is, the currently executing handler yields the CPU to a waiting higher-priority handler after processing up to a certain (configurable) number of packets (the preemption granularity). Besides bounding CPU access latency, this allows us to study the influence of preemption granularity and overhead on channel admissibility <ref> [74] </ref>. Link scheduling decisions are made by calling a scheduling function either by the channel handler, or by the transmission-complete interrupt service routine (Option 1 in [74]). 90 In order to support real-time communication, network adapters must provide a bounded, predictable transmission time for a packet of a given size. <p> Besides bounding CPU access latency, this allows us to study the influence of preemption granularity and overhead on channel admissibility <ref> [74] </ref>. Link scheduling decisions are made by calling a scheduling function either by the channel handler, or by the transmission-complete interrupt service routine (Option 1 in [74]). 90 In order to support real-time communication, network adapters must provide a bounded, predictable transmission time for a packet of a given size. <p> Overload protection is provided by per channel traffic enforcement, both for the CPU scheduling and link scheduling. It is also fair, since early real-time traffic is delayed till its logical arrival time, and does not take away resources from best-effort traffic. When combined with channel admission control <ref> [74] </ref>, since the order of CPU processing and link transmission is determined by message deadlines, this also guarantees that all messages meet their deadlines. 6.2 Research Goals and Approach In this chapter, we focus on some of the QoS issues highlighted in Section 4.2, namely, the necessity and effectiveness of QoS <p> The long-term average data rate does not exceed R max (= S max =I min ), but short-term bursts of up to B max messages may occur. The real-time channels were established using the analysis and techniques presented in <ref> [74] </ref>. Using EDD scheduling for protocol processing (with packets between preemption set to 4) and EDD link scheduling, all real-time traffic is guaranteed to meet its deadline. All messages are 60 KB, and the maximum packet size is configured as 4 KB.
Reference: [75] <author> A. Mehra, A. Indiresan, and K. Shin, </author> <title> "Structuring communication software for quality-of-service guarantees," </title> <booktitle> in Proc. of 17th Real-Time Systems Symposium, </booktitle> <pages> pp. 144-154, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: Recently, there have been a few papers in the literature that address the issues related to the constraints imposed by real systems, and how the admission control and run-time scheduling of existing service disciplines need to be modified to provide QoS guarantees under these circumstances <ref> [50, 74, 75] </ref>. Given below are a few examples of implementations of real-time communication services, and how they address these issues. The Time-Triggered Protocol (TTP) [66] is an integrated communication protocol for 11 time-triggered architectures. <p> Some other implementations have used CPU scheduling to address some problems related to network interfaces [39, 80], but not in the context of QoS. Our implementation of real-time channels <ref> [56, 74, 75] </ref> is described in detail in Chapter 3. It discusses the efficacy of link scheduling for our hardware and software architecture, and explicitly considers issues related to the network adapter interface to the host. <p> It discusses the efficacy of link scheduling for our hardware and software architecture, and explicitly considers issues related to the network adapter interface to the host. Chapter 6 presents a brief description of our QoS-sensitive communication architecture, and discusses how CPU and network scheduling were integrated on this platform <ref> [74, 75] </ref>. <p> Note that when the pipeline depth (i.e., the number of packets queued on the adapter) is 1, the host exercises complete control over packet transmission order <ref> [75] </ref>. The queuing and packet selection policy used by the adapter is relevant whenever the host generates data at a rate faster than the adapter can transmit. <p> Buffer management: Buffers are allocated for outgoing packets from a shared pool on the host, while incoming packets are allocated buffers on the adapter. Packet buffers on the host and/or adapter may also be reserved on a per-connection basis <ref> [75] </ref>. Network interface: The network interface for data transmission is a pure delay model. Data transmission may be synchronous (the emulator waits until the transmission delay elapses), or asynchronous (the emulator performs other operations during the "data transmission" delay). The delay services are provided by the time device, described below. <p> In such a case, it is necessary that not only the link, but the CPU resources as well, are consumed in an order determined by the QoS requirements of individual applications. In this chapter, we briefly describe a QoS-sensitive communication subsystem that integrates CPU and link scheduling <ref> [74, 75] </ref>. We consider various configurations of the host operating system, networks and network adapters with differing levels of QoS support. Using END, we examine how delivered QoS is affected by the level of QoS support provided by the different components of the end-host communication subsystem. <p> The rest of this chapter is organized as follows. Section 6.1 presents a summary of our QoS-sensitive communication software architecture implemented on HARTS <ref> [75] </ref>. Given this architecture, and the QoS issues in adapter design discussed in Section 4.2, Section 6.2 outlines our research goals and approach. Sections 6.3 and 6.4 present results from performance evaluation for point-to-point networks and shared networks, respectively, and also compare and contrast the two. <p> Sections 6.3 and 6.4 present results from performance evaluation for point-to-point networks and shared networks, respectively, and also compare and contrast the two. Finally, Section 6.5 concludes this chapter. 6.1 A QoS-sensitive Communication Subsystem <ref> [75] </ref> for details). This architecture provides a process-per-channel model of protocol processing adapted from the process-per-message model provided by x-kernel. In this model, a 89 unique process, called a channel handler , is associated with each real-time channel to per-form protocol processing for all messages generated on the channel. <p> The architecture above has been demonstrated to provide overload protection and fairness, and maintain QoS guarantees <ref> [75] </ref>. Overload protection is provided by per channel traffic enforcement, both for the CPU scheduling and link scheduling. It is also fair, since early real-time traffic is delayed till its logical arrival time, and does not take away resources from best-effort traffic. <p> However, instead of reserving capacity for real-time traffic using real-time channels and providing absolute deadline guarantees, we simply reserved bandwidth for each connection and ensured that it was provided its data rate using the run-time mechanisms described in <ref> [75] </ref>. <p> The three queuing policies that we considered differ significantly in their level of complexity, cost (i.e., overhead), and performance (i.e., ability to maintain QoS). While comparing these alternatives, we note that their efficacy is strongly influenced by the QoS support provided on the host <ref> [75] </ref>. Since the host sends (generates) packets in order of their deadlines (due to QoS-sensitive CPU scheduling of channel handlers), reordering of RT packets is required only for urgent packets that arrive subsequently. <p> However, with just TwoQ on the emulator, the number of RT packets that are late increases significantly. Still, just approximately 15% of the packets are late, which is much better performance than we expected, based on our earlier experience <ref> [75] </ref>. The reason that QoS does not suffer very much even with relatively weak CPU support is that the CPU is not a bottleneck, i.e., there is enough CPU capacity to complete all the protocol processing on time.
Reference: [76] <author> H. E. Meleis and D. N. Serpanos, </author> <title> "Designing communication subsystems for high-speed networks," </title> <journal> IEEE Network, </journal> <pages> pp. 40-46, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: QoS support in network interfaces has been studied in [18, 30]. While most designs are qualitative in nature with measurements to verify performance, quantitative studies predict network performance based on the analysis of the system configuration and costs of individual communication subsystem components <ref> [74, 76] </ref>. The examples discussed in this section present an overview of the design of specific network adapters and the design goals and issues addressed in each case. They illustrate the increasing importance of integration of hardware and software for optimal performance.
Reference: [77] <author> C. W. Mercer, S. Savage, and H. Tokuda, </author> <title> "Processor capacity reserves: Operating system support for multimedia applications," </title> <booktitle> in Proc. IEEE International Conference on Multimedia Computing and Systems, </booktitle> <pages> pp. 90-99, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: On a uniprocessor system there is no need to coordinate between the activities of multiple processors. However, having a dedicated processor for network activities trivially guarantees a minimum processing bandwidth for these activities. On a uniprocessor system, other approaches, such as Processor Capacity Reserves <ref> [68, 77] </ref>, could be used to ensure that sufficient CPU capacity is available for protocol processing. We optimize the data transfer path such that there is no unnecessary data copying and bus bandwidth on transmission is consumed in the link-access order determined by the link scheduler.
Reference: [78] <author> C. W. Mercer, S. Savage, and H. Tokuda, </author> <title> "Processor capacity reserves for multimedia operating systems," </title> <institution> Computer Science Technical Report CMU-CS-93-157, Carnegie Mellon University, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: An orthogonal requirement is making protocol processing predictable within hosts. The need for scheduling protocol processing at priority levels consistent with those of the communicating application is highlighted in [7] and some implementation strategies demonstrated in [51]. More recently, processor capacity reserves in Real-Time Mach <ref> [78] </ref> have been combined with user-level protocol processing [72] to make protocol processing inside hosts predictable [79]. Some other implementations have used CPU scheduling to address some problems related to network interfaces [39, 80], but not in the context of QoS.
Reference: [79] <author> C. W. Mercer, J. Zelenka, and R. Rajkumar, </author> <title> "On predictable operating system protocol processing," </title> <type> Technical Report CMU-CS-94-165, </type> <institution> Carnegie Mellon University, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: More recently, processor capacity reserves in Real-Time Mach [78] have been combined with user-level protocol processing [72] to make protocol processing inside hosts predictable <ref> [79] </ref>. Some other implementations have used CPU scheduling to address some problems related to network interfaces [39, 80], but not in the context of QoS. Our implementation of real-time channels [56, 74, 75] is described in detail in Chapter 3.
Reference: [80] <author> J. Mogul and K. K. Ramakrishnan, </author> <title> "Eliminating receive livelock in an interrupt-driven kernel," </title> <booktitle> in Winter USENIX Conference, </booktitle> <pages> pp. 99-111, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: More recently, processor capacity reserves in Real-Time Mach [78] have been combined with user-level protocol processing [72] to make protocol processing inside hosts predictable [79]. Some other implementations have used CPU scheduling to address some problems related to network interfaces <ref> [39, 80] </ref>, but not in the context of QoS. Our implementation of real-time channels [56, 74, 75] is described in detail in Chapter 3. It discusses the efficacy of link scheduling for our hardware and software architecture, and explicitly considers issues related to the network adapter interface to the host. <p> It also demonstrated that straight-forward design of the operating system and network interface makes the system susceptible to receive livelock . Operating system modifications to avoid receive livelock are proposed in <ref> [80] </ref>. Other (partial) solutions based on modifications to the network adapter and/or operating system have also been proposed [39]. We study receive livelock and its solutions in detail in Chapter 7. <p> Section 7.5 concludes this chapter. 7.1 Receive Livelock A brief description of the receive livelock problem (summarized from <ref> [80, 83] </ref>) is presented below. Packets received at a host must either be forwarded to other hosts (as in the case of a router), or to application programs where they are consumed. The delivered system throughput is a measure of the rate at which such packets are processed successfully. <p> The problem of avoiding receive livelock has been addressed at length in <ref> [80] </ref>. The 111 tion of offered load. authors' goals in designing packet reception mechanisms and policies were to guarantee acceptable system throughput, reasonable latency and jitter , fair allocation of resources, and overall system stability. <p> Note that prevention of receive livelock is facilitated by allowing the host to exercise control over the packet arrival interrupts. This can be done either by eliminating device interrupts entirely in favor of polling [99], or using a hybrid scheme <ref> [80] </ref> to limit the input arrival rate. Pure polling imposes significant CPU overhead and tends to exacerbate the average latencies seen by incoming packets, with the additional disadvantage that it is difficult to choose the proper polling frequency. In the hybrid scheme of [80], interrupts 113 are used only to initiate <p> polling [99], or using a hybrid scheme <ref> [80] </ref> to limit the input arrival rate. Pure polling imposes significant CPU overhead and tends to exacerbate the average latencies seen by incoming packets, with the additional disadvantage that it is difficult to choose the proper polling frequency. In the hybrid scheme of [80], interrupts 113 are used only to initiate polling and are enabled only when the polling thread has finished handling all the packets pending at an interface. <p> Under a burst of incoming packets, it is likely that the polling thread may continue running until the capacity threshold is reached for that polling period. As the authors of <ref> [80] </ref> also point out, this introduces additional latency for applications that require received packets to be queued for processing by another thread. Further, there is also the question of selecting the polling timeout to re-enable interrupts on the attached interface. <p> In the following sections, we describe our implementations of variants of the schemes described in the literature <ref> [80, 83, 99] </ref>. We then propose and implement a novel adapter-based solution to avoid receive livelock and demonstrate how it achieves our goals of performance, generality and simplicity. We realize these extensions using END, and perform experiments to evaluate the relative efficacy of the various host- and adapter-based schemes. <p> The techniques presented here are partly derived from solutions proposed in <ref> [80, 99] </ref>. 116 Traffic Specification Commands CTRL CREATE PERIODIC Create a periodic packet generation process CTRL CLEAR PERIODIC Terminate a periodic packet generation process Adapter Mode Control Commands CTRL MODE POLL Poll mode adapter does not interrupt CTRL MODE INTR Interrupt mode (default) CTRL HOST INTR CTRL ON Host explicitly enables <p> of over 1500 packets per second was the highest we observed for any scheme. 126 7.3.7 Discussion In Section 7.1, the goals of designing packet reception mechanisms and policies were identified to be to guarantee acceptable system throughput, reasonable latency and jitter, fair allocation of resources, and overall system stability <ref> [80] </ref>. Further, we required that these techniques be as general as possible and must minimize implementation complexity. Host-based schemes are often very sensitive to parameter settings and the specific scheduling paradigm. Even with a single source of interrupts, they have to be debugged carefully and tuned for stability of performance. <p> Host-based schemes are often very sensitive to parameter settings and the specific scheduling paradigm. Even with a single source of interrupts, they have to be debugged carefully and tuned for stability of performance. While this might be acceptable for special-purpose systems like the routers described in <ref> [80] </ref>, a more general approach is desirable. Adaptive backoff performs as well as, if not better than, the host-based solutions on all the performance criteria. While such a scheme does require some minor changes to the adapter firmware, changes to the host OS are minimal.
Reference: [81] <author> A. K. Parekh and R. G. Gallager, </author> <title> "A generalized processor sharing approach to flow control in integrated services networks: The multiple node case," </title> <booktitle> in IEEE INFOCOM, </booktitle> <pages> pp. 521-530, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: When combined with a leaky bucket admission scheme, a generalized form of the packet-based GPS (PGPS) [82] provides performance guarantees in a flexible environment. For leaky-bucket constrained sources, PGPS may be used to tightly bound the end-to-end delay <ref> [81] </ref>. While GPS has been proven to be optimal, and PGPS is a good approximation of it, these schemes are very complicated and hard to implement. Self-Clocked Fair Queuing (SCFQ) [46] is somewhat simpler, with comparable performance, but, in the worst case, does not guarantee fairness.
Reference: [82] <author> A. K. Parekh and R. G. Gallager, </author> <title> "A generalized processor sharing approach to flow control in integrated services networks the single node case," </title> <booktitle> in IEEE INFOCOM, </booktitle> <pages> pp. 915-924, </pages> <year> 1992. </year>
Reference-contexts: Scheduler-based schemes are more complex to implement, but allow greater flexibility in independently selecting bandwidth, deadlines and delay jitter. Some of the notable rate-based schemes include Weighted Fair Queuing [36], Packet-by-Packet Generalized Processor Sharing (PGPS) <ref> [82] </ref>, Stop-and-Go [48], Hierarchical Round 9 Robin (HRR) [60], and Rate-Controlled Static-Priority Queuing (RCSP) [105]. Scheduler--based schemes include the Real-time Channel (RTC) [43] and its variants and enhancements [63, 109, 111]. <p> Generalized Processor Sharing (GPS) was first proposed as Weighted Fair Queuing (WFQ) [36]. This is a work conserving scheme that guarantees bandwidth to applications based on their average traffic rate. When combined with a leaky bucket admission scheme, a generalized form of the packet-based GPS (PGPS) <ref> [82] </ref> provides performance guarantees in a flexible environment. For leaky-bucket constrained sources, PGPS may be used to tightly bound the end-to-end delay [81]. While GPS has been proven to be optimal, and PGPS is a good approximation of it, these schemes are very complicated and hard to implement.
Reference: [83] <author> K. K. Ramakrishnan, </author> <title> "Performance considerations in designing network interfaces," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 11, no. 2, </volume> <pages> pp. 203-219, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: For a given network and end host, the network adapter should be designed such that its hardware and software components do not limit communication performance. 3 Several researchers have studied many of the issues above <ref> [14, 33, 41, 83, 95] </ref>, and com-munication subsystems in general [38, 39, 89]. While many of these studies have influenced this work, they are often constrained by their host and network adapter architectures, thus preventing them from exploring novel architectural features. <p> However, such adapters are typically found only for very mature and ubiquitous technologies (e.g., Ethernet). Most other adapters lie on the system I/O bus, allowing them to be designed independently of the CPU architecture. One such network adapter for FDDI networks is described in <ref> [83] </ref>. It considers various design alternatives for partitioning the functions between the network interface and host software and proposes a simple model for predicting user-perceived throughput. It also demonstrated that straight-forward design of the operating system and network interface makes the system susceptible to receive livelock . <p> Note that bus bandwidth is a concern on uniprocessor hosts as well, since most network adapters are on the system I/O bus, rather than on the CPU's memory bus <ref> [83] </ref>, and hence will need to share the bus with other I/O activities. Three aspects pertaining to the performance of real-time and best-effort traffic on our hardware and software architecture are explored. <p> We now present the E mulated N etwork Device (END), a network adapter design tool that interfaces to a real communication protocol stack on a host via the system I/O bus. Since most network interfaces are on the system's I/O bus instead of the private memory bus <ref> [83] </ref>, this configuration allows END to generate the same overhead as a real adapter. Further, END can emulate all the operations of a network adapter without interfacing to a real network. Instead, it uses a synthetic network model as a sink and source of traffic. <p> Transmission and reception to/from host memory is accomplished via interaction between all of these components, as discussed below. Note that most network adapters are accessed by the host via the system I/O bus <ref> [83] </ref>. Network adapters can vary significantly in complexity depending on their desired performance goals and the underlying network technology. <p> Our work relates to, and builds upon the following areas of research. Communication subsystem design and performance: Several researchers have studied the issues affecting the design and performance of network adapters <ref> [33, 41, 83, 95] </ref>, and communication subsystems in general [38, 89]. While many of these studies have influenced our work, we have focussed as much on the design process, as the design itself. Simulation-based evaluation: Performance evaluation via simulation can be conducted at various levels of detail, and hence, accuracy. <p> Section 7.5 concludes this chapter. 7.1 Receive Livelock A brief description of the receive livelock problem (summarized from <ref> [80, 83] </ref>) is presented below. Packets received at a host must either be forwarded to other hosts (as in the case of a router), or to application programs where they are consumed. The delivered system throughput is a measure of the rate at which such packets are processed successfully. <p> Packets received at a host must either be forwarded to other hosts (as in the case of a router), or to application programs where they are consumed. The delivered system throughput is a measure of the rate at which such packets are processed successfully. Figure 7.1 (adapted from <ref> [83] </ref>) demonstrates the possible behaviors of delivered throughput versus offered input load. Ideally, every packet received is processed, no matter what the packet arrival rate is. <p> However, all practical systems have a finite capacity, and cannot receive and process packets beyond a maximum rate (determined by their processing capacity, and the cost of receiving and processing the packet), called the Maximum Loss-Free Receive Rate (MLF RR) <ref> [83] </ref>. In poorly-designed communication subsystems, under network input overload, a host can be swamped with receiving arriving packets to the extent that the effective system throughput falls to zero. <p> Similarly, under receive livelock, a router may be unable to forward packets to the outgoing interface, resulting in transmit starvation <ref> [83] </ref>. <p> In the following sections, we describe our implementations of variants of the schemes described in the literature <ref> [80, 83, 99] </ref>. We then propose and implement a novel adapter-based solution to avoid receive livelock and demonstrate how it achieves our goals of performance, generality and simplicity. We realize these extensions using END, and perform experiments to evaluate the relative efficacy of the various host- and adapter-based schemes.
Reference: [84] <author> P. Ramanathan, D. D. Kandlur, and K. G. Shin, </author> <title> "Hardware-assisted software clock synchronization for homogeneous distributed systems," </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. 39, no. 4, </volume> <pages> pp. 514-524, </pages> <month> April </month> <year> 1990. </year> <month> 147 </month>
Reference-contexts: was similar to that obtained in [70], we could only obtain a data transfer bandwidth of about 3 MB/second with 3 MB transfers. 3 This implementation of clock synchronization is completely in software, but it uses some ideas from the Hardware Assisted Software Clock Synchronization proposed by Ramanathan et al. <ref> [84] </ref> that help both to reduce the synchronization error and to increase the probability of synchronization. Even without any hardware assistance, the HARTS nodes maintain their clocks within 1 millisecond of each other. 4 bcopy performs the transfer a word at a time, using programmed I/O.
Reference: [85] <author> L. Rizzo, "Dummynet: </author> <title> A simple approach to the evaluation of network protocols," </title> <journal> Computer Communication Review, </journal> <volume> vol. 27, no. 1, </volume> <pages> pp. 31-41, </pages> <month> January </month> <year> 1997. </year>
Reference-contexts: One of the disadvantages of Delayline is that it requires modification of the application code to manage these intercepts. Dummynet <ref> [85] </ref> is very similar to Delayline. Here again, arbitrary topologies are emulated on a LAN. A thin layer of code is added between protocol layers to capture the delays of the emulated network, thus making it completely transparent to the application code.
Reference: [86] <author> O. Rose, </author> <title> "Statistical properties of MPEG video traffic and their impact on traffic modeling in ATM systems," </title> <institution> Institute of Computer Science Research Report Series 101, University of Wuerzburg, </institution> <month> February </month> <year> 1995. </year>
Reference-contexts: In some of the experiments, some of the CPU support may be relaxed. The workload used for the evaluation comprises a mix of real-time channels, multiple channels generating traffic based on MPEG traces <ref> [86] </ref>, and best-effort traffic. 6.3 Point-to-point Network Model Point-to-point networks such as switch-based and mesh-based topologies are characterized by dedicated links between source and destination hosts such that a source host exercises complete control over access to its attached link. <p> This implies that even though we reserved 100% of the link (of which only 83% is usable) there was still unused bandwidth, which was absorbed by the best effort channel. Many MPEG sources and their properties are described in detail in <ref> [86] </ref>. The frames are 384x288 pixels in a cycle of 12 with the frame sequence IBBPBBPBBPBB. We selected six different traces, two each of movies, sporting events, and television news and talk shows, and have summarized their properties in Table 6.4. <p> dino movie 880 119632 13078 14749 2 lambs movie 288 134224 7311 11195 3 atp sports 280 190856 21889 20408 4 race sports 4192 202416 30749 21167 5 news news/talk 16 194416 20664 25992 6 talk news/talk 2080 106768 14536 16519 Table 6.4: Traffic characterization of sample MPEG traces from <ref> [86] </ref>. 6.4.4 Host and Emulator QoS Support The host generates data from the 75 channels as described above and issues transmit commands to the emulator. When the emulator does not have the network token, it performs any necessary DMA and interface operations.
Reference: [87] <author> M. A. R. Saghir, P. Chow, and C. G. Lee, </author> <title> "Exploiting dual data-memory banks in digital signal processors," </title> <booktitle> in Proceedings of the Seventh International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pp. 234-243, </pages> <address> Cambridge, Massachusetts, </address> <month> October 1-5, </month> <year> 1996. </year>
Reference-contexts: Dual memory banks with independent memory buses have been suggested as a cost effective technique to increase the memory system's bandwidth, as opposed to more expensive memory organizations like dual-ported memory <ref> [87] </ref>. For general purpose applications, data placement is a problem in such an architecture, since it is hard to guarantee that simultaneous memory accesses will be from different memory banks.
Reference: [88] <author> D. Saha, S. Mukherjee, and S. K. Tripathi, </author> <title> "Carry-over round robin: A simple cell scheduling mechanism for ATM networks," </title> <booktitle> in IEEE INFOCOM, </booktitle> <pages> pp. 630-637, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: Self-Clocked Fair Queuing (SCFQ) [46] is somewhat simpler, with comparable performance, but, in the worst case, does not guarantee fairness. These schemes often serve as a benchmark to compare against the performance of simpler schemes <ref> [88] </ref>. The Stop-and-Go [47-49, 97] queuing framework includes a packet admission policy at the edge of the network, and a framing strategy at all nodes. This bounds the end-to-end delay, and guarantees a low jitter.
Reference: [89] <author> D. C. Schmidt and T. Suda, </author> <title> "Transport system architecture services for high-performance communications systems," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 11, no. 4, </volume> <pages> pp. 489-506, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: For a given network and end host, the network adapter should be designed such that its hardware and software components do not limit communication performance. 3 Several researchers have studied many of the issues above [14, 33, 41, 83, 95], and com-munication subsystems in general <ref> [38, 39, 89] </ref>. While many of these studies have influenced this work, they are often constrained by their host and network adapter architectures, thus preventing them from exploring novel architectural features. <p> NP Kernel: The NP employs a derivative of the x-kernel [55] as the communication executive. It employs a process-per-message 2 model for protocol processing, in which a process or thread shepherds a message through the protocol stack. This eliminates extraneous context switches encountered in the process-per-protocol model <ref> [89] </ref>. A process-per-message model also allows protocol processing for each message to be independently scheduled on the processor based on a variety of scheduling policies, as opposed to the software-interrupt level processing in BSD Unix [69]. This improves the traffic insulation between different real-time channels. <p> Our work relates to, and builds upon the following areas of research. Communication subsystem design and performance: Several researchers have studied the issues affecting the design and performance of network adapters [33, 41, 83, 95], and communication subsystems in general <ref> [38, 89] </ref>. While many of these studies have influenced our work, we have focussed as much on the design process, as the design itself. Simulation-based evaluation: Performance evaluation via simulation can be conducted at various levels of detail, and hence, accuracy.
Reference: [90] <author> H. Schulzrinne, J. Kurose, and D. Towsley, </author> <title> "An evaluation of scheduling mechanisms for providing best-effort, real-time communication in wide-area networks," </title> <booktitle> in IEEE INFOCOM, </booktitle> <pages> pp. 1352-1361, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: While the schemes mentioned so far are for hard real-time communication, with strong guarantees, proposals have been made for predicted (or best-effort) real-time communication, which provide some kind of statistical guarantees. These include FIFO+ [28] and Hop-Laxity <ref> [90] </ref>. The Internet Engineering Task Force (IETF) is examining these issues in the context of providing integrated services on the Internet [19]. Generalized Processor Sharing (GPS) was first proposed as Weighted Fair Queuing (WFQ) [36].
Reference: [91] <author> K. G. Shin, D. D. Kandlur, D. L. Kiskis, P. S. Dodd, H. A. Rosenberg, and A. Indire-san, </author> <title> "A distributed real-time operating system," </title> <journal> IEEE Software, </journal> <pages> pp. 58-68, </pages> <month> Septem-ber </month> <year> 1992. </year>
Reference-contexts: Implementation of real-time communication services: We describe the architecture and implementation of real-time channels on HARTS <ref> [91, 92] </ref>, an experimentation testbed for studying architectural and operating systems issues in distributed real-time systems. We explore the tradeoffs between throughput and real-time behavior, and demonstrate how the host software can overcome the limitations of a best-effort network adapter to provide real-time communication guarantees. <p> Though the CIM has a general-purpose I/O processor, the on-board firmware is controlled by the manufacturer and cannot be modified by the user. The NP exercises control over the CIM only through command/response FIFOs. 3.1.2 Software HARTOS <ref> [61, 91] </ref>, the operating system running on each HARTS node, provides a uniform interface for application programs to access kernel and network services, and supports real-time applications in a distributed environment. Figure 3.1 highlights the main HARTOS components.
Reference: [92] <author> K. G. Shin, </author> <title> "HARTS: A distributed real-time architecture," </title> <journal> IEEE Computer, </journal> <volume> vol. 24, no. 5, </volume> <pages> pp. 25-35, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Implementation of real-time communication services: We describe the architecture and implementation of real-time channels on HARTS <ref> [91, 92] </ref>, an experimentation testbed for studying architectural and operating systems issues in distributed real-time systems. We explore the tradeoffs between throughput and real-time behavior, and demonstrate how the host software can overcome the limitations of a best-effort network adapter to provide real-time communication guarantees. <p> Section 3.6 concludes this chapter. 3.1 The Experimentation Platform This section describes the hardware and software architecture of the experimentation platform which is being developed as a part of the HARTS project <ref> [92] </ref>. The primary goal of HARTS is to investigate architectural and operating system issues in distributed real-time computing. 3.1.1 Hardware Each HARTS node (also referred to as end host) is a VMEbus-based multiprocessor with 2-4 processors, as shown in Figure 3.1. This multiprocessor configuration provides several benefits over uniprocessor configurations.
Reference: [93] <author> J. M. Smith and C. B. S. Traw, </author> <title> "Giving applications access to Gb/s networking," </title> <journal> IEEE Network Magazine, </journal> <pages> pp. 44-52, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Polling for per-cell operations is also necessary since process contexts that need to be saved during interrupts are often larger than the cell size. Some operations were further optimized by using Programmable Logic Devices (PLD) for per-cell operations [34]. Later work on Aurora shifted the focus to software issues <ref> [38, 93, 99] </ref>. Per-cell operations were now moved completely to hardware, and the software abstraction of the hardware was that of a device that transferred arbitrary sized data between the host memory and the network.
Reference: [94] <author> P. Steenkiste, </author> <title> "Analyzing communication latency using the Nectar communication processor," </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 199-209. </pages> <publisher> ACM, ACM, </publisher> <address> New York, NY, USA, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: Application Device Channels (ADC) were proposed as a means to give applications direct access to the network interface bypassing the overhead of the operating system. The Nectar project <ref> [10, 29, 94, 95] </ref> was another significant effort in the design of high 14 performance network interfaces for heterogeneous multicomputers. This has now evolved into the Gigabit Nectar project which focuses on network interfaces for supercomputers [54].
Reference: [95] <author> P. A. Steenkiste, </author> <title> "A systematic approach to host interface design for high-speed networks," </title> <booktitle> IEEE Computer, </booktitle> <pages> pp. 47-57, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: For a given network and end host, the network adapter should be designed such that its hardware and software components do not limit communication performance. 3 Several researchers have studied many of the issues above <ref> [14, 33, 41, 83, 95] </ref>, and com-munication subsystems in general [38, 39, 89]. While many of these studies have influenced this work, they are often constrained by their host and network adapter architectures, thus preventing them from exploring novel architectural features. <p> Application Device Channels (ADC) were proposed as a means to give applications direct access to the network interface bypassing the overhead of the operating system. The Nectar project <ref> [10, 29, 94, 95] </ref> was another significant effort in the design of high 14 performance network interfaces for heterogeneous multicomputers. This has now evolved into the Gigabit Nectar project which focuses on network interfaces for supercomputers [54]. <p> These optimizations have received significant attention in recent years <ref> [39-42, 72, 95] </ref>. The primary focus of these efforts has been to eliminate unnecessary copies of data as it moves between the application's address space and the network through the OS kernel. <p> Our work relates to, and builds upon the following areas of research. Communication subsystem design and performance: Several researchers have studied the issues affecting the design and performance of network adapters <ref> [33, 41, 83, 95] </ref>, and communication subsystems in general [38, 89]. While many of these studies have influenced our work, we have focussed as much on the design process, as the design itself. Simulation-based evaluation: Performance evaluation via simulation can be conducted at various levels of detail, and hence, accuracy.
Reference: [96] <author> P. A. Subrahmanyam, </author> <title> "Hot topics: Hardware-software codesign: Cautious optimism for the future," </title> <journal> Computer, </journal> <volume> vol. 26, no. 1, </volume> <pages> pp. 84, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Such a process is 4 called hardware/software codesign <ref> [21, 44, 96] </ref>. Various techniques may be used in the design process. <p> comparison of END, the emulator used in this research, with other emulators used for network evaluation. 2.3.2 The Case for Device Emulation Hardware/software codesign involves identifying the various functions that need to be implemented, and how to partition these functions between the hardware and software for optimal cost and performance <ref> [21, 44, 59, 96] </ref>. Typically, hardware models are built using a hardware description language like VHDL, and simulating the software in conjunction with these hardware models [25, 67, 101].
Reference: [97] <author> L. Trajkovic and S. J. Golestani, </author> <title> "Congestion Control for Multimedia Services," </title> <journal> IEEE Network, </journal> <pages> pp. 20-26, </pages> <month> Sept. </month> <year> 1992. </year>
Reference-contexts: Self-Clocked Fair Queuing (SCFQ) [46] is somewhat simpler, with comparable performance, but, in the worst case, does not guarantee fairness. These schemes often serve as a benchmark to compare against the performance of simpler schemes [88]. The Stop-and-Go <ref> [47-49, 97] </ref> queuing framework includes a packet admission policy at the edge of the network, and a framing strategy at all nodes. This bounds the end-to-end delay, and guarantees a low jitter.
Reference: [98] <author> B. Traw and J. Smith, </author> <title> "A high performance host interface for ATM networks," </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 317-325, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: While early work was mainly targeted towards improving throughput and reducing latency, more recently, adapters have been designed with explicit support for QoS. The Aurora project has studied the design and implementation of high-performance ATM adapters. Early work <ref> [35, 98] </ref> focused on the hardware aspects of the design, and optimized performance by implementing fixed services like Segmentation and Reassembly (SAR) in hardware, and allowing parallel operations for each communication channel.
Reference: [99] <author> C. B. S. Traw and J. M. Smith, </author> <title> "Hardware/software organization of a high-performance ATM host interface," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 11, no. 2, </volume> <pages> pp. 240-253, </pages> <month> February </month> <year> 1993. </year> <month> 148 </month>
Reference-contexts: Polling for per-cell operations is also necessary since process contexts that need to be saved during interrupts are often larger than the cell size. Some operations were further optimized by using Programmable Logic Devices (PLD) for per-cell operations [34]. Later work on Aurora shifted the focus to software issues <ref> [38, 93, 99] </ref>. Per-cell operations were now moved completely to hardware, and the software abstraction of the hardware was that of a device that transferred arbitrary sized data between the host memory and the network. <p> Note that prevention of receive livelock is facilitated by allowing the host to exercise control over the packet arrival interrupts. This can be done either by eliminating device interrupts entirely in favor of polling <ref> [99] </ref>, or using a hybrid scheme [80] to limit the input arrival rate. Pure polling imposes significant CPU overhead and tends to exacerbate the average latencies seen by incoming packets, with the additional disadvantage that it is difficult to choose the proper polling frequency. <p> In the following sections, we describe our implementations of variants of the schemes described in the literature <ref> [80, 83, 99] </ref>. We then propose and implement a novel adapter-based solution to avoid receive livelock and demonstrate how it achieves our goals of performance, generality and simplicity. We realize these extensions using END, and perform experiments to evaluate the relative efficacy of the various host- and adapter-based schemes. <p> The techniques presented here are partly derived from solutions proposed in <ref> [80, 99] </ref>. 116 Traffic Specification Commands CTRL CREATE PERIODIC Create a periodic packet generation process CTRL CLEAR PERIODIC Terminate a periodic packet generation process Adapter Mode Control Commands CTRL MODE POLL Poll mode adapter does not interrupt CTRL MODE INTR Interrupt mode (default) CTRL HOST INTR CTRL ON Host explicitly enables
Reference: [100] <author> C. Venkatramani and T. Chiueh, </author> <title> "Design, implementation, and evaluation of a software-based real-time ethernet protocol," </title> <booktitle> in Proceedings of the ACM SIGCOMM, </booktitle> <pages> pp. 27-37, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: In the next section, we consider an adapter for such a network, and determine the nature and efficacy of its QoS support. 6.4 Shared Network Model Various schemes have been proposed to support real-time traffic over shared networks such as FDDI [26] and Ethernet <ref> [100] </ref>. Typically, such schemes involve passing a token between the nodes on the network, and permitting the host holding the token to transmit data.
Reference: [101] <author> A. S. Wenban, J. W. O'Leary, and G. M. Brown, </author> <title> "Codesign of communication protocols," </title> <journal> Computer, </journal> <volume> vol. 26, no. 12, </volume> <pages> pp. 46-52, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Typically, hardware models are built using a hardware description language like VHDL, and simulating the software in conjunction with these hardware models <ref> [25, 67, 101] </ref>. Emulation is another hardware/software codesign technique, but, in contrast to the methods used in [25, 67, 101], instead of simulating the hardware model with the software, the software runs on the target host, and interacts with an executable model of the hardware in real time while capturing the <p> Typically, hardware models are built using a hardware description language like VHDL, and simulating the software in conjunction with these hardware models <ref> [25, 67, 101] </ref>. Emulation is another hardware/software codesign technique, but, in contrast to the methods used in [25, 67, 101], instead of simulating the hardware model with the software, the software runs on the target host, and interacts with an executable model of the hardware in real time while capturing the details of the actual hardware/software interface.
Reference: [102] <author> E. Witchell and M. Rosenblum, "Embra: </author> <title> Fast and flexible machine simulation," </title> <booktitle> in Proceedings of ACM Sigmetrics 96, </booktitle> <pages> pp. 68-79, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Simulation-based evaluation: Performance evaluation via simulation can be conducted at various levels of detail, and hence, accuracy. Recently, significant attention has been given to accurate, low-level simulation to study machine architectures while capturing operating system overhead <ref> [15, 102] </ref>. Other efforts have focused on protocol-level simulation with the ability to run the actual protocol stack during simulation [20], and network-level simulation with a focus on routing and end-to-end protocol performance [64, 73]. Most relevant to our work is architecture-level and protocol-level simulation.
Reference: [103] <author> B. L. Worthington, G. R. Ganger, and Y. N. Patt, </author> <title> "On-line extraction of SCSI disk drive parameters," </title> <booktitle> in Proceedings of Sigmetrics 95/Performance 95, </booktitle> <pages> pp. 146-156, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Note that both simulation and emulation require construction of accurate parameterized device models that are typically derived from existing devices <ref> [103] </ref>. In our case, END emulates a network adapter and interfaces with the target host, giving the impression that the host communication software is communicating with a real network. This has several significant advantages. <p> Besides modeling the source/sink behavior of the network, our approach captures significantly more details of the adapter design and its interactions with the protocol stack. I/O device modeling: The issues involved in modeling disks have been studied by other researchers <ref> [103] </ref>. While the focus of our work is network device emulation, our emulation framework can be extended to emulate disks and interact with the file system layer in the operating system.
Reference: [104] <author> G. G. Xie and S. S. Lam, </author> <title> "Delay guarantee of a virtual clock server," </title> <journal> IEEE/ACM Trans. on Networking, </journal> <pages> pp. 683-689, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: Unlike RTCs, this scheme only provides guaranteed bandwidth for connections, but does not guarantee specific deadlines. However, extensions of the VirtualClock scheme have been used to compute end-to-end delay bounds as well <ref> [104] </ref>. Our approach to real-time communication is based on the real-time channel , a scheduler-based scheme.
Reference: [105] <author> H. Zhang and D. Ferrari, </author> <title> "Rate-controlled static-priority queueing," </title> <booktitle> in IEEE INFO-COM, </booktitle> <pages> pp. 227-236, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Scheduler-based schemes are more complex to implement, but allow greater flexibility in independently selecting bandwidth, deadlines and delay jitter. Some of the notable rate-based schemes include Weighted Fair Queuing [36], Packet-by-Packet Generalized Processor Sharing (PGPS) [82], Stop-and-Go [48], Hierarchical Round 9 Robin (HRR) [60], and Rate-Controlled Static-Priority Queuing (RCSP) <ref> [105] </ref>. Scheduler--based schemes include the Real-time Channel (RTC) [43] and its variants and enhancements [63, 109, 111]. While the schemes mentioned so far are for hard real-time communication, with strong guarantees, proposals have been made for predicted (or best-effort) real-time communication, which provide some kind of statistical guarantees.
Reference: [106] <author> L. Zhang, "VirtualClock: </author> <title> A new traffic control algorithm for packet switching networks," </title> <booktitle> in Proceedings of the SIGCOMM Symposium, </booktitle> <pages> pp. 19-29. </pages> <publisher> ACM, </publisher> <month> September </month> <year> 1990. </year>
Reference-contexts: This bounds the end-to-end delay, and guarantees a low jitter. The main drawback is that the end-to-end delay is tied to the sizes of frames, reducing the flexibility in satisfying different delay requirements. VirtualClock <ref> [106, 107] </ref> is a scheduler-based flow control mechanism that supports diverse performance requirements by enforcing resource usage based on prior reservations. Though the formulation of the algorithm is different, it is equivalent to the logical arrival time method used for policing traffic in RTCs [43, 63].
Reference: [107] <author> L. Zhang, </author> <title> "Virtual Clock: A new traffic control algorithm for packet-switched networks," </title> <journal> ACM Trans. Computer Systems, </journal> <volume> vol. 9, no. 2, </volume> <pages> pp. 101-124, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: This bounds the end-to-end delay, and guarantees a low jitter. The main drawback is that the end-to-end delay is tied to the sizes of frames, reducing the flexibility in satisfying different delay requirements. VirtualClock <ref> [106, 107] </ref> is a scheduler-based flow control mechanism that supports diverse performance requirements by enforcing resource usage based on prior reservations. Though the formulation of the algorithm is different, it is equivalent to the logical arrival time method used for policing traffic in RTCs [43, 63].
Reference: [108] <author> L. Zhang, S. Deering, D. Estrin, S. Shenker, and D. Zappala, "RSVP: </author> <title> A new resource ReSerVation Protocol," </title> <journal> IEEE Network Magazine, </journal> <pages> pp. 8-18, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: Though the effectiveness of these protocols in providing and maintaining bandwidth and delay guarantees has been demonstrated [12], delay jitter is quite large, probably due to the variance in the CPU processing delays. The resource ReSerVation Protocol (RSVP) has been proposed for use in the Internet <ref> [108] </ref>. While SRP and Tenet 1 were geared towards unicast sessions with performance guarantees, RSVP is geared more towards multi-point multi-party communication. RSVP is a signaling protocol that permits resource reservation for real-time communication in the Internet.
Reference: [109] <author> Q. Zheng and K. G. Shin, </author> <title> "Real-time communication in local area ring networks," </title> <booktitle> in Conference on Local Computer Networks, </booktitle> <pages> pp. 416-425, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Some of the notable rate-based schemes include Weighted Fair Queuing [36], Packet-by-Packet Generalized Processor Sharing (PGPS) [82], Stop-and-Go [48], Hierarchical Round 9 Robin (HRR) [60], and Rate-Controlled Static-Priority Queuing (RCSP) [105]. Scheduler--based schemes include the Real-time Channel (RTC) [43] and its variants and enhancements <ref> [63, 109, 111] </ref>. While the schemes mentioned so far are for hard real-time communication, with strong guarantees, proposals have been made for predicted (or best-effort) real-time communication, which provide some kind of statistical guarantees. These include FIFO+ [28] and Hop-Laxity [90]. <p> The details of our implementation of this scheme are described in Chapter 3. RTCs have also been adapted for other communication architectures. For example, extensions to the RTC scheme have been proposed for local area networks and FDDI rings <ref> [109, 110] </ref>. The examples selected here are not a comprehensive survey of real-time communication.
Reference: [110] <author> Q. Zheng and K. G. Shin, </author> <title> "Synchronous bandwidth allocation in FDDI networks," </title> <booktitle> in Computer Graphics (Multimedia '93 Proceedings), </booktitle> <pages> pp. 31-38. </pages> <publisher> ACM, Addison-Wesley, </publisher> <month> August </month> <year> 1993. </year>
Reference-contexts: The details of our implementation of this scheme are described in Chapter 3. RTCs have also been adapted for other communication architectures. For example, extensions to the RTC scheme have been proposed for local area networks and FDDI rings <ref> [109, 110] </ref>. The examples selected here are not a comprehensive survey of real-time communication.
Reference: [111] <author> Q. Zheng and K. G. Shin, </author> <title> "On the ability of establishing real-time channels in point-to-point packet-switched networks," </title> <journal> IEEE Trans. Communications, </journal> <volume> vol. 42, no. 2/3/4, </volume> <pages> pp. 1096-1105, </pages> <month> February/March/April </month> <year> 1994. </year> <month> 149 </month>
Reference-contexts: Some of the notable rate-based schemes include Weighted Fair Queuing [36], Packet-by-Packet Generalized Processor Sharing (PGPS) [82], Stop-and-Go [48], Hierarchical Round 9 Robin (HRR) [60], and Rate-Controlled Static-Priority Queuing (RCSP) [105]. Scheduler--based schemes include the Real-time Channel (RTC) [43] and its variants and enhancements <ref> [63, 109, 111] </ref>. While the schemes mentioned so far are for hard real-time communication, with strong guarantees, proposals have been made for predicted (or best-effort) real-time communication, which provide some kind of statistical guarantees. These include FIFO+ [28] and Hop-Laxity [90].
References-found: 111

