URL: ftp://ftp.cs.washington.edu/tr/1993/03/UW-CSE-93-03-06.PS.Z
Refering-URL: http://www.cs.washington.edu/homes/ruzzo/
Root-URL: 
Title: Pointers versus Arithmetic in PRAMs  
Author: Patrick W. Dymond Faith E. Fich Naomi Nishimura Prabhakar Ragde Walter L. Ruzzo 
Note: and via anonymous FTP from cs.washington.edu (128.95.1.4), file tr/1993/03/UW-CSE-93-03-06.PS.Z.  
Address: port CS-93-21,  Seattle, WA 98195  
Affiliation: University of Waterloo Department of Computer Science Technical Re  Department of Computer Science and Engineering, FR-35 University of Washington  
Abstract: Technical Report 93-03-06 March, 1993 A preliminary version of this paper will appear in Proceedings of the 8 th Annual IEEE Structure in Complexity Theory Conference, San Diego, CA, May 1993. Also available as: * York University Department of Computer Science Technical Report CS-93-01, 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Archibald and J.-L. Baer. </author> <title> Cache coherence protocols: Evaluation using a multiprocessor simulation model. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 4(4) </volume> <pages> 273-298, </pages> <year> 1986. </year>
Reference-contexts: It is interesting to note that similar but not identical notions of "ownership" have proven useful in practice in certain cache coherence protocols <ref> [1] </ref>, and have appeared in earlier lower bound work [4, 13]. Pointer Machines: Pointer-based data structures are ubiquitous in sequential algorithms. One reason to study pointer-based computation is that useful lower bounds may be more easily obtained in such a structured model. For examples, see [23, 17, 2]. <p> Section 2 defines the Arithmeti cally Restricted PRAM more fully. Sections 3 and 4 sketch our lower and upper bounds, respectively. 2 The Arithmetically Restricted PRAM We consider PRAMs with an infinite shared global memory (M <ref> [1] </ref>; M [2]; : : :) and p processors P 1 ; : : : ; P p that each have an infinite private local memory (L [1]; L [2]; : : :). Each (global and local) memory cell can hold one nonnegative integer of arbitrary size. <p> 4 sketch our lower and upper bounds, respectively. 2 The Arithmetically Restricted PRAM We consider PRAMs with an infinite shared global memory (M <ref> [1] </ref>; M [2]; : : :) and p processors P 1 ; : : : ; P p that each have an infinite private local memory (L [1]; L [2]; : : :). Each (global and local) memory cell can hold one nonnegative integer of arbitrary size. Each processor also has an accumulator that initially contains the processor's number. For convenience, we call the accumulator L [0]. <p> This is an interesting extension to consider since the pairing problem may be a frequently executed 6 read L [0] M [L [0]] indirect read from global memory lreadi L [0] L [i] direct read from local memory write M [L <ref> [1] </ref>] L [0] indirect write into global memory lwritei L [i] L [0] direct write into local memory load-c L [0] c assign a predefined constant c 2 C f L [0] f (L [0]) apply a unary function f 2 F q L [0] q (L [0]; : : : <p> a unary function f 2 F q L [0] q (L [0]; : : : ; L [k 1]) evaluate a k-ary function q 2 Q k Table 1: Arithmetically restricted PRAM: Basic instructions branch if L [0] &gt; 0 then goto : : : conditional branch conditional-f if L <ref> [1] </ref> &gt; 0 then L [0] f (L [0]) conditional function application (L [1] 2 f0; 1g) k-concatenate L [0] L [0] 2 k + L [1] k-bit concatenation (L [1] &lt; 2 k ) lread L [0] L [L [0]] indirect read from local memory lwrite L [L [1]] L <p> : : ; L [k 1]) evaluate a k-ary function q 2 Q k Table 1: Arithmetically restricted PRAM: Basic instructions branch if L [0] &gt; 0 then goto : : : conditional branch conditional-f if L <ref> [1] </ref> &gt; 0 then L [0] f (L [0]) conditional function application (L [1] 2 f0; 1g) k-concatenate L [0] L [0] 2 k + L [1] k-bit concatenation (L [1] &lt; 2 k ) lread L [0] L [L [0]] indirect read from local memory lwrite L [L [1]] L [0] indirect write to local memory Table 2: Arithmetically restricted PRAM: Extensions subroutine <p> k Table 1: Arithmetically restricted PRAM: Basic instructions branch if L [0] &gt; 0 then goto : : : conditional branch conditional-f if L <ref> [1] </ref> &gt; 0 then L [0] f (L [0]) conditional function application (L [1] 2 f0; 1g) k-concatenate L [0] L [0] 2 k + L [1] k-bit concatenation (L [1] &lt; 2 k ) lread L [0] L [L [0]] indirect read from local memory lwrite L [L [1]] L [0] indirect write to local memory Table 2: Arithmetically restricted PRAM: Extensions subroutine in a larger computation whose total cost dominates the cost of precomputing tables <p> restricted PRAM: Basic instructions branch if L [0] &gt; 0 then goto : : : conditional branch conditional-f if L <ref> [1] </ref> &gt; 0 then L [0] f (L [0]) conditional function application (L [1] 2 f0; 1g) k-concatenate L [0] L [0] 2 k + L [1] k-bit concatenation (L [1] &lt; 2 k ) lread L [0] L [L [0]] indirect read from local memory lwrite L [L [1]] L [0] indirect write to local memory Table 2: Arithmetically restricted PRAM: Extensions subroutine in a larger computation whose total cost dominates the cost of precomputing tables used by the pairing <p> L <ref> [1] </ref> &gt; 0 then L [0] f (L [0]) conditional function application (L [1] 2 f0; 1g) k-concatenate L [0] L [0] 2 k + L [1] k-bit concatenation (L [1] &lt; 2 k ) lread L [0] L [L [0]] indirect read from local memory lwrite L [L [1]] L [0] indirect write to local memory Table 2: Arithmetically restricted PRAM: Extensions subroutine in a larger computation whose total cost dominates the cost of precomputing tables used by the pairing subroutine. <p> The branch instruction changes flow of control. If this operation is allowed, a processor's program can be viewed as a computation tree with at most 2 t nodes at distance t from the root. Conditional function application provides a much more restricted form of branching. Here L <ref> [1] </ref> must contain either 0 or 1 and, in the latter case, the unary function f 2 F is applied to the value in L [0]. The k-concatenate instruction requires that the second argument L [1] contain a number that is at most k bits in length. <p> Conditional function application provides a much more restricted form of branching. Here L <ref> [1] </ref> must contain either 0 or 1 and, in the latter case, the unary function f 2 F is applied to the value in L [0]. The k-concatenate instruction requires that the second argument L [1] contain a number that is at most k bits in length. In this case, the concatenation is performed with the second argument treated as a k-bit number by adding leading zeros, if necessary. The last extension considered is indirect addressing of local memory. <p> In this case, the concatenation is performed with the second argument treated as a k-bit number by adding leading zeros, if necessary. The last extension considered is indirect addressing of local memory. When the address argument L [0] of lread or L <ref> [1] </ref> of lwrite is restricted to be a positive integer no larger than k, we say that the indirect addressing of local memory is k-limited. In this case, one of the local memory cells L [1]; : : : ; L [k] of the processor will be accessed. 3 Lower Bounds <p> When the address argument L [0] of lread or L <ref> [1] </ref> of lwrite is restricted to be a positive integer no larger than k, we say that the indirect addressing of local memory is k-limited. In this case, one of the local memory cells L [1]; : : : ; L [k] of the processor will be accessed. 3 Lower Bounds In this section we prove lower bounds on the pairing problem, defined in Section 1. Initially, M [1] and M [2] each contain a value in the range f1; : : : ; ng. <p> In this case, one of the local memory cells L <ref> [1] </ref>; : : : ; L [k] of the processor will be accessed. 3 Lower Bounds In this section we prove lower bounds on the pairing problem, defined in Section 1. Initially, M [1] and M [2] each contain a value in the range f1; : : : ; ng. Call these values x and y, 7 respectively. At the end of the computation, the value in M [1] must be an injective function of x and y. <p> Initially, M <ref> [1] </ref> and M [2] each contain a value in the range f1; : : : ; ng. Call these values x and y, 7 respectively. At the end of the computation, the value in M [1] must be an injective function of x and y. All three of our lower bounds are tight, as will be shown in Section 4. The lower bound proof technique was partly inspired by results of Dymond concerning sequential RAMs [6], but the PRAM case is substantially more difficult. <p> a; x; y; t) j a 2 A t ; x; y 2 f1; : : : ; ngg. 8 When an indirect write to global memory is performed by processor P i , its accumulator, L [0], contains the value to be written and its local memory cell L <ref> [1] </ref> contains the address to which to write. If L [1] is oblivious at time t, then M [L [1]] is affected at time t + 1 if and only if L [0] is affected at time t and, if so, the value written is in A t . <p> x; y 2 f1; : : : ; ngg. 8 When an indirect write to global memory is performed by processor P i , its accumulator, L [0], contains the value to be written and its local memory cell L <ref> [1] </ref> contains the address to which to write. If L [1] is oblivious at time t, then M [L [1]] is affected at time t + 1 if and only if L [0] is affected at time t and, if so, the value written is in A t . Now suppose that L [1] is affected at time t. <p> 8 When an indirect write to global memory is performed by processor P i , its accumulator, L [0], contains the value to be written and its local memory cell L <ref> [1] </ref> contains the address to which to write. If L [1] is oblivious at time t, then M [L [1]] is affected at time t + 1 if and only if L [0] is affected at time t and, if so, the value written is in A t . Now suppose that L [1] is affected at time t. <p> If L <ref> [1] </ref> is oblivious at time t, then M [L [1]] is affected at time t + 1 if and only if L [0] is affected at time t and, if so, the value written is in A t . Now suppose that L [1] is affected at time t. Then the set of locations to which P i writes during step t + 1 is a subset of A t . Note that there can be at most a t such processors; otherwise, by the pigeonhole principle, a write conflict will occur. <p> Let B t be the set of indices i 2 f1; : : : pg of processors P i such that P i writes to global memory during step t + 1, its accumulator L [0] is oblivious at time t, and its local memory cell L <ref> [1] </ref> is affected at time t. <p> When a processor performs a write to local or global memory, the value in its accumulator is written. Hence, at the end of step t, the value in each memory cell is either its initial value or a value in V t . Except for M <ref> [1] </ref> and M [2], whose initial values are contained in f1; : : : ; ng V 0 , each memory cell has the same initial value for all inputs. <p> Any value in a global memory cell is either the initial value of that cell or a value that was written there by the processor that owns the cell. Except for M <ref> [1] </ref> and M [2], whose initial values are contained in f1; : : : ; ng, each memory cell has a single initial value. <p> With the exception of Theorem 14, they are mainly important in showing that the lower bounds proved in the previous section are tight. 11 do dlog ne times M <ref> [1] </ref> double (M [1]) Concatenate each of 0 and 1 to x. M [2] successor (M [1]) L [1] successor (mod 2 (L [0])) Use the least significant bit of y to M [1] M [L [1]] choose between these two alternatives. <p> With the exception of Theorem 14, they are mainly important in showing that the lower bounds proved in the previous section are tight. 11 do dlog ne times M <ref> [1] </ref> double (M [1]) Concatenate each of 0 and 1 to x. M [2] successor (M [1]) L [1] successor (mod 2 (L [0])) Use the least significant bit of y to M [1] M [L [1]] choose between these two alternatives. <p> With the exception of Theorem 14, they are mainly important in showing that the lower bounds proved in the previous section are tight. 11 do dlog ne times M <ref> [1] </ref> double (M [1]) Concatenate each of 0 and 1 to x. M [2] successor (M [1]) L [1] successor (mod 2 (L [0])) Use the least significant bit of y to M [1] M [L [1]] choose between these two alternatives. L [0] div 2 (L [0]) Delete the least significant bit of y. <p> With the exception of Theorem 14, they are mainly important in showing that the lower bounds proved in the previous section are tight. 11 do dlog ne times M <ref> [1] </ref> double (M [1]) Concatenate each of 0 and 1 to x. M [2] successor (M [1]) L [1] successor (mod 2 (L [0])) Use the least significant bit of y to M [1] M [L [1]] choose between these two alternatives. L [0] div 2 (L [0]) Delete the least significant bit of y. <p> that the lower bounds proved in the previous section are tight. 11 do dlog ne times M <ref> [1] </ref> double (M [1]) Concatenate each of 0 and 1 to x. M [2] successor (M [1]) L [1] successor (mod 2 (L [0])) Use the least significant bit of y to M [1] M [L [1]] choose between these two alternatives. L [0] div 2 (L [0]) Delete the least significant bit of y. In the interest of simplicity, the code fragments presented in this section are not given in full detail. <p> bounds proved in the previous section are tight. 11 do dlog ne times M <ref> [1] </ref> double (M [1]) Concatenate each of 0 and 1 to x. M [2] successor (M [1]) L [1] successor (mod 2 (L [0])) Use the least significant bit of y to M [1] M [L [1]] choose between these two alternatives. L [0] div 2 (L [0]) Delete the least significant bit of y. In the interest of simplicity, the code fragments presented in this section are not given in full detail. <p> In particular, we often omit motion of constants and data to or from the accumulator, especially via direct addressing. Obviously, using dlog ne-concatenate, a single processor can solve the pairing problem in constant time by concatenating x and y. M <ref> [1] </ref> dlog ne-concatenate (M [1]; M [2]): If dlog ne-concatenate is not available, it can be replaced by 1-concatenate using the following (slower) sequence of code. <p> In particular, we often omit motion of constants and data to or from the accumulator, especially via direct addressing. Obviously, using dlog ne-concatenate, a single processor can solve the pairing problem in constant time by concatenating x and y. M <ref> [1] </ref> dlog ne-concatenate (M [1]; M [2]): If dlog ne-concatenate is not available, it can be replaced by 1-concatenate using the following (slower) sequence of code. The idea is that the bits of the second argument are pulled off one at a time and concatenated to the end of the first argument. <p> The resulting program solves the pairing problem in O (log n) time using one processor. do dlog ne times L [2] mod 2 (L <ref> [1] </ref>) L [0] 1-concatenate (L [0]; L [2]) (Here mod k and div k are the unary functions that return the remainder and quotient, respectively, when their arguments are divided by k. <p> There is a unique processor P r for which q (x; y; r) = 1. This processor writes its number, as the answer, to M <ref> [1] </ref>. All other processors write their numbers to M [2], a location whose contents we do not care about. In short, each processor P r executes the following. <p> As before, the desired processor writes its number into M <ref> [1] </ref>. L [0] 1 q (x; y; r) if L [0] &gt; 0 then L [0] r L [0] successor (L [0]) M [L [0]] r By Theorem 3, the result of Theorem 6 cannot be strengthened from CREW to CROW. <p> The idea is to apply the function unconditionally and then choose between the original and resulting values. 13 L [0] double (L [0]) Shift L [0] one bit if L <ref> [1] </ref> = 1 then L [0] successor (L [0]) Conditionally change low order bit from 0 to 1 L [3] successor (L [1]) L [3] has value 1 or 2 L [1] L [0] L [0] L [L [3]] Choose between L [1] and L [2] L [3] M [2i] Temporarily <p> is to apply the function unconditionally and then choose between the original and resulting values. 13 L [0] double (L [0]) Shift L [0] one bit if L <ref> [1] </ref> = 1 then L [0] successor (L [0]) Conditionally change low order bit from 0 to 1 L [3] successor (L [1]) L [3] has value 1 or 2 L [1] L [0] L [0] L [L [3]] Choose between L [1] and L [2] L [3] M [2i] Temporarily save the values L [4] M [2i + 1] in the global memory cells. M [2i] L [1] Move the necessary values <p> between the original and resulting values. 13 L [0] double (L [0]) Shift L [0] one bit if L <ref> [1] </ref> = 1 then L [0] successor (L [0]) Conditionally change low order bit from 0 to 1 L [3] successor (L [1]) L [3] has value 1 or 2 L [1] L [0] L [0] L [L [3]] Choose between L [1] and L [2] L [3] M [2i] Temporarily save the values L [4] M [2i + 1] in the global memory cells. M [2i] L [1] Move the necessary values from M [2i + 1] L [2] local to <p> [0]) Shift L [0] one bit if L <ref> [1] </ref> = 1 then L [0] successor (L [0]) Conditionally change low order bit from 0 to 1 L [3] successor (L [1]) L [3] has value 1 or 2 L [1] L [0] L [0] L [L [3]] Choose between L [1] and L [2] L [3] M [2i] Temporarily save the values L [4] M [2i + 1] in the global memory cells. M [2i] L [1] Move the necessary values from M [2i + 1] L [2] local to global memory. <p> L [3] successor (L <ref> [1] </ref>) L [3] has value 1 or 2 L [1] L [0] L [0] L [L [3]] Choose between L [1] and L [2] L [3] M [2i] Temporarily save the values L [4] M [2i + 1] in the global memory cells. M [2i] L [1] Move the necessary values from M [2i + 1] L [2] local to global memory. L [0] 1-concatenate (i; L [0]) Concatenate the first argument to the end of the processor number, i. L [0] M [L [0]] Determine the answer using (indirect) read from global memory. <p> M [2i + 1] L [4] Furthermore, 1-concatenate can simulate 2-limited indirect addressing of local memory. The idea is for processor P i to temporarily use the global memory cells M [2i] and M [2i + 1] in place of its local memory cells L <ref> [1] </ref> and L [2]. See Figure 5. 2 Finally, we note that none of the three lower bounds holds when other restrictions on the model mentioned in Section 2 are relaxed. Clearly, allowing a binary function with a quadratic (or even superlinear) range would cause problems. <p> Then the following Arithmetically Restricted CROW PRAM program solves the pairing problem in constant time using only n processors. 14 Step 1 L [0] M [2] M [i] f i (M <ref> [1] </ref>) Step 2 M [1] M [L [0]] Note that, after the first step, M [i] = x + n (i 1) for all i 2 f1; : : : ; ng. <p> Then the following Arithmetically Restricted CROW PRAM program solves the pairing problem in constant time using only n processors. 14 Step 1 L [0] M [2] M [i] f i (M <ref> [1] </ref>) Step 2 M [1] M [L [0]] Note that, after the first step, M [i] = x + n (i 1) for all i 2 f1; : : : ; ng. <p> Specifically, each processor P i corresponding to an internal node performs the operation M [i] M [M [i]] 1+dlog 2 ke times. Finally, to solve the k-join problem, processor 1 applies the mod 2 k function to remove the unwanted high-order bit from the answer constructed above: M <ref> [1] </ref> mod 2 k (M [1]) (Recall that we are assuming a nonuniform model, so the available unary functions, e.g. mod 2 k , are allowed to depend on k. <p> Finally, to solve the k-join problem, processor 1 applies the mod 2 k function to remove the unwanted high-order bit from the answer constructed above: M <ref> [1] </ref> mod 2 k (M [1]) (Recall that we are assuming a nonuniform model, so the available unary functions, e.g. mod 2 k , are allowed to depend on k.
Reference: [2] <author> A. M. Ben-Amram and Z. Galil. </author> <title> On pointers versus addresses. </title> <journal> Journal of the ACM, </journal> <volume> 39(3) </volume> <pages> 617-648, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Pointer Machines: Pointer-based data structures are ubiquitous in sequential algorithms. One reason to study pointer-based computation is that useful lower bounds may be more easily obtained in such a structured model. For examples, see <ref> [23, 17, 2] </ref>. The Storage Modification Machine (SMM) or Pointer Machine is a formal model that captures the notion of sequential computation by pointer manipulation. <p> Section 2 defines the Arithmeti cally Restricted PRAM more fully. Sections 3 and 4 sketch our lower and upper bounds, respectively. 2 The Arithmetically Restricted PRAM We consider PRAMs with an infinite shared global memory (M [1]; M <ref> [2] </ref>; : : :) and p processors P 1 ; : : : ; P p that each have an infinite private local memory (L [1]; L [2]; : : :). Each (global and local) memory cell can hold one nonnegative integer of arbitrary size. <p> our lower and upper bounds, respectively. 2 The Arithmetically Restricted PRAM We consider PRAMs with an infinite shared global memory (M [1]; M <ref> [2] </ref>; : : :) and p processors P 1 ; : : : ; P p that each have an infinite private local memory (L [1]; L [2]; : : :). Each (global and local) memory cell can hold one nonnegative integer of arbitrary size. Each processor also has an accumulator that initially contains the processor's number. For convenience, we call the accumulator L [0]. <p> In this case, one of the local memory cells L [1]; : : : ; L [k] of the processor will be accessed. 3 Lower Bounds In this section we prove lower bounds on the pairing problem, defined in Section 1. Initially, M [1] and M <ref> [2] </ref> each contain a value in the range f1; : : : ; ng. Call these values x and y, 7 respectively. At the end of the computation, the value in M [1] must be an injective function of x and y. <p> When a processor performs a write to local or global memory, the value in its accumulator is written. Hence, at the end of step t, the value in each memory cell is either its initial value or a value in V t . Except for M [1] and M <ref> [2] </ref>, whose initial values are contained in f1; : : : ; ng V 0 , each memory cell has the same initial value for all inputs. Thus at most one new value is obtained from each local or global memory cell that can be read during step t+1. <p> Any value in a global memory cell is either the initial value of that cell or a value that was written there by the processor that owns the cell. Except for M [1] and M <ref> [2] </ref>, whose initial values are contained in f1; : : : ; ng, each memory cell has a single initial value. <p> With the exception of Theorem 14, they are mainly important in showing that the lower bounds proved in the previous section are tight. 11 do dlog ne times M [1] double (M [1]) Concatenate each of 0 and 1 to x. M <ref> [2] </ref> successor (M [1]) L [1] successor (mod 2 (L [0])) Use the least significant bit of y to M [1] M [L [1]] choose between these two alternatives. L [0] div 2 (L [0]) Delete the least significant bit of y. <p> In particular, we often omit motion of constants and data to or from the accumulator, especially via direct addressing. Obviously, using dlog ne-concatenate, a single processor can solve the pairing problem in constant time by concatenating x and y. M [1] dlog ne-concatenate (M [1]; M <ref> [2] </ref>): If dlog ne-concatenate is not available, it can be replaced by 1-concatenate using the following (slower) sequence of code. The idea is that the bits of the second argument are pulled off one at a time and concatenated to the end of the first argument. <p> The idea is that the bits of the second argument are pulled off one at a time and concatenated to the end of the first argument. The resulting program solves the pairing problem in O (log n) time using one processor. do dlog ne times L <ref> [2] </ref> mod 2 (L [1]) L [0] 1-concatenate (L [0]; L [2]) (Here mod k and div k are the unary functions that return the remainder and quotient, respectively, when their arguments are divided by k. <p> The resulting program solves the pairing problem in O (log n) time using one processor. do dlog ne times L <ref> [2] </ref> mod 2 (L [1]) L [0] 1-concatenate (L [0]; L [2]) (Here mod k and div k are the unary functions that return the remainder and quotient, respectively, when their arguments are divided by k. <p> There is a unique processor P r for which q (x; y; r) = 1. This processor writes its number, as the answer, to M [1]. All other processors write their numbers to M <ref> [2] </ref>, a location whose contents we do not care about. In short, each processor P r executes the following. <p> [0] one bit if L [1] = 1 then L [0] successor (L [0]) Conditionally change low order bit from 0 to 1 L [3] successor (L [1]) L [3] has value 1 or 2 L [1] L [0] L [0] L [L [3]] Choose between L [1] and L <ref> [2] </ref> L [3] M [2i] Temporarily save the values L [4] M [2i + 1] in the global memory cells. M [2i] L [1] Move the necessary values from M [2i + 1] L [2] local to global memory. <p> 2 L [1] L [0] L [0] L [L [3]] Choose between L [1] and L <ref> [2] </ref> L [3] M [2i] Temporarily save the values L [4] M [2i + 1] in the global memory cells. M [2i] L [1] Move the necessary values from M [2i + 1] L [2] local to global memory. L [0] 1-concatenate (i; L [0]) Concatenate the first argument to the end of the processor number, i. L [0] M [L [0]] Determine the answer using (indirect) read from global memory. M [2i] L [3] Restore the global memory cells. <p> M [2i + 1] L [4] Furthermore, 1-concatenate can simulate 2-limited indirect addressing of local memory. The idea is for processor P i to temporarily use the global memory cells M [2i] and M [2i + 1] in place of its local memory cells L [1] and L <ref> [2] </ref>. See Figure 5. 2 Finally, we note that none of the three lower bounds holds when other restrictions on the model mentioned in Section 2 are relaxed. Clearly, allowing a binary function with a quadratic (or even superlinear) range would cause problems. <p> Then the following Arithmetically Restricted CROW PRAM program solves the pairing problem in constant time using only n processors. 14 Step 1 L [0] M <ref> [2] </ref> M [i] f i (M [1]) Step 2 M [1] M [L [0]] Note that, after the first step, M [i] = x + n (i 1) for all i 2 f1; : : : ; ng.
Reference: [3] <author> S. A. Cook. </author> <title> Towards a complexity theory of synchronous parallel computation. </title> <booktitle> L'Enseignement Mathematique, XXVII(1-2):99-124, Jan.-June 1981. Also in [20, </booktitle> <pages> pages 75-100]. </pages>
Reference-contexts: The notion of parallel computation by pointer manipulation is formally captured by the PPM 1 , studied by Dymond and Cook <ref> [3, 7, 5] </ref>. In brief, the model consists of a collection of finite state units, each with a fixed number of pointers to other units. Each unit can read the state of, and/or copy the pointers of, the units to which it points. <p> The idea is to apply the function unconditionally and then choose between the original and resulting values. 13 L [0] double (L [0]) Shift L [0] one bit if L [1] = 1 then L [0] successor (L [0]) Conditionally change low order bit from 0 to 1 L <ref> [3] </ref> successor (L [1]) L [3] has value 1 or 2 L [1] L [0] L [0] L [L [3]] Choose between L [1] and L [2] L [3] M [2i] Temporarily save the values L [4] M [2i + 1] in the global memory cells. <p> apply the function unconditionally and then choose between the original and resulting values. 13 L [0] double (L [0]) Shift L [0] one bit if L [1] = 1 then L [0] successor (L [0]) Conditionally change low order bit from 0 to 1 L <ref> [3] </ref> successor (L [1]) L [3] has value 1 or 2 L [1] L [0] L [0] L [L [3]] Choose between L [1] and L [2] L [3] M [2i] Temporarily save the values L [4] M [2i + 1] in the global memory cells. <p> L [0] double (L [0]) Shift L [0] one bit if L [1] = 1 then L [0] successor (L [0]) Conditionally change low order bit from 0 to 1 L <ref> [3] </ref> successor (L [1]) L [3] has value 1 or 2 L [1] L [0] L [0] L [L [3]] Choose between L [1] and L [2] L [3] M [2i] Temporarily save the values L [4] M [2i + 1] in the global memory cells. M [2i] L [1] Move the necessary values from M [2i + 1] L [2] local to global memory. <p> bit if L [1] = 1 then L [0] successor (L [0]) Conditionally change low order bit from 0 to 1 L <ref> [3] </ref> successor (L [1]) L [3] has value 1 or 2 L [1] L [0] L [0] L [L [3]] Choose between L [1] and L [2] L [3] M [2i] Temporarily save the values L [4] M [2i + 1] in the global memory cells. M [2i] L [1] Move the necessary values from M [2i + 1] L [2] local to global memory. <p> L [0] 1-concatenate (i; L [0]) Concatenate the first argument to the end of the processor number, i. L [0] M [L [0]] Determine the answer using (indirect) read from global memory. M [2i] L <ref> [3] </ref> Restore the global memory cells. M [2i + 1] L [4] Furthermore, 1-concatenate can simulate 2-limited indirect addressing of local memory. <p> In the course of constructing these tables, we will coincidentally activate the correct number of processors. (The rCROW, as defined in [19], as well as the PPM, as defined in <ref> [3, 7, 5] </ref>, are forking models. That is, there is only one initially active processor; others are activated by fork instructions.
Reference: [4] <author> S. A. Cook, C. Dwork, and R. Reischuk. </author> <title> Upper and lower time bounds for parallel random access machines without simultaneous writes. </title> <journal> SIAM Journal on Computing, </journal> <volume> 15(1) </volume> <pages> 87-97, </pages> <month> Feb. </month> <year> 1986. </year>
Reference-contexts: It is interesting to note that similar but not identical notions of "ownership" have proven useful in practice in certain cache coherence protocols [1], and have appeared in earlier lower bound work <ref> [4, 13] </ref>. Pointer Machines: Pointer-based data structures are ubiquitous in sequential algorithms. One reason to study pointer-based computation is that useful lower bounds may be more easily obtained in such a structured model. For examples, see [23, 17, 2]. <p> [0] successor (L [0]) Conditionally change low order bit from 0 to 1 L [3] successor (L [1]) L [3] has value 1 or 2 L [1] L [0] L [0] L [L [3]] Choose between L [1] and L [2] L [3] M [2i] Temporarily save the values L <ref> [4] </ref> M [2i + 1] in the global memory cells. M [2i] L [1] Move the necessary values from M [2i + 1] L [2] local to global memory. L [0] 1-concatenate (i; L [0]) Concatenate the first argument to the end of the processor number, i. <p> L [0] 1-concatenate (i; L [0]) Concatenate the first argument to the end of the processor number, i. L [0] M [L [0]] Determine the answer using (indirect) read from global memory. M [2i] L [3] Restore the global memory cells. M [2i + 1] L <ref> [4] </ref> Furthermore, 1-concatenate can simulate 2-limited indirect addressing of local memory. The idea is for processor P i to temporarily use the global memory cells M [2i] and M [2i + 1] in place of its local memory cells L [1] and L [2]. <p> This result is within a constant factor of optimal, since even on a CREW PRAM with an unlimited number of processors and an arbitrarily powerful instruction set, computing the OR of n Boolean values requires (log n) steps <ref> [4] </ref>. It is also possible to solve multiple instances of the k-join problem in parallel, although determining which cell a processor should access is somewhat more complicated.
Reference: [5] <author> S. A. Cook and P. W. Dymond. </author> <title> Parallel pointer machines, </title> <note> 1991. Submitted. </note>
Reference-contexts: The notion of parallel computation by pointer manipulation is formally captured by the PPM 1 , studied by Dymond and Cook <ref> [3, 7, 5] </ref>. In brief, the model consists of a collection of finite state units, each with a fixed number of pointers to other units. Each unit can read the state of, and/or copy the pointers of, the units to which it points. <p> Each unit can read the state of, and/or copy the pointers of, the units to which it points. Also, in each step, a unit may create and initialize a new unit. (See [7] or <ref> [5] </ref> for a more complete definition.) Lam and Ruzzo [19] proved the equivalence of PPMs and a restricted version of the CROW PRAM, namely one stripped of arithmetic capabilities except for the successor (+1) and double (fi2) operations. <p> As one important example, the "pointer doubling" technique of Fortune and Wyllie [14] has been used to show that DSPACE (log n) can be simulated by a PPM in time O (log n) <ref> [7, 5] </ref>. To relate pointer machines to PRAMs, it is not hard to see that a PRAM can perform a step-by-step simulation of a PPM, by maintaining the PPM's pointer structure in global memory. Of course, the characterization results cited above make the relationship between PPMs and PRAMs more concrete. <p> In the course of constructing these tables, we will coincidentally activate the correct number of processors. (The rCROW, as defined in [19], as well as the PPM, as defined in <ref> [3, 7, 5] </ref>, are forking models. That is, there is only one initially active processor; others are activated by fork instructions.
Reference: [6] <author> P. W. Dymond. </author> <title> Indirect addressing and the time relationships of some models of sequential computation. </title> <journal> Int. J. of Computers and Math. with Applications, </journal> <volume> 5 </volume> <pages> 195-209, </pages> <year> 1979. </year>
Reference-contexts: All three of our lower bounds are tight, as will be shown in Section 4. The lower bound proof technique was partly inspired by results of Dymond concerning sequential RAMs <ref> [6] </ref>, but the PRAM case is substantially more difficult.
Reference: [7] <author> P. W. Dymond and S. A. Cook. </author> <title> Hardware complexity and parallel computation. </title> <booktitle> In 21st Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 360-372, </pages> <address> Syracuse, NY, </address> <month> Oct. </month> <year> 1980. </year> <note> IEEE. </note>
Reference-contexts: The notion of parallel computation by pointer manipulation is formally captured by the PPM 1 , studied by Dymond and Cook <ref> [3, 7, 5] </ref>. In brief, the model consists of a collection of finite state units, each with a fixed number of pointers to other units. Each unit can read the state of, and/or copy the pointers of, the units to which it points. <p> Each unit can read the state of, and/or copy the pointers of, the units to which it points. Also, in each step, a unit may create and initialize a new unit. (See <ref> [7] </ref> or [5] for a more complete definition.) Lam and Ruzzo [19] proved the equivalence of PPMs and a restricted version of the CROW PRAM, namely one stripped of arithmetic capabilities except for the successor (+1) and double (fi2) operations. <p> As one important example, the "pointer doubling" technique of Fortune and Wyllie [14] has been used to show that DSPACE (log n) can be simulated by a PPM in time O (log n) <ref> [7, 5] </ref>. To relate pointer machines to PRAMs, it is not hard to see that a PRAM can perform a step-by-step simulation of a PPM, by maintaining the PPM's pointer structure in global memory. Of course, the characterization results cited above make the relationship between PPMs and PRAMs more concrete. <p> In the course of constructing these tables, we will coincidentally activate the correct number of processors. (The rCROW, as defined in [19], as well as the PPM, as defined in <ref> [3, 7, 5] </ref>, are forking models. That is, there is only one initially active processor; others are activated by fork instructions.
Reference: [8] <author> P. W. Dymond and W. L. Ruzzo. </author> <title> Parallel random access machines with owned global memory and deterministic context-free language recognition. </title> <editor> In L. Kott, editor, </editor> <booktitle> Automata, Languages, and Programming: 13th International Colloquium, volume 226 of Lecture Notes in Computer Science, </booktitle> <pages> pages 95-104, </pages> <publisher> Rennes, </publisher> <address> France, July 1986. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: In this paper we take a modest step towards this difficult goal by proving a separation between PRAMs with restricted arithmetic capabilities, and ones with more normal arithmetic operations. Below we outline prior work and our results in more detail. CROW PRAMs: Dymond and Ruzzo <ref> [8] </ref> observe that most known Concurrent Read, Exclusive Write (CREW) PRAM algorithms guarantee write-exclusion by the simple stratagem of assigning an owner to each global memory cell and requiring that the owner of a memory cell be the only processor allowed to write into the cell. <p> The known relationships among the various complexity classes described above are summarized in Figure 1. The open problem that motivated the present paper was the question of whether the simulation of rCROWs by Parallel Pointer Machines could be extended to the more general CROW PRAM model considered in <ref> [8] </ref>. Specifically, could a PPM simulate addition? On the one hand, "adding" two unrelated pointers seems difficult. On the other hand, by [8] it would suffice if one could do DCFL recognition on a PPM, and the DCFL recognition algorithm given in [8] is basically a generalization of the pointer doubling <p> the present paper was the question of whether the simulation of rCROWs by Parallel Pointer Machines could be extended to the more general CROW PRAM model considered in <ref> [8] </ref>. Specifically, could a PPM simulate addition? On the one hand, "adding" two unrelated pointers seems difficult. On the other hand, by [8] it would suffice if one could do DCFL recognition on a PPM, and the DCFL recognition algorithm given in [8] is basically a generalization of the pointer doubling algorithm. Thus, it doesn't seem out of the question that one could show equality between PPMs and CROW PRAMs. <p> the more general CROW PRAM model considered in <ref> [8] </ref>. Specifically, could a PPM simulate addition? On the one hand, "adding" two unrelated pointers seems difficult. On the other hand, by [8] it would suffice if one could do DCFL recognition on a PPM, and the DCFL recognition algorithm given in [8] is basically a generalization of the pointer doubling algorithm. Thus, it doesn't seem out of the question that one could show equality between PPMs and CROW PRAMs. <p> codomain f1; : : : ; n 2 g is an example, as is the function that concatenates the dlog 2 ne-bit binary representations of x and y. (The latter is the function used by our upper bound algorithm.) The pairing problem was motivated by the DCFL recognition algorithm of <ref> [8] </ref>, a key component of which was accessing a two dimensional array. It is easy to see that a pairing function can be computed by one processor in constant time, given a simple precomputed table of multiples of n and an addition instruction. <p> It is weaker than most other CRCW PRAMs. For more details, see [12], [9], [16], [11]. A concurrent-read, owner-write (CROW) PRAM <ref> [8] </ref> is a CREW PRAM in which each global memory cell is owned by a single processor; only the owner of a global memory cell may write to it. Note that processors may own many different global memory cells.
Reference: [9] <author> D. Eppstein and Z. Galil. </author> <booktitle> Parallel Algorithmic Techniques for Combinatorial Computation, </booktitle> <pages> pages 233-283. </pages> <booktitle> Annual Reviews in Computer Science. Annual Reviews, </booktitle> <publisher> Inc., </publisher> <year> 1988. </year>
Reference-contexts: A ROBUST PRAM resolves write conflicts in a completely arbitrary way | i.e., no assumption may be made about the final value in a cell at which a write conflict occurred. It is weaker than most other CRCW PRAMs. For more details, see [12], <ref> [9] </ref>, [16], [11]. A concurrent-read, owner-write (CROW) PRAM [8] is a CREW PRAM in which each global memory cell is owned by a single processor; only the owner of a global memory cell may write to it. Note that processors may own many different global memory cells. <p> The MAXIMUM PRAM <ref> [9] </ref> is an example of such a model. Clearly, the lower bound does not apply to a PRAM in which the value that appears as the result of a write conflict is the sum of the values written.
Reference: [10] <author> F. E. Fich. </author> <title> The complexity of computation on the parallel random access machine. </title> <editor> In J. H. Reif, editor, </editor> <title> Synthesis of Parallel Algorithms. </title> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year> <note> To appear. </note>
Reference-contexts: Then the logarithm of f 's decision tree complexity characterizes to within a constant factor the time for a (nonuniform) CREW PRAM with an arbitrarily powerful instruction set to compute f <ref> [21, 10] </ref>. With normal arithmetic capabilities, a nonuniform CROW PRAM can evaluate any decision tree of height h and size s in dlog 2 he + O (1) steps using s processors, by pointer jumping (Ragde, personal communication; see also [21, 10]). <p> PRAM with an arbitrarily powerful instruction set to compute f <ref> [21, 10] </ref>. With normal arithmetic capabilities, a nonuniform CROW PRAM can evaluate any decision tree of height h and size s in dlog 2 he + O (1) steps using s processors, by pointer jumping (Ragde, personal communication; see also [21, 10]). Preinitialized memory is used to specify the decision tree, naming the input variable to be tested at each internal node, the out-edges from each, and the function value at each leaf. Addition is used to index into the list of out-edges at each internal node in constant time.
Reference: [11] <author> F. E. Fich, R. Impagliazzo, B. Kapron, V. King, and M. Kuty lowski. </author> <title> Limits on the power of parallel random access machines with weak forms of write conflict resolution. </title> <booktitle> In 10th Annual Symposium on Theoretical Aspects of Computer Science, Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: A ROBUST PRAM resolves write conflicts in a completely arbitrary way | i.e., no assumption may be made about the final value in a cell at which a write conflict occurred. It is weaker than most other CRCW PRAMs. For more details, see [12], [9], [16], <ref> [11] </ref>. A concurrent-read, owner-write (CROW) PRAM [8] is a CREW PRAM in which each global memory cell is owned by a single processor; only the owner of a global memory cell may write to it. Note that processors may own many different global memory cells.
Reference: [12] <author> F. E. Fich, P. Ragde, and A. Wigderson. </author> <title> Relations between concurrent-write models of parallel computation. </title> <journal> SIAM Journal on Computing, </journal> <volume> 17 </volume> <pages> 606-627, </pages> <year> 1988. </year>
Reference-contexts: A ROBUST PRAM resolves write conflicts in a completely arbitrary way | i.e., no assumption may be made about the final value in a cell at which a write conflict occurred. It is weaker than most other CRCW PRAMs. For more details, see <ref> [12] </ref>, [9], [16], [11]. A concurrent-read, owner-write (CROW) PRAM [8] is a CREW PRAM in which each global memory cell is owned by a single processor; only the owner of a global memory cell may write to it. Note that processors may own many different global memory cells.
Reference: [13] <author> F. E. Fich and A. Wigderson. </author> <title> Towards understanding exclusive read. </title> <journal> SIAM Journal on Computing, </journal> <volume> 19(4) </volume> <pages> 717-727, </pages> <year> 1990. </year>
Reference-contexts: It is interesting to note that similar but not identical notions of "ownership" have proven useful in practice in certain cache coherence protocols [1], and have appeared in earlier lower bound work <ref> [4, 13] </ref>. Pointer Machines: Pointer-based data structures are ubiquitous in sequential algorithms. One reason to study pointer-based computation is that useful lower bounds may be more easily obtained in such a structured model. For examples, see [23, 17, 2].
Reference: [14] <author> S. Fortune and J. Wyllie. </author> <title> Parallelism in random access machines. </title> <booktitle> In Proceedings of the Tenth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 114-118, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1978. </year>
Reference-contexts: DSPACE (log n) and AC 1 .) It is important to note that these results apply to CROW PRAMs having a simple instruction set, basically including only indirect addressing, conditional branching, and addition. (To be precise, it is exactly the instruction set of the CREW PRAM of Fortune and Wyllie <ref> [14] </ref>.) For definiteness, the term "CROW PRAM" below will refer to this model unless otherwise qualified. It is interesting to note that similar but not identical notions of "ownership" have proven useful in practice in certain cache coherence protocols [1], and have appeared in earlier lower bound work [4, 13]. <p> Parallel Pointer Machines versus PRAMs: How powerful are Parallel Pointer Machines? A variety of parallel algorithms have been adapted to PPMs. As one important example, the "pointer doubling" technique of Fortune and Wyllie <ref> [14] </ref> has been used to show that DSPACE (log n) can be simulated by a PPM in time O (log n) [7, 5].
Reference: [15] <author> M. T. Goodrich and S. R. Kosaraju. </author> <title> Sorting on a parallel pointer machine with applications to set expression evaluation. </title> <booktitle> In 30th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 190-195, </pages> <address> Research Triangle Park, NC, </address> <month> Oct. </month> <year> 1989. </year> <note> IEEE. Preliminary version. 21 </note>
Reference-contexts: Adding 1 In the earlier papers, the PPM is called an HMM, or Hardware Modification Machine, by analogy to Schonhage's SMM. The PPM considered subsequently by Goodrich and Kosaraju <ref> [15] </ref> is a more complex model having both pointers and integer arithmetic. 3 AC 0 ( NC 1 DSPACE (log n) 8 : rCROW (log n) 9 ; 8 : LOGDCFL CROW (log n) 9 ; 8 : CRCW (log n) 9 ; certain other simple unary functions such as those
Reference: [16] <author> T. Hagerup and T. Radzik. </author> <title> Every robust CRCW PRAM can efficiently simulate a Priority PRAM. </title> <booktitle> In Proceedings of the 1990 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 117-124, </pages> <address> Crete, Greece, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: A ROBUST PRAM resolves write conflicts in a completely arbitrary way | i.e., no assumption may be made about the final value in a cell at which a write conflict occurred. It is weaker than most other CRCW PRAMs. For more details, see [12], [9], <ref> [16] </ref>, [11]. A concurrent-read, owner-write (CROW) PRAM [8] is a CREW PRAM in which each global memory cell is owned by a single processor; only the owner of a global memory cell may write to it. Note that processors may own many different global memory cells.
Reference: [17] <author> D. Harel and R. E. Tarjan. </author> <title> Fast algorithms for finding nearest common ancestors. </title> <journal> SIAM Journal on Computing, </journal> <volume> 13(2) </volume> <pages> 338-355, </pages> <month> May </month> <year> 1984. </year>
Reference-contexts: Pointer Machines: Pointer-based data structures are ubiquitous in sequential algorithms. One reason to study pointer-based computation is that useful lower bounds may be more easily obtained in such a structured model. For examples, see <ref> [23, 17, 2] </ref>. The Storage Modification Machine (SMM) or Pointer Machine is a formal model that captures the notion of sequential computation by pointer manipulation.
Reference: [18] <author> R. M. Karp and V. Ramachandran. </author> <title> Parallel algorithms for shared-memory machines. </title> <editor> In J. van Leeuwan, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, volume A: Algorithms and Complexity, chapter 17, </booktitle> <pages> pages 869-941. </pages> <publisher> M.I.T. </publisher> <address> Press/Elsevier, </address> <year> 1990. </year>
Reference-contexts: We will consider uniform versions below.) Note that the only processor to write into M [i] is P i , i.e., the algorithm obeys the owner write restriction with P i owning M [i]. 2 Using standard techniques <ref> [18] </ref>, the number of processors can be improved to 2 k =k O (1) , while only increasing the time by a constant factor.
Reference: [19] <author> T. W. Lam and W. L. Ruzzo. </author> <title> The power of parallel pointer manipulation. </title> <booktitle> In Proceedings of the 1989 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 92-102, </pages> <address> Santa Fe, NM, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: Each unit can read the state of, and/or copy the pointers of, the units to which it points. Also, in each step, a unit may create and initialize a new unit. (See [7] or [5] for a more complete definition.) Lam and Ruzzo <ref> [19] </ref> proved the equivalence of PPMs and a restricted version of the CROW PRAM, namely one stripped of arithmetic capabilities except for the successor (+1) and double (fi2) operations. <p> In the course of constructing these tables, we will coincidentally activate the correct number of processors. (The rCROW, as defined in <ref> [19] </ref>, as well as the PPM, as defined in [3, 7, 5], are forking models. That is, there is only one initially active processor; others are activated by fork instructions. <p> We sketch below how this can be done. Some of the techniques are borrowed from <ref> [19] </ref>, and, incidentally, illustrate a few of the ideas used there to simulate rCROWs by Parallel Pointer Machines. 18 Lemma 13 For fixed integers n; k; l; c; e, and h, where k; e = O (log n), l = 2 e , c &gt; 0, and h = c dlog
Reference: [20] <editor> Logic and Algorithmic, </editor> <booktitle> An International Symposium Held in Honor of Ernst Specker, </booktitle> <address> Zurich, </address> <month> Feb. </month> <pages> 5-11, </pages> <year> 1980. </year> <note> Monographie No. </note> <institution> 30 de L'Enseignement Mathematique, Universite de Geneve, </institution> <year> 1982. </year>
Reference: [21] <author> N. </author> <title> Nisan. </title> <booktitle> CREW PRAMs and decision trees In Proceedings of the Twenty First Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 327-335, </pages> <address> Seattle, WA, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: Then the logarithm of f 's decision tree complexity characterizes to within a constant factor the time for a (nonuniform) CREW PRAM with an arbitrarily powerful instruction set to compute f <ref> [21, 10] </ref>. With normal arithmetic capabilities, a nonuniform CROW PRAM can evaluate any decision tree of height h and size s in dlog 2 he + O (1) steps using s processors, by pointer jumping (Ragde, personal communication; see also [21, 10]). <p> PRAM with an arbitrarily powerful instruction set to compute f <ref> [21, 10] </ref>. With normal arithmetic capabilities, a nonuniform CROW PRAM can evaluate any decision tree of height h and size s in dlog 2 he + O (1) steps using s processors, by pointer jumping (Ragde, personal communication; see also [21, 10]). Preinitialized memory is used to specify the decision tree, naming the input variable to be tested at each internal node, the out-edges from each, and the function value at each leaf. Addition is used to index into the list of out-edges at each internal node in constant time.
Reference: [22] <author> A. Schonhage. </author> <title> Storage modification machines. </title> <journal> SIAM Journal on Computing, </journal> <volume> 9(3) </volume> <pages> 490-508, </pages> <month> Aug. </month> <year> 1980. </year>
Reference-contexts: Deep insight into the power of such machines is provided by Schonhage's demonstration of the equivalence of SMMs and unit-cost successor RAMs, i.e., ordinary unit cost RAMs stripped of all arithmetic capabilities except for the successor, or +1 operation <ref> [22] </ref>. The notion of parallel computation by pointer manipulation is formally captured by the PPM 1 , studied by Dymond and Cook [3, 7, 5]. In brief, the model consists of a collection of finite state units, each with a fixed number of pointers to other units.
Reference: [23] <author> R. E. Tarjan. </author> <title> A class of algorithms which require nonlinear time to maintain disjoint sets. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 18 </volume> <pages> 110-127, </pages> <year> 1979. </year>
Reference-contexts: Pointer Machines: Pointer-based data structures are ubiquitous in sequential algorithms. One reason to study pointer-based computation is that useful lower bounds may be more easily obtained in such a structured model. For examples, see <ref> [23, 17, 2] </ref>. The Storage Modification Machine (SMM) or Pointer Machine is a formal model that captures the notion of sequential computation by pointer manipulation.
Reference: [24] <author> L. G. Valiant. </author> <title> A bridging model for parallel computation. </title> <journal> Communications of the ACM, </journal> <volume> 33(8) </volume> <pages> 103-111, </pages> <month> Aug. </month> <year> 1990. </year> <note> (RCS Revision: 1.56 Date: 1993/05/12 06:04:07) </note>
Reference-contexts: Nevertheless, the model is often criticized for being too powerful to correspond to realistic computer architectures. At this point the right (i.e., most useful) parallel model for bridging the gap between algorithms and architectures is still not settled <ref> [24] </ref>. This motivates further study of restrictions on the PRAM model, and the power of its arithmetic and addressing instructions. Memory restrictions (e.g., CRCW versus CREW) have already been widely studied.
References-found: 24

