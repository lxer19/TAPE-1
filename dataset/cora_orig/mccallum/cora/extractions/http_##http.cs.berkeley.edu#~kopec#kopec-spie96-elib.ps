URL: http://http.cs.berkeley.edu/~kopec/kopec-spie96-elib.ps
Refering-URL: http://elib.cs.berkeley.edu:8080/admin/quarterly_reports/report.95.html
Root-URL: 
Title: Document Image Decoding in the UC Berkeley Digital Library  
Author: Gary E. Kopec 
Affiliation: Xerox PARC  
Abstract: The UC Berkeley Environmental Digital Library Project is one of six university-led projects that were initiated in the fall of 1994 as part of a four-year digital library initiative sponsored by the NSF, NASA and ARPA. The Berkeley project is particularly interesting from a document image analysis perspective because its testbed collection consists almost entirely of scanned materials. As a result, the Berkeley project is making extensive use of document recognition and other image analysis technology to provide content-based access to the collection. The Document Image Decoding (DID) group at Xerox PARC is a member of the Berkeley team and is investigating the application of DID techniques to providing high-quality (accurate and properly structured) transcriptions of scanned documents in the collection. This paper briefly describes the Berkeley project, discusses some of its recognition requirements and presents examples of online structured documents created using DID technology. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> California Dept. </author> <title> of Water Resources, General Comparison of Water District Acts, </title> <journal> Bulletin 155-94, </journal> <month> March, </month> <year> 1994. </year>
Reference-contexts: The following is a brief summary of a quantitative evaluation of the method using one of the environmental documents; full details are presented in [7, 8]. *** Kopec, SPIE '96 *** 4 Bulletin 155 (B155) <ref> [1] </ref> is a DWR report that summarizes the provisions of 157 California state water district acts. The information about the acts is presented in 375 pages of two-column tables; Fig. 5 shows a portion of one table.
Reference: [2] <institution> California Dept. of Water Resources, Dams Within Jurisdiction of the State of California, </institution> <note> Bulletin 17-93, </note> <month> June, </month> <year> 1993. </year>
Reference-contexts: Thus, omni-document recognition technology is unlikely to provide much support for true content-based access for the foreseeable future. The problems of OCR accuracy and information structure can be illustrated using one of the documents from the Berkeley testbed. Bulletin 17 (B17) <ref> [2] </ref> is a report by the California Department of Water Resources (DWR) that provides information about 1395 dams in California. The bulk of the printed bulletin is a single 90 page table with one three-line entry for each dam. Fig. 2 shows a portion of one page.
Reference: [3] <author> P. Chou and G. Kopec, </author> <title> A stochastic attribute grammar model of document production and its use in document image decoding, Document Recognition II, </title> <editor> L. Vincent and H. Baird, editors, </editor> <booktitle> Proc. SPIE vol. </booktitle> <volume> 2422, </volume> <pages> pp. 66-73, </pages> <year> 1995. </year> *** <title> Kopec, </title> <type> SPIE '96 *** 9 </type>
Reference-contexts: In the current implementation, the specialized decoders are in-line C programs that are compiled and linked with a support library. The most general document models formulated in DID theory take the form of stochastic attributed context-free grammars <ref> [3] </ref>. Most of the published algorithmic and implementation work has focussed on a special class of finite-state (Markov) source models that use a simple displacement-based attribute set. These models have proven extremely powerful in decoding material that can be viewed as essentially a single column of formatted text lines.
Reference: [4] <author> M. Hearst, </author> <title> Context and Structure in Automated Full-Text Information Access, </title> <institution> UC Berkeley Computer Science Technical Report UCB:CSD-94-836. </institution>
Reference-contexts: A simple page-based viewer provides standard next page / previous page navigation. For rapid browsing, the recognized text of a document can be viewed as a continuous ASCII file with embedded links to the page images, a format called hyper-OCR. Advanced viewers include a tile bars <ref> [4] </ref> interface to documents retrieved by full-text search and an experimental image browser based on the multivalent document (MVD) paradigm [9]. The MVD browser uses word location information provided by ScanWorX to highlight search terms and provide text select-and-paste from the page image to a text input buffer.
Reference: [5] <author> G. Kopec and P. Chou, </author> <title> Automatic generation of custom document image decoders, </title> <booktitle> Proc. Second Intl. Conf. on Document Analysis and Recognition, </booktitle> <address> Tsukuba Science City, Japan, </address> <month> Oct. </month> <pages> 20-22, </pages> <year> 1993. </year>
Reference-contexts: DID is an approach to document image analysis that is based on an explicit communication theory view of the processes of document creation, transmission and interpretation. The theoretical and algorithmic foundations of DID and document-specific decoding have been discussed in detail elsewhere <ref> [6, 5, 7, 8] </ref>. In this paper we describe its application to high-accuracy OCR and structured information extraction in the Berkeley project. 2. <p> The goal of DID in this regard is to support the automatic generation of custom recognizers from declarative specifications, in a manner analogous to the way LEX and YACC generate character string parsers from language grammars <ref> [5] </ref>. The overall vision is summarized in fig. 6.
Reference: [6] <author> G. Kopec and P. Chou, </author> <title> Document image decoding using Markov source models, </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 16, no. 6, </volume> <month> June, </month> <year> 1994, </year> <pages> pp. 602-617. </pages>
Reference-contexts: The general goal of the document recognition research component of the Berkeley project is improve the accuracy and structuring of the information extracted from scanned documents. The technical approach being followed is the use of document-specific decoders within the document image decoding (DID) framework <ref> [6] </ref>. DID is an approach to document image analysis that is based on an explicit communication theory view of the processes of document creation, transmission and interpretation. The theoretical and algorithmic foundations of DID and document-specific decoding have been discussed in detail elsewhere [6, 5, 7, 8]. <p> DID is an approach to document image analysis that is based on an explicit communication theory view of the processes of document creation, transmission and interpretation. The theoretical and algorithmic foundations of DID and document-specific decoding have been discussed in detail elsewhere <ref> [6, 5, 7, 8] </ref>. In this paper we describe its application to high-accuracy OCR and structured information extraction in the Berkeley project. 2.
Reference: [7] <author> G. Kopec and M. Lomelin, </author> <title> Document image decoding approach to character template estimation, </title> <journal> submitted to IEEE. Trans. Pattern Analysis and Machine Intelligence, </journal> <month> Nov., </month> <year> 1995. </year>
Reference-contexts: DID is an approach to document image analysis that is based on an explicit communication theory view of the processes of document creation, transmission and interpretation. The theoretical and algorithmic foundations of DID and document-specific decoding have been discussed in detail elsewhere <ref> [6, 5, 7, 8] </ref>. In this paper we describe its application to high-accuracy OCR and structured information extraction in the Berkeley project. 2. <p> If the document is large enough, the cost of creating the specialized templates will be more than offset by a reduced need for post-recognition proofreading and error correction. A DID approach to supervised template estimation that supports the document-specific decoding paradigm has been described in detail elsewhere <ref> [7, 8] </ref>. The following is a brief summary of a quantitative evaluation of the method using one of the environmental documents; full details are presented in [7, 8]. *** Kopec, SPIE '96 *** 4 Bulletin 155 (B155) [1] is a DWR report that summarizes the provisions of 157 California state water <p> A DID approach to supervised template estimation that supports the document-specific decoding paradigm has been described in detail elsewhere <ref> [7, 8] </ref>. The following is a brief summary of a quantitative evaluation of the method using one of the environmental documents; full details are presented in [7, 8]. *** Kopec, SPIE '96 *** 4 Bulletin 155 (B155) [1] is a DWR report that summarizes the provisions of 157 California state water district acts. The information about the acts is presented in 375 pages of two-column tables; Fig. 5 shows a portion of one table.
Reference: [8] <author> G. Kopec and M. Lomelin, </author> <title> Document-Specific Character Template Estimation, </title> <booktitle> IS&T/SPIE 1996 Intl. Symposium on Electronic Imaging: Science & Technology, </booktitle> <address> San Jose, CA, Jan. 27-Feb. 2, </address> <year> 1996. </year>
Reference-contexts: DID is an approach to document image analysis that is based on an explicit communication theory view of the processes of document creation, transmission and interpretation. The theoretical and algorithmic foundations of DID and document-specific decoding have been discussed in detail elsewhere <ref> [6, 5, 7, 8] </ref>. In this paper we describe its application to high-accuracy OCR and structured information extraction in the Berkeley project. 2. <p> If the document is large enough, the cost of creating the specialized templates will be more than offset by a reduced need for post-recognition proofreading and error correction. A DID approach to supervised template estimation that supports the document-specific decoding paradigm has been described in detail elsewhere <ref> [7, 8] </ref>. The following is a brief summary of a quantitative evaluation of the method using one of the environmental documents; full details are presented in [7, 8]. *** Kopec, SPIE '96 *** 4 Bulletin 155 (B155) [1] is a DWR report that summarizes the provisions of 157 California state water <p> A DID approach to supervised template estimation that supports the document-specific decoding paradigm has been described in detail elsewhere <ref> [7, 8] </ref>. The following is a brief summary of a quantitative evaluation of the method using one of the environmental documents; full details are presented in [7, 8]. *** Kopec, SPIE '96 *** 4 Bulletin 155 (B155) [1] is a DWR report that summarizes the provisions of 157 California state water district acts. The information about the acts is presented in 375 pages of two-column tables; Fig. 5 shows a portion of one table.
Reference: [9] <author> T. Phelps and R. Wilensky, </author> <title> Toward active, extensible, networked documents: </title> <booktitle> multivalent architecture and applications, to appear in Proc. ACM Digital Libraries '96, </booktitle> <address> Bethesda, MD, </address> <month> Mar. </month> <pages> 20-23, </pages> <year> 1996. </year>
Reference-contexts: Advanced viewers include a tile bars [4] interface to documents retrieved by full-text search and an experimental image browser based on the multivalent document (MVD) paradigm <ref> [9] </ref>. The MVD browser uses word location information provided by ScanWorX to highlight search terms and provide text select-and-paste from the page image to a text input buffer. Fig. 1 shows some of the capabilities of the current production version of the MVD browser.
Reference: [10] <author> J. Wang, </author> <title> Fishes of the Sacramento-San Joaquin Estuary and Adjacent Waters, California: A Guide to the Early Life Histories, </title> <type> Technical Report 6, </type> <institution> Prepared for the Interagency Ecological Study Program for the Sacramento-San Joaquin Estuary, </institution> <month> Jan., </month> <year> 1986. </year> *** <title> Kopec, </title> <type> SPIE '96 *** 10 </type>
Reference-contexts: FUTURE PLANS Over the next six months, a number of additional examples of advanced structured documents will be constructed. After consultation with the testbed user group, it is likely that the next one will be a large (650 page) catalog describing 125 species of fish <ref> [10] </ref>. Simultaneously with these case studies, generators and decoding algorithms for more general types of document image models will developed. As noted above, it is expected that the amont of hand-crafted code used in the examples will decrease as this technology is deployed.
Reference: [11] <author> R. Wilensky, </author> <title> Toward work-centered digital information services, </title> <note> to appear in IEEE Computer, special issue on Building Large-scale Digital Libraries, </note> <month> May, </month> <year> 1996. </year> *** <title> Kopec, </title> <type> SPIE '96 *** 11 *** Kopec, SPIE '96 *** 12 </type>
Reference-contexts: 1. INTRODUCTION The UC Berkeley Environmental Digital Library Project is one of six university-led projects that were initiated in the fall of 1994 as part of a four-year digital library initiative sponsored by the NSF, NASA and ARPA <ref> [11] </ref>. The Berkeley project is particularly interesting from a document image analysis perspective because its testbed collection consists almost entirely of scanned materials. <p> The button labeled Photo? issues a query to the ground photograph database to look for color pictures of the dam using the Cypress client <ref> [11] </ref>. Unlike B155, the printed table in B17 is not ruled. Moreover, each logical record of the table is folded into three unaligned lines in the printed document. Thus, extracting the labeled fields from B17 was significantly more complicated than finding the table cells of B155.
References-found: 11

