URL: http://www-cad.eecs.berkeley.edu/~sriramr/fccm.dlx.ps
Refering-URL: http://www-cad.eecs.berkeley.edu/~sriramr/research.html
Root-URL: 
Email: sriramr@cs.berkeley.edu pvi@cs.berkeley.edu  
Title: A Quantitative Analysis of Processor Programmable Logic Interface  
Author: Sriram Rajamani Pramod Viswanath 
Address: Berkeley, CA 94720 Berkeley, CA 94720  
Affiliation: Department of EECS Department of EECS University of California, Berkeley University of California, Berkeley  
Abstract: The addition of programmable logic to RISC machines has the potential of exploiting the inherent parallelism of hardware to speedup an application. In this paper, we study the effect of adding a programmable accelerator to DLX, a RISC prototype. We build this model and parameterize the communication overhead between the processor and programmable unit and logic/routing delays inside the programmable unit. We use simulation to evaluate the performance of this model, parameterized by communication overhead and logic delays, by comparing it with the baseline DLX architecture on some sample problems. Our methodology is useful in studying the relative importance of the parameters and in projecting the performance of the system, if the programmable logic were to be implemented inside the processor. Key Words: Programmable Logic, FPGA, Hardware-Software Co-design, RISC. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. F. Silverman et. al, </author> <title> Processor Reconfiguration Through Instruction-Set Metamorphosis, </title> <journal> IEEE Computer, </journal> <volume> 23(3) </volume> <pages> 11-18, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: By this parameterization, we can study the general problem, by abstracting out considerations as to whether the programmable unit is on the processor chip or on a separate chip. The references <ref> [1] </ref>, [2] report speedups for several arithmetic operations. The question we ask is: How fast should the communication and logic execution get in order for this type of hardware acceleration to be viable? (This question is in the context of the specific applications we study). <p> This is an active research area by itself [12]. Due to the recent success and popularity of FPGAs, several systems have been built with a programmable unit added on to a host system. PRISM <ref> [1] </ref> [2] developed at Brown University demonstrates the use of reconfigurable logic to obtain substantial speedup in the case of large regular binary operations. DEC Paris's PAM (Programmable Active Memories) is an array of Xilinx FPGAs attached to a host work station [3]. <p> The RISC processor we choose is DLX. DLX is a simple processor, representative of the current generation of RISC processors. UC Berkeley has a DLX simulator and the Gnu-C-Compiler targeted for DLX [21]. The program interface for the programmable unit follows Instruction-Set Metamorphosis as proposed in <ref> [1] </ref> i.e, new instructions are added to the processor. The new instructions are implemented by modifying the simulator. Our primary measure of performance is execution time. We compare execution times of an application with and without the programmable unit added to the processor.
Reference: [2] <editor> M. Walzlowski et. al, </editor> <booktitle> PRISM-II Compiler and Architecture, Proceedings of the IEEE worksop on FPGAs for Custom Computing Machines 1993, </booktitle> <pages> pp 9-16. </pages>
Reference-contexts: By this parameterization, we can study the general problem, by abstracting out considerations as to whether the programmable unit is on the processor chip or on a separate chip. The references [1], <ref> [2] </ref> report speedups for several arithmetic operations. The question we ask is: How fast should the communication and logic execution get in order for this type of hardware acceleration to be viable? (This question is in the context of the specific applications we study). <p> This is an active research area by itself [12]. Due to the recent success and popularity of FPGAs, several systems have been built with a programmable unit added on to a host system. PRISM [1] <ref> [2] </ref> developed at Brown University demonstrates the use of reconfigurable logic to obtain substantial speedup in the case of large regular binary operations. DEC Paris's PAM (Programmable Active Memories) is an array of Xilinx FPGAs attached to a host work station [3].
Reference: [3] <author> P.Bertin and H.Touati, </author> <title> PAM Programming Environments: Practice and Experience, </title> <booktitle> Proceedings of the IEEE worksop on FPGAs for Custom Computing Machines 1993, </booktitle> <pages> pp 9-16. </pages>
Reference-contexts: PRISM [1] [2] developed at Brown University demonstrates the use of reconfigurable logic to obtain substantial speedup in the case of large regular binary operations. DEC Paris's PAM (Programmable Active Memories) is an array of Xilinx FPGAs attached to a host work station <ref> [3] </ref>. The Super computing Research Center in Maryland has built a system called SPLASH [4]. SPLASH has been used to speed up genome sequence matching applications. We find that the existing literature does not analyze the effect of processor-programmable-logic-interface on the performance of the system.
Reference: [4] <author> D.Lopresti, </author> <title> Rapid Implementation of a Genetic Sequence Comparator using Field-Programmable Logic Arrays, </title> <booktitle> Advanced Research in VLSI, </booktitle> <month> April </month> <year> 1991, </year> <pages> pp 138-152. </pages>
Reference-contexts: DEC Paris's PAM (Programmable Active Memories) is an array of Xilinx FPGAs attached to a host work station [3]. The Super computing Research Center in Maryland has built a system called SPLASH <ref> [4] </ref>. SPLASH has been used to speed up genome sequence matching applications. We find that the existing literature does not analyze the effect of processor-programmable-logic-interface on the performance of the system.
Reference: [5] <author> M.Shand and J.Vuillemin, </author> <title> Fast Implementations of RSA Cryptography, </title> <booktitle> Proceedings of the 11th Symposium on Computer Arithmetic, </booktitle> <year> 1993, </year> <pages> pp. 252-259. </pages>
Reference: [6] <author> Andre DeHon, </author> <title> DPGA-Coupled Microprocessors: </title> <booktitle> Commodity ICs for the Early 21st Century, Proceedings of the IEEE worksop on FPGAs for Custom Computing Machines 1994, </booktitle> <pages> pp 31-39. </pages>
Reference-contexts: Improving processor-FPGA communication delays sounds more plausible. One could conceive the FPGA and the processor being in the same chip as suggested in <ref> [6] </ref>. As mentioned before, it will be useful to compare performance of the DLX-FPGA system for the MPEG decoder, with a two-issue superscalar DLX. We are cur rently building the infrastructure to make this comparison.
Reference: [7] <author> Jeffrey M. Arnold, </author> <title> The Splash 2 Software Environment, </title> <booktitle> Proceedings of the IEEE worksop on FPGAs for Custom Computing Machines 1993, </booktitle> <pages> pp 88 - 93. </pages>
Reference-contexts: A very general and flexible interface between the processor and the FPGA has been designed for the SPLASH system <ref> [7] </ref>. A detailed description of the interface can be found in [7], [8]. [19] summarizes the design issues in the interface. Here we give details sufficient enough to motivate our model of the processor-programmable-unit interface. The processor can communicate with the programmable unit in both synchronous and asynchronous modes. <p> A very general and flexible interface between the processor and the FPGA has been designed for the SPLASH system <ref> [7] </ref>. A detailed description of the interface can be found in [7], [8]. [19] summarizes the design issues in the interface. Here we give details sufficient enough to motivate our model of the processor-programmable-unit interface. The processor can communicate with the programmable unit in both synchronous and asynchronous modes.
Reference: [8] <institution> Splash 2 interface, Athanas and B.Pudipeddi, private communication athanas@vt.edu </institution>
Reference-contexts: A very general and flexible interface between the processor and the FPGA has been designed for the SPLASH system [7]. A detailed description of the interface can be found in [7], <ref> [8] </ref>. [19] summarizes the design issues in the interface. Here we give details sufficient enough to motivate our model of the processor-programmable-unit interface. The processor can communicate with the programmable unit in both synchronous and asynchronous modes. <p> Type 2: The processor can also set up the DMA channels enabling asynchronous data transfer with the programmable unit.This requires the transfer of data to and from the memory and FPGA unit using a DMA controller. Details of such an arrangement can be found in <ref> [8] </ref>. This mode may be used when the amount of data to be communicated to the FPGA is large. We consider this approach for computing the IDCT for an entire macro block in a frame of the mpeg-stream.
Reference: [9] <institution> Programmable Logic Data Book, Xilinx Inc. </institution>
Reference: [10] <author> Le Gall Didier, </author> <title> MPEG: A Video Compression Standard for Multimedia Applications, </title> <journal> Communications of the ACM, </journal> <month> April </month> <year> 1991, </year> <month> Vol.34., No.4. </month> <pages> pp 45-58. </pages>
Reference: [11] <author> John L Hennessy and David Patterson, </author> <title> Computer Architecture A Quantitative Approach, 2nd ed., </title> <publisher> Morgan Kaufman 1995. </publisher>
Reference-contexts: Some instruction statistics for fpga idct and float idct are shown in the histogram in Fig 6. All Instruction Statistics are in [20] and the complete DLX Instruction Set can be found in <ref> [11] </ref>. The number of floating point operations go down from 3521 to 0, as expected. Equally drastic, if not more, is that the integer operations go down from 69409 to 6180.
Reference: [12] <author> A Kalavade, </author> <title> System Level Codesign of Mixed Hardware-Software systems, </title> <type> Ph.D Dissertation, </type> <institution> UC Berkeley, </institution> <month> Sept. </month> <year> 1995. </year>
Reference-contexts: The addition of programmable unit to the processor requires complier technology that can partition the application into hardware and software, generate code for the software component and synthesize logic that can be mapped into the programmable unit for the hardware component. This is an active research area by itself <ref> [12] </ref>. Due to the recent success and popularity of FPGAs, several systems have been built with a programmable unit added on to a host system. PRISM [1] [2] developed at Brown University demonstrates the use of reconfigurable logic to obtain substantial speedup in the case of large regular binary operations.
Reference: [13] <author> B.Sikstrom, et al., </author> <title> A high speed 2-D discrete cosine transform chip, INTEGRATION, </title> <note> the VLSI journal 5 (1987) pp 159-169. </note>
Reference-contexts: A single 8 fi 8 IDCT takes 2 fi 8 3 floating point multiplications and floating point additions. 3.1.2 Hardware Implementation in IDCT The literature on the hardware implementations can be seen in <ref> [13] </ref>, [14], [15], [18]. Our implementation of the IDCT follows [13]. As in their approach, the latency of the IDCT unit is 4W c clock cycles, where W c is the number of bits used to store the cosine coefficients. <p> A single 8 fi 8 IDCT takes 2 fi 8 3 floating point multiplications and floating point additions. 3.1.2 Hardware Implementation in IDCT The literature on the hardware implementations can be seen in <ref> [13] </ref>, [14], [15], [18]. Our implementation of the IDCT follows [13]. As in their approach, the latency of the IDCT unit is 4W c clock cycles, where W c is the number of bits used to store the cosine coefficients. With W c = 8 bits, the latency of the unit is 32 FPGA clock cycles. <p> This tradeoff is discussed in [20]. We give an estimate of the space requirement for a Xilinx 4K family chip below. We require 8 sets of Processing Elements (PE) and ROMs, as discussed in <ref> [13] </ref>. Each PE and a ROM has a requirement of the order of 80 CLBs, summing to 640 CLBs.
Reference: [14] <author> U.Sjostrosm, et al., </author> <title> Discrete Cosine Transform Chips for real-time video applications, </title> <booktitle> Proc. IEEE ISCAS '90, </booktitle> <pages> pp 77-80, </pages> <address> New Orleans, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: A single 8 fi 8 IDCT takes 2 fi 8 3 floating point multiplications and floating point additions. 3.1.2 Hardware Implementation in IDCT The literature on the hardware implementations can be seen in [13], <ref> [14] </ref>, [15], [18]. Our implementation of the IDCT follows [13]. As in their approach, the latency of the IDCT unit is 4W c clock cycles, where W c is the number of bits used to store the cosine coefficients.
Reference: [15] <author> M.Maruyama, et al., </author> <title> VLSI Architecture and Implementation of a multi-function, forward/inverse Discrete Cosine Transform Processor, </title> <booktitle> SPIE Vol. 1360 Visual Communications and Image Processing '90 pp 410-417. </booktitle>
Reference-contexts: Each macro block in turn consists of 4 to 6 blocks which have undergone DCT and quantization. Thus, in the decoding stage, a major com-putationally intensive procedure is the Inverse Discrete Cosine Transform (IDCT). The IDCT is a floating point intensive operation <ref> [15] </ref> and mpeg play offers two alternative implementations to this computation. We implement the IDCT computation in programmable logic. <p> A single 8 fi 8 IDCT takes 2 fi 8 3 floating point multiplications and floating point additions. 3.1.2 Hardware Implementation in IDCT The literature on the hardware implementations can be seen in [13], [14], <ref> [15] </ref>, [18]. Our implementation of the IDCT follows [13]. As in their approach, the latency of the IDCT unit is 4W c clock cycles, where W c is the number of bits used to store the cosine coefficients.
Reference: [16] <author> Christoph Loe*er, et al., </author> <title> Practical Fast 1-D DCT Algorithms with 11 Multiplications, </title> <booktitle> Proc. ICASSP 1989 pp. </booktitle> <pages> 988-991. </pages>
Reference-contexts: The first of the implementations j rev dct compromises quality for speed of execution, while the latter float idct is slow, but provides good quality of the transform. The implementation of j rev dct is based on a recent result in literature <ref> [16] </ref> which provides an algorithm for 1 fi 8 IDCT computation in 11 multiplications and 29 additions. The advantage of this method is that no data path contains more than one multiplication; this allows a very simple and accurate implementation in scaled fixed-point arithmetic, with a minimal number of shifts.
Reference: [17] <author> Kronader,T., et al., </author> <title> VLSI implementation of the discrete cosine transform, </title> <booktitle> Proc. Nordic Symposium. Computers and Communications, </booktitle> <address> Tampere, Finland, </address> <month> June 13-16, </month> <year> 1984. </year>
Reference: [18] <author> P Duhamel, et al., </author> <title> A DCT chip based on a new structured and computationally effiecient DCT algorithm, </title> <booktitle> Proc. IEEE ISCAS '90, </booktitle> <pages> pp 77-80, </pages> <address> New Orleans May 1990. </address>
Reference-contexts: A single 8 fi 8 IDCT takes 2 fi 8 3 floating point multiplications and floating point additions. 3.1.2 Hardware Implementation in IDCT The literature on the hardware implementations can be seen in [13], [14], [15], <ref> [18] </ref>. Our implementation of the IDCT follows [13]. As in their approach, the latency of the IDCT unit is 4W c clock cycles, where W c is the number of bits used to store the cosine coefficients.
Reference: [19] <author> Andre DeHon, </author> <title> Notes on Coupling Processors with Reconfigurable Logic, Transit Note #118, MIT Transit Project, </title> <month> March </month> <year> 1995. </year>
Reference-contexts: A very general and flexible interface between the processor and the FPGA has been designed for the SPLASH system [7]. A detailed description of the interface can be found in [7], [8]. <ref> [19] </ref> summarizes the design issues in the interface. Here we give details sufficient enough to motivate our model of the processor-programmable-unit interface. The processor can communicate with the programmable unit in both synchronous and asynchronous modes.
Reference: [20] <author> Sriram Rajamani and Pramod Viswanath, </author> <title> Accelerating the RISC processor using Programmable Logic, </title> <type> Project Report CS252, </type> <institution> UC Berkeley, </institution> <note> http://www.cs.berkeley.edu/~ pvi/cs252/project.html Dec 1995. </note>
Reference-contexts: With W c = 8 bits, the latency of the unit is 32 FPGA clock cycles. However, precision in the cosine coefficients directly affects the storage data required and hence space on the chip. This tradeoff is discussed in <ref> [20] </ref>. We give an estimate of the space requirement for a Xilinx 4K family chip below. We require 8 sets of Processing Elements (PE) and ROMs, as discussed in [13]. Each PE and a ROM has a requirement of the order of 80 CLBs, summing to 640 CLBs. <p> Obviously, we have avoided expensive floating point multiplications and additions using bit arithmetic in the FPGA, but further analyses can be done using the instruction statistics. Some instruction statistics for fpga idct and float idct are shown in the histogram in Fig 6. All Instruction Statistics are in <ref> [20] </ref> and the complete DLX Instruction Set can be found in [11]. The number of floating point operations go down from 3521 to 0, as expected. Equally drastic, if not more, is that the integer operations go down from 69409 to 6180.
Reference: [21] <institution> UC Berkeley, dlxsim A simulator for DLX architecture, </institution> <address> http://po.eecs.berkeley.edu:80/~ cs252 </address>
Reference-contexts: The RISC processor we choose is DLX. DLX is a simple processor, representative of the current generation of RISC processors. UC Berkeley has a DLX simulator and the Gnu-C-Compiler targeted for DLX <ref> [21] </ref>. The program interface for the programmable unit follows Instruction-Set Metamorphosis as proposed in [1] i.e, new instructions are added to the processor. The new instructions are implemented by modifying the simulator. Our primary measure of performance is execution time.
References-found: 21

