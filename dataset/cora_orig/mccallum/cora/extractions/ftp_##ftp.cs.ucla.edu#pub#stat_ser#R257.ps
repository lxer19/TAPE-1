URL: ftp://ftp.cs.ucla.edu/pub/stat_ser/R257.ps
Refering-URL: http://singapore.cs.ucla.edu/csl_papers.html
Root-URL: http://www.cs.ucla.edu
Email: judea@cs.ucla.edu  
Title: Testing Regression Models With Fewer Regressors  
Author: Judea Pearl and Peyman Meshkat 
Address: Los Angeles, CA 90024  
Affiliation: Cognitive Systems Laboratory Computer Science Department University of California,  
Abstract-found: 0
Intro-found: 1
Reference: [Geiger and Pearl, 1990] <author> D. Geiger and J. Pearl. </author> <title> Logical and algorithmic properties of independence and their application to Bayesian networks. </title> <journal> Annals of Mathematics and AI, </journal> <volume> 2(1-4):165-178, </volume> <year> 1990. </year>
Reference-contexts: of B sep been a basis for C 0 , the missing inequalities would have to be implied by B 0 , and this would mean that the diagram created by adding arrows to D for each element of B sep nB would be inconsistent, contrary to the theorem of <ref> [Geiger and Pearl, 1990] </ref>. Section 4 establishes several lemmas which provide weak versions of Theorem 1 and lead the way toward the proof.
Reference: [Lauritzen, 1996] <author> S.L. Lauritzen. </author> <title> Graphical Models. </title> <publisher> Clarendon Press, Oxford, </publisher> <year> 1996. </year>
Reference: [Pearl, 1988] <author> J. Pearl. </author> <booktitle> Probabilistic Reasoning in Intelligence Systems. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: This follows from the fact that in any DAG D, the parents of node i separate i from all its nondescendants in D <ref> [Pearl, 1988, pp. 119-120] </ref>. Moreover, the DAG D (M) also enables us to identify a basis for C 0 , choosing the set of parents of node i as the conditioning variables Z in each member r ijZ of B. <p> These lemmas are based on two properties of partial correlations, 1 The d in d-separation connotes "directional." In this paper, however, we will use the term "separation" to mean d-separation. 3 called weak union and contraction in <ref> [Pearl, 1988] </ref>. weak union : ijZ = 0 & ikZ = 0 ) ijZk = 0 (4) contraction : ijZk = 0 & ikZ = 0 ) ijZ = 0 (5) To facilitate the derivation, we introduce additional notation. <p> Whenever this implication holds, we will say that D is an I-map of P (see <ref> [Pearl, 1988, p. 96] </ref>). In this paper, our concern lies not with general conditional independencies but rather with vanishing partial correlations.
Reference: [Verma and Pearl, 1988] <author> T. Verma and J. Pearl. </author> <title> Causal networks: Semantics and expressiveness. </title> <booktitle> In Proceedings of the 4th Workshop on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 352-359, </pages> <address> Mountain View, CA, </address> <year> 1988. </year> <note> Also in R. </note> <editor> Shachter, T.S. Levitt, and L.N. Kanal (Eds.), </editor> <booktitle> Uncertainty in AI 4, </booktitle> <publisher> Elesevier Science Publishers, </publisher> <pages> 69-76, </pages> <year> 1990. </year> <month> 7 </month>
Reference-contexts: Moreover, the DAG D (M) also enables us to identify a basis for C 0 , choosing the set of parents of node i as the conditioning variables Z in each member r ijZ of B. This follows from the d-separation 1 theorem <ref> [Verma and Pearl, 1988] </ref>, which states that every separation conditions in G (M ) corresponds to conditional independence relationship in the model M from which G was constructed.
References-found: 4

