URL: ftp://speech.cse.ogi.edu/pub/docs/Schmid_Pronunciation_ICASSP93.ps.gz
Refering-URL: http://www.cse.ogi.edu/~philipp/vitae.html
Root-URL: http://www.cse.ogi.edu
Title: AUTOMATICALLY GENERATED WORD PRONUNCIATIONS FROM PHONEME CLASSIFIER OUTPUT  for Spoken Language Understanding  
Author: Philipp Schmid, Ronald Cole, Mark Fanty 
Address: 97006 1999 USA  
Affiliation: Center  Oregon Graduate Institute of Science Technology Beaverton, Oregon  
Abstract: We describe an automatic procedure for modeling alternate pronunciations of words produced by different talkers. The research compared recognition performance on forty city and state names using three different representations of each word. In the first case, the expected pronunciation(s) of each word was produced by an expert. In the second case, a dynamic programming algorithm was used to create a pronunciation network for each word by combining phonetic transcriptions from ten utterances of the word produced by human labelers. The third case was identical to the second, except that the phonetic labels were provided automatically by a phonetic recognition algorithm. On a test set of words produced by new speakers, equivalent recognition performance was observed for the pronunciation networks derived from human and machine labels, and both produced superior performance to that obtained with the pronunciations produced by the expert. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. Zue, J. Glass, M. Phillips, and S. Seneff. </author> <title> The mit summit speech recognition system: a progress report. </title> <booktitle> In Proceedings of DARPA Speech and Natural Language Workshop, </booktitle> <year> 1989. </year>
Reference-contexts: Rules, for example, may account for deletion of word-final stop consonants or flapping of word-medial /t/ between stressed and unstressed syllables. The use of rules to model pronunciation variability has led to performance improvements in the MIT SUMMIT system and the SRI DECIPHER system <ref> [1] </ref> [2]. In addition, SUMMIT uses automatic procedures to adjust the transition weights in the pronunciation networks. Riley and Ljolje [3] use a statistical procedure to determine the phonetic realization of phonemes in word base-forms (the "expected" pronunciation).
Reference: [2] <author> M. Cohen. </author> <title> Phonological Structures for Speech Recognition. </title> <type> PhD thesis, </type> <institution> Department of EE and CS, University of California,, Berkeley, </institution> <address> CA, </address> <year> 1989. </year>
Reference-contexts: Rules, for example, may account for deletion of word-final stop consonants or flapping of word-medial /t/ between stressed and unstressed syllables. The use of rules to model pronunciation variability has led to performance improvements in the MIT SUMMIT system and the SRI DECIPHER system [1] <ref> [2] </ref>. In addition, SUMMIT uses automatic procedures to adjust the transition weights in the pronunciation networks. Riley and Ljolje [3] use a statistical procedure to determine the phonetic realization of phonemes in word base-forms (the "expected" pronunciation).
Reference: [3] <author> M. Riley and A. Ljolje. </author> <title> Recognizing phonemes vs. recognizing phones: a comparison. </title> <booktitle> In Proceedings of IC-SLP, </booktitle> <year> 1992. </year>
Reference-contexts: The use of rules to model pronunciation variability has led to performance improvements in the MIT SUMMIT system and the SRI DECIPHER system [1] [2]. In addition, SUMMIT uses automatic procedures to adjust the transition weights in the pronunciation networks. Riley and Ljolje <ref> [3] </ref> use a statistical procedure to determine the phonetic realization of phonemes in word base-forms (the "expected" pronunciation). Taking account of lexical stress and word boundary information, they generated statistics for phonemes in word baseforms from a pho netically labeled speech corpus (TIMIT).
Reference: [4] <author> H. Murveit, M. Weintraub, M. Cohen, and J.Bernstein. </author> <title> Lexical access with lattice input. </title> <booktitle> In Proceedings of DARPA Speech and Natural Language Workshop, </booktitle> <year> 1987. </year>
Reference-contexts: conditions of noise or limited channel bandwidth. (These misperceptions often go unnoticed in fluent speech, since the perceptual system is able to use redundant information to correctly recognize the intended word.) The approach described here models word-level pronunciation variability directly from machine-generated sub-word units, as proposed by Murveit et al. <ref> [4] </ref> and Rulot et al. [5]. This approach offers the potential to model variability contributed by both the speaker and recognizer. For segment-based recognition systems, this requires modeling the insertions, deletions and substitutions produced by the phonetic recognizer.
Reference: [5] <author> H. Roulot, N. Prieto, and E. Vidal. </author> <title> Learning accurate finite-state structural models of words through the ecgi algorithm. </title> <booktitle> In Proceedings of ICASSP, </booktitle> <year> 1989. </year>
Reference-contexts: channel bandwidth. (These misperceptions often go unnoticed in fluent speech, since the perceptual system is able to use redundant information to correctly recognize the intended word.) The approach described here models word-level pronunciation variability directly from machine-generated sub-word units, as proposed by Murveit et al. [4] and Rulot et al. <ref> [5] </ref>. This approach offers the potential to model variability contributed by both the speaker and recognizer. For segment-based recognition systems, this requires modeling the insertions, deletions and substitutions produced by the phonetic recognizer. We note that no amount of modeling can fully compensate for phonetic recognition errors in some situations.
Reference: [6] <author> M. Fanty, P. Schmid, and R. Cole. </author> <title> City name recognition over the telephone. </title> <booktitle> In Proceedings of ICASSP, </booktitle> <year> 1993. </year>
Reference-contexts: To generate a pronunciation string for each word, a neural network first assigns a score for each of 39 phonemes to each 6 msec frame in the word. The details of the network are given in <ref> [6] </ref> in this proceedings. A Viterbi search then finds the best scoring sequence of broad phonetic category segments, subject to minimal and maximal duration constraints as well as ordering constraints (e.g. no 2 stop segments in a row). <p> The word final segments /ah/ /n/ and /s/ correspond to the breath release following the word. 4. RECOGNITION The recognition system used is described in <ref> [6] </ref> in this proceedings. A neural network (the same used to generate the pronunciations as described above) generates scores for each of 39 phonemes every 6 msec. <p> The phonetic labels were provided by full time speech corpus development staff at the Center for Spoken Language Understanding. The machine labels were generated from the ten utterances of each word in the training set, as described above. The recognition system described in <ref> [6] </ref> was used throughout the experiments. On the 160 words in the development test set, the system recognized 85.0% of the words using the models generated by an expert, and 87.5% using the models generated from the hand labeled utterances.
Reference: [7] <author> R. Cole, K. Roginski, and M. Fanty. </author> <title> A telephone speech database of spelled and spoken names. </title> <booktitle> In Proceedings of ICSLP, </booktitle> <year> 1992. </year> <month> 4 </month>
Reference-contexts: The states are constrained to have durations between the minimum and maximum seen during construction of the pronunciation network. 5. EXPERIMENTS The speech data used in the experiments consisted of utterances of forty common city and state names taken from the telephone speech corpus described in <ref> [7] </ref>. 1 These names were chosen so there would be sufficient training and test data. The utterances were given by callers in response to questions about their home town and the city the were calling from.
References-found: 7

