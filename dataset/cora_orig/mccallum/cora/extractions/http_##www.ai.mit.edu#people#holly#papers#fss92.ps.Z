URL: http://www.ai.mit.edu/people/holly/papers/fss92.ps.Z
Refering-URL: http://www.ai.mit.edu/people/holly/papers/papers.html
Root-URL: 
Email: holly@ai.mit.edu  
Phone: (617)253-7884  
Title: Towards an Adaptable Robot Language  
Author: Holly Yanco 
Address: 545 Technology Square, Room 741 Cambridge, MA 02139  
Affiliation: MIT Artificial Intelligence Laboratory  
Abstract: Robot communication is necessary to complete collaborative tasks efficiently. The robots will need an adaptable language if we want them to function in new and changing environments. This paper reports steps already taken towards the creation of an adaptable robot language and discusses extensions to the work that are being ex amined.
Abstract-found: 1
Intro-found: 1
Reference: [Kaelbling, 1990] <author> Leslie Pack Kaelbling. </author> <title> Learning in embedded systems. </title> <type> Technical Report TR-90-04, </type> <institution> Teleos Research, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: When Ernie hears a signal from Bert, he must select an action to perform (again, either spin or straight). Initially, the robots select actions randomly. The robots learn the task using a reinforcement learning algorithm. Currently, the interval estimation method <ref> [Kaelbling, 1990] </ref> is being employed. Tallies are kept of the number of times a particular action has been performed on an input and the number of times that positive reinforcement has been received. An optimization function is used to select the next action to be performed on a given input.
Reference: [Martin and Sargent, 1991] <author> Fred Martin and Randy Sar-gent. </author> <title> The mit sensor robot: User's guide and technical reference, </title> <month> October </month> <year> 1991. </year>
Reference-contexts: So, once the robots can learn a language, they can also adapt their language. 2.1 The robots Bert and Ernie, the two robots used in this research, are "Sensor Robots" designed by Fred Martin at the Media Laboratory at the Massachusetts Institute of Technology <ref> [Martin and Sargent, 1991] </ref>. Each robot is approximately 9 00 lfi6 00 wfi4 00 h, with a single circuit board containing most of the computational and sensory resources of the robot. A 6v battery strapped to the underside of the chassis supplies the power for the robot.
Reference: [Sargent and Martin, 1991] <author> Randy Sargent and Fred Martin. </author> <title> IC: Multi-tasking interactive C for the 6811. </title> <note> IC Version 2.5, </note> <month> October </month> <year> 1991. </year>
Reference-contexts: A 6v battery strapped to the underside of the chassis supplies the power for the robot. The robots are shown in figure 1. The primary computational resource is an on-board Mo-torola 6811 microprocessor. The programming environment is ic, an multi-tasking interactive C compiler and interpreter developed by Randy Sargent <ref> [Sargent and Martin, 1991] </ref>. ic allows the sensor robot to be addressed through a serial line from a host computer as well as the downloading of programs for autonomous activity. The work described in this paper was implemented with the robots under autonomous control.
Reference: [Shewchuk, 1991] <author> John P. Shewchuk. </author> <type> Ph.D. thesis proposal, </type> <year> 1991. </year>
Reference-contexts: If human-to-robot communication were destroyed for some reason, the robots would be able to carry on with their tasks by reinforcing one another. 4 Acknowledgements The initial work has been directly inspired by work done by John Shewchuk <ref> [Shewchuk, 1991] </ref>. Portions of the research described here were done jointly with Lynn Stein, who has provided immeasurable guidance. I'd also like to thank Candy Sidner, Rod Brooks, Fred Martin, Ian Horswill and Jeanne Speckman. The author is supported in part by a scholarship from the Digital Equipment Corporation.
Reference: [Sutton, 1992] <author> Richard S. Sutton. </author> <title> Special issue on reinforcement learning. </title> <booktitle> Machine Learning, </booktitle> <pages> 8(3-4), </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Reinforcement learning is being used to teach the robots. Much of the work done in reinforcement learning is in simulation only; moving this work to robots provides a richer testbed for the algorithms. (For an overview of research in reinforcement learning, see <ref> [Sutton, 1992] </ref>.) The world is its own best simulation running algorithms in a toy world can overlook problems in the real world, no matter how well-intentioned the designer of the simulation.
Reference: [Yanco and Stein, 1992] <author> Holly Yanco and Lynn Andrea Stein. </author> <title> An adaptive communication protocol for cooperating mobile robots. MIT AI Memo 1379, </title> <institution> MIT Artifical Intelligence Lab, </institution> <month> August </month> <year> 1992. </year> <note> Submitted to SAB-92. </note>
Reference-contexts: The additional sensory abilities of the robots were not substantively used in the experiments described here. 2.2 Description of initial work In <ref> [Yanco and Stein, 1992] </ref>, we report work in which Bert and Ernie develop a simple two signal language. The robots are given the task of coordinated movement (either both spin or both go straight). <p> The robots only receive good reinforcement (+) when the task is performed correctly. If the robots have been told to both spin but only one spins, the robots receive negative reinforcement (). (Understanding of reinforcement signals is hard-coded into the robots.) This task based reinforcement is discussed in <ref> [Yanco and Stein, 1992] </ref>. The robots learn the task and a private robot language after five to fifteen instruction-action-reinforcement cycles. A sample run is shown in figure 2. Already we have developed an adaptable language.
References-found: 6

