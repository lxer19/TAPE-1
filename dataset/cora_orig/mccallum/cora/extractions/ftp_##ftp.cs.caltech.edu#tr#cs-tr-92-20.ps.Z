URL: ftp://ftp.cs.caltech.edu/tr/cs-tr-92-20.ps.Z
Refering-URL: ftp://ftp.cs.caltech.edu/tr/INDEX.html
Root-URL: http://www.cs.caltech.edu
Title: Invariance Hints and the VC Dimension  
Author: William John Andrew Fyfe 
Degree: Thesis by  In Partial Fulfillment of the Requirements for the Degree of Doctor of Philosophy  
Date: 1992 (Submitted 26 May 1992)  
Address: Pasadena, California  
Affiliation: California Institute of Technology  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Yaser S. Abu-Mostafa, </author> <title> Learning from hints in neural networks, </title> <journal> Journal of Complexity 6 (1990), </journal> <volume> no. 2, </volume> <pages> 192-198. </pages>
Reference-contexts: Note that we don't actually need to know the value of the function f at any of these points. This method of learning an invariant was suggested by Abu-Mostafa <ref> [1] </ref>. Minimizing the error functions E (ff) and E I (ff) is only guaranteed to give us a network that performs well on the given examples. <p> The range of values for 2 depends on the transfer function we use in our network; we will assume that values for y are within the same range. If we use (x) = (1 + e x ) 1 then we have a range of <ref> [0; 1] </ref> and the vectors b ff are points within the n dimensional hypercube [0; 1] n . If we use instead (x) = (2=) arctan (x) then we have a range of [1; 1] and the hypercube becomes [0; 4] n . <p> If we use (x) = (1 + e x ) 1 then we have a range of <ref> [0; 1] </ref> and the vectors b ff are points within the n dimensional hypercube [0; 1] n . If we use instead (x) = (2=) arctan (x) then we have a range of [1; 1] and the hypercube becomes [0; 4] n . The uniform bound c on the functions F ff (z) is the edge length of the hypercube. <p> If we use instead (x) = (2=) arctan (x) then we have a range of <ref> [1; 1] </ref> and the hypercube becomes [0; 4] n . The uniform bound c on the functions F ff (z) is the edge length of the hypercube. Let B be the set of all the vectors b ff . <p> Again we can call d the VC dimension, and we have uniform convergence. Let's now turn to an example. Our functions g ff are the lines g ff (x) = mx + b, where m; b; x 2 <ref> [0; 1] </ref>. Our index ff will be the ordered pair (m; b). The range of 18 these functions is [0; 2]. Our samples (x i ; y i ) will have x i 2 [0; 1] and y i 2 [0; 2]. <p> ff are the lines g ff (x) = mx + b, where m; b; x 2 <ref> [0; 1] </ref>. Our index ff will be the ordered pair (m; b). The range of 18 these functions is [0; 2]. Our samples (x i ; y i ) will have x i 2 [0; 1] and y i 2 [0; 2]. For a choice of n samples, we want to investigate the structure of the points b ff = y (mx + b) . First lets consider the points ^ b ff = y mx b. <p> Then our points ^ b ff are (y 1 mx 1 b; y 2 mx 2 b) 2 [2; 2] 2 . Here x 1 ; y 1 ; x 2 ; y 2 are constants, and we have m; b 2 <ref> [0; 1] </ref> Provided x 1 6= x 2 , these points ^ b ff form a parallelogram in the plane. The points b ff also form a region in the plane. This region is related to the parallelogram in the following way. <p> This time, however, these vectors are points within an n-dimensional hypercube. For what follows, let's assume that the functions g ff map X to <ref> [1; 1] </ref>, and thus the hypercube is [0; 4] n . The particular choices for these ranges is not important, so long as there is a uniform bound on h ff (x i ; x 0 i ) as required for the generalized VC result. <p> Now let's return to our example of real-valued functions g ff (x) = mx+b, where m; b; x 2 <ref> [0; 1] </ref>. These functions are a poor choice for fitting data that satisfies an invariant. Suppose for our unknown function f , we have f (x) = f (x 0 ), where x 6= x 0 . Suppose a function g ff satisfies this invariant. <p> Further, from the second layer forward, the outputs of all neurons will be even, and thus the function computed by the network is also even. This network is very similar to the network suggested by Abu-Mostafa in <ref> [1] </ref>. Instead of having ^'(x) = '(x), he uses ^'(x) = '(x). This means that the weights multiplying the outputs '(x) and ^'(x) are negations of one another, rather than identical as we have derived here. <p> Thus it is simple to establish conditions under which the update will increase the distance between v 1 and v 2 . Assume the range of the sigmoid is <ref> [1; 1] </ref>. Note that the derivative of is strictly positive. Assume further that the three thresholds are large in magnitude, making u 1 (x) 1, u 2 (x) 1, and u 3 (x) 1. Also assume that v 1 &gt; 0 and v 2 &lt; 0. <p> The former carries more information with it; we expect to see this reflected in the relative performance of these two types of hint. A hint is chosen at random. First an input x is picked at random, uniformly in <ref> [1; 1] </ref> n . Then an element of the group is picked, again uniformly, and applied 59 0.05 0.15 0.25 0.35 0.45 General ization Error Millions of Iterations 5 inputs 6 inputs 7 inputs to x producing x 0 . The pair (x; x 0 ) is our hint.
Reference: [2] <author> Eric B. Baum and David Haussler, </author> <title> What size net gives valid generalization?, </title> <booktitle> Neural Computation 1 (1989), </booktitle> <volume> no. 1, </volume> <pages> 151-160. </pages>
Reference-contexts: Let's now turn to an example. Our functions g ff are the lines g ff (x) = mx + b, where m; b; x 2 [0; 1]. Our index ff will be the ordered pair (m; b). The range of 18 these functions is <ref> [0; 2] </ref>. Our samples (x i ; y i ) will have x i 2 [0; 1] and y i 2 [0; 2]. For a choice of n samples, we want to investigate the structure of the points b ff = y (mx + b) . <p> Our index ff will be the ordered pair (m; b). The range of 18 these functions is <ref> [0; 2] </ref>. Our samples (x i ; y i ) will have x i 2 [0; 1] and y i 2 [0; 2]. For a choice of n samples, we want to investigate the structure of the points b ff = y (mx + b) . First lets consider the points ^ b ff = y mx b. <p> First lets consider the points ^ b ff = y mx b. Suppose we have 2 samples (x 1 ; y 1 ) and (x 2 ; y 2 ). Then our points ^ b ff are (y 1 mx 1 b; y 2 mx 2 b) 2 <ref> [2; 2] </ref> 2 . Here x 1 ; y 1 ; x 2 ; y 2 are constants, and we have m; b 2 [0; 1] Provided x 1 6= x 2 , these points ^ b ff form a parallelogram in the plane. <p> In this network we have placed constraints on the weights in the first two layers, 49 and the thresholds in the input layer. These constraints reduce the number of free variables that determine each network. Baum and Haussler <ref> [2] </ref> have shown that the VC dimension of the networks can be bounded in terms of the number of weights and thresholds in the network. Our constraints effectively reduces this number, and thus tends to reduce the VC dimension of the networks. <p> The behaviour of our network depends on the VC dimension of the set of all possible networks. To estimate the VC dimension, we again appeal to the results of Baum and Haussler <ref> [2] </ref>. There are a 2n + 2 weights and 3 thresholds, for a total of 2n + 5 parameters. All of these are not independent; nevertheless, we will use 2n + 5 as an estimate of the VC dimension.
Reference: [3] <author> H. D. Block and S. A. Levin, </author> <title> On the boundedness of an iterative procedure for solving a system of linear inequalities, </title> <booktitle> Proceedings of the American Mathematical Society 26 (1970), </booktitle> <volume> no. 2, </volume> <pages> 229-235. </pages>
Reference-contexts: Thus for any two equivalent functions ' and ^', the increment to the weight vector w is the same. Thus we have preserved the equal weight property of w. So show convergence, we will follow the proof of Block and Levin <ref> [3] </ref>. We want to show that if there is a solution, then we will converge to some solution, after a finite number of updates to the perceptron. By a solution, we mean a set of assignments to the weights such that the perceptron correctly classifies all of the examples given.
Reference: [4] <author> W. N. Colquitt and L. Welsh, Jr., </author> <title> A new Mersenne prime, </title> <booktitle> Mathematics of Computation 56 (1991), </booktitle> <volume> no. 194, </volume> <pages> 867-870. </pages>
Reference-contexts: Colquitt and Welsh combined this test with other heuristics to find the 29th Mersenne prime, 2 110503 1 and to verify that 2 132049 1 is the 30th, in order of increasing size <ref> [4] </ref>. These primes have 33,265 and 39,751 digits respectively; it would be impossible to verify their primality by checking divisibility, using our solution above. <p> If we use instead (x) = (2=) arctan (x) then we have a range of [1; 1] and the hypercube becomes <ref> [0; 4] </ref> n . The uniform bound c on the functions F ff (z) is the edge length of the hypercube. Let B be the set of all the vectors b ff . In the Boolean case the set B was a subset of the vertices of the hypercube. <p> This time, however, these vectors are points within an n-dimensional hypercube. For what follows, let's assume that the functions g ff map X to [1; 1], and thus the hypercube is <ref> [0; 4] </ref> n . The particular choices for these ranges is not important, so long as there is a uniform bound on h ff (x i ; x 0 i ) as required for the generalized VC result.
Reference: [5] <author> Gerald A. Edgar, </author> <title> Measure, topology and fractal geometry, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: We can define a metric dimension [9] as dim (B) = lim log N (*; B) ; where this limit exists. For our volume, the metric dimension will be 3. This quantity need not be integral; if it is fractional then the set B is fractal <ref> [10, 5] </ref>. Suppose that for any n, and n samples (x i ; y i ), the set B = fb ff g has its metric dimension bounded by d.
Reference: [6] <author> Andrew Fyfe, </author> <title> Properties of the V-C dimension, </title> <type> Master's thesis, </type> <institution> California Institute of Technology, </institution> <year> 1990. </year>
Reference: [7] <author> David Haussler, </author> <title> Generalizing the PAC model: sample size bounds from metric dimension-based uniform convergence results, </title> <booktitle> Proceedings of the 30th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1989, </year> <pages> pp. 40-45. </pages>
Reference-contexts: For our *-nets, we will follow Vapnik and Chervonenkis and use the L 1 distance (b; u) = max i jb i u i j. Others, such as Haussler <ref> [7] </ref>, use the L 1 distance (b; u) = 1 P n i=1 jb i u i j. In [17], Vapnik and Chervonenkis investigate the implications of using the L 1 norm, relative to the L 1 norm. <p> In such a case, we have uniform convergence, and d becomes our VC dimension. There are additional ways to attempt to bound the size of the minimal *- net. Haussler <ref> [7] </ref>, following Pollard [13], uses the combinatorial dimension. This approach is similar to that of Vapnik. Here we are given our set of points B, and translate each by some constant vector b fl .
Reference: [8] <author> David Haussler, Michael Kearns, and Robert E. Schapire, </author> <title> Bounds on the sample complexity of Bayesian learning using information theory and the VC dimension, </title> <booktitle> Proceedings of the Fourth Annual Workshop on Computational Learning Theory, </booktitle> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1991, </year> <pages> pp. 61-74. </pages>
Reference-contexts: The results for uniform convergence of E I (ff) to I I (ff) make this assumption. It can be relaxed, under some circumstances, though there is a penalty involved in the number of required examples. Haussler and other investigate this in <ref> [8] </ref>. Further, the ability to restrict our set of networks relies on the observation that I (ff) &lt; * implies that I I (ff) &lt; 2*. <p> For example, equivalent inputs may be equally likely. Even if we don't know the conditional probability, we can substitute another, at the expense of a penalty. The implications of such a substitution are investigated by Haussler and others in <ref> [8] </ref>. 3. Group Invariance and Feed-Forward Networks For perceptrons, we have seen how invariance under a group can be ensured. We would like to see if a similar result can be obtained for feed-forward neural networks. We will start with a simple example.
Reference: [9] <author> A. N. Kolmogorov and V. M. Tihomirov, </author> <title> *-entropy and *-capacity of sets in functional spaces, </title> <journal> American Mathematical Society Translations, </journal> <volume> Series 2 17 (1961), </volume> <pages> 277-364. </pages>
Reference-contexts: Now it is a possibly uncountable collection of points within the hypercube. Since we cannot count these points we need to use another method to quantify the size of B. We will use one of two roughly equivalent techniques; both, as well as a third, are investigated in <ref> [9] </ref>. First, an *-net for B is a finite set of points U in R n such that for every b 2 B, there is some u 2 U such that (b; u) *. <p> The size of such an *-net will be about (a=*) 3 points, for some constant a. The exponent 3 corresponds to our volume being 3-dimension. We can define a metric dimension <ref> [9] </ref> as dim (B) = lim log N (*; B) ; where this limit exists. For our volume, the metric dimension will be 3. This quantity need not be integral; if it is fractional then the set B is fractal [10, 5].
Reference: [10] <author> Benoit B. Mandelbrot, </author> <title> The fractal geometry of nature, </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1977. </year>
Reference-contexts: We can define a metric dimension [9] as dim (B) = lim log N (*; B) ; where this limit exists. For our volume, the metric dimension will be 3. This quantity need not be integral; if it is fractional then the set B is fractal <ref> [10, 5] </ref>. Suppose that for any n, and n samples (x i ; y i ), the set B = fb ff g has its metric dimension bounded by d.
Reference: [11] <author> James L. McClelland and David E. Rumelhart, </author> <title> Explorations in parallel distributed processing, </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1988. </year>
Reference-contexts: We can define an error function on n examples (x i ; y i ) by E (ff) = n i=1 y i g ff (x i ) : We can then minimize this error by gradient descent. For feed-forward networks this is the back propagation algorithm <ref> [11] </ref>. Suppose our function f satisfies an invariant. Earlier, we defined an invariant by a group of transformations T . This group induces a partition of the input set X into equivalence classes.
Reference: [12] <author> Marvin L. Minsky and Seymour A. Papert, </author> <title> Perceptrons, </title> <editor> expanded ed., </editor> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1988. </year> <month> 70 </month>
Reference-contexts: In particular, we will look at the perceptron model, where group invariance is asserted by the structure of the network. In the feed-forward model, the invariance is asserted during the learning process. 1. Perceptrons Perceptrons are defined by Minsky and Papert <ref> [12] </ref>; they are simple, two layer networks. The first layer is made up of functions ', taken from the set . <p> The group divides the input set X and input functions into equivalence classes. Finally, a function f is invariant under such a group of transformations T , or T -invariant, if, 8t 2 T , f ffi t (x) = f (x). In <ref> [12] </ref>, Minsky and Papert prove the group invariance theorem. Suppose we have a perceptron, and the function g ff it computes is invariant under the group T . Suppose also that the group is finite, and that the set of functions is closed under T .
Reference: [13] <author> David Pollard, </author> <title> Convergence of stochastic processes, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1984. </year>
Reference-contexts: In such a case, we have uniform convergence, and d becomes our VC dimension. There are additional ways to attempt to bound the size of the minimal *- net. Haussler [7], following Pollard <ref> [13] </ref>, uses the combinatorial dimension. This approach is similar to that of Vapnik. Here we are given our set of points B, and translate each by some constant vector b fl . We seek the translation that results in a maximal number of occupied orthants of R n .
Reference: [14] <author> N. Sauer, </author> <title> On the density of families of sets, </title> <journal> Journal of Combinatorial Theory, Series A 13 (1972), </journal> <volume> no. 1, </volume> <pages> 145-147. </pages>
Reference-contexts: If there is no such d, then we consider the VC dimension to be infinite. In the case of a finite VC dimension, we can derive stronger bounds on the growth function m (n). Theorem 3.2 (Sauer <ref> [14] </ref>). Suppose the VC dimension of a set of events fE ff g is d. For n &gt; d, d X i : Corollary 3.3. For n &gt; d and n 4, m (n) 1:5n d =d!. Sauer's result also follows from the following theorem. Theorem 3.4 ([6]).
Reference: [15] <author> Patrice Simard, Bernard Victorri, Yann Le Cun, and John Denker, </author> <title> Tangent prop | a formalism for specifying selected invariances in an adaptive network, </title> <booktitle> Advances in Neural Information Processing Systems 4 (John E. </booktitle> <editor> Moody, Steven J. Hanson, and Richard P. Lippmann, eds.), </editor> <publisher> Morgan Kauf-mann Publishers, </publisher> <year> 1992, </year> <pages> pp. 895-903. </pages>
Reference-contexts: And, since we don't need to know the value of the function for our examples of the invariant, we can generate arbitrary numbers of examples of the invariant, as required. 3. Tangent Prop Simard and others <ref> [15] </ref> propose a technique for handling certain types of invariant, which they call tangent prop. Their technique generalizes back propagation to learn both the unknown function and its derivative. Suppose we define an invariant by a function t (a; x) that transforms an input x according to a parameter a.
Reference: [16] <author> V. N. Vapnik and A. Ya. Chervonenkis, </author> <title> On the uniform convergence of relative frequencies of events to their probabilities, </title> <booktitle> Theory of Probability and Its Applications 16 (1971), </booktitle> <volume> no. 2, </volume> <month> 264-280. </month> <title> [17] , Necessary and sufficient conditions for the uniform convergence of means to their probabilities, </title> <booktitle> Theory of Probability and Its Applications 26 (1981), </booktitle> <volume> no. 3, </volume> <pages> 532-553. </pages>
Reference-contexts: We need, therefore, a uniform result, that gives us a bound, given a number of examples, on the probability that any network has a difference between observed and overall behaviour of more than ffi. This result is due to Vapnik and Chervonenkis <ref> [16, 17, 18] </ref>. 1. Boolean-Valued Functions First let us consider a probability model. We have a collection of events fE ff g, with each event E ff a subset of some set X. <p> What we want are the conditions under which -(n) ff tends to ff uniformly, that is, for any ffi &gt; 0, we want lim Prob ff fi ff -(n) fi Theorem 3.1 (Vapnik and Chervonenkis <ref> [16] </ref>). For a series of n samples, n &gt; 2=ffi 2 , Prob ff fi ff -(n) fi The growth function m (n) is defined in terms of the events fE ff g. <p> Thus we have N (n) = E m (x) = X n Finally, let H (n) = E We can use H (n) to strengthen theorem 3.5. 13 Theorem 3.5 (Vapnik and Chervonenkis <ref> [16] </ref>). For lim Prob ff fi ff -(n) fi it is necessary and sufficient that lim H (n) = 0: The difficultly in using this definition is the fact that the quantity H (n) depends on the probability distribution, which we assume we do not know.
Reference: [18] <author> Vladimir Vapnik, </author> <title> Estimation of dependences based on empirical data, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: We need, therefore, a uniform result, that gives us a bound, given a number of examples, on the probability that any network has a difference between observed and overall behaviour of more than ffi. This result is due to Vapnik and Chervonenkis <ref> [16, 17, 18] </ref>. 1. Boolean-Valued Functions First let us consider a probability model. We have a collection of events fE ff g, with each event E ff a subset of some set X. <p> Theorem 3.6 gives the necessary and sufficient conditions for uniform convergence in the real-valued case, just as theorem 3.5 does for the Boolean case. However, we do not yet have an analogue for the VC dimension. Vapnik <ref> [18] </ref> defines a VC dimension of a class of real-valued functions to be equal to that of a corresponding class of Boolean functions. These Boolean functions are those created by taking each real-valued function g ff , and applying an arbitrary threshold to it. <p> Finally, associated with the growth function ^m (n), we have a VC dimension ^ d, which is then also the VC dimension for the set of functions g ff . 17 Theorem 3.7 (Vapnik <ref> [18] </ref>). For n samples, where n &gt; 2=ffi, Prob ( ff fi fi E y g ff (x) n i=1 y i g ff (x i ) fi fi fi &gt; cffi ) There are other ways to define a VC dimension.
References-found: 17

