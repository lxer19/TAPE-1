URL: file://ftp.cis.ohio-state.edu/pub/tech-report/1993/TR32.ps.gz
Refering-URL: ftp://ftp.cis.ohio-state.edu/pub/tech-report/TRList.html
Root-URL: 
Email: Email: ftseng, laig@cis.ohio-state.edu  
Phone: Tel: 614-292-5813, Fax: 614-292-2911  
Title: Parallel Compacting Free Buddy Subcubes in a Hypercube  
Author: Yu-Chee Tseng, Ten-Hwang Lai, and Young Man Kim 
Keyword: hypercube, fragmentation problem, subcube compaction, job migration, buddy system, circuit-switching, wormhole-routing, e-cube routing, deadlock-free.  
Note: This research was supported by National Science Foundation under Grant CCR-9010589.  
Address: Columbus, OH 43210 1277  
Affiliation: Department of Computer and Information Science The Ohio State University  
Abstract: A hypercube can be partitioned into subcubes of various sizes to run independent jobs. As jobs arrive, grabbing subcubes, and leave, releasing subcubes, the system tends to become fragmented. When this happens, one solution that has been proposed is to relocate (or migrate) jobs so as to compact free processors into bigger subcubes. Assuming a circuit-switched or wormhole-routed n-cube using a buddy-system allocation strategy, this paper proposes two algorithms for subcube compaction that are both structure-preserving, adjacency-preserving, path-disjoint, and interference-free, with high concurrency during the migration. The first algorithm uses the simple dimension-ordered (e-cube) routing and needs at most d steps to free up a d-cube, d &lt; n, provided that there are at least 2 d free processors in the cube. The second algorithm exploits more concurrency and cuts down the number of steps to no more than dd=2e, but may not use dimension-ordered routing. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G.-I. Chen and T.-H. Lai, </author> <title> "Constructing Parallel Paths between Two Subcubes," </title> <journal> IEEE Trans. on Computers, </journal> <volume> Vol. 41, No. 1, </volume> <month> Jan. </month> <year> 1992, </year> <pages> pp. 118-123. </pages>
Reference-contexts: Their result emphasizes on the migration of a single job | a job can be migrated from a source subcube to a destination subcube in the minimum amount of time. Chen and Lai <ref> [1] </ref> considered the problem of migrating a single job from any subcube to another (of the same dimension) in a hypercube system with an arbitrary allocation scheme and a circuit-switched network.

Reference: [3] <author> M.-S. Chen and K. G. Shin, </author> <title> "Subcube Allocation and Task Migration in Hypercube Multiprocessors," </title> <journal> IEEE Trans. on Computers, </journal> <volume> Vol. 39, No. 9, </volume> <month> Sep. </month> <year> 1990, </year> <pages> pp. 1146-55. </pages>
Reference-contexts: Subcube allocation is a difficult task and several methods have been proposed: e.g., buddy system [2, 13], Gray code [2], Free List [10] and MSS [5]. Some distributed subcube management schemes are in [7, 8]. It has been pointed out by Chen and Shin <ref> [3] </ref> that as jobs arrive at the system, grabbing subcubes, and leave, releasing them to the system, the hypercube tends to become fragmented. <p> One way to solve the hypercube fragmentation problem is to migrate (or relocate) job (s) currently running in the system so as to compact a large free subcube <ref> [3] </ref>. Migrating a job involves suspending all its processes, identifying a destination subcube, moving all processes to the destination, and resuming the execution. This process is feasible in a hypercube due to its small diameter and large number of communication links, provided efficient cube-compaction schemes are available. <p> A full one, on the other hand, compacts all free processors into as few (and thus as large) subcubes as possible. Job migration posts different problems for different communication models and different allocation schemes. Assuming a packet-switched (store-and-forward) network and a Gray-code-based subcube-allocation scheme, Chen and Shin <ref> [3] </ref> first showed a full scheme that compacts all free processors in a hypercube into one or more large subcubes. The routing, though deadlock-free, is not disjoint in migration paths and thus may cause congestion in circuit-switched or wormhole-routed hypercubes.
Reference: [4] <author> W. J. Dally and C. L. Seitz, </author> <title> "Deadlock-free Message Routing in Multiprocessor Interconnection Networks," </title> <journal> IEEE Trans. on Computers, </journal> <volume> Vol. C-36, </volume> <month> May </month> <year> 1987, </year> <pages> pp. 547-553. </pages>
Reference-contexts: As can be seen, earlier results either do not consider migrating multiple jobs concurrently or may have congestion during migrations. Parallelism and the communication power provided by the many links of a hypercube are not well exploited. Also, with the recent increasing popularity of circuit-switched and wormhole-routed networks <ref> [4, 9, 12, 14] </ref>, routing congestion has become a more significant factor for communication latency than routing distance. This is especially true for job migration, which incurs a large amount of communication. That motivates our work. <p> Both algorithms are partial schemes. The first one needs at most d migration steps to free up a d-cube, d &lt; n, and in each step processes are routed in a dimension-ordered manner. This conforms with the popular e-cube routing scheme <ref> [4] </ref> and thus is directly applicable to many existing machines. To further accelerate the migration, we propose a more sophisticated algorithm that cuts down the number of migration steps to dd=2e or less. <p> ; : : :), indicating the order of dimensions along which the job will be routed. (Thus, a process will, from its original location, first move along dimension d 1 , then d 2 , and so on.) When is strictly decreasing, the routing is also called the e-cube routing <ref> [4] </ref>. 2.3 Outline of the Compaction Algorithms In this paper, two effective cube-compaction algorithms are developed. The strategy used is outlined as follows. To compact a free d-cube, we first collect from the system (under the current system state) a set of free subcubes F containing 2 d nodes. <p> Although wormhole-routed networks are much faster as opposed to packet-switched networks, it has been known by the literature that arbitrarily routing should be avoided, as it may cause communication deadlock <ref> [4, 16] </ref>. The e-cube routing scheme is known to be deadlock-free. Thus, our first algorithm, which uses the e-cube routing, can coexist with other communications which also use the e-cube routing in the system without deadlock. This algorithm is ready to be used in many existing machines.
Reference: [5] <author> S. Dutt and J. P. Hayes, </author> <title> "Subcube Allocation in Hypercube Computers," </title> <journal> IEEE Trans. on Computers, </journal> <volume> Vol. 40, No. 3, </volume> <month> March </month> <year> 1991, </year> <pages> pp. 341-352. </pages>
Reference-contexts: The subcube is released to the system on completion of the job. Subcube allocation is a difficult task and several methods have been proposed: e.g., buddy system [2, 13], Gray code [2], Free List [10] and MSS <ref> [5] </ref>. Some distributed subcube management schemes are in [7, 8]. It has been pointed out by Chen and Shin [3] that as jobs arrive at the system, grabbing subcubes, and leave, releasing them to the system, the hypercube tends to become fragmented. <p> On the other hand, any element in S should also be recognizable by this scheme. For any given state S, if an allocation scheme can recognize all possible free sub-cubes, then it is called perfect (e.g., Free List [10] and MSS <ref> [5] </ref>); it is imperfect otherwise. The buddy system, which is imperfect, can only recognize subcubes of pattern x = x n : : : x d+1 fl : : : fl, where x i are binary numbers, i &gt; d. Such subcubes are referred to as buddy subcubes.
Reference: [6] <author> C.-H. Huang and J.-Y. Juang, </author> <title> "A Partial Compaction Scheme for Processor Allocation in Hypercube Multiprocessors," </title> <booktitle> Int'l Conf. on Parallel Processing, </booktitle> <address> V.1, </address> <year> 1990, </year> <pages> pp. 211-217. </pages>
Reference-contexts: This process is feasible in a hypercube due to its small diameter and large number of communication links, provided efficient cube-compaction schemes are available. Huang and Juang classified cube-compaction schemes as partial and full <ref> [6] </ref>. A partial scheme only compacts necessary number of subcubes to free up a subcube of the requested size. A full one, on the other hand, compacts all free processors into as few (and thus as large) subcubes as possible. <p> The routing, though deadlock-free, is not disjoint in migration paths and thus may cause congestion in circuit-switched or wormhole-routed hypercubes. Huang and Juang <ref> [6] </ref> considered the buddy-system allocation strategy and indicated that a partial scheme would be more efficient than a full one.
Reference: [7] <author> M. Jeng and H. J. Siegel, </author> <title> "Dynamic Partitioning in a Class of Parallel Systems," </title> <booktitle> Proc. Int'l Conference on Distributed Computing Systems, </booktitle> <year> 1988, </year> <pages> pp. 33-40. </pages>
Reference-contexts: The subcube is released to the system on completion of the job. Subcube allocation is a difficult task and several methods have been proposed: e.g., buddy system [2, 13], Gray code [2], Free List [10] and MSS [5]. Some distributed subcube management schemes are in <ref> [7, 8] </ref>. It has been pointed out by Chen and Shin [3] that as jobs arrive at the system, grabbing subcubes, and leave, releasing them to the system, the hypercube tends to become fragmented.
Reference: [8] <author> M. Jeng and H. J. Siegel, </author> <title> "A Distributed Management Scheme for Partitionable Parallel Computers," </title> <booktitle> Proc. Int'l Conf. on Parallel Processing, V.2, </booktitle> <year> 1989, </year> <month> pp.57-64. </month>
Reference-contexts: The subcube is released to the system on completion of the job. Subcube allocation is a difficult task and several methods have been proposed: e.g., buddy system [2, 13], Gray code [2], Free List [10] and MSS [5]. Some distributed subcube management schemes are in <ref> [7, 8] </ref>. It has been pointed out by Chen and Shin [3] that as jobs arrive at the system, grabbing subcubes, and leave, releasing them to the system, the hypercube tends to become fragmented.
Reference: [9] <author> J. Kim and C. R. Das, </author> <title> "Modeling Wormhole Routing in a Hypercube," </title> <booktitle> Int'l Conf. on Distributed Computing Systems, </booktitle> <month> May </month> <year> 1991, </year> <pages> pp. 386-393. </pages>
Reference-contexts: As can be seen, earlier results either do not consider migrating multiple jobs concurrently or may have congestion during migrations. Parallelism and the communication power provided by the many links of a hypercube are not well exploited. Also, with the recent increasing popularity of circuit-switched and wormhole-routed networks <ref> [4, 9, 12, 14] </ref>, routing congestion has become a more significant factor for communication latency than routing distance. This is especially true for job migration, which incurs a large amount of communication. That motivates our work.
Reference: [10] <author> J. Kim, C. R. Das, and W. Lin, </author> <title> "A Top-Down Processor Allocation Scheme for Hypercube Computers," </title> <journal> IEEE Trans. on Parallel and Distrib. Systems, </journal> <volume> Vol. 2, No. 1, </volume> <month> Jan. </month> <year> 1991, </year> <pages> pp. 20-30. </pages>
Reference-contexts: The subcube is released to the system on completion of the job. Subcube allocation is a difficult task and several methods have been proposed: e.g., buddy system [2, 13], Gray code [2], Free List <ref> [10] </ref> and MSS [5]. Some distributed subcube management schemes are in [7, 8]. It has been pointed out by Chen and Shin [3] that as jobs arrive at the system, grabbing subcubes, and leave, releasing them to the system, the hypercube tends to become fragmented. <p> On the other hand, any element in S should also be recognizable by this scheme. For any given state S, if an allocation scheme can recognize all possible free sub-cubes, then it is called perfect (e.g., Free List <ref> [10] </ref> and MSS [5]); it is imperfect otherwise. The buddy system, which is imperfect, can only recognize subcubes of pattern x = x n : : : x d+1 fl : : : fl, where x i are binary numbers, i &gt; d.
Reference: [11] <author> P. E. Krueger, T.-H. Lai, and V. A. Radiya, </author> <title> "Processor Allocation vs. Job Scheduling on Hypercube Computers", </title> <booktitle> Int'l Conf. on Distrib. </booktitle> <institution> Comput. Systems, </institution> <year> 1991, </year> <pages> pp. </pages> <note> 394-401 (also to appear in IEEE Trans. on Parallel and Distrib. Systems). </note>
Reference-contexts: Thus, our results not only remove the congestion problem of existing solutions, but also reduce the migration time significantly, making them prospective solutions for the cube fragmentation problem. Although the buddy system can recognize fewer subcubes than can other existing 2 strategies, a recent study <ref> [11] </ref> has indicated that under most workload conditions, the differences in performance between simple, imperfect allocation schemes (e.g., buddy system and Gray code) and perfect, but much more complex, ones (e.g., Free list and MSS) are small; that the job-scheduling discipline has far more impact on performance than allocation strategy; and
Reference: [12] <author> L. M. Ni and P. K. McKinley, </author> <title> "A Survey of Wormhole Routing Techniques in Direct Networks," </title> <journal> IEEE Computer, </journal> <volume> Vol. 26, </volume> <pages> pp. 62-76, </pages> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: As can be seen, earlier results either do not consider migrating multiple jobs concurrently or may have congestion during migrations. Parallelism and the communication power provided by the many links of a hypercube are not well exploited. Also, with the recent increasing popularity of circuit-switched and wormhole-routed networks <ref> [4, 9, 12, 14] </ref>, routing congestion has become a more significant factor for communication latency than routing distance. This is especially true for job migration, which incurs a large amount of communication. That motivates our work.
Reference: [13] <author> C. L. Seitz, </author> <title> "The Cosmic Cube," </title> <journal> Comm. ACM, </journal> <volume> Vol. 28, </volume> <year> 1985, </year> <pages> pp. 22-33. </pages>
Reference-contexts: The subcube is released to the system on completion of the job. Subcube allocation is a difficult task and several methods have been proposed: e.g., buddy system <ref> [2, 13] </ref>, Gray code [2], Free List [10] and MSS [5]. Some distributed subcube management schemes are in [7, 8].
Reference: [14] <author> S. F. </author> <title> Nugent, </title> <booktitle> "The iPSC/2 Direct-Connect communications technology," Proc. of 3rd Conf. on Hypercube Computers and Applications, </booktitle> <month> January </month> <year> 1988, </year> <pages> pp. 51-60. </pages>
Reference-contexts: As can be seen, earlier results either do not consider migrating multiple jobs concurrently or may have congestion during migrations. Parallelism and the communication power provided by the many links of a hypercube are not well exploited. Also, with the recent increasing popularity of circuit-switched and wormhole-routed networks <ref> [4, 9, 12, 14] </ref>, routing congestion has become a more significant factor for communication latency than routing distance. This is especially true for job migration, which incurs a large amount of communication. That motivates our work.
Reference: [15] <author> T. Schwederski, H. J. Siegel, and T. L. Casavant, </author> <title> "Optimal task migration transfers using multistage cube networks," </title> <booktitle> Proc. Int'l Conf. on Parallel Processing, Vol. I (1990), </booktitle> <pages> pp. 51-58. </pages>
Reference-contexts: Their scheme is sequential 1 in nature (i.e., only one process is migrated at a time) and as many as O (2 d ) steps of migration might be needed to free up a d-cube. Schwederski et al. <ref> [15] </ref> assumed the communication model of multistage cube networks with either packet-switching or circuit-switching capability with perfect subcube allocation schemes. Their result emphasizes on the migration of a single job | a job can be migrated from a source subcube to a destination subcube in the minimum amount of time.
Reference: [16] <author> Y.-C. Tseng and D. K. Panda, </author> <title> "A Trip-based Multicasting Model for Wormhole-routed Networks with Virtual Channels," </title> <booktitle> Int'l Parallel Processing Symp., </booktitle> <year> 1993, </year> <pages> pp. 276-283. </pages>
Reference-contexts: Although wormhole-routed networks are much faster as opposed to packet-switched networks, it has been known by the literature that arbitrarily routing should be avoided, as it may cause communication deadlock <ref> [4, 16] </ref>. The e-cube routing scheme is known to be deadlock-free. Thus, our first algorithm, which uses the e-cube routing, can coexist with other communications which also use the e-cube routing in the system without deadlock. This algorithm is ready to be used in many existing machines.
References-found: 15

