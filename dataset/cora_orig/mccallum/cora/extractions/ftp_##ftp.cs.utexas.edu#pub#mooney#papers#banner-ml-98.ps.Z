URL: ftp://ftp.cs.utexas.edu/pub/mooney/papers/banner-ml-98.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/ml/abstracts.html
Root-URL: 
Email: sowmya@shai.com  mooney@cs.utexas.edu  
Title: Theory Refinement for Bayesian Networks with Hidden Variables  
Author: Sowmya Ramachandran, Raymond J. Mooney 
Address: 1660, So. Amphlett Blvd. Ste. 350, San Mateo, CA, 94402  Austin, TX, 78712  
Affiliation: Stottler Henke and Associates, Inc.,  Department of Computer Sciences, University of Texas at Austin,  
Date: 1998  
Note: Appears in Proceedings of the Fifteenth International Conference on Machine Learning,  
Abstract: While there has been a growing interest in the problem of learning Bayesian networks from data, no technique exists for learning or revising Bayesian networks with hidden variables (i.e. variables not represented in the data), that has been shown to be efficient, effective, and scalable through evaluation on real data. The few techniques that exist for revising such networks perform a blind search through a large space of revisions, and are therefore computationally expensive. This paper presents Banner, a technique for using data to revise a given Bayesian network with noisy-or and noisy-and nodes, to improve its classification accuracy. The initial network can be derived directly from a logical theory expressed as propositional rules. Banner can revise networks with hidden variables, and add hidden variables when necessary. Unlike previous approaches, Banner employs mechanisms similar to logical theory refinement techniques for using the data to focus the search for effective modifications. Experiments on real-world problems in the domain of molecular biology demonstrate that Banner can effectively revise fairly large networks to significantly improve their accuracies. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Baffes, P. T., & Mooney, R. J. </author> <year> (1996). </year> <title> A novel application of theory refinement to student modeling. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 403-408 Portland, OR. </address>
Reference-contexts: Banner also performs well on revising the original promoter theory, but since its structure is already adequate, this problem does not test structure revision. The system also performed well on revising a knowledge base on C++ programming to model students for an intelligent tutoring system <ref> (Baffes & Mooney, 1996) </ref>. Ramachandran (1998) presents complete results. In order to compare to previous results, we generated learning curves in which the data was randomly split into independent training and test sets, systems were trained on the training data, and then tested on classifying the test examples.
Reference: <author> Brunk, C., & Pazzani, M. </author> <year> (1995). </year> <title> A lexically based semantic bias for theory revision. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 81-89 San Francisco, CA. </address> <publisher> Morgan Kaufman. </publisher>
Reference: <author> Buntine, W. </author> <year> (1991). </year> <title> Theory refinement on Bayesian networks. </title> <booktitle> In Proceedings of the Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pp. 52-60. </pages>
Reference: <author> Friedman, N., Goldszmidt, M., Heckerman, D., & Russell, S. </author> <year> (1997). </year> <title> Challenge: </title> <booktitle> What is the impact of Bayesian networks on learning?.. </booktitle> <pages> pp. </pages> <address> 10-15 Nagoya, Japan. </address>
Reference-contexts: However, learning both the structure and the parameters of a Bayesian network with hidden variables remains a problem. Many of the existing methods can be adapted to discover hidden variables, but only by conducting extensive search that is impractical for most problems. A recent development is MS-EM <ref> (Friedman, 1997) </ref>, which learns the structure of a network with hidden variables; however, it requires specifying the number of hidden variables and has not been tested on real data. <p> MS-EM <ref> (Friedman, 1997) </ref> extends EM to learn the structure as well as the parameters of a network from incomplete data. While it works when the initial theory contains hidden variables, it cannot construct new hidden variables. <p> More detailed comparisons of different Bayes-net induction and revision algorithms and competing methods on realistic problems measuring both training time and predictive accuracy are clearly needed. The current literature on Bayes-net learning is particularly lacking in this regard relative to other areas of machine learning <ref> (Friedman, Goldszmidt, Heckerman, & Russell, 1997) </ref>. Extending Banner's general approach to handle nodes other than noisy-or/and ones is an important area for future study. Another is theory refinement for unsupervised learning where there is not a specific targeted inference task.
Reference: <author> Friedman, N. </author> <year> (1997). </year> <title> Learning belief networks in the pres-ence of missing values and hidden variables. </title> <booktitle> In Proceedings of the Fourteenth International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 125-133 Nashville, Ten-nessee. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: However, learning both the structure and the parameters of a Bayesian network with hidden variables remains a problem. Many of the existing methods can be adapted to discover hidden variables, but only by conducting extensive search that is impractical for most problems. A recent development is MS-EM <ref> (Friedman, 1997) </ref>, which learns the structure of a network with hidden variables; however, it requires specifying the number of hidden variables and has not been tested on real data. <p> MS-EM <ref> (Friedman, 1997) </ref> extends EM to learn the structure as well as the parameters of a network from incomplete data. While it works when the initial theory contains hidden variables, it cannot construct new hidden variables. <p> More detailed comparisons of different Bayes-net induction and revision algorithms and competing methods on realistic problems measuring both training time and predictive accuracy are clearly needed. The current literature on Bayes-net learning is particularly lacking in this regard relative to other areas of machine learning <ref> (Friedman, Goldszmidt, Heckerman, & Russell, 1997) </ref>. Extending Banner's general approach to handle nodes other than noisy-or/and ones is an important area for future study. Another is theory refinement for unsupervised learning where there is not a specific targeted inference task.
Reference: <author> Friedman, N., & Goldszmidt, M. </author> <year> (1996). </year> <title> Building classifiers using Bayesian networks. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 1277-1284. </pages>
Reference-contexts: Banner's goal is to improve the accuracy of an initial network for a specific inference task by modifying both its parameters and structure, including adding new hidden variables. Although Bayesian networks can simultaneously support many types of inference, training directly for the desired classification task results in better performance <ref> (Friedman & Goldszmidt, 1996) </ref>.
Reference: <author> Heckerman, D. </author> <year> (1995). </year> <title> A tutorial on learning Bayesian networks. </title> <type> Tech. rep. </type> <institution> MSR-TR-95-06, Microsoft Research, </institution> <address> Redmond, WA. </address>
Reference-contexts: In an attempt to automate their construction, induction of Bayes nets has become a topic of increasing interest. A number of learning methods have been developed for the case where all relevant variables are observable <ref> (Heckerman, 1995) </ref>. Parameter learning methods for networks with hidden variables (variables not represented in the data) have also been developed (Russell, Binder, Koller, & Kanazawa, 1995; Thiesson, 1995). However, learning both the structure and the parameters of a Bayesian network with hidden variables remains a problem.
Reference: <author> Kohavi, R., Becker, B., & Sommerfield, D. </author> <year> (1997). </year> <title> Improving simple Bayes. </title> <booktitle> In Proceedings of the European Conference on Machine Learning. </booktitle>
Reference-contexts: These problems include imperfect, expert-provided theories represented as propositional rules. These theories contain fan-ins of up to 17 inputs, which would require more than 130,000 2 Our version includes smoothing with Laplace estimates which significantly improves performance <ref> (Kohavi, Becker, & Sommerfield, 1997) </ref> parameters for general nodes, demonstrating the importance of using noisy-or/ands. Here we present the splice-junction results and results on a corrupted version of the promoter theory.
Reference: <author> Kwoh, C.-K., & Gillies, D. </author> <year> (1996). </year> <title> Using hidden nodes in Bayesian networks. </title> <journal> Artificial Intelligence, </journal> <volume> 88 (1-2), </volume> <pages> 1-38. </pages>
Reference: <author> Lam, W., & Bacchus, F. </author> <year> (1994). </year> <title> Using new data to refine a Bayesian network. </title> <booktitle> In Proceedings of the Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pp. 383-390. </pages>
Reference: <author> Mahoney, J. J., & Mooney, R. J. </author> <year> (1994). </year> <title> Comparing methods for refining certainty-factor rule bases. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 173-180 New Brunswick, NJ. </address>
Reference-contexts: We also compared its performance to naive Bayes which learns a simple Bayes net that includes all features and assumes conditional independence, 2 with Kbann (Towell & Shavlik, 1994) a neural-network refinement method, Rapture <ref> (Mahoney & Mooney, 1994) </ref> a certainty-factor refinement method, and with two standard inductive algorithms: C4.5 (Quinlan, 1993) for decision trees and Backprop (McClelland & Rumelhart, 1988) for neural networks.
Reference: <author> McClelland, J. L., & Rumelhart, D. E. </author> <year> (1988). </year> <title> Explorations in Parallel Distributed Processing: A Handbook of Models, Programs, and Exercises. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: naive Bayes which learns a simple Bayes net that includes all features and assumes conditional independence, 2 with Kbann (Towell & Shavlik, 1994) a neural-network refinement method, Rapture (Mahoney & Mooney, 1994) a certainty-factor refinement method, and with two standard inductive algorithms: C4.5 (Quinlan, 1993) for decision trees and Backprop <ref> (McClelland & Rumelhart, 1988) </ref> for neural networks. In order to study the contribution of Banner's components, we also performed ablation studies, where we disabled parts of the algorithm and compared performance to the full system.
Reference: <author> Mitchell, T. </author> <year> (1997). </year> <title> Machine Learning. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY. </address>
Reference-contexts: Ra-machandran (1998) presents further details. 1 The parameter revision component uses 10-fold internal cross-validation on the training set to determine when to stop <ref> (Mitchell, 1997) </ref>. Structure revision exploits the idea that networks with noisy-or/and nodes are similar to logical theories and therefore techniques used to revise rule bases are useful. These methods attribute classification errors on particular examples to specific portions of the theory and directly construct revisions to handle the misclassified cases.
Reference: <author> Mooney, R. J. </author> <year> (1997). </year> <title> Integrating abduction and induction in machine learning. </title> <booktitle> In Working Notes of the IJCAI-97 Workshop on Abduction and Induction in AI, </booktitle> <pages> pp. </pages> <address> 37-42 Nagoya, Japan. </address>
Reference-contexts: These methods attribute classification errors on particular examples to specific portions of the theory and directly construct revisions to handle the misclassified cases. Most logical refinement systems use abduction to diagnose faults <ref> (Mooney, 1997) </ref>. Since Bayesian networks place no restrictions on the direction of inference, abduction can be performed using the standard inference algorithms. In addition, leak nodes (Pradhan et al., 1994) provide a way to model the incompleteness and incorrectness of a Bayesian network with noisy-or/and nodes.
Reference: <author> Opitz, D. W., & Shavlik, J. W. </author> <year> (1993). </year> <title> Heuristically expanding knowledge-based neural networks. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 512-517 Cham-berry, France. </address>
Reference: <author> Ourston, D., & Mooney, R. J. </author> <year> (1994). </year> <title> Theory refinement combining analytical and empirical methods. </title> <journal> Artificial Intelligence, </journal> <volume> 66, </volume> <pages> 311-344. </pages>
Reference: <author> Pazzani, M., & Brunk, C. </author> <year> (1993). </year> <title> Finding accurate frontiers: A knowledge-intensive approach to relational learning. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 328-334 Washington, D.C. </address>
Reference-contexts: Figure 6 shows a portion of the Bayesian network derived from the initial theory for this problem, The data set contains 468 examples, consisting of strings of 57 nucleotides classified as promoters or non-promoters. Although in refinement experiments theories are sometimes corrupted randomly <ref> (Pazzani & Brunk, 1993) </ref>, we found that the redundancy in this theory makes it very robust to small corruptions.
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, Inc., </publisher> <address> San Mateo,CA. </address>
Reference: <author> Pradhan, M., Provan, G., Middleton, B., & Henrion, M. </author> <year> (1994). </year> <title> Knowledge engineering for large belief networks. </title> <booktitle> In Proceedings of the Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 484-490 Seattle, WA. </address>
Reference-contexts: Most logical refinement systems use abduction to diagnose faults (Mooney, 1997). Since Bayesian networks place no restrictions on the direction of inference, abduction can be performed using the standard inference algorithms. In addition, leak nodes <ref> (Pradhan et al., 1994) </ref> provide a way to model the incompleteness and incorrectness of a Bayesian network with noisy-or/and nodes. A leak node is a source in the graph added as an extra input to a node in order to represent a possible unknown cause.
Reference: <author> Provan, G. M., & Singh, M. </author> <year> (1994). </year> <title> Learning Bayesian networks using feature selection. </title> <booktitle> In Proceedings of the Workshop on Artificial Intelligence and Statistics, </booktitle> <pages> pp. </pages> <address> 291-300 New York. </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Quinlan, J. R. </author> <year> (1983). </year> <title> Learning efficient classification procedures and their application to chess end games. </title> <editor> In Michalski, R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA. </address>
Reference: <author> Quinlan, J. R. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 (1), </volume> <pages> 81-106. </pages>
Reference: <author> Quinlan, J. R. </author> <year> (1993). </year> <title> C4.5: Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo,CA. </address>
Reference-contexts: We also compared its performance to naive Bayes which learns a simple Bayes net that includes all features and assumes conditional independence, 2 with Kbann (Towell & Shavlik, 1994) a neural-network refinement method, Rapture (Mahoney & Mooney, 1994) a certainty-factor refinement method, and with two standard inductive algorithms: C4.5 <ref> (Quinlan, 1993) </ref> for decision trees and Backprop (McClelland & Rumelhart, 1988) for neural networks. In order to study the contribution of Banner's components, we also performed ablation studies, where we disabled parts of the algorithm and compared performance to the full system.
Reference: <author> Quinlan, J. </author> <year> (1990). </year> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5 (3), </volume> <pages> 239-266. </pages>
Reference-contexts: The new parent needs to be true for the examples it must enable and false for the ones it must inhibit. Banner uses a standard information gain metric <ref> (Quinlan, 1990) </ref> to choose a parent that best discriminates between these two sets of examples. This metric, commonly used in inductive learning algorithms (Mahoney & Mooney, 1994; Quinlan, 1990, 1986), estimates the information gained about a target function value from knowing the value of an attribute.
Reference: <author> Ramachandran, S. </author> <year> (1998). </year> <title> Theory Refinement of Bayesian Networks with Hidden Variables. </title> <type> Ph.D. thesis, </type> <institution> University of Texas, Austin, TX. </institution> <note> Also appears as Artificial Intelligence Laboratory Technical Report AI 98-265 (see http://www.cs.utexas.edu/users/ai-lab). </note>
Reference: <author> Ramachandran, S., & Mooney, R. J. </author> <year> (1996). </year> <title> Revising Bayesian networks parameters using backpropagation. </title> <booktitle> In International Conference on Neural Networks: Plenary, Panel and Special Sessions, </booktitle> <pages> pp. </pages> <address> 82-87 Washington D.C., USA. </address>
Reference-contexts: This process repeats until it is determined that additional training results in over-fitting. 1 In this paper, we focus on structure revision. Our current implementation includes two parameter revision algorithms, Banner-Pr <ref> (Ramachandran & Mooney, 1996) </ref> and C-APN (based on (Russell et al., 1995)), which use different forms of gradient descent. Ra-machandran (1998) presents further details. 1 The parameter revision component uses 10-fold internal cross-validation on the training set to determine when to stop (Mitchell, 1997).
Reference: <author> Ramoni, M., & Sebastiani, P. </author> <year> (1997). </year> <title> Learning Bayesian networks from incomplete databases. </title> <editor> In Geiger, D., & Shenoy, P. (Eds.), </editor> <booktitle> Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference: <author> Russell, S., Binder, J., Koller, D., & Kanazawa, K. </author> <year> (1995). </year> <title> Local learning in probabilistic networks with hidden variables. </title> <booktitle> In Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 1146-1152 Montreal, Canada. </address>
Reference-contexts: This process repeats until it is determined that additional training results in over-fitting. 1 In this paper, we focus on structure revision. Our current implementation includes two parameter revision algorithms, Banner-Pr (Ramachandran & Mooney, 1996) and C-APN (based on <ref> (Russell et al., 1995) </ref>), which use different forms of gradient descent. Ra-machandran (1998) presents further details. 1 The parameter revision component uses 10-fold internal cross-validation on the training set to determine when to stop (Mitchell, 1997).
Reference: <author> Thiesson, B. </author> <year> (1995). </year> <title> Accelerated quantification of Bayesian networks with incomplete data. </title> <editor> In Fayyad, U. M., & Uthurusamy, R. (Eds.), </editor> <booktitle> Proceedings of the First International Conference on Knowledge Discovery and Data Mining, </booktitle> <pages> pp. 306-11. </pages> <publisher> AAAI Press. </publisher>
Reference: <author> Towell, G. G., & Shavlik, J. W. </author> <year> (1994). </year> <title> Knowledge-based artificial neural networks. </title> <journal> Artificial Intelligence, </journal> <volume> 70, </volume> <pages> 119-165. </pages>
Reference-contexts: We also compared its performance to naive Bayes which learns a simple Bayes net that includes all features and assumes conditional independence, 2 with Kbann <ref> (Towell & Shavlik, 1994) </ref> a neural-network refinement method, Rapture (Mahoney & Mooney, 1994) a certainty-factor refinement method, and with two standard inductive algorithms: C4.5 (Quinlan, 1993) for decision trees and Backprop (McClelland & Rumelhart, 1988) for neural networks. <p> Finally, we specifically evaluated structure revision by attempting to fix an artificially corrupted initial theory. We present results on two molecular biology problems employed in previous refinement experiments: recognizing promoters and splice-junctions in DNA strands <ref> (Towell & Shavlik, 1994) </ref>. These problems include imperfect, expert-provided theories represented as propositional rules.
References-found: 30

