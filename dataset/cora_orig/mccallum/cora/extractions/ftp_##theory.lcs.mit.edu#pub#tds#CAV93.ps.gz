URL: ftp://theory.lcs.mit.edu/pub/tds/CAV93.ps.gz
Refering-URL: http://theory.lcs.mit.edu/tds/papers/Andersen/CAV93.html
Root-URL: 
Phone: 2  
Title: Computer-Assisted Simulation Proofs  
Author: Jtrgen F. Stgaard-Andersen ? Stephen J. Garland, John V. Guttag, Nancy A. Lynch, and Anna Pogosyants ?? 
Address: Denmark, Building 344, DK-2800 Lyngby, Denmark  Cambridge, MA 02139, USA  
Affiliation: University of  MIT Laboratory for Computer Science,  
Pubnum: 1 Technical  
Abstract: This paper presents a scalable approach to reasoning formally about distributed algorithms. It uses results about I/O automata to extract a set of proof obligations for showing that the behaviors of one algorithm are among those of another, and it uses the Larch tools for specification and deduction to discharge these obligations in a natural and easy-to-read fashion. The approach is demonstrated by proving the behavior equivalence of two high-level specifications for a communication protocol.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> M. Abadi and L. Lamport. </author> <title> The existence of refinement mappings. </title> <journal> Theoretical Computer Science, </journal> <volume> 2(82) </volume> <pages> 253-284, </pages> <year> 1992. </year>
Reference-contexts: Our approach uses forward and backward simulation methods, described in <ref> [1, 9] </ref>, to isolate sets of proof obligations that guarantee that the traces of one automaton are included in the traces of another. We formalize the automata using the Larch Shared Language (LSL) [5] and then use LP, the Larch Proof Assistant [3], to construct simulation proofs. <p> Combinations of forward and backward simulations can be shown to be complete. We refer to [9] for details. We note that the forward and backward simulation techniques are more general than refinement mappings of <ref> [1] </ref>.
Reference: 2. <author> R. S. Boyer and J S. Moore. </author> <title> A Computational Logic Handbook. </title> <publisher> Academic Press, </publisher> <year> 1988. </year>
Reference-contexts: Once an LP proof has been completed, the proof script is easily read by a person, and it contains enough information for the reader to reproduce the elided steps, given access to LP or another sufficiently powerful theorem prover <ref> [2, 4] </ref>. The remainder of this paper describes our approach in more detail and provides an illustrative example. Section 2 provides background about I/O automata and simulation proofs. Section 3 contains part of a careful hand proof that two example automata simulate each other.
Reference: 3. <author> S. J. Garland and J. V. Guttag. </author> <title> A guide to LP, the Larch Prover. </title> <type> Technical Report 82, </type> <institution> DEC Systems Research Center, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: This approach brings together the work that some of us have done using I/O automata to reason about distributed algorithms [8] and the work that others of us have done to provide tools for formalizing specifications [5] and for automating deductions <ref> [3] </ref>. Our approach uses forward and backward simulation methods, described in [1, 9], to isolate sets of proof obligations that guarantee that the traces of one automaton are included in the traces of another. <p> We formalize the automata using the Larch Shared Language (LSL) [5] and then use LP, the Larch Proof Assistant <ref> [3] </ref>, to construct simulation proofs. We use simulation proofs because we believe that this method captures formally the natural structure of many informal correctness proofs for both finite and infinite state systems. In particular, it catches the structure of proofs based on successive refinements.
Reference: 4. <author> M. J. C. Gordon. </author> <title> HOL: A proof generating system for higher-order logic. </title> <editor> In G. Birtwistle and P. A. Subrahmanyam, editors, </editor> <title> VLSI Specification, Verification and Synthesis. </title> <publisher> Kluwer, </publisher> <year> 1988. </year>
Reference-contexts: Once an LP proof has been completed, the proof script is easily read by a person, and it contains enough information for the reader to reproduce the elided steps, given access to LP or another sufficiently powerful theorem prover <ref> [2, 4] </ref>. The remainder of this paper describes our approach in more detail and provides an illustrative example. Section 2 provides background about I/O automata and simulation proofs. Section 3 contains part of a careful hand proof that two example automata simulate each other.
Reference: 5. <author> J. V. Guttag and J. J. Horning. </author> <title> Larch: Languages and Tools for Formal Specifica tion. </title> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: This approach brings together the work that some of us have done using I/O automata to reason about distributed algorithms [8] and the work that others of us have done to provide tools for formalizing specifications <ref> [5] </ref> and for automating deductions [3]. Our approach uses forward and backward simulation methods, described in [1, 9], to isolate sets of proof obligations that guarantee that the traces of one automaton are included in the traces of another. We formalize the automata using the Larch Shared Language (LSL) [5] and <p> specifications <ref> [5] </ref> and for automating deductions [3]. Our approach uses forward and backward simulation methods, described in [1, 9], to isolate sets of proof obligations that guarantee that the traces of one automaton are included in the traces of another. We formalize the automata using the Larch Shared Language (LSL) [5] and then use LP, the Larch Proof Assistant [3], to construct simulation proofs. We use simulation proofs because we believe that this method captures formally the natural structure of many informal correctness proofs for both finite and infinite state systems.
Reference: 6. <author> B. Lampson, N. Lynch, and J. F. Stgaard-Andersen. </author> <title> Reliable at-most-once mes sage delivery protocols. </title> <type> Tech. report under preparation, </type> <institution> Laboratory for Computer Science, Massachusetts Institute Technology, </institution> <year> 1993. </year>
Reference-contexts: This correctness for I/O automata is usually proved in two steps. First, a simulation proof technique is used to prove trace inclusion. Second, other proof techniques, e.g., based on a temporal logic, use the simulation result and fairness requirements to prove fair trace inclusion. Examples like that in <ref> [6] </ref> show that the simulation step can be complex. Hence the techniques described in this paper for proving trace inclusion can provide significant help in this first step of a correctness proof. Techniques for Proving Trace Inclusion. Several simulation proof techniques can be used to show trace inclusion. <p> The soundness result of Theorem 4 allows us to conclude that the two automata have the same traces. These automata are slight simplifications of the top two levels of the correctness proofs in <ref> [6] </ref>. The first protocol, S, is the specification of the at-most-once message delivery problem. It describes a "lossy message queue"|a queue for which special crash events can cause the loss of any of the messages in the queue. All proofs in [6] can be done directly via simulations of S; however, <p> the top two levels of the correctness proofs in <ref> [6] </ref>. The first protocol, S, is the specification of the at-most-once message delivery problem. It describes a "lossy message queue"|a queue for which special crash events can cause the loss of any of the messages in the queue. All proofs in [6] can be done directly via simulations of S; however, doing this requires very complicated combinations of forward and backward simulations. <p> The method used in <ref> [6] </ref> to reduce the complexity of the simulations is to split up the mapping into two parts. A new version D of the specification is defined; this is similar to S, except that it delays the decision about which messages are lost because of a crash.
Reference: 7. <author> P. Loewenstein and D. L. Dill. </author> <title> Verification of a multiprocessor cache protocol using simulation relations and higher-order logic. </title> <editor> In E. M. Clarke and R. P. Kurshan, editors, </editor> <booktitle> Computer-Aided Verification '90, number 531 in LNCS, </booktitle> <pages> pages 302-311. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: We are currently working on incorporating also proofs of timing-based systems into our approach. This involves reasoning about reals but seems, at this point, to be feasible with minor extensions to the work presented in this paper. Other works in the area of automating simulation proofs exist. In <ref> [7] </ref> the equivalent of forward simulations for state based automata are considered, however, using a higher-order logic approach (HOL). In [10] forward simulations are considered for I/O automata using the Isabelle theorem prover.
Reference: 8. <author> N. Lynch and M. Tuttle. </author> <title> An introduction to Input/Output automata. </title> <journal> CWI Quarterly, </journal> <volume> 2(3) </volume> <pages> 219-246, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: This approach brings together the work that some of us have done using I/O automata to reason about distributed algorithms <ref> [8] </ref> and the work that others of us have done to provide tools for formalizing specifications [5] and for automating deductions [3]. <p> Section 4 shows how we formalize the definitions of these automata in LSL, and Section 5 presents the LP proof scripts. Finally, Section 6 draws some conclusions about this approach. 2 Automata In this paper we consider simplified versions of I/O automata <ref> [8] </ref>. The major simplification is that we do not deal with fairness or other types of liveness; hence our automata lack a component that defines what it means for an execution to be fair. <p> By itself, trace inclusion is not sufficient to express a notion of correct implementation, because it does not rule out trivial implementations that do nothing. The definition of I/O automata <ref> [8] </ref> rules out automata with trivial trace sets by partitioning the external actions into input actions and output actions and by requiring that some step with every input action be enabled in every state. The definition also imposes additional fairness requirements on executions.
Reference: 9. <author> N. Lynch and F. Vaandrager. </author> <title> Forward and backward simulations for timing-based systems. </title> <editor> In J. W. de Bakker, C. Huizing, and G. Rozenberg, editors, </editor> <booktitle> Proceedings of REX Workshop "Real-Time: Theory in Practice", number 600 in LNCS, </booktitle> <pages> pages 397-446. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Our approach uses forward and backward simulation methods, described in <ref> [1, 9] </ref>, to isolate sets of proof obligations that guarantee that the traces of one automaton are included in the traces of another. We formalize the automata using the Larch Shared Language (LSL) [5] and then use LP, the Larch Proof Assistant [3], to construct simulation proofs. <p> We also do not distinguish between input and output actions, which we group together into a single set of external actions. In fact, our notion of automata is the same as that of untimed automata in <ref> [9] </ref>, except that we allow multiple internal actions. Definition 1 (Automaton). <p> Techniques for Proving Trace Inclusion. Several simulation proof techniques can be used to show trace inclusion. We define two: forward and backward simulations. Other simulation proof techniques are defined in <ref> [9] </ref>. Definition 2 (Forward Simulation). Let A and B be automata with the same external actions. A forward simulation from A to B is a relation f over states (A) fi states (B) such that: 1. <p> Theorem 4 (Soundness of Simulations <ref> [9] </ref>). Let A and B be automata with the same external actions. 1. If there is a forward simulation from A to B, then traces (A) traces (B). 2. If there is a backward simulation from A to B, then finite-traces (A) finite-traces (B). <p> Combinations of forward and backward simulations can be shown to be complete. We refer to <ref> [9] </ref> for details. We note that the forward and backward simulation techniques are more general than refinement mappings of [1].
Reference: 10. <author> T. Nipkow. </author> <title> Formal verification of data type refinement. </title> <editor> In J. W. de Bakker, W.-P. de Roever, and G. Rozenberg, editors, </editor> <booktitle> Stepwise Refinement of Distributed Systems, number 430 in LNCS, </booktitle> <pages> pages 561-589. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: Other works in the area of automating simulation proofs exist. In [7] the equivalent of forward simulations for state based automata are considered, however, using a higher-order logic approach (HOL). In <ref> [10] </ref> forward simulations are considered for I/O automata using the Isabelle theorem prover.
References-found: 10

