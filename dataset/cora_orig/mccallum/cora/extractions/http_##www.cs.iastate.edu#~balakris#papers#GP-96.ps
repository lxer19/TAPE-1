URL: http://www.cs.iastate.edu/~balakris/papers/GP-96.ps
Refering-URL: http://www.cs.iastate.edu/~balakris/research.html
Root-URL: http://www.cs.iastate.edu
Email: balakris@cs.iastate.edu, honavar@cs.iastate.edu  
Title: On Sensor Evolution in Robotics  
Author: Karthik Balakrishnan and Vasant Honavar 
Web: http://www.cs.iastate.edu/~fbalakris,honavarg/homepage.html  
Address: Ames, IA 50011.  
Affiliation: Artificial Intelligence Research Group Iowa State University  
Abstract: In recent years, evolutionary algorithms (EAs) have been successfully used in the design of artificial neural networks for a variety of applications. The suitability of EAs for this design task stems from their ability to adaptively search large spaces in near-optimal ways. One direct application of this advance has been in the area of evolutionary robotics, where EAs are typically used for designing behavior controllers for robots and autonomous agents. While such designs have been found to work well in general, their performance is often limited by the number, placement, quality, efficacy, and reliability of the sensors that the robots are endowed with. In this paper we argue that designing the sensory systems of these robots, in addition to the usual practice of designing the controller, can lead to improvements in the performance of the robot. Our results indicate that the evolution of sensors is a useful enterprise, and can lead to efficient and often counterintuitive controller designs. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Balakrishnan and V. Honavar. </author> <title> Analysis of neuro-controllers designed by simulated evolution. </title> <type> Technical Report CS TR 95-25, </type> <institution> Department of Computer Science, Iowa State University, Ames, </institution> <address> IA - 50011, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: For the purposes of keeping the analysis simple and the discussion focused, we have chosen to explore networks without any hidden units, although the addition of hidden units is seen to improve performance considerably <ref> [1] </ref>. In addition, only one kind of sensor is simulated in our experiments and the information acquisition by the sensors is assumed to be fault-free.
Reference: [2] <author> K. Balakrishnan and V. Honavar. </author> <title> Evolutionary design of neural architectures | a preliminary taxonomy and guide to literature. </title> <type> Technical Report CS TR 95-01, </type> <institution> Department of Computer Science, Iowa State University, Ames, </institution> <address> IA - 50011, </address> <month> January </month> <year> 1995. </year>
Reference-contexts: Not only must these control mechanisms be efficient and robust, but also able to adapt to a changing environment. Artificial neural networks are therefore viable candidates for such behavioral control mechanisms <ref> [7, 5, 2] </ref>. However, realizing even the simplest of robotic behaviors requires fairly complex trade-offs among several, often conflicting, objectives.
Reference: [3] <author> K. Balakrishnan and V. Honavar. </author> <title> Analysis of neu-rocontrollers designed by simulated evolution. </title> <booktitle> In Proceedings of IEEE International Conference on Neural Networks ICNN'96, </booktitle> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: Evolutionary Algorithms (EAs), simulated models of natural evolution, have been shown to be effective procedures for searching large, complex, multi-modal, and deceptive spaces [8, 6], and can thus be employed to solve multi-criterion optimization problems like the design of neurocontrollers for robots and autonomous agents <ref> [9, 12, 5, 10, 3] </ref> Although a large body of work exists in this area, most of them assume a fixed sensory system architecture, while concentrating only on the design and development of the control mechanism. <p> In each trial, the robot was placed in a randomly chosen empty cell, facing a random direction and allowed to perform O (N 3 ) = 216 actions (where each action takes one time step). For reasons mentioned in <ref> [3] </ref>, Teller's simulation time estimate of O (N 2 ) = 80 was not used. At the end of 216 time steps each box against the wall was awarded one point, while boxes in the corners fetched one extra point. <p> By this we mean that evolution starts off with feedforward networks, but through low probability mutation, retains the ability to add recurrent links, if need be. Our earlier work shows the empirical usefulness of such an approach in designing neural networks with near-minimal recurrence <ref> [3] </ref>. The absence of a link is represented by a zero value at the corresponding weight position (see, for example, Figure 2). <p> This also happens to be the network with the best labeled fitness (5:03), and is shown in Figure 3. figure on the left shows the eight active sensors. Also notice the large negative self-loop at the action unit A. As observed in <ref> [3] </ref>, the evolved neurocontrollers have a large negative self-loop at the output unit coding for action (labeled A in the figure). <p> Such an arrangement biases the robots to interleave actions of moving forward and turning, thereby preventing them from getting into states in which they might be stuck till the end of simulation. This feature allows such robots to achieve higher fitnesses on this simulation task <ref> [3] </ref>. 4.2 Experiment 2: Evolving Sensor Positions In this experiment, evolution was allowed to operate not only on the structure of the neurocontroller, but also on the placement of the sensors.
Reference: [4] <author> D. Cliff, P. Husbands, and I. Harvey. </author> <title> Analysis of evolved sensory-motor controllers. </title> <booktitle> In Second Euro-pean Conference on Artificial Life, </booktitle> <year> 1993. </year>
Reference-contexts: The primary reason for this shortcoming is that the robots often get stuck in repetitive/cyclic paths. This can be handled by introducing noise in the system <ref> [4] </ref>, thereby allowing the robots to break out of such fixed cycles. As some researchers have argued [4, 10], such noisy systems are of particular importance if controller designs evolved in simulation are to be successfully transferred on to real robots. <p> The primary reason for this shortcoming is that the robots often get stuck in repetitive/cyclic paths. This can be handled by introducing noise in the system [4], thereby allowing the robots to break out of such fixed cycles. As some researchers have argued <ref> [4, 10] </ref>, such noisy systems are of particular importance if controller designs evolved in simulation are to be successfully transferred on to real robots. Sensory system design, in our view, has two main applications.
Reference: [5] <author> D. Floreano and F. Mondada. </author> <title> Automatic creation of an autonomous agent: Genetic evolution of a neural-network driven robot. </title> <editor> In D. Cliff, P. Husbands, J-A Meyer, and S. Wilson, editors, </editor> <booktitle> From Animals to Animats 3: Proceedings of the Third Inter national Conference on Simulation of Adaptive Be--havior, </booktitle> <pages> pages 421-430, </pages> <address> Cambridge, MA, 1994. </address> <publisher> MIT Press. </publisher>
Reference-contexts: Not only must these control mechanisms be efficient and robust, but also able to adapt to a changing environment. Artificial neural networks are therefore viable candidates for such behavioral control mechanisms <ref> [7, 5, 2] </ref>. However, realizing even the simplest of robotic behaviors requires fairly complex trade-offs among several, often conflicting, objectives. <p> Evolutionary Algorithms (EAs), simulated models of natural evolution, have been shown to be effective procedures for searching large, complex, multi-modal, and deceptive spaces [8, 6], and can thus be employed to solve multi-criterion optimization problems like the design of neurocontrollers for robots and autonomous agents <ref> [9, 12, 5, 10, 3] </ref> Although a large body of work exists in this area, most of them assume a fixed sensory system architecture, while concentrating only on the design and development of the control mechanism. <p> For example, the miniature robot Khepera [11] was used in the navigation studies in <ref> [5] </ref>. Since Khepera comes equipped with eight infra-red (IR) sensors, the neurocontrollers evolved in [5], assumed the availability of eight IR sensors. Fewer (or more) sensors might have resulted in better performance, but that dimension was not explored. <p> For example, the miniature robot Khepera [11] was used in the navigation studies in <ref> [5] </ref>. Since Khepera comes equipped with eight infra-red (IR) sensors, the neurocontrollers evolved in [5], assumed the availability of eight IR sensors. Fewer (or more) sensors might have resulted in better performance, but that dimension was not explored.
Reference: [6] <author> D. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: Thus, design of appropriate neural network controllers (or neurocontrollers) to realize such behaviors is an instance of a difficult multi-criterion optimization problem. Evolutionary Algorithms (EAs), simulated models of natural evolution, have been shown to be effective procedures for searching large, complex, multi-modal, and deceptive spaces <ref> [8, 6] </ref>, and can thus be employed to solve multi-criterion optimization problems like the design of neurocontrollers for robots and autonomous agents [9, 12, 5, 10, 3] Although a large body of work exists in this area, most of them assume a fixed sensory system architecture, while concentrating only on the <p> For reasons mentioned in section 1, we use EAs to search for such designs. 3 Implementation Details In our simulations we use Genetic Algorithms (GAs) <ref> [8, 6] </ref> to evolve sensory and neurocontroller designs. Our genetic representation had two parts, one encoding the placement and ranges of the sensors, and the other encoding the input connectivities of the units of the neu-rocontroller, as shown in Figure 2.
Reference: [7] <author> I. Harvey, P. Husbands, and D. Cliff. </author> <title> Issues in evolutionary robotics. </title> <editor> In J. Meyer, H. Roitblat, and S. Wilson, editors, </editor> <booktitle> From Animals to Animats II: Proceedings of the Second International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 364-373, </pages> <address> Cambridge, MA, 1992. </address> <publisher> MIT Press-Bradford Books. </publisher>
Reference-contexts: Not only must these control mechanisms be efficient and robust, but also able to adapt to a changing environment. Artificial neural networks are therefore viable candidates for such behavioral control mechanisms <ref> [7, 5, 2] </ref>. However, realizing even the simplest of robotic behaviors requires fairly complex trade-offs among several, often conflicting, objectives.
Reference: [8] <author> J. Holland. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, </address> <year> 1975. </year>
Reference-contexts: Thus, design of appropriate neural network controllers (or neurocontrollers) to realize such behaviors is an instance of a difficult multi-criterion optimization problem. Evolutionary Algorithms (EAs), simulated models of natural evolution, have been shown to be effective procedures for searching large, complex, multi-modal, and deceptive spaces <ref> [8, 6] </ref>, and can thus be employed to solve multi-criterion optimization problems like the design of neurocontrollers for robots and autonomous agents [9, 12, 5, 10, 3] Although a large body of work exists in this area, most of them assume a fixed sensory system architecture, while concentrating only on the <p> For reasons mentioned in section 1, we use EAs to search for such designs. 3 Implementation Details In our simulations we use Genetic Algorithms (GAs) <ref> [8, 6] </ref> to evolve sensory and neurocontroller designs. Our genetic representation had two parts, one encoding the placement and ranges of the sensors, and the other encoding the input connectivities of the units of the neu-rocontroller, as shown in Figure 2.
Reference: [9] <author> P. Husbands, I. Harvey, and D. Cliff. </author> <title> Analysing recurrent dynamical networks evolved for robot control. </title> <booktitle> In Proceedings of the 3rd IEE International Conference on Artificial Neural Networks. </booktitle> <publisher> IEE Press, </publisher> <year> 1993. </year>
Reference-contexts: Evolutionary Algorithms (EAs), simulated models of natural evolution, have been shown to be effective procedures for searching large, complex, multi-modal, and deceptive spaces [8, 6], and can thus be employed to solve multi-criterion optimization problems like the design of neurocontrollers for robots and autonomous agents <ref> [9, 12, 5, 10, 3] </ref> Although a large body of work exists in this area, most of them assume a fixed sensory system architecture, while concentrating only on the design and development of the control mechanism.
Reference: [10] <author> O. Miglino, K. Nafasi, and C. Taylor. </author> <title> Selection for wandering behavior in a small robot. </title> <journal> Artificial Life, </journal> <volume> 2(1) </volume> <pages> 101-116, </pages> <year> 1994. </year>
Reference-contexts: Evolutionary Algorithms (EAs), simulated models of natural evolution, have been shown to be effective procedures for searching large, complex, multi-modal, and deceptive spaces [8, 6], and can thus be employed to solve multi-criterion optimization problems like the design of neurocontrollers for robots and autonomous agents <ref> [9, 12, 5, 10, 3] </ref> Although a large body of work exists in this area, most of them assume a fixed sensory system architecture, while concentrating only on the design and development of the control mechanism. <p> The primary reason for this shortcoming is that the robots often get stuck in repetitive/cyclic paths. This can be handled by introducing noise in the system [4], thereby allowing the robots to break out of such fixed cycles. As some researchers have argued <ref> [4, 10] </ref>, such noisy systems are of particular importance if controller designs evolved in simulation are to be successfully transferred on to real robots. Sensory system design, in our view, has two main applications.
Reference: [11] <author> F. Mondada, E. Franzi, and P. Ienne. </author> <title> Mobile robot miniaturization: A tool for investigation in control algorithms. </title> <booktitle> In Proceedings of the Third International Symposium on Experimental Robotics, </booktitle> <address> Kyoto, Japan, </address> <year> 1993. </year>
Reference-contexts: For example, the miniature robot Khepera <ref> [11] </ref> was used in the navigation studies in [5]. Since Khepera comes equipped with eight infra-red (IR) sensors, the neurocontrollers evolved in [5], assumed the availability of eight IR sensors. Fewer (or more) sensors might have resulted in better performance, but that dimension was not explored.
Reference: [12] <author> S. Nolfi, J. Elman, and D. Parisi. </author> <title> Learning and evolution in neural networks. </title> <booktitle> Adaptive Behavior, </booktitle> <volume> 3(1) </volume> <pages> 5-28, </pages> <year> 1994. </year>
Reference-contexts: Evolutionary Algorithms (EAs), simulated models of natural evolution, have been shown to be effective procedures for searching large, complex, multi-modal, and deceptive spaces [8, 6], and can thus be employed to solve multi-criterion optimization problems like the design of neurocontrollers for robots and autonomous agents <ref> [9, 12, 5, 10, 3] </ref> Although a large body of work exists in this area, most of them assume a fixed sensory system architecture, while concentrating only on the design and development of the control mechanism.
Reference: [13] <author> A. Teller. </author> <title> The evolution of mental models. </title> <editor> In Kim Kinnear, editor, </editor> <booktitle> Advances in Genetic Programming, </booktitle> <pages> pages 199-219. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: This paper attempts to answer this question by using evolutionary techniques to discover good designs of sensory systems. 2 The Simulation Task The robotic simulation that we consider in this paper is based on a task proposed by Teller <ref> [13] </ref>. Here the robot is placed in a square arena of N fiN cells, in which M boxes are randomly scattered in the inner (N 2)fi (N 2) grid. The arena is enclosed by impenetrable walls as shown in squares represent boxes and unshaded ones, empty space. <p> On a turn action, the actual direction of turn is given by the output of the turn unit (-1 for clockwise and +1 for anti-clockwise). The general framework for the simulation experiments was borrowed from <ref> [13] </ref>. Thus we used 6 fi 6 arenas, with 6 boxes randomly distributed in the inner 4 fi 4 grid. <p> In order to determine if Teller's configuration of eight sensors <ref> [13] </ref>, could be improved upon, we allowed evolution to start with random initial networks with the eight sensors placed as in Exper iment 1. The sensor positions were incorporated as eight additional genes in the genotypic representation used in the above experiment.
References-found: 13

