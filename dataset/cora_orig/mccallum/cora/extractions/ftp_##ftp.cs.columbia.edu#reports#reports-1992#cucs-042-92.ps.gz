URL: ftp://ftp.cs.columbia.edu/reports/reports-1992/cucs-042-92.ps.gz
Refering-URL: http://www.cs.columbia.edu/~library/1992.html
Root-URL: http://www.cs.columbia.edu
Title: Revision Approach  
Author: Jacques Robin 
Degree: (PhD. Thesis Proposal)  
Date: September 9, 1992  
Address: New York, NY 10027  
Affiliation: Department of Computer Science Columbia University  
Note: Information: a Draft and  
Pubnum: Technical Report CUCS-042-92  
Abstract: Generating Newswire Report Leads with Historical Abstract In this paper I investigate the issue of providing historical background in computer-generated reports. I first observe that ignoring this issue is the most drastic limitation of existing report generation systems. I then present an empirical corpus analysis of basketball summaries aimed at discovering the specific means by which historical information is conveyed in human-generated reports. This analysis resulted in a set of data that forms the basis for the implementation of streak, a system generating basketball report leads with historical information. This data shows that building such a system cannot be based on the single-pass pipelined architecture of previous systems. Instead, I propose an entirely new architecture in which generation proceeds in two passes. The first pass builds a report draft containing only the basic facts. The second pass incrementally revises this draft to include additional facts providing the historical background. Independently of the issue of historical information, I show that this architecture also allows the generation of more complex and syntactically diverse sentences than previous generation systems. I also explain how the information-adding revision framework defined by this architecture differs from previous work in generation with revision. I then delimit the additional research I propose to pursue within this framework. I conclude by showing how the proposed work will make several significant contributions to four natural language generation topics: report generation, complex sentence generation, generation architecture and generation with revision. 
Abstract-found: 1
Intro-found: 1
Reference: [ Anderson 1985 ] <author> D. Anderson. </author> <title> Contemporary sports reporting. </title> <address> Nelson-Hall, Chicago, IL, </address> <year> 1985. </year>
Reference-contexts: An example box-score with the corresponding report is given in Fig. 8. In this report, fine-grained statistics not available in the box-score are emphasized by an italic font (historical information is, as usual, emphasized by a boldface font). Such finer grained statistics come from complete game charts <ref> [ Anderson 1985 ] </ref> . Box-scores are available on-line through newswire and sport statistic computer services, whereas game charts are not 12 . Therefore, only box-scores constitute a realistic statistical input for a report generation system.
Reference: [ Appelt 1985 ] <author> D. Appelt. </author> <title> Planning Natural Language Utterances. </title> <booktitle> Studies in Natural Language Processing. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1985. </year>
Reference-contexts: work: * It works in a two-pass draft and revision mode [ Mann 1983 ] [ Vaughan and McDonald 1986 ] [ Yazdani 1987 ] [ Wong and Simmons 1988 ] [ Cline and Nutter 1991 ] [ Inui et al. 1992 ] . * It interleaves planning and realization <ref> [ Appelt 1985 ] </ref> [ Hovy 1988 ] . * It is incremental [ De Smedt 1990 ] . * It uses declarative knowledge sources [ Nogier 1990 ] [ Polguere 1990 ] . * It is stratificational and modular [ Polguere 1990 ] . * It uses a uniform underlying
Reference: [ Bateman 1989 ] <author> J.A. Bateman. Upper-modelling: </author> <title> current states of theory and practise - part1: foundations and related approaches -, 1989. </title> <type> Draft. </type>
Reference-contexts: This identity can be captured only by a purely conceptual representation that totally abstracts from linguistic form. A linguistically motivated semantic representation such as penman's Upper-Model <ref> [ Bateman 1989 ] </ref> , would view (X) as a material action and (Y) as a possessed object, two radically different semantic categories. It would thus fail to capture their identity of meaning. This contrast between conceptual and linguistic semantic representations is further discussed in section 3.3.1. <p> If it is like an SSS, the domain knowledge of the generator must be encoded in terms of linguistically motivated categories. This is the approach advocated by PENMAN's Upper-Model <ref> [ Bateman 1989 ] </ref> , where the propositions and entities of the domain knowledge base are viewed as instances of domain-independent categories defined in terms of linguistic ranks and thematic roles.
Reference: [ Bourbeau et al. 1990 ] <author> L. Bourbeau, D. Carcagno, E. Goldberg, R. Kittredge, and A. Polguere. </author> <title> Bilingual generation of weather forecasts in an operations environment. </title> <booktitle> In Proceedings of the 13th International Conference on Computational Linguistics. COLING, </booktitle> <year> 1990. </year>
Reference-contexts: Two existing systems have established the feasibility of report generation from statistics 1 : Ana [ Kukich 1983 ] and FoG <ref> [ Bourbeau et al. 1990 ] </ref> . Ana summarizes the daily fluctuations of several stock market indexes from half-hourly updates of their values. A report generated by Ana is given in Fig. 1. <p> In the introduction of this paper, I noted that both Ana [ Kukich 1983 ] and FoG <ref> [ Bourbeau et al. 1990 ] </ref> are based on the classic single-pass pipeline architecture 36 . I also explained that a single pass architecture is impractical for simultaneously achieving syntactic complexity and variety. <p> systems Target output coded Macrocoded of streak FoG Ana Danlos' system pauline min avg max Proposition number per sentences 4 4 7 7 4 6 9 Word number per sentences 10 28 33 34 21 32 46 In this table it is important to note that the output of FoG <ref> [ Bourbeau et al. 1990 ] </ref> is much simpler than the output of Ana [ Kukich 1983 ] , pauline [ Hovy 1988 ] and Danlos' system [ Danlos 1986 ] .
Reference: [ Boyer and Lapalme 1985 ] <author> M. Boyer and G. Lapalme. </author> <title> Generating paraphrases from meaning-text semantic networks. </title> <journal> Computational Intelligence, </journal> (3&4):103-117, August-November 1985. 
Reference-contexts: In contrast, this diversity can be economically achieved by a microcoding approach to sentence generation, where syntactic structures at all ranks are constructed from individual words 5 . Generators focusing on syntactic diversity (e.g., the system of <ref> [ Boyer and Lapalme 1985 ] </ref> and cook [ Smadja 1991 ] ) perform such micro-level planning. They have, however, limited themselves to the generation of simple sentences. Simultaneously achieving surface form complexity and surface form diversity requires microcoding complex sentences down to the individual words when necessary.
Reference: [ Cline and Nutter 1991 ] <author> B.E. Cline and J.T. Nutter. </author> <title> Conceptual revision for natural language generation, </title> <booktitle> 1991. Student session of the 29th Annual Meeting of the ACL. </booktitle>
Reference-contexts: It has been proposed in different flavors by Mann [ Mann 1983 ] , Meteer [ Vaughan and McDonald 1986 ] [ Meteer 1990 ] , Yazdani [ Yazdani 1987 ] , Gabriel [ Gabriel 1988 ] , Wong and Simmons [ Wong and Simmons 1988 ] Cline and Nutter <ref> [ Cline and Nutter 1991 ] </ref> and very recently [ Inui et al. 1992 ] . However, to the best of my knowledge, only two implemented generation system emerged from these proposals: Gabriel's Yh and Inui et. al's weiveR. <p> also interesting in that it combines a unique set of properties whose desirability has been independently advocated in previous work: * It works in a two-pass draft and revision mode [ Mann 1983 ] [ Vaughan and McDonald 1986 ] [ Yazdani 1987 ] [ Wong and Simmons 1988 ] <ref> [ Cline and Nutter 1991 ] </ref> [ Inui et al. 1992 ] . * It interleaves planning and realization [ Appelt 1985 ] [ Hovy 1988 ] . * It is incremental [ De Smedt 1990 ] . * It uses declarative knowledge sources [ Nogier 1990 ] [ Polguere 1990
Reference: [ Dale 1988 ] <author> R. Dale. </author> <title> Generating referring expressions in a domain of objects and processes. </title> <type> PhD thesis, </type> <institution> University of Edinburgh, </institution> <address> Scotland, </address> <year> 1988. </year>
Reference-contexts: A macrocoded generator like Ana produces sentences by assembling entire clauses and group patterns stored as a whole in its phrasal lexicon. In contrast, a microcoded generator like epicure <ref> [ Dale 1988 ] </ref> dynamically builds from a word-based lexicon 32 every sentence constituent down to the group rank. The level of microcoding at which a generator operates is a crucial architectural characteristic because, apart from content realization, it also has repercussions on content selection and content organization. <p> The architecture thus belongs to the stratificational tradition of computational linguistics (cf. <ref> [ Dale 1988 ] </ref> and [ Polguere 1990 ] for other generation systems using a stratificational utterance representation scheme), with multiple representation layers, each capturing a specific set of regularities. The general stratificational scheme I propose is sketched in Fig. 21. <p> Implicit content, such as aspect in the example above, is inferable from the context and represented only at the DSS level. In contrast, explicit content, such as time-scope in the example above, is necessarily realized by some linguistic element and also represented at the SSS level. <ref> [ Dale 1988 ] </ref> adopted a double semantic representation in epicure specifically for such purpose. The issue of implicit content is linked to problems such as user models and hearer's knowledge, that lay beyond the scope of the research proposed here. <p> uses declarative knowledge sources [ Nogier 1990 ] [ Polguere 1990 ] . * It is stratificational and modular [ Polguere 1990 ] . * It uses a uniform underlying formalism (fuf's feature structures) to represent utterances at all levels of abstraction and all linguistic ranks [ Simonin 1985 ] <ref> [ Dale 1988 ] </ref> [ Elhadad 1992 ] .
Reference: [ Danlos 1986 ] <author> L. Danlos. </author> <title> The linguistic basis of text generation. </title> <booktitle> Studies in Natural Language Processing. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1986. </year>
Reference-contexts: In order to discover the specific means by which historical information is conveyed, I carried out an empirical analysis of a corpus of basketball game reports 1 Danlos' generator <ref> [ Danlos 1986 ] </ref> , PAULINE [ Hovy 1988 ] and TEXPLAN [ Maybury 1990 ] are other generation systems producing "reports". However, they work in non-quantitative domains and take as input frame-like structures instead of statistics. <p> number per sentences 10 28 33 34 21 32 46 In this table it is important to note that the output of FoG [ Bourbeau et al. 1990 ] is much simpler than the output of Ana [ Kukich 1983 ] , pauline [ Hovy 1988 ] and Danlos' system <ref> [ Danlos 1986 ] </ref> . This difference 60 To the best of my knowledge. 61 More sophisticated measures could be devised, for example counting only open-class words or taking into account maximal depth of constituent embedding.
Reference: [ De Smedt 1990 ] <author> K.J.M.J. De Smedt. </author> <title> Incremental sentence generation: a computer model of grammatical encoding. </title> <address> Samson-Sijthoff, The Netherlands, </address> <year> 1990. </year>
Reference-contexts: 1983 ] [ Vaughan and McDonald 1986 ] [ Yazdani 1987 ] [ Wong and Simmons 1988 ] [ Cline and Nutter 1991 ] [ Inui et al. 1992 ] . * It interleaves planning and realization [ Appelt 1985 ] [ Hovy 1988 ] . * It is incremental <ref> [ De Smedt 1990 ] </ref> . * It uses declarative knowledge sources [ Nogier 1990 ] [ Polguere 1990 ] . * It is stratificational and modular [ Polguere 1990 ] . * It uses a uniform underlying formalism (fuf's feature structures) to represent utterances at all levels of abstraction and
Reference: [ Elhadad and Robin 1992 ] <author> M. Elhadad and J. Robin. </author> <title> Controlling Content Realization with Functional Unification Grammars. </title> <editor> In R. Dale, H. Hovy, D. Roesner, and O. Stock, editors, </editor> <booktitle> Aspects of Automated Natural Language Generation, </booktitle> <pages> pages 89-104. </pages> <publisher> Springler Verlag, </publisher> <year> 1992. </year>
Reference-contexts: This mechanism is a general facility that allows dynamic enrichment of a fuf grammar with information from any outside knowledge source. It is presented in detail in <ref> [ Elhadad and Robin 1992 ] </ref> .
Reference: [ Elhadad 1990 ] <author> M. Elhadad. </author> <title> Types in Functional Unification Grammars. </title> <booktitle> In Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> Detroit, MI, </address> <year> 1990. </year> <booktitle> ACL. </booktitle>
Reference-contexts: In the streak prototype, the domain knowledge base is implemented in classic [ Resnick et al. 1990 ] and the surface sentence generator is surge [ Elhadad 1992 ] , an realization grammar of English working with the functional unifier fuf <ref> [ Elhadad 1990 ] </ref> [ Elhadad 1991 ] . 33 Because of these biases and in order to ensure maximum uniformity the three layers are syntactically identical: they are all fuf feature structures. A fuf feature structure is essentially a set of attribute-value pairs.
Reference: [ Elhadad 1991 ] <author> M. Elhadad. FUF: </author> <title> The universal unifier user manual, version 5.0. </title> <type> Technical Report CUCS-038-91, </type> <institution> Columbia University, </institution> <year> 1991. </year>
Reference-contexts: In the streak prototype, the domain knowledge base is implemented in classic [ Resnick et al. 1990 ] and the surface sentence generator is surge [ Elhadad 1992 ] , an realization grammar of English working with the functional unifier fuf [ Elhadad 1990 ] <ref> [ Elhadad 1991 ] </ref> . 33 Because of these biases and in order to ensure maximum uniformity the three layers are syntactically identical: they are all fuf feature structures. A fuf feature structure is essentially a set of attribute-value pairs. <p> This system consists of the functional unifier fuf <ref> [ Elhadad 1991 ] </ref> underlying the implementation of the other components of streak and of the English grammar surge (Semantic Unification Realization Grammar of English). fuf produces an English sentence by unifying surge with an input Functional Description (FD).
Reference: [ Elhadad 1992 ] <author> M. Elhadad. </author> <title> Using argumentation to control lexical choice: a unification-based approach. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Columbia University, </institution> <year> 1992. </year>
Reference-contexts: In the streak prototype, the domain knowledge base is implemented in classic [ Resnick et al. 1990 ] and the surface sentence generator is surge <ref> [ Elhadad 1992 ] </ref> , an realization grammar of English working with the functional unifier fuf [ Elhadad 1990 ] [ Elhadad 1991 ] . 33 Because of these biases and in order to ensure maximum uniformity the three layers are syntactically identical: they are all fuf feature structures. <p> In the streak implementation, content production and the two first rounds of content selection will be simulated by hand. The surface sentence generator in charge of morpho-syntactic grammaticalization and linearization will be an extension of the system surge <ref> [ Elhadad 1992 ] </ref> . 3.3.4 Wider applicability of the proposed architecture Although the proposed architecture was conceived to answer the specific needs of historical background in report generation, its scope of applicability is wider. <p> Unification of this grammar with an input layer constituent simultaneously fires the appropriate mapping rule and builds the corresponding output layer constituent through enrichment. The details of top-down recursive functional unification process are presented in <ref> [ Elhadad 1992 ] </ref> , which also discusses related control issues. The DSS7!SSS rule base maps the purely conceptual features of the DSS onto the semantic linguistic features (thematic roles and general rhetorical relations) of the SSS. It thus chooses a surface realization perspective for each semantic constituent. <p> (add-path -^4 sss partic created elaboration- -partic created classifier sss-) (copy -bls partic created- -partic created head-) (add-path -^4 sss partic created elaborated- -partic created head sss-))))) 52 4.2.4 The surface sentence generator To produce actual English sentences streak will rely on the general purpose surface sentence generator developed by <ref> [ Elhadad 1992 ] </ref> . <p> As surface sentence generator streak uses surge. This system, implemented by M. Elhadad and described in detail in <ref> [ Elhadad 1992 ] </ref> , has been extensively tested in a variety of generation applications developed at several research centers. The remaining work on processing components thus concerns the revision rule interpreter. <p> In this example the participial adjunct clause is underlined, the parenthetical adjuncts and numbers are slanted and the complex NP headed by a compound proper name italicized. 54 Note that without these constructs specifically needed for report generation, surge is already one of the most extensive generation grammars available (cf. <ref> [ Elhadad 1992 ] </ref> ). 60 judged only as a testbed for the innovative solutions proposed in this paper. <p> entity by considering both (a) a set of features to convey about the entity in order to satisfy the current communicative goals, and (b) the complete description of this entity in the domain knowledge base [ Reiter 1991 ] . * Realization of floating semantic elements at various linguistic ranks <ref> [ Elhadad 1992 ] </ref> . * Conflation of several semantic elements inside a single syntactic constituent [ Elhadad 1992 ] The proposed architecture is also interesting in that it combines a unique set of properties whose desirability has been independently advocated in previous work: * It works in a two-pass draft <p> to satisfy the current communicative goals, and (b) the complete description of this entity in the domain knowledge base [ Reiter 1991 ] . * Realization of floating semantic elements at various linguistic ranks <ref> [ Elhadad 1992 ] </ref> . * Conflation of several semantic elements inside a single syntactic constituent [ Elhadad 1992 ] The proposed architecture is also interesting in that it combines a unique set of properties whose desirability has been independently advocated in previous work: * It works in a two-pass draft and revision mode [ Mann 1983 ] [ Vaughan and McDonald 1986 ] [ Yazdani 1987 <p> [ Nogier 1990 ] [ Polguere 1990 ] . * It is stratificational and modular [ Polguere 1990 ] . * It uses a uniform underlying formalism (fuf's feature structures) to represent utterances at all levels of abstraction and all linguistic ranks [ Simonin 1985 ] [ Dale 1988 ] <ref> [ Elhadad 1992 ] </ref> .
Reference: [ Fawcett 1987 ] <author> R.P. Fawcett. </author> <title> The semantics of clause and verb for relational processes in English. In M.A.K. Halliday and R.P. Fawcett, editors, New developments in systemic linguistics. </title> <publisher> Frances Pinter, </publisher> <address> London and New York, </address> <year> 1987. </year>
Reference-contexts: against an average 3.83 and a maximum 7 realization patterns per game result cluster proposition combination. 20 The particular grammatical functions, structural relations and syntactic categories used in this paper are inspired from: [ Quirk et al. 1972 ] , [ Winograd 1983 ] , [ Halliday 1985 ] and <ref> [ Fawcett 1987 ] </ref> . 21 e.g. connectives, mood etc. 22 The "aspect" of a streak event specifies whether the streak has been extended or interrupted by the reported game result. <p> Fig. 23 gives three example SSSs. Consider SSS 2 at the bottom of that figure. Its features agent and created are examples of general semantic features. They are part of a set of thematic roles proposed by systemic linguists <ref> [ Fawcett 1987 ] </ref> . Similarly, its features elaboration and elaborated are examples of general rhetorical features. They are part of a set of rhetorical relations proposed by researchers in Rhetorical Structure Theory (RST) [ Mann and Thompson 1987 ] 38 . <p> The representation obtained after this mapping is what constitutes a surface grammatical specification. The thematic and syntactic roles used in surge are inspired from a variety of sources, most notably [ Quirk et al. 1972 ] [ Winograd 1983 ] [ Halliday 1985 ] and <ref> [ Fawcett 1987 ] </ref> . One great quality of surge is its ability to complete partially specified inputs with default features. These defaults concern syntactic roles, syntactic properties and closed-class lexical items. <p> It consists of a revision rule interpreter and a revision rule base. The revision rule interpreter is implemented on top of fuf and uses functional unification for rule matching. The LHS of a revision rule is made of two fields: a base LS pattern 44 In the sense of <ref> [ Fawcett 1987 ] </ref> . 47 Example of DSS7!SSS mapping rule: ((dss ((deepsemcat game-stat-ref) (actor GIVEN) (value GIVEN))) (sss ((surfsemcat evt-spec) (concept game-stat) (proc ((type material) (effect-type creative))) (partic ((agent ((dss -^4 dss actor-))) (created ((dss -^ 4 dss value-)))))))) Example of SSS7!DGS mapping rule: ((sss ((surfsemcat evt-spec) (concept game-stat) (partic
Reference: [ Fensch 1988 ] <author> T. Fensch. </author> <title> The sports writing handbook. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1988. </year>
Reference-contexts: I then distinguished between different types of information conveyed in the corpus to choose a semantic focus. Report structure and discursive focus Journalism textbooks define a variety of standard report structures. The corpus reports are organized following the so-called inverted pyramid structure with summary lead <ref> [ Fensch 1988 ] </ref> , meaning that crucial information is packed in the lead followed by facts of decreasing importance towards the end of the report. Summary type leads, often consisting in a single sentence in the corpus reports, are thus self-contained mini-reports containing the basic facts.
Reference: [ Gabriel 1988 ] <editor> R. Gabriel. Deliberate writing. In D.D. McDonald and Bolc L., editors, </editor> <booktitle> Natural Language Generation Systems. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1988. </year>
Reference-contexts: It has been proposed in different flavors by Mann [ Mann 1983 ] , Meteer [ Vaughan and McDonald 1986 ] [ Meteer 1990 ] , Yazdani [ Yazdani 1987 ] , Gabriel <ref> [ Gabriel 1988 ] </ref> , Wong and Simmons [ Wong and Simmons 1988 ] Cline and Nutter [ Cline and Nutter 1991 ] and very recently [ Inui et al. 1992 ] .
Reference: [ Gross 1984 ] <author> M. Gross. </author> <title> Lexicon-Grammar and the syntactic analysis of French. </title> <booktitle> In Proceedings of the 10th International Conference on Computational Linguistics, </booktitle> <pages> pages 275-282. COLING, </pages> <year> 1984. </year>
Reference-contexts: Certain complex revision tools can only be applied to specific types of base structure. For example, adjunctization applies only to clausal base patterns headed by a support verb Sv. Following Gross <ref> [ Gross 1984 ] </ref> , I call support verb any verb that does not realize any semantic element. Appearing only because each clause syntactically requires a verb in English, its sole function is to support one of its meaning-bearing arguments.
Reference: [ Halliday 1985 ] <author> M.A.K. Halliday. </author> <title> An introduction to functional grammar. </title> <publisher> Edward Arnold, </publisher> <address> London, </address> <year> 1985. </year>
Reference-contexts: In the first structure they are in parataxis while in the second they are in hypotaxis, with the prominent statistic as head. In this paper, I use the notions of parataxis and hypotaxis defined in <ref> [ Halliday 1985 ] </ref> , because they are general relations between syntactic constituents occurring at all linguistic ranks (sentence, clause, group). Two constituents are in parataxis if they are both at the same structural level. Parataxis is thus a general symmetric relation covering both coordination and apposition. <p> prominent statistic cluster proposition combination against an average 3.83 and a maximum 7 realization patterns per game result cluster proposition combination. 20 The particular grammatical functions, structural relations and syntactic categories used in this paper are inspired from: [ Quirk et al. 1972 ] , [ Winograd 1983 ] , <ref> [ Halliday 1985 ] </ref> and [ Fawcett 1987 ] . 21 e.g. connectives, mood etc. 22 The "aspect" of a streak event specifies whether the streak has been extended or interrupted by the reported game result. <p> The representation obtained after this mapping is what constitutes a surface grammatical specification. The thematic and syntactic roles used in surge are inspired from a variety of sources, most notably [ Quirk et al. 1972 ] [ Winograd 1983 ] <ref> [ Halliday 1985 ] </ref> and [ Fawcett 1987 ] . One great quality of surge is its ability to complete partially specified inputs with default features. These defaults concern syntactic roles, syntactic properties and closed-class lexical items.
Reference: [ Hovy 1988 ] <author> E. Hovy. </author> <title> Generating natural language under pragmatic constraints. </title> <editor> L. </editor> <publisher> Erlbaum Associates, </publisher> <address> Hillsdale, N.J., </address> <year> 1988. </year>
Reference-contexts: In order to discover the specific means by which historical information is conveyed, I carried out an empirical analysis of a corpus of basketball game reports 1 Danlos' generator [ Danlos 1986 ] , PAULINE <ref> [ Hovy 1988 ] </ref> and TEXPLAN [ Maybury 1990 ] are other generation systems producing "reports". However, they work in non-quantitative domains and take as input frame-like structures instead of statistics. The system SAGE suggests the great potential for office-automation applications of quantitative report generation. <p> Although in many cases an underlying application provides the generator with all the potential content, in other cases the generator's input is but one part of that content. The rest of the content has to be produced by the generator itself. This is what Hovy calls interpretation in generation <ref> [ Hovy 1988 ] </ref> : the generator needs to enrich its input with more content. In the extreme case the input consists only of communicative goals and it is the generator's task to produce all content from the knowledge sources it can access. <p> in a two-pass draft and revision mode [ Mann 1983 ] [ Vaughan and McDonald 1986 ] [ Yazdani 1987 ] [ Wong and Simmons 1988 ] [ Cline and Nutter 1991 ] [ Inui et al. 1992 ] . * It interleaves planning and realization [ Appelt 1985 ] <ref> [ Hovy 1988 ] </ref> . * It is incremental [ De Smedt 1990 ] . * It uses declarative knowledge sources [ Nogier 1990 ] [ Polguere 1990 ] . * It is stratificational and modular [ Polguere 1990 ] . * It uses a uniform underlying formalism (fuf's feature structures) <p> 4 7 7 4 6 9 Word number per sentences 10 28 33 34 21 32 46 In this table it is important to note that the output of FoG [ Bourbeau et al. 1990 ] is much simpler than the output of Ana [ Kukich 1983 ] , pauline <ref> [ Hovy 1988 ] </ref> and Danlos' system [ Danlos 1986 ] . This difference 60 To the best of my knowledge. 61 More sophisticated measures could be devised, for example counting only open-class words or taking into account maximal depth of constituent embedding.
Reference: [ Hovy 1990 ] <author> E. Hovy. </author> <title> Unresolved issues in paragraph planning. </title> <editor> In R. Dale, C.S. Mellish, and M. Zock, editors, </editor> <booktitle> Current Research in Natural Language Generation. </booktitle> <publisher> Academic Press, </publisher> <year> 1990. </year> <month> 85 </month>
Reference-contexts: This expensive search is avoided in Yh by relying on knowledge extremely specific to the tiny domain of the Dutch National Flag game. It could not be avoided in a more complex domain. 49 Or in Hovy's term, expanding growth-points <ref> [ Hovy 1990 ] </ref> . 55 6 Current status and remaining work In this section I review, for each aspect of the research proposed in this paper, what has already been completed and what part of the remaining work I intend to complete before the thesis defense.
Reference: [ Hovy 1991 ] <author> E. Hovy. </author> <title> Approaches to the planning of coherent text. </title> <editor> In C. Paris, W. Swartout, and Mann. W.C., editors, </editor> <booktitle> Natutal Language Generation in Artificial Intelligence and Computational Linguistics. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year>
Reference-contexts: I will thus not address the issues raised by the identification and operational use of these rhetorical patterns. I simply assume that it can be carried out using known techniques such as schemata [ McKeown 1985 ] or RST planning <ref> [ Hovy 1991 ] </ref> . The result of this structuring process is a structured DSS that constitutes the first layer of the initial draft representation. This DSS is sent to the DSS7!SSS mapper which returns a corresponding SSS.
Reference: [ Inui et al. 1992 ] <author> K. Inui, T. Tokunaga, and H. Tanaka. </author> <title> Text revision: a model and its implementation. </title> <editor> In R. Dale, E. Hovy, D. Roesner, and O. Stock, editors, </editor> <booktitle> Aspects of Automated Natural Language Generation, </booktitle> <pages> pages 215-230. </pages> <address> Springler-Verlag, </address> <year> 1992. </year>
Reference-contexts: [ Mann 1983 ] , Meteer [ Vaughan and McDonald 1986 ] [ Meteer 1990 ] , Yazdani [ Yazdani 1987 ] , Gabriel [ Gabriel 1988 ] , Wong and Simmons [ Wong and Simmons 1988 ] Cline and Nutter [ Cline and Nutter 1991 ] and very recently <ref> [ Inui et al. 1992 ] </ref> . However, to the best of my knowledge, only two implemented generation system emerged from these proposals: Gabriel's Yh and Inui et. al's weiveR. <p> a unique set of properties whose desirability has been independently advocated in previous work: * It works in a two-pass draft and revision mode [ Mann 1983 ] [ Vaughan and McDonald 1986 ] [ Yazdani 1987 ] [ Wong and Simmons 1988 ] [ Cline and Nutter 1991 ] <ref> [ Inui et al. 1992 ] </ref> . * It interleaves planning and realization [ Appelt 1985 ] [ Hovy 1988 ] . * It is incremental [ De Smedt 1990 ] . * It uses declarative knowledge sources [ Nogier 1990 ] [ Polguere 1990 ] . * It is stratificational <p> Recall from section 5 that, although the literature contains many proposal for generation with revision, only one such proposal resulted in an implementation, the system weiveR <ref> [ Inui et al. 1992 ] </ref> . But weiveR performs only information-preserving revisions that makes its output more stylistically elegant. In addition of being entirely new, the information-adding type of revision performed by streak is also interesting because it brings together generation with revision and incremental generation.
Reference: [ Kukich 1983 ] <author> K. Kukich. </author> <title> Knowledge-based report generation: a knowledge engineering approach to natural language report generation. </title> <type> PhD thesis, </type> <institution> University of Pittsburgh, </institution> <year> 1983. </year>
Reference-contexts: 1 Introduction As computer access to larger and more diverse sources of quantitative data is becoming commonplace, the automatic production of natural language reports summarizing such data is a generation application of increasing interest. Two existing systems have established the feasibility of report generation from statistics 1 : Ana <ref> [ Kukich 1983 ] </ref> and FoG [ Bourbeau et al. 1990 ] . Ana summarizes the daily fluctuations of several stock market indexes from half-hourly updates of their values. A report generated by Ana is given in Fig. 1. <p> In the introduction of this paper, I noted that both Ana <ref> [ Kukich 1983 ] </ref> and FoG [ Bourbeau et al. 1990 ] are based on the classic single-pass pipeline architecture 36 . I also explained that a single pass architecture is impractical for simultaneously achieving syntactic complexity and variety. <p> In particular, FoG maps domain propositions onto a lexicalized syntactic structures in a single step. Polguere notes that for domains with floating semantic elements, this mapping would need to be decomposed in several steps. Ana's target stock market sublanguage contains examples of floating semantic elements (cf. <ref> [ Kukich 1983 ] </ref> , p.74-75). However, although Ana does produce paraphrases where the same floating element is realized at different ranks, Ana does not explicitly choose at what rank to realize floating elements. With Ana's macrocoded architecture, no distinction is made between structural and floating elements. <p> max Proposition number per sentences 4 4 7 7 4 6 9 Word number per sentences 10 28 33 34 21 32 46 In this table it is important to note that the output of FoG [ Bourbeau et al. 1990 ] is much simpler than the output of Ana <ref> [ Kukich 1983 ] </ref> , pauline [ Hovy 1988 ] and Danlos' system [ Danlos 1986 ] . This difference 60 To the best of my knowledge. 61 More sophisticated measures could be devised, for example counting only open-class words or taking into account maximal depth of constituent embedding.
Reference: [ Lenat and Guha 1989 ] <author> D.B. Lenat and R.V Guha. </author> <title> Building large knowledge base systems: representation and inference in the Cyc project. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: The problem arises with overusing linguistic criteria and in particular linguistic rank and thematic roles for defining these general concepts. The temptation for such overuse is great because there are not too many non-linguistic criteria to fall back on for defining an Upper-Model (see <ref> [ Lenat and Guha 1989 ] </ref> for an attempt to build a non-linguistically motivated general ontology). However, semantic linguistic categories are best viewed as constituting a "surface perspective" model rather than an "upper" model. Without a DSS, a system can thus hardly handle paraphrases that cut across linguistic ranks.
Reference: [ Mann and Moore 1981 ] <author> W.C. Mann and J.A. Moore. </author> <title> Computer Generation of Multiparagraph English Text. </title> <journal> Computational Linguistics, </journal> <volume> 7(1) </volume> <pages> 17-29, </pages> <year> 1981. </year>
Reference-contexts: Apart from distinguishing information-adding revision from plan-elaboration, the presence of a surface 47 Note that Meteer's proposal is for future work. SPOKESMAN does not perform revision. 48 In that sense, the hill-climbing phase of KDS <ref> [ Mann and Moore 1981 ] </ref> is not revision but local backtracking. 54 layer in the representation on which revision is performed is needed for another reason. By nature, report generation is a summarization task. It thus involves trade-offs between inherently conflicting goals: (1) informativity, (2) conciseness and (3) readability.
Reference: [ Mann and Thompson 1987 ] <author> W.C. Mann and S. Thompson. </author> <title> Rhetorical Structure Theory: description and constructions of text structures. </title> <editor> In Gerard Kempen, editor, </editor> <booktitle> Natural Language Generation: New Results in Artificial Intellligence, Psychology and Linguistics, </booktitle> <pages> pages 85-96. </pages> <publisher> Martinus Ninjhoff Publishers, </publisher> <year> 1987. </year>
Reference-contexts: They are part of a set of thematic roles proposed by systemic linguists [ Fawcett 1987 ] . Similarly, its features elaboration and elaborated are examples of general rhetorical features. They are part of a set of rhetorical relations proposed by researchers in Rhetorical Structure Theory (RST) <ref> [ Mann and Thompson 1987 ] </ref> 38 . Although linguistically motivated, the SSS is still a semantic representation abstracting from lexical and syntactic details.
Reference: [ Mann 1983 ] <author> W.C. Mann. </author> <title> An overview of the PENMAN text generation system. </title> <type> Technical Report ISI/RR-83-114, ISI, </type> <institution> Marina del Rey, </institution> <address> CA, </address> <year> 1983. </year>
Reference-contexts: The limitations of the current implementation are discussed in detail in section 6.1. 53 5 Previous work in generation with revision In itself, the idea of revision in generation is not really new. It has been proposed in different flavors by Mann <ref> [ Mann 1983 ] </ref> , Meteer [ Vaughan and McDonald 1986 ] [ Meteer 1990 ] , Yazdani [ Yazdani 1987 ] , Gabriel [ Gabriel 1988 ] , Wong and Simmons [ Wong and Simmons 1988 ] Cline and Nutter [ Cline and Nutter 1991 ] and very recently [ <p> . * Conflation of several semantic elements inside a single syntactic constituent [ Elhadad 1992 ] The proposed architecture is also interesting in that it combines a unique set of properties whose desirability has been independently advocated in previous work: * It works in a two-pass draft and revision mode <ref> [ Mann 1983 ] </ref> [ Vaughan and McDonald 1986 ] [ Yazdani 1987 ] [ Wong and Simmons 1988 ] [ Cline and Nutter 1991 ] [ Inui et al. 1992 ] . * It interleaves planning and realization [ Appelt 1985 ] [ Hovy 1988 ] . * It is
Reference: [ Maybury 1990 ] <author> M.T. </author> <title> Maybury. Using discourse focus, temporal focus and spatial focus to generate mul-tisentential text. </title> <booktitle> In Proceedings of the 5th International Workshop on Natural Language Generation, </booktitle> <address> Pittsburgh, PA, </address> <year> 1990. </year>
Reference-contexts: In order to discover the specific means by which historical information is conveyed, I carried out an empirical analysis of a corpus of basketball game reports 1 Danlos' generator [ Danlos 1986 ] , PAULINE [ Hovy 1988 ] and TEXPLAN <ref> [ Maybury 1990 ] </ref> are other generation systems producing "reports". However, they work in non-quantitative domains and take as input frame-like structures instead of statistics. The system SAGE suggests the great potential for office-automation applications of quantitative report generation.
Reference: [ McKeown 1985 ] <author> K. R. McKeown. </author> <title> Using Discourse Strategies and Focus Constraints to Generate Natural Language Text. </title> <booktitle> Studies in Natural Language Processing. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1985. </year>
Reference-contexts: All the other classes consistently appeared in the same cluster. This proposition clustering phenomenon is illustrated in Fig. 12. It shows where additional propositions from each ontological class gets attached. These semantic constraints on proposition clustering can be viewed as schemata <ref> [ McKeown 1985 ] </ref> for sentence-rank planning. <p> The report structuring component is also out of the scope of the research proposed here. I will thus not address the issues raised by the identification and operational use of these rhetorical patterns. I simply assume that it can be carried out using known techniques such as schemata <ref> [ McKeown 1985 ] </ref> or RST planning [ Hovy 1991 ] . The result of this structuring process is a structured DSS that constitutes the first layer of the initial draft representation. This DSS is sent to the DSS7!SSS mapper which returns a corresponding SSS.
Reference: [ Mencher 1984 ] <author> M. Mencher. </author> <title> News reporting and writing. Wm. </title> <address> C. </address> <publisher> Brown Publishers, </publisher> <address> Dubuque, Iowa, </address> <year> 1984. </year>
Reference-contexts: Summary type leads, often consisting in a single sentence in the corpus reports, are thus self-contained mini-reports containing the basic facts. This type of report structure is not particular to sports reporting but is pervasive in newswire articles <ref> [ Mencher 1984 ] </ref> . It is preferred because newswire reports are essentially used as draft material to be edited by client newspapers under heavy time-pressure and stringent space constraints. An inverted pyramid structure with a summary lead makes a report instantly editable by cutting its tail.
Reference: [ Meteer et al. 1987 ] <author> M.W. Meteer, D.D. McDonald, S.D. Anderson, D. Forster, L.S. Gay, A.K. Huettner, and P. Sibun. Mumble-86: </author> <title> Design and implementation. </title> <type> Technical Report COINS 87-87, </type> <institution> University of Massachussets at Amherst, </institution> <address> Ahmerst, Ma., </address> <year> 1987. </year>
Reference-contexts: Although grammatical constituency is already decided at that level, many grammatical features and open-class lexical items with different stylistic impacts are not yet specified. The level of representation that unequivocally determines a natural language utterance in spokesman is the Linguistic Specification input to mumble-86 <ref> [ Meteer et al. 1987 ] </ref> . Using spokesman levels of representation, revising to improve the draft trade-off between informativity, conciseness and readability, would probably require acting upon both the Text-Structure level and the Linguistic Specification level.
Reference: [ Meteer 1990 ] <author> M.W. Meteer. </author> <title> The generation gap: the problem of expressibility in text planning. </title> <type> PhD thesis, </type> <institution> University of Massachussets at Ahmerst, </institution> <year> 1990. </year> <note> Also available as BBN technical report No. 7347. </note>
Reference-contexts: The need for a representation that bridges the gap between conceptual and syntactic processing has been advocated in detail by <ref> [ Meteer 1990 ] </ref> . For alternative schemes using a single semantic representation, there are two possibilities: either their single semantic layer is like a DSS or it is like an SSS. <p> It has been proposed in different flavors by Mann [ Mann 1983 ] , Meteer [ Vaughan and McDonald 1986 ] <ref> [ Meteer 1990 ] </ref> , Yazdani [ Yazdani 1987 ] , Gabriel [ Gabriel 1988 ] , Wong and Simmons [ Wong and Simmons 1988 ] Cline and Nutter [ Cline and Nutter 1991 ] and very recently [ Inui et al. 1992 ] . <p> This is why the other authors proposed, like I do, to perform revision directly on some representation of the generator's internal draft. This is also perhaps why in her thesis <ref> [ Meteer 1990 ] </ref> , after having dismissed revision of an internal representation as mere "optimization" and opposed it to "true revision" requiring analyzing an actual natural language output, Meteer then proposes to perform revision on the Text-Structure, a level of representation internal to her spokesman generation system 47 .
Reference: [ Nogier 1990 ] <author> J.F. Nogier. </author> <title> Un systeme de production de language fonde sur le modele des graphes conceptuels. </title> <type> PhD thesis, </type> <institution> Universite de Paris VII, </institution> <year> 1990. </year>
Reference-contexts: [ Wong and Simmons 1988 ] [ Cline and Nutter 1991 ] [ Inui et al. 1992 ] . * It interleaves planning and realization [ Appelt 1985 ] [ Hovy 1988 ] . * It is incremental [ De Smedt 1990 ] . * It uses declarative knowledge sources <ref> [ Nogier 1990 ] </ref> [ Polguere 1990 ] . * It is stratificational and modular [ Polguere 1990 ] . * It uses a uniform underlying formalism (fuf's feature structures) to represent utterances at all levels of abstraction and all linguistic ranks [ Simonin 1985 ] [ Dale 1988 ] [
Reference: [ Pavard 1985 ] <editor> B. Pavard. La conception de systemes de traitement de texte. Intellectica, </editor> <volume> 1(1) </volume> <pages> 37-67, </pages> <year> 1985. </year>
Reference-contexts: have also suggested that the need to produce very complex sentences through microcoding calls for a two-pass draft and revision generation model. 36 This architecture was outlined in Fig. 6 on p.6. 30 From a cognitive perspective, the need to generate very complex sentences in itself supports this revision approach. <ref> [ Pavard 1985 ] </ref> describes an experiment providing psychological evidence supporting the revision model for the generation of very complex sentences. In this experiment, human subjects were asked to write a single sentence paraphrasing a text of three sentences which together conveyed eight propositions in 42 words. <p> Generating sentences semantically denser and syntactically more complex than macrocoded systems with the added flexibility of the microcoding approach will be the major contribution of streak to complex sentence generation. A lesser contribution will be to generate these sentences in a cognitively plausible way. The experiment of <ref> [ Pavard 1985 ] </ref> discussed in section 3.2.3 suggests that, for sentences of a complexity comparable to the target output of streak, the draft and revision model on which it is based is more cognitively plausible than the single-pass model of previous systems. 7.4 Contributions to generation with revision The research
Reference: [ Polguere 1990 ] <author> A. </author> <month> Polguere. </month> <institution> Structuration et mise en jeu procedurale d'un modele linguistique declaratif dans un cadre de generation de texte. </institution> <type> PhD thesis, </type> <institution> Universite de Montreal, </institution> <address> Quebec, Canada, </address> <year> 1990. </year>
Reference-contexts: FoG has no use for these abilities, since, as pointed out by Polguere in his thesis (cf. <ref> [ Polguere 1990 ] </ref> , p.14-16), there is only one realization pattern per proposition combination in FoG's meteorological target sublanguage. All semantic elements of this domain are thus structural. This peculiar property was exploited to simplify the architecture of FoG. <p> The architecture thus belongs to the stratificational tradition of computational linguistics (cf. [ Dale 1988 ] and <ref> [ Polguere 1990 ] </ref> for other generation systems using a stratificational utterance representation scheme), with multiple representation layers, each capturing a specific set of regularities. The general stratificational scheme I propose is sketched in Fig. 21. <p> 1988 ] [ Cline and Nutter 1991 ] [ Inui et al. 1992 ] . * It interleaves planning and realization [ Appelt 1985 ] [ Hovy 1988 ] . * It is incremental [ De Smedt 1990 ] . * It uses declarative knowledge sources [ Nogier 1990 ] <ref> [ Polguere 1990 ] </ref> . * It is stratificational and modular [ Polguere 1990 ] . * It uses a uniform underlying formalism (fuf's feature structures) to represent utterances at all levels of abstraction and all linguistic ranks [ Simonin 1985 ] [ Dale 1988 ] [ Elhadad 1992 ] . <p> al. 1992 ] . * It interleaves planning and realization [ Appelt 1985 ] [ Hovy 1988 ] . * It is incremental [ De Smedt 1990 ] . * It uses declarative knowledge sources [ Nogier 1990 ] <ref> [ Polguere 1990 ] </ref> . * It is stratificational and modular [ Polguere 1990 ] . * It uses a uniform underlying formalism (fuf's feature structures) to represent utterances at all levels of abstraction and all linguistic ranks [ Simonin 1985 ] [ Dale 1988 ] [ Elhadad 1992 ] .
Reference: [ Quirk et al. 1972 ] <author> R. Quirk, S. Greenbaum, G. Leech, and J. Svartvik. </author> <title> A grammar of contemporary English. </title> <publisher> Longman, </publisher> <year> 1972. </year>
Reference-contexts: corpus contained an average 1.29 and a maximum 4 realization patterns per prominent statistic cluster proposition combination against an average 3.83 and a maximum 7 realization patterns per game result cluster proposition combination. 20 The particular grammatical functions, structural relations and syntactic categories used in this paper are inspired from: <ref> [ Quirk et al. 1972 ] </ref> , [ Winograd 1983 ] , [ Halliday 1985 ] and [ Fawcett 1987 ] . 21 e.g. connectives, mood etc. 22 The "aspect" of a streak event specifies whether the streak has been extended or interrupted by the reported game result. <p> The representation obtained after this mapping is what constitutes a surface grammatical specification. The thematic and syntactic roles used in surge are inspired from a variety of sources, most notably <ref> [ Quirk et al. 1972 ] </ref> [ Winograd 1983 ] [ Halliday 1985 ] and [ Fawcett 1987 ] . One great quality of surge is its ability to complete partially specified inputs with default features. These defaults concern syntactic roles, syntactic properties and closed-class lexical items.
Reference: [ Reiter 1991 ] <author> E.B. Reiter. </author> <title> A New Model for Lexical Choice for Open-Class Words. </title> <journal> Computational Intelligence, </journal> <volume> (7), </volume> <month> December </month> <year> 1991. </year>
Reference-contexts: This querying facility also addresses the issue of dual input to the lexical choice component in a generation system. This issue was raised by <ref> [ Reiter 1991 ] </ref> who argued that in order to generate referring expressions appropriately, the lexical chooser needs two inputs: (1) a set of features describing the referent in way that satisfies the current communicative goals of the system and (2) the complete description of the referent in the domain knowledge <p> to convey op portunistically [ Rubinoff 1990 ] * Lexicalization of reference to a domain entity by considering both (a) a set of features to convey about the entity in order to satisfy the current communicative goals, and (b) the complete description of this entity in the domain knowledge base <ref> [ Reiter 1991 ] </ref> . * Realization of floating semantic elements at various linguistic ranks [ Elhadad 1992 ] . * Conflation of several semantic elements inside a single syntactic constituent [ Elhadad 1992 ] The proposed architecture is also interesting in that it combines a unique set of properties whose
Reference: [ Resnick et al. 1990 ] <author> L.A. Resnick, A. Borgida, R.J. Brachman, D.L. McGuiness, </author> <title> and Patel-Schneider R.F. CLASSIC: description and reference manual for the COMMON LISP implementation version 1.02, </title> <year> 1990. </year>
Reference-contexts: The three intermediate representations have been conceived with the following biases concerning these two end representations: the domain knowledge base uses a frame-like language and the surface sentence generator uses unification with a functional grammar. In the streak prototype, the domain knowledge base is implemented in classic <ref> [ Resnick et al. 1990 ] </ref> and the surface sentence generator is surge [ Elhadad 1992 ] , an realization grammar of English working with the functional unifier fuf [ Elhadad 1990 ] [ Elhadad 1991 ] . 33 Because of these biases and in order to ensure maximum uniformity the <p> There is therefore no such component in streak. However, streak does include an historical knowledge base implemented in classic <ref> [ Resnick et al. 1990 ] </ref> . Recall from section 3.3.2, that in the proposed architecture the mappers and the reviser must have the ability to query the historical knowledge base.
Reference: [ Roth et al. 1991 ] <author> S. Roth, J. Mattis, and X. Mesnard. </author> <title> Graphics and natural language as component of automatic explanation. </title> <editor> In J.W. Sullivan and S.W. Tyler, editors, </editor> <booktitle> Intelligent user-interfaces, </booktitle> <publisher> ACM press frontier. Addison-Wesley, </publisher> <year> 1991. </year> <month> 86 </month>
Reference-contexts: The system SAGE suggests the great potential for office-automation applications of quantitative report generation. However, focusing on the issue of coordinating textual and graphical media, this system relies on ad-hoc techniques for text generation (cf. <ref> [ Roth et al. 1991 ] </ref> , p.216). 2 The mention of the big board volume of the preceding day in the report of Fig. 1 is not historical information.
Reference: [ Rubinoff 1990 ] <author> R. Rubinoff. </author> <title> Natural Language Generation as an Intelligent Activity, 1990. </title> <type> PhD. Thesis Proposal, </type> <institution> Computer Science Department, University of Pennsylvania. </institution>
Reference-contexts: 66 In addition to these two individually unique abilities, another contribution of the proposed architecture is to be the first to cumulate a set of abilities which have been separately provided by previously proposed architectures: * Distinction between foreground content to convey obligatorily and background content to convey op portunistically <ref> [ Rubinoff 1990 ] </ref> * Lexicalization of reference to a domain entity by considering both (a) a set of features to convey about the entity in order to satisfy the current communicative goals, and (b) the complete description of this entity in the domain knowledge base [ Reiter 1991 ] .
Reference: [ Simonin 1985 ] <author> N. Simonin. Essai de modelisation de l'expertise en redaction de textes. </author> <booktitle> In Proceedings of COGNITIVA 85. COGNITIVA, </booktitle> <year> 1985. </year>
Reference-contexts: ] . * It uses declarative knowledge sources [ Nogier 1990 ] [ Polguere 1990 ] . * It is stratificational and modular [ Polguere 1990 ] . * It uses a uniform underlying formalism (fuf's feature structures) to represent utterances at all levels of abstraction and all linguistic ranks <ref> [ Simonin 1985 ] </ref> [ Dale 1988 ] [ Elhadad 1992 ] .
Reference: [ Smadja and McKeown 1991 ] <author> F.A. Smadja and K.R. McKeown. </author> <title> Using collocations for language generation. </title> <journal> Computational Intelligence, </journal> (7):229-239, December 1991. 
Reference-contexts: Macrocoding thus obviates the need for planning any syntactic structure below the sentence rank. Its drawback is that it does not scale-up in the face of great syntactic diversity. Far too many phrasal patterns need to be hand-coded in the lexicon to achieve such diversity (cf. <ref> [ Smadja and McKeown 1991 ] </ref> for a detailed discussion of this problem). In contrast, this diversity can be economically achieved by a microcoding approach to sentence generation, where syntactic structures at all ranks are constructed from individual words 5 . <p> As a test corpus on which to perform this search, I could use, for example, the corpus of stock market newswire reports that was used at Columbia for building the generation system cook <ref> [ Smadja and McKeown 1991 ] </ref> . This second corpus analysis would not consist of discovering new tools from scratch but merely in verifying the usage of the revision tools from the basketball corpus. <p> In addition, this type of data can have interesting applications beyond pure generation. For example, in the context of a computer assisted document production system the various revisions available to elaborate a document sentence could be presented as menu options. 62 See also <ref> [ Smadja and McKeown 1991 ] </ref> for a detailed discussion of this issue. 63 Including information about the historical background. 68 A Domain ontology of the corpus sentences In section 2.2, the basketball reports corpus analysis underlying the research presented in this paper was focused on the report first sentences which
Reference: [ Smadja 1991 ] <author> F. Smadja. </author> <title> Retrieving Collocational Knowledge from Textual Corpora. An Application: Language Generation. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Columbia University, </institution> <year> 1991. </year>
Reference-contexts: In contrast, this diversity can be economically achieved by a microcoding approach to sentence generation, where syntactic structures at all ranks are constructed from individual words 5 . Generators focusing on syntactic diversity (e.g., the system of [ Boyer and Lapalme 1985 ] and cook <ref> [ Smadja 1991 ] </ref> ) perform such micro-level planning. They have, however, limited themselves to the generation of simple sentences. Simultaneously achieving surface form complexity and surface form diversity requires microcoding complex sentences down to the individual words when necessary. <p> This restricted category defined both a subcorpus for systematic and in-depth analysis and a realistic target output for the prototype system streak. Sorting the corpus sentences pertaining to the subcorpus was carried out semi-automatically using free-text information retrieval tools described in <ref> [ Smadja 1991 ] </ref> . The second step consisted of defining the ontology of the subcorpus. It involved identifying the different types of entities mentioned in the corpus 9 as well as the different types of propositions expressed about these entities.
Reference: [ Talmy 1975 ] <author> L. Talmy. </author> <title> Figure and Ground in complex sentences. </title> <editor> In C.E. Ferguson and E.A. Moravcsik, editors, </editor> <booktitle> Syntax, volume 4 of Universals of human language. </booktitle> <publisher> Stanford University Press, </publisher> <year> 1975. </year>
Reference-contexts: This observation has been made in many domains (cf. <ref> [ Talmy 1975 ] </ref> , [ Talmy 1985 ] , [ Zock 1988 ] ). To illustrate this point in the basketball domain consider the expression of an extremum predicate.
Reference: [ Talmy 1985 ] <author> L. Talmy. </author> <title> Lexicalization patterns: semantic structure in lexical form. </title> <editor> In T. Shopen, editor, </editor> <title> Grammatical categories and the lexicon, volume 3 of Language typology and syntactic description. </title> <publisher> Cambridge University Press, </publisher> <year> 1985. </year>
Reference-contexts: This observation has been made in many domains (cf. [ Talmy 1975 ] , <ref> [ Talmy 1985 ] </ref> , [ Zock 1988 ] ). To illustrate this point in the basketball domain consider the expression of an extremum predicate.
Reference: [ Vaughan and McDonald 1986 ] <author> M. Vaughan and D.D. McDonald. </author> <title> A Model of Revision in Natural Language Generation. </title> <booktitle> In Proceedings of the 23rd Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> Columbia University, New York, </address> <year> 1986. </year> <booktitle> ACL. </booktitle>
Reference-contexts: The limitations of the current implementation are discussed in detail in section 6.1. 53 5 Previous work in generation with revision In itself, the idea of revision in generation is not really new. It has been proposed in different flavors by Mann [ Mann 1983 ] , Meteer <ref> [ Vaughan and McDonald 1986 ] </ref> [ Meteer 1990 ] , Yazdani [ Yazdani 1987 ] , Gabriel [ Gabriel 1988 ] , Wong and Simmons [ Wong and Simmons 1988 ] Cline and Nutter [ Cline and Nutter 1991 ] and very recently [ Inui et al. 1992 ] . <p> I compare revision in streak with previous proposals along these two dimensions. 5.1 At what level to perform revision? Both Yazdani and Meteer (at least in her initial paper <ref> [ Vaughan and McDonald 1986 ] </ref> ) proposed performing revision from an actual natural language draft. <p> several semantic elements inside a single syntactic constituent [ Elhadad 1992 ] The proposed architecture is also interesting in that it combines a unique set of properties whose desirability has been independently advocated in previous work: * It works in a two-pass draft and revision mode [ Mann 1983 ] <ref> [ Vaughan and McDonald 1986 ] </ref> [ Yazdani 1987 ] [ Wong and Simmons 1988 ] [ Cline and Nutter 1991 ] [ Inui et al. 1992 ] . * It interleaves planning and realization [ Appelt 1985 ] [ Hovy 1988 ] . * It is incremental [ De Smedt
Reference: [ Winograd 1983 ] <author> T. Winograd. </author> <title> Language as a cognitive process. </title> <publisher> Addison-Wesley, </publisher> <year> 1983. </year>
Reference-contexts: maximum 4 realization patterns per prominent statistic cluster proposition combination against an average 3.83 and a maximum 7 realization patterns per game result cluster proposition combination. 20 The particular grammatical functions, structural relations and syntactic categories used in this paper are inspired from: [ Quirk et al. 1972 ] , <ref> [ Winograd 1983 ] </ref> , [ Halliday 1985 ] and [ Fawcett 1987 ] . 21 e.g. connectives, mood etc. 22 The "aspect" of a streak event specifies whether the streak has been extended or interrupted by the reported game result. <p> The representation obtained after this mapping is what constitutes a surface grammatical specification. The thematic and syntactic roles used in surge are inspired from a variety of sources, most notably [ Quirk et al. 1972 ] <ref> [ Winograd 1983 ] </ref> [ Halliday 1985 ] and [ Fawcett 1987 ] . One great quality of surge is its ability to complete partially specified inputs with default features. These defaults concern syntactic roles, syntactic properties and closed-class lexical items.
Reference: [ Wong and Simmons 1988 ] <author> W.K.C. Wong and R.F Simmons. </author> <title> A blackboard model for text production with revision. </title> <booktitle> In Proceedings of the AAAI workshop on text-planning and realization, </booktitle> <address> St-Paul, MN, 1988. </address> <publisher> AAAI. </publisher>
Reference-contexts: It has been proposed in different flavors by Mann [ Mann 1983 ] , Meteer [ Vaughan and McDonald 1986 ] [ Meteer 1990 ] , Yazdani [ Yazdani 1987 ] , Gabriel [ Gabriel 1988 ] , Wong and Simmons <ref> [ Wong and Simmons 1988 ] </ref> Cline and Nutter [ Cline and Nutter 1991 ] and very recently [ Inui et al. 1992 ] . However, to the best of my knowledge, only two implemented generation system emerged from these proposals: Gabriel's Yh and Inui et. al's weiveR. <p> 1992 ] The proposed architecture is also interesting in that it combines a unique set of properties whose desirability has been independently advocated in previous work: * It works in a two-pass draft and revision mode [ Mann 1983 ] [ Vaughan and McDonald 1986 ] [ Yazdani 1987 ] <ref> [ Wong and Simmons 1988 ] </ref> [ Cline and Nutter 1991 ] [ Inui et al. 1992 ] . * It interleaves planning and realization [ Appelt 1985 ] [ Hovy 1988 ] . * It is incremental [ De Smedt 1990 ] . * It uses declarative knowledge sources [
Reference: [ Yazdani 1987 ] <author> M. Yazdani. </author> <title> Reviewing as a component of the text generation process. </title> <editor> In Gerard Kempen, editor, </editor> <booktitle> Natural Language Generation: New Results in Artificial Intellligence, Psychology and Linguistics. </booktitle> <publisher> Martinus Ninjhoff Publishers, </publisher> <year> 1987. </year>
Reference-contexts: It has been proposed in different flavors by Mann [ Mann 1983 ] , Meteer [ Vaughan and McDonald 1986 ] [ Meteer 1990 ] , Yazdani <ref> [ Yazdani 1987 ] </ref> , Gabriel [ Gabriel 1988 ] , Wong and Simmons [ Wong and Simmons 1988 ] Cline and Nutter [ Cline and Nutter 1991 ] and very recently [ Inui et al. 1992 ] . <p> syntactic constituent [ Elhadad 1992 ] The proposed architecture is also interesting in that it combines a unique set of properties whose desirability has been independently advocated in previous work: * It works in a two-pass draft and revision mode [ Mann 1983 ] [ Vaughan and McDonald 1986 ] <ref> [ Yazdani 1987 ] </ref> [ Wong and Simmons 1988 ] [ Cline and Nutter 1991 ] [ Inui et al. 1992 ] . * It interleaves planning and realization [ Appelt 1985 ] [ Hovy 1988 ] . * It is incremental [ De Smedt 1990 ] . * It uses
Reference: [ Zock 1988 ] <author> M. Zock. </author> <title> Natural languages are flexible tools, that's what makes them hard to explain, to learn and to use. </title> <editor> In M. Zock and G. Sabah, editors, </editor> <title> Advances in Natural Language Generation: an Interdisciplinary Perspective. </title> <publisher> Pinter and Ablex, </publisher> <year> 1988. </year> <month> 87 </month>
Reference-contexts: This observation has been made in many domains (cf. [ Talmy 1975 ] , [ Talmy 1985 ] , <ref> [ Zock 1988 ] </ref> ). To illustrate this point in the basketball domain consider the expression of an extremum predicate.
References-found: 50

