URL: http://www.ri.cmu.edu/afs/cs/project/ai-repository/ai/pubs/journals/jair/volume1/ginsberg93a.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs/project/ai-repository/ai/pubs/journals/jair/volume1/
Root-URL: 
Email: ginsberg@cs.uoregon.edu  
Title: Dynamic Backtracking  
Author: Matthew L. Ginsberg 
Address: Eugene, OR 97403-1269 USA  
Affiliation: CIRL, University of Oregon,  
Note: Journal of Artificial Intelligence Research 1 (1993) 25-46 Submitted 7/93; published 8/93  
Abstract: Because of their occasional need to return to shallow points in a search tree, existing backtracking methods can sometimes erase meaningful progress toward solving a search problem. In this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty. The technique developed is a variant of dependency-directed backtracking that uses only polynomial space while still providing useful control information and retaining the completeness guarantees provided by earlier approaches.
Abstract-found: 1
Intro-found: 1
Reference: <author> Bruynooghe, M. </author> <year> (1981). </year> <title> Solving combinatorial search problems by intelligent backtracking. </title> <journal> Information Processing Letters, </journal> <volume> 12 (1), </volume> <pages> 36-39. </pages> <editor> de Kleer, J. </editor> <year> (1986). </year> <title> An assumption-based truth maintenance system. </title> <journal> Artificial Intelligence, </journal> <volume> 28, </volume> <pages> 127-162. </pages>
Reference-contexts: Backjumping avoids this problem by resetting the set E i of eliminating explanations in step 2 of Algorithm 3.3. The description that we have given is quite similar to that developed in <ref> (Bruynooghe, 1981) </ref>. The explanations there are somewhat coarser than ours, listing all of the variables that have been involved in any eliminating explanation for a particular variable in the csp, but the idea is essentially the same.
Reference: <author> Dechter, R., & Meiri, I. </author> <year> (1989). </year> <title> Experimental evaluation of preprocessing techniques in constraint satisfaction problems. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 271-277. </pages>
Reference: <author> Gaschnig, J. </author> <year> (1979). </year> <title> Performance measurement and analysis of certain search algorithms. </title> <type> Tech. rep. </type> <institution> CMU-CS-79-124, Carnegie-Mellon University. </institution>
Reference-contexts: The solutions that have been proposed to this involve finding ways to backtrack directly to some state that might actually allow us to make progress, in this case Arizona or earlier. Dependency-directed backtracking (Stallman & Sussman, 1977) involves a direct backtrack to the source of the difficulty; backjumping <ref> (Gaschnig, 1979) </ref> avoids the computational overhead of this technique by using syntactic methods to estimate the point to which backtrack is necessary. c fl1993 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. <p> Again, there are other ways to view this - Gashnig's notion of backmarking <ref> (Gaschnig, 1979) </ref> records similar information about the reason that particular portions of a search space are known not to contain solutions. 7.2 Future work There are a variety of ways in which the techniques we have presented can be extended; in this section, we sketch a few of the more obvious
Reference: <author> Ginsberg, M. L., Frank, M., Halpin, M. P., & Torrance, M. C. </author> <year> (1990). </year> <title> Search lessons learned from crossword puzzles. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 210-215. </pages>
Reference-contexts: Dynamic backtracking can also be expected to be of use in situations where the problem in question does not split into two or more disjoint subproblems. 1 6. Experimentation Dynamic backtracking has been incorporated into the crossword-puzzle generation program described in <ref> (Ginsberg, Frank, Halpin, & Torrance, 1990) </ref>, and leads to significant performance improvements in that restricted domain. <p> This ensures that no word will be entered into the crossword if the word has no potential crossing words at some point. The cheapest-first heuristic would identify the problem at the next step in the search, but forward checking reduces the number of backtracks substantially. The "least-constraining" heuristic <ref> (Ginsberg et al., 1990) </ref> was not used; this heuristic suggests that each word slot be filled with the word that minimally constrains the subsequent search. The heuristic was not used because it would invalidate the technique of shu*ing the dictionary between solution attempts in order to gather useful statistics.
Reference: <author> Ginsberg, M. L., & Harvey, W. D. </author> <year> (1992). </year> <title> Iterative broadening. </title> <journal> Artificial Intelligence, </journal> <volume> 55, </volume> <pages> 367-383. </pages>
Reference-contexts: The dictionary was shu*ed between solution attempts and a maximum of 1000 backtracks were permitted before the program was deemed to have failed. In both cases, the algorithms were extended to include iterative broadening <ref> (Ginsberg & Harvey, 1992) </ref>, the cheapest-first heuristic and forward checking. Cheapest-first has also been called "most constrained first" and selects for instantiation that variable with the fewest number of remaining possibilities (i.e., that variable for which it is cheapest to enumerate the possible values (Smith & Genesereth, 1985)).
Reference: <author> Jonsson, A. K., & Ginsberg, M. L. </author> <year> (1993). </year> <title> Experimenting with new systematic and nonsystematic search techniques. </title> <booktitle> In Proceedings of the AAAI Spring Symposium on AI and NP-Hard Problems Stanford, </booktitle> <address> California. </address>
Reference-contexts: A somewhat broader set of experiments is described in <ref> (Jonsson & Ginsberg, 1993) </ref> and leads to similar conclusions. There are some examples in (Jonsson & Ginsberg, 1993) where dynamic backtracking leads to performance degradation, however; a typical case appears in Figure 4. 3 In this 1. I am indebted to David McAllester for these observations. 2. <p> A somewhat broader set of experiments is described in <ref> (Jonsson & Ginsberg, 1993) </ref> and leads to similar conclusions. There are some examples in (Jonsson & Ginsberg, 1993) where dynamic backtracking leads to performance degradation, however; a typical case appears in Figure 4. 3 In this 1. I am indebted to David McAllester for these observations. 2. <p> If region 1 were easy to color, we would have been better off erasing it even though we didn't need to. This analysis suggests that dependency-directed backtracking should also fare worse on those coloring problems where dynamic backtracking has trouble, and we are currently extending the experiments of <ref> (Jonsson & Ginsberg, 1993) </ref> to confirm this. If this conjecture is borne out, a variety of solutions come to mind.
Reference: <author> McAllester, D. A. </author> <year> (1993). </year> <title> Partial order backtracking. </title> <journal> Journal of Artificial Intelligence Research, </journal> <note> 1. Submitted. </note>
Reference-contexts: Another solution appears in <ref> (McAllester, 1993) </ref>. 39 Ginsberg Finally, there is some measure of the "directness" with which a variable bears on a problem.
Reference: <author> Minton, S., Johnston, M. D., Philips, A. B., & Laird, P. </author> <year> (1990). </year> <title> Solving large-scale constraint satisfaction and scheduling problems using a heuristic repair method. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 17-24. </pages> <note> 45 Ginsberg P. </note> <author> Purdom, C. B., & Robertson, E. </author> <year> (1981). </year> <title> Backtracking with multi-level dynamic search rearrangement. </title> <journal> Acta Informatica, </journal> <volume> 15, </volume> <pages> 99-114. </pages>
Reference-contexts: Another way to look at this idea is that we have found a way to "erase" the value given to a variable directly as opposed to backtracking to it. This idea has also been explored by Minton et.al. in <ref> (Minton, Johnston, Philips, & Laird, 1990) </ref> and by Selman et.al. in (Selman, Levesque, & Mitchell, 1992); these authors also directly replace values assigned to variables in satisfiability problems.
Reference: <author> Seidel, R. </author> <year> (1981). </year> <title> A new method for solving constraint satisfaction problems. </title> <booktitle> In Proceedings of the Seventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 338-342. </pages>
Reference: <author> Selman, B., Levesque, H., & Mitchell, D. </author> <year> (1992). </year> <title> A new method for solving hard satisfiability problems. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence. </booktitle>
Reference-contexts: This idea has also been explored by Minton et.al. in (Minton, Johnston, Philips, & Laird, 1990) and by Selman et.al. in <ref> (Selman, Levesque, & Mitchell, 1992) </ref>; these authors also directly replace values assigned to variables in satisfiability problems. Unfortunately, the heuristic repair method used is incomplete because no dependency information is retained from one state of the problem solver to the next.
Reference: <author> Smith, D. E., & Genesereth, M. R. </author> <year> (1985). </year> <title> Ordering conjunctive queries. </title> <journal> Artificial Intelligence, </journal> <volume> 26 (2), </volume> <pages> 171-215. </pages>
Reference-contexts: Cheapest-first has also been called "most constrained first" and selects for instantiation that variable with the fewest number of remaining possibilities (i.e., that variable for which it is cheapest to enumerate the possible values <ref> (Smith & Genesereth, 1985) </ref>). Forward checking prunes the set of possibilities for crossing words whenever a new word is entered and constitutes our experimental choice of elimination mechanism: at any point, words for which there is no legal crossing word are eliminated.
Reference: <author> Stallman, R. M., & Sussman, G. J. </author> <year> (1977). </year> <title> Forward reasoning and dependency-directed backtracking in a system for computer-aided circuit analysis. </title> <journal> Artificial Intelligence, </journal> <volume> 9 (2), </volume> <pages> 135-196. </pages>
Reference-contexts: The solutions that have been proposed to this involve finding ways to backtrack directly to some state that might actually allow us to make progress, in this case Arizona or earlier. Dependency-directed backtracking <ref> (Stallman & Sussman, 1977) </ref> involves a direct backtrack to the source of the difficulty; backjumping (Gaschnig, 1979) avoids the computational overhead of this technique by using syntactic methods to estimate the point to which backtrack is necessary. c fl1993 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.
Reference: <author> Zabih, R. </author> <year> (1990). </year> <title> Some applications of graph bandwidth to constraint satisfaction problems. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 46-51. </pages>
Reference: <author> Zabih, R., & McAllester, D. A. </author> <year> (1988). </year> <title> A rearrangement search strategy for determining propositional satisfiability. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. 155-160. 46 </pages>
References-found: 14

