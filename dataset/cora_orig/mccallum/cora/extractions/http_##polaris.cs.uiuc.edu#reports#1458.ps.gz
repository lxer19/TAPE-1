URL: http://polaris.cs.uiuc.edu/reports/1458.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: Quantifying the performance potential of a data prefetch mechanism for pointer-intensive and numeric programs  
Author: Sharad Mehrotra Luddy Harrison 
Keyword: CPU architecture, data cache, memory access pattern classification, prefetching, memory latency tolerance  
Note: Some aspects of this research are covered by a patent application filed by the University of Illinois. Corresponding author.  
Address: 1308 West Main Street Urbana, IL 61801-2307  One Kendall Square, Building 200 Cambridge, MA 02139  
Affiliation: CSRD and UI Department of Computer Science  UI Dept. of Computer Science and Connected Components Corporation  
Email: (mehrotra@csrd.uiuc.edu)  (harrison@csrd.uiuc.edu)  
Phone: Phone: (217) 244-4657 Fax: (217) 244-1351  (617) 577-1024  
Date: 7 November 1995  
Abstract: This paper uses a simple recurrence-based classification of memory access patterns, introduced by us in earlier work [HM94], to develop a data prefetch mechanism (the Indirect Reference Buffer, or, IRB) for primary data caches in future CPU implementations. The IRB is described in detail, followed by an examination of its performance potential. We analyze the behavior of the IRB for a range of realistic primary data cache organizations, assuming zero-latency prefetches. The results are encouraging: performance, as measured by CPI, improves on average by 11% for 8K, two-way associative caches, and by 36% for 32K, two-way associative caches. This improvement is achieved at a cost of an average 5% increase in traffic for the 8K caches, and a 1% traffic increase for the 32K caches. We also investigate the combined gains from prefetching and 4-way associativity. For 8K caches there is an average improvement of 34% in CPI, and for 32K caches an average CPI improvement of 48%. In both cases there is a reduction in traffic of 1% on average. 
Abstract-found: 1
Intro-found: 1
Reference: [APS95] <author> Todd M. Austin, Dionisios N. Pnevmatikatos, and Gurindar S. Sohi. </author> <title> Streamlining Data Cache Access with Fast Address Calculation. </title> <booktitle> In Pro 31 ceedings of the 22nd International Symposium on Computer Architecture, </booktitle> <pages> pages 369-380, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Several software and hybrid hardware-software prefetching schemes have also been reported <ref> [APS95, Chi94a, Chi94b, YGHH94, MLG92, Sel92, CKP91, KL91, CMCH91] </ref>. The hybrid schemes either populate a stride table using software support, or reschedule the code being generated by the compiler to assist the hardware being proposed.
Reference: [CB95] <author> Tien-Fu Chen and Jean-Loup Baer. </author> <title> Effective Hardware-Based Data Prefetching for High-Performance Processors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 44(5) </volume> <pages> 609-623, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Our assumptions for the IRB are described in Section 4. Our results show that the IRB holds considerable promise for use in future CPU implementations. In related work, several researchers have proposed stride-directed hardware data prefetch mechanisms <ref> [CB95, EV93, JT93, FPJ92, Skl92] </ref>. Such schemes attempt to use runtime information gathered from a program's execution to predict its future memory access requirements. Other schemes react to sequences of misses experienced by the cache in determining when and what to prefetch [PK94, CR94, VS92, Jou90, SR88, Smi78]. <p> The RPT resembles a Branch Target Buffer commonly used in pipelined processors to reduce branch misprediction penalty [LS84]. It is also similar to the load predictor tables proposed for other hardware data prefetching schemes <ref> [CB95, JT93, EV93, FPJ92] </ref>. However, in comparison to previous designs, some additional information is cached in each of the RPT entries. The entries are indexed by the virtual addresses of load instructions. Each entry consists of several fields, the first of which is the instruction address. <p> The IRB hardware makes no attempt to detect the most likely path of execution through a program's control flow graph of its own, unlike the data prefetch scheme proposed by Chen and Baer <ref> [CB95] </ref>.
Reference: [Chi94a] <author> Chi-Hung Chi. </author> <title> Compiler Optimization Technique for Data Cache Prefetch-ing Using a Small CAM Array. </title> <booktitle> In Proceedings of the 1994 International Conference on Parallel Processing, </booktitle> <volume> volume I, </volume> <pages> pages 263-266, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: Several software and hybrid hardware-software prefetching schemes have also been reported <ref> [APS95, Chi94a, Chi94b, YGHH94, MLG92, Sel92, CKP91, KL91, CMCH91] </ref>. The hybrid schemes either populate a stride table using software support, or reschedule the code being generated by the compiler to assist the hardware being proposed.
Reference: [Chi94b] <author> Tzi-cker Chiueh. </author> <title> Sunder: A Programmable Hardware Prefetch Architecture for Numerical Loops. </title> <booktitle> In Proceedings of Supercomputing '94, </booktitle> <pages> pages 488-497, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Several software and hybrid hardware-software prefetching schemes have also been reported <ref> [APS95, Chi94a, Chi94b, YGHH94, MLG92, Sel92, CKP91, KL91, CMCH91] </ref>. The hybrid schemes either populate a stride table using software support, or reschedule the code being generated by the compiler to assist the hardware being proposed.
Reference: [CKP91] <author> David Callahan, Ken Kennedy, and Allan Porterfield. </author> <booktitle> Software prefetch-ing. In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 40-52, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Several software and hybrid hardware-software prefetching schemes have also been reported <ref> [APS95, Chi94a, Chi94b, YGHH94, MLG92, Sel92, CKP91, KL91, CMCH91] </ref>. The hybrid schemes either populate a stride table using software support, or reschedule the code being generated by the compiler to assist the hardware being proposed.
Reference: [CMCH91] <author> William Y. Chen, Scott A. Mahlke, Pohua P. Chang, and Wen-mei W. Hwu. </author> <title> Data Access Microarchitectures for Superscalar Processors with Compiler-Assisted Data Prefetching. </title> <booktitle> In Proceedings of the 24th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 69-73, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: Several software and hybrid hardware-software prefetching schemes have also been reported <ref> [APS95, Chi94a, Chi94b, YGHH94, MLG92, Sel92, CKP91, KL91, CMCH91] </ref>. The hybrid schemes either populate a stride table using software support, or reschedule the code being generated by the compiler to assist the hardware being proposed.
Reference: [CR94] <author> Mark J. Charney and Anthony P. Reeves. </author> <title> Correlation-Based Hardware Prefetching. </title> <note> Submitted to IEEE Transactions on Computers, </note> <month> September </month> <year> 1994. </year>
Reference-contexts: Such schemes attempt to use runtime information gathered from a program's execution to predict its future memory access requirements. Other schemes react to sequences of misses experienced by the cache in determining when and what to prefetch <ref> [PK94, CR94, VS92, Jou90, SR88, Smi78] </ref>. Some of these schemes also use stride detection in some form to complement the cache miss sequence detection.
Reference: [ER + 95] <author> John H. Edmondson, Paul I. Rubinfield, et al. </author> <title> Internal Organization of the Alpha 21164, a 300-MHz 64-bit Quad-issue CMOS RISC Microprocessor. </title> <journal> Digital Technical Journal, </journal> <volume> 7(1) </volume> <pages> 119-135, </pages> <year> 1995. </year>
Reference-contexts: The IRB interfaces with the first-level data cache and the CPU's bus interface unit by means of a prefetch queue, a load miss queue, and a write buffer. All three queues utilize merge logic to eliminate redundant entries <ref> [ER + 95] </ref>. The prefetch queue is very similar to the load miss queue. All queues contain physical addresses, and loads and prefetches are checked against the write buffer to prevent obsolete data from being returned. Entries in each queue are retired by the hardware as the appropriate operation completes.
Reference: [EV93] <author> Richard J. Eickemeyer and S. Vassiliadis. </author> <title> A load-instruction unit for pipelined processors. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 37(4) </volume> <pages> 547-564, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Our assumptions for the IRB are described in Section 4. Our results show that the IRB holds considerable promise for use in future CPU implementations. In related work, several researchers have proposed stride-directed hardware data prefetch mechanisms <ref> [CB95, EV93, JT93, FPJ92, Skl92] </ref>. Such schemes attempt to use runtime information gathered from a program's execution to predict its future memory access requirements. Other schemes react to sequences of misses experienced by the cache in determining when and what to prefetch [PK94, CR94, VS92, Jou90, SR88, Smi78]. <p> The RPT resembles a Branch Target Buffer commonly used in pipelined processors to reduce branch misprediction penalty [LS84]. It is also similar to the load predictor tables proposed for other hardware data prefetching schemes <ref> [CB95, JT93, EV93, FPJ92] </ref>. However, in comparison to previous designs, some additional information is cached in each of the RPT entries. The entries are indexed by the virtual addresses of load instructions. Each entry consists of several fields, the first of which is the instruction address.
Reference: [FPJ92] <author> John W. C. Fu, Janak H. Patel, and Bob L. Janssens. </author> <title> Stride Directed Prefetching in Scalar Processors. </title> <booktitle> In Proceedings of the 25th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 102-110, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: Our assumptions for the IRB are described in Section 4. Our results show that the IRB holds considerable promise for use in future CPU implementations. In related work, several researchers have proposed stride-directed hardware data prefetch mechanisms <ref> [CB95, EV93, JT93, FPJ92, Skl92] </ref>. Such schemes attempt to use runtime information gathered from a program's execution to predict its future memory access requirements. Other schemes react to sequences of misses experienced by the cache in determining when and what to prefetch [PK94, CR94, VS92, Jou90, SR88, Smi78]. <p> The RPT resembles a Branch Target Buffer commonly used in pipelined processors to reduce branch misprediction penalty [LS84]. It is also similar to the load predictor tables proposed for other hardware data prefetching schemes <ref> [CB95, JT93, EV93, FPJ92] </ref>. However, in comparison to previous designs, some additional information is cached in each of the RPT entries. The entries are indexed by the virtual addresses of load instructions. Each entry consists of several fields, the first of which is the instruction address.
Reference: [HM94] <author> Luddy Harrison and Sharad Mehrotra. </author> <title> A data prefetch mechanism for accelerating general-purpose computation. </title> <type> Technical Report 1351, </type> <institution> CSRD, University of Illinois at Urbana-Champaign, Urbana, </institution> <address> IL 61801, </address> <month> 8 May </month> <year> 1994. </year> <title> Last revised 9 March 1995. This report is the basis for Patent Application No. 08508290, Prefetch System Applicable to Complex Memory Access Schemes, </title> <note> filed by the University of Illinois on 27 July 1995. </note>
Reference: [Jou90] <author> Norman P. Jouppi. </author> <title> Improving Direct-mapped Cache Performance by the Addition of a Small Fully-Associative Cache and Prefetch Buffers. </title> <booktitle> In Proceedings of the 17th International Symposium on Computer Architecture, </booktitle> <pages> pages 364-373, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Such schemes attempt to use runtime information gathered from a program's execution to predict its future memory access requirements. Other schemes react to sequences of misses experienced by the cache in determining when and what to prefetch <ref> [PK94, CR94, VS92, Jou90, SR88, Smi78] </ref>. Some of these schemes also use stride detection in some form to complement the cache miss sequence detection. <p> Hardware prefetching for instruction caches has also 1 To conserve space, references to prefetching techniques for multiprocessors have been elided. 3 int i, m, a [100]; m = m + a [i]; been studied in the literature <ref> [SH92, McF92, Jou90, Smi78] </ref>. Several software and hybrid hardware-software prefetching schemes have also been reported [APS95, Chi94a, Chi94b, YGHH94, MLG92, Sel92, CKP91, KL91, CMCH91]. The hybrid schemes either populate a stride table using software support, or reschedule the code being generated by the compiler to assist the hardware being proposed.
Reference: [JT93] <author> Ivan Jegou and Olivier Temam. </author> <title> Speculative Prefetching. </title> <booktitle> In Proceedings of the 1993 ACM International Conference on Supercomputing, </booktitle> <pages> pages 57 - 66, </pages> <month> July </month> <year> 1993. </year> <month> 32 </month>
Reference-contexts: Our assumptions for the IRB are described in Section 4. Our results show that the IRB holds considerable promise for use in future CPU implementations. In related work, several researchers have proposed stride-directed hardware data prefetch mechanisms <ref> [CB95, EV93, JT93, FPJ92, Skl92] </ref>. Such schemes attempt to use runtime information gathered from a program's execution to predict its future memory access requirements. Other schemes react to sequences of misses experienced by the cache in determining when and what to prefetch [PK94, CR94, VS92, Jou90, SR88, Smi78]. <p> The RPT resembles a Branch Target Buffer commonly used in pipelined processors to reduce branch misprediction penalty [LS84]. It is also similar to the load predictor tables proposed for other hardware data prefetching schemes <ref> [CB95, JT93, EV93, FPJ92] </ref>. However, in comparison to previous designs, some additional information is cached in each of the RPT entries. The entries are indexed by the virtual addresses of load instructions. Each entry consists of several fields, the first of which is the instruction address.
Reference: [KL91] <author> Alexander C. Klaiber and Henry M. Levy. </author> <title> An architecture for software--controlled data prefetching. </title> <booktitle> In Proceedings of the 18th International Symposium on Computer Architecture, </booktitle> <pages> pages 43-53, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Several software and hybrid hardware-software prefetching schemes have also been reported <ref> [APS95, Chi94a, Chi94b, YGHH94, MLG92, Sel92, CKP91, KL91, CMCH91] </ref>. The hybrid schemes either populate a stride table using software support, or reschedule the code being generated by the compiler to assist the hardware being proposed.
Reference: [Lar93] <author> James R. Larus. </author> <title> Efficient Program Tracing. </title> <journal> IEEE Computer, </journal> <volume> 26(5) </volume> <pages> 52-61, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Input data sets for the codes were selected so as to generate roughly 100 million to 500 million load instructions in the program traces. All programs were compiled with standard optimization 12 , and the resulting executables instrumented using Qpt <ref> [Lar93] </ref>. We have modified Qpt so that in addition to generating instruction and data traces, it also generates the contents of all memory locations that are read, a unique identifier (an integer) for each load when it executes, and the load opcode type (byte, half, or word load).
Reference: [LS84] <author> Johnny K. F. Lee and Alan J. Smith. </author> <title> Branch Prediction Strategies and Branch Target Buffer Design. </title> <journal> IEEE Computer, </journal> <volume> 17(1) </volume> <pages> 6-22, </pages> <month> January </month> <year> 1984. </year>
Reference-contexts: Similarly, the PU consists of a table, the Active Prefetch Buffer (APB), and a collection of simple logic circuits. The RPT resembles a Branch Target Buffer commonly used in pipelined processors to reduce branch misprediction penalty <ref> [LS84] </ref>. It is also similar to the load predictor tables proposed for other hardware data prefetching schemes [CB95, JT93, EV93, FPJ92]. However, in comparison to previous designs, some additional information is cached in each of the RPT entries. The entries are indexed by the virtual addresses of load instructions.
Reference: [LW94] <author> Alvin R. Lebeck and David A. Wood. </author> <title> Cache Profiling and the SPEC Benchmarks: A Case Study. </title> <journal> IEEE Computer, </journal> <volume> 27(10) </volume> <pages> 15-26, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Loops of this type are common in dense numeric programs. An approximate analysis for the cache behavior of loop A can be performed using the technique Lebeck and Wood have called mental simulation <ref> [LW94] </ref>. Assume that we are programming on a 32-bit machine that uses a byte-addressed memory, and where integers and pointers occupy four bytes each. Single-precision floating point numbers occupy four bytes and double precision ones eight.
Reference: [McF92] <author> Scott McFarling. </author> <title> Cache Replacement with Dynamic Exclusion. </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture, </booktitle> <pages> pages 191-200, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Hardware prefetching for instruction caches has also 1 To conserve space, references to prefetching techniques for multiprocessors have been elided. 3 int i, m, a [100]; m = m + a [i]; been studied in the literature <ref> [SH92, McF92, Jou90, Smi78] </ref>. Several software and hybrid hardware-software prefetching schemes have also been reported [APS95, Chi94a, Chi94b, YGHH94, MLG92, Sel92, CKP91, KL91, CMCH91]. The hybrid schemes either populate a stride table using software support, or reschedule the code being generated by the compiler to assist the hardware being proposed.
Reference: [MDO94] <author> Ann Marie Grizzaffi Maynard, Colette M. Donnelly, and Bret R. Olszewski. </author> <title> Contrasting Characteristics and Cache Performance of Technical and MultiUser Commercial Workloads. </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 145-156, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: While scientific codes are an important class of applications, modern CPUs need to efficiently execute a much wider spectrum of programs, including pointer-intensive and sparse matrix computations. The latter two categories of codes tend to exhibit poorer cache locality than their regular, numeric counterparts <ref> [MDO94] </ref>, and are less amenable to compile-time restructuring. In this paper we describe the Indirect Reference Buffer (IRB), a hardware data prefetch mechanism applicable to both pointer-intensive and numeric programs.
Reference: [MLG92] <author> Todd C. Mowry, Monica S. Lam, and Anoop Gupta. </author> <title> Design and Evaluation of a Compiler Algorithm for Prefetching. </title> <booktitle> In Proceedings of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 62-73, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Several software and hybrid hardware-software prefetching schemes have also been reported <ref> [APS95, Chi94a, Chi94b, YGHH94, MLG92, Sel92, CKP91, KL91, CMCH91] </ref>. The hybrid schemes either populate a stride table using software support, or reschedule the code being generated by the compiler to assist the hardware being proposed.
Reference: [PK94] <author> Subbarao Palacharla and Richard E. Kessler. </author> <title> Evaluating Stream Buffers as a Secondary Cache Replacement. </title> <booktitle> In Proceedings of the 21st International Symposium on Computer Architecture, </booktitle> <pages> pages 24-33, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Such schemes attempt to use runtime information gathered from a program's execution to predict its future memory access requirements. Other schemes react to sequences of misses experienced by the cache in determining when and what to prefetch <ref> [PK94, CR94, VS92, Jou90, SR88, Smi78] </ref>. Some of these schemes also use stride detection in some form to complement the cache miss sequence detection.
Reference: [Sel92] <author> Charles William Selvidge. </author> <title> Compilation-Based Prefetching for Memory Latency Tolerance. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science, </institution> <address> Cambridge, MA 02139, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: Several software and hybrid hardware-software prefetching schemes have also been reported <ref> [APS95, Chi94a, Chi94b, YGHH94, MLG92, Sel92, CKP91, KL91, CMCH91] </ref>. The hybrid schemes either populate a stride table using software support, or reschedule the code being generated by the compiler to assist the hardware being proposed.
Reference: [SH92] <author> James E. Smith and Wei-Chung Hsu. </author> <title> Prefetching in Supercomputer Instruction Caches. </title> <booktitle> In Proceedings of Supercomputing '92, </booktitle> <pages> pages 588-597, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Hardware prefetching for instruction caches has also 1 To conserve space, references to prefetching techniques for multiprocessors have been elided. 3 int i, m, a [100]; m = m + a [i]; been studied in the literature <ref> [SH92, McF92, Jou90, Smi78] </ref>. Several software and hybrid hardware-software prefetching schemes have also been reported [APS95, Chi94a, Chi94b, YGHH94, MLG92, Sel92, CKP91, KL91, CMCH91]. The hybrid schemes either populate a stride table using software support, or reschedule the code being generated by the compiler to assist the hardware being proposed. <p> MPI dread is the number of read misses per instruction, and CPM dread is the data cache read miss penalty in cycles/miss. We also consider the traffic to and from the L1 data cache. Following <ref> [SH92] </ref>, and recalling that the performance data reported in this paper is for write through caches, traffic is defined as: Traffic = (#Read Misses + #Writes + #Launched prefetches) fi 0:008 (11) 21 Traffic is reported in Kwords, where a word consists of 4 bytes.
Reference: [Skl92] <author> Ivan Sklenar. </author> <title> Prefetch unit for vector operations on scalar computers. </title> <journal> Computer Architecture News, </journal> <volume> 20(4) </volume> <pages> 31-37, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Our assumptions for the IRB are described in Section 4. Our results show that the IRB holds considerable promise for use in future CPU implementations. In related work, several researchers have proposed stride-directed hardware data prefetch mechanisms <ref> [CB95, EV93, JT93, FPJ92, Skl92] </ref>. Such schemes attempt to use runtime information gathered from a program's execution to predict its future memory access requirements. Other schemes react to sequences of misses experienced by the cache in determining when and what to prefetch [PK94, CR94, VS92, Jou90, SR88, Smi78].
Reference: [Smi78] <author> Alan Jay Smith. </author> <title> Sequential Program Prefetching in Memory Hierarchies. </title> <journal> IEEE Computer, </journal> <volume> 11(12) </volume> <pages> 7-21, </pages> <month> December </month> <year> 1978. </year>
Reference-contexts: Such schemes attempt to use runtime information gathered from a program's execution to predict its future memory access requirements. Other schemes react to sequences of misses experienced by the cache in determining when and what to prefetch <ref> [PK94, CR94, VS92, Jou90, SR88, Smi78] </ref>. Some of these schemes also use stride detection in some form to complement the cache miss sequence detection. <p> Hardware prefetching for instruction caches has also 1 To conserve space, references to prefetching techniques for multiprocessors have been elided. 3 int i, m, a [100]; m = m + a [i]; been studied in the literature <ref> [SH92, McF92, Jou90, Smi78] </ref>. Several software and hybrid hardware-software prefetching schemes have also been reported [APS95, Chi94a, Chi94b, YGHH94, MLG92, Sel92, CKP91, KL91, CMCH91]. The hybrid schemes either populate a stride table using software support, or reschedule the code being generated by the compiler to assist the hardware being proposed.
Reference: [SR88] <author> Kimming So and Rudolph N. Rechtschaffen. </author> <title> Cache Operations by MRU Change. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37(6) </volume> <pages> 700-709, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: Such schemes attempt to use runtime information gathered from a program's execution to predict its future memory access requirements. Other schemes react to sequences of misses experienced by the cache in determining when and what to prefetch <ref> [PK94, CR94, VS92, Jou90, SR88, Smi78] </ref>. Some of these schemes also use stride detection in some form to complement the cache miss sequence detection.
Reference: [UMS + 95] <author> Richard Uhlig, Trevor Mudge, Stuart Sechrest, David Nagle, and Joel Emer. </author> <title> Instruction Fetching: Coping with Code Bloat. </title> <booktitle> In Proceedings of the 22nd International Symposium on Computer Architecture, </booktitle> <pages> pages 345-356, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: the IRB is able to exploit both kinds of loads for prefetching, it has an advantage over schemes that cannot detect any patterns for non-linear loads. 4.3 Quantifying the prefetching potential of the IRB 4.3.1 Baseline configurations and performance metrics To quantify the performance potential of the IRB, we follow <ref> [UMS + 95] </ref>, and define 13 Note that a load that executes once or twice denotes a trivial linear sequence. 20 Cache size 8K Cache size 32K Parameter Economy High Perf. <p> Table 3 lists the baseline configurations. For both 8K and 32K caches, two models are defined, one economy and another high-performance. Most of the parameters for the configurations are taken from <ref> [UMS + 95] </ref>. This table also specifies our assumptions about IRB behavior. The device modeled has an entry for each load executed, and its prefetches complete instantaneously.
Reference: [VS92] <author> Anujan Varma and Gunjan K. Sinha. </author> <title> A Class of Prefetch Schemes for On-Chip Data Caches. </title> <booktitle> Poster in Proceedings of the 19th International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1992. </year> <month> 33 </month>
Reference-contexts: Such schemes attempt to use runtime information gathered from a program's execution to predict its future memory access requirements. Other schemes react to sequences of misses experienced by the cache in determining when and what to prefetch <ref> [PK94, CR94, VS92, Jou90, SR88, Smi78] </ref>. Some of these schemes also use stride detection in some form to complement the cache miss sequence detection.
Reference: [YGHH94] <author> Yoji Yamada, John Gyllenhall, Grant Haab, and Wen-mei W. Hwu. </author> <title> Data Relocation and Prefetching for Programs with Large Data Sets. </title> <booktitle> In Proceedings of the 27th Annual International Symposium on Microarchitecture, </booktitle> <month> November </month> <year> 1994. </year> <month> 34 </month>
Reference-contexts: Several software and hybrid hardware-software prefetching schemes have also been reported <ref> [APS95, Chi94a, Chi94b, YGHH94, MLG92, Sel92, CKP91, KL91, CMCH91] </ref>. The hybrid schemes either populate a stride table using software support, or reschedule the code being generated by the compiler to assist the hardware being proposed.
References-found: 29

