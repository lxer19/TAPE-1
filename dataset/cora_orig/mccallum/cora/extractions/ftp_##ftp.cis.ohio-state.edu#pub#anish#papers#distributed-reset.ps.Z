URL: ftp://ftp.cis.ohio-state.edu/pub/anish/papers/distributed-reset.ps.Z
Refering-URL: http://www.cis.ohio-state.edu/~anish/pub.html
Root-URL: 
Email: anish@cs.utexas.edu, gouda@cs.utexas.edu  
Title: Distributed Reset  
Author: Anish ARORA Mohamed GOUDA 
Keyword: Categories and Subject Descriptors: C.2.4 [Computer Communication Systems]: Distributed Systems-distributed applications, network operating systems D.1.3 [Programming Techniques]: Concurrent Programming D.4.5 [Operating Systems]: Reliability-verification, fault-tolerance G.2.2 [Discrete Mathematics]: Graph theory-trees, graph algorithms. General Terms: Reliability, Algorithms. Additional Key Words and Phrases: Fault-tolerance, self-stabilization, leader election, spanning tree, diffusing computation.  
Note: Email Address:  
Address: Austin, TX, USA  
Affiliation: Department of Computer Sciences, The University of Texas at Austin Microelectronics and Computer Technology Corporation,  
Abstract: We design a reset subsystem that can be embedded in an arbitrary distributed system in order to allow the system processes to reset the system when necessary. Our design is layered, and comprises three main components: a leader election, a spanning tree construction, and a diffusing computation. Each of these components is self-stabilizing in the following sense. If the coordination between the up processes in the system is ever lost (due to failures or repairs of processes and channels) then each component eventually reaches a state where coordination is regained. This capability makes our reset subsystem very robust: it can tolerate fail-stop failures and repairs of processes and channels even when a reset is in progress. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Afek, B. Awerbuch, and E. Gafni, </author> <title> "Applying static network protocols to dynamic networks", </title> <booktitle> Proceedings of 28th IEEE Symposium on Foundations of Computer Science (1987). </booktitle>
Reference-contexts: The design consists of three major components: a leader election, a spanning tree construction, and a diffusing computation. Each of these components is self-stabilizing, can tolerate process and channel failures and repairs, and admits bounded-space implementations. These features distinguish our design of these components from earlier designs <ref> [1, 9, 10] </ref> and redress the following comment made by Lamport and Lynch [15, page 1193] : "A self-stabilizing algorithm [that translates a distributed system designed for a fixed but arbitrary network into one that works for a changing network] using a finite number of identifiers would be quite useful, but
Reference: [2] <author> A. Arora, </author> <title> "A foundation of fault-tolerant computing," </title> <type> Ph.D. Dissertation, </type> <institution> The University of Texas at Austin, </institution> <month> December </month> <year> 1992. </year>
Reference-contexts: Second, our design remains correct even if we weaken the interleaving requirement as follows: in each step, an arbitrary subset of the processes each execute some enabled action, as long as no two executed actions access the same shared variable <ref> [2, 3, 5] </ref>. A comment is also in order regarding our methodology for achieving fault-tolerance in distributed systems. One way to achieve system fault-tolerance is to ensure that when faults occur the system continues to satisfy its input-output relation.
Reference: [3] <author> A. Arora, P. Attie, M. Evangelist, and M.G. Gouda, </author> <title> "Convergence of iteration systems", </title> <note> Distributed Computing , to appear. </note>
Reference-contexts: Second, our design remains correct even if we weaken the interleaving requirement as follows: in each step, an arbitrary subset of the processes each execute some enabled action, as long as no two executed actions access the same shared variable <ref> [2, 3, 5] </ref>. A comment is also in order regarding our methodology for achieving fault-tolerance in distributed systems. One way to achieve system fault-tolerance is to ensure that when faults occur the system continues to satisfy its input-output relation.
Reference: [4] <author> A. Arora and M.G. Gouda, </author> <title> "Distributed reset (extended abstract)", </title> <booktitle> Proceedings of 10th Conference on Foundations of Software Technology and Theoretical Computer Science, LNCS 472 (1990), </booktitle> <pages> pp. 316-331, </pages> <publisher> Springer-Verlag. </publisher>
Reference: [5] <author> J.E. Burns, M.G. Gouda, and R.E. Miller, </author> <title> "On relaxing interleaving assumptions", </title> <type> Technical Report GIT-ICS-88/29, </type> <institution> School of ICS, Georgia Institute of Technology (1988). </institution>
Reference-contexts: Second, our design remains correct even if we weaken the interleaving requirement as follows: in each step, an arbitrary subset of the processes each execute some enabled action, as long as no two executed actions access the same shared variable <ref> [2, 3, 5] </ref>. A comment is also in order regarding our methodology for achieving fault-tolerance in distributed systems. One way to achieve system fault-tolerance is to ensure that when faults occur the system continues to satisfy its input-output relation.
Reference: [6] <author> G.M. Brown, M.G. Gouda, and C.-L. Wu, </author> <title> "Token systems that self-stabilize", </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 38, No. 6 (1989), </volume> <pages> pp. 845-852. </pages>
Reference-contexts: Once coordination is restored, it is maintained unless a later failure causes it to be lost again, and the cycle repeats <ref> [6, 7] </ref>.
Reference: [7] <author> J.E. Burns and J. Pachl, </author> <title> "Uniform self-stabilizing rings", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 11, No. 2 (1989), </volume> <pages> pp. 330-344. </pages>
Reference-contexts: Once coordination is restored, it is maintained unless a later failure causes it to be lost again, and the cycle repeats <ref> [6, 7] </ref>.
Reference: [8] <author> K.M. Chandy and L. Lamport, </author> <title> "Distributed snapshots: Determining global states of distributed systems", </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol. 3, No. 1 (1985), </volume> <pages> pp. 63-75. </pages>
Reference-contexts: The situations in which distributed resets are necessary are application specific. One such situation, however, is when the global state of the application layer is erroneous. Erroneous states may be detected by periodically executing a self-stabilizing global state detection algorithm <ref> [8, 14] </ref>. Towards this end, we note that it is possible to implement a self-stabilizing global state detection with minor modifications to our reset subsystem.
Reference: [9] <author> S. Dolev, A. Israeli, and S. Moran, </author> <title> "Self-stabilization of dynamic systems assuming only read/write atomicity", </title> <booktitle> Proceedings of the Ninth ACM Symposium on Principles of Distributed Computing (1990), </booktitle> <pages> pp. 103-117. </pages>
Reference-contexts: The design consists of three major components: a leader election, a spanning tree construction, and a diffusing computation. Each of these components is self-stabilizing, can tolerate process and channel failures and repairs, and admits bounded-space implementations. These features distinguish our design of these components from earlier designs <ref> [1, 9, 10] </ref> and redress the following comment made by Lamport and Lynch [15, page 1193] : "A self-stabilizing algorithm [that translates a distributed system designed for a fixed but arbitrary network into one that works for a changing network] using a finite number of identifiers would be quite useful, but <p> This restriction is too severe for our purposes, and we have lifted it by designing the tree layer to be self-stabilizing; i.e., insensitive to the initial state. We note that a self-stabilizing spanning tree algorithm has been recently described in <ref> [9] </ref>. However, the algorithm in [9] is based on the simplifying assumption that, at all times, there exists a special process which knows that it is the root. <p> This restriction is too severe for our purposes, and we have lifted it by designing the tree layer to be self-stabilizing; i.e., insensitive to the initial state. We note that a self-stabilizing spanning tree algorithm has been recently described in <ref> [9] </ref>. However, the algorithm in [9] is based on the simplifying assumption that, at all times, there exists a special process which knows that it is the root.
Reference: [10] <author> E.W. Dijkstra, and C.S. Scholten, </author> <title> "Termination detection for diffusing computations", </title> <journal> Information Processing Letters, </journal> <volume> Vol. 11, No. 1 (1980), </volume> <pages> pp. 1-4. </pages>
Reference-contexts: The design consists of three major components: a leader election, a spanning tree construction, and a diffusing computation. Each of these components is self-stabilizing, can tolerate process and channel failures and repairs, and admits bounded-space implementations. These features distinguish our design of these components from earlier designs <ref> [1, 9, 10] </ref> and redress the following comment made by Lamport and Lynch [15, page 1193] : "A self-stabilizing algorithm [that translates a distributed system designed for a fixed but arbitrary network into one that works for a changing network] using a finite number of identifiers would be quite useful, but <p> We have not made this assumption: if a root process fails, then the remaining up processes elect a new root. 8 4 The Wave Layer As outlined in Section 2, the task of the wave layer is to perform a diffusing computation <ref> [10] </ref> in which each appl:i module resets its state. The diffusing computation uses the spanning tree maintained by the tree layer, and consists of three phases.
Reference: [11] <author> M. Fischer, N. Lynch, and M. Paterson, </author> <title> "Impossibility of distributed consensus with one faulty process", </title> <journal> Journal of the ACM , Vol. </journal> <volume> 32, No. 2 (1985), </volume> <pages> pp. 374-382. </pages>
Reference-contexts: First, in some distributed systems, masking fault-tolerance may be impossible to achieve. For example, there is no masking fault-tolerant distributed system whose up processes communicate asynchronously and reach consensus on a binary value even when one or more of the processes fail <ref> [11] </ref>. Second, even if it is possible to implement masking fault-tolerance, the cost of doing so may be prohibitive. For example, the amount of redundancy or synchronization required may be infeasible to implement. And third, requiring masking fault-tolerance may be more strict than is desirable.
Reference: [12] <author> N. Francez, </author> <title> Fairness, </title> <publisher> Springer-Verlag, </publisher> <year> 1986. </year>
Reference-contexts: The maximality of a computation implies that no computation is a proper prefix of another computation. The fairness of a computation means that each continuously enabled action is eventually executed in the computation <ref> [12] </ref>. 5 3 The Tree Layer The task of the tree layer is to continually maintain a rooted spanning tree even when there are changes in the set of up processes or in the adjacency relation.
Reference: [13] <author> M.G. Gouda, and N. Multari, </author> <title> "Stabilizing communication protocols", </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 40, No. 4 (1991), </volume> <pages> pp. 448-458. </pages>
Reference-contexts: Therefore, a rooted spanning tree exists. Also, note that each state in G is a fixed-point; i.e., once the tree:i modules reach a state in G, no action in any of the tree:i modules is enabled. 7 Our proof employs the "convergence stair" method <ref> [13] </ref>: we exhibit a finite sequence of state predicates H:0; H:1; :::; H:K such that (i) H:0 true (ii) H:K G (iii) For each l such that 0 l K: H:l is closed under system execution; that is, once H:l holds in an arbitrary system com putation, it continues to hold
Reference: [14] <author> S. Katz and K. Perry, </author> <title> "Self-stabilizing extensions for message-passing systems", </title> <booktitle> Proceedings of the Ninth ACM Symposium on Principles of Distributed Computing (1990), </booktitle> <pages> pp. 91-101. </pages>
Reference-contexts: The situations in which distributed resets are necessary are application specific. One such situation, however, is when the global state of the application layer is erroneous. Erroneous states may be detected by periodically executing a self-stabilizing global state detection algorithm <ref> [8, 14] </ref>. Towards this end, we note that it is possible to implement a self-stabilizing global state detection with minor modifications to our reset subsystem. <p> We are currently implementing distributed operating system programs based on dis 16 tributed resets including, for example, system programs for multiprocess resynchronization. We are also currently studying reconfiguration protocols for high speed networks. We note that distributed resets provide a systematic method for making arbitrary distributed systems self-stabilizing (cf. <ref> [14] </ref>): application layer modules can be augmented to perform a self-stabilizing global state detection periodically, and to request a distributed reset upon detecting erroneous global states thereby making the distributed system self-stabilizing.
Reference: [15] <author> L. Lamport, and L. Lynch, </author> <title> "Distributed computing: models and methods", </title> <journal> Hand--book of Theoretical Computer Science, </journal> <volume> Chapter 18, Vol. 2 (1990), </volume> <pages> pp. 1158-1199, </pages> <publisher> Elsevier Science Publishers. </publisher>
Reference-contexts: Each of these components is self-stabilizing, can tolerate process and channel failures and repairs, and admits bounded-space implementations. These features distinguish our design of these components from earlier designs [1, 9, 10] and redress the following comment made by Lamport and Lynch <ref> [15, page 1193] </ref> : "A self-stabilizing algorithm [that translates a distributed system designed for a fixed but arbitrary network into one that works for a changing network] using a finite number of identifiers would be quite useful, but we know of no such algorithm." The rest of the paper is organized <p> We conclude this section with the remark that the problems of leader election and spanning tree construction have received considerable attention in the literature (see, for example, <ref> [15, 16, 17] </ref>). Most of these algorithms are based on the assumption that all processes start execution in some designated initial state. This restriction is too severe for our purposes, and we have lifted it by designing the tree layer to be self-stabilizing; i.e., insensitive to the initial state.
Reference: [16] <author> R. Perlman, </author> <title> "An algorithm for distributed computation of a spanning tree in an extended LAN", </title> <booktitle> Ninth ACM Data Communications Symposium, </booktitle> <volume> Vol. 20, No. 7 (1985), </volume> <pages> pp. 44-52. </pages>
Reference-contexts: We conclude this section with the remark that the problems of leader election and spanning tree construction have received considerable attention in the literature (see, for example, <ref> [15, 16, 17] </ref>). Most of these algorithms are based on the assumption that all processes start execution in some designated initial state. This restriction is too severe for our purposes, and we have lifted it by designing the tree layer to be self-stabilizing; i.e., insensitive to the initial state.

References-found: 16

