URL: http://www.cs.umd.edu/~keleher/papers/writers.ps.gz
Refering-URL: http://www.cs.umd.edu/~keleher/papers.html
Root-URL: 
Email: keleher@cs.umd.edu  
Title: The Relative Importance of Concurrent Writers and Weak Consistency Models  
Author: Peter J. Keleher 
Address: College Park, MD 20742-3255  
Affiliation: Department of Computer Science University of Maryland  
Abstract: This paper presents a detailed comparison of the relative importance of allowing concurrent writers versus the choice of the underlying consistency model. Our comparison is based on single- and multiple-writer versions of a lazy release consistent (LRC) protocol, and a single-writer sequentially consistent protocol, all implemented in the CVM software distributed shared memory system. We find that in our environment, which we believe to be representative of distributed systems today and in the near future, the consistency model has a much higher impact on overall performance than the choice of whether to allow concurrent writers. The multiple writer LRC protocol performs an average of 9% better than the single writer LRC protocol, but 34% better than the single-writer sequentially consistent protocol. Set against this, MW-LRC required an average of 72% memory overhead, compared to 10% overhead for the single-writer protocols. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B.N. Bershad, M.J. Zekauskas, </author> <title> and W.A. </title> <booktitle> Sawdon. The Midway distributed shared memory system. In Proceedings of the '93 CompCon Conference, </booktitle> <pages> pages 528-537, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: All of our applications are free of data-races. The cost of creating a diff is substantial (approximately three fourths of the cost of an RPC in our system), and will probably grow relative to processor speed as memory latency falls further behind processor speed. Systems such as Midway <ref> [1] </ref> avoid the page-length copies and comparison by using a modified compiler to annotate all shared writes with code that tracks accesses by using software dirty bits [17]. When the diff needs to be created, the software dirty bits are used to determine exactly which words have been modified.
Reference: [2] <author> J.B. Carter, J.K. Bennett, and W. Zwaenepoel. </author> <title> Implementation and performance of Munin. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 152-164, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: The larger coherence granularities used by DSMs cause them to suffer increased coherence traffic because of false sharing, or simultaneous accesses by different processors to unrelated parts of the datum. Software DSMs such as TreadMarks [9] Munin <ref> [2] </ref>, and CarlOS [12], alleviate the effects of false sharing by supporting multiple-writer protocols. These protocols allow multiple nodes to simultaneously modify different sections of the same page. The modifications are later reconciled by creating summaries of each of the modifications, called diffs [2], and applying the diffs to all copies <p> Software DSMs such as TreadMarks [9] Munin <ref> [2] </ref>, and CarlOS [12], alleviate the effects of false sharing by supporting multiple-writer protocols. These protocols allow multiple nodes to simultaneously modify different sections of the same page. The modifications are later reconciled by creating summaries of each of the modifications, called diffs [2], and applying the diffs to all copies of the page. The advantages of multiple-writer protocols for software DSMs are clear: the effects of false sharing are minimized because processors can make local decisions to write valid page without communicating with other processors. <p> Note that this is the case for any single-writer protocol, including the sequentially consistent protocol implemented in IVY [13] and the eager release consistent protocol implemented in Munin <ref> [2] </ref>. The obvious disadvantage of multiple-writer protocols is that they must use diffs to merge concurrent updates to the same page.
Reference: [3] <author> Alan Cox, Sandhya Dwarkadas, and Willy Zwaenepoel. </author> <title> A comparison of entry consistency and lazy release consistency implementations. </title> <type> DRAFT: </type> <note> submitted for publication, </note> <month> August </month> <year> 1995. </year>
Reference-contexts: When the diff needs to be created, the software dirty bits are used to determine exactly which words have been modified. While the copy and comparison are avoided, the software dirty bit approach requires language support and adds overhead to every shared write. Recent work <ref> [3] </ref> shows that well-implemented diffing mechanism can outperform software dirty bits in object-based systems, but the tradeoff is less clear for page-based systems. 2.3.4 Tradeoffs The most obvious advantage of the multiple-writer protocol is that it allows concurrent modifications of the same page without network communication.
Reference: [4] <author> S.J. Eggers and R.H. Katz. </author> <title> A characterization of sharing in parallel programs and its application to coherency protocol evaluation. </title> <booktitle> In Proceedings of the 15th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 373-383, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: Our comparisons show that the performance of SW-LRC trails MW-LRC's by nine percent overall, but SW-LRC actually averages three percent better than MW-LRC for six of the eight applications in our study. This result has several root causes. First, write-write false sharing is much less common than read-write <ref> [4] </ref> sharing. Second, the weak memory model allows even SW-LRC to hide most of the effects of read-write false sharing by allowing multiple readers to co-exist with a single writer. Finally, communication in this environment has a high startup cost for each message, while the per-byte cost is relatively low.
Reference: [5] <author> B. Fleisch and G. Popek. </author> <title> Mirage: A coherent distributed shared memory design. </title> <booktitle> In Proceedings of the 12th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 211-223, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: Ownership could be retained by the current owner while servicing read faults, but the status of the owner's page still needs to be downgraded to read-only. We chose to migrate ownership as an optimization favoring migratory data. Like Mirage <ref> [5] </ref>, we address the ping-pong problem by guaranteeing a processor a minimum quantum of time with any newly retrieved page before it can be invalidated by another processor. The ping-pong problem occurs when multiple processors simultaneously attempt to write the same page.
Reference: [6] <author> K. Gharachorloo, D. Lenoski, J. Laudon, P. Gibbons, A. Gupta, and J. Hennessy. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: conclusions. 2 CVM and Protocols This section provides a brief overview of lazy release consistency, a description of the CVM system in which the protocols are implemented, and a description of the protocols themselves. 2.1 Lazy Release Consistency Lazy Release Consistency [8] is a variant of eager release consistency (ERC) <ref> [6] </ref>, a relaxed memory consistency that allows the effects of shared memory accesses to be delayed until selected synchronization accesses occur. Simplifying matters somewhat, shared memory accesses are labeled either as ordinary or as synchronization accesses, with the latter category further divided into acquire and release accesses.
Reference: [7] <author> P. Keleher. </author> <title> Distributed Shared Memory Using Lazy Release Consistency. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <year> 1994. </year>
Reference: [8] <author> P. Keleher, A. L. Cox, and W. Zwaenepoel. </author> <title> Lazy release consistency for software distributed shared memory. </title> <booktitle> In Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 13-21, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: For the comparison described in this paper, we implemented three protocols: a multiple-writer LRC protocol (MW-LRC), a single-writer LRC protocol (SW-LRC), and a single-writer SC protocol (SW-SC). SW-LRC and MW-LRC are single- and multiple-writer protocols that implement the lazy release consistent (LRC) <ref> [8] </ref> memory model. While SW-LRC requires processors to gain ownership of a page before modifying it, the lazy protocol allows any number of readers to co-exist with a single writer. We compare the performance of the two protocols in order to gauge the importance of allowing multiple simultaneous writers. <p> Finally, in Section 4, we present our conclusions. 2 CVM and Protocols This section provides a brief overview of lazy release consistency, a description of the CVM system in which the protocols are implemented, and a description of the protocols themselves. 2.1 Lazy Release Consistency Lazy Release Consistency <ref> [8] </ref> is a variant of eager release consistency (ERC) [6], a relaxed memory consistency that allows the effects of shared memory accesses to be delayed until selected synchronization accesses occur.
Reference: [9] <author> P. Keleher, S. Dwarkadas, A. Cox, and W. Zwaenepoel. Treadmarks: </author> <title> Distributed shared memory on standard workstations and operating systems. </title> <booktitle> In Proceedings of the 1994 Winter Usenix Conference, </booktitle> <pages> pages 115-131, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: The larger coherence granularities used by DSMs cause them to suffer increased coherence traffic because of false sharing, or simultaneous accesses by different processors to unrelated parts of the datum. Software DSMs such as TreadMarks <ref> [9] </ref> Munin [2], and CarlOS [12], alleviate the effects of false sharing by supporting multiple-writer protocols. These protocols allow multiple nodes to simultaneously modify different sections of the same page. <p> Like commercially available systems such as TreadMarks <ref> [9] </ref>, CVM is written entirely as a user-level library and runs on most UNIX-like systems. Unlike Tread-Marks, CVM was created specifically as a platform for protocol experimentation. The system is written in C++, and opaque interfaces are strictly enforced between different functional units of the system whenever possible. <p> The underlying system calls protocol hooks before and after page faults, synchronization, and I/O events take place. Since many of the methods are inlined, the resulting system is able to perform within a few percent of a severely optimized system, Tread-Marks <ref> [9] </ref>, running a nearly identical protocol. However, CVM was designed to take advantage of generalized synchronization interfaces, as well as to use multi-threading for latency toleration. We therefore expect the performance of the fully functional system to improve over the existing base.
Reference: [10] <author> Pete Keleher. </author> <title> The Coherent Virtual Machine. </title> <type> Technical Report Maryland TR93-215, </type> <institution> Department of Computer Science, University of Maryland, </institution> <month> September </month> <year> 1995. </year>
Reference: [11] <author> Pete Keleher, Alan L. Cox, Sandhya Dwarkadas, and Willy Zwaenepoel. </author> <title> An evaluation of software-based release consistent protocols. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 29(2) </volume> <pages> 126-141, </pages> <month> September </month> <year> 1995. </year>
Reference: [12] <author> Povl T. Koch, Robert J. Fowler, and Eric Jul. </author> <title> Message-driven relaxed consistency in a software distributed shared memory. </title> <booktitle> In Proc. of the First Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 75-85, </pages> <address> Monterey, CA, </address> <month> November </month> <year> 1994. </year> <note> USENIX Assoc. </note>
Reference-contexts: The larger coherence granularities used by DSMs cause them to suffer increased coherence traffic because of false sharing, or simultaneous accesses by different processors to unrelated parts of the datum. Software DSMs such as TreadMarks [9] Munin [2], and CarlOS <ref> [12] </ref>, alleviate the effects of false sharing by supporting multiple-writer protocols. These protocols allow multiple nodes to simultaneously modify different sections of the same page.
Reference: [13] <author> K. Li and P. Hudak. </author> <title> Memory coherence in shared virtual memory systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(4) </volume> <pages> 321-359, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: Therefore, unless single-writer protocols are carefully crafted, producer-consumer interactions will require two network RPCs, each of which can consist of up to three messages. Note that this is the case for any single-writer protocol, including the sequentially consistent protocol implemented in IVY <ref> [13] </ref> and the eager release consistent protocol implemented in Munin [2]. The obvious disadvantage of multiple-writer protocols is that they must use diffs to merge concurrent updates to the same page. <p> Both IVY and Munin use a scheme based on following chains of probable owners until the real owner is located, collapsing the probable owner pointers as a request is forwarded. Li and Hudac <ref> [13] </ref> showed that in the worst case, k faults of a page in an n-processor system can result in a worst case of O (n + k log n) hops.
Reference: [14] <author> Message Passing Interface Forum. </author> <title> MPI: A Message-Passing Interface, </title> <year> 1994. </year>
Reference-contexts: The SP-2 has a high-performance Omega switch in which each bi-directional link is capable of a sustained bandwidth of approximately forty megabytes per second. Each processor is a 66MHz RS/6000 Power2. The applications were run on a version of CVM ported to MPI <ref> [14] </ref>. MPI does not yet allow handlers to be called asynchronously on receipt of messages, so the system polls for incoming messages when outgoing messages are sent.
Reference: [15] <author> C. B. Stunkel, D. G. Shea, B. Abali, M. M. Denneau, P. H. Hochschild, D. J. Joseph, B. J. Nathanson, M. Tsao, and P. R. Varker. </author> <booktitle> Architecture and implementation of vulcan. In Proceedings of the 8th International parallel Processing Symposium, </booktitle> <pages> pages 268-274, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: TSP performs well despite fine-grained sharing because it synchronizes infrequently (see Table 1). 3.3.1 Sharing We used our run-time system to generate traces showing all page protection changes during executions. These traces, timestamped by the globally synchronous clock on the switch of the SP-2 <ref> [15] </ref>, drive a post-mortem analyzer that tracks how long individual pages are shared in various modes. Table 2 shows the results. Several items are of interest. First, two applications, SPA and QS, have substantial write sharing under MW-LRC.
Reference: [16] <author> S. C. Woo, M. Ohara, E. Torrie, J. P. Singh, and A. Gupta. </author> <title> The SPLASH-2 programs: Characterization and methodological considerations. </title> <booktitle> In Proceedings of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 24-37, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: However, virtual memory primitive costs in the current system are location-dependent, occasionally increasing these costs to a millesecond or more. 3.2 Applications The applications used in this study include four applications from the SPLASH-2 <ref> [16] </ref> suite of shared-memory programs: Water-Nsquared (Water), Water-spatial (SPA), FMM, and LU. The other four programs were locally written: FFT, SOR, Quicksort (QS), and Traveling Salesman Problem (TSP).
Reference: [17] <author> Mathew J. Zekauskas, Wayne A. Sawdon, and Brian N. Ber-shad. </author> <title> Software write detection for distributed shared memory. </title> <booktitle> In Proceedings of the First USENIX Symposium on Operating System Design and Implementation, </booktitle> <pages> pages 87-100, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Systems such as Midway [1] avoid the page-length copies and comparison by using a modified compiler to annotate all shared writes with code that tracks accesses by using software dirty bits <ref> [17] </ref>. When the diff needs to be created, the software dirty bits are used to determine exactly which words have been modified. While the copy and comparison are avoided, the software dirty bit approach requires language support and adds overhead to every shared write.
References-found: 17

