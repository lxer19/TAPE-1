URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/ytw/www/paper.ps.gz
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/ytw/www/facial.html
Root-URL: 
Title: Optical Flow Estimation Using Wavelet Motion Model  
Author: ; Yu-Te Wu Takeo Kanade Jeffrey Cohn Ching-Chung Li 
Address: Pittsburgh Pittsburgh, PA 15213 Pittsburgh, PA 15260 Pittsburgh, PA 15260  
Affiliation: 1 The Robotics Institute 2 Dept. of Psychology and Psychiatry 3 Dept. of Electrical Engr. Carnegie Mellon University University of Pittsburgh University of  
Abstract: A motion estimation algorithm using wavelet approximation as an optical flow model has been developed to estimate accurate dense optical flow from an image sequence. This wavelet motion model is particularly useful in estimating optical flows with large displacement. Traditional pyramid methods which use the coarse-to-fine image pyramid by image burring in estimating optical flow often produce incorrect results when the coarse-level estimates contain large errors that cannot be corrected at the subsequent finer levels. This happens when regions of low texture become flat or certain patterns result in spatial aliasing due to image blurring. Our method, in contrast, uses large-to-small full-resolution regions without blurring images, and simultaneously optimizes the coarser and finer parts of optical flow so that the large and small motion can be estimated correctly. We compare results obtained by using our method with those obtained by using one of the leading optical flow methods, the Szeliski pyramid spline-based method. The experiments include cases of small displacement (less than 4 pixels under 128fi 128 image size or equivalent displacement under other image sizes), and those of large displacement (10 pixels). While both methods produce comparable results when the displacements are small, our method outperforms pyramid spline-based method when the displacements are large. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Barron, J.L., </author> <title> Fleet, D.J., and Beauchemin, S.S. Performance of optical flow techniques, </title> <journal> International Journal of Computer Vision, </journal> <volume> vol. 12, </volume> <year> 1994, </year> <pages> pp. 43-77. </pages>
Reference-contexts: As finer-scale coefficients are estimated by minimizing the sum of squared intensity differences between the warped image and the second image, we obtain more accurate results. To handle large displacement, a number of coarse-to-fine hierarchical methods <ref> [2, 4, 1] </ref> have been developed. The pyramid methods which use coarse-to-fine blurred images sequentially in estimating optical flow often produce incorrect results when large errors occurring in coarser estimates cannot be subsequently corrected in the finer estimates. <p> but also larger patches are optimally used in the sense that the coarser- and finer-scale coefficients minimize SSD. 4 Experimental Results This section compares the results produced by wavelet-based and spline-based methods. 4.1 Synthetic Image Pairs Containing Small Displacement In the first experiment, we use the synthetic images in paper <ref> [1] </ref>, where the ground truth of optical flow vectors is provided. In the pyramid spline-based method, the low-pass Gaussian filter with mask size 3 fi 3 pixels is successively applied to create the coarse-to-fine blurred images. Two error measurements we use are the angular measure e [1] and the magnitude measure <p> synthetic images in paper <ref> [1] </ref>, where the ground truth of optical flow vectors is provided. In the pyramid spline-based method, the low-pass Gaussian filter with mask size 3 fi 3 pixels is successively applied to create the coarse-to-fine blurred images. Two error measurements we use are the angular measure e [1] and the magnitude measure m e , defined by e = arcos ( uu t + vv t + 1 u 2 + v 2 + 1 u 2 t + 1 m e = j u 2 + v 2 u 2 t j (17) Image Pairs Spline-based method <p> In the Yosemite image pair, the three level spline flow is better than the wavelet flow. However, we obtained better results when 4 levels were used. In general, both flow estimates are accurate and comparable, and both methods outperform other methods in <ref> [1] </ref> and method in [7]. (see [4] and [8]). 4.2 Synthetic Image Pair Containing Large Displacement In the second experiment, the input image (Figure 9) is created by cropping part of the Sinusoidal 1 and the Tree images where the sinusoidal pattern has a displacement of 1.585 pixels upward and 0.863 <p> The results using wavelet method are shown in the right column of Figures 10. The flow vectors of the sinusoidal 1 and Tree patterns are well recovered. 4.3 Real Image Sequences The results of three real image sequences, SRI, NASA, Hamburg Taxi sequences in <ref> [1] </ref> are presented in Figures 11, 12, and 13, respectively. Flow of ten image frames is presented for each image sequence. Overall, the results look reasonable.
Reference: [2] <author> Bergen, J. R., Anandan, P., Hanna, K. J., and Hingorani R. </author> <title> Hierarchical model-based motion estimation, </title> <editor> in: G. Sandini, ed., </editor> <booktitle> Computer Vision-ECCV '92,Springer, </booktitle> <address> Berlin, </address> <year> 1992, </year> <pages> pp. 237-252. </pages>
Reference-contexts: As finer-scale coefficients are estimated by minimizing the sum of squared intensity differences between the warped image and the second image, we obtain more accurate results. To handle large displacement, a number of coarse-to-fine hierarchical methods <ref> [2, 4, 1] </ref> have been developed. The pyramid methods which use coarse-to-fine blurred images sequentially in estimating optical flow often produce incorrect results when large errors occurring in coarser estimates cannot be subsequently corrected in the finer estimates.
Reference: [3] <author> Horn, B.K.P. and Schunck, B.G. </author> <title> Determining optical flow: A retrospective, </title> <journal> Artificial Intelligence, </journal> <volume> vol. 17, </volume> <year> 1981, </year> <pages> pp. 185-203. </pages>
Reference-contexts: Using the scaling function, they tions at different resolution scales constructed the wavelet (Figure 1.(b)) (x) = 7 12 (2x 1) 7 The supports of (x) and (x) are [0; 4] and <ref> [0; 3] </ref>, respectively, i.e., the values of (x) (or (x)) are zeros outside [0; 4] (or [0; 3]). <p> Using the scaling function, they tions at different resolution scales constructed the wavelet (Figure 1.(b)) (x) = 7 12 (2x 1) 7 The supports of (x) and (x) are [0; 4] and <ref> [0; 3] </ref>, respectively, i.e., the values of (x) (or (x)) are zeros outside [0; 4] (or [0; 3]). <p> on the boundraries [0; 128 2 j ] and [256 128 3 Wavelet-Based Flow Estimation Suppose image I 0 (x; y) and I 1 (x; y) are related by horizontal and vertical displacement (flow or motion) vectors u (x; y) and v (x; y) under the intensity con stancy constraint <ref> [3] </ref>.
Reference: [4] <author> Szeliski, R. and Coughlan, J. </author> <title> Spline-Based Image Registration International Journal of Computer Vision, </title> <type> 22(3), </type> <year> 1997, </year> <pages> pp. 199-218. </pages>
Reference-contexts: As finer-scale coefficients are estimated by minimizing the sum of squared intensity differences between the warped image and the second image, we obtain more accurate results. To handle large displacement, a number of coarse-to-fine hierarchical methods <ref> [2, 4, 1] </ref> have been developed. The pyramid methods which use coarse-to-fine blurred images sequentially in estimating optical flow often produce incorrect results when large errors occurring in coarser estimates cannot be subsequently corrected in the finer estimates. <p> Using the scaling function, they tions at different resolution scales constructed the wavelet (Figure 1.(b)) (x) = 7 12 (2x 1) 7 The supports of (x) and (x) are <ref> [0; 4] </ref> and [0; 3], respectively, i.e., the values of (x) (or (x)) are zeros outside [0; 4] (or [0; 3]). <p> Using the scaling function, they tions at different resolution scales constructed the wavelet (Figure 1.(b)) (x) = 7 12 (2x 1) 7 The supports of (x) and (x) are <ref> [0; 4] </ref> and [0; 3], respectively, i.e., the values of (x) (or (x)) are zeros outside [0; 4] (or [0; 3]). <p> Influence of coefficients c j;k can be global or local depending on the size of support of the corresponding basis function. To see this, let us assume L = 4 for simplicity such that the scaling functions (x k) in the coarsest scale have support <ref> [0; 4] </ref> (except on the boundary), and the wavelet functions j;k have (narrower) support [0; 3 2 j ] (except near the boundary), j 0. Let us also assume a finite sampled function defined on pixel domain [0; 256]. We map [0; 4] into [0; 256] so that the effects are <p> functions (x k) in the coarsest scale have support <ref> [0; 4] </ref> (except on the boundary), and the wavelet functions j;k have (narrower) support [0; 3 2 j ] (except near the boundary), j 0. Let us also assume a finite sampled function defined on pixel domain [0; 256]. We map [0; 4] into [0; 256] so that the effects are interpreted on pixel unit. <p> In the Yosemite image pair, the three level spline flow is better than the wavelet flow. However, we obtained better results when 4 levels were used. In general, both flow estimates are accurate and comparable, and both methods outperform other methods in [1] and method in [7]. (see <ref> [4] </ref> and [8]). 4.2 Synthetic Image Pair Containing Large Displacement In the second experiment, the input image (Figure 9) is created by cropping part of the Sinusoidal 1 and the Tree images where the sinusoidal pattern has a displacement of 1.585 pixels upward and 0.863 pixel rightward, and the tree pattern
Reference: [5] <author> Cai, W. and Wang J. </author> <title> Adaptive multiresolution collocation methods for initial boundary value problems of nonlinear PDEs, </title> <journal> SIAM NUMER. ANAL. </journal> <volume> Vol. 33, No. 3, </volume> <pages> pp. 937-970, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: 1 Introduction This paper presents a method to estimate optical flow using coarse-to-fine wavelet representation, newly presented by Cai and Wang <ref> [5] </ref>, as a motion model. The wavelet motion model represents motion vectors by a linear combination of hierarchical basis functions. The coarser-scale basis function has larger support while the finer-scale basis function has smaller support. Corresponding to these variably sized supports, large-to-small full-resolution regions are used in image matching. <p> Cai and Wang have shown that <ref> [5] </ref> any continuous function d (x) 2 H 2 (I) can be approximated as closely as possible by a function in V j for a sufficiently large j which has a unique orthogonal approximation d (x) d 1 (x) + d 0 (x) + d 1 (x) + d j (x) <p> Although the existence of approximation is (a) (x)(y), (b) (x) (y), (c) (x)(y) and (d) proved for any continuous function in H 2 (I), it has been demonstrated in <ref> [5, 8] </ref> that it holds for any finite sampled function in the practical applications. Influence of coefficients c j;k can be global or local depending on the size of support of the corresponding basis function.
Reference: [6] <author> Press, W. H., Flannery, B. P., Teukolsky, S. A., and Vetter-ling,W. T. </author> <title> Numerical Recipes in C: </title> <booktitle> The Art of Scientific Computing, </booktitle> <publisher> Cambridge University Press, </publisher> <address> Cambridge, 2nd, </address> <year> 1992. </year>
Reference-contexts: The gradient (I x ; I y ) and the residual difference, I 1 (x + u i ; y + v i ) I 0 (x; y), are then computed. When E (ffi^c 1 ) is minimized using the Levenberg-Marquardt algorithm <ref> [6] </ref>, the resultant coefficients ^c i 1 are used as the initial guess and propagated into the next finer level. In the next finer level, we update the coefficients estimated at the previous coarsest level, and estimate three sets of coefficients at the current level one by one.
Reference: [7] <author> Xiong, Y. and Shafer, S. A. </author> <title> Moment and Hypergeometric Filters for High Precision Computation of Focus, Stereo and Optical Flow, </title> <journal> International Journal of Computer Vision, </journal> <volume> vol. 22(1), </volume> <year> 1997, </year> <pages> 25-59. </pages>
Reference-contexts: In the Yosemite image pair, the three level spline flow is better than the wavelet flow. However, we obtained better results when 4 levels were used. In general, both flow estimates are accurate and comparable, and both methods outperform other methods in [1] and method in <ref> [7] </ref>. (see [4] and [8]). 4.2 Synthetic Image Pair Containing Large Displacement In the second experiment, the input image (Figure 9) is created by cropping part of the Sinusoidal 1 and the Tree images where the sinusoidal pattern has a displacement of 1.585 pixels upward and 0.863 pixel rightward, and the

References-found: 7

