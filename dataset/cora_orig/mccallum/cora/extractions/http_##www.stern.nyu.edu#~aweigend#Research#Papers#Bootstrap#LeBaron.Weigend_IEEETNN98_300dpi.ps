URL: http://www.stern.nyu.edu/~aweigend/Research/Papers/Bootstrap/LeBaron.Weigend_IEEETNN98_300dpi.ps
Refering-URL: http://www.stern.nyu.edu/~aweigend/Research/Papers/Bootstrap/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: A Bootstrap Evaluation of the Effect of Data Splitting on Financial Time Series  
Phone: 1  
Author: LEONARD N. STERN Blake LeBaron and Andreas S. Weigend 
Keyword: Model evaluation. Model uncertainty. Bootstrap. Resampling. Financial forecasting. Time series prediction. Linear bias of early stopping. Superposition of forecasts. Model merging.  
Address: NEW YORK UNIVERSITY  
Affiliation: SCHOOL OF BUSINESS,  
Note: WORKING PAPER IS-97-013,  Data|Dow Jones Industrial Average, 1962-1987. Volume from New York Stock Exchange, 1962-1987. The data used in this article is available from the web sites of the authors.  
Abstract: This article exposes problems of the commonly used technique of splitting the available data into training, validation, and test sets that are held fixed, warns about drawing too strong conclusions from such static splits, and shows potential pitfalls of ignoring variability across splits. Using a bootstrap or resampling method, we compare the uncertainty in the solution stemming from the data splitting with neural network specific uncertainties (parameter initialization, choice of number of hidden units, etc.). We present two results on data from the New York Stock Exchange. First, the variation due to different resamplings is significantly larger than the variation due to different network conditions. This result implies that it is important to not over-interpret a model (or an ensemble of models) estimated on one specific split of the data. Second, on each split, the neural network solution with early stopping is very close to a linear model; no significant nonlinearities are extracted. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bates, J. M. and C. W. J. Granger. </author> <year> 1969. </year> <title> The combination of forecasts. </title> <journal> Operations Research Quarterly 20, </journal> <pages> 451-468. </pages>
Reference-contexts: The main reason for this spreading is that the inputs wander off into re 11 The idea of combining of forecasts <ref> (Bates & Granger, 1969) </ref>, based on the idea that superposition helps to the degree that the errors are uncorrelated, has recently reached the connectionist community, see e.g., (Jacobs, 1995).
Reference: <author> Bollerslev, T., R. Y. Chou, N. Jayaraman and K. F. Kroner. </author> <year> 1990. </year> <title> ARCH modeling in finance: A review of the theory and empirical evidence. </title> <journal> Journal of Econometrics 52(1), </journal> <pages> 5-60. </pages>
Reference: <author> Bollerslev, T., R. F. Engle and D. B. Nelson. </author> <year> 1995. </year> <title> ARCH models. In Handbook of Econometrics, </title> <editor> R. F. En-gle and D. L. McFadden (eds), </editor> <volume> vol. 4, chapter 49. </volume> <publisher> North-Holland, </publisher> <address> New York, NY. </address>
Reference: <author> Buntine, W. L. and A. S. Weigend. </author> <year> 1991. </year> <title> Bayesian backpropagation. </title> <booktitle> Complex Systems 5, </booktitle> <pages> 603-643. </pages>
Reference: <author> Carroll, R., D. Ruppert and L. Stefanski. </author> <year> 1995. </year> <title> Measurement Error in Nonlinear Models. </title> <publisher> Chapman and Hall, London. </publisher>
Reference: <author> Connor, J. T. </author> <year> 1993. </year> <title> Bootstrap methods in neural network time series prediction. </title> <booktitle> In International Workshop on Applications of Neural Networks to Telecommunications, </booktitle> <editor> J. Alspector, R. Goodman and T. </editor> <publisher> X. </publisher>
Reference: <editor> Brown (eds), </editor> <booktitle> pp. </booktitle> <pages> 125-131, </pages> <address> Hillsdale, NJ. </address> <publisher> Erlbaum. </publisher>
Reference: <author> Efron, B. and R. Tibshirani. </author> <year> 1993. </year> <title> An Introduction to the Bootstrap. </title> <publisher> Chapman and Hall, </publisher> <address> New York. </address>
Reference-contexts: We combine bootstrapping along with random network selection and initialization. In more detail, in order to understand the impact of the splitting and network choices, we draw a realization of splits and network conditions, and train a complete model on this realization. This is sometimes called bootstrapping pairs <ref> (Efron & Tibshirani, 1993) </ref>, since the input-output pairs or patterns remain intact, and are resampled as full patterns. This can be contrasted with training one model only, and resampling the errors of that one model to obtain a distribution, called bootstrapping residuals.
Reference: <author> Efron, B. </author> <year> 1982. </year> <title> The Jackknife, The Bootstrap, and Other Resampling Plans, </title> <booktitle> vol. 38 of CBMS-NSF Regional Conference Series in Applied Mathematics. </booktitle> <publisher> SIAM, </publisher> <address> Philadelphia, Pennsylvania. </address>
Reference: <author> Fuller, W. A. </author> <year> 1987. </year> <title> Measurement Error Models. </title> <publisher> John Wiley, </publisher> <address> New York. </address>
Reference: <author> Gallant, A. R., P. E. Rossi and G. Tauchen. </author> <year> 1993. </year> <title> Nonlinear dynamic structures. </title> <type> Econometrica 61, </type> <pages> 871-908. </pages>
Reference: <author> Jacobs, R. A. </author> <year> 1995. </year> <title> Methods for combining experts' probability assessments. </title> <booktitle> Neural Computation 7, </booktitle> <pages> 867-888. </pages>
Reference-contexts: The main reason for this spreading is that the inputs wander off into re 11 The idea of combining of forecasts (Bates & Granger, 1969), based on the idea that superposition helps to the degree that the errors are uncorrelated, has recently reached the connectionist community, see e.g., <ref> (Jacobs, 1995) </ref>.
Reference: <author> Jacobs, R. A., M. I. Jordan, S. J. Nowlan and G. E. Hin-ton. </author> <year> 1991. </year> <title> Adaptive mixtures of local experts. </title> <booktitle> Neural Computation 3, </booktitle> <pages> 79-87. </pages>
Reference: <author> Karpov, J. M. </author> <year> 1987. </year> <title> The relation between price changes and trading volume: A survey. </title> <journal> Journal of Financial and Quantitative Analysis 22, </journal> <pages> 109-126. </pages>
Reference: <author> Kunsch, H. R. </author> <year> 1989. </year> <title> The jacknife and the bootstrap for general stationary observations. </title> <journal> Annals of Statistics 17(3), </journal> <pages> 1217-1241. </pages>
Reference: <author> LeBaron, B. </author> <year> 1992. </year> <title> Persistence of the Dow Jones index on rising volume. </title> <type> Technical report, </type> <institution> University of Wisconsin - Madison, Madison, Wisconsin. </institution>
Reference: <author> LeBaron, B. </author> <year> 1992. </year> <title> Some relations between volatility and serial correlations in stock market returns. </title> <journal> Journal of Business 65, </journal> <pages> 199-219. </pages>
Reference: <author> Liu, R. Y. and K. Singh. </author> <year> 1992. </year> <title> Moving blocks jackknife and bootstrap capture weak dependence. In Exploring the Limits of the Bootstrap, </title> <editor> R. LePage and L. </editor> <booktitle> Billard (eds), </booktitle> <pages> pp. 225-248. </pages> <publisher> John Wiley, </publisher> <address> New York, NY. </address>
Reference: <author> MacKay, D. J. C. </author> <year> 1992. </year> <title> A practical Bayesian framework for backpropagation networks. </title> <booktitle> Neural Computation 4, </booktitle> <pages> 448-472. </pages>
Reference: <author> Neal, R. </author> <year> 1996. </year> <title> Bayesian Learning for Neural Networks. </title> <booktitle> Number 118 in Lecture Notes in Statistics. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference: <author> Nix, D. A. and A. S. Weigend. </author> <year> 1995. </year> <title> Learning local error bars for nonlinear regression. </title> <booktitle> In Advances in Neural Information Processing Systems 7 (NIPS*94), </booktitle> <editor> G. Tesauro, D. S. Touretzky and T. K. Leen (eds), </editor> <booktitle> pp. </booktitle> <pages> 488-496. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Paass, G. </author> <year> 1993. </year> <title> Assessing and improving neural network predictions by the bootstrap algorithm. </title> <booktitle> In Advances in Neural Information Processing Systems 5 (NIPS*92), </booktitle> <editor> S. J. Hanson, J. D. Cowan and C. L. Giles (eds), </editor> <booktitle> pp. </booktitle> <pages> 196-203, </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Tibshirani, R. </author> <year> 1996. </year> <title> A comparison of some error estimates for neural network models. </title> <booktitle> Neural Computation 8, </booktitle> <pages> 152-163. </pages>
Reference: <author> Timmer, J. and A. S. Weigend. </author> <year> 1997. </year> <title> Modeling volatility using state space models. </title> <journal> International Journal of Neural Systems 8, forthcoming. </journal>
Reference: <author> Weigend, A. S. and A. N. Srivastava. </author> <year> 1995. </year> <title> Predicting conditional probability distributions: A connectionist approach. </title> <journal> International Journal of Neural Systems 6, </journal> <pages> 109-118. </pages>
Reference: <author> Weigend, A. S., B. A. Huberman and D. E. Rumelhart. </author> <year> 1990. </year> <title> Predicting the future: A connectionist approach. </title> <journal> International Journal of Neural Systems 1, </journal> <pages> 193-209. </pages>
Reference: <author> Weigend, A. S., B. A. Huberman and D. E. Rumelhart. </author> <year> 1992. </year> <title> Predicting sunspots and exchange rates with connectionist networks. In Nonlinear Modeling and Forecasting, </title> <editor> M. Casdagli and S. </editor> <booktitle> Eubank (eds), </booktitle> <pages> pp. 395-432. </pages> <publisher> Addison-Wesley. </publisher>
Reference: <author> Weigend, A. S., M. Mangeas and A. N. Srivastava. </author> <year> 1995. </year> <title> Nonlinear gated experts for time series: Discovering regimes and avoiding overfitting. </title> <journal> International Journal of Neural Systems 6, </journal> <pages> 373-399. </pages>
Reference: <author> Weigend, A. S., H. G. Zimmermann and R. Neuneier. </author> <year> 1996. </year> <title> Clearning. </title> <booktitle> In Neural Networks in Financial Engineering (Proceedings of the Third International Conference on Neural Networks in the Capital Markets, </booktitle> <editor> NNCM-95), A.-P. N. Refenes, Y. Abu-Mostafa, J. Moody and A. </editor> <booktitle> Weigend (eds), </booktitle> <pages> pp. 511-522, </pages> <address> Singapore. </address> <publisher> World Scientific. </publisher>
Reference: <author> Citation of this paper: LeBaron, B., and A. S. Weigend. </author> <year> 1998. </year>
References-found: 30

