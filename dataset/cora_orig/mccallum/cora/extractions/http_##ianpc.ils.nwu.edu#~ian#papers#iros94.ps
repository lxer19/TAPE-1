URL: http://ianpc.ils.nwu.edu/~ian/papers/iros94.ps
Refering-URL: http://www.ils.nwu.edu/~ian/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: ian@ai.mit.edu  
Title: Visual Collision Avoidance by Segmentation  
Author: Ian Horswill 
Address: 545 Technology Square Cambridge, MA 02139  
Affiliation: MIT Artificial Intelligence Laboratory  
Abstract: Visual collision avoidance involves two difficult subprob-lems: obstacle recognition and depth measurement. We present a class of algorithms that use particularly simple methods for each subproblem and derive a set of sufficient conditions for their proper functioning based on a set of idealizations. We then discuss and compare two different implementations of the approach and discuss their performance. Finally, we experimentally validate the idealizations. 1 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> David Coombs and Karen Roberts. "bee-bot": </author> <title> using peripheral optical flow to avoid obstacles. </title> <booktitle> In Proc. of the SPIE Conf. on Intelligent Robots and Computer Vision XI: Algorithms, Techniques, and Active Vision, </booktitle> <address> (Boston, MA, </address> <month> November 15-20, </month> <year> 1992), 1992. </year>
Reference-contexts: The stereo algorithm of Storjohann et al. [12] is similar, but does not require the presence of vertical edges, only some sort of texture. The motion-based systems of Coombs and Roberts <ref> [1] </ref> and of Sandini et al. [11] also make these assumptions. Each system is compatible with a particular class of obstacles and incompatible with another.
Reference: [2] <author> James E. </author> <title> Cutting. Perception with an Eye for Motion. </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: Call this the "figure/ground" image. It has been known at least since Euclid (see Cutting <ref> [2] </ref>) that for points projected from a ground plane, image plane height is a strictly increasing function of distance.
Reference: [3] <author> Andrew S. Gavin and Masaki Yamamoto. </author> <title> A fast, cheap, and easy system for outside vision on mars. </title> <booktitle> In Intelligent Robots and Computer Vision XI, </booktitle> <address> Cam-bridge, MA, </address> <month> September </month> <year> 1993. </year> <pages> SPIE. </pages>
Reference-contexts: It is much more robust, both mechanically and electrically, than Polly. Image acquisition is performed by directly interfacing a CCD image sensor to the processor bus by way of an A/D converter (see Gavin and Yamamoto <ref> [3] </ref>, Horswill and Yamamoto [7]). The CCD is mounted on a pan/tilt head built from Futaba model airplane servo motors. The complete vision system costs roughly $700 US. The Frankie version of the collision avoidance algorithm has been modified to take advantage of the pan/tilt head.
Reference: [4] <author> Takashi Gomi and Koh ichi Ide. </author> <title> Vision based navigation for an office messenger robot. </title> <booktitle> In submission, </booktitle> <month> January </month> <year> 1994. </year>
Reference-contexts: We have implemented the algorithm on three different robots here at MIT. The algorithm has also been implemented and tested at another lab by Gomi and Ide <ref> [4] </ref>. The algorithm is quite robust and has seen hundreds of hours of testing in many different environments. The next section describes the edge-based algorithm. <p> The most recent is due to Gomi and Ide <ref> [4] </ref>. The other implementations have been done at MIT (see table 1). The first implementation was part of a vision-based mobile robot called Polly (Horswill [5][6]). Polly uses vision to seek out visitors and give them primitive tours of our laboratory.
Reference: [5] <author> Ian Horswill. Polly: </author> <title> A vision-based artificial agent. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 824-829. </pages> <publisher> AAAI, MIT Press, </publisher> <year> 1993. </year>
Reference: [6] <author> Ian Horswill. </author> <title> Specialization of perceptual processes. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <address> Cambridge, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: The interested reader is referred to the proofs of lemma 3 and theorem 2 in <ref> [6] </ref>. We can represent the perfect-information system schematically as follows: image ) oracle ! l; r; c ! velocity eqs ! dt An image is fed to an oracle that somehow determines for each direction the distance to the closest object in that direction. <p> The GPC requires that all obstacles rest on the ground plane and that their projections be contained within the interiors of their regions of contact with the ground plane (see <ref> [6] </ref>). To complete the transformation of the distance oracle algorithm into the section 2 algorithm, we need only replace the figure/ground oracle with an edge detector. We would like justify this substitution and to know what constraints there are on the choice of edge detector. <p> Cost, weight and power refer only to the vision system, not to the base or power supply. The Frankie frame rate is variable because of varying CCD integration times. details of these other algorithms are outside the scope of this paper. See <ref> [6] </ref> for further information. Frankie is an on-going robot project based on new-generation hardware. At present, only the collision avoidance algorithm has been implemented on Frankie, although we intend to port the rest of the Polly system and add a number of new features. <p> If the sum is greater than a threshold (15 grey levels out of a possible 510 on Polly, 22 grey levels for Frankie which has more camera noise). The Polly system is described in detail in <ref> [6] </ref>. The important parts of the code for the Frankie system are given in section 6. 5 Evaluation The algorithm has been thoroughly tested, having seen many hundreds of hours of service.
Reference: [7] <author> Ian Horswill and Masaki Yamamoto. </author> <title> A $1000 active stereo vision system. </title> <note> In Submitted to CVPR-94, </note> <year> 1994. </year>
Reference-contexts: It is much more robust, both mechanically and electrically, than Polly. Image acquisition is performed by directly interfacing a CCD image sensor to the processor bus by way of an A/D converter (see Gavin and Yamamoto [3], Horswill and Yamamoto <ref> [7] </ref>). The CCD is mounted on a pan/tilt head built from Futaba model airplane servo motors. The complete vision system costs roughly $700 US. The Frankie version of the collision avoidance algorithm has been modified to take advantage of the pan/tilt head.
Reference: [8] <author> David J. Kriegman, Ernst Triendl, and Tomas O. Binford. </author> <title> A mobile robot: Sensing, planning and locomotion. </title> <booktitle> In 1987 IEEE Internation Conference on Robotics and Automation, </booktitle> <pages> pages 402-408. </pages> <publisher> IEEE, </publisher> <month> March 87. </month>
Reference-contexts: Different algorithms can be seen as embodying different assumptions about the appearance of obstacles. Moravec's Stanford Cart [10] can be seen as assuming that obstacles (1) project significantly from the ground plane and (2) are densely covered with visual corners. Kriegman, Triendl and Binford's Mobi system <ref> [8] </ref> can be seen as assuming that obstacles (1) have at least a certain height and (2) have vertical edges around their perimeters. The stereo algorithm of Storjohann et al. [12] is similar, but does not require the presence of vertical edges, only some sort of texture.
Reference: [9] <author> David Marr. </author> <title> Vision. </title> <editor> W. H. </editor> <publisher> Freeman and Co., </publisher> <year> 1982. </year>
Reference-contexts: However, it is a hack which has been demonstrated to operate in a larger number of environments than any other vision-based robot of which we are aware. In addition, nearly any vision system will make some set of assumptions about its environment (see Marr <ref> [9] </ref> for the canonical discussion of this point). A stereo or motion system, for example, requires the presence of texture not only on the obstacles, but on the floors and walls also, at least if it is to make accurate depth readings there.
Reference: [10] <author> Hans P. Moravec. </author> <title> The stanford cart and cmu rover. </title> <type> Technical report, </type> <institution> Robotics Institute, Carnegie-Mellon University, </institution> <month> February </month> <year> 1983. </year>
Reference-contexts: 1 Introduction One of the major difficulties of visual obstacle avoidance is that obstacles can seemingly have arbitrary appearance. They can be tall or fat, plain or textured, rigid or flexible. Different algorithms can be seen as embodying different assumptions about the appearance of obstacles. Moravec's Stanford Cart <ref> [10] </ref> can be seen as assuming that obstacles (1) project significantly from the ground plane and (2) are densely covered with visual corners.
Reference: [11] <author> G. Sandini, F. Gandolfo, E. Grosso, and M. Tistarelli. </author> <title> Vision during action. </title> <editor> In Yiannis Aloimonos, editor, </editor> <title> Active Perception, </title> <booktitle> chapter 4, </booktitle> <pages> pages 151-190. </pages> <publisher> Lawrence Erlbaum Associates, Inc., </publisher> <year> 1993. </year>
Reference-contexts: The stereo algorithm of Storjohann et al. [12] is similar, but does not require the presence of vertical edges, only some sort of texture. The motion-based systems of Coombs and Roberts [1] and of Sandini et al. <ref> [11] </ref> also make these assumptions. Each system is compatible with a particular class of obstacles and incompatible with another.
Reference: [12] <author> K. Storjohann, T. Zeilke, H. A. Mallot, and W. von Seelen. </author> <title> Visual obstacle detection for automatically guided vehicles. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 761-766, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Kriegman, Triendl and Binford's Mobi system [8] can be seen as assuming that obstacles (1) have at least a certain height and (2) have vertical edges around their perimeters. The stereo algorithm of Storjohann et al. <ref> [12] </ref> is similar, but does not require the presence of vertical edges, only some sort of texture. The motion-based systems of Coombs and Roberts [1] and of Sandini et al. [11] also make these assumptions. Each system is compatible with a particular class of obstacles and incompatible with another.
Reference: [13] <author> Michael J. Swain. </author> <title> Color indexing. </title> <type> Technical Report 390, </type> <institution> University of Rochester Computer Science Department, </institution> <month> November </month> <year> 1990. </year>
Reference-contexts: One can easily imagine other algorithms using other cues (e.g. color or scale) in other contexts. To change the cue, one need only change the final substitution in the analysis given in section 3. For example, one could substitute a color-based identification system (e.g. Swain <ref> [13] </ref>) for the edge detector: ) color ! bproj ! l; r; c ! vel. eqs ! if the BTC didn't hold of the environment but the floor could be relied on to have a predictable color.
References-found: 13

