URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1992/tr-92-012.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1992.html
Root-URL: http://www.icsi.berkeley.edu
Title: Towards a Complexity Theory for Approximation  
Author: Karl Aberer and Bruno Codenotti 
Address: Pisa (ITALY).  
Affiliation: Sistemi Informatici e Calcolo  
Note: The work of Bruno Codenotti was partially supported by the Italian National Research Council under the "Progetto Finalizzato  Parallelo, Sottoprogetto 2". Bruno Codenotti is on leave from IEI-CNR,  
Pubnum: TR-92-012  
Email: email: aberer@icsi.berkeley.edu email: brunoc@icsi.berkeley.edu  
Date: February 1992  
Abstract: This paper presents a novel approach to the analysis of numerical problems, which is closely related to the actual nature of numerical algorithms. In fact, models of computation are introduced which take into account such issues as adaptivity and error. Moreover, complexity vs error bounds and examples regarding the role of adaptivity are provided. Finally, it is shown that the overall approach fits naturally into an algebraic framework. 
Abstract-found: 1
Intro-found: 1
Reference: [Aberer, 1991] <author> Aberer, K. </author> <year> (1991). </year> <title> Combinatory Differential Fields and Constructive Analysis. </title> <journal> ETH-Thesis, </journal> <volume> 9357. </volume>
Reference-contexts: Among these where conditional functions, approximations and recursion. In this section we show how these concepts fit naturally in the framework of combinatory differential fields. <ref> [Aberer, 1991] </ref> 5.1 Representation Let us assume that a structure, e.g., IR, is given. To be more precise, we have to distinguish between the domain (e.g., IN) and the structure (e.g., &lt; IN; +; 0 &gt; or &lt; IN; +; fl; 0; 1 &gt;).
Reference: [Aberer & Codenotti, 1991A] <author> Aberer, K., Codenotti, B. </author> <year> (1991). </year> <title> Towards a Complexity Theory of Approximation. </title> <note> manuscript submitted for publication. </note>
Reference: [Aberer & Codenotti, 1991B] <author> Aberer, K., Codenotti, B. </author> <year> (1991). </year> <title> Efficiency in Numerical Analysis: Oblivious versus Adaptive Algorithms. </title> <note> manuscript submitted for publication. </note>
Reference: [Ajtai et al., 1983] <author> Ajtai, M., Komlos, J., Szemerdedi, E., </author> <year> (1983). </year> <title> An O(n log n) Sorting Network. </title> <booktitle> Proc. of 15th Annual ACM Symp. on Theory of Computing, </booktitle> <pages> pp. 133-139. </pages>
Reference-contexts: All the O (log n) time parallel algorithms for sorting using only comparators are not work-optimal [Borodin & Hopcroft, 1985]. On the other hand, the two work-optimal known algorithms need to encode input data into specific data-structures <ref> [Ajtai et al., 1983, Cole, 1986] </ref>. 8 The model we describe here (see Figure 6), consists of building blocks corresponding to the following three phases: 1. Encoding: Some discrete information is extracted from the input and transferred to a discrete computation which represents the combinatorial stage. 2.
Reference: [Blum et al., 1989] <author> Blum, L., Shub, M., Smale, S. </author> <year> (1989). </year> <title> On a Theory of Computation and Complexity over the Real Numbers: NP-Completeness. Recursive Functions and Universal Machines, </title> <journal> Bulletin of AMS, </journal> <volume> Vol. 21, No. 1, </volume> <pages> pp 1-36. </pages>
Reference-contexts: Some were oriented toward quantifying the cost of computing up to a given accuracy [Traub et al., 1988]; some others were directed to extending combinatorial notions (e.g., NP-completeness) to problems defined on continuous structures <ref> [Blum et al., 1989] </ref>. Other theories have led to an information-theoretic view of computations [Chaitin, 1987]. Finally, several trials were oriented to evaluate the bit-complexity of problems, i.e. the number of bit-operations necessary to compute up to a given accuracy (see, e.g., [Brent, 1976]). <p> These issues are analyzed in Section 4, mainly by proposing several interesting case studies. The investigation of Section 4 takes some motivations from [Smale, 1990], and has strong connections to [Traub et al., 1988], <ref> [Blum et al., 1989] </ref> and [Codenotti et al., 1991]. The above discussion puts also into evidence that there is a need for a suitable language for computing with approximation. This issue is the topic of Section 5. 3 Summarizing, the rest of this paper is organized as follows.
Reference: [Borodin & Hopcroft, 1985] <author> Borodin, A., Hopcroft, J.. </author> <year> (1985). </year> <title> Routing, Merging and Sorting on Parallel Models of Computation. </title> <booktitle> Proc. of 14th Annual ACM Symp. on Theory of Computing, </booktitle> <pages> pp. 338-344. </pages>
Reference-contexts: The need for such a model comes out from several arguments. As an example, consider the typical case in which adaptivity leads to sorting. All the O (log n) time parallel algorithms for sorting using only comparators are not work-optimal <ref> [Borodin & Hopcroft, 1985] </ref>. On the other hand, the two work-optimal known algorithms need to encode input data into specific data-structures [Ajtai et al., 1983, Cole, 1986]. 8 The model we describe here (see Figure 6), consists of building blocks corresponding to the following three phases: 1.
Reference: [Brent, 1976] <author> Brent, R.P., </author> <year> (1976). </year> <title> Fast Multiple-Precision Evaluation of Elementary Functions. </title> <journal> Journal of ACM, </journal> <volume> Vol. 23, No. 2, </volume> <pages> pp 242-251. </pages>
Reference-contexts: Other theories have led to an information-theoretic view of computations [Chaitin, 1987]. Finally, several trials were oriented to evaluate the bit-complexity of problems, i.e. the number of bit-operations necessary to compute up to a given accuracy (see, e.g., <ref> [Brent, 1976] </ref>). From the result in [Cai, Hartmanis, 1989], where it is proved that the Kolmogorov complexity of the real line is a fractal, the following observations naturally follow: (i) from a computational viewpoint, the representation of real numbers is a very intriguing issue; (ii) real numbers are computationally different. <p> Nevertheless, in Figure 11 on page 22, a situation is depicted where, besides the expected perturbation error, an additional unavoidable error occurs. This is exactly the error we have introduced in Section 3 as representation error. Case Study 2. Note that in <ref> [Brent, 1976] </ref> the phenomenon of representation error was incidentally discovered. In fact, it was observed that an algorithm for the computation of n digits of in O (t) steps needed to work with extra O (log t) digits.
Reference: [Cai, Hartmanis, 1989] <author> Cai, J., Hartmanis, J., </author> <year> (1989). </year> <title> The Complexity of the Real Line is a Fractal. </title> <booktitle> Proceedings Fourth Annual Conference on Structure in Complexity Theory, </booktitle> <pages> p 138-146. </pages>
Reference-contexts: Other theories have led to an information-theoretic view of computations [Chaitin, 1987]. Finally, several trials were oriented to evaluate the bit-complexity of problems, i.e. the number of bit-operations necessary to compute up to a given accuracy (see, e.g., [Brent, 1976]). From the result in <ref> [Cai, Hartmanis, 1989] </ref>, where it is proved that the Kolmogorov complexity of the real line is a fractal, the following observations naturally follow: (i) from a computational viewpoint, the representation of real numbers is a very intriguing issue; (ii) real numbers are computationally different.
Reference: [Chaitin, 1987] <author> Chaitin, G. J., </author> <year> (1987). </year> <title> Information, Randomness and Incompleteness. </title> <publisher> World Scientific. </publisher>
Reference-contexts: Some were oriented toward quantifying the cost of computing up to a given accuracy [Traub et al., 1988]; some others were directed to extending combinatorial notions (e.g., NP-completeness) to problems defined on continuous structures [Blum et al., 1989]. Other theories have led to an information-theoretic view of computations <ref> [Chaitin, 1987] </ref>. Finally, several trials were oriented to evaluate the bit-complexity of problems, i.e. the number of bit-operations necessary to compute up to a given accuracy (see, e.g., [Brent, 1976]).
Reference: [Codenotti et al., 1991] <author> Codenotti, B., Leoncini, M., Resta, E. </author> <year> (1991). </year> <title> Oracle Computations in Parallel Numerical Linear Algebra. </title> <type> TR ICSI 91-060. </type>
Reference-contexts: A drawback of this situation is the following: when one tries to turn algorithms developed for the algebraic complexity framework into concrete algorithms, e.g., to be run on finite machines, then many computational obstacles come into play (see, for example, <ref> [Codenotti et al., 1991] </ref>). We face this problem by proposing a framework in which both the numerical analysis and computation theory approaches would fit, and show a number of results strongly relating complexity and accuracy (Section 3). <p> These issues are analyzed in Section 4, mainly by proposing several interesting case studies. The investigation of Section 4 takes some motivations from [Smale, 1990], and has strong connections to [Traub et al., 1988], [Blum et al., 1989] and <ref> [Codenotti et al., 1991] </ref>. The above discussion puts also into evidence that there is a need for a suitable language for computing with approximation. This issue is the topic of Section 5. 3 Summarizing, the rest of this paper is organized as follows. Section 2 introduces the models of computation. <p> Consequently, the arithmetic operations have also to be extended to this more general domain. In the model of Section 2.1, this leads to the notion of an approximating circuit, taking approximations as inputs and returning approximations as outputs. (For a definition of approximating circuits see <ref> [Codenotti et al., 1991] </ref>.) In the functional model we have to consider expressions which take such approximations as inputs and return approximations as output, e.g., these expressions are of the form T (X 1 ; : : : ; X k ): In Section 5 we describe an algebraic model, which <p> To be able to solve classes of problems of the form I = S k2IN I k , we have to deal with the notion of uniformity <ref> [Codenotti et al., 1991] </ref>. For this purpose we consider the specific programs for size k as the output of a universal program for the problem which takes as input only the problem size k. Then the computation proceeds as shown above for fixed input size. <p> Therefore we adopt the following strategy, which is based on the adversary argument (a similar approach can be found in <ref> [Codenotti et al., 1991] </ref>). We assume an adversary can decide about the input distribution, so that the representation error is the roundoff error, associated to the given instance, by using the most accurate algorithm.
Reference: [Codenotti & Leoncini, 1991] <author> Codenotti, B., Leoncini , M., </author> <year> (1991). </year> <title> Parallel Complexity of Linear System Solution. </title> <publisher> World Scientific. </publisher>
Reference-contexts: This result shows that it is unlikely (i.e., unless P = N C) that Gaussian elimination with pivoting has an N C implementation. Since the basic Gaussian elimination process can be parallelized (see <ref> [Codenotti & Leoncini, 1991] </ref>), it follows that adaptivity, in this case, translates into a difficulty to parallelize. From the above discussion, it follows that three basic strategies with different features can be adopted to perform Gaussian elimination (see also Example 2). 1. Oblivious algorithm: perform the elimination.
Reference: [Cole, 1986] <author> Cole, R., </author> <year> (1986). </year> <title> Parallel Merge Sort. </title> <booktitle> 27th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 511-516. </pages> <note> [Csanky, 1976] , Csanky, </note> <author> L., </author> <year> (1976). </year> <title> Fast Parallel Matrix Inversion Algorithms. </title> <journal> SIAM J. Comput., </journal> <pages> pp 117-122. </pages> <note> [Demmel, 1984] , Demmel, J., </note> <year> (1984). </year> <title> Underflow and the Reliability of Numerical Software. </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> Vol. 5, No. </volume> <pages> 4. </pages>
Reference-contexts: All the O (log n) time parallel algorithms for sorting using only comparators are not work-optimal [Borodin & Hopcroft, 1985]. On the other hand, the two work-optimal known algorithms need to encode input data into specific data-structures <ref> [Ajtai et al., 1983, Cole, 1986] </ref>. 8 The model we describe here (see Figure 6), consists of building blocks corresponding to the following three phases: 1. Encoding: Some discrete information is extracted from the input and transferred to a discrete computation which represents the combinatorial stage. 2.
Reference: [Engeler, 1981A] <author> Engeler, E., </author> <year> (1981). </year> <editor> Metamathematik der Elementarmathematik. </editor> <publisher> Springer Verlag. </publisher>
Reference: [Engeler, 1990] <author> Engeler, E. </author> <year> (1990). </year> <title> Combinatory Differential Fields. </title> <booktitle> Theoretical Computer Science 72, </booktitle> <pages> 119-131. </pages>
Reference: [Kaplansky, 1957] <author> Kaplansky, I. </author> <year> (1957). </year> <title> An Introduction to Differential Algebra. </title> <publisher> Paris: Hermann. </publisher>
Reference: [Smale, 1990] <author> Smale, S., </author> <year> (1990)., </year> <title> Some Remarks on the Foundation of Numerical Analysis. </title> <journal> SIAM Review, </journal> <volume> Vol. 32, No. 2, </volume> <pages> pp 211-220. </pages>
Reference-contexts: 1 Introduction There is a lack of understanding among different scientific communities working on numerical problems from different viewpoints. The main conflict, reported for example in <ref> [Smale, 1990] </ref>, is between numerical analysis and computer science. Numerical analysis is essentially concerned with computing with fixed-precision numbers intended to be approximations of real numbers. <p> These properties deeply reflect in this paper, where we find evidence of the non straightforward nature of approximating and computing with approximations. On a different side, in <ref> [Smale, 1990] </ref>, several questions of fundamental importance are addressed. <p> Our opinion is that quantitative answers to these last questions would give a new insight into the design and analysis of numerical computations. These issues are analyzed in Section 4, mainly by proposing several interesting case studies. The investigation of Section 4 takes some motivations from <ref> [Smale, 1990] </ref>, and has strong connections to [Traub et al., 1988], [Blum et al., 1989] and [Codenotti et al., 1991]. The above discussion puts also into evidence that there is a need for a suitable language for computing with approximation.
Reference: [Traub et al., 1988] <author> Traub, J.F., Wasilkowski G.W., Wozniakowski H., </author> <year> (1988). </year> <title> Information Based Complexity. </title> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference-contexts: Many authors have tried to capture the many features of numerical problems, using different models and theories. Some were oriented toward quantifying the cost of computing up to a given accuracy <ref> [Traub et al., 1988] </ref>; some others were directed to extending combinatorial notions (e.g., NP-completeness) to problems defined on continuous structures [Blum et al., 1989]. Other theories have led to an information-theoretic view of computations [Chaitin, 1987]. <p> These issues are analyzed in Section 4, mainly by proposing several interesting case studies. The investigation of Section 4 takes some motivations from [Smale, 1990], and has strong connections to <ref> [Traub et al., 1988] </ref>, [Blum et al., 1989] and [Codenotti et al., 1991]. The above discussion puts also into evidence that there is a need for a suitable language for computing with approximation.
Reference: [Vavasis, 1989] <author> Vavasis, S., </author> <year> (1989). </year> <title> Gaussian Elimination with Pivoting is P-Complete. </title> <journal> SIAM J. Disc. Math., </journal> <volume> Vol. 2, No.3, </volume> <pages> pp. 413-423. </pages>
Reference-contexts: The on-line adaptive algorithm finds, at the i-th stage, by knowing the ordering information of intermediate numerical data, the optimal pivot for eliminating the i-th column. This approach is known as Gaussian elimination with pivoting <ref> [Vavasis, 1989] </ref>. 3. The purely numerical algorithm simply performs Gaussian elimination on the original input matrix. 5 To describe the cost of a computation we adopt the natural measures associated to the above described models. <p> Thus Gaussian elimination is usually accomplished in combination with a "searching strategy", called pivoting 14 which consists of finding a permutation matrix which allows to continue the elimination or, more in general, to perform a numerically stable elimination. 14 We should distinguish between partial and total pivoting (see, e.g. <ref> [Vavasis, 1989] </ref>). 23 Gaussian elimination with pivoting is a classical example of how adaptivity can be used to avoid large errors. A quantitative analysis of the advantages of such an approach can be found in [Wilkinson, 1963]. <p> On the other hand, the "combinatorial" work needed to seek the pivot leads to a computational overhead. This extra work is asymptotically negligible in sequential models of computation, but increases the parallel time by an O (log n) factor. More fundamentally, it has been proved by Vavasis <ref> [Vavasis, 1989] </ref> that Gaussian elimination with pivoting is P -complete. This result shows that it is unlikely (i.e., unless P = N C) that Gaussian elimination with pivoting has an N C implementation.
Reference: [Wilkinson, 1963] <author> Wilkinson, J.H., </author> <year> (1963). </year> <title> Rounding Errors in Algebraic Processes. </title> <publisher> Prentice-Hall, </publisher> <address> Engle-wood Cliffs, NJ. </address> <month> 38 </month>
Reference-contexts: A quantitative analysis of the advantages of such an approach can be found in <ref> [Wilkinson, 1963] </ref>. On the other hand, the "combinatorial" work needed to seek the pivot leads to a computational overhead. This extra work is asymptotically negligible in sequential models of computation, but increases the parallel time by an O (log n) factor.
References-found: 19

