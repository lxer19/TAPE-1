URL: http://www.almaden.ibm.com/cs/quest/papers/edbt96_sliq.ps
Refering-URL: http://www.almaden.ibm.com/cs/quest/publications.html
Root-URL: 
Title: SLIQ: A Fast Scalable Classifier for Data Mining  
Author: Manish Mehta, Rakesh Agrawal and Jorma Rissanen 
Address: 650 Harry Road, San Jose, CA 95120  
Affiliation: IBM Almaden Research Center  
Abstract: Classification is an important problem in the emerging field of data mining. Although classification has been studied extensively in the past, most of the classification algorithms are designed only for memory-resident data, thus limiting their suitability for data mining large data sets. This paper discusses issues in building a scalable classifier and presents the design of SLIQ 1 , a new classifier. SLIQ is a decision tree classifier that can handle both numeric and categorical attributes. It uses a novel pre-sorting technique in the tree-growth phase. This sorting procedure is integrated with a breadth-first tree growing strategy to enable classification of disk-resident datasets. SLIQ also uses a new tree-pruning algorithm that is inexpensive, and results in compact and accurate trees. The combination of these techniques enables SLIQ to scale for large data sets and classify data sets irrespective of the number of classes, attributes, and examples (records), thus making it an attractive tool for data mining.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> R. Agrawal, T. Imielinski, and A. Swami. </author> <title> Database mining: A performance perspective. </title> <journal> IEEE Trans. on Knowledge and Data Engineering, </journal> <volume> 5(6), </volume> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: The recent emergence of Data Mining, or Knowledge Discovery in Databases, is a testimony to this trend. Data mining involves the development of tools that can extract patterns from large data bases. Classification is an important data mining problem <ref> [1] </ref> and can be described as follows. The input data, also called the training set, consists of multiple examples (records), each having multiple attributes or features. Additionally, each example is tagged with a special class label. <p> Table 1 summarizes the important parameters of this benchmark. The second part of the performance evaluation examines SLIQ's performance on disk-resident data. In the absence of a benchmark with large classification datasets, we used the evaluation methodology and synthetic databases proposed in <ref> [1] </ref>. Each tuple in these databases has nine attributes. Ten classification functions were used in [1] to produce data distributions of varying complexities. <p> The second part of the performance evaluation examines SLIQ's performance on disk-resident data. In the absence of a benchmark with large classification datasets, we used the evaluation methodology and synthetic databases proposed in <ref> [1] </ref>. Each tuple in these databases has nine attributes. Ten classification functions were used in [1] to produce data distributions of varying complexities.
Reference: 2. <author> J. Catlett. </author> <title> Megainduction: Machine Learning on Very Large Databases. </title> <type> PhD thesis, </type> <institution> University of Sydney, </institution> <year> 1991. </year>
Reference-contexts: Fig. 1. Example of a decision tree The idea of modifying tree classifiers to enable them to classify large datasets has been explored previously. Previous proposal include sampling of data at each decision tree node <ref> [2] </ref>, and discretization of numeric attributes [2]. These methods decrease classification time significantly but also reduce the classification accuracy. Chan and Stolfo [3] have studied the method of partitioning the input data and then building a classifier for each partition. <p> Fig. 1. Example of a decision tree The idea of modifying tree classifiers to enable them to classify large datasets has been explored previously. Previous proposal include sampling of data at each decision tree node <ref> [2] </ref>, and discretization of numeric attributes [2]. These methods decrease classification time significantly but also reduce the classification accuracy. Chan and Stolfo [3] have studied the method of partitioning the input data and then building a classifier for each partition. The outputs of the multiple classifiers are then combined to get the final classification. <p> The combination of these techniques enables SLIQ to scale for large data sets and classify data sets with a large number of classes, attributes, and examples. 4.2 Pre-Sorting and Breadth-First Growth For numeric attributes, sorting time is the dominant factor when finding the best split at a decision tree node <ref> [2] </ref>. Therefore, the first technique used in SLIQ is to implement a scheme that eliminates the need to sort the data at each node of the decision tree. Instead, the training data are sorted just once for each numeric attribute at the beginning of the tree growth phase.
Reference: 3. <author> P. K. Chan and S. J. Stolfo. </author> <title> Meta-learning for multistrategy and parallel learning. </title> <booktitle> In Proc. Second Intl. Workshop on Multistrategy Learning, </booktitle> <pages> pages 150-165, </pages> <year> 1993. </year>
Reference-contexts: Previous proposal include sampling of data at each decision tree node [2], and discretization of numeric attributes [2]. These methods decrease classification time significantly but also reduce the classification accuracy. Chan and Stolfo <ref> [3] </ref> have studied the method of partitioning the input data and then building a classifier for each partition. The outputs of the multiple classifiers are then combined to get the final classification.
Reference: 4. <author> L. Breiman et. al. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <address> Belmont, </address> <year> 1984. </year>
Reference-contexts: Section 2 describes a generic decision tree classifier and Section 3 discusses scalability issues. Sections 4 and 5 present the design and a detailed performance analysis of SLIQ, respectively. Finally, Section 6 contains our conclusions. 2 Decision-Tree Classification Most decision-tree classifiers (e.g. CART <ref> [4] </ref>, C4.5 [10]) perform classification in two phases: Tree Building and Tree Pruning. Tree Building An initial decision tree is grown in this phase by repeatedly partitioning the training data. The training set is split into two or more partitions using an attribute 2 . <p> Having determined the overall best split, partitions can be created by a simple application of the splitting criterion to the data. The 2 Multivariate splits based on values of multiple attributes have also been proposed <ref> [4] </ref>. complexity lies in determining the best split for each attribute. The choice of the splitting criterion depends on the domain of the attribute being numeric or categorical (attributes with a finite discrete set of possible values). <p> Several splitting indices have been proposed in the past [13]. We use the gini index, originally proposed in <ref> [4] </ref>. <p> There are two main approaches to estimating the error rate: one using the original training dataset and the other using an independent dataset for error estimation. Cross-validation <ref> [4] </ref> belongs to the first category. Multiple samples are taken from the training data and a tree is grown for each sample. These multiple trees are then used to estimate the error rates of the subtrees of the original tree. <p> The first part compares SLIQ with the classifiers provided with the IND classifier package [8]. The IND package implements two of the most popular decision tree classifiers: CART <ref> [4] </ref> and C4 (a predecessor of C4.5 [10]). These implementations are henceforth referred to as IND-Cart and IND-C4. Since the IND classifiers handle only datasets that fit in memory, the comparison used datasets from the STATLOG classification benchmark [7]. Table 1 summarizes the important parameters of this benchmark.
Reference: 5. <author> R. Agrawal et. al. </author> <title> An interval classifier for database mining applications. </title> <booktitle> In Proc. of the VLDB Conf., </booktitle> <address> Vancouver, British Columbia, Canada, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: In many applications, there were simply not many training examples available. As a matter of fact, the largest dataset in the Irvine Machine Learning repositary is only 700KB with 20000 examples. Even in <ref> [5] </ref>, a classifier built with database considerations, the size of the training set was overlooked. Instead, the focus was on building a classifier that can use database indices to improve the retrieval efficiency while classifying test data. <p> Methods like neural networks can have extremely long training times even for small datasets. A decision tree can be converted into simple and easy to understand classification rules [10]. They can also be converted into SQL queries for accessing databases <ref> [5] </ref>. Finally, tree classifiers obtain similar and sometimes better accuracy when compared with other classification methods [7]. Figure 1 gives an example of a decision tree classifier for a toy dataset of six examples. Fig. 1.
Reference: 6. <author> M. Mehta, J. Rissanen, and R. Agrawal. </author> <title> MDL-based decision tree pruning. </title> <booktitle> In Int'l Conf. on Knowledge Discovery in Databases and Data Mining (KDD-95), </booktitle> <address> Montreal, Canada, </address> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: The objective of MDL pruning is to find the subtree of T that best describes the training set S. Earlier applications of the MDL principle to tree pruning [9][12] showed that the resultant trees were "over-pruned", causing a decrease in the classification accuracy. In <ref> [6] </ref>, an alternative application of MDL was presented that yielded small trees without sacrificing accuracy. However, the pruning algorithm in [6] was limited; it either pruned all or none of the children of a node in the decision tree. <p> Earlier applications of the MDL principle to tree pruning [9][12] showed that the resultant trees were "over-pruned", causing a decrease in the classification accuracy. In <ref> [6] </ref>, an alternative application of MDL was presented that yielded small trees without sacrificing accuracy. However, the pruning algorithm in [6] was limited; it either pruned all or none of the children of a node in the decision tree. We present a new algorithm that is able to prune a subset of the children at each node and thus subsumes the previous algorithm. <p> C 0 (t i ) repre sents the cost of encoding the children's examples using the parent's statistics. We consider three pruning strategies: 1. Full: This strategy, first presented in <ref> [6] </ref>, considers only options (1) and (2). If C leaf (t) is smaller than C both (t) for a node t then both the children are pruned and the node is converted into a leaf. This approach codes the decision tree using only one bit (method Code 1 ). 2.
Reference: 7. <author> D. Michie, D. J. Spiegelhalter, and C. C. Taylor. </author> <title> Machine Learning, Neural and Statistical Classification. </title> <publisher> Ellis Horwood, </publisher> <year> 1994. </year>
Reference-contexts: A decision tree can be converted into simple and easy to understand classification rules [10]. They can also be converted into SQL queries for accessing databases [5]. Finally, tree classifiers obtain similar and sometimes better accuracy when compared with other classification methods <ref> [7] </ref>. Figure 1 gives an example of a decision tree classifier for a toy dataset of six examples. Fig. 1. Example of a decision tree The idea of modifying tree classifiers to enable them to classify large datasets has been explored previously. <p> These implementations are henceforth referred to as IND-Cart and IND-C4. Since the IND classifiers handle only datasets that fit in memory, the comparison used datasets from the STATLOG classification benchmark <ref> [7] </ref>. Table 1 summarizes the important parameters of this benchmark. The second part of the performance evaluation examines SLIQ's performance on disk-resident data. In the absence of a benchmark with large classification datasets, we used the evaluation methodology and synthetic databases proposed in [1].
Reference: 8. <institution> NASA Ames Res. Ctr. </institution> <note> Intro. to IND Version 2.1, GA23-2475-02 edition, </note> <year> 1992. </year>
Reference-contexts: SLIQ uses a hybrid approach to overcome this issue. If the cardinality of S is less than a threshold, MAXSETSIZE, then all of the subsets of S are evaluated 3 . Otherwise, a greedy algorithm (initially proposed for IND <ref> [8] </ref>) is used to obtain the desired subset. The greedy algorithm starts with an empty subset S 0 adds that one element of S to S 0 which gives the best split. The process is repeated until there is no improvement in the splits. <p> The ideal goal for a classifier is to produce compact, accurate trees in a short time. 5.2 Experimental Setup The performance evaluation of SLIQ was divided into two parts. The first part compares SLIQ with the classifiers provided with the IND classifier package <ref> [8] </ref>. The IND package implements two of the most popular decision tree classifiers: CART [4] and C4 (a predecessor of C4.5 [10]). These implementations are henceforth referred to as IND-Cart and IND-C4.
Reference: 9. <author> J. R. Quinlan and R. L. Rivest. </author> <title> Inferring decision trees using minimum description length principle. </title> <booktitle> Information and Computation, </booktitle> <year> 1989. </year>
Reference: 10. <author> J. Ross Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufman, </publisher> <year> 1993. </year>
Reference-contexts: large data sets, we focus mainly on decision tree classifiers [4]<ref> [10] </ref>. Decision tree classifiers are relatively fast compared to other classification methods. Methods like neural networks can have extremely long training times even for small datasets. A decision tree can be converted into simple and easy to understand classification rules [10]. They can also be converted into SQL queries for accessing databases [5]. Finally, tree classifiers obtain similar and sometimes better accuracy when compared with other classification methods [7]. Figure 1 gives an example of a decision tree classifier for a toy dataset of six examples. Fig. 1. <p> Section 2 describes a generic decision tree classifier and Section 3 discusses scalability issues. Sections 4 and 5 present the design and a detailed performance analysis of SLIQ, respectively. Finally, Section 6 contains our conclusions. 2 Decision-Tree Classification Most decision-tree classifiers (e.g. CART [4], C4.5 <ref> [10] </ref>) perform classification in two phases: Tree Building and Tree Pruning. Tree Building An initial decision tree is grown in this phase by repeatedly partitioning the training data. The training set is split into two or more partitions using an attribute 2 . <p> These multiple trees are then used to estimate the error rates of the subtrees of the original tree. Although this approach selects compact trees with high accuracies, it is inapplicable for large data sets, where building even one decision tree is expensive. Alternative approaches <ref> [10] </ref> that use only a single decision tree often lead to large decision trees. The second class of methods divide the training data into two parts where one part is used to build the tree and the other for pruning the tree. <p> The first part compares SLIQ with the classifiers provided with the IND classifier package [8]. The IND package implements two of the most popular decision tree classifiers: CART [4] and C4 (a predecessor of C4.5 <ref> [10] </ref>). These implementations are henceforth referred to as IND-Cart and IND-C4. Since the IND classifiers handle only datasets that fit in memory, the comparison used datasets from the STATLOG classification benchmark [7]. Table 1 summarizes the important parameters of this benchmark.
Reference: 11. <author> J. Rissanen. </author> <title> Stochastic Complexity in Statistical Inquiry. </title> <publisher> World Scientific Publ. Co., </publisher> <year> 1989. </year>
Reference-contexts: This sorting procedure is integrated with a breadth-first tree growing strategy to enable SLIQ to classify disk-resident datasets. In addition, SLIQ uses a fast subsetting algorithm for determining splits for categorical attributes. SLIQ also uses a new tree-pruning algorithm based on the Minimum Description Length principle <ref> [11] </ref>. This algorithm is inexpensive, and results in compact and accurate trees. <p> The process is repeated until there is no improvement in the splits. This hybrid approach finds the optimal subset if S is small and also performs well for larger subsets. 4.4 Tree Pruning The pruning strategy used in SLIQ is based on the principle of Minimum Description Length (MDL) <ref> [11] </ref>. We first review briefly the MDL principle and then show its application in decision-tree pruning.
Reference: 12. <author> C. Wallace and J. Patrick. </author> <title> Coding decision trees. </title> <journal> Machine Learning, </journal> <volume> 11 </volume> <pages> 7-22, </pages> <year> 1993. </year>
Reference: 13. <author> S. M. Weiss and C. A. </author> <title> Kulikowski. Computer Systems that Learn: Classification and Prediction Methods from Statistics, Neural Nets, Machine Learning, and Expert Systems. </title> <publisher> Morgan Kaufman, </publisher> <year> 1991. </year> <note> 4 A similar discontinuity also occurs in the previous experiment at 800K tuples. </note>
Reference-contexts: They can also be used to develop a better understanding of each class in the data. Applications of classification include credit approval, target marketing, medical diagnosis, treatment effectiveness, store location, etc. Classification has been studied extensively (see <ref> [13] </ref> for an excellent overview of various techniques). However, the existing classification algorithms have the 1 SLIQ stands for Supervised Learning In Quest, where Quest is the Data Mining project at the IBM Almaden Research Center. problem that they do not scale. <p> But let us first specify how alternative splits for an attribute are compared. 3.1.1 Splitting Index A splitting index is used to evaluate the "goodness" of the alternative splits for an attribute. Several splitting indices have been proposed in the past <ref> [13] </ref>. We use the gini index, originally proposed in [4].
References-found: 13

