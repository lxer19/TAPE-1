URL: ftp://theory.lcs.mit.edu/pub/tcryptol/98-18.ps
Refering-URL: http://theory.lcs.mit.edu/~tcryptol/1998/98-18.html
Root-URL: 
Title: Security and Composition of Multi-party Cryptographic Protocols definitions follow the general paradigm of known definitions;
Author: Ran Canetti suggested by Micali and Rogaway. 
Keyword: multi-party cryptographic protocols, security of protocols, secure composition of protocols.  
Address: Center.  
Affiliation: IBM T.J. Watson Research  
Note: The  
Email: Email: canetti@watson.ibm.com.  
Date: June 5, 1998  
Abstract: We present general definitions of security for multi-party cryptographic protocols and show that, using these definitions, security is preserved under a natural composition method. We first present the general definitional approach. Next we consider several settings for multi-party protocols. These include the cases of non-adaptive and adaptive adversaries, as well as the information-theoretic and the computational models. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Beaver, </author> <title> "Foundations of Secure Interactive Computing", </title> <booktitle> CRYPTO, </booktitle> <year> 1991. </year>
Reference: [2] <author> D. Beaver, </author> <title> "Secure Multi-party Protocols and Zero-Knowledge Proof Systems Tolerating a Faulty Minority", </title> <editor> J. </editor> <booktitle> Cryptology (1991) 4: </booktitle> <pages> 75-122. </pages>
Reference-contexts: Post-protocol corruption. To be able to prove the composition theorem in the adaptive case (and following <ref> [2] </ref>), we introduce an additional structure to the adversary. This structure models the fact that if the parties are running also other protocols together with the current one, then a party can get corrupted even long after the current execution is completed. <p> As noted in Remark 4 (Section 3.1.1), this apparent relaxation is of no technical consequence. Yet, it may help prove security of protocols. Finally, we remark that a notion of post-protocol corruption appears also in <ref> [2] </ref>; yet there the formalization is somewhat different. In particular, the [2] there is no algorithmic post-protocol corruptor; instead the security requirement is stated for "all sequences of post-protocol corruptions". <p> As noted in Remark 4 (Section 3.1.1), this apparent relaxation is of no technical consequence. Yet, it may help prove security of protocols. Finally, we remark that a notion of post-protocol corruption appears also in <ref> [2] </ref>; yet there the formalization is somewhat different. In particular, the [2] there is no algorithmic post-protocol corruptor; instead the security requirement is stated for "all sequences of post-protocol corruptions". <p> The computation at each special round mimics the ideal process. That is, all parties hand their f j -inputs to T (party P i hands x f i ), and are handed back their respective outputs (P i learns 23 In <ref> [2] </ref> the term "postprotocol corruptor" refers to a different entity than the one here. There it is a module within the adversary that receives external corruption requests and corrupts parties accordingly.
Reference: [3] <author> D. Beaver and S. Goldwasser, </author> <title> "Multi-party computation with faulty majority", </title> <booktitle> 30th FOCS, </booktitle> <year> 1989, </year> <pages> pp. 468-473. </pages>
Reference: [4] <author> M. Bellare, R. Canetti and H. Krawczyk, </author> <title> "A modular approach to the design and analysis of authentication and key-exchange protocols", </title> <booktitle> 30th STOC, </booktitle> <year> 1998. </year>
Reference: [5] <author> M. Ben-Or, R. Canetti and O. Goldreich, </author> <title> "Asynchronous Secure Computations", </title> <booktitle> 25th STOC, </booktitle> <year> 1993, </year> <pages> pp. 52-61. </pages>
Reference: [6] <author> M. Ben-Or, S. Goldwasser and A. Wigderson, </author> <title> "Completeness Theorems for Non-Cryptographic Fault-Tolerant Distributed Computation", </title> <booktitle> 20th STOC, </booktitle> <year> 1988, </year> <pages> pp. 1-10. </pages>
Reference: [7] <author> R. Canetti, </author> <title> "Studies in Secure Multi-party Computation and Applications", </title> <type> Ph.D. Thesis, </type> <institution> Weizmann Institute, Israel, </institution> <year> 1995. </year>
Reference-contexts: Indeed, in a distributed setting where no party is thoroughly trusted it is unrealistic to base the security of a protocol on such instructions. In particular, a party may be reluctant to base its security on the good will of other parties to locally erase data. See <ref> [7, 9] </ref> for a more elaborate discussion of semi-honest parties that appear honest to an external observer but may internally deviate from their protocols. In particular, the [7, 9] definitions incorporate additional structure for better capturing this concern. For sake of simplicity, our definition does not contain this structure. <p> See <ref> [7, 9] </ref> for a more elaborate discussion of semi-honest parties that appear honest to an external observer but may internally deviate from their protocols. In particular, the [7, 9] definitions incorporate additional structure for better capturing this concern. For sake of simplicity, our definition does not contain this structure. Yet, in some scenarios putting trust in internal erasures is reasonable and necessary.
Reference: [8] <author> R. Canetti, </author> <title> "Modular composition of multi-party cryptographic protocols: The concurrent case", </title> <note> in preparation. </note>
Reference-contexts: A natural generalization of the definition, dealing with the case where several subroutine calls are running concurrently, would allow P to interact with the adversary (both in real-life and in the ideal process) also during the run of the protocol. This generalization is addressed in <ref> [8] </ref>. Note that Definition 10 lets the ideal-process adversary S depend on the post-protocol corruptor P. As noted in Remark 4 (Section 3.1.1), this apparent relaxation is of no technical consequence. Yet, it may help prove security of protocols.
Reference: [9] <author> R. Canetti, U. Feige, O. Goldreich and M. Naor, </author> <title> "Adaptively Secure Computation", </title> <booktitle> 28th STOC, </booktitle> <year> 1996. </year> <note> Fuller version in MIT-LCS-TR #682, </note> <year> 1996. </year>
Reference-contexts: It is easy to see that an adaptively secure protocol is also non-adaptively secure. Yet, the converse does not hold. We demonstrate the difference between adaptive and non-adaptive security of protocols via an example, taken from <ref> [9] </ref>. <p> Indeed, in a distributed setting where no party is thoroughly trusted it is unrealistic to base the security of a protocol on such instructions. In particular, a party may be reluctant to base its security on the good will of other parties to locally erase data. See <ref> [7, 9] </ref> for a more elaborate discussion of semi-honest parties that appear honest to an external observer but may internally deviate from their protocols. In particular, the [7, 9] definitions incorporate additional structure for better capturing this concern. For sake of simplicity, our definition does not contain this structure. <p> See <ref> [7, 9] </ref> for a more elaborate discussion of semi-honest parties that appear honest to an external observer but may internally deviate from their protocols. In particular, the [7, 9] definitions incorporate additional structure for better capturing this concern. For sake of simplicity, our definition does not contain this structure. Yet, in some scenarios putting trust in internal erasures is reasonable and necessary.
Reference: [10] <author> R. Canetti and A. Herzberg. </author> <title> Maintaining security in the presence of transient faults. </title> <booktitle> In Proceedings of CRYPTO'94. </booktitle>
Reference-contexts: In particular, the [7, 9] definitions incorporate additional structure for better capturing this concern. For sake of simplicity, our definition does not contain this structure. Yet, in some scenarios putting trust in internal erasures is reasonable and necessary. An example is the case of proactive security <ref> [29, 10] </ref>, where the parties are servers controlled by a single authority, and use erasures to maintain security in the face of repeated break-ins.
Reference: [11] <author> R. Canetti and R. Gennaro, </author> <note> Incoercible multi-party computation, 37th FOCS, 1996. 41 </note>
Reference: [12] <author> R. Canetti, S. Halevi and A. Herzberg, </author> <title> "How to Maintain Authenticated Communication", Available at the Theory of Cryptography Library, </title> <note> http://theory.lcs.mit.edu/~tcryptol/, 1998. Preliminary version at 16th PODC, 15-25, </note> <year> 1997. </year>
Reference: [13] <author> R. Canetti, E. Kushilevitz, R. Ostrovsky and A. Rosen, </author> <title> "Randomness vs. Fault-Tolerance", Available at the Theory of Cryptography Library, </title> <note> http://theory.lcs.mit.edu/~tcryptol/, 1998. Preliminary version at 16th PODC, 35-45, </note> <year> 1997. </year>
Reference: [14] <author> D. Chaum, C. Crepeau, and I. Damgard. </author> <title> Multi-party Unconditionally Secure Protocols. </title> <booktitle> In Proc. 20th Annual Symp. on the Theory of Computing, </booktitle> <pages> pages 11-19. </pages> <publisher> ACM, </publisher> <year> 1988. </year>
Reference: [15] <author> B. Chor and E. Kushilevitz, </author> <title> "a Zero-One law for boolean privacy", </title> <journal> SIAM J. Disc. Math. </journal> <note> 4 (1991) 36-47. Preliminary version in STOC 21 (1989) 62-72. </note>
Reference: [16] <author> D. Dolev, C. Dwork and M. Naor, </author> <title> Non-malleable cryptography, </title> <booktitle> 23rd STOC, </booktitle> <year> 1991. </year>
Reference: [17] <author> P. Feldman, </author> <title> "A practical scheme for non-interactive Verifiable Secret Sharing", </title> <booktitle> 28th FOCS, </booktitle> <year> 1987, </year> <pages> pp. 427-437 </pages>
Reference: [18] <author> Z. Galil, S. Haber and M. Yung, </author> <title> Cryptographic computation: Secure faut-tolerant protocols and the public-key model, </title> <booktitle> CRYPTO '87, </booktitle> <volume> LNCS 293, </volume> <pages> 1988 pages 135-155. </pages>
Reference: [19] <author> O. Goldreich, </author> <title> "Foundations of Cryptography (Fragments of a book)", </title> <institution> Weizmann Inst. of Science, </institution> <year> 1995. </year> <note> (Avaliable at http://theory.lcs.mit.edu/~tcryptol/) </note>
Reference: [20] <author> O. Goldreich. </author> <title> "Secure Multi-Party Computation", </title> <note> In preparation, </note> <year> 1998. </year>
Reference: [21] <author> O. Goldreich, S. Micali and A. Wigderson, </author> <title> "How to Play any Mental Game", </title> <booktitle> 19th STOC, </booktitle> <year> 1987,pp. </year> <pages> 218-229. </pages>
Reference: [22] <author> S. Goldwasser, and L. Levin, </author> <title> "Fair Computation of General Functions in Presence of Immoral Majority", </title> <booktitle> CRYPTO, </booktitle> <year> 1990. </year>
Reference: [23] <author> S. Goldwasser and S. Micali, </author> <title> Probabilistic encryption, </title> <journal> JCSS, </journal> <volume> Vol. 28, No 2, </volume> <month> April </month> <year> 1984, </year> <pages> pp. 270-299. </pages>
Reference: [24] <author> S. Goldwasser, S. Micali and C. Rackoff, </author> <title> "The Knowledge Complexity of Interactive Proof Systems", </title> <journal> SIAM Journal on Comput., </journal> <volume> Vol. 18, No. 1, </volume> <year> 1989, </year> <pages> pp. 186-208. </pages>
Reference: [25] <author> M. Hirt and U. Maurer, </author> <title> "Complete characterization of adversaries tolerable in secure multi-party computation", </title> <booktitle> 16th PODC, </booktitle> <year> 1997, </year> <pages> pp. 25-34. </pages>
Reference: [26] <author> E. Kushilevitz, </author> <title> "Privacy and communication complexity", </title> <note> SIAM Jour. disc. Math. Vol. 29th FOCS (1989). </note>
Reference: [27] <author> J. Kilian, E. Kushilevitz, S. Micali, R. Ostrovsky, </author> <title> "Reducibility and Completeness in Private Computations", </title> <type> manuscript, </type> <year> 1997. </year> <note> Preliminary versions in 23rd STOC (1991) by Kilian and in 35th FOCS (1994) by Kushilevits. Micali and Ostrovsky. </note>
Reference: [28] <author> S. Micali and P. Rogaway, </author> <title> "Secure Computation", </title> <type> unpublished manuscript, </type> <year> 1992. </year> <note> Preliminary version in CRYPTO 91. 42 </note>
Reference: [29] <author> R. Ostrovsky and M. Yung. </author> <title> "How to withstand mobile virus attacks". </title> <booktitle> In Proceedings of the 10 th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <address> Montreal, Quebec, Canada, </address> <pages> pages 51-59, </pages> <year> 1991. </year>
Reference-contexts: In particular, the [7, 9] definitions incorporate additional structure for better capturing this concern. For sake of simplicity, our definition does not contain this structure. Yet, in some scenarios putting trust in internal erasures is reasonable and necessary. An example is the case of proactive security <ref> [29, 10] </ref>, where the parties are servers controlled by a single authority, and use erasures to maintain security in the face of repeated break-ins.
Reference: [30] <author> T. Rabin and M. Ben-Or, </author> <title> "Verifiable Secret Sharing and Multi-party Protocols with Honest Majority", </title> <booktitle> 21st STOC, </booktitle> <year> 1989, </year> <pages> pp. 73-85. </pages>
Reference: [31] <author> A. Yao, </author> <title> Protocols for Secure Computation, </title> <booktitle> In Proc. 23th Annual Symp. on Foundations of Computer Science, </booktitle> <pages> pages 160-164. </pages> <publisher> IEEE, </publisher> <year> 1982. </year>
References-found: 31

