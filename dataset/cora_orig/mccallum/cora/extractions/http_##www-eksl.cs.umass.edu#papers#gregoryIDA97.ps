URL: http://www-eksl.cs.umass.edu/papers/gregoryIDA97.ps
Refering-URL: http://www-eksl.cs.umass.edu/~gregory/publications.html
Root-URL: 
Email: E-mail: fgregory,coheng@cs.umass.edu  
Phone: Phone: (413) 545-3616 Fax: (413) 545-1249  
Title: Integrating Many Techniques for Discovering Structure in Data  
Author: Dawn E. Gregory Paul R. Cohen 
Address: Box 34610, Amherst, MA 01003-4610  
Affiliation: Experimental Knowledge Systems Laboratory Computer Science Department, LGRC University of Massachusetts  
Abstract: This paper describes a formal representation of the discovery process that efficiently integrates of any number of data analysis strategies, regardless of their similarities and differences. We have implemented a system based on this formalization, called the Scientist's Empirical Assistant (SEA). SEA employs several analysis strategies from the discovery literature, including techniques for function finding, causal modeling, and Bayesian conditioning. It uses high-level knowledge about the discovery process, the strategies, and the domain of study to coordinate the selection and application of analyses. It relies on the skills and initiatives of an expert user to guide its search for structure. Finally, it designs and runs experiments with a simulator to verify its findings. SEA is currently capable of performing a full cycle of discovery and analysis, from hypothesis formulation to experiment design, data collection, analysis, and the generation of explanatory hypotheses. In addition, the formalization on which it is based provides an environment for studying the how, what, why, and when of intelligent data analysis. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Scott D. Anderson, Adam Carlson, David L. Westbrook, David M. Hart, and Paul R. Cohen. Clasp/Clip: </author> <title> Common Lisp Analytical Statistics Package/Common Lisp Instrumentation Package. </title> <type> Technical Report 93-55, </type> <institution> Computer Science Department, University of Massachusetts at Amherst, </institution> <year> 1993. </year>
Reference-contexts: Experiment plans are protocols for data collection, specifying sample values for independent variables and rules for taking observations. Experiment plans rely on the instrumentation package CLIP <ref> [1] </ref> to run the experiment and collect data. 4.3 Meta-Level Strategy The planner selects and applies plans to manipulate the primary data structures according to a high-level plan for data analysis.
Reference: 2. <author> Carla E. Brodley. </author> <title> Addressing the selective superiority problem: Automatic algorithm/model class selection. </title> <booktitle> In Proceedings of the Tenth International Machine Learning Conference, </booktitle> <pages> pages 17-24, </pages> <year> 1993. </year>
Reference-contexts: There are several reasons to suspect this is true. First, in having several techniques to choose from, a system can select the one most suited to the analysis problem at hand (e.g. <ref> [2] </ref>). Second, integrated systems have the advantage of supplementing one kind of result with others, information which often constitutes an explanation of previous findings (e.g. [7]). Finally, interesting structure is often discovered in the process of shifting from one representation to another [10].
Reference: 3. <author> Michael P. Georgeff and Amy L. Lansky. </author> <title> Procedural knowledge. </title> <journal> Proceedings of the IEEE Special Issue on Knowledge Representation, </journal> <volume> 74(10) </volume> <pages> 1383-1398, </pages> <year> 1986. </year>
Reference-contexts: Given an initial hypothesis input by the user, it defines an analysis strategy, collects experiment data, performs statistical tests, and explains the results of analysis, often by generating new hypotheses. 4.1 Control Architecture SEA accomodates the iterative, multi-stage process of data analysis through partial-hierarchical planning (PHP) <ref> [3] </ref>. Planning is the problem of selecting a sequence of actions that move the system from its current state to some desired, or goal, state.
Reference: 4. <author> Clark Glymour, Richard Scheines, Peter Spirtes, and Kevin Kelly. </author> <title> Discovering Causal Structure: </title> <booktitle> Artificial Intelligence, Philosophy of Science, and Statistical Modeling. </booktitle> <publisher> Academic Press, </publisher> <address> Orlando, FL, </address> <year> 1987. </year>
Reference-contexts: Statistical packages provide facilities for hypothesis testing, but must rely on the user to formulate hypotheses, select the appropriate analysis, prepare the data, and explain the results. Intelligent discovery systems, such as Bacon [6], Tetrad <ref> [4] </ref>, and C4.5 [8], formulate hypotheses of a specific form and then perform analysis in this context, but rarely have facilities for gathering and preparing data or explaining the results of analysis.
Reference: 5. <author> Dawn Gregory, Lixin Gao, Arnold L. Rosenberg, and Paul R. Cohen. </author> <title> An empirical study of dynamic scheduling on rings of processors. </title> <booktitle> In Eighth IEEE Symposium on Parallel and Distributed Processing, </booktitle> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: Finally, we describe the key contributions and identify areas of future work. 2 Example We begin with a detailed example of data analysis to show how different strategies and representations might be employed to discover structure within data. This analysis was originally performed manually, as described in <ref> [5] </ref>, and has subsequently been replicated by SEA under the guidance of a human user. The example focuses on a real-world problem from the domain of parallel computing. Parallel architectures employ several processing units that work in conjunction to solve problems more quickly than is possible on a single processor. <p> In this case, we are interested in dependencies among variables; for example, whether the value of 1 Detailed descriptions of the architecture, the task, and the policies are irrelevant to the ensuing discussion, so we refer the interested reader to <ref> [5] </ref> for more information. * depends on P . Heuristic rules generate hypotheses about potential dependen-cies: * might depend on any of P , , ff, or N . 2 The new representation indicates a different set of analysis strategies which are applied in turn.
Reference: 6. <author> Pat Langley, Herbert A. Simon, Gary L. Bradshaw, and Jan M. Zytkow. </author> <title> Scientific Discovery: Computational Explorations of the Creative Processes. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference-contexts: Statistical packages provide facilities for hypothesis testing, but must rely on the user to formulate hypotheses, select the appropriate analysis, prepare the data, and explain the results. Intelligent discovery systems, such as Bacon <ref> [6] </ref>, Tetrad [4], and C4.5 [8], formulate hypotheses of a specific form and then perform analysis in this context, but rarely have facilities for gathering and preparing data or explaining the results of analysis.
Reference: 7. <author> Bernd Nordhausen and Pat Langley. </author> <title> An integrated approach to empirical discovery. In Jeff Shrager and Pat Langley, editors, Computational Models of Scientific Discovery and Theory Formation. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: First, in having several techniques to choose from, a system can select the one most suited to the analysis problem at hand (e.g. [2]). Second, integrated systems have the advantage of supplementing one kind of result with others, information which often constitutes an explanation of previous findings (e.g. <ref> [7] </ref>). Finally, interesting structure is often discovered in the process of shifting from one representation to another [10]. Thus, there is a significant advantage to integrated discovery systems.
Reference: 8. <author> J. Ross Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Statistical packages provide facilities for hypothesis testing, but must rely on the user to formulate hypotheses, select the appropriate analysis, prepare the data, and explain the results. Intelligent discovery systems, such as Bacon [6], Tetrad [4], and C4.5 <ref> [8] </ref>, formulate hypotheses of a specific form and then perform analysis in this context, but rarely have facilities for gathering and preparing data or explaining the results of analysis.
Reference: 9. <author> Robert St. Amant and Paul R. Cohen. </author> <title> A planner for exploratory data analysis. </title> <booktitle> In Proceedings of the Third International Conference on Artificial Intelligence Planning Systems, </booktitle> <pages> pages 205-212. </pages> <publisher> AAAI Press, </publisher> <year> 1996. </year>
Reference-contexts: Plans may contain iteration, conditionals, executable statements, variable bindings, and subgoals; thus, the planning language is essentially a high-level programming language. The planner used by SEA was developed by St. Amant <ref> [9] </ref> and applied to the problem of exploratory data analysis. In addition to the basic PHP mechanisms mentioned above, the planner includes two important features. First, it can be easily extended to accomodate new control constructs in the planning language.
Reference: 10. <author> Raul E. Valdes-Perez. </author> <title> Some recent human/computer discoveries in science and what accounts for them. </title> <journal> AI Magazine, </journal> <volume> 16(3) </volume> <pages> 37-44, </pages> <year> 1995. </year>
Reference-contexts: Second, integrated systems have the advantage of supplementing one kind of result with others, information which often constitutes an explanation of previous findings (e.g. [7]). Finally, interesting structure is often discovered in the process of shifting from one representation to another <ref> [10] </ref>. Thus, there is a significant advantage to integrated discovery systems. This paper describes our approach to the integration of analysis techniques and a system, called the Scientist's Empirical Assistant (SEA), that implements this view.
Reference: 11. <author> Jan M. Zytkow, Jieming Zhu, and Abul Hussam. </author> <title> Automated discovery in a chemistry laboratory. </title> <booktitle> In Proceedings of the 8th National Conference on Artificial Intelligence (AAAI-90), </booktitle> <pages> pages 889-894, </pages> <year> 1990. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: Other discovery systems have addressed these latter concerns in the context of certain domains; for example, Fahrenheit <ref> [11] </ref> deals with issues of experiment design within the domain of chemistry. Unfortunately, none of these systems supports all the stages in a flexible, domain-independent manner. There are good reasons why intelligent data analysis has been restricted to certain domains or specific types of hypothesis.
References-found: 11

