URL: http://www.irisa.fr/EXTERNE/projet/lande/consel/papers/rt_bench.ps.gz
Refering-URL: http://www.cs.washington.edu/research/projects/unisw/DynComp/www/Related/papers.html
Root-URL: 
Email: jllg@irisa.fr  
Title: Automatic, Template-Based Run-Time Specialization: Implementation and Experimental Study approach is highly effective, its implementation is
Author: Fran~cois Noel, Luke Hornof Charles Consel, Julia L. Lawall ffnoel, hornof, consel, 
Note: Although this  
Address: 35042 Rennes Cedex, France  
Affiliation: IRISA, Campus Universitaire de Beaulieu,  
Abstract: Specializing programs with respect to run-time values has been shown to drastically improve code performance on realistic programs ranging from operating systems to graphics. Recently, various approaches to specializing code at run-time have been proposed. However, these approaches still suffer from shortcomings that limit their applicability: they are manual, too expensive, or require programs to be written in a dedicated language. We solve these problems by introducing new techniques to implement run-time specialization. The key to our approach is the use of code templates. Templates are automatically generated from ordinary programs and are optimized before run time, allowing high-quality code to be quickly generated at run time. Experimental results obtained on scientific and graphics code indicate that our approach is highly effective. Little run-time overhead is introduced, since code generation primarily consists of copying instructions. Run-time specialized programs run up to 10 times faster, and are nearly as fast as fully optimized programs (80% on average). The combination of low run-time overhead and high code quality enables specialization to be amortized in as few as 3 runs. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Auslander, M. Philipose, C. Chambers, S.J. Eggers, and B.N. Bershad. </author> <title> Fast, effective dynamic compilation. </title> <booktitle> In PLDI'96 [21], </booktitle> <pages> pages 149-159. </pages>
Reference-contexts: These templates are compiled before run time, using an existing C compiler. At run time, the specialized code is generated from this precompiled code. This process introduces little run-time overhead. In contrast to other approaches <ref> [1, 14] </ref>, we make extensive reuse of existing technology. How should we assess the performance of run-time specialization? The value of run-time specialization depends on its ability to exploit the available specialization opportunities. <p> Taking advantage of run-time information allows the compiler to generate higher quality code (compared to statically compiled code), at the cost of incurring additional run-time overhead. Several dynamic compilation systems have recently been developed. Auslander et.al. treat the C language <ref> [1] </ref>. Their system performs instruction scheduling and peephole optimizations at run time. They achieve speedups between 1.2 and 1.8, and their break-even points range from 700 to 30,000. These figures suggest that the extra run-time investment does not pay off.
Reference: [2] <author> R. Bernstein. </author> <title> Multiplication by integer constants. </title> <journal> Software|Practice and Experience, </journal> <volume> 16(7) </volume> <pages> 641-652, </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: Essentially, the analysis phase propagates this information throughout the source program. The analysis phase comprises alias, side-effect, binding-time, and action analyses. To deal with the int dotproduct 1 (int v []) f res = 0; res = res + 38 * v <ref> [2] </ref>; res = res + 12 * v [4]; return res; g (w.r.t. size = 4, u [] = f14, 38, 93, 12g) complexities of realistic source programs, the analyses are flow sensitive, context sensitive, return sensitive, and use sensitive [3, 8, 9, 10]. <p> Here we consider integer multiplication. The Sparc integer multiplication instruction is fairly expensive. When one of the arguments is a constant, an optimizing compiler can rewrite the multiplication as a cheaper sequence of shift and add operations <ref> [2] </ref>. This behavior is exhibited by the dot product and dithering examples. 4.3.1 Dot product As shown in Figure 4, specialization of dot product with respect to a vector and its size produces a sequence of multiplications of a constant by an array reference.
Reference: [3] <author> C. Consel, L. Hornof, F. Noel, J. </author> <title> Noye, and E.N. Volanschi. A uniform approach for compile-time and run-time specialization. </title> <editor> In O. Danvy, R. Gluck, and P. Thiemann, editors, </editor> <title> Partial Evaluation, </title> <booktitle> International Seminar, Dagstuhl Castle, number 1110 in Lecture Notes in Computer Science, </booktitle> <pages> pages 54-72, </pages> <month> Febru-ary </month> <year> 1996. </year>
Reference-contexts: res = 0; res = res + 38 * v [2]; res = res + 12 * v [4]; return res; g (w.r.t. size = 4, u [] = f14, 38, 93, 12g) complexities of realistic source programs, the analyses are flow sensitive, context sensitive, return sensitive, and use sensitive <ref> [3, 8, 9, 10] </ref>. Using the results of the alias and side-effect analyses, the binding-time analysis annotates as static (S ) each construct that depends only on the static data. All other constructs are annotated dynamic (D ).
Reference: [4] <author> C. Consel and F. Noel. </author> <title> A general approach for run-time specialization and its application to C. </title> <booktitle> In POPL96 [22], </booktitle> <pages> pages 145-156. </pages>
Reference-contexts: In previous works, we formally defined our ap proach for a subset of an imperative language and proved it correct <ref> [4, 18] </ref>. We review this approach in Section 2. We have implemented this approach and performed experimental studies, which are the contributions of this paper. * Section 3 presents the techniques used to implement our run-time specializer. <p> The analysis phase comprises alias, side-effect, binding-time, and action analyses. To deal with the int dotproduct 1 (int v []) f res = 0; res = res + 38 * v [2]; res = res + 12 * v <ref> [4] </ref>; return res; g (w.r.t. size = 4, u [] = f14, 38, 93, 12g) complexities of realistic source programs, the analyses are flow sensitive, context sensitive, return sensitive, and use sensitive [3, 8, 9, 10].
Reference: [5] <author> D.R. Engler, W.C. Hsieh, and M.F. Kaashoek. </author> <title> `C: A language for high-level, efficient, and machine independent dynamic code generation. </title> <booktitle> In POPL96 [22], </booktitle> <pages> pages 131-144. </pages>
Reference-contexts: Our results, however, show that it is possible to dynamically generate optimized binary code efficiently. 5.2 Run-time code generation languages Recently there has been much interest in developing and implementing languages to express what code should be generated at run time <ref> [5, 26] </ref>. These languages provide some support, such as static typing, to ensure that the code generated at run time is meaningful. Such languages, however, correspond only to the back end of our system. <p> We can, however, easily use our front end to construct code in such languages. For example, we have experimented with the C-like run-time code generation language Tick C <ref> [5] </ref> as a back end of our specializer. 5.3 Grammars Malmkjr originated the use of grammars to characterize the set of possible specializations [16].
Reference: [6] <author> C. W. Fraser and D. R. Hanson. </author> <title> A code generation interface for ANSI C. </title> <journal> Software Practice and Experience, </journal> <volume> 21(9) </volume> <pages> 963-988, </pages> <year> 1991. </year>
Reference-contexts: Some compiler optimizations, such as code motion, may mix instructions between templates. This would make template extraction extremely difficult. In general, the types of optimizations performed depend on the compiler. The lcc compiler only performs intra-block transformations <ref> [6] </ref>. Since templates consist of complete blocks, such optimizations cannot corrupt templates. More powerful optimizations, such as those found in gcc -O2, are capable of interfering with template integrity. The fact that labels delimit templates helps prevent most inter-template transformations.
Reference: [7] <author> R. Gluck, R. Nakashige, and R. Zochling. </author> <title> Binding-time analysis applied to mathematical algorithms. </title> <editor> In J. Dolezal and J. Fidler, editors, </editor> <booktitle> System Modelling and Optimization, </booktitle> <pages> pages 137-146. </pages> <publisher> Chapman & Hall, </publisher> <year> 1995. </year>
Reference-contexts: In this paper we present a partial evaluator that performs specialization at run time, and assess its performance. We begin by motivating the need for specialization at run time. Specialization can be useful in a variety of domains, such as scientific computing <ref> [7] </ref>, operating systems [24] and graphics [20]. For example, in scientific computing, matrix multiplication can be specialized to each row of the first matrix. In graphics, an image viewer can be specialized with respect to the number of colors available on the host machine. <p> The numerical programs are those used in Gluck, Nakashige, and Zochling's work on applying partial evaluation to mathematical algorithms <ref> [7] </ref>, and are based on algorithms given in Kincaid and Cheney [13] and Press et al. [23]. The measurements were obtained using a Sun SPARCstation 20 Model 70 with 96 MB of main memory running SunOS version 4.1.4.
Reference: [8] <author> L. Hornof. </author> <title> Static Analyses for the Effective Specialization of Realistic Applications. </title> <type> PhD thesis, </type> <institution> Universite de Rennes I, </institution> <month> June </month> <year> 1997. </year>
Reference-contexts: res = 0; res = res + 38 * v [2]; res = res + 12 * v [4]; return res; g (w.r.t. size = 4, u [] = f14, 38, 93, 12g) complexities of realistic source programs, the analyses are flow sensitive, context sensitive, return sensitive, and use sensitive <ref> [3, 8, 9, 10] </ref>. Using the results of the alias and side-effect analyses, the binding-time analysis annotates as static (S ) each construct that depends only on the static data. All other constructs are annotated dynamic (D ).
Reference: [9] <author> L. Hornof and J. </author> <title> Noye. Accurate binding-time analysis for imperative languages: Flow, context, and return sensitivity. </title> <booktitle> In PEPM'97 [19], </booktitle> <pages> pages 63-73. </pages>
Reference-contexts: res = 0; res = res + 38 * v [2]; res = res + 12 * v [4]; return res; g (w.r.t. size = 4, u [] = f14, 38, 93, 12g) complexities of realistic source programs, the analyses are flow sensitive, context sensitive, return sensitive, and use sensitive <ref> [3, 8, 9, 10] </ref>. Using the results of the alias and side-effect analyses, the binding-time analysis annotates as static (S ) each construct that depends only on the static data. All other constructs are annotated dynamic (D ).
Reference: [10] <author> L. Hornof, J. Noye, and C. Consel. </author> <title> Effective specialization of realistic programs via use sensitivity. </title> <editor> In P. Van Hentenryck, editor, </editor> <booktitle> Proceedings of the Fourth International Symposium on Static Analysis, SAS'97, volume 1302 of Lecture Notes in Computer Science, </booktitle> <pages> pages 293-314, </pages> <address> Paris, France, </address> <month> September </month> <year> 1997. </year> <note> Springer-Verlag. </note>
Reference-contexts: res = 0; res = res + 38 * v [2]; res = res + 12 * v [4]; return res; g (w.r.t. size = 4, u [] = f14, 38, 93, 12g) complexities of realistic source programs, the analyses are flow sensitive, context sensitive, return sensitive, and use sensitive <ref> [3, 8, 9, 10] </ref>. Using the results of the alias and side-effect analyses, the binding-time analysis annotates as static (S ) each construct that depends only on the static data. All other constructs are annotated dynamic (D ).
Reference: [11] <author> N.D. Jones, C. Gomard, and P. Sestoft. </author> <title> Partial Evaluation and Automatic Program Generation. </title> <booktitle> International Series in Computer Science. </booktitle> <publisher> Prentice-Hall, </publisher> <month> June </month> <year> 1993. </year>
Reference-contexts: For example, many machines provide either 8-bit or 24-bit color, so specializations could be prepared for these common cases. This rewriting is known in the partial evaluation community as "The Trick" <ref> [11] </ref>. Generally, however, it is not possible to predict all the possible specialization contexts at compile time. Furthermore, only a few of the many possible contexts may end up being used.
Reference: [12] <author> D. Keppel, S. Eggers, and R. Henry. </author> <title> A case for run-time code generation. </title> <type> Technical Report 91-11-04, </type> <institution> Department of Computer Science, University of Wash-ington, </institution> <address> Seattle, WA, </address> <year> 1991. </year>
Reference-contexts: The generating extension is used to derive both the object templates and the run-time specializer. 2.4.2 Deriving object templates First, the right-hand side of each rule of the specialization grammar is converted into a set of source templates. A template <ref> [12] </ref> is a fragment of code parameterized by holes.
Reference: [13] <author> D. Kincaid and W. </author> <title> Cheney. Numerical Analysis: </title> <booktitle> Mathematics of Scientific Computing. </booktitle> <address> Brooks/Cole, </address> <year> 1991. </year>
Reference-contexts: The numerical programs are those used in Gluck, Nakashige, and Zochling's work on applying partial evaluation to mathematical algorithms [7], and are based on algorithms given in Kincaid and Cheney <ref> [13] </ref> and Press et al. [23]. The measurements were obtained using a Sun SPARCstation 20 Model 70 with 96 MB of main memory running SunOS version 4.1.4.
Reference: [14] <author> P. Lee and M. Leone. </author> <title> Optimizing ML with run-time code generation. </title> <booktitle> In PLDI'96 [21], </booktitle> <pages> pages 137-148. </pages>
Reference-contexts: These templates are compiled before run time, using an existing C compiler. At run time, the specialized code is generated from this precompiled code. This process introduces little run-time overhead. In contrast to other approaches <ref> [1, 14] </ref>, we make extensive reuse of existing technology. How should we assess the performance of run-time specialization? The value of run-time specialization depends on its ability to exploit the available specialization opportunities. <p> They achieve speedups between 1.2 and 1.8, and their break-even points range from 700 to 30,000. These figures suggest that the extra run-time investment does not pay off. Fabius treats a pure, first-order subset of the SML programming language <ref> [14, 15] </ref>. It also performs instruction scheduling and peephole optimizations at run-time, and an inexpensive form of register allocation called register assignment is being investigated. Benchmarks for this system are also given, but they are hard to interpret since they do not precisely assess run-time generation costs.
Reference: [15] <author> M. Leone and P. Lee. </author> <title> Lightweight run-time code generation. </title> <booktitle> In ACM SIGPLAN Workshop on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <address> Orlando, FL, USA, </address> <month> June </month> <year> 1994. </year> <type> Technical Report 94/9, </type> <institution> University of Melbourne, Australia. </institution>
Reference-contexts: They achieve speedups between 1.2 and 1.8, and their break-even points range from 700 to 30,000. These figures suggest that the extra run-time investment does not pay off. Fabius treats a pure, first-order subset of the SML programming language <ref> [14, 15] </ref>. It also performs instruction scheduling and peephole optimizations at run-time, and an inexpensive form of register allocation called register assignment is being investigated. Benchmarks for this system are also given, but they are hard to interpret since they do not precisely assess run-time generation costs.
Reference: [16] <author> Karoline Malmkjr. </author> <title> Abstract Interpretation of Partial-Evaluation Algorithms. </title> <type> PhD thesis, </type> <institution> Department of Computing and Information Sciences, Kansas State University, Manhattan, Kansas, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: For example, we have experimented with the C-like run-time code generation language Tick C [5] as a back end of our specializer. 5.3 Grammars Malmkjr originated the use of grammars to characterize the set of possible specializations <ref> [16] </ref>. She used word grammars to characterize infinite sets of programs in concrete syntax, whereas we use tree grammars to characterize infinite sets of programs as abstract syntax trees. 6 Conclusions and Future Work We have developed new techniques to implement efficient run-time specialization for C programs.
Reference: [17] <author> G. Muller, B. Moura, F. Bellard, and C. Consel. </author> <title> JIT vs. o*ine compilers: Limits and benefits of byte-code compilation. </title> <institution> Rapport de recherche 1063, IRISA, Rennes, France, </institution> <month> December </month> <year> 1996. </year>
Reference-contexts: A promising avenue of research is to compile programs written in various source languages, such as Module-3, C++, or Java, into C programs, and using Tempo as a back-end partial evaluator. In fact, we have developed an o*ine compiler for Java bytecode to C <ref> [17] </ref> and we are studying the specialization of the resulting C programs at both compile time and run time. This strategy amounts to obtaining a Java partial evaluator solely by introducing a translation phase. Tempo is now being used in areas such as graphics, scientific computing, and operating systems.
Reference: [18] <author> F. Noel. </author> <title> Specialisation dynamique de code par evaluation partielle. </title> <type> PhD thesis, </type> <institution> Universite de Rennes I, </institution> <month> October </month> <year> 1996. </year>
Reference-contexts: In previous works, we formally defined our ap proach for a subset of an imperative language and proved it correct <ref> [4, 18] </ref>. We review this approach in Section 2. We have implemented this approach and performed experimental studies, which are the contributions of this paper. * Section 3 presents the techniques used to implement our run-time specializer.
Reference: [19] <institution> ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </institution> <address> Ams-terdam, The Netherlands, June 1997. </address> <publisher> ACM Press. </publisher>
Reference: [20] <author> R. Pike, B. N. Locanthi, and J.F. Reiser. </author> <title> Hardware/software trade-offs for bitmap graphics on the blit. </title> <journal> Software Practice and Experience, </journal> <volume> 15(2) </volume> <pages> 131-151, </pages> <year> 1985. </year>
Reference-contexts: In this paper we present a partial evaluator that performs specialization at run time, and assess its performance. We begin by motivating the need for specialization at run time. Specialization can be useful in a variety of domains, such as scientific computing [7], operating systems [24] and graphics <ref> [20] </ref>. For example, in scientific computing, matrix multiplication can be specialized to each row of the first matrix. In graphics, an image viewer can be specialized with respect to the number of colors available on the host machine. Traditionally partial evaluation has been carried out at compile time. <p> Furthermore, only a few of the many possible contexts may end up being used. Generating code at com pile time for all the possible contexts of the bitblt graphics routine, for example, would produce over ten thousand times more unused code than used code <ref> [20] </ref>. Thus we consider specialization at run time. Run-time specialization is the process of producing specialized code at run time, given a program and a description of the run-time context. Specialization encompasses two phases: a front end and a back end. Our approach addresses both issues.
Reference: [21] <institution> Proceedings of the ACM SIGPLAN '96 Conference on Programming Language Design and Implementation, </institution> <address> Philadelphia, PA, </address> <month> May </month> <year> 1996. </year> <journal> ACM SIGPLAN Notices, </journal> <volume> 31(5). </volume>
Reference: [22] <institution> Conference Record of the 23 rd Annual ACM SIGPLAN-SIGACT Symposium on Principles Of Programming Languages, </institution> <address> St. Petersburg Beach, FL, USA, </address> <month> January </month> <year> 1996. </year> <note> ACM Press. </note>
Reference: [23] <author> W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery. </author> <title> Numerical Recipes in FORTRAN The Art of Scientific Computing. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, 2nd edition, </address> <year> 1993. </year>
Reference-contexts: The numerical programs are those used in Gluck, Nakashige, and Zochling's work on applying partial evaluation to mathematical algorithms [7], and are based on algorithms given in Kincaid and Cheney [13] and Press et al. <ref> [23] </ref>. The measurements were obtained using a Sun SPARCstation 20 Model 70 with 96 MB of main memory running SunOS version 4.1.4.
Reference: [24] <author> C. Pu, H. Massalin, and J. Ioannidis. </author> <title> The Synthesis kernel. </title> <journal> Computing Systems, </journal> <volume> 1(1) </volume> <pages> 11-32, </pages> <month> Winter </month> <year> 1988. </year>
Reference-contexts: In this paper we present a partial evaluator that performs specialization at run time, and assess its performance. We begin by motivating the need for specialization at run time. Specialization can be useful in a variety of domains, such as scientific computing [7], operating systems <ref> [24] </ref> and graphics [20]. For example, in scientific computing, matrix multiplication can be specialized to each row of the first matrix. In graphics, an image viewer can be specialized with respect to the number of colors available on the host machine.
Reference: [25] <author> M. Sperber and T. Thiemann. </author> <title> Two for the price of one: Composing partial evaluation and compilation. </title> <booktitle> In Proceedings of the ACM SIGPLAN '97 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 215-224, </pages> <address> Las Vegas, Nevada, </address> <month> June 15-18, </month> <year> 1997. </year>
Reference-contexts: Benchmarks for this system are also given, but they are hard to interpret since they do not precisely assess run-time generation costs. Sperber and Thiemann have developed a run-time specializer for Scheme by composing an existing compiler with an existing specializer <ref> [25] </ref>. As most of the machinery of the specializer and the compiler is invoked at run time, it appears to incur a substantial cost at run time. The QuaC system performs run-time optimizations on templates expressed in C and compiled using a standard compiler [27].
Reference: [26] <author> W. Taha and T. Sheard. </author> <title> Multi-state programming with explicit annotations. </title> <booktitle> In PEPM'97 [19], </booktitle> <pages> pages 203-217. </pages>
Reference-contexts: Our results, however, show that it is possible to dynamically generate optimized binary code efficiently. 5.2 Run-time code generation languages Recently there has been much interest in developing and implementing languages to express what code should be generated at run time <ref> [5, 26] </ref>. These languages provide some support, such as static typing, to ensure that the code generated at run time is meaningful. Such languages, however, correspond only to the back end of our system.
Reference: [27] <author> C. Yarvin and A. Sah. QuaC: </author> <title> Binary optimization for fast runtime code generation in C. </title> <type> Technical Report 94-792, </type> <institution> Computer Science Department, University of California, Berkeley, </institution> <year> 1994. </year>
Reference-contexts: As most of the machinery of the specializer and the compiler is invoked at run time, it appears to incur a substantial cost at run time. The QuaC system performs run-time optimizations on templates expressed in C and compiled using a standard compiler <ref> [27] </ref>. Few details about the implementation are available. All of these systems perform optimizations at run time, adding significantly to the run-time overhead.
References-found: 27

