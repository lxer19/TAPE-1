URL: ftp://ftp.cs.toronto.edu/pub/mes/papers/jcr_new.ps.Z
Refering-URL: http://www.cs.toronto.edu/~mes/papers/printed.html
Root-URL: 
Email: email: mes@cs.toronto.edu  
Title: Automata Simulation of N-Person Social Dilemma Games  
Author: Vladimir Akimov Mikhail Soutchanski 
Date: 15 May 1992. Revised: 7 August 1992; 19 April 1993  
Address: 2/3 Khlebny St., 121069 Moscow Russia  M5S 1A4 Canada,  
Affiliation: Instititute of the US&Canada Studies of Russian Academy of Sciences  Dep. of Computer Science, Univ. Of Toronto,  
Abstract: Collective behavior of N players in a social dilemma game is simulated by automata exhibiting asymptotically cooperative behavior. In his automata models of simple biological systems M.Tsetlin assumed minimum of information available to the "players." Our automata were somewhat more sophisticated, using Markov strategies in their interactions. We investigated relationships between information received by the automata and the emergence of cooperation in a simulated evolution process. In some ways our approach is similar to that of R.Axelrod. It differs in that instead of determining the "most successful" strategy, we seek surviving strategies in a social dilemma environment. Previous results showed that cooperation could be established asymptotically under partially centralized control. In our model there is no such control. Our main result is that more sophisticated behavior of "self-seeking" automata compensates for the absence of such control. Moreover cooperation is established more rapidly when more information is available to the automata. 1 fl Lab. of Structural Analysis and Modeling of Decision Making y 10 King's College Road SF3303 1 Acknowledgment: We would especially like to thank Prof. Anatol Rapoport for his kind help, in his role 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alker H.R., </author> <title> Hurwitz R."Resolving Prisoner's Dilemmas", MIT, (Student's Manual), </title> <year> 1981, </year> <month> 132p. </month>
Reference-contexts: Anatol Rapoport for his kind help, in his role as editor, to get this paper out. 1 1 Dilemma game background The history of attempts to describe international security and crisis bargaining by social dilemma games (SD) is long <ref> [9, 1] </ref>. Perhaps the most extensive empirically oriented treatment of SD in situation of international tension is [12], where 18 different international crises were typologized and studied. After [6] mathematically oriented sociologist and politologist encountered different generalizations of simple 2-persons, 2-actions dilemma and those generalizations have received increased interest. <p> They can get out of these traps only if a player switches from D to C and the other follows suit or continues to cooperate, in other words responds to a "peace initiative". H.R. Alker and R. Hurwitz <ref> [1] </ref> and H. Moulin [7] pointed out that in conditions of information exchange, TFT can provide a "deterrence" effect. In our case such information exchange was excluded.
Reference: [2] <institution> Axelrod R."The evolution of cooperation". Basic Books, </institution> <address> 1984, N.Y. </address>
Reference-contexts: We would not like to confine ourselves to using a more or less appealing principle of rationality chosen in advance. Our approach does not follow the main stream of game theory but is to some extent closer to the evolutionary approach proposed in <ref> [2] </ref>. Unlike decision rules submitted to the 5 tournament our automata can not use more sophisticated strategies than Markov ones. It is not surprising that we limit our consideration only by Markov strategies: the most prominent one is "TIT-FOR-TAT" the winner of the computer tournament that was described by R.Axelrod. <p> Let us remind: when the automaton begins play a new strategy its memory state is the deepest one. Our experiment differs from Axelrod's tournaments <ref> [2] </ref> in two ways. On the one hand, the strategies available to the players were much simpler than those submitted to Axelrod's tournaments. On the other hand, our players could switch from one strategy to another during the iterated plays. <p> That is to say, an automaton adopting any of these strategies and only these would continue to cooperate after a cooperative outcome. Hence a stable cooperative situation has to be based on this set of "cooperation preserving" strategies (they were called in <ref> [2] </ref> nice strategies). Cooperation can be established due to at least two different reasons. Either it happened to arise by lucky chance or it could be rationally produced as a result of strategies interaction. First way is very simple.
Reference: [3] <author> Dawes R.M. </author> <title> "Formal models of dilemmas in social decision-making". </title> <editor> In: M.F.Kaplan, S Schwartz (eds.) </editor> <booktitle> "Human judgment and decision processes", </booktitle> <address> N.Y., </address> <year> 1975, </year> <month> p.88-107. </month>
Reference-contexts: Perhaps the most extensive empirically oriented treatment of SD in situation of international tension is [12], where 18 different international crises were typologized and studied. After [6] mathematically oriented sociologist and politologist encountered different generalizations of simple 2-persons, 2-actions dilemma and those generalizations have received increased interest. Papers <ref> [11, 5, 3] </ref> discussed the N-player case, and [8] studied a disarmament process in which each of two players has six options, each representing the number of warheads he has following each round.
Reference: [4] <author> Gurvich E.T. </author> <title> "Method for asymptotic investigation of games between automata". In: Au tomation and Remote Control, </title> <note> 1975, v.36, N2, p.257-270. </note>
Reference-contexts: The best way to simulate this type of behavior is by means of automata models. E.T. Gurvich developed an analytical method for investigating asymptotic behavior of game-playing automata <ref> [4] </ref>. M.E.Soutchanski used this method to propose a pattern of interactions among automata that guarantees asymptotically stable cooperation in SD games [14].
Reference: [5] <author> Hamburger H. </author> <title> "N-person prisoner's dilemma". In: </title> <journal> J. of Mathematical Sociology, </journal> <note> 1973, v.3, N1, p.27-48. </note>
Reference-contexts: Perhaps the most extensive empirically oriented treatment of SD in situation of international tension is [12], where 18 different international crises were typologized and studied. After [6] mathematically oriented sociologist and politologist encountered different generalizations of simple 2-persons, 2-actions dilemma and those generalizations have received increased interest. Papers <ref> [11, 5, 3] </ref> discussed the N-player case, and [8] studied a disarmament process in which each of two players has six options, each representing the number of warheads he has following each round.
Reference: [6] <author> Hardin G. </author> <title> "The tragedy of the commons". </title> <booktitle> In: Science, 1968, </booktitle> <address> v.162, N3859, p.1243-1248. </address>
Reference-contexts: Perhaps the most extensive empirically oriented treatment of SD in situation of international tension is [12], where 18 different international crises were typologized and studied. After <ref> [6] </ref> mathematically oriented sociologist and politologist encountered different generalizations of simple 2-persons, 2-actions dilemma and those generalizations have received increased interest.
Reference: [7] <author> Moulin H. </author> <title> "Theorie des Jeux Pour L'Economie et la Politique". </title> <publisher> Hermann, </publisher> <address> Paris, </address> <year> 1981. </year>
Reference-contexts: They can get out of these traps only if a player switches from D to C and the other follows suit or continues to cooperate, in other words responds to a "peace initiative". H.R. Alker and R. Hurwitz [1] and H. Moulin <ref> [7] </ref> pointed out that in conditions of information exchange, TFT can provide a "deterrence" effect. In our case such information exchange was excluded.
Reference: [8] <author> Pilisuk M. </author> <title> "Experimenting with the arms race". In: J. of Conflict Resolution, </title> <note> 1984, v.28, N2, p.296-315. </note>
Reference-contexts: After [6] mathematically oriented sociologist and politologist encountered different generalizations of simple 2-persons, 2-actions dilemma and those generalizations have received increased interest. Papers [11, 5, 3] discussed the N-player case, and <ref> [8] </ref> studied a disarmament process in which each of two players has six options, each representing the number of warheads he has following each round.
Reference: [9] <author> Rapoport A., Chammah A.M. </author> <title> "Prisoner's dilemma. A study in conflict and cooperation". </title> <address> Ann Arbor, </address> <year> 1965, </year> <month> 258p. </month>
Reference-contexts: Anatol Rapoport for his kind help, in his role as editor, to get this paper out. 1 1 Dilemma game background The history of attempts to describe international security and crisis bargaining by social dilemma games (SD) is long <ref> [9, 1] </ref>. Perhaps the most extensive empirically oriented treatment of SD in situation of international tension is [12], where 18 different international crises were typologized and studied. After [6] mathematically oriented sociologist and politologist encountered different generalizations of simple 2-persons, 2-actions dilemma and those generalizations have received increased interest.
Reference: [10] <author> Robbins H.A. </author> <title> "A sequential decision problem with finite memory". </title> <booktitle> In: Proceedings of the National Academy of Science of USA, 1956, v. </booktitle> <volume> 42, </volume> <pages> N 3. </pages>
Reference-contexts: M.Tsetlin introduced several families of automata exhibiting "expedient" behavior, that is, behavior in some sense adapted to a stationary random medium [15]. Earlier, but in terms of many-arms bandit problem, one kind of automata was introduced by <ref> [10] </ref>. There is a long tradition within Tsetlin's scientific school to investigate individual and collective behavior in stochastic environment. To be successful in SD-games each player must be capable to adapt its behavior quickly to the dynamic behavior of the other participants. <p> When the automaton, being in state ' i - , receives a reward, it remains in that state. A trusting tactic, introduced by H.A. Robbins <ref> [10] </ref> differs from the linear tactic in that the automaton passes to state of maximum depth ' i whenever it receives a reward after the action f i has been chosen. A quasi-linear tactic, introduced by V.G.Sragovich [13] is like a linear tactic when the automaton receives a reward.
Reference: [11] <author> Schelling Th. "Hockey helmets, concealed weapons, and daylight-saving: </author> <title> a study of binary choices with externalities". In: J. of Conflict Resolution, </title> <note> 1973, v.17, N3, p.381-428. </note>
Reference-contexts: Perhaps the most extensive empirically oriented treatment of SD in situation of international tension is [12], where 18 different international crises were typologized and studied. After [6] mathematically oriented sociologist and politologist encountered different generalizations of simple 2-persons, 2-actions dilemma and those generalizations have received increased interest. Papers <ref> [11, 5, 3] </ref> discussed the N-player case, and [8] studied a disarmament process in which each of two players has six options, each representing the number of warheads he has following each round.
Reference: [12] <author> Snyder G.H., Diesing P. </author> <title> "Conflict among nations". </title> <publisher> Princeton, </publisher> <year> 1977, </year> <month> 528p. </month>
Reference-contexts: Perhaps the most extensive empirically oriented treatment of SD in situation of international tension is <ref> [12] </ref>, where 18 different international crises were typologized and studied. After [6] mathematically oriented sociologist and politologist encountered different generalizations of simple 2-persons, 2-actions dilemma and those generalizations have received increased interest.
Reference: [13] <author> Sragovich V.G. </author> <title> "Adaptive control". </title> <address> Moscow, </address> <note> "Nauka", 1981 (in Russian). </note>
Reference-contexts: A trusting tactic, introduced by H.A. Robbins [10] differs from the linear tactic in that the automaton passes to state of maximum depth ' i whenever it receives a reward after the action f i has been chosen. A quasi-linear tactic, introduced by V.G.Sragovich <ref> [13] </ref> is like a linear tactic when the automaton receives a reward. When it receives a punishment, however, the automaton passes from state ' i j to either ' i j1 or to ' i j+1 with equal probabilities. <p> A reason for introducing the quasi-linear tactic was a result proved by [15] that expedient behavior cannot be "learned" by an automaton using a linear tactic in a stochastic environment when the probability of punishment exceeds the probability of reward. <ref> [13] </ref> showed that an automaton using quasi-linear or trusting tactic can demonstrate expedient behavior in a much broader range of environments. The parameter is called the memory span of the automaton. It can be interpreted as a 4 measure of the automaton's "patience" or, perhaps, "stubbornness". <p> W j (m) (according to the law of large numbers). It seems that interactions of the automata society within the stationary random environment under consideration can be described by a Markov chain <ref> [15, 13] </ref>. To achieve ergodicity of this Markov chain we added small steps from 0 and 1 during normalization, so that for every j: 0 &lt; W j (m) &lt; 1. The transformed expected payoffs are shown in table 4.
Reference: [14] <author> Soutchanski M.E. </author> <title> (Suchanskiy M.E.) "Adaptive algorithm for determination of weakly effi cient variant under randomness". In: </title> <journal> Soviet J. of Computer and Systems Sciences, </journal> <note> 1987, v.25, N3, p.148-157 </note>
Reference-contexts: The best way to simulate this type of behavior is by means of automata models. E.T. Gurvich developed an analytical method for investigating asymptotic behavior of game-playing automata [4]. M.E.Soutchanski used this method to propose a pattern of interactions among automata that guarantees asymptotically stable cooperation in SD games <ref> [14] </ref>. The main drawback of this proposal is that it presupposed synchronized switching to new options (these new options may coincide with the old ones), that is, some sort of partial centralization. M. <p> We would like to investigate which strategies will survive and which will perish under different conditions and what type of collective behavior this process will result in. It is important to note that contrary to <ref> [14] </ref> in the current model decision makers are fully decentralized and all participants are self-seeking individuals.
Reference: [15] <author> Tsetlin M.L. </author> <title> "Automaton theory and modeling of biological systems". </title> <journal> (ser. Mathematics in Science and Engineering, v. </journal> <volume> 102), </volume> <publisher> Academic Press, </publisher> <address> N.Y., </address> <year> 1973, </year> <title> 288p. The paper "Automata Simulation of N-Person Social Dilemma Games" published in the Journal of Conflict Resolution, </title> <booktitle> 1994, </booktitle> <volume> vol. </volume> <month> 38, </month> <title> N1 (March) is different from this version because the editorial board did not receive the final improved copy of the manuscript. At the time when this paper has been written, both authors were employed at the Laboratory of Structural Analysis and Modeling of Decision Making in the Institute of the USA and Canada Studies. </title> <type> 16 </type>
Reference-contexts: M.Tsetlin introduced several families of automata exhibiting "expedient" behavior, that is, behavior in some sense adapted to a stationary random medium <ref> [15] </ref>. Earlier, but in terms of many-arms bandit problem, one kind of automata was introduced by [10]. There is a long tradition within Tsetlin's scientific school to investigate individual and collective behavior in stochastic environment. <p> When it receives a punishment, however, the automaton passes from state ' i j to either ' i j1 or to ' i j+1 with equal probabilities. A reason for introducing the quasi-linear tactic was a result proved by <ref> [15] </ref> that expedient behavior cannot be "learned" by an automaton using a linear tactic in a stochastic environment when the probability of punishment exceeds the probability of reward. [13] showed that an automaton using quasi-linear or trusting tactic can demonstrate expedient behavior in a much broader range of environments. <p> W j (m) (according to the law of large numbers). It seems that interactions of the automata society within the stationary random environment under consideration can be described by a Markov chain <ref> [15, 13] </ref>. To achieve ergodicity of this Markov chain we added small steps from 0 and 1 during normalization, so that for every j: 0 &lt; W j (m) &lt; 1. The transformed expected payoffs are shown in table 4.
References-found: 15

