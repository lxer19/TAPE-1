URL: http://www.isi.edu/isd/rickel/icai_survey.ps
Refering-URL: http://www.isi.edu/isd/rickel/publications.html
Root-URL: http://www.isi.edu
Title: Intelligent Computer-Aided Instruction: A Survey Organized Around System Components  
Author: Jeff W. Rickel 
Note: IEEE Transactions on Systems, Man, and Cybernetics, Vol. 19, No. 1,January/February 1989, pp. 40-57  ICAI research in a form which is appropriate for use by future designers of ICAI systems.  
Abstract: This paper presents a survey of the issues and previous research in Intelligent Computer-Aided Instruction (ICAI). Unlike previous surveys of ICAI, which have been organized around the seminal ICAI systems, this one concentrates on the contribution of each effort to our understanding of the various components of ICAI systems. Along the way, comparisons are made between ICAI and CAI, although a CAI straw man is used due to the focus of the paper. Various learning scenarios are discussed, including computer coaches, gaming environments, mixed initiative dialog, Socratic tutors, articulate experts, interactive simulation, and discovery learning. Various forms of knowledge representation are discussed along with relevant issues and examples. Several techniques for student modeling and diagnosis are presented, as are their respective advantages and disadvantages. Pedagogical knowledge, its role in ICAI, and several examples are highlighted. The evolution of discourse management techniques for ICAI is outlined. Techniques for the automatic generation of problems from a general base of domain knowledge are presented. Finally, issues in the design of user interfaces for ICAI systems are briefly discussed. The purpose of this paper is to place previous 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.R. Anderson, C.F. Boyle, and G. Yost, </author> <title> "The Geometry Tutor," </title> <booktitle> Proc. IJCAI-85, </booktitle> <address> Los Angeles, CA, </address> <pages> pp. 1-7, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: The requisite skills are modeled by condition/action rules which choose moves based on probabilistic and logical evidence. When the student makes suboptimal moves, he is postulated to be missing the appropriate rule. More recently, Anderson and Reiser used rules in their respective Geometry <ref> [1] </ref> and lisp [46] tutors. The attractiveness of rules is their modular nature, since each rule is, ideally, independent of all others and thus rules can be added and deleted with only an incremental effect on system performance. <p> The coach's role, in their view, is to intervene when the student is likely to miss the evidence of his error or misconception. Woolf [65] contrasts her philosophy of letting students explore possible wrong paths with Anderson et al. <ref> [1] </ref> and Reiser et al. [46], whose Geometry and lisp tutors immediately correct student errors. This immediate feedback is justified by its authors because errors in geometry and lisp are so ambiguous and delayed that much fruitless effort could be wasted on erroneous solution paths.
Reference: [2] <author> J.R. Anderson, </author> <title> "The Expert Module," AFHRL Research Planning Forum for Intelligent Tutoring Systems, </title> <address> San Antonio, TX, </address> <month> September </month> <year> 1986. </year>
Reference-contexts: Most other systems have bypassed the natural language problem by using graphical or menu-based input. It is worthy to note that experts in the field of intelligent tutoring have labeled natural language the "Achilles' heel" of potential tutoring systems <ref> [2, 28] </ref>, and warn against its use because of its potential to consume project resources. However, it is often difficult to provide adequately-flexible interactions with the student without some level of natural language.
Reference: [3] <author> A. Barr, M. Beard, and R.C. Atkinson, </author> <title> "The Computer as a Tutorial Laboratory: The Stanford BIP Project," </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> Vol. 8, </volume> <pages> pp. 567-596, </pages> <year> 1976. </year>
Reference-contexts: A similar idea was developed further by researchers at Stanford University and resulted in the notion of a curriculum information network, used in the Stanford bip system <ref> [3] </ref>, in which skills to be taught are related to tasks that exercise those skills. The curriculum net is organized as a large set of problems (in their case, basic programming problems) indexed in terms of the generic skills they require. <p> Work by Stevens and Collins [55] showed that human tutors maintain an agenda of goals and that the challenge is to add and remove goals from this agenda in a last-in-first-out (LIFO) manner. Other work, exemplified by bip <ref> [3] </ref>, showed the utility of a richly structured knowledge of the course curriculum which can be used to dynamically sequence the domain topics.
Reference: [4] <author> J. Bonar, R. Cunningham, and J. Schultz, </author> <title> "An Object-Oriented Architecture for Intelligent Tutoring Systems," </title> <booktitle> Proc. of OOPSLA-86, </booktitle> <address> Portland, OR, </address> <month> September </month> <year> 1986, </year> <pages> pp. 269-276. </pages>
Reference-contexts: While most ICAI systems revolve around their knowledge representation, some attempts have been made to combine heterogeneous knowledge in a more modular architecture. Bonar et al. <ref> [4] </ref> describe an object-oriented tutoring architecture in which domain knowledge classes, called "Bites," are organized into a hierarchical inheritance lattice to take advantage of shared structure. <p> classes of Bites include Abstraction Hierarchy Bites, which represent an ordering of concepts in the curriculum; Definition Bites, which are relatively standalone; I/O Bites, which represent black-box (functional) behaviors; and Discovery Bites, which include skills such as scientific inquiry which allow the student to explore an environment with minimal coaching <ref> [4] </ref>. Abstraction Hierarchy Bites are especially critical in student diagnosis since only IV STUDENT MODELING 13 they have connection to other related Bites and so can test for understanding of concepts that span several Bites. <p> While most systems treat diagnosis as a separate module, the object-oriented approach of Bonar et al. <ref> [4] </ref> allows different classes of knowledge to use different diagnosis techniques. Each knowledge class inherits diagnostic capabilities from a particular Diagnoser class. <p> Misuse is defined by that component Bite's own Diagnoser class. The Diagnoser then updates the student model, which of course is local to each knowledge Bite, and invokes the Task Selector to choose the next action <ref> [4] </ref>. It is important not to become so wrapped up in diagnosing the student's misconceptions that we lose sight of our goal. <p> Their work is significant because of the experimental data (human tutorial dialogs) on which it is based. The control structure used in the object-oriented architecture of Bonar et al. <ref> [4] </ref> uses a similar scheme. They have a stack on which TutoringMode objects are stored. Each Tutor-ingMode object includes a satisfaction criteria and a floundering threshold. <p> The satisfaction criteria determines when the TutoringMode object can be popped, while the floundering threshold determines when a remedial object should be pushed onto the stack. They currently have six modes, including exploration, experimentation, elaboration, didactic, demonstration, and VII DISCOURSE MANAGEMENT 22 coaching <ref> [4] </ref>. tdus [47], an acronym for Task-oriented Dialog Understanding System, is a natural language understanding system built at SRI International as part of research into the knowledge structures and reasoning mechanisms needed to guide a human apprentice through a task.
Reference: [5] <author> J.S. Brown, R.R. Burton, and F. Zydbel, </author> <title> "A Model-Driven Question-Answering System for Mixed-Initiative Computer-Assisted Instruction," </title> <journal> IEEE Trans. Systems, Man, and Cybernetics, </journal> <volume> Vol. 3, No. 3, </volume> <pages> pp. 248-257, </pages> <year> 1973. </year>
Reference-contexts: The semantic network has a rich history of use in intelligent tutoring and continues in popularity today. Brown et al. <ref> [5] </ref> discuss the use of a semantic net to store factual knowledge and an augmented finite automata structure for describing causal process relationships.
Reference: [6] <author> J.S. Brown, R.R. Burton, and J. deKleer, </author> <title> "Pedagogical, Natural Language and Knowledge Engineering Techniques in SOPHIE I, II and III," in Intelligent Tutoring Systems (eds. </title> <editor> Sleeman and Brown). </editor> <address> Cambridge, MA: </address> <publisher> Academic Press, </publisher> <year> 1982, </year> <pages> pp. 227-282. </pages>
Reference-contexts: Both learning scenarios offer unique advantages and disadvantages, however, and each introduces its own architectural requirements. Another popular instructional paradigm is that of the articulate expert exemplified by the famous sophie systems <ref> [6] </ref>. sophie 2 is designed to teach students about troubleshooting electronic circuits by allowing them to view the tutor solving problems before they are given their own problems. <p> Obviously, one component of such a system is a simulation, so the challenge is the integration of this simulation with the rest of the tutoring system. The sophie systems teach electronic troubleshooting and hence include a circuit simulator. Brown et al. <ref> [6] </ref> report that the simulator used in sophie ii requires careful use since violation of the assumptions on which it depends could yield unexpected and inaccurate results. <p> To deal with this problem, sophie ii uses pieces of code termed procedural experts which know how to run the simulator, how to use the results, and what the limitations are <ref> [6] </ref>. steamer [29], the interactive, inspectable, simulation-based tutor described earlier, is connected to a detailed mathematical simulation of a steam propulsion system. The steamer graphical editor allows graphics objects to be tied to the underlying simulation. <p> They report the development of "a frame-based representation system 4 that supports multiple perspectives and permits an integration of the vast amount of structural, functional, topological, and graphical information contained within steamer" [29]. sophie iii <ref> [6] </ref>, the successor to sophie ii referenced above, takes a different approach to simulation than its predecessor. While sophie ii used a black-box circuit simulator with procedural experts as the glue between the simulator and tutoring system, sophie iii includes specially-designed circuit simulation techniques which are more articulate. <p> By propagating values from known measurements (i.e., current or voltage) through the many constraints in the circuit, sophie iii can predict measurements at other points. Furthermore, these inferences can be recorded as they are made so that sophie can justify the predictions to the student <ref> [6] </ref>. Such an articulate simulation has pedagogical benefits which far exceed a simple black-box simulator. Besides its use of scripts, why [55, 58] also makes use of constraint-based reasoning, in this case to describe functional relationships at work in processes. <p> however, have allowed true natural language input. scholar included rich natural language facilities that allowed it to understand most student questions and answers. sophie used a technique called semantic grammars, in which the basic idea is to look for understandable fragments in the input rather than parse the entire sentence <ref> [6] </ref>. Most other systems have bypassed the natural language problem by using graphical or menu-based input.
Reference: [7] <author> J.S. Brown, R.R. Burton, and W.J. Clancey, </author> <title> "Applications of AI to Training and Education," AAAI-84 Tutorial No. </title> <type> 2, </type> <institution> Austin, TX, </institution> <year> 1984. </year>
Reference-contexts: The knowledge required by the tutoring system is minimal on either ends of this spectrum, but increases towards the middle <ref> [7] </ref>. Evidence suggests that learned information is retained longer if the student is an active participant in the learning process (rather than a passive "absorber") and if the presentation II LEARNING SCENARIOS 3 involves several of the student's senses.
Reference: [8] <author> J.S. Brown and Gary Moskowitz, </author> <title> "AI: Windows of Opportunity in Office Automation," </title> <institution> Xerox Corporation, </institution> <month> July </month> <year> 1985. </year> <note> REFERENCES 29 </note>
Reference-contexts: One particularly popular form of instructional philosophy is that of the computer coach [22]. Brown and Moskowitz sum up the coaching scenario as follows: "At your request, the intelligent coach `looks over your shoulder' while you attempt to carry out tasks, offering timely but unobtrusive advice" <ref> [8] </ref>. One advantage of computer coaches is that training becomes more cost-effective since the coach is available at the convenience of the student and thus off-site learning is minimized. <p> The coach is available not just for formal training, but also to help out during normal work activities, saving the user time that might otherwise "be spent thumbing through a manual or waiting for help from a colleague" <ref> [8] </ref>. In this sense, we can see that tutorial ICAI and job aiding need not be mutually exclusive [38, 49]. <p> As Brown and Moskowitz note, "... good teachers don't just mark off points. Rather, they try to determine the student's misunderstandings as the best basis for correcting those misunderstandings" <ref> [8] </ref>. The techniques for student diagnosis are intertwined with student modeling methods; the reader will notice the close connection between topics in section IV and this section. <p> It is guided by strategies and techniques which are selected and combined dynamically in reaction to the student. Therefore, teaching itself can be considered a knowledge-based skill which we can model computationally. In the words of Brown and Moskowitz <ref> [8] </ref>, "... we must formalize the intuitive knowledge that guides good teachers". Instructional strategies deal with choosing an effective presentation method, determining the balance of student and tutor control, governing the amount and timing of feedback, and choosing evaluation criteria with which to judge student competence [20].
Reference: [9] <author> B.G. Buchanan and E.H. Shortliffe, Eds., </author> <title> Rule-Based Expert Systems: The MYCIN Experiments of the Stanford Heuristic Programming Project. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley, </publisher> <year> 1984. </year>
Reference-contexts: The structure and interrelationships of knowledge needed for tutoring are much greater than for typical problem-solving expert systems. This important lesson was clearly demonstrated by research at Stanford University in which they tried to use the famous mycin expert system <ref> [9] </ref> as a tutor for medical students. The resulting system, guidon [14], was shown to be inadequate in many ways, all resulting from mycin's uniform rule-based knowledge representation.
Reference: [10] <author> R.R. Burton and J.S. Brown, </author> <title> "An Investigation of Computer Coaching for Informal Learning Activities," in Intelligent Tutoring Systems (eds. </title> <editor> Sleeman and Brown). </editor> <address> Cambridge, MA: </address> <publisher> Academic Press, </publisher> <year> 1982, </year> <pages> pp. 79-98. </pages>
Reference-contexts: Coaching is most effective in tasks where the student's performance tends to reach plateaus [25]; the exposition of key knowledge often opens up a whole new area for exploration by the student. Gaming environments can combine the characteristics of both coaching and informal discovery learning <ref> [10] </ref>. In such a scenario, a game is designed to teach more general skills. The student learns these skills by applying them in the context of the game and may even discover them through their positive influence on his game position. <p> The prototypical example of a game-based learning scenario is the west system of Burton and Brown <ref> [10] </ref>. west is a computer tutoring system which coaches students through the game "How the West was Won." The game requires students to combine numbers, using arithmetic operators and parentheses, into expressions which evaluate to the number of board positions they would like to move. <p> Proficiency in the game thus requires mathematical as well as tactical skills, and it is the job of the west coach to determine whether or not the student is employing the right skills and when he needs guidance. Their paper <ref> [10] </ref> is an excellent treatise on the issues involved in computer coaching, especially in gaming environments. Many educators have lamented the one-sided nature of CAI. They claim that the student should be allowed to ask questions of the tutor and in general affect the directions of the tutoring session. <p> On the other hand, a computer coach must infer student shortcomings from the context of the game, whereas mixed-initiative dialog systems allow the computer tutor to test hypotheses by asking new questions <ref> [10] </ref>. <p> Goldstein and Papert [23] suggest the use of a "glass-box" expert that can both solve domain problems and explain its reasoning to the student. Burton and Brown <ref> [10] </ref>, on the other hand, state that a "black-box" expert which solves domain problems in the most efficient (albeit possibly obscure) way may be more efficient than a more complex glass-box, articulate expert. <p> This opinion is reflected in scholar, which, in contrast to Wexler's approach, starts with the expert knowledge base as the student model and annotates deviations that are subsequently discovered [13]. Burton and Brown's west tutor <ref> [10] </ref> typifies a skill modeler, which is an overlay modeler in which expert knowledge is represented as skills, and the student is modeled by the set of skills he has mastered (used successfully). They also introduce the notion of differential modeling [10], which is similar to Carbonell's method of modeling explicitly <p> Burton and Brown's west tutor <ref> [10] </ref> typifies a skill modeler, which is an overlay modeler in which expert knowledge is represented as skills, and the student is modeled by the set of skills he has mastered (used successfully). They also introduce the notion of differential modeling [10], which is similar to Carbonell's method of modeling explicitly the differences between expert and student knowledge. <p> While ICAI student modeling techniques are designed to overcome the limitations with CAI tallies of right and wrong answers, such tallies are often still embedded within richer student models. Burton and Brown <ref> [10] </ref> have pointed out the difficulties with keeping such tallies, pointing out that even after a student has mastered an area, this model would continue to reflect his past weaknesses. Pieces of the model should really decay with time, yet the computational costs involved would then be prohibitive. <p> For instance, student shortcomings in discovery learning environments can only be detected through comparison with a computer-based expert, because you need some way of determining when particular knowledge is applicable <ref> [10] </ref>. In their west tutor, Burton and Brown use an "Issue Recognizer" to detect student shortcomings and an "Issue Evaluator" which uses the student V STUDENT DIAGNOSIS 16 model to decide if the student is really lacking the skill or is using an equally valid strategy. <p> Sometimes the student has the correct answer but expresses it in a fundamentally different way [63]. Similarly, in gaming environments, the student may appear to be missing certain skills when instead he is employing a totally different strategy from the expert <ref> [10] </ref>. Finally, Stevens et al. [58] note that sometimes bugs interact, so we must always consider the possibility that an error resulted from a combination of student misconceptions. One of the few techniques which handles multiple bugs is Burton's Buggy model [11]. <p> Perhaps the two most important pedagogical decisions are when to interrupt and what to say <ref> [10] </ref>. There is a distinction between determination of what to say (the content) and the actual choice of words and input/output behavior of the machine. <p> number of human tutorial dialogs and present a detailed theory in the form of condition/action rules of the goals, strategies, and priorities that guide an VI PEDAGOGICAL KNOWLEDGE 19 * "If the student is about to lose interrupt and tutor him only with moves that will keep him from losing" <ref> [10] </ref>. * "If (1) a student proposes a rule or makes a prediction based on one or more factors that are insufficient, or (2) is entrapped by a rule (ens 1 or ens 9) based on one or more factors that are insufficient, then (3) pick a case that has the <p> In a less detailed way, Burton and Brown <ref> [10] </ref> list twelve general guidelines that tutoring systems should follow. To give a general feel for the content of various systems' instructional strategies, Figure 3 lists some example rules. As a further perspective on instructional strategies, we can survey some of the conclusions reached through other research efforts. <p> However, it is interesting to note the similarities across domains and learning scenarios. Many researchers have investigated the tradeoffs between correcting a student explicitly, trying to entrap him into discovering the error himself, and simply letting him make mistakes and view the consequences. Burton and Brown <ref> [10] </ref> discuss this point at length, pointing out that "every time the Coach tells the student something, it is robbing him of the opportunity to discover it for himself." Their paper points out the importance of allowing students to observe the results of incorrect decisions. <p> In Woolf's rbt, tutor output is created by extracting text from emergency-specific text files which are loaded when the emergency is invoked [65]. In west, textual explanations are attached to each issue (skill); each issue is responsible for presenting a few lines of text explaining itself <ref> [10] </ref>. west therefore distributes prestored text to the actual knowledge structures and combines the text dynamically to fit the situation.
Reference: [11] <author> R.R. Burton, </author> <title> "Diagnosing Bugs in a Simple Procedural Skill," in Intelligent Tutoring Systems (eds. </title> <editor> Sleeman and Brown). </editor> <address> Cambridge, MA: </address> <publisher> Academic Press, </publisher> <year> 1982, </year> <pages> pp. 157-183. </pages>
Reference-contexts: All these methods are variants of the basic overlay modeling paradigm. Other domains, however, have been shown to defy simple overlay modeling techniques. The research described by Burton <ref> [11] </ref> clearly indicates that the bizarre nature of children's arithmetic bugs suggests that no subset of the expert's knowledge could explain the incorrect procedures used by novices. Instead, Burton's Buggy model employs both correct and "buggy" rules which the student may be following [11]. <p> The research described by Burton <ref> [11] </ref> clearly indicates that the bizarre nature of children's arithmetic bugs suggests that no subset of the expert's knowledge could explain the incorrect procedures used by novices. Instead, Burton's Buggy model employs both correct and "buggy" rules which the student may be following [11]. Understanding a student's error then becomes a task of finding a suitable combination of these correct and buggy rules which together would produce the same incorrect answer as was produced by the student. <p> Finally, Stevens et al. [58] note that sometimes bugs interact, so we must always consider the possibility that an error resulted from a combination of student misconceptions. One of the few techniques which handles multiple bugs is Burton's Buggy model <ref> [11] </ref>. In this model, the system has rules corresponding to both correct domain skills and typical buggy techniques. Applying this model to subtraction, Burton built procedural networks [50] of the techniques (both correct and incorrect) needed to perform subtraction.
Reference: [12] <author> R.R. Burton, </author> <title> "The Environment Module of Intelligent Tutoring Systems," AFHRL Research Planning Forum for Intelligent Tutoring Systems, </title> <address> San Antonio, TX, </address> <month> September </month> <year> 1986. </year>
Reference: [13] <author> J.R. Carbonell, </author> <title> "AI in CAI: An Artificial Intelligence Approach to Computer-Assisted Instruction," </title> <journal> IEEE Trans. Man-Machine Systems, </journal> <volume> Vol. 11, No. 4, </volume> <pages> pp. 190-202, </pages> <month> December </month> <year> 1970. </year>
Reference-contexts: They claim that the student should be allowed to ask questions of the tutor and in general affect the directions of the tutoring session. In 1970, Jaime Carbonell launched the field of ICAI by using AI techniques to build a mixed-initiative tutoring system. His seminal tutor, scholar <ref> [13] </ref>, tutors students in geography by carrying on a natural language dialog with the student in which the student can respond to II LEARNING SCENARIOS 4 computer questions or initiate a line of questioning which scholar must answer. <p> Carbonell emphasizes the benefits of mixed-initiative tutorial dialog, pointing out that it results in a more reactive tutoring system and that allowance for student initiative is crucial to effective education <ref> [13] </ref>. Closely related to mixed-initiative dialog is the use of the Socratic teaching method [42]. The Greek philosopher Socrates believed that education could not be attained through passive exercises such as reading or listening, but instead came from actual problem solving. <p> is an effective taxonomy of question types, from both a semantic and syntactic point of view?", "What classification of errors should be utilized, if it is to apply regardless of the specific subject matter?", and "What different efficient techniques can possibly be defined and used for diagnostic and remedial purposes?" <ref> [13] </ref>. Although the expert module or domain knowledge of the system does not necessarily have to have the ability to solve problems it poses to the student, it must at least recognize an incorrect answer [63]. <p> Carbonell sees the semantic network representation being used in the following ways: "answering questions not specifically anticipated, constructing questions on given topics, and generally carrying on a mixed-initiative contextual dialog with a human in a rather free and comfortable subset of English" <ref> [13] </ref>. Obviously, this requires a highly-structured data base in which concepts and facts are connected along many dimensions and in which linguistic information can be embedded. The semantic network knowledge representation fills this need. <p> The semantic network knowledge representation fills this need. Rather than store any specific pieces of text, questions, predicted answers, errors, or branching information, scholar's contribution was that it generated all this from its semantic network of geographic knowledge <ref> [13] </ref>. Each unit of the semantic net is organized as an object with properties. Each property consists of the property name (attribute), a set of tags, and the property value. Values themselves can either be properties or pointers into other units. <p> Furthermore, procedures may be embedded into the network which can use the semantic network to make inferences; an example is a procedure that infers climate from local conditions like latitude and altitude <ref> [13] </ref>. By organizing the information in such an interconnected way, scholar avoids storing information redundantly in the data base, and it can index into the information in a variety of ways, thus supporting a very flexible method of query and reasoning. <p> Reasoning in a semantic net involves a lot of pointer following. In Wexler's system [61], the net is searched (using backtracking) for nodes which satisfy the question skeletons. The search is begun at class nodes and proceeds to the various instances. Carbonell <ref> [13] </ref> notes that Rockart, who uses a semantic network to represent accounting information [48], "makes an interesting use of the semantic representation to find relations via intersections between two concepts in the data base." scholar uses a similar intersection search to answer questions like "Is Buenos Aires in Brazil?" scholar can <p> This allows scholar to relate a student's answer to the correct one and thus realize that if a city with certain characteristics was asked for, the student is not as far off if his answer is an incorrect city as if he answered with some country <ref> [13] </ref>. There are many other techniques for information retrieval in a semantic net, but the point is that, by endowing the executive program with knowledge of the semantics of the various links, most of the facilities needed for effective tutoring are reduced to graph search procedures. <p> Besides representing geographic knowledge, scholar's semantic net represents other world knowledge and even meta-knowledge (knowledge about knowledge). Representing com-monsense knowledge such as reasonable temperatures enables the system to recognize ridiculous answers, such as 200 degrees in response to "What is the average temperature in Minnesota?" <ref> [13] </ref>. In order to reason about the extent of its knowledge, properties are tagged as to whether scholar has complete or incomplete knowledge of them. For instance, I have complete knowledge of my family members, but incomplete knowledge of all AI researchers. <p> Carbonell notes that it would be nice if the relavancy of one node to another was simply the distance betweeen them in a graph-theoretic sense, but it turned out that solution was not refined enough <ref> [13] </ref>. <p> Different approaches have been taken to the construction of the student model. In Wexler's system [61], the student model is constructed as a semantic net, with nodes and links added as they are taught. Carbonell <ref> [13] </ref> states that building a student model from scratch is too inaccurate and that the system should instead start with what it thinks the student knows (perhaps an ideal student) and tweak this model as is necessary. <p> This opinion is reflected in scholar, which, in contrast to Wexler's approach, starts with the expert knowledge base as the student model and annotates deviations that are subsequently discovered <ref> [13] </ref>. Burton and Brown's west tutor [10] typifies a skill modeler, which is an overlay modeler in which expert knowledge is represented as skills, and the student is modeled by the set of skills he has mastered (used successfully). <p> Student diagnosis is similar to other diagnostic tasks such as equipment or disease diagnosis. Carbonell views student errors as symptoms of diseases (misconceptions) and notes that our diagnostic reasoning should operate on an open set of alternatives <ref> [13] </ref>. Koffman and Blount [31] similarly suggest that an intelligent tutoring system should make and test hypotheses concerning the source of student errors, considering his past problems. <p> This is based on a differential model of the student's behavior (as compared with the expert's behavior). Such a differential model is effective only when there is a relatively "... unique and well-defined closed set of correct answers ..." <ref> [13] </ref>. An alternative to differential modeling is direct interpretation of the student's answer in terms of semantic memory, considering the compatibility and relevancy of the answer in relation to the question [13]. <p> model is effective only when there is a relatively "... unique and well-defined closed set of correct answers ..." <ref> [13] </ref>. An alternative to differential modeling is direct interpretation of the student's answer in terms of semantic memory, considering the compatibility and relevancy of the answer in relation to the question [13]. Wexler's system [61], for instance, which stores its domain knowledge in a semantic net, evaluates the student's response by searching the net for nodes which satisfy the conditions of the question. <p> While not everyone subscribes to the Buggy method, most see the need for some sort of error taxonomy. As Stevens et al. [58] so aptly point out, "A good teacher must possess knowledge of the types of misconceptions that arise in the domain being taught". Carbonell <ref> [13] </ref> suggests a taxonomy of errors, which would allow the tutor to determine the significance of various errors, choose appropriate remediation strategies, and notice patterns of related errors in the student's answers/actions. <p> Many people have distinguished between problems local to the immediate topic, problems involving relationships between various topics or pieces of knowledge, and problems that indicate downright confusion on the part of the student. Carbonell <ref> [13] </ref> suggests the following generic error types (which, not surprisingly, have strong ties to semantic net representations): (1) missing information, (2) misfiled fact, (3) wrong entry, (4) lack of a concept, (5) wrong superordinate (superpart or superconcept), (6) overgeneralization, (7) failure to draw some superordinate inference, (8) failure to draw some <p> The Diagnoser then updates the student model, which of course is local to each knowledge Bite, and invokes the Task Selector to choose the next action [4]. It is important not to become so wrapped up in diagnosing the student's misconceptions that we lose sight of our goal. Carbonell <ref> [13] </ref> reminds us that student diagnosis is a means rather than an end and that the real objective is for the student to overcome his misunderstandings, not for the teacher to magically infer them. <p> As has been stated, the general purpose of pedagogical rules is to indicate discourse directions, strategies, and tactics. In the next section, the more global problem of discourse management, of which pedagogical rules are a component, will be considered. VII Discourse Management As Carbonell <ref> [13] </ref> so elegantly put it, "Man-computer interaction is basically a communication between two information structures, including their computational abilities". Without a formal protocol, this communication must be driven by the goals and needs of both parties. <p> Flexibility in the tutorial discourse is a hallmark of ICAI. In scholar, the executive program that uses the semantic network to generate teaching material and questions is almost independent of the subject matter in the semantic net <ref> [13] </ref>. Carbonell [13] discusses the issue of "contextual continuity" and topic coverage, noting that traditional "ad-hoc frame-oriented" (AFO) systems have a large degree of anticipation (they know what they are going to do next), while scholar has almost none (it is very reactive). <p> Flexibility in the tutorial discourse is a hallmark of ICAI. In scholar, the executive program that uses the semantic network to generate teaching material and questions is almost independent of the subject matter in the semantic net <ref> [13] </ref>. Carbonell [13] discusses the issue of "contextual continuity" and topic coverage, noting that traditional "ad-hoc frame-oriented" (AFO) systems have a large degree of anticipation (they know what they are going to do next), while scholar has almost none (it is very reactive). <p> Figure 4 shows her discourse VII DISCOURSE MANAGEMENT 23 management network. Work in discourse management for tutorial purposes has thus followed several distinct transitions. In a backlash against the very deterministic branching structure of early CAI systems, Carbonell's scholar <ref> [13] </ref> included a very loose organization of tutorial goals and basically just reacted to the student. Work by Stevens and Collins [55] showed that human tutors maintain an agenda of goals and that the challenge is to add and remove goals from this agenda in a last-in-first-out (LIFO) manner. <p> Thus, no text is canned in scholar, and all sentences and questions are processed completely from the semantic internal representation into English <ref> [13] </ref>. Another approach to text generation, intended for use in explanation and tutoring, was recently developed by Perry Miller [34]. His prosenet is an atn-based approach to text generation. Each arc in the atn has three components.
Reference: [14] <author> W.J. Clancey, </author> <title> "Tutoring," in Rule-Based Expert Systems (eds. Buchanan and Shortliffe). </title> <address> Reading, MA: </address> <publisher> Addison-Wesley, </publisher> <year> 1984, </year> <title> Part 8. </title>
Reference-contexts: This important lesson was clearly demonstrated by research at Stanford University in which they tried to use the famous mycin expert system [9] as a tutor for medical students. The resulting system, guidon <ref> [14] </ref>, was shown to be inadequate in many ways, all resulting from mycin's uniform rule-based knowledge representation. <p> examination of a single topic, to a shallow examination of a number of topics" [64]. * "IF: The recent context of the dialog mentioned either a `deeper subgoal' or a factor relevant to the current goal THEN: Define the focus rule to be the d-rule that mentions this focus topic" <ref> [14] </ref>. effective teacher. In a less detailed way, Burton and Brown [10] list twelve general guidelines that tutoring systems should follow. To give a general feel for the content of various systems' instructional strategies, Figure 3 lists some example rules.
Reference: [15] <author> W.J. Clancey, </author> <title> "From Guidon to Neomycin and Heracles in Twenty Short Lessons," </title> <journal> AI Magazine, </journal> <volume> Vol. VII, No. 3, </volume> <pages> pp. 40-60, </pages> <note> Conference 1986. </note>
Reference: [16] <author> W.J. Clancey, </author> <title> "Methodology for Building an Intelligent Tutoring System," </title> <booktitle> in Artificial Intelligence and Instruction (ed. </booktitle> <address> Kearsley). Reading, MA: </address> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: In building mycin, we did not make explicit how an expert organizes his knowledge, how he remembers it, and strategies he uses for approaching problems. We need to be able to articulate how the rules fit together, how they are constructed" <ref> [16] </ref>. A tutoring system, then, needs not only knowledge of its domain, but also the perspective on this knowledge that allows it to convey it to the student. <p> The criticism of rule-based approaches has been that their uniformity masks the underlying abstractions and cognitive models of the domain necessary for teaching <ref> [16] </ref>. While most ICAI systems revolve around their knowledge representation, some attempts have been made to combine heterogeneous knowledge in a more modular architecture.
Reference: [17] <author> M. Edwards, </author> <title> "The Mercedes Benz of Interactive Video," </title> <journal> Hardcopy, </journal> <volume> Vol. 14, No. 5, </volume> <pages> pp. 74-80, </pages> <month> May </month> <year> 1985. </year>
Reference-contexts: One study reports that people retain about 25 percent of what they hear, 45 percent of what they see and hear, and 70 percent of what they see, hear, and do <ref> [17] </ref>. Experts in diverse fields suggest that true understanding of knowledge gained from formal training comes when the student later combines that knowledge with actual experience and application [38, 53]. <p> As was stated earlier, one study reports that people retain about twenty-five percent of what they hear, forty-five percent of what they see and hear, and seventy percent of what they see, hear, and do <ref> [17] </ref>. This is a strong argument for user interfaces that include not only text but also visually exciting graphics and the ability for the user to interact with the graphical environment as though he were a part of it.
Reference: [18] <editor> E.A. Feigenbaum and A. Barr, Eds., </editor> <booktitle> The Handbook of Artificial Intelligence, </booktitle> <volume> Vol. </volume> <pages> 2. </pages> <address> Los Altos, CA: </address> <publisher> William Kaufmann Inc., </publisher> <year> 1982, </year> <note> Chapter 9. </note>
Reference-contexts: Having been through this process, the author will present in this paper this latter perspective so that the designers of future ICAI systems can readily leverage the lessons learned by their predecessors. The interested reader is referred to Fletcher [19], Feigenbaum and Barr <ref> [18] </ref>, and Park et al. [40] for good surveys of past ICAI systems, and to Park et al. [40] for an extensive comparison of CAI and ICAI. II Learning Scenarios A learning scenario is the situation in which the student's learning is to take place. <p> representation to find relations via intersections between two concepts in the data base." scholar uses a similar intersection search to answer questions like "Is Buenos Aires in Brazil?" scholar can determine what two things have in common by searching both their superp (superpart) or superc (superconcept) links for an intersection <ref> [18] </ref>. This allows scholar to relate a student's answer to the correct one and thus realize that if a city with certain characteristics was asked for, the student is not as far off if his answer is an incorrect city as if he answered with some country [13]. <p> Stevens and Collins [56] argue further that a good human tutor doesn't follow a prespec-ified syllabus, but instead lets the responses and misconceptions of the student drive the dialog. The tutor should "opportunistically adapt material to the needs of the dialog" <ref> [18] </ref>. While traditional CAI efforts notoriously hardcoded the syllabus (allowing prespecified branches based on predicted student responses), this problem of discourse management and topic selection has been addressed at some level by most ICAI efforts. Flexibility in the tutorial discourse is a hallmark of ICAI. <p> In sophie, each concept has an associated grammar rule that provides alternate ways of expressing the concept in terms of other concepts <ref> [18] </ref>. Thus, none of these systems generates English from deep linguistic knowledge. One of the few tutoring systems to incorporate rich natural language generation mechanisms is scholar. Carbonell separated question generation into two distinct levels: semantic and syntactic.
Reference: [19] <author> J.D. Fletcher, </author> <title> "Intelligent Instructional Systems in Training," </title> <booktitle> in Applications in Artificial Intelligence (ed. Andriole). </booktitle> <address> Princeton, NJ: </address> <publisher> Petrocelli, </publisher> <year> 1984. </year>
Reference-contexts: Having been through this process, the author will present in this paper this latter perspective so that the designers of future ICAI systems can readily leverage the lessons learned by their predecessors. The interested reader is referred to Fletcher <ref> [19] </ref>, Feigenbaum and Barr [18], and Park et al. [40] for good surveys of past ICAI systems, and to Park et al. [40] for an extensive comparison of CAI and ICAI. II Learning Scenarios A learning scenario is the situation in which the student's learning is to take place.
Reference: [20] <author> R.S. Freedman and J.P. Rosenking, </author> <title> "Designing Computer-Based Training Systems: </title> <journal> OBIE-1:KNOBE," IEEE Expert, </journal> <pages> pp. 31-38, </pages> <month> Summer </month> <year> 1986. </year>
Reference-contexts: The most important criterion with which to view a learning scenario is the balance of control between student and tutor. Along this dimension, learning scenarios range from the simple "rule-example-practice" paradigm used in traditional frame-oriented CAI programs to controllable simulation to mixed-initiative dialog to discovery learning <ref> [20] </ref>. This dimension forms a continuous spectrum from frame-based CAI, in which the student can't explore things of interest, to open-ended discovery environments, such as logo [39], in which the student may get stuck or waste a lot of time. <p> Instructional strategies deal with choosing an effective presentation method, determining the balance of student and tutor control, governing the amount and timing of feedback, and choosing evaluation criteria with which to judge student competence <ref> [20] </ref>. Perhaps the two most important pedagogical decisions are when to interrupt and what to say [10]. There is a distinction between determination of what to say (the content) and the actual choice of words and input/output behavior of the machine.
Reference: [21] <author> M.R. Genesereth, </author> <title> "The Role of Plans in Intelligent Teaching Systems," in Intelligent Tutoring Systems (eds. </title> <editor> Sleeman and Brown). </editor> <address> Cambridge, MA: </address> <publisher> Academic Press, </publisher> <year> 1982, </year> <pages> pp. 137-155. </pages>
Reference-contexts: Also, this method requires an explicit enumeration of possible bugs, which certainly runs counter to Carbonell's opinions. Similar in spirit to the Buggy model, Genesereth suggests evaluation of student actions through plan recognition <ref> [21] </ref>.
Reference: [22] <author> I.P. Goldstein, </author> <title> "The Computer as Coach: An Athletic Paradigm for Intellectual Education," AI Memo 389, </title> <publisher> MIT, </publisher> <address> Cambridge, MA, </address> <year> 1976. </year>
Reference-contexts: This explains the more ambitious computer learning scenarios that will be described in this section. One particularly popular form of instructional philosophy is that of the computer coach <ref> [22] </ref>. Brown and Moskowitz sum up the coaching scenario as follows: "At your request, the intelligent coach `looks over your shoulder' while you attempt to carry out tasks, offering timely but unobtrusive advice" [8].
Reference: [23] <author> I.P. Goldstein and S. </author> <title> Papert, </title> <journal> "Artificial Intelligence, Language, and the Study of Knowledge," Cognitive Science, </journal> <volume> Vol. 1, No. 1, </volume> <pages> pp. 84-123, </pages> <year> 1977. </year> <note> Also AI Memo 337, </note> <institution> MIT, </institution> <address> Cam-bridge, MA, </address> <month> March </month> <year> 1976. </year> <note> REFERENCES 30 </note>
Reference-contexts: Although the expert module or domain knowledge of the system does not necessarily have to have the ability to solve problems it poses to the student, it must at least recognize an incorrect answer [63]. Goldstein and Papert <ref> [23] </ref> suggest the use of a "glass-box" expert that can both solve domain problems and explain its reasoning to the student.
Reference: [24] <author> I.P. Goldstein, "Overlays: </author> <title> A Theory of Modelling for Computer Aided Instruction," AI Memo 406, </title> <publisher> MIT, </publisher> <address> Cambridge, MA, </address> <month> February </month> <year> 1977. </year>
Reference-contexts: Ira Goldstein of MIT introduced the now widely-used method of Overlay Modeling, in which the student's knowledge is viewed in terms of the tutor's domain knowledge; that is, the student model is embedded (conceptually anyway) in the tutor's knowledge <ref> [24] </ref>. This permits IV STUDENT MODELING 14 an easy comparison between that which the student knows and that which he should know. Of course, annotating the tutor's knowledge base with student model information implies that there is a knowledge base to annotate, which explains the simpler models used in CAI.
Reference: [25] <author> I.P. Goldstein, </author> <title> "Developing a Computational Representation for Problem Solving Skills," AI Memo 495, </title> <publisher> MIT, </publisher> <address> Cambridge, MA, </address> <month> October </month> <year> 1978. </year>
Reference-contexts: In this sense, we can see that tutorial ICAI and job aiding need not be mutually exclusive [38, 49]. Coaching is most effective in tasks where the student's performance tends to reach plateaus <ref> [25] </ref>; the exposition of key knowledge often opens up a whole new area for exploration by the student. Gaming environments can combine the characteristics of both coaching and informal discovery learning [10]. In such a scenario, a game is designed to teach more general skills. <p> Carbonell notes that it would be nice if the relavancy of one node to another was simply the distance betweeen them in a graph-theoretic sense, but it turned out that solution was not refined enough [13]. Although not included in scholar, Goldstein <ref> [25] </ref> suggests that an estimate of cognitive complexity for different tasks should be maintained so the presentation and necessary remediation for that topic can reflect the expected difficulty the student will have; the tutor should know if it is teaching a hard task or an easy one. <p> Such rules, which model behavior as "recognize a condition, initiate an action," have long been considered as a possible model of human intelligence and thus serve as the domain knowledge for many different tutoring systems. One example is Goldstein's wumpus tutor <ref> [25] </ref>. This tutor serves as a coach for students playing "Hunt the Wumpus," a game requiring mathematical and logical skills whose goal is to find and kill the deadly Wumpus in a dark cave filled with many perils. <p> He suggested the explicit representation of intermediate forms of knowledge such as specialized rules that the student may discover before he recognizes the general form. Goldstein uses a genetic graph exposing relationships between intermediate and mature pieces of knowledge such as analogy links, specialization links, etc. <ref> [25, 26] </ref>. Different approaches have been taken to the construction of the student model. In Wexler's system [61], the student model is constructed as a semantic net, with nodes and links added as they are taught. <p> They also introduce the notion of differential modeling [10], which is similar to Carbonell's method of modeling explicitly the differences between expert and student knowledge. As mentioned earlier, Goldstein's wumpus tutor <ref> [25] </ref> includes intermediate forms of knowledge linked with the expert knowledge in a genetic graph [26] and therefore can model the student not only on his mastery of the expert knowledge but also on his progress toward this mastery. All these methods are variants of the basic overlay modeling paradigm.
Reference: [26] <author> I.P. Goldstein, </author> <title> "The Genetic Graph: A Representation for the Evolution of Procedural Knowledge," in Intelligent Tutoring Systems (eds. </title> <editor> Sleeman and Brown). </editor> <address> Cambridge, MA: </address> <publisher> Academic Press, </publisher> <year> 1982, </year> <pages> pp. 51-77. </pages>
Reference-contexts: He suggested the explicit representation of intermediate forms of knowledge such as specialized rules that the student may discover before he recognizes the general form. Goldstein uses a genetic graph exposing relationships between intermediate and mature pieces of knowledge such as analogy links, specialization links, etc. <ref> [25, 26] </ref>. Different approaches have been taken to the construction of the student model. In Wexler's system [61], the student model is constructed as a semantic net, with nodes and links added as they are taught. <p> They also introduce the notion of differential modeling [10], which is similar to Carbonell's method of modeling explicitly the differences between expert and student knowledge. As mentioned earlier, Goldstein's wumpus tutor [25] includes intermediate forms of knowledge linked with the expert knowledge in a genetic graph <ref> [26] </ref> and therefore can model the student not only on his mastery of the expert knowledge but also on his progress toward this mastery. All these methods are variants of the basic overlay modeling paradigm. Other domains, however, have been shown to defy simple overlay modeling techniques.
Reference: [27] <author> R. Guindon and P. Sladky, </author> <title> "Analysis of User-Expert Dialogues: Task Networks, Subdia-logue Boundary Markers and Antecedent Distribution," </title> <type> MCC Technical Report Number HI-084-85, </type> <institution> Microelectronics and Computer Technology Corporation, Austin, TX, </institution> <month> December </month> <year> 1985. </year>
Reference: [28] <author> H.M. Halff, </author> <title> "Curriculum and Instruction in Automated Tutors," AFHRL Research Planning Forum for Intelligent Tutoring Systems, </title> <address> San Antonio, TX, </address> <month> September </month> <year> 1986. </year>
Reference-contexts: Most other systems have bypassed the natural language problem by using graphical or menu-based input. It is worthy to note that experts in the field of intelligent tutoring have labeled natural language the "Achilles' heel" of potential tutoring systems <ref> [2, 28] </ref>, and warn against its use because of its potential to consume project resources. However, it is often difficult to provide adequately-flexible interactions with the student without some level of natural language.
Reference: [29] <author> J.D. Hollan, E.L. Hutchins, and L. Weitzman, "STEAMER: </author> <title> An Interactive Inspectable Simulation-Based Training System," </title> <journal> AI Magazine, </journal> <volume> Vol. 5, No. 2, </volume> <pages> pp. 15-27, </pages> <month> Summer </month> <year> 1984. </year>
Reference-contexts: Also, by thrusting the student into the ultimate performance environment, and coaching him into the right actions, the student will be more likely to carry his training into real-life situations. steamer <ref> [29] </ref> is the archetypal example of an interactive, inspectable simulation. Although steamer grew into more generic tools, its original purpose was to provide simulation-based instruction on the workings of a basic steam propulsion system. It is interactive in that students can manipulate controls and see their effect. <p> Its authors coined the expression "dynamic graphical explanations" to describe steamer's style of instruction, noting that "relationships that are difficult to describe unambiguously in words are often easily depicted graphically" <ref> [29] </ref>. In a more recent attempt at simulation-based training, Beverly Woolf built a tutoring system for the Kraft recovery boiler whose goal "is to challenge an operator to solve boiler problems and to maintain his incentive to play with the tutor" [65]. <p> The authors of steamer raise an important point about simulation-based training. It is not enough to simply present the simulation as a black box with which the student can play. The training tool must provide conceptual fidelity <ref> [29] </ref>; that is, the information must be presented to the student in a way that helps him build the correct cognitive constructs for thinking about the domain. These cognitive constructs need not accurately model the internal behavior of the domain, but should instead reflect the way experts think about it. <p> To deal with this problem, sophie ii uses pieces of code termed procedural experts which know how to run the simulator, how to use the results, and what the limitations are [6]. steamer <ref> [29] </ref>, the interactive, inspectable, simulation-based tutor described earlier, is connected to a detailed mathematical simulation of a steam propulsion system. The steamer graphical editor allows graphics objects to be tied to the underlying simulation. <p> The steamer graphical editor allows graphics objects to be tied to the underlying simulation. They allow icons to reflect the value or state of various simulation variables and also permit the user to change variables by clicking on these icons. Hollan et al. <ref> [29] </ref> discuss the difficult problems of this so-called "tapping." In an effort to achieve the conceptual fidelity mentioned in Section II, steamer also represents operating procedures in a form that allows explanation at different hierarchical levels, and it associates operating procedures with their underlying engineering principles. <p> They report the development of "a frame-based representation system 4 that supports multiple perspectives and permits an integration of the vast amount of structural, functional, topological, and graphical information contained within steamer" <ref> [29] </ref>. sophie iii [6], the successor to sophie ii referenced above, takes a different approach to simulation than its predecessor. <p> This is a strong argument for user interfaces that include not only text but also visually exciting graphics and the ability for the user to interact with the graphical environment as though he were a part of it. The authors of the steamer paper <ref> [29] </ref> feel that graphical depiction of causal relationships and topology are very important and that some concepts can be elucidated through graphical animation which defy textual explanation.
Reference: [30] <author> W.B. Johnson, </author> <title> "Pragmatic Considerations in Development and Implementation of Intelligent Tutoring Systems," AFHRL Research Planning Forum for Intelligent Tutoring Systems, </title> <address> San Antonio, TX, </address> <month> September </month> <year> 1986. </year>
Reference: [31] <author> E.B. Koffman and S.E. </author> <title> Blount, </title> <journal> "Artificial Intelligence and Automatic Programming in CAI," Artificial Intelligence, </journal> <volume> Vol. 6, </volume> <pages> pp. 215-234, </pages> <year> 1975. </year>
Reference-contexts: Student diagnosis is similar to other diagnostic tasks such as equipment or disease diagnosis. Carbonell views student errors as symptoms of diseases (misconceptions) and notes that our diagnostic reasoning should operate on an open set of alternatives [13]. Koffman and Blount <ref> [31] </ref> similarly suggest that an intelligent tutoring system should make and test hypotheses concerning the source of student errors, considering his past problems. <p> VII DISCOURSE MANAGEMENT 21 As ICAI research developed, more sophisticated discourse control schemes were utilized. Koffman and Blount <ref> [31] </ref> briefly describe a control scheme based around a student model and a concept tree of prerequisites. The system, based on the student model, determines whether the student prefers to advance quickly to new material or build a solid foundation on current material. <p> The system, based on the student model, determines whether the student prefers to advance quickly to new material or build a solid foundation on current material. Based on the student model, the system "decides at which plateau of the concept tree the student should be working" <ref> [31] </ref>. The concepts on this plateau are evaluated with respect to recency of use, the student's progression, his current knowledge, the impact of the concept on his current knowledge, and relevance to other concepts. <p> Problem generation can be viewed as a tree-structured decision process in which each level represents another decision on what to include in the problem, each branch represents one alternative, and the branches can be augmented with probabilities based on the student's competence and prior experience <ref> [31] </ref>. Koffman and Blount [31] go into some detail on such a generative scheme, pointing out the need to avoid regenerating problems the student has solved. <p> Problem generation can be viewed as a tree-structured decision process in which each level represents another decision on what to include in the problem, each branch represents one alternative, and the branches can be augmented with probabilities based on the student's competence and prior experience <ref> [31] </ref>. Koffman and Blount [31] go into some detail on such a generative scheme, pointing out the need to avoid regenerating problems the student has solved.
Reference: [32] <author> E.B. Koffman and J.M. Perry, </author> <title> "A Model for Generative CAI and Concept Selection," </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> Vol. 8, </volume> <pages> pp. 397-410. </pages>
Reference-contexts: While early attempts at problem generation substituted values for variables in canned question templates, later efforts generated problems from deeper structures, yielding a richer mix of problems which were potentially better suited to the student's needs <ref> [32] </ref>. As work progressed, people noticed the applicability of AI techniques and the suitability of rich knowledge representations as a base from which to both generate and solve problems.
Reference: [33] <author> M.L. Miller and I.P. Goldstein, "PAZATN: </author> <title> A Linguistic Approach to Automatic Analysis of Elementary Programming Protocols," AI Memo 388, </title> <publisher> MIT, </publisher> <address> Cambridge, MA, </address> <month> December </month> <year> 1976. </year>
Reference-contexts: Besides natural language parsing, atn's have been used in many other contexts including natural language generation [34] and plan recognition in a programming tutor <ref> [33] </ref>. Woolf's dmn is isomorphic to an atn but is conceptually a top-down refinement of tutorial goals through the strategies and tactics which implement them.
Reference: [34] <author> P.L. Miller, </author> <title> A Critiquing Approach to Expert Computer Advise: </title> <address> ATTENDING. Boston, MA: </address> <publisher> Pitman Advanced Publishing Program, </publisher> <year> 1984. </year>
Reference-contexts: Besides natural language parsing, atn's have been used in many other contexts including natural language generation <ref> [34] </ref> and plan recognition in a programming tutor [33]. Woolf's dmn is isomorphic to an atn but is conceptually a top-down refinement of tutorial goals through the strategies and tactics which implement them. <p> Thus, no text is canned in scholar, and all sentences and questions are processed completely from the semantic internal representation into English [13]. Another approach to text generation, intended for use in explanation and tutoring, was recently developed by Perry Miller <ref> [34] </ref>. His prosenet is an atn-based approach to text generation. Each arc in the atn has three components. <p> The system places the information to be conveyed into global registers, and the appropriate prosenet network is activated. To maintain coherency in the text, sentence-level, paragraph-level, and global constraints may be introduced as the text is generated <ref> [34] </ref>. Natural language parsing is another difficult area; even a survey of this area is beyond the scope of this paper.
Reference: [35] <author> J.R. Miller, </author> <title> "Human-Computer Interaction and Intelligent Tutoring Systems," AFHRL Research Planning Forum for Intelligent Tutoring Systems, </title> <address> San Antonio, TX, </address> <month> September </month> <year> 1986. </year> <note> Also MCC Technical Report HI-284-86, </note> <institution> Microelectronics and Computer Technology Corporation, Austin, TX, </institution> <month> September </month> <year> 1986. </year>
Reference: [36] <author> M. Minsky, </author> <title> "A Framework for Representing Knowledge," in The Psychology of Computer Vision (ed. </title> <editor> Patrick Winston). </editor> <address> New York: </address> <publisher> McGraw-Hill, </publisher> <year> 1975. </year> <note> Also in Readings in Knowledge Representation (eds. </note> <editor> Brachman and Levesque). </editor> <address> Los Altos, CA: </address> <publisher> Morgan Kaufmann, </publisher> <year> 1985. </year> <note> REFERENCES 31 </note>
Reference-contexts: Problems can be generated which provide all necessary inputs but one. The constraint can infer the remaining one and compare this with the student's answer. The constraint knows how to describe itself in the abstract and 4 Frames <ref> [36] </ref> are really very similar to semantic nets, although the two have different conceptualizations. While a semantic net is a graph of nodes and links, a frame encodes the same information in structures with slots.
Reference: [37] <author> T. Moran, D.M. Russell, D.S. Jordan, F. Halasz, J. Orr, and J. Shrager, </author> <title> "ARI Project Phase 1 Report: Problems in Training and Procedure-Oriented Job Performance Aids," </title> <note> Xerox PARC Internal Report, </note> <institution> Intelligent Systems Lab, </institution> <address> Palo Alto, CA, </address> <month> October </month> <year> 1984. </year>
Reference-contexts: A tutoring system must therefore present procedural skills at varying levels of abstraction and should explain actions in terms of their causal effects in the domain. For instance, in the Fault Isolation Procedure (fip) tutor <ref> [38, 37] </ref>, the current goal hierarchy is maintained. Tracing up this goal hierarchy answers the question "Why am I doing this action?". This goal-oriented perspective, along with qualitative, causal knowledge 2 There are actually three distinct SOPHIE systems, known as SOPHIE I, II, and III.
Reference: [38] <editor> L.H. Nawrocki, </editor> <booktitle> "Artificial Intelligence Applications to Maintenance Training," in Artificial Intelligence and Instruction (ed. </booktitle> <address> Kearsley). Reading, MA: </address> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: Experts in diverse fields suggest that true understanding of knowledge gained from formal training comes when the student later combines that knowledge with actual experience and application <ref> [38, 53] </ref>. Indeed, the backlash against traditional CAI has focused on the passive role of the student and has prompted educators and instructional designers to seek more effective uses of computers for education. This explains the more ambitious computer learning scenarios that will be described in this section. <p> In this sense, we can see that tutorial ICAI and job aiding need not be mutually exclusive <ref> [38, 49] </ref>. Coaching is most effective in tasks where the student's performance tends to reach plateaus [25]; the exposition of key knowledge often opens up a whole new area for exploration by the student. Gaming environments can combine the characteristics of both coaching and informal discovery learning [10]. <p> A tutoring system must therefore present procedural skills at varying levels of abstraction and should explain actions in terms of their causal effects in the domain. For instance, in the Fault Isolation Procedure (fip) tutor <ref> [38, 37] </ref>, the current goal hierarchy is maintained. Tracing up this goal hierarchy answers the question "Why am I doing this action?". This goal-oriented perspective, along with qualitative, causal knowledge 2 There are actually three distinct SOPHIE systems, known as SOPHIE I, II, and III. <p> I speak of them in general under the name SOPHIE. II LEARNING SCENARIOS 5 of how a system works, enables students to fully understand why and when certain actions are appropriate <ref> [38, 53] </ref>. Another way to give students a feel for the causal relationships in a domain is to provide them a simulation of that domain with which they can explore the consequences of their actions without fear of real-life consequences. <p> The interested reader is referred for instance to Sleeman [54]. It should be pointed out that the student model is potentially very open-ended, and its design should therefore be driven by the domain knowledge representation <ref> [38, 41] </ref> and, more importantly, by the needs of the student diagnosis module, which will be discussed in the next section. In order to diagnose student misconceptions and explain student errors, it is necessary to understand his current state of knowledge and past history.
Reference: [39] <author> Seymour Papert, </author> <title> Mindstorms. </title> <address> New York: </address> <publisher> Basic Books, </publisher> <year> 1980. </year>
Reference-contexts: This dimension forms a continuous spectrum from frame-based CAI, in which the student can't explore things of interest, to open-ended discovery environments, such as logo <ref> [39] </ref>, in which the student may get stuck or waste a lot of time. The knowledge required by the tutoring system is minimal on either ends of this spectrum, but increases towards the middle [7].
Reference: [40] <author> O.C. Park, </author> <title> R.S. Perez, and R.J. Seidel, "Intelligent CAI: Old Wine in New Bottles, or a New Vintage?," </title> <booktitle> in Artificial Intelligence and Instruction (ed. </booktitle> <address> Kearsley). Reading, MA: </address> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: Having been through this process, the author will present in this paper this latter perspective so that the designers of future ICAI systems can readily leverage the lessons learned by their predecessors. The interested reader is referred to Fletcher [19], Feigenbaum and Barr [18], and Park et al. <ref> [40] </ref> for good surveys of past ICAI systems, and to Park et al. [40] for an extensive comparison of CAI and ICAI. II Learning Scenarios A learning scenario is the situation in which the student's learning is to take place. <p> The interested reader is referred to Fletcher [19], Feigenbaum and Barr [18], and Park et al. <ref> [40] </ref> for good surveys of past ICAI systems, and to Park et al. [40] for an extensive comparison of CAI and ICAI. II Learning Scenarios A learning scenario is the situation in which the student's learning is to take place. The most important criterion with which to view a learning scenario is the balance of control between student and tutor. <p> Although the ideas developed in this period have been of further use, the techniques were usually limited to simple drill and practice in arithmetic and language vocabulary and were rarely adapted to the student's learning needs <ref> [40] </ref>. While early attempts at problem generation substituted values for variables in canned question templates, later efforts generated problems from deeper structures, yielding a richer mix of problems which were potentially better suited to the student's needs [32].
Reference: [41] <author> P.L. Pirolli and J.G. Greeno, </author> <title> "The Problem Space of Instructional Design," in Intelligent Tutoring Systems: </title> <editor> Lessons Learned (eds. Psotka, Massey, and Mutter). </editor> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1988. </year>
Reference-contexts: The interested reader is referred for instance to Sleeman [54]. It should be pointed out that the student model is potentially very open-ended, and its design should therefore be driven by the domain knowledge representation <ref> [38, 41] </ref> and, more importantly, by the needs of the student diagnosis module, which will be discussed in the next section. In order to diagnose student misconceptions and explain student errors, it is necessary to understand his current state of knowledge and past history.
Reference: [42] <author> Plato, Laches, Protagoras, </author> <title> Meno, </title> <journal> and Euthydemus (trans. </journal> <pages> Lamb). </pages> <address> Cambridge, MA: </address> <publisher> Harvard University Press, </publisher> <year> 1924. </year>
Reference-contexts: Carbonell emphasizes the benefits of mixed-initiative tutorial dialog, pointing out that it results in a more reactive tutoring system and that allowance for student initiative is crucial to effective education [13]. Closely related to mixed-initiative dialog is the use of the Socratic teaching method <ref> [42] </ref>. The Greek philosopher Socrates believed that education could not be attained through passive exercises such as reading or listening, but instead came from actual problem solving.
Reference: [43] <author> J. Psotka, D.B. Pliske, and W.D. Gray, </author> <title> "Intelligent Design Environments and Assistant Systems," </title> <booktitle> Proc. Expert Systems in Government, </booktitle> <month> October </month> <year> 1985. </year>
Reference-contexts: Although there has been much research in ICAI, few if any commercial systems exist due to the current cost of building such systems and the lack of experienced people in the area. As noted by Psotka et al. <ref> [43] </ref>, "When one considers the ICAI systems that have been built to date, one is impressed with the fact that each is somewhat like the work of a craftsman, a combination of technical skill and artistic creativity." ICAI is still very much a research topic, with today's systems suffering the same
Reference: [44] <author> M.R. Quillian, </author> <title> "Semantic Memory," </title> <type> Report AFCRL-66-189, </type> <institution> Bolt Beranek and Newman Inc., </institution> <address> Cambridge, MA, </address> <year> 1966. </year>
Reference-contexts: apply his general knowledge to this specific case. why provides a perfect example of how the domain knowledge and teaching strategies together drive the choice of knowledge representation. scholar, on the other hand, demonstrates the needs of a mixed-initiative, fact-oriented tutoring system. scholar stores its knowledge in a semantic network <ref> [44] </ref>, which is essentially a highly-interconnected network of nodes and links representing objects and their properties.
Reference: [45] <author> S. Ramani and A. Newell, </author> <title> "On the Generation of Problems," </title> <type> SDL 348, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> November </month> <year> 1973. </year>
Reference-contexts: They also make the interesting observation that the tutoring system should solve subproblems for the student that he has already solved before, thus allowing him to concentrate on those aspects of the problem from which he can derive the greatest benefit. Ramani and Newell <ref> [45] </ref> provide a more thorough treatment of problem generation. They suggest that one must first identify and analyze the various sets of problems in the domain and then develop suitable structures from which to generate these sets. <p> Too much information must be specified in the grammar itself, which is not the right level of abstraction <ref> [45] </ref>. They sum up the problems with generative grammars by explaining that problem generation needs semantic information, while grammars bundle syntax and semantics all into syntactic VIII PROBLEM GENERATION 25 structures. <p> While generative grammars are driven by top-down refinement of choices, this new view on problem generation is more constraint based, a paradigm that was later to have profound influence on planning and design research in AI. The basic techniques of Ramani and Newell's <ref> [45] </ref> problem generation theory are relatively simple. The underlying data structure is a semantic net which encodes the types of manipulable objects (i.e., numbers, symbols, sets, and sequences) and relevant attributes of these objects.
Reference: [46] <author> B.J. Reiser, J.R. Anderson, and R.G. Farrell, </author> <title> "Dynamic Student Modelling in an Intelligent Tutor for LISP Programming," </title> <booktitle> Proc. IJCAI-85, </booktitle> <address> Los Angeles, CA, </address> <pages> pp. 8-14, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: The requisite skills are modeled by condition/action rules which choose moves based on probabilistic and logical evidence. When the student makes suboptimal moves, he is postulated to be missing the appropriate rule. More recently, Anderson and Reiser used rules in their respective Geometry [1] and lisp <ref> [46] </ref> tutors. The attractiveness of rules is their modular nature, since each rule is, ideally, independent of all others and thus rules can be added and deleted with only an incremental effect on system performance. <p> The coach's role, in their view, is to intervene when the student is likely to miss the evidence of his error or misconception. Woolf [65] contrasts her philosophy of letting students explore possible wrong paths with Anderson et al. [1] and Reiser et al. <ref> [46] </ref>, whose Geometry and lisp tutors immediately correct student errors. This immediate feedback is justified by its authors because errors in geometry and lisp are so ambiguous and delayed that much fruitless effort could be wasted on erroneous solution paths.
Reference: [47] <author> A.E. Robinson, D.E. Appelt, B.J. Grosz, G.G. Hendrix, and J.J. Robinson, </author> <title> "Interpreting Natural-Language Utterances in Dialogs About Tasks," </title> <type> SRI Memo 210, </type> <institution> SRI International, </institution> <address> Menlo Park, CA, </address> <month> March </month> <year> 1980. </year>
Reference-contexts: The satisfaction criteria determines when the TutoringMode object can be popped, while the floundering threshold determines when a remedial object should be pushed onto the stack. They currently have six modes, including exploration, experimentation, elaboration, didactic, demonstration, and VII DISCOURSE MANAGEMENT 22 coaching [4]. tdus <ref> [47] </ref>, an acronym for Task-oriented Dialog Understanding System, is a natural language understanding system built at SRI International as part of research into the knowledge structures and reasoning mechanisms needed to guide a human apprentice through a task.
Reference: [48] <author> J.F. Rockart, M.S. Morton, and Z.S. Zannetos, </author> <title> "Associative Learning Project - Phase-1 System," </title> <type> Working Paper, </type> <institution> Sloan School of Management, MIT, </institution> <address> Cambridge, MA, </address> <month> January </month> <year> 1970. </year>
Reference-contexts: In Wexler's system [61], the net is searched (using backtracking) for nodes which satisfy the question skeletons. The search is begun at class nodes and proceeds to the various instances. Carbonell [13] notes that Rockart, who uses a semantic network to represent accounting information <ref> [48] </ref>, "makes an interesting use of the semantic representation to find relations via intersections between two concepts in the data base." scholar uses a similar intersection search to answer questions like "Is Buenos Aires in Brazil?" scholar can determine what two things have in common by searching both their superp (superpart)
Reference: [49] <author> D.M. Russell, </author> <title> T.P. Moran, and D.S. Jordan, "The Instructional Design Environment," in Intelligent Tutoring Systems: </title> <editor> Lessons Learned (eds. Psotka, Massey, and Mutter). </editor> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1988. </year>
Reference-contexts: In this sense, we can see that tutorial ICAI and job aiding need not be mutually exclusive <ref> [38, 49] </ref>. Coaching is most effective in tasks where the student's performance tends to reach plateaus [25]; the exposition of key knowledge often opens up a whole new area for exploration by the student. Gaming environments can combine the characteristics of both coaching and informal discovery learning [10].
Reference: [50] <author> E. Sacerdoti, </author> <title> A Structure for Plans and Behavior. </title> <address> New York: </address> <publisher> Elsevier North-Holland, </publisher> <year> 1977. </year> <note> Also SRI Memo 109, SRI International, </note> <month> August </month> <year> 1975. </year>
Reference-contexts: One of the few techniques which handles multiple bugs is Burton's Buggy model [11]. In this model, the system has rules corresponding to both correct domain skills and typical buggy techniques. Applying this model to subtraction, Burton built procedural networks <ref> [50] </ref> of the techniques (both correct and incorrect) needed to perform subtraction. These procedural networks are partially-ordered sequences of arithmetic operations, noting not only when certain skills such as borrowing are needed but also when particular buggy techniques are likely to be used (such as erroneous forms of borrowing). <p> Their thesis was that knowledge of the human's current progress through the task would allow them to disambiguate and therefore understand his questions and comments. Their basic task representation is the procedural network <ref> [50] </ref>, which models the task as a partial order of actions organized into a hierarchy of goals. They also represent the objects which are associated with actions, such as tools or the target of the action.
Reference: [51] <author> R.C. Schank and R. Abelson, </author> <title> Scripts, Plans, Goals, and Understanding. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1977. </year> <note> REFERENCES 32 </note>
Reference-contexts: Therefore, their knowledge dictates a representation which emphasizes causality, while their intended teaching strategy necessitates different levels of abstraction from high-level factors to lower-order ones. The representation which they chose was the script <ref> [51] </ref>; their use of scripts is described in detail in [58].
Reference: [52] <author> R.C. Schank and S. Slade, </author> <title> "Education and Computers: An AI Perspective," </title> <type> Report 431, </type> <institution> Yale University, </institution> <month> October </month> <year> 1985. </year>
Reference-contexts: V Student Diagnosis As Schank and Slade have noted, the opportunity to fail is an important part of learning and one which the computer can readily provide without the fear of peer or teacher judgement <ref> [52] </ref>. But the computer must capitalize on each student failure as an opportunity to correct a misconception.
Reference: [53] <author> J. Shrager, D. Jordan, T. Moran, G. Kizcales, and D.M. Russell, </author> <title> "Pragmatic Issues in Qualitative Modelling: Lessons Learned from Modelling Xerography," </title> <journal> Communications of the ACM, </journal> <volume> Vol. 30, No. 12, </volume> <month> December </month> <year> 1987. </year>
Reference-contexts: Experts in diverse fields suggest that true understanding of knowledge gained from formal training comes when the student later combines that knowledge with actual experience and application <ref> [38, 53] </ref>. Indeed, the backlash against traditional CAI has focused on the passive role of the student and has prompted educators and instructional designers to seek more effective uses of computers for education. This explains the more ambitious computer learning scenarios that will be described in this section. <p> I speak of them in general under the name SOPHIE. II LEARNING SCENARIOS 5 of how a system works, enables students to fully understand why and when certain actions are appropriate <ref> [38, 53] </ref>. Another way to give students a feel for the causal relationships in a domain is to provide them a simulation of that domain with which they can explore the consequences of their actions without fear of real-life consequences.
Reference: [54] <author> D.H. Sleeman, </author> <title> "Assessing Aspects of Competence in Basic Algebra," in Intelligent Tutoring Systems (eds. </title> <editor> Sleeman and Brown). </editor> <address> Cambridge, MA: </address> <publisher> Academic Press, </publisher> <year> 1982, </year> <pages> pp. 185-199. </pages>
Reference-contexts: Student models more complicated than those presented in this section have been devel V STUDENT DIAGNOSIS 15 oped and tested, although they are beyond the scope of this paper. The interested reader is referred for instance to Sleeman <ref> [54] </ref>. It should be pointed out that the student model is potentially very open-ended, and its design should therefore be driven by the domain knowledge representation [38, 41] and, more importantly, by the needs of the student diagnosis module, which will be discussed in the next section.
Reference: [55] <author> A. Stevens and A. Collins, </author> <title> "The Goal Structure of a Socratic Tutor," </title> <type> BBN Report 3518, </type> <institution> Bolt Beranek and Newman Inc., </institution> <address> Cambridge, MA, </address> <year> 1977. </year>
Reference-contexts: Stevens and Collins have explored the use of a Socratic method in their why tutor <ref> [55, 58] </ref>, which tutors students on the causal relationships and factors affecting rainfall. Gaming environments and mixed-initiative dialog scenarios differ in the demands they put on the tutoring system. <p> Many such tradeoffs exist, and it would be foolish to think that one best answer applies to all domains. The choice of knowledge representation in a tutoring system depends on both the type of knowledge to be stored and its intended tutorial use. why <ref> [55, 58] </ref>, for instance, is a Socratic tutoring system which teaches the causal relationships and factors affecting rainfall. Stevens et al. [58] list the sorts of knowledge that are represented in why along with sentences which illustrate each type; these are shown in Figure 2. <p> Furthermore, these inferences can be recorded as they are made so that sophie can justify the predictions to the student [6]. Such an articulate simulation has pedagogical benefits which far exceed a simple black-box simulator. Besides its use of scripts, why <ref> [55, 58] </ref> also makes use of constraint-based reasoning, in this case to describe functional relationships at work in processes. For instance, a process such as evaporation can be modeled by a constraint prototype with actors (the instance variables or terminals which are being constrained). <p> They also developed a sophisticated task selection procedure which uses the various links to guide the sequencing and selection of problems for the student. Note the similarities between this new curriculum net and Goldstein's genetic graph. In <ref> [55] </ref>, Stevens and Collins present a theory of the goal structure of a Socratic tutor based on an analysis of human tutorial dialogs. <p> Woolf points out the absence of any need for a goal agenda, as used by Stevens and Collins <ref> [55] </ref>, and suggests that her approach more closely mirrors the behavior of human tutors [64]. She also claims that her dmn is relatively domain independent, although she acknowledges that it may need some further refinement. Figure 4 shows her discourse VII DISCOURSE MANAGEMENT 23 management network. <p> Work in discourse management for tutorial purposes has thus followed several distinct transitions. In a backlash against the very deterministic branching structure of early CAI systems, Carbonell's scholar [13] included a very loose organization of tutorial goals and basically just reacted to the student. Work by Stevens and Collins <ref> [55] </ref> showed that human tutors maintain an agenda of goals and that the challenge is to add and remove goals from this agenda in a last-in-first-out (LIFO) manner.
Reference: [56] <author> A. Stevens and A. Collins, </author> <title> "Diagnosing Student's Misconceptions in Causal Models," </title> <type> BBN Report 3786, </type> <institution> Bolt Beranek and Newman Inc., </institution> <address> Cambridge, MA, </address> <year> 1978. </year>
Reference-contexts: Each side must not only communicate its knowledge, but must reactively structure its dialog to meet the needs and goals of the other. Effective communication lies not in the words, but rather in the determination of what the tutor and student need to communicate [63]. Stevens and Collins <ref> [56] </ref> argue further that a good human tutor doesn't follow a prespec-ified syllabus, but instead lets the responses and misconceptions of the student drive the dialog. The tutor should "opportunistically adapt material to the needs of the dialog" [18].
Reference: [57] <author> A. Collins and A.L. Stevens, </author> <title> "Goals and Strategies of Inquiry Teachers," in Advances in Instructional Psychology II (ed. Glaser). </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1982, </year> <pages> pp. 65-119. </pages>
Reference-contexts: In a seminal paper with respect to the development of a theory of teaching, Stevens and Collins <ref> [57] </ref> discuss their analysis of a number of human tutorial dialogs and present a detailed theory in the form of condition/action rules of the goals, strategies, and priorities that guide an VI PEDAGOGICAL KNOWLEDGE 19 * "If the student is about to lose interrupt and tutor him only with moves that <p> or more factors that are insufficient, or (2) is entrapped by a rule (ens 1 or ens 9) based on one or more factors that are insufficient, then (3) pick a case that has the values specified on the insufficient factors, but not the value specified on the dependent variable" <ref> [57] </ref>. * If "the present topic is complete, but the tutor has little confidence in its assessment of the student's knowledge," then generate "... an expository shift from detailed examination of a single topic, to a shallow examination of a number of topics" [64]. * "IF: The recent context of the <p> Pedagogical rules in why fire on the type of knowledge being taught and the type of misconception the student is having and suggest a strategy for exposing this misconception to the student <ref> [57] </ref>. Rules in Meno-tutor [63, 64] take the tutor off some default dialog path and suggest a different tutorial strategy or tactic.
Reference: [58] <author> A. Stevens, A. Collins, and S. Goldin, </author> <title> "Misconceptions in Students' Understanding," in Intelligent Tutoring Systems (eds. </title> <editor> Sleeman and Brown). </editor> <address> Cambridge, MA: </address> <publisher> Academic Press, </publisher> <year> 1982, </year> <pages> pp. 13-24. </pages>
Reference-contexts: Stevens and Collins have explored the use of a Socratic method in their why tutor <ref> [55, 58] </ref>, which tutors students on the causal relationships and factors affecting rainfall. Gaming environments and mixed-initiative dialog scenarios differ in the demands they put on the tutoring system. <p> To quote several of the most influential ICAI researchers, "By far the most important issue we have been forced to confront is the overwhelmingly central role of detailed, domain-specific knowledge in governing almost every aspect of the tutorial process" <ref> [58] </ref>. The structure and interrelationships of knowledge needed for tutoring are much greater than for typical problem-solving expert systems. This important lesson was clearly demonstrated by research at Stanford University in which they tried to use the famous mycin expert system [9] as a tutor for medical students. <p> Many such tradeoffs exist, and it would be foolish to think that one best answer applies to all domains. The choice of knowledge representation in a tutoring system depends on both the type of knowledge to be stored and its intended tutorial use. why <ref> [55, 58] </ref>, for instance, is a Socratic tutoring system which teaches the causal relationships and factors affecting rainfall. Stevens et al. [58] list the sorts of knowledge that are represented in why along with sentences which illustrate each type; these are shown in Figure 2. <p> The choice of knowledge representation in a tutoring system depends on both the type of knowledge to be stored and its intended tutorial use. why [55, 58], for instance, is a Socratic tutoring system which teaches the causal relationships and factors affecting rainfall. Stevens et al. <ref> [58] </ref> list the sorts of knowledge that are represented in why along with sentences which illustrate each type; these are shown in Figure 2. The intended use of this knowledge is to test the student's understanding of the major causal factors involved in rainfall. <p> Therefore, their knowledge dictates a representation which emphasizes causality, while their intended teaching strategy necessitates different levels of abstraction from high-level factors to lower-order ones. The representation which they chose was the script [51]; their use of scripts is described in detail in <ref> [58] </ref>. Their version of the script representation has nodes, which represent processes and events, and links between these nodes which express such relations as X enables Y or X causes Y (where X and Y are processes or events such as evaporation or condensation). <p> Furthermore, these inferences can be recorded as they are made so that sophie can justify the predictions to the student [6]. Such an articulate simulation has pedagogical benefits which far exceed a simple black-box simulator. Besides its use of scripts, why <ref> [55, 58] </ref> also makes use of constraint-based reasoning, in this case to describe functional relationships at work in processes. For instance, a process such as evaporation can be modeled by a constraint prototype with actors (the instance variables or terminals which are being constrained). <p> III DOMAIN KNOWLEDGE REPRESENTATION 12 can give examples using its instantiated actors. This provides an articulate inference procedure for causal, factor-oriented concepts. The paper of Stevens et al. <ref> [58] </ref>, an excellent treatise on the knowledge representation issues in tutoring and one that has greatly influenced this author's understanding, emphasizes the need for "multiple representational viewpoints." Using their why system as an example, they point out that scripts serve well to guide the sequencing of topics, but are particularly weak <p> While scripts are "ordered and sequential," the functional perspective is "non-linear and interactive" <ref> [58] </ref>. This functional perspective embodies the viewpoint that was lacking with scripts; while the scripts convey the causal sequencing of events, the functional perspective describes the "interaction microstructure" [58]. <p> While scripts are "ordered and sequential," the functional perspective is "non-linear and interactive" <ref> [58] </ref>. This functional perspective embodies the viewpoint that was lacking with scripts; while the scripts convey the causal sequencing of events, the functional perspective describes the "interaction microstructure" [58]. They note that the availability of multiple viewpoints allows a tutoring system to view student errors as a reflection of some perspective missing in the student's knowledge. <p> The experience of Stevens et al. with why led them to state perhaps the most important maxim of student diagnosis: "The types of misconceptions in a student's knowledge that a system can diagnose are heavily dependent on the knowledge represented in the system" <ref> [58] </ref>. For instance, student shortcomings in discovery learning environments can only be detected through comparison with a computer-based expert, because you need some way of determining when particular knowledge is applicable [10]. <p> Sometimes the student has the correct answer but expresses it in a fundamentally different way [63]. Similarly, in gaming environments, the student may appear to be missing certain skills when instead he is employing a totally different strategy from the expert [10]. Finally, Stevens et al. <ref> [58] </ref> note that sometimes bugs interact, so we must always consider the possibility that an error resulted from a combination of student misconceptions. One of the few techniques which handles multiple bugs is Burton's Buggy model [11]. <p> The difference between plan recognition and the Buggy model is that the former considers more levels of abstraction. While not everyone subscribes to the Buggy method, most see the need for some sort of error taxonomy. As Stevens et al. <ref> [58] </ref> so aptly point out, "A good teacher must possess knowledge of the types of misconceptions that arise in the domain being taught". <p> Misconceptions that can arise in a particular domain should be represented, and their commonalities should be abstracted into more general misconceptions ranging from basic misconceptions that people experience, such as misusing a metaphor, down to the ways in which these misconceptions manifest themselves in particular domain concepts <ref> [58] </ref>. There have been various approaches to such an error taxonomy, each being somewhat tied to a particular type of knowledge. <p> Stevens et al. <ref> [58] </ref> identified sixteen common bugs that accounted for 58% of the errors of students in the area of rainfall (72% ignoring omissions). They discuss the more abstract error types which underly these sixteen bugs, including application of an incorrect metaphor and missing generalizations.
Reference: [59] <author> K. VanLehn, </author> <title> "Student Modelling in Intelligent Teaching Systems," AFHRL Research Planning Forum for Intelligent Tutoring Systems, </title> <address> San Antonio, TX, </address> <month> September </month> <year> 1986. </year>
Reference: [60] <author> K.T. Wescourt, M. Beard, and L. Gould, </author> <title> "Knowledge-Based Adaptive Curriculum Sequencing for CAI: Application of a Network Representation," </title> <booktitle> Proc. of ACM-77, </booktitle> <address> Seattle, WA, </address> <pages> pp. 234-240, </pages> <year> 1977. </year>
Reference-contexts: In a second-generation bip system, known as bip-ii, the curriculum net was generalized into a semantic network of skills, each interconnected to other skills via relational links which denote prerequisites, relative difficulty, and analogies, as well as taxonomic links such as component and kind <ref> [60] </ref>. They also developed a sophisticated task selection procedure which uses the various links to guide the sequencing and selection of problems for the student. Note the similarities between this new curriculum net and Goldstein's genetic graph.
Reference: [61] <author> J.D. </author> <title> Wexler, "Information Networks in Generative Computer-Assisted Instruction," </title> <journal> IEEE Trans. Man-Machine Systems, </journal> <volume> Vol. 11, No. 4, </volume> <pages> pp. 181-190, </pages> <month> December </month> <year> 1970. </year>
Reference-contexts: By organizing the information in such an interconnected way, scholar avoids storing information redundantly in the data base, and it can index into the information in a variety of ways, thus supporting a very flexible method of query and reasoning. Jonathan Wexler <ref> [61] </ref> independently developed a system very similar to scholar. In Wexler's domain-independent system, knowledge is encoded in an information network and is used to generate questions, statements, and answers. Net objects are grouped into classes and each object includes a value/character string and unlabelled links to other objects. <p> Net objects are grouped into classes and each object includes a value/character string and unlabelled links to other objects. More complex relationships can be built by creating new classes, such as family (which could be used to link mother, father, and children) <ref> [61] </ref>. Questions, statements, and answers are constructed from the network using prespecified skeleton patterns, which are textual templates annotated with information net paths and constraints. Thus, Wexler's information net is similar to scholar's III DOMAIN KNOWLEDGE REPRESENTATION 10 semantic net, and is used for similar purposes, albeit through different mechanisms. <p> Thus, Wexler's information net is similar to scholar's III DOMAIN KNOWLEDGE REPRESENTATION 10 semantic net, and is used for similar purposes, albeit through different mechanisms. Reasoning in a semantic net involves a lot of pointer following. In Wexler's system <ref> [61] </ref>, the net is searched (using backtracking) for nodes which satisfy the question skeletons. The search is begun at class nodes and proceeds to the various instances. <p> Goldstein uses a genetic graph exposing relationships between intermediate and mature pieces of knowledge such as analogy links, specialization links, etc. [25, 26]. Different approaches have been taken to the construction of the student model. In Wexler's system <ref> [61] </ref>, the student model is constructed as a semantic net, with nodes and links added as they are taught. <p> An alternative to differential modeling is direct interpretation of the student's answer in terms of semantic memory, considering the compatibility and relevancy of the answer in relation to the question [13]. Wexler's system <ref> [61] </ref>, for instance, which stores its domain knowledge in a semantic net, evaluates the student's response by searching the net for nodes which satisfy the conditions of the question. <p> Often VI PEDAGOGICAL KNOWLEDGE 18 we can use the Socratic method of posing carefully selected problems to the student in order to allow him to see his own misconceptions. Finally, a little meaningful feedback in the style of Wexler <ref> [61] </ref> discussed above can go a long way towards helping the student find his error. VI Pedagogical Knowledge A good teacher is more than just knowledgeable. The communication of a body of knowledge to a person doesn't simply follow a protocol of information transfer as between two computers. <p> Finally, the course author should be able to specify high-level strategies for ordering topics. For instance, a teacher should be able to tell the tutor to teach about a phylum, then its classes, then the class species, and finally the characteristics of each species <ref> [61] </ref>. Other teachers may prefer a different ordering, and so the tutoring system should give each teacher access to these ordering heuristics. As has been stated, the general purpose of pedagogical rules is to indicate discourse directions, strategies, and tactics.
Reference: [62] <author> W.A. Woods, </author> <title> "An Experimental Parsing System for Transition Network Grammars," </title> <booktitle> in Natural Language Processing (ed. </booktitle> <address> Rustin). New York: </address> <publisher> Algorithmics Press, </publisher> <year> 1972, </year> <pages> pp. 113-154. </pages>
Reference-contexts: She uses a discourse management network (dmn) to guide the tutorial session, plan pedagogical strategies and tactics, and determine natural language utterances. The discourse management network has three successive levels: the tutoring approach, the strategy, and the tactics. These are organized into states of an augmented transition network (atn) <ref> [62] </ref>, with additional meta-rules which can affect the transitions [63].
Reference: [63] <author> B. Woolf and D.D. McDonald, </author> <title> "Building a Computer Tutor: </title> <booktitle> Design Issues," IEEE Computer, </booktitle> <pages> pp. 61-73, </pages> <month> September </month> <year> 1984. </year>
Reference-contexts: On the other hand, a computer coach must infer student shortcomings from the context of the game, whereas mixed-initiative dialog systems allow the computer tutor to test hypotheses by asking new questions [10]. Woolf and McDonald <ref> [63] </ref> draw an important distinction between "context-dependent" tutoring systems, in which the tutoring system adapts its strategy based on the state of the student, and "retrieval-oriented" systems like west that place their emphasis on retrieving the correct answer, and suggest that the former provide more reactive tutoring. <p> The suggestion has been made that the original rules of the mycin system represent `compiled' knowledge devoid of the low-level detail and relations necessary for learning and tutoring" <ref> [63] </ref>. Bill Clancey, the prime architect of guidon, concurs: "Teaching and explanation, we came to recognize, place different demands on an expert than simply solving problems. A teacher can provide analogies, multiple views, and levels of explanation which are unknown to mycin. <p> Although the expert module or domain knowledge of the system does not necessarily have to have the ability to solve problems it poses to the student, it must at least recognize an incorrect answer <ref> [63] </ref>. Goldstein and Papert [23] suggest the use of a "glass-box" expert that can both solve domain problems and explain its reasoning to the student. <p> Student diagnosis is not as easy as the above example would suggest, however. Sometimes the student has the correct answer but expresses it in a fundamentally different way <ref> [63] </ref>. Similarly, in gaming environments, the student may appear to be missing certain skills when instead he is employing a totally different strategy from the expert [10]. <p> The scope of the tutoring knowledge ends with choosing the content, just as it ends with the choice of a presentation method or an evaluation strategy <ref> [63] </ref>. Thus the pedagogical knowledge guides the overall goals and strategies of the tutor, but the other modules carry out these intentions. Although, as outlined above, the pedagogical knowledge is tasked with many responsibilities, the most important is the determination of a strategy to deal with student errors. <p> Since students are seldom consistent, and since diagnosis of one's own misconceptions is often more effective than too much guidance, a tutor cannot just provide remediation whenever the student errs. Woolf and McDonald <ref> [63] </ref> suggest that the pedagogical component be applied "after the expert and student modules have been accessed and some assessment [has been] made about the level of the student's knowledge." At this point, the tutor must select between ignoring the error, pointing it out, correcting it, or somehow guiding the student <p> Pedagogical rules in why fire on the type of knowledge being taught and the type of misconception the student is having and suggest a strategy for exposing this misconception to the student [57]. Rules in Meno-tutor <ref> [63, 64] </ref> take the tutor off some default dialog path and suggest a different tutorial strategy or tactic. Woolf's thesis work [64] in particular is an attempt at a domain-independent set of pedagogical rules to guide tutorial discourse; this work will be described further in section VII. <p> Each side must not only communicate its knowledge, but must reactively structure its dialog to meet the needs and goals of the other. Effective communication lies not in the words, but rather in the determination of what the tutor and student need to communicate <ref> [63] </ref>. Stevens and Collins [56] argue further that a good human tutor doesn't follow a prespec-ified syllabus, but instead lets the responses and misconceptions of the student drive the dialog. The tutor should "opportunistically adapt material to the needs of the dialog" [18]. <p> The discourse management network has three successive levels: the tutoring approach, the strategy, and the tactics. These are organized into states of an augmented transition network (atn) [62], with additional meta-rules which can affect the transitions <ref> [63] </ref>. <p> Transitions through the states follow a default path, but pedagogical rules fire off the student model, current mode, and student responses to lift the tutor off its default path and onto some other state in the network, thus creating a discourse transition <ref> [63] </ref>. These transitions could be between states at the same level, such as two tactical states, or they could lift the tutor from its current level up to a higher level, effecting a more radical shift in the tutorial directions.
Reference: [64] <author> B. Woolf, </author> <title> "Context-Dependent Planning in a Machine Tutor," </title> <type> Ph.D. dissertation, </type> <institution> Dept. of Computer and Information Science, University of Massachusetts, </institution> <address> Amherst, MA, </address> <year> 1984. </year>
Reference-contexts: The semantic network has a rich history of use in intelligent tutoring and continues in popularity today. Brown et al. [5] discuss the use of a semantic net to store factual knowledge and an augmented finite automata structure for describing causal process relationships. Recently, Woolf <ref> [64] </ref> used kl-one, which is a semantic net representation tool, annotated with pedagogical information about the relative importance of domain topics, for her Ph.D. work on tutorial dialogs. <p> the value specified on the dependent variable" [57]. * If "the present topic is complete, but the tutor has little confidence in its assessment of the student's knowledge," then generate "... an expository shift from detailed examination of a single topic, to a shallow examination of a number of topics" <ref> [64] </ref>. * "IF: The recent context of the dialog mentioned either a `deeper subgoal' or a factor relevant to the current goal THEN: Define the focus rule to be the d-rule that mentions this focus topic" [14]. effective teacher. <p> Pedagogical rules in why fire on the type of knowledge being taught and the type of misconception the student is having and suggest a strategy for exposing this misconception to the student [57]. Rules in Meno-tutor <ref> [63, 64] </ref> take the tutor off some default dialog path and suggest a different tutorial strategy or tactic. Woolf's thesis work [64] in particular is an attempt at a domain-independent set of pedagogical rules to guide tutorial discourse; this work will be described further in section VII. <p> Rules in Meno-tutor [63, 64] take the tutor off some default dialog path and suggest a different tutorial strategy or tactic. Woolf's thesis work <ref> [64] </ref> in particular is an attempt at a domain-independent set of pedagogical rules to guide tutorial discourse; this work will be described further in section VII. Finally, the course author should be able to specify high-level strategies for ordering topics. <p> The most recent work in tutorial discourse management was performed by Beverly Woolf as her Ph.D. thesis <ref> [64] </ref>. She uses a discourse management network (dmn) to guide the tutorial session, plan pedagogical strategies and tactics, and determine natural language utterances. The discourse management network has three successive levels: the tutoring approach, the strategy, and the tactics. <p> Woolf points out the absence of any need for a goal agenda, as used by Stevens and Collins [55], and suggests that her approach more closely mirrors the behavior of human tutors <ref> [64] </ref>. She also claims that her dmn is relatively domain independent, although she acknowledges that it may need some further refinement. Figure 4 shows her discourse VII DISCOURSE MANAGEMENT 23 management network. Work in discourse management for tutorial purposes has thus followed several distinct transitions. <p> Other work, exemplified by bip [3], showed the utility of a richly structured knowledge of the course curriculum which can be used to dynamically sequence the domain topics. Finally, Woolf's work <ref> [64] </ref> returns us to a prespecified network of tutorial states, but now the network is a domain-independent model of discourse knowledge rather than the earlier-used sequences of domain topics. <p> In Woolf's Meno-tutor, a description of the content of the textual output is constructed and sent to a surface language generator, although she dummied up the surface language generator for her thesis work <ref> [64] </ref>. In sophie, each concept has an associated grammar rule that provides alternate ways of expressing the concept in terms of other concepts [18]. Thus, none of these systems generates English from deep linguistic knowledge. One of the few tutoring systems to incorporate rich natural language generation mechanisms is scholar.
Reference: [65] <author> B. Woolf, D. Blegan, J.H. Jansen, and A. Verloop, </author> <title> "Teaching a Complex Industrial Process," </title> <booktitle> Proc. AAAI-86, </booktitle> <address> Philadelphia, PA, </address> <pages> pp. 722-728, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: In a more recent attempt at simulation-based training, Beverly Woolf built a tutoring system for the Kraft recovery boiler whose goal "is to challenge an operator to solve boiler problems and to maintain his incentive to play with the tutor" <ref> [65] </ref>. In the Recovery Boiler Tutor (rbt), students are presented with a graphical window into the process and given problems to correct. Based on their actions, rbt offers coaching and advice. <p> Based on their actions, rbt offers coaching and advice. Although rbt is a real-time simulation, updating its process variables every one or two seconds, operators who have used it seem to like the ability to stop the process to ask questions or explore boiler characteristics <ref> [65] </ref>. The authors of steamer raise an important point about simulation-based training. It is not enough to simply present the simulation as a black box with which the student can play. <p> The coach's role, in their view, is to intervene when the student is likely to miss the evidence of his error or misconception. Woolf <ref> [65] </ref> contrasts her philosophy of letting students explore possible wrong paths with Anderson et al. [1] and Reiser et al. [46], whose Geometry and lisp tutors immediately correct student errors. <p> Thus, although immediate feedback is not always desired, it may be chosen for domain or technical reasons. Besides deciding when to interrupt, pedagogical rules must decide what to say (the content). For instance, tutor responses in the Recovery Boiler Tutor (rbt) <ref> [65] </ref> fall into three categories: redirect the student, synthesize data (point out relationships), and confirm correct VII DISCOURSE MANAGEMENT 20 actions. <p> In rbt, instructional condition/action rules based on specific emergencies and student responses are "designed to verify that the student has asked the right questions and has made the correct inferences about the saliency of his data" <ref> [65] </ref>. Pedagogical rules in why fire on the type of knowledge being taught and the type of misconception the student is having and suggest a strategy for exposing this misconception to the student [57]. <p> They also give the student the ability to control the steam propulsion plant by touching icons on the screen. rbt <ref> [65] </ref> similarly uses graphical animation of its process, a recovery boiler, including visual clues such as a darkened smelt bed, acoustic clues such as ringing alarm buzzers, and textual help and explanations. <p> Although the process simulation runs in real time, students are allowed to stop the simulation in order to ask questions, a feature that many users mentioned that they like <ref> [65] </ref>. The more a student feels connected to his learning environment, the richer his experience will be, and interactive graphics help with this connection. <p> Many different approaches have been taken for text generation in tutoring systems, most of which avoid true natural language mechanisms. In Woolf's rbt, tutor output is created by extracting text from emergency-specific text files which are loaded when the emergency is invoked <ref> [65] </ref>. In west, textual explanations are attached to each issue (skill); each issue is responsible for presenting a few lines of text explaining itself [10]. west therefore distributes prestored text to the actual knowledge structures and combines the text dynamically to fit the situation.
References-found: 65

