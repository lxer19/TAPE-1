URL: http://www.media.mit.edu/people/rennison/mux-hyperpres-paper.ps
Refering-URL: http://rennison.www.media.mit.edu/people/rennison/
Root-URL: http://www.media.mit.edu
Email: -rennison,finn-@erg.sri.com  
Title: MULTIDIMENSIONAL HYPERPRESENTATIONS IN A DISTRIBUTED MULTIMEDIA SYSTEM  
Author: Earl Rennison, Kate Finn DooHyun Kim, Young-Hwan Lim 
Date: July 1993  
Address: 14-15  Menlo Park, California, U.S.A.  Daejeon, Korea  
Affiliation: Wollongong, New South Wales,  Information, Telecommunications, and Automation Division SRI International  Electronics and Telecommunications Research Institute,  
Note: 3rd Australian Multi-Media Communications, Applications, and Technology Workshop  
Abstract: We have defined a model for multidimensional hyperpresentations, in which time-varying multimedia presentations are dynamically linked together. In our model a hyperlinks context can change over time. Thus, at any time during a continuous presentation, a user can interactively access context-specific information. How the hyperlinks are traversed depends upon user interaction and/or context-sensitive triggers. This generalized model can be applied to solve many issues associated with multimedia information representation and access. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Zellweger, P., </author> <title> Toward a model for active multimedia documents, in Multimedia Interface Design, </title> <editor> eds. M. Blattner and R. Dannenberg, </editor> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: In contrast, hypermedia systems provide effective techniques for precisely navigating through and accessing information spaces, thus enabling users to quickly find information of interest via a more natural interface <ref> [1; 2] </ref>. Attempts to merge the richness of video with the navigability/accessibility of hypermedia, however, have not provided adequate support for multidimensional data. <p> PC Channel PC Track ClipList PC Track ClipList PC Mixer LTS Stream Stream Stream PC Time V l m Volume = interval (0,3)*40 + 100 60 20 interval (3,5)*(40+(time-3)*(40/2))+ interval (5,9)*80 + interval (9,14)*(80-(time-9)*(80/5) 3rd Australian Multi-Media Communications, Applications, and Technology Workshop Wollongong, New South Wales, 14-15 July 1993 5 <ref> [4; 5; 6; 7; 1] </ref>. Within the context of this model, hyperlinks can be associated with tracks, channels, and presentations, and can link them to any of the aforementioned components, as illustrated in Figure 6. A publication binds together a set of presentations linked together with hyperlinks. <p> Similar relationships have also been explored <ref> [1; 2; 4; 6; 7; 15; 17; 18; 19; 20; 21] </ref>. In the MuX system, the graphical specification of relationships is not explicit; rather, it is implicit, expressing the start-time and end-time or duration by means of a cue that is associated with another component. <p> which uses them to correlate the timing of the control stream with the timing specified by the condition context. 3.4 HyperPresentation Scripting and the MuX API An integral support facility for hyperpresentations is a scripting language that allows users to directly or indirectly specify the relationships and hyperlinks between media <ref> [1; 6; 2] </ref>. The MuX system provides a scripting toolkit that allows users to script hyperpresentations. The MuX scripting language [10] is an object-oriented language that provides facilities to define publications that may consist of multiple presentations (and their associated channels, tracks, and so on) and hyperlinks between the presentations. <p> We also plan to investigate the relationship between hyperpresentation authoring systems and media logging systems such as video loggers. Finally, we plan to address issues relating to the integration of context-based queries with an authoring system <ref> [1; 6; 7; 19] </ref>. 6. ACKNOWLEDGEMENTS This work was conducted with the cooperation and support of the Electronics and Telecommunications Research Institute, Korea, which is sponsoring SRI Project 2026, Integrated Multimedia I/O Interface for Intelligent Computing.
Reference: [2] <author> Buchanan, M.C., and Zellweger, P., </author> <title> Scheduling Multimedia Documents Using Temporal Constraints, </title> <booktitle> presented at 3rd International Workshop on Networking and Operating Systems for Digital Audio-Video, </booktitle> <address> San Diego, California, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: In contrast, hypermedia systems provide effective techniques for precisely navigating through and accessing information spaces, thus enabling users to quickly find information of interest via a more natural interface <ref> [1; 2] </ref>. Attempts to merge the richness of video with the navigability/accessibility of hypermedia, however, have not provided adequate support for multidimensional data. <p> Similar relationships have also been explored <ref> [1; 2; 4; 6; 7; 15; 17; 18; 19; 20; 21] </ref>. In the MuX system, the graphical specification of relationships is not explicit; rather, it is implicit, expressing the start-time and end-time or duration by means of a cue that is associated with another component. <p> which uses them to correlate the timing of the control stream with the timing specified by the condition context. 3.4 HyperPresentation Scripting and the MuX API An integral support facility for hyperpresentations is a scripting language that allows users to directly or indirectly specify the relationships and hyperlinks between media <ref> [1; 6; 2] </ref>. The MuX system provides a scripting toolkit that allows users to script hyperpresentations. The MuX scripting language [10] is an object-oriented language that provides facilities to define publications that may consist of multiple presentations (and their associated channels, tracks, and so on) and hyperlinks between the presentations.
Reference: [3] <author> Baker, R., Downing, A., Finn, K., and Rennison, E., </author> <title> Multimedia Processing Model for a Distributed Multimedia I/O System, </title> <booktitle> presented at 3rd International Workshop on Networking and Operating Systems for Digital Audio-Video, </booktitle> <address> San Diego, California, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: MuX DISTRIBUTED MULTIMEDIA SYSTEM In this section, we will present a very brief and high-level overview of the multimedia data processing model employed and the MuX distributed multimedia I/O system that uses the model. A more detailed description of the MuX model is provided by Baker et al. <ref> [3] </ref>. 2.1 MuX Multimedia Data Processing Model The MuX model comprises a stream layer, a multimedia presentation layer, and a hyperpresentation layer, as shown in Figure 2.
Reference: [4] <author> Brondmo, H.P., and Davenport, G., </author> <title> Creating and viewing the Elastic Charles - a hypermedia journal, in Hypertext: State of the Art, </title> <editor> eds. R. McAleese and C. Green, </editor> <publisher> Intellect, Ltd., </publisher> <address> Great Britain, </address> <year> 1990. </year>
Reference-contexts: PC Channel PC Track ClipList PC Track ClipList PC Mixer LTS Stream Stream Stream PC Time V l m Volume = interval (0,3)*40 + 100 60 20 interval (3,5)*(40+(time-3)*(40/2))+ interval (5,9)*80 + interval (9,14)*(80-(time-9)*(80/5) 3rd Australian Multi-Media Communications, Applications, and Technology Workshop Wollongong, New South Wales, 14-15 July 1993 5 <ref> [4; 5; 6; 7; 1] </ref>. Within the context of this model, hyperlinks can be associated with tracks, channels, and presentations, and can link them to any of the aforementioned components, as illustrated in Figure 6. A publication binds together a set of presentations linked together with hyperlinks. <p> Similar relationships have also been explored <ref> [1; 2; 4; 6; 7; 15; 17; 18; 19; 20; 21] </ref>. In the MuX system, the graphical specification of relationships is not explicit; rather, it is implicit, expressing the start-time and end-time or duration by means of a cue that is associated with another component. <p> For example, hyperlinks might be categorized by whether they connect nodes that operate simultaneously or nodes that operate sequentially; or by whether or not the hyperlinks return the user to the originating node. Brondmo and Davenport <ref> [4] </ref>, in the Elastic Charles project, used links whose physical appearance denoted the type of media they connect: a link to a video segment, for example, was indicated by a micon, or motion icon. Ogawa et al. [7] categorize links as user driven, time driven, or condition driven. <p> Duration: The length of time in which the hyperlink is active. Appearance: The physical form taken by the hyperlinks activation area; e.g., dashed or solid line; opaque or transparent; circle, square, or micon <ref> [4; 6] </ref>; outlined or invisible. Origin: The location of the upper-left corner of the physical activation area, expressed as the pixel specification of the x and y coordinates (and z coordinates, for 3-D graphics and animation).
Reference: [5] <author> Halasz, F., </author> <title> Reflections on NoteCards: Seven Issues for the Next Hypermedia Systems, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 34, No. 12, </volume> <year> 1988, </year> <pages> pp. 836-852. </pages>
Reference-contexts: PC Channel PC Track ClipList PC Track ClipList PC Mixer LTS Stream Stream Stream PC Time V l m Volume = interval (0,3)*40 + 100 60 20 interval (3,5)*(40+(time-3)*(40/2))+ interval (5,9)*80 + interval (9,14)*(80-(time-9)*(80/5) 3rd Australian Multi-Media Communications, Applications, and Technology Workshop Wollongong, New South Wales, 14-15 July 1993 5 <ref> [4; 5; 6; 7; 1] </ref>. Within the context of this model, hyperlinks can be associated with tracks, channels, and presentations, and can link them to any of the aforementioned components, as illustrated in Figure 6. A publication binds together a set of presentations linked together with hyperlinks. <p> HYPERPRESENTATION IMPLEMENTATION Classical hypertext is discussed in terms of links and nodes [22]. However, the definitions of links and nodes have varied among authors, researchers, and applications <ref> [5; 12; 23] </ref>. For example, nodes could be the current and subsequent points of reference, and a link could be a definition of the way to traverse from one node to another.
Reference: [6] <author> Michon, B., </author> <title> Highly iconic interfaces, in Multimedia Interface Design, </title> <editor> eds. M. Blattner and R. Dannenberg, </editor> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: PC Channel PC Track ClipList PC Track ClipList PC Mixer LTS Stream Stream Stream PC Time V l m Volume = interval (0,3)*40 + 100 60 20 interval (3,5)*(40+(time-3)*(40/2))+ interval (5,9)*80 + interval (9,14)*(80-(time-9)*(80/5) 3rd Australian Multi-Media Communications, Applications, and Technology Workshop Wollongong, New South Wales, 14-15 July 1993 5 <ref> [4; 5; 6; 7; 1] </ref>. Within the context of this model, hyperlinks can be associated with tracks, channels, and presentations, and can link them to any of the aforementioned components, as illustrated in Figure 6. A publication binds together a set of presentations linked together with hyperlinks. <p> Similar relationships have also been explored <ref> [1; 2; 4; 6; 7; 15; 17; 18; 19; 20; 21] </ref>. In the MuX system, the graphical specification of relationships is not explicit; rather, it is implicit, expressing the start-time and end-time or duration by means of a cue that is associated with another component. <p> From the users perspective they behave as transparent buttons that exactly conform to an object in a video image...Once hotspots are defined, they are automatically scaled to register correctly with a video image even if the image is resized, moved, or stretched. <ref> [6, p. 365] </ref>. 2 Presentation A Display Channel Audio Channel User Control Video Track Audio Track Presentation B Display Channel Audio Channel Video Track Audio Track HyperLink User Control Play Play Start Stop Time Time 4 3 1 2 1 2 2 3 Hierarchical relationships Relative to time line Relationship between <p> Control Stream: The type of stream containing the triggering event: e.g., mouse, microphone, keyboard. Trigger Event: The event that activates the hyperlink, e.g., &lt;control-C&gt;, mouseWithin, leftButtonDown, jump or link (spoken); more than one trigger can activate a link <ref> [6; 15] </ref>. <p> Duration: The length of time in which the hyperlink is active. Appearance: The physical form taken by the hyperlinks activation area; e.g., dashed or solid line; opaque or transparent; circle, square, or micon <ref> [4; 6] </ref>; outlined or invisible. Origin: The location of the upper-left corner of the physical activation area, expressed as the pixel specification of the x and y coordinates (and z coordinates, for 3-D graphics and animation). <p> which uses them to correlate the timing of the control stream with the timing specified by the condition context. 3.4 HyperPresentation Scripting and the MuX API An integral support facility for hyperpresentations is a scripting language that allows users to directly or indirectly specify the relationships and hyperlinks between media <ref> [1; 6; 2] </ref>. The MuX system provides a scripting toolkit that allows users to script hyperpresentations. The MuX scripting language [10] is an object-oriented language that provides facilities to define publications that may consist of multiple presentations (and their associated channels, tracks, and so on) and hyperlinks between the presentations. <p> We also plan to investigate the relationship between hyperpresentation authoring systems and media logging systems such as video loggers. Finally, we plan to address issues relating to the integration of context-based queries with an authoring system <ref> [1; 6; 7; 19] </ref>. 6. ACKNOWLEDGEMENTS This work was conducted with the cooperation and support of the Electronics and Telecommunications Research Institute, Korea, which is sponsoring SRI Project 2026, Integrated Multimedia I/O Interface for Intelligent Computing.
Reference: [7] <author> Ogawa, R., Harada, K., and Kameko, A., </author> <title> Scenario-based Hypermedia: A Model and a System, in Hypertext: Concepts, Systems, and Applications, </title> <editor> eds. A. Rizk, N. Steitz, and J. Andre, </editor> <publisher> Cambridge University Press, </publisher> <address> Great Britain, </address> <year> 1990. </year>
Reference-contexts: PC Channel PC Track ClipList PC Track ClipList PC Mixer LTS Stream Stream Stream PC Time V l m Volume = interval (0,3)*40 + 100 60 20 interval (3,5)*(40+(time-3)*(40/2))+ interval (5,9)*80 + interval (9,14)*(80-(time-9)*(80/5) 3rd Australian Multi-Media Communications, Applications, and Technology Workshop Wollongong, New South Wales, 14-15 July 1993 5 <ref> [4; 5; 6; 7; 1] </ref>. Within the context of this model, hyperlinks can be associated with tracks, channels, and presentations, and can link them to any of the aforementioned components, as illustrated in Figure 6. A publication binds together a set of presentations linked together with hyperlinks. <p> Similar relationships have also been explored <ref> [1; 2; 4; 6; 7; 15; 17; 18; 19; 20; 21] </ref>. In the MuX system, the graphical specification of relationships is not explicit; rather, it is implicit, expressing the start-time and end-time or duration by means of a cue that is associated with another component. <p> Brondmo and Davenport [4], in the Elastic Charles project, used links whose physical appearance denoted the type of media they connect: a link to a video segment, for example, was indicated by a micon, or motion icon. Ogawa et al. <ref> [7] </ref> categorize links as user driven, time driven, or condition driven. <p> We also plan to investigate the relationship between hyperpresentation authoring systems and media logging systems such as video loggers. Finally, we plan to address issues relating to the integration of context-based queries with an authoring system <ref> [1; 6; 7; 19] </ref>. 6. ACKNOWLEDGEMENTS This work was conducted with the cooperation and support of the Electronics and Telecommunications Research Institute, Korea, which is sponsoring SRI Project 2026, Integrated Multimedia I/O Interface for Intelligent Computing.
Reference: [8] <author> Rennison, E., Baker, R., Kim, D.-H., and Lim, Y.-H., MuX: </author> <title> An X Co-Existent Time-Based Multimedia I/O Server, The X Resource, </title> <booktitle> Issue 1, Winter 1992, </booktitle> <pages> pp. 213-33. </pages>
Reference-contexts: The MuX system supports the routing and delivery of real-time multimedia data; real-time video, audio, and graphics acquisition; and media processing and output. To facilitate its support of a distributed environment, the MuX system is based on the client-server paradigm. The system consists of a multimedia I/O server <ref> [8] </ref>; a presentation manager; the MuXLib client library, which embodies the MuX application programmers interface (API) [9]; and a scripting language [10]. <p> specifying timing and synchronization relationships between media: (1) hierarchical relationships specified by the relationship between presentations, channels, and tracks, where track times are relative to a channels time, and channel times are relative to a presentations time; (2) timing relative to a time-line using either a logical time system (LTS) <ref> [8] </ref> or a relative real-time system (RRTS) [11; 12]; (3) relationships between streams using cues, e.g., before, after, starts, and finishes [13; 14; 15]; and (4) direct interactions with the user via the application. These timing and synchronization specifications are illustrated in Figure 7.
Reference: [9] <author> Finn, K., Downing, A., Randolph, S., Rennison, E., and Kim, D.-H., </author> <title> Application Programmer Interface for MuX, </title> <booktitle> ITAD-2026-TR-93-104, SRI International, </booktitle> <address> Menlo Park, California, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: To facilitate its support of a distributed environment, the MuX system is based on the client-server paradigm. The system consists of a multimedia I/O server [8]; a presentation manager; the MuXLib client library, which embodies the MuX application programmers interface (API) <ref> [9] </ref>; and a scripting language [10]. In this environment, the client application specifies the timing and synchronization relationships among media streams, and the multimedia I/O servers exchange real-time data directly among themselves to meet these specifications. <p> The action definitions in the script specify execution-oriented operations such as play, pause, and stop. There is a tight relationship between the scripting toolkit and the client library, whose interface is defined by the MuX API <ref> [9] </ref>. The client library provides facilities to construct objects on the server and set the object parameters. The objects constructed are primarily control structures used for executing real-time presentations. <p> Thus, a hyperpresentation script can model user interactions and define the appropriate responses. 3.5 HyperPresentation System Overview To gain an overview of how the MuX system implements a hyperpresentation, consider the interactions, illustrated in Figure 9, between the MuX system components (the application, scripting toolkit [10], client library <ref> [9] </ref>, and server) to load a script and execute a presentation. This operation is initiated by the application, which instructs the script toolkit to load a publication. The publication defined by a script specifies the construction and parameters of stream, multimedia presentation and hyperpresentation objects.
Reference: [10] <author> Finn, K., and Rennison, E., MuXScript: </author> <title> A Scripting Language for Specifying Time-Based Multimedia and Hypermedia Presentations, </title> <booktitle> ITAD-2026-TR-92-147, SRI International, </booktitle> <address> Menlo Park, California, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: To facilitate its support of a distributed environment, the MuX system is based on the client-server paradigm. The system consists of a multimedia I/O server [8]; a presentation manager; the MuXLib client library, which embodies the MuX application programmers interface (API) [9]; and a scripting language <ref> [10] </ref>. In this environment, the client application specifies the timing and synchronization relationships among media streams, and the multimedia I/O servers exchange real-time data directly among themselves to meet these specifications. The system services are defined according to object-oriented concepts, both in design and in implementation (using C++). <p> The MuX system provides a scripting toolkit that allows users to script hyperpresentations. The MuX scripting language <ref> [10] </ref> is an object-oriented language that provides facilities to define publications that may consist of multiple presentations (and their associated channels, tracks, and so on) and hyperlinks between the presentations. The action definitions in the script specify execution-oriented operations such as play, pause, and stop. <p> Thus, a hyperpresentation script can model user interactions and define the appropriate responses. 3.5 HyperPresentation System Overview To gain an overview of how the MuX system implements a hyperpresentation, consider the interactions, illustrated in Figure 9, between the MuX system components (the application, scripting toolkit <ref> [10] </ref>, client library [9], and server) to load a script and execute a presentation. This operation is initiated by the application, which instructs the script toolkit to load a publication. The publication defined by a script specifies the construction and parameters of stream, multimedia presentation and hyperpresentation objects.
Reference: [11] <author> Rennison, E., Brown, M., Downing, A., Finn, K., and Randolph, S., </author> <title> The MuX Multimedia I/O System, </title> <booktitle> ITAD-2026-TR-93-178, SRI International, </booktitle> <address> Menlo Park, California, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: (1) hierarchical relationships specified by the relationship between presentations, channels, and tracks, where track times are relative to a channels time, and channel times are relative to a presentations time; (2) timing relative to a time-line using either a logical time system (LTS) [8] or a relative real-time system (RRTS) <ref> [11; 12] </ref>; (3) relationships between streams using cues, e.g., before, after, starts, and finishes [13; 14; 15]; and (4) direct interactions with the user via the application. These timing and synchronization specifications are illustrated in Figure 7.
Reference: [12] <author> Halasz, F. and Conklin, J., </author> <title> Issues in the Design and Application of Hypermedia Systems, </title> <booktitle> Tutorial at CHI90, </booktitle> <address> Seattle, Washington, </address> <month> April </month> <year> 1990. </year> <booktitle> 3rd Australian Multi-Media Communications, Applications, and Technology Workshop Wollongong, </booktitle> <address> New South Wales, </address> <month> 14-15 July </month> <year> 1993 </year> <month> 18 </month>
Reference-contexts: (1) hierarchical relationships specified by the relationship between presentations, channels, and tracks, where track times are relative to a channels time, and channel times are relative to a presentations time; (2) timing relative to a time-line using either a logical time system (LTS) [8] or a relative real-time system (RRTS) <ref> [11; 12] </ref>; (3) relationships between streams using cues, e.g., before, after, starts, and finishes [13; 14; 15]; and (4) direct interactions with the user via the application. These timing and synchronization specifications are illustrated in Figure 7. <p> HYPERPRESENTATION IMPLEMENTATION Classical hypertext is discussed in terms of links and nodes [22]. However, the definitions of links and nodes have varied among authors, researchers, and applications <ref> [5; 12; 23] </ref>. For example, nodes could be the current and subsequent points of reference, and a link could be a definition of the way to traverse from one node to another.
Reference: [13] <author> Little, T.T.D., and Ghafoor, A., </author> <title> Synchronization and Storage Models for Multimedia Objects, </title> <journal> Journal on Selected Areas of Communications, </journal> <volume> Vol. 8, No. 3, </volume> <month> April </month> <year> 1990. </year>
Reference-contexts: times are relative to a channels time, and channel times are relative to a presentations time; (2) timing relative to a time-line using either a logical time system (LTS) [8] or a relative real-time system (RRTS) [11; 12]; (3) relationships between streams using cues, e.g., before, after, starts, and finishes <ref> [13; 14; 15] </ref>; and (4) direct interactions with the user via the application. These timing and synchronization specifications are illustrated in Figure 7. Note that during execution the relative time system is elastic, meaning that it can stretch and shrink by changing the speed of the presentation.
Reference: [14] <author> Blakowski, G., Hubel, J., and Langrehr, U., </author> <title> Tools for Specifying and Executing Synchronized Multimedia Presentations, </title> <booktitle> Second International Workshop on Networking and Operating System Support for Digital Audio and Video, </booktitle> <address> Heidelberg, Germany, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: times are relative to a channels time, and channel times are relative to a presentations time; (2) timing relative to a time-line using either a logical time system (LTS) [8] or a relative real-time system (RRTS) [11; 12]; (3) relationships between streams using cues, e.g., before, after, starts, and finishes <ref> [13; 14; 15] </ref>; and (4) direct interactions with the user via the application. These timing and synchronization specifications are illustrated in Figure 7. Note that during execution the relative time system is elastic, meaning that it can stretch and shrink by changing the speed of the presentation.
Reference: [15] <author> Guimaraes, N., Correia, N., and Carmo, T., </author> <title> Programming time in multimedia user interfaces, </title> <booktitle> Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <pages> 15-18 November, </pages> <address> Monterey, California, </address> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1992, </year> <pages> pp. 125-134. </pages>
Reference-contexts: times are relative to a channels time, and channel times are relative to a presentations time; (2) timing relative to a time-line using either a logical time system (LTS) [8] or a relative real-time system (RRTS) [11; 12]; (3) relationships between streams using cues, e.g., before, after, starts, and finishes <ref> [13; 14; 15] </ref>; and (4) direct interactions with the user via the application. These timing and synchronization specifications are illustrated in Figure 7. Note that during execution the relative time system is elastic, meaning that it can stretch and shrink by changing the speed of the presentation. <p> These timing and synchronization specifications are illustrated in Figure 7. Note that during execution the relative time system is elastic, meaning that it can stretch and shrink by changing the speed of the presentation. Guimaraes et al. <ref> [15] </ref> have developed a set of tools for defining temporal relationships between media types, and a system that supports periodic, time-event, and state-change actions; their work is based partially on Allens set of thirteen temporal relationships between pairs of objects [16]. <p> Similar relationships have also been explored <ref> [1; 2; 4; 6; 7; 15; 17; 18; 19; 20; 21] </ref>. In the MuX system, the graphical specification of relationships is not explicit; rather, it is implicit, expressing the start-time and end-time or duration by means of a cue that is associated with another component. <p> Control Stream: The type of stream containing the triggering event: e.g., mouse, microphone, keyboard. Trigger Event: The event that activates the hyperlink, e.g., &lt;control-C&gt;, mouseWithin, leftButtonDown, jump or link (spoken); more than one trigger can activate a link <ref> [6; 15] </ref>.
Reference: [16] <author> Allen, J., </author> <title> Maintaining Knowledge about Temporal Intervals, </title> <journal> Communications of the ACM, </journal> <volume> 26(1), </volume> <month> November </month> <year> 1983, </year> <pages> pp. 832-843. </pages>
Reference-contexts: Guimaraes et al. [15] have developed a set of tools for defining temporal relationships between media types, and a system that supports periodic, time-event, and state-change actions; their work is based partially on Allens set of thirteen temporal relationships between pairs of objects <ref> [16] </ref>. Similar relationships have also been explored [1; 2; 4; 6; 7; 15; 17; 18; 19; 20; 21].
Reference: [17] <author> Buchanan, M.C., and Zellweger, P., </author> <title> Specifying temporal behavior in hypermedia documents, </title> <booktitle> Proceedings of the ACM Conference on Hypertext, 30 November-4 December, </booktitle> <address> Milano, Italy, </address> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1992, </year> <pages> pp. 262-271. </pages>
Reference-contexts: Similar relationships have also been explored <ref> [1; 2; 4; 6; 7; 15; 17; 18; 19; 20; 21] </ref>. In the MuX system, the graphical specification of relationships is not explicit; rather, it is implicit, expressing the start-time and end-time or duration by means of a cue that is associated with another component.
Reference: [18] <author> Fountain, A., Hall, W., Heath, I., and Davis, H., MICROCOSM: </author> <title> An open model for hypermedia with dynamic linking, </title> <booktitle> in Proceedings of the ACM Conference on Hypertext, </booktitle> <year> 1990, </year> <pages> pp. 298-311. </pages>
Reference-contexts: Similar relationships have also been explored <ref> [1; 2; 4; 6; 7; 15; 17; 18; 19; 20; 21] </ref>. In the MuX system, the graphical specification of relationships is not explicit; rather, it is implicit, expressing the start-time and end-time or duration by means of a cue that is associated with another component.
Reference: [19] <author> Ogawa, R., Tanaka, E., Taguchi, D., and Harada, K., </author> <title> Design strategies for scenario-based hypermedia: Description of its structure, dynamics, and style, </title> <booktitle> Proceedings of the ACM Conference on Hypertext, 30 November4 December, </booktitle> <address> Milano, Italy, </address> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1992, </year> <pages> pp. 71-80. </pages>
Reference-contexts: Similar relationships have also been explored <ref> [1; 2; 4; 6; 7; 15; 17; 18; 19; 20; 21] </ref>. In the MuX system, the graphical specification of relationships is not explicit; rather, it is implicit, expressing the start-time and end-time or duration by means of a cue that is associated with another component. <p> We also plan to investigate the relationship between hyperpresentation authoring systems and media logging systems such as video loggers. Finally, we plan to address issues relating to the integration of context-based queries with an authoring system <ref> [1; 6; 7; 19] </ref>. 6. ACKNOWLEDGEMENTS This work was conducted with the cooperation and support of the Electronics and Telecommunications Research Institute, Korea, which is sponsoring SRI Project 2026, Integrated Multimedia I/O Interface for Intelligent Computing.
Reference: [20] <author> Rhyne, J., and Wolf, C., </author> <title> Tools for supporting the collaborative process, </title> <address> UIST92, </address> <month> 15-18 November </month> <year> 1992, </year> <pages> pp. 161-170. </pages>
Reference-contexts: Similar relationships have also been explored <ref> [1; 2; 4; 6; 7; 15; 17; 18; 19; 20; 21] </ref>. In the MuX system, the graphical specification of relationships is not explicit; rather, it is implicit, expressing the start-time and end-time or duration by means of a cue that is associated with another component.
Reference: [21] <author> Sherman, M., Hansen, W., McInerny, M., and Neuendorffer, T., </author> <title> Building hypertext on a multimedia toolkit: An overview of Andrew Toolkit, </title> <booktitle> in Proceedings of the ACM Conference on Hypertext, </booktitle> <publisher> Cambridge University Press, </publisher> <address> Great Britain, </address> <year> 1990, </year> <pages> pp. 13-24. </pages>
Reference-contexts: Similar relationships have also been explored <ref> [1; 2; 4; 6; 7; 15; 17; 18; 19; 20; 21] </ref>. In the MuX system, the graphical specification of relationships is not explicit; rather, it is implicit, expressing the start-time and end-time or duration by means of a cue that is associated with another component.
Reference: [22] <author> Conklin, J., </author> <title> Hypertext: An Introduction and Survey, </title> <booktitle> IEEE Computer, </booktitle> <year> 1987, </year> <pages> pp. 17-41. </pages>
Reference-contexts: The timing specifications employed by MuX are fundamental to hyperlink trigger detection and will be discussed in further detail in the following section. 3. HYPERPRESENTATION IMPLEMENTATION Classical hypertext is discussed in terms of links and nodes <ref> [22] </ref>. However, the definitions of links and nodes have varied among authors, researchers, and applications [5; 12; 23]. For example, nodes could be the current and subsequent points of reference, and a link could be a definition of the way to traverse from one node to another.
Reference: [23] <author> Nielsen, J., </author> <title> Hypertext & Hypermedia, </title> <publisher> Academic Press, Inc., </publisher> <address> San Diego, California, </address> <year> 1990. </year>
Reference-contexts: HYPERPRESENTATION IMPLEMENTATION Classical hypertext is discussed in terms of links and nodes [22]. However, the definitions of links and nodes have varied among authors, researchers, and applications <ref> [5; 12; 23] </ref>. For example, nodes could be the current and subsequent points of reference, and a link could be a definition of the way to traverse from one node to another.
Reference: [24] <author> Aguierre Smith, T.G., and Davenport, G., </author> <title> The Stratification System: A Design Environment for Random Access Video, </title> <booktitle> Third International Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <address> San Diego, California, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: We denote the span of time that a link is active as a segment. Segments are generally associated with the underlying content of the presentation. The notion of a segment is similar to the concept of stratification described by Aguierre Smith and Davenport <ref> [24] </ref>. The Tell Me More button mentioned above is an example of a context-sensitive link: the location pointed to by the link may vary according to the current position in a presentation. Other, less dynamic links may always point to the same place, regardless of when they are activated.
Reference: [25] <author> Laurel, B., Oren, T., and Don, A., </author> <title> Issues in Multimedia Interface Design: Media Integration and Interface Agents, </title> <booktitle> in Proceedings of CHI90, </booktitle> <address> Seattle, Washington, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: We have developed mock-ups of several versions of a GUI, but as of this publication have not implemented them. The characteristics of nodes and links, and the node-link relationship itself, need to be further refined for the multimedia environment. As pointed out by Laurel, Oren, and Don <ref> [25] </ref>, the application of hypermedia to multimedia requires new conventions. We plan to investigate more fluid transitions between two hyperpresentation nodes when a hyperlink is traversed.
References-found: 25

