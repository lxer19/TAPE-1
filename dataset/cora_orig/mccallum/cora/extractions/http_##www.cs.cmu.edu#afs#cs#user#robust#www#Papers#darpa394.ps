URL: http://www.cs.cmu.edu/afs/cs/user/robust/www/Papers/darpa394.ps
Refering-URL: http://www.cs.cmu.edu/afs/cs/user/robust/www/Papers/
Root-URL: 
Title: ABSTRACT  
Abstract: This paper describes a series of cepstral-based compensation procedures that render the SPHINX-II system more robust with respect to acoustical environment. The first algorithm, phone-dependent cepstral compensation, is similar in concept to the previously-described MFCDCN method, except that cepstral compensation vectors are selected according to the current phonetic hypothesis, rather than on the basis of SNR or VQ codeword identity. We also describe two procedures to accomplish adaptation of the VQ codebook for new environments, as well as the use of reduced-bandwidth frequency analysis to process telephone-bandwidth speech. Use of the various compensation algorithms in consort produces a reduction of error rates for SPHINX-II by as much as 40 percent relative to the rate achieved with cepstral mean normalization alone, in both development test sets and in the context of the 1993 ARPA CSR evaluations. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Juang, B.-H., </author> <title> Speech Recognition in Adverse Environments, </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 5 </volume> <pages> 275-294, </pages> <year> 1991. </year>
Reference: 2. <author> Acero, A., </author> <title> Acoustical and Environmental Robustness in Automatic SPeech Recognition, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Bos-ton, MA, </address> <year> 1993. </year>
Reference-contexts: In previous years we described the performance of cepstral mapping procedures such as the CDCN algorithm, which is ef fective but fairly computationally costly <ref> [2] </ref>. More recently we discussed the use of cepstral highpass-filtering algorithms [such as the popular RASTA and cepstral-mean-normalization algorithms (CMN) [6]. These algorithms are very simple to implement but somewhat limited in effectiveness, and CMN is now part of baseline processing for the CMU and many other systems.
Reference: 3. <author> Liu, F.H., Acero, A., and Stern, </author> <title> R.M., Effective Joint Compensation of Speech for the Effects of Additive Noise and Linear Filtering, </title> <booktitle> ICASSP-92, </booktitle> <pages> pp. 865-868, </pages> <month> March </month> <year> 1992. </year>
Reference: 4. <author> Hwang, M.Y., </author> <title> Subphonetic Acoustic Modeling for Speaker-Independent Continuous Speech Recognition, </title> <type> Ph.D. Thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1993. </year>
Reference: 5. <author> Huang, X.D., Ariki, Y., and Jack, M., </author> <title> Hidden Markov Models for Speech Recognition, </title> <publisher> Edinburgh University Press, </publisher> <address> Edin-burgh, U.K., </address> <year> 1990. </year>
Reference-contexts: In these circumstances, transformations can be developed between environments using the contents of the adaptation utterances using the Baum-Welch algorithm. In Baum-Welch codebook adaptation, mean vectors and covari-ance matrices, along with senones, are reestimated and updated using the Baum-Welch algorithm <ref> [5] </ref> during each iteration of training process. To compensate for the effect of changes in acoustical environments, the Baum-Welch approach is used to transform the means and covariances toward the cepstral space of the target testing environments.
Reference: 6. <author> Liu, F.H., Stern, R.M., Huang, X.D., and Acero A., </author> <title> Efficient Cepstral Normalization for Robust Speech Recognition, </title> <booktitle> Proceedings of ARPA Speech and Natural Language Workshop, </booktitle> <pages> pp. 69-74, </pages> <address> Princeton, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: In previous years we described the performance of cepstral mapping procedures such as the CDCN algorithm, which is ef fective but fairly computationally costly [2]. More recently we discussed the use of cepstral highpass-filtering algorithms [such as the popular RASTA and cepstral-mean-normalization algorithms (CMN) <ref> [6] </ref>. These algorithms are very simple to implement but somewhat limited in effectiveness, and CMN is now part of baseline processing for the CMU and many other systems. SIGNAL PROCESSING FOR ROBUST SPEECH RECOGNITION Fu-Hua Liu, Pedro J. Moreno, Richard M. <p> Multiple Fixed Codeword-Dependent Cepstral Normalization (MFCDCN) Multiple fixed codeword-dependent cepstral normalization (MFCDCN) provides additive cepstral compensation vectors that depend on signal-to-noise ratio (SNR) and that also vary from codeword to codeword of the vector quantized (VQ) representation of the incoming speech at each SNR <ref> [6] </ref>. At low SNRs these vectors primarily compensate for effects of additive noise. At higher SNRs, the algorithm compensates for linear filtering, while at intermediate SNRs, they compensate for both of these ef fects.
Reference: 7. <author> Schwartz, R., Anastasakos, T., Kubala, F., Makhoul, J., Nguyen, L., and Zavaliagkos, G., </author> <title> Comparative Experiments on Large Vocabulary Speech Recognition, </title> <booktitle> Proc. ARPA Human Language Technology Workshop, </booktitle> <month> March, </month> <year> 1993. </year>
Reference-contexts: The third procedure, referred to as Gaussian environment classifier, models each environment with mixtures of Gaussian densities. Environment selection is accomplished so that the test data has the highest probability from the corresponding classifier. This latter approach is similar to one proposed previously by BBN <ref> [7] </ref>. All three methods produce similar speech recognition accuracy. 2.3. <p> Codebook Adaptation (DCCA and BWCA) A vector quantization (VQ) codebook, which is a set of mean vectors and/or co-variance matrices of cepstal representations, also exhibits some fundamental dif ferences when mismatches are encountered between training and testing environments <ref> [7] </ref>. This suggests that when such mismatches exist, the codebook can be tuned to better characterize the cepstral space of testing data. In this section, we propose two dif ferent implementations of such codebook adaptation. Dual-Channel Codebook Adaptation (DCCA).
Reference: 8. <author> Huang, X., Alleva, F., Hon, H., Hwang, M., Lee, K., and Rosenfeld, R., </author> <title> The SPHINX-II Speech Recognition System: An Overview, </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 2 </volume> <pages> 137-148, </pages> <year> 1993. </year>
Reference-contexts: Applications such as speech recognition in automobiles, over telephones, on a factory floor, or outdoors demand an even greater degree of environmental robustness. In this paper we describe and compare the performance of a series of cepstrum-based procedures that enable the CMU SPHINX-II <ref> [8] </ref> speech recognition system to maintain a high level of recognition accuracy over a wide variety of acoustical environments.






Reference: 1. <author> Juang, B.-H., </author> <title> Speech Recognition in Adverse Environments, </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 5 </volume> <pages> 275-294, </pages> <year> 1991. </year>
Reference: 2. <author> Acero, A., </author> <title> Acoustical and Environmental Robustness in Automatic SPeech Recognition, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Bos-ton, MA, </address> <year> 1993. </year>
Reference-contexts: In previous years we described the performance of cepstral mapping procedures such as the CDCN algorithm, which is ef fective but fairly computationally costly <ref> [2] </ref>. More recently we discussed the use of cepstral highpass-filtering algorithms [such as the popular RASTA and cepstral-mean-normalization algorithms (CMN) [6]. These algorithms are very simple to implement but somewhat limited in effectiveness, and CMN is now part of baseline processing for the CMU and many other systems.
Reference: 3. <author> Liu, F.H., Acero, A., and Stern, </author> <title> R.M., Effective Joint Compensation of Speech for the Effects of Additive Noise and Linear Filtering, </title> <booktitle> ICASSP-92, </booktitle> <pages> pp. 865-868, </pages> <month> March </month> <year> 1992. </year>
Reference: 4. <author> Hwang, M.Y., </author> <title> Subphonetic Acoustic Modeling for Speaker-Independent Continuous Speech Recognition, </title> <type> Ph.D. Thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1993. </year>
Reference: 5. <author> Huang, X.D., Ariki, Y., and Jack, M., </author> <title> Hidden Markov Models for Speech Recognition, </title> <publisher> Edinburgh University Press, </publisher> <address> Edin-burgh, U.K., </address> <year> 1990. </year>
Reference-contexts: In these circumstances, transformations can be developed between environments using the contents of the adaptation utterances using the Baum-Welch algorithm. In Baum-Welch codebook adaptation, mean vectors and covari-ance matrices, along with senones, are reestimated and updated using the Baum-Welch algorithm <ref> [5] </ref> during each iteration of training process. To compensate for the effect of changes in acoustical environments, the Baum-Welch approach is used to transform the means and covariances toward the cepstral space of the target testing environments.
Reference: 6. <author> Liu, F.H., Stern, R.M., Huang, X.D., and Acero A., </author> <title> Efficient Cepstral Normalization for Robust Speech Recognition, </title> <booktitle> Proceedings of ARPA Speech and Natural Language Workshop, </booktitle> <pages> pp. 69-74, </pages> <address> Princeton, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: In previous years we described the performance of cepstral mapping procedures such as the CDCN algorithm, which is ef fective but fairly computationally costly [2]. More recently we discussed the use of cepstral highpass-filtering algorithms [such as the popular RASTA and cepstral-mean-normalization algorithms (CMN) <ref> [6] </ref>. These algorithms are very simple to implement but somewhat limited in effectiveness, and CMN is now part of baseline processing for the CMU and many other systems. SIGNAL PROCESSING FOR ROBUST SPEECH RECOGNITION Fu-Hua Liu, Pedro J. Moreno, Richard M. <p> Multiple Fixed Codeword-Dependent Cepstral Normalization (MFCDCN) Multiple fixed codeword-dependent cepstral normalization (MFCDCN) provides additive cepstral compensation vectors that depend on signal-to-noise ratio (SNR) and that also vary from codeword to codeword of the vector quantized (VQ) representation of the incoming speech at each SNR <ref> [6] </ref>. At low SNRs these vectors primarily compensate for effects of additive noise. At higher SNRs, the algorithm compensates for linear filtering, while at intermediate SNRs, they compensate for both of these ef fects.
Reference: 7. <author> Schwartz, R., Anastasakos, T., Kubala, F., Makhoul, J., Nguyen, L., and Zavaliagkos, G., </author> <title> Comparative Experiments on Large Vocabulary Speech Recognition, </title> <booktitle> Proc. ARPA Human Language Technology Workshop, </booktitle> <month> March, </month> <year> 1993. </year>
Reference-contexts: The third procedure, referred to as Gaussian environment classifier, models each environment with mixtures of Gaussian densities. Environment selection is accomplished so that the test data has the highest probability from the corresponding classifier. This latter approach is similar to one proposed previously by BBN <ref> [7] </ref>. All three methods produce similar speech recognition accuracy. 2.3. <p> Codebook Adaptation (DCCA and BWCA) A vector quantization (VQ) codebook, which is a set of mean vectors and/or co-variance matrices of cepstal representations, also exhibits some fundamental dif ferences when mismatches are encountered between training and testing environments <ref> [7] </ref>. This suggests that when such mismatches exist, the codebook can be tuned to better characterize the cepstral space of testing data. In this section, we propose two dif ferent implementations of such codebook adaptation. Dual-Channel Codebook Adaptation (DCCA).
Reference: 8. <author> Huang, X., Alleva, F., Hon, H., Hwang, M., Lee, K., and Rosenfeld, R., </author> <title> The SPHINX-II Speech Recognition System: An Overview, </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 2 </volume> <pages> 137-148, </pages> <year> 1993. </year>
Reference-contexts: Applications such as speech recognition in automobiles, over telephones, on a factory floor, or outdoors demand an even greater degree of environmental robustness. In this paper we describe and compare the performance of a series of cepstrum-based procedures that enable the CMU SPHINX-II <ref> [8] </ref> speech recognition system to maintain a high level of recognition accuracy over a wide variety of acoustical environments.






Reference: 1. <author> Juang, B.-H., </author> <title> Speech Recognition in Adverse Environments, </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 5 </volume> <pages> 275-294, </pages> <year> 1991. </year>
Reference: 2. <author> Acero, A., </author> <title> Acoustical and Environmental Robustness in Automatic SPeech Recognition, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Bos-ton, MA, </address> <year> 1993. </year>
Reference-contexts: In previous years we described the performance of cepstral mapping procedures such as the CDCN algorithm, which is ef fective but fairly computationally costly <ref> [2] </ref>. More recently we discussed the use of cepstral highpass-filtering algorithms [such as the popular RASTA and cepstral-mean-normalization algorithms (CMN) [6]. These algorithms are very simple to implement but somewhat limited in effectiveness, and CMN is now part of baseline processing for the CMU and many other systems.
Reference: 3. <author> Liu, F.H., Acero, A., and Stern, </author> <title> R.M., Effective Joint Compensation of Speech for the Effects of Additive Noise and Linear Filtering, </title> <booktitle> ICASSP-92, </booktitle> <pages> pp. 865-868, </pages> <month> March </month> <year> 1992. </year>
Reference: 4. <author> Hwang, M.Y., </author> <title> Subphonetic Acoustic Modeling for Speaker-Independent Continuous Speech Recognition, </title> <type> Ph.D. Thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1993. </year>
Reference: 5. <author> Huang, X.D., Ariki, Y., and Jack, M., </author> <title> Hidden Markov Models for Speech Recognition, </title> <publisher> Edinburgh University Press, </publisher> <address> Edin-burgh, U.K., </address> <year> 1990. </year>
Reference-contexts: In these circumstances, transformations can be developed between environments using the contents of the adaptation utterances using the Baum-Welch algorithm. In Baum-Welch codebook adaptation, mean vectors and covari-ance matrices, along with senones, are reestimated and updated using the Baum-Welch algorithm <ref> [5] </ref> during each iteration of training process. To compensate for the effect of changes in acoustical environments, the Baum-Welch approach is used to transform the means and covariances toward the cepstral space of the target testing environments.
Reference: 6. <author> Liu, F.H., Stern, R.M., Huang, X.D., and Acero A., </author> <title> Efficient Cepstral Normalization for Robust Speech Recognition, </title> <booktitle> Proceedings of ARPA Speech and Natural Language Workshop, </booktitle> <pages> pp. 69-74, </pages> <address> Princeton, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: In previous years we described the performance of cepstral mapping procedures such as the CDCN algorithm, which is ef fective but fairly computationally costly [2]. More recently we discussed the use of cepstral highpass-filtering algorithms [such as the popular RASTA and cepstral-mean-normalization algorithms (CMN) <ref> [6] </ref>. These algorithms are very simple to implement but somewhat limited in effectiveness, and CMN is now part of baseline processing for the CMU and many other systems. SIGNAL PROCESSING FOR ROBUST SPEECH RECOGNITION Fu-Hua Liu, Pedro J. Moreno, Richard M. <p> Multiple Fixed Codeword-Dependent Cepstral Normalization (MFCDCN) Multiple fixed codeword-dependent cepstral normalization (MFCDCN) provides additive cepstral compensation vectors that depend on signal-to-noise ratio (SNR) and that also vary from codeword to codeword of the vector quantized (VQ) representation of the incoming speech at each SNR <ref> [6] </ref>. At low SNRs these vectors primarily compensate for effects of additive noise. At higher SNRs, the algorithm compensates for linear filtering, while at intermediate SNRs, they compensate for both of these ef fects.
Reference: 7. <author> Schwartz, R., Anastasakos, T., Kubala, F., Makhoul, J., Nguyen, L., and Zavaliagkos, G., </author> <title> Comparative Experiments on Large Vocabulary Speech Recognition, </title> <booktitle> Proc. ARPA Human Language Technology Workshop, </booktitle> <month> March, </month> <year> 1993. </year>
Reference-contexts: The third procedure, referred to as Gaussian environment classifier, models each environment with mixtures of Gaussian densities. Environment selection is accomplished so that the test data has the highest probability from the corresponding classifier. This latter approach is similar to one proposed previously by BBN <ref> [7] </ref>. All three methods produce similar speech recognition accuracy. 2.3. <p> Codebook Adaptation (DCCA and BWCA) A vector quantization (VQ) codebook, which is a set of mean vectors and/or co-variance matrices of cepstal representations, also exhibits some fundamental dif ferences when mismatches are encountered between training and testing environments <ref> [7] </ref>. This suggests that when such mismatches exist, the codebook can be tuned to better characterize the cepstral space of testing data. In this section, we propose two dif ferent implementations of such codebook adaptation. Dual-Channel Codebook Adaptation (DCCA).
Reference: 8. <author> Huang, X., Alleva, F., Hon, H., Hwang, M., Lee, K., and Rosenfeld, R., </author> <title> The SPHINX-II Speech Recognition System: An Overview, </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 2 </volume> <pages> 137-148, </pages> <year> 1993. </year>
Reference-contexts: Applications such as speech recognition in automobiles, over telephones, on a factory floor, or outdoors demand an even greater degree of environmental robustness. In this paper we describe and compare the performance of a series of cepstrum-based procedures that enable the CMU SPHINX-II <ref> [8] </ref> speech recognition system to maintain a high level of recognition accuracy over a wide variety of acoustical environments.






Reference: 1. <author> Juang, B.-H., </author> <title> Speech Recognition in Adverse Environments, </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 5 </volume> <pages> 275-294, </pages> <year> 1991. </year>
Reference: 2. <author> Acero, A., </author> <title> Acoustical and Environmental Robustness in Automatic SPeech Recognition, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Bos-ton, MA, </address> <year> 1993. </year>
Reference-contexts: In previous years we described the performance of cepstral mapping procedures such as the CDCN algorithm, which is ef fective but fairly computationally costly <ref> [2] </ref>. More recently we discussed the use of cepstral highpass-filtering algorithms [such as the popular RASTA and cepstral-mean-normalization algorithms (CMN) [6]. These algorithms are very simple to implement but somewhat limited in effectiveness, and CMN is now part of baseline processing for the CMU and many other systems.
Reference: 3. <author> Liu, F.H., Acero, A., and Stern, </author> <title> R.M., Effective Joint Compensation of Speech for the Effects of Additive Noise and Linear Filtering, </title> <booktitle> ICASSP-92, </booktitle> <pages> pp. 865-868, </pages> <month> March </month> <year> 1992. </year>
Reference: 4. <author> Hwang, M.Y., </author> <title> Subphonetic Acoustic Modeling for Speaker-Independent Continuous Speech Recognition, </title> <type> Ph.D. Thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1993. </year>
Reference: 5. <author> Huang, X.D., Ariki, Y., and Jack, M., </author> <title> Hidden Markov Models for Speech Recognition, </title> <publisher> Edinburgh University Press, </publisher> <address> Edin-burgh, U.K., </address> <year> 1990. </year>
Reference-contexts: In these circumstances, transformations can be developed between environments using the contents of the adaptation utterances using the Baum-Welch algorithm. In Baum-Welch codebook adaptation, mean vectors and covari-ance matrices, along with senones, are reestimated and updated using the Baum-Welch algorithm <ref> [5] </ref> during each iteration of training process. To compensate for the effect of changes in acoustical environments, the Baum-Welch approach is used to transform the means and covariances toward the cepstral space of the target testing environments.
Reference: 6. <author> Liu, F.H., Stern, R.M., Huang, X.D., and Acero A., </author> <title> Efficient Cepstral Normalization for Robust Speech Recognition, </title> <booktitle> Proceedings of ARPA Speech and Natural Language Workshop, </booktitle> <pages> pp. 69-74, </pages> <address> Princeton, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: In previous years we described the performance of cepstral mapping procedures such as the CDCN algorithm, which is ef fective but fairly computationally costly [2]. More recently we discussed the use of cepstral highpass-filtering algorithms [such as the popular RASTA and cepstral-mean-normalization algorithms (CMN) <ref> [6] </ref>. These algorithms are very simple to implement but somewhat limited in effectiveness, and CMN is now part of baseline processing for the CMU and many other systems. SIGNAL PROCESSING FOR ROBUST SPEECH RECOGNITION Fu-Hua Liu, Pedro J. Moreno, Richard M. <p> Multiple Fixed Codeword-Dependent Cepstral Normalization (MFCDCN) Multiple fixed codeword-dependent cepstral normalization (MFCDCN) provides additive cepstral compensation vectors that depend on signal-to-noise ratio (SNR) and that also vary from codeword to codeword of the vector quantized (VQ) representation of the incoming speech at each SNR <ref> [6] </ref>. At low SNRs these vectors primarily compensate for effects of additive noise. At higher SNRs, the algorithm compensates for linear filtering, while at intermediate SNRs, they compensate for both of these ef fects.
Reference: 7. <author> Schwartz, R., Anastasakos, T., Kubala, F., Makhoul, J., Nguyen, L., and Zavaliagkos, G., </author> <title> Comparative Experiments on Large Vocabulary Speech Recognition, </title> <booktitle> Proc. ARPA Human Language Technology Workshop, </booktitle> <month> March, </month> <year> 1993. </year>
Reference-contexts: The third procedure, referred to as Gaussian environment classifier, models each environment with mixtures of Gaussian densities. Environment selection is accomplished so that the test data has the highest probability from the corresponding classifier. This latter approach is similar to one proposed previously by BBN <ref> [7] </ref>. All three methods produce similar speech recognition accuracy. 2.3. <p> Codebook Adaptation (DCCA and BWCA) A vector quantization (VQ) codebook, which is a set of mean vectors and/or co-variance matrices of cepstal representations, also exhibits some fundamental dif ferences when mismatches are encountered between training and testing environments <ref> [7] </ref>. This suggests that when such mismatches exist, the codebook can be tuned to better characterize the cepstral space of testing data. In this section, we propose two dif ferent implementations of such codebook adaptation. Dual-Channel Codebook Adaptation (DCCA).
Reference: 8. <author> Huang, X., Alleva, F., Hon, H., Hwang, M., Lee, K., and Rosenfeld, R., </author> <title> The SPHINX-II Speech Recognition System: An Overview, </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 2 </volume> <pages> 137-148, </pages> <year> 1993. </year>
Reference-contexts: Applications such as speech recognition in automobiles, over telephones, on a factory floor, or outdoors demand an even greater degree of environmental robustness. In this paper we describe and compare the performance of a series of cepstrum-based procedures that enable the CMU SPHINX-II <ref> [8] </ref> speech recognition system to maintain a high level of recognition accuracy over a wide variety of acoustical environments.
Reference: 9. <author> Moreno, P. J., and Stern, R. M., </author> <title> Sources of Degradation of Speech Recognition in the Telephone Network, </title> <address> ICASSP-94, </address> <month> April, </month> <year> 1994. </year>
Reference-contexts: This choice of analysis bandwidth is appropriate when the system processes speech recorded through good-quality microphones such as the CLSTLK microphone. Nev ertheless, when speech is recorded from telephone lines, previous research at CMU <ref> [9] </ref> indicates that error rates are sharply decreased when the analysis bandwidth is reduced. This is accomplished by performing the normal DFT analysis with the normal 16,000-Hz sampling rate, but only retaining DFT coefficients after the triangular frequency smothing from center frequencies of 200 to 3700 Hz.
References-found: 33

