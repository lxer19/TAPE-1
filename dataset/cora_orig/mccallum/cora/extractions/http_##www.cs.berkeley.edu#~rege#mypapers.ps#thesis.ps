URL: http://www.cs.berkeley.edu/~rege/mypapers.ps/thesis.ps
Refering-URL: http://www.cs.berkeley.edu/~rege/
Root-URL: http://www.cs.berkeley.edu
Title: A Toolkit for Algebra and Geometry  
Degree: by Ashutosh Gajanan Rege A dissertation submitted in partial satisfaction of the requirements for the degree of Doctor of Philosophy in Computer Science in the GRADUATE DIVISION of the UNIVERSITY of CALIFORNIA at BERKELEY Committee in charge: Professor John Canny, Chair Professor David Forsyth Professor Bernd Sturmfels  
Date: 1996  
Abstract-found: 0
Intro-found: 1
Reference: [ABRW94] <author> M. Alonso, E. Becker, M.-F. Roy, and T. Wormann. </author> <title> Zeros, Multiplicities and Idempotents for Zero Dimensional Systems. </title> <booktitle> In Proceedings, </booktitle> <address> MEGA-94, </address> <year> 1994. </year>
Reference-contexts: A more efficient approach using the same general idea was given by Renegar in [Ren89b], [Ren92] and we will discuss this algorithm in more detail in Chapter 2. An alternate approach, based on much the same idea, goes by the name of the "Generalized Shape Lemma" <ref> [ABRW94] </ref>. The main difference from Renegar's approach is that the primitive element is obtained using a Grobner basis computation rather than by resultant. The general setting for the problem of answering logical questions about polynomial equations and inequalities is the first order theory of the reals [Tar48].
Reference: [Ald88] <author> B. Aldefeld. </author> <title> Variations of Geometries based on a Geometric-Reasoning Method. </title> <booktitle> Computer Aided Design, </booktitle> <volume> 20(3) </volume> <pages> 117-126, </pages> <year> 1988. </year>
Reference-contexts: The geometric theorem proving problem was shown to be related to the problem of constraint-based systems. Though a simpler problem (due to the absence of the parameters) it raises computational issues in its own right. There has been a fair amount of work done on developing constraint-based solvers (see <ref> [Ald88] </ref>, [BFH + 95], [Owe91] for a sampling). However, most of the work has focused on constraint-solvers for relatively simple objects such as line segments, points etc.
Reference: [AS88] <author> W. Auzinger and H.J. Stetter. </author> <title> An Elimination Algorithm for the Computation of all Zeros of a System of Multivariate Polynomial Equations. </title> <booktitle> In Proc. Intern. Conf. on Numerical Math., Intern. Series of Numerical Math., </booktitle> <volume> 86, </volume> <pages> pages 12-30. </pages> <publisher> Birkhauser Verlag, </publisher> <address> Basel, </address> <year> 1988. </year>
Reference-contexts: A similar approach is outlined in [ER94] where a monomial basis for the coordinate algebra of a zero-dimensional variety is obtained via the sparse resultant formulation [CE93]. The problem of counting and enumerating roots can then be reduced to a matrix eigenvalue problem <ref> [AS88] </ref>, [MC92]. The standard method for encoding the roots of a system of polynomial equations is to compute a (generalized) primitive element polynomial for the system.
Reference: [Bar68] <author> E.H. Bareiss. </author> <title> Sylvester's Identity and Multistep Integer-Preserving Gaussian Elimination. </title> <journal> Math. Comp., </journal> <volume> 22(103) </volume> <pages> 565-578, </pages> <year> 1968. </year>
Reference-contexts: The non-genericity of the input polynomials can result in a matrix which is singular or non-square. In both these cases we can resort to using Gaussian elimination (using a fraction-free method like that of Bareiss <ref> [Bar68] </ref>) to obtain the determinant of a maximal non-singular minor. As reported in [KSY94] this approach seems to work in most cases. In Section 4.4 we will address the issue of extra factors introduced during the resultant computation. <p> The entries of D can now be treated essentially as constants. 3. Computation of the Dixon resultant. If the Dixon matrix obtained in step 2 was square, we can compute its determinant using Bareiss' algorithm <ref> [Bar68] </ref>. If the determinant was not identically zero, we proceed to the next step. Else we have two cases: 1. The determinant is zero and 2. the matrix was not square.
Reference: [Ber75] <author> D. N. Bernstein. </author> <title> The number of roots of a system of equations. </title> <journal> (Translated from) Funktsional'nyi Analiz i Ego Prilozheniya, </journal> <volume> 9(3) </volume> <pages> 1-4, </pages> <month> Jul-Sep </month> <year> 1975. </year>
Reference: [BFH + 95] <author> W. Bouma, I. Fudos, C. Hoffmann, J. Cai, and R. Paige. </author> <title> A Geometric Constraint Solver. </title> <booktitle> Computer Aided Design, </booktitle> <volume> 27(6) </volume> <pages> 487-501, </pages> <year> 1995. </year>
Reference-contexts: Though a simpler problem (due to the absence of the parameters) it raises computational issues in its own right. There has been a fair amount of work done on developing constraint-based solvers (see [Ald88], <ref> [BFH + 95] </ref>, [Owe91] for a sampling). However, most of the work has focused on constraint-solvers for relatively simple objects such as line segments, points etc.
Reference: [BOKR86] <author> M. Ben-Or, D. Kozen, and J. Reif. </author> <title> The Complexity of Elementary Algebra and Geometry. </title> <journal> J. Comp. and Sys. Sci., </journal> <volume> 32 </volume> <pages> 251-264, </pages> <year> 1986. </year>
Reference-contexts: This has been shown to be decidable in polynomial space and single exponential time [Can88], [Ren89a]. Most of the work on real algebraic algorithms makes use of a sign-determination lemma due to Ben-Or, Kozen and Reif <ref> [BOKR86] </ref> which provides an algorithm for determining the signs of a set of polynomials at the roots on another. <p> A fundamental result in computational real algebraic geometry is that due to Ben-Or, Kozen and Reif <ref> [BOKR86] </ref>: The input is the polynomial p and q i 's and the output is m sign sequences 2 f+; ; 0g where m is the number of real roots of p (s). <p> In general for n polynomials, g i , one can generate the matrix A n analogously. Ben-Or, Kozen and Reif <ref> [BOKR86] </ref> give a method for solving such systems in time polynomial in n. An improvement on the BKR algorithm was given in [Can91a] and [Can93] where the matrix rank tests of the BKR algorithm were eliminated.
Reference: [BR90] <author> R. Benedetti and J.-J. Risler. </author> <title> Real Algebraic and Semi-Algebraic Sets. </title> <publisher> Hermann, </publisher> <address> Paris, </address> <year> 1990. </year>
Reference: [BS83] <author> W. Baur and V. Strassen. </author> <title> The Complexity of Partial Derivatives. </title> <journal> Theoretical Computer Science, </journal> <volume> 22 </volume> <pages> 317-330, </pages> <year> 1983. </year> <month> 91 </month>
Reference: [BT71] <author> W.S. Brown and J.F. Traub. </author> <title> On Euclid's Algorithm and the Theory of Subre-sultants. </title> <journal> Journal of the ACM, </journal> <volume> 18 </volume> <pages> 505-514, </pages> <year> 1971. </year>
Reference: [Can88] <author> J.F. Canny. </author> <title> Some Algebraic and Geometric Computations in PSPACE. </title> <booktitle> In ACM Symposium on Theory of Computing, </booktitle> <pages> pages 460-467, </pages> <year> 1988. </year>
Reference-contexts: The standard method for encoding the roots of a system of polynomial equations is to compute a (generalized) primitive element polynomial for the system. Typically one computes (a multiple of ) the resultant as outlined in <ref> [Can88] </ref> as the primitive element polynomial and a set of rational functions which encode the roots symbolically. A more efficient approach using the same general idea was given by Renegar in [Ren89b], [Ren92] and we will discuss this algorithm in more detail in Chapter 2. <p> A useful restriction of the first order theory is the existential theory of the reals where only existential quantifiers are allowed. This has been shown to be decidable in polynomial space and single exponential time <ref> [Can88] </ref>, [Ren89a]. Most of the work on real algebraic algorithms makes use of a sign-determination lemma due to Ben-Or, Kozen and Reif [BOKR86] which provides an algorithm for determining the signs of a set of polynomials at the roots on another. <p> One method is to use polynomial greatest common divisors as outlined in <ref> [Can88] </ref>. An alternate approach based on differentiation was given by Renegar in [Ren89b], [Ren92]. This algorithm is more efficient in practice and is particularly suited for use with the straight-line program described in Chapter 3.
Reference: [Can91a] <author> J.F. Canny. </author> <title> An Improved Sign Determination Algorithm. </title> <booktitle> In AAECC-91, 1991. </booktitle> <address> New Orleans. </address>
Reference-contexts: Since most logical questions such as those posed in section 1.1.2 can be rephrased in terms of signs of polynomials, this algorithm, and variants thereof <ref> [Can91a] </ref>, can be used to solve a large class of such problems. 1.3 Thesis Motivation and Overview Several factors motivated the development of the toolkit described in this thesis. The first is the development of a collection of techniques which improve the efficiency of solving systems of equations and inequalities. <p> The first is the development of a collection of techniques which improve the efficiency of solving systems of equations and inequalities. These include algorithms for sign determination <ref> [Can91a] </ref> and techniques for integrating symbolic and numeric computations which we will describe in Chapter 4. Additionally, we make use of the straight-line program data structure to represent computations involving polynomials and rational functions. <p> In general for n polynomials, g i , one can generate the matrix A n analogously. Ben-Or, Kozen and Reif [BOKR86] give a method for solving such systems in time polynomial in n. An improvement on the BKR algorithm was given in <ref> [Can91a] </ref> and [Can93] where the matrix rank tests of the BKR algorithm were eliminated. <p> That is, set u i = h i (t) in lcoeff (p 1 (s)); : : :; lcoeff (p k (s)) 5. Apply the sign determination algorithm of <ref> [Can91a] </ref> to determine the sign sequences for the lcoeff (p i ) at the roots of H (t). For each root ff of H (t) we get a sign sequence ff 2 f+; ; 0g k . 6.
Reference: [Can91b] <author> J.F. Canny. </author> <title> Computing Roadmaps of General Semi-Algebraic Sets. </title> <booktitle> In AAECC-91, 1991. </booktitle> <address> New Orleans. </address>
Reference-contexts: This approach can be used in various algorithms in which the assumption is that the semi-algebraic sets corresponding to the input polynomials are in generic position [HRS90], <ref> [Can91b] </ref>. One provides a scheme to perturb the input with infinitesimals without changing properties such as connectivity. Typically, then, one is interested in determining the signs of the leading coefficients of various polynomials generated in the course of the computation. <p> ; a n ) 2 A n , we have to specify the variable with respect to which the derivative was taken. 3.5 Computing with Infinitesimals A standard approach to dealing with singularities in various algebraic and geometric problems defined by polynomials is to perturb the input polynomials with infinitesimals <ref> [Can91b] </ref>, [HRS90]. This de-singularizes the problem, and preserves important properties like connectivity or non-emptiness of the input. Perturbations of this kind require computation over the base field augmented by infinitesimals. <p> Solve the following system in the limit as * ! 0: R 0 = 0 @u 0 = = @u 0 = 0 (5.15) using the algorithm described in <ref> [Can91b] </ref>. The result of this step is a polynomial H (t) and rational functions (h 1 (t); : : : ; h d (t)) describing "witness points" in the connected components of V IR (r). 4.
Reference: [Can93] <author> John Canny. </author> <title> Improved Algorithms for Sign-Determination and Existential Quantifier Elimination. </title> <journal> Computer Journal, </journal> <note> 1993. Special Issue on Quantifier Elimination. </note>
Reference-contexts: In general for n polynomials, g i , one can generate the matrix A n analogously. Ben-Or, Kozen and Reif [BOKR86] give a method for solving such systems in time polynomial in n. An improvement on the BKR algorithm was given in [Can91a] and <ref> [Can93] </ref> where the matrix rank tests of the BKR algorithm were eliminated. <p> Then the sign of g j at the roots of of f 1 ; : : : ; f n is obtained by determining the sign of h j at the roots of the resultant polynomial p (s). This can be done efficiently by using the algorithm of <ref> [Can93] </ref>. 4.4 The Complete Algorithm We will now give a description of the complete algorithm based on the aforementioned ideas. <p> Thus we are interested in computing the signs of the h j (s) at the roots of p (s) these will be the signs of the g j 's at the common roots of the f i 's. We compute these signs using univariate sign determination algorithm of <ref> [Can93] </ref> which computes the signs of a set of polynomials at the roots of a given polynomial. These are output as as tuples [sign (g 1 ); : : :; sign (g m )] for each root of p (s), where sign (g j ) 2 f0; +; g.
Reference: [CE93] <author> John Canny and Ioannis Emiris. </author> <title> An efficient algorithm for the sparse mixed resultant. </title> <editor> In G. Cohen, T. Mora, and O. Moreno, editors, </editor> <booktitle> Proc. 10th Intern. Symp. on Applied Algebra, Algebraic Algorithms and Error-Correcting Codes, </booktitle> <pages> pages 89-104. </pages> <publisher> Springer Verlag, </publisher> <month> May </month> <year> 1993. </year> <note> Lect. Notes in Comp. Science 263. </note>
Reference-contexts: An alternate approach based on multivariate symmetric functions is given in [Ped91]. A similar approach is outlined in [ER94] where a monomial basis for the coordinate algebra of a zero-dimensional variety is obtained via the sparse resultant formulation <ref> [CE93] </ref>. The problem of counting and enumerating roots can then be reduced to a matrix eigenvalue problem [AS88], [MC92]. The standard method for encoding the roots of a system of polynomial equations is to compute a (generalized) primitive element polynomial for the system. <p> More recently, attention has focused on taking the inherent sparseness of the given system of equations into account. The foundations of sparse elimination theory were laid in the work of Gelfand, Kapranov and Zelevinsky [GKZ90] and Sturmfels [Stu91]. Canny and Emiris <ref> [CE93] </ref> provide an algorithm for constructing the so-called sparse resultant which, in general, gives a more compact condition than the Macaulay or other formulations. To summarize then, we have in general a range of resultant formulations available to us. <p> We have shown how to compute the number of real roots for polynomial systems defined by two equations in two variables using Sylvester resultants. The next step is to use the sparse resultant formulation <ref> [CE93] </ref> to compute the real roots of systems with more variables.
Reference: [CF] <author> C. Chauvin and J.-C. Faugere. </author> <title> Basic user's manual of faugere's gb package. </title> <note> Manuscript available at http://posso.ibp.fr. </note>
Reference-contexts: The former approach has been implemented as part of the "Gb" package [Fau94], <ref> [CF] </ref> and is indicated as such in the following table. The latter approach is based on using numerical continuation methods and is implemented in the Fortran package HOMPACK.
Reference: [CGZ94] <author> S.-C. Chou, X.-S. Gao, and J.-Z. Zhang. </author> <title> Machine Proofs in Geometry Automated Production of Readable Proofs for Geometry Theorems. </title> <publisher> World Scientifc, </publisher> <address> Singapore, </address> <year> 1994. </year>
Reference-contexts: A more recent approach is that based on the "area" method <ref> [CGZ94] </ref>. It is a combination of the synthetic and algebraic approaches. The algebraic component reflects the natural progression in geometric invariants from cartesian coordinates to distance geometry to the use of areas and volumes as the basic quantities.
Reference: [Cho84] <author> S.-C. Chou. </author> <title> Proving Elementary Geometry Theorems Using Wu's Algorithm. In W.W. </title> <editor> Bledsoe and D.W. Loveland, editors, </editor> <title> Theorem Proving : After 25 Years. </title> <publisher> American Mathematical Society, </publisher> <year> 1984. </year>
Reference-contexts: Wu's seminal work ([Wu78], [Wu84]) recast the problem in terms of algebraic geometry and thereafter a significant amount of the recent work has focussed on an algebraic approach involving determining the feasibility of systems of polynomial equations <ref> [Cho84] </ref>, [KS86], [Kap88]. The papers by Wu and others showed how a subclass of geometric theorems can be proved by expressing the hypotheses and conclusions as polynomial equations as described in section 5.1. <p> The basis of his work was a triangulation procedure which was implicit in the work of Ritt [Rit32], [Rit50] and which was given in detail by Wu. Wu's approach was implemented with various modifications and improvements by Chou in his prover <ref> [Cho84] </ref>, [Cho88]. The following is based on the book by Chou [Cho88] with some notational changes.
Reference: [Cho88] <author> S.-C. Chou. </author> <title> Mechanical Geometry Theorem Proving. Mathematics and its applications. </title> <address> D. </address> <publisher> Reidel, Holland, </publisher> <year> 1988. </year>
Reference-contexts: Other work has focussed on using Grobner bases to determine whether a system of polynomials (obtained from the original polynomials) has a common zero [KS86], [Kap88]. As noted in <ref> [Cho88] </ref> (pp. 88-89) and evinced by the some of the benchmarks [KS86], [Kap88], Grobner basis methods for theorem proving have proved to be rather slow, in most cases requiring times 50-100 times more than the characteristic set methods 1 . A somewhat different approach is taken in [Wan93] and [Wan95]. <p> Several formulations of these two questions have been proposed [Gel63], [Kap86],[KS86]. See the book by Chou <ref> [Cho88] </ref> for a discussion of the various formulations and the limitations of each. We will use the formulation used by Chou [Cho88] which seems to be the one that is the most satisfactory: Definition 5.4.1 By a geometric statement (S) we shall mean a collection of n polynomial equations h 1 <p> Several formulations of these two questions have been proposed [Gel63], [Kap86],[KS86]. See the book by Chou <ref> [Cho88] </ref> for a discussion of the various formulations and the limitations of each. We will use the formulation used by Chou [Cho88] which seems to be the one that is the most satisfactory: Definition 5.4.1 By a geometric statement (S) we shall mean a collection of n polynomial equations h 1 (y 1 ; : : : ; y m ) = : : : = h n (y 1 ; : <p> We will also consider a prover implemented by Chou and derived essentially from this algorithm <ref> [Cho88] </ref>. Among all the approaches that have been used and implemented, Chou's prover seems to be most complete and efficient and we will use this prover as the basis of comparison for our prover. <p> The basis of his work was a triangulation procedure which was implicit in the work of Ritt [Rit32], [Rit50] and which was given in detail by Wu. Wu's approach was implemented with various modifications and improvements by Chou in his prover [Cho84], <ref> [Cho88] </ref>. The following is based on the book by Chou [Cho88] with some notational changes. <p> Wu's approach was implemented with various modifications and improvements by Chou in his prover [Cho84], <ref> [Cho88] </ref>. The following is based on the book by Chou [Cho88] with some notational changes. <p> A triangular form is a collection of polynomials f i of the form f 1 (u 1 ; : : : ; u d ; x 1 ) (5.5) A triangular form can be obtained from the original hypotheses polynomials very easily by applying the following naive triangulation algorithm (cf. <ref> [Cho88] </ref>, [CLO92]). Algorithm 5.5.1 (Naive Triangulation) Input: Set of polynomials H = fh 1 ; : : : ; h n g, h i 2 K [x; u] Output: Ordered set of polynomials T = ff 1 ; : : : ; f n g satisfying (5.5). <p> If I is prime and prem (g; f 1 ; : : : ; f r ) = 0 then g 2 I. In practice, one computes what is called an extended characteristic set (see <ref> [Cho88] </ref>). The basic Ritt-Wu algorithm is then obvious: Algorithm 5.5.2 (Basic Ritt-Wu Algorithm) Input: Hypotheses H = fh 1 ; : : : ; h n g and conclusion g Output: "True", if the conclusion is generally true. 1. <p> As stated earlier, we will use the prover due to Chou <ref> [Cho88] </ref> as the reference point since it is based on the Ritt-Wu algorithm and has proven to be the most successful implementation. <p> We have the following result (see e.g., <ref> [Cho88] </ref>): We first define P = f g j g 2 K [u; x] and prem (g; f 1 ; : : : ; f n ) = 0g (5.8) Theorem 5.5.10 (Necessary Condition) If F = &lt; f 1 ; : : : ; f r &gt; is an irreducible <p> We can translate the hypotheses into polynomial equations by using the tangent equations for the angles (cf. <ref> [Cho88] </ref>, pp. 40). h 1 = (u 1 x 2 ) 3x 1 u 1 3u 1 3 (5.18) 2 (u 2 x 2 ) + x 1 u 2 h 3 = (u 1 2 2u 1 x 2 + x 2 2 + x 1 2 ) where, a <p> The time taken is about 45 minutes on a Sun Sparc 10. Chou's prover cannot deal with this problem. It will require factoring a degree 8 equation as well as a degree 4 equation over an extension field. As described in <ref> [Cho88] </ref> (pp. 67-69), Chou's approach is to first reformulate the problem to get a system of hypotheses equations which are at most quadratic in degree. <p> Statements of these theorems can be obtained from <ref> [Cho88] </ref>. The second and third columns give the number of variables and the total degree of the system in the variables x 1 ; : : : ; x n . The fourth column gives the time required to compute the root representation of the system using Algorithm 5.7.1.
Reference: [CLO92] <author> D. Cox, J. Little, and D. O'Shea. </author> <title> Ideals, Varieties, and Algorithms. Undergraduate Texts in Mathematics. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1992. </year> <month> 92 </month>
Reference-contexts: triangular form is a collection of polynomials f i of the form f 1 (u 1 ; : : : ; u d ; x 1 ) (5.5) A triangular form can be obtained from the original hypotheses polynomials very easily by applying the following naive triangulation algorithm (cf. [Cho88], <ref> [CLO92] </ref>). Algorithm 5.5.1 (Naive Triangulation) Input: Set of polynomials H = fh 1 ; : : : ; h n g, h i 2 K [x; u] Output: Ordered set of polynomials T = ff 1 ; : : : ; f n g satisfying (5.5). Procedure: NaiveTriangulate (H) 1.
Reference: [Col67] <author> G. Collins. </author> <title> Subresultants and Reduced Polynomial Remainder Sequences. </title> <journal> Journal of ACM, </journal> <volume> 14 </volume> <pages> 128-142, </pages> <year> 1967. </year>
Reference: [Col75] <author> G. Collins. </author> <title> Quantifier elimination for real closed fields by cylindrical algebraic decomposition. </title> <publisher> Springer LNCS, </publisher> <pages> 33 135-183, </pages> <year> 1975. </year>
Reference-contexts: This theory has been shown to be decidable [Tar48] in time doubly exponential in the size of the input <ref> [Col75] </ref>. A useful restriction of the first order theory is the existential theory of the reals where only existential quantifiers are allowed. This has been shown to be decidable in polynomial space and single exponential time [Can88], [Ren89a].
Reference: [Cox69] <author> H.S.M. Coxeter. </author> <title> Introduction to Geometry. </title> <editor> J. </editor> <publisher> Wiley and Sons, Inc., </publisher> <address> New York, </address> <year> 1969. </year>
Reference: [Cra86] <author> J. Craig. </author> <title> Introduction to Robotics. </title> <publisher> Addison-Wesley Publishing Co., </publisher> <year> 1986. </year>
Reference-contexts: And the problem is to determine the corresponding values of p and R. The matrix R, being an orientation matrix, is defined by three scalar variables. Thus we get a system of 6 equations in 6 unknowns. We can write R as (see <ref> [Cra86] </ref>): 0 B @ cos ffcos fi cos ffsin fisin fl sin ffcos fl cos ffsin ficos fl + sin ffsin fl sin ffcos fi sin ffsin fisin fl + cos ffcos fl sin ffsin ficos fl cos ffsin fl sin fi cos ffsin fl cos ficos fl 1 C A
Reference: [Dix08] <author> A.L. Dixon. </author> <title> The eliminant of three quantics in two independent variables. </title> <journal> Proceedings of London Mathematical Society, </journal> <volume> 6 </volume> <pages> 49-69, 209-236, </pages> <year> 1908. </year>
Reference-contexts: For the case of two polynomials in one unknown, the Sylvester formulation of the resultant (See, e.g. [Mis93] for a review of the Sylvester resultant and its properties) gives a determinantal condition on the existence of a common solution. The Dixon resultant <ref> [Dix08] </ref> gives a similar condition for the case of three polynomials in two unknowns. A more general construction is due to Macaulay [Mac21] who gave the formulation of the resultant of n homogeneous polynomials in n variables as the quotient of a determinant by one of its minors.
Reference: [Ede87] <author> H. Edelsbrunner. </author> <title> Algorithms in Combinatorial Geometry. </title> <booktitle> Number 10 in EATCS Monographs on Theoretical Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1987. </year>
Reference-contexts: The second major application of SLP's is to the problem of geometric theorem proving which is discussed in Chapter 5. 35 Chapter 4 Implicit Point Location and Predicates for Geometry 4.1 Introduction Point location problems are a fundamental area of interest in computational geometry <ref> [Ede87] </ref>. Problems of this kind arise in various contexts: In some applications one is given a subdivision of the Euclidean plane or 3-space and a query point, and one wishes to locate the query point with respect to the subdivision.
Reference: [Emi94] <author> I. Emiris. </author> <title> Sparse Elimination and Applications in Kinematics. </title> <type> Ph.D. Thesis, </type> <institution> University of Calfifornia, Berkeley, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: In Chapter 5, we will show that the Sylvester resultant is sufficient for solving triangular systems of equations. In other cases, such as the Stewart platform discussed in section 1.1.1 using the sparse resultant gives us a more compact formulation than can be obtained from other methods <ref> [Emi94] </ref> [ER94]. 2.1 Encoding the Roots of Systems of Polynomials A fundamental algorithm in the toolkit is that for symbolically encoding the roots of a given system of polynomials. <p> We have shown how to compute the number of real roots for polynomial systems defined by two equations in two variables using Sylvester resultants. The next step is to use the sparse resultant formulation [CE93] to compute the real roots of systems with more variables. In <ref> [Emi94] </ref> and [ER94], this formulation was applied successfully to count (or give upper bounds for) the total number of isolated roots (both real and complex) for large systems such as those defined by the Stewart platform described in Chapter 1.
Reference: [ER94] <author> I. Emiris and A. </author> <title> Rege. Monomial Bases and Polynomial System Solving. </title> <booktitle> In International Symposium on Symbolic and Algebraic Computation, </booktitle> <pages> pages 114-122, </pages> <address> 1994. Oxford, England. </address>
Reference-contexts: Several systems have proved themselves amenable to sparse elimination theory and tighter bounds for systems such as those defined by the cyclic n-roots problem and the "motion from point matches" problem in vision have been obtained <ref> [ER94] </ref>. The case of the reals is harder and not many general results exist on tight bounds for the number of real roots of a given polynomial system. <p> This algorithm is based on computing a monomial basis (usually via a Grobner basis computation) and setting up a multiplication table for the coordinate algebra. An alternate approach based on multivariate symmetric functions is given in [Ped91]. A similar approach is outlined in <ref> [ER94] </ref> where a monomial basis for the coordinate algebra of a zero-dimensional variety is obtained via the sparse resultant formulation [CE93]. The problem of counting and enumerating roots can then be reduced to a matrix eigenvalue problem [AS88], [MC92]. <p> In Chapter 5, we will show that the Sylvester resultant is sufficient for solving triangular systems of equations. In other cases, such as the Stewart platform discussed in section 1.1.1 using the sparse resultant gives us a more compact formulation than can be obtained from other methods [Emi94] <ref> [ER94] </ref>. 2.1 Encoding the Roots of Systems of Polynomials A fundamental algorithm in the toolkit is that for symbolically encoding the roots of a given system of polynomials. <p> We have shown how to compute the number of real roots for polynomial systems defined by two equations in two variables using Sylvester resultants. The next step is to use the sparse resultant formulation [CE93] to compute the real roots of systems with more variables. In [Emi94] and <ref> [ER94] </ref>, this formulation was applied successfully to count (or give upper bounds for) the total number of isolated roots (both real and complex) for large systems such as those defined by the Stewart platform described in Chapter 1.
Reference: [Fau94] <author> J.-C. Faugere. </author> <title> Resolution des Systemes d'Equations Algebriques. </title> <type> Ph.D. Thesis, </type> <institution> Universite Paris 6, </institution> <year> 1994. </year>
Reference-contexts: The former approach has been implemented as part of the "Gb" package <ref> [Fau94] </ref>, [CF] and is indicated as such in the following table. The latter approach is based on using numerical continuation methods and is implemented in the Fortran package HOMPACK.
Reference: [FIKY88] <author> T. S. Freeman, G. Imirzian, E. Kaltofen, and L. Yagati. DAGWOOD: </author> <title> A System for Manipulating Polynomials Given by Straight-Line Programs. </title> <journal> ACM Trans. Math. Software, </journal> <volume> 14(3) </volume> <pages> 218-240, </pages> <year> 1988. </year>
Reference-contexts: Most of the above work was theoretical in nature, attempting to classify various algebraic problems with respect to their complexity as measured in the sizes of the SLP's etc. An implementation of a system for creating and manipulating SLP's is described in <ref> [FIKY88] </ref>. 3.3 Straight-line Program Basics There are two standard definitions of straight-line programs which lead to two distinct approaches for their implementation. Definition 3.3.1 (see [Str72], [vzG87]) Let A be a ring (resp. field) and x 1 ; : : : ; x n inde-terminates over A.
Reference: [For92] <author> S. Fortune. </author> <title> Numerical Stability of Algorithms for Delaunay Triangulations. </title> <booktitle> In ACM Symposium on Computationl Geometry, </booktitle> <pages> pages 83-92, </pages> <year> 1992. </year>
Reference-contexts: A common approach is to use fixed precision floating-point arithmetic but there are no simple techniques that guarantee that the program will provide reliable answers. Usually the approach is to analyze the particular algorithm on hand for stability and correctness when using floating-point arithmetic <ref> [For92] </ref>, [Mil88]. Such analyses do not lend themselves to generalization and tend to be difficult and algorithm-specific. An alternate approach is to use exact integer arithmetic. The immediate problem with this approach is that one often requires precision beyond the standard 32 bits provided by most computers.
Reference: [FW93] <author> S. Fortune and C. Van Wyk. </author> <title> Efficient Exact Arithmetic for Computational Geometry. </title> <booktitle> In ACM Symposium on Computationl Geometry, </booktitle> <pages> pages 163-172, </pages> <year> 1993. </year>
Reference-contexts: Fixed-precision floating point arithmetic has the problem that there are no simple techniques that guarantee the reliability of the result. One runs into 37 fairly severe problems of numerical stability even when dealing with relatively uncompli-cated computations such as those in planar computational geometry of line segments and polygons <ref> [FW93] </ref>. When dealing with higher degree objects such as spheres, the problem gets worse. Most algebraic computations result in polynomials with large coefficients, usually beyond the range of fixed-precision floating point. One solution is to use software multiprecision integer arithmetic.
Reference: [GCL92] <author> K. Geddes, S. Czapor, and G. Labahn. </author> <title> Algorithms for Computer Algebra. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1992. </year> <month> 93 </month>
Reference-contexts: These include SLP arithmetic, evaluation, interpolation, differentiation (both symbolic and otherwise), detecting singularities, and computing the sign of an SLP over a real ordered field. Chapter 3 discusses all of these operations in detail. Polynomials. Polynomials are represented in the toolkit using the sparse recursive representation <ref> [GCL92] </ref>. That is, the sparse recursive polynomial data structure defines it as a polynomial in the leading variable with coefficients which are sparse recursive polynomials in the rest of the variables. Various algorithms for polynomials are provides including polynomial arithmetic, pseudoremainders etc.
Reference: [Gel63] <author> H. Gelernter. </author> <title> Realization of a Geometry Theorem Proving Machine. In E.A. </title> <editor> Feigenbaum and J.E. Feldman, editors, </editor> <booktitle> Computers and Thought. </booktitle> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1963. </year>
Reference-contexts: the requirements of what it means to "prove" a theorem in this setting to take into account such degenerate cases. 52 5.2 Background and Related Work Earlier methods for geometric theorem proving were based on a synthetic geometric reasoning approach using natural deduction, forward and backward chaining and the like <ref> [Gel63] </ref>. Wu's seminal work ([Wu78], [Wu84]) recast the problem in terms of algebraic geometry and thereafter a significant amount of the recent work has focussed on an algebraic approach involving determining the feasibility of systems of polynomial equations [Cho84], [KS86], [Kap88]. <p> It should be practicable. 54 5.4 Geometric Theorem Proving Formulation of the Prob lem This section provides the formulation we shall use of the questions of what constitutes a geometric theorem and what it means to prove it. Several formulations of these two questions have been proposed <ref> [Gel63] </ref>, [Kap86],[KS86]. See the book by Chou [Cho88] for a discussion of the various formulations and the limitations of each.
Reference: [GH93] <author> M. Giusti and J. Heintz. </author> <title> La determination des points isoles et de la dimension d'une variete algebrique peut se faire en temps polynomial. </title> <editor> In D. Eisenbud and L. Robbiano, editors, </editor> <booktitle> Computational Algebraic Geoemetry and Commutative Algebra Proceedings of the Cortona Conference, volume 34 of Symposia Matematica. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1993. </year>
Reference-contexts: The prob 24 lem of equivalence of polynomials is considered in [HS80], [IM83]. Various problems such as greatest common divisors and factorization are considered in [Kal88], [Kal89]. The straight-line program view was extended to multivariate elimination theory in <ref> [GH93] </ref>, [GJML95], [GJM + 95]. Most of the above work was theoretical in nature, attempting to classify various algebraic problems with respect to their complexity as measured in the sizes of the SLP's etc.
Reference: [GJM + 95] <author> M. Giusti, J.Heintz, J. Morais, J. Morgenstern, and L.Pardo. </author> <title> Straight-line Programs in Geometric Elimination Theory. </title> <type> Manuscript, </type> <year> 1995. </year>
Reference-contexts: The prob 24 lem of equivalence of polynomials is considered in [HS80], [IM83]. Various problems such as greatest common divisors and factorization are considered in [Kal88], [Kal89]. The straight-line program view was extended to multivariate elimination theory in [GH93], [GJML95], <ref> [GJM + 95] </ref>. Most of the above work was theoretical in nature, attempting to classify various algebraic problems with respect to their complexity as measured in the sizes of the SLP's etc.
Reference: [GJML95] <author> M. Giusti, J.Heintz, J. Morais, and L.Pardo. </author> <title> When Polynomial Equation Systems Can Be "Solved" Fast ? In AAECC-11. </title> <publisher> Springer LNCS 948, </publisher> <year> 1995. </year>
Reference-contexts: The prob 24 lem of equivalence of polynomials is considered in [HS80], [IM83]. Various problems such as greatest common divisors and factorization are considered in [Kal88], [Kal89]. The straight-line program view was extended to multivariate elimination theory in [GH93], <ref> [GJML95] </ref>, [GJM + 95]. Most of the above work was theoretical in nature, attempting to classify various algebraic problems with respect to their complexity as measured in the sizes of the SLP's etc.
Reference: [GKZ90] <author> I. M. Gel'fand, M. M. Kapranov, and A. V. Zelevinsky. </author> <title> Discriminants of Polynomials in Several Variables and Triangulations of Newton Polytopes. </title> <journal> (Translated from) Algebara i Analiz, </journal> <volume> 2 </volume> <pages> 1-62, </pages> <year> 1990. </year> <note> (English Translation in) Leningrad Math. J. 2 (1991). </note>
Reference-contexts: For more details on these formulations see the excellent review by Kapur and Lakshman [KL92]. More recently, attention has focused on taking the inherent sparseness of the given system of equations into account. The foundations of sparse elimination theory were laid in the work of Gelfand, Kapranov and Zelevinsky <ref> [GKZ90] </ref> and Sturmfels [Stu91]. Canny and Emiris [CE93] provide an algorithm for constructing the so-called sparse resultant which, in general, gives a more compact condition than the Macaulay or other formulations. To summarize then, we have in general a range of resultant formulations available to us.
Reference: [GM91] <author> G. Gallo and B. Mishra. </author> <title> Efficient Algorithms and Bounds for Wu-Ritt Characteristic Sets. </title> <editor> In T. Mora and C. Traverso, editors, </editor> <title> Effective Methods in Algebraic Geometry, </title> <booktitle> volume 94 of Progress in Mathematics, </booktitle> <pages> pages 119-142. </pages> <publisher> Birkhauser, </publisher> <year> 1991. </year>
Reference-contexts: However, it was shown in <ref> [GM91] </ref> that the degree of the polynomials in a characteristic set for a zero-dimensional ideal I Q [x 1 ; : : : ; x n ] is O (d O (n) ) and the complexity of computing 71 these characteristic sets is O (n 3:376 d O (n 3 )
Reference: [Hav91] <author> T. </author> <title> Havel. Some Examples of the use of Distances as Coordinates for Euclidean Geometry. </title> <journal> Journal of Symbolic Computation, </journal> <volume> 11 </volume> <pages> 579-593, </pages> <year> 1991. </year>
Reference-contexts: Both the Ritt-Wu approach and this one, however, rely on factorization over extension fields as we shall see in section 5.5. Another technique based on algebraic formulation is the distance geometry method for proving theorems <ref> [Hav91] </ref>. Here the hypotheses constraints are formulated as polynomials in variables which represent distances rather than cartesian coordinates. The trade-off is that equations involving distances are reduced in degree at the expense of adding more variables than in the case of cartesian coordinates.
Reference: [Hof89] <author> C.M. Hoffmann. </author> <title> Geometric and Solid Modeling. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1989. </year>
Reference-contexts: Even if the point is given by its cartesian coordinates, locating it with respect to a solid is still a non-trivial task due to the difficulties arising when the point lies on the surface of the object <ref> [Hof89] </ref>. The more natural problem arises when the point is represented implicitly as the intersection of other geometric objects, where the complications are compounded. <p> x 3 2 + x 2 g 5 = x 2 3 6x 2 x 3 = 0 The semi-algebraic set S is given by: ((g 1 ^ g 2 ) ^ (:g 3 ) ^ (:g 4 )) ^ g 5 (The object defined by S is discussed in <ref> [Hof89] </ref> where the problem of edge identification is considered.
Reference: [HRS90] <author> J. Heintz, M.F. Roy, and P. Solerno. Complexite du Principe de Tarski-Seidenberg. </author> <title> Bull. </title> <journal> Soc. Math. France, </journal> <volume> 118 </volume> <pages> 101-126, </pages> <year> 1990. </year>
Reference-contexts: This approach can be used in various algorithms in which the assumption is that the semi-algebraic sets corresponding to the input polynomials are in generic position <ref> [HRS90] </ref>, [Can91b]. One provides a scheme to perturb the input with infinitesimals without changing properties such as connectivity. Typically, then, one is interested in determining the signs of the leading coefficients of various polynomials generated in the course of the computation. <p> a n ) 2 A n , we have to specify the variable with respect to which the derivative was taken. 3.5 Computing with Infinitesimals A standard approach to dealing with singularities in various algebraic and geometric problems defined by polynomials is to perturb the input polynomials with infinitesimals [Can91b], <ref> [HRS90] </ref>. This de-singularizes the problem, and preserves important properties like connectivity or non-emptiness of the input. Perturbations of this kind require computation over the base field augmented by infinitesimals. Consider the case where we introduce one infinitesimal *: the computations are now carried out over the extension field A (*).
Reference: [HS80] <author> J. Heintz and C.P. Schnorr. </author> <title> Testing Polynomials which are Easy to Compute. </title> <booktitle> In ACM Symposium on Theory of Computing, </booktitle> <year> 1980. </year> <month> 94 </month>
Reference-contexts: Since then a considerable amount of work has been devoted to understanding the algebraic complexity of various problems in terms of straight-line programs. The prob 24 lem of equivalence of polynomials is considered in <ref> [HS80] </ref>, [IM83]. Various problems such as greatest common divisors and factorization are considered in [Kal88], [Kal89]. The straight-line program view was extended to multivariate elimination theory in [GH93], [GJML95], [GJM + 95].
Reference: [IM83] <author> O. Ibarra and S. Moran. </author> <title> Probabilistic Algorithms for Deciding Equivalence of Straight-Line Programs. </title> <journal> JACM, </journal> <volume> 30(1) </volume> <pages> 217-228, </pages> <year> 1983. </year>
Reference-contexts: Since then a considerable amount of work has been devoted to understanding the algebraic complexity of various problems in terms of straight-line programs. The prob 24 lem of equivalence of polynomials is considered in [HS80], <ref> [IM83] </ref>. Various problems such as greatest common divisors and factorization are considered in [Kal88], [Kal89]. The straight-line program view was extended to multivariate elimination theory in [GH93], [GJML95], [GJM + 95].
Reference: [Kal88] <author> Erich Kaltofen. </author> <title> Greatest Common Divisors of Polynomials Given by Straight-Line programs. </title> <journal> Journal of the ACM, </journal> <volume> 35(1) </volume> <pages> 231-264, </pages> <year> 1988. </year>
Reference-contexts: Since then a considerable amount of work has been devoted to understanding the algebraic complexity of various problems in terms of straight-line programs. The prob 24 lem of equivalence of polynomials is considered in [HS80], [IM83]. Various problems such as greatest common divisors and factorization are considered in <ref> [Kal88] </ref>, [Kal89]. The straight-line program view was extended to multivariate elimination theory in [GH93], [GJML95], [GJM + 95]. Most of the above work was theoretical in nature, attempting to classify various algebraic problems with respect to their complexity as measured in the sizes of the SLP's etc.
Reference: [Kal89] <author> Erich Kaltofen. </author> <title> Factorization of Polynomials Given by Straight-Line Programs. </title> <editor> In S. Micali, editor, </editor> <booktitle> Randomness and Computation, volume 5 of Advances in Computing Research, </booktitle> <pages> pages 375-412. </pages> <publisher> JAI Press, </publisher> <address> Greenwhich, Connecticut, </address> <year> 1989. </year>
Reference-contexts: Since then a considerable amount of work has been devoted to understanding the algebraic complexity of various problems in terms of straight-line programs. The prob 24 lem of equivalence of polynomials is considered in [HS80], [IM83]. Various problems such as greatest common divisors and factorization are considered in [Kal88], <ref> [Kal89] </ref>. The straight-line program view was extended to multivariate elimination theory in [GH93], [GJML95], [GJM + 95]. Most of the above work was theoretical in nature, attempting to classify various algebraic problems with respect to their complexity as measured in the sizes of the SLP's etc.
Reference: [Kap86] <author> D. Kapur. </author> <title> Geometry Theorem Proving using Hilbert's Nullstellensatz. </title> <booktitle> In Symposium on Symbolic and Algebraic Computation, </booktitle> <pages> pages 202-208, </pages> <address> 1986. Waterloo, Ontario. </address>
Reference: [Kap88] <author> D. Kapur. </author> <title> A Refutational Approach to Geometry Theorem Proving. </title> <editor> In D. Ka-pur and J.L. Mundy, editors, </editor> <title> Geometric Reasoning. </title> <publisher> MIT Press, </publisher> <year> 1988. </year>
Reference-contexts: Wu's seminal work ([Wu78], [Wu84]) recast the problem in terms of algebraic geometry and thereafter a significant amount of the recent work has focussed on an algebraic approach involving determining the feasibility of systems of polynomial equations [Cho84], [KS86], <ref> [Kap88] </ref>. The papers by Wu and others showed how a subclass of geometric theorems can be proved by expressing the hypotheses and conclusions as polynomial equations as described in section 5.1. <p> Other work has focussed on using Grobner bases to determine whether a system of polynomials (obtained from the original polynomials) has a common zero [KS86], <ref> [Kap88] </ref>. As noted in [Cho88] (pp. 88-89) and evinced by the some of the benchmarks [KS86], [Kap88], Grobner basis methods for theorem proving have proved to be rather slow, in most cases requiring times 50-100 times more than the characteristic set methods 1 . <p> Other work has focussed on using Grobner bases to determine whether a system of polynomials (obtained from the original polynomials) has a common zero [KS86], <ref> [Kap88] </ref>. As noted in [Cho88] (pp. 88-89) and evinced by the some of the benchmarks [KS86], [Kap88], Grobner basis methods for theorem proving have proved to be rather slow, in most cases requiring times 50-100 times more than the characteristic set methods 1 . A somewhat different approach is taken in [Wan93] and [Wan95].
Reference: [Kho78] <author> A.G. Khovanskii. </author> <title> Newton polyhedra and the genus of complete intersections. </title> <journal> (Translated from) Funktsional'nyi Analiz i Ego Prilozheniya, </journal> <volume> 12(1) </volume> <pages> 51-61, </pages> <month> Jan-Mar </month> <year> 1978. </year>
Reference-contexts: In practice, 12 however, Bezout's bound turns out to be too loose; considerable improvement can be obtained on Bezout's bound by using the Bernstein-Kushnirenko-Khovanskii (BKK) bound ([Ber75], [Kus75], <ref> [Kho78] </ref>) which takes into account inherent sparseness in a given (generic) system of polynomial equations (see [Stu91] for an overview of sparse elimination theory).
Reference: [KL92] <author> D. Kapur and Y. Lakshman. </author> <title> Elimination Methods: An Introduction. </title> <journal> Journal of Symbolic Computation, </journal> <volume> 11, </volume> <year> 1992. </year>
Reference-contexts: The drawback of the Macaulay formulation (and formulations based on it, such as the u -resultant [vdW50] [Laz81]) is that it is infeasible to construct the resultant for even low degree input polynomials. For more details on these formulations see the excellent review by Kapur and Lakshman <ref> [KL92] </ref>. More recently, attention has focused on taking the inherent sparseness of the given system of equations into account. The foundations of sparse elimination theory were laid in the work of Gelfand, Kapranov and Zelevinsky [GKZ90] and Sturmfels [Stu91]. <p> For general multivariate systems, the two efficient methods for computing the resultant are the Dixon resultant and the "sparse" resultant. Since we are primarily interested in computing the resultant of low-dimensional systems we will use the Dixon method (see <ref> [KL92] </ref> and [KSY94] for more on the Dixon resultant formulation). There are several considerations which need to be addressed when using resultants.
Reference: [Knu81] <author> D. E. Knuth. </author> <title> The Art of Computer Programming, vol. II - Seminumerical Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1981. </year>
Reference-contexts: Compute Sylvester resultant R (f; g; x) = SLP (R (y)) (the resultant is obtained as an SLP in y). 3. Interpolate SLP (R (y)) using the Chinese remainder theorem <ref> [Knu81] </ref> to get R (y). 4. Compute the Sturm sequence r 0 (y) = R (y); r 1 (y) = R 0 (y); r 2 (y); : : : ; r k (y) with numerical coefficients as SLP's. 5. <p> Then by the process of pseudodivision (see e.g., <ref> [Knu81] </ref>) we have, b t The remainder r is called the pseudoremainder of f on division by g with respect to z and denoted prem (f; g; z). 56 Definition 5.5.1 A triangular form is a collection of polynomials f i of the form f 1 (u 1 ; : :
Reference: [KS86] <author> B. Kutzler and S. Stifter. </author> <title> On the Application of Buchberger's Algorithm to Automated Geometry Theorem Proving. </title> <journal> Journal of Symbolic Computation, </journal> <volume> 2 </volume> <pages> 409-420, </pages> <year> 1986. </year>
Reference-contexts: Wu's seminal work ([Wu78], [Wu84]) recast the problem in terms of algebraic geometry and thereafter a significant amount of the recent work has focussed on an algebraic approach involving determining the feasibility of systems of polynomial equations [Cho84], <ref> [KS86] </ref>, [Kap88]. The papers by Wu and others showed how a subclass of geometric theorems can be proved by expressing the hypotheses and conclusions as polynomial equations as described in section 5.1. <p> Other work has focussed on using Grobner bases to determine whether a system of polynomials (obtained from the original polynomials) has a common zero <ref> [KS86] </ref>, [Kap88]. As noted in [Cho88] (pp. 88-89) and evinced by the some of the benchmarks [KS86], [Kap88], Grobner basis methods for theorem proving have proved to be rather slow, in most cases requiring times 50-100 times more than the characteristic set methods 1 . <p> Other work has focussed on using Grobner bases to determine whether a system of polynomials (obtained from the original polynomials) has a common zero <ref> [KS86] </ref>, [Kap88]. As noted in [Cho88] (pp. 88-89) and evinced by the some of the benchmarks [KS86], [Kap88], Grobner basis methods for theorem proving have proved to be rather slow, in most cases requiring times 50-100 times more than the characteristic set methods 1 . A somewhat different approach is taken in [Wan93] and [Wan95].
Reference: [KS91] <author> E. Kaltofen and M. Singer. </author> <title> Size Efficient Parallel Algebraic Circuits for Partial Derivatives. </title> <booktitle> In Proceedings of the IV International Conference on Computer Algebra in Physical Research, </booktitle> <pages> pages 133-145, </pages> <address> 1991. Singapore. </address>
Reference-contexts: As observed in <ref> [KS91] </ref> the Baur-Strassen construction can produce an SLP of depth as large as the number of instructions in the original SLP. A modified construction is provided in [KS91] which increases the length by a factor of no more than 4. <p> As observed in <ref> [KS91] </ref> the Baur-Strassen construction can produce an SLP of depth as large as the number of instructions in the original SLP. A modified construction is provided in [KS91] which increases the length by a factor of no more than 4. This construction is easy to implement with the SLP model given in Definition 3.3.1. However, it is relatively complicated to implement their scheme in the graph-theoretic model of an SLP. <p> We use an alternate scheme which allows us to compute the derivative SLP of an SLP when given in the graph-theoretic form and with the same worst-case penalty as in <ref> [KS91] </ref>. We first introduce a new type of SLP operator node called the "DIFF" or "@" node. A DIFF node has only one input and the input edge must come from a leaf node of variable type.
Reference: [KSY94] <author> D. Kapur, T. Saxena, and L. Yang. </author> <title> Algebraic and Geometric Reasoning using Dixon Resultants. </title> <booktitle> In International Symposium on Symbolic and Algebraic Computation, </booktitle> <pages> pages 99-107, </pages> <address> New York, N.Y., 1994. </address> <publisher> ACM Press. </publisher> <pages> 95 </pages>
Reference-contexts: For general multivariate systems, the two efficient methods for computing the resultant are the Dixon resultant and the "sparse" resultant. Since we are primarily interested in computing the resultant of low-dimensional systems we will use the Dixon method (see [KL92] and <ref> [KSY94] </ref> for more on the Dixon resultant formulation). There are several considerations which need to be addressed when using resultants. <p> The non-genericity of the input polynomials can result in a matrix which is singular or non-square. In both these cases we can resort to using Gaussian elimination (using a fraction-free method like that of Bareiss [Bar68]) to obtain the determinant of a maximal non-singular minor. As reported in <ref> [KSY94] </ref> this approach seems to work in most cases. In Section 4.4 we will address the issue of extra factors introduced during the resultant computation.
Reference: [Kus75] <author> A.G. Kushnirenko. </author> <title> The Newton polyhedron and the number of solutions of a system of k equations in k unknowns. </title> <journal> (Translated from) Uspekhi Mat. Nauk., </journal> <volume> 30 </volume> <pages> 266-267, </pages> <year> 1975. </year>
Reference-contexts: In practice, 12 however, Bezout's bound turns out to be too loose; considerable improvement can be obtained on Bezout's bound by using the Bernstein-Kushnirenko-Khovanskii (BKK) bound ([Ber75], <ref> [Kus75] </ref>, [Kho78]) which takes into account inherent sparseness in a given (generic) system of polynomial equations (see [Stu91] for an overview of sparse elimination theory).
Reference: [Laz81] <author> D. Lazard. </author> <title> Resolution des Systemes d'Equations Algebriques. </title> <journal> Theoretical Computer Science, </journal> <volume> 15 </volume> <pages> 77-110, </pages> <year> 1981. </year>
Reference-contexts: The drawback of the Macaulay formulation (and formulations based on it, such as the u -resultant [vdW50] <ref> [Laz81] </ref>) is that it is infeasible to construct the resultant for even low degree input polynomials. For more details on these formulations see the excellent review by Kapur and Lakshman [KL92]. More recently, attention has focused on taking the inherent sparseness of the given system of equations into account.
Reference: [Mac21] <author> F.S. </author> <title> Macaulay. Note on the resultant of a number of polynomials of the same degree. </title> <booktitle> Proceedings of London Mathematical Society, </booktitle> <pages> pages 14-21, </pages> <month> June </month> <year> 1921. </year>
Reference-contexts: The Dixon resultant [Dix08] gives a similar condition for the case of three polynomials in two unknowns. A more general construction is due to Macaulay <ref> [Mac21] </ref> who gave the formulation of the resultant of n homogeneous polynomials in n variables as the quotient of a determinant by one of its minors.
Reference: [MC92] <author> D. Manocha and J. Canny. </author> <title> Multipolynomial Resultants and Linear Algebra. </title> <booktitle> In International Symposium on Symbolic and Algebraic Computation, </booktitle> <pages> pages 96-102, </pages> <address> Berkeley, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: A similar approach is outlined in [ER94] where a monomial basis for the coordinate algebra of a zero-dimensional variety is obtained via the sparse resultant formulation [CE93]. The problem of counting and enumerating roots can then be reduced to a matrix eigenvalue problem [AS88], <ref> [MC92] </ref>. The standard method for encoding the roots of a system of polynomial equations is to compute a (generalized) primitive element polynomial for the system. <p> Our primary algebraic tool is the resultant. Resultant based methods are fast gaining popularity as they tend to be faster than standard algebraic approaches like Grobner bases for certain problems <ref> [MC92] </ref>. Their matrix formulation makes them particularly well suited to taking advantage of efficient and time-tested eigenvalue methods such as those implemented in standard linear algebra packages like LAPACK. One of the main contributions of this thesis is the demonstration of the utility of the straight-line program data structure.
Reference: [Mil88] <author> V. Milenkovic. </author> <title> Verifiable Implementations of Geometric Algorithms using Finite-Precision Arithmetic. </title> <journal> Artificial Intelligence, </journal> <volume> 37 </volume> <pages> 377-401, </pages> <year> 1988. </year>
Reference-contexts: A common approach is to use fixed precision floating-point arithmetic but there are no simple techniques that guarantee that the program will provide reliable answers. Usually the approach is to analyze the particular algorithm on hand for stability and correctness when using floating-point arithmetic [For92], <ref> [Mil88] </ref>. Such analyses do not lend themselves to generalization and tend to be difficult and algorithm-specific. An alternate approach is to use exact integer arithmetic. The immediate problem with this approach is that one often requires precision beyond the standard 32 bits provided by most computers.
Reference: [Mis93] <author> Bud Mishra. </author> <title> Computer Algebra. </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY 10010, </address> <year> 1993. </year>
Reference-contexts: However, it can vanish identically when no affine solution exists due to a 17 component at infinity. The algorithmic question then is to construct this polynomial for a given system of equations. For the case of two polynomials in one unknown, the Sylvester formulation of the resultant (See, e.g. <ref> [Mis93] </ref> for a review of the Sylvester resultant and its properties) gives a determinantal condition on the existence of a common solution. The Dixon resultant [Dix08] gives a similar condition for the case of three polynomials in two unknowns.
Reference: [MSW89] <author> A.P. Morgan, A.J. Sommese, and L.T. Watson. </author> <title> Finding all isolated solutions to polynomial systems using hompack. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 15 </volume> <pages> 93-122, </pages> <year> 1989. </year>
Reference-contexts: The total complexity of the algorithm therefore is O (d 7 ). 3.6.1 Benchmarks for Counting Real Solutions We will compare the implementation of our approach with two other methods - one based on Grobner bases and Hermite's method [PRS92], the other on a homotopy-based algorithm <ref> [MSW89] </ref>. The former approach has been implemented as part of the "Gb" package [Fau94], [CF] and is indicated as such in the following table. The latter approach is based on using numerical continuation methods and is implemented in the Fortran package HOMPACK.
Reference: [NU] <author> S. Naher and C. Uhrig. </author> <title> The LEDA user manual. MPI, </title> <address> Germany. </address>
Reference-contexts: The toolkit provides various arithmetics that the user can use depending on the application. These include integer arithmetic modulo a prime, fixed precision floating-point, arbitrary precision integer and floating-point arithmetics (currently implemented using LEDA's "bignum" arithmetic <ref> [NU] </ref>), rational arithmetic, (implemented as pairs of integers), adaptive floating point arithmetic (see section 4.5.1 for a description) among others. Additionally, the toolkit provides "mixed" arithmetic where a number is represented as a pair the integer value of the number modulo a prime, and a floating-point approximation. <p> the only time we will compute every component of an expansion is when the number is provably nonzero. 4.6 Implementation and Benchmarks For the numerical computation in the benchmarks below we use the big integer package from LEDA (Library of Efficient Data types and Algorithms) package of Naher and Mehlhorn <ref> [NU] </ref>. As mentioned in the Introduction, we use arbitrary precision arithmetic for the current version of the implemented algorithm.
Reference: [Owe91] <author> J. C. Owen. </author> <title> Algebraic solution for geometry from dimensional constraints. </title> <editor> In J. Rossignac and J. Turner, editors, </editor> <booktitle> Symp. on Solid Modeling Foundations and CAD/CAM Applications, </booktitle> <pages> pages 397-407. </pages> <publisher> ACM Press, </publisher> <year> 1991. </year>
Reference-contexts: Though a simpler problem (due to the absence of the parameters) it raises computational issues in its own right. There has been a fair amount of work done on developing constraint-based solvers (see [Ald88], [BFH + 95], <ref> [Owe91] </ref> for a sampling). However, most of the work has focused on constraint-solvers for relatively simple objects such as line segments, points etc.
Reference: [Ped91] <author> P. Pedersen. </author> <title> Counting Real Zeros. </title> <type> Thesis. </type> <institution> Courant Institute, </institution> <address> New York University, </address> <year> 1991. </year>
Reference-contexts: This algorithm is based on computing a monomial basis (usually via a Grobner basis computation) and setting up a multiplication table for the coordinate algebra. An alternate approach based on multivariate symmetric functions is given in <ref> [Ped91] </ref>. A similar approach is outlined in [ER94] where a monomial basis for the coordinate algebra of a zero-dimensional variety is obtained via the sparse resultant formulation [CE93]. The problem of counting and enumerating roots can then be reduced to a matrix eigenvalue problem [AS88], [MC92].
Reference: [Pri91] <author> D. Priest. </author> <title> Algorithms for Arbitrary Precision Floating Point Arithmetic. </title> <booktitle> In Tenth Symposium on Computer Arithmetic, </booktitle> <pages> pages 132-143, </pages> <address> 1991. Los Alamitos, CA. </address>
Reference-contexts: We use the adaptive floating point approach <ref> [Pri91] </ref>, [Pri92]. Informally, an adaptive floating point number is a representation of a number with an "adaptive" number of bits, i.e. the number of bits of a given number are computed till such point as we know the sign of the number correctly. <p> In the remainder of this section we outline the adaptive approach to floating point computation and extend it to the mixed approach we use in the toolkit. 4.5.1 Adaptive Precision Floating-Point Arithmetic The adaptive floating point approach was pioneered by Priest [Pri92], <ref> [Pri91] </ref> and extended by Shewchuk [She96].
Reference: [Pri92] <author> D. Priest. </author> <title> On Properties of Floting Point Arithmetic : Numerical Stability and the Cost of Accurate Computations. </title> <type> Ph.D. thesis, </type> <institution> Department of Mathematics, University of California at Berkeley, Berkeley, </institution> <address> CA, </address> <year> 1992. </year> <month> 96 </month>
Reference-contexts: We use the adaptive floating point approach [Pri91], <ref> [Pri92] </ref>. Informally, an adaptive floating point number is a representation of a number with an "adaptive" number of bits, i.e. the number of bits of a given number are computed till such point as we know the sign of the number correctly. <p> In the remainder of this section we outline the adaptive approach to floating point computation and extend it to the mixed approach we use in the toolkit. 4.5.1 Adaptive Precision Floating-Point Arithmetic The adaptive floating point approach was pioneered by Priest <ref> [Pri92] </ref>, [Pri91] and extended by Shewchuk [She96]. <p> The issue then becomes devising algorithms for the various arithmetic operations which will take as input two expansions and compute the components of the resulting expansion in this successive fashion. These algorithms are provided in <ref> [Pri92] </ref> where the restrictions on the format of the floating point numbers are few (different radices and rounding modes are allowed), which makes the algorithms more general but somewhat slower. Shewchuk improves on these algorithms by assuming the IEEE 754 standard with radix 2 and exact rounding.
Reference: [PRS92] <author> P. Pedersen, M.-F. Roy, and A. Szpirglas. </author> <title> Counting Real Zeros in the Multi-variate Case. </title> <booktitle> In Proc. </booktitle> <address> MEGA-92, </address> <year> 1992. </year> <title> appearing in `Computational Algebraic Geometry', edited by F. </title> <editor> Eyssette, and A. Galligo, </editor> <publisher> Birkhauser. </publisher>
Reference-contexts: However, since the number of real solutions is in general much smaller than the total number of solutions, the Bezout bound can be very weak. An algorithm based on Her-mite's method is given in <ref> [PRS92] </ref> for counting the number of real roots of zero-dimensional systems. This algorithm is based on computing a monomial basis (usually via a Grobner basis computation) and setting up a multiplication table for the coordinate algebra. An alternate approach based on multivariate symmetric functions is given in [Ped91]. <p> The total complexity of the algorithm therefore is O (d 7 ). 3.6.1 Benchmarks for Counting Real Solutions We will compare the implementation of our approach with two other methods - one based on Grobner bases and Hermite's method <ref> [PRS92] </ref>, the other on a homotopy-based algorithm [MSW89]. The former approach has been implemented as part of the "Gb" package [Fau94], [CF] and is indicated as such in the following table. The latter approach is based on using numerical continuation methods and is implemented in the Fortran package HOMPACK.
Reference: [Reg95] <author> A. </author> <title> Rege. A Complete and Practical Algorithm for Geometric Theorem Proving. </title> <booktitle> In ACM Symposium on Computational Geometry, </booktitle> <pages> pages 277-286, </pages> <address> 1995. Vancouver, B.C. </address>
Reference-contexts: We have had a good measure of success with our algorithm due to its ability to solve non-trivial problems of large dimension and degree, which were hitherto unsolvable by all of the standard approaches. Portions of our work described in this chapter appeared in <ref> [Reg95] </ref>. The overview of the chapter is as follows: We start with an example which illustrates the problem and motivates the rest of the material in the chapter. In section 5.2 we will provide the historical background and references to previous work.
Reference: [Ren89a] <author> J. Renegar. </author> <title> A Faster PSPACE Algorithm for Deciding the Existential Theory of the Reals. </title> <booktitle> In IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1989. </year>
Reference-contexts: A useful restriction of the first order theory is the existential theory of the reals where only existential quantifiers are allowed. This has been shown to be decidable in polynomial space and single exponential time [Can88], <ref> [Ren89a] </ref>. Most of the work on real algebraic algorithms makes use of a sign-determination lemma due to Ben-Or, Kozen and Reif [BOKR86] which provides an algorithm for determining the signs of a set of polynomials at the roots on another.
Reference: [Ren89b] <author> J. Renegar. </author> <title> On the Computational Complexity and Geometry of the First-Order Theory of the Reals, parts I, II and III. </title> <type> Technical Report 852,855,856, </type> <institution> Cornell University, Operations Research Dept., </institution> <year> 1989. </year>
Reference-contexts: Typically one computes (a multiple of ) the resultant as outlined in [Can88] as the primitive element polynomial and a set of rational functions which encode the roots symbolically. A more efficient approach using the same general idea was given by Renegar in <ref> [Ren89b] </ref>, [Ren92] and we will discuss this algorithm in more detail in Chapter 2. An alternate approach, based on much the same idea, goes by the name of the "Generalized Shape Lemma" [ABRW94]. <p> One method is to use polynomial greatest common divisors as outlined in [Can88]. An alternate approach based on differentiation was given by Renegar in <ref> [Ren89b] </ref>, [Ren92]. This algorithm is more efficient in practice and is particularly suited for use with the straight-line program described in Chapter 3. Algorithm 2.1.1 (Renegar's Algorithm) Input: Polynomials f 1 ; : : : ; f n 2 C [x 1 ; : : : ; x n ]. <p> C n , for i = 1; : : : ; N , As discussed in section 2.1, we will produce an encoding of its roots from it as a univariate polynomial p (s) and rational functions r 1 (s); : : : ; r n (s) using Renegar's algorithm <ref> [Ren89b] </ref> described in section 2.1.1. Computing the Resultant Algorithm 2.1.1 presupposes a method for computing the resultant of n + 1 polynomials in n variables. There are several approaches to doing this. <p> It could turn out, of course, that we treat as identically zero an SLP coefficient which was not so though the probability of this happening is low. 5.7.1 Theoretical Algorithm Our algorithm is based on an approach for computing (p; r) for more general systems due to Renegar <ref> [Ren89b] </ref>. We use his basic method but take advantage of certain properties of triangular systems. <p> We showed how a simple use of SLP's allows us to reduce the complexity of the problem. In Chapter 4 the problem of implicit point location and 87 predicates for geometry was considered. We give an algorithm based on Renegar's algorithm <ref> [Ren89b] </ref> to solve this problem.
Reference: [Ren92] <author> J. Renegar. </author> <title> On the computational complexity of the first-order theory of the reals, parts I, II, III. </title> <journal> Journal of Symbolic Computation, </journal> <volume> 13(3) </volume> <pages> 255-352, </pages> <year> 1992. </year>
Reference-contexts: Typically one computes (a multiple of ) the resultant as outlined in [Can88] as the primitive element polynomial and a set of rational functions which encode the roots symbolically. A more efficient approach using the same general idea was given by Renegar in [Ren89b], <ref> [Ren92] </ref> and we will discuss this algorithm in more detail in Chapter 2. An alternate approach, based on much the same idea, goes by the name of the "Generalized Shape Lemma" [ABRW94]. <p> One method is to use polynomial greatest common divisors as outlined in [Can88]. An alternate approach based on differentiation was given by Renegar in [Ren89b], <ref> [Ren92] </ref>. This algorithm is more efficient in practice and is particularly suited for use with the straight-line program described in Chapter 3. Algorithm 2.1.1 (Renegar's Algorithm) Input: Polynomials f 1 ; : : : ; f n 2 C [x 1 ; : : : ; x n ].
Reference: [Rit32] <author> J.F. Ritt. </author> <title> Differential Equations from the Algebraic Standpoint. </title> <booktitle> Number 14 in AMS Colloquium publications. </booktitle> <publisher> American Mathematical Society, </publisher> <address> New York, </address> <year> 1932. </year>
Reference-contexts: In 1978, Wu introduced an elegant method for automated theorem proving for algebraic geometry [Wu78]. The basis of his work was a triangulation procedure which was implicit in the work of Ritt <ref> [Rit32] </ref>, [Rit50] and which was given in detail by Wu. Wu's approach was implemented with various modifications and improvements by Chou in his prover [Cho84], [Cho88]. The following is based on the book by Chou [Cho88] with some notational changes.
Reference: [Rit50] <author> J.F. Ritt. </author> <title> Differential Algebra. </title> <booktitle> Number 33 in AMS Colloquium publications. </booktitle> <publisher> American Mathematical Society, </publisher> <address> New York, </address> <year> 1950. </year>
Reference-contexts: In 1978, Wu introduced an elegant method for automated theorem proving for algebraic geometry [Wu78]. The basis of his work was a triangulation procedure which was implicit in the work of Ritt [Rit32], <ref> [Rit50] </ref> and which was given in detail by Wu. Wu's approach was implemented with various modifications and improvements by Chou in his prover [Cho84], [Cho88]. The following is based on the book by Chou [Cho88] with some notational changes.
Reference: [Sha74] <author> I.R. Shafarevich. </author> <title> Basic Algebra Geometry. </title> <publisher> Springer Verlag, </publisher> <year> 1974. </year>
Reference: [She96] <author> J.R. Shewchuk. </author> <title> Robust Adaptive Floating-Point Geometric Predicates. </title> <booktitle> In ACM Symposium on Computationl Geometry, </booktitle> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: In the remainder of this section we outline the adaptive approach to floating point computation and extend it to the mixed approach we use in the toolkit. 4.5.1 Adaptive Precision Floating-Point Arithmetic The adaptive floating point approach was pioneered by Priest [Pri92], [Pri91] and extended by Shewchuk <ref> [She96] </ref>. There are two standard approaches to storing numbers in implementations of arbitrary precision floating point arithmetic: In the multiple-digit format, an arbitrary precision floating point number is stored as a sequence of digits, of 45 some large radix like 2 32 , with a single exponent.
Reference: [Ste65] <author> D. Stewart. </author> <title> A platform with six degrees of freedom. </title> <journal> Proc. Inst. Mech. Eng., </journal> <volume> 180 </volume> <pages> 371-386, </pages> <year> 1965. </year>
Reference-contexts: developmental platforms and software. 1.1 Example Problems We begin with a first look at some problems drawn from different domains to give us a flavor of the kinds of problems we expect to be able to solve with the toolkit. 1.1.1 Forward Kinematics for the Stewart Platform 7 Stewart platform <ref> [Ste65] </ref> is a six-degree-of-freedom parallel manipulator comprising a base platform, a support platform (or end-effector) and six chains (or legs) connected in parallel between the base and the support.
Reference: [Str72] <author> V. Strassen. </author> <title> Berechnung und Programm I. </title> <journal> Acta Informatica, </journal> <volume> 1 </volume> <pages> 320-335, </pages> <year> 1972. </year> <note> In German. </note>
Reference-contexts: In the rest of the chapter we will consider various algorithms and implementation issues related to computations with straight-line programs. 3.2 Previous Work Straight-line programs were introduced by Strassen <ref> [Str72] </ref> as a model for algebraic computation. Since then a considerable amount of work has been devoted to understanding the algebraic complexity of various problems in terms of straight-line programs. The prob 24 lem of equivalence of polynomials is considered in [HS80], [IM83]. <p> An implementation of a system for creating and manipulating SLP's is described in [FIKY88]. 3.3 Straight-line Program Basics There are two standard definitions of straight-line programs which lead to two distinct approaches for their implementation. Definition 3.3.1 (see <ref> [Str72] </ref>, [vzG87]) Let A be a ring (resp. field) and x 1 ; : : : ; x n inde-terminates over A. A straight-line program is sequence P = (P 1 ; : : : ; P r ) of arithmetic operations where 1.
Reference: [Stu91] <author> Bernd Sturmfels. </author> <title> Sparse Elimination Theory. </title> <editor> In D. Eisenbud and L. Robbiano, editors, </editor> <booktitle> Proc. Computat. Algebraic Geom. and Commut. Algebra, </booktitle> <address> Cortona, Italy, June 1991. </address> <publisher> Cambridge Univ. Press. </publisher> <pages> 97 </pages>
Reference-contexts: In practice, 12 however, Bezout's bound turns out to be too loose; considerable improvement can be obtained on Bezout's bound by using the Bernstein-Kushnirenko-Khovanskii (BKK) bound ([Ber75], [Kus75], [Kho78]) which takes into account inherent sparseness in a given (generic) system of polynomial equations (see <ref> [Stu91] </ref> for an overview of sparse elimination theory). Several systems have proved themselves amenable to sparse elimination theory and tighter bounds for systems such as those defined by the cyclic n-roots problem and the "motion from point matches" problem in vision have been obtained [ER94]. <p> More recently, attention has focused on taking the inherent sparseness of the given system of equations into account. The foundations of sparse elimination theory were laid in the work of Gelfand, Kapranov and Zelevinsky [GKZ90] and Sturmfels <ref> [Stu91] </ref>. Canny and Emiris [CE93] provide an algorithm for constructing the so-called sparse resultant which, in general, gives a more compact condition than the Macaulay or other formulations. To summarize then, we have in general a range of resultant formulations available to us.
Reference: [Tar48] <author> A. Tarski. </author> <title> A Decision Method for Elementary Algebra and Geometry. </title> <institution> University of California Press, Berkeley, </institution> <year> 1948. </year>
Reference-contexts: The main difference from Renegar's approach is that the primitive element is obtained using a Grobner basis computation rather than by resultant. The general setting for the problem of answering logical questions about polynomial equations and inequalities is the first order theory of the reals <ref> [Tar48] </ref>. <p> This theory has been shown to be decidable <ref> [Tar48] </ref> in time doubly exponential in the size of the input [Col75]. A useful restriction of the first order theory is the existential theory of the reals where only existential quantifiers are allowed. This has been shown to be decidable in polynomial space and single exponential time [Can88], [Ren89a]. <p> Specifically, the number of real roots of f (s) equals SC (f; f 0 ), i.e., SC (f; f 0 ) = jc g j + j c g j. Theorem 2.2.3 (Tarski <ref> [Tar48] </ref>) SC (f; f 0 g) = jc g j j c g j.
Reference: [Tay83] <author> K.B. Taylor. </author> <title> Three Circles with Collinear Centers. </title> <journal> American Mathematical Monthly, </journal> <volume> 90 </volume> <pages> 486-487, </pages> <year> 1983. </year>
Reference-contexts: V. Thebault made this conjecture in 1938 and it was finally proved by K.B. Taylor in 1983 <ref> [Tay83] </ref>. Theorem 5.10.4 (Thebault-Taylor) Let ABC be a triangle, with M a point on side BC. Let O and I be the centers of the circumscribed circle (O) and inscribed circle (I) respectively of ABC.
Reference: [vdW50] <editor> B.L. van der Waerden. </editor> <booktitle> Modern Algebra, </booktitle> <volume> volume 2. </volume> <publisher> Ungar Publishing Co., </publisher> <address> New York, </address> <note> 3rd edition, </note> <year> 1950. </year>
Reference-contexts: The drawback of the Macaulay formulation (and formulations based on it, such as the u -resultant <ref> [vdW50] </ref> [Laz81]) is that it is infeasible to construct the resultant for even low degree input polynomials. For more details on these formulations see the excellent review by Kapur and Lakshman [KL92]. More recently, attention has focused on taking the inherent sparseness of the given system of equations into account. <p> Proof The proof follows directly from Theorem 5.8.1 and the fact that the resultant of a reducible variety is reducible and factors into irreducible factors, one for each irreducible component. (See, e.g., <ref> [vdW50] </ref>, pp. 13-15.) We could have the problem discussed earlier of having introduced extra roots in the triangulation procedure, that is, we could add extra components to the original hypothesis variety.
Reference: [vzG87] <author> J. von zur Gathen. </author> <title> Feasible Arithmetic Computations : Valiant's Hypothesis. </title> <journal> JSC, </journal> <volume> 4 </volume> <pages> 137-172, </pages> <year> 1987. </year>
Reference-contexts: An implementation of a system for creating and manipulating SLP's is described in [FIKY88]. 3.3 Straight-line Program Basics There are two standard definitions of straight-line programs which lead to two distinct approaches for their implementation. Definition 3.3.1 (see [Str72], <ref> [vzG87] </ref>) Let A be a ring (resp. field) and x 1 ; : : : ; x n inde-terminates over A. A straight-line program is sequence P = (P 1 ; : : : ; P r ) of arithmetic operations where 1.
Reference: [Wan93] <author> D. Wang. </author> <title> An Elimination Method for Polynomial Systems. </title> <journal> Journal of Symbolic Computation, </journal> <volume> 16 </volume> <pages> 83-114, </pages> <year> 1993. </year>
Reference-contexts: A somewhat different approach is taken in <ref> [Wan93] </ref> and [Wan95]. Though the method is similar to the characteristic set approach, the requirements for the decomposition of a given hypotheses system into its irreducible components are relaxed. Both the Ritt-Wu approach and this one, however, rely on factorization over extension fields as we shall see in section 5.5.
Reference: [Wan95] <author> D. Wang. </author> <title> Elimination Procedures for Mechanical Theorem Proving in Geometry. </title> <journal> Annals of Mathematics and Artificial Intelligence, </journal> <volume> 13 </volume> <pages> 1-24, </pages> <year> 1995. </year>
Reference-contexts: A somewhat different approach is taken in [Wan93] and <ref> [Wan95] </ref>. Though the method is similar to the characteristic set approach, the requirements for the decomposition of a given hypotheses system into its irreducible components are relaxed. Both the Ritt-Wu approach and this one, however, rely on factorization over extension fields as we shall see in section 5.5. <p> The largest remainder produced has 674,927 (= maxt) terms. We note that the above example has not been solved by any theorem proving algorithm we know of. Wang <ref> [Wan95] </ref> reports the solution of this problem using a different formulation which reduces the problem to a degree 8 system rather than the original degree 32 system.
Reference: [Wu78] <author> W. Wu. </author> <title> On the Decision Problem and Mechanization of Theorem Proving in Elementary Geometry. </title> <journal> Sci. Sinica, </journal> <volume> 21 </volume> <pages> 150-172, </pages> <year> 1978. </year>
Reference-contexts: This section will therefore examine the Ritt-Wu algorithm and the techniques used by Chou's prover so we can better understand its strengths and limitations. In 1978, Wu introduced an elegant method for automated theorem proving for algebraic geometry <ref> [Wu78] </ref>. The basis of his work was a triangulation procedure which was implicit in the work of Ritt [Rit32], [Rit50] and which was given in detail by Wu. Wu's approach was implemented with various modifications and improvements by Chou in his prover [Cho84], [Cho88].
Reference: [Wu84] <author> W. Wu. </author> <title> Some Recent Advances in Mechanical Theorem Proving of Geometries. In W.W. </title> <editor> Bledsoe and D.W. Loveland, editors, </editor> <title> Theorem Proving : After 25 Years. </title> <publisher> American Mathematical Society, </publisher> <year> 1984. </year>
Reference-contexts: Wu's seminal work ([Wu78], <ref> [Wu84] </ref>) recast the problem in terms of algebraic geometry and thereafter a significant amount of the recent work has focussed on an algebraic approach involving determining the feasibility of systems of polynomial equations [Cho84], [KS86], [Kap88].
Reference: [Wu86] <author> W. Wu. </author> <title> Basic Principles of Mechanical Theorem Proving in Elementary Geometries. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 2 </volume> <pages> 221-252, </pages> <year> 1986. </year>
Reference-contexts: Interestingly enough, it turns out that one can reformulate the theorem as shown by Wu <ref> [Wu86] </ref> and it can be reduced to a system of equations which can be solved using naive triangulation. The more interesting problem arises when the theorem is formulated without using Wu's trick.
Reference: [Zip93] <author> R. Zippel. </author> <title> Effective Polynomial Computation. </title> <publisher> Kluwer Academic publishers, </publisher> <address> Massachusetts, </address> <year> 1993. </year>
Reference-contexts: Consider the case where we want to interpolate an SLP with one input variable (say x) into its polynomial form. We can do this easily by using any (univariate) interpolation scheme such as Vandermonde interpolation <ref> [Zip93] </ref>. A depth-first search of the SLP will give the degree d in x of the polynomial represented by the SLP. To interpolate, we need the value of the polynomial at d + 1 points where d is the degree of the polynomial. <p> This can be obtained with d + 1 evaluations of the SLP. Interpolation is now straight-forward and can be done in time proportional to O (d 2 ) and space O (d) <ref> [Zip93] </ref>. If N is the number of nodes in the SLP, the total time required is therefore max (O (d 2 ); O (d N )) and the space required is O (d).
References-found: 88

