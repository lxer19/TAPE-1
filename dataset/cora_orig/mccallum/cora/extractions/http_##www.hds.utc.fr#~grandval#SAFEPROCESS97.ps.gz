URL: http://www.hds.utc.fr/~grandval/SAFEPROCESS97.ps.gz
Refering-URL: http://www.hds.utc.fr/~grandval/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: DIAGNOSIS OF GLASS QUALITY IN A MANUFACTURING PROCESS: TWO CONNECTIONIST SOLUTIONS 1  
Author: Y. Grandvalet and S. Canu 
Keyword: Neural networks, Flexible regression, Model selection, Resampling scheme  
Address: B.P. 20529, 60205 Compiegne Cedex, France  
Affiliation: Heudiasyc, U.M.R. C.N.R.S. 6599, Universite de Technologie de Compiegne,  
Abstract: We describe and compare two kinds of connexionist solutions for predicting the quality rating of glass according to chemical inlet of the manufacturing process. We show that according to the approach used to select a predictor in the set of Multi-layered perceptrons, the results may vary dramatically. We also show some practical limitations of prediction error estimates based on resampling techniques. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Amaldi, E. </author> <year> (1991). </year> <title> On the complexity of training perceptrons. </title> <booktitle> In: Artificial Neural Networks (Koho-nen, </booktitle> <editor> Makisara, Simula and Kangas, Eds.). </editor> <publisher> North-Holland. </publisher>
Reference-contexts: 0 ; (5) where H is the number of hidden units, ih and fi h are the weights of the input-to-hidden and hidden-to-output layer, 0h and fi 0 are the corresponding thresholds,and tanh is the units activation function. 3.1 Optimization issues The optimization of an MLP is a NP-hard problem <ref> (Amaldi, 1991) </ref>. Thus, even if ideally the optimization algorithm should not have any influence on the so lution, it is indeed important, especially considering the stopping criteria of the iterative optimization algorithm. Here, we use a variable step algorithm (Harris et al., 1986).
Reference: <author> Breiman, L. </author> <year> (1994). </year> <title> Bagging predictors. </title> <type> Technical report. </type> <institution> Statistics Department, UC Berkeley. </institution>
Reference-contexts: However, for numerous problems, the stability of ridge regression type methods is a recognized advantage over subset selection methods. The latter can gain stability and thus be improved by using bagging <ref> (Breiman, 1994) </ref> or similar techniques. Some properties of resampling prediction error estimates are also pointed out in this paper. These estimates are random variables, possibly biased. The risk of selecting a sub-optimal model exist for any regression scheme.
Reference: <author> Breiman, L. and P. </author> <title> Spector (1992). Submodel selection and evaluation in regression the X-random case. </title> <journal> International Review of Statistics 3, </journal> <pages> 291-319. </pages>
Reference-contexts: Two plausible explanation of this surprising result may be suggested. First, it has been shown that, for linear regressors, the leave-one-out estimate of the prediction error tend to be less reliable on subset selection procedures than leave-many-out or bootstrap procedures <ref> (Breiman and Spector, 1992) </ref>. The second explanation invokes the optimization issues already discussed. They are likely to cause down-biased estimates. For leave-one-out cross-validation, the net function is initialized to b f .
Reference: <author> Efron, B. and R.J. </author> <month> Tibshirani </month> <year> (1993). </year> <title> An Introduction to the Bootstrap. </title> <booktitle> Vol. 57 of Monographs on Statistics and Applied Probability. </booktitle> <publisher> Chapman & Hall. </publisher>
Reference-contexts: This gain in extracted information is paid by extensive computation. 2.4 Resampling methods In this paper, we applied three resampling schemes to estimate PE (1): cross-validation (leave-one-out), sophisticated bootstrap, and .632 bootstrap <ref> (Efron and Tib-shirani, 1993) </ref>. These schemes used to select a model provide also a basis for comparing different methods. 2.4.1. Cross-validation PE ( b f ) can be estimated by the empirical cost on a sample independent from the one used to estimate b f . <p> According to the sophisticated bootstrap, the ranking is ANI &gt; NI Linear &gt; Kernel &gt; #HU ; according to the .632 bootstrap the ranking is ANI &gt; NI Linear #HU Kernel. Although there is yet no theoretical justification, .632 bootstrap is considered to be a more reliable estimate in <ref> (Efron and Tibshirani, 1993) </ref>. For MLP, architecture selection yields the worse results. Compared to linear regression, the MLP is more flexible and thus fits better the data, but this flexibility is paid by too much variability. Noise Injection is always best ranked.
Reference: <author> Grandvalet, Y. </author> <year> (1995). </year> <title> Effets de l'injection de bruit sur les perceptrons multicouches. </title> <type> PhD thesis. </type> <institution> Univer-site de Technologie de Compiegne. France. </institution>
Reference-contexts: Pre diction error estimates obtained by sophisticated and .632 bootstrap. 3.3.2. Anisotropic Noise Injection In Isotropic Noise Injection, the noise covariance matrix is 2 I. A Gaussian noise is thus generated in spherical neighborhoods of the data points. Anisotropic Noise Injection <ref> (Grandvalet, 1995) </ref> is more flexible, as it adapts a full covariance matrix 2 . The noise is thus generated in elliptical neighborhoods of the data points.
Reference: <author> Harris, R.W., D.M. Chabries and A. </author> <title> Bishop (1986). A variable step (VS) adaptive filter algorithm.. </title> <journal> IEEE Trans. on Acoustics, Speech and Signal Processing 34(2), </journal> <pages> 309-316. </pages>
Reference-contexts: Thus, even if ideally the optimization algorithm should not have any influence on the so lution, it is indeed important, especially considering the stopping criteria of the iterative optimization algorithm. Here, we use a variable step algorithm <ref> (Harris et al., 1986) </ref>. The optimization is stopped when the absolute or relative changes of each weight is below 10 3 after 100 updates. When minimizing C emp , 10 starting points are randomly picked near zero. Thus, we avoid (at least to some extent) the problem of local minima.
Reference: <author> Hastie, T.J. and R.J. </author> <month> Tibshirani </month> <year> (1990). </year> <title> Generalized Additive Models. </title> <booktitle> Vol. 43 of Monographs on Statistics and Applied Probability. </booktitle> <publisher> Chapman & Hall. </publisher>
Reference-contexts: The minimimum of C emp (), b f is thus a random functional. As F grows, its number of degrees of freedom <ref> (Hastie and Tibshirani, 1990) </ref> grows. The latter may be thought as the number of free parameters of b f to be estimated on the basis of Z ` . <p> Fig. 1. Criteria for architecture selection and empirical cost C emp . Prediction error estimates obtained by cross-validation, sophisticated and .632 bootstrap. Adding units in the hidden layer increases its number of degrees of freedom <ref> (Hastie and Tibshirani, 1990) </ref>. The optimism, i.e. the mean difference between PE (1) and C emp (2), is thus increasing. But, it is clearly seen on Fig. 1, that the optimism estimates obtained by CV and bootstrap are not incresing with complexity. <p> The connection of Noise Injection to ridge regression is shown by the minimizer of C NI in L 2 . It is a Nadaraya-Watson kernel estimate <ref> (Hastie and Tibshirani, 1990) </ref>, where the width of the kernel is the standard deviation of the noise. The hyper-parameter is thus a function of this standard deviation. To test Noise Injection in this application, we used a MLP with 10 hidden units (161 parameters). 3.3.1. <p> SUMMARY OF RESULTS The results obtained in section 3 are summarized on table 1. They are compared to the ones obtained by two other regression schemes: regularized linear regression, and Nadaraya-Watson kernel regression <ref> (Hastie and Tibshirani, 1990) </ref>. These two competitors do not suit the problem at hand. Linear regression is not very flexible 3 , and kernel regression usually behaves poorly in high dimensional features spaces. However, this comparison sets some reference points on the scale of performances. Table 1.
Reference: <author> Hertz, J., A. Krogh and R.G. </author> <title> Palmer (1991). Introduction to the Theory of Neural Computation. Computation and neural systems. </title> <publisher> Addison-Wesley. </publisher>
Reference-contexts: The regression methods dedicated to this kind of problem are often designated as non-parametric techniques. This name may be confusing as these methods explicitly or implicitly use parameterized estimates. This is the reason why we will use here the term of flexible regression. Multi-Layer Perceptrons <ref> (Hertz et al., 1991) </ref> (MLP) are among the well-tried techniques for problems involving a large number of features. In this paper, we investigate some practical issues oc-curing when using a MLP as a regression/decision tool. Model selection is a crucial point of flexible methods.
Reference: <author> Kotz, K. </author> <title> and N.L Johnson (1985-1989). Encyclopedia of Statistical Sciences. </title> <publisher> John Wiley & sons. </publisher>
Reference-contexts: But this estimation requires to put aside a part of the sample for estimating PE, and thus to loose information when de termining b f . Analytic estimates of the prediction error exist (cf. <ref> (Kotz and Johnson, 1985-1989) </ref>), but they are based on some strong assumptions on the distribution (X; Y ). Otherwise, they only provide an estimate of the error on x i values.
Reference: <author> Moody, J. </author> <year> (1994). </year> <title> Prediction risk and architecture selection for neural networks. In: From statistics to neural networks (Cherkassky, </title> <editor> Friedman and Wechsler, Eds.). </editor> <volume> Vol. </volume> <booktitle> 136 of NATO ASI series F: Computer and systems sciences. </booktitle> <publisher> Springer-Verlag. </publisher> <pages> pp. 147-165. </pages>
Reference-contexts: Model selection is a crucial point of flexible methods. Its goal is to select the best candidate among a set of models. For MLP, these models are typically defined by the net architecture, or by the effective number of parameter <ref> (Moody, 1994) </ref>. We first recall the main practical features of model selection for flexible methods. Then we rapidly recall the basic principles of some resampling schemes. We finally describe and compare two kinds of connexionist solutions which could be proposed here. 2. <p> Using multiple starts for the optimization algorithm would require 10` = 1260 optimizations for each net size. Instead, we use b f as the starting point for optimization, as the b f i are supposed to be close to b f . This procedure is recommended in <ref> (Moody, 1994) </ref> to lighten computing while avoiding some local minima. The bootstrap estimates b f b boot are not supposed to be very close to b f , the initial weights are thus randomly picked 2 . Here again, we do not use multiple starts to avoid out-of-hand computing.
Reference: <author> Plaut, D.C., S.J. Nowlan and G.E. </author> <title> Hinton (1986). Experiments on learning by back propagation. </title> <type> Technical Report CMU-CS-86-126. </type> <institution> Carnegie-Melon. </institution>
Reference-contexts: The hyper-parameter is thus a function of this standard deviation. To test Noise Injection in this application, we used a MLP with 10 hidden units (161 parameters). 3.3.1. Isotropic Noise Injection In the original setting of Noise Injection <ref> (Plaut et al., 1986) </ref>, the distribution of the noise added to the inputs is unimodal, even, with IE [] = 0 , and IE [ T ] = 2 I (where T denotes the transposition operator, and I denotes the identity matrix). Here, we consider a Gaussian noise.
Reference: <author> Tibshirani, R.J. </author> <year> (1995). </year> <title> A comparison of some error estimates for neural networks models. </title> <type> Technical report. </type> <institution> University of Toronto. </institution>
Reference-contexts: Otherwise, they only provide an estimate of the error on x i values. Some of these estimates have been tested on MLP, when the assumptions are verified, but their reliability seems to be much lower compared to the estimates obtained by resampling techniques <ref> (Tibshirani, 1995) </ref>. Resampling techniques provide out-of-sample estimates of PE (1), while the whole sample can be used to determine b f . <p> The leave-one-out cross-validation criteria is highly down-biased and does not exhibit an optimal hyper-parameter in our problem. Bootstrap seems to be more reliable. The (relative) robustness of bootstrap methods observed here confirm the results of <ref> (Tibshirani, 1995) </ref>, but a thorough study is still to be done.
References-found: 12

