URL: http://sneezy.sri.com/~ravi/Papers/icip-STF.ps
Refering-URL: http://sneezy.sri.com/~ravi/pubs.html
Root-URL: 
Email: E-mail ravi@peregrine.engr.utk.edu  
Title: MOTION PERCEPTION USING SPATIOTEMPORAL FREQUENCY ANALYSIS (First IEEE International Conference on Image Processing, November 1994)  
Author: Gopalan Ravichandran and Mohan M. Trivedi 
Address: Knoxville, TN 37996-2100  
Affiliation: Computer Vision and Robotics Research Laboratory Electrical and Computer Engineering Department University of Tennessee,  
Abstract: Motion information is extracted by identifying the temporal signature associated with the textured objects in the scene. In this paper, we present a new computational framework for motion perception. Our methodology considers spatiotemporal frequency (STF) domain analysis to extract the optical flow information. First, we show that a sequence of image frames can be used to extract the motion parameters for the different regions in a dynamic scene using the basic Fourier transform properties in the STF analysis approach. A detailed analytical description of this model to interchangably extract motion and depth parameters and results to highlight their salient properties are presented. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. J. Gibson, </author> <title> The Perception of the Visual World. </title> <address> Boston, Mass.: Houghton Mi*in, </address> <year> 1950. </year>
Reference-contexts: 1. INTRODUCTION AND PRIOR WORK Several definitions have been forwarded to describe visual motion. The earlier view considered visual motion to be a physical property of the stimulus <ref> [1] </ref>, and used the word optic flow to describe this property. However, the more recent and popular view is that all movement is apparent.
Reference: [2] <author> A. B. Watson and A. J. Ahumada, </author> <title> "Model of hu-man visual-motion sensing," </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> vol. 2, </volume> <pages> pp. 322-341, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: However, the more recent and popular view is that all movement is apparent. Visual motion is not a physical property of the stimulus; the observer has to compute the optic flow from a sequence of images, and the interpretation of the optic flow characteristics gives rise to motion <ref> [2] </ref>. Optic flow is generated by the temporal variation of intensity in the image plane and several approaches have been advanced to compute optic flow.
Reference: [3] <author> R. Kasturi and R. C. Jain, </author> <title> "Dynamic vision," </title> <booktitle> in Computer Vision: Principles, </booktitle> <pages> pp. 469-481, </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1991. </year>
Reference-contexts: Although optical flow has recieved considerable attention from researchers, the techniques developed for the computation of optical flow produce results that do not allow the valuable information to be recovered <ref> [3] </ref>. The techniques described for computing optical flow are broadly classified into three categories. The feature matching-based technique [4-6] is the earliest and most common approach; it uses pairs of images, isolates features in each and subsequently matches them.
Reference: [4] <author> S. Ullman, </author> <title> The Interpretation of Visual Motion. </title> <address> Cambridge, Mass.: </address> <publisher> MIT U. Press, </publisher> <year> 1979. </year>
Reference: [5] <author> P. J. Burt, C. Yen, and X. Xu, </author> <title> "Multi-resolution flow-through motion analysis," </title> <booktitle> in Proc. IEEE CVPR Conf., </booktitle> <pages> pp. 246-252, </pages> <year> 1983. </year>
Reference: [6] <author> P. Anandan, </author> <title> "A computational framework and an algorithm for the measurement of visual motion," </title> <journal> Intern. J. Comput. Vision, </journal> <volume> vol. 2, </volume> <pages> pp. 283-310, </pages> <year> 1989. </year>
Reference: [7] <author> H. H. Nagel, </author> <title> "On the estimation of optical flow : Relations between different approaches and some new results," </title> <journal> Artif. Intell., </journal> <volume> vol. 33, </volume> <pages> pp. 299-324, </pages> <year> 1987. </year>
Reference: [8] <author> B. K. P. Horn and B. Schunck, </author> <title> "Determining op-tical flow," </title> <journal> Artif. Intell., </journal> <volume> vol. 17, </volume> <pages> pp. 185-203, </pages> <year> 1983. </year>
Reference: [9] <author> B. F. Buxton and H. Buxton, </author> <title> "Computation of optic flow from the motion of edge features in im-age sequences," </title> <journal> Image Vision Computing, </journal> <volume> vol. 2, </volume> <year> 1984. </year>
Reference: [10] <author> J. P. H. van Santen and G. Sperling, </author> <title> "Temporal covariance model of human motion perception," </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> vol. 1, </volume> <pages> pp. 451-473, </pages> <month> May </month> <year> 1984. </year>
Reference: [11] <author> E. H. Adelson and J. R. Bergen, </author> <title> "Spatiotemporal energy models for the perception of motion," </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> vol. 2, </volume> <pages> pp. 284-299, </pages> <month> February </month> <year> 1985. </year>
Reference: [12] <author> D. J. Heeger, </author> <title> "Model for the extraction of image flow," </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> vol. 4, </volume> <pages> pp. 1455-1471, </pages> <month> August </month> <year> 1987. </year>
Reference-contexts: The gradient-based technique [7-9] involves the computation of image gradients, and the intensity variations between successive image frames along these image gradients. The spatiotemporal filtering approach [2,10,11] defines the use of separable spa- tiotemporal filters that are expressed as a combination of spatial and temporal impulse responses. Heeger <ref> [12] </ref> used a temporal sequence of 2-D spatial filters to determine the motion characteristics of the different regions in the input. In the recent years, much work has also been done in estimating the velocity component using local phase information [13] obtained from the spatiotemporal responses of tuned Gabor functions.
Reference: [13] <author> D. J. Fleet and A. D. Jepson, </author> <title> "Computation of component image velocity from local phase infor-mation," </title> <journal> Int. J. Comput. Vision, </journal> <volume> vol. 5, no. 1, </volume> <pages> pp. 77-104, </pages> <year> 1990. </year>
Reference-contexts: Heeger [12] used a temporal sequence of 2-D spatial filters to determine the motion characteristics of the different regions in the input. In the recent years, much work has also been done in estimating the velocity component using local phase information <ref> [13] </ref> obtained from the spatiotemporal responses of tuned Gabor functions. In this paper, we use the spatiotemporal frequency (STF) domain analysis approach to extract motion information from a sequence of image frames.
Reference: [14] <author> A. K. Jain, </author> <title> Fundamentals of Digital Image Processing. </title> <address> Englewood Cliffs, NJ 07632: PrenticeHall, </address> <publisher> Inc., </publisher> <year> 1989. </year>
Reference-contexts: Hence in the following discussions, we consider P (u; v : a; b) more closely. When an image is sampled evenly in time, its Fourier transform is periodic. According to the Nyquist criterion <ref> [14] </ref>, the largest temporal frequency that can be represented without aliasing is w max = 1=2 cycle/frame. Each period of the Fourier transform extends between w max and +w max , and thus the periodicity of the Fourier transform is w p = 2w max , i.e.
References-found: 14

