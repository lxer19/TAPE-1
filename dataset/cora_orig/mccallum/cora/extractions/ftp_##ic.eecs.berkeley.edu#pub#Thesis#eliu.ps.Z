URL: ftp://ic.eecs.berkeley.edu/pub/Thesis/eliu.ps.Z
Refering-URL: http://www-cad.eecs.berkeley.edu/Respep/Research/Thesis/thesis.html
Root-URL: http://www.cs.berkeley.edu
Title: Analog Behavioral Simulation and Modeling  
Author: by Edward W. Y. Liu B.S. (U. C. Professor Paul R. Gray Professor David Brillinger 
Degree: 1987 M.S. (Stanford University) 1988 A dissertation submitted in partial satisfaction of the requirements for the degree of Doctor of Philosophy in Engineering-Electrical Engineering and Computer Science in the GRADUATE DIVISION of the UNIVERSITY of CALIFORNIA at BERKELEY Committee in charge: Professor Alberto Sangiovanni-Vincentelli, Chair  
Date: 1993  
Affiliation: Berkeley)  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> P. E. Allen and P. R. Barton. </author> <title> A silicon compiler for successive approximation A/D and D/A converters. </title> <booktitle> In Proc. IEEE Custom Integrated Circuits Conference, </booktitle> <pages> pages 552-555, </pages> <year> 1986. </year>
Reference-contexts: Because parasitics degrade analog system performance, it is crucial to verify by simulation as completely as possible the circuit functionality in the presence of these second order effects. Existing design methodologies, manual or automatic <ref> [26, 7, 1] </ref>, use SPICE simulations to verify the final designs at the transistor level. Unfortunately, SPICE simulations often fail for larger systems due to non-convergence or unreasonable computational cost. For example, to simulate process variations of a circuit, designers traditionally use worst case analysis.
Reference: [2] <author> B. Antao and F. El-Turky. </author> <title> Automatic analog model generation for behavioral simulation. </title> <booktitle> In Proc. IEEE Custom Integrated Circuits Conference, </booktitle> <pages> pages 12.2.1-12.2.4, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: The reason is that although each iteration is fast, a large number of iterations are needed for convergence in tightly coupled circuits. 2.2 Macromodeling 2.2.1 Macromodeling for circuit simulation One approach to address the problem of long simulation time is macromodel-ing in circuit simulation <ref> [13, 40, 2, 36, 4, 18, 56] </ref>. Macromodels constructed from a set of basic circuit elements in circuit simulators such as resistors, capacitors, inductors, and controlled sources approximate the transient behavior of circuits.
Reference: [3] <author> M. Box and N. Draper. </author> <title> Factorial designs, the jx 0 xj criterion, and some related matters. </title> <journal> Technometrics, </journal> <volume> 13, </volume> <year> 1971. </year>
Reference-contexts: The objective is to find the optimal subset of the full set of 2 N 1 test points that minimizes the prediction variance of m. This problem falls in the category of Optimal Design of Experiments. It has been shown under the D-Optimality criterion <ref> [3] </ref> that in the limit where the number of test points is large, an optimal selection is S 0 v , an m by m matrix formed by selected rows of S v .
Reference: [4] <author> G. Boyle, B. Cohn, D. Pederson, and J. Solomon. </author> <title> Macromodeling of integrated circuit operational amplifiers. </title> <journal> IEEE Journal of Solid State Circuits, </journal> <volume> SC-9:353-363, </volume> <year> 1974. </year>
Reference-contexts: The reason is that although each iteration is fast, a large number of iterations are needed for convergence in tightly coupled circuits. 2.2 Macromodeling 2.2.1 Macromodeling for circuit simulation One approach to address the problem of long simulation time is macromodel-ing in circuit simulation <ref> [13, 40, 2, 36, 4, 18, 56] </ref>. Macromodels constructed from a set of basic circuit elements in circuit simulators such as resistors, capacitors, inductors, and controlled sources approximate the transient behavior of circuits. <p> The architecture of macromodels are developed by designers based on experience. Macromodel component values are tuned either manually or automatically. Manually tuned macromodels have been available for SPICE for specific types of circuits such as opamps by Boyle <ref> [4] </ref>, comparators by Getreu [18], and phase-locked loops by Tan [56]. In these cases, the macromodel values are hand tuned to minimize the error. As a result, the accuracy of the macromodel can neither be quantified nor controlled.
Reference: [5] <author> D. Brillinger. </author> <title> Time Series Data Analysis and Theory, Expanded Edition. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: In such cases, the Gaussian model can be extended to a non-Gaussian model by appending a nonlinear filter to create the non-Gaussian distributions <ref> [5, 6] </ref>. Figure 4.1 shows a block diagram of a nonlinear model where the zero mean Gaussian error, e = U t c t , is being filtered to model a non-Gaussian error. <p> A least square estimate of a is obtained by linear regression over the points (x (i); 2 From linear regression theory <ref> [5] </ref>, the optimal least square fit corresponds to a = (X T X) 1 X T D 1 y (4:42) where X (i; j) = x (i) j1 is an 2 N 1 by N a matrix and D 1 is an 2 N 1 by 2 N transfor mation matrix
Reference: [6] <author> D. R. Brillinger. </author> <title> The identification of polynomial systems by means of higher order spectra. </title> <journal> Journal Sound Vibration, </journal> <volume> 12 </volume> <pages> 301-31, </pages> <year> 1970. </year>
Reference-contexts: In such cases, the Gaussian model can be extended to a non-Gaussian model by appending a nonlinear filter to create the non-Gaussian distributions <ref> [5, 6] </ref>. Figure 4.1 shows a block diagram of a nonlinear model where the zero mean Gaussian error, e = U t c t , is being filtered to model a non-Gaussian error.
Reference: [7] <author> L. R. Carley and et. al. </author> <title> Acacia: The CMU analog design system. </title> <booktitle> In Proc. IEEE Custom Integrated Circuits Conference, </booktitle> <year> 1989. </year>
Reference-contexts: Because parasitics degrade analog system performance, it is crucial to verify by simulation as completely as possible the circuit functionality in the presence of these second order effects. Existing design methodologies, manual or automatic <ref> [26, 7, 1] </ref>, use SPICE simulations to verify the final designs at the transistor level. Unfortunately, SPICE simulations often fail for larger systems due to non-convergence or unreasonable computational cost. For example, to simulate process variations of a circuit, designers traditionally use worst case analysis.
Reference: [8] <author> G. Casinovi and A. Sangiovanni-Vincentelli. </author> <title> A macromodeling algorithm for analog circuits. </title> <journal> IEEE Trans. on CAD, </journal> <volume> Vol. 10, No. 2 </volume> <pages> 150-160, </pages> <year> 1991. </year>
Reference-contexts: Because a macromodel is simpler than the original circuit, simulation time is reduced at the expense of accuracy. For example, the operational amplifier (opamp) circuit shown in Figure 2.1 is modeled by the macromodel <ref> [8] </ref> shown in Figure 2.2. The opamp with nine nonlinear transistors is modeled by a simpler network of a nonlinear-controlled current source, a DC voltage source, a resistor, and a capacitor. The nonlinear-controlled current source, gm1, represents the transconductance of the nonlinear input differential pair. <p> The DC voltage source sets the DC output bias. The resistor, rlm, and capacitor, clm, represent the output resistance and capacitance at the output node, respectively. The elements values are tuned to minimize the difference between macro-model and actual circuit outputs. In <ref> [8] </ref>, the difference is defined as c (m; i w ) = 2 0 where m is a macromodel, i w is an input waveform, T is the time duration for the comparison, v 2 is the output from the macromodel m, and v 1 is the output from the 9 <p> In these cases, the macromodel values are hand tuned to minimize the error. As a result, the accuracy of the macromodel can neither be quantified nor controlled. On the other hand, Casinovi <ref> [8] </ref> proposed algorithms for solving (2.2) based on 10 an extension of the Hamiltonian formulation of a classical optimal control problem. In this approach, the accuracy of the macromodel can be quantified and controlled. Macromodeling has been implemented in commercial circuit simulators such as PSPICE [13] and HSPICE [40]. <p> Consequently, the simulation time reduction is small. Moreover, great expertise is needed to devise the macromodel. Also, there are limited tools for extracting parameters for macromodels. Casinovi <ref> [8] </ref> proposed a methodology for automatic macromodel construction and Ma [34] presented model generation and validation tools for iMACSIM. Furthermore, using the circuit simulation and macromodeling approaches, it is very difficult to simulate frequency domain effects, noise effects, or effects due to process variations.
Reference: [9] <author> R. Chadha, C. Visweswariah, and C. F. Chen. </author> <title> m 3 a multi-level mixed-mode mixed D/A simulator. </title> <booktitle> Proc. IEEE ICCAD, </booktitle> <pages> pages 258-261, </pages> <month> November </month> <year> 1988. </year> <month> 104 </month>
Reference-contexts: As in PSPICE, these elements are voltage or current sources described by functions. In HSPICE, the functions can include nodal voltages, element currents, time, or user defined parameters. 2.2.2 Macromodeling for Mixed Analog/Digital Simulators Simulators such as <ref> [17, 50, 9] </ref> have a simulation engine for mixed analog/digital circuits, as well as a more flexible macromodeling capability. The SABER simulator [17] uses the MAST language as input. The circuit is described as a network of templates using MAST.
Reference: [10] <author> H. Chang, A. Sangiovanni-Vincentelli, F. Balarin, E. Charbon, U. Choudhury, G. Jusuf, E. Liu, E. Malavasi, R. Neff, and P. Gray. </author> <title> A top-down, constraint-driven design methodology for analog integrated circuits. </title> <booktitle> In Proc. IEEE Custom Integrated Circuits Conference, </booktitle> <pages> pages 841-846, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Besides, as the circuit size increases, more simulations are required to estimate system performances affected by noise or process variations. To circumvent the design and verification problems associated with traditional simulators, we propose a top-down constraint-driven approach <ref> [10, 11] </ref> to designing complex mixed signal circuits, where abstraction and successive design refinement are key. Previously, several design methodologies [60, 25] have been proposed for high level synthesis of digital circuits. <p> Finally, a conclusion is presented in Chapter 8. 1.4 Conclusion System design and verification using traditional simulators such as SPICE is often impossible due to the long simulation times. To circumvent the design and verification problems associated with traditional simulators, we propose a top-down, constraint-driven approach <ref> [10, 11] </ref> to designing complex mixed signal circuits, where abstraction and successive design refinement are key. <p> Furthermore, behavioral simulation results agree well with measurements for an 8-bit cyclic A/D converter [38]; thus, validating the behavioral model. 40 Chapter 5 Analog System Verification using Behavioral Simulation 5.1 Background We have proposed a constraint-driven, top-down design methodology for mixed-mode systems <ref> [10] </ref> that is supported by analog design tools. An integral part of such methodology is the complete verification of the synthesized circuit in the presence of layout parasitic resistances and capacitances due to routing, supply variations, and coupling. <p> In some design methodologies such as standard cell analog designs, designers verify each cell extensively by SPICE simulation. Yet, the final system of interconnected cells may fail due to interconnect parasitics or cell interactions. 5.2 Verification Tasks in Top-Down Design In contrast, our top-down design methodology <ref> [10] </ref> decomposes a system into its components, then the components into subcomponents using the same methodology until constraint-driven physical layout synthesis. In such a design environment, the key verification tasks are the verification of component functionality and the verification of the system after the components are routed in a system. <p> The 10 bit converter is synthesized using our proposed constraint-driven, top-down design methodology <ref> [10] </ref> for maximum INL less than 2.0 LSB. Due to high converter resolution, parasitic effects are no longer negligible. The key non-idealities in the design are mismatches in the transistors, parasitic resistances, parasitic capacitances, and output resistances in the transistors. Capacitances cause output glitches during fast switching. <p> Then, we find the sensitivity matrix of the output current with respect to the resistances, @t @R , by solving the adjoint network with the appropriate ideal voltage and current sources. 5.4.7 Experimental Results We verified an industrial strength 10 bit D/A <ref> [10] </ref> bottom-up from layout to system level performance on a DEC 5000/125. By using the adjoint technique for sensitivity analysis on the linearized chip-level interconnect network, we computed efficiently the INL performance sensitivity with respect to all chip level routing resistances. <p> Because Monte Carlo integration is used, our estimate Y improves with the number of trials, k. The variance of our estimate is inversely proportional to k 2 . 6.5 Experimental Results We have applied the new strategy to the automatic test generation for a 10 bit current-switched, interpolative D/A <ref> [10] </ref> shown in Figure 6.2. We used a bottom-up verification strategy [29] to compute the D/A behavioral model parameters from SPICE netlist and expected process variation parameters. Behavioral simulation of the D/A and automatic test generation have been integrated into a single software package to facilitate design-for-testability. <p> To circumvent the design and verification problems associated with traditional simulators, we proposed a top-down, constraint-driven approach <ref> [10, 11] </ref> to designing complex mixed-signal circuits, where abstraction, successive design refinement, and constraint propagations are key. To support the proposed design methodology, we developed system simulation algorithms and behavioral models for different types of analog systems and components.
Reference: [11] <author> H. Chang, A. Sangiovanni-Vincentelli, E. Charbon, U. Choudhury, E. Felt, G. Jusuf, E. Liu, E. Malavasi, and R. Neff. </author> <title> A top-down, constraint-driven design methodology for analog integrated circuits. </title> <booktitle> In Proc. Workshop on Advances in Analog Circuit Design, Scheveningen, NL, </booktitle> <pages> pages 301-325, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: Besides, as the circuit size increases, more simulations are required to estimate system performances affected by noise or process variations. To circumvent the design and verification problems associated with traditional simulators, we propose a top-down constraint-driven approach <ref> [10, 11] </ref> to designing complex mixed signal circuits, where abstraction and successive design refinement are key. Previously, several design methodologies [60, 25] have been proposed for high level synthesis of digital circuits. <p> Finally, a conclusion is presented in Chapter 8. 1.4 Conclusion System design and verification using traditional simulators such as SPICE is often impossible due to the long simulation times. To circumvent the design and verification problems associated with traditional simulators, we propose a top-down, constraint-driven approach <ref> [10, 11] </ref> to designing complex mixed signal circuits, where abstraction and successive design refinement are key. <p> To circumvent the design and verification problems associated with traditional simulators, we proposed a top-down, constraint-driven approach <ref> [10, 11] </ref> to designing complex mixed-signal circuits, where abstraction, successive design refinement, and constraint propagations are key. To support the proposed design methodology, we developed system simulation algorithms and behavioral models for different types of analog systems and components.
Reference: [12] <author> L. O. Chua and Pen-Min Lin. </author> <title> Computer aided analysis of electronic circuits: algorithms & computational techniques. </title> <publisher> Prentice-hall, </publisher> <year> 1975. </year>
Reference-contexts: V 0 , * Parameter fitting for behavioral models. * Component linearization at ideal bias conditions, * Linearized component insertion into interconnection network, * Network solving for new bias conditions V , * Optional step: Sensitivity computation of V with respect to all elements in the interconnect using adjoint techniques <ref> [12] </ref>. * Bias change (from ideal bias conditions) computation, V V o , on linearized com ponents. * Changes (sensitivity) of V propagation to changes (sensitivity) of behavioral model parameters W , and then to changes (sensitivity) of system performance S. 50 The advantage of the new approach is that we <p> Furthermore, we create an adjoint network by building a network using the adjoint representation of elements <ref> [12] </ref>.
Reference: [13] <author> MicroSim Corporation. </author> <title> Circuit Analysis User's Guide Version 5.0. </title> <publisher> MicroSim Corporation, </publisher> <month> July </month> <year> 1991. </year>
Reference-contexts: The reason is that although each iteration is fast, a large number of iterations are needed for convergence in tightly coupled circuits. 2.2 Macromodeling 2.2.1 Macromodeling for circuit simulation One approach to address the problem of long simulation time is macromodel-ing in circuit simulation <ref> [13, 40, 2, 36, 4, 18, 56] </ref>. Macromodels constructed from a set of basic circuit elements in circuit simulators such as resistors, capacitors, inductors, and controlled sources approximate the transient behavior of circuits. <p> In this approach, the accuracy of the macromodel can be quantified and controlled. Macromodeling has been implemented in commercial circuit simulators such as PSPICE <ref> [13] </ref> and HSPICE [40]. In PSPICE, the Analog Behavioral Modeling (macromodeling) option allows for flexible description of electronic components in terms of a transfer function described by a formula or table. For non-linear components, the transfer function describes the instantaneous relation between the input and output.
Reference: [14] <author> Analog Devices. </author> <title> Data converter reference manual volume II. </title> <address> Norwood, MA 02062-9106, </address> <year> 1992. </year>
Reference-contexts: Intuitively, Definition 4.3.5 means that we transform t using constants a and b such that the two end-points are ideal. In this case, we have adopted the more popular end-point method for linear error compensation <ref> [14] </ref>, instead of the less popular least square method. The motivation behind the transformation is to compensate for the offset and gain errors before calculation of nonlinearity. In many applications, offset and gain errors are irrelevant as they do not contribute to distortion. <p> + 2 21a (6) (4:46) a (3) + 16 V (4) = 8 3a (6) (4:48) a (5) (4:49) a (6) (4:50) According to the definition of harmonic distortion, the i th harmonic distortion param eter is HD i = V (1) Ignoring higher order harmonics, the total harmonic distortion <ref> [14] </ref> in decibels is esti mated to be T HD = 20log 4 V (2) 2 + V (3) 2 + V (4) 2 + V (5) 2 + V (6) 2 3 35 The mean and standard deviation of all harmonic distortion parameters are computed using a small number of <p> A standard measure of effective converter resolution is the effective number of bits <ref> [14] </ref>, S=N + D 1:76 (4:59) The mean and standard deviation of the above parameters are estimated using a small number of Monte Carlo simulations from which the 3 worst case values are estimated. 36 4.4 Model Validation A model must be verified against measurements to test its validity.
Reference: [15] <author> S. C. Fang, Y. P. Tsividis, and O. Wing. SWITCAP: </author> <title> a switched capacitor network analysis program. </title> <journal> IEEE Circuits Syst. Mag., </journal> <volume> 5(3) </volume> <pages> 4-10, </pages> <month> September </month> <year> 1983. </year>
Reference-contexts: Yet, verification of system performance in the presence of noise and process variation effects are crucial. 2.3 Special Purpose Simulators 2.3.1 Simulators for switched-capacitor networks For simulating specific classes of circuits such as switched-capacitor networks, special purpose simulators <ref> [15, 35] </ref> are more efficient than general purpose circuit simulators. SWITCAP [15] is a program for the exact analysis of linear networks containing ideal capacitors, independent and dependent voltage sources, and switches 13 from which macromodels of components are constructed. <p> Yet, verification of system performance in the presence of noise and process variation effects are crucial. 2.3 Special Purpose Simulators 2.3.1 Simulators for switched-capacitor networks For simulating specific classes of circuits such as switched-capacitor networks, special purpose simulators [15, 35] are more efficient than general purpose circuit simulators. SWITCAP <ref> [15] </ref> is a program for the exact analysis of linear networks containing ideal capacitors, independent and dependent voltage sources, and switches 13 from which macromodels of components are constructed.
Reference: [16] <author> Y. Gendai, Y. Komatsu, S. Hirase, and M. Kawata. </author> <title> An 8b 500MHz ADC. </title> <booktitle> In Proc. IEEE International Solid-State Circuits Conference, </booktitle> <pages> pages 172-174, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: If a simple digital decoder (Figure 7.12) is used, the output code can be very different from the correct code, in which case the error is called a sparkle <ref> [16] </ref>. Because the output error probabilities are usually very small, (6:4 10 4 in Figure 7.13), many simulations are needed in the Monte Carlo method to predict sparkles.
Reference: [17] <author> I. Getreu. </author> <title> Behavioral modeling of analog blocks using the SABER simulator. </title> <booktitle> Proc. MWCAS, </booktitle> <pages> pages 977-980, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: As in PSPICE, these elements are voltage or current sources described by functions. In HSPICE, the functions can include nodal voltages, element currents, time, or user defined parameters. 2.2.2 Macromodeling for Mixed Analog/Digital Simulators Simulators such as <ref> [17, 50, 9] </ref> have a simulation engine for mixed analog/digital circuits, as well as a more flexible macromodeling capability. The SABER simulator [17] uses the MAST language as input. The circuit is described as a network of templates using MAST. <p> In HSPICE, the functions can include nodal voltages, element currents, time, or user defined parameters. 2.2.2 Macromodeling for Mixed Analog/Digital Simulators Simulators such as [17, 50, 9] have a simulation engine for mixed analog/digital circuits, as well as a more flexible macromodeling capability. The SABER simulator <ref> [17] </ref> uses the MAST language as input. The circuit is described as a network of templates using MAST. Each template defines a component's behavior using differential equations or equations relating timing of events.
Reference: [18] <author> I. Getreu, A. Hadiwidjaja, and J. Brinch. </author> <title> An integrated-circuit comparator macro-model. </title> <journal> IEEE Journal of Solid State Circuits, </journal> <volume> SC-11:826-833, </volume> <year> 1976. </year>
Reference-contexts: The reason is that although each iteration is fast, a large number of iterations are needed for convergence in tightly coupled circuits. 2.2 Macromodeling 2.2.1 Macromodeling for circuit simulation One approach to address the problem of long simulation time is macromodel-ing in circuit simulation <ref> [13, 40, 2, 36, 4, 18, 56] </ref>. Macromodels constructed from a set of basic circuit elements in circuit simulators such as resistors, capacitors, inductors, and controlled sources approximate the transient behavior of circuits. <p> The architecture of macromodels are developed by designers based on experience. Macromodel component values are tuned either manually or automatically. Manually tuned macromodels have been available for SPICE for specific types of circuits such as opamps by Boyle [4], comparators by Getreu <ref> [18] </ref>, and phase-locked loops by Tan [56]. In these cases, the macromodel values are hand tuned to minimize the error. As a result, the accuracy of the macromodel can neither be quantified nor controlled.
Reference: [19] <author> G. Gielen, E. Liu, A. Sangiovanni-Vincentelli, and P. Gray. </author> <title> Analog behavioral models for simulation and synthesis of mixed-signal systems. </title> <booktitle> In Proc. EDAC, </booktitle> <month> March </month> <year> 1992. </year>
Reference-contexts: Unfortunately, there are no noise simulators that can analyze noise effects for mixed-mode systems. To develop such a simulator, we follow the behavioral simulation paradigm in which circuits are modeled mathematically as in <ref> [33, 19, 30, 31] </ref>. In this chapter, we present a new noise behavioral model and a direct noise analysis approach for mixed-mode systems. Using the appropriate model, there is no need for circuit 77 or macromodel simulation, but a direct algebraic approach where the objects being manipulated are noise characterizations.
Reference: [20] <author> P. R. Gray and R. G. Meyer. </author> <title> Analysis and design of analog integrated circuits. </title> <editor> J. </editor> <publisher> Wiley & Sons, 3rd Edition, </publisher> <year> 1993. </year> <month> 105 </month>
Reference-contexts: Thermal, flicker, and shot noise in the transistors and thermal noise in resistors contribute to the noise of the circuit. Traditionally, electronic noise is modeled with a Gaussian random process described by its power spectral density <ref> [20] </ref>. From the noise sources, the system architecture, and the deterministic input, we seek the distribution of the output. For example, we seek the continuous output distribution of a D/A converter, the bit error rate of a receiver, or the output code distribution of an A/D converter.
Reference: [21] <author> J. M. Hammersley and D. C. Handscomb. </author> <title> Monte Carlo Methods. </title> <publisher> London, Methuen & Co Ltd., </publisher> <year> 1964. </year>
Reference-contexts: In simple Monte Carlo, the integral is computed by generating samples of x from density function f () and summing g (x). An important sample, x, provides useful information such as non-zero g (x). Importance sampling <ref> [21] </ref> forces generation of important samples by using an artificial density function instead of f (x).
Reference: [22] <author> R. Harjani, R. A. Rutenbar, and L. R. Carley. OASYS: </author> <title> A framework for analog circuit synthesis. </title> <journal> IEEE Trans. on CAD, </journal> <pages> pages 1247-1266, </pages> <year> 1989. </year>
Reference-contexts: ADAM uses both hard-coded and knowledge-based techniques to achieve these goals. In the analog domain, OASYS <ref> [22] </ref> is a hierarchically structured framework for analog circuit synthesis. Analog circuit 2 topologies are represented as a hierarchy of templates of abstract functional blocks each with associated detailed design knowledge.
Reference: [23] <author> G. Hemink, B. Meijer, and H. Kerkhoff. </author> <title> Testability analysis of analog systems. </title> <journal> IEEE Trans. on CAD, </journal> <month> June </month> <year> 1990. </year>
Reference-contexts: Moreover, measurement noise poses a significant problem because it corrupts the estimated parameters. To reduce measurement noise problems, Hemink <ref> [23] </ref> presented algorithms for testability analysis and optimal test selection in the presence of measurement noise. On the other hand, Souders [52] proposed adding more test points to reduce noise effects by creating an overdetermined system of equations to be solved by least square techniques. <p> We will show that these are essential to developing a testing strategy that tradeoffs between test set size, test coverage, detection thresholds, measurement noise, chip performance, and estimated yield. 6.3.1 Measurement and Detection Threshold As mentioned in Section 6.2, previous testing strategies <ref> [53, 23] </ref> have difficulty in accurate measurements of circuit performance such as A/D converter transition points in the presence of measurement noise. To circumvent the problem, we propose a simpler measurement that is robust against noise.
Reference: [24] <author> H. Kahn. </author> <title> Use of different monte carlo sampling techniques. </title> <booktitle> In Symposium on Monte Carlo Methods, </booktitle> <pages> pages 146-190. </pages> <address> New York, </address> <publisher> Wiley, </publisher> <year> 1956. </year>
Reference-contexts: There are typically many different noise sources, so the number of possible h (x) is large. As a result, automatic selection of a suitable h (x) out of many possibilities is difficult. To circumvent the difficulty of choosing h (x), Kahn introduced splitting techniques <ref> [24] </ref> as another form of importance sampling.
Reference: [25] <author> D. W. Knapp and A. C. Parker. </author> <title> The ADAM design planning engine. </title> <journal> IEEE Trans. on CAD, </journal> <pages> pages 829-846, </pages> <year> 1991. </year>
Reference-contexts: To circumvent the design and verification problems associated with traditional simulators, we propose a top-down constraint-driven approach [10, 11] to designing complex mixed signal circuits, where abstraction and successive design refinement are key. Previously, several design methodologies <ref> [60, 25] </ref> have been proposed for high level synthesis of digital circuits. For example, the System Architect's Workbench [60] takes as input a behavioral description of a system to be designed, along with a set of constraints, and produces a set of register-transfer modules and a control sequence table. <p> For example, the System Architect's Workbench [60] takes as input a behavioral description of a system to be designed, along with a set of constraints, and produces a set of register-transfer modules and a control sequence table. The ADAM <ref> [25] </ref> system is designed to unify a number of design automation programs into a single framework.
Reference: [26] <author> H. Y. Koh, C. H. S equin, and P. R. Gray. </author> <title> Automatic synthesis of operational amplifiers based on analytic circuit models. </title> <booktitle> In Proc. IEEE ICCAD, </booktitle> <pages> pages 502-505, </pages> <year> 1987. </year>
Reference-contexts: Because parasitics degrade analog system performance, it is crucial to verify by simulation as completely as possible the circuit functionality in the presence of these second order effects. Existing design methodologies, manual or automatic <ref> [26, 7, 1] </ref>, use SPICE simulations to verify the final designs at the transistor level. Unfortunately, SPICE simulations often fail for larger systems due to non-convergence or unreasonable computational cost. For example, to simulate process variations of a circuit, designers traditionally use worst case analysis.
Reference: [27] <author> K. S. Kundert. </author> <title> Sparse matrix techniques and their application to circuit simulation. </title> <editor> In A. E. Ruehli, editor, </editor> <title> Circuit Analysis, </title> <booktitle> Simulation and Design, </booktitle> <pages> pages 281-324. </pages> <publisher> North-Holland, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: We describe global parasitic resistances by a linear network of resistors, R = fR 1 ; R 2 ; : : :g, the linearized components, and ideal voltage and current sources. Then, we compute the new DC bias using modified node analysis [44] implemented with a sparse matrix solver <ref> [27] </ref>. We repeat the bias calculations for all 1024 input codes to get a new nominal output current vector, 0 t .
Reference: [28] <author> W. Lam, A. Saldanha, R. Brayton, and A. Sangiovanni-Vincentelli. </author> <title> Delay fault coverage and performance tradeoffs. </title> <booktitle> Proc. Design Automation Conference, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: Typically, we choose k = 5 for a 10 statistical limit. If c s is unbounded, then the statistical information provided by the distribution of c s is lost. 67 In a different context of delay fault testing <ref> [28] </ref>, a similar problem formulation has been applied to check bounds on delays of digital circuits. In both formulations, the problems seem to be analytically intractable.
Reference: [29] <author> E. Liu, H. Chang, and A. Sangiovanni-Vincentelli. </author> <title> Analog system verification in the presence of parasitics using behavioral simulation. </title> <booktitle> In Proc. Design Automation Conference, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: In this experiment, the ideal bias point is chosen to be very close to the actual bias point. In cases where a bias point is not known in advance, we use a procedure based on sensitivity analysis <ref> [29] </ref> (Section 5.4). Variances of k i are extracted using either sensitivity analysis (exact) or Monte Carlo SPICE simulations (approximate) of each component. <p> The variance of our estimate is inversely proportional to k 2 . 6.5 Experimental Results We have applied the new strategy to the automatic test generation for a 10 bit current-switched, interpolative D/A [10] shown in Figure 6.2. We used a bottom-up verification strategy <ref> [29] </ref> to compute the D/A behavioral model parameters from SPICE netlist and expected process variation parameters. Behavioral simulation of the D/A and automatic test generation have been integrated into a single software package to facilitate design-for-testability.
Reference: [30] <author> E. Liu, G. Gielen, H. Chang, and A. Sangiovanni-Vincentelli. </author> <title> Behavioral modeling and simulation of data converters. </title> <booktitle> In Proc. IEEE Int. Symposium on Circuits and Systems, </booktitle> <pages> pages 2144-2147, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: This identification/data fitting procedure is then repeated for components higher in the hierarchy until the top level system is verified. 1.3 Organization of thesis Behavioral simulation algorithms and behavioral representations for many types of mixed analog/digital circuits have been researched <ref> [33, 31, 30, 32] </ref>. This thesis presents a behavioral representation for the class of Nyquist data converters, an analog 6 system verification strategy using behavioral simulation, a testing strategy for data converters using behavioral simulation, and noise models and simulation algorithms for mixed-mode sampled-data systems. <p> Unfortunately, there are no noise simulators that can analyze noise effects for mixed-mode systems. To develop such a simulator, we follow the behavioral simulation paradigm in which circuits are modeled mathematically as in <ref> [33, 19, 30, 31] </ref>. In this chapter, we present a new noise behavioral model and a direct noise analysis approach for mixed-mode systems. Using the appropriate model, there is no need for circuit 77 or macromodel simulation, but a direct algebraic approach where the objects being manipulated are noise characterizations.
Reference: [31] <author> E. Liu and A. Sangiovanni-Vincentelli. </author> <title> Behavioral representation for vco and detectors in phase-lock systems. </title> <booktitle> In Proc. IEEE Custom Integrated Circuits Conference, </booktitle> <pages> pages 1231-1234, </pages> <month> May </month> <year> 1992. </year> <month> 106 </month>
Reference-contexts: This identification/data fitting procedure is then repeated for components higher in the hierarchy until the top level system is verified. 1.3 Organization of thesis Behavioral simulation algorithms and behavioral representations for many types of mixed analog/digital circuits have been researched <ref> [33, 31, 30, 32] </ref>. This thesis presents a behavioral representation for the class of Nyquist data converters, an analog 6 system verification strategy using behavioral simulation, a testing strategy for data converters using behavioral simulation, and noise models and simulation algorithms for mixed-mode sampled-data systems. <p> Unfortunately, there are no noise simulators that can analyze noise effects for mixed-mode systems. To develop such a simulator, we follow the behavioral simulation paradigm in which circuits are modeled mathematically as in <ref> [33, 19, 30, 31] </ref>. In this chapter, we present a new noise behavioral model and a direct noise analysis approach for mixed-mode systems. Using the appropriate model, there is no need for circuit 77 or macromodel simulation, but a direct algebraic approach where the objects being manipulated are noise characterizations.
Reference: [32] <author> E. Liu and A. Sangiovanni-Vincentelli. </author> <title> Behavioral simulation for noise in mixed-mode sampled-data systems. </title> <booktitle> In Proc. IEEE ICCAD, </booktitle> <pages> pages 322-326, </pages> <month> Nov </month> <year> 1992. </year>
Reference-contexts: This identification/data fitting procedure is then repeated for components higher in the hierarchy until the top level system is verified. 1.3 Organization of thesis Behavioral simulation algorithms and behavioral representations for many types of mixed analog/digital circuits have been researched <ref> [33, 31, 30, 32] </ref>. This thesis presents a behavioral representation for the class of Nyquist data converters, an analog 6 system verification strategy using behavioral simulation, a testing strategy for data converters using behavioral simulation, and noise models and simulation algorithms for mixed-mode sampled-data systems. <p> In our model, noise and process variation effects are separated. The distribution t captures process variation effects, while the joint density function f () captures noise effects. The function f () is computed using either direct techniques <ref> [32] </ref> or Monte Carlo techniques. The process variation effects can be derived by making assumption: Assumption 4.2.1 Process variations are the cumulative effects of many integrated circuit fabrication steps. Thus, we assume that the distribution of the process variations, v, is multivariate normal.
Reference: [33] <author> E. Liu, A. Sangiovanni-Vincentelli, G. Gielen, and P. Gray. </author> <title> A behavioral representation for nyquist rate A/D converters. </title> <booktitle> In Proc. IEEE ICCAD, </booktitle> <pages> pages 386-389, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: This identification/data fitting procedure is then repeated for components higher in the hierarchy until the top level system is verified. 1.3 Organization of thesis Behavioral simulation algorithms and behavioral representations for many types of mixed analog/digital circuits have been researched <ref> [33, 31, 30, 32] </ref>. This thesis presents a behavioral representation for the class of Nyquist data converters, an analog 6 system verification strategy using behavioral simulation, a testing strategy for data converters using behavioral simulation, and noise models and simulation algorithms for mixed-mode sampled-data systems. <p> From the information contained in the behavioral model, engineers can evaluate the tradeoffs between test set size, test coverage, detection thresholds, measurement noise, chip performance, and estimated yield. To achieve this goal, we propose a new converter testing strategy for data converters from a behavioral model <ref> [33] </ref>. We present previous work in Section 6.2, a new testing strategy in Section 6.3, a yield analysis algorithm in Section 6.4, and experimental results in Section 6.5. 61 6.2 Previous Work In [51, 53] a linear model for data converters along with a test selection strategy was presented. <p> Unfortunately, there are no noise simulators that can analyze noise effects for mixed-mode systems. To develop such a simulator, we follow the behavioral simulation paradigm in which circuits are modeled mathematically as in <ref> [33, 19, 30, 31] </ref>. In this chapter, we present a new noise behavioral model and a direct noise analysis approach for mixed-mode systems. Using the appropriate model, there is no need for circuit 77 or macromodel simulation, but a direct algebraic approach where the objects being manipulated are noise characterizations.
Reference: [34] <author> V. Ma, J. Singh, and R. Saleh. </author> <title> Modeling, Simulation, and Optimization of Analog Macromodels. </title> <booktitle> In Proc. IEEE Custom Integrated Circuits Conference, </booktitle> <pages> pages 12.1.1-12.1.4, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Consequently, the simulation time reduction is small. Moreover, great expertise is needed to devise the macromodel. Also, there are limited tools for extracting parameters for macromodels. Casinovi [8] proposed a methodology for automatic macromodel construction and Ma <ref> [34] </ref> presented model generation and validation tools for iMACSIM. Furthermore, using the circuit simulation and macromodeling approaches, it is very difficult to simulate frequency domain effects, noise effects, or effects due to process variations. The reason is that the models are deterministic and focus on the time domain circuit behavior.
Reference: [35] <author> H. J. De Man, J. Rabaey, G. Arnout, and J. Vandewalle. </author> <title> Practical implementation of a general computer aided design technique for switched capacitor circuits. </title> <journal> IEEE Journal of Solid State Circuits, </journal> <volume> SC-15:190-200, </volume> <month> April </month> <year> 1980. </year>
Reference-contexts: Yet, verification of system performance in the presence of noise and process variation effects are crucial. 2.3 Special Purpose Simulators 2.3.1 Simulators for switched-capacitor networks For simulating specific classes of circuits such as switched-capacitor networks, special purpose simulators <ref> [15, 35] </ref> are more efficient than general purpose circuit simulators. SWITCAP [15] is a program for the exact analysis of linear networks containing ideal capacitors, independent and dependent voltage sources, and switches 13 from which macromodels of components are constructed. <p> Using the circuit simulation and macromodeling approaches, it is very difficult to simulate frequency domain effects, noise effects, or effects due to process variations because all models are deterministic. Special purpose simulators 14 are more efficient than general purpose circuit simulators. Some <ref> [35] </ref> handle frequency domain and noise simulations, while others [62] perform only time domain simulations and rely on spectral estimation techniques and Monte Carlo simulations for estimating frequency response and noise effects, respectively. But, none considers process variation effects.
Reference: [36] <author> H. A. Mantooth and P. E. Allen. </author> <title> Behavioral simulation of a 3-bit flash ADC. </title> <booktitle> In Proc. IEEE Int. Symposium on Circuits and Systems, </booktitle> <pages> pages 1356-1359, </pages> <year> 1990. </year>
Reference-contexts: The reason is that although each iteration is fast, a large number of iterations are needed for convergence in tightly coupled circuits. 2.2 Macromodeling 2.2.1 Macromodeling for circuit simulation One approach to address the problem of long simulation time is macromodel-ing in circuit simulation <ref> [13, 40, 2, 36, 4, 18, 56] </ref>. Macromodels constructed from a set of basic circuit elements in circuit simulators such as resistors, capacitors, inductors, and controlled sources approximate the transient behavior of circuits. <p> However, this distinction is largely irrelevant from a mathematical point of view and is only related to the formalism used to input data. To illustrate modeling using SABER, the equations representing a comparator <ref> [36] </ref> is presented below, I M1 + I M2 = C T dt V S + I BIAS (2:3) F (I M1 ; I M2 ) G 1 (V 1 ) = C 1 dt 11 dV 0 (2:5) where F (I M1 ; I M2 ) = I M1 I <p> Consequently, designers simulate a subset of the process corners, but no general algorithm has been proposed for choosing the subset. 41 Due to the difficulties, several behavioral simulation approaches have been proposed earlier <ref> [36, 46] </ref>. Unfortunately, they do not take into account loading para-sitics and must also use worst case analysis to compute process variation effects. In some design methodologies such as standard cell analog designs, designers verify each cell extensively by SPICE simulation.
Reference: [37] <author> A. Matsuzawa, S. Nakashima, I. Hidaka, S. Sawada, H. Kodaka, and S. Shimada. </author> <title> A 6b 1GHz dual-parallel A/D converter. </title> <booktitle> In Proc. IEEE International Solid-State Circuits Conference, </booktitle> <pages> pages 174-175, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: In contrast, using the direct noise computation method, we have modeled two flash A/D's, one with a simple thermometer-to-binary ROM decoder and one with a more advanced decoder (Figure 7.12). Effective comparator noise can be estimated from <ref> [37] </ref>. In this experiment, for convenience we set the standard deviation of the comparator noise to a quarter of the smallest input voltage step size. Input voltage is half of the full range input. The output code distribution, computed using direct method (k=2), is shown in Figure 7.13.
Reference: [38] <author> R. McCharles. </author> <title> Charge circuits for analog LSI. </title> <type> Ph.d. thesis, </type> <institution> University of Califor-nia at Berkeley, </institution> <year> 1980. </year>
Reference-contexts: Another implication of the A/D model is that the errors of a converter can be decomposed into its errors signatures. To verify that errors signatures are sufficient to characterize an actual A/D, we obtained the measured error, t t , of a fabricated cyclic A/D <ref> [38] </ref>, and try to fit the measured data, t, with a linear combination of error signatures using linear regression techniques t = t + U t c + ffi (4:61) where we solve for c, an unknown realization of c that minimize the measurement noise jjffijj 2 , where jj jj <p> From SPICE simulations, the distribution of D/A errors for a 10-bit converter were shown to agree well with the Gaussian distribution; thus, validating our Gaussian error assumption. Furthermore, behavioral simulation results agree well with measurements for an 8-bit cyclic A/D converter <ref> [38] </ref>; thus, validating the behavioral model. 40 Chapter 5 Analog System Verification using Behavioral Simulation 5.1 Background We have proposed a constraint-driven, top-down design methodology for mixed-mode systems [10] that is supported by analog design tools.
Reference: [39] <author> J. McCreary and P. R. Gray. </author> <title> All-mos charge-redistribution analog-to-digital conversion techniques, part i. </title> <journal> IEEE Journal of Solid State Circuits, </journal> <volume> SC-10:371-379, </volume> <month> December </month> <year> 1975. </year>
Reference-contexts: Its applications include simulation of switched-capacitor filters and charge redistribution systems, such as several types of A/D and D/A and PCM encoders and decoders <ref> [39, 58] </ref>. The simulation algorithm is based on charge conservation equations before and after switching states and Kirchhoff 's voltage law (KVL). As a result, the network variables to be solved for are the voltages and charges. The network equations are formed from the network topology and element values.
Reference: [40] <author> Meta-Software. </author> <note> HSPICE User's Manual H9001. Meta-Software, </note> <year> 1990. </year>
Reference-contexts: The reason is that although each iteration is fast, a large number of iterations are needed for convergence in tightly coupled circuits. 2.2 Macromodeling 2.2.1 Macromodeling for circuit simulation One approach to address the problem of long simulation time is macromodel-ing in circuit simulation <ref> [13, 40, 2, 36, 4, 18, 56] </ref>. Macromodels constructed from a set of basic circuit elements in circuit simulators such as resistors, capacitors, inductors, and controlled sources approximate the transient behavior of circuits. <p> In this approach, the accuracy of the macromodel can be quantified and controlled. Macromodeling has been implemented in commercial circuit simulators such as PSPICE [13] and HSPICE <ref> [40] </ref>. In PSPICE, the Analog Behavioral Modeling (macromodeling) option allows for flexible description of electronic components in terms of a transfer function described by a formula or table. For non-linear components, the transfer function describes the instantaneous relation between the input and output. <p> For linear components, the transfer function describes the behavior in the frequency domain. This macromodeling capability is simply an extension of the basic nonlinear controlled voltage and current sources in traditional circuit simulators. In HSPICE <ref> [40] </ref>, macromodels offer a higher level of abstraction and a speedup over the lower level description of an analog function. As in PSPICE, these elements are voltage or current sources described by functions.
Reference: [41] <author> C. Michael and M. Ismail. </author> <title> Statistcial modeling of device mismatch for analog mos integrated circuits. </title> <journal> IEEE Journal of Solid State Circuits, SC-27, </journal> <volume> No. 2, </volume> <month> November </month> <year> 1992. </year>
Reference: [42] <author> M. Pelgrom, A. Duinmaijer, and A. Welbers. </author> <title> Matching properties of mos transistors. </title> <journal> IEEE Journal of Solid State Circuits, SC-24, </journal> <volume> No. 5, </volume> <month> October </month> <year> 1989. </year> <month> 107 </month>
Reference-contexts: Such prediction is consistent with data in [41]<ref> [42] </ref>. Although theories for mismatches in MOS transistors were developed in [42] based on spatial frequency, we propose here a new theory that can estimate covariance of transistor parameters in large transistor arrays efficiently by using sensitivity analysis and matrix algebra. 53 5.4.4 From SPICE Netlist to Behavioral Models We extract behavioral model parameters from netlist for each component using SPICE.
Reference: [43] <author> W. Press, B. Flannery, S. Teukolsky, and W. Vetterling. </author> <title> Numerical Recipes in C. </title> <booktitle> The Art of Scientific Computing. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1989. </year>
Reference-contexts: For example, an A/D produces a discrete output code from a continuous input. Under the previous testing strategy, we measure the transitions between adjacent output codes using a bisection search 62 algorithm <ref> [43] </ref>. In this algorithm, we guess initial lower bound, t l (i), and upper bound, t u (i), for the transition t (i). <p> Due to linear dependence, we use linear programming <ref> [43] </ref> to check the bounds on untested INL, s (i), in (6.17). We formulate the problem as follows. <p> A numerical solver is difficult to implement due to the need for good initial guesses. As a result, parameters 1 ; 2 ; a are computed from x 1 ; x 2 ; x 3 using the downhill simplex optimization method in multidimensions <ref> [43] </ref> to best match the moments. The cost function being used is c = P k k ) 2 , where x k are the moments given, and x 0 k are the resulting moments given by (7.28) to (7.30).
Reference: [44] <author> T. Quarles. </author> <note> SPICE3 version 3c1 user's guide. Memorandum UCB/ERL M89/46, </note> <editor> U. C. </editor> <address> Berkeley, </address> <year> 1989. </year>
Reference-contexts: support the proposed top-down design methodology, we are developing system simulation algorithms and behavioral models for many types of analog components such as converters, phase-locked loops, and filters that capture second order effects. 7 Chapter 2 Previous Work 2.1 Circuit simulation Most popular circuit simulators today are based on SPICE <ref> [44] </ref> developed at U. C. Berkeley. The user inputs a circuit netlist that describes the connectivity of the components. The components are modeled with a network of basic circuit elements such as inductors, capacitors, resistors, and controlled sources that are described by differential equations. <p> We describe global parasitic resistances by a linear network of resistors, R = fR 1 ; R 2 ; : : :g, the linearized components, and ideal voltage and current sources. Then, we compute the new DC bias using modified node analysis <ref> [44] </ref> implemented with a sparse matrix solver [27]. We repeat the bias calculations for all 1024 input codes to get a new nominal output current vector, 0 t . <p> Since the N -bit digital output code is a logic function of N successive outputs of the comparator, we seek the probabilities for each of the 2 N possible output codes given a deterministic input. 7.3 Previous work Traditionally, the SPICE-like simulators <ref> [44] </ref> analyze analog circuit noise in the frequency domain. SPICE linearizes the circuit at the operating point, adds sinusoidal sources in parallel to the noisy elements, and analyze the resulting AC equivalent circuit. The approach has two problems.
Reference: [45] <author> S. Ross. </author> <title> A First Course in Probability, volume page 211. </title> <publisher> Macmillan Publishing Company, </publisher> <address> New York, </address> <note> second edition, </note> <year> 1984. </year>
Reference-contexts: An overview of sample space, events, probability, random variables, jointly distributed random variables, random vectors, and random processes will be provided below. 3.2 Sample Space and Events Consider an experiment whose outcome is unpredictable. The set of all possible outcomes is known as the sample space <ref> [45] </ref> denoted by S. <p> For example, the event for odd outcomes in the previous experiment is E = f1; 3; 5g (3:2) The event E occurs if the outcome of the experiment is 1, 3, or 5. 16 3.3 Axioms of Probability Following <ref> [45] </ref>, we use an axiomatic definition of probability. Consider an experiment whose sample space is S. For each event E of the sample space, we define a number P (E), the probability of event E, that satisfies the following three axioms. <p> P (E) = lim n (E) (3:4) where n (E) is the number of times in the first n repetitions of the experiment that the event E occurs. The definition is justified in <ref> [45] </ref> using the Strong Law of Large Numbers and Axioms 3.3.1, 3.3.2, 3.3.3. 3.4 Random Variable Often we are interested in some numerical value associated with experimental outcomes. Therefore, we define a random variable as a real-valued function with domain the sample space, S. <p> However, there are random variables whose possible values are not countable. We take the definition for a continuous random variable from <ref> [45] </ref>, Definition 3.4.1 X is a continuous random variable if there exists a nonnegative function, f , defined for all real x 2 (1; 1), having the property that for any set B of real numbers P fX 2 Bg = B The function, f , is called the probability density <p> For example, P fa X bg = a The probability density function completely characterizes the random variable because all probability statements about X can be answered in terms of f . For example, the cumulative distribution function <ref> [45] </ref>, F (), of a random variable, X, is defined for all real numbers b; 1 &lt; b &lt; 1, by F (b) = P fX bg = 1 The expected value of g (X), where g () is any real-valued function is E [g (X)] = 1 E [g (X)] <p> p e 2 2 ; 1 &lt; x &lt; 1 (3:12) The cumulative distribution function of a normal random variable is F (b) = 1 (3:13) where Q () is a standard mathematical function defined as Q (x) = 1 p e u 2 3.5 Jointly Distributed Random Variables Following <ref> [45] </ref>, we define, for any two random variables X and Y , the joint cumulative probability distribution function of X and Y by F (a; b) = P fX a; Y bg; 1 &lt; a; b &lt; 1 (3:15) We say that X and Y are jointly continuous if there exists <p> The joint probability density function completely characterizes the random variables X and Y because all probability statements about X and Y can be answered in terms of f . In <ref> [45] </ref> it is shown that the joint probability density function and joint cumulative distribution function are related by f (a; b) = @a@b The probability density functions of X and Y can be obtained using f X (x) = 1 19 Z 1 f (x; y)dx (3:19) The expectation of a <p> )] = 1 1 g (x; y)f (x; y)dxdy (3:20) The covariance of random variables X and Y , denoted by Cov (X; Y ), is defined as Cov (X; Y ) = E [(X E [X])(Y E [Y ])] = E [XY ] E [X]E [Y ] (3:21) From <ref> [45] </ref>, if X and Y have a joint probability density function f (x; y), then the conditional probability density function of X, given that Y = y, is defined for all values of y such that f Y (y) &gt; 0, by f XjY (xjy) = f Y (y) The use <p> For example, X can be a continuous random variable with density function f X , while Y can be a discrete random variable. The joint density function is f (X; Y ). In this case, the conditional density of X given that Y = y is given in <ref> [45] </ref> by f XjY (xjy) = f (X; Y = y) = P fY = yg 3.5.1 Independent Random Variables The continuous random variables X and Y are said to be independent [45] if f (x; y) = f X (x)f Y (y) (3:24) in which case for any functions h <p> In this case, the conditional density of X given that Y = y is given in <ref> [45] </ref> by f XjY (xjy) = f (X; Y = y) = P fY = yg 3.5.1 Independent Random Variables The continuous random variables X and Y are said to be independent [45] if f (x; y) = f X (x)f Y (y) (3:24) in which case for any functions h and g E [g (X)h (Y )] = E [g (X)]E [h (y)] (3:25) and Cov (X; Y ) = 0 from (3.21). 20 3.6 Random Vector Whereas scalar random variables take
Reference: [46] <author> G. Ruan. </author> <title> A behavioral model of A/D converters using a mixed-mode simulator. </title> <journal> IEEE Journal of Solid State Circuits, SC-26, </journal> <volume> No. 3, </volume> <month> March </month> <year> 1991. </year>
Reference-contexts: In this research, we focus on modeling a memoryless converter for static performance specifications. Previously, Ruan <ref> [46] </ref> proposed different behavioral models for different types 24 of A/D converter architectures. One drawback is that the architectural dependence necessitates derivation of a new model for any changes in the converter architecture. Another drawback is that the model is deterministic. <p> Consequently, designers simulate a subset of the process corners, but no general algorithm has been proposed for choosing the subset. 41 Due to the difficulties, several behavioral simulation approaches have been proposed earlier <ref> [36, 46] </ref>. Unfortunately, they do not take into account loading para-sitics and must also use worst case analysis to compute process variation effects. In some design methodologies such as standard cell analog designs, designers verify each cell extensively by SPICE simulation.
Reference: [47] <author> R. Saleh, J. E. Kleckner, and A. R. </author> <title> Newton. Iterated timing analysis and SPLICE1. </title> <booktitle> In Proc. IEEE ICCAD, </booktitle> <month> November </month> <year> 1983. </year>
Reference-contexts: To address the problem of long simulation time, a new generation of circuit simulators have been developed in the 1980's. Rather than solving the linear equa 8 tions directly, simulators such as SPLICE1 <ref> [47] </ref>, solves the equations iteratively using relaxation techniques. The idea of the iterative method can also be applied at the waveform level (voltage as a function of time).
Reference: [48] <author> R. A. Saleh and A. R. </author> <title> Newton. Mixed-Mode Simulation. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1990. </year>
Reference-contexts: Blocks can also be described in the C language. At the functional level, macromodels such as switches and controlled sources may be used. At the circuit level, electrical simulation is performed using a relaxation based method <ref> [48] </ref>. 2.2.3 Limitations of Circuit Simulation and Macromodeling Although macromodels reduce simulation time, they are not satisfactory to solve analog system problems. For example, the element values for the macromodel shown in Figure 2.2 are optimized for specific input waveforms and output responses.
Reference: [49] <author> K. S. Shanmugan and A. M. Breipohl. </author> <title> Random Signals Detection, Estimation and Data Analysis. </title> <address> New York, </address> <publisher> J. Wiley & Sons, </publisher> <year> 1988. </year>
Reference-contexts: For example, if X is diagonal, then the components of X are independent in additional to being uncorrelated. Also, if A is a k x m matrix of rank k, then Y = AX has a k-variate normal distribution with <ref> [49] </ref> Y = A X (3:34) 3.7 Random Process A random variable is a mapping from the sample space, S, to a real value. Similarly, a random process or stochastic process is a mapping from the sample space, S, to a waveform. <p> Similarly, a random process or stochastic process is a mapping from the sample space, S, to a waveform. To every outcome fl 2 S, we assign a waveform using X (t; fl) (3:36) Following the notations in <ref> [49] </ref>, we omit fl and write a random process simply as X (t). <p> The autocovariance of X (t), denoted by C XX (t 1 ; t 2 ), is defined as C XX (t 1 ; t 2 ) = R XX (t 1 ; t 2 ) fl 22 3.7.1 Stationarity According to definitions in <ref> [49] </ref>, a random process is strict sense stationary if all of the distribution functions describing the process are invariant under a translation in time. A random process is wide sense stationary if the mean and autocorrelation function are invariant under a translation in time. <p> For a wide sense stationary signal, it can be shown <ref> [49] </ref> that the power spectral density is the Fourier transform of the autocorrelation function.
Reference: [50] <author> J. Singh and R. Saleh. iMACSIM: </author> <title> A program for multi-level analog circuit simulation. </title> <booktitle> In Proc. IEEE ICCAD, </booktitle> <pages> pages 16-19, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: As in PSPICE, these elements are voltage or current sources described by functions. In HSPICE, the functions can include nodal voltages, element currents, time, or user defined parameters. 2.2.2 Macromodeling for Mixed Analog/Digital Simulators Simulators such as <ref> [17, 50, 9] </ref> have a simulation engine for mixed analog/digital circuits, as well as a more flexible macromodeling capability. The SABER simulator [17] uses the MAST language as input. The circuit is described as a network of templates using MAST. <p> The output voltage is V 0 . To show the fact that modeling in SABER is equivalent to macromodeling, a traditional macromodel representing the same circuit is shown in Figure 2.3. iMACSIM <ref> [50] </ref> is a multi-level, mixed-domain simulator. At the highest level is behavioral simulation which is used when the function of a block is known, but its detailed structure is undefined yet.
Reference: [51] <author> T. Souders and G. Stenbakken. </author> <title> Modeling and test point selection for data converter testing. </title> <booktitle> IEEE International Test Conference, </booktitle> <year> 1985. </year>
Reference-contexts: We present previous work in Section 6.2, a new testing strategy in Section 6.3, a yield analysis algorithm in Section 6.4, and experimental results in Section 6.5. 61 6.2 Previous Work In <ref> [51, 53] </ref> a linear model for data converters along with a test selection strategy was presented.
Reference: [52] <author> T. Souders and G. Stenbakken. </author> <title> A comprehensive approach for modeling and testing analog and mixed-signal devices. </title> <booktitle> IEEE International Test Conference, </booktitle> <year> 1990. </year>
Reference-contexts: Moreover, measurement noise poses a significant problem because it corrupts the estimated parameters. To reduce measurement noise problems, Hemink [23] presented algorithms for testability analysis and optimal test selection in the presence of measurement noise. On the other hand, Souders <ref> [52] </ref> proposed adding more test points to reduce noise effects by creating an overdetermined system of equations to be solved by least square techniques.
Reference: [53] <author> T. Souders and G. Stenbakken. </author> <title> Cutting the high cost of testing. </title> <journal> IEEE Spectrum, </journal> <month> March </month> <year> 1991. </year>
Reference-contexts: The columns of U t are called the error signatures <ref> [53] </ref> and form a set of orthonormal vectors spanning the error space. <p> We present previous work in Section 6.2, a new testing strategy in Section 6.3, a yield analysis algorithm in Section 6.4, and experimental results in Section 6.5. 61 6.2 Previous Work In <ref> [51, 53] </ref> a linear model for data converters along with a test selection strategy was presented. <p> Our strategy focuses on testing all DC performance of Nyquist data convert 63 ers including offset error, full scale gain error, integral nonlinearity, and differential nonlinearity. The behavioral model for data converters presented in Chapter 4 is useful for testing DC performance. In contrast, the model proposed previously in <ref> [53] </ref> is deterministic and hence does not represent statistical effects. We represent electronic noise as well as process variation effects. Moreover, our model has distributions for INL and DNL. <p> We will show that these are essential to developing a testing strategy that tradeoffs between test set size, test coverage, detection thresholds, measurement noise, chip performance, and estimated yield. 6.3.1 Measurement and Detection Threshold As mentioned in Section 6.2, previous testing strategies <ref> [53, 23] </ref> have difficulty in accurate measurements of circuit performance such as A/D converter transition points in the presence of measurement noise. To circumvent the problem, we propose a simpler measurement that is robust against noise. <p> Also, the size drops below the rank of 38 for INL larger than 3.2 LSB, where the rank is the number of INL signatures. This occurs because some INL signatures with small magnitudes do not contribute significantly to large INL errors. In contrast, previous 70 testing strategy <ref> [53] </ref> uses the same number of tests as the rank because such strategy does not take into consideration the magnitudes of the signatures. In Figure 6.4, we plotted the DEC ALPHA CPU times for test generation against INL. Notice that test generation times drops significantly for lower performance chips.
Reference: [54] <author> G. Stenbakken and T. Souders. </author> <title> Test-point selection and testability measures via QR factorization of linear models. </title> <journal> IEEE Transactions on Instrumentation and Measurement, </journal> <month> June </month> <year> 1987. </year>
Reference-contexts: Under this criterion, the prediction variance of v is minimized by maximizing jS 0T v S 0 v j where j j is the determinant. While the D-Optimality criterion gives the optimal solution, the computational complexity prevents its use for large models. Stenbakken <ref> [54] </ref> introduced an algorithm for a near optimal solution based on QR factorization with pivoting. <p> As a result, the optimum test selection problem is likely intractable. Thus, we propose a heuristic solution. First, we rank the tests according to the algorithm proposed in <ref> [54] </ref> based on QR factorization with pivoting. * (a) Choose the row of U s with the largest norm, * (b) Orthogonalize all remaining rows to it using a modified Gram-Schmidt or thogonalization procedure, * (c) Choose the row of largest L 2 norm of those remaining, * (d) Repeat (b)
Reference: [55] <author> S. M. Sze. </author> <title> VLSI Technology, volume page 226. </title> <publisher> McGraw-Hill Book Company, </publisher> <year> 1983. </year> <month> 108 </month>
Reference-contexts: Letting B ~ f XjY (xjL), the moments of B are given by b 1 = (x 1 a 1 p H )=p L (7:25) Highest moment k=3 When k = 3, the random variable, X, is approximated by distribution <ref> [55] </ref> created by joining together two halves of two different Gaussian random variables defined as f X (x) = &gt; &gt; &gt; &lt; 2 p e 2 2 2 p (xa) 2 2 x &lt; a 87 where its moments are given by x 1 = ( 2 1 + a)
Reference: [56] <author> E. Tan. </author> <title> Phase-locked loop macromodels. </title> <type> Master's thesis, </type> <address> U. C. Berkeley, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: The reason is that although each iteration is fast, a large number of iterations are needed for convergence in tightly coupled circuits. 2.2 Macromodeling 2.2.1 Macromodeling for circuit simulation One approach to address the problem of long simulation time is macromodel-ing in circuit simulation <ref> [13, 40, 2, 36, 4, 18, 56] </ref>. Macromodels constructed from a set of basic circuit elements in circuit simulators such as resistors, capacitors, inductors, and controlled sources approximate the transient behavior of circuits. <p> The architecture of macromodels are developed by designers based on experience. Macromodel component values are tuned either manually or automatically. Manually tuned macromodels have been available for SPICE for specific types of circuits such as opamps by Boyle [4], comparators by Getreu [18], and phase-locked loops by Tan <ref> [56] </ref>. In these cases, the macromodel values are hand tuned to minimize the error. As a result, the accuracy of the macromodel can neither be quantified nor controlled.
Reference: [57] <author> L. J. Tick. </author> <title> The estimation of the transfer functions of quadratic systems. </title> <journal> Techno-metrics, </journal> <volume> 3 </volume> <pages> 563-567, </pages> <year> 1961. </year>
Reference-contexts: Figure 4.1 shows a block diagram of a nonlinear model where the zero mean Gaussian error, e = U t c t , is being filtered to model a non-Gaussian error. For example, to model an error with third order non-Gaussian statistics <ref> [57] </ref>, a quadratic filter b is used in the following equation for t as a replacement for (4.9), t = t + U t c t + 1 1 b (t u; t v)e (u)e (v)dudv (4:11) where e = U t c t , b is the two-dimensional impulse response
Reference: [58] <author> Y. P. Tsividis, P. R. Gray, D. A. Hodges, and Jr. J. Chacko. </author> <title> A segmented -225 law pcm voice encoder utilizing nmos technology. </title> <journal> IEEE Journal of Solid State Circuits, </journal> <volume> SC-11:740-747, </volume> <month> December </month> <year> 1976. </year>
Reference-contexts: Its applications include simulation of switched-capacitor filters and charge redistribution systems, such as several types of A/D and D/A and PCM encoders and decoders <ref> [39, 58] </ref>. The simulation algorithm is based on charge conservation equations before and after switching states and Kirchhoff 's voltage law (KVL). As a result, the network variables to be solved for are the voltages and charges. The network equations are formed from the network topology and element values.
Reference: [59] <author> J. Vandewalle, H. De Man, and J. Rabaey. </author> <title> The adjoint switched capacitor network and its application to frequency, noise and sensitivity analysis. In Circuit Theory and Applications, </title> <journal> pages Vol. </journal> <volume> 9, </volume> <pages> pages 77-88, </pages> <year> 1981. </year>
Reference-contexts: Secondly, mixed-mode systems are usually non-steady state (e.g. an 78 A/D produces an output code after a finite time), so an operating point does not exist for the circuit. Simulators such as <ref> [59] </ref> analyze noise in switched-capacitor circuits using linear systems theory, but fail to handle noise in mixed-mode switched-capacitor circuits as mixed-mode circuits are in general nonlinear. Without simulators for noise effects, designers use the Monte Carlo noise simulation technique.
Reference: [60] <author> R. A. Walker and D. E. Thomas. </author> <title> Design representation and transformation in the system architect's workbench. </title> <booktitle> Proc. IEEE ICCAD, </booktitle> <pages> pages 166-169, </pages> <year> 1987. </year>
Reference-contexts: To circumvent the design and verification problems associated with traditional simulators, we propose a top-down constraint-driven approach [10, 11] to designing complex mixed signal circuits, where abstraction and successive design refinement are key. Previously, several design methodologies <ref> [60, 25] </ref> have been proposed for high level synthesis of digital circuits. For example, the System Architect's Workbench [60] takes as input a behavioral description of a system to be designed, along with a set of constraints, and produces a set of register-transfer modules and a control sequence table. <p> Previously, several design methodologies [60, 25] have been proposed for high level synthesis of digital circuits. For example, the System Architect's Workbench <ref> [60] </ref> takes as input a behavioral description of a system to be designed, along with a set of constraints, and produces a set of register-transfer modules and a control sequence table. The ADAM [25] system is designed to unify a number of design automation programs into a single framework.
Reference: [61] <author> J. White and A. Sangiovanni-Vincentelli. </author> <title> RELAX2.1 a waveform relaxation based circuit simulation program. </title> <booktitle> In Proc. IEEE Custom Integrated Circuits Conference, </booktitle> <month> June </month> <year> 1984. </year>
Reference-contexts: Rather than solving the linear equa 8 tions directly, simulators such as SPLICE1 [47], solves the equations iteratively using relaxation techniques. The idea of the iterative method can also be applied at the waveform level (voltage as a function of time). In simulators such as RELAX2.1 <ref> [61] </ref>, initial guesses are made for waveforms on each circuit node, then the waveforms are modified iteratively until they converge to the correct waveforms.
Reference: [62] <author> L. A. Williams, B. E. Boser, E. W. Y. Liu, and B. A. Wooley. </author> <title> MIDAS user manual. </title> <institution> Center for Integrated Systems, Stanford University, </institution> <year> 1989. </year>
Reference-contexts: Key elements of switched-capacitor circuits such as opamps and comparators are nonlinear. Moreover, only primitive elements are available, so the task of circuit modeling falls entirely on the user. Finally, process variations are not considered. 2.3.2 Simulators for sampled-data systems MIDAS <ref> [62] </ref> is a behavioral simulator for mixed-mode sampled-data systems. In MIDAS, a sampled-data system is modeled as a graph of primitive component models such as comparators, delays, and adders. Each cycle in the graph must be broken by at least one delay element. <p> Special purpose simulators 14 are more efficient than general purpose circuit simulators. Some [35] handle frequency domain and noise simulations, while others <ref> [62] </ref> perform only time domain simulations and rely on spectral estimation techniques and Monte Carlo simulations for estimating frequency response and noise effects, respectively. But, none considers process variation effects.
References-found: 62

