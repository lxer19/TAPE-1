URL: ftp://ftp.isi.edu/isi-pubs/rs-96-441.ps.Z
Refering-URL: http://www.isi.edu/isi-technical-reports.html
Root-URL: http://www.isi.edu
Email: jihie@isi.edu, rosenbloom@isi.edu  
Title: Learning Efficient Rules by Maintaining the Explanation Structure  
Author: Jihie Kim and Paul S. Rosenbloom 
Address: 4676 Admiralty Way Marina del Rey, CA 90292, U.S.A.  
Affiliation: Information Sciences Institute and Computer Science Department University of Southern California  
Abstract: Many learning systems suffer from the utility problem; that is, that time after learning is greater than time before learning. Discovering how to assure that learned knowledge will in fact speed up system performance has been a focus of research in explanation-based learning (EBL). One way to analyze the utility problem is by examining the differences between the match process (match search) of the learned rule and the problem-solving process from which it is learned. Prior work along these lines examined one such difference. It showed that if the search-control knowledge used during problem solving is not maintained in the match process for learned rules, then learning can engender a slowdown; but that this slowdown could be eliminated if the match is constrained by the original search-control knowledge. This article examines a second difference when the structure of the problem solving differs from the structure of the match process for the learned rules, time after learning can be greater than time before learning. This article also shows that this slowdown can be eliminated by making the learning mechanism sensitive to the problem-solving structure; i.e., by reflecting such structure in the match of the learned rule. 
Abstract-found: 1
Intro-found: 1
Reference: <author> DeJong, G. F., and Mooney, R. </author> <year> 1986. </year> <title> Explanation-based learning: An alternative view. </title> <booktitle> Machine Learning 1(2) </booktitle> <pages> 145-176. </pages>
Reference: <author> Doorenbos, B.; Tambe, M.; and Newell, A. </author> <year> 1992. </year> <title> Learning 10,000 chunks: </title> <booktitle> What's it like out there? In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> 830-836. </pages>
Reference-contexts: The second issue is the average growth effect <ref> (Doorenbos, Tambe, & Newell 1992) </ref>, in which the interactions across the rules slow down the system, even if none of the rules individually are all that expensive. <p> Also, we have introduced decision sub-nodes into Rete. We have applied the resulting experimental system to the Grid task (Tambe 1991) (Figure 8), which is one of the known expensive-chunk tasks. The results shown here are all from Soar6 (version 6.0.4), a C-based release of Soar <ref> (Doorenbos 1992) </ref> on a Sun SPARCstation-20. Each problem in the Grid task is to find a path between two points in a two dimensional grid. For example, finding a path from point F to point O is a Grid task.
Reference: <author> Doorenbos, B. </author> <year> 1992. </year> <note> Soar6 release notes. </note>
Reference-contexts: The second issue is the average growth effect <ref> (Doorenbos, Tambe, & Newell 1992) </ref>, in which the interactions across the rules slow down the system, even if none of the rules individually are all that expensive. <p> Also, we have introduced decision sub-nodes into Rete. We have applied the resulting experimental system to the Grid task (Tambe 1991) (Figure 8), which is one of the known expensive-chunk tasks. The results shown here are all from Soar6 (version 6.0.4), a C-based release of Soar <ref> (Doorenbos 1992) </ref> on a Sun SPARCstation-20. Each problem in the Grid task is to find a path between two points in a two dimensional grid. For example, finding a path from point F to point O is a Grid task.
Reference: <author> Doorenbos, B. </author> <year> 1993. </year> <title> Matching 100,000 learned rules. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence. </booktitle>
Reference: <author> Etzioni, O. </author> <year> 1990. </year> <title> Why Prodigy/EBL works. </title> <booktitle> In Pro--ceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> 916-922. </pages>
Reference: <author> Gratch, J., and Dejong, G. </author> <year> 1992. </year> <title> COMPOSER: A probabilistic solution to the utility problem in speed-up learning. </title> <booktitle> In Proceedings of the Tenth National Conference on Ariti-ficial Intelligence, </booktitle> <pages> 235-240. </pages>
Reference: <author> Greiner, R., and Jurisica, I. </author> <year> 1992. </year> <title> A statistical approach to solving the EBL utility problem. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> 241-248. </pages>
Reference: <author> Hanson, E. N., and Hasan, M. S. </author> <year> 1993. </year> <title> Gator: An optimized discrimination network for active database rule condition testing. </title> <type> Technical Report TR-93-036, </type> <institution> CIS Department, University of Florida. </institution>
Reference: <author> Kim, J., and Rosenbloom, P. S. </author> <year> 1993. </year> <title> Constraining learning with search control. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> 174-181. </pages>
Reference-contexts: This problem was solved in <ref> (Kim & Rosenbloom 1993) </ref> by extending the explanation to include the search-control rules used during problem solving, thus creating more appropriately constrained rules. <p> Summary and Discussion The cost increase of using learned knowledge can be analyzed by examining the difference between the match process (match search) of learned rules and the problem-solving process from which they are learned. In this context, <ref> (Kim & Rosenbloom 1993) </ref> examined an approach that is based on incorporating search-control knowledge into the learned rule. That analysis showed that omitting search control in learning (i.e., in the explanation) can increase the cost of learned rules. <p> The consequence of this omission is that the learned rules are not constrained by the path actually taken in the problem space, and thus can perform an exponential amount of search even when the original problem-space search was highly directed (by the control rules). <ref> (Kim & Rosenbloom 1993) </ref> extended the explanation to include search-control rules, thus creating more constrained rules. <p> We expect that whenever these approaches are used in an EBL system, the explanation structure could give a clue for how to construct a nonlinear match structure. 6 The results presented in <ref> (Kim & Rosenbloom 1993) </ref> are based on chunking in Soar, not Soar/EBL. Because chunking's rule generalization is based on the explanation (instead of the explanation structure), it can create overspecialized rules. The overspecialization of the rules can avoid part of this problem.
Reference: <author> Kim, J., and Rosenbloom, P. </author> <year> 1995. </year> <title> Transformation analyses of learning in Soar. </title> <type> Technical Report ISI/RR-95-4221, </type> <institution> Information Sciences Institute and Computer Science Department University of Southern California. </institution>
Reference-contexts: If instead, the learning mechanism is made sensitive to the problem-solving structure i.e., by reflecting such hierarchical structure in the match of the learned rule this source of expensiveness can be avoided. The focus of the analysis in this paper is Soar/EBL <ref> (Kim & Rosenbloom 1995) </ref>. Although our prior work is based on chunking (Laird, Rosenbloom, & Newell 1985) in Soar, we analyze an implementation of EBL in Soar here to be able to more easily generalize the resulting analysis to other EBL systems.
Reference: <author> Laird, J. E.; Newell, A.; and Rosenbloom, P. S. </author> <year> 1987. </year> <title> Soar: An architecture for general intelligence. </title> <booktitle> Artificial Intelligence 33 </booktitle> <pages> 1-64. </pages>
Reference: <author> Laird, J. E.; Rosenbloom, P. S.; and Newell, A. </author> <year> 1985. </year> <title> Chunking in Soar: The anatomy of a general learning mechanism. </title> <booktitle> Machine Learning 1. </booktitle>
Reference-contexts: The focus of the analysis in this paper is Soar/EBL (Kim & Rosenbloom 1995). Although our prior work is based on chunking <ref> (Laird, Rosenbloom, & Newell 1985) </ref> in Soar, we analyze an implementation of EBL in Soar here to be able to more easily generalize the resulting analysis to other EBL systems. Soar/EBL is a little different from the standard version of Soar with chunking.
Reference: <author> Lee, H. S., and Schor, M. I. </author> <year> 1992. </year> <title> Match algorithms for generalized Rete networks. </title> <booktitle> Artificial Intelligence 54 </booktitle> <pages> 249-274. </pages>
Reference: <author> Markovitch, S., and Scott, P. D. </author> <year> 1993. </year> <title> Information filtering : Selection mechanism in learning systems. </title> <booktitle> Machine Learning 10(2) </booktitle> <pages> 113-151. </pages>
Reference: <author> Minton, S. </author> <year> 1988. </year> <title> Quantitative results concerning the utility of explanation-based learning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> 564-569. </pages>
Reference: <author> Minton, S. </author> <year> 1993. </year> <type> Personal communication. </type>
Reference-contexts: This is a generalization of the term used in the Soar system. 3 What is referred to as k-search in (Tambe 1991). Rosenbloom 1993). For example, PRODIGY/EBL <ref> (Minton 1993) </ref> and Soar (Laird, Newell, & Rosenbloom 1987; Rosenbloom et al. 1991) two problem solvers that learn rules by variants of EBL ignore many of the search-control rules during learning in order to increase the generality of the learned rules.
Reference: <author> Miranker, D. P. </author> <year> 1987. </year> <title> Treat: A better match algorithm for AI production systems. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <pages> 42-47. </pages>
Reference-contexts: Avoiding those identified sources should lead to relative boundedness in the match. (Time after learning would be bounded by time before learning.) Match algorithms are critical in computing both the cost of problem solving and the cost of matching learned rules. Rete and Treat <ref> (Miranker 1987) </ref> are the best known rule match algorithms. We performed an analysis based on Rete. We conjecture that EBL with Treat might suffer similar problems because a Treat network does not have hierarchical structure; however, we have not yet done the analysis.
Reference: <author> Mitchell, T. M.; Keller, R. M.; and Kedar-Cabelli, S. T. </author> <year> 1986. </year> <title> Explanation-based generalization a unifying view. </title> <booktitle> Machine Learning 1(1) </booktitle> <pages> 47-80. </pages>
Reference: <author> Mooney, R. J., and Bennett, S. W. </author> <year> 1986. </year> <title> A domain independent explanaion-based generalization. </title> <booktitle> In Proceedings of the Fifth National Conference on Artificial Intelligence, </booktitle> <pages> 551-555. </pages>
Reference-contexts: The instantiations in the explanation are replaced by rules which have unique names for the variables across the rules. This new structure is called the explanation structure. A regression algorithm (our algorithm is inspired by the EGGS generalization algorithm <ref> (Mooney & Bennett 1986) </ref>) is applied to this explanation structure. A set of substitutions is computed by unifying each connected action-condition pair, and the substitutions are then applied to the variables in the explanation structure. The operational conditions become the conditions of the new rule.
Reference: <author> Prieditis, A. E., and Mostow, J. </author> <year> 1987. </year> <title> PROLEARN: Towards a Prolog interpreter that learns. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <pages> 494-498. </pages>
Reference: <author> Rosenbloom, P. S.; Laird, J. E.; Newell, A.; and McCarl, R. </author> <year> 1991. </year> <title> A preliminary analysis of the Soar architecture as a basis for general intelligence. </title> <journal> Artificial Intelligence 47(1-3):289-325. </journal>
Reference: <author> Scales, D. J. </author> <year> 1986. </year> <title> Efficient matching algorithms for the Soar/Ops5 production system. </title> <type> Technical Report KSL-86-47, </type> <institution> Knowledge Systems Laboratory, Department of Computer Science, Stanford University. </institution>
Reference: <author> Shavlik, J. W. </author> <year> 1990. </year> <title> Aquiring recursive and iterative concepts with explanation-based learning. </title> <booktitle> Machine Learning 5 </booktitle> <pages> 39-70. </pages>
Reference: <author> Shell, P., and Carbonell, J. </author> <year> 1991. </year> <title> Empirical and analytical performance of iterative operators. </title> <booktitle> In The 13th Annual Conference of The Cognitive Science Society, </booktitle> <pages> 898-902. </pages> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: <author> Subramanian, D., and Feldman, R. </author> <year> 1990. </year> <title> The utility of EBL in recursive domain theories. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> 942-949. </pages>
Reference: <author> Tambe, M.; Kalp, D.; Gupta, A.; Forgy, C. L.; Milnes, B. G.; and Newell, A. </author> <year> 1988. </year> <title> Soar/PSM-E: Investigating match parallelism in a learning production system. </title> <booktitle> In Proceedings of the ACM/SIGPLAN Symposium on Parallel Programming: Experience with applications, languages, and systems, </booktitle> <pages> 146-160. </pages>
Reference: <author> Tambe, M.; Kalp, D.; and Rosenbloom, P. S. </author> <year> 1991. </year> <title> Uni-Rete: Specializing the Rete match algorithm for the unique-attribute representation. </title> <type> Technical Report CMU-CS-91-180, </type> <institution> School of Computer Science, Carnegie Mellon University. </institution>
Reference-contexts: Research on the utility problem can be divided up into 1 EBL can also be used to acquire other types of structures, such as macro-operators, but we focus on search-control rules here. two key issues. The first issue is the expensive chunk 2 problem <ref> (Tambe 1991) </ref>, in which individual learned rules are so expensive to match that the system suffers a slow down from learning (Minton 1988; Tambe 1991; Etzioni 1990; Shell & Carbonell 1991; Subramanian & Feldman 1990). <p> That is, the cost of a learned rule can be greater than the cost of solving the problem with the original set of rules. There has been developed a technique for restricting the expressiveness of the rules to bound the match cost of the rules <ref> (Tambe 1991) </ref>. However, the restriction reduces the expressibility of the rules, requiring a large number of rules to encode tasks. Also, the learned rules may become very specific. <p> This is a generalization of the term used in the Soar system. 3 What is referred to as k-search in <ref> (Tambe 1991) </ref>. Rosenbloom 1993). For example, PRODIGY/EBL (Minton 1993) and Soar (Laird, Newell, & Rosenbloom 1987; Rosenbloom et al. 1991) two problem solvers that learn rules by variants of EBL ignore many of the search-control rules during learning in order to increase the generality of the learned rules. <p> Experimental Results In order to supplement the analysis provided in the previous section with experimental evidence, we have extended the current Rete implementation to interpret nonlinear structure. Also, we have introduced decision sub-nodes into Rete. We have applied the resulting experimental system to the Grid task <ref> (Tambe 1991) </ref> (Figure 8), which is one of the known expensive-chunk tasks. The results shown here are all from Soar6 (version 6.0.4), a C-based release of Soar (Doorenbos 1992) on a Sun SPARCstation-20. <p> This multiple usage keeps the cost bounded by constraining the sub-parts as they were in the problem solving. We also applied the system to the Magic Square task <ref> (Tambe 1991) </ref> (Figure 10), another known expensive-chunk task. The task involves placing tiles 1 through 9 in empty squares one at a time. If the sums of horizontal, vertical, and diagonal lines are different in the current tile placement, the task fails. Otherwise, the task succeeds.
Reference: <author> Tambe, M. </author> <year> 1991. </year> <title> Eliminating combinatorics from production match. </title> <type> Ph.D. Dissertation, </type> <institution> Carnegie-Mellon University. </institution>
Reference-contexts: Research on the utility problem can be divided up into 1 EBL can also be used to acquire other types of structures, such as macro-operators, but we focus on search-control rules here. two key issues. The first issue is the expensive chunk 2 problem <ref> (Tambe 1991) </ref>, in which individual learned rules are so expensive to match that the system suffers a slow down from learning (Minton 1988; Tambe 1991; Etzioni 1990; Shell & Carbonell 1991; Subramanian & Feldman 1990). <p> That is, the cost of a learned rule can be greater than the cost of solving the problem with the original set of rules. There has been developed a technique for restricting the expressiveness of the rules to bound the match cost of the rules <ref> (Tambe 1991) </ref>. However, the restriction reduces the expressibility of the rules, requiring a large number of rules to encode tasks. Also, the learned rules may become very specific. <p> This is a generalization of the term used in the Soar system. 3 What is referred to as k-search in <ref> (Tambe 1991) </ref>. Rosenbloom 1993). For example, PRODIGY/EBL (Minton 1993) and Soar (Laird, Newell, & Rosenbloom 1987; Rosenbloom et al. 1991) two problem solvers that learn rules by variants of EBL ignore many of the search-control rules during learning in order to increase the generality of the learned rules. <p> Experimental Results In order to supplement the analysis provided in the previous section with experimental evidence, we have extended the current Rete implementation to interpret nonlinear structure. Also, we have introduced decision sub-nodes into Rete. We have applied the resulting experimental system to the Grid task <ref> (Tambe 1991) </ref> (Figure 8), which is one of the known expensive-chunk tasks. The results shown here are all from Soar6 (version 6.0.4), a C-based release of Soar (Doorenbos 1992) on a Sun SPARCstation-20. <p> This multiple usage keeps the cost bounded by constraining the sub-parts as they were in the problem solving. We also applied the system to the Magic Square task <ref> (Tambe 1991) </ref> (Figure 10), another known expensive-chunk task. The task involves placing tiles 1 through 9 in empty squares one at a time. If the sums of horizontal, vertical, and diagonal lines are different in the current tile placement, the task fails. Otherwise, the task succeeds.
References-found: 28

