URL: ftp://ftp.cse.cuhk.edu.hk/pub/techreports/96/tr-96-6.ps.gz
Refering-URL: ftp://ftp.cs.cuhk.hk/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Yet another algorithm which can generate topography map  
Date: 24, 1996  
Note: June  
Abstract: John Sum, Chi-sing Leung, Lai-wan Chan and Lei Xu Department of Computer Science and Engineering, The Chinese University of Hong Kong Shatin, N.T., Hong Kong Technical report : CS-TR-96-06 Abstract This paper presents an algorithm to generate a topographic map resembling to the Self-Organizing Map. The idea stems on defining an energy function which reveals the local correlation between neighboring neurons. The larger the value of the energy function, the higher the correlation of the neighborhood neurons. On this account, the proposed algorithm is defined as the gradient ascent of this energy function. Simulations on two-dimensional maps are illustrated. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Angeniol B. et al., </author> <title> Self-Organizing Feature Maps and the Traveling Salesman Problem, Neural Networks, </title> <booktitle> Vol.1, </booktitle> <pages> 289-293, </pages> <year> 1988. </year>
Reference-contexts: As its mechanism is simple, it has been widely applied to solve many engineering problems <ref> [1, 6, 7, 14] </ref>. For clarity, we assume that the SOM consists of N neurons. The input to the SOM is denoted by x 2 R n and the weight vectors are denoted by 1 ; 2 ; : : : ; N 2 R n .
Reference: [2] <author> Durbin R. and D.Willshaw, </author> <title> An analogue approach to the travelling salesman problem using an elastic net method. </title> <booktitle> Nature, Vol.326, </booktitle> <pages> 644-647, </pages> <year> 1987. </year>
Reference-contexts: 1 Introduction In the recent decades, many researchers have attempted to mimic the mammalian sensory ordered map, in particular the topography map. Willshaw and van der Malsburg [12], Kohonen [5] and Goodhill [4] have proposed self-organizing algorithms based on the idea of competition. Durbin and Willshaw <ref> [2] </ref> on the other hand considered the map formation as a process similar to that of elastic string.
Reference: [3] <author> Durbin R. and G.Mitchison, </author> <title> A dimension reduction framework for understanding cortical maps. </title> <booktitle> Nature, </booktitle> <address> Vol.343, </address> <month> Feb., </month> <pages> 644-647, </pages> <year> 1990. </year> <month> 6 </month>
Reference-contexts: Some of these algorithms can be described as gradient algorithms because they are embedded with well-defined objective functions which not only ease the formulation of the convergence proof but also suggest possible physical interpretations for the algorithms <ref> [3] </ref>. This paper will be organized into six sections. In the next section, the algorithm of self-organizing map (SOM) will be briefly reviewed and its mechanism is re-interpreted. In accordance with this new interpretation, we suggest the idea of maximum neighborhood coupling.
Reference: [4] <author> Goodhill G.J., </author> <title> Topography and ocular dominance: A model exploring positive correla-tions. </title> <journal> Biological Cybernetics, </journal> <volume> 69, </volume> <pages> 109-118, </pages> <year> 1993. </year>
Reference-contexts: 1 Introduction In the recent decades, many researchers have attempted to mimic the mammalian sensory ordered map, in particular the topography map. Willshaw and van der Malsburg [12], Kohonen [5] and Goodhill <ref> [4] </ref> have proposed self-organizing algorithms based on the idea of competition. Durbin and Willshaw [2] on the other hand considered the map formation as a process similar to that of elastic string.
Reference: [5] <author> Kohonen T., </author> <title> Self-Organized Formation of Topologically Correct Feature Maps. </title> <journal> Biological Cybernetics, </journal> <volume> 43 </volume> <pages> 59-69, </pages> <year> 1982. </year>
Reference-contexts: 1 Introduction In the recent decades, many researchers have attempted to mimic the mammalian sensory ordered map, in particular the topography map. Willshaw and van der Malsburg [12], Kohonen <ref> [5] </ref> and Goodhill [4] have proposed self-organizing algorithms based on the idea of competition. Durbin and Willshaw [2] on the other hand considered the map formation as a process similar to that of elastic string. <p> Section five presents the connection between the proposed algorithm and two other algorithms. Finally, the conclusion is presented in section six. 2 Preliminary Review of Self-Organizing Map SOM was proposed by Kohonen in the early 1980s <ref> [5] </ref> which was based on the idea of competition and neighborhood update concepts. As its mechanism is simple, it has been widely applied to solve many engineering problems [1, 6, 7, 14]. For clarity, we assume that the SOM consists of N neurons.
Reference: [6] <author> Kohonen T. </author> <title> Self Organizing Map, </title> <publisher> Springer Verlag, </publisher> <year> 1995. </year>
Reference-contexts: As its mechanism is simple, it has been widely applied to solve many engineering problems <ref> [1, 6, 7, 14] </ref>. For clarity, we assume that the SOM consists of N neurons. The input to the SOM is denoted by x 2 R n and the weight vectors are denoted by 1 ; 2 ; : : : ; N 2 R n . <p> The neurons are arranged in lattice form. The neighborhood relationship amongst these neurons is defined by the connection matrix G = (g ij ), where g ij = 1 in G means that the ith and jth neurons are neighbor. In Kohonen's definition <ref> [6] </ref>, the set consisting of all the neighborhood neurons of the ith neuron is denoted by N i and is called the ith neighborhood set.
Reference: [7] <author> Kraaijveld M.A. et al., </author> <title> A Nonlinear Projection Method Based on Kohonen's Topology Preserving Maps, </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> Vol.6(3), </volume> <pages> 548-559, </pages> <year> 1995. </year>
Reference-contexts: As its mechanism is simple, it has been widely applied to solve many engineering problems <ref> [1, 6, 7, 14] </ref>. For clarity, we assume that the SOM consists of N neurons. The input to the SOM is denoted by x 2 R n and the weight vectors are denoted by 1 ; 2 ; : : : ; N 2 R n .
Reference: [8] <author> Kushner H.K. and D.S.Clark, </author> <title> Stochastic Approximation for Constrained and Unconstrained Systems, </title> <publisher> Springer Verlag, </publisher> <year> 1978. </year> <title> [9] van der Malsburg C., Development of ocularity domains and growth behavior of axon terminals. </title> <journal> Biological Cybernetics. </journal> <volume> 32, </volume> <pages> 49-62, </pages> <year> 1979. </year>
Reference-contexts: The vector x is the input pattern presented at step t and ff (t) is the step size satisfying the conditions for stochastic approximation (see Theorem 4.3.1 in <ref> [8] </ref>.). The winning neuron c is defined as the one whose weight vector is 2 the closest to the input x, i.e. c = arg min fkx k kg: Two points should be noted from the step (1).
Reference: [10] <author> Nowlan S, </author> <title> Maximum Likelihood Competitive Learning, </title> <booktitle> Advance in Neural Information Processing Systems, </booktitle> <pages> 574-582, </pages> <year> 1990. </year> <title> [11] van Velzen G.A., Topological maps on Ising spin networks, </title> <journal> Physica A, </journal> <volume> 185, </volume> <pages> 439-443, </pages> <year> 1992. </year>
Reference-contexts: Summing &lt; ~ ij &gt; x over i; j, we can obtain the average network coupling energy: E x = ~ i=1 j=1 Inspired by the algorithm of Maximum Likehood Competitive Learning <ref> [10] </ref>, we have C = x = M log ~ + k=1 2 N X N X g ij p i (x k )p j (x k ) 5 : (7) As our objective is to maximize the correlation between neighboring neurons, the network parameters, i.e. i s, should maximize the <p> Furthermore, we have shown that the proposed algorithm can be reduced to van Velzen algorithm [11] and maximum likelihood competitive learning <ref> [10] </ref>. For clarity, the similarities and differences between SOM and the proposed algorithm are summarized in Table 1. As the algorithm proposed by van Velzen is based on the idea of Ising spinning, it is suspected that our algorithm can also be interpreted in the same manner.
Reference: [12] <author> Willshaw D. and C. von der Malsburg, </author> <title> A marker induction for the establishment of order neural mapping: Its application to the retino-tectal problem, </title> <journal> Philosophical Transactions of Royal Society of London, </journal> <volume> 287, B1021, </volume> <pages> 203-243, </pages> <year> 1979. </year>
Reference-contexts: 1 Introduction In the recent decades, many researchers have attempted to mimic the mammalian sensory ordered map, in particular the topography map. Willshaw and van der Malsburg <ref> [12] </ref>, Kohonen [5] and Goodhill [4] have proposed self-organizing algorithms based on the idea of competition. Durbin and Willshaw [2] on the other hand considered the map formation as a process similar to that of elastic string.
Reference: [13] <author> Zemel R. S and G. Hinton, </author> <title> Learning Population Codes by Minimizing Description Length, </title> <journal> Neural Computation, </journal> <volume> 7, </volume> <pages> 549-564, </pages> <year> 1995. </year>
Reference-contexts: By minimizing this Hamiltonian, he derived an algorithm and network model, Ising spin network, to generate a topographic map. Recently, the idea of minimum description length (MDL) has also been applied to define such an algorithm <ref> [13] </ref>. Some of these algorithms can be described as gradient algorithms because they are embedded with well-defined objective functions which not only ease the formulation of the convergence proof but also suggest possible physical interpretations for the algorithms [3]. This paper will be organized into six sections.
Reference: [14] <author> Leung C.S. and L.W.Chan, </author> <title> Kohonen map: Transmission of vector quantization data under noisy channel, </title> <note> Accepted for publication in IEEE Transactions on Neural Networks. </note>
Reference-contexts: As its mechanism is simple, it has been widely applied to solve many engineering problems <ref> [1, 6, 7, 14] </ref>. For clarity, we assume that the SOM consists of N neurons. The input to the SOM is denoted by x 2 R n and the weight vectors are denoted by 1 ; 2 ; : : : ; N 2 R n .
Reference: [15] <author> Duda R. and P. Hart, </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley-Interscience Publication, </publisher> <year> 1973. </year>
Reference-contexts: Thus SOM does not have a physical meaning such as maximum entropy or maximum likelihood, etc, except in the special case that G is an identity matrix. In such case, SOM learning reduces to K-means clustering which objective function is an approximated maximum likelihood function (chapter 6 of <ref> [15] </ref>). 3 From New Interpretation To The New Algorithm Considering the points noted in the above section, it is possible to interpret the topological map formation based on an idea similar to correlation. Imagine that each of the weight vectors is the center of a set of data.
Reference: [16] <author> Erwin E. et al., </author> <title> Self-organizing maps: Ordering, convergence properties and energy functions. </title> <journal> Biological Cybernetics, </journal> <volume> 67, </volume> <pages> 47-55, </pages> <year> 1992. </year> <note> 7 6 6 6 @ @ @ @ @I A A A </note>
Reference-contexts: Second, they move closer to each other. Although the map is able to search for the location of the set of data and self-organize to an ordered map by repeating equation (1), it has been proven that there is no energy function reflecting the mechanism of SOM <ref> [16] </ref>. Thus SOM does not have a physical meaning such as maximum entropy or maximum likelihood, etc, except in the special case that G is an identity matrix.
References-found: 14

