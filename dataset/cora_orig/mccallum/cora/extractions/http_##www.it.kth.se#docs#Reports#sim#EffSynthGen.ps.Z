URL: http://www.it.kth.se/docs/Reports/sim/EffSynthGen.ps.Z
Refering-URL: http://www.it.kth.se/docs/Reports/sim/
Root-URL: http://www.it.kth.se
Title: paged/segmented systems, disk usage and database sys-tems.  
Note: 2. Background  
Abstract: Recently, Thiebaut et al [6] proposed and validated a synthetic generation scheme. The validation of this method shows that the impact of ST on caches is very close to the one that a corresponding real trace would have caused. While this feature makes ST attractive, it remains to see how is their performance compared to secondary-storage based traces. The rest of this paper is or ganized as follows. We provide some background on synthetic trace generation in section 2. In section 3 we evaluate its performance and analyze the obtained results. In section 4 we propose two schemes to generate ST more ef ficiently. In section 5 we present our conclusions. To reduce the time and space requirements during the evaluation of memory systems analytical models have been proposed [6][7][11][12]. Probabilistic models have been used instead of real traces to study multiprocessor caches[13]. ST is a plausible alternative since it is believed that it requires much less space and it is faster to generate them compared to disk based traces. Moreover , it offers the possibility to control program behavior by manipulating a small number of parameters even for non existing architectures. ST can also be used as a replacement for real traces when the set of parameters is extracted from the real trace. Recently, Thiebaut [6] proposed and validated a model that generates traces that behave like real traces. The model is based on the Least Recently Used (LRU) stack model [7] and assumes that the full set of addresses that a program ever accesses is stored in a large LRU stack. A hit index is defined as the position of an item in the LRU stack. Indices to this stack are generated by a hyperbolic marginal probability distribution. When an item is referenced, it is moved to the top of the stack becoming the Abstract Trace-driven simulation is a widely used technique to evaluate memory hierarchies. One problem with this method is that traces require enormous memory space. Synthetic traces (ST) have been proposed as an alternative approach. Research reported in the literature shows that ST behave as real traces, they do not demand secondary storage, and it is claimed that they can quickly generate memory references. We have evaluated the performance of both the traditional trace-driven and the ST approaches. The results show that generation of ST is slower than the traditional one. An analysis of the ST model and its implementation shows that the bottlenecks lie in hyperbolic function computations and updating large LRU stacks. In this paper we focus on reducing the LRU stack update time. We propose a parallel and a lazy updating scheme, and present some performance figures for these methods. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M.A. Holliday, </author> <title> Techniques for Cache and Memory Simulation Using Address Reference Traces, </title> <journal> Int. Journal in Computer Simulation, Vol.1 Nr. </journal> <volume> 2, </volume> <year> 1991. </year>
Reference-contexts: To collect a trace, hardware or software monitors are used. The amount of data to be saved is of the order of hundreds or thousands of megabytes for some minutes of the program execution. This is necessary to produce reliable results <ref> [1] </ref>. Due to the large amount of data to be processed the computer time is also very long. Several techniques have been proposed to reduce the cache simulation time: trace stripping, trace sampling, simulation of several cache configurations in one pass of the trace [2] and parallel simulation [3][4][5].
Reference: [2] <author> H. Stone, </author> <title> High Performance Computer Architecture, </title> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: Due to the large amount of data to be processed the computer time is also very long. Several techniques have been proposed to reduce the cache simulation time: trace stripping, trace sampling, simulation of several cache configurations in one pass of the trace <ref> [2] </ref> and parallel simulation [3][4][5]. Synthetic traces (ST) have been proposed as a plausible alternative to secondary-storage based traces since it is believed that they are faster and do not demand disk space.
Reference: [3] <author> P. Heildelberger, H. Stone, </author> <title> Parallel Trace-Driven Simulation by time Partitioning, </title> <booktitle> Proceedings of the Winter Simulation Conference (1990), </booktitle> <pages> pp. 734-737. </pages>
Reference: [4] <author> D. Nicol, A.G. Greenberg, </author> <title> B.D. Lubachevsky, Massively Parallel Algorithms for Trace-Driven Cache Simulation, </title> <booktitle> Proceedings of the 6th workshop on Parallel and Distributed Simulation (1992) pp. </booktitle> <pages> 3-11. </pages>
Reference: [5] <author> L. Barriga and R. Ayani, </author> <title> Parallel Cache Simulation on Multiprocessor Workstations, </title> <booktitle> Proceeding of the 22nd International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: We compared the performance of ST with an enhanced version of the DineroIII cache simulator that reads traces from local disk <ref> [5] </ref>. Our version of DineroIII differs from the original one in that it reads input traces in binary format, and references are read in disk blocks to reduce crossing the file system and procedure calls for each reference.
Reference: [6] <author> D. Thiebaut, J.L. Wolf, and H. Stone, </author> <title> Synthetic Traces for Trace-Driven Simulation of Cache Memories, </title> <journal> IEEE Transactions on Computers, </journal> <month> (April, </month> <year> 1992), </year> <pages> pp. 388-410 </pages>
Reference-contexts: The index is computed by generating a random number between 0 and 1. Using the inverse transformation for EQ 4, the index is computed. The tag is computed probabilistically as explained in the previous section. As suggested in <ref> [6] </ref> the stack does not need to be as large as the address space size. Since the stack will contain only the unique references its maximum size can be estimated by equation EQ 2. <p> We found that the C library function memcpy () fails to move overlapping blocks of data. bcopy () does the job cleanly though too slowly We implemented this algorithm for generating a trace which according to <ref> [6] </ref> describes the execution of a T urbo Pascal compiler. <p> Summary and conclusions We have evaluated the performance of a synthetic trace generator based on a scheme proposed by Thiebaut et.al <ref> [6] </ref>. A comparative analysis with disk-based traces shows that ST have a very slow generation rate. For a 5 million trace, the synthetic trace generation method is 15 times slower than reading it from disk.
Reference: [7] <author> J. R. Spirn. </author> <title> Program Behavior: Models and Measurements, </title> <booktitle> Operating and Programming system series. </booktitle> <address> New York, </address> <publisher> Elsevier, </publisher> <year> 1976. </year>
Reference: [8] <author> R. Mattson, J. Gecsei, D. Slutz, and I. Traiger, </author> <title> Evaluation Techniques for Storage Hierarchies, </title> <journal> IBM Systems Journal, </journal> <volume> Vol. 9, </volume> <pages> (12(2),1970) pp. 78-117. </pages>
Reference-contexts: Most Recently Used (MRU) reference. Such stack exactly contains the items that a fully associative cache of inf inite size would contain <ref> [8] </ref>. The miss rate at a given distance D in this cache would provide approximately the miss rate for a cache of size D.
Reference: [9] <author> Raj Jain, </author> <title> The Art of Computer Systems Performance Analysis, </title> <publisher> John Wiley & Sons, Inc. </publisher> <year> (1991), </year> <pages> pp. 474-476. </pages>
Reference-contexts: ST showed that they produce miss-ratios and lifetime functions (average distance between two misses) which are close enough to the corresponding real ones. The address generation is done as follows. Using the marginal distribution given by EQ 4, and the inverse transformation <ref> [9] </ref> a stack index i is generated. This number gives the position of a memory reference in an LRU stack (see Figure 1). The size of the LRU stack is equal to the address space size.
Reference: [10] <author> Mark D. Hill, </author> <title> The DineroIII Cache Simulator, </title> <institution> Univ. of Wisconsin, Comp. Sciences Dept. </institution> <year> 1991 </year>
Reference: [11] <author> D. Thiebaut, </author> <title> On the Fractal Dimension of Computer Programs and its application to the Prediction of Cache Miss Ratio, </title> <journal> IEEE Transaction on Computers, </journal> <volume> Vol C-38, </volume> <pages> pp. 1012-1026, </pages> <month> July </month> <year> 1989. </year>
Reference: [12] <author> M. Kobayashi, and M.H. MacDougall, </author> <title> The Stack Growth Function: Cache Line Reference Models, </title> <journal> IEE Transaction on Computers, </journal> <volume> Vol. C-38, </volume> <pages> pp. 798-804, </pages> <month> June </month> <year> 1989. </year>
Reference: [13] <author> J. Lee, and U. Ramachandran, </author> <title> Synchronization with Multiprocessor Caches, </title> <booktitle> 17th Int. Symp. on Computer Architecture, </booktitle> <year> 1990. </year>
References-found: 13

