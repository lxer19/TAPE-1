URL: ftp://ftp.dai.ed.ac.uk/pub/user/chrisg/chrisg_for_public_gp97_small_pops.ps.gz
Refering-URL: http://www.dai.ed.ac.uk/students/chrisg/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fchrisg, peterg@dai.ed.ac.uk  
Phone: +44 (0)131 650-3090  
Title: Small Populations over Many Generations can beat Large Populations over Few Generations in Genetic Programming  
Author: Chris Gathercole and Peter Ross 
Web: http://www.dai.ed.ac.uk/  
Address: CA, USA  80 South Bridge Edinburgh EH1 1HN U.K.  
Affiliation: Stanford University,  Department of Artificial Intelligence University of Edinburgh  
Date: 97, 13-16 July,  
Note: To be presented at Genetic Programming  
Abstract: This paper looks at the use of small populations in Genetic Programming (GP), where the trend in the literature appears to be towards using as large a population as possible, which requires more memory resources and CPU-usage is less efficient. Dynamic Subset Selection (DSS) and Limited Error Fitness (LEF) are two different, adaptive variations of the standard supervised learning method used in GP. This paper compares the performance of GP, GP+DSS, and GP+LEF, on a 958 case classification problem, using a small population size of 50. A similar comparison between GP and GP+DSS is done on a larger and messier 3772 case classification problem. For both problems, GP+DSS with the small population size consistently produces a better answer using fewer tree evaluations than other runs using much larger populations. Even standard GP can be seen to perform well with the much smaller population size, indicating that it is certainly worth an exploratory run or three with a small population size before assuming that a large population size is necessary. It is an interesting notion that smaller can mean faster and better. 
Abstract-found: 1
Intro-found: 1
Reference: [Aha, 1993] <author> David W. Aha. </author> <title> Tic-tac-toe endgame database. The AI CD-ROM, </title> <type> Revision 2, </type> <institution> Network Cybernetics Corporation, </institution> <year> 1993. </year>
Reference-contexts: Taken from <ref> [Aha, 1993] </ref>, the set consists of all legal 3fi3 board configurations (taking into account the board's rotational symmetries) at the end of TicTacToe games (also known as "Noughts and Crosses"), where player `x' is assumed to have played first.
Reference: [Angeline and Pollack, 1993] <author> Peter J. Angeline and Jordan B. Pollack. </author> <title> Competitive environments evolve better solutions for complex tasks. </title> <booktitle> In Proceedings of the 5th International Conference on Genetic Algorithms, ICGA-93, </booktitle> <pages> pages 264-270. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: In [Gathercole and Ross, 1997], very similar dynamics are noted for LEF and Hillis's co-evolving host and parasite populations, [Hillis, 1990]. Other similarities are noted with niches and fitness-sharing, [Rosin and Belew, 1995], and competitive environments, <ref> [Angeline and Pollack, 1993] </ref>, using the population as a `reservoir for comparison'. 5 DSS Algorithm and Parameters Dynamic Subset Selection (DSS), like LEF, has its own fair share of parameters. <p> Dynamic selection of training examples has been shown to be effective for artificial neural networks with backpropagation, using the change in node weights as a guide for selection, [Zhang, 1994]. Co-evolving populations, [Hillis, 1990], and competitive environments, <ref> [Angeline and Pollack, 1993] </ref>, are also fertile areas of study.
Reference: [Daida et al., 1996] <author> Jason M. Daida, Tommaso F. Bersano-Begey, Steven J. Ross, and John F. Vesecky. </author> <title> Computer-assisted design of image classification algorithms: Dynamic and static fitness evaluations in a scaffolded genetic programming environment. </title> <editor> In John R. Koza, David E. Goldberg, David B. Fogel, and Rick L. Riolo, editors, </editor> <booktitle> Genetic Programming 1996: Proceedings of the First Annual Conference, </booktitle> <pages> pages 279-284, </pages> <address> Stanford University, CA, USA, 28-31 July 1996. </address> <publisher> MIT Press. </publisher>
Reference-contexts: Co-evolving populations, [Hillis, 1990], and competitive environments, [Angeline and Pollack, 1993], are also fertile areas of study. In some instances, it is the only possibility of making an extremely large problem tractable, <ref> [Daida et al., 1996] </ref>. 9 Conclusion GP has been shown here to perform well with a small population over many generations, on two different supervised learning classification problems, matching or beating the performance of GP with a much larger population.
Reference: [Gathercole and Ross, 1994a] <author> Chris Gathercole and Peter Ross. </author> <title> Dynamic training subset selection for supervised learning in genetic programming. </title> <editor> In Yuval Davidor, Hans-Paul Schwefel, and Re-inhard Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature III, </booktitle> <pages> pages 312-321, </pages> <address> Berlin, </address> <month> 9-14 October </month> <year> 1994. </year> <note> Springer-Verlag. </note>
Reference-contexts: DSS and LEF, described and used in <ref> [Gathercole and Ross, 1994a] </ref>, and elsewhere in this volume, [Gathercole and Ross, 1997], are both modifications to the standard supervised learning approach used in GP, making more use of the training set and the GP population's changing abilities. <p> The DSS algorithm, described more fully in <ref> [Gathercole and Ross, 1994a] </ref>, involves picking a subset of cases from the full training set Results from looking at the effects of different settings of the PAUSE parameters for LEF (population size = 50, tournament size = 4, maximum 4000 generations) PAUSE Runs Successes % Success Avg Gens Avg Evals Exact <p> The age exponent was kept the same at 3:5. The difficulty exponent, however, was increased from 1:0 to 2:0 to accommodate the smaller population size (and thus lower difficulty values). Unlike the more random subset selection algorithm described in <ref> [Gathercole and Ross, 1994a] </ref>, a version of roulette-wheel selection is used here to ensure that exactly the specified number of cases are selected to be in the subset. <p> 1.1e+08 Population Size = 2000, DSS subset size = 200 GP 0/1 (0%) 94 1.8e+08 Table 4: Comparison of GP, GP with DSS, and GP with LEF, on TicTacToe Problem. 7 Solving the Thyroid problem with a small population The Thyroid problem, a large and messy classification problem, described in <ref> [Gathercole and Ross, 1994a] </ref> and [UCI, 1997], is tackled again in this paper, but using a much smaller population size of 50, as for the TicTacToe problem above. It is near the limit in terms of difficulty and CPU time of what is practical for GP. <p> With a population of size 50, GP+DSS has produced a substantially better result than any of the other GP runs, with or without DSS, for the much larger population sizes of 5000 and 10000 shown in <ref> [Gathercole and Ross, 1994b, Gathercole and Ross, 1994a] </ref>, and one of these runs had already beaten the best test set performance by a Neural Network, reported in [Schiffmann et al., 1992].
Reference: [Gathercole and Ross, 1994b] <author> Chris Gather--cole and Peter Ross. </author> <title> Some training subset selection methods for supervised learning in genetic programming. </title> <booktitle> Presented at ECAI Workshop on Applied Genetic and other Evolutionary Algorithms, </booktitle> <editor> organised by Gusz Eiben, Bernard Manderick, Zsofi Ruttkay, </editor> <year> 1994. </year>
Reference-contexts: For GP in this paper, the function and terminal sets are f AND (both &gt; 0), OR (either &gt; 0), IFGTZ, IFLTZ, IFEQZ, NEGATE g f cornerNW, edgeN, cornerNE, edgeW, centre, edgeE, cornerSW, edgeS, cornerSE g 3 GP parameters Previous GP runs used population sizes of 1000 and 2000, <ref> [Gathercole and Ross, 1994b] </ref>, and took several days each to complete. Some experimental runs indicated that a smaller population size might be effective, and several runs carried out with population sizes ranging from 400 down to 50 demonstrated this to be so. <p> The two biases take the form of exponents which increase the size, i.e. importance, of the difficulty and age values of each case. Initial runs indicated that a subset size of 100, half the size of the one used in <ref> [Gathercole and Ross, 1994b] </ref>, worked well with the population size of 50, and a tournament size of 4. The age exponent was kept the same at 3:5. The difficulty exponent, however, was increased from 1:0 to 2:0 to accommodate the smaller population size (and thus lower difficulty values). <p> able to perform well with many different parameter settings. 6 Comparison of GP, GP+LEF, and GP+DSS on TicTacToe Using the GP, LEF, and DSS parameters established above, the results of fifty runs for each of GP, GP+LEF, and GP+DSS, are presented in Table 4, alongside some of the results from <ref> [Gathercole and Ross, 1994b] </ref> using much larger population sizes. The runs involving populations of size 50 all have the same number of permitted tree evaluations, equivalent to GP over 4000 generations. As can be seen, GP+DSS performs very well, discover ing an optimal tree in all fifty runs. <p> With a population of size 50, GP+DSS has produced a substantially better result than any of the other GP runs, with or without DSS, for the much larger population sizes of 5000 and 10000 shown in <ref> [Gathercole and Ross, 1994b, Gathercole and Ross, 1994a] </ref>, and one of these runs had already beaten the best test set performance by a Neural Network, reported in [Schiffmann et al., 1992].
Reference: [Gathercole and Ross, 1997] <author> Chris Gathercole and Peter Ross. </author> <title> Tackling the boolean even n parity problem with genetic programming and limited-error fitness. </title> <booktitle> In Genetic Programming 1997: Proceedings of the Second Annual Conference, </booktitle> <address> Stanford University, CA, USA, </address> <month> 13-16 July </month> <year> 1997. </year> <note> Elsewhere in this volume. </note>
Reference-contexts: DSS and LEF, described and used in [Gathercole and Ross, 1994a], and elsewhere in this volume, <ref> [Gathercole and Ross, 1997] </ref>, are both modifications to the standard supervised learning approach used in GP, making more use of the training set and the GP population's changing abilities. <p> Assuming all the other GP parameters have reasonably effective values, this completes the brief search for an adequate setup for GP. 4 LEF Algorithm and Parameters The Limited-Error Fitness (LEF) algorithm, described more fully in <ref> [Gathercole and Ross, 1997] </ref>, has extra parameters which need to be set. LEF uses the idea of an error limit. During the evaluation stage, when a GP individual is evaluated on each case in the training set, the evaluations are curtailed if the individual exceeds the error limit. <p> For this paper, the initial error limit was arbitrarily set to 50, but, with hindsight, there should perhaps have been some more effort put into finding a good initial value. In <ref> [Gathercole and Ross, 1997] </ref>, very similar dynamics are noted for LEF and Hillis's co-evolving host and parasite populations, [Hillis, 1990]. <p> There were, however, very few instances of the catastrophic decrease in the best of generation fitness reported in <ref> [Gathercole and Ross, 1997] </ref>. The results for populations sizes of 1000 and 2000 are only reported for individual runs, and are not averaged. They are more to indicate the potential of those population sizes.
Reference: [Hillis, 1990] <author> W. D. Hillis. </author> <title> Co-evolving parasites improve simulated evolution as an optimization procedure. </title> <type> Technical Report TR-1 AE91-1, </type> <institution> Thinking Machines Corporation, </institution> <year> 1990. </year> <note> (Appeared in Physica D42 [1990]: pp. 228-234). </note>
Reference-contexts: For this paper, the initial error limit was arbitrarily set to 50, but, with hindsight, there should perhaps have been some more effort put into finding a good initial value. In [Gathercole and Ross, 1997], very similar dynamics are noted for LEF and Hillis's co-evolving host and parasite populations, <ref> [Hillis, 1990] </ref>. Other similarities are noted with niches and fitness-sharing, [Rosin and Belew, 1995], and competitive environments, [Angeline and Pollack, 1993], using the population as a `reservoir for comparison'. 5 DSS Algorithm and Parameters Dynamic Subset Selection (DSS), like LEF, has its own fair share of parameters. <p> Dynamic selection of training examples has been shown to be effective for artificial neural networks with backpropagation, using the change in node weights as a guide for selection, [Zhang, 1994]. Co-evolving populations, <ref> [Hillis, 1990] </ref>, and competitive environments, [Angeline and Pollack, 1993], are also fertile areas of study.
Reference: [Koza, 1992] <author> J.R. Koza. </author> <title> Genetic Programming: on the Programming of Computers by means of Natural Selection. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction This paper takes a brief and interesting look at the use of small populations with Genetic Programming (GP), where the trend in the literature appears to be towards using as large a population as possible. Certainly this is the recommendation put forward in <ref> [Koza, 1992] </ref>. The rationale behind using large populations is that GP is inefficient, i.e. it produces a low ratio of fit children. For a generation of parents to produce fitter children, a large number of children must be generated.
Reference: [Rosin and Belew, 1995] <author> Christopher D. Rosin and Richard K. Belew. </author> <title> Finding opponents worth beating: Methods for competitive co-evolution. </title> <booktitle> In Proceedings of the 6th International Conference on Genetic Algorithms, </booktitle> <year> 1995. </year>
Reference-contexts: In [Gathercole and Ross, 1997], very similar dynamics are noted for LEF and Hillis's co-evolving host and parasite populations, [Hillis, 1990]. Other similarities are noted with niches and fitness-sharing, <ref> [Rosin and Belew, 1995] </ref>, and competitive environments, [Angeline and Pollack, 1993], using the population as a `reservoir for comparison'. 5 DSS Algorithm and Parameters Dynamic Subset Selection (DSS), like LEF, has its own fair share of parameters.
Reference: [Schiffmann et al., 1992] <author> W. Schiffmann, M. Joost, and R. Werner. </author> <title> Optimization of the backpropagation algorithm for training multilayer perceptrons. </title> <type> Technical Report 15, </type> <institution> University of Koblenz, Institute of Physics, </institution> <year> 1992. </year>
Reference-contexts: than any of the other GP runs, with or without DSS, for the much larger population sizes of 5000 and 10000 shown in [Gathercole and Ross, 1994b, Gathercole and Ross, 1994a], and one of these runs had already beaten the best test set performance by a Neural Network, reported in <ref> [Schiffmann et al., 1992] </ref>. Compared with the poor early performance exhibited by GP during early research done on the Thyroid problem, achieving 99.92% on the training set, and 99.32% on the test set is nothing short of astonishing.
Reference: [Siegel, 1994] <author> Eric V. Siegel. </author> <title> Competitively evolving decision trees against fixed training cases for natural language processing. </title> <editor> In Kenneth E. Kinnear, Jr., editor, </editor> <booktitle> Advances in Genetic Programming, chapter 19. </booktitle> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: This means that more difficult cases will be re-selected more often, but also ensures that all cases will repeatedly selected, allowing their difficulty rating to be updated according to the changing abilities of later generations. Siegel describes a similar algorithm in <ref> [Siegel, 1994] </ref>, but does not make use of the age aspect. The three main DSS parameters are subset size, bias given to difficulty, and bias given to age.
Reference: [UCI, 1997] <author> UCI. </author> <title> Machine Learning Repository. </title> <note> Datasets held at http://www.ics.uci.edu/~mlearn/MLRepository.html, 1997. </note>
Reference-contexts: DSS subset size = 200 GP 0/1 (0%) 94 1.8e+08 Table 4: Comparison of GP, GP with DSS, and GP with LEF, on TicTacToe Problem. 7 Solving the Thyroid problem with a small population The Thyroid problem, a large and messy classification problem, described in [Gathercole and Ross, 1994a] and <ref> [UCI, 1997] </ref>, is tackled again in this paper, but using a much smaller population size of 50, as for the TicTacToe problem above. It is near the limit in terms of difficulty and CPU time of what is practical for GP.
Reference: [Zhang, 1994] <author> Byoung-Tak Zhang. </author> <title> Accelerated learning by active example selection. </title> <journal> International Journal of Neural Systems, </journal> <volume> 5 </volume> <pages> 67-75, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: Dynamic selection of training examples has been shown to be effective for artificial neural networks with backpropagation, using the change in node weights as a guide for selection, <ref> [Zhang, 1994] </ref>. Co-evolving populations, [Hillis, 1990], and competitive environments, [Angeline and Pollack, 1993], are also fertile areas of study.
References-found: 13

