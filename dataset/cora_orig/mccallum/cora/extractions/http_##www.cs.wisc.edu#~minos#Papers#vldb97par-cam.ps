URL: http://www.cs.wisc.edu/~minos/Papers/vldb97par-cam.ps
Refering-URL: 
Root-URL: 
Email: minos@cs.wisc.edu  yannis@cs.wisc.edu  
Title: Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources  
Author: Minos N. Garofalakis Yannis E. Ioannidis 
Affiliation: University of Wisconsin-Madison  University of Wisconsin-Madison  
Abstract: Scheduling query execution plans is a particularly complex problem in hierarchical parallel systems, where each site consists of a collection of local time-shared (e.g., CPU(s) or disk(s)) and space-shared (e.g., memory) resources and communicates with remote sites by message-passing. We develop a general approach to the problem, capturing the full complexity of scheduling distributed multi-dimensional resource units for all kinds of parallelism within and across queries and operators. We present heuristic algorithms for various forms of the problem, some of which are provably near-optimal. Preliminary experimental results confirm the effectiveness of our approach. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C.K. Baru, G. Fecteau, A. Goyal, H. Hsiao, A. Jhingran, S. Padman abhan, </author> <title> G.P. Copeland, and W.G. Wilson. DB2 Parallel Edition. </title> <journal> IBM Systems Journal, </journal> <volume> 34(2) </volume> <pages> 292-322, </pages> <year> 1995. </year>
Reference-contexts: Startup is added to the work components of only one of these sites, the coordinator for the parallel execution. EA2. Uniform TS Resource Overlapping: The amount of over lap achieved between processing at different TS resources at a site can be characterized by a single system-wide parameter* 2 <ref> [0; 1] </ref> for all query operators. This parameter allows us to express the response time of a work vector as a convex combination of the maximum and the sum of its components, i.e., T seq (W ) = * max 1id fW [i]g + (1*) i=1 W [i]. <p> Prior work has demonstrated that a two-phase approach [17] using the traditional work (i.e., resource consumption) metric during the plan generation phase often results in plans that are inherently sequential and, consequently, unable to exploit the available parallelism <ref> [1] </ref>. On the other hand, using a detailed resource scheduling model during plan generation (as advocated by the one-phase approach [19, 23]) can have a tremendous impact on optimizer complexity and optimization cost.
Reference: [2] <author> L. Bouganim, D. Florescu, and P. Valduriez. </author> <title> Dynamic Load Balanc ing in Hierarchical Parallel Database Systems. </title> <booktitle> In Proc. of the 22nd Intl. VLDB Conf., </booktitle> <month> September </month> <year> 1996. </year>
Reference-contexts: 1 Introduction In the shared-nothing [7] and the more general hierarchical (or, hybrid) <ref> [2] </ref> multiprocessor architectures, each site consists of its own set of local resources and communicates with other sites only by message-passing. <p> For an extensive bibliography, the interested reader is referred to the full version of the paper [12]. 2 Problem Formulation 2.1 Definitions We consider hierarchical parallel systems <ref> [2] </ref> with identical mul-tiprogrammed resource sites connected by an interconnection network. Each site is a collection of d TS resources (e.g., CPU (s), disk (s), and network interface (s) or communication processor (s)) and s SS resources (e.g., memory).
Reference: [3] <author> S. Chakrabarti and S. Muthukrishnan. </author> <title> Resource Scheduling for Par allel Database and Scientific Applications. </title> <booktitle> In Proc. of the 8th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <month> June </month> <year> 1996. </year>
Reference-contexts: Given an operator clone with a (stand-alone) execution time of T and a SS demand of V , we define the volume vector of the clone as the product T V , i.e., the resource-time product 2 for the clone's execution <ref> [3] </ref>. S W V T V are used to denote the set of work, demand, and volume vectors (respectively) for the set S of all the clones to be scheduled. We use the W , V , and T V superscripts in this manner throughout the paper.
Reference: [4] <author> E.G. Coffman, Jr., M.R. Garey, and D.S. Johnson. </author> <title> Approximation Algorithms for Bin-Packing An Updated Survey. In Algorithm Design for Computing System Design, </title> <publisher> Springer-Verlag, </publisher> <address> NY, </address> <year> 1984. </year>
Reference-contexts: We will see that this new parameter plays an important role in our analytical and experimental results. The basic idea of our heuristic scheduling algorithm, termed OPSCHED, is to construct the partition of clones into compatible subsets incrementally, using a Next-Fit rule <ref> [4, 5] </ref>. Specifically, OPSCHED scans the list of clones in non-increasing order of execution time. At each step, the clone selected is placed in the site B i of minimal height T site (B i ) (see Equation (1)). This placement is done as follows. <p> Given a collection of operator clones in a pipeline, the schedulability question poses an N P-hard decision problem that essentially corresponds to the decision problem of s-dimensional vector packing <ref> [4] </ref>. Thus, it is highly unlikely that efficient (i.e., polynomial time) necessary and sufficient conditions for pipeline schedulability exist. Note that no such problems were raised in the previous section, since the clones were executing independently of each other.
Reference: [5] <author> E.G. Coffman, Jr., M.R. Garey, D.S. Johnson, and R.E. Tarjan. </author> <title> Per formance Bounds for Level-Oriented Two-Dimensional Packing Algorithms. </title> <journal> SIAM Journal on Computing, </journal> <volume> 9(4) </volume> <pages> 808-826, </pages> <year> 1980. </year>
Reference-contexts: We develop a fast resource scheduling algorithm for operator pipelines called PIPESCHED that belongs to the class of list scheduling algorithms [14]. We then extend our approach to multiple independent pipelines, using a level-based (or, shelf-based) scheduling algorithm <ref> [5, 24] </ref> that treats PIPESCHED as a subroutine within each level. The resulting algorithm, termed LEVELSCHED, is analytically shown to be near-optimal for given degrees of operator parallelism. <p> We will see that this new parameter plays an important role in our analytical and experimental results. The basic idea of our heuristic scheduling algorithm, termed OPSCHED, is to construct the partition of clones into compatible subsets incrementally, using a Next-Fit rule <ref> [4, 5] </ref>. Specifically, OPSCHED scans the list of clones in non-increasing order of execution time. At each step, the clone selected is placed in the site B i of minimal height T site (B i ) (see Equation (1)). This placement is done as follows. <p> Our algorithm for scheduling multiple independent pipelines uses a Next-Fit Decreasing Height (NFDH) policy <ref> [5] </ref> in conjunction with Lemma 4.1 to identify pipelines that can be scheduled to execute concurrently on P sites (i.e., in one layer of execution). PIPESCHED is then used for determining the execution schedule within each layer. The overall algorithm, LEVELSCHED, is formally outlined in Figure 5.
Reference: [6] <author> D. J. DeWitt, S. Ghandeharizadeh, D. A. Schneider, A. Bricker, H.-I Hsiao, and R. Rasmussen. </author> <title> The Gamma Database Machine Project. </title> <journal> IEEE Trans. on Knowledge and Data Engineering, </journal> <volume> 2(1) </volume> <pages> 44-62, </pages> <year> 1990. </year>
Reference-contexts: in our future work. 3.2 Quantifying the Granularity of Parallel Execution As is well known, increasing the parallelism of an operator reduces its execution time until a saturation point is reached, beyond which additional parallelism causes a speed-down, due to excessive communication startup and coordination overhead over too many sites <ref> [6] </ref>. To avoid operating beyond that point, we want to ensure that the granules of the parallel execution are sufficiently coarse [8, 11]. <p> Finally, we estimate the communication area W c (op; N ) using a simple linear model of communication costs that has been adopted in previous studies of shared-nothing architectures [11, 26] and validated on the Gamma research prototype <ref> [6] </ref>. Specifically, if D is the total size of the operator's input and output transferred over the interconnect, then W c (op; N ) = ff N + fi D, where ff and fi are architecture-specific parameters [11].
Reference: [7] <author> D. J. DeWitt and J. Gray. </author> <title> Parallel Database Systems: The Future of High Performance Database Database Systems. </title> <journal> Comm. of the ACM, </journal> <volume> 35(6) </volume> <pages> 85-98, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction In the shared-nothing <ref> [7] </ref> and the more general hierarchical (or, hybrid) [2] multiprocessor architectures, each site consists of its own set of local resources and communicates with other sites only by message-passing. <p> Finally, we discuss the implications of our results for the open problem of designing efficient cost models for parallel query optimization <ref> [7] </ref>. 1 Due to space constraints, we do not discuss the details of earlier work.
Reference: [8] <author> S. Ganguly, A. Goel, and A. Silberschatz. </author> <title> Efficient and Accurate Cost Models for Parallel Query Optimization. </title> <booktitle> In Proc. of the 15th ACM PODS Symp., </booktitle> <month> June </month> <year> 1996. </year>
Reference-contexts: Given a query execution plan, our goal is to find a parallel schedule with minimal response time. Accounting for both TS and SS resource dimensions, our scheduling framework gives rise to interesting tradeoffs with respect to the degree of partitioned parallelism. Coarse grain operator parallelizations <ref> [8, 10, 11] </ref> are desirable since they typically result in reduced communication overhead and effective parallel executions with respect to TS resource use. <p> To avoid operating beyond that point, we want to ensure that the granules of the parallel execution are sufficiently coarse <ref> [8, 11] </ref>. <p> The goal is to devise cost metrics that are more realistic than resource consumption, in the sense that they are cognizant of the available parallelism, and at the same time are sufficiently efficient to keep the optimization process tractable. In recent work, Ganguly et al. <ref> [8] </ref> suggested the use of a novel scalar cost metric for parallel query optimization. Their metric was defined as the maximum of two bulk parameters of a parallel query plan, namely the critical path length of the plan tree and the aver age work per site. <p> Consequently, we feel that these three components can provide the basis for an efficient and accurate cost model for parallel query optimiz-ers. Finally, note that although Ganguly et al. <ref> [8] </ref> suggested combining the plan parameters through a maxfg function to produce a scalar metric, the way these parameters are used should depend on the optimization strategy.
Reference: [9] <author> S. Ganguly, W. Hasan, and R. Krishnamurthy. </author> <title> Query Optimization for Parallel Execution. </title> <booktitle> In Proc. of the 1992 ACM SIGMOD Intl. Conf., </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: Despite the popularity of these architectures, the development of effective and efficient query processing and optimization techniques to exploit their full potential still remains an issue of concern <ref> [9, 25] </ref>. Prior work has already demonstrated the importance of resource scheduling during parallel query optimization. One of the main sources of complexity for the problem is the multidimensionality of the resource needs of database queries. <p> To copy otherwise, or to republish, requires a fee and/or special permission from the Endowment. Proceedings of the 23rd VLDB Conference Athens, Greece, 1997 * Time-Shared (TS) (or, preemptable) resources (e.g., CPUs, disks, network interfaces), that can be sliced between operators at very low overhead <ref> [9, 11] </ref>. For such resources, operators specify an amount of work (i.e., the effective time for which the resource is used) that can be stretched over the operator's execution time. * Space-Shared (SS) resources (e.g., memory buffers), whose time-sharing among operators introduces prohibitively high overheads [9]. <p> For such resources, operators specify an amount of work (i.e., the effective time for which the resource is used) that can be stretched over the operator's execution time. * Space-Shared (SS) resources (e.g., memory buffers), whose time-sharing among operators introduces prohibitively high overheads <ref> [9] </ref>. For such resources, operators typically specify rigid capacity requirements that must be satisfied throughout their execution. Most previous work on parallel query scheduling has ignored the multi-dimensional nature of database queries and has concentrated on simplified models of SS resources, resulting in unrealistic approaches to the problem. <p> An obvious advantage of this general formulation is that it allows us the flexibility to draw the line between TS and SS resources at any boundary, depending on factors such as application requirements or user view of resources. An operator tree <ref> [9, 17] </ref> is created as a macro-expansion of an execution plan tree by refining each node into a subtree of physical operator nodes, e.g., scan, probe, build (Figure 1 (a,b)). <p> Further, it can be readily used to handle on-line task arrivals (e.g., in a dynamic or multi-query execution environment). 2.3 Assumptions Our approach is based on the following set of assumptions: A1. No Time-Sharing Overhead for TS Resources. Follow ing Ganguly et al. <ref> [9] </ref>, slicing a preemptable resource among multiple operators introduces no additional resource costs. A2. Uniform TS Resource Usage. Following Ganguly et al. [9], usage of a preemptable resource by an operator is uniformly spread over the execution of the operator. A3. Constant SS Resource Demand. <p> No Time-Sharing Overhead for TS Resources. Follow ing Ganguly et al. <ref> [9] </ref>, slicing a preemptable resource among multiple operators introduces no additional resource costs. A2. Uniform TS Resource Usage. Following Ganguly et al. [9], usage of a preemptable resource by an operator is uniformly spread over the execution of the operator. A3. Constant SS Resource Demand. The total SS requirements of an operator are constant and independent of its degree of parallelism. <p> attributes of pipelined joins are different, the degrees of partitioned parallelism differ, or different declustering schemes must be used for load balancing. 3 Quantifying Partitioned Parallelism 3.1 A Resource Usage Model Our treatment of TS resource usage is based on the model of pre-emptable resources proposed by Ganguly et al. <ref> [9] </ref>, which we briefly describe here. <p> Although this abstraction can model the true utilization of a system resource, it does not allow us to predict exactly when the busy periods are. Thus, we make assumption A2 which, in conjunction with assumption A1, leads to straightforward quantification of the effects of resource sharing <ref> [9] </ref>. In our previous work [11], we presented a multi-dimensional version of the model of Ganguly et al. [9] that can quantify the effects of sharing sites with TS resources among query operators. <p> Thus, we make assumption A2 which, in conjunction with assumption A1, leads to straightforward quantification of the effects of resource sharing <ref> [9] </ref>. In our previous work [11], we presented a multi-dimensional version of the model of Ganguly et al. [9] that can quantify the effects of sharing sites with TS resources among query operators. <p> of d TS resources and s SS resources by the triple (T seq ; W ; V ), where: * T is the (stand-alone) sequential execution time of the operator, * W is a d-dimensional work vector whose componentsdenote the work done on individual TS resources, i.e., the effective time <ref> [9, 11] </ref> for which each resource is used by the operator; and * V is an s-dimensional demand vector whose components de note the SS resource requirements of the operator throughout its execution. <p> extensions account for all forms of parallelism and quantify the effects of sharing TS and SS resources on the response time of a parallel execution. 4.2.1 Partitioned and Independent Parallelism In partitioned parallelism, the work and demand vectors of an operator are partitioned among a collection of independent operator clones <ref> [9] </ref>. Each clone executes on a single site and works on a portion of the operator's data. The partitioning of W op i and V op i into work and demand vectors for operator clones is determined based on statistical information kept in the DBMS catalogs. <p> For example, a Dynamic Programming (DP) algorithm must use much stricter pruning criteria that account for the use of system resources <ref> [9, 19] </ref>. This leads to a combinatorial explosion in the state that must be maintained while building the DP tree, rendering the algorithm impractical even for small query sizes. The role of the optimizer cost model is to provide an abstraction of the underlying execution system. <p> For example, a DP-based parallel optimizer should use our three bulk parameters as a 3-dimensional vector and use a 3-dimensional less than to prune the search space <ref> [9] </ref>. Clearly, using only three dimensions turns the Partial Order DP (PODP) approach of Ganguly et al. [9] into a feasible and efficient paradigm for DP-based parallel query optimization. 7 Conclusions The problem of scheduling complex queries in hierarchical parallel database systems of multiple time-shared and space-shared resources has been open <p> For example, a DP-based parallel optimizer should use our three bulk parameters as a 3-dimensional vector and use a 3-dimensional less than to prune the search space <ref> [9] </ref>. Clearly, using only three dimensions turns the Partial Order DP (PODP) approach of Ganguly et al. [9] into a feasible and efficient paradigm for DP-based parallel query optimization. 7 Conclusions The problem of scheduling complex queries in hierarchical parallel database systems of multiple time-shared and space-shared resources has been open for a long time both within the database field and the deterministic scheduling theory field.
Reference: [10] <author> S. Ganguly and W. Wang. </author> <title> Optimizing Queries for Coarse Grain Par allelism. </title> <type> Tech. Report LCSR-TR-218, </type> <institution> Dept. of Computer Sciences, Rutgers University, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: Given a query execution plan, our goal is to find a parallel schedule with minimal response time. Accounting for both TS and SS resource dimensions, our scheduling framework gives rise to interesting tradeoffs with respect to the degree of partitioned parallelism. Coarse grain operator parallelizations <ref> [8, 10, 11] </ref> are desirable since they typically result in reduced communication overhead and effective parallel executions with respect to TS resource use. <p> ratio W p (op) W c (op;N) and V (op; N ), where * W p (op) denotes the total amount of work performed during the execution of op on a single site, when all its operands are locally resident (i.e., zero communication cost); it corresponds to the processing area <ref> [10] </ref> of op and is constant for all possible executions of op; * W c (op; N ) denotes the total communication overhead in curred when the execution of op is partitioned among N clones; it corresponds to the communication area of the partitioned execution of op and is a non-decreasing <p> The work vector components for the CPU and the disk were estimated using the cost model equations given by Hsiao et al. [18]. The communication costs were calculated using the model described in Section 3. The values of the cost model parameters were obtained from the literature <ref> [18, 10, 26] </ref> and are summarized in Table 5.1.
Reference: [11] <author> M. N. Garofalakis and Y. E. Ioannidis. </author> <title> Multi-dimensional Resource Scheduling for Parallel Queries. </title> <booktitle> In Proc. of the 1996 ACM SIGMOD Intl. Conf., </booktitle> <month> June </month> <year> 1996. </year>
Reference-contexts: To copy otherwise, or to republish, requires a fee and/or special permission from the Endowment. Proceedings of the 23rd VLDB Conference Athens, Greece, 1997 * Time-Shared (TS) (or, preemptable) resources (e.g., CPUs, disks, network interfaces), that can be sliced between operators at very low overhead <ref> [9, 11] </ref>. For such resources, operators specify an amount of work (i.e., the effective time for which the resource is used) that can be stretched over the operator's execution time. * Space-Shared (SS) resources (e.g., memory buffers), whose time-sharing among operators introduces prohibitively high overheads [9]. <p> Most previous work on parallel query scheduling has ignored the multi-dimensional nature of database queries and has concentrated on simplified models of SS resources, resulting in unrealistic approaches to the problem. Similar limitations exist in previous efforts within the field of deterministic scheduling theory. 1 In our earlier work <ref> [11] </ref>, we have presented a multidimensional framework for query scheduling in shared-nothing parallel systems with only TS resources, dealing with the full variety of bushy plans and schedules that incorporate independent and pipelined forms of inter-operation parallelism as well as intra-operation (i.e., partitioned) parallelism. <p> Given a query execution plan, our goal is to find a parallel schedule with minimal response time. Accounting for both TS and SS resource dimensions, our scheduling framework gives rise to interesting tradeoffs with respect to the degree of partitioned parallelism. Coarse grain operator parallelizations <ref> [8, 10, 11] </ref> are desirable since they typically result in reduced communication overhead and effective parallel executions with respect to TS resource use. <p> Thus, we make assumption A2 which, in conjunction with assumption A1, leads to straightforward quantification of the effects of resource sharing [9]. In our previous work <ref> [11] </ref>, we presented a multi-dimensional version of the model of Ganguly et al. [9] that can quantify the effects of sharing sites with TS resources among query operators. <p> of d TS resources and s SS resources by the triple (T seq ; W ; V ), where: * T is the (stand-alone) sequential execution time of the operator, * W is a d-dimensional work vector whose componentsdenote the work done on individual TS resources, i.e., the effective time <ref> [9, 11] </ref> for which each resource is used by the operator; and * V is an s-dimensional demand vector whose components de note the SS resource requirements of the operator throughout its execution. <p> Time T seq is actually a function of the operator's individual resource requirements, i.e., its work vector W (sometimes emphasized by using T seq (W ) instead of T seq ), and the amount of overlap that can be achieved between processing at different resources <ref> [11] </ref>. This overlap is a system parameter that depends on the hardware and software architecture of the resource sites (e.g., buffering architecture for disk I/O) as well as the algorithm implementing the operator. <p> To avoid operating beyond that point, we want to ensure that the granules of the parallel execution are sufficiently coarse <ref> [8, 11] </ref>. <p> Definition 3.1 A parallel execution of an operator op with degree of partitioned parallelism equal to N is -granular if V (op; N ) , where 1. The following quantification of coarse grain parallelism extends our earlier formulation <ref> [11] </ref>. <p> Finally, we estimate the communication area W c (op; N ) using a simple linear model of communication costs that has been adopted in previous studies of shared-nothing architectures <ref> [11, 26] </ref> and validated on the Gamma research prototype [6]. Specifically, if D is the total size of the operator's input and output transferred over the interconnect, then W c (op; N ) = ff N + fi D, where ff and fi are architecture-specific parameters [11]. <p> Specifically, if D is the total size of the operator's input and output transferred over the interconnect, then W c (op; N ) = ff N + fi D, where ff and fi are architecture-specific parameters <ref> [11] </ref>. The following proposition is an immediate consequence of Definition 3.3 and our communication cost model. <p> Specifically, under our model of preemptable resources described in Section 3.1, the execution time for all the operator clones in S i is defined as <ref> [11] </ref> T (S i ) = max max i seq W ) Thus, if we let S (B j ) denote the collection of compatible subsets mapped to site B j under a given schedule SCHED, the execution time for B j is T site (B j ) = S i <p> The details can be found in the full version of this paper [12]. Compared to our earlier results <ref> [11] </ref>, the lower bound in Theorem 4.1 introduces a third term containing l (S T V ), i.e., the total volume of the parallel execution. We will see that this new parameter plays an important role in our analytical and experimental results. <p> Thus, our layer-based approach provides a uniform scheduling framework for handling intra-query as well as inter-query parallelism. As we have already indicated in our earlier work <ref> [11] </ref>, deriving performance bounds in the presence of data dependencies is a very difficult problem that continues to elude our efforts. The difficulty stems from the interdependencies between different execution layers: scheduling decisions made at earlier layers can impose data placement and operator execution constraints on the layers that follow. <p> Experiments were conducted with various combinations of values for the , f , and * parameters. Since the effects of f and * on scheduler performance were also studied in our prior work <ref> [11] </ref>, the discussion in this paper mostly concentrates on the new parameter . (The results presented in the next section are indicative of the results obtained for all values of f , *.) In all experiments, we assumed system nodes consisting of d = 3 TS resources (one CPU, one disk <p> Note that our algorithm is consistently within a small constant factor (i.e., less than 2) of the lower bound on the optimal schedule length. Although the distance from the lower bound has certainly increased compared to our results for only TS resources <ref> [11] </ref>, the results clearly demonstrate that the worst-case multiplicative factors derived in our analytical bounds are overly pessimistic as far as average performance is concerned. Observing Figure 6 (a), it appears that TREESCHED performs better for larger values of the memory granularity parameter .
Reference: [12] <author> M. N. Garofalakis and Y. E. Ioannidis. </author> <title> Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources. </title> <type> Unpublished manuscript, </type> <month> June </month> <year> 1997. </year>
Reference-contexts: For an extensive bibliography, the interested reader is referred to the full version of the paper <ref> [12] </ref>. 2 Problem Formulation 2.1 Definitions We consider hierarchical parallel systems [2] with identical mul-tiprogrammed resource sites connected by an interconnection network. Each site is a collection of d TS resources (e.g., CPU (s), disk (s), and network interface (s) or communication processor (s)) and s SS resources (e.g., memory). <p> The details can be found in the full version of this paper <ref> [12] </ref>. Compared to our earlier results [11], the lower bound in Theorem 4.1 introduces a third term containing l (S T V ), i.e., the total volume of the parallel execution. We will see that this new parameter plays an important role in our analytical and experimental results. <p> Due to space constraints, we only discuss our results for TREESCHED and refer the interested reader to the full paper <ref> [12] </ref> for more details. Some additional assumptions were made to obtain a specific experimental model from the general parallel execution model described in Sections 3 and 4. These are briefly summarized below: EA1.
Reference: [13] <author> G. Graefe. </author> <title> Query Evaluation Techniques for Large Databases. </title> <journal> ACM Comp. Surveys, </journal> <volume> 25(2) </volume> <pages> 73-170, </pages> <year> 1993. </year>
Reference-contexts: The problems with load-balancing a pipelined execution have been identified in previous work <ref> [13] </ref>. Compared to our model of a schedule for partitioned and independent parallelism (Definition 4.1), pipelined execution constrains the placement and execution of compatible clone subsets to ensure that all the clones in a pipe run concurrently they all start and terminate at the same time [16].
Reference: [14] <author> R.L. Graham. </author> <title> Bounds on Multiprocessing Timing Anomalies. </title> <journal> SIAM Journal on Computing, </journal> <volume> 17(2) </volume> <pages> 416-429, </pages> <year> 1969. </year>
Reference-contexts: We develop a fast resource scheduling algorithm for operator pipelines called PIPESCHED that belongs to the class of list scheduling algorithms <ref> [14] </ref>. We then extend our approach to multiple independent pipelines, using a level-based (or, shelf-based) scheduling algorithm [5, 24] that treats PIPESCHED as a subroutine within each level. The resulting algorithm, termed LEVELSCHED, is analytically shown to be near-optimal for given degrees of operator parallelism. <p> The performance ratio of a scheduling algorithm is defined as the ratio of the response time of the schedule it generates over that of the optimal schedule. All the scheduling problems addressed in this paper are non-trivial generalizations of traditional multiprocessor scheduling <ref> [14] </ref> and, thus, they are clearly N P-hard. Given the intractability of the problems, we develop polynomial time heuristics that are provably near-optimal, i.e., with a constant bound on the performance ratio. <p> We then demonstrate that a heuristic based on Graham's LPT (Largest Processing Time) list scheduling method <ref> [14] </ref> can guarantee near-optimal schedules for such operators. Theorem 4.1 Let fop i ; i = 1; : : : M g be independent operators with respective degrees of partitioned parallelism N = (N 1 ; N 2 ; : : : ; N M ). <p> The following lemma provides a sufficient condition for schedulability. Lemma 4.1 The number of sites required to schedule a -granular pipeline C is always less than or equal to l (S C ) s=(1 ). Our heuristic, PIPESCHED, belongs to the family of list scheduling algorithms <ref> [14] </ref>. PIPESCHED assumes that it is given a number of sites P C that is sufficient for the scheduling of C, according to the condition of Lemma 4.1. The algorithm considers the clones in S C in non-increasing order of their work density ratio l (W i ) .
Reference: [15] <author> W. Hasan, D. Florescu, and P. Valduriez. </author> <title> Open Issues in Parallel Query Optimization. </title> <journal> ACM SIGMOD Record, </journal> <volume> 25(3) </volume> <pages> 28-33, </pages> <year> 1996. </year>
Reference-contexts: The importance of such work-space tradeoffs for parallel query processing and optimization has been stressed in recent work <ref> [15] </ref>. 4.4.2 Scheduling Multiple Independent Pipelines The basic observation here is that the PIPESCHED algorithm presented in the previous section can be used to schedule any collection of independent pipelines as long as schedulability is guaranteed by Lemma 4.1.
Reference: [16] <author> W. Hasan and R. Motwani. </author> <title> Optimization Algorithms for Exploiting the Parallelism-Communication Tradeoff in Pipelined Parallelism. </title> <booktitle> In Proc. of the 20th Intl. VLDB Conf., </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: Compared to our model of a schedule for partitioned and independent parallelism (Definition 4.1), pipelined execution constrains the placement and execution of compatible clone subsets to ensure that all the clones in a pipe run concurrently they all start and terminate at the same time <ref> [16] </ref>. This means that it is no longer possible to schedule resources at one site independent of the others, as we suggested in the previous section. Compatible subsets containing clones from the same pipeline must run concurrently.
Reference: [17] <author> W. Hong. </author> <title> Exploiting Inter-Operation Parallelism in XPRS. </title> <booktitle> In Proc. of the 1992 ACM SIGMOD Intl. Conf., </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: An obvious advantage of this general formulation is that it allows us the flexibility to draw the line between TS and SS resources at any boundary, depending on factors such as application requirements or user view of resources. An operator tree <ref> [9, 17] </ref> is created as a macro-expansion of an execution plan tree by refining each node into a subtree of physical operator nodes, e.g., scan, probe, build (Figure 1 (a,b)). <p> This choice of metric implies that a parallel query optimizer cannot afford to ignore resource scheduling during the optimization process. Prior work has demonstrated that a two-phase approach <ref> [17] </ref> using the traditional work (i.e., resource consumption) metric during the plan generation phase often results in plans that are inherently sequential and, consequently, unable to exploit the available parallelism [1].
Reference: [18] <author> H.-I Hsiao, M.-S. Chen, and P. S. Yu. </author> <title> On Parallel Execution of Mul tiple Pipelined Hash Joins. </title> <booktitle> In Proc. of the 1994 ACM SIGMOD Intl. Conf., </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: We have devised an algorithm for scheduling bushy execution plan trees that consists of the following steps: 1. Construct the corresponding operator and task trees, and for each operator, determine its individual resource requirements using hardware parameters, DBMS statistics, and conventional optimizer cost models (e.g., <ref> [18, 21] </ref>). 2. For each floating operator, determine the degree of paral lelism based on the TS vs. SS resource tradeoffs discussed above (partitioned parallelism). 3. Place the tasks corresponding to the leaf nodes of the task tree in the ready list L of the scheduler. <p> The work vector components for the CPU and the disk were estimated using the cost model equations given by Hsiao et al. <ref> [18] </ref>. The communication costs were calculated using the model described in Section 3. The values of the cost model parameters were obtained from the literature [18, 10, 26] and are summarized in Table 5.1. <p> The work vector components for the CPU and the disk were estimated using the cost model equations given by Hsiao et al. [18]. The communication costs were calculated using the model described in Section 3. The values of the cost model parameters were obtained from the literature <ref> [18, 10, 26] </ref> and are summarized in Table 5.1.
Reference: [19] <author> R. S.G. Lanzelotte, P. Valduriez, and M. </author> <title> Za it. On the Effectiveness of Optimization Search Strategies for Parallel Execution Spaces. </title> <booktitle> In Proc. of the 19th Intl. VLDB Conf., </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: On the other hand, using a detailed resource scheduling model during plan generation (as advocated by the one-phase approach <ref> [19, 23] </ref>) can have a tremendous impact on optimizer complexity and optimization cost. For example, a Dynamic Programming (DP) algorithm must use much stricter pruning criteria that account for the use of system resources [9, 19]. <p> For example, a Dynamic Programming (DP) algorithm must use much stricter pruning criteria that account for the use of system resources <ref> [9, 19] </ref>. This leads to a combinatorial explosion in the state that must be maintained while building the DP tree, rendering the algorithm impractical even for small query sizes. The role of the optimizer cost model is to provide an abstraction of the underlying execution system.
Reference: [20] <author> V. Poosala and Y. E. Ioannidis. </author> <title> Estimation of Query-Result Distri bution and its Application in Parallel-Join Load Balancing. </title> <booktitle> In Proc. of the 22nd Intl. VLDB Conf., </booktitle> <month> September </month> <year> 1996. </year>
Reference-contexts: Similarly, the SS grain size V (op; N ) can be estimated using traditional optimizer cost models and statistics kept in the database catalogs <ref> [20] </ref>. Finally, we estimate the communication area W c (op; N ) using a simple linear model of communication costs that has been adopted in previous studies of shared-nothing architectures [11, 26] and validated on the Gamma research prototype [6].
Reference: [21] <author> P. Selinger, M.M. Astrahan, D.D. Chamberlin, R.A. Lorie, and T.G. Price. </author> <title> Access Path Selection in a Relational Database Management System. </title> <booktitle> In Proc. of the 1979 ACM SIGMOD Intl. Conf., </booktitle> <month> June </month> <year> 1979. </year>
Reference-contexts: We have devised an algorithm for scheduling bushy execution plan trees that consists of the following steps: 1. Construct the corresponding operator and task trees, and for each operator, determine its individual resource requirements using hardware parameters, DBMS statistics, and conventional optimizer cost models (e.g., <ref> [18, 21] </ref>). 2. For each floating operator, determine the degree of paral lelism based on the TS vs. SS resource tradeoffs discussed above (partitioned parallelism). 3. Place the tasks corresponding to the leaf nodes of the task tree in the ready list L of the scheduler. <p> in Figure 3. 0 0 3.3 Degree of Partitioned Parallelism Assuming zero communication costs, the TS and SS resource requirements of an operator are described by a d-dimensional work vector W and an s-dimensional demand vector V whose components can be derived from system parameters and traditional optimizer cost models <ref> [21] </ref>. By definition, the processing area of the operator W p (op) is simply the sum of W 's components, i.e., W p (op) = i=1 W [i].
Reference: [22] <author> L. D. Shapiro. </author> <title> Join Processing in Database Systems with Large Main Memories. </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 11(3) </volume> <pages> 239-264, </pages> <year> 1986. </year>
Reference-contexts: EA3. Simple Hash-Join Plan Nodes: The query plan consists of hash-join nodes, where the memory demand for each join equals the size of the inner relation times a fudge factor accounting for the hash table overhead. Note that although it is possible to execute a hash-join with less memory <ref> [22] </ref>, such memory limitations complicate the processing of multi-join pipelines since probe operators cannot keep their entire data sets (i.e., inner hash tables) in memory, it is no longer possible to execute the probe pipeline in one pass.
Reference: [23] <author> J. Srivastava and G. Elsesser. </author> <title> Optimizing Multi-Join Queries in Par allel Relational Databases. </title> <booktitle> In Proc. of the 2nd Intl. Conf. on Parallel and Distributed Information Systems, </booktitle> <month> January </month> <year> 1993. </year>
Reference-contexts: On the other hand, using a detailed resource scheduling model during plan generation (as advocated by the one-phase approach <ref> [19, 23] </ref>) can have a tremendous impact on optimizer complexity and optimization cost. For example, a Dynamic Programming (DP) algorithm must use much stricter pruning criteria that account for the use of system resources [9, 19].
Reference: [24] <author> J. Turek, J. L. Wolf, K. R. Pattipati, and P. S. Yu. </author> <title> Scheduling Paral lelizable Tasks: Putting it All on the Shelf. </title> <booktitle> In Proc. of the 1992 ACM SIGMETRICS Conf., </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: We develop a fast resource scheduling algorithm for operator pipelines called PIPESCHED that belongs to the class of list scheduling algorithms [14]. We then extend our approach to multiple independent pipelines, using a level-based (or, shelf-based) scheduling algorithm <ref> [5, 24] </ref> that treats PIPESCHED as a subroutine within each level. The resulting algorithm, termed LEVELSCHED, is analytically shown to be near-optimal for given degrees of operator parallelism.
Reference: [25] <author> P. Valduriez. </author> <title> Parallel Database Systems: Open Problems and New Issues. </title> <booktitle> Distributed and Parallel Databases, </booktitle> <volume> 1 </volume> <pages> 137-165, </pages> <year> 1993. </year>
Reference-contexts: Despite the popularity of these architectures, the development of effective and efficient query processing and optimization techniques to exploit their full potential still remains an issue of concern <ref> [9, 25] </ref>. Prior work has already demonstrated the importance of resource scheduling during parallel query optimization. One of the main sources of complexity for the problem is the multidimensionality of the resource needs of database queries.
Reference: [26] <author> A. N. Wilschut, J. Flokstra, and P. M.G. Apers. </author> <title> Parallelism in a Main-Memory DBMS: </title> <booktitle> The Performance of PRISMA/DB. In Proc. of the 18th Intl. VLDB Conf., </booktitle> <month> August </month> <year> 1992. </year>
Reference-contexts: Finally, we estimate the communication area W c (op; N ) using a simple linear model of communication costs that has been adopted in previous studies of shared-nothing architectures <ref> [11, 26] </ref> and validated on the Gamma research prototype [6]. Specifically, if D is the total size of the operator's input and output transferred over the interconnect, then W c (op; N ) = ff N + fi D, where ff and fi are architecture-specific parameters [11]. <p> The work vector components for the CPU and the disk were estimated using the cost model equations given by Hsiao et al. [18]. The communication costs were calculated using the model described in Section 3. The values of the cost model parameters were obtained from the literature <ref> [18, 10, 26] </ref> and are summarized in Table 5.1.
References-found: 26

