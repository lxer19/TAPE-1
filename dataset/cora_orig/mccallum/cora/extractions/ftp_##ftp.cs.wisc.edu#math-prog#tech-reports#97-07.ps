URL: ftp://ftp.cs.wisc.edu/math-prog/tech-reports/97-07.ps
Refering-URL: http://www.cs.wisc.edu/math-prog/tech-reports/
Root-URL: 
Title: Arbitrary-Norm Separating Plane  
Author: O. L. Mangasarian 
Abstract: A plane separating two point sets in n-dimensional real space is constructed such that it minimizes the sum of arbitrary-norm distances of misclassified points to the plane. In contrast to previous approaches that used surrogates for distance-minimization, the present work is based on a precise norm-dependent explicit closed form for the projection of a point on a plane. This projection is used to formulate the separating-plane problem as a minimization of a convex function on a unit sphere in a norm dual to that of the arbitrary norm used. For the 1-norm, the problem can be solved in polynomial time by solving 2n linear programs or by solving a bilinear program. For a general p-norm, the minimization problem can be transformed via an exact penalty formulation to minimizing the sum of a convex function and a bilinear function on a convex set. For the one and infinity norms, a finite successive linearization algorithm can be used for solving the exact penalty formulation.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. F. Beckenbach and R. Bellman. </author> <title> Inequalities. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1961. </year>
Reference-contexts: 0 on R n is defined as kxk 0 := max x 0 y; (1) from which follows the generalized Cauchy-Schwarz inequality, x 0 y jx 0 yj kxk 0 kyk: (2) p + 1 q = 1, the p-norm and q-norm are dual norms by the classical Holder inequality <ref> [1] </ref>. A norm k k on R n is said to be monotonic (or absolute) if either of the following equivalent conditions hold: x; y 2 R n ; jxj jyj =) kxk kyk For p 2 [1; 1], the p-norm is monotonic. <p> A norm k k on R n is said to be monotonic (or absolute) if either of the following equivalent conditions hold: x; y 2 R n ; jxj jyj =) kxk kyk For p 2 <ref> [1; 1] </ref>, the p-norm is monotonic. <p> make use of standard inequalities between various norms such as [24, p 170]: kxk 1 kxk 2 kxk 1 n 2 kxk 2 nkxk 1 ; (14) and the fact that for a fixed x 2 R n , the p-norm is a nonincreasing function of p 2 (0; 1] <ref> [1, p 18] </ref>, we obtain the following corollary to Theorem 2.1 relating norm-dependent distances between the point q and its projection p (q) on the plane P . Corollary 2.5 Inequalities Between Norm-Dependent Distances to Projections. <p> Corollary 2.5 Inequalities Between Norm-Dependent Distances to Projections. Let d (q; P ) ` denote the distance between the point q and its projection p (q) on the plane P using the norm k k ` , ` 2 <ref> [1; 1] </ref>.
Reference: [2] <author> K. P. Bennett and O. L. Mangasarian. </author> <title> Robust linear programming discrimination of two linearly inseparable sets. </title> <journal> Optimization Methods and Software, </journal> <volume> 1 </volume> <pages> 23-34, </pages> <year> 1992. </year>
Reference-contexts: When the convex hulls of the two sets do not intersect, a single linear program can construct a strict separating plane such that each of the two open halfspaces generated by the plane contains one of the two sets <ref> [6, 12, 2] </ref>. Such a plane corresponds to a perceptron and can also be obtained by the iterative perceptron learning algorithm [22, 10] which can be interpreted as the Motzkin-Schoenberg iterative scheme for solving consistent linear inequalities [21]. <p> Unfortunately, if precise distances are used, linearity of the objective function is lost, as will be shown in this work. What many of the previous approaches have tended to use, are distance surrogates that maintained linearity of the problem <ref> [9, 8, 20, 2] </ref> but did not measure distances of violating points to the separating plane. Invariably such approaches have to contend with the null solution that does not generate any separating plane. <p> The feasible region of (17), which is the unit sphere in the dual norm k k 0 , is however not convex. It is precisely this essential nonconvex condition that has been either ignored in most previous work <ref> [12, 9, 8, 2] </ref> or used heuristically [13, 20] to enforce nonzeroness of w but not as a distance-normalization constraint. Thus in these papers, the sum of the distances of misclassified points to the separating plane has not been the real objective function that has been minimized. <p> Thus in these papers, the sum of the distances of misclassified points to the separating plane has not been the real objective function that has been minimized. In [5] a 2-norm error term is used, instead of the 1-norm error term of <ref> [2] </ref>, which again is not a measure of the distance of misclassified points to the separating plane in either [2] or [5]. <p> In [5] a 2-norm error term is used, instead of the 1-norm error term of <ref> [2] </ref>, which again is not a measure of the distance of misclassified points to the separating plane in either [2] or [5]. However, if the 1-norm is used to measure actual distance to the separating plane, then the resulting dual norm appearing in (17) is the 1-norm and (17) can be solved by solving 2n linear programs as shown in (22) below.
Reference: [3] <author> K. P. Bennett and O. L. Mangasarian. </author> <title> Bilinear separation of two sets in n-space. </title> <journal> Computational Optimization & Applications, </journal> <volume> 2 </volume> <pages> 207-227, </pages> <year> 1993. </year>
Reference-contexts: This will allow us to construct a penalty problem that is convex except for a bilinear penalty term. Such bilinear reformulations have been successfully used to solve other difficult problems <ref> [3, 16, 4] </ref>. We state and establish this equivalent reformulation of (17). <p> that (21) has a vertex solution because from any solution point a vertex of the (w; fl; y; z) constraints can be obtained by a single linear program in (w; fl; y; z), and second linear program in (t; s) from that vertex gives the desired vertex solution of (21) <ref> [3, Proposition 2.1] </ref>. <p> It follows by an argument similar to that of <ref> [3, Algorithm 2.2] </ref> that the above algorithm terminates at a vertex that satisfies the minimum principle necessary optimality condition for (21). 4 Summary & Conclusion By using an exact expression for an arbitrary-norm projection of a point on a plane we are able to formulate precisely the separating plane problem as <p> A successive linearization algorithm for the bilinear problem terminates in a finite number of steps at a stationary point of the bilinear exact penalty formulation. Successful experience in solving difficult NP-hard problems by such a bilinear formulation <ref> [3, 16, 17, 4] </ref> indicates that such an approach might be viable in the present context as well. An interesting open question that is worth investigating is the following.
Reference: [4] <author> P. S. Bradley, O. L. Mangasarian, and W. N. </author> <title> Street. Clustering via concave minimization. </title> <editor> In M. C. Mozer, M. I. Jordan, and T. Petsche, editors, </editor> <booktitle> Advances in Neural Information Processing Systems -9-, </booktitle> <pages> pages 368-374, </pages> <address> Cambridge, MA, 1997. </address> <publisher> MIT Press. ftp://ftp.cs.wisc.edu/math-prog/tech-reports/96-03.ps.Z. </publisher>
Reference-contexts: This will allow us to construct a penalty problem that is convex except for a bilinear penalty term. Such bilinear reformulations have been successfully used to solve other difficult problems <ref> [3, 16, 4] </ref>. We state and establish this equivalent reformulation of (17). <p> A successive linearization algorithm for the bilinear problem terminates in a finite number of steps at a stationary point of the bilinear exact penalty formulation. Successful experience in solving difficult NP-hard problems by such a bilinear formulation <ref> [3, 16, 17, 4] </ref> indicates that such an approach might be viable in the present context as well. An interesting open question that is worth investigating is the following.
Reference: [5] <author> R. Bramley and B. Winnicka. </author> <title> Solving linear inequalities in a least square sense. </title> <journal> SIAM Jornal on Scientific Computing, </journal> <volume> 17 </volume> <pages> 275-286, </pages> <year> 1996. </year>
Reference-contexts: Thus in these papers, the sum of the distances of misclassified points to the separating plane has not been the real objective function that has been minimized. In <ref> [5] </ref> a 2-norm error term is used, instead of the 1-norm error term of [2], which again is not a measure of the distance of misclassified points to the separating plane in either [2] or [5]. <p> In <ref> [5] </ref> a 2-norm error term is used, instead of the 1-norm error term of [2], which again is not a measure of the distance of misclassified points to the separating plane in either [2] or [5]. However, if the 1-norm is used to measure actual distance to the separating plane, then the resulting dual norm appearing in (17) is the 1-norm and (17) can be solved by solving 2n linear programs as shown in (22) below.
Reference: [6] <author> A. Charnes. </author> <title> Some fundamental theorems of perceptron theory and their geometry. </title> <editor> In J. T. Lou and R. H. Wilcox, editors, </editor> <booktitle> Computer and Information Sciences, </booktitle> <pages> pages 67-74, </pages> <address> Washington, D.C., 1964. </address> <publisher> Spartan Books. </publisher>
Reference-contexts: When the convex hulls of the two sets do not intersect, a single linear program can construct a strict separating plane such that each of the two open halfspaces generated by the plane contains one of the two sets <ref> [6, 12, 2] </ref>. Such a plane corresponds to a perceptron and can also be obtained by the iterative perceptron learning algorithm [22, 10] which can be interpreted as the Motzkin-Schoenberg iterative scheme for solving consistent linear inequalities [21].
Reference: [7] <author> M. Frank and P. Wolfe. </author> <title> An algorithm for quadratic programming. </title> <journal> Naval Research Logistics Quarterly, </journal> <volume> 3 </volume> <pages> 95-110, </pages> <year> 1956. </year>
Reference-contexts: 0 y + e 0 z ffw 0 t fi fi Aw + efl y; y 0; Bw efl z; z 0; ) Since the quadratic objective function of (21) is bounded below by ffkwk 1 ktk 1 = ff, it follows that the quadratic program (21) has a solution <ref> [7] </ref>.
Reference: [8] <author> F. Glover. </author> <title> Improved linear programming models for discriminant analysis. </title> <journal> Decision Sciences, </journal> <volume> 21 </volume> <pages> 771-785, </pages> <year> 1990. </year>
Reference-contexts: Unfortunately, if precise distances are used, linearity of the objective function is lost, as will be shown in this work. What many of the previous approaches have tended to use, are distance surrogates that maintained linearity of the problem <ref> [9, 8, 20, 2] </ref> but did not measure distances of violating points to the separating plane. Invariably such approaches have to contend with the null solution that does not generate any separating plane. <p> The feasible region of (17), which is the unit sphere in the dual norm k k 0 , is however not convex. It is precisely this essential nonconvex condition that has been either ignored in most previous work <ref> [12, 9, 8, 2] </ref> or used heuristically [13, 20] to enforce nonzeroness of w but not as a distance-normalization constraint. Thus in these papers, the sum of the distances of misclassified points to the separating plane has not been the real objective function that has been minimized.
Reference: [9] <author> R. C. Grinold. </author> <title> Mathematical methods for pattern classification. </title> <booktitle> Management Science, </booktitle> <address> 19:272--289, </address> <year> 1972. </year>
Reference-contexts: Unfortunately, if precise distances are used, linearity of the objective function is lost, as will be shown in this work. What many of the previous approaches have tended to use, are distance surrogates that maintained linearity of the problem <ref> [9, 8, 20, 2] </ref> but did not measure distances of violating points to the separating plane. Invariably such approaches have to contend with the null solution that does not generate any separating plane. <p> The feasible region of (17), which is the unit sphere in the dual norm k k 0 , is however not convex. It is precisely this essential nonconvex condition that has been either ignored in most previous work <ref> [12, 9, 8, 2] </ref> or used heuristically [13, 20] to enforce nonzeroness of w but not as a distance-normalization constraint. Thus in these papers, the sum of the distances of misclassified points to the separating plane has not been the real objective function that has been minimized.
Reference: [10] <author> J. Hertz, A. Krogh, and R. G. Palmer. </author> <title> Introduction to the Theory of Neural Computation. </title> <publisher> Addison-Wesley, </publisher> <address> Redwood City, California, </address> <year> 1991. </year>
Reference-contexts: Such a plane corresponds to a perceptron and can also be obtained by the iterative perceptron learning algorithm <ref> [22, 10] </ref> which can be interpreted as the Motzkin-Schoenberg iterative scheme for solving consistent linear inequalities [21].
Reference: [11] <author> N. Karmarkar. </author> <title> A new polynomial time algorithm for linear programming. </title> <journal> Combinatorica, </journal> <volume> 4 </volume> <pages> 373-395, </pages> <year> 1984. </year>
Reference-contexts: First we note that it can be solved in polynomial time because the solution of (17) for the 1-norm can be obtained by the best solution of the following 2n polynomially solvable <ref> [11, 25] </ref> linear programs min ( fi fi fi e w e; w i = 1 ; i = 1; : : : ; n: (22) If n is large, one may wish to resort to the following finitely terminating successive linearization algorithm for solving the bilinear formulation (21) of the
Reference: [12] <author> O. L. Mangasarian. </author> <title> Linear and nonlinear separation of patterns by linear programming. </title> <journal> Operations Research, </journal> <volume> 13 </volume> <pages> 444-452, </pages> <year> 1965. </year>
Reference-contexts: When the convex hulls of the two sets do not intersect, a single linear program can construct a strict separating plane such that each of the two open halfspaces generated by the plane contains one of the two sets <ref> [6, 12, 2] </ref>. Such a plane corresponds to a perceptron and can also be obtained by the iterative perceptron learning algorithm [22, 10] which can be interpreted as the Motzkin-Schoenberg iterative scheme for solving consistent linear inequalities [21]. <p> The feasible region of (17), which is the unit sphere in the dual norm k k 0 , is however not convex. It is precisely this essential nonconvex condition that has been either ignored in most previous work <ref> [12, 9, 8, 2] </ref> or used heuristically [13, 20] to enforce nonzeroness of w but not as a distance-normalization constraint. Thus in these papers, the sum of the distances of misclassified points to the separating plane has not been the real objective function that has been minimized.
Reference: [13] <author> O. L. Mangasarian. </author> <title> Multi-surface method of pattern separation. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-14:801-807, </volume> <year> 1968. </year>
Reference-contexts: The feasible region of (17), which is the unit sphere in the dual norm k k 0 , is however not convex. It is precisely this essential nonconvex condition that has been either ignored in most previous work [12, 9, 8, 2] or used heuristically <ref> [13, 20] </ref> to enforce nonzeroness of w but not as a distance-normalization constraint. Thus in these papers, the sum of the distances of misclassified points to the separating plane has not been the real objective function that has been minimized.
Reference: [14] <author> O. L. Mangasarian. </author> <title> Nonlinear Programming. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1969. </year> <note> Reprint: SIAM Classic in Applied Mathematics 10, 1994, Philadelphia. </note>
Reference-contexts: w 0 y: (6) Consequently, the distance between q and its projection p (q) is given by: kq p (q)k = kwk 0 : (7) Proof The proof consists of showing that p (q) 2 P and that it satisfies the right inequality of the Karush-Kuhn-Tucker saddlepoint sufficient optimality criterion <ref> [14, Equation 5.1.4, Theorem 5.3.1] </ref> for some Lagrange multiplier 2 R: kp (q) qk kx qk (w 0 x fl); 8x 2 R n : (8) To show that p (q) 2 P note that: w 0 p (q) fl = w 0 q + kwk 0 w 0 y (w) <p> Hence (8) holds, and by the Karush-Kuhn-Tucker saddlepoint sufficiency theorem <ref> [14, Theorem 5.3.1] </ref> p (q) as given by (5) is a projection of q on P .
Reference: [15] <author> O. L. Mangasarian. </author> <title> Some applications of penalty functions in mathematical programming. </title> <editor> In R. Conti, E. De Giorgi, and F. Giannessi, editors, </editor> <booktitle> Optimization and Related Fields, </booktitle> <pages> pages 307-329. </pages> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, </address> <year> 1986. </year> <note> Lecture Notes in Mathematics 1190. </note>
Reference-contexts: Dropping the constant term ff, gives the penalty term ffw 0 t of (19). The first part of the theorem then follows from standard exterior penalty function results such as <ref> [15, Theorem 2.8] </ref>. We establish the second part for the 1-norm only, the proof for the 1-norm is similar.
Reference: [16] <author> O. L. Mangasarian. </author> <title> Misclassification minimization. </title> <journal> Journal of Global Optimization, </journal> <volume> 5 </volume> <pages> 309-323, </pages> <year> 1994. </year>
Reference-contexts: This will allow us to construct a penalty problem that is convex except for a bilinear penalty term. Such bilinear reformulations have been successfully used to solve other difficult problems <ref> [3, 16, 4] </ref>. We state and establish this equivalent reformulation of (17). <p> A successive linearization algorithm for the bilinear problem terminates in a finite number of steps at a stationary point of the bilinear exact penalty formulation. Successful experience in solving difficult NP-hard problems by such a bilinear formulation <ref> [3, 16, 17, 4] </ref> indicates that such an approach might be viable in the present context as well. An interesting open question that is worth investigating is the following.
Reference: [17] <author> O. L. Mangasarian. </author> <title> The linear complementarity problem as a separable bilinear program. </title> <journal> Journal of Global Optimization, </journal> <volume> 6 </volume> <pages> 153-161, </pages> <year> 1995. </year>
Reference-contexts: A successive linearization algorithm for the bilinear problem terminates in a finite number of steps at a stationary point of the bilinear exact penalty formulation. Successful experience in solving difficult NP-hard problems by such a bilinear formulation <ref> [3, 16, 17, 4] </ref> indicates that such an approach might be viable in the present context as well. An interesting open question that is worth investigating is the following.
Reference: [18] <author> O. L. Mangasarian. </author> <title> Arbitrary-norm separating plane. </title> <type> Technical Report 97-07, </type> <institution> Computer Sciences Department, University of Wisconsin, Madison, Wisconsin, </institution> <month> May </month> <year> 1997. </year> <note> Operations Research Letters, submitted. ftp://ftp.cs.wisc.edu/math-prog/tech-reports/97-07.ps.Z. </note>
Reference-contexts: Successful experience in solving difficult NP-hard problems by such a bilinear formulation [3, 16, 17, 4] indicates that such an approach might be viable in the present context as well. An interesting open question that is worth investigating is the following. In <ref> [18] </ref> it was shown that if we append the additional consistent constraint kwk 1 1 n to (17) for p 2 (1; 1], an associated decision problem with (17) is NP-complete. Whether (17) can also be associated with an NP-complete decision problem without the additional constraint is an open question.
Reference: [19] <author> O. L. Mangasarian and J.-S. Pang. </author> <title> Exact penalty functions for mathematical programs with linear complementarity constraints. </title> <journal> Optimization, </journal> <volume> 42 </volume> <pages> 1-8, </pages> <year> 1997. </year> <note> Available from: ftp://ftp.cs.wisc.edu/math-prog/tech-reports/96-06.ps.Z. </note>
Reference-contexts: By <ref> [19, Theorem 2.1] </ref>, or more simply by noting that some fixed vertex of the feasible region of (21) solves (21) for a subsequence fff i j g " 1 and hence must also solve (20).- We turn our attention now to algorithmic aspects for solving 1-norm separating plane.
Reference: [20] <author> O. L. Mangasarian, R. Setiono, and W. H. Wolberg. </author> <title> Pattern recognition via linear programming: Theory and application to medical diagnosis. </title> <editor> In T. F. Coleman and Y. Li, editors, </editor> <booktitle> Large-Scale Numerical Optimization, </booktitle> <pages> pages 22-31, </pages> <address> Philadelphia, Pennsylvania, </address> <year> 1990. </year> <title> SIAM. </title> <booktitle> Proceedings of the Workshop on Large-Scale Numerical Optimization, </booktitle> <institution> Cornell University, </institution> <address> Ithaca, New York, </address> <month> October 19-20, </month> <year> 1989. </year>
Reference-contexts: Unfortunately, if precise distances are used, linearity of the objective function is lost, as will be shown in this work. What many of the previous approaches have tended to use, are distance surrogates that maintained linearity of the problem <ref> [9, 8, 20, 2] </ref> but did not measure distances of violating points to the separating plane. Invariably such approaches have to contend with the null solution that does not generate any separating plane. <p> The feasible region of (17), which is the unit sphere in the dual norm k k 0 , is however not convex. It is precisely this essential nonconvex condition that has been either ignored in most previous work [12, 9, 8, 2] or used heuristically <ref> [13, 20] </ref> to enforce nonzeroness of w but not as a distance-normalization constraint. Thus in these papers, the sum of the distances of misclassified points to the separating plane has not been the real objective function that has been minimized.
Reference: [21] <author> T. S. Motzkin and I. J. </author> <title> Schoenberg. The relaxation method for linear inequalities. </title> <journal> Canadian Journal of Mathematics, </journal> <volume> 6 </volume> <pages> 393-404, </pages> <year> 1954. </year>
Reference-contexts: Such a plane corresponds to a perceptron and can also be obtained by the iterative perceptron learning algorithm [22, 10] which can be interpreted as the Motzkin-Schoenberg iterative scheme for solving consistent linear inequalities <ref> [21] </ref>. When the convex hulls of the two sets intersect the iterative scheme fails because the underlying linear inequalities are inconsistent, while the linear programming approach must be provided with an error criterion to be minimized.
Reference: [22] <author> N. J. Nilsson. </author> <title> Learning Machines. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1966. </year>
Reference-contexts: Such a plane corresponds to a perceptron and can also be obtained by the iterative perceptron learning algorithm <ref> [22, 10] </ref> which can be interpreted as the Motzkin-Schoenberg iterative scheme for solving consistent linear inequalities [21].
Reference: [23] <author> R. T. Rockafellar. </author> <title> Convex Analysis. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, New Jersey, </address> <year> 1970. </year>
Reference-contexts: A norm k k on R n is said to be monotonic (or absolute) if either of the following equivalent conditions hold: x; y 2 R n ; jxj jyj =) kxk kyk For p 2 [1; 1], the p-norm is monotonic. It is well known <ref> [23] </ref> that for x 2 R n the general norm kxk is convex on R n , has bounded level sets in R n , and is continuous on R n . 2 Arbitrary-Norm Projection on a Plane In this section we derive an explicit expression for the projection of a
Reference: [24] <author> G. W. Stewart. </author> <title> Introduction to Matrix Computations. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: and hence y i (w) = 1 for w i &gt; 0 ) Furthermore, since ky (w)k 1 = 1, it follows from (5) and (7) that: p (q) = q kwk 1 jw 0 q flj : If we make use of standard inequalities between various norms such as <ref> [24, p 170] </ref>: kxk 1 kxk 2 kxk 1 n 2 kxk 2 nkxk 1 ; (14) and the fact that for a fixed x 2 R n , the p-norm is a nonincreasing function of p 2 (0; 1] [1, p 18], we obtain the following corollary to Theorem 2.1
Reference: [25] <author> Robert J. Vanderbei. </author> <title> Linear Programming: Foundations and Extensions. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Hingham, MA, </address> <year> 1997. </year> <month> 9 </month>
Reference-contexts: First we note that it can be solved in polynomial time because the solution of (17) for the 1-norm can be obtained by the best solution of the following 2n polynomially solvable <ref> [11, 25] </ref> linear programs min ( fi fi fi e w e; w i = 1 ; i = 1; : : : ; n: (22) If n is large, one may wish to resort to the following finitely terminating successive linearization algorithm for solving the bilinear formulation (21) of the
References-found: 25

