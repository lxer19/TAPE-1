URL: http://ebbets.poly.edu/PDC-lab/research_papers/job_scheduling_in_rings.ps
Refering-URL: http://ebbets.poly.edu/PDC-lab/wein.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: email: pfizzano@ups.edu  email: karger@theory.lcs.mit.edu  email: cliff@cs.dartmouth.edu  email: wein@mem.poly.edu  
Title: Distributed Job Scheduling in Rings  
Author: Perry Fizzano David Karger Clifford Stein Joel Wein 
Address: College.  
Note: Research partially supported by NSF grant CCR-9308701, a Walter Burke Research Initiation Award and a  Research Initiation Award. This work was done while the author was a graduate student at  yResearch supported by a Hertz Foundation Graduate Fellowship and by NSF Young Investigator Award CCR-9357849, with matching funds from IBM, Schlumberger Foundation, Shell Foundation and Xerox Corporation. This work was done while the author was a graduate student at Stanford University.  zResearch partially supported by NSF grant CCR-9308701, a Walter Burke Research Initiation Award and a  Research Initiation Award.  xResearch partially supported by NSF grant CCR-9211494 and a grant from the New York State Science and Technology Foundation, Center for Advanced Technology in Telecommunications. Part of this work was done while the author was visiting DIMACS.  
Affiliation: University of Puget Sound Department of Mathematics and Computer Science  MIT Laboratory for Computer Science  Dartmouth College Department of Computer Science  Polytechnic University Department of Computer and Information Science  Dartmouth College  Dartmouth  Dartmouth College  
Abstract: We give a distributed approximation algorithm for job scheduling in a ring architecture. In contrast to many other parallel scheduling models, the model we consider captures the influence of the underlying communications network by specifying that task migration from one processor to another takes time proportional to the distance between those two processors in the network. As a result, our algorithm must balance both computational load and communication time. The algorithm is simple, requires no global control, and yields schedules of length at most 4:22 times optimal. We also give a lower bound on the performance of any distributed algorithm, and the results of simulation experiments which suggest better performance than does our worst-case analysis. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Ravindra K. Ahuja, Thomas L. Magnanti, and James B. Orlin. </author> <title> Network Flows. </title> <publisher> Prentice Hall, </publisher> <year> 1993. </year>
Reference-contexts: A well-known method for solving maximum cardinality bipartite matching uses maximum flow. Connect a source, s, to each vertex in V and connect each vertex in W to a sink, t. The edges between V and W are as described above. Finally, give every edge unit capacity. (see <ref> [1] </ref> for details). This leads to an algorithm that is very simple to understand and code but unfortunately it could require nmT space which is far too large for the large instances in Table 5. We refer to this procedure as First-opt.
Reference: [2] <author> W. Aiello, B. Awerbuch, B. Maggs, and S. Rao. </author> <title> Approximate load balancing on dynamic and asynchronous networks. </title> <booktitle> In Proceedings of the 25th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 632-641, </pages> <year> 1993. </year>
Reference-contexts: Distributed job scheduling is related to, but different from, load balancing, which is another common problem in parallel and distributed systems (see <ref> [2, 14, 23, 10, 8, 29, 12, 13] </ref>). In the load balancing problem one is given a set of tasks or tokens and must distribute the tasks so that each processor in the system has approximately the same number.
Reference: [3] <author> F. Allen, M. Burke, P. Charles, R. Cytron, and J. Ferrante. </author> <title> An overview of the ptran analysis system for multiprocessing. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5 </volume> <pages> 617-640, </pages> <year> 1988. </year>
Reference-contexts: Simply put, the problem is to assign each of a set of independent tasks to processors in the system so as to finish the processing of the set of tasks as quickly as possible. Job scheduling arises frequently in parallel computing, for example in algorithms for automatic loop parallelization <ref> [3, 18, 19, 27] </ref> or in the use of a parallel system to process batches of transactions of independent sequential programs.
Reference: [4] <author> N. Alon, G. Kalai, M. Ricklin, and L. Stockmeyer. </author> <title> Lower bounds on the competitive ratio for mobile user tracking and distributed job scheduling. </title> <booktitle> In Proceedings of the 24th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 334-343, </pages> <year> 1992. </year>
Reference-contexts: Tel [33] and Choi and Esfahanian [9] argue that the assumption of overlap occurring in these three tasks is supported by current technology, and this is the model considered by Deng et al., Awerbuch et al., and others <ref> [6, 11, 4, 26] </ref>. If a processor, at time t, sends a job to a neighbor, the neighbor receives the job at time t + 1. We assume that the job granularity is large enough so that the time for basic control operations, such as simple arithmetic, is negligible. <p> We assume that the job granularity is large enough so that the time for basic control operations, such as simple arithmetic, is negligible. In this paper we assume, as do our predecessors <ref> [6, 11, 4] </ref>, that there is no bound on the capacity of each network link in the ring; specifically, we allow a processor to send an arbitrary number of jobs to a neighbor in one time step.
Reference: [5] <author> H. Attiya, M. Snir, and M. Warmuth. </author> <title> Computing on an anonymous ring. </title> <journal> Journal of the ACM, </journal> <volume> 35(4) </volume> <pages> 845-875, </pages> <year> 1988. </year>
Reference-contexts: We focus on the ring architecture, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [5, 7, 16, 22, 24, 30, 31] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [20, 28, 32, 33].
Reference: [6] <author> B. Awerbuch, S. Kutten, and D. Peleg. </author> <title> Competetive distributed job scheduling. </title> <booktitle> In Proceedings of the 24th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 571-580, </pages> <year> 1992. </year>
Reference-contexts: Our work was inspired by the work of Deng, Liu, Long and Xiao [11] and Awerbuch, Kutten and Peleg <ref> [6] </ref>, who introduced this distributed scheduling model. We will soon discuss their work in detail, but we note here that the major accomplishment of these papers that is relevant to our work is the algorithm of Awerbuch, Kutten and Peleg for distributed job scheduling in any network. <p> Tel [33] and Choi and Esfahanian [9] argue that the assumption of overlap occurring in these three tasks is supported by current technology, and this is the model considered by Deng et al., Awerbuch et al., and others <ref> [6, 11, 4, 26] </ref>. If a processor, at time t, sends a job to a neighbor, the neighbor receives the job at time t + 1. We assume that the job granularity is large enough so that the time for basic control operations, such as simple arithmetic, is negligible. <p> We assume that the job granularity is large enough so that the time for basic control operations, such as simple arithmetic, is negligible. In this paper we assume, as do our predecessors <ref> [6, 11, 4] </ref>, that there is no bound on the capacity of each network link in the ring; specifically, we allow a processor to send an arbitrary number of jobs to a neighbor in one time step. <p> Their algorithm was the first polynomial time algorithm that produced optimal length schedules in networks with finite capacity. The paper most directly related to our work is that of Awerbuch, Kutten and Peleg <ref> [6] </ref>, who were the first to study the problem of distributed dynamic job scheduling in general networks; they gave a distributed polylogarithmic-approximation algorithm. <p> An interesting open problem is whether simple, small-constant approximation algorithms which require no centralized control exist for the other networks, such as the mesh. As stated earlier, Awerbuch et al. <ref> [6] </ref> give a distributed algorithm for job scheduling in general networks. When applied to the mesh their algorithm is a constant-approximation algorithm.
Reference: [7] <author> L. Bhuyan, D. Ghosal, and Q. Yang. </author> <title> Approximate analysis of single and multiple ring networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38 </volume> <pages> 1027-1040, </pages> <year> 1989. </year>
Reference-contexts: We focus on the ring architecture, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [5, 7, 16, 22, 24, 30, 31] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [20, 28, 32, 33].
Reference: [8] <author> J. E. Boillat. </author> <title> Load balancing and poisson equation in a graph. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 2(4) </volume> <pages> 289-313, </pages> <year> 1990. </year>
Reference-contexts: Finally, we note that a related problem, that of load-balancing, has also received significant attention in an "unbounded link capacity model" (e.g. see <ref> [23, 10, 8, 29, 12, 13] </ref>). Previous Work: To the best of our knowledge, the first paper to consider the problem of scheduling independent jobs on a specific network of processors was that of Deng, Liu, Long and Xiao [11]. <p> Distributed job scheduling is related to, but different from, load balancing, which is another common problem in parallel and distributed systems (see <ref> [2, 14, 23, 10, 8, 29, 12, 13] </ref>). In the load balancing problem one is given a set of tasks or tokens and must distribute the tasks so that each processor in the system has approximately the same number.
Reference: [9] <author> H. Choi and A. Esfahanian. </author> <title> A message routing strategy for multicomputer systems. </title> <journal> Networks, </journal> <volume> 22 </volume> <pages> 627-646, </pages> <year> 1992. </year>
Reference-contexts: We require that each job be processed on exactly one processor without preemption. We assume that in one unit of time each processor can receive some jobs from each neighbor, send some jobs to each neighbor, and process one unit of work. Tel [33] and Choi and Esfahanian <ref> [9] </ref> argue that the assumption of overlap occurring in these three tasks is supported by current technology, and this is the model considered by Deng et al., Awerbuch et al., and others [6, 11, 4, 26].
Reference: [10] <author> G. Cybenko. </author> <title> Dynamic load balancing for distributed memory multiprocessors. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 2 </volume> <pages> 279-301, </pages> <year> 1989. </year>
Reference-contexts: Finally, we note that a related problem, that of load-balancing, has also received significant attention in an "unbounded link capacity model" (e.g. see <ref> [23, 10, 8, 29, 12, 13] </ref>). Previous Work: To the best of our knowledge, the first paper to consider the problem of scheduling independent jobs on a specific network of processors was that of Deng, Liu, Long and Xiao [11]. <p> Distributed job scheduling is related to, but different from, load balancing, which is another common problem in parallel and distributed systems (see <ref> [2, 14, 23, 10, 8, 29, 12, 13] </ref>). In the load balancing problem one is given a set of tasks or tokens and must distribute the tasks so that each processor in the system has approximately the same number.
Reference: [11] <author> X. Deng, H. Liu, J. Long, and B. Xiao. </author> <title> Deterministic load balancing in computer networks. </title> <booktitle> In Proceedings of 2nd IEEE Symposium on Parallel and Distributed Processing, </booktitle> <year> 1990. </year>
Reference-contexts: Our work was inspired by the work of Deng, Liu, Long and Xiao <ref> [11] </ref> and Awerbuch, Kutten and Peleg [6], who introduced this distributed scheduling model. <p> Deng et al. gave an optimal polynomial-time algorithm for this problem that requires centralized control <ref> [11] </ref>; in contrast, in this paper, we prove that no distributed algorithm can solve this problem optimally. Finally, although our primary vehicle of evaluation is worst-case analysis, we also report on an experimental study of our algorithm, which suggests better performance than does our worst-case analysis. <p> Tel [33] and Choi and Esfahanian [9] argue that the assumption of overlap occurring in these three tasks is supported by current technology, and this is the model considered by Deng et al., Awerbuch et al., and others <ref> [6, 11, 4, 26] </ref>. If a processor, at time t, sends a job to a neighbor, the neighbor receives the job at time t + 1. We assume that the job granularity is large enough so that the time for basic control operations, such as simple arithmetic, is negligible. <p> We assume that the job granularity is large enough so that the time for basic control operations, such as simple arithmetic, is negligible. In this paper we assume, as do our predecessors <ref> [6, 11, 4] </ref>, that there is no bound on the capacity of each network link in the ring; specifically, we allow a processor to send an arbitrary number of jobs to a neighbor in one time step. <p> Previous Work: To the best of our knowledge, the first paper to consider the problem of scheduling independent jobs on a specific network of processors was that of Deng, Liu, Long and Xiao <ref> [11] </ref>. <p> For each instance, we computed the length of the optimal centralized schedule (a centralized scheduler is given global knowledge of the system). It was previously known how to compute the optimal schedule length for an instance with unit size jobs <ref> [11] </ref> [17]. The former of these two approaches, due to Deng. et al [11], formulated the problem as a minimum cost flow problem. Their algorithm is difficult to implement because it requires the use of a very wide range of costs. <p> It was previously known how to compute the optimal schedule length for an instance with unit size jobs <ref> [11] </ref> [17]. The former of these two approaches, due to Deng. et al [11], formulated the problem as a minimum cost flow problem. Their algorithm is difficult to implement because it requires the use of a very wide range of costs. For instance, an instance with a thousand machines would require that the costs range from 1 to 100 1000 . <p> We developed a different polynomial time algorithm that uses less than m 3 space and only requires a maximum flow subroutine. This approach made the problem more tractable than the algorithm of Deng et al. <ref> [11] </ref> and easier to code than Hoppe and Tardos' algorithm [17]. The algorithm we implemented is a polynomial time algorithm that works for general graphs with infinite capacity links.
Reference: [12] <author> B. Ghosh and S. Muthukrishnan. </author> <title> Dynamic load balancing on parallel and distributed networks by random matchings. </title> <booktitle> In Proceedings of the 6th ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 226-235, </pages> <year> 1994. </year>
Reference-contexts: Finally, we note that a related problem, that of load-balancing, has also received significant attention in an "unbounded link capacity model" (e.g. see <ref> [23, 10, 8, 29, 12, 13] </ref>). Previous Work: To the best of our knowledge, the first paper to consider the problem of scheduling independent jobs on a specific network of processors was that of Deng, Liu, Long and Xiao [11]. <p> Distributed job scheduling is related to, but different from, load balancing, which is another common problem in parallel and distributed systems (see <ref> [2, 14, 23, 10, 8, 29, 12, 13] </ref>). In the load balancing problem one is given a set of tasks or tokens and must distribute the tasks so that each processor in the system has approximately the same number.
Reference: [13] <author> Bhaskar Ghosh, S. Muthukrishnan, and M.H. Schultz. </author> <title> First and second order diffusive methods for rapid, coarse, distributed load balancing. </title> <booktitle> In Proceedings of the 8th ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 72-81, </pages> <year> 1996. </year>
Reference-contexts: Finally, we note that a related problem, that of load-balancing, has also received significant attention in an "unbounded link capacity model" (e.g. see <ref> [23, 10, 8, 29, 12, 13] </ref>). Previous Work: To the best of our knowledge, the first paper to consider the problem of scheduling independent jobs on a specific network of processors was that of Deng, Liu, Long and Xiao [11]. <p> Distributed job scheduling is related to, but different from, load balancing, which is another common problem in parallel and distributed systems (see <ref> [2, 14, 23, 10, 8, 29, 12, 13] </ref>). In the load balancing problem one is given a set of tasks or tokens and must distribute the tasks so that each processor in the system has approximately the same number.
Reference: [14] <author> M. Herlihy, B. Lim, and N. Shavit. </author> <title> Low contention load-balancing on large-scale multiprocessors. </title> <booktitle> In Proceedings of the 4th ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 219-227, </pages> <year> 1992. </year>
Reference-contexts: Distributed job scheduling is related to, but different from, load balancing, which is another common problem in parallel and distributed systems (see <ref> [2, 14, 23, 10, 8, 29, 12, 13] </ref>). In the load balancing problem one is given a set of tasks or tokens and must distribute the tasks so that each processor in the system has approximately the same number.
Reference: [15] <editor> Dorit Hochbaum, editor. </editor> <booktitle> Approximation Algorithms. </booktitle> <address> PWS, </address> <year> 1997. </year> <note> to appear. </note>
Reference-contexts: We call an algorithm A a -approximation algorithm if it produces, on any instance I, a schedule of length no more than L (I) + O (1). The worst-case study of approximation algorithms has a long and rich history; see <ref> [15] </ref> for an extensive treatment. The major contribution of this paper is a distributed 4:22-approximation algorithm for scheduling jobs in a ring. Our algorithm has low control overhead, accounts for communication constraints and does not require global control.
Reference: [16] <author> Y. Hong and T. Payne. </author> <title> Parallel sorting in a ring network of processors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38:458 - 464, </volume> <year> 1989. </year>
Reference-contexts: We focus on the ring architecture, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [5, 7, 16, 22, 24, 30, 31] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [20, 28, 32, 33].
Reference: [17] <author> B. Hoppe and E. Tardos. </author> <title> The quickest transhipment problem. </title> <booktitle> In Proceedings of the 6th ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1995. </year>
Reference-contexts: Phillips, Stein and Wein [26] gave a centralized 2-approximation algorithm for a very general form of the problem, as well as hardness-to-approximate results and approximation algorithms for different optimality criteria. Hoppe and Tardos <ref> [17] </ref> gave a polynomial time centralized algorithm for general networks and unit size jobs. Their algorithm was the first polynomial time algorithm that produced optimal length schedules in networks with finite capacity. <p> For each instance, we computed the length of the optimal centralized schedule (a centralized scheduler is given global knowledge of the system). It was previously known how to compute the optimal schedule length for an instance with unit size jobs [11] <ref> [17] </ref>. The former of these two approaches, due to Deng. et al [11], formulated the problem as a minimum cost flow problem. Their algorithm is difficult to implement because it requires the use of a very wide range of costs. <p> Even if we shifted the values so that the largest value is representable then the smallest value is too small to be represented. The latter of the approaches, due to Hoppe and Tardos <ref> [17] </ref>, requires the use of a polynomial time procedure for convex function minimization as a subroutine [34]. We developed a different polynomial time algorithm that uses less than m 3 space and only requires a maximum flow subroutine. <p> We developed a different polynomial time algorithm that uses less than m 3 space and only requires a maximum flow subroutine. This approach made the problem more tractable than the algorithm of Deng et al. [11] and easier to code than Hoppe and Tardos' algorithm <ref> [17] </ref>. The algorithm we implemented is a polynomial time algorithm that works for general graphs with infinite capacity links. We begin by describing a variation of this algorithm and then discuss the necessary refinements to make it run in polynomial time.
Reference: [18] <author> S. Flynn Hummel and E. Schonberg. </author> <title> Low-overhead scheduling of nested parallelism. </title> <journal> IBM Journal of Research and Development, </journal> 35(5/6):743-765, 1991. 
Reference-contexts: Simply put, the problem is to assign each of a set of independent tasks to processors in the system so as to finish the processing of the set of tasks as quickly as possible. Job scheduling arises frequently in parallel computing, for example in algorithms for automatic loop parallelization <ref> [3, 18, 19, 27] </ref> or in the use of a parallel system to process batches of transactions of independent sequential programs.
Reference: [19] <author> S. Flynn Hummel, E. Schonberg, and L. E. Flynn. </author> <title> Factoring: A practical and robust method for scheduling parallel loops. </title> <journal> Comm. of the ACM, </journal> <volume> 35(8) </volume> <pages> 90-101, </pages> <year> 1992. </year>
Reference-contexts: Simply put, the problem is to assign each of a set of independent tasks to processors in the system so as to finish the processing of the set of tasks as quickly as possible. Job scheduling arises frequently in parallel computing, for example in algorithms for automatic loop parallelization <ref> [3, 18, 19, 27] </ref> or in the use of a parallel system to process batches of transactions of independent sequential programs. <p> Furthermore, in the scheduling of independent iterations of parallel loops, one of the major real-world sources of motivation for the problem of scheduling independent jobs on a parallel computer, a large number of iterations can be characterized by just a few numbers describing a range of loop indices <ref> [19] </ref>. Finally, we note that a related problem, that of load-balancing, has also received significant attention in an "unbounded link capacity model" (e.g. see [23, 10, 8, 29, 12, 13]).
Reference: [20] <author> D. Hutchinson. </author> <title> Local Area Network Architectures. </title> <publisher> Addison-Wesley, </publisher> <year> 1988. </year>
Reference-contexts: In practice the ring is either the basis of or an essential component of many parallel and distributed architectures <ref> [20, 28, 32, 33] </ref>. Our primary vehicle for the evaluation of an algorithm is by a worst-case analysis of the quality of the schedule it produces. Our goal will be to schedule all jobs as quickly as possible, or in other words to produce a short schedule.
Reference: [21] <author> E.L. Lawler, J.K. Lenstra, A.H.G. Rinooy Kan, </author> <title> and D.B. Shmoys. Sequencing and scheduling: Algorithms and complexity. In S.C. Graves, </title> <editor> A.H.G. Rinnooy Kan, and P.H. Zipkin, editors, </editor> <booktitle> Handbooks in Operations Research and Management Science, </booktitle> <volume> Vol 4., </volume> <booktitle> Logistics of Production and Inventory, </booktitle> <pages> pages 445-522. </pages> <publisher> North-Holland, </publisher> <year> 1993. </year> <month> 16 </month>
Reference-contexts: There is a wealth of literature on the analytical evaluation of parallel machine scheduling (see Lawler et al. <ref> [21] </ref> for a number of examples) but much of it fails to capture the full complexity of many real scheduling problems. Many of the proposed algorithms have significant control overhead, and almost all of the literature ignores the communication constraints imposed by an underlying network architecture.
Reference: [22] <author> F. T. Leighton. </author> <title> An Introduction to Parallel Algorithms and Architectures. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: The study of parallel and distributed algorithms on specific network architectures has a rich history; a good reference is the textbook authored by Leighton <ref> [22] </ref>. We focus on the ring architecture, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it [5, 7, 16, 22, 24, 30, 31]. <p> We focus on the ring architecture, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [5, 7, 16, 22, 24, 30, 31] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [20, 28, 32, 33].
Reference: [23] <author> F. C. H. Lin and R. M. Keller. </author> <title> The gradient model load balancing method. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 13(1) </volume> <pages> 32-38, </pages> <year> 1987. </year>
Reference-contexts: Finally, we note that a related problem, that of load-balancing, has also received significant attention in an "unbounded link capacity model" (e.g. see <ref> [23, 10, 8, 29, 12, 13] </ref>). Previous Work: To the best of our knowledge, the first paper to consider the problem of scheduling independent jobs on a specific network of processors was that of Deng, Liu, Long and Xiao [11]. <p> Distributed job scheduling is related to, but different from, load balancing, which is another common problem in parallel and distributed systems (see <ref> [2, 14, 23, 10, 8, 29, 12, 13] </ref>). In the load balancing problem one is given a set of tasks or tokens and must distribute the tasks so that each processor in the system has approximately the same number.
Reference: [24] <author> Y. Mansour and L. Schulman. </author> <title> Sorting on a ring of processors. </title> <journal> Journal of Algorithms, </journal> <volume> 11 </volume> <pages> 622-630, </pages> <year> 1990. </year>
Reference-contexts: We focus on the ring architecture, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [5, 7, 16, 22, 24, 30, 31] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [20, 28, 32, 33].
Reference: [25] <author> C. Papadimitriou and M. Yannakakis. </author> <title> Towards an architecture-independent analysis of parallel algorithms. </title> <booktitle> In Proceedings of the 20th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 510-514, </pages> <year> 1988. </year>
Reference-contexts: The model we consider is not the only attempt to incorporate the constraints imposed by communication latency into a scheduling model. A line of research which is quite different from ours, yet still has some similarity in spirit, was started by Papadimitriou and Yannakakis <ref> [25] </ref>. They modeled communication issues in parallel machine scheduling by abstracting away from particular networks and instead describe the communication time between any two processors by one network-dependent constant.
Reference: [26] <author> C. A. Phillips, C. Stein, and J. Wein. </author> <title> Task scheduling in networks. </title> <booktitle> In Proceedings of the 4th Scandinavian Workshop on Algorithm Theory, </booktitle> <month> July </month> <year> 1994. </year>
Reference-contexts: Tel [33] and Choi and Esfahanian [9] argue that the assumption of overlap occurring in these three tasks is supported by current technology, and this is the model considered by Deng et al., Awerbuch et al., and others <ref> [6, 11, 4, 26] </ref>. If a processor, at time t, sends a job to a neighbor, the neighbor receives the job at time t + 1. We assume that the job granularity is large enough so that the time for basic control operations, such as simple arithmetic, is negligible. <p> While this is an interesting result, in realistic settings an algorithm would certainly want to take advantage of this information. Phillips, Stein and Wein <ref> [26] </ref> gave a centralized 2-approximation algorithm for a very general form of the problem, as well as hardness-to-approximate results and approximation algorithms for different optimality criteria. Hoppe and Tardos [17] gave a polynomial time centralized algorithm for general networks and unit size jobs.
Reference: [27] <author> C. Polychronopoulos and D. Kuck. </author> <title> Guided self-scheduling: A practical scheduling scheme for parallel computers. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 12 </volume> <pages> 1425-1439, </pages> <year> 1987. </year>
Reference-contexts: Simply put, the problem is to assign each of a set of independent tasks to processors in the system so as to finish the processing of the set of tasks as quickly as possible. Job scheduling arises frequently in parallel computing, for example in algorithms for automatic loop parallelization <ref> [3, 18, 19, 27] </ref> or in the use of a parallel system to process batches of transactions of independent sequential programs.
Reference: [28] <author> J. Rothnie. </author> <title> Kendall square research introduction to the ksr1. </title> <booktitle> In Dartmouth Institute for Advanced Graduate Studies in Parallel Computation, </booktitle> <pages> pages 200-210, </pages> <year> 1992. </year>
Reference-contexts: In practice the ring is either the basis of or an essential component of many parallel and distributed architectures <ref> [20, 28, 32, 33] </ref>. Our primary vehicle for the evaluation of an algorithm is by a worst-case analysis of the quality of the schedule it produces. Our goal will be to schedule all jobs as quickly as possible, or in other words to produce a short schedule.
Reference: [29] <author> J. Song. </author> <title> A partially asynchronous and iterative algorithm for distributed load balancing. </title> <journal> Parallel Computing, </journal> <volume> 20 </volume> <pages> 853-868, </pages> <year> 1994. </year>
Reference-contexts: Finally, we note that a related problem, that of load-balancing, has also received significant attention in an "unbounded link capacity model" (e.g. see <ref> [23, 10, 8, 29, 12, 13] </ref>). Previous Work: To the best of our knowledge, the first paper to consider the problem of scheduling independent jobs on a specific network of processors was that of Deng, Liu, Long and Xiao [11]. <p> Distributed job scheduling is related to, but different from, load balancing, which is another common problem in parallel and distributed systems (see <ref> [2, 14, 23, 10, 8, 29, 12, 13] </ref>). In the load balancing problem one is given a set of tasks or tokens and must distribute the tasks so that each processor in the system has approximately the same number.
Reference: [30] <author> W. Sung and S. Mitra. </author> <title> Multiprocessor implementation of recursive least squares algorithms using a parallel block processing method. </title> <booktitle> In IEEE International Symposium on Circuits and Systems, </booktitle> <pages> pages 2939-2942, </pages> <year> 1991. </year>
Reference-contexts: We focus on the ring architecture, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [5, 7, 16, 22, 24, 30, 31] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [20, 28, 32, 33].
Reference: [31] <author> W. Sung, S. Mitra, and K. Kum. </author> <title> Mapping locally recursive sfgs upon a multiprocessor system in a ring network. </title> <booktitle> In Proceedings of the International Conference on Application Specific Array Processors, </booktitle> <pages> pages 560-573, </pages> <year> 1992. </year>
Reference-contexts: We focus on the ring architecture, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [5, 7, 16, 22, 24, 30, 31] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [20, 28, 32, 33].
Reference: [32] <author> A.S. Tanenbaum. </author> <title> Computer Networks. </title> <publisher> Prentice Hall, </publisher> <year> 1989. </year>
Reference-contexts: In practice the ring is either the basis of or an essential component of many parallel and distributed architectures <ref> [20, 28, 32, 33] </ref>. Our primary vehicle for the evaluation of an algorithm is by a worst-case analysis of the quality of the schedule it produces. Our goal will be to schedule all jobs as quickly as possible, or in other words to produce a short schedule.
Reference: [33] <author> Gerard Tel. </author> <title> Introduction to Distributed Algorithms. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, U.K., </address> <year> 1994. </year>
Reference-contexts: In practice the ring is either the basis of or an essential component of many parallel and distributed architectures <ref> [20, 28, 32, 33] </ref>. Our primary vehicle for the evaluation of an algorithm is by a worst-case analysis of the quality of the schedule it produces. Our goal will be to schedule all jobs as quickly as possible, or in other words to produce a short schedule. <p> We require that each job be processed on exactly one processor without preemption. We assume that in one unit of time each processor can receive some jobs from each neighbor, send some jobs to each neighbor, and process one unit of work. Tel <ref> [33] </ref> and Choi and Esfahanian [9] argue that the assumption of overlap occurring in these three tasks is supported by current technology, and this is the model considered by Deng et al., Awerbuch et al., and others [6, 11, 4, 26].

References-found: 33

