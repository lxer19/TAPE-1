URL: http://www.cs.toronto.edu/~vassos/research/publications/LH94/paper.ps.gz
Refering-URL: http://www.cs.toronto.edu/~vassos/research/list-of-publications.html
Root-URL: 
Title: Using Failure Detectors to Solve Consensus in Asynchronous Shared-Memory Systems (Extended Abstract)  
Author: Wai-Kau Lo and Vassos Hadzilacos 
Address: 6 King's College Road Toronto, Ontario Canada M5S 1A4  
Affiliation: Department of Computer Science University of Toronto  
Abstract: Chandra and Toueg proposed a new approach to overcome the impossibility of reaching consensus in asynchronous message-passing systems subject to crash failures [6]. They augment the asynchronous message-passing system with a (possibly unreliable) failure detector. Informally, a failure detector provides some information about the processes that have crashed during an execution of the system. In this paper, we present several Consensus algorithms using different types failure detectors in asynchronous shared-memory systems. We also prove several lower bounds and impossibility results regarding solving Consensus 1 Background and Overview of Results using failure detectors in asynchronous shared-memory systems.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Yehuda Afek, Hagit Attiya, Danny Dolev, Eli Gafni, Michael Merritt and Nir Shavit. </author> <title> Atomic snapshots of shared memory. </title> <booktitle> In Proceedings of the 9th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 1-13, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: A schedule S is a finite or infinite sequence of steps of the algorithm. S [i] denotes the ith step of S. A schedule S is applicable to a configuration C if and only if S is the empty sequence, or S <ref> [1] </ref> is applicable to C, and S [2] is applicable to S [1](C), etc. <p> Lemma 4. No correct process can be stuck in the repeat until statement (lines 22-24). Proof: Omitted from the extended abstract. 6 This procedure is not to be confused with the scan of an atomic snapshot object <ref> [1] </ref>: We do not require that scan-registers be linearised with respect to the other write and scan-registers operations. Only the individual reads that are within scan registers are linearised with respect to the other read and write operations.
Reference: 2. <author> Yehuda Afek, David S. Greenberg, Michael Merritt, and Gadi Taubenfeld. </author> <title> Computing with faulty shared memory. </title> <booktitle> In Proceedings of the 11th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 47-58, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: In this paper we assume that only processes may fail, and do so by crashing, i.e., halting prematurely. In particular, the shared registers behave correctly. Problems related to tolerating faulty registers are discussed in <ref> [2, 10] </ref>. We now give an overview of our results. First, some definitions (cf. [6]): A Strong failure detector satisfies the Strong Completeness and Weak Accuracy properties; an Eventual Strong failure detector satisfies Strong Completeness and Eventual Weak Accuracy. <p> A schedule S is a finite or infinite sequence of steps of the algorithm. S [i] denotes the ith step of S. A schedule S is applicable to a configuration C if and only if S is the empty sequence, or S [1] is applicable to C, and S <ref> [2] </ref> is applicable to S [1](C), etc.
Reference: 3. <author> James Aspnes and Maurice Herlihy. </author> <title> Fast randomized consensus using shared memory. </title> <journal> Journal of Algorithms, </journal> <volume> 11 </volume> <pages> 441-461, </pages> <year> 1990. </year>
Reference-contexts: Many randomised Consensus algorithms have been devised for both message-passing and shared-memory asynchronous systems <ref> [4, 3] </ref>. Recently, Chandra and Toueg [6] introduced another approach to overcome the impossibility of reaching Consensus in asynchronous message-passing systems subject to crash failures. In their approach, the asynchronous model is augmented with a (possibly unreliable) failure detector.
Reference: 4. <author> Michael Ben-Or. </author> <title> Another advantage of free choice: Completely asynchronous agreement protocol. </title> <booktitle> In Proceedings of the 2th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 27-30, </pages> <month> August </month> <year> 1983. </year>
Reference-contexts: Many randomised Consensus algorithms have been devised for both message-passing and shared-memory asynchronous systems <ref> [4, 3] </ref>. Recently, Chandra and Toueg [6] introduced another approach to overcome the impossibility of reaching Consensus in asynchronous message-passing systems subject to crash failures. In their approach, the asynchronous model is augmented with a (possibly unreliable) failure detector.
Reference: 5. <author> Tushar Deepak Chandra, Vassos Hadzilacos, and Sam Toueg. </author> <title> The weakest failure detector for solving consensus. </title> <booktitle> In Proceedings of the 11th ACM Symposium on Principles of Distributed Computing, </booktitle> <month> August </month> <year> 1992. </year> <note> Also technical report, </note> <institution> Department of Computer Science, Cornell University, </institution> <address> 1993, Ithaca, NY 14853-7501. </address>
Reference-contexts: Chandra and Toueg [6] define a host of different failure detectors by considering different combinations of completeness and accuracy properties. For each failure detector they consider they give an algorithm for Consensus that uses that failure detector. In a related paper, Chandra, Hadzilacos and Toueg <ref> [5] </ref>, prove that W is, in fact, the weakest failure detector that can be used to solve Consensus. More precisely, they show that any failure detector D that can be used to solve Consensus can also be used to emulate W. <p> Finally, we show that the Eventual Weak failure detector is the weakest one that can solve Consensus in asynchronous shared-memory systems, just as it is in message-passing systems. The proof technique follows closely the one presented in <ref> [5] </ref>, except for some technical difficulties that arise as a result of the difference between message-passing and shared-memory asynchronous systems that was pointed out previously. The rest of the extended abstract is organised as follows: In Section 2, we briefly describe our model of computation. <p> In Section 3, we present our Consensus algorithms that use different types of failure detectors. Section 4 contains some lower bounds and impossibility results. We conclude in Section 5 with a discussion of some open problems. 2 Model of Computation Our model of computation follows <ref> [5] </ref> and [11]. In this extended abstract we only sketch the main features of the model, without going into all the formal details. <p> We write D -E D fl to denote the fact that D can be used to emulate D fl in E . In <ref> [5] </ref>, Chandra, Hadzilacos and Toueg show that the Eventual Weak failure detector W is the weakest that can be used to solve Consensus in asynchronous message-passing systems. we have shown that this result also holds for asynchronous shared-memory systems: Theorem 12. <p> The Eventual Weak failure detector W is the weakest failure detector that can used to solve Consensus in asynchronous shared-memory systems. The proof of this theorem follows closely that in <ref> [5] </ref>. Some technical difficulties arise due to the fact that in shared-memory systems a write step of a process cannot be "hidden" from other processes (in contrast, as we have remarked, in message-passing systems, the sending of a message can be hidden for arbitrarily long by delaying that message).
Reference: 6. <author> Tushar Deepak Chandra and Sam Toueg. </author> <title> Unreliable failure detectors for asynchronous systems. </title> <booktitle> In Proceedings of the 10th ACM Symposium on Principles of Distributed Computing, </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: Many randomised Consensus algorithms have been devised for both message-passing and shared-memory asynchronous systems [4, 3]. Recently, Chandra and Toueg <ref> [6] </ref> introduced another approach to overcome the impossibility of reaching Consensus in asynchronous message-passing systems subject to crash failures. In their approach, the asynchronous model is augmented with a (possibly unreliable) failure detector. Informally, a failure detector, denoted D, consists of a collection of modules, one associated with each process. <p> Note that the quality of information about failures that such a failure detector provides can be quite poor: A correct process can be permanently suspected by all other processes; it can also be suspected and then not suspected repeatedly (infinitely often) by the other processes. Chandra and Toueg <ref> [6] </ref> define a host of different failure detectors by considering different combinations of completeness and accuracy properties. For each failure detector they consider they give an algorithm for Consensus that uses that failure detector. <p> In this paper we assume that only processes may fail, and do so by crashing, i.e., halting prematurely. In particular, the shared registers behave correctly. Problems related to tolerating faulty registers are discussed in [2, 10]. We now give an overview of our results. First, some definitions (cf. <ref> [6] </ref>): A Strong failure detector satisfies the Strong Completeness and Weak Accuracy properties; an Eventual Strong failure detector satisfies Strong Completeness and Eventual Weak Accuracy. Similarly, a Weak failure detector satisfies Weak Completeness and Weak Accuracy; an Eventual Weak failure detector satisfies Weak Completeness and Eventual Weak Accuracy. <p> Both algorithms are wait-free; i.e., they can tolerate up to n 1 faulty processes. It is noteworthy that in message-passing systems any algorithm that solves Consensus using an Eventual Strong failure detector requires that a majority of the processes be correct <ref> [6] </ref>. Thus, our Consensus algorithm for the Eventual Strong failure detector reveals an inherent difference between message-passing and shared-memory systems. <p> The significance of this behaviour was originally noted in [7], in the closely related context of partially synchronous message-passing systems. Chandra and Toueg showed how to emulate a Strong (resp. Eventual Strong) failure detector using a Weak (resp. Eventual Weak) one in message-passing systems <ref> [6] </ref>. The algorithm that accomplishes these emulations can be adapted to shared-memory systems in a straightforward manner, and we therefore get wait-free Consensus algorithms that use these two weaker failure detectors. <p> Algorithm 2 follows the "rotating coordinator" paradigm <ref> [6] </ref>. Process p i is the coordinator of asynchronous round l, if and only if i = (l mod n) + 1. In every round l, each process p first "announces" its estimate by writing (l; v p ; announce) into its own register r p . <p> Thus Validity is also satisfied. Chandra and Toueg proved that in a message-passing asynchronous system, there is no Consensus algorithm that uses an Eventual Strong failure detector unless a majority of processes are correct <ref> [6] </ref>. The proof is based on a partition argument: Suppose that n=2 of the processes have initial value 0 and n=2 of them have initial value 1. Further suppose that in reality all processes are correct. <p> Algorithm 2 takes advantage of this property of shared memory to achieve wait-free Consensus with an Eventual Strong failure detector. Thus, unlike the message-passing Consensus algorithm for Eventual Strong failure detectors of <ref> [6] </ref>, our shared-memory algorithm does not require a majority of correct processes. 3.3 Weaker Failure Detectors Chandra and Toueg give an algorithm which emulates a Strong failure detector from a Weak one, and an Eventual Strong failure detector from and Eventual Weak one. (The same algorithm accomplishes both emulations.) This algorithm <p> does not require a majority of correct processes. 3.3 Weaker Failure Detectors Chandra and Toueg give an algorithm which emulates a Strong failure detector from a Weak one, and an Eventual Strong failure detector from and Eventual Weak one. (The same algorithm accomplishes both emulations.) This algorithm was presented in <ref> [6] </ref> in the context of message-passing asynchronous systems, but can be easily adapted to our shared-memory setting, as follows: Each process p maintains a shared register suspects p , which contains the value returned by p's failure detector module when it was last queried, and a sequence number indicating how many
Reference: 7. <author> Danny Dolev, Cynthia Dwork, and Larry Stockmeyer. </author> <title> On the minimal synchronism needed for distributed consensus. </title> <journal> Journal of the ACM, </journal> <volume> 34(1) </volume> <pages> 77-97, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: 1 Background and Overview of Results It is well-known that there is no deterministic algorithm for Consensus in asynchronous distributed systems, even if a single process may crash; this result applies both to message-passing and shared-memory systems <ref> [9, 7, 11] </ref>. 3 This impossibility result has motivated the use of randomisation to solve Consensus. Many randomised Consensus algorithms have been devised for both message-passing and shared-memory asynchronous systems [4, 3]. <p> In contrast, in shared-memory systems, when a process writes a value into a register, the fact that this has occurred cannot be hidden from any process that subsequently reads that register. The significance of this behaviour was originally noted in <ref> [7] </ref>, in the closely related context of partially synchronous message-passing systems. Chandra and Toueg showed how to emulate a Strong (resp. Eventual Strong) failure detector using a Weak (resp. Eventual Weak) one in message-passing systems [6].
Reference: 8. <author> Faith Fich, Maurice Herlihy, and Nir Shavit. </author> <title> On the space complexity of randomized synchronization. </title> <booktitle> In Proceedings of the 12th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 241-249, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: We do not know how this result generalises beyond the special case of n = 3. Using the technique of Fich, Herlihy and Shavit <ref> [8] </ref>, it can be shown that any wait-free halting Consensus algorithm using an Eventual Weak failure detector for n processes must use at least ( p n) shared n-writer-n-reader registers. We do not know whether this lower bound is tight.
Reference: 9. <author> Michael J. Fischer, Nancy A. Lynch, and Michael S. Paterson. </author> <title> Impossibility of distributed consensus with one faulty process. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 32(2) </volume> <pages> 374-382, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: 1 Background and Overview of Results It is well-known that there is no deterministic algorithm for Consensus in asynchronous distributed systems, even if a single process may crash; this result applies both to message-passing and shared-memory systems <ref> [9, 7, 11] </ref>. 3 This impossibility result has motivated the use of randomisation to solve Consensus. Many randomised Consensus algorithms have been devised for both message-passing and shared-memory asynchronous systems [4, 3].
Reference: 10. <author> Prasad Jayanti, Tushar Deepak Chandra, and Sam Toueg. </author> <title> Fault-tolerant wait-free shared objects. </title> <booktitle> In Proceedings of the 33rd Annual Symposium on Foundations of Computer Science, </booktitle> <year> 1992. </year>
Reference-contexts: In this paper we assume that only processes may fail, and do so by crashing, i.e., halting prematurely. In particular, the shared registers behave correctly. Problems related to tolerating faulty registers are discussed in <ref> [2, 10] </ref>. We now give an overview of our results. First, some definitions (cf. [6]): A Strong failure detector satisfies the Strong Completeness and Weak Accuracy properties; an Eventual Strong failure detector satisfies Strong Completeness and Eventual Weak Accuracy.
Reference: 11. <author> Michael C. Loui and Hosame H. Abu-Amara. </author> <title> Memory requirements for agreement among unreliable asynchronous processes. </title> <booktitle> In Advances in Computer Research, </booktitle> <volume> volume 4, </volume> <pages> pages 163-183. </pages> <publisher> JAI Press Inc., </publisher> <year> 1987. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: 1 Background and Overview of Results It is well-known that there is no deterministic algorithm for Consensus in asynchronous distributed systems, even if a single process may crash; this result applies both to message-passing and shared-memory systems <ref> [9, 7, 11] </ref>. 3 This impossibility result has motivated the use of randomisation to solve Consensus. Many randomised Consensus algorithms have been devised for both message-passing and shared-memory asynchronous systems [4, 3]. <p> In Section 3, we present our Consensus algorithms that use different types of failure detectors. Section 4 contains some lower bounds and impossibility results. We conclude in Section 5 with a discussion of some open problems. 2 Model of Computation Our model of computation follows [5] and <ref> [11] </ref>. In this extended abstract we only sketch the main features of the model, without going into all the formal details.
References-found: 11

