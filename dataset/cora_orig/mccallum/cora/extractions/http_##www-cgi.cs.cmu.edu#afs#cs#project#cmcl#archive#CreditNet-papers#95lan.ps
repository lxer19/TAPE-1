URL: http://www-cgi.cs.cmu.edu/afs/cs/project/cmcl/archive/CreditNet-papers/95lan.ps
Refering-URL: 
Root-URL: 
Title: DRAM ATM ASIC UTOPIA bridge Buffer Management and Flow Control in the Credit Net ATM
Author: PCI Corey Kosak, David Eckhardt, Todd Mummert, Peter Steenkiste and Allan Fisher 
Date: SRAM  
Address: 155 or 622  Pittsburgh, PA 15213  
Affiliation: SONET  School of Computer Science Carnegie Mellon University  
Abstract: Among the many benefits of ATM networking are the potential for connections with negotiated quality-of-service (QoS) guarantees and application-specific data management at network endpoints. In this paper we describe the architecture of a PCI bus host adapter for OC-3 and OC-12 ATM, focusing on challenges in the areas of buffer management and ow control, since these are vital to realizing the bandwidth and QoS potential of ATM endpoint hosts. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. E. Anderson, S. S. Owicki, J. B. Saxe, and C. P. Thacker. </author> <title> High-speed switch scheduling for local-area networks. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 11(4):319352, </volume> <month> November </month> <year> 1993. </year>
Reference-contexts: In this section we first discuss the implementation of credit-based ow control; we then briey outline one possible implementation of rate-based ow control. There are many variants of credit-based ow control. They differ in granularity of the credit (incremental <ref> [1] </ref> or in bursts [7, 8, 9]), the encoding of the credit (absolute or relative), and the buffer management strategy used by the receiver (per-VC buffers, statistical sharing of buffers between VCs, etc.). Credit Net implements per-VC ow control based on the FCVC absolute credit scheme [8].
Reference: [2] <author> F. Bonomi and K. Fendick. </author> <title> The rate-based ow control framework for the available bit rate ATM service. </title> <journal> IEEE Network Magazine, </journal> <volume> 9(2):2539, </volume> <month> March/April </month> <year> 1995. </year>
Reference-contexts: One method for supporting traffic management in ATM networks is to use per-VC ow control. Many variants have been proposed, and they can be organized in two classes. Rate-based schemes <ref> [2, 11] </ref> propagate information about preferred transmission rates backward along a connection, while in credit-based schemes [8, 10], each node on a VC provides information to the preceding node regarding the availability of buffer space.
Reference: [3] <author> J. Brustoloni. </author> <title> Exposed buffering and subdatagram ow control for ATM LANs. </title> <booktitle> In Proceedings of the 19th Conference on Local Computer Networks, </booktitle> <pages> pages 324 334. </pages> <publisher> IEEE, </publisher> <month> October </month> <year> 1994. </year>
Reference-contexts: The adapter will assign buffers according to demand. High-performance protocol stacks use copy optimization to eliminate the copy between user space and kernel buffers for large packets. Several techniques can be used to achieve this: use of APIs that have share semantics instead of copy semantics <ref> [3, 6, 5] </ref>, use of outboard buffering to combine the application-kernel copy with the kernel-device copy [14], or use of remapping as a replacement for the application-kernel copy. <p> The requirements can be very simple, e.g. each packet goes in an aligned buffer, or very complicated, e.g. scatter/gather of each packet to allow efficient use by the application <ref> [3, 15] </ref>. In addition, applications of this type benefit from low per-message overhead because they send small control messages in addition to large data messages. These applications can have private buffer areas and private mailboxes.
Reference: [4] <author> C. Dalton, G. Watson, D. Banks, C. Calamvokis, A. Ed-wards, and J. Lumley. </author> <title> Afterburner. </title> <journal> IEEE Network Magazine, </journal> <volume> 7(4):3643, </volume> <month> July </month> <year> 1993. </year>
Reference-contexts: Outboard packet buffering Outboard buffering, as exemplified by the Prototype Nectar adapter [13], the Gigabit Nectar HIPPI adapter [14], or the HP Afterburner adapter <ref> [4] </ref>, assembles and stores all packets in memory located on the adapter (Figure 2). The packets can be mapped into host kernel or user virtual memory, or DMAed into host memory.
Reference: [5] <author> P. Druschel and L. Peterson. Fbufs: </author> <title> A high-bandwidth cross-domain transfer facility. </title> <booktitle> In Proceedings of the Fourteenth Symposium on Operating System Principles, </booktitle> <pages> pages 189202. </pages> <publisher> ACM, </publisher> <month> December </month> <year> 1993. </year>
Reference-contexts: The adapter will assign buffers according to demand. High-performance protocol stacks use copy optimization to eliminate the copy between user space and kernel buffers for large packets. Several techniques can be used to achieve this: use of APIs that have share semantics instead of copy semantics <ref> [3, 6, 5] </ref>, use of outboard buffering to combine the application-kernel copy with the kernel-device copy [14], or use of remapping as a replacement for the application-kernel copy.
Reference: [6] <author> K. Kleinpaste, P. Steenkiste, and B. Zill. </author> <title> Software support for outboard buffering and checksumming. </title> <booktitle> In Proceedings of the SIGCOMM 95 Symposium on Communications Architectures and Protocols, page To Appear, </booktitle> <address> Boston, </address> <month> August </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: The adapter will assign buffers according to demand. High-performance protocol stacks use copy optimization to eliminate the copy between user space and kernel buffers for large packets. Several techniques can be used to achieve this: use of APIs that have share semantics instead of copy semantics <ref> [3, 6, 5] </ref>, use of outboard buffering to combine the application-kernel copy with the kernel-device copy [14], or use of remapping as a replacement for the application-kernel copy.
Reference: [7] <author> H. Kung, T. Blackwell, and A. Chapman. </author> <title> Credit update protocol for ow-controlled ATM networks: Statistical multiplexing and adaptive credit allocation. </title> <booktitle> In Proceedings of the SIGCOMM 94 Symposium on Communications Architectures and Protocols, </booktitle> <pages> pages 101114. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1994. </year>
Reference-contexts: In this section we first discuss the implementation of credit-based ow control; we then briey outline one possible implementation of rate-based ow control. There are many variants of credit-based ow control. They differ in granularity of the credit (incremental [1] or in bursts <ref> [7, 8, 9] </ref>), the encoding of the credit (absolute or relative), and the buffer management strategy used by the receiver (per-VC buffers, statistical sharing of buffers between VCs, etc.). Credit Net implements per-VC ow control based on the FCVC absolute credit scheme [8].
Reference: [8] <author> H. Kung and A. Chapman. </author> <title> The FCVC (Flow Controlled Virtual Channels) proposal for ATM networks. </title> <booktitle> In International Conference on Network Protocols, </booktitle> <address> San Francisco, CA, </address> <month> October </month> <year> 1993. </year> <note> IEEE. </note>
Reference-contexts: In Section 2 we describe possible buffer management architectures, for both adapter and host buffers, and present our solution. We then discuss ow control in Section 3, focusing on FCVC, which is a credit-based, per-VC, link-by-link ow control scheme <ref> [8] </ref>. In Section 4 we present the results of our initial experience with the OC-3 adapter, and we conclude in Section 5. 2 Buffer Management A host interface requires the management of two types of buffers. Most memory is shared and managed in cooperation with the host. <p> One method for supporting traffic management in ATM networks is to use per-VC ow control. Many variants have been proposed, and they can be organized in two classes. Rate-based schemes [2, 11] propagate information about preferred transmission rates backward along a connection, while in credit-based schemes <ref> [8, 10] </ref>, each node on a VC provides information to the preceding node regarding the availability of buffer space. In either case, the goal is to ensure, with varying degrees of certainty, that cells will be forwarded over a link only when memory is available to store them. <p> In this section we first discuss the implementation of credit-based ow control; we then briey outline one possible implementation of rate-based ow control. There are many variants of credit-based ow control. They differ in granularity of the credit (incremental [1] or in bursts <ref> [7, 8, 9] </ref>), the encoding of the credit (absolute or relative), and the buffer management strategy used by the receiver (per-VC buffers, statistical sharing of buffers between VCs, etc.). Credit Net implements per-VC ow control based on the FCVC absolute credit scheme [8]. <p> Credit Net implements per-VC ow control based on the FCVC absolute credit scheme <ref> [8] </ref>. We briey explain the algorithm, using the following terminology: for a given VC and network link, data traffic travels from the upstream node to the downstream node, and credit messages travel in the reverse direction. A node can be either a host or a switch.
Reference: [9] <author> H. Kung, R. Morris, T. Charuhas, and D. Lin. </author> <title> Use of link-by-link ow control in maximizing ATM performance: Simulation results. </title> <booktitle> In Proceedings of the IEEE Hot Interconnect Symposium 93, </booktitle> <address> Palo Alto, CA, </address> <month> August </month> <year> 1993. </year> <note> IEEE. </note>
Reference-contexts: In this section we first discuss the implementation of credit-based ow control; we then briey outline one possible implementation of rate-based ow control. There are many variants of credit-based ow control. They differ in granularity of the credit (incremental [1] or in bursts <ref> [7, 8, 9] </ref>), the encoding of the credit (absolute or relative), and the buffer management strategy used by the receiver (per-VC buffers, statistical sharing of buffers between VCs, etc.). Credit Net implements per-VC ow control based on the FCVC absolute credit scheme [8].
Reference: [10] <author> C. Ozveren, R. Simcoe, and G. Varghese. </author> <title> Reliable and efficient hop-by-hop ow control. </title> <booktitle> In Proceedings of the SIGCOMM 94 Symposium on Communications Architectures and Protocols, </booktitle> <pages> pages 89100, </pages> <address> University College, London, UK, </address> <month> October </month> <year> 1994. </year> <note> ACM. </note>
Reference-contexts: One method for supporting traffic management in ATM networks is to use per-VC ow control. Many variants have been proposed, and they can be organized in two classes. Rate-based schemes [2, 11] propagate information about preferred transmission rates backward along a connection, while in credit-based schemes <ref> [8, 10] </ref>, each node on a VC provides information to the preceding node regarding the availability of buffer space. In either case, the goal is to ensure, with varying degrees of certainty, that cells will be forwarded over a link only when memory is available to store them.
Reference: [11] <author> K. K. Ramakrishnan and P. Neuman. </author> <title> Integration of rate and credit schemes for ATM ow control. </title> <journal> IEEE Network Magazine, </journal> <volume> 9(2):4956, </volume> <month> March/April </month> <year> 1995. </year>
Reference-contexts: One method for supporting traffic management in ATM networks is to use per-VC ow control. Many variants have been proposed, and they can be organized in two classes. Rate-based schemes <ref> [2, 11] </ref> propagate information about preferred transmission rates backward along a connection, while in credit-based schemes [8, 10], each node on a VC provides information to the preceding node regarding the availability of buffer space.
Reference: [12] <author> A. Romanow and S. Floyd. </author> <title> Dynamics of TCP traffic over ATM networks. </title> <booktitle> In Proceedings of the SIGCOMM 94 Symposium on Communications Architectures and Protocols, </booktitle> <pages> pages 7988, </pages> <address> University College, London, UK, </address> <month> October </month> <year> 1994. </year> <note> ACM. </note>
Reference-contexts: certain amount of buffer space, preventing blockage by bursts of data traffic that consume all available buffer space. 3 Flow Control In ATM networks, it is very important to minimize cell loss, since the loss of a single cell typically renders the entire PDU useless, usually requiring its retransmission (e.g. <ref> [12] </ref>). One method for supporting traffic management in ATM networks is to use per-VC ow control. Many variants have been proposed, and they can be organized in two classes.
Reference: [13] <author> P. A. Steenkiste. </author> <title> A systematic approach to host interface design for high-speed networks. </title> <journal> IEEE Computer, </journal> <volume> 26(3):4757, </volume> <month> March </month> <year> 1994. </year>
Reference-contexts: The buffer management strategy used by an adapter plays a pivotal role in reducing data access steps <ref> [13] </ref>. For applications to achieve low latency, their data must be able to bypass less urgent data. <p> Outboard packet buffering Outboard buffering, as exemplified by the Prototype Nectar adapter <ref> [13] </ref>, the Gigabit Nectar HIPPI adapter [14], or the HP Afterburner adapter [4], assembles and stores all packets in memory located on the adapter (Figure 2). The packets can be mapped into host kernel or user virtual memory, or DMAed into host memory.
Reference: [14] <author> P. A. Steenkiste, B. D. Zill, H. Kung, S. J. Schlick, J. Hughes, B. Kowalski, and J. Mullaney. </author> <title> A host interface architecture for high-speed networks. </title> <booktitle> In Proceedings of the 4th IFIP Conference on High Performance Networks, </booktitle> <pages> pages A3 116, </pages> <address> Liege, Belgium, </address> <month> December </month> <year> 1992. </year> <title> IFIP, </title> <publisher> Elsevier. </publisher>
Reference-contexts: Outboard packet buffering Outboard buffering, as exemplified by the Prototype Nectar adapter [13], the Gigabit Nectar HIPPI adapter <ref> [14] </ref>, or the HP Afterburner adapter [4], assembles and stores all packets in memory located on the adapter (Figure 2). The packets can be mapped into host kernel or user virtual memory, or DMAed into host memory. <p> Several techniques can be used to achieve this: use of APIs that have share semantics instead of copy semantics [3, 6, 5], use of outboard buffering to combine the application-kernel copy with the kernel-device copy <ref> [14] </ref>, or use of remapping as a replacement for the application-kernel copy. A common element of all approaches is storing the packet header separately from the data, since the header and data are generated/processed by different entities, namely the protocol stack and the application.
Reference: [15] <author> J. Stichnoth, D. OHallaron, and T. Gross. </author> <title> Generating communication for array statements: Design, implementation, and evaluation. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 21(1):150159, </volume> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: The requirements can be very simple, e.g. each packet goes in an aligned buffer, or very complicated, e.g. scatter/gather of each packet to allow efficient use by the application <ref> [3, 15] </ref>. In addition, applications of this type benefit from low per-message overhead because they send small control messages in addition to large data messages. These applications can have private buffer areas and private mailboxes.
References-found: 15

