URL: http://www.neci.nj.nec.com/homepages/lawrence/papers/search-www7/search-www7.ps.gz
Refering-URL: http://www.neci.nj.nec.com/homepages/lawrence/papers.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Inquirus, the NECI meta search engine  
Author: Steve Lawrence and C. Lee Giles 
Keyword: Information retrieval; Search engine; Meta search; Context-based search  
Address: 4 Independence Way, Princeton, NJ 08540, U.S.A.  
Affiliation: NEC Research Institute,  
Note: Appears in the Seventh International World Wide Web Conference, Brisbane, Australia, Elsevier Science, pp.  
Email: lawrence@research.nj.nec.com and giles@research.nj.nec.com  
Date: 95-105, 1998.  
Abstract: World Wide Web (WWW) search engines (e.g. AltaVista, Infoseek, HotBot, etc.) have a number of deficiencies including: periods of downtime, low coverage of the WWW, inconsistent and inefficient user interfaces, out of date databases, poor relevancy ranking and precision, and difficulties with spamming techniques. Meta search engines have been introduced which address some of these and other difficulties in searching the WWW. However, current meta search engines retain some of these difficulties and may also introduce their own problems (e.g. reduced relevance because one or more of the search engines returns results with poor relevance). We present Inquirus, the NECI meta search engine, which addresses many of the deficiencies in current techniques. Rather than working with the list of documents and summaries returned by search engines, as current meta search engines typically do, the Inquirus meta search engine works by downloading and analyzing the individual documents. The Inquirus meta search engine makes improvements over existing search engines in a number of areas, e.g.: more useful document summaries incorporating query term context, identification of both pages which no longer exist and pages which no longer contain the query terms, advanced detection of duplicate pages, improved document ranking using proximity information, dramatically improved precision for certain queries by using specific expressive forms, and quick jump links and highlighting when viewing the full documents. Keywords 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Dreilinger, D. and Howe, A., </author> <title> An information gathering agent for querying Web search engines, </title> <type> Technical Report CS-96-111, </type> <institution> Computer Science Department, Colorado State University, </institution> <year> 1996. </year>
Reference-contexts: introduction of meta search engines, e.g. MetaCrawler [5] and SavvySearch <ref> [1] </ref>. A meta search engine searches the Web by making requests to multiple search engines such as AltaVista or Infoseek.
Reference: [2] <author> Kirsch, S.T., </author> <title> Document retrieval over networks wherein ranking and relevance scores are computed at the client for multiple database documents, </title> <institution> United States Patent #5,659,732, </institution> <year> 1997. </year>
Reference-contexts: Pages are considered duplicates if the relevant context strings are identical. This allows the detection of a duplicate if the page has a different header or footer (e.g. a mailing list message archived in several places). 7. Kirsch has presented a technique for relevance ranking with meta search techniques <ref> [2] </ref> wherein the underlying search engines are modified to return extra information such as the number of occurrences of each search term in the documents and the number of occurrences in the entire database.
Reference: [3] <author> Notess, </author> <title> G.R. Internet "onesearch" with the mega search engines, </title> <booktitle> Online 20(6): </booktitle> <pages> 36-39, </pages> <year> 1996. </year>
Reference-contexts: These pages are listed after pages which properly match the query. This can be very important - different engines use different relevance techniques, and if just one engine returns poor relevance results, this can lead to poor results from standard meta search techniques <ref> [3] </ref>. Search terms in meta tags are treated as if they were part of the main text. 6. More advanced detection of duplicate pages is done. Pages are considered duplicates if the relevant context strings are identical.
Reference: [4] <author> Salton, G., </author> <title> Automatic Text Processing: The Transformation, Analysis and Retrieval of Information by Computer. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: After all pages have been downloaded the engine then relists the pages according to a simple relevance measure. This measure currently considers the number of query terms present in the document, the proximity between query terms, and term frequency (the usual inverse document frequency may also be useful <ref> [4] </ref>): (1) where N p is the number of query terms that are present in the document (each term is counted only once), N t the total number of query terms in the document (each term is counted as many times as it appears), d (i, j) is the minimum distance
Reference: [5] <author> Selberg, E. and Etzioni, O., </author> <title> Multi-service search and comparison using the MetaCrawler, </title> <booktitle> in: Proc. of the 1995 World Wide Web Conference, </booktitle> <year> 1995. </year>
Reference-contexts: introduction of meta search engines, e.g. MetaCrawler <ref> [5] </ref> and SavvySearch [1]. A meta search engine searches the Web by making requests to multiple search engines such as AltaVista or Infoseek. <p> The primary advantages of current meta search engines are the ability to combine the results of multiple search engines, and the ability to provide a consistent user interface for searching these engines [6]. The results of Selberg and Etzioni <ref> [5] </ref> suggest that the major search engines index a relatively small amount of the Web. Combining the results of multiple engines can therefore return many documents that would otherwise not be found. <p> Limited coverage. Our experience with using different search engines suggested that the coverage of the individual engines was relatively low, i.e. searching with a second engine would often return several documents which were not returned by the first engine. The results of Selberg and Etzioni <ref> [5] </ref> suggest that the coverage of any one engine is limited. Limited availability. Due to search engine and/or network difficulties, we have observed that the engine which responds the quickest varies over time. Limited user interfaces. <p> Previous work The idea of querying and collating results from multiple databases is not new. Companies like PLS (http://www.pls.com), Lexis-Nexis (http://www.lexis-nexis.com), DIALOG (http://www.dialog.com), and Verity (http://www.verity.com) have long since created systems which integrate the results of multiple heterogeneous databases <ref> [5] </ref>. Many Web meta search services exist such as the popular MetaCrawler and SavvySearch services [6,1]. 4. The Inquirus meta search engine One of the fundamental features of the Inquirus meta search engine is that it analyzes each document and displays local context around the query terms.
Reference: [6] <author> Selberg, E. and Etzioni, O., </author> <title> The MetaCrawler architecture for resource aggregation on the Web, </title> <journal> IEEE Expert, </journal> <volume> January-February: </volume> <pages> 11-14, </pages> <year> 1997, </year> <note> http://www.cs.washington.edu/homes/speed/papers/ieee/ieee-metacrawler.ps </note>
Reference-contexts: The primary advantages of current meta search engines are the ability to combine the results of multiple search engines, and the ability to provide a consistent user interface for searching these engines <ref> [6] </ref>. The results of Selberg and Etzioni [5] suggest that the major search engines index a relatively small amount of the Web. Combining the results of multiple engines can therefore return many documents that would otherwise not be found.

References-found: 6

