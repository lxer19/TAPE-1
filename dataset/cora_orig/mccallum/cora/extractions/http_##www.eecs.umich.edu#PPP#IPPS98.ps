URL: http://www.eecs.umich.edu/PPP/IPPS98.ps
Refering-URL: http://www.eecs.umich.edu/PPP/publist.html
Root-URL: http://www.cs.umich.edu
Email: fgabandah,davidsong@eecs.umich.edu  
Title: Configuration Independent Analysis for Characterizing Shared-Memory Applications  
Author: Gheith A. Abandah Edward S. Davidson 
Address: Ann Arbor  
Affiliation: Advanced Computer Architecture Laboratory, University of Michigan,  
Date: March 1998. 1  
Note: In the 12th International Parallel Processing Symposium (IPPS'98),  
Abstract: This paper demonstrates that configuration independent analysis of shared-memory applications is useful tool to characterize inherent application characteristics that do not change from one machine configuration to another. Although traditional configuration dependent analysis, or simulation, may directly provide more information about performance on specific configurations, it requires developing a machine model and repeating the analysis for each target configuration. A judicious combination of the two constitutes a comprehensive and efficient methodology. In this paper, we use configuration independent analysis to characterize seven aspects of application behavior: general characteristics; working sets; concurrency; communication patterns, variation over time, and locality; and sharing behavior. Case-studies of eight scientific and commercial benchmarks are used to illustrate the advantages and limitations of this approach. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. J. Denning, </author> <title> Working Set Model for Program Behavior, </title> <journal> Commun. ACM, </journal> <volume> vol. 11, no. 6, </volume> <pages> pp. 323333, </pages> <year> 1968. </year>
Reference-contexts: This paper addresses seven characteristics of shared-memory applications: * General characteristics of the application, including dynamic instruction count, number of distinct touched instructions, a parallel execution profile (serial and parallel phases), number of synchronization barriers and locks, I/O traffic, and percentage of memory instructions (by type). * The working set <ref> [1] </ref> of an application in an execution interval is the number of distinct memory locations accessed in this interval. The working set size is a measure of the application's temporal locality, which affects its cache performance.
Reference: [2] <author> G. Abandah, </author> <title> Tools for Characterizing Distributed Shared Memory Applications, </title> <type> Tech. Rep. </type> <institution> HPL96157, HP Labs, </institution> <month> Dec. </month> <year> 1996. </year>
Reference-contexts: CDAT is used to characterize things like cache misses and false sharing that depend on configuration parameters, e.g. cache size and line width. This paper concentrates on CIAT, more detail on other tools is in <ref> [2] </ref>. CIAT analyzes application properties that do not change from one configuration to another, thus relieving CDAT from repeating analysis methodology. this analysis for every configuration. CDAT, which uses fairly detailed models of the system coherence protocol and system state, is generally slower than CIAT.
Reference: [3] <author> Hewlett-Packard, </author> <title> PA-RISC 1.1 Architecture and Instruction Set, </title> <booktitle> third ed., </booktitle> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: CDAT, which uses fairly detailed models of the system coherence protocol and system state, is generally slower than CIAT. SMAIT has two parts: a perl script program for instrumenting PA-RISC <ref> [3] </ref> assembly language files (based on a tool called RYO [4]), and a run-time library that is linked with the instrumented program. The perl script program replaces some PA-RISC instructions with calls to run-time library subroutines.
Reference: [4] <author> D. F. Zucker and A. H. Karp, RYO: </author> <title> A Versatile Instruction Instrumentation Tool for PA-RISC, </title> <type> Tech. Rep. </type> <institution> CSLTR 95658, Stanford University, </institution> <month> Jan. </month> <year> 1995. </year>
Reference-contexts: CDAT, which uses fairly detailed models of the system coherence protocol and system state, is generally slower than CIAT. SMAIT has two parts: a perl script program for instrumenting PA-RISC [3] assembly language files (based on a tool called RYO <ref> [4] </ref>), and a run-time library that is linked with the instrumented program. The perl script program replaces some PA-RISC instructions with calls to run-time library subroutines. During program execution, the run-time library generates trace records for the instrumented memory instructions, taken branches, and synchronization and I/O calls.
Reference: [5] <author> S. Fortune and J. Wyllie, </author> <title> Parallelism in Random Access Machines, </title> <booktitle> in Proc. 10th ACM Symp. on Theory of Computing, </booktitle> <pages> pp. 114118, </pages> <year> 1978. </year>
Reference-contexts: TDAT can also analyze CDAT's traffic trace. The characterizations reported by these tools are used to support application tuning, early-stage design of scalable shared-memory systems, parameterizing synthetic work-load generators, comparing alternative design options, and investigating new design approaches. CIAT, as in the PRAM model <ref> [5] </ref>, assumes that p processors can execute p instructions concurrently and each instruction takes a fixed time. CIAT thus keeps track of time in instruction units.
Reference: [6] <author> S. Woo, M. Ohara, E. Torrie, J. Singh, and A. Gupta, </author> <title> The SPLASH-2 Programs: Characterization and Methodology Considerations, </title> <booktitle> in Proc. 22nd ISCA, </booktitle> <pages> pp. 2436, </pages> <year> 1995. </year>
Reference-contexts: CIAT identifies serial and parallel phases automatically and identifies user-defined phases delimited by special markers. CIAT reports phase characteristics at the end of each phase, and also reports aggregate characteristics over all phases. 4. Applications We have analyzed Radix, FFT, LU, and Cholesky from SPLASH-2 <ref> [6] </ref>, CG and SP from NPB [7], and TPC benchmarks C and D [8, 9]. The SPLASH-2 benchmarks are drawn from scientific, engineering, and graphics computing. NPB mimic the computation and data movement characteristics of large-scale computational fluid dynamic applications. TPC-C is an on-line transaction processing benchmark. <p> Cholesky uses many load-word instructions to find non-zero element indices of its sparse matrix. 5.2. Working Sets An application's working set size is often characterized by simulations to obtain the miss ratios of fully-associative LRU caches of various sizes <ref> [13, 6] </ref>. The knees of a graph of cache miss ratio vs. cache size then determine the working set sizes; a knee at size C indicates a working set of size C. This is a time consuming procedure.
Reference: [7] <author> D. Bailey et al., </author> <title> The NAS Parallel Benchmarks, </title> <type> Tech. Rep. </type> <institution> RNR-94-07, NASA Ames Research Center, </institution> <month> Mar. </month> <year> 1994. </year>
Reference-contexts: CIAT reports phase characteristics at the end of each phase, and also reports aggregate characteristics over all phases. 4. Applications We have analyzed Radix, FFT, LU, and Cholesky from SPLASH-2 [6], CG and SP from NPB <ref> [7] </ref>, and TPC benchmarks C and D [8, 9]. The SPLASH-2 benchmarks are drawn from scientific, engineering, and graphics computing. NPB mimic the computation and data movement characteristics of large-scale computational fluid dynamic applications. TPC-C is an on-line transaction processing benchmark.
Reference: [8] <author> Transaction Processing Performance Council, </author> <title> TPC Benchmark C, Standard Specification, </title> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: CIAT reports phase characteristics at the end of each phase, and also reports aggregate characteristics over all phases. 4. Applications We have analyzed Radix, FFT, LU, and Cholesky from SPLASH-2 [6], CG and SP from NPB [7], and TPC benchmarks C and D <ref> [8, 9] </ref>. The SPLASH-2 benchmarks are drawn from scientific, engineering, and graphics computing. NPB mimic the computation and data movement characteristics of large-scale computational fluid dynamic applications. TPC-C is an on-line transaction processing benchmark. TPC-D is a decision support application benchmark that performs complex and long-running queries against large databases.
Reference: [9] <author> Transaction Processing Performance Council, </author> <title> TPC Benchmark D, Decision Support, Standard Specification, </title> <month> May </month> <year> 1995. </year>
Reference-contexts: CIAT reports phase characteristics at the end of each phase, and also reports aggregate characteristics over all phases. 4. Applications We have analyzed Radix, FFT, LU, and Cholesky from SPLASH-2 [6], CG and SP from NPB [7], and TPC benchmarks C and D <ref> [8, 9] </ref>. The SPLASH-2 benchmarks are drawn from scientific, engineering, and graphics computing. NPB mimic the computation and data movement characteristics of large-scale computational fluid dynamic applications. TPC-C is an on-line transaction processing benchmark. TPC-D is a decision support application benchmark that performs complex and long-running queries against large databases.
Reference: [10] <institution> Transaction Processing Performance Council Home Page. </institution> <note> http://www.tpc.org/. </note>
Reference-contexts: The TPC-D analysis presented in this paper is for a 2.8-Giga instruction trace representing the third phase of Query 3 where most of the query's time is spent. Compared with other queries, although Query 3 takes a moderate run time, it has high disk I/O and communication rates <ref> [10] </ref>. A comprehensive characterization of TPC-D's queries is beyond the scope of this paper. Table 1 shows the set of problem sizes analyzed in this study. For conducting comparisons, smaller problem sizes were also analyzed, as reported in [11].
Reference: [11] <author> G. Abandah and E. Davidson, </author> <title> Configuration Independent Analysis for Characterizing Shared-Memory Applications, </title> <type> Tech. Rep. </type> <institution> CSE-TR-357-98, University of Michigan, </institution> <month> Jan. </month> <year> 1998. </year> <note> http://www.eecs.umich.edu/home/techreports/compsci.html. </note>
Reference-contexts: A comprehensive characterization of TPC-D's queries is beyond the scope of this paper. Table 1 shows the set of problem sizes analyzed in this study. For conducting comparisons, smaller problem sizes were also analyzed, as reported in <ref> [11] </ref>. The scientific benchmarks were analyzed on 1 to 32 processors using the default options. We analyzed the Convex Exemplar [12] implementation of NPB. However, to get a general characterization of these benchmarks, we undid some of the Exemplar-specific optimizations. <p> For an S-byte cache, every access with age S is a hit, every access with age = 1 generates a compulsory miss, and every access with age &gt; S generates a capacity miss. CIAT uses an efficient algorithm to find the access age, as described in <ref> [11] </ref>. processors, ignoring infinite ages. A point (x; y) indicates that y% of the accesses have access age x bytes. A distinguishable rise to a plateau beginning at x bytes indicates that the respective benchmark has an important working set of size x. <p> For more detail, see <ref> [11] </ref>. 5.6. Communication Locality CIAT characterizes communication locality by reporting (in the matrix COMM MAT) the number of communication events for each processor pair. <p> This indicates that parallelism is exploited functionally between two 8-process groups and spatially by partitioning the data into 8 parts. The communication matrices of the other benchmarks are available in <ref> [11] </ref>. 5.7. Sharing Behavior The data presented in this section is based on analyzing the code and data accesses of the whole execution, including the serial phase. Figure 10 shows the number of referenced memory locations in three classes: code locations, private data locations, and shared data locations.
Reference: [12] <author> T. Brewer, </author> <title> A Highly Scalable System Utilizing up to 128 PA-RISC Processors, </title> <booktitle> in Digest of Papers, COMPCON'95, </booktitle> <pages> pp. 133140, </pages> <month> Mar. </month> <year> 1995. </year>
Reference-contexts: Table 1 shows the set of problem sizes analyzed in this study. For conducting comparisons, smaller problem sizes were also analyzed, as reported in [11]. The scientific benchmarks were analyzed on 1 to 32 processors using the default options. We analyzed the Convex Exemplar <ref> [12] </ref> implementation of NPB. However, to get a general characterization of these benchmarks, we undid some of the Exemplar-specific optimizations. The six scientific benchmarks were instrumented, compiled, and analyzed on a 4-node Exemplar SPP1600 running SPP-UX 4.2.
Reference: [13] <author> E. Rothberg, J. Singh, and A. Gupta, </author> <title> Working Sets, Cache Sizes, and Node Granularity Issues for Large-Scale Multiprocessors, </title> <booktitle> in Proc. 20th ISCA, </booktitle> <pages> pp. 1425, </pages> <year> 1993. </year>
Reference-contexts: Cholesky uses many load-word instructions to find non-zero element indices of its sparse matrix. 5.2. Working Sets An application's working set size is often characterized by simulations to obtain the miss ratios of fully-associative LRU caches of various sizes <ref> [13, 6] </ref>. The knees of a graph of cache miss ratio vs. cache size then determine the working set sizes; a knee at size C indicates a working set of size C. This is a time consuming procedure.
Reference: [14] <author> J. Singh, E. Rothberg, and A. Gupta, </author> <title> Modeling Communication in Parallel Algorithms: A Fruitful Interaction between Theory and Systems?, </title> <booktitle> in Proc. Symp. Parallel Algorithms and Architectures, </booktitle> <pages> pp. 189199, </pages> <year> 1994. </year> <month> 7 </month>
Reference-contexts: Communication Patterns Total (inherent plus artifactual) communication is the traffic generated by processors when accessing data that is not allocated in its local memory, including traffic due to inherent coherence communication, cold-start misses, finite cache capacity, limited cache associativity, and false sharing <ref> [14] </ref>. Inherent communication is that which must occur in order to access a shared location, assuming that unlimited replication is allowed and that a memory location's status is not affected by accesses to other locations (i.e. no false sharing). CDAT reports total communication; CIAT, inherent communication.
References-found: 14

