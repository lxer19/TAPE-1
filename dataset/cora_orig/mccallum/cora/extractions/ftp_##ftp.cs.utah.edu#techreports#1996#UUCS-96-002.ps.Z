URL: ftp://ftp.cs.utah.edu/techreports/1996/UUCS-96-002.ps.Z
Refering-URL: ftp://ftp.cs.utah.edu/techreports/1996/index.html
Root-URL: 
Email: E-mail: fswanson,kuramkot,stoller,ttateyamg@cs.utah.edu  
Title: Message Passing Support in the Avalanche Widget  
Author: Mark R. Swanson Ravindra Kuramkote Leigh B. Stoller Terry Tateyama 
Date: March 10, 1996  
Address: Salt Lake City, UT 84112, USA  
Affiliation: Department of Computer Science University of Utah  
Web: WWW: http://www.cs.utah.edu/projects/avalanche UUCS-96-002  
Abstract: Minimizing communication latency in message passing multiprocessing systems is critical. An emerging problem in these systems is the latency contribution costs caused by the need to percolate the message through the memory hierarchy (at both sending and receiving nodes) and the additional cost of managing consistency within the hierarchy. This paper, considers three important aspects of these costs: cache coherence, message copying, and cache miss rates. The paper then shows via a simulation study how a design called the Widget can be used with existing commercial workstation technology to significantly reduce these costs to support efficient message passing in the Avalanche multiprocessing system. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Banks, D., and Prudence, M. </author> <title> A High-Performance Network Architecture for a PA-RISC Workstation. </title> <journal> IEEE Journal on Selected Areas in Communications 11, </journal> <month> 2 (February </month> <year> 1993), </year> <pages> 191-202. </pages>
Reference-contexts: is the processor freed from explicit flush actions and attendant delays and explicit synchronization, but savings in system bus bandwidth can also be realized if data can be moved directly between the cache and the network interface. 2.2 Message Copying Message copying costs have been the subject of many studies <ref> [1, 12, 4] </ref>. A common theme is that the initial attack on this cost should focus on the message passing software.
Reference: [2] <author> Boden, N., cohen, D., R.Felderman, Kulawik, A., Seitz, C., Seizovic, J., and Su, W. Myrinet: </author> <title> A Gigabit-per-Second Local Area Network. </title> <booktitle> IEEE Micro 15, </booktitle> <month> 1 (February </month> <year> 1995), </year> <pages> 29-36. </pages>
Reference-contexts: We model a bus similar to HP's Runway bus [8] that operates at 120 MHz, is 64 bits wide, and delivers an effective bandwidth of 768 MB per second. The interconnect in our simulations is based on Myrinet <ref> [2] </ref>; we model a 160 MHz, 8-bit wide, full duplex connection to the fabric switch, with 1 cycle transmission delays to and between switches, and a switch fallthrough time of 45 cycles (at 160 MHz). 4.2 Simulation Results In Table 2, the latencies of fundamental operations used to implement message passing
Reference: [3] <author> Carter, J., and Kuramkote, R. </author> <title> Avalanche: Cache and DSM Protocol Design. </title> <type> Tech. rep., </type> <institution> University of Utah, </institution> <month> Apr. </month> <year> 1995. </year>
Reference-contexts: This paper primarily discusses the message passing aspects of the Widget. The distributed shared memory aspects are described in <ref> [3] </ref>. Efficiency in message passing encompasses several cost components. Traditionally, the metrics have been latency and bandwidth. They are not however independent metrics, and from the application perspective the important metric is latency.
Reference: [4] <author> Druschel, P., and Peterson, L. Fbufs: </author> <title> A High-Bandwidth Cross-Domain Transfer Facility. </title> <booktitle> In Proceedings of the Fourteenth ACM Symposium on Operating System Principles (December 1993), </booktitle> <pages> pp. 189-202. </pages>
Reference-contexts: is the processor freed from explicit flush actions and attendant delays and explicit synchronization, but savings in system bus bandwidth can also be realized if data can be moved directly between the cache and the network interface. 2.2 Message Copying Message copying costs have been the subject of many studies <ref> [1, 12, 4] </ref>. A common theme is that the initial attack on this cost should focus on the message passing software.
Reference: [5] <author> Hewlett-Packard Co. </author> <title> PA-RISC 1.1 Architecture and Instruction Set Reference Manual, </title> <month> Febru-ary </month> <year> 1994. </year>
Reference-contexts: PAINT provides cycle-by-cycle simulations of a distributed memory multicomputer composed of HP PA-RISC processors <ref> [5] </ref>; it is based on the MINT simulator developed by Veenstra [13]. In keeping with HP's system design approach, the memory hierarchy we model consists of just two levels: a large, direct mapped, virtually indexed, coherent, single level cache and a main memory on a high frequency, split transaction bus.
Reference: [6] <author> Kronenberg, N., Levy, H., and Strecker, W. </author> <title> An Analysis of TCP Processing Overhead. </title> <journal> ACM Transactions on Computer Systems 4, </journal> <month> 2 (May </month> <year> 1986), </year> <pages> 130-146. </pages>
Reference-contexts: A common theme is that the initial attack on this cost should focus on the message passing software. In this paper we assume use of software, such as Direct Deposit [11], a sender-based protocol <ref> [14, 6] </ref>, that supports direct transfers of message data between user process memory and the network interface.
Reference: [7] <author> Kubiatowicz, J., and Agarwal, A. </author> <title> Anatomy of a Message in the Alewife Multiprocessor. </title> <booktitle> In Proceedings of the 7th ACM International Conference on Supercomputing (July 1993). </booktitle>
Reference-contexts: Alewife <ref> [7] </ref> represents one of the earliest hybrid distributed shared memory/explicit message passing systems. Its approach was very invasive, requiring fabrication of a custom version of a SPARC [10] cpu.
Reference: [8] <author> Kurpanek, G., Chan, K., Zheng, J., DeLano, E., and Bryg, W. PA7200: </author> <title> A PA-RISC Processor with Integrated High Performance MP Bus Interface. </title> <booktitle> In digest of papers, </booktitle> <month> Spring COM-PCON 94 (March </month> <year> 1994), </year> <pages> pp. 378-382. </pages>
Reference-contexts: In particular, we model single-issue processors running at 120 MHz with non-blocking writes, read interlocks, and up to 6 outstanding cache misses. We model a bus similar to HP's Runway bus <ref> [8] </ref> that operates at 120 MHz, is 64 bits wide, and delivers an effective bandwidth of 768 MB per second.
Reference: [9] <author> Kuskin, J., Ofelt, D., Heinrich, M., Heinlein, J., Simoni, R., Gharachorloo, K., Chapin, J., Nakahira, D., Baxter, J., Horowitz, M., Gupta, A., Rosenblum, M., and Hennessy, J. </author> <title> The Stanford FLASH Multiprocessor. </title> <booktitle> In Proceedings of the 21st International Symposium on Computer Architecture (April 19943), </booktitle> <pages> pp. 302-313. </pages>
Reference-contexts: Data and control are separated at the periphery of the device in much the same way as they are in the Flash project's MAGIC <ref> [9] </ref>. Message data, whether outgoing or incoming, is staged in the Shared Buffer (SB), which is a dual-ported SRAM array logically arranged into 128-byte lines.
Reference: [10] <institution> SUN Microsystems, Mountain View, CA. SPARC Architecture Manual, </institution> <year> 1988. </year>
Reference-contexts: Alewife [7] represents one of the earliest hybrid distributed shared memory/explicit message passing systems. Its approach was very invasive, requiring fabrication of a custom version of a SPARC <ref> [10] </ref> cpu. Message handling received little support, other than limited DMA capability, necessitating significant processor involvement in message reception and a high reliance on interrupts. Alewife implemented local cache coherence, as does the Avalanche Widget. Little is reported on the memory system performance implications of their design.
Reference: [11] <author> Swanson, M., and Stoller, L. </author> <title> Direct Deposit: A Basic User-Level Protocol for Carpet Clusters. </title> <type> Tech. Rep. </type> <institution> UUCS-95-003, Compuer Systems Laboratory, University of Utah, </institution> <month> September </month> <year> 1995. </year>
Reference-contexts: A common theme is that the initial attack on this cost should focus on the message passing software. In this paper we assume use of software, such as Direct Deposit <ref> [11] </ref>, a sender-based protocol [14, 6], that supports direct transfers of message data between user process memory and the network interface.
Reference: [12] <author> Thekkath, C., and Levy, H. </author> <title> Limits to Low-Latency Communications on High-Speed Networks. </title> <journal> ACM Transactions on Computer Systems 11, </journal> <month> 2 (May </month> <year> 1993), </year> <pages> 179-203. </pages>
Reference-contexts: is the processor freed from explicit flush actions and attendant delays and explicit synchronization, but savings in system bus bandwidth can also be realized if data can be moved directly between the cache and the network interface. 2.2 Message Copying Message copying costs have been the subject of many studies <ref> [1, 12, 4] </ref>. A common theme is that the initial attack on this cost should focus on the message passing software.
Reference: [13] <author> Veenstra, J., and Fowler, R. Mint: </author> <title> A Front End for Efficient Simulation of Shared-Memory Multiprocessors. </title> <note> In MASCOTS 94 (January 1994). </note>
Reference-contexts: PAINT provides cycle-by-cycle simulations of a distributed memory multicomputer composed of HP PA-RISC processors [5]; it is based on the MINT simulator developed by Veenstra <ref> [13] </ref>. In keeping with HP's system design approach, the memory hierarchy we model consists of just two levels: a large, direct mapped, virtually indexed, coherent, single level cache and a main memory on a high frequency, split transaction bus.
Reference: [14] <author> Wilkes, J. </author> <title> Hamlyn an interface for sender-based communication. </title> <type> Tech. Rep. </type> <institution> HPL-OSR-92-13, Hewlett-Packard Research Laboratory, </institution> <month> November </month> <year> 1992. </year> <month> 14 </month>
Reference-contexts: A common theme is that the initial attack on this cost should focus on the message passing software. In this paper we assume use of software, such as Direct Deposit [11], a sender-based protocol <ref> [14, 6] </ref>, that supports direct transfers of message data between user process memory and the network interface.
References-found: 14

