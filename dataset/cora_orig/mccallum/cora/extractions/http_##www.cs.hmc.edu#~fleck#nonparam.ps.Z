URL: http://www.cs.hmc.edu/~fleck/nonparam.ps.Z
Refering-URL: http://www.cs.hmc.edu/~fleck/iowa-lab/wide.html
Root-URL: http://www.cs.hmc.edu
Email: des@cs.uiowa.edu mfleck@cs.uiowa.edu  
Title: Nonparametric Correction of Distortion 1 Nonparametric Correction of Distortion  
Author: Daniel E. Stevenson Margaret M. Fleck 
Keyword: Category: imaging geometry and camera calibration  
Date: October 1995  
Address: Iowa City, IA 52242 USA  
Affiliation: Department of Computer Science University of Iowa  
Abstract: Previous work on camera calibration, and particularly work on self-calibration, has assumed that the camera is well modeled by an ideal, relatively simple, parametric model. Real camera systems, however, diverge significantly from a simple pinhole perspective imaging model. Therefore, parametric calibration models are typically extended to include parameters which model distortions from perspective. However, fitting these extra parameters greatly complicates calibration algorithms. This paper presents a new approach to camera calibration, which avoids elaborate parametric models. The imaging geometry of a camera is modeled by a 3 degree-of-freedom stereographic imaging model, together with a smooth distortion function D. D maps the raw camera output to the ideal model, subsuming the effects of traditional parametric distortion parameters. The calibration algorithm reconstructs D from images of spheres, using the fact that spheres must appear circular in ideal stereographic projection. Accuracy and stability results for this algorithm are presented. The remaining free parameters (image center and focal length) can be estimated using several standard methods. New methods are presented for estimating the focal length (given the image center) using a single unknown image rotation and for pasting several images, taken by rotating the camera, into a panoramic image. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Brown, </author> <title> D.C. (1971) "Close-range Camera Calibration," </title> <booktitle> Photogrammetric Engineering 37, </booktitle> <pages> pp. 855-866. </pages>
Reference-contexts: A variety of methods have been proposed for locating the image center in the presence of radial distortion <ref> [1, 4, 15, 16, 17, 24] </ref>. Some algorithms [1, 23] estimate the image center as part of a larger monolithic optimization. <p> A variety of methods have been proposed for locating the image center in the presence of radial distortion [1, 4, 15, 16, 17, 24]. Some algorithms <ref> [1, 23] </ref> estimate the image center as part of a larger monolithic optimization. However, it is known that this parameter is poorly determined by the image data: large changes in the position of the image center generate only small changes in image appearance [15, 24, 25]. <p> However, it is known that this parameter is poorly determined by the image data: large changes in the position of the image center generate only small changes in image appearance [15, 24, 25]. Thus, accurate algorithms for locating the image center require very high precision measurements <ref> [1, 15] </ref>. This paper presents a new approach to camera calibration, which avoids elaborate parametric models. The imaging geometry of a camera is modeled by 1) a 3 degree-of-freedom stereographic imaging model, together with 2) a smooth distortion function D mapping the actual camera output onto this ideal model. <p> Images of spheres have been used to estimate the image center and focal length of perspective images [2, 3]. As discussed above, these methods cannot cope robustly with non-trivial radial distortion. The plumb line algorithm for correcting an image to perspective projection <ref> [1, 22] </ref> (also used by [2, 23]) is based on a similar idea. That is, straight 3D lines should appear straight in an ideal perspective image. The algorithm examines images of many straight lines, and builds a distortion function which straightens all the lines as well as possible. <p> That is, straight 3D lines should appear straight in an ideal perspective image. The algorithm examines images of many straight lines, and builds a distortion function which straightens all the lines as well as possible. However, the specific algorithm <ref> [1] </ref> used to do this correction is parametric and involves a cumbersome optimization process. More importantly, the plumb line method cannot calibrate the aspect ratio of the camera system, because the distortion created by unequal horizontal and vertical distances preserves straightness of lines.
Reference: [2] <author> Beardsley, Paul, </author> <title> David Murray and Andrew Zisserman (1992) "Camera Calibration Using Multiple Images," </title> <booktitle> European Conf. Comp. Vision 1992, </booktitle> <pages> pp. 312-320. </pages>
Reference-contexts: Not one of our lenses is a good approximation to the standard pinhole perspective model. The divergence from perspective can change the apparent shape of objects as much, or more, than the elongation of peripheral regions in ideal perspective images. Two recent papers <ref> [2, 3] </ref> have proposed estimating the image center and focal length using the fact that spheres in perspective projection appear elongated towards the image center, after first pre-processing to correct radial distortion. <p> Penna [18] used images of spheres to correct the aspect ratio of narrow-angle perspective images. Our algorithm corrects a larger number of parameters, and works on wide-angle images. Images of spheres have been used to estimate the image center and focal length of perspective images <ref> [2, 3] </ref>. As discussed above, these methods cannot cope robustly with non-trivial radial distortion. The plumb line algorithm for correcting an image to perspective projection [1, 22] (also used by [2, 23]) is based on a similar idea. <p> Images of spheres have been used to estimate the image center and focal length of perspective images [2, 3]. As discussed above, these methods cannot cope robustly with non-trivial radial distortion. The plumb line algorithm for correcting an image to perspective projection [1, 22] (also used by <ref> [2, 23] </ref>) is based on a similar idea. That is, straight 3D lines should appear straight in an ideal perspective image. The algorithm examines images of many straight lines, and builds a distortion function which straightens all the lines as well as possible.
Reference: [3] <author> Daucher, N., M. Dhome, and J.T. </author> <title> Lapreste (1994) "Camera Calibration From Spheres Images," </title> <booktitle> European Conf. Comp. Vision 1994, </booktitle> <pages> pp. 449-454. </pages> <note> Nonparametric Correction of Distortion 21 </note>
Reference-contexts: Not one of our lenses is a good approximation to the standard pinhole perspective model. The divergence from perspective can change the apparent shape of objects as much, or more, than the elongation of peripheral regions in ideal perspective images. Two recent papers <ref> [2, 3] </ref> have proposed estimating the image center and focal length using the fact that spheres in perspective projection appear elongated towards the image center, after first pre-processing to correct radial distortion. <p> Penna [18] used images of spheres to correct the aspect ratio of narrow-angle perspective images. Our algorithm corrects a larger number of parameters, and works on wide-angle images. Images of spheres have been used to estimate the image center and focal length of perspective images <ref> [2, 3] </ref>. As discussed above, these methods cannot cope robustly with non-trivial radial distortion. The plumb line algorithm for correcting an image to perspective projection [1, 22] (also used by [2, 23]) is based on a similar idea.
Reference: [4] <author> Du, </author> <title> Fenglei and Michael Brady (1993) "Self-Calibration of the Intrinsic Parameters of Cameras for Active Vision Systems," </title> <booktitle> Proc. IEEE Conf. Comp. Vision and Pattern Recogn. </booktitle> <year> 1993, </year> <pages> pp. 477-482. </pages>
Reference-contexts: A variety of methods have been proposed for locating the image center in the presence of radial distortion <ref> [1, 4, 15, 16, 17, 24] </ref>. Some algorithms [1, 23] estimate the image center as part of a larger monolithic optimization.
Reference: [5] <author> Faugeras, </author> <title> Olivier (1992) "Camera Self-Calibration: Theory and Experiment," </title> <booktitle> Euro-pean Conf. Comp. Vision 1992, </booktitle> <pages> pp. 321-334. </pages>
Reference-contexts: Lenses are commercially available with fields of view up to 220 ffi . Details of optical designs can be found in [14, 19, 21]. It is frequently assumed that most video camera lenses are nominally perspective, and that the divergences from this ideal model are insignificant (e.g. <ref> [5] </ref>). This is not the case. Figure 1 shows the measured radial projection functions r for our eight C-mount and micro-camera lenses, ranging from a 50 ffi (normal field of view) lens and a 30 ffi 60 ffi zoom lens, to a 116 ffi degree wide-angle lens.
Reference: [6] <author> Fiala, John C., Ronald Lumia, Karen J. Roberts, and Albert J. </author> <month> Wavering </month> <year> (1994) </year> <month> "TRICLOPS: </month> <title> A Tool for Studying Active Vision," </title> <journal> Intern. J. of Comp. </journal> <pages> Vision 12/2-3, pp. 231-250. </pages>
Reference: [7] <author> Fleck, Margaret M. </author> <title> (1995) "Perspective Projection: the Wrong Imaging Model," </title> <type> TR 95-01, </type> <institution> Comp. Sci., U. Iowa. </institution>
Reference-contexts: Stereographic is conformal (preserves local shape) and projects circles on the viewing sphere (including images of 3D spheres) onto circles and lines in the planar image [10, 13]. Three of the projections support fields of view above 180 ffi : stereographic, equidistant, and equi-solid angle. (See <ref> [7] </ref> for details and proofs.) Nonparametric Correction of Distortion 5 Perspective projection is the most popular ideal camera model. <p> The other four ("fisheye") projections expand peripheral areas less and, thus, reduce intensity drop-off <ref> [7, 14, 19] </ref>. Therefore, 35mm lenses with fields of view wider than 120 ffi 140 ffi and C-mount lenses with fields of view wider than 60 ffi 80 ffi are designed to approximate a fisheye projection model. Lenses are commercially available with fields of view up to 220 ffi . <p> It can represent fields of view up to about 250 ffi , before peripheral expansion creates practical problems, whereas perspective is limited to less than 140 ffi (figure 2). The images of 3D spheres are circles and, thus, the images of 3D local symmetries have 2D local symmetries <ref> [7] </ref>. Stereographic projection maps the viewing sphere conformally onto the planar image. Therefore, an object subtending a small visual angle has the same shape (though not the same size) no matter where it appears in the field of view. <p> Instead, we will specify what properties the output of D must satisfy and our algorithm will reconstruct a function whose output satisfies them. Specifically, in ideal stereographic projection, images of 3D spheres appear circular, no matter what their size <ref> [7, 10, 13] </ref>. Our calibration algorithm is given images of spheres, taken with an uncalibrated camera. We assume that D is well approximated locally as an affine transformation, and that affine parameters vary only slowly across the image.
Reference: [8] <author> Floriani, </author> <title> Leila De and Enrico Puppo (1988) "Constrained Delaunay Triangulation for Multiresolution Surface Description," </title> <booktitle> Proceedings of the 9th International Conference on Pattern Recognition Roma, </booktitle> <address> Italy. </address> <month> Nov </month> <year> 1988. </year> <pages> pp. 566-569. </pages>
Reference-contexts: Alternatively, we could use smaller ellipses near the image edges. 4.2 Triangulation We then construct a constrained Delaunay triangulation, using the ellipse centers as vertices. We use an incremental algorithm <ref> [8, 9] </ref>, which must be given a polygonal region R of the plane to triangulate. If extrapolation to the extreme edges of the image is required, R should be the outer boundary of the image. However, the calibration function is significantly less accurate when extrapolation is required.
Reference: [9] <author> Guibas, </author> <title> Leonidas and Jorge Stolfi (1985) "Primitives for the Manipulation of General Subdivisions and the Computation of Voronoi Diagrams," </title> <journal> ACM Transactions on Graphics Vol. </journal> <volume> 4, No. 2, </volume> <month> April </month> <year> 1985. </year> <pages> pp. 74-123. </pages>
Reference-contexts: Alternatively, we could use smaller ellipses near the image edges. 4.2 Triangulation We then construct a constrained Delaunay triangulation, using the ellipse centers as vertices. We use an incremental algorithm <ref> [8, 9] </ref>, which must be given a polygonal region R of the plane to triangulate. If extrapolation to the extreme edges of the image is required, R should be the outer boundary of the image. However, the calibration function is significantly less accurate when extrapolation is required.
Reference: [10] <author> Hahn, Liang-shin, </author> <title> Complex Numbers and Geometry, </title> <booktitle> Mathematical Association of America, </booktitle> <address> Washington D.C. </address> <year> 1994. </year>
Reference-contexts: The form of D is constrained by the fact that its output must be a stereographic image. Stereographic images of 3D are characterized by the fact that images of spheres are always circular <ref> [10, 13] </ref>. We present an algorithm that, given images of spheres, constructs a function D which will make these images near-circular. <p> Equi-solid angle projection preserves viewing sphere areas in the planar image [19]. Stereographic is conformal (preserves local shape) and projects circles on the viewing sphere (including images of 3D spheres) onto circles and lines in the planar image <ref> [10, 13] </ref>. Three of the projections support fields of view above 180 ffi : stereographic, equidistant, and equi-solid angle. (See [7] for details and proofs.) Nonparametric Correction of Distortion 5 Perspective projection is the most popular ideal camera model. <p> Instead, we will specify what properties the output of D must satisfy and our algorithm will reconstruct a function whose output satisfies them. Specifically, in ideal stereographic projection, images of 3D spheres appear circular, no matter what their size <ref> [7, 10, 13] </ref>. Our calibration algorithm is given images of spheres, taken with an uncalibrated camera. We assume that D is well approximated locally as an affine transformation, and that affine parameters vary only slowly across the image. <p> One can then position the image of a distant object at the image center and observe its motion under a measured rotation. For many applications, a rough estimate of the focal length constant (equivalently, the field of view) is sufficient. Because stereographic projection is conformal <ref> [10, 13] </ref>, objects subtending small visual angles have approximately the same shape regardless of where they appear in the field of view, as illustrated in figure 5. <p> Any two stereographic images, taken with fixed center of projection, are related by a Moebius transformation of the plane <ref> [10, 13] </ref>. That is, pick any arbitrary point to be the center of the image, and treat image coordinates as complex numbers.
Reference: [11] <author> Haralick, Robert M. and Linda G. Shapiro, </author> <title> Computer and Robot Vision, volume I, </title> <publisher> Addison-Wesley Publishing Co. </publisher> <address> Reading, MA. </address> <year> 1992. </year>
Reference-contexts: Then a 4-connected component algorithm is used to separate the sphere images from each other. An ellipse is fit to each sphere image, using moments to compute the major and minor axes <ref> [11, 20] </ref>. We use a moment-based technique because it produces more stable fits than an edge-based technique [20]. We do not believe that our method requires high accuracy from the test spheres or the ellipse fitter, unless the application requires the output calibration to have high accuracy.
Reference: [12] <author> Hartley, Richard I. </author> <title> (1994) "Self-Calibration from Multiple Views with a Rotating Camera," </title> <booktitle> European Conf. Comp. Vision 1994, </booktitle> <volume> vol. </volume> <pages> I., 471-478. </pages>
Reference-contexts: The other parameters can be reconstructed similarly. For example, fi = 2arctan ( q AD ). This method works for an arbitrary, unknown rotation about the camera center, so long as fi is large enough to ensure numerical stability. The general idea is similar to that used in <ref> [12] </ref> to calibrate an ideal perspective camera. However, assuming stereographic projection Nonparametric Correction of Distortion 20 and an estimate for the image center greatly simplifies the equations. (The equations can be solved, as in [12], without the image center, but measurements from more than one rotation are required.) 8 Conclusions This <p> The general idea is similar to that used in <ref> [12] </ref> to calibrate an ideal perspective camera. However, assuming stereographic projection Nonparametric Correction of Distortion 20 and an estimate for the image center greatly simplifies the equations. (The equations can be solved, as in [12], without the image center, but measurements from more than one rotation are required.) 8 Conclusions This paper has presented a new method for calibrating images, in which a free-form distortion function is used to convert the raw camera output into an ideal stereographic image.
Reference: [13] <author> Hilbert, D. and S. Cohn-Vossen, </author> <title> Geometry and the Imagination, </title> <publisher> Chelsea Publishing Co., </publisher> <address> New York, </address> <note> second edition, </note> <year> 1990, </year> <title> translation by P. </title> <booktitle> Nemenyi of Anschauliche Ge-ometrie, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1932. </year>
Reference-contexts: The form of D is constrained by the fact that its output must be a stereographic image. Stereographic images of 3D are characterized by the fact that images of spheres are always circular <ref> [10, 13] </ref>. We present an algorithm that, given images of spheres, constructs a function D which will make these images near-circular. <p> Equi-solid angle projection preserves viewing sphere areas in the planar image [19]. Stereographic is conformal (preserves local shape) and projects circles on the viewing sphere (including images of 3D spheres) onto circles and lines in the planar image <ref> [10, 13] </ref>. Three of the projections support fields of view above 180 ffi : stereographic, equidistant, and equi-solid angle. (See [7] for details and proofs.) Nonparametric Correction of Distortion 5 Perspective projection is the most popular ideal camera model. <p> Instead, we will specify what properties the output of D must satisfy and our algorithm will reconstruct a function whose output satisfies them. Specifically, in ideal stereographic projection, images of 3D spheres appear circular, no matter what their size <ref> [7, 10, 13] </ref>. Our calibration algorithm is given images of spheres, taken with an uncalibrated camera. We assume that D is well approximated locally as an affine transformation, and that affine parameters vary only slowly across the image. <p> One can then position the image of a distant object at the image center and observe its motion under a measured rotation. For many applications, a rough estimate of the focal length constant (equivalently, the field of view) is sufficient. Because stereographic projection is conformal <ref> [10, 13] </ref>, objects subtending small visual angles have approximately the same shape regardless of where they appear in the field of view, as illustrated in figure 5. <p> Any two stereographic images, taken with fixed center of projection, are related by a Moebius transformation of the plane <ref> [10, 13] </ref>. That is, pick any arbitrary point to be the center of the image, and treat image coordinates as complex numbers.
Reference: [14] <author> Kingslake, Rudolf, </author> <title> A History of the Photographic Lens, </title> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1989. </year>
Reference-contexts: The other four ("fisheye") projections expand peripheral areas less and, thus, reduce intensity drop-off <ref> [7, 14, 19] </ref>. Therefore, 35mm lenses with fields of view wider than 120 ffi 140 ffi and C-mount lenses with fields of view wider than 60 ffi 80 ffi are designed to approximate a fisheye projection model. Lenses are commercially available with fields of view up to 220 ffi . <p> Lenses are commercially available with fields of view up to 220 ffi . Details of optical designs can be found in <ref> [14, 19, 21] </ref>. It is frequently assumed that most video camera lenses are nominally perspective, and that the divergences from this ideal model are insignificant (e.g. [5]). This is not the case.
Reference: [15] <author> Lenz, Reimar K. and Roger Y. </author> <title> Tsai (1988) "Techniques for Calibration of the Scale Factor and Image Center for High Accuracy 3-D Machine Vision Metrology," </title> <journal> IEEE PAMI 10/5, </journal> <pages> pp. 713-720. </pages>
Reference-contexts: A variety of methods have been proposed for locating the image center in the presence of radial distortion <ref> [1, 4, 15, 16, 17, 24] </ref>. Some algorithms [1, 23] estimate the image center as part of a larger monolithic optimization. <p> Some algorithms [1, 23] estimate the image center as part of a larger monolithic optimization. However, it is known that this parameter is poorly determined by the image data: large changes in the position of the image center generate only small changes in image appearance <ref> [15, 24, 25] </ref>. Thus, accurate algorithms for locating the image center require very high precision measurements [1, 15]. This paper presents a new approach to camera calibration, which avoids elaborate parametric models. <p> However, it is known that this parameter is poorly determined by the image data: large changes in the position of the image center generate only small changes in image appearance [15, 24, 25]. Thus, accurate algorithms for locating the image center require very high precision measurements <ref> [1, 15] </ref>. This paper presents a new approach to camera calibration, which avoids elaborate parametric models. The imaging geometry of a camera is modeled by 1) a 3 degree-of-freedom stereographic imaging model, together with 2) a smooth distortion function D mapping the actual camera output onto this ideal model. <p> Whether these parameters are required and, if required, how precisely they must be determined, depends on the application and the camera's field of view. Without high-precision measurements (e.g. as in <ref> [15] </ref>), the image center can only be located to perhaps 5 ffi [24]. However, conversely, even a 20 pixel displacement of the image center may cause only sub-pixel displacement of image features [15]. <p> Without high-precision measurements (e.g. as in <ref> [15] </ref>), the image center can only be located to perhaps 5 ffi [24]. However, conversely, even a 20 pixel displacement of the image center may cause only sub-pixel displacement of image features [15]. For applications requiring only moderate precision, e.g. object recognition, the center of the CCD array can be used as an estimate of the image center [15, 24, 25]. <p> However, conversely, even a 20 pixel displacement of the image center may cause only sub-pixel displacement of image features [15]. For applications requiring only moderate precision, e.g. object recognition, the center of the CCD array can be used as an estimate of the image center <ref> [15, 24, 25] </ref>.
Reference: [16] <author> Li, </author> <title> Mengxiang (1994) "Camera Calibration of a Head-Eye System for Active Vision," </title> <booktitle> European Conf. Comp. Vision 1994, </booktitle> <pages> pp. 543-554. </pages>
Reference-contexts: A variety of methods have been proposed for locating the image center in the presence of radial distortion <ref> [1, 4, 15, 16, 17, 24] </ref>. Some algorithms [1, 23] estimate the image center as part of a larger monolithic optimization.
Reference: [17] <author> Oh, Sung Jun and Ernest L. </author> <title> Hall (1989) "Calibration of an Omnidirectional Vision Navigation System Using an Industrial Robot," </title> <booktitle> Optical Engineering 28/9, </booktitle> <pages> pp. 955-962. </pages> <note> Nonparametric Correction of Distortion 22 </note>
Reference-contexts: A variety of methods have been proposed for locating the image center in the presence of radial distortion <ref> [1, 4, 15, 16, 17, 24] </ref>. Some algorithms [1, 23] estimate the image center as part of a larger monolithic optimization.
Reference: [18] <author> Penna, M.A. </author> <title> (1991) "Camera Calibration: A quick and Easy Way to Determine the Scale Factor," </title> <journal> IEEE Trans. Pattern Anal. Machine Intell. </journal> <volume> 13, </volume> <pages> pp. 1240-1245. </pages>
Reference-contexts: Figure 6 shows that the algorithm can also correct these larger deviations from stereographic projection. Images of spheres have been used in other camera calibration algorithms, but not in this way. Penna <ref> [18] </ref> used images of spheres to correct the aspect ratio of narrow-angle perspective images. Our algorithm corrects a larger number of parameters, and works on wide-angle images. Images of spheres have been used to estimate the image center and focal length of perspective images [2, 3].
Reference: [19] <author> Ray, Sidney F. </author> <title> (1994) Applied Photographic Optics, second edition, </title> <publisher> Focal Press, Oxford. </publisher>
Reference-contexts: Each ideal projection has useful characteristic properties. Perspective projection preserves straightness: straight lines in 3D project into great circles on the viewing sphere, and thence into lines in the planar image. Equi-solid angle projection preserves viewing sphere areas in the planar image <ref> [19] </ref>. Stereographic is conformal (preserves local shape) and projects circles on the viewing sphere (including images of 3D spheres) onto circles and lines in the planar image [10, 13]. <p> The other four ("fisheye") projections expand peripheral areas less and, thus, reduce intensity drop-off <ref> [7, 14, 19] </ref>. Therefore, 35mm lenses with fields of view wider than 120 ffi 140 ffi and C-mount lenses with fields of view wider than 60 ffi 80 ffi are designed to approximate a fisheye projection model. Lenses are commercially available with fields of view up to 220 ffi . <p> Lenses are commercially available with fields of view up to 220 ffi . Details of optical designs can be found in <ref> [14, 19, 21] </ref>. It is frequently assumed that most video camera lenses are nominally perspective, and that the divergences from this ideal model are insignificant (e.g. [5]). This is not the case.
Reference: [20] <editor> Russ, John C., </editor> <booktitle> The Image Processing Handbook, 2nd ed., </booktitle> <publisher> CRC Press, </publisher> <address> Roca Raton, FL. </address> <year> 1995. </year>
Reference-contexts: Then a 4-connected component algorithm is used to separate the sphere images from each other. An ellipse is fit to each sphere image, using moments to compute the major and minor axes <ref> [11, 20] </ref>. We use a moment-based technique because it produces more stable fits than an edge-based technique [20]. We do not believe that our method requires high accuracy from the test spheres or the ellipse fitter, unless the application requires the output calibration to have high accuracy. <p> Then a 4-connected component algorithm is used to separate the sphere images from each other. An ellipse is fit to each sphere image, using moments to compute the major and minor axes [11, 20]. We use a moment-based technique because it produces more stable fits than an edge-based technique <ref> [20] </ref>. We do not believe that our method requires high accuracy from the test spheres or the ellipse fitter, unless the application requires the output calibration to have high accuracy.
Reference: [21] <author> Smith, Warren J. </author> <title> (1992) Modern Lens Design: A Resource Manual, </title> <publisher> McGraw-Hill, </publisher> <address> New York. </address>
Reference-contexts: Lenses are commercially available with fields of view up to 220 ffi . Details of optical designs can be found in <ref> [14, 19, 21] </ref>. It is frequently assumed that most video camera lenses are nominally perspective, and that the divergences from this ideal model are insignificant (e.g. [5]). This is not the case. <p> Thus, the output of the center-finder will only be as accurate as the center estimate that was used during correction of distortion. Based on the range of radial projection functions shown in figure 1 and in <ref> [21] </ref>, it seems that the radial projection function for an uncalibrated lens may follow any reasonably-shaped curve in the range between sine-law and perspective projection. In addition, an uncalibrated camera system may have tangential distortion, due to misalignment of lens components.
Reference: [22] <editor> Slama, C.C. ed, </editor> <booktitle> Manual of Photogrammetry, 4th edition, American Society of Pho-togrammetry (1980). </booktitle>
Reference-contexts: Images of spheres have been used to estimate the image center and focal length of perspective images [2, 3]. As discussed above, these methods cannot cope robustly with non-trivial radial distortion. The plumb line algorithm for correcting an image to perspective projection <ref> [1, 22] </ref> (also used by [2, 23]) is based on a similar idea. That is, straight 3D lines should appear straight in an ideal perspective image. The algorithm examines images of many straight lines, and builds a distortion function which straightens all the lines as well as possible.
Reference: [23] <author> Stein, </author> <title> G.P. (1995) "Accurate Internal Camera Calibration using Rotation, with Analysis of Sources of Error," </title> <booktitle> IEEE 5th International Conference on Computer Vision, </booktitle> <address> Cambridge MA, </address> <pages> pp. 230-236. </pages>
Reference-contexts: A variety of methods have been proposed for locating the image center in the presence of radial distortion [1, 4, 15, 16, 17, 24]. Some algorithms <ref> [1, 23] </ref> estimate the image center as part of a larger monolithic optimization. However, it is known that this parameter is poorly determined by the image data: large changes in the position of the image center generate only small changes in image appearance [15, 24, 25]. <p> Images of spheres have been used to estimate the image center and focal length of perspective images [2, 3]. As discussed above, these methods cannot cope robustly with non-trivial radial distortion. The plumb line algorithm for correcting an image to perspective projection [1, 22] (also used by <ref> [2, 23] </ref>) is based on a similar idea. That is, straight 3D lines should appear straight in an ideal perspective image. The algorithm examines images of many straight lines, and builds a distortion function which straightens all the lines as well as possible.
Reference: [24] <author> Stevenson, Daniel E. and Margaret M. </author> <title> Fleck (1995) "Robot Aerobics: Four Easy Steps to a More Flexible Calibration," </title> <booktitle> IEEE 5th International Conference on Computer Vision, </booktitle> <address> Cambridge MA, </address> <pages> pp. 34-39. </pages>
Reference-contexts: A variety of methods have been proposed for locating the image center in the presence of radial distortion <ref> [1, 4, 15, 16, 17, 24] </ref>. Some algorithms [1, 23] estimate the image center as part of a larger monolithic optimization. <p> Some algorithms [1, 23] estimate the image center as part of a larger monolithic optimization. However, it is known that this parameter is poorly determined by the image data: large changes in the position of the image center generate only small changes in image appearance <ref> [15, 24, 25] </ref>. Thus, accurate algorithms for locating the image center require very high precision measurements [1, 15]. This paper presents a new approach to camera calibration, which avoids elaborate parametric models. <p> To test the algorithm on more interesting types of distortion, we simulated a pure perspective lens using calibration information obtained by the method in <ref> [24] </ref>, both with square pixels and with significantly non-square pixels (aspect ratio 1.27). Figure 6 shows that the algorithm can also correct these larger deviations from stereographic projection. Images of spheres have been used in other camera calibration algorithms, but not in this way. <p> Whether these parameters are required and, if required, how precisely they must be determined, depends on the application and the camera's field of view. Without high-precision measurements (e.g. as in [15]), the image center can only be located to perhaps 5 ffi <ref> [24] </ref>. However, conversely, even a 20 pixel displacement of the image center may cause only sub-pixel displacement of image features [15]. For applications requiring only moderate precision, e.g. object recognition, the center of the CCD array can be used as an estimate of the image center [15, 24, 25]. <p> However, conversely, even a 20 pixel displacement of the image center may cause only sub-pixel displacement of image features [15]. For applications requiring only moderate precision, e.g. object recognition, the center of the CCD array can be used as an estimate of the image center <ref> [15, 24, 25] </ref>. <p> By far the simplest method, sufficient for many purposes, is to position the camera with its lens centered on a turntable, optical axis parallel to the turntable. This can be done using the procedures in <ref> [24] </ref> or approximately by hand. One can then position the image of a distant object at the image center and observe its motion under a measured rotation. For many applications, a rough estimate of the focal length constant (equivalently, the field of view) is sufficient.
Reference: [25] <author> Tsai, Roger Y., </author> <title> "An Efficient and Accurate Camera Calibration Technique for 3D Machine Vision," </title> <booktitle> IEEE CVPR 1986, </booktitle> <pages> pp. 364-374. </pages>
Reference-contexts: Some algorithms [1, 23] estimate the image center as part of a larger monolithic optimization. However, it is known that this parameter is poorly determined by the image data: large changes in the position of the image center generate only small changes in image appearance <ref> [15, 24, 25] </ref>. Thus, accurate algorithms for locating the image center require very high precision measurements [1, 15]. This paper presents a new approach to camera calibration, which avoids elaborate parametric models. <p> However, conversely, even a 20 pixel displacement of the image center may cause only sub-pixel displacement of image features [15]. For applications requiring only moderate precision, e.g. object recognition, the center of the CCD array can be used as an estimate of the image center <ref> [15, 24, 25] </ref>.
References-found: 25

