URL: http://www.cs.utexas.edu/users/jthomas/93.USENIX.Linking_shared_segments.ps
Refering-URL: http://www.cs.utexas.edu/users/jthomas/publications.html
Root-URL: 
Title: Linking Shared Segments  
Author: W. E. Garrett, M. L. Scott, R. Bianchini, L. I. Kontothanassis, R. A. McCallum, J. A. Thomas, R. Wisniewski and S. Luk 
Address: Rochester  
Affiliation: University of  
Abstract: As an alternative to communication via messages or files, shared memory has the potential to be simpler, faster, and less wasteful of space. Unfortunately, the mechanisms available for sharing in Unix are not very easy to use. As a result, shared memory tends to appear primarily in self-contained parallel applications, where library or compiler support can take care of the messy details. We have developed a system, called Hemlock, for transparent sharing of variables and/or subroutines across application boundaries. Our system is backward compatible with existing versions of Unix. It employs dynamic linking in conjunction with the Unix mmap facility and a kernel-maintained correspondence between virtual addresses and files. It introduces the notion of scoped linking to avoid naming conflicts in the face of extensive sharing. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> M. Accetta, R. Baron, W. Bolosky, D. Golub, R. Rashid, A. Tevanian, and M. Young, </author> <title> ``Mach: A New Kernel Foundation for UNIX Development,'' </title> <booktitle> Proceedings of the Summer 1986 USENIX Technical Conference and Exhibition, </booktitle> <pages> pp. 93-112, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: ATT's shm facility became available in Unix System V and its derivatives. More recently, memory sharing via inheritance has been incorporated in the versions of Unix for several commercial multiprocessors, and the external pager mechanisms of Mach <ref> [1] </ref> and Chorus [18] can be used to establish data sharing between arbitrary processes. Shared memory has several important advantages over interaction via files or messages. 1. Many programmers find shared memory more conceptually appealing than message passing.
Reference: 2. <author> T. E. Anderson, B. N. Bershad, E. D. Lazowska, and H. M. Levy, </author> <title> ``Scheduler Activations: Effective Kernel Support for the User-Level Management of Parallelism,'' </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 10, no. 1, </volume> <pages> pp. 53-79, </pages> <month> February </month> <year> 1992. </year> <booktitle> Originally presented at the Thirteenth ACM Symposium on Operating Systems Principles, </booktitle> <month> 13-16 October </month> <year> 1991. </year>
Reference-contexts: For lighter-weight synchronization, blocking mechanisms can be implemented in user space by providing standard interfaces to thread schedulers [13], and several researchers have demonstrated that spin locks can be used successfully in user space as well, by preventing, avoiding, or recovering from preemption during critical sections <ref> [2, 6, 13] </ref>, or by relinquishing the processor when a lock is unavailable [11]. Garbage Collection When a Unix process finishes execution or terminates abnormally, its private segments can be reclaimed. The same cannot be said of segments shared between processes.
Reference: 3. <author> B. N. Bershad, E. D. Lazowska, H. M. Levy, and D. B. Wagner, </author> <title> ``An Open Environment for Building Parallel Programming Systems,'' </title> <booktitle> Proceedings of the First ACM Conference on Parallel Programming: Experience with Applications, Languages and Systems, </booktitle> <pages> pp. 1-9, </pages> <address> New Haven, CT, </address> <month> 19-21 July </month> <year> 1988. </year> <note> In ACM SIG-PLAN Notices 23:9. </note>
Reference-contexts: Linking Shared Segments synchronization and data exchange. On a shared memory multiprocessor this communication occurs via shared variables. In most parallel environments global variables are considered to be shared between the the threads of an application while local variables are private to a thread. In systems like Presto <ref> [3] </ref>, however, both shared and private global variables are permitted. Presto was originally designed to run on a Sequent multiprocessor under the Dynix operating system. The Dynix compilers provide language extensions that allow the programmer to distinguish explicitly between shared and private variables.
Reference: 4. <author> B. N. Bershad, T. E. Anderson, E. D. Lazowska, and H. M. Levy, </author> <title> ``Lightweight Remote Procedure Call,'' </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 8, no. 1, </volume> <pages> pp. 37-55, </pages> <month> February </month> <year> 1990. </year> <booktitle> Originally presented at the Twelfth ACM Symposium on Operating Systems Principles, </booktitle> <month> 3-6 December </month> <year> 1989. </year>
Reference-contexts: When supported by hardware, shared memory is generally faster than either messages or files, since operating system overhead and copying costs can often be avoided. Work by Bershad and Anderson, for example <ref> [4] </ref>, indicates that message passing should be built on top of shared memory when possible. 5. As an implementation technique, sharing of read-only objects can save significant amounts of disk space and memory. <p> In their work on lightweight and user-level remote procedure calls, Bershad et al. argue that high-speed interfaces permit a much more modular style of system construction than has been the norm to date <ref> [4] </ref>. The growing interest in microkernels [28] suggests that this philosophy is catching on. In effect, the microkernel argument is that the proliferation of boundaries becomes acceptable when crossing these boundaries is cheap.
Reference: 5. <author> J. S. Chase, H. M. Levy, M. Baker-Harvey, and E. D. Lazowska, </author> <title> ``How to Use a 64-Bit Virtual Address Space,'' </title> <type> Technical Report 92-03-02, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> March </month> <year> 1992. 1993 </year> <month> Winter USENIX - January 25-29, </month> <title> 1993 - San Diego, CA 25 Linking Shared Segments Garrett, </title> <institution> et al. </institution>
Reference: 6. <author> J. Edler, J. Lipkis, and E. Schonberg, </author> <title> ``Process Management for Highly Parallel UNIX Systems,'' </title> <booktitle> Proceedings of the USENIX Workshop on Unix and Supercomputers, </booktitle> <address> Pittsburgh, PA, </address> <month> 26-27 September </month> <year> 1988. </year> <note> Also available as Ultracomputer Note #136, </note> <author> Courant Institute, N. Y. U., </author> <month> April </month> <year> 1988. </year>
Reference-contexts: For lighter-weight synchronization, blocking mechanisms can be implemented in user space by providing standard interfaces to thread schedulers [13], and several researchers have demonstrated that spin locks can be used successfully in user space as well, by preventing, avoiding, or recovering from preemption during critical sections <ref> [2, 6, 13] </ref>, or by relinquishing the processor when a lock is unavailable [11]. Garbage Collection When a Unix process finishes execution or terminates abnormally, its private segments can be reclaimed. The same cannot be said of segments shared between processes.
Reference: 7. <author> W. E. Garrett, R. Bianchini, L. Kontothanassis, R. A. McCallum, J. Thomas, R. Wisniewski, and M. L. Scott, </author> <title> ``Dynamic Sharing and Backward Compatibility on 64-Bit Machines,'' </title> <type> TR 418, </type> <institution> Computer Science Department, University of Rochester, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: The fundamental assumption of this work was that sharing would occur both within and among applications. Our current work <ref> [7, 23] </ref> is an attempt to make that sharing commonplace in the context of traditional operating systems. Hemlock uses dynamic linking to allow processes to access shared code and data with the same syntax employed for private code and data.
Reference: 8. <author> M. Herlihy and B. Liskov, </author> <title> ``A Value Transmission Method for Abstract Data Types,'' </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> vol. 4, no. 4, </volume> <pages> pp. 527-551, </pages> <month> October </month> <year> 1982. </year>
Reference-contexts: The complexity of this saving and restoring is a perennial complaint of compiler writers, and much research has been devoted to automating the process [15]. 4 Similar work has occurred in the message-passing community <ref> [8] </ref>. With pointers permitted in files, and with a global consensus on the location of every segment, pointer-rich data structures can be left in their original form when saved across program executions.
Reference: 9. <author> W. W. Ho and R. A. Olsson, </author> <title> ``An Approach to Genuine Dynamic Linking,'' </title> <journal> Software Practice and Experience, </journal> <volume> vol. 21, no. 4, </volume> <pages> pp. 375-390, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: linked not yet in memory module and path fixed unknown at present path not fixed A.o B.o C.o G.o G.o G.o - privateG.o - private F.o D.o - private E.o - shared E.o - shared E.o - shared F.o - private Several dynamic linkers, including the Free Software Foundation's dld <ref> [9] </ref> and those of SunOS and SVR4, provide library routines that allow the user to link object modules into a running program. Dld will resolve undefined references in the modules it brings in, allowing them to point into the main program or into other dynamically-loaded modules.
Reference: 10. <author> E. Jul, H. Levy, N. Hutchinson, and A. Black, </author> <title> ``Fine-Grained Mobility in the Emerald System,'' </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 6, no. 1, </volume> <pages> pp. 109-133, </pages> <month> February </month> <year> 1988. </year> <booktitle> Originally presented at the Eleventh ACM Symposium on Operating Systems Principles, </booktitle> <address> Aus-tin, TX, </address> <month> 8-11 November </month> <year> 1987. </year>
Reference-contexts: Unlike the ``shared'' libraries of systems such as SunOS and SVR4, Hemlock supports genuine write sharing, not just the physical sharing of logically private pages. Unlike such integrated programming environments as Cedar [24] and Emerald <ref> [10] </ref>, it supports sharing of modules written in conventional languages, in a manner that is backward compatible with Unix. An early prototype of Hemlock ran under SunOS, but we are now working on Silicon Graphics machines (with SGI's IRIX operating system).
Reference: 11. <author> A. R. Karlin, K. Li, M. S. Manasse, and S. Owicki, </author> <title> ``Empirical Studies of Competitive Spinning for a Shared-Memory Multiprocessor,'' </title> <booktitle> Proceedings of the Thirteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pp. 41-55, </pages> <address> Pacific Grove, CA, </address> <month> 13-16 October </month> <year> 1991. </year> <booktitle> In ACM SIGOPS Operating Systems Review 25:5. </booktitle>
Reference-contexts: user space by providing standard interfaces to thread schedulers [13], and several researchers have demonstrated that spin locks can be used successfully in user space as well, by preventing, avoiding, or recovering from preemption during critical sections [2, 6, 13], or by relinquishing the processor when a lock is unavailable <ref> [11] </ref>. Garbage Collection When a Unix process finishes execution or terminates abnormally, its private segments can be reclaimed. The same cannot be said of segments shared between processes. Sharing introduces (or at least exacerbates) the problem of garbage collection.
Reference: 12. <author> S. J. Leffler, M. K. McKusick, M. J. Karels, and J. S. Quarterman, </author> <title> The Design and Implementation of the 4.3BSD UNIX Operating System, </title> <publisher> The Addison-Wesley Publishing Company, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: It suffered something of a hiatus in the 1970s, but has now been incorporated into most variants of Unix. The Berkeley mmap facility was designed, though never actually included, as part of the 4.2BSD and 4.3BSD releases <ref> [12] </ref>; it appears in several commercial systems, including SunOS. ATT's shm facility became available in Unix System V and its derivatives.
Reference: 13. <author> B. D. Marsh, M. L. Scott, T. J. LeBlanc, and E. P. Markatos, </author> <title> ``First-Class User-Level Threads,'' </title> <booktitle> Proceedings of the Thirteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pp. 110-121, </pages> <address> Pacific Grove, CA, </address> <month> 14-16 October </month> <year> 1991. </year> <booktitle> In ACM SIGOPS Operating Systems Review 25:5. </booktitle>
Reference-contexts: Synchronization Files are seldom write-shared, and message passing subsumes synchronization. When accessing shared memory, however, processes must synchronize explicitly. Unix already includes kernel-supported semaphores. For lighter-weight synchronization, blocking mechanisms can be implemented in user space by providing standard interfaces to thread schedulers <ref> [13] </ref>, and several researchers have demonstrated that spin locks can be used successfully in user space as well, by preventing, avoiding, or recovering from preemption during critical sections [2, 6, 13], or by relinquishing the processor when a lock is unavailable [11]. <p> For lighter-weight synchronization, blocking mechanisms can be implemented in user space by providing standard interfaces to thread schedulers [13], and several researchers have demonstrated that spin locks can be used successfully in user space as well, by preventing, avoiding, or recovering from preemption during critical sections <ref> [2, 6, 13] </ref>, or by relinquishing the processor when a lock is unavailable [11]. Garbage Collection When a Unix process finishes execution or terminates abnormally, its private segments can be reclaimed. The same cannot be said of segments shared between processes.
Reference: 14. <author> B. D. Marsh, C. M. Brown, T. J. LeBlanc, M. L. Scott, T. G. Becker, P. Das, J. Karlsson, and C. A. Quiroz, </author> <title> ``Operating System Support for Animate Vision,'' </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol. 15, no. 2, </volume> <pages> pp. 103-117, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: An Overview of Hemlock Our emphasis on shared memory has its roots in the Psyche project [19, 20]. Our focus in Psyche was on mechanisms and conventions that allow processes from dissimilar programming models (e.g., Lynx threads and Multilisp futures) to share data abstractions, and to synchronize correctly <ref> [14, 21] </ref>. The fundamental assumption of this work was that sharing would occur both within and among applications. Our current work [7, 23] is an attempt to make that sharing commonplace in the context of traditional operating systems.
Reference: 15. <author> C. R. Morgan, </author> <title> ``Special Issue on the Interface Description Language IDL,'' </title> <journal> ACM SIGPLAN Notices, </journal> <volume> vol. 22, no. 11, </volume> <month> November </month> <year> 1987. </year>
Reference-contexts: The complexity of this saving and restoring is a perennial complaint of compiler writers, and much research has been devoted to automating the process <ref> [15] </ref>. 4 Similar work has occurred in the message-passing community [8]. With pointers permitted in files, and with a global consensus on the location of every segment, pointer-rich data structures can be left in their original form when saved across program executions.
Reference: 16. <author> B. Nitzberg and V. Lo, </author> <title> ``Distributed Shared Memory: A Survey of Issues and Algorithms,'' </title> <journal> Computer, </journal> <volume> vol. 24, no. 8, </volume> <pages> pp. 52-60, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: Shared memory has several important advantages over interaction via files or messages. 1. Many programmers find shared memory more conceptually appealing than message passing. The growing popularity of distributed shared memory systems <ref> [16] </ref> suggests that programmers will adopt a sharing model even at the expense of performance. 2. Shared memory facilitates transparent, asynchronous interaction between processes, and shares with files the advantage of not requiring that the interacting processes be active concurrently. 3.
Reference: 17. <author> E. I. Organick, </author> <title> The Multics System: An Examination of Its Structure, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1972. </year>
Reference-contexts: Both mechanisms have their limitations, however, and support for a third approach shared memory can also be extremely useful. Memory sharing between arbitrary processes is at least as old as Multics <ref> [17] </ref>. It suffered something of a hiatus in the 1970s, but has now been incorporated into most variants of Unix. The Berkeley mmap facility was designed, though never actually included, as part of the 4.2BSD and 4.3BSD releases [12]; it appears in several commercial systems, including SunOS. <p> A different philosophical position is taken in systems such as Multics <ref> [17] </ref>, Hydra [27], and Opal, which clearly separate code from data and speak explicitly of processes executing in shared code but using private (static) data. Multics employs an elaborate hardware/software mechanism in which references to static data are made indirectly through a base register and process-private link segment.
Reference: 18. <author> M. Rozier and others, </author> <title> ``Chorus Distributed Operating Systems,'' </title> <journal> Computing Systems, </journal> <volume> vol. 1, no. 4, </volume> <pages> pp. 305-370, </pages> <month> Fall </month> <year> 1988. </year>
Reference-contexts: ATT's shm facility became available in Unix System V and its derivatives. More recently, memory sharing via inheritance has been incorporated in the versions of Unix for several commercial multiprocessors, and the external pager mechanisms of Mach [1] and Chorus <ref> [18] </ref> can be used to establish data sharing between arbitrary processes. Shared memory has several important advantages over interaction via files or messages. 1. Many programmers find shared memory more conceptually appealing than message passing.
Reference: 19. <author> M. L. Scott, T. J. LeBlanc, and B. D. Marsh, </author> <title> ``Design Rationale for Psyche, a General-Purpose Multiprocessor Operating System,'' </title> <booktitle> Proceedings of the 1988 International Conference on Parallel Processing, vol. II Software, </booktitle> <pages> pp. 255-262, </pages> <address> St. Charles, IL, </address> <month> 15-19 August </month> <year> 1988. </year>
Reference-contexts: We describe example applications in section 4, discuss some semantic subtleties in section 5, and conclude in section 6. 2. An Overview of Hemlock Our emphasis on shared memory has its roots in the Psyche project <ref> [19, 20] </ref>. Our focus in Psyche was on mechanisms and conventions that allow processes from dissimilar programming models (e.g., Lynx threads and Multilisp futures) to share data abstractions, and to synchronize correctly [14, 21]. The fundamental assumption of this work was that sharing would occur both within and among applications.
Reference: 20. <author> M. L. Scott, T. J. LeBlanc, and B. D. Marsh, </author> <title> ``Evolution of an Operating System for Large-Scale Shared-Memory Multiprocessors,'' </title> <type> TR 309, </type> <institution> Computer Science Department, University of Rochester, </institution> <month> March </month> <year> 1989. </year>
Reference-contexts: We describe example applications in section 4, discuss some semantic subtleties in section 5, and conclude in section 6. 2. An Overview of Hemlock Our emphasis on shared memory has its roots in the Psyche project <ref> [19, 20] </ref>. Our focus in Psyche was on mechanisms and conventions that allow processes from dissimilar programming models (e.g., Lynx threads and Multilisp futures) to share data abstractions, and to synchronize correctly [14, 21]. The fundamental assumption of this work was that sharing would occur both within and among applications.
Reference: 21. <author> M. L. Scott, T. J. LeBlanc, and B. D. Marsh, </author> <booktitle> ``Multi-Model Parallel Programming in Psyche,'' Proceedings of the Second ACM Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pp. 70-78, </pages> <address> Seattle, WA, 14-16 March, </address> <year> 1990. </year> <journal> In ACM SIGPLAN Notices 25:3. </journal>
Reference-contexts: An Overview of Hemlock Our emphasis on shared memory has its roots in the Psyche project [19, 20]. Our focus in Psyche was on mechanisms and conventions that allow processes from dissimilar programming models (e.g., Lynx threads and Multilisp futures) to share data abstractions, and to synchronize correctly <ref> [14, 21] </ref>. The fundamental assumption of this work was that sharing would occur both within and among applications. Our current work [7, 23] is an attempt to make that sharing commonplace in the context of traditional operating systems.
Reference: 22. <author> M. L. Scott, </author> <title> ``The Lynx Distributed Programming Language: Motivation, Design, </title> <journal> and Experience,'' Computer Languages, </journal> <volume> vol. 16, no. 3/4, </volume> <pages> pp. 209-233, </pages> <year> 1991. </year> <note> Earlier version published as TR 308, ``An Overview of Lynx,'' </note> <institution> Computer Science Department, University of Rochester, </institution> <month> August </month> <year> 1989. </year>
Reference-contexts: Segments thus saved are position-dependent, but for the compiler writer this is not a problem; the idea is simply to transfer the data between passes. In a related case study, we have examined our compiler for the Lynx distributed programming language <ref> [22] </ref>, designed around scanner and parser generators developed at the University of Wisconsin. The Wisconsin tools produce numeric tables which a pair of utility programs translate into initialized data structures for separately-developed scanner and parser drivers, written in Pascal.
Reference: 23. <author> M. L. Scott and W. Garrett, </author> <title> ``Shared Memory Ought to be Commonplace,'' </title> <booktitle> Proceedings of the Third Workshop on Workstation Operating Systems, </booktitle> <address> Key Biscayne, FL, </address> <month> 23-24 April </month> <year> 1992. </year>
Reference-contexts: The fundamental assumption of this work was that sharing would occur both within and among applications. Our current work <ref> [7, 23] </ref> is an attempt to make that sharing commonplace in the context of traditional operating systems. Hemlock uses dynamic linking to allow processes to access shared code and data with the same syntax employed for private code and data.
Reference: 24. <author> D. Swinehart, P. Zellweger, R. Beach, and R. Hagmann, </author> <title> ``A Structural View of the Cedar Programming Environment,'' </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> vol. 8, no. 4, </volume> <pages> pp. 419-490, </pages> <month> October </month> <year> 1986. </year>
Reference-contexts: Unlike the ``shared'' libraries of systems such as SunOS and SVR4, Hemlock supports genuine write sharing, not just the physical sharing of logically private pages. Unlike such integrated programming environments as Cedar <ref> [24] </ref> and Emerald [10], it supports sharing of modules written in conventional languages, in a manner that is backward compatible with Unix. An early prototype of Hemlock ran under SunOS, but we are now working on Silicon Graphics machines (with SGI's IRIX operating system). <p> Utility Programs and Servers Traditionally, UNIX has been a fertile environment for the creation and use of small tools that can be connected together, e.g., via pipes. Other systems, including Multics and the various open operating systems <ref> [24, 25] </ref> encourage the construction of similar building blocks at the level of functions, rather than program executables. In future work, we plan to use Hemlock facilities to experiment with functional building blocks in Unix.
Reference: 25. <author> J. H. Walker, D. A. Moon, D. L. Weinreb, and M. McMahon, </author> <title> ``The Symbolics Genera Programming Environment,'' </title> <journal> IEEE Software, </journal> <volume> vol. 4, no. 6, </volume> <pages> pp. 36-45, </pages> <month> November </month> <year> 1987. </year> <booktitle> 26 1993 Winter USENIX - January 25-29, </booktitle> <address> 1993 - San Diego, </address> <publisher> CA Garrett, </publisher> <editor> et al. </editor> <title> Linking Shared Segments </title>
Reference-contexts: Utility Programs and Servers Traditionally, UNIX has been a fertile environment for the creation and use of small tools that can be connected together, e.g., via pipes. Other systems, including Multics and the various open operating systems <ref> [24, 25] </ref> encourage the construction of similar building blocks at the level of functions, rather than program executables. In future work, we plan to use Hemlock facilities to experiment with functional building blocks in Unix.
Reference: 26. <author> M. Weiser, L. P. Deutsch, and P. B. Kessler, </author> <title> ``UNIX Needs a True Integrated Environment: CASE Closed,'' </title> <type> Technical Report CSL-89-4, </type> <note> Xerox PARC, 1989. Earlier version published as Toward a Single Milieu, UNIX Review 6:11. </note>
Reference-contexts: supplant the use of files in traditional Unix utilities? * In general, how much of the power and flexibility of open operating systems can be extended to an environment with multiple users and languages? Many of the issues involved in this last question are under investigation at Xerox PARC (see <ref> [26] </ref> in particular). The multiple languages of Unix, and the reliance on kernel protection, pose serious obstacles to the construction of integrated programming environments. It is not clear whether all of these obstacles can be overcome, but there is certainly much room for improvement.
Reference: 27. <author> W. A. Wulf, R. Levin, and S. P. Harbison, Hydra/C.mmp: </author> <title> An Experimental Computer System, </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: A different philosophical position is taken in systems such as Multics [17], Hydra <ref> [27] </ref>, and Opal, which clearly separate code from data and speak explicitly of processes executing in shared code but using private (static) data. Multics employs an elaborate hardware/software mechanism in which references to static data are made indirectly through a base register and process-private link segment.

References-found: 27

