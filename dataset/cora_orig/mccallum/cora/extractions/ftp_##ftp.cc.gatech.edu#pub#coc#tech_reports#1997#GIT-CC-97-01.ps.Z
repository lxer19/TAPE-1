URL: ftp://ftp.cc.gatech.edu/pub/coc/tech_reports/1997/GIT-CC-97-01.ps.Z
Refering-URL: http://www.cs.gatech.edu/tech_reports/index.97.html
Root-URL: 
Title: Software Approach to Hazard Detection Using On-line Analysis of Safety Constraints  
Author: Beth Schroeder Sudhir Aggarwal Karsten Schwan 
Address: Atlanta, Georgia 30332  
Affiliation: College of Computing Georgia Institute of Technology  
Pubnum: GIT-CC-97-01  
Abstract: The research here addresses the problem of improving software safety through hazard detection. The premise of our work is that hazard situations can and do occur, and are often complex, involving multiple sources. So there is a need for a mechanism to detect complex hazards and react in a timely and meaningful way. This paper addresses such a detection mechanism through Cnet, an on-line analysis tool that supports the specification of complex multi-source hazards using a query-like language, uses both synchronous and asynchronous checking approaches to balance efficiency and expressiveness, accommodates dynamic applications through dynamic constraint addition, and supports distributed and parallel applications running in heterogeneous environments. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Tucker Balch and Ronald Arkin. </author> <title> Avoiding the past: A simple but effective strategy for reactive navigation. </title> <booktitle> Proceedings IEEE Robotics and Automation, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: This work was funded in part by NSF equipment grants CDA-9501637, CDA-9422033, and ECS-9411846. applications through dynamic constraint addition, and supports distributed and parallel applications running in heterogeneous environments. We have applied our detection approach to a set of autonomous robots, developed by Balch and Arkin <ref> [1] </ref> in their work on the Autonomous Robot Architecture (AuRA) at the Georgia Institute of Technology. Balch and Arkin have designed a robot that can navigate toward a goal across unmapped terrain, 'reacting' to stimuli in its environment.
Reference: [2] <author> Tucker Balch and Ronald Arkin. </author> <title> Communication in reactive multiagent robot systems. </title> <booktitle> Autonomous Robots, </booktitle> <volume> 1(1) </volume> <pages> 27-52, </pages> <year> 1994. </year>
Reference-contexts: In Section 5 we discuss related work. We conclude in Section 6, with a discussion of current status and future work. 2 Multiagent Reactive Robot Example The application used in our work is a multiagent reactive robotic system simulation by Balch and Arkin <ref> [2] </ref>. The work was undertaken to investigate the importance of communication in robotic societies. The authors tested their strategy through an iteration of simulation and instantiation on real systems. The application area was chosen because it is a well-defined domain where developers are accustomed to specifying semantics of a system.
Reference: [3] <author> Peter C. Bates and Jack C. Wileden. </author> <title> High-level debugging of distributed systems: The behavioral abstraction approach. </title> <journal> Journal of Systems and Science, </journal> <volume> 3 </volume> <pages> 255-264, </pages> <year> 1983. </year>
Reference-contexts: Because the filter receives its event stream from a single sensor type, it is a candidate for placement within the sensor. This synchronous checking technique reduces the event flow to the analysis tool by eliminating events at the source. A cluster is a building abstraction <ref> [3] </ref>. It gathers events of the same type to build a new abstraction such as a group of robots or a group of robot legs. A self-replacing node is a set of constraints implemented as a small finite state machine.
Reference: [4] <author> Monica Brockmeyer, Farnam Jahanian, Connie Heitmeyer, and Bruce Labaw. </author> <title> An approach to monitoring and assertion-checking of real time specifications in modechart. </title> <booktitle> In Workshop on Parallel and Distributed Real-Time Systems, </booktitle> <month> April </month> <year> 1996. </year>
Reference-contexts: The work is important to us though in that it defines a class of constraints specifiable and monitorable by our tool. The Monitoring and Assertion tool (MAC) <ref> [4] </ref> is a formal analysis technique for monitoring symbolic execution traces generated by the Modechart Toolset [5]. It provides a mechanism for evaluating properties of the system on a particular execution trace.
Reference: [5] <author> P. C. Clements, C. L. Heitmeyer, B. G. Labaw, and A. T. Rose. </author> <title> MT: A toolset for specifying and analyzing real-time systems. </title> <booktitle> In Proceedings IEEE Real-Time Systems Symposium, </booktitle> <month> December </month> <year> 1993. </year>
Reference-contexts: The work is important to us though in that it defines a class of constraints specifiable and monitorable by our tool. The Monitoring and Assertion tool (MAC) [4] is a formal analysis technique for monitoring symbolic execution traces generated by the Modechart Toolset <ref> [5] </ref>. It provides a mechanism for evaluating properties of the system on a particular execution trace. Leveson's work in the early 1980's [21] is early recognition of the need for run-time checking for hazard prevention. Her synchronous approach, though, requires embedding constraints in the application. On-line Application of Query Languages. <p> Language-oriented tasks in addition to implementing the complier include exploring the specification of hazards that occur over time (e.g., temperature rising too fast). We are also comparing SafeTQuel to specification languages suitable for safety critical systems (e.g., MT <ref> [5] </ref> and RSML [20]). This comparison will establish the suitability of a query language for constraint specification. 6.2 Future Work There are several avenues of long term pursuit. We would like to apply hazard detection to a virtual environment, where hazards still have meaning though in a less critical context.
Reference: [6] <author> Ingeman J. Cox and Narian H. Gehani. </author> <title> Exception handling in robotics. </title> <journal> Computer, </journal> <volume> 22(3) </volume> <pages> 43-49, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: If the radiation level of one of the robots exceeds 200 roentgens per hour, a violation occurs, causing a transition to the minDist constraint which ensures no robot approaches within 10 ft. of the radiated robot. Self replacing nodes are also useful for loosely hierarchical error recovery <ref> [6] </ref>. For example, when a robot encounters an obstacle in its path, its first response could be to wait some amount of time in the hope that the obstacle will move. If this simple error recovery fails, its second response would be to determine a new route.
Reference: [7] <author> Greg Eisenhauer. </author> <title> Portable self-describing binary data streams. </title> <type> Technical Report GIT-CC-94-45, </type> <institution> College of Computing, Georgia Institute of Technology, </institution> <year> 1994. </year> <note> http://www.cc.gatech.edu/tech reports. </note>
Reference-contexts: The interpreter when completed yields control to the Dispatcher which begins executing the nodes. The interpreter becomes active again only while a constraint is being dynamically added to the system. Falcon uses one or more local agents for online information capture and collection. It includes PBIO <ref> [7] </ref> and DataExchange [8] as the communication infrastructure. The Portable Binary Input Output (PBIO), library supports transmission of binary records between heterogeneous machines. PBIO handles differences in the sizes, locations, and even basic types of fields in the records to be exchanged.
Reference: [8] <author> Greg Eisenhauer and Beth Schroeder. </author> <title> The DataExchange library. </title> <type> Technical Report GIT-CC-96-17, </type> <institution> Georgia Institute of Technology, </institution> <year> 1996. </year> <note> http://www.cc.gatech.edu/tech reports. </note>
Reference-contexts: The interpreter when completed yields control to the Dispatcher which begins executing the nodes. The interpreter becomes active again only while a constraint is being dynamically added to the system. Falcon uses one or more local agents for online information capture and collection. It includes PBIO [7] and DataExchange <ref> [8] </ref> as the communication infrastructure. The Portable Binary Input Output (PBIO), library supports transmission of binary records between heterogeneous machines. PBIO handles differences in the sizes, locations, and even basic types of fields in the records to be exchanged.
Reference: [9] <author> Richard Gerber, Seongsoo Hong, and Manas Saksena. </author> <title> Guaranteeing end-to-end timing constraints by calibrating intermediate processes. </title> <booktitle> In Proceedings 15th Real Time Systems Symposium, </booktitle> <pages> pages 192-203. </pages> <publisher> IEEE, </publisher> <month> December </month> <year> 1994. </year>
Reference-contexts: The safety kernel is itself a system that must be rigorously safe and, thus, does not itself solve the safety problem, but perhaps reduces it to a size that can be tackled successfully by other methods [24]. Assertion Checking in Real-Time Systems. Gerber's work <ref> [9] </ref> on guaranteeing end-to-end timing constraints is an automated design methodology that generates a solution for a set of tasks that keeps consistent a set of end-to-end timing constraints.
Reference: [10] <author> Weiming Gu, Greg Eisenhauer, Eileen Kraemer, Karsten Schwan, John Stasko, Jeffrey Vetter, and Nirupama Mallavarupu. </author> <title> Falcon: On-line monitoring and steering of large-scale parallel programs. </title> <booktitle> In Proceedings of FRONTIERS'95, </booktitle> <month> February </month> <year> 1995. </year> <note> Also available as Technical Report GIT-CC-94-21, </note> <institution> College of Computing, Georgia Institute of Technology. </institution>
Reference-contexts: As described earlier, we have chosen to implement the analysis tool external to the application to minimize perturbation and enhance ease of use. Latency is addressed through the run-time component, Dispatcher, and by employing a monitoring and communication infrastructure, collectively referred to as Falcon <ref> [10] </ref> to support online monitoring and steering of the parallel or distributed applications. The Dispatcher is the run-time component of the analysis tool that controls net execution. At startup, nodes register their existence with the Dispatcher. The Dispatcher is responsible for linking nodes together.
Reference: [11] <author> W. Hammer. </author> <title> Handbook of system and product safety. </title> <publisher> Prentice Hall, </publisher> <year> 1972. </year> <month> 19 </month>
Reference-contexts: But the goal of an intrinsically safe system is difficult to achieve for some of today's complex, dynamic applications running in parallel or distributed environments. Adapting guidelines established by system safety engineers <ref> [11] </ref>, if one cannot guarantee an intrinsically safe system, the next preferred approach is a technique that prevents, minimizes, or detects the presence of hazards. A hazard is a state or condition of the system that combined with some environmental conditions can lead to an accident or loss event [19].
Reference: [12] <author> M. P. E. Heimdahl and Nancy G. Leveson. </author> <title> Completeness and consistency checking of software require-ments. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 22(6), </volume> <month> June </month> <year> 1996. </year>
Reference-contexts: A safe system is one that is free from accidents or unacceptable losses [19]. There is important research and development being done in providing intrinsically safe systems <ref> [12, 23, 24, 28, 29] </ref>, systems incapable of evolving into a state that could lead to injury or loss of life. But the goal of an intrinsically safe system is difficult to achieve for some of today's complex, dynamic applications running in parallel or distributed environments.
Reference: [13] <author> G. D. Held, M. Stonebraker, and E. Wong. </author> <title> INGRES a relational data base management sytstem. </title> <booktitle> In Proceedings AFIPS 1975 National Computer Conference 44, </booktitle> <pages> pages 409-416. </pages> <publisher> AFIPS Press, </publisher> <month> May </month> <year> 1975. </year>
Reference-contexts: The language he developed to explore the application of relational query languages to monitoring is TQuel, a general temporal query language augmenting the relational tuple calculus query language Quel <ref> [13] </ref> with additional constructs and semantics for treating time as an integral part of the database. We use TQuel as our starting point and extend it with abstractions to enhance its use in specifying safety constraints. We call this extension SafeTQuel.
Reference: [14] <author> Carol Kilpatrick, Karsten Schwan, and David Ogle. </author> <title> Using languages for capture, analysis and display of performance information for parallel and distributed applications. </title> <booktitle> In Proceedings 1990 Int'l Conference on Programming Languages, </booktitle> <year> 1990. </year>
Reference-contexts: Snodgrass [31] has shown that the relational model is an appropriate formalism for the information processed by the monitor. Earlier applications of this formalism to monitoring were primarily for performance evaluation <ref> [14, 26, 31] </ref>. Whereas performance evaluation is oriented toward the collection and organization of information for what is often post-mortem analysis, hazard detection is oriented toward filtering an overwhelming percentage of the information received. After all, the ultimate goal is to have no query satisfied.
Reference: [15] <author> Joh Kuhl, Douglas Evans, Yiannis Papelis, Richard Romano, and Ginger Watson. </author> <title> The Iowa Driving Simulator: An immersive research environment. </title> <journal> Computer, </journal> <volume> 28(7) </volume> <pages> 35-41, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: By taking a somewhat more relaxed definition of hazards, our detection approach has broader uses in, for example, virtual reality. A fully immersive ground-vehicle simulator can place a driver in a highly realistic driving environment. One such virtual environment is the Iowa Driving Simulator (IDS) <ref> [15] </ref>. Hazard conditions in virtual environments are the same as in real-life but without the attendant risk of harm or loss. For example, excessive driving speeds on icy roads creates a hazard condition to be avoided in either a virtual or real world.
Reference: [16] <author> Nancy Leveson. </author> <title> Software Safety. </title> <address> http://www.cs.washington.edu/research/projects/safety/www. </address>
Reference-contexts: Lutz [23] has taken a pragmatic approach to improving system safety by devising a Safety Checklist by which developers can better identify and understand the requirements needed for embedded software to interact correctly with the system. The Safety-Critical Software Project group at the University of Washington <ref> [16] </ref> has developed a set of tools for automating the safety analysis of specifications written in RSML [20].
Reference: [17] <author> Nancy Leveson. </author> <title> An investigation of the Therac-25 accidents. </title> <journal> Computer, </journal> <volume> 26(7) </volume> <pages> 18-41, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: One of the more tragic examples involved the Therac-25, a computerized radiation therapy machine. Six people either died or suffered serious injuries from massive overdoses of radiation between 1985 and 1987 before the problems were acknowledged and corrected <ref> [17] </ref>. A safe system is one that is free from accidents or unacceptable losses [19]. There is important research and development being done in providing intrinsically safe systems [12, 23, 24, 28, 29], systems incapable of evolving into a state that could lead to injury or loss of life.
Reference: [18] <author> Nancy G. Leveson. </author> <title> Software safety in embedded computer systems. </title> <journal> Communications of the ACM, </journal> <pages> pages 34-46, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: Automatic pressure relief valves, lockins, lockouts, and interlocks are common hardware hazard prevention approaches. An example of a software approach is a trip computer in a nuclear power plant that initiates procedures to shutdown the plant when operating conditions are hazardous <ref> [18] </ref>. The research here addresses the problem of improving software safety through hazard detection. The premise of our work is that hazard situations can and do occur, and are often complex, involving multiple sources. <p> virtual reality driving simulator by allowing developers to play what-if scenarios by iteratively adjusting speed and environmental conditions to determine what combination of conditions will be classified a hazard to which the simulator will react. 1.1 Problem and Solution Strategy Hazard detection is a viable approach to improving software safety <ref> [18] </ref> and, in some cases, is the only approach.
Reference: [19] <author> Nancy G. Leveson. Safeware: </author> <title> system safety and computers. </title> <publisher> Addison-Wesley, </publisher> <year> 1995. </year>
Reference-contexts: Six people either died or suffered serious injuries from massive overdoses of radiation between 1985 and 1987 before the problems were acknowledged and corrected [17]. A safe system is one that is free from accidents or unacceptable losses <ref> [19] </ref>. There is important research and development being done in providing intrinsically safe systems [12, 23, 24, 28, 29], systems incapable of evolving into a state that could lead to injury or loss of life. <p> A hazard is a state or condition of the system that combined with some environmental conditions can lead to an accident or loss event <ref> [19] </ref>. Automatic pressure relief valves, lockins, lockouts, and interlocks are common hardware hazard prevention approaches. An example of a software approach is a trip computer in a nuclear power plant that initiates procedures to shutdown the plant when operating conditions are hazardous [18].
Reference: [20] <author> Nancy G. Leveson, Mats P. E. Heimdahl, Holly Hildreth, and Jon D. Reese. </author> <title> Requirements specification for process-control systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 20(9), </volume> <month> September </month> <year> 1994. </year>
Reference-contexts: The Safety-Critical Software Project group at the University of Washington [16] has developed a set of tools for automating the safety analysis of specifications written in RSML <ref> [20] </ref>. Tools include forward simulation, backward hazard analysis using fault trees to display results, a robustness and non-determinism checker, and a software deviation analysis tool which produces scenarios in which specified assumptions about deviations in software inputs can lead to specified hazardous states [28]. <p> Language-oriented tasks in addition to implementing the complier include exploring the specification of hazards that occur over time (e.g., temperature rising too fast). We are also comparing SafeTQuel to specification languages suitable for safety critical systems (e.g., MT [5] and RSML <ref> [20] </ref>). This comparison will establish the suitability of a query language for constraint specification. 6.2 Future Work There are several avenues of long term pursuit. We would like to apply hazard detection to a virtual environment, where hazards still have meaning though in a less critical context.
Reference: [21] <author> Nancy G. Leveson and Timothy J. Shimeall. </author> <title> Safety assertions for process-control systems. </title> <booktitle> In Proceedings 13th Int'l Symposium on Fault Tolerant Computing, </booktitle> <pages> pages 236-240, </pages> <month> June </month> <year> 1983. </year>
Reference-contexts: The Monitoring and Assertion tool (MAC) [4] is a formal analysis technique for monitoring symbolic execution traces generated by the Modechart Toolset [5]. It provides a mechanism for evaluating properties of the system on a particular execution trace. Leveson's work in the early 1980's <ref> [21] </ref> is early recognition of the need for run-time checking for hazard prevention. Her synchronous approach, though, requires embedding constraints in the application. On-line Application of Query Languages.
Reference: [22] <author> Ling Liu, Calton Pu, Roger Barga, and Tong Zhou. </author> <title> Differential evaluation of continual queries. </title> <type> Technical Report TR95-17, </type> <institution> Department of Computer Science, University of Alberta, </institution> <year> 1996. </year>
Reference-contexts: Leveson's work in the early 1980's [21] is early recognition of the need for run-time checking for hazard prevention. Her synchronous approach, though, requires embedding constraints in the application. On-line Application of Query Languages. In Liu and Pu's work on continual queries <ref> [22] </ref>, a client specifies continual querys over information stored in a distributed interoperable environment such as the Internet. The objective is to compute the query and return the entire resulting relation upon the first 17 triggering only. On subsequent triggerings, only the add, modify, and delete change information is returned.
Reference: [23] <author> Robyn R. Lutz. </author> <title> Targeting safety related errors during software requirements analysis. </title> <booktitle> In Proceedings 1st ACM SIGSOFT Symposium on Foundations of Software Engineering. ACM, </booktitle> <year> 1993. </year>
Reference-contexts: A safe system is one that is free from accidents or unacceptable losses [19]. There is important research and development being done in providing intrinsically safe systems <ref> [12, 23, 24, 28, 29] </ref>, systems incapable of evolving into a state that could lead to injury or loss of life. But the goal of an intrinsically safe system is difficult to achieve for some of today's complex, dynamic applications running in parallel or distributed environments. <p> Lutz <ref> [23] </ref> has taken a pragmatic approach to improving system safety by devising a Safety Checklist by which developers can better identify and understand the requirements needed for embedded software to interact correctly with the system.
Reference: [24] <author> Louise E. Moser and P.M. Melliar-Smith. </author> <title> Formal verification of safety-critical systems. </title> <journal> Software - Practice and Experience, </journal> <volume> 20(8) </volume> <pages> 799-821, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: A safe system is one that is free from accidents or unacceptable losses [19]. There is important research and development being done in providing intrinsically safe systems <ref> [12, 23, 24, 28, 29] </ref>, systems incapable of evolving into a state that could lead to injury or loss of life. But the goal of an intrinsically safe system is difficult to achieve for some of today's complex, dynamic applications running in parallel or distributed environments. <p> The safety kernel is itself a system that must be rigorously safe and, thus, does not itself solve the safety problem, but perhaps reduces it to a size that can be tackled successfully by other methods <ref> [24] </ref>. Assertion Checking in Real-Time Systems. Gerber's work [9] on guaranteeing end-to-end timing constraints is an automated design methodology that generates a solution for a set of tasks that keeps consistent a set of end-to-end timing constraints.
Reference: [25] <author> Peter G. Neumann. </author> <title> Computer Related Risks. </title> <publisher> Addison-Wesley, </publisher> <year> 1995. </year>
Reference-contexts: For example, the confluence of events that caused the 1990 AT&T system runaway (a combination of heavy load, software errors, and neighboring switches) caused a 9 hour nationwide blockade that was not anticipated despite extensive testing of the involved 114 electronic switching systems <ref> [25] </ref>. Multiple cause failures such as this can be most easily mitigated with detection oriented approaches. Our goal is to provide such a detection approach through on-line hazard analysis.
Reference: [26] <author> David Ogle. </author> <title> The Real-Time Monitoring of Distributed and Parallel Systems. </title> <type> PhD thesis, </type> <institution> Department of Computer and Information Sciences, The Ohio State University, </institution> <month> Aug </month> <year> 1988. </year>
Reference-contexts: Snodgrass [31] has shown that the relational model is an appropriate formalism for the information processed by the monitor. Earlier applications of this formalism to monitoring were primarily for performance evaluation <ref> [14, 26, 31] </ref>. Whereas performance evaluation is oriented toward the collection and organization of information for what is often post-mortem analysis, hazard detection is oriented toward filtering an overwhelming percentage of the information received. After all, the ultimate goal is to have no query satisfied.
Reference: [27] <author> John Ousterhout. </author> <title> Tcl and the Tk toolkit. </title> <publisher> Addison-Wesley, </publisher> <year> 1995. </year>
Reference-contexts: The nodes are linked together at runtime as a directed acyclic graph (DAG), sometimes referred to as the 'net'. A node object presents an interface that includes the ability to create the node, query the node, and link to it. The toolkit also includes a Tcl interpreter <ref> [27] </ref>, run-time dispatcher, and user interface. As shown in Figure 1, the SafeTQuel compiler accepts both sensor and constraint specifications. From a sensor specification it generates sensor definitions that are used to instrument the application code. The sensor definitions are also used in calls to the Cnet library.
Reference: [28] <author> Vivek Ratan, Kurt Partridge, Jon Reese, and Nancy G. Leveson. </author> <title> Safety analysis tools for requirements specifications. </title> <booktitle> In Proceedings Compass96, </booktitle> <month> June </month> <year> 1996. </year>
Reference-contexts: A safe system is one that is free from accidents or unacceptable losses [19]. There is important research and development being done in providing intrinsically safe systems <ref> [12, 23, 24, 28, 29] </ref>, systems incapable of evolving into a state that could lead to injury or loss of life. But the goal of an intrinsically safe system is difficult to achieve for some of today's complex, dynamic applications running in parallel or distributed environments. <p> Tools include forward simulation, backward hazard analysis using fault trees to display results, a robustness and non-determinism checker, and a software deviation analysis tool which produces scenarios in which specified assumptions about deviations in software inputs can lead to specified hazardous states <ref> [28] </ref>. Kernelization [33] involves structuring the system into two parts, a safety kernel and the rest of the system, so that safety-critical actions do not occur without the consent of the safety kernel.
Reference: [29] <author> Joh Damon Reese and Nancy G. Leveson. </author> <title> Software deviation analysis: A "safeware" technique. </title> <type> Technical report, </type> <institution> University of Washington, </institution> <year> 1996. </year>
Reference-contexts: A safe system is one that is free from accidents or unacceptable losses [19]. There is important research and development being done in providing intrinsically safe systems <ref> [12, 23, 24, 28, 29] </ref>, systems incapable of evolving into a state that could lead to injury or loss of life. But the goal of an intrinsically safe system is difficult to achieve for some of today's complex, dynamic applications running in parallel or distributed environments.
Reference: [30] <author> Richard Snodgrass. </author> <title> The temporal query language TQuel. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 12(2) </volume> <pages> 247-298, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: In particular, hazards are represented as constraints specified on application behavior. These constraints, called safety constraints are specified with a query-like language, SafeTQuel, based on TQuel <ref> [30] </ref>. The SafeTQuel compiler produces a list of commands to the Cnet library. The Cnet library is a collection of routines, written in C, that create operation subroutines (e.g., selection, projection, Cartesian product) and node objects as a collection of operations.
Reference: [31] <author> Richard Snodgrass. </author> <title> A relational approach to monitoring complex systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 6(2) </volume> <pages> 156-196, </pages> <month> May </month> <year> 1988. </year> <month> 20 </month>
Reference-contexts: The specification for the first constraint given above is provided in Section 3.2. The second constraint specification appears in the Appendix. 3 The SafeTQuel Language: New Abstractions 3.1 Introduction to SafeTQuel Snodgrass <ref> [31] </ref> has shown that a relational database query language can be meaningfully applied to asking questions of monitored information. <p> A database that supports valid time but not transaction time is called a historical database. For purposes of monitoring, a historical database is sufficient <ref> [31] </ref>. In addition, the analysis tool checks constraints against a conceptual historical database instead of an actual database. That is, no database per se exists. Instead, each constraint has sufficient storage to maintain the application state it needs. <p> As with its predecessor, TQuel, a SafeTQuel query can be expressed in a relational algebraic form involving the relational operations selection ( F ), projection ( d 1 ;d 2 ;:::;d m ), Cartesian product (fi), and intersection (") <ref> [31] </ref>. For example, for the following constraint C:3 Notify if robot with an ID of 2 is within 10 ft. of a goal. <p> The operations performed on the incoming event stream are applied in the order implicit in the equation. Adapting the operations to an event based environment involves some changes, many of which are discussed in <ref> [31] </ref>. The selection and projection operators are extended in a straightforward manner. Each such operator generates at most one output tuple for each input tuple, and no tuples need to be stored. Cartesian product is more complex. <p> Its efficiency is strongly dependent on the number of tuples from one input which are concatenated with a tuple from the other input and the number of tuples in the underlying relation <ref> [31] </ref>. Number of tuples from one input stream which are concatenated with a tuple from the other. <p> Technically the robot1 stop event precedes every other stop event from the moment it occurs until the end of time. But one cannot realistically implement infinite storage in an on-line system with finite buffers. We adopt an approach similar to that taken in <ref> [31] </ref> by introducing a bounding parameter that limits the life of an event participating in a sequence operation (and in the process limits the semantics of the 'precede' operator as well). <p> The underlying assumptions of the two approaches are quite different, hence continual queries cannot be applied to our problem. Snodgrass <ref> [31] </ref> has shown that the relational model is an appropriate formalism for the information processed by the monitor. Earlier applications of this formalism to monitoring were primarily for performance evaluation [14, 26, 31]. <p> Snodgrass [31] has shown that the relational model is an appropriate formalism for the information processed by the monitor. Earlier applications of this formalism to monitoring were primarily for performance evaluation <ref> [14, 26, 31] </ref>. Whereas performance evaluation is oriented toward the collection and organization of information for what is often post-mortem analysis, hazard detection is oriented toward filtering an overwhelming percentage of the information received. After all, the ultimate goal is to have no query satisfied.
Reference: [32] <author> R. Wahbe, S. Lucco, T. Anderson, and S. Graham. </author> <title> Efficient software-based fault isolation. </title> <booktitle> In Proceedings 14th SOSP, </booktitle> <pages> pages 175-188, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Predictable performance guarantees can be made because of the DAG nature of the graph of connected constraints. Low perturbation is achieved through the use of a separate thread to perform monitoring and synchronous constraint checking. Perturbation could be further reduced by employing a technique used in software fault isolation <ref> [32] </ref> of embedding monitoring related instructions in open slots in the instruction stream. Dynamic applications can be a problem for analysis techniques requiring well defined (i.e., static) applications. Cnet accommodates dynamic applications by allowing dynamic constraint addition.
Reference: [33] <author> K. G. Wika and J. C. Knight. </author> <title> A safety kernel architecture. </title> <type> Technical Report CS-94-04, </type> <institution> University of Virginia, </institution> <year> 1994. </year> <month> 21 </month>
Reference-contexts: Tools include forward simulation, backward hazard analysis using fault trees to display results, a robustness and non-determinism checker, and a software deviation analysis tool which produces scenarios in which specified assumptions about deviations in software inputs can lead to specified hazardous states [28]. Kernelization <ref> [33] </ref> involves structuring the system into two parts, a safety kernel and the rest of the system, so that safety-critical actions do not occur without the consent of the safety kernel.
References-found: 33

