URL: http://www.cogs.susx.ac.uk/users/christ/papers/hw_mch_rprsnttn.ps
Refering-URL: http://www.cogs.susx.ac.uk/users/christ/index-noframes.html
Root-URL: 
Email: Email: Chris.Thornton@cogs.susx.ac.uk  
Phone: Tel: (44)273 606755 3239  
Title: How Much is Enough? A Connectionist Perspective on the Representation Debate  
Author: Chris Thornton 
Address: Brighton BN1 9QN  
Affiliation: Cognitive and Computing Sciences University of Sussex  
Abstract: The paper looks at the tension between the classical assumption that representation is vital for effective cognition and the relatively recent `re-activist' movement which takes a contrary view. A statistical analysis of cognitive tasks is developed and used to support the argument that purely reactivist approaches cannot hope to deal with anything but the most primitive of domains.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Anderson, J., Speohr, K. and Bennett, D. </author> <year> (1991). </year> <title> A study in numerical perversity: teaching arithmetic to a neural network. </title> <type> Technical Report 91-3, </type> <institution> Department of Cognitive and Linguistic Systems, Brown University, </institution> <address> Providence, RI 02912. </address>
Reference-contexts: AI researchers threw themselves enthusiastically into the task of thinking up pithy epigrams which neatly encapsulated the essence of this faith. 1 But now the old, simple trust in the absolute primacy of representation is coming under attack. 1 A recent example appears in <ref> [1] </ref>: `there are three important aspects to any AI system: representation, representation, and representation.' 1 The name that is often associated with this new attack is that of Rodney Brooks.
Reference: [2] <author> Brooks, R. </author> <year> (1986). </year> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, RA-2, </journal> <volume> No. </volume> <pages> 1 (pp. 14-23). </pages>
Reference-contexts: In his own work he has concentrated efforts on the development of situated or embedded `Creatures' | simple, insect-like robots which rely primarily on reactive behaviour to negotiate and interact with genuine (ie. non-simulated), physical environments <ref> [2, 3, 4, 5] </ref>. Of course, the line Brooks is taking is not entirely new.
Reference: [3] <author> Brooks, R. </author> <year> (1986). </year> <title> Achieving artificial intelligence through building robots. MIT A.I. </title> <type> Memo 899, </type> <institution> Masachusetts Institute of Technology. </institution>
Reference-contexts: In his own work he has concentrated efforts on the development of situated or embedded `Creatures' | simple, insect-like robots which rely primarily on reactive behaviour to negotiate and interact with genuine (ie. non-simulated), physical environments <ref> [2, 3, 4, 5] </ref>. Of course, the line Brooks is taking is not entirely new.
Reference: [4] <author> Brooks, R. </author> <year> (1991). </year> <title> Intelligence without reason. </title> <booktitle> Proceedings of the Twelth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 569-595). </pages> <address> San Mateo, California: </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: In his own work he has concentrated efforts on the development of situated or embedded `Creatures' | simple, insect-like robots which rely primarily on reactive behaviour to negotiate and interact with genuine (ie. non-simulated), physical environments <ref> [2, 3, 4, 5] </ref>. Of course, the line Brooks is taking is not entirely new. <p> Of course, the line Brooks is taking is not entirely new. The key idea that `the world is its own best model' <ref> [4] </ref> can be traced back to Gibson's work on vision (which stressed the ways in which the world provides information about itself) while the notion that `Intelligence is determined by the dynamics of interaction with the world' [4] is perhaps best known to cognitivists through the writings of Simon and his <p> The key idea that `the world is its own best model' <ref> [4] </ref> can be traced back to Gibson's work on vision (which stressed the ways in which the world provides information about itself) while the notion that `Intelligence is determined by the dynamics of interaction with the world' [4] is perhaps best known to cognitivists through the writings of Simon and his well-known parable of `the ant on the beach' [6]. But even if the reactivists position is not entirely novel, it is certainly not lacking in force as Brooks' recent publications amply testify. <p> When the arm located a soda can with its local sensors it simply drove the hand so that the two fingers lined up on either side of the can. The hand then independently grasped the can. <ref> [4] </ref> It is fairly clear from this and other extracts that Brooks' robots do not attempt to take any cognisance of relationships in the domain that inhabit.
Reference: [5] <author> Brooks, R. </author> <year> (1991). </year> <title> Intelligence without representation. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 47 (pp. 139-159). </pages>
Reference-contexts: In his own work he has concentrated efforts on the development of situated or embedded `Creatures' | simple, insect-like robots which rely primarily on reactive behaviour to negotiate and interact with genuine (ie. non-simulated), physical environments <ref> [2, 3, 4, 5] </ref>. Of course, the line Brooks is taking is not entirely new. <p> He has described the way in which one of his robots explores the office environment at MIT `searching' for soda cans. On finding a can it removes it <ref> [5] </ref>. Brooks characterizes the reflexes involved as follows. The hand had a grasp reflex that operated whenever something broke an infrared beam between the fingers.
Reference: [6] <author> Simon, H. </author> <year> (1969). </year> <booktitle> The Sciences of the Artificial. </booktitle> <address> Cambridge, Mass.: </address> <publisher> MIT Press. </publisher>
Reference-contexts: vision (which stressed the ways in which the world provides information about itself) while the notion that `Intelligence is determined by the dynamics of interaction with the world' [4] is perhaps best known to cognitivists through the writings of Simon and his well-known parable of `the ant on the beach' <ref> [6] </ref>. But even if the reactivists position is not entirely novel, it is certainly not lacking in force as Brooks' recent publications amply testify. In the context of this developing debate, connectionism finds itself `pig-in-the-middle'.
Reference: [7] <author> Torrance, S. and Thornton, C. (Eds.) </author> <year> (1991). </year> <title> Special issue on hybrid models. </title> <journal> AISB Quarterly, </journal> <volume> No. </volume> <month> 78, </month> <title> AISB society. 6 There is a serious question concerning the extent to which Brooks actually holds this view. Sometimes he seems to take the extreme line (`we believe representations are not necessary and appear only in the eye or mind of the beholder [5, p. 154]). Other times he appears much more moderate and in-line with the current AI orthodoxy (`... abstraction is the essence of intelligence and the hard part of the problems being solved [5, </title> <editor> p. </editor> <volume> 143]). </volume> <pages> 13 </pages>
Reference-contexts: have both put in long-service in the support and advancement of the `principle of good representation', neither discipline has been able to provide any sort of theory that might give the principle a rational basis. 2 In fact hybrid approaches are more eclectic and retain the emphasis on structured representation <ref> [7] </ref>. 2 When one considers the central role that representation has occupied in the thoughts and practices of AI researchers, the total absence of any consensual theory of representation is perplexing. Brooks has certainly done the field a great service in drawing attention to it.
Reference: [8] <author> Hinton, G. </author> <year> (1989). </year> <title> Connectionist learning procedures. </title> <booktitle> Artificial Intelli--gence, </booktitle> <pages> 40 (pp. 185-234). </pages>
Reference-contexts: On the other hand, connectionist researchers continue to volubly stress the central importance of representation in all nontrivial computational tasks (cf. <ref> [8, 9] </ref>). In fact, much state-of-the-art work on constructive algorithms, eg. [10], is directly concerned with methods via which useful representational structures can be learned. Thus, the field might be seen as exerting pressure against the reactivist thesis.
Reference: [9] <author> Fahlman, S. and Lebiere, C. </author> <year> (1990). </year> <title> The Cascade-Correlation Learning Architecture. </title> <institution> CMU-CS-90-100, School of Computer Science, Carnegie-Mellon University, </institution> <address> Pittsburgh, PA 15213. </address>
Reference-contexts: On the other hand, connectionist researchers continue to volubly stress the central importance of representation in all nontrivial computational tasks (cf. <ref> [8, 9] </ref>). In fact, much state-of-the-art work on constructive algorithms, eg. [10], is directly concerned with methods via which useful representational structures can be learned. Thus, the field might be seen as exerting pressure against the reactivist thesis.
Reference: [10] <author> Frean, M. </author> <year> (1989). </year> <title> The Upstart Algorithm: A Method for Constructing and Training Feed-Forward Neural Networks. </title> <type> Edinburgh Physics Preprint 89/479, </type> <institution> Dept. of Physics, University of Edinburgh. </institution>
Reference-contexts: On the other hand, connectionist researchers continue to volubly stress the central importance of representation in all nontrivial computational tasks (cf. [8, 9]). In fact, much state-of-the-art work on constructive algorithms, eg. <ref> [10] </ref>, is directly concerned with methods via which useful representational structures can be learned. Thus, the field might be seen as exerting pressure against the reactivist thesis.
Reference: [11] <author> Thornton, C. </author> <year> (1990). </year> <title> The complexity of constructive induction. DAI Research Paper No. </title> <type> 463, </type> <institution> University of Edinburgh, Dept. of Artificial Intelligence. </institution> <month> 14 </month>
Reference-contexts: pairs are as follows. 0 0 1 1 0 --&gt; 1 1 0 1 0 1 --&gt; 1 1 1 1 1 0 --&gt; 1 1 1 1 0 1 --&gt; 1 3 The question of how a particular mapping can be learned is usually even more difficult to answer <ref> [11] </ref>. 4 No generality is lost by making this assumption since more complex representational forms (eg. structured forms) can always be converted to/from `flat', vector form. 3 0 1 0 0 1 --&gt; 0 0 1 1 0 1 --&gt; 1 Each line here represents a particular entry in the mapping.
References-found: 11

