URL: ftp://ftp.cs.caltech.edu/tr/cs-tr-94-03.ps.Z
Refering-URL: ftp://ftp.cs.caltech.edu/tr/INDEX.html
Root-URL: http://www.cs.caltech.edu
Title: A Message-Driven Programming System for Fine-Grain Multicomputers 1  
Author: Daniel Maskit 
Degree: In Partial Fulfillment of the Requirements for the Degree of Master of Science  
Date: February 1, 1994  
Address: Pasadena, California  
Affiliation: Scalable Concurrent Programming Laboratory California Institute of Technology  
Abstract: 1 The research described in this report is sponsored primarily by the Advanced Research Projects Agency, ARPA Order number 8176, and monitored by the Office of Navel Research under contract number N00014-91-J-1986. The author is partially supported by an NSF Graduate Research Fellowship. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Agha, G., </author> <title> Actors, </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: This concept has been a recurrent theme in both hardware and software designs from the Submicron Systems Architecture Project over the years. It has been incorporated directly into most commercial multicomputer programming systems. In common with Cantor and Actor <ref> [1] </ref> programs, this work utilizes message-driven concurrent processes that do not employ a stack. However, unlike these systems, Message-Driven C processes typically communicate and synchronize via a simple shared variable concept, suspend to cover latency, and may share global state for efficiency. <p> One of the approaches to solving this problem is the use of program transformations to increase locality. An example of an Actors program, reproduced from <ref> [1] </ref>, can be found in Figure 2.5. As Actors is intended 7 to provide an abstraction of concurrency which emphasizes processes without reference to processors, it is not necessary to provide annotations for mapping. def exp Rec-Factorial ()[n] become Rec-Factorial () if n = 0 then reply [1] else reply [n <p> program, reproduced from <ref> [1] </ref>, can be found in Figure 2.5. As Actors is intended 7 to provide an abstraction of concurrency which emphasizes processes without reference to processors, it is not necessary to provide annotations for mapping. def exp Rec-Factorial ()[n] become Rec-Factorial () if n = 0 then reply [1] else reply [n * (call self [n-1])] fi Andrew Chien, in similar work also done at the University of Illinois at Urbana-Champaign explores the use of Concurrent Aggregates to provide an object-oriented approach to implementing a concurrent version of Actors [8].
Reference: [2] <author> Agha, G., et. al., </author> <title> Abstraction and Modularity Mechanisms for Concurrent Computing, </title> <booktitle> IEEE Parallel and Distributed Technology, </booktitle> <month> May, </month> <year> 1993. </year>
Reference-contexts: Gul Agha, in recent work at the University of Illinois at Urbana-Champaign has been working on expanding the Actor model to better reflect the realities of concurrent programming. In <ref> [2] </ref> he discusses the use of Actors within an object-oriented programming framework. The rationale behind this type of framework is the need to provide the programmer with support for abstraction. In particular, the concern of managing concurrency without unduly restricting the expressiveness of the source language is addressed.
Reference: [3] <author> Arvind and Nikhil, </author> <title> R.S. "Executing a Program on the MIT Tagged-Token Dataflow Architecture," </title> <booktitle> Lecture Notes In Computer Science 259, </booktitle> <year> 1987. </year>
Reference-contexts: Arvind and Nikhil at MIT have argued that problems with supporting parallelism on a sequential architecture machine relate to intolerance to the high memory latency required for concurrent programs and the lack of acceptably fast synchronization mechanisms <ref> [3] </ref>. These ideas led to the development of the Tagged-Token Dataflow architecture, a machine that uses additional bits on each data word for synchronization, and is designed to provide optimal support for dataflow programs.
Reference: [4] <author> Athas, W. C. and Seitz, C. L., </author> <title> Cantor User Report, </title> <type> Version 2.0, </type> <institution> California Institute of Technology, Department of Computer Science Technical Report, 5232:TR:86, </institution> <year> 1986. </year>
Reference-contexts: Traditional parallel machines have supported local computation at a significantly lower cost than communication. The result of this has been languages and programs that emphasize executing large pieces of code with minimal communication. Previous reactive programming systems <ref> [4, 7, 24] </ref> hide latency by overlapping computation and communication, but strive to minimize communication. Hardware platforms such as the J-Machine allow the programming system to do far more communication than earlier machines such as the Intel Touchstone Delta. <p> Chapter 2 Related Research The basic concept of message-driven process execution was integrated in Chuck Seitz's hardware design philosophy for multicomputer architectures, and incorporated in a variety of reactive programming systems <ref> [4, 24, 25] </ref>. This concept has been a recurrent theme in both hardware and software designs from the Submicron Systems Architecture Project over the years. It has been incorporated directly into most commercial multicomputer programming systems.
Reference: [5] <author> Boden, Nanette J., </author> <title> Runtime Systems for Fine-Grain Multicomputers, </title> <type> Ph.D. dissertation, </type> <institution> California Institute of Technology, Department of Computer Science, </institution> <year> 1993. </year>
Reference-contexts: An example of an MDC program that computes n! can be found in Figure 2.1. Note the use of the mapping anotation @ to specify the location for execution of each recursive call. Recently, a new generation of fine-grain systems have appeared. The MADRE <ref> [5] </ref> system developed for the Mosaic Architecture [24] distributes the microkernel across multiple computers, and hides the details of process to processor mapping from the user.
Reference: [6] <author> Canetti, R., et. al., </author> <title> "The parallel C (pC) programming language, </title> " <journal> IBM Journal of Research and Development, </journal> 35(5/6):727-741, September/November, 1991. 
Reference-contexts: The hardware process support offered by the J-Machine provides acceptable context-switching performance. Although there have been a variety of systems that have implemented concurrent versions of the C language, such as <ref> [6, 15] </ref>, the previous systems that have involved multicomputer implementations have focused on developing a system that relies on UNIX-style support for system services.
Reference: [7] <author> Chandy, K. M., and Taylor, S., </author> <title> An Introduction to Parallel Programming, </title> <editor> Jones and Bartlett, </editor> <year> 1991. </year>
Reference-contexts: Traditional parallel machines have supported local computation at a significantly lower cost than communication. The result of this has been languages and programs that emphasize executing large pieces of code with minimal communication. Previous reactive programming systems <ref> [4, 7, 24] </ref> hide latency by overlapping computation and communication, but strive to minimize communication. Hardware platforms such as the J-Machine allow the programming system to do far more communication than earlier machines such as the Intel Touchstone Delta. <p> After a computer has received messages from all of its neighbors, the local norm is computed. Another barrier is used to recompute the global norm across the whole machine. The structure of this program is illustrated in 5.4, which is based on discussion in <ref> [7] </ref>. The domain of the problem is broken up into partitions. Each partition is mapped onto a computer. The exchange of information for each timestep requires the transmission of the edges adjacent to a partition boundary being sent to the computer containing the neighboring partition.
Reference: [8] <author> Chien, Andrew, </author> <title> "Supporting Modularity in Highly-Parallel Programs", </title> <booktitle> in research Directions in Object-Based Concurrent Systems, </booktitle> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: become Rec-Factorial () if n = 0 then reply [1] else reply [n * (call self [n-1])] fi Andrew Chien, in similar work also done at the University of Illinois at Urbana-Champaign explores the use of Concurrent Aggregates to provide an object-oriented approach to implementing a concurrent version of Actors <ref> [8] </ref>. The difference between this work and Agha's work is that Chien is experimenting with a new variation on Actors which he calls aggregates. An aggregate is a collection of Actors in which each of the Actors can concurrently receive messages. <p> As the compiler matures it is expected that the number of unnecessary instructions generated will decrease. #define ITERATIONS 1000000 /* Number of messages to send */ #define TARGET 8 /* Computer to send messages to */ void producer (void) f int i; int a <ref> [8] </ref> = f0, 1, 2, 3, 4, 5, 6, 7g; /* Data to Send */ for (i = 0; i &lt; ITERATIONS ; i++) /* Send ITERATION messages */ consumer (sizeof (a), a)@TARGET; g In terms of communication and synchronization, the generated code has the following main components (the reference numbers <p> len, int *array); /* No return value */ #define ITERATIONS 1000000 /* Number of messages to send */ #define TARGET 8 /* Computer to send messages to */ main () f producer ()@0; g /* Start the producer on computer 0 */ void producer (void) f int i; int array <ref> [8] </ref> = f0, 1, 2, 3, 4, 5, 6, 7g; /* Data to Send */ for (i = 0; i &lt; ITERATIONS ; i++) /* Send ITERATION messages */ consumer (sizeof (array), array)@TARGET; g int counter = 0; /* Count the number of messages received */ void consumer (int len, int <p> sets to execute */ #define ITERATIONS 40 /* Number of messages to send per set */ #define TARGET 8 /* Computer to send messages to */ main () f producer ()@0; g /* Start the producer on computer 0 */ void producer (void) f int i, j, k; int array <ref> [8] </ref> = f0, 1, 2, 3, 4, 5, 6, 7g; /* Data to Send */ int returns [ITERATIONS]; /* Array for return values from consumer */ for (k = 0; k &lt; RUNS ; k++) f /* Execute RUNS sets */ for (i = 0; i &lt; ITERATIONS ; i++) /*
Reference: [9] <author> Chien, A., Karamcheti, V., and Plevyak, J., </author> <title> "The concert system compiler and run-time support for efficient fine-grained concurrent object-oriented programs," </title> <type> Technical Report, </type> <institution> UIUCDCS-R-93-1815, Department of Computer Science, University of Illinois, Urbana, Illinois, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: Greater support for abstraction, as well as the use of transformations to improve communication performance, are both topics considered as future work. Chien is also involved in exploring optimization techniques for concurrent object-oriented programs executing on multicomputers constructed with stock processors, such as the CM5 [27]. This work <ref> [9] </ref> describes the design of the Concert system. The key idea in this system is the performance of optimizations at all points in the program compilation and execution cycle. Early optimization is performed using source-to-source transformations in the front-end of the compiler.
Reference: [10] <author> Dally, W. J., et al., </author> <title> "The J-Machine: A Fine-grain Concurrent Computer," Information Processing 89, </title> <editor> G. X. Ritter (ed.), </editor> <publisher> Elsevier Science Publishers B.V., North Holland, IFIP, </publisher> <year> 1989. </year>
Reference-contexts: The J-machine is a similar design, developed at MIT by the Concurrent VLSI Architecture Project, that supports fine-grain processes but also provides on-chip associative memory, and hardware support for process synchronization <ref> [10] </ref>. One of the contributions of these fine-grained architectures is that they have changed the basic set of assumptions for parallel computation. Traditional parallel machines have supported local computation at a significantly lower cost than communication. <p> This thesis describes an experimental message-driven programming system and its implementation on a 512-computer J-machine <ref> [10] </ref>. This machine is an architectural experiment which focuses on the evaluation of hardware mechanisms, such as the integration of messages and processes, to support concurrent programming. The machine combines a unique collection of architectural features that include fine-grain processes, on-chip associative memory, and hardware support for process synchronization. <p> Unfortunately, scalable multicomputer architectures have traditionally supported only Unix-style, coarse-grain, stack-based processes. Thus previous implementations have been forced to utilize an emulation technique to provide efficient systems [13, 26]. The J-machine supports fine-grain processes and also provides on-chip associative memory, and hardware support for process synchronization <ref> [10] </ref>.
Reference: [11] <author> Darnell, Peter A., Margolis, Philip E., and Taylor, Stephen, </author> <note> Software Engineering in C, Springer-Verlag, revised edition in progress. </note>
Reference-contexts: It is important to recognize that although global variables are supported, the intent is to capitalize on their efficiency when used in a good software engineering style for building abstract data types <ref> [11] </ref>. Their use for global sharing between program components in a completely unstructured manner such as that found in most FORTRAN programs is discouraged. An example of an MDC program that computes n! can be found in Figure 2.1.
Reference: [12] <author> Foster, I. and Taylor, S., Strand: </author> <title> New Concepts in Parallel Programming, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J. </address> <year> 1989. </year> <note> 49 50 BIBLIOGRAPHY </note>
Reference-contexts: This model allows code and data to be distributed across the computers in the machine, and is supported at every stage of the program development cycle. Although the concepts are language independent, the prototype system is based on GNU-C. The programming system carries the experience gained from previous experiments <ref> [12, 26, 14] </ref> into a C-based system, while exploiting the special features available in the underlying architecture. The basic programming model for the system is: A computation is a collection of concurrent processes that may execute in any order or in parallel. Processes communicate and synchronize using shared variables. <p> The high-level programming systems that have been developed within this group <ref> [12, 26, 14] </ref>, all share the same fine-grain process model present in this work. An example program written in one of these languages, PCN, can be found in Figure 2.4. The mapping annotations used by PCN and MDC are identical.
Reference: [13] <author> Foster, I., and Taylor, S., </author> <title> "A Portable Run-Time System for PCN," </title> <note> in Argonne National Laboratory Technical Memorandum No. 137, ANL/MCS-TM-137, </note> <month> January, </month> <year> 1990. </year>
Reference-contexts: The mapping annotations used by PCN and MDC are identical. Unfortunately, scalable multicomputer architectures have traditionally supported only Unix-style, coarse-grain, stack-based processes. Thus previous implementations have been forced to utilize an emulation technique to provide efficient systems <ref> [13, 26] </ref>. The J-machine supports fine-grain processes and also provides on-chip associative memory, and hardware support for process synchronization [10]. <p> This work involved designing a set of modifications to the PCN Runtime System <ref> [13] </ref> to take advantage of the hardware capabilities of the J-Machine. In addition, research was done into extensions to the PCN source language that would allow optimizations to take greater advantage of the hardware.
Reference: [14] <author> Foster, I., and Taylor, S., </author> <title> "A Compiler Approach to Scalable Concurrent Program Design", </title> <note> ACM Transactions on Programming Langauges and Systems (to appear). </note>
Reference-contexts: This model allows code and data to be distributed across the computers in the machine, and is supported at every stage of the program development cycle. Although the concepts are language independent, the prototype system is based on GNU-C. The programming system carries the experience gained from previous experiments <ref> [12, 26, 14] </ref> into a C-based system, while exploiting the special features available in the underlying architecture. The basic programming model for the system is: A computation is a collection of concurrent processes that may execute in any order or in parallel. Processes communicate and synchronize using shared variables. <p> The high-level programming systems that have been developed within this group <ref> [12, 26, 14] </ref>, all share the same fine-grain process model present in this work. An example program written in one of these languages, PCN, can be found in Figure 2.4. The mapping annotations used by PCN and MDC are identical. <p> Given the appropriate hardware support, it is clear that efficient parallel implementations of sequential languages can be constructed. In addition, in earlier publications from the Scalable Concurrent Programming Laboratory <ref> [14] </ref>, the feasibility of layering concurrency abstractions on top of a system that provides only the basic support described in this thesis has been demonstrated. This can be achieved through the use of source-to-source transformations.
Reference: [15] <author> Gehani, N.H., and Roome, W.D., </author> <title> "Implementing Concurrent C, </title> " <journal> Software Practice and Experience, </journal> <volume> 22(3) </volume> <pages> 265-285, </pages> <month> March, </month> <year> 1992. </year>
Reference-contexts: The hardware process support offered by the J-Machine provides acceptable context-switching performance. Although there have been a variety of systems that have implemented concurrent versions of the C language, such as <ref> [6, 15] </ref>, the previous systems that have involved multicomputer implementations have focused on developing a system that relies on UNIX-style support for system services.
Reference: [16] <author> Horwat, W., </author> <title> Concurrent Smalltalk on the Message-Driven Processor, </title> <type> Masters thesis, </type> <institution> Massachssetts Institute of Technology, Computer Science Department, </institution> <month> September, </month> <year> 1991. </year>
Reference-contexts: the language does allow the programmer to specify mappings, it's authors recommend that this process be left to the runtime system. processdef factorial f public: atomic int compute (int n) f if (!n) return 1; else f factorial f1; return (n * f1.compute (n-1)); g g A Concurrent Smalltalk (CST) <ref> [16] </ref> system has also been developed for programming the J-machine. CST requires a larger and more complex microkernel to handle a broad range of language concepts that applications within the Scalable Concurrent Programming Laboratory do not require. Figure 2.3 shows an example of a CST program.
Reference: [17] <author> Horwat, W., </author> <title> Message-Driven Processor Simulator, MIT Concurrent VLSI Architecture Memo 38, </title> <institution> Massachssetts Institute of Technology, Computer Science Department, </institution> <month> May, </month> <year> 1991. </year>
Reference-contexts: Although many of these interfaces are based on work done by other people, the final form of the interfaces in this system reflect special needs and goals particular to message-driven C. The initial assembly language definition was developed by Waldemar Horwat at MIT <ref> [17] </ref>. This language was modified by this author as described in [20] to provide explicit support for code distribution, as well as improved efficiency of other tools in the system.
Reference: [18] <author> Marlin, </author> <title> C.D., "A Heap-Based Implementation of the Programing Language Pascal," </title> <journal> Software Practice and Experience, </journal> <volume> 9(2) </volume> <pages> 101-119, </pages> <month> February, </month> <year> 1979. </year>
Reference-contexts: and development of high-level systems on fine-grain multicomputers. factorial (y, result) f ? y == 0 ! result = 1, y &gt; 0 ! fk result = y*r1, factorial (y-1, r1)@nextg g The idea of using a heap-based implementation of a stack-oriented language was earlier reported for Pascal by Marlin <ref> [18] </ref>. This work focused primarily on the Pascal-specific issues of the implementation. In Message-Driven C, heap-based frames are used to support light-weight processes. Although Marlin's work was discussed as a predecessor to a system that supports multi-threaded execution via coroutines, this work shows that a variety of 6 CHAPTER 2.
Reference: [19] <author> Maskit, D., Taylor, S., </author> <title> Experiences in Programming the J-Machine, </title> <institution> California Institute of Technology, Department of Computer Science Technical Report, CS-TR-93-11, </institution> <year> 1993. </year>
Reference: [20] <author> Maskit, D., et. al., </author> <title> System Tools for the J-Machine, </title> <institution> California Institute of Technology, Department of Computer Science Technical Report, CS-TR-93-12, </institution> <year> 1993. </year>
Reference-contexts: The initial assembly language definition was developed by Waldemar Horwat at MIT [17]. This language was modified by this author as described in <ref> [20] </ref> to provide explicit support for code distribution, as well as improved efficiency of other tools in the system.
Reference: [21] <author> Noakes, M., Wallach, D. and Dally, W., </author> <title> "The J-Machine Multicomputer: An Architectural Evaluation," </title> <booktitle> Proceedings of the 20th ` International Symposium on Computer Architecture, </booktitle> <month> May, </month> <year> 1993. </year>
Reference-contexts: The numbers for the hardware performance are derived from the results reported by the MIT Concurrent VLSI Architecture Project in <ref> [21] </ref>. The results reported here are based on a simple producer-consumer code. This code spawns a producer process on one computer which sends 100,000 messages, each of which creates a consumer process on another computer.
Reference: [22] <author> Schauser, K.E., Culler, D.E. and von Eicken, T., </author> <booktitle> "Compiler-Controlled Multithread-ing for Lenient Parallel Languages," Lecture Notes In Computer Science 523, </booktitle> <year> 1991. </year>
Reference-contexts: This can be achieved through the use of source-to-source transformations. Schauser, Culler and von Eicken have developed the idea of compiler decomposition of a program into threads, some of which can be statically scheduled <ref> [22] </ref>. The motivation for this work is the belief that high-speed context switching in hardware is hard. The philosophy of this work is that it is best to leave control of program decomposition to the user, or to tools specific to a class of applications.
Reference: [23] <author> Seizovic, Jakov N., </author> <title> The Architecture and Programming of a Fine-Grain Multicom-puter, </title> <type> Ph.D. dissertation, </type> <institution> California Institute of Technology, Department of Computer Science, </institution> <year> 1994. </year>
Reference-contexts: If a program exhausts local resources, then it is considered to be a poorly-formed program. It is left to the programmer to restructure the code to better balance its resource usage. The language that is supported on the Mosaic for use with the MADRE runtime system is C+- <ref> [23] </ref>. This language is a superset of C++, with additions for process creation and destruction, and communication. The particular emphasis of this work is on supporting 3 4 CHAPTER 2.
Reference: [24] <author> Seitz, C. L., </author> <title> "Multicomputers," Developments in Concurrency and Communication, C.A.R. </title> <editor> Hoare (ed.), </editor> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: Introduction Recently, two radical new architectural experiments have been conducted at Caltech and MIT. At Caltech, the Mosaic architecture, developed by the Submicron Systems Architecture Project, is designed expressly to support efficient fine-grain process execution <ref> [24] </ref>. The J-machine is a similar design, developed at MIT by the Concurrent VLSI Architecture Project, that supports fine-grain processes but also provides on-chip associative memory, and hardware support for process synchronization [10]. <p> Traditional parallel machines have supported local computation at a significantly lower cost than communication. The result of this has been languages and programs that emphasize executing large pieces of code with minimal communication. Previous reactive programming systems <ref> [4, 7, 24] </ref> hide latency by overlapping computation and communication, but strive to minimize communication. Hardware platforms such as the J-Machine allow the programming system to do far more communication than earlier machines such as the Intel Touchstone Delta. <p> Chapter 2 Related Research The basic concept of message-driven process execution was integrated in Chuck Seitz's hardware design philosophy for multicomputer architectures, and incorporated in a variety of reactive programming systems <ref> [4, 24, 25] </ref>. This concept has been a recurrent theme in both hardware and software designs from the Submicron Systems Architecture Project over the years. It has been incorporated directly into most commercial multicomputer programming systems. <p> Note the use of the mapping anotation @ to specify the location for execution of each recursive call. Recently, a new generation of fine-grain systems have appeared. The MADRE [5] system developed for the Mosaic Architecture <ref> [24] </ref> distributes the microkernel across multiple computers, and hides the details of process to processor mapping from the user. <p> considered a useful platform for large-scale scientific 5 applications. (Defmethod factorial Integer ():Integer ( if (= self 0) 1 (* self (factorial @(next) (- self 1))) ) The Scalable Concurrent Programming group has been involved for several years in developing portable, high-performance programming systems that execute efficiently on scalable multicomputers <ref> [24] </ref>. The high-level programming systems that have been developed within this group [12, 26, 14], all share the same fine-grain process model present in this work. An example program written in one of these languages, PCN, can be found in Figure 2.4.
Reference: [25] <author> Su, W., </author> <title> Reactive-Process Programming and Distributed Discrete Event Simulation, </title> <institution> California Institute of Technology, Department of Computer Science Technical Report, CS-TR-89-11, </institution> <year> 1990. </year>
Reference-contexts: Chapter 2 Related Research The basic concept of message-driven process execution was integrated in Chuck Seitz's hardware design philosophy for multicomputer architectures, and incorporated in a variety of reactive programming systems <ref> [4, 24, 25] </ref>. This concept has been a recurrent theme in both hardware and software designs from the Submicron Systems Architecture Project over the years. It has been incorporated directly into most commercial multicomputer programming systems.
Reference: [26] <author> Taylor, S., </author> <title> Parallel Logic Programming Techniques, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1989. </year>
Reference-contexts: This model allows code and data to be distributed across the computers in the machine, and is supported at every stage of the program development cycle. Although the concepts are language independent, the prototype system is based on GNU-C. The programming system carries the experience gained from previous experiments <ref> [12, 26, 14] </ref> into a C-based system, while exploiting the special features available in the underlying architecture. The basic programming model for the system is: A computation is a collection of concurrent processes that may execute in any order or in parallel. Processes communicate and synchronize using shared variables. <p> The high-level programming systems that have been developed within this group <ref> [12, 26, 14] </ref>, all share the same fine-grain process model present in this work. An example program written in one of these languages, PCN, can be found in Figure 2.4. The mapping annotations used by PCN and MDC are identical. <p> The mapping annotations used by PCN and MDC are identical. Unfortunately, scalable multicomputer architectures have traditionally supported only Unix-style, coarse-grain, stack-based processes. Thus previous implementations have been forced to utilize an emulation technique to provide efficient systems <ref> [13, 26] </ref>. The J-machine supports fine-grain processes and also provides on-chip associative memory, and hardware support for process synchronization [10].
Reference: [27] <institution> Thinking Machines Corporation, Cambridge, MA. </institution> <type> CM5 Technical Summary, </type> <institution> Octo-ber, </institution> <year> 1991. </year>
Reference-contexts: Greater support for abstraction, as well as the use of transformations to improve communication performance, are both topics considered as future work. Chien is also involved in exploring optimization techniques for concurrent object-oriented programs executing on multicomputers constructed with stock processors, such as the CM5 <ref> [27] </ref>. This work [9] describes the design of the Concert system. The key idea in this system is the performance of optimizations at all points in the program compilation and execution cycle. Early optimization is performed using source-to-source transformations in the front-end of the compiler.
References-found: 27

