URL: ftp://ftp.cs.cmu.edu/project/chimera/npapas.icra94.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/project/chimera/www/journal_pages/publications.html
Root-URL: 
Title: Abstract  
Abstract: Algorithms for 3D robotic visual tracking of moving targets whose motion is 3D and consists of translational and rotational components are presented. The objective of the system is to track selected features on moving objects and to place their projections on the image plane at desired positions by appropriate camera motion. The most important characteristics of the proposed algorithms are the use of a single camera mounted on the end-effector of a robotic manipulator (eye-in-hand configuration), and the fact that these algorithms do not require accurate knowledge of the relative distance of the target object from the camera frame. This fact makes these algorithms particularly useful in environments that are difficult to calibrate. The camera model used introduces a number of parameters that are estimated on-line, further reducing the algorithms reliance on precise calibration of the system. An adaptive control algorithm compensates for modeling errors, tracking errors, and unavoidable computational delays which result from time-consuming image processing. Experimental results are presented to verify the efficacy of the proposed algorithms. These experiments were performed using a multi-robotic system consisting of Puma 560 manipulators. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Anandan, </author> <title> Measuring Visual Motion from Image Sequences, </title> <type> Technical Report COINS-TR-87-21, </type> <institution> COINS Department, University of Massachusetts, </institution> <year> 1987. </year>
Reference: [2] <author> P.I. Corke, </author> <title> Video-Rate Visual Servoing for Robots, </title> <booktitle> in Lecture Notes in Control and Information Science, </booktitle> <editor> eds. V. Hayward and O. </editor> <booktitle> Khatib, </booktitle> <pages> pp. 429-451, </pages> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference: [3] <author> P.A. Couvignou, N.P. Papanikolopoulos, and P.K. Khosla, </author> <title> Hand-eye Robotic Visual Servoing Around Moving Objects Using Active Deformable Models in Proc. </title> <booktitle> of the 1992 IEEE/RSJ Int. Conf. on Intelligent Robots and Systems (IROS-92), </booktitle> <pages> pp. 1855-1862, </pages> <month> July 7-10, </month> <year> 1992. </year>
Reference-contexts: The measurement y F (k) is computed using the SSD algorithm described in [9]. In order to solve for the manipulator control input, it can be shown that at least three feature points which are not collinear are needed <ref> [3] </ref>.
Reference: [4] <author> E.D. Dickmanns, B. Mysliwetz, and T. Christians, </author> <title> An Integrated Spatio-Temporal Approach to Automatic Visual Guidance of Autonomous Vehicles, </title> <journal> in IEEE Trans. on Systems, Man, and Cybernetics, </journal> <volume> 20(6), </volume> <pages> pp. 1273-1284, </pages> <year> 1990. </year>
Reference: [5] <author> J.T. Feddema and C.S.G. Lee, </author> <title> Adaptive Image Feature Prediction and Control for Visual Tracking with a Hand-Eye Coordinated Camera, </title> <journal> in IEEE Trans. on Systems, Man, and Cybernetics, </journal> <volume> 20(5), </volume> <pages> pp. </pages> <year> 1172-1183,1990. </year>
Reference-contexts: This estimation scheme requires the use of one parameter per feature point making it computationally realistic for real-time control. Some researchers, for example <ref> [5] </ref>, propose the use of an adaptive scheme which estimates all of the elements of the matrix B (k) on-line. As reported in [5], this approach is computationally difficult to perform in real-time. Our proposed approach alleviates these computational problems. 4. <p> This estimation scheme requires the use of one parameter per feature point making it computationally realistic for real-time control. Some researchers, for example <ref> [5] </ref>, propose the use of an adaptive scheme which estimates all of the elements of the matrix B (k) on-line. As reported in [5], this approach is computationally difficult to perform in real-time. Our proposed approach alleviates these computational problems. 4. Experimental Results The results of one experiment using the control and estimation schemes described previously are presented in this section.
Reference: [6] <author> A.J. Koivo and N. Houshangi, </author> <title> Real-Time Vision Feedback for Servoing of a Robotic Manipulator with Self-Tuning Controller, </title> <journal> in IEEE Trans. on Systems, Man, and Cybernetics, </journal> <volume> 21(1), </volume> <pages> pp. </pages> <year> 134-142,1991. </year>
Reference: [7] <author> F.L. Lewis, </author> <title> Optimal Control, </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: Q y k d+( ) y D k d+( )[ ] uD k ( )L d uD k ( ) T u k ( ) B k ( )QB k ( ) L L d + + X= m 1= L d u k 1 ( ) the optimization technique <ref> [7] </ref>. The control law derived previously (11) did not account for noise or inaccuracies in the camera and depth related parameters contained in B (k). Noise and inaccurate parameter values can cause the system to exhibit sluggish and even unstable tracking behavior.
Reference: [8] <author> P.S. Maybeck, </author> <title> Stochastic Processes, Estimation, and Control, </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1979. </year>
Reference-contexts: The term is a covariance scalar which corresponds to the white noise that characterizes the transition between states and is assumed constant. N (j) (k) is the constant predefined covari ance matrix of the gaussian noise vector . The recursive equations are given by <ref> [8] </ref> The depth related parameter is time-varying since the target and the camera move in 3D. The estimation scheme described by equations (31)-(35) can compensate for the time-varying nature of , because the scheme was designed under the assumption that the estimated variable undergoes a random change.
Reference: [9] <author> N.P. Papanikolopoulos, P.K. Khosla, and T. Kanade, </author> <title> Vision and Control Techniques for Robotic Visual Tracking, </title> <booktitle> in Proc. of the IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pp. 857-864, </pages> <month> April, </month> <year> 1991. </year>
Reference-contexts: The measurement y F (k) is computed using the SSD algorithm described in <ref> [9] </ref>. In order to solve for the manipulator control input, it can be shown that at least three feature points which are not collinear are needed [3]. <p> The delay factor d is 2. The four features on the object being tracked are selected by the user with a mouse, and the tracking quality of the features are then evaluated on-line based on the confidence measures described in <ref> [9] </ref>. If a feature does not satisfy a confidence threshold, the user is asked to select a replacement object feature. Figures 1 through 6 show the results from the experiment.
Reference: [10] <author> N.P. Papanikolopoulos, P.K. Khosla, and T. Kanade, </author> <title> Adaptive Robotic Visual Tracking, </title> <booktitle> in Proc. of the American Control Confer-B k( ) ence, </booktitle> <pages> pp. 962-967, </pages> <month> June, </month> <year> 1991. </year>
Reference-contexts: Experimental results demonstrate the ability of the system to successfully track objects moving with six degrees of freedom. This work also demonstrates that the Controlled Active Vision paradigm <ref> [10] </ref> can be success fully used to extend the capabilities of eye-in-hand systems where other tracking methods have failed. 6. Acknowledgments This research was supported by the U.S. Army Research Office through Grant Number DAAL03-91-G-0272 and by Sandia National Laboratories through Contract Number AC-3752D.
Reference: [11] <author> N.P. Papanikolopoulos and P.K. Khosla, </author> <title> Robotic Visual Servo-ing Around a Static Target: An Example of Controlled Active Vision, </title> <booktitle> in Proc. of the 1992 American Control Conference, </booktitle> <pages> pp. 1489-1494, </pages> <year> 1992. </year>
Reference-contexts: The matrix B (k) loses rank when the M feature points are collinear [5]<ref> [11] </ref>. An extensive study of other conditions which cause a loss of rank in B (k) can be found in [11]. No standard procedure exists for choosing the individual elements of L, L d , and Q.
Reference: [12] <author> N.P. Papanikolopoulos and P.K. Khosla, </author> <title> Adaptive Robotic Visual Tracking: Theory and Experiments, </title> <journal> in IEEE Trans. on Automatic Control, </journal> <volume> 38(3), pp.429-445, </volume> <year> 1993. </year> <title> moving object with respect to its initial pose. </title>
References-found: 12

