URL: http://www.neci.nj.nec.com/homepages/oliensis/Oliensis_IUW.ps
Refering-URL: http://www.neci.nj.nec.com/homepages/oliensis/AbstractOliensis.html
Root-URL: 
Title: A Linear Solution for Multiframe Structure from Motion  
Author: John Oliensis 
Address: Amherst, Massachusetts 01003  
Affiliation: Department of Computer Science University of Massachusetts at Amherst  
Abstract: We focus on the problem domain of a robot navigating in and reconstructing an unknown environment from a sequence of images. We argue that the correct approach is to find the appropriate approximation that linearizes the problem, yielding fast, non-iterative algorithms that compute structure and motion with no initial guess. A class of algorithms (batch and recursive) is developed that accomplishes this, where the appropriate algorithm depends on the particular image sequence. Experiments are described on the PUMA sequence [13] and the Rocket Field sequence [2].
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Azarbayejani, B. Horowitz, and A. Pent-land, </author> <title> "Recursive estimation of structure and motion using relative orientation constraints," </title> <booktitle> CVPR, </booktitle> <pages> 294-299, </pages> <year> 1993. </year>
Reference-contexts: Our approach makes no important approximation in singling out one image for special treatment, in contrast to the algorithm of <ref> [1] </ref>. The inverse square root of C H can be computed exactly: it is [C H ] hh 0 = ffi hh 0 N 1 Define D CH C 1=2 H D H and similarly T C (x;y) C H T (x;y) .
Reference: [2] <author> R. Dutta, R. Manmatha, </author> <title> L.R. Williams, and E.M. Riseman, "A data set for quantitative motion analysis," </title> <booktitle> CVPR, </booktitle> <pages> 159-164, </pages> <year> 1989. </year>
Reference: [3] <author> G. Golub and C. F. Van Loan, </author> <title> Matrix Computations, </title> <publisher> John Hopkins Press, Balti-more, Maryland,1983. </publisher>
Reference-contexts: Heeger and Jep-son used this basic trick [6, 4, 7] in the context of recovering motion from optical flow, but their technique did not extend to annihilating general vectors or to sparse flows. Our extension is based on Householder matrices. The Householder matrix <ref> [3] </ref> H ab is an orthogonal ma trix that takes a to b by a reflection. With ^ n (0; 0 : : :1) t , the matrix defined by the first n 1 rows of H a^n is a rank n 1 matrix annihilating ^ n.
Reference: [4] <author> D.J. Heeger and A.D. Jepson, </author> <title> "Subspace methods for recovering rigid motion I: Algorithm and implementation," </title> <booktitle> IJCV 7, </booktitle> <pages> 95-117, </pages> <year> 1992. </year>
Reference-contexts: It also relates to the work of Heeger and Jepson <ref> [6, 4, 7, 5, 15] </ref> on recovering translational motion from optical flow, yielding a simple algorithm for recovering translation from sparse as well as dense optical flow. Our motivation is to develop methods for MFSFM that are approximate but make effective use of the information available and are fast. <p> This is done by postmultiplying D by a rank 2M 3 matrix annihilating V x ; V y ; V z . Heeger and Jep-son used this basic trick <ref> [6, 4, 7] </ref> in the context of recovering motion from optical flow, but their technique did not extend to annihilating general vectors or to sparse flows. Our extension is based on Householder matrices.
Reference: [5] <author> R. Hummel and V. Sundareswaran, </author> <title> "Motion parameter estimation from global flow field data," </title> <type> PAMI 15, </type> <pages> 459-476, </pages> <year> 1993. </year>
Reference-contexts: It also relates to the work of Heeger and Jepson <ref> [6, 4, 7, 5, 15] </ref> on recovering translational motion from optical flow, yielding a simple algorithm for recovering translation from sparse as well as dense optical flow. Our motivation is to develop methods for MFSFM that are approximate but make effective use of the information available and are fast.
Reference: [6] <author> A.D. </author> <title> Jepson and D.J. Heeger, "Linear sub-space methods for recovering translational direction," </title> <institution> University of Toronto Technical Report RBCV-TR-92-40,1992. </institution>
Reference-contexts: It also relates to the work of Heeger and Jepson <ref> [6, 4, 7, 5, 15] </ref> on recovering translational motion from optical flow, yielding a simple algorithm for recovering translation from sparse as well as dense optical flow. Our motivation is to develop methods for MFSFM that are approximate but make effective use of the information available and are fast. <p> This is done by postmultiplying D by a rank 2M 3 matrix annihilating V x ; V y ; V z . Heeger and Jep-son used this basic trick <ref> [6, 4, 7] </ref> in the context of recovering motion from optical flow, but their technique did not extend to annihilating general vectors or to sparse flows. Our extension is based on Householder matrices.
Reference: [7] <author> A.D. </author> <title> Jepson and D.J. Heeger, "A fast sub-space algorithm for recovering rigid motion," </title> <booktitle> Motion Workshop , Princeton, N.J., </booktitle> <pages> 124-131, </pages> <year> 1991. </year>
Reference-contexts: It also relates to the work of Heeger and Jepson <ref> [6, 4, 7, 5, 15] </ref> on recovering translational motion from optical flow, yielding a simple algorithm for recovering translation from sparse as well as dense optical flow. Our motivation is to develop methods for MFSFM that are approximate but make effective use of the information available and are fast. <p> This is done by postmultiplying D by a rank 2M 3 matrix annihilating V x ; V y ; V z . Heeger and Jep-son used this basic trick <ref> [6, 4, 7] </ref> in the context of recovering motion from optical flow, but their technique did not extend to annihilating general vectors or to sparse flows. Our extension is based on Householder matrices.
Reference: [8] <author> A.D. </author> <title> Jepson and D.J. Heeger, "Subspace methods for recovering rigid motion II: Theory," </title> <institution> University of Toronto Technical Report RBCV-TR-90-36, </institution> <year> 1990. </year>
Reference-contexts: However, these results are less informative than those of Table 1, since it is clear there that most of the error is due to just a few structure components, in line with the analysis of Jepson and Heeger <ref> [8] </ref> and Maybank [11, 12] for optical flow. Note that two frame algorithms fail completely on this sequence [14]. We have conducted synthetic experiments to verify the stability of our results against different random noise.
Reference: [9] <author> R. Kumar and A.R. Hanson, </author> <title> "Sensitivity of the Pose Refinement Problem to Accurate Estimation of Camera Parameters," </title> <booktitle> ICCV, </booktitle> <pages> 365-369, </pages> <year> 1990. </year>
Reference-contexts: Such an algorithm was developed and used for the experiments described below. Its description is omitted for lack of space. We applied our algorithm to part of the PUMA image sequence obtained by R. Kumar and H. Sahnwey, described in <ref> [9, 10] </ref>. Specifically, we used a sequence of 32 automatically tracked feature points over 16 image frames tabulated and provided to us by J. I. Thomas. The algorithm of [16], when applied to this sequence, fails to produce a reconstruction.
Reference: [10] <author> R. Kumar and A.R. Hanson, </author> <title> "Pose Refinement: Application to Model Extension and Sensitivity to Camera Parameters," </title> <booktitle> IUW, </booktitle> <pages> 660-669, </pages> <year> 1990. </year>
Reference-contexts: Such an algorithm was developed and used for the experiments described below. Its description is omitted for lack of space. We applied our algorithm to part of the PUMA image sequence obtained by R. Kumar and H. Sahnwey, described in <ref> [9, 10] </ref>. Specifically, we used a sequence of 32 automatically tracked feature points over 16 image frames tabulated and provided to us by J. I. Thomas. The algorithm of [16], when applied to this sequence, fails to produce a reconstruction.
Reference: [11] <author> S. Maybank, </author> <title> Theory of Reconstruction from Image Motion, </title> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1992. </year>
Reference-contexts: However, these results are less informative than those of Table 1, since it is clear there that most of the error is due to just a few structure components, in line with the analysis of Jepson and Heeger [8] and Maybank <ref> [11, 12] </ref> for optical flow. Note that two frame algorithms fail completely on this sequence [14]. We have conducted synthetic experiments to verify the stability of our results against different random noise.
Reference: [12] <author> S. Maybank, </author> <title> "A Theoretical Study of Optical Flow," </title> <type> Doctoral Dissertation, </type> <institution> University of London, </institution> <year> 1987. </year>
Reference-contexts: However, these results are less informative than those of Table 1, since it is clear there that most of the error is due to just a few structure components, in line with the analysis of Jepson and Heeger [8] and Maybank <ref> [11, 12] </ref> for optical flow. Note that two frame algorithms fail completely on this sequence [14]. We have conducted synthetic experiments to verify the stability of our results against different random noise.
Reference: [13] <author> H. S. Sawhney, J. Oliensis, and A. R. Han-son, </author> <title> "Description and Reconstruction from Image Trajectories of Rotational Motion", </title> <booktitle> ICCV, </booktitle> <pages> 494-498, </pages> <year> 1990. </year>
Reference: [14] <author> H.S. Sawhney and A.R. Hanson, </author> <title> "Comparative results of some motion algorithms on real image sequences," </title> <booktitle> IUW, </booktitle> <pages> 307-313, </pages> <year> 1990. </year>
Reference-contexts: Note that two frame algorithms fail completely on this sequence <ref> [14] </ref>. We have conducted synthetic experiments to verify the stability of our results against different random noise. We first generated an exact image sequence corresponding to the ground truth for the structure and motion for the PUMA sequence.
Reference: [15] <author> V. Sun-dareswaran, </author> <title> "Egomotion from global flow field data," Motion Workshop, </title> <publisher> Princeton, </publisher> <pages> 140-145, </pages> <year> 1991. </year>
Reference-contexts: It also relates to the work of Heeger and Jepson <ref> [6, 4, 7, 5, 15] </ref> on recovering translational motion from optical flow, yielding a simple algorithm for recovering translation from sparse as well as dense optical flow. Our motivation is to develop methods for MFSFM that are approximate but make effective use of the information available and are fast.
Reference: [16] <author> C. Tomasi and T. Kanade, </author> <title> "Shape and motion from image streams under orthography: A factorization method," </title> <booktitle> IJCV 9, </booktitle> <pages> 137-154, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction The approach to multiframe structure from motion (MFSFM) for point features described here may be seen as a generalization of the earlier work by Tomasi <ref> [16] </ref> to the case of full perspective|for instance, our approach works well on the Rocket Field sequence, where perspective effects are crucial. <p> We applied our algorithm to part of the PUMA image sequence obtained by R. Kumar and H. Sahnwey, described in [9, 10]. Specifically, we used a sequence of 32 automatically tracked feature points over 16 image frames tabulated and provided to us by J. I. Thomas. The algorithm of <ref> [16] </ref>, when applied to this sequence, fails to produce a reconstruction. First, the images were unrotated automatically to match the first (base) image frame. We used the fact that the rotation was known to be primarily around the optical axis and unrotated around this axis only.
Reference: [17] <author> C. Tomasi and T. Kanade, </author> <title> "Factoring Image Sequences into Shape and Motion," Motion Workshop, </title> <publisher> Princeton, </publisher> <pages> 21-28, </pages> <year> 1991. </year>
References-found: 17

