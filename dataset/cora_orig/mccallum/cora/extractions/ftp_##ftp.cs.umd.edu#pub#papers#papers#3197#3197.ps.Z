URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3197/3197.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Email: E-mail: min@cs.umd.edu, nick@cs.umd.edu  
Title: Adaptive Selectivity Estimation Using Query Feedback  
Author: Chungmin Melvin Chen Nick Roussopoulos 
Address: College Park  
Affiliation: Institute for Advanced Computer Studies and Department of Computer Science University of Maryland,  
Date: December 1993  
Pubnum: UMIACS-TR-93-138  CS-TR-3197  
Abstract: In this paper, we propose a novel approach for estimating the record selectivities of database queries. The real attribute value distribution is adaptively approximated by a curve-fitting function using a query feedback mechanism. This approach has the advantages of requiring no extra database access overhead for gathering statistics and of being able to continuously adapt the value distribution through queries and updates. Experimental results show that the estimation accuracy of this approach is comparable to traditional methods based on statistics gathering.
Abstract-found: 1
Intro-found: 1
Reference: [AG67] <author> A.E. Albert and L.A. Gardner. </author> <title> Stochastic Approximation and Nonlinear Regression. </title> <publisher> M.I.T. Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1967. </year>
Reference-contexts: We describe later in this section how to initialize G 0 and A 0 with appropriate values. It is interesting to see that the computation of A fl i resembles the technique of stochastic approximation <ref> [AG67] </ref>, in the sense that A fl i is adjusted from A fl i1 by subtracting a correction term which is the product of the estimation error (X i A fl i1 s i ) and the gain value G i X t i .
Reference: [Chr83a] <author> S. Christodoulakis. </author> <title> Estimating block transfers and join sizes. </title> <booktitle> In Proceeding of 1983 ACM-SIGMOD Intl. Conf. on Management of Data, </booktitle> <pages> pages 40-54, </pages> <address> New York, </address> <year> 1983. </year>
Reference-contexts: This paper also appears in Proceedings of the 1994 ACM-SIGMOD International Conference on Management of Data, 1994. 1 The issue of selectivity estimation has attracted popular interest, and different methods have been proposed <ref> [MO79, Chr83b, Chr83a, PSC84, KK85, HOT88, Lyn88, MD88, LN90, SLRD93, Ioa93] </ref>. They can be categorized into four classes: the non-parametric method, the parametric method, sampling, and curve fitting. In the following paragraphs, we review the essential approaches for each of these four classes. <p> Moreover, when the actual distribution is not shaped like any of the known model functions, any attempt to approximate the distribution by this method will be in vain. Contributions to research of parametric methods can be found in <ref> [S + 79, SB83, Fed84, Chr83b, Chr83a] </ref>. Curve Fitting In order to overcome the inflexibility of the parametric method, [LST83] and [SLRD93] used a general polynomial function and applied the criterion of least-square-error to approximate attribute value distribution.
Reference: [Chr83b] <author> S. Christodoulakis. </author> <title> Estimating record selectivities. </title> <journal> Inf. Syst., </journal> <volume> 8(2) </volume> <pages> 105-115, </pages> <year> 1983. </year>
Reference-contexts: This paper also appears in Proceedings of the 1994 ACM-SIGMOD International Conference on Management of Data, 1994. 1 The issue of selectivity estimation has attracted popular interest, and different methods have been proposed <ref> [MO79, Chr83b, Chr83a, PSC84, KK85, HOT88, Lyn88, MD88, LN90, SLRD93, Ioa93] </ref>. They can be categorized into four classes: the non-parametric method, the parametric method, sampling, and curve fitting. In the following paragraphs, we review the essential approaches for each of these four classes. <p> Moreover, when the actual distribution is not shaped like any of the known model functions, any attempt to approximate the distribution by this method will be in vain. Contributions to research of parametric methods can be found in <ref> [S + 79, SB83, Fed84, Chr83b, Chr83a] </ref>. Curve Fitting In order to overcome the inflexibility of the parametric method, [LST83] and [SLRD93] used a general polynomial function and applied the criterion of least-square-error to approximate attribute value distribution.
Reference: [dB78] <author> C. de Boor. </author> <title> A practical guide to splines. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1978. </year>
Reference-contexts: Therefore, our choice of degree 6 is a compromise between these concerns 3 . Another interesting class of functions is the spline functions <ref> [dB78] </ref>, which are piecewise polynomial functions. Splines have many advantages over polynomials in the aspects of adaptability and numerical stability. However, they are more complex in computation and particularly in representation. We are currently investigating this approach and will not discuss it here.
Reference: [Fed84] <author> J. Fedorowicz. </author> <title> Database evaluation using multiple regression techniques. </title> <booktitle> In Proceedings of the ACM-SIGMOD Intl. Conf. on Management of Data, </booktitle> <pages> pages 70-76, </pages> <address> Boston, MA, </address> <year> 1984. </year>
Reference-contexts: Moreover, when the actual distribution is not shaped like any of the known model functions, any attempt to approximate the distribution by this method will be in vain. Contributions to research of parametric methods can be found in <ref> [S + 79, SB83, Fed84, Chr83b, Chr83a] </ref>. Curve Fitting In order to overcome the inflexibility of the parametric method, [LST83] and [SLRD93] used a general polynomial function and applied the criterion of least-square-error to approximate attribute value distribution.
Reference: [HOT88] <author> W. Hou, G. Ozsoyoglu, and B. K. Taneja. </author> <title> Statistical estimators for relational algebra expressions. </title> <booktitle> In Proceedings of the ACM SIGACT-SIGMOD Symposium on Principles of Database Systems, </booktitle> <pages> pages 276-287, </pages> <year> 1988. </year>
Reference-contexts: This paper also appears in Proceedings of the 1994 ACM-SIGMOD International Conference on Management of Data, 1994. 1 The issue of selectivity estimation has attracted popular interest, and different methods have been proposed <ref> [MO79, Chr83b, Chr83a, PSC84, KK85, HOT88, Lyn88, MD88, LN90, SLRD93, Ioa93] </ref>. They can be categorized into four classes: the non-parametric method, the parametric method, sampling, and curve fitting. In the following paragraphs, we review the essential approaches for each of these four classes. <p> Sample tuples are taken from the relations, and queries are performed against these samples to collect the statistics. Sufficient samples must be examined before desired accuracy can be achieved. Variations of this method have been proposed in <ref> [HOT88, LN90, HS92] </ref>. Though the sampling method usually gives more accurate estimation than all other methods (suppose suffucient samples are taken), it is primarily used in answering statistical queries (such as COUNT (: : :)).
Reference: [HS92] <author> P. Haas and A. Swami. </author> <title> Sequential sampling procedures for query size estimation. </title> <booktitle> In Proceedings of the ACM-SIGMOD Intl. Conf. on Management of Data, </booktitle> <pages> pages 341-350, </pages> <address> San Diego, CA, </address> <year> 1992. </year>
Reference-contexts: Sample tuples are taken from the relations, and queries are performed against these samples to collect the statistics. Sufficient samples must be examined before desired accuracy can be achieved. Variations of this method have been proposed in <ref> [HOT88, LN90, HS92] </ref>. Though the sampling method usually gives more accurate estimation than all other methods (suppose suffucient samples are taken), it is primarily used in answering statistical queries (such as COUNT (: : :)).
Reference: [IC91] <author> Y.E. Ioannidid and S. Christodoulakis. </author> <title> On the propagation of errors in the size of join results. </title> <booktitle> In Proceedings of the ACM-SIGMOD Intl. Conf. on Management of Data, </booktitle> <pages> pages 268-277, </pages> <address> Denver, Colorado, </address> <year> 1991. </year>
Reference-contexts: One of the most important factors that affects plan cost is selectivity, which is the number of tuples satisfying a given predicate. Therefore, in most cases, the accuracy of selectivity estimates directly affects the choice of best plan. A study on error propagation <ref> [IC91] </ref> revealed that selectivity estimation errors can increase exponentially with the number of joins and thus affect the decisions in query optimization. Accurate selectivity estimation has become even more important in today's systems of much larger database sizes, possibly distributed over a LAN or a WAN.
Reference: [Ioa93] <author> Y.E. Ioannidis. </author> <title> Universality of serial histograms. </title> <booktitle> In Proceedings of the 19th VLDB Conference, </booktitle> <address> Dublin, Ireland, </address> <year> 1993. </year>
Reference-contexts: This paper also appears in Proceedings of the 1994 ACM-SIGMOD International Conference on Management of Data, 1994. 1 The issue of selectivity estimation has attracted popular interest, and different methods have been proposed <ref> [MO79, Chr83b, Chr83a, PSC84, KK85, HOT88, Lyn88, MD88, LN90, SLRD93, Ioa93] </ref>. They can be categorized into four classes: the non-parametric method, the parametric method, sampling, and curve fitting. In the following paragraphs, we review the essential approaches for each of these four classes. <p> The most common method is the histogram, which divides an attribute domain into intervals and counts the number of tuples holding values which fall into each of the intervals. Variations of the histogram method can be found in <ref> [MO79, PSC84, MD88, Lyn88, Ioa93] </ref>. The histogram is simple, but tradeoff between the computation/storage overhead and the estimation accuracy must be considered. Satisfactory accuracy will not be reached until the domain is divided into a sufficient large number of small intervals.
Reference: [KK85] <author> N. Kamel and R. King. </author> <title> A method of data distribution based on texture analysis. </title> <booktitle> In Proceedings of the ACM-SIGMOD Intl. Conf. on Management of Data, </booktitle> <pages> pages 319-325, </pages> <address> Austin, Texas, </address> <year> 1985. </year>
Reference-contexts: This paper also appears in Proceedings of the 1994 ACM-SIGMOD International Conference on Management of Data, 1994. 1 The issue of selectivity estimation has attracted popular interest, and different methods have been proposed <ref> [MO79, Chr83b, Chr83a, PSC84, KK85, HOT88, Lyn88, MD88, LN90, SLRD93, Ioa93] </ref>. They can be categorized into four classes: the non-parametric method, the parametric method, sampling, and curve fitting. In the following paragraphs, we review the essential approaches for each of these four classes. <p> The histogram is simple, but tradeoff between the computation/storage overhead and the estimation accuracy must be considered. Satisfactory accuracy will not be reached until the domain is divided into a sufficient large number of small intervals. In addition to the histogram, a pattern recognition technique was used by <ref> [KK85] </ref> to construct discrete cells of distribution table, and [Lyn88] used a keyterm-oriented approach to keep counts of the most frequently queried attribute values.
Reference: [LN90] <author> R. J. Lipton and J. F. Naughton. </author> <title> Practical selectivity estimation through adaptive sampling. </title> <booktitle> In Proceedings of the ACM SIGMOD Intl. Conf. on Management of Data, </booktitle> <pages> pages 1-11, </pages> <address> Atlantic City, NJ, </address> <year> 1990. </year>
Reference-contexts: This paper also appears in Proceedings of the 1994 ACM-SIGMOD International Conference on Management of Data, 1994. 1 The issue of selectivity estimation has attracted popular interest, and different methods have been proposed <ref> [MO79, Chr83b, Chr83a, PSC84, KK85, HOT88, Lyn88, MD88, LN90, SLRD93, Ioa93] </ref>. They can be categorized into four classes: the non-parametric method, the parametric method, sampling, and curve fitting. In the following paragraphs, we review the essential approaches for each of these four classes. <p> Sample tuples are taken from the relations, and queries are performed against these samples to collect the statistics. Sufficient samples must be examined before desired accuracy can be achieved. Variations of this method have been proposed in <ref> [HOT88, LN90, HS92] </ref>. Though the sampling method usually gives more accurate estimation than all other methods (suppose suffucient samples are taken), it is primarily used in answering statistical queries (such as COUNT (: : :)).
Reference: [LST83] <author> E. Lefons, A. Silvestri, and F. Tangorra. </author> <title> An analytic approach to statistical databases. </title> <booktitle> In Proceedings of the 9th VLDB Conference, </booktitle> <year> 1983. </year> <month> 14 </month>
Reference-contexts: Contributions to research of parametric methods can be found in [S + 79, SB83, Fed84, Chr83b, Chr83a]. Curve Fitting In order to overcome the inflexibility of the parametric method, <ref> [LST83] </ref> and [SLRD93] used a general polynomial function and applied the criterion of least-square-error to approximate attribute value distribution. First, the relation is exhaustively scanned, and the number of occurrences of each attribute value is counted. <p> The rest of this paper is organized as follows: Section 2 describes the adaptive selectivity estimator in detail. Section 3 presents some of our experimental results. Finally, conclusions are given in Section 4. the Legendre polynomials are used as the basis in <ref> [LST83] </ref>. 3 2 Adaptive Selectivity Estimation In this section, we describe the implementation of an Adaptive Selectivity Estimator (ASE). At the heart of our approach is a technique called recursive least-square-error (RLSE), which is adopted to adjust the approximating distribution according to subsequent feedbacks. <p> Choosing the Model Functions The remaining problem now is to choose the model functions i (x). The polynomial function is a good candidate due to its generality and simplicity and has been used in <ref> [LST83] </ref> and [SLRD93]. We adopted polynomials of degree 6 throughout our experiments, i.e., the approxi mating function is of the form f (x) = P 6 i=0 a i x i .
Reference: [Lyn88] <author> C. A. Lynch. </author> <title> Selectivity estimation and query optimization in large databases with highly skewed distributions of column values. </title> <booktitle> In Proceedings of the 14th VLDB Conference, </booktitle> <pages> pages 240-251, </pages> <address> Los Angeles, CA, </address> <year> 1988. </year>
Reference-contexts: This paper also appears in Proceedings of the 1994 ACM-SIGMOD International Conference on Management of Data, 1994. 1 The issue of selectivity estimation has attracted popular interest, and different methods have been proposed <ref> [MO79, Chr83b, Chr83a, PSC84, KK85, HOT88, Lyn88, MD88, LN90, SLRD93, Ioa93] </ref>. They can be categorized into four classes: the non-parametric method, the parametric method, sampling, and curve fitting. In the following paragraphs, we review the essential approaches for each of these four classes. <p> The most common method is the histogram, which divides an attribute domain into intervals and counts the number of tuples holding values which fall into each of the intervals. Variations of the histogram method can be found in <ref> [MO79, PSC84, MD88, Lyn88, Ioa93] </ref>. The histogram is simple, but tradeoff between the computation/storage overhead and the estimation accuracy must be considered. Satisfactory accuracy will not be reached until the domain is divided into a sufficient large number of small intervals. <p> Satisfactory accuracy will not be reached until the domain is divided into a sufficient large number of small intervals. In addition to the histogram, a pattern recognition technique was used by [KK85] to construct discrete cells of distribution table, and <ref> [Lyn88] </ref> used a keyterm-oriented approach to keep counts of the most frequently queried attribute values. Parametric Method Parametric methods approximate the actual distribution with a mathematical distribution function of a certain number of free statistical parameter (s) to be estimated (we call such a function a model function).
Reference: [MCS88] <author> M.V. Mannino, P. Chu, and T. Sager. </author> <title> Statistical profile estimation in database systems. </title> <journal> ACM Computing Surveys, </journal> <volume> 20(3), </volume> <year> 1988. </year>
Reference-contexts: They can be categorized into four classes: the non-parametric method, the parametric method, sampling, and curve fitting. In the following paragraphs, we review the essential approaches for each of these four classes. A detailed survey of the first two classes can be found in <ref> [MCS88] </ref>. Non-Parametric Method Methods in this class maintain attribute value distributions using ad hoc data structures and algorithms. The most common method is the histogram, which divides an attribute domain into intervals and counts the number of tuples holding values which fall into each of the intervals.
Reference: [MD88] <author> M. Muralikrishma and D. DeWitt. </author> <title> Equi-depth histograms for estimating selectivity factors for multi-dimensional queries. </title> <booktitle> In Proceedings of the ACM-SIGMOD Conf. on Management of Data, </booktitle> <pages> pages 28-36, </pages> <address> Chicago, Illinois, </address> <year> 1988. </year>
Reference-contexts: This paper also appears in Proceedings of the 1994 ACM-SIGMOD International Conference on Management of Data, 1994. 1 The issue of selectivity estimation has attracted popular interest, and different methods have been proposed <ref> [MO79, Chr83b, Chr83a, PSC84, KK85, HOT88, Lyn88, MD88, LN90, SLRD93, Ioa93] </ref>. They can be categorized into four classes: the non-parametric method, the parametric method, sampling, and curve fitting. In the following paragraphs, we review the essential approaches for each of these four classes. <p> The most common method is the histogram, which divides an attribute domain into intervals and counts the number of tuples holding values which fall into each of the intervals. Variations of the histogram method can be found in <ref> [MO79, PSC84, MD88, Lyn88, Ioa93] </ref>. The histogram is simple, but tradeoff between the computation/storage overhead and the estimation accuracy must be considered. Satisfactory accuracy will not be reached until the domain is divided into a sufficient large number of small intervals.
Reference: [MO79] <author> T.H. Merrett and E. Otoo. </author> <title> Distribution models of relations. </title> <booktitle> In Proceedings of the 5th VLDB Conference, </booktitle> <pages> pages 418-425, </pages> <address> Rio De Janero, Brazil, </address> <year> 1979. </year>
Reference-contexts: This paper also appears in Proceedings of the 1994 ACM-SIGMOD International Conference on Management of Data, 1994. 1 The issue of selectivity estimation has attracted popular interest, and different methods have been proposed <ref> [MO79, Chr83b, Chr83a, PSC84, KK85, HOT88, Lyn88, MD88, LN90, SLRD93, Ioa93] </ref>. They can be categorized into four classes: the non-parametric method, the parametric method, sampling, and curve fitting. In the following paragraphs, we review the essential approaches for each of these four classes. <p> The most common method is the histogram, which divides an attribute domain into intervals and counts the number of tuples holding values which fall into each of the intervals. Variations of the histogram method can be found in <ref> [MO79, PSC84, MD88, Lyn88, Ioa93] </ref>. The histogram is simple, but tradeoff between the computation/storage overhead and the estimation accuracy must be considered. Satisfactory accuracy will not be reached until the domain is divided into a sufficient large number of small intervals.
Reference: [PSC84] <author> G. Piatetsky-Shapiro and C. Connell. </author> <title> Accurate estimation of the number of tuples satisfying a condition. </title> <booktitle> In Proceedings of the ACM-SIGMOD Intl. Conf. on Management of Data, </booktitle> <pages> pages 256-275, </pages> <address> Boston, MA, </address> <year> 1984. </year>
Reference-contexts: This paper also appears in Proceedings of the 1994 ACM-SIGMOD International Conference on Management of Data, 1994. 1 The issue of selectivity estimation has attracted popular interest, and different methods have been proposed <ref> [MO79, Chr83b, Chr83a, PSC84, KK85, HOT88, Lyn88, MD88, LN90, SLRD93, Ioa93] </ref>. They can be categorized into four classes: the non-parametric method, the parametric method, sampling, and curve fitting. In the following paragraphs, we review the essential approaches for each of these four classes. <p> The most common method is the histogram, which divides an attribute domain into intervals and counts the number of tuples holding values which fall into each of the intervals. Variations of the histogram method can be found in <ref> [MO79, PSC84, MD88, Lyn88, Ioa93] </ref>. The histogram is simple, but tradeoff between the computation/storage overhead and the estimation accuracy must be considered. Satisfactory accuracy will not be reached until the domain is divided into a sufficient large number of small intervals.
Reference: [S + 79] <author> P. G. Selinger et al. </author> <title> Access path selection in a relational database management system. </title> <booktitle> In Procs. of ACM-SIGMOD, </booktitle> <pages> pages 23-34, </pages> <year> 1979. </year>
Reference-contexts: Moreover, when the actual distribution is not shaped like any of the known model functions, any attempt to approximate the distribution by this method will be in vain. Contributions to research of parametric methods can be found in <ref> [S + 79, SB83, Fed84, Chr83b, Chr83a] </ref>. Curve Fitting In order to overcome the inflexibility of the parametric method, [LST83] and [SLRD93] used a general polynomial function and applied the criterion of least-square-error to approximate attribute value distribution.
Reference: [SB83] <author> W. Samson and A. Bendell. </author> <title> Rank order distriburions and secondary key indexing. </title> <booktitle> In Proceedings of the 2nd Intl. Conf. on Databases, </booktitle> <address> Cambridge, England, </address> <year> 1983. </year>
Reference-contexts: Moreover, when the actual distribution is not shaped like any of the known model functions, any attempt to approximate the distribution by this method will be in vain. Contributions to research of parametric methods can be found in <ref> [S + 79, SB83, Fed84, Chr83b, Chr83a] </ref>. Curve Fitting In order to overcome the inflexibility of the parametric method, [LST83] and [SLRD93] used a general polynomial function and applied the criterion of least-square-error to approximate attribute value distribution.
Reference: [SLRD93] <author> W. Sun, Y. Ling, N. Rishe, and Y. Deng. </author> <title> An instant and accurate size estimation method for joins and selection in a retrieval-intensive environment. </title> <booktitle> In Proceedings of the ACM-SIGMOD Intl. Conf. on Management of Data, </booktitle> <pages> pages 79-88, </pages> <address> Washington, DC, </address> <year> 1993. </year>
Reference-contexts: This paper also appears in Proceedings of the 1994 ACM-SIGMOD International Conference on Management of Data, 1994. 1 The issue of selectivity estimation has attracted popular interest, and different methods have been proposed <ref> [MO79, Chr83b, Chr83a, PSC84, KK85, HOT88, Lyn88, MD88, LN90, SLRD93, Ioa93] </ref>. They can be categorized into four classes: the non-parametric method, the parametric method, sampling, and curve fitting. In the following paragraphs, we review the essential approaches for each of these four classes. <p> Contributions to research of parametric methods can be found in [S + 79, SB83, Fed84, Chr83b, Chr83a]. Curve Fitting In order to overcome the inflexibility of the parametric method, [LST83] and <ref> [SLRD93] </ref> used a general polynomial function and applied the criterion of least-square-error to approximate attribute value distribution. First, the relation is exhaustively scanned, and the number of occurrences of each attribute value is counted. <p> Choosing the Model Functions The remaining problem now is to choose the model functions i (x). The polynomial function is a good candidate due to its generality and simplicity and has been used in [LST83] and <ref> [SLRD93] </ref>. We adopted polynomials of degree 6 throughout our experiments, i.e., the approxi mating function is of the form f (x) = P 6 i=0 a i x i . <p> If q i is the first query after the latest update, set the fading weight ff i to a positive number less than 1. Use i to adjust A and G, as shown in Eqs. 11 and 12. Comparison with <ref> [SLRD93] </ref> Sun, Ling, Rishe, and Deng proposed in [SLRD93] a method of approximating the attribute distribution using a polynomial with the criterion of least-square-error. While both their method and ours use polynomial approximations, there are several differences between the two methods. <p> If q i is the first query after the latest update, set the fading weight ff i to a positive number less than 1. Use i to adjust A and G, as shown in Eqs. 11 and 12. Comparison with <ref> [SLRD93] </ref> Sun, Ling, Rishe, and Deng proposed in [SLRD93] a method of approximating the attribute distribution using a polynomial with the criterion of least-square-error. While both their method and ours use polynomial approximations, there are several differences between the two methods. <p> We ran the experiments using the mathematics package MAPLE, developed by the Symbolic Computation Group of the University of Waterloo; MAPLE was chosen for its provision of immediate access to matrix operations and random number generators. We experimented also with the method proposed in <ref> [SLRD93] </ref> (referred to as SLR in what follows) for comparisons whenever appropri 9 ate. The selectivity estimation errors and the adaptation dynamics of ASE were observed and graphed for demonstration.
Reference: [Wil91] <author> D.E. Willard. </author> <title> Optimal sample cost residues for differential database batch query problems. </title> <journal> Journal of the ACM, </journal> <volume> 38(1) </volume> <pages> 104-119, </pages> <year> 1991. </year>
Reference-contexts: This approach is advantageous in the following respects: * Efficiency | Unlike the previous methods, no off-line database scans or on-line sampling are needed to form the value distribution. Also, unlike all the other methods (except sampling <ref> [Wil91] </ref>), where the statistics collection and computation overhead is proportional to the relation size, the overhead of our method has a negligible cost in constant time for each query feedback, regardless of the relation size. * Adaptation | The technique we use here adapts the approximating value distribution to queries and
Reference: [You84] <author> P. Young. </author> <title> Recursive estimation and time-series analysis. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1984. </year>
Reference-contexts: Also notice that by using Eqs. 6 and 7, only two constant size arrays, P and N , need to be maintained. The above equations can be further transformed into another form where the expensive matrix inversion P 1 i need not be explicitly computed. <ref> [You84] </ref> derived the following recursive formulas, referred to as Recursive Least-Square-Error (RLSE), from Eqs. 6 and 7 : A fl i1 G i X t i1 s i ); (8) i (1 + X i G i1 X t for i = 1; 2; : : :, while A 0 and <p> Initializing A 0 and G 0 The initial values of G 0 and A 0 must be determined before the recursive formulas in Eqs. 11 and 12 can be used. Theoretically, arbitrary initial values can be used for G 0 and A 0 <ref> [You84] </ref>, though they differ greatly in convergence rates.
References-found: 22

