URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR94488.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Email: seema@sgi.com ken@cs.rice.edu tseng@cs.stanford.edu scott@cs.rice.edu  
Title: The D Editor: A New Interactive Parallel Programming Tool  
Author: Seema Hiranandani Ken Kennedy* Chau-Wen Tseng Scott Warren* 
Address: Mountain View, CA 94039-7311  Houston, TX 77251-1892  Stanford, CA 94305-4070  
Affiliation: Silicon Graphics Computer Systems,  *Department of Computer Science, Rice University,  Computer Systems Laboratory, Stanford University,  
Note: Proceedings of Supercomputing'94. ISSN 1063-9535. Copyright (c) 1994 IEEE. All rights reserved.  
Abstract: Fortran D and High Performance Fortran are languages designed to support efficient data-parallel programming on a variety of parallel architectures. The goal of the D Editor is to provide a tool that allows scientists to use these languages efficiently. The D Editor combines analyses for shared-memory machines and compiler optimizations for distributed-memory machines. By cooperating with the underlying compiler, it can provide novel information on partitioning, parallelism, and communication based on compile-time analysis at the level of the original Fortran program. The D Editor uses color coding and a collection of graphical displays to help the user to zoom in on portions of the program containing sequentialized code or expensive communication. The prototype implementation is useful for interactively displaying the results of compile-time analysis; however, it has a number of shortcomings that must be addressed. Future enhancements will provide additional advice and transformation capabilities. We believe the D Editor is representative of a new generation of tools that will be needed to assist scientists to fully exploit languages such as High Performance Fortran. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> ANSI X3J3/S8.115. </author> <title> Fortran 90, </title> <month> June </month> <year> 1990. </year>
Reference-contexts: HPF was based on a number of existing languages such as Fortran 90 <ref> [1] </ref>, CM Fortran [25], Fortran D [11], and Vienna Fortran [7]. It simplifies programming by providing a global name space for the user, along with a variety of useful data-parallel array operations.
Reference: [2] <institution> Applied Parallel Research, Placerville, CA. </institution> <note> Forge 90 Distributed Memory Parallelizer: User's Guide, version 8.0 edition, </note> <year> 1992. </year>
Reference-contexts: One of the novel features found in HPF are annotations that allow users or automatic tools to specify data placement, the partitioning of data onto processors. Using these annotations, in many cases advanced compilers can automatically generate efficient programs for MIMD distributed-memory machines [17] or even networks of workstations <ref> [2] </ref>. This research was sponsored by ARPA under contract #DABT63-91-K-0005 & DABT63-92-C-0038 and the IBM Corporation. Additional support was provided by the Center for Research on Parallel Computation (CRPC), a Science and Technology Center funded by NSF through Cooperative Agreement Number CCR-9120008. <p> TINY is a system that provides precise data dependence analysis and program transformations for a core subset of Fortran [28]. FORGE 90 is an interactive parallelization system that performs data-flow and dependence analyses and also supports loop-level transformations <ref> [2] </ref>. Associated tools graphically display call graph, control flow, dependence, and profiling information. FORGE 90 can be used to generate parallel programs for both shared and distributed-memory machines. The VIENNA FORTRAN compilation system, a successor to SUPERB, can display the program after different stages of compilation to distributed-memory machines [7].
Reference: [3] <author> V. Balasundaram, G. Fox, K. Kennedy, and U. Kremer. </author> <title> An interactive environment for data partitioning and distribution. </title> <booktitle> In Proceedings of the 5th Distributed Memory Computing Conference, </booktitle> <address> Charleston, SC, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: The system contains FIAT, an interprocedural analysis framework [15], the Fortran D compiler [17], and tools for performing automatic data decomposition <ref> [3] </ref>, data-race detection, static performance estimation [4, 20], and performance profiling. All these components will be integrated in the D Editor, the core of the D system. <p> From Fortran D statements we find array A is distributed block-wise in the first dimension. Since the data dependence occurs only between elements of the third dimension, the endpoints of the dependence are on the same processor. The dependence is thus internalized and does not affect node-level parallelism <ref> [3] </ref>. The entire loop nest is thus executed in parallel without synchronization. In order to avoid reporting these internalized data dependences, the Fortran D compiler applies algorithms to distinguish dependences causing synchronization between nodes as cross-processor dependences [17]. <p> Automatic Data Decomposition. The D Editor currently provides information for the data decomposition specified in the program. Instead of evaluating each data decomposition and presenting its effect on parallelism and communication, the D Editor can incorporate heuristics for automatically selecting data decompositions <ref> [3] </ref>. The resulting choices can then be presented to the user as a list of possible selections, or be used to suggest data decompositions that provide better overall performance. Performance Statistics. Another useful feature for the D Editor is providing performance data.
Reference: [4] <author> V. Balasundaram, G. Fox, K. Kennedy, and U. Kremer. </author> <title> A static performance estimator to guide data partitioning decisions. </title> <booktitle> In Proceedings of the Third ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> Williamsburg, VA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: The system contains FIAT, an interprocedural analysis framework [15], the Fortran D compiler [17], and tools for performing automatic data decomposition [3], data-race detection, static performance estimation <ref> [4, 20] </ref>, and performance profiling. All these components will be integrated in the D Editor, the core of the D system. <p> Execution times would also make it easier to evaluate the effectiveness of automatic data decomposition or program transformations. Performance statistics may either be collected at compile time through static performance estimation <ref> [4, 20] </ref> or at run time via profiling [10]. Graphic User Interfaces. Additional facilities for presenting analyses and performance data graphically can improve the usefulness of the D Editor.
Reference: [5] <author> Z. Bozkus, A. Choudhary, G. Fox, T. Haupt, S. Ranka, and M. Wu. </author> <title> Compiling Fortran 90D/HPF for distributed memory MIMD computers. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 21(1) </volume> <pages> 15-26, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: It incorporates a performance estimation system that relies on profiling information [10]. The FORTRAN 90D compiler is a closely related project that shares many of the design and implementation strategies of the Fortran D compiler <ref> [5] </ref>. It takes Fortran 90 as input, provides robust run-time support, but does not attempt automatic paralleliza-tion.
Reference: [6] <author> D. Callahan and K. Kennedy. </author> <title> Compiling programs for distributed-memory multiprocessors. </title> <journal> Journal of Supercomputing, </journal> <volume> 2 </volume> <pages> 151-169, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: The D Editor is one of the first to combine both features in a single parallel programming tool. The Fortran D compiler is similar to CALLAHAN-KENNEDY <ref> [6] </ref>, SUPERB [12], and KALI [23] in that the compilation process is based on the decomposition of data in the program.
Reference: [7] <author> B. Chapman, P. Mehrotra, and H. Zima. </author> <title> Programming in Vienna Fortran. </title> <journal> Scientific Programming, </journal> <volume> 1(1) </volume> <pages> 31-50, </pages> <month> Fall </month> <year> 1992. </year>
Reference-contexts: HPF was based on a number of existing languages such as Fortran 90 [1], CM Fortran [25], Fortran D [11], and Vienna Fortran <ref> [7] </ref>. It simplifies programming by providing a global name space for the user, along with a variety of useful data-parallel array operations. One of the novel features found in HPF are annotations that allow users or automatic tools to specify data placement, the partitioning of data onto processors. <p> Associated tools graphically display call graph, control flow, dependence, and profiling information. FORGE 90 can be used to generate parallel programs for both shared and distributed-memory machines. The VIENNA FORTRAN compilation system, a successor to SUPERB, can display the program after different stages of compilation to distributed-memory machines <ref> [7] </ref>. It incorporates a performance estimation system that relies on profiling information [10]. The FORTRAN 90D compiler is a closely related project that shares many of the design and implementation strategies of the Fortran D compiler [5].
Reference: [8] <author> K. Cooper, M. W. Hall, R. T. Hood, K. Kennedy, K. S. McKinley, J. M. Mellor-Crummey, L. Torczon, and S. K. Warren. </author> <title> The Para-Scope parallel programming environment. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 81(2) </volume> <pages> 244-263, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: Details are presented elsewhere [14, 17, 19, 26]. 2.3 The ParaScope Programming Environment The Fortran D compiler is implemented as a part of ParaScope, a programming environment that pioneered research on inter-procedural optimization in an efficient compilation system <ref> [8, 9] </ref>. Its interprocedural compilation framework has been encapsulated into a system called FIAT (Framework for Interprocedural Analysis and Transformation) [15] and used to solve a number of inter-procedural problems in both ParaScope and the Stanford SUIF compiler.
Reference: [9] <author> K. Cooper, K. Kennedy, and L. Torczon. </author> <title> The impact of inter-procedural analysis and optimization in the IR n programming environment. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 8(4) </volume> <pages> 491-523, </pages> <month> October </month> <year> 1986. </year>
Reference-contexts: Details are presented elsewhere [14, 17, 19, 26]. 2.3 The ParaScope Programming Environment The Fortran D compiler is implemented as a part of ParaScope, a programming environment that pioneered research on inter-procedural optimization in an efficient compilation system <ref> [8, 9] </ref>. Its interprocedural compilation framework has been encapsulated into a system called FIAT (Framework for Interprocedural Analysis and Transformation) [15] and used to solve a number of inter-procedural problems in both ParaScope and the Stanford SUIF compiler.
Reference: [10] <author> T. Fahringer, R. Blasko, and H. Zima. </author> <title> Automatic performance prediction to support parallelization of Fortran programs for massively parallel systems. </title> <booktitle> In Proceedings of the 1992 ACM International Conference on Supercomputing, </booktitle> <address> Washington, DC, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: Execution times would also make it easier to evaluate the effectiveness of automatic data decomposition or program transformations. Performance statistics may either be collected at compile time through static performance estimation [4, 20] or at run time via profiling <ref> [10] </ref>. Graphic User Interfaces. Additional facilities for presenting analyses and performance data graphically can improve the usefulness of the D Editor. <p> FORGE 90 can be used to generate parallel programs for both shared and distributed-memory machines. The VIENNA FORTRAN compilation system, a successor to SUPERB, can display the program after different stages of compilation to distributed-memory machines [7]. It incorporates a performance estimation system that relies on profiling information <ref> [10] </ref>. The FORTRAN 90D compiler is a closely related project that shares many of the design and implementation strategies of the Fortran D compiler [5]. It takes Fortran 90 as input, provides robust run-time support, but does not attempt automatic paralleliza-tion.
Reference: [11] <author> G. Fox, S. Hiranandani, K. Kennedy, C. Koelbel, U. Kremer, C.-W. Tseng, and M. Wu. </author> <title> Fortran D language specification. </title> <type> Technical Report TR90-141, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> De-cember </month> <year> 1990. </year>
Reference-contexts: HPF was based on a number of existing languages such as Fortran 90 [1], CM Fortran [25], Fortran D <ref> [11] </ref>, and Vienna Fortran [7]. It simplifies programming by providing a global name space for the user, along with a variety of useful data-parallel array operations. <p> Each dimension is distributed in a BLOCK, CYCLIC, or BLOCK CYCLIC manner; the symbol : marks dimensions that are not distributed. Because the alignment and distribution statements are executable, dynamic data decomposition is possible. The complete language is described in detail elsewhere <ref> [11] </ref>. Apart from minor syntactic differences, HPF provides data decomposition specifications virtually identical to those in Fortran D. Our experiences with the Fortran D compiler and D Editor are thus immediately applicable to HPF. HPF provides additional array in-trinsics, procedure interfaces, and external interfaces not found in Fortran D.
Reference: [12] <author> M. Gerndt. </author> <title> Updating distributed variables in local computations. </title> <journal> Concurrency: Practice & Experience, </journal> <volume> 2(3) </volume> <pages> 171-193, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: The D Editor is one of the first to combine both features in a single parallel programming tool. The Fortran D compiler is similar to CALLAHAN-KENNEDY [6], SUPERB <ref> [12] </ref>, and KALI [23] in that the compilation process is based on the decomposition of data in the program. In comparison with these and other systems, the Fortran D compiler performs significantly more compile-time analysis and optimization and relies less on program transformations, language extensions or an extensive run-time system.
Reference: [13] <author> M. W. Hall, T. Harvey, K. Kennedy, N. McIntosh, K. S. M c Kinley, J. D. Oldham, M. Paleczny, and G. Roth. </author> <title> Experiences using the ParaScope Editor: an interactive parallel programming tool. </title> <booktitle> In Proceedings of the Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: However, experience with parallelizing compilers for shared-memory machines has shown that no automatic system will work perfectly in all (some say most) cases. When automatic systems fail due to imperfect analysis or incorrect heuristics, compiler feedback [27] or interactive parallelization systems <ref> [13, 21] </ref> can prove helpful. 1.1 Feedback for High Performance Fortran We believe that user feedback and interaction will be very important for languages such as HPF, because on massively parallel systems small mistakes may cause large degradations in performance. <p> A key component of the ParaScope environment is the Para-Scope Editor (PED), an intelligent interactive editor for shared-memory machines <ref> [13, 21, 22] </ref>. The ParaScope Editor provides the results of sophisticated program analyses and a variety of powerful program transformations that have been shown useful in converting programs to parallel form. <p> We first examine features of the graphical display, then show how it works on an example program. The D Editor display is derived from the display of the ParaScope Editor <ref> [13, 21, 22] </ref>, but contains significantly more information. Figure 6 provides an example of the user interface of the D Editor for different versions of SOR. The display is separated into five panes. <p> In comparison with these and other systems, the Fortran D compiler performs significantly more compile-time analysis and optimization and relies less on program transformations, language extensions or an extensive run-time system. The D Editor is based on the ParaScope Editor <ref> [13, 21, 22] </ref>. They share many features, including the underlying hybrid text/structure editor, graphics utilities, and dependence display. The ParaScope Editor is distinguished by its incremental analysis and ability to provide guidance on a large number of interactive program transformations.
Reference: [14] <author> M. W. Hall, S. Hiranandani, K. Kennedy, and C.-W. Tseng. </author> <title> Inter-procedural compilation of Fortran D for MIMD distributed-memory machines. </title> <booktitle> In Proceedings of Supercomputing'92, </booktitle> <address> Minneapolis, MN, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: the D Editor must be able to explain to the user how changes in the high-level program will affect both the output code and its performance, especially changes to the data decomposition. 1.3 Contributions In previous work, we described the design, implementation, and evaluation of a prototype Fortran D compiler <ref> [14, 17, 18, 19] </ref>. <p> The compiler applies the following passes in order: analyze program, partition data, partition computation, analyze communication, optimize communication, manage storage, and generate code. Details are presented elsewhere <ref> [14, 17, 19, 26] </ref>. 2.3 The ParaScope Programming Environment The Fortran D compiler is implemented as a part of ParaScope, a programming environment that pioneered research on inter-procedural optimization in an efficient compilation system [8, 9]. <p> Furthermore, in Fortran D, data decompositions are propagated between procedures. For each procedure invocation, the formal parameters of the called procedure inherit the decompositions of the corresponding actual parameters passed at the call <ref> [14] </ref>. Global variables retain their decomposition from the caller. Since a program may span multiple modules (files), the actual Fortran D statements that describe the data decomposition for the reference may reside in another module. Interprocedural Reaching Decompositions. <p> Interprocedural Reaching Decompositions. Reaching decompositions refers to the problem of determining the data decomposition of a variable at a given point in the program <ref> [14] </ref>; the Fortran D compiler solves this problem using FIAT [15]. <p> If the solution was computed earlier, then the system returns the annotation without recomputing it. Details on how the interprocedural reaching decomposition solution is computed are discussed elsewhere <ref> [14] </ref>. After the interprocedural reaching decomposition annotation is computed by FIAT, the compiler performs local reaching decomposition to determine if an array's decomposition has been re-defined within the procedure. The resulting details on the decomposition, alignment, and distribution that reach every reference in the procedure are then stored.
Reference: [15] <author> M. W. Hall, J. Mellor-Crummey, A. Carle, and R. Rodriguez. FIAT: </author> <title> A framework for interprocedural analysis and transformation. </title> <booktitle> In Proceedings of the Sixth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: The D System supports Fortran D, a precursor and contributor to HPF that contains a subset of features found in HPF as well as support for capabilities not currently in HPF. The system contains FIAT, an interprocedural analysis framework <ref> [15] </ref>, the Fortran D compiler [17], and tools for performing automatic data decomposition [3], data-race detection, static performance estimation [4, 20], and performance profiling. All these components will be integrated in the D Editor, the core of the D system. <p> Its interprocedural compilation framework has been encapsulated into a system called FIAT (Framework for Interprocedural Analysis and Transformation) <ref> [15] </ref> and used to solve a number of inter-procedural problems in both ParaScope and the Stanford SUIF compiler. A key component of the ParaScope environment is the Para-Scope Editor (PED), an intelligent interactive editor for shared-memory machines [13, 21, 22]. <p> Interprocedural Reaching Decompositions. Reaching decompositions refers to the problem of determining the data decomposition of a variable at a given point in the program [14]; the Fortran D compiler solves this problem using FIAT <ref> [15] </ref>. Since FIAT's interprocedural analysis strategy is based upon a demand-driven paradigm, the compiler interface is able to obtain the solution to the reaching decomposition problem at any node in the call graph by demanding the annotation that corresponds to our problem.
Reference: [16] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran language specification, version 1.0. </title> <type> Technical Report CRPC-TR92225, </type> <institution> Center for Research on Parallel Computation, Rice University, Hous-ton, TX, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: The development process was tedious, error-prone, and the results were not very portable. To solve this problem, researchers, vendors, and users together informally created High Performance Fortran (HPF), a version of Fortran designed to provide a simple yet efficient data-parallel programming model across a wide range of modern architectures <ref> [16] </ref>. HPF was based on a number of existing languages such as Fortran 90 [1], CM Fortran [25], Fortran D [11], and Vienna Fortran [7]. It simplifies programming by providing a global name space for the user, along with a variety of useful data-parallel array operations.
Reference: [17] <author> S. Hiranandani, K. Kennedy, and C.-W. Tseng. </author> <title> Compiling Fortran D for MIMD distributed-memory machines. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 66-80, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: One of the novel features found in HPF are annotations that allow users or automatic tools to specify data placement, the partitioning of data onto processors. Using these annotations, in many cases advanced compilers can automatically generate efficient programs for MIMD distributed-memory machines <ref> [17] </ref> or even networks of workstations [2]. This research was sponsored by ARPA under contract #DABT63-91-K-0005 & DABT63-92-C-0038 and the IBM Corporation. Additional support was provided by the Center for Research on Parallel Computation (CRPC), a Science and Technology Center funded by NSF through Cooperative Agreement Number CCR-9120008. <p> Once communication is introduced, the first kernel will be sequentialized (unless additional program transformations such as strip-mining and loop interchange are applied by the compiler). In comparison, the second kernel will execute mostly in parallel, exploiting pipeline parallelism <ref> [17] </ref>. If the array A is distributed block-wise by rows instead, the situation is reversed. All four versions of SOR are shown in Figure 2. Arrows represent execution order; communication is required at the boundaries. <p> The D System supports Fortran D, a precursor and contributor to HPF that contains a subset of features found in HPF as well as support for capabilities not currently in HPF. The system contains FIAT, an interprocedural analysis framework [15], the Fortran D compiler <ref> [17] </ref>, and tools for performing automatic data decomposition [3], data-race detection, static performance estimation [4, 20], and performance profiling. All these components will be integrated in the D Editor, the core of the D system. <p> the D Editor must be able to explain to the user how changes in the high-level program will affect both the output code and its performance, especially changes to the data decomposition. 1.3 Contributions In previous work, we described the design, implementation, and evaluation of a prototype Fortran D compiler <ref> [14, 17, 18, 19] </ref>. <p> The compiler applies the following passes in order: analyze program, partition data, partition computation, analyze communication, optimize communication, manage storage, and generate code. Details are presented elsewhere <ref> [14, 17, 19, 26] </ref>. 2.3 The ParaScope Programming Environment The Fortran D compiler is implemented as a part of ParaScope, a programming environment that pioneered research on inter-procedural optimization in an efficient compilation system [8, 9]. <p> The dependence is thus internalized and does not affect node-level parallelism [3]. The entire loop nest is thus executed in parallel without synchronization. In order to avoid reporting these internalized data dependences, the Fortran D compiler applies algorithms to distinguish dependences causing synchronization between nodes as cross-processor dependences <ref> [17] </ref>. They are calculated by examining the pattern of data accesses of both endpoints of the dependence to determine whether they occur on separate processors. Non-time-step loops that can carry cross-processor dependences are labeled cross-processor loops; they help guide program transformations to exploit pipeline parallelism. <p> Cross-processor dependences can also be used to point out specific references that cause synchronization. Parallel and Pipelined Loops. Using information from cross--processor dependencesand loops, the Fortran D compiler can classify computations as parallel, pipelined, or sequential <ref> [17] </ref>. Using our definitions, parallel loop nests contain no cross-processor loops, sequential computations have an outermost cross-processor loop, and pipelined computations have a cross-processor loop in an inner position. For the D Editor we classify any loop enclosed in a cross-processor loop to be sequential. <p> respect to a loop, a message is classified as independent if it is communicated once before the loop, carried-all if it is executed by all processors at the beginning of each iteration of the loop, and carried-part if it is executed before and after the loop to synchronize pipelined computations <ref> [17] </ref>. Figure 5 shows examples of the three message types and references that cause each message. Note that the message type is selected based on the fundamental ordering constraint imposed by data dependence of the program, and is not an artifact of the Fortran D compiler. <p> Then the compiler interface can return the correct parallelism and granularity information depending on whether loop interchange and strip-mining are enabled in the control panel. As an added advantage, expert users can use the control panel to enable or disable various compiler optimizations and select the granularity for pipelining <ref> [17] </ref>. Unfortunately, providing a control panel for optimizations only solves part of the problem. Mapping performance and debugging information from the transformed program back to the original source is an open research problem; compiler assistance is likely to be essential. Communication Information.
Reference: [18] <author> S. Hiranandani, K. Kennedy, and C.-W. Tseng. </author> <title> Preliminary experiences with the Fortran D compiler. </title> <booktitle> In Proceedings of Supercomputing '93, </booktitle> <address> Portland, OR, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: the D Editor must be able to explain to the user how changes in the high-level program will affect both the output code and its performance, especially changes to the data decomposition. 1.3 Contributions In previous work, we described the design, implementation, and evaluation of a prototype Fortran D compiler <ref> [14, 17, 18, 19] </ref>. <p> Preliminary results show that for many programs, it is able to produce output that approaches the quality of hand-optimized code <ref> [18] </ref>. Given a data decomposition, the prototype compiler can automatically translate sequential programs into efficient parallel programs using the owner computes rule. The two major steps it performs in targeting MIMD distributed-memory machines are partitioning the data and computation across processors, then introducing communication for nonlocal accesses where needed.
Reference: [19] <author> S. Hiranandani, K. Kennedy, and C.-W. Tseng. </author> <title> Evaluating compiler optimizations for Fortran D. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 21(1) </volume> <pages> 27-45, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: the D Editor must be able to explain to the user how changes in the high-level program will affect both the output code and its performance, especially changes to the data decomposition. 1.3 Contributions In previous work, we described the design, implementation, and evaluation of a prototype Fortran D compiler <ref> [14, 17, 18, 19] </ref>. <p> The compiler applies the following passes in order: analyze program, partition data, partition computation, analyze communication, optimize communication, manage storage, and generate code. Details are presented elsewhere <ref> [14, 17, 19, 26] </ref>. 2.3 The ParaScope Programming Environment The Fortran D compiler is implemented as a part of ParaScope, a programming environment that pioneered research on inter-procedural optimization in an efficient compilation system [8, 9].
Reference: [20] <author> K. Kennedy, N. McIntosh, and K. S. M c Kinley. </author> <title> Static performance estimation in a parallelizing compiler. </title> <type> Technical Report TR91-174, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: The system contains FIAT, an interprocedural analysis framework [15], the Fortran D compiler [17], and tools for performing automatic data decomposition [3], data-race detection, static performance estimation <ref> [4, 20] </ref>, and performance profiling. All these components will be integrated in the D Editor, the core of the D system. <p> Execution times would also make it easier to evaluate the effectiveness of automatic data decomposition or program transformations. Performance statistics may either be collected at compile time through static performance estimation <ref> [4, 20] </ref> or at run time via profiling [10]. Graphic User Interfaces. Additional facilities for presenting analyses and performance data graphically can improve the usefulness of the D Editor.
Reference: [21] <author> K. Kennedy, K. S. M c Kinley, and C.-W. Tseng. </author> <title> Interactive parallel programming using the ParaScope Editor. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(3) </volume> <pages> 329-341, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: However, experience with parallelizing compilers for shared-memory machines has shown that no automatic system will work perfectly in all (some say most) cases. When automatic systems fail due to imperfect analysis or incorrect heuristics, compiler feedback [27] or interactive parallelization systems <ref> [13, 21] </ref> can prove helpful. 1.1 Feedback for High Performance Fortran We believe that user feedback and interaction will be very important for languages such as HPF, because on massively parallel systems small mistakes may cause large degradations in performance. <p> A key component of the ParaScope environment is the Para-Scope Editor (PED), an intelligent interactive editor for shared-memory machines <ref> [13, 21, 22] </ref>. The ParaScope Editor provides the results of sophisticated program analyses and a variety of powerful program transformations that have been shown useful in converting programs to parallel form. <p> A loop can only be executed in parallel if it does not carry any dependences. Data dependence information is provided by traditional programming tools such as the ParaScope Editor <ref> [21] </ref>. Because the D Editor is built on the ParaScope Editor, it can calculate and display data dependences in the same manner. Unfortunately, simply reporting occurrences of parallel loops is insufficient for determining the amount of parallelism exploited for languages such as Fortran D and HPF. <p> We first examine features of the graphical display, then show how it works on an example program. The D Editor display is derived from the display of the ParaScope Editor <ref> [13, 21, 22] </ref>, but contains significantly more information. Figure 6 provides an example of the user interface of the D Editor for different versions of SOR. The display is separated into five panes. <p> In this section we discuss some limitations of the current prototype and possible solutions, as well as some new features planned for the D Editor. 6.1 Limitations Compiler Transformations. The prototype D Editor assumes that the underlying compiler does not perform program transformations such as loop interchange and strip-mining <ref> [21] </ref>. As a result, the information it presents may be inaccurate for an automatically transformed program. For instance, for kernels such as SOR the Fortran D compiler can apply loop interchange to convert sequential computations into pipelined computations; these loops should be colored yellow rather than red. <p> These new features either display new information or suggest actions to improve program performance. Interactive Program Transformations. The ParaScope Editor provides a number of automatic structured program transformations targeting shared-memory machines, as well as advice as to the legality and profitability of each transformation <ref> [21] </ref>. We believe the same transformations can be useful in the D Editor. Legality may be determined in the same manner, but profitability may be quite different. <p> In comparison with these and other systems, the Fortran D compiler performs significantly more compile-time analysis and optimization and relies less on program transformations, language extensions or an extensive run-time system. The D Editor is based on the ParaScope Editor <ref> [13, 21, 22] </ref>. They share many features, including the underlying hybrid text/structure editor, graphics utilities, and dependence display. The ParaScope Editor is distinguished by its incremental analysis and ability to provide guidance on a large number of interactive program transformations.
Reference: [22] <author> K. Kennedy, K. S. M c Kinley, and C.-W. Tseng. </author> <title> Analysis and transformation in an interactive parallel programming tool. </title> <journal> Concurrency: Practice & Experience, </journal> <volume> 5(7) </volume> <pages> 575-602, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: A key component of the ParaScope environment is the Para-Scope Editor (PED), an intelligent interactive editor for shared-memory machines <ref> [13, 21, 22] </ref>. The ParaScope Editor provides the results of sophisticated program analyses and a variety of powerful program transformations that have been shown useful in converting programs to parallel form. <p> We first examine features of the graphical display, then show how it works on an example program. The D Editor display is derived from the display of the ParaScope Editor <ref> [13, 21, 22] </ref>, but contains significantly more information. Figure 6 provides an example of the user interface of the D Editor for different versions of SOR. The display is separated into five panes. <p> We believe the same transformations can be useful in the D Editor. Legality may be determined in the same manner, but profitability may be quite different. The D Editor can use the same algorithms as the ParaScope Editor to incrementally update dependence information after transformations <ref> [22] </ref>, but new techniques for updating parallelism, partitioning, and communication information are needed. Researchers are also studying the problem of incremental interprocedural analysis. New transformations to Fortran D or HPF data decomposition statements can also benefit the user. Automatic Data Decomposition. <p> In comparison with these and other systems, the Fortran D compiler performs significantly more compile-time analysis and optimization and relies less on program transformations, language extensions or an extensive run-time system. The D Editor is based on the ParaScope Editor <ref> [13, 21, 22] </ref>. They share many features, including the underlying hybrid text/structure editor, graphics utilities, and dependence display. The ParaScope Editor is distinguished by its incremental analysis and ability to provide guidance on a large number of interactive program transformations.
Reference: [23] <author> C. Koelbel and P. Mehrotra. </author> <title> Compiling global name-space parallel loops for distributed execution. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4) </volume> <pages> 440-451, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: The D Editor is one of the first to combine both features in a single parallel programming tool. The Fortran D compiler is similar to CALLAHAN-KENNEDY [6], SUPERB [12], and KALI <ref> [23] </ref> in that the compilation process is based on the decomposition of data in the program. In comparison with these and other systems, the Fortran D compiler performs significantly more compile-time analysis and optimization and relies less on program transformations, language extensions or an extensive run-time system.
Reference: [24] <author> B. Shei and D. Gannon. SIGMACS: </author> <title> A programmable programming environment. </title> <booktitle> In Advances in Languages and Compilers for Parallel Computing, </booktitle> <address> Irvine, CA, August 1990. </address> <publisher> The MIT Press. </publisher>
Reference-contexts: The ParaScope Editor is distinguished by its incremental analysis and ability to provide guidance on a large number of interactive program transformations. SIGMACS is another interactive system targeting shared-memory systems; it can display call graphs, process graphs, and a statement dependence graph <ref> [24] </ref>. TINY is a system that provides precise data dependence analysis and program transformations for a core subset of Fortran [28]. FORGE 90 is an interactive parallelization system that performs data-flow and dependence analyses and also supports loop-level transformations [2].
Reference: [25] <institution> Thinking Machines Corporation, </institution> <address> Cambridge, MA. </address> <note> CM Fortran Reference Manual, version 1.0 edition, </note> <month> February </month> <year> 1991. </year>
Reference-contexts: HPF was based on a number of existing languages such as Fortran 90 [1], CM Fortran <ref> [25] </ref>, Fortran D [11], and Vienna Fortran [7]. It simplifies programming by providing a global name space for the user, along with a variety of useful data-parallel array operations.
Reference: [26] <author> C.-W. Tseng. </author> <title> An Optimizing Fortran D Compiler for MIMD Distributed-Memory Machines. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: The compiler applies the following passes in order: analyze program, partition data, partition computation, analyze communication, optimize communication, manage storage, and generate code. Details are presented elsewhere <ref> [14, 17, 19, 26] </ref>. 2.3 The ParaScope Programming Environment The Fortran D compiler is implemented as a part of ParaScope, a programming environment that pioneered research on inter-procedural optimization in an efficient compilation system [8, 9].
Reference: [27] <author> M. J. Wolfe. </author> <title> Semi-automatic domain decomposition. </title> <booktitle> In Proceedings of the 4th Conference on Hypercube Concurrent Computers and Applications, </booktitle> <address> Monterey, CA, </address> <month> March </month> <year> 1989. </year>
Reference-contexts: However, experience with parallelizing compilers for shared-memory machines has shown that no automatic system will work perfectly in all (some say most) cases. When automatic systems fail due to imperfect analysis or incorrect heuristics, compiler feedback <ref> [27] </ref> or interactive parallelization systems [13, 21] can prove helpful. 1.1 Feedback for High Performance Fortran We believe that user feedback and interaction will be very important for languages such as HPF, because on massively parallel systems small mistakes may cause large degradations in performance.
Reference: [28] <author> M. J. Wolfe. </author> <title> The Tiny loop restructuring research tool. </title> <booktitle> In Proceedings of the 1991 International Conference on Parallel Processing, </booktitle> <address> St. Charles, IL, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: SIGMACS is another interactive system targeting shared-memory systems; it can display call graphs, process graphs, and a statement dependence graph [24]. TINY is a system that provides precise data dependence analysis and program transformations for a core subset of Fortran <ref> [28] </ref>. FORGE 90 is an interactive parallelization system that performs data-flow and dependence analyses and also supports loop-level transformations [2]. Associated tools graphically display call graph, control flow, dependence, and profiling information. FORGE 90 can be used to generate parallel programs for both shared and distributed-memory machines.
References-found: 28

