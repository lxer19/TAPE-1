URL: http://www.cs.ucsb.edu/TRs/techreports/TRCS95-11.ps
Refering-URL: http://www.cs.ucsb.edu/TRs/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: EXPLOITING COMMUTING OPERATIONS IN PARALLELIZING SERIAL PROGRAMS  
Author: PEDRO DINIZ AND MARTIN RINARD 
Address: SANTA BARBARA, CA 93106  
Affiliation: DEPARTMENT OF COMPUTER SCIENCE UNIVERSITY OF CALIFORNIA, SANTA BARBARA  
Abstract: Two operations commute if the result of their execution is independent of the order in which they execute. Commuting operations can be executed concurrently provided they execute atomically on the objects they access. Statically recognizing commuting operations is of great interest because they increase the amount of concurrency a compiler can exploit. In this document we introduce commutativity analysis anew technique for automatically parallelizing serial programs. We then conduct a feasibility study of existing scientific applications as to the existence and exploitability of commuting operations. We study the commuting operations present in one such application the Barnes-Hut hierarchical N-body algorithm. We then parallelize this application using knowledge of commuting operations and present performance results of the parallel code for a shared-memory multiprocessor. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> U. Banerjee, R. Eigenmann, A. Nicolau, and D. Padua. </author> <title> Automatic program parallelization. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 81(2) </volume> <pages> 211-243, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: The obvious programming advantages of the sequential imperative programming paradigm have therefore inspired the development of analysis techniques and compilers designed to automatically parallelize serial programs. Current parallelizing compilers preserve the semantics of the original serial program by preserving the data dependencies <ref> [1, 10] </ref>. These compilers attempt to identify independent pieces of computation (two pieces of computation are independent if neither writes a piece of data that the other accesses), then generate code that executes independent pieces concurrently.
Reference: [2] <author> J. Barnes and P. Hut. </author> <title> A hierarchical O(NlogN) force-calculation algorithm. </title> <journal> Nature, </journal> <volume> 324(4), </volume> <pages> pp 446-449, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: The Barnes-Hut Hierarchical N-body algorithm. The Barnes-Hut Hierarchical algorithm <ref> [2] </ref> is an important application code for several areas of science and engineering such as astrophysics and chemistry. The Barnes-Hut algorithm simulates the trajectories of a set of interacting bodies, for example galaxies or particles, under Newtonian forces from which system macro level properties can be computed.
Reference: [3] <author> P. Barth, R. Nikhil, and Arvind. M-structures: </author> <title> Extending a parallel, non-strict, functional language with state. </title> <booktitle> In Proceedings of the Fifth ACM Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 538-568. </pages> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1991. </year>
Reference-contexts: Finally, 1 preserving the data dependences for programs that periodically update shared data structures can artificially limit the amount of exposed concurrency, since tasks must delay updates until they are sure that each update will not change the relative order of reads and writes to the shared data structure <ref> [3, 16] </ref>. A new technique, commutativity analysis [17], has been developed that eliminates many of the limitations of existing data-dependence based approaches. Instead of preserving the relative order of individual reads and writes to single words of memory, commutativity analysis aggregates both data and computation into larger grain units.
Reference: [4] <author> D. Callahan. </author> <title> Recognizing and parallelizing bounded recurrences. </title> <booktitle> In Proceedings of the Fourth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Santa Clara, CA, </address> <month> August </month> <year> 1991. </year>
Reference: [5] <author> A. Fisher and A. Ghuloum. </author> <title> Parallelizing complex scans and reductions. </title> <booktitle> In Proceedings of the SIGPLAN '94 Conference on Program Language Design and Implementation, </booktitle> <address> Orlando, FL, </address> <month> June </month> <year> 1994. </year>
Reference: [6] <author> W .L. Harrison. </author> <title> The interprocedural analysis and automatic parallelization of Scheme programs. </title> <journal> Lisp and Symbolic Computation, </journal> 2(3/4):179-396, October 1989. 
Reference-contexts: While researchers have been able to develop reasonably effective algorithms for loop nests that manipulate dense matrices using affine access functions [13], there has been little progress towards the successful automatic analysis of programs that manipulate pointer-based data structures. Researchers have attempted to build totally automatic systems <ref> [6] </ref>, but the most promising approaches require the programmer to provide annotations that specify information about the global topology of the manipulated data structures [7]. The goal of these annotations is to help the compiler to discover pieces of code that access disjoint pieces of data. <p> Each method invocation locks the tree node object of the computation, concurrently spawns the recursive invocations and waits for them to terminate to compute the node's CofM new value. The problem of statically recognizing the shape of a recursively defined pointer-based data structure is a difficult one. General techniques <ref> [6] </ref> have been proposed but their effectiveness in dealing with existing applications not yet demonstrated. Related techniques [8] exist that can be used to verify properties of data structure, such as trees or acyclic graphs.
Reference: [7] <author> L. Hendren, J. Hummel, and A. Nicolau. </author> <title> Abstractions for recursive pointer data structures: improving the analysis and transformation of imperative programs. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Program Language Design and Implementation, </booktitle> <address> San Francisco, CA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Researchers have attempted to build totally automatic systems [6], but the most promising approaches require the programmer to provide annotations that specify information about the global topology of the manipulated data structures <ref> [7] </ref>. The goal of these annotations is to help the compiler to discover pieces of code that access disjoint pieces of data. A second, more fundamental limitation of data-dependence based approaches is an inability to parallelize computations that manipulate graph-like data structures.
Reference: [8] <author> L. Hendren, and A. Nicolau. </author> <title> Parallelizing programs with recursive data structures In IEEE Transacions on Parallel and Distributed Systems, </title> <publisher> 1(1),1990 </publisher>
Reference-contexts: The problem of statically recognizing the shape of a recursively defined pointer-based data structure is a difficult one. General techniques [6] have been proposed but their effectiveness in dealing with existing applications not yet demonstrated. Related techniques <ref> [8] </ref> exist that can be used to verify properties of data structure, such as trees or acyclic graphs.
Reference: [9] <author> S. Hummel, E. Schonberg and L. Flynn. </author> <title> Factoring: A Practical and Robust Method for Scheduling Parallel Loops Technical Report 74172, </title> <institution> IBM Research Divison, </institution> <year> 1987. </year>
Reference-contexts: In the Barnes-Hut case study this recursive computation paradigm was used in the computation of the center of mass. 5.2.2. Loop computations. For the cases of the simple loop level parallelism a more efficient scheme can be devised. Instead of filling task descriptors a self-scheduling <ref> [9, 12, 15] </ref> strategy might be used where each processor "steals" a set of loop iterations which executes in a irrevocable fashion.
Reference: [10] <author> D. Kuck, Y. Muraoka, and S. Chen. </author> <title> On the number of operations simultaneously executable in Fortran-like programs and their resulting speedup. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-21(12):1293-1310, </volume> <month> December </month> <year> 1972. </year>
Reference-contexts: The obvious programming advantages of the sequential imperative programming paradigm have therefore inspired the development of analysis techniques and compilers designed to automatically parallelize serial programs. Current parallelizing compilers preserve the semantics of the original serial program by preserving the data dependencies <ref> [1, 10] </ref>. These compilers attempt to identify independent pieces of computation (two pieces of computation are independent if neither writes a piece of data that the other accesses), then generate code that executes independent pieces concurrently.
Reference: [11] <author> D. Lenoski. </author> <title> The Design and Analysis of DASH: A Scalable Direcoty-based Multiprocessor. </title> <institution> Department of Computer Science, Stanford University, </institution> <type> Technical Report CSL-TR-92-507, </type> <month> February </month> <year> 1992. </year>
Reference-contexts: We then take a particular application, the Barnes-Hut hierarchical N-body algorithm, and parallelize it using the knowledge of commuting operations. We evaluate the performance of the parallel code on the Stanford DASH <ref> [11] </ref>, a cache-coherent, shared-memory multiprocessor. This document is organized as follows. The next section introduces commutativ-ity analysis by means of a graph traversal example. Section 3 describes the analysis of SPLASH applications in light of commuting operations used. <p> In the next subsections we describe the multiprocessor characterization, run-time environment used and the parallel code generation templates. 11 5.1. The Stanford DASH Machine. The Stanford DASH machine <ref> [11] </ref> is a cache-coherent shared-memory multiprocessor. It uses a distributed directory-based protocol to provide cache coherence. It is organized as a group of processing clusters connected by a mesh interconnection network. Each of the clusters is a Silicon Graphics 4D/340 bus-based multiprocessor.
Reference: [12] <author> S. Lucco. </author> <title> A Dynamic Scheduling Method for Irregular Parallel Programs. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Program Language Design and Implementation, </booktitle> <address> San Francisco, CA, </address> <month> June </month> <year> 1992 </year>
Reference-contexts: In the Barnes-Hut case study this recursive computation paradigm was used in the computation of the center of mass. 5.2.2. Loop computations. For the cases of the simple loop level parallelism a more efficient scheme can be devised. Instead of filling task descriptors a self-scheduling <ref> [9, 12, 15] </ref> strategy might be used where each processor "steals" a set of loop iterations which executes in a irrevocable fashion.
Reference: [13] <author> D. Maydan, J. Hennessy, and M. Lam. </author> <title> Efficient and exact data dependence analysis. </title> <booktitle> In Proceedings of the SIGPLAN '91 Conference on Program Language Design and Implementation, </booktitle> <address> Toronto, Canada, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: A significant limitation of this approach is the difficulty of performing dependence analysis that is precise enough to expose substantial amounts of concurrency. While researchers have been able to develop reasonably effective algorithms for loop nests that manipulate dense matrices using affine access functions <ref> [13] </ref>, there has been little progress towards the successful automatic analysis of programs that manipulate pointer-based data structures.
Reference: [14] <author> E. Mohr, D. Kranz and R. Halstead. </author> <title> Lazy Task Creation: A Technique for Increasing the Granularity of Parallel Programs In IEEE Transactions on Parallel and Distributed Systems, </title> <journal> Vol. </journal> <volume> 2 (3), </volume> <pages> pp 264-280, </pages> <month> July, </month> <year> 1991. </year>
Reference-contexts: Relevant issues in the design of such run-time support are both load-balancing and task grain size. For its simplicity we use a variant of the simple load-based task inlining mechanism despite some of the drawbacks mentioned by Mohr <ref> [14] </ref>. Each process may spawn as many task as desired, constructing and putting in a globally accessible work list a task descriptor. This descriptor holds the address and the arguments of the function to be executed.
Reference: [15] <author> C. Polychronopoulos and D. Kuck. </author> <title> Guided Self-Scheduling: A Practical Scheduling Scheme for Parallel Supercomputers. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 36(12) </volume> <pages> 1425-1439, </pages> <month> December </month> <year> 1987. </year>
Reference-contexts: In the Barnes-Hut case study this recursive computation paradigm was used in the computation of the center of mass. 5.2.2. Loop computations. For the cases of the simple loop level parallelism a more efficient scheme can be devised. Instead of filling task descriptors a self-scheduling <ref> [9, 12, 15] </ref> strategy might be used where each processor "steals" a set of loop iterations which executes in a irrevocable fashion.
Reference: [16] <author> M. Rinard. </author> <title> The Design, Implementation and Evaluation of Jade, a Portable, Implicitly Parallel Programming Language. </title> <type> PhD thesis, </type> <institution> Stanford, </institution> <address> CA, </address> <year> 1994. </year>
Reference-contexts: Finally, 1 preserving the data dependences for programs that periodically update shared data structures can artificially limit the amount of exposed concurrency, since tasks must delay updates until they are sure that each update will not change the relative order of reads and writes to the shared data structure <ref> [3, 16] </ref>. A new technique, commutativity analysis [17], has been developed that eliminates many of the limitations of existing data-dependence based approaches. Instead of preserving the relative order of individual reads and writes to single words of memory, commutativity analysis aggregates both data and computation into larger grain units.
Reference: [17] <author> M. Rinard and P. Diniz. </author> <title> Commutativity Analysis : A New Technique for Automatically Paral-lelizing Serial Programs. </title> <type> Tech. Rep. </type> <institution> TRCS94-16, University of California, Santa Barbara, </institution> <address> CA, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: A new technique, commutativity analysis <ref> [17] </ref>, has been developed that eliminates many of the limitations of existing data-dependence based approaches. Instead of preserving the relative order of individual reads and writes to single words of memory, commutativity analysis aggregates both data and computation into larger grain units. <p> In section 5 we describe practical experiments with this application and report performance results. Finally, we present the conclusions in section 6. 2. Commutativity Analysis. We briefly describe the basic commutativity analysis approach. A full description of this technique can be found in <ref> [17] </ref>. Commutativity analysis is a static analysis framework for detecting commuting operations. Two operations commute when they generate the same result regardless of the order in which they execute. Commutativity analysis is designed for programs written using a pure object-based paradigm.
Reference: [18] <author> J. Singh, W. Weber, and A. Gupta. </author> <title> SPLASH: Stanford parallel applications for shared memory. </title> <type> Tech. Rep. </type> <institution> Computer Science Laboratory, CSL-TR-91-469, </institution> <month> April 91. </month>
Reference-contexts: The goals of this study are twofold. First, observe which commuting operations have been used in effectively parallelizing sequential applications. Second, assess the difficulty in automatically detecting and exploiting such commuting operations. For the purpose of this study we analyze applications included in the SPLASH benchmark <ref> [18] </ref> as they represent complete applications engineers and scientists use in practice. We then take a particular application, the Barnes-Hut hierarchical N-body algorithm, and parallelize it using the knowledge of commuting operations. We evaluate the performance of the parallel code on the Stanford DASH [11], a cache-coherent, shared-memory multiprocessor. <p> Commuting operations in application codes. The applications we have analyzed are included in the Stanford SPLASH benchmark set of applications for shared-memory multiprocessors. Details of both sequential codes and the technical issues pertaining the parallelization process for the DASH machine can be found in the SPLASH report <ref> [18] </ref> and references within. In this study we have observed the parallelized applications' source codes. No sequential codes were available. With the available description of the applications we were able to reason in the cases described in this section about the sequential program's semantics.
Reference: [19] <author> J. Singh and J. Hennessy, </author> <title> Finding and Exploiting Parallelism in an Ocean Simulation Program: Experience, Results and Implications, </title> <journal> In Journal of Parallel and Distributed Computing, </journal> <volume> vol. 15, no. 1, </volume> <year> (1992), </year> <pages> pp. 27-58. </pages>
Reference: [20] <author> J. Singh. </author> <title> Parallel Hierarchical N-Body Methods and their Implications for Multiprocessors. </title> <type> PhD thesis, Tech. Report No. </type> <institution> CSL-TR-93-565, Stanford, </institution> <address> CA, </address> <year> 1993. </year> <month> 15 </month>
Reference-contexts: Each leaf holds a maximum constant capacity of bodies. Under suitable cut-off distance selection the error incurred in the algorithm approximation can be made negligible and consistent with the finite-arithmetic round-off error. sequential algorithm or its parallelization for shared-memory or distributed-memory machines can be found in <ref> [24, 20] </ref>. read simulation parameters while (simulated time &lt; final time) do f /* construct BH tree */ for all bodies do insert body b i in the BH tree /* compute center of mass */ recursively traverse tree and compute center-of-mass /* compute gravitational forces */ for all bodies do <p> Even at 16K particles the SPLASH2 version is at most 20% faster. This is a very encouraging result considering the amount of effort and sophistication of the optimizations in the SPLASH2 version <ref> [20] </ref>. 13 Processors Nbody 1 2 4 8 16 Time Spdup Time Speedup Time Speedup Time Speedup Time Speedup 1024 7.94 1.0 4.05 1.96 2.19 3.63 1.38 5.75 0.92 8.63 4096 51.23 1.0 26.82 1.91 14.20 3.61 8.09 6.33 5.16 9.93 16384 301.4 1.0 146.9 2.05 77.56 3.88 45.60 6.61 26.13
Reference: [21] <author> D. Wagner and B. Calder. </author> <title> Leapfrogging: A Portable Technique for Implementing Efficient Futures. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Principles and Practive of Parallel Programing, </booktitle> <month> July, </month> <year> 1993. </year>
Reference-contexts: Task descriptors are seized and executed by idle processes filling the appropriate return value slots. We have implemented a very simple task spawning policy based on local and global load information. Rather then examining system load by the length of its task queue, as is the case in <ref> [21] </ref>, we use a unitary length queue per processor, i.e. a table, as suggested by Weening [22] and a global shared variable indicating if there idle processes based on which either spawning or task inlining is performed. The implementation is in spirit close to Leapfroging [21]. <p> as is the case in <ref> [21] </ref>, we use a unitary length queue per processor, i.e. a table, as suggested by Weening [22] and a global shared variable indicating if there idle processes based on which either spawning or task inlining is performed. The implementation is in spirit close to Leapfroging [21]. However, we have implemented more task spawning/synchronization schemes to efficiently meet the diversity of applications' computation paradigms. 5.2.1. Recursive computations. At each invocation multiple tasks are potentially spawned and added to a local queue in the computations' activation frame 3 (see code generation) upon which synchronization might be enforced.
Reference: [22] <author> I. A. Mason, J. D. Pehoushek, C. Talcott and J. Weening. </author> <title> Programming in QLisp. </title> <institution> Department of Computer Science, Stanford University, </institution> <type> Technical Report CS-90-1340, </type> <year> 1990. </year>
Reference-contexts: We have implemented a very simple task spawning policy based on local and global load information. Rather then examining system load by the length of its task queue, as is the case in [21], we use a unitary length queue per processor, i.e. a table, as suggested by Weening <ref> [22] </ref> and a global shared variable indicating if there idle processes based on which either spawning or task inlining is performed. The implementation is in spirit close to Leapfroging [21]. However, we have implemented more task spawning/synchronization schemes to efficiently meet the diversity of applications' computation paradigms. 5.2.1. Recursive computations.
Reference: [23] <author> W. Weihl. </author> <title> Commutativity-based concurrency control for abstract data types. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37(12) </volume> <pages> 1488-1505, </pages> <month> December </month> <year> 1988. </year>
Reference: [24] <author> M. S. Warren and J. K. Salmon. </author> <title> Astrophysical N-Body Simulations Using Hierarchical Tree Data Structures. </title> <booktitle> In Proceedings of SuperComputing '92 IEEE Comp. </booktitle> <publisher> Soc. </publisher> <pages> pp 570-576, </pages> <year> 1992. </year>
Reference-contexts: Each leaf holds a maximum constant capacity of bodies. Under suitable cut-off distance selection the error incurred in the algorithm approximation can be made negligible and consistent with the finite-arithmetic round-off error. sequential algorithm or its parallelization for shared-memory or distributed-memory machines can be found in <ref> [24, 20] </ref>. read simulation parameters while (simulated time &lt; final time) do f /* construct BH tree */ for all bodies do insert body b i in the BH tree /* compute center of mass */ recursively traverse tree and compute center-of-mass /* compute gravitational forces */ for all bodies do
Reference: [25] <author> S. Woo, M. Ohara, E. Torrie, J. Singh, and Anoop Gupta. </author> <title> The SPLASH-2 Programs: Characterization and Methodological Considerations. </title> <booktitle> In Proceedings of the 22nd Annual International Symposium on Computer Architecture. </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: We have derived the code from the barnes application code included in the SPLASH2 benchmark set <ref> [25] </ref> and modified it to an object-based style suitable for analysis by a compiler using commutativity analysis techniques. We then parallelized by hand this serial program taking advantage of the fact that the methods comp grav, body interaction and cell interaction commute.
References-found: 25

