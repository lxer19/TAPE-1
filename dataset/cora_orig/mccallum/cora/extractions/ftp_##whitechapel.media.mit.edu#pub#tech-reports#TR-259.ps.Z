URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-259.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: steve@media.mit.edu, picard@media.mit.edu  
Title: VIRTUAL BELLOWS: CONSTRUCTING HIGH QUALITY STILLS FROM VIDEO Examples of constructing high-quality stills are shown
Author: Steve Mann and Rosalind W. Picard 
Address: 20 Ames Street; Cambridge, MA 02139  
Affiliation: MIT Media Laboratory;  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 259 Appears, Proc. First IEEE Int. Conf. on Image Proc., Austin TX, November 1994. Abstract Cameras with bellows give photographers flexibility for controlling perspective, but once the picture is taken, its perspective is set. We introduce `virtual bellows' to provide control over perspective after a picture has been taken. Virtual bellows can be used to align images taken from different viewpoints, an important initial step in applications such as creating a high-resolution still image from video. We show how the virtual bellows, which implements the projective group, is an exact model fit to both pan and tilt. Specifically, we identify two important classes of image sequences accomodated by the virtual bellows. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.M. Tekalp, M.K. Ozkan, and M.I. Sezan. </author> <title> High-resolution image reconstruction from lower-resolution image sequences and space-varying image restoration. </title> <booktitle> In Proc. of the Int. Conf. on Acoust., Speech and Sig. Proc., pages III-169, </booktitle> <address> San Francisco, CA, </address> <month> Mar. </month> <pages> 23-26, </pages> <year> 1992. </year> <note> IEEE. </note>
Reference-contexts: The enhancement relies on the fact that typically there is some relative movement between the scene and the camera; movement is exploited in some way, using multiple frames of an image sequence to make a new image with higher resolution. Tekalp, Ozkan, and Sezan <ref> [1] </ref> have assumed the movement between frames is translation: in their model, they assume that the image sensor has shifted by some small amount between frames, so one frame may be used to fill in some of the spaces between the samples of another. <p> Although our mapping is from IR to IR (as opposed to theirs from C to C ), we can still borrow the concepts of complex analysis. In particular, a simple group-representation is provided using the 2 fi 2 matrices, p = <ref> [a; b; c; 1] </ref> 2 IR 2 fi IR 2 . <p> Let's begin with the mapping from X 2 to x 2 : x 2 = z 2 tan (arctan (X 2 =Z 2 ) 2 ) = a 2 X 2 + b 2 (5) which can be represented by the matrix p 2 = <ref> [a 2 ; b 2 ; c 2 ; 1] </ref>, so that x 2 = p 2 ffi X 2 . <p> X 1 t x and it is clear that this coordinate transformation is inside the group, for there exists the choice of a = 1, b = t x , and c = 0 that describe it: X 2 = p t ffi X 1 , where p t = <ref> [1; t x ; 0; 1] </ref>. Finally, x 1 = z 1 tan (arctan (X 1 =Z 1 ) ) = p 1 ffi X 1 . Let p 1 = [a 1 ; b 1 ; c 1 ; 1]. <p> Finally, x 1 = z 1 tan (arctan (X 1 =Z 1 ) ) = p 1 ffi X 1 . Let p 1 = <ref> [a 1 ; b 1 ; c 1 ; 1] </ref>. Then p = p 2 ffi p t ffi p 1 1 is in the group by the law of composition. <p> Proposition 3 The two groups P 1 and P 2 are isomorphic; a group-representation for both is given by the 2 fi 2 square matrix <ref> [a; b; c; 1] </ref>. Isomorphism follows because P 1 and P 2 have the same group representation. The (ax + b)=(cx + 1) operators in the above propositions form the projective group P in Flatland. <p> Let us now construct a similar plot for a member of the group of operators, p 2 P, in particular, the operator p = <ref> [2; 2; 1; 1] </ref> which corresponds to p 0 = f1; 2; 45 ffi g 2 P 1 . We have also depicted the result of mapping g (x 1 ) = sin (2x 1 ) to h (x 2 ). <p> The planar object case, P 2 , exists inside an 8-parameter operator group based on the coordinate transformations: u = u A [x; y] T + b = c T x + 1 where the group representation may be obtained, again using 2 fi 2 matrices, p = <ref> [A; b; c; 1] </ref>, but where A 2 IR 2fi2 , and b; c 2 IR 2fi1 . An example of the group-action of (10) is illustrated in Fig. 4 together with an exemplar affine group-action.
Reference: [2] <author> M. Irani and S. Peleg. </author> <title> Improving Resolution by Image Registration. Graphical Models and Img. </title> <booktitle> Proc., </booktitle> <month> May </month> <year> 1991. </year>
Reference-contexts: They note that image noise reduction can be applied either after this filling-in process, or concurrently, to further enhance the image. Others have assumed affine motion (six parameters) between frames <ref> [2] </ref> [3]. Consider an "ideal" 1 pinhole camera. <p> Let us now construct a similar plot for a member of the group of operators, p 2 P, in particular, the operator p = <ref> [2; 2; 1; 1] </ref> which corresponds to p 0 = f1; 2; 45 ffi g 2 P 1 . We have also depicted the result of mapping g (x 1 ) = sin (2x 1 ) to h (x 2 ). <p> Since the circuit board is almost flat, it is a close fit to the model depicted in Fig. 2, and is well-described by the virtual bellows. In both cases the method we used was similar to that of Irani and Peleg <ref> [2] </ref>, except that the proposed virtual bellows (projective group) model was used, instead of the affine group model. 4.1 The "chirping" point spread function Estimating and working with the point spread function (PSF) is an important aspect of resolution enhancement. <p> As the images are `dechirped', the PSFs associated with each image become `rechirped' onto the no-longer periodic lattice. Irani and Peleg <ref> [2] </ref> have proposed the use of a small dot to characterize the PSF. We found, however, in attempting 4 space, namely the center of a typical computer room.
Reference: [3] <author> L. Teodosio and W. Bender. </author> <title> Salient video stills: Content and context preserved. </title> <booktitle> Proc. ACM Multimedia Conf., </booktitle> <year> 1993. </year>
Reference-contexts: They note that image noise reduction can be applied either after this filling-in process, or concurrently, to further enhance the image. Others have assumed affine motion (six parameters) between frames [2] <ref> [3] </ref>. Consider an "ideal" 1 pinhole camera.
Reference: [4] <author> R. Y. Tsai and T. S. Huang. </author> <title> Estimating Three-Dimensional Motion Parameters of a Rigid Planar Patch . Trans. Accoust., Speech, and Sig. </title> <booktitle> Proc., </booktitle> <year> 1981. </year>
Reference-contexts: Tsai and Huang <ref> [4] </ref> have also explored the group structure associated with images of a 3-D rigid planar patch, as well as the associated Lie algebra, although they assume that explicit features have been located and that the correspondence problem has already been solved.
Reference: [5] <author> S. Mann. </author> <title> Compositing multiple pictures of the same scene: Generalized large-displacement 8-parameter motion. </title> <booktitle> In Proceedings of the 46th Annual IS&T Conference, </booktitle> <address> Cambridge, Mas-sachusetts, </address> <month> May 9-14 </month> <year> 1993. </year> <institution> The Society of Imaging Science and Technology. </institution>
Reference-contexts: Previous work has been done to simply blend multiple pictures of a single scene <ref> [5] </ref>, using a 2-D projective model. This work involved a search over the 8-parameter space to minimize the mean-square error (or maximize the inner product) between one frame and a 2-D projective coordinate transformation of the next frame, and did not rely on explicit feature correspondences.
Reference: [6] <author> R. Szeliski and J. Coughlan. </author> <title> Hierarchical spline-based image registration. </title> <address> CVPR, </address> <year> 1994. </year>
Reference-contexts: This work involved a search over the 8-parameter space to minimize the mean-square error (or maximize the inner product) between one frame and a 2-D projective coordinate transformation of the next frame, and did not rely on explicit feature correspondences. Szeliski and Coughlan <ref> [6] </ref> have more recently proposed a similar blending of images using an 8-parameter projective model. In this paper we propose a means of resolution enhancement that does not require the tracking and correspondence of explicit features, yet runs fast enough to be computation-ally practical.
Reference: [7] <author> Edwin A. Abbott. Flatland. Signet Classic, </author> <month> June </month> <year> 1984. </year>
Reference-contexts: The 1-D "images" are confined to a line within a planar world, which we call "Flatland" after the title of Abbott's book <ref> [7] </ref>, which is a story about an alien culture living in a 2-D world.
Reference: [8] <author> M. </author> <title> Artin. Algebra. </title> <publisher> Prentice Hall, </publisher> <year> 1991. </year>
Reference-contexts: We should 2 also known as a group action or G-set <ref> [8] </ref>. 3 Single quotes denote terms coined by the authors here or elsewhere in the literature. a different principal distance (zoom setting). In both cases the camera is located at the same place (COP). <p> Closure 4 and associativity are obtained by using the usual laws of matrix multiplication followed with dividing the resulting vector's first element by its second element. 2 4 Also know as law of composition <ref> [8] </ref> 2 imaged twice, each time with a different camera orientation, a different principal distance (zoom setting), and different camera location (resolved into components parallel and perpendicular to the object).
Reference: [9] <author> B. Horn and B. Schunk. </author> <title> Determining Optical Flow. </title> <journal> Artificial Intelligence, </journal> <year> 1981. </year>
Reference-contexts: When the change from one image to another is small, optical flow <ref> [9] </ref> is often used.
Reference: [10] <author> S. Mann. </author> <title> Wavelets and chirplets: Time-frequency perspectives, with applications. </title> <editor> In Petriu Archibald, editor, </editor> <booktitle> Advances in Machine Vision, Strategies and Applications. World Scientific, </booktitle> <year> 1992. </year>
Reference-contexts: The two image sensors are in front of the camera to simplify mathematical derivations. emphasize here that if we set c = 0 we arrive at the affine group, and that c, the degree of perspective, has been given the interpretation of a chirp-rate <ref> [10] </ref> uniformly spaced points in x 1 are mapped to "chirped" points in x 2 . <p> We have also depicted the result of mapping g (x 1 ) = sin (2x 1 ) to h (x 2 ). When G is the space of Fourier analysis functions (harmonic oscillations), then H is a family of functions known as P-chirps <ref> [10] </ref>, adapted to a particular vanishing point, o 2 and `normalized chirp-rate', c 0 = c 2 =(bc a) [11]. <p> The usual affine model is augmented with an additional parameter, c = [c x ; c y ], which, again has the interpretation of mapping a uniform pattern to a "chirp" <ref> [10] </ref> but now with two components. The fixed COP case, P 1 , extends to a 4-parameter group based on c, rotation about the optical axis by , and zoom by z. <p> A useful interpretation of the 8 parameters of this group are as follows: 6 of the parameters correspond to the affine group, and the remaining two have the interpretation of chirp rate <ref> [10] </ref>. Analogous to the 1-D case, the element p, that maps one image to another, may be found from explicit feature correspondences by solving a system of 8 (or more) linear equations in 8 (or more) unknowns. Four (or more) point correspondences are required in 2-D.
Reference: [11] <author> S. Mann and R.W. </author> <title> Picard. The virtual bellows: A new perspective on the rigid planar patch. </title> <type> TR 260, </type> <institution> M.I.T. Media Lab Perceptual Computing Section, </institution> <address> Cambridge, Ma, </address> <month> Jan </month> <year> 1994. </year>
Reference-contexts: 1 6= o 1 (2) where a = z 2 =z 1 , b = z 2 tan (), c = tan ()=z 1 , and o 1 = z 1 tan (=2 + ) = 1=c, is the location of the singularity in the domain (`appearing point 3 ' <ref> [11] </ref>). We should 2 also known as a group action or G-set [8]. 3 Single quotes denote terms coined by the authors here or elsewhere in the literature. a different principal distance (zoom setting). In both cases the camera is located at the same place (COP). <p> When G is the space of Fourier analysis functions (harmonic oscillations), then H is a family of functions known as P-chirps [10], adapted to a particular vanishing point, o 2 and `normalized chirp-rate', c 0 = c 2 =(bc a) <ref> [11] </ref>. <p> In particular, the multivariate Taylor series expansion of (10) takes on the form: u = p u +p ux x+p uy y+p uxy xy+p uxx x +p uyy y +: : : 2 2 There are different ways <ref> [11] </ref> of relating the parameters in (11) to the three parameters (eight scalar parameters) A; b, and c using a hierarchical and recursive (iterative) approach. functions for four samples (pixels). (a) Frame 1 of the image sequence. (b) Frame 2 of the sequence. (c) Frames 1 and 2 registered. <p> This process amounts to automatically aligning (register ing) the various frames without using explicit features. We should emphasize that while the Taylor series is an approximation, the recursion <ref> [11] </ref> is done using the exact projective model (approximate feedforward, exact feedback) leading to a system where very large image motions can be estimated accurately. 4 HIGH RESOLUTION STILLS FROM VIDEO We now apply the `virtual bellows' model to resolution enhancement for each of the two cases depicted in Figs. 1
Reference: [12] <author> L.V. Ahlfors. </author> <title> Complex Analysis. </title> <booktitle> International Series in Pure and Applied Mathematics. </booktitle> <publisher> McGraw Hill, Inc., 3rd edition, </publisher> <year> 1979. </year> <month> 5 </month>
Reference-contexts: The identity operation is given by g = g ffi e, where e is given by a = 1, b = 0, and c = 0. In complex analysis, (see for example, Ahlfors <ref> [12] </ref>) the form (az + b)=(cz + d) is known as a linear fractional transformation. Although our mapping is from IR to IR (as opposed to theirs from C to C ), we can still borrow the concepts of complex analysis.
References-found: 12

